\section{Universal Continuous Mapping} % 2 pages
\label{sec:UCM}
The previous \cref{sec:UE} proposes universal encoding model for various data.
%
Taking that function as a basis, in this section, our Universal Continuous Mapping produces a map of latents to implicitly represent the scene.
We name such scene representation \textbf{Latent Implicit Maps (LIM)}.
%is uesed to produce Latent Implicit Maps 
Which supports surface, surface properties, and high-dimensional surface features. 
%
%\begin{figure}[htbp]
%	\centering
%	\includegraphics[width=.8\linewidth]{im/inherit_graph}
%	\caption{Inheritance graph for the class of Latent Implicit Maps (LIM).}
%	\label{fig:inherit}
%\end{figure}
\begin{figure}[htbp]
	\centering
	\psfragfig[width=1\linewidth]{im/eps/graph}{
		\psfrag{A}{\color{white}{\textbf{BaseMap}}}
		\psfrag{B}{\color{white}{\textbf{SurfaceMap}}}
		\psfrag{C}{\color{white}{\textbf{PropertyMap}}}
		\psfrag{D}{\color{white}{\textbf{LatentMap}}}
	}
	\caption{Inheritance graph for the class of Latent Implicit Maps (LIM).}
\label{fig:inherit}
\end{figure}

%Instead of directly producing a explicit map, our universal continuous mapping produces a map of latents to implicitly represent the scene.
%We name it \textbf{Latent Implicit Maps (LIM)}.
%FIXED: With was used before and should therefore be defined before.



The inheritance graph is plotted in \cref{fig:inherit}.
We design a BaseMap for operating the voxel structure (\cref{sec:map_rep}), dynamically allocating space and fusing maps (\cref{sec:fuse}).
The derived SurfaceMap (\cref{sec:surface_mapping}) and PropertyMap (\cref{sec:context_fields}) process specific data and operate for the specific application.
The LatentMap (\cref{sec:latent_fields}) is derived from PropertyMap.
The main difference is that the PropertyMap mainly operates low dimensional properties, such as color ($c=3$) or infrared ($c=1$) data, etc. 
While the LatentMap operates much higher dimensional feature, such as CLIP embeddings~\cite{ghiasi2022scaling} ($c=768$), for different application purposes.

\subsection{Map Representation}
\label{sec:map_rep}

We follow Neural Implicit Maps (~\cite{huang2021di,yuan2022algorithm,li2022bnv}) to use uniform-spaced voxels to sparsely represent the scene. The scene is $\V V=\{\V v_m = (\V c_m, \V F_m, w_m)\}$. $m$ is the voxel index. $\V v_m$ denotes the contents of that voxel which are $\V c_m\in \mathbb R^3$, $\V F_m\in \mathbb R^{l \times c}$ and $w_m\in\mathbb N$ respectively representing the voxel center, voxel latent feature and observed points count.

With a sequence of incremental frames as input, our model constructs local LIMs (\cref{sec:surface_mapping}, \cref{sec:context_fields}, \cref{sec:latent_fields}) and fuses (\cref{sec:fuse}) into a global LIM.
%
Then the resulting explicit map is inferenced from the global LIM.

\subsection{Surface Mapping}
\label{sec:surface_mapping}

Because the input point cloud $\V X$ is on zero-level of the surface, it is not adequate to recover a 3D field of scene, $f_{SDF}:\mathbb R^3 \rightarrow \mathbb R$.
%
Thus, we explopit the idea of Gaussian Process Implicit Surfaces (GPIS)~\cite{martens2016geometric,lee2019online,wu2021faithful,ivan2022online} to feed derivatives to kernel or to additionally sample non zero-level points.
%And the $\V y$ we use for regression is distance.
%
Both, derivative-based and sample-based GPISs use normal information.
Thus, we first pre-process $\V X$ to obtain normals $\V S$. 

\subsubsection{Using Derivatives based GPIS}
\label{sec:GPIS:deri}

From~\cite{martens2016geometric}, derivatives of a GP are also Gaussian. 
So the covariance between data and derivatives is the differentiation of the covariance function~\cite{solak2002derivative}:
%FIXED: Citation ???
\begin{equation}
	\begin{split}
cov(\frac{f_{SDF}(\V x) }{\partial x_i}, f_{SDF}((x^{'}))) &= \frac{\partial k(\V x, \V x^{'})}{\partial x_i}\\
&=\frac{\partial}{\partial x_i}[f_{posi}(\V x)]^Tf_{posi}(\V x^{'}).
	\end{split}
\end{equation}
Additionally,
\begin{equation}
\begin{split}
cov(\frac{f_{SDF}(\V x) }{\partial x_i}, \frac{f_{SDF}(\V x^{'}) }{\partial x_j}) &= \frac{\partial^2 k(\V x, \V x^{'})}{\partial x_i\partial x^{'}_j}\\
&=\frac{\partial}{\partial x_i}[f_{posi}(\V x)]^T\frac{\partial}{\partial x^{'}_j}[f_{posi}(\V x^{'})].
\end{split}
\end{equation}
So given points $\{\V x_n\}^N_{n=1}$ with normals $\{\V s_n\}^N_{n=1}$ and field values $\{\V y_n=0\}^N_{n=1}$,
the positional encoding function for derivatives is $f_{posi, deri}(\V x, i) = \frac{\partial}{\partial x_i}[f_{posi}(\V x)]$.
Its corresponding field value is the normal value $s_i$ on the axis $i$.
Then,
\begin{multline}
f_{posi, gpis}(\V X)=\\ [f_{posi}(\V X), f_{posi, deri}(\V x, 1), f_{posi, deri}(\V x, 2), f_{posi, deri}(\V x, 3)]
\end{multline}
with regression values $\V y_{gpis}=[\V 0, \V s_{\cdot,1}, \V s_{\cdot,2}, \V s_{\cdot,3}]^T$, where $\V 0 = zeros(1,N)$, $\V s_{\cdot,i}=[\V s_{1,i},\cdots,s_{N,i}]$.

Therefore the local geometric encoding function is
\begin{multline}
f_{enc, GPIS}(\V X, \V y, \V S)=\\
f_{posi, gpis}(\V X)(f_{posi, gpis}(\V X)^Tf_{posi, gpis}(\V X) + \sigma_n^2\V I)^{-1}\V y_{gpis}.
\end{multline}
By introducing derivation into kernels, the matrix size is enlarged 15-times, 
while the encoded feature is still of low dimension $l$:
$F_{\V X, \V y, \V S}=f_{enc, GPIS}(\V X, \V y, \V S)\in \mathbb R^l$.

For inferenceing with the points $\V x_*$, predictions are consistant to \cref{eq:decode}, $y_*=f_{posi}(\V x_*)^T F_{\V X, \V y, \V S}$.

% it extend regression data: $\{\V x_n , )\}^N_{n=1}$ with $\V d_1=(s_{n,1},0,0)$, $\V d_1=(0, s_{n,2}, 0)$, $\V d_3=(0,0,s_{n,3}$ and field values $\{0, \}$

\subsubsection{Using Sample based GPIS}
\label{sec:GPIS:sample}
%Sample based GPIS is more simple.

Sample-based GPIS are mostly used in GPIS researches.
This is because such method does not compute Jacobians and the kernel size can be small.% (e.g. 2 on positive and negative directions each). 
This highly-reduces the processing cost both on time and memory.
%
Given points $\{\V x_n\}^N_{n=1}$ with normals $\{\V s_n\}^N_{n=1}$ and field value $\{\V y_n=0\}^N_{n=1}$,
sample-based GPIS extends the dataset by sample points along the normal direction.
Corresponding field values are the signed distance as the sampled points walk along the normal.
Afterwards, with the extended points and distances $\V X_{ext}$, $\V y_{ext}$, \cref{eq:encode} is applied.
The inference of such model is the same as derivative-based GPIS \cref{sec:GPIS:deri}.

\bigskip

For each frame, points are distributed to its corresponding voxel.
Then we encode the local geometry in voxel using \cref{sec:GPIS:deri} or \cref{sec:GPIS:sample} to obtain $\V v=(\V c, \V F, w)$ with $F\in\mathbb R ^ l$ the geometric latent vector.
Then local LIMs are fused to a global LIM following \cref{sec:fuse}.

To achieve a surface result for visualization, we %follow DI-Fusion to
construct the Signed Distance Field from global LIM by inferring on sample points.
The sample points are from a grid in each voxel with a certain resolution.
By applying the MarchingCube algorithm on SDF, a surface mesh is obtained.


\subsection{Surface Property Fields}
\label{sec:context_fields}

The previous surface mapping (\cref{sec:surface_mapping}) can be considered as a special case of this Surface Property Mapping.
But the two mappings actually do not handling in the same space. 
More precisely for implementation, we do not derive the SurfaceMap class from PropertyMap. 
Instead, as shown in \cref{fig:inherit}, we further introduce a BaseMap to perform the common operations and let them operate specificly on local map construction and visualization, e.g., meshing and coloring.

%Because its surface properties for given point cloud are zero 

%Additionally, it provides a Signed Distance Field as an intermediate for mesh construction. 

We introduce the more general mapping of surface properties.
Since the points are all on zero-level in signed distance fields, the PropertyMap naturally handles in a subspace of $\mathbb R^3$, the surface $\mathcal{S}$.
A surface property in this paper could be any properties for each point, such as color, infrared, and etc.
%
They only differ on $\V y$ in~\cref{fig:encoder} with dimension $c$.

We set the most widely used data color as an example.
Given an observed colored point cloud $\{(\V x_n, \V c_n)|n=0\cdots N\}$ as input, where $\V c_n$ denote the RGB.
Its surface field properties values are $\{\V y_n=c_n\}^N_{n=1}$.
We aggregate the values in two $N\times 3$ matrices $\V X$ and $\V C$.
%
So encoded feature for this point cloud is 
\begin{equation}
\V F_{color}=f_{posi}(\V X)(f_{posi}(\V X)^Tf_{posi}(\V X) +\delta^2_n\V I)^{-1}\V C,
\end{equation}
where $\V F_{color}\in \mathbb R^{l\times 3}$.

Since we use $l=20$ in the approximation function for experiments, the color feature are small.
The color map only stores $20\times3$ float in each voxel for a continuous color field.
%
Note that, our model does not need any training.
It can be directly applied to different types of data.
%
For the inference, because the field is on the surface space, we sample points $\V x_*$ in arbitrary resolution, from the given know mesh or surface construction of a previous surface mapping (\cref{sec:surface_mapping}).
Following~\cref{eq:decode}, the inference points $\V x_*$ are positional-encoded and directly multiplied with color feature $\V F_{color,m}$ in the corresponding voxel $m$ to obtain its value $\V c_{*}=f_{dec}(\V x_{*}, \V F_{color,m})$.

\subsection{Surface Feature Fields}
\label{sec:latent_fields}

Surface Feature Fields are considered as an extensive use of previous Surface Property Fields (\cref{sec:context_fields}).
%
Here we extend the surface properties scope to include features. 
This extension further demonstrates the capability of our mapping model as it is directly used without any training.

Given an embedding function $\phi:\mathbb R^{N\times 3}\rightarrow \mathbb R^{N\times c}$ to process the data $\V X$, we approach the feature of each point as surface properties
$\{\V y_n=\phi (\V X)_{\V x_n}\in \mathbb R^{l\times c}\}^N_{n=1}$.

Following the encoding and fusion as \cref{sec:context_fields} and \cref{sec:fuse}, we construct latent implicit maps for the surface feature fields.
Thus, arbitrary resolutional maps of feature are extracted with $f_{dec}(\cdot, \V F_\cdot)$.

We provide one application in~\cref{sec:openvoc}: Open Vocabulary Scene Understanding. Our model constructs a CLIP space feature field on the surface.
And is therefore able to answer a text input.
The differences compared to Surface Property Fields are demonstrated in~\cref{fig:latent_diff}.
In (c), a CLIP text encoder $f_{text}$ is appended to encode the text command $\pmb u$ to the CLIP feature $\pmb U$.
Considering the left branch produces a surface field for CLIP embeddings, our model is capable to find the wanted region by computing the similarity between features.
\begin{figure}[htbp]
	\centering
	\psfragfig[width=1\linewidth]{im/eps/latent}{
		\psfrag{t}{$f_{text}$}
		\psfrag{xm}{$\V X_m$}
		\psfrag{ym}{$\V y_m$}
		\psfrag{fe}{$f_{enc}$}
		\psfrag{fm}{$f_{im}$}
		\psfrag{Fm}{$\V F_m$}
		\psfrag{x}{$\V x_{*}$}
		\psfrag{y}{$\V y_{*}$}
		\psfrag{fd}{$f_{dec}$}
		\psfrag{u}{$\pmb u$}
		\psfrag{U}{$\pmb U$}
		\psfrag{s}{$score$}
	}
	%\includegraphics[width=1\linewidth]{im/latent}
	\caption{Encoding-decoding diagram in different applications. (a) fold applications directly obtain point properties ($\V y_\text{m}$) from sensor. (b) fold applications achieves point properties with (style, saliency and etc.) function $\phi_{im}$. (c) fold applications use feature as $\V y_\text{m}$ to build a LIM for a (CLIP) feature field. Then a text command is used for extracting the semantic information.}
	\label{fig:latent_diff}
\end{figure}

\subsection{Map Fusion}
\label{sec:fuse}

We follow Neural Implicit Maps~\cite{huang2021di} to update the LIM in a voxel-to-voxel manner:
\begin{equation}
\label{eq:fuse}
\V F_m \leftarrow \frac{\V F_m w_m+\V F^{'}_m w^{'}_m}{w_m+w^{'}_m}, w_m\leftarrow w_m+w^{'}_m,
\end{equation}
where $\V v_m=(\V c_m, \V F_m, w_m)$ and $\V v^{'}_m=(\V c^{'}_m, \V F^{'}_m, w^{'}_m)$ are the voxel $m$ from global and local LIMs respectively.
