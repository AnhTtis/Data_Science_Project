\subsection{Application: Incremental Reconstruction}
\label{sec:incremental_reconstruction}

%\begin{figure}[t]%[htbp]
%	\centering
%	\includegraphics[width=1.\linewidth]{im/reconstruction}
%	\caption{Reconstruction application pipeline. External tracking runs in parallel to reconstruction to provide coarse poses. While reconstructing, internal tracking refines the pose estimation to have better surface fit. ``$\cdots$'' means that we can add more other properties from \cref{sec:recons:other} and \cref{sec:fabircated_prop} into this pipeline.}
%	\label{fig:recons}
%\end{figure}
\begin{figure*}[t]
	\centering
	\includegraphics[width=1.\linewidth]{im/application_pipeline}
	\caption{Reconstruction and scene understanding applications pipeline. On the left incremental reconstruction application, external tracking runs in parallel to reconstruction to provide coarse poses. While reconstructing, internal tracking refines the pose estimation to have better surface fit. ``$\cdots$'' means that we can add more other properties from \cref{sec:recons:other} and \cref{sec:fabircated_prop} into this pipeline. On the right scene understanding application, we assume the pose of the frame is pre-known. The upper part of the white line is the fusing of LIM for the feature field. The lower part infers specific semantic information by input text command.}
	\label{fig:recons_and_scene_understanding}
\end{figure*}
\label{sec:app_recons}

In this section, we build an incremental 3D reconstruction application with RGBD sequences.
Since RGBD sequences provide point positions and color values, the application constructs two kinds of LIMs: one for surface (~\cref{sec:surface_mapping}), and one for color (~\cref{sec:context_fields}).

The pipeline is shown in \cref{fig:recons_and_scene_understanding}.
When a RGBD frame $i$ is fed into the framework, it is firstly converted to a colored point cloud ($\V X\in\mathbb R^{N\times 3}, \V Q\in\mathbb R^{N\times 3}$).
Then, tracking module takes $(\V X, \V Q)$ to compute the current pose $\V T$.
%
Afterwards we feed transformed point cloud $\V X \V T^T$ into surface mapping (\cref{sec:surface_mapping}), colored point cloud $(\V X \V T^T, \V Q)$ into surface color mapping (\cref{sec:context_fields}) to obtain the local LIMs.
%
With \cref{eq:fuse}, we fuse local LIM to global LIM voxel-to-voxel.

For visualization, we first sample the grid in each voxel and inference with the global surface LIM to achieve the SDF.
The MarchingCube algorithm is applied to extract the mesh.

With the surface reconstructed, we are able to sample points in an arbitrary resolution from it and inference with global color LIM to reconstruct the surface color.

\subsubsection{Tracking}
\label{sec:tracking}

From~\cite{zhu2022nice}, we find that the current implicit scene representation based tracking models, i.e., iMAP, DI-Fusion and NICE-SLAM, still have a performance gap to state-of-the-art tracking approaches like BAD-SLAM and ORB-SLAM2.
%
Thus, instead of following the neural implicit models to track with frame-to-model or ray-tracing based optimization, we run ORB-SLAM2 in the other thread to provide the pose prior.

To note that, the SLAM model is designed for localization which cares less on reconstruction.
This means directly utilizing ORB-SLAM2 provides coarse surface construction.
We further use 
%Because our model actually works with colored point cloud, which is not limited to RGB-D frame,
colored point cloud registration (CPCR)~\cite{park2017colored} as the tracking refiner for better surface and color fitness.
This is tested much more robust than more recent tracking algorithms in fusion models.
%
ORB-SLAM2 runs independently over all frames.
Every few frames, CPCR track one initially posed colored point cloud to compute the odometry in local window.
Mapping is applied afterwards.

%More detail please find our experiments.

\subsubsection{Other types of datas}
\label{sec:recons:other}

Application 4) uses a point cloud with infrared, which is simply replacing the color with infrared.
LIM feature dimension is also correspondingly reduced.
%
For all other kind of point cloud properties, this application is easily adapted.
