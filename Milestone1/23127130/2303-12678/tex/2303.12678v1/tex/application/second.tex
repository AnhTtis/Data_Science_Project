\subsection{Application: 2D-to-3D Transfer}
\label{sec:fabircated_prop}

Applications like 2) and 4) work easily alongside application 1): incremental reconstruction (\cref{sec:incremental_reconstruction}) by feeding the fabricated result together with the point cloud.
%
For example, given RGB-D frames, we detect saliency or transfer image styles for a fabricated $X$ image. Here $X$ denotes saliency, style, and etc. 
Then by unprojecting it together with depth, the fabricated value is assigned to points for points pairs ($\V X$, $\V C_{X}$).

Similar to \cref{fig:recons_and_scene_understanding} the reconstruction pipeline, with encoding (\cref{sec:encoder}) and fusion (\cref{eq:fuse}), a global LIM for the fabricated properties $X$ is constructed.
Which is also a surface $X$ fields for later inference.
%
It is also possible to similarly transfer a 2D semantic image to 3D.
But it is not affordable as different types of semantic information may requires a remapping on the same data.
Therefore in the following, we demonstrate construction of a surface feature field for the scene understanding application that uses one pass of mapping to meet various needs.
