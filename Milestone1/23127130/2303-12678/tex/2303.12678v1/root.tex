\documentclass[lettersize,journal]{IEEEtran}

\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{pstool}
%\usepackage{subcaption}
%\usepackage{caption}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}

\usepackage[dvipsnames]{xcolor}

\usepackage{booktabs}
\usepackage{makecell}
\usepackage{multirow}

\usepackage{colortbl}
\usepackage{adjustbox}
\newcommand*\rot{\rotatebox{50}}

\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
\usepackage[capitalize]{cleveref}
\usepackage{siunitx}


\newcommand*{\M}{\mathbf}
\newcommand*{\V}{\mathbf}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


\definecolor{mybronze}{RGB}{194, 151, 44} % #C2972C


\begin{document}

\title{Uni-Fusion: Universal Continuous Mapping}% for Surface, Surface Context and More}

\author{Yijun Yuan and Andreas N\"uchter
\thanks{The authors are with Informatics XVII -- Robotics at Julius-Maximilians-University of W\"urzburg, Germany.
  {\tt\small \{yijun.yuan|andreas. nuechter\}@uni-wuerzburg.de}~ 
%The implementation is available at {\tt\small\protect\url{https://jarrome.github.io/}} and further online content at
%{\tt\small\protect\url{https://robotik.informatik.uni-wuerzburg.de/telematics/download/UniFusion/}}
}
} 


\maketitle

\begin{abstract}
We introduce Uni-Fusion, an universal continuous mapping framework for surfaces, surface properties (color, infrared, etc.) and more (latent features in CLIP embedding space, etc.).
We propose the first Universal Implicit Encoding model that supports encoding of both geometry and various types of properties (RGB, infrared, feature and etc.) without the need for any training.
Based on that, our framework divides the point cloud into regular grid voxels and produces a latent feature in each voxel to form a Latent Implicit Map (LIM) for geometries and arbitrary properties.
Then, by fusing a Local LIM of new frame to Global LIM, an incremental reconstruction is approached.
Encoded with corresponding types of data, our Latent Implicit Map is capable to generate continuous surfaces, surface properties fields, surface feature fields and any other possible options. 
To demonstrate the capabilities of our model, we implement three applications:
(1) incremental reconstruction for surfaces and color 
(2) 2D-to-3D fabricated properties transfers
(3) open-vocabulary scene understanding by producing a text CLIP feature field on surfaces. 
We evaluate Uni-Fusion by comparing in corresponding applications, from which, Uni-Fusion shows high flexibility to various of application while performing best or competitive.
The project page of Uni-Fusion is available at {\tt\small\protect\url{https://jarrome.github.io/Uni-Fusion/}} 

%In experiment of (1), we choose the most wide available data, color (RGB) as surface property and compare the performance on predict surface and color.
%For (3), we compare with SOTA scene understanding frameworks.
%
%In the end, we also demonstrate several novel application that can be easily obtrained from our model. Examples for more surface properties (Infrared, Density, Normal) to better reveal the wide usage of our model.

%Out framework is universal to different types of data

%To approach the goal, we propose to approximate eigenfunctions with neural network model. By embedding it under the framework of Gaussian Process Regression we generate the neural implicit features.

%Our proposed method is universal to apply in various types of reconstructions because (1) it is unsupervised learning model, (2) it is generalized for 3D and surface space.

%We implement experiments on incremental reconstructions of different types to approve the contribution of this work.
\end{abstract}

\begin{IEEEkeywords}
Mapping, RGB-D perception, Semantic scene understanding, Universal mapping
\end{IEEEkeywords}

% Introduction (2 pages)
\input{tex/introduction.tex}

% Relatex (2 pages)
\input{tex/relatedwork.tex}

% Method (2+2 pages)
\input{tex/method.tex}

% Experiments (5 pages)
\input{tex/exp.tex}



%\section{Future Works}
%Our future work would be on two fold: (1) post-optimization should be included for refinement of result. (2) We would like extend our OpenVoc application in the use of Autonomous Driving.

\section{Limitations and Future Works}

\subsubsection{Remapping}

Right now, Uni-Fusion does not support deintegrating local LIM from global LIM that is essential to include bundle adjustment (BA) or loop closing.
More importantly, the local LIM does not support transformation of LIMs as NIM-REM~\cite{yuan2022algorithm} does it at the current stage.
To foster a better qualities and higher computational performances and to support large scale mapping, loop closing and bundle adjustment are future targets.

\subsubsection{Visual Language Navigation}

Uni-Fusion provides a good reconstruction and scene understanding basis for Visual-Language Robot Navigation (VLN).
Related works produces a 2D embedding map~\cite{huang2023visual} while Uni-Fusion is capable to construct a 3D embedding map with the scene.
Thus Uni-Fusion can help the robot to have a richer understanding of the scene. In future work, we will investigate applications like navigation.

%From NICE-SLAM, we find Bundle Adjustment can highly enhance the precision and robustness of camera tracking.
%However, Uni-Fusion does not support pose changes at current stage. 
%The missing of BA and Loop-closing further constraint the usage in long range scenes.
%
%Therefore, it would further improve this work if above problem could be addressed.

\section{Conclusion}

In this work, we propose a novel universal model for all continuous mapping applications, namely Uni-Fusion.
%
Without any training, Uni-Fusion constructs Latent Implicit Maps that support geometry and arbitrary properties. 
Moving one step further to scene understanding, Uni-Fusion is also the first model that is capable to construct continuous maps with high dimensional embeddings.
%
With such a basis, we have implemented a high-quality incremental Surface\&Color reconstruction application, a 2D-to-3D fabricated properties transfer application and an open-vocabulary scene understanding application.

\section*{Acknowledgements}

This work was in parts supported by the Federal Ministry for Economic Affairs and Climate Action (BMWK) on the basis of a decision by the German Bundestag und the grant number KK5150104GM1. We also acknowledge the support by the Elite Network Bavaria (ENB) through the ``Satellite Technology'' academic program..

{\small
	\bibliographystyle{IEEEtran}
	\bibliography{ref}
}

\end{document}


