\section{Introduction} % page 1,2
% why 3D
In robotics, 3D perception plays an important role in enabling robots to interact with their surroundings.
To achieve this, robots must use different types of sensors and employ techniques such as reconstruction and scene understanding. 
These tasks require the processing of various types of information, including geometry and surface properties.
However, algorithms must be designed specifically to handle these different types of data.

Therefore, at the outset, we pose the \textbf{following question}: \textit{Is it feasible to handle all these information with a single, universal mapping model?}
%So in this beginning, we post \textbf{one question}: 
%\textit{Is it possible to address all those information with one universal mapping model?}

% why 3D reconstruction
Reconstruction, as one of the most prominent topics in the field, has been developing for decades. 
During this period, numerous works have pushed the limits~\cite{o2012gaussian,kim2013continuous,ghaffari2018gaussian,yuan2018fast,martens2016geometric,lee2019online,wu2021faithful,ivan2022online,curless1996volumetric,izadi2011kinectfusion,dai2017bundlefusion,huang2021di,yuan2022algorithm,sucar2021imap,zhu2022nice}. 
% recent surface reconstruction model
Reconstruction models aim to extract the zero-level surface given a set of points.
These approaches are typically based on occupancy grids and signed distance functions (SDFs).
Occupancy grids are primarily used in 2D and object-level shape reconstruction, where Gaussian Process Occupancy Maps (GPOM), Gaussian Process Implicit Surface (GPIS), and Hilbert Maps have been developed to generate continuous probabilistic occupancy maps.
\begin{figure}[t]
	\centering
	\includegraphics[width=1\linewidth]{im/cover_2}
	\caption{One Universal Continuous Mapping for all reconstructions. Such as surface, properties including RGB, saliency, style and $...$, even high dimensional features (CLIP embeddings, and etc). A rendered video is available on youtube\protect\footnotemark.}
	\label{fig:cover}
	\vspace{-.3cm}
\end{figure}
\footnotetext{\url{https://www.youtube.com/watch?v=4Z-u7yU2ARU}}
For scene-level reconstruction, most recent works rely on SDFs.
TSDF-Fusion~\cite{curless1996volumetric}, as the most widely used reconstruction model, has facilitated real-time 3D reconstruction.
With the rapid development of RGB-D sensors, such as the Kinect and RealSense series, standard models have been invented~\cite{izadi2011kinectfusion,dai2017bundlefusion}.
These models utilize discretized SDFs and the Marching Cubes algorithm~\cite{lorensen1987marching} to generate surface meshes. 

% Neural Implicit Maps
To address the high memory consumption associated with such a representation, recent techniques rely on deep neural networks to encode the geometry~\cite{huang2021di,yuan2022algorithm,li2022bnv,zhu2022nice}.
By using sparse voxels in the whole scene, high-dimensional vectors are extracted for each local geometry.
With this representation, researchers have proposed to fuse the map of latent vectors instead of the explicit field.
The explicit field is then extracted with arbitrary resolution.
Thus, such a form of representation produces a continuous mapping.
These methods are called Neural Implicit Maps (NIMs).

% for recent NIM techniques
%FIXED: What does it refer to?
Previous studies have demonstrated it with encoding functions
pre-trained on object datasets~\cite{huang2021di,yuan2022algorithm,li2022bnv}.
Pre-training on color or other point properties becomes impractical due to the much higher complexity of the context pattern, compared to shape.
Currently, the only recent solutions for continuous color reconstruction are based on back-propagation to update local latent features~\cite{zhu2022nice} or Neural Radiance Fields (NeRF)~\cite{rosinol2022nerf}.
However, these methods require a significant number of training epochs and are not suitable for real-time applications.
Therefore, this paper aims to fill the gap by introducing a universal model that directly encodes arbitrary properties without the need for time-consuming learning or training.

Our model uses Gaussian Process Regression (GPR) as its basis.
%Firstly, we propose to decouple the GPR by approximate the kernel function to  
Firstly, we propose to decouple the GPR by utilizing the approximation of the kernel function.
Which supports the encoding of the point cluster into a single feature vector.
Then, by leveraging the
sparse voxel structure, we construct a local feature vector within each voxel to form a map of latents.
Since our encoding-decoding function uses GPR, the entire model does not pre-touch any format of data properties.
Therefore, our Uni-Fusion is applicable to arbitrary reconstruction applications.

We believe that there dose not exist such a model that can handle every aspect of robot perception.
Therefore, based on this encoder, we introduce Uni-Fusion, a universal model for all types of data that generates continuous maps.
A selected set of examples of ``what Uni-Fusion can do'' is presented in~\cref{fig:cover}.
With various input data, our Uni-Fusion model efficiently encodes and generates continuous maps for surfaces, colors, styles, and more.
To further explore the potential of this model, we even construct a field for high-dimensional CLIP embedding~\cite{ghiasi2022scaling}.

% Contribution
The contributions of this work are as follows:
\begin{itemize}
\item
  we propose a universal encoding-decoding model for local information that does not require any training,
\item
  we present the first universal continuous mapping model, capable of constructing continuous surfaces and various surface property fields, including high-dimensional features such as CLIP embeddings.
\item
  we implement applications to demonstrate the capabilities of our proposed model, including: (1) incremental surface \& color reconstruction, (2) 2D-to-3D transfer on a 3D canvas, (3) open-vocabulary scene understanding.
\end{itemize}
\noindent \textit{Content Overview:} %\paragraph*{Content Overview}
In \cref{sec:related_works}, we provide an overview of related works. 
Then, in~\cref{sec:UE} and~\cref{sec:UCM}, we present the Universal Encoder and the Uni-Fusion model, a universal continuous mapping framework built upon that encoder.
%
Afterwards, in~\cref{sec:apps}, we showcase the broad applicability of Uni-Fusion by presenting a number of applications in different scenarios.
% demonstrate the wide  of Uni-Fusion in various scenarios.
The capabilities of Uni-Fusion are evaluated in~\cref{sec:exp}.
%We evaluate the capabilities of Uni-Fusion in~\cref{sec:exp}.
%
Finally, we outline the future directions and conclude this paper.
