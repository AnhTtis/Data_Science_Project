\subsection{Application: 2D-to-3D Transfer}
\label{sec:fabircated_prop}

Applications such as 2) and 4) can be easily integrated with application 1) incremental reconstruction (\cref{sec:incremental_reconstruction}) by incorporating the fabricated result together with the point cloud.
%
For instance, given RGB-D frames, we detect saliency or transfer image styles to generate a fabricated $X$ image. Here, $X$ represents saliency, style, or other properties. 
By combining $X$ with depth information through unprojection,
we assign
the fabricated values to corresponding points, resulting in point pairs ($\V X$, $\V Q_{X}$).

Similar to the reconstruction pipeline in~\cref{fig:recons_and_scene_understanding}, we employ encoding (\cref{sec:encoder}) and fusion (\cref{eq:fuse}) to construct a global LIM for the fabricated properties $X$.
This global LIM represents a surface $X$ fields that is utilized for subsequent inference.

While it is possible to similarly transfer a 2D semantic image to 3D,
it may not be feasible in practice due to the need for multiple passes of different categories of semantic information 
 on the same dataset (such as object, usability, etc.).
Therefore, in the following section, we demonstrate the construction of a surface feature field for scene understanding application that satisfies various 
requirements through a single mapping pass.
