\documentclass[lettersize,journal]{IEEEtran}

\usepackage{amsmath,amsfonts}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{pstool}
%\usepackage{subcaption}
%\usepackage{caption}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}

\usepackage[dvipsnames]{xcolor}

\usepackage{booktabs}
\usepackage{makecell}
\usepackage{multirow}

\usepackage{colortbl}
\usepackage{adjustbox}
\newcommand*\rot{\rotatebox{50}}

\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
\usepackage[capitalize]{cleveref}
\usepackage{siunitx}


\newcommand*{\M}{\mathbf}
\newcommand*{\V}{\mathbf}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


\definecolor{mybronze}{RGB}{194, 151, 44} % #C2972C


\begin{document}

\title{Uni-Fusion: Universal Continuous Mapping}% for Surface, Surface Context and More}

\author{Yijun Yuan and Andreas N\"uchter
\thanks{The authors are with Informatics XVII -- Robotics at Julius-Maximilians-University of W\"urzburg, Germany.
  {\tt\small \{yijun.yuan|andreas. nuechter\}@uni-wuerzburg.de}~ 
%The implementation is available at {\tt\small\protect\url{https://jarrome.github.io/}} and further online content at
%{\tt\small\protect\url{https://robotik.informatik.uni-wuerzburg.de/telematics/download/UniFusion/}}

This work was in parts supported by the Federal Ministry for Economic Affairs and Climate Action (BMWK) on the basis of a decision by the German Bundestag und the grant number KK5150104GM1. We also acknowledge the support by the Elite Network Bavaria (ENB) through the ``Satellite Technology'' academic program.
}
} 

\maketitle

\begin{abstract}
We present Uni-Fusion, a universal continuous mapping framework for surfaces, surface properties (color, infrared, etc.) and more (latent features in CLIP embedding space, etc.).
We propose the first universal implicit encoding model that supports encoding of both geometry and different types of properties (RGB, infrared, features, etc.) without requiring any training.
Based on this, our framework divides the point cloud into regular grid voxels and generates a latent feature in each voxel to form a Latent Implicit Map (LIM) for geometries and arbitrary properties.
Then, by fusing a local LIM frame-wisely into a global LIM, an incremental reconstruction is achieved.
Encoded with corresponding types of data, our Latent Implicit Map is capable of generating continuous surfaces, surface property fields, surface feature fields, and all other possible options. 
To demonstrate the capabilities of our model, we implement three applications:
(1) incremental reconstruction for surfaces and color 
(2) 2D-to-3D transfer of fabricated properties
(3) open-vocabulary scene understanding by creating a text CLIP feature field on surfaces. 
We evaluate Uni-Fusion by comparing it in corresponding applications, from which Uni-Fusion shows high-flexibility in various applications while performing best or being competitive.
The project page of Uni-Fusion is available at {\tt\small\protect\url{https://jarrome.github.io/Uni-Fusion/}}. 
\end{abstract}

\begin{IEEEkeywords}
Mapping, RGB-D perception, Semantic scene understanding, Universal mapping
\end{IEEEkeywords}


\input{tex/introduction.tex}
\input{tex/relatedwork.tex}
\input{tex/method.tex}
\input{tex/exp.tex}

\section{Limitations and Future Work}

\subsubsection{Remapping}

Uni-Fusion currently lacks support for deintegrating local LIM from global LIM, which is essential for incorporating bundle adjustment or loop closing techniques. 
In addition, the current state of Uni-Fusion does not allow the transformation of LIMs as demonstrated by NIM-REM~\cite{yuan2022algorithm}. 
To enhance a better quality and to facilitate large scale mapping, loop closing and bundle adjustment are future targets.

\subsubsection{Visual Language Navigation}

Uni-Fusion serves as a solid foundation for reconstruction and scene understanding in the context of Visual-Language Robot Navigation (VLN).
While existing work produces a 2D embedding map~\cite{huang2023visual}, Uni-Fusion excels in constructing a 3D embedding map of the scene.
As a result, Uni-Fusion empowers the robot with a deeper understanding of the scene. In our future work, we intend to explore applications such as navigation.

\section{Conclusion}

In this paper, we have introduced Uni-Fusion, a novel universal model for all continuous mapping applications.
%
Without any training, Uni-Fusion constructs Latent Implicit Maps that support geometry and arbitrary properties. 
Moving one step further to scene understanding, Uni-Fusion is also the first model that is capable of constructing continuous maps with high-dimensional embeddings without the training of map representation.
%
With such a basis, we have implemented several applications, including a high-quality incremental surface and color reconstruction application, a 2D-to-3D transfer of fabricated properties, and an open-vocabulary scene understanding application.

{\small
	\bibliographystyle{IEEEtran}
	\bibliography{ref}
}
\end{document}


