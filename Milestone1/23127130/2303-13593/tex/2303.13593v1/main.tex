\pdfoutput=1
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[legalpaper, margin=1.3in]{geometry}

\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tabularx} 
\usepackage{mathtools} 
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{authblk}
\usepackage{tikz-cd}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage[sort]{cite}
\usepackage{microtype}
\usepackage{appendix}
\usepackage{babel}

\newcommand{\FR}[1]{{\color{olive}{\textbf{FR:} #1 }}}
\newcommand{\AT}[1]{{\color{purple}{\textbf{AT:} #1 }}}
\newcommand{\elima}[1]{{\color{red}{\textbf{ES:} #1 }}}
\newcommand{\PP}{{\mathbb{P}}}
\newcommand{\CC}{{\mathbb{C}}}
\newcommand{\RR}{{\mathbb{R}}}
\newcommand{\ZZ}{{\mathbb{Z}}}
\newcommand{\Gr}{{\rm Gr}}

\usepackage{chngcntr}
\usepackage{apptools}
\AtAppendix{\counterwithin{theorem}{section}}

\usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false]{hyperref}
\usepackage{cleveref}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}

\newtheorem{innercustomgeneric}{\customgenericname}
\providecommand{\customgenericname}{}
\newcommand{\newcustomtheorem}[2]{
  \newenvironment{#1}[1]
  {
   \renewcommand\customgenericname{#2}
   \renewcommand\theinnercustomgeneric{##1}
   \innercustomgeneric
  }
  {\endinnercustomgeneric}
}

\newcustomtheorem{customtheorem}{Theorem}
\newcustomtheorem{customproposition}{Proposition}
\newcustomtheorem{customlemma}{Lemma}
\newcustomtheorem{customcorollary}{Corollary}


\begin{document}
\title{Theoretical and Numerical Analysis of 3D Reconstruction Using Point and Line Incidences}
\author[1]{Felix Rydell}
\author[2]{Elima Shehu}
\author[3]{Angélica Torres}
\affil[1]{{\small KTH Royal Institute of Technology, Stockholm, Sweden}}
\affil[2]{{\small University of Osnabr\"uck, Osnabr\"uck, Germany}}
\affil[2]{{\small Max Planck Institute for Mathematics in the Sciences, Leipzig, Germany}}
\affil[3]{{\small Centre de Recerca Matemàtica, Barcelona, Spain}}

\maketitle

\begin{abstract}
 

  We study the joint image of lines incident to points, meaning the set of image tuples obtained from fixed cameras observing a varying 3D point-line incidence. We prove a formula for the number of complex critical points of the triangulation problem that aims to compute a 3D point-line incidence from noisy images. Our formula works for an arbitrary number of images and measures the intrinsic difficulty of this triangulation. Additionally, we conduct numerical experiments using homotopy continuation methods, comparing different approaches of triangulation of such incidences. In our setup, exploiting the incidence relations gives both a faster point reconstruction and in three views more accurate. 
 
\end{abstract}

\section*{Introduction}

The structure-from-motion pipeline takes a set of images and aims to estimate both the camera positions and the relative position of the objects in said images. The process starts by identifying sets of point and line features in one image that are recognizable as the same points or lines in another. These matching features, that we call \textit{correspondences}, are used to estimate the camera position and orientation, which then allow for the triangulation step.

The triangulation of points is well understood and, in practice, it is efficiently implemented. However, point features are more prone to errors and light changes. The inclusion of line features in the reconstruction process may give a more accurate estimation of scenes as they are more robust to noise than points, and their frequent appearance in interior scenes and man-made scenarios makes their study necessary. Additionally, in some real data sets standard feature detection algorithms fail due to a lack of point correspondences but succeed when line correspondences are taken into account \cite{fabbri2020trplp}.

In this work, we study the triangulation of points and lines satisfying a certain incidence relation for an arbitrary number of pinhole cameras assuming complete visibility. We restrict our focus to (L1): a single line incident with multiple points, see \Cref{fig:L1_and_P1}, and we use methods from applied algebraic geometry to study different approaches for its reconstruction. Our results provide a theoretical foundation for the reconstruction of incident points and lines and  give an understanding of the complexity of the triangulation of points and lines preserving these incidences.  

\begin{figure}
    \centering
    \includegraphics[width = 0.50\textwidth]{inc.png}
    \caption{An illustration of two different types of incidence relations: (L1)~represents the scenario where multiple points are incident to a line, while (P1) represents the scenario where multiple lines are incident to a point.}
    \label{fig:L1_and_P1}
\end{figure}



Our approach relies on the use of \textit{(algebraic) varieties}, by which we mean the vanishing set of a system of polynomial equations. Varieties have been used extensively to study triangulation of point correspondences \cite{agarwal2019ideals, EDDegree_point, faugeras1995geometry}, line correspondences \cite{faugeras1993three,breiding2022line, Kileel_Thesis} and minimal problems \cite{duff2019plmp,Duff20_partialvis} to name a few. In particular, these studies introduced the point and line multiview varieties which we now recall. 

A \textit{pinhole camera}, is modeled by a (complex) projective linear map $C: \mathbb{P}^3 \dashrightarrow \mathbb{P}^2$ defined by a full rank $3\times 4$ matrix~$C$. A camera arrangement with $m\geq 2$ cameras is denoted by $\mathcal{C}=(C_1,\ldots ,C_m)$, and the \textit{joint camera map}

\begin{align}
\begin{split}
\Phi_\mathcal{C}:\mathbb{P}^3&\dashrightarrow (\mathbb{P}^2)^m,\\
    X&\mapsto (C_1X,\ldots,C_mX),
    \end{split}
\end{align}

models the process of taking the images of a point $X$ in homogeneous coordinates with $m$ cameras. For fixed cameras, the \textit{(point) multiview variety} $\mathcal{M}_\mathcal{C}$ is the smallest variety that contains all point correspondences. An extensive account of the pinhole cameras is given by \cite{Hartley2004}, and a survey of the multiview variety is found in \cite{trager2015joint}. The joint camera map can be extended from the space of points $\PP^3$ to the space of lines, denoted by $\Gr(1,\PP^3)$, where each line is parameterized as the span of two points. The map

\begin{align}
  \begin{split}
\Upsilon_{\mathcal{C}}:\mathrm{Gr}(1,\PP^3)&\dashrightarrow (\PP^2)^m\\
  \quad L&\mapsto (C_1\cdot L,\ldots, C_m\cdot L).  
  \end{split}
\end{align}

models the image of a line~$L$ under the cameras of~$\mathcal C$. To be precise, if $u,v$ span the line $L\in\Gr(1,\PP^3)$, then $\ell=C\cdot L$ is defined as $Cu\times Cv\in \PP^2$, where $\times$ is the cross product. Observe that $\{x\in \PP^2:\ell^Tx=0\}$ equals $\mathrm{span}\{Cu,Cv\}$. Recently, in \cite{breiding2022line}, the authors study the \textit{line multiview variety} $\mathcal{L}_\mathcal{C}$, which is the smallest variety containing all line correspondences. 


 
The main contribution of this work is the definition and study of the \textit{anchored} point and line multiview varieties, and the numerical simulations for reconstruction we implement using them. Given a fixed line $L\in \Gr(1,\PP^3)$, the anchored point multiview variety, $\mathcal{M}_\mathcal{C}^L$, is defined as the smallest variety containing all point correspondences coming from points in $L$; and the anchored line multiview variety, $\mathcal{L}_\mathcal{C}^X$, is the smallest variety containing the line correspondences coming from lines passing through a given point $X\in\PP^3$. 


In terms of theoretical results, we mathematically prove formulas for the \textit{Euclidean distance degree} (EDD) of the anchored multiview varieties, which are a measurement of complexity for error correction using exact algebraic methods \cite{draisma2016euclidean}.  
\begin{theorem} Let $\mathcal{C}$ be a generic arrangement of $m$ cameras.  
\begin{enumerate}
    \item $\mathrm{EDD}( \mathcal{M}_\mathcal{C}^L)=3m-2 $;
    \item If $m\ge 3$, then $\mathrm{EDD}( \mathcal{L}_\mathcal{C}^X)=\frac{9}{2}m^2-\frac{19}{2}m+3.$
\end{enumerate}
\end{theorem}
We provide a precise definition of this degree in \Cref{ss:EDD}. Previous work on Euclidean distance degrees for multiview varieties include \cite{EDDegree_point,harris2018chern} and \cite[Section 5]{breiding2022line}. By \cite{EDDegree_point}, $\mathrm{EDD}(\mathcal{M}_\mathcal{C})=\frac{9}{2}m^3-\frac{21}{2}m^2+8m-4$. The fact that the EDDs of the anchored multiview varieties have smaller degree suggests that they are less complex for the purpose of denoising data. This conclusion is backed by the results of our numerical experiments using \texttt{HomotopyContinuation.jl}  \cite{HC.jl}, presented in \Cref{s:NUM}. 

A traditional way of reconstructing points is to fit point correspondences to the multiview variety $\mathcal{M}_\mathcal{C}$ by minimizing the square sum of reprojection errors. We present different approaches to reconstructing data of type (L1) using the anchored multiview varieties that preserve the incidence relations, that are also based on minimizing reprojection errors and that, therefore, are projectively invariant. In particular, for $m=2$ views, our implementation is notably faster than the traditional triangulation of points, while the accuracy is comparable. For $m=3$ views we get both higher accuracy and faster speed by using $\mathcal{L}_\mathcal{C}$, compared to usual point triangulation. All of our proposed methods outperform the traditional approaches in terms of run-time and give a comparably accurate result. In application, special software and hardware are used for triangulation, but based on our experiments, we believe that they could be implemented with good results even in practice.

\subsection*{Related work} 

\paragraph{Algebra.} Algebraic geometry, whose connection to computer vision is well established, is our main tool for the theoretical study of the triangulation of problem (L1). Fundamental theory regarding the point multiview variety is found in \cite{faugeras1995geometry, Hartley1997, Hartley2004}, in particular for two and three views. The paper \cite{trager2015joint} by Trager et. al. serves as a survey for the algebraic properties of this multiview variety. For applications, finding a good set of polynomial constraints satisfied by the point correspondences is important, this is precisely the work of \cite{agarwal2019ideals} by Agarwal et al.

Regarding the algebra of lines in a computer vision setting, Kileel presented in \cite[Definition 3.9, Theorem 3.10]{Kileel_Thesis} several types of multiview varieties with respect to a point-line incidence relation in $\PP^3$ in 3 views, and their basic properties. One of those types is called the LLL-multiview variety and constitutes a special case of the more recent work by Breiding et. al. \cite{breiding2022line}, where they study the algebraic properties of the line multiview variety. Furthermore, a recent manuscript \cite{2303.02066} studies the polynomial constraints satisfied by line correspondences.


\paragraph{Projective Reconstruction.} Different approaches to triangulation of points have been considered in the literature, in particular for two views \cite{hartley1997triangulation,kanazawa1995reliability,kanatani2005statistical,kanatani2008triangulation,beardsley1994navigation,beardsley1997sequential}. Hartley and Sturm compare many different approaches in \cite{hartley1997triangulation}, including the ``midpoint'' method. The midpoint method inputs a point correspondence in two views and outputs the midpoint of the line segment determined by the points on the two back-projected lines (rays) that are closest two the other. In other words, it finds the midpoint of the common perpendicular to the two back-projected lines. This is a natural approach, but it has several downsides, also pointed out in \cite{beardsley1994navigation,beardsley1997sequential}. Importantly, it is not \textit{projectively invariant}. A projectively invariant reconstruction has the property that acting on the cameras by a global projective transformation induces the same action on the triangulated point or line. Instead, Hartley and Sturm propose minimizing the reprojection error as the optimal triangulation method, which accepted as a standard formulation \cite{stewenius2005hard}. In \cite{stewenius2005hard}, the focus is on triangulation via minimizing reprojections errors in three views and the authors point out that three views often lead to greater stability and stronger disambiguation compared to two views.


\paragraph{Implementation of Line Reconstruction.} From the algorithmic point of view, the simultaneous re\-cons\-truction of point and line features have been studied specially with the goal of reconstructing line segments. For example, \cite{BARTOLI2005416} provides a thorough overview of the structure-from-motion pipeline using lines, going through different methods for line parameterization and error correction depending on such parameterizations. In \cite{Quan}, Quan and Takeo study the algebraic structure of line correspondences with uncalibrated affine cameras. They reduce the problem of reconstructing affine lines to the reconstruction of projective points in a lower-dimensional projective camera. In~\cite{Hartley1997}, Hartley and coauthors provide an algorithm for the reconstruction of point and line features where 3D lines are parameterized by their projections in 2 views (as the intersection of two back-projected planes).
Micusik and Wildenauer reconstruct lines to estimate line segments, but only use incident points for error correction~\cite{Micusik_Wildenauer}. Furthermore in \cite{L_2_ref}, the authors propose a technique for 3D reconstruction incorporating line segments.  
They assert that this method surpasses traditional approaches, especially in efficiency while getting accurate
results. Finally, in \cite{L_3_ref}, the authors present a framework for the computation of the relative motion between two images using a triplet of lines. 
\bigskip


This paper is structured as follows. In the first part of \Cref{s:AMV} we formally introduce \textit{anchored} multiview varieties and study properties such as dimension and multidegrees. In the second part of \Cref{s:AMV}, we study the smoothness and find the Euclidean Distance Degree of the anchored multiview varieties. Finally, in \Cref{s:NUM}, we provide a numerical analysis of the different approaches to reconstructing lines described in \Cref{s:AMV}. The proofs of all our results are included in the Appendix together with a small background on the concepts of Algebraic Geometry used for these results. The code used for the numerical experiments can be found in the GitHub repository \url{github.com/amtorresbu/Anchored_LMV.git}.


\paragraph{Acknoledgements.} The authors thank Kathlén Kohn for helpful discussions, Lukas Gustafsson for the initial insight of \Cref{thm:anchoredmulti_isomorphism}, and Viktor Larsson for pointing out relevant references at the start of this project. 
 Felix Rydell and Angélica Torres were supported by the Knut and Alice Wallenberg Foundation within their WASP (Wallenberg AI, Autonomous
Systems and Software Program) AI/Math initiative. Elima Shehu is funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation), Projektnummer 445466444. Angélica Torres is currently supported by the Spanish State Research Agency, through the Severo Ochoa and María de Maeztu Program for Centers and Units of Excellence in R\&D. 


\section{Anchored Multiview Varieties} \label{s:AMV}

A \textit{camera} refers to a full-rank $3\times 4$ matrix. A \textit{camera arrangement} is a collection $\mathcal{C}=(C_1,\ldots ,C_m)$ of $m\ge 2$ cameras whose \textit{centers} $c_1,\ldots,c_m$, i.e. kernels, are all distinct. 

We collect helpful definitions and results from algebraic geometry in \Cref{s:AlgPre}. In particular, a \textit{variety} is the solution set to a system of polynomials. The \textit{Zariski closure} of a set $U$ is the smallest possible variety containing $U$. We work in complex projective space, denoted $\PP^n$. This is defined as $(\CC^n\setminus\{0\})/\sim$, where $x\sim y$ if $x$ and $y$ differ by a non-zero constant. The set of lines in $\PP^n$ is denoted as $\Gr(1,\PP^n)$. In the language of algebraic geometry, it is called the Grasmmanian of lines in $\PP^n$. 


\begin{definition}
       Let $X\in\PP^3$ be a point distinct from all camera centers, and $L\in\Gr(1,\PP^3)$ a line containing none of the camera centers.
       \begin{enumerate}
           \item The \textnormal{anchored point multiview variety}, denoted $\mathcal{M}_\mathcal{C}^L$, is defined as the Zariski closure of the image of the map
           
           \begin{equation}
               \begin{split}
                   \Phi_\mathcal{C}|_L: L & \dashrightarrow (\PP^2)^m \\
                   X & \longmapsto (C_1X,\ldots ,C_mX).
               \end{split}
           \end{equation}
           
           \item The \textnormal{anchored line multiview variety}, denoted $\mathcal{L}_\mathcal{C}^X$, is defined as the Zariski closure of the image of the map
           
           \begin{equation}
               \begin{split}
                   \Upsilon_\mathcal{C}|_X: \Lambda(X) & \dashrightarrow (\PP^2)^m \\
                   L & \longmapsto (C_1\cdot L,\ldots ,C_m\cdot L),
               \end{split}
           \end{equation}
           
           where $\Lambda(X)$ denotes the set of lines in $\Gr(1,\PP^3)$ that contain $X$. 
       \end{enumerate}
\end{definition}
In the previous definition, the Zariski closures equal the Euclidean closures of the images by Chevalley's theorem \cite[Theorem 4.1]{michalek2021invitation}. Our definition of anchored multiview varieties is different from the anchored features in\cite{Sola2012} for monocular EKF-SLAM.


\begin{proposition}\label{prop:first_eq} $ $

        \begin{enumerate}
        \item If there are two camera centers $c_i$ and $c_j$ such that the span of $\{c_i,c_j,L\}$ is $\PP^3$, then 
        \begin{equation}
            \mathcal{M}_\mathcal{C}^L=\{(x_1,\ldots,x_m)\in \mathcal{M}_{\mathcal{C}}: x_i\in C_i\cdot L\};
        \end{equation}

        \item If for each camera center $c_i$, the line spanned by $c_i$ and $X$ contains no other center than $c_i$, then 
        \begin{equation}
            \mathcal{L}_\mathcal{C}^X=\{(\ell_1,\ldots,\ell_m)\in \mathcal{L}_{\mathcal{C}}: C_iX\in \ell_i\}.
        \end{equation}
    \end{enumerate}
\end{proposition}

We recall that all proofs are found in the Appendix.


\subsection{Properties} 


Consider an arrangement $\widetilde{\mathcal{C}}$ of full-rank $2\times 2$ matrices, and an arrangement $\widehat{\mathcal{C}}$ of full-rank $2\times 3$ matrices. We define $\mathcal{M}_{\widetilde{\mathcal{C}}}^{1,1}$, and $\mathcal{M}_{\widehat{\mathcal{C}}}^{2,1}$, respectively as the Zarizki closure of the image of the joint maps
    \begin{equation}
        \begin{split}
    \Phi_{\widetilde{\mathcal{C}}}: \PP^1&\longrightarrow (\PP^1)^m \\
            X & \longmapsto (\widetilde C_1X,\ldots,\widetilde C_mX),
        \end{split}
    \end{equation}
and 
    \begin{equation}
        \begin{split}   \Phi_{\widehat{\mathcal{C}}}:\PP^2&\dashrightarrow (\PP^1)^m\\
            X& \longmapsto (\widehat{C}_1X,\ldots \widehat{C}_mX).
        \end{split} 
    \end{equation}

These lower-dimensional multiview varieties are fundamental in our work due to the theorem below. 

\begin{theorem}\label{thm:anchoredmulti_isomorphism}  $ $ 

\begin{enumerate}
     \item Let $\phi_L:L \to \PP^1$ and $\psi_{i}:C_i\cdot L\to \PP^1$ be any choices of linear isomorphisms. Let $\widetilde{\mathcal{C}}$ denote the arrangement of matrices $\widetilde{C}_i=\psi_{\mathcal{C},i} \circ C_i\circ \phi_L^{-1} $. Then 
    \begin{align}
        \psi_{\mathcal{C},L}:=(\psi_{1},\ldots,\psi_{m}):\mathcal{M}_\mathcal{C}^L\to  \mathcal{M}_{\widetilde{\mathcal{C}}}^{1,1},
    \end{align}
    is a linear isomorphism.
    \item Let $\phi_X: \Lambda(X)\to \PP^2$ and $\psi_i: \Lambda(C_i X)\to \PP^1$ be any choices of linear isomorphisms. Let $\widehat{\mathcal{C}}$ denote the arrangement of matrices $\widehat{C}_i=\psi_{i} \circ C_i\circ \phi_X^{-1} $. Then 
    \begin{align}
        \psi_{\mathcal{C},X}:=(\psi_1,\ldots,\psi_{m}): \mathcal{L}_\mathcal{C}^X\to \mathcal{M}_{\widehat{\mathcal{C}}}^{2,1},
    \end{align}
    is a linear isomorphism.
\end{enumerate}
\end{theorem} 
By the term \textit{linear isomorphism} in the previous theorem, we refer to an invertible linear map. In \Cref{sss:Red}, we exploit these linear isomorphisms to improve the speed of triangulation. A consequence of this theorem is also that many results for the anchored multiview varieties translate into results about $\mathcal{M}_{\widetilde{\mathcal{C}}}^{1,1}$ and $\mathcal{M}_{\widehat{\mathcal{C}}}^{2,1}$. For instance, there is a direct relation between the Euclidean distance degrees as in \Cref{cor:EDD_p}.

 

\begin{proposition}\label{cor:dim} $\mathcal{M}_\mathcal{C}^L$ and $\mathcal{L}_\mathcal{C}^X$ are irreducible. Further, 

\begin{enumerate}
    \item $\mathcal{M}_\mathcal{C}^L$ is isomorphic to $\PP^1$. In particular, $\dim\mathcal{M}_\mathcal{C}^L=1$.
    \item If the centers $c_i$ and $X$ are not collinear, then $\dim \mathcal{L}_\mathcal{C}^X=2$. 
\end{enumerate}
\end{proposition}



In \Cref{prop:first_eq} we get a set of equations for the anchored multiview varieties. In the generic case, some of those equations are superfluous: Using the fundamental matrices of $C_i$ and $C_j$, denoted as $F^{ij}$, we give a smaller set of necessary and sufficient polynomial constraints that describe the correspondences of points or lines in the anchored multiview varieties. 

\begin{proposition}\label{prop:eq} For a point $X$ and line $L$, let $\mathcal{C}$ be a generic (random) camera arrangement of $m$ cameras. 
\begin{enumerate}
    \item $x\in \mathcal{M}_\mathcal{C}^L$ if and only if $x_1^TF^{1j}x_j=0$ for each $j=2,\ldots,m$ and $x_i^TC_i\cdot L=0$ for every $i=1,\ldots,m$;
    \item $\ell\in \mathcal{L}_\mathcal{C}^X$ if and only if
    \begin{align}
    \begin{split}
        \det \begin{bmatrix}
    C_1^T \ell_1 & C_2^T \ell_2 & C_i^T\ell_i 
    \end{bmatrix}=0,\\  
    \det \begin{bmatrix}
    C_1^T \ell_1 & C_3^T \ell_3 & C_i^T\ell_i 
    \end{bmatrix}=0,
    \end{split}
    \end{align}
    for each $i=3,\ldots,m$ and $\ell_i^T C_iX=0$ for every $i=1,\ldots,m$.
\end{enumerate}
\end{proposition}

The determinantal constraints described in the second item correspond to the constraints that are satisfied by elements of the line multiview variety, presented in~\cite{breiding2022line}.


We denote by~$L_{d}\subseteq \mathbb P^{h}$ a general linear subspace of codimension $d$, meaning dimension $h-d$. The \textit{multidegree} of a variety $\mathcal{X}\subseteq \PP^{h_1}\times \cdots \times\PP^{h_m}$ is the function 
\begin{align}
    D(d_{1},\dots,d_{m}):= \#( \mathcal{X}\cap (L_{d_{1}}^{(1)}\times \cdots\times L_{d_{m}}^{(m)})), 
\end{align}
for $(d_{1},\dots,d_{m})\in \mathbb N^{n}$ such that $d_{1}+\cdots +d_{m} = \operatorname{dim} \mathcal{X}$. First note that for any multiview variety, the function $D$ is symmetric under generic camera conditions. This implies that for any permutation $\sigma \in S_n$, $D(d_{1},\dots,d_{m})$ is equal to $D(d_{\sigma{(1)}},\dots,d_{\sigma{(m)}})$.

\begin{proposition}\label{prop:multideg} Let $\mathcal{C}$ be a generic arrangement of cameras.

\begin{enumerate}
    \item The multidegree of $\mathcal{M}_\mathcal{C}^L$ is given by the single number $D(1,0,\ldots,0)=1$.
    \item The multidegree of $\mathcal{L}_\mathcal{C}^X$ is given by the two numbers $D(2,0,\ldots,0)=0$ and $D(1,1,0,\ldots,0)=1$.
    \end{enumerate}
\end{proposition}

The multidegrees tell us what information we need from images to be able to triangulate. The above result shows that in  $\mathcal{M}_\mathcal{C}^L$, the data of one image point is enough to triangulate, and in $\mathcal{L}_\mathcal{C}^X$, the data of two image lines is enough to triangulate. 

\subsection{The Euclidean Distance problem} \label{ss:EDD} 

 
For a variety $\mathcal{X}\subseteq \RR^n$ and a point $u\in\RR^n$ outside the variety, a natural problem is finding the closest point of the variety to $u$, which corresponds to the optimization problem
\begin{equation}\label{eq:ED_problem}
    \mathrm{minimize}\quad \sum_{i=1}^n(u_i-x_i)^2\quad \textnormal{subject to} \quad x\in \mathcal{X}.
\end{equation}
This is called the \textit{Euclidean distance problem} and models the process of error correction and fitting noisy data to a mathematical model $\mathcal{X}$. The \textit{Euclidean distance degree} (EDD) is an estimate of how difficult it is to solve this problem by exact algebraic methods. 
In the case of a smooth variety, the EDD is the number of complex solutions to the critical equations of \eqref{eq:ED_problem} \cite{draisma2016euclidean}. For a variety in a product of projective spaces, the \textit{affine Euclidean distance degree} is the EDD of an affine patch of the variety, by which we mean a special section of the variety where the points are parameterized non-homogeneously, see the Appendix for more details. 

Before computing the EDD of the anchored multiview varieties, we study their smoothness. A variety $\mathcal{X}$ is \textit{smooth} at a point $x$ if $\mathcal{X}$ locally around $x$ looks like Euclidean space. $\mathcal X$ is \textit{smooth} if all its points is smooth. The \textit{singular locus} of a variety is the set of non-smooth points. See \cite{Gathmann} for more details. The singular locus of the point multiview variety is well-understood, see for instance \cite{trager2015joint}, and it is mostly understood for the line multiview variety, see \cite[Section 3]{breiding2022line}. 

\begin{proposition}\label{prop:smooth} $ $

\begin{enumerate}
    \item $\mathcal{M}_\mathcal{C}^L$ is always smooth; 
    \item If there are exactly two cameras, or the centers together with $X$ span $\PP^3$, then $\mathcal{L}_\mathcal{C}^X$ is smooth.
\end{enumerate}
\end{proposition}


Below we present a mathematically rigorous result on the EDDs of the anchored multiview varieties, along with the proofs that are included in the Appendix. Using the \texttt{HomotopyContinuation.jl}\cite{breiding2018homotopycontinuation} package in the \texttt{julia}\cite{bezanson2012julia} programming language, we find that our numerical computations confirm these formulas.

\begin{theorem}\label{thm:EDDthm} Let $\mathcal{C}$ be a generic arrangement of $m$ cameras.  
\begin{enumerate}
    \item $\mathrm{EDD}( \mathcal{M}_\mathcal{C}^L)=3m-2 $;
    \item If $m\ge 3$, then $\mathrm{EDD}( \mathcal{L}_\mathcal{C}^X)=\frac{9}{2}m^2-\frac{19}{2}m+3.$
\end{enumerate}
\end{theorem}

We end with an implication of \Cref{thm:anchoredmulti_isomorphism}: there is a direct correspondence between the EDDs of the anchored multiview varieties and $\mathcal{M}_{\widetilde{\mathcal{C}}}^{1, 1},\mathcal{M}_{\widehat{\mathcal{C}}}^{2, 1}$.



\begin{theorem}\label{cor:EDD_p} Let $\widetilde{\mathcal{C}}$ denote a generic arrangement of $2\times 2$ matrices and let $\widehat{\mathcal{C}}$ denote a generic arrangement of $2\times 3$ matrices. 
\begin{enumerate}
    \item $\mathrm{EDD}( \mathcal{M}_{\widetilde{\mathcal{C}}}^{1, 1})=3m-2 $;
    \item $\mathrm{EDD}( \mathcal{M}_{\widehat{\mathcal{C}}}^{2,1})=\frac{9}{2}m^2-\frac{19}{2}m+3.$
\end{enumerate}
\end{theorem}


\section{Numerical Experiments} \label{s:NUM}

In this section we conduct numerical experiments of the triangulation process of incident point and lines. The code can be found in the GitHub repository \url{github.com/amtorresbu/Anchored_LMV.git}.

To describe incidence relations, we use the notation of \cite{duff2019plmp}. A \textit{point-line problem} is a tuple $(p,l,I,m)$ specifying that $p$ points and $l$ lines are incident according to a given incidence relation $I \subseteq \{1, \ldots , p\} \times \{1, \ldots ,l\}$ (i.e. $(i, j) \in I$ means that the
$i$-th point is on the $j$-th line) and are projected onto $m$ views. Given such a point-line problem, a \textit{point-line arrangement} is an element of
\begin{equation}
\begin{split}
    \mathcal{X}_{p,l,I}=\{&(X,L)\in (\PP^3)^p\times \Gr(1,\PP^3)^l:\\ 
    &\forall (i,j)\in I,~ X_i\in L_j\}.
\end{split}
\end{equation}
We focus on (L1): $(p,1,I,m)$, where $I=\{(1,1),\ldots,(p,1)\}$. Such a point-line problem is depicted in~\Cref{fig:L1_and_P1}. We compare the following approaches to triangulation of (L1) incidences with $p$ point correspondences given a camera arrangement $\mathcal{C}$.  
\begin{enumerate}
    \item[(L1).0] Triangulate each point correspondence by fitting it to the point multiview variety $\mathcal{M}_{\mathcal{C}}$, i.e. find the closest point correspondence in $\mathcal{M}_{\mathcal{C}}$;
    \item[(L1).1] Reconstruct the 3D line $L$ by back-projecting the image lines from two views. Triangulate the point correspondences by fitting them to the anchored multiview variety $\mathcal{M}_{\mathcal{C}}^L$;
    \item[(L1).2] Triangulate two point correspondences by fitting them to $\mathcal{M}_{\mathcal{C}}$ to get 3D points $X$ and $Y$. Let $L$ be the line they span in $\RR^3$. Triangulate the remaining point correspondences by fitting them to $\mathcal{M}_{\mathcal{C}}^L$;  
    \item[(L1).3] Triangulate one point correspondence by fitting it to $\mathcal{M}_{\mathcal{C}}$ to get a 3D point $X$. Reconstruct the 3D line $L$ by fitting the line correspondence to the anchored variety $\mathcal{L}_\mathcal{C}^X$. Triangulate the remaining point correspondences by fitting them to $\mathcal{M}_{\mathcal{C}}^L$;  
    \item[(L1).4] Reconstruct the 3D line $L$ by fitting the line correspondence to the line multiview variety $\mathcal{L}_\mathcal{C}$. Triangulate the point correspondences by fitting them to the anchored multiview variety $\mathcal{M}_{\mathcal{C}}^L$.
\end{enumerate}  

Approaches (L1).1-4 take the incidence relations into account in the triangulation, whereas (L1).0 does not. Therefore, in contrast to (L1).1-4, the resulting triangulation of (L1).0 does not preserve the point-line incidences, see \Cref{fig:my_label1}. 
\begin{figure}
   \centering
   \includegraphics[width = 0.6\textwidth]{L1.0_L1.1.png}
   \caption{Comparison of (L1).0 and (L1).1 triangulation approaches. (L1).0 expects non-collinear points in the reconstruction, while (L1).1 produces collinear points.}
   \label{fig:my_label1}
\end{figure}


\subsection{Implementation}


Our experiments are implemented in \texttt{HomotopyContinuation.jl} \cite{breiding2018homotopycontinuation} in \texttt{Julia} \cite{bezanson2012julia}. Here we explain them in some detail. The full explanation can be found in the code itself. We ran the code on a Intel(R) Core(TM) i5-8300H CPU running at 2.30GHz.


\subsubsection{Reducing the number of parameters} \label{sss:Red} We reduce the number of parameters involved in the problem of fitting data to $\mathcal{M}_\mathcal{C}^L$ and $\mathcal{L}_\mathcal{C}^X$ in the following way. Fix affine patches on each product of projective spaces. 
 Given the data of a point correspondence $(u_1,\ldots,u_m)\in (\RR^2)^m$, in \Cref{thm:anchoredmulti_isomorphism} 1., we choose $\phi_L$ and $\psi_i$ to be isometries, i.e. defined by matrices $A$ and $A_i$ such that $AA^T=I$ and $A_iA_i^T=I$. Consider the optimization problem 
\begin{align}\label{eq:ED11}     \mathrm{minimize}\;\sum_{i=1}^n(A_iu_i-y_i)^2\;\textnormal{subject to }y\in \mathcal{M}_{\widetilde{\mathcal{C}}}^{1,1}.
\end{align}
If $y^*\in \mathcal{M}_{\widetilde{\mathcal{C}}}^{1,1}$ is the solution to \Cref{eq:ED11}, then $x^*=A^Ty^*$ is the solution to 
\begin{align}\label{eq:ED}
     \mathrm{minimize}\;\sum_{i=1}^n(u_i-x_i)^2\;\textnormal{subject to }x\in \mathcal{M}_{\mathcal{C}}^{L}.
\end{align}
The analogous can be stated for \Cref{thm:anchoredmulti_isomorphism} 2 and $\mathcal{L}_\mathcal{C}^X$. This corresponds to a reduction of parameters because the affine patch of $\mathcal{M}_{\widetilde{\mathcal{C}}}^{1,1}$ lives in $\RR^m$, while the affine patch of $\mathcal{M}_{\mathcal{C}}^{X}$ lives in $(\RR^3)^m$. Pseudocode for such implementations are included in the Appendix.

We call the methods that use \Cref{eq:ED} directly \textit{standard} and for instance, write (L1).1 std. to denote it. By just writing (L1).1, we denote the implementation of \Cref{eq:ED11}.


\subsubsection{Evaluating error} 

In our experiments, each iteration starts by randomly generating a 3D line $L$ and $p$ points $X_i$ on this line. These line and points are projected by a randomly generated camera arrangement to line and point correspondences in $(\RR^2)^m$. For fixed $\epsilon =10^{-12}$, randomly generated noise vectors $\sigma(\epsilon)$ of length $\epsilon$ are added in each factor. Our approaches then find points $Y_i\in \RR^3$ that best match the noisy correspondences, meaning that minimize reprojection errors. We measure the accuracy by taking the logarithm after averaging the relative error of reconstructed points:
\begin{equation}
e= \log_{10}\left(\frac{\sum \|Y_i-X_i\|}{p\epsilon}\right),
\end{equation}
where $\|Y_i-X_i\|$ denotes the Euclidean distance. The interpretation of this number is that the error in the data gets amplified by $10^e$ during the triangulation. 

\subsubsection{Algorithms} 

The pseudocode for the approach (L1).1 is presented in~\Cref{alg:L1_1}. In lines 1 and 2, we generate noisy data by introducing randomly generated noise $\sigma(\epsilon)$ as explained above, where $\epsilon=10^{-12}$ is a fixed parameter for our experiments. Lines 3 and 4 correspond to the triangulation of the line and the point correspondences using the anchored point multiview variety at the line $L_0$. Note that we solve the closest point problem in line 4 by computing the zeros of a system of polynomial (critical) equations using the \textit{solve} function in \texttt{HomotopyContinuation.jl} \cite{HC.jl}. Finally, line 5 compares the points obtained in the previous step with the original starting points, measuring the logarithmic average relative error of the $p$ points. 

The pseudocodes for most the other approaches are similar to~\Cref{alg:L1_1}. For instance, approach (L1).0 does not take into account line incidence, so it corresponds deleting lines 1 and 3 from~\Cref{alg:L1_1} and modifying
the minimization domain in line 4, replacing $L_0$ by $\mathcal{M}_{\mathcal{C}}$. In approach (L1).2, line 3 is modified so that $L_0$ is obtained by the span of two triangulated points instead of by intersecting two back-projected planes. The pseudocodes for all approaches are included in the Appendix. 

Below, for a point $X\in \RR^n$, let $\Bar{X}\in \RR^{n+1}$ be $[X \; 1]$. Further, we denote by $\Bar{X}$ a point on this form. This corresponds to choosing an affine patch of $\PP^n$. 

 \begin{algorithm}
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\SetKwInOut{Return}{Return}
\caption{One iteration of the (L1).1 std. method given a randomly generated camera arrangement $\mathcal{C}$, a line in $L\subset \PP^3$, and $p$ points $\Bar{X}_i$ on $L$.}
\label{alg:L1_1}
\Input{$\mathcal{C}=(C_1,\ldots,C_m)$, $L$, $\Bar{X}_1,\ldots,\Bar{X}_p$}
\Output{The log of the average relative error} 
    \For{$j$ \textnormal{from $1$ to $m$}}{
    \For{$i$ \textnormal{from $1$ to $p$}}{
        $q_{i,j} \gets C_j\bar{X}_i +\sigma(\epsilon$)\;}
        $u_j \gets C_j \cdot L +\sigma(\epsilon)$\;}
    $L_0\gets \mathrm{nullspace} \begin{bmatrix}
    C^T_1u_1&C^T_2u_2
    \end{bmatrix}^T$\;
    \For{$i$ \textnormal{from 1 to $p$}}{$\Bar{Y}_i \gets \mathrm{argmin}_{\Bar{X}\in L_0} \sum^{m}_{j=1} (q_{i,j}-C_j\Bar{X})^2$\; }
    $e\gets \log_{10}\left(\frac{\sum \|\Bar{Y}_i-\Bar{X}_i\|}{p\epsilon}\right) $\;
\Return{$e$}

\end{algorithm}

\subsection{Numerical results}


The results of our numerical experiments are presented in \Cref{fig:m_2,fig:m_3,fig:m_4} and~\Cref{tab:m_2,tab:m_3,tab:m_4}. In~\cref{fig:m_2} and~\Cref{tab:m_2} we compare the performance of the five different triangulation approaches for (L1) for $p=5$ point correspondences when $m=2$ cameras. Note that for two cameras, (L1).1 and (L1).4 are essentially the same. 
In \Cref{fig:m_2} and \Cref{tab:m_2} we therefore only include (L1).0, (L1).1 and (L1).3. We also compare with the standard implementations of (L1).1 and (L1).3 that do not use the linear isomorphisms of \Cref{thm:anchoredmulti_isomorphism} to improve computation time as described in \Cref{sss:Red}. This simulation is iterated 1000 times, where for each iteration the logarithmic average relative error of the $p=5$ reconstructed points and the total time for this reconstruction are stored. The results are displayed in histograms and tables created with \texttt{Plots.jl}~\cite{plots} .

 \Cref{fig:m_3} and \Cref{tab:m_3} compare the different reconstruction approaches for (L1) with $p=5$ point correspondences and $m=3$ cameras. The simulations are again iterated 1000 times.

\Cref{fig:m_4} and \Cref{tab:m_4} compare the different reconstruction approaches for (L1) with $p=5$ point correspondences and $m=4$ cameras. The simulations are iterated only 100 times, due to the longer run-time of the simulations.

Our theoretical studies in \Cref{s:AMV}, specifically~\Cref{thm:EDDthm}, implies that methods such as (L1).1, (L1).2 and (L1).3 are less complex, from the algebraic point of view, than (L1).0 for triangulation of points incident to a line. Additionally, using \Cref{sss:Red}, we were able to improve the computation time while retaining comparable accuracy, which is exemplified by the two cases (L1).1 vs. (L1).1 std. and (L1).3 vs. (L1).3 std. in \Cref{tab:m_2}.

Finally, our numerical simulations show that in our \texttt{HomotopyContinuation.jl} implementation, the (L1).1 approach is the fastest across all number of views, but least accurate. In the case of $m=3$, (L1).4 is the most accurate and faster than the traditional (L1).0 method. Even for $m=4$, (L1).4 is the most accurate but is notably slower than (L1).0. 

\begin{figure}[ht]
\begin{center}
    \includegraphics[width = 0.35\textwidth]{Hist_error_1000_std_nonstd_2_cam_new.png}
    \includegraphics[width = 0.35\textwidth]{Hist_time_1000_std_nonstd_2_cam_new.png}
    \caption{Triangulation of $p=5$ point correspondences incident to a line for $m=2$ views with complete visibility. The triangulation of this setting was done 1000 times, and each histogram shows the frequency both for the average relative error and the running time of the triangulation. }
    \label{fig:m_2}
\end{center}
\end{figure}

\begin{table}[ht]
\begin{center}
\begin{tabular}{|l|c|c|c|l|} 
\hline
Accuracy & median & mean & $\sigma$\\
\hline\hline
(L1).0 & 1.031 & 1.243 & 1.213 \\
(L1).1 & 1.489 & 1.702 & 1.085 \\
(L1).1 std. & 1.374 & 1.548 & 0.990\\
(L1).3 & 1.250 & 1.449 & 0.964 \\
(L1).3 std. & 1.147 & 1.393 & 1.205 \\
\hline
\end{tabular}
\hspace{1cm}
\begin{tabular}{|l|c|c|c|l|}
\hline
Speed & median & mean & $\sigma$\\
\hline\hline
(L1).0 & 0.170 & 0.201 & 0.220 \\
(L1).1 & 0.0430 & 0.0470 & 0.0207 \\
(L1).1 std. & 0.122 & 0.141 & 0.202\\
(L1).3 & 0.0838 & 0.0941 & 0.0464 \\
(L1).3 std. & 0.167 & 0.188 & 0.0764 \\
\hline
\end{tabular}
\end{center}
\caption{Results on the relative error (accuracy) and running time of standard and non-standard triangulation approaches, for 1000 iterations of the triangulation of $p=5$ point correspondences incident to one line in $m=2$ views with complete visibility.}
\label{tab:m_2}
\end{table}



\begin{figure}[ht]
\begin{center}
    \includegraphics[width = 0.35\textwidth]{Hist_error_1000_01234_3_cam_newnew.png}
    \includegraphics[width = 0.35\textwidth]{Hist_time_1000_01234_3_cam_newnew.png}
    \caption{Triangulation of $p=5$ point correspondences incident to a line for $m=3$ views with complete visibility. The triangulation of this setting was done 1000 times, and each histogram shows the frequency both for the relative error and the running time of the depicted triangulation methods. }
    \label{fig:m_3}
\end{center}
\end{figure}




\begin{table}[ht]
\begin{center}
\begin{tabular}{|l|c|c|c|l|} 
\hline
Accuracy & median & mean & $\sigma$\\
\hline\hline
(L1).0 & 0.620 & 0.817 & 1.023 \\
(L1).1 & 1.562 & 1.781 & 1.128 \\
(L1).2 & 0.878 & 1.125 & 0.998\\
(L1).3 & 1.011 & 1.243 & 1.078 \\
(L1).4 & 0.407 & 0.499 & 0.901 \\
\hline
\end{tabular}
\hspace{1cm}
\begin{tabular}{|l|c|c|c|l|}
\hline
Speed & median & mean & $\sigma$\\
\hline\hline
(L1).0 & 0.984 & 1.060 & 0.514 \\
(L1).1 & 0.0806 & 0.0858 & 0.0318 \\
(L1).2 & 0.431 & 0.456 & 0.155\\
(L1).3 & 0.304 & 0.331 & 0.134 \\
(L1).4 & 0.616 & 0.763 & 0.500 \\
\hline
\end{tabular}
\end{center}
\caption{Results on the relative error (accuracy) and running time of the (L1) triangulation approaches, for 1000 iterations of the triangulation of $p=5$ point correspondences incident to one line in $m=3$ views with complete visibility.}
\label{tab:m_3}
\end{table}

\begin{figure}[ht]
\begin{center}
    \includegraphics[width = 0.35\textwidth]{Hist_error_100_01234_4_cam.png}
    \includegraphics[width = 0.35\textwidth]{Hist_time_100_01234_4_cam.png}
    \caption{Triangulation of $p=5$ point correspondences incident to a line for $m=4$ views with complete visibility. The triangulation of this setting was done 100 times, and each histogram shows the frequency both for the relative error and the running time of the depicted triangulation methods. }
    \label{fig:m_4}
\end{center}
\end{figure}


\begin{table}[ht]
\begin{center}
\begin{tabular}{|l|c|c|c|l|} 
\hline
Accuracy & median & mean & $\sigma$\\
\hline\hline
(L1).0 & 0.385 & 0.551 & 0.776 \\
(L1).1 & 1.437 & 1.762 & 1.249 \\
(L1).2 & 1.095 & 1.077 & 0.845\\
(L1).3 & 0.817 & 1.110 & 1.094 \\
(L1).4 & 0.203 & 0.421 & 1.324 \\
\hline
\end{tabular}
\hspace{1cm}
\begin{tabular}{|l|c|c|c|l|}
\hline
Speed & median & mean & $\sigma$\\
\hline\hline
(L1).0 & 4.365 & 4.675 & 1.576 \\
(L1).1 & 0.141 & 0.149 & 0.0431 \\
(L1).2 & 1.809 & 1.863 & 0.323\\
(L1).3 & 1.107 & 1.157 & 0.234 \\
(L1).4 & 6.599 & 7.391 & 3.068 \\
\hline
\end{tabular}
\end{center}

\caption{Results on the relative error (accuracy) and running time of the (L1) triangulation approaches, for 100 iterations of the triangulation of $p=5$ point correspondences incident to one line in $m=4$ views with complete visibility.}
\label{tab:m_4}
\end{table}

\section{Conclusion and Future Work}

This work focused on the algebraic study of the triangulation of incident points and lines. To do so, we introduced the anchored line multiview varieties and showed that, not only do they correspond to a lower dimensional traditional multiview variety, but also have a smaller complexity when the reconstruction is done via critical points. These theoretical results are also aligned with the numerical experiments we conducted. 
In particular, the proposed methods in~\Cref{s:NUM} compare different methods for triangulating a set of points incident to a line. We highlight that according to our experiments, the use of the theoretical results in~\Cref{s:AMV} allows for a notably faster triangulation while preserving the accuracy of the traditional method for point reconstruction. 


We hope this work motivates the use of new algebraic constraints in the triangulation of incident points and lines. Some questions that arose in the development of this work, and that we believe are worth studying, are included below.
\begin{itemize}
    \item A triangulation approach inspired by \cite{BARTOLI2005416} consists on reconstructing the 3D line $L$ by fitting it to $ \mathcal L_{\mathcal C}$ solving the following optimization problem 
    \begin{align}
        \mathrm{minimize}\quad \sum_{ij}d(x_{ij},\ell_i)^2 \textnormal{subject to} \quad \ell\in \mathcal{L}_\mathcal{C}.
    \end{align}
    Here, $x_{ij}$ denotes the $j=1,\ldots,p$ point correspondences across $i=1,\ldots,m$ cameras, and $d(x_{ij},\ell_i)$ is the affine distance from a line in $\RR^2$ to the point, meaning
\begin{align}
d(x_{ij},\ell_i)=\frac{|1+(\ell_{i})_1(x_{ij})_1+(\ell_{i})_2(x_{ij})_2|}{\sqrt{(\ell_{i})_1^2+(\ell_{i})_2^2}}.
\end{align} We believe that this method is more accurate than (L1).4, but with longer running time. This is due to the appearance of fractions.

\item Consider the point-line problem (P1) defined by one point incident to $l$ lines, illustrated in~\Cref{fig:L1_and_P1}. Can similar approaches to (L1).1-4 be formulated for the triangulation of the (P1) setting? Can they be used to improve accuracy and/or the speed of triangulation in this setting?


\item Our implementation for the numerical experiments does not directly correspond to the specialized software and hardware used for triangulation in practice. However, our results motivate that patterns displayed in our figures and tables could translate to such settings. This could improve the efficiency of current specialized solvers. 
\end{itemize}

{\small
\bibliographystyle{abbrv}
\bibliography{VisionBib}
}
\newpage

\appendix

\section*{Appendix} 
In this Supplementary Material we prove all the mathematical results from the main body of the paper. For convenience of the
reader, we start in \Cref{s:AlgPre} by explaining the elementary notions of algebraic geometry, that are helpful to understand the rest of the Appendix. Results that appear in the main body
of the paper are restated and are given the same number. Additional results not stated in the main body, are numbered independently.




\Cref{s:AMV_App} deals with \Cref{s:AMV} apart from the Euclidean distance degree. In \Cref{s:EDDprelim} we provide helpful background for the EDD calculations of \Cref{s:EDD}. In \Cref{s:Pseudo} we provide pseudocode for the different reconstruction approaches from \Cref{s:NUM}.


\section{Algebraic Geometry Preliminaries}\label{s:AlgPre} See \cite[Section 1]{breiding2022line} for background on the basic properties of rational maps that are used in this section.

The \textit{complex projective space} of dimension $n$ is the set of one-dimensional linear subspaces of $\CC^n$, equivalently $\PP^{n-1}\coloneqq (\CC^n\setminus \{0\})/\sim $, where $\sim$ denotes the equivalence relation defined by
\begin{equation}
    x\sim y \Leftrightarrow x=\lambda y \quad\mbox{ for some }\quad 0\neq\lambda\in\CC.
\end{equation}

The ring of polynomials in $n+1$ variables is denoted by $R\coloneqq \CC\left[x_0,\ldots ,x_n\right]$. A subset $X\subseteq \PP^n$  is called a \textit{projective algebraic variety}, if there exists a set of homogeneous polynomials $\{f_1,\ldots ,f_k\}$ such that $X=\{x\in\PP^n \mid f_1(x)=\cdots f_k(x)=0\}$. In other words, $X$ is the vanishing set of the polynomials $f_i$ for $i=1,\ldots ,k$ such  that each term of the polynomial has degree $d$ and $f_i(\lambda x_0,\ldots ,\lambda x_n)=\lambda^df_i(x_0,\ldots ,x_n)$. Similarly, a subset $X\subseteq \PP^{n_1}\times \cdots \times \PP^{n_m}$ is an algebraic variety, if $X$ is the vanishing set of multi-homogeneous polynomials $\{f_1,\ldots ,f_k\}$.  

The Zariski topology on $\PP^n$ (or $\PP^{n_1}\times \cdots \times \PP^{n_m}$) is the topology whose closed sets are algebraic varieties. Given a set $U$, its Zariski closure, denoted $\overline{U}$, is the smallest variety containing $U$. 


Let $X\subseteq \PP^n$ and $Y\subseteq \PP^m$ be projective varieties. A map $\varphi:X\longrightarrow Y$ is regular if it can be written as 
    \begin{equation}
        \varphi(x)=\left[\varphi_0(x) : \cdots :\varphi_m(x) \right]
    \end{equation}
for some polynomials $\varphi_0, \ldots ,\varphi_m$. If there is a regular map $\psi: Y\longrightarrow X$ such that $\varphi\circ\psi ={\rm Id}_Y$ and $\psi\circ \varphi ={\rm Id}_X$, we say that $X$ and $Y$ are \textit{isomorphic}, and we denote it by $X\cong Y$. If $U\subseteq X$ is a Zariski dense open set, and $\varphi:U\longrightarrow Y$ is a regular map, we say that $\varphi$ is a \textit{rational map} from $X$ to $Y$, and denote it by $\varphi:X\dashrightarrow Y$. 

Given a variety $X$, we define its \textit{ideal} as the set
\begin{equation}
    I(X)=\{f\in R \mid f(x)=0 \mbox{ for every } x\in X\}
\end{equation}
of homogeneous polynomials that vanish in every element of $X$. For every ideal $I$, it is possible to find a (not necessarily unique) finite set of polynomials $\{f_1,\ldots ,f_k\}\subseteq I$, such that every element $f\in I$ can be written as
\begin{equation}
    f(x)=g_1(x)f_1(x)+\cdots +g_k(x)f_k(x),
\end{equation}
for some polynomials $g_i(x)\in R$. In this case we say that $I$ is \textit{generated} by $\{f_1,\ldots ,f_k\}$, and denote it by $I=\langle f_1,\ldots ,f_k\rangle$. 

Given a variety $X$ and its ideal $I(X)=\langle f_1,\ldots ,f_k\rangle$, we say that a point $a\in X$ is \textit{smooth} if the rank of the Jacobian matrix $J(a)\coloneqq \left[\frac{\partial f_i}{\partial x_i} (a)\right]$ is equal to the codimension of $X$. This definition is independent of the choice of generators of $I(X)$. For a broader description and results on smoothness of algebraic varieties we refer the reader to~\cite{Gathmann}.  

We use the notation $\vee$ to denote the \textit{join} of two vectors spaces, meaning $U\vee V=\mathrm{span}\{U,V\}$. Similarly, $\wedge$ denotes the intersection of linear spaces.

\section{Anchored Multiview Varieties} \label{s:AMV_App} 

For a camera matrix $C:\PP^3\dashrightarrow\PP^2$ and a point $x\in \PP^2$, its back-projected line is the line in $\PP^3$ containing all the points that are by $C$ projected onto $x$. Recall that a line in $\Gr(1,\PP^2)$ is identified with its linear equation $\ell\in \PP^2$. Its back-projected plane is the plane in $\PP^3$ containing all lines that are by $C$ projected onto $\ell$. The defining linear equation of the back-projected plane is $C^T\ell$. We may parameterize lines in ${\rm Gr}(1,\PP^3)$ by two points spanning it.

Throughout all this work we assume that any camera arrangement has at least two cameras and all centers are disjoint. 

\subsection{The linear isomorphisms}

Consider an arrangement $\widetilde{\mathcal{C}}$ of full-rank $2\times 2$ matrices, and an arrangement $\widehat{\mathcal{C}}$ of full-rank $2\times 3$ matrices. We define $\mathcal{M}_{\widetilde{\mathcal{C}}}^{1,1}$, and $\mathcal{M}_{\widehat{\mathcal{C}}}^{2,1}$, respectively as the Zarizki closure of the image of the joint maps
    \begin{equation}
        \begin{split}
            \Phi_{\widetilde{\mathcal{C}}}: \PP^1&\longrightarrow (\PP^1)^m \\
            X & \longmapsto (\widetilde C_1X,\ldots,\widetilde C_mX)
        \end{split}
    \end{equation}
and 
    \begin{equation}
        \begin{split}
            \Phi_{\widehat{\mathcal{C}}}:\PP^2&\dashrightarrow (\PP^1)^m\\
            X& \longmapsto (\widehat{C}_1X,\ldots \widehat{C}_mX).
        \end{split} 
    \end{equation}

For a rational map $f:\mathcal{X}\dashrightarrow \mathcal Y$, let $f|_A$ denote the restriction of $f$ to $A\subseteq \mathcal X$.

\begin{customtheorem}{\ref{thm:anchoredmulti_isomorphism}} $ $ 

\begin{enumerate}
     \item Let $\phi_L:L \to \PP^1$ and $\psi_{i}:C_i\cdot L\to \PP^1$ be any choices of linear isomorphisms. Let $\widetilde{\mathcal{C}}$ denote the arrangement of matrices $\widetilde{C}_i=\psi_{\mathcal{C},i} \circ C_i\circ \phi_L^{-1} $. Then 
    \begin{align}
        \psi_{\mathcal{C},L}:=(\psi_{1},\ldots,\psi_{m}):\mathcal{M}_\mathcal{C}^L\to  \mathcal{M}_{\widetilde{\mathcal{C}}}^{1,1},
    \end{align}
    is a linear isomorphism.
    \item Let $\phi_X: \Lambda(X)\to \PP^2$ and $\psi_i: \Lambda(C_i X)\to \PP^1$ be any choices of linear isomorphisms. Let $\widehat{\mathcal{C}}$ denote the arrangement of matrices $\widehat{C}_i=\psi_{i} \circ C_i\circ \phi_X^{-1} $. Then 
    \begin{align}
        \psi_{\mathcal{C},X}:=(\psi_1,\ldots,\psi_{m}): \mathcal{L}_\mathcal{C}^X\to \mathcal{M}_{\widehat{\mathcal{C}}}^{2,1},
    \end{align}
    is a linear isomorphism.
\end{enumerate}
\end{customtheorem}
We interpret $C_i\circ \phi_X^{-1}$ as a matrix as follows. Let $H$ be a plane in $\PP^3$ disjoint from $X$. Then $\phi_X^{-1}:\PP^2\to \Lambda(X)$ is defined by a linear map $f_X:\PP^2\to H$ such that $\phi_X^{-1}(Y)=\mathrm{span}\{X,f_X(Y)\}$. As a matrix, $C_i\circ \phi_X^{-1}$ is equal to $[C_iX]_\times C_i f_X$, where 
\begin{align}
    [a]_\times:=\begin{bmatrix}0 & -a_3 & a_2 \\
    a_3 & 0 & -a_1 \\
    -a_2 & a_1 & 0\end{bmatrix}.
\end{align}

\begin{lemma}\label{le:ClosIsomo} Let $\psi:\mathcal X \to\mathcal Y$ be an isomorphism and $U\subseteq \mathcal X,V\subseteq \mathcal Y$ sets whose Euclidean closures equal their Zariski closures. If $\psi(U)=V$, then $\psi(\overline{U})=\overline{V}$.
\end{lemma}

\begin{proof} Take a point $v\in \overline{V}\setminus V$. There is a sequence $V\ni v^{(n)}\to v$ in Euclidean topology. Then $u^{(n)}=\psi^{-1}(v^{(n)})\in U$ converges in Euclidean topology by continuity of $\psi$ to a point $u\in \overline{U}$ for which $\psi(u)=v$. We have shown $\overline{V}\subseteq \psi(\overline{U})$. Similarly we show $\overline{U}\subseteq \psi^{-1}(\overline{V})$ from which it follows that $\psi(\overline{U})\subseteq \overline{V}$.
\end{proof}

\begin{proof}[Proof of \Cref{thm:anchoredmulti_isomorphism}] $ $

$1.$ It is worth noting that $\Phi_\mathcal{C}|_L$ is well-defined everywhere, as $L$ does not contain any center. Additionally, $\Phi_{\widetilde{\mathcal{C}}}$ is defined everywhere. In particular, the images of both maps are Zariski closed. By construction, $\psi_{\mathcal C,L}(\Phi_{\mathcal C}|_L(X))=\Phi_{\widetilde{\mathcal{C}}}(\phi_L(X))$, which shows that $\psi_{\mathcal C,L}$ is a well-defined map.

Take $x\in\mathcal{M}_{\widetilde{\mathcal{C}}}^{1,1}$, then there is an $X\in \PP^1$ such that $x_i=\widetilde{C}_iX$ for each $i$. Consider the image $x'\in \mathcal{M}_{\mathcal{C}}^L$ of $X'=\phi_L^{-1}(X)$. We have $x_i'=C_iX'$. By construction, $x$ is the image of $x'$ under $\psi_{\mathcal C,L}$, which shows surjectivity.  

For injectivity, assume that $\psi_{\mathcal C,L}(X)=\psi_{\mathcal C,L}(X')$. Then for each $i$, $C_iX=C_iX'$. However, since the line $L$ does not meet any of the centers, this implies that $X=X'$.

$2.$ As we wish to use \Cref{le:ClosIsomo}, we let 
\begin{align}
   \mathcal X=(\PP^2)^m, \quad \mathcal Y=\Lambda(C_1X)\times \cdots\times \Lambda(C_mX).
\end{align}
Further, let $U=\mathrm{Im}\;\Phi_{\widehat{\mathcal{C}}}$, and $V$ be the image of $\Upsilon_\mathcal{C}|_{\Lambda(X)}$. We show that $\psi_{\mathcal{C},X}(U)=V$ by similar calculations to 1.  
\end{proof}


\subsection{Irreducibility, dimension, and equations} 

In the main body of the paper it was claimed that the anchored multiview varieties under natural conditions equal
\begin{align}
    \mathcal{X}_\mathcal{C}^L&=\{(x_1,\ldots,x_m)\in \mathcal{M}_{\mathcal{C}}: x_i\in C_i\cdot L\},\label{eq:defAnc1}\\
    \mathcal{Y}_\mathcal{C}^X&=\{(\ell_1,\ldots,\ell_m)\in \mathcal{L}_{\mathcal{C}}: C_iX\in \ell_i\}.\label{eq:defAnc2}
\end{align}

This provides an alternative characterization as the closure of the images of restrictions of $\Phi_\mathcal{C}$ and $\Upsilon_\mathcal{C}$, which is a useful fact that we formalize in the following lemma. 

\begin{customproposition}{\ref{prop:first_eq}} $ $

    \begin{enumerate}
        \item If there are two camera centers $c_i$ and $c_j$ such that the span of $\{c_i,c_j,L\}$ is $\PP^3$, then $\mathcal M_\mathcal{C}^L$ equals $\mathcal{X}_\mathcal{C}^L$;

        \item If for each camera center $c_i$, the line spanned by $c_i$ and $X$ contains no other center than $c_i$, then $\mathcal{L}_\mathcal{C}^X$ equals $ \mathcal{Y}_\mathcal{C}^X$.
    \end{enumerate}
\end{customproposition}


\begin{proof} 

$1.$ We recall the assumption that $L$ contains no center. Then $\Phi_\mathcal{C}|_L$ is defined everywhere and the image of this map is closed. Let $x\in \mathrm{Im}\Phi_\mathcal{C}|_L$. There is an $X\in L$ such that $x=\Phi_\mathcal{C}(X)$. Therefore $x\in \mathcal{M}_\mathcal{C}$ and $x_i\in C_i\cdot L$. Conversely, if $x\in \mathcal{M}_\mathcal{C}$ and $x_i\in C_i\cdot L$, then since the back-projected line of $x_i$ meet $L$ in a unique points $X_i\in L$, we just have to argue that $X_i$ are all the same. If there are two centers $c_i,c_j$ that together with $L$ span $\PP^3$, then the planes $c_i\vee L$ and $c_j\vee L$ meet in exactly the line $L$. Then the back-projected lines of $x_i,x_j$ must meet in $L$, showing $X_i=X_j$. For any other center $c_k$, we either have that $c_i,c_k$ and $L$ span $\PP^3$ or $c_j,c_k$ and $L$ span $\PP^3$. This either implies $X_i=X_k$ or $X_j=X_k$ by the above. Either way repeating this process shows that all $X_i$ are equal and $x=\Phi_\mathcal{C}(X)$ for $X=X_i$.  

$2.$ For any line $L\in \Lambda(X)$ that does not meet any center, it is clear that $\ell=\Upsilon_\mathcal{C}(L)$ satisfies $\ell\in \mathcal{L}_\mathcal{C}$ and $C_iX\in \ell_i$. Therefore $\mathcal{L}_\mathcal{C}^X\subseteq  \mathcal{Y}_\mathcal{C}^X$. For the other inclusion, take $\ell\in \mathcal{Y}_\mathcal{C}^X$. If the intersection of the back-projected planes $H_i$ of $\ell_i$ contain a line $L$ through $X$ meeting no center, then $\ell=\Upsilon_{\mathcal{C}}|_{\Lambda(X)}(L)$. This especially happens when $H_i$ intersect in a plane. Note that if the intersection contains a line $L$ that doesn't meet $X$, then the intersection also contains the plane $X\vee L$. We are left to check what happens if $H_i$ intersect in exactly a line $L$ that meets a center, say $c_i$. By assumption, no other center is contained in this line. Therefore $H_j,j\neq i$ is equal to $c_j\vee L$. Let $L^{(n)}\in \Lambda(X)$ be any sequence of lines in $H^{(i)}$ meeting no centers and such that $L^{(n)}\to L$. It is clear that $c_j\vee L^{(n)}\to H_j$ and $c_i\vee L^{(n)}\to H_i$ as $n\to \infty$. Then $\Upsilon_\mathcal{C}(L^{(n)})\to \ell$, showing $\ell\in \mathcal{L}_\mathcal{C}^X$ and we are done.  \end{proof}


If the assumptions of \Cref{prop:first_eq} do not hold, then the result doesn't either. In the first statement, let $c_1,c_2$ be centers that together with $L$ spans a plane $P$. Given any point $X\in P\setminus \{c_1,c_2\}$, the element $x=(C_1 X, C_2X)$ satisfies that $x\in \mathcal{M}_\mathcal{C}$ and $x_i\in C_i\cdot L$. However, generally for a point $X\in P\setminus L$, we have $x\not\in \mathrm{Im}\Phi_\mathcal{C}|_L$. For the second statement, consider two centers $c_1,c_2$ that together with $X$ span a line $L$. Consider two distinct planes $H_1,H_2$, both containing the line $L$. They meet therefore exactly in $L$ and the pair of corresponding image lines $(\ell_1,\ell_2)$ lies in $ \mathcal{Y}_\mathcal{C}^X$ for the camera arrangement given by these two cameras. However, in the image of $\Upsilon_\mathcal{C}|_{\Lambda(X)}$, the back-projected planes $H_1$ and $H_2$ are always the same.


\begin{customproposition}{\ref{cor:dim}} $\mathcal{M}_\mathcal{C}^L$ and $\mathcal{L}_\mathcal{C}^X$ are irreducible. Further, 

\begin{enumerate}
    \item $\mathcal{M}_\mathcal{C}^L$ is isomorphic to $\PP^1$. In particular, $\dim\mathcal{M}_\mathcal{C}^L=1$;
    \item If the centers $c_i$ and the point $X$ are not collinear, then $\dim \mathcal{L}_\mathcal{C}^X=2$. 
\end{enumerate}   
\end{customproposition}

\begin{proof} Both varieties are irreducible since the image of any rational map from an irreducible variety is irreducible.

$1.$ Since we assume no center lies in $L$, $\Phi_\mathcal{C}$ restricted to $L$ is defined everywhere, and therefore the image of this restriction equals $\mathcal{M}_\mathcal{C}^L$. This map is further injective since if $x\in \mathcal{M}_\mathcal{C}^L$, then the back-projected line of $x_i\in \PP^2$ meets $L$ in exactly a point $X$, which implies that $X$ is the only point on $L$ for which $x=\Phi_\mathcal{C}(X)$. 

$2.$ Note that since $\dim \Lambda(X)=2$, we have $ \dim\mathcal{L}_\mathcal{C}^X\le 2$. Let $U\subseteq \Lambda(X)$ be the subset of lines that meets no center. Without restriction, assume $c_1,c_2$ and $X$ span a plane. Each line $L\in U$ uniquely defined two planes via $c_1\vee L,c_2\vee L$. Since $\dim \Lambda(X)=2$, projection of $ \mathcal{L}_\mathcal{C}^X$ onto the first two factors is at least two dimensional, showing $ \dim\mathcal{L}_\mathcal{C}^X\ge 2$. 
\end{proof}

For the result below, let $F^{ij}$ denote the fundamental matrix of $C_i$ and $C_j$ \cite{Hartley2004,trager2015joint}.

\begin{customproposition}{\ref{prop:eq}} For a point $X\in \PP^3$ and line $L\in \Gr(1,\PP^3)$, let $\mathcal{C}$ be a generic (random) camera arrangement of $m$ cameras. 
\begin{enumerate}
    \item $x\in \mathcal{M}_\mathcal{C}^L$ if and only if $x_1^TF^{1j}x_j=0$ for every $j=2,\ldots,m$ and $x_i^TC_i\cdot L=0$ for every $i=1,\ldots,m$;
    \item $\ell\in \mathcal{L}_\mathcal{C}^X$ if and only if
    \begin{align}\label{eq:triples}\begin{aligned}
        \det \begin{bmatrix}
    C_1^T \ell_1 & C_2^T \ell_2 & C_i^T\ell_i 
    \end{bmatrix}=0,\\  
    \det \begin{bmatrix}
    C_1^T \ell_1 & C_3^T \ell_3 & C_i^T\ell_i 
    \end{bmatrix}=0,
    \end{aligned}
    \end{align}
    for $i=3,\ldots,m$ and $\ell_i^T C_iX=0$ for every $i=1,\ldots,m$.
\end{enumerate}
\end{customproposition}



\begin{proof} $ $

$1.$ Recall that $x_i^TC_i\cdot L=0$ is equivalent to $x_i\in C_i\cdot L$. As in the proof of \Cref{cor:dim}, $x\in \mathcal{M}_\mathcal{C}^L$ is uniquely determined by the intersection $X\in L$ of its back-projected lines. The back-projected lines $L_i$ of $x_i$ intersect if and only if the pairs $(L_1,L_i)$ intersect for $i\ge 2$, which in turn is equivalent to $x_1^TF^{1i}x_i=0$ for the fundamental matrix $F^{1i}$. 

$2.$ By \Cref{prop:first_eq}, $\ell\in \mathcal{L}_{\mathcal{C}}^X$ is equivalent to $\ell\in \mathcal{L}_{\mathcal{C}}$ and $C_iX\in \ell_i$. For generic cameras, $\ell\in \mathcal{L}_{\mathcal{C}}$ if and only if the back-projected planes of $\ell_i$ meet in at least a line \cite{breiding2022line}. Recall that $C_iX\in \ell_i$ is equivalent to $\ell_i^T C_iX=0$. Further, 
 \begin{align} \label{eq:ijk}
        \det \begin{bmatrix}
    C_i^T \ell_i & C_j^T \ell_j & C_k^T\ell_k 
    \end{bmatrix}=0,
\end{align}
means that the back-projected planes of $\ell_i,\ell_j,\ell_k$ meet in at least a line. Therefore, we need to show that under the assumption $C_iX\in \ell_i$, the back-projected planes $H_i$ of $\ell_i$ meet in a line if \Cref{eq:triples} holds for each $i=1,\ldots,m$. For $m=2$, the two back-projected planes always meet in a line. Let $m\ge 3$. By genericity, $c_1,c_2,c_3$ span together with $X$ all of $\PP^3$. Since $X\in H_i$ for each $i$, $H_1,H_2,H_3$ always meet in exactly a line. If $m\ge 4$, it suffices without restriction to show that $H_4$ meets $H_1,H_2,H_3$ in this line. Note that either $H_1,H_2$ or $H_1,H_3$ meet exactly in a line. Let $i,j\in \{1,2,3\}$ denote such indices. Then for $i,j$ and $k=4$, \Cref{eq:ijk} guarantees that $H_i,H_j,H_4$ meet in exactly a line, which suffices. 
\end{proof}

\subsection{Smoothness and multidegrees} In order to determine smoothness properties of multiview varieties, both of \cite{trager2015joint,breiding2022line} use the variety of back-projected lines, respectively back-projected planes. We use the same technique for $\mathcal{L}_\mathcal{C}^X$.  

\begin{customproposition}{\ref{prop:smooth}} $ $

\begin{enumerate}
    \item $\mathcal{M}_\mathcal{C}^L$ is smooth; 
    \item If there are exactly two cameras, or the centers together with the point $X$ span $\PP^3$, then $\mathcal{L}_\mathcal{C}^X$ is smooth. 
\end{enumerate}
\end{customproposition}

\begin{proof} $ $

$1.$ Since $\mathcal{M}_\mathcal{C}^L$ is isomorphic to $\PP^1$ by \Cref{cor:dim}, it is smooth.

$2.$ Assume that the line $c_i\vee X$ contains $c_j$ for $j\neq i$. In the image we always have $H_i=H_j$ for the back-projected planes of $\ell_i,\ell_j$. Therefore $\mathcal{L}_\mathcal{C}^X$ is isomorphic to $\mathcal{L}_{\mathcal{C}'}^X$, where $\mathcal{C}'$ is equal to $\mathcal{C}$ after having removed the smallest amount of cameras from $\mathcal{C}$ such that each line $c_i\vee X$ contains exactly one center, namely $c_i$ itself. We therefore assume now that $\mathcal{C}$ has this property.

If $m=2$ one can check that $\mathcal{L}_{\mathcal{C}}^X$ is isomorphic to $\PP^1\times \PP^1$. The latter is for instance because any choice of $\ell_1,\ell_2$, where $C_iX\in \ell_i$ guarantees that the back-projected planes $H_i$ meet in a line containing $X$. Therefore we now assume that there are at least three cameras. 

First we recall that $\Lambda(X)$ is a smooth variety and the lines $c_i\vee X$ are smooth subvarieties. Up to linear transformation we may without loss of generality assume $X=(1:0:0:0)$. Let $a=(a_0:a_1:a_2:a_3)$ be distinct from $X$. Then the Plücker coordinates of $a\vee X$ are $(0:0:a_0:0:a_1:a_2)$. Especially, 
\begin{align}
    \Lambda(X)=\{w\in \PP^5: w_0=w_1=w_3=0\}.
\end{align}
In Plücker coordinates, the plane spanned by the line $L=a\vee X$ in coordinates $w$ and the point $b=(b_0:b_1:b_2:b_3)$ is 
\begin{align}\label{eq:PluPlane}
    (0: w_2b_1-w_4b_0: w_2b_2-w_5b_0:w_4b_2-w_5b_1).
\end{align}
The three linear non-zero functions in $w$ in \Cref{eq:PluPlane} vanish if and only if $b$ lies in the line $L$. Denote them by $f_{b,1},f_{b,2},f_{b,3}$ and write $f_b(L)=(0:f_{b,1}(L):f_{b,2}(L):f_{b,3}(L))$ for a line $L\in \Lambda(X)$. Let $c\neq X$. Since the blow-up of a linear space at a linear space is smooth, 
\begin{align}
   \Gamma_{c}:= \overline{\{(L,f_c(L)):c\vee X\neq L\in \Lambda(X) \}},
\end{align}
is a smooth variety in $\Lambda(X)\times \Gr(1,\PP^3)$. Note that $f_c(L)=c\vee L$. Next we consider the joint blow-up $\Gamma_\mathcal{C}$ defined as,
\begin{align}
\overline{\{(L,f_{c_1}(L),\ldots,f_{c_m}(L)): c_i\vee X\neq L\in \Lambda(X)\}},
\end{align}
in $\Lambda(X)\times \mathrm{Gr}(1,\PP^3)^m$. Take an element $\ell\in \mathcal{L}_\mathcal{C}^X$. By assumption that there are at least three cameras, and the centers together with the point $X$ span $\PP^3$, we have that the back-projected planes meet in exactly a line $L$ containing $X$ as argued in the proof of \Cref{prop:eq}. We have also assumed that $L$ contains at most one center. If $c_i\in L$, then fix the index $i$, otherwise choose any index $i$. Consider the natural projection,
\begin{align}
\pi_i:\Gamma_\mathcal{C}\to \Gamma_{c_i}.
\end{align}
Restricting to the set where $L$ meets none of the other centers $c_j,j\neq i$, this map is an isomorphism. Since $\Gamma_{c_i}$ is smooth, that means that any element of $\Gamma_\mathcal{C}$, where $L$ does not meet $c_j,j\neq i$ is smooth. But since $i$ was arbitrary, all of $\Gamma_\mathcal{C}$ is smooth. Finally, since the back-projected planes always meet in exactly a line, the projection onto the last $m$ coordinates
\begin{align}
    \pi:\Gamma_{\mathcal{C}}\to \widetilde{\mathcal{L}}_\mathcal{C}^X,
\end{align}
is an isomorphism and therefore $ \widetilde{\mathcal{L}}_\mathcal{C}^X$ is smooth, but this is the variety of the back-projected planes of $\mathcal{L}_\mathcal{C}^X$. In particular, they are isomorphic and therefore $\mathcal{L}_\mathcal{C}^X$ is also smooth.
\end{proof}

We next prove the result on the multidegree presented in the main body of the paper.

\begin{customproposition}{\ref{prop:multideg}} Let $\mathcal{C}$ be a generic arrangement of cameras.

\begin{enumerate}
    \item The multidegree of $\mathcal{M}_\mathcal{C}^L$ is given by the single number $D(1,0,\ldots,0)=1$.
    \item Let $m\ge 2$. The multidegree of $\mathcal{L}_\mathcal{C}^X$ is given by $D(2,0,\ldots,0)=0$ and $D(1,1,0,\ldots,0)=1$.
    \end{enumerate}
\end{customproposition}


\begin{proof} $ $

1.  Since $\mathcal{M}_{\mathcal{C}}^L$ is of dimension 1 and by symmetry, we only need to consider one number, namely $D(1,0,\ldots,0)$. A generic linear form intersecting the line $C_1\cdot L$ leaves one point, say $x_1$. Its back-projected line meets $L$ in a unique point $X$. Recall that any point outside the back-projected line is not projected onto $x_1$ by $C_1$. Since $\mathcal{M}_\mathcal{C}^L$ equals the image of $\Phi_{\mathcal{C}}|_L$, $X$ is therefore the unique point on $L$ such that $x=\Phi_\mathcal{L}(X)$.

2. Due to the symmetry and that $\dim \mathcal{L}_\mathcal{C}^X=2$, we only need to find $D(2,0,\ldots,0)$ and 
$D(1,1,0,\ldots,0)$. Two generic linear forms intersecting $\Lambda(C_1X)\subseteq \PP^2$ leaves an empty set, why $D(2,0,\ldots,0)=0$. Intersecting $\Lambda(C_1X)$ and $\Lambda(C_2X)$ each with generic linear forms leaves one point in each copy of $\PP^2$, say $\ell_1$ and $\ell_2$. In particular, $C_1X\in \ell_1$ and $C_2X\in \ell_2$. Since $\ell_i$ are generic such that $C_iX\in \ell_i$, their back-projected planes $H_i$ both contain $X$. By genericity, $H_i$ meet in a unique line through $X$ that meets no center, showing $D(1,1,0,\ldots,0)=1$.
 \end{proof}


\subsection{The Euclidean distance problem} It is not always true that linearly isomorphic varieties have the same Euclidean distance degree. Take for instance the circle and ellipse in $\RR^2$. The circle has EDD $2$ and the ellipse has EDD $4$. However, under additional assumption the EDD is the same.


\begin{proposition}\label{prop:EDbij} Let $X\subseteq \CC^n, Y\subseteq \CC^m$ be varieties containing $0$ (with $n\ge m$) and let $\psi:X\to Y$ be a real linear isomorphism given by a full-rank matrix $A$ such that $AA^T=I$. Assume that the smallest linear space $V$ that $X$ lies in is spanned by real vectors. Then, $\mathrm{EDD}(X)=\mathrm{EDD}(Y)$. 

In particular, fix a generic $u\in \CC^n$. If $y_1^*,\ldots,y_k^*$ are the solutions to the critical equations of the ED problem on $Y$ given $Au$, then $x_1^*=A^Ty_1^*,\ldots,x_k^*=A^Ty_k^*$ are the solutions to the critical equations of the ED problem on $X$ given $u$. 
\end{proposition}

Translation does not affect the Euclidean distance degree, and therefore assuming $0\in X,Y$ is not really a restriction.

\begin{proof} Let $I_X=\langle f_1,\ldots,f_r\rangle$ be the defining ideal of $X$. Let $g_i=f_i\circ A^T$. We claim that $I_Y=\langle g_1,\ldots,g_r\rangle$ is the defining ideal of $Y$. Indeed, $y\in Y$ if and only if $A^Ty\in X$ if and only if $f_i(A^Ty)=0$ for each $i$. Further, a full-rank linear change of coordinates preserves radicality of ideals. 

Since $\psi$ is an isomorphism, $x\in X$ is smooth if and only if $Ax\in Y$ is smooth. Now for a generic $u\in \CC^n$, let $z^*=(z_1,\ldots,z_m)\in Y$ be smooth and a solution to the critical equations given $Au$. Write $c_Y=\mathrm{codim}_{\CC^m}Y$. Then
\begin{align}\label{eq:gzstar}
     g_i(z^*)=0~\mbox{ for all } i~\&~\mathrm{rank} \begin{bmatrix} (z^*-Au)^T\\
    \nabla g_1(z^*)\\
     \vdots \\
     \nabla g_k(z^*)  
    \end{bmatrix}=c_Y.
\end{align}
We define $w^*=A^Tz^*$ and prove that it is a solution to the critical equations of $X$ given $u$. First we note that $f_i(w^*)=0$ for each $i$ by construction.  
By the chain rule, $\nabla g_i(z^*)=\nabla f_i (A^Tz^*) A^T$. Now we argue that for $c_X=\mathrm{codim}_{\CC^n}X$,
\begin{align}\label{eq:rankcoX}
    \mathrm{rank} \begin{bmatrix} (w^*-A^TAu)^T\\
    \nabla f_1(w^*)\\
     \vdots \\
     \nabla f_k(w^*)  
    \end{bmatrix}=c_X.
\end{align}
Note that because the $w^*$ is smooth in $X$, the last $k$ rows of the matrix in \Cref{eq:rankcoX} are of rank $c_X$. We need to see that $(w^*-A^TAu)^T$ lies in the row span of those $k$ rows. To begin with, we claim that the matrix $A^TA:\CC^n\to \CC^n$ is the complex orthogonal projection onto $V$. Let $V'=AV$ be the image of $V$ under $A$; this is the smallest linear space containing $Y$. In addition, one has $V=A^TV'$. Any element of $V$ can be written $A^Tv'$ for some $v'\in V'$, and $A^TA(A^Tv')=A^Tv'$, proving that $A^TA$ is a projection onto $V$. To see that it is a complex orthogonal projection, we have that $\overline{(A^TAv)}^T(A^TAu-u)$ equals $\overline{v}^TA^TAA^TAu-\overline{v}^TA^TAu$, since $A$ is real. This expression equals $0$ for any $v$, because $AA^T=I$.

It is not hard to see from \Cref{eq:gzstar} that $w^*-A^TAu$ lies in the span of $A^TA\nabla f_i (A^Tz^*)^T$, since $w^*=A^TAw^*$. In other words, the projection of $ \nabla f_i(w^*)^T$ onto $V$ span $w^*-A^TAu$. Then it suffices if we can show that $\nabla f_i(w^*)^T$ span the complex orthogonal complement of $V$. However, the defining equations $f_i$ of $X$ generate the real linear equations that define $V$, and their gradients span exactly the complex orthogonal complement of $V$. This means that $\nabla f_i(w^*)^T$ span the complex orthogonal complement. Finally, we can change $A^TAu$ to $u$ in \Cref{eq:rankcoX}, because $A^TAu$ is the complex orthogonal projection onto $V$, and $\nabla f_i(w^*)^T$ span $A^TAu-u$ by the above. 


For the other direction, let $w^*$ be a smooth point satisfying
\begin{align} \label{eq:fullrankcoX}
     f_i(w^*)=0~\mbox{ for all } i~\&~\mathrm{rank} \begin{bmatrix} (w^*-u)^T\\
    \nabla f_1(w^*)\\
     \vdots \\
     \nabla f_k(w^*)  
    \end{bmatrix}=c_X.
\end{align}
Then $(w^*-u)^T$ is a linear combination of the rows $\nabla f_i(w^*)$. Then $(w^*-u)^TA^T$ is a linear combination of $\nabla f_i(w^*)A^T$. Writing $z^*=Aw^*$ and recalling that this is smooth point of $Y$, we have that $(z^*-Au)^T$ is a linear combination of $\nabla g_i(z^*)$. Therefore,   
\begin{align}\label{eq:fullrankcoY}
    g_i(z^*)=0~\mbox{ for all } i~\&~ \mathrm{rank} \begin{bmatrix} (z^*-Au)^T\\
    \nabla g_1(z^*)\\
     \vdots \\
     \nabla g_k(z^*)  
    \end{bmatrix}=c_Y,
\end{align}
are all satisfied.
\end{proof}

In the theorem below we use the relation between $\mathcal{C}$ and $\widetilde{\mathcal{C}}$ and $\widehat{\mathcal{C}}$ from \Cref{thm:anchoredmulti_isomorphism}.

\begin{theorem}\label{thm:EDbij}  Let $U_i\subseteq \PP^{2}$ be affine patches and write $U=U_1\times \cdots\times U_m$. Fix real matrices $A_i:\CC^2\to \CC^1$ such that $A_iA_i^T=I$. Let $A:(\CC^2)^m\to \CC^m$ be the map that sends $(x_1,\ldots,x_m)$ to $(A_1x_1,\ldots,A_mx_m)$. Let $u\in (\RR^2)^m$ and assume that we are given real cameras.
\begin{enumerate}
    \item Write $L_i=\{x\in \PP^2:x\in C_i\cdot L\}$, $V_i=A_i(U_i\cap L_i)$, assume $V_i=\CC$ and let $V=V_1\times\cdots\times V_m$. If $y^*$ is a critical point of the ED problem for $\mathcal{M}_{\widetilde{\mathcal{C}}}^{1,1}$ (in the affine patch $V$) given $Au$, then $x^*=A^Ty^*$ is a critical point of the ED problem for $\mathcal{M}_\mathcal{C}^L$ (in the affine patch $U$) given $u$;
    \item Write $V_i=A_i(U_i\cap \Lambda(C_iX))$, assume $V_i=\CC$ and let $V=V_1\times\cdots\times V_m$. If $y^*$ is a critical point of the ED problem for $\mathcal{M}_{\widehat{\mathcal{C}}}^{2,1}$ (in the affine patch $V$) given $Au$, then $x^*=A^Ty^*$ is a critical point of the ED problem for $\mathcal{L}_\mathcal{C}^X$ (in the affine patch $U$) given $u$. 
\end{enumerate}
In both cases, this is a bijection of critical points.
\end{theorem}


Note that the requirement that $V_i=\CC$ can easily be achieved by a good choice of $A_i$.

\begin{proof} We first use \Cref{thm:anchoredmulti_isomorphism} to see that the multiview varieties from 1. and 2. are linearly isomorphic. More precisely, we set $\phi_{\mathcal{C},i}=A_i$ and note that the linear isomorphism restricted to $U$ map onto $V$, which is enough. Then directly apply \Cref{prop:EDbij}.
\end{proof}

\section{Euclidean Distance Degree Preliminaries}\label{s:EDDprelim}

The main theorem of this article is:

\begin{customtheorem}{\ref{thm:EDDthm}}  $ $  

\begin{enumerate}
    \item For a generic arrangement of $m\ge 2$ cameras, $\mathrm{EDD}( \mathcal{M}_\mathcal{C}^L)=3m-2 $;
    \item For a generic arrangement of $m\ge 3$ cameras, $\mathrm{EDD}( \mathcal{L}_\mathcal{C}^X)=\frac{9}{2}m^2-\frac{19}{2}m+3.$
\end{enumerate}
\end{customtheorem}

In order to compute these two Euclidean distance degrees we make use of the following theorem:

\begin{theorem}[Theorem 3.8 of \cite{EDDegree_point}]
Let $X\subseteq \CC^n$ be a smooth variety and let $U_{\beta}$ denote the complement of the hypersurface $\sum_{1\leq i\leq n}(z_{i}-\beta_{i})^2+\beta_{0}=0$ in $\mathbb C^n$ where $z\in\mathbb C^n$ and $\beta\in\mathbb C^{n+1}$. Then,
\begin{align}
    \mathrm{EDD}(X)=(-1)^{\operatorname{dim} X}\chi(X\cap U_{\beta}).
\end{align}
\end{theorem}

Here $\chi$ is the topological Euler characteristic. In the next section we closely follow \cite{EDDegree_point}, by specializing their techniques to our setting in \Cref{s:EDD}. First we provide the reader with helpful preliminaries. We include many details that are necessary to understand the proof, but not all. We often take this section for granted and not refer to specific results from it. 

We have verified with numerical evidence for a number of values of $m$ that these formulas hold. The code is included in the repository \url{github.com/amtorresbu/Anchored_LMV.git}.

\subsection{The Euler characteristic} 

There are different approaches to defining the Euler characteristic of a topological space. References to the broader topic of algebraic topology include \cite{may1999concise,hatcher2005algebraic}. For instance, given a \textit{triangulation} of a topological space, the Euler characteristic is the alternating sum
\begin{align}
    k_0-k_1+k_2-\ldots,
\end{align}
where $k_i$ is the number of simplices of dimension $i$. An \textit{$n$-simplex} is a polytope of dimension $n$ with $n+1$ vertices, and a \textit{triangulation} is essentially a way of writing a space as a union of simplices that intersect in a good way. Importantly, all real and complex algebraic varieties can be triangulated \cite{hofmann2009triangulation} with respect to Euclidean topology.

The Euler characteristic can more generally be defined for CW complexes and any topological space through singular homology. For spaces where all definitions apply, they are the same.
\begin{lemma}[{\hspace{1sp}\cite[Section 2]{cappell2008euler}}]\label{le:Eul1} Let $N,M$ be subvarieties of a complex variety. Then,
\begin{align}
\begin{aligned}
\chi(M\setminus N)&=\chi(M)-\chi(M\cap N),\\
    \chi(M\cup N)&=\chi(M)+\chi(N)-\chi(M\cap N).
    \end{aligned}
\end{align}

\end{lemma}
The above does not hold over the real numbers. For instance, $\chi(\RR)=1$, while $\chi(\{x\})=1$ and $\chi(\RR\setminus \{x\})=2$.

\begin{lemma}[{\hspace{1sp}\cite[Section 2.1]{hatcher2005algebraic}}]\label{le:Eul2} Let $f:X\to Y$ be a homeomorphism, such as an isomorphism between varieties, then 
\begin{equation}
    \chi(X)=\chi(Y).
\end{equation}
\end{lemma}

\begin{lemma}[{\hspace{1sp}\cite[Chapter 10, Section 1]{may1999concise}}]\label{le:Eul3} The Euler Characteristic of $\PP^n$ is $n+1$.  
\end{lemma}


\subsection{Chow rings}\label{ss:Chow}

We refer to \cite{fulton2013intersection,eisenbud-harris:16} for a thorough treatment of intersection theory, and \cite{Fulvio21notes} for a friendly introduction. Here we recall the basic definitions and results that are needed to understand this material. 


Let $X$ be a variety. We denote by $Z(X)$ the
free abelian group of formal integral linear combinations of irreducible subvarieties of $X$. An \textit{effective cycle} is a formal sum $\sum n_i Y_i$ of irreducible subvarieties $Y_i$ with $n_i\ge0$. A \textit{zero-cycle} is a formal sum of zero dimensional varieties $Y_i$. The \textit{degree} of a zero-cycle is the sum of the associated integers $n_i$ as in \cite[Definition 1.4]{fulton2013intersection}. We say that two irreducible subvarieties $Y_0, Y_\infty \in Z( X)$ are \textit{rationally equivalent}, and write $Y_0\sim Y_\infty$ or $Y_0\equiv Y_\infty$ if there exists
an irreducible variety $W \subseteq   X \times\PP^1$, whose projection onto $\PP^1$ is dense, such that $W \cap ( X \times  \{0\}) = Y_0$ and $W \cap  (X \times \{\infty\}) = Y_\infty$. Here $0\in \PP^1$ refers to the point $(1:0)$ and $\infty\in \PP^1$ is $(0:1)$.

The Chow group of $X$ is
\begin{align}
    \mathrm{CH}( X) = Z( X)/\sim.
\end{align}
For a subvariety, $Y \subseteq   X$, write $[Y]$ for the class in $\mathrm{CH}( X)$ of its associated effective cycle. We now aim to turn this group into a ring, by giving it a multiplicative structure.


Let $X$ be an irreducible variety and let $Y_1, Y_2$ be subvarieties. $Y_1$ and $Y_2$ \textit{intersect transversely} at $p \in Y_1 \cap Y_2$ if $Y_1, Y_2$ and $X$ are smooth at $p$ and
$T_pY_1 + T_pY_2 = T_pX$. Further, $Y_1$ and $Y_2$ are \textit{generically transverse} if they intersect transversely at generic points of every irreducible component of the intersection $Y_1 \cap Y_2$. In particular, if the intersection is empty, then they intersect transversally.



\begin{theorem}\label{thm:prod} Let $ X$ be a smooth variety. Then there is a unique product structure on $\mathrm{CH}( X)$
such that whenever $A, B$ are generically transverse subvarieties of $X$, then $[A][B] = [A \cap B]$.
This product makes $\mathrm{CH}( X)$ into a graded ring, where the grading is given by codimension.
\end{theorem}

A natural example of Chow rings are those of products of projective space,
\begin{align}
    \mathrm{CH}((\PP^n)^s)\cong \ZZ[[H_1],\ldots,[H_s]]/\langle [H_1]^{n+1},\ldots,[H_s]^{n+1}\rangle.
\end{align}
In the above ring isomorphism, $[H_i]$ represent the class of a hyperplane in $\mathrm{CH}(\PP^n)$ in factor $i$.

For a morphism of smooth varieties $f:X\to Y$, there are two corresponding ring maps between Chow rings, the \textit{pushforward} $f_*:\mathrm{CH}(X)\to \mathrm{CH}(Y)$ and the \textit{pullback} $f^*:\mathrm{CH}(Y)\to \mathrm{CH}(X)$. 

We define the pushforward on irreducible subvarieties $A\subseteq X$ by setting 
\begin{align}
    f_*(A):=\begin{cases}0 & \textnormal{if the generic fiber of }f|_A \textnormal{is infinite},\\
    d[f(A)] & \textnormal{if the generic fiber of }f|_A\textnormal{has cardinality }d.\end{cases}
\end{align}
By \textit{generic fiber} above we mean $f|_A^{-1}(y)$ for generic $y\in f(A)$.

We say that $A\subseteq Y$ is \textit{generically transverse} to $f$ if $f^{-1}(A)$ is generically reduced and the codimension of $f^{-1}(A)$ in $X$ equals the codimension of $A$ in $Y$. The pullback $f_*$ is defined as the unique map $\mathrm{CH}(Y) \to \mathrm{CH}(X)$ such that, if $A \subseteq Y$ is generically transverse to $f$, then $f^*[A] := [f^{-1}(A)]$. There is such a unique map by \cite[Theorem 1.23]{eisenbud-harris:16}.


\subsection{Chern classes}\label{ss:Chern} In intersection theory, Chern classes are algebraic invariants of a variety that lie in its Chow ring. General references again include \cite{fulton2013intersection,eisenbud-harris:16}. Here we only state the properties of them that we use.

Chern classes $c(E)$ are in general defined for vector bundles $E$, but when the vector bundle is the tangent bundle of a smooth variety $X$, then we write $c(X)$ for the total Chern class. 

\begin{lemma}[Whitney Sum Formula {\cite[Theorem 3.2]{fulton2013intersection}}] For a short exact sequence $0\to E'\to E\to E''\to 0$ of vector bundles on a variety $X$, we have for the total Chern classes that
\begin{align}
    c(E)=c(E')c(E'').
\end{align}
\end{lemma}

By a \textit{divisor} of $X$ we mean a subvariety of codimension 1. Let $i: A\hookrightarrow X$ be the inclusion map for a subvariety $A\subseteq X$. For an element $[V]\in \mathrm{CH}(X)$, the restriction $[V]|_A$ denotes the pullback $i^*[V]$. If $V$ is generically transverse to $i$, then $[V]|_A=[V\cap A]$. We observe that $[V]|_A[U]|_A$ equals $i^*[V]i^*[U]$ and since $i^*$ is a ring homorphism, this equals $i^*([V][U])=([V][U])|_A$.

\begin{lemma}[Adjunction Formula {\cite[Example 3.2.11]{fulton2013intersection},\cite[Theorem 5.3]{eisenbud-harris:16}}] If $X$ is smooth variety and $D$ a smooth divisor on $X$, then 
\begin{align}
    c(D)=\frac{c(X)|_D}{(1+[D])|_D}.
\end{align}
\end{lemma}


\begin{lemma}[Functoriality {\cite[Theorem 5.3]{eisenbud-harris:16}}] Let $f:X\to Y$ be morphism of smooth varieties, then 
\begin{align}
    f^*c(E)=c(f^*E),
\end{align}
for vector bundles $E$ on $Y$.
\end{lemma}
By putting $E$ to be the tangent bundle of $Y$, its pullback equals $X$ if $f$ is an isomorphism, which we make precise below.

\begin{lemma} Let $f:X\to Y$ be an isomorphism, then 
\begin{align}
    c(X)=f^*c(Y).
\end{align}
\end{lemma}

\begin{lemma}[{\hspace{1sp}\cite[Example 3.2.11]{fulton2013intersection}}]\label{le:ChernP} Let $[H]$ be the class of a hyperplane of $\PP^n$. Then we have
\begin{align}
    c(\PP^n)=(1+[H])^{n+1}.
\end{align}
\end{lemma}


The \textit{top} Chern class $c_{\mathrm{top}}(X)$ of $X$ is the zero-cycle part written of $c(X)\in \mathrm{CH}(X)$.

\begin{theorem}[Chern-Gauss-Bonnet {\cite[Section 3.3]{griffiths2014principles}}]\label{thm:CGB} For a smooth variety $X$, we have
\begin{align}
    \chi(X)=\deg(c_{\mathrm{top}}(X)).
\end{align}
\end{theorem}

It happens that authors use the integration symbol for the degree of a zero-cycle $[Z]$ in $X$ in the follows sense,
\begin{align}
 \int_{X}[Z]:=\deg(Z).
\end{align}
More generally let $[Z]$ a formal sum of irreducible subvarieties of $X$ of codimension $k$. Consider the inclusion $i:A\hookrightarrow X$ for a $k$-dimensional $A$. We get the following,
\begin{align}
 \int_{A}[Z]|_A=\int_A i^*[Z]=\int_X [Z][A],
\end{align}
where we assume that $i^{-1}(Z)$ is a $0$-dimensional.

Next we consider Chern classes of blow-ups. First some notation. Let $X\subseteq Y$ be an inclusion of smooth varieties. Let $\Tilde{Y}$ be the blow-up of $Y$ at $X$. Let $\Tilde{X}$ be the exceptional locus. Let $\pi,\rho$ be the projection maps and $j,i$ the inclusion maps. The following diagram commutes, 
\begin{equation}\label{eq:diagram} \begin{tikzcd}
\Tilde{X} \arrow{r}{j} \arrow[swap]{d}{\rho} & \Tilde{Y}  \arrow{d}{\pi} \\
X \arrow{r}{i}& Y
\end{tikzcd}.
\end{equation}
Porteus' formula \cite[Theorem 15.4]{fulton2013intersection} gives a formula for the Chern class of $\Tilde{Y}$ in terms of the Chern classes of $X$ and $Y$. For our purposes, we only need the following special case of this theorem, which follows from \cite[Example 15.4.2]{fulton2013intersection} as stated in \cite{EDDegree_point}. 

\begin{theorem} In \Cref{eq:diagram}, let $X$ be a set of $m$ disjoint points $X_i$. Then 
\begin{align}
c(\Tilde{Y})=\pi^*c(Y)+\sum_{i=1}^m(1+\eta_i)(1-\eta_i)^d-1,
\end{align}
where $d=\dim Y$ and $\eta_i=j_*(\rho^*[X_i])$.
\end{theorem}

\subsection{Line bundles \& Linear systems} We recall basic definition and state Bertini's theorem. An introduction to line bundles and other relevant concepts are given in the lecture notes of Vakil \cite{vakil1999introduction}. For a rational function $s$ on a projective variety $X$, we define $(s)=\sum \mathrm{ord}_Z(s) Z\in \mathrm{CH}(X)$, where $\mathrm{ord}_Z(s)$ is the order of $s$ at the irreducible hypersurface $Z$ \cite[Chapter II, Section 6]{hartshorne2013algebraic}. Two divisors $D,D'$ are \textit{linearly equivalent} if $D'= D+(s)$ for some rational function $s$.

\begin{definition} Let $X$ be a smooth variety. A \textnormal{complete linear system} $|D_0|$ of an effective divisor $D_0$ ($\sum n_iD_i$ so that $n_i\ge 0$) is the set of all effective divisors linearly equivalent to it. A \textnormal{linear system} is a linear subspace of a complete linear system.
\end{definition}

\begin{definition} Let $D_0$ be an effective divisor. $\Gamma(X,\mathcal{O}(D_0))$ is the set of rational functions $s$ on $X$ with $(s)+D_0\ge 0$, called \textnormal{global sections}.
\end{definition}

 $\Gamma(X,\mathcal{O}(D_0))$ is interpreted as a complete linear system via the map $f\mapsto (f)+D_0 \in \mathrm{CH}(X)$. Since $(f)=(g)$ if and only if they differ by a non-zero scalar (zeros and poles determine a rational function), $\Gamma(X,\mathcal{O}(D_0))$ can be viewed as a projective space. Linear subspaces of $\Gamma(X,\mathcal{O}(D_0))$ are also called linear systems.

The \textit{base locus} of a linear system is the intersection of the set zero set of all global sections on $X$ of the linear system. A linear system is \textit{basepoint free} if the base locus is empty. In other words, for every point  $x\in X$ there is a global section $s$ such that $s(x)\neq 0$. 

We say that a linear system of a divisor $D_0$ in $X$ is \textit{very ample} if there are global section $s_0,\ldots,s_n$ in $\Gamma(X,\mathcal O(D_0))$ that do not vanish simultaneously and the map 
\begin{align}\label{eq:vample}
    [s_0:\cdots:s_n]:X\to \PP^n,
\end{align}
is isomorphic onto its image. If this holds, we also say that the divisor $D_0$ is \textit{very ample}. 
\begin{lemma}\label{le:basepoint_free} Let $Y\subseteq X$ be an inclusion of smooth complex irreducible projective varieties. Let $D$ be a divisor of $X$ such that $D\cap Y$ is a divisor of $Y$. If $D$ is very ample, then $D\cap Y$ is very ample. 
\end{lemma}

\begin{proof}[Sketch of Proof] 
For $D$, choose global sections $s_i$ as in \Cref{eq:vample}. The restriction of these global sections $s_i|_Y$ to $Y$ gives us global sections of $Y$. Then 
\begin{align}
 [s_0|_Y:\cdots:s_n|_Y]:Y\to \PP^n,
\end{align}
must also be an isomorphism onto its image.
\end{proof}

One important application of basepoint free linear systems come in the form of this celebrated result: 

\begin{theorem}[Bertini's Theorem {\cite[Section 1.1]{griffiths2014principles}}]\label{thm:Bertini} 
Let $X$ be a smooth complex variety and let $\Gamma$ be a positive dimensional linear system
on $X$. Then the general element of $~\Gamma$ is smooth away
from the base locus.
\end{theorem}


\subsection{Whitney stratification}\label{ss:Whitney} 

A natural way to partition a variety $X$ is via the inclusion
\begin{align}
    X\supseteq \mathrm{sing}(X)\supseteq \mathrm{sing}(\mathrm{sing}(X))\supseteq \cdots,
\end{align}
where $\mathrm{sing}$ denote the singular locus. However, not all points of $\mathrm{sing}(X)\setminus \mathrm{sing}(\mathrm{sing}(X))$ necessarily look locally the same. A more fine grained version of this partition is called \textit{Whitney stratification} \cite{trotman2020stratification}. We don't state the definition here, because all we need to know is that a Whitney stratification of a smooth variety $X$ is $\mathcal{S}=\{X\}$ and the Whitney stratification of a variety $X$ whose singular locus is a finite set of point is $\mathcal{S}=\{X_{\mathrm{reg}},\{s_1\},\ldots,\{s_r\}\}$, where $X_{\mathrm{reg}}$ is the set of smooth points of $X$ and $s_1,\ldots,s_r$ are the singular points of $X$. By a theorem of Whitney, any algebraic variety has a Whintey stratification \cite{whitney1992local,whitney1992tangents}. 


Before we state the main theorem on Whitney stratifications that we use in this article, we define \textit{Milnor fibers} \cite[Chapter 10]{maxim2019intersection}. Let $X$ be a smooth variety and $V$ a divisor on $X$. Choose any Whitney stratum $S \in \mathcal S$ and any point $x \in S$. In a
sufficiently small ball $B_{\epsilon,x}$ centered at $x$, the hypersurface $V$ is equal to the zero locus of a holomorphic function $f$. The Milnor fiber of $V$ at $x \in  S$ is given by
\begin{align}   
F_x:=B_{\epsilon,x} \cap {f = t},
\end{align}
for small $|t|$ greater than 0. The Euler characteristic of $F_x$ is independent of the choice 
of the local equation $f$ at $x$, and it is constant along the given stratum containing $x$.

\begin{theorem}[{\hspace{1sp}\cite{parusinski1995formula},\cite[Theorem 10.4.4]{maxim2019intersection}}] \label{thm:Whitney} Let $X$ be a smooth complex projective variety,
and let $V$ be a very ample divisor in $X$. Let $V=\sqcup_{s\in \mathcal{S}} S$ be a Whitney stratification
of $X$. Let $W$ be another divisor on $X$ that is linearly equivalent to $V$. Suppose $W$ is
smooth and $W$ intersects $V$ transversally in the stratified sense (with respect to the above
Whitney stratification). Then we have
\begin{align}
    \chi(W)-\chi(V)=\sum_{S\in \mathcal S} \mu_S \chi(S\setminus W), 
\end{align}
where $\mu_S$ is the Euler characteristic of the reduced cohomology of the Milnor fiber at any
point $x \in S$.
\end{theorem}

The Euler characteristic of the \textit{reduced cohomology} is the normal Euler characteristic minus one.

\section{Computation of Euclidean Distance Degrees}\label{s:EDD} 

Let $X\in \PP^3$ be a point and $L\in \Gr(1,\PP^3)$ a line. Let $\mathcal
C$ be a generic arrangement of $m$ cameras. For the sake of notation we write $\mathcal M_m^L$ for $\mathcal{M}_\mathcal{C}^L$ and $\mathcal{L}_m^X$ for $\mathcal{L}_\mathcal{C}^X$. We assume from now on that $m\ge 3$ for the anchored line multiview variety $\mathcal{L}_m^X$. We recall notation from \cite{EDDegree_point}. Write each $\PP^2$ as $\CC^2 \cup\PP_\infty^1$, where $\CC^2$ is the chosen affine chart and $\PP_\infty^1$ is the line at
infinity. Denote the hypersurface $\PP^2\times \cdots\times \PP_\infty^1\times \cdots\times \PP^2$ in $(\PP^2)^m$ by $H_{\infty,i}$, where $\PP_\infty^1$ is the $i$-th factor. Let $H_\infty=\cup_{i=1}^m H_{\infty,i}$. Denote by $H_Q$ the closure of the
hypersurface $\sum_{i=1}^{2m}(z_i - \beta_i)^2+\beta_0=0$ in $(\PP^2)^m$. In the remaining of this proof, we will
use the following notations:
\begin{equation}
    D_Q^L \coloneqq \mathcal{M}_m^L \cap  H_Q, \qquad D_{\infty,i}^L \coloneqq \mathcal{M}_m^L \cap H_{\infty,i}, \qquad
    D_\infty^L \coloneqq \mathcal{M}_m^L\cap H_{\infty},
\end{equation}
for the anchored point multiview variety, and
\begin{equation}
    D_Q^X \coloneqq \mathcal{L}_m^X \cap  H_Q, \qquad D_{\infty,i}^X \coloneqq \mathcal{L}_m^X \cap H_{\infty,i}, \qquad
    D_\infty^X \coloneqq \mathcal{L}_m^X\cap H_{\infty},
\end{equation}
for the anchored line multiview variety. Write $M_m^L$ and $L_m^X$ for the corresponding affine varieties. Notice that $H_\infty$ is the complement of the affine chart $\CC^{2m}$ in $(\PP^2)^m$, thus $D_\infty^L$ is the
complement of $M_m^L$ in $\mathcal{M}_m^L$ and $D_\infty^X$ is the
complement of $L_m^X$ in $\mathcal{L}_m^X$ and.
As derived in \cite{EDDegree_point}, we have,
\begin{equation}\label{eq:eulML1}
    \chi(M_m^L\cap U_\beta)=
    \chi(\mathcal M_m^L)-\chi(D_\infty^L)+\chi(D_Q^L\cap D_\infty^L)-\chi(D_Q^L), 
\end{equation}
\begin{equation}\label{eq:eulLX1}
    \chi(L_m^X\cap U_\beta)= \chi(\mathcal{L}_m^X)-\chi(D_\infty^X)+\chi(D_Q^X\cap D_\infty^X)-\chi(D_Q^X).
\end{equation}
The structure of the proof of \Cref{thm:EDDthm} is to calculate the four terms of \Cref{eq:eulML1,eq:eulLX1}. 

\begin{lemma}\label{lem:anchored_chiY_n} For a fixed $X$ and $L$, let $\mathcal{C}$ be a generic arrangement of $m$ cameras.


\begin{enumerate}
    \item $\chi(\mathcal{M}_\mathcal{C}^L)=2$;
    \item $\chi(\mathcal{L}_\mathcal{C}^X)=3+m$.
\end{enumerate}
\end{lemma}

\begin{proof} $ $

$1.$ $\mathcal{M}_\mathcal{C}^L$ is isomorphic to $\PP^1$ and we are done by \Cref{le:Eul3}.

$2.$ Recall that we here assume $m\ge 3$. By genericity, $c_i$ are not collinear. Therefore the back-projected planes of an element $\ell\in \mathcal{L}_\mathcal{C}^X$ meet in exactly a line. Consider the partition 
\begin{align}\mathcal{L}_\mathcal{C}^X= U\cup \bigcup_{i=1}^m U_i,
\end{align}
where $U$ is the set of $\ell\in \mathcal{L}_\mathcal{C}^X$ whose back-projected planes meet in a line away from any center, and $U_i$ is the set of $\ell\in \mathcal{L}_\mathcal{C}^X$ whose back-projected planes meet in $c_i\vee X$. By \Cref{le:Eul1}, $\chi(\mathcal{L}_\mathcal{C}^X)=\chi(U)+\sum \chi(U_i)$. Since $\Upsilon_\mathcal{C}$ is injective on the subset of $\Lambda(X)\setminus\cup ( c_i\vee X)$, we see via the isomorphism $U\cong \PP^2$ that $U$ is isomorphic to $\PP^2$ minus $m$ points. By \Cref{le:Eul2}, $\chi(U)=3-m$. If instead $\ell\in \mathcal{L}_\mathcal{C}^X$ meet exactly in $c_i\vee X$, then for $j\neq i$ we have $\ell_j=C_j\cdot (c_i\vee X)$, and $\ell_i$ is any line in $\Lambda(C_iX)$. However, $\Lambda(C_iX)\cong \PP^1$, implying $\chi(U_i)=2$. In total, $\chi(\mathcal{L}_\mathcal{C}^X)=3-m+2m=3+m$.
\end{proof}

\begin{lemma}\label{lem:anchored_chiDinfty} For a fixed $X$ and $L$, let $\mathcal C$ be a generic arrangement of cameras of $m$ cameras.


\begin{enumerate}
    \item $\chi(D_\infty^L)=m$;
    \item $\chi(D_\infty^X)=2m-\binom{m}{2}$.
\end{enumerate}
\end{lemma}



\begin{proof} $ $

$1.$ Each $D_{\infty, i}^L$ is a generic point of $\mathcal{M}_m^L$. By additivity of the Euler characteristic we have that 
\begin{align}
    \chi(D_{\infty}^L)=\chi(\cup_{i=1}^m D_{\infty, i}^L) =\sum _{i=1}^m\chi( D_{\infty, i}^L)=  m.
\end{align}

$2.$ Each $D_{\infty, i}^X$ is a curve inside $\mathcal{L}_m^X$, it corresponds precisely to fixing the $i$-th back-projected plane $H_i$ to be generic through $c_i$ and $X$. Such a plane contains no other center, and a line in this plane uniquely determines all other back-projected planes. Therefore $D_{\infty, i}^L$ is isomorphic to the set of lines in $H_i$ through $X$, which in turn is isomorphic to $\mathbb{P}^1$. We get $\chi(D_{\infty,i}^X) = 2$. Moreover, $D_{\infty,i}^X$ only have pairwise intersections with each other, and two generic back-projected planes $H_i,H_j$ through $c_i,X$ and $c_j,X$ respectively meet in exactly a generic line through $X$. This intersection is a single point. We then get
\begin{equation}
    \begin{split}
        \chi(D_\infty^X)&=\chi(\cup_{i=1}^m D_{\infty,i}^X) \\
        &=\sum_{i=1}^m \chi( D_{\infty,i}^X) - \sum_{i<j} \chi\left( D_{\infty,i}^X \cap D_{\infty,j}^X \right) \\
        &= \sum_{i=1}^m 2 - \sum_{i<j} 1 =  2m - \binom{m}{2},
    \end{split}
\end{equation}
by additivity.
\end{proof}
We recall that $H_Q$ is the closure of the affine hypersurface
\begin{align}\label{eq:quad}
 \sum_{1\le i\le 2m}
(z_i-\beta_i)^2+ \beta_0 = 0,
\end{align}
in $(\PP^2)^m$. We introduce homogeneous coordinates $x_i, y_{2i-1}, y_{2i}$ with $z_{2i-1} =y_{2i-1}/x_i$ and $z_{2i} =y_{2i}/x_i$ for $1\le i\le m$. Write $\textbf{x}=x_1\cdots x_m$. Then the homogenization of \Cref{eq:quad}, and hence the equation of
$H_Q$, is
\begin{equation}\label{eq:homog1}
   \sum_{i=1}^m \Big((y_{2i-1}- \beta_{2i-1}x_i)^2
 + (y_{2i}- \beta_{2i}x_i)^2\Big)\frac{\textbf{x}^2}{x_i^2}+\beta_0 \textbf{x}^2=0. 
\end{equation}


\begin{lemma}
\label{lem:achored_chiDinftycapDQ}
$ $
\begin{enumerate}
    \item $\chi(D_Q^L\cap D_\infty^L)=0$;
    \item $\chi(D_Q^X\cap D_\infty^X)=\binom{m}{2}$.
\end{enumerate}

\end{lemma}

\begin{proof} We assume without loss of generality that $H_{\infty,i}$ is defined by the equation $x_i=0$. We have by inspection of \Cref{eq:homog1} that
\begin{equation}
    H_Q\cap H_{\infty,i}=\{y_{2i-1}+\sqrt{-1}y_{2i}=x_i=0\}\cup\{y_{2i-1}-\sqrt{-1}y_{2i}=x_i=0\}\cup \bigcup_{j\neq i}\{x_i=x_j=0\}.
\end{equation}	
Let
\begin{align*}
    	K_i^{L,+}:= &\mathcal{M}_m^L \cap \{y_{2i-1}+\sqrt{-1}y_{2i}=x_i=0\},\\
		K_i^{L,-}:= &\mathcal{M}_m^L \cap \{y_{2i-1}-\sqrt{-1}y_{2i}=x_i=0\}, \\
		A_{i,j}^L:= &\mathcal{M}_m^L \cap \{x_i=x_j=0\}, j\neq i,
\end{align*}
and write $K_i^{X,+},K_i^{X,-}$ and $A_{i,j}^X$ analogously for intersecting with $\mathcal{L}_m^X$ instead of $\mathcal{M}_m^L$. With this notation,
\begin{align}
    \mathcal{M}_m^L\cap H_Q\cap H_{\infty,i}=K_i^{L,+} \cup K_i^{L,-} \cup \bigcup_{i\neq j} A_{i,j}^L,\\
      \mathcal{L}_m^X\cap H_Q\cap H_{\infty,i}=K_i^{X,+} \cup K_i^{X,-} \cup \bigcup_{i\neq j} A_{i,j}^X.
\end{align}
As we shall see below, $K_i^{L,\pm},K_i^{X,\pm}=\emptyset$. Therefore, 
\begin{align}
    \chi(D_Q^L\cap D_\infty^L)&=\chi(\bigcup_{i\neq j} A_{i,j}^L),\label{eq:AijL}\\
    \chi(D_Q^X\cap D_\infty^X)&=\chi(\bigcup_{i\neq j} A_{i,j}^X).\label{eq:AijX}
\end{align}

$1.$ By construction, the $i$-th factor of any element of $K_i^{L,\pm}\subseteq (\PP^2)^m$ is fixed equal to $[0:\mp\sqrt{-1}:1]$. However, by genericity, this point does not lie in $C_i\cdot L$, implying that $K_i^{L,\pm}=\emptyset$. Regarding $A_{i,j}^L$, setting $x_i=0,x_j=0$ corresponds to fixing two generic image lines in the corresponding image planes. The back-projected planes meet in a generic line, and such a line does not meet $L$. This implies $A_{i,j}^L=\emptyset$, and we are done by \Cref{eq:AijL}.


$2.$ By construction, the $i$-th factor of any element of $K_i^{X,\pm}\subseteq (\PP^2)^m$ is fixed equal to $[0:\mp\sqrt{-1}:1]$. However, by genericity, this line does not contain $C_iX$, implying that $K_i^{X,\pm}=\emptyset$. Regarding $A_{i,j}^X$, setting $x_i=0,x_j=0$ corresponds to fixing two generic image lines in the corresponding image planes. These intersect $\Lambda(C_iX),\Lambda(C_jX)$ in two points, $\ell_i,\ell_j$. Their back-projected planes meet in a generic line through $X$. Therefore $A_{i,j}^X$ is a generic point of $\mathcal{L}_m^X$, and all $A_{i,j}^X$ are disjoint, and we are done by \Cref{eq:AijX}.\end{proof}

The only terms left to calculate from \Cref{eq:eulML1,eq:eulLX1} are $\chi(D_Q^L)$ and $\chi(D_Q^X)$. These are more difficult. As we aim to use \Cref{thm:Whitney}, we need to find appropriate smooth divisors and calculate their Euler characteristics.


In $(\PP^2)^m$, the hypersurface $H_Q$ is defined by \Cref{eq:homog1}. It follows from \Cref{ss:Chow} that we have the linear equivalence of divisors in $(\PP^2)^m$
\begin{align}
    H_Q\equiv 2H_{\infty,1}+\cdots +2H_{\infty,m}.
\end{align}
Then as divisors of the anchored multiview varieties,
\begin{align}
    D_Q^L&\equiv 2 \mathcal{M}_m^L\cap H_{\infty,1}+\cdots+2 \mathcal{M}_m^L\cap H_{\infty,m},\\
    D_Q^X&\equiv 2 \mathcal{L}_m^X\cap H_{\infty,1}+\cdots+2 \mathcal{L}_m^X\cap H_{\infty,m}.
\end{align}
Consider the well-defined projections $\pi_L:\mathcal{M}_m^L\to L$, and $\pi_X: \mathcal{L}_m^X\to \Lambda(X)$, sending image points and image lines to the intersection of their back-projected lines or planes. In the Chow ring of $\PP^3$, every element of $L$ is equivalent. We denote by $D_H^L$ the preimage of a generic hyperplane in $L$, i.e. a generic point of $L$. In the Chow ring of $\Gr(1,\PP^3)$, every element of $\Lambda(X)$ is equivalent. In particular, we have $\pi_X^*[H]=\pi_X^*[H']$, where $H,H'$ are the set of lines in some hyperplane through $X$ in $\PP^3$. So let $H$ be a generic plane of lines in $\Lambda(X)$, write $D_H^X=\pi_X^{-1}(H)$, and let $H'$ be the plane of lines in $\Lambda(X)$ that contains $c_i$ and corresponds to the the affine patch $H_{\infty,i}$. As a subvariety of $\mathcal L_m^X$, $\pi_X^{-1}(H')$ is the union of $\mathcal{L}_m^X\cap H_{\infty,i}$ and the variety $E_i^X$ of elements $\ell$ whose back-projected planes meet exactly in the line $c_i\vee X$. In other words, $E_i^X=\pi_X^{-1}(c_i\vee X)$. We get
\begin{align} 
\mathcal{M}_m^L\cap H_{\infty,i}&\equiv D_H^L.\\
E_i^X+\mathcal{L}_m^X\cap H_{\infty,i}&\equiv D_H^X.
\end{align}
It follows that,
\begin{align}\label{eq:Dqx}
\begin{aligned}
D_Q^L&\equiv 2mD_H^L,\\
    D_Q^X&\equiv 2mD_H^X-2E_i^X-\cdots -2E_i^X.
\end{aligned}
\end{align}

\begin{lemma}\label{le:ChowID} $ $

\begin{enumerate}
    \item $[D_H^L]^2=0$;
    \item $[E_i^X]^3=0$;
    \item $[D_H^X]^3=0$;
    \item $[D_H^X][E_i^X]=0$ for $i\neq j$;
    \item $[E_i^X][E_j^X]=0$ for $i\neq j$.
\end{enumerate}
\end{lemma}

\begin{proof} $ $

$1,2,3.$ This is a consequence of the fact that $D_H^L$ is a proper subvariety of an irreducible variety of dimension 1. Similary, both $E_i^X$ and $D_H^X$ are proper subvariety of an irreducible variety of dimension 2.

$4.$ For a generic plane of lines $H$ through $X$, $D_H^X\cap E_i^X$ is empty. This suffices by \Cref{thm:prod}. 

$5.$ We use the fact that $E_j^X\equiv D_H^X-\mathcal{L}_m^X\cap H_{\infty,j}$. By $4.$, intersecting the right-hand side with $E_i^X$ leaves $E_i^X\cap (L_m^X\cap H_{\infty,j})$. Now the $j$-th image line in $\mathcal L_m^X\cap H_{\infty,j}$ is a fixed generic line through $C_iX$. It follows that the intersection must be empty. This suffices by \Cref{thm:prod}. 
\end{proof}

To calculate the needed Euler characteristics, we use the Chern-Gauss-Bonnet theorem, \Cref{thm:CGB}. In this direction we calculate Chern classes:

\begin{proposition}\label{prop:Chow} In the chow ring of $(\PP^2)^m$, we have the following identities.
\begin{enumerate}
    \item  \label{eq:chernM}
        $c(\mathcal{M}_m^L)=1+2[D_H^L]$;
         
    \item \label{eq:chernL} $
        c(\mathcal{L}_m^X)=(1+[D_H^X])^3-\sum_{i=1}^m [E_i^X]+[E_i^X]^2.$
\end{enumerate}
\end{proposition}

As a sanity check, we note that this formula gives us the correct Euler characteristics. The top Chern class of $\mathcal{M}_m^L$ is $2[D_H^L]$, where $[D_H^L]$ is the class of a single point. The top Chern class of $\mathcal{L}_m^X$ is $3[D_H^X]^2+\sum -[E_i^X]^2$. Now $[D_H^X]^2$ correspond to the preimage of the intersection of two generic planes through $X$; it corresponds to a single point. Since $E_i^X\equiv D_H^X-\mathcal{L}_m^X\cap H_{\infty,i}$, we have that $[E_i^X]^2\equiv [D_H^X]^2-2[D_H^X\cap \mathcal{L}_m^X\cap H_{\infty,i}]+[\mathcal{L}_m^X\cap H_{\infty,i}]^2$. However, $[D_H^X\cap \mathcal{L}_m^X\cap H_{\infty,i}]$ is a single point and $(\mathcal{L}_m^X\cap H_{\infty,i})^2$ is empty. Therefore $[E_i^X]^2$ is equal to minus a single point. The Chern-Gauss-Bonnet theorem then states that,
\begin{align}
    \chi(\mathcal{M}_m^L)&=2,\\
     \chi(\mathcal{L}_m^X)&=3+m.
\end{align}

\begin{proof} $ $

$1.$ Follows from the fact that $\mathcal{M}_m^L$ is isomorphic to $\PP^1$, which in turn has Chern class $1+2[x]$ by \Cref{le:ChernP}, where $x$ is a point of $\PP^1$.

$2.$ Recalling that we in the proof of \Cref{prop:smooth} viewed $\mathcal{L}_m^X$ as a blow-up, the Chern class formula from \Cref{ss:Chern} gives us 
\begin{equation}
    c(\mathcal{L}_m^X)=(1+[D_H^X])^3+\sum_{i=1}^m (1+[E_i^X])(1-[E_i^X])^3-1.
\end{equation}
After simplication and noting that $[E_i^X]^3=0$, we get the statement.
\end{proof}



We aim to use \Cref{thm:Whitney} to determine the Euler characteristic of $D_Q^X$ and $D_Q^L$. For this we first prove that they are very ample. 

\begin{lemma}\label{le:veryample} Both $D_Q^L$ and $D_Q^X$ are very ample.
\end{lemma}

\begin{proof}[Sketch of Proof] Both $D_Q^L$ and $D_Q^X$ are restrictions of $H_Q$ in $(\PP^2)^m$. In the Chow ring of $(\PP^2)^m$, we have
\begin{align}
    H_Q\equiv 2H_{\infty,1}+\cdots +2H_{\infty,m}.
\end{align}
Let $h_Q$ denote the equation of $H_Q$. Any rational function $s=g/h_Q$, given a polynomial $g$ that is homogeneous quadratic in every copy of $\PP^2$, defines a global section and we have $H_Q+(s)\ge 0$. We can clearly choose such numerators $g_0,\ldots,g_n$ that do not all vanish at the same time. Applying the Veronese embedding $\PP^2\to \PP^5$ in each copy of $\PP^2$ and then the Segre embedding from $(\PP^5)^m$ into projective space $V\subseteq \PP^N$, each $g_i$ becomes a linear function $l_i$ from $V$ to $\CC$. This means that
\begin{align}
    [l_0:\cdots : l_n]:V\to \PP^n,
\end{align}
is isomorphic onto its image. This however implies that $[g_0:\cdots : g_n]$ from $(\PP^2)^m$ to $\PP^n$ is also isomorphic onto its image. 
\end{proof}

\begin{lemma} $ $



\begin{enumerate}
     \item A generic divisor $D'^{L}$ in the linear system $\Gamma (\mathcal{M}_m^L,\mathcal O(D_Q^L ))$ is smooth;
    \item A generic divisor $D'^X$ in the linear system $\Gamma (\mathcal{L}_m^X,\mathcal O(D_Q^X ))$ is smooth.
    \end{enumerate}
\end{lemma}


\begin{proof} Very ample divisors have basepoint free linear systems. Therefore we are done by \Cref{le:veryample} and \Cref{thm:Bertini}.
\end{proof}



\begin{proposition}\label{prop:eulgendiv} $ $

\begin{enumerate}
    \item $\chi(D'^L)=2m$;
    \item $\chi(D'^X)=-4m^2+8m$.
\end{enumerate}
\end{proposition}

\begin{proof} $ $

$1.$ For the purpose of applying the Chern-Gauss-Bonnet theorem, we want to find the top Chern class of $D'^L$, which is $c_0(D'^L)=1$. Using $D'^X\equiv D_H^X$, it follows that $\chi(D'^L)$ equals
\begin{align}
    \int_{D'^L} 1|_{D'^L} =\int_{\mathcal{M}_m^L}1 [D'^X]= \int_{\mathcal{M}_m^L} 2m[D_H^X] ,\label{eq:finalCGBpoint}
\end{align}
which equals $2m$ since $[D_H^X]$ is the class of one simple point in $\mathcal M_m^L$.


$2.$ By the adjunction formula and the fact that $D'^X\equiv D_Q^X$, we have 
\begin{align}\label{eq:D_rest}
\begin{aligned}
     c(D'^X) = \frac{c(\mathcal L_m^X|_{D'^X})}{(1+[D'^X])|_{D'^X}}=\Big(c(\mathcal L_m^X)(1+[D_Q^X])^{-1}\Big)\Big|_{D'^X}.
\end{aligned}
\end{align}
Throughout this proof we use \Cref{le:ChowID}. The identity $(1+u)^{-1}=1-u+u^2-\cdots$ and \Cref{eq:Dqx} imply  
\begin{align}\label{eq:1_plus_inverse}
\begin{aligned}
     (1+[D_Q^X])^{-1}=1-2m[D_H^X]+2\sum [E_i^X]+4m^2[D_H^X]^2+4\sum [E_i^X]^2.    
\end{aligned}
\end{align}
For the purpose of applying the Chern-Gauss-Bonnet theorem we want to find the top Chern class of $D'^X$, which is $c_1(D'^X)$. However, this is first Chern class of $c(\mathcal L_m^X)(1+[D_Q^X])^{-1}$ restricted to $D'^X$, by \Cref{eq:D_rest}. Using \Cref{eq:1_plus_inverse}, the first Chern class of $c(\mathcal L_m^X)(1+[D_Q^X])^{-1}$ is
\begin{align}
(-2m+3)[D_H^X] +\sum [E_i^X].
\end{align}
It follows that $\chi(D'^X)$ equals
\begin{equation}\label{eq:finalCGB}
\begin{split}
     \int_{D'^X} \Big((-2m+3)[D_H^X] +\sum [E_i^X]\Big)\Big|_{D'^X}
    = & \int_{\mathcal{L}_m^X} \Big((-2m+3)[D_H^X] +\sum [E_i^X]\Big)[D'^X] \\
    = &\int_{\mathcal{L}_m^X}(-4m^2+6m)[D_H^X]^2 -2\sum [E_i^X]^2,
\end{split}   
\end{equation}
where we for the last equality used \Cref{eq:Dqx}. Recall then that $\deg [D_H^X]^2=1$ and $\deg [E_i^X]^2=-1$. So \Cref{eq:finalCGB} adds to $-4m^2+6m+2m$. 
\end{proof}

If we consider $y_{2i-1}, y_{2i}$ and $x_i$ as sections of line bundles $\mathcal{M}_m^L$ and $\mathcal L_m^X$, then $D_Q^L = \mathcal{M}_m^L \cap H_Q$, respectively $D_Q^X = \mathcal{L}_m^X \cap H_Q$, is a
general divisor in the linear system given by the subspace $\Gamma'^L$ of $\Gamma(\mathcal{M}_m^L, \mathcal O(2mD_H^L))$, respectively $\Gamma'^X$ of $\Gamma(\mathcal{L}_m^X, \mathcal O(2mD_H^X-2E_i^X-\cdots-2E_i^X))$, generated by the sections
\begin{align}\label{eq:gen_sec}
\begin{aligned}
   1.\; &(y_1^2 + y_2^2) x_2^2\cdots x_m^2 +\cdots +(y_{2m-1}^2 + y_{2m}^2) x_1^2\cdots x_{m-1}^2,\\
   2.\; &x_1^2\cdots x_m^2,\\
   3.\; & \frac{y_{2i-1}}{x_i}x_1^2\cdots x_m^2 \textnormal{ for }i=1,\ldots,m,\\
   4.\; & \frac{y_{2i}}{x_i}x_1^2\cdots x_m^2 \textnormal{ for }i=1,\ldots,m.
\end{aligned}
\end{align}
To be precise, $D_Q^L$ and $D_Q^X$ are defined through global sections determined by $H_Q$, and $H_Q$ is a linear combination of the generators of \Cref{eq:gen_sec} with generic coefficients as in \Cref{eq:homog1}.

\begin{proposition} $ $

\begin{enumerate}
    \item $D_Q^L$ is smooth;
    \item The singular locus of $D_Q^X$ is the set of $\binom{m}{2}$ points
    \begin{align}\label{eq:singloc}
        S_{i,j}=\bigcup_{i\neq j} D_{\infty,i}^X\cap D_{\infty,j}^X.
    \end{align}
\end{enumerate}


\end{proposition}

\begin{proof} $ $ 

$1.$ The base locus of $\Gamma'^L$ is $\cup D_{\infty,i}^L\cap D_{\infty,j}^L$. Indeed, this is precisely the zero locus of the polynomials of \Cref{eq:gen_sec}. Observe that each $D_{\infty,i}^L\cap D_{\infty,j}^L$ is empty. By Bertini's theorem, $D_Q^L$ is smooth away from this empty set. 

$2.$ Similarly, the base locus of $\Gamma'^X$ is $\cup D_{\infty,i}^X\cap D_{\infty,j}^X$. Observe that each $D_{\infty,i}^X\cap D_{\infty,j}^X$ is a point. On the other hand, $D_Q^X$
has multiplicity at least 2 along $\cup D_{\infty,i}^X\cap D_{\infty,j}^X$. We can see this by looking at the Jacobian condition. The vanishing ideal of $\mathcal{L}_m^X$ together with the additional equation of $H_Q$ defines $D_Q^X$, a variety of dimension $1$. At $S_{i,j}$, the gradient of the generators of $\mathcal{L}_m^X$ gives the correct corank $2$ since it is smooth, but the additional equation has gradient zero, so that the corank is not equal to 1. 
\end{proof}

\begin{proposition}\label{prop:whit} $ $

\begin{enumerate}
    \item A Whitney stratification of $D_Q^L$ is the single stratum $S_{\textnormal{reg}}=D_Q^L$;
    \item A Whitney stratification of $D_Q^X$ consists of the stratum of smooth points $S_{\textnormal{reg}}$ and $S_{i,j}=D_{\infty,i}^X\cap D_{\infty,j}^X $.
\end{enumerate}\label{prop:Whitney}
\end{proposition}

\begin{proof} This is stated in \Cref{ss:Whitney}.
\end{proof}

\begin{proposition}\label{prop:redMilnor} The reduced Milnor fibers of each $S_{i,j}$ is $-1$. 
\end{proposition}

\begin{proof} Near
\begin{align}
    S_{i,j}=D_{\infty,i}^X\cap D_{\infty,j}^X,
\end{align}
the functions $x=\frac{x_i}{y_{2i}},y=\frac{x_j}{y_{2j}}$ form a coordinate frame of $\mathcal{L}_{\mathcal{C}}^X$, meaning the values of $x,y$ determine a unique point of $\mathcal{L}_{\mathcal{C}}^X$. This translates to $D_Q^X$ being determined by the equation
\begin{align}
u_1x^2+u_2y^2=u_3x^2y^2,
\end{align}
for holomorphic locally non-vanishing functions $u_1,u_2,u_3$ that we can read off from the homogenization of $H_Q$ in \Cref{eq:homog1}. In a neighbourhood, we may after coordinate change assume that $u_1,u_2,u_3$ are constantly equal to $1$ for the purpose of calculating Milnor fibers.

Next look at $G_t=\{x^2+y^2-x^2y^2=t\}\cap B_{\epsilon}$ and the map
\begin{align}
    \psi:G_t\to \{x+y-xy=t\}\cap B_{\epsilon^2},\quad (x,y)\mapsto (x^2,y^2), 
\end{align}
for $t$ such that $0<|t|$ is much smaller than $\epsilon$. Denote by $G_t'$ the set $ \{x+y-xy=t\}\cap B_{\epsilon^2}$. Consider the disjoint union
\begin{align}\label{eq:part}
    G_t'=(G_t'\cap \{x,y\neq 0\})\cup (G_t'\cap \{x=0\})\cup (G_t'\cap \{y= 0\}).
\end{align}
Note that $G_t'$ is smooth at every point for small $\epsilon$; the gradient is $(1-x,1-y)$. Observe that $G_t'\cap \{x=0\}$ and $G_t'\cap \{y=0\}$ are by construction single points. We have that $\psi$ is 4-to-1 on the first set of the disjoint union of \Cref{eq:part} and 2-to-1 on the second and third sets. This gives us 
\begin{align}
    \chi(G_t)&=4\chi((G_t'\cap \{x,y\neq 0\})+2 \chi(G_t'\cap \{x=0\})+2\chi (G_t'\cap \{y= 0\})\\
    &=4(1-2)+2+2=0.
\end{align}
We conclude that the reduced Milnor fiber is $-1$.
\end{proof}

We are now ready to prove the main theorem.

\begin{proof}[Proof of \Cref{thm:EDDthm}] $ $

$1.$ We use \Cref{thm:Whitney} and \Cref{prop:Whitney} to conclude that 
\begin{align}
\chi(D_Q^L)=\chi(D'^L).
\end{align}
Here we used that the Milnor fiber at a smooth point is contractible and the corresponding reduced Euler characteristics is therefore 0. We get by \Cref{eq:eulML1}, and \Cref{lem:anchored_chiY_n,lem:anchored_chiDinfty,lem:achored_chiDinftycapDQ} and \Cref{prop:eulgendiv} that
\begin{align}
    \chi(M_m^L\cap U_\beta)= 2-m+0-2m,
\end{align}
which sums to $2-3m$. Since $\dim \mathcal{M}_m^L=1$, \Cref{thm:EDDthm} says that $\mathrm{EDD}(\mathcal{M}_m^L)=3m-2$.

$2.$ Similarly, \Cref{thm:Whitney} and \Cref{prop:Whitney} give that  
\begin{equation}
\chi(D'^X)-\chi(D_Q^X)=\mu_0 \chi(S_{\textnormal{reg}}\setminus D'^X)
+\sum_{i\neq j}\mu_{i,j} \chi(S_{i,j}\setminus D'^X). 
\end{equation}
The reduced Milnor fiber of the stratum of smooth points can easily be seen to be 0. Observe that $D'^X$ does not meet any singular points ($\Gamma(\mathcal{L}_m^X,\mathcal O(D_Q^X))$ is basepoint free). Therefore $\chi(S_{i,j}\setminus D'^X)=\chi(S_{i,j})=1$. We get by \Cref{eq:eulML1}, and \Cref{lem:anchored_chiY_n,lem:anchored_chiDinfty,lem:achored_chiDinftycapDQ} and \Cref{prop:eulgendiv,prop:redMilnor} that 
\begin{equation}
    \chi(L_m^X\cap U_\beta)= (3+m)- \left(2m-\binom{m}{2}\right)+{\binom{m}{2}}-\left(-4m^2+8m+\binom{m}{2}\right),
\end{equation}
which sums to $\frac{9}{2}m^2-\frac{19}{2}m+3$. Since $\dim \mathcal{L}_m^X=2$, \Cref{thm:EDDthm} says that $\mathrm{EDD}(\mathcal{L}_m^X)=\frac{9}{2}m^2-\frac{19}{2}m+3 $.
\end{proof}

The following is a direct consequence:

\begin{customtheorem}{\ref{cor:EDD_p}} Let $\mathcal{C}$ denote a generic camera arrangement of at least two cameras. 
\begin{enumerate}
    \item $\mathrm{EDD}( \mathcal{M}_\mathcal{C}^{1, 1})=3m-2 $;
    \item $\mathrm{EDD}( \mathcal{M}_\mathcal{C}^{2,1})=\frac{9}{2}m^2-\frac{19}{2}m+3.$
\end{enumerate}
\end{customtheorem}

\begin{proof} Follows from \Cref{thm:EDDthm} and \Cref{thm:EDbij}.
\end{proof}

\section{Pseudocodes}\label{s:Pseudo} Finally, in the last section we provide the pseudocode that lay the foundation for our numerical results. For the plots presented in the main document, we iterate 1000 times on each of the 5 different ways of reconstruction and then we plot the relative error.
Note that each time we generate new random camera arrangements, a line in $\RR^3$ and $p$ points on this line.

In the pseudocodes below, for a point $X\in \RR^n$, let $\Bar{X}\in \RR^{n+1}$ be $[X \; 1]$. Further, we denote by $\Bar{X}$ a point on this form. This corresponds to choosing an affine patch of $\PP^n$. 

In \Cref{alg:L1_0,alg:L1_1,alg:L1_2,alg:L1_3,alg:L1_4} we use the standard approach for simplicity, but we provide in \Cref{alg:L1_1_nonstd} the non-standard approach for (L1).1 to emphasize the distinction. 
\begin{algorithm}[ht]
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\SetKwInOut{Return}{Return}
\caption{One iteration of the (L1).0 method given a randomly generated camera arrangement $\mathcal{C}$, and $p$ collinear points $\Bar{X}_i$.}
\label{alg:L1_0}
\Input{$\mathcal{C}=(C_1,\ldots,C_m)$, $\Bar{X}_1,\ldots,\Bar{X}_p$}
\Output{The log of the average relative error} 
\For{$j$ from $1$ to $m$}{
    \For{$i$ from $1$ to $p$}{
        $q_{i,j} \gets C_j\Bar{X}_i +\sigma(\epsilon$)\;}}
\For{$i$ from 1 to $p$}{
$\Bar{Y}_i \gets \mathrm{argmin}_{\Bar{X}\in \PP^3} \sum^{m}_{j=1} (q_{i,j}-C_j\Bar{X})^2$\;}

$e\gets \log_{10}\left(\frac{\sum_{i=1}^p \|\Bar{Y}_i-\Bar{X}_i\|}{p\epsilon}\right) $\;
\Return{$e$}

 \end{algorithm}

 \begin{algorithm}[ht]
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\SetKwInOut{Return}{Return}
\caption{One iteration of the (L1).1 std. method given a randomly generated camera arrangement $\mathcal{C}$, a line in $L\subset \PP^3$, and $p$ points $\Bar{X}_i$ on $L$.}
\Input{$\mathcal{C}=(C_1,\ldots,C_m)$, $L$, $\Bar{X}_1,\ldots,\Bar{X}_p$}
\Output{The log of the average relative error} 
   \For{$j$ from $1$ to $m$}{
        \For{$i$ from $1$ to $p$}{
        $q_{i,j} \gets C_j\Bar{X}_i +\sigma(\epsilon$)\;}
        $u_j \gets C_j \cdot L +\sigma(\epsilon)$\;}
    $L_0\gets \mathrm{nullspace} \begin{bmatrix}
    C^T_1u_1&C^T_2u_2
    \end{bmatrix}^T$\;
    \For{$i$ from 1 to $p$}{$\Bar{Y}_i \gets \mathrm{argmin}_{\Bar{X}\in L_0} \sum^{m}_{j=1} (q_{i,j}-C_j\Bar{X})^2$\; }
    $e\gets \log_{10}\left(\frac{\sum_{i=1}^p \|\Bar{Y}_i-\Bar{X}_i\|}{p\epsilon}\right) $\;


\Return{$e$}

\end{algorithm}

\begin{algorithm}[ht]
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\SetKwInOut{Return}{Return}
\caption{One iteration of the (L1).2 std. method given a randomly generated camera arrangement $\mathcal{C}$, and $p$ collinear points $\Bar{X}_i$.}
\label{alg:L1_2}
\Input{$\mathcal{C}=(C_1,\ldots,C_m)$, $\Bar{X}_1,\ldots,\Bar{X}_p$}
\Output{The log of the average relative error}
   \For{$j$ from 1 to $m$}{
        \For{$i$ from $1$ to $p$}{$q_{i,j} \gets C_j\Bar{X}_i +\sigma(\epsilon$)\;}}
    $Z_1 \gets \mathrm{argmin}_{X\in \RR^3} \sum^{m}_{j=1} (q_{1,j}-C_j\Bar{X})^2$\;
    $Z_2 \gets \mathrm{argmin}_{X\in \RR^3} \sum^{m}_{j=1} (q_{2,j}-C_j\Bar{X})^2$\;
    $L_0\gets \mathrm{span}\{\Bar{Z_1}, \Bar{Z_2}\}$\;
    \For{$i$ from 3 to $p$}{
    $\Bar{Y}_i \gets \mathrm{argmin}_{\Bar{X}\in L_0} \sum^{m}_{j=1} (q_{i,j}-C_j \Bar{X})^2$\; 
    }
    $e\gets \log_{10}\left(\frac{\sum_{i=1}^p \|\Bar{Y}_i-\Bar{X}_i\|}{p\epsilon}\right) $\;
\Return{$e$}

 \end{algorithm}

 \begin{algorithm}[ht]
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\SetKwInOut{Return}{Return}
\caption{One iteration of the (L1).3 std. method given a randomly generated camera arrangement $\mathcal{C}$, a line in $L\subset \PP^3$, and $p$ points $\Bar{X}_i$ on $L$.}
\label{alg:L1_3}
\Input{$\mathcal{C}=(C_1,\ldots,C_m)$, $L$,$\Bar{X}_1,\ldots,\Bar{X}_p$}
\Output{The log of the average relative error}
    \For{$j$ from 1 to $m$}{
        \For{$i$ from 1 to $p$}{
        $q_{i,j} \gets C_j\Bar{X}_i +\sigma(\epsilon)$ for each $i=1,\ldots ,p$ \;}
        $u_j \gets C_j \cdot L +\sigma(\epsilon)$\;}
    $Z \gets \mathrm{argmin}_{X\in \RR^3} \sum_{j=1}^m(q_{1,j}-C_j\Bar{X})^2$\;
    $L_0 \gets \mathrm{argmin}_{L'\in \Lambda(\Bar{Z})} \sum^{m}_{j=1} (u_j-C_j \cdot L')^2$\;
    \For{$i$ from $1$ to $p$}{
    $\Bar{Y}_i \gets \mathrm{argmin}_{\Bar{X}\in L_0} \sum^{m}_{j=2} (q_{i,j}-C_j\Bar{X})^2$\;}
    $e\gets \log_{10}\left(\frac{\sum \|\Bar{Y}_i-\Bar{X}_i\|}{p\epsilon}\right) $\;

\Return{$e$}

 \end{algorithm}

 \begin{algorithm}[ht]
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\SetKwInOut{Return}{Return}
\caption{One iteration of the (L1).4 method given a randomly generated camera arrangement $\mathcal{C}$, a line in $L\subset \PP^3$, and $p$ points $\Bar{X}_i$ on $L$.}
\label{alg:L1_4}
\Input{$\mathcal{C}=(C_1,\ldots,C_m)$, $L$, $\Bar{X}_1,\ldots,\Bar{X}_p$}
\Output{The log of the average relative error} 
   \For{$j$ from $1$ to $m$}{
        \For{$i$ from $1$ to $m$}{
            $q_{i,j} \gets C_j\Bar{X}_i +\sigma(\epsilon)$\;}
        $u_j \gets C_j \cdot L +\sigma(\epsilon)$\;
        }
    $L_0 \gets \mathrm{argmin}_{L'\in \mathrm{Gr}(1,\RR^3)} \sum^{m}_{j=1} (u_j-C_j\cdot L')^2$\;
    \For{$i$ from $1$ to $m$}{$\Bar{Y}_i \gets \mathrm{argmin}_{\Bar{X}\in L_0} \sum^{m}_{j=1} (q_{i,j}-C_j\Bar{X})^2$\;}
    $e\gets \log_{10}\left(\frac{\sum_{i=1}^p \|\Bar{Y}_i-\Bar{X}_i\|}{p\epsilon}\right) $\;

\Return{$e$}
\end{algorithm}



\begin{algorithm}[ht]
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\SetKwInOut{Return}{Return}
\caption{One iteration of the (L1).1 non-std. method given a randomly generated camera arrangement $\mathcal{C}$, a line in $L\subset \PP^3$, and $p$ points $\Bar{X}_i$ on $L$.}
\label{alg:L1_1_nonstd}
\Input{$\mathcal{C}=(C_1,\ldots,C_m)$, $L$, $\Bar{X}_1,\ldots,\Bar{X}_p$}
\Output{The log of the average relative error} 
   \For{$j$ from $1$ to $m$}{
        \For{$i$ from $1$ to $p$}{
        $q_{i,j} \gets C_j\Bar{X}_i +\sigma(\epsilon)$\;}
        $u_j \gets C_j \cdot L +\sigma(\epsilon)$\;
    }
    $l_0,l_1\gets \textnormal{ON-basis of } \mathrm{nullspace} \begin{bmatrix}
    C^T_1u_1&C^T_2u_2
    \end{bmatrix}^T$\;
    \For{$j$ from $1$ to $m$}{
        $a_{j1},a_{j2}\gets \textnormal{ON-basis of } [C_jl_0\; C_jl_1]^T$ \;
        $A_j\gets [a_{j1}\; a_{j2}]^T $\;
        $C_{\mathrm{aug},j}\gets  A_jC_j[l_0\; l_1]$\;
       }
    \For{$i$ from $1$ to $p$}{
        $\Bar{Y}_i' \gets \mathrm{argmin}_{X\in \RR^1} \sum^{m}_{j=1} (A_iq_{i,j}-C_{\mathrm{aug},j}\Bar{X})^2$\;
        $\Bar{Y}_i\gets [l_0\; l_1]\Bar{Y}_i'$\;
    }
    $e\gets \log_{10}\left(\frac{\sum \|\Bar{Y}_i-\Bar{X}_i\|}{p\epsilon}\right) $\;
\Return{$e$}

 \end{algorithm}

\end{document}

