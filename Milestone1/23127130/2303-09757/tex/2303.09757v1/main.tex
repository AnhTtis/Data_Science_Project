% CVPR 2023 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
% \usepackage[review]{cvpr}      % To produce the REVIEW version
% \usepackage{cvpr}              % To produce the CAMERA-READY version
\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}

% custom
\usepackage{adjustbox}
\usepackage{pifont}
\usepackage[misc]{ifsym}

\usepackage[accsupp]{axessibility}  % Improves PDF readability for those with disabilities.

% Hide or show our comments
\newif\ifshowcomments
\showcommentstrue
%\showcommentsfalse

% Coloring for our comments (use showcommentstrue or showcommentsfalse above to show/hide)
\ifshowcomments

\newcommand{\TODO}[1]{{\color{red}{[TODO: #1]}}}
\newcommand{\Outline}[1]{{\color{blue}{[Outline: #1]}}}
\newcommand{\revised}[1]{{\color[rgb]{0.2,0.7,0.2}{#1}}}
\newcommand{\zl}[1]{{\color[rgb]{0.9,0.1,0.1}{#1}}}
\newcommand{\xwhu}[1]{{\color[rgb]{0.5,0.2,0.7}{#1}}}
\newcommand{\jqxu}[1]{{\color[rgb]{0.7,0.3,0.3}{#1}}}

\else
\newcommand{\TODO}[1]{}
\newcommand{\revised}[1]{}
\fi


% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}
\usepackage{tabularx}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{3725} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}

\makeatletter
\def\thanks#1{\protected@xdef\@thanks{\@thanks
        \protect\footnotetext{#1}}}
\makeatother


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Video Dehazing via a Multi-Range Temporal Alignment \\ Network with Physical Prior}

\author{Jiaqi Xu \textsuperscript{\rm 1, 2, $^{\star}$},
%\thanks{ \hspace{-6mm}  ${\star}$ : This work was done during their internship at Shanghai Artificial Intelligence Laboratory. \\ ${\dagger}$ : Corresponding authors (huxiaowei@pjlab.org.cn; leizhu@ust.hk).}, 
   Xiaowei Hu \textsuperscript{\rm 2, $^{\textrm{\Letter}}$},
   Lei Zhu \textsuperscript{\rm 3, 4, $^{\textrm{\Letter}}$},
   Qi Dou \textsuperscript{\rm 1},
   Jifeng Dai \textsuperscript{\rm 5, 2},
   Yu Qiao  \textsuperscript{\rm 2},
   Pheng-Ann Heng \textsuperscript{\rm 1} \\
 \textsuperscript{\rm 1} The Chinese University of Hong Kong \quad
 \textsuperscript{\rm 2} Shanghai Artificial Intelligence Laboratory \\
 \textsuperscript{\rm 3} The Hong Kong University of Science and Technology (Guangzhou) \\
 \textsuperscript{\rm 4} The Hong Kong University of Science and Technology \quad
 \textsuperscript{\rm 5} Tsinghua University
}
\thanks{ 
\hspace{-6mm}  ${\star}$ : This work was done during Jiaqi Xu's internship at Shanghai Artificial Intelligence Laboratory. \\
 $^{\textrm{\Letter}}$ : Corresponding authors (huxiaowei@pjlab.org.cn; leizhu@ust.hk).}

\maketitle


%%%%%%%%% ABSTRACT
\begin{abstract}
   Video dehazing aims to recover haze-free frames with high visibility and contrast.
   %
   This paper presents a novel framework to effectively explore the physical haze priors and aggregate temporal information.
   %
   Specifically, we design a memory-based physical prior guidance module to encode the prior-related features into long-range memory.
   %
   Besides, we formulate a multi-range scene radiance recovery module to capture space-time dependencies in multiple space-time ranges, which helps to effectively aggregate temporal information from adjacent frames.
   %
   Moreover, we construct the first large-scale outdoor video dehazing benchmark dataset, which contains videos in various real-world scenarios.
   %
   Experimental results on both synthetic and real conditions show the superiority of our proposed method.
   %
   % The dataset and code will be publicly available.

   % Video dehazing aims to recover haze-free frames with high visibility and contrast. This paper presents a novel framework to effectively explore the physical haze priors and aggregate temporal information. Specifically, we design a memory-based physical prior guidance module to encode the prior-related features into long-range memory. Besides, we formulate a multi-range scene radiance recovery module to capture space-time dependencies in multiple space-time ranges, which helps to effectively aggregate temporal information from adjacent frames. Moreover, we construct the first large-scale outdoor video dehazing benchmark dataset, which contains video frames in various real-world scenarios. Experimental results on both synthetic and real conditions show the superiority of our proposed method. The dataset and code will be publicly available.
   
   %Video dehazing aims to recover haze-free frames with high visibility and contrast, which is appealing for vision applications.
   %The main challenge in video dehazing lies in explicitly leveraging haze priors and efficiently aggregating temporal information.
   %In this paper, we propose a novel framework, video dehazing Transformer (VDHT), which performs physical model-based feature disentanglement and inject haze-related priors into the scene radiance recovery.
   %Specifically, we present a memory-based haze guidance module, which integrates the haze-related features into the radiance counterpart to remove haze better.
   %Besides, we show a multi-range radiance recovery design that effectively captures space-time dependencies in multiple space-time resolutions via the attention mechanism.
   %Extensive experiments show that our proposed method outperforms state-of-the-art methods on one real indoor and our generated large-scale outdoor video dehazing dataset.
   % 
   %The code and data will be made publicly available.
   \vspace{-3mm}
\end{abstract}

%%%%%%%%% BODY TEXT
\input{introduction.tex}
\input{background.tex}
\input{dataset.tex}
\input{method.tex}
\input{experiments.tex}

%------------------------------------------------------------------------
\section{Conclusion}
% 
This work designs a video dehazing framework via a multi-range temporal alignment network with physical prior.
%
Two new techniques, a memory-based physical prior guidance module and a multi-range scene radiance recovery module, are formulated to effectively explore the physical haze priors and aggregate temporal information.
%
We construct the first large-scale benchmark dataset for outdoor video dehazing, which enables us to evaluate the dehazing performance on various application scenarios and downstream tasks.
%
In the end, the experimental results on both synthetic and real conditions demonstrate the superior of our framework against the recent state-of-the-art methods.

\vspace{-4mm}
\paragraph{Limitations.}
% 
Our method might not work well for videos with extremely heavy haze, and more prior knowledge is required.
% 
Also, though our method achieves superior performance and faster speed than many dehazing methods, it still cannot meet the real-time requirement. 

\vspace{-4mm}
\paragraph{Acknowledgment.}
This work was partially supported by the
Research Grants Council of the Hong Kong Special Administrative Region, China (Project Reference Number: 14201321 and 14201620),
the National Natural Science Foundation of China (Grant No. 61902275),
the National Key R\&D Program of China (NO.2022ZD0160100),
and Shanghai Committee of Science and Technology (Grant No. 21DZ1100100).

%\vspace{-2.5mm}
%\paragraph{Border impacts.}

%\clearpage

%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{ref}
}

\end{document}
