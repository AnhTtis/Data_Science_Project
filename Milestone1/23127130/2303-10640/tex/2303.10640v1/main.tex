\documentclass[oneside, 12pt]{amsart}
\usepackage[utf8]{inputenc}

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[a4paper]{geometry}
\usepackage{mathrsfs} %for nicer caligraphic letters via mathscr
\usepackage[dvipsnames]{xcolor}

\usepackage[pagebackref=true,colorlinks=true, linkcolor=RedViolet, citecolor=RedViolet]{hyperref}
\renewcommand*\backref[1]{\ifx#1\relax \else (Cited on #1) \fi}

\usepackage{appendix}
\usepackage{enumerate}
%\usepackage{geometry}
% \geometry{
% a4paper,
% total={170mm,257mm},
% left=25mm,
% right=25mm,
% top=22mm,
% }
\usepackage{tikz-cd} 

% Theorem Environments: 
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{problem}[]{Problem}

\theoremstyle{definition}
\newtheorem{example}[theorem]{Example}

\numberwithin{theorem}{section}
\numberwithin{equation}{section} %Equations are numbered as #section.#equation

% For abstracts in multiple languages: 
\newenvironment{poliabstract}[1]
  {\renewcommand{\abstractname}{#1}\begin{abstract}}
  {\end{abstract}}

% Notation: 
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\norm}[1]{\left \lVert  #1 \right \rVert}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\indic}[1]{\mathbf{1}_{#1}}
\newcommand{\domL}{\text{\normalfont dom}(\mathscr{L})}
\newcommand{\rangeResolvent}{\text{\normalfont range}(\text{\normalfont Id}-\lambda \mathscr{L})}
% Triple norm: 
\newcommand{\vertiii}[1]{{\left\vert\kern-0.25ex\left\vert\kern-0.25ex\left\vert #1 
    \right\vert\kern-0.25ex\right\vert\kern-0.25ex\right\vert}}

% Zahlenbereiche: 
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}

% Kaligraphische Buchstaben: 
\newcommand{\calA}{\mathcal{A}}
\newcommand{\calB}{\mathcal{B}}
\newcommand{\calD}{\mathcal{D}}
\newcommand{\calE}{\mathcal{E}}
\newcommand{\calF}{\mathcal{F}}
\newcommand{\calG}{\mathcal{G}}
\newcommand{\calH}{\mathcal{H}}
\newcommand{\calL}{\mathcal{L}}
\newcommand{\calM}{\mathcal{M}}
\newcommand{\calN}{\mathcal{N}}
\newcommand{\calO}{\mathcal{O}}
\newcommand{\calP}{\mathcal{P}}
\newcommand{\calX}{\mathcal{X}}
\newcommand{\calY}{\mathcal{Y}}

% expectation and probability measures: 
\newcommand{\bbE}{\mathbb{E}}
\newcommand{\bbP}{\mathbb{P}}
\newcommand{\condexp}[2]{\bbE \left[ #1 \lvert #2 \right]}
\newcommand{\vol}{\text{\upshape vol}}
\newcommand{\dom}[1]{\text{\upshape dom}(#1)}
\newcommand{\determinant}{\text{\upshape det}}
\newcommand{\argmin}{\text{\upshape argmin}}

\newcommand{\jk}[1]{\textcolor{purple}{Jonas: {#1}}}
\newcommand{\bj}[1]{\textcolor{orange}{Benedikt: {#1}}}

\title[Long-time behaviour of IPS]{On the long-time behaviour of reversible interacting particle systems in one and two dimensions}
\author{Benedikt Jahnel}
\address{Institut f\"ur Mathematische Stochastik, Technische Universit\"at Braunschweig, Universit\"atsplatz 2,
38106 Braunschweig, Germany \& Weierstrass Institute for Applied Analysis and Stochastics\\
Mohrenstraße 39\\
10117 Berlin\\
Germany}
\email{benedikt.jahnel@tu-braunschweig.de}

\author{Jonas Köppl}
\address{Weierstrass Institute for Applied Analysis and Stochastics\\
Mohrenstraße 39\\
10117 Berlin\\
Germany}
\email{jonas.koeppl@wias-berlin.de}

\date{\today}
\keywords{Interacting particle systems, gibbs measures, relative entropy, attractor}
\subjclass{Primary 82C22; Secondary 60K35} 


\begin{document}

\maketitle
\begin{abstract}
  \noindent 
  By refining Holley's free energy technique, we show that, under quite general assumptions on the dynamics, the attractor of a (possibly non-translation-invariant) interacting particle system in one or two spatial dimensions is contained in the set of Gibbs measures if the dynamics admits a reversible Gibbs measure. In particular, this implies that there can be no reversible interacting particle system that exhibits time-periodic behaviour and that every reversible interacting particle system is ergodic if and only if the reversible Gibbs measure is unique. In the special case of non-attractive stochastic Ising models this answers a question due to Liggett. 
\end{abstract}


%1. Introduction: 
\section{Introduction and motivation}
One major part of the literature on interacting particle systems deals with the study of their long-time behaviour, in particular the convergence to time-stationary measures and the question of ergodicity. For continuous-time Markov processes on finite state spaces, this is a rather simple question and very well-understood, but for interacting particle systems on $\Z^d$ this is much more subtle. For example, in \cite{jahnel_class_2014} it was shown that for dimension $d\geq 3$, there are non-degenerate irreducible systems with a unique time-stationary measure that fail to be ergodic due to the existence of a periodic orbit in the associated measure-valued dynamics. This is a type of complex behaviour that simply does not occur for irreducible continuous-time Markov processes on finite state spaces.

While a classical result by Mountford, see \cite{mountford_coupling_1995}, shows that no such system can exist in one spatial dimension, it is an open problem whether a two-dimensional interacting particle system can exhibit non-trivial time-periodic behaviour. By now, there is a variety of mean-field systems that have been shown to exhibit time-periodic behaviour, see \cite{collet_rhythmic_2016} or \cite{cerf_rhythmic_2021} for recent results in this spirit. Probably the most famous and classical example for such behaviour is the Kuramoto model which has been studied very successfully, see for example \cite{acebron_kuramoto_2005} and \cite{giacomin_global_2012}. However, according to numerical experiments all of the known examples seem not to exhibit periodic behaviour in two dimensions. 

In this article, we want to investigate the possible long-time behaviour of interacting particle systems in one and two spatial dimensions under the assumption that they admit at least one reversible measure. We show that the presence of a single such fixed point narrows down the possible types of behaviours dramatically and at least morally describes the long-term behaviour completely. 

In particular, we show that the presence of at least one reversible fixed point of the measure-valued dynamics implies that there can be no periodic orbits. This provides a first partial answer to an open question which asks for the existence of interacting particle systems that exhibit time-periodic behaviour in two spatial dimensions, see e.g. \cite[Section 1.2]{maes_rotating_2011} or \cite[Section 1.8]{swart_course_2022}.

It is often argued that the presence of effects that break the time-symmetry is needed in order for an interacting particle system to exhibit time-periodic behaviour. To our knowledge, our proof gives the first rigorous mathematical justification for using this heuristic for spatially extended systems in continuous time. 

We expect that a similar result should also hold in dimensions $d \geq 3$, but the method of proof breaks down and one needs to proceed differently. It is also not clear if one can or cannot extend this method of proof to non-reversible systems. 

Moreover, as a second application of our main result we show that, if the reversible fixed-point is unique, then the interacting particle system is necessarily ergodic, i.e., the fixed point is globally attractive. In particular this confirms a conjecture of Liggett, see \cite[Chapter IV, Problem 2]{liggett_interacting_2005}, in the one- and two-dimensional case, and provides a partial answer to \cite[Chapter I, Problem~4]{liggett_interacting_2005}. 


For our proofs, we use a Lyapunov-functional approach which was pioneered in the context of lattice systems by Holley in \cite{holley_free_1971} and later extended to more general and even non-reversible systems in \cite{higuchi_results_1975}, \cite{kunsch_non_1984}, \cite{jahnel_attractor_2019}, and \cite{jahnel_dynamical_2022}. 
However, all of these results heavily rely on certain subadditivity properties and therefore only apply to \textit{translation-invariant} measures and cannot be used to say anything meaningful if one starts in a non-translation-invariant measure. 
The only results on non-translation-invariant measures that were obtained via the free-energy method are contained in \cite{holley_one_1977}. There, the authors were able to show that every time-stationary measure of a stochastic Ising model in one and two spatial dimensions is even reversible, hence a Gibbs measure. 
We extend their results to show that not just every time-stationary measure is reversible, but actually every element of the attractor is reversible. Since periodic orbits are contained in the attractor, this shows that there can be no non-trivial periodic behaviour. 
Therefore, it is not possible to both admit a reversible Gibbs measure and exhibit time-periodic behaviour. 

The main conceptual contribution of this article can therefore be summarised as the realisation that the finite-volume free energy technique from \cite{holley_one_1977} can not only be used for analysing stationary measures but can also be applied to every measure in the attractor and thereby yields much more information about the long-term behaviour of interacting particle systems than previously thought. In particular, we show that free energy techniques can be used to detect ergodic-non-ergodic phase transitions for interacting particle systems. 

Note that, since we are working with techniques from \cite{holley_one_1977}, we do \textit{not} need to assume any translation-invariance. This is due to being able to only work with finite-volume relative entropy losses and not taking any density limits, which is only possible in dimensions one and two. 

% Limit theorems with explicit convergence rates via log-Sobolev inequalities: TODO. 
The concept of relative entropy decay has become a very powerful tool for studying systems of interacting particles, and it connects probability, analysis, and geometry in an intricate way. One particularly fruitful application of relative entropy techniques is in the context of Log-Sobolev inequalities for Markov processes. These inequalities can be used to obtain bounds on the (exponential) speed of convergence to equilibrium. However, these methods are limited to the situation where the time-stationary measure is unique, whereas our method goes beyond this case and is also applicable in the non-uniqueness regime. A pedagogical introduction to Log-Sobolev inequalities in the easier setting of Markov chains on finite state spaces can be found in \cite{diaconis_logarithmic_1996}, while a very general approach can be found in \cite[Chapter 5]{bakry_analysis_2014}. 

% Relative entropy method for hydrodynamic limits: TODO. 
Another sub-area of probability where relative-entropy methods have successfully been applied to obtain limit theorems is the derivation of hydrodynamic equations as scaling limits of microscopic models of systems of interacting particles. In this context, the method is used to study the infinite particle limit, with additional rescaling of space and time, and not for long-time asymptotics. An introduction to this method can for example be found in the monograph \cite{kipnis_scaling_1999}. 

\subsection{Structure of the manuscript}
In Section~\ref{section:setting-and-notation} we introduce the framework in which we are working and setup the required notation before we state our main results in Section~\ref{section:main-results}. We then proceed by explaining the structure and key ideas of the main proof in Section~\ref{section:proof-strategy}. After this, we finally start with the main work and carry out the proof of our main results in Sections~\ref{section:holley-stroock-principle}, \ref{section:positive-mass} and \ref{section:zero-finite-volume-loss}. In the end, we comment on possible extensions to more general interacting particle systems in Section~\ref{section:generalisations}.

%2. Setting and Notation: 
\section{Setting and notation}\label{section:setting-and-notation}
Let $q \in \N$ and consider the configuration space $\Omega := \Omega_0^{\Z^d} = \{1,\dots,q\}^{\Z^d}$, which we will equip with the usual product topology and the corresponding Borel sigma-algebra $\calF$. For $\Lambda \subset \Z^d$ let $\calF_\Lambda$ be the sub-sigma-algebra of $\calF$ that is generated by the open sets in $\Omega_\Lambda := \{1,\dots, q\}^{\Lambda}$. We will use the shorthand notation $\Lambda \Subset \Z^d$ to signify that $\Lambda$ is a finite subset of $\Z^d$. In the following we will often denote for a given configuration $\omega \in \Omega$ by $\omega_\Lambda$ its projection to the volume $\Lambda \subset \Z^d$ and write $\omega_\Lambda \omega_\Delta$ for the configuration on in $\Lambda \cup \Delta$ composed of $\omega_\Lambda$ and $\omega_\Delta$ for disjoint $\Lambda, \Delta \subset \Z^d$. For the special case $\Lambda = \{x\}$ we will also write $x^c = \Z^d \setminus \{x\}$ and $\omega_x\omega_{x^c}$. 
The set of probability measures on $\Omega$ will be denoted by $\calM_1(\Omega)$ and the space of continuous functions by $C(\Omega)$. For a configuration $\eta \in \Omega$ we will denote by $\eta^{x,i}$ the configuration that is equal to $\eta$ everywhere except at the site $x$ where it is equal to $i$. Moreover, for $\Lambda \subset \Z^d$ we will denote the corresponding cylinder sets by 
$
    [\eta_\Lambda] = \{\omega : \ \omega_\Lambda \equiv \eta_\Lambda \}. 
$
Whenever we are taking the probability of such a cylinder event with respect to some measure $\nu \in \calM_1(\Omega)$, we will omit the square brackets and simply write $\nu(\eta_\Lambda)$. 

\subsection{Gibbs measures and interacting particle systems}
\subsubsection{Gibbs measures}
We begin by recalling the definition of a specification. 
\begin{definition}
A \emph{specification} $\gamma = (\gamma_\Lambda)_{\Lambda \Subset \Z^d}$ is a family of probability kernels $\gamma_{\Lambda}$ from $\Omega _{\Lambda^c}$ to $\calM_1(\Omega)$ that additionally satisfies the following properties. 
\begin{enumerate}[i.]
    \item Each $\gamma_{\Lambda}$ is \emph{proper}, i.e., if $\Delta \subset \Lambda^c$, then 
    \begin{align*}
        \gamma_\Lambda(\eta_{\Lambda}\eta_\Delta | \eta_{\Lambda^c}) = \gamma_{\Lambda}(\eta_{\Lambda}|\eta_{\Lambda^c}) \mathbf{1}_{\eta_\Delta}(\eta_{\Lambda^c}). 
    \end{align*}
    \item The probability kernels are \emph{consistent} in the sense that if $\Delta \subset \Lambda \Subset \Z^d$, then 
    \begin{align*}
        \gamma_{\Lambda}(\gamma_{\Delta}(\eta_{\Delta}|\cdot)|\eta_{\Lambda^c}) 
        = 
        \gamma_\Lambda(\eta_\Delta | \eta_{\Lambda^c}). 
    \end{align*}
\end{enumerate}
\end{definition}


An infinite-volume probability measure $\mu$ on $\Omega$ is called a \textit{Gibbs measure} for a specification $\gamma$ if $\mu$ satisfies the so-called \textit{DLR equations}, namely for all $\Lambda \Subset \Z^d$  and $\eta_\Lambda$ we have
\begin{align}\label{dlr-equations}
    \mu(\gamma_\Lambda(\eta_\Lambda | \cdot)) = \mu(\eta_\Lambda). 
\end{align}
We will denote the set of all Gibbs measures for a specification $\gamma$ by $\mathscr{G}(\gamma)$. For the existence and further properties of Gibbs measures one needs to impose some conditions on the specification $\gamma$. One sufficient condition for the existence of a Gibbs measure for a specification $\gamma$ is \textit{quasilocality}, which should be thought of as a continuous dependence on the boundary condition.

\begin{definition}
A specification $\gamma$ is called 
\begin{enumerate}[i.]
    \item \emph{non-null}, if for some $\delta >0$
    \begin{align*}
        \inf_{\eta \in \Omega}\gamma_0(\eta_0 | \eta_{0^c}) \geq \delta.
    \end{align*}
    \item \emph{quasilocal}, if for all $\Lambda \Subset \Z^d$
    \begin{align*}
        \lim_{\Delta \uparrow \Z^d}\sup_{\eta, \xi \in \Omega}\abs{\gamma_{\Lambda}(\eta_\Lambda | \eta_{\Delta \setminus \Lambda}\xi_{\Delta^c}) - \gamma_\Lambda(\eta_{\Lambda}|\eta_{\Lambda^c})} = 0. 
    \end{align*}
    %\item \emph{translation invariant}, if for all $\Lambda \Subset \Z^d$ and $i \in \Z^d$ we have 
    %\begin{align*}
    %    \gamma_{\Lambda +i}(\eta_{\Lambda +i}| \eta_{(\Lambda +i)^c}), 
    %\end{align*}
    %where $\Lambda+i$ denotes the lattice translate of $\Lambda$ by $i$.
\end{enumerate}
\end{definition}
We will sometimes consider the probability kernels $\gamma_\Lambda$ as functions $\Omega\to[0,1]$, $ \omega\mapsto\gamma_\Lambda(\omega_\Lambda | \omega_{\Lambda^c})$.
If $\gamma$ is a quasilocal specification, then each such map is uniformly continuous.
For example, specifications defined via a uniformly absolutely summable potential $\Phi=(\Phi_B)_{B \Subset \Z^d}$ are non-null and quasilocal. For more details on Gibbs measures and specifications see~\cite{georgii_gibbs_2011},~\cite[Chapter 6]{friedli_statistical_2017} and~\cite[Chapter 4]{bovier_statistical_2006}. 

\subsubsection{Interacting particle systems}

We will consider time-continuous Markovian dynamics on $\Omega$, namely interacting particle systems characterized by time-homogeneous generators $\mathscr{L}$ with domain $\text{dom}(\mathscr{L})$ and its associated Markov semigroup $(P_t)_{t \geq 0}$. 
For interacting particle systems we adopt the notation and exposition of the classical textbook \cite[Chapter 1]{liggett_interacting_2005}. 
In our setting, the generator $\mathscr{L}$ is given via a collection of  single-site transition rates $c_x(\eta, \xi_x)$, which are continuous in the starting configuration $\eta \in \Omega$. 
These rates can be interpreted as the infinitesimal rate at which the particle at site $x$ switches from the state $\eta_x$ to $\xi_x$, given that the rest of the system is currently in state $\eta_{x^c}$. 
The full dynamics of the interacting particle system is then given as the superposition of these local dynamics, i.e., 
\begin{align*}
    \mathscr{L}f(\eta) = \sum_{x \in \Z^d}\sum_{\xi_x}c_x(\eta, \xi_x)[f(\xi_x \eta_{x^c}) - f(\eta)].
\end{align*}
In \cite[Chapter 1]{liggett_interacting_2005} it is shown that the following two conditions are sufficient to guarantee the well-definedness. 
\begin{enumerate}[\bfseries (L1)]
    \item The rate at which the particle at a particular site changes its spin is uniformly bounded, i.e.,
    \begin{align*}
        \sup_{x \in \Z^d}\sum_{\xi_x}\norm{c_{x}(\cdot, \xi_{x})}_{\infty} < \infty 
    \end{align*}
    \item and the total influence of all other particles on a single particle is uniformly bounded, i.e.,
    \begin{align*}
        \sup_{x \in \Z^d}\sum_{y \neq x}\sum_{\xi_{x}}\delta_y\left(c_{x}(\cdot, \xi_{x})\right) < \infty, 
    \end{align*}
    where 
    \begin{align*}
        \delta_y(f) := \sup_{\eta, \xi: \ \eta_{y^c} = \xi_{y^c}}\abs{f(\eta)-f(\xi)}
    \end{align*}
    is the oscillation of a function $f:\Omega \to \R$ at the site $y \in \Z^d$. 
\end{enumerate}
Under these conditions, one can then show that the operator $\mathscr{L}$, defined as above, is the generator of a well-defined Markov process and that a core of $\mathscr{L}$ is given by the space of functions with finite total oscillation, i.e.
\begin{align*}
    D(\Omega) := \Big\{ f \in C(\Omega): \quad \sum_{x \in \Z^d} \delta_x(f) < \infty\Big\}.
\end{align*}

\noindent Let us emphasise briefly that we will not assume translation-invariance of the rates. 
 


\subsection{Relative entropy loss}
For $\mu, \nu \in \calM_1(\Omega)$ and a finite volume $\Lambda \Subset \Z^d$ define the relative entropy of $\nu$ with respect to $\mu$ in $\Lambda$ via 
\begin{align*}
    h_\Lambda(\nu | \mu) :=
    \begin{cases}
    \sum_{\omega_\Lambda \in \Omega_\Lambda}\nu(\omega_{\Lambda})\log\frac{\nu(\omega_{\Lambda})}{\mu(\omega_\Lambda)}, \quad &\text{if } \nu \ll \mu, 
    \\\
    \infty, &\text{else,}
    \end{cases}
\end{align*}
where we use the convention that $0 \log 0 = 0$. Now recall that $(P_t)_{t \geq 0}$ denotes the Markov semigroup corresponding to the Markov generator $\mathscr{L}$. We write $\nu_t:=\nu P_t$ for the time-evolved measure $\nu\in\calM_1(\Omega)$.
The finite-volume relative entropy loss in $\Lambda \Subset \Z^d$ is defined by 
\begin{align*}
    g_\Lambda^{\mathscr{L}}(\nu|\mu) 
    := \frac{d}{dt}\Big \lvert_{t=0}h_{\Lambda}( \nu_t\lvert \mu). 
\end{align*}
%In the special case where $\Lambda$ is the centered cube $[-n,n]^d$ we will use the short-hand notation $g^n_{\mathscr{L}}(\cdot \lvert \mu)$. 
Usually, one then works with the density limits of the relative entropy and the relative entropy loss and shows that the latter can still be used as a Lyapunov function for the dynamics. However, the sub-additivity arguments that are used to show that the relative entropy loss density actually exists as a limit are only available for translation-invariant measures. We do not want to make any such assumptions and therefore we will have to instead work with the family of finite-volume relative entropy losses. Note that calling the finite-volume derivatives \textit{loss} is not entirely correct, since they are not necessarily non-positive. However one can show that the positive contributions are of boundary order and vanish in the density limit, see \cite[Lemma~3.10 and Lemma~3.12]{jahnel_dynamical_2022}. 

\subsection{Time-stationary measures and the attractor}
If one is interested in the long-term behaviour of an interacting particle system, a natural object to study is the so-called \textit{attractor} of the measure-valued dynamics which is defined as
\begin{align*}
    \mathscr{A} = \set{\nu \in \calM_1(\Omega): \exists \nu_0 \in \calM_1(\Omega) \text{ and } t_n \uparrow \infty \text{ such that } \lim_{n \to \infty}\nu_{t_n} = \nu}. 
\end{align*}
This is the set of all accumulation points of the measure-valued dynamics induced by $\mathscr{L}$. In the language of dynamical systems this is the $\omega$-limit set. This encodes (most of) the dynamically relevant information about the long-time behaviour of the system. In particular,  the set of time-stationary measures is always a subset of $\mathscr{A}$ and in general this inclusion is strict as can be seen by considering the non-trivial example constructed in \cite{jahnel_class_2014} or the (from a probabilistic point of view) trivial example given in \cite[p.12]{liggett_interacting_2005}. 
Historically, most attention has been paid to investigating the set of time-stationary measures and their properties, but not much was known about the behaviour of interacting particle systems outside of this set. 
% 3. Main results
\section{Main results}\label{section:main-results}
\subsection{Assumptions on the transition rates and the specification}
Before we can state our main results, let us introduce some further conditions on the specification $\gamma = (\gamma_\Delta)_{\Delta \Subset \Z^d}$ and the rates $(c_x(\cdot, \xi_x))_{x \in \Z^d, \xi_x \in \Omega_0}$ that will turn out to be crucial for our results. 
\medskip

\noindent
\textbf{Conditions for the specification.} 
\begin{enumerate}[\bfseries (S1)]
\item $\gamma$ is quasilocal.
\item $\gamma$ is non-null with constant $\delta >0$. 
\item $\gamma$ satisfies 
\begin{align*}
    \sum_{y \in \Z^d}\abs{y}\sup_{x \in \Z^d}\delta_{x+y}\gamma_x(\cdot) < \infty. 
\end{align*}
\end{enumerate}

\noindent \textbf{Conditions for the rates.} 
\begin{enumerate}[\bfseries (R1)]
    \item  The rate at which the particle at a particular site changes its spin is uniformly bounded, i.e.,
    \begin{align*}
        \sup_{x \in \Z^d}\sum_{\xi_{x}}\norm{c_{x}(\cdot, \xi_{x})}_{\infty} < \infty. 
    \end{align*}
    \item For every $x \in \Z^d$ and $\xi_x \in \Omega_0$ the function 
    \begin{align*}
        \Omega \ni \eta \mapsto c_x(\eta, \xi_x) \in [0,\infty)
    \end{align*}
    is continuous.
    \item The transition rates are bounded away from zero, i.e.,
    \begin{align*}
        \inf_{x\in \Z^d,\, \eta \in \Omega,\, \xi_x \in \Omega_0 } c_x(\eta, \xi_x) \geq \delta >0. 
    \end{align*}
 %   \jk{Would be nice to weaken this assumption but it seems to be crucial in the proof of Lemma \ref{lemma:upper-bound-alpha}}
\item We have 
\begin{align*}
    \sum_{y \in \Z^d} \abs{y}\sup_{x \in \Z^d} \delta_{x+y}c_x(\cdot) < \infty,
\end{align*}
where $c_x(\eta) = \sum_{i \neq \eta_x}c_x(\eta,i)$ is the total rate at which the particle at site $x$ changes its state when the system is in configuration $\eta$. 
\end{enumerate}

Let us emphasise again that we do not assume that either the rates or the specification are translation invariant.  The most general result we obtain takes the following form. 
\begin{theorem}\label{theorem:main-result}
Let $d \in \{1,2\}$ and assume that $\mathscr{L}$ is the generator of an interacting particle system that satisfies assumptions $\mathbf{(R1)-(R4)}$ and that it admits a reversible measure $\mu$ that is a Gibbs measure with respect to a specification $\gamma$ that satisfies $\mathbf{(S1)-(S3)}$.
Then we have that 
\begin{align*}
    \mathscr{A} = \mathscr{G}(\gamma).
\end{align*}
\end{theorem}

This rather abstract limit theorem implies the following corollaries which are already interesting on their own. 

\subsubsection{Impossibility of time-periodic behaviour for reversible systems}
The, in our eyes, most noteworthy consequence of Theorem~\ref{theorem:main-result} is the following no-go result that essentially states that the presence of a reversible fixed point for the measure-valued dynamics makes it impossible to also possess periodic orbits. The precise formulation is as follows. 

\begin{corollary}\label{corollary:no-periodic}
Let $d \in \{1,2\}$ and assume that $\mathscr{L}$ and $\gamma$ satisfy the above assumptions and that $(P_t)_{t \geq 0}$ is the Markov semigroup generated by $\mathscr{L}$ with $\mu \in \mathscr{G}(\gamma)$ as reversible fixed point. Then, the measure-valued dynamics given by 
\begin{align*}
    [0,\infty) \times \calM_1(\Omega) \ni (t, \nu) \mapsto \nu P_t \in \calM_1(\Omega)
\end{align*}
does not contain non-trivial time-periodic orbits, i.e., there is no probability measure $\nu \in \calM_1(\Omega)$ such that $(\nu P_t)_{t\geq 0}$ is non-constant and such that there exists a $T>0$ with $\nu_t = \nu_{t +T}$. 
\end{corollary}

To our knowledge this is the first result on time-periodic behaviour in two spatial dimensions. Moreover, it is the first result that makes the physical intuition rigorous that time-periodic behaviour can only happen in driven, i.e. non-reversible, systems.  

\begin{proof}
    Let $(\nu_t)_{ t\geq 0}$ be a periodic orbit with minimal period $T \in [0, \infty)$. Then it must necessarily be contained in the attractor $\mathscr{A}$. But since we have $\mathscr{A} = \mathscr{G}(\gamma)$ by Theorem \ref{theorem:main-result} and every element of $\mathscr{G}(\gamma)$ is in particular time-stationary for the process generated by $\mathscr{L}$ by Proposition \ref{proposition:characterizations-reversibility}. So we must have $T = 0$ and the periodic orbit is actually constant. 
\end{proof}

\subsubsection{Ergodicity and uniqueness}

To state the next result without any confusion or ambiguity, we recall the definition of the term \textit{ergodic} as in \cite{liggett_interacting_2005}. 
\begin{definition}
A Markov process with semigroup $(P_t)_{t \geq 0}$ is said to be \emph{ergodic} if the following two conditions hold. 
\begin{enumerate}[(a)]
    \item The set of of time-stationary measures is a singleton $\{\mu\}$, and
    \item for all initial distributions $\nu \in \calM_1(\Omega)$ it holds that $\lim_{t \to \infty}\nu P_t = \mu$. 
\end{enumerate}
\end{definition}

In this language, the following result can be summarised as follows. If an interacting particle system admits a reversible Gibbs measure, then it is ergodic if and only if the associated specification gives rise to a unique Gibbs measure. This provides a partial answer to \cite[Chapter I, Problem 4]{liggett_interacting_2005}. 

\begin{corollary}\label{corollary:uniqueness-iff-ergodic}
    Let $d \in \{1,2\}$ and $\mathscr{L}$ and $\gamma$ satisfy the above assumptions and assume that $\mu \in \mathscr{G}(\gamma)$ is a reversible measure for $\mathscr{L}$. Then the interacting particle system is ergodic if and only if $\mathscr{G}(\gamma) = \{\mu\}$, i.e., we have ergodicity if and only if uniqueness holds for the associated specification. 
\end{corollary}


\begin{proof}
The direction that ergodicity implies uniqueness is clear, since in this situation every Gibbs measure is reversible for the interacting particle system by Proposition~\ref{proposition:characterizations-reversibility}. For the converse direction, let $\nu \in \calM_1(\Omega)$ be an arbitrary initial distribution. By compactness of $\Omega$, every subsequence of $(\nu_t)_{t\geq 0}$ contains a convergent subsequence, and by Theorem \ref{theorem:main-result} all of these subsequences converge to the same limit $\mu$. Since $\calM_1(\Omega)$ is metrisable, this implies that the full sequence $(\nu_t)_{t \geq 0}$ also has to converge to $\mu$. 
\end{proof}


\subsubsection{Ergodicity for non-attractive stochastic Ising models}

Specialising to binary local state spaces, i.e., $q = 2$, and Gibbsian specifications which are given in terms of a Hamiltonian, this provides a positive answer to an open problem in \cite[Chapter IV, Question 2]{liggett_interacting_2005} for non-attractive stochastic Ising models in one and two spatial dimensions. To give some more context to this, let us note that so far the above result was only known to hold under the additional assumption of \textit{attractivity}, see \cite[Theorem 2.16]{liggett_interacting_2005}, with the advantage that it then holds for any dimension $d$. We show that this additional assumption is not necessary, at least not in one and two spatial dimensions.  We expect that Corollary \ref{corollary:uniqueness-iff-ergodic} also holds for $d\geq 3$, but one needs to come up with a different proof strategy to tackle this problem. 

In the special case $d=1$ it is known that, at least under a suitable decay assumption on the interaction potential, Gibbs measures are  unique. So in this case we have shown that reversible interacting particle systems with positive rates are always ergodic in one spatial dimension. In the case of finite-range interactions this was already shown in \cite{holley_uniform_1989} by means of Log-Sobolev inequalities, which also provide an exponential speed of convergence. 

%4. Proof strategy 
\section{Proof strategy}\label{section:proof-strategy}
The proof essentially consists of three main steps that we will now explain briefly before we start with the actual mathematics. 

\subsection{Finite-volume relative entropy loss and Gibbs measures}

The first technical result is the following extension of the results in \cite{holley_one_1977} to general finite local state spaces and  specifications. 

\begin{proposition}[Holley--Stroock principle]\label{proposition:holley-stroock-principle}
Assume that $d \in \{1,2\}$, that $\mathscr{L}$ satisfies $\mathbf{(R1)-(R4)}$ and admits a reversible measure $\mu$ which is a Gibbs measure with respect to a specification $\gamma$ that satisfies $\mathbf{(S1)-(S3)}$. 
If $\nu \in \calM_1(\Omega)$ is a probability measure that satisfies
\begin{enumerate}[\bfseries \upshape (M1)]
    \item for all $\eta  \in \Omega$ and $\Lambda \Subset \Z^d$ it holds that $\nu(\eta_\Lambda) > 0$, and
    \item for all $\Lambda \Subset \Z^d$ we have $g_\Lambda^{\mathscr{L}}(\nu \lvert \mu) = 0$,
\end{enumerate} 
then we have $\nu \in  \mathscr{G}(\gamma)$. 
\end{proposition}

The proof of this follows the strategy laid out in \cite[Chapter IV.5]{liggett_interacting_2005} in our more general setting and can be found in Section~\ref{section:holley-stroock-principle}. 
After establishing this general principle, our main result Theorem \ref{theorem:main-result} will follow by showing that $\mathbf{(M1)-(M2)}$ are satisfied for elements of the attractor. The proof of this proceeds in two steps. 


\subsection{The positive-mass property}
If one considers an irreducible continuous-time Markov chain on a finite state space $X$, then it is easy to show that there exists a constant $\rho>0$ such that for any initial distribution $\nu$ and all $x \in X$ and $t\geq 0$, we have $\nu_t(x) \geq \rho$. In other words, every state has strictly positive mass for any positive time. In the setting of infinite-volume interacting particle systems that are irreducible in a suitable way, something similar should be true, but here it is not as straightforward to see as in the setting of finite state spaces. Proposition~\ref{proposition:positive-mass} makes this intuition precise. A less general but also stronger result was previously derived in \cite{jahnel_attractor_2019}. 


To show this positivity property, we will compare our dynamics to an interacting particle system in which all of the sites inside of $\Lambda$ behave independently and flip with the minimal transition rate. We then use the following Girsanov-type formula to compare this finite-volume perturbation with the original dynamics. 

\begin{lemma}\label{lemma:girsanov-transformation}
   Consider an interacting particle system with generator $L$ such that its transition rates $(c_x(\cdot, \cdot))_{x \in \Z^d}$ satisfy assumptions $\mathbf{(L1)-(L2)}$ and are strictly positive. Let $\hat{L}^\Lambda$ be the generator of another interacting particle system with rates $(\hat{c}_x(\cdot, \cdot))_{x \in \Z^d}$ such that the rates of $L$ and $\hat{L}^\Lambda$ agree for sites outside of the finite volume $\Lambda \Subset \Z^d$. 
   Denote the induced path measures on the space of $\Omega$-valued c\'adl\'ag paths $\sigma[0,\tau]$ up to time $\tau >0$ by $\mathbb{Q}_\omega$ respectively $\hat{\mathbb{Q}}_\omega^\Lambda$, where the initial condition $\sigma(0) = \omega$ is deterministic. Then the following Girsanov-type formula holds 
   \begin{align*}
    \frac{d \mathbb{Q}_\omega}{d\hat{\mathbb{Q}}^\Lambda_\omega} ( \sigma[0,\tau])
    =
    \exp\left(-\int_0^\tau \lambda(\sigma(s)) + \sum_{s \in [0,\tau]: \sigma_{\Lambda}(s_-) \neq \sigma_{\Lambda}(s)}\sum_{i \in \Lambda}\log\left(\frac{c_i(\sigma(s_-), \sigma_i(s))}{\hat{c}_i(\sigma(s_-), \sigma_i(s))}\right)\right), 
\end{align*}
where 
\begin{align*}
    \lambda(\eta) :=\sum_{i \in \Lambda}\left(c_i(\eta) - \hat{c}_i(\eta)\right),
\end{align*}
and $c_i(\eta)$ respectively $\hat{c}_i(\eta)$ are the total rates at which we see a flip at site $i$ when we are currently in configuration $\eta$, i.e.,
\begin{align*}
        c_i(\eta) = \sum_{\xi_i \neq \eta_i}c_i(\eta, \xi_i) \quad \text{respectively} \quad \hat{c}_i(\eta) = \sum_{\xi_i \neq \eta_i}\hat{c}_i(\eta, \xi_i). 
\end{align*}
\end{lemma}

In a similar form this appeared in \cite{pra_large_1993} in the context of large deviations for interacting particle systems. 
With this explicit transformation formula at hand, the problem described above can essentially be reduced to controlling the tails of a Poisson random variable and we obtain the following result. 

\begin{proposition}[Positive-mass property]\label{proposition:positive-mass}
Assume that the rates of an interacting particle system satisfy assumptions $\mathbf{(R1)}-\mathbf{(R4)}$. Then, for all $\tau >0$ and $\Lambda \Subset \Z^d$, there exists a constant $C(\tau, \Lambda) >0$ such that, for any starting measure $\nu$ and any time $t \in [\tau, \infty)$, we have
\begin{align*}
    \forall \eta \in \Omega: \quad \nu_t(\eta_\Lambda) \geq C(\tau, \Lambda). 
\end{align*}
In particular, for all subsequential limits $\nu^* = \lim_{n \to \infty}\nu_{t_n}$ with $t_n \uparrow \infty$, we have 
\begin{align*}
    \forall \eta \in \Omega \ \forall \Lambda \Subset \Z^d: \quad \nu^*(\eta_\Lambda) \geq  C(\tau, \Lambda) > 0. 
\end{align*}
\end{proposition}

On an intuitive level, the above result should be interpreted as a somewhat quantitative version of the diffusive nature of the dynamics. Even if we start our process with a point mass $\delta_\omega$ in $\omega \in \Omega$ as initial condition, the distribution of the process at time $t>0$ will already put positive mass on any cylinder set $[\eta_\Lambda]$. The proof of this can be found in Section~\ref{section:positive-mass}. 


\subsection{The zero finite-volume entropy loss property}

As a last step we then need to verify that, if a probability measure $\nu$ lies in the attractor $\mathscr{A}$ of the measure-valued dynamics induced by $\mathscr{L}$, then its time-derivative of the relative entropy vanishes in every finite volume $\Lambda \Subset \Z^d$. 

\begin{proposition}\label{proposition:zero-loss}
    Assume that the rates satisfy $\mathbf{(R1)-(R4)}$ and the specification satisfies $\mathbf{(S1)-(S3)}$. Then, for every $\nu \in \mathscr{A}$, it holds that for any $\Lambda \Subset \Z^d$, we have 
    \begin{align*}
        g^\mathscr{L}_\Lambda(\nu \lvert \mu) = 0. 
    \end{align*}
\end{proposition}

The main idea here is that by the fundamental theorem of calculus one has 
\begin{align*}
    h_\Lambda(\nu_t \lvert \mu) - h_\Lambda(\nu_0 \lvert \mu) = \int_0^t g^\mathscr{L}_\Lambda(\nu_s \lvert \mu) \ ds,
\end{align*}
and the difference on the left-hand side can be bounded from above and below by constants that do not depend on $t$ and $\nu$, but only on $\mu$ and $\Lambda$. By using Proposition~\ref{proposition:positive-mass} and continuity properties of the Markov semigroup and the functional $g^\mathscr{L}_\Lambda(\cdot \lvert \mu)$, one can then show that if $\nu$ is in the attractor, then its finite-volume relative entropy loss must vanish. The precise proof can be found in Section~\ref{section:zero-finite-volume-loss}. 

%5. Holley--Stroock principle: 
\section{Proof of the relative entropy loss principle}\label{section:holley-stroock-principle}
%5a. Characterisations reversibility
\subsection{Characterising reversible measures}
Before we start with characterising reversible measures we state a technical tool that is reminiscent of Lebesgue's differentiation theorem. 
\begin{lemma}[Differentiation lemma]\label{differentiation-lemma}
    Let $\mu$ be a probability measure on $\Omega$ such that we have $\mu(\eta_{\Lambda})>0$ for all $\Lambda \Subset \Z^d$ and $\eta \in \Omega$. 
    Then, for any continuous functions $f: \Omega \to \R$, we have that for all $\eta \in \Omega$
    \begin{align*}
         \lim_{\Lambda \uparrow \Z^d} \frac{1}{\mu(\eta_{\Lambda})}\int_{[\eta_{\Lambda}]}f(\xi)\mu(d\xi) = f(\eta). 
    \end{align*}
    Moreover, if $f$ is uniformly continuous, then the claimed convergence is also uniform in $\eta \in \Omega$. 
\end{lemma}

\begin{proof}
    First note that, for fixed $\Lambda \Subset \Z^d$, the compactness of $\Omega$ implies the trivial inequalities 
    \begin{align}\label{sandwich}
        - \infty < \inf_{\xi: \xi_{\Lambda}=\eta_{\Lambda}}f(\xi) \leq f(\eta) \leq \sup_{\xi: \xi_{\Lambda}=\eta_{\Lambda}}f(\xi) < \infty. 
    \end{align}
    The continuity of $f$ implies that 
    \begin{align*}
        \lim_{\Lambda \uparrow \Z^d}\inf_{\xi: \xi_{\Lambda}=\eta_{\Lambda}}f(\xi) = f(\eta), \quad \lim_{\Lambda \uparrow \Z^d}\sup_{\xi: \xi_{\Lambda}=\eta_{\Lambda}}f(\xi) = f(\eta).
    \end{align*} 
    Combining this with~\eqref{sandwich} and the squeeze theorem (for nets) from real analysis yields
    \begin{align*}
        \lim_{\Lambda \uparrow \Z^d} \frac{1}{\mu(\eta_{\Lambda})}\int_{[\eta_{\Lambda}]}f(\xi)\mu(d\xi) = f(\eta). 
    \end{align*}
    This concludes the proof. 
\end{proof}

With this technical helper at hand, we begin with the following standard result that provides us with alternative formulations of reversibility. These will turn out to be more convenient to work with.  

\begin{proposition}\label{proposition:characterizations-reversibility}
Consider an interacting particle system with generator $\mathscr{L}$ whose rates satisfy assumptions $\mathbf{(L1)}-\mathbf{(L2)}$ and $\mathbf{(R3)}$. Then, for a probability measure $\nu \in \calM_1(\Omega)$, the following conditions are equivalent. 
\begin{enumerate}[i.]
    \item $\nu$ is reversible. 
    \item For all $\Lambda \Subset \Z^d$, $x \in \Z^d$, $i \in \Omega_0$ and $\eta \in \Omega$ it holds that $\nu(\eta_\Lambda) >0$ and
    \begin{align*}
        \int_{[\eta_\Lambda]}c_x(\omega,i)\nu(d\omega)
        =
        \int_{[\eta_\Lambda^{x,i}]}c_x(\omega,\eta_x)\nu(d\omega). 
    \end{align*}
    \item For all $\Lambda \Subset \Z^d$ and $\eta \in \Omega$ we have $\nu(\eta_\Lambda) >0$ and the conditional marginals of $\nu$ satisfy the detailed balance condition, i.e., $\nu$-almost surely
    \begin{align*}
        \forall x \in \Z^d \ \forall \xi_x \in \Omega_0: \nu(\eta_x \lvert \eta_{x^c})c_x(\eta,\xi_x) = \nu(\xi_x \lvert \eta_{x^c})c_x(\xi_x \eta_{x^c},\eta_x). 
    \end{align*}
\end{enumerate}
\end{proposition}

\begin{proof}
    \textit{Ad $i. \Rightarrow ii.$: } As a first step, note that Proposition~\ref{proposition:positive-mass} applies to $\nu$ which yields $\nu(\eta_\Lambda) > 0$. By reversibility of $\nu$ we know that for all $f,g \in D(\Omega)$
    \begin{align*}
        \int_\Omega f(\omega) \mathscr{L}g(\omega) \nu(d\omega) = \int_\Omega g(\omega) \mathscr{L}f(\omega)\nu(d\omega). 
    \end{align*}
    For fixed $\eta \in \Omega$, $\Lambda \Subset \Z^d$, $x \in \Z^d$ and $i=1,\dots,q$ we can apply this to the functions 
    \begin{align*}
        f = \mathbf{1}_{[\eta_\Lambda]}, \quad g=\mathbf{1}_{[\eta_\Lambda^{x,i}]}. 
    \end{align*}
    Then we have
    \begin{align*}
        \int_\Omega f(\omega) \mathscr{L}g(\omega)
        &=
        \sum_{y \in \Z^d}\sum_{j=1}^q \int_\Omega c_y(\omega, j)\left[\mathbf{1}_{[\eta_\Lambda]}(\omega)\mathbf{1}_{[\eta_\Lambda^{x,i}]}(\omega^{y,j}) - \mathbf{1}_{[\eta_\Lambda]}(\omega)\mathbf{1}_{[\eta_\Lambda^{x,i}]}(\omega)\right]\nu(d\omega)
        \\\
        &=
        \int_\Omega c_x(\omega,i)\mathbf{1}_{[\eta_\Lambda]}(\omega)\nu(d\omega). 
    \end{align*}
    On the other hand 
    \begin{align*}
        \int_\Omega g(\omega) \mathscr{L}f(\omega)
        &=
        \sum_{y \in \Z^d}\sum_{j=1}^q \int_\Omega c_y(\omega, j)\left[\mathbf{1}_{[\eta_\Lambda]}(\omega^{y,j})\mathbf{1}_{[\eta_\Lambda^{x,i}]}(\omega) - \mathbf{1}_{[\eta_\Lambda]}(\omega)\mathbf{1}_{[\eta_\Lambda^{x,i}]}(\omega)\right]\nu(d\omega)
        \\\
        &=
        \int_\Omega c_x(\omega,\eta_x)\mathbf{1}_{[\eta_\Lambda^{x,i}]}(\omega)\nu(d\omega).
    \end{align*}
    So the assumed reversibility of $\nu$ implies
    \begin{align*}
         \int_\Omega c_x(\omega,i)\mathbf{1}_{[\eta_\Lambda]}(\omega)\nu(d\omega)
        =
        \int_\Omega c_x(\omega,\eta_x)\mathbf{1}_{[\eta_\Lambda^{x,i}]}(\omega)\nu(d\omega).
    \end{align*}
    \medskip 

    \noindent 
    \textit{Ad $ii. \Rightarrow iii.$: } We have 
    \begin{align*}
    \int_{[\eta_\Lambda]}c_x(\omega,i)\nu(d\omega) = \int_{[\eta_\Lambda^{x,i}]}c_x(\omega, \eta_x)\nu(d\omega). 
    \end{align*}
    So in particular we get 
    \begin{align*}
    \frac{\nu(\eta_\Lambda)}{\nu(\eta_\Lambda)}\int_{[\eta_\Lambda]}c_x(\omega,i)\nu(d\omega)
    =
    \frac{\nu(\eta_\Lambda^{x,i})}{\nu(\eta_\Lambda^{x,i})}\int_{[\eta_\Lambda^{x,i}]}c_x(\omega, \eta_x)\nu(d\omega). 
    \end{align*}
    Now let us rearrange this to get 
    \begin{align*}
    \frac{\nu(\eta_\Lambda)}{\nu(\eta_{\Lambda}^{x,i})}
    =
    \frac{\nu(\eta_\Lambda^{x,i})^{-1}\int_{[\eta_\Lambda^{x,i}]}c_x(\omega,\eta_x)\nu(d\omega)}{\nu(\eta_\Lambda)^{-1}\int_{[\eta_\Lambda]c_x(\omega,i)\nu(d\omega)}}. 
    \end{align*}
    By Lemma \ref{differentiation-lemma} the right hand side converges to 
    \begin{align*}
    \frac{c_x(\eta^{x,i}, \eta_x)}{c_x(\eta,i)}
    \end{align*}
    and by martingale convergence the left hand side converges almost surely to 
    \begin{align*}
    \frac{\nu(\eta_x \lvert \eta_{x^c})}{\nu(i \lvert \eta_{x^c})}.
    \end{align*}
    After rearranging this is simply the detailed balance equation. 
    \medskip 

    \noindent 
    \textit{Ad $iii. \Rightarrow i.$: } Here it suffices to show that, for all local functions $f,g : \Omega \to \R$, it holds that 
    \begin{align*}
        \int_\Omega f(\omega) \mathscr{L}g(\omega) \nu(d\omega) = \int_\Omega g(\omega) \mathscr{L}f(\omega) \nu(d\omega). 
    \end{align*}
    To do this, one can proceed exactly as in the proof of \cite[Lemma 3.1]{jahnel_dynamical_2022}. 
\end{proof}

Let us briefly summarise the main implications of Proposition~\ref{proposition:characterizations-reversibility} for what is to come. On the one hand, since we assume that our interacting particle system admits a reversible measure $\mu$ that is a Gibbs measure with respect to a non-null specification $\gamma$, we see that $\mu$-almost surely 
\begin{align*}
    c_x(\eta, i) \gamma_x(\eta_x \lvert \eta_{x^c}) = c_x(\eta^{x,i}, \eta_x) \gamma_x(i \lvert \eta_{x^c}). 
\end{align*}
In particular, every other measure $\mu' \in \mathscr{G}(\gamma)$ is also reversible for our process.
On the other hand, the above characterisation tells us that, in order to show that a measure $\nu$ is reversible, we actually only need to show that it satisfies $\nu(\eta_\Lambda) > 0$ for all $\Lambda \Subset \Z^d$ and $\eta \in \Omega$ and that, for all $x \in \Z^d$ and $i \in \Omega_0$, it holds that 
\begin{align*}
    \int_{[\eta_\Lambda]}c_x(\omega,i)\nu(d\omega)
        =
    \int_{[\eta_\Lambda^{x,i}]}c_x(\omega,\eta_x)\nu(d\omega). 
\end{align*}
So our goal will be to show that if $\nu \in \calM_1(\Omega)$ is such that $g^\mathscr{L}_\Lambda(\nu \lvert \mu) = 0$ for all $\Lambda$, then it necessarily satisfies this equation. 
%5b. Finite volume loss: 
\subsection{Finite-volume relative entropy loss}
We now proceed by obtaining a more convenient representation of the relative entropy loss in the finite cube $\Lambda_n = [-n,n]^d$. Recall that the relative entropy loss in the finite volume $\Lambda_n$ is defined by 
\begin{align*}
    g^n_{\mathscr{L}}(\nu|\mu) 
    := \frac{d}{dt}\Big \lvert_{t=0}h_{\Lambda_n}( \nu_t\lvert \mu), \quad \nu \in \calM_1(\Omega). 
\end{align*}

The first step in our proof of Proposition ~\ref{proposition:holley-stroock-principle} is the following very convenient rewriting of the relative entropy loss in a finite volume $\Lambda$. This first appeared in in \cite{moulin_ollagnier_free_1977} and is really the backbone of the whole proof technique. 
We will come back to the importance of this representation in Section~\ref{section:generalisations}, where we discuss possible directions for future generalisations. 

\begin{lemma}\label{lemma:finite-volume-relative-entropy-loss}
    For $n\in \N$ and $\nu \in \calM_1(\Omega)$ we have 
    \begin{align*}
        2 g^n_{\mathscr{L}}(\nu|\mu) 
        =
    -&\sum_{\eta_{\Lambda_n}}\sum_{x \in \Lambda_n}\sum_{i\neq \eta_x}
    \left[\Gamma_n(x,\eta_x,\eta^{x,i})-\Gamma_n(x,i,\eta) \right]
    \log\left(\frac{\Gamma_n(x, \eta_x, \eta^{x,i})}{\Gamma_n(x,i,\eta)}\right)
    \\\
    +
    &\sum_{\eta_{\Lambda_n}}\sum_{x \in \Lambda_n}\sum_{i\neq \eta_x}
    \left[\Gamma_n(x,\eta_x,\eta^{x,i})-\Gamma_n(x,i,\eta) \right]
    \\\
    &\quad 
    \times \left\{
        \log\left(\frac{\nu(\eta_{\Lambda_n})}{{\Gamma_n(x,i,\eta)}}\right)
        -
        \log\left(\frac{\nu(\eta^{x,i}_{\Lambda_n})}{\Gamma_n(x,\eta_x, \eta^{x,i})}\right)
        -
        \log\left(\frac{\mu(\eta_{\Lambda_n})}{\mu(\eta_{\Lambda_n}^{x,i})}\right)
        \right\}, 
    \end{align*}
    where we introduce the notation 
    \begin{align*}
    \Gamma_n(x,j,\eta) := \int_{[\eta_{\Lambda_n}]}c_x(\omega, j)\nu(d\omega). 
    \end{align*}
\end{lemma}
Before we start with the proof, note that by Proposition \ref{proposition:characterizations-reversibility}, our goal will be to show that, for all $x \in \Lambda_n$ and $i\in \Omega_0$, we have $\Gamma_n(x,i,\eta) = \Gamma_n(x,\eta_x, \eta^{x,i})$. 
\begin{proof}
    This can be seen by a direct calculation using the definition of the generator and some subsequent algebraic manipulations. We have 
    \begin{align*}
        g^n_{\mathscr{L}}(\nu\lvert \mu) 
        &=
        \sum_{\eta_{\Lambda_n}}
            \nu(\mathscr{L}\mathbf{1}_{\eta_{\Lambda_n}})
            \log
            \left(
                \frac{\nu(\eta_{\Lambda_n})}{\mu(\Lambda_n)}
            \right)
        \\\
        &=
        \sum_{\eta_{\Lambda_n}}\sum_{x \in \Lambda_n}\sum_{j=1}^q
            \int \nu(d\omega)
                c_x(\omega, j)
                \left[
                    \mathbf{1}_{\eta_{\Lambda_n}}(\omega^{x,j}) 
                    -
                    \mathbf{1}_{\eta_{\Lambda_n}}(\omega)
                    \right]
            \log
            \left(
                \frac{\nu(\eta_{\Lambda_n})}{\mu(\eta_{\Lambda_n})}
            \right).
    \end{align*}
    Now let us rewrite this a little bit to bring it into the nicer form
    \begin{align*}
        g^n_{\mathscr{L}}(\nu|\mu) 
        &=
        \sum_{\eta_{\Lambda_n}}\sum_{x \in \Lambda_n}\sum_{i\neq \eta_x}
        \left[\int_{[\eta_{\Lambda_n}^{x,i}]}c_x(\omega, \eta_x)\nu(d\omega) - \int_{[\eta_{\Lambda_n}]}c_x(\omega,i)\nu(d\omega)\right]\log\left(\frac{\nu(\eta_{\Lambda_n})}{\mu(\eta_{\Lambda_n})}\right).
    \end{align*}
     With the notation introduced above this can be written as
    \begin{align*}
        g^n_{\mathscr{L}}(\nu|\mu) 
        &=
        \sum_{\eta_{\Lambda_n}}\sum_{x \in \Lambda_n}\sum_{i\neq \eta_x}
        \left[\Gamma_n(x,\eta_x,\eta^{x,i})-\Gamma_n(x,i,\eta) \right]
        \log\left(\frac{\nu(\eta_{\Lambda_n})}{\mu(\eta_{\Lambda_n})}\right)
        \\\
        &= 
        \frac{1}{2} \sum_{\eta_{\Lambda_n}}\sum_{x \in \Lambda_n}\sum_{i\neq \eta_x}
        \left[\Gamma_n(x,\eta_x,\eta^{x,i})-\Gamma_n(x,i,\eta) \right]
        \log\left(\frac{\nu(\eta_{\Lambda_n})}{\mu(\eta_{\Lambda_n})}\frac{\mu(\eta_{\Lambda_n}^{x,i})}{\nu(\eta_{\Lambda_n}^{x,i})}\right)
        \\\
        &= 
        \frac{1}{2} \sum_{\eta_{\Lambda_n}}\sum_{x \in \Lambda_n}\sum_{i\neq \eta_x}
        \left[\Gamma_n(x,\eta_x,\eta^{x,i})-\Gamma_n(x,i,\eta) \right]
        \log\left(\frac{\nu(\eta_{\Lambda_n})}{\nu(\eta_{\Lambda_n}^{x,i})}\right)
        \\\
        &\ -
        \frac{1}{2}\sum_{\eta_{\Lambda_n}}\sum_{x \in \Lambda_n}\sum_{i\neq \eta_x}
        \left[\Gamma_n(x,\eta_x,\eta^{x,i})-\Gamma_n(x,i,\eta) \right]
        \log\left(\frac{\mu(\eta_{\Lambda_n})}{\mu(\eta_{\Lambda_n}^{x,i})}\right).
    \end{align*}
    Now we add and substract some terms to obtain
    \begin{align*}
    2 g^n_{\mathscr{L}}(\nu|\mu) 
    =
    -&\sum_{\eta_{\Lambda_n}}\sum_{x \in \Lambda_n}\sum_{i\neq \eta_x}
    \left[\Gamma_n(x,\eta_x,\eta^{x,i})-\Gamma_n(x,i,\eta) \right]
    \log\left(\frac{\Gamma_n(x, \eta_x, \eta^{x,i})}{\Gamma_n(x,i,\eta)}\right)
    \\\
    +
    &\sum_{\eta_{\Lambda_n}}\sum_{x \in \Lambda_n}\sum_{i\neq \eta_x}
    \left[\Gamma_n(x,\eta_x,\eta^{x,i})-\Gamma_n(x,i,\eta) \right]
    \\\
    &\quad \times \left\{
        \log\left(\frac{\nu(\eta_{\Lambda_n})}{\nu(\eta_{\Lambda_n}^{x,i})}\right)
        -
        \log\left(\frac{\mu(\eta_{\Lambda_n})}{\mu(\eta_{\Lambda_n}^{x,i})}\right)
        +
        \log\left(\frac{\Gamma_n(x, \eta_x, \eta^{x,i})}{\Gamma_n(x,i,\eta)}\right)
    \right\}
    \\\
    =
    -&\sum_{\eta_{\Lambda_n}}\sum_{x \in \Lambda_n}\sum_{i\neq \eta_x}
    \left[\Gamma_n(x,\eta_x,\eta^{x,i})-\Gamma_n(x,i,\eta) \right]
    \log\left(\frac{\Gamma_n(x, \eta_x, \eta^{x,i})}{\Gamma_n(x,i,\eta)}\right)
    \\\
    +
    &\sum_{\eta_{\Lambda_n}}\sum_{x \in \Lambda_n}\sum_{i\neq \eta_x}
    \left[\Gamma_n(x,\eta_x,\eta^{x,i})-\Gamma_n(x,i,\eta) \right]
    \\\
    &\quad 
    \times \left\{
        \log\left(\frac{\nu(\eta_{\Lambda_n})}{{\Gamma_n(x,i,\eta)}}\right)
        -
        \log\left(\frac{\nu(\eta^{x,i}_{\Lambda_n})}{\Gamma_n(x,\eta_x, \eta^{x,i})}\right)
        -
        \log\left(\frac{\mu(\eta_{\Lambda_n})}{\mu(\eta_{\Lambda_n}^{x,i})}\right)
    \right\},
\end{align*}
which yields the claim. 
\end{proof}
%5c. Quantitative differentiation lemma: 
\subsection{A quantitative differentiation lemma}

To control the terms in the second sum in Lemma~\ref{lemma:finite-volume-relative-entropy-loss}, one can consider the following technical helper that tells us that the quotients of $\mu$ are actually approximating the conditional marginals of $\mu$ which are given by $\gamma$. Indeed, by using Lemma~\ref{differentiation-lemma} one can easily show the following convergence. 

\begin{lemma}\label{lemma:uniform-convergence-conditional-probabilities}
    Let $\mu \in \mathscr{G}(\gamma)$ and assume that the specification $\gamma$ is quasilocal and non-null. 
    Let $x \in \Z^d$ and fix $i\in \Omega_0$. Then, the following convergence holds uniform in $\eta \in \Omega$
    \begin{align*}
        \frac{\mu(\eta_{\Lambda_n})}{\mu(\eta^{x,i}_{\Lambda_n})} 
        \to 
        \frac{\gamma_x(\eta_x| \eta_{x^c})}{\gamma_x(i| \eta_{x^c})} 
        \quad 
        \text{as } n \to \infty.  
    \end{align*}
\end{lemma}

However, the above result does not give us any quantitative control over the speed of convergence. Therefore we have to use a tool that gives us a more precise result than Lemma \ref{differentiation-lemma}. 
For this, recall the notation
\begin{align*}
    \delta_x f  = \sup_{\eta \in \Omega, i \in \Omega_0}\abs{f(\eta^{x,i})-f(\eta)}.
\end{align*}

Now, as a first step towards getting a quantitative bound on the error term in Lemma~\ref{lemma:uniform-convergence-conditional-probabilities}, we obtain a quantitative version of Lemma~\ref{differentiation-lemma} in terms of the oscillations of $f$. 

\begin{lemma}\label{lemma:quantitative-differentiation}
    Let $\nu$ be a probability measure such that $\nu(\eta_{\Lambda})>0$ for all $\eta_{\Lambda}$. Then, for any function $f:\Omega \to \R$ with the property 
    \begin{align*}
        \sum_{x \in \Z^d}\delta_x f < \infty,
    \end{align*}
    the following uniform error estimate holds for all $\eta \in \Omega$
    \begin{align*}
        \abs{\frac{1}{\nu(\eta_\Lambda)}\int_{[\eta_\Lambda]}f(\omega)\nu(d\omega) - f(\eta)}
        \leq 
        \sum_{x \notin \Lambda}\delta_x f. 
    \end{align*}
\end{lemma}

\begin{proof}
    Fix $\eta \in \Omega$ and $\Lambda \Subset \Z^d$. Then we can fix an enumeration of the vertices in $\Lambda^c$ and write 
    $$[n] = \Lambda \cup \{x_1, \dots, x_n\}.$$ 
    By a telescope sum we see
    \begin{align*}
        f(\eta) - f(\omega)
        = \sum_{n=1}^\infty\left(f(\eta_{[n]}\omega_{[n]^c})-f(\eta_{[n-1]}\omega_{[n-1]^c})\right)
        \leq 
        \sum_{x \notin \Lambda}\delta_x f. 
    \end{align*}
    The claim now follows via integration. 
\end{proof}

Now let us apply this result to obtain a quantitative version of the convergence of conditional probabilities. Here we will use the short-hand notation
\begin{align*}
    \delta_y \gamma_x(\cdot) := \sup_{\omega \in \Omega, i \in \Omega_0}\abs{\gamma_x(\omega_x \lvert \omega_{x^c}^{y,i}) - \gamma_x(\omega_x \lvert \omega_{x^c})}, \quad x\neq y \in \Z^d. 
\end{align*}
This quantity tells us how much the conditional distribution of the particle at site $x$ depends on the state of the particle at a different site $y$. 
\begin{lemma}
     Let $\mu \in \mathscr{G}(\gamma)$ and assume that the specification $\gamma$ is quasilocal and non-null with constant $\delta >0$. Let $x \in \Z^d$ and fix $i \in \Omega_0$. Then, for all $\eta \in \Omega$ and $\Lambda \Subset \Z^d$, it holds that 
    \begin{align}
        \abs{\frac{\mu(\eta_{\Lambda})}{\mu(\eta_{\Lambda}^{x,i})}-\frac{\gamma_x(\eta_x \lvert \eta_{x^c})}{\gamma_x(i\lvert \eta_{x^c})}} \leq
        \frac{2}{\delta^2}\sum_{y \notin \Lambda}\delta_y \gamma_x(\cdot). 
    \end{align}
\end{lemma}

\begin{proof}
   As a first step, note that we can write
   \begin{align*}
       \frac{\mu(\eta_{\Lambda})}{\mu(\eta_{\Lambda_n}^{x,i})} = \frac{\mu(\eta_x \lvert \eta_{\Lambda \setminus \{x\}})}{\mu(i \lvert \eta_{\Lambda_n \setminus \{x\}})}.
   \end{align*}
   We first show uniform error bounds for the denominator and the numerator. For this, observe that the DLR equations imply 
   \begin{align*}
       \mu(\eta_x \lvert \eta_{\Lambda \setminus \{x\}}) = \frac{1}{\mu( \eta_{\Lambda \setminus \{x\}})}\int_{ [\eta_{\Lambda \setminus \{x\}}]}\gamma_x(\eta_x \lvert \omega_{x^c})\mu(d\omega). 
   \end{align*}
   To this  we can now apply the quantitative differentiation lemma to obtain 
   \begin{align*}
       \abs{ \mu(\eta_x \lvert \eta_{\Lambda \setminus  \{x\}}) - \gamma_x(\eta_x \lvert \eta_{x^c})} \leq \sum_{y \notin \Lambda}\delta_y \gamma_x(\cdot). 
   \end{align*}
   Analogously we obtain 
   \begin{align*}
       \abs{ \mu(i\lvert \eta_{\Lambda \setminus  \{x\}}) - \gamma_x(i \lvert \eta_{x^c})} \leq \sum_{y \notin \Lambda}\delta_y \gamma_x(\cdot). 
   \end{align*}
   Now we can use the simple algebraic rule 
   \begin{align*}
       ad - bc =  \frac{1}{2}[(a-b)(c+d) - (a+b)(c-d)]
   \end{align*}
   in conjunction with the non-nullness of $\gamma$, and hence $\mu$, to obtain the inequality
   \begin{align*}
       \abs{\frac{\mu(\eta_{\Lambda})}{\mu(\eta_{\Lambda_n}^{x,i})} - \frac{\gamma_x(\eta_x \lvert \eta_{x^c})}{\gamma_x(i\lvert \eta_{x^c})}}
       \leq 
       \frac{2}{\delta^2}\sum_{y \notin \Lambda}\delta_y \gamma_x(\cdot), 
   \end{align*}
   as desired.
\end{proof}
%5d. First estimate 
\subsection{The zero-loss equation}
The previously derived representation of the relative entropy loss in finite boxes $\Lambda_n$ directly implies the following equation in case the relative entropy loss vanishes. 
\begin{lemma}\label{lemma:zero-loss-equation}
Let $\nu$ be a probability measure such that $\nu(\eta_{\Lambda_n})>0$ for all $\eta$ and assume that $g^n_{\mathscr{L}}(\nu \lvert \mu) = 0$, then we have 
\begin{align*}
    &\sum_{\eta_{\Lambda_n}}\sum_{x \in \Lambda_n}\sum_{i\neq \eta_x}
    \left[\Gamma_n(x,\eta_x,\eta^{x,i})-\Gamma_n(x,i,\eta) \right]
    \log\left(\frac{\Gamma_n(x, \eta_x, \eta^{x,i})}{\Gamma_n(x,i,\eta)}\right)
    \\\
    =
    &\sum_{\eta_{\Lambda_n}}\sum_{x \in \Lambda_n}\sum_{i\neq \eta_x}
    \left[\Gamma_n(x,\eta_x,\eta^{x,i})-\Gamma_n(x,i,\eta) \right]
    \\\
    &\quad 
    \times \left\{
        \log\left(\frac{\nu(\eta_{\Lambda_n})}{{\Gamma_n(x,i,\eta)}}\right)
        -
        \log\left(\frac{\nu(\eta^{x,i}_{\Lambda_n})}{\Gamma_n(x,\eta_x, \eta^{x,i})}\right)
        -
        \log\left(\frac{\mu(\eta_{\Lambda_n})}{\mu(\eta_{\Lambda_n}^{x,i})}\right)
        \right\}.  
\end{align*}
\end{lemma}

We now want to estimate the terms appearing in this equation with the final goal to show that every term on the right-hand side actually vanishes. 
For this, let us first introduce some more notation, 
\begin{align*}
    \alpha_n(x) &= \sum_{\eta_{\Lambda_n}}\sum_{i \neq \eta_x}\left[\Gamma_n(x,\eta_x,\eta^{x,i})-\Gamma_n(x,i,\eta) \right]
    \log\left(\frac{\Gamma_n(x, \eta_x, \eta^{x,i})}{\Gamma_n(x,i,\eta)}\right), 
    \\\
    \beta_n(x) &= \sum_{\eta_{\Lambda_n}}\sum_{i \neq \eta_x}\lvert\Gamma_n(x,\eta_x,\eta^{x,i})-\Gamma_n(x,i,\eta) \rvert,
    \\\
    \rho_n(x) &= \sum_{y \notin \Lambda_n}\left(\delta_y \gamma_x(\cdot) + \delta_y c_x(\cdot)\right). 
\end{align*}

\begin{lemma}\label{lemma:upper-bound-alpha}
    Suppose that $\nu$ is such that $\nu(\eta_{\Lambda_n})>0$ for all $\eta_{\Lambda_n}$ and $g^n_\mathscr{L}(\nu  \lvert \mu) = 0$, then there exists a constant $C > 0$ that does not depend on $n$ such that 
    \begin{align*}
        \sum_{x \in \Lambda_n}\alpha_n(x) \leq C \sum_{x\in \Lambda_n}\beta_n(x)\rho_n(x). 
    \end{align*}
\end{lemma}

\begin{proof}
By Lemma~\ref{lemma:zero-loss-equation} it suffices to show that, for all $x \in \Lambda_n$ and $ \eta_{\Lambda_n}$, we have
    \begin{align*}
           \left\lvert 
        \log\left(\frac{\nu(\eta_{\Lambda_n})}{{\Gamma_n(x,i,\eta)}}\right)
        -
        \log\left(\frac{\nu(\eta^{x,i}_{\Lambda_n})}{\Gamma_n(x,\eta_x, \eta^{x,i})}\right)
        -
        \log\left(\frac{\mu(\eta_{\Lambda_n})}{\mu(\eta_{\Lambda_n}^{x,i})}\right)
        \right\rvert 
        \leq 
        \rho_n(x).
    \end{align*}
    To do this, we introduce a reference configuration $\Bar{\eta}$ defined by 
    \begin{align*}
        \overline{\eta} 
        =
        \begin{cases}
        \eta_y, \quad &\text{if $y \in \Lambda_n$}, \\\
        1, &\text{otherwise}. 
        \end{cases}
    \end{align*}
    and add and subtract terms of the form 
    \begin{align*}
        \log\left(c_x(\overline{\eta},i)\gamma_x(\eta_x \lvert \overline{\eta}_{x^c}) \right).
    \end{align*}
    By detailed balance we have
    \begin{align*}
        c_x(\overline{\eta},i)\gamma_x(\eta_x \lvert \overline{\eta}_{x^c})
        =
        c_x(\overline{\eta}^{x,i},\eta_x)\gamma_x(i \lvert \overline{\eta}_{x^c}). 
    \end{align*}
    So we actually just need to add (or subtract)
    \begin{align*}
        0 = \log\left(\frac{c_x(\overline{\eta},i)\gamma_x(\eta_x \lvert \overline{\eta}_{x^c})}{c_x(\overline{\eta}^{x,i},\eta_x)\gamma_x(i \lvert \overline{\eta}_{x^c})}\right).
    \end{align*}
    For every term in the sum above this gives us 
    \begin{align*}
        &\left\lvert
        \log\left(\frac{\nu(\eta_{\Lambda_n})}{{\Gamma_n(x,i,\eta)}}\right)
        -
        \log\left(\frac{\nu(\eta^{x,i}_{\Lambda_n})}{\Gamma_n(x,\eta_x, \eta^{x,i})}\right)
        -
        \log\left(\frac{\mu(\eta_{\Lambda_n})}{\mu(\eta_{\Lambda_n}^{x,i})}\right)
        +
        \log\left(\frac{c_x(\overline{\eta},i)\gamma_x(\eta_x \lvert \overline{\eta}_{x^c})}{c_x(\overline{\eta}^{x,i},\eta_x)\gamma_x(i \lvert \overline{\eta}_{x^c})}\right)
        \right\rvert 
        \\\
        =
        &\left\lvert 
        \log\left(\frac{\nu(\eta_{\Lambda_n})c_x(\overline{\eta},i)}{{\Gamma_n(x,i,\eta)}} \right)
        -
\log\left(\frac{\nu(\eta^{x,i}_{\Lambda_n})c_x(\overline{\eta}^{x,i},\eta_x)}{\Gamma_n(x,\eta_x, \eta^{x,i})}\right)
        -
        \log\left(\frac{\mu(\eta_{\Lambda_n})}{\mu(\eta_{\Lambda_n}^{x,i})}\frac{\gamma_x(i\lvert \overline{\eta}_{x^c})}{\gamma_x(\eta_x \lvert \overline{\eta}_{x^c})}\right)
        \right\rvert.
    \end{align*}
    By assumption $\mathbf{(R3)}$ and $\mathbf{(S2)}$ we know that all the terms in the logarithms are bounded away from $0$, so we can use the Lipschitz continuity of $\log(\cdot)$ away from $0$, apply  Lemma~\ref{lemma:quantitative-differentiation} to the first two terms and Lemma~\ref{lemma:uniform-convergence-conditional-probabilities} to the third term to obtain the estimate 
    \begin{align*}
        &\left\lvert 
        \log\left(\frac{\nu(\eta_{\Lambda_n})c_x(\overline{\eta},i)}{{\Gamma_n(x,i,\eta)}} \right)
        -\log\left(\frac{\nu(\eta^{x,i}_{\Lambda_n})c_x(\overline{\eta}^{x,i},\eta_x)}{\Gamma_n(x,\eta_x, \eta^{x,i})}\right)
        -
        \log\left(\frac{\mu(\eta_{\Lambda_n})}{\mu(\eta_{\Lambda_n}^{x,i})}\frac{\gamma_x(i\lvert \overline{\eta}_{x^c})}{\gamma_x(\eta_x \lvert \overline{\eta}_{x^c})}\right)
        \right\rvert
        \\\
        \leq 
        &L\Bigg(
        \abs{c_x(\Bar{\eta},i)-\frac{\Gamma_n(x,i,\eta)}{\nu(\eta_{\Lambda_n})}}
        +
        \abs{c_x(\Bar{\eta}^{x,i},\eta_x) - \frac{\Gamma_n(x,\eta_x, \eta^{x,i})}{\nu(\eta^{x,i}_{\Lambda_n})}}
        +
        \abs{\frac{\mu(\eta_{\Lambda_n})}{\mu(\eta_{\Lambda_n}^{x,i})} - \frac{\gamma_x(\eta_x \lvert \bar{\eta}_{x^c})}{\gamma_x(i\lvert \Bar{\eta}_{x^c})}}\Bigg)
        \\\
        \leq 
        &\frac{2L}{\delta^2} \sum_{y \notin \Lambda_n} \left( \delta_y c_x(\cdot) + \delta_y \gamma_x(\cdot) \right), 
    \end{align*}
    where $\delta >0$ is the non-nullness constant of the specification $\gamma$.  
\end{proof}
%5e. Monotonicity

As a next step,  we will show that the quantity $\alpha_n(x)$ is non-decreasing in $n$. Also note that each summand in the definition of $\alpha_n(x)$ is actually non-negative.  
\begin{lemma}\label{lemma:monotonicity-alpha}
    For all $n \in \N$ and $x \in \Lambda_n \subset  \Lambda_{n+1}$ it holds that 
    \begin{align*}
        0 \leq \alpha_n(x) \leq \alpha_{n+1}(x). 
    \end{align*}
\end{lemma}
\begin{proof}
    Define the function 
    \begin{align*}
        \Phi(u,v) = (u-v)\log\left(\frac{u}{v}\right), \quad u,v >0. 
    \end{align*}
    Then $\Phi$ is convex and homogeneous of degree one, i.e., $\Phi(\lambda u, \lambda v) = \lambda \Phi(u,v)$ for all $\lambda > 0$. This implies that it is subadditive. Indeed, for all $u_1, u_2, v_1, v_2>0$ we have that 
    \begin{align*}
        \Phi(u_1 + u_2, v_1 + v_2) 
        &= 
        2\Phi\left( \frac{1}{2}u_1+\frac{1}{2}u_2, \frac{1}{2}v_1 + \frac{1}{2}v_2\right)
        \\\
        &\leq 
        2\left[ \frac{1}{2}\Phi(u_1, v_1) + \frac{1}{2}\Phi(u_2, v_2)\right]
        =
        \Phi(u_1,v_2) + \Phi(u_2, v_2). 
    \end{align*}
    We can rewrite $\alpha_n(x)$ and $\alpha_{n+1}(x)$ in terms of $\Phi$ as 
    \begin{align*}
        \alpha_n(x) &= \sum_{\eta_{\Lambda_n}}\sum_{i \neq \eta_x}\Phi\left(\Gamma_n(x, i, \eta_{\Lambda_n}), \Gamma_n(x, \eta_x, \eta^{x,i}_{\Lambda_n})\right),\\\
        \alpha_{n+1}(x) &= \sum_{\eta_{\Lambda_{n+1}}}\sum_{i \neq \eta_x}\Phi\left(\Gamma_{n+1}(x, i, \eta_{\Lambda_n}), \Gamma_{n+1}(x, \eta_x, \eta^{x,i}_{\Lambda_{n+1}})\right). 
    \end{align*}
    Since we have 
     \begin{align*}
         \Gamma_n(x,i,\eta_{\Lambda_n}) = \sum_{\xi_{\Lambda_{n+1}}: \xi_{\Lambda_{n}} = \eta_{\Lambda_n}}\Gamma_{n+1}(x,i,\xi_{\Lambda_{n+1}}),
     \end{align*}
     the claim follows from the subadditivity of $\Phi$. 
\end{proof}
%5f. Second estimate 
Let us briefly pause here and discuss what we have shown so far and where we are headed. We want to show that all of the terms $\alpha_n(x)$ vanish and in Lemma~\ref{lemma:upper-bound-alpha} we have established the inequality 
\begin{align*}
    0 \leq \sum_{x \in \Lambda_n} \alpha_n(x) \leq \sum_{x \in \Lambda_n}\beta_n(x) \rho_n(x). 
\end{align*}
Now if we were able to show that we can control the terms $\beta_n(x)$ in terms of $\alpha_n(x)$, then a sufficiently fast decay of $\rho_n(x)$ should allow us to conclude that the $\alpha_n(x)$ vanish. But this decay is implied by our assumptions.  
Therefore, our strategy will be the following. We first estimate $\beta_n(x)$ in terms of $\alpha_n(x)$ and then put everything together at the end of the section to prove Proposition~\ref{proposition:holley-stroock-principle}. 

\begin{lemma}\label{lemma:upper-bound-beta}
    For all $n \in \N$ and $x \in \Lambda_n$ it holds that 
    \begin{align*}
        \beta_n(x)^2 \leq |\Omega_0| \cdot \sup_{\omega, i}\abs{c_x(\omega,i)}\alpha_n(x). 
    \end{align*}

\end{lemma}

\begin{proof}
    Here we can use the symmetry and subadditivity of $\Phi$ to show that 
    \begin{align*}
        \alpha_n(x)
        =
        \sum_{\eta_{\Lambda_n}}\sum_{i\neq \eta_x}\Phi\left(\Gamma_n(x,i,\eta_{\Lambda_n}), \Gamma(x,\eta_x, \eta_{\Lambda_n}^{x,i})\right)
        \geq 
        \Phi(M,m),
    \end{align*}
    where we use the notation
    \begin{align*}
        M &= \sum_{\eta_{\Lambda_n}}\sum_{i\neq \eta_x}\max\left\{\Gamma_n(x,i, \eta_{\Lambda_n}), \Gamma_n(x,\eta_x, \eta^{x,i}_{\Lambda_n})\right\},
        \\\
        m &= \sum_{\eta_{\Lambda_n}}\sum_{i\neq \eta_x}\min\left\{\Gamma_n(x,i, \eta_{\Lambda_n}), \Gamma_n(x,\eta_x, \eta^{x,i}_{\Lambda_n})\right\}. 
    \end{align*}
    Since we have 
    \begin{align*}
        \beta_n(x) = M - m
    \end{align*}
    and the trivial bound 
    \begin{align*}
        M \leq |\Omega_0| \sup_{\omega, i} c_x(\omega,i), 
    \end{align*}
    the claimed inequality follows from the fact that
    \begin{align*}
        u - v \leq u \log \frac{u}{v}, \quad 0 < v \leq u. 
    \end{align*}
    Indeed, by the above calculations we have 
    \begin{align*}
        \alpha_n(x) \cdot M \geq (M-m)\log\left(\frac{M}{m}\right) \cdot M 
        \geq (M-m)^2 = \beta_n(x)^2. 
    \end{align*}
    Using the previously derived upper bound on $M$ now yields the claim. 
\end{proof}

%5g. Conclusion

With all of these rather technical estimates in place, we are finally ready to prove Proposition~\ref{proposition:holley-stroock-principle}. 

\begin{proof}[Proof of Proposition \ref{proposition:holley-stroock-principle}]
Recall that our goal is to show that $\alpha_n(x) = 0$ for every $n \in \N$ and $x\in \Lambda_n$. As a first step we will show that it suffices to prove that 
\begin{align*}
    \mathbf{C}_1 := \sup_{x \in \Z^d} \sum_{n=1}^\infty \rho_n(x) < \infty\quad\text{ and }\quad \mathbf{C}_2 := \sup_{n \in \N} \frac{1}{n^{d-1}}\sum_{x \in \Lambda_n} \rho_n(x) < \infty. 
\end{align*}
Indeed, if this is the case then we can first combine Lemma~\ref{lemma:upper-bound-alpha} and Lemma  \ref{lemma:upper-bound-beta} to obtain the inequality
\begin{align*}
    \sum_{x \in \Lambda_n} \alpha_n(x) \leq C \sum_{x \in \Lambda_n}\rho_n(x) \sqrt{\alpha_n(x)}
\end{align*}
for some constant $C > 0$. By the Cauchy--Schwarz inequality for sums this implies 
\begin{align}\label{ineq:cauchy-schwarz-bound}
    \left[\sum_{x \in \Lambda_n}\alpha_n(x) \right]^2 \leq C^2 \left[\sum_{x \in \Lambda_n} \rho_n(x)\right] \left[\sum_{x \in \Lambda_n}\rho_n(x) \alpha_n(x) \right]. 
\end{align}
Now observe that by Lemma~\ref{lemma:monotonicity-alpha} we have
\begin{align}\label{ineq:alpha-sum-lower-bound} 
    \sum_{x \in \Lambda_n}\alpha_n(x) 
    &\geq \mathbf{C}_1^{-1}\sum_{x \in \Lambda_n}\alpha_n(x)\sum_{k=1}^n \rho_k(x)
   \geq \mathbf{C}_1^{-1}\sum_{k=1}^n\sum_{x \in \Lambda_k} \alpha_k(x)\rho_k(x). 
\end{align}
Now define for $k \in \N$
\begin{align*}
    \delta_k = \sum_{x \in \Lambda_k} \alpha_k(x)\rho_k(x). 
\end{align*}
Note that by definition of $\alpha$ and $\rho$ we have $\delta_k \geq 0$ for all $k \in \N$.
By combining \eqref{ineq:cauchy-schwarz-bound} and \eqref{ineq:alpha-sum-lower-bound} we see that 
\begin{align*}
    \mathbf{C}_1^{-2}\left[\sum_{k=1}^n \delta_k\right]^2 \leq C^2 \delta_n \sum_{x \in \Lambda_n}\rho_n(x). 
\end{align*}
 So we finally obtain
\begin{align*}
    \left[\sum_{k=1}^n \delta_k \right]^2 \leq \mathbf{C}_2 \mathbf{C}_1^2 C^2 \delta_n n^{d-1} =: \mathbf{C} \delta_n n^{d-1}.
\end{align*}
If there were an index $n_0 \in \N$ such that $\delta_{n_0} > 0$, then for all $n > n_0$ it would hold that 
\begin{align*}
    \frac{1}{n^{d-1}} \leq \mathbf{C} \left[\frac{1}{\sum_{k=1}^{n-1}\delta_k} - \frac{1}{\sum_{k=1}^n\delta_k} \right]. 
\end{align*}
By a standard telescoping argument and monotonicity, the series over the terms on the right-hand side converges, which leads to a contradiction for $d \in \{1,2\}$. Therefore we must have $\delta_n = 0$ for all $n \in \N$ and hence $\alpha_n(x) = 0$ for all $n \in \N$ and $x \in \Lambda_n$. So it remains to show that $\mathbf{C}_1$ and $\mathbf{C}_2$ are actually finite. 
\medskip 

\noindent
\textit{Ad $\mathbf{C}_1$}: For fixed $x\in\Z^d$ we have 
\begin{align*}
    \sum_{n=1}^\infty \rho_n(x)
    &=
    \sum_{n=1}^\infty \sum_{y \notin \Lambda_n}(\delta_y \gamma_x(\cdot) + \delta_y c_x(\cdot))
    \\\
    &=
    \sum_{y \in \Z^d}(\delta_y \gamma_x(\cdot) + \delta_y c_x(\cdot))\abs{\{n \in \N: \ x \in \Lambda_n, y \notin \Lambda_n\}}
    \\\
    &\leq 
    \sum_{y \in \Z^d}(\delta_y \gamma_x(\cdot) + \delta_y c_x(\cdot)) \abs{x-y}.
\end{align*}
Now assumption $\mathbf{(R4)}$ and $\mathbf{(S3)}$ yield a uniform in $x$ upper bound on this quantity. 

\medskip 
\noindent 
\textit{Ad $\mathbf{C}_2$}: Here we have for fixed $n \in  \N$
\begin{align*}
    \sum_{x \in  \Lambda_n}\sum_{y \notin \Lambda_n}(\delta_y \gamma_x(\cdot) + \delta_y c_x(\cdot))
    &\leq
    \sum_{v \in \Z^d}\sum_{x \in \Lambda_n: \ x+v \notin \Lambda_n}(\delta_{x+v}\gamma_x(\cdot) + \delta_{x+v}c_x(\cdot))
    \\\
    &\leq 
    d(2n+1)^{d-1} \sum_{v \in \Z^d}\abs{v}\sup_{x \in \Z^d}(\delta_{x+v}\gamma_x(\cdot) + \delta_{x+v}c_x(\cdot)).
\end{align*}
This can be bounded from above, independent of $n$, by assumptions $\mathbf{(R4)}$ and $\mathbf{(S3)}$. 
\end{proof}
%6. Positive mass property: 
\section{Proof of the positive-mass property}\label{section:positive-mass}

We actually show the following more general result which implies Proposition~\ref{proposition:positive-mass} as a special case.

\begin{proposition}
Consider an interacting particle system with single-site updates with generator given by 
\begin{align*}
    Lf(\eta) = \sum_{i  \in \Z^d}\sum_{\xi_i = 1, \dots, q}c_i(\eta, \xi_i)\left[f(\xi_i \eta_{i^c}) - f(\eta)\right],
\end{align*}
where the rates satisfy the assumptions $(\mathbf{L1})-(\mathbf{L2})$.
We further assume the following.
\begin{enumerate}[\bfseries \upshape (R1')]
    \item For $L$, reachability is independent of the boundary conditions, i.e., whenever $c_x(\eta, \xi_x) >0$ we also have $c_x(\sigma, \xi_x) >0$ for all $\sigma$ with $\sigma_x = \eta_x$. 
    In this case we say that $\xi_x$ is reachable from $\eta_x$ and write $d_x(\eta_0, \xi_x)$ for the indicator of this event. 
    \item $L$ is single-site irreducible, i.e., the Markov chain on the single state space with rates given by $d$ is irreducible. 
    \item The minimal transition rate is strictly positive, i.e.,
    \begin{align*}
        \hat{c} = \inf_{i, \omega, \xi_i: \ c_i(\omega, \xi_i) >0}c_i(\omega, \xi_i) > 0.
    \end{align*}
 \end{enumerate}
 Then, for all $\tau >0$ and $\Lambda \Subset \Z^d$, there exists a constant $C(\tau, \Lambda) > 0$ such that for any initial distribution $\nu \in \calM_1(\Omega)$ and any time $t \in [\tau, \infty)$ we have 
 \begin{align*}
     \forall \eta \in \Omega: \quad \nu_t(\eta_\Lambda) \geq C(\tau, \Lambda). 
 \end{align*}
 In particular, for all subsequential limits $\nu^* = \lim_{n \to \infty} \nu_{t_n}$ with $t_n \uparrow \infty$ we have 
 \begin{align*}
     \forall \eta \in \Omega \ \forall \Lambda \Subset \Z^d: \quad \nu^*(\eta_\Lambda) > 0. 
 \end{align*}
\end{proposition}

\begin{proof}
We will show that there exists $C(\tau, \Lambda) > 0$ such that for all initial infinite-volume configurations $\omega$, there is a lower bound 
\begin{align*}
    \mathbb{Q}_\omega[\sigma_\Lambda(\tau) = \eta_\Lambda] \geq C(\tau, \Lambda). 
\end{align*}
This then implies for all $t \in [\tau, \infty)$ and $\nu \in \calM_1(\Omega)$
\begin{align*}
    \nu_t(\eta_\Lambda) = \int_\Omega \mathbb{Q}_\omega[\sigma_\Lambda(\tau) = \eta_\Lambda]\nu_{t - \tau}(d\omega) \geq C(\tau, \Lambda). 
\end{align*}
\medskip 
    
\noindent 
\textit{Step 0: } We will compare our dynamics to a second interacting particle system with generator $\hat{L}$, that can be seen as a finite-volume perturbation of $L$. More precisely, we consider a generator $\hat{L}$ with rates $\hat{c}$ that agree with the rates $c$, except inside of $\Lambda$, where all of the sites $i \in \Lambda$ will behave independently with transition rates 
$\hat{c}_i(\eta, \xi_i) = \hat{c} \cdot d_i(\eta_i, \xi_i)$.
We will denote the path measure on the space of $\Omega$-valued cádlág paths with respect to the original dynamics by $\mathbb{Q}$ and with respect to the perturbed dynamics by $\hat{\mathbb{Q}}^\Lambda$. 
\medskip 

\noindent 
\textit{Step 1:} By Lemma~\ref{lemma:girsanov-transformation} we have the following  Girsanov-type formula on the space of cádlág paths
\begin{align*}
    \frac{d \mathbb{Q}_\omega}{d\hat{\mathbb{Q}}^\Lambda_\omega} ( \sigma[0,\tau])
    =
    \exp\left(-\int_0^\tau \lambda(\sigma(s)) + \sum_{s \in [0,\tau]: \sigma_{\Lambda}(s_-) \neq \sigma_{\Lambda}(s)}\sum_{i \in \Lambda}\log\left(\frac{c_i(\sigma(s_-), \sigma_i(s))}{\hat{c}_i(\sigma(s_-), \sigma_i(s))}\right)\right), 
\end{align*}
where 
\begin{align*}
    \lambda(\eta) :=\sum_{i \in \Lambda}\left(c_i(\eta) - \hat{c}_i(\eta)\right),
\end{align*}
and $c_i(\eta)$ respectively $\hat{c}_i(\eta)$ are the total rates at which we see a flip at site $i$ when we are currently in configuration $\eta$, i.e., 
\begin{align*}
        c_i(\eta) = \sum_{\xi_i \neq \eta_i}c_i(\eta, \xi_i) \quad \text{respectively} \quad \hat{c}_i(\eta) = \sum_{\xi_i \neq \eta_i}\hat{c}_i(\eta, \xi_i). 
\end{align*}
Let us introduce additional notation to refer to the two separate parts of the above Radon--Nikodym derivative 
\begin{align*}
    a(\sigma[0,\tau]) &= \exp\left(-\int_0^\tau \lambda(\sigma(s))\right),
    \\\
    A(\sigma[0,\tau]) &= \exp\left(\sum_{s \in [0,\tau]: \sigma_{\Lambda}(s_-) \neq \sigma_{\Lambda}(s)}\sum_{i \in \Lambda}\log\left(\frac{c_i(\sigma(s_-), \sigma_i(s))}{\hat{c}_i(\sigma(s_-), \sigma_i(s))}\right)\right). 
\end{align*}
\medskip

\noindent 
\textit{Step 2: } By the Girsanov-type formula we can rewrite the probability we want to bound as
\begin{align*}
        \mathbb{Q}_\omega(\sigma_\Lambda(\tau) = \eta_\Lambda(\tau))
        =
        \hat{\mathbb{Q}}^\Lambda_\omega\left(a(\sigma[0,\tau]) A(\sigma[0,\tau]) \mathbf{1}_{\{\sigma_\Lambda(\tau) = \eta_\Lambda\}}\right). 
\end{align*}
  So in order to obtain the claimed lower bound, we only need to lower bound the functionals $a$ and $A$.
    \medskip

    \noindent
    \textit{Step 3: Deterministic lower bound on $a$.} 
    Since the rates of $L$ and the finite-volume perturbation $\hat{L}$ are assumed to be bounded from above by some constant $\mathbf{c}$ (this follows from well-definedness via Liggetts criteria), we can bound the function $\lambda(\cdot)$ by 
    \begin{align*}
    - \mathbf{c}\abs{\Lambda} \leq \lambda(\sigma[0,\tau]) \leq \mathbf{c}\abs{\Lambda}.
    \end{align*}
    This translates into an upper and lower bound for $a(\sigma[0,\tau])$ via 
    \begin{align*}
    \kappa(\tau) := \exp(-\tau \mathbf{c}\abs{\Lambda}) \leq a([0,\tau]) \leq \exp(\tau \mathbf{c}\abs{\Lambda}). 
    \end{align*}
    This implies 
    \begin{align*}
        \hat{\mathbb{Q}}^\Lambda_\omega\left(a(\sigma[0,\tau]) A(\sigma[0,\tau]) \mathbf{1}_{\{\sigma_\Lambda(\tau) = \eta_\Lambda\}}\right)
        \geq 
        \kappa(\tau, \Lambda) 
        \hat{\mathbb{Q}}^\Lambda_\omega\left(A(\sigma[0,\tau]) \mathbf{1}_{\{\sigma_\Lambda(\tau) = \eta_\Lambda\}}\right). 
    \end{align*}
    \medskip 

    \noindent 
    \textit{Step 5: Probabilistic lower bounds for $A$.} 
    We can lower bound $A$ in terms of the total number of jumps inside $\Lambda$, i.e., 
    \begin{align*}
        A(\sigma[0,\tau]) \geq e^{-R N_\Lambda(\tau)},
    \end{align*}
    where $R>0$ is a constant that depends on the minimal positive and maximal transition rate of $L$ and for any volume $\Delta \Subset \Z^d$ we define the (almost-surely finite) random variable $N_\Delta(\tau)$ by
    \begin{align*}
        N_\Delta(\tau) := \abs{\{s \in [0,\tau]: \ \sigma(s_-) \neq \sigma(s)\}}.
    \end{align*}
    In this notation we obtain 
    \begin{align*}
        \hat{\mathbb{Q}}^\Lambda_\omega\left(A(\sigma[0,\tau]) \mathbf{1}_{\{\sigma_\Lambda(\tau) = \eta_\Lambda\}}\right)
        \geq 
        \hat{\mathbb{Q}}^\Lambda_\omega\left(e^{-RN_\Lambda(\tau)} \mathbf{1}_{\{\sigma_\Lambda(\tau) = \eta_\Lambda\}}\right).
    \end{align*}
    \medskip 

    \noindent 
    \textit{Step 5: Using the independence to factorize.}
    Now note that under $\hat{\mathbb{Q}}^\Lambda_\omega$ all spins inside of $\Lambda$ are independent, and we have $N_\Lambda = \sum_{i\in \Lambda}N_i$. So we should get a really nice factorization, more precisely 
    \begin{align*}
        \hat{\mathbb{Q}}^\Lambda_\omega\left(e^{-RN_\Lambda(\tau)} \mathbf{1}_{\{\sigma_\Lambda(\tau) = \eta_\Lambda\}}\right)
        = \prod_{i \in \Lambda}\hat{\mathbb{Q}}^\Lambda_\omega\left(e^{-RN_i(\tau)} \mathbf{1}_{\{\sigma_i(\tau) = \eta_i\}}\right).
    \end{align*}
    \medskip 

    \noindent 
    \textit{Step 6: Estimating the factors via Poisson tails.}
    The factors can now each be estimated separately. For every $i \in \Lambda$ we have
    \begin{align*}
        \hat{\mathbb{Q}}^\Lambda_\omega\left(e^{-RN_i(\tau)} \mathbf{1}_{\{\sigma_i(\tau) = \eta_i\}}\right)
        &\geq 
        e^{-Rm}\hat{\mathbb{Q}}^\Lambda_\omega\left(N_0(\tau) \leq m, \sigma_i(\tau) = \eta_i \right)
        \\\
        &\geq
        e^{-Rm} \left(\hat{\mathbb{Q}}^\Lambda_\omega\left(\sigma_i(\tau) = \eta_i \right) - \hat{\mathbb{Q}}^\Lambda_\omega\left(N_0(\tau) > m \right)\right).
    \end{align*}
    By irreducibility of the single-site dynamics, there is a strictly positive lower bound for $\hat{\mathbb{Q}}^\Lambda_\omega\left(\sigma_i(\tau) = \eta_i \right)$ that only depends on $\tau$ (and not on $\omega$, $i$ or $\eta_i$) and the second term is the tail of a Poisson random variable. Hence, we will need to choose $m$ sufficiently large to make the right-hand side positive. So let us choose such an $m$ and denote the thereby obtained lower bound by $\rho(\tau) >0$.
    
    By putting all of the steps above together the claimed lower bound follows. 
\end{proof}


%7. Entropy loss on attractor:
\section{Finite-volume entropy loss vanishes for all measures in the attractor}\label{section:zero-finite-volume-loss}

\begin{proof}[Proof of Proposition \ref{proposition:zero-loss}]
Let us fix a finite volume $\Lambda \Subset \Z^d$. 
By definition of $\mathscr{A}$ there exists an initial distribution $\nu_0$ and a strictly increasing sequence $t_n \to \infty$ such that $\nu = \lim_{n \to \infty} \nu_{t_n}$. By Proposition~\ref{proposition:positive-mass} there exists a constant $c >0$ such that $\nu(\eta_\Delta)\geq c$ for all $\eta \in \Omega$.
Recall that the relative entropy of $\nu$ with respect to $\mu$ in the finite volume $\Lambda$ is given by 
\begin{align*}
    h_\Lambda(\nu \lvert \mu) = \sum_{\eta_\Lambda}\nu(\eta_\Lambda)\log\frac{\nu(\eta_\Lambda)}{\mu(\eta_\Lambda)} 
\end{align*}
and the relative entropy loss can be written as 
\begin{align*}
    g^\mathscr{L}_\Lambda(\nu \lvert \mu) 
    =
    \sum_{\eta_\Lambda}\sum_{x\in \Lambda}\sum_{j=1}^q \int_\Omega \nu(d\omega) c_x(\omega,j)\left[\mathbf{1}_{\eta_\Lambda}(\omega^{x,j}) - \mathbf{1}_{\eta_\Lambda}(\omega)\right]\log\frac{\nu(\eta_\Lambda)}{\mu(\eta_\Lambda)}. 
\end{align*}
From these explicit representations it is easy to see, that they are both continuous with respect to the weak topology. At least on the set of measures $\rho$ that put at least mass $c$ on every cylinder set $[\eta_\Lambda]$. 
Hence we have 
\begin{align*}
    h_\Lambda(\nu \lvert \mu) = \lim_{n \to \infty}h_\Lambda(\nu_{t_n}\lvert \mu), \quad g^\mathscr{L}_\Lambda(\nu \lvert \mu) = \lim_{n \to \infty}g^\mathscr{L}_\Lambda(\nu_{t_n}\lvert \mu). 
\end{align*}
Moreover, by non-nullness of $\mu$ we have
\begin{align*}
-M \abs{\Lambda} \leq h_\Lambda(\nu \lvert \ \mu)  \leq M \abs{\Lambda}
\end{align*}
for some constant $M > 0$ that does not depend on $\nu$, only on $\mu$. Indeed, we can decompose
\begin{align*}
    h_\Lambda(\nu \lvert \mu)
    =
    \sum_{\eta_\Lambda}\nu(\eta_\Lambda) \log(\nu(\eta_\Lambda)) - \sum_{\eta_\Lambda}\nu(\eta_{\Lambda})\log(\mu(\eta_\Lambda)). 
\end{align*}
The first sum is bounded from below by $0$ and from above by $\abs{\Lambda}\log q$. The second sum can be bounded in absolute value, because by the non-nullness estimate we have 
\begin{align*}
    \abs{\log(\mu(\eta_\Lambda))} \leq \abs{\Lambda} \log \frac{1}{\delta}. 
\end{align*}
Now if $g^\mathscr{L}_\Lambda(\nu \lvert \mu)$ is not equal to $0$, then there exists an open neighbourhood $G = G(\Lambda)$ of $\nu$ such that for $\nu_{t_n} \in G$ for all $n \geq N(G)$ and $g^\mathscr{L}_\Lambda(\cdot \lvert \mu)$ is bounded away from $0$ on $G$ by some value $\epsilon$ with $\abs{\varepsilon} >0$. 
Now we make a little case distinction over whether $g^\mathscr{L}_\Lambda(\nu \lvert \mu)>0$ or $<0$. We start with $<0$.
This leads to a contradiction since the relative entropy is bounded from below by $-M \abs{\Lambda}$ and the fundamental theorem of calculus tells us that 
\begin{align*}
    h_\Lambda(\nu \lvert \mu) 
    \leq h(\nu_{t_{m+N}}\lvert \mu) - h(\nu_{t_N}\lvert \mu) + h(\nu \lvert \mu) 
    \leq
    -\delta \sum_{k=0}^{m-1}\min\{\lambda, t_{N+k+1}-t_{N+k}\} + M,
\end{align*}
where $\lambda>0$ is chosen such that for all $s \in (0,\lambda)$ and $\rho_0 \in G$ we have $\rho_s \in G$, where we use the continuity of the Markov semigroup $(P_t)_{t \geq 0}$ generated by $\mathscr{L}$. But this leads to a contradiction since the constant $M$ is finite. Deriving a contradiction in the alternative case where $\epsilon > 0$ works analogously by constructing an $m$-dependent lower bound that goes to $\infty$ as $m \to \infty$. Therefore we must necessarily have $g^\mathscr{L}_\Lambda(\nu \lvert \mu) = 0$. 
\end{proof}

%8. Towards a generalisation

\section{Towards a generalisation}\label{section:generalisations}
\subsection{Generalisation to synchronous multi-site updates}
While the smoothness assumptions on the rates and the specification seem to be quite natural, it would be nice to lift the restriction of only considering single-site updates. However, there one runs into the trouble that 
\begin{align*}
    g_n^\mathscr{L}(\nu \lvert \mu) 
    = 
    &\sum_{\Delta \cap \Lambda_n \neq \emptyset} \sum_{\xi_\Delta}\int_\Omega \nu(d\eta) c_\Delta(\eta,\xi_\Delta)\log \frac{\nu(\xi_{\Delta \cap \Lambda_n}\eta_{\Lambda_n \setminus \Delta}) \mu (\eta_{\Lambda_n})}{\mu(\xi_{\Delta \cap \Lambda_n}\eta_{\Lambda_n \setminus \Delta})\nu(\eta_{\Lambda_n})}
    \\\
    =
    &\sum_{\Delta \subset \Lambda_n} \sum_{\xi_\Delta}\int_\Omega \nu(d\eta) c_\Delta(\eta,\xi_\Delta)\log \frac{\nu(\xi_{\Delta \cap \Lambda_n}\eta_{\Lambda_n \setminus \Delta}) \mu (\eta_{\Lambda_n})}{\mu(\xi_{\Delta \cap \Lambda_n}\eta_{\Lambda_n \setminus \Delta})\nu(\eta_{\Lambda_n})}
    \\\
    +
    &\sum_{\Delta \nsubseteq \Lambda_n : \Delta \cap \Lambda_n \neq \emptyset}\sum_{\xi_\Delta}\int_\Omega \nu(d\eta) c_\Delta(\eta,\xi_\Delta)\log \frac{\nu(\xi_{\Delta \cap \Lambda_n}\eta_{\Lambda_n \setminus \Delta}) \mu (\eta_{\Lambda_n})}{\mu(\xi_{\Delta \cap \Lambda_n}\eta_{\Lambda_n \setminus \Delta})\nu(\eta_{\Lambda_n})}.
\end{align*}
We can only rewrite the first sum as in Lemma \ref{lemma:finite-volume-relative-entropy-loss}, but this doesn't work for the second sum, because there are not enough terms to perform the change of variables.
One could now try to just bound the second term and thereby obtain Lemma \ref{lemma:upper-bound-alpha} with an additional additive error term on the right-hand side. One can show that this error term is of boundary order, see \cite[Lemma 3.10]{jahnel_dynamical_2022} for a proof in a more general setting, but naively carrying this term through the rest of the proof makes it impossible to apply the summability argument at the end of the proof of Proposition~\ref{proposition:holley-stroock-principle}. 

This is a bit strange, because at least heuristically one could say that the Holley--Stroock argument works in one and two dimensions, because the boundary contributions cannot weigh up against the bulk contribution and the error term is also of boundary order, but unfortunately we have not been able to make this (potentially misguided) intuition rigorous. 

\subsection{Non-reversible dynamics}
To make a similar argument work in the non-reversible case seems a bit more hopeless, because there we cannot hope to show that the $\Gamma_n(\cdot)$ terms all vanish as this would imply reversibility, c.f. Proposition ~\ref{proposition:characterizations-reversibility}. 

In some sense, assuming reversibility allows to reduce it to a very local question, whereas mere stationarity is a global question. Compare this to Proposition 2.8 in \cite{liggett_interacting_2005} and the preceding discussion. On an intuitive level this can already be seen when considering continuous-time Markov chains on a finite state space. Under the assumption of reversibility, every edge of the transition graph is in equilibrium, whereas the weaker assumption of time-stationarity just implies that for every state the inflow and outflow of probability mass are equal. 

An alternative but related approach to show a result in the spirit of Corollary~\ref{corollary:no-periodic} for non-reversible interacting particle system would be to show that the relative entropy density as in e.g.~\cite{jahnel_dynamical_2022} is really a true Lyapunov function, in the sense that it is strictly negative for non-stationary $\nu$. This might not imply a result similar to Theorem~\ref{theorem:main-result}, but it would be sufficient to conclude that there can be no periodic behaviour. 
However, working with non-shift-invariant measures requires to work with the $\limsup$ instead of the more convenient representations derived in \cite{jahnel_dynamical_2022} and additionally any argument of this type has to use the geometry of $d=1,2$ explicitly, because the above cannot be true in dimensions $d>2$, as the example in \cite{jahnel_class_2014} shows. 


\section*{Acknowledgements}
The authors acknowledge the financial support of the Leibniz Association within the Leibniz Junior Research Group on \textit{Probabilistic Methods for Dynamic Communication Networks} as part of the Leibniz Competition.

\bibliography{references}
\bibliographystyle{alpha}
\end{document}
