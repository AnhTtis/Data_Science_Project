%!TeX root=main.tex

\section{Proposed Algorithm}
\label{sec:proposal}

Considering the two aforementioned difficulties, we convert $\mathcal{P}$ into a bilevel optimization problem. In this study, the VLiE is regarded as the lower-level optimization problem with the goal of maximizing profit by leasing optical spectrum, whereas the VNoE is regarded as the upper-level optimization problem with the goal of maximizing profit by leasing the total resources.
As a result, $\mathcal{P}$ can be changed into a bilevel problem as

\begin{equation}\label{eq-Problem-P1}
    \begin{aligned}
    \mathcal{P}1: \  &\max \limits_{{ \textbf{x}, \textbf{y}, \textbf{z}}}\   {\sum\limits_{G^r \in \Upsilon}} {\nu^r} \left\{\mathbb{R}(G^r) - \mathbb{C}_n(G^r, \textbf{x}) - \mathbb{C}_e(G^r, \textbf{y}, \textbf{z}) \right\} \\
                 &\mathrm{ s.t.}\  (\textbf{y}, \textbf{z}) \in \mathop{\arg\max}_{\textbf{y}, \textbf{z}} \Big\{- \sum\limits_{G^r \in \Upsilon} {\nu^r} \mathbb{C}_e(G^r, \textbf{y}, \textbf{z}) : \text{C6}-\text{C11} \Big\} \\
                 &\quad \ \  \text{C1} - \text{C5}.
    \end{aligned}
\end{equation}

In order to prove the relationship between $\mathcal{P}$ and $\mathcal{P}1$, Lemma \ref{lemma1} must first be introduced \cite{HuangWWL20}.

\begin{lemma}\label{lemma1}
The optimal solution to $\mathcal{P}$ is a feasible solution to $\mathcal{P}1$.
\end{lemma}

\begin{proof}\label{proof1}
Denote the optimal solution to the original problem $\mathcal{P}$ as $\{\textbf{x}^{*}, \textbf{y}^{*}, \textbf{z}^{*}\}$. Since $\{\textbf{x}^{*}, \textbf{y}^{*}, \textbf{z}^{*}\}$ satisfies C1 $-$ C11, the problem we need to prove becomes that $\{\textbf{y}^{*}, \textbf{z}^{*}\}$ is the optimal solution to the lower-level optimization problem of $\mathcal{P}1$.

Suppose the optimal solution to the lower-level optimization problem of $\mathcal{P}1$ is not $\{\textbf{y}^{*}, \textbf{z}^{*}\}$ but $\{\textbf{y}', \textbf{z}'\}$, then
\begin{equation}\label{eq-proof-c'>c*}
     - \sum\limits_{G^r \in \Upsilon} {\nu^r} \mathbb{C}_e(G^r, \textbf{y}', \textbf{z}') >  - \sum\limits_{G^r \in \Upsilon} {\nu^r} \mathbb{C}_e(G^r, \textbf{y}^{*}, \textbf{z}^{*}).
\end{equation}

Obviously, $\{\textbf{x}^{*}, \textbf{y}', \textbf{z}'\}$ is a feasible solution to $\mathcal{P}$. If we substitute (\ref {eq-proof-c'>c*}) into $\mathcal{P}$, then
\begin{equation}\label{eq-proof-p'>p*}
    \begin{aligned}
     &{\sum\limits_{G^r \in \Upsilon}} {\nu^r} \left\{\mathbb{R}(G^r) - \mathbb{C}_n(G^r, \textbf{x}^{*}) - \mathbb{C}_e(G^r, \textbf{y}', \textbf{z}') \right\}\\
     & > {\sum\limits_{G^r \in \Upsilon}} {\nu^r} \left\{\mathbb{R}(G^r) - \mathbb{C}_n(G^r, \textbf{x}^{*}) - \mathbb{C}_e(G^r, \textbf{y}^{*}, \textbf{z}^{*}) \right\}.
     \end{aligned}
\end{equation}

This clearly contradicts the assumption that $\{\textbf{x}^{*}, \textbf{y}^{*}, \textbf{z}^{*}\}$ is the optimal solution to $\mathcal{P}$. Thus, $\{\textbf{y}^{*}, \textbf{z}^{*}\}$ is proved to be the optimal solution to the lower-level optimization problem. This proves that the optimal solution to $\mathcal{P}$ is a feasible solution to $\mathcal{P}1$.
\end{proof}

\begin{theorem}\label{Theorem1}
$\mathcal{P}$ and $\mathcal{P}1$ have the same optimal solution.
\end{theorem}

\begin{proof}\label{proof2}
 Denote the optimal solution to $\mathcal{P}$ as $\{\textbf{x}^{*}, \textbf{y}^{*}, \textbf{z}^{*}\}$. By Lemma \ref{lemma1}, we can know that it is a feasible solution to $\mathcal{P}1$. Assume that $\{\textbf{x}', \textbf{y}', \textbf{z}'\}$ is the optimal solution to $\mathcal{P}1$, then
\begin{equation}\label{eq-proof-p*=p1*}
    \begin{aligned}
     &{\sum\limits_{G^r \in \Upsilon}} {\nu^r} \left\{\mathbb{R}(G^r) - \mathbb{C}_n(G^r, \textbf{x}') - \mathbb{C}_e(G^r, \textbf{y}', \textbf{z}') \right\}\\
     & > {\sum\limits_{G^r \in \Upsilon}} {\nu^r} \left\{\mathbb{R}(G^r) - \mathbb{C}_n(G^r, \textbf{x}^{*}) - \mathbb{C}_e(G^r, \textbf{y}^{*}, \textbf{z}^{*}) \right\}.
     \end{aligned}
\end{equation}

Obviously, this contradicts the assumption that $\{\textbf{x}^{*}, \textbf{y}^{*}, \textbf{z}^{*}\}$ is the optimal solution to $\mathcal{P}$. Thus, the optimal solution to $\mathcal{P}$ is the optimal solution to $\mathcal{P}1$. By the same token, it can be proved that the optimal solution to $\mathcal{P}1$ is also the optimal solution to $\mathcal{P}$.
\end{proof}

The modified problem $\mathcal{P}1$ provides some benefits in addition to maintaining the original problem $\mathcal{P}$'s optimal solution.
\begin{enumerate}
    \item The initial problem is convert into two more manageable combinatorial optimization problems with fewer decision variables.
    \item $\mathcal{P}1$ allows for comprehensive consideration of the interdependence between VNoE and VLiE. The quality of each VNoE result can be evaluated because the best VLiE result corresponding to each VNoE result has been produced in the lower level.


\end{enumerate}


\subsection{BiVNE}
To solve this transformed problem, we propose BiVNE, a nested bilevel VNE approach. \textbf{Algorithm \ref{Algorithm-General-BiVNE}} depicts the general framework of BiVNE. The VNRs are fulfilled one by one through BiVNE. During the initialization phase, the feasible candidate node set of each VN is pruned to a smaller scale.
The upper-level and lower-level optimizations are performed at each iteration of the main loop, with the latter nested within the former.
The ACS with a sorting approach is used in the upper-level optimization to generate a VNoE solution.
The Dijkstra algorithm and an exact-fit spectrum slot allocation method are used in the lower-level optimization to obtain the corresponding optimal embedding of VLs based on the provided VNoE result.
The performance of the whole VNE solution can be evaluated after the corresponding optimal VLiE of each VNoE is found~\cite{LiK14,LiFK11,LiKWTM13,CaoKWL12,CaoKWL14,LiDZZ17,LiKD15,LiDZK15,LiCFY19,LiKZD15,LiZKLW14,LiFKZ14}.
The above operation will be repeated until a predefined threshold is reached.
In the next sections, we will introduce BiVNE in detail.

\begin{algorithm}[ht]
 \caption{BiVNE}
  \label{Algorithm-General-BiVNE}
   \begin{algorithmic}[1]
        \STATE $gen = 0$;
        \STATE Obtain a feasible candidate PNs set using \textbf{Algorithm \ref{Algorithm-Can-NSet-Pruning}};  
        \WHILE {$gen < gen_{max}$}
            \STATE Establish a VNoE solution using \textbf{Algorithm \ref{Algorithm-Solution-Construction}}: $\textbf{x} = \{ x_{n^s}^{n^r} \ | \ n^r \in N^r, n^s \in N^s  \} $; 
            \STATE Apply \textbf{Algorithm \ref{Algorithm-link-embedding}} to calculate the optimal embedding of VLs and FS allocation based on the given $\textbf{x}$: $\textbf{y} = \{ y_{p^s}^{e^r}\ | \ e^r \in E^r, p^s \in P^s \}$, $\textbf{z} = \{ z_{e^s,b}^{e^r} \ | \ e^r \in E^r, e^s \in e^s, b < B(e^s)  \}$;
            \STATE Evaluate the total resource consumed by each VNoE solution with the corresponding optimal embedding of VLs and FS allocation;
            \STATE Apply the local search procedure to the iteration-best solution $(\textbf{x}^b, \textbf{y}^b, \textbf{z}^b)$;
            \STATE Based on (\ref{eq-phe-upd-glo}), update the global pheromone in ACS;
            \STATE $gen = gen + 1$;
        \ENDWHILE
        
        \STATE \textbf{Output:} the best VNoE solution with the corresponding optimal VLiE solution and FS allocation $(\textbf{x}^*, \textbf{y}^*, \textbf{z}^*)$.
  \end{algorithmic}
 \end{algorithm}


\subsection{Candidate Node Set Reduction}
In the upper-level optimization problem, the size of the solution space for each VN is determined by the total number of PNs.
For instance, if a VNR contains $|N^r|$ VNs, the solution space of this VNR is ${|N^s|}^{|N^r|}$.
Obviously, the upper-level solution space is so large that it has to be reduced.

As shown in \textbf{Algorithm \ref{Algorithm-Can-NSet-Pruning}}, a method to shrink the solution space is designed on the basis of three facts:
\begin{enumerate}[i)]
    \item \label {fact-1} When a VNR arrives, we can preselect a candidate node set $\Phi_N(n^r)$ for every $n^r$ according to its resource capacity requirement and preferred area: $\Phi_N(n^r) = \{n^s \in N^s \mid C_a(n^s) \ge C(n^r),\  W_a(n^s) \ge W(n^r), \ dis[loc(n^r),loc(n^s)] \le \Delta loc(n^r)\}$.
    \item \label {fact-2}For any PN $n^s$ in the candidate node set $\Phi_N(n^r)$ selected by \ref{fact-1}), if it has fewer attached links than $n^r$, it is not applicable for $n^r$.
    \item \label {fact-3}The PN is still not applicable if the amount of spectrum provided by its attached links cannot meet the requirement of the corresponding VLs.
\end{enumerate}

Thus, the PNs in cases \ref{fact-2}) and \ref{fact-3}) are removed from the original candidate set. In order to make the reduction, the number of the available attached links of $n^s$ is first calculated as
\begin{equation}\label{eq-dl(n^s)}
  d_l(n^s) = \sum\limits_{e_n^s \in E(n^s)} \phi_{n^s}^{e^s},
\end{equation}
where $E(n^s) = \{e^s \in E^s \mid s(e^s) = n^s \parallel t(e^s) = n^s\}$ is the set of attached links of PN $n^s$, $\phi_{n^s}^{e^s} = \mathbb{I} (f(m_{e_n^s}^{max}) \geq B(e^r))$ is a binary variable indicating whether attached link $e_n^s$ has enough available contiguous FSs to meet the bandwidth requirement or not, and $m_{e_n^s}^{max}$ is the MACSB with the largest length on $e^s$.
As a result, the candidate node set of each VN $n^r$ should be reduced by the following constraint
\begin{equation}\label{eq-ds>dr}
  d_l(n^s) \geq d(n^r),
\end{equation}
where $d(n^r)$ is the number of attached links of $n^r$.

\textbf{Algorithm \ref{Algorithm-Can-NSet-Pruning}} depicts the detailed procedure of set reduction. Based on (\ref{eq-st-n-121}) - (\ref{eq-st-n-lc}) and (\ref{eq-ds>dr}), each PN in the candidate node set is evaluated separately. If any PN in the candidate node set does not satisfy (\ref{eq-st-n-121}) - (\ref{eq-st-n-lc}) and (\ref{eq-ds>dr}), it is considered infeasible and removed from the alternative set. After the reduction, each candidate node set has a size smaller than or equal to $|N^s|$. In consequence, the size of the search space is significantly reduced.

\begin{algorithm}[ht]
 \caption{Candidate Node Set Reducing}
    \label{Algorithm-Can-NSet-Pruning}
     \begin{algorithmic}[1]
       \FOR {all $n^r$ in $N^r$}
            \STATE $\Phi_N(n^r) = N^s$,%candidate node set
            \FOR {all $n^s$ in $\Phi_N(n^r)$}
                \IF {$C_a(n^s) < C(n^r)$ or $W_a(n^s) < W(n^r)$ or $dis[loc(n^r),loc(n^s)] > \Delta loc(n^r)$ or $d_l(n^s) < d(n^r)$}
                 \STATE $\Phi_N(n^r) \leftarrow \Phi_N(n^r) \setminus \{n^s\}$,%candidate node set
                \ENDIF
            \ENDFOR
       \ENDFOR
   \RETURN $\Phi_N(n^r)$
  \end{algorithmic}
 \end{algorithm}

\subsection{Upper-Level Optimization}
Normally, the InP will earn greater profit by consuming less resources to fulfill the requirement of each VNR.
Therefore, the upper-level optimization goal can be simplified to minimize the sum of all resources allocated to any VNR and the resulting resource fragments.
The VNoE problem is a combinational optimization problem with the constraint that two VNs in a VNR cannot be embedded onto the same PN \cite{HernandoML16}.
To solve the upper-level problem, we propose an ACS-based algorithm. ACS is chosen for the following reasons:
\begin{enumerate}
    \item Evolutionary computation algorithms are widely applied to combinational optimization problems. Especially, ACS, as a variant of the ant colony optimization algorithm, has demonstrated higher strengths than other evolutionary algorithms in solving real-world problems.
    \item Unlike other evolutionary computation algorithms generating solutions simultaneously, the ACS optimizers construct solutions one by one. By this way, once a PN is assigned to a VN, it will not be assigned again to any other VN in the same VNR.
\end{enumerate}

The proposed ACS-based algorithm BiVNE consists of four operations: solution construction, fitness evaluation, local search and pheromone management.

\subsubsection{Solution Construction} \label{ssubsec-solu-constr}

\begin{algorithm}[ht]
 \caption{VNoE Solution Construction}
  \label{Algorithm-Solution-Construction}
   \begin{algorithmic}[1]
   \STATE Generate the embedding order of VNs based on the sorting strategy;
   \STATE Sort the VNs, and get the sorted set ${N^r}'$;
   \STATE $\textbf{x} = \emptyset$; \label{alg-in-SloCons-X=0}
   \FOR {all $n^r$ in ${N^r}'$}%{$ i =1$ to $|N^r|$}
       \IF {$\Phi_N(n^r) \neq \emptyset$ } %$\Phi_N(n_i^r)
            \STATE Calculate the probability that each candidate PN in $\Phi_N(n^r)$ based on (\ref{eq-probability});
            \STATE Select a PN $n^s$ from $\Phi_N(n^r)$ based on (\ref{eq-state-transition-rule}) and set $x_{n^s}^{n^r} = 1$;
            \STATE Delete $n^s$ from candidate node set of remaining VNs in the same VNR;
            \STATE Update the local pheromone in ACS based on (\ref{eq-phe-upd-loc});
       \ENDIF
   \ENDFOR
   \RETURN $\textbf{x}$
  \end{algorithmic}
 \end{algorithm}

During each iteration, ants search for all the possible solutions and then choose the optimal one, i.e. the VNoE solution.
By allocating the PNs in the candidate node set to the VNs one by one at a time, each ant builds a potential VNoE solution.
The request of embedding a VNR is rejected if any involved VN's corresponding candidate node set is empty.
The complete procedure of VNoE solution construction is shown in \textbf{Algorithm \ref{Algorithm-Solution-Construction}}.

\begin{figure}[ht]%[h t b p]: here, top, bottom, 浮动。
    \centering
    \subfloat[Random.]{\label{fig_virtual_node_order-random}
    \includegraphics[width=3.5cm]{Graphics/fig_virtual_node_order-random.eps}
    }
    \subfloat[Sorted.]{\label{fig_virtual_node_order-sorted}
    \includegraphics[width=3.5cm]{Graphics/fig_virtual_node_order-sorted.eps}
    }
    \caption{Illustration of operating principle of proposed sorting strategy.}
    \label{fig_virtual_node_order-subs}       % Give a unique label
\end{figure}

The VNoE is generally performed by ants in a random order \cite{LiuZDLGZ18, LiangZZZ20}.
However, it is not the best way in solving this problem.
Fig. \ref{fig_virtual_node_order-random} shows an example of performing the embedding randomly.
We assume three VNs (i.e., $n_1^v$, $n_2^v$, $n_3^v$) need to be embedded.
The numbers of PNs in the candidate node sets of nodes $n_1^v$, $n_2^v$, and $n_3^v$ are 3, 2, and 1, respectively.
If the three VNs are embedded in this order, the solution will be infeasible in most cases due to the difficulty of embedding $n_3^v$.
As shown in Fig. \ref{fig_virtual_node_order-random}, the ant assigns a PN for $n_1^r$ first, and the corresponding result is $\{n_1^r \rightarrow n_1^s\}$.
Then, the ant only can assign $n_2^s$ to $n_2^v$ due to constraint C2.
Thus, there is no PN for $n_3^v$ to select.
We can easily find that $n_3^v$ cannot be embedded successfully as long as $\{n_1^r \rightarrow n_1^s\}$ or $\{n_2^r \rightarrow n_1^s\}$.
 The reason is that the VNs with fewer candidate nodes are embedded later.
So, to construct a feasible solution efficiently, we propose a sorting strategy by reranking the VNs in ascending order of the number of their candidate nodes.
As a result, ${N^r}$ becomes a new set ${N^r}'$.
Fig. \ref{fig_virtual_node_order-sorted} depicts an implementation of performing the proposed sorting strategy, where ${N^r}' = \{n_3^v, n_2^v, n_1^v \}$.
In this way, the feasible embedding solution for ${N^r}'$ can easily be found, and the result is $\{ n_3^v \rightarrow n_1^s, n_2^v \rightarrow n_2^s, n_1^v \rightarrow n_3^s \}$.

 As shown in \textbf{Algorithm \ref{Algorithm-Solution-Construction}}, after performing the sorting strategy, the VNs are embedded in turn.
First, the matrix of VNoE result is initialized as $\textbf{x} = \emptyset$ (Line \ref{alg-in-SloCons-X=0}).
Then, for $n^r \in {N^r}'$, if its candidate PN set $\Phi_N(n^r)$ is not empty, the probability that each candidate PN in $\Phi_N(n^r)$ to be selected is given as \cite{DorigoG97}
 \begin{equation}\label{eq-probability}
 \begin{aligned}
     pr(n^r, n^s) = \frac{\tau(n^r, n^s) \cdot {\eta(n^r, n^s)}^\beta}{\sum\limits_{{n^s}' \in \Phi_N(n^r)} \tau(n^r,{n^s}') \cdot {\eta(n^r, {n^s}')}^\beta},\\
    \forall n^r \in {N^r}', \forall n^s \in {\Phi_N(n^r)},
 \end{aligned}
 \end{equation}
where $\tau(n^r, n^s)$ is the pheromone, $\eta(n^r, n^s)$ is the heuristic information, and $\beta$ is a factor that determines the relative weight of $\tau(n^r, n^s)$ and $\eta(n^r, n^s)$.
The heuristic information is used as a subjective incentive for ants to search for a potentially good solution.
In BiVNE, we define it as
\begin{equation}\label{eq-heuristic-information}
   \eta(n^r, n^s) = \frac{1}{\mathbb{C}^I(n^r\rightarrow n^s)},
\end{equation}
where $\mathbb{C}^I(n^r \rightarrow n^s)$ is the increment of the cost of fulfilling the resource requirements of $n^r$ and its attached links with the already embedded VNs.
Thus, the smaller the cost increment, the higher the probability of assigning PN $n^s$ to $n^r$ in (\ref{eq-probability}). $\mathbb{C}^I(n^r \rightarrow n^s)$ is calculated as
\begin{equation}\label{eq-resource-increment-embed-VNN}
  \mathbb{C}^I(n^r \rightarrow n^s)= \mathbb{C}_n(x_{n^s}^{n^r}) + \mathbb{C}_e^{min}( x_{n^s}^{n^r}),
\end{equation}
where $\mathbb{C}_e^{min}( x_{n^s}^{n^r})$ is the minimum increment of cost for link resource consumption if $x_{n^s}^{n^r} = 1$, which can be calculated as
\begin{equation}\label{eq-Ce_min}
  \mathbb{C}_e^{min}( x_{n^s}^{n^r}) = \sum\limits_{n_i^r \in {N_{as}^r}'} h(n^s, \mathcal{M}(n_i^r)) \cdot B(G^r)  \cdot \gamma',
\end{equation}
where ${N_{as}^r}'$ is the set of VNs whose embedding orders are in front of $n^r$, $h(n^s, \mathcal{M}(n_i^r))$ is the length of the shortest path between $n^s$ and the PN $\mathcal{M}(n_i^r)$ host $n_i^r$, and $B(G^r)$ is the number of FSs required by every VL in corresponding VNR $G^r$.

Then, for $n^r$, an ant chooses a PN from the candidate node set ${\Phi_N(n^r)}$ according to the state transition rule based on the pseudorandom proportional given by% 伪随机比例
{\small
\begin{equation}\label{eq-state-transition-rule}
      n^s =
        \begin{cases}
            \mathop{\arg\max}\limits_{ {n^s}' \in \Phi_N(n^r)} \tau(n^r,{n^s}') \cdot {\eta(n^r, {n^s}')}^\beta, &\text{if ${q \leq q_0}$,} \\
            RWS(pr(n^r, n^s)),                            & \text{otherwise,} %n_{rw}^s
        \end{cases}
\end{equation}}
where $q$ is a uniformly distributed random number between $[0,1]$, $RWS(pr(n^r, n^s))$ is a PN chosen from $\Phi_N(n^r)$ by using the roulette wheel selection function $RWS(\cdot)$ on the basis of the probability distribution given in (\ref{eq-probability}), and $q_0$ is a parameter that controls the behaviors of ants in exploitation and exploration.

\subsubsection{Fitness Evaluation}
Following the construction of the VNoE solution, the corresponding optimal VLiE solution and FS allocation are obtained in the lower-level optimization, which will be discussed in Section \ref{subsection-lower}.
The performance of a completed solution comprised of the VNoE and VLiE results can then be evaluated~\cite{WuLKZZ19,WuLKZZ17,LiC23,WilliamsLM23,LyuYWHL23}.
The fitness function is the cost for fulfilling the total resource requirements of both VNoE and VLiE, and it is calculated as follows
\begin{equation}\label{eq-fitness}
   \mathbb{C}(\textbf{x},\  \textbf{y}^{*}, \textbf{z}^{*}) = \mathbb{C}_n(\textbf{x}) + \mathbb{C}_e(\textbf{y}^{*}, \textbf{z}^{*}),
\end{equation}
where $\mathbb{C}_n(\textbf{x})$ is the cost for fulfilling the resource requirements of VNs with the VNoE result matrix $\textbf{x}$, and $\mathbb{C}_e(\textbf{y}^{*}, \textbf{z}^{*})$ is the minimum cost corresponding to the optimal VLiE solution and FS allocation result $(\textbf{y}^{*}, \textbf{z}^{*})$ when $\textbf{x}$ is given.

\subsubsection{Local Search}
Following the evaluation of fitness, if the iteration-best solution $ \{\textbf{x}^{b}, \textbf{y}^{b}, \textbf{z}^{b}\}$ is feasible, a local search operation is carried out on it to speed up the convergence.
First, the order of VNs is generated as introduced in subsection \ref{ssubsec-solu-constr}.
Then, each VN is checked according to its order.
Besides the selected PN in the solution, any other PN belonging to the VN's candidate set is judged on whether it can contribute a lower fitness value~\cite{LiKWCR12,LiWKC13,CaoKWLLK15,LiDY18,WuKZLWL15,LiKCLZS12,LiDAY17,LiDZ15,LiXT19,GaoNL19,LiuLC19,LiZ19,KumarBCLB18,CaoWKL11,LiX0WT20,LiuLC20,LiXCT20,WangYLK21,ShanL21,LaiL021,LiLLM21,WuKJLZ17,LiCSY19,LiLDMY20,WuLKZ20,PruvostDLL020,XuLA22,LiLL22,ZhouLM22,ChenLTL22,Williams0M22,FanLT20}.
The original selected PN is replaced by the new one if it can contribute a lower fitness value.
Note that, to ensure constraint C2, the PN for substitution should not be assigned to the other VNs.
After that, the solution $ \{\textbf{x}^{b}, \textbf{y}^{b}, \textbf{z}^{b}\}$ is updated accordingly.


\subsubsection{Pheromone Management}
During the solution construction procedure, each time an ant finds a feasible assignment $n^s$ for $n^r$, the local pheromone is updated on pair $(n^r, n^s)$ accordingly to reduce the probability of other ants making the same assignment. The local pheromone updating rule is
\begin{equation}\label{eq-phe-upd-loc}
  \tau(n^r, n^s) = (1 - \varphi) \cdot \tau(n^r, n^s) + \varphi \cdot \tau_{0},
\end{equation}
where $\varphi$ is the pheromone decay coefficient and $\tau_{0}$ is the initial value of the pheromone.

At the end of each iteration, only the global best ant is allowed to release pheromone.
After all the ants complete their assignments, the best assignment can be found and labeled as $(\textbf{x}^b, \textbf{y}^b, \textbf{z}^b)$.
To increase the pheromone on the good potential assignments, the global pheromone updating rule is applied to $(\textbf{x}^b, \textbf{y}^b, \textbf{z}^b)$.
The rule of global pheromone updating is
\begin{small}
\begin{equation}\label{eq-phe-upd-glo}
  \tau(n^r, n^s) =
  \begin{cases}
        (1 - \rho) \cdot \tau(n^r, n^s) + \rho \cdot \Delta\tau, &\text{if ${x_{n^s}^{n^r} = 1}$,} \\
        \tau(n^r, n^s),                            & \text{otherwise,}
  \end{cases}
\end{equation}
\end{small}
where $\rho$ denotes the pheromone decay parameter, and
\begin{equation}\label{eq-Delta-tau}
  \Delta\tau = \frac{1}{\mathbb{C}(\textbf{x}^b, \textbf{y}^b, \textbf{z}^b)}.
\end{equation}
\subsection{Lower-Level Optimization}\label{subsection-lower}

Similar to the upper-level optimization, the aim of the lower-level optimization can be simplified to minimize the cost of fulfilling the resource requirement of VLs through optimizing the VLiE solution $\textbf{y}$ and the FS allocation $\textbf{z}$ under the given VNoE result $\textbf{x}$, which can be formulated as
\begin{equation}\label{eq-lower-objective}
 \begin{split}
    &\min \limits_{{ \textbf{y, z}}}
   {\sum\limits_{e^r \in E^r}}{\sum\limits_{e^s \in E^s}}
    { y_{p^s}^{e^r} \cdot I_{e^s}^{p^s} \cdot \gamma' \cdot \left [ \sum\limits_{b = 1}^{B(e^s)} z_{e^s,b}^{e^r} + \xi_{e^s}^{e^r}\right]}\\
    & \mathrm{s.t. }  \ \text{C6} - \text{C11}.
    \end{split}
\end{equation}

It can be seen from (\ref{eq-lower-objective}) that the longer the physical path in which a VL is embedded, and/or the more new spectrum fragments generated by this path, the greater the cost of InP.
On this basis, we propose \textbf{Algorithm \ref{Algorithm-link-embedding}} to embed VLs.

\begin{algorithm}[!t]
 \caption{VLiE and FS Assignment}
  \label{Algorithm-link-embedding}
   \begin{algorithmic}[1]
   \STATE ${G^s}' = G^s$; \label{alg-in-LiEmbed-Des-i}
    \FOR {all ${e^s}'$ in ${E^s}'$} \label{alg-in-LiEmbed-Des-s}
        \IF {$f(m_{{e^s}'}^{max}) < B(e^r)$}
             \STATE Delete ${e^s}'$ from ${G^s}'$;
        \ENDIF
    \ENDFOR  \label{alg-in-LiEmbed-Des-t}
    \FOR {all ${e^r}$ in ${E^r}$}
        \STATE Find the shortest path $p^s$ using Dijksra algorithm;
        \STATE Delete $p^s$ from ${G^s}'$;
    \ENDFOR
    \STATE $P^s_e = \{ p^s \}$;
    \IF {$f(m_{P^s_e}^{max}) < B(e^r)$}
        \STATE The VNR is rejected;
    \ELSE
        \STATE set $y_{p^s}^{e^r} = 1$;
        \STATE Find the optimal available continuous FSs $[s_b(e^r), t_b(e^r)]$ with the smallest size of newly-generated spectrum fragment, and set $z_{e^s, b}^{e^r} = 1,\  s_b(e^r) \leq b \leq t_b(e^r)$.
    \ENDIF

   \RETURN $\{\textbf{y}, \textbf{z}\}$
  \end{algorithmic}
 \end{algorithm}

As mentioned before, the VNE is transparent, in other words, all the VLs require the same amount of FSs in a VNR.
To improve search efficiency, in the beginning, we check every PL and remove those that cannot meet the spectrum requirements of the VLs (Line \ref{alg-in-LiEmbed-Des-s} - \ref{alg-in-LiEmbed-Des-t}).
The removing operation is performed on a replica of $G^s$, i.e. ${G^s}'$ (Line \ref{alg-in-LiEmbed-Des-i}), so the links in $G^s$ are not deleted, and the embedding result on ${G^s}'$ can be directly applied to $G^s$.
Afterwards, for each VL, a greedy algorithm is used to find the shortest path for it based on the Dijkstra algorithm.
If the size of MACSB on the path is smaller than the bandwidth requirement of the VL, the corresponding VNR is rejected~\cite{LiWKC13,RuanLDL20,SunL20,LiNGY22}.
Otherwise, the PLs on the shortest path are allocated to the VL.
Subsequently, an FS assignment method is used to select the optimal available continuous FS block which has the smallest size of newly-generated spectrum fragment.
And then, the corresponding FSs are allocated to the VL.
After the shortest path and optimal FSs are assigned to the VL, the VLiE is completed, and then, the shortest path is deleted from ${G^s}'$ to prevent spectrum overlapping (constraint C11).
 After the path selection and the FS assignment procedures, the result $\{\textbf{y}, \textbf{z}\}$ is generated.

