{
    "arxiv_id": "2303.11809",
    "paper_title": "Addressing Class Variable Imbalance in Federated Semi-supervised Learning",
    "authors": [
        "Zehui Dong",
        "Wenjing Liu",
        "Siyuan Liu",
        "Xingzhi Chen"
    ],
    "submission_date": "2023-03-21",
    "revised_dates": [
        "2023-11-27"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG",
        "cs.AI"
    ],
    "abstract": "Federated Semi-supervised Learning (FSSL) combines techniques from both fields of federated and semi-supervised learning to improve the accuracy and performance of models in a distributed environment by using a small fraction of labeled data and a large amount of unlabeled data. Without the need to centralize all data in one place for training, it collect updates of model training after devices train models at local, and thus can protect the privacy of user data. However, during the federal training process, some of the devices fail to collect enough data for local training, while new devices will be included to the group training. This leads to an unbalanced global data distribution and thus affect the performance of the global model training. Most of the current research is focusing on class imbalance with a fixed number of classes, while little attention is paid to data imbalance with a variable number of classes. Therefore, in this paper, we propose Federated Semi-supervised Learning for Class Variable Imbalance (FCVI) to solve class variable imbalance. The class-variable learning algorithm is used to mitigate the data imbalance due to changes of the number of classes. Our scheme is proved to be significantly better than baseline methods, while maintaining client privacy.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.11809v1"
    ],
    "publication_venue": "12th International Conference on Cloud Computing: Services and Architecture (CLOUD 2023)",
    "doi": "10.5121/csit.2023.130522"
}