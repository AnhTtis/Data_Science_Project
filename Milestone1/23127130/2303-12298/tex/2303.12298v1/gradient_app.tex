\section{Proofs of GD and SGD convergence}\label{sec:gd_sgd_missing_proofs}
In this section, we provide proofs of convergence analysis the gradient descent and stochastic gradient descent matrix sensing algorithms.
\subsection{Proof of GD Progress on Potential Function}\label{sec:proof_gradient_descent}
We start with the progress of the gradient on the potential function in below lemma.
\begin{lemma}[Restatement of Lemma~\ref{lem:gradient_descent}]
Assume that $u_i \perp u_j = 0 $ for any $i,j \in [m]$ and $\| u_i\|^2 = 1$. Let $c \in (0,1)$ denote a sufficiently small positive constant. Then, for any $\epsilon,\lambda>0$ such that $\epsilon\lambda \leq c$,


we have for any $t>0$,
\begin{align*}
    \Phi_{\lambda} ( A_{t+1} ) \leq (1-0.9 \frac{ \lambda \epsilon }{\sqrt{m} }) \cdot \Phi_{\lambda} (A_t) +  \lambda \epsilon \sqrt{m}
\end{align*}

\end{lemma}

\begin{proof}
We first Taylor expand $\Phi_\lambda(A_{t+1})$ as follows:
\begin{align}\label{eq:gd_define_Delta_1_and_Delta_2}
    & ~ \Phi_{\lambda}(A_{t+1})- \Phi_{\lambda} (A_t) \notag \\
    \leq & ~ \langle \nabla \Phi_{\lambda} (A_t) , (A_{t+1} - A_t) \rangle  + O(1) \langle \nabla^2 \Phi_{\lambda}(A_t), (A_{t+1} - A_t) \otimes (A_{t+1} - A_t) \rangle \notag \\
    := & ~ \Delta_1 + O(1) \cdot \Delta_2,
\end{align}
which follows from Lemma~\ref{lem:jn08}.
\iffalse
Lemma~\ref{lem:jn08} that for any function $f$,
\begin{align*}
    \tr[ f( M'') ] 
   \leq & ~ \tr[ f(M') ] + \tr[ f'(M') ( M'' - M' ) ] \\
    & ~ + O(1) \cdot \tr[ f''(M') ( M'' - M' )^2 ]. 
\end{align*}
\Ruizhe{add the constraint for $f$, i.e., $C^2$?}
\fi

We choose
\begin{align*}
    A_{t+1} = A_t - \epsilon \cdot \nabla \Phi_{\lambda}(A_t) / \| \nabla \Phi_{\lambda}(A_t) \|_F.
\end{align*}

We can bound
\begin{align}\label{eq:tr_phi_At_first_moment} 
 \Delta_1 = & ~ \tr[\nabla \Phi_{\lambda}(A_t) (A_{t+1} - A_t)] \notag \\
=  & ~ -\epsilon \cdot \|\nabla \Phi_{\lambda} (A_t) \|_F.
\end{align}





Next, we upper-bound $\Delta_2$. Define
\begin{align*}
    z_{t,i} := \lambda (u_i^\top A_t u_i - b_i).
\end{align*}
and consider $\Delta_2 \cdot (\lambda\epsilon )^{-2} \cdot \| \nabla \Phi_{\lambda} (A_t) \|_F^2$, which can be expressed as:
\begin{align}\label{eq:tr_phi_At_second_moment}
&\Delta_2 \cdot (\lambda\epsilon )^{-2} \cdot \| \nabla \Phi_{\lambda} (A_t) \|_F^2\notag\\
     = & ~ (\lambda\epsilon )^{-2} \tr[ \nabla^2 \Phi_{\lambda}(A_t) \cdot (A_{t+1} - A_t) \otimes (A_{t+1} - A_t) ] \cdot 
      \| \nabla \Phi_{\lambda}(A_t) \|_F^2 \notag\\
    = & ~  \tr\Big[ \nabla^2 \Phi_{\lambda}(A_t) \cdot 
    ( \sum_{i=1}^m u_i u_i^\top  \sinh( z_{t,i} ) ) \otimes ( \sum_{i=1}^m u_i u_i^\top \sinh( z_{t,i} ) )\Big] \notag\\
    = & ~ \tr\Big[ \nabla^2 \Phi_{\lambda}(A_t) \cdot ( \sum_{i,j}  \sinh( z_{t,i} )\sinh( z_{t,i} ) (u_i u_i^\top \otimes u_ju_j^\top) ) \Big] \notag\\
    = & ~ \tr\Big[ \nabla^2 \Phi_{\lambda}(A_t) \cdot ( \sum_{i=1}^m \sinh^2( z_{t,i} )) (u_i u_i^\top \otimes u_iu_i^\top) ) \Big] \notag\\
    + & ~  \tr\Big[ \nabla^2 \Phi_{\lambda}(A_t) \cdot ( \sum_{i\neq j} \sinh( z_{t,i} )\sinh( z_{t,j} ) (u_i u_i^\top \otimes u_j u_j^\top) ) \Big] \notag\\
    =: & ~  Q_1 + Q_2  ,
\end{align}
where 
\begin{align}\label{eq:def_Q1}
Q_1:= \tr\Big[ \nabla^2 \Phi_{\lambda}(A_t) \cdot ( \sum_{i=1}^m \sinh^2( z_{t,i} )) (u_i u_i^\top \otimes u_iu_i^\top) ) \Big]
\end{align}
denotes the diagonal term, and
\begin{align}\label{eq:def_Q2}
    Q_2:=&~\tr\Big[ \nabla^2 \Phi_{\lambda}(A_t) \cdot
    ( \sum_{i\neq j} \sinh( z_{t,i} )\sinh( z_{t,j} ) (u_i u_i^\top \otimes u_j u_j^\top) ) \Big]
\end{align}
denotes the off-diagonal term. 
The first step comes from the definition of $\Delta_2$,
the second step follows fromr eplacing $A_{t+1} - A_t$ using Eq~\eqref{eq:A_t1_update}, the third step follows that we extract the scalar values from Kronecker product, the fourth step comes from splitting into two partitions based on whether $i = j$, the fifth step comes from the definition of $Q_1$ and $Q_2$.




Thus,
\begin{align}\label{eq:bound_gd_Delta_2}
    \Delta_2 = & ~ (\epsilon \lambda)^2 (Q_1 + Q_2) / \| \nabla \Phi_{\lambda}(A_t) \|_F^2 \notag \\
    = & ~ (\epsilon \lambda)^2 (Q_1 + 0) / \| \nabla \Phi_{\lambda}(A_t) \|_F^2 \notag \\
    = & ~ (\epsilon \lambda )^2 \cdot ( \sqrt{m} + \frac{1}{\lambda} \| \nabla \Phi_{\lambda}(A_t) \|_F ).
\end{align}
where the second step follows from Claim~\ref{cla:gd_Q2}, and the third step follows from Claim~\ref{cla:gd_Q1}.

Hence, we have
\begin{align*}
    & ~ \Phi_{\lambda} (A_{t+1}) - \Phi_{\lambda} (A_t) \\
    \leq & ~  \Delta_1    + O(1) \cdot \Delta_2 \\
    \leq & ~ - \epsilon \| \nabla \Phi_{\lambda}(A_t) \|_F   + O(1) (\epsilon \lambda)^2 (\sqrt{m} + \frac{1}{\lambda} \| \nabla \Phi_{\lambda}(A_t) \|_F ) \\
    \leq & ~ - 0.9 \epsilon \| \Phi_{\lambda}(A_t) \|_F+ O(\epsilon \lambda)^2 \sqrt{m} 
\end{align*}
where the first step follows from Eq.~\eqref{eq:gd_define_Delta_1_and_Delta_2}, the second step follows from Eq.~\eqref{eq:bound_gd_Delta_1} and Eq.~\eqref{eq:bound_gd_Delta_2},  the third step follows from $\epsilon \lambda \in (0, 0.01)$.

For $\| \Phi_{\lambda} (A_t) \|_F$, we have
\begin{align}\label{eq:phi_At_F_norm}
& ~ \frac{1}{\lambda^2} \| \nabla \Phi_{\lambda} (A_t) \|_F^2 \notag \\
= & ~   \tr[ (\sum_{i=1}^m u_i u_i^\top \sinh( \lambda( u_i^\top A_t u_i - b_i ) )  )^2 ] \notag\\
= & ~   \tr[ \sum_{i=1}^m (u_i u_i^\top)^{2} \sinh^2 ( \lambda( u_i^\top A_t u_i - b_i ) )  ] \notag\\ 
= & ~ \sum_{i=1}^m \sinh^2 ( \lambda ( u_i^\top A_t u_i - b_i ) ) \notag \\ 
\geq & ~ \frac{1}{m} ( \sum_{i=1}^m \cosh ( \lambda ( u_i^\top A_t u_i - b_i ) ) - m )^2 \notag \\
= & ~ \frac{1}{m} ( \Phi_{\lambda} (A_t) - m )^2,
\end{align}
where the first step comes from Eq.~\eqref{eq:gradient_phi_A},
the second  steps follow from $u_i^\top u_j = 0$, the third step follows from $\| u_i \|_2 = 1$, the forth step follows from Part 2 in Lemma~\ref{lem:property_sinh_cosh_scalar}, {  the fifth step follows from the definition of $\Phi_{\lambda}(A)$.}

Thus, we get that
\begin{align}\label{eq:bound_gd_Delta_1}
\| \Phi_{\lambda} (A_t) \|_F^2 \geq ~
\lambda \epsilon \cdot \frac{1}{ \sqrt{m} } | \Phi_{\lambda}(A_t) - m |,
\end{align}

It implies that
\begin{align*}
&\Phi_{\lambda} (A_{t+1}) - \Phi_{\lambda} (A_t)\\
\leq & ~ -0.9 \epsilon \lambda \frac{1}{\sqrt{m}} | \Phi_{\lambda}(A_t) - m| +O(\epsilon \lambda)^2 \sqrt{m}\\
\leq &~ -0.9 \epsilon \lambda \frac{1}{\sqrt{m}} | \Phi_{\lambda}(A_t) - m| + 0.1\epsilon \lambda\sqrt{m},
\end{align*}
where the second step follows from extracting the constant term from the summation.

Then, when $\Phi(A_t)> m$, we have
\begin{align*}
    \Phi_{\lambda} (A_{t+1}) \leq (1-0.9 \frac{ \lambda \epsilon }{\sqrt{m} }) \cdot \Phi_{\lambda} (A_t) +  \lambda \epsilon \sqrt{m}.
\end{align*}
When $\Phi(A_t)\leq m$, we have
\begin{align*}
    \Phi_{\lambda} (A_{t+1}) \leq (1+0.9 \frac{ \lambda \epsilon }{\sqrt{m} }) \cdot \Phi_{\lambda} (A_t) -0.8  \lambda \epsilon \sqrt{m}.
\end{align*}

The lemma is then proved.
\end{proof}

 




 




\subsection{Proof of GD Convergence}\label{sec:gd_convergence_proof}
In this section, we provide proofs of convergence analysis of gradient descent matrix sensing algorithm.

\begin{lemma}[Restatement of Lemma~\ref{lem:gd_convergence}]
Suppose the measurement vectors $\{u_i\}_{i\in [m]}$ are orthogonal unit vectors, and suppose $|b_i|$ is bounded by $R$ for $i\in [m]$.  Then, for any $\delta \in (0,1)$, if we take $\lambda = \Omega(\delta^{-1}\log m)$ and $\epsilon=O(\lambda^{-1})$ in Algorithm~\ref{alg:GD}, then for $T=\widetilde{\Omega}(\sqrt{m}R\delta^{-1})$ iterations, the solution matrix $A_T$ satisfies:
\begin{align*}
    | u_i^\top A_{T} u_i - b_i| \leq \delta~~~\forall i\in [m].
\end{align*}
\end{lemma}

\begin{proof}
Let $\tau = \max_{i\in [m]} b_i$. At the beginning, we choose the initial solution $A_1 :=\tau I_n$ where $I_n \in \R^{n \times n}$ is the identity matrix, and we have
\begin{align*}
    \Phi(A_1) =&~ \sum_{i=1}^m \cosh(\lambda\cdot (\tau - b_i))\\
    \leq &~ e^{\lambda \tau} \sum_{i=1}^m e^{-\lambda b_i}\leq 2^{O(\lambda R)},
\end{align*}
where the last step follows from $|b_i|\leq R$ for all $i\in [m]$.

After $T$ iterations, we have
\begin{align*}
    \Phi(A_{T+1}) \leq & ~ (1-\frac{\epsilon \lambda}{\sqrt{m}})^T \Phi(A_1) + 2  m \\
    \leq & ~ (1-\frac{\epsilon \lambda}{\sqrt{m}})^T \cdot 2^{O(\lambda R) }+ 2  m \\
    \leq & ~ 2^{-\Omega( T  \epsilon \lambda / \sqrt{m} ) + O(\lambda R)} + 2  m
\end{align*}
where the first step follows from applying Lemma~\ref{lem:gradient_descent} for $T$ times, and $\sum_{i=1}^T (1-\epsilon\lambda/\sqrt{m})^{i-1}\epsilon \lambda \sqrt{m}\leq 2m$.

As long as $T= \Omega(R \sqrt{m} / \epsilon )=\Omega(R\sqrt{m}\lambda)$, then we have
\begin{align*}
    \Phi(A_{T+1}) \leq O(m).
\end{align*}

This implies that for any $i\in [m]$,
\begin{align*}
    | u_i^\top A_{T+1} u_i - b_i| \leq &~ \lambda^{-1}\cdot \cosh^{-1}(O(m))\\
    = &~ \lambda^{-1}\cdot O(\log m)\\
    = &~ \delta,
\end{align*}
where we take $R = \Omega(\delta^{-1}\log m)$.  

Therefore, with $T=\widetilde{\Omega}(\sqrt{m}R\delta^{-1})$ iterations, Algorithm~\ref{alg:GD} can achieve that
\begin{align}\label{eq:gd_approximation_guarantee}
    | u_i^\top A_{T+1} u_i - b_i| \leq \delta~~~\forall i\in [m].
\end{align}
The theorem is then proved.
\end{proof}
