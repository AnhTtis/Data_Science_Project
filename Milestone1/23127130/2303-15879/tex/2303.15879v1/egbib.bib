@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 目标检测 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{deformableDETR,
  author    = {Xizhou Zhu and
               Weijie Su and
               Lewei Lu and
               Bin Li and
               Xiaogang Wang and
               Jifeng Dai},
  title     = {Deformable {DETR:} Deformable Transformers for End-to-End Object Detection},
  booktitle = {{ICLR}},
  publisher = {OpenReview.net},
  year      = {2021}
}
@inproceedings{maskrcnn,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={ICCV},
  pages={2961--2969},
  year={2017}
}
@inproceedings{DETR,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={ECCV},
  pages={213--229},
  year={2020},
  organization={Springer}
}
@inproceedings{sparsercnn,
  title={Sparse r-cnn: End-to-end object detection with learnable proposals},
  author={Sun, Peize and Zhang, Rufeng and Jiang, Yi and Kong, Tao and Xu, Chenfeng and Zhan, Wei and Tomizuka, Masayoshi and Li, Lei and Yuan, Zehuan and Wang, Changhu and others},
  booktitle={CVPR},
  pages={14454--14463},
  year={2021}
}
@inproceedings{cascadercnn, 
  title={Cascade r-cnn: Delving into high quality object detection}, 
  author={Cai, Zhaowei and Vasconcelos, Nuno}, 
  booktitle={CVPR}, pages={6154--6162}, 
  year={2018}
}
@inproceedings{rcnn,
  title={Rich feature hierarchies for accurate object detection and semantic segmentation},
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={CVPR},
  pages={580--587},
  year={2014}
}
@inproceedings{fasterrcnn,
  author    = {Shaoqing Ren and
               Kaiming He and
               Ross B. Girshick and
               Jian Sun},
  title     = {Faster {R-CNN:} Towards Real-Time Object Detection with Region Proposal
               Networks},
  booktitle = {{NIPS}},
  pages     = {91--99},
  year      = {2015}
}
@inproceedings{yolo9000,
  title={YOLO9000: better, faster, stronger},
  author={Redmon, Joseph and Farhadi, Ali},
  booktitle={CVPR},
  pages={7263--7271},
  year={2017}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 时空动作检测 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{ava,
  title={Ava: A video dataset of spatio-temporally localized atomic visual actions},
  author={Gu, Chunhui and Sun, Chen and Ross, David A and Vondrick, Carl and Pantofaru, Caroline and Li, Yeqing and Vijayanarasimhan, Sudheendra and Toderici, George and Ricco, Susanna and Sukthankar, Rahul and others},
  booktitle={CVPR},
  pages={6047--6056},
  year={2018}
}
@article{avakinetics,
  title={The ava-kinetics localized human actions video dataset},
  author={Li, Ang and Thotakuri, Meghana and Ross, David A and Carreira, Jo{\~a}o and Vostrikov, Alexander and Zisserman, Andrew},
  journal={arXiv preprint arXiv:2005.00214},
  year={2020}
}
@inproceedings{carcnn,
  title={Context-aware rcnn: A baseline for action detection in videos},
  author={Wu, Jianchao and Kuang, Zhanghui and Wang, Limin and Zhang, Wayne and Wu, Gangshan},
  booktitle={ECCV},
  pages={440--456},
  year={2020},
  organization={Springer}
}
@inproceedings{slowfast,
  title={Slowfast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={ICCV},
  pages={6202--6211},
  year={2019}
}
@inproceedings{lfb,
  title={Long-term feature banks for detailed video understanding},
  author={Wu, Chao-Yuan and Feichtenhofer, Christoph and Fan, Haoqi and He, Kaiming and Krahenbuhl, Philipp and Girshick, Ross},
  booktitle={CVPR},
  pages={284--293},
  year={2019}
}

@inproceedings{acarn,
  title={Actor-context-actor relation network for spatio-temporal action localization},
  author={Pan, Junting and Chen, Siyu and Shou, Mike Zheng and Liu, Yu and Shao, Jing and Li, Hongsheng},
  booktitle={CVPR},
  pages={464--474},
  year={2021}
}
@inproceedings{acrn,
  title={Actor-centric relation network},
  author={Sun, Chen and Shrivastava, Abhinav and Vondrick, Carl and Murphy, Kevin and Sukthankar, Rahul and Schmid, Cordelia},
  booktitle={ECCV},
  pages={318--334},
  year={2018}
}
@inproceedings{stagn,
  title={Spatio-temporal action graph networks},
  author={Herzig, Roei and Levi, Elad and Xu, Huijuan and Gao, Hang and Brosh, Eli and Wang, Xiaolong and Globerson, Amir and Darrell, Trevor},
  booktitle={ICCVW},
  pages={0--0},
  year={2019}
}
@inproceedings{step, 
  title={Step: Spatio-temporal progressive learning for video action detection}, 
  author={Yang, Xitong and Yang, Xiaodong and Liu, Ming-Yu and Xiao, Fanyi and Davis, Larry S and Kautz, Jan}, booktitle={CVPR}, pages={264--272}, year={2019} 
}

@inproceedings{woo,
  title={Watch only once: An end-to-end video action detection framework},
  author={Chen, Shoufa and Sun, Peize and Xie, Enze and Ge, Chongjian and Wu, Jiannan and Ma, Lan and Shen, Jiajun and Luo, Ping},
  booktitle={ICCV},
  pages={8178--8187},
  year={2021}
}
@article{yowo,
  title={You only watch once: A unified cnn architecture for real-time spatiotemporal action localization},
  author={K{\"o}p{\"u}kl{\"u}, Okan and Wei, Xiangyu and Rigoll, Gerhard},
  journal={arXiv preprint arXiv:1911.06644},
  year={2019}
}
@inproceedings{aia,
  title={Asynchronous interaction aggregation for action detection},
  author={Tang, Jiajun and Xia, Jin and Mu, Xinzhi and Pang, Bo and Lu, Cewu},
  booktitle={ECCV},
  pages={71--87},
  year={2020},
  organization={Springer}
}
@inproceedings{moc,
  title={Actions as moving points},
  author={Li, Yixuan and Wang, Zixu and Wang, Limin and Wu, Gangshan},
  booktitle={ECCV},
  pages={68--84},
  year={2020},
  organization={Springer}
}

@inproceedings{fat,
  title={Finding action tubes},
  author={Gkioxari, Georgia and Malik, Jitendra},
  booktitle={CVPR},
  pages={759--768},
  year={2015}
}

@inproceedings{multitwo,
  title={Multi-region two-stream R-CNN for action detection},
  author={Peng, Xiaojiang and Schmid, Cordelia},
  booktitle={ECCV},
  pages={744--759},
  year={2016},
  organization={Springer}
}

@inproceedings{hfcn,
  title={Actionness estimation using hybrid fully convolutional networks},
  author={Wang, Limin and Qiao, Yu and Tang, Xiaoou and Van Gool, Luc},
  booktitle={CVPR},
  pages={2708--2717},
  year={2016}
}

@inproceedings{learningtrack, 
  title={Learning to track for spatio-temporal action localization}, 
  author={Weinzaepfel, Philippe and Harchaoui, Zaid and Schmid, Cordelia}, 
  booktitle={ICCV}, 
  pages={3164--3172}, 
  year={2015}
}

@inproceedings{online,
  title={Online real-time multiple spatiotemporal action localisation and prediction},
  author={Singh, Gurkirt and Saha, Suman and Sapienza, Michael and Torr, Philip HS and Cuzzolin, Fabio},
  booktitle={ICCV},
  pages={3637--3646},
  year={2017}
}

@inproceedings{vat,
  title={Video action transformer network},
  author={Girdhar, Rohit and Carreira, Joao and Doersch, Carl and Zisserman, Andrew},
  booktitle={CVPR},
  pages={244--253},
  year={2019}
}

@inproceedings{hcstal,
  title={Human centric spatio-temporal action localization},
  author={Jiang, Jianwen and Cao, Yu and Song, Lin and Zhang, Shiwei and Li, Yunkai and Xu, Z and Wu, Q and Gan, C and Zhang, C and Yu, G},
  booktitle={CVPRW},
  year={2018}
}

@inproceedings{jhmdb,
  author    = {Hueihan Jhuang and
               Juergen Gall and
               Silvia Zuffi and
               Cordelia Schmid and
               Michael J. Black},
  title     = {Towards Understanding Action Recognition},
  booktitle = {ICCV},
  pages     = {3192--3199},
  publisher = {{IEEE} Computer Society},
  year      = {2013}
}

@article{ucf101,
  author    = {Khurram Soomro and
               Amir Roshan Zamir and
               Mubarak Shah},
  title     = {{UCF101:} {A} Dataset of 101 Human Actions Classes From Videos in
               The Wild},
  journal   = {CoRR},
  volume    = {abs/1212.0402},
  year      = {2012}
}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% action recognition %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{timesformer,
  author    = {Gedas Bertasius and
               Heng Wang and
               Lorenzo Torresani},
  title     = {Is Space-Time Attention All You Need for Video Understanding?},
  booktitle = {{ICML}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {813--824},
  publisher = {{PMLR}},
  year      = {2021}
}

@inproceedings{vidtr,
  title={Vidtr: Video transformer without convolutions},
  author={Zhang, Yanyi and Li, Xinyu and Liu, Chunhui and Shuai, Bing and Zhu, Yi and Brattoli, Biagio and Chen, Hao and Marsic, Ivan and Tighe, Joseph},
  booktitle={ICCV},
  pages={13577--13587},
  year={2021}
}
@inproceedings{vivit, 
  title={Vivit: A video vision transformer}, 
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{'c}, Mario and Schmid, Cordelia}, 
  booktitle={ICCV}, 
  pages={6836--6846}, 
  year={2021}
}

@inproceedings{videoswin,
  author    = {Ze Liu and
               Jia Ning and
               Yue Cao and
               Yixuan Wei and
               Zheng Zhang and
               Stephen Lin and
               Han Hu},
  title     = {Video Swin Transformer},
  booktitle = {{CVPR}},
  pages     = {3192--3201},
  publisher = {{IEEE}},
  year      = {2022}
}

@inproceedings{mvit,
  title={Multiscale vision transformers},
  author={Fan, Haoqi and Xiong, Bo and Mangalam, Karttikeya and Li, Yanghao and Yan, Zhicheng and Malik, Jitendra and Feichtenhofer, Christoph},
  booktitle={ICCV},
  pages={6824--6835},
  year={2021}
}
@inproceedings{c3d,
  title={Learning spatiotemporal features with 3d convolutional networks},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle={ICCV},
  pages={4489--4497},
  year={2015}
}
@inproceedings{s3d,
  title={Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs in video classification},
  author={Xie, Saining and Sun, Chen and Huang, Jonathan and Tu, Zhuowen and Murphy, Kevin},
  booktitle={ECCV},
  pages={305--321},
  year={2018}
}
@inproceedings{i3d,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={CVPR},
  pages={6299--6308},
  year={2017}
}
@inproceedings{r2p1d,
  author    = {Du Tran and
               Heng Wang and
               Lorenzo Torresani and
               Jamie Ray and
               Yann LeCun and
               Manohar Paluri},
  title     = {A Closer Look at Spatiotemporal Convolutions for Action Recognition},
  booktitle = {{CVPR}},
  pages     = {6450--6459},
  publisher = {Computer Vision Foundation / {IEEE} Computer Society},
  year      = {2018}
}

@inproceedings{non-local,
  title={Non-local neural networks},
  author={Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
  booktitle={CVPR},
  pages={7794--7803},
  year={2018}
}

@misc{fan2020pyslowfast,
  author =       {Haoqi Fan and Yanghao Li and Bo Xiong and Wan-Yen Lo and
                  Christoph Feichtenhofer},
  title =        {PySlowFast},
  howpublished = {\url{https://github.com/facebookresearch/slowfast}},
  year =         {2020}
}

@inproceedings{csn,
  author    = {Du Tran and
               Heng Wang and
               Matt Feiszli and
               Lorenzo Torresani},
  title     = {Video Classification With Channel-Separated Convolutional Networks},
  booktitle = {{ICCV}},
  pages     = {5551--5560},
  publisher = {{IEEE}},
  year      = {2019}
}

@inproceedings{vmae,
  author    = {Zhan Tong and
               Yibing Song and
               Jue Wang and
               Limin Wang},
  title     = {{VideoMAE}: Masked Autoencoders are Data-Efficient Learners for Self-Supervised
               Video Pre-Training},
  booktitle = {NeurIPS},
  year      = {2022}
}

@article{kinetics400,
  title={The kinetics human action video dataset},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and others},
  journal={arXiv preprint arXiv:1705.06950},
  year={2017}
}
@article{kinetics600,
  title={A short note about kinetics-600},
  author={Carreira, Joao and Noland, Eric and Banki-Horvath, Andras and Hillier, Chloe and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1808.01340},
  year={2018}
}
@article{kinetics700,
  title={A short note on the kinetics-700-2020 human action dataset},
  author={Smaira, Lucas and Carreira, Jo{\~a}o and Noland, Eric and Clancy, Ellen and Wu, Amy and Zisserman, Andrew},
  journal={arXiv preprint arXiv:2010.10864},
  year={2020}
}




%%%%%%%%%%%%%%%%%%image datasets%%%%%%%%%%%%%%%%%
@inproceedings{coco,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={ECCV},
  pages={740--755},
  year={2014},
  organization={Springer}
}
@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={CVPR},
  pages={248--255},
  year={2009},
  organization={Ieee}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% others %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



@article{layernorm,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@inproceedings{mlpmixer,
  author    = {Ilya O. Tolstikhin and
               Neil Houlsby and
               Alexander Kolesnikov and
               Lucas Beyer and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Jessica Yung and
               Andreas Steiner and
               Daniel Keysers and
               Jakob Uszkoreit and
               Mario Lucic and
               Alexey Dosovitskiy},
  title     = {MLP-Mixer: An all-MLP Architecture for Vision},
  booktitle = {NeurIPS},
  pages     = {24261--24272},
  year      = {2021}
}







@inproceedings{TubeR,
  author    = {Jiaojiao Zhao and
               Yanyi Zhang and
               Xinyu Li and
               Hao Chen and
               Bing Shuai and
               Mingze Xu and
               Chunhui Liu and
               Kaustav Kundu and
               Yuanjun Xiong and
               Davide Modolo and
               Ivan Marsic and
               Cees G. M. Snoek and
               Joseph Tighe},
  title     = {TubeR: Tubelet Transformer for Video Action Detection},
  booktitle = {{CVPR}},
  pages     = {13588--13597},
  publisher = {{IEEE}},
  year      = {2022}
}

@inproceedings{AdaMixer,
  author    = {Ziteng Gao and
               Limin Wang and
               Bing Han and
               Sheng Guo},
  title     = {AdaMixer: {A} Fast-Converging Query-Based Object Detector},
  booktitle = {{CVPR}},
  pages     = {5354--5363},
  publisher = {{IEEE}},
  year      = {2022}
}

@article{VitDet,
  author    = {Yanghao Li and
               Hanzi Mao and
               Ross B. Girshick and
               Kaiming He},
  title     = {Exploring Plain Vision Transformer Backbones for Object Detection},
  journal   = {CoRR},
  volume    = {abs/2203.16527},
  year      = {2022}
}

@inproceedings{ViT,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition
               at Scale},
  booktitle = {{ICLR}},
  publisher = {OpenReview.net},
  year      = {2021}
}

@inproceedings{attention,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention is All you Need},
  booktitle = {{NIPS}},
  pages     = {5998--6008},
  year      = {2017}
}

@inproceedings{groupconv,
  author    = {Saining Xie and
               Ross B. Girshick and
               Piotr Doll{\'{a}}r and
               Zhuowen Tu and
               Kaiming He},
  title     = {Aggregated Residual Transformations for Deep Neural Networks},
  booktitle = {{CVPR}},
  pages     = {5987--5995},
  publisher = {{IEEE} Computer Society},
  year      = {2017}
}

@article{linearscale,
  author    = {Priya Goyal and
               Piotr Doll{\'{a}}r and
               Ross B. Girshick and
               Pieter Noordhuis and
               Lukasz Wesolowski and
               Aapo Kyrola and
               Andrew Tulloch and
               Yangqing Jia and
               Kaiming He},
  title     = {Accurate, Large Minibatch {SGD:} Training ImageNet in 1 Hour},
  journal   = {CoRR},
  volume    = {abs/1706.02677},
  year      = {2017}
}


@inproceedings{fpn,
  title={Feature pyramid networks for object detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={CVPR},
  pages={2117--2125},
  year={2017}
}

@article{adamw,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@inproceedings{hit,
  author    = {Gueter Josmy Faure and
               Min{-}Hung Chen and
               Shang{-}Hong Lai},
  title     = {Holistic Interaction Transformer Network for Action Detection},
  booktitle = {{WACV}},
  pages     = {3329--3339},
  publisher = {{IEEE}},
  year      = {2023}
}

@inproceedings{VideoMAEv2,
  author    = {Limin Wang and
               Bingkun Huang and
               Zhiyu Zhao and
               Zhan Tong and
               Yihan He and
               Yi Wang and
               Yali Wang and
               Yu Qiao},
  title     = {{VideoMAE V2}: Scaling Video Masked Autoencoders with Dual Masking},
  booktitle = {{CVPR}},
  year      = {2023}
}

@inproceedings{multisports,
  author    = {Yixuan Li and
               Lei Chen and
               Runyu He and
               Zhenzhi Wang and
               Gangshan Wu and
               Limin Wang},
  title     = {MultiSports: {A} Multi-Person Video Dataset of Spatio-Temporally Localized
               Sports Actions},
  booktitle = {{ICCV}},
  pages     = {13516--13525},
  publisher = {{IEEE}},
  year      = {2021}
}