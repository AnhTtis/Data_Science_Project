\begin{algorithm}
\textbf{Inputs}:
            
        \hspace*{0.2cm} \textit{Datasets:} $\mathbb{D}_{u}$, $\mathbb{D}_{l}$\\
        \hspace*{0.2cm} \textit{\#Epochs:} $max\_ssl\_epoch_{I}$, $max\_ssl\_epoch_{D}$, $max\_epoch_{tune}$, 
        $max\_epoch$\\
        \hspace*{0.2cm} \textit{Learning Rates: $\alpha_I$, $\alpha_D$, $\alpha_S$}
        
\textbf{Output}: Student model $\theta_{S}$
    

\SetAlgoLined
Initialize $\theta_I$, $\theta_D$ randomly;

Initialize $\theta_S$ with any SSL~\cite{tclr, cvrl} method on $\mathbb{D}_{u}$;

\hrule

Temporally-Invariant Self-supervised Pretraining:

\For{$e_0 \gets 1$ \KwTo $max\_ssl\_epoch_{I}$}
{   
    $\theta_{I} \gets \theta_I-\alpha_I\nabla_{\theta_I}L_{I}(\theta_I)$
}
Temporally-Distinctive Self-supervised Pretraining:

\For{$e_0 \gets 1$ \KwTo $max\_ssl\_epoch_{D}$}
{   
    $\theta_{D} \gets \theta_D-\alpha_D\nabla_{\theta_D}L_{D}(\theta_D)$
}

Compute the similarity score $s^{(i)}$ using Eq.~\ref{eq:similarity1}
\hrule



Finetuning the teacher models on labeled set $\mathbb{D}_{l}$:

\For{$e_0 \gets 1$ \KwTo $max\_epoch_{tune}$}
{   
    $\theta_{I}^{*} = argmin_{\theta_{I}} L_{sup}(\theta_{I})$ 
    
    $\theta_{D}^{*} = argmin_{\theta_{D}} L_{sup}(\theta_{D})$
    
}

\hrule

Semi-supervised training of student on $\mathbb{D}_{l}$ + $\mathbb{D}_{u}$:

\For{$e_0 \gets 1$ \KwTo $max\_epoch$}
{   

    $L$= $L_{sup}(\theta_S) +  \omega L_{unsup}(\theta_S, \theta_{D}^{*}, \theta_{I}^{*}, s^{(i)})$
    
    $\theta_{S} \gets \theta_S- \alpha_S\nabla_{\theta_S}L$


}
\caption{TimeBalance training algorithm}
 \label{alg:algo1}

\end{algorithm}
