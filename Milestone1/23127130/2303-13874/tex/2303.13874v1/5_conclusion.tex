% \section{Limitation, Societal Impact, and Conclusion}
\section{Limitation and Conclusion}
\paragraph{Limitation}
As elaborated in the paper, we aim to highlight the role of the text query in retrieving the relevant moments and estimating their accordance level with the given text query. 
Likewise, the proposed components expect a given query to maintain a meaningful context. 
If not, and noisy text queries are provided, i.e., mismatched or irrelevant ground truth texts, the training may not be effective as reported.
% 원준 원본
% As we illustrated in the paper, our goal is to highlight the role of query in searching the moments.
% Likewise, since our objective expects the query to retain meaningful contexts, it may not work well when given text queries are noisy.
% 상익 수정
% As elaborated in the paper, we aim to highlight the role of the text query in retrieving the relevant moments and estimating their accordance level with the given query. 
% Likewise, the proposed components expect that the given query retains semantically meaningful contexts. 
% Otherwise, for example, if noisy text queries are given as input, our method may fail to localize the desirable moments.
% % Likewise, the proposed components, in both architectural and training scheme aspects, expect that the given query retains semantically meaningful contexts. 
% Otherwise, for example, if noisy text queries are given as input, our method may fail to localize the desirable moments.
% \paragraph{Potential negative societal impacts.} 
% Long video content may not record high full-video view counts, which may affect the video suppliers and the quality of information that viewers perceive.
% It may also result in information distortion.
\vspace{-10pt}
\paragraph{Conclusion}
Although the advent of transformer architecture has been powerful for MR/HD, investigation of the role of text query has been lacking in such architectures.
Therefore, we focused on studying the role of the text query.
As we found that the textual information is not fully exploited in expressing the video representations, we designed the cross-attentive transformer encoder and proposed a negative-pair training scheme.
Cross-attentive encoder assures the query's contributions while extracting video representation, and negative-pair training enforces the model to learn the relationship between query and video by preventing solving the problems without consideration of the query.
Finally, to preserve the diversity of query-dependent video representation, we defined the saliency token to be an input-adaptive saliency predictor.
Extensive experiments validated the strength of QD-DETR with superior performances. 

\vspace{5pt}
\noindent\textbf{Acknowledgements.} This work was supported in part by MSIT/IITP (No. 2022-0-00680, 2019-0-00421, 2020-0-01821, 2021-0-02068), and MSIT\&KNPA/KIPoT (Police Lab 2.0, No. 210121M06).