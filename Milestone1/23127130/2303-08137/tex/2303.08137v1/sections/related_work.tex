\section{Related Work}
\subsection{Layout Generation}
Studies on automatic layout generation have appeared several times in literature~\cite{lok2001survey,agrawala2011design,o2014learning,yang2016automatic}.
Layout tasks are commonly observed in design applications, including magazine covers, posters, presentation slides, application user interface, or banner advertising~\cite{deka2017rico, yang2016automatic,zheng2019content,qian2020retrieve,yamaguchi2021canvasvae,guo2021vinci,kikuchi2021modeling,fu2022doc2ppt}.
Recent approaches to layout generation consider both unconditional generation~\cite{jyothi2019layoutvae,gupta2021layout,arroyo2021variational,jiang2022coarse} and conditional generation in various setups, such as conditional inputs of category or size~\cite{li2019layoutgan,lee2020neural,Kikuchi2021,kong2022blt}, relational constraints~\cite{lee2020neural,Kikuchi2021}, element completion~\cite{gupta2021layout}, and refinement~\cite{rahman2021ruite}.
Some attempt at solving multiple tasks in a single model~\cite{kong2022blt,paschalidou2021atiss}.

BLT~\cite{kong2022blt} points out that the recent autoregressive decoders~\cite{arroyo2021variational,gupta2021layout} are not fully capable of considering partial inputs, \ie known elements or attributes, during generation because they have a fixed generation order.
BLT addresses the conditional generation by fill-in-the-blank task formulation using a bidirectional Transformer encoder similar to masked language models~\cite{devlin-etal-2019-bert}.
However, BLT cannot solve layout completion demonstrated in the decoder-based models because of the requirement of the known number of elements.
Our LayoutDM enjoys the best of both worlds and supports a broader range of conditional generation tasks in a single model.

Another layout-specific consideration is the complex user-specified constraints, such as the positional requirements between two boxes (e.g., a header box should be on top of a paragraph box).
Earlier approaches~\cite{merrell2011interactive,yu2011make,o2014learning} propose hand-crafted cost functions representing the violation degree of aesthetic constraints so that those constraints guide the optimization process of layout inference.
CLG-LO~\cite{Kikuchi2021} proposes an aesthetically constrained optimization framework for pre-trained GANs.
Our LayoutDM solves such constrained generation tasks on top of the task-agnostic iterative prediction via logit adjustment.

\subsection{Discrete Diffusion Models}
Diffusion models~\cite{sohl2015deep} are generative models characterized by a forward and reverse Markov process.
The forward process corrupts the data into a sequence of increasingly noisy variables.
The reverse process gradually denoises the variables toward the actual data distribution.
Diffusion models are stable to train and achieve faster sampling than autoregressive models by parallel iterative refinement.
Recently, many approaches have learned the reverse process by a neural network and show strong empirical performance~\cite{ho2020denoising,song2020improved,dhariwal2021diffusion} in continuous state spaces, such as images.

Discrete state spaces are a natural representation of discrete variables, such as text. D3PM~\cite{austin2021structured} extends the pioneering work of Hoogeboom~\etal~\cite{hoogeboom2021argmax} to structured categorical corruption processes for diffusion models in discrete state spaces, while maintaining the advantages of diffusion models for continuous state spaces.
VQDiffusion~\cite{gu2022vector} develops a corruption approach called mask-and-replace, so as to avoid accumulated prediction errors that are common in models based on iterative prediction.
Following the corruption model of VQDiffusion, we carefully design a modality-wise corruption process for layout tasks that involve tokens from disjoint sets of vocabulary per modality.


Several studies consider a conditional input to the inference process of diffusion models.
Some approaches alter the reverse diffusion iteration to carefully inject given conditions for free-form image inpainting~\cite{lugmayr2022repaint} or image editing by strokes or composition~\cite{meng2022sdedit}.
We extend the discrete state-space diffusion models via hard masking or logit adjustment to support the conditional generation of layouts.
