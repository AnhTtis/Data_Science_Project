\section{Implementation Details}

\subsection{Baseline}
We explain more details on task-agnostic layout generation baselines using masking, especially when the original model is not designed for layout generation.
We mostly describe unconditional generation cases, but partial layout fields can be easily injected by hard masking.

\noindent \textbf{BART}: BART is a denoising autoencoder and was originally designed for learning a sequence-to-sequence model for text generation.
Text is usually represented as a 1D sequence of discrete tokens.
Since we also handle the shuffled layout as a 1D sequence of discrete tokens during training, a BART-like model may be another solid baseline.
To build a task-agnostic layout generation model, we apply random masking similar to the noise pattern of MaskGIT~\cite{chang2022maskgit}, instead of text-specific noises, such as span-level masking.

\noindent \textbf{MaskGIT$^\ast$}:
MaskGIT~\cite{chang2022maskgit} is originally built for unconditional image generation.
Following recent two-stage approaches for efficient image modeling, such as VQ-GAN~\cite{esser2021taming}, MaskGIT first generates a small number of discrete tokens and subsequently decodes those tokens into a continuous high-dimensional image by a pre-trained neural decoder.
We consider the first generation part of MaskGIT to be another baseline.
We use \texttt{[PAD]} to enable variable-length generation.
For a masking schedule during decoding, \ie fraction of the tokens masked in each iteration, we employ a cosine schedule as in MaskGIT.

\noindent \textbf{VQDiffusion$^\ast$}: VQDiffusion~\cite{gu2022vector} is a discrete diffusion-based model designed for text-to-image generation.
To adapt VQDiffusion for conditional layout generation with minimal modification, we (i) remove the text conditioning branch in the reverse process, (ii) replace the image tokens with layout tokens, and (iii) add \texttt{[PAD]} token to enable variable-length generation. As described in the main manuscript, there are three major differences between VQDiffusion$^\ast$ and our proposed LayoutDM: modality-wise diffusion, decoupled positional encoding, and adaptive quantization.

We adjust the number of parameters for each model to have about 12M parameters for a fair comparison.
We show the exact numbers in \cref{tab:number_of_parameters}.

\subsection{Relationship Guidance}
Similarly to the main manuscript, let us denote the predicted coordinates of an $i$-th element $(\hat{x}_{i},\hat{y}_{i},\hat{w}_{i},\hat{h}_{i}) \in [0, 1]^{4}$. We follow ~\cite{Kikuchi2021} to define the loss for penalizing size and location relationships between elements that do not match user specifications. For example, if we want to make the $j$-th element larger than the $i$-th element, the loss is defined by:
\begin{equation}
    g_{lg}(i, j) = \max\left(\left(1+\gamma\right)\hat{w}_{i}\hat{h}_{i}-\hat{w}_{j}\hat{h}_{j}, 0\right),
\end{equation}
where $\gamma$ is a tolerance parameter, which is empirically set to 0.1.
If we want to make the $j$-th element above the $i$-th element, the loss is defined by:
\begin{equation}
    g_{ab}(i, j) = \max\left(\left(\hat{y}_{j} + \frac{\hat{h}_{j}}{2}\right) - \left(\hat{y}_{i} - \frac{\hat{h}_{i}}{2}\right), 0\right),
\end{equation}
which compares the bottom of the $j$-th element and the top of the $i$-th element.
Please refer to the code for losses for the rest of the relationships.

Although it is not experimentally demonstrated, we believe that it is also possible to incorporate area, aspect ratio, and reading order constraints used in Attribute-conditioned GAN~\cite{li2020attribute}.
\begin{itemize}[noitemsep,nolistsep,leftmargin=*]
\item Area: given a target area of the element $a_{i} \in \mathbb{R}$, we use $|a_{i} - \hat{h}_{i}\hat{w}_{i}|$ as a loss.
\item Aspect ratio: Given a target aspect ratio $r_{i} \in \mathbb{R}$, we use $|r_{i} - \frac{\hat{h}_{i}}{\hat{w}_{i}}|$ as a loss.
\item Reading order: we follow [22] and define that the reading order solely depends on the distance between the left-top of the canvas and each element.
We first compute the distance by $\hat{d}_{i}=\sqrt{(\hat{x}_{i} - \frac{\hat{w}_{i}}{2})^{2} + (\hat{y}_{i} - \frac{\hat{h}_{i}}{2})^{2}}$.
We can use $\max(\hat{d}_{i} - \hat{d}_{j}, 0)$ as a loss to make the $i$-th element come before the $j$-th element in the reading order.
\end{itemize}

\subsection{Hyper-parameters}
We search for the best hyper-parameters using a validation set.
During sampling from $p_{\theta}\!\left(\bm{z}_{t-1}|\bm{z}_{t}\right)$ for all the tasks, we search for $p$ used in nucleus (or top-$p$) sampling~\cite{holtzman2019curious} out of $\{0.90, 0.95, 0.99, 1.0\}$.
We train the models for 50 and 20 epochs in Rico and PubLayNet, respectively.

We attempt a grid search for additional hyper-parameters in the refinement task.
The ranges of possible values are the following: the distance margin $m$ in $\{0.1, 0.2\}$ and the weighting term $\lambda_{\pi}$ in $\{1.0, 2.0, 3.0, 4.0, 5.0\}$.


\begin{table}[t]
    \centering
    \begin{tabular}{ccc} \toprule
        & Rico & PubLayNet \\ \midrule
        LayoutVAE~\cite{jyothi2019layoutvae}~(C$\rightarrow$S+P) & 13.2 & 13.0 \\
        NDN-none~\cite{lee2020neural}~(C$\rightarrow$S+P) & 21.8 & 21.8 \\
        LayoutGAN++~\cite{Kikuchi2021}~(C$\rightarrow$S+P) & 12.9 &  12.9 \\
        LayoutVAE~\cite{jyothi2019layoutvae}~(C+S$\rightarrow$P) & 14.7 & 14.5 \\
        NDN-none~\cite{lee2020neural}~(C+S$\rightarrow$P) & 14.8 & 14.8  \\
        LayoutGAN++~\cite{Kikuchi2021}~(C+S$\rightarrow$P) & 13.0 & 13.0 \\
        LayoutTrans~\cite{gupta2021layout} & 12.7 & 12.7 \\
        LayoutTrans-fixed~\cite{gupta2021layout} & 12.7 & 12.7 \\
        MaskGIT*~\cite{chang2022maskgit} & 12.7 & 12.7 \\
        BLT~\cite{kong2022blt} & 12.7 & 12.7 \\
        RUITE~\cite{rahman2021ruite} & 12.7 & 12.7 \\
        BART~\cite{lewis2020bart} & 12.8 & 12.8 \\
        VQDiffusion*~\cite{gu2022vector} & 12.4 & 12.4 \\
        LayoutDM & 12.4 & 12.4 \\ \bottomrule
    \end{tabular}
    \caption{
        The number of parameters [M] used for each model.
    }
    \label{tab:number_of_parameters}
\end{table}


\subsection{Evaluation}
In unconditional generation, the model generates 1,000 samples from the random seed.
In conditional generation, the test set of each dataset is used to make a partial input for conditional generation and the model generates one sample per each data in the test set.


\section{Additional Results}

\subsection{Ablation Study}
\paragraph{State space}
Continuous state space diffusion models have gained much attention compared to discrete state space models.
Recently, Li~\etal~\cite{li2022diffusion} propose DiffusionLM that adapts the continuous models to handle discrete text generation.
DiffusionLM introduces an embedding and rounding step to bridge the continuous and discrete state spaces.
We train DiffusionLM (with 12.6M parameters) and show the results in \cref{tab:state-space}.
We show the results of DiffusionLM with embedding dimensions $d=16$ because it works best out of $\{16, 64, 128\}$ in Rico~\cite{deka2017rico} dataset.
Although We tried different samplers (DDPM~\cite{ho2020denoising} and DDIM~\cite{song2020denoising}) and training timesteps, DiffusionLM is still far behind the discrete state space models in layout generation as shown in \cref{tab:state-space}.

\begin{table}[t]
    \centering
    \begin{tabular}{ccccc} \toprule
        & State & \#steps & Sampler & FID $\downarrow$ \\ \midrule
        LayoutDM & dis. & 100 & - & \textbf{6.65} \\
        VQDiffusion*~\cite{gu2022vector} & dis. & 100 & - & \underline{7.46} \\
        \multirow{4}{*}{DiffusionLM~\cite{li2022diffusion}} & con. & 100 & DDIM & 34.5 \\
         & con. & 100 & DDPM & 24.8 \\
         & con. & 1000 & DDIM & 33.8 \\
         & con. & 1000 & DDPM & 22.8 \\ \bottomrule
    \end{tabular}
    \caption{
        Ablation study results on the choice of state spaces: discrete (dis.) and continuous (con.), in the unconditional generation task of Rico~\cite{deka2017rico} dataset. Top two results are highlighted in \textbf{bold} and \underline{underline}, respectively.
    }
    \label{tab:state-space}
\end{table}

\paragraph{Refinement}
The logit adjustment proposed in the main manuscript has some choices for injecting positional prior.
Without loss of generality, we describe a constraint that imposes the x-coordinate estimate of $i$-th element close to the noisy continuous observation $\hat{x}_i$.
We denote a sliced vector of the prior term $\pi\!\left(\bm{z}_{t-1}\right)$ that corresponds to the x-coordinate of $i$-th element as $\bm{\pi}_x^i \in \mathbb{R}^K$.

\begin{itemize}[noitemsep,nolistsep,leftmargin=*]
    \item Gaussian: $j$-th token is more likely to be sampled when $\mathrm{loc}(j)$ is closer to $\hat{x}_{i}$. The prior is defined by:
    \begin{equation}
        \begin{aligned}
        & \left[ \bm{\pi}_x^i \right]_j = \\
        & \begin{cases}
            \left(\mathrm{loc}\left(j\right)-\hat{x}_{i}\right)^{2} & \text{if}\ \left|\mathrm{loc}(j)-\hat{x}_{i}\right| < m~\text{and}~j \in X \\
            0 & \text{otherwise},
        \end{cases}
        \end{aligned}
    \end{equation}
    The ranges of possible values are similar to our method used in the main manuscript (Default).

    \item Negation: $j$-th token is never sampled when $\mathrm{loc}(j)$ is far away from $\hat{x}_{i}$. The prior is defined by:
    \begin{equation}
        \begin{aligned}
        \left[ \bm{\pi}_x^i \right]_j =
        \begin{cases}
            0 & \text{if}\ \left|\mathrm{loc}(j)-\hat{x}_{i}\right| < m~\text{and}~j \in X \\
            -\infty & \text{otherwise}.
        \end{cases}
        \end{aligned}
    \end{equation}
    The ranges of possible values are the following: the distance margin $m$ in $\{0.2, 0.4, 0.6, 0.7, 0.8, 0.9\}$.
\end{itemize}

We show the quantitative evaluation results in \cref{tab:ablation_refinement}.
We can see that Default outperforms other possible choices by a large margin.

\begin{table}[t]
    \centering
    \begin{tabular}{cccc} \toprule
        & FID $\downarrow$ & Max. $\uparrow$ & Sim $\uparrow$ \\ \midrule
        Default & \textbf{2.77}\std{2.0} & \textbf{0.370}\std{0.3} & \textbf{0.205}\std{0.0} \\
        Gaussian & 5.82\std{1.7} & \underline{0.330}\std{0.4} & \underline{0.188}\std{0.3} \\ %
        Negation & \underline{3.78}\std{3.1} & 0.276\std{0.4} & 0.169\std{0.3} \\ \bottomrule %
    \end{tabular}
    \caption{
    Ablation study results on the choice of logit adjustment methods in the refinement task. Top two
results are highlighted in \textbf{bold} and \underline{underline}, respectively.
    }
    \label{tab:ablation_refinement}
\end{table}


\subsection{Speed-Quality Trade-off}
\label{subsec:speed_quality_tradeoff}
We show more speed-quality trade-off curves in \cref{fig:sup_tradeoff_time_fid}.
We perform generation with a batch size of 64 and report the average runtime to generate a single layout for all the models.
Lightly colored regions around the line plots, such as the one in BLT for C$\rightarrow$S+P in Rico represent the standard deviation of three trials for each model, though the deviations are too small to see in most cases.


\subsection{More Results}
We show more results compared with task-specific baselines in C$\rightarrow$S+P (\cref{fig:sup_comparison_c_publaynet}), C+S$\rightarrow$P (\cref{fig:sup_comparison_cwh_publaynet}), unconditional generation (\cref{fig:sup_comparison_unconditional_publaynet}), the refinement task (\cref{fig:sup_comparison_refinement_publaynet}) for PubLayNet.
Typical failure cases are frequent overlap between elements (often in BLT), unnecessarily broad blank space (often in LayoutTrans.), and lack of diversity.
We show more results in C$\rightarrow$S+P (\cref{fig:sup_comparison_c_rico}), C+S$\rightarrow$P (\cref{fig:sup_comparison_cwh_rico}), unconditional generation (\cref{fig:sup_comparison_unconditional_rico}), the refinement task (\cref{fig:sup_comparison_refinement_rico}) for Rico.
Rico is more difficult to generate since the number of categories is large and elements are less aligned compared to PubLayNet.

\subsection{Diversity-Fidelity Trade-off}
We introduce density and coverage metrics by~\cite{naeem2020reliable} to analyze the results from a different viewpoint.
Density measures fidelity; \ie, how closely generated samples resemble real ones.
Coverage measures diversity; \ie, whether generated samples cover the full variability of the real samples.
We plot the diversity and fidelity of iterative refinement-based models in \cref{fig:sup_tradeoff_density_coverage} as we increase the number of timesteps for the iterative prediction.
Discrete diffusion-based models usually have higher coverage scores and lower density scores.
We conjecture that the coverage difference comes from the inference decoding strategy.
BLT~\cite{kong2022blt} and MaskGIT$^\ast$~\cite{chang2022maskgit} fix high-confident predictions and re-initialize lower-confident fields by \texttt{[MASK]} for the next step that leads to higher fidelity.
In contrast, discrete diffusion-based models \textit{randomly} corrupt the predictions and result in higher diversity.


\subsection{Alignment and Overlap}
We additionally show the metrics reported in many previous works: Alignment and Overlap.
Note that these metrics only capture the fidelity of generated layouts.
There are a few variants for both Alignment~\cite{li2019layoutgan,lee2020neural,li2020attribute,Kikuchi2021} and Overlap~\cite{li2019layoutgan,li2020attribute,Kikuchi2021}.
We employ the definition in \cite{Kikuchi2021}.
We scale the values of Alignment by $100\times$ for visibility.
For reference, we show Alignment and Overlap computed in a validation set as~\emph{Real data}.
The lowest score in Alignment or Overlap does not always mean the best performance for a model, but a model closest to~\emph{Real data} is the best model.
We show the result in \cref{fig:sup_overlap_alignment}.
In the fixed-length generation \ie C$\rightarrow$S+P and C+S$\rightarrow$P, LayoutDM performs almost comparably to VQDiffusion*~\cite{gu2022vector} and BART~\cite{lewis2020bart}, and better than the other models.
In the variable-length generation \ie the completion task and unconditional generation, autoregressive models, such as BART~\cite{lewis2020bart} and LayoutTrans.~\cite{gupta2021layout}, are moderately better than LayoutDM.
This result is reasonable since these models predict the fields one by one.
Diffusion-based models, such as LayoutDM and VQDiffusion$^\ast$, are better than BLT and MaskGIT$^\ast$.
We believe this is because diffusion models avoid the error accumulation in iterative prediction according to~\cite{gu2022vector}.

\input{figures/supplementary/time_fid_tradeoff.tex}
\input{figures/supplementary/comparison.tex}
\input{figures/supplementary/density_coverage_tradeoff.tex}
\input{figures/supplementary/overlap_alignment.tex}
