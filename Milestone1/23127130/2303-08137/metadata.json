{
    "arxiv_id": "2303.08137",
    "paper_title": "LayoutDM: Discrete Diffusion Model for Controllable Layout Generation",
    "authors": [
        "Naoto Inoue",
        "Kotaro Kikuchi",
        "Edgar Simo-Serra",
        "Mayu Otani",
        "Kota Yamaguchi"
    ],
    "submission_date": "2023-03-14",
    "revised_dates": [
        "2023-03-15"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.GR"
    ],
    "abstract": "Controllable layout generation aims at synthesizing plausible arrangement of element bounding boxes with optional constraints, such as type or position of a specific element. In this work, we try to solve a broad range of layout generation tasks in a single model that is based on discrete state-space diffusion models. Our model, named LayoutDM, naturally handles the structured layout data in the discrete representation and learns to progressively infer a noiseless layout from the initial input, where we model the layout corruption process by modality-wise discrete diffusion. For conditional generation, we propose to inject layout constraints in the form of masking or logit adjustment during inference. We show in the experiments that our LayoutDM successfully generates high-quality layouts and outperforms both task-specific and task-agnostic baselines on several layout tasks.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.08137v1"
    ],
    "publication_venue": "To be published in CVPR2023, project page: https://cyberagentailab.github.io/layout-dm/"
}