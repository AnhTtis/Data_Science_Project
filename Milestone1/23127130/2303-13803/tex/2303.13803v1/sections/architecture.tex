\section{\sysname architecture}
\label{sec:arch}

\begin{figure}[t]
        \centerline{\includegraphics[width=\linewidth]{figures/Arch_arch.pdf}}
        \vspace{-0.1in}
        \caption{\sysname architecture.}
        \vspace{-0.1in}
        \label{fig:arch_arch}
\end{figure}

\sysname is a cluster system that enables efficient and safe space-sharing in production clusters with tens of thousands of heterogeneous GPUs at \company.
The architecture of \sysname is shown in Figure~\ref{fig:arch_arch}.
\sysname consists of a service manager for online workloads, a global manager for offline workloads, and a set of local executors for each GPU.

\parabf{Service manager.}
In this paper, we only describe the functionality of the service manager briefly as the details of the service manager are beyond the scope of this paper.
The service manager is responsible for online workloads deployment, online requests discovery, and horizontal pod autoscaling.

\parabf{Global manager.} 
When an offline workload is submitted to \sysname, the global manager buffers the offline workload in a pending queue and makes scheduling decisions periodically.
The global manager includes three components: workload profiler, speed predictor, and scheduler.

\textit{Workload profiler.}
The workload profiler gets the GPU resource utilization and execution time for each offline workload.
When an offline workload is first submitted, the workload profiler runs the job for a few iterations and measures the execution information.
The measured information is stored in a database and can be used by the speed predictor when making scheduling decisions.

\textit{Speed predictor.}
When the speed predictor gets an online workload and an offline workload, it can predict the sharing speed of the given workloads.
The speed predictor employs a DL model to perform prediction.
The DL model leverages the execution information when the workloads are executed separately.
The execution information is reported by the GPU monitor for online workloads and is profiled by the workload profiler in advance for offline workloads.
The predicted speed is passed to the scheduler to make scheduling decisions.

\textit{Scheduler.}
The scheduler schedules the offline workloads from the pending queue.
By utilizing the predicted speed from the speed predictor, the scheduler exploits a matching-based scheduling algorithm to decide which offline workload and online workload should share the same GPU.
The scheduling algorithm can find the optimal sharing strategy.
The scheduler performs global rescheduling periodically at a fixed interval.

\parabf{Local executor.}
Each local executor manages the workloads on one GPU.
The local executor executes workloads according to the scheduling decision of the scheduler and monitors the running workloads.
Besides, it can evict the offline workload if the online workload is under threat.
The workloads share the same GPU in space with MPS.
There are four components in the local executor: online container, offline container with \bytecuda, GPU monitor, and \sysprobe.

\textit{Online container and offline container.}
The online container runs the server for online workload and serves the online requests from upstream callers registered in the server manager.
The offline container runs the offline workload.
With \bytecuda built in the offline container, the execution of the offline workload is controlled to guarantee the performance of the online workload.
To do so, \bytecuda limits the GPU memory and computing power used by the offline workloads.

\textit{GPU monitor.}
The GPU monitor periodically collects GPU metrics, such as GPU utilization, memory usage, and SM clock.
These data reflect the workload pressure of each GPU and they are leveraged by the \sysprobe and \bytecuda to manage offline workloads.

\textit{\sysprobe.}
The \sysprobe maintains a state machine reflecting the device status and ensures that the device is not in unhealthy status.
The state machine transits according to the GPU metrics collected by the GPU monitor.
When the state machine indicates one online workload is highly influenced, the \sysprobe will evict the shared offline workload. 
