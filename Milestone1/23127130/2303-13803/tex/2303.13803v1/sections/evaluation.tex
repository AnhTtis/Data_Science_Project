\section{Evaluation}
\label{sec:evaluation}

Our evaluation consists of testbed experiments, trace-driven simulations, and results from the production deployment.
We mainly focus on the efficiency and safety of \sysname.
The results show that \sysname oversells up to $90.0\%$ GPU resources to offline workloads, and improves the GPU utilization by $4.0\times$, SM activity by $4.7\times$, and GPU memory usage by $1.5\times$.
The error rate of \sysname is similar to the dedicated inference clusters in production deployment at \company.

\subsection{Experimental setup}
\paraf{Testbed.}
We conduct the testbed experiments with $125$ machines and $1,000$ GPUs.
Each machine is equipped with $8$ NVIDIA Tesla T4 GPUs, 2 Intel Xeon Platinum CPUs, 128G memory, and 100+25G NIC.
We PyTorch v1.8.0 with CUDA 11.1 for offline workloads.
We use real online workloads in our production clusters and these workloads use different DL frameworks and CUDA drivers.

\parabf{Simulator.}
Inspired by ~\cite{gu2019tiresias,zhao2022multi}, we build a simulator to evaluate a broader set of configurations, traces, and baselines.
We profile the iteration duration, GPU resource utilization, and device metrics of the selected DL workloads when they are executed separately and shared with others.
The profiling results include more than 200 executions.
The difference between the simulation and testbed experiment is under $5\%$, showing the high fidelity of the simulator.

\parabf{Workloads.}
We use the actual online workloads and real-time requests at \company for the testbed experiment.
\revise{
The online workloads use a wide spectrum of DL models, including CNN, GNN, LLM, and recommendation models.
}
For trace-driven simulation, we select three online workloads deployed over hundreds of GPUs at \company, and generate requests according to their actual query per second (QPS) varying from 20 to 190.
For offline workloads, we leverage the public trace from Microsoft~\cite{jeon2019analysis} and split the trace according to the virtual cluster ID.
We use submission time and duration from the traces and randomly choose DL models from four popular DL models including ResNet50~\cite{he2016deep}, VGG16~\cite{simonyan2014very}, DensNet201~\cite{huang2017densely}, and Inception-V3~\cite{szegedy2016rethinking}, in accordance with the common practice~\cite{gu2019tiresias,zhao2022multi,han2022microsecond}.
We repeat the workloads to fit in 1,000 GPUs and guarantee that the generated traces can be finished in 12 hours for the testbed experiment and 24 hours for simulations.
The numbers of offline workloads in these traces vary from 1,410 to 7,287.
We set the batch size according to the memory quota limited by \bytecuda.

\parabf{Baselines.}
We compare \sysname with three related systems, Online-only, Time-sharing, and Priority-based time-sharing (PB-time-sharing).
Online-only executes only the online workloads and shows the optimal latency for online workloads.
Time-sharing shares workloads in time and assigns the time slices of GPUs to the shared workloads by the GPU driver strategy, which is adopted by Gandiva~\cite{xiao2018gandiva}.
PB-time-sharing sets online workloads with high priority and assigns more time slices of GPUs to high-priority workloads to protect the high-priority workloads' performance, which is adopted by AntMan~\cite{xiao2020antman} and PAI~\cite{weng2022pai}.

\parabf{Metrics.}
Average latency and $99\%-th$ latency are two common metrics to evaluate the performance of online workloads~\cite{gujarati2020serving,han2022microsecond}.
Average job completion time (JCT) and makespan are used to reflect the workload efficiency of schedulers~\cite{xiao2020antman,zhao2022multi}.
Offline normalized throughput shows the sharing efficiency.
\revise{
We define how much GPU the offline workloads get in the aspect of computation speed as the oversold GPU.
This metric is in the range of $[0,1]$, where $0$ represents that the offline workloads get no GPU computation resource, and $1$ represents that the offline workloads get equivalent GPU computation resources as they are executed exclusively.}
This metric can be calculated by Equation~\ref{equ:oversold}.
\begin{equation}
Oversold\ GPU=\frac{\sum_{w\in W_{off}} T^{real}_w}{\sum_{w\in W_{off}} T^{sep}_w} ,
\label{equ:oversold}
\end{equation}
where $W_{off}$ represents offline workloads, $T^{real}_w$ represents the real execution time of $w$, and $T^{sep}_w$ represents the execution time of $w$ when running exclusively.
We report GPU resource utilization with three metrics: GPU utilization, SM activity, and GPU memory utilization.

\subsection{Testbed experiments}

\begin{figure}[t]
        \centerline{\includegraphics[width=0.95\linewidth,trim=0 0 0 50, clip]{figures/Eval_testbed.pdf}}
        \vspace{-0.15in}
        \caption{Detailed metrics in the testbed experiment.}
        \vspace{-0.1in}
        \label{fig:eval_testbed}
\end{figure}


We first evaluate \sysname on a testbed with 1,000 GPUs.
Figure~\ref{fig:eval_testbed} shows the detailed metrics for online workloads, offline workloads, and GPU resource utilization.
To get the metrics of Online-only, we stop the offline workloads for one minute in every scheduling interval and collect the metrics.
The scheduling interval is set to 15 minutes considering the overhead of pulling images and initialization.
\revise{
Though the trace of offline workloads lasts for 12 hours, most workloads finish before 8 hours.
Thus, there is an obvious shift for \sysname's curves of offline normalized throughput and GPU resource utilizations between 7 to 8 hours.
}

\begin{figure*}[t]
	\subfigure[Latency of online workloads.]{
        \begin{minipage}{0.32\linewidth}
        \centerline{\includegraphics[width=\linewidth,trim=10 0 20 0,clip]{figures/Eval_baselines_avglatency.pdf}}
        % \vspace{-0.1in}
        \label{fig:eval_baseline_avglatency}
        \end{minipage}
    }
	\subfigure[JCT of offline workloads.]{
        \begin{minipage}{0.32\linewidth}
        \centerline{\includegraphics[width=\linewidth,trim=0 0 20 0,clip]{figures/Eval_baselines_JCT.pdf}}
        % \vspace{-0.1in}
        \label{fig:eval_baseline_jct}
        \end{minipage}
    }
	\subfigure[Oversold GPU.]{
        \begin{minipage}{0.32\linewidth}
        \centerline{\includegraphics[width=\linewidth,trim=10 0 20 0,clip]{figures/Eval_baselines_oversold.pdf}}
        % \vspace{-0.1in}
        \label{fig:eval_baseline_oversold}
        \end{minipage}
    }
     \vspace{-0.2in}
     \caption{Compare \sysname with related work.}
     \vspace{-0.1in}
    \label{fig:eval_baseline}
\end{figure*}

\parabf{Performance of online workloads.}
Figure~\ref{fig:eval_testbed} shows that \sysname increases the average latency by $16.0\%$, the $99\%-th$ latency by $15.3\%$.
These results indicate that \sysname slows down online workloads less than $20\%$, i.e., 10ms.
It is worth mentioning that such a slowdown is almost imperceptible for most online workloads, e.g. recommendation services and machine translation.
In the wide spectrum of industrial online workloads deployed in  \company, the latency demand of most online workloads is more than 100ms, hence the 10ms slowdown of online workloads is acceptable in practice. 
Additionally, we can adjust \bytecuda and the dynamic SM allocation mechanism to reduce the slowdown threshold or improve the oversold resource for offline workloads.
\revise{
We observe that $1.5\%$ executions of offline workloads are evicted, indicating the functionality of performance protection mechanisms.
}

\parabf{Efficiency of offline workloads.}
We find that \sysname provides up to $86.42\%$ GPU resource to offline workloads, which is a substantial number considering the large number of GPUs in production.

\parabf{GPU resource utilization.}
Figure~\ref{fig:eval_testbed} compares the GPU computing utilization and memory usage between Online-only and \sysname.
The utilization numbers are the average of all GPUs.
\sysname improves the GPU utilization by $4.0\times$, SM activity by $4.7\times$, and GPU memory usage by $1.5\times$.

\parabf{Safety.}
We observe that during the 12-hour testbed experiments, no error propagation happens.
That is, no online workload is influenced by offline workload errors, verifying the safety of \sysname.

\subsection{Comparison with related work}

We compare \sysname with three related systems, Online-only, Time-sharing, and PB-time-sharing.
The related systems are implemented in our simulator, and evaluated with production online workloads and popular offline workloads.
Figure~\ref{fig:eval_baseline} demonstrates the average latency of online workloads, average JCT of offline workloads, and oversold GPU to offline workloads.
We normalize the latency by that of Online-only and other metrics by that of \sysname.
\sysname improves the average JCT by $1.10-2.24\times$, and the oversold GPU by $1.08-1.97\times$, while slowing down the online workloads by less than $20\%$.
Time-sharing slows down online workloads by up to $50\%$, indicating a great impact on online workloads.
PB-time-sharing utilizes priority to protect the performance of online workloads, but its metrics for offline workloads are worse than \sysname due to two reasons.
First, \sysname can utilize the GPU resource wasted by online workloads in space.
Second, \sysname employs the scheduling algorithm to improve the efficiency of offline workloads.

\subsection{Analysis of \sysname}

\begin{figure}[t]
	\subfigure[Impact of the hidden size.]{
        \begin{minipage}{0.45\linewidth}
        \centerline{\includegraphics[width=\linewidth]{figures/Eval_MLP_hidden_size.pdf}}
        % \vspace{-0.1in}
        \label{fig:eval_mlp_hidden_size}
        \end{minipage}
    }
	\subfigure[Impact of the number of layers.]{
        \begin{minipage}{0.45\linewidth}
        \centerline{\includegraphics[width=\linewidth]{figures/Eval_MLP_layer.pdf}}
        % \vspace{-0.1in}
        \label{fig:eval_mlp_layers}
        \end{minipage}
    }
     \vspace{-0.15in}
     \caption{Impact of the MLP architecture on the prediction accuracy.}
     \vspace{-0.1in}
    \label{fig:eval_mlp}
\end{figure}

\parabf{Accuracy of the speed predictor.}
\revise{
To better understand the impact of MLP architecture on prediction accuracy, we evaluate the speed predictor with various hidden sizes and numbers of the network layers in MLP.
}
We vary the hidden size from $64\times 64$ to $1024\times 1024$ and fix the number of layers to 4.
The test error curves in Figure~\ref{fig:eval_mlp_hidden_size} show that the MLPs with different hidden sizes have similar accuracy and convergence speed.
For the number of layers, we evaluate the MLP with 2 to 8 layers as shown in Figure~\ref{fig:eval_mlp_layers}, with the hidden size fixed to $64\times 64$.
We find that the error is lowest for 4 layers due to its proper relationship between dataset size and parameters.
Thus, we select $64\times 64$ as the hidden size and $4$ as the layer number for better accuracy and faster inference time.

\begin{figure*}[t]
	\subfigure[Latency of online workloads.]{
        \begin{minipage}{0.32\linewidth}
        \centerline{\includegraphics[width=\linewidth,trim=10 0 20 0,clip]{figures/Eval_design_avglatency.pdf}}
        % \vspace{-0.1in}
        \label{fig:eval_design_avglatency}
        \end{minipage}
    }
	\subfigure[JCT of offline workloads.]{
        \begin{minipage}{0.32\linewidth}
        \centerline{\includegraphics[width=\linewidth,trim=0 0 20 0,clip]{figures/Eval_design_JCT.pdf}}
        % \vspace{-0.1in}
        \label{fig:eval_design_jct}
        \end{minipage}
    }
	\subfigure[Oversold GPU.]{
        \begin{minipage}{0.32\linewidth}
        \centerline{\includegraphics[width=\linewidth,trim=10 0 20 0,clip]{figures/Eval_design_oversold.pdf}}
        % \vspace{-0.1in}
        \label{fig:eval_design_oversold}
        \end{minipage}
    }
     \vspace{-0.2in}
     \caption{Impact of the mechanisms for offline efficiency.}
     \vspace{-0.1in}
    \label{fig:eval_design}
\end{figure*}
\parabf{Impact of the mechanisms for offline efficiency.}
We also study the impact of the dynamic SM allocation mechanism and the matching-based scheduling.
We leverage the simulator to compare \sysname with three variants, \sysname without dynamic SM allocation mechanism (\sysname-S), \sysname without matching-based scheduling (\sysname-M), 
\revise{
and \sysname without both dynamic SM allocation mechanism and matching-based scheduling but only the protection mechanisms for online workloads  (\sysname-S-M).
}
Figure~\ref{fig:eval_design} reports the metrics for online and offline workloads over traces A to D.
We normalize the latency by that of Online-only and average JCT by that of \sysname.
Note that compared with \sysname-S-M, both \sysname-S and \sysname-M improve the average JCT and oversold GPU.
\revise{
These improvements confirm that only the online protection mechanisms are not efficient, and dynamic SM allocation mechanism and matching-based scheduling are important for offline efficiency.
}
Additionally, combining the two mechanisms, i.e., \sysname, brings more benefits.

\parabf{System overhead.}
\revise{
\sysname mainly introduces two kinds of overhead, i.e., the profiling overhead and the scheduling overhead.
The profiling takes less than 10 minutes for each offline workload.
The profiling overhead is marginal, as the offline workloads usually take hours or even days,
The overhead of the scheduling algorithm consists of two periods.
The first period is to predict the sharing performance and build the bipartite graph.
Each prediction only takes less than one millisecond, and each internal cluster at \company consists of thousands of GPUs and thousands of workloads.
Thus, the first period only takes several seconds for each cluster using the batched prediction.
The second period is to execute the KM algorithm, which takes several minutes for thousands of workloads.
Note that the scheduling algorithm can be executed in parallel with the workload execution.
Thus, we can hide the scheduling overhead within each scheduling interval.
}

\subsection{Production deployment}

\begin{figure}[t]
	\subfigure[Latency.]{
        \begin{minipage}{0.47\linewidth}
        \centerline{\includegraphics[width=\linewidth,trim=0 0 0 20,clip]{figures/Eval_deploy_online_latency.pdf}}
        % \vspace{-0.1in}
        \label{fig:eval_deploy_latency}
        \end{minipage}
    }
	\subfigure[Throughput.]{
        \begin{minipage}{0.47\linewidth}
        \centerline{\includegraphics[width=\linewidth,trim=0 0 0 20,clip]{figures/Eval_deploy_online_qps.pdf}}
        % \vspace{-0.1in}
        \label{fig:eval_deploy_qps}
        \end{minipage}
    }
     \vspace{-0.15in}
     \caption{Performance of online workloads in deployment.}
     % \vspace{-0.1in}
    \label{fig:eval_deploy_online}
\end{figure}

\begin{figure}[t]
    \centerline{\includegraphics[width=\linewidth,trim=0 0 0 30, clip]{figures/Eval_deploy_gpu.pdf}}
    \vspace{-0.15in}
    \caption{GPU resource utilization in deployment.}
    \vspace{-0.1in}
    \label{fig:eval_deploy_gpu}
\end{figure}

We have deployed \sysname on the production clusters with more than 20,000 GPUs at \company.
As the results of the whole system are not ready when the paper is written, we concentrate on the results of \sysname without the dynamic SM allocation mechanism and the matching-based scheduling.
\revise{
To verify the performance protection for online workloads provided by \sysname, we collect the latency and throughput of online workloads that are deployed with both \sysname and dedicated inference clusters (Online-only), as shown in Figure~\ref{fig:eval_deploy_online}.
The average latency and $99\%-th$ latency of online workloads increase by less than $10ms$.
The slowdown of online workloads is acceptable compared with the latency demand of our online workloads.
Besides, we collect the average resource utilization of all GPUs used by \sysname and Online-only for four weeks in Figure~\ref{fig:eval_deploy_gpu}.
We observe that \sysname improves the GPU utilization from $26\%$ to $76\%$, SM activity from $16\%$ to $33\%$, and GPU memory from $42\%$ to $48\%$, indicating the efficiency of \sysname.
The GPU memory utilization increases less than other utilizations because of our conservative memory limitation for offline workloads.
}

\revise{
The percentage of daily error devices of \sysname is below $0.9\%$, which is slightly higher than the error rate of Online-only at \company, $0.7\%$.
However, the increase of the error rate is much less than the increase of the executed containers, i.e., $2\times$.
Compared with Online-only, the extra device errors of \sysname come from MPS server crashes and other MPS hangs, which cannot be handled with existing mechanisms.
}
