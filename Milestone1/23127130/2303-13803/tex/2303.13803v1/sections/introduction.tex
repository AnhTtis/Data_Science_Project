\section{Introduction}
\label{sec:intro}

Deep learning (DL) has been widely integrated into intelligent applications and services, such as intelligent recommendation~\cite{covington2016deep,gao2021learning},  autonomous driving~\cite{alcon2020timing, jang2020r}, image recognition~\cite{simonyan2014very,he2016deep}, and machine translation~\cite{vaswani2017attention,gehring2017convolutional}.
Some of them provide real-time inference and have critical latency demand (called \textit{online workloads}).
Meanwhile, other workloads do not have hard latency demand (called \textit{offline workloads}). 
Enterprises usually build large-scale GPU clusters for DL workloads and reserve specific GPUs for online workloads.

Existing efforts in online workload management have significantly improved the serving efficiency~\cite{crankshaw2017clipper,gujarati2020serving,shen2019nexus}.
However, a major limitation is that most methods dedicate the whole GPU to a single workload.
It is reported that an online workload usually cannot fully utilize the expensive GPU resource~\cite{ma2020rammer,han2022microsecond} mainly due to two reasons.
First, the frequency of online requests fluctuates from time to time.
When the request frequency is low, more GPU computing units are idle, leading to a great waste of GPU.
Second, even if the request frequency is high, the batch size of online workloads is usually limited to a small value for latency demand and most kernels need few computing resources.
Thus, the computing units in GPU are still underutilized.

A common idea is to share GPUs among multiple workloads with different latency demands~\cite{xiang2019pipelined,xiao2020antman,han2022microsecond}, i.e., sharing GPUs between online and offline workloads.
Time-sharing and space-sharing are two paradigms for GPU sharing.
Time-sharing~\cite{xiao2020antman,cgpu} assigns time slices to different workloads, but it may degrade the performance of online workloads and cannot improve GPU resource utilization in space.
Space-sharing~\cite{han2022microsecond,mps} is a better way to improve GPU resource utilization.
For widely-deployed NVIDIA GPUs, multi-process service (MPS)~\cite{mps} is a feasible choice due to its efficacy, flexibility, and compatibility with NVIDIA GPUs.

However, MPS brings new challenges to production clusters.
First, the primary goal for production clusters is to guarantee the performance of online workloads, such as real-time recommendation and machine translation.
These workloads have hard latency demands because longer latency may influence the user's experience. 
However, MPS cannot guarantee the performance of online workloads.
Second, MPS has a serious error propagation problem, i.e., when one workload encounters an error, the shared workload may also be influenced.
It is critical to guarantee the safety of shared workloads, especially the online workloads in production clusters.


This paper presents \sysname, a system that supports efficient and safe space-sharing of large-scale GPU clusters for DL workloads in the production environment.
\sysname addresses the above challenges to guarantee the performance and safety of online workloads.
\sysname exploits a two-level protection mechanism to guarantee the performance of online workloads from both the workload level and GPU level.
At the workload level, we propose \bytecuda to constrain the GPU memory and computing power used by offline workloads.
\bytecuda monitors the GPU memory allocation to limit the memory usage of offline workloads, and controls kernel launches to limit the computing power used by offline workloads.
Besides, \bytecuda provides adjustable parameters to control how much the online workloads are influenced.
At the GPU level, \sysname employs the \textit{\sysprobe} to monitor the GPU device status.
The \sysprobe maintains a state machine according to multi-dimensional GPU metrics, and will evict offline workloads if the GPU status can potentially compromise the performance of online workloads.

To guarantee the safety of online workloads, we investigate all propagated errors in our production clusters and propose a mixed error-handling mechanism.
We find that $99\%$ propagated errors are caused by \textit{SIGINT} and \textit{SIGTERM} signals, which are usually used to stop containers in Kubernetes~\cite{k8s}.
\sysname employs a graceful exit mechanism that intercepts related signals and releases CUDA context actively to avoid the propagated error.
For other corner cases, \sysname resets the CUDA context and restarts the workloads.


Furthermore, \sysname improves the efficiency of offline workloads.
\sysname dynamically allocates the computing unit of NVIDIA GPU, i.e., streaming multiprocessor (SM), used by offline workloads.
Our key intuition is that we can set the SM percentage of offline workloads complementary to the SM percentage used by online workloads, with an acceptable slowdown of online workloads.
Besides, we observe that different sharing pairs vary dramatically in the efficiency of offline workloads.
To maximize the efficiency, we formulate the problem as a maximum weighted bipartite matching problem.
\sysname exploits a DL approach to build the bipartite graph and the KM algorithm~\cite{kuhn1955hungarian,munkres1957algorithms} to solve this problem.

In summary, we make the following contributions.

\begin{itemize}[leftmargin=*]
    \item We investigate the characteristics of production inference clusters and identify the opportunity in space sharing to better utilize GPU.
    \item We provide efficient and safe space-sharing with three mechanisms: a two-level protection mechanism to guarantee the performance of online workloads, a mixed error-handling mechanism to ensure the safety of online workloads, and a dynamic SM percentage mechanism to improve the efficiency of offline workloads.
    \item We design a matching-based scheduling algorithm to improve the sharing efficiency at the cluster level.
    The scheduling algorithm can improve the overall normalized throughput of offline workloads while maintaining the performance of online workloads.
    \item We introduce \sysname, the first production cluster system that enables efficient and safe space sharing.
    We have deployed \sysname in a production cluster with more than $20,000$ GPUs at \company to serve tens of thousands of daily workloads.
    Deployment results show that \sysname improves the GPU utilization from $26\%$ to $76\%$, SM activity from $16\%$ to $33\%$, and GPU memory from $42\%$ to $48\%$.
\end{itemize}
