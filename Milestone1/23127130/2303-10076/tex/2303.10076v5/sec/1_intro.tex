\section{Introduction}
\label{sec:intro}


3D scene understanding is a challenging mission for autonomous driving, especially only relying on the camera. In recent years, Bird's Eye View (BEV) perception, including 3D detection \cite{liu2022petr} and map segmentation \cite{li2022hdmapnet} is getting a lot of attention with the advantage of doing the 3D task estimation in the 2D feature plane and is beneficial for downstream tasks such as prediction and planning \cite{bevsurvey, arnold2019survey}. However, some vital information for driving safety is ignored in the BEV tasks, such as an unrecognizable obstacle. Therefore, reconstructing the 3D geometry of the driving scenes is a longstanding task for autonomous driving. 

To obtain the 3D geometry information, depth estimation from RGB images, such as monocular depth estimation \cite{monosurvery, xiang2023towards,lee2022self} and stereo matching \cite{poggi2021synergies}, has been well investigated. While depth maps can provide 3D geometry information at the pixel level, we need to project them into the point cloud format in 3D space, and multiple post-processing procedures are required as depth maps may be inconsistent in the local region \cite{tesla}, which is not a straightforward manner for the 3D perception in autonomous driving. For better geometry representation in driving scenarios, occupancy estimation has gained attention in the industrial community. It has shown superiority over the representation in the BEV space \cite{tesla}. To advance the study in 3D occupancy estimation, we explore a simple framework for 3D occupancy estimation, starting from the surrounding-view setting, like BEV perception. 

To make the framework self-contained, we investigate the baseline in terms of network design, optimization, and evaluation. For the network design, as shown in Figure \ref{fig:task}, the final output representation for 3D occupancy estimation is different from monocular depth estimation and stereo matching. The network architecture of the 3D occupancy estimation is similar to stereo matching, which means that the experiences from the stereo matching task can be adapted to occupancy estimation to reduce the burden in the network design. Therefore, we design the pipeline to resemble stereo matching closely and investigate a CNN-based framework as the baseline. In terms of optimization, we investigate supervised and self-supervised learning, which are based on the render depth map \cite{nerf} and point-level classification label. For evaluation, we conduct experiments on two well-known datasets, DDAD and Nuscenes \cite{ddad, nuscenes}, for broader recognition. Besides, we propose a novel distance-based metric for occupancy evaluation, which is inspired by the sampling strategy in volume rendering \cite{nerf}. Our experimental results demonstrate that the proposed metric is more equitable compared to alternative options, such as classification metrics. Additionally, the proposed metric boasts flexibility as it solely relies on the point cloud as the ground truth, thereby eliminating any additional burdens when implementing the metric on similar datasets.

The main contributions of this work are summarized as follows.
\begin{itemize}
    % 压缩itemize的间距，默认的占用空间太多
    \setlength{\itemsep}{0pt}
    \setlength{\parsep}{0pt}
    \setlength{\parskip}{0pt}
    \setlength{\topsep}{0pt}
    \setlength{\partopsep}{0pt}
    \item We introduce a framework for surrounding-view 3D occupancy estimation, featuring a novel network design, loss design, and evaluation metric based on discrete point level sampling.
    \item We propose an occupancy metric and demonstrate its efficacy for 3D occupancy evaluation. Furthermore, we connect 3D occupancy estimation to the monocular depth estimation task and establish a new depth estimation benchmark with competitive performance.
    \item We delve deeper into self-supervised learning within our framework, extending its application to 3D reconstruction through the representation of the signed distance function. To the best of our knowledge, we are the first work to investigate the 3D reconstruction at mesh level in the surrounding-view driving scenes.
    \item We propose an effective pretrain strategy for the 3D semantic occupancy task based on the sampling strategy and reveal the different characteristic of the point-level optimization and dense voxel-level optimization.
    \item Through extensive qualitative and quantitative experiments for the DDAD and Nuscenes datasets, we demonstrate the effectiveness of our proposed framework as a universal solution that can utilize existing unlabeled point cloud datasets to perform the 3D occupancy estimation and evaluation as simple as depth estimation. 
    
\end{itemize}

\begin{figure}[t!]
\centering
{
% \includegraphics[width=0.48\textwidth]{figure/task.jpg}
\includegraphics[width=\linewidth]{fig/occupancy.png}
}
\caption{\textbf{A comparison of the overall pipline of monocular depth estimation, stereo matching, and 3D occupancy estimation}.}
\label{fig:task}
\end{figure}
