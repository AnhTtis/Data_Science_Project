{
    "arxiv_id": "2303.13859",
    "paper_title": "XGC-VQA: A unified video quality assessment model for User, Professionally, and Occupationally-Generated Content",
    "authors": [
        "Xinhui Huang",
        "Chunyi Li",
        "Abdelhak Bentaleb",
        "Roger Zimmermann",
        "Guangtao Zhai"
    ],
    "submission_date": "2023-03-24",
    "revised_dates": [
        "2023-03-27"
    ],
    "latest_version": 1,
    "categories": [
        "cs.MM",
        "eess.IV"
    ],
    "abstract": "With the rapid growth of Internet video data amounts and types, a unified Video Quality Assessment (VQA) is needed to inspire video communication with perceptual quality. To meet the real-time and universal requirements in providing such inspiration, this study proposes a VQA model from a classification of User Generated Content (UGC), Professionally Generated Content (PGC), and Occupationally Generated Content (OGC). In the time domain, this study utilizes non-uniform sampling, as each content type has varying temporal importance based on its perceptual quality. In the spatial domain, centralized downsampling is performed before the VQA process by utilizing a patch splicing/sampling mechanism to lower complexity for real-time assessment. The experimental results demonstrate that the proposed method achieves a median correlation of $0.7$ while limiting the computation time below 5s for three content types, which ensures that the communication experience of UGC, PGC, and OGC can be optimized altogether.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13859v1"
    ],
    "publication_venue": "6 pages, 4 figures"
}