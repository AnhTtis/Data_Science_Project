\section{Conclusion}\label{conclusion}
% Restate problem
On heterogeneous systems, it is pragmatic and, therefore, attractive to use a hybrid parallelization, i.e., different simulation modules running on different hardware.
However, hybrid implementations increase the complexity of achieving good performance and scalability, especially on large-scale systems.
% Repeat what has been done
In this paper, we have examined a hybrid coupled fluid-particle simulation with geometrically resolved particles. We use \glspl{gpu} for the fluid dynamics, whereas the particle simulation runs on the \glspl{cpu}.
% Summarize arguments and findings
We have reported and studied the performance of this approach for two cases of a fluidized bed simulation that differ in terms of the number of particles per volume.
The overhead introduced by the hybrid implementation (i.e., \gls{cpu}-\gls{gpu} communication) is negligible because we are transferring only a small amount of data per particle but no fluid cells.
The performance of the fluid simulation is close to utilizing the full memory bandwidth of the A100, implying that using the \gls{gpu} is a good choice for the fluid simulation.
In both cases, the \gls{gpu} routines take most of the run time.
In a weak scaling benchmark, the hybrid fluid-particle implementation reaches a parallel efficiency of 71\% in the dilute case and 53\% in the dense case when using 1024 \gls{cpu}-\gls{gpu} pairs.
The current \gls{pd} methodology requires 32 \gls{cpu}-\gls{cpu} communication steps per time step, which is the driving force for the decrease of the overall parallel efficiency. Our results are limited insofar as different numbers of particle sub-cycles, fluid cells per diameter, etc., will result in different performance results.
% Key takeaways from the paper
We have formulated four criteria that a hybrid implementation must meet to be suitable for the responsible use of heterogeneous supercomputers.
The performance results have shown that our hybrid implementation fulfills all criteria, making it suitable for large-scale simulations on heterogeneous supercomputers.
% Future work / Outlook
In the future, we plan to investigate the particle communication steps in more detail regarding the bottleneck and optimization possibilities. We are employing sub-cycles to increase stability for stiff systems. Using other integrators may permit longer time steps and thus less communication due to sub-cycles. We have shown the acceleration potential of hybrid implementations. Therefore, we plan to run coupled fluid-particle simulations of even larger scenarios to better analyze, among others, the physical phenomena of erosion in sediment beds.
