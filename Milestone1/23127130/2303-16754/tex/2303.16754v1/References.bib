@INPROCEEDINGS{9451726,
  author={G, Sreena V and Ponraj, Narain and L, Deepa P},
  booktitle={2021 3rd International Conference on Signal Processing and Communication (ICPSC)}, 
  title={Study on Public Chest X-ray Data sets for Lung Disease Classification}, 
  year={2021},
  volume={},
  number={},
  pages={54-58},
  doi={10.1109/ICSPC51351.2021.9451726}}

  @article{Tan2022,
author = {Tan, Ching Leng and Chan, Yinghan and Candasamy, Mayuren and Chellian, Jestin and Madheswaran, Thiagarajan and Sakthivel, Lakshmana Prabu and Patel, Vyoma K and Chakraborty, Amlan and MacLoughlin, Ronan and Kumar, Deepak and Verma, Nitin and Malyla, Vamshikrishna and Gupta, Piyush Kumar and Jha, Niraj Kumar and Thangavelu, Lakshmi and Devkota, Hari Prasad and Bhatt, Shvetank and Prasher, Parteek and Gupta, Gaurav and Gulati, Monica and Singh, Sachin Kumar and Paudel, Keshav Raj and Hansbro, Philip M and Oliver, Brian G and Dua, Kamal and Chellappan, Dinesh Kumar},
doi = {https://doi.org/10.1016/j.ejphar.2022.174821},
issn = {0014-2999},
journal = {European Journal of Pharmacology},
keywords = {Asthma,COPD,Chronic respiratory diseases,Cystic fibrosis,Lung cancer,models},
pages = {174821},
title = {{Unravelling the molecular mechanisms underlying chronic respiratory diseases for the development of novel therapeutics via in vitro experimental models}},
url = {https://www.sciencedirect.com/science/article/pii/S0014299922000826},
volume = {919},
year = {2022}
}

@article{Li2022,
author = {Li, Lijie and Gang, Xiaochao and Wang, Jiajia and Gong, Xiaoyan},
doi = {10.3892/etm.2022.11197},
issn = {1792-0981 1792-1015},
journal = {Exp Ther Med},
keywords = {melatonin pulmonary disorders inflammation respira},
number = {4},
pages = {271},
title = {{Role of melatonin in respiratory diseases (Review)}},
url = {https://doi.org/10.3892/etm.2022.11197},
volume = {23},
year = {2022}
}
@article{Liu_2022,
doi = {10.1088/2516-1091/ac2eae},
url = {https://dx.doi.org/10.1088/2516-1091/ac2eae},
year = {2021},
month = {oct},
publisher = {IOP Publishing},
volume = {4},
number = {1},
pages = {012001},
author = {Yuxuan Liu and Darpan Shukla and Holly Newman and Yong Zhu},
title = {Soft wearable sensors for monitoring symptoms of COVID-19 and other respiratory diseases: a review},
journal = {Progress in Biomedical Engineering}
}
@article{Bala2021,
abstract = {There is increasing interest in understanding the role of air pollution as one of the greatest threats to human health worldwide. Nine of 10 individuals breathe air with polluted compounds that have a great impact on lung tissue. The nature of the relationship is complex, and new or updated data are constantly being reported in the literature. The goal of our review was to summarize the most important air pollutants and their impact on the main respiratory diseases (chronic obstructive pulmonary disease, asthma, lung cancer, idiopathic pulmonary fibrosis, respiratory infections, bronchiectasis, tuberculosis) to reduce both short- and the long-term exposure consequences. We considered the most important air pollutants, including sulfur dioxide, nitrogen dioxide, carbon monoxide, volatile organic compounds, ozone, particulate matter and biomass smoke, and observed their impact on pulmonary pathologies. We focused on respiratory pathologies, because air pollution potentiates the increase in respiratory diseases, and the evidence that air pollutants have a detrimental effect is growing. It is imperative to constantly improve policy initiatives on air quality in both high- and low-income countries.},
author = {Bălă, Gabriel-Petrică and R{\^{a}}jnoveanu, Ruxandra-Mioara and Tudorache, Emanuela and Motișan, Radu and Oancea, Cristian},
doi = {10.1007/s11356-021-13208-x},
issn = {1614-7499},
journal = {Environmental Science and Pollution Research},
number = {16},
pages = {19615--19628},
title = {{Air pollution exposure—the (in)visible risk factor for respiratory diseases}},
url = {https://doi.org/10.1007/s11356-021-13208-x},
volume = {28},
year = {2021}
}

@article{Zhou2020,
abstract = {Background: Since December, 2019, Wuhan, China, has experienced an outbreak of coronavirus disease 2019 (COVID-19), caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Epidemiological and clinical characteristics of patients with COVID-19 have been reported but risk factors for mortality and a detailed clinical course of illness, including viral shedding, have not been well described. Methods: In this retrospective, multicentre cohort study, we included all adult inpatients (≥18 years old) with laboratory-confirmed COVID-19 from Jinyintan Hospital and Wuhan Pulmonary Hospital (Wuhan, China) who had been discharged or had died by Jan 31, 2020. Demographic, clinical, treatment, and laboratory data, including serial samples for viral RNA detection, were extracted from electronic medical records and compared between survivors and non-survivors. We used univariable and multivariable logistic regression methods to explore the risk factors associated with in-hospital death. Findings: 191 patients (135 from Jinyintan Hospital and 56 from Wuhan Pulmonary Hospital) were included in this study, of whom 137 were discharged and 54 died in hospital. 91 (48{\%}) patients had a comorbidity, with hypertension being the most common (58 [30{\%}] patients), followed by diabetes (36 [19{\%}] patients) and coronary heart disease (15 [8{\%}] patients). Multivariable regression showed increasing odds of in-hospital death associated with older age (odds ratio 1{\textperiodcentered}10, 95{\%} CI 1{\textperiodcentered}03–1{\textperiodcentered}17, per year increase; p=0{\textperiodcentered}0043), higher Sequential Organ Failure Assessment (SOFA) score (5{\textperiodcentered}65, 2{\textperiodcentered}61–12{\textperiodcentered}23; p{\textless}0{\textperiodcentered}0001), and d-dimer greater than 1 $\mu$g/mL (18{\textperiodcentered}42, 2{\textperiodcentered}64–128{\textperiodcentered}55; p=0{\textperiodcentered}0033) on admission. Median duration of viral shedding was 20{\textperiodcentered}0 days (IQR 17{\textperiodcentered}0–24{\textperiodcentered}0) in survivors, but SARS-CoV-2 was detectable until death in non-survivors. The longest observed duration of viral shedding in survivors was 37 days. Interpretation: The potential risk factors of older age, high SOFA score, and d-dimer greater than 1 $\mu$g/mL could help clinicians to identify patients with poor prognosis at an early stage. Prolonged viral shedding provides the rationale for a strategy of isolation of infected patients and optimal antiviral interventions in the future. Funding: Chinese Academy of Medical Sciences Innovation Fund for Medical Sciences; National Science Grant for Distinguished Young Scholars; National Key Research and Development Program of China; The Beijing Science and Technology Project; and Major Projects of National Science and Technology on New Drug Creation and Development.},
doi = {10.1016/S0140-6736(20)30566-3},
issn = {1474547X},
journal = {The Lancet},
number = {10229},
pages = {1054--1062},
pmid = {32171076},
publisher = {Elsevier Ltd},
title = {{Clinical course and risk factors for mortality of adult inpatients with COVID-19 in Wuhan, China: a retrospective cohort study}},
url = {http://dx.doi.org/10.1016/S0140-6736(20)30566-3},
volume = {395},
year = {2020}
}
@misc{WHO_covid19_dashboard,
  author = {{World Health Organization}},
  title = {Coronavirus (COVID-19) Dashboard},
  howpublished = {\url{https://covid19.who.int/}},
  note = {Accessed on March 8, 2023}
}
@misc{CDC_TB_bacterial_infection,
  author = {{Centers for Disease Control and Prevention}},
  title = {Tuberculosis (TB)},
  howpublished = {\url{https://www.cdc.gov/tb/topic/basics/default.htm}},
  note = {Accessed on March 8, 2023}
}
@book{WHO_TB_report_2021,
  author = {{World Health Organization}},
  title = {Global Tuberculosis Report 2021},
  year = {2021},
  publisher = {WHO},
  url = {https://www.who.int/publications/i/item/9789240037021},
  note = {Accessed on March 8, 2023}
}
@misc{ALA_pneumonia,
  author = {{American Lung Association}},
  title = {Pneumonia},
  howpublished = {\url{https://www.lung.org/lung-health-diseases/lung-disease-lookup/pneumonia/learn-about-pneumonia}},
  note = {Accessed on March 8, 2023}
}
@misc{CDC_viral_pneumonia,
  author = {{Centers for Disease Control and Prevention}},
  title = {Pneumonia},
  howpublished = {\url{https://www.cdc.gov/pneumonia/viralpneumonia.html}},
  note = {Accessed on March 8, 2023}
}
@article{Nicolini_2021,
  author = {Nicolini, Antonello and Ferrara, Giovanni and Napoli, Nicola and Sgueglia, Guido A.},
  title = {Bacterial Pneumonia},
  journal = {StatPearls},
  year = {2021},
  note = {Accessed on March 8, 2023},
  url = {https://www.ncbi.nlm.nih.gov/books/NBK537293/}
}
@misc{ATS_fungal_pneumonia,
  author = {{American Thoracic Society}},
  title = {Fungal Pneumonia},
  howpublished = {\url{https://www.thoracic.org/patients/patient-resources/resources/fungal-pneumonia.pdf}},
  note = {Accessed on March 8, 2023}
}
@misc{WHO_pneumonia,
  author = {{World Health Organization}},
  title = {Pneumonia},
  howpublished = {\url{https://www.who.int/news-room/fact-sheets/detail/pneumonia}},
  note = {Accessed on March 8, 2023}
}
@misc{WHO_lung_cancer_tuberculosis,
  author = {{World Health Organization}},
  title = {Cancer},
  howpublished = {\url{https://www.who.int/health-topics/cancer#tab=tab_1}} and {\url{https://www.who.int/health-topics/tuberculosis#tab=tab_1}},
  note = {Accessed on March 8, 2023}
}
@misc{ACS_lung_cancer_US,
  author = {{American Cancer Society}},
  title = {Key Statistics for Lung Cancer},
  howpublished = {\url{https://www.cancer.org/cancer/lung-cancer/about/key-statistics.html}},
  note = {Accessed on March 8, 2023}
}
@article{lee2014differential,
  title={Differential diagnoses of acute ground-glass opacity in chest computed tomography: pictorial essay},
  author={Lee, Sang Min and Park, Chang Min and Goo, Jin Mo and Lee, Hyun Ju},
  journal={Korean journal of radiology},
  volume={15},
  number={6},
  pages={734--744},
  year={2014},
  publisher={Korean Society of Radiology}
}
@article{ohannessian2020global,
title={Global Telemedicine Implementation and Integration Within Health Systems to Fight the COVID-19 Pandemic: A Call to Action},
author={Ohannessian, Raffi and Duong, Tram Anh and Odone, Anna},
journal={JMIR Public Health and Surveillance},
volume={6},
number={2},
pages={e18810},
year={2020},
publisher={JMIR Publications Inc.},
doi={10.2196/18810}
}
@article{kanne2020chest,
title={Chest CT Findings in 2019 Novel Coronavirus (2019-nCoV) Infections from Wuhan, China: Key Points for the Radiologist},
author={Kanne, Jeffrey P},
journal={Radiology},
volume={295},
number={1},
pages={16--17},
year={2020},
publisher={Radiological Society of North America},
doi={10.1148/radiol.2020200241}
}
@article{jiang2017artificial,
  title={Artificial intelligence in healthcare: past, present and future},
  author={Jiang, Fei and Jiang, Yong and Zhi, Hui and Dong, Yi and Li, Hao and Ma, Sufeng and Wang, Yilong and Dong, Qiang and Shen, Haipeng and Wang, Yongjun},
  journal={Stroke and vascular neurology},
  volume={2},
  number={4},
  year={2017},
  publisher={BMJ Specialist Journals}
}
@article{wurm2008telemedicine,
  title={Telemedicine and teledermatology: past, present and future},
  author={Wurm, Elisabeth MT and Hofmann-Wellenhof, Rainer and Wurm, Robert and Soyer, Hans Peter},
  journal={JDDG: Journal Der Deutschen Dermatologischen Gesellschaft},
  volume={6},
  number={2},
  pages={106--112},
  year={2008},
  publisher={Wiley Online Library}
}
@article{ratnatunga2020rise,
  title={The rise of non-tuberculosis mycobacterial lung disease},
  author={Ratnatunga, Champa N and Lutzky, Viviana P and Kupz, Andreas and Doolan, Denise L and Reid, David W and Field, Matthew and Bell, Scott C and Thomson, Rachel M and Miles, John J},
  journal={Frontiers in immunology},
  volume={11},
  pages={303},
  year={2020},
  publisher={Frontiers}
}
@article{benzaquen2019lung,
  title={Lung cancer screening, towards a multidimensional approach: why and how?},
  author={Benzaquen, Jonathan and Boutros, Jacques and Marquette, Charles and Delingette, Herv{\'e} and Hofman, Paul},
  journal={Cancers},
  volume={11},
  number={2},
  pages={212},
  year={2019},
  publisher={MDPI}
}
@article{wang2023diffuse,
  title={Diffuse cystic lung disease caused by tuberculosis infection: case series},
  author={Wang, Lu and Liu, Jingwei and Yang, Huahong and Peng, Liping},
  journal={Journal of Infection and Public Health},
  year={2023},
  publisher={Elsevier}
}
@article{El-Fiky2021,
author = {El-Fiky, Azza and Shouman, Marwa Ahmed and Hamada, Salwa and El-Sayed, Ayman and Karar, Mohamed Esmail},
doi = {10.1109/ICEEM52022.2021.9480622},
isbn = {9781665418423},
journal = {ICEEM 2021 - 2nd IEEE International Conference on Electronic Engineering},
keywords = {Classification,Computer-aided diagnosis,Thorax diseases,Transfer learning,X-ray},
publisher = {IEEE},
title = {{Multi-label transfer learning for identifying lung diseases using chest X-rays}},
year = {2021}
}
@article{Li2020,
author = {Li, Matthew D. and Arun, Nishanth Thumbavanam and Gidwani, Mishka and Chang, Ken and Deng, Francis and Little, Brent P. and Mendoza, Dexter P. and Lang, Min and Lee, Susanna I. and O'Shea, Aileen and Parakh, Anushri and Singh, Praveer and Kalpathy-Cramer, Jayashree},
doi = {10.1148/ryai.2020200079},
issn = {26386100},
journal = {Radiology: Artificial Intelligence},
number = {4},
pages = {1--39},
pmid = {33928256},
title = {{Automated assessment and tracking of COVID-19 pulmonary disease severity on chest radiographs using convolutional siamese neural networks}},
volume = {2},
year = {2020}
}
@article{qin2018computer,
  title={Computer-aided detection in chest radiography based on artificial intelligence: a survey},
  author={Qin, Cheng and Yao, Dengfeng and Shi, Yong and Song, Zhijian},
  journal={Biomedical engineering online},
  volume={17},
  number={1},
  pages={113},
  year={2018},
  publisher={Springer},
  doi={10.1186/s12938-018-0544-y}
}
@article{gao2018computer,
  title={Computer vision in healthcare applications},
  author={Gao, Junfeng and Yang, Yong and Lin, Pan and Park, Dong Sun},
  journal={Journal of healthcare engineering},
  volume={2018},
  year={2018},
  pages={1--12},
  publisher={Hindawi},
  doi={10.1155/2018/5154792}
}
@article{Asif2022,
author = {Asif, Sohaib and Zhao, Ming and Tang, Fengxiao and Zhu, Yusen},
doi = {10.1007/s00530-022-00917-7},
isbn = {0123456789},
issn = {14321882},
journal = {Multimedia Systems},
keywords = {COVID-19 detection,Chest X-ray,Convolutional neural network (CNN),Deep learning,Transfer learning},
number = {4},
pages = {1495--1513},
publisher = {Springer Berlin Heidelberg},
title = {{A deep learning-based framework for detecting COVID-19 patients using chest X-rays}},
url = {https://doi.org/10.1007/s00530-022-00917-7},
volume = {28},
year = {2022}
}
@article{Ramteke2012,
author = {Ramteke, R. J. and Y, Khachane Monali},
journal = {International Journal of Advanced Computer Research},
keywords = {Computed Tomography (CT),K –Nearest Neighbour (KNN),Radial Basis Function (RBF).,Support Vector Machine (SVM)},
number = {4},
pages = {190--196},
title = {{Automatic Medical Image Classification and Abnormality Detection Using K- Nearest Neighbour}},
volume = {2},
year = {2012}
}
@ARTICLE{8575127,
  author={Xu, Shuaijing and Wu, Hao and Bie, Rongfang},
  journal={IEEE Access}, 
  title={CXNet-m1: Anomaly Detection on Chest X-Rays With Image-Based Deep Learning}, 
  year={2019},
  volume={7},
  number={},
  pages={4466-4477},
  doi={10.1109/ACCESS.2018.2885997}}
@article{doi:10.1177/2472555218818756,
author = {Alexander Kensert and Philip J. Harrison and Ola Spjuth},
title ={Transfer Learning with Deep Convolutional Neural Networks for Classifying Cellular Morphological Changes},
journal = {SLAS DISCOVERY: Advancing the Science of Drug Discovery},
volume = {24},
number = {4},
pages = {466-475},
year = {2019},
doi = {10.1177/2472555218818756},
    note ={PMID: 30641024},

URL = { 
        https://doi.org/10.1177/2472555218818756
    
},
eprint = { 
        https://doi.org/10.1177/2472555218818756
    
}
}
@article{yang2019deep,
  title={Deep-learning inversion: A next-generation seismic velocity model building methodDL for velocity model building},
  author={Yang, Fangshu and Ma, Jianwei},
  journal={Geophysics},
  volume={84},
  number={4},
  pages={R583--R599},
  year={2019},
  publisher={GeoScienceWorld}
}
@article{Aggarwal2021,
author = {Aggarwal, Ravi and Sounderajah, Viknesh and Martin, Guy and Ting, Daniel S W and Karthikesalingam, Alan and King, Dominic and Ashrafian, Hutan and Darzi, Ara},
doi = {10.1038/s41746-021-00438-z},
issn = {2398-6352},
journal = {npj Digital Medicine},
number = {1},
pages = {65},
title = {{Diagnostic accuracy of deep learning in medical imaging: a systematic review and meta-analysis}},
url = {https://doi.org/10.1038/s41746-021-00438-z},
volume = {4},
year = {2021}
}
@article{Liu2019,
author = {Liu, Zhuo and Yao, Chenhui and Yu, Hang and Wu, Taihua},
doi = {https://doi.org/10.1016/j.future.2019.02.068},
issn = {0167-739X},
journal = {Future Generation Computer Systems},
keywords = {Deep reinforcement learning,Lung cancer,Medical Internet of Things,Smart medicine},
pages = {1--9},
title = {{Deep reinforcement learning with its application for lung cancer detection in medical Internet of Things}},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19303772},
volume = {97},
year = {2019}
}

@incollection{ElAsnaoui2021,
address = {Cham},
author = {{El Asnaoui}, Khalid and Chawki, Youness and Idri, Ali},
doi = {10.1007/978-3-030-74575-2_14},
editor = {Maleh, Yassine and Baddi, Youssef and Alazab, Mamoun and Tawalbeh, Loai and Romdhani, Imed},
isbn = {978-3-030-74575-2},
pages = {257--284},
publisher = {Springer International Publishing},
title = {{Automated Methods for Detection and Classification Pneumonia Based on X-Ray Images Using Deep Learning BT  - Artificial Intelligence and Blockchain for Future Cybersecurity Applications}},
url = {https://doi.org/10.1007/978-3-030-74575-2{\_}14},
year = {2021}
}
@article{misra2020multi,
  title={Multi-channel transfer learning of chest X-ray images for screening of COVID-19},
  author={Misra, Sampa and Jeon, Seungwan and Lee, Seiyon and Managuli, Ravi and Jang, In-Su and Kim, Chulhong},
  journal={Electronics},
  volume={9},
  number={9},
  pages={1388},
  year={2020},
  publisher={MDPI}
}
@article{krishna2019deep,
  title={Deep learning and transfer learning approaches for image classification},
  author={Krishna, Sajja Tulasi and Kalluri, Hemantha Kumar},
  journal={International Journal of Recent Technology and Engineering (IJRTE)},
  volume={7},
  number={5S4},
  pages={427--432},
  year={2019}
}
@article{huang2017transfer,
  title={Transfer learning with deep convolutional neural network for SAR target classification with limited labeled data},
  author={Huang, Zhongling and Pan, Zongxu and Lei, Bin},
  journal={Remote Sensing},
  volume={9},
  number={9},
  pages={907},
  year={2017},
  publisher={MDPI}
}
@incollection{torrey2010transfer,
  title={Transfer learning},
  author={Torrey, Lisa and Shavlik, Jude},
  booktitle={Handbook of research on machine learning applications and trends: algorithms, methods, and techniques},
  pages={242--264},
  year={2010},
  publisher={IGI global}
}
@inproceedings{cirecsan2012transfer,
  title={Transfer learning for Latin and Chinese characters with deep neural networks},
  author={Cire{\c{s}}an, Dan C and Meier, Ueli and Schmidhuber, J{\"u}rgen},
  booktitle={The 2012 international joint conference on neural networks (IJCNN)},
  pages={1--6},
  year={2012},
  organization={IEEE}
}
@article{kunze2017transfer,
  title={Transfer learning for speech recognition on a budget},
  author={Kunze, Julius and Kirsch, Louis and Kurenkov, Ilia and Krug, Andreas and Johannsmeier, Jens and Stober, Sebastian},
  journal={arXiv preprint arXiv:1706.00290},
  year={2017}
}
@ARTICLE{9241777,
  author={Vrbančič, Grega and Podgorelec, Vili},
  journal={IEEE Access}, 
  title={Transfer Learning With Adaptive Fine-Tuning}, 
  year={2020},
  volume={8},
  number={},
  pages={196197-196211},
  doi={10.1109/ACCESS.2020.3034343}}

  @article{BHARATI2020100391,
title = {Hybrid deep learning for detecting lung diseases from X-ray images},
journal = {Informatics in Medicine Unlocked},
volume = {20},
pages = {100391},
year = {2020},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2020.100391},
url = {https://www.sciencedirect.com/science/article/pii/S2352914820300290},
author = {Subrato Bharati and Prajoy Podder and M. Rubaiyat Hossain Mondal},
keywords = {Capsule network, CNN, COVID-19, Vanilla NN, VDSNet, VGG}
}
@article{apostolopoulos2020extracting,
  title={Extracting possibly representative COVID-19 biomarkers from X-ray images with deep learning approach and image data related to pulmonary diseases},
  author={Apostolopoulos, Ioannis D and Aznaouridis, Sokratis I and Tzani, Mpesiana A},
  journal={Journal of Medical and Biological Engineering},
  volume={40},
  pages={462--469},
  year={2020},
  publisher={Springer}
}
@article{asuntha2020deep,
  title={Deep learning for lung Cancer detection and classification},
  author={Asuntha, A and Srinivasan, Andy},
  journal={Multimedia Tools and Applications},
  volume={79},
  pages={7731--7762},
  year={2020},
  publisher={Springer}
}
@inproceedings{kabiraj2022detection,
  title={Detection and Classification of Lung Disease Using Deep Learning Architecture from X-ray Images},
  author={Kabiraj, Anwesh and Meena, Tanushree and Reddy, Pailla Balakrishna and Roy, Sudipta},
  booktitle={Advances in Visual Computing: 17th International Symposium, ISVC 2022, San Diego, CA, USA, October 3--5, 2022, Proceedings, Part I},
  pages={444--455},
  year={2022},
  organization={Springer}
}

@inproceedings{Liu2017a,
author = {Liu, C and Cao, Y and Alcantara, M and Liu, B and Brunette, M and Peinado, J and Curioso, W},
booktitle = {2017 IEEE International Conference on Image Processing (ICIP)},
doi = {10.1109/ICIP.2017.8296695},
isbn = {2381-8549 VO  -},
pages = {2314--2318},
title = {{TX-CNN: Detecting tuberculosis in chest X-ray images using convolutional neural network}},
year = {2017}
}
@article{Liu2021,
abstract = {To date, coronavirus disease 2019 (COVID-19) becomes increasingly fierce due to the emergence of variants. Rapid herd immunity through vaccination is needed to block the mutation and prevent the emergence of variants that can completely escape the immune surveillance. We aimed to systematically evaluate the effectiveness and safety of COVID-19 vaccines in the real world and to establish a reliable evidence-based basis for the actual protective effect of the COVID-19 vaccines, especially in the ensuing waves of infections dominated by variants.},
author = {Liu, Qiao and Qin, Chenyuan and Liu, Min and Liu, Jue},
doi = {10.1186/s40249-021-00915-3},
issn = {2049-9957},
journal = {Infectious Diseases of Poverty},
number = {1},
pages = {132},
title = {{Effectiveness and safety of SARS-CoV-2 vaccine in real-world studies: a systematic review and meta-analysis}},
url = {https://doi.org/10.1186/s40249-021-00915-3},
volume = {10},
year = {2021}
}
@article{Han2022,
abstract = {BackgroundThe interpretation of coronary computed tomography angiography (CCTA) stenosis may be difficult among radiologists of different experience levels. Artificial intelligence (AI) may improve the diagnostic performance.PurposeTo investigate whether the diagnostic performance and time efficiency of radiologists with different levels of experience in interpreting CCTA images could be improved by using CCTA with AI assistance (CCTA-AI).Material and MethodsThis analysis included 200 patients with complete CCTA and invasive coronary angiography (ICA) data, using ICA results as the reference. Eighteen radiologists were divided into three levels based on experience (Levels I, II, and III), and the three levels were divided into groups without (Groups 1, 2, and 3) and with (Groups 4, 5, and 6) AI assistance, totaling six groups (to avoid reader recall bias). The average sensitivity, specificity, NPV, PPV, and AUC were reported for the six groups and CCTA-AI at the patient, vessel, and segment levels. The interpretation time in the groups with and without CCTA-AI was recorded.ResultsCompared to the corresponding group without CCTA-AI, the Level I group with CCTA-AI had improved sensitivity (75.0{\%} vs. 83.0{\%} on patient-based; P?=?0.003). At Level III, the specificity was better with CCTA-AI. The median interpretation times for the groups with and without CCTA-AI were 413 and 615?s, respectively (P?{\textless}?0.001).ConclusionCCTA-AI could assist with and improve the diagnostic performance of radiologists with different experience levels, with Level I radiologists exhibiting improved sensitivity and Level III radiologists exhibiting improved specificity. The use of CCTA-AI could shorten the training time for radiologists.},
annote = {doi: 10.1177/02841851221089263},
author = {Han, Xianjun and He, Yi and Luo, Nan and Zheng, Dandan and Hong, Min and Wang, Zhenchang and Yang, Zhenghan},
doi = {10.1177/02841851221089263},
issn = {0284-1851},
journal = {Acta Radiologica},
month = {apr},
pages = {02841851221089263},
publisher = {SAGE Publications},
title = {{The influence of artificial intelligence assistance on the diagnostic performance of CCTA for coronary stenosis for radiologists with different levels of experience}},
url = {https://doi.org/10.1177/02841851221089263},
year = {2022}
}
@article{Meng2022,
abstract = {The recognition of medical images with deep learning techniques can assist physicians in clinical diagnosis, but the effectiveness of recognition models relies on massive amounts of labeled data. With the rampant development of the novel coronavirus (COVID-19) worldwide, rapid COVID-19 diagnosis has become an effective measure to combat the outbreak. However, labeled COVID-19 data are scarce. Therefore, we propose a two-stage transfer learning recognition model for medical images of COVID-19 (TL-Med) based on the concept of “generic domain-target-related domain-target domain”. First, we use the Vision Transformer (ViT) pretraining model to obtain generic features from massive heterogeneous data and then learn medical features from large-scale homogeneous data. Two-stage transfer learning uses the learned primary features and the underlying information for COVID-19 image recognition to solve the problem by which data insufficiency leads to the inability of the model to learn underlying target dataset information. The experimental results obtained on a COVID-19 dataset using the TL-Med model produce a recognition accuracy of 93.24{\%}, which shows that the proposed method is more effective in detecting COVID-19 images than other approaches and may greatly alleviate the problem of data scarcity in this field.},
author = {Meng, Jiana and Tan, Zhiyong and Yu, Yuhai and Wang, Pengjie and Liu, Shuang},
doi = {https://doi.org/10.1016/j.bbe.2022.04.005},
issn = {0208-5216},
journal = {Biocybernetics and Biomedical Engineering},
keywords = {COVID-19,Pretrained Model,Transfer Learning,ViT},
number = {3},
pages = {842--855},
title = {{TL-med: A Two-stage transfer learning recognition model for medical images of COVID-19}},
url = {https://www.sciencedirect.com/science/article/pii/S0208521622000377},
volume = {42},
year = {2022}
}
@inproceedings{Haritha2020a,
author = {Haritha, D and Pranathi, M K and Reethika, M},
booktitle = {2020 5th International Conference on Computing, Communication and Security (ICCCS)},
doi = {10.1109/ICCCS49678.2020.9277077},
isbn = {VO  -},
pages = {1--5},
title = {{COVID Detection from Chest X-rays with DeepLearning: CheXNet}},
year = {2020}
}
@incollection{ElAsnaoui2021,
abstract = {Recently, researchers, specialists, and companies around the world are rolling out deep learning and image processing-based systems that can fastly process hundreds of X-Ray and Computed Tomography (CT) images to accelerate the diagnosis of pneumonia such as SARS, covid-19, etc., and aid in its containment. Medical image analysis is one of the most promising research areas; it provides facilities for diagnosis and making decisions of several diseases such as MERS, covid-19, etc. In this paper, we present a comparison of recent deep convolutional neural network (CNN) architectures for automatic binary classification of pneumonia images based on fined tuned versions of (VGG16, VGG19, DenseNet201, Inception{\_}ResNet{\_}V2, Inception{\_}V3, Resnet50, MobileNet{\_}V2 and Xception) and a retraining of a baseline CNN. The proposed work has been tested using chest X-Ray {\&} CT dataset, which contains 6087 images (4504 pneumonia and 1583 normal). As a result, we can conclude that the fine-tuned version of Resnet50 shows highly satisfactory performance with rate of increase in training and testing accuracy (more than 96{\%} of accuracy).},
address = {Cham},
author = {{El Asnaoui}, Khalid and Chawki, Youness and Idri, Ali},
doi = {10.1007/978-3-030-74575-2_14},
editor = {Maleh, Yassine and Baddi, Youssef and Alazab, Mamoun and Tawalbeh, Loai and Romdhani, Imed},
isbn = {978-3-030-74575-2},
pages = {257--284},
publisher = {Springer International Publishing},
title = {{Automated Methods for Detection and Classification Pneumonia Based on X-Ray Images Using Deep Learning BT  - Artificial Intelligence and Blockchain for Future Cybersecurity Applications}},
url = {https://doi.org/10.1007/978-3-030-74575-2{\_}14},
year = {2021}
}
@misc{Stokel-Walker2022,
author = {Stokel-Walker, Chris},
booktitle = {Nature},
doi = {10.1038/d41586-022-00620-7},
issn = {14764687},
keywords = {SARS-CoV-2},
number = {7902},
pages = {563},
pmid = {35256787},
title = {{COVID restrictions are lifting - what scientists think}},
url = {https://www.nature.com/articles/d41586-022-00620-7},
volume = {603},
year = {2022}
}
@article{Sharma2022,
abstract = {Chest X-ray (CXR) imaging is one of the most widely used and economical tests to diagnose a wide range of diseases. However, even for expert radiologists, it is a challenge to accurately diagnose diseases from CXR samples. Furthermore, there remains an acute shortage of trained radiologists worldwide. In the present study, a range of machine learning (ML), deep learning (DL), and transfer learning (TL) approaches have been evaluated to classify diseases in an openly available CXR image dataset. A combination of the synthetic minority over-sampling technique (SMOTE) and weighted class balancing is used to alleviate the effects of class imbalance. A hybrid Inception-ResNet-v2 transfer learning model coupled with data augmentation and image enhancement gives the best accuracy. The model is deployed in an edge environment using Amazon IoT Core to automate the task of disease detection in CXR images with three categories, namely pneumonia, COVID-19, and normal. Comparative analysis has been given in various metrics such as precision, recall, accuracy, AUC-ROC score, etc. The proposed technique gives an average accuracy of 98.66{\&}{\#}x0025;. The accuracies of other TL models, namely SqueezeNet, VGG19, ResNet50, and MobileNetV2 are 97.33{\&}{\#}x0025;, 91.66{\&}{\#}x0025;, 90.33{\&}{\#}x0025;, and 76.00{\&}{\#}x0025;, respectively. Further, a DL model, trained from scratch, gives an accuracy of 92.43{\&}{\#}x0025;. Two feature-based ML classification techniques, namely support vector machine with local binary pattern (SVM{\&}{\#}x2009;{\&}{\#}x2b;{\&}{\#}x2009;LBP) and decision tree with histogram of oriented gradients (DT{\&}{\#}x2009;{\&}{\#}x2b;{\&}{\#}x2009;HOG) yield an accuracy of 87.98{\&}{\#}x0025; and 86.87{\&}{\#}x0025;, respectively.},
author = {Sharma, Chandra Mani and Goyal, Lakshay and Chariar, Vijayaraghavan M and Sharma, Navel},
doi = {10.1155/2022/9036457},
editor = {Gupta, Suneet Kumar},
issn = {2040-2295},
journal = {Journal of Healthcare Engineering},
pages = {9036457},
publisher = {Hindawi},
title = {{Lung Disease Classification in CXR Images Using Hybrid Inception-ResNet-v2 Model and Edge Computing}},
url = {https://doi.org/10.1155/2022/9036457},
volume = {2022},
year = {2022}
}
@article{Rajagopal2023a,
abstract = {Lung disease is a most common disease all over the world. A numerous feature extraction with classification models were discussed previously about the lung disease, but those methods having high over fitting problem, consequently, decrease the accuracy of detection. To overwhelm this issue, a Deep Convolutional Spiking Neural Network optimized with Arithmetic Optimization Algorithm is proposed in this manuscript for Lung Disease Detection using Chest X-ray Images as COVID-19, normal and viral pneumonia. Initially, NIH chest X-ray image dataset is taken from Kaggle repository for detecting lung disease. Then, the chest X-ray images are pre-processed using the Anisotropic Diffusion Filter Based Unsharp Masking and crispening scheme for removing noise and enhancing the image quality. These pre-processed outputs are fed to feature extraction. In feature extraction process, the empirical wavelet transform method is used. These extracted features are given into Deep Convolutional Spiking Neural Network classifier (DCSNN) for detecting lung diseases. Here, the weight with bias parameter of DCSNN is enhanced based upon Arithmetic Optimization Algorithm (AOA), which improves detection accuracy. The simulation is executed in MATLAB. The proposed LDC-DCSNN-AOA technique attains higher accuracy, higher Precision, higher F-Score analyzed with the existing techniques, like Lung disease detection using Support Vector Machines optimized with Social Mimic Optimization (LDC-SVM-SMO), Lung disease detection using eXtreme Gradient Boosting optimized by particle swarm optimization (LDC-XGBoost-PSO), Lung disease detection using neuro-fuzzy classifier optimized with multi-objective genetic algorithm (LDC-NFC-MOGA), Lung disease detection using convolutional neural network optimized with Bayesian optimization LDC –CNN-BOA respectively.},
author = {Rajagopal, R and Karthick, R and Meenalochini, P and Kalaichelvi, T},
doi = {https://doi.org/10.1016/j.bspc.2022.104197},
issn = {1746-8094},
journal = {Biomedical Signal Processing and Control},
keywords = {Anisotropic Diffusion Filter Based Unsharp Masking,Arithmetic Optimization Algorithm,Chest X-ray images,Deep Convolutional Spiking Neural Network classifi,Empirical wavelet transform,Lung Disease detection},
pages = {104197},
title = {{Deep Convolutional Spiking Neural Network optimized with Arithmetic optimization algorithm for lung disease detection using chest X-ray images}},
url = {https://www.sciencedirect.com/science/article/pii/S1746809422006516},
volume = {79},
year = {2023}
}
@article{Alazab2020a,
abstract = {Currently, the detection of coronavirus disease 2019 (COVID-19) is one of the main challenges in the world, given the rapid spread of the disease. Recent statistics indicate that the number of people diagnosed with COVID-19 is increasing exponentially, with more than 1.6 million confirmed cases; the disease is spreading to many countries across the world. In this study, we analyse the incidence of COVID-19 distribution across the world. We present an artificial-intelligence technique based on a deep convolutional neural network (CNN) to detect COVID-19 patients using real-world datasets. Our system examines chest X-ray images to identify such patients. Our findings indicate that such an analysis is valuable in COVID-19 diagnosis as X-rays are conveniently available quickly and at low costs. Empirical findings obtained from 1000 X-ray images of real patients confirmed that our proposed system is useful in detecting COVID-19 and achieves an F-measure range of 95-99{\%}. Additionally, three forecasting methods-the prophet algorithm (PA), autoregressive integrated moving average (ARIMA) model, and long short-term memory neural network (LSTM)-were adopted to predict the numbers of COVID-19 confirmations, recoveries, and deaths over the next 7 days. The prediction results exhibit promising performance and offer an average accuracy of 94.80{\%} and 88.43{\%} in Australia and Jordan, respectively. Our proposed system can significantly help identify the most infected cities, and it has revealed that coastal areas are heavily impacted by the COVID-19 spread as the number of cases is significantly higher in those areas than in non-coastal areas.},
author = {Alazab, Moutaz and Awajan, Albara and Mesleh, Abdelwadood and Abraham, Ajith and Jatana, Vansh and Alhyari, Salah},
file = {:C$\backslash$:/Users/iradspm/Downloads/ijcisim{\_}1.pdf:pdf},
issn = {21507988},
journal = {International Journal of Computer Information Systems and Industrial Management Applications},
keywords = {Artificial intelligence,COVID-19,Convolutional neural network,Machine learning,X-ray},
number = {April},
pages = {168--181},
title = {{COVID-19 prediction and detection using deep learning}},
volume = {12},
year = {2020}
}
@article{Matos2021,
abstract = {Ground-glass opacity is a very frequent and unspecified finding in chest computed tomography. Therefore, it admits a wide range of differential diagnoses in the acute context, from viral pneumonias such as influenza virus, coronavirus disease 2019 and cytomegalovirus and even non-infectious lesions, such as vaping, pulmonary infarction, alveolar hemorrhage and pulmonary edema. For this diagnostic differentiation, ground glass must be correlated with other findings in imaging tests, with laboratory tests and with the patients' clinical condition. In the context of a pandemic, it is extremely important to remember the other pathologies with similar findings to coronavirus disease 2019 in the imaging exams.},
author = {de Matos, Marina Justi Rosa and Rosa, Marcela Emer Egypto and Brito, Vanessa Mizubuti and Amaral, Lucas Tadashi Wada and Beraldo, Gabriel Laverdi and Fonseca, Eduardo Kaiser Ururahy Nunes and Chate, Rodrigo Caruso and Passos, Rodrigo Bastos Duarte and Silva, Murilo Marques Almeida and Yokoo, Patr{\'{i}}cia and {Sasdelli Neto}, Roberto and Teles, Gustavo Borges da Silva and da Silva, Marina Carolina Bueno and Szarf, Gilberto},
doi = {10.31744/einstein_journal/2021RW5772},
file = {:C$\backslash$:/Users/iradspm/Downloads/2317{\_}6385{\_}eins{\_}19{\_}eRW5772{\_}pdf.pdf:pdf},
issn = {23176385},
journal = {Einstein (Sao Paulo, Brazil)},
keywords = {amaral lt,article,brito vm,coronavirus infections,covid-19,diagnosis,diagnostic imaging,differential,how to cite this,matos mj,pandemics,rosa me,sars-cov-2,thorax,tomography,x-ray computed},
pages = {eRW5772},
pmid = {33729289},
title = {{Differential diagnoses of acute ground-glass opacity in chest computed tomography: pictorial essay}},
volume = {19},
year = {2021}
}
@article{Wu2020,
abstract = {Importance: Chest radiography is the most common diagnostic imaging examination performed in emergency departments (EDs). Augmenting clinicians with automated preliminary read assistants could help expedite their workflows, improve accuracy, and reduce the cost of care. Objective: To assess the performance of artificial intelligence (AI) algorithms in realistic radiology workflows by performing an objective comparative evaluation of the preliminary reads of anteroposterior (AP) frontal chest radiographs performed by an AI algorithm and radiology residents. Design, Setting, and Participants: This diagnostic study included a set of 72 findings assembled by clinical experts to constitute a full-fledged preliminary read of AP frontal chest radiographs. A novel deep learning architecture was designed for an AI algorithm to estimate the findings per image. The AI algorithm was trained using a multihospital training data set of 342126 frontal chest radiographs captured in ED and urgent care settings. The training data were labeled from their associated reports. Image-based F1 score was chosen to optimize the operating point on the receiver operating characteristics (ROC) curve so as to minimize the number of missed findings and overcalls per image read. The performance of the model was compared with that of 5 radiology residents recruited from multiple institutions in the US in an objective study in which a separate data set of 1998 AP frontal chest radiographs was drawn from a hospital source representative of realistic preliminary reads in inpatient and ED settings. A triple consensus with adjudication process was used to derive the ground truth labels for the study data set. The performance of AI algorithm and radiology residents was assessed by comparing their reads with ground truth findings. All studies were conducted through a web-based clinical study application system. The triple consensus data set was collected between February and October 2018. The comparison study was preformed between January and October 2019. Data were analyzed from October to February 2020. After the first round of reviews, further analysis of the data was performed from March to July 2020. Main Outcomes and Measures: The learning performance of the AI algorithm was judged using the conventional ROC curve and the area under the curve (AUC) during training and field testing on the study data set. For the AI algorithm and radiology residents, the individual finding label performance was measured using the conventional measures of label-based sensitivity, specificity, and positive predictive value (PPV). In addition, the agreement with the ground truth on the assignment of findings to images was measured using the pooled $\kappa$ statistic. The preliminary read performance was recorded for AI algorithm and radiology residents using new measures of mean image-based sensitivity, specificity, and PPV designed for recording the fraction of misses and overcalls on a per image basis. The 1-sided analysis of variance test was used to compare the means of each group (AI algorithm vs radiology residents) using the F distribution, and the null hypothesis was that the groups would have similar means. Results: The trained AI algorithm achieved a mean AUC across labels of 0.807 (weighted mean AUC, 0.841) after training. On the study data set, which had a different prevalence distribution, the mean AUC achieved was 0.772 (weighted mean AUC, 0.865). The interrater agreement with ground truth finding labels for AI algorithm predictions had pooled $\kappa$ value of 0.544, and the pooled $\kappa$ for radiology residents was 0.585. For the preliminary read performance, the analysis of variance test was used to compare the distributions of AI algorithm and radiology residents' mean image-based sensitivity, PPV, and specificity. The mean image-based sensitivity for AI algorithm was 0.716 (95{\%} CI, 0.704-0.729) and for radiology residents was 0.720 (95{\%} CI, 0.709-0.732) (P =.66), while the PPV was 0.730 (95{\%} CI, 0.718-0.742) for the AI algorithm and 0.682 (95{\%} CI, 0.670-0.694) for the radiology residents (P {\textless}.001), and specificity was 0.980 (95{\%} CI, 0.980-0.981) for the AI algorithm and 0.973 (95{\%} CI, 0.971-0.974) for the radiology residents (P {\textless}.001). Conclusions and Relevance: These findings suggest that it is possible to build AI algorithms that reach and exceed the mean level of performance of third-year radiology residents for full-fledged preliminary read of AP frontal chest radiographs. This diagnostic study also found that while the more complex findings would still benefit from expert overreads, the performance of AI algorithms was associated with the amount of data available for training rather than the level of difficulty of interpretation of the finding. Integrating such AI systems in radiology workflows for preliminary interpretations has the potential to expedite existing radiology workflows and address resource scarcity while improving overall accuracy and reducing the cost of care..},
author = {Wu, Joy T. and Wong, Ken C.L. and Gur, Yaniv and Ansari, Nadeem and Karargyris, Alexandros and Sharma, Arjun and Morris, Michael and Saboury, Babak and Ahmad, Hassan and Boyko, Orest and Syed, Ali and Jadhav, Ashutosh and Wang, Hongzhi and Pillai, Anup and Kashyap, Satyananda and Moradi, Mehdi and Syeda-Mahmood, Tanveer},
doi = {10.1001/jamanetworkopen.2020.22779},
file = {:C$\backslash$:/Users/iradspm/Downloads/wu{\_}2020{\_}oi{\_}200758{\_}1601603854.73034.pdf:pdf},
issn = {25743805},
journal = {JAMA Network Open},
number = {10},
pages = {1--14},
pmid = {33034642},
title = {{Comparison of Chest Radiograph Interpretations by Artificial Intelligence Algorithm vs Radiology Residents}},
volume = {3},
year = {2020}
}
@misc{Crider2022,
author = {Crider, Catherine},
title = {{Lung Opacity: What You Should Know}},
url = {https://www.healthline.com/health/lung-opacity},
year = {2022}
}
@article{UshaKiruthika2019a,
abstract = {x-rays are the most commonly performed which are costly diagnostic imaging tests ordered by physicians. Here we are proposing an artificial intelligence system that can reliably separate normal from abnormal would be invaluable in addressing the problem of undiagnosed disease and the lack of radiologists in low-resource settings. The aim of this study is to develop and validate a deep learning system to detect chest x-ray abnormalities and hence detect Tuberculosis (TB) and to provide a tool for Computer Aided Diagnosis (CAD).In this paper by trying to explore existing systems of Image Processing and Deep learning architectures, we are trying to achieve radiologist level detection as well as lower False Negative detection of TB by using ensemble datasets and algorithms. The prototype of a WebApp is created and can be checked on https://parth-patel12.github.io where one can upload the chest x-ray which give probabilities of the chest x-ray to be normal or TB affected.},
author = {{Usha Kiruthika}, S. and {Kanaga Suba Raja}, S. and Balaji, V. and Raman, C. J. and {Durai Arumugam}, S. S.L.},
doi = {10.35940/ijitee.A4834.119119},
file = {:C$\backslash$:/Users/iradspm/Downloads/26DetectionofTuberculosisinChestX-raysusingU-NetArchitecture.pdf:pdf},
issn = {22783075},
journal = {International Journal of Innovative Technology and Exploring Engineering},
keywords = {Artificial neural network,Autism,Computer aided diagnosis,Convolutional neural networks,Generative adversarial network,Tuberculosis},
number = {1},
pages = {2514--2519},
title = {{Detection of tuberculosis in chest X-rays using U-net architecture}},
volume = {9},
year = {2019}
}
@article{Ravi2022a,
abstract = {This paper proposes a multichannel deep learning approach for lung disease detection using chest X-rays. The multichannel models used in this work are EfficientNetB0, EfficientNetB1, and EfficientNetB2 pretrained models. The features from EfficientNet models are fused together. Next, the fused features are passed into more than one non-linear fully connected layer. Finally, the features passed into a stacked ensemble learning classifier for lung disease detection. The stacked ensemble learning classifier contains random forest and SVM in the first stage and logistic regression in the second stage for lung disease detection. The performance of the proposed method is studied in detail for more than one lung disease such as pneumonia, Tuberculosis (TB), and COVID-19. The performances of the proposed method for lung disease detection using chest X-rays compared with similar methods with the aim to show that the method is robust and has the capability to achieve better performances. In all the experiments on lung disease, the proposed method showed better performance and outperformed similar lung disease existing methods. This indicates that the proposed method is robust and generalizable on unseen chest X-rays data samples. To ensure that the features learnt by the proposed method is optimal, t-SNE feature visualization was shown on all three lung disease models. Overall, the proposed method has shown 98{\%} detection accuracy for pediatric pneumonia lung disease, 99{\%} detection accuracy for TB lung disease, and 98{\%} detection accuracy for COVID-19 lung disease. The proposed method can be used as a tool for point-of-care diagnosis by healthcare radiologists.Journal instruction requires a city for affiliations; however, this is missing in affiliation 3. Please verify if the provided city is correct and amend if necessary.correct},
author = {Ravi, Vinayakumar and Acharya, Vasundhara and Alazab, Mamoun},
doi = {10.1007/s10586-022-03664-6},
issn = {1573-7543},
journal = {Cluster Computing},
title = {{A multichannel EfficientNet deep learning-based stacking ensemble approach for lung disease detection using chest X-ray images}},
url = {https://doi.org/10.1007/s10586-022-03664-6},
year = {2022}
}
@inproceedings{Dornadula2021,
author = {Dornadula, B and Geetha, S and Phamila, A V and Priscilla, R and Vijayakumar, K},
booktitle = {2021 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)},
doi = {10.1109/ICSES52305.2021.9633887},
isbn = {VO  -},
pages = {1--6},
title = {{Forecasting the lung diseases from Radiography scans with hybrid Transfer Learning Techniques}},
year = {2021}
}
@article{Yamamoto2021,
abstract = {Background Human microbiotas are communities of microorganisms living in symbiosis with humans. They play an important role in the host immune response to respiratory viral infection. However, evidence on the human microbiome and coronavirus disease (COVID-19) relationship is insufficient. The aim of this systematic literature review was to evaluate existing evidence on the association between the microbiome and COVID-19 in humans and summarize these data in the pandemic era. Methods We conducted a systematic literature review on the association between the microbiome and COVID-19 in humans by searching PubMed, Embase, and the Cochrane Library, CINAHL, and Web of Science databases for articles in English published up to October 31, 2020. The results were analyzed qualitatively. This study is registered with PROSPERO (CRD42020195982). Results Of the 543 articles identified by searching databases, 16 in line with the research objectives were eligible for qualitative review: eight sampled the microbiome using stool, four using nasopharyngeal or throat swab, three using bronchoalveolar lavage fluid, and one using lung tissue. Fecal microbiome dysbiosis and increased opportunistic pathogens were reported in COVID-19 patients. Several studies suggested the dysbiosis in the lung microbiome of COVID-19 patients with an abundance of opportunistic pathogens using lower respiratory tract samples. The association between COVID-19 severity and the human microbiome remains uncertain. Conclusion The human fecal and respiratory tract microbiome changed in COVID-19 patients with opportunistic pathogen abundance. Further research to elucidate the effect of alternation of the human microbiome in disease pathogenesis is warranted.},
author = {Yamamoto, Shinya and Saito, Makoto and Tamura, Azumi and Prawisuda, Diki and Mizutani, Taketoshi and Yotsuyanagi, Hiroshi},
doi = {10.1371/journal.pone.0253293},
file = {:C$\backslash$:/Users/iradspm/Downloads/journal.pone.0253293.pdf:pdf},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS ONE},
number = {6 June},
pages = {1--13},
pmid = {34161373},
title = {{The human microbiome and COVID-19: A systematic review}},
url = {http://dx.doi.org/10.1371/journal.pone.0253293},
volume = {16},
year = {2021}
}
@article{Song2020,
abstract = {Background: The chest CT findings of patients with 2019 Novel Coronavirus (2019-nCoV) pneumonia have not previously been described in detail. Purpose: To investigate the clinical, laboratory, and imaging findings of emerging 2019-nCoV pneumonia in humans. Materials and Methods: Fifty-one patients (25 men and 26 women; age range 16–76 years) with laboratory-confirmed 2019-nCoV infection by using real-time reverse transcription polymerase chain reaction underwent thin-section CT. The imaging findings, clinical data, and laboratory data were evaluated. Results: Fifty of 51 patients (98{\%}) had a history of contact with individuals from the endemic center in Wuhan, China. Fever (49 of 51, 96{\%}) and cough (24 of 51, 47{\%}) were the most common symptoms. Most patients had a normal white blood cell count (37 of 51, 73{\%}), neutrophil count (44 of 51, 86{\%}), and either normal (17 of 51, 35{\%}) or reduced (33 of 51, 65{\%}) lymphocyte count. CT images showed pure ground-glass opacity (GGO) in 39 of 51 (77{\%}) patients and GGO with reticular and/ or interlobular septal thickening in 38 of 51 (75{\%}) patients. GGO with consolidation was present in 30 of 51 (59{\%}) patients, and pure consolidation was present in 28 of 51 (55{\%}) patients. Forty-four of 51 (86{\%}) patients had bilateral lung involvement, while 41 of 51 (80{\%}) involved the posterior part of the lungs and 44 of 51 (86{\%}) were peripheral. There were more consolidated lung lesions in patients 5 days or more from disease onset to CT scan versus 4 days or fewer (431 of 712 lesions vs 129 of 612 lesions; P , .001). Patients older than 50 years had more consolidated lung lesions than did those aged 50 years or younger (212 of 470 vs 198 of 854; P , .001). Follow-up CT in 13 patients showed improvement in seven (54{\%}) patients and progression in four (31{\%}) patients. Conclusion: Patients with fever and/or cough and with conspicuous ground-glass opacity lesions in the peripheral and posterior lungs on CT images, combined with normal or decreased white blood cells and a history of epidemic exposure, are highly suspected of having 2019 Novel Coronavirus (2019-nCoV) pneumonia.},
author = {Song, Fengxiang and Shi, Nannan and Shan, Fei and Zhang, Zhiyong and Shen, Jie and Lu, Hongzhou and Ling, Yun and Jiang, Yebin and Shi, Yuxin},
doi = {10.1148/radiol.2020200274},
file = {:C$\backslash$:/Users/iradspm/Downloads/radiol.2020200274.pdf:pdf},
issn = {15271315},
journal = {Radiology},
number = {1},
pages = {210--217},
pmid = {32027573},
title = {{Emerging 2019 novel coronavirus (2019-NCoV) pneumonia}},
volume = {295},
year = {2020}
}
@inproceedings{Ahsan2019a,
author = {Ahsan, M and Gomes, R and Denton, A},
booktitle = {2019 IEEE International Conference on Electro Information Technology (EIT)},
doi = {10.1109/EIT.2019.8833768},
isbn = {2154-0373 VO  -},
pages = {427--433},
title = {{Application of a Convolutional Neural Network using transfer learning for tuberculosis detection}},
year = {2019}
}
@article{Aggarwal2021,
abstract = {Deep learning (DL) has the potential to transform medical diagnostics. However, the diagnostic accuracy of DL is uncertain. Our aim was to evaluate the diagnostic accuracy of DL algorithms to identify pathology in medical imaging. Searches were conducted in Medline and EMBASE up to January 2020. We identified 11,921 studies, of which 503 were included in the systematic review. Eighty-two studies in ophthalmology, 82 in breast disease and 115 in respiratory disease were included for meta-analysis. Two hundred twenty-four studies in other specialities were included for qualitative review. Peer-reviewed studies that reported on the diagnostic accuracy of DL algorithms to identify pathology using medical imaging were included. Primary outcomes were measures of diagnostic accuracy, study design and reporting standards in the literature. Estimates were pooled using random-effects meta-analysis. In ophthalmology, AUC's ranged between 0.933 and 1 for diagnosing diabetic retinopathy, age-related macular degeneration and glaucoma on retinal fundus photographs and optical coherence tomography. In respiratory imaging, AUC's ranged between 0.864 and 0.937 for diagnosing lung nodules or lung cancer on chest X-ray or CT scan. For breast imaging, AUC's ranged between 0.868 and 0.909 for diagnosing breast cancer on mammogram, ultrasound, MRI and digital breast tomosynthesis. Heterogeneity was high between studies and extensive variation in methodology, terminology and outcome measures was noted. This can lead to an overestimation of the diagnostic accuracy of DL algorithms on medical imaging. There is an immediate need for the development of artificial intelligence-specific EQUATOR guidelines, particularly STARD, in order to provide guidance around key issues in this field.},
author = {Aggarwal, Ravi and Sounderajah, Viknesh and Martin, Guy and Ting, Daniel S W and Karthikesalingam, Alan and King, Dominic and Ashrafian, Hutan and Darzi, Ara},
doi = {10.1038/s41746-021-00438-z},
issn = {2398-6352},
journal = {npj Digital Medicine},
number = {1},
pages = {65},
title = {{Diagnostic accuracy of deep learning in medical imaging: a systematic review and meta-analysis}},
url = {https://doi.org/10.1038/s41746-021-00438-z},
volume = {4},
year = {2021}
}
@article{Parekh2020,
abstract = {Coronavirus disease 2019 (COVID-19), a recently emerged lower respiratory tract illness, has quickly become a pandemic. The purpose of this review is to discuss and differentiate typical imaging findings of COVID-19 from those of other diseases, which can appear similar in the first instance. The typical CT findings of COVID-19 are bilateral and peripheral predominant ground-glass opacities. As per the Fleischner Society consensus statement, CT is appropriate in certain scenarios, including for patients who are at risk for and/or develop clinical worsening. The probability that CT findings represent COVID-19, however, depends largely on the pretest probability of infection, which is in turn defined by community prevalence of infection. When the community prevalence of COVID-19 is low, a large gap exists between positive predictive values of chest CT versus those of reverse transcriptase polymerase chain reaction. This implies that with use of chest CT there are a large number of false-positive results. Imaging differentiation is important for management and isolation purposes and for appropriate disposition of patients with false-positive CT findings. Herein the authors discuss differential pathology with close imaging resemblance to typical CT imaging features of COVID-19 and highlight CT features that may help differentiate COVID-19 from other conditions.},
author = {Parekh, Maansi and Donuru, Achala and Balasubramanya, Rashmi and Kapur, Sangita},
doi = {10.1148/radiol.2020202504},
file = {:C$\backslash$:/Users/iradspm/Downloads/radiol.2020202504.pdf:pdf},
issn = {15271315},
journal = {Radiology},
number = {3},
pages = {E289--E302},
pmid = {32633678},
title = {{Review of the chest CT differential diagnosis of ground-glass opacities in the COVID era}},
volume = {297},
year = {2020}
}
@article{Bharati2020a,
abstract = {Lung disease is common throughout the world. These include chronic obstructive pulmonary disease, pneumonia, asthma, tuberculosis, fibrosis, etc. Timely diagnosis of lung disease is essential. Many image processing and machine learning models have been developed for this purpose. Different forms of existing deep learning techniques including convolutional neural network (CNN), vanilla neural network, visual geometry group based neural network (VGG), and capsule network are applied for lung disease prediction. The basic CNN has poor performance for rotated, tilted, or other abnormal image orientation. Therefore, we propose a new hybrid deep learning framework by combining VGG, data augmentation and spatial transformer network (STN) with CNN. This new hybrid method is termed here as VGG Data STN with CNN (VDSNet). As implementation tools, Jupyter Notebook, Tensorflow, and Keras are used. The new model is applied to NIH chest X-ray image dataset collected from Kaggle repository. Full and sample versions of the dataset are considered. For both full and sample datasets, VDSNet outperforms existing methods in terms of a number of metrics including precision, recall, F0.5 score and validation accuracy. For the case of full dataset, VDSNet exhibits a validation accuracy of 73{\%}, while vanilla gray, vanilla RGB, hybrid CNN and VGG, and modified capsule network have accuracy values of 67.8{\%}, 69{\%}, 69.5{\%} and 63.8{\%}, respectively. When sample dataset rather than full dataset is used, VDSNet requires much lower training time at the expense of a slightly lower validation accuracy. Hence, the proposed VDSNet framework will simplify the detection of lung disease for experts as well as for doctors.},
author = {Bharati, Subrato and Podder, Prajoy and Mondal, M Rubaiyat Hossain},
doi = {https://doi.org/10.1016/j.imu.2020.100391},
issn = {2352-9148},
journal = {Informatics in Medicine Unlocked},
keywords = {CNN,COVID-19,Capsule network,VDSNet,VGG,Vanilla NN},
pages = {100391},
title = {{Hybrid deep learning for detecting lung diseases from X-ray images}},
url = {https://www.sciencedirect.com/science/article/pii/S2352914820300290},
volume = {20},
year = {2020}
}
@inproceedings{Monowar2020a,
author = {Monowar, K F and Hasan, M A M and Shin, J},
booktitle = {2020 11th International Conference on Electrical and Computer Engineering (ICECE)},
doi = {10.1109/ICECE51571.2020.9393135},
isbn = {VO  -},
pages = {169--172},
title = {{Lung Opacity Classification With Convolutional Neural Networks Using Chest X-rays}},
year = {2020}
}
@article{Zhou2020,
abstract = {Background: Since December, 2019, Wuhan, China, has experienced an outbreak of coronavirus disease 2019 (COVID-19), caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Epidemiological and clinical characteristics of patients with COVID-19 have been reported but risk factors for mortality and a detailed clinical course of illness, including viral shedding, have not been well described. Methods: In this retrospective, multicentre cohort study, we included all adult inpatients (≥18 years old) with laboratory-confirmed COVID-19 from Jinyintan Hospital and Wuhan Pulmonary Hospital (Wuhan, China) who had been discharged or had died by Jan 31, 2020. Demographic, clinical, treatment, and laboratory data, including serial samples for viral RNA detection, were extracted from electronic medical records and compared between survivors and non-survivors. We used univariable and multivariable logistic regression methods to explore the risk factors associated with in-hospital death. Findings: 191 patients (135 from Jinyintan Hospital and 56 from Wuhan Pulmonary Hospital) were included in this study, of whom 137 were discharged and 54 died in hospital. 91 (48{\%}) patients had a comorbidity, with hypertension being the most common (58 [30{\%}] patients), followed by diabetes (36 [19{\%}] patients) and coronary heart disease (15 [8{\%}] patients). Multivariable regression showed increasing odds of in-hospital death associated with older age (odds ratio 1{\textperiodcentered}10, 95{\%} CI 1{\textperiodcentered}03–1{\textperiodcentered}17, per year increase; p=0{\textperiodcentered}0043), higher Sequential Organ Failure Assessment (SOFA) score (5{\textperiodcentered}65, 2{\textperiodcentered}61–12{\textperiodcentered}23; p{\textless}0{\textperiodcentered}0001), and d-dimer greater than 1 $\mu$g/mL (18{\textperiodcentered}42, 2{\textperiodcentered}64–128{\textperiodcentered}55; p=0{\textperiodcentered}0033) on admission. Median duration of viral shedding was 20{\textperiodcentered}0 days (IQR 17{\textperiodcentered}0–24{\textperiodcentered}0) in survivors, but SARS-CoV-2 was detectable until death in non-survivors. The longest observed duration of viral shedding in survivors was 37 days. Interpretation: The potential risk factors of older age, high SOFA score, and d-dimer greater than 1 $\mu$g/mL could help clinicians to identify patients with poor prognosis at an early stage. Prolonged viral shedding provides the rationale for a strategy of isolation of infected patients and optimal antiviral interventions in the future. Funding: Chinese Academy of Medical Sciences Innovation Fund for Medical Sciences; National Science Grant for Distinguished Young Scholars; National Key Research and Development Program of China; The Beijing Science and Technology Project; and Major Projects of National Science and Technology on New Drug Creation and Development.},
author = {Zhou, Fei and Yu, Ting and Du, Ronghui and Fan, Guohui and Liu, Ying and Liu, Zhibo and Xiang, Jie and Wang, Yeming and Song, Bin and Gu, Xiaoying and Guan, Lulu and Wei, Yuan and Li, Hui and Wu, Xudong and Xu, Jiuyang and Tu, Shengjin and Zhang, Yi and Chen, Hua and Cao, Bin},
doi = {10.1016/S0140-6736(20)30566-3},
file = {:C$\backslash$:/Users/iradspm/Downloads/1-s2.0-S0140673620305663-main.pdf:pdf},
issn = {1474547X},
journal = {The Lancet},
number = {10229},
pages = {1054--1062},
pmid = {32171076},
publisher = {Elsevier Ltd},
title = {{Clinical course and risk factors for mortality of adult inpatients with COVID-19 in Wuhan, China: a retrospective cohort study}},
url = {http://dx.doi.org/10.1016/S0140-6736(20)30566-3},
volume = {395},
year = {2020}
}
@article{Li2016a,
abstract = {Computer aided detection (CAD) systems can assist radiologists by offering a second opinion on early diagnosis of lung cancer. Classification and feature representation play critical roles in false-positive reduction (FPR) in lung nodule CAD. We design a deep convolutional neural networks method for nodule classification, which has an advantage of autolearning representation and strong generalization ability. A specified network structure for nodule images is proposed to solve the recognition of three types of nodules, that is, solid, semisolid, and ground glass opacity (GGO). Deep convolutional neural networks are trained by 62,492 regions-of-interest (ROIs) samples including 40,772 nodules and 21,720 nonnodules from the Lung Image Database Consortium (LIDC) database. Experimental results demonstrate the effectiveness of the proposed method in terms of sensitivity and overall accuracy and that it consistently outperforms the competing methods.},
author = {Li, Wei and Cao, Peng and Zhao, Dazhe and Wang, Junbo},
doi = {10.1155/2016/6215085},
editor = {Suzuki, Kenji},
issn = {1748-670X},
journal = {Computational and Mathematical Methods in Medicine},
pages = {6215085},
publisher = {Hindawi Publishing Corporation},
title = {{Pulmonary Nodule Classification with Deep Convolutional Neural Networks on Computed Tomography Images}},
url = {https://doi.org/10.1155/2016/6215085},
volume = {2016},
year = {2016}
}
@article{Bala2021,
abstract = {There is increasing interest in understanding the role of air pollution as one of the greatest threats to human health worldwide. Nine of 10 individuals breathe air with polluted compounds that have a great impact on lung tissue. The nature of the relationship is complex, and new or updated data are constantly being reported in the literature. The goal of our review was to summarize the most important air pollutants and their impact on the main respiratory diseases (chronic obstructive pulmonary disease, asthma, lung cancer, idiopathic pulmonary fibrosis, respiratory infections, bronchiectasis, tuberculosis) to reduce both short- and the long-term exposure consequences. We considered the most important air pollutants, including sulfur dioxide, nitrogen dioxide, carbon monoxide, volatile organic compounds, ozone, particulate matter and biomass smoke, and observed their impact on pulmonary pathologies. We focused on respiratory pathologies, because air pollution potentiates the increase in respiratory diseases, and the evidence that air pollutants have a detrimental effect is growing. It is imperative to constantly improve policy initiatives on air quality in both high- and low-income countries.},
author = {Bălă, Gabriel-Petrică and R{\^{a}}jnoveanu, Ruxandra-Mioara and Tudorache, Emanuela and Motișan, Radu and Oancea, Cristian},
doi = {10.1007/s11356-021-13208-x},
issn = {1614-7499},
journal = {Environmental Science and Pollution Research},
number = {16},
pages = {19615--19628},
title = {{Air pollution exposure—the (in)visible risk factor for respiratory diseases}},
url = {https://doi.org/10.1007/s11356-021-13208-x},
volume = {28},
year = {2021}
}
@article{Tan2022,
abstract = {Chronic respiratory diseases have collectively become a major public health concern and have now taken form as one of the leading causes of mortality worldwide. Most chronic respiratory diseases primarily occur due to prolonged airway inflammation. In addition, critical environmental factors such as cigarette smoke, industrial pollutants, farm dust, and pollens may also exacerbate such diseases. Moreover, alterations in the genetic sequence of an individual, abnormalities in the chromosomes or immunosuppression resulting from bacterial, fungal, and viral infections may also play a key role in the pathogenesis of respiratory diseases. Over the years, multiple in vitro models have been employed as the basis of existing as well as emerging advancements in chronic respiratory disease research. These include cell lines, gene expression techniques, single cell RNA sequencing, cytometry, culture techniques, as well as serum/sputum biomarkers that can be used to elucidate the molecular mechanisms underlying these diseases, and to identify novel diagnostic and management options for these diseases. This review summarizes the current understanding of the pathogenesis of various chronic respiratory diseases derived through in vitro experimental models, where the knowledge obtained from these studies can greatly benefit researchers in the discovery and development of novel screening techniques and advanced therapeutic strategies that could be translated into clinical use in the future.},
author = {Tan, Ching Leng and Chan, Yinghan and Candasamy, Mayuren and Chellian, Jestin and Madheswaran, Thiagarajan and Sakthivel, Lakshmana Prabu and Patel, Vyoma K and Chakraborty, Amlan and MacLoughlin, Ronan and Kumar, Deepak and Verma, Nitin and Malyla, Vamshikrishna and Gupta, Piyush Kumar and Jha, Niraj Kumar and Thangavelu, Lakshmi and Devkota, Hari Prasad and Bhatt, Shvetank and Prasher, Parteek and Gupta, Gaurav and Gulati, Monica and Singh, Sachin Kumar and Paudel, Keshav Raj and Hansbro, Philip M and Oliver, Brian G and Dua, Kamal and Chellappan, Dinesh Kumar},
doi = {https://doi.org/10.1016/j.ejphar.2022.174821},
issn = {0014-2999},
journal = {European Journal of Pharmacology},
keywords = {Asthma,COPD,Chronic respiratory diseases,Cystic fibrosis,Lung cancer,models},
pages = {174821},
title = {{Unravelling the molecular mechanisms underlying chronic respiratory diseases for the development of novel therapeutics via in vitro experimental models}},
url = {https://www.sciencedirect.com/science/article/pii/S0014299922000826},
volume = {919},
year = {2022}
}
@misc{JulieSteenhuysen2022,
author = {{Julie Steenhuysen}, Deena Beasley},
title = {{New COVID model predicts over 1 million deaths in China}},
url = {https://www.reuters.com/world/china/new-covid-model-predicts-over-1-mln-deaths-china-through-2023-2022-12-17/},
year = {2022}
}
@article{Bhosale2023a,
abstract = {Background and Objective In the current COVID-19 outbreak, efficient testing of COVID-19 individuals has proven vital to limiting and arresting the disease's accelerated spread globally. It has been observed that the severity and mortality ratio of COVID-19 affected patients is at greater risk because of chronic pulmonary diseases. This study looks at radiographic examinations exploiting chest X-ray images (CXI), which have become one of the utmost feasible assessment approaches for pulmonary disorders, including COVID-19. Deep Learning(DL) remains an excellent image classification method and framework; research has been conducted to predict pulmonary diseases with COVID-19 instances by developing DL classifiers with nine class CXI. However, a few claim to have strong prediction results; because of noisy and small data, their recommended DL strategies may suffer from significant deviation and generality failures. Methods Therefore, a unique CNN model(PulDi-COVID) for detecting nine diseases (atelectasis, bacterial-pneumonia, cardiomegaly, covid19, effusion, infiltration, no-finding, pneumothorax, viral-Pneumonia) using CXI has been proposed using the SSE algorithm. Several transfer-learning models: VGG16, ResNet50, VGG19, DenseNet201, MobileNetV2, NASNetMobile, ResNet152V2, DenseNet169 are trained on CXI of chronic lung diseases and COVID-19 instances. Given that the proposed thirteen SSE ensemble models solved DL's constraints by making predictions with different classifiers rather than a single, we present PulDi-COVID, an ensemble DL model that combines DL with ensemble learning. The PulDi-COVID framework is created by incorporating various snapshots of DLmodels, which have spearheaded chronic lung diseases with COVID-19 cases identification process with a deep neural network produced CXI by applying a suggested SSE method.That is familiar with the idea of various DL perceptions on different classes. Results PulDi-COVID findings were compared to thirteen existing studies for nine-class classification using COVID-19. Test results reveal that PulDi-COVID offers impressive outcomes for chronic diseases with COVID-19 identification with a 99.70{\%} accuracy, 98.68{\%} precision, 98.67{\%} recall, 98.67{\%} F1 score, lowest 12 CXIs zero-one loss, 99.24{\%} AUC-ROC score, and lowest 1.33{\%} error rate. Overall test results are superior to the existing Convolutional Neural Network(CNN). To thebest of our knowledge, the observed results for nine-class classification are significantly superior to the state-of-the-art approaches employed for COVID-19 detection. Furthermore, the CXIthat we usedto assess our algorithm is one of the larger datasets for COVID detection with pulmonary diseases. Conclusion The empirical findings of our suggested approach PulDi-COVIDshow that it outperforms previously developed methods. The suggested SSE method with PulDi-COVID can effectively fulfill the COVID-19 speedy detection needs with different lung diseases for physicians to minimize patient severity and mortality.},
author = {Bhosale, Yogesh H and Patnaik, K Sridhar},
doi = {https://doi.org/10.1016/j.bspc.2022.104445},
issn = {1746-8094},
journal = {Biomedical Signal Processing and Control},
keywords = {Biomedical engineering,COVID-19,Chronic Obstructive Pulmonary Diseases (COPD),Convolution neural networks (CNN),Diagnosis {\&} Classification,Ensemble deep learning,Medical Imaging,Transfer learning},
pages = {104445},
title = {{PulDi-COVID: Chronic obstructive pulmonary (lung) diseases with COVID-19 classification using ensemble deep convolutional neural network from chest X-ray images to minimize severity and mortality rates}},
url = {https://www.sciencedirect.com/science/article/pii/S1746809422008990},
volume = {81},
year = {2023}
}
@article{Tang2020a,
abstract = {As one of the most ubiquitous diagnostic imaging tests in medical practice, chest radiography requires timely reporting of potential findings and diagnosis of diseases in the images. Automated, fast, and reliable detection of diseases based on chest radiography is a critical step in radiology workflow. In this work, we developed and evaluated various deep convolutional neural networks (CNN) for differentiating between normal and abnormal frontal chest radiographs, in order to help alert radiologists and clinicians of potential abnormal findings as a means of work list triaging and reporting prioritization. A CNN-based model achieved an AUC of 0.9824 ± 0.0043 (with an accuracy of 94.64 ± 0.45{\%}, a sensitivity of 96.50 ± 0.36{\%} and a specificity of 92.86 ± 0.48{\%}) for normal versus abnormal chest radiograph classification. The CNN model obtained an AUC of 0.9804 ± 0.0032 (with an accuracy of 94.71 ± 0.32{\%}, a sensitivity of 92.20 ± 0.34{\%} and a specificity of 96.34 ± 0.31{\%}) for normal versus lung opacity classification. Classification performance on the external dataset showed that the CNN model is likely to be highly generalizable, with an AUC of 0.9444 ± 0.0029. The CNN model pre-trained on cohorts of adult patients and fine-tuned on pediatric patients achieved an AUC of 0.9851 ± 0.0046 for normal versus pneumonia classification. Pretraining with natural images demonstrates benefit for a moderate-sized training image set of about 8500 images. The remarkable performance in diagnostic accuracy observed in this study shows that deep CNNs can accurately and effectively differentiate normal and abnormal chest radiographs, thereby providing potential benefits to radiology workflow and patient care.},
author = {Tang, Yu-Xing and Tang, You-Bao and Peng, Yifan and Yan, Ke and Bagheri, Mohammadhadi and Redd, Bernadette A and Brandon, Catherine J and Lu, Zhiyong and Han, Mei and Xiao, Jing and Summers, Ronald M},
doi = {10.1038/s41746-020-0273-z},
issn = {2398-6352},
journal = {npj Digital Medicine},
number = {1},
pages = {70},
title = {{Automated abnormality classification of chest radiographs using deep convolutional neural networks}},
url = {https://doi.org/10.1038/s41746-020-0273-z},
volume = {3},
year = {2020}
}
@misc{WHO2021,
author = {WHO},
title = {{Tracking SARS-CoV-2 variants}},
url = {https://www.who.int/activities/tracking-SARS-CoV-2-variants},
year = {2021}
}
@article{Kim2005a,
abstract = {The purpose of this study was to develop an automated scheme to facilitate detection of localized ground-glass opacity (GGO) in the lung at computed tomography (CT). Institutional review board approval and informed consent were not required. Two radiologists reviewed CT images from 14 patients (five men, nine women) who had lung cancer or metastasis and whose malignancy was classified as GGO. The lung region was sampled and completely covered with contiguous, 50{\%} overlapping regions of interest (ROIs) measuring 30 ? 30 pixels in size. The lung area within each ROI was analyzed to compute texture features and gaussian curve fitting features. Performance of the artificial neural networks (ANNs) measured by using the area under the receiver operating characteristic curve was 0.92. With a threshold of 0.9, the sensitivity of the ANN for detecting GGO ROIs was 94.3{\%} (280 of 297 ROIs), and the positive predictive value was 29.1{\%} (280 of 963 ROIs). A computerized scheme may hold promise in facilitating detection of localized GGO at CT. ? RSNA, 2005},
annote = {doi: 10.1148/radiol.2372041461},
author = {Kim, Kwang Gi and Goo, Jin Mo and Kim, Jong Hyo and Lee, Hyun Ju and Min, Byung Goo and Bae, Kyongtae T and Im, Jung-Gi},
doi = {10.1148/radiol.2372041461},
issn = {0033-8419},
journal = {Radiology},
month = {nov},
number = {2},
pages = {657--661},
publisher = {Radiological Society of North America},
title = {{Computer-aided Diagnosis of Localized Ground-Glass Opacity in the Lung at CT: Initial Experience}},
url = {https://doi.org/10.1148/radiol.2372041461},
volume = {237},
year = {2005}
}
@article{Liu2019,
abstract = {Recently, deep reinforcement learning has achieved great success by integrating deep learning models into reinforcement learning algorithms in various applications such as computer games and robots. Specially, it is promising for computer-aided diagnosis and treatment to combine deep reinforcement learning with medical big data generated and collected from medical Internet of Things. In this paper, we focus on the potential of the deep reinforcement learning for lung cancer detection as many people are suffering from the lung tumor and about 1.8 million patients died from lung cancer in 2018. Early detection and diagnosis of lung tumor can significantly improve the treatment effect and prolong survival. In this work, we present several representative deep reinforcement learning models that are potential to use for lung cancer detection. Furthermore, we summarize the common types of lung cancer and the main characteristics of each type. Finally, we point out the open challenges and possible future research directions of applying deep reinforcement learning to lung cancer detection, which is expected to promote the evolution of smart medicine with medical Internet of Things.},
author = {Liu, Zhuo and Yao, Chenhui and Yu, Hang and Wu, Taihua},
doi = {https://doi.org/10.1016/j.future.2019.02.068},
issn = {0167-739X},
journal = {Future Generation Computer Systems},
keywords = {Deep reinforcement learning,Lung cancer,Medical Internet of Things,Smart medicine},
pages = {1--9},
title = {{Deep reinforcement learning with its application for lung cancer detection in medical Internet of Things}},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19303772},
volume = {97},
year = {2019}
}
@article{Zaman2010,
author = {Zaman, K.},
doi = {10.3329/jhpn.v28i2.4879},
file = {:C$\backslash$:/Users/iradspm/Downloads/3891.pdf:pdf},
issn = {16060997},
journal = {Journal of Health, Population and Nutrition},
number = {2},
pages = {111--113},
pmid = {20411672},
title = {{Tuberculosis: A global health problem}},
volume = {28},
year = {2010}
}
@article{Rahman2020a,
author = {Rahman, T and Khandakar, A and Kadir, M A and Islam, K R and Islam, K F and Mazhar, R and Hamid, T and Islam, M T and Kashem, S and Mahbub, Z B and Ayari, M A and Chowdhury, M E H},
doi = {10.1109/ACCESS.2020.3031384},
issn = {2169-3536 VO  - 8},
journal = {IEEE Access},
pages = {191586--191601},
title = {{Reliable Tuberculosis Detection Using Chest X-Ray With Deep Learning, Segmentation and Visualization}},
volume = {8},
year = {2020}
}
@article{Zhang2022,
abstract = {In the past decade, the application of machine learning (ML) to healthcare has helped drive the automation of physician tasks as well as enhancements in clinical capabilities and access to care. This progress has emphasized that, from model development to model deployment, data play central roles. In this Review, we provide a data-centric view of the innovations and challenges that are defining ML for healthcare. We discuss deep generative models and federated learning as strategies to augment datasets for improved model performance, as well as the use of the more recent transformer models for handling larger datasets and enhancing the modelling of clinical text. We also discuss data-focused problems in the deployment of ML, emphasizing the need to efficiently deliver data to ML models for timely clinical predictions and to account for natural data shifts that can deteriorate model performance.},
author = {Zhang, Angela and Xing, Lei and Zou, James and Wu, Joseph C.},
doi = {10.1038/s41551-022-00898-y},
file = {:C$\backslash$:/Users/iradspm/Downloads/s41551-022-00898-y.pdf:pdf},
issn = {2157846X},
journal = {Nature Biomedical Engineering},
pmid = {35788685},
publisher = {Springer US},
title = {{Shifting machine learning for healthcare from development to deployment and from models to data}},
year = {2022}
}
@article{Park2022,
abstract = {The coronavirus disease 2019 (COVID-19) pandemic has transitioned to a third phase and many variants have been originated. There has been millions of lives loss as well as billions in economic loss. The morbidity and mortality for COVID-19 varies by country. There were different preventive approaches and public restrictions policies have been applied to control the COVID-19 impacts and usually measured by Stringency Index. This study aimed to explore the COVID-19 trend, public restriction policies and vaccination status with economic ranking of countries.},
author = {Park, Myung-Bae and Ranabhat, Chhabi Lal},
doi = {10.1186/s13690-022-00936-w},
issn = {2049-3258},
journal = {Archives of Public Health},
number = {1},
pages = {197},
title = {{COVID-19 trends, public restrictions policies and vaccination status by economic ranking of countries: a longitudinal study from 110 countries}},
url = {https://doi.org/10.1186/s13690-022-00936-w},
volume = {80},
year = {2022}
}
@article{Kassania2021a,
abstract = {The newly identified Coronavirus pneumonia, subsequently termed COVID-19, is highly transmittable and pathogenic with no clinically approved antiviral drug or vaccine available for treatment. The most common symptoms of COVID-19 are dry cough, sore throat, and fever. Symptoms can progress to a severe form of pneumonia with critical complications, including septic shock, pulmonary edema, acute respiratory distress syndrome and multi-organ failure. While medical imaging is not currently recommended in Canada for primary diagnosis of COVID-19, computer-aided diagnosis systems could assist in the early detection of COVID-19 abnormalities and help to monitor the progression of the disease, potentially reduce mortality rates. In this study, we compare popular deep learning-based feature extraction frameworks for automatic COVID-19 classification. To obtain the most accurate feature, which is an essential component of learning, MobileNet, DenseNet, Xception, ResNet, InceptionV3, InceptionResNetV2, VGGNet, NASNet were chosen amongst a pool of deep convolutional neural networks. The extracted features were then fed into several machine learning classifiers to classify subjects as either a case of COVID-19 or a control. This approach avoided task-specific data pre-processing methods to support a better generalization ability for unseen data. The performance of the proposed method was validated on a publicly available COVID-19 dataset of chest X-ray and CT images. The DenseNet121 feature extractor with Bagging tree classifier achieved the best performance with 99{\%} classification accuracy. The second-best learner was a hybrid of the a ResNet50 feature extractor trained by LightGBM with an accuracy of 98},
author = {Kassania, Sara Hosseinzadeh and Kassanib, Peyman Hosseinzadeh and Wesolowskic, Michal J and Schneidera, Kevin A and Detersa, Ralph},
doi = {https://doi.org/10.1016/j.bbe.2021.05.013},
issn = {0208-5216},
journal = {Biocybernetics and Biomedical Engineering},
keywords = {Computer-Aided Diagnosis,Coronavirus Disease,Deep Learning,Feature Extraction,Lung Opacity,Transfer Learning},
number = {3},
pages = {867--879},
title = {{Automatic Detection of Coronavirus Disease (COVID-19) in X-ray and CT Images: A Machine Learning Based Approach}},
url = {https://www.sciencedirect.com/science/article/pii/S020852162100067X},
volume = {41},
year = {2021}
}
@article{Siegel2022,
abstract = {Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths in the United States and compiles the most recent data on population-based cancer occurrence and outcomes. Incidence data (through 2018) were collected by the Surveillance, Epidemiology, and End Results program; the National Program of Cancer Registries; and the North American Association of Central Cancer Registries. Mortality data (through 2019) were collected by the National Center for Health Statistics. In 2022, 1,918,030 new cancer cases and 609,360 cancer deaths are projected to occur in the United States, including approximately 350 deaths per day from lung cancer, the leading cause of cancer death. Incidence during 2014 through 2018 continued a slow increase for female breast cancer (by 0.5{\%} annually) and remained stable for prostate cancer, despite a 4{\%} to 6{\%} annual increase for advanced disease since 2011. Consequently, the proportion of prostate cancer diagnosed at a distant stage increased from 3.9{\%} to 8.2{\%} over the past decade. In contrast, lung cancer incidence continued to decline steeply for advanced disease while rates for localized-stage increased suddenly by 4.5{\%} annually, contributing to gains both in the proportion of localized-stage diagnoses (from 17{\%} in 2004 to 28{\%} in 2018) and 3-year relative survival (from 21{\%} to 31{\%}). Mortality patterns reflect incidence trends, with declines accelerating for lung cancer, slowing for breast cancer, and stabilizing for prostate cancer. In summary, progress has stagnated for breast and prostate cancers but strengthened for lung cancer, coinciding with changes in medical practice related to cancer screening and/or treatment. More targeted cancer control interventions and investment in improved early detection and treatment would facilitate reductions in cancer mortality.},
author = {Siegel, Rebecca L. and Miller, Kimberly D. and Fuchs, Hannah E. and Jemal, Ahmedin},
doi = {10.3322/caac.21708},
file = {:C$\backslash$:/Users/iradspm/Downloads/CA A Cancer J Clinicians - 2022 - Siegel - Cancer statistics  2022.pdf:pdf},
issn = {0007-9235},
journal = {CA: A Cancer Journal for Clinicians},
keywords = {cancer cases,cancer statistics,death rates,incidence,mortality},
number = {1},
pages = {7--33},
pmid = {35020204},
title = {{Cancer statistics, 2022}},
volume = {72},
year = {2022}
}
@inproceedings{Khobragade2016a,
author = {Khobragade, S and Tiwari, A and Patil, C Y and Narke, V},
booktitle = {2016 IEEE 1st International Conference on Power Electronics, Intelligent Control and Energy Systems (ICPEICES)},
doi = {10.1109/ICPEICES.2016.7853683},
isbn = {VO  -},
pages = {1--5},
title = {{Automatic detection of major lung diseases using Chest Radiographs and classification by feed-forward artificial neural network}},
year = {2016}
}
@article{Seixas2013a,
abstract = {BACKGROUND: Clinicians in countries with high tuberculosis (TB) prevalence often treat pleural TB based on clinical grounds, as the availability and sensitivity of diagnostic tests are poor. OBJECTIVE: To evaluate the role of artificial neural networks (ANN) as an aid for the non-invasive diagnosis of pleural TB. These tools can be used in simple computer devices (tablets) without remote internet connection. METHODS: The clinical history and human immunodeficiency virus (HIV) status of 137 patients were prospectively entered in a database. Both non-linear ANN and the linear Fisher discriminant were used to calculate performance indexes based on clinical grounds. The same procedure was performed including pleural fluid test results (smear, culture, adenosine deaminase, serology and nucleic acid amplification test). The gold standard was any positive test for TB. RESULTS: In pre-test modelling, the neural model reached {\textgreater}90{\%} accuracy (Fisher discriminant 74.5{\%}). Under pre-test conditions, ANN had better accuracy compared to each test considered separately. CONCLUSIONS: ANN are highly reliable for diagnosing pleural TB based on clinical grounds and HIV status only, and are useful even in remote conditions lacking access to sophisticated medical or computer infrastructure. In other better-equipped scenarios, these tools should be evaluated as substitutes for thoracocentesis and pleural biopsy. {\textcopyright} 2013 The Union.},
author = {Seixas, J. M. and Faria, J. and {Souza Filho}, J. B.O. and Vieira, A. F.M. and Kritski, A. and Trajman, A.},
doi = {10.5588/ijtld.12.0829},
file = {:C$\backslash$:/Users/iradspm/Downloads/s21.pdf:pdf},
issn = {10273719},
journal = {International Journal of Tuberculosis and Lung Disease},
keywords = {Accuracy,Artificial intelligence,Diagnosis,Pleurisy,Tuberculosis},
number = {5},
pages = {682--686},
pmid = {23575336},
title = {{Artificial neural network models to support the diagnosis of pleural tuberculosis in adult patients}},
volume = {17},
year = {2013}
}
@article{Li2022,
abstract = {Melatonin, primarily secreted by the pineal gland, is an anthracemal compound. Its chemical name is N‑acetyl‑5‑methoxytryptamine. Great advances in melatonin‑related research have been made, including the understanding of its roles in the rhythm of the sleep/wake cycle, retardation of aging processes, as well as antioxidant and/or anti‑inflammatory effects. Melatonin exerts a wide range of physiological effects related to the high lipophilicity of melatonin itself. Melatonin has strong radical scavenging activity, which serves an important role in pulmonary disorders. Pulmonary disorders are among the diseases that threaten human health. Especially in developing countries, due to environmental factors such as smoke and dust, the incidences of pulmonary disorders are high. Melatonin has been reported to have great potential to treat patients with pulmonary disorders. The present review discusses the relationship between melatonin and pulmonary disorders, including coronavirus disease‑2019, chronic obstructive pulmonary disease, non‑small cell lung cancer and pulmonary fibrosis.},
address = {Department of Chinese Medicine, Changchun University of Chinese Medicine, Changchun, Jilin 130021, P.R. China Department of Acupuncture and Tuina, Changchun University of Chinese Medicine, Changchun, Jilin 130021, P.R. China Department of Pediatrics, Affi},
author = {Li, Lijie and Gang, Xiaochao and Wang, Jiajia and Gong, Xiaoyan},
doi = {10.3892/etm.2022.11197},
issn = {1792-0981 1792-1015},
journal = {Exp Ther Med},
keywords = {melatonin pulmonary disorders inflammation respira},
number = {4},
pages = {271},
title = {{Role of melatonin in respiratory diseases (Review)}},
url = {https://doi.org/10.3892/etm.2022.11197},
volume = {23},
year = {2022}
}
@article{Panwar2020a,
abstract = {Presently, COVID-19 has posed a serious threat to researchers, scientists, health professionals, and administrations around the globe from its detection to its treatment. The whole world is witnessing a lockdown like situation because of COVID-19 pandemic. Persistent efforts are being made by the researchers to obtain the possible solutions to control this pandemic in their respective areas. One of the most common and effective methods applied by the researchers is the use of CT-Scans and X-rays to analyze the images of lungs for COVID-19. However, it requires several radiology specialists and time to manually inspect each report which is one of the challenging tasks in a pandemic. In this paper, we have proposed a deep learning neural network-based method nCOVnet, an alternative fast screening method that can be used for detecting the COVID-19 by analyzing the X-rays of patients which will look for visual indicators found in the chest radiography imaging of COVID-19 patients.},
author = {Panwar, Harsh and Gupta, P K and Siddiqui, Mohammad Khubeb and Morales-Menendez, Ruben and Singh, Vaishnavi},
doi = {https://doi.org/10.1016/j.chaos.2020.109944},
issn = {0960-0779},
journal = {Chaos, Solitons {\&} Fractals},
keywords = {COVID-19,Convolutional neural network (CNN),Deep learning,Detection,X-Rays,nCOVnet},
pages = {109944},
title = {{Application of deep learning for fast detection of COVID-19 in X-Rays using nCOVnet}},
url = {https://www.sciencedirect.com/science/article/pii/S096007792030343X},
volume = {138},
year = {2020}
}
@article{Singh2022,
abstract = {COVID-19 is an infectious and contagious disease caused by the new coronavirus. The total number of cases is over 19 million and continues to grow. A common symptom noticed among COVID-19 patients is lung infection that results in breathlessness, and the lack of essential resources such as testing, oxygen, and ventilators enhances its severity. Chest X-ray can be used to design and develop a COVID-19 detection mechanism for a quicker diagnosis using AI and machine learning techniques. Due to this silver lining, various new COVID-19 detection techniques and prediction models have been introduced in recent times based on chest radiography images. However, due to a high level of unpredictability and the absence of essential data, standard models have showcased low efficiency and also suffer from overheads and complexities. This paper proposes a model fine tuning transfer learning-coronavirus 19 (Ftl-CoV19) for COVID-19 detection through chest X-rays, which embraces the ideas of transfer learning in pretrained VGG16 model with including combination of convolution, max pooling, and dense layer at different stages of model. Ftl-CoV19 reported promising experimental results; it observed training and validation accuracy of 98.82{\&}{\#}x0025; and 99.27{\&}{\#}x0025; with precision of 100{\&}{\#}x0025;, recall of 98{\&}{\#}x0025;, and F1 score of 99{\&}{\#}x0025;. These results outperformed other conventional state of arts such as CNN, ResNet50, InceptionV3, and Xception.},
author = {Singh, Tarishi and Saurabh, Praneet and Bisen, Dhananjay and Kane, Lalit and Pathak, Mayank and Sinha, G R},
doi = {10.1155/2022/1953992},
editor = {Sharma, Kapil},
issn = {1687-5265},
journal = {Computational Intelligence and Neuroscience},
pages = {1953992},
publisher = {Hindawi},
title = {{Ftl-CoV19: A Transfer Learning Approach to Detect COVID-19}},
url = {https://doi.org/10.1155/2022/1953992},
volume = {2022},
year = {2022}
}
@misc{WorldHealthOrganization2020,
abstract = {Covid-19 can be considered as a pandemic},
author = {{World Health Organization}},
booktitle = {World Health Organization},
number = {March},
title = {{Opening remarks at the media briefing on COVID-19}},
url = {https://www.who.int/dg/speeches/detail/who-director-general-s-opening-remarks-at-the-media-briefing-on-covid-19---16-march-2020},
volume = {11},
year = {2020}
}
@article{WHO2022,
abstract = {All patients with MDR/RR-TB, including those with additional resistance to fluoroquinolones, stand to benefit from effective all-oral treatment regimens, either shorter or longer, implemented under programmatic conditions. • MDR/RR-TB patients with extensive TB disease, severe forms of extrapulmonary TB, those with resistance to fluoroquinolones or who have been exposed to treatment with second-line drugs will benefit from an individualized longer regimen designed using the WHO priority grouping of medicines recommended in 2018. • For MDR/RR-TB patients without previous exposure to second-line treatment (including bedaquiline), without fluoroquinolone resistance and no extensive TB disease or severe extrapulmonary TB, the preferred treatment option is a shorter, all-oral, bedaquiline-containing regimen. In this group of patients, national TB programmes are advised to phase out use of the injectable-containing shorter regimen. • Access to rapid drug susceptibility testing, especially for ruling out fluoroquinolone resistance, is required before starting the shorter, all-oral, bedaquiline-containing MDR-TB regimen. • In settings with a high probability of, or patients with confirmed resistance to other medicines in the regimen, further modifications of the shorter, all-oral, bedaquiline-containing regimen using priority grouping of second-line TB medicines may be implemented. However, the efficacy, safety and tolerability of such modifications to regimens {\textless}12 months are unknown and should therefore be evaluated under operational research conditions. • The BPaL regimen may be used under operational research conditions in patients with XDR-TB who have not had previous exposure to bedaquiline and linezolid (defined as less than two weeks). This regimen may not be considered for programmatic use worldwide until additional evidence on efficacy and safety has been generated. However, in individual patients for whom design of an effective regimen based on existing recommendations is not possible, BPal regimen may be considered as a last resort under prevailing ethical standards. • Decisions on appropriate regimens should be made according to patient preference and clinical judgement, also considering the results of susceptibility testing, patient treatment history and severity and site of the disease. • All treatment should be delivered under WHO-recommended standards, including patient-centered care and support, informed consent where necessary, principles of good clinical practice, active drug safety monitoring and management, and regular patient monitoring to assess regimen effectiveness.},
author = {WHO},
file = {:C$\backslash$:/Users/iradspm/Downloads/WHO-UCN-TB-2022.2-eng.pdf:pdf},
journal = {World Health Organization},
keywords = {Multidrug-Resistant,Rifampin,Tuberculosis,drug therapy,tb,therapeutic use,tuberculosis [subject]},
number = {WHO/UCN/TB/2022.2.},
pages = {6},
title = {{Rapid Communication: Key changes to the treatment of drug-resistant tuberculosis}},
url = {https://apps.who.int/iris/handle/10665/275383{\%}0Ahttp://apps.who.int/bookorders.},
year = {2022}
}
@article{Oguz2022a,
abstract = {Since the patient is not quarantined during the conclusion of the Polymerase Chain Reaction (PCR) test used in the diagnosis of COVID-19, the disease continues to spread. In this study, it was aimed to reduce the duration and amount of transmission of the disease by shortening the diagnosis time of COVID-19 patients with the use of Computed Tomography (CT). In addition, it is aimed to provide a decision support system to radiologists in the diagnosis of COVID-19. In this study, deep features were extracted with deep learning models such as ResNet-50, ResNet-101, AlexNet, Vgg-16, Vgg-19, GoogLeNet, SqueezeNet, Xception on 1345 CT images obtained from the radiography database of Siirt Education and Research Hospital. These deep features are given to classification methods such as Support Vector Machine (SVM), k Nearest Neighbor (kNN), Random Forest (RF), Decision Trees (DT), Naive Bayes (NB), and their performance is evaluated with test images. Accuracy value, F1-score and ROC curve were considered as success criteria. According to the data obtained as a result of the application, the best performance was obtained with ResNet-50 and SVM method. The accuracy was 96.296{\%}, the F1-score was 95.868{\%}, and the AUC value was 0.9821. The deep learning model and classification method examined in this study and found to be high performance can be used as an auxiliary decision support system by preventing unnecessary tests for COVID-19 disease.},
author = {Oğuz, {\c{C}}inare and Yağanoğlu, Mete},
doi = {https://doi.org/10.1016/j.ipm.2022.103025},
issn = {0306-4573},
journal = {Information Processing {\&} Management},
keywords = {COVID-19,Classification,Deep learning,ResNet},
number = {5},
pages = {103025},
title = {{Detection of COVID-19 using deep learning techniques and classification methods}},
url = {https://www.sciencedirect.com/science/article/pii/S0306457322001352},
volume = {59},
year = {2022}
}
@article{Pune2016a,
author = {Pune, Engineering and Pune, V I T},
file = {:C$\backslash$:/Users/iradspm/Downloads/Automatic{\_}detection{\_}of{\_}major{\_}lung{\_}diseases{\_}using{\_}Chest{\_}Radiographs{\_}and{\_}classification{\_}by{\_}feed-forward{\_}artificial{\_}neural{\_}network.pdf:pdf},
isbn = {9781467385879},
keywords = {-art ijici al,feature extraction,lung cancer,pneumonia,radiographs},
pages = {16--20},
title = {{Automatie Deteetion ofMajor Lung Diseases U sing Chest Radiographs and Classifieation by Feed-forward Artifieial Neural Network}},
year = {2016}
}
@article{Lakhani2017a,
abstract = {PurposeTo evaluate the efficacy of deep convolutional neural networks (DCNNs) for detecting tuberculosis (TB) on chest radiographs.Materials and MethodsFour deidentified HIPAA-compliant datasets were used in this study that were exempted from review by the institutional review board, which consisted of 1007 posteroanterior chest radiographs. The datasets were split into training (68.0{\%}), validation (17.1{\%}), and test (14.9{\%}). Two different DCNNs, AlexNet and GoogLeNet, were used to classify the images as having manifestations of pulmonary TB or as healthy. Both untrained and pretrained networks on ImageNet were used, and augmentation with multiple preprocessing techniques. Ensembles were performed on the best-performing algorithms. For cases where the classifiers were in disagreement, an independent board-certified cardiothoracic radiologist blindly interpreted the images to evaluate a potential radiologist-augmented workflow. Receiver operating characteristic curves and areas under the curve (AUCs) were used to assess model performance by using the DeLong method for statistical comparison of receiver operating characteristic curves.ResultsThe best-performing classifier had an AUC of 0.99, which was an ensemble of the AlexNet and GoogLeNet DCNNs. The AUCs of the pretrained models were greater than that of the untrained models (P {\textless} .001). Augmenting the dataset further increased accuracy (P values for AlexNet and GoogLeNet were .03 and .02, respectively). The DCNNs had disagreement in 13 of the 150 test cases, which were blindly reviewed by a cardiothoracic radiologist, who correctly interpreted all 13 cases (100{\%}). This radiologist-augmented approach resulted in a sensitivity of 97.3{\%} and specificity 100{\%}.ConclusionDeep learning with DCNNs can accurately classify TB at chest radiography with an AUC of 0.99. A radiologist-augmented approach for cases where there was disagreement among the classifiers further improved accuracy.? RSNA, 2017},
annote = {doi: 10.1148/radiol.2017162326},
author = {Lakhani, Paras and Sundaram, Baskaran},
doi = {10.1148/radiol.2017162326},
issn = {0033-8419},
journal = {Radiology},
month = {apr},
number = {2},
pages = {574--582},
publisher = {Radiological Society of North America},
title = {{Deep Learning at Chest Radiography: Automated Classification of Pulmonary Tuberculosis by Using Convolutional Neural Networks}},
url = {https://doi.org/10.1148/radiol.2017162326},
volume = {284},
year = {2017}
}
@misc{WHO2022a,
author = {WHO},
title = {{Tuberculosis}},
url = {https://www.who.int/news-room/fact-sheets/detail/tuberculosis},
year = {2022}
}
@article{Almezhghwi2021a,
abstract = {Chest X-ray medical imaging technology allows the diagnosis of many lung diseases. It is known that this technology is frequently used in hospitals, and it is the most accurate way of detecting most thorax diseases. Radiologists examine these images to identify lung diseases; however, this process can require some time. In contrast, an automated artificial intelligence system could help radiologists detect lung diseases more accurately and faster. Therefore, we propose two artificial intelligence approaches for processing and identifying chest X-ray images to detect chest diseases from such images. We introduce two novel deep learning methods for fast and automated classification of chest X-ray images. First, we propose the use of support vector machines based on the AlexNet model. Second, we develop support vector machines based on the VGGNet16 method. Combined deep networks with a robust classifier have shown that the proposed methods outperform AlexNet and VGG16 deep learning approaches for the chest X-ray image classification tasks. The proposed AlexNet and VGGNet based SVM provide average area under the curve values of 98{\%} and 97{\%}, respectively, for twelve chest X-ray diseases.},
author = {Almezhghwi, Khaled and Serte, Sertan and Al-Turjman, Fadi},
doi = {10.1007/s11042-021-10907-y},
issn = {1573-7721},
journal = {Multimedia Tools and Applications},
number = {19},
pages = {29051--29065},
title = {{Convolutional neural networks for the classification of chest X-rays in the IoT era}},
url = {https://doi.org/10.1007/s11042-021-10907-y},
volume = {80},
year = {2021}
}
@misc{WHO,
author = {WHO},
title = {{Pneumonia in Children}},
url = {https://www.who.int/news-room/fact-sheets/detail/pneumonia{\#}:{~}:text=Pneumonia is a form of,painful and limits oxygen intake.}
}
@article{Hussain2021a,
abstract = {Background and Objective The Coronavirus 2019, or shortly COVID-19, is a viral disease that causes serious pneumonia and impacts our different body parts from mild to severe depending on patient's immune system. This infection was first reported in Wuhan city of China in December 2019, and afterward, it became a global pandemic spreading rapidly around the world. As the virus spreads through human to human contact, it has affected our lives in a devastating way, including the vigorous pressure on the public health system, the world economy, education sector, workplaces, and shopping malls. Preventing viral spreading requires early detection of positive cases and to treat infected patients as quickly as possible. The need for COVID-19 testing kits has increased, and many of the developing countries in the world are facing a shortage of testing kits as new cases are increasing day by day. In this situation, the recent research using radiology imaging (such as X-ray and CT scan) techniques can be proven helpful to detect COVID-19 as X-ray and CT scan images provide important information about the disease caused by COVID-19 virus. The latest data mining and machine learning techniques such as Convolutional Neural Network (CNN) can be applied along with X-ray and CT scan images of the lungs for the accurate and rapid detection of the disease, assisting in mitigating the problem of scarcity of testing kits. Methods Hence a novel CNN model called CoroDet for automatic detection of COVID-19 by using raw chest X-ray and CT scan images have been proposed in this study. CoroDet is developed to serve as an accurate diagnostics for 2 class classification (COVID and Normal), 3 class classification (COVID, Normal, and non-COVID pneumonia), and 4 class classification (COVID, Normal, non-COVID viral pneumonia, and non-COVID bacterial pneumonia). Results The performance of our proposed model was compared with ten existing techniques for COVID detection in terms of accuracy. A classification accuracy of 99.1{\%} for 2 class classification, 94.2{\%} for 3 class classification, and 91.2{\%} for 4 class classification was produced by our proposed model, which is obviously better than the state-of-the-art-methods used for COVID-19 detection to the best of our knowledge. Moreover, the dataset with x-ray images that we prepared for the evaluation of our method is the largest datasets for COVID detection as far as our knowledge goes. Conclusion The experimental results of our proposed method CoroDet indicate the superiority of CoroDet over the existing state-of-the-art-methods. CoroDet may assist clinicians in making appropriate decisions for COVID-19 detection and may also mitigate the problem of scarcity of testing kits.},
author = {Hussain, Emtiaz and Hasan, Mahmudul and Rahman, Md Anisur and Lee, Ickjai and Tamanna, Tasmi and Parvez, Mohammad Zavid},
doi = {https://doi.org/10.1016/j.chaos.2020.110495},
issn = {0960-0779},
journal = {Chaos, Solitons {\&} Fractals},
keywords = {Accuracy,COVID-19,Confusion matrix,Convolutional neural network,Deep learning,Pneumonia-bacterial,Pneumonia-viral,X-ray},
pages = {110495},
title = {{CoroDet: A deep learning based classification for COVID-19 detection using chest X-ray images}},
url = {https://www.sciencedirect.com/science/article/pii/S0960077920308870},
volume = {142},
year = {2021}
}
@article{MITRA2021153649,
abstract = {Background
Indole alkaloids are very promising for potential therapeutic purposes and appear to be particularly effective against respiratory diseases. Several experimental studies have been performed, both in vivo and in vitro, to evaluate the effectiveness of indole alkaloids for the management of respiratory disorders, including asthma, emphysema, tuberculosis, cancer, and pulmonary fibrosis.
Purpose
The fundamental objective of this review was to summarize the in-depth therapeutic potential of indole alkaloids against various respiratory disorders.
Study design
In addition to describing the therapeutic potential, this review also evaluates the toxicity of these alkaloids, which have been utilized for therapeutic benefits but have demonstrated toxic consequences. Some indole alkaloids, including scholaricine, 19-epischolaricine, vallesamine, and picrinine, which are derived from the plant Alstonia scholaris, have shown toxic effects in non-rodent models.
Methods
This review also discusses clinical studies exploring the therapeutic efficacy of indole alkaloids, which have confirmed the promising benefits observed in vivo and in vitro.
Results
The indole alkaloidal compounds have shown efficacy in subjects with respiratory diseases.
Conclusion
The available data established both preclinical and clinical studies confirm the potential of indole alkaloids to treat the respiratory disorders.},
author = {Mitra, Saikat and Prova, Shajuthi Rahman and Sultana, Sifat Ara and Das, Rajib and Nainu, Firzan and Emran, Talha Bin and Tareq, Abu Montakim and Uddin, Md. Sahab and Alqahtani, Ali M and Dhama, Kuldeep and Simal-Gandara, Jesus},
doi = {https://doi.org/10.1016/j.phymed.2021.153649},
issn = {0944-7113},
journal = {Phytomedicine},
keywords = {Asthma,Indole alkaloids,Lung cancer,Pulmonary fibrosis,Respiratory diseases},
pages = {153649},
title = {{Therapeutic potential of indole alkaloids in respiratory diseases: A comprehensive review}},
url = {https://www.sciencedirect.com/science/article/pii/S0944711321001926},
volume = {90},
year = {2021}
}
@article{s18051530,
abstract = {Recent research has shown that the ubiquitous use of cameras and voice monitoring equipment in a home environment can raise privacy concerns and affect human mental health. This can be a major obstacle to the deployment of smart home systems for elderly or disabled care. This study uses a social robot to detect embarrassing situations. Firstly, we designed an improved neural network structure based on the You Only Look Once (YOLO) model to obtain feature information. By focusing on reducing area redundancy and computation time, we proposed a bounding-box merging algorithm based on region proposal networks (B-RPN), to merge the areas that have similar features and determine the borders of the bounding box. Thereafter, we designed a feature extraction algorithm based on our improved YOLO and B-RPN, called F-YOLO, for our training datasets, and then proposed a real-time object detection algorithm based on F-YOLO (RODA-FY). We implemented RODA-FY and compared models on our MAT social robot. Secondly, we considered six types of situations in smart homes, and developed training and validation datasets, containing 2580 and 360 images, respectively. Meanwhile, we designed three types of experiments with four types of test datasets composed of 960 sample images. Thirdly, we analyzed how a different number of training iterations affects our prediction estimation, and then we explored the relationship between recognition accuracy and learning rates. Our results show that our proposed privacy detection system can recognize designed situations in the smart home with an acceptable recognition accuracy of 94.48{\%}. Finally, we compared the results among RODA-FY, Inception V3, and YOLO, which indicate that our proposed RODA-FY outperforms the other comparison models in recognition accuracy.},
author = {Yang, Guanci and Yang, Jing and Sheng, Weihua and Junior, Francisco Erivaldo Fernandes and Li, Shaobo},
doi = {10.3390/s18051530},
issn = {1424-8220},
journal = {Sensors},
number = {5},
title = {{Convolutional Neural Network-Based Embarrassing Situation Detection under Camera for Social Robot in Smart Homes}},
url = {https://www.mdpi.com/1424-8220/18/5/1530},
volume = {18},
year = {2018}
}
@inproceedings{9451726,
author = {G, Sreena V and Ponraj, Narain and L, Deepa P},
booktitle = {2021 3rd International Conference on Signal Processing and Communication (ICPSC)},
doi = {10.1109/ICSPC51351.2021.9451726},
pages = {54--58},
title = {{Study on Public Chest X-ray Data sets for Lung Disease Classification}},
year = {2021}
}
@inproceedings{9718847,
author = {Li, Yinglong},
booktitle = {2022 IEEE 2nd International Conference on Power, Electronics and Computer Applications (ICPECA)},
doi = {10.1109/ICPECA53709.2022.9718847},
pages = {994--999},
title = {{Research and Application of Deep Learning in Image Recognition}},
year = {2022}
}
@article{9841572,
author = {Mehrrotraa, Rajat and Ansari, M A and Agrawal, Rajeev and Tripathi, Pragati and {Bin Heyat}, Md Belal and Al-Sarem, Mohammed and Muaad, Abdullah Yahya Mohammed and Nagmeldin, Wamda Abdelrahman Elhag and Abdelmaboud, Abdelzahir and Saeed, Faisal},
doi = {10.1109/ACCESS.2022.3194152},
journal = {IEEE Access},
pages = {85442--85458},
title = {{Ensembling of Efficient Deep Convolutional Networks and Machine Learning Algorithms for Resource Effective Detection of Tuberculosis Using Thoracic (Chest) Radiography}},
volume = {10},
year = {2022}
}
@article{KIZNYGORDON2021S40,
abstract = {The World Health Organization (WHO) estimates that around 10 million people develop tuberculosis (TB) every year, with 1.5 million deaths attributed to TB in 2019 (World Health Organization, 2020). The majority of the disease burden occurs in low-income countries, where access to diagnostics and tailored treatment remains problematic. The current COVID-19 pandemic further threatens to impact global TB control by diverting resources, reducing notifications and hence significantly increasing deaths attributable to TB (World Health Organization, 2020). Whole genome sequencing (WGS) is becoming increasingly accessible, and has particular value in the diagnosis and management of TB disease (Cabibbe et al., 2018; Meehan et al., 2019). Not only does it have the potential to give more rapid and complete information on drug-resistance, but the high discriminatory power it offers allows detection of clusters and transmission pathways, as well as likely contamination events, mixed infections and to differentiate between re-infection and relapse with much greater confidence than previous typing methods.},
annote = {Commemorating World Tuberculosis Day March 24th, 2021: “The Clock is Ticking”},
author = {{Kizny Gordon}, Alice and Marais, Ben and Walker, Timothy M and Sintchenko, Vitali},
doi = {https://doi.org/10.1016/j.ijid.2021.02.114},
issn = {1201-9712},
journal = {International Journal of Infectious Diseases},
keywords = {Multidrug-resistance,Whole genome sequencing},
pages = {S40--S42},
title = {{Clinical and public health utility of Mycobacterium tuberculosis whole genome sequencing}},
url = {https://www.sciencedirect.com/science/article/pii/S1201971221002009},
volume = {113},
year = {2021}
}
@article{ALSHMRANI2022,
abstract = {In 2019, the world experienced the rapid outbreak of the Covid-19 pandemic creating an alarming situation worldwide. The virus targets the respiratory system causing pneumonia with other symptoms such as fatigue, dry cough, and fever which can be mistakenly diagnosed as pneumonia, lung cancer, or TB. Thus, the early diagnosis of COVID-19 is critical since the disease can provoke patients' mortality. Chest X-ray (CXR) is commonly employed in healthcare sector where both quick and precise diagnosis can be supplied. Deep learning algorithms have proved extraordinary capabilities in terms of lung diseases detection and classification. They facilitate and expedite the diagnosis process and save time for the medical practitioners. In this paper, a deep learning (DL) architecture for multi-class classification of Pneumonia, Lung Cancer, tuberculosis (TB), Lung Opacity, and most recently COVID-19 is proposed. Tremendous CXR images of 3615 COVID-19, 6012 Lung opacity, 5870 Pneumonia, 20,000 lung cancer, 1400 tuberculosis, and 10,192 normal images were resized, normalized, and randomly split to fit the DL requirements. In terms of classification, we utilized a pre-trained model, VGG19 followed by three blocks of convolutional neural network (CNN) as a feature extraction and fully connected network at the classification stage. The experimental results revealed that our proposed VGG19 + CNN outperformed other existing work with 96.48 {\%} accuracy, 93.75 {\%} recall, 97.56 {\%} precision, 95.62 {\%} F1 score, and 99.82 {\%} area under the curve (AUC). The proposed model delivered superior performance allowing healthcare practitioners to diagnose and treat patients more quickly and efficiently.},
author = {Alshmrani, Goram Mufarah M and Ni, Qiang and Jiang, Richard and Pervaiz, Haris and Elshennawy, Nada M},
doi = {https://doi.org/10.1016/j.aej.2022.10.053},
issn = {1110-0168},
journal = {Alexandria Engineering Journal},
keywords = {COVID-19,Deep learning,Lung cancer,Lung opacity,Multiclass diseases classification,Pneumonia,TB,VGG19 +CNN,X-ray images},
title = {{A deep learning architecture for multi-class lung diseases classification using chest X-ray (CXR) images}},
url = {https://www.sciencedirect.com/science/article/pii/S1110016822007104},
year = {2022}
}


@article{Pune2016a,
author = {Pune, Engineering and Pune, V I T},
file = {:C$\backslash$:/Users/iradspm/Downloads/Automatic{\_}detection{\_}of{\_}major{\_}lung{\_}diseases{\_}using{\_}Chest{\_}Radiographs{\_}and{\_}classification{\_}by{\_}feed-forward{\_}artificial{\_}neural{\_}network.pdf:pdf},
isbn = {9781467385879},
keywords = {-art ijici al,feature extraction,lung cancer,pneumonia,radiographs},
pages = {16--20},
title = {{Automatie Deteetion ofMajor Lung Diseases U sing Chest Radiographs and Classifieation by Feed-forward Artifieial Neural Network}},
year = {2016}
}
@article{SAIKOUSHIK2021109153,
title = {Detection of respiratory diseases from chest X rays using Nesterov accelerated adaptive moment estimation},
journal = {Measurement},
volume = {176},
pages = {109153},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2021.109153},
url = {https://www.sciencedirect.com/science/article/pii/S0263224121001779},
author = {S.S. {Sai Koushik} and K.G. Srinivasa},
keywords = {Augmentation, Confusion Matrix, Convolutions, Deep Learning, Neural Networks, Transfer Learning},
abstract = {Recent developments in the field of machine learning have led to drastic improvements in medical diagnosis. Identification of different medical conditions with high accuracy is possible through machine learning, specifically deep learning. Convolutional Neural Networks are a subset of deep neural networks, used in investigating visual images. In this study, a method to identify bacterial pneumonia, viral pneumonia and COVID-19 from chest X-rays is proposed using convolutional neural networks. Training accuracy of 0.9440 and validation accuracy of 0.9356 was obtained using this model. The test accuracy was found to be 0.8753. As a matter of fact, COVID-19 diagnosing precision and recall of the proposed method are 0.95 and 1.00 respectively. Significant improvements are seen when compared to other approaches.}
}
@article{sittig2012electronic,
  title={Electronic health records and national patient-safety goals},
  author={Sittig, Dean F and Singh, Hardeep},
  journal={The New England journal of medicine},
  volume={367},
  number={19},
  pages={1854},
  year={2012},
  publisher={NIH Public Access}
}
@article{bowman2013impact,
  title={Impact of electronic health record systems on information integrity: quality and safety implications},
  author={Bowman, Sue},
  journal={Perspectives in health information management},
  volume={10},
  number={Fall},
  year={2013},
  publisher={American Health Information Management Association}
}
@article{jiang2017artificial,
  title={Artificial intelligence in healthcare: past, present and future},
  author={Jiang, Fei and Jiang, Yong and Zhi, Hui and Dong, Yi and Li, Hao and Ma, Sufeng and Wang, Yilong and Dong, Qiang and Shen, Haipeng and Wang, Yongjun},
  journal={Stroke and vascular neurology},
  volume={2},
  number={4},
  year={2017},
  publisher={BMJ Specialist Journals}
}
@article{wurm2008telemedicine,
  title={Telemedicine and teledermatology: past, present and future},
  author={Wurm, Elisabeth MT and Hofmann-Wellenhof, Rainer and Wurm, Robert and Soyer, Hans Peter},
  journal={JDDG: Journal Der Deutschen Dermatologischen Gesellschaft},
  volume={6},
  number={2},
  pages={106--112},
  year={2008},
  publisher={Wiley Online Library}
}
@inproceedings{zhou2017fine,
  title={Fine-tuning convolutional neural networks for biomedical image analysis: actively and incrementally},
  author={Zhou, Zongwei and Shin, Jae and Zhang, Lei and Gurudu, Suryakanth and Gotway, Michael and Liang, Jianming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7340--7351},
  year={2017}
}
@ARTICLE{9134370,
  author={Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing},
  journal={Proceedings of the IEEE}, 
  title={A Comprehensive Survey on Transfer Learning}, 
  year={2021},
  volume={109},
  number={1},
  pages={43-76},
  doi={10.1109/JPROC.2020.3004555}}

  @article{perez2017effectiveness,
  title={The effectiveness of data augmentation in image classification using deep learning},
  author={Perez, Luis and Wang, Jason},
  journal={arXiv preprint arXiv:1712.04621},
  year={2017}
}
@inproceedings{long2015learning,
  title={Learning transferable features with deep adaptation networks},
  author={Long, Mingsheng and Cao, Yue and Wang, Jianmin and Jordan, Michael},
  booktitle={International conference on machine learning},
  pages={97--105},
  year={2015},
  organization={PMLR}
}
@article{shin2016deep,
  title={Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning},
  author={Shin, Hoo-Chang and Roth, Holger R and Gao, Mingchen and Lu, Le and Xu, Ziyue and Nogues, Isabella and Yao, Jianhua and Mollura, Daniel and Summers, Ronald M},
  journal={IEEE transactions on medical imaging},
  volume={35},
  number={5},
  pages={1285--1298},
  year={2016},
  publisher={IEEE}
}
@article{krizhevsky2017imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Communications of the ACM},
  volume={60},
  number={6},
  pages={84--90},
  year={2017},
  publisher={AcM New York, NY, USA}
}

@book{goodfellow2016deep,
title={Deep Learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
year={2016},
publisher={MIT Press}
}

@article{lecun2015deep,
title={Deep learning},
author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
journal={Nature},
volume={521},
number={7553},
pages={436--444},
year={2015},
publisher={Nature Publishing Group}
}

@article{schmidhuber2015deep,
title={Deep learning in neural networks: An overview},
author={Schmidhuber, J{"u}rgen},
journal={Neural Networks},
volume={61},
pages={85--117},
year={2015},
publisher={Elsevier}
}

@article{simonyan2015very,
title={Very deep convolutional networks for large-scale image recognition},
author={Simonyan, Karen and Zisserman, Andrew},
journal={arXiv preprint arXiv:1409.1556},
year={2015}
}

@book{graves2012supervised,
title={Supervised Sequence Labelling with Recurrent Neural Networks},
author={Graves, Alex},
year={2012},
publisher={Springer}
}
@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{simonyan2015very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2015}
}

@inproceedings{szegedy2017inception,
  title={Inception-v4, inception-resnet and the impact of residual connections on learning},
  author={Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alex},
  booktitle={AAAI},
  pages={4278--4284},
  year={2017}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@inproceedings{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}
@article{pan2010survey,
  title={A survey on transfer learning},
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={22},
  number={10},
  pages={1345--1359},
  year={2010},
  publisher={IEEE}
}
@article{goddard1984computed,
title={Computed tomography in pulmonary emphysema},
author={Goddard, P. R. and Nicholson, E. M. and Laszlo, G. and Watt, I. and Hutchinson, T. A.},
journal={Clinical radiology},
volume={35},
number={4},
pages={317--325},
year={1984},
}

@article{henschke2002ct,
title={CT screening for lung cancer: past and ongoing studies},
author={Henschke, C. I. and Yankelevitz, D. F. and Mirtcheva, R.},
journal={Lung cancer},
volume={38},
pages={S23--S26},
year={2002},
}

@article{ohno2014magnetic,
title={Magnetic resonance imaging of the lung: recent advances},
author={Ohno, Y. and Koyama, H. and Onishi, Y.},
journal={Magnetic resonance imaging clinics of North America},
volume={22},
number={2},
pages={255--273},
year={2014},
}

@article{kalemkerian2018molecular,
title={Molecular diagnostics for lung cancer: Adenocarcinoma, squamous cell carcinoma, and malignant pleural mesothelioma},
author={Kalemkerian, G. P. and Ettinger, D. S. and Mason, D. P.},
journal={Clinical lung cancer},
volume={19},
number={5},
pages={336--344},
year={2018},
}
@article{abbas2020chest,
  title={Chest X-ray in COVID-19: a key parameter?},
  author={Abbas, Abdullah and Abdalwahab, Ahmad and Al-Maslamani, Mohammed},
  journal={Future virology},
  volume={15},
  number={10},
  pages={623--630},
  year={2020},
  publisher={Future Medicine Ltd}
}

@article{ozturk2020automated,
  title={Automated detection of COVID-19 cases using deep neural networks with X-ray images},
  author={Ozturk, Tulin and Talo, Muhammed and Yildirim, Omer Akgun and Baloglu, Ulas Bilgen and Yildirim, Ozal and Acharya, U Rajendra},
  journal={Computers in Biology and Medicine},
  volume={121},
  pages={103792},
  year={2020},
  publisher={Elsevier}
}

@article{pan2020chest,
  title={Chest imaging appearance of COVID-19 infection},
  author={Pan, Yuxin and Guan, Huashi and Zhou, Shuchang and Wang, Yuting and Li, Qian and Zhu, Tengfei and Hu, Qian and Xia, Liming},
  journal={Radiology: Cardiothoracic Imaging},
  volume={2},
  number={1},
  pages={e200028},
  year={2020},
  publisher={Radiological Society of North America}
}

@article{salgame2020imaging,
  title={Imaging in tuberculosis},
  author={Salgame, Padmini and Geadas, Catherine},
  journal={Cold Spring Harbor perspectives in medicine},
  volume={10},
  number={6},
  pages={a038944},
  year={2020},
  publisher={Cold Spring Harbor Laboratory Press}
}

@article{wong2020chest,
  title={Chest radiographic patterns and differential diagnoses of lung opacity},
  author={Wong, Kenneth TC and Antonio, Grace E},
  journal={Radiologic clinics},
  volume={58},
  number={3},
  pages={461--480},
  year={2020},
  publisher={Elsevier}
}
@article{wang2020covid,
  title={COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images},
  author={Wang, Linda and Wong, Alexander},
  journal={IEEE Transactions on Medical Imaging},
  volume={39},
  number={8},
  pages={2515--2525},
  year={2020},
  publisher={IEEE}
}

@article{ghassemi2020using,
  title={Using transfer learning to improve mammogram breast cancer risk prediction},
  author={Ghassemi, Mohammad and Greiner, Russell and Jin, Panayiotis and Aucoin, Nicole and Patel, Vatsal and Sahiner, Berkman and Erickson, Bradley J},
  journal={IEEE Journal of Biomedical and Health Informatics},
  volume={24},
  number={7},
  pages={2065--2074},
  year={2020},
  publisher={IEEE}
}

@article{tajbakhsh2016convolutional,
  title={Convolutional neural networks for medical image analysis: full training or fine tuning?},
  author={Tajbakhsh, Nima and Shin, Jae Y and Gurudu, Suryakanth R and Hurst, R Todd and Kendall, William L and Gotway, Michael B and Liang, Jianming},
  journal={IEEE transactions on medical imaging},
  volume={35},
  number={5},
  pages={1299--1312},
  year={2016},
  publisher={IEEE}
}

@article{li2020artificial,
  title={Artificial intelligence distinguishes COVID-19 from community acquired pneumonia on chest CT},
  author={Li, Lin and Qin, Lixin and Xu, Zeguo and Yin, Youbing and Wang, Xin and Kong, Bin and Bai, Jie and Lu, Yubing and Fang, Zhenghan and Song, Qiuyu and others},
  journal={Radiology},
  volume={296},
  number={2},
  pages={E65--E71},
  year={2020},
  publisher={Radiological Society of North America}
}

@article{vaid2020automated,
  title={Automated detection of COVID-19 cases using deep neural networks with X-ray images},
  author={Vaid, Shashank and Somaiya, Neeraj and Sharma, Dhruv and Bhandari, Manik},
  journal={Biocybernetics and Biomedical Engineering},
  volume={40},
  number={4},
  pages={1391--1405},
  year={2020},
  publisher={Elsevier}
}

@article{wang2021chest,
  title={Chest radiography-based deep learning model for detecting COVID-19},
  author={Wang, Zhaohua and Chen, Zhenguo and Hu, Junjie and Zhang, Zhihui and Zhong, Lilin and Wang, Xiangdong and Zhao, Yu},
  journal={Diagn Interv Radiol},
  volume={27},
  number={3},
  pages={298--305},
  year={2021},
  publisher={Turkish Society of Radiology}
}
@article{minaee2020deep,
  title={Deep-COVID: Predicting COVID-19 From Chest X-Ray Images Using Deep Transfer Learning},
  author={Minaee, Shervin and Kafieh, Rahele and Sonka, Milan and Yazdani, Saeed and Soufi, Gholamreza},
  journal={arXiv preprint arXiv:2004.09363},
  year={2020}
}
@article{apostolopoulos2020covid,
  title={COVID-19: A comparative study of deep learning approaches for detection and diagnosis},
  author={Apostolopoulos, Ioannis D and Aznaouridis, Stamatios I and Tzani, Maria A},
  journal={medRxiv},
  year={2020},
  publisher={Cold Spring Harbor Laboratory Press}
}
@article{chowdhury2020can,
  title={Can AI help in screening viral and COVID-19 pneumonia?},
  author={Chowdhury, Mohammad Emtiyaz Khan and Rahman, Tasnim and Khandakar, Amith Kumar and Mazhar, Riad and Kadir, Muhammad Abdul},
  journal={IEEE Access},
  volume={8},
  pages={132665--132676},
  year={2020},
  publisher={IEEE}
}
@article{zhang2021automated,
  title={Automated detection of COVID-19 from chest X-ray using transfer learning with convolutional neural networks},
  author={Zhang, Jianxing and Xie, Yong and Li, Yuchen and Shen, Chen and Xia, Yang and Guo, Xiaohui and Wang, Li and Liang, Weimin},
  journal={Journal of X-Ray Science and Technology},
  volume={29},
  number={3},
  pages={405--417},
  year={2021},
  publisher={IOS Press}
}

@inproceedings{simonyan2015very,
title={Very deep convolutional networks for large-scale image recognition},
author={Simonyan, Karen and Zisserman, Andrew},
booktitle={Proceedings of the international conference on learning representations},
year={2015}
}

@inproceedings{he2016deep,
title={Deep residual learning for image recognition},
author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
pages={770--778},
year={2016}
}

@inproceedings{huang2017densely,
title={Densely connected convolutional networks},
author={Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q.},
booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
pages={4700--4708},
year={2017}
}

@inproceedings{szegedy2016rethinking,
title={Rethinking the inception architecture for computer vision},
author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
pages={2818--2826},
year={2016}
}
@article{ardila2019end,
title={End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography},
author={Ardila, Daniel and Kiraly, Adam P and Bharadwaj, Shravya and Choi, Brian and Reicher, Jacob J and Peng, Lily and Tse, Daniel and Etemadi, Mozziyar and Ye, Wenlu and Corrado, Greg S and others},
journal={Nature Medicine},
volume={25},
number={6},
pages={954--961},
year={2019},
publisher={Nature Publishing Group}
}

@article{liu2019deep,
title={Deep learning model for diagnosis of pulmonary embolism on computed tomography pulmonary angiography},
author={Liu, Yi and Wang, Heng and Li, Lei and Tian, Zhiqiang and Gu, Jian and Chen, Lin},
journal={Radiology},
volume={290},
number={1},
pages={520--528},
year={2019},
publisher={Radiological Society of North America}
}

@article{wang2020tailored,
title={COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images},
author={Wang, Linda and Wong, Alexander},
journal={IEEE Transactions on Medical Imaging},
volume={39},
number={8},
pages={2515--2525},
year={2020},
publisher={IEEE}
}

@article{gong2019predicting,
title={Predicting lung function using convolutional neural networks from CT images},
author={Gong, Lequan and Zhang, Jing and Yang, Guanyu and Chen, Lin and Shi, Jianping and Zheng, Gang},
journal={Scientific Reports},
volume={9},
number={1},
pages={14440},
year={2019},
publisher={Nature Publishing Group}
}
@article{wang2020densenet,
  title={DenseNet-based classification models for COVID-19 detection using chest X-ray images},
  author={Wang, Linda and Lin, Zhong Qiu and Wong, Alexander},
  journal={PeerJ Computer Science},
  volume={6},
  number={1},
  pages={e523},
  year={2020},
  doi={10.7717/peerj-cs.523}
}
@INPROCEEDINGS{4633969,
  author={Haibo He and Yang Bai and Garcia, Edwardo A. and Shutao Li},
  booktitle={2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)}, 
  title={ADASYN: Adaptive synthetic sampling approach for imbalanced learning}, 
  year={2008},
  volume={},
  number={},
  pages={1322-1328},
  doi={10.1109/IJCNN.2008.4633969}}
@article{blagus2013smote,
  title={SMOTE for high-dimensional class-imbalanced data},
  author={Blagus, Rok and Lusa, Lara},
  journal={BMC bioinformatics},
  volume={14},
  pages={1--16},
  year={2013},
  publisher={Springer}
}
@INPROCEEDINGS{9451726,
  author={G, Sreena V and Ponraj, Narain and L, Deepa P},
  booktitle={2021 3rd International Conference on Signal Processing and Communication (ICPSC)}, 
  title={Study on Public Chest X-ray Data sets for Lung Disease Classification}, 
  year={2021},
  volume={},
  number={},
  pages={54-58},
  doi={10.1109/ICSPC51351.2021.9451726}}

  @article{Tan2022,
author = {Tan, Ching Leng and Chan, Yinghan and Candasamy, Mayuren and Chellian, Jestin and Madheswaran, Thiagarajan and Sakthivel, Lakshmana Prabu and Patel, Vyoma K and Chakraborty, Amlan and MacLoughlin, Ronan and Kumar, Deepak and Verma, Nitin and Malyla, Vamshikrishna and Gupta, Piyush Kumar and Jha, Niraj Kumar and Thangavelu, Lakshmi and Devkota, Hari Prasad and Bhatt, Shvetank and Prasher, Parteek and Gupta, Gaurav and Gulati, Monica and Singh, Sachin Kumar and Paudel, Keshav Raj and Hansbro, Philip M and Oliver, Brian G and Dua, Kamal and Chellappan, Dinesh Kumar},
doi = {https://doi.org/10.1016/j.ejphar.2022.174821},
issn = {0014-2999},
journal = {European Journal of Pharmacology},
keywords = {Asthma,COPD,Chronic respiratory diseases,Cystic fibrosis,Lung cancer,models},
pages = {174821},
title = {{Unravelling the molecular mechanisms underlying chronic respiratory diseases for the development of novel therapeutics via in vitro experimental models}},
url = {https://www.sciencedirect.com/science/article/pii/S0014299922000826},
volume = {919},
year = {2022}
}

@article{Li2022,
author = {Li, Lijie and Gang, Xiaochao and Wang, Jiajia and Gong, Xiaoyan},
doi = {10.3892/etm.2022.11197},
issn = {1792-0981 1792-1015},
journal = {Exp Ther Med},
keywords = {melatonin pulmonary disorders inflammation respira},
number = {4},
pages = {271},
title = {{Role of melatonin in respiratory diseases (Review)}},
url = {https://doi.org/10.3892/etm.2022.11197},
volume = {23},
year = {2022}
}
@article{Liu_2022,
doi = {10.1088/2516-1091/ac2eae},
url = {https://dx.doi.org/10.1088/2516-1091/ac2eae},
year = {2021},
month = {oct},
publisher = {IOP Publishing},
volume = {4},
number = {1},
pages = {012001},
author = {Yuxuan Liu and Darpan Shukla and Holly Newman and Yong Zhu},
title = {Soft wearable sensors for monitoring symptoms of COVID-19 and other respiratory diseases: a review},
journal = {Progress in Biomedical Engineering}
}
@article{Bala2021,
abstract = {There is increasing interest in understanding the role of air pollution as one of the greatest threats to human health worldwide. Nine of 10 individuals breathe air with polluted compounds that have a great impact on lung tissue. The nature of the relationship is complex, and new or updated data are constantly being reported in the literature. The goal of our review was to summarize the most important air pollutants and their impact on the main respiratory diseases (chronic obstructive pulmonary disease, asthma, lung cancer, idiopathic pulmonary fibrosis, respiratory infections, bronchiectasis, tuberculosis) to reduce both short- and the long-term exposure consequences. We considered the most important air pollutants, including sulfur dioxide, nitrogen dioxide, carbon monoxide, volatile organic compounds, ozone, particulate matter and biomass smoke, and observed their impact on pulmonary pathologies. We focused on respiratory pathologies, because air pollution potentiates the increase in respiratory diseases, and the evidence that air pollutants have a detrimental effect is growing. It is imperative to constantly improve policy initiatives on air quality in both high- and low-income countries.},
author = {Bălă, Gabriel-Petrică and R{\^{a}}jnoveanu, Ruxandra-Mioara and Tudorache, Emanuela and Motișan, Radu and Oancea, Cristian},
doi = {10.1007/s11356-021-13208-x},
issn = {1614-7499},
journal = {Environmental Science and Pollution Research},
number = {16},
pages = {19615--19628},
title = {{Air pollution exposure—the (in)visible risk factor for respiratory diseases}},
url = {https://doi.org/10.1007/s11356-021-13208-x},
volume = {28},
year = {2021}
}

@article{Zhou2020,
abstract = {Background: Since December, 2019, Wuhan, China, has experienced an outbreak of coronavirus disease 2019 (COVID-19), caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Epidemiological and clinical characteristics of patients with COVID-19 have been reported but risk factors for mortality and a detailed clinical course of illness, including viral shedding, have not been well described. Methods: In this retrospective, multicentre cohort study, we included all adult inpatients (≥18 years old) with laboratory-confirmed COVID-19 from Jinyintan Hospital and Wuhan Pulmonary Hospital (Wuhan, China) who had been discharged or had died by Jan 31, 2020. Demographic, clinical, treatment, and laboratory data, including serial samples for viral RNA detection, were extracted from electronic medical records and compared between survivors and non-survivors. We used univariable and multivariable logistic regression methods to explore the risk factors associated with in-hospital death. Findings: 191 patients (135 from Jinyintan Hospital and 56 from Wuhan Pulmonary Hospital) were included in this study, of whom 137 were discharged and 54 died in hospital. 91 (48{\%}) patients had a comorbidity, with hypertension being the most common (58 [30{\%}] patients), followed by diabetes (36 [19{\%}] patients) and coronary heart disease (15 [8{\%}] patients). Multivariable regression showed increasing odds of in-hospital death associated with older age (odds ratio 1{\textperiodcentered}10, 95{\%} CI 1{\textperiodcentered}03–1{\textperiodcentered}17, per year increase; p=0{\textperiodcentered}0043), higher Sequential Organ Failure Assessment (SOFA) score (5{\textperiodcentered}65, 2{\textperiodcentered}61–12{\textperiodcentered}23; p{\textless}0{\textperiodcentered}0001), and d-dimer greater than 1 $\mu$g/mL (18{\textperiodcentered}42, 2{\textperiodcentered}64–128{\textperiodcentered}55; p=0{\textperiodcentered}0033) on admission. Median duration of viral shedding was 20{\textperiodcentered}0 days (IQR 17{\textperiodcentered}0–24{\textperiodcentered}0) in survivors, but SARS-CoV-2 was detectable until death in non-survivors. The longest observed duration of viral shedding in survivors was 37 days. Interpretation: The potential risk factors of older age, high SOFA score, and d-dimer greater than 1 $\mu$g/mL could help clinicians to identify patients with poor prognosis at an early stage. Prolonged viral shedding provides the rationale for a strategy of isolation of infected patients and optimal antiviral interventions in the future. Funding: Chinese Academy of Medical Sciences Innovation Fund for Medical Sciences; National Science Grant for Distinguished Young Scholars; National Key Research and Development Program of China; The Beijing Science and Technology Project; and Major Projects of National Science and Technology on New Drug Creation and Development.},
doi = {10.1016/S0140-6736(20)30566-3},
issn = {1474547X},
journal = {The Lancet},
number = {10229},
pages = {1054--1062},
pmid = {32171076},
publisher = {Elsevier Ltd},
title = {{Clinical course and risk factors for mortality of adult inpatients with COVID-19 in Wuhan, China: a retrospective cohort study}},
url = {http://dx.doi.org/10.1016/S0140-6736(20)30566-3},
volume = {395},
year = {2020}
}
@misc{WHO_covid19_dashboard,
  author = {{World Health Organization}},
  title = {Coronavirus (COVID-19) Dashboard},
  howpublished = {\url{https://covid19.who.int/}},
  note = {Accessed on March 8, 2023}
}
@misc{CDC_TB_bacterial_infection,
  author = {{Centers for Disease Control and Prevention}},
  title = {Tuberculosis (TB)},
  howpublished = {\url{https://www.cdc.gov/tb/topic/basics/default.htm}},
  note = {Accessed on March 8, 2023}
}
@book{WHO_TB_report_2021,
  author = {{World Health Organization}},
  title = {Global Tuberculosis Report 2021},
  year = {2021},
  publisher = {WHO},
  url = {https://www.who.int/publications/i/item/9789240037021},
  note = {Accessed on March 8, 2023}
}
@misc{ALA_pneumonia,
  author = {{American Lung Association}},
  title = {Pneumonia},
  howpublished = {\url{https://www.lung.org/lung-health-diseases/lung-disease-lookup/pneumonia/learn-about-pneumonia}},
  note = {Accessed on March 8, 2023}
}
@misc{CDC_viral_pneumonia,
  author = {{Centers for Disease Control and Prevention}},
  title = {Pneumonia},
  howpublished = {\url{https://www.cdc.gov/pneumonia/viralpneumonia.html}},
  note = {Accessed on March 8, 2023}
}
@article{Nicolini_2021,
  author = {Nicolini, Antonello and Ferrara, Giovanni and Napoli, Nicola and Sgueglia, Guido A.},
  title = {Bacterial Pneumonia},
  journal = {StatPearls},
  year = {2021},
  note = {Accessed on March 8, 2023},
  url = {https://www.ncbi.nlm.nih.gov/books/NBK537293/}
}
@misc{ATS_fungal_pneumonia,
  author = {{American Thoracic Society}},
  title = {Fungal Pneumonia},
  howpublished = {\url{https://www.thoracic.org/patients/patient-resources/resources/fungal-pneumonia.pdf}},
  note = {Accessed on March 8, 2023}
}
@misc{WHO_pneumonia,
  author = {{World Health Organization}},
  title = {Pneumonia},
  howpublished = {\url{https://www.who.int/news-room/fact-sheets/detail/pneumonia}},
  note = {Accessed on March 8, 2023}
}
@misc{WHO_lung_cancer_tuberculosis,
  author = {{World Health Organization}},
  title = {Cancer},
  howpublished = {\url{https://www.who.int/health-topics/cancer#tab=tab_1}} and {\url{https://www.who.int/health-topics/tuberculosis#tab=tab_1}},
  note = {Accessed on March 8, 2023}
}
@misc{ACS_lung_cancer_US,
  author = {{American Cancer Society}},
  title = {Key Statistics for Lung Cancer},
  howpublished = {\url{https://www.cancer.org/cancer/lung-cancer/about/key-statistics.html}},
  note = {Accessed on March 8, 2023}
}
@article{lee2014differential,
  title={Differential diagnoses of acute ground-glass opacity in chest computed tomography: pictorial essay},
  author={Lee, Sang Min and Park, Chang Min and Goo, Jin Mo and Lee, Hyun Ju},
  journal={Korean journal of radiology},
  volume={15},
  number={6},
  pages={734--744},
  year={2014},
  publisher={Korean Society of Radiology}
}
@article{ohannessian2020global,
title={Global Telemedicine Implementation and Integration Within Health Systems to Fight the COVID-19 Pandemic: A Call to Action},
author={Ohannessian, Raffi and Duong, Tram Anh and Odone, Anna},
journal={JMIR Public Health and Surveillance},
volume={6},
number={2},
pages={e18810},
year={2020},
publisher={JMIR Publications Inc.},
doi={10.2196/18810}
}
@article{kanne2020chest,
title={Chest CT Findings in 2019 Novel Coronavirus (2019-nCoV) Infections from Wuhan, China: Key Points for the Radiologist},
author={Kanne, Jeffrey P},
journal={Radiology},
volume={295},
number={1},
pages={16--17},
year={2020},
publisher={Radiological Society of North America},
doi={10.1148/radiol.2020200241}
}
@article{jiang2017artificial,
  title={Artificial intelligence in healthcare: past, present and future},
  author={Jiang, Fei and Jiang, Yong and Zhi, Hui and Dong, Yi and Li, Hao and Ma, Sufeng and Wang, Yilong and Dong, Qiang and Shen, Haipeng and Wang, Yongjun},
  journal={Stroke and vascular neurology},
  volume={2},
  number={4},
  year={2017},
  publisher={BMJ Specialist Journals}
}
@article{wurm2008telemedicine,
  title={Telemedicine and teledermatology: past, present and future},
  author={Wurm, Elisabeth MT and Hofmann-Wellenhof, Rainer and Wurm, Robert and Soyer, Hans Peter},
  journal={JDDG: Journal Der Deutschen Dermatologischen Gesellschaft},
  volume={6},
  number={2},
  pages={106--112},
  year={2008},
  publisher={Wiley Online Library}
}
@article{ratnatunga2020rise,
  title={The rise of non-tuberculosis mycobacterial lung disease},
  author={Ratnatunga, Champa N and Lutzky, Viviana P and Kupz, Andreas and Doolan, Denise L and Reid, David W and Field, Matthew and Bell, Scott C and Thomson, Rachel M and Miles, John J},
  journal={Frontiers in immunology},
  volume={11},
  pages={303},
  year={2020},
  publisher={Frontiers}
}
@article{benzaquen2019lung,
  title={Lung cancer screening, towards a multidimensional approach: why and how?},
  author={Benzaquen, Jonathan and Boutros, Jacques and Marquette, Charles and Delingette, Herv{\'e} and Hofman, Paul},
  journal={Cancers},
  volume={11},
  number={2},
  pages={212},
  year={2019},
  publisher={MDPI}
}
@article{wang2023diffuse,
  title={Diffuse cystic lung disease caused by tuberculosis infection: case series},
  author={Wang, Lu and Liu, Jingwei and Yang, Huahong and Peng, Liping},
  journal={Journal of Infection and Public Health},
  year={2023},
  publisher={Elsevier}
}
@article{El-Fiky2021,
author = {El-Fiky, Azza and Shouman, Marwa Ahmed and Hamada, Salwa and El-Sayed, Ayman and Karar, Mohamed Esmail},
doi = {10.1109/ICEEM52022.2021.9480622},
isbn = {9781665418423},
journal = {ICEEM 2021 - 2nd IEEE International Conference on Electronic Engineering},
keywords = {Classification,Computer-aided diagnosis,Thorax diseases,Transfer learning,X-ray},
publisher = {IEEE},
title = {{Multi-label transfer learning for identifying lung diseases using chest X-rays}},
year = {2021}
}
@article{Li2020,
author = {Li, Matthew D. and Arun, Nishanth Thumbavanam and Gidwani, Mishka and Chang, Ken and Deng, Francis and Little, Brent P. and Mendoza, Dexter P. and Lang, Min and Lee, Susanna I. and O'Shea, Aileen and Parakh, Anushri and Singh, Praveer and Kalpathy-Cramer, Jayashree},
doi = {10.1148/ryai.2020200079},
issn = {26386100},
journal = {Radiology: Artificial Intelligence},
number = {4},
pages = {1--39},
pmid = {33928256},
title = {{Automated assessment and tracking of COVID-19 pulmonary disease severity on chest radiographs using convolutional siamese neural networks}},
volume = {2},
year = {2020}
}
@article{qin2018computer,
  title={Computer-aided detection in chest radiography based on artificial intelligence: a survey},
  author={Qin, Cheng and Yao, Dengfeng and Shi, Yong and Song, Zhijian},
  journal={Biomedical engineering online},
  volume={17},
  number={1},
  pages={113},
  year={2018},
  publisher={Springer},
  doi={10.1186/s12938-018-0544-y}
}
@article{gao2018computer,
  title={Computer vision in healthcare applications},
  author={Gao, Junfeng and Yang, Yong and Lin, Pan and Park, Dong Sun},
  journal={Journal of healthcare engineering},
  volume={2018},
  year={2018},
  pages={1--12},
  publisher={Hindawi},
  doi={10.1155/2018/5154792}
}
@article{Asif2022,
author = {Asif, Sohaib and Zhao, Ming and Tang, Fengxiao and Zhu, Yusen},
doi = {10.1007/s00530-022-00917-7},
isbn = {0123456789},
issn = {14321882},
journal = {Multimedia Systems},
keywords = {COVID-19 detection,Chest X-ray,Convolutional neural network (CNN),Deep learning,Transfer learning},
number = {4},
pages = {1495--1513},
publisher = {Springer Berlin Heidelberg},
title = {{A deep learning-based framework for detecting COVID-19 patients using chest X-rays}},
url = {https://doi.org/10.1007/s00530-022-00917-7},
volume = {28},
year = {2022}
}
@article{Ramteke2012,
author = {Ramteke, R. J. and Y, Khachane Monali},
journal = {International Journal of Advanced Computer Research},
keywords = {Computed Tomography (CT),K –Nearest Neighbour (KNN),Radial Basis Function (RBF).,Support Vector Machine (SVM)},
number = {4},
pages = {190--196},
title = {{Automatic Medical Image Classification and Abnormality Detection Using K- Nearest Neighbour}},
volume = {2},
year = {2012}
}
@ARTICLE{8575127,
  author={Xu, Shuaijing and Wu, Hao and Bie, Rongfang},
  journal={IEEE Access}, 
  title={CXNet-m1: Anomaly Detection on Chest X-Rays With Image-Based Deep Learning}, 
  year={2019},
  volume={7},
  number={},
  pages={4466-4477},
  doi={10.1109/ACCESS.2018.2885997}}
@article{doi:10.1177/2472555218818756,
author = {Alexander Kensert and Philip J. Harrison and Ola Spjuth},
title ={Transfer Learning with Deep Convolutional Neural Networks for Classifying Cellular Morphological Changes},
journal = {SLAS DISCOVERY: Advancing the Science of Drug Discovery},
volume = {24},
number = {4},
pages = {466-475},
year = {2019},
doi = {10.1177/2472555218818756},
    note ={PMID: 30641024},

URL = { 
        https://doi.org/10.1177/2472555218818756
    
},
eprint = { 
        https://doi.org/10.1177/2472555218818756
    
}
}
@article{yang2019deep,
  title={Deep-learning inversion: A next-generation seismic velocity model building methodDL for velocity model building},
  author={Yang, Fangshu and Ma, Jianwei},
  journal={Geophysics},
  volume={84},
  number={4},
  pages={R583--R599},
  year={2019},
  publisher={GeoScienceWorld}
}
@article{Aggarwal2021,
author = {Aggarwal, Ravi and Sounderajah, Viknesh and Martin, Guy and Ting, Daniel S W and Karthikesalingam, Alan and King, Dominic and Ashrafian, Hutan and Darzi, Ara},
doi = {10.1038/s41746-021-00438-z},
issn = {2398-6352},
journal = {npj Digital Medicine},
number = {1},
pages = {65},
title = {{Diagnostic accuracy of deep learning in medical imaging: a systematic review and meta-analysis}},
url = {https://doi.org/10.1038/s41746-021-00438-z},
volume = {4},
year = {2021}
}
@article{Liu2019,
author = {Liu, Zhuo and Yao, Chenhui and Yu, Hang and Wu, Taihua},
doi = {https://doi.org/10.1016/j.future.2019.02.068},
issn = {0167-739X},
journal = {Future Generation Computer Systems},
keywords = {Deep reinforcement learning,Lung cancer,Medical Internet of Things,Smart medicine},
pages = {1--9},
title = {{Deep reinforcement learning with its application for lung cancer detection in medical Internet of Things}},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19303772},
volume = {97},
year = {2019}
}

@incollection{ElAsnaoui2021,
address = {Cham},
author = {{El Asnaoui}, Khalid and Chawki, Youness and Idri, Ali},
doi = {10.1007/978-3-030-74575-2_14},
editor = {Maleh, Yassine and Baddi, Youssef and Alazab, Mamoun and Tawalbeh, Loai and Romdhani, Imed},
isbn = {978-3-030-74575-2},
pages = {257--284},
publisher = {Springer International Publishing},
title = {{Automated Methods for Detection and Classification Pneumonia Based on X-Ray Images Using Deep Learning BT  - Artificial Intelligence and Blockchain for Future Cybersecurity Applications}},
url = {https://doi.org/10.1007/978-3-030-74575-2{\_}14},
year = {2021}
}
@article{misra2020multi,
  title={Multi-channel transfer learning of chest X-ray images for screening of COVID-19},
  author={Misra, Sampa and Jeon, Seungwan and Lee, Seiyon and Managuli, Ravi and Jang, In-Su and Kim, Chulhong},
  journal={Electronics},
  volume={9},
  number={9},
  pages={1388},
  year={2020},
  publisher={MDPI}
}
@article{krishna2019deep,
  title={Deep learning and transfer learning approaches for image classification},
  author={Krishna, Sajja Tulasi and Kalluri, Hemantha Kumar},
  journal={International Journal of Recent Technology and Engineering (IJRTE)},
  volume={7},
  number={5S4},
  pages={427--432},
  year={2019}
}
@article{huang2017transfer,
  title={Transfer learning with deep convolutional neural network for SAR target classification with limited labeled data},
  author={Huang, Zhongling and Pan, Zongxu and Lei, Bin},
  journal={Remote Sensing},
  volume={9},
  number={9},
  pages={907},
  year={2017},
  publisher={MDPI}
}
@incollection{torrey2010transfer,
  title={Transfer learning},
  author={Torrey, Lisa and Shavlik, Jude},
  booktitle={Handbook of research on machine learning applications and trends: algorithms, methods, and techniques},
  pages={242--264},
  year={2010},
  publisher={IGI global}
}
@inproceedings{cirecsan2012transfer,
  title={Transfer learning for Latin and Chinese characters with deep neural networks},
  author={Cire{\c{s}}an, Dan C and Meier, Ueli and Schmidhuber, J{\"u}rgen},
  booktitle={The 2012 international joint conference on neural networks (IJCNN)},
  pages={1--6},
  year={2012},
  organization={IEEE}
}
@article{kunze2017transfer,
  title={Transfer learning for speech recognition on a budget},
  author={Kunze, Julius and Kirsch, Louis and Kurenkov, Ilia and Krug, Andreas and Johannsmeier, Jens and Stober, Sebastian},
  journal={arXiv preprint arXiv:1706.00290},
  year={2017}
}
@ARTICLE{9241777,
  author={Vrbančič, Grega and Podgorelec, Vili},
  journal={IEEE Access}, 
  title={Transfer Learning With Adaptive Fine-Tuning}, 
  year={2020},
  volume={8},
  number={},
  pages={196197-196211},
  doi={10.1109/ACCESS.2020.3034343}}

  @article{BHARATI2020100391,
title = {Hybrid deep learning for detecting lung diseases from X-ray images},
journal = {Informatics in Medicine Unlocked},
volume = {20},
pages = {100391},
year = {2020},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2020.100391},
url = {https://www.sciencedirect.com/science/article/pii/S2352914820300290},
author = {Subrato Bharati and Prajoy Podder and M. Rubaiyat Hossain Mondal},
keywords = {Capsule network, CNN, COVID-19, Vanilla NN, VDSNet, VGG}
}
@article{apostolopoulos2020extracting,
  title={Extracting possibly representative COVID-19 biomarkers from X-ray images with deep learning approach and image data related to pulmonary diseases},
  author={Apostolopoulos, Ioannis D and Aznaouridis, Sokratis I and Tzani, Mpesiana A},
  journal={Journal of Medical and Biological Engineering},
  volume={40},
  pages={462--469},
  year={2020},
  publisher={Springer}
}
@article{asuntha2020deep,
  title={Deep learning for lung Cancer detection and classification},
  author={Asuntha, A and Srinivasan, Andy},
  journal={Multimedia Tools and Applications},
  volume={79},
  pages={7731--7762},
  year={2020},
  publisher={Springer}
}
@inproceedings{kabiraj2022detection,
  title={Detection and Classification of Lung Disease Using Deep Learning Architecture from X-ray Images},
  author={Kabiraj, Anwesh and Meena, Tanushree and Reddy, Pailla Balakrishna and Roy, Sudipta},
  booktitle={Advances in Visual Computing: 17th International Symposium, ISVC 2022, San Diego, CA, USA, October 3--5, 2022, Proceedings, Part I},
  pages={444--455},
  year={2022},
  organization={Springer}
}

@inproceedings{Liu2017a,
author = {Liu, C and Cao, Y and Alcantara, M and Liu, B and Brunette, M and Peinado, J and Curioso, W},
booktitle = {2017 IEEE International Conference on Image Processing (ICIP)},
doi = {10.1109/ICIP.2017.8296695},
isbn = {2381-8549 VO  -},
pages = {2314--2318},
title = {{TX-CNN: Detecting tuberculosis in chest X-ray images using convolutional neural network}},
year = {2017}
}
@article{Liu2021,
abstract = {To date, coronavirus disease 2019 (COVID-19) becomes increasingly fierce due to the emergence of variants. Rapid herd immunity through vaccination is needed to block the mutation and prevent the emergence of variants that can completely escape the immune surveillance. We aimed to systematically evaluate the effectiveness and safety of COVID-19 vaccines in the real world and to establish a reliable evidence-based basis for the actual protective effect of the COVID-19 vaccines, especially in the ensuing waves of infections dominated by variants.},
author = {Liu, Qiao and Qin, Chenyuan and Liu, Min and Liu, Jue},
doi = {10.1186/s40249-021-00915-3},
issn = {2049-9957},
journal = {Infectious Diseases of Poverty},
number = {1},
pages = {132},
title = {{Effectiveness and safety of SARS-CoV-2 vaccine in real-world studies: a systematic review and meta-analysis}},
url = {https://doi.org/10.1186/s40249-021-00915-3},
volume = {10},
year = {2021}
}
@article{Han2022,
abstract = {BackgroundThe interpretation of coronary computed tomography angiography (CCTA) stenosis may be difficult among radiologists of different experience levels. Artificial intelligence (AI) may improve the diagnostic performance.PurposeTo investigate whether the diagnostic performance and time efficiency of radiologists with different levels of experience in interpreting CCTA images could be improved by using CCTA with AI assistance (CCTA-AI).Material and MethodsThis analysis included 200 patients with complete CCTA and invasive coronary angiography (ICA) data, using ICA results as the reference. Eighteen radiologists were divided into three levels based on experience (Levels I, II, and III), and the three levels were divided into groups without (Groups 1, 2, and 3) and with (Groups 4, 5, and 6) AI assistance, totaling six groups (to avoid reader recall bias). The average sensitivity, specificity, NPV, PPV, and AUC were reported for the six groups and CCTA-AI at the patient, vessel, and segment levels. The interpretation time in the groups with and without CCTA-AI was recorded.ResultsCompared to the corresponding group without CCTA-AI, the Level I group with CCTA-AI had improved sensitivity (75.0{\%} vs. 83.0{\%} on patient-based; P?=?0.003). At Level III, the specificity was better with CCTA-AI. The median interpretation times for the groups with and without CCTA-AI were 413 and 615?s, respectively (P?{\textless}?0.001).ConclusionCCTA-AI could assist with and improve the diagnostic performance of radiologists with different experience levels, with Level I radiologists exhibiting improved sensitivity and Level III radiologists exhibiting improved specificity. The use of CCTA-AI could shorten the training time for radiologists.},
annote = {doi: 10.1177/02841851221089263},
author = {Han, Xianjun and He, Yi and Luo, Nan and Zheng, Dandan and Hong, Min and Wang, Zhenchang and Yang, Zhenghan},
doi = {10.1177/02841851221089263},
issn = {0284-1851},
journal = {Acta Radiologica},
month = {apr},
pages = {02841851221089263},
publisher = {SAGE Publications},
title = {{The influence of artificial intelligence assistance on the diagnostic performance of CCTA for coronary stenosis for radiologists with different levels of experience}},
url = {https://doi.org/10.1177/02841851221089263},
year = {2022}
}
@article{Meng2022,
abstract = {The recognition of medical images with deep learning techniques can assist physicians in clinical diagnosis, but the effectiveness of recognition models relies on massive amounts of labeled data. With the rampant development of the novel coronavirus (COVID-19) worldwide, rapid COVID-19 diagnosis has become an effective measure to combat the outbreak. However, labeled COVID-19 data are scarce. Therefore, we propose a two-stage transfer learning recognition model for medical images of COVID-19 (TL-Med) based on the concept of “generic domain-target-related domain-target domain”. First, we use the Vision Transformer (ViT) pretraining model to obtain generic features from massive heterogeneous data and then learn medical features from large-scale homogeneous data. Two-stage transfer learning uses the learned primary features and the underlying information for COVID-19 image recognition to solve the problem by which data insufficiency leads to the inability of the model to learn underlying target dataset information. The experimental results obtained on a COVID-19 dataset using the TL-Med model produce a recognition accuracy of 93.24{\%}, which shows that the proposed method is more effective in detecting COVID-19 images than other approaches and may greatly alleviate the problem of data scarcity in this field.},
author = {Meng, Jiana and Tan, Zhiyong and Yu, Yuhai and Wang, Pengjie and Liu, Shuang},
doi = {https://doi.org/10.1016/j.bbe.2022.04.005},
issn = {0208-5216},
journal = {Biocybernetics and Biomedical Engineering},
keywords = {COVID-19,Pretrained Model,Transfer Learning,ViT},
number = {3},
pages = {842--855},
title = {{TL-med: A Two-stage transfer learning recognition model for medical images of COVID-19}},
url = {https://www.sciencedirect.com/science/article/pii/S0208521622000377},
volume = {42},
year = {2022}
}
@inproceedings{Haritha2020a,
author = {Haritha, D and Pranathi, M K and Reethika, M},
booktitle = {2020 5th International Conference on Computing, Communication and Security (ICCCS)},
doi = {10.1109/ICCCS49678.2020.9277077},
isbn = {VO  -},
pages = {1--5},
title = {{COVID Detection from Chest X-rays with DeepLearning: CheXNet}},
year = {2020}
}
@incollection{ElAsnaoui2021,
abstract = {Recently, researchers, specialists, and companies around the world are rolling out deep learning and image processing-based systems that can fastly process hundreds of X-Ray and Computed Tomography (CT) images to accelerate the diagnosis of pneumonia such as SARS, covid-19, etc., and aid in its containment. Medical image analysis is one of the most promising research areas; it provides facilities for diagnosis and making decisions of several diseases such as MERS, covid-19, etc. In this paper, we present a comparison of recent deep convolutional neural network (CNN) architectures for automatic binary classification of pneumonia images based on fined tuned versions of (VGG16, VGG19, DenseNet201, Inception{\_}ResNet{\_}V2, Inception{\_}V3, Resnet50, MobileNet{\_}V2 and Xception) and a retraining of a baseline CNN. The proposed work has been tested using chest X-Ray {\&} CT dataset, which contains 6087 images (4504 pneumonia and 1583 normal). As a result, we can conclude that the fine-tuned version of Resnet50 shows highly satisfactory performance with rate of increase in training and testing accuracy (more than 96{\%} of accuracy).},
address = {Cham},
author = {{El Asnaoui}, Khalid and Chawki, Youness and Idri, Ali},
doi = {10.1007/978-3-030-74575-2_14},
editor = {Maleh, Yassine and Baddi, Youssef and Alazab, Mamoun and Tawalbeh, Loai and Romdhani, Imed},
isbn = {978-3-030-74575-2},
pages = {257--284},
publisher = {Springer International Publishing},
title = {{Automated Methods for Detection and Classification Pneumonia Based on X-Ray Images Using Deep Learning BT  - Artificial Intelligence and Blockchain for Future Cybersecurity Applications}},
url = {https://doi.org/10.1007/978-3-030-74575-2{\_}14},
year = {2021}
}
@misc{Stokel-Walker2022,
author = {Stokel-Walker, Chris},
booktitle = {Nature},
doi = {10.1038/d41586-022-00620-7},
issn = {14764687},
keywords = {SARS-CoV-2},
number = {7902},
pages = {563},
pmid = {35256787},
title = {{COVID restrictions are lifting - what scientists think}},
url = {https://www.nature.com/articles/d41586-022-00620-7},
volume = {603},
year = {2022}
}
@article{Sharma2022,
abstract = {Chest X-ray (CXR) imaging is one of the most widely used and economical tests to diagnose a wide range of diseases. However, even for expert radiologists, it is a challenge to accurately diagnose diseases from CXR samples. Furthermore, there remains an acute shortage of trained radiologists worldwide. In the present study, a range of machine learning (ML), deep learning (DL), and transfer learning (TL) approaches have been evaluated to classify diseases in an openly available CXR image dataset. A combination of the synthetic minority over-sampling technique (SMOTE) and weighted class balancing is used to alleviate the effects of class imbalance. A hybrid Inception-ResNet-v2 transfer learning model coupled with data augmentation and image enhancement gives the best accuracy. The model is deployed in an edge environment using Amazon IoT Core to automate the task of disease detection in CXR images with three categories, namely pneumonia, COVID-19, and normal. Comparative analysis has been given in various metrics such as precision, recall, accuracy, AUC-ROC score, etc. The proposed technique gives an average accuracy of 98.66{\&}{\#}x0025;. The accuracies of other TL models, namely SqueezeNet, VGG19, ResNet50, and MobileNetV2 are 97.33{\&}{\#}x0025;, 91.66{\&}{\#}x0025;, 90.33{\&}{\#}x0025;, and 76.00{\&}{\#}x0025;, respectively. Further, a DL model, trained from scratch, gives an accuracy of 92.43{\&}{\#}x0025;. Two feature-based ML classification techniques, namely support vector machine with local binary pattern (SVM{\&}{\#}x2009;{\&}{\#}x2b;{\&}{\#}x2009;LBP) and decision tree with histogram of oriented gradients (DT{\&}{\#}x2009;{\&}{\#}x2b;{\&}{\#}x2009;HOG) yield an accuracy of 87.98{\&}{\#}x0025; and 86.87{\&}{\#}x0025;, respectively.},
author = {Sharma, Chandra Mani and Goyal, Lakshay and Chariar, Vijayaraghavan M and Sharma, Navel},
doi = {10.1155/2022/9036457},
editor = {Gupta, Suneet Kumar},
issn = {2040-2295},
journal = {Journal of Healthcare Engineering},
pages = {9036457},
publisher = {Hindawi},
title = {{Lung Disease Classification in CXR Images Using Hybrid Inception-ResNet-v2 Model and Edge Computing}},
url = {https://doi.org/10.1155/2022/9036457},
volume = {2022},
year = {2022}
}
@article{Rajagopal2023a,
abstract = {Lung disease is a most common disease all over the world. A numerous feature extraction with classification models were discussed previously about the lung disease, but those methods having high over fitting problem, consequently, decrease the accuracy of detection. To overwhelm this issue, a Deep Convolutional Spiking Neural Network optimized with Arithmetic Optimization Algorithm is proposed in this manuscript for Lung Disease Detection using Chest X-ray Images as COVID-19, normal and viral pneumonia. Initially, NIH chest X-ray image dataset is taken from Kaggle repository for detecting lung disease. Then, the chest X-ray images are pre-processed using the Anisotropic Diffusion Filter Based Unsharp Masking and crispening scheme for removing noise and enhancing the image quality. These pre-processed outputs are fed to feature extraction. In feature extraction process, the empirical wavelet transform method is used. These extracted features are given into Deep Convolutional Spiking Neural Network classifier (DCSNN) for detecting lung diseases. Here, the weight with bias parameter of DCSNN is enhanced based upon Arithmetic Optimization Algorithm (AOA), which improves detection accuracy. The simulation is executed in MATLAB. The proposed LDC-DCSNN-AOA technique attains higher accuracy, higher Precision, higher F-Score analyzed with the existing techniques, like Lung disease detection using Support Vector Machines optimized with Social Mimic Optimization (LDC-SVM-SMO), Lung disease detection using eXtreme Gradient Boosting optimized by particle swarm optimization (LDC-XGBoost-PSO), Lung disease detection using neuro-fuzzy classifier optimized with multi-objective genetic algorithm (LDC-NFC-MOGA), Lung disease detection using convolutional neural network optimized with Bayesian optimization LDC –CNN-BOA respectively.},
author = {Rajagopal, R and Karthick, R and Meenalochini, P and Kalaichelvi, T},
doi = {https://doi.org/10.1016/j.bspc.2022.104197},
issn = {1746-8094},
journal = {Biomedical Signal Processing and Control},
keywords = {Anisotropic Diffusion Filter Based Unsharp Masking,Arithmetic Optimization Algorithm,Chest X-ray images,Deep Convolutional Spiking Neural Network classifi,Empirical wavelet transform,Lung Disease detection},
pages = {104197},
title = {{Deep Convolutional Spiking Neural Network optimized with Arithmetic optimization algorithm for lung disease detection using chest X-ray images}},
url = {https://www.sciencedirect.com/science/article/pii/S1746809422006516},
volume = {79},
year = {2023}
}
@article{Alazab2020a,
abstract = {Currently, the detection of coronavirus disease 2019 (COVID-19) is one of the main challenges in the world, given the rapid spread of the disease. Recent statistics indicate that the number of people diagnosed with COVID-19 is increasing exponentially, with more than 1.6 million confirmed cases; the disease is spreading to many countries across the world. In this study, we analyse the incidence of COVID-19 distribution across the world. We present an artificial-intelligence technique based on a deep convolutional neural network (CNN) to detect COVID-19 patients using real-world datasets. Our system examines chest X-ray images to identify such patients. Our findings indicate that such an analysis is valuable in COVID-19 diagnosis as X-rays are conveniently available quickly and at low costs. Empirical findings obtained from 1000 X-ray images of real patients confirmed that our proposed system is useful in detecting COVID-19 and achieves an F-measure range of 95-99{\%}. Additionally, three forecasting methods-the prophet algorithm (PA), autoregressive integrated moving average (ARIMA) model, and long short-term memory neural network (LSTM)-were adopted to predict the numbers of COVID-19 confirmations, recoveries, and deaths over the next 7 days. The prediction results exhibit promising performance and offer an average accuracy of 94.80{\%} and 88.43{\%} in Australia and Jordan, respectively. Our proposed system can significantly help identify the most infected cities, and it has revealed that coastal areas are heavily impacted by the COVID-19 spread as the number of cases is significantly higher in those areas than in non-coastal areas.},
author = {Alazab, Moutaz and Awajan, Albara and Mesleh, Abdelwadood and Abraham, Ajith and Jatana, Vansh and Alhyari, Salah},
file = {:C$\backslash$:/Users/iradspm/Downloads/ijcisim{\_}1.pdf:pdf},
issn = {21507988},
journal = {International Journal of Computer Information Systems and Industrial Management Applications},
keywords = {Artificial intelligence,COVID-19,Convolutional neural network,Machine learning,X-ray},
number = {April},
pages = {168--181},
title = {{COVID-19 prediction and detection using deep learning}},
volume = {12},
year = {2020}
}
@article{Matos2021,
abstract = {Ground-glass opacity is a very frequent and unspecified finding in chest computed tomography. Therefore, it admits a wide range of differential diagnoses in the acute context, from viral pneumonias such as influenza virus, coronavirus disease 2019 and cytomegalovirus and even non-infectious lesions, such as vaping, pulmonary infarction, alveolar hemorrhage and pulmonary edema. For this diagnostic differentiation, ground glass must be correlated with other findings in imaging tests, with laboratory tests and with the patients' clinical condition. In the context of a pandemic, it is extremely important to remember the other pathologies with similar findings to coronavirus disease 2019 in the imaging exams.},
author = {de Matos, Marina Justi Rosa and Rosa, Marcela Emer Egypto and Brito, Vanessa Mizubuti and Amaral, Lucas Tadashi Wada and Beraldo, Gabriel Laverdi and Fonseca, Eduardo Kaiser Ururahy Nunes and Chate, Rodrigo Caruso and Passos, Rodrigo Bastos Duarte and Silva, Murilo Marques Almeida and Yokoo, Patr{\'{i}}cia and {Sasdelli Neto}, Roberto and Teles, Gustavo Borges da Silva and da Silva, Marina Carolina Bueno and Szarf, Gilberto},
doi = {10.31744/einstein_journal/2021RW5772},
file = {:C$\backslash$:/Users/iradspm/Downloads/2317{\_}6385{\_}eins{\_}19{\_}eRW5772{\_}pdf.pdf:pdf},
issn = {23176385},
journal = {Einstein (Sao Paulo, Brazil)},
keywords = {amaral lt,article,brito vm,coronavirus infections,covid-19,diagnosis,diagnostic imaging,differential,how to cite this,matos mj,pandemics,rosa me,sars-cov-2,thorax,tomography,x-ray computed},
pages = {eRW5772},
pmid = {33729289},
title = {{Differential diagnoses of acute ground-glass opacity in chest computed tomography: pictorial essay}},
volume = {19},
year = {2021}
}
@article{Wu2020,
abstract = {Importance: Chest radiography is the most common diagnostic imaging examination performed in emergency departments (EDs). Augmenting clinicians with automated preliminary read assistants could help expedite their workflows, improve accuracy, and reduce the cost of care. Objective: To assess the performance of artificial intelligence (AI) algorithms in realistic radiology workflows by performing an objective comparative evaluation of the preliminary reads of anteroposterior (AP) frontal chest radiographs performed by an AI algorithm and radiology residents. Design, Setting, and Participants: This diagnostic study included a set of 72 findings assembled by clinical experts to constitute a full-fledged preliminary read of AP frontal chest radiographs. A novel deep learning architecture was designed for an AI algorithm to estimate the findings per image. The AI algorithm was trained using a multihospital training data set of 342126 frontal chest radiographs captured in ED and urgent care settings. The training data were labeled from their associated reports. Image-based F1 score was chosen to optimize the operating point on the receiver operating characteristics (ROC) curve so as to minimize the number of missed findings and overcalls per image read. The performance of the model was compared with that of 5 radiology residents recruited from multiple institutions in the US in an objective study in which a separate data set of 1998 AP frontal chest radiographs was drawn from a hospital source representative of realistic preliminary reads in inpatient and ED settings. A triple consensus with adjudication process was used to derive the ground truth labels for the study data set. The performance of AI algorithm and radiology residents was assessed by comparing their reads with ground truth findings. All studies were conducted through a web-based clinical study application system. The triple consensus data set was collected between February and October 2018. The comparison study was preformed between January and October 2019. Data were analyzed from October to February 2020. After the first round of reviews, further analysis of the data was performed from March to July 2020. Main Outcomes and Measures: The learning performance of the AI algorithm was judged using the conventional ROC curve and the area under the curve (AUC) during training and field testing on the study data set. For the AI algorithm and radiology residents, the individual finding label performance was measured using the conventional measures of label-based sensitivity, specificity, and positive predictive value (PPV). In addition, the agreement with the ground truth on the assignment of findings to images was measured using the pooled $\kappa$ statistic. The preliminary read performance was recorded for AI algorithm and radiology residents using new measures of mean image-based sensitivity, specificity, and PPV designed for recording the fraction of misses and overcalls on a per image basis. The 1-sided analysis of variance test was used to compare the means of each group (AI algorithm vs radiology residents) using the F distribution, and the null hypothesis was that the groups would have similar means. Results: The trained AI algorithm achieved a mean AUC across labels of 0.807 (weighted mean AUC, 0.841) after training. On the study data set, which had a different prevalence distribution, the mean AUC achieved was 0.772 (weighted mean AUC, 0.865). The interrater agreement with ground truth finding labels for AI algorithm predictions had pooled $\kappa$ value of 0.544, and the pooled $\kappa$ for radiology residents was 0.585. For the preliminary read performance, the analysis of variance test was used to compare the distributions of AI algorithm and radiology residents' mean image-based sensitivity, PPV, and specificity. The mean image-based sensitivity for AI algorithm was 0.716 (95{\%} CI, 0.704-0.729) and for radiology residents was 0.720 (95{\%} CI, 0.709-0.732) (P =.66), while the PPV was 0.730 (95{\%} CI, 0.718-0.742) for the AI algorithm and 0.682 (95{\%} CI, 0.670-0.694) for the radiology residents (P {\textless}.001), and specificity was 0.980 (95{\%} CI, 0.980-0.981) for the AI algorithm and 0.973 (95{\%} CI, 0.971-0.974) for the radiology residents (P {\textless}.001). Conclusions and Relevance: These findings suggest that it is possible to build AI algorithms that reach and exceed the mean level of performance of third-year radiology residents for full-fledged preliminary read of AP frontal chest radiographs. This diagnostic study also found that while the more complex findings would still benefit from expert overreads, the performance of AI algorithms was associated with the amount of data available for training rather than the level of difficulty of interpretation of the finding. Integrating such AI systems in radiology workflows for preliminary interpretations has the potential to expedite existing radiology workflows and address resource scarcity while improving overall accuracy and reducing the cost of care..},
author = {Wu, Joy T. and Wong, Ken C.L. and Gur, Yaniv and Ansari, Nadeem and Karargyris, Alexandros and Sharma, Arjun and Morris, Michael and Saboury, Babak and Ahmad, Hassan and Boyko, Orest and Syed, Ali and Jadhav, Ashutosh and Wang, Hongzhi and Pillai, Anup and Kashyap, Satyananda and Moradi, Mehdi and Syeda-Mahmood, Tanveer},
doi = {10.1001/jamanetworkopen.2020.22779},
file = {:C$\backslash$:/Users/iradspm/Downloads/wu{\_}2020{\_}oi{\_}200758{\_}1601603854.73034.pdf:pdf},
issn = {25743805},
journal = {JAMA Network Open},
number = {10},
pages = {1--14},
pmid = {33034642},
title = {{Comparison of Chest Radiograph Interpretations by Artificial Intelligence Algorithm vs Radiology Residents}},
volume = {3},
year = {2020}
}
@misc{Crider2022,
author = {Crider, Catherine},
title = {{Lung Opacity: What You Should Know}},
url = {https://www.healthline.com/health/lung-opacity},
year = {2022}
}
@article{UshaKiruthika2019a,
abstract = {x-rays are the most commonly performed which are costly diagnostic imaging tests ordered by physicians. Here we are proposing an artificial intelligence system that can reliably separate normal from abnormal would be invaluable in addressing the problem of undiagnosed disease and the lack of radiologists in low-resource settings. The aim of this study is to develop and validate a deep learning system to detect chest x-ray abnormalities and hence detect Tuberculosis (TB) and to provide a tool for Computer Aided Diagnosis (CAD).In this paper by trying to explore existing systems of Image Processing and Deep learning architectures, we are trying to achieve radiologist level detection as well as lower False Negative detection of TB by using ensemble datasets and algorithms. The prototype of a WebApp is created and can be checked on https://parth-patel12.github.io where one can upload the chest x-ray which give probabilities of the chest x-ray to be normal or TB affected.},
author = {{Usha Kiruthika}, S. and {Kanaga Suba Raja}, S. and Balaji, V. and Raman, C. J. and {Durai Arumugam}, S. S.L.},
doi = {10.35940/ijitee.A4834.119119},
file = {:C$\backslash$:/Users/iradspm/Downloads/26DetectionofTuberculosisinChestX-raysusingU-NetArchitecture.pdf:pdf},
issn = {22783075},
journal = {International Journal of Innovative Technology and Exploring Engineering},
keywords = {Artificial neural network,Autism,Computer aided diagnosis,Convolutional neural networks,Generative adversarial network,Tuberculosis},
number = {1},
pages = {2514--2519},
title = {{Detection of tuberculosis in chest X-rays using U-net architecture}},
volume = {9},
year = {2019}
}
@article{Ravi2022a,
abstract = {This paper proposes a multichannel deep learning approach for lung disease detection using chest X-rays. The multichannel models used in this work are EfficientNetB0, EfficientNetB1, and EfficientNetB2 pretrained models. The features from EfficientNet models are fused together. Next, the fused features are passed into more than one non-linear fully connected layer. Finally, the features passed into a stacked ensemble learning classifier for lung disease detection. The stacked ensemble learning classifier contains random forest and SVM in the first stage and logistic regression in the second stage for lung disease detection. The performance of the proposed method is studied in detail for more than one lung disease such as pneumonia, Tuberculosis (TB), and COVID-19. The performances of the proposed method for lung disease detection using chest X-rays compared with similar methods with the aim to show that the method is robust and has the capability to achieve better performances. In all the experiments on lung disease, the proposed method showed better performance and outperformed similar lung disease existing methods. This indicates that the proposed method is robust and generalizable on unseen chest X-rays data samples. To ensure that the features learnt by the proposed method is optimal, t-SNE feature visualization was shown on all three lung disease models. Overall, the proposed method has shown 98{\%} detection accuracy for pediatric pneumonia lung disease, 99{\%} detection accuracy for TB lung disease, and 98{\%} detection accuracy for COVID-19 lung disease. The proposed method can be used as a tool for point-of-care diagnosis by healthcare radiologists.Journal instruction requires a city for affiliations; however, this is missing in affiliation 3. Please verify if the provided city is correct and amend if necessary.correct},
author = {Ravi, Vinayakumar and Acharya, Vasundhara and Alazab, Mamoun},
doi = {10.1007/s10586-022-03664-6},
issn = {1573-7543},
journal = {Cluster Computing},
title = {{A multichannel EfficientNet deep learning-based stacking ensemble approach for lung disease detection using chest X-ray images}},
url = {https://doi.org/10.1007/s10586-022-03664-6},
year = {2022}
}
@inproceedings{Dornadula2021,
author = {Dornadula, B and Geetha, S and Phamila, A V and Priscilla, R and Vijayakumar, K},
booktitle = {2021 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)},
doi = {10.1109/ICSES52305.2021.9633887},
isbn = {VO  -},
pages = {1--6},
title = {{Forecasting the lung diseases from Radiography scans with hybrid Transfer Learning Techniques}},
year = {2021}
}
@article{Yamamoto2021,
abstract = {Background Human microbiotas are communities of microorganisms living in symbiosis with humans. They play an important role in the host immune response to respiratory viral infection. However, evidence on the human microbiome and coronavirus disease (COVID-19) relationship is insufficient. The aim of this systematic literature review was to evaluate existing evidence on the association between the microbiome and COVID-19 in humans and summarize these data in the pandemic era. Methods We conducted a systematic literature review on the association between the microbiome and COVID-19 in humans by searching PubMed, Embase, and the Cochrane Library, CINAHL, and Web of Science databases for articles in English published up to October 31, 2020. The results were analyzed qualitatively. This study is registered with PROSPERO (CRD42020195982). Results Of the 543 articles identified by searching databases, 16 in line with the research objectives were eligible for qualitative review: eight sampled the microbiome using stool, four using nasopharyngeal or throat swab, three using bronchoalveolar lavage fluid, and one using lung tissue. Fecal microbiome dysbiosis and increased opportunistic pathogens were reported in COVID-19 patients. Several studies suggested the dysbiosis in the lung microbiome of COVID-19 patients with an abundance of opportunistic pathogens using lower respiratory tract samples. The association between COVID-19 severity and the human microbiome remains uncertain. Conclusion The human fecal and respiratory tract microbiome changed in COVID-19 patients with opportunistic pathogen abundance. Further research to elucidate the effect of alternation of the human microbiome in disease pathogenesis is warranted.},
author = {Yamamoto, Shinya and Saito, Makoto and Tamura, Azumi and Prawisuda, Diki and Mizutani, Taketoshi and Yotsuyanagi, Hiroshi},
doi = {10.1371/journal.pone.0253293},
file = {:C$\backslash$:/Users/iradspm/Downloads/journal.pone.0253293.pdf:pdf},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS ONE},
number = {6 June},
pages = {1--13},
pmid = {34161373},
title = {{The human microbiome and COVID-19: A systematic review}},
url = {http://dx.doi.org/10.1371/journal.pone.0253293},
volume = {16},
year = {2021}
}
@article{Song2020,
abstract = {Background: The chest CT findings of patients with 2019 Novel Coronavirus (2019-nCoV) pneumonia have not previously been described in detail. Purpose: To investigate the clinical, laboratory, and imaging findings of emerging 2019-nCoV pneumonia in humans. Materials and Methods: Fifty-one patients (25 men and 26 women; age range 16–76 years) with laboratory-confirmed 2019-nCoV infection by using real-time reverse transcription polymerase chain reaction underwent thin-section CT. The imaging findings, clinical data, and laboratory data were evaluated. Results: Fifty of 51 patients (98{\%}) had a history of contact with individuals from the endemic center in Wuhan, China. Fever (49 of 51, 96{\%}) and cough (24 of 51, 47{\%}) were the most common symptoms. Most patients had a normal white blood cell count (37 of 51, 73{\%}), neutrophil count (44 of 51, 86{\%}), and either normal (17 of 51, 35{\%}) or reduced (33 of 51, 65{\%}) lymphocyte count. CT images showed pure ground-glass opacity (GGO) in 39 of 51 (77{\%}) patients and GGO with reticular and/ or interlobular septal thickening in 38 of 51 (75{\%}) patients. GGO with consolidation was present in 30 of 51 (59{\%}) patients, and pure consolidation was present in 28 of 51 (55{\%}) patients. Forty-four of 51 (86{\%}) patients had bilateral lung involvement, while 41 of 51 (80{\%}) involved the posterior part of the lungs and 44 of 51 (86{\%}) were peripheral. There were more consolidated lung lesions in patients 5 days or more from disease onset to CT scan versus 4 days or fewer (431 of 712 lesions vs 129 of 612 lesions; P , .001). Patients older than 50 years had more consolidated lung lesions than did those aged 50 years or younger (212 of 470 vs 198 of 854; P , .001). Follow-up CT in 13 patients showed improvement in seven (54{\%}) patients and progression in four (31{\%}) patients. Conclusion: Patients with fever and/or cough and with conspicuous ground-glass opacity lesions in the peripheral and posterior lungs on CT images, combined with normal or decreased white blood cells and a history of epidemic exposure, are highly suspected of having 2019 Novel Coronavirus (2019-nCoV) pneumonia.},
author = {Song, Fengxiang and Shi, Nannan and Shan, Fei and Zhang, Zhiyong and Shen, Jie and Lu, Hongzhou and Ling, Yun and Jiang, Yebin and Shi, Yuxin},
doi = {10.1148/radiol.2020200274},
file = {:C$\backslash$:/Users/iradspm/Downloads/radiol.2020200274.pdf:pdf},
issn = {15271315},
journal = {Radiology},
number = {1},
pages = {210--217},
pmid = {32027573},
title = {{Emerging 2019 novel coronavirus (2019-NCoV) pneumonia}},
volume = {295},
year = {2020}
}
@inproceedings{Ahsan2019a,
author = {Ahsan, M and Gomes, R and Denton, A},
booktitle = {2019 IEEE International Conference on Electro Information Technology (EIT)},
doi = {10.1109/EIT.2019.8833768},
isbn = {2154-0373 VO  -},
pages = {427--433},
title = {{Application of a Convolutional Neural Network using transfer learning for tuberculosis detection}},
year = {2019}
}
@article{Aggarwal2021,
abstract = {Deep learning (DL) has the potential to transform medical diagnostics. However, the diagnostic accuracy of DL is uncertain. Our aim was to evaluate the diagnostic accuracy of DL algorithms to identify pathology in medical imaging. Searches were conducted in Medline and EMBASE up to January 2020. We identified 11,921 studies, of which 503 were included in the systematic review. Eighty-two studies in ophthalmology, 82 in breast disease and 115 in respiratory disease were included for meta-analysis. Two hundred twenty-four studies in other specialities were included for qualitative review. Peer-reviewed studies that reported on the diagnostic accuracy of DL algorithms to identify pathology using medical imaging were included. Primary outcomes were measures of diagnostic accuracy, study design and reporting standards in the literature. Estimates were pooled using random-effects meta-analysis. In ophthalmology, AUC's ranged between 0.933 and 1 for diagnosing diabetic retinopathy, age-related macular degeneration and glaucoma on retinal fundus photographs and optical coherence tomography. In respiratory imaging, AUC's ranged between 0.864 and 0.937 for diagnosing lung nodules or lung cancer on chest X-ray or CT scan. For breast imaging, AUC's ranged between 0.868 and 0.909 for diagnosing breast cancer on mammogram, ultrasound, MRI and digital breast tomosynthesis. Heterogeneity was high between studies and extensive variation in methodology, terminology and outcome measures was noted. This can lead to an overestimation of the diagnostic accuracy of DL algorithms on medical imaging. There is an immediate need for the development of artificial intelligence-specific EQUATOR guidelines, particularly STARD, in order to provide guidance around key issues in this field.},
author = {Aggarwal, Ravi and Sounderajah, Viknesh and Martin, Guy and Ting, Daniel S W and Karthikesalingam, Alan and King, Dominic and Ashrafian, Hutan and Darzi, Ara},
doi = {10.1038/s41746-021-00438-z},
issn = {2398-6352},
journal = {npj Digital Medicine},
number = {1},
pages = {65},
title = {{Diagnostic accuracy of deep learning in medical imaging: a systematic review and meta-analysis}},
url = {https://doi.org/10.1038/s41746-021-00438-z},
volume = {4},
year = {2021}
}
@article{Parekh2020,
abstract = {Coronavirus disease 2019 (COVID-19), a recently emerged lower respiratory tract illness, has quickly become a pandemic. The purpose of this review is to discuss and differentiate typical imaging findings of COVID-19 from those of other diseases, which can appear similar in the first instance. The typical CT findings of COVID-19 are bilateral and peripheral predominant ground-glass opacities. As per the Fleischner Society consensus statement, CT is appropriate in certain scenarios, including for patients who are at risk for and/or develop clinical worsening. The probability that CT findings represent COVID-19, however, depends largely on the pretest probability of infection, which is in turn defined by community prevalence of infection. When the community prevalence of COVID-19 is low, a large gap exists between positive predictive values of chest CT versus those of reverse transcriptase polymerase chain reaction. This implies that with use of chest CT there are a large number of false-positive results. Imaging differentiation is important for management and isolation purposes and for appropriate disposition of patients with false-positive CT findings. Herein the authors discuss differential pathology with close imaging resemblance to typical CT imaging features of COVID-19 and highlight CT features that may help differentiate COVID-19 from other conditions.},
author = {Parekh, Maansi and Donuru, Achala and Balasubramanya, Rashmi and Kapur, Sangita},
doi = {10.1148/radiol.2020202504},
file = {:C$\backslash$:/Users/iradspm/Downloads/radiol.2020202504.pdf:pdf},
issn = {15271315},
journal = {Radiology},
number = {3},
pages = {E289--E302},
pmid = {32633678},
title = {{Review of the chest CT differential diagnosis of ground-glass opacities in the COVID era}},
volume = {297},
year = {2020}
}
@article{Bharati2020a,
abstract = {Lung disease is common throughout the world. These include chronic obstructive pulmonary disease, pneumonia, asthma, tuberculosis, fibrosis, etc. Timely diagnosis of lung disease is essential. Many image processing and machine learning models have been developed for this purpose. Different forms of existing deep learning techniques including convolutional neural network (CNN), vanilla neural network, visual geometry group based neural network (VGG), and capsule network are applied for lung disease prediction. The basic CNN has poor performance for rotated, tilted, or other abnormal image orientation. Therefore, we propose a new hybrid deep learning framework by combining VGG, data augmentation and spatial transformer network (STN) with CNN. This new hybrid method is termed here as VGG Data STN with CNN (VDSNet). As implementation tools, Jupyter Notebook, Tensorflow, and Keras are used. The new model is applied to NIH chest X-ray image dataset collected from Kaggle repository. Full and sample versions of the dataset are considered. For both full and sample datasets, VDSNet outperforms existing methods in terms of a number of metrics including precision, recall, F0.5 score and validation accuracy. For the case of full dataset, VDSNet exhibits a validation accuracy of 73{\%}, while vanilla gray, vanilla RGB, hybrid CNN and VGG, and modified capsule network have accuracy values of 67.8{\%}, 69{\%}, 69.5{\%} and 63.8{\%}, respectively. When sample dataset rather than full dataset is used, VDSNet requires much lower training time at the expense of a slightly lower validation accuracy. Hence, the proposed VDSNet framework will simplify the detection of lung disease for experts as well as for doctors.},
author = {Bharati, Subrato and Podder, Prajoy and Mondal, M Rubaiyat Hossain},
doi = {https://doi.org/10.1016/j.imu.2020.100391},
issn = {2352-9148},
journal = {Informatics in Medicine Unlocked},
keywords = {CNN,COVID-19,Capsule network,VDSNet,VGG,Vanilla NN},
pages = {100391},
title = {{Hybrid deep learning for detecting lung diseases from X-ray images}},
url = {https://www.sciencedirect.com/science/article/pii/S2352914820300290},
volume = {20},
year = {2020}
}
@inproceedings{Monowar2020a,
author = {Monowar, K F and Hasan, M A M and Shin, J},
booktitle = {2020 11th International Conference on Electrical and Computer Engineering (ICECE)},
doi = {10.1109/ICECE51571.2020.9393135},
isbn = {VO  -},
pages = {169--172},
title = {{Lung Opacity Classification With Convolutional Neural Networks Using Chest X-rays}},
year = {2020}
}
@article{Zhou2020,
abstract = {Background: Since December, 2019, Wuhan, China, has experienced an outbreak of coronavirus disease 2019 (COVID-19), caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Epidemiological and clinical characteristics of patients with COVID-19 have been reported but risk factors for mortality and a detailed clinical course of illness, including viral shedding, have not been well described. Methods: In this retrospective, multicentre cohort study, we included all adult inpatients (≥18 years old) with laboratory-confirmed COVID-19 from Jinyintan Hospital and Wuhan Pulmonary Hospital (Wuhan, China) who had been discharged or had died by Jan 31, 2020. Demographic, clinical, treatment, and laboratory data, including serial samples for viral RNA detection, were extracted from electronic medical records and compared between survivors and non-survivors. We used univariable and multivariable logistic regression methods to explore the risk factors associated with in-hospital death. Findings: 191 patients (135 from Jinyintan Hospital and 56 from Wuhan Pulmonary Hospital) were included in this study, of whom 137 were discharged and 54 died in hospital. 91 (48{\%}) patients had a comorbidity, with hypertension being the most common (58 [30{\%}] patients), followed by diabetes (36 [19{\%}] patients) and coronary heart disease (15 [8{\%}] patients). Multivariable regression showed increasing odds of in-hospital death associated with older age (odds ratio 1{\textperiodcentered}10, 95{\%} CI 1{\textperiodcentered}03–1{\textperiodcentered}17, per year increase; p=0{\textperiodcentered}0043), higher Sequential Organ Failure Assessment (SOFA) score (5{\textperiodcentered}65, 2{\textperiodcentered}61–12{\textperiodcentered}23; p{\textless}0{\textperiodcentered}0001), and d-dimer greater than 1 $\mu$g/mL (18{\textperiodcentered}42, 2{\textperiodcentered}64–128{\textperiodcentered}55; p=0{\textperiodcentered}0033) on admission. Median duration of viral shedding was 20{\textperiodcentered}0 days (IQR 17{\textperiodcentered}0–24{\textperiodcentered}0) in survivors, but SARS-CoV-2 was detectable until death in non-survivors. The longest observed duration of viral shedding in survivors was 37 days. Interpretation: The potential risk factors of older age, high SOFA score, and d-dimer greater than 1 $\mu$g/mL could help clinicians to identify patients with poor prognosis at an early stage. Prolonged viral shedding provides the rationale for a strategy of isolation of infected patients and optimal antiviral interventions in the future. Funding: Chinese Academy of Medical Sciences Innovation Fund for Medical Sciences; National Science Grant for Distinguished Young Scholars; National Key Research and Development Program of China; The Beijing Science and Technology Project; and Major Projects of National Science and Technology on New Drug Creation and Development.},
author = {Zhou, Fei and Yu, Ting and Du, Ronghui and Fan, Guohui and Liu, Ying and Liu, Zhibo and Xiang, Jie and Wang, Yeming and Song, Bin and Gu, Xiaoying and Guan, Lulu and Wei, Yuan and Li, Hui and Wu, Xudong and Xu, Jiuyang and Tu, Shengjin and Zhang, Yi and Chen, Hua and Cao, Bin},
doi = {10.1016/S0140-6736(20)30566-3},
file = {:C$\backslash$:/Users/iradspm/Downloads/1-s2.0-S0140673620305663-main.pdf:pdf},
issn = {1474547X},
journal = {The Lancet},
number = {10229},
pages = {1054--1062},
pmid = {32171076},
publisher = {Elsevier Ltd},
title = {{Clinical course and risk factors for mortality of adult inpatients with COVID-19 in Wuhan, China: a retrospective cohort study}},
url = {http://dx.doi.org/10.1016/S0140-6736(20)30566-3},
volume = {395},
year = {2020}
}
@article{Li2016a,
abstract = {Computer aided detection (CAD) systems can assist radiologists by offering a second opinion on early diagnosis of lung cancer. Classification and feature representation play critical roles in false-positive reduction (FPR) in lung nodule CAD. We design a deep convolutional neural networks method for nodule classification, which has an advantage of autolearning representation and strong generalization ability. A specified network structure for nodule images is proposed to solve the recognition of three types of nodules, that is, solid, semisolid, and ground glass opacity (GGO). Deep convolutional neural networks are trained by 62,492 regions-of-interest (ROIs) samples including 40,772 nodules and 21,720 nonnodules from the Lung Image Database Consortium (LIDC) database. Experimental results demonstrate the effectiveness of the proposed method in terms of sensitivity and overall accuracy and that it consistently outperforms the competing methods.},
author = {Li, Wei and Cao, Peng and Zhao, Dazhe and Wang, Junbo},
doi = {10.1155/2016/6215085},
editor = {Suzuki, Kenji},
issn = {1748-670X},
journal = {Computational and Mathematical Methods in Medicine},
pages = {6215085},
publisher = {Hindawi Publishing Corporation},
title = {{Pulmonary Nodule Classification with Deep Convolutional Neural Networks on Computed Tomography Images}},
url = {https://doi.org/10.1155/2016/6215085},
volume = {2016},
year = {2016}
}
@article{Bala2021,
abstract = {There is increasing interest in understanding the role of air pollution as one of the greatest threats to human health worldwide. Nine of 10 individuals breathe air with polluted compounds that have a great impact on lung tissue. The nature of the relationship is complex, and new or updated data are constantly being reported in the literature. The goal of our review was to summarize the most important air pollutants and their impact on the main respiratory diseases (chronic obstructive pulmonary disease, asthma, lung cancer, idiopathic pulmonary fibrosis, respiratory infections, bronchiectasis, tuberculosis) to reduce both short- and the long-term exposure consequences. We considered the most important air pollutants, including sulfur dioxide, nitrogen dioxide, carbon monoxide, volatile organic compounds, ozone, particulate matter and biomass smoke, and observed their impact on pulmonary pathologies. We focused on respiratory pathologies, because air pollution potentiates the increase in respiratory diseases, and the evidence that air pollutants have a detrimental effect is growing. It is imperative to constantly improve policy initiatives on air quality in both high- and low-income countries.},
author = {Bălă, Gabriel-Petrică and R{\^{a}}jnoveanu, Ruxandra-Mioara and Tudorache, Emanuela and Motișan, Radu and Oancea, Cristian},
doi = {10.1007/s11356-021-13208-x},
issn = {1614-7499},
journal = {Environmental Science and Pollution Research},
number = {16},
pages = {19615--19628},
title = {{Air pollution exposure—the (in)visible risk factor for respiratory diseases}},
url = {https://doi.org/10.1007/s11356-021-13208-x},
volume = {28},
year = {2021}
}
@article{Tan2022,
abstract = {Chronic respiratory diseases have collectively become a major public health concern and have now taken form as one of the leading causes of mortality worldwide. Most chronic respiratory diseases primarily occur due to prolonged airway inflammation. In addition, critical environmental factors such as cigarette smoke, industrial pollutants, farm dust, and pollens may also exacerbate such diseases. Moreover, alterations in the genetic sequence of an individual, abnormalities in the chromosomes or immunosuppression resulting from bacterial, fungal, and viral infections may also play a key role in the pathogenesis of respiratory diseases. Over the years, multiple in vitro models have been employed as the basis of existing as well as emerging advancements in chronic respiratory disease research. These include cell lines, gene expression techniques, single cell RNA sequencing, cytometry, culture techniques, as well as serum/sputum biomarkers that can be used to elucidate the molecular mechanisms underlying these diseases, and to identify novel diagnostic and management options for these diseases. This review summarizes the current understanding of the pathogenesis of various chronic respiratory diseases derived through in vitro experimental models, where the knowledge obtained from these studies can greatly benefit researchers in the discovery and development of novel screening techniques and advanced therapeutic strategies that could be translated into clinical use in the future.},
author = {Tan, Ching Leng and Chan, Yinghan and Candasamy, Mayuren and Chellian, Jestin and Madheswaran, Thiagarajan and Sakthivel, Lakshmana Prabu and Patel, Vyoma K and Chakraborty, Amlan and MacLoughlin, Ronan and Kumar, Deepak and Verma, Nitin and Malyla, Vamshikrishna and Gupta, Piyush Kumar and Jha, Niraj Kumar and Thangavelu, Lakshmi and Devkota, Hari Prasad and Bhatt, Shvetank and Prasher, Parteek and Gupta, Gaurav and Gulati, Monica and Singh, Sachin Kumar and Paudel, Keshav Raj and Hansbro, Philip M and Oliver, Brian G and Dua, Kamal and Chellappan, Dinesh Kumar},
doi = {https://doi.org/10.1016/j.ejphar.2022.174821},
issn = {0014-2999},
journal = {European Journal of Pharmacology},
keywords = {Asthma,COPD,Chronic respiratory diseases,Cystic fibrosis,Lung cancer,models},
pages = {174821},
title = {{Unravelling the molecular mechanisms underlying chronic respiratory diseases for the development of novel therapeutics via in vitro experimental models}},
url = {https://www.sciencedirect.com/science/article/pii/S0014299922000826},
volume = {919},
year = {2022}
}
@misc{JulieSteenhuysen2022,
author = {{Julie Steenhuysen}, Deena Beasley},
title = {{New COVID model predicts over 1 million deaths in China}},
url = {https://www.reuters.com/world/china/new-covid-model-predicts-over-1-mln-deaths-china-through-2023-2022-12-17/},
year = {2022}
}
@article{Bhosale2023a,
abstract = {Background and Objective In the current COVID-19 outbreak, efficient testing of COVID-19 individuals has proven vital to limiting and arresting the disease's accelerated spread globally. It has been observed that the severity and mortality ratio of COVID-19 affected patients is at greater risk because of chronic pulmonary diseases. This study looks at radiographic examinations exploiting chest X-ray images (CXI), which have become one of the utmost feasible assessment approaches for pulmonary disorders, including COVID-19. Deep Learning(DL) remains an excellent image classification method and framework; research has been conducted to predict pulmonary diseases with COVID-19 instances by developing DL classifiers with nine class CXI. However, a few claim to have strong prediction results; because of noisy and small data, their recommended DL strategies may suffer from significant deviation and generality failures. Methods Therefore, a unique CNN model(PulDi-COVID) for detecting nine diseases (atelectasis, bacterial-pneumonia, cardiomegaly, covid19, effusion, infiltration, no-finding, pneumothorax, viral-Pneumonia) using CXI has been proposed using the SSE algorithm. Several transfer-learning models: VGG16, ResNet50, VGG19, DenseNet201, MobileNetV2, NASNetMobile, ResNet152V2, DenseNet169 are trained on CXI of chronic lung diseases and COVID-19 instances. Given that the proposed thirteen SSE ensemble models solved DL's constraints by making predictions with different classifiers rather than a single, we present PulDi-COVID, an ensemble DL model that combines DL with ensemble learning. The PulDi-COVID framework is created by incorporating various snapshots of DLmodels, which have spearheaded chronic lung diseases with COVID-19 cases identification process with a deep neural network produced CXI by applying a suggested SSE method.That is familiar with the idea of various DL perceptions on different classes. Results PulDi-COVID findings were compared to thirteen existing studies for nine-class classification using COVID-19. Test results reveal that PulDi-COVID offers impressive outcomes for chronic diseases with COVID-19 identification with a 99.70{\%} accuracy, 98.68{\%} precision, 98.67{\%} recall, 98.67{\%} F1 score, lowest 12 CXIs zero-one loss, 99.24{\%} AUC-ROC score, and lowest 1.33{\%} error rate. Overall test results are superior to the existing Convolutional Neural Network(CNN). To thebest of our knowledge, the observed results for nine-class classification are significantly superior to the state-of-the-art approaches employed for COVID-19 detection. Furthermore, the CXIthat we usedto assess our algorithm is one of the larger datasets for COVID detection with pulmonary diseases. Conclusion The empirical findings of our suggested approach PulDi-COVIDshow that it outperforms previously developed methods. The suggested SSE method with PulDi-COVID can effectively fulfill the COVID-19 speedy detection needs with different lung diseases for physicians to minimize patient severity and mortality.},
author = {Bhosale, Yogesh H and Patnaik, K Sridhar},
doi = {https://doi.org/10.1016/j.bspc.2022.104445},
issn = {1746-8094},
journal = {Biomedical Signal Processing and Control},
keywords = {Biomedical engineering,COVID-19,Chronic Obstructive Pulmonary Diseases (COPD),Convolution neural networks (CNN),Diagnosis {\&} Classification,Ensemble deep learning,Medical Imaging,Transfer learning},
pages = {104445},
title = {{PulDi-COVID: Chronic obstructive pulmonary (lung) diseases with COVID-19 classification using ensemble deep convolutional neural network from chest X-ray images to minimize severity and mortality rates}},
url = {https://www.sciencedirect.com/science/article/pii/S1746809422008990},
volume = {81},
year = {2023}
}
@article{Tang2020a,
abstract = {As one of the most ubiquitous diagnostic imaging tests in medical practice, chest radiography requires timely reporting of potential findings and diagnosis of diseases in the images. Automated, fast, and reliable detection of diseases based on chest radiography is a critical step in radiology workflow. In this work, we developed and evaluated various deep convolutional neural networks (CNN) for differentiating between normal and abnormal frontal chest radiographs, in order to help alert radiologists and clinicians of potential abnormal findings as a means of work list triaging and reporting prioritization. A CNN-based model achieved an AUC of 0.9824 ± 0.0043 (with an accuracy of 94.64 ± 0.45{\%}, a sensitivity of 96.50 ± 0.36{\%} and a specificity of 92.86 ± 0.48{\%}) for normal versus abnormal chest radiograph classification. The CNN model obtained an AUC of 0.9804 ± 0.0032 (with an accuracy of 94.71 ± 0.32{\%}, a sensitivity of 92.20 ± 0.34{\%} and a specificity of 96.34 ± 0.31{\%}) for normal versus lung opacity classification. Classification performance on the external dataset showed that the CNN model is likely to be highly generalizable, with an AUC of 0.9444 ± 0.0029. The CNN model pre-trained on cohorts of adult patients and fine-tuned on pediatric patients achieved an AUC of 0.9851 ± 0.0046 for normal versus pneumonia classification. Pretraining with natural images demonstrates benefit for a moderate-sized training image set of about 8500 images. The remarkable performance in diagnostic accuracy observed in this study shows that deep CNNs can accurately and effectively differentiate normal and abnormal chest radiographs, thereby providing potential benefits to radiology workflow and patient care.},
author = {Tang, Yu-Xing and Tang, You-Bao and Peng, Yifan and Yan, Ke and Bagheri, Mohammadhadi and Redd, Bernadette A and Brandon, Catherine J and Lu, Zhiyong and Han, Mei and Xiao, Jing and Summers, Ronald M},
doi = {10.1038/s41746-020-0273-z},
issn = {2398-6352},
journal = {npj Digital Medicine},
number = {1},
pages = {70},
title = {{Automated abnormality classification of chest radiographs using deep convolutional neural networks}},
url = {https://doi.org/10.1038/s41746-020-0273-z},
volume = {3},
year = {2020}
}
@misc{WHO2021,
author = {WHO},
title = {{Tracking SARS-CoV-2 variants}},
url = {https://www.who.int/activities/tracking-SARS-CoV-2-variants},
year = {2021}
}
@article{Kim2005a,
abstract = {The purpose of this study was to develop an automated scheme to facilitate detection of localized ground-glass opacity (GGO) in the lung at computed tomography (CT). Institutional review board approval and informed consent were not required. Two radiologists reviewed CT images from 14 patients (five men, nine women) who had lung cancer or metastasis and whose malignancy was classified as GGO. The lung region was sampled and completely covered with contiguous, 50{\%} overlapping regions of interest (ROIs) measuring 30 ? 30 pixels in size. The lung area within each ROI was analyzed to compute texture features and gaussian curve fitting features. Performance of the artificial neural networks (ANNs) measured by using the area under the receiver operating characteristic curve was 0.92. With a threshold of 0.9, the sensitivity of the ANN for detecting GGO ROIs was 94.3{\%} (280 of 297 ROIs), and the positive predictive value was 29.1{\%} (280 of 963 ROIs). A computerized scheme may hold promise in facilitating detection of localized GGO at CT. ? RSNA, 2005},
annote = {doi: 10.1148/radiol.2372041461},
author = {Kim, Kwang Gi and Goo, Jin Mo and Kim, Jong Hyo and Lee, Hyun Ju and Min, Byung Goo and Bae, Kyongtae T and Im, Jung-Gi},
doi = {10.1148/radiol.2372041461},
issn = {0033-8419},
journal = {Radiology},
month = {nov},
number = {2},
pages = {657--661},
publisher = {Radiological Society of North America},
title = {{Computer-aided Diagnosis of Localized Ground-Glass Opacity in the Lung at CT: Initial Experience}},
url = {https://doi.org/10.1148/radiol.2372041461},
volume = {237},
year = {2005}
}
@article{Liu2019,
abstract = {Recently, deep reinforcement learning has achieved great success by integrating deep learning models into reinforcement learning algorithms in various applications such as computer games and robots. Specially, it is promising for computer-aided diagnosis and treatment to combine deep reinforcement learning with medical big data generated and collected from medical Internet of Things. In this paper, we focus on the potential of the deep reinforcement learning for lung cancer detection as many people are suffering from the lung tumor and about 1.8 million patients died from lung cancer in 2018. Early detection and diagnosis of lung tumor can significantly improve the treatment effect and prolong survival. In this work, we present several representative deep reinforcement learning models that are potential to use for lung cancer detection. Furthermore, we summarize the common types of lung cancer and the main characteristics of each type. Finally, we point out the open challenges and possible future research directions of applying deep reinforcement learning to lung cancer detection, which is expected to promote the evolution of smart medicine with medical Internet of Things.},
author = {Liu, Zhuo and Yao, Chenhui and Yu, Hang and Wu, Taihua},
doi = {https://doi.org/10.1016/j.future.2019.02.068},
issn = {0167-739X},
journal = {Future Generation Computer Systems},
keywords = {Deep reinforcement learning,Lung cancer,Medical Internet of Things,Smart medicine},
pages = {1--9},
title = {{Deep reinforcement learning with its application for lung cancer detection in medical Internet of Things}},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19303772},
volume = {97},
year = {2019}
}
@article{Zaman2010,
author = {Zaman, K.},
doi = {10.3329/jhpn.v28i2.4879},
file = {:C$\backslash$:/Users/iradspm/Downloads/3891.pdf:pdf},
issn = {16060997},
journal = {Journal of Health, Population and Nutrition},
number = {2},
pages = {111--113},
pmid = {20411672},
title = {{Tuberculosis: A global health problem}},
volume = {28},
year = {2010}
}
@article{Rahman2020a,
author = {Rahman, T and Khandakar, A and Kadir, M A and Islam, K R and Islam, K F and Mazhar, R and Hamid, T and Islam, M T and Kashem, S and Mahbub, Z B and Ayari, M A and Chowdhury, M E H},
doi = {10.1109/ACCESS.2020.3031384},
issn = {2169-3536 VO  - 8},
journal = {IEEE Access},
pages = {191586--191601},
title = {{Reliable Tuberculosis Detection Using Chest X-Ray With Deep Learning, Segmentation and Visualization}},
volume = {8},
year = {2020}
}
@article{Zhang2022,
abstract = {In the past decade, the application of machine learning (ML) to healthcare has helped drive the automation of physician tasks as well as enhancements in clinical capabilities and access to care. This progress has emphasized that, from model development to model deployment, data play central roles. In this Review, we provide a data-centric view of the innovations and challenges that are defining ML for healthcare. We discuss deep generative models and federated learning as strategies to augment datasets for improved model performance, as well as the use of the more recent transformer models for handling larger datasets and enhancing the modelling of clinical text. We also discuss data-focused problems in the deployment of ML, emphasizing the need to efficiently deliver data to ML models for timely clinical predictions and to account for natural data shifts that can deteriorate model performance.},
author = {Zhang, Angela and Xing, Lei and Zou, James and Wu, Joseph C.},
doi = {10.1038/s41551-022-00898-y},
file = {:C$\backslash$:/Users/iradspm/Downloads/s41551-022-00898-y.pdf:pdf},
issn = {2157846X},
journal = {Nature Biomedical Engineering},
pmid = {35788685},
publisher = {Springer US},
title = {{Shifting machine learning for healthcare from development to deployment and from models to data}},
year = {2022}
}
@article{Park2022,
abstract = {The coronavirus disease 2019 (COVID-19) pandemic has transitioned to a third phase and many variants have been originated. There has been millions of lives loss as well as billions in economic loss. The morbidity and mortality for COVID-19 varies by country. There were different preventive approaches and public restrictions policies have been applied to control the COVID-19 impacts and usually measured by Stringency Index. This study aimed to explore the COVID-19 trend, public restriction policies and vaccination status with economic ranking of countries.},
author = {Park, Myung-Bae and Ranabhat, Chhabi Lal},
doi = {10.1186/s13690-022-00936-w},
issn = {2049-3258},
journal = {Archives of Public Health},
number = {1},
pages = {197},
title = {{COVID-19 trends, public restrictions policies and vaccination status by economic ranking of countries: a longitudinal study from 110 countries}},
url = {https://doi.org/10.1186/s13690-022-00936-w},
volume = {80},
year = {2022}
}
@article{Kassania2021a,
abstract = {The newly identified Coronavirus pneumonia, subsequently termed COVID-19, is highly transmittable and pathogenic with no clinically approved antiviral drug or vaccine available for treatment. The most common symptoms of COVID-19 are dry cough, sore throat, and fever. Symptoms can progress to a severe form of pneumonia with critical complications, including septic shock, pulmonary edema, acute respiratory distress syndrome and multi-organ failure. While medical imaging is not currently recommended in Canada for primary diagnosis of COVID-19, computer-aided diagnosis systems could assist in the early detection of COVID-19 abnormalities and help to monitor the progression of the disease, potentially reduce mortality rates. In this study, we compare popular deep learning-based feature extraction frameworks for automatic COVID-19 classification. To obtain the most accurate feature, which is an essential component of learning, MobileNet, DenseNet, Xception, ResNet, InceptionV3, InceptionResNetV2, VGGNet, NASNet were chosen amongst a pool of deep convolutional neural networks. The extracted features were then fed into several machine learning classifiers to classify subjects as either a case of COVID-19 or a control. This approach avoided task-specific data pre-processing methods to support a better generalization ability for unseen data. The performance of the proposed method was validated on a publicly available COVID-19 dataset of chest X-ray and CT images. The DenseNet121 feature extractor with Bagging tree classifier achieved the best performance with 99{\%} classification accuracy. The second-best learner was a hybrid of the a ResNet50 feature extractor trained by LightGBM with an accuracy of 98},
author = {Kassania, Sara Hosseinzadeh and Kassanib, Peyman Hosseinzadeh and Wesolowskic, Michal J and Schneidera, Kevin A and Detersa, Ralph},
doi = {https://doi.org/10.1016/j.bbe.2021.05.013},
issn = {0208-5216},
journal = {Biocybernetics and Biomedical Engineering},
keywords = {Computer-Aided Diagnosis,Coronavirus Disease,Deep Learning,Feature Extraction,Lung Opacity,Transfer Learning},
number = {3},
pages = {867--879},
title = {{Automatic Detection of Coronavirus Disease (COVID-19) in X-ray and CT Images: A Machine Learning Based Approach}},
url = {https://www.sciencedirect.com/science/article/pii/S020852162100067X},
volume = {41},
year = {2021}
}
@article{Siegel2022,
abstract = {Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths in the United States and compiles the most recent data on population-based cancer occurrence and outcomes. Incidence data (through 2018) were collected by the Surveillance, Epidemiology, and End Results program; the National Program of Cancer Registries; and the North American Association of Central Cancer Registries. Mortality data (through 2019) were collected by the National Center for Health Statistics. In 2022, 1,918,030 new cancer cases and 609,360 cancer deaths are projected to occur in the United States, including approximately 350 deaths per day from lung cancer, the leading cause of cancer death. Incidence during 2014 through 2018 continued a slow increase for female breast cancer (by 0.5{\%} annually) and remained stable for prostate cancer, despite a 4{\%} to 6{\%} annual increase for advanced disease since 2011. Consequently, the proportion of prostate cancer diagnosed at a distant stage increased from 3.9{\%} to 8.2{\%} over the past decade. In contrast, lung cancer incidence continued to decline steeply for advanced disease while rates for localized-stage increased suddenly by 4.5{\%} annually, contributing to gains both in the proportion of localized-stage diagnoses (from 17{\%} in 2004 to 28{\%} in 2018) and 3-year relative survival (from 21{\%} to 31{\%}). Mortality patterns reflect incidence trends, with declines accelerating for lung cancer, slowing for breast cancer, and stabilizing for prostate cancer. In summary, progress has stagnated for breast and prostate cancers but strengthened for lung cancer, coinciding with changes in medical practice related to cancer screening and/or treatment. More targeted cancer control interventions and investment in improved early detection and treatment would facilitate reductions in cancer mortality.},
author = {Siegel, Rebecca L. and Miller, Kimberly D. and Fuchs, Hannah E. and Jemal, Ahmedin},
doi = {10.3322/caac.21708},
file = {:C$\backslash$:/Users/iradspm/Downloads/CA A Cancer J Clinicians - 2022 - Siegel - Cancer statistics  2022.pdf:pdf},
issn = {0007-9235},
journal = {CA: A Cancer Journal for Clinicians},
keywords = {cancer cases,cancer statistics,death rates,incidence,mortality},
number = {1},
pages = {7--33},
pmid = {35020204},
title = {{Cancer statistics, 2022}},
volume = {72},
year = {2022}
}
@inproceedings{Khobragade2016a,
author = {Khobragade, S and Tiwari, A and Patil, C Y and Narke, V},
booktitle = {2016 IEEE 1st International Conference on Power Electronics, Intelligent Control and Energy Systems (ICPEICES)},
doi = {10.1109/ICPEICES.2016.7853683},
isbn = {VO  -},
pages = {1--5},
title = {{Automatic detection of major lung diseases using Chest Radiographs and classification by feed-forward artificial neural network}},
year = {2016}
}
@article{Seixas2013a,
abstract = {BACKGROUND: Clinicians in countries with high tuberculosis (TB) prevalence often treat pleural TB based on clinical grounds, as the availability and sensitivity of diagnostic tests are poor. OBJECTIVE: To evaluate the role of artificial neural networks (ANN) as an aid for the non-invasive diagnosis of pleural TB. These tools can be used in simple computer devices (tablets) without remote internet connection. METHODS: The clinical history and human immunodeficiency virus (HIV) status of 137 patients were prospectively entered in a database. Both non-linear ANN and the linear Fisher discriminant were used to calculate performance indexes based on clinical grounds. The same procedure was performed including pleural fluid test results (smear, culture, adenosine deaminase, serology and nucleic acid amplification test). The gold standard was any positive test for TB. RESULTS: In pre-test modelling, the neural model reached {\textgreater}90{\%} accuracy (Fisher discriminant 74.5{\%}). Under pre-test conditions, ANN had better accuracy compared to each test considered separately. CONCLUSIONS: ANN are highly reliable for diagnosing pleural TB based on clinical grounds and HIV status only, and are useful even in remote conditions lacking access to sophisticated medical or computer infrastructure. In other better-equipped scenarios, these tools should be evaluated as substitutes for thoracocentesis and pleural biopsy. {\textcopyright} 2013 The Union.},
author = {Seixas, J. M. and Faria, J. and {Souza Filho}, J. B.O. and Vieira, A. F.M. and Kritski, A. and Trajman, A.},
doi = {10.5588/ijtld.12.0829},
file = {:C$\backslash$:/Users/iradspm/Downloads/s21.pdf:pdf},
issn = {10273719},
journal = {International Journal of Tuberculosis and Lung Disease},
keywords = {Accuracy,Artificial intelligence,Diagnosis,Pleurisy,Tuberculosis},
number = {5},
pages = {682--686},
pmid = {23575336},
title = {{Artificial neural network models to support the diagnosis of pleural tuberculosis in adult patients}},
volume = {17},
year = {2013}
}
@article{Li2022,
abstract = {Melatonin, primarily secreted by the pineal gland, is an anthracemal compound. Its chemical name is N‑acetyl‑5‑methoxytryptamine. Great advances in melatonin‑related research have been made, including the understanding of its roles in the rhythm of the sleep/wake cycle, retardation of aging processes, as well as antioxidant and/or anti‑inflammatory effects. Melatonin exerts a wide range of physiological effects related to the high lipophilicity of melatonin itself. Melatonin has strong radical scavenging activity, which serves an important role in pulmonary disorders. Pulmonary disorders are among the diseases that threaten human health. Especially in developing countries, due to environmental factors such as smoke and dust, the incidences of pulmonary disorders are high. Melatonin has been reported to have great potential to treat patients with pulmonary disorders. The present review discusses the relationship between melatonin and pulmonary disorders, including coronavirus disease‑2019, chronic obstructive pulmonary disease, non‑small cell lung cancer and pulmonary fibrosis.},
address = {Department of Chinese Medicine, Changchun University of Chinese Medicine, Changchun, Jilin 130021, P.R. China Department of Acupuncture and Tuina, Changchun University of Chinese Medicine, Changchun, Jilin 130021, P.R. China Department of Pediatrics, Affi},
author = {Li, Lijie and Gang, Xiaochao and Wang, Jiajia and Gong, Xiaoyan},
doi = {10.3892/etm.2022.11197},
issn = {1792-0981 1792-1015},
journal = {Exp Ther Med},
keywords = {melatonin pulmonary disorders inflammation respira},
number = {4},
pages = {271},
title = {{Role of melatonin in respiratory diseases (Review)}},
url = {https://doi.org/10.3892/etm.2022.11197},
volume = {23},
year = {2022}
}
@article{Panwar2020a,
abstract = {Presently, COVID-19 has posed a serious threat to researchers, scientists, health professionals, and administrations around the globe from its detection to its treatment. The whole world is witnessing a lockdown like situation because of COVID-19 pandemic. Persistent efforts are being made by the researchers to obtain the possible solutions to control this pandemic in their respective areas. One of the most common and effective methods applied by the researchers is the use of CT-Scans and X-rays to analyze the images of lungs for COVID-19. However, it requires several radiology specialists and time to manually inspect each report which is one of the challenging tasks in a pandemic. In this paper, we have proposed a deep learning neural network-based method nCOVnet, an alternative fast screening method that can be used for detecting the COVID-19 by analyzing the X-rays of patients which will look for visual indicators found in the chest radiography imaging of COVID-19 patients.},
author = {Panwar, Harsh and Gupta, P K and Siddiqui, Mohammad Khubeb and Morales-Menendez, Ruben and Singh, Vaishnavi},
doi = {https://doi.org/10.1016/j.chaos.2020.109944},
issn = {0960-0779},
journal = {Chaos, Solitons {\&} Fractals},
keywords = {COVID-19,Convolutional neural network (CNN),Deep learning,Detection,X-Rays,nCOVnet},
pages = {109944},
title = {{Application of deep learning for fast detection of COVID-19 in X-Rays using nCOVnet}},
url = {https://www.sciencedirect.com/science/article/pii/S096007792030343X},
volume = {138},
year = {2020}
}
@article{Singh2022,
abstract = {COVID-19 is an infectious and contagious disease caused by the new coronavirus. The total number of cases is over 19 million and continues to grow. A common symptom noticed among COVID-19 patients is lung infection that results in breathlessness, and the lack of essential resources such as testing, oxygen, and ventilators enhances its severity. Chest X-ray can be used to design and develop a COVID-19 detection mechanism for a quicker diagnosis using AI and machine learning techniques. Due to this silver lining, various new COVID-19 detection techniques and prediction models have been introduced in recent times based on chest radiography images. However, due to a high level of unpredictability and the absence of essential data, standard models have showcased low efficiency and also suffer from overheads and complexities. This paper proposes a model fine tuning transfer learning-coronavirus 19 (Ftl-CoV19) for COVID-19 detection through chest X-rays, which embraces the ideas of transfer learning in pretrained VGG16 model with including combination of convolution, max pooling, and dense layer at different stages of model. Ftl-CoV19 reported promising experimental results; it observed training and validation accuracy of 98.82{\&}{\#}x0025; and 99.27{\&}{\#}x0025; with precision of 100{\&}{\#}x0025;, recall of 98{\&}{\#}x0025;, and F1 score of 99{\&}{\#}x0025;. These results outperformed other conventional state of arts such as CNN, ResNet50, InceptionV3, and Xception.},
author = {Singh, Tarishi and Saurabh, Praneet and Bisen, Dhananjay and Kane, Lalit and Pathak, Mayank and Sinha, G R},
doi = {10.1155/2022/1953992},
editor = {Sharma, Kapil},
issn = {1687-5265},
journal = {Computational Intelligence and Neuroscience},
pages = {1953992},
publisher = {Hindawi},
title = {{Ftl-CoV19: A Transfer Learning Approach to Detect COVID-19}},
url = {https://doi.org/10.1155/2022/1953992},
volume = {2022},
year = {2022}
}
@misc{WorldHealthOrganization2020,
abstract = {Covid-19 can be considered as a pandemic},
author = {{World Health Organization}},
booktitle = {World Health Organization},
number = {March},
title = {{Opening remarks at the media briefing on COVID-19}},
url = {https://www.who.int/dg/speeches/detail/who-director-general-s-opening-remarks-at-the-media-briefing-on-covid-19---16-march-2020},
volume = {11},
year = {2020}
}
@article{WHO2022,
abstract = {All patients with MDR/RR-TB, including those with additional resistance to fluoroquinolones, stand to benefit from effective all-oral treatment regimens, either shorter or longer, implemented under programmatic conditions. • MDR/RR-TB patients with extensive TB disease, severe forms of extrapulmonary TB, those with resistance to fluoroquinolones or who have been exposed to treatment with second-line drugs will benefit from an individualized longer regimen designed using the WHO priority grouping of medicines recommended in 2018. • For MDR/RR-TB patients without previous exposure to second-line treatment (including bedaquiline), without fluoroquinolone resistance and no extensive TB disease or severe extrapulmonary TB, the preferred treatment option is a shorter, all-oral, bedaquiline-containing regimen. In this group of patients, national TB programmes are advised to phase out use of the injectable-containing shorter regimen. • Access to rapid drug susceptibility testing, especially for ruling out fluoroquinolone resistance, is required before starting the shorter, all-oral, bedaquiline-containing MDR-TB regimen. • In settings with a high probability of, or patients with confirmed resistance to other medicines in the regimen, further modifications of the shorter, all-oral, bedaquiline-containing regimen using priority grouping of second-line TB medicines may be implemented. However, the efficacy, safety and tolerability of such modifications to regimens {\textless}12 months are unknown and should therefore be evaluated under operational research conditions. • The BPaL regimen may be used under operational research conditions in patients with XDR-TB who have not had previous exposure to bedaquiline and linezolid (defined as less than two weeks). This regimen may not be considered for programmatic use worldwide until additional evidence on efficacy and safety has been generated. However, in individual patients for whom design of an effective regimen based on existing recommendations is not possible, BPal regimen may be considered as a last resort under prevailing ethical standards. • Decisions on appropriate regimens should be made according to patient preference and clinical judgement, also considering the results of susceptibility testing, patient treatment history and severity and site of the disease. • All treatment should be delivered under WHO-recommended standards, including patient-centered care and support, informed consent where necessary, principles of good clinical practice, active drug safety monitoring and management, and regular patient monitoring to assess regimen effectiveness.},
author = {WHO},
file = {:C$\backslash$:/Users/iradspm/Downloads/WHO-UCN-TB-2022.2-eng.pdf:pdf},
journal = {World Health Organization},
keywords = {Multidrug-Resistant,Rifampin,Tuberculosis,drug therapy,tb,therapeutic use,tuberculosis [subject]},
number = {WHO/UCN/TB/2022.2.},
pages = {6},
title = {{Rapid Communication: Key changes to the treatment of drug-resistant tuberculosis}},
url = {https://apps.who.int/iris/handle/10665/275383{\%}0Ahttp://apps.who.int/bookorders.},
year = {2022}
}
@article{Oguz2022a,
abstract = {Since the patient is not quarantined during the conclusion of the Polymerase Chain Reaction (PCR) test used in the diagnosis of COVID-19, the disease continues to spread. In this study, it was aimed to reduce the duration and amount of transmission of the disease by shortening the diagnosis time of COVID-19 patients with the use of Computed Tomography (CT). In addition, it is aimed to provide a decision support system to radiologists in the diagnosis of COVID-19. In this study, deep features were extracted with deep learning models such as ResNet-50, ResNet-101, AlexNet, Vgg-16, Vgg-19, GoogLeNet, SqueezeNet, Xception on 1345 CT images obtained from the radiography database of Siirt Education and Research Hospital. These deep features are given to classification methods such as Support Vector Machine (SVM), k Nearest Neighbor (kNN), Random Forest (RF), Decision Trees (DT), Naive Bayes (NB), and their performance is evaluated with test images. Accuracy value, F1-score and ROC curve were considered as success criteria. According to the data obtained as a result of the application, the best performance was obtained with ResNet-50 and SVM method. The accuracy was 96.296{\%}, the F1-score was 95.868{\%}, and the AUC value was 0.9821. The deep learning model and classification method examined in this study and found to be high performance can be used as an auxiliary decision support system by preventing unnecessary tests for COVID-19 disease.},
author = {Oğuz, {\c{C}}inare and Yağanoğlu, Mete},
doi = {https://doi.org/10.1016/j.ipm.2022.103025},
issn = {0306-4573},
journal = {Information Processing {\&} Management},
keywords = {COVID-19,Classification,Deep learning,ResNet},
number = {5},
pages = {103025},
title = {{Detection of COVID-19 using deep learning techniques and classification methods}},
url = {https://www.sciencedirect.com/science/article/pii/S0306457322001352},
volume = {59},
year = {2022}
}
@article{Pune2016a,
author = {Pune, Engineering and Pune, V I T},
file = {:C$\backslash$:/Users/iradspm/Downloads/Automatic{\_}detection{\_}of{\_}major{\_}lung{\_}diseases{\_}using{\_}Chest{\_}Radiographs{\_}and{\_}classification{\_}by{\_}feed-forward{\_}artificial{\_}neural{\_}network.pdf:pdf},
isbn = {9781467385879},
keywords = {-art ijici al,feature extraction,lung cancer,pneumonia,radiographs},
pages = {16--20},
title = {{Automatie Deteetion ofMajor Lung Diseases U sing Chest Radiographs and Classifieation by Feed-forward Artifieial Neural Network}},
year = {2016}
}
@article{Lakhani2017a,
abstract = {PurposeTo evaluate the efficacy of deep convolutional neural networks (DCNNs) for detecting tuberculosis (TB) on chest radiographs.Materials and MethodsFour deidentified HIPAA-compliant datasets were used in this study that were exempted from review by the institutional review board, which consisted of 1007 posteroanterior chest radiographs. The datasets were split into training (68.0{\%}), validation (17.1{\%}), and test (14.9{\%}). Two different DCNNs, AlexNet and GoogLeNet, were used to classify the images as having manifestations of pulmonary TB or as healthy. Both untrained and pretrained networks on ImageNet were used, and augmentation with multiple preprocessing techniques. Ensembles were performed on the best-performing algorithms. For cases where the classifiers were in disagreement, an independent board-certified cardiothoracic radiologist blindly interpreted the images to evaluate a potential radiologist-augmented workflow. Receiver operating characteristic curves and areas under the curve (AUCs) were used to assess model performance by using the DeLong method for statistical comparison of receiver operating characteristic curves.ResultsThe best-performing classifier had an AUC of 0.99, which was an ensemble of the AlexNet and GoogLeNet DCNNs. The AUCs of the pretrained models were greater than that of the untrained models (P {\textless} .001). Augmenting the dataset further increased accuracy (P values for AlexNet and GoogLeNet were .03 and .02, respectively). The DCNNs had disagreement in 13 of the 150 test cases, which were blindly reviewed by a cardiothoracic radiologist, who correctly interpreted all 13 cases (100{\%}). This radiologist-augmented approach resulted in a sensitivity of 97.3{\%} and specificity 100{\%}.ConclusionDeep learning with DCNNs can accurately classify TB at chest radiography with an AUC of 0.99. A radiologist-augmented approach for cases where there was disagreement among the classifiers further improved accuracy.? RSNA, 2017},
annote = {doi: 10.1148/radiol.2017162326},
author = {Lakhani, Paras and Sundaram, Baskaran},
doi = {10.1148/radiol.2017162326},
issn = {0033-8419},
journal = {Radiology},
month = {apr},
number = {2},
pages = {574--582},
publisher = {Radiological Society of North America},
title = {{Deep Learning at Chest Radiography: Automated Classification of Pulmonary Tuberculosis by Using Convolutional Neural Networks}},
url = {https://doi.org/10.1148/radiol.2017162326},
volume = {284},
year = {2017}
}
@misc{WHO2022a,
author = {WHO},
title = {{Tuberculosis}},
url = {https://www.who.int/news-room/fact-sheets/detail/tuberculosis},
year = {2022}
}
@article{Almezhghwi2021a,
abstract = {Chest X-ray medical imaging technology allows the diagnosis of many lung diseases. It is known that this technology is frequently used in hospitals, and it is the most accurate way of detecting most thorax diseases. Radiologists examine these images to identify lung diseases; however, this process can require some time. In contrast, an automated artificial intelligence system could help radiologists detect lung diseases more accurately and faster. Therefore, we propose two artificial intelligence approaches for processing and identifying chest X-ray images to detect chest diseases from such images. We introduce two novel deep learning methods for fast and automated classification of chest X-ray images. First, we propose the use of support vector machines based on the AlexNet model. Second, we develop support vector machines based on the VGGNet16 method. Combined deep networks with a robust classifier have shown that the proposed methods outperform AlexNet and VGG16 deep learning approaches for the chest X-ray image classification tasks. The proposed AlexNet and VGGNet based SVM provide average area under the curve values of 98{\%} and 97{\%}, respectively, for twelve chest X-ray diseases.},
author = {Almezhghwi, Khaled and Serte, Sertan and Al-Turjman, Fadi},
doi = {10.1007/s11042-021-10907-y},
issn = {1573-7721},
journal = {Multimedia Tools and Applications},
number = {19},
pages = {29051--29065},
title = {{Convolutional neural networks for the classification of chest X-rays in the IoT era}},
url = {https://doi.org/10.1007/s11042-021-10907-y},
volume = {80},
year = {2021}
}
@misc{WHO,
author = {WHO},
title = {{Pneumonia in Children}},
url = {https://www.who.int/news-room/fact-sheets/detail/pneumonia{\#}:{~}:text=Pneumonia is a form of,painful and limits oxygen intake.}
}
@article{Hussain2021a,
abstract = {Background and Objective The Coronavirus 2019, or shortly COVID-19, is a viral disease that causes serious pneumonia and impacts our different body parts from mild to severe depending on patient's immune system. This infection was first reported in Wuhan city of China in December 2019, and afterward, it became a global pandemic spreading rapidly around the world. As the virus spreads through human to human contact, it has affected our lives in a devastating way, including the vigorous pressure on the public health system, the world economy, education sector, workplaces, and shopping malls. Preventing viral spreading requires early detection of positive cases and to treat infected patients as quickly as possible. The need for COVID-19 testing kits has increased, and many of the developing countries in the world are facing a shortage of testing kits as new cases are increasing day by day. In this situation, the recent research using radiology imaging (such as X-ray and CT scan) techniques can be proven helpful to detect COVID-19 as X-ray and CT scan images provide important information about the disease caused by COVID-19 virus. The latest data mining and machine learning techniques such as Convolutional Neural Network (CNN) can be applied along with X-ray and CT scan images of the lungs for the accurate and rapid detection of the disease, assisting in mitigating the problem of scarcity of testing kits. Methods Hence a novel CNN model called CoroDet for automatic detection of COVID-19 by using raw chest X-ray and CT scan images have been proposed in this study. CoroDet is developed to serve as an accurate diagnostics for 2 class classification (COVID and Normal), 3 class classification (COVID, Normal, and non-COVID pneumonia), and 4 class classification (COVID, Normal, non-COVID viral pneumonia, and non-COVID bacterial pneumonia). Results The performance of our proposed model was compared with ten existing techniques for COVID detection in terms of accuracy. A classification accuracy of 99.1{\%} for 2 class classification, 94.2{\%} for 3 class classification, and 91.2{\%} for 4 class classification was produced by our proposed model, which is obviously better than the state-of-the-art-methods used for COVID-19 detection to the best of our knowledge. Moreover, the dataset with x-ray images that we prepared for the evaluation of our method is the largest datasets for COVID detection as far as our knowledge goes. Conclusion The experimental results of our proposed method CoroDet indicate the superiority of CoroDet over the existing state-of-the-art-methods. CoroDet may assist clinicians in making appropriate decisions for COVID-19 detection and may also mitigate the problem of scarcity of testing kits.},
author = {Hussain, Emtiaz and Hasan, Mahmudul and Rahman, Md Anisur and Lee, Ickjai and Tamanna, Tasmi and Parvez, Mohammad Zavid},
doi = {https://doi.org/10.1016/j.chaos.2020.110495},
issn = {0960-0779},
journal = {Chaos, Solitons {\&} Fractals},
keywords = {Accuracy,COVID-19,Confusion matrix,Convolutional neural network,Deep learning,Pneumonia-bacterial,Pneumonia-viral,X-ray},
pages = {110495},
title = {{CoroDet: A deep learning based classification for COVID-19 detection using chest X-ray images}},
url = {https://www.sciencedirect.com/science/article/pii/S0960077920308870},
volume = {142},
year = {2021}
}
@article{MITRA2021153649,
abstract = {Background
Indole alkaloids are very promising for potential therapeutic purposes and appear to be particularly effective against respiratory diseases. Several experimental studies have been performed, both in vivo and in vitro, to evaluate the effectiveness of indole alkaloids for the management of respiratory disorders, including asthma, emphysema, tuberculosis, cancer, and pulmonary fibrosis.
Purpose
The fundamental objective of this review was to summarize the in-depth therapeutic potential of indole alkaloids against various respiratory disorders.
Study design
In addition to describing the therapeutic potential, this review also evaluates the toxicity of these alkaloids, which have been utilized for therapeutic benefits but have demonstrated toxic consequences. Some indole alkaloids, including scholaricine, 19-epischolaricine, vallesamine, and picrinine, which are derived from the plant Alstonia scholaris, have shown toxic effects in non-rodent models.
Methods
This review also discusses clinical studies exploring the therapeutic efficacy of indole alkaloids, which have confirmed the promising benefits observed in vivo and in vitro.
Results
The indole alkaloidal compounds have shown efficacy in subjects with respiratory diseases.
Conclusion
The available data established both preclinical and clinical studies confirm the potential of indole alkaloids to treat the respiratory disorders.},
author = {Mitra, Saikat and Prova, Shajuthi Rahman and Sultana, Sifat Ara and Das, Rajib and Nainu, Firzan and Emran, Talha Bin and Tareq, Abu Montakim and Uddin, Md. Sahab and Alqahtani, Ali M and Dhama, Kuldeep and Simal-Gandara, Jesus},
doi = {https://doi.org/10.1016/j.phymed.2021.153649},
issn = {0944-7113},
journal = {Phytomedicine},
keywords = {Asthma,Indole alkaloids,Lung cancer,Pulmonary fibrosis,Respiratory diseases},
pages = {153649},
title = {{Therapeutic potential of indole alkaloids in respiratory diseases: A comprehensive review}},
url = {https://www.sciencedirect.com/science/article/pii/S0944711321001926},
volume = {90},
year = {2021}
}
@article{s18051530,
abstract = {Recent research has shown that the ubiquitous use of cameras and voice monitoring equipment in a home environment can raise privacy concerns and affect human mental health. This can be a major obstacle to the deployment of smart home systems for elderly or disabled care. This study uses a social robot to detect embarrassing situations. Firstly, we designed an improved neural network structure based on the You Only Look Once (YOLO) model to obtain feature information. By focusing on reducing area redundancy and computation time, we proposed a bounding-box merging algorithm based on region proposal networks (B-RPN), to merge the areas that have similar features and determine the borders of the bounding box. Thereafter, we designed a feature extraction algorithm based on our improved YOLO and B-RPN, called F-YOLO, for our training datasets, and then proposed a real-time object detection algorithm based on F-YOLO (RODA-FY). We implemented RODA-FY and compared models on our MAT social robot. Secondly, we considered six types of situations in smart homes, and developed training and validation datasets, containing 2580 and 360 images, respectively. Meanwhile, we designed three types of experiments with four types of test datasets composed of 960 sample images. Thirdly, we analyzed how a different number of training iterations affects our prediction estimation, and then we explored the relationship between recognition accuracy and learning rates. Our results show that our proposed privacy detection system can recognize designed situations in the smart home with an acceptable recognition accuracy of 94.48{\%}. Finally, we compared the results among RODA-FY, Inception V3, and YOLO, which indicate that our proposed RODA-FY outperforms the other comparison models in recognition accuracy.},
author = {Yang, Guanci and Yang, Jing and Sheng, Weihua and Junior, Francisco Erivaldo Fernandes and Li, Shaobo},
doi = {10.3390/s18051530},
issn = {1424-8220},
journal = {Sensors},
number = {5},
title = {{Convolutional Neural Network-Based Embarrassing Situation Detection under Camera for Social Robot in Smart Homes}},
url = {https://www.mdpi.com/1424-8220/18/5/1530},
volume = {18},
year = {2018}
}
@inproceedings{9451726,
author = {G, Sreena V and Ponraj, Narain and L, Deepa P},
booktitle = {2021 3rd International Conference on Signal Processing and Communication (ICPSC)},
doi = {10.1109/ICSPC51351.2021.9451726},
pages = {54--58},
title = {{Study on Public Chest X-ray Data sets for Lung Disease Classification}},
year = {2021}
}
@inproceedings{9718847,
author = {Li, Yinglong},
booktitle = {2022 IEEE 2nd International Conference on Power, Electronics and Computer Applications (ICPECA)},
doi = {10.1109/ICPECA53709.2022.9718847},
pages = {994--999},
title = {{Research and Application of Deep Learning in Image Recognition}},
year = {2022}
}
@article{9841572,
author = {Mehrrotraa, Rajat and Ansari, M A and Agrawal, Rajeev and Tripathi, Pragati and {Bin Heyat}, Md Belal and Al-Sarem, Mohammed and Muaad, Abdullah Yahya Mohammed and Nagmeldin, Wamda Abdelrahman Elhag and Abdelmaboud, Abdelzahir and Saeed, Faisal},
doi = {10.1109/ACCESS.2022.3194152},
journal = {IEEE Access},
pages = {85442--85458},
title = {{Ensembling of Efficient Deep Convolutional Networks and Machine Learning Algorithms for Resource Effective Detection of Tuberculosis Using Thoracic (Chest) Radiography}},
volume = {10},
year = {2022}
}
@article{KIZNYGORDON2021S40,
abstract = {The World Health Organization (WHO) estimates that around 10 million people develop tuberculosis (TB) every year, with 1.5 million deaths attributed to TB in 2019 (World Health Organization, 2020). The majority of the disease burden occurs in low-income countries, where access to diagnostics and tailored treatment remains problematic. The current COVID-19 pandemic further threatens to impact global TB control by diverting resources, reducing notifications and hence significantly increasing deaths attributable to TB (World Health Organization, 2020). Whole genome sequencing (WGS) is becoming increasingly accessible, and has particular value in the diagnosis and management of TB disease (Cabibbe et al., 2018; Meehan et al., 2019). Not only does it have the potential to give more rapid and complete information on drug-resistance, but the high discriminatory power it offers allows detection of clusters and transmission pathways, as well as likely contamination events, mixed infections and to differentiate between re-infection and relapse with much greater confidence than previous typing methods.},
annote = {Commemorating World Tuberculosis Day March 24th, 2021: “The Clock is Ticking”},
author = {{Kizny Gordon}, Alice and Marais, Ben and Walker, Timothy M and Sintchenko, Vitali},
doi = {https://doi.org/10.1016/j.ijid.2021.02.114},
issn = {1201-9712},
journal = {International Journal of Infectious Diseases},
keywords = {Multidrug-resistance,Whole genome sequencing},
pages = {S40--S42},
title = {{Clinical and public health utility of Mycobacterium tuberculosis whole genome sequencing}},
url = {https://www.sciencedirect.com/science/article/pii/S1201971221002009},
volume = {113},
year = {2021}
}
@article{ALSHMRANI2022,
abstract = {In 2019, the world experienced the rapid outbreak of the Covid-19 pandemic creating an alarming situation worldwide. The virus targets the respiratory system causing pneumonia with other symptoms such as fatigue, dry cough, and fever which can be mistakenly diagnosed as pneumonia, lung cancer, or TB. Thus, the early diagnosis of COVID-19 is critical since the disease can provoke patients' mortality. Chest X-ray (CXR) is commonly employed in healthcare sector where both quick and precise diagnosis can be supplied. Deep learning algorithms have proved extraordinary capabilities in terms of lung diseases detection and classification. They facilitate and expedite the diagnosis process and save time for the medical practitioners. In this paper, a deep learning (DL) architecture for multi-class classification of Pneumonia, Lung Cancer, tuberculosis (TB), Lung Opacity, and most recently COVID-19 is proposed. Tremendous CXR images of 3615 COVID-19, 6012 Lung opacity, 5870 Pneumonia, 20,000 lung cancer, 1400 tuberculosis, and 10,192 normal images were resized, normalized, and randomly split to fit the DL requirements. In terms of classification, we utilized a pre-trained model, VGG19 followed by three blocks of convolutional neural network (CNN) as a feature extraction and fully connected network at the classification stage. The experimental results revealed that our proposed VGG19 + CNN outperformed other existing work with 96.48 {\%} accuracy, 93.75 {\%} recall, 97.56 {\%} precision, 95.62 {\%} F1 score, and 99.82 {\%} area under the curve (AUC). The proposed model delivered superior performance allowing healthcare practitioners to diagnose and treat patients more quickly and efficiently.},
author = {Alshmrani, Goram Mufarah M and Ni, Qiang and Jiang, Richard and Pervaiz, Haris and Elshennawy, Nada M},
doi = {https://doi.org/10.1016/j.aej.2022.10.053},
issn = {1110-0168},
journal = {Alexandria Engineering Journal},
keywords = {COVID-19,Deep learning,Lung cancer,Lung opacity,Multiclass diseases classification,Pneumonia,TB,VGG19 +CNN,X-ray images},
title = {{A deep learning architecture for multi-class lung diseases classification using chest X-ray (CXR) images}},
url = {https://www.sciencedirect.com/science/article/pii/S1110016822007104},
year = {2022}
}


@article{Pune2016a,
author = {Pune, Engineering and Pune, V I T},
file = {:C$\backslash$:/Users/iradspm/Downloads/Automatic{\_}detection{\_}of{\_}major{\_}lung{\_}diseases{\_}using{\_}Chest{\_}Radiographs{\_}and{\_}classification{\_}by{\_}feed-forward{\_}artificial{\_}neural{\_}network.pdf:pdf},
isbn = {9781467385879},
keywords = {-art ijici al,feature extraction,lung cancer,pneumonia,radiographs},
pages = {16--20},
title = {{Automatie Deteetion ofMajor Lung Diseases U sing Chest Radiographs and Classifieation by Feed-forward Artifieial Neural Network}},
year = {2016}
}
@article{SAIKOUSHIK2021109153,
title = {Detection of respiratory diseases from chest X rays using Nesterov accelerated adaptive moment estimation},
journal = {Measurement},
volume = {176},
pages = {109153},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2021.109153},
url = {https://www.sciencedirect.com/science/article/pii/S0263224121001779},
author = {S.S. {Sai Koushik} and K.G. Srinivasa},
keywords = {Augmentation, Confusion Matrix, Convolutions, Deep Learning, Neural Networks, Transfer Learning},
abstract = {Recent developments in the field of machine learning have led to drastic improvements in medical diagnosis. Identification of different medical conditions with high accuracy is possible through machine learning, specifically deep learning. Convolutional Neural Networks are a subset of deep neural networks, used in investigating visual images. In this study, a method to identify bacterial pneumonia, viral pneumonia and COVID-19 from chest X-rays is proposed using convolutional neural networks. Training accuracy of 0.9440 and validation accuracy of 0.9356 was obtained using this model. The test accuracy was found to be 0.8753. As a matter of fact, COVID-19 diagnosing precision and recall of the proposed method are 0.95 and 1.00 respectively. Significant improvements are seen when compared to other approaches.}
}
@article{sittig2012electronic,
  title={Electronic health records and national patient-safety goals},
  author={Sittig, Dean F and Singh, Hardeep},
  journal={The New England journal of medicine},
  volume={367},
  number={19},
  pages={1854},
  year={2012},
  publisher={NIH Public Access}
}
@article{bowman2013impact,
  title={Impact of electronic health record systems on information integrity: quality and safety implications},
  author={Bowman, Sue},
  journal={Perspectives in health information management},
  volume={10},
  number={Fall},
  year={2013},
  publisher={American Health Information Management Association}
}
@article{jiang2017artificial,
  title={Artificial intelligence in healthcare: past, present and future},
  author={Jiang, Fei and Jiang, Yong and Zhi, Hui and Dong, Yi and Li, Hao and Ma, Sufeng and Wang, Yilong and Dong, Qiang and Shen, Haipeng and Wang, Yongjun},
  journal={Stroke and vascular neurology},
  volume={2},
  number={4},
  year={2017},
  publisher={BMJ Specialist Journals}
}
@article{wurm2008telemedicine,
  title={Telemedicine and teledermatology: past, present and future},
  author={Wurm, Elisabeth MT and Hofmann-Wellenhof, Rainer and Wurm, Robert and Soyer, Hans Peter},
  journal={JDDG: Journal Der Deutschen Dermatologischen Gesellschaft},
  volume={6},
  number={2},
  pages={106--112},
  year={2008},
  publisher={Wiley Online Library}
}
@inproceedings{zhou2017fine,
  title={Fine-tuning convolutional neural networks for biomedical image analysis: actively and incrementally},
  author={Zhou, Zongwei and Shin, Jae and Zhang, Lei and Gurudu, Suryakanth and Gotway, Michael and Liang, Jianming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7340--7351},
  year={2017}
}
@ARTICLE{9134370,
  author={Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing},
  journal={Proceedings of the IEEE}, 
  title={A Comprehensive Survey on Transfer Learning}, 
  year={2021},
  volume={109},
  number={1},
  pages={43-76},
  doi={10.1109/JPROC.2020.3004555}}

  @article{perez2017effectiveness,
  title={The effectiveness of data augmentation in image classification using deep learning},
  author={Perez, Luis and Wang, Jason},
  journal={arXiv preprint arXiv:1712.04621},
  year={2017}
}
@inproceedings{long2015learning,
  title={Learning transferable features with deep adaptation networks},
  author={Long, Mingsheng and Cao, Yue and Wang, Jianmin and Jordan, Michael},
  booktitle={International conference on machine learning},
  pages={97--105},
  year={2015},
  organization={PMLR}
}
@article{shin2016deep,
  title={Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning},
  author={Shin, Hoo-Chang and Roth, Holger R and Gao, Mingchen and Lu, Le and Xu, Ziyue and Nogues, Isabella and Yao, Jianhua and Mollura, Daniel and Summers, Ronald M},
  journal={IEEE transactions on medical imaging},
  volume={35},
  number={5},
  pages={1285--1298},
  year={2016},
  publisher={IEEE}
}
@article{krizhevsky2017imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Communications of the ACM},
  volume={60},
  number={6},
  pages={84--90},
  year={2017},
  publisher={AcM New York, NY, USA}
}

@book{goodfellow2016deep,
title={Deep Learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
year={2016},
publisher={MIT Press}
}

@article{lecun2015deep,
title={Deep learning},
author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
journal={Nature},
volume={521},
number={7553},
pages={436--444},
year={2015},
publisher={Nature Publishing Group}
}

@article{schmidhuber2015deep,
title={Deep learning in neural networks: An overview},
author={Schmidhuber, J{"u}rgen},
journal={Neural Networks},
volume={61},
pages={85--117},
year={2015},
publisher={Elsevier}
}

@article{simonyan2015very,
title={Very deep convolutional networks for large-scale image recognition},
author={Simonyan, Karen and Zisserman, Andrew},
journal={arXiv preprint arXiv:1409.1556},
year={2015}
}

@book{graves2012supervised,
title={Supervised Sequence Labelling with Recurrent Neural Networks},
author={Graves, Alex},
year={2012},
publisher={Springer}
}
@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{simonyan2015very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2015}
}

@inproceedings{szegedy2017inception,
  title={Inception-v4, inception-resnet and the impact of residual connections on learning},
  author={Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alex},
  booktitle={AAAI},
  pages={4278--4284},
  year={2017}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@inproceedings{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}
@article{pan2010survey,
  title={A survey on transfer learning},
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={22},
  number={10},
  pages={1345--1359},
  year={2010},
  publisher={IEEE}
}
@article{goddard1984computed,
title={Computed tomography in pulmonary emphysema},
author={Goddard, P. R. and Nicholson, E. M. and Laszlo, G. and Watt, I. and Hutchinson, T. A.},
journal={Clinical radiology},
volume={35},
number={4},
pages={317--325},
year={1984},
}

@article{henschke2002ct,
title={CT screening for lung cancer: past and ongoing studies},
author={Henschke, C. I. and Yankelevitz, D. F. and Mirtcheva, R.},
journal={Lung cancer},
volume={38},
pages={S23--S26},
year={2002},
}

@article{ohno2014magnetic,
title={Magnetic resonance imaging of the lung: recent advances},
author={Ohno, Y. and Koyama, H. and Onishi, Y.},
journal={Magnetic resonance imaging clinics of North America},
volume={22},
number={2},
pages={255--273},
year={2014},
}

@article{kalemkerian2018molecular,
title={Molecular diagnostics for lung cancer: Adenocarcinoma, squamous cell carcinoma, and malignant pleural mesothelioma},
author={Kalemkerian, G. P. and Ettinger, D. S. and Mason, D. P.},
journal={Clinical lung cancer},
volume={19},
number={5},
pages={336--344},
year={2018},
}
@article{abbas2020chest,
  title={Chest X-ray in COVID-19: a key parameter?},
  author={Abbas, Abdullah and Abdalwahab, Ahmad and Al-Maslamani, Mohammed},
  journal={Future virology},
  volume={15},
  number={10},
  pages={623--630},
  year={2020},
  publisher={Future Medicine Ltd}
}

@article{ozturk2020automated,
  title={Automated detection of COVID-19 cases using deep neural networks with X-ray images},
  author={Ozturk, Tulin and Talo, Muhammed and Yildirim, Omer Akgun and Baloglu, Ulas Bilgen and Yildirim, Ozal and Acharya, U Rajendra},
  journal={Computers in Biology and Medicine},
  volume={121},
  pages={103792},
  year={2020},
  publisher={Elsevier}
}

@article{pan2020chest,
  title={Chest imaging appearance of COVID-19 infection},
  author={Pan, Yuxin and Guan, Huashi and Zhou, Shuchang and Wang, Yuting and Li, Qian and Zhu, Tengfei and Hu, Qian and Xia, Liming},
  journal={Radiology: Cardiothoracic Imaging},
  volume={2},
  number={1},
  pages={e200028},
  year={2020},
  publisher={Radiological Society of North America}
}

@article{salgame2020imaging,
  title={Imaging in tuberculosis},
  author={Salgame, Padmini and Geadas, Catherine},
  journal={Cold Spring Harbor perspectives in medicine},
  volume={10},
  number={6},
  pages={a038944},
  year={2020},
  publisher={Cold Spring Harbor Laboratory Press}
}

@article{wong2020chest,
  title={Chest radiographic patterns and differential diagnoses of lung opacity},
  author={Wong, Kenneth TC and Antonio, Grace E},
  journal={Radiologic clinics},
  volume={58},
  number={3},
  pages={461--480},
  year={2020},
  publisher={Elsevier}
}
@article{wang2020covid,
  title={COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images},
  author={Wang, Linda and Wong, Alexander},
  journal={IEEE Transactions on Medical Imaging},
  volume={39},
  number={8},
  pages={2515--2525},
  year={2020},
  publisher={IEEE}
}

@article{ghassemi2020using,
  title={Using transfer learning to improve mammogram breast cancer risk prediction},
  author={Ghassemi, Mohammad and Greiner, Russell and Jin, Panayiotis and Aucoin, Nicole and Patel, Vatsal and Sahiner, Berkman and Erickson, Bradley J},
  journal={IEEE Journal of Biomedical and Health Informatics},
  volume={24},
  number={7},
  pages={2065--2074},
  year={2020},
  publisher={IEEE}
}

@article{tajbakhsh2016convolutional,
  title={Convolutional neural networks for medical image analysis: full training or fine tuning?},
  author={Tajbakhsh, Nima and Shin, Jae Y and Gurudu, Suryakanth R and Hurst, R Todd and Kendall, William L and Gotway, Michael B and Liang, Jianming},
  journal={IEEE transactions on medical imaging},
  volume={35},
  number={5},
  pages={1299--1312},
  year={2016},
  publisher={IEEE}
}

@article{li2020artificial,
  title={Artificial intelligence distinguishes COVID-19 from community acquired pneumonia on chest CT},
  author={Li, Lin and Qin, Lixin and Xu, Zeguo and Yin, Youbing and Wang, Xin and Kong, Bin and Bai, Jie and Lu, Yubing and Fang, Zhenghan and Song, Qiuyu and others},
  journal={Radiology},
  volume={296},
  number={2},
  pages={E65--E71},
  year={2020},
  publisher={Radiological Society of North America}
}

@article{vaid2020automated,
  title={Automated detection of COVID-19 cases using deep neural networks with X-ray images},
  author={Vaid, Shashank and Somaiya, Neeraj and Sharma, Dhruv and Bhandari, Manik},
  journal={Biocybernetics and Biomedical Engineering},
  volume={40},
  number={4},
  pages={1391--1405},
  year={2020},
  publisher={Elsevier}
}

@article{wang2021chest,
  title={Chest radiography-based deep learning model for detecting COVID-19},
  author={Wang, Zhaohua and Chen, Zhenguo and Hu, Junjie and Zhang, Zhihui and Zhong, Lilin and Wang, Xiangdong and Zhao, Yu},
  journal={Diagn Interv Radiol},
  volume={27},
  number={3},
  pages={298--305},
  year={2021},
  publisher={Turkish Society of Radiology}
}
@article{minaee2020deep,
  title={Deep-COVID: Predicting COVID-19 From Chest X-Ray Images Using Deep Transfer Learning},
  author={Minaee, Shervin and Kafieh, Rahele and Sonka, Milan and Yazdani, Saeed and Soufi, Gholamreza},
  journal={arXiv preprint arXiv:2004.09363},
  year={2020}
}
@article{apostolopoulos2020covid,
  title={COVID-19: A comparative study of deep learning approaches for detection and diagnosis},
  author={Apostolopoulos, Ioannis D and Aznaouridis, Stamatios I and Tzani, Maria A},
  journal={medRxiv},
  year={2020},
  publisher={Cold Spring Harbor Laboratory Press}
}
@article{chowdhury2020can,
  title={Can AI help in screening viral and COVID-19 pneumonia?},
  author={Chowdhury, Mohammad Emtiyaz Khan and Rahman, Tasnim and Khandakar, Amith Kumar and Mazhar, Riad and Kadir, Muhammad Abdul},
  journal={IEEE Access},
  volume={8},
  pages={132665--132676},
  year={2020},
  publisher={IEEE}
}
@article{zhang2021automated,
  title={Automated detection of COVID-19 from chest X-ray using transfer learning with convolutional neural networks},
  author={Zhang, Jianxing and Xie, Yong and Li, Yuchen and Shen, Chen and Xia, Yang and Guo, Xiaohui and Wang, Li and Liang, Weimin},
  journal={Journal of X-Ray Science and Technology},
  volume={29},
  number={3},
  pages={405--417},
  year={2021},
  publisher={IOS Press}
}

@inproceedings{simonyan2015very,
title={Very deep convolutional networks for large-scale image recognition},
author={Simonyan, Karen and Zisserman, Andrew},
booktitle={Proceedings of the international conference on learning representations},
year={2015}
}

@inproceedings{he2016deep,
title={Deep residual learning for image recognition},
author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
pages={770--778},
year={2016}
}

@inproceedings{huang2017densely,
title={Densely connected convolutional networks},
author={Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q.},
booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
pages={4700--4708},
year={2017}
}

@inproceedings{szegedy2016rethinking,
title={Rethinking the inception architecture for computer vision},
author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
pages={2818--2826},
year={2016}
}
@article{ardila2019end,
title={End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography},
author={Ardila, Daniel and Kiraly, Adam P and Bharadwaj, Shravya and Choi, Brian and Reicher, Jacob J and Peng, Lily and Tse, Daniel and Etemadi, Mozziyar and Ye, Wenlu and Corrado, Greg S and others},
journal={Nature Medicine},
volume={25},
number={6},
pages={954--961},
year={2019},
publisher={Nature Publishing Group}
}

@article{liu2019deep,
title={Deep learning model for diagnosis of pulmonary embolism on computed tomography pulmonary angiography},
author={Liu, Yi and Wang, Heng and Li, Lei and Tian, Zhiqiang and Gu, Jian and Chen, Lin},
journal={Radiology},
volume={290},
number={1},
pages={520--528},
year={2019},
publisher={Radiological Society of North America}
}

@article{wang2020tailored,
title={COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest Radiography Images},
author={Wang, Linda and Wong, Alexander},
journal={IEEE Transactions on Medical Imaging},
volume={39},
number={8},
pages={2515--2525},
year={2020},
publisher={IEEE}
}

@article{gong2019predicting,
title={Predicting lung function using convolutional neural networks from CT images},
author={Gong, Lequan and Zhang, Jing and Yang, Guanyu and Chen, Lin and Shi, Jianping and Zheng, Gang},
journal={Scientific Reports},
volume={9},
number={1},
pages={14440},
year={2019},
publisher={Nature Publishing Group}
}
@article{wang2020densenet,
  title={DenseNet-based classification models for COVID-19 detection using chest X-ray images},
  author={Wang, Linda and Lin, Zhong Qiu and Wong, Alexander},
  journal={PeerJ Computer Science},
  volume={6},
  number={1},
  pages={e523},
  year={2020},
  doi={10.7717/peerj-cs.523}
}
@INPROCEEDINGS{4633969,
  author={Haibo He and Yang Bai and Garcia, Edwardo A. and Shutao Li},
  booktitle={2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)}, 
  title={ADASYN: Adaptive synthetic sampling approach for imbalanced learning}, 
  year={2008},
  volume={},
  number={},
  pages={1322-1328},
  doi={10.1109/IJCNN.2008.4633969}}
@article{blagus2013smote,
  title={SMOTE for high-dimensional class-imbalanced data},
  author={Blagus, Rok and Lusa, Lara},
  journal={BMC bioinformatics},
  volume={14},
  pages={1--16},
  year={2013},
  publisher={Springer}
}
@article{mamalakis2021denrescov,
  title={DenResCov-19: A deep transfer learning network for robust automatic classification of COVID-19, pneumonia, and tuberculosis from X-rays},
  author={Mamalakis, Michail and Swift, Andrew J and Vorselaars, Bart and Ray, Surajit and Weeks, Simonne and Ding, Weiping and Clayton, Richard H and Mackenzie, Louise S and Banerjee, Abhirup},
  journal={Computerized Medical Imaging and Graphics},
  volume={94},
  pages={102008},
  year={2021},
  publisher={Elsevier}
}
@inproceedings{katsamenis2020transfer,
  title={Transfer learning for COVID-19 pneumonia detection and classification in chest X-ray images},
  author={Katsamenis, Iason and Protopapadakis, Eftychios and Voulodimos, Athanasios and Doulamis, Anastasios and Doulamis, Nikolaos},
  booktitle={24th Pan-Hellenic Conference on Informatics},
  pages={170--174},
  year={2020}
}

@article{boudrioua2020covid,
  title={COVID-19 detection from chest X-ray images using CNNs models: Further evidence from Deep Transfer Learning},
  author={Boudrioua, Mohamed Samir},
  journal={Boudrioua, Mohamed Samir (2020)" COVID-19 Detection from Chest X-ray Images using CNNs Models: Further Evidence from Deep Transfer Learning," The University of Louisville Journal of Respiratory Infections},
  volume={4},
  number={1},
  year={2020}
}
@article{gianchandani2020rapid,
  title={Rapid COVID-19 diagnosis using ensemble deep transfer learning models from chest radiographic images},
  author={Gianchandani, Neha and Jaiswal, Aayush and Singh, Dilbag and Kumar, Vijay and Kaur, Manjit},
  journal={Journal of ambient intelligence and humanized computing},
  pages={1--13},
  year={2020},
  publisher={Springer}
}
@article{venkataramana2022classification,
  title={Classification of COVID-19 from tuberculosis and pneumonia using deep learning techniques},
  author={Venkataramana, Lokeswari and Prasad, D Venkata Vara and Saraswathi, S and Mithumary, CM and Karthikeyan, R and Monika, N},
  journal={Medical \& Biological Engineering \& Computing},
  volume={60},
  number={9},
  pages={2681--2691},
  year={2022},
  publisher={Springer}
}
@article{wentzell2018learning,
  title={E-learning for chest x-ray interpretation improves medical student skills and confidence levels},
  author={Wentzell, S and Moran, L and Dobranowski, J and Levinson, A and Hannigan, A and Dunne, CP and McGrath, D},
  journal={BMC Medical Education},
  volume={18},
  pages={1--8},
  year={2018},
  publisher={Springer}
}
@article{mehta2021classification,
  title={Classification of X-ray images into COVID-19, pneumonia, and TB using cGAN and fine-tuned deep transfer learning models},
  author={Mehta, Tirth and Mehendale, Ninad},
  journal={Research on Biomedical Engineering},
  volume={37},
  pages={803--813},
  year={2021},
  publisher={Springer}
}
@article{keskar2017improving,
  title={Improving generalization performance by switching from adam to sgd},
  author={Keskar, Nitish Shirish and Socher, Richard},
  journal={arXiv preprint arXiv:1712.07628},
  year={2017}
}
@article{rahman2020reliable,
  title={Reliable tuberculosis detection using chest X-ray with deep learning, segmentation and visualization},
  author={Rahman, Tawsifur and Khandakar, Amith and Kadir, Muhammad Abdul and Islam, Khandaker Rejaul and Islam, Khandakar F and Mazhar, Rashid and Hamid, Tahir and Islam, Mohammad Tariqul and Kashem, Saad and Mahbub, Zaid Bin and others},
  journal={IEEE Access},
  volume={8},
  pages={191586--191601},
  year={2020},
  publisher={IEEE}
}
@article{kavya2022detecting,
  title={Detecting Covid19 and pneumonia from chest X-ray images using deep convolutional neural networks},
  author={Kavya, Nallamothu Sri and Veeranjaneyulu, N and Priya, D Divya and others},
  journal={Materials Today: Proceedings},
  volume={64},
  pages={737--743},
  year={2022},
  publisher={Elsevier}
}
@article{chowdhury2020can,
  title={Can AI help in screening viral and COVID-19 pneumonia?},
  author={Chowdhury, Muhammad EH and Rahman, Tawsifur and Khandakar, Amith and Mazhar, Rashid and Kadir, Muhammad Abdul and Mahbub, Zaid Bin and Islam, Khandakar Reajul and Khan, Muhammad Salman and Iqbal, Atif and Al Emadi, Nasser and others},
  journal={Ieee Access},
  volume={8},
  pages={132665--132676},
  year={2020},
  publisher={IEEE}
}
@article{rahman2021exploring,
  title={Exploring the effect of image enhancement techniques on COVID-19 detection using chest X-ray images},
  author={Rahman, Tawsifur and Khandakar, Amith and Qiblawey, Yazan and Tahir, Anas and Kiranyaz, Serkan and Kashem, Saad Bin Abul and Islam, Mohammad Tariqul and Al Maadeed, Somaya and Zughaier, Susu M and Khan, Muhammad Salman and others},
  journal={Computers in biology and medicine},
  volume={132},
  pages={104319},
  year={2021},
  publisher={Elsevier}
}
@inproceedings{faruk2021residualcovid,
  title={Residualcovid-net: An interpretable deep network to screen covid-19 utilizing chest ct images},
  author={Faruk, Md Farukuzzaman},
  booktitle={2021 3rd International Conference on Electrical \& Electronic Engineering (ICEEE)},
  pages={69--72},
  year={2021},
  organization={IEEE}
}
@article{lujan2020transfer,
  title={A transfer learning method for pneumonia classification and visualization},
  author={Luj{\'a}n-Garc{\'\i}a, Juan Eduardo and Y{\'a}{\~n}ez-M{\'a}rquez, Cornelio and Villuendas-Rey, Yenny and Camacho-Nieto, Oscar},
  journal={Applied Sciences},
  volume={10},
  number={8},
  pages={2908},
  year={2020},
  publisher={MDPI}
}