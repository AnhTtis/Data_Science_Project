\section*{Appendix}

\section{Derivation of Equation~\ref{eq:Ulearning}}\label{ap:U1}
    \begin{align}
        \Uprior{}(x) &= \int_y \int_\phi \log{\left( \frac{\pprior{\phi \vert y, x}}{\pprior{\phi}} \right)} ~ \pprior{\phi \vert y, x} ~ \ppop{y \vert x} \nonumber \\
        &= \int_y \int_\phi \log{\left( \frac{\pprior{y \vert x, \phi}}{\pprior{y \vert x}} \right)} ~ \pprior{\phi \vert y, x} ~ \ppop{y \vert x} \nonumber \\
        &= \int_y \int_\phi \log{\left( \pprior{y \vert x, \phi} \right)} - \log{\left( \pprior{y \vert x} \right)} ~ \pprior{\phi \vert y, x} ~ \ppop{y \vert x} \nonumber \\
        &= \int_y \int_\phi \log{\left( \pprior{y \vert x, \phi} \right)} ~ \pprior{\phi \vert y, x} ~ \ppop{y \vert x} - \int_y \log{\left( \pprior{y \vert x} \right)} ~ \ppop{y \vert x} \nonumber \\
        &= \Ent{\cond{\True{\RV{Y}}}{x} ~ \vert \vert ~ \cond{\Sp{\RV{Y}}}{x}} + \int_y \int_\phi \log{\left( \pprior{y \vert x, \phi} \right)} ~ \pprior{\phi \vert y, x} ~ \ppop{y \vert x} \nonumber \\
        &= \Ent{\cond{\True{\RV{Y}}}{x}} + \KLD{\cond{\True{\RV{Y}}}{x}}{\cond{\Sp{\RV{Y}}}{x}} + \int_y \int_\phi \log{\left( \pprior{y \vert x, \phi} \right)} ~ \pprior{\phi \vert y, x} ~ \ppop{y \vert x}
    \end{align}
    where $\Ent{\RV{X_1} ~ \vert \vert ~ \RV{X_2}}$ denotes the cross entropy of the distribution that characterizes the random variable $\RV{X_2}$, relative to the distribution that characterizes the random variable $\RV{X_1}$.

\section{Experimental results using linear probability measures}\label{ap:linearp}
    Figures \ref{fig:irt-results-linearp}--\ref{fig:memreten-model-linearp} reproduce Figures \ref{fig:irt-results}, \ref{fig:memreten-paramest-absolute} and \ref{fig:memreten-model-popunif}--\ref{fig:memreten-model-popcmpk}, respectively, with the values on the $y$-axis showing the average probability assigned to the true value of the focus, rather than the average log probability.

    \begin{figure}
        \caption{}
        \label{fig:irt-results-linearp}
        {\centering
            \begin{subfigure}{.48\linewidth}
                \caption{}
                \label{fig:irt-results-priorfixed-linearp}
                \includegraphics[width=\linewidth]{paramrobust-figs/irt-results-priorfixed-linearp}
            \end{subfigure}
                    
            \begin{subfigure}{.48\linewidth}
                \caption{}
                \label{fig:irt-results-popfixed2-linearp}
                \includegraphics[width=\linewidth]{paramrobust-figs/irt-results-popfixed2-linearp}
            \end{subfigure}\hfill\begin{subfigure}{.48\linewidth}
                \caption{}
                \label{fig:irt-results-popfixed0-linearp}
                \includegraphics[width=\linewidth]{paramrobust-figs/irt-results-popfixed0-linearp}
            \end{subfigure}
        }
        \notes{\textbf{(a)} Corresponds to Figure \ref{fig:irt-results-priorfixed}.
            This highlights that focal divergence in the low-$\theta$ population is both higher and on average in the right direction (divergence in the wrong direction contributes to the overall trend more when probabilities are logged, since the log operation exacerbates low probabilities).
            \textbf{(b)} Corresponds to Figure \ref{fig:irt-results-popfixed2}.
            \textbf{(c)} Corresponds to Figure \ref{fig:irt-results-popfixed0}.
        }
    \end{figure}

    \begin{figure}
        \caption{}
        \label{fig:memreten-paramest-linearp}
        \begin{subfigure}{\linewidth}
            \caption{}
            \label{fig:memreten-paramest-absolute-linearp}
            \includegraphics[width=\linewidth]{paramrobust-figs/memreten-paramest-absolute-linearp}
        \end{subfigure}
        \notes{Corresponds to Figure \ref{fig:memreten-paramest-absolute}.
        }
    \end{figure}

    \begin{figure}
        \caption{}
        \label{fig:memreten-model-linearp}
        \begin{subfigure}{.48\linewidth}
            \caption{}
            \label{fig:memreten-model-popunif-linearp}
            \includegraphics[width=\linewidth]{paramrobust-figs/memreten-model-popunif-linearp}
        \end{subfigure}\hfill\begin{subfigure}{.48\linewidth}
            \caption{}
            \label{fig:memreten-model-popcmpk-linearp}
            \includegraphics[width=\linewidth]{paramrobust-figs/memreten-model-popcmpk-linearp}
        \end{subfigure}
        \notes{\textbf{(a)} Corresponds to Figure \ref{fig:memreten-model-popunif}.
            \textbf{(b)} Corresponds to Figure \ref{fig:memreten-model-popcmpk}.
            Here, not taking the logs and thus not penalizing for extremely small values helps ADO, which tends to result in more extreme posterior probabilities than the fixed design.
        }
    \end{figure}

\section{Experimental results using the total entropy utility function}\label{ap:total-entropy}
    Section \ref{sec:total-ent} introduced the total entropy utility function.
    Figure \ref{fig:memreten-totalent} reproduces the experiments shown in Figures \ref{fig:memreten-model-popunif}--\ref{fig:memreten-model-popcmpk}, with the exception that the ADO experiments use the total entropy utility function.
    While it appears to make a difference in the experiments shown in Figure \ref{fig:memreten-totalent-popunif}, it actually appears to exacerbate the problem in Figure \ref{fig:memreten-totalent-popcmpk}.
    It therefore does not appear to be a consistent solution to the problem.

    \begin{figure}
        \caption{}
        \label{fig:memreten-totalent}
        \begin{subfigure}{.48\linewidth}
            \caption{}
            \label{fig:memreten-totalent-popunif}
            \includegraphics[width=\linewidth]{paramrobust-figs/memreten-totalent-popunif}
        \end{subfigure}\hfill\begin{subfigure}{.48\linewidth}
            \caption{}
            \label{fig:memreten-totalent-popcmpk}
            \includegraphics[width=\linewidth]{paramrobust-figs/memreten-totalent-popcmpk}
        \end{subfigure}
        \notes{Memory retention models (total entropy): Empirical results.
            Absolute performance across the course of the experiment.
            $x$-axes: Trial number.
            $y$-axes: $\log{\left( \pprior{m^*} \right)}$.
            Lines denote means, and shaded regions denote standard errors around those means (across $n =$ 2 models $\times$ 100 repetitions = 200 simulated experiments).
            \textbf{(a)} $\cond{\True{\RV{\Theta}}}{m}$ is uninformative in parameter space; $\cond{\Sp{\RV{\Theta}}}{m}$ is uninformative in data space, for all $m$.
            \textbf{(b)} $\cond{\True{\RV{\Theta}}}{m}$ is uninformative in data space; $\cond{\Sp{\RV{\Theta}}}{m}$ is uninformative in parameter space, for all $m$.
        }
    \end{figure}

\section{Upper-confidence bound global utility}\label{ap:UCB}
    In \S \ref{sec:novel-approaches}, we framed ADO's failures in the case of model selection under the more general framework of an exploration--exploitation dilemma.
    Here, we leverage our framework to suggest one way the global mutual information utility function could be modified to incorporate principles from UCB sampling, an approach for navigating this dilemma discussed in \S \ref{sec:novel-approaches}.

    A direct application of UCB in ADO would involve incorporating a measure of dispersion of the local utility values around the global utility.
    However, this would not be sufficient to address our motivating problem: Recall that our goal for ``exploration'' here is to challenge our pre-existing beliefs about the specified prior parameter distributions.
    First of all, notice that this na\"{i}ve application of UCB targets uncertainty in the utility values, which is not what we care about.
    Secondly, in the same way that the global utility (the expectation of the local utility) is calculated on the basis of the specified prior (Equation \ref{eq:U}), the most natural way to calculate the analogous second moment would also be on the basis of the specified prior.
    Thus, rather than challenging our beliefs about the priors, this approach would actually incorporate additional reliance on them.

    Nevertheless, we can leverage core principles of UCB --- maximizing an additive combination of an exploitation and exploration measure that dynamically adjusts over time --- to construct a decision-making policy that targets the dual goals of model selection and parameter estimation.
    As discussed, existing measures of global mutual information utility effectively exploit specified prior knowledge.
    To construct a UCB policy, we can directly use this as a measure of exploitation.
    As a measure of exploration, we seek a quantity that both reflects the degree to which we will learn about the parameter estimates, and shrinks as these estimates become more precise.

    With reference to our decomposition of the expected \obsU{} (Equation \ref{eq:Ulearning}), notice that the response variability and surprisal terms are shared by both the expected \obsU{} corresponding to model selection and to parameter estimation.
    If a decision-making policy for model selection selects stimuli that induce high response variability and/or surprisal, this will facilitate not only the explicit goal of model selection, but also the implicit goal of parameter estimation.
    Thus, together, response variability and surprisal achieve our first criterion for an appropriate measure of exploration: They reflect the degree to which the experimenter can be expected to learn about the parameter values.\footnote{
        Although recall from \S \ref{sec:uprior} the caveat that the effect of response variability on inference will depend on the source of the variability, i.e., whether it stems from uncertainty about the parameter value, or uncertainty about responses even conditioned on a particular parameter value.
    }
    Combined, these terms will also tend to achieve the second criterion: Surprisal, by definition, will shrink as the parameter estimates converge.

    Therefore, one could consider the combination of response variability and surprisal as an exploration measure.
    Equation \ref{eq:Ulearning-ucb} gives the corresponding expected \obsU{} function:
            
    \begin{align}\label{eq:Ulearning-ucb}
        U_{UCB}^1(x) &= \underbrace{\Uprior{}(x)}_{\mathrm{Exploitation ~ term}} + \underbrace{\Ent{\cond{\True{\RV{Y}}}{x}} + \KLD{\cond{\True{\RV{Y}}}{x}}{\cond{\Sp{\RV{Y}}}{x}}}_{\mathrm{Exploration ~ term}} \nonumber \\
        &= \Uprior{}(x) + \Ent{\cond{\True{\RV{Y}}}{x} ~ \vert \vert ~ \cond{\Sp{\RV{Y}}}{x}} \nonumber \\
        &= \int_y \int_\phi \left( \log{\left( \frac{\pprior{\cond{y}{x,\phi}}}{\pprior{\cond{y}{x}}} \right)} - \log{\left( \pprior{\cond{y}{x}} \right)} \right) ~ \pprior{\phi} ~ \ppop{\cond{y}{x}} \nonumber \\
        &= \int_y \int_\phi \log{\left( \frac{\pprior{\cond{y}{x,\phi}}}{\pprior{\cond{y}{x}}^2} \right)} ~ \pprior{\phi} ~ \ppop{\cond{y}{x}}
    \end{align}
    where $\Ent{\cond{\True{\RV{Y}}}{x} ~ \vert \vert ~ \cond{\Sp{\RV{Y}}}{x}}$ denotes the cross entropy of the predictive distribution relative to the response distribution.

    Of course, in practice we are not maximizing the expected \obsU{} (the expectation of the \obsU{} under the population prior), but rather the global utility (the expectation of the \obsU{} under the specified prior).
    Equation \ref{eq:U-ucb} gives the global utility function implied by Equation \ref{eq:Ulearning-ucb}, i.e., what one would actually maximize in practice:

    \begin{align}\label{eq:U-ucb}
        U_{UCB}(x) &= \int_\phi \int_y \log{\left( \frac{\pprior{\cond{\phi}{y,x}}}{\pprior{\phi} ~ \pprior{\cond{y}{x}}} \right)} ~ \pprior{\cond{y}{x,\phi}} ~ \pprior{\phi} \nonumber \\
        &= \int_\phi \int_y \log{\left( \frac{\pprior{\cond{y}{x,\phi}}}{\pprior{\cond{y}{x}}^2} \right)} ~ \pprior{\cond{y}{x,\phi}} ~ \pprior{\phi} \nonumber \\
        &= I \left( \Sp{\RV{\Phi}}; \cond{\Sp{\RV{Y}}}{x} \right) + \Ent{\cond{\Sp{\RV{Y}}}{x}}.
    \end{align}

    Equation \ref{eq:U-ucb} is an additive combination of the mutual information between $\Sp{\RV{\Phi}}$ and $\cond{\Sp{\RV{Y}}}{x}$, i.e., our original measure of global utility, and the entropy of $\cond{\Sp{\RV{Y}}}{x}$, a criterion used for an alternative sampling scheme known as uncertainty sampling \citep{lee_number-line_2021}.

    Both Equations \ref{eq:Ulearning-ucb} and \ref{eq:U-ucb} are written using the more generic notation of $\phi$, to emphasize their potential application in any case the value of the focus of interest does not completely identify the true data-generating distribution.
    For the problem of model selection, Equation \ref{eq:U-ucb} would more specifically become:

    \begin{align}
        U_{UCB}(x) &= I \left( \Sp{\RV{M}}; \cond{\Sp{\RV{Y}}}{x} \right) + \Ent{\cond{\Sp{\RV{Y}}}{x}} \nonumber \\
        &= \sum_{m \in M} \pprior{m} \int_\theta \int_y \log{\left( \frac{\pprior{\cond{y}{x,m}}}{\pprior{\cond{y}{x}}^2} \right)} ~ p(\cond{y}{x,\theta,m}) ~ \pprior{\cond{\theta}{m}}.
    \end{align}

    In other words, a relatively straightforward combination of two common sequential experimental design strategies --- one that targets mutual information, and one that targets uncertainty --- can be theoretically motivated to achieve the dual goals of model selection and parameter estimation in the presence of prior misinformation.