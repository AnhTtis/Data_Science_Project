\documentclass[acmlarge,prologue,table,xcdraw]{acmart}
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}







\usepackage{lettrine}

\usepackage{tcolorbox}
\usepackage{listings}
\usepackage{adjustbox}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{colortbl} 
\usepackage{hhline}
\definecolor{mygray}{gray}{0.8}


\usepackage{xcolor,color,soul,bm}

\usepackage{tikz}
\usetikzlibrary{backgrounds}



\newcommand{\ds}[1]{\sethlcolor{yellow}\hl{[Dimitris: #1]}}
\newcommand{\mc}[1]{\sethlcolor{lime}\hl{[Marios: #1]}}
\newcommand{\sy}[1]{\sethlcolor{cyan}\hl{[Sofia: #1]}}
\newcommand{\ot}[1]{\sethlcolor{lightgray}\hl{[Other: #1]}}

\newcommand{\todo}[1]{\textcolor{red}{[TODO: #1]}}

\begin{document}

\title{\textit{Beyond Accuracy}: A Critical Review of Fairness in Machine Learning for Mobile and Wearable Computing}



\author{Sofia Yfantidou}
\authornote{Work done at Nokia Bell Labs}
\email{syfantid@csd.auth.gr}
\orcid{0000-0002-5629-3493}
\affiliation{%
  \institution{Aristotle University of Thessaloniki}
  \city{Thessaloniki}
  \country{Greece}
}


\author{Marios Constantinides}\authornote{Also affiliated with the University of Cambridge, United Kingdom}
\email{marios.constantinides@nokia-bell-labs.com}
\orcid{0000-0003-1454-0641}
\affiliation{%
  \institution{Nokia Bell Labs}
  \city{Cambridge}
  \country{United Kingdom}
}

\author{Dimitris Spathis}
\email{dimitrios.spathis@nokia-bell-labs.com}
\orcid{0000-0001-9761-951X}
\authornotemark[2]
\affiliation{%
  \institution{Nokia Bell Labs}
  \city{Cambridge}
  \country{United Kingdom}
}

\author{Athena Vakali}
\email{avakali@csd.auth.gr}
\orcid{0000-0002-0666-6984}
\affiliation{%
  \institution{Aristotle University of Thessaloniki}
  \city{Thessaloniki}
  \country{Greece}
}

\author{Daniele Quercia}
\email{daniele.quercia@nokia-bell-labs.com}
\orcid{0000-0001-9461-5804}
\affiliation{%
  \institution{Nokia Bell Labs}
  \city{Cambridge}
  \country{United Kingdom}
}

\author{Fahim Kawsar}
\email{fahim.kawsar@nokia-bell-labs.com}
\orcid{0000-0001-5057-9557}
\affiliation{%
  \institution{Nokia Bell Labs}
  \city{Cambridge}
  \country{United Kingdom}
}

\renewcommand{\shortauthors}{Yfantidou, et al.}

\begin{abstract}
The field of mobile, wearable, and ubiquitous computing (UbiComp) is undergoing a revolutionary integration of machine learning. Devices can now diagnose diseases, predict heart irregularities, and unlock the full potential of human cognition. However, the underlying algorithms are not immune to biases with respect to sensitive attributes (e.g., gender, race), leading to discriminatory outcomes. The research communities of HCI and AI-Ethics have recently started to explore ways of reporting information about datasets to surface and, eventually, counter those biases. The goal of this work is to explore the extent to which the UbiComp community has adopted such ways of reporting and highlight potential shortcomings. Through a systematic review of papers published in the Proceedings of the ACM Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT) journal over the past 5 years (2018-2022), we found that progress on algorithmic fairness within the UbiComp community lags behind. Our findings show that only a small portion (5\%) of published papers adheres to modern fairness reporting, while the overwhelming majority thereof focuses on accuracy or error metrics. In light of these findings, our work provides practical guidelines for the design and development of ubiquitous technologies that not only strive for accuracy but also for fairness.












\end{abstract}

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003120.10003138</concept_id>
       <concept_desc>Human-centered computing~Ubiquitous and mobile computing</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
          <concept>
       <concept_id>10010405.10010444.10010446</concept_id>
       <concept_desc>Applied computing~Consumer health</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010178</concept_id>
       <concept_desc>Computing methodologies~Artificial intelligence</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10003456.10003457.10003580.10003543</concept_id>
       <concept_desc>Social and professional topics~Codes of ethics</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Human-centered computing~Ubiquitous and mobile computing}
\ccsdesc[300]{Applied computing~Consumer health}
\ccsdesc[300]{Computing methodologies~Artificial intelligence}
\ccsdesc[300]{Social and professional topics~Codes of ethics}

\keywords{literature review, survey, machine learning, bias, fairness, responsible artificial intelligence, ubiquitous computing, sensing data}

\received{15 February 2023}

\maketitle

\input{sections/01_Introduction}
\input{sections/02_Related_Work}
\input{sections/03_Background}
\input{sections/04_Methodology}
\input{sections/05_Results}
\input{sections/06_Discussion}
\input{sections/07_Conclusion}

\newpage


\begin{acks}
This project has received funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska-Curie grant agreement No 813162. The content of this paper reflects only the authors' view and the Agency and the Commission are not responsible for any use that may be made of the information it contains. 
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{main-tidy}

\appendix


\end{document}
