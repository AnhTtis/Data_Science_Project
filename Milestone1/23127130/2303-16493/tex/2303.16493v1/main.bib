@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@inproceedings{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}


@inproceedings{raft,
author = {Zachary Teed and Jia Deng},
title = {RAFT: Recurrent All-Pairs Field Transforms for Optical Flow},
booktitle = ECCV,
year = 2020
}

@inproceedings{gma,
  title={Learning to estimate hidden motions with global motion aggregation},
  author={Jiang, Shihao and Campbell, Dylan and Lu, Yao and Li, Hongdong and Hartley, Richard},
  booktitle=ICCV,
  year={2021}
}

@inproceedings{craft, 
author={Sui, Xiuchao and Li, Shaohua and Geng, Xue and Wu, Yan and Xu, Xinxing and Liu, Yong and Goh, Rick Siow Mong and Zhu, Hongyuan},
title={CRAFT: Cross-Attentional Flow Transformers for Robust Optical Flow},
booktitle=CVPR,
year={2022}}

@inproceedings{separableflow,
  title={Separable Flow: Learning Motion Cost Volumes for Optical Flow Estimation},
  author={Zhang, Feihu and Woodford, Oliver J. and Prisacariu, Victor Adrian and Torr, Philip H.S.},
  booktitle=ICCV,
  year={2021}
}

@inproceedings{flow1d,
  title={High-Resolution Optical Flow from 1D Attention and Correlation},
  author={Xu, Haofei and Yang, Jiaolong and Cai, Jianfei and Zhang, Juyong and Tong, Xin},
  booktitle=ICCV,
  year={2021}
}

@InProceedings{Luo_2022_CVPR,
    author    = {Luo, Ao and Yang, Fan and Li, Xin and Liu, Shuaicheng},
    title     = {Learning Optical Flow With Kernel Patch Attention},
    booktitle = CVPR,
    month     = {June},
    year      = {2022},
    pages     = {8906-8915}
}
@inproceedings{jiang2021learning,
  title={Learning optical flow from a few matches},
  author={Jiang, Shihao and Lu, Yao and Li, Hongdong and Hartley, Richard},
  booktitle=CVPR,
  pages={16592--16600},
  year={2021}
}

@InProceedings{luo2022learning,
  title={Learning Optical Flow with Adaptive Graph Reasoning},
  author={Luo, Ao and Yang, Fan and Luo, Kunming and Li, Xin and Fan, Haoqiang and Liu, Shuaicheng},
  booktitle=AAAI,
  year={2022},
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10012--10022},
  year={2021}
}
@inproceedings{sun2022disentangling,
  title={Disentangling Architecture and Training for Optical Flow},
  author={Sun, Deqing and Herrmann, Charles and Reda, Fitsum and Rubinstein, Michael
   and Fleet, David J. and Freeman, William T}, 
    booktitle=ECCV,
  year={2022}
}

@inproceedings{sun2021autoflow,
  title={Autoflow: Learning a better training set for optical flow},
  author={Sun, Deqing and Vlasic, Daniel and Herrmann, Charles and Jampani, Varun and Krainin, Michael and Chang, Huiwen and Zabih, Ramin and Freeman, William T and Liu, Ce},
  booktitle=CVPR,
  year={2021}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle=NIPS,
  year={2017}
}
@inproceedings{xu2022gmflow,
  title={GMFlow: Learning Optical Flow via Global Matching},
  author={Xu, Haofei and Zhang, Jing and Cai, Jianfei and Rezatofighi, Hamid and Tao, Dacheng},
  booktitle=CVPR,
  year={2022}
}
@inproceedings{zhao2022global,
  title={Global Matching with Overlapping Attention for Optical Flow Estimation},
  author={Zhao, Shiyu and Zhao, Long and Zhang, Zhixing and Zhou, Enyu and Metaxas, Dimitris},
  booktitle=CVPR,
  year={2022}
}
@inproceedings{huang2022flowformer,
  title={FlowFormer: A Transformer Architecture for Optical Flow},
  author={Huang, Zhaoyang and Shi, Xiaoyu and Zhang, Chao and Wang, Qiang and Cheung, Ka Chun and Qin, Hongwei and Dai, Jifeng and Li, Hongsheng},
  booktitle=ECCV,
  year={2022}
}
@inproceedings{liif,
  title={Learning continuous image representation with local implicit image function},
  author={Chen, Yinbo and Liu, Sifei and Wang, Xiaolong},
  booktitle=CVPR,
  pages={8628--8638},
  year={2021}
}


@inproceedings{pixelshuffle,
  title={Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network
},
  author={Wenzhe Shi and Jose Caballero and Ferenc Huszár and Johannes Totz and Andrew P. Aitken and Rob Bishop and Daniel Rueckert and Zehan Wang},
  booktitle=CVPR,
  year={2016}
}

@inproceedings{implicit1,
  title={Learning Implicit Fields for Generative Shape Modeling},
  author={Zhiqin Chen and Hao Zhang},
  booktitle=CVPR,
  year={2019}
}

@inproceedings{sitzmann2019siren,
    author = {Sitzmann, Vincent
              and Martel, Julien N.P.
              and Bergman, Alexander W.
              and Lindell, David B.
              and Wetzstein, Gordon},
    title = {Implicit Neural Representations
              with Periodic Activation Functions},
    booktitle = NIPS,
    year={2020}
}

@inproceedings{Karras2021,
  author = {Tero Karras and Miika Aittala and Samuli Laine and Erik H\"ark\"onen and Janne Hellsten and Jaakko Lehtinen and Timo Aila},
  title = {Alias-Free Generative Adversarial Networks},
  booktitle = NIPS,
  year = {2021}
}
@inproceedings{inr_gan,
    author    = {Skorokhodov, Ivan and Ignatyev, Savva and Elhoseiny, Mohamed},
    title     = {Adversarial Generation of Continuous Images},
    booktitle = CVPR,
    year      = {2021},
}
@inproceedings{anokhin2020image,
  title={Image Generators with Conditionally-Independent Pixel Synthesis},
  author={Anokhin, Ivan and Demochkin, Kirill and Khakhulin, Taras and Sterkin, Gleb and Lempitsky, Victor and Korzhenkov, Denis},
  booktitle=CVPR,
  year={2021}
}

@inproceedings{videoinr,
  author    = {Chen, Zeyuan and Chen, Yinbo and Liu, Jingwen and Xu, Xingqian and Goel, Vidit and Wang, Zhangyang and Shi, Humphrey and Wang, Xiaolong},
  title     = {VideoINR: Learning Video Implicit Neural Representation for\\Continuous Space-Time Super-Resolution},
  booktitle   = CVPR,
  year      = {2022},
}

@inproceedings{ultrasr,
  title={UltraSR: Spatial Encoding is a Missing Key for Implicit Image Function-based Arbitrary-Scale Super-Resolution},
  author={Xingqian Xu and Zhangyang Wang and Humphrey Shi},
  booktitle={arXiv preprint arXiv:2103.12716},
  year={2021}
}

@inproceedings{park2019deepsdf,
      title={DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation}, 
      author={Jeong Joon Park and Peter Florence and Julian Straub and Richard Newcombe and Steven Lovegrove},
      year={2019},
      booktitle=CVPR
}


@inproceedings{oechsle2019texture,
      title={Texture Fields: Learning Texture Representations in Function Space}, 
      author={Michael Oechsle and Lars Mescheder and Michael Niemeyer and Thilo Strauss and Andreas Geiger},
      year={2019},
      booktitle=ICCV
}

@inproceedings{OccupancyFlow,
    title = {Occupancy Flow: 4D Reconstruction by Learning Particle Dynamics},
    author = {Niemeyer, Michael and Mescheder, Lars and Oechsle, Michael and Geiger, Andreas},
    booktitle = ICCV,
    year = {2019}
}


@inproceedings{mescheder2018training,
      title={Which Training Methods for GANs do actually Converge?}, 
      author={Lars Mescheder and Andreas Geiger and Sebastian Nowozin},
      year={2018},
      booktitle={ICML}
}
@inproceedings{mescheder2019occupancy,
      title={Occupancy Networks: Learning 3D Reconstruction in Function Space}, 
      author={Lars Mescheder and Michael Oechsle and Michael Niemeyer and Sebastian Nowozin and Andreas Geiger},
      year={2019},
      booktitle=CVPR
}
@inproceedings{genova2019learning,
      title={Learning Shape Templates with Structured Implicit Functions}, 
      author={Kyle Genova and Forrester Cole and Daniel Vlasic and Aaron Sarna and William T. Freeman and Thomas Funkhouser},
      year={2019},
      booktitle=ICCV
}

@inproceedings{chen2019learning,
      title={Learning Implicit Fields for Generative Shape Modeling}, 
      author={Zhiqin Chen and Hao Zhang},
      year={2019},
      booktitle=CVPR
}
@inproceedings{nerf,
 title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
 author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
 year={2020},
 booktitle=ECCV,
}
@inproceedings{saito2019pifu,
      title={PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization}, 
      author={Shunsuke Saito and Zeng Huang and Ryota Natsume and Shigeo Morishima and Angjoo Kanazawa and Hao Li},
      year={2019},
      booktitle=ICCV
}

@InProceedings{flownet,
  author    = {A. Dosovitskiy and P. Fischer and E. Ilg and P. H{\"a}usser and C. Haz{\i}rba{\c{s}} and V. Golkov and P. v.d. Smagt and D. Cremers and T. Brox},
  title     = {FlowNet: Learning Optical Flow with Convolutional Networks},
  booktitle = ICCV,
  year      = {2015},
}


@InProceedings{things,
  author    = "N. Mayer and E. Ilg and P. H{\"a}usser and P. Fischer and D. Cremers and A. Dosovitskiy and T. Brox",
  title     = "A Large Dataset to Train Convolutional Networks for Disparity, Optical Flow, and Scene Flow Estimation",
  booktitle = CVPR,
  year      = "2016",

}

@inproceedings{sintel,
title = {A naturalistic open source movie for optical flow evaluation},
author = {Butler, D. J. and Wulff, J. and Stanley, G. B. and Black, M. J.},
booktitle = ECCV,
year = {2012}
}

@inproceedings{kitti,
  author = {Moritz Menze and Andreas Geiger},
  title = {Object Scene Flow for Autonomous Vehicles},
  booktitle = CVPR,
  year = {2015}
}

@inproceedings{hd1k,
  title={The HCI Benchmark Suite: Stereo and Flow Ground Truth With Uncertainties for Urban Autonomous Driving},
  author={Kondermann, Daniel and Nair, Rahul and Honauer, Katrin and Krispin, Karsten and Andrulis, Jonas and Brock, Alexander and Gussefeld, Burkhard and Rahimimoghaddam, Mohsen and Hofmann, Sabine and Brenner, Claus and others},
  booktitle=CVPRW,
  year={2016}
}

@inproceedings{pwcnet,
  author    = {Deqing Sun and Xiaodong Yang and Ming-Yu Liu and Jan Kautz},
  title     = {{PWC-Net}: {CNNs} for Optical Flow Using Pyramid, Warping, and Cost Volume},
  booktitle = CVPR,
  year      = {2018},
}

@inproceedings{hui2018liteflownet,
  title={Liteflownet: A lightweight convolutional neural network for optical flow estimation},
  author={Hui, Tak-Wai and Tang, Xiaoou and Loy, Chen Change},
  booktitle=CVPR,
  year={2018}
}

@inproceedings{hofinger2020improving,
  title={Improving optical flow on a pyramid level},
  author={Hofinger, Markus and Bul{\`o}, Samuel Rota and Porzi, Lorenzo and Knapitsch, Arno and Pock, Thomas and Kontschieder, Peter},
  booktitle=ECCV,
  year={2020},
}
@inproceedings{sun2022skflow,
  title={SKFlow: Learning Optical Flow with Super Kernels},
  author={Sun, Shangkun and Chen, Yuanqi and Zhu, Yu and Guo, Guodong and Li, Ge},
  booktitle={arXiv preprint arXiv:2205.14623},
  year={2022}
}
@inproceedings{zhao2020maskflownet,
  author = {Zhao, Shengyu and Sheng, Yilun and Dong, Yue and Chang, Eric I-Chao and Xu, Yan},
  title = {MaskFlownet: Asymmetric Feature Matching with Learnable Occlusion Mask},
  booktitle = CVPR,
  year = {2020}
}

@inproceedings{yin2019hierarchical,
  title={Hierarchical discrete distribution decomposition for match density estimation},
  author={Yin, Zhichao and Darrell, Trevor and Yu, Fisher},
  booktitle=CVPR,
  year={2019}
}
@inproceedings{jeong2022imposing,
  title={Imposing Consistency for Optical Flow Estimation},
  author={Jeong, Jisoo and Lin, Jamie Menjay and Porikli, Fatih and Kwak, Nojun},
  booktitle=CVPR,
  year={2022}
}
@inproceedings{ilg2017flownet,
  title={Flownet 2.0: Evolution of optical flow estimation with deep networks},
  author={Ilg, Eddy and Mayer, Nikolaus and Saikia, Tonmoy and Keuper, Margret and Dosovitskiy, Alexey and Brox, Thomas},
  booktitle=CVPR,
  year={2017}
}
@inproceedings{zheng2022dip,
  title={DIP: Deep Inverse Patchmatch for High-Resolution Optical Flow},
  author={Zheng, Zihua and Nie, Ni and Ling, Zhi and Xiong, Pengfei and Liu, Jiangyu and Wang, Hao and Li, Jiankun},
  booktitle=CVPR,
  year={2022}
}
@inproceedings{ranjan2017optical,
  title={Optical flow estimation using a spatial pyramid network},
  author={Ranjan, Anurag and Black, Michael J},
  booktitle=CVPR,
  year={2017}
}

@inproceedings{yang2019vcn,
  title={Volumetric Correspondence Networks for Optical Flow},
  author={Yang, Gengshan and Ramanan, Deva},
  booktitle=NIPS,
  year={2019}
}

@inproceedings{hur2019iterative,
  title={Iterative residual refinement for joint optical flow and occlusion estimation},
  author={Hur, Junhwa and Roth, Stefan},
  booktitle=CVPR,
  year={2019}
}

@inproceedings{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = NIPS,
year = {2019},
}
@inproceedings{adamw,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle=ICLR,
  year={2019}
}

@inproceedings{smith2019super,
  title={Super-convergence: Very fast training of neural networks using large learning rates},
  author={Smith, Leslie N and Topin, Nicholay},
  booktitle={Artificial intelligence and machine learning for multi-domain operations applications},
}


@inproceedings{det,
author = {Horn, Berthold and Schunck, Brian},
year = {1981},

title = {Determining Optical Flow},
booktitle = {Artificial Intelligence},
}

@inproceedings{chen2016full,
  title={Full flow: Optical flow estimation by global optimization over regular grids},
  author={Chen, Qifeng and Koltun, Vladlen},
  booktitle=CVPR,
  year={2016}
}

@inproceedings{tvl1,
author = {Zach, Christopher and Pock, Thomas and Bischof, Horst},
year = {2007},
title = {A Duality Based Approach for Realtime TV-L1 Optical Flow},
booktitle = {Pattern Recognition},
}

@inproceedings{378214,
  author={Black, M.J. and Anandan, P.},
  booktitle=ICCV, 
  title={A framework for the robust estimation of optical flow}, 
  year={1993},
  }
@inproceedings{Kanade,
author = {Bruhn, Andres and Weickert, Joachim and Schnörr, Christoph},
year = {2005},
title = {Lucas/Kanade Meets Horn/Schunck: Combining Local and Global Optic Flow Methods},
booktitle=IJCV,

}

@inproceedings{qt,
author = {Sun, Deqing and Roth, Stefan and Black, Michael},
year = {2014},
title = {A Quantitative Analysis of Current Practices in Optical Flow Estimation and The Principles Behind Them},
booktitle=IJCV
}

@inproceedings{468400,
  author={Max, N.},
  booktitle={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Optical models for direct volume rendering}, 
  year={1995},
  }
 
 @inproceedings{barron2021mipnerf,
      title={Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields},
      author={Jonathan T. Barron and Ben Mildenhall and Matthew Tancik and Peter Hedman and Ricardo Martin-Brualla and Pratul P. Srinivasan},
      year={2021},
      booktitle=ICCV
}
@inproceedings{lin2021barf,
      title={BARF: Bundle-Adjusting Neural Radiance Fields}, 
      author={Chen-Hsuan Lin and Wei-Chiu Ma and Antonio Torralba and Simon Lucey},
      year={2021},
      booktitle=ICCV
}
@inproceedings{park2021nerfies,
  author    = {Park, Keunhong 
                and Sinha, Utkarsh 
               and Barron, Jonathan T. 
               and Bouaziz, Sofien 
               and Goldman, Dan B 
               and Seitz, Steven M. 
               and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  booktitle   = ICCV,
  year      = {2021},
}
@inproceedings{pixelnerf,
  author = {Yu, Alex and Ye, Vickie and Tancik, Matthew and Kanazawa, Angjoo},
  title = {pixelNeRF: Neural Radiance Fields from One or Few Images},
  year={2021},
  booktitle=CVPR
}
@inproceedings{chen2021mvsnerf,
  title={MVSNeRF: Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo},
  author={Chen, Anpei and Xu, Zexiang and Zhao, Fuqiang and Zhang, Xiaoshuai and Xiang, Fanbo and Yu, Jingyi and Su, Hao},
  booktitle=ICCV,
  year={2021}
}
@inproceedings{kaizhang2020,
    author    = {Kai Zhang and Gernot Riegler and Noah Snavely and Vladlen Koltun},
    title     = {NeRF++: Analyzing and Improving Neural Radiance Fields},
    booktitle   = {arXiv preprint arXiv:2010.07492},
    year      = {2020},
}
@inproceedings{wang2021nerfmm,
  title={Ne{RF}$--$: Neural Radiance Fields Without Known Camera Parameters},
  author={Zirui Wang and Shangzhe Wu and Weidi Xie and Min Chen and Victor Adrian Prisacariu},
  booktitle={arXiv preprint arXiv:2102.07064},
  year={2021}
}
@inproceedings{pumarola2020d,
  title={D-NeRF: Neural Radiance Fields for Dynamic Scenes},
  author={Pumarola, Albert and Corona, Enric and Pons-Moll, Gerard and Moreno-Noguer, Francesc},
  booktitle=CVPR,
  year={2021}
}
@inproceedings{ifa,
  title={Learning implicit feature alignment function for semantic segmentation},
  author={Hu, Hanzhe and Chen, Yinbo and Xu, Jiarui and Borse, Shubhankar and Cai, Hong and Porikli, Fatih and Wang, Xiaolong},
  booktitle=ECCV,
  year={2022},
}

@inproceedings{6082986,
  author={Drulea, Marius and Nedevschi, Sergiu},
  booktitle={International IEEE Conference on Intelligent Transportation Systems (ITSC)}, 
  title={Total variation regularization of local-global optical flow}, 
  year={2011},
  }
 
@inproceedings{jahedi2022multi,
  title={Multi-Scale Raft: Combining Hierarchical Concepts for Learning-Based Optical Flow Estimation},
  author={Jahedi, Azin and Mehl, Lukas and Rivinius, Marc and Bruhn, Andr{\'e}s},
  booktitle=ICIP,
  year={2022},

}

@inproceedings{yu2020joint,
  title={Joint learning of blind video denoising and optical flow estimation},
  author={Yu, Songhyun and Park, Bumjun and Park, Junwoo and Jeong, Jechang},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={500--501},
  year={2020}
}

@inproceedings{buades2016patch,
  title={Patch-based video denoising with optical flow estimation},
  author={Buades, Antoni and Lisani, Jose-Luis and Miladinovi{\'c}, Marko},
  booktitle=TIP,
  year={2016},
}

@inproceedings{liu2010high,
  title={A high-quality video denoising algorithm based on reliable motion estimation},
  author={Liu, Ce and Freeman, William T},
  booktitle=ECCV,
  year={2010},

}

@inproceedings{bao2019depth,
  title={Depth-aware video frame interpolation},
  author={Bao, Wenbo and Lai, Wei-Sheng and Ma, Chao and Zhang, Xiaoyun and Gao, Zhiyong and Yang, Ming-Hsuan},
  booktitle=ICCV,
  year={2019}
}

@inproceedings{niklaus2017video,
  title={Video frame interpolation via adaptive convolution},
  author={Niklaus, Simon and Mai, Long and Liu, Feng},
  booktitle=CVPR,
  year={2017}
}

@inproceedings{zhang2020video,
  title={Video frame interpolation without temporal priors},
  author={Zhang, Youjian and Wang, Chaoyue and Tao, Dacheng},
  booktitle=NIPS,
  year={2020}
}

@inproceedings{sun2018optical,
  title={Optical flow guided feature: A fast and robust motion representation for video action recognition},
  author={Sun, Shuyang and Kuang, Zhanghui and Sheng, Lu and Ouyang, Wanli and Zhang, Wei},
  booktitle=CVPR,
  year={2018}
}

@inproceedings{wang2013action,
  title={Action recognition with improved trajectories},
  author={Wang, Heng and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={3551--3558},
  year={2013}
}

@inproceedings{wang2019hallucinating,
  title={Hallucinating idt descriptors and i3d optical flow features for action recognition with cnns},
  author={Wang, Lei and Koniusz, Piotr and Huynh, Du Q},
  booktitle=ICCV,
  year={2019}
}

@inproceedings{decarlo2000optical,
  title={Optical flow constraints on deformable models with applications to face tracking},
  author={Decarlo, Douglas and Metaxas, Dimitris},
  booktitle=IJCV,
  year={2000},

}

@inproceedings{kale2015moving,
  title={Moving object tracking using optical flow and motion vector estimation},
  author={Kale, Kiran and Pawar, Sushant and Dhulekar, Pravin},
  booktitle={2015 4th international conference on reliability, infocom technologies and optimization (ICRITO)(trends and future directions)},
  pages={1--6},
  year={2015},
  organization={IEEE}
}

@inproceedings{schwarz2012human,
  title={Human skeleton tracking from depth data using geodesic distances and optical flow},
  author={Schwarz, Loren Arthur and Mkhitaryan, Artashes and Mateus, Diana and Navab, Nassir},
  booktitle={Image and Vision Computing},
  year={2012},

}

@inproceedings{horn1981determining,
  title={Determining optical flow},
  author={Horn, Berthold KP and Schunck, Brian G},
  booktitle={Artificial intelligence},
  year={1981},
}

@inproceedings{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{imagenet_cvpr09,
        author = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
        title = {ImageNet: A Large-Scale Hierarchical Image Database},
        booktitle = CVPR,
        year = {2009},
        }
        
@inproceedings{wang2020deep,
  title={Deep video super-resolution using HR optical flow estimation},
  author={Wang, Longguang and Guo, Yulan and Liu, Li and Lin, Zaiping and Deng, Xinpu and An, Wei},
  booktitle=TIP,
  year={2020},
}

@inproceedings{sajjadi2018frame,
  title={Frame-recurrent video super-resolution},
  author={Sajjadi, Mehdi SM and Vemulapalli, Raviteja and Brown, Matthew},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6626--6634},
  year={2018}
}

@inproceedings{caballero2017real,
  title={Real-time video super-resolution with spatio-temporal networks and motion compensation},
  author={Caballero, Jose and Ledig, Christian and Aitken, Andrew and Acosta, Alejandro and Totz, Johannes and Wang, Zehan and Shi, Wenzhe},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4778--4787},
  year={2017}
}
@inproceedings{tao2017detail,
  title={Detail-revealing deep video super-resolution},
  author={Tao, Xin and Gao, Hongyun and Liao, Renjie and Wang, Jue and Jia, Jiaya},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={4472--4480},
  year={2017}
}

@inproceedings{tu2022optical,
  title={Optical Flow for Video Super-Resolution: A Survey},
  author={Tu, Zhigang and Li, Hongyan and Xie, Wei and Liu, Yuanzhong and Zhang, Shifu and Li, Baoxin and Yuan, Junsong},
  booktitle={arXiv preprint arXiv:2203.10462},
  year={2022}
}

@inproceedings{dong2015image,
  title={Image super-resolution using deep convolutional networks},
  author={Dong, Chao and Loy, Chen Change and He, Kaiming and Tang, Xiaoou},
  booktitle=PAMI,
  year={2015},
}
@inproceedings{lai2017deep,
  title={Deep laplacian pyramid networks for fast and accurate super-resolution},
  author={Lai, Wei-Sheng and Huang, Jia-Bin and Ahuja, Narendra and Yang, Ming-Hsuan},
  booktitle=CVPR,
  year={2017}
}@inproceedings{lim2017enhanced,
  title={Enhanced deep residual networks for single image super-resolution},
  author={Lim, Bee and Son, Sanghyun and Kim, Heewon and Nah, Seungjun and Mu Lee, Kyoung},
  booktitle=CVPRW,
  year={2017}
}@inproceedings{ledig2017photo,
  title={Photo-realistic single image super-resolution using a generative adversarial network},
  author={Ledig, Christian and Theis, Lucas and Husz{\'a}r, Ferenc and Caballero, Jose and Cunningham, Andrew and Acosta, Alejandro and Aitken, Andrew and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and others},
  booktitle=CVPR,
  year={2017}
}