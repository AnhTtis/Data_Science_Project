{
    "arxiv_id": "2303.16493",
    "paper_title": "AnyFlow: Arbitrary Scale Optical Flow with Implicit Neural Representation",
    "authors": [
        "Hyunyoung Jung",
        "Zhuo Hui",
        "Lei Luo",
        "Haitao Yang",
        "Feng Liu",
        "Sungjoo Yoo",
        "Rakesh Ranjan",
        "Denis Demandolx"
    ],
    "submission_date": "2023-03-29",
    "revised_dates": [
        "2023-03-30"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "To apply optical flow in practice, it is often necessary to resize the input to smaller dimensions in order to reduce computational costs. However, downsizing inputs makes the estimation more challenging because objects and motion ranges become smaller. Even though recent approaches have demonstrated high-quality flow estimation, they tend to fail to accurately model small objects and precise boundaries when the input resolution is lowered, restricting their applicability to high-resolution inputs. In this paper, we introduce AnyFlow, a robust network that estimates accurate flow from images of various resolutions. By representing optical flow as a continuous coordinate-based representation, AnyFlow generates outputs at arbitrary scales from low-resolution inputs, demonstrating superior performance over prior works in capturing tiny objects with detail preservation on a wide range of scenes. We establish a new state-of-the-art performance of cross-dataset generalization on the KITTI dataset, while achieving comparable accuracy on the online benchmarks to other SOTA methods.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16493v1"
    ],
    "publication_venue": "CVPR 2023 (Highlight)"
}