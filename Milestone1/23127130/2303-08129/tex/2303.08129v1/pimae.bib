@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@inproceedings{gwak2020gsdn,
  title={Generative Sparse Detection Networks for 3D Single-shot Object Detection},
  author={Gwak, JunYoung and Choy, Christopher B and Savarese, Silvio},
  booktitle={European conference on computer vision},
  year={2020}
}


@misc{3D-SIS,
  doi = {10.48550/ARXIV.1812.07003},
  
  url = {https://arxiv.org/abs/1812.07003},
  
  author = {Hou, Ji and Dai, Angela and Nießner, Matthias},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {3D-SIS: 3D Semantic Instance Segmentation of RGB-D Scans},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{houji,
  doi = {10.48550/ARXIV.2012.09165},
  
  url = {https://arxiv.org/abs/2012.09165},
  
  author = {Hou, Ji and Graham, Benjamin and Nießner, Matthias and Xie, Saining},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Exploring Data-Efficient 3D Scene Understanding with Contrastive Scene Contexts},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{H3DNet,
  doi = {10.48550/ARXIV.2006.05682},
  
  url = {https://arxiv.org/abs/2006.05682},
  
  author = {Zhang, Zaiwei and Sun, Bo and Yang, Haitao and Huang, Qixing},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {H3DNet: 3D Object Detection Using Hybrid Geometric Primitives},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{zhu2022pointclip,
  title={PointCLIP V2: Adapting CLIP for Powerful 3D Open-world Learning},
  author={Zhu, Xiangyang and Zhang, Renrui and He, Bowei and Zeng, Ziyao and Zhang, Shanghang and Gao, Peng},
  journal={arXiv preprint arXiv:2211.11682},
  year={2022}
}
@article{wu2022eda,
  title={EDA: Explicit Text-Decoupling and Dense Alignment for 3D Visual and Language Learning},
  author={Wu, Yanmin and Cheng, Xinhua and Zhang, Renrui and Cheng, Zesen and Zhang, Jian},
  journal={arXiv preprint arXiv:2209.14941},
  year={2022}
}
@article{guo2022calip,
  title={Calip: Zero-shot enhancement of clip with parameter-free attention},
  author={Guo, Ziyu and Zhang, Renrui and Qiu, Longtian and Ma, Xianzheng and Miao, Xupeng and He, Xuming and Cui, Bin},
  journal={arXiv preprint arXiv:2209.14169},
  year={2022}
}

@inproceedings{zhang2022can,
  title={Can Language Understand Depth?},
  author={Zhang, Renrui and Zeng, Ziyao and Guo, Ziyu and Li, Yafeng},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={6868--6874},
  year={2022}
}

@inproceedings{zhang2023parameter,
  title={Parameter is Not All You Need: Starting from Non-Parametric Networks for 3D Point Cloud Analysis},
  author={Zhang, Renrui and Wang, Liuhui and Wang, Yali and Gao, Peng and Li, Hongsheng and Shi, Jianbo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2023}
}

@article{fu2022pos,
  title={Pos-bert: Point cloud one-stage bert pre-training},
  author={Fu, Kexue and Gao, Peng and Liu, ShaoLei and Zhang, Renrui and Qiao, Yu and Wang, Manning},
  journal={arXiv preprint arXiv:2204.00989},
  year={2022}
}

@article{gaomimic,
  title={Mimic before Reconstruct: Enhance Masked Autoencoders with Feature Mimicking},
  author={Gao, Peng and Zhang, Renrui and Li, Hongyang and Li, Hongsheng and Qiao, Yu}
}

@article{huang2022tig,
  title={TiG-BEV: Multi-view BEV 3D Object Detection via Target Inner-Geometry Learning},
  author={Huang, Peixiang and Liu, Li and Zhang, Renrui and Zhang, Song and Xu, Xinli and Wang, Baichao and Liu, Guoyi},
  journal={arXiv preprint arXiv:2212.13979},
  year={2022}
}

@misc{pri3d,
  doi = {10.48550/ARXIV.2104.11225},
  
  url = {https://arxiv.org/abs/2104.11225},
  
  author = {Hou, Ji and Xie, Saining and Graham, Benjamin and Dai, Angela and Nießner, Matthias},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Pri3D: Can 3D Priors Help 2D Representation Learning?},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{bachmann2022multimae,
  author    = {Roman Bachmann and David Mizrahi and Andrei Atanov and Amir Zamir},
  title     = {{MultiMAE}: Multi-modal Multi-task Masked Autoencoders},
  journal   = {arXiv preprint arXiv:2204.01678},
  year      = {2022},
}

@article{hou2021pri3d,
  title={Pri3D: Can 3D Priors Help 2D Representation Learning?},
  author={Hou, Ji and Xie, Saining and Graham, Benjamin and Dai, Angela and Nie{\ss}ner, Matthias},
  journal={arXiv preprint arXiv:2104.11225},
  year={2021}
}


@article{pointmae,
  title={Masked autoencoders for point cloud self-supervised learning},
  author={Pang, Yatian and Wang, Wenxiao and Tay, Francis EH and Liu, Wei and Tian, Yonghong and Yuan, Li},
  journal={arXiv preprint arXiv:2203.06604},
  year={2022}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}

@article{zhang2022learning,
  title={Learning 3D Representations from 2D Pre-trained Models via Image-to-Point Masked Autoencoders},
  author={Zhang, Renrui and Wang, Liuhui and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  journal={arXiv preprint arXiv:2212.06785},
  year={2022}
}

@article{zhang2022i-mae,
  title={i-MAE: Are Latent Representations in Masked Autoencoders Linearly Separable?},
  author = {Zhang, Kevin and Shen, Zhiqiang},
  journal={arXiv preprint arXiv:2210.11470},
  year={2022}
}

@INPROCEEDINGS{sunrgbd,  
    author={Song, Shuran and Lichtenberg, Samuel P. and Xiao, Jianxiong},  
    booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   
    title={SUN RGB-D: A RGB-D scene understanding benchmark suite},   
    year={2015},  
    volume={},  number={},  
    pages={567-576},  
    doi={10.1109/CVPR.2015.7298655}}

@inproceedings{dai2017scannet,
    title={ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes},
    author={Dai, Angela and Chang, Angel X. and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
    booktitle = {Proc. Computer Vision and Pattern Recognition (CVPR), IEEE},
    year = {2017}
}

@article{groupfree,
  title={Group-Free 3D Object Detection via Transformers},
  author={Liu, Ze and Zhang, Zheng and Cao, Yue and Hu, Han and Tong, Xin},
  journal={arXiv preprint arXiv:2104.00678},
  year={2021}
}

@inproceedings{misra2021-3detr,
    title={{An End-to-End Transformer Model for 3D Object Detection}},
    author={Misra, Ishan and Girdhar, Rohit and Joulin, Armand},
    booktitle={{ICCV}},
    year={2021},
}

@inproceedings{wang2022tokenfusion,
  title={Multimodal Token Fusion for Vision Transformers},
  author={Wang, Yikai and Chen, Xinghao and Cao, Lele and Huang, Wenbing and Sun, Fuchun and Wang, Yunhe},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{qi2016pointnet,
  title={PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  journal={arXiv preprint arXiv:1612.00593},
  year={2016}
}

@article{pointm2ae,
  title={Point-M2AE: Multi-scale Masked Autoencoders for Hierarchical Point Cloud Pre-training},
  author={Zhang, Renrui and Guo, Ziyu and Gao, Peng and Fang, Rongyao and Zhao, Bin and Wang, Dong and Qiao, Yu and Li, Hongsheng},
  journal={arXiv preprint arXiv:2205.14401},
  year={2022}
}

@article{convmae,
  title={ConvMAE: Masked Convolution Meets Masked Autoencoders},
  author={Gao, Peng and Ma, Teli and Li, Hongsheng and Dai, Jifeng and Qiao, Yu},
  journal={arXiv preprint arXiv:2205.03892},
  year={2022}
}

@misc{voxelnet,
  doi = {10.48550/ARXIV.1711.06396},
  
  url = {https://arxiv.org/abs/1711.06396},
  
  author = {Zhou, Yin and Tuzel, Oncel},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Liu2020TANetR3,
  title={TANet: Robust 3D Object Detection from Point Clouds with Triple Attention},
  author={Zhe Liu and Xin Zhao and Tengteng Huang and Ruolan Hu and Yu Zhou and Xiang Bai},
  journal={ArXiv},
  year={2020},
  volume={abs/1912.05163}
}

@misc{transformers,
  doi = {10.48550/ARXIV.1706.03762},
  
  url = {https://arxiv.org/abs/1706.03762},
  
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Attention Is All You Need},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{pointTrans,
  author    = {Hengshuang Zhao and
               Li Jiang and
               Jiaya Jia and
               Philip H. S. Torr and
               Vladlen Koltun},
  title     = {Point Transformer},
  journal   = {CoRR},
  volume    = {abs/2012.09164},
  year      = {2020},
  url       = {https://arxiv.org/abs/2012.09164},
  eprinttype = {arXiv},
  eprint    = {2012.09164},
  timestamp = {Sat, 02 Jan 2021 15:43:30 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2012-09164.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{detr,
  author    = {Nicolas Carion and
               Francisco Massa and
               Gabriel Synnaeve and
               Nicolas Usunier and
               Alexander Kirillov and
               Sergey Zagoruyko},
  title     = {End-to-End Object Detection with Transformers},
  journal   = {CoRR},
  volume    = {abs/2005.12872},
  year      = {2020},
  url       = {https://arxiv.org/abs/2005.12872},
  eprinttype = {arXiv},
  eprint    = {2005.12872},
  timestamp = {Thu, 28 May 2020 17:38:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2005-12872.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  eprinttype = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{imvoxelnet,
  author    = {Danila Rukhovich and
               Anna Vorontsova and
               Anton Konushin},
  title     = {ImVoxelNet: Image to Voxels Projection for Monocular and Multi-View
               General-Purpose 3D Object Detection},
  journal   = {CoRR},
  volume    = {abs/2106.01178},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.01178},
  eprinttype = {arXiv},
  eprint    = {2106.01178},
  timestamp = {Thu, 10 Jun 2021 16:34:18 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-01178.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{Xu_2018_CVPR,
author = {Xu, Bin and Chen, Zhenzhong},
title = {Multi-Level Fusion Based 3D Object Detection From Monocular Images},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}
@misc{conv1,
  doi = {10.48550/ARXIV.1712.02294},
  
  url = {https://arxiv.org/abs/1712.02294},
  
  author = {Ku, Jason and Mozifian, Melissa and Lee, Jungwook and Harakeh, Ali and Waslander, Steven},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Joint 3D Proposal Generation and Object Detection from View Aggregation},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{conv2,
  doi = {10.48550/ARXIV.2012.10992},
  
  url = {https://arxiv.org/abs/2012.10992},
  
  author = {Liang, Ming and Yang, Bin and Wang, Shenlong and Urtasun, Raquel},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Deep Continuous Fusion for Multi-Sensor 3D Object Detection},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}


@inproceedings{xie2021simmim,
  title={SimMIM: A Simple Framework for Masked Image Modeling},
  author={Xie, Zhenda and Zhang, Zheng and Cao, Yue and Lin, Yutong and Bao, Jianmin and Yao, Zhuliang and Dai, Qi and Hu, Han},
  booktitle={International Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@misc{P4Constrast,
  author    = {Yunze Liu and
               Li Yi and
               Shanghang Zhang and
               Qingnan Fan and
               Thomas A. Funkhouser and
               Hao Dong},
  title     = {P4Contrast: Contrastive Learning with Pairs of Point-Pixel Pairs for
               {RGB-D} Scene Understanding},
  volume    = {abs/2012.13089},
  year      = {2020},
  publisher = {arXiv},
  eprinttype = {arXiv},
}


@article{M3AE,
  doi = {10.48550/ARXIV.2205.14204},
  author = {Geng, Xinyang and Liu, Hao and Lee, Lisa and Schuurmans, Dale and Levine, Sergey and Abbeel, Pieter},
  title = {Multimodal Masked Autoencoders Learn Transferable Representations},
  publisher = {arXiv},
  year = {2022},
}

@article{vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  journal={ICLR},
  year={2021}
}

@misc{adamw,
  doi = {10.48550/ARXIV.1412.6980},  
  url = {https://arxiv.org/abs/1412.6980},  
  author = {Kingma, Diederik P. and Ba, Jimmy},  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}, 
  title = {Adam: A Method for Stochastic Optimization},
  publisher = {arXiv},
  year = {2014},  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1812.02833,
  doi = {10.48550/ARXIV.1812.02833},
  
  url = {https://arxiv.org/abs/1812.02833},
  
  author = {Mathieu, Emile and Rainforth, Tom and Siddharth, N. and Teh, Yee Whye},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Disentangling Disentanglement in Variational Autoencoders},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@InProceedings{crosspoint,
    author    = {Afham, Mohamed and Dissanayake, Isuru and Dissanayake, Dinithi and Dharmasiri, Amaya and Thilakarathna, Kanchana and Rodrigo, Ranga},
    title     = {CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {9902-9912}
}

@inproceedings{
cifar-fs,
title={Meta-learning with differentiable closed-form solvers},
author={Luca Bertinetto and Joao F. Henriques and Philip Torr and Andrea Vedaldi},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HyxnZh0ct7},
}



@inproceedings{sanghi2020info3d,
  title={Info3d: Representation learning on 3d objects using mutual information maximization and contrastive learning},
  author={Sanghi, Aditya},
  booktitle={European Conference on Computer Vision},
  pages={626--642},
  year={2020},
  organization={Springer}
}

@inproceedings{xie2020pointcontrast,
  title={Pointcontrast: Unsupervised pre-training for 3d point cloud understanding},
  author={Xie, Saining and Gu, Jiatao and Guo, Demi and Qi, Charles R and Guibas, Leonidas and Litany, Or},
  booktitle={European conference on computer vision},
  pages={574--591},
  year={2020},
  organization={Springer}
}

@inproceedings{zhang2021self,
  title={Self-supervised pretraining of 3d features on any point-cloud},
  author={Zhang, Zaiwei and Girdhar, Rohit and Joulin, Armand and Misra, Ishan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10252--10263},
  year={2021}
}


@article{min2022voxel,
  title={Voxel-MAE: Masked Autoencoders for Pre-training Large-scale Point Clouds},
  author={Min, Chen and Zhao, Dawei and Xiao, Liang and Nie, Yiming and Dai, Bin},
  journal={arXiv preprint arXiv:2206.09900},
  year={2022}
}

@article{hess2022masked,
  title={Masked Autoencoders for Self-Supervised Learning on Automotive Point Clouds},
  author={Hess, Georg and Jaxing, Johan and Svensson, Elias and Hagerman, David and Petersson, Christoffer and Svensson, Lennart},
  journal={arXiv preprint arXiv:2207.00531},
  year={2022}
}

@inproceedings{li2022simipu,
  title={Simipu: Simple 2d image and 3d point cloud unsupervised pre-training for spatial-aware visual representations},
  author={Li, Zhenyu and Chen, Zehui and Li, Ang and Fang, Liangji and Jiang, Qinhong and Liu, Xianming and Jiang, Junjun and Zhou, Bolei and Zhao, Hang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={2},
  pages={1500--1508},
  year={2022}
}

@article{xu2021object,
  title={Object detection based on fusion of sparse point cloud and image information},
  author={Xu, Xiaobin and Zhang, Lei and Yang, Jian and Cao, Chenfei and Tan, Zhiying and Luo, Minzhou},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={70},
  pages={1--12},
  year={2021},
  publisher={IEEE}
}

@inproceedings{wang2022multimodal,
  title={Multimodal Token Fusion for Vision Transformers},
  author={Wang, Yikai and Chen, Xinghao and Cao, Lele and Huang, Wenbing and Sun, Fuchun and Wang, Yunhe},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12186--12195},
  year={2022}
}

@article{yang2022boosting,
  title={Boosting 3D Object Detection via Object-Focused Image Fusion},
  author={Yang, Hao and Shi, Chen and Chen, Yihong and Wang, Liwei},
  journal={arXiv preprint arXiv:2207.10589},
  year={2022}
}
@inproceedings{wang2021pointaugmenting,
  title={Pointaugmenting: Cross-modal augmentation for 3d object detection},
  author={Wang, Chunwei and Ma, Chao and Zhu, Ming and Yang, Xiaokang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11794--11803},
  year={2021}
}

@inproceedings{peng2021sparse,
  title={Sparse-to-dense feature matching: Intra and inter domain cross-modal learning in domain adaptation for 3d semantic segmentation},
  author={Peng, Duo and Lei, Yinjie and Li, Wen and Zhang, Pingping and Guo, Yulan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7108--7117},
  year={2021}
}

@article{jaritz2022cross,
  title={Cross-modal learning for domain adaptation in 3d semantic segmentation},
  author={Jaritz, Maximilian and Vu, Tuan-Hung and De Charette, Raoul and Wirbel, {\'E}milie and P{\'e}rez, Patrick},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2022},
  publisher={IEEE}
}

@misc{AIST,
  doi = {10.48550/ARXIV.2101.08779},
  url = {https://arxiv.org/abs/2101.08779},  
  author = {Li, Ruilong and Yang, Shan and Ross, David A. and Kanazawa, Angjoo},  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR), Multimedia (cs.MM), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {AI Choreographer: Music Conditioned 3D Dance Generation with AIST++}, 
  publisher = {arXiv}, 
  year = {2021}, 
  copyright = {Creative Commons Attribution 4.0 International}
}

@Article{chen2021mocov3,
  author  = {Xinlei Chen* and Saining Xie* and Kaiming He},
  title   = {An Empirical Study of Training Self-Supervised Vision Transformers},
  journal = {arXiv preprint arXiv:2104.02057},
  year    = {2021},
}

@article{chen2020simple,
  title={A Simple Framework for Contrastive Learning of Visual Representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  journal={arXiv preprint arXiv:2002.05709},
  year={2020}
}

@article{huang2022unsupervised,
  title={Unsupervised Prompt Learning for Vision-Language Models},
  author={Huang, Tony and Chu, Jack and Wei, Fangyun},
  journal={arXiv preprint arXiv:2204.03649},
  year={2022}
}

@inproceedings{NEURIPS2020_63c3ddcc,
  author = {Chuang, Ching-Yao and Robinson, Joshua and Lin, Yen-Chen and Torralba, Antonio and Jegelka, Stefanie},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
  pages = {8765--8775},
  publisher = {Curran Associates, Inc.},
  title = {Debiased Contrastive Learning},
  url = {https://proceedings.neurips.cc/paper/2020/file/63c3ddcc7b23daa1e42dc41f9a44a873-Paper.pdf},
  volume = {33},
  year = {2020}
}


@inproceedings{zhao2021graph,
  title={Graph Debiased Contrastive Learning with Joint Representation Clustering.},
  author={Zhao, Han and Yang, Xu and Wang, Zhenru and Yang, Erkun and Deng, Cheng},
  booktitle={IJCAI},
  pages={3434--3440},
  year={2021}
}

@article{hong2021unbiased,
  title={Unbiased classification through bias-contrastive and bias-balanced learning},
  author={Hong, Youngkyu and Yang, Eunho},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={26449--26461},
  year={2021}
}

@misc{votenet,
  doi = {10.48550/ARXIV.1904.09664},  
  url = {https://arxiv.org/abs/1904.09664},  
  author = {Qi, Charles R. and Litany, Or and He, Kaiming and Guibas, Leonidas J.}, 
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},  
  title = {Deep Hough Voting for 3D Object Detection in Point Clouds},  
  publisher = {arXiv}, 
  year = {2019},  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{beit,
      title={{BEiT}: {BERT} Pre-Training of Image Transformers}, 
      author={Hangbo Bao and Li Dong and Furu Wei},
      year={2021},
      eprint={2106.08254},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{FC100,
  doi = {10.48550/ARXIV.1805.10123},  
  url = {https://arxiv.org/abs/1805.10123},  
  author = {Oreshkin, Boris N. and Rodriguez, Pau and Lacoste, Alexandre},  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences}, 
  title = {TADAM: Task dependent adaptive metric for improved few-shot learning}, 
  publisher = {arXiv}, 
  year = {2018}, 
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{miniImageNet,
 author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and kavukcuoglu, koray and Wierstra, Daan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Matching Networks for One Shot Learning},
 url = {https://proceedings.neurips.cc/paper/2016/file/90e1357833654983612fb05e3ec9148c-Paper.pdf},
 volume = {29},
 year = {2016}
}

@misc{MAML,
  doi = {10.48550/ARXIV.1703.03400},
  
  url = {https://arxiv.org/abs/1703.03400},
  
  author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{matching,
  doi = {10.48550/ARXIV.1606.04080},
  
  url = {https://arxiv.org/abs/1606.04080},
  
  author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Kavukcuoglu, Koray and Wierstra, Daan},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Matching Networks for One Shot Learning},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{protypical,
  doi = {10.48550/ARXIV.1703.05175},
  
  url = {https://arxiv.org/abs/1703.05175},
  
  author = {Snell, Jake and Swersky, Kevin and Zemel, Richard S.},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Prototypical Networks for Few-shot Learning},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{relationnetwork,
  doi = {10.48550/ARXIV.1711.06025},
  
  url = {https://arxiv.org/abs/1711.06025},
  
  author = {Sung, Flood and Yang, Yongxin and Zhang, Li and Xiang, Tao and Torr, Philip H. S. and Hospedales, Timothy M.},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Learning to Compare: Relation Network for Few-Shot Learning},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{metaoptnet,
  doi = {10.48550/ARXIV.1904.03758},
  
  url = {https://arxiv.org/abs/1904.03758},
  
  author = {Lee, Kwonjoon and Maji, Subhransu and Ravichandran, Avinash and Soatto, Stefano},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Meta-Learning with Differentiable Convex Optimization},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{DSS,
  doi = {10.48550/ARXIV.1511.02300},
  
  url = {https://arxiv.org/abs/1511.02300},
  
  author = {Song, Shuran and Xiao, Jianxiong},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Deep Sliding Shapes for Amodal 3D Object Detection in RGB-D Images},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@INPROCEEDINGS{2D-driven,  
    author={Lahoud, Jean and Ghanem, Bernard}, 
    booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
    title={2D-Driven 3D Object Detection in RGB-D Images},  
    year={2017}, 
    volume={}, 
    number={}, 
    pages={4632-4640}, 
    doi={10.1109/ICCV.2017.495}
}

@misc{PointFusion,
  doi = {10.48550/ARXIV.1711.10871},
  
  url = {https://arxiv.org/abs/1711.10871},
  
  author = {Xu, Danfei and Anguelov, Dragomir and Jain, Ashesh},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {PointFusion: Deep Sensor Fusion for 3D Bounding Box Estimation},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{F-PointNet,
  doi = {10.48550/ARXIV.1711.08488},
  
  url = {https://arxiv.org/abs/1711.08488},
  
  author = {Qi, Charles R. and Liu, Wei and Wu, Chenxia and Su, Hao and Guibas, Leonidas J.},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Frustum PointNets for 3D Object Detection from RGB-D Data},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{akbari2021vatt,
  title={Vatt: Transformers for multimodal self-supervised learning from raw video, audio and text},
  author={Akbari, Hassan and Yuan, Liangzhe and Qian, Rui and Chuang, Wei-Hong and Chang, Shih-Fu and Cui, Yin and Gong, Boqing},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={24206--24221},
  year={2021}
}

@inproceedings{amrani2021noise,
  title={Noise estimation using density estimation for self-supervised multimodal learning},
  author={Amrani, Elad and Ben-Ari, Rami and Rotman, Daniel and Bronstein, Alex},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={8},
  pages={6644--6652},
  year={2021}
}

@article{xu2017multi,
  title={Multi-modal deep feature learning for RGB-D object detection},
  author={Xu, Xiangyang and Li, Yuncheng and Wu, Gangshan and Luo, Jiebo},
  journal={Pattern Recognition},
  volume={72},
  pages={300--313},
  year={2017},
  publisher={Elsevier}
}

@article{liang2019strong,
  title={Strong and simple baselines for multimodal utterance embeddings},
  author={Liang, Paul Pu and Lim, Yao Chong and Tsai, Yao-Hung Hubert and Salakhutdinov, Ruslan and Morency, Louis-Philippe},
  journal={arXiv preprint arXiv:1906.02125},
  year={2019}
}

@inproceedings{khare2021self,
  title={Self-supervised learning with cross-modal transformers for emotion recognition},
  author={Khare, Aparna and Parthasarathy, Srinivas and Sundaram, Shiva},
  booktitle={2021 IEEE Spoken Language Technology Workshop (SLT)},
  pages={381--388},
  year={2021},
  organization={IEEE}
}

@misc{rfs,
  doi = {10.48550/ARXIV.2003.11539},
  
  url = {https://arxiv.org/abs/2003.11539},
  
  author = {Tian, Yonglong and Wang, Yue and Krishnan, Dilip and Tenenbaum, Joshua B. and Isola, Phillip},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Rethinking Few-Shot Image Classification: a Good Embedding Is All You Need?},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{shi20193d,
  title={3d object proposal generation and detection from point cloud},
  author={Shi, S and Wang, X and Li, H Pointrcnn and others},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition, Long Beach, CA, USA},
  pages={15--20},
  year={2019}
}

@inproceedings{shi2020pv,
  title={Pv-rcnn: Point-voxel feature set abstraction for 3d object detection},
  author={Shi, Shaoshuai and Guo, Chaoxu and Jiang, Li and Wang, Zhe and Shi, Jianping and Wang, Xiaogang and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10529--10538},
  year={2020}
}

@article{rukhovich2021fcaf3d,
  title={FCAF3D: Fully Convolutional Anchor-Free 3D Object Detection},
  author={Rukhovich, Danila and Vorontsova, Anna and Konushin, Anton},
  journal={arXiv preprint arXiv:2112.00322},
  year={2021}
}

@misc{chamferdistance,
  doi = {10.48550/ARXIV.1612.00603},
  
  url = {https://arxiv.org/abs/1612.00603},
  
  author = {Fan, Haoqiang and Su, Hao and Guibas, Leonidas},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {A Point Set Generation Network for 3D Object Reconstruction from a Single Image},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{3dshapenet,
  doi = {10.48550/ARXIV.1406.5670},
  
  url = {https://arxiv.org/abs/1406.5670},
  
  author = {Wu, Zhirong and Song, Shuran and Khosla, Aditya and Yu, Fisher and Zhang, Linguang and Tang, Xiaoou and Xiao, Jianxiong},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {3D ShapeNets: A Deep Representation for Volumetric Shapes},
  
  publisher = {arXiv},
  
  year = {2014},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{mao2021dual,
  title={Dual-stream network for visual recognition},
  author={Mao, Mingyuan and Zhang, Renrui and Zheng, Honghui and Ma, Teli and Peng, Yan and Ding, Errui and Zhang, Baochang and Han, Shumin and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={25346--25358},
  year={2021}
}

@article{zheng2020end,
  title={End-to-end object detection with adaptive clustering transformer},
  author={Zheng, Minghang and Gao, Peng and Zhang, Renrui and Li, Kunchang and Wang, Xiaogang and Li, Hongsheng and Dong, Hao},
  journal={arXiv preprint arXiv:2011.09315},
  year={2020}
}

@inproceedings{zhang2022pointclip,
  title={Pointclip: Point cloud understanding by clip},
  author={Zhang, Renrui and Guo, Ziyu and Zhang, Wei and Li, Kunchang and Miao, Xupeng and Cui, Bin and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8552--8562},
  year={2022}
}

@inproceedings{qi2020imvotenet,
  title={Imvotenet: Boosting 3d object detection in point clouds with image votes},
  author={Qi, Charles R and Chen, Xinlei and Litany, Or and Guibas, Leonidas J},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020}
}

@misc{pointbert,
  doi = {10.48550/ARXIV.2111.14819},
  
  url ={https://arxiv.org/abs/2111.14819},
  
  author = {Yu, Xumin and Tang, Lulu and Rao, Yongming and Huang, Tiejun and Zhou, Jie and Lu, Jiwen},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Point-BERT: Pre-training 3D Point Cloud Transformers with Masked Point Modeling},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{zhang2022monodetr,
  title={MonoDETR: Depth-aware Transformer for Monocular 3D Object Detection},
  author={Zhang, Renrui and Qiu, Han and Wang, Tai and Xu, Xuanzhuo and Guo, Ziyu and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  journal={arXiv preprint arXiv:2203.13310},
  year={2022}
}

@INPROCEEDINGS{kitti,
  author = {Andreas Geiger and Philip Lenz and Raquel Urtasun},
  title = {Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2012}
}