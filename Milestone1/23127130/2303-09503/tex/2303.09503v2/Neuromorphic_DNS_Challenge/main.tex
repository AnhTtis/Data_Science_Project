% \documentclass{article}
\documentclass[10pt, journal]{IEEEtran}


% if you need to pass options to natbib, use, {\eg}:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2022


% ready for submission
% \usepackage{neurips_2022}


% to compile a preprint version, {\eg}, for submission to arXiv, add add the
% [preprint] option:
%usepackage[preprint]{neurips_2022}

% \usepackage[backend=biber,style=numeric,sortcites,sorting=none,backref,natbib,hyperref]{biblatex}
% \addbibresource{references.bib}
% \usepackage[square,numbers]{natbib}
% \PassOptionsToPackage{square, numbers}{natbib}
% \bibliographystyle{unsrtnat}
% to compile a camera-ready version, add the [final] option, {\eg}:
% \usepackage[final,nonatbib]{neurips_2022}





% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2022}

\usepackage[english]{babel}
\usepackage{cite}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{pifont}         % symbols



\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    }
\usepackage{float}
\usepackage{graphicx}
\usepackage{prettyref}
\usepackage{amsfonts}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{mathtools}


\newcommand{\secrefprefix}{Section~}
\newcommand{\subsecrefprefix}{Subsection~}
\newcommand{\figrefprefix}{Figure~}
\newcommand{\tablerefprefix}{Table~}
\newcommand{\equationprefix}{Equation~}
\newcommand{\equationsprefix}{Equations~}

\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\newcommand{\intelndnschallenge}{Intel N-DNS Challenge}
\newcommand{\ndnschallenge}{Intel N-DNS Challenge}
\newcommand{\ndnsrepourl}{https://github.com/IntelLabs/IntelNeuromorphicDNSChallenge}
\newcommand{\ipgnet}{Intel DNS network}
\newcommand{\eg}{\it{e.g.}}
\newcommand{\Eg}{\it{E.g.}}
\newcommand{\ie}{\it{i.e.}}
\newcommand{\Ie}{\it{I.e.}}

\newif\ifblacktext
\blacktexttrue
% \blacktextfalse

\ifblacktext
    \newcommand{\jt}[1]{}
    \newcommand{\ipgcontrib}[1]{}
    \newcommand{\mdcontrib}[1]{}
    \newcommand{\dbdrcontrib}[1]{}
    \newcommand{\sscontrib}[1]{}
\else
    \newcommand{\jt}[1]{{\color{gray} [#1]}}
    \newcommand{\ipgcontrib}[1]{{\color{magenta} [#1]}} % "contribution needed"
    \newcommand{\mdcontrib}[1]{{\color{blue} [#1]}} % "contribution needed"
    \newcommand{\dbdrcontrib}[1]{{\color{purple} [#1]}} % "contribution needed"
    \newcommand{\sscontrib}[1]{{\color{olive} [#1]}} % "contribution needed"
\fi


\title{The Intel Neuromorphic DNS Challenge}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


% \author{%
%   % David S.~Hippocampus\thanks{Use footnote for providing further information
%   %   about author (webpage, alternative address)---\emph{not} for acknowledging
%   %   funding agencies.} \\
%   % Department of Computer Science\\
%   % Cranberry-Lemon University\\
%   % Pittsburgh, PA 15213 \\
%   % \texttt{hippo@cs.cranberry-lemon.edu} \\
%     Jonathan Timcheck$^1$\\
%   \texttt{jonathan.timcheck@intel.com} \\
%   % examples of more authors
%   \And
%   Sumit Bam Shrestha$^1$ \\
%   \texttt{sumit.bam.shrestha@intel.com} \\
%    \And
%      Daniel Ben Dayan Rubin$^1$ \\
%   \texttt{daniel.ben-dayan.rubin@intel.com} \\
%   \And
%     Adam Kupryjanow$^2$ \\
%   \texttt{adam.kupryjanow@intel.com} \\
%   \And
%   Lukasz Pindor$^2$ \\
%   \texttt{lukasz.pindor@intel.com} \\
%   \And
% %  Andreas Wild$^1$ \\
% %  \texttt{andreas.wild@intel.com} \\
% %    \And
% Timothy Shea$^1$ \\
%   \texttt{timothy.shea@intel.com} \\
%   \And
%   Garrick Orchard$^1$ \\
%   \texttt{garrick.orchard@intel.com} \\
%   \And
%   Mike Davies$^1$ \\
%   \texttt{mike.davies@intel.com} \\
%   \AND
%     $~$\\
%      $^1 \text{Intel Neuromorphic Computing Lab}$\\
%      $^2 \text{Intel Design Engineering Group Poland}$\\
% }

\author{
\IEEEauthorblockN{
    Jonathan Timcheck\IEEEauthorrefmark{1},
    Sumit Bam Shrestha\IEEEauthorrefmark{1},
    Daniel Ben Dayan Rubin\IEEEauthorrefmark{1},
    Adam Kupryjanow\IEEEauthorrefmark{2},
    Garrick Orchard\IEEEauthorrefmark{1},
    Lukasz Pindor\IEEEauthorrefmark{2},
    Timothy Shea\IEEEauthorrefmark{1}, and
    Mike Davies\IEEEauthorrefmark{1}
    \\\IEEEauthorblockA{\small\IEEEauthorrefmark{1}Neuromorphic Computing Lab, Intel Labs}
    \\\IEEEauthorblockA{\IEEEauthorrefmark{2}Design Engineering Group Poland, Intel}
    \\ndns@intel.com
}
\thanks{Manuscript submitted \today.}
%\thanks{\date Manuscript received MMM DD, YYYY; revised MMM DD, YYYY.}
}


\begin{document}


\maketitle

% consider asctethic - denser encourages concise; important thing is just document in good form; depending on exact venue, we can change format

% mike help as well - neuromorphic seciton, messenging, etc.
% mike reach out to adam, wojeich, co-author

\begin{abstract}
A critical enabler for progress in neuromorphic computing research is the ability to transparently evaluate different neuromorphic solutions on important tasks and to compare them to state-of-the-art conventional solutions. 
%
%However, existing neuromorphic challenge problems and benchmarks often fall short in terms of full-system evaluations, real-world relevance, and existence of state-of-the-art reference solutions.
%
%Thus to help foster neuromorphic innovation, we introduce the Intel Neuromorphic Deep Noise Suppression Challenge (\intelndnschallenge{}).
%
The Intel Neuromorphic Deep Noise Suppression Challenge (\intelndnschallenge{}), inspired by the Microsoft DNS Challenge, tackles a ubiquitous and commercially relevant task: real-time audio denoising. 
%
Audio denoising is likely to reap the benefits of neuromorphic computing due to its low-bandwidth, temporal nature and its relevance for low-power devices.
%
The \intelndnschallenge{} consists of two tracks: a simulation-based algorithmic track to encourage algorithmic innovation, and a neuromorphic hardware (Loihi 2) track to rigorously evaluate solutions. For both tracks, we specify an evaluation methodology based on energy, latency, and resource consumption in addition to output audio quality.
%
We make the \intelndnschallenge{} dataset scripts and evaluation code freely accessible, 
%provide an example baseline solution,
encourage community participation with monetary prizes, and release a neuromorphic baseline solution which shows promising audio quality, high power efficiency, and low resource consumption when compared to Microsoft NsNet2 and a proprietary Intel denoising model used in production.
%
%and invitations to present at a future Intel Neuromorphic Research Community (INRC) forum.
%
%We view the \intelndnschallenge{} as a valuable iteration in the neuromorphic community’s ongoing effort to improve challenge problems and benchmarks, and we look forward to using the learnings from this challenge to help mature and evolve the notion of neuromorphic computing and of its potential. 
We hope the \intelndnschallenge{} will hasten innovation in neuromorphic algorithms research, especially in the area of training tools and methods for real-time signal processing. 
%
We expect the winners of the challenge will demonstrate that for problems like audio denoising, significant gains in power and resources can be realized on neuromorphic devices available today compared to conventional state-of-the-art solutions.
\end{abstract}

\ipgcontrib{magenta = input requested from IPG}

\mdcontrib{blue = input requested from Mike}

\dbdrcontrib{purple = input requested from Daniel}

\sscontrib{olive = input requested from Sumit}

\jt{gray = notes from Jonathan}

\section{Introduction}

% need to capture "what is neuromorphic"

\IEEEPARstart{``N}{euromorphic} computing achieves excellent performance with power and latency savings for certain algorithms \cite{davies2021advancing}, and the field stands to greatly benefit from focusing on well-defined neuromorphic challenge problems motivated by recent progress. Challenge problems
%---sometimes referred to as benchmarks---
facilitate the consistent evaluation and comparison of different approaches to solving important classes of problems and can help align researchers toward the most promising directions, thus accelerating progress. Historically, challenge problems have often spurred breakthroughs in the field of machine learning, {\eg}, MNIST \cite{lecun1998gradient}, CIFAR-10 \cite{krizhevsky2009learning}, and ImageNet \cite{deng2009imagenet}.
%\jt{perhaps historical survey paper on usage of benchmarks in DL}
However, the less-mature field of neuromorphic computing lacks unifying challenge problems. Most results of benchmarking neuromorphic systems are bespoke, where custom tasks are conceived chiefly to highlight the capabilities of a given neuromorphic system, making it difficult to compare across different systems and solutions, whether neuromorphic or conventional \cite{tan2015benchmarking}. %\jt{perhaps +citations to additional survey papers highlighting this problem}.

%Importantly, defining a new useful neuromorphic challenge problem is not a trivial task, and ought to be executed carefully.
Any neuromorphic challenge problem must be chosen and structured carefully. 
A poorly-selected problem could direct focus in the wrong direction, on tasks for which neuromorphic hardware is unlikely to provide advantages over conventional hardware. This includes many existing popular machine learning tasks, such as those involving static image processing. 
%
Similarly, defining a challenge problem without an accompanying methodology for comprehensively evaluating neuromorphic compute cost makes it difficult to rigorously compare different solutions. 

Researchers have discussed at length what makes for good neuromorphic challenge problems and benchmarks \cite{davies2019benchmarks}, identifying qualities such as easy access and use, freely available data, not computationally prohibitive,  representative of an important real-world task, and unsaturated \cite{cramer2020heidelberg}. 
%, and some specifications for what qualifies a system as neuromorphic, such as non-von Neumann \cite{schuman2022opportunities,bose2019my}
Existing neuromorphic benchmarks support these goals, but they are few in number and have key shortcomings. We briefly discuss several existing neuromorphic challenge problems in the following section. 

% "we discuss representaitive challenges in neuromrphic" cover popular datasets

% start off with N-MNIST N-Caltech - SS
% DVS Gesture
% SHD
% other

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\columnwidth]{audio_denoising_task_vertical.png}
  \caption{The audio denoising task. Audio denoising is ubiquitous and has many attributes that are likely to reap benefits from neuromorphic hardware. }
  \label{fig:audio-denoising-task}
\end{figure}


\subsection{Past neuromorphic challenge problems}\label{subsec:past-challenge-problems}

%These  challenge here is to classify the spiking version of popular image classification datasets: 
One of the first prominent neuromorphic challenge problems was image classification on the N-MNIST or N-Caltech101 datasets \cite{orchard2015converting}. N-MNIST and N-Caltech101 are neuromrophic versions of the classic  MNIST\cite{lecun1998gradient} and Caltech101\cite{FeiFei2004LearningGV} datasets: the neuromorphic datasets were captured using an event-based camera moving in a precise saccadic motion while pointed at a computer monitor displaying an MNIST or Caltech101 static image. %\sscontrib{[JT] Sumit - is this correct?} % @JT Yes it was on a monitor. The saccade was precisely chosen to get rid of monitor flickering.
While N-MNIST and N-Caltech101 were instrumental in advancing neuromorphic vision research and provided common datasets to compare various neuromorphic algorithms, the inherent source of information is a static image and lacks spatiotemporal information content\cite{iyer2021neuromorphic}, especially once the saccadic motion is compensated. 
Thus these datasets are generally not ideal for showcasing the full potential of neuromorphic computational models which aim to exploit neuronal dynamics inspired by biological neurons for efficient temporal signal processing
%, which often have inherently temporal processing capabilities 
(\secrefprefix \ref{sec:neuromorphic-audio-denoising}).

Another popular neuromorphic vision challenge problem is gesture recognition on the DVS Gesture dataset \cite{amir17cvpr}. 
The DVS Gesture dataset is naturally matched to neuromorphic computing---the sparse, event-based, and spatiotemporal nature of dynamic vision sensor data naturally lends itself to neuromorphic processors that also possess these attributes.
Evaluated as a neuromorphic challenge problem, however, DVS Gesture uses specialized event-based sensor data which limits widespread applicability and the dataset is small (1,342 instances). Neuromorphic solutions on DVS Gesture achieve a latency of 104ms\cite{amir2017low} on TrueNorth and 12.5ms on Loihi\cite{davies2021advancing} processing at 1ms per step. Further study shows that the accuracy on the task improves with coarser timestep of up to 25ms\cite{yao2021temporal}. This indicates that the fine-grained temporal information in the DVS Gesture dataset may not be vital in this task.
%Ideally, specialized sensor information would be critical to such a challenge problem. 

A popular neuromorphic audio challenge problem is keyword spotting on the Spiking Heidelberg Datasets \cite{cramer2020heidelberg}. The Spiking Heidelberg Datasets target the widely-applicable task of keyword spotting, and importantly, audio is pre-processed with a neuroscience-inspired cochlea model. 
This provides a consistent neuromorphic encoding to spikes upon which researchers can build their keyword spotting algorithms, thus facilitating simple and fair task performance comparisons across different spiking neural network (SNN) algorithms.
%---a substantial value to driving progress as a research community.
%
However, the cochlear encoding of the Spiking Heidelberg Datasets presents some critical shortcomings when viewed from the greater context of more general and more difficult audio processing tasks. Firstly, the information preservation of the cochlear encoding is unquantified, thus this encoding could artificially bottleneck the performance of keyword spotting, and perhaps severely bottleneck performance for more sophisticated audio processing tasks. Secondly, the power cost of computing the cochlear encoding is also unquantified, yet power is an important factor in real-world low-power audio processing systems. Indeed, how to encode an audio signal efficiently and faithfully for processing in a neuromorphic system is an open research question which plays an important role in our definition of the \intelndnschallenge.   

Other neuromorphic benchmarks have been proposed that target applications that are also well-matched to the spatiotemporal event-based neuromorphic computing style, such as Braille letter reading \cite{muller2022braille} and gesture recognition using electromyograph and dynamic vision sensor fusion \cite{ceolini2020hand}. 
However, these benchmarks involve niche sensors and applications, limiting their real-world impact and interest compared to more mainstream AI problems dealing with images, video, text, or audio. 

% building on microsoft dns challenge


% [DVS Gesture]\cite{amir17cvpr}
% - Looks spatiotemporal, but temporal information is not important to solve it
% - 


% \jt{braile sensing} \cite{muller2022braille}
% - spatiotemporal data
% - low spatial dimension (just 11)
% - Niche sensor and application

% \jt{sumit eeg sensing} \cite{ceolini2020hand}
% - sensor fusion from DVS and emg sensor
% - Niche sensor and applicaiton


% For example, while the Heidelberg spiking datasets \cite{cramer2020heidelberg} targets the widely-applicable task of keyword spotting, it also pre-processes audio with a neuroscience-inspired cochlea model, whose power-efficiency is unquantified.
% %power on edge devices is not quantified specialized low-power chips for keyword spotting already exist \jt{cite}, making the case for a neuromorphic system difficult to justify.
% As another example, the neuromorphic vision N-MNIST dataset \cite{orchard2015converting} is generated using a stationary observer with a Asynchronous Time-based Image Sensor (ATIS)  that performs prescribed saccades; in contrast, a real-world neuromorphic vision observer may be mobile, and the observer may saccade its sensor as a function of what it sees.



% subsection on past challenges

% could go a little deeper on existing challenges
% another point about heidelberg [Tim] - the problem is that they chose a spike encoding system; power efficinect yeah; but more importantly not clear if it's a good spike encoder; can you do well with that constraint in place
% ties into how we frame the challenge - someone has removed a degree of freedom to make well-defined challenge, but hte problem with that is tthat encoding data with spikes is a research problem itself
% value of heidelberg is that it emphasizes training

% drop N-MNIST
% look for other examples - recently braile sensing; shortcoming = quite simple, relying on very exotic tactile sensors; isn't ubiquitous; not broad appear; number of ppl tactile sensing very specific to emerging research sensors
% emg sensing (sumit co-author), fusion of vision and emg sensing - not really a great challenge because it's so niche with unusual sensors and it's not clear that it's a hard problem; unclear that it's solvable with the data they ahve captured
% niche challenges does not attarac a wide community of people trying to solve it; unclear if you'll ever have a strong reference with conventional methods
% broader relevance is key

%pervasive
% received a lot of attention in ML domain
% well-defined reference point
% also highlight that it's not specific to neuromorphic

% DVS-gesture; best-perofmring solutions use windowed frames and conventional deep nets on top; because of that datset, there isn't much of a temporal component; although popular dataset, not good for really challenging neuromrphic netwokrs and explotiing the merits of what they offer



% tone
% lot of talk about the community and driving algorithmic innovation; so much language in that way gives certain tone of being promotional
% at end of chlallenge, neuromorphic rigoursly outperforming conventional 

%phenomenal = big words, bring a little down to earth; these words make people; look we know there is still some skeptisims, still yet to be definitive demonstration
% we recongize there is work to be done to unabiguosuly - put that matter to rest



% just explain what we are tyring to accomplish with this challenge
% spirit or intention of the challenge
% just can expand this section to talk bout how it related to rpeiort microsoft dns challenge
% at least a paragraph modled on microsfot dns challenge & why we chose to model on that; how we expect it to differ, microsoft dns challenge focused on audio quality above all else, this challenge focusing on more holistic eval of KPI that includes quality & power, latency, ultimately the motivatio is to progress SOTA algorithimc maturity for neuromrphc computing for solving these kinds of workload, bu tnot necessarily tryign taim to produce top of leaderboard for microsfot dns, approx state of the art results (in league of soat) but tdrafmaitcally lower power and latency, breakthrough in those kpi
% they've chosen the arch, and given that constraint, they are tyring to achieve best quality
% in our case, we are changing the arch constraint; now loihi 2, and we're looking for a fixed constraint on quality (at least 3db improvment) "good enough" and now eval lowest power most compact possible; 
% first order, we want to achieve sota denoising capability (this part is fuzzy, but we want solutions that are in league of sota, we offered 2 example of near-sota models, as long as solutions are in that ballpark, that's satifysing the aim of the challenge, but if someone exceeds by some margin, that's fantastic, and we'll consider that, but we're not expecting tha to be the vector of empahsis), then minimum model size
%more the spirit; our belief by leveraging neuromrphic features of loihi 2 (representative of future neurompchi devices) possible to achieve at least order of mangitude gain compared to cpu-based sota

% segway into what is neuromrphic

% track 1 - motivate new features to progress down architectural path
% track 2 - focusing challenge on what existing here and now; solutions run well on loihi 2 not on cpu and vice versa
% that's our persective on neuromrphic computing for the purpose of the chalelge


\subsection{Audio denoising as a neuromorphic challenge}%\jt{better title?}

In this work, we identify audio denoising as an excellent neuromorphic challenge task.
%, and we define the Intel Neuromorphic Deep Noise Suppression Challenge (\intelndnschallenge{}). 
As detailed in subsequent sections, audio denoising has ubiquitous real-world applicability and plays to the strengths of neuromorphic computing.  
We have developed the \intelndnschallenge{} to make the task easily accessible, free to all, unsaturated, and designed specifically to make it easy to compare solutions over a comprehensive set of metrics.


The \intelndnschallenge{} is inspired by the Microsoft DNS Challenge, an audio denoising challenge that has been running since 2020 \cite{reddy2020interspeech, reddy2021icassp,reddy2021interspeech,
dubey2022icassp}. At a basic level, the Microsoft DNS Challenge has focused on improving speech denoising solutions as measured by human perceptual audio quality metrics and the Challenge included a track with the constraint that solutions must run in real-time on an Intel i5 or equivalent processor; essentially, the goal was to obtain the highest audio quality possible under the compute architecture constraint. In contrast, in the \intelndnschallenge{}, we are changing this architecture constraint and taking a more holistic approach to evaluating solutions by defining metrics for power and latency in addition to audio quality metrics.

The spirit of the \intelndnschallenge{} is to achieve production-level (near-SOTA) denoising performance in a system with at least an order of magnitude reduction in power, while also reducing latency, compared to real-time denoising solutions on conventional architectures. Our belief is that the neuromorphic computing features of Intel’s Loihi 2 chip---representative of future commercial neuromorphic devices---will enable the realization of such gains. Thus in the \intelndnschallenge{} we define one track focusing on evaluating solutions on existing neuromorphic hardware (Loihi 2) and another track focusing on neuromorphic algorithm development, which may motivate new features in future neuromorphic hardware.

The \intelndnschallenge{} has a 1-year timeline, but we invite the community to continue using the \ndnschallenge{} as a benchmark after the challenge ends.
%
More broadly, we view the N-DNS challenge as a single iteration in a continuing effort to develop challenge problems that help to advance neuromorphic computing to commercial maturity. 
%to help facilitate innovation in the neuromorphic community.
%, and we look forward to learning how we can improve future challenges to better serve this end.

We 
define the audio denoising task in \secrefprefix{}\ref{sec:audio-denoising-task},
%
discuss neuromorphic computing as it pertains to this work in \secrefprefix{}\ref{sec:neuromorphic-audio-denoising},
overview the Intel Neuromorphic DNS Challenge in \secrefprefix{}\ref{sec:n-dns-challenge}, describe the data in \secrefprefix{}\ref{sec:dataset}, specify evaluation criteria in \secrefprefix{}\ref{sec:evaluation}, %
 describe our baseline solution in \secrefprefix{}\ref{sec:baseline-solutions},
 address additional clarifications in \secrefprefix{}\ref{sec:clarifications}, 
 and summarize our contributions in \secrefprefix{}\ref{sec:conclusion}.
%
We make our code publicly available for obtaining the challenge data, evaluation pipeline, and the example baseline solution in the \href{\ndnsrepourl}{ \ndnschallenge{} Github  Repository ({\ndnsrepourl})} with a permissive MIT license.



\section{Primer on audio denoising}\label{sec:audio-denoising-task}
%\jt{what is audio denoising task and why is it good for making a good neuromorphic challenge problem}

%\ipgcontrib{input from Adam and Lukasz to make a more comprehensive description of the audio denoising application domain - {\eg}, what audio denoising is used for, what devices, history, etc. We don't need a particularly long description, but a bit more context from the perspective of audio experts. - DONE. We will add statement that DNS features is available in all new Intel platforms }

% Digital audio signal denoising, also called audio signal enhancement task, is not new. It is fast growing area of research starting from late 70's and early 80's when Spectral Subtraction \cite{Boll_1979} and Wiener filter \cite{Ephraim_1985} algorithms were introduced. Then beamforming techniques were successfully adopted \cite{Higuchi_2016, Nakatani_2010}. Beamforming was not practical due to its limitations, {\ie}, multiple microphones are needed to perform noise reduction, SNR improvement is highly correlated with the number of microphones and compute complexity increases with the square of the number of microphones. During last few years, high increase in research interest in single microphone denoising is observed. It is related with the successful utilization of Deep Neural Networks for this task \cite{WaveNet_2017,Luo_2019,Yanxin_2020}.


Digital audio signal denoising, also called audio signal enhancement, is a fast-growing research area, but its origin can be traced back to the late 70's and early 80's when Spectral Subtraction \cite{Boll_1979} and Wiener filter \cite{Ephraim_1985} algorithms were introduced. Subsequently, beamforming techniques were successfully adopted \cite{Higuchi_2016, Nakatani_2010}. While a significant advance, Beamforming was not practical due to several limitations, namely, that multiple microphones are needed to perform noise reduction, Signal-to-Noise Ratio (SNR) improvement is highly correlated with the number of microphones, and compute complexity increases with the square of the number of microphones.
%
Furthermore, in the last few years, there has been an increased research interest in single microphone denoising. Single-microphone device configurations are omnipresent, and the utilization of Deep Neural Networks has enabled very successful single-microphone denoising  \cite{WaveNet_2017,Luo_2019,Yanxin_2020}. We address the single-microphone audio denoising task in the \intelndnschallenge{} (\figrefprefix{} \ref{fig:audio-denoising-task}).

Typically, the signal captured by a microphone contains a source signal, like speech or music, and stationary or non-stationary noises.
%
Stationary noises change amplitude and frequency profile slowly in time, whereas non-stationary noises vary quickly over time. Some examples of the former are an air conditioner, dishwasher, fan, or engine noises.
Examples of the latter are a baby crying, a dog barking, or keyboard typing. Notably, reduction of stationary noises is a significantly simpler task than the removal of non-stationary noises. 
%
Noise is an additive distortion defined in the time domain according to
\begin{gather}
 y(t) = x(t) + n(t),\label{additive_eq}
\end{gather}
where $x(t)$ is the amplitude of the source signal for time index $t$, $n(t)$ is the noise signal, and $y(t)$ is the noisy signal captured by the microphone. 
%
%

Furthermore, most recordings are conducted in a reverberant environment; {\eg}, in indoor conditions, the signal is contaminated by reverb. Noisy reverberant signals can be expressed as 
\begin{gather}
   y(t) = h(t) * x(t) + n(t),\label{combined_eq}
\end{gather}
where $h(t)$ represents impulse response.
%
Since reverb is a multiplicative distortion, most denoising algorithms will focus on noise removal \cite{Ochieng_2022}. There are alternative approaches that perform reverb reduction and noise removal in one shot \cite{Nakatani_2020} or use a cascade of processing with reverb reduction \cite{Nakatani_2010} in a first stage, followed by a denoising stage. Audio denoising refers specifically to the process of enhancing an audio signal by subtracting noise from it; this is the task in the \intelndnschallenge{} (\figrefprefix \ref{fig:audio-denoising-task}). 


Audio denoising is commonly utilized in both real-time and non-real-time scenarios. An example of a real-time scenario is a voice call which is performed on an end-user device, such as a PC, phone, headset, or smart device, or inside applications like Microsoft Teams or Zoom.
In this use case, algorithms must not introduce latency greater than 40ms. Furthermore, the compute load must be light enough to fit into existing power and memory constraints without degrading user experience. 
Another example of a real-time application is speech enhancement in human-to-computer communication, where denoising is performed to improve the accuracy of downstream processing such as keyword spotting or Automatic Speech Recognition (ASR). 
There are other use cases, such as transcribing meeting minutes, where denoising can be performed offline. These are viewed as non-real-time scenarios that impose fewer restrictions on the algorithm, {\eg}, permitting non-causal filtering. 


% \begin{figure*}[!ht]
%   \centering
%   \includegraphics[width=0.8\textwidth]{audio_denoising_task_2023-01-23.png}
%   \caption{The audio denoising task. Audio denoising is ubiquitous and has many attributes that are likely to reap benefits from neuromorphic hardware. }
%   \label{fig:audio-denoising-task}
% \end{figure*}



\subsection{Current state-of-the-art solutions}
\ipgcontrib{Would like input here from Adam and Lukasz - brief overview of state of the art 
\begin{enumerate}
    \item Encoding/decoding
    \item Networks
    \item Metrics
\end{enumerate} for the audio denoising problem on conventional hardware.

What we are currently missing is a discussion of SOTA DNS - what general approaches people have tried, what works/doesn't, general approaches leading in the literature today, how important training techniques are like data augmentation versus model innovation, how different metrics are important for different applications ({\eg}, IPG does not focus on DNSMOS solely; model size is important for IPG but perhaps not important for Microsoft DNS challnege), where we see potentially fruitful directions to improve DNS using neuromorphic hardware.

Would also like to mention where NsNet2 fits in this picture (because we mention it in the comparison table later). - WIP
}
\ipgcontrib{
In the last few years audio denoising performed with neural network (NN) based algorithms has become a state-of-the-art solution. Over this time many challenges has been resolved and some of them are still in constant development. One of the examples is the feature extraction. In the literature, there are two main approaches to this problem: utilization of Encoder/Decoder concept or short-time Fourier transform (STFT)  \cite{citation_needed} \jt{potential citation for STFT: \cite{grochenig2001foundations}}. Some of the solution that utilize STFT also preform additional post-processing of magnitude, phase or both of the components \cite{citation_needed}. Some of them utilize complex spectrum \cite{citation_needed}. .... Another aspect of the development is NN topology. Due to the real-time application restriction there is a constant work on  the algorithm not only in case of quality but also prioritization of the models in case of compute, power consumption in real-word scenarios or real-time model's performance. 
}

% The change in focus of Microsoft DNS challenge from 2020 to 2023.
% - 2020 -> realtime and non-real time track focusing on computational complexity and speech quality separately
% - 2021 -> real time only

Recently neural networks (NN) based algorithms have been extensively applied to audio denoising problems. Initial solutions focused exclusively on denoising quality and used large models to solve the problem with great breakthroughs in accuracy. However, as the models become more and more accurate, the focus has shifted to real-time denoising performance. In fact, the most recent Microsoft DNS Challenges have dropped the non-real-time track\cite{reddy2020interspeech, reddy2021interspeech, dubey2022icassp}. % Microsoft DNS 2020, 2021, 2022, 2023].

% Types of networks
% - CCBAM -> Complex convolutional attention model -> 20M params
% - Sudo RM RF (Nested U-Net) ->
% - ReMix IT -> Teacher-Student training. Focus seems to be training on out-of-distribution datasets.
% - DCTCRN, DCCRN -> Discrete cosine transform
% - PoCoNet -> Semi supervised
% - PHASEN -> 

Non-real-time solutions focus purely on the quality of denoising and are typically non-causal. Non-real-time solutions include attention architectures \cite{zhao2021monaural},
%[CCBAM @ 20M params], 
%
temporal convolutional networks (TCN) \cite{koyama2020exploring}, %[ @ 5M params],
the Convolutional Time-domain audio separation Network (Conv TasNet) \cite{luo2019conv}, convolutional phase and amplitude processing (PHASEN) \cite{yin2020phasen}, and audio source separation with nested depthwise convolutional downsampling (SuDoRM-RF) \cite{tzinis2020sudo}. 
Real-time solutions focus on making the network lightweight and causal while maintaining denoising performance. Some examples include causal forms of TCN, Conv TasNet \cite{koyama2020exploring}, and recurrent topologies with stacked LSTM or GRU \cite{braun2020data}.

% Types of preprocessing
The most common encoding-decoding method of choice is STFT-ISTFT\cite{braun2020data, yin2020phasen, zhao2021monaural} or its similar spectrogram transformation like DCT\cite{li2021real},  while methods like SuDoRM-RF\cite{tzinis2020sudo} directly process the raw audio samples. There are different approaches for processing the complex STFT input in the literature. Some methods only make use of the magnitude information\cite{braun2020data, koyama2020exploring, luo2019conv}, some process the magnitude and phase separately and combine them\cite{braun2022task}, while some process the complex spectrum directly using complex convolutional filters\cite{zhao2021monaural}.

% training loss
The majority of the solutions use backpropagation-based supervised training. However, a wide variety of losses have been used in different works. The most common ones are the mean-square error of the resulting spectrum, maximization of the signal-to-noise ratio. A survey of various loss metrics used in audio denoising with their benefits is described in \cite{braun2021consolidated}. Some solutions even prioritize speech over suppression with an additional loss penalty term\cite{braun2022task}. In addition, unsupervised or semi-supervised training methods have also been investigated to achieve a general solution even on out-of-distribution datasets. A particularly interesting method is the teacher-student training method proposed in RemixIT\cite{tzinis2022remixit} where a teacher network trained on out-of-distribution data is used to bootstrap the noisy signals to multiply the variety of in-distribution data samples.

It is evident that noise suppression with deep neural networks is an active area of research with new methods being introduced regularly. Recent efforts have not only focused on the quality of denoising but also on the size of models and satisfying real-time requirements. There is a vast body of research from which to borrow for neuromorphic audio denoising.


\section{Neuromorphic audio denoising}\label{sec:neuromorphic-audio-denoising}

% [What is neuromorphic?]

% [Why audio deoising task?]

% [Neuromorphic audio encoding \& decoding]

We chose the audio denoising task for this challenge because it presents an excellent opportunity for neuromorphic algorithm innovation (\figrefprefix \ref{fig:audio-denoising-task}). Audio denoising is a ubiquitous power-constrained task with commercial relevance.  It is often performed on mobile devices,  and every Intel Core\texttrademark{} CPU in production now includes AI hardware acceleration support for it. Given the significant compute load of today's denoising solutions, lowering the power with a neuromorphic solution could not only lead to longer battery lives and smaller form factors but could bring the functionality to even more power-constrained devices such as headsets, earbuds, hearing aids, and cochlear implants.
Moreover, it is a temporal signal processing task, which neuromorphic systems are expected to excel at \cite{davies2019benchmarks}.
Indeed, commercial neuromorphic vendors are already targeting speech-enhancing hearing aids, promising orders-of-magnitude gains \cite{femtosenseblog}.   
%we already see hints of this neuromorphic power efficiency advantage in our baseline solution, which we describe in \secref{sec:baseline-solutions}.
Looking forward, the audio denoising task represents a starting point for the development of more general neuromorphic audio processing algorithms that operate in real time with imperceptible latency, such as audio environment emulation, speech separation, voice morphing, and speech-to-speech language translation.
%etc.---and the possibility of developing a ``neuromorphic microphone,'' a fusion of event-based microphone and neuromorphic chip for phenomenal power efficiency in edge audio processing systems.

Furthermore, audio denoising is especially timely as a neuromorphic research vector. It is a generative task unsolved in neuromorphic computing, and audio is a low data-rate signal that is well-matched to current neuromorphic chips and designs that generally target low-power edge processing. 
Solutions can be readily compared to recent conventional machine learning advances, including models deployed in production, and can leverage insights, methods, and datasets from those recent efforts. %\cite{reddy2020interspeech,reddy2021icassp,reddy2021interspeech,dubey2022icassp}.


\subsection{Neuromorphic computing and Loihi 2}\label{sec:neuromorphic-computing}
% what is neuromorphic computing
% what do we mean by neuromorphic computing
% how we define neuromorphic



Neuromorphic computing aims to apply fundamental principles of the brain's information processing mechanisms to engineered computing devices.  The brain consumes a mere 20 watts of power yet can execute remarkable feats of perception, planning, control, and learning while operating in real time processing sequential data streams. In contrast, our conventional computer systems today struggle to emulate even a narrow subset of such feats with much larger power budgets, even though they have the advantage of precisely engineered ultra-fast nanoscale transistors as a computational substrate \cite{mehonic2022brain}.
Indeed, biological inspiration is compelling. However, when computer architects go about designing neuromorphic systems, they face a fundamental question: What biology-inspired computational strategies unlock neuromorphic performance advantages versus conventional architectures?


Neuromorphic researchers have identified several promising strategies, such as analog computation, sparse connectivity, spike-based communication, in-memory computation, local synaptic learning rules, recurrent feedback, and stateful, dynamic neuron models \cite{schuman2022opportunities}. 
Subsets of these computational strategies are being implemented in hardware, {\eg}, novel analog devices\cite{wan2022compute}, %\mdcontrib{Wan A compute-in-memory chip based on resistive random-access memory}
analog computation in conventional circuits\cite{neckar2018braindrop, frenkel20180, schemmel2021accelerated, qiao2015reconfigurable}, %\mdcontrib{A Neckar Braindrop: A Mixed-Signal Neuromorphic Architecture With a Dynamical Systems-Based Programming Model}
%\mdcontrib{BrainScaleS}
%\mdcontrib{N Chiao A reconfigurable on-line learning spiking neuromorphic processor...}
digital processing with spike-based communication \cite{akopyan2015truenorth, davies2018loihi, pei2019towards, furber2014spinnaker, furber2020spinnaker}, %\jt{TrueNorth, tijanic, brainstorm, spinnaker, odin, etc.}\sscontrib{Odin is a mixed signal device}
and many others.
%\mdcontrib{Mike is considering adding here a table or a box with a few lists to give a clear, comprehensive overview of what all can be considered neuromorphic} 

In the Intel Neuromorphic Computing Lab, we focus on designing all-digital neuromorphic processors that can be manufactured in state-of-the-art semiconductor process technology. The SOTA process enables direct comparisons to SOTA conventional architectures, and the all-digital character allows a broad range of architectural features to be rapidly prototyped with fully deterministic and repeatable execution. While the all-digital character sacrifices some efficiency benefits of analog computation, we believe it is most important to first rapidly explore the architecture-algorithm co-design space before undertaking the more difficult, slower, and currently less area-efficient path of analog circuit design and novel device engineering.  
%also necessarily restricts the feature set (no analog computation) \mdcontrib{Mike plans to add here the engineering perspective - digital design actually affords a great deal of simplification and flexibility in the design process vs analog}, 
We believe the subset of neuromorphic computational principles supported by our latest chip, Loihi 2, are sufficient to show significant gains in power and latency compared to conventional computer architectures, and that this will motivate further optimizations via more nascent neuromorphic computing principles.

Loihi 2 is a state-of-the-art neuromorphic chip designed to efficiently compute temporal dynamics in sparse networks using sparse, event-based communication \cite{loihi2techbrief}. Like its predecessor \cite{davies2018loihi}, Loihi 2 consists of neuron cores that compute the temporal dynamics of stateful neural models and a communication mesh optimized for spike-based communication. Loihi 2 implements a number of generalizations and optimizations motivated by the learnings and pain points of its predecessor. These include microcode-programmed neuron models, which enable a much wider variety of neurons as seen in the brain \cite{kandel2000principles} as well as in novel neuromorphic algorithms \cite{orchard2021efficient} and promising computational benefits in heterogeneous networks \cite{perez2021neural}. 
Loihi 2 also features graded spikes, {\ie}, spikes that carry an integer value, rather than binary spikes. While not biologically motivated, graded spikes are only marginally more costly to support than binary spikes in digital neuromorphic hardware and offer straightforward gains in algorithmic precision and processing speed. Loihi 2 also enhances Loihi 1's learning support so arbitrary local modulating factors (``third factors'') may be computed by postsynaptic neuron microcode.  We believe Loihi 2’s rich feature set is sufficient to unveil significant performance gains in tasks well-suited to temporal dynamics processing, hence the spirit of using Loihi 2 as a model for neuromorphic processing in the \intelndnschallenge{}.





% Neuromorphic computers are designed to mimic the computational architecture of the brain---the brain uses only 20 watts and is comprised of biological tissue, yet the brain can execute remarkable feats of intelligence; in contrast, our conventional computer systems today struggle to emulate such feats with comparable power budgets, even though they have the advantage of precisely engineered ultra-fast nanoscale transistors as a computational substrate \cite{mehonic2022brain}.
% Indeed, biological inspiration is compelling. However, when computer architects go about designing neuromorphic systems, they face two fundamental questions: (1) what biology-inspired computational strategies are critical to unlocking neuromorphic performance advantage versus conventional architectures? and (2) what hardware features must be implemented to support these computational strategies?

% \mdcontrib{Would like input here from Mike - how deep would we like to go into discussing neuromorphic computing?}
% Neuromorphic researchers have identified several promising biology-inspired computational strategies, such as analog computation, sparse, spike-based communication, and in-memory computation \cite{schuman2022opportunities}, and subsets of these computational strategies have been implemented in hardware to achieve varying degrees of performance versus conventional architectures \jt{cite other chips}. \jt{For instance, chips XYZ implemented analog, chips ABC did digital sparse spike-based comm, etc., but these had difficulties DEF.}

% \jt{We at Intel choose to develop digital circuits with capabilities XYZ in Loihi 1 and improved in Loihi 2 \cite{loihi2techbrief}; we focus on keeping the important features for performance, but make behavior deterministic and development easier, and we find that we do indeed implement a subset of biology-inspired features that enables order-of-magnitude gains for certain algorithms \cite{davies2021advancing} in Loihi 1 and improved in Loihi 2, {\eg}, efficient signal processing \cite{orchard2021efficient}. }

% Importantly, we recognize that the advancement of neuromorphic computing architecture proceeds as a co-evolution of neuromorphic algorithm development and neuromorphic hardware development. Novel algorithms can reveal and motivate new valuable hardware features. Simultaneously, evaluating algorithms on existing neuromorphic hardware can highlight the strengths and weaknesses of neuromorphic architectures, guiding future hardware development and the identification of other algorithms that may be well-suited to neuromorphic hardware.


% With this co-evolution in mind, we design the \intelndnschallenge{} such that it fulfills both vectors: one track of the challenge caters to non-platform-specific neuromorphic algorithm development, and another track focuses on evaluation on a general-purpose, state-of-the-art existing neuromorphic system, Loihi 2. \jt{todo: remove redundancy of two track explanation from introduction}
% %
% And to ensure that the most useful neuromorphic features rise to the prominence---rather than working within a predetermined set of neuromorphic primitives---we focus on evaluating solutions with metrics in which we expect neuromorphic computers to shine, such as power and latency (\secrefprefix{} \ref{sec:evaluation}). Such metrics will naturally reveal the computational features that are most useful, thus helping to faithfully guide neuromorphic architecture development.

\subsection{Neuromorphic audio processing and promising directions}\label{sec:past-and-promising}


The computational model implemented by neuromorphic processors such as Loihi 2 is that of a discretized dynamical system. 
Unlike conventional artificial neurons from machine learning, the state variables of a dynamical systems evolve and process inputs in time---{\ie}, time is a fundamental ingredient of the computation. Thus we expect neuromorphic processors to naturally excel in temporal processing tasks, such as audio processing.
%
Indeed, precisely-timed spiking codes are well-known to underlie audio processing in the brain \cite{Kayser_Logothetis_Panzeri2010, Bialek_Wit1984, Martignoli_etAl2013}, and cochleas perform sophisticated transformations to encode incoming audio for effective processing \cite{Bialek_Wit1984, Martignoli_etAl2013}.
%
These insights from neuroscience provide clear hope for the feasibility and success of neuromorphic audio processing, and recent progress on tasks such as keyword spotting provide some evidence thereof\cite{orchard2021efficient, cramer2020heidelberg, Anumula18fns, YargaRouatWood2022}.

%
% [list of other audio processing tasks that neuromorphic systems have been used to solve and references to the papers of those systems solving those tasks}.
%
%sips paper

One can immediately ascertain three critical research questions when designing a neuromorphic audio processing system: (1) How to efficiently represent an audio waveform with high fidelity in the neuromorphic domain? (2) How to efficiently perform the desired audio processing (denoising) on this neuromorphic representation? and (3) How to efficiently invert the neuromorphic representation to yield an output (waveform)?


A natural place to start answering these questions is to start with the first: how to efficiently represent a waveform in the neuromorphic domain.
%
There exist a variety of possibilities for representing data neuromorphicly---{\eg}, binary spikes, graded spikes, population codes, sparse distributed codes, and phase codes---and a variety of encoding algorithms---{\eg}, biology-inspired cochleogram models \cite{orchard2021efficient, cramer2020heidelberg}, Short-Time Fourier Transforms (STFT)  \cite{grochenig2001foundations}, and  Mel-frequency cepstral coefficients (MFCCs) \cite{rabiner1993fundamentals}.
%
Taking inspiration from biology, in developing our baseline solution for the \intelndnschallenge{}, we initiated our study of neuromorphic audio encodings on cochleogram models, which can provide sparse representations in binary spikes, high sensitivity, frequency selectivity, large dynamic range, pitch-shifting, and self-peak normalization \cite{Magnasco2003, Hudspeth_etAl2010, Martignoli_etAl2013, orchard2021efficient}.
%
However, we quickly realized that cochleogram models such as \cite{zilany2014updated, cramer2020heidelberg} are generally computationally expensive to invert with high fidelity, which is prohibitive for a low-power denoising system.
% 
As an alternative, we developed our initial baseline solution for the \intelndnschallenge{} using a more conventional audio encoding, the Short-time Fourier Transform (STFT) \cite{grochenig2001foundations}, which is easy to invert and has perfect fidelity (aside from quantization and numerical error); furthermore, the STFT encoding can take advantage of graded spikes which are supported on Loihi 2.

While we select an STFT encoding for our baseline, we emphasize that new solutions to the \intelndnschallenge{} have a wide range of encoding strategies to explore, {\eg}, designing invertible bio-inspired cochleogram models, utilizing sparse STFTs \cite{orchard2021efficient}, or even encoding schemes that depend on feedback from other portions of the neuromorphic denoising system, much like the recurrent feedback connections from deeper areas of the brain to more low-level sensory encoding areas. Importantly, the encoding used in a neuromorphic audio processing system must be co-designed with the task for efficient operation; indeed, such synergistic design is observed in biology \cite{DeWeese_Wehr_Zador2003, SmithLewicki2005}.

% Cochleogram models carry over the aforementioned beneficial properties in their physical counterparts. 
% %
% However, we quickly noted that there is a fundamental problem with taking an arbitrary biology-inspired cochleogram model,
% %
% Cochleograms are not in general trivially invertible; that is, it can be computationally prohibitive to decode a waveform from a cochleogram, which would defeat the energy efficiency goal of the \intelndnschallenge{}. 
% %
% Moreover, cochleograms do not generally guarantee a high-fidelity encoding, as mentioned previously in the Spiking Heidelberg Digits dataset \cite{cramer2020heidelberg}; while a low-fidelity encoding may be acceptable for a simple task like keyword spotting, denoising requires high fidelity to reconstruct the output signal---this further serves as example of the need to properly pair the choice of encoding with the audio processing task at hand. 

Secondly, after audio is encoded, the actual execution of the audio processing in the neuromorphic domain is a very open research opportunity. 
%
Neuromorphic audio processing systems can employ a wide variety of strategies to perform processing in the neuromorphic domain, such as simplistic DNN conversion \cite{blouw2019benchmarking}, using a network of feedforward or recurrent leaky integrate-and-fire neurons \cite{yin2020effective, shrestha2022spikemax, cramer2020heidelberg}, a network of complex resonate-and-fire neurons \cite{orchard2021efficient}, or a sigma-delta neural network as we describe in the following subsection for our baseline solution.
%
Methodologies inspired by conventional deep learning, {\eg}, multi-timescale networks\cite{tzinis2020sudo, tzinis2022remixit, koyama2020exploring} or attention\cite{zhao2021monaural}, if mapped efficiently to the neuromorphic domain, could be promising directions as well.  
%
And finally for completeness---to address the third question posed above---decoding the output of the neuromorphically-processed audio again depends on the processing used and must be tailored appropriately to operate in an efficient manner.
%

Thus we see much opportunity for innovation throughout a neuromorphic processing pipeline---encoding, processing, and decoding. Furthermore, the audio denoising task represents just one potential audio processing task that opens the door to tackling many others with methods that are transferable to other signal processing domains such as wireless, biosensors, and control.   
%The advances obtained in the neuromorphic audio processing pipelines in solutions to the \intelndnschallenge{} can serve as an inspiration and concrete starting point for future neuromorphic audio processing systems that perform more sophisticated tasks.  
%
% Importantly, the choice of audio encoding and neuromorphic processing must be made in a synergistic fashion such that the overall system is efficient and effective; we see this also in biology where evolution has resulted in task-specialized encodings \cite{DeWeese_Wehr_Zador2003, SmithLewicki2005}.
%
% Thus for the audio denoising task in the \intelndnschallenge, we see three critical opportunities for innovation: 



%With this knowledge in hand, we developed our initial baseline solution for the \intelndnschallenge{} using a more conventional audio encoding, the Short-time Fourier Transform (STFT) \cite{grochenig2001foundations}, which is easy to invert and has perfect fidelity (aside from quantization and numerical error). Furthermore, the STFT encoding can utilize graded spikes---as opposed to strictly binary spikes in cochlear encodings---which are supported on Loihi 2.
%
%Given this choice of STFT encoding, we turned our focus to developing the neuromorphic processing section of the denoising system, which we introduce in the next subsection. 
%
%This trajectory in the development of our baseline solution emphasizes the importance in simultaneously addressing the three aforementioned questions in designing a neuromorphic audio denosing system; in fact, these questions together present a wide and promising space to explore innovations in neuromorphic audio denoising in the \intelndnschallenge.





\jt{begin old version

The computational model implemented by neuromorphic processors such as Loihi 2 is that of a discretized dynamical system---thus, we expect neuromorphic processors to naturally excel in temporal processing tasks, such as audio processing.
%
Indeed, precisely-timed spiking codes are well-known to underlie audio processing in the brain \cite{Kayser_Logothetis_Panzeri2010}. This precision is astounding despite the generating stochastic processes at its early auditory outset evinced in the cochlea \cite{Bialek_Wit1984, Martignoli_etAl2013}. 
Our earlier explorations of the neuromorphic DNS problem did consider binary spiking models such as cochleograms. These models are typically operating as an analog filter bank and in particular those incorporating the Hopf oscillator\cite{Magnasco2003}, are exploiting non-linear resonance near criticality that are modulated by parameters such as sensitivity and gain. The attractiveness of these model are because of their simplicity despite which these models are able to show case much of the known psycophysics and electrophysiological responses observed in awake animals. Among these properties are the striking sensitivity, frequency selectivity, and dynamic range through an active process mediated by the inner ear's mechanoreceptive cells. \cite{Hudspeth_etAl2010}. In particular, the critical oscillation explains the amplification with a specific form of compressive nonlinearity and frequency tuning whose sharpness depends on the degree of amplification as well as spontaneous otoacoustic emissions together with the spectrum and level dependence of the ear's distortion products; moreover, local cochlear correlates of the perceived pitch explain all essential pitch-shifting phenomena from physical grounds such that combination tone and two-tone suppression laws \cite{Magnasco2003, Hudspeth_etAl2010, Martignoli_etAl2013}. Recently, it was also shown that the model displays properties for self-peak normalization \cite{orchard2021efficient}. 

%
These insights from neuroscience provide clear hope for the feasibility and success of neuromorphic audio processing, and we do in fact see neuromorphic systems being employed to address keyword spotting\cite{orchard2021efficient, cramer2020heidelberg, Anumula18fns, YargaRouatWood2022}. In particular \cite{YargaRouatWood2022} have recently shown that a cochleogram, compared to a spectrogram audio pre-processing, when sampled by a spike process, can return better representations solving  with higher accuracy classification problems while offering a much sparser representation.

%sips paper
Neuromorphic audio processings systems employ a variety of strategies to perform processing in the neuromorphic domain, such as simplistic DNN conversion\cite{blouw2019benchmarking}, using a network of feedforward/recurrent LIF SNNs\cite{yin2020effective, shrestha2022spikemax, cramer2020heidelberg}, a network of complex resonate and fire neurons\cite{orchard2021efficient} 

\textbf{[see above my writeup and the msg in the chat]}
\dbdrcontrib{simplistic DNN conversion], [approach 2], …, [approach N] [list of approaches people have used to do audio processing in neuromorphic systems and references to the papers; this list should include ABR keyword spotting that Mike suggested}, and a variety of encodings of the input audio to the neuromorphic processor, such as 
STFT \cite{grochenig2001foundations}, MFCC, or perceptual \cite{pan2020efficient} encodings. 
%
Importantly, the choice of audio encoding and neuromorphic processing must be made in a synergistic fashion such that the overall system is efficient and effective; we see this also in biology where evolution has resulted in task-specialized encodings \cite{DeWeese_Wehr_Zador2003, SmithLewicki2005}.
%
Thus for the audio denoising task in the \intelndnschallenge, we see three critical opportunities for innovation: (1) How to efficiently represent a waveform with high fidelity in the neuromorphic domain ({\eg}, spikes)? (2) How to efficiently process this neuromorphic representation to perform denoising? and (3) How to efficiently invert the neuromorphic representation to yield an output waveform?

\textbf{[here, please use the paragraph I already wrote about our binary effort]}
A natural place to start answering these questions is to start with the first---how to efficiently represent a waveform.
%
However, we quickly noted that there is a fundamental problem with taking an popular biology-inspired cochleogram models, such as \cite{zilany2014updated, cramer2020heidelberg} (the latter was discarded because of ringing effects at high pitch).
%
Cochleograms are not in general trivially invertible \textbf{[check the msg in the chat]} \dbdrcontrib{references?, or is this just our personal experience}; that is, it can be computationally demanding if solved for as a general approach. \textbf{[again, we are trying to pitch for the cochleogram as an alternative, not to kill it! The point is that in our current so far understanding of the spike process reconstrution we need probably a set of filters that are learnt from the specs of the problem at hand]}
%
Moreover, cochleograms do not generally guarantee a high-fidelity encoding, as mentioned previously in the Spiking Heidelberg Digits (SHD) dataset \cite{cramer_heidelberg_2020}; while a low-fidelity encoding may be acceptable for a simple task like keyword spotting, denoising requires high fidelity to reconstruct the output signal---this further serves as example of the need to properly pair the choice of encoding with the audio processing task at hand. 

\textbf{[Here speak about the evolution of the neuromorphic concept introducing graded spikes. This greatly fuelled hybrid approaches that were impractical previously, offering faster solutions and easier/practical implementations - albeit pushing away the biological realism].}


With this knowledge in hand, we developed our initial baseline solution for the \intelndnschallenge{} using a more conventional audio encoding, a Short-time Fourier Transform (STFT) \cite{grochenig2001foundations}, which is easy to invert and has perfect fidelity (aside from quantization and numerical error). Furthermore the STFT encoding can utilize graded spikes---as opposed to strictly binary spikes in cochlear encodings---which are supported on Loihi 2.
%
Given this choice of STFT encoding, we turned our focus to develop the neuromorphic processing section of the denoising system, which we introduce in the next subsection. 
%
This trajectory in the development of our baseline solution emphasizes the importance in simultaneously addressing the three aforementioned questions in designing a neuromorphic audio denosing system; in fact, these questions together present a wide and promising space to explore innovations in neuromorphic audio denoising in the \intelndnschallenge.





% The computational model implemented by neuromorphic processors such as Loihi 2 is that of a discretized dynamical system---thus, we expect neuromorphic processors to naturally excel in temporal processing tasks. The human speech audio denoising is one such task, rich with temporal information.
% %
% Indeed, precisely-timed spiking codes are well-known to underly audio processing in the brain, and there is a long history of studying the intricate cochlear preprocessing that occurs in the human auditory system \dbdrcontrib{JT - Daniel, do you know of any sources that would provide support for the preceding statement? I would like to cite a few key sources to concisely support the spirit of the preceding statement.}. 
% %
% These insights from neuroscience provide clear hope for the feasibility and success of neuromorphic audio processing; however, several questions remain: (1) How to efficiently represent waveform with high fidelity using spikes? (2) How to efficiently convert to and invert a neuromorphic ({\eg}, sparse and spike-based) representation? and (3) How to efficiently process on the spike representation?

% \dbdrcontrib{
% JT - I need these from Daniel:

% (1) why cochleograms are compelling (list of features)

% (2) citations from evolution for how auditory system encodings are customized for the processing task at hand

% }
% % we have tried other attempts (first start with mimicing the brain), concept of neuromrohpc computing has been evovled


% % bank of filters is the best, even better than FFT
% % you want to make the encoding/decoding tailored to the computation
% % tailored to denoising and reconstruction
% % important task - design spike rep so that it is efficiently processable for audio denoising task

% % why? efficient, evolution across species, auditory system; specialized audio processing [bats, monkey, parrots]
% % "human" speech

% Indeed, as noted in \subsecrefprefix{} \ref{subsec:past-challenge-problems}, attempts to simply import a cochlear encoding model from neuroscience and apply it to an audio processing task like in the Spiking Heidelberg Digits (SHD) dataset \cite{cramer_heidelberg_2020} does not guarantee a high-fidelity encoding, let alone an encoding that is tenable for audio denoising. Namely, in contrast to the low-dimensional output of the keyword spotting (classification) task in SHD, the output of the audio denoising task is a full audio waveform; the audio encoding must be invertable. Cochleogram models are in general not trivially invertible and are very sensitive to noise \dbdrcontrib{JT - Daniel, are there any sources we can cite that support this statement concisely? Or do we need to explain that this was our personal experience at Intel?}.  
% %
% And finally, a neuromorphic audio encoding must be amenable to efficient processing, in terms encoding, processing (denoising), and inversion or decoding. 
% %
% Thus the three questions above present a wide and promising space to explore innovations in neuromorphic audio denoising. 


\jt{JT – I was working on revising this section (new version above; WIP)}


\dbdrcontrib{Daniel's original draft of this section:

Our earlier explorations of the neuromorphic DNS problem considered purely binary spiking generating models - so called cochleograms - mimicking the early auditory processing. These models are typically operating as an analog filter bank exploiting non-linear resonance effects modulated by parameters such as sensitivity and gain. The attractiveness of these models is because its simplicity despite which these models are able to show case much of the known psycophysics and electrophysiological responses observed in awake animals. 
Starting from the encoder we overviewed a few common spike generation models, {\eg} the aforementioned Heidelberg spike conversion method \cite{cramer_heidelberg_2020}, which, for the problem at hand, resulted with strong correlations and ringing effects; other methods [] were considered, these did not fit the requirements of noise robust representations for the DNS settings; finally, the work of Zilany \cite{Zilany2014, +}, although extremely slow because very detailed, offered a more refined control over the spiking output to better fit the processing at hand. The processing stage was entirely binary spike based and so was the output. The results we obtained were not satisfactory and given the complexity involved in the training, dynamics and stability of the solutions, we understood that this was a perfect opportunity to involve the larger research community with a challenge. This effort showed us yet again, although biology is full of such instances, that an encoder has to be a dedicated (optimized) function of the processing. Decoupling the two is possible, but surely there is no universal spike encoder method. Static solutions that are untangled from the processing model such as the Heidelberg dataset are limiting in this sense. We can do more, were the encoding left to our discretion. To this end, and clearly also for more practical reasons of training ease, in order to offer a practical baseline we are moving away from the binary spiking models by introducing a baseline SDNN model. Historically, also, the binary spiking approach was the only one available over the previous generations of neuromorphic processors. Closely mimicking the brain communication paradigma meant only binary spikes and although novel neural models would become more popular and studied {\eg} exploiting graded spikes, previous process technology was not yet power/cost effective to enable all their required infrastructure. This was true until we introduced Loihi2 on Intel 4 process. We still think that there could well be solutions exploiting binary spikes and they could be amenable of much simpler dedicated HW architecture, but more general HW is allowing explorations previously unimaginable.
}

\jt{talk about promising neuromorphic audio processing directions}
\jt{audio encoding issue, neuromorphic processing}
}

% , as opposed to constraining systems to use certain biology-inspired computational features. Furthermore, we design one track of the challenge to run on one of today’s state-of-the-art neuromorphic systems, Intel’s Loihi 2, as an evaluation platform to straightforwardly measure such performance metrics (\secrefprefix{} \ref{sec:n-dns-challenge}). The evaluation of solutions with appropriate metrics is the key differentiator in the \intelndnschallenge{} from conventional machine learning challenge problems and imbues the challenge with its neuromorphic character.




% it's a continous dev evolution of algs and hardware features to see what neuromrohpic systems shoudl support next

% Part of the challenge here is to new features for future neuromrophci hardware, so rather than constrain to specific neuromrhpic platform, we instead focus on metrics. 
% track 1 is perfect for this
% then to really evaluate on existing hardware, we have track 2



% \cite{loihi2techbrief} % loihi tech brief
% \cite{davies2021advancing} % Advancing Neuromorphic Computing With Loihi: A Survey of Results and Outlook

% extent to which biology ought to be imitated is greatly debated in the neuromorphic research community. Neuromorphic researchers have identified several biology-inspired computational strategies---{\eg}, analog computation, sparse, spike-based communication, and in-memory computation \cite{schuman2022opportunities}---however, there is not consensus regarding which biology-inspired features are necessary or most important for achieving significant energy and latency benefits in silicon.

% expand this out; less no conesus; more just saying while there is debate wshat constitues neuromrophic, there are clear prprites that we (many) belive are inherent to brain comp. 1. stateful neurons, 2. sparse, etc. sumit listed out (not list analog comp). 
% important to differentiate orders of mangitude impact analog is an opt, but we're not focused on it.

% loihi 2 suports these features (this hyp) we cna test this hyp + commercial value



% \jt{OK-but what is loihi 2? Reference tech brief for Loihi 2. Cite signal processing with resonant and fire as example of using novel stateful neuron models; do more computation with fewer resources. Loihi 2 supports....}
% track 1 inherently less constrained; alg shoudl be compatible with loihi2, but doesn't have to be



% Neuromorphic computers are designed to mimic the computational architecture of the brain---the brain uses only 20 watts and is comprised of biological tissue, yet the brain can execute remarkable feats of intelligence; in contrast, our conventional computer systems today struggle to emulate such feats with comparable power budgets, even though they have the advantage of precisely engineered ultra-fast nanoscale transistors as a computational substrate \cite{mehonic2022brain}. This contrast suggests that something is missing in the way that we architect our computers, and this is what neuromorphic computing aims to rectify---by taking inspiration from the brain, we can develop more efficient computer architectures. Indeed, results using neuromorphic computers have already begun to show energy and latency benefits versus conventional architectures \cite{davies2021advancing}. 

% Naturally, however, there is a substantial difference in the hardware---or rather, `wetware’---of brains versus silicon integrated circuits, thus neuromorphic architectures do not directly copy the neurons and their connectivity in the brain, but rather, they abstract out the primitives that appear to imbue the brain with its efficient computational abilities. Neuromorphic researchers have identified several such primitives, including the following: analog computation, sparse, spike-based communication, and in-memory computation \cite{schuman2022opportunities}. This yields a broad spectrum of computer architectures that may be considered neuromorphic, depending on the subset of these attributes the architecture exhibits.

% While this diversity of neuromorphic primitives provides a rich space of computer architectures to explore, the diversity also makes it difficult to cohesively advance research on neuromorphic algorithms; generally, solutions do not map readily from one neuromorphic architecture to another. This disunity makes it difficult to drive progress as a research community and make definitive demonstrations of the energy and latency gains from neuromorphic hardware on more challenging tasks. Thus for the purpose of Intel N-DNS Challenge, we narrow the definition of neuromorphic to a Loihi-like architecture: an all-digital processor that supports efficient sparse communication and in-memory computation. Additionally, Intel’s Loihi is manufactured in a cutting-edge process \cite{loihi2techbrief}---rather than older processes often used in other neuromorphic processors, \jt{{\eg},  citations}---thus providing an “all else equal” comparison versus state-of-the-art conventional computer chips, thus rendering definitive demonstrations of neuromorphic advantage more readily obtainable.





\subsection{Baseline neuromorphic solution}
% explain 
% this example exploits properites X, Y, Z neuromorphic peroperits; doesn't yet have these characterists; could provide further gains
% explain training methodology is key; how we managed to train it is important

% describe sigma-delta neuron

We have developed a simple baseline neuromorphic solution to the audio denoising task, and we already begin to see evidence of significant energy efficiency gains from using neuromorphic features. The baseline solution uses a sigma-delta neural network (SDNN), an adaptation of a conventional feedforward ReLU neural network architecture that exploits sparse message passing with graded spikes and stateful neurons---computational strategies that can be implemented efficiently in neuromorphic architectures and that are supported by Loihi 2 in particular. The SDNN baseline solution achieves similar audio quality to a conventional baseline solution NsNet2 from the Micrsoft DNS Challenge 2022, but with an order of magnitude fewer operations and less than half its latency. We provide a more detailed overview of the baseline solution architecture and its performance in \secrefprefix{} \ref{sec:baseline-solutions}.

%Neuromorphic features that are performant on Loihi 2 and which of these features are exploited in the baseline solution.
Importantly, our SDNN baseline solution is a very basic feedforward architecture, and does not exploit several of the aforementioned neuromorphic features that perform well on Loihi 2 (\tablerefprefix \ref{table:neuromorphic-features-used-by-baseline}). 
As new solutions incorporate more of these features, such as recurrent and sparse connectivity, we anticipate further significant improvements in power and model size.

\begin{table}[H]
\centering
\caption{Neuromorphic features that are performant on Loihi 2 and their utilization in our N-DNS baseline solution.}
% \begin{tabular}{ p{5cm}c{3cm}}
\begin{tabular}{ p{5cm} c}
 Neuromorphic feature           & In baseline solution \\ \hline
 Sparse activity                & \cmark \\
 Sparse connectivity            & \xmark \\
 Recurrence                     & \xmark \\
 Stateful neurons               & \cmark \\
 Neuron temporal dynamics       & \xmark \\
 Synaptic plasticity            & \xmark \\
 Graded spikes                  & \cmark \\
 Delay as computational element & \cmark \\
 \hline
\end{tabular}\label{table:neuromorphic-features-used-by-baseline}
\end{table}



\section{Intel Neuromorphic DNS Challenge}\label{sec:n-dns-challenge}
%The Intel Neuromorphic DNS Challenge is a neuromorphic audio denoising challenge inspired by the Microsoft DNS Challenge \cite{dubey2022icassp}.
Just like the Microsoft DNS Challenge, 
The objective of the Intel Neuromorphic DNS Challenge 
%(abbreviated as ``\intelndnschallenge{}") 
is to create a system that removes the noise from noisy human speech in real-time. However, in contrast to the denoising system that runs on a conventional CPU in the Microsoft DNS Challenge, the \intelndnschallenge{} targets the Loihi 2 neuromorphic processor aiming to  realize the neuromorphic system’s potential for power and latency improvements. To this end, the \intelndnschallenge{} hosts two tracks:
\begin{enumerate}
    \item Algorithmic. The objective in Track 1 is to develop a high-quality audio denoising solution that operates efficiently on a neuromorphic system. The algorithm is not required to run on actual neuromorphic hardware, but rather will be simulated on conventional hardware. Latency and a neuromorphic proxy power are estimated. % by a procedure involving counting the number of CPU and neuromorphic operations that the solution uses. 
    \item Loihi 2. The objective in Track 2 is to develop a high-quality audio denoising system that operates efficiently on Loihi 2 \cite{loihi2techbrief}. The power and latency of the denoising solution will be measured by running it on actual Loihi 2 hardware.

\end{enumerate}
Track 1 provides freedom to explore a wide range of neuromorphic denoising solutions, without the need to demonstrate the solutions on actual neuromorphic hardware; this track is intended for rapid development and potentially to inspire future neuromorphic hardware features. 
Track 2 guarantees that neuromorphic denoising solutions can indeed run on actual neuromorphic hardware. This track provides a rigorous demonstration of power and latency benefits realized by neuromorphic hardware. 

Both tracks follow the same structure: noisy audio is encoded into a form suitable for processing on a neuromorphic system, processed on a neuromorphic system (simulated for Track 1, or real hardware system for Track 2), and decoded into a clean output audio waveform (Figure \ref{fig:solution_structure}). Solutions are evaluated by an audio quality metric and a computational resource usage metric and are subject to a minimum audio quality and maximum latency (real-time) requirement.

The selection procedure for the winner of each track is described in the \href{\ndnsrepourl}{\intelndnschallenge{} Github Repository}, along with challenge logistics and timeline.
Solutions will be judged not only on the measured or estimated computational metrics, but also on commercial relevance, broader research impact, and quality of solution write-up.
%
%Solutions are also evaluated These two metrics are combined in a final compound metric, which is used to create a ranking of solutions.
We describe the dataset, evaluation metrics, 
%quality metric, computational resource metric, combined metric, 
and an example baseline solution in the following sections. 

\begin{figure*}[!ht]
  \centering
  \includegraphics[width=0.8\textwidth]{solution_structure_2023-03-16.png}
  \caption{Intel Neuromorphic DNS Challenge Solution Structure. 
  Input noisy audio is encoded before it enters the neuromorphic denoiser (N-DNS). The neuromorophic denoiser processes its input, and the output of the neuromorphic denoiser is decoded to produce the final output clean audio. The encoder, decoder, and neuromorphic denoiser are the constituents of a solution to the \ndnschallenge{} and their power and latency are evaluated, in addition to the output audio quality. In Track 1, all components run on CPU, while in Track 2, the neuromorphic denoiser runs on Loihi 2.
  }
  \label{fig:solution_structure}
\end{figure*}




\section{Dataset}\label{sec:dataset}
The Intel N-DNS dataset is derived from the Microsoft DNS Challenge dataset, which is a corpus of human speech audio samples of various categories including but not limited to English, German, French, Spanish, Russian and various categories of noises (\href{https://github.com/microsoft/DNS-Challenge}{ DNS Challenge Github Repository}). We provide a synthesizer script that generates 30-second segments of clean (ground truth), noise (additive), and noisy (ground truth + noise) audio data for both the training and validation dataset in the challenge repository. For training the network, participants are free to choose and/or tweak the data synthesis parameters or choose only a subset of the Microsoft DNS Dataset language and noise categories, or even include additional speech and noise corpus for synthesis. The default is 500 total hours (60,000 samples) of audio data with the synthesized SNR between 20dB to -5dB at 16kHz with a bit depth of 16 bits. % according to .wav file inspected using Windows 11
The validation set, on the other hand, is generated using the default settings in the audio synthesis script.

The testing data for \intelndnschallenge will be provided at a later point after participant models are frozen. Thereafter, there can be no changes to the submitted models in order to ensure a fair evaluation on the test set. 
%
The characteristics of the testing data will be similar to the training and validation set. %The audio samples will be released directly rather than a synthesis script to ensure uniform evaluation of all the submissions.
Note that this model freeze is only a feature for administering the challenge in a fixed timeline with blinded test set, and we encourage the continued use of the \intelndnschallenge{} resources and framework as a general, non-time-bound challenge problem for neuromorphic research.

In addition, we include general dataloader modules in the \intelndnschallenge\ that load the clean, noise, and noisy audio from the training, validation, and testing samples. Optionally, the dataloader also provides metadata about synthesized audio samples like the clean audio sources, noise sources, the noise mixture level and so on.


\section{Evaluation} \label{sec:evaluation}

There is no single metric that captures the overall performance of a solution in the \intelndnschallenge. Instead, there are multiple metrics that characterize different dimensions of performance. Naturally, we must quantify the output audio quality of the N-DNS system, and so we define metrics for this related to signal-to-noise ratio and perceptual audio quality. Equally important for the objective of the challenge is to assess computational resource costs: latency to ensure real-time processing, power to quantify energy efficiency, and chip resources required to support the solution on neuromorphic hardware.
%a count of the number of parameters, to quantity memory usage or chip area. 
With these four performance dimensions covered, we can comprehensively evaluate each solution. We also consider certain derived figures of merit, such as power-delay product, a common quantity used to represent the tradeoff between speed and energy efficiency in electronics systems. 

This collection of metrics allows us to compare solutions designed for different points in performance space, {\ie}, its positioning on a Pareto frontier with top-performing solutions designed for low-power or high-power, with correspondingly lower or higher audio quality. 
%
%The metrics we describe in the sections that follow enable the holistic quantitative comparison of solutions to the N-DNS challenge and are key to demonstrating the advantages of neuromorphic hardware over conventional hardware. 

% Given our objectives to compare different solutions’ task performance easily and to demonstrate the benefits of neuromorphic hardware in terms of energy, latency, and resource consumption, it is imperative that we rigorously define a set of evaluation metrics that capture these measures in a consistent and faithful manner. Doing so enables us to compare solutions fairly and holistically. In the following subsections, we define such evaluation metrics for the N-DNS Challenge. We also specify minimum performance requirements on these metrics to help ensure solutions' real-world applicability, and we carefully define proxy metrics for physical quantities that cannot be directly measured in the algorithmic Track 1.

\subsection{Audio quality metrics and minimum audio quality improvement}
% there is not signle metric that rules themall; in tradiational DL it's accuracy at all costs
% really there are multipe metrics that are all very important; matters that there is a solution that isaccuare nough that operates under latency constraint, an dhas low poer; and does not conesuem a lot of chip resources, related to the cost of the solution. laying out a number of exlicpli metrics that will be measured and repoted; dconsidering this all todgether when we are donsidering winnder for the challenge

%explain the jist of each one, si-snr, delay, power, and power-delay product, at least allows us to collapse down and compare, different solutions optimizes for differ points

% evaluate different solutions optimized in different ways

\subsubsection{SI-SNR metric}
Task performance in the N-DNS Challenge is measured as the output audio quality; we use the Scale-Invariant Source-to-Noise Ratio (SI-SNR)---SI-SNR is a common metric in the audio processing literature ({\eg}, \cite{bahmaninezhad2019comprehensive, le2019sdr}).
%
%
SI-SNR measures how clear the human speech is above the noise in the output of the N-DNS system, similar to a Source-to-Noise Ratio (SNR) \cite{le2019sdr}.
%the degree to which the clean human speech is present in the output from the N-DNS system, relative to the amount of noise present in the output, {\ie}, a measure of how clear the human speech is above the noise. 
%
But importantly, SI-SNR is also scale-invariant---{\ie}, changing the overall magnitude (volume) of the output does not change the SI-SNR; intuitively, we do not wish to favor solutions over others' that simply increase the output volume. 
%

For a single input waveform, a real-valued 
zero-mean
 vector $s$, and the corresponding output waveform from the N-DNS system $\hat{s}$, the SI-SNR is defined as 
\begin{equation}
\text{SI-SNR} := 10 \log_{10} \frac{|| s_\text{target} ||^2 }{||e_\text{noise} ||^2},\label{eq:si-snr}
\end{equation}
where
$
s_\text{target} := \frac{\langle \hat{s}, s \rangle s}{||s||^2} %\label{eq:si-sni-eq-2}
$ and $
e_\text{noise} := \hat{s} - s_\text{target}%\label{eq:si-sni-eq-3}
$.
% and $s$ and $\hat{s}$ are the zero-mean real-valued vectors of the ground truth clean speech waveform and denoised output waveform, respectively.
%SI-SNR measures the extent to which noise is removed from the noisy input audio waveform, and can be easily used as a loss function for machine learning methods. 
%

We choose SI-SNR as one of our metrics for its simplicity and generality, rather than more complicated audio quality metrics, such as speech-to-text word accuracy used in the Microsoft DNS Challenge \cite{dubey2022icassp}. 
The focus of the N-DNS challenge is on neuromorphic algorithm innovation; this in itself constitutes a sufficiently challenging task. Moreover, we view the audio denoising task as a representative of a general audio processing workload, and some commercial applications may not specifically prioritize human-listener perceptual quality. Finally, the SI-SNR can be conveniently used as a loss function for machine learning approaches.

The mean $\text{SI-SNR}$ on the test set will be used to compare solutions. A script for computing mean SI-SNR is provided in the \href{\ndnsrepourl}{\intelndnschallenge{} Github Repository}.

\subsubsection{Minimum SI-SNR improvement}

Since solutions in the \ndnschallenge{} are evaluated holistically, solutions may target high audio quality by using a large amount of power, or lower audio quality using a smaller amount of power, or any audio quality-power point in between.
However, to ensure that the audio denoising task is being solved to some significant extent, we require solutions to achieve a minimum audio quality improvement over the noisy input audio quailty. 
Moreover, per our emphasis on neuromorphic computing, we require that the neuromorphic component of the N-DNS system be responsible for a significant portion of the audio quality improvement; a solution may optionally perform some denoising in the encoder and decoder, but the spirit of the \ndnschallenge{} is in performing neuromorphic denoising. 

Therefore, we define two measures of audio quality (SI-SNR) improvement (i) relative to 
(1) the noisy data ($\text{SI-SNRi}_{\text{data}}$) and 
(2) the encode+decode processing ($\text{SI-SNRi}_{\text{encode+decode}}$),
expressed by the following inequalities:
\begin{align}
\text{SI-SNRi}_{\text{data}} &> 3\text{dB}\label{eq:min-si-snr-system} \\
\text{SI-SNRi}_{\text{enc+dec}} &> 3\text{dB}, \label{eq:min-si-snr-neuromorphic}
\end{align}
where
\begin{itemize}%[label={--}]
    \item $\text{SI-SNRi}_\text{data} = \text{SI-SNR}_{\text{full system}} - \text{SI-SNR}_{\text{data}}$,
    \item $\text{SI-SNRi}_\text{enc+dec} = \text{SI-SNR}_{\text{full system}} - \text{SI-SNR}_{\text{enc+dec}}$,
    \item $\text{SI-SNR}_{\text{full system}}$ is the mean test-set SI-SNR from the full N-DNS system (input audio $\rightarrow$ encode $\rightarrow$ neuromorphic denoiser $\rightarrow$ decode $\rightarrow$ output audio),
    \item $\text{SI-SNR}_{\text{enc+dec}}$ 
    is the mean test-set SI-SNR from running only encoder and decoder
    (input audio $\rightarrow$ 
    encode $\rightarrow$
    decode $\rightarrow$
    output audio), and
    \item $\text{SI-SNR}_{\text{data}}$ 
    is the mean test-set SI-SNR on the noisy input audio (no transformations).
\end{itemize}

{\equationprefix} \eqref{eq:min-si-snr-system} ensures that the solution achieves a minimum audio quality improvement, and {\equationprefix} \eqref{eq:min-si-snr-neuromorphic} ensures that the neuromorphic denoiser itself is responsible for a minimum audio quality improvement. These definitions allow for some amount of denoising to occur in the encoder and decoder, but critically, adding the neuromrophic denoiser must further improve audio quality.

\subsubsection{DNSMOS metric}
% need some input from adam or tim; give some sense for what is done in conventional deep noise suppresion domain; what' sthe history of the challenge we are modeling after; why they themselves moved away from si-snr to this dnsmos
% explain there are clear limitations to focusing exclusively on si-snr, on the other hand we don't want to put too much emaphsis on dnsmos so that we are reuqireing ppl paritcpating that htey become dns experts, data aug, etc. current SOTA in dns is beyond good training of dnn arch, not about dataset curation, hyp tuning, etc.
% broader context to whole challenge, we're not expecting ppl to go deeply down that path, dont' want to just focus on dnsmos, hoping primarily to get progress on basic alg solns for problems reparesntative of dns of ajduio processing
% need to provide this level of context not down in metrics section, but need t cover this in introdcution, motivation

% We also evaluate solutions using DNSMOS \cite{reddy2022dnsmos}. In this method perceptual quality metric is generated by a model trained to reflect human perceptual quality expressed in MOS (Mean Opinion Score). MOS score is in a range from 1 to 5, where 1 means bad and 5 excellent quality. We used DNSMOS model for perceptual evaluation since it generates scores that highly correlates with perpetual assessment. Other methods for preceptural quality assessment, like PESQ (Perceptual Evaluation of Speech Quality) \cite{rix2001perceptual}, POLQA (Perceptual Objective
% Listening Quality Analysis) \cite{Beerends2013PerceptualOL} or VisQOL \cite{ViSQOL_2015}, have lower correlation with subjective scores. Commercial solution like 3QUEST might be alternative but its utilization is limited due to license fees.

% DNSMOS generates three scores that reflect: speech signal quality (SIG), background noise quality (BAK), and overall audio quality (OVRL). From the perspective of speech enhancement, SIG score let us know if speech quality was affected by the processing. Usually most of denoising algorithms will not improve SIG. Best systems will keep this score on the same level as for unprocessed signal. BAK illustrates how much noise is present in a signal. Thus, after speech enhancement we should observe significant improvement of this score. Finally, OVRL score represents general quality assessment. It is not a simple average of SIG and BAK scores, but some general assessment of quality. After denoising signal must have higher OVRL score.

% DNSMOS provides a valuable additional facet in evaluating audio quality in the \intelndnschallenge{} and gives another point of comparison to existing denoising systems; namely, DNSMOS (OVRL) was used in the Microsoft DNS Challenge \cite{dubey2022icassp}. 

% \ipgcontrib{Would like commentary here from Adam and Lukasz on audio metrics; discuss significance of all three DNSMOS metrics. - DONE}

For audio signals, the perceptual quality of the audio signal is important in addition to the signal quality measured by SI-SNR. We use the widely adopted DNSMOS\cite{reddy2022dnsmos} metric to evaluate the perceptual quality of the solution. In DNSMOS, the perceptual quality score is predicted by a deep network that is trained to reflect the human perceptual quality expressed in Mean Opinion Score (MOS) in its training corpus. MOS score ranges from 1 to 5, where 1 corresponds to poor quality, and 5 corresponds to excellent quality. DNSMOS is particularly effective because it has been shown to generate scores that are highly correlated with human perceptual assessment \cite{reddy2022dnsmos} compared to other similar methods like Perceptual Evaluation of Speech Quality (PESQ) \cite{rix2001perceptual}, Perceptual Objective Listening Quality Analysis (POLQA) \cite{Beerends2013PerceptualOL}, or VisQL \cite{ViSQOL_2015}. There exist commercial alternatives like 3QUEST, but its use is limited due to its proprietary nature.

A DNSMOS score consists of three values: speech signal quality~(SIG), background noise quality~(BAK), and overall audio quality~(OVRL). From the perspective of speech enhancement, the SIG score reflects the change in speech quality due to processing. Usually, most of denoising algorithms do not improve SIG score significantly compared to the unprocessed signal. BAK score reflects the degree of noise present in the signal. Thus, after a speech enhancement, a significant improvement in this score is expected. Finally, OVRL score reflects the general audio quality assessment. It is not a simple average of SIG and BAK scores, but rather a general assessment of audio quality. After denoising, a signal should have a higher OVRL score.

DNSMOS provides a valuable additional facet in evaluating audio quality in the \intelndnschallenge{}. In addition, it gives another point of comparison to existing denoising systems; namely, DNSMOS (OVRL) was used in the Microsoft DNS Challenge \cite{dubey2022icassp}. However, we note that while DNSMOS is an important metric, we emphasize that it is not the only metric used for the evaluation of audio quality in the \intelndnschallenge{}; indeed, the spirit of the \intelndnschallenge{} is directed toward holistic innovation on neuromorphic denoising systems.

\subsection{Computational resource usage and real-time requirement}\label{subsec:comp-resource-and-real-time-req}

%\jt{This section is under construction: will have a section for latency, section for power, and then section for power-delay product. Both tracks described in each subsection; will match notation in example jupyter notebook}

Computational resource cost is evaluated in terms of power, latency, number of parameters, and model size.  To qualify as a real-time solution, the end-to-end latency must not be greater than 40ms. We measure power and latency on neuromorphic hardware in Track 2, but for Track 1, we introduce proxy metrics.  

\subsubsection{Latency}
% maximum time difference between input and output

An audio denoising system takes some amount of time to process input audio as the audio streams into the system; this results in the output human speech being delayed relative to the input human speech. This delay is the latency of the denoising system. For the denoising system to be considered real-time, the latency must be less than some human perceptual threshold, which in our case we choose to be 40ms.

We define latency as the maximum time difference between any corresponding segment of audio in the input and output of the N-DNS system. Intuitively, the longest delay in any segment of audio is the overall delay the output must be presented at in order to not introduce playback speed fluctuations in the output audio. 

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.8\textwidth]{real_time_pipeline_2023-03-09.png}
    \caption{Real-time N-DNS pipeline. Latency is calculated by considering a real-time input propagating through an entire N-DNS system. This includes latency from buffering the input data, latency from CPU processing time of the encoder and decoder, and any latency introduced by the N-DNS component ({\eg}, a network that was trained to output audio delayed relative to the input). 
    %\jt{make it clear in this figure what components are responsible for which components of latency}
    }
    \label{fig:latency}
\end{figure*}

Latency should be calculated by considering a real-time input propagating through an entire N-DNS system (\figrefprefix \ref{fig:latency}). This includes \emph{data buffer latency}, \emph{encoder-decoder latency}, and \emph{network latency (N-DNS latency)}:
\begin{enumerate}
    \item \emph{Data buffer latency} is the time required to collect the audio stream to process one discrete timestep, however that may be defined for a given encoding scheme. For the STFT encoder in our SDNN baseline solution, the data buffer latency is equal to the STFT \it{hop length}.
    \item \emph{Encoder-decoder latency} is the wall clock processing time to encode one discrete timestep-worth of the audio data, to be processed by the N-DNS network, and decode it back.
    \item \emph{Network latency (N-DNS latency)} is the latency introduced by the neuromorphic denoising network. It is measured by the maximum autocorrelation between the clean target audio and the denoised audio from the  network.
\end{enumerate}

In Track 1, notably, the (CPU) processing time for the neuromorphic denoiser (N-DNS) portion of the solution is not included in the latency calculation. We assume that the neuromorphic processing time will be small relative to the real-time timestep due to the high degree of parallelization in neuromorphic algorithms and hardware. 
In the case of the baseline SDNN, for example, the network must process a new STFT frame every 8 milliseconds, whereas Loihi 2 circuits typically complete all spike processing and neuron evaluations for a timestep within microseconds.
We provide an example Track 1 latency calculation in \secrefprefix{} \ref{sec:baseline-solutions}.

% Mathematically, we define the latency, $l$, for a single input audio clip as follows. Consider the input audio clip $s = (s_1, s_2, ..., s_N)$, where $N\in \mathbb{N}^+$ is the number of samples in the audio clip, and consider $s$ being streamed into the N-DNS system in real-time, {\ie}, $s_i$ arrives at time $t_i^s = i \Delta t_s$, where $\Delta t_s = 1/16\text{kHz}$. 
% %
% The N-DNS system processes input and outputs the waveform $\hat{s} = (\hat{s}_1, \hat{s}_2, ..., \hat{s}_N)$. 
% %
% Each $\hat{s}_{i}$ is output at a certain time; call this time $t_i^{\hat{s}}$. Then the latency is 
% \begin{equation}
% l=\max_{i \in \{1,...,N\}} (t_i^{\hat{s}} - t_i^{s}).
% \end{equation}
% Intuitively, the longest delay in any single segment of audio is the overall delay the output must be presented at in order to not introduce playback speed fluctuations in the output audio. 
% %
% We also note that an audio denoising system can optionally output an audio waveform sequence that is longer than the input audio sequence length ($N$); for example, a system might output silence while the first few milliseconds of audio are streamed in. In such a case, a continuous subsequence must be specified to form the output sequence $\hat{s}$ of length $N$, and the corresponding output times for the samples in the continuous subsequence are then used as the $t_i^{\hat{s}}$.

% highlight which block corresponds to particular latencies mentioned in baseline solution eval
% measuring the latnecy is to make sure denoising isn't all happening in encoder/decoder


% To calculate the mean latency on the test set, $L$, we first consider the latency, $l$, of a single audio clip. To calculate $l$, consider the input waveform
% $
%  a_i$  arriving at time  $t_i^a = i \Delta t_a,
% $
% $\text{where } a_i \in \mathbb{R} \text{ } \forall i \in \{1, 2, ..., S\}, S \in \mathbb{N}^+$ is the duration of the audio clip, and $\Delta t_a = \frac{1}{16kHz}$ is the audio sampling time-step.
% %
% Also consider additional zero-padding of arbitrary duration $P \in \mathbb{N}^+$, {\ie}, $a_i = 0 \; \forall i \in \{S+1, ..., S+P\}$.


% Now let the output of N-DNS system be $y_i \in \mathbb{R} \forall i \in \{1, 2, ..., S+P\}$, where each output $y_i$ occurs at time $t_i^y$. 
% %
% The latency $l$ is then 
% \begin{equation}
% l=\max_{i \in \{1,...,S\}}(t_{i+d_{step}}^y - t_i^a)
% \end{equation}
% where  $d_{step} \in \mathbb{N} $ is the output sequence lag that is used in computing SI-SNR. (In \equationsprefix \eqref{eq:si-snr}, \eqref{eq:si-sni-eq-2}, and \eqref{eq:si-sni-eq-3}, $s = (a_1, a_2, ..., a_S)$ and $\hat{s} = (y_{1+d_{step}}, y_{2+d_{step}}, ..., y_{S+d_{step}})$.) $d_{step}$ may be predetermined, {\eg}, by simply setting $d_{step}=0$ for all samples. Alternatively, $d_{step}$ may be determined post hoc, {\eg}, to align for maximum cross-correlation of input and output waveforms: $d_{step} = \arg\max_{d \in \mathbb{N}} \sum_{i=1}^{S} a_i y_{i+d}$.

% For Track 1, the times $t_i^{\hat{s}}$ include contributions from any buffering and CPU processing time for the encoder and decoder. Notably, however, the (CPU) processing time for the neuromorphic denoiser (N-DNS) portion of the solution is not included in the latency calculation; we choose to assume that the neuromorphic processing time will be relatively small due to the typically high degree of parallelization in neuromorphic algorithms and hardware. 
%
%We provide an example Track 1 latency calculation for our baseline solution in the \href{\ndnsrepourl}{\intelndnschallenge{} Github Repository}.

% the mean test set 
For Track 2, latency is simply measured on a reference CPU + Loihi 2 system. The measurement methodology and an example will be provided in the \href{\ndnsrepourl}{\intelndnschallenge{} Github Repository} later in the challenge.


% \begin{equation}
% \text{encoder output } x_i \text{ occurring at time } t_i^x,
% \end{equation}
% $\text{where } x_i \in \mathbb{R}^{D_{enc}} \text{ } \forall i \in \{1, 2, ..., S_{enc}\}, D_{enc} \in \mathbb{N}^+ \text{ is the dimension of the encoding}, S_{enc} \in \mathbb{N}^+$,
% \begin{equation}
% \text{denoiser output } o_i \text{ occurring at time } t_i^o,
% \end{equation}
% $\text{where } o_i \in \mathbb{R}^{D_{enc}} \text{ } \forall i \in \{1, 2, ..., S_{enc}\}$, and 
% \begin{equation}
% \text{decoder output } y_i \text{ occurring at time } t_i^y,
% \end{equation}
% $\text{where } y_i \in \mathbb{R} \text{ } \forall i \in \{1, 2, ..., S\}$.


% Computational resource usage is evaluated in terms of a neuromorphic power proxy for Track 1 and measured power for Track 2. 
% %\jt{A detailed procedure for measuring power and latency on the reference CPU + Loihi 2 system in Intel’s vlab will be published at a later date.} 
% The real-time requirement is implemented as a constraint on the measured latency for Track 2, and a constraint on an estimated latency for Track 1.

\subsubsection{Power}
% In the following subsections, we define the aforementioned power and latency estimate/measurements; we provide a detailed procedure for carrying out these estimates/measurements via example for our baseline solutions in \secref{sec:baseline-solutions} and \href{\ndnsrepourl}{\intelndnschallenge{} Github Repository}.

For Track 1, we calculate a power proxy by estimating the effective number of synaptic operations per second:
\begin{equation}
P_\text{proxy} = \text{Effective SynOPS} = \text{SynOPS} + 10 \times \text{NeuronOPS}, \label{eq:power-proxy}
\end{equation}
where SynOPS and NeuronOPS are the mean number of synaptic operations and mean number of neuron updates, respectively, per second of audio processed in the N-DNS stage. Synaptic operations and neuron operations can be considered the computational primitives of a neuromorphic system, and energy usage is roughly proportional to their number, with the approximate weighting of the energy of one neuron operation being equal to that of about 10 synaptic operations in our experience with the Loihi architecture \cite{davies2018loihi}. 
%
While $P_{\text{Track 1}}$ gives only a crude power estimate, it provides a simple and sufficiently reliable assessment of a neuromorphic power advantage without needing to run on neuromorphic hardware.
%
%he approximate weighting of $10 \times$ on NeuronOpRate is motivated by our experience with the Loihi chip \cite{davies2018loihi}.
%

The power consumption of the encoder and decoder is not taken into account in Track 1. We make this choice for simplicity, in expectation of the neuromorphic power dominating in realistic solutions. Note that the real-time requirement implicitly bounds the amount of computation that can be performed in the encoder and decoder. % \jt{still requires consensus}

%\subsubsection{Power for Track 2}
In Track 2, the encoder and decoder are implemented on a CPU and the N-DNS stage is implemented on a Loihi 2 system. The power is simply measured on a reference CPU and Loihi 2 system. 
Note that since both CPU and Loihi 2 power components will be measured, any attempt to implement a disproportionate amount of the denoising functionality inside the encoding/decoding CPU stages will result in a very high power result.
Details for measuring power on a reference system will be provided in the \href{\ndnsrepourl}{\intelndnschallenge{} Github Repository}.

%The latency $L_{Track 2}$ is defined with the same formula as in Track 1, however, in Track 2, it is simply measured on the reference CPU + Loihi 2 system, rather than formed by an implicit sum of latencies from various components as in Track 1. 

% \subsubsection{Latency for Track 2}
% \jt{Written description to follow consensus and match with example solution methodology}

% %\jt{Point out that we provide example latency evaluation in our baseline solution evaluations.}
% \begin{figure}[H]
%     \centering
%     \includegraphics[width=1.0\textwidth]{latency-track-2.png}
%     \caption{Latency for Track 2}
%     \label{fig:latency-track-2}
% \end{figure}

% To form an estimate for latency, consider the 
% \begin{equation}
% \text{input waveform } a_i \text{ arriving at time } t_i^a = i \Delta t_a,
% \end{equation}
% $\text{where } a_i \in \mathbb{R} \text{ } \forall i \in \{1, 2, ..., S\}, S \in \mathbb{N}^+, \text{ and } \Delta t_a = \frac{1}{16kHz}$,
% \begin{equation}
% \text{encoder output } x_i \text{ occurring at time } t_i^x,
% \end{equation}
% $\text{where } x_i \in \mathbb{R}^{D_{enc}} \text{ } \forall i \in \{1, 2, ..., S_{enc}\}, D_{enc} \in \mathbb{N}^+ \text{ is the dimension of the encoding}, S_{enc} \in \mathbb{N}^+$,
% \begin{equation}
% \text{denoiser output } o_i \text{ occurring at time } t_i^o,
% \end{equation}
% $\text{where } o_i \in \mathbb{R}^{D_{enc}} \text{ } \forall i \in \{1, 2, ..., S_{enc}\}$, and 
% \begin{equation}
% \text{decoder output } y_i \text{ occurring at time } t_i^y,
% \end{equation}
% $\text{where } y_i \in \mathbb{R} \text{ } \forall i \in \{1, 2, ..., S\}$.

% And consider a system running 

% \subsubsection{Latency Estimate for Track 1}
% \jt{Written description to follow consensus and match with example solution methodology}
% \begin{figure}[H]
%     \centering
%     \includegraphics[width=1.0\textwidth]{latency-track-1.png}
%     \caption{Latency for Track 1}
%     \label{fig:latency-track-2}
% \end{figure}

% \begin{equation}
% \text{encoder output } x_i \text{ at } t_i^a = i \Delta t_a
% \end{equation}

% To form an estimate for latency, let x[i] be the input noisy audio waveform and y[i] be the output audio waveform in discretized time, with timesteps of size $\Delta t = 1/16kHz$. We assume the input audio x[i] is sent to the encoder in real-time, {\ie}, at walltime $t = i \times \Delta t$. Similarly, the output from the decoder y[i] is read out in real-time. Thus we express the N-DNS system latency as 
% \begin{equation}
% L_{Track 1} =  argmax_d(x \star y)[d] \times  \Delta t,
% \end{equation}
% where implicitly in this formula, we include the latency from CPU processing time for the encoder and decoder, which is to be estimated by running the encoder and decoder on an actual CPU reference system \jt{specify standard reference CPU on AWS}, we include any additional latency from the (optional) grouping of audio into frames, and we include any algorithmic latency introduced by the neuromorphic denoiser, {\eg}, a multi-stage neural network with a specified wait-time between each stage. Note however, for simplicity, we do not include the processing time for the neuromorphic denoiser in this latency specification.

% \subsubsection{Real-time requirement}
% For both tracks, the real-time requirement is that the mean test set latency must be less than $40ms$. {\Ie}, $L_{Track1} < 40ms$ for Track 1, and $L_{Track2} < 40ms$ for Track 2.

%Latency must be less than 
%\jt{mean latency}

\subsubsection{Power delay product}
The Power Delay Product~(PDP) metric combines both latency and power efficiency in one number that allows comparing between different solutions that make different tradeoffs between running faster at higher power versus running slower at lower power. For Track 1, a proxy PDP measure is given by
\begin{equation}
    PDP_{\text{proxy}} = P_{\text{proxy}} \times L,
    \label{eq:pdp_proxy}
\end{equation}
which is in units of Ops because $P_{\text{proxy}}$ (\equationprefix \eqref{eq:power-proxy}) has units of Ops/s and the latency, $L$, has units of seconds.

For Track 2, PDP is directly calculated from the measured power as
\begin{equation}
    PDP = P_\text{Track 2} \times L.
\end{equation}

\subsubsection{Chip resources}
The physical resource cost of mapping networks into neuromorphic architectures is an important evaluation metric since chip resources impose a hard constraint on network complexity. Compared to conventional architectures that scale through the use of bountiful off-chip memory, neuromorphic architectures embed all network configuration on-chip, hence are limited by available state for representing synaptic weights, network routing tables, neuron parameters, and other configuration parameters. 

For Loihi 2 and similar architectures, the ultimate measure of a workload's chip resource cost is {\em core count}.  For Track 2, this is the definitive chip resource utilization metric used in this challenge.

Before networks are successfully mapped to chip, it is difficult to reliably estimate core count requirements, so for Track 1, we assess solutions by indirect measures of resource cost: parameter count and total model size.

A network's parameter count includes its total synaptic state ({\eg}, weights and delays) and neuron parameters such as decay factors.  Only unique parameters are to be counted, as expected to be uniquely configured in on-chip memories and tables leveraging convolutional and other network compression features. Note that a network's {\em trainable} parameters will be a subset of its total unique configuration parameters.  

Model size is the sum over the bit widths of all unique parameters, measured in bytes.  Since Loihi 2 supports a range of synaptic weights from one to eight bits, it is possible for two networks with the same parameter counts to have very different model sizes. All else being equal, solutions with smaller model sizes are preferred.


% \subsection{Solution code and write-up}

% Challenge participants must provide the source code used in the creation of their solution (model definition, training scripts, inference scripts, etc.) with MIT or BSD3 license.

% We encourage participants to post their code publicly during the challenge, {\eg} to Github, to help inspire others' solutions, but we understand that some participants may wish to keep their code private for competitive advantage. Thus we only require that participants publicly share their code within 14 days after the deadlines for each track. 

% We also ask that challenge participants submit a short (one or two page) write-up that explains the thought process that went into developing their solution. E.g., what worked, what did not work, why certain strategies were chosen versus others. While audio quality and power are key metrics for evaluating solutions, the overarching goal of this challenge is to drive neuromorphic algorithm innovation, and challenge participant learnings are extremely valuable.

% This write-up can be submitted directly to Intel to maintain privacy before the track deadline, but for the write-up to be considered in the holistic evaluation of the solution for the monetary prize (see Section \secref{sec:monetary-prize}), we require that it be shared publicly within 14 days after the deadline for each track. Naturally, however, we encourage participants to share their write-ups publicly at any time, to help inspire others' solutions. Additionally, we plan to invite a select group of challenge participants to present their solutions at a future Intel Neuromorphic Research Community (INRC) forum \jt{add public link to past forums} to share their learnings and participate in a discussion on developing new and improved neuromorphic computing challenges.
% %
% \jt{question - should we allow challenge participants to not publicly share their code/writeup after track 1 if they are also participating in track 2?}

% For ease of comparison, we additionally ask that solution write-ups include a table with evaluation metrics akin to Table \ref{table:baseline-metrics}.
% % \jt{write-up must include table with metrics just like [ref table in our example solution]}



% \section{Challenge timeline and submission process}\label{sec:timeline-and-submission}
% \jt{January 2022 challenge released; July 2023 Track 1 deadline; January 2024 Track 2 deadline.}

% \jt{Participants can sign up [link to some form].}

% \jt{Will participants have to sign up as affiliate members of the INRC?}

% \jt{Submissions will be welcome and encouraged at any time before the deadline.}

% \jt{Will we have a preliminary test set for them to use before the final blind test set that we'll use after the deadline?}

% \jt{Challenge participants will be given cloud access to log into Intel Lab's vLab so that they can set up and evaluate their models on Intel reference systems.}

% \jt{After the deadline has past, we will require that challenge participants log in and run their models on the blind test set within 14 days. (Uploading new models is not allowed at this point.) This step should be as simple as pointing to the final blind test set and re-running the evaluation they already had running on the example test set.}


% \section{Monetary prize}\label{sec:monetary-prize}
% Submissions from these countries will be eligible for a monetary prize:
% \begin{itemize}
% \item United States of America
% \item \jt{…}
% \end{itemize}
% Submissions from countries not on this list are also welcome \jt{is this true?}, but these submissions will not be considered for a monetary prize.
% %Submissions must report mean SI-SNR and power on the test set and satisfy the minimum audio quality (eqnref) and real-time requirement (eqnref) to be considered for a monetary prize.
% A committee of Intel employees will evaluate the solutions to decide the winners, making a holistic evaluation including audio quality, computational resource usage, solution write-up quality, innovativeness, and commercial relevance. 15,000 USD will be awarded for Track 1, and 45,000 USD will be awarded for Track 2.
% %\jt{note that this wording allows us the flexibility to split the prize as we wish vs. giving the entire award to the top submission}

% Intel reserves the right to consider and evaluate submissions at its discretion. Intel also reserves and the right to not award a monetary prize at its discretion.

% %\jt{holistically evaluated in terms of audio quality, power, write-up quality, innovativenss, and commercial relevance}



% \begin{itemize}
% \item Solutions must run inference on the test set in the \href{https://github.com/lava-nc}{Lava} framework. Our intention here is to increase neuromorphic software convergence, reproducibility, and extensibility, which has been lacking in the neuromorphic community \cite{schuman2022opportunities}. Lava provides convenient abstractions for mapping algorithms efficiently to neuromorphic hardware---which we certainly encourage challenge participants to take advantage of---however, importantly, Lava is also very flexible and arbitrary code can be wrapped into a Lava process. Also please note that there is no requirement to use Lava for model training.
% %{\Eg}, we implemented the NSNet 2 baseline solution in Section with minimal effort in Lava. \jt{tbd if we actually implement NSNet 2 in Lava?}
% \item We encourage participants to utilize the Microsoft DNS dataloaders for training data and focus on neuromorphic algorithm innovation; however, we do not restrict participants to only use the Microsoft DNS Dataset. External data and data augmentation are allowed. 
% \item Preprocessing to the input audio waveforms before the encoder is not allowed. All preprocessing is considered part of the encoder. Likewise for postprocessing and the decoder.
% \item Intel compute resources are provided only for the purpose of evaluating the metrics in \subsecref{subsec:comp-resource-and-real-time-req}. Participants must procure their own compute resources for the other aspects of the development of their solutions ({\eg}, model training).
% \end{itemize}



\section{Baseline solution}\label{sec:baseline-solutions}
We provide a baseline solution for Track 1 of the \intelndnschallenge{}, available in the \href{\ndnsrepourl}{\intelndnschallenge{} Github Repository}. In this section, we outline the baseline solution architecture, a sigma-delta neural network, and the evaluation of the baseline solution on the metrics defined in \secrefprefix{} \ref{sec:evaluation}. 
%
Later in the challenge, we will provide a Loihi 2 version of the baseline solution and evaluate it on a Loihi 2 system; we will also release the Track 2 baseline associated code.  
%is designed to map to Loihi 2, but the implementation 
 %address that this is not on Track 2 on Loihi, indicate that there will be a future baseline on Loihi; we intend to advnace to running on chip & release the code
% future work (give some sense for why intel doesn't have baseline solution on the chip)
% living baseline, designed in a way to fully support mapping onto loihi 2, what are the blocking steps we are working on, just need some software features implemented
% maybe another name for "network latency"
%

\subsection{Sigma-delta neural network architecture}


The proposed neuromorphic solution is a simple feedforward sigma-delta ReLU neural network (SDNN). The solution makes use of two neuromorphic computation ideologies: \emph{sparse message passing} using sigma-delta neuron and \emph{temporal computation} using axonal delays.

The delta encoding exploits the temporal similarity in the data. It sparsifies the data communicated to the next layer by sending only a change that is higher in magnitude than a certain threshold. The sigma encoding, on the other hand, reconstructs the original signal at the receiving end. A combination of sigma and delta units wrapped around a dynamics or a non-linearity (ReLU in this case) is a sigma-delta neuron \cite{oconnor2017sigma}. Sigma-delta neurons make use of the sparse messaging paradigm in neuromorphic hardware and result in a significant reduction in synaptic computations.

The axonal delays endow the network with a short-term memory capability that allows the interaction of audio/features originating at different points in time. Learnable axonal delays have been shown to increase the expressivity and performance of network, particularly for applications with spatio-temporal features \cite{shrestha2018slayer, shrestha2022spikemax}. Audio denoising is one such application.

The structure of the SDNN baseline solution is illustrated in \figrefprefix\ref{fig:baseline_solution}, and we describe the solution in the following.

\begin{figure*}[!ht]
    \centering
    % \includegraphics[width=\textwidth]{baseline_solution_2023-02-16.png}
    \includegraphics[width=0.8\textwidth]{sdnn_baseline.png}
    \caption{Sigma-delta neural network baseline solution structure. }
    \label{fig:baseline_solution}
\end{figure*}

\textbf{Encoder:}
The encoder is a straightforward Short-Time Fourier Transform (STFT) \cite{grochenig2001foundations} of the noisy audio waveform followed by delta encoding of the STFT magnitude. The STFT uses a \textit{window length} of 512 with a \textit{hop length} of 128, leading to 8ms per time-step. These parameters are user-configurable. The delta encoding sparsifies the STFT magnitude which is then fed to the N-DNS network.

\textbf{N-DNS:}
The neuromorphic denoiser (N-DNS) network is a three-layer feedforward sigma-delta ReLU network with axonal delays. The sigma-delta layer efficiently performs denoising in the sparse domain. The axonal delays provide the network with short term memory which can be used to incorporate previous temporal patterns during denoising. The N-DNS network predicts a multiplicative mask at some delay which is then used to mask the STFT Magnitude. The STFT phase and magnitude from the encoder need to be delayed accordingly during the decoding phase.

\textbf{Decoder:}
The decoder combines the multiplicative mask predicted by the N-DNS network with the delayed STFT phase and magnitude of the noisy audio signal and performs inverse STFT with the same \textit{window length} and \textit{hop length} as the encoder. The resulting output is the clean reconstruction (denoised) audio waveform.

% How is this trained? Important to cover (lava-dl etc.)
The SDNN baseline network was trained with Lava-dl\footnote{Lava-dl is a deep spiking neural network training library available publicly at \url{https://github.com/lava-nc/lava-dl}}, which includes the extended version of the SNN backpropagation training tool SLAYER \cite{shrestha2018slayer}. Lava-dl SLAYER uses a surrogate gradient method ({\eg}, see \cite{neftci2019surrogate}) to address the critical challenge in training spiking neural networks---the non-differentiability of spikes. The baseline network was trained with Loihi 2's fixed precision computation in mind and trained with appropriate quantization for synapse and neuron dynamics.
%
We used a combination of negative SI-SNR and a mean-square error measuring the STFT magnitude reconstruction quality as the minimization loss and a RADAM optimizer for training. The detailed training procedure, as well as Lava\footnote{Lava is a neuromorphic software framework available publicly at \url{https://github.com/lava-nc/lava}} evaluation of the baseline network, are available in \href{\ndnsrepourl}{\intelndnschallenge{} Github Repository}.


% % explain 
% % this example exploits properites X, Y, Z neuromorphic peroperits; doesn't yet have these characterists; could provide further gains
% % explain training methodology is key; how we managed to train it is important

% % describe sigma-delta neuron

% The proposed baseline solution for the \intelndnschallenge{} is a simple feedforward sigma-delta ReLU network. 
% %
% The solution makes use of two neuromorphic computation ideologies: \emph{sparse message passing} using sigma-delta neuron and \emph{temporal computation} using axonal delays.




% The delta encoding exploits the temporal similarity in the data. It sparsifies the data communicated to the next layer by sending only a change that is higher in magnitude than a certain threshold. The sigma encoding, on the other hand, reconstructs the original signal at the receiving end. A combination of sigma and delta units wrapped around a dynamics or a non-linearity (ReLU in this case) is a sigma-delta neuron \cite{oconnor2017sigma}. Sigma-delta neurons make use of the sparse messaging paradigm in neuromorphic hardware and result in a significant reduction in synaptic computations.

% The axonal delays endow the network with a short-term memory capability that allows the interaction of audio/features originating at different points in time. Learnable axonal delays have been shown to increase the expressivity and performance of network, particularly for applications with spatio-temporal features \cite{shrestha2018slayer, shrestha2022spikemax}. Audio denoising is one such application.

% The structure of the SDNN baseline solution is illustrated in \figrefprefix\ref{fig:baseline_solution}, and we describe the solution in the following.

% \begin{figure}[!ht]
%     \centering
%     % \includegraphics[width=\textwidth]{baseline_solution_2023-02-16.png}
%     \includegraphics[width=\textwidth]{sdnn_baseline.png}
%     \caption{Sigma-delta neural network baseline solution structure. }
%     \label{fig:baseline_solution}
% \end{figure}

% \textbf{Encoder:}
% The encoder is a straightforward Short-Time Fourier Transform (STFT) \cite{grochenig2001foundations} of the noisy audio waveform followed by delta encoding of the STFT magnitude. The STFT uses a \textit{window length} of 512 with a \textit{hop length} of 128, leading to 8ms per time-step. These parameters are user-configurable. The delta encoding sparsifies the STFT magnitude which is then fed to the N-DNS network.

% \textbf{N-DNS:}
% The neuromorphic denoiser (N-DNS) network is a three-layer feedforward sigma-delta ReLU network with axonal delays. The sigma-delta layer efficiently performs denoising in the sparse domain. The axonal delays provide the network with short term memory which can be used to incorporate previous temporal patterns during denoising. The N-DNS network predicts a multiplicative mask at some delay which is then used to mask the STFT Magnitude. The STFT phase and magnitude from the encoder need to be delayed accordingly during the decoding phase.

% \textbf{Decoder:}
% The decoder combines the multiplicative mask predicted by the N-DNS network with the delayed STFT phase and magnitude of the noisy audio signal and performs inverse STFT with the same \textit{window length} and \textit{hop length} as the encoder. The resulting output is the clean reconstruction (denoised) audio waveform.

% % How is this trained? Important to cover (lava-dl etc.)
% The SDNN baseline network was trained with lava-dl SLAYER \footnote{Lava-dl is a deep spiking neural network training library available publicly at \url{https://github.com/lava-nc/lava-dl}}. Lava-dl uses a surrogate gradient method \cite{shrestha2018slayer,neftci2019surrogate} to address the critical challenge in training spiking neural networks---the non-differentiability of spikes. 
% We used a combination of negative SI-SNR and a mean-square error measuring the STFT magnitude reconstruction quality as the minimization loss and a RADAM optimizer for training. The detailed training procedure, as well as lava\footnote{Lava is a neuromorphic software framework available publicly at \url{https://github.com/lava-nc/lava}} evaluation of the baseline network, are available in \href{\ndnsrepourl}{\intelndnschallenge{} Github Repository}.

\subsection{Evaluation Metrics}
% emphasize this is Track 1
% address that this is not on Track 2 on Loihi, indicate that there will be a future baseline on Loihi; we intend to advnace to running on chip & release the code
% future work (give some sense for why intel doesn't have baseline solution on the chip)
% living baseline, designed in a way to fully support mapping onto loihi 2, what are the blocking steps we are working on, just need some software features implemented
% maybe another name for "network latency"


We evaluated the SDNN baseline solution, Microsoft NsNet2 (the baseline network for Microsoft DNS 2022), and \ipgnet\/ using Track 1 metrics on the validation set.
The metrics are summarized in \tablerefprefix{} \ref{tab:evaluation_metrics_comparison}.
All three networks use STFT encoding and ISTFT decoding.

\ipgnet{} is an Intel proprietary network used in production. The model is causal, operates in real-time, and is built from LSTM and 2D convolution layers. Power metrics for this network are not available. The network was trained using proprietary datasets and augmentation techniques, and as such we view its audio quality results as upper-bound aspirational targets for challenge submissions.  

The audio quality metrics include DNSMOS scores, SI-SNR, and improvement in SI-SNR (SI-SNRi). The encoder and decoder for all three networks perform lossless transformation using STFT and ISTFT. As a result, relative performance differences across models in SI-SNR and SI-SNRi are equal.

The latency was calculated by summing data buffer latency, encoder-decoder latency, and network latency (N-DNS latency), as described in \secrefprefix{} \ref{sec:evaluation}. 

Power proxy and PDP proxy metrics provide some measure of the relative power and power-delay-product across the three networks suitable for Track 1 comparisons. For the SDNN baseline, these are calculated according to {\equationsprefix} (\ref{eq:power-proxy}) and (\ref{eq:pdp_proxy}), respectively. For the conventional Microsoft NsNet2 network, Ops refer to Multiply–accumulate operations (MACs) without considering the negligible cost of per-neuron ReLU evaluation.

% \jt{commentary on DNSMOS, all three scores from Adam}
% \jt{(just put in text) An Intel proprietary network used in production. The Intel proprietary network is used in production/close to a network shipped in production systems.}
% \jt{everything in table should be explained in text, why power measurement not available for IPG network}
% \jt{missing: discussion of SOTA DNS - generally approaches people have taken, where we see potentially fruitful directions to improve on them in neuromorphic domain. cochleogram-based encoding approach, reference sips paper, NsNet, general approaches leading in the literature today, nsnet not representative of current sota; IPG doens't focus on improving mos like dns. these ar eth arch tha re being devloepd in dns domain, our obseration that we see model size expense to audio qulaity metrics}
% \jt{ talk about SOTA and differnet ideas, avenues for innovation, in "audio denoising task" section}
% \jt{baseline is an example of this direction we are proposing}
% \jt{methods section after?}
% \jt{share results in simplified way in section 3; how much is the signal quality better/worse and how much power has been reduce, latency, etc parameters, c.f. Microsoft nsnet2; punchline early in paper; like msr; little hard with audio quality because all different metrics to consider, include si-snr and representative }
% \jt{find a way to more simply state in section 3 si-snr is amoutn of nlsie elimianted, ovrl is overal perceptual quality. if they dont' understan dpsecific, look to later sections}


% \jt{
% after audio denoising task section

% "neuromorphic denoising"
% here's the first solution to this problem
% audio encoding perspective and network perspective
% and talk about cochleogram
% }
% \jt{ expand audio denoising task to cover current soluation sota and soem backgorudn of this applicaiton domain, what ppl have tried and what's working now}
% \jt{new section on neuromrophic audio denoisign, different directions for innovation and first neuromrophci solution we are offering here as baseline for the challenge}

% \jt{maybe consider putting neuromrophic computing + neuromrphic denosing together}

% \jt{intro, audio denoising, neuromorphic audio denoising - directions and our example solution and as we've hypthethiszed we've been able to reduce power}

% \jt{somewhere may want to mention; also possible to apply sigme delta to other neuron models}

% \jt{daniel can add a few words about promises and challenges of going down cochleogram path (but don't want to turn this into a big long discussion), good to highlight these other ideas, and interesting space of research to explore}

% \jt{new structure, and clear sections where we need input}

\begin{table*}[!ht]
    \centering
    \scriptsize
    \caption{Evaluation metrics comparison.}
    \label{tab:evaluation_metrics_comparison}
    \setlength\tabcolsep{3pt} % default is 6pt
    \begin{tabular}{l|r|r|r|r|r|r|r|r|r|r|r|r}
         \multicolumn{1}{@{}c@{}|}{\multirow{3}{*}{\bf Network}} &
         \multirow{2}{*}{\bf SI-SNR} &
         \multicolumn{2}{@{}c@{}|}{\bf SI-SNRi} &
         \multicolumn{3}{@{}c@{}|}{\bf DNSMOS$^\ddag$} &
         \multicolumn{2}{@{}c@{}|}{\bf Latency} &
         \multicolumn{1}{c|}{\bf Power} &
         \multicolumn{1}{c|}{\bf PDP} &
         \multicolumn{1}{c|}{\bf Param} &
         \multicolumn{1}{c}{\bf Model}\\ \cline{3-9}
         & &data & enc+dec & OVRL & SIG & BAK & enc+dec$^\dagger$
         & \multicolumn{1}{c|}{total} &
         \multicolumn{1}{c|}{\bf proxy} &
         \multicolumn{1}{c|}{\bf proxy} & 
         \multicolumn{1}{c|}{\bf count} &
         \multicolumn{1}{c}{\bf size} \\
         & \multicolumn{1}{c|}{dB}
         & \multicolumn{1}{c|}{dB}
         & \multicolumn{1}{c|}{dB}
         & \multicolumn{1}{c|}{}
         & \multicolumn{1}{c|}{}
         & \multicolumn{1}{c|}{}
         & \multicolumn{1}{c|}{ms}
         & \multicolumn{1}{c|}{ms}
         & \multicolumn{1}{c|}{M-Ops/s}
         & \multicolumn{1}{c|}{M-Ops}
         & \multicolumn{1}{c|}{$\times 10^3$}
         & \multicolumn{1}{c}{KB}\\ \hline\hline
         Microsoft NsNet2    & 11.89 & 4.26 & 4.26 & 2.95 & 3.27 & 3.94 & 0.024 & 20.024 & 136.13 & 2.72 & 2,681 & 10,500\\
         \ipgnet             & 12.71 & 5.09 & 5.09 & 3.09 & 3.35 & 4.08 & 0.036 &  8.036 &  - & - &   1,901 & 3,802\\  % 1901571
         {\bf SDNN baseline} & 12.50 & 4.88 & 4.88 & 2.71 & 3.21 & 3.46 & 0.036 &  8.036 &  14.54 & 0.11 &   525 & 465\\
         Validation set (noisy)     &  7.62 &    - &    - & 2.45 & 3.19 & 2.72 & - & - & - & - & - & -\\
         \hline
         & \multicolumn{6}{c|}{higher is better ($\uparrow$)} & \multicolumn{6}{c}{lower is better ($\downarrow$)} \\
         \multicolumn{12}{p{12cm}}{\tiny$^\dagger$ Latency results measured on a system with Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz and 32 GB RAM as of Feb 2023 and may not reflect all publicly available security updates. Results may vary.} \\
         \multicolumn{12}{p{12cm}}{\tiny$^\ddag$ Please note that the DNSMOS scores in this table are not directly comparable to the DNSMOS scores presented in the results of the Microsoft DNS Challenge due to differing composition of validation/test sets.}
    \end{tabular}\label{table:baseline-metrics}
\end{table*}

% Power Proxy without SDNN filtering: 29564640.594 ops/s (2.03x more)

% an extra metric to the effect of number of parameters or memory
% parameter count; model size

% separate out dollar amounts, countries, about the competition
% clarita's rules document - customized to the competition, legal def of the rules

% factor out 6,7,8?
% add summary/conclusion - what are we hoping to accomplish; like GSC dataset paper
% representative of wide class of problems

% missing - existing tools available for training models for the challenge, expecting innovation in training tools to win the challenge -> Mike read introduction and determine where to add 

% talk about how baseline solution was trained (lava-dl, dataset, etc.) and the training scripts.

% change format to NeurIPS format

% don't emphasize relevant for Intel in diagram

%\ipgcontrib{Would like Adam and Lukasz's review of this "results table take-home story" below (no need to write this section; just review)}

%\jt{Mike's advice - first write in a way that doesn't reveal details about Intel DNS Network}

%\jt{Mike's advice - in parallel, if these is something OK to disclose, would be nice to get sense if can disclose some information; but if not, OK}

%
%\jt{Mike rec - point out SDNN model has not been tuned to do well on DNSMOS; we trained it for SI-SNR}

%\jt{Mike rec - baseline scoring high on SI-SNR, even happier to raise DNSMOS value, but objective is to show we can train snns to achieve high performance with minimal parameters and power; groups should not focus unduly on DNSMOS} 

We see that our SDNN baseline is a promising neuromorphic solution to the audio denoising problem. In terms of audio quality, the SDNN baseline has a higher SI-SNR relative to the NsNet2 baseline solution from the Microsoft DNS Challenge 2022, and lower relative DNSMOS scores. Notably, our baseline solution training targeted an SI-SNR loss, thus better relative SI-SNR performance may be expected. Nonetheless, it is encouraging to see substantial DNSMOS improvement over the unprocessed noisy input in a system not trained specifically for perceptual quality. And importantly, the SDNN solution is an order of magnitude more efficient than the NsNet2 baseline in terms of the power proxy, and it uses $5\times$ fewer parameters. The quantization-aware training of the baseline SDNN solution further reduces the model size by $22\times$ compared to NsNet2.

Naturally, the NsNet2 solution is a baseline and does not represent state-of-the-art for audio denoising today. For example, the Intel production DNS model (Intel DNS network) achieves higher SI-SNR and DNSMOS than both NsNet2 and the SDNN baseline solution (\tablerefprefix{} \ref{tab:evaluation_metrics_comparison}). 
Given the simplicity of our SDNN baseline solution as a starting point for neuromorphic audio denoising, we believe it will be possible to significantly improve its denoising quality while also reducing its computational resources with further algorithmic innovations in the \intelndnschallenge{}.
%\sscontrib{Jonathan: moved this para here. It makes more impact.}

Notably, the sigma-delta approach in our baseline solution is quite general. Sigma-delta sparsification can be applied to any conventional ReLU-like nonlinearity as well as to the dynamics present in typical neuromorphic neuron models such as leaky integrators and resonators.  
Furthermore, sigma-delta sparsification represents just one neuromorphic feature available of many to exploit by participants in the challenge. We see a wide space of uncharted waters to explore for the \intelndnschallenge{}. Our baseline solution represents just a first step, and we find it encouraging that it already provides promising results.


% \sscontrib{Sumit - was our SDNN baseline architecture inspired by the NsNet2 architecture? If this is the case, we could mention that they have similar levels of “simplicity” as baseline solutions, so this bodes well for further neuromorphic innovation} % Not really. So commented it.



% The SDNN baseline solution shows a promising neuromorphic solution with better denoising quality as well as lower computation resource usage metrics when compared to NsNet2 (the baseline network of Microsoft DNS challenge 2022). However, there is still a gap in sheer denoising quality to the best non-neuromorphic DNN solution. [TODO: discuss DNSMOS implications]. On the other hand, there is still room for reducing the computational resource of the solution. For {\eg}, the internal production DNS network at Intel <<Uses ?? resources>>. We believe it is possible to push the envelope of denoising quality as well as minimize the computational resources through further algorithmic innovations in neuromorphic computation through the challenge.
% We can see that the SDNN baseline solution does not yield as high audio quality as NsNet2. However, the SDNN baseline solution compares quite favorably in terms of computational resource usage metrics. Given the sheer simplicity of the SDNN baseline solution, we believe this comparison bodes well for the challenge that remains: improving audio quality beyond the SDNN baseline solution while maintaining the efficiency advantage provided by neuromorphic computation. 

% this bodes well for unveiling 

% simp shows promise for neuromorphic efficiency, and now the challenge is to improve the audio quality beyond that of the SDNN solution, while maintaining the efficiency advantage from neuromorphic processing.

\section{Additional information}\label{sec:clarifications}

Please see the \href{\ndnsrepourl}{\intelndnschallenge{} Github Repository} for the official competition rules, timeline, registration procedure, metrics boards, code, and datasets. Any additional clarifications that may arise during the challenge will be posted there. 
%\sscontrib{Do we need a separate section just to send this message?}

% \section{Discussion}\label{sec:discussion}


\section{Conclusion}\label{sec:conclusion}



We introduce the Intel Neuromorphic DNS Challenge to fulfill a vital need for a widely-applicable challenge problem that facilities algorithm innovation leading to a clear demonstration of neuromorphic hardware benefits. 

%
We include two tracks to encourage (1) algorithmic innovation and (2) demonstration on neuromorphic hardware, and we specify task performance metrics and computational cost metrics to make it easy to compare different solutions.
%
Furthermore, we provide permissively-licensed dataloader scripts, evaluation scripts, and an example neuromorphic baseline solution for accessibility, convenience, consistency, and extensibility. 
We also offer a monetary prize to encourage participation. 
%

We look forward to the learnings that we gain as a community through the \ndnschallenge{}, both in terms of the innovation that occurs in the solution space, as well as the insights that can inform the development of future neuromorphic challenge problems.
%These learnings, taken together, represent a powerful vector of progress toward fully realizing the incredible potential of neuromorphic computation. 




% \bibliographystyle{unsrtnat}
% \bibliographystyle{abbrvnat}
% \bibliography{references}


% \printbibliography[title=References]
% \bibliographystyle{unsrt}
\bibliographystyle{ieeetr}
% \bibliography{references}
\bibliography{references}

\end{document}