\section{Conclusion}
In this study, we investigated the non-equivariant similarity issue in VLMs, hidden behind their excellent performances on standard evaluation benchmarks.
To address this issue, we proposed Equivariance Similarity Learning (\algname), an elegant and effective regularization method that can be easily integrated into the fine-tuning process of existing VLMs. 
Meanwhile, to better diagnose the equivariance of VLMs, we further introduced a new challenging benchmark \benchname, the first to focus on ``visual-minimal change''.
Our proposed \algname is backed by the strong results on both challenging benchmarks (\eg, Winoground, VALSE, \benchname) and the conventional Flickr30K dataset.
In future work, we plan to explore the application of \algname in VL pre-training and instruction tuning.
\noindent\textbf{Acknowledgement.} We thank Ziyi Dou, Xuejiao Zhao for valuable discussions and help, and all 
anonymous reviewers for constructive suggestions. This work is partly supported by AI Singapore AISG2-RP-2021-022.