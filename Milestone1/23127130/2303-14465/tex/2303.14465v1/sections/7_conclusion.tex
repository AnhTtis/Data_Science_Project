\section{Conclusion}
In this study, we investigated the non-equivariant similarity issue in VLMs, hidden behind their excellent performances on standard evaluation benchmarks.
To address this issue, we proposed Equivariance Similarity Learning (\algname), an elegant and effective regularization method that can be easily integrated into the fine-tuning process of existing VLMs. 
Meanwhile, to better diagnose the equivariance of VLMs, we further introduced a new challenging benchmark \benchname, the first to focus on ``visual-minimal change''.
Our proposed \algname is backed by the strong results on both challenging benchmarks (\eg, Winoground, VALSE, \benchname) and the conventional Flickr30K dataset.
In future work, we plan to explore the application of \algname in VL pre-training, as well as extending \benchname to more diverse video datasets and synthetic engines. 