\input{table/classification_race.tex}

\newpage

\newpage

\appendix
\section{Appendix}

\subsection{Implementation Details}
\textbf{\model{}: }
\model{} exploits the multi-layer perceptron architecture for both the main model and counterfactual sample generator. The main model consists of the backbone network ($f$), the projection head ($g$), and two prediction heads ($h_1$, $h_2$). We chose all components to be ReLU networks, whose hidden dimension is set to 256. The backbone network has three layers, and all heads have two layers. \model{} is trained 200 epochs, and its batch size is set to 128. The Adam optimizer with a learning rate of 1e-3 and a weight decay factor of 1e-6 is adopted. We apply one-hot encoding to discrete variables for input preprocessing and z-score scaling to continuous variables. \looseness=-1 \smallskip

\noindent
\textbf{Counterfactual sample generator: }
We introduce the C-VAE model to generate counterfactual samples. When preprocessing the input data, discrete values are encoded into the one-hot vector, and every continuous value is converted to a vector of probability density via mode-specific normalization~\cite{xu2019modeling}. Mode-specific normalization uses a variational Gaussian mixture model (VGM) to estimate the number of modes and fit the Gaussian mixture model on top of the target distribution. Then, the probability density of each mode is computed for the normalization. We discovered that mode-specific normalization improves counterfactual sample quality more than naive min-max normalization. The counterfactual sample generator is trained for 600 epochs, and the batch size is set to 256. The weight between reconstruction loss and probability distribution loss is set to 2:1. \looseness=-1 \smallskip

% \noindent
% \textbf{Baselines: } For baseline implementations, we followed the settings from the original paper. L-MIFR and MIFR aim to maximize the conditional mutual information while satisfying the fairness constraints (i.e., $\max MI(X; Y|Z)$ s.t. $MI(Y;Z) < \epsilon$). Similarly, C-InfoNCE and WeaC-InfoNCE aim to maximize the conditional mutual information but optimize lower bound via the InfoNCE objective. \model{} and baseline results satisfy $\epsilon = 0.1$ fairness constraints. We followed the same data preprocessing step for all baselines for comparison. \smallskip

\noindent
\textbf{Computational complexity: } 
We used four A100 GPUs for all experiments. Our model took 20\% more training time than WeaC-InfoNCE (11 vs. 9 minutes for 200 epochs), and the counterfactual VAE training took less than 5 minutes.

\subsection{Further Results on Performance Evaluation}
We present the performance of \model{} and other baselines on downstream classification tasks by setting gender as the sensitive attribute in the main manuscript. We here present the extra results on race to support \model{}'s generalizability on different sensitive attributes. In the race attribute, UCI Adult, COMPAS, and LSAC have five, five, and six classes, respectively. UCI German Credit dataset does not include race information and hence is skipped. The evaluation results in Table~\ref{table:overallresults_race} demonstrate that \model{} learns data distribution of critical features while minimizing spurious information from the multi-class sensitive attribute. 


\begin{figure*}[t!]
\centering
\begin{subfigure}[t]{0.23\textwidth}
\captionsetup{justification=centering}
       \centering\includegraphics[height=3.2cm]{figure/qualitative_unaware_scarf.png}
      \caption{SCARF \\(AUC=0.92)}
      \label{fig:scarf}
\end{subfigure}
\hspace{1mm}
\begin{subfigure}[t]{0.23\textwidth}
\captionsetup{justification=centering}
       \centering\includegraphics[height=3.2cm]{figure/qualitative_epoch1.png}
      \caption{\model{} 1 epoch \\(AUC=0.75)}
      \label{fig:epoch1}
\end{subfigure}
\hspace{1mm}
\begin{subfigure}[t]{0.23\textwidth}
\captionsetup{justification=centering}
      \centering\includegraphics[height=3.2cm]{figure/qualitative_epoch10.png}
      \caption{\model{} 10 epochs \\(AUC=0.72)}
      \label{fig:epoch10}
\end{subfigure}
\hspace{1mm}
\begin{subfigure}[t]{0.23\textwidth}
\captionsetup{justification=centering}
       \centering\includegraphics[height=3.2cm]{figure/qualitative_epoch200.png}
      \caption{\model{} 200 epochs \\(AUC=0.61)}
      \label{fig:epoch200}
\end{subfigure}
\caption{UMAP visualization of trained embeddings over UCI Adult dataset from (a) SCARF and (b-d) \model{} with different epochs. Each dot represents the embedding of each individual, and color displays his/her gender. With these embeddings, we fit a classifier to predict the sensitive attribute (i.e., gender) of the test instances, anticipating that sensitive attribute cannot be determined from \model{} embeddings. As we expected, classifying the sensitive attribute using \model{} embeddings was difficult (i.e., AUC=0.61). We can infer that sensitive information was avoided in the process of creating the embedding.
}
\label{fig:qualitative}
\end{figure*}

% To confirm the effectiveness of TabMix, we tested three ablations on positive sample selection strategy: (1) Identical: setting positive sample identical to the anchor, (2) Gaussian noise: adding small noise, (3) Dropout: dropping random features. When we perform experiments on the Adult dataset, baselines show either lower AUROC (Gaussian noise: 0.86$\rightarrow$0.82) or higher DP (Identical: 0.07$\rightarrow$0.11, Dropout: 0.07$\rightarrow$0.08) than TabMix. In addition, WeaC-InfoNCE with counterfactual loss shows better results than the original WeaC-InfoNCE. (AUROC: 0.82$\rightarrow$0.82, DP: 0.08$\rightarrow$0.06, CP: 0.19$\rightarrow$0.16). However, the performance was not as good as DualFair (AUROC: 0.82, DP: 0.04, CP: 0.02).

\subsection{Further Results on Ablation study}
To confirm the effectiveness of the proposed counterfactual sample generator, we further assessed two ablations on loss objectives: (1) without cyclic consistency loss $L_{\text{cyc}}$ (Eq.~\ref{eq:cyc_loss}) and (2) without reconstruction loss in $L_{\text{vae}}$ (Eq.~\ref{eq:vae_loss}). Table~\ref{Tab:counterfactual-ablation} reports the test set performance of the logistic regression model, after fitting with synthetic counterfactual samples from each baseline. When we conduct experiments over four datasets, our model with full components outperforms baselines in terms of both the AUC and F1-score.

\input{table/counterfactual_ablation.tex}


\subsection{Further Results on Qualitative Analysis}
Figure~\ref{fig:qualitative} visualizes the embeddings over the UCI Adult dataset from four models: SCARF and \model{} at three different points of training (1, 10, and 200 epoch). SCARF does not consider any fairness requirements, and hence the learned representations of the same protected group (i.e., gender) are placed nearby, forming a local cluster in the embedding space (see Fig.~\ref{fig:scarf}). When we fit the logistic regression model to predict the sensitive attribute on top of the embeddings, the model reports very high AUC values. Meanwhile, the sensitive information is debiased across the epochs, and the sensitive attribute becomes indistinguishable in the embedding space (see Fig.~\ref{fig:epoch1}--\ref{fig:epoch200}). The AUC result in this new embedding gradually decreases with the training epoch. 

