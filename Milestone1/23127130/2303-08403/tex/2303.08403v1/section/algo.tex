
% \normalem
\begin{algorithm}[t!]
\small{
\SetAlgoLined
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
\Indmm \Indmm
\Input{Backbone network $f$, projection head $g$, two prediction heads $h_1$, $h_2$, sample generator $q_\phi$ and $p_\theta$, and the training set $\mathcal{D}$}
\Output{Trained backbone network $f$}
\Indpp \Indpp
\ForEach{batch $\mathcal{B}^s \subset \mathcal{D}$}
{
    $L_{\text{fair-CL}}, L_{\text{self-KD}} \gets 0, 0 $ \\
    $\mathcal{B}^{s}_{\text{pert}} \gets \text{TabMix}(\mathcal{B}^s, \text{Sample}(\mathcal{D} \setminus \mathcal{B}^s))$  \tcp{(Eq.~\ref{eq:tabmix})}
    $\mathcal{B}^{s'}_{\text{cnt}} \gets \text{Convert}(\mathcal{B}^s, q_\phi, p_\theta)$ \tcp{(Sec. 3.2)}
    \ForEach{$\mathbf{x}^s \in \mathcal{B}_s$, $\mathbf{x}^s_{\text{pert}} \in \mathcal{B}^{s}_{\text{pert}}$, and $\mathbf{x}^{s'}_{\text{cnt}} \in \mathcal{B}^{s'}_{\text{cnt}}$}
    {   
        $\mathcal{X}^s_{-} = \{ \mathbf{x} | \mathbf{x} \in \mathcal{B}_s\setminus\{\mathbf{x}^s\} \}$ \\
         \tcp{Fairness-aware contrastive loss (Eq.~\ref{eq:contrast_loss})}
         $L_{\text{fair-CL}} \gets L_{\text{fair-CL}} + L_{\text{gen-c}} (\mathbf{x}^s, \mathbf{x}^{s'}_{\text{cnt}}, \mathcal{X}^s_{-})$ \\ \vspace{2mm}
         \tcp{Self-knowledge distillation loss (Eq.~\ref{eq:self-kd})}
         $\mathbf{p}_{\text{student}} \gets h_2 \circ g \circ f(\mathbf{x}^s_{\text{pert}})$ \\
         $\mathbf{z}_{\text{teacher}} \gets (g \circ f(\mathbf{x}^s)).\text{detach()}$ \\
         $L_{\text{self-KD}} \gets L_{\text{self-KD}} - ({\mathbf{p}_{\text{student}} \over || \mathbf{p}_{\text{student}} ||_2} \cdot {\mathbf{z}_{\text{teacher}}  \over || \mathbf{z}_{\text{teacher}} ||_2})$  \\
    }
    $L_{\text{total}} = {1 \over |\mathcal{B}_s|}(L_{\text{fair-CL}} +  L_{\text{self-KD}})$  \\
    Update weights via back-propagation
}
\caption{Overall training procedure (for one epoch)}}
\label{algo:algorithm}
\end{algorithm}
% \ULforem