

\vspace{-1mm}
\section{Conclusion}
\vspace{-2mm}
We proposed FAVD, a new audio-visual-language modeling task that aims to generate paragraph-level fine-grained textual descriptions for every object in the given audible videos. A new benchmark called FAVDBench was constructed to facilitate the research. Two new metrics were designed to evaluate the quality of the generated descriptions, where the EntityScore is used to assess the completeness of entities in descriptions and the AudioScore evaluates the accuracy of audio descriptions. We also presented a transformer-based architecture AVLFormer for this task. Extensive experiments validated our model and metrics design. We intend to 
explore architectures in FAVDBench~\cite{qin2022cosformer,sun2022vicinity,qin2023toeplitz}, and use FAVDBench to investigate audible video generation in the future.



\noindent
\textbf{Acknowledgement:}
We thank Lei Li and Hai Jie for their valuable advice on this work. This work is partially supported by the National Key R\&D Program of China (NO.2022ZD0160100) and partly by the Shanghai Committee of Science and Technology (Grant No. 21DZ1100100). 