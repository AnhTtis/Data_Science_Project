@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


@inproceedings{xu2016msr,
  title={Msr-vtt: A large video description dataset for bridging video and language},
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5288--5296},
  year={2016}
}
@inproceedings{wang2019vatex,
  title={Vatex: A large-scale, high-quality multilingual dataset for video-and-language research},
  author={Wang, Xin and Wu, Jiawei and Chen, Junkun and Li, Lei and Wang, Yuan-Fang and Wang, William Yang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4581--4591},
  year={2019}
}
@inproceedings{ZhXuCoAAAI18,
    author={Zhou, Luowei and Xu, Chenliang and Corso, Jason J},
    title = {Towards Automatic Learning of Procedures From Web Instructional Videos},
    booktitle = {AAAI Conference on Artificial Intelligence},
    pages={7590--7598},
    year = {2018},
    url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17344}
}
@inproceedings{vinyals2015show,
  title={Show and tell: A neural image caption generator},
  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3156--3164},
  year={2015}
}
@inproceedings{donahue2015long,
  title={Long-term recurrent convolutional networks for visual recognition and description},
  author={Donahue, Jeffrey and Anne Hendricks, Lisa and Guadarrama, Sergio and Rohrbach, Marcus and Venugopalan, Subhashini and Saenko, Kate and Darrell, Trevor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2625--2634},
  year={2015}
}
@inproceedings{fang2015captions,
  title={From captions to visual concepts and back},
  author={Fang, Hao and Gupta, Saurabh and Iandola, Forrest and Srivastava, Rupesh K and Deng, Li and Doll{\'a}r, Piotr and Gao, Jianfeng and He, Xiaodong and Mitchell, Margaret and Platt, John C and others},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1473--1482},
  year={2015}
}
@inproceedings{lu2017knowing,
  title={Knowing when to look: Adaptive attention via a visual sentinel for image captioning},
  author={Lu, Jiasen and Xiong, Caiming and Parikh, Devi and Socher, Richard},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={375--383},
  year={2017}
}
@inproceedings{chen2015mind,
  title={Mind's eye: A recurrent visual representation for image caption generation},
  author={Chen, Xinlei and Lawrence Zitnick, C},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2422--2431},
  year={2015}
}
@article{venugopalan2014translating,
  title={Translating videos to natural language using deep recurrent neural networks},
  author={Venugopalan, Subhashini and Xu, Huijuan and Donahue, Jeff and Rohrbach, Marcus and Mooney, Raymond and Saenko, Kate},
  journal={arXiv preprint arXiv:1412.4729},
  year={2014}
}
@inproceedings{chen2011collecting,
  title={Collecting highly parallel data for paraphrase evaluation},
  author={Chen, David and Dolan, William B},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies},
  pages={190--200},
  year={2011}
}
@inproceedings{caba2015activitynet,
  title={ActivityNet: A Large-Scale Video Benchmark for Human Activity Understanding},
  author={Fabian Caba Heilbron, Victor Escorcia, Bernard Ghanem and Juan Carlos Niebles},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={961--970},
  year={2015}
}
@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2425--2433},
  year={2015}
}
@article{wang2022geb+,
  title={GEB+: A benchmark for generic event boundary captioning, grounding and text-based retrieval.},
  author={Wang, Yuxuan and Gao, Difei and Yu, Licheng and Lei, Stan Weixian and Feiszli, Matt and Shou, Mike Zheng},
  journal={CoRR},
  year={2022}
}



@inproceedings{zhou2018end,
  title={End-to-end dense video captioning with masked transformer},
  author={Zhou, Luowei and Zhou, Yingbo and Corso, Jason J and Socher, Richard and Xiong, Caiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8739--8748},
  year={2018}
}

@inproceedings{li2018jointly,
  title={Jointly localizing and describing events for dense video captioning},
  author={Li, Yehao and Yao, Ting and Pan, Yingwei and Chao, Hongyang and Mei, Tao},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7492--7500},
  year={2018}
}

@inproceedings{mun2019streamlined,
  title={Streamlined dense video captioning},
  author={Mun, Jonghwan and Yang, Linjie and Ren, Zhou and Xu, Ning and Han, Bohyung},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6588--6597},
  year={2019}
}

@inproceedings{wang2018bidirectional,
  title={Bidirectional attentive fusion with context gating for dense video captioning},
  author={Wang, Jingwen and Jiang, Wenhao and Ma, Lin and Liu, Wei and Xu, Yong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7190--7198},
  year={2018}
}

@inproceedings{krishna2017dense,
  title={Dense-captioning events in videos},
  author={Krishna, Ranjay and Hata, Kenji and Ren, Frederic and Fei-Fei, Li and Carlos Niebles, Juan},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={706--715},
  year={2017}
}

@inproceedings{suin2020efficient,
  title={An efficient framework for dense video captioning},
  author={Suin, Maitreya and Rajagopalan, AN},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={07},
  pages={12039--12046},
  year={2020}
}


@inproceedings{wang2021end,
  title={End-to-end dense video captioning with parallel decoding},
  author={Wang, Teng and Zhang, Ruimao and Lu, Zhichao and Zheng, Feng and Cheng, Ran and Luo, Ping},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6847--6857},
  year={2021}
}

@inproceedings{deng2021sketch,
  title={Sketch, ground, and refine: Top-down dense video captioning},
  author={Deng, Chaorui and Chen, Shizhe and Chen, Da and He, Yuan and Wu, Qi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={234--243},
  year={2021}
}

@inproceedings{iashin2020multi,
  title={Multi-modal dense video captioning},
  author={Iashin, Vladimir and Rahtu, Esa},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={958--959},
  year={2020}
}

@inproceedings{chen2020learning,
  title={Learning modality interaction for temporal sentence localization and event captioning in videos},
  author={Chen, Shaoxiang and Jiang, Wenhao and Liu, Wei and Jiang, Yu-Gang},
  booktitle={European Conference on Computer Vision},
  pages={333--351},
  year={2020},
  organization={Springer}
}

@article{iashin2020better,
  title={A better use of audio-visual cues: Dense video captioning with bi-modal transformer},
  author={Iashin, Vladimir and Rahtu, Esa},
  journal={arXiv preprint arXiv:2005.08271},
  year={2020}
}

@inproceedings{rahman2019watch,
  title={Watch, listen and tell: Multi-modal weakly supervised dense event captioning},
  author={Rahman, Tanzila and Xu, Bicheng and Sigal, Leonid},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={8908--8917},
  year={2019}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}

@inproceedings{tran2015learning,
  title={Learning spatiotemporal features with 3d convolutional networks},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4489--4497},
  year={2015}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}
@inproceedings{kim2019audiocaps,
  title={Audiocaps: Generating captions for audios in the wild},
  author={Kim, Chris Dongjoo and Kim, Byeongchang and Lee, Hyunmin and Kim, Gunhee},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={119--132},
  year={2019}
}
@inproceedings{drossos2020clotho,
  title={Clotho: An audio captioning dataset},
  author={Drossos, Konstantinos and Lipping, Samuel and Virtanen, Tuomas},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={736--740},
  year={2020},
  organization={IEEE}
}
@inproceedings{das2013thousand,
  title={A thousand frames in just a few words: Lingual description of videos through latent topics and sparse object stitching},
  author={Das, Pradipto and Xu, Chenliang and Doell, Richard F and Corso, Jason J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2634--2641},
  year={2013}
}
@inproceedings{lei2020tvr,
  title={Tvr: A large-scale dataset for video-subtitle moment retrieval},
  author={Lei, Jie and Yu, Licheng and Berg, Tamara L and Bansal, Mohit},
  booktitle={European Conference on Computer Vision},
  pages={447--463},
  year={2020},
  organization={Springer}
}
@inproceedings{liu2022video,
  title={Video swin transformer},
  author={Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3202--3211},
  year={2022}
}
@article{koutini2021efficient,
  title={Efficient training of audio transformers with patchout},
  author={Koutini, Khaled and Schl{\"u}ter, Jan and Eghbal-zadeh, Hamid and Widmer, Gerhard},
  journal={arXiv preprint arXiv:2110.05069},
  year={2021}
}
@inproceedings{lin2022swinbert,
  title={SwinBERT: End-to-end transformers with sparse attention for video captioning},
  author={Lin, Kevin and Li, Linjie and Lin, Chung-Ching and Ahmed, Faisal and Gan, Zhe and Liu, Zicheng and Lu, Yumao and Wang, Lijuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17949--17958},
  year={2022}
}
@article{hessel2021clipscore,
  title={Clipscore: A reference-free evaluation metric for image captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv preprint arXiv:2104.08718},
  year={2021}
}

@article{mei2021audio,
  title={Audio captioning transformer},
  author={Mei, Xinhao and Liu, Xubo and Huang, Qiushi and Plumbley, Mark D and Wang, Wenwu},
  journal={arXiv preprint arXiv:2107.09817},
  year={2021}
}

@article{ye2021improving,
  title={Improving the performance of automated audio captioning via integrating the acoustic and textual information},
  author={Ye, Zhongjie and Wang, Helin and Yang, Dongchao and Zou, Yuexian},
  journal={DCASE2021 Challenge, Tech. Rep.},
  year={2021}
}

@article{liu2021cl4ac,
  title={CL4AC: A contrastive loss for audio captioning},
  author={Liu, Xubo and Huang, Qiushi and Mei, Xinhao and Ko, Tom and Tang, H Lilian and Plumbley, Mark D and Wang, Wenwu},
  journal={arXiv preprint arXiv:2107.09990},
  year={2021}
}

@article{eren2021audio,
  title={Audio Captioning Using Sound Event Detection},
  author={Eren, Ay{\c{s}}eg{\"u}l {\"O}zkaya and Sert, Mustafa},
  journal={arXiv preprint arXiv:2110.01210},
  year={2021}
}

@article{mei2021encoder,
  title={An encoder-decoder based audio captioning system with transfer and reinforcement learning},
  author={Mei, Xinhao and Huang, Qiushi and Liu, Xubo and Chen, Gengyun and Wu, Jingqian and Wu, Yusong and Zhao, Jinzheng and Li, Shengchen and Ko, Tom and Tang, H Lilian and others},
  journal={arXiv preprint arXiv:2108.02752},
  year={2021}
}

@article{chan2015listen,
  title={Listen, attend and spell},
  author={Chan, William and Jaitly, Navdeep and Le, Quoc V and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1508.01211},
  year={2015}
}

@inproceedings{amodei2016deep,
  title={Deep speech 2: End-to-end speech recognition in english and mandarin},
  author={Amodei, Dario and Ananthanarayanan, Sundaram and Anubhai, Rishita and Bai, Jingliang and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Cheng, Qiang and Chen, Guoliang and others},
  booktitle={International conference on machine learning},
  pages={173--182},
  year={2016},
  organization={PMLR}
}

@article{gulati2020conformer,
  title={Conformer: Convolution-augmented transformer for speech recognition},
  author={Gulati, Anmol and Qin, James and Chiu, Chung-Cheng and Parmar, Niki and Zhang, Yu and Yu, Jiahui and Han, Wei and Wang, Shibo and Zhang, Zhengdong and Wu, Yonghui and others},
  journal={arXiv preprint arXiv:2005.08100},
  year={2020}
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

@article{chorowski2015attention,
  title={Attention-based models for speech recognition},
  author={Chorowski, Jan K and Bahdanau, Dzmitry and Serdyuk, Dmitriy and Cho, Kyunghyun and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}
@inproceedings{sigurdsson2016hollywood,
  title={Hollywood in homes: Crowdsourcing data collection for activity understanding},
  author={Sigurdsson, Gunnar A and Varol, G{\"u}l and Wang, Xiaolong and Farhadi, Ali and Laptev, Ivan and Gupta, Abhinav},
  booktitle={European Conference on Computer Vision},
  pages={510--526},
  year={2016},
  organization={Springer}
}

@inproceedings{tang2021clip4caption,
  title={Clip4caption: Clip for video caption},
  author={Tang, Mingkang and Wang, Zhanyu and Liu, Zhenhua and Rao, Fengyun and Li, Dian and Li, Xiu},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={4858--4862},
  year={2021}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{chen2018less,
  title={Less is more: Picking informative frames for video captioning},
  author={Chen, Yangyu and Wang, Shuhui and Zhang, Weigang and Huang, Qingming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={358--373},
  year={2018}
}

@inproceedings{venugopalan2015sequence,
  title={Sequence to sequence-video to text},
  author={Venugopalan, Subhashini and Rohrbach, Marcus and Donahue, Jeffrey and Mooney, Raymond and Darrell, Trevor and Saenko, Kate},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4534--4542},
  year={2015}
}

@inproceedings{xu2017learning,
  title={Learning multimodal attention LSTM networks for video captioning},
  author={Xu, Jun and Yao, Ting and Zhang, Yongdong and Mei, Tao},
  booktitle={Proceedings of the 25th ACM international conference on Multimedia},
  pages={537--545},
  year={2017}
}

@inproceedings{wang2018reconstruction,
  title={Reconstruction network for video captioning},
  author={Wang, Bairui and Ma, Lin and Zhang, Wei and Liu, Wei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7622--7631},
  year={2018}
}

@inproceedings{pei2019memory,
  title={Memory-attended recurrent network for video captioning},
  author={Pei, Wenjie and Zhang, Jiyuan and Wang, Xiangrong and Ke, Lei and Shen, Xiaoyong and Tai, Yu-Wing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8347--8356},
  year={2019}
}
@inproceedings{arandjelovic2018objects,
  title={Objects that sound},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={435--451},
  year={2018}
}

@inproceedings{aafaq2019spatio,
  title={Spatio-temporal dynamics and semantic attribute enriched visual encoding for video captioning},
  author={Aafaq, Nayyer and Akhtar, Naveed and Liu, Wei and Gilani, Syed Zulqarnain and Mian, Ajmal},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12487--12496},
  year={2019}
}

@inproceedings{zhang2020object,
  title={Object relational graph with teacher-recommended learning for video captioning},
  author={Zhang, Ziqi and Shi, Yaya and Yuan, Chunfeng and Li, Bing and Wang, Peijin and Hu, Weiming and Zha, Zheng-Jun},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={13278--13288},
  year={2020}
}

@inproceedings{pan2020spatio,
  title={Spatio-temporal graph for video captioning with knowledge distillation},
  author={Pan, Boxiao and Cai, Haoye and Huang, De-An and Lee, Kuan-Hui and Gaidon, Adrien and Adeli, Ehsan and Niebles, Juan Carlos},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10870--10879},
  year={2020}
}

@article{fang2020video2commonsense,
  title={Video2commonsense: Generating commonsense descriptions to enrich video captioning},
  author={Fang, Zhiyuan and Gokhale, Tejas and Banerjee, Pratyay and Baral, Chitta and Yang, Yezhou},
  journal={arXiv preprint arXiv:2003.05162},
  year={2020}
}

@article{luo2020univl,
  title={Univl: A unified video and language pre-training model for multimodal understanding and generation},
  author={Luo, Huaishao and Ji, Lei and Shi, Botian and Huang, Haoyang and Duan, Nan and Li, Tianrui and Li, Jason and Bharti, Taroon and Zhou, Ming},
  journal={arXiv preprint arXiv:2002.06353},
  year={2020}
}

@article{2020t5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1-67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@inproceedings{papineni-etal-2002-bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}

@inproceedings{denkowski-lavie-2014-meteor,
    title = "Meteor Universal: Language Specific Translation Evaluation for Any Target Language",
    author = "Denkowski, Michael  and
      Lavie, Alon",
    booktitle = "Proceedings of the Ninth Workshop on Statistical Machine Translation",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W14-3348",
    doi = "10.3115/v1/W14-3348",
    pages = "376--380",
}

@INPROCEEDINGS{7299087,  
    author={Vedantam, Ramakrishna and Zitnick, C. Lawrence and Parikh, Devi},  
    booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   
    title={CIDEr: Consensus-based image description evaluation},   
    year={2015},  
    volume={},  
    number={},  
    pages={4566-4575},  
    doi={10.1109/CVPR.2015.7299087}
}

@inproceedings{10.3115/1073445.1073465,
    author = {Lin, Chin-Yew and Hovy, Eduard},
    title = {Automatic Evaluation of Summaries Using N-Gram Co-Occurrence Statistics},
    year = {2003},
    publisher = {Association for Computational Linguistics},
    address = {USA},
    url = {https://doi.org/10.3115/1073445.1073465},
    doi = {10.3115/1073445.1073465},
    abstract = {Following the recent adoption by the machine translation community of automatic evaluation using the BLEU/NIST scoring process, we conduct an in-depth study of a similar idea for evaluating summaries. The results show that automatic evaluation using unigram co-occurrences between summary pairs correlates surprising well with human evaluations, based on various statistical metrics; while direct application of the BLEU evaluation procedure does not always give good results.},
    booktitle = {Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1},
    pages = {71â€“78},
    numpages = {8},
    location = {Edmonton, Canada},
    series = {NAACL '03}
}

@INPROCEEDINGS{7952261,  
    author={Gemmeke, Jort F. and Ellis, Daniel P. W. and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R. Channing and Plakal, Manoj and Ritter, Marvin},  
    booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   
    title={Audio Set: An ontology and human-labeled dataset for audio events},   year={2017},  
    volume={},  
    number={},  
    pages={776-780},  
    doi={10.1109/ICASSP.2017.7952261}
}
@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}
@article{carreira2018short,
  title={A short note about kinetics-600},
  author={Carreira, Joao and Noland, Eric and Banki-Horvath, Andras and Hillier, Chloe and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1808.01340},
  year={2018}
}
@inproceedings{gemmeke2017audio,
  title={Audio set: An ontology and human-labeled dataset for audio events},
  author={Gemmeke, Jort F and Ellis, Daniel PW and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R Channing and Plakal, Manoj and Ritter, Marvin},
  booktitle={2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={776--780},
  year={2017},
  organization={IEEE}
}
@article{merullo2022linearly,
  title={Linearly Mapping from Image to Text Space},
  author={Merullo, Jack and Castricato, Louis and Eickhoff, Carsten and Pavlick, Ellie},
  journal={arXiv preprint arXiv:2209.15162},
  year={2022}
}
@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}
@inproceedings{denkowski2014meteor,
  title={Meteor universal: Language specific translation evaluation for any target language},
  author={Denkowski, Michael and Lavie, Alon},
  booktitle={Proceedings of the ninth workshop on statistical machine translation},
  pages={376--380},
  year={2014}
}
@inproceedings{rouge2004package,
  title={A package for automatic evaluation of summaries},
  author={ROUGE, Lin CY},
  booktitle={Proceedings of Workshop on Text Summarization of ACL, Spain},
  year={2004}
}
@inproceedings{vedantam2015cider,
  title={Cider: Consensus-based image description evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4566--4575},
  year={2015}
}
@article{hong2022cogvideo,
  title={CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers},
  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},
  journal={arXiv preprint arXiv:2205.15868},
  year={2022}
}
@inproceedings{monfort2021spoken,
  title={Spoken moments: Learning joint audio-visual representations from video descriptions},
  author={Monfort, Mathew and Jin, SouYoung and Liu, Alexander and Harwath, David and Feris, Rogerio and Glass, James and Oliva, Aude},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14871--14881},
  year={2021}
}
@article{singer2022make,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792},
  year={2022}
}
@inproceedings{rohrbach2015dataset,
  title={A dataset for movie description},
  author={Rohrbach, Anna and Rohrbach, Marcus and Tandon, Niket and Schiele, Bernt},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3202--3212},
  year={2015}
}
@article{aafaq2019video,
  title={Video description: A survey of methods, datasets, and evaluation metrics},
  author={Aafaq, Nayyer and Mian, Ajmal and Liu, Wei and Gilani, Syed Zulqarnain and Shah, Mubarak},
  journal={ACM Computing Surveys (CSUR)},
  volume={52},
  number={6},
  pages={1--37},
  year={2019},
  publisher={ACM New York, NY, USA}
}
@article{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  journal={arXiv preprint arXiv:2201.12086},
  year={2022}
}
@inproceedings{lei2021less,
  title={Less is more: Clipbert for video-and-language learning via sparse sampling},
  author={Lei, Jie and Li, Linjie and Zhou, Luowei and Gan, Zhe and Berg, Tamara L and Bansal, Mohit and Liu, Jingjing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7331--7341},
  year={2021}
}
@InProceedings{Vinyals_2015_CVPR,
author = {Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
title = {Show and Tell: A Neural Image Caption Generator},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
}
@article{ordonez2011im2text,
  title={Im2text: Describing images using 1 million captioned photographs},
  author={Ordonez, Vicente and Kulkarni, Girish and Berg, Tamara},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@inproceedings{pan2020x,
  title={X-linear attention networks for image captioning},
  author={Pan, Yingwei and Yao, Ting and Li, Yehao and Mei, Tao},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10971--10980},
  year={2020}
}

@inproceedings{li2022comprehending,
  title={Comprehending and Ordering Semantics for Image Captioning},
  author={Li, Yehao and Pan, Yingwei and Yao, Ting and Mei, Tao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17990--17999},
  year={2022}
}

@inproceedings{gurari2020captioning,
  title={Captioning images taken by people who are blind},
  author={Gurari, Danna and Zhao, Yinan and Zhang, Meng and Bhattacharya, Nilavra},
  booktitle={European Conference on Computer Vision},
  pages={417--434},
  year={2020},
  organization={Springer}
}

@inproceedings{huang2022dse,
  title={DSE-GAN: Dynamic Semantic Evolution Generative Adversarial Network for Text-to-Image Generation},
  author={Huang, Mengqi and Mao, Zhendong and Wang, Penghui and Wang, Quan and Zhang, Yongdong},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={4345--4354},
  year={2022}
}

@inproceedings{wu2022nuwa,
  title={N{\"u}wa: Visual synthesis pre-training for neural visual world creation},
  author={Wu, Chenfei and Liang, Jian and Ji, Lei and Yang, Fan and Fang, Yuejian and Jiang, Daxin and Duan, Nan},
  booktitle={European Conference on Computer Vision},
  pages={720--736},
  year={2022},
  organization={Springer}
}

@article{nichol2021glide,
  title={Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
  author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  journal={arXiv preprint arXiv:2112.10741},
  year={2021}
}

@inproceedings{gu2022vector,
  title={Vector quantized diffusion model for text-to-image synthesis},
  author={Gu, Shuyang and Chen, Dong and Bao, Jianmin and Wen, Fang and Zhang, Bo and Chen, Dongdong and Yuan, Lu and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10696--10706},
  year={2022}
}

@inproceedings{ruan2021dae,
  title={Dae-gan: Dynamic aspect-aware gan for text-to-image synthesis},
  author={Ruan, Shulan and Zhang, Yong and Zhang, Kun and Fan, Yanbo and Tang, Fan and Liu, Qi and Chen, Enhong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={13960--13969},
  year={2021}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@inproceedings{bar2022text2live,
  title={Text2live: Text-driven layered image and video editing},
  author={Bar-Tal, Omer and Ofri-Amar, Dolev and Fridman, Rafail and Kasten, Yoni and Dekel, Tali},
  booktitle={European Conference on Computer Vision},
  pages={707--723},
  year={2022},
  organization={Springer}
}

@inproceedings{li2020manigan,
  title={Manigan: Text-guided image manipulation},
  author={Li, Bowen and Qi, Xiaojuan and Lukasiewicz, Thomas and Torr, Philip HS},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7880--7889},
  year={2020}
}
@article{nam2018text,
  title={Text-adaptive generative adversarial networks: manipulating images with natural language},
  author={Nam, Seonghyeon and Kim, Yunji and Kim, Seon Joo},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@article{ho2022imagen,
  title={Imagen video: High definition video generation with diffusion models},
  author={Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norouzi, Mohammad and Fleet, David J and others},
  journal={arXiv preprint arXiv:2210.02303},
  year={2022}
}
@article{villegas2022phenaki,
  title={Phenaki: Variable length video generation from open domain textual description},
  author={Villegas, Ruben and Babaeizadeh, Mohammad and Kindermans, Pieter-Jan and Moraldo, Hernan and Zhang, Han and Saffar, Mohammad Taghi and Castro, Santiago and Kunze, Julius and Erhan, Dumitru},
  journal={arXiv preprint arXiv:2210.02399},
  year={2022}
}
@article{aytar2017see,
  title={See, hear, and read: Deep aligned representations},
  author={Aytar, Yusuf and Vondrick, Carl and Torralba, Antonio},
  journal={arXiv preprint arXiv:1706.00932},
  year={2017}
}
@article{hayakawa2019language,
  title={How Language Shapes the Brain},
  author={Hayakawa, Sayuri and Marian, Viorica},
  journal={Scientific Am., Apr},
  volume={30},
  year={2019}
}

@article{origgi2000evolution,
  title={Evolution, communication and the proper function of language},
  author={Origgi, Gloria and Sperber, Dan},
  journal={Evolution and the human mind: Language, modularity and social cognition},
  pages={140--169},
  year={2000},
  publisher={Cambridge University Press Cambridge}
}
@misc{leech1974semantics,
  title={Semantics. England},
  author={Leech, Geoffrey},
  year={1974},
  publisher={Penguin Books Ltd}
}
@inproceedings{guzhov2022audioclip,
  title={Audioclip: Extending clip to image, text and audio},
  author={Guzhov, Andrey and Raue, Federico and Hees, J{\"o}rn and Dengel, Andreas},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={976--980},
  year={2022},
  organization={IEEE}
}
@article{unterthiner2018towards,
  title={Towards accurate generative models of video: A new metric \& challenges},
  author={Unterthiner, Thomas and van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Raphael and Michalski, Marcin and Gelly, Sylvain},
  journal={arXiv preprint arXiv:1812.01717},
  year={2018}
}

#######################
@article{zhou2023audio,
  title={Audio-Visual Segmentation with Semantics},
  author={Zhou, Jinxing and Shen, Xuyang and Wang, Jianyuan and Zhang, Jiayi and Sun, Weixuan and Zhang, Jing and Birchfield, Stan and Guo, Dan and Kong, Lingpeng and Wang, Meng and others},
  journal={arXiv preprint arXiv:2301.13190},
  year={2023}
}
@inproceedings{zhou2022audio,
  title={Audio--Visual Segmentation},
  author={Zhou, Jinxing and Wang, Jianyuan and Zhang, Jiayi and Sun, Weixuan and Zhang, Jing and Birchfield, Stan and Guo, Dan and Kong, Lingpeng and Wang, Meng and Zhong, Yiran},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXVII},
  pages={386--403},
  year={2022},
  organization={Springer}
}
@article{qin2022devil,
  title={The Devil in Linear Transformer},
  author={Qin, Zhen and Han, XiaoDong and Sun, Weixuan and Li, Dongxu and Kong, Lingpeng and Barnes, Nick and Zhong, Yiran},
  journal={arXiv preprint arXiv:2210.10340},
  year={2022}
}
@article{lu2022linear,
  title={Linear Video Transformer with Feature Fixation},
  author={Lu, Kaiyue and Liu, Zexiang and Wang, Jianyuan and Sun, Weixuan and Qin, Zhen and Li, Dong and Shen, Xuyang and Deng, Hui and Han, Xiaodong and Dai, Yuchao and others},
  journal={arXiv preprint arXiv:2210.08164},
  year={2022}
}
@article{liu2022neural,
  title={Neural architecture search on efficient transformers and beyond},
  author={Liu, Zexiang and Li, Dong and Lu, Kaiyue and Qin, Zhen and Sun, Weixuan and Xu, Jiacheng and Zhong, Yiran},
  journal={arXiv preprint arXiv:2207.13955},
  year={2022}
}
@article{sun2022vicinity,
  title={Vicinity vision transformer},
  author={Sun, Weixuan and Qin, Zhen and Deng, Hui and Wang, Jianyuan and Zhang, Yi and Zhang, Kaihao and Barnes, Nick and Birchfield, Stan and Kong, Lingpeng and Zhong, Yiran},
  journal={arXiv preprint arXiv:2206.10552},
  year={2022}
}
@article{qin2022cosformer,
  title={cosformer: Rethinking softmax in attention},
  author={Qin, Zhen and Sun, Weixuan and Deng, Hui and Li, Dongxu and Wei, Yunshen and Lv, Baohong and Yan, Junjie and Kong, Lingpeng and Zhong, Yiran},
  journal={arXiv preprint arXiv:2202.08791},
  year={2022}
}
@inproceedings{
qin2023toeplitz,
title={Toeplitz Neural Network for Sequence Modeling},
author={Zhen Qin and Xiaodong Han and Weixuan Sun and Bowen He and Dong Li and Dongxu Li and Yuchao Dai and Lingpeng Kong and Yiran Zhong},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=IxmWsm4xrua}
}
@article{zhou2023improving,
  title={Improving Audio-Visual Video Parsing with Pseudo Visual Labels},
  author={Zhou, Jinxing and Guo, Dan and Zhong, Yiran and Wang, Meng},
  journal={arXiv preprint arXiv:2303.02344},
  year={2023}
}
@inproceedings{cheng2022implicit,
  title={Implicit motion handling for video camouflaged object detection},
  author={Cheng, Xuelian and Xiong, Huan and Fan, Deng-Ping and Zhong, Yiran and Harandi, Mehrtash and Drummond, Tom and Ge, Zongyuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13864--13873},
  year={2022}
}
@article{sun2021getam,
  title={Getam: Gradient-weighted element-wise transformer attention map for weakly-supervised semantic segmentation},
  author={Sun, Weixuan and Zhang, Jing and Liu, Zheyuan and Zhong, Yiran and Barnes, Nick},
  journal={arXiv preprint arXiv:2112.02841},
  year={2021}
}
@inproceedings{zhong20183d,
  title={3D geometry-aware semantic labeling of outdoor street scenes},
  author={Zhong, Yiran and Dai, Yuchao and Li, Hongdong},
  booktitle={2018 24th International Conference on Pattern Recognition (ICPR)},
  pages={2343--2349},
  year={2018},
  organization={IEEE}
}
@article{zhang2021depth,
  title={Depth confidence-aware camouflaged object detection},
  author={Zhang, Jing and Lv, Yunqiu and Xiang, Mochu and Li, Aixuan and Dai, Yuchao and Zhong, Yiran},
  journal={arXiv e-prints},
  pages={arXiv--2106},
  year={2021}
}
@article{sun2023munet,
  title={Munet: Motion uncertainty-aware semi-supervised video object segmentation},
  author={Sun, Jiadai and Mao, Yuxin and Dai, Yuchao and Zhong, Yiran and Wang, Jianyuan},
  journal={Pattern Recognition},
  volume={138},
  pages={109399},
  year={2023},
  publisher={Elsevier}
}

@article{song2022memorial,
  title={Memorial GAN With Joint Semantic Optimization for Unpaired Image Captioning},
  author={Song, Peipei and Guo, Dan and Zhou, Jinxing and Xu, Mingliang and Wang, Meng},
  journal={IEEE Transactions on Cybernetics},
  year={2022},
  publisher={IEEE}
}

@article{song2022contextual,
  title={Contextual attention network for emotional video captioning},
  author={Song, Peipei and Guo, Dan and Cheng, Jun and Wang, Meng},
  journal={IEEE Transactions on Multimedia},
  year={2022},
  publisher={IEEE}
}

@inproceedings{zhou2021semi,
  title={Semi-autoregressive transformer for image captioning},
  author={Zhou, Yuanen and Zhang, Yong and Hu, Zhenzhen and Wang, Meng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3139--3143},
  year={2021}
}