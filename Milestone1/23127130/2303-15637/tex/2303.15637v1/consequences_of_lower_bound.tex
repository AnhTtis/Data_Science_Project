\section{Consequences of the Lower Bound}
\label{s: consequences of lower bound}

In this section, we examine cases where the bound in \Cref{cor: asymptotic lower bound} has interpretable dependence upon system properties. To do so, we restrict attention to the setting where all system parameters are unknown, i.e. $\VEC \bmat{A(\theta) & B(\theta)} = \theta$. 
In this setting, the quantity $\dop_\theta \VEC \bmat{A(\theta) & B(\theta)}$ arising in the bounds from the previous section is the identity matrix. 

The derivative of the controller multiplied by a matrix with orthonormal columns,  $\dop_\theta \VEC K(\theta) V$, arises in the bounds from the previous section. In this section, this quantity is expressed in terms of the directional derivative of the controller in some direction $v$, denoted $d_v K(\theta)$. In particular, we represent the columns of $V$ as $v = \VEC \bmat{\Delta_A & \Delta_B}$ for arbitrary perturbations $\Delta_A$ of $A$ and $\Delta_B$ of $B$ which satisfy $\norm{\bmat{\Delta_A & \Delta_B}}_F=1$. The corresponding change in the closed-loop state matrix is denoted $\Delta_{A_{cl}} = \Delta_A + \Delta_B K$. 
Then the directional derivative of the controller is shown in Lemma B.1 of \cite{simchowitz2020naive} to be
    \begin{align}
        \label{eq: directional derivative of lqr}
        d_v K(\theta)\! =\! -\!\Psi^{-1} (\Delta_B^\top P A_{cl} \!+\! B^\top P \Delta_{A_{cl}} \!+\! B^\top P' A_{cl}),
    \end{align}
    where $P' = \texttt{dlyap}(A_{cl}, A_{cl}^\top P \Delta_{A_{cl}} + \Delta_{A_{cl}}^\top P A_{cl})$.
The subsequent sections study the bound from \Cref{cor: asymptotic lower bound} under various perturbations $\bmat{\Delta_A & \Delta_B}$.  \ifnum\value{cdc}>0{}\else{Proofs are deferred to \Cref{s: proofs of consequences}}\fi. 

%We show in Section~\ref{s: dimensional dependence} that the lower bound recovers the optimal dimensional dependence. In Section~\ref{s: exp}, we will demonstrate that there exist systems where the lower bound grows exponentially in the state dimesion. Lastly, in Section~\ref{s: system properties}, we will show that the bounds scale as expected with interpretable system properties such as the eigenvalues of the controllability gramian. 

% \Ingvar{Consider re-organizing so that system dependecies show up first. Our audience probably cares more about these!}





\subsection{Dimensional dependence}

In the setting of online LQR for an unknown system, recent works \citep{simchowitz2020naive, ziemann2022regret} obtaining lower bounds on the regret have %\footnote{Regret is the running average  suboptimality for online problems.} 
used perturbation directions which cause tension between identification and control \citep{polderman1986necessity}. In particular, they considered the set of perturbation directions 
\ifnum\value{cdc}>0{
\begin{equation}
\begin{aligned}
\label{eq: polderman perturbation}
&\boldsymbol \Delta \!=\!
\curly{\!\VEC\! \bmat{-\Delta K \!\! &\!\! \Delta } \!\bigg\vert \Delta \!\in\! \mathbb{R}^{\dx \times \du}, \! \norm{\bmat{-\Delta K \!\! &\!\! \Delta }}_F \!=\! 1\!}.
\end{aligned} 
\end{equation}
}\else{
\begin{align}
\label{eq: polderman perturbation}
\boldsymbol \Delta = \curly{\VEC \bmat{-\Delta K & \Delta } \bigg\vert \Delta \in \mathbb{R}^{\dx \times \du}, \norm{\bmat{-\Delta K & \Delta }}_F = 1}.
\end{align} }\fi
% Such perturbations are parameterized as $v(\Delta) \in \boldsymbol\Delta$. 
For all such perturbations, $\Delta_{A_{cl}} = 0$, making it impossible to distinguish between the true parameters and the perturbed parameters online without sufficient exploratory input noise. 

While the tension between identification and control is no longer present in the offline setting, this set of perturbation directions retains the benefit that the directional derivative in \eqref{eq: directional derivative of lqr} is easy to work with. In particular for any $v = \VEC \bmat{-\Delta K & \Delta} \in \boldsymbol \Delta$,
\begin{align}
    \label{eq: polderman derivative}
        d_v K(\theta) = -\Psi^{-1} \Delta^\top P A_{cl}. 
\end{align}
 
    As the matrices $\Delta$ parametrizing the set $\boldsymbol \Delta$ are $\dx \times \du$ dimensional, we may stack $\dx\du$ orthogonal vectors $v_i$ belonging $\boldsymbol \Delta$ into a matrix $V = \bmat{v_1 & \dots & v_{\dx \du}}$. This allows us to present a lower bound which demonstrates the dependence of the offline LQR problem upon the system dimensions $\dx$ and $\du$. 
    \begin{proposition}
    \label{prop: dimensional dependence}
    Suppose that $T \geq \frac{16 \norm{\Sigma_X}^2}{\lambda_{\min}(\Sigma_X)}$. Then for $\alpha \in (0,1/2)$, 
    \ifnum\value{cdc}>0{
    \begin{align*}
        \liminf_{N \to \infty} &\sup_{\theta' \in \mathcal{B}(\theta, N^{-\alpha}) } N \mathsf{EC}_T^\pi(\theta')   \geq \\  &\frac{\dx \du \lambda_{\min}(\Sigma_X - \Sigma_W) \lambda_{\min}(P)^2}{16 T \norm{\Psi} \norm{ \bmat{-K & I}}^2 \tilde L},
    \end{align*}
    }\else{
    \begin{align*}
        \liminf_{N \to \infty} \sup_{\theta' \in \mathcal{B}(\theta, N^{-\alpha}) } N \mathsf{EC}_T^\pi(\theta')   \geq  \frac{\dx \du \lambda_{\min}(\Sigma_X - \Sigma_W) \lambda_{\min}(P)^2}{16T \norm{\Psi} \norm{ \bmat{-K & I}}^2  \tilde L} 
    \end{align*}}\fi
    % where $\bar L$ is as in \Cref{prop: system theoretic}.
    where $\tilde L$ is given by $L(\theta)$ as in \eqref{eq: info bound L} by replacing $\nu_1$ with $1$ and $\nu_2$ with $1 + 2\norm{F}^2$.
    % \ifnum\value{cdc}>0{
    % \begin{align*}
    %      \bar L &= \frac{2 }{\lambda_{\min}(\Sigma_W)}
    %      \bigg( 2 \beta + \paren{1 +  2 \norm{F}^2}  \\ &\cdot \bigg(\norm{\dlyap\paren{(A(\theta)+B(\theta)F)^\top, \Sigma_W}} \\ &\qquad  
    %      + \beta \sum_{t=0}^{\infty} \norm{\paren{(A(\theta) +  B(\theta)F)^t B}}^2 \bigg) \bigg). 
    % \end{align*}
    % }\else{
    % \begin{align*}
    %      \bar L &= \frac{2 }{\lambda_{\min}(\Sigma_W)}
    %      \bigg( 2 \beta + \paren{1 +  2 \norm{F}^2}  \\ &\cdot \bigg(\norm{\dlyap\paren{(A(\theta)+B(\theta)F)^\top, \Sigma_W}} 
    %      + \beta \sum_{t=0}^{\infty} \norm{\paren{(A(\theta) +  B(\theta)F)^t B}}^2 \bigg) ). 
    % \end{align*}}\fi
    \end{proposition}
    
    In addition to the system dimensions, we can interpret the remaining system-theoretic parameters. 
    Note that $\tilde L$ bounds the information available from the offline experimentation. It depends on the norm of the controllability gramian from noise to the state, as well as $ \sigma_{\tilde u}^2 \paren{\sum_{t=0}^\infty \norm{(A+BF)^t B}}^2$, which bounds the impact of the exploratory input on the state. %consists of norms of quantities that resemble the Gramian of the closed-loop system under the exploration policy from the noise, and from the exploratory input. The energy of the exploratory input signal also makes an appearance. As the exploratory budget becomes small, $\beta \to 0$, the $\bar L$ approaches the norm of the controllabiltiy gramian from noise of the closed-loop system, scaled by the process noise level and the norm of the pre-stabilizing controller. 
    % As in \Cref{prop: dimensional dependence}, $\lambda_{\min}(\Sigma_X - \Sigma_W)$ highlights the dependence on the closed-loop state covariance, and $\bar L$ describes the impact of the controllability of the closed-loop system under the pre-stabilizing controller, as well as the input budget.
     %In particular, the lower bound becomes small as the system becomes easily controllable during experimentation. Similarly, the lower bound becomes small when the exploratory input budget is large. 
     The $\Psi$ in the denominator of the above bound may scale as $\lambda_{\max}(P)$, and therefore effectively cancels a $\lambda_{\min}(P)$ in the numerator for well-conditioned problems. This leaves a single $\lambda_{\min}(P)$ in the numerator. As $x^\top P x$ is the optimal objective value of the noiseless LQR problem starting from initial state $x$, the appearance of $\lambda_{\min}(P)$ in the bound captures the fact that as the system becomes harder to control, it also becomes harder to learn to control. 
     Lastly, the variance term $\lambda_{\min}(\Sigma_X  - \Sigma_W)$ implies that the excess cost is large when the optimal closed-loop system has a large state covariance relative to the process noise covariance. 

    \ifnum\value{cdc}>0{
    \begin{remark}
        The dimensional dependence $\dx\du$  is optimal up to constant factors for classes of under-actuated systems in which remaining system-theoretic quantities are constant with respect to system dimension. In particular, suppose that  $\tilde U_{t,n} \sim \calN(0, \sigma_{\tilde u}^2 I)$, and that $N \geq c \dx$, for some universal constant $c$. In this case, Theorem 2 of \cite{mania2019certainty} combined with Theorem 5.4 in \cite{tu2022learning} demonstrate 
        the upper bound on the excess cost scales with  $\frac{\dx \du}{NT}$. 
    \end{remark}
    }\else{
    \begin{remark}
        The dimensional dependence $\dx\du$ in the above bound is optimal up to constant factors when $\du \leq \dx$. To see that this is so, observe that Theorem 2 of \cite{mania2019certainty} demonstrates an upper bound on the excess cost that scales as $\du \e^2$, where $\e^2$ bounds the system identification error, $\max\curly{\norm{\hat A - A}^2, \norm{\hat B - B}^2}$. A consequence of Theorem 5.4 in \cite{tu2022learning} is that if we apply exploratory inputs which are generated from a Gaussian distribution with mean zero and covariance $ \sigma_{\tilde u}^2 I$, then the upper bound on the system identification error scales as $\frac{\dx + \du}{NT}$. In particular, as long as number of offline trajectories $N$ exceeds $c \dx$, for some universal constant $c$, then 
        $\max\curly{\norm{\hat A - A}^2, \norm{\hat B - B}^2} \lesssim \norm{\Sigma_W} \frac{\dx+\du}{NT \lambda_{\min}(\textrm{controllability gramian})}$. 
        Consequently, the upper bound on the excess cost scales with $\frac{\du (\dx + \du)}{NT} \lesssim \frac{\dx \du}{NT}$ in the underactuated setting.
        %\Tasos{typo? $\du (\dx + \du)$?}. 
        Therefore, for classes of systems where the remaining system-theoretic quantities are constant with respect to system dimension, the bound is optimal in the dimension. 
    \end{remark}
    }\fi

\label{s: dimensional dependence}
\subsection{Exponential Lower Bounds}
\label{s: exp}
% \Tasos{I still have some questions regarding Lemma 2.4. Shouldn't we have a product between $D_{\theta}B(\theta)$ and the covariance of $X$ even for $F=0$? For example in the system below. We have $x_{t,1}=2^{n-1}(1+\theta)u_{t-n}+noise$, if we take $1+\theta$ to be the last coordinate of $B$. It seems to me that the  Fisher information should be exponential (or $\nu_1\neq 0$), not equal to $16\beta$. With a small perturbation of $B$ we get a huge effect on $x_{t,1}$. Am I missing something? Is it hidden under the Sigma noise somehow?}
The previous section demonstrated a lower bound that scales linearly with $\dx \du$. Prior work \citep{tsiamis2022learning} has shown that in the setting of online LQR, there exist classes of systems where the lower bounds on the regret may scale exponentially with the state dimension. This is shown by demonstrating that particular system-theoretic terms, which are often treated as constant with respect to dimension, may actually grow exponentially with the state dimension. 
We demonstrate that in the setting of offline LQR, such systems still cause exponential dependence on dimension. Furthermore, because there are fewer restrictions upon the perturbation directions in the lower bound for the offline setting, we construct a simpler class of a systems which exhibits this behavior. In particular, consider the system
\ifnum\value{cdc}>0{
\begin{equation}
\begin{aligned}
    \label{eq: integrator}
    A &= \bmat{ \rho & 2 & 0 & & 0 & 0 \\ %0 & \rho & 2 & & 0 & 0 \\ 
    & & & \ddots  \\ 0 & 0 & 0 & & \rho & 2 \\ 0 & 0 & 0 & & 0 & \rho}, \quad B = \bmat{0 \\ \vdots \\ 0 \\ 1}, %\\ 
    %F&=0, Q = I, R = 1, \Sigma_W = I,
\end{aligned}
\end{equation}
}\else{
\begin{align}
    \label{eq: integrator}
    A = \bmat{ \rho & 2 & 0 & & 0 & 0 \\ 0 & \rho & 2 & & 0 & 0 \\ & & & \ddots  \\ 0 & 0 & 0 & & \rho & 2 \\ 0 & 0 & 0 & & 0 & \rho}, \quad B = \bmat{0 \\ 0\\ \vdots \\ 0 \\ 1}, %\quad F=0, Q = I, R = 1, \Sigma_W = I,
\end{align}}\fi
with $0 < \rho < 1$, $F=0$, $Q = I$, $R = 1$, and $\Sigma_W = I$.
\ifnum\value{cdc}>0{
Using the perturbation direction $V =  \VEC \bmat{0 & B/\norm{B}_F}$, \Cref{cor: asymptotic lower bound} may be used to reach the following conclusion.
}
\else{
Let $V = \VEC \bmat{0 & B/\norm{B}_F}$. Then the quantity $L(\theta)$ in \Cref{cor: asymptotic lower bound} becomes $8  \sigma_{\tilde u}^2$, as $\nu_1(V) = 0$. Meanwhile, (using the option $\Gamma= \Sigma_W = I$), the quantity $G$ becomes
% \ifnum\value{cdc}>0{
% \begin{equation}
% \begin{aligned}
%     \label{eq: F LB exp}
%     %&\tr\left(   (I \otimes \Psi)  \dop_\theta \VEC  K(\theta) VV^\top \dop_\theta  \VEC    K(\theta)^\T \right) \\
%     %& \qquad 
%     G = \tr(\Psi d_V K(\theta) d_V K(\theta)^\top).
% \end{aligned}
% \end{equation}
% }\else{
\begin{equation}
\begin{aligned}
    \label{eq: F LB exp}
    G = \tr\left(   (I \otimes \Psi)  \dop_\theta \VEC  K(\theta) VV^\top \dop_\theta  \VEC    K(\theta)^\T \right) = \tr(\Psi d_V K(\theta) d_V K(\theta)^\top).
\end{aligned}
\end{equation}
% }\fi
Using this insight, we may show that the lower bound grows exponentially with the system dimension. 
}\fi
\begin{proposition}
    \label{prop: exponential}
    For the system in \eqref{eq: integrator} suppose $\dx \geq 3$. Then for $\alpha \in (0,1/2)$,
    \begin{align*}
        \liminf_{N \to \infty} \sup_{\theta' \in \mathcal{B}(\theta, N^{-\alpha}) } N \mathsf{EC}_T^\pi(\theta')   \geq \frac{\rho^2}{256 T  \sigma_{\tilde u}^2} 4^{\dx-2}.
    \end{align*}
\end{proposition}

We have therefore demonstrated that accurately learning the LQR controller from offline data may require an amount of data that is exponential in the state dimension. The reason that this system is particularly challenging to learn to control is that a small misidentification of $B$ causes the learner to apply slightly suptoptimal control inputs, which are then amplified by the off-diagonal terms of $A$.  The construction used, \eqref{eq: integrator}, avoids the two subsystem example that was used to derive exponential lower bounds for online LQR in \cite{tsiamis2022learning}. A crucial reason that we are able to bypass such a construction in the offline setting is that the dominant statistical rate of $\frac{1}{NT}$ for offline LQR is present for any perturbation direction of the underlying parameters. In contrast, the regret in the online setting only has the dominant statistical rate in the directions defined by the perturbation set in \eqref{eq: polderman perturbation}.




% \begin{remark}
%     {\color{red} It appears as though it should also be possible to get exponential lower bounds from this system in the online setting. Currently I have reduced the lower bound to $\tr(K\Gamma_0 K^\top)/KK^\top$. Leave working out this remark for the journal submission.} 
% \end{remark}


 \subsection{Interesting System-Theoretic Quantities}
\label{s: system-theoretic}

% \Bruce{I like some parts of the following discussion, but I'm not sure it's all necessary/the best location for it.}
% \Cref{s: system-theoretic} focuses on on a perturbation direction for which the lower bound aligns with intuition about when it should be difficult to learn a controller. 
%\Cref{s: dimensional dependence} demonstrates a set of perturbation directions for which the dependence on the dimension is optimal. \Cref{s: exp} illustrates that for reasonable systems, the system theoretic quantities appearing in the lower bound may grow exponentially with the system dimension. 
A consequence of the result in \Cref{s: exp} is that treating system-theoretic quantities as constant with respect to dimension, as is done in \Cref{s: dimensional dependence}, may fail to capture the difficulty of the problem. This leads to unfavorable aspects of the lower bound in \Cref{s: dimensional dependence}, such as the dependence of the denominator on $\norm{K}$. Such an appearance indicates that for systems where the optimal LQR has a large gain, the lower bound becomes small. This is in contrast to our expectations, as a large optimal gain is often indicative of poor controllability (consider a scalar system, with $B\to 0$). %As the control problem becomes more difficult in such a setting, intuition tells us that the suboptimality of a learned controller  should become large.  
% By focusing on system-theoretic quantities, the result in \Cref{s: system-theoretic} avoids several of the pitfalls of that in \Cref{s: dimensional dependence}. 

Motivated by the above discussion, we focus our attention on deriving bounds which have favorable dependence upon system-theoretic quantities. To do so, we examine a perturbation direction for which the lower bound from \Cref{cor: asymptotic lower bound} reduces to easily interpretable quantities which align with our intuition. By taking $V=  \VEC \frac{\bmat{A & B}}{\norm{\bmat{A & B}}_F}$, the directional derivative expression from \eqref{eq: directional derivative of lqr} reduces to 
\begin{align}
    \label{eq: system properties directional derivative}
    d_V  K(\theta) = \frac{2\Psi^{-1} (B^\top \texttt{dlyap}(A_{cl}, P) A_{cl})}{\norm{\bmat{A & B}}_F} .
\end{align}
\ifnum\value{cdc}>0{}\else{
Then the quantity $G$ in \Cref{cor: asymptotic lower bound} (using $\Gamma = \Sigma_X$), 
is
\begin{equation}
\label{eq: G system theoretic}
\begin{aligned}
    &\tr\paren{(\Sigma_X \otimes (B^\top P B + R))\dop_\theta \VEC  K(\theta )V \paren{\dop_\theta  \VEC K(\theta) V }^\T } \\
    &=\tr((B^\top P B+R) d_V K(\theta) \Sigma_X d_V K(\theta)^\top) \\
    &=\frac{4}{\norm{\bmat{A & B}}_F^2} \tr((B^\top P B+R)^{-1} B^\top \dlyap\paren{A_{cl}, P} A_{cl} \Sigma_X A_{cl}^\top \dlyap\paren{A_{cl}, P} B).
    %&\geq \frac{4 \lambda_{\min}(\Gamma_0 - \Sigma_W)}{\norm{\bmat{A & B}}_F^2 } \frac{\tr\paren{B^\top P B}}{\norm{B^\top P B+ R}} \lambda_{\min}(\dlyap(A_{cl}, P))
\end{aligned}
\end{equation}}\fi
This leads to the following proposition.
\begin{proposition}
    \label{prop: system theoretic}
    Suppose that $R$ and $B^\top P B$ are simultaneously diagonalizable by $U$: $B^\top P B = U \Lambda_{B^\top P B} U^\top$ and $R = U \Lambda_R U^\top$, where $\Lambda_{B^\top P B}$ and $\Lambda_R$ are diagonal. Also suppose that the diagonal entries of $\Lambda_{B^\top P B}$ are sorted in non-ascending order.  Assume $T \geq \frac{16 \norm{\Sigma_X}^2}{\lambda_{\min}(\Sigma_X)}$. Let $\tilde L$ be as in \Cref{prop: dimensional dependence}. Then for $\alpha \in (0,1/2)$
    \ifnum\value{cdc}>0{
    \begin{align*}
        &\liminf_{N \to \infty} \sup_{\theta' \in \mathcal{B}(\theta, N^{-\alpha}) } N \mathsf{EC}_T^\pi(\theta')  \geq  \frac{ \lambda_{\min}(\Sigma_X - \Sigma_W)}{2T \norm{\bmat{A & B}}_F^2 \bar L} 
        \\ &\qquad 
        \cdot\inf_{i \in [\du]} \frac{\lambda_{i}(B^\top P B)}{\lambda_i(B^\top P B) + \Lambda_{R, ii}} \sum_{j=1}^{\du} \lambda_{n-j} (\dlyap(A_{cl}, P)).
    \end{align*}
    }\else{
    \begin{align*}
        &\liminf_{N \to \infty} \sup_{\theta' \in \mathcal{B}(\theta, N^{-\alpha}) } N \mathsf{EC}_T^\pi(\theta')  \geq  \frac{ \lambda_{\min}(\Sigma_X - \Sigma_W)}{2T \norm{\bmat{A & B}}_F^2 \tilde L} 
        % \\ &\quqad \cdot
        \inf_{i \in [\du]} \frac{\lambda_{i}(B^\top P B)}{\lambda_i(B^\top P B) + \Lambda_{R, ii}} \sum_{j=1}^{\du} \lambda_{n-j} (\dlyap(A_{cl}, P)).
    \end{align*}}\fi
    %where $\tilde L$ is as in \Cref{prop: dimensional dependence}.  
    % \begin{align*}
    %      \bar L &= \frac{8 }{\lambda_{\min}(\Sigma_W)}
    %      \bigg(\paren{1 +  2 \norm{F}^2} \bigg(\norm{\dlyap\paren{(A(\theta)+B(\theta)F)^\top, \Sigma_W}} \\
    %      &\qquad
    %      + \beta \sum_{t=0}^{\infty} \norm{\paren{(A(\theta) +  B(\theta)F)^t B}}^2 \bigg) + 2\beta \bigg). 
    % \end{align*}
\end{proposition}

\ifnum\value{cdc}>0{The assumption that $R$ and $B^\top P B$ are simultaneously diagonalizable is satisfied if $R$ is chosen as a scalar multiple of the identity. }\else{
As $R$ is often chosen to be a scalar multiple of the identity for LQR problems, the assumption that $R$ and $B^\top P B$ are simultaneously diagonalizable is often satisfied. If we additionally have $R \preceq B^\top P B$, then $\inf_{i \in [\du]} \frac{\lambda_i(B^\top P B)}{\lambda_i(B^\top P B) + \Lambda_{R, ii}} \geq \frac{1}{2}$. }\fi
As in \Cref{prop: dimensional dependence}, $\lambda_{\min}(\Sigma_X - \Sigma_W)$ highlights the dependence on the closed-loop state covariance, 
\ifnum\value{cdc}>0{ and $\tilde L$ describes the how easily system is excited offline. }\else{
and $\tilde L$ describes the impact of the controllability of the closed-loop system under the pre-stabilizing controller, as well as the input budget.}\fi \ifnum\value{cdc}>0{}\else{ Note that $\tilde L$ provides an upper bound on the information in the face of an optimal offline exploration policy. Studying it may therefore assist with experiment design, as in \cite{wagenmaker2021task}.}\fi\  Rather than the appearance of $\norm{\bmat{-K & I}}$ on the denominator, as we saw in \Cref{prop: dimensional dependence},  we have $\norm{\bmat{A & B}}_F$. Therefore, the bound does not diminish as a result of a large optimal controller gain. 
Lastly, observe that $ \sum_{j=1}^{du} \lambda_{n-j} (\dlyap(A_{cl}, P))$ replaces $\lambda_{\min}(P)$ from \Cref{prop: dimensional dependence}. %The new quantity is strictly larger. 
This quantity captures the $\du$ smallest eigenvalues rather than just the smallest. %, as appeared in \Cref{prop: dimensional dependence}. 
If $\du = \dx$, we get all eigenvalues of $\dlyap(A_{cl}, P)$. Further note that the eigenvalues of $\dlyap(A_{cl}, P)$ diverge as $A_{cl}$ approaches marginal stability, leading to an infinite excess cost. 


% As $R$ is often chosen to be a scalar multiple of the identity for LQR problems, the assumption that $R$ and $B^\top P B$ are simultaneously diagonalizable is often satisfied. If we additionally have $R \preceq B^\top P B$, then $\inf_{i \in [\du]} \frac{\lambda_i(B^\top P B)}{\lambda_i(B^\top P B) + \Lambda_{R, ii}} \geq \frac{1}{2}$. 
% As in \Cref{prop: dimensional dependence}, $\lambda_{\min}(\Sigma_X - \Sigma_W)$ highlights the dependence on the closed-loop state covariance, and $\tilde L$ describes the impact of the controllability of the closed-loop system under the pre-stabilizing controller, as well as the input budget. Note that $\tilde L$ provides an upper bound on the information in the face of an optimal offline exploration policy. Studying it may therefore assist with experiment design, as in \cite{wagenmaker2021task}.
% % Note that $\bar L$ consists of norms of quantities that resemble the Gramian of the closed-loop system under the exploration policy from the noise, and from the exploratory input. The energy of the exploratory input signal also makes an appearance. As the exploratory budget becomes small, $\beta \to 0$, the $\bar L$ approaches the norm of the controllabiltiy gramian from noise of the closed-loop system, scaled by the process noise level and the norm of the pre-stabilizing controller. 
% Rather than the appearance of $\norm{\bmat{-K & I}}$ on the denominator, as we saw in \Cref{prop: dimensional dependence},  we have $\norm{\bmat{A & B}}_F$ on the denominator. Therefore, the bound does not diminish as a result of a large optimal controller gain. 
% Lastly, observe that $ \sum_{j=1}^{du} \lambda_{n-j} (\dlyap(A_{cl}, P))$ replaces $\lambda_{\min}(P)$ from \Cref{prop: dimensional dependence}. The new quantity is strictly larger. In particular, it captures the $\du$ smallest eigenvalues rather than just the smallest, as appeared in \Cref{prop: dimensional dependence}. If $\du = \dx$, we get all eigenvalues of the matrix $\dlyap(A_{cl}, P)$. Further note that the eigenvalues of $\dlyap(A_{cl}, P)$ are at least the eigenvalues of $P$, and may be much larger when $A_{cl}$ approaches marginal stability. As the closed-loop system approaches marginally stability, $\rho(A_{cl})\to 1$ and $\dlyap(A_{cl}, P)$ diverges, leading to an infinite suboptimality gap. 