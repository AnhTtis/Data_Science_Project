% TODO: Relevant details from ICSE'22 deadline
%  Page limit (text + figures + references + appendices)
%  Date(s)
%  Do we need to pre-register? If so, set a calendar reminder.

% \documentclass[sigconf,review,anonymous]{acmart}
% \documentclass[sigconf,review]{acmart}
\documentclass[10pt,conference]{IEEEtran}


%\acmConference[ICSE 2023]{The 45th International Conference on Software Engineering}{TODO}{TODO}
%\documentclass[conference]{IEEEtran}

% Flags to control document properties
%%%

\newif\ifSPACEHACK
\SPACEHACKtrue 
% \SPACEHACKfalse

\newif\ifDEBUG
\DEBUGtrue
% \DEBUGfalse

\newif\ifANONYMOUS
%\ANONYMOUStrue
\ANONYMOUSfalse

%%%
% Typesetting configuration
%%%

\input{misc/typesetting}
\usepackage{scalerel}
\usepackage{tikz}
\usetikzlibrary{svg.path}

\definecolor{orcidlogocol}{HTML}{A6CE39}
\tikzset{
    orcidlogo/.pic={
        \fill[orcidlogocol] svg{M256,128c0,70.7-57.3,128-128,128C57.3,256,0,198.7,0,128C0,57.3,57.3,0,128,0C198.7,0,256,57.3,256,128z};
        \fill[white] svg{M86.3,186.2H70.9V79.1h15.4v48.4V186.2z}
        svg{M108.9,79.1h41.6c39.6,0,57,28.3,57,53.6c0,27.5-21.5,53.6-56.8,53.6h-41.8V79.1z M124.3,172.4h24.5c34.9,0,42.9-26.5,42.9-39.7c0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z}
        svg{M88.7,56.8c0,5.5-4.5,10.1-10.1,10.1c-5.6,0-10.1-4.6-10.1-10.1c0-5.6,4.5-10.1,10.1-10.1C84.2,46.7,88.7,51.3,88.7,56.8z};
    }
}

\newcommand\orcidicon[1]{\href{https://orcid.org/#1}{\mbox{\scalerel*{
                \begin{tikzpicture}[yscale=-1,transform shape]
                \pic{orcidlogo};
                \end{tikzpicture}
            }{|}}}}

\usepackage{hyperref}
%%%
% Data from research & experiments
%%%

% \input{data/data}

%%%%%%%%%%%%%%%%%%

\begin{document}

\input{data/data}

%%%
% Body
%%%

\newcommand{\MyTitle}[1]{}

\renewcommand{\MyTitle}{PTMTorrent: A Dataset of Package Snapshots in PTM Registries }
\renewcommand{\MyTitle}{PTMTorrent: An Open-source Dataset for Mining Pre-trained Model Packages}
\renewcommand{\MyTitle}{PTMTorrent: A Dataset of Pre-trained Machine Learning Models From Five Registries}
\renewcommand{\MyTitle}{PTMTorrent: 124,000 Pre-trained Machine Learning Models From Five Registries}
\renewcommand{\MyTitle}{PTMTorrent: A Dataset for Mining Open-source Pre-trained Model Packages}

\newcommand{\orcid}[1]{\href{https://orcid.org/#1}{\textcolor[HTML]{A6CE39}{\aiOrcid}}}


\title{\MyTitle}

    % \author{Anonymous author(s)}
        \author{
    \IEEEauthorblockN{Wenxin Jiang \IEEEauthorrefmark{1}\textsuperscript{\textsection}$^{\textsuperscript{\orcidicon{0000-0003-2608-8576}}}$\, 
    Nicholas Synovic\IEEEauthorrefmark{2}\textsuperscript{\textsection}$^{\textsuperscript{\orcidicon{0000-0003-0413-4594}}}$\, 
    Purvish Jajal\IEEEauthorrefmark{1}$^{\textsuperscript{\orcidicon{0000-0002-1199-6363}}}$\, 
    Taylor R. Schorlemmer\IEEEauthorrefmark{1}$^{\textsuperscript{\orcidicon{0000-0003-2181-5527}}}$\, 
    Arav Tewari\IEEEauthorrefmark{1}$^{\textsuperscript{\orcidicon{0000-0002-1512-858X}}}$\,\\ 
    Bhavesh Pareek\IEEEauthorrefmark{1}$^{\textsuperscript{\orcidicon{0000-0002-6885-9810}}}$\, 
    George K. Thiruvathukal\IEEEauthorrefmark{2}$^{\textsuperscript{\orcidicon{0000-0002-0452-5571}}}$\, 
    James C. Davis\IEEEauthorrefmark{1}$^{\textsuperscript{\orcidicon{0000-0003-2495-686X}}}$\
    }
    \IEEEauthorblockA{\IEEEauthorrefmark{1}Purdue University and \IEEEauthorrefmark{2}Loyola University Chicago}
}
    
\maketitle
\begingroup\renewcommand\thefootnote{\textsection}
\footnotetext{Authors contributed equally.}
\endgroup

\begin{abstract} \label{sec: abstract}
% \WJ{The current draft is based on HFTorrent.}
% \JD{@WJ I updated the abstract, please review}
% GKT cleaning up a few things here (e.g. some tense agreement, etc.)
% \TODO{Co-first author mark!}
% \TODO{Reviewer3: With all large datasets for the scientific community, maintainability is key to sustained success. What is the planned periodicity for the PTMTorrent updates? This should be clarified.
Due to the cost of developing and training deep learning models from scratch, machine learning engineers have begun to reuse pre-trained models (PTMs) and fine-tune them for downstream tasks.
% Recently, PTM registries has emerged as a way for engineers to distribute deep learning (DL) models and provided a convenient way for PTM reuse. 
PTM registries known as ``model hubs'' support engineers in distributing and reusing deep learning models.
PTM packages include pre-trained weights, documentation, model architectures, datasets, and metadata.
% There exist datasets that aim to mirror open-source project metadata like GHTorrent.
%Currently, datasets like GHTorrent mirror open-source project repositories --- enabling research of open-source software.
% Following the path of prior work, we present PTM Torrent, which is a snapshot of
% \CS{Is the previously mentioned information what you're mining? IF so, then it might be nice to make it clear in the abstract you're mining}
Mining the information in PTM packages will enable the discovery of engineering phenomena and tools to support software engineers.
However, accessing this information is difficult --- there are many PTM registries, and both the registries and the individual packages may have rate limiting for accessing the data.

We present an open-source dataset, PTMTorrent, to facilitate the evaluation and understanding of PTM packages.
This paper describes the creation, structure, usage, and limitations of the dataset.
The dataset includes a snapshot of \numberOfModelHub model hubs and a total of \TotalNumberOfPackages PTM packages.
These packages are represented in a uniform data schema for cross-hub mining.
We describe prior uses of this data and suggest research opportunities for mining using our dataset.

The \textit{PTMTorrent} dataset (v1) is available at: \url{https://app.globus.org/file-manager?origin_id=55e17a6e-9d8f-11ed-a2a2-8383522b48d9&origin_path=\%2F\%7E\%2F}.

Our dataset generation tools are available on GitHub: %\url{https://github.com/SoftwareSystemsLaboratory/PTM-Torrent}. 
\url{https://doi.org/10.5281/zenodo.7570357}
%\JD{Zenodo please} \GKT{We'll work on this. Stay tuned.}
% In this paper, we highlight the limitation and potential improvement of our dataset, and inform further measurements on understanding the characteristic of PTM package supply chain, including dataset enhancement, PTM supply chain analysis, and mining tool development.

% \TODO{How we get the model and what are the future works.}

% This paper presents \TODO{PTMTorrent} -- 


% Deep Neural Networks (DNNs) are increasingly being adopted in software systems. %,
% %  including autonomous vehicles (computer vision) and virtual assistants (natural language processing).
% Creating and specializing DNNs from scratch has grown increasingly difficult as state-of-the-art architectures grow more complex.
% %The size and training cost of DNNs continue to grow year over year. 
% %Training these neural networks also incurs a huge carbon footprint.
% Similar to traditional software reuse, machine learning engineers have begun to reuse large-scale pre-trained models (PTMs) and fine-tune them for downstream tasks.
% To better evaluate and understand PTM packages, we present an open-source datset, PTMTorrent, which include a snapshot of \numberOfModelHub model hubs and the corresponding PTM packages. We hope this dataset can inform further measurements and understanding of machine learning software.



\end{abstract}



\begin{IEEEkeywords}
Open-Source Software, 
Data Mining,
Machine learning,
Empirical software engineering
\end{IEEEkeywords}

%%%%%

%Package reuse has transformed software engineering~\cite{raymond1999cathedral} in programming languages such as Python and JavaScript~\cite{abdalkareem2017developers}.
%The reuse paradigm is also being adopted in deep learning model engineering~\cite{Jiang2022PTMReuse}.

\section{Introduction} \label{sec:Intro}
% Introduction / Background / Related Works (what's so important about this data? why do we need it? why would it be useful?)
% Package reuse has transformed software engineering in programming languages such as JavaScript and Python~\cite{raymond1999cathedral, abdalkareem2017developers}, and is also transforming the engineering of deep learning models~\cite{Gopalakrishna2022IoTPractices}.
% Pruning Citations: ~\cite{raymond1999cathedral,abdalkareem2017developers}
% Just as package reuse transformed software engineering in programming languages such as JavaScript and Python~\cite{raymond1999cathedral,abdalkareem2017developers}, package reuse is transforming deep learning model engineering.
% Deep Neural Networks (DNNs) are widely used and have been a significant part of modern software systems~\cite{} \AT{Should there be more examples?}.
Modern software systems reuse Deep Neural Networks (DNNs) to build intelligent and adaptive systems~\cite{Amershi2019SE4MLCaseStudy, Shafiq2021LitReviewofMLinSWDevLifeCycle}.
% \TRS{Broken citation here.}
Engineering a DNN from scratch is challenging for many reasons,
  including the variation in deep learning libraries~\cite{Pham2020AnalysisofVarianceinDLSWSystems,banna2021experience}
  and
  the high expense of training models~\cite{patterson2021carbon}.
% One way to address these challenges is to reuse \emph{pre-trained DNN models} (PTMs). 
Organizations and developers can address some of these challenges and reduce the cost and effort associated with DNN development by reusing \emph{pre-trained DNN models} (PTMs)~\cite{Tan2018DeepTransferLearningSurvey, Pan2010TransferLearning}. 
% By leveraging PTMs, organizations and developers can reduce the cost and effort associated with training and fine-tuning DNNs for specific tasks~\cite{Pan2022DecomposingCNN}.
% Some of these problems can be addressed by reusing \emph{pre-trained DNN models} (PTMs) to amortize DNN development costs across multiple projects and organizations~\cite{Pan2022DecomposingCNN}.
% \JD{@WJ: Add 2 survey papers to the citations in the previous sentence.}
PTMs are shared via \emph{deep learning model registries}, which are modeled on traditional software package registries such as NPM~\cite{npm}. These PTM packages include reusable components, such as model architectures, weights, licenses, and other metadata.
% DL model registries enable reuse-driven DNN engineering~\cite{TensorFlowHubIntroduction,HuggingFacePaper2020}
% PTM reuse is approaching the scale of reuse in traditional software~\cite{2022JiangEmpirical}. 
Deep learning model registries enable engineers to develop their models with re-usability in mind~\cite{TensorFlowHubIntroduction,HuggingFacePaper2020}.
Although PTM reuse is still in its early stages, the most popular PTMs are downloaded millions of times each month~\cite{2022JiangEmpirical, Jiang2022PTMReuse}.

As PTM reuse becomes more widespread, the engineering community will benefit from research into PTM reuse practices, challenges, and tools~\cite{Jiang2022PTMReuse, 2022JiangEmpirical}.
By analogy to traditional software, mining PTM software repositories can help us understand development trends~\cite{Ray2014StudyofProgrammingLanguagesandCodeQualityinGitHub, Zampetti2017HowOSProjectsUseStaticCodeAnalysisinCIPipelines, Gousios2014PullBasedSWDevelopment} and usage patterns~\cite{anbalagan2009predicting, Malinen2015UserParticipationinOnlineCommunities}. 
However, mining the software repositories associated with PTM packages is difficult for three reasons related to \emph{data availability}.
First, researchers must look in many places --- PTM packages are distributed across many competing PTM registries~\cite{2022JiangEmpirical}.
Second, researchers must access the packages --- PTMs include complex DNN models and weights with sizes over 1 TB, and access to these packages may be hindered by throttling or rate limiting~\cite{HFDoc}.
Third, for scientific replicability, this large-scale data needs to be hosted long-term.

\iffalse
Prior mining software repository studies were conducted to help the community better understand open-source software by presenting a dataset by mirroring a specific set of open-source software~\cite{Gousios2012GHTorrent, Mattis2020RTPTorrent, Beller2017TravisTorrent}. These studies can inform further studies on understanding the characteristics of open-source software, including development trends~\cite{Ray2014StudyofProgrammingLanguagesandCodeQualityinGitHub, Zampetti2017HowOSProjectsUseStaticCodeAnalysisinCIPipelines, Gousios2014PullBasedSWDevelopment} and usage patterns~\cite{anbalagan2009predicting, Malinen2015UserParticipationinOnlineCommunities}. 
% A better understanding can therefore envision further studies on ~\cite{Beller2017ExplorativeStudyofTravisCI, Zampetti2017HowOSProjectsUseStaticCodeAnalysisinCIPipelines, Gousios2014PullBasedSWDevelopment, Elsner2021RegressionTestOptimizationinCI}.
\fi

\iffalse
Until now, researchers do not have easy access to handle the information of all PTMs from different model registries. There are multiple reasons, including the limited rate of model downloading~\cite{HFDoc} and non-standardized documentation~\cite{Jiang2022PTMReuse}.
\fi

%%%
% Methods
%%%

To enable mining of PTM packages, we share \emph{PTMTorrent}, the first many-hub dataset of PTM packages.
PTMTorrent contains \TotalNumberOfPackages PTMs from \numberOfModelHub different PTM registries identified in our prior work~\cite{2022JiangEmpirical}: \HF~\cite{HuggingFaceWeb1}, Model Zoo~\cite{ModelZooWeb},
% TensorFlow Hub~\cite{TFHub}, 
PyTorch Hub~\cite{PytorchHub}, ONNX Model Zoo~\cite{ONNXModelZoo}, and Modelhub~\cite{ModelhubWeb}.
Our dataset is hosted on a high-performance storage system (HPSS) maintained by Purdue University's Research Computing center.
The dataset includes the metadata of each PTM and the package histories for each GitHub repository.
These packages are represented in a uniform data schema for cross-hub mining.
Out dataset supports many directions for further research, including studies of the PTM supply chain, PTM package evolution, PTM mining tools, and DNN architectural trends.
%We also encourage community support to help extend the PTMTorrent dataset.

% \AT{Introduction is lacking. Are we not allowed to re-use parts of the abstract in the introduction? I think it would be ideal if we defined PTMs like they were defined in the abstract. In addition, we still haven't fully explained the reason behind PTMTorrent. We say that PTMs are becoming a big thing and people are using them more, then we jump straight into PTMTorrent. Why do we believe this data would be useful? Why did we go out of our way to make this data available?} 

% https://drive.google.com/file/d/1Ck-Kov6gMIo6snz_kC9ODVDn9_PDj4F0/view?usp=sharing
{
\small
\renewcommand{\arraystretch}{0.9}
\begin{figure*}[t]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/MSR/MSR-Datacollection-4.drawio.pdf}
    \caption{
    \small
    Data collection and preprocessing workflow for PTMTorrent. We standardize the PTM metadata by using a data schema, collecting it from PTM packages and the corresponding GitHub repository.
    % \CS{I feel like the caption here is lacking. It would be helpful to explain box with what info you're collecting.}
    % \WJ{Are there any details missing in this figure?}
    % \JD{Put hub names underneath hub logos. Not all of these logos are familiar to the reader.}
    % \JD{If what we actually did was clone the underlying repo, that is not clear from this diagram. Are we guarnateeing to have all of the elements listed here from the ``PTM packages'' block?}
    }
    \label{fig:DataCollection}
    % \vspace{-5mm}
\end{figure*}
}


\section{The PTMTorrent Dataset} \label{sec:Dataset}
% Data Model (what does our data look like? how is structured? statistics?)

\subsection{Data Source} \label{sec:PTMTorrent-DataSource}
% \TODO{A description of the data source. @Nick, let's add more details here.}
% \JD{Please describe each hub listed in Table 1 -- what kind of models does it contain? Who contributes packages --- hobbyists? commercial? a mix?}
% \JD{Explain where we got the list of hubs! It's single-blind submission so it's OK to say ``in prior work we mapped the major model hubs. As described in Jiang \etal, there are open and commercial hubs. We provide a snapshot of the open hubs.''}

% What are in the dataset
% \myparagraph{\textbf{Dataset contents}}
In prior work we mapped the major model hubs and indicated that there exist open, gated, and commercial hubs~\cite{2022JiangEmpirical}.
Open and gated hubs tend to be larger and more widely used because they accept contributions from anyone, and can be accessed by anyone.
Commercial hubs are offered by individual companies to share vetted models with their clients.
Due to the limited access to commercial model hubs, we only provide a snapshot of the open hubs (\HF) and some of the gated hubs (Model Zoo, PyTorch Hub, Modelhub, and ONNX Model Zoo).

The PTMTorrent dataset contains the repository histories of \TotalNumberOfPackages PTM packages available as of January 2023.
They are provided as complete git clones, resulting in a compressed footprint of \TotalDataSize. 
Each PTM package was cloned at its most recent version, including the model card, architecture, weights, and other information provided by the maintainers (\eg training configuration, hyper-parameters).
% \AT{Provenance may be the wrong word here (it means the place of origin). It makes sense for the first part which is not complete yet, the description of the data source. The information following the TODO item and Wenxin's note is not the provenance of our data, rather the end product of PTMTorrent. It might make more sense to put this under Data Storage and rename the subsection to something more encompassing.}\WJ{I changed the heading to ``Data Source''. Yes I agree that the prose is more like product instead of provenance. I think it could be better if we describe the source based on the UML diagram.}



% \subsection{Data Collection and Preprocessing}
% \WJ{a description of the methodology used to gather the data (including provenance and the tool used to create/generate/gather the data, if any)}
\cref{fig:DataCollection} indicates the collection and preprocessing approaches of our dataset.
%Jiang \etal indicated 6 popular model hubs~\cite{2022JiangEmpirical}.

We collected PTM packages from all open and gated model hubs per Jiang \etal~\cite{2022JiangEmpirical}, excluding \TFH because it does not support version control features.
We downloaded all PTM packages from Model Zoo, PyTorch Hub, ONNX Model Zoo, and Modelhub.
Due to the size of Hugging Face, we downloaded only the top 10\% most-downloaded PTMs.\footnote{Although we collected a small amount of the full Hugging Face registry, this ``top 10\%'' snapshot includes all Hugging Face PTMs with over 30 downloads.}
Overall, our dataset contains \TotalNumberOfPackages packages from \numberOfModelHub PTM registries, distributed as described in~\cref{tab:DatasetContents}.
%including \HF (\HFNumberOfPackages), \MZ (\MZNumberOfPackages),
% \TFH (\THNumberOfPackages), 
%\PH (\PHNumberOfPackages), \MH (\MHNumberOfPackages).

{
\small
\renewcommand{\arraystretch}{0.5}
\begin{table}[h]
\centering
\caption{
    Details about the PTMTorrent content for each of the \numberOfModelHub model registries we collected.
    }
\begin{tabular}{lcccc}
\toprule
          \textbf{Name} & \textbf{\# Models} & \textbf{Data Size} \\
\midrule
  Hugging Face~\cite{HuggingFaceWeb} &    \HFNumberOfPackages  &  \HFDataSize\\
\\
% \midrule
% TensorFlow Hub~\cite{TFHub}  &         \THNumberOfPackages & \THNumberOfDatasets & xx\\
% \\
Model Zoo~\cite{ModelZooWeb}  &         \MZNumberOfPackages & \MZDataSize\\
\\
PyTorch Hub~\cite{PytorchHub} &         \PHNumberOfPackages &  \PHDataSize\\
\\
ONNX Model Zoo~\cite{ONNXModelZoo}  &         \ONNXNumberOfPackages &   \ONNXDataSize\\
\\
Modelhub~\cite{ModelhubWeb}  &        \MHNumberOfPackages &   \MHDataSize\\
\midrule
\textbf{PTMTorrent}  &       \textbf{\TotalNumberOfPackages} & 
% \textbf{\TotalNumberOfDatasets} &   
\textbf{\TotalDataSize}\\
     
\bottomrule
\end{tabular}
\label{tab:DatasetContents}
%\vspace{-4mm}
\end{table}
}

\iffalse
\JD{I don't think we actually do much rate limiting, and anyway it's not crucial here. Cut for space.}
To reduce the impact on the \HF service and vice versa \CS{What's the 'vice versa' in reference to?} \JD{I can't tell, seems like we should delete it. Also, presumably we're trying to reduce impact on all the services and not just HF?}, we took a snapshot of each PTM and the corresponding GitHub repository.
We initiated a copy of all PTM packages from the \numberOfModelHub registries.
Copies were taken on January 2023, with rate limiting to avoid abuse of each registry.
\JD{Sanity check: is this rate limiting evident in our cloners? I don't remember seeing it when I looked at them yesterday.}
\WJ{@Nick Do we have any copies failed in PTMTorrent?}
\TotalNumberOfFailedPackages (\TotalNumberOfFailedPercentage) of the copies failed. We believe the failures were caused by concurrent changes in package names.
\fi

\subsection{Data Schema}
% \JD{It is a schema. We represent it in JSON. Let's not call it a ``JSON schema'', that sounds like JSON is the focus (it is not).}
\cref{fig:DataSchema} shows the overview of the data schema we used to standardize the dataset. 
% Listing \ref{lst:DataSchema}. 
We extracted common entities into a general PTM schema.
Each PTM registry has some custom features, so we customized the schema slightly for each model registry.
The full data schema is encoded following the JSON Schema format,\footnote{See \url{https://json-schema.org/draft/2020-12/json-schema-core.html}} and is available in the GitHub repository associated with this project.

% \WJ{I asked @Nick to make a UML diagram and then we can remove the json version.}

% \begin{lstlisting}[language=json, firstnumber=1, caption={General data schema used for PTMTorrent.},captionpos=t, label=lst:DataSchema]

% {
%     "type": "object",
%     "properties": {
%         "id": {"type": "number"},
%         "ModelHub": {
%             "type": "object",
%             "properties": {
%                 "ModelHubName": {"type": "string"},
%                 "MetadataFilePath": {"type": "string"},
%                 "MetadataObjectID": {"type": "number"}
%             }
%         },
%         "ModelName": {"type": "string"},
%         "ModelOwner": {"type": "string"},
%         "ModelURL": {"type": "string"},
%         "ModelOwnerURL": {"type": "string"},
%         "Datasets": {"type": "array"}
%         "ModelPaperDOI": {"type": "string"},
%         "LatestGitCommitSHA": {"type": "string"},
%         "ModelTask": {"type": "string"},
%         "ModelArchitecture": {"type": "string"}
%     }
% }

% \end{lstlisting}



\subsection{Data Storage}
% \TODO{Need to double check this section.}
% \TRS{I've made changes to this subsection}
As shown in \cref{tab:DatasetContents}, the entire PTMTorrent dataset (v1) needs \TotalDataSize of storage space. 
A cost-effective storage system is required to serve this dataset.
Commercial services are cost-prohibitive at this scale, \eg we estimated a monthly cost of over \$1000 to store and serve this dataset from Amazon Web Services.
We opted instead for an internal resource available at Purdue University: the Purdue Fortress tape-based hierarchical storage system.\footnote{For more information about Fortress, see \url{https://www.rcac.purdue.edu/knowledge/fortress/overview}. Our GitHub repository includes a guide on how to access data stored in Globus.} 
To facilitate external distribution of our dataset, we offer a Globus share~\cite{chard2015globus} named \textit{PTMTorrent}.
%The Globus interface simplifies moving data to other highperformance computing clusters used to generate data and the storage system.
%This greatly simplifies our PTMTorrent maintenance processes.
\iffalse
Our \textit{PTMTorrent} Globus collection is available at: \url{https://app.globus.org/file-manager?origin_id=55e17a6e-9d8f-11ed-a2a2-8383522b48d9&origin_path=\%2F\%7E\%2F}.
\fi

\subsection{Maintainability and Extensibility}

The sizes of PTM registries are increasing rapidly. For example, \HF provided \PTMDatasetNPackages public PTM packages on August 2022, and now it provides \HFNumberOfPackagesMetadata packages.
We believe the number of open-source PTM packages will increase in the foreseeable future. 
Therefore, maintainability and extensibility are two important properties of PTMTorrent.

% \JD{Re-running the scripts is ``maintainable'' -- you can update the dataset. But ``extensible'' means that you can add new hubs. Describe here, briefly, how to add a new hub, and the extent to which things are standardized in the existing scripts...}
The PTMTorrent dataset is designed to be maintainable by re-running our scripts to gather any additional changes that may have been made to the PTM registry since its last collection. 
Expect a biannual update.
%\new{We plan to update the PTMTorrent dataset every 6 months.}
% \JD{This material belongs in the next section, since it's not relevant to Data Storage}
% We make our dataset generation scripts available on GitHub: \url{https://github.com/SoftwareSystemsLaboratory/PTM-Torrent}. 

% \JD{Describe here, briefly, how to add a new hub, and the extent to which things are standardized in the existing scripts...}
% \WJ{PTAL, does the extensibility make sense?}
% \WJ{Can you check ``the extent to which things are standardized in the existing scripts...''}
For extensibility, new model hubs can be incorporated into the dataset.
We follow an open-source model and will review Issue and Pull Request contributions on GitHub.
The PTMTorrent data schema captures most elements of a PTM package, though some specialization is needed.
The downloaders for a new model hub can be developed based on the examples of the already-supported model hubs in our open-source data collection tools.
% The general PTMTorrent schema can be also used in other model hubs.
An extender must provide 2-4 scripts following the pattern we used on the other hubs.
%To encompass new model hubs and extend the current PTMTorrent, contributors can open issues on GitHub and make Pull Requests to provide an updated script to get the new metadata and a customized schema. 
% These GitHub features can ensure that our dataset will be maintainable.
% \JD{Previous sentences are a bit ridiculous, please try again.}
% \WJ{Need to revise based on our storage plan.} \AT{I understand what you are trying to say here, but it can be structured better for clarification. First explain how PTM registry hubs are rapidly growing. Then say how PTMTorrent is extensible by re-running the scripts. In a new paragraph, elaborate on the maintenance through GitHub requests.}

% \GKT{This schema reflects what we discussed; however, I'm wondering exactly what type of diagram you are using here. For example, the labeling of the edge for datasets to data sets doesn't look quite right, either for UML or other schemas, e.g. E/R diagrams. Can someone please check? I think this would read better if the 0 to N is shown clearly on the edge. But maybe I am getting too old to remember the right way....}
% \JD{Is there any right way? :-).}
% \GKT{I think there is, but I don't want to add to your or anyone's stress so if everyone thinks it is clear, I defer to your judgment. At least show the 0 to N relationship on the arrow, similar to E/R!}
% \AT{I believe this is the right way. The node shows a "0 to many optional" relationship, which is representative of the JSON.}
{
\begin{figure*}[t]
    \centering
    \includegraphics[width=0.75\textwidth]{figures/MSR/MSR_UML_Diagram.drawio.pdf}
    % {example-image-a}
    \caption{
    \small
    An overview of PTMTorrent's data schema. Each model hub shares a general schema (\textit{grey boxes}), with hub-specific data stored in customized schema (\textit{colored boxes}). The full schema is available in JSON in the dataset generation repository. 
    % \TODO{Add the 0 to N relationships to the diagram to make it clear.}
    % Entity-Relationship Diagram (ERD) for the PTMTorrent dataset.
    % \JD{Add another sentence here summarizing the general structure: ``Each model hub shares...with hub-specific data...''.
    % If this is NOT the full schema, then add another sentence indicating that, and say that the full one is available in JSON in the dataset generation repo. The main README of Nick's PTM-Torrent repo must link to the directory with the schema.}
    }
    \label{fig:DataSchema}
    % \vspace{-5mm}
\end{figure*}
}


\section{Originality and Relevance}
\label{sec:Originality}
% \WJ{@Nick any idea how PTMTorrent is relevant to previous Torrent datasets?}

Prior works have extracted information from open-source projects to a dataset and provide it for future analysis, such as GHTorrent~\cite{Gousios2012GHTorrent}, TravisTorrent~\cite{Beller2017TravisTorrent}, and RTPTorrent~\cite{Mattis2020RTPTorrent}.
These datasets can be used for further mining software repository researches and help the community better understand open-source software projects~\cite{Beller2017ExplorativeStudyofTravisCI, Zampetti2017HowOSProjectsUseStaticCodeAnalysisinCIPipelines, Gousios2014PullBasedSWDevelopment, Elsner2021RegressionTestOptimizationinCI}.

Similarly, our dataset captures the open-source PTM packages from many model hubs.
The structure of our dataset imitates prior datasets that were focused on traditional open-source software~\cite{Gousios2012GHTorrent, Mattis2020RTPTorrent}.
Compared to prior work, PTMTorrent focuses on PTM packages, including the metadata, architecture, dataset, and performance metrics.
Our dataset provides a way for users to efficiently download and access large amount of data on PTM packages and relevant repositories. 

% fine-grained program versions: GHTorrent\cref{Gousios2012GHTorrent}
% SOTorrent\cref{Baltes2018SOTorrent}
% TravisTorrent: real build bugs

% \section{Usage Examples} \label{sec:Usage Examples}
% % Usage Examples / Applications  (how could another person use this data? how can they access it?)% if the data has been used by the authors or others, a description of how this was done including references to previously published papers,

\section{Usage Examples}

% \JD{Use a subsection labeled ``Prior use of the dataset'' to make this really obvious to the reader.}
\subsection{Prior Usage in the Literature}
% \JD{Add more detail here please. Indicate specific measures.}
% \JD{Summarize the SCORED paper as well, esp. Fig 4 from that paper}
In prior work, we used a part of PTMTorrent (the Hugging Face part) to measure potential risks in the \HF model registry~\cite{Jiang2022PTMReuse}. 
We measured the dependencies of model architecture and datasets, PTM documentation, and GPG commit signing in \HF PTMs.
Our analysis identified potential software supply chain concerns facing PTM reusers, including spoofing, tampering, and repudiation. %~\cite{STRIDEAnalysis}.

In prior work, we also used metadata from \HF to measure model discrepancies and maintainers' reach~\cite{2022JiangEmpirical}.
Our analysis showed that existing defenses appear insufficient for ensuring the security of PTMs.
% the risks of collaboration in \HF, includ and identified potential software supply chain concerns facing PTM reusers.

The PTMTorrent dataset provides more opportunities for mining PTM data by covering more PTM registries and providing greater structure.
We believe that these large amount of PTM packages can be analyzed in similar ways as traditional packages~\cite{Zimmermann2019SecurityThreatsinNPMEcosystem, Zahan2022WeakLinksinNPMSupplyChain, Decan2018SecurityVulnerabilitiesinNPMDependencyNetwork}.

% \AT{I think the "relevance" part of this section is more about the applications of the dataset. Consider renaming it? The application part of the dataset seems to be a  big part of some MSR papers, it's almost like documentation for how to access their dataset. See Buchkova et al. and Bui et al.} 
% \WJ{I thought the ``relevance'' here is aimed to link the dataset to our ICSE submission. We can rename the section as ``usage example/scenario'' and then use ``prior usage'' and ``future usage'' as subsection headings.}

\subsection{Applying an Existing MSR Tool}

Since PTMTorrent consists of git repositories, it is possible to use existing software repository mining tools on the PTM packages. 
Our GitHub repository includes a demonstration of this.
We used our PRIME tool~\cite{synovic_snapshot_2022} to analyze software process metrics on a subset of the dataset.

\section{Limitations} \label{sec:Limitations}
% Limitations (where does our data lack? what is it missing?)
% \myparagraph{External validity}
% In PTMTorrent, we have only collected data from popular PTM registries indicated by prior work~\cite{2022JiangEmpirical}. However, 
% \TODO{potential ethical or privacy concerns?}
%\new{We highlight that PTMTorrent is incomplete, \ie having biases towards the top 10\% most-downloaded PTMs in Hugging Face.}

PTMTorrent is incomplete.
It is biased towards the top 10\% most-downloaded PTMs in HuggingFace (though this is almost all PTMs with any downloads, cf.~\cref{sec:PTMTorrent-DataSource}).
There are other model hubs, such as Papers With Code~\cite{PapersWithCode}, PINTO Model Zoo~\cite{PINTOModelZoo}, and Jetson Zoo~\cite{JetsonZoo}. 
Beyond these, there are other deep learning-specific registries that lack versioning or packaging features.
% To have a comprehensive picture of the PTM supply chain and a better understanding of the PTM package reuse, we will eventually need to encompass all the other model registries. 
% Despite this limitation, 
% We are focused on things that look like traditional software packages, as identified by Jiang \etal~\cite{22022JiangEmpirical}. We acknowledge that there are other DL-specific sharing locations that lack versioning, packaging, etc. but nevertheless are used by practitioners. We leave their capture for future work.
The initial PTMTorrent release provides PTMs from model hubs that are similar to traditional software packages, as defined by Jiang \etal~\cite{2022JiangEmpirical}.
We leave their capture for future work.


% Despite this limitation, we are confident we can analyze most major PTMs with minimal risk of missing others.
% \GKT{As I am reading this, I don't see this as a show-stopping limitation. Wenxin, is there any analysis that you think is not possible because we're not including registries mentioned here? We could say: Despite this limitation, we are confident we can analysze most major PTMMs with minimal risk of missing other important ones.}
% \GKT{Following up with myself, the question is: Is there any effort to support that we are likely to miss some important PTM if we leave these out? Otherwise, I posit that this a minimal-risk limitation. Can we somehow characterize how many models are in the ones that are missing? I am guessing this was not part of our previous analysis.}
% \JD{@GKT I think we are overemphasizing this weakness. Perhaps we can use sentences like these: ``We are focused on things that look like traditional SW packages, as identified by Jiang et al. We acknowledge that there are other DL-specific sharing locations, such as Kaggle and Papers With Code, that lack versioning, packaging, etc. but nevertheless are used by practitioners. We leave their capture for future work.''}
% \GKT{Thanks, @JD. I think our work is awesome, so I don't want to see us giving the reviewers an assist to reject us! New wording looks good.}

% \myparagraph{Internal validity}
Another limitation of our data is the non-standardized granularity.
% \JD{Let's use another word than ``granular'' because it is used with opposite meanings in different contexts.} 
% \WJ{Can we use the word ``granularity'' instead? See the previous sentence.}
The current version of PTMTorrent lacks detailed metadata and does not provide uniform information, \eg datasets, model architectures. During the data collection, we notice that the provided information from PTM registries can be quite different and we use customized data schemas for each PTM registry. As a result, it is difficult to analyze all the PTM packages under the same umbrella when using our dataset.

For example, \HF provides detailed documentation and structured metadata, as well as relevant configuration files for each PTM, while ONNX Model Zoo provides PTM metadata through unstructured Markdown files. Thereby making metadata extraction challenging. 
% Furthermore, the version control features in each PTM registry can be different. ONNX Model Zoo employs a naming convention to track different versions of PTMs. 
To mitigate this problem, we have a parent data schema for all the PTM registries and child schemas for each specific registry that represents their custom data.
% \AT{It might be a good idea to mention how we tried to mitigate this limitation. We had a parent JSON schema for all the PTM registries and then made child schemas for each hub. }


\section{Future Work} \label{sec:Future Work}
% \JD{Consider using subsection instead of myparagraph. We have space for it and it promotes accessibility (better table of contents for screen readers)}
% Future Work (what can this data be used for? what future research can be done with it?)
% \WJ{This section is longer than other dataset papers. I think we need to cut some paragraphs}
% \WJ{Should we shorten this part and move it to \$IV.B?}
% \JD{IV.B: I think the section heading is important}
 % \JD{Length: I don't think we should cut paragraphs. We can cut sentences. But each paragraph is about distinct directions and I think it is important to outline several directoins.}
% \TODO{the platform is a bit inconvenient to use. Also, how to handle this huge data at ease remains a challenge.}
In addition to the risk measurements presented by Jiang \etal~\cite{Jiang2022PTMReuse,2022JiangEmpirical}, the PTMTorrent dataset can be used in different ways.
%to help the community better understand the development trends and usage of PTM packages.
%Considering the relevant work (\cref{sec:Originality} and limitation (\cref{sec:Limitations}),
We suggest three research directions:
  PTM supply chain analysis,
  tools for PTM reuse,
  and
  mining tool development.

\iffalse
\subsection{Dataset enhancement}
% \myparagraph{Dataset enhancement}
% \WJ{Visualization of data?}
\CS{If you need to cut down future works, this part seems easy to go. It's a less compelling future direction than the others and seems to be the least expanded upon.}
The presented PTMTorrent does not cover all the existing model hubs and the metadata of different model registries are lack of standardization (\cref{sec:Limitations}).
As the number and variety of PTMs and PTM registries increase, it will be important to have a more detailed and comprehensive dataset, including the information about the training data, model performance and relevant dependencies.
% Future improvement can first be focused on enlarge the coverage of PTMTorrent to all the existing PTM registries. 
\fi

\subsection{Supporting Future PTM Supply Chain Analysis}
Prior work has focused on understanding the characteristics of package registries and their supply chains.
Zimmermann \etal analyzed the metadata of NPM packages and identified the potential threats on downstream users~\cite{Zimmermann2019SecurityThreatsinNPMEcosystem}.
Ladisa \etal proposed an attack taxonomy on open-source supply chains, including code contributions to package distribution~\cite{Ladisa2022TaxonomyofAttackonOSSSupplyChains}.
Similar studies are also important in PTM supply chain alongside studies focused on PTM-specific aspects.
%However, we highlight that there is not such study to deeply understand the characteristics of PTM packages yet. 
We propose that future studies can analyze PTMTorrent dataset to understand the characteristics of the PTM supply chain, including the dependency analysis~\cite{Zimmermann2019SecurityThreatsinNPMEcosystem}, vulnerabilities~\cite{Alfadel2021SecurityAnalysisinPythonPackages}, and code knowledge transfer~\cite{Ma2021OpenSourceVCSData}.
Recent advances in AI, such as ChatGPT~\cite{ChatGPT}, that clearly build upon composing various PTMs strongly suggest that being able to study how PTMs and are composed to build more complex systems (a trait shared with traditional software) will become more important.
We hope our dataset will aid in performing such analyses.

% \myparagraph{PTM recommendation system}
\subsection{Expanding PTM Model Registry Analysis}
% \TODO{If we have the measurements using PRIME, we can move this as part of the usage example.}
% \TODO{JD: For the PTM paper camera-ready, should we cite Diego's FSE-IVR paper under Future Work subsection B? It seems to match the heading and it's a relevant prior work I think? }
Researchers can extract more information from these model registries by reusing or developing software metrics for PTM packages, including provenance, reproducibility, and portability~\cite{Jiang2022PTMReuse}. PTM registries can help us develop comprehensive attributes and provide these details in the PTM dashboard, similar to the measured attributes from NPM~\cite{npmsAttribute} and PyPi~\cite{pypi}. 

Our prior study has indicated that engineers can have trouble finding the best PTM that matches their requirements, and it can therefore be hard to identify the portability and reproducibility of the open-source PTMs~\cite{Jiang2022PTMReuse}. 
Montes \etal shows that there exist notable discrepancies among different model zoos~\cite{montes_discrepancies_2022}. 
With more detailed and comprehensive metadata provided for each PTM and the corresponding usage patterns on downstream tasks, it will be possible to develop a recommender
% \GKT{This is the correct term, not recommendation.}
system to help engineers find the right set of PTMs for a given application and requirements~\cite{Robillard2010RecommendationSystems4SE}. PTM Registry contributors can develop sophisticated visualization tools---with the aid of our dataset---that help PTM users understand the strengths and limitations of each model.


\subsection{Furthering the State of Mining Tool Development}
Given the lack of standardization among different PTM registries (\cref{sec:Limitations}), it was challenging to standardize all the metadata.
PTMTorrent may not have everything needed for every type of analysis.
Researchers can 
%can develop tools by using manual regexes~\cite{Li2008RegexLearning4IE} or language models to
augment the dataset during the data collection and processing stage for other subsequent mining needs. %~\cite{Hong2022BROSKeyInformationExtractionfromDocs}.
We have included the relevant GitHub pages of each PTM in out dataset, and therefore the extraction can be done either based on the provided documentation from PTM registries~\cite{Slankas2013AutomatedExtractionofNonfunctionalRequirements} or source code from the underlying repositories~\cite{Allamanis2016AttentionNetwork4ExtremeSummarizationofSourceCode}.


% \JD{Citation 35's author is rendering oddly}
\iffalse
\section{Summary}
\WJ{We can remove this section for space.}
% \WJ{Do we need a conclusion section? I found some dataset papers do not have this section.}
% \AT{No, not really. The conclusion section usually addresses future works, but we already do that. But I do like the idea of explicitly stating the URLs.}
This paper presents PTMTorrent, an effort to provide the community an easy access to open-source PTM packages. Our dataset includes \TotalNumberOfPackages PTMs with extracted metadata and the corresponding GitHub repositories. The PTMTorrent dataset is in its initial stage and we encourage the community to help extend it. We also envision future work on PTM supply chain analysis and mining tool development. The dataset is available at \TODO{url}. The source code and scripts can be obtained at \TODO{url}
\fi

\ifANONYMOUS
\else
\section{Acknowledgements}
This work was supported by gifts from Google and Cisco and by NSF awards \#2107230, \#2229703, \#2107020, and \#2104319.
\fi

\raggedbottom
\pagebreak
\balance

\bibliographystyle{refs/IEEEtran}
% \bibliographystyle{refs/IEEEtran}
% \bibliography{refs/WenxinZotero, refs/Reference, refs/DualityLab}
\bibliography{main}
%\begin{appendices}
%
%\end{appendices}
\raggedbottom
\pagebreak
\balance


\end{document}