\documentclass[../main.tex]{subfiles}

\begin{document}

\textit{J. Mold칩n, L. Darriba, L. Verdes-Montenegro, D. Kleiner, S. S치nchez, M. Parra, J. Garrido, A. Alberdi, J. M. Cannon, Michael G. Jones, G. J칩zsa, P. Kamphuis, I. M치rquez, M. Pandey-Pommier, J. Sabater, A. Sorgho}\newline

\noindent The HI-FRIENDS team implemented a workflow \citep{moldon_javier_2021_5172930} based on a combination of {\sc SoFiA-2} \citep{2021MNRAS.506.3962W} and {\sc python} scripts to process the data cube. The workflow, which is publicly available in GitHub\footnote{\url{https://github.com/HI-FRIENDS-SDC2/hi-friends}}, is managed by the workflow engine {\sc snakemake} \citep{10.12688/f1000research.29032.2}, which orchestrates the execution of a series of steps (called rules) and parallelizes the data analysis jobs.  {\sc snakemake} also manages the installation of the software dependencies of each rule in isolated environments using conda \cite{anaconda}. Each rule executes a single program, script, shell command or {\sc jupyter} notebook. With this methodology, each step can be developed, tested and executed independently from the others, facilitating modularisation and reproducibility of the workflow.

First, the cube is divided into smaller subcubes using the {\sc spectral-cube} from {\sc astropy} \citep{astropy:2018}. An overlap of 40 pixels (112 arcsec) to avoid splitting large galaxies. Source detection and characterisation is performed in the second rule using {\sc Sofia-2} \citep{2021MNRAS.506.3962W}. We optimised the {\sc Sofia-2} input parameters based on visual inspection of plots of the statistical quality of the fit and of some individual sources. In particular, we found that the parameters \texttt{scfind.threshold}, \texttt{reliability.fmin}, and \texttt{reliability.threshold} were key to optimising our solution. We found that using the spectral noise scaling in {\sc SoFiA-2} dealt well with the effects of RFI-contaminated channels and we did not include any flagging step.

The third rule converts the {\sc Sofia-2} output catalogues to new catalogues containing the relevant SDC2 source parameters in the correct physical units. We computed the inclination of the sources based on the ratio of minor to major axis of the ellipse fitted to each galaxy, including a correction factor dependent on the intrinsic axial ratio distribution from a sample of galaxies, as described in \cite{1992MNRAS.258..334S}. The next two rules produce a concatenated catalogue for the whole cube: we concatenate the individual catalogues into a main, unfiltered catalogue containing all the measured sources, and then we remove the duplicates coming from the overlapping regions between subcubes using the r.m.s. as a quality parameter to discern the best fit. Because the cube was simulated based on real sources from catalogues in the literature we further filtered the detected sources to eliminate outliers using a known correlation between derived physical properties of each galaxy. In particular, we used the correlation in Fig.~1 in \cite{2016MNRAS.460.2143W} that relates the H{\sc i} size and H{\sc i} mass of nearby galaxies. Several plots are produced during the workflow execution, and a final visualization rule generates a {\sc jupyter} notebook with a summary of the most relevant plots. 

Our workflow aims to follow FAIR principles \citep{Wilkinson2016,katz2021fresh} to be as open and reproducible as possible. To make it findable, we uploaded the code for the general workflow to Zenodo  \citep{hifriendswf} and WorkflowHub \citep{hifriendswf2}, which includes metadata and globally unique and persistent identifiers. To make the code accessible, we made derived products and containers available on Github and Zenodo as open source. To make it interoperable, our workflow can be easily deployed on different platforms with dependencies either automatically installed (e.g., in a virtual machine instance in myBinder \citep{project_jupyter-proc-scipy-2018} or executed through singularity, podman or docker containers. Finally, to make it reusable we used an open license, we included workflow documentation\footnote{\url{https://hi-friends-sdc2.readthedocs.io/en/latest/}} that contains information for developers, the workflow is modularized as {\sc snakemake} rules, we included detailed provenance of all dependencies and we followed The Linux Foundation Core Infrastructure Initiative (CII) Best Practices\footnote{\url{https://bestpractices.coreinfrastructure.org/en/projects/5138}}. Therefore, the workflow can be used to process other data cubes and should be easy to adapt to include new methodologies or adjust the parameters as needed.






\end{document}