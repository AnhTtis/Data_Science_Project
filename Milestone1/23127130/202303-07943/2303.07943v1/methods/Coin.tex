\documentclass[../main.tex]{subfiles}

\begin{document}

\textit{C. Heneka, M. Delli Veneri, A. Soroka, F. Gubanov,  A. Meshcheryakov, B. Fraga,  C.R. Bom,  M. BrÃ¼ggen }\newline


\noindent During the Challenge the Coin team tested several modern ML algorithms from scratch alongside the development our own wavelet-based `classical' baseline detection algorithm. For all approaches we first flagged the first 324 channels in order to remove residual RFI, as measured by the per-channel signal mean and variance. We considered the following ML architectures for object detection: 2D/3D U-Nets, R-CNN and an inception-style network that mimics filtering with wavelets. The to-date best-performing architecture was a comparably shallow segmentation U-Net that translated the 2D U-Net in~\citet{ronneberger2015u} to 3D. It was trained on 3D cubic patches taken from the development cube, each containing a source and with no preprocessing applied. We mitigated High ($> 90\%$) rates of false positives to moderate levels ($\sim 50\%$; see Fig.~\ref{coin_im}) by imposing interconnectivity and size cuts on the potential sources and discarding continuum-bright areas. We obtained a roughly constant $\sim$50:50 ratio between true and false positives for 0.25 deg$^2$ cutouts across the development cube and the full Challenge cube. Our `classical' baseline performed an alternative detection procedure, first using Gaussian filtering in the frequency dimension followed by wavelet filtering and thresholding.  Interscale connectivity~\citep{scherzer2010handbook} and reconstruction were performed on the denoised and segmented output. This pipeline detected $< 10\%$ true positives for the Challenge data release: an order of magnitude higher false positive rate than the ML-based pipeline. 


Source positions (RA, Dec, central frequency, line width) were directly inferred from the obtained segmentation maps via the \texttt{regionprops} function of the {\sc scikit-image python} package~\citep{scikit-image}.  Source properties (flux, size) were derived through a series of ResNet CNNs~\citep{He2016DeepRecognition} applied to the source candidate 3D cutouts. The position angle was measured using the {\sc scikit-image} package to fit ellipses to sources masks; inclination could not be fitted for most objects.  


We conclude that further cleaning and denoising and the application of techniques from the `classical' baseline, such as wavelet filtering, is needed to improve on our machine learning pipeline method. Alternatively, further steps that include classification and a more curated training set could be desirable. Lessons learned in these `from-scratch' developments can give valuable insights into the performance and application of said algorithms, such as the suitability of 3D U-Nets for segmentation of tomographic H{\sc i} data and the need for additional cleaning algorithms jointly with networks or multi-step procedures, such as a classification step, when faced with low S/N data.




\begin{figure}
	\centering
	\includegraphics[width=0.9\columnwidth]{images/diagram_SDC2_coin.png}
	\caption{Data processing pipeline used by the Coin team.}
	\label{coin_im}
\end{figure}



\end{document}


