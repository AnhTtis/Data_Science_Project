\begin{abstract}
    The generation of high-quality images has become widely accessible and is a rapidly evolving process. As a result, anyone can generate images that are indistinguishable from real ones. This leads to a wide range of applications, including malicious usage with deceptive intentions. Despite advances in detection techniques for generated images, a robust detection method still eludes us. Furthermore, model personalization techniques might affect the detection capabilities of existing methods.
    In this work, we utilize the architectural properties of convolutional neural networks (CNNs) to develop a new detection method. Our method can detect images from a known generative model and enable us to establish relationships between fine-tuned generative models. We tested the method on images produced by both Generative Adversarial Networks (GANs) and recent large text-to-image models (\TI{s}) that rely on Diffusion Models. Our approach
    outperforms others trained under identical conditions and
    achieves comparable performance to state-of-the-art pre-trained detection methods on images generated by Stable Diffusion and MidJourney, with significantly fewer required train samples.\\
    Update (June 2024): We have re-validated our method according to recent studies, which indicate that most detection methods rely only on JPEG artifacts found in real images. In this setting our results are still on par with competitors.
  
    \blfootnote{\textbf{Acknowledgement}: This work was supported in part by the Israel Science Foundation (grant No. 1574/21).}
    \blfootnote{
    \textbf{Project page}:
    \niceurl{https://sergo2020.github.io/DIF/}
    }
    
\end{abstract}