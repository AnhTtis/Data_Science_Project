
% Comparison of proposed method to others

\begin{table*}[ht]
    \centering
    \footnotesize
    \begin{tabular}{ llcccccc|c }
    \toprule 
    \textbf{$N_S$} &\textbf{Method} & \textbf{SD 1.4} & \textbf{SD 2.1} & \textbf{MJ} &\textbf{\dalM}& \textbf{GLIDE} & \textbf{\dalT} & \textbf{Mean}\\
    \midrule
    \multirow{9}{2.em}{1024} & Joslin20  & 49.7 & 49.9  & 49.9 & 52.3 & 57.0 & 51.4 & 51.7 \\
    & Marra18 & 52.6 & 48.0  & 75.7 & 85.3 & 57.6 & 56.3 & 62.6  \\
    & Ning18 & 50.8 & 51.4  & 59.5 & 58.1 & 57.7 & 52.2 & 55.0 \\
    & Wang20$_{F}$ &  63.7 & 61.7 & 75.7 & 78.3 & 74.5 & 74.7 & 71.4  \\
    & Resnet50$_{F}$ & 72.2 & 72.6 & 87.1 & 87.5 & 94.1 & 88.7 & 83.7  \\
    & Grag21 &  69.2 & 73.6 & 89.7 & 89.4 & 94.3 & 85.9  & 83.7 \\
    & Grag21$_{F}$ & 93.5 & 86.9 & 93.5 & 96.1 & \textbf{97.5} & \textbf{93.5}  & 93.5 \\
   & Corv22$_{F}$ &  \textbf{99.7} & \textbf{99.0} & \textbf{99.2} & 96.4 & 96.0 & 91.9  & \textbf{97.0} \\
    & DIF & 99.3 & 89.5  & 99.0 & \textbf{99.0} & 90.3 & 79.5  & \underline{92.8} \\
    \midrule
    
    \multirow{5}{2.em}{512} & Resnet50$_{F}$ & 70.6 & 70.5 & 90.0 & 85.4 & 92.7 & 85.4  & 82.4 \\
    & Grag21 &  68.3 & 71.4 & 81.1 & 85.2 & 91.3 & 83.8 & 80.2  \\
    & Grag21$_{F}$  &  93.0 & 86.0 & 94.7 & 96.1 & \textbf{96.4} & \textbf{92.1}  & 93.1  \\
    & Corv22$_{F}$ &  \textbf{99.6} & \textbf{98.6} & \textbf{98.8} & 95.9 & 95.1 & 89.4  &\textbf{96.2} \\
    & DIF & 99.2 & 86.3  & \textbf{98.8} & \textbf{98.7} & 88.2 & 79.1  & \underline{91.7} \\
    \midrule
    
    \multirow{5}{2.em}{256} & Resnet50$_{F}$ & 66.2 & 64.0 & 86.4 & 82.0 & 89.0 & 81.4  & 78.2  \\
    & Grag21 &  67.2 & 65.8 & 74.4 &  83.5 & 88.0 & 75.3  & 75.7 \\
    & Grag21$_{F}$  &  89.9 & 82.9 & 94.1 & 94.9 & \textbf{95.6} & 90.5  & 91.3 \\
    & Corv22$_{F}$ &  \textbf{99.6} & \textbf{98.6} & \textbf{99.0} & 95.6 & 94.8 & 89.0  & \textbf{96.1} \\
    & DIF & 98.5 & 81.3  & 98.1 & \textbf{98.0} & 85.9 & 77.7  & \underline{89.9} \\
    \midrule
    
    \multirow{5}{2.em}{128} & Resnet50$_{F}$ & 66.2 & 64.0 & 85.9 & 75.1 & 87.6 & 75.2  & 75.7 \\
    & Grag21 &  68.0 & 66.4 & 72.6 & 81.0 & 80.3 & 71.7  & 73.3\\
    & Grag21$_{F}$  &  87.9 & 82.2 & 93.4 & 93.5 & \textbf{94.2} & \textbf{90.4}  & 90.3 \\
    & Corv22$_{F}$ &  \textbf{99.6} & \textbf{98.4} & \textbf{98.6} & 93.9 & 89.1 & 77.5 & \textbf{92.9} \\
    & DIF & 97.7 & 75.5  & 97.3 & \textbf{97.0} & 81.4 & 76.1  & \underline{87.5} \\
    \midrule
    
    \multirow{3}{2.em}{---}& Wang20$_{D}$ &  50.0 & 49.8 & 50.2 & 50.7 & 53.3 & 51.0  & 55.9 \\
    & Grag21$_{D}$ &  57.0 & 50.2 & 63.1 & 58.0 & 54.3 & 51.2  & 55.6 \\
    & Corv22$_{D}$ &  \textbf{99.3} & \textbf{99.3} & \textbf{99.0} & \textbf{89.5} & \textbf{57.0} & \textbf{51.6}  & \textbf{82.6} \\
     \bottomrule
     
    \end{tabular}
    \caption{Classification accuracy (\%). $N_S$ is the amount of train samples. Methods are indexed as follows: $D$ pre-trained and not fine-tuned, $F$ pre-trained and fine-tuned on the given data, no index indicates that the model is trained from scratch. \new{The only true competitor to DIF are fine-tuned SOTA Grag21 and Corv22, which were pre trained on a large datasets. Corv22 is expected to have edge over DIF as it was pre-trained on images from SD models. \serge{If we leave Grag22 then we should remove one of the $N_S$ sections.}}
    \label{tab:accuracyTI}}
\end{table*}
