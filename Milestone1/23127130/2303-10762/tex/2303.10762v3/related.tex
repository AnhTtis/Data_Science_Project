
\section{Related Work}\label{sec:related}

Data-driven methods rely on CNN classification models. These methods aim to detect compressed images from unknown image generators by training a detector on images from a single image generator. The authors of \cite{art:easycnn} fine-tune a pre-trained \RES~\cite{art:resnet} with 720k fake and real images produced by ProGAN and apply a set of compressions during training. They achieve high average precision on images from several GAN models, but demonstrate poor accuracy (\cref{sec:detection}). In \cite{art:easygan}, the authors repeat the process, but with a modified Resnet50 and heavier augmentations, resulting in SOTA performance. However, after the development of \TI{s}, another study~\cite{art:diffDetect} revealed that later model generalizes well only on the same image generator family.

One notable approach from rule-based methods involves detecting spatially-stationary \new{and high-frequency} artifacts that image generators produce within images~\cite{art:checkerboard}. These artifacts were observed in generated images~\cite{art:ganfingerprint,art:ganfingerprintAE,art:Joslin2020}, including those produced by \TI{s}~\cite{art:diffDetect, art:intrigue}. Since they are unique to each trained image generator, they are referred to as \emph{fingerprints} (\FI). To estimate \FI, a set of residuals is produced by passing each image through a denoising filter (\HP), and the residuals are then averaged. This leaves only the common deterministic pattern within the residuals --- the fingerprint. The image is associated with the generative model by calculating the correlation coefficient between its residual and the model's \FI.

\new{

The usage of \FI{-s} holds great potential in model lineage analysis. Marra~et~al.~\cite{art:ganfingerprint} demonstrated that residuals of images generated by a specific model architecture exhibit high correlation not only with the model's fingerprint but also with the fingerprints of models sharing the same architecture \cite{art:ganfingerprint}. 
Yu~et~al. proposed a supervised method to attribute fake images to their source models, training a detector on a dataset of images generated by multiple GANs \cite{art:ganfingerprintAE}. Nevertheless, this approach relies on manual supervision, requiring researchers to make educated guesses about the relationship between different models prior to training. Previous studies have not explored 
the relationship between models and their fine-tuned versions, or the methodology for model lineage analysis.}


In addition to the above, \FI{-s} and other artifacts are primarily observed in the spectrum space, by transforming the image with the Fast Fourier Transform~(\fft). Some studies~\cite{art:spec, art:ganfreq} use this concept by training models on image spectrum samples or performing operations within Fourier space. Some attempts have also been made to synthesize a large set of \FI{-s} for further training of detectors~\cite{art:spec, inp:fingerprintNet}. However, while these methods demonstrate good detection accuracy for a set of image generators on average, they may perform poorly with some of them.

Another group of rule-based methods focuses on detecting color distortions in generated images~\cite{art:ganColorspaces, art:ganclues, art:graphgan, art:forencisCNN}. These detection methods are usually evaluated on both generated and natural images and have shown promising results. However, it should be noted that color distortions have only been demonstrated for a few image domains and GAN models.

