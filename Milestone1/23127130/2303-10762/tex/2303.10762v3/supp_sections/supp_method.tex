
\section{Implementation Details}\label{apx:method}

This section includes the implementation details of our work. The DIF models were trained and tested on an RTX 3060 GPU with 12 GB of VRAM. We used PyTorch~\cite{art:pytorch} as our deep learning framework
\footnote{\url{https://github.com/Sergo2020/DIF_pytorch_official}}.

\new{
\subsection{Selection of Denoising Filter}


Here we explain why DnCNN~\cite{art:dncnn} was chosen as the denoising filter (\HP{}) for all the fingerprint methods. The objective of the \HP{} is to extract only noise and artifacts while filtering out the semantic information of the image. The pattern of $\mathcal{F}$ is primarily present in the high-mid frequencies~\cite{art:ganfingerprint}, making a high-pass filter a straightforward choice as a reference \HP{}. However, some semantic content, such as edges, also exists in these frequencies. Therefore, a more sophisticated denoising filter is required. DnCNN is such a filter. It is trained to extract Gaussian noise while preserving edges, and it has demonstrated good performance with other types of noise as well~\cite{art:dncnn}. To validate our assumption, we compare the performance of Marra18, Joslin20, and DIF using both a Gaussian high-pass filter and DnCNN (\cref{tab:filters}).  
\input{figs/tables/filter_comp}

As expected, all of the methods perform worse with the Gaussian high-pass filter. The high-frequency content of the image influences the averaged and extracted fingerprint pattern, leading to low correlation values between unseen residuals (test set) and fingerprints. 
}

\subsection{Usage of DnCNN}

The DnCNN-S~\cite{art:dncnn} model was trained separately from the residual extraction procedure. The training was performed according to the original work with minor changes. We trained the DnCNN-S model for 2,000 epochs with a learning rate of $10^{-4}$ and the Adam optimizer~\cite{art:adam}. Only real images were used during training. Random crop is set to size $(48 \times 48)$ pixels and a sigma range is set to [5, 15]. The number of training images is 1024.

During the inference of the DnCNN, we applied post-processing. First, the input to the DnCNN was padded with 10 pixels on each dimension and then reduced as post-processing according to the recommendations of the authors~\cite{art:dncnn}. Additionally, we observed a bias within the residuals, so we performed an additional post-processing step. We took the training set of the DnCNN and calculated the average of its residuals, thus estimating the fingerprint of the DnCNN ($\mathcal{F}_{DnCNN}$). During the inference of the model, this fingerprint was subtracted from the output according to:
\begin{equation}
    R_i = f_{D}(X_i) - \mathcal{F}_{DnCNN}
\end{equation}

\subsection{U-Net Architecture}\label{sec:}

In \cref{tab:unet}, we summarize the architecture of the U-Net model, denoted in the paper as $g_{\theta}$. Each row represents a convolution block, comprised of two convolutional layers and either an up-sampling or a down-sampling layer. The convolutional layers have a kernel size of 3, stride of 1, and padding of 1 pixels for each spatial dimension \new{to achieve boundary artifacts}. Each convolutional layer is accompanied by Batch-Normalization~\cite{art:batchnorm} and an activation function, which are specified in \cref{tab:unet}. We use max-pooling with a kernel size of $2 \times 2$ pixels for down-sampling and a deconvolution layer with a kernel size of $2 \times 2$ pixels and stride of 2 pixels for up-sampling. The latter is suspected to be the main causes of grid-like artifacts~\cite{art:checkerboard}. The last block consists only of a single convolution layer where we do not use Batch-Normalization and rely on hyperbolic tangent (TanH) as the activation function.
\input{figs/tables/unet}

\new{
\subsection{Selection of Model Architecture}

We selected the U-Net architecture through hyperparameter tuning and by incorporating concepts mentioned in Section 3.1. A Convolutional Network (C-Net) consists of convolutional blocks without down-sampling and up-sampling operations. An Up-Sampling Network (D-Net) serves as the decoder in the U-Net model. U-Net with 1x1 kernels within convolutional layers denoted as U1-Net, where we test the importance of only up-sampling artifacts. U-Net refers to the aforementioned architecture.

In \cref{tab:accuracyArch}, U-Net outperforms other architectures, while C-Net shows the worst performance due to the lack of up-sampling, which is crucial (Section 3). Interestingly, C-Net shows minimal decline when used with the GLIDE model, indicating a dominant presence of boundary artifacts (Figure 2). Additionally, U1-Net, designed to reduce boundary artifacts, experiences approximately a 5\% decline compared to other architectures when used with GLIDE.

D-Net performs similarly to U-Net as both models generate both up-sampling and boundary artifacts. However, U-Net was chosen due to its superior performance.

\input{figs/tables/arch_compare}
}

