\subsection*{Additional Experimental Details and Results}

\textbf{Details on experiment implementation}
As mentioned in the main text, we use Bayesian Optimization with Gaussian processes as our choice of optimization-guided sampler. When we sample using one of these optimizers, we have it maximize a target value that is equivalent to the quantitative semantics of the STL specification it is sampling for. In the case of the individual properties baseline, these specifications are simply $G(p)$, where $p \in LP$ are the individual properties themselves, and $G$ is the globally operator in temporal logic semantics. To encourage exploration, we add a term to the optimizer's target value that adds the following quantity \textit{if and only if} the sample and its corresponding trajectory satisfies the specification:
\[
a \cdot \min_{\xi_{\pi} \in \varphi}(\text{distance}(\xi_{\pi}, \xi_{\pi}^{c}))
\]
Here, $\xi_{\pi}^{c}$ is the current trajectory of the sampled environment condition that is being evaluated, and $a$ is our exploration hyperparameter. Intuitively, we find the \textit{minimum} distance between our current trajectory and all other trajectories that satisfied the same trajectory, and use that as our exploration bonus. Although this does not guarantee a minimum level of exploration, it does incentivize finding new regions of the environment condition space that also satisfy our specification. We keep the same exploration bonus with the same hyperparameter multiplier $a$ for all baselines that use optimization-based sampling.

For our behavior cloning models, we use a 3-layer, 256-unit MLP network as our model class. We train the model for 100 epochs on its training dataset with a learning rate of 0.0001 and a batch size of 500. We perform all training on an NVIDIA RTX A4500, which is the same hardware on which CARLA environments were sampled and simulated on. Our training data was a vector of features that captured relevant information about the trajectory and environment, namely, the ego's location, velocity, heading, and acceleration, and if the ado was within the line of sight (i.e., not blocked by the occlusion in the environment), the ado's location and speed, both modified by injecting Gaussian noise (centered at zero in both cases, with variances of two and one for location coordinates and speed, respectively.) 

\textbf{Additional Results.} In Tables~\ref{tab:ocm_ap_straight},~\ref{tab:ocm_ap_left}, and~\ref{tab:ocm_ap_right}, we present the results for outcome-specific matching rates for each of the CARLA autopilot maneuvers. Like the results for our neural network expert, we see that SGDA largely outperforms our baselines in having higher outcome-specific matching rates, especially in cases where the outcomes are highly unlikely. On more likely outcomes, SGDA is able to perform close to the level of our baselines, which have seen significantly more of these outcomes for, such as the example mentioned in the main text. Part of these discrepancies can be attributed to the limited amount of data shown to each model during training. We expect that with more data, SGDA will improve even more relative to baselines, since SGDA will aggregate data on outcomes that it matches poorly on (both unlikely and likely), whereas the baseline methods do not have a principled way to sample many different unlikely outcomes and improve their imitations in such settings.

\textbf{Robustness Experiment.} As mentioned in the main text, we run a simple experiment to observe how the performance of SGDA changes when we vary a property in the set $LP$. Specifically, we repeat our NN-Expert experiment, and vary the threshold for the braking threshold in our ``Do not abruptly brake'' property, keeping the other properties fixed. By varying this threshold, we change the frequency with which this property is violated by our expert in different environment conditions. We run SGDA for two rounds, with the same additional properties (avoid collisions and do not halt) and experimental setup described in the main text. We then measure the matching percentage of SGDA on \emph{just} the property we vary. Concretely, we observe: if the expert violated the braking property when set to a certain threshold, does our learned imitation violate the property at that threshold as well? We study the performance on this property in isolation from the others.

\begin{figure}
     \centering
\includegraphics[width=0.98\linewidth]{imgs/robustness.png}
     \caption{Matching rates (in orange and blue) for SGDA and the uniform baseline on violations of the brake property, when varying the brake rate threshold. We also present the frequency (in purple) with which the property is violated when the threshold is set at varying rates.}
     \label{fig:robustness}
\end{figure}

We present our results in Fig.~\ref{fig:robustness}. We collect a test dataset of 500 episodes, sampling from the uniform prior distribution of environment conditions (without any rejection sampling, as done in the main experiment.) The purple (dashed) line records how frequently the property is violated in the expert trajectories in our test dataset, at a given braking threshold. We see that as the braking threshold (x-axis) increases, the frequency of observing a violation decreases slightly, then drops off significantly from a threshold of 0.4 to 0.5. The blue line shows SGDA's  matching percentage for \textbf{violations} of this single property. To compare with a baseline, we present the same results for the uniform baseline, shown in orange. We see that SGDA's matching rate changes little for threshold values from 0.2-0.4, even as the frequency drops from just below 30 percent to just above 20 percent. However, at a threshold of 0.5, when the frequency drops to below 10 percent, both SGDA and the uniform baseline's performances drop precipitously. This indicates to us that the frequency of seeing a property has a strong impact on SGDA's performance, when that frequency falls below a certain threshold. 

We reason that both a larger pool of environments to sample and select from, as well as more rounds of data aggregation, will help mitigate such dropoffs in practice. Measuring the relative frequencies of properties included in $LP$ will help inform the choices of hyperparameters when using SGDA, such as the amount of data to aggregate, how many environments to sample and select, and how to balance exploitation and exploration in the UCB algorithm during environment sampling. The exact nature of the property matters as well - we observe that in situations where our NN-expert abruptly brakes with a high brake rate, that high rate is only applied for a small number of initial timesteps before the rate comes down and the expert slows down more gradually. Our imitations had trouble replicating this exact behavior during learning, which further explains the dropoff in performance as the threshold grew to 0.5. 


\begin{table*}[]
    \centering
    \normalsize
    \caption{Number of samples for each specification in the expert test dataset and outcome match rates for each baseline in the Autopilot straight maneuver experiment.}
    \label{tab:ocm_ap_straight}
    \begin{tabular}{ccc|c|cccc}
        \toprule
        (1) Avoid & (2) Do not & (3) Do not & & \multicolumn{4}{c}{\textbf{AP-Straight Match Rates}} \\
        Collisions & Halt & Abruptly Brake & \# Outcomes & SGDA & Ind. Props & Single-Spec & Uniform \\
        \midrule
        \cmark & \cmark & \cmark & 226 & 91\% & 85\% & \textbf{92\%} & \textbf{92\%} \\
        % \hline
        \cmark & \cmark & \xmark & 20 & \textbf{15\%} & 0\% & 0\% & 0\% \\
        % \hline
        \cmark & \xmark & \cmark & 67 & \textbf{92\%} & 76\% & 21\% & 34\% \\
        % \hline
        \cmark & \xmark & \xmark & 65 & 88\% & \textbf{91\%} & 75\% & 44\% \\
        % \hline
        \xmark & \cmark & \cmark & 20 & \textbf{80\%} & \textbf{80\%} & 55\% & 50\% \\
        % \hline
        \xmark & \cmark & \xmark & 26 & \textbf{31\%} & 23\% & 15\% & 0\% \\
        % \hline
        \xmark & \xmark & \cmark & 20 & \textbf{70\%} & 50\% & 20\% & 0\% \\
        % \hline
        \xmark & \xmark & \xmark & 56 & \textbf{20\%} & 0\% & 0\% & 7\% \\
        \bottomrule
    \end{tabular}
\end{table*}

\begin{table*}[]
    \normalsize
    \centering
    \caption{Number of samples for each specification in the expert test dataset and outcome match rates for each baseline in the Autopilot left-turn maneuver experiment.}
    \label{tab:ocm_ap_left}    
    \begin{tabular}{ccc|c|cccc}
        \toprule
        (1) Avoid & (2) Do not & (3) Do not & & \multicolumn{4}{c}{\textbf{AP-Left Match Rates}} \\
        Collisions & Halt & Abruptly Brake & \# Outcomes & SGDA & Ind. Props & Single-Spec & Uniform \\
        \midrule
        \cmark & \cmark & \cmark & 191 & 82\% & \textbf{89\%} & \textbf{89\%} & 88\% \\
        % \hline
        \cmark & \cmark & \xmark & 20 & \textbf{20\%} & 0\% & 0\% & 0\% \\
        % \hline
        \cmark & \xmark & \cmark & 115 & 92\% & \textbf{96\%} & 95\% & 87\% \\
        % \hline
        \cmark & \xmark & \xmark & 20 & \textbf{65\%} & 0\% & \textbf{65\%} & 10\% \\
        % \hline
        \xmark & \cmark & \cmark & 20 & \textbf{35\%} & \textbf{35\%} & 10\% & 0\% \\
        % \hline
        \xmark & \cmark & \xmark & 68 & \textbf{37\%} & 0\% & 13\% & \textbf{37\%} \\
        % \hline
        \xmark & \xmark & \cmark & 20 & \textbf{90\%} & 40\% & 5\% & 0\% \\
        % \hline
        \xmark & \xmark & \xmark & 46 & \textbf{70\%} & 0\% & 0\% & 20\% \\
        \bottomrule
    \end{tabular}
\end{table*}

\begin{table*}[]
    \normalsize
    \centering
    \caption{Number of samples for each specification in the expert test dataset and outcome match rates for each baseline in the Autopilot right-turn maneuver experiment.}
    \label{tab:ocm_ap_right}
    \begin{tabular}{ccc|c|cccc}
        \toprule
        (1) Avoid & (2) Do not & (3) Do not & & \multicolumn{4}{c}{\textbf{AP-Right Match Rates}} \\
        Collisions & Halt & Abruptly Brake & \# Outcomes & SGDA & Ind. Props & Single-Spec & Uniform \\
        \midrule
        \cmark & \cmark & \cmark & 195 & 88\% & \textbf{93\%} & 91\% & \textbf{93\%} \\
        % \hline
        \cmark & \cmark & \xmark & 20 & \textbf{20\%} & 5\% & 0\% & 0\% \\
        % \hline
        \cmark & \xmark & \cmark & 97 & \textbf{73\%} & 67\% & 34\% & 60\% \\
        % \hline
        \cmark & \xmark & \xmark & 20 & \textbf{30\%} & 0\% & 0\% & 0\% \\
        % \hline
        \xmark & \cmark & \cmark & 20 & \textbf{80\%} & 50\% & 55\% & 70\% \\
        % \hline
        \xmark & \cmark & \xmark & 55 & \textbf{62\%} & 25\% & 18\% & 16\% \\
        % \hline
        \xmark & \xmark & \cmark & 37 & \textbf{84\%} & 41\% & 79\% & 38\% \\
        % \hline
        \xmark & \xmark & \xmark & 56 & 28\% & 34\% & \textbf{39\%} & 23\% \\
        \bottomrule
    \end{tabular}
\end{table*}

\subsection*{Additional Algorithmic Details} 

\textbf{Property Weights.} In section~\ref{sec:env_partition}, we noted that a potential issue of our STP method is the partition size that is exponential in the size of our property set, $p \in LP$. If we were to run the original algorithm on an extremely large partition, we would likely be sampling for specifications that we may value less than others, leading to inefficiency in environment sampling and selection. To combat this, we generalize SGDA and our STP formation to a setting where a user can provide \textit{weights} for each property in their set to quantify how semantically meaningful the existence of a given property is relative to other properties. 

Formally, we define a \textit{weighted} property set as a tuple $(w, p) \in LP^w$, where each weight $w$ associated with a property is a real-valued number in the range $(0, 1)$. We can then take the product of these weights (or their complements, in the case of negated properties), to assign weights to entire specifications. To make this more concrete, recall the simple example introduced in section~\ref{sec:env_partition}, where we have just two properties: \textbf{A} (avoid collisions) and \textbf{B} (avoid speeding.) Suppose that a user is very interested in outcomes where collisions occur, and only slightly interested in seeing outcomes where the car is not speeding. Following this reasoning, the user assigns the following property weights: \textbf{A} is assigned a weight of 0.1, and \textbf{B} is assigned a weight of 0.6. This means that the negation of \textbf{A} (in presence of a collision) is assigned the complementary weight to \textbf{A}, or (1 - 0.1) = 0.9, and the negation of \textbf{B} is assigned (1 - 0.6) = 0.4. These weights then are multiplied to form weights for each specification in the STP. In this example, $(A \land B)$ would have weight $(0.1 * 0.6) = 0.06$, $(\neg A \land B)$ would have $(0.9 * 0.6) = 0.54$, $(A \land \neg B)$ would have $(0.1 * 0.4) = 0.04$, and $(\neg A \land \neg B)$ would have $(0.9 * 0.4) = 0.36$. 

Once we have computed weights for each specification in our STP, leveraging these weights in the SGDA algorithm is conceptually straightforward. We can use each specification's weight as a multiplicative factor in the Q-value assigned to each specification defined in algorithm~\ref{ecs_alg}. These weighted Q-values will then be used by the UCB algorithm to select future specifications to sample for. This means that specifications with lower weights will have lower Q-values, and are less likely to be sampled for during the sampling step of SGDA.


\textbf{Computational Overhead of SGDA.} 
The SGDA algorithm will incur an asymptotic computational overhead with respect to the hyperparameters of the algorithm that differs from other environment sampling approaches. We informally discuss the overhead here.

The computational overhead that SGDA sustains lies primarily in the sampling step (EC-Samp). In the sampling step, outlined in algorithm~\ref{ecs_alg}, the following computations will add nontrivial overhead: (1) the invoking of an optimization-based sampler to get new environment conditions, (2) actuating the dynamics to collect a trajectory $ \xi_{\pi^{\text{IL}}}(e) = d(\pi^{\text{IL}}, e) $ and checking which specification in the partition $(e, \xi_{\pi^{\text{IL}}}(e))$ falls into, and (3) computing the Q-values for each specification and invoking the UCB computations with these Q-values to select the next specification to sample for. 

Regarding (1), distributions learned by optimization-guided samplers are generally learned iteratively and online, so this computation will contribute only minor overhead. Regarding (3), the computational complexity for these operations will scale linearly with the size of the partition, but the computation of Q-values and UCB values for each specification only requires simple arithmetic operations and will not heavily burden the computation. Both algorithmically and in practice, we find that (2) adds the most overhead: invoking the dynamics for a given environment condition can be expensive and is done for each sample. Monitoring each specification to determine the $\varphi \in \Phi$ for a given $(e, \xi_{\pi^{\text{IL}}}(e))$ pair satisfies also requires evaluating the semantics of every $\varphi$ in the worst-case. 

We note that the combination of these operations contributes nontrivial, but not prohibitive, overhead in practice, and that this overhead will scale linearly with the size of $\Phi$ and exponentially with the size of $LP$. However, many parts of this overhead are also shared by other environment sampling techniques (such as our two baselines), namely in invoking an optimization-guided sampler and actuating the dynamics. More importantly, as evidenced by our experiments, we trade off the increase in computation for an increase in model performance, and therefore less required involvement of an expert model. Such improvements are critical when expert models are expensive to query, such as in human studies, which we see as a primary contribution of SGDA.

% \textbf{Upper-Confidence Bound Algorithm}