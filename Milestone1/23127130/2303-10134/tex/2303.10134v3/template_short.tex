%% 
%% Copyright 2007-2020 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with harvard style bibliographic references

\documentclass[11pt,english]{article}

%% Use the option review to obtain double line spacing
%\documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%\documentclass[final,1p,times,authoryear]{elsarticle}
%% \documentclass[final,1p,times,twocolumn,authoryear]{elsarticle}
% \documentclass[final,3p,times,authoryear]{elsarticle}
%% \documentclass[final,3p,times,twocolumn,authoryear]{elsarticle}
%% \documentclass[final,5p,times,authoryear]{elsarticle}
%% \documentclass[final,5p,times,twocolumn,authoryear]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }
\usepackage{setspace}
\doublespacing
\usepackage{amssymb}
\usepackage{custom_tex}
%\usepackage[doi=false,isbn=false,url=false,eprint=false]{natbib}
\title{Proximal Causal Inference without Uniqueness Assumptions}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

%\journal{Statistics and Probability Letters}

\begin{document}

%\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \affiliation for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \affiliation{organization={},
%%            addressline={}, 
%%            city={},
%%            postcode={}, 
%%            state={},
%%            country={}}
%% \fntext[label3]{}
\author{Jeffrey Zhang, Wei Li, Wang Miao, Eric Tchetgen Tchetgen}
\maketitle

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \affiliation[label1]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%%
%% \affiliation[label2]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}

%\author[1]{Jeffrey Zhang}
%\author[2]{Wei Li}
%\author[3]{Wang Miao}
%\author[1]{Eric Tchetgen Tchetgen}

%\affiliation[1]{organization={Department of Statistics and Data Science, The Wharton School, The University of Pennsylvania},%Department and Organization state={PA},country={U.S.A.}}
        
%\affiliation[2]{organization={Center for Applied Statistics and School of Statistics, Renmin University of China}, country={P.R.C.}}
%\affiliation[3]{organization={Department of Probability and Statistics,Peking University}, country={P.R.C.}}

\begin{abstract}
%% Text of abstract
We consider identification and inference about a counterfactual outcome mean when there is unmeasured confounding using tools from proximal causal inference (\cite{miao}, \cite{intro_proxy}). Proximal causal inference requires existence of solutions to at least one of two integral equations. We motivate the existence of solutions to the integral equations from proximal causal inference by demonstrating that, assuming  the existence of a solution to one of the integral equations, $\sqrt{n}$-estimability of a linear functional (such as its mean) of that solution requires the existence of a solution to the other integral equation. Solutions
to the integral equations may not be unique, which complicates estimation and inference. We construct a consistent estimator for the solution set for one of the integral equations and then adapt
the theory of extremum estimators to find from the estimated set a consistent estimator
for a uniquely defined solution. A debiased estimator for the counterfactual mean is shown to be root-$n$ consistent, regular, and asymptotically semiparametrically locally efficient  under additional regularity conditions.
\end{abstract}

%%Graphical abstract


%%Research highlights
%\begin{highlights}
%\item Research highlight 1
%\item Research highlight 2
%\end{highlights}

%\begin{keyword}
%Proximal Causal Inference \sep $\sqrt{n}$-estimability
%% keywords here, in the form: keyword \sep keyword

%% PACS codes here, in the form: \PACS code \sep code

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

%\end{keyword}

%\end{frontmatter}

%% \linenumbers

%% main text
\newtheorem{assumption}{Assumption}
\section{Introduction}
It is widely acknowledged that unmeasured confounding is pervasive in observational studies, as it is unlikely that an investigator will have measured all confounders of the treatment and outcome. Often, the most one can hope for is that some measured confounders can act as proxies for true, unmeasured confounders. Proximal causal inference was developed to circumvent the issue of unmeasured confounders through the use of suitable proxy variables. See \cite{miao}, \cite{intro_proxy}, \cite{selective_review}, and \cite{shi_jrssb} for a more comprehensive overview of the framework. Proximal causal inference leverages the existence of either a treatment confounding bridge function or an outcome confounding bridge function, which solve certain integral equations (\cite{miao}, \cite{semi_proxy}, \cite{deaner}, \cite{kallus}).  Then, the population average treatment effect (ATE) and the average treatment effect on the treated (ATT) are respectively uniquely identified nonparametrically as a certain linear functional of a confounding bridge function, without the latter necessarily being uniquely identified (\cite{miao}, \cite{semi_proxy}, \cite{deaner}, \cite{kallus}). However, construction of a root-$n$ consistent, regular and asymptotically linear semiparametric locally efficient estimator of the ATE or ATT in prior literature has relied exclusively on uniqueness of the bridge functions with a notable exception being the concurrent work of \cite{bennett2022}. In this note, the goal is to investigate estimation and inference of the counterfactual mean, and thus of the ATE and ATT, when uniqueness does not hold. Specifically, we construct a root-$n$ consistent, regular and asymptotically linear nonparametric estimator of the ATE without requiring uniqueness. The proposed methods build on recent de-biasing methods developed in \cite{SANTOS2011129} and \cite{nonig}. In somewhat related settings, the former considers a linear functional of the structural function in (i) the widely studied nonparametric instrumental variable problem (\cite{chen_2012}), while the latter considers (ii) a nonparametric shadow variable framework in a nonignorable missing data problem (\cite{dhaul}, \cite{miao_shadow}).
Proximal identification and inference differs from both of these settings in that the identification challenge requires the use of two proxies, while (i) and (ii) technically require a single proxy, mainly a valid instrument in (i) and a valid shadow variable in (ii). De-biasing methods have also been utilized for other purposes in causal inference, see for example \cite{auto_debias}.

An outline of the paper is as follows:
in Section \ref{identifcation}, we review identification strategies for the counterfactual mean, and thus the ATE and ATT, from previous works under the proximal framework, and describe sufficient and necessary conditions for identification and root-$n$ estimation of the ATE. In Section \ref{estimation_strat}, we develop an estimator for the counterfactual mean, and therefore for the ATE and ATT, establish the asymptotic theory,  and discuss its semiparametric efficiency.  We conclude
with a discussion in Section \ref{discussion} and include proofs in the Supplementary Material. While for ease of exposition, all results are given for the counterfactual outcome mean, they equally apply to a broader class of functionals as discussed in the Supplementary Material. 
\section{Identification}
\label{identifcation}
We wish to estimate the effect of a binary treatment $A$ on an outcome $Y$ in a setting with unmeasured confounding. Define $Y(a)$ for $a=0,1$ to be the potential outcomes of the response if treatment had been externally set to $a$. The goal is to estimate the average treatment effect, $\E[Y(1)-Y(0)]$. Let $U$ be an unmeasured confounder and $X$ a vector of observed covariates. Statistical independence is denoted by $\perp$. Instead of assuming no unmeasured confounding, we adopt the recent proximal causal inference framework wherein we require there to be a treatment confounding proxy $Z$ and an outcome confounding proxy $W$. This leads to the following assumptions as introduced by \cite{semi_proxy}:
\begin{assumption}
\label{cons}
(Consistency) $Y=AY(1)+(1-A)Y(0)$, almost surely.
\end{assumption}
\begin{assumption}
\label{lat_unc}
(Latent Unconfoundedness)  $(Z,A) \perp (Y(a),W) | U,X \text{ for } a = 0, 1.$ 
\end{assumption}
\begin{assumption}
\label{pos2}
(Positivity) $0 < \mathbb{P}(A = a|U, X) < 1$ almost surely, for $a = 0, 1$.
\end{assumption}
\begin{assumption}
\label{comp1}
(Completeness 1)
\begin{enumerate}
    \item For any $a, x$, if $\E[g(U)|Z, A = a, X = x] = 0$ almost surely, then $g(U) = 0$ almost
surely.
    \item For any $a, x$, if $\E[g(Z)|W, A = a, X = x] = 0$ almost surely, then $g(Z) = 0$ almost surely.
\end{enumerate}
\end{assumption}
There are two ways to identify the counterfactual mean $\E[Y(a)]$. The first method is as follows:
\begin{theorem}
\label{miao}
(\cite{miao}) Suppose that there exists an outcome confounding bridge
function $h(w, a, x)$ that solves the following integral equation
\begin{equation}
\label{eq:1}
    \E[Y |Z, A, X] = \int
h(w, A, X)dF(w|Z, A, X),
\end{equation}
almost surely. Then, under Assumptions \ref{cons}, \ref{lat_unc},\ref{pos2}, and \ref{comp1}(1), one has that
\begin{comment}
\begin{equation}
\label{eq:2}
\E[Y |U, A, X] = \int
h(w, A, X)dF(w|U, X)
\end{equation}
almost surely. Moreover, the counterfactual mean $\E[Y (a)]$ is nonparametrically identified by
\end{comment}
\begin{equation}
\label{eq:3}
\E[Y (a)] = \int_{\mathcal{X}}  \int h(w, a, x)dF(w|x)dF(x).
\end{equation}
\begin{comment}
and thus the average treatment effect is identified by
\begin{equation}
\label{eq:4}
\psi = \int_{\mathcal{X}}  \int
[h(w, 1, x) - h(w, 0, x)]dF(w|x)dF(x)
\end{equation}
\end{comment}
\end{theorem}

\begin{assumption}
\label{comp2}
(Completeness 2) 
\begin{enumerate}
    \item 
For any a, x, if $\E[g(U)|W, A = a, X = x] = 0$ almost surely, then $g(U) = 0 $ almost
surely.
\item For any a, x, if $\E[g(W)|Z, A = a, X = x] = 0$ almost surely, then $g(W) = 0$ almost
surely.
\end{enumerate}
\end{assumption}
Using the second completeness assumption provides an alternative identification scheme:
\begin{theorem}
\label{cui}
(\cite{semi_proxy}) Suppose that there exists a treatment confounding bridge function $q(z, a, x)$
that solves the integral equation
\begin{equation}
\label{eq:5}
    \E[q(Z, a, X)|W, A = a, X] = \frac{1}{\mathbb{P}(A = a|W, X)}.
\end{equation}
Then, under Assumptions \ref{cons}, \ref{lat_unc}, \ref{pos2}, and \ref{comp2}(1), one has
\begin{comment}
\begin{equation}
\label{eq:6}
    \int q(z, a, X)dF(z|U, A = a, X) = \frac{1}{\mathbb{P}(A = a|U, X)}
\end{equation}
almost surely. Moreover, $\E[Y (a)]$ is nonparametrically identified by
    
\end{comment}
\begin{equation}
\label{eq:7}
\E[Y (a)] = \int_{\mathcal{X}} \int
I(\tilde{a} = a)q(z, a, x)ydF(y, z, \tilde{a}|x)dF(x).
\end{equation}
\begin{comment}
Therefore, the average treatment effect is identified by
\begin{equation}
\label{eq:8}
    \psi = \int_{\mathcal{X}}  \int
(-1)^{1-a}
q(z, a, x)ydF(y, z, a|x)dF(x)
\end{equation}
\end{comment}
\end{theorem}
Only existence of an outcome confounding bridge function $h$ or treatment confounding bridge function $q$ is required for identification of the ATE; they need not be unique. Suppose that one has observed $n$ i.i.d. data samples consisting of variables  $(A,Z,X,W,Y)$. Let $L_2(Y,W,Z,A,X)$ denote the space of real valued functions of $(Y,W,Z,A,X)$ that are square integrable with respect to the distribution of $(Y,W,Z,A,X)$ and use the inner product $ \langle f_1,f_2\rangle:=\E[f_1f_2]$. For any bounded linear map $T$, define $\mathcal{D}(T), \mathcal{R}(T), \mathcal{N}(T), T'$ to be the domain, range, null space, and adjoint of $T$. Let $T^{\perp}$ be the orthocomplement of a set $T$. Let the suffix $o$ denote relationship to the outcome confounding bridge function and let the suffix $tr$ denote relationship to the treatment confounding bridge function. Accordingly, define $T_o:L_2(W,A,X) \to L_2(Z,A,X)$ where $T_o g(W,A,X)=\E[g(W,A,X)|Z,A,X]$. Let $T_{tr}:L_2(Z,A,X) \to L_2(W,A,X)$ where $T_{tr} g(Z,A,X)=\E[g(Z,A,X)|W,A,X]$.
Before proceeding with inference, we provide a purely statistical motivation for the integral equations \ref{eq:1} and \ref{eq:5}. The following requires no reference to an unmeasured confounder $U$ or the causal structure.
Consider the following two scenarios:
\begin{enumerate}
    \item Suppose (\ref{eq:1}) holds, i.e. there exists a function $h \in L_2(W,A,X)$ such that $\E[Y|Z,A,X]=\E[h(W,A,X)|Z,A,X]$.
    \item Suppose (\ref{eq:5}) holds, i.e. there exists a function $q \in L_2(Z,A,X)$ such that $\frac{1}{\mathbb{P}(A|W,X)}=\E[q(Z,A,X)|W,A,X]$.
\end{enumerate}
Under the first scenario, consider the problem of estimating a functional of the following form:
\begin{equation}
\label{wfunctional}
    \beta_o=\E[\phi_o(W,A,X)h(W,A,X)],
\end{equation}
where $\phi_o$ is a known function in $L_2(W,A,X)$.
  Then we have the following:
\begin{proposition}
\label{id1}
Under the assumption that \ref{eq:1} holds, 
$\beta_o$ is identified iff $\phi_o \in \mathcal{N}(T_o)^{\perp}$. 
\end{proposition}
\begin{proof}
First, suppose $\beta_o$ is identified. Consider $h_1$, $h_2$ that satisfy Equation $\ref{eq:1}$. Note that this implies that $h_1-h_2 \in \mathcal{N}(T_o)$. Since $\beta_o$ is identified, both $h_1$ and $h_2$ yield the same value of $\beta_o$. Thus, we have that 
$0=\E[\phi_o(W,A,X)(h_1-h_2)]$
and so $\phi_o(W,A,X) \in \mathcal{N}(T_o)^{\perp}$ since $h_1-h_2$ is an arbitrary element of $\mathcal{N}(T_o)$. Conversely, suppose $\phi_o(W,A,X) \in \mathcal{N}(T_o)^{\perp}$. Then for any $h_1$ and $h_2$ that satisfy Equation \ref{eq:1}, we have $h_1-h_2 \in \mathcal{N}(T_o)$ and so $\E[\phi_o(W,A,X)h_1]=\E[\phi_o(W,A,X)h_2]$ and so $\beta_o$ is identified.
\end{proof}
Note that $\mathcal{N}(T_o)^{\perp}=\text{cl}(\mathcal{R}(T_o'))$. However, the following Lemma establishes that $\phi_o(W,X) \in \mathcal{R}(T_o')$ is necessary for $\beta_o$ to be $\sqrt{n}$ estimable.
\begin{lemma}
\label{rootnh}
Assuming equation \ref{eq:1} holds and regularity condition \ref{regularityh} in the appendix, $\phi_o(W,X) \in \mathcal{R}(T_o')$ is necessary for $\beta_o$ to be $\sqrt{n}$ estimable.
\end{lemma}
This result is analogous to a result derived in \cite{SEVERINI2012491} in the non-parametric instrumental variables context.
Next, note that
\begin{align*}
    \E[h(W,a,X)]  &= \E[\E[h(W,a,X)|W,X]] \\ &= \E[\E[h(W,a,X)I(A=a)/\mathbb{P}(A=a|W,X)|W,X]] \\  &= \E[h(W,A,X)/\mathbb{P}(A=a|W,X)I(A=a)]
\end{align*}
which is in the form of equation \ref{wfunctional} with  $\phi_o(W,A,X)=I(A=a)/\mathbb{P}(A=a|W,X)$ which for current purposes  may be assumed known.  Lemma \ref{rootnh} thus implies that for $\E[h(W,a,X)]$ to be $\sqrt{n}$ estimable, there must be a function $q(Z,A,X)$ that satisfies
\begin{equation*}
    \E[q(Z,A,X)|W,A,X]=I(A=a)/\mathbb{P}(A=a|W,X).
\end{equation*}
This corresponds to the condition from Equation \ref{eq:5}. 
Likewise, consider the problem of estimating a functional of the following form:
\begin{equation}
\label{zfunctional}
\beta_{tr}=\E[\phi_{tr}(Z,A,X)q(Z,A,X)],
\end{equation}
where $\phi_{tr}$ is a known function in $L_2(Z,A,X)$. Analogous to Proposition \ref{id1}, we have the following:
\begin{proposition}
\label{id2}
Under the assumption that \ref{eq:5} holds, $\beta_{tr}$ is identified iff $\phi_{tr} \in \mathcal{N} (T_{tr})^{\perp}$.
\end{proposition}
\begin{proof}
Note that for any $q_1$ and $q_2$ that satisfy \ref{eq:5}, we must have $q_1-q_2 \in \mathcal{N}(T_{tr})$. Then the argument follows in the exact same manner as in Proposition \ref{id1}.
\end{proof}
As above, it is possible to establish that $\phi_{tr} \in \mathcal{R}(T_{tr}')$ is necessary for $\beta_{tr}$ to be $\sqrt{n}$ estimable.
\begin{lemma}
\label{rootnq}
Assuming equation \ref{eq:5} holds and regularity condition \ref{regularityq} in the appendix, $\phi_o(W,X) \in \mathcal{R}(T_o')$ is necessary for $\beta_o$ to be $\sqrt{n}$ estimable.
\end{lemma}
Next, observe that from Equation \ref{eq:7}, we have 
\begin{align*}
    \E[I(A=a)q(Z,a,X)Y]  &= \E[\E[I(A=a)q(Z,a,X)Y|Z,A,X]] \\ &= \E[I(A=a)q(Z,a,X)\E[Y|Z,A,X]]
    \\ &= \E[I(A=a)q(Z,A,X)\E[Y|Z,A,X]]
\end{align*}
which is in the form of equation \ref{zfunctional} with $\phi_{tr}(Z,A,X)=I(A=a)\E[Y|Z,A,X]$ which for current purposes  may be assumed known.  Lemma \ref{rootnq} thus implies that for $\E[I(A=a)q(Z,A,X)Y]$ to be $\sqrt{n}$ estimable, there must be a function $h(W,A,X)$ such that
\begin{equation*}
    \E[h(W,A,X)|Z,A,X]=I(A=a)\E[Y|Z,A,X].
\end{equation*}
This corresponds to the condition from Equation \ref{eq:1}. We may conclude that taking as a primitive condition that a solution to Equation \ref{eq:1} exists everywhere in the model, i.e. at all laws included in the semiparametric model, identification and root-n estimation of the counterfactual outcome mean necessarily implies that a solution to \ref{eq:5} exists at the true data generating law. On the other hand, taking as a primitive condition that a solution to Equation \ref{eq:5} exists at all laws of the semiparametric model, identification and root-n estimation of the counterfactual outcome mean necessarily implies that a solution to \ref{eq:1} exists at the true data generating law. 

The present setting differs from the shadow variable missing data setting studied in \cite{nonig} in ways worth discussing. In the current setting, we aim to account for the presence of an unmeasured confounder $U$ and the key assumption \ref{lat_unc} to identification involves this latent variable together with two fully observed auxiliary factors in the form of a pair of proxies $Z$ and $W$, each of which plays a specific role. In contrast, identification in a shadow variable setting does not require invoking a latent factor, and  requires only a single fully observed auxiliary variable which satisfies a certain conditional independence condition (\cite{nonig}). Despite these differences, our paper demonstrates that the analytic framework of \cite{nonig} readily extends to the proximal causal inference setting. We further establish in the Supplementary Material that the approach actually applies to a general class of doubly robust functionals studied by \cite{ghassami}, for which a pair of nuisance functions are defined as solutions to Fredholm integral equations. The above propositions give formal justification that certain Fredholm integral equations must admit a solution in order for a regular estimator of functionals in this class to exist. In the next section, we describe an estimation strategy for the counterfactual mean without the assumption of a unique $h$ or $q$ that solve the integral equations. 

\section{Estimation Strategy}
\label{estimation_strat}
We follow estimation strategies from \cite{SANTOS2011129} and \cite{nonig}. Based on the above discussion, it is sensible to construct solution sets for either of the Fredholm integral equations from equation \ref{eq:1} and \ref{eq:5}. Without loss of generality, we consider estimating the solution set of equation \ref{eq:1}. First, let $\mathcal{H}$ be a set of smooth functions. Define the solution sets of the Fredholm integral equations as follows:
\begin{equation}
    \mathcal{H}_0 = \{h \in \mathcal{H} : \E[h(W,A,X)|Z,A,X]=\E[Y|Z,A,X]\}.
\end{equation}
Under the assumptions from Theorem \ref{miao}, $\E[h(W,a,X)]$ has a causal interpretation as the counterfactual mean $\E[Y(a)]$. Under these assumptions, to estimate $\mu_a:=\E[Y(a)]$, we first construct a consistent estimator $\wh{\mathcal{H}}_0$ for the set $\mathcal{H}_0$; next, we choose a specific $\wh{h}_0 \in \wh{\mathcal{H}}_0$ so that it is a consistent estimator for a fixed element $h_0 \in \mathcal{H}_0$. 
\subsection{Estimation of solution sets}
Define the criterion function
\begin{align*}
    C(h)&=\E[\{\E[Y-h(W,A,X)|Z,A,X]^2\}].
\end{align*}
In practice, the estimation of the solution set can be done in the two arms separately, for example, by taking the criterion function $C(h)=\E[I(A=a)\E[(Y-h(W,a,X))|Z,A=a,X]^2] $. Note that 
$\mathcal{H}_0=\{h \in \mathcal{H} : C(h)=0\},$
i.e., the solution set of the Fredholm integral equation consists of the zeros of the criterion function. To proceed with estimation, we adopt a two-stage approach. We aim to construct sample analogues $C_n$ of the criterion function $C$. We let $\mathcal{H}_n$ be sieve for $\hh$. Specifically, for a known sequence of approximating functions $\{\psi_m(w,a,x)\}_{m=1}^\infty$, let 
\begin{equation}
\begin{aligned}
    \mathcal{H}_n&=\left\{h \in \hh : h(w,a,x) = \sum_{m=1}^{m_n}\beta_m \psi_m(w,a,x)\right\},
\end{aligned}
\end{equation}
for $\beta,h$ unknown and $m_n$ known.
To construct $C_n$, we require a nonparametric estimator of conditional expectations. For this, let $\{\phi_k(z,a,x)\}_{k=1}^\infty$ be a known sequence of approximating functions. Denote
\begin{equation*}
\begin{aligned}
    \mathbf{\phi}(z,a,x)=\{\phi_1(z,a,x),\ldots,\phi_{k_n}(z,a,x)\}^T, \\
    \mathbf{\Phi}=\{\mathbf{\phi}(Z_1,A_1,X_1),\ldots,\mathbf{\phi}(Z_n,A_n,X_n)\}^T.
\end{aligned}
\end{equation*}

For a generic random variable $B=B(W,A,X,Y,)$ with realizations $\{B_i=B(W_i,A_i,X_i,Y_i)_{i=1}^n\}$ the nonparametric sieve estimator of $\E[B|a,z,x]$ is 
\begin{equation}
    \wh{\E}(B|A,Z,X)=\mathbf{\phi}(Z,A,X)(\mathbf{\Phi}^T\mathbf{\Phi})^{-1}\sum_{i=1}^n \mathbf{\phi(Z_i,A_i,X_i)}B_i.
\end{equation}
The sample analogue $C_n(h)$ is then
\begin{equation}
    C_n(h)=\frac{1}{n}\sum_{i=1}^n\wh{e}^2(Z_i,A_i,X_i,h),
\text{ where }
    \wh{e}(Z_i,A_i,X_i,h)=\wh{\E}[Y-h(W,A,X)|A_i,Z_i,X_i].
\end{equation}
Then the proposed estimator of $\hh_0$ is $\wh{\hh}_0=\{h \in \hh_n: C_n(h)\leq c_n \}$
where $c_n$ is an appropriately chosen sequence that tends to 0. 
\subsection{Set consistency}
In this section, we establish the set consistency of $\wh{\mathcal{H}}_0$ for $\mathcal{H}_0$ under Hausdorff distances. For this, define the Hausdorff distance between two sets $\hh_1,\hh_2 \subset \hh$ as 
\begin{equation*}
    d_H(\hh_1,\hh_2, ||\cdot||)=\text{max}\{d(\hh_1,\hh_2),d(\hh_2,\hh_1)\},
\end{equation*}
where $d(\hh_1,\hh_2)=\text{sup}_{h_1 \in \hh_1}\inf_{h_2 \in \hh_2}||h_1-h_2||$ and $||\cdot|| $ is a given norm. Consider the following two norms:
\begin{align*}
    ||h||_w^2&=\E[\{\E[h(W,A,X)|Z,A,X]\}^2], \ ||h||_\infty^2=\sup_{w,a,x}|h(w,a,x)|.
\end{align*}
We say that a set of estimators $\widehat{K}$ is said to be \emph{consistent} for a set $K$ if $d_H(\widehat{K}, K,\|\cdot\|) \rightarrow_p 0.$
Next, notice that any $h,h_0 \in \hh_0$ satisfy \ref{eq:1}, so it holds that for any $\wh{h}_0 \in \wh{\hh}_0$ and any $h, h_0 \in \hh_0$, $||\wh{h}_0-h_0||_w=||\wh{h}_0-h||_w$ and so 
\begin{equation}
    ||\wh{h}_0-h_0||_w=\inf_{h \in \hh_0}||\wh{h}_0-h||_w \leq d_H(\wh{\hh}_0,\hh_0,||\cdot||_w).
\end{equation}
Thus, we can calculate the convergence rate of $||\wh{h}_0-h_0||_w$ by finding the convergence rate of $d_H(\wh{\hh}_0,\hh_0,||\cdot||_w)$. We will need to consistently estimate $\hh_0$ under the supremum norm because under the $||\cdot||_w$ norm, elements of $\hh_0$ form an equivalence class. We will require several assumptions.
\begin{assumption}
\label{compact} 
%(Analogous to Assumption 3 from \cite{nonig})
The vector of covariates $X \in \RR^d$ has support $[0,1]^d$, and outcome $Y \in \mathbb{R}$ and proxies $Z,W \in \RR$ have compact support.
\end{assumption}
\begin{definition}
For a generic function $\rho(\omega)$ defined on $\omega \in \R^d$ we define
\begin{equation*}
    \|\rho\|_{\infty, \alpha}=\max _{|\lambda| \leq \underline{\alpha}} \sup _{w}\left|D^{\lambda} \rho(w)\right|+\max _{\lambda=\underline{\alpha}} \sup _{w \neq w^{\prime}} \frac{D^{\lambda} \rho(w)-D^{\lambda} \rho\left(w^{\prime}\right)}{\left\|w-w^{\prime}\right\|^{\alpha-\underline{\alpha}}},
\end{equation*}
where $\lambda$ is a $d$-dimensional vector of nonegative integers, $|\lambda|=\sum_{i=1}^d \lambda_i$, $\underline{\alpha}$ denotes the
largest integer smaller than $\alpha$, $D^{\lambda} \rho(\omega)=\partial^{|\lambda|}\rho(\omega)/\partial \omega_1^{\lambda_1}\ldots \partial \omega_d^{\lambda_d}$, and $D^{0}\rho(\omega)=\rho(\omega)$.
\end{definition}
\begin{assumption}
\label{H_approx}
%(Analogous to Assumption 4 from \cite{nonig})
The following conditions hold:
\begin{enumerate}[(i)]
    \item $\sup_{h \in \hh} ||h||_{\infty,\alpha} < \infty$ for some $\alpha > (d+1)/2$; $\hh_0 \neq \emptyset$, $\hh_n$ and $\hh$ are closed.
    \item for every $h \in \hh$, there is a $\Pi_n h \in \hh_n$ such that $\sup_{h \in \hh}||h-\Pi_n h||_{\infty} = O(\eta_n)$ for some $\eta_n=o(1)$.
\end{enumerate}
\end{assumption}
\begin{assumption}
\label{Phi_approx}
%(Analogous to Assumption 5 from \cite{nonig})
The following conditions hold:
\begin{enumerate}[(i)]
\item The smallest and largest eigenvalues of $\E[\phi(Z,A,X)\phi(Z,A,X)^T]$ are bounded above and away from zero for all $k_n$.
\item for every $h \in \hh$, there is a $\mathbf{\pi}_n(h) \in \RR^{k_n}$ such that \\$\sup_{h\in\hh} ||\E[h(W,A,X)|a,z,x]-\phi^T(z,a,x)\mathbf{\pi}_n(h)||_{\infty}=O\left(k_n^{-\frac{\alpha}{d+1}}\right).$
\item $\xi_n^2k_n=o(n)$, where $\xi_n=\sup_{z,a,x}||\phi(z,a,x)||_2$.
\end{enumerate}
\end{assumption}
Then we have the following proposition:
\begin{proposition}
\label{prop:2.1}
%(Analogous to Theorem 3.2 from \cite{nonig})
Suppose that Assumptions \ref{compact}-\ref{Phi_approx} hold. If $a_n=O\lambda_n^{-1}$, $b_n \to \infty$, and $b_n=o(a_n)$, then
$$d_H(\wh{\hh}_0,\hh_0,\Norm{\cdot}_\infty)=o_p(1) \text{ and } d_H(\wh{\hh}_0,\hh_0,\Norm{\cdot}_w)=O_p(c_n^{1/2}).$$
\end{proposition}
After obtaining a consistent estimator $\wh{\hh}_0$ of $\hh_0$, we select a specific estimator from $\wh{\hh}_0$ such that it converges to a unique element in $\hh_0$. 
\subsection{A representer-based estimator}
To do so, we let $M:\hh\to \R$ be a population criterion function that attains a unique minimum $h_0$ on $\hh_0$ and $M_n(h)$ its sample analogue. We then select
\begin{equation}
\label{eq:15}
    \wh{h}_0\in \argmin_{h \in \wh{\hh}_0}M_n(h).
\end{equation}
We make the following assumption about $M$:
\begin{assumption}
\label{M}
%(Analogous to Assumption 6 from \cite{nonig})
The function set $\hh$ is convex; the functional $M:\hh \to \R$ is strictly convex and attains a unique minimum at $h_0$ on $\hh_0$; its sample analogue $M_n: \hh \to \R$ is continuous and $\sup_{h\in \hh}|M_n(h)-M(h)|=o_p(1)$. 
\end{assumption}
A sensible choice for $M$ is the squared length $M(h)=\E[h(W,A,X)^2]$
 with corresponding sample analog $M_n(h)=\frac{1}{n}\sum_{i=1}^n h(W_i,A_i,X_i)^2$.

\begin{proposition}
\label{prop:2.2}
%(Analogous to Theorem 3.3 from \cite{nonig})
Suppose that assumptions \ref{compact}-\ref{M} hold. Then $\Norm{\wh{h}_0-h_0}_\infty=o_p(1),$
where $\wh{h}_0$ is defined in equation \ref{eq:15}. If $a_n=O(\lambda_n^{-1})$, $b_n\to \infty$ and $b_n=o(a_n)$, we then have 
$\Norm{\wh{h}_0-h_0}_w=O_p(C_n^{1/2}).$
\end{proposition}
Based on the identification $\mu_a=\E[Y(a)]=\E[h_0(W,a,X)]$, we propose the following estimator for $\mu_a$:
\begin{equation}
    \wh{\mu}_a=\frac{1}{n}\sum_{i=1}^n\cb{\wh{h}_0(W_i,a,X_i)}.
\end{equation}
To facilitate analysis of the asymptotic properties of the estimator, let $\overline{\hh}$ be the closure of the linear span of $\hh$ under $\Norm{\cdot}_w$, and define
\begin{equation*}
    \la h_1,h_2 \ra_w=\E\sqb{I(A=a)\E\{h_1(W,A,X)|A,Z,X\}\E\{h_2(W,A,X)|A,Z,X\}}.
\end{equation*}
Next, we require the following:
\begin{assumption}
\label{rep}
%(Analogous to Assumption 7 from \cite{nonig})
The following conditions hold:
\begin{enumerate}[(i)]
    \item there exists a function $g_0 \in \hh$ such that
    $\la g_0, h \ra_w=\E\{h(W,a,X)\},$ for all $h \in \overline{\hh}$.
    \item $\eta_n=o(n^{-1/3}), k_n^{-3\alpha/(d+1)}=o(n^{-1}), k_n^3=o(n), \xi_n^2k_n^2=o(n)$, and $\xi_n^2k_n^{-2\alpha/(d+1)}=o(1)$.
\end{enumerate}
\end{assumption}
Observe that any $g_0$ that satisfies Assumption \ref{rep}(i) satisfies the following for all $h \in \overline{\hh}$:
\begin{equation}
\label{eq:ass_rep_imp}
    \E\sqb{I(A=a)\E\{g_0(W,A,X)|A,Z,X\}h(W,A,X)} = \E[I(A=a)/\mathbb{P}(A=a\mid W,X)h(W,A,X)].
\end{equation}
Then suppose that $\E\sqb{I(A=a)\E\{g_0(W,A,X)|A,Z,X\}-I(A=a)/\mathbb{P}(A=a\mid W,X)\mid W,A,X} \in \overline{\hh}.$ Using \ref{eq:ass_rep_imp}, this implies that 
\begin{equation}
\label{repisaq}
    \E[\{g_0(W,A,X)|A,Z,X\}-1/\mathbb{P}(A=a\mid W,X)\mid W,A,X]=0.
\end{equation}
In other words, $\E[\{g_0(W,A,X)|A,Z,X\}]$ solves the integral equation from \ref{eq:5}. Thus, Assumption \ref{rep}(i) can be viewed as a strengthening of the assumption that there exists a function $q(Z,A,X)$ that solves Equation \ref{eq:5}.
As in \cite{SANTOS2011129}, the $g_0$ function will be unique up to equivalence class. In the Supplementary Material, we present a theorem characterizing the asymptotic expansion of $\wh{\mu}_a$, which includes the non-negligible term $r_n(\wh{h}_0)$ defined below: 
\begin{equation}
r_n(\wh{h}_0)=\frac{1}{n}\sum_{i=1}^n  I(A_i=a)\wh{\E}\{\Pi_n g_0(W,A,X)|A_i,Z_i,X_i\}\wh{e}(Z_i,A_i,X_i,\wh{h}_0).
\end{equation}

\begin{comment}
Observe that a sufficient condition for Assumption \ref{rep}(i) to hold is 
\begin{equation}
\label{eq:17}
    \E\{g_0(W,A,X)|A,Z,X\}=I(A=a)q(Z,A,X)
\end{equation}
for \emph{some} $q(Z,A,X)$ that satisfies the equation $\E[q(Z,A,X)|W,A,X]=\frac{1}{P(A=a|W,X)}$. To see this, note that if \ref{eq:17} holds,
\begin{equation*}
\begin{aligned}
    \la g_0, h\ra_w&= \E\sqb{\E\{g_0(W,A,X)|A,Z,X\}\E\{h(W,A,X)|A,Z,X\}} \\ &=\E\sqb{I(A=a)q(Z,A,X)\E\{h(W,A,X)|A,Z,X\}} \\ &= \E\sqb{\E\{I(A=a)q(Z,A,X)h(W,A,X)|A,Z,X\}} \\ &=\E[I(A=a)q(Z,A,X)h(W,A,X)] \\ &= \E\sqb{\E[I(A=a)q(Z,A,X)h(W,A,X)|A,W,X]} \\ &= \E[I(A=a)/P(A=a|W,X)h(W,A,X)]\\ &= \E[h(W,a,X)]
\end{aligned}
\end{equation*}
\end{comment}


\begin{comment}
\begin{theorem}
\label{thm:2.3}
%(Analogous to Theorem 3.4 from \cite{nonig})
Suppose that assumptions \ref{compact}-\ref{rep} hold. Then we have that 
\begin{equation*}
\begin{aligned}
    \sqrt{n}(\wh{\mu}_a-\mu_a)&=\frac{1}{\sqrt{n}}\sum_{i=1}^n\sqb{h_0(W_i,a,X_i)-\mu_a+I(A_i=a)\E\{g_0(W,A,X)|A_i,Z_i,X_i\}\times(Y_i-h_0(W_i,A_i,X_i))}\\&-\sqrt{n}r_n(\wh{h}_0)+o_p(1),
    \end{aligned}
\end{equation*}
where 
\begin{equation}
r_n(\wh{h}_0)=\frac{1}{n}\sum_{i=1}^n  I(A_i=a)\wh{\E}\{\Pi_n g_0(W,A,X)|A_i,Z_i,X_i\}\wh{e}(Z_i,A_i,X_i,\wh{h}_0).
\end{equation}
\end{theorem}  
\end{comment}

\subsection{A de-biased estimator}
To get an asymptotically normal estimator, we will de-bias the estimator $\wh{\mu}_a$, which requires estimation of $r_n(\wh{h}_0)$. First, we define a new criterion function $R(h)$ and its sample analog $R_n(h)$:
\begin{equation*}
\begin{aligned}
    &R(h)=\E\sqb{I(A=a)\E\{h(W,A,X)|Z,A,X\}^2}-2\E\{h(W,a,X)\} \ , \forall h \in \hh, \\
    &R_n(h)=\frac{1}{n}\sum_{i=1}^nI(A_i=a)\wh{\E}\{h(W,A,X)|Z_i,A_i,X_i\}^2-\frac{2}{n}\sum_{i=1}^n h(W_i,a,X_i) \ , \forall h \in \hh.
\end{aligned}
\end{equation*}
Since $\la g_0, h \ra_w=\E\{h(W,a,X)\}$, we have that $R(h)=\Norm{h-g_0}^2_w-\Norm{g_0}_w^2$. It follows that $g_0$ is the unique minimizer of the mapping $h \to R(h)$. Then since $g_0$ is close to $\Pi_n g_0$ by assumption \ref{H_approx}(ii), we can estimate the term $\Pi_n g_0$ by 
\begin{equation}
    \wh{g} \in \argmin_{h \in \hh_n } R_n(h).
\end{equation}
With this estimate, we can construct the following estimator for $r_n(\wh{h}_0)$:
\begin{equation}
    \wh{r}_n(\wh{h}_0)=\frac{1}{n}\sum_{i=1}^n  I(A_i=a)\wh{\E}\{\wh{g}(W,A,X)|A_i,Z_i,X_i\}\wh{e}(Z_i,A_i,X_i,\wh{h}_0).
\end{equation}
Next, we have a lemma characterizing the convergence of $\wh{r}_n(\wh{h}_0)$ to $r_n(\wh{h}_0)$.
\begin{lemma}
\label{lem:2.4}
%(Analogous to Lemma 3.5 from \cite{nonig})
Suppose that assumptions \ref{compact}-\ref{Phi_approx} and \ref{rep} hold. Then 
\begin{equation*}
    \sup_{\wh{h}_0\in \wh{\hh}_0} \left|\widehat{r}_{n}\left(\widehat{h}_{0}\right)-r_{n}\left(\widehat{h}_{0}\right)\right|=O_{p}\left[c_{n}^{1 / 2}\left\{\left(\frac{k_{n}}{n}\right)^{1 / 4}+k_{n}^{-\frac{\alpha}{2(d+1)}}\right\}\right].
\end{equation*}
\end{lemma}
Using this lemma, we can construct the de-biased estimator $\wh{\mu}_{a-db}=\wh{\mu}_{a}+\wh{r}_n(\wh{h}_0)$.

\begin{theorem}
\label{thm:2.5}
%(Analogous to Theorem 3.6 in \cite{nonig})
Suppose assumptions \ref{compact}-\ref{rep} hold. If $a_n = O(\lambda_n^{-1})$, $b_n \to \infty$ and
$n^{2/3}b_n = o(a_n)$, then $\sqrt{n}(\wh{\mu}_{a-db} -\mu_a)$ converges in distribution to $N(0, \sigma^2)$, where $\sigma^2$
is
the variance of 
\begin{equation}
\label{eq:22}
h_0(W,a,X)-\mu_a+I(A=a)\E\{g_0(W,A,X)|Z,A,X\}\times(Y-h_0(W,A,X)).
\end{equation}
\begin{comment}
Moreover, a consistent estimator for the variance $\sigma^2$ is given by 
\begin{equation*}
\begin{aligned}
    &\frac{1}{n}\sum_{i=1}^n \sqb{ \wh{h}_0^2(W_i,a,X_i)-\cb{\frac{1}{n}\sum_{i=1}^n\wh{h}_0(W_i,a,X_i)}^2+ I(A_i=a)\{\wh{\E}(\wh{g}(W,X)|Z_i,A=a,X_i\}^2\{Y_i-\widehat{h}_0(W_i,a,X_i)\}^2}\\&+2
\end{aligned}
\end{equation*}
\end{comment}
\end{theorem}
Equation \ref{eq:22} is the influence function for the de-biased estimator $\wh{\mu}_{a-db}$.
 We present an immediate corollary of \ref{thm:2.5} regarding local efficiency of this estimator in the Supplementary Material. 
\section{Discussion}
Using the proximal causal inference framework, we have established an estimator for the counterfactual mean under unmeasured confounding. We have shown it is consistent and presented conditions for when it is asymptotically normal.  Note that if interest is in the average causal effect, $\E[Y(1)-Y(0)]$, the proposed methodology can be adapted by slightly adjusting \ref{rep}(i). 
\label{discussion}

\section*{Acknowledgements}
J. Zhang was supported by NIH grant 5R01HD101415-02. W. Li's research was supported by the National Natural Science Foundation of China (NSFC 12101607), the Fundamental Research Funds for the Central Universities
and the Research Funds of Renmin University of China. E. Tchetgen Tchetgen (PI) was supported by NIH Grants: R01AI27271, R01CA222147, R01AG065276, R01GM139926.
\appendix

\section{Regularity conditions}
\begin{assumption}
\label{regularityh}
Let $h^*(W,A,X)=P_{\mathcal{N}(T_o)^{\perp}}h(W,A,X)$.
\begin{enumerate}[(i)]
    \item Denote $\Psi_o(z,a,x)=\E[(Y-h^*(W,A,X))^2|Z=z,A=a,X=x]$. Suppose $0 < \inf_{z,a,x} \Psi_o(z,a,x) < \sup_{z,a,x} \Psi_o(z,a,x) < \infty$.
    \item $T_o'$ is compact.
\end{enumerate}

\end{assumption}
\begin{assumption}
\label{regularityq} Let $q^*(Z,A,X)=P_{\mathcal{N}(T_{tr})^{\perp}}q(Z,A,X)$.
\begin{enumerate}[(i)]
    \item Denote $\Psi_{tr}(w,a,x)=\E[(q^*(Z,A,X))^2|W=w,A=a,X=x]$. Suppose $0 < \inf_{w,a,x} \Psi_{tr}(w,a,x) < \sup_{w,a,x} \Psi_{tr}(w,a,x) < \infty$.
    \item $T_{tr}'$ is compact.
\end{enumerate}

\end{assumption}

\begin{comment}
\section{Discussion on Efficiency}
Let $\mathcal{M}$ be the model which places no restriction on the observed data distribution other than existence (but not necessarily uniqueness)
of a bridge function h that solves Equation \ref{eq:1} at all regular laws. We do not compute the semiparametric efficiency bound under this model. Within this model, \cite{semi_proxy} consider the submodel in which the following also hold:
\begin{enumerate}[(a)]
    \item The maps $T_o$ and $T_o'$ are surjective.
    \item Equation \ref{eq:5} holds at the true data generating law.
    \item The $h$ and $q$ that solve \ref{eq:1} and \ref{eq:5} are unique.
\end{enumerate}
They derive that the efficient influence function for the counterfactual mean under the full model $\mathcal{M}$ evaluated at the submodel where a - c hold is $h(W,a,X)-\mu_a+I(A=a)q(Z,a,X)\times(Y-h(W,a,X))$. Thus,
we get the following corollary of Theorem \ref{thm:2.5}:
\begin{corollary}
\label{cor:2.6}
Suppose that assumptions \ref{cons},\ref{lat_unc}-\ref{comp2} and equation \ref{repisaq} in this manuscript hold. The influence function \ref{eq:22} of the debiased estimator equals the efficient influence function of $\mu_a$ under model $\mathcal{M}$ if a - c also hold at the true data generating law. Thus, the debiased estimator is locally efficient.
\end{corollary}
Importantly, we do not assume a - c for our estimator to be regular and asymptotically linear, nor do we assume a - c hold for all laws in \mathcal{M} for local efficiency, only that they hold at the true data generating law. For more details about local efficiency, we refer the reader to \cite{Bickel1993EfficientAA}. A useful illustration of local efficiency is that of the ordinary least squares estimator. Let $(Y_i,X_i) \sim_{iid} F$ for $F$ unknown. Consider the linear model that only a priori assumes that $E(Y|X)=\beta'X$, but allows the distribution of $Y|X$ to otherwise be unspecified. Then the OLS estimator is regular and asymptotically linear at all laws of the linear model, but also attains the semiparametric efficiency bound for the linear model at the submodel where Var$(Y|X)$ does not depend on $X$, i.e. when the errors are homescedastic. Thus, the least squares estimator is locally efficient. Analogously, our estimator is regular and asymptotically linear at all laws in $\mathcal{M}$, but also attains the semiparametric efficiency bound at the submodel introduced in \cite{semi_proxy}. 
\end{comment}

%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
%% \appendix

%% \section{}
%% \label{}

%% If you have bibdatabase file and want bibtex to generate the
%% bibitems, please use
%%
%%  \bibliographystyle{elsarticle-harv} 
%%  \bibliography{<your bibdatabase>}

%% else use the following coding to input the bibitems directly in the
%% TeX file.

\bibliographystyle{plainnat}
\bibliography{template_short}


%\begin{thebibliography}{00}

%% \bibitem[Author(year)]{label}
%% Text of bibliographic item

%\bibitem[ ()]{}

%\end{thebibliography}
\end{document}

\endinput
%%
%% End of file `elsarticle-template-harv.tex'.
