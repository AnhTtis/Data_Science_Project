% sage_latex_guidelines.tex V1.20, 14 January 2017

\documentclass[Royal,sagev,times]{sagej}

\usepackage{moreverb,url}
\usepackage{amsthm}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{caption}
\usepackage{subcaption}

\usepackage[colorlinks,bookmarksopen,bookmarksnumbered,citecolor=red,urlcolor=red]{hyperref}

\newcommand\BibTeX{{\rmfamily B\kern-.05em \textsc{i\kern-.025em b}\kern-.08em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\def\volumeyear{2022}

\begin{document}

\runninghead{Watson, Girling, Hemming, and Lilford}

\title{Optimal Study Designs for Cluster Randomised Trials: An Overview of Methods and Results}

\author{Samuel I. Watson\affilnum{1}, Alan Girling\affilnum{1}, Karla Hemming\affilnum{1}}

\affiliation{\affilnum{1}University of Birmingham, Birmingham, UK} %\\
%\affilnum{2}SAGE Publications Ltd, UK}

\corrauth{Samuel I. Watson, Institute for Applied Health Research,
University of Birmingham,
Birmingham,
B152TT, UK.}

\email{s.i.watson@bham.ac.uk}

\begin{abstract}
There are multiple cluster randomised trial designs that vary in when the clusters cross between control and intervention states, when observations are made within clusters, and how many observations are made at that time point. Identifying the most efficient study design is complex though, owing to the correlation between observations within clusters and over time. In this article, we present a review of statistical and computational methods for identifying optimal cluster randomised trial designs. We also adapt methods from the experimental design literature for experimental designs with correlated observations to the cluster trial context. We identify three broad classes of methods: using exact formulae for the treatment effect estimator variance for specific models to derive algorithms or weights for cluster sequences; generalised methods for estimating weights for experimental units; and, combinatorial optimisation algorithms to select an optimal subset of experimental units. We also discuss methods for rounding weights to whole numbers of clusters and extensions to non-Gaussian models. We present results from multiple cluster trial examples that compare the different methods, including problems involving determining optimal allocation of clusters across a set of cluster sequences, and selecting the optimal number of single observations to make in each cluster-period for both Gaussian and non-Gaussian models, and including exchangeable and exponential decay covariance structures.
\end{abstract}

\keywords{Cluster randomised trial, optimal experimental design, generalised linear mixed model}

\maketitle

\section{Introduction}
The cluster randomised trial is an increasingly popular experimental study design. It is used to evaluate interventions applied to groups of people, like classrooms, clinics, or villages, or when the outcome for one individual in the group depends on the outcomes for the others, as is the case with infectious diseases, for example \citep{Eldridge2012,Murray1998}. The design of a cluster trial involves the specification of all aspects of the study, many of which are determined by practical, ethical, and contextual restrictions. However, one major aspect of cluster trial design that can be resolved, or at least supported, with statistical analysis is the sample size of individuals and clusters, when observations are captured from the clusters and individuals, and when each cluster receives the intervention(s). 

From both an ethical and practical standpoint, minimising the number of observations required to achieve an inferential goal is highly desirable. For cluster trials, inferences are almost always based on the variance of the estimator of the treatment effect. Designs that minimise the variance of a specific parameter are said to be \textit{c}-optimal. However, for any particular design problem, enumerating all the different possible designs and their associated variances to identify the \textit{c}-optimal design is often impossible, given the number of possible variants. We must therefore use methods and algorithms that can quickly identify an efficient, or `optimal', design from within the set of possible designs. The correlation of outcomes within clusters, over time, and potentially within-individuals over time, makes the analysis of the efficiency of a study design more complex though, over and above individual-level studies with independent observations.\citep{Hooper2016,Hemming2020,Li2021} There has been recent methodological advances in the optimal experimental design literature to identify \textit{c}-optimal designs in studies with correlated observations, as well as several recent studies to look at the problem specifically for certain types of cluster randomised trial. In this article, we review the literature on optimal cluster randomised trial designs and review and translate more general methods and algorithms from the broader literature to this context. We present a range of results for different cluster trial design scenarios using a range of methods to illustrate use of the available methods and identify optimal cluster trial design for a range of contexts. 

\section{What is the optimal cluster trial problem?}
There are multiple types of optimality in the experimental design literature, which are referenced using a ``alphabet'' system of letters. The primary objective of a cluster randomised trial is almost always to provide an estimate of the treatment effect of an intervention and an associated measure of uncertainty for one or more outcomes. Other parameters in the statistical model are not of primary interest. For example, the predominant method used to justify the sample size within a particular study design is the power for a null hypothesis significance test of the treatment effect parameter \citep{Hooper2016,Hemming2020}. Thus, efficiency and optimality in this setting relates to minimising the variance of the treatment effect estimator, which is \textit{c}-optimality.

We now introduce concepts and notation to describe the methods to identify \textit{c}-optimal cluster trial designs. We assume time is modelled discretely where there are repeated measures, such that observations are considered to have been made within clusters at discrete points in time. Approximations can be made to a continuous time model by finely discretising time within this framework; using a regular grid over a continuous space is a common strategy in optimal design work.\citep{Yang2013} In what follows, we represent matrices using capital letters, e.g. $X$. We use a subscript to denote submatrices or elements of a matrix, in particular, we notate $X_A$ as the rows of $X$ in set $A$ with all the columns, and $\Sigma_{A}$ as the sub-matrix of $\Sigma$ with rows and columns in $A$. Lower case letters represent scalars and so $X_{i,j}$ indicates the element of $X$ in the $i$th row and $j$th column.

To set up the problem, we assume there are $N$ possible observations we could make for the design problem. An observation consists of a single `design point' that generates an outcome datum. Often observations are grouped into higher-level units around which the study is designed. For cluster trials with cross-sectional sampling each observation will be a unique individual grouped into cluster-periods and then clusters. For cohort designs, observations will be grouped within an individual trial participant and then in clusters. We refer to an \textit{experimental unit} as the smallest indivisible set of observations for the design problem. For example, we may wish to choose which whole cluster sequences to include so the cluster sequence is the experimental unit. Equally we may be selecting cluster-periods, if we do not need to include all time periods within a cluster, or indeed which specific observations. The set of all experimental units is the \textit{design space}. To simplify matters, we assume each observation is in one and only one experimental unit. However, experimental units in the design space need not be unique. For example, in the absence of individual-level covariates, an observation made in a cluster at a given time will have identical covariates to another observation from the same cluster-period.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{design-spaces-page-001.jpg}
    \caption{Examples of cluster trial design spaces and study designs for six time periods. Each row represents a cluster, or cluster sequence, and may be repeated more than once in the design space. Each cell is a cluster-period and contains one or more individual potential observations. Design Space A encodes a no reversibility assumption and includes contemporaneous comparisons. Design Space B allows for both addition and removal of the intervention over time. Parallel, stepped-wedge, hybrid, and staircase are all designs within both design spaces.}
    \label{fig:desspace}
\end{figure}

The top left panel of Figure \ref{fig:desspace} (Design Space A) represents a cluster randomised trial design space. Each row indicates a cluster sequence, and each column a discrete time interval or period. Within each cell, there are a pre-specified number of observations. Each row in the diagram is repeated only once, but there may be multiple repeats of the same row depending on the formulation of the problem and design space. Where there are multiple instances of the same cluster sequence, the design space includes the most common types of cluster randomised trial design with repeated measures: a parallel design, in which a cluster receives the intervention in all periods or the control in all periods, or a stepped-wedge cluster randomised trial, where the intervention roll out is staggered such that all clusters start in the control condition and then one or more clusters receives the intervention in each time period until all clusters are in the intervention state. A `hybrid' design consists of a mix of parallel and stepped-wedge cluster sequences, and a `staircase' design includes only the cluster-periods on the diagonal. Figure 1 illustrates these designs. This design space includes the following restrictions:
\begin{enumerate}
    \item[i] No reversibility, i.e. clusters can only cross from control to intervention states. 
    \item[ii] There must be contemporaneous comparison in at least one time period, i.e. a before-and-after design would not be permitted since it would not include a randomised comparison.
\end{enumerate}
Given that this design space incorporates the most widely used cluster randomised trial designs, and that these restrictions reflect common real-world limitations, it is an obvious choice for many applications. However, more complex design spaces are required to allow for alternative designs like cluster cross-over. Such a design space is illustrated in Figure 2, which removes the no reversibility restriction. We note though that the most efficient design for this design space when considering clusters as experimental units under EXC1 and EXC2 is the cluster cross-over, and so some authors compare the efficiency of designs relative to this\citep{Girling2016}. 

We base our analyses around a generalised linear mixed model (GLMM). For outcome vector $y$:
\begin{align}
    \begin{split}
    \label{eq:glmm}
        y &\sim F(\mu,\sigma) \\
        \mu &= h^{-1}(\eta)\\
        \eta &= X\beta + Z\mathbf{u}\\
        \mathbf{u} &\sim N(0,D)
    \end{split}
\end{align}
where $F$ is a statistical distribution with mean $\mu$ and scale parameter $\sigma$, and $h^{-1}$ is a link function. We assume that the distribution $F$ is in the exponential family. The matrix $Z$ is the `design matrix' for the random effects $\mathbf{u}$ and $D$ is the covariance matrix of the random effects. We discuss below the specification of $X$, $Z$, and $D$.

We assume that the matrices $X$ and $Z$ have $N$ rows and so contain all of the observations in the design space. There are $J$ experimental units, which we denote as $\mathcal{E}_j$ for $j=1,...,J$ where each $\mathcal{E}_j \subset [1,...,N]$ contains a subset of the rows. We also denote the design space as $\mathcal{D} := \{\mathcal{E}_j : j=1,...,J \}$ and a specific design as $d \subset \mathcal{D}$. The optimal design problem is then to identify the optimal design $d$ of size $m<J$ by selecting the most efficient set of $m$ experimental units from $\mathcal{D}$.

Most experimental design criteria are based on the Fisher information matrix. For the GLMM above, the information matrix for the generalised least squares estimator, the best linear unbiased estimator, for a particular design is:
\begin{equation}
\label{eq:infomat}
    M_d = X_d^T \Sigma_{d}^{-1} X_d
\end{equation}
where $\Sigma$ is the covariance matrix of the observations $y$. Then the \textit{c}-optimal design criterion is:
\begin{equation}
\label{eq:coptim}
    f(d) = \begin{cases}
        c^T M_d^{-1} c & \text{if } M \text{positive semi-definite} \\
        \infty & \text{ otherwise}
    \end{cases}
\end{equation}
where $c$ is a vector consisting of zeroes except for a one in the position of the treatment effect parameter. For some designs, such as if there were no observations in the treatment condition, $M$ would not be positive semi-definite and so we define the variance as infinite, i.e. the design provides no information on the parameter. The formal design problem is then to find $d \subset \mathcal{D}$ that minimises $f(d)$ such that $\vert d \vert = m < J$.

\subsection{Statistical Models for Cluster Randomised Trials}
We now present some common GLMM specifications for cluster randomised trials. Some of the methods we discuss are model-specific, while other are general, and these models are also used for the results and examples. Without loss of generality, we focus on models for cluster trials where individuals are cross-sectionally sampled in each cluster-period. Where relevant and also without loss of generality, we use $r$ to represent the number of observations per cluster-period. For a comprehensive discussion of different models relevant to cluster randomised trials, see Li et al\citep{Li2021}. 

\subsubsection{Covariance Function}
The observed outcome for an individual $i$ in cluster $k$ at time $t$ is specified as $y_{ikt}$ with linear predictor $\eta_{ikt} = x_{ikt}\beta + s_{ikt}$ where $s_{ikt} = z_{ikt}\mathbf{u}$ represents the random effects. The covariance function defines the entries of the covariance matrix $D$. We define a covariance function as:
\begin{equation}
    \text{Cov}(s_{ikt},s_{i'k't'}) = g(\Delta t, \Delta k)
\end{equation}
where $\Delta t = \vert t - t' \vert$ and $\Delta k = \vert k - k' \vert$. We define the following covariance functions:
\begin{enumerate}
    \item[EXC1] Cluster Exchangeable \begin{equation*}
        g(\Delta t, \Delta k) = \begin{cases}
            \tau^2 & \text{ if } \Delta k = 0 \\
            0 & \text{ otherwise}
        \end{cases}
    \end{equation*}
    \item[EXC2] Nested Exchangable \begin{equation*}
        g(\Delta t, \Delta k) = \begin{cases}
            \tau^2 + \omega^2 & \text{ if } \Delta k = 0 \text{ and } \Delta t = 0 \\
            \tau^2 & \text{ if } \Delta k = 0 \text{ and } \Delta t > 0 \\
            0 & \text{ otherwise}
        \end{cases}
    \end{equation*}
    \item[AR1] Auto-regressive or exponential decay \begin{equation*}
        h(\Delta t, \Delta k) = \begin{cases}
            \tau^2 \lambda^{\Delta t} & \text{ if } \Delta k = 0 \\
            0 & \text{ otherwise}
        \end{cases}
    \end{equation*}
\end{enumerate}

For Gaussian-identity models, we use $\sigma^2$ to denote the individual-level variance. Gaussian-identity models are often re-parameterised in terms of other parameters, in particular:
\begin{itemize}
    \item[ICC] Intra-class correlation coefficient. Equal to $\rho = \frac{\tau^2}{\tau^2 + \sigma^2}$ for EXC1 and AR1 and $\rho = \frac{\tau^2 + \omega^2}{\tau^2 + \sigma^2 + \omega^2}$ for EXC2. More precisely, this is the within-period ICC for designs with repeated measures and EXC2 function.\citep{Hooper2016}
    \item[CAC] Cluster-autocorrelation coefficient. Equal to $r = \frac{\tau^2}{\tau^2 + \omega^2}$ for EXC2 and not defined for the other models. 
\end{itemize}

\subsubsection{Matrix X}
The $n \times P$ matrix $X$ is a matrix of covariates. For cluster trials with repeated measures $X$ typically consists of an intercept, time period indicators for $T-1$ time periods, and a treatment indicator. Equivalently, matrix $X$ may be specified without the intercept and with $T$ time period indicators. We use this specification for the examples in subsequent sections. For some trial designs, investigators may consider alternative specifications. For a parallel design, the treatment effect estimator from a model that does not adjust for time period is unbiased. However, such a specification would result in a biased treatment effect estimator where the intervention roll out is staggered over time. Thus, we assume that for most applications where staggered designs feature in the design space, adjustment for time is incorporated in the specification for $X$. We may also consider adjusting for continuous functions of time, such as polynomials, if the time periods are an approximation to continuous time. For example, Hooper and Copas\citep{Hooper2021} consider cubic and piecewise continuous polynomials.

In this discussion, we also assume there is a single treatment that enters the model as a dichotomous treatment indicator. More complex cluster trial designs may feature multiple arms and treatments,\citep{Watson2021} including continuous treatments representing dose. However, we do not consider these designs here.

\section{Methods and previous literature}
We divide the currently available methods for the optimal cluster trial design problem into three categories: (i) derivation of explicit formulae for the optimal design for specific models and design spaces; (ii) general `multiplicative' methods that derive weights to place on each unique experimental unit; and (iii) general combinatorial optimisation algorithms designed to select the optimum $m$ items from a discrete set of size $J$.

\subsection{Exact Formulae}
For simpler models one can derive explicit formulae for $f(d)$. Given a statement of the variance or precision one can then either determine an algorithm to identify an optimal solution, or use it to calculate the variance for a wide range of designs and/or parameter values and compare numerically or graphically. Many such studies are based on the formula for the variance of the treatment effect estimator in the linear mixed model with EXC1 covariance given by Hussey and Hughes.\citep{Hussey2007}

Girling and Hemming\citep{Girling2016} provide perhaps the most notable study of this type for cluster trials. They derive a formula for the precision of the treatment effect estimator in a linear mixed model under covariance structure EXC2 along with individual-level cohort effects, although we drop the individual level cohort effects for this summary. They consider the problem of determining in which period to introduce the intervention into each of $m$ clusters, which are all observed for each of $T$ time periods, and each cluster-period has $n$ observations. One can map this problem onto Design Space A in Figure \ref{fig:desspace} where each row is an experimental unit repeated $m$ times, and the goal is to identify the optimal $m$ set of experimental units.

We can rewrite model (\ref{eq:glmm}) as a linear mixed model for individual $i$ in cluster $k$ at time $t$ as:
\begin{equation}
\label{eq:lmm2}
    y_{ikt} = J_{kt}\delta + w_t\gamma_t + \alpha_{k} + \theta_{kt} + u_{ikt}
\end{equation}
where $J_{kt}$ is an indicator for if cluster $k$ has the intervention at time $t$, $w_t$ is a time period indicator with time period parameters $\gamma_t$, and $\alpha_{1k} \sim N(0,\tau^2)$ and $\theta_{kt} \sim N(0,\omega^2)$ are the cluster and cluster-period random effect terms, and $u_{ikt} \sim N(0,\sigma^2)$ is the error term. The fixed effect parameters are $\beta = [\delta, \gamma_1, ..., \gamma_T]^T$ and $\delta$ is the treatment effect parameter. With discrete clusters and time periods, we can `collapse' model (\ref{eq:lmm2}) into a model for the cluster-period means:
\begin{equation}
\label{eq:lmm3}
    \Bar{y}_{jt} = J_{jt}\delta + w_t\gamma_t + \alpha_{j} + e_{jt}
\end{equation}
where $\Bar{y}_{jt} = \frac{1}{n}\sum_{i=1}^n y_{ikt}$ is the mean outcome for cluster $k$ in time period $t$ and $\text{Var}(e_{kt}) \sim N(0, \omega^2 + \frac{\sigma^2}{n})$. Girling and Hemming, following work by Hussey and Hughes\citep{Hussey2007} and others, then show that the precision of the treatment effect estimator $\Hat{\delta}$ is given by:
\begin{align}
\begin{split}
\label{eq:prec}
    \frac{1}{f(d)} &= \text{Var}^{-1}(\Hat{\delta}) \\
    &= \frac{mT}{(\omega^2 + \frac{\sigma^2}{n})(1-\Bar{\rho})}(a_d - b_d R)
\end{split}
\end{align}
where $\Bar{\rho} = \frac{\tau^2}{\tau^2+\omega^2+\sigma^2/n}$ is equivalent to the ICC at the cluster-period mean level and $R = \frac{T\Bar{\rho}}{1+(T-1)\Bar{\rho}}$ is the cluster mean correlation. The coefficients $a_d$ and $b_d$ are determined by the study design:
\begin{align*}
    a_d &= \frac{1}{mT} \sum_{t=1}^T \sum_{k=1}^m (J_{kt} - \Bar{J}_{\cdot t})^2 \\
    b_d &= \frac{1}{m} \sum_{k=1}^m (\Bar{J}_{\cdot t} - \Bar{J}_{\cdot \cdot})^2
\end{align*}
where the dot indicates the index over which the mean is taken. 

Girling and Hemming\citep{Girling2016} provide a method for using Equation (\ref{eq:prec}) to produce an optimal design under a no reversibility constraint. We assume the clusters are numbered such that a lower numbered cluster has greater than or equal number of intervention periods than any higher numbered cluster. We then map the cluster-period indexed to coordinates on a unit square $(j,t) \mapsto (x_{0j},x_{1t})$ where $x_{0j}, x_{1t} \in [-1/2,1/2]$. All cluster-periods start in the control state, and then starting with cluster 1 in the $T$th period, one successively changes the cluster-period to an intervention state in the order of decreasing values of $R x_{1t} - x_{0j}$ until $\Bar{J}_{\cdot \cdot}$ cluster-periods are included in the treated set. Examples of this methods are provided in the article, which we reproduce in the examples section.

Lawrie, Carlin, and Forbes\citep{Lawrie2015} derive explicit formulae for the optimal proportion of clusters to allocate to each sequence (row) in the Design Space A to minimise $f(d)$ using a linear mixed model and the EXC1 covariance function. They show that the optimal proportion of clusters allocated to the $t$th sequence in the stepped-wedge design space (see Figure \ref{fig:desspace}) with $T-1$ sequences, $\phi_{t}$ is:
\begin{align}
\begin{split}
\label{eq:probweight1}
    \phi_1 &= \phi_{T-1} = \frac{1 + \rho(3r-1)}{2(1+\rho(rT-1)} \\
    \phi_t &= \frac{r\rho}{1+\rho(rT-1)} \text{ for } t=2,...,T-2
    \end{split}
\end{align}

Zhan, Bock, and Heuvel\citep{Zhan2018} extend Lawrie et al's analyses using Girling and Hemming's work to identify more general `optimal unidirectional switch designs' by extending the probability weights (\ref{eq:probweight1}) to a larger design space with sequences incorporating exclusively control or intervention conditions, and with EXC1 covariance functions. Here, unidirectional switching means applying the no reversibility restrictions, giving, for example Design Space A in Figure \ref{fig:desspace}. The more general probability weights for the design space with $T+1$ sequences are:
\begin{align}
\begin{split}
\label{eq:probweight2}
    \phi_0 &= \phi^{T} = \frac{1 + \rho(r-1)}{2(1+\rho(rT-1)} \\
    \phi_t &= \frac{r\rho}{1+\rho(rT-1)} \text{ for } t=1,...,T-1
    \end{split}
\end{align}. Zhan et al also extend this analysis to smaller design spaces including only a subset of the rows of Design Space A. We discuss below methods for rounding proportions to whole numbers of clusters and how it can result in several possible designs. 

There are several other studies that derive expressions for the treatment effect variance to identify efficient study designs. Hooper and Copas\citep{Hooper2021b} consider a linear mixed model with AR1 covariance for a cluster randomised trial with continuous recruitment. They consider a parallel study design with baseline measures and aim to identify the when the intervention should be implemented in the intervention arm under different sample sizes and covariance parameters. They calculate the value of (\ref{eq:coptim}) for a large range of models and graphically compare the results. Copas and Hooper\citep{Copas2020} take a similar approach with a linear mixed model with EXC1 covariance with a parallel trial design. They aim to identify optimal sample sizes and the proportion of data to collect in baseline and endline periods. Moerbeek\citep{Moerbeek2020} also uses a explict criterion, although not strictly for c-optimality, as she aims to identify an optimal sample size within treatment and control groups subject to a budget constraint. They consider only a single time period, such that the treatment effect estimator is a difference in means.

Deriving explicit formulae for the variance or precision is appealing due to its relative simplicity. Comparing designs and identifying a c-optimal design does not require specialist tools and can be done using spreadsheet software. However, these methods are typically limited to specific models and designs, such as exchangeable covariance structures, linear models, and equal cluster-period sizes. The mathematical approach used to derive the precision formula does not carry over to more complex covariance structures or design spaces, nor to problems where the experimental unit is an observation or cluster-period. One can calculate the value of the c-optimality criterion directly for any design, as Hooper and Copas\citep{Hooper2021b} do. However, the number of designs one must calculate the variance of grows exponentially with the size of the design space and quickly becomes too large to do in any reasonable time frame. Thus, more general methods are required for these extended problems.

\subsection{Multiplicative weighting methods}
Determining probability weights for experimental units, as the studies cited above do explicitly\citep{Zhan2018,Lawrie2015}, is a useful strategy to simplify the optimal design problem. One can generalise this approach to tackle more complex models and design spaces. We place a probability measure $\phi$ on $\mathcal{D}$ so that our design is characterised by $\boldsymbol{\phi} := \{(\mathcal{E}_k,\phi_k):k=1,...,K\}$ where $\phi_k \in [0,1]$ are weights. These weights can be interpreted as `amount of effort' to place on each experimental unit. The optimal design problem can them be re-stated as finding a design that minimises $f(\boldsymbol{\phi})$.

Elfving's Theorem is a classic result in the theory of optimal designs.\citep{Elfving1952} The original formulation considered independent, identically distributed observations. Holland-Letz, Dette, and Pepelyshev (2011)\citep{Holland-Letz2011} and Sangol (2011)\citep{Sagnol2011} generalised the theorem to the case where there is correlation within experimental units, such as within a cluster, but not \textit{between} experimental units, such as if the experimental unit was a cluster-period or observation. Elfving's theorem provides a geometric characterisation of the \textit{c}-optimal design problem. If the experimental units are uncorrelated, the information matrix in Equation (\ref{eq:infomat}) can be rewritten as:
\begin{equation*}
    M_d = \sum_{\mathcal{E}_j \in d} X^T_{\mathcal{E}_j}\Sigma^{-1}_{\mathcal{E}_j}X_{\mathcal{E}_j}
\end{equation*}
thus for the approximate design $\boldsymbol{\phi}$ we can write:
\begin{equation}
\label{eq:infomatsum2}
    M_{\boldsymbol{\phi}} = \sum_{k=1}^K X_{\mathcal{E}_k} \Sigma_{\mathcal{E}_k,\mathcal{E}_k}^{-1} X_{\mathcal{E}_k} \phi_k
\end{equation}
 which we can rewrite as:
\begin{equation}
\label{eq:infoF}
      M_{\boldsymbol{\phi}} = \sum_{k=1}^K F_{\mathcal{E}_k}^T F_{\mathcal{E}_k} \phi_k
\end{equation}
where $F_{\mathcal{E}_k} = L_{\mathcal{E}_k,\mathcal{E}_k}^T X_{\mathcal{E}_k}$ and $L_{\mathcal{E}_k,\mathcal{E}_k}$ is a square root of $ \Sigma_{\mathcal{E}_k,\mathcal{E}_k}^{-1}$.

A `generalised Elfving set' is:
\begin{equation}
    \mathcal{R} = \text{co}\{   F_{\mathcal{E}_{k}}^T \epsilon_k: X_{\mathcal{E}_k} \in \mathcal{X}^{\vert \mathcal{E}_k \vert \times P}; || \epsilon_k ||= 1; k = 1,...,K \}
\end{equation}
where $\text{co}$ denotes the convex hull. This set leads us to a generalised Elfving theorem:
\begin{theorem}[Generalised Elfving Theorem]\label{th2}
A design $\boldsymbol{\phi} := \{(\mathcal{E}_k,\phi_k):k=1,...,K\}$ is c-optimal if and only if there exists vectors $\epsilon_1,...,\epsilon_K$ where $||\epsilon_k|| = 1$ and positive real scalar $\pi$ such that $\pi c = \sum_{k=1}^K \phi_k F_{\mathcal{E}_k}^T \epsilon_k$ is a boundary point of the set $\mathcal{R}$.
\end{theorem}
For proof see\citep{Holland-Letz2011,Sagnol2011}.

Sagnol\citep{Sagnol2011} shows how the generalised Elfving theorem can be used to define a second-order cone program, which is a type of conic optimisation problem than can be solved with interior point methods. This program returns the optimal values of $\phi_1,...,\phi_k$. We provide functionality for the problems we consider in this article in the R package \texttt{glmmrOptim}, including this program. Other proposals exist for identifying the optimal weights, such as using a multiplicative algorithm based on an upper bound for the solution.\citep{HollandLetz2012} 

\subsection{Rounding proportions of experimental units}
Where a method produces an optimal design in terms of the proportion of experimental units of each type to include, we must use a rounding procedure to translate it into exact numbers. There are several methods for converting proportions to integer counts that sum to a given total. The problem was famously identified for converting popular vote totals in states into numbers of seats in the US House of Representatives; the solutions are named after their proposers.\citep{Balinski2002}  Pukelsheim and Rieder (1992)\citep{PUKELSHEIM1992} following others\citep{Fedorov1972} argue that the procedure of John Quincy Adams is the most efficient method of rounding to an exact design. As Pukelsheim and Rieder note though, the design weights do not contain enough information to exactly identify a experimental design, and so multiple designs may be generated. The multiplication may also result in counts that do not sum to the desired total number of clusters $J$, and so counts are adjusted based. However, this procedure is based on the assumption that a `fair' allocation includes at least one experimental unit of each type. For many cluster trial design problems we do not require this restriction, for example, a parallel trial is optimal in some cases.\citep{Girling2016} In other cases, there may be practical reasons to ensure staggering of the roll-out,\citep{Hooper2021,Hemming2015} in which case this rounding scheme would be the most efficient. Hamilton's rounding procedure is the most notable alternative to Adam's method. In this method, we initially assign $\lfloor J\phi_j \rfloor$ clusters to each sequence, and the incrementally add clusters according to the largest remainder $J\phi_j - \lfloor J\phi_j \rfloor$. In the later examples (and the implementation in the R package \texttt{glmmrOptim}) we use all rounding procedures and then select the design with the smallest value of $f(d)$ since evaluating the variance for the small number of possibly optimal designs does not bear a high computational cost.

While the solutions generated by different rounding schemes, and the algorithms discussed in the next section, may in fact be an exact optimal solution, they cannot guarantee such a result. In the results section we provide several examples where the results of the methods may disagree. The equivalence theorem\citep{Pukelsheim2006} provides precise conditions to check whether a given design is indeed optimal. However, it requires knowledge of the optimal design. Girling and Hemming\citep{Girling2016} use an approach of comparing the relative efficiency of the design to that of a cluster cross-over, which is the most efficient if it is within the design space. Not all design spaces include the cluster cross-over design, and so the optimal design may not be known. Holland-Letz, Dette, and Renard (2012)\citep{HollandLetz2012} derive a lower bound for the relative efficiency of a given design in the context of a pharmacokinetic study with correlated observations.

%Pukelsheim and Rieder show a variant of John Quincy Adam's method is the most efficient. Algorithm \ref{alg:round} shows the complete rounding procedure. The rounding procedure first multiplies the weights by a constant to generate the vector $w$ and then uses a rounding procedure to generate whole numbers. If any of the elements of $w$ are already integers then two numbers are returned by the rounding function CEIL(.), itself and itself rounded up to the next integer. As Pukelsheim and Rieder discuss, the design weights do not contain enough information to exactly identify a experimental design, and so multiple designs may be generated. The multiplication may also result in counts that do not sum to the desired total number of clusters $J$, and so counts are adjusted based. The c-optimality criterion is then calculated for the resulting designs and we select the lowest variance design.

%\begin{algorithm}
%\caption{Efficient rounding of design weights $\phi_1,...,\phi_K$ to a design with $m$ clusters. In the algorithm below a design $D_a$ can be represented by $D_a = \{ n_{a,1},...,n_{a,K}$, which indicates that the design $D_a$ has $n_{a,1}$ copies of experimental unit $\mathcal{E}_1$, $n_{a,2}$ copies of experimental unit $\mathcal{E}_2$, and so forth.}
%\label{alg:round}
%\begin{algorithmic}
%\Procedure{Efficient apportionment}{$\boldsymbol{\phi}=\{\phi_1,...,\phi_K$\}, $J$}
% \State $v \gets m - \frac{K}{2}$
% \State $w \gets v\boldsymbol{\phi}$
% \State $z \gets \text{CEIL}(w)$ 
% \State $A \gets \sum_{k=1}^K \vert z_k \vert$
% \State Generate the set of designs $\mathcal{A}:= \{D_a: a=1,...,A, n_{a,i} \in z_i, i=1,...,K\} $
% \ForAll{$D_a \in \mathcal{A}$}
%    \If{$\sum_k n_{a,k} < m$}
%        \While{$\sum_k n_{a,k} < m$}
%            \State $k* \gets \argmin_{k} \frac{n_{a,k}}{\phi_k}$
%            \State $n_{a,k^*} \gets n_{a,k^*} + 1$
%        \EndWhile
%    \EndIf
%    \If{$\sum_k n_{a,k} > m$}
%        \While{$\sum_k n_{a,k} < m$}
%            \State $k* \gets \argmax_{k} \frac{n_{a,k}-1}{\phi_k}$
%            \State $n_{a,k^*} \gets n_{a,k^*} - 1$
%        \EndWhile
%    \EndIf
% \EndFor
% \State \textbf{Return} $D_{a^*}$ where $a^* = \argmin_a f_c(D_a)$ such that $D_a \in \mathcal{A}$
%\EndProcedure

%\Function {$\text{ceil}$}{w}
%\State $z \gets \begin{cases} \{b+1\} & \text{ for } w \in (b, b+1)\\
%    \{b,b+1\} & \text{ for } w = b\end{cases}$
%\State \textbf{Return} z
%\EndFunction
%\end{algorithmic}
% \end{algorithm}


%As an illustration, consider the linear mixed model with $T$ time period indicators, an intervention indicator, EXC2 covariance function, and the study has equal cluster-period sizes of size $m$. Let $u_j$ represent the number of time periods cluster $j$ has the intervention, $U = \sum_j u_j$, and $U_2 = \sum_j u_j^2$. We also specify $v_t$ as the number of clusters that have the intervention in time period $t$. Then, assuming the first $T$ elements of the information matrix correspond to the time period indicators and the $T+1$th element the treatment effect parameter, then the elements of $M$ are:
%\begin{align*}
%    M_{T+1,T+1} &= \frac{m}{\sigma^2}\left( (1-mk_1)U - mk_1 k_2 U_2 \right) \\
%    M_{t,t} &=  \frac{Jm}{\sigma^2}\left( 1-mk_1 - mk_1k_2 \right) \\
%    M_{t,t'} &= -\frac{Jm}{\sigma^2}mk_1k_2  \\
%    M_{T+1,t} &= \frac{m}{\sigma^2}\left( -mk_1k_2 U + v_t(1 - mk_1) \right)
%\end{align*}
%where $k_1 = 1/(m+s)$ and $k_2 = s^2/(r(m+s) + msT)$ with $r = \sigma^2/\tau^2$ and $s = \sigma^2/\omega^2$ and $t,t' <= T$ and $t \neq t'$. One can see that $m$, $k_1$, and $k_2$ do not depend on the design, only the parameters and sample size, and that $k_1,k_2 > 0$. Therefore, if one were to use this expression to identify an optimal design, then any design with smaller $U_2$, that is with a more `staggered' intervention implementation, would always be preferred. The time period effects and their relationship with the study design and covariance structure evidently play an influential role in determining the optimal design despite not being of interest themselves.

 %The assume `irreversibility' of the intervention, i.e. that once the intervention has been implemented, it cannot be removed. One can map this problem onto the design space in Figure XX where each row is an experimental unit repeated $J$ times, and the goal is to identify the optimal $J$ set of experimental units. However, in developing this review we identified an error in the derivation of the formula for the precision in that study, which means the precision formula is only valid for models without time period effects. Thus, the results from that study may not be valid for certain specifications.

%As exact, general solutions are not possible, 

\subsection{Combinatorial Optimisation Algorithms}
Another general method treats the cluster design problem as a combinatorial optimisation problem: how to select the optimum $m$ discrete items from a set of size $J$. Watson and Pan\citep{Watson2022} show how the \textit{c}-optimal design criterion in Equation (\ref{eq:coptim}) is a `monotone supermodular function', which means it is amenable to one of several algorithms that are well-studied in the literature. A supermodular function is one for which, given a design $d \subset \mathcal{D}$ and a smaller design $d' \subseteq d$, then $f(d \cup \mathcal{E}) - f(d) \geq f(d' \cup \mathcal{E}) - f(d')$ is true.\citep{Sviridenko2017} Intuitively, one can see this is the case for the design problems considered in this article since it states that the decline in variance from adding a new experimental unit $\mathcal{E}$ is smaller for larger designs. The function is monotone decreasing if $d' \subseteq d \rightarrow f(d') \geq f(d)$, which means that the variance will be larger if you remove any observations. The advantage of these algorithms is that they allow identification of optimal designs in cases where there is correlation between experimental units, such as when the experimental units are cluster-periods or single observations.

The three algorithms relevant to supermodular function minimisation are the local search, the greedy search, and the reverse greedy search algorithm.\citep{Wynn1970,Fedorov1972,Fisher1978,Nemhauser1978} We exclude the greedy search algorithm here, as it starts from the empty set and successively adds observations. As we require a minimum of $P$ observations to ensure a positive semidefinite information matrix, the algorithm therefore performs poorly as Watson and Pan\citep{Watson2022} show. The local and reverse greedy searchers are shown in Algorithm box \ref{alg:combin}. These algorithms are also implemented in the R package \texttt{glmmrOptim}. 

Finding the subset of size $m$ from the design space that minimises $f(d)$ is an NP-hard problem, however, much work has been produced from the 1970s onwards on computationally efficient methods of finding approximate solutions. In some cases, these algorithms give a `constant factor approximation', that is the worst case result has a provable bound on $f(d)/f(d^*)$ if $d^*$ is the \textit{c}-optimal design. For the design problem we consider in this article, only the local search has a constant factor approximation. However, we also include the reverse greedy search as it, or similar variants, have appeared in the literature for cluster trials.

\begin{algorithm}
\caption{Combinatorial algorithms to generate a design of size $m$}
\label{alg:combin}
\begin{algorithmic}
\Procedure{Local search}{}
 \State Let $D_0$ be size $m$ design 
 \State Set $\delta = 1$ and $D \leftarrow D_0$ 
 \While{$\delta > 0$}
 \ForAll{element $\mathcal{E}_k \in D$ and $\mathcal{E}_{k'}\in \mathcal{D} / D$}
    Calculate $f_c(D / \{\mathcal{E}_k\} \cup \{\mathcal{E}_{k'}\})$ 
 \EndFor
 \State Set $D' \leftarrow \argmin_{k,k'} f_c(D / \{\mathcal{E}_k\} \cup \{\mathcal{E}_{k'}\})$ 
 \State $\delta = f_c(D') - f_c(D)$ 
 \If{$\delta > 0$ }
    $D \leftarrow D'$
 \EndIf
 \EndWhile
\EndProcedure

%\Procedure{Greedy search}{}
%\State Let $D$ be a non-degenerate design of size $s < m$
% \State $l \gets s$\;
% \While{$l \leq m$}
% \ForAll{$\mathcal{E}_{k}\in \mathcal{D} / D$}
%    \State Calculate $f_c(D \cup \{\mathcal{E}_{k}'\})$
% \EndFor
% \State Set $D \leftarrow D \cup \argmin_{\mathcal{E}_k} f_c(D \cup \{\mathcal{E}_k\})$ \;
% \State $l \leftarrow l + 1$
% \EndWhile
% \EndProcedure

 \Procedure{Reverse greedy search}{}
\State $D \gets \mathcal{D}$
 \State $l \gets N$\;
 \While{$l > m$}
 \ForAll{$\mathcal{E}_{k}\in D$}
    \State Calculate $f_c(D / \{\mathcal{E}_{k}'\})$
 \EndFor
 \State Set $D \leftarrow D / \argmin_{\mathcal{E}_k} f_c(D / \{\mathcal{E}_k\})$ \;
 \State $l \leftarrow l - 1$
 \EndWhile
 \EndProcedure
\end{algorithmic}
 \end{algorithm}


The local search algorithm starts from a design of the desired size $m$ and then makes the swap of an experimental unit in the design with one not in the design that leads to the greatest reduction in the c-optimality criterion. Such swaps are made until no further value improving swaps are available. The worst possible design that this algorithm produces under a cardinality constraint (i.e. $\vert D \vert \leq J$) has a value no larger than $3/2$ times the true c-optimal design.\citep{Fisher1978} This bound can be improved to $1 + 1/e$ with certain extensions to the algorithm.\citep{Filmus2014} 

The reverse greedy algorithm starts from the complete design space and successively removes the experimental unit that results in the largest decrease in variance.  Proofs of the constant factor approximation for these algorithms depend on the `steepness' or `curvature' of $f(.)$, which depends on the value of $f(\emptyset)$, where $\emptyset$ is the empty set, i.e. a design with no observations. A reasonable choice for the variance of an estimator from a design with no observations is infinity, as we specify in (\ref{eq:coptim}). However, the resulting curvature of the function then means there is no constant factor approximation bound.\citep{Ilev2001,Sviridenko2017} Alternatively we could say $f(\emptyset)$ is undefined, and we would again lack a theoretical guarantee.

%The local and greedy search algorithms are equivalent to the algorithms proposed by Wynn (1970)\citep{Wynn1970} and Federov (1972)\citep{Fedorov1972} to identify D-optimal experimental designs (maximising $\text{det}(I_D)$), however these algorithms lack proof of covergence to D-optimal designs.

Watson and Pan\citep{Watson2022} investigate these algorithms for a range of study designs, including cluster randomised trials. They find that empirically the reverse greedy and local search algorithms provide similar performance in terms of the variance of the resulting design. The reverse greedy search is deterministic, while the local search starts from a random design, so Watson and Pan run the local search multiple times and select the best design. They also suggest several approaches to improve the computational efficiency of these algorithms.

Kasza and Forbes\citep{Kasza2019} use a reverse greedy approach to identify optimal designs. They describe the method as estimating the `information content' of clusters or cluster-periods in a design space like Figure \ref{fig:desspace} to identify which experimental units to remove if a smaller design is required where their measure of information is the marginal change in variance from removing the observations from the design. The results presented by Kasza and Forbes\citep{Kasza2019} are qualitatively similar to those using other methods and algorithms, such as those presented below. 

Hooper, Kasza, and Forbes (2020)\citep{Hooper2020} examine optimal cluster trial designs in the context of the linear mixed model with covariance function AR1. They consider a discrete approximation to a continuous time model with continuous recruitment and polynomial functions of time. The design space consists of individuals regularly spaced over a time interval within clusters; the individuals constitute the experimental unit. They aim to provide a set of illustrative optimal designs under different parameter values for the covariance function. The method used to identify these designs could also be described as a variant of the `reverse greedy' algorithm. Each iteration of the algorithm is supplemented with a type of local search, although the swaps of experimental units that can be made are limited at each step to preserve a no reversibility restriction. The designs presented by Hooper, Kasza, and Forbes\citep{Hooper2021} are often qualitatively different from those presented here resulting from other methods. However, the inferred design space they use includes a wide range of other designs, and their specfication of $X$ does not include time period indiciators, which may account for some of the differences. 

\subsubsection{Computational Complexity}
The computational complexity of the local and greedy searches scales as $O(m^4r^3(J-m))$ and $O(J^3r^3(J-m)$, respectively,\citep{Watson2022} where $r$ is the number of observations in an experimental unit. These algorithms scale relatively poorly with the size of the design. However, the approach taken by Girling and Hemming\citep{Girling2016} discussed above suggests a way of improving the computational time of these algorithms when the experimental unit is a cluster or cluster-period. Equation (\ref{eq:lmm3}) specifies a model for the cluster-period mean under covariance function EXC2. A similar model can be specified for the AR1 function with equal sized cluster-periods:
 \begin{align}
 \begin{split}
 \label{eq:lmm4}
    \Bar{y}_{kt} &= J_{kt}\delta + W_t\tau_t + \alpha_{kt} + e_{kt} \\
    \text{Cov}(\alpha_{kt},\alpha_{kt'}) &= \tau^2 \lambda^{\vert t - t' \vert} \\
    \text{Var}(e_{kt}) &= \frac{\sigma^2}{n}
    \end{split}
\end{align}
The advantage of using a model for the cluster-periods is that it only requires a single swap or addition to change an experimental unit as opposed to $n$ swaps or additions to the design. 

\subsection{Non-Gaussian Models}
Both the multiplicative weighting and combinatorial methods require calculation of the covariance matrix $\Sigma$ and its inverse. For Gaussian models with identity link function $\Sigma = \sigma^2I + ZDZ^T$, and so it can be calculated exactly. For non-Gaussian models, such as Binomial or Poisson, generating $\Sigma$ can be highly computationally demanding. As such an approximation to $\Sigma$ and hence to the information matrix $M$ is typically used.\citep{Waite2015} Breslow and Clayton (1993)\citep{Breslow1993} used the marginal quasilikelihood of the GLMM to propose the first-order approximation:
\begin{equation}
\label{eq:sigapprox}
    \Sigma \approx W^{-1} + ZDZ^T
\end{equation}
where $W$ is a diagonal matrix with entries $W_{i,i} = \left(\left(\frac{\partial \mu}{\partial \eta} \right)^2 \text{Var}(y|\mathbf{u}) \right)$, which are the GLM iterated weights.\citep{mccullagh2019generalized} Here, $W$ is evaluated at the marginal mean $X\beta$. However, Zeger et al (1988)\citep{Zeger1988} suggest that when using the marginal quasilikelihood, approximations can be improved by `attenuating' the linear predictor. For example, for the binomial-logit model one would use $\mu_i = h^{-1}(x_i\beta\text{det}(aDz_i^Tz_i + I)^{-1/2})$ where $a = 16\sqrt{3}/15\pi$. For other types of optimality this attenuation can improve the resulting designs,\citep{Waite2015} however for \textit{c}-optimality there was little evidence of a difference in the designs considered by Watson and Pan.\citep{Watson2022} Other information matrix approximations that may be relevant for non-Gaussian models include using the GEE working covariance matrix or higher order approximations, however, these methods are either more restrictive or there is little evidence they improve the designs. The approximation also permits the use of cluster-period mean models, like (\ref{eq:lmm3}) and (\ref{eq:lmm4}), with heteroskedastic errors given by $\text{Var}(e_{jt}) = \frac{W_{ii}}{n_{jt}}$ where the $n_{jt}$ is the number of observations in cluster $j$ at time period $t$, and $W_{ii}$ the individual-level variance of an observation in that cluster-period. For the non-Gaussian examples we give below, we use Equation \ref{eq:sigapprox} without attenutation. 

\subsection{Robust Optimality}
The methods to generate an optimal design have so far assumed the model parameters are known. However, a well known issue for optimal experimental design methodology is that a design that may be optimal for one set of parameters or model specification may perform very poorly for another. As such robust methods that are efficient across a range of designs are desirable. There are multiple possible criteria for modifying the c-optimal design criterion to account for multiple designs. For example, Girling and Hemming\citep{Girling2016} consider a minimax criterion in which they identify a design that maximises (minimises) the minimum (maximum) precision (variance) over all values of the correlation between cluster-period means. This results in a `hybrid' trial design (see Figure \ref{fig:desspace}). 

As a robust optimality criterion, the maximin function is not necessarily generally applicable. For the combinatorial methods, we require that the objective function is supermodular, and the maximum of a set of supermodular functions is not necessarily supermodular. As an alternative, we can use a `weighted average'. In particular, we assume there is a set of $L$ candidate models and we specify a prior probability for each model $p_1,...,p_L$ with the property $\sum_{l=1}^L p_l = 1$. Dette (1993)\citep{Dette1993} and Lauter (1974)\citep{Lauter1974} propose the following generalisation the c-optimality criterion:
\begin{equation}
\label{eq:extcoptim}
    f(d;\mathcal{A}) = \sum_{l=1}^L p_l \log(c_l^T M^{-1}_{d,l} c^T_l)
\end{equation}
where $M_{d,l} = (X^T_{d,(l)}\Sigma^{-1}_{d,(l)}X_{d,(l)})^{-1}$ represents the information matrix for design $D$ under the $l$th model. As well as the parameters varying between model specification, the vectors $c_{l}$ and matrices $X_{(l)}$ and $\Sigma_{(l)}$ can vary between models, for example, there may be different specifications of time and covariance functions. 

Dette\citep{Dette1993} generalises the Elfving theorem for this robust criterion for models with uncorrelated observations. One can further generalise this theorem to the case where observations are correlated within experimental units following the results of Holland-Letz et al\citep{Holland-Letz2011} and Sagnol\citep{Sagnol2011}. However, a specification for a program to solve this generalised problem using conic optimisation methods, extending the results of Sagnol in the single model case, is not currently available, and remains a topic for future research. We thus omit a statement for a `doubly-generalised' Elfving theorem. 

Another robust c-optimality criterion is the weighted average:
\begin{equation}
\label{eq:extcoptim2}
    f(d;\mathcal{A}) = \sum_{l=1}^L p_l c_l^T M^{-1}_{d,l} c^T_l
\end{equation}
Both this criterion and (\ref{eq:extcoptim}) can be used with the combinatorial search methods, since they are also supermodular and maintain the same theoretical guarantees. Following Dette\citep{Dette1993} we describe a design that maximises either of these criteria as being c-optimal for the class $\mathcal{A}$ \textit{with respect to} the prior $p$.  

\section{Results and Examples}
In this section we provide a range of examples to illustrate the use of the methods and summarise results from several of the papers cited above. As previously discussed, the general methods do not guarantee exactly optimal designs. For the combinatorial algorithms, we use the local search and run the algorithm 100 times from random starting points and run the reverse greedy algorithm and select the best resulting design. For multiplicative weighting methods, we select the best design from a variety of different rounding methods. Where applicable we also compare the results to those presented by Girling and Hemming\citep{Girling2016}.

\subsection{Clusters as Experimental Units}
For the first set of examples we consider Design Space A in Figure \ref{fig:desspace} with seven unique cluster sequences and six time periods. Our goal is to identify a design of $m=10$ clusters. Each row is repeated up to five times in the design space, which is to say each sequence could be duplicated up to five times in the final design. Limiting the number of duplicate sequences to five, rather than ten, prevents the final design being, for example, a purely before and after design, while permitting parallel, stepped-wedge, and hybrid designs (although, we have not found a scenario where before-and-after design is optimal). We consider the linear mixed models given in Equations (\ref{eq:lmm3}) and (\ref{eq:lmm4}) with EXC2 and AR1 covariance functions, respectively. The method proposed by Girling and Hemming is applicable in the EXC2 case (the scenario here is the same as that given in Figure 5 of Girling and Hemming\citep{Girling2016}).

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{exc2_m10_allperiods-page-001.jpg}
    \caption{Optimal study designs with ten clusters and six time periods for different values of the ICC and CAC using a linear mixed model with EXC2 covariance structure with $m=10$ individuals per cluster-period. `Combin' are results from the combinatorial local search run 100 times and selecting the best design, `G-H' are results using the method from Girling and Hemming, and `Weight' are designs produced by estimating experimental unit weights. The number is the estimator variance from the design.}
    \label{fig:ex1}
\end{figure}

Figure \ref{fig:ex1} shows the results using the EXC2 covariance function with $m=10$ individuals per cluster-period. The resulting designs for each set of covariance parameters are the same from each method, with only a couple of exceptions. However, the difference between the variances from the designs do not exceed 0.0001. In all cases, the design from the combinatorial method has the lowest variance. Figure \ref{fig:ex2} shows the results from the model with AR1 covariance function. As with EXC2, the designs are generally the same from both combinatorial and weighting methods, but where there is a difference, the combinatorial method produces a design with marginally lower variance. For both covariance functions, as the level of correlation within a cluster and between periods or the overall level of within cluster-period correlation gets higher, the degree of `staggering' increases.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{ar1_m10_allperiods-page-001.jpg}
    \caption{Optimal study designs with ten clusters and six time periods for different values of the ICC and autoregressive parameter $\lambda$ (`lambda') using a linear mixed model with AR1 covariance structure with $m=10$ individuals per cluster-period. `Combin' are results from the combinatorial local search run 100 times and selecting the best design and `Weight' are designs produced by estimating experimental unit weights. The number is the estimator variance from the design.}
    \label{fig:ex2}
\end{figure}

The previous example assumes any design might be permissible within the design space. However, more restrictive design problems may be of interest given practical limitations on intervention roll out. As an example, we may require there to be only two trial arms within which all clusters receive the intervention at the same time. The question is then when each arm should receive the intervention (if at all). We can consider this problem as selecting two experimental units from Design Space A containing the seven experimental units in Figure \ref{fig:desspace}, since the variance of this design is proportional to a design with $J$ clusters allocated 1:1 to each of the two sequences. Figure \ref{fig:extwop} shows the optimal two cluster sequences using combinatorial and weighting methods. The two methods agree for all parameter values with the AR1 covariance function, however, for the EXC2 function the weighting method produces designs with higher variance. For low values of the CAC or $\lambda$ and the ICC a parallel design is optimal. For higher values of these parameters, inclusion of baseline or endline observations in which both trial arms are in control or treatment states, respectively, is superior to a purely parallel design.

\begin{figure}
    \centering
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{exc2_m10_twoperiod-page-001.jpg}
        \caption{EXC2 covariance function}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{ar1_m10_twoperiod-page-001.jpg}
        \caption{AR1 covariance function}
    \end{subfigure}
    \caption{Optimal study designs of two cluster sequences and six time periods for different values of the covariance parameters with the EXC2 and AR1 covariance functions. C = Combinatorial local search. W = experimental unit weights. The number on each panel is the treatment effect estimator variance for the design. The rows are difference values of the ICC.}
    \label{fig:extwop}
\end{figure}

\subsection{Single Observations as Experimental Units}

For the next examples we specify a single observation as the experimental unit. The design space is as specified in Figure \ref{fig:desspace} with seven clusters and six time periods, and each cluster-period has ten unique individuals who each contribute an observation. Our goal here is to select 80 observations of the 420 possible observations up to a maximum of ten per cluster-period. Only the combinatorial methods, of those discussed above, can provide a solution to this problem as the experimental units are correlated within a cluster and cluster-period. Figures \ref{fig:ex3} and \ref{fig:ex4} show the results for the EXC2 and AR1 covariance functions, respectively. In general, the levels of within cluster-period correlation (CAC or $\lambda$) appear to determine the optimal design, with higher levels resulting in greater numbers of observations placed along the main diagonal. Not all the designs are exactly symmetric, which may suggest the algorithm has not found the exactly optimal design.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{exc2_m10_ind-page-001.jpg}
    \caption{Optimal study designs of 80 individuals with seven clusters and six time periods using a linear mixed model with EXC2 covariance structure with up to ten per cluster-period. Results from the combinatorial local search run 100 times and selecting the best design. The number is the estimator variance from the design. The number within each cell is the intervention status and the colour represents the number of observations.}
    \label{fig:ex3}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{ar1_m10_ind-page-001.jpg}
    \caption{Optimal study designs of 80 individuals for different values of the ICC and $\lambda$ using a linear mixed model with AR1 covariance structure with $m=10$ individuals per cluster-period. Results from the combinatorial local search run 100 times. The number at the top of each panel is the estimator variance from the design. The number within each cell is the intervention status and the colour represents the number of observations.}
    \label{fig:ex4}
\end{figure}

\subsection{Non-Gaussian Models}
For non-Gaussian models, we illustrate how the parameters $\beta$ affect the resulting optimal design. We consider the design problem given for the examples shown in Figures \ref{fig:ex3} and \ref{fig:ex4} with single observations as experimental units and Design Space A of Figure \ref{fig:desspace} with up to ten individuals per cluster-period. We specify a binomial-logistic model. In all the examples we use parameters $\tau^2 = 0.16$ and $\omega^2 = 0.04$ for EXC2 or $\tau^2 = 0.20$ and $\lambda = 0.8$ for AR1, giving an approximate ICC of 0.05. The time period parameters are specified to give a control group mean outcome proportion of either 5\%, 25\%, or 50\% and odds ratios for the six time periods of 0.8, 0.9, 1.0, 1.0, 1.1, and 1.2, respectively. The treatment effect is an odds ratio of either 0.5 or 1.5. 

Figure \ref{fig:ex5} shows the optimal designs of 80 individuals for the binomial-logistic example. When the base rate is low, the relative difference in individual-level variance between time periods is larger, and the resulting designs favour placing more observations in those later time periods. When the base rate is higher, the designs more closely resemble those from the linear model in Figures \ref{fig:ex3} and \ref{fig:ex4}.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{binom_example-page-001.jpg}
    \caption{Optimal study designs of 80 indivudals with ten clusters and six time periods for different values of the ICC and autoregressive parameter $\lambda$ (`lambda') using a binomial-logistic mixed model with up to ten individuals per cluster-period. Results from the combinatorial local search run 100 times and selecting the best design. The number is the estimator variance from the design. Rows are by mean control group outcome proportion and columns indicate the treatment effect.}
    \label{fig:ex5}
\end{figure}



\subsection{Robust Optimal Designs}
To illustrate robust optimal designs we consider the 18 models and parameter values represented by the panels Figure 1 and 2. We assume that there is no prior knowledge of the likely values of the covariance parameters, nor the covariance function, and so assign equal prior weights to all 18 designs. We use the weighted average robust criterion (\ref{eq:extcoptim2}), and run the local search algorithm 100 times, selecting the lowest variance design. The left panel of Figure \ref{fig:ex6} shows the resulting optimal design with respect to the equal weighting prior. Similarly to Girling and Hemming\citep{Girling2016}, the design is a `hybrid' trial design with six of ten clusters following a parallel trial design, and the remaining four a staggered implementation roll-out. We also identify a robust optimal design for individual experimental units with the 18 designs shown in Figures \ref{fig:ex3} and \ref{fig:ex4} using the same procedure. The resulting design is shown in the right-hand panel of Figure \ref{fig:ex6}. 

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{robust-page-001.jpg}
    \caption{Robust optimal study designs of 80 indivudals with ten clusters and six time periods with respect to a prior that weights each possibility from earlier examples equally. Results from the combinatorial local search run 100 times and selecting the best design. The left panel is for a design space with clusters as experimental units, and the right panel where individuals are experimental units. The numbers in the cells on the right panel show the intervention status.}
    \label{fig:ex6}
\end{figure}

%\section{Bayesian Optimality}
%\label{sec:bayes}
%The discussion so far has considered only Frequentist optimal designs. However, there is a growing interest in and use of Bayesian methods for the design and analysis of cluster-randomised trials. Chaloner\citep{Chaloner1995} provides a review of Bayesian optimal experimental design criteria. Bayesian optimal designs are based on maximising a utility function $U(.)$ for the experiment averaging over the prior distributions for the model parameters. Our motivation for using the c-optimality criterion was that the objective of a cluster randomised trial is to obtain an estimate of a specific model parameter that represents the treatment effect of the intervention. From a Bayesian perspective then, a utility function that imposes quadratic losses on estimates that deviate from the true treatment effect may be appropriate. This squared error loss leads to the Bayesian c-optimality criterion for the linear model:
%\begin{equation}
%\label{eq:bayesc}
%    U_c(D) = c^T (I_D + V_0)^{-1} c
%\end{equation}
%where the parameters in the linear predictor are assigned the prior distribution $\beta \sim N(0,V_0)$ and $V_0$ is the prior covariance matrix. One could use (\ref{eq:bayesc}) with the combinatorial algorithms above to identify approximate Bayesian c-optimal designs, however we would be required to assume that the covariance parameters $\theta$ are known. A fully Bayesian criterion may instead average over the prior distributions for these parameters $h(\theta)$:
%\begin{equation*}
%    U_c(D) = \int \int (c^T (I_D + V_0)^{-1} c) h_{\Theta}(\theta) h_{\beta}(\beta) d\theta d\beta
%\end{equation*}
%where the integral is over $\beta$ for non-linear models as the covariance also depends on the linear predictor, however this can be omitted for linear models. However, this integral is generally intractable for the GLMMs used for the analysis of cluster randomised trials.

%There have been several methodological advances and new algorithms proposed for identifying Bayesian optimal experiemental designs. For example, Overstall and Woods (2017)\citep{Overstall2017} provide perhaps the most general solution to this problem for non-linear Bayesian models. We do not aim to provide a comprehensive review of methods for Bayesian optimality in this context given the relative rarity of Bayesian methods in the cluster randomised trial literature. However, we provide a brief discussion of how the methods discuss so far might translate to a Bayesian context.

%Watson and Pan\citep{Watson2022} discuss using a Riemann sum approximation. We can partition the prior for $(\theta,\beta)$ in to $L$ discrete cells $\psi_l = [ \beta_l \beta_{l+1} ] \cup [ \theta_l, \theta_{l+1} ]$ with volume $V_l$ for $l=1,...,L$.
%\begin{equation*}
%    U_c(D) \approx \sum_{l=1}^L (c^T (I_{D,(l)} + V_0)^{-1} c) h_\Theta(\theta^*_l) h_\beta(\beta^*_l) V_l
%\end{equation*}
%where $(\theta^*_l,\beta^*_l) \in \psi_l$ and $I_{D,(l)}$ is the information matrix for design $D$ evaluated at the parameters $(\theta^*_l,\beta^*_l)$. A common approach for Riemann sum approximations is to select the midpoint of the interval, although the `left' or `right' value of the set can also be used. This approximation is equivalent to criteria (\ref{eq:extcoptim2}) with weights $p_l \propto h_\Theta(\theta^*_l) h_\beta(\beta^*_l) V_l$. This criterion is therefore then amenable to the combinatorial algorithms. 

\section{Discussion and Conclusions}
The correlation between observations in a cluster randomised trial setting complicates identification of optimal study designs. Indeed, there have been relatively few studies on the topic of optimal cluster trial designs, particularly when compared with individual-level randomised controlled trials. However, recent methodological advances provide several approaches for approximating c-optimal designs with correlated observations. 

We have discussed three different types of method within a general framework for cluster trials with discrete time: using exact formulae for specific models specifications and design spaces and using an algorithm or enumerating and evaluating multiple relevant designs; determining weights to place on each experimental units in a design space; and, combinatorial algorithms for selecting an optimal subset of experimental units. These categories are not exhaustive and new methods may be developed using novel approaches. Each of the three types of method has their advantages and disadvantages. Minimising exact functions for the estimator variance would be preferable, but explicit formulae are only available in the simpler cases. Many authors (e.g.\citep{Girling2016,Zhan2018,Lawrie2015}) consider the linear mixed model with cluster and cluster-period exchangeable random effects, for example. The combinatorial algorithms produced the lowest variance design in all the examples we considered where we could compare methods, but were generally more computationally demanding when one takes into account the suggestion to run the algorithm multiple times and select the best design. They also scale poorly with the size of the design space. However, the combinatorial algorithms are also the only method currently in the literature that can provide solutions when the experimental units may be correlated with one another. The approximate weighting method provides a computationally efficient approach when the experimental units are uncorrelated, but can produce designs with higher variance after rounding to whole numbers of clusters, particularly if the overall number of clusters is small. We note that in testing the probability weights given in Zhan, Bock, and Heuvel\citep{Zhan2018} and Lawrie, Carlin, and Forbes\citep{Lawrie2015} are replicated by the generalised methodf for the linear mixed model with EXC1 covariance function.

Optimal designs are not always practical. For example, many of the designs in Figures \ref{fig:ex3} to \ref{fig:ex6} where the experimental unit was the individual included cluster-periods with a single individual. It is very unlikely that this would ever be implementable in practice given the logistics of data collection within clusters such as hospitals, clinics, or schools. However, one can view these optimal designs as a benchmark against which to justify a chosen study design. Hooper\citep{Hooper2021} suggests that there is a common misconception among cluster trial practitioners that the stepped-wedge design is more efficient than a parallel trial. The results of Girling and Hemming,\citep{Girling2016} which are replicated in Figure \ref{fig:ex1}, and others show that this is not the case.  The most efficient design depends on the covariance parameters, and in the case of a non-linear model, the parameters in the linear predictor too. Indeed, a useful heuristic is that emerges from these results is that the less variable the cluster means over time, the more `variable' the intervention should be (i.e. more staggered over time). Identifying an optimal design can help design a practicable trial that is more efficient than might otherwise be considered. Where individual-level experimental units are used, it can identify which cluster-periods to exclude entirely and which to place more effort into. Kasza et al\citep{Kasza2019} propose just such an approach based on a `reverse greedy' type algorithm. 

The framework we use to present these methods requires enumeration of all the unique experimental units. For more complex design problems the design space can then become very large. For example, Hooper et al\citep{Hooper2021b} use a discrete approximation to a continuous time model, and aim to identify when a cluster should start and stop recruiting and when it should implement the intervention. There is a very large number of possible cluster sequences that would fit within this design space given the large number of time increments, even with the no reversibility and symmetric restrictions they use. Enumerating the complete design space and subjecting it to one of the algorithms above would likely be highly computationally demanding. Indeed, this issue raises the question of how one might approach cluster trial optimal design question with continuous time. Other examples in the literature in which a treatment variable is potentially continuous, have relied on selecting a small number of discrete possible values; the finer the discretisation the better the result.\citep{Yang2013} Extending this to larger numbers of possible conditions, or treating time as truly continuous thus remains a topic of future research.

We have also not considered Bayesian optimal design. While Bayesian methods are relatively rarely used for the design and analysis of cluster randomised trials, there are growing number of examples (e.g.\citep{ThriveatWorkWellbeingProgrammeCollaboration2019}). Chaloner\citep{Chaloner1995} provides a review of Bayesian optimal experimental design criteria. Bayesian optimal designs are based on maximising a utility function for the experiment. The optimality criteria are highly similar to their Frequentist counterparts, but introduce the added complexity of needing to integrate over the prior distributions of the model parameters. There have been several methodological advances and new algorithms proposed for identifying Bayesian optimal experiemental designs. For example, Overstall and Woods (2017)\citep{Overstall2017} provide perhaps the most general solution to this problem for non-linear Bayesian models. The algorithms here might also be used to find approximate solutions to Bayesian cluster trial design problems. For example, the robust criterion (\ref{eq:extcoptim2}) could be translated to a Bayesian context where the weights are derived using a Riemann sum approximation to the integral over the prior distributions.\citep{Watson2022} However, further research is required into Bayesian methods for the design and analysis of cluster randomised trials.

The final choice of study design for a cluster randomised trial results from the confluence of a range of practical, financial, and statistical considerations. However, there is an ethical obligation to try to minimise the sample size required to achieve a research objective. Methods to identify optimal or approximately optimal study designs therefore serve a useful purpose where there is flexibility in the roll out of an intervention. We have identified several methods relevant to cluster randomised trials, which can be used on a standard computer in a short amount of time. We would therefore suggest that examining the optimal trial design should be a step in the design of every cluster randomised trial.


%\subsection{End of paper special sections}
%Depending on the requirements of the journal that you are submitting to,
%there are macros defined to typeset various special sections.

%The commands available are:
%\begin{verbatim}
%\begin{acks}
%To typeset an
%  "Acknowledgements" section.
%\end{acks}
%\end{verbatim}

%\begin{verbatim}
%\begin{biog}
%To typeset an
%  "Author biography" section.
%\end{biog}
%\end{verbatim}

%\begin{verbatim}
%\begin{biogs}
%To typeset an
%  "Author Biographies" section.
%\end{biogs}
%\end{verbatim}

%\newpage

%\begin{verbatim}
%\begin{dci}
%To typeset a "Declaration of
%  conflicting interests" section.
%\end{dci}
%\end{verbatim}

%\begin{verbatim}
%\begin{funding}
%To typeset a "Funding" section.
%\end{funding}
%\end{verbatim}

%\begin{verbatim}
%\begin{sm}
%To typeset a
%  "Supplemental material" section.
%\end{sm}
%\end{verbatim}

%\subsection{Endnotes}
%Most \textit{SAGE} journals use endnotes rather than footnotes, so any notes should be coded as \verb+\endnote{<Text>}+.
%Place the command \verb+\theendnotes+ just above the Reference section to typeset the endnotes.

%To avoid any confusion for papers that use Vancouver style references,  footnotes/endnotes should be edited into the text.

%\subsection{References}
%Please note that the files \textsf{SageH.bst} and \textsf{SageV.bst} are included with the class file
%for those authors using \BibTeX.
%The files work in a completely standard way, and you just need to uncomment one of the lines in the %below example depending on what style you require:
%\begin{verbatim}
%%Harvard (name/date)
%\bibliographystyle{SageH}
%%Vancouver (numbered)
%\bibliographystyle{SageV}
%\bibliography{<YourBibfile.bib>}
%\end{verbatim}
%and remember to add the relevant option to the \verb+\documentclass[]{sagej}+ line as listed in Table~\ref{T1}. 

%\section{Copyright statement}
%Please  be  aware that the use of  this \LaTeXe\ class file is
%governed by the following conditions.

%\subsection{Copyright}
%Copyright \copyright\ \volumeyear\ SAGE Publications Ltd,
%1 Oliver's Yard, 55 City Road, London, EC1Y~1SP, UK. All
%rights reserved.

%\subsection{Rules of use}
%This class file is made available for use by authors who wish to
%prepare an article for publication in a \textit{SAGE Publications} journal.
%The user may not exploit any
%part of the class file commercially.

%This class file is provided on an \textit{as is}  basis, without
%warranties of any kind, either express or implied, including but
%not limited to warranties of title, or implied  warranties of
%merchantablility or fitness for a particular purpose. There will
%be no duty on the author[s] of the software or SAGE Publications Ltd
%to correct any errors or defects in the software. Any
%statutory  rights you may have remain unaffected by your
%acceptance of these rules of use.

%\begin{acks}
%This class file was developed by Sunrise Setting Ltd,
%Brixham, Devon, UK.\\
%Website: \url{http://www.sunrise-setting.co.uk}
%\end{acks}

\bibliographystyle{SageV}
\bibliography{main}

\appendix
\section{Additional Results}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{exc2_m100_allperiods-page-001.jpg}
    \caption{Optimal study designs with ten clusters and six time periods for different values of the ICC and CAC using a linear mixed model with EXC2 covariance structure with $m=100$ individuals per cluster-period. `Combin' are results from the combinatorial local search run 100 times and selecting the best design, `G-H' are results using the method from Girling and Hemming, and `Weight' are designs produced by estimating experimental unit weights.}
    \label{fig:ex1b}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{ar1_m100_allperiods-page-001.jpg}
    \caption{Optimal study designs with ten clusters and six time periods for different values of the ICC and autoregressive parameter $\lambda$ (`lambda') using a linear mixed model with AR1 covariance structure with $m=100$ individuals per cluster-period. `Combin' are results from the combinatorial local search run 100 times and selecting the best design, `G-H' are results using the method from Girling and Hemming, and `Weight' are designs produced by estimating experimental unit weights.}
    \label{fig:ex2b}
\end{figure}


\end{document}
