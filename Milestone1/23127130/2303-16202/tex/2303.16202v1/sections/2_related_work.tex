\section{Related Work}\label{sec:related} 

\noindent\textbf{Quantum Computer Vision (QCV).} Several algorithms for computer vision relying on quantum hardware were proposed over the last three years for such problems as shape matching \cite{golyanik2020quantum, SeelbachBenkner2021, Meli_2022_CVPR}, object tracking \cite{LiGhosh2020, Zaech_2022_CVPR}, fundamental matrix estimation, point triangulation \cite{Doan_2022_CVPR} and motion segmentation \cite{Arrigoni2022}, among others. 
The majority of 
them 
address various types of alignment problems, \textit{i.e.,} transformation estimation \cite{golyanik2020quantum, Meli_2022_CVPR}, 
point set \cite{golyanik2020quantum, NoormandipourWang2022} and mesh alignment  \cite{SeelbachBenkner2021}, 
graph matching \cite{SeelbachBenkner2020, QuantumSync2021} and permutation synchronisation \cite{QuantumSync2021}.  

Only one of them, QSync \cite{QuantumSync2021}, can operate on more than two inputs and ensure cycle consistency for the underlying matchings. 
In contrast to QSync, we can align inputs with substantially larger (by two orders of magnitude) shapes in the number of vertices. 
Furthermore, we address a different problem, \textit{i.e.,} mesh alignment, for which an algorithm for two-mesh alignment with the help of AQC exists, namely Q-Match \cite{SeelbachBenkner2021}, as we discuss in the introduction. 

To maintain the valid structure of permutation matrices, Quantum Graph Matching, QGM\cite{SeelbachBenkner2020} and Q-Sync \cite{QuantumSync2021} impose linear constraints. %
However, this requires that 
the corresponding penalty parameter is carefully chosen. 
If the parameter is chosen too big and the linear constraints are enforced too strongly, this
severely limits QGM and Q-Sync's ability to handle large sets of vertices. 
On the other hand, if the linear constraints are enforced too weakly, there is no guarantee to obtain valid permutations as solutions. 
As discussed in the introduction, our approach follows Q-Match to ensure valid permutation matrices by construction. 
























\noindent\textbf{Multi-Shape Matching.} 
We focus this section on multi-shape and non-learning methods as CCuantuMM falls in this category. 
As our approach is not learning-based, it trivially generalises to unknown object categories without a need for training data. 
For a general survey of recent advances in shape matching, see Sahillioglu  \cite{sahillioglu2019survey}. 

Matching shape pairs is a classical problem in geometry processing \cite{melzi2019zoomout}. 
When more than two shapes of the same class exist, stronger geometric cues can be leveraged to improve results by matching all of them simultaneously. 
Unfortunately, the already very high problem complexity increases even further the more shapes are used. 
Hence, existing multi-shape matching methods 
limit the total number of shapes and their resolution \cite{cosmo2017consistent,Gao2021}, work in spectral space \cite{huang2020consistent}, or relax the permutation constraints  \cite{kezurer2015tight}. 
Early multi-matching methods computed pair-wise matchings and subsequently used permutation synchronisation to establish cycle consistency~\cite{pachauri2013solving, maset2017practical,shen2016normalized}.
Still, permutation synchronisation requires the eigendecomposition of a matrix with quadratically increasing dimensions \cite{pachauri2013solving}. 

HiPPI \cite{bernard2019hippi} is a  computationally efficient method that takes geometric relations into account while generalising permutation  synchronization but is still limited in resolution. 
Instead of looking at permutations directly, ZoomOut~\cite{melzi2019zoomout} reduces the  dimensionality of the problem by projecting it onto the spectral decomposition. 
This idea has been extended to take cycle consistency within the spectral space into account  \cite{huang2013consistent}, which does not guarantee a point-wise consistent matching. 
To circumvent this issue, IsoMuSh~\cite{Gao2021} jointly optimises point and functional correspondences. 
The method detangles the optimisation into smaller subproblems by using a so-called \textit{universe shape} that all shapes are mapped to instead of each other, as Cao and Bernard do \cite{cao2022unsupervised}. 
Using a \textit{universe} is similar to requiring a template shape, as many learning-based approaches  do \cite{groueix2018b,deprelle2019learning,sundararaman2022implicit}: Both synchronise all correspondences by matching them through a unified space. 
This is similar to the concept of anchor shape we use but inherently less flexible because the universe size or template have to be given \emph{a priori}. 
Our anchor is chosen from the given collection as part of the method. 
Although using an anchor slightly improves our results, we note that our method does not necessarily require one for operation.  
Hence, a random shape could be picked instead in each iteration without an increase in complexity if using an anchor is not feasible or does not represent the shape collection well. 






