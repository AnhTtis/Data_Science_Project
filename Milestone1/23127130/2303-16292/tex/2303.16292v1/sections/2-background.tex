\section{Background}
\label{sec:background}

In this section, we first introduce more background about XAI (Sec.~\ref{sub:background:xai}).
We then summarize existing XAI design frameworks and demonstrate the need for a new XAI framework that is specifically applicable to AR scenarios (Sec.~\ref{sub:background:xai_in_ar}).

\subsection{What is XAI?}
\label{sub:background:xai}
The notion of XAI can be traced back more than four decades~\cite{xu2019explainable}, where expert systems would explain output via a set of decision rules~\cite{scott1977explanation,swartout1985explaining}.
This concept has been brought back into focus by the success of black-box AI/ML models~\cite{confalonieri2021historical}.
The working definition of XAI used in this paper is: 
\textit{``given an audience, an explainable AI is one that produces details or reasons to make its functioning clear or easy to understand''}~\cite{barredo_arrieta_explainable_2020}.

With the increasing prevalence of advanced black-box models that make more critical predictions and decisions, the interpretability and transparency of AI systems has attracted increasing attention from various academic, industrial, and regulatory stakeholders~\cite{gregor1999explanations,preece2018stakeholders,gdpr_2019,gunning2019darpa}.
% For instance, the European Union General Data Protection Regulation (GDPR) commission established the legal right to obtain explanations~\cite{gdpr_2019}, and the Defense Advanced Research Projects Agency (DARPA) also formulated the XAI program to enable effective understanding and management of AI systems~\cite{gunning2019darpa}.
Addressing the broad vision of making AI more understandable for humans involves multidisciplinary research efforts.
ML researchers have developed algorithms that results in transparent models (\eg decision trees, Bayesian models~\cite{letham2015interpretable,caruana2015intelligible}) or used post-hoc explanation techniques (\eg feature importance, visual explanation, ~\cite{Lundberg2017,selvaraju2017grad,Shrikumar2017}) to generate explanations for users.
HCI researchers, on the other hand, have focused on improving user trust~\cite{pu2006trust,holliday2016user} and understanding~\cite{lim_assessing_2009,lim_why_2009} of machine generated explanations.
Psychology researchers have approached XAI from a more fundamental perspective and studied how people generate, communicate, and understand explanations~\cite{taylor2021artificial,yarkoni2017choosing}.
% We refer readers to several survey papers for more details: ML~\cite{barredo_arrieta_explainable_2020,holzinger_explainable_2018,zhang_explainable_2020,adadi_peeking_2018}, HCI~\cite{abdul_trends_2018,wang_designing_2019,amershi2014power,bellotti_intelligibility_2001}, and psychology~\cite{hoffman2018metrics,miller2019explanation,lepri2018fair}.

% , and can offer various benefits to different target audiences by providing transparency and interpretability.
% Depending on the target audience, XAI can have various benefits by providing more transparency and interpretability.
By providing more transparency and interpretability, XAI can offer different target audiences different benefits.
For instance, for algorithm developers and data scientists, XAI can provide more details for model debugging and improvement~\cite{lipton2018mythos} and increase production efficiency and robustness~\cite{samek2017explainable,yuan2019adversarial}.
For domain experts, XAI can reveal insights about causality~\cite{louizos2017causal}, transferability~\cite{tickle1998truth,chander2018working}, confidence~\cite{belle2017logic,pope2019explainability}, and also enhance the reliability of model output~\cite{dovsilovic2018explainable,Ribeiro2016,xu_leveraging_2019,xu_leveraging_2021}.
\review{
Early XAI research only focused on these two groups of users. Recently, there have been an 
% , \ie developers~\cite{Lundberg2017,Shrikumar2017,adadi_peeking_2018} and domain experts~\cite{liao_personalized_2020,wang_designing_2019,eiband_bringing_2018}.
increasing number of XAI studies that have focused on non-expert end-users who represent a large potential audience of XAI~\cite{jiang_who_2022,ehsan2021explainable}.
}
XAI has been found to improve reliance and build trust with non-experts~\cite{pu2006trust}, especially when users encounter unexpected AI outcomes~\cite{dhanorkar_who_2021}, have privacy concerns~\cite{edwards2017slave}, or seek additional information~\cite{doshi2017towards,burrell2016machine}.
Some companies have integrated XAI into products used by the general population~\cite{google_map_match_rate_2018,zhang_explainable_2020}, \eg visualizing the match rate of restaurant suggestions in a map application~\cite{google_map_match_rate_2018} or showing reasons for product recommendations on a  shopping website~\cite{zhang_explainable_2020}. However, these efforts are still at an early stage.


\subsection{Why do we need XAI in Everyday AR?}
\label{sub:background:xai_in_ar}
Since the first AR HMD was built in 1968~\cite{sutherland_head-mounted_1968}, researchers and engineers have been striving to integrate AR HMDs into everyday living.
Recent examples include simple head-mounted cameras and displays (\eg Google Glass Enterprise~\cite{google_glass} and Snap Spectacles~\cite{snap_spectacle}), as well as more advanced HMDs with 3D-depth sensing (\eg Microsoft Hololens~\cite{microsoft_hololens} and Magic Leap~\cite{magic_leap}).
% There is a growing number of examples of commercializing AR HMD for specific applications, such as assisting doctors with surgeries~\cite{vavra2017recent}, providing instructions for manufacturing workers~\cite{nee2012augmented}, or enabling convenient life logging for the general population~\cite{snap_spectacle}.
As hardware improves, it is foreseeable that AR will become an integral aspect of everyday living for general consumers and support a wide range of applications in the near future~\cite{cipresso2018past,rese2017augmented}.

\subsubsection{The Importance of AI and XAI in AR}
\label{subsub:background:xai_in_ar:importance}
The role of AI will be critical for AR devices if they are to provide intelligent services.
% For example, with sensors to track various signals (\eg motion, gaze, EEG), existing research has shown that AI can power AR devices to understand of user status in real-time, such as cognitive load~\cite{hess1964pupil,duchowski_index_2018} and attention~\cite{huang2018predicting,chong2018connecting,stappen2020x}.
% With a front-camera, existing research has shown the potential to infer users' daily activities~\cite{fathi2011understanding,singh2016first,schroder2017deep}, their context object details~\cite{redmon2016you,liu2020deep}, and semantics of the scene~\cite{grauman2022ego4d,pan2019content,bolanos2016toward,miech2020end}, \etc\
% This low-level intelligence would enable AR to provide an extensive variety of high-level smart services.
The integration of sensors enables AR systems to understand users' current states~\cite{huang2018predicting,stappen2020x,schroder2017deep} and their environment~\cite{liu2020deep,miech2020end} to provide a variety of intelligent functionalities.
For example, AR could infer user intent~\cite{admoni2016predicting} and provide contextual recommendations for daily activities (\eg recipe recommendations when a user opens the fridge during lunch)~\cite{adomavicius2011context,lam_a2w_2021,lee_all_2021}.
The rich interaction between the outcomes of AI and end-users requires effectively designed XAI that can support users in a variety of contexts, such as when users are confused or surprised while encountering an unexpected AI outcome, or when they want to make sure that an AI outcome is reliable and trustworthy~\cite{mohseni_multidisciplinary_2021,Amershi2019}.
% Like other AI systems outside AR, providing explanations of AI outcomes when needed can increase system transparency, resolve users' concerns, and build more trust~\cite{pu2006trust,holliday2016user}, thus improving user experience in AR.
Recent work has started to explore the application of XAI in AR~\cite{ahmed2022artificial}.
For instance, Wintersberger \etal found that showing traffic-related information in AR while driving can provide much needed explanation to users and improve user trust~\cite{wintersberger2018fostering}.
Danry \etal explored the use of an explainable AI assistant integrated within wearable glasses to enhance human rationality~\cite{danry2020wearable}.
Zimmermann \etal found that introducing XAI during an AR-based shopping process could improve user experiences~\cite{zimmermann2022enhancing}.
However, these studies proposed their own case-by-case XAI designs. In this research, we aggregated the major factors identified in the literature and studied the when/what/how questions systematically.

\subsubsection{The Need for A New XAI Framework for AR}
\label{subsub:background:xai_in_ar:need}
Researchers have proposed several XAI design spaces and frameworks for AI systems, \eg knowledge-based systems~\cite{graesser1992mechanisms}, decision support systems~\cite{amini2022discovering}, and recommendation systems~\cite{herlocker2000explaining}.
For instance, Wang~\etal proposed a conceptual framework for building user-centric XAI systems and put it into practice by implementing an explainable clinical diagnostic tool~\cite{wang_designing_2019}.
Eiband~\etal presented a stage-based participatory design process for designers to integrate transparency into systems~\cite{eiband_bringing_2018}. They evaluated the process using a commercial AI fitness coach.
Zhu~\etal proposed a co-creation design space between game designers using ML techniques and investigated the usability of XAI algorithms to support game designers~\cite{zhu_explainable_2018}.
Liao~\etal developed an algorithm-informed XAI question bank to support design practices for AI systems~\cite{liao_questioning_2020}.
\review{
Ehsan~\etal investigated how social transparency in AI systems supported sellers from technology companies and developed a conceptual framework to address what, who, why, when questions~\cite{ehsan2021expanding}.
Wolf proposed the concept of scenario-based XAI design and highlighted researchers' need to understand AI systems in specific scenarios such as when researchers are not uncertain or they want to explain data limitations~\cite{wolf_explainability_2019}.
These existing frameworks aim to guide XAI design for developers or domain experts for specific applications.
% Most of these existing frameworks aim to guide XAI design for developers or domain experts for specific applications, rather than non-expert end-users for everyday scenarios.
Focusing on non-expert end-users, Lim and Dey systematically investigated end-users' opinions and preferences about different types of explanations in multiple context-aware applications, and provided an XAI framework for intelligible context-aware systems~\cite{lim_assessing_2009}.
Moreover, recent industry practitioners have also made efforts towards a designing framework for end-user-facing explanations~\cite{ttc_labs}.
}

\input{tex_fig_tab_alg/fig_uniqueness_ar}

Such XAI frameworks focused on the content design of XAI, which is mostly visualized on laptops or mobile phones, thus making them insufficient for the myriad of AR contexts.
There are several factors that distinguish AR from other platforms and necessitate the need for a new XAI design framework (see Fig.~\ref{fig:uniqueness_ar}).
First, AR has a much deeper real-time understanding of a user's current state via the sensors within an HMD~\cite{bonanni2005attention,samadiani2019review}.
Second, compared to other platforms, AR systems can develop a more fine-grained understanding of a user's context~\cite{liu2020deep,grauman2022ego4d,damen2022rescaling}.
This richer information not only provides new types of information that can be integrated into AR-based XAI explanations, but also influences the design of XAI as explanations need to be tailored to a user's state and context.
Third, from an interface perspective, the ability to be always-on and 3D-aware enables AR to present information at any time~\cite{zhu_bishare_2020,lu_glanceable_2021,azuma_survey_1997}, and spatially adapt explanations to the physical world~\cite{feiner1993windows,reitmayr2001mobile}.
% , such as displaying an interface on the wall (world-based) or over a certain object (object-based).
These factors influence the design of XAI in AR, as they need to be presented to users in an appropriate, efficient, and effective way.
Overall, these unique factors demonstrate how current frameworks are insufficient and there is a need for a new XAI framework specifically designed for AR scenarios.
% To the best of our knowledge, there is no prior work investigating this topic.
