\section{Applications}
\label{sec:applications}
% Our framework can support the XAI design of a wide range of everyday AR scenarios. 
In addition to the scenarios in Sec.~\ref{sec:evaluation}, we further illustrate the capability and practicality of XAIR by presenting a series of design examples for everyday AR applications.
We worked with two designers to propose four designs.
The first two (Sec.~\ref{sub:applications:scenario_jogging}-\ref{sub:applications:scenario_driving}) cover different recommendation scenarios, while the rest (Sec.~\ref{sub:applications:scenario_automation}-\ref{sub:applications:scenario_reminder}) show examples of AR automation and reminders besides recommendations.
The details of each scenario can be found in Appendix C.

\input{tex_fig_tab_alg/fig_applications}

\subsection{Scenario 1: Route Recommendation when Jogging}
\label{sub:applications:scenario_jogging}
\textit{Scene}. Nancy (general end-user, low AI literacy) is jogging in the morning. Since it is the cherry-blossom season and Nancy loves cherry, the AR displays a map beside her and recommends a detour that is different from her usual one. Nancy is surprised, but happy to explore it. She is also curious to know why the new route is being recommended.

\colorwhen{\textit{\textbf{When}}}.
\colorwhen{Delivery}. Nancy has enough capacity in this scenario. Her \textit{User Goal} is Resolving Surprise. The explanation is automatically triggered as the two conditions are met (\gthree).

\colorwhat{\textit{\textbf{What}}}.
\colorwhat{Content}. Other than the \textit{User Goal}, the \textit{System Goal} is User Intent Discovery (exploring a new route to see cherry blossom). Considering Nancy's \textit{User Profile} that she is a general end-user, appropriate explanation categories (\gfour) are Input/Output (\eg ``This route is recommended based on seasons, your routine and preferences.'') and Why/Why-Not (\eg ``The route has cherry blossom trees that you can enjoy. The length of the route is appropriate and fits your morning schedule.'').\\
\colorwhat{Detail}. The AR interface shows the Why as default (\gfive), and can be expanded to show both categories in detail upon clicking the ``More'' button (\gsix).

\colorhow{\textit{\textbf{How}}}.
\colorhow{Modality}. The explanation is presented visually, the same as the recommendation (\gseven).\\
\colorhow{Format}. The default explanation uses texts, while the detailed explanation can contain cherry-blossom pictures of the new route to help explain the Why part (\geight).\\
\colorhow{Pattern}. The explanation is shown explicitly with the route recommendation window (\gnine).

\subsection{Scenario 2: Podcast Suggestion while Driving}
\label{sub:applications:scenario_driving}
\textit{Scene}. Jeff (high AI literacy) is about to drive to work. The AR uses audio to recommend a new podcast, "TEDx Shorts", that Jeff is unfamiliar with. However, the topic is interesting and Jeff wants to give it a try. Meanwhile, Jeff is curious to know the reason for this recommendation.

\colorwhen{\textit{\textbf{When}}}.
\colorwhen{Delivery}. Driving is a high-loading task, which does not fit the first condition of \gthree. Therefore, the explanation should wait until Jeff's request (\gtwo) via a simple voice command (\eg ``Why'' or ``Explain''). 

\colorwhat{\textit{\textbf{What}}}.
\colorwhat{Content}. The \textit{System Goal} is similar to Scenario 1 as User Intent Discovery (trying a new podcast). The \textit{User Goal} is Informativeness (Jeff is curious). Jeff's AI literacy is high. According to \gfour, this leads to Input/Output (\eg ``The recommendation takes your playlist history and driving routine into account.''), Why/Why-Not (\eg ``This podcast's topic is in line with your interest, and its length fits your expected driving time.''), and Examples (\eg ```The Daily' and `Fresh Air' are other appropriate examples when you are driving to work.'').\\
\colorwhat{Detail}. Why is the default explanation (\gfive). If Jeff wants more, all three categories can be presented (\gsix).

\colorhow{\textit{\textbf{How}}}.
\colorhow{Modality}. The explanation is presented in the same audio modality as the recommendation (\gseven). In this case, the visual \colorhow{paradigm} factor is no longer applicable.

\subsection{Scenario 3: Automatic Do-Not-Disturb Mode}
\label{sub:applications:scenario_automation}
\textit{Scene}. Richard (high AI literacy) set up an automation setting on AR to improve work efficiency last week. The setting would turn on Do-Not-Disturb mode when he is working in the office during working hours. However, this week Richard didn't remember the setting (shown as a small icon on the vision peripheral), thus he missed a few important messages. Richard is confused about why the Do-Not-Disturb mode is on, and wants to know how he can adjust it.

\colorwhen{\textit{\textbf{When}}}.
\colorwhen{Delivery}. In the office, Richard's capacity is limited as he needs to focus on work. Therefore the explanation waits until Richard needs them (\gtwo).

\colorwhat{\textit{\textbf{What}}}.
\colorwhat{Content}. The system has two goals: User Intent Assistance (improving work efficiency) and Trust Building (aiding Richard to resolve the problem). Richard's goal is Resolving confusion. Since Richard is familiar with AI, this leads to a long list of categories: Input/Output, Why/Why-Not, How, Certainty, and How-To (\gfour). \\
\colorwhat{Detail}. In this case, the default explanation combines Input, Why, and How-To into a short paragraph (\gfive, \eg ``Last week you turned on smart Do-Not-Disturb mode. This setting automatically blocks notifications when you are at the office during working hour and working on the laptop. Click [the button] to change settings.''). The detailed explanation lists all five categories (\gsix).

\colorhow{\textit{\textbf{How}}}.
\colorhow{Modality}. Since the automated mode is shown as an icon, the explanation also uses visual modality  (\gseven). This also applies to the triggering part shown as a button icon near the Do-Not-Disturb mode icon. \\
\colorhow{Format}. These explanation contents are too abstract for graphics, thus the explanation adopted textual format (\geight).\\ 
\colorhow{Pattern}. Related to \colorhow{format}, the textual paragraph is not compatible with the environment. The explanation is presented in an explicit dialogue window (\gnine).

\subsection{Scenario 4: Plant Nutrition Reminder}
\label{sub:applications:scenario_reminder}
\textit{Scene}. Sarah (low AI literacy) chatted with her neighbor about gardening. When she returns home and sits on the sofa, the AR recommends instructions on plant nutrition by showing a caring icon on the plant. Sarah is a bit concerned about technology invading her privacy, and wants to know the reason behind the recommendation.

\colorwhen{\textit{\textbf{When}}}.
\colorwhen{\textit{Delivery}}. Although Sarah has enough capacity in this case, none of the three cases in the second condition of \gthree are met. Therefore, the explanation needs to be manually triggered (\gtwo).

\colorwhat{\textit{\textbf{What}}}.
\colorwhat{Content}. In this case, the \textit{System Goal} is Trust Building (clarifying the usage of data), and the \textit{User Goal} is Privacy Awareness. Sarah's \textit{User Profile} indicates that she is not familiar with AI. According to \gfour, the category list contains Input/Output, Why/Why-Not, and How.\\
\colorwhat{Detail}. Considering Sarah's concern, the default explanation merges Why and How: ``The system scans the plant's visual appearance. It has abnormal spots on the leaves, which indicates fungi or bacteria infection.'' (\gfive).
As for the detailed explanation, the full contents of the three categories are presented in a drop-down list upon users' request (\gsix).

\colorhow{\textit{\textbf{How}}}.
\colorhow{Modality}. Following \gseven, visual modality is adopted for both the explanation and the manual trigger (a button beside the plant caring icon).\\
\colorhow{Format}. Other than using texts as the primary format, the abnormal spots on the leaves are also highlighted via circles to provide an in-situ explanation (\geight).\\
\colorhow{Pattern}. Since the highlighting of spots is compatible with the environment (shown on the plant), it adopts the implicit pattern (\gnine). The rest of the textual part of the explanations uses the explicit pattern.