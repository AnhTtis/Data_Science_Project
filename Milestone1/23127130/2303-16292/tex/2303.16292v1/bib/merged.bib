
@inproceedings{gajos_exploring_2006,
	address = {Venezia, Italy},
	title = {Exploring the design space for adaptive graphical user interfaces},
	isbn = {978-1-59593-353-9},
	url = {http://portal.acm.org/citation.cfm?doid=1133265.1133306},
	doi = {10.1145/1133265.1133306},
	language = {en},
	urldate = {2022-07-11},
	booktitle = {Proceedings of the working conference on {Advanced} visual interfaces  - {AVI} '06},
	publisher = {ACM Press},
	author = {Gajos, Krzysztof Z. and Czerwinski, Mary and Tan, Desney S. and Weld, Daniel S.},
	year = {2006},
	pages = {201},
	file = {Gajos et al. - 2006 - Exploring the design space for adaptive graphical .pdf:/Users/orsonxu/Zotero/storage/57E6AHJU/Gajos et al. - 2006 - Exploring the design space for adaptive graphical .pdf:application/pdf},
}

@inproceedings{lindlbauer_context-aware_2019,
	address = {New Orleans LA USA},
	title = {Context-{Aware} {Online} {Adaptation} of {Mixed} {Reality} {Interfaces}},
	isbn = {978-1-4503-6816-2},
	url = {https://dl.acm.org/doi/10.1145/3332165.3347945},
	doi = {10.1145/3332165.3347945},
	abstract = {We present an optimization-based approach for Mixed Reality (MR) systems to automatically control when and where applications are shown, and how much information they display. Currently, content creators design applications, and users then manually adjust which applications are visible and how much information they show. This choice has to be adjusted every time users switch context, i.e., whenever they switch their task or environment. Since context switches happen many times a day, we believe that MR interfaces require automation to alleviate this problem. We propose a real-time approach to automate this process based on users’ current cognitive load and knowledge about their task and environment. Our system adapts which applications are displayed, how much information they show, and where they are placed. We formulate this problem as a mix of rule-based decision making and combinatorial optimization which can be solved effciently in real-time. We present a set of proof-of-concept applications showing that our approach is applicable in a wide range of scenarios. Finally, we show in a dual-task evaluation that our approach decreased secondary tasks interactions by 36\%.},
	language = {en},
	urldate = {2022-07-15},
	booktitle = {Proceedings of the 32nd {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Lindlbauer, David and Feit, Anna Maria and Hilliges, Otmar},
	month = oct,
	year = {2019},
	pages = {147--160},
	file = {Lindlbauer et al. - 2019 - Context-Aware Online Adaptation of Mixed Reality I.pdf:/Users/orsonxu/Zotero/storage/MWPG2AAF/Lindlbauer et al. - 2019 - Context-Aware Online Adaptation of Mixed Reality I.pdf:application/pdf},
}

@inproceedings{lages_walking_2019,
	address = {Marina del Ray California},
	title = {Walking with adaptive augmented reality workspaces: design and usage patterns},
	isbn = {978-1-4503-6272-6},
	shorttitle = {Walking with adaptive augmented reality workspaces},
	url = {https://dl.acm.org/doi/10.1145/3301275.3302278},
	doi = {10.1145/3301275.3302278},
	abstract = {Mobile augmented reality may eventually replace our smartphones as the primary way of accessing information on the go. However, current interfaces provide little support to walking and to the variety of actions we perform in the real world. To achieve its full potential, augmented reality interfaces must support the fluid way we move and interact in the physical world. We explored how different adaptation strategies can contribute towards this goal. We evaluated design alternatives through contextual studies and identified the key interaction patterns that interfaces for walking should support. We also identified desirable properties of adaptation-based interface techniques, which can be used to guide the design of the next-generation walking-centered augmented reality workspaces.},
	language = {en},
	urldate = {2022-07-15},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Lages, Wallace S. and Bowman, Doug A.},
	month = mar,
	year = {2019},
	pages = {356--366},
	file = {Lages and Bowman - 2019 - Walking with adaptive augmented reality workspaces.pdf:/Users/orsonxu/Zotero/storage/8LHHFKHA/Lages and Bowman - 2019 - Walking with adaptive augmented reality workspaces.pdf:application/pdf},
}

@inproceedings{qian_scalar_2022,
	address = {New Orleans LA USA},
	title = {{ScalAR}: {Authoring} {Semantically} {Adaptive} {Augmented} {Reality} {Experiences} in {Virtual} {Reality}},
	isbn = {978-1-4503-9157-3},
	shorttitle = {{ScalAR}},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517665},
	doi = {10.1145/3491102.3517665},
	abstract = {Augmented Reality (AR) experiences tightly associate virtual contents with environmental entities. However, the dissimilarity of different environments limits the adaptive AR content behaviors under large-scale deployment. We propose ScalAR, an integrated workflow enabling designers to author semantically adaptive AR experiences in Virtual Reality (VR). First, potential AR consumers collect local scenes with a semantic understanding technique. ScalAR then synthesizes numerous similar scenes. In VR, a designer authors the AR contents’ semantic associations and validates the design while being immersed in the provided scenes. We adopt a decision-tree-based algorithm to fit the designer’s demonstrations as a semantic adaptation model to deploy the authored AR experience in a physical scene. We further showcase two application scenarios authored by ScalAR and conduct a two-session user study where the quantitative results prove the accuracy of the AR content rendering and the qualitative results show the usability of ScalAR.},
	language = {en},
	urldate = {2022-07-15},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Qian, Xun and He, Fengming and Hu, Xiyun and Wang, Tianyi and Ipsita, Ananya and Ramani, Karthik},
	month = apr,
	year = {2022},
	pages = {1--18},
	file = {Qian et al. - 2022 - ScalAR Authoring Semantically Adaptive Augmented .pdf:/Users/orsonxu/Zotero/storage/NIUHWNXZ/Qian et al. - 2022 - ScalAR Authoring Semantically Adaptive Augmented .pdf:application/pdf},
}

@inproceedings{huang_adaptutar_2021,
	address = {Yokohama Japan},
	title = {{AdapTutAR}: {An} {Adaptive} {Tutoring} {System} for {Machine} {Tasks} in {Augmented} {Reality}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {{AdapTutAR}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445283},
	doi = {10.1145/3411764.3445283},
	language = {en},
	urldate = {2022-07-15},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Huang, Gaoping and Qian, Xun and Wang, Tianyi and Patel, Fagun and Sreeram, Maitreya and Cao, Yuanzhi and Ramani, Karthik and Quinn, Alexander J.},
	month = may,
	year = {2021},
	pages = {1--15},
	file = {Huang et al. - 2021 - AdapTutAR An Adaptive Tutoring System for Machine.pdf:/Users/orsonxu/Zotero/storage/W2ENEVJU/Huang et al. - 2021 - AdapTutAR An Adaptive Tutoring System for Machine.pdf:application/pdf},
}

@inproceedings{tatzgern_adaptive_2016,
	title = {Adaptive information density for augmented reality displays},
	doi = {10.1109/VR.2016.7504691},
	abstract = {Augmented Reality (AR) browsers show geo-referenced data in the current view of a user. When the amount of data grows too large, the display quickly becomes cluttered. Clustering items by spatial and semantic attributes can temporarily alleviate the issue, but is not effective against an increasing amount of data. We present an adaptive information density display for AR that balances the amount of presented information against the potential clutter created by placing items on the screen. We use hierarchical clustering to create a level-of-detail structure, in which nodes closer to the root encompass groups of items, while the leaf nodes contain single items. Our method selects items and groups from different levels of this hierarchy based on user-defined preferences and on the amount of visual clutter caused by placing these items. The number of presented items is adapted during user interaction to avoid clutter. We compare our interface to a conventional AR browser interface in a qualitative user study. Users clearly preferred our interface, because it provided a better overview of the data and allowed for easier comparison. In a second study, we evaluated the effect of different degrees of clustering on search and recall tasks. Users generally made fewer errors, when using our interface for a search task, which indicates that the reduced clutter allowed them to stay focused on finding the relevant items.},
	booktitle = {2016 {IEEE} {Virtual} {Reality} ({VR})},
	author = {Tatzgern, Markus and Orso, Valeria and Kalkofen, Denis and Jacucci, Giulio and Gamberini, Luciano and Schmalstieg, Dieter},
	month = mar,
	year = {2016},
	note = {ISSN: 2375-5334},
	keywords = {Visualization, Browsers, Clustering algorithms, Clutter, Data visualization, Electronic mail, Semantics},
	pages = {83--92},
	file = {IEEE Xplore Abstract Record:/Users/orsonxu/Zotero/storage/XNIHICME/7504691.html:text/html;IEEE Xplore Full Text PDF:/Users/orsonxu/Zotero/storage/VFJ9AN2W/Tatzgern et al. - 2016 - Adaptive information density for augmented reality.pdf:application/pdf},
}

@inproceedings{lu_exploring_2022,
	address = {New Orleans LA USA},
	title = {Exploring {Spatial} {UI} {Transition} {Mechanisms} with {Head}-{Worn} {Augmented} {Reality}},
	isbn = {978-1-4503-9157-3},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517723},
	doi = {10.1145/3491102.3517723},
	abstract = {Imagine in the future people comfortably wear augmented reality (AR) displays all day, how do we design interfaces that adapt to the contextual changes as people move around? In current operating systems, the majority of AR content defaults to staying at a fxed location until being manually moved by the users. However, this approach puts the burden of user interface (UI) transition solely on users. In this paper, we frst ran a bodystorming design workshop to capture the limitations of existing manual UI transition approaches in spatially diverse tasks. Then we addressed these limitations by designing and evaluating three UI transition mechanisms with different levels of automation and controllability (low-efort manual, semi-automated, fully-automated). Furthermore, we simulated imperfect contextual awareness by introducing prediction errors with diferent costs to correct them. Our results provide valuable lessons about the trade-ofs between UI automation levels, controllability, user agency, and the impact of prediction errors.},
	language = {en},
	urldate = {2022-07-17},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Lu, Feiyu and Xu, Yan},
	month = apr,
	year = {2022},
	pages = {1--16},
	file = {Lu and Xu - 2022 - Exploring Spatial UI Transition Mechanisms with He.pdf:/Users/orsonxu/Zotero/storage/BYKC4GHM/Lu and Xu - 2022 - Exploring Spatial UI Transition Mechanisms with He.pdf:application/pdf},
}

@inproceedings{cheng_semanticadapt_2021,
	title = {{SemanticAdapt}: {Optimization}-based {Adaptation} of {Mixed} {Reality} {Layouts} {Leveraging} {Virtual}-{Physical} {Semantic} {Connections}},
	abstract = {We present an optimization-based approach that automatically adapts Mixed Reality (MR) interfaces to different physical environments. Current MR layouts, including the position and scale of virtual interface elements, need to be manually adapted by users ∗This work was done while Yifei Cheng was an intern at Tsinghua University.},
	language = {en},
	booktitle = {Proceedings of the 34th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	author = {Cheng, Yifei and Yan, Yukang and Yi, Xin and Shi, Yuanchun and Lindlbauer, David},
	year = {2021},
	pages = {16},
	file = {Cheng - 2021 - SemanticAdapt Optimization-based Adaptation of Mi.pdf:/Users/orsonxu/Zotero/storage/4Q4FNCW7/Cheng - 2021 - SemanticAdapt Optimization-based Adaptation of Mi.pdf:application/pdf},
}

@inproceedings{duchowski_index_2018,
	address = {Montreal QC Canada},
	title = {The {Index} of {Pupillary} {Activity}: {Measuring} {Cognitive} {Load} \textit{vis-à-vis} {Task} {Difficulty} with {Pupil} {Oscillation}},
	isbn = {978-1-4503-5620-6},
	shorttitle = {The {Index} of {Pupillary} {Activity}},
	url = {https://dl.acm.org/doi/10.1145/3173574.3173856},
	doi = {10.1145/3173574.3173856},
	abstract = {A novel eye-tracked measure of the frequency of pupil diameter oscillation is proposed for capturing what is thought to be an indicator of cognitive load. The proposed metric, termed the Index of Pupillary Activity, is shown to discriminate task difﬁculty vis-à-vis cognitive load (if the implied causality can be assumed) in an experiment where participants performed easy and difﬁcult mental arithmetic tasks while ﬁxating a central target (a requirement for replication of prior work). The paper’s contribution is twofold: full documentation is provided for the calculation of the proposed measurement which can be considered as an alternative to the existing proprietary Index of Cognitive Activity (ICA). Thus, it is possible for researchers to replicate the experiment and build their own software which implements this measurement. Second, several aspects of the ICA are approached in a more data-sensitive way with the goal of improving the measurement’s performance.},
	language = {en},
	urldate = {2022-07-20},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Duchowski, Andrew T. and Krejtz, Krzysztof and Krejtz, Izabela and Biele, Cezary and Niedzielska, Anna and Kiefer, Peter and Raubal, Martin and Giannopoulos, Ioannis},
	month = apr,
	year = {2018},
	pages = {1--13},
	file = {Duchowski et al. - 2018 - The Index of Pupillary Activity Measuring Cogniti.pdf:/Users/orsonxu/Zotero/storage/YEHGLN9S/Duchowski et al. - 2018 - The Index of Pupillary Activity Measuring Cogniti.pdf:application/pdf},
}


@inproceedings{zhu_bishare_2020,
	address = {Honolulu HI USA},
	title = {{BISHARE}: {Exploring} {Bidirectional} {Interactions} {Between} {Smartphones} and {Head}-{Mounted} {Augmented} {Reality}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {{BISHARE}},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376233},
	doi = {10.1145/3313831.3376233},
	abstract = {In pursuit of a future where HMD devices can be used in tandem with smartphones and other smart devices, we present BISHARE, a design space of cross-device interactions between smartphones and ARHMDs. Our design space is unique in that it is bidirectional in nature, as it examines how both the HMD can be used to enhance smartphone tasks, and how the smartphone can be used to enhance HMD tasks. We then present an interactive prototype that enables cross-device interactions across the proposed design space. A 12-participant user study demonstrates the promise of the design space and provides insights, observations, and guidance for the future.},
	language = {en},
	urldate = {2022-07-11},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Zhu, Fengyuan and Grossman, Tovi},
	month = apr,
	year = {2020},
	pages = {1--14},
	file = {Zhu and Grossman - 2020 - BISHARE Exploring Bidirectional Interactions Betw.pdf:/Users/orsonxu/Zotero/storage/7MS5EW4A/Zhu and Grossman - 2020 - BISHARE Exploring Bidirectional Interactions Betw.pdf:application/pdf},
}

@inproceedings{bailly_livingdesktop_2016,
	address = {San Jose California USA},
	title = {{LivingDesktop}: {Augmenting} {Desktop} {Workstation} with {Actuated} {Devices}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {{LivingDesktop}},
	url = {https://dl.acm.org/doi/10.1145/2858036.2858208},
	doi = {10.1145/2858036.2858208},
	abstract = {We investigate the potential beneﬁts of actuated devices for the desktop workstation which remains the most used environment for daily ofﬁce works. A formative study reveals that the desktop workstation is not a ﬁxed environment because users manually change the position and the orientation of their devices. Based on these ﬁndings, we present the LivingDesktop, an augmented desktop workstation with devices (mouse, keyboard, monitor) capable of moving autonomously. We describe interaction techniques and applications illustrating how actuated desktop workstations can improve ergonomics, foster collaboration, leverage context and reinforce physicality. Finally, the ﬁndings of a scenario evaluation are (1) the perceived usefulness of ergonomics and collaboration applications; (2) how the LivingDesktop inspired our participants to elaborate novel accessibility and social applications; (3) the location and user practices should be considered when designed actuated desktop devices.},
	language = {en},
	urldate = {2022-07-11},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Bailly, Gilles and Sahdev, Sidharth and Malacria, Sylvain and Pietrzak, Thomas},
	month = may,
	year = {2016},
	pages = {5298--5310},
	file = {Bailly et al. - 2016 - LivingDesktop Augmenting Desktop Workstation with.pdf:/Users/orsonxu/Zotero/storage/KQTMV7X5/Bailly et al. - 2016 - LivingDesktop Augmenting Desktop Workstation with.pdf:application/pdf},
}

@misc{lee_all_2021,
	title = {All {One} {Needs} to {Know} about {Metaverse}: {A} {Complete} {Survey} on {Technological} {Singularity}, {Virtual} {Ecosystem}, and {Research} {Agenda}},
	shorttitle = {All {One} {Needs} to {Know} about {Metaverse}},
	url = {http://arxiv.org/abs/2110.05352},
	abstract = {Since the popularisation of the Internet in the 1990s, the cyberspace has kept evolving. We have created various computer-mediated virtual environments including social networks, video conferencing, virtual 3D worlds (e.g., VR Chat), augmented reality applications (e.g., Pokemon Go), and Non-Fungible Token Games (e.g., Upland). Such virtual environments, albeit non-perpetual and unconnected, have bought us various degrees of digital transformation. The term `metaverse' has been coined to further facilitate the digital transformation in every aspect of our physical lives. At the core of the metaverse stands the vision of an immersive Internet as a gigantic, unified, persistent, and shared realm. While the metaverse may seem futuristic, catalysed by emerging technologies such as Extended Reality, 5G, and Artificial Intelligence, the digital `big bang' of our cyberspace is not far away. This survey paper presents the first effort to offer a comprehensive framework that examines the latest metaverse development under the dimensions of state-of-the-art technologies and metaverse ecosystems, and illustrates the possibility of the digital `big bang'. First, technologies are the enablers that drive the transition from the current Internet to the metaverse. We thus examine eight enabling technologies rigorously - Extended Reality, User Interactivity (Human-Computer Interaction), Artificial Intelligence, Blockchain, Computer Vision, IoT and Robotics, Edge and Cloud computing, and Future Mobile Networks. In terms of applications, the metaverse ecosystem allows human users to live and play within a self-sustaining, persistent, and shared realm. Therefore, we discuss six user-centric factors -- Avatar, Content Creation, Virtual Economy, Social Acceptability, Security and Privacy, and Trust and Accountability. Finally, we propose a concrete research agenda for the development of the metaverse.},
	urldate = {2022-07-17},
	publisher = {arXiv},
	author = {Lee, Lik-Hang and Braud, Tristan and Zhou, Pengyuan and Wang, Lin and Xu, Dianlei and Lin, Zijun and Kumar, Abhishek and Bermejo, Carlos and Hui, Pan},
	month = nov,
	year = {2021},
	note = {Number: arXiv:2110.05352
arXiv:2110.05352 [cs]},
	keywords = {A.1, Computer Science - Computers and Society, K.0},
	file = {arXiv Fulltext PDF:/Users/orsonxu/Zotero/storage/HS2AFIW5/Lee et al. - 2021 - All One Needs to Know about Metaverse A Complete .pdf:application/pdf;arXiv.org Snapshot:/Users/orsonxu/Zotero/storage/Z5H5LXVX/2110.html:text/html},
}

@inproceedings{lam_a2w_2021,
	address = {Virtual Event China},
	title = {{A2W}: {Context}-{Aware} {Recommendation} {System} for {Mobile} {Augmented} {Reality} {Web} {Browser}},
	isbn = {978-1-4503-8651-7},
	shorttitle = {{A2W}},
	url = {https://dl.acm.org/doi/10.1145/3474085.3475413},
	doi = {10.1145/3474085.3475413},
	abstract = {Augmented Reality (AR) offers new capabilities for blurring the boundaries between physical reality and digital media. However, the capabilities of integrating web contents and AR remain underexplored. This paper presents an AR web browser with an integrated context-aware AR-to-Web content recommendation service named as A2W browser, to provide continuously user-centric web browsing experiences driven by AR headsets. We implement the A2W browser on an AR headset as our demonstration application, demonstrating the features and performance of A2W framework. The A2W browser visualizes the AR-driven web contents to the user, which is suggested by the content-based filtering model in our recommendation system. In our experiments, 20 participants with the adaptive UIs and recommendation system in A2W browser achieve up to 30.69\% time saving compared to smartphone conditions. Accordingly, A2W-supported web browsing on workstations facilitates the recommended information leading to 41.67\% faster reaches to the target information than typical web browsing.},
	language = {en},
	urldate = {2022-07-17},
	booktitle = {Proceedings of the 29th {ACM} {International} {Conference} on {Multimedia}},
	publisher = {ACM},
	author = {Lam, Kit Yung and Lee, Lik Hang and Hui, Pan},
	month = oct,
	year = {2021},
	pages = {2447--2455},
	file = {Lam et al. - 2021 - A2W Context-Aware Recommendation System for Mobil.pdf:/Users/orsonxu/Zotero/storage/EBRYVWP5/Lam et al. - 2021 - A2W Context-Aware Recommendation System for Mobil.pdf:application/pdf},
}

@article{azuma_survey_1997,
	title = {A {Survey} of {Augmented} {Reality}},
	abstract = {This paper surveys the field of Augmented Reality, in which 3-D virtual objects are integrated into a 3-D real environment in real time. It describes the medical, manufacturing, visualization, path planning, entertainment and military applications that have been explored. This paper describes the characteristics of Augmented Reality systems, including a detailed discussion of the tradeoffs between optical and video blending approaches. Registration and sensing errors are two of the biggest problems in building effective Augmented Reality systems, so this paper summarizes current efforts to overcome these problems. Future directions and areas requiring further research are discussed. This survey provides a starting point for anyone interested in researching or using Augmented Reality.},
	language = {en},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Azuma, Ronald T},
	year = {1997},
	pages = {48},
	file = {Azuma - A Survey of Augmented Reality.pdf:/Users/orsonxu/Zotero/storage/V857WH2B/Azuma - A Survey of Augmented Reality.pdf:application/pdf},
}

@article{billinghurst_survey_2015,
	title = {A {Survey} of {Augmented} {Reality}},
	volume = {8},
	issn = {1551-3955, 1551-3963},
	url = {http://www.nowpublishers.com/article/Details/HCI-049},
	doi = {10.1561/1100000049},
	abstract = {This survey summarizes almost 50 years of research and development in the ﬁeld of Augmented Reality (AR). From early research in the 1960’s until widespread availability by the 2010’s there has been steady progress towards the goal of being able to seamlessly combine real and virtual worlds. We provide an overview of the common deﬁnitions of AR, and show how AR ﬁts into taxonomies of other related technologies. A history of important milestones in Augmented Reality is followed by sections on the key enabling technologies of tracking, display and input devices. We also review design guidelines and provide some examples of successful AR applications. Finally, we conclude with a summary of directions for future work and a review of some of the areas that are currently being researched.},
	language = {en},
	number = {2-3},
	urldate = {2022-07-17},
	journal = {Foundations and Trends® in Human–Computer Interaction},
	author = {Billinghurst, Mark and Clark, Adrian and Lee, Gun},
	year = {2015},
	pages = {73--272},
	file = {Billinghurst et al. - 2015 - A Survey of Augmented Reality.pdf:/Users/orsonxu/Zotero/storage/6T3XLZEX/Billinghurst et al. - 2015 - A Survey of Augmented Reality.pdf:application/pdf},
}

@article{carmigniani_augmented_2011,
	title = {Augmented reality technologies, systems and applications},
	volume = {51},
	issn = {1380-7501, 1573-7721},
	url = {http://link.springer.com/10.1007/s11042-010-0660-6},
	doi = {10.1007/s11042-010-0660-6},
	abstract = {This paper surveys the current state-of-the-art of technology, systems and applications in Augmented Reality. It describes work performed by many different research groups, the purpose behind each new Augmented Reality system, and the difficulties and problems encountered when building some Augmented Reality applications. It surveys mobile augmented reality systems challenges and requirements for successful mobile systems. This paper summarizes the current applications of Augmented Reality and speculates on future applications and where current research will lead Augmented Reality’s development. Challenges augmented reality is facing in each of these applications to go from the laboratories to the industry, as well as the future challenges we can forecast are also discussed in this paper. Section 1 gives an introduction to what Augmented Reality is and the motivations for developing this technology. Section 2 discusses Augmented Reality Technologies with computer vision methods, AR devices, interfaces and systems, and visualization tools. The mobile and wireless systems for Augmented Reality are discussed in Section 3. Four classes of current applications that have been explored are described in Section 4. These applications were chosen as they are the most famous type of applications encountered when researching AR apps. The future of augmented reality and the challenges they will be facing are discussed in Section 5.},
	language = {en},
	number = {1},
	urldate = {2022-07-17},
	journal = {Multimedia Tools and Applications},
	author = {Carmigniani, Julie and Furht, Borko and Anisetti, Marco and Ceravolo, Paolo and Damiani, Ernesto and Ivkovic, Misa},
	month = jan,
	year = {2011},
	pages = {341--377},
	file = {Carmigniani et al. - 2011 - Augmented reality technologies, systems and applic.pdf:/Users/orsonxu/Zotero/storage/PEWV3NNF/Carmigniani et al. - 2011 - Augmented reality technologies, systems and applic.pdf:application/pdf},
}

@inproceedings{tanya_r_jonker_role_2020,
	title = {The role of {AI} in mixed and augmented reality interactions},
	shorttitle = {{CHI}'20},
	url = {https://doi.org/10.1145/3334480},
	language = {en},
	urldate = {2022-07-19},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} {Workshop}: "{Artificial} {Intelligence}: {A} {Modern} {Approach}"},
	author = {{Tanya R. Jonker} and {Ruta Desai} and {Kevin Carlberg} and {James Hillis} and {Sean Keller} and {Hrvoje Benko}},
	year = {2020},
	note = {OCLC: 1175624697},
	file = {CHI Conference et al. - 2020 - CHI'20 extended abstracts of the 2020 CHI Confere.pdf:/Users/orsonxu/Zotero/storage/PX4VR5P4/CHI Conference et al. - 2020 - CHI'20 extended abstracts of the 2020 CHI Confere.pdf:application/pdf},
}

@article{sahu_artificial_2020,
	title = {Artificial intelligence ({AI}) in augmented reality ({AR})-assisted manufacturing applications: a review},
	volume = {59},
	shorttitle = {Artificial intelligence ({AI}) in augmented reality ({AR})-assisted manufacturing applications},
	doi = {10.1080/00207543.2020.1859636},
	abstract = {Augmented reality (AR) has proven to be an invaluable interactive medium to reduce cognitive load by bridging the gap between the task-at-hand and relevant information by displaying information without disturbing the user's focus. AR is particularly useful in the manufacturing environment where a diverse set of tasks such as assembly and maintenance must be performed in the most cost-effective and efficient manner possible. While AR systems have seen immense research innovation in recent years, the current strategies utilised in AR for camera calibration, detection, tracking, camera position and orientation (pose) estimation, inverse rendering, procedure storage, virtual object creation, registration, and rendering are still mostly dominated by traditional non-AI approaches. This restricts their practicability to controlled environments with limited variations in the scene. Classical AR methods can be greatly improved through the incorporation of various AI strategies like deep learning, ontology, and expert systems for adapting to broader scene variations and user preferences. This research work provides a review of current AR strategies, critical appraisal for these strategies, and potential AI solutions for every component of the computational pipeline of AR systems. Given the review of current work in both fields, future research work directions are also outlined.},
	journal = {International Journal of Production Research},
	author = {Sahu, Chandan Kumar and Young, Crystal and Rai, Rahul},
	month = dec,
	year = {2020},
	pages = {1--57},
}

@article{sutherland_head-mounted_1968,
	title = {A head-mounted three dimensional display},
	language = {en},
	journal = {Fall Joint Computer Conference},
	author = {Sutherland, Ivan E},
	year = {1968},
	pages = {8},
	file = {Sutherland - A head-mounted three dimensional display.pdf:/Users/orsonxu/Zotero/storage/GKZF4UX5/Sutherland - A head-mounted three dimensional display.pdf:application/pdf},
}

@article{grubert2016towards,
  title={Towards pervasive augmented reality: Context-awareness in augmented reality},
  author={Grubert, Jens and Langlotz, Tobias and Zollmann, Stefanie and Regenbrecht, Holger},
  journal={IEEE transactions on visualization and computer graphics},
  volume={23},
  number={6},
  pages={1706--1724},
  year={2016},
  publisher={IEEE}
}


@article{Leslie2019,
	title = {Engineering {Music} to {Slow} {Breathing} and {Invite} {Relaxed} {Physiology}},
	doi = {10.1109/ACII.2019.8925531},
	abstract = {We engineered an interactive music system that influences a user's breathing rate to induce a relaxation response. This system generates ambient music containing periodic shifts in loudness that are determined by the user's own breathing patterns. We evaluated the efficacy of this music intervention for participants who were engaged in an attention-demanding task, and thus explicitly not focusing on their breathing or on listening to the music. We measured breathing patterns in addition to multiple peripheral and cortical indicators of physiological arousal while users experienced three different interaction designs: (1) a 'Fixed Tempo' amplitude modulation rate at six beats per minute; (2) a 'Personalized Tempo' modulation rate fixed at 75\% of each individual's breathing rate baseline, and (3) a 'Personalized Envelope' design in which the amplitude modulation matches each individual's breathing pattern in real-time. Our results revealed that each interactive music design slowed down breathing rates, with the 'Personalized Tempo' design having the largest effect, one that was more significant than the non-personalized design. The physiological arousal indicators (electrodermal activity, heart rate, and slow cortical potentials measured in EEG) showed concomitant reductions, suggesting that slowing users' breathing rates shifted them towards a more calmed state. These results suggest that interactive music incorporating biometric data may have greater effects on physiology than traditional recorded music.},
	journal = {2019 8th International Conference on Affective Computing and Intelligent Interaction, ACII 2019},
	author = {Leslie, Grace and Ghandeharioun, Asma and Zhou, Diane and Picard, Rosalind W.},
	year = {2019},
	note = {ISBN: 9781728138886},
	keywords = {Breathing, ECG, EDA, EEG, Intervention, Music, Relaxation, Stress},
	pages = {276--282},
	file = {Leslie et al_2019_Engineering Music to Slow Breathing and Invite Relaxed Physiology.pdf:/Users/orsonxu/Zotero/storage/WHS3RDW8/Leslie et al_2019_Engineering Music to Slow Breathing and Invite Relaxed Physiology.pdf:application/pdf;Leslie et al_2019_Engineering Music to Slow Breathing and Invite Relaxed Physiology.pdf:/Users/orsonxu/Zotero/storage/6N7E6MJG/Leslie et al_2019_Engineering Music to Slow Breathing and Invite Relaxed Physiology.pdf:application/pdf},
}

@article{Pisa2017,
	title = {Towards interactive mindfulness training using breathing based feedback},
	doi = {10.1145/3123024.3129268},
	abstract = {Although regular meditation practice is linked to numerous mental health and cognitive benefits, it is often difficult for beginners to maintain focus during practice and persevere with the activity over time. To tackle this issue, we externalised the ability of self reporting loss of focus by developing a feedback loop that helps the user track and maintain their concentration levels in a non-invasive manner. We hypothesise that the change in breathing pattern can indicate a loss of concentration and the act of audibly amplifying a person's breathing sounds during meditation can help them regain and maintain focus on their breathing, leading to a more effective meditation session. We present experimental designs and findings towards this end. Copyright held by the owner/author(s).},
	journal = {UbiComp/ISWC 2017 - Adjunct Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International Symposium on Wearable Computers},
	author = {Pisa, Andrea M. and Chernyshov, George and Nassou, Andriana F. and Kunze, Kai},
	year = {2017},
	note = {ISBN: 9781450351904},
	keywords = {Attention, Biosignals, Breathing feedback, Focus, Interactivity, Meditation, Mindfulness, Self-regulation process},
	pages = {688--692},
	file = {Pisa et al_2017_Towards interactive mindfulness training using breathing based feedback.pdf:/Users/orsonxu/Zotero/storage/S9ZB748W/Pisa et al_2017_Towards interactive mindfulness training using breathing based feedback.pdf:application/pdf;Pisa et al_2017_Towards interactive mindfulness training using breathing based feedback.pdf:/Users/orsonxu/Zotero/storage/7D4F7TNG/Pisa et al_2017_Towards interactive mindfulness training using breathing based feedback.pdf:application/pdf},
}

@article{Holman2018,
	title = {Stress management interventions: improving subjective psychological well-being in the workplace},
	volume = {5},
	abstract = {In this chapter we provide an overview of stress management interventions (SMI) and review the evidence for their effects on employee stress and well-being. We start by setting out a typology of SMI that classes SMI according to level (i.e., the individual-level or organisation-level) and focus (i.e., a 'primary' focus on altering the causes of stress or a 'secondary' or 'tertiary' focus on reducing stress itself). We then use this typology to describe key types of SMI, after which we review the evidence for those SMI with the most extensive evidence bases, namely secondary individual-level SMI that seek to reduce stress in employees (e.g., relaxation techniques, cognitive-behavioral therapy, mindfulness training) and primary organisational-level SMI that seek to remove the causes of stress by changing organisational practices (e.g., job redesign, changes to working time schedules). We conclude by suggesting that there is convincing evidence for both of these SMI approaches. However, the evidence base needs strengthening through more robust methodological designs (e.g., randomised control trials, broad based evaluations of intervention processes) and a better understanding of the contexts and individuals in which SMIs are most effective, how the implementation of SMIs affects outcomes, and the long-term impacts of SMIs. 1 Keywords: stress management interventions, evaluation, review, cognitive-behavioral therapy, mindfulness training, job redesign Improving employee well-being and reducing stress can have a number of benefits for organizations, from increasing performance, improving relationships, to reducing sickness and absenteeism rates (De Neve, Diener, Tay \& Xuereb, 2013; Warr, 2003). Stress management interventions refer to a class of activities that are used by organizations to improve employee well-being and reduce stress, principally by either addressing the causes of stress or by reducing the impact of stress on an individual. The aim of this chapter is to review the literature on stress management interventions to establish what we know about the effectiveness of different interventions in improving psychological well-being. It is split into three main sections. First, we introduce a typology of stress management interventions (SMI) and provide examples of the different types of intervention. Second, we discuss the evidence concerning the effectiveness of SMI, although before this we will briefly discuss methodological considerations used when evaluating interventions to provide the reader with some grounds for understanding the quality of evidence in this area. Finally, we conclude the chapter with an overview of what works best. When reviewing the literature, we use a broad definition of subjective psychological well-being which enables us to include studies on burnout, anxiety, and depression, for example, as well as studies focusing directly on positive psychological well-being. Furthermore, as we are interested in psychological well-being we do not include studies that have looked at physical health or job attitudes, or those on well-being related outcomes at the organizational-level such as sickness and absenteeism. However, it is worth noting that these outcomes are related such that improvements in psychological well-being can lead to improvements in health, job satisfaction and absenteeism rates.},
	journal = {Handbook of well-being},
	author = {Holman, D and Johnson, S and O' Connor, E},
	year = {2018},
	keywords = {a number of benefits, absenteeism, cognitive-behavioral therapy, evaluation, for, from increasing performance, improving employee well-being and, improving relationships, job redesign, mindfulness training, organizations, reducing stress can have, review, stress management interventions, to reducing sickness and},
	pages = {1--13},
	file = {Holman et al_2018_Stress management interventions.pdf:/Users/orsonxu/Zotero/storage/ZH7NM9TA/Holman et al_2018_Stress management interventions.pdf:application/pdf;Holman et al_2018_Stress management interventions.pdf:/Users/orsonxu/Zotero/storage/GMLP9ZSQ/Holman et al_2018_Stress management interventions.pdf:application/pdf},
}

@article{Paredes2014,
	title = {{PopTherapy}: {Coping} with {Stress} through {Pop} {Culture}},
	journal = {Proceedings of the International Conference on Pervasive Computing Technologies for Healthcare},
	author = {Paredes, Pablo and Gilad-bachrach, Ran and Czerwinski, Mary and Roseway, Asta and Hernandez, Javier},
	year = {2014},
	file = {Paredes et al_2014_PopTherapy.pdf:/Users/orsonxu/Zotero/storage/S9FII5PX/Paredes et al_2014_PopTherapy.pdf:application/pdf;Paredes et al_2014_PopTherapy.pdf:/Users/orsonxu/Zotero/storage/KYQ3IFVG/Paredes et al_2014_PopTherapy.pdf:application/pdf},
}

@article{Kunzler2019,
	title = {Exploring the {State}-of-{Receptivity} for {mHealth} {Interventions}},
	volume = {3},
	issn = {2474-9567},
	doi = {10.1145/3369805},
	abstract = {Recent advancements in sensing techniques for mHealth applications have led to successful development and deployments of several mHealth intervention designs, including Just-In-Time Adaptive Interventions (JITAI). JITAIs show great potential because they aim to provide the right type and amount of support, at the right time. Timing the delivery of a JITAI such as the user is receptive and available to engage with the intervention is crucial for a JITAI to succeed. Although previous research has extensively explored the role of context in users’ responsiveness towards generic phone notifications, it has not been thoroughly explored for actual mHealth interventions. In this work, we explore the factors affecting users’ receptivity towards JITAIs. To this end, we conducted a study with 189 participants, over a period of 6 weeks, where participants received interventions to improve their physical activity levels. The interventions were delivered by a chatbot-based digital coach -Ally - which was available on Android and iOS platforms. We define several metrics to gauge receptivity towards the interventions, and found that (1) several participant-specific characteristics (age, personality, and device type) show significant associations with the overall participant receptivity over the course of the study, and that (2) several contextual factors (day/time, phone battery, phone interaction, physical activity, and location), show significant associations with the participant receptivity, in-the-moment. Further, we explore the relationship between the effectiveness of the intervention and receptivity towards those interventions; based on our analyses, we speculate that being receptive to interventions helped participants achieve physical activity goals, which in turn motivated participants to be more receptive to future interventions. Finally, we build machine-learning models to detect receptivity, with up to a 77\% increase in F1 score over a biased random classifier.},
	number = {4},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Künzler, Florian and Mishra, Varun and Kramer, Jan-Niklas and Kotz, David and Fleisch, Elgar and Kowatsch, Tobias},
	year = {2019},
	keywords = {Intervention, Interruption, Mobile He, Receptivity},
	pages = {1--27},
	file = {Künzler et al_2019_Exploring the State-of-Receptivity for mHealth Interventions.pdf:/Users/orsonxu/Zotero/storage/8DYDJWI3/Künzler et al_2019_Exploring the State-of-Receptivity for mHealth Interventions.pdf:application/pdf;Künzler et al_2019_Exploring the State-of-Receptivity for mHealth Interventions.pdf:/Users/orsonxu/Zotero/storage/7BYB2EWW/Künzler et al_2019_Exploring the State-of-Receptivity for mHealth Interventions.pdf:application/pdf},
}

@article{Creswell2017,
	title = {Mindfulness {Interventions}},
	volume = {68},
	issn = {0066-4308},
	url = {http://www.annualreviews.org/doi/10.1146/annurev-psych-042716-051139},
	doi = {10.1146/annurev-psych-042716-051139},
	abstract = {Mindfulness interventions aim to foster greater attention to and awareness of present moment experience. There has been a dramatic increase in randomized controlled trials (RCTs) of mindfulness interventions over the past two decades. This article evaluates the growing evidence of mindfulness intervention RCTs by reviewing and discussing (a) the effects of mindfulness interventions on health, cognitive, affective, and interpersonal outcomes; (b) evidence-based applications of mindfulness interventions to new settings and populations (e.g., the workplace, military, schools); (c) psychological and neurobiological mechanisms of mindfulness interventions; (d) mindfulness intervention dosing considerations; and (e) potential risks of mindfulness interventions. Methodologically rigorous RCTs have demonstrated that mindfulness interventions improve outcomes in multiple domains (e.g., chronic pain, depression relapse, addiction). Discussion focuses on opportunities and challenges for mindfulness intervention research and on community applications.},
	number = {1},
	journal = {Annual Review of Psychology},
	author = {Creswell, J. David},
	month = jan,
	year = {2017},
	pmid = {27687118},
	keywords = {Meditation, Mindfulness, Health, Randomized controlled trial, Review},
	pages = {491--516},
	file = {Creswell_2017_Mindfulness Interventions.pdf:/Users/orsonxu/Zotero/storage/UUHVG8R7/Creswell_2017_Mindfulness Interventions.pdf:application/pdf;Creswell_2017_Mindfulness Interventions.pdf:/Users/orsonxu/Zotero/storage/NN9EA28V/Creswell_2017_Mindfulness Interventions.pdf:application/pdf},
}

@article{Baer2003,
	title = {Mindfulness {Training} as a {Clinical} {Intervention}: {A} {Conceptual} and {Empirical} {Review}},
	volume = {10},
	issn = {0969-5893},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1093/clipsy.bpg015},
	doi = {10.1093/clipsy.bpg015},
	abstract = {Mindfulness interventions aim to foster greater attention to and awareness of present moment experience. There has been a dramatic increase in randomized controlled trials (RCTs) of mindfulness interventions over the past two decades. This article evaluates the growing evidence of mindfulness intervention RCTs by reviewing and discussing (a) the effects of mindfulness interventions on health, cognitive, affective, and interpersonal outcomes; (b) evidence-based applications of mindfulness interventions to new settings and populations (e.g., the workplace, military, schools); (c) psychological and neurobiological mechanisms of mindfulness interventions; (d) mindfulness intervention dosing considerations; and (e) potential risks of mindfulness interventions. Methodologically rigorous RCTs have demonstrated that mindfulness interventions improve outcomes in multiple domains (e.g., chronic pain, depression relapse, addiction). Discussion focuses on opportunities and challenges for mindfulness intervention research and on community applications.},
	number = {2},
	journal = {Clinical Psychology: Science and Practice},
	author = {Baer, Ruth A.},
	month = jun,
	year = {2003},
	pmid = {27687118},
	keywords = {Meditation, Mindfulness, Health, Randomized controlled trial, Review},
	pages = {125--143},
	file = {Baer_2003_Mindfulness Training as a Clinical Intervention.pdf:/Users/orsonxu/Zotero/storage/M2BMZJZ6/Baer_2003_Mindfulness Training as a Clinical Intervention.pdf:application/pdf;Baer_2003_Mindfulness Training as a Clinical Intervention.pdf:/Users/orsonxu/Zotero/storage/P4G2H6P2/Baer_2003_Mindfulness Training as a Clinical Intervention.pdf:application/pdf},
}

@article{Brady2016,
	title = {Old dog, new tricks: treating co-occurring anxiety and alcohol use disorders},
	volume = {42},
	issn = {10979891},
	doi = {10.1080/00952990.2016.1188935},
	number = {5},
	journal = {American Journal of Drug and Alcohol Abuse},
	author = {Brady, Kathleen T.},
	year = {2016},
	pmid = {27314615},
	pages = {479--480},
	file = {Brady_2016_Old dog, new tricks.pdf:/Users/orsonxu/Zotero/storage/QM7XHSDG/Brady_2016_Old dog, new tricks.pdf:application/pdf;Brady_2016_Old dog, new tricks.pdf:/Users/orsonxu/Zotero/storage/5R3WJXJT/Brady_2016_Old dog, new tricks.pdf:application/pdf},
}

@article{Chiesa2009,
	title = {Mindfulness-based stress reduction for stress management in healthy people: {A} review and meta-analysis},
	volume = {15},
	issn = {10755535},
	doi = {10.1089/acm.2008.0495},
	abstract = {Background: Mindfulness-based stress reduction (MBSR) is a clinically standardized meditation that has shown consistent efficacy for many mental and physical disorders. Less attention has been given to the possible benefits that it may have in healthy subjects. The aim of the present review and meta-analysis is to better investigate current evidence about the efficacy of MBSR in healthy subjects, with a particular focus on its benefits for stress reduction. Materials and methods: A literature search was conducted using MEDLINE (PubMed), the ISI Web of Knowledge, the Cochrane database, and the references of retrieved articles. The search included articles written in English published prior to September 2008, and identified ten, mainly low-quality, studies. Cohen's d effect size between meditators and controls on stress reduction and spirituality enhancement values were calculated. Results: MBSR showed a nonspecific effect on stress reduction in comparison to an inactive control, both in reducing stress and in enhancing spirituality values, and a possible specific effect compared to an intervention designed to be structurally equivalent to the meditation program. A direct comparison study between MBSR and standard relaxation training found that both treatments were equally able to reduce stress. Furthermore, MBSR was able to reduce ruminative thinking and trait anxiety, as well as to increase empathy and self-compassion. Conclusions: MBSR is able to reduce stress levels in healthy people. However, important limitations of the included studies as well as the paucity of evidence about possible specific effects of MBSR in comparison to other nonspecific treatments underline the necessity of further research. © 2009 Mary Ann Liebert, Inc.},
	number = {5},
	journal = {Journal of Alternative and Complementary Medicine},
	author = {Chiesa, Alberto and Serretti, Alessandro},
	year = {2009},
	pmid = {19432513},
	pages = {593--600},
	file = {Chiesa_Serretti_2009_Mindfulness-based stress reduction for stress management in healthy people.pdf:/Users/orsonxu/Zotero/storage/VAUQWXJK/Chiesa_Serretti_2009_Mindfulness-based stress reduction for stress management in healthy people.pdf:application/pdf;Chiesa_Serretti_2009_Mindfulness-based stress reduction for stress management in healthy people.pdf:/Users/orsonxu/Zotero/storage/UZG4DSQU/Chiesa_Serretti_2009_Mindfulness-based stress reduction for stress management in healthy people.pdf:application/pdf},
}

@article{Visuri2019,
	title = {Understanding smartphone notifications’ user interactions and content importance},
	volume = {128},
	issn = {10959300},
	url = {https://doi.org/10.1016/j.ijhcs.2019.03.001},
	doi = {10.1016/j.ijhcs.2019.03.001},
	abstract = {We present the results of our experiment aimed to comprehensively understand the combination of 1) how smartphone users interact with their notifications, 2) what notification content is considered important, 3) the complex relationship between the interaction choices and content importance, and lastly 4) establish an intelligent method to predict user's preference to seeing an incoming notification. We use a dataset of notifications received by 40 anonymous users in-the-wild, which consists of 1) qualitative user-labelled information about their preferences on notification's contents, 2) notification source, and 3) the context in which the notification was received. We assess the effectiveness of personalised prediction models generated using a combination of self-reported content importance and contextual information. We uncover four distinct user types, based on the number of daily notifications and interaction choices. We showcase how usage traits of these groups highlight the requirement for notification filtering approaches, e.g., when specific users habitually neglect to manually filter out unimportant notifications. Our machine learning-based predictor, based on both contextual sensing and notification contents can predict the user's preference for successfully acknowledging an incoming notification with 91.1\% mean accuracy, crucial for time-critical user engagement and interventions.},
	number = {March},
	journal = {International Journal of Human Computer Studies},
	author = {Visuri, Aku and van Berkel, Niels and Okoshi, Tadashi and Goncalves, Jorge and Kostakos, Vassilis},
	year = {2019},
	note = {Publisher: Elsevier Ltd},
	keywords = {Interactions, Machine learning, Notifications, Semantic analysis, Smartphone},
	pages = {72--85},
	file = {Visuri et al_2019_Understanding smartphone notifications’ user interactions and content importance.pdf:/Users/orsonxu/Zotero/storage/BTDJGVF7/Visuri et al_2019_Understanding smartphone notifications’ user interactions and content importance.pdf:application/pdf;Visuri et al_2019_Understanding smartphone notifications’ user interactions and content importance.pdf:/Users/orsonxu/Zotero/storage/6EQRGRJ8/Visuri et al_2019_Understanding smartphone notifications’ user interactions and content importance.pdf:application/pdf},
}

@article{Rabbi2015,
	title = {{MyBehavior}: {Automatic} {Personalized} {Health} {Feedback} from {User} {Behaviors} and {Preferences} using {Smartphones}},
	doi = {10.1145/2750858.2805840},
	abstract = {Mobile sensing systems have made significant advances in tracking human behavior. However, the development of personalized mobile health feedback systems is still in its infancy. This paper introduces MyBehavior, a smartphone application that takes a novel approach to generate deeply personalized health feedback. It combines state-of-the-art behavior tracking with algorithms that are used in recommendation systems. MyBehavior automatically learns a user's physical activity and dietary behavior and strategically suggests changes to those behaviors for a healthier lifestyle. The system uses a sequential decision making algorithm, Multi-armed Bandit, to generate suggestions that maximize calorie loss and are easy for the user to adopt. In addition, the system takes into account user's preferences to encourage adoption using the pareto-frontier algorithm. In a 14-week study, results show statistically significant increases in physical activity and decreases in food calorie when using MyBehavior compared to a control condition.{\textbackslash}r{\textbackslash}n},
	number = {September},
	journal = {Proceedings of the ACM International Joint Conference on Pervasive and Ubiquitous Computing},
	author = {Rabbi, Mashfiqui and Aung, Min Hane and Zhang, Mi and Choudhury, Tanzeem},
	year = {2015},
	note = {ISBN: 9781450317702},
	keywords = {archival format, proceedings, SIGCHI},
	pages = {707--718},
	file = {Rabbi et al_2015_MyBehavior.pdf:/Users/orsonxu/Zotero/storage/SQ8EWKTA/Rabbi et al_2015_MyBehavior.pdf:application/pdf;Rabbi et al_2015_MyBehavior.pdf:/Users/orsonxu/Zotero/storage/9VX6IEAH/Rabbi et al_2015_MyBehavior.pdf:application/pdf},
}

@article{Wahle2017,
	title = {Toward the {Design} of {Evidence}-{Based} {Mental} {Health} {Information} {Systems} for {People} {With} {Depression}: {A} {Systematic} {Literature} {Review} and {Meta}-{Analysis}},
	volume = {19},
	issn = {14388871},
	doi = {10.2196/jmir.7381},
	abstract = {Background: Existing research postulates a variety of components that show an impact on utilization of technology-mediated mental health information systems (MHIS) and treatment outcome. Although researchers assessed the effect of isolated design elements on the results of Web-based interventions and the associations between symptom reduction and use of components across computer and mobile phone platforms, there remains uncertainty with regard to which components of technology-mediated interventions for mental health exert the greatest therapeutic gain. Until now, no studies have presented results on the therapeutic benefit associated with specific service components of technology-mediated MHIS for depression. Objective: This systematic review aims at identifying components of technology-mediated MHIS for patients with depression. Consequently, all randomized controlled trials comparing technology-mediated treatments for depression to either waiting-list control, treatment as usual, or any other form of treatment for depression were reviewed. Updating prior reviews, this study aims to (1) assess the effectiveness of technology-supported interventions for the treatment of depression and (2) add to the debate on what components in technology-mediated MHIS for the treatment of depression should be standard of care. Methods: Systematic searches in MEDLINE, PsycINFO, and the Cochrane Library were conducted. Effect sizes for each comparison between a technology-enabled intervention and a control condition were computed using the standard mean difference (SMD). Chi-square tests were used to test for heterogeneity. Using subgroup analysis, potential sources of heterogeneity were analyzed. Publication bias was examined using visual inspection of funnel plots and Begg’s test. Qualitative data analysis was also used. In an explorative approach, a list of relevant components was extracted from the body of literature by consensus between two researchers. Results: Of 6387 studies initially identified, 45 met all inclusion criteria. Programs analyzed showed a significant trend toward reduced depressive symptoms (SMD –0.58, 95\% CI –0.71 to –0.45, P{\textless}.001). Heterogeneity was large (I2≥76). A total of 15 components were identified. Conclusions: Technology-mediated MHIS for the treatment of depression has a consistent positive overall effect compared to controls. A total of 15 components have been identified. Further studies are needed to quantify the impact of individual components on treatment effects and to identify further components that are relevant for the design of future technology-mediated interventions for the treatment of depression and other mental disorders. [J Med Internet Res 2017;19(5):e191]},
	number = {5},
	journal = {Journal of medical Internet research},
	author = {Wahle, Fabian and Bollhalder, Lea and Kowatsch, Tobias and Fleisch, Elgar},
	year = {2017},
	pmid = {28566267},
	note = {ISBN: 1438-8871},
	keywords = {depression, design feature, information systems, literature review, mental health},
	pages = {e191},
	file = {Wahle et al_2017_Toward the Design of Evidence-Based Mental Health Information Systems for People With Depression.pdf:/Users/orsonxu/Zotero/storage/HQSHQZ3F/Wahle et al_2017_Toward the Design of Evidence-Based Mental Health Information Systems for People With Depression.pdf:application/pdf;Wahle et al_2017_Toward the Design of Evidence-Based Mental Health Information Systems for People With Depression.pdf:/Users/orsonxu/Zotero/storage/9255WS9W/Wahle et al_2017_Toward the Design of Evidence-Based Mental Health Information Systems for People With Depression.pdf:application/pdf},
}

@article{Michie2008,
	title = {A {Taxonomy} of {Behavior} {Change} {Techniques} used in {Interventions}},
	journal = {Health Psychology},
	author = {Michie, Susan and Abraham, Charles},
	year = {2008},
	file = {Michie_Abraham_2008_A Taxonomy of Behavior Change Techniques used in Interventions.pdf:/Users/orsonxu/Zotero/storage/YSQMMPYC/Michie_Abraham_2008_A Taxonomy of Behavior Change Techniques used in Interventions.pdf:application/pdf;Michie_Abraham_2008_A Taxonomy of Behavior Change Techniques used in Interventions.pdf:/Users/orsonxu/Zotero/storage/S5ZNCGPZ/Michie_Abraham_2008_A Taxonomy of Behavior Change Techniques used in Interventions.pdf:application/pdf},
}

@article{Michie2013,
	title = {The behavior change technique taxonomy (v1) of 93 hierarchically clustered techniques: {Building} an international consensus for the reporting of behavior change interventions},
	volume = {46},
	issn = {08836612},
	doi = {10.1007/s12160-013-9486-6},
	abstract = {Background: CONSORT guidelines call for precise reporting of behavior change interventions: we need rigorous methods of characterizing active content of interventions with precision and specificity. Objectives: The objective of this study is to develop an extensive, consensually agreed hierarchically structured taxonomy of techniques [behavior change techniques (BCTs)] used in behavior change interventions. Methods: In a Delphi-type exercise, 14 experts rated labels and definitions of 124 BCTs from six published classification systems. Another 18 experts grouped BCTs according to similarity of active ingredients in an open-sort task. Inter-rater agreement amongst six researchers coding 85 intervention descriptions by BCTs was assessed. Results: This resulted in 93 BCTs clustered into 16 groups. Of the 26 BCTs occurring at least five times, 23 had adjusted kappas of 0.60 or above. Conclusions: "BCT taxonomy v1," an extensive taxonomy of 93 consensually agreed, distinct BCTs, offers a step change as a method for specifying interventions, but we anticipate further development and evaluation based on international, interdisciplinary consensus. © 2013 The Society of Behavioral Medicine.},
	number = {1},
	journal = {Annals of Behavioral Medicine},
	author = {Michie, Susan and Richardson, Michelle and Johnston, Marie and Abraham, Charles and Francis, Jill and Hardeman, Wendy and Eccles, Martin P. and Cane, James and Wood, Caroline E.},
	year = {2013},
	keywords = {Behavior change interventions, Behavior change techniques, Taxonomy},
	pages = {81--95},
	file = {Michie et al_2013_The behavior change technique taxonomy (v1) of 93 hierarchically clustered techniques.pdf:/Users/orsonxu/Zotero/storage/WUNCZCGY/Michie et al_2013_The behavior change technique taxonomy (v1) of 93 hierarchically clustered techniques.pdf:application/pdf;Michie et al_2013_The behavior change technique taxonomy (v1) of 93 hierarchically clustered techniques.pdf:/Users/orsonxu/Zotero/storage/47KUINWK/Michie et al_2013_The behavior change technique taxonomy (v1) of 93 hierarchically clustered techniques.pdf:application/pdf},
}

@article{Fogg2009,
	title = {The behavior grid: 35 {Ways} behavior can change},
	volume = {350},
	doi = {10.1145/1541948.1542001},
	abstract = {This paper presents a new way of categorizing behavior change in a framework called the Behavior Grid. This preliminary work shows 35 types of behavior along two categorical dimensions. To demonstrate the analytical potential for the Behavior Grid, this paper maps behavior goals from Facebook onto the framework, revealing potential patterns of intent. To show the potential for designers of persuasive technology, this paper uses the Behavior Grid to show what types of behavior change might most easily be achieved through mobile technology. The Behavior Grid needs further development, but this early version can still be useful for designers and researchers in thinking more clearly about behavior change and persuasive technology. Copyright © 2009 ACM.},
	journal = {Proceedings of the International Conference on Persuasive Technology,},
	author = {Fogg, Bj},
	year = {2009},
	note = {ISBN: 9781605583761},
	keywords = {Behavior change, Captology, Motivation, Persuasion, Persuasive design, Persuasive technology, Psychological frameworks},
	pages = {1--5},
	file = {Fogg_2009_The behavior grid.pdf:/Users/orsonxu/Zotero/storage/AVRGGYIX/Fogg_2009_The behavior grid.pdf:application/pdf;Fogg_2009_The behavior grid.pdf:/Users/orsonxu/Zotero/storage/5YPWIB55/Fogg_2009_The behavior grid.pdf:application/pdf},
}

@article{Wiafe2012,
	title = {Bibliographic analysis of persuasive systems: techniques, methods and domains of application},
	url = {http://centaur.reading.ac.uk/28976/},
	abstract = {This paper presents findings of our study on peer-reviewed papers published in the International Conference on Persuasive Technology from 2006 to 2010. The study indicated that out of 44 systems reviewed, 23 were reported to be successful, 2 to be unsuccessful and 19 did not specify whether or not it was successful. 56 different techniques were mentioned and it was observed that most designers use ad hoc definitions for techniques or methods used in design. Hence we propose the need for research to establish unambiguous definitions of techniques and methods in the field.},
	journal = {International Conference on Persuasive Technology},
	author = {Wiafe, Isaac and Nakata, Keiichi},
	year = {2012},
	keywords = {methods, system features, systems evaluation, Theories},
	pages = {61--64},
	file = {Wiafe_Nakata_2012_Bibliographic analysis of persuasive systems.pdf:/Users/orsonxu/Zotero/storage/A4UH5Q29/Wiafe_Nakata_2012_Bibliographic analysis of persuasive systems.pdf:application/pdf;Wiafe_Nakata_2012_Bibliographic analysis of persuasive systems.pdf:/Users/orsonxu/Zotero/storage/9L3LAKZB/Wiafe_Nakata_2012_Bibliographic analysis of persuasive systems.pdf:application/pdf},
}

@article{Sarker2014,
	title = {Assessing the availability of users to engage in just-in-time intervention in the natural environment},
	doi = {10.1145/2632048.2636082},
	abstract = {Wearable wireless sensors for health monitoring are enabling the design and delivery of just-in-time interventions (JITI). Critical to the success of JITI is to time its delivery so that the user is available to be engaged. We take a first step in modeling users' availability by analyzing 2,064 hours of physiological sensor data and 2,717 self-reports collected from 30 participants in a week-long field study. We use delay in responding to a prompt to objectively measure availability. We compute 99 features and identify 30 as most discriminating to train a machine learning model for predicting availability. We find that location, affect, activity type, stress, time, and day of the week, play significant roles in predicting availability. We find that users are least available at work and during driving, and most available when walking outside. Our model finally achieves an accuracy of 74.7\% in 10-fold cross-validation and 77.9\% with leave-one-subject-out.},
	journal = {UbiComp 2014 - Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
	author = {Sarker, Hillol and Sharmin, Moushumi and Ali, Amin Ahsan and Rahman, Md Mahbubur and Bari, Rummana and Hossain, Syed Monowar and Kumar, Santosh},
	year = {2014},
	note = {ISBN: 9781450329682},
	keywords = {Intervention, Interruption, Mobile health, EMA, Mobile application, Self-report},
	pages = {909--920},
	file = {Sarker et al_2014_Assessing the availability of users to engage in just-in-time intervention in the natural environment.pdf:/Users/orsonxu/Zotero/storage/PFNQJQ4J/Sarker et al_2014_Assessing the availability of users to engage in just-in-time intervention in the natural environment.pdf:application/pdf;Sarker et al_2014_Assessing the availability of users to engage in just-in-time intervention in the natural environment.pdf:/Users/orsonxu/Zotero/storage/NGKCQT6Q/Sarker et al_2014_Assessing the availability of users to engage in just-in-time intervention in the natural environment.pdf:application/pdf},
}

@article{Liao2018,
	title = {Just-in-{Time} but {Not} {Too} {Much}: {Determining} {Treatment} {Timing} in {Mobile} {Health}},
	volume = {2},
	issn = {24749567},
	url = {http://dl.acm.org/citation.cfm?doid=3301777.3287057},
	doi = {10.1145/3287057},
	number = {4},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Liao, Peng and Dempsey, Walter and Sarker, Hillol and Hossain, Syed Monowar and Al'Absi, Mustafa and Klasnja, Predrag and Murphy, Susan},
	year = {2018},
	keywords = {Just-in-Time Adaptive Intervention, Mobile Health, Just-in-Time Adaptive Intervention,},
	pages = {1--21},
	file = {Liao et al_2018_Just-in-Time but Not Too Much.pdf:/Users/orsonxu/Zotero/storage/MZCCXXY8/Liao et al_2018_Just-in-Time but Not Too Much.pdf:application/pdf;Liao et al_2018_Just-in-Time but Not Too Much.pdf:/Users/orsonxu/Zotero/storage/AIGGR8F6/Liao et al_2018_Just-in-Time but Not Too Much.pdf:application/pdf},
}

@article{Orji2018,
	title = {Persuasive technology for health and wellness: {State}-of-the-art and emerging trends},
	volume = {24},
	issn = {17412811},
	doi = {10.1177/1460458216650979},
	abstract = {The evolving field of persuasive and behavior change technology is increasingly targeted at influencing behavior in the area of health and wellness. This paper provides an empirical review of 16 years (85 papers) of literature on persuasive technology for health and wellness to: (1.) answer important questions regarding the effectiveness of persuasive technology for health and wellness, (2.) summarize and highlight trends in the technology design, research methods, motivational strategies, theories, and health behaviors targeted by research to date, (3.) uncover pitfalls of existing persuasive technological interventions for health and wellness, and (4.) suggest directions for future research.},
	number = {1},
	journal = {Health Informatics Journal},
	author = {Orji, Rita and Moffatt, Karyn},
	year = {2018},
	keywords = {behavior change systems, behavior theories, gamification, health and wellness, health interventions, health technology, healthy behavior, motivational strategies, persuasive strategies, persuasive technology},
	pages = {66--91},
	file = {Orji_Moffatt_2018_Persuasive technology for health and wellness.pdf:/Users/orsonxu/Zotero/storage/HN99RJG7/Orji_Moffatt_2018_Persuasive technology for health and wellness.pdf:application/pdf;Orji_Moffatt_2018_Persuasive technology for health and wellness.pdf:/Users/orsonxu/Zotero/storage/86KD3MEW/Orji_Moffatt_2018_Persuasive technology for health and wellness.pdf:application/pdf},
}

@article{Alshurafa2018,
	title = {Is {More} {Always} {Better} ? {Discovering} {Incentivized} {mHealth} {Intervention} {Engagement} {Related} to {Health} {Behavior} {Trends}},
	volume = {2},
	number = {4},
	journal = {IMWUT},
	author = {Alshurafa, Nabil and Jain, Jayalakshmi and Alharbi, Rawan and Iakovlev, Gleb and Spring, Bonnie and Pfammatter, Angela},
	year = {2018},
	keywords = {mHealth, adherence, engagement, longitudinal study},
	file = {Alshurafa et al_2018_Is More Always Better.pdf:/Users/orsonxu/Zotero/storage/U6FW76Q9/Alshurafa et al_2018_Is More Always Better.pdf:application/pdf;Alshurafa et al_2018_Is More Always Better.pdf:/Users/orsonxu/Zotero/storage/RLXMZHNM/Alshurafa et al_2018_Is More Always Better.pdf:application/pdf},
}

@article{Thornicroft2016,
	title = {Evidence for effective interventions to reduce mental-health-related stigma and discrimination},
	volume = {387},
	issn = {1474547X},
	url = {http://dx.doi.org/10.1016/S0140-6736(15)00298-6},
	doi = {10.1016/S0140-6736(15)00298-6},
	abstract = {Stigma and discrimination in relation to mental illnesses have been described as having worse consequences than the conditions themselves. Most medical literature in this area of research has been descriptive and has focused on attitudes towards people with mental illness rather than on interventions to reduce stigma. In this narrative Review, we summarise what is known globally from published systematic reviews and primary data on effective interventions intended to reduce mental-illness-related stigma or discrimination. The main findings emerging from this narrative overview are that: (1) at the population level there is a fairly consistent pattern of short-term benefits for positive attitude change, and some lesser evidence for knowledge improvement; (2) for people with mental illness, some group-level anti-stigma inventions show promise and merit further assessment; (3) for specific target groups, such as students, social-contact-based interventions usually achieve short-term (but less clearly long-term) attitudinal improvements, and less often produce knowledge gains; (4) this is a heterogeneous field of study with few strong study designs with large sample sizes; (5) research from low-income and middle-income countries is conspicuous by its relative absence; (6) caution needs to be exercised in not overgeneralising lessons from one target group to another; (7) there is a clear need for studies with longer-term follow-up to assess whether initial gains are sustained or attenuated, and whether booster doses of the intervention are needed to maintain progress; (8) few studies in any part of the world have focused on either the service user's perspective of stigma and discrimination or on the behaviour domain of behavioural change, either by people with or without mental illness in the complex processes of stigmatisation. We found that social contact is the most effective type of intervention to improve stigma-related knowledge and attitudes in the short term. However, the evidence for longer-term benefit of such social contact to reduce stigma is weak. In view of the magnitude of challenges that result from mental health stigma and discrimination, a concerted effort is needed to fund methodologically strong research that will provide robust evidence to support decisions on investment in interventions to reduce stigma.},
	number = {10023},
	journal = {The Lancet},
	author = {Thornicroft, Graham and Mehta, Nisha and Clement, Sarah and Evans-Lacko, Sara and Doherty, Mary and Rose, Diana and Koschorke, Mirja and Shidhaye, Rahul and O'Reilly, Claire and Henderson, Claire},
	year = {2016},
	pmid = {26410341},
	note = {Publisher: Elsevier Ltd
ISBN: 0140-6736},
	pages = {1123--1132},
	file = {Thornicroft et al_2016_Evidence for effective interventions to reduce mental-health-related stigma and discrimination.pdf:/Users/orsonxu/Zotero/storage/UX4Z665N/Thornicroft et al_2016_Evidence for effective interventions to reduce mental-health-related stigma and discrimination.pdf:application/pdf;Thornicroft et al_2016_Evidence for effective interventions to reduce mental-health-related stigma and discrimination.pdf:/Users/orsonxu/Zotero/storage/ECVYD3IQ/Thornicroft et al_2016_Evidence for effective interventions to reduce mental-health-related stigma and discrimination.pdf:application/pdf},
}

@article{Nahum-Shani2016,
	title = {Building health behavior models to guide the development of just-in-time adaptive interventions: {A} pragmatic framework {Inbal}},
	volume = {176},
	doi = {10.1016/j.gde.2016.03.011},
	abstract = {Genetic and epigenetic heterogeneity is emerging as a fundamental property of human cancers. Reflecting the genesis of tumors as an evolutionary process driven by clonal selection. The complexity of clonal architecture has been known for many years in the setting of acute myeloid leukemia (AML), based on karyotyping studies. However the true complexity of AMLs is only now being understood thanks to in depth genome sequencing studies in humans, which reveal that heterogeneity is a multilayered and involves not only the genome but also the epigenome. Here, we review recent advances in genetic and epigenetic heterogeneity and clonal dynamics in AML and their relevance to biology, clinical outcomes and therapeutic implications. Special attention is focused on somatic mutations affecting regulators of cytosine methylation, since these tend to occur early in disease evolution, reprogram the epigenome of hematopoietic stem cells, and are linked to unfavorable outcome.},
	number = {1},
	journal = {Health Psychology},
	author = {Nahum-Shani, Inbal and Hekler, Eric B. and Spruijt-Metz, Donna},
	year = {2016},
	keywords = {determination, protein crystallography, protein data bank, r -factor, resolution, restraints, structure, structure interpretation, structure quality, structure refinement, structure validation},
	pages = {100--106},
	file = {Nahum-Shani et al_2016_Building health behavior models to guide the development of just-in-time adaptive interventions.pdf:/Users/orsonxu/Zotero/storage/RU7VW778/Nahum-Shani et al_2016_Building health behavior models to guide the development of just-in-time adaptive interventions.pdf:application/pdf;Nahum-Shani et al_2016_Building health behavior models to guide the development of just-in-time adaptive interventions.pdf:/Users/orsonxu/Zotero/storage/DBNHC7CK/Nahum-Shani et al_2016_Building health behavior models to guide the development of just-in-time adaptive interventions.pdf:application/pdf},
}

@article{Murnane2020,
	title = {Designing {Ambient} {Narrative}-{Based} {Interfaces} to {Reflect} and {Motivate} {Physical} {Activity}},
	journal = {Proceedings of the ACM CHI Conference on Human Factors in Computing Systems},
	author = {Murnane, Elizabeth L and Jiang, Xin and Kong, Anna and Park, Michelle and Shi, Weili and Soohoo, Connor and Vink, Luke and Xia, Iris and Xin, Yu and Yang-sammataro, John and Young, Grace and Zhi, Jenny and Moya, Paula and Landay, James A},
	year = {2020},
	note = {ISBN: 9781450367080},
	file = {Murnane et al_2020_Designing Ambient Narrative-Based Interfaces to Reflect and Motivate Physical Activity.pdf:/Users/orsonxu/Zotero/storage/JJRCHXMY/Murnane et al_2020_Designing Ambient Narrative-Based Interfaces to Reflect and Motivate Physical Activity.pdf:application/pdf;Murnane et al_2020_Designing Ambient Narrative-Based Interfaces to Reflect and Motivate Physical Activity.pdf:/Users/orsonxu/Zotero/storage/F8FJZB8Z/Murnane et al_2020_Designing Ambient Narrative-Based Interfaces to Reflect and Motivate Physical Activity.pdf:application/pdf},
}

@article{Hamari2014,
	title = {Do persuasive technologies persuade? - {A} review of empirical studies},
	volume = {8462 LNCS},
	issn = {16113349},
	doi = {10.1007/978-3-319-07127-5_11},
	abstract = {This paper reviews the current body of empirical research on persuasive technologies (95 studies). In recent years, technology has been increasingly harnessed to persuade and motivate people to engage in various behaviors. This phenomenon has also attracted substantial scholarly interest over the last decade. This review examines the results, methods, measured behavioral and psychological outcomes, affordances in implemented persuasive systems, and domains of the studies in the current body of research on persuasive technologies. The reviewed studies have investigated diverse persuasive systems/designs, psychological factors, and behavioral outcomes. The results of the reviewed studies were categorized into fully positive, partially positive, and negative and/or no effects. This review provides an overview of the state of empirical research regarding persuasive technologies. The paper functions as a reference in positioning future research within the research stream of persuasive technologies in terms of the domain, the persuasive stimuli and the psychological and behavioral outcomes. © 2014 Springer International Publishing.},
	journal = {International Conference on Persuasive Technology},
	author = {Hamari, Juho and Koivisto, Jonna and Pakkanen, Tuomas},
	year = {2014},
	note = {ISBN: 9783319071268},
	keywords = {gamification, health technology, persuasive technology, behavioral change support system, captology, game-based learning, motivational affordance, persuasive computing, sustainability},
	pages = {118--136},
	file = {Hamari et al_2014_Do persuasive technologies persuade.pdf:/Users/orsonxu/Zotero/storage/ZZ5RWUGH/Hamari et al_2014_Do persuasive technologies persuade.pdf:application/pdf;Hamari et al_2014_Do persuasive technologies persuade.pdf:/Users/orsonxu/Zotero/storage/64YECYNX/Hamari et al_2014_Do persuasive technologies persuade.pdf:application/pdf},
}

@article{Spruijt-Metz2014,
	title = {Dynamic models of behavior for just-in-time adaptive interventions},
	volume = {13},
	issn = {15361268},
	doi = {10.1109/MPRV.2014.46},
	abstract = {Improvements in health behavior theory will be central to creating successful interventions that encourage and support behavior change and maintenance. The authors discuss dynamic, multimethod, conceptually driven, and data-rich approaches for the development of testable computational models of health-related behaviors in real time. © 2014 IEEE.},
	number = {3},
	journal = {IEEE Pervasive Computing},
	author = {Spruijt-Metz, Donna and Nilsen, Wendy},
	year = {2014},
	note = {Publisher: IEEE},
	keywords = {adaptive interventions, behavior theory, healthcare, JITAI, just-in-time, pervasive computing},
	pages = {13--17},
	file = {Spruijt-Metz_Nilsen_2014_Dynamic models of behavior for just-in-time adaptive interventions.pdf:/Users/orsonxu/Zotero/storage/UBPM9CCP/Spruijt-Metz_Nilsen_2014_Dynamic models of behavior for just-in-time adaptive interventions.pdf:application/pdf;Spruijt-Metz_Nilsen_2014_Dynamic models of behavior for just-in-time adaptive interventions.pdf:/Users/orsonxu/Zotero/storage/PK9MDNW4/Spruijt-Metz_Nilsen_2014_Dynamic models of behavior for just-in-time adaptive interventions.pdf:application/pdf},
}

@article{Goyal2017,
	title = {Intelligent {Interruption} {Management} using {Electro} {Dermal} {Activity} based {Physiological} {Sensor} for {Collaborative} {Sensemaking}},
	volume = {1},
	doi = {10.1145/3130917},
	abstract = {Submarine channel avulsion is a fundamental process in the evolution of submarine fans that records abrupt changes in the sediment dispersal patterns, and the development of sand-rich splay deposits. On passive margins, changing flow conditions have been invoked to explain the location and timing of channel avulsion. On tectonically active basin margins, processes such as seismic activity, seabed faulting and folding and emplacement of mass-transport complexes (MTCs) are additional triggers. This study is based on the detailed mapping and interpretation of the first 1000m below seabed of a 1900km23D seismic volume in the southern Magdalena Fan, offshore Colombia, a tectonically-active margin. The emplacement of a large MTC deposit ({\textgreater}400km2in area and 200m in thickness) is interpreted to have controlled the avulsion node of a major channel-levee complex-set and influenced the evolution of the subsequent avulsion lobe complex-set. The basal surface of the MTC is highly erosional resulting in net degradation of the seascape. Substrate entrainment by the MTC left behind a narrow erosional remnant ridge that formed a bathymetric anomaly upon which a channel-levee complex-set developed. The irregular levee geometries above the remnant ridge led to instability and levee collapse prior to channel avulsion. Map view geometries and seismic amplitude extractions suggest that the initial avulsion lobes were mud-prone and relatively erratically distributed, and evolved to form well-defined sand-prone lobes. The distribution, morphology and evolution of the avulsion lobe complexes were strongly influenced by the bathymetric anomalies on the MTC top surface which, are generally coincident with protruding megaclasts. The role of MTC emplacement in triggering submarine channel avulsion and the development of sand-prone deposits in proximal locations has important implications for hydrocarbon exploration and production. This study serves as a high-resolution, shallow-subsurface analogue for less well-imaged avulsion cycles on tectonically-active basin margins that are prone to MTCs.},
	number = {3},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Goyal, Nitesh and Fussell, Susan R.},
	year = {2017},
	keywords = {-  Computing methodologies  -{\textgreater}  Cognitive science, -  Hardware  -{\textgreater}  Sensor applications and deploymen, -  Human-centered computing  -{\textgreater}  Human computer in, Collaborative and social computing},
	pages = {1--21},
	file = {Goyal_Fussell_2017_Intelligent Interruption Management using Electro Dermal Activity based Physiological Sensor for Collaborative Sensemaking.pdf:/Users/orsonxu/Zotero/storage/YY8HQPZT/Goyal_Fussell_2017_Intelligent Interruption Management using Electro Dermal Activity based Physiological Sensor for Collaborative Sensemaking.pdf:application/pdf;Goyal_Fussell_2017_Intelligent Interruption Management using Electro Dermal Activity based Physiological Sensor for Collaborative Sensemaking.pdf:/Users/orsonxu/Zotero/storage/G4UEK59G/Goyal_Fussell_2017_Intelligent Interruption Management using Electro Dermal Activity based Physiological Sensor for Collaborative Sensemaking.pdf:application/pdf},
}

@article{Pielot2015,
	title = {When attention is not scarce - detecting boredom from mobile phone usage},
	issn = {0277-9536},
	url = {http://dl.acm.org/citation.cfm?doid=2750858.2804252},
	doi = {10.1145/2750858.2804252},
	abstract = {Boredom is a common human emotion which may lead to an active search for stimulation. People often turn to their mobile phones to seek that stimulation. In this paper, we tackle the challenge of automatically inferring boredom from mobile phone usage. In a two-week in-the-wild study, we collected over 40,000,000 usage logs and 4398 boredom self-reports of 54 mobile phone users. We show that a user-independent machine-learning model of boredom –leveraging features related to recency of communication, usage intensity, time of day, and demographics– can infer boredom with an accuracy (AUCROC) of up to 82.9\%. Results from a second field study with 16 participants suggest that people are more likely to engage with recommended content when they are bored, as inferred by our boredom-detection model. These findings enable boredom-triggered proactive recommender systems that attune their users’ level of attention and need for stimulation.},
	journal = {Proceedings of ACM International Joint Conference on Pervasive and Ubiquitous Computing},
	author = {Pielot, Martin and Dingler, Tilman and Pedro, Jose San and Oliver, Nuria},
	year = {2015},
	pmid = {9071391},
	note = {ISBN: 9781450335744},
	pages = {825--836},
	file = {Pielot et al_2015_When attention is not scarce - detecting boredom from mobile phone usage.pdf:/Users/orsonxu/Zotero/storage/APZCTS6E/Pielot et al_2015_When attention is not scarce - detecting boredom from mobile phone usage.pdf:application/pdf;Pielot et al_2015_When attention is not scarce - detecting boredom from mobile phone usage.pdf:/Users/orsonxu/Zotero/storage/3JXKEXWI/Pielot et al_2015_When attention is not scarce - detecting boredom from mobile phone usage.pdf:application/pdf},
}

@article{Pielot2017a,
	title = {Beyond {Interruptibility}: {Predicting} {Opportune} {Moments} to {Engage} {Mobile} {Phone} {Users}},
	volume = {1},
	issn = {24749567},
	url = {http://dl.acm.org/citation.cfm?doid=3139486.3130956},
	doi = {10.1145/3130956},
	abstract = {Many of today's mobile products and services engage their users proactively via push notifications. However, such notifications are not always delivered at the right moment, therefore not meeting products' and users' expectations. To address this challenge, we aim at developing an intelligent mobile system that automatically infers moments in which users are open to engage with suggested content. To inform the development of such a system, we carried out a field study with 337 mobile phone users. For 4 weeks, participants ran a study application on their primary phones. They were tasked to frequently report their current mood via a notification-administered experience-sampling questionnaire. In this study, however, we analyze whether they voluntarily engaged with content that we offered at the bottom of that questionnaire. In addition, the study app logged a wide range of data related to their phone use. Based on 120 Million phone-use events and 78,930 questionnaire notifications, we build a machine-learning model that before delivering a notification predicts whether a participant will click on the notification and subsequently engage with the offered content. When compared to a naïve baseline, which emulates current non-intelligent engagement strategies, our model achieves 66.6\% higher success rate in its predictions. If the model also considers the user's past behavior, predictions improve 5-fold over the baseline. Based on these findings, we discuss the implications for building an intelligent service that identifies opportune moments for proactive user engagement, while, at the same time, reduces the number of undesirable interruptions.},
	number = {3},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Pielot, Martin and Cardoso, Bruno and Katevas, Kleomenis and Serrà, Joan and Matic, Aleksandar and Oliver, Nuria},
	year = {2017},
	keywords = {Conversion, Mobile Devices, Proactive Recommendations, Push Notifications},
	pages = {1--25},
	file = {Pielot et al_2017_Beyond Interruptibility.pdf:/Users/orsonxu/Zotero/storage/IHA463HB/Pielot et al_2017_Beyond Interruptibility.pdf:application/pdf;Pielot et al_2017_Beyond Interruptibility.pdf:/Users/orsonxu/Zotero/storage/HSXXCS7W/Pielot et al_2017_Beyond Interruptibility.pdf:application/pdf},
}

@article{gronholm2017interventions,
	title = {Interventions to reduce discrimination and stigma: the state of the art},
	volume = {52},
	number = {3},
	journal = {Social psychiatry and psychiatric epidemiology},
	author = {Gronholm, Petra C and Henderson, Claire and Deb, Tanya and Thornicroft, Graham},
	year = {2017},
	note = {Publisher: Springer},
	pages = {249--258},
	file = {Gronholm et al_2017_Interventions to reduce discrimination and stigma.pdf:/Users/orsonxu/Zotero/storage/RDBP5XBP/Gronholm et al_2017_Interventions to reduce discrimination and stigma.pdf:application/pdf;Gronholm et al_2017_Interventions to reduce discrimination and stigma.pdf:/Users/orsonxu/Zotero/storage/PFJQ3PA6/Gronholm et al_2017_Interventions to reduce discrimination and stigma.pdf:application/pdf},
}

@article{lattie_digital_2019,
	title = {Digital {Mental} {Health} {Interventions} for {Depression}, {Anxiety}, and {Enhancement} of {Psychological} {Well}-{Being} {Among} {College} {Students}: {Systematic} {Review}},
	volume = {21},
	issn = {1438-8871},
	shorttitle = {Digital {Mental} {Health} {Interventions} for {Depression}, {Anxiety}, and {Enhancement} of {Psychological} {Well}-{Being} {Among} {College} {Students}},
	url = {http://www.jmir.org/2019/7/e12869/},
	doi = {10.2196/12869},
	abstract = {Background: College students are increasingly reporting common mental health problems, such as depression and anxiety, and they frequently encounter barriers to seeking traditional mental health treatments. Digital mental health interventions, such as those delivered via the Web and apps, offer the potential to improve access to mental health treatment.
Objective: This study aimed to review the literature on digital mental health interventions focused on depression, anxiety, and enhancement of psychological well-being among samples of college students to identify the effectiveness, usability, acceptability, uptake, and adoption of such programs.
Methods: We conducted a systematic review using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines (registration number CRD42018092800), and the search strategy was conducted by a medical research librarian in the following databases: MEDLINE (Ovid), EMBASE (Elsevier), PsycINFO (EbscoHost), the Cochrane Library (Wiley), and Web of Science (Thomson Reuters) from the date of inception to April 2019. Data were synthesized using a systematic narrative synthesis framework, and formal quality assessments were conducted to address the risk of bias.
Results: A total of 89 studies met the inclusion criteria. The majority of interventions (71/89, 80\%) were delivered via a website, and the most common intervention was internet-based cognitive behavioral therapy (28, 31\%). Many programs (33, 37\%) featured human support in the form of coaching. The majority of programs were either effective (42, 47\%) or partially effective (30, 34\%) in producing beneficial changes in the main psychological outcome variables. Approximately half of the studies (45, 51\%) did not present any usability or acceptability outcomes, and few studies (4, 4\%) examined a broad implementation of digital mental health interventions on college campuses. Quality assessments revealed a moderate-to-severe risk of bias in many of the studies.
Conclusions: Results suggest that digital mental health interventions can be effective for improving depression, anxiety, and psychological well-being among college students, but more rigorous studies are needed to ascertain the effective elements of these interventions. Continued research on improving the user experience of, and thus user engagement with, these programs appears vital for the sustainable implementation of digital mental health interventions on college campuses.},
	language = {en},
	number = {7},
	urldate = {2021-10-30},
	journal = {Journal of Medical Internet Research},
	author = {Lattie, Emily G and Adkins, Elizabeth C and Winquist, Nathan and Stiles-Shields, Colleen and Wafford, Q Eileen and Graham, Andrea K},
	month = jul,
	year = {2019},
	pages = {e12869},
	file = {Lattie et al. - 2019 - Digital Mental Health Interventions for Depression.pdf:/Users/orsonxu/Zotero/storage/9P4U3FIM/Lattie et al. - 2019 - Digital Mental Health Interventions for Depression.pdf:application/pdf},
}

@article{torous_digital_2020,
	title = {Digital {Mental} {Health} and {COVID}-19: {Using} {Technology} {Today} to {Accelerate} the {Curve} on {Access} and {Quality} {Tomorrow}},
	volume = {7},
	issn = {2368-7959},
	shorttitle = {Digital {Mental} {Health} and {COVID}-19},
	url = {http://mental.jmir.org/2020/3/e18848/},
	doi = {10.2196/18848},
	abstract = {As interest in and use of telehealth during the COVID-19 global pandemic increase, the potential of digital health to increase access and quality of mental health is becoming clear. Although the world today must “flatten the curve” of spread of the virus, we argue that now is the time to “accelerate and bend the curve” on digital health. Increased investments in digital health today will yield unprecedented access to high-quality mental health care. Focusing on personal experiences and projects from our diverse authorship team, we share selected examples of digital health innovations while acknowledging that no single piece can discuss all the impressive global efforts past and present. Exploring the success of telehealth during the present crisis and how technologies like apps can soon play a larger role, we discuss the need for workforce training, high-quality evidence, and digital equity among other factors critical for bending the curve further.},
	language = {en},
	number = {3},
	urldate = {2021-10-30},
	journal = {JMIR Mental Health},
	author = {Torous, John and Jän Myrick, Keris and Rauseo-Ricupero, Natali and Firth, Joseph},
	month = mar,
	year = {2020},
	pages = {e18848},
	file = {Torous et al. - 2020 - Digital Mental Health and COVID-19 Using Technolo.pdf:/Users/orsonxu/Zotero/storage/G7S22SNM/Torous et al. - 2020 - Digital Mental Health and COVID-19 Using Technolo.pdf:application/pdf},
}

@article{torous_needed_2017,
	title = {Needed {Innovation} in {Digital} {Health} and {Smartphone} {Applications} for {Mental} {Health}: {Transparency} and {Trust}},
	volume = {74},
	issn = {2168-622X},
	shorttitle = {Needed {Innovation} in {Digital} {Health} and {Smartphone} {Applications} for {Mental} {Health}},
	url = {http://archpsyc.jamanetwork.com/article.aspx?doi=10.1001/jamapsychiatry.2017.0262},
	doi = {10.1001/jamapsychiatry.2017.0262},
	language = {en},
	number = {5},
	urldate = {2021-10-30},
	journal = {JAMA Psychiatry},
	author = {Torous, John and Roberts, Laura Weiss},
	month = may,
	year = {2017},
	pages = {437},
	file = {Torous and Roberts - 2017 - Needed Innovation in Digital Health and Smartphone.pdf:/Users/orsonxu/Zotero/storage/8T9BV7Z5/Torous and Roberts - 2017 - Needed Innovation in Digital Health and Smartphone.pdf:application/pdf},
}

@inproceedings{rahman_towards_2021,
	address = {Athens, Greece},
	title = {Towards {Motion}-{Aware} {Passive} {Resting} {Respiratory} {Rate} {Monitoring} {Using} {Earbuds}},
	isbn = {978-1-66540-362-7},
	url = {https://ieeexplore.ieee.org/document/9507016/},
	doi = {10.1109/BSN51625.2021.9507016},
	abstract = {Breathing rate is an important vital sign and an indicator of overall health and ﬁtness. Traditionally breathing is monitored using specialized devices such as chestband or spirometers which are uncomfortable for daily use. Recent works show the feasibility of estimating breathing rate using earbuds’ motion sensors. However, non-breathing head motion is one of the biggest challenges for breathing rate estimation using earbuds. In this paper, we propose algorithms to estimate breathing rate in presence of non-breathing head motion using inertial sensors embedded in commodity earbuds. Using the chestband as a reference device, we show that our algorithms can estimate breathing rate in resting positions with error rate 2.34 breaths per minute (BPM). Our algorithms can handle passive head motion and reduce the error by 27.78\%. Furthermore, our algorithms can handle active head motion and help reduce the error by 45.70\% when intentional non-breathing head motion is present in the data segment. It can be a big stride towards passive breathing monitoring in daily life using commodity earbuds.},
	language = {en},
	urldate = {2021-10-20},
	booktitle = {2021 {IEEE} 17th {International} {Conference} on {Wearable} and {Implantable} {Body} {Sensor} {Networks} ({BSN})},
	publisher = {IEEE},
	author = {Rahman, Md Mahbubur and Ahmed, Tousif and Ahmed, Mohsin Yusuf and Nemati, Ebrahim and Dinh, Minh and Folkman, Nathan and Hasan, Md Mehedi and Kuang, Jilong and Gao, Jun Alex},
	month = jul,
	year = {2021},
	pages = {1--4},
	file = {Rahman et al. - 2021 - Towards Motion-Aware Passive Resting Respiratory R.pdf:/Users/orsonxu/Zotero/storage/HPCPA4XJ/Rahman et al. - 2021 - Towards Motion-Aware Passive Resting Respiratory R.pdf:application/pdf},
}

@article{ahmed_rrmonitor_nodate,
	title = {{RRMonitor}: {A} {Resource}-{Aware} {End}-to-{End} {System} for {Continuous} {Monitoring} of {Respiration} {Rate} {Using} {Earbuds}},
	abstract = {Respiration rate is considered as a critical vital sign, and daily monitoring of respiration rate could provide helpful information about any acute condition in the human body. While researchers have been exploring mobile devices for respiration rate monitoring, passive and continuous monitoring is still not feasible due to many usability challenges (e.g., active participation) in existing approaches. This paper presents an end-to-end system called RRMonitor that leverages the movement sensors from commodity earbuds to continuously monitor the respiration rate in near real-time. While developing the systems, we extensively explored some key parameters, algorithms, and approaches from existing literature that are better suited for continuous and passive respiration rate monitoring. RRMonitor can passively track the respiration rate with a mean absolute error as low as 1.64 cycles per minute without requiring active participation from the user.},
	language = {en},
	author = {Ahmed, Tousif and Rahman, Mahbubur and Ahmed, Mohsin Yusuf and Nemati, Ebrahim and Dinh, Minh and Folkman, Nathan and Kuang, Jilong and Gao, Alex},
	pages = {5},
	file = {Ahmed et al. - RRMonitor A Resource-Aware End-to-End System for .pdf:/Users/orsonxu/Zotero/storage/C5JJWPN2/Ahmed et al. - RRMonitor A Resource-Aware End-to-End System for .pdf:application/pdf},
}

@article{InstituteofElectricalandElectronicsEngineers2016,
	title = {Is providing mobile interventions “just-in-time” helpful? {An} experimental proof of concept study of just-in-time intervention for stress management},
	abstract = {Conference location: Bethesda, MD, USA.},
	author = {{Institute of Electrical and Electronics Engineers}},
	year = {2016},
	note = {ISBN: 9781509030903},
	keywords = {Mobile health, mHealth, Well-being},
	pages = {89--95},
	file = {Institute of Electrical and Electronics Engineers_2016_2016 IEEE Wireless Health (WH).pdf:/Users/orsonxu/Zotero/storage/VJT9YQ7Y/Institute of Electrical and Electronics Engineers_2016_2016 IEEE Wireless Health (WH).pdf:application/pdf;Institute of Electrical and Electronics Engineers_2016_2016 IEEE Wireless Health (WH).pdf:/Users/orsonxu/Zotero/storage/8Z6KY8KA/Institute of Electrical and Electronics Engineers_2016_2016 IEEE Wireless Health (WH).pdf:application/pdf},
}

@article{Pejovic2014,
	title = {Anticipatory mobile computing for behaviour change interventions},
	url = {http://dl.acm.org/citation.cfm?doid=2638728.2641284},
	doi = {10.1145/2638728.2641284},
	abstract = {Behavioural change interventions represent a powerful means for tackling a number of health and well-being issues, from obesity to stress and addiction. In the current medical practice, the change is induced through tailored coaching, support and information delivery. However, with the advent of smartphones, innovative ways of delivering interventions are emerging. Indeed, mobile phones, equipped with an array of sensors, and carried by their users at all times, enable therapists to both learn about the user behaviour, and impact the behaviour through the delivery of more relevant and personalised information. In this work we propose harnessing pervasive computing to not only learn from users’ past behaviour, but also predict future actions and emotional states, deliver interventions proactively, evaluate their impact at run-time, and over time learn a personal intervention-effect model of a participant. Author},
	journal = {Proceedings of the ACM International Joint Conference on Pervasive and Ubiquitous Computing Adjunct},
	author = {Pejovic, Veljko and Musolesi, Mirco},
	year = {2014},
	note = {ISBN: 9781450330473},
	pages = {1025--1034},
	file = {Pejovic_Musolesi_2014_Anticipatory mobile computing for behaviour change interventions.pdf:/Users/orsonxu/Zotero/storage/HNEIKX4U/Pejovic_Musolesi_2014_Anticipatory mobile computing for behaviour change interventions.pdf:application/pdf;Pejovic_Musolesi_2014_Anticipatory mobile computing for behaviour change interventions.pdf:/Users/orsonxu/Zotero/storage/GJX3M8KA/Pejovic_Musolesi_2014_Anticipatory mobile computing for behaviour change interventions.pdf:application/pdf},
}

@article{Elavsky2019,
	title = {Mobile {Health} {Interventions} for {Physical} {Activity}, {Sedentary} {Behavior}, and {Sleep} in {Adults} {Aged} 50 {Years} and {Older}: {A} {Systematic} {Literature} {Review}},
	volume = {27},
	issn = {1063-8652},
	url = {https://journals.humankinetics.com/view/journals/japa/27/4/article-p565.xml},
	doi = {10.1123/japa.2017-0410},
	abstract = {We provide a systematic review of interventions utilizing mobile technology to alter physical activity, sedentary behavior, and sleep among adults aged 50 years and older. A systematic search identified 52 relevant articles (randomized control trial [RCT], quasi-experimental, pre/post single-group design). Of 50 trials assessing physical activity, 17 out of 29 RCTs and 13 out of 21 trials assessed for pre/post changes only supported the effectiveness of mobile interventions to improve physical activity, and 9 studies (five out of 10 RCTs and all four pre/post studies) out of 14 reduced sedentary behavior. Only two of five interventions improved sleep (one out of two RCTs and one out of three pre/post studies). Text messaging was the most frequently used intervention (60\% of all studies) but was usually used in combination with other components (79\% of hybrid interventions included SMS, plus either web or app components). Although more high-quality RCTs are needed, there is evidence supporting the effectiveness of mHealth approaches in those aged 50 years and older.},
	number = {4},
	journal = {Journal of Aging and Physical Activity},
	author = {Elavsky, Steriani and Knapova, Lenka and Klocek, Adam and Smahel, David},
	month = aug,
	year = {2019},
	pmid = {30507266},
	keywords = {MHealth, Smartphones, Behavior change, Aging, Technologies},
	pages = {565--593},
	file = {Elavsky et al_2019_Mobile Health Interventions for Physical Activity, Sedentary Behavior, and Sleep in Adults Aged 50 Years and Older.pdf:/Users/orsonxu/Zotero/storage/YIM6R67V/Elavsky et al_2019_Mobile Health Interventions for Physical Activity, Sedentary Behavior, and Sleep in Adults Aged 50 Years and Older.pdf:application/pdf;Elavsky et al_2019_Mobile Health Interventions for Physical Activity, Sedentary Behavior, and Sleep in Adults Aged 50 Years and Older.pdf:/Users/orsonxu/Zotero/storage/ASSXGR6X/Elavsky et al_2019_Mobile Health Interventions for Physical Activity, Sedentary Behavior, and Sleep in Adults Aged 50 Years and Older.pdf:application/pdf},
}

@article{Elavsky2019,
	title = {Mobile {Health} {Interventions} for {Physical} {Activity}, {Sedentary} {Behavior}, and {Sleep} in {Adults} {Aged} 50 {Years} and {Older}: {A} {Systematic} {Literature} {Review}},
	volume = {27},
	issn = {1063-8652},
	url = {https://journals.humankinetics.com/view/journals/japa/27/4/article-p565.xml},
	doi = {10.1123/japa.2017-0410},
	abstract = {We provide a systematic review of interventions utilizing mobile technology to alter physical activity, sedentary behavior, and sleep among adults aged 50 years and older. A systematic search identified 52 relevant articles (randomized control trial [RCT], quasi-experimental, pre/post single-group design). Of 50 trials assessing physical activity, 17 out of 29 RCTs and 13 out of 21 trials assessed for pre/post changes only supported the effectiveness of mobile interventions to improve physical activity, and 9 studies (five out of 10 RCTs and all four pre/post studies) out of 14 reduced sedentary behavior. Only two of five interventions improved sleep (one out of two RCTs and one out of three pre/post studies). Text messaging was the most frequently used intervention (60\% of all studies) but was usually used in combination with other components (79\% of hybrid interventions included SMS, plus either web or app components). Although more high-quality RCTs are needed, there is evidence supporting the effectiveness of mHealth approaches in those aged 50 years and older.},
	number = {4},
	journal = {Journal of Aging and Physical Activity},
	author = {Elavsky, Steriani and Knapova, Lenka and Klocek, Adam and Smahel, David},
	month = aug,
	year = {2019},
	pmid = {30507266},
	keywords = {MHealth, Smartphones, Behavior change, Aging, Technologies},
	pages = {565--593},
	file = {Elavsky et al_2019_Mobile Health Interventions for Physical Activity, Sedentary Behavior, and Sleep in Adults Aged 50 Years and Older.pdf:/Users/orsonxu/Zotero/storage/HW8S4K6Y/Elavsky et al_2019_Mobile Health Interventions for Physical Activity, Sedentary Behavior, and Sleep in Adults Aged 50 Years and Older2.pdf:application/pdf;Elavsky et al_2019_Mobile Health Interventions for Physical Activity, Sedentary Behavior, and Sleep in Adults Aged 50 Years and Older.pdf:/Users/orsonxu/Zotero/storage/7GWPBCD8/Elavsky et al_2019_Mobile Health Interventions for Physical Activity, Sedentary Behavior, and Sleep in Adults Aged 50 Years and Older2.pdf:application/pdf},
}

@article{Joe2013,
	title = {Older adults and mobile phones for health: {A} review},
	volume = {46},
	issn = {15320464},
	url = {http://dx.doi.org/10.1016/j.jbi.2013.06.008},
	doi = {10.1016/j.jbi.2013.06.008},
	abstract = {Objective: To report on the results of a review concerning the use of mobile phones for health with older adults. Methods: PubMed and CINAHL were searched for articles using "older adults" and "mobile phones" along with related terms and synonyms between 1965 and June 2012. Identified articles were filtered by the following inclusion criteria: original research project utilizing a mobile phone as an intervention, involve/target adults 60. years of age or older, and have an aim emphasizing the mobile phone's use in health. Results: Twenty-one different articles were found and categorized into ten different clinical domains, including diabetes, activities of daily life, and dementia care, among others. The largest group of articles focused on diabetes care (4 articles), followed by COPD (3 articles), Alzheimer's/dementia Care (3 articles) and osteoarthritis (3 articles). Areas of interest studied included feasibility, acceptability, and effectiveness. While there were many different clinical domains, the majority of studies were pilot studies that needed more work to establish a stronger base of evidence. Conclusions: Current work in using mobile phones for older adult use are spread across a variety of clinical domains. While this work is promising, current studies are generally smaller feasibility studies, and thus future work is needed to establish more generalizable, stronger base of evidence for effectiveness of these interventions. © 2013 Elsevier Inc.},
	number = {5},
	journal = {Journal of Biomedical Informatics},
	author = {Joe, Jonathan and Demiris, George},
	month = oct,
	year = {2013},
	pmid = {23810858},
	note = {Publisher: Elsevier Inc.},
	keywords = {Older adults, Mobile phones, Consumer health},
	pages = {947--954},
	file = {Joe_Demiris_2013_Older adults and mobile phones for health.pdf:/Users/orsonxu/Zotero/storage/SCK7WVTS/Joe_Demiris_2013_Older adults and mobile phones for health.pdf:application/pdf;Joe_Demiris_2013_Older adults and mobile phones for health.pdf:/Users/orsonxu/Zotero/storage/7Y5LFNJ3/Joe_Demiris_2013_Older adults and mobile phones for health.pdf:application/pdf},
}

@article{Regehr2013,
	title = {Interventions to reduce stress in university students: {A} review and meta-analysis},
	volume = {148},
	issn = {01650327},
	doi = {10.1016/j.jad.2012.11.026},
	abstract = {Background: Recent research has revealed concerning rates of anxiety and depression among university students. Nevertheless, only a small percentage of these students receive treatment from university health services. Universities are thus challenged with instituting preventative programs that address student stress and reduce resultant anxiety and depression. Method: A systematic review of the literature and meta-analysis was conducted to examine the effectiveness of interventions aimed at reducing stress in university students. Studies were eligible for inclusion if the assignment of study participants to experimental or control groups was by random allocation or parallel cohort design. Results: Retrieved studies represented a variety of intervention approaches with students in a broad range of programs and disciplines. Twenty-four studies, involving 1431 students were included in the meta-analysis. Cognitive, behavioral and mindfulness interventions were associated with decreased symptoms of anxiety. Secondary outcomes included lower levels of depression and cortisol. Limitations: Included studies were limited to those published in peer reviewed journals. These studies over-represent interventions with female students in Western countries. Studies on some types of interventions such as psycho-educational and arts based interventions did not have sufficient data for inclusion in the meta-analysis. Conclusion: This review provides evidence that cognitive, behavioral, and mindfulness interventions are effective in reducing stress in university students. Universities are encouraged to make such programs widely available to students. In addition however, future work should focus on developing stress reduction programs that attract male students and address their needs. © 2012 Elsevier B.V.},
	number = {1},
	journal = {Journal of Affective Disorders},
	author = {Regehr, Cheryl and Glancy, Dylan and Pitts, Annabel},
	year = {2013},
	pmid = {23246209},
	note = {Publisher: Elsevier},
	keywords = {Stress, Mindfulness, Depression, Anxiety, Cognitive-behavioral, University student},
	pages = {1--11},
	file = {Regehr et al_2013_Interventions to reduce stress in university students.pdf:/Users/orsonxu/Zotero/storage/AEB7CWJU/Regehr et al_2013_Interventions to reduce stress in university students.pdf:application/pdf;Regehr et al_2013_Interventions to reduce stress in university students.pdf:/Users/orsonxu/Zotero/storage/3IFTSLIT/Regehr et al_2013_Interventions to reduce stress in university students.pdf:application/pdf},
}

@article{Morrison2017,
	title = {The effect of timing and frequency of push notifications on usage of a smartphone-based stress management intervention: {An} exploratory trial},
	volume = {12},
	issn = {19326203},
	doi = {10.1371/journal.pone.0169162},
	abstract = {Push notifications offer a promising strategy for enhancing engagement with smartphone-based health interventions. Intelligent sensor-driven machine learning models may improve the timeliness of notifications by adapting delivery to a user's current context (e.g. location). This exploratory mixed-methods study examined the potential impact of timing and frequency on notification response and usage of Healthy Mind, a smartphone-based stress management intervention. 77 participants were randomised to use one of three versions of Healthy Mind that provided: intelligent notifications; daily notifications within pre-defined time frames; or occasional notifications within pre-defined time frames. Notification response and Healthy Mind usage were automatically recorded. Telephone interviews explored participants' experiences of using Healthy Mind. Participants in the intelligent and daily conditions viewed (d = .47, .44 respectively) and actioned (d = .50, .43 respectively) more notifications compared to the occasional group. Notification group had no meaningful effects on percentage of notifications viewed or usage of Healthy Mind. No meaningful differences were indicated between the intelligent and non-intelligent groups. Our findings suggest that frequent notifications may encourage greater exposure to intervention content without deterring engagement, but adaptive tailoring of notification timing does not always enhance their use. Hypotheses generated from this study require testing in future work. Trial registration number: ISRCTN67177737},
	number = {1},
	journal = {PLoS ONE},
	author = {Morrison, Leanne G. and Hargood, Charlie and Pejovic, Veljko and Geraghty, Adam W.A. and Lloyd, Scott and Goodman, Natalie and Michaelides, Danius T. and Weston, Anna and Musolesi, Mirco and Weal, Mark J. and Yardley, Lucy},
	year = {2017},
	pmid = {28046034},
	note = {ISBN: 1111111111},
	pages = {1--15},
	file = {Morrison et al_2017_The effect of timing and frequency of push notifications on usage of a smartphone-based stress management intervention.pdf:/Users/orsonxu/Zotero/storage/UTMGG7GI/Morrison et al_2017_The effect of timing and frequency of push notifications on usage of a smartphone-based stress management intervention.pdf:application/pdf;Morrison et al_2017_The effect of timing and frequency of push notifications on usage of a smartphone-based stress management intervention.pdf:/Users/orsonxu/Zotero/storage/33QU7MJH/Morrison et al_2017_The effect of timing and frequency of push notifications on usage of a smartphone-based stress management intervention.pdf:application/pdf},
}

@inproceedings{Prpa2020,
	address = {New York, NY, USA},
	title = {Inhaling and {Exhaling}: {How} {Technologies} {Can} {Perceptually} {Extend} our {Breath} {Awareness}},
	isbn = {978-1-4503-6708-0},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376183},
	doi = {10.1145/3313831.3376183},
	abstract = {Attending to breath is a self-awareness practice that exists within many contemplative and reflective traditions and is recognized for its benefits to well-being. Our current technological landscape embraces a large body of systems that utilize breath data in order to foster self-awareness. This paper seeks to deepen our understanding of the design space of systems that perceptually extend breath awareness. Our contribution is twofold: (1) our analysis reveals how the underlying theoretical frameworks shape the system design and its evaluation, and (2) how system design features support perceptual extension of breath awareness. We review and critically analyze 31 breath-based interactive systems. We identify 4 theoretical frameworks and 3 design strategies for interactive systems that perceptually extend breath awareness. We reflect upon this design space from both a theoretical and system design perspective, and propose future design directions for developing systems that "listen to" breath and perceptually extend it.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Prpa, Mirjana and Stepanova, Ekaterina R. and Schiphorst, Thecla and Riecke, Bernhard E. and Pasquier, Philippe},
	month = apr,
	year = {2020},
	keywords = {breath, breathing regulation, breathing synchronization, mindfulness-based design, perceptually extending, soma design},
	pages = {1--15},
	file = {Prpa et al_2020_Inhaling and Exhaling.pdf:/Users/orsonxu/Zotero/storage/T4IYTUVT/Prpa et al_2020_Inhaling and Exhaling.pdf:application/pdf;Prpa et al_2020_Inhaling and Exhaling.pdf:/Users/orsonxu/Zotero/storage/79SNGYF4/Prpa et al_2020_Inhaling and Exhaling.pdf:application/pdf},
}

@article{Paredes2018,
	title = {Just {Breathe}: {In}-{Car} {Interventions} for {Guided} {Slow} {Breathing}},
	volume = {2},
	issn = {2474-9567},
	url = {https://dl.acm.org/doi/10.1145/3191760},
	doi = {10.1145/3191760},
	abstract = {ABSTRACT The conjecture of Vainshtein \&amp; Zel\&apos;dovich (1972) concerning the existence of a fast dynamo (i.e. one whose growth rate is independent of magnetic diffusivity \&eta; in the limit \&eta; \&rarr; 0) is discussed with particular reference to (i) the stretch\&ndash;twist\&ndash;fold cycle which can double the strength of a magnetic flux tube, and (ii) the space-periodic Beltrami flow of maximal helicity, which has been shown to be capable of space-periodic dynamo action with the same period as the velocity field, by Arnold \&amp; Korkina (1983) and by Galloway \&amp; Frisch (1984). The topological constraint associated with conservation of magnetic helicity is shown to preclude fast dynamo action unless the scale of the magnetic field is almost everywhere of order \&eta;\&half; as \&eta; \&rarr; 0; in this case, the field structure is severely singular in the limit. A steady incompressible velocity field, quadratic in the space variables, is shown to mimic the action of the stretch\&ndash;twist\&ndash;fold cycle, and is proposed as a plausible candidate for fast dynamo action.},
	number = {1},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Paredes, Pablo E. and Zhou, Yijun and Hamdan, Nur Al-Huda and Balters, Stephanie and Murnane, Elizabeth and Ju, Wendy and Landay, James A.},
	month = mar,
	year = {2018},
	keywords = {Breathing, Mindfulness, Health, Autonomous automobiles, Commute, Deep Breathing, Interventions, Stress Management},
	pages = {1--23},
	file = {Paredes et al_2018_Just Breathe.pdf:/Users/orsonxu/Zotero/storage/HWIQ7PJB/Paredes et al_2018_Just Breathe.pdf:application/pdf;Paredes et al_2018_Just Breathe.pdf:/Users/orsonxu/Zotero/storage/H8PU4SF4/Paredes et al_2018_Just Breathe.pdf:application/pdf},
}

@article{McDuff2019,
	title = {Visceral {Machines}: {Risk}-{Aversion} in {Reinforcement} {Learning} with {Intrinsic} {Physiological} {Rewards}},
	url = {http://arxiv.org/abs/1805.09975},
	abstract = {As people learn to navigate the world, autonomic nervous system (e.g., "fight or flight") responses provide intrinsic feedback about the potential consequence of action choices (e.g., becoming nervous when close to a cliff edge or driving fast around a bend.) Physiological changes are correlated with these biological preparations to protect one-self from danger. We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. Our hypothesis is that such reward functions can circumvent the challenges associated with sparse and skewed rewards in reinforcement learning settings and can help improve sample efficiency. We test this in a simulated driving environment and show that it can increase the speed of learning and reduce the number of collisions during the learning stage.},
	journal = {7th International Conference on Learning Representations, ICLR 2019},
	author = {McDuff, Daniel and Kapoor, Ashish},
	month = may,
	year = {2018},
	pages = {1--11},
	file = {McDuff_Kapoor_2018_Visceral Machines.pdf:/Users/orsonxu/Zotero/storage/82SW2ZML/McDuff_Kapoor_2018_Visceral Machines.pdf:application/pdf;McDuff_Kapoor_2018_Visceral Machines.pdf:/Users/orsonxu/Zotero/storage/7M27TE59/McDuff_Kapoor_2018_Visceral Machines.pdf:application/pdf},
}

@article{NicholasDiasYungPeng2017,
	title = {Sensing behavioral symptoms of mental health and delivering personalized interventions using mobile technologies},
	volume = {176},
	doi = {10.1016/j.physbeh.2017.03.040},
	number = {3},
	journal = {Depression and anxiety},
	author = {Aung, Min Hane and Matthews, Mark and Choudhury, Tanzeem},
	year = {2017},
	note = {ISBN: 3902264330},
	keywords = {endothelium, estrogen, estrogen receptors, vascular smooth muscle},
	pages = {139--148},
	file = {Aung et al_2017_Sensing behavioral symptoms of mental health and delivering personalized interventions using mobile technologies.pdf:/Users/orsonxu/Zotero/storage/S37KFAUQ/Aung et al_2017_Sensing behavioral symptoms of mental health and delivering personalized interventions using mobile technologies.pdf:application/pdf;Aung et al_2017_Sensing behavioral symptoms of mental health and delivering personalized interventions using mobile technologies.pdf:/Users/orsonxu/Zotero/storage/QJ83GJ63/Aung et al_2017_Sensing behavioral symptoms of mental health and delivering personalized interventions using mobile technologies.pdf:application/pdf},
}

@inproceedings{Sarker2016,
	address = {New York, NY, USA},
	title = {Finding {Significant} {Stress} {Episodes} in a {Discontinuous} {Time} {Series} of {Rapidly} {Varying} {Mobile} {Sensor} {Data}},
	isbn = {978-1-4503-3362-7},
	url = {http://dl.acm.org/citation.cfm?doid=2858036.2858218},
	doi = {10.1145/2858036.2858218},
	abstract = {Management of daily stress can be greatly improved by de-livering sensor-triggered just-in-time interventions (JITIs) on mobile devices. The success of such JITIs critically depends on being able to mine the time series of noisy sensor data to find the most opportune moments. In this paper, we propose a time series pattern mining method to detect significant stress episodes in a time series of discontinuous and rapidly varying stress data. We apply our model to 4 weeks of physiological, GPS, and activity data collected from 38 users in their natu-ral environment to discover patterns of stress in real-life. We find that the duration of a prior stress episode predicts the du-ration of the next stress episode and stress in mornings and evenings is lower than during the day. We then analyze the relationship between stress and objectively rated disorder in the surrounding neighborhood and develop a model to predict stressful episodes.},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Sarker, Hillol and Tyburski, Matthew and Rahman, Md Mahbubur and Hovsepian, Karen and Sharmin, Moushumi and Epstein, David H. and Preston, Kenzie L. and Furr-Holden, C. Debra and Milam, Adam and Nahum-Shani, Inbal and Al'Absi, Mustafa and Kumar, Santosh},
	month = may,
	year = {2016},
	pmid = {28058409},
	pages = {4489--4501},
	file = {Sarker et al_2016_Finding Significant Stress Episodes in a Discontinuous Time Series of Rapidly Varying Mobile Sensor Data.pdf:/Users/orsonxu/Zotero/storage/DMGWCB8Z/Sarker et al_2016_Finding Significant Stress Episodes in a Discontinuous Time Series of Rapidly Varying Mobile Sensor Data.pdf:application/pdf;Sarker et al_2016_Finding Significant Stress Episodes in a Discontinuous Time Series of Rapidly Varying Mobile Sensor Data.pdf:/Users/orsonxu/Zotero/storage/AXRP2DLN/Sarker et al_2016_Finding Significant Stress Episodes in a Discontinuous Time Series of Rapidly Varying Mobile Sensor Data.pdf:application/pdf},
}

@article{Burns2011,
	title = {Harnessing {Context} {Sensing} to {Develop} a {Mobile} {Intervention} for {Depression}},
	volume = {13},
	doi = {10.2196/jmir.1838},
	number = {3},
	journal = {JMIR},
	author = {Burns, Michelle Nicole and Begale, Mark and Duffecy, Jennifer and Gergle, Darren and Karr, Chris J and Giangrande, Emily and Mohr, David C},
	year = {2011},
	keywords = {depression, data mining, mobile health, artificial intelligence, behavior therapy, cellular phone, context-aware systems, mobile phone, sensors, telemedicine},
	file = {Burns et al_2011_Harnessing Context Sensing to Develop a Mobile Intervention for Depression.pdf:/Users/orsonxu/Zotero/storage/Z5DLTZ6T/Burns et al_2011_Harnessing Context Sensing to Develop a Mobile Intervention for Depression.pdf:application/pdf;Burns et al_2011_Harnessing Context Sensing to Develop a Mobile Intervention for Depression.pdf:/Users/orsonxu/Zotero/storage/88TYV6IB/Burns et al_2011_Harnessing Context Sensing to Develop a Mobile Intervention for Depression.pdf:application/pdf},
}

@article{George2013,
	title = {Facebook-based stress management resources for first-year medical students: {A} multi-method evaluation},
	volume = {29},
	issn = {07475632},
	url = {http://dx.doi.org/10.1016/j.chb.2012.12.008},
	doi = {10.1016/j.chb.2012.12.008},
	abstract = {Student anxiety and doubt about academic performance in the early years of medical school have been well documented. Stress management programs can be helpful but are challenged by shortages of time, personnel, and resources. Therefore, popular online social networks such as Facebook may offer an innovative strategy for addressing student stress and supporting coping. This pilot study explored whether first-year medical students could benefit from a stress management intervention based exclusively on Facebook. During orientation week at Penn State College of Medicine, participants were randomly assigned to a Facebook stress management group that addressed problematic issues during the first semester. The intervention took place during the first eleven weeks of medical school. A multi-method evaluation of the intervention was completed using descriptive statistics for demographics and frequencies and qualitative procedures for focus group data. The accessibility and ease of use of a Facebook-based stress management program proved valuable for medical students, particularly early in the semester when engagement was greatest. These preliminary results suggest that medical schools might consider adding an online social networking component to existing stress management programming. This online strategy may also be of benefit to other health professionals and students from other health disciplines. © 2012 Elsevier Ltd. All rights reserved.},
	number = {3},
	journal = {Computers in Human Behavior},
	author = {George, Daniel R. and Dellasega, Cheryl and Whitehead, Megan M. and Bordon, Alan},
	year = {2013},
	pmid = {85814659},
	note = {ISBN: 07475632},
	keywords = {Social media, Communication, Medical education, Social network, Stress management, Technology},
	pages = {559--562},
	file = {George et al_2013_Facebook-based stress management resources for first-year medical students.pdf:/Users/orsonxu/Zotero/storage/SIKV6WT6/George et al_2013_Facebook-based stress management resources for first-year medical students.pdf:application/pdf;George et al_2013_Facebook-based stress management resources for first-year medical students.pdf:/Users/orsonxu/Zotero/storage/5LY4VTD9/George et al_2013_Facebook-based stress management resources for first-year medical students.pdf:application/pdf},
}

@inproceedings{Sharmin2015,
	address = {New York, New York, USA},
	title = {Visualization of time-series sensor data to inform the design of just-in-time adaptive stress interventions},
	isbn = {978-1-4503-3574-4},
	url = {http://dl.acm.org/citation.cfm?doid=2750858.2807537},
	doi = {10.1145/2750858.2807537},
	abstract = {We investigate needs, challenges, and opportunities in visualizing time-series sensor data on stress to inform the design of just-in-Time adaptive interventions (JITAIs). We identify seven key challenges: massive volume and variety of data, complexity in identifying stressors, scalability of space, multifaceted relationship between stress and time, a need for representation at multiple granularities, interperson variability, and limited understanding of JITAI design requirements due to its novelty. We propose four new visualizations based on one million minutes of sensor data (n=70). We evaluate our visualizations with stress researchers (n=6) to gain first insights into its usability and usefulness in JITAI design. Our results indicate that spatiotemporal visualizations help identify and explain betweenand within-person variability in stress patterns and contextual visualizations enable decisions regarding the timing, content, and modality of intervention. Interestingly, a granular representation is considered informative but noise-prone; an abstract representation is the preferred starting point for designing JITAIs.},
	booktitle = {Proceedings of the 2015 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} - {UbiComp} '15},
	publisher = {ACM Press},
	author = {Sharmin, Moushumi and Raij, Andrew and Epstien, David and Nahum-Shani, Inbal and Beck, J. Gayle and Vhaduri, Sudip and Preston, Kenzie and Kumar, Santosh},
	year = {2015},
	pmid = {26539566},
	keywords = {Stress, Visualization, Stress Management, Just-in-Time Adaptive Interventions (JITAIs)},
	pages = {505--516},
	file = {Sharmin et al_2015_Visualization of time-series sensor data to inform the design of just-in-time adaptive stress interventions.pdf:/Users/orsonxu/Zotero/storage/X9WUYNBB/Sharmin et al_2015_Visualization of time-series sensor data to inform the design of just-in-time adaptive stress interventions.pdf:application/pdf;Sharmin et al_2015_Visualization of time-series sensor data to inform the design of just-in-time adaptive stress interventions.pdf:/Users/orsonxu/Zotero/storage/R95Q4ZWG/Sharmin et al_2015_Visualization of time-series sensor data to inform the design of just-in-time adaptive stress interventions.pdf:application/pdf},
}

@article{Paredes2011,
	title = {{CalmMeNow}: exploratory research and design of stress mitigating mobile interventions},
	url = {http://portal.acm.org/citation.cfm?doid=1979742.1979831},
	doi = {10.1145/1979742.1979831},
	abstract = {This paper describes design explorations for stress mitigation on mobile devices based on three types of interventions: haptic feedback, games and social networks. The paper offers a qualitative assessment of the usability of these three types of interventions together with an initial analysis of their potential efficacy. Social networking and games show great potential for stress relief. Lastly, the paper discusses key findings and considerations for long-term studies of stress mitigation in HCI, as well as a list of aspects to be considered when designing calming interventions.},
	journal = {Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems - CHI EA '11},
	author = {Paredes, Pablo and Chan, Matthew},
	year = {2011},
	note = {ISBN: 9781450302685},
	keywords = {games, health technology, social networks, wearable computing, acm classification keywords, haptics, touch therapy},
	pages = {1699},
	file = {Paredes_Chan_2011_CalmMeNow.pdf:/Users/orsonxu/Zotero/storage/9SJCLGQ9/Paredes_Chan_2011_CalmMeNow.pdf:application/pdf;Paredes_Chan_2011_CalmMeNow.pdf:/Users/orsonxu/Zotero/storage/L3CSJ5NG/Paredes_Chan_2011_CalmMeNow.pdf:application/pdf},
}

@article{Yamaguchi2013,
	title = {Effects of short-term interventions to reduce mental health-related stigma in university or college students: {A} systematic review},
	volume = {201},
	issn = {00223018},
	doi = {10.1097/NMD.0b013e31829480df},
	abstract = {Although there are many interventions to reduce mental health-related stigma in university or college students, their overall effect is unknown. This article systematically reviews intervention studies and aims to identify the effective approaches. We searched 11 bibliographic databases, Google, Web sites of relevant associations, and reference lists and contacted specialists. A total of 35 studies (N = 4257) of a wide range of interventions met the inclusion criteria. Social contact or video-based social contact interventions seemed to be the most effective in improving attitudes and reducing desire for social distance. Evidence from one study suggests that a lecture that provided treatment information may enhance students' attitudes toward the use of services. However, methodological weaknesses in many studies were also found. There was a lack of evidence for interventions in medical students, for long-term effects of interventions, or for having a positive impact on actual behaviors. Further research having more rigorous methods is needed to confirm this.},
	number = {6},
	journal = {Journal of Nervous and Mental Disease},
	author = {Yamaguchi, Sosei and Wu, Shu I. and Biswas, Milly and Yate, Madinah and Aoki, Yuta and Barley, Elizabeth A. and Thornicroft, Graham},
	year = {2013},
	pmid = {23719324},
	note = {ISBN: 00223018 (ISSN)},
	keywords = {Stigma, Systematic review, University students},
	pages = {490--503},
	file = {Yamaguchi et al_2013_Effects of short-term interventions to reduce mental health-related stigma in university or college students.pdf:/Users/orsonxu/Zotero/storage/8JSC876Q/Yamaguchi et al_2013_Effects of short-term interventions to reduce mental health-related stigma in university or college students.pdf:application/pdf;Yamaguchi et al_2013_Effects of short-term interventions to reduce mental health-related stigma in university or college students.pdf:/Users/orsonxu/Zotero/storage/3TJ6PS9M/Yamaguchi et al_2013_Effects of short-term interventions to reduce mental health-related stigma in university or college students.pdf:application/pdf},
}

@inproceedings{Zepf2020,
	address = {New York, NY, USA},
	title = {Studying {Personalized} {Just}-in-time {Auditory} {Breathing} {Guides} and {Potential} {Safety} {Implications} during {Simulated} {Driving}},
	isbn = {978-1-4503-6861-2},
	url = {https://dl.acm.org/doi/10.1145/3340631.3394854},
	doi = {10.1145/3340631.3394854},
	abstract = {Driving can occupy a considerable part of our daily lives and is often associated with high levels of stress. Motivated by the effectiveness of controlled breathing, this work studies the potential use of breathing interventions while driving to help manage stress. In particular, we implemented and evaluated a closed-loop system that monitored the breathing rate of drivers in real-time and delivered either a conscious or an unconscious personalized acoustic breathing guide whenever needed. In a study with 24 participants, we observed that conscious interventions more effectively reduced the breathing rate but also increased the number of driving mistakes. We observed that prior driving experience as well as personality are significantly associated with the effect of the interventions, which highlights the importance of considering user profiles for in-car stress management interventions.},
	booktitle = {Proceedings of the 28th {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {ACM},
	author = {Zepf, Sebastian and El Haouij, Neska and Lee, Jinmo and Ghandeharioun, Asma and Hernandez, Javier and Picard, Rosalind W.},
	month = jul,
	year = {2020},
	keywords = {personalization, auditory interventions, automotive, breathing, closed-loop interventions, stress management},
	pages = {275--283},
	file = {Zepf et al_2020_Studying Personalized Just-in-time Auditory Breathing Guides and Potential Safety Implications during Simulated Driving.pdf:/Users/orsonxu/Zotero/storage/WM39UHH6/Zepf et al_2020_Studying Personalized Just-in-time Auditory Breathing Guides and Potential Safety Implications during Simulated Driving.pdf:application/pdf;Zepf et al_2020_Studying Personalized Just-in-time Auditory Breathing Guides and Potential Safety Implications during Simulated Driving.pdf:/Users/orsonxu/Zotero/storage/NQR2JM3F/Zepf et al_2020_Studying Personalized Just-in-time Auditory Breathing Guides and Potential Safety Implications during Simulated Driving.pdf:application/pdf},
}

@inproceedings{Rojas2020,
	title = {Activity {Recommendation}: {Optimizing} {Life} in the {Long} {Term}},
	isbn = {978-1-72814-657-7},
	url = {https://ieeexplore.ieee.org/document/9127358/},
	doi = {10.1109/PerCom45495.2020.9127358},
	booktitle = {2020 {IEEE} {International} {Conference} on {Pervasive} {Computing} and {Communications} ({PerCom})},
	publisher = {IEEE},
	author = {Ramos Rojas, Julian A. and Rosas, Johana and Shen, Yilin and Jin, Hongxia and Dey, Anind K.},
	month = mar,
	year = {2020},
	keywords = {reinforcement learning, in this article, a way that will, build an activity recommendation, college, lead, method to automatically, model that can help, q-learning, students to better plan, their everyday life in, we present a novel},
	pages = {1--10},
	file = {Ramos Rojas et al_2020_Activity Recommendation.pdf:/Users/orsonxu/Zotero/storage/FCSCBSBM/Ramos Rojas et al_2020_Activity Recommendation.pdf:application/pdf;Ramos Rojas et al_2020_Activity Recommendation.pdf:/Users/orsonxu/Zotero/storage/9JZZELP9/Ramos Rojas et al_2020_Activity Recommendation.pdf:application/pdf},
}

@article{Hardeman2019,
	title = {A systematic review of just-in-time adaptive interventions ({JITAIs}) to promote physical activity},
	volume = {16},
	issn = {1479-5868},
	url = {https://ijbnpa.biomedcentral.com/articles/10.1186/s12966-019-0792-7},
	doi = {10.1186/s12966-019-0792-7},
	abstract = {Background: Progress in mobile health (mHealth) technology has enabled the design of just-in-time adaptive interventions (JITAIs). We define JITAIs as having three features: behavioural support that directly corresponds to a need in real-time; content or timing of support is adapted or tailored according to input collected by the system since support was initiated; support is system-triggered. We conducted a systematic review of JITAIs for physical activity to identify their features, feasibility, acceptability and effectiveness. Methods: We searched Scopus, Medline, Embase, PsycINFO, Web of Science, DBLP, ACM Digital Library, Cochrane Central Register of Controlled Trials, ClinicalTrials.gov and the ISRCTN register using terms related to physical activity, mHealth interventions and JITAIs. We included primary studies of any design reporting data about JITAIs, irrespective of population, age and setting. Outcomes included physical activity, engagement, uptake, feasibility and acceptability. Paper screening and data extraction were independently validated. Synthesis was narrative. We used the mHealth Evidence Reporting and Assessment checklist to assess quality of intervention descriptions. Results: We screened 2200 titles, 840 abstracts, 169 full-text papers, and included 19 papers reporting 14 unique JITAIs, including six randomised studies. Five JITAIs targeted both physical activity and sedentary behaviour, five sedentary behaviour only, and four physical activity only. JITAIs prompted breaks following sedentary periods and/or suggested physical activities during opportunistic moments, typically over three to four weeks. Feasibility challenges related to the technology, sensor reliability and timeliness of just-in-time messages. Overall, participants found JITAIs acceptable. We found mixed evidence for intervention effects on behaviour, but no study was sufficiently powered to detect any effects. Common behaviour change techniques were goal setting (behaviour), prompts/cues, feedback on behaviour and action planning. Five studies reported a theory-base. We found lack of evidence about cost-effectiveness, uptake, reach, impact on health inequalities, and sustained engagement. Conclusions: Research into JITAIs to increase physical activity and reduce sedentary behaviour is in its early stages. Consistent use and a shared definition of the term 'JITAI' will aid evidence synthesis. We recommend robust evaluation of theory and evidence-based JITAIs in representative populations. Decision makers and health professionals need to be cautious in signposting patients to JITAIs until such evidence is available, although they are unlikely to cause health-related harm. Reference: PROSPERO 2017 CRD42017070849.},
	number = {1},
	journal = {International Journal of Behavioral Nutrition and Physical Activity},
	author = {Hardeman, Wendy and Houghton, Julie and Lane, Kathleen and Jones, Andy and Naughton, Felix},
	month = dec,
	year = {2019},
	pmid = {30943983},
	note = {Publisher: International Journal of Behavioral Nutrition and Physical Activity},
	keywords = {Mobile applications, Physical activity, Mobile Health, Digital intervention, Exercise, Just-in-time Adaptive Intervention, Sedentary behaviour, Telemedicine},
	pages = {31},
	file = {Hardeman et al_2019_A systematic review of just-in-time adaptive interventions (JITAIs) to promote physical activity.pdf:/Users/orsonxu/Zotero/storage/Z6Z3CUZU/Hardeman et al_2019_A systematic review of just-in-time adaptive interventions (JITAIs) to promote physical activity.pdf:application/pdf;Hardeman et al_2019_A systematic review of just-in-time adaptive interventions (JITAIs) to promote physical activity.pdf:/Users/orsonxu/Zotero/storage/KZTCKZSF/Hardeman et al_2019_A systematic review of just-in-time adaptive interventions (JITAIs) to promote physical activity.pdf:application/pdf;supp_study_condition_control.pdf:/Users/orsonxu/Zotero/storage/ZV7ITEIN/supp_study_condition_control.pdf:application/pdf},
}

@article{ringland_designing_2021,
	title = {Designing for {Emotional} {Well}-being : {Integrating} {Persuasion} and {Customization} into {Mental} {Health} {Technologies}},
	author = {Ringland, Kathryn E and Paan, Melina and Mohr, David C},
	year = {2021},
	note = {ISBN: 9781450380966},
	keywords = {mental health, acm reference format, behavior change, customiza-, ethics, mhealth, mHealth, mobile apps, mental health, behavior chan, mobile apps, persuasion, tion},
	file = {Ringland et al_2021_Designing for Emotional Well-being.pdf:/Users/orsonxu/Zotero/storage/AQTGMACM/Ringland et al_2021_Designing for Emotional Well-being.pdf:application/pdf;Ringland et al_2021_Designing for Emotional Well-being.pdf:/Users/orsonxu/Zotero/storage/57FI7T3B/Ringland et al_2021_Designing for Emotional Well-being.pdf:application/pdf},
}

@article{Michie2011_behaviorchange_wheel,
	title = {The behaviour change wheel: {A} new method for characterising and designing behaviour change interventions},
	volume = {6},
	issn = {1748-5908},
	url = {http://implementationscience.biomedcentral.com/articles/10.1186/1748-5908-6-42g},
	doi = {10.1186/1748-5908-6-42},
	number = {1},
	journal = {Implementation Science},
	author = {Michie, Susan and van Stralen, Maartje M and West, Robert},
	month = dec,
	year = {2011},
	pmid = {4015142},
	pages = {42},
	file = {Michie et al_2011_The behaviour change wheel.pdf:/Users/orsonxu/Zotero/storage/NRG3LW4L/Michie et al_2011_The behaviour change wheel.pdf:application/pdf;Michie et al_2011_The behaviour change wheel.pdf:/Users/orsonxu/Zotero/storage/TF8CDVZI/Michie et al_2011_The behaviour change wheel.pdf:application/pdf},
}

@inproceedings{Fogg2009Behaivomodel,
	address = {New York, New York, USA},
	title = {A behavior model for persuasive design},
	volume = {56},
	isbn = {978-1-60558-376-1},
	url = {http://portal.acm.org/citation.cfm?doid=1541948.1541999},
	doi = {10.1145/1541948.1541999},
	booktitle = {Proceedings of the 4th {International} {Conference} on {Persuasive} {Technology} - {Persuasive} '09},
	publisher = {ACM Press},
	author = {Fogg, BJ},
	year = {2009},
	note = {Issue: 5
ISSN: 17511097},
	keywords = {captology, technology, behavior change, persuasion, motivation, persuasive, persuasive design, simplicity, the need to understand, triggers},
	pages = {1},
	file = {Fogg_2009_A behavior model for persuasive design.pdf:/Users/orsonxu/Zotero/storage/39ZDSYET/Fogg_2009_A behavior model for persuasive design.pdf:application/pdf;Fogg_2009_A behavior model for persuasive design.pdf:/Users/orsonxu/Zotero/storage/KV3H5MGU/Fogg_2009_A behavior model for persuasive design.pdf:application/pdf},
}

@article{Kim2019,
	title = {{GoalKeeper}: {Exploring} {Interaction} {Lockout} {Mechanisms} for {Regulating} {Smartphone} {Use}},
	volume = {3},
	issn = {2474-9567},
	doi = {10.1145/3314403},
	abstract = {Many people often experience difficulties in achieving behavioral goals related to smartphone use. Most of prior studies approached this problem with various behavior change strategies such as self-reflection and social support. However, little is known about the effectiveness and user experiences of restrictive and coercive interventions such as blocking. In this work, we developed “GoalKeeper,” a smartphone intervention app that locks the user into the self-defined daily use time limit with restrictive intervention mechanisms. We conducted a four-week field experiment with 36 participants to investigate the effects and user experiences of varying intensities of restrictive interventions. The results showed that restrictive mechanisms are more effective than non-restrictive mechanisms such as warning. However, we found that restrictive mechanisms caused more frustration and pressure to the users, mainly due to diversity of usage contexts and needs. Based on our study results, we extracted practical implications for designing restrictive mechanisms that balance the intervention effectiveness for behavioral changes and the flexibility for user acceptability},
	number = {1},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Kim, Jaejeung and Jung, Hayoung and Ko, Minsam and Lee, Uichin},
	year = {2019},
	keywords = {persuasive technology, behavior change, commitment device, ILM, interaction lockout, lockout intensity, lockout mechanism, restrictive technology, self-imposed restriction, smartphone non-use},
	pages = {1--29},
	file = {Kim et al_2019_GoalKeeper.pdf:/Users/orsonxu/Zotero/storage/TQ9GSLFI/Kim et al_2019_GoalKeeper.pdf:application/pdf;Kim et al_2019_GoalKeeper.pdf:/Users/orsonxu/Zotero/storage/CAVQGEDW/Kim et al_2019_GoalKeeper.pdf:application/pdf},
}

@article{Pinder2018,
	title = {Digital {Behaviour} {Change} {Interventions} to {Break} and {Form} {Habits}},
	volume = {25},
	issn = {10730516},
	url = {http://dl.acm.org/citation.cfm?doid=3231919.3196830},
	doi = {10.1145/3196830},
	abstract = {Digital behaviour change interventions, particularly those using pervasive computing technology, hold great promise in supporting users to change their behaviour. However, most interventions fail to take habitual behaviour into account, limiting their potential impact. This failure is partly driven by a plethora of overlapping behaviour change theories and related strategies that do not consider the role of habits. We critically review the main theories and models used in the research to analyse their application to designing effective habitual behaviour change interventions. We highlight the potential for Dual Process Theory, modern habit theory, and Goal Setting Theory, which together model how users form and break habits, to drive effective digital interventions. We synthesise these theories into an explanatory framework, the Habit Alteration Model, and use it to outline the state of the art. We identify the opportunities and challenges of habit-focused interventions. CCS Concepts: • Human-centered computing → HCI theory, concepts and models; Ubiquitous and mobile computing design and evaluation methods; • General and reference → Surveys and overviews; Additional Key Words and Phrases: Digital behaviour change interventions, behaviour change technology, persuasive technology, habit breaking technology, habit forming technology ACM Reference format:},
	number = {3},
	journal = {ACM Transactions on Computer-Human Interaction},
	author = {Pinder, Charlie and Vermeulen, Jo and Cowan, Benjamin R. and Beale, Russell},
	year = {2018},
	pages = {1--66},
	file = {Pinder et al_2018_Digital Behaviour Change Interventions to Break and Form Habits.pdf:/Users/orsonxu/Zotero/storage/VJGZPTAL/Pinder et al_2018_Digital Behaviour Change Interventions to Break and Form Habits.pdf:application/pdf;Pinder et al_2018_Digital Behaviour Change Interventions to Break and Form Habits.pdf:/Users/orsonxu/Zotero/storage/7M655K8Q/Pinder et al_2018_Digital Behaviour Change Interventions to Break and Form Habits.pdf:application/pdf},
}

@article{Hiniker2016,
	title = {{MyTime}: {Designing} and evaluating an intervention for smartphone non-use},
	doi = {10.1145/2858036.2858403},
	abstract = {Though many people report an interest in self-limiting certain aspects of their phone use, challenges adhering to selfdefined limits are common. We conducted a design exercise and online survey to map the design space of interventions for smartphone non-use and distilled these into a small taxonomy of intervention categories. Using these findings, we implemented "MyTime," an intervention to support people in achieving goals related to smartphone non-use. We conducted a deployment study with 23 participants over two weeks and found that participants reduced their time with the apps they feel are a poor use of time by 21\% while their use of the apps they feel are a good use of time remained unchanged. We found that a small taxonomy describes users' diverse set of desired behavior changes relating to smartphone non-use, and that these desired changes predict: 1) the hypothetical features they are interested in trying, 2) the extent to which they engage with these features in practice, and 3) their changes in behavior in response to the intervention. We link users' desired behaviors to the categories of our design taxonomy, providing a foundation for a theoretical model of designing for smartphone non-use.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Hiniker, Alexis and Hong, Sungsoo and Kohno, Tadayoshi and Kientz, Julie A.},
	year = {2016},
	note = {ISBN: 9781450333627},
	keywords = {Mindfulness, Smartphones, Mobile phones, Productivity, Technology non-use},
	pages = {4746--4757},
	file = {Hiniker et al_2016_MyTime.pdf:/Users/orsonxu/Zotero/storage/SEALDE5Q/Hiniker et al_2016_MyTime.pdf:application/pdf;Hiniker et al_2016_MyTime.pdf:/Users/orsonxu/Zotero/storage/EIFTHK4D/Hiniker et al_2016_MyTime.pdf:application/pdf},
}

@article{Kim2019a,
	title = {{LocknType}: {Lockout} task intervention for discouraging smartphone app use},
	doi = {10.1145/3290605.3300927},
	abstract = {Instant access and gratification make it difficult for us to self-limit the use of smartphone apps. We hypothesize that a slight increase in the interaction cost of accessing an app could successfully discourage app use. We propose a proactive intervention that requests users to perform a simple lockout task (e.g., typing a fixed length number) whenever a target app is launched. We investigate how a lockout task with varying workloads (i.e., pause only without number input, 10-digit input, and 30-digit input) influence a user’s decision making, by a 3-week, in-situ experiment with 40 participants. Our findings show that even the pause-only task that requires a user to press a button to proceed discouraged an average of 13.1\% of app use, and the 30-digit-input task discouraged 47.5\%. We derived determinants of app use and non-use decision making for a given lockout task. We further provide implications for persuasive technology design for discouraging undesired behaviors.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Kim, Jaejeung and Park, Joonyoung and Lee, Hyunsoo and Ko, Minsam and Lee, Uichin},
	year = {2019},
	note = {ISBN: 9781450359702},
	keywords = {Interaction restraint, Intervention design, Lockout task, Smartphone overuse},
	pages = {1--12},
	file = {Kim et al_2019_LocknType.pdf:/Users/orsonxu/Zotero/storage/Y3JX9SGP/Kim et al_2019_LocknType.pdf:application/pdf;Kim et al_2019_LocknType.pdf:/Users/orsonxu/Zotero/storage/CW4PUG3B/Kim et al_2019_LocknType.pdf:application/pdf},
}

@article{Lyngs2019,
	title = {Self-control in cyberspace: {Applying} dual systems theory to a review of digital self-control tools},
	doi = {10.1145/3290605.3300361},
	abstract = {Many people struggle to control their use of digital devices. However, our understanding of the design mechanisms that support user self-control remains limited. In this paper, we make two contributions to HCI research in this space: first, we analyse 367 apps and browser extensions from the Google Play, Chrome Web, and Apple App stores to identify common core design features and intervention strategies afforded by current tools for digital self-control. Second, we adapt and apply an integrative dual systems model of self-regulation as a framework for organising and evaluating the design features found. Our analysis aims to help the design of better tools in two ways: (i) by identifying how, through a well-established model of self-regulation, current tools overlap and differ in how they support self-control; and (ii) by using the model to reveal underexplored cognitive mechanisms that could aid the design of new tools.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Lyngs, Ulrik and Lukoff, Kai and Slovak, Petr and Binns, Reuben and Slack, Adam and Inzlicht, Michael and Van Kleek, Max and Shadbolt, Nigel},
	year = {2019},
	note = {ISBN: 9781450359702},
	keywords = {Attention, Focus, Addiction, Distraction, ICT non-use, Interruptions, Self-control, Self-regulation},
	pages = {1--18},
	file = {Lyngs et al_2019_Self-control in cyberspace.pdf:/Users/orsonxu/Zotero/storage/YVT3ZIQE/Lyngs et al_2019_Self-control in cyberspace.pdf:application/pdf;Lyngs et al_2019_Self-control in cyberspace.pdf:/Users/orsonxu/Zotero/storage/5MNYBT7L/Lyngs et al_2019_Self-control in cyberspace.pdf:application/pdf},
}

@article{qu_exploring_2019,
	title = {Exploring and {Designing} for {Memory} {Impairments} in {Depression}},
	author = {Qu, Chengcheng and Doherty, Gavin},
	year = {2019},
	note = {ISBN: 9781450359702},
	pages = {1--14},
	file = {Qu_Doherty_2019_Exploring and Designing for Memory Impairments in Depression.pdf:/Users/orsonxu/Zotero/storage/C4H66GXJ/Qu_Doherty_2019_Exploring and Designing for Memory Impairments in Depression.pdf:application/pdf;Qu_Doherty_2019_Exploring and Designing for Memory Impairments in Depression.pdf:/Users/orsonxu/Zotero/storage/X342VE23/Qu_Doherty_2019_Exploring and Designing for Memory Impairments in Depression.pdf:application/pdf},
}

@article{choi_multi-stage_2019,
	title = {Multi-{Stage} {Receptivity} {Model} for {Mobile} {Just}-{In}-{Time} {Health} {Intervention}},
	volume = {3},
	issn = {2474-9567},
	url = {https://dl.acm.org/doi/10.1145/3328910},
	doi = {10.1145/3328910},
	abstract = {A critical aspect of mobile just-in-time (JIT) health intervention is proper delivery timing, which correlates with successfully promoting target behaviors. Despite extensive prior studies on interruptibility, however, our understanding of the receptivity of mobile JIT health intervention is limited. This work extends prior interruptibility models to capture the JIT intervention process by including multiple stages of conscious and subconscious decisions. We built BeActive, a mobile intervention system for preventing prolonged sedentary behaviors, and we collected users' responses to a given JIT support and relevant contextual factors and cognitive/physical states for three weeks. Using a multi-stage model, we systematically analyzed the responses to deepen our understanding of receptivity using a mixed methodology. Herein, we identify the key factors relevant to each stage outcome and show that the receptivity of JIT intervention is nuanced and context-dependent. We propose several practical design implications for mobile JIT health intervention and context-aware computing.},
	language = {en},
	number = {2},
	urldate = {2022-06-05},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Choi, Woohyeok and Park, Sangkeun and Kim, Duyeon and Lim, Youn-kyung and Lee, Uichin},
	month = jun,
	year = {2019},
	pages = {1--26},
	file = {Choi et al. - 2019 - Multi-Stage Receptivity Model for Mobile Just-In-T.pdf:/Users/orsonxu/Zotero/storage/M5ADIHBV/Choi et al. - 2019 - Multi-Stage Receptivity Model for Mobile Just-In-T.pdf:application/pdf},
}

@inproceedings{kim_prediction_2022,
	address = {New Orleans LA USA},
	title = {Prediction for {Retrospection}: {Integrating} {Algorithmic} {Stress} {Prediction} into {Personal} {Informatics} {Systems} for {College} {Students}’ {Mental} {Health}},
	isbn = {978-1-4503-9157-3},
	shorttitle = {Prediction for {Retrospection}},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517701},
	doi = {10.1145/3491102.3517701},
	abstract = {Refecting on stress-related data is critical in addressing one’s mental health. Personal Informatics (PI) systems augmented by algorithms and sensors have become popular ways to help users collect and refect on data about stress. While prediction algorithms in the PI systems are mainly for diagnostic purposes, few studies examine how the explainability of algorithmic prediction can support user-driven self-insight. To this end, we developed MindScope, an algorithm-assisted stress management system that determines user stress levels and explains how the stress level was computed based on the user’s everyday activities captured by a smartphone. In a 25day feld study conducted with 36 college students, the prediction and explanation supported self-refection, a process to re-establish preconceptions about stress by identifying stress patterns and recalling past stress levels and patterns that led to coping planning. We discuss the implications of exploiting prediction algorithms that facilitate user-driven retrospection in PI systems.},
	language = {en},
	urldate = {2022-05-27},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Kim, Taewan and Kim, Haesoo and Lee, Ha Yeon and Goh, Hwarang and Abdigapporov, Shakhboz and Jeong, Mingon and Cho, Hyunsung and Han, Kyungsik and Noh, Youngtae and Lee, Sung-Ju and Hong, Hwajung},
	month = apr,
	year = {2022},
	pages = {1--20},
	file = {Kim et al. - 2022 - Prediction for Retrospection Integrating Algorith.pdf:/Users/orsonxu/Zotero/storage/VYD3EEKW/Kim et al. - 2022 - Prediction for Retrospection Integrating Algorith.pdf:application/pdf},
}

@article{wahle_mobile_2016,
	title = {Mobile {Sensing} and {Support} for {People} {With} {Depression}: {A} {Pilot} {Trial} in the {Wild}},
	volume = {4},
	issn = {2291-5222},
	url = {http://mhealth.jmir.org/2016/3/e111/},
	doi = {10.2196/mhealth.5960},
	abstract = {Background: Depression is a burdensome, recurring mental health disorder with high prevalence. Even in developed countries, patients have to wait for several months to receive treatment. In many parts of the world there is only one mental health professional for over 200 people. Smartphones are ubiquitous and have a large complement of sensors that can potentially be useful in monitoring behavioral patterns that might be indicative of depressive symptoms and providing context-sensitive intervention support. Objective: The objective of this study is 2-fold, first to explore the detection of daily-life behavior based on sensor information to identify subjects with a clinically meaningful depression level, second to explore the potential of context sensitive intervention delivery to provide in-situ support for people with depressive symptoms. Methods: A total of 126 adults (age 20-57) were recruited to use the smartphone app Mobile Sensing and Support (MOSS), collecting context-sensitive sensor information and providing just-in-time interventions derived from cognitive behavior therapy. Real-time learning-systems were deployed to adapt to each subject's preferences to optimize recommendations with respect to time, location, and personal preference. Biweekly, participants were asked to complete a self-reported depression survey (PHQ-9) to track symptom progression. Wilcoxon tests were conducted to compare scores before and after intervention. Correlation analysis was used to test the relationship between adherence and change in PHQ-9. One hundred twenty features were constructed based on smartphone usage and sensors including accelerometer, Wifi, and global positioning systems (GPS). Machine-learning models used these features to infer behavior and context for PHQ-9 level prediction and tailored intervention delivery. Results: A total of 36 subjects used MOSS for ≥2 weeks. For subjects with clinical depression (PHQ-9≥11) at baseline and adherence ≥8 weeks (n=12), a significant drop in PHQ-9 was observed (P=.01). This group showed a negative trend between adherence and change in PHQ-9 scores (rho=−.498, P=.099). Binary classification performance for biweekly PHQ-9 samples (n=143), with a cutoff of PHQ-9≥11, based on Random Forest and Support Vector Machine leave-one-out cross validation resulted in 60.1\% and 59.1\% accuracy, respectively. Conclusions: Proxies for social and physical behavior derived from smartphone sensor data was successfully deployed to deliver context-sensitive and personalized interventions to people with depressive symptoms. Subjects who used the app for an extended period of time showed significant reduction in self-reported symptom severity. Nonlinear classification models trained on features extracted from smartphone sensor data including Wifi, accelerometer, GPS, and phone use, demonstrated a proof of concept for the detection of depression superior to random classification. While findings of effectiveness must be reproduced in a RCT to proof causation, they pave the way for a new generation of digital health interventions leveraging smartphone sensors to provide context sensitive information for in-situ support and unobtrusive monitoring of critical mental health states.},
	number = {3},
	journal = {JMIR mHealth and uHealth},
	author = {Wahle, Fabian and Kowatsch, Tobias and Fleisch, Elgar and Rufer, Michael and Weidt, Steffi},
	year = {2016},
	pmid = {27655245},
	note = {ISBN: doi:10.2196/mhealth.5960},
	pages = {e111},
	file = {Wahle et al_2016_Mobile Sensing and Support for People With Depression.pdf:/Users/orsonxu/Zotero/storage/ZXQUUMEB/Wahle et al_2016_Mobile Sensing and Support for People With Depression.pdf:application/pdf;Wahle et al_2016_Mobile Sensing and Support for People With Depression.pdf:/Users/orsonxu/Zotero/storage/JEIZ2QYS/Wahle et al_2016_Mobile Sensing and Support for People With Depression.pdf:application/pdf},
}

@article{nahum-shani_translating_2021,
	title = {Translating {Strategies} for {Promoting} {Engagement} in {Mobile} {Health}: {A} {Proof}-of-{Concept} {Micro}-{Randomized} {Trial}},
	volume = {40},
	issn = {0278-6133},
	shorttitle = {Translating {Strategies} for {Promoting} {Engagement} in {Mobile} {Health}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8738098/},
	doi = {10.1037/hea0001101},
	abstract = {Objective:
Mobile technologies allow for accessible and cost-effective health monitoring and intervention delivery. Despite these advantages, mobile health (mHealth) engagement is often insufficient. While monetary incentives may increase engagement, they can backfire, dampening intrinsic motivations and undermining intervention scalability. Theories from psychology and behavioral economics suggest useful non-monetary strategies for promoting engagement; however, examinations of the applicability of these strategies to mHealth engagement are lacking. This proof-of-concept study evaluates the translation of theoretically-grounded engagement strategies into mHealth, by testing their potential utility in promoting daily self-reporting.

Methods:
A micro-randomized trial (MRT) was conducted with adolescents and emerging adults with past-month substance use. Participants were randomized multiple times daily to receive theoretically-grounded strategies, namely reciprocity (the delivery of inspirational quote prior to self-reporting window) and non-monetary reinforcers (e.g., the delivery of meme/gif following self-reporting completion) to improve proximal engagement in daily mHealth self-reporting.

Results:
Daily self-reporting rates (62.3\%; n=68) were slightly lower than prior literature, albeit with much lower financial incentives. The utility of specific strategies was found to depend on contextual factors pertaining to the individual’s receptivity and risk for disengagement. For example, the effect of reciprocity significantly varied depending on whether this strategy was employed (vs. not employed) during the weekend. The non-monetary reinforcement strategy resulted in different outcomes when operationalized in various ways.

Conclusions:
While the results support the translation of the reciprocity strategy into this mHealth setting, the translation of non-monetary reinforcement requires further consideration prior to inclusion in a full scale MRT.},
	number = {12},
	urldate = {2022-02-03},
	journal = {Health psychology : official journal of the Division of Health Psychology, American Psychological Association},
	author = {Nahum-Shani, Inbal and Rabbi, Mashfiqui and Yap, Jamie and Philyaw-Kotov, Meredith L. and Klasnja, Predrag and Bonar, Erin E. and Cunningham, Rebecca M. and Murphy, Susan A. and Walton, Maureen A.},
	month = dec,
	year = {2021},
	pmid = {34735165},
	pmcid = {PMC8738098},
	pages = {974--987},
	file = {Nahum-Shani et al_2021_Translating Strategies for Promoting Engagement in Mobile Health.pdf:/Users/orsonxu/Zotero/storage/TVHXN2JK/Nahum-Shani et al_2021_Translating Strategies for Promoting Engagement in Mobile Health.pdf:application/pdf;Nahum-Shani et al_2021_Translating Strategies for Promoting Engagement in Mobile Health.pdf:/Users/orsonxu/Zotero/storage/2WAU6IUU/Nahum-Shani et al_2021_Translating Strategies for Promoting Engagement in Mobile Health.pdf:application/pdf},
}

@article{Adams2015,
	title = {Mindless computing: {Designing} technologies to subtly influence behavior},
	doi = {10.1145/2750858.2805843},
	abstract = {Persuasive technologies aim to influence user's behaviors. In order to be effective, many of the persuasive technologies developed so far relies on user's motivation and ability, which is highly variable and often the reason behind the failure of such technology. In this paper, we present the concept of Mindless Computing, which is a new approach to persuasive technology design. Mindless Computing leverages theories and concepts from psychology and behavioral economics into the design of technologies for behavior change. We show through a systematic review that most of the current persuasive technologies do not utilize the fast and automatic mental processes for behavioral change and there is an opportunity for persuasive technology designers to develop systems that are less reliant on user's motivation and ability. We describe two examples of mindless technologies and present pilot studies with encouraging results. Finally, we discuss design guidelines and considerations for developing this type of persuasive technology.},
	journal = {Proceedings of the ACM International Joint Conference on Pervasive and Ubiquitous Computing},
	author = {Adams, Alexander T. and Costa, Jean and Jung, Malte F. and Choudhury, Tanzeem},
	year = {2015},
	note = {ISBN: 9781450335744},
	keywords = {Unread, Behavior Change, Mindless, Nudging, Persuasive Technology, Subconscious, Subliminal, System 1, System 2},
	pages = {719--730},
	file = {Adams et al_2015_Mindless computing.pdf:/Users/orsonxu/Zotero/storage/YS666YL7/Adams et al_2015_Mindless computing.pdf:application/pdf;Adams et al_2015_Mindless computing.pdf:/Users/orsonxu/Zotero/storage/LAK83IYK/Adams et al_2015_Mindless computing.pdf:application/pdf},
}

@article{costa_boostmeup_2019,
	title = {{BoostMeUp}: {Improving} {Cognitive} {Performance} in the {Moment} by {Unobtrusively} {Regulating} {Emotions} with a {Smartwatch}},
	volume = {3},
	issn = {2474-9567},
	shorttitle = {{BoostMeUp}},
	url = {https://dl.acm.org/doi/10.1145/3328911},
	doi = {10.1145/3328911},
	abstract = {A person's emotional state can strongly influence their ability to achieve optimal task performance. Aiming to help individuals manage their feelings, different emotion regulation technologies have been proposed. However, despite the well-known influence that emotions have on task performance, no study to date has shown if an emotion regulation technology can also enhance user's cognitive performance in the moment. In this paper, we present BoostMeUp, a smartwatch intervention designed to improve user's cognitive performance by regulating their emotions unobtrusively. Based on studies that show that people tend to associate external signals that resemble heart rates as their own, the intervention provides personalized haptic feedback simulating a different heart rate. Users can focus on their tasks and the intervention acts upon them in parallel, without requiring any additional action. The intervention was evaluated in an experiment with 72 participants, in which they had to do math tests under high pressure. Participants who were exposed to slow haptic feedback during the tests decreased their anxiety, increased their heart rate variability and performed better in the math tests, while fast haptic feedback led to the opposite effects. These results indicate that the BoostMeUp intervention can lead to positive cognitive, physiological and behavioral changes.},
	language = {en},
	number = {2},
	urldate = {2021-11-22},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Costa, Jean and Guimbretière, François and Jung, Malte F. and Choudhury, Tanzeem},
	month = jun,
	year = {2019},
	pages = {1--23},
	file = {Costa et al. - 2019 - BoostMeUp Improving Cognitive Performance in the .pdf:/Users/orsonxu/Zotero/storage/5EBJEEHY/Costa et al. - 2019 - BoostMeUp Improving Cognitive Performance in the .pdf:application/pdf},
}

@inproceedings{rooksby_student_2019,
	address = {Glasgow Scotland Uk},
	title = {Student {Perspectives} on {Digital} {Phenotyping}: {The} {Acceptability} of {Using} {Smartphone} {Data} to {Assess} {Mental} {Health}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {Student {Perspectives} on {Digital} {Phenotyping}},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300655},
	doi = {10.1145/3290605.3300655},
	abstract = {There is a mental health crisis facing universities internationally. A growing body of interdisciplinary research has successfully demonstrated that using sensor and interaction data from students’ smartphones can give insight into stress, depression, mood, suicide risk and more. The approach, which is sometimes termed Digital Phenotyping, has potential to transform how mental health and wellbeing can be monitored and understood. The approach could also transform how interventions are designed, delivered and evaluated. To date, little work has addressed the human and ethical side of digital phenotyping, including how students feel about being monitored. In this paper we report findings from in-depth focus groups, prototyping and interviews with students. We find they are positive about mental health technology, but also that there are multi-layered issues to address if digital phenotyping is to become acceptable. Using an acceptability framework, we set out the key design challenges that need to be addressed.},
	language = {en},
	urldate = {2021-11-10},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Rooksby, John and Morrison, Alistair and Murray-Rust, Dave},
	month = may,
	year = {2019},
	pages = {1--14},
	file = {Rooksby et al. - 2019 - Student Perspectives on Digital Phenotyping The A.pdf:/Users/orsonxu/Zotero/storage/MBRUN25T/Rooksby et al. - 2019 - Student Perspectives on Digital Phenotyping The A.pdf:application/pdf},
}

@article{choi_multi-stage_2019-1,
	title = {Multi-{Stage} {Receptivity} {Model} for {Mobile} {Just}-{In}-{Time} {Health} {Intervention}},
	volume = {3},
	issn = {2474-9567},
	url = {https://dl.acm.org/doi/10.1145/3328910},
	doi = {10.1145/3328910},
	abstract = {A critical aspect of mobile just-in-time (JIT) health intervention is proper delivery timing, which correlates with successfully promoting target behaviors. Despite extensive prior studies on interruptibility, however, our understanding of the receptivity of mobile JIT health intervention is limited. This work extends prior interruptibility models to capture the JIT intervention process by including multiple stages of conscious and subconscious decisions. We built BeActive, a mobile intervention system for preventing prolonged sedentary behaviors, and we collected users' responses to a given JIT support and relevant contextual factors and cognitive/physical states for three weeks. Using a multi-stage model, we systematically analyzed the responses to deepen our understanding of receptivity using a mixed methodology. Herein, we identify the key factors relevant to each stage outcome and show that the receptivity of JIT intervention is nuanced and context-dependent. We propose several practical design implications for mobile JIT health intervention and context-aware computing.},
	language = {en},
	number = {2},
	urldate = {2021-11-10},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Choi, Woohyeok and Park, Sangkeun and Kim, Duyeon and Lim, Youn-kyung and Lee, Uichin},
	month = jun,
	year = {2019},
	pages = {1--26},
	file = {Choi et al. - 2019 - Multi-Stage Receptivity Model for Mobile Just-In-T.pdf:/Users/orsonxu/Zotero/storage/L3XU5MGE/Choi et al. - 2019 - Multi-Stage Receptivity Model for Mobile Just-In-T.pdf:application/pdf},
}

@article{everitt_exploring_2021,
	title = {Exploring the features of an app-based just-in-time intervention for depression},
	volume = {291},
	issn = {01650327},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165032721004651},
	doi = {10.1016/j.jad.2021.05.021},
	abstract = {Background: Technological advancements make it possible to deliver depression interventions via smartphone applications (“Apps”), including those that deliver content “just-in-time” (e.g., in response to acute negative mood states). This study examined whether an app-based just-in-time intervention (ImproveYourMood+) decreased depressive symptoms, and whether the following features were related to symptom improvement: micro-intervention content, mood monitoring, and just-in-time prompts to use content.
Methods: Participants (n = 235) from the general population who self-identified as wanting to improve their negative mood were randomised to a waitlist control group (n = 55) or one of three intervention groups: MoodTracker (monitoring-only, n = 58), ImproveYourMood (monitoring and content; n = 62), or ImproveYourMood+ (monitoring, content, and prompts; n = 60). The active intervention phase was 3 weeks. Depressive and anxiety symptoms, and negative automatic thoughts were assessed at baseline, immediately postintervention, and one month following post-intervention.
Results: Linear mixed modelling revealed greater declines over time in depressive and anxiety symptoms and negative automatic thoughts for the ImproveYourMood group (standardized mean differences [SMDs] ranged from .32 to .40) and improves for the ImproveYourMood+ group for negative automatic thoughts (SMDs ≥ .37) compared to the waitlist control group. No between-group differences were observed between the MoodTracker and control groups (SMDs = .04–.23). User experience appeared to be superior in more comprehensive/multimodal versions. Limitations: The study employed a naturalistic design, whereby participants self-selected to utilise the program, did not complete eligibility assessments, and did not receive compensation. The study therefore attained considerable drop-out rate ({\textasciitilde}50\% by the follow-up timepoints), potentially reflecting the usage patterns of realworld mental health apps.
Conclusions: The findings suggest that micro-interventions can be an effective way to reduce depressive symp­ toms both in the moment and 1–2 months later. Integration of micro-interventions with full treatment programs is a viable next step in micro-intervention research.},
	language = {en},
	urldate = {2021-11-09},
	journal = {Journal of Affective Disorders},
	author = {Everitt, Nicole and Broadbent, Jaclyn and Richardson, Ben and Smyth, Joshua M. and Heron, Kristin and Teague, Samantha and Fuller-Tyszkiewicz, Matthew},
	month = aug,
	year = {2021},
	pages = {279--287},
	file = {Everitt et al. - 2021 - Exploring the features of an app-based just-in-tim.pdf:/Users/orsonxu/Zotero/storage/SHPH74CP/Everitt et al. - 2021 - Exploring the features of an app-based just-in-tim.pdf:application/pdf},
}

@article{liao_personalized_2020,
	title = {Personalized {HeartSteps}: {A} {Reinforcement} {Learning} {Algorithm} for {Optimizing} {Physical} {Activity}},
	volume = {4},
	issn = {2474-9567},
	shorttitle = {Personalized {HeartSteps}},
	url = {https://dl.acm.org/doi/10.1145/3381007},
	doi = {10.1145/3381007},
	abstract = {With the recent proliferation of mobile health technologies, health scientists are increasingly interested in developing justin-time adaptive interventions (JITAIs), typically delivered via notifications on mobile devices and designed to help users prevent negative health outcomes and to promote the adoption and maintenance of healthy behaviors. A JITAI involves a sequence of decision rules (i.e., treatment policies) that take the user’s current context as input and specify whether and what type of intervention should be provided at the moment. In this work, we describe a reinforcement learning (RL) algorithm that continuously learns and improves the treatment policy embedded in the JITAI as data is being collected from the user. This work is motivated by our collaboration on designing an RL algorithm for HeartSteps V2 based on data collected HeartSteps V1. HeartSteps is a physical activity mobile health application. The RL algorithm developed in this work is being used in HeartSteps V2 to decide, five times per day, whether to deliver a context-tailored activity suggestion. CCS Concepts: • Computing methodologies → Machine learning algorithms; • Applied computing → Health care information systems.},
	language = {en},
	number = {1},
	urldate = {2021-11-09},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Liao, Peng and Greenewald, Kristjan and Klasnja, Predrag and Murphy, Susan},
	month = mar,
	year = {2020},
	keywords = {Star},
	pages = {1--22},
	file = {Liao et al. - 2020 - Personalized HeartSteps A Reinforcement Learning .pdf:/Users/orsonxu/Zotero/storage/8474EH2Z/Liao et al. - 2020 - Personalized HeartSteps A Reinforcement Learning .pdf:application/pdf},
}

@article{cho_reflect_2021,
	title = {Reflect, not {Regret}: {Understanding} {Regretful} {Smartphone} {Use} with {App} {Feature}-{Level} {Analysis}},
	volume = {5},
	issn = {2573-0142},
	shorttitle = {Reflect, not {Regret}},
	url = {https://dl.acm.org/doi/10.1145/3479600},
	doi = {10.1145/3479600},
	language = {en},
	number = {CSCW2},
	urldate = {2021-11-09},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Cho, Hyunsung and Choi, DaEun and Kim, Donghwi and Kang, Wan Ju and Choe, Eun Kyoung and Lee, Sung-Ju},
	month = oct,
	year = {2021},
	pages = {1--36},
	file = {Cho et al. - 2021 - Reflect, not Regret Understanding Regretful Smart.pdf:/Users/orsonxu/Zotero/storage/VUYIZXC3/Cho et al. - 2021 - Reflect, not Regret Understanding Regretful Smart.pdf:application/pdf},
}

@article{battalio_sense2stop_2021,
	title = {{Sense2Stop}: {A} micro-randomized trial using wearable sensors to optimize a just-in-time-adaptive stress management intervention for smoking relapse prevention},
	volume = {109},
	issn = {15517144},
	shorttitle = {{Sense2Stop}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1551714421002706},
	doi = {10.1016/j.cct.2021.106534},
	abstract = {Background: Relapse to smoking is commonly triggered by stress, but behavioral interventions have shown only modest efficacy in preventing stress-related relapse. Continuous digital sensing to detect states of smoking risk and intervention receptivity may make it feasible to increase treatment efficacy by adapting intervention timing. Objective: Aims are to investigate whether the delivery of a prompt to perform stress management behavior, as compared to no prompt, reduces the likelihood of (a) being stressed and (b) smoking in the subsequent two hours, and (c) whether current stress moderates these effects.},
	language = {en},
	urldate = {2021-11-08},
	journal = {Contemporary Clinical Trials},
	author = {Battalio, Samuel L. and Conroy, David E. and Dempsey, Walter and Liao, Peng and Menictas, Marianne and Murphy, Susan and Nahum-Shani, Inbal and Qian, Tianchen and Kumar, Santosh and Spring, Bonnie},
	month = oct,
	year = {2021},
	pages = {106534},
	file = {Battalio et al. - 2021 - Sense2Stop A micro-randomized trial using wearabl.pdf:/Users/orsonxu/Zotero/storage/9F5UQFNZ/Battalio et al. - 2021 - Sense2Stop A micro-randomized trial using wearabl.pdf:application/pdf},
}

@article{klasnja_micro-randomized_2015,
	title = {Micro-{Randomized} {Trials}: {An} {Experimental} {Design} for {Developing} {Just}-in-{Time} {Adaptive} {Interventions}},
	volume = {34},
	issn = {0278-6133},
	shorttitle = {Micro-{Randomized} {Trials}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4732571/},
	doi = {10.1037/hea0000305},
	abstract = {Objective
This paper presents an experimental design, the micro-randomized trial, developed to support optimization of just-in-time adaptive interventions (JITAIs). JITAIs are mHealth technologies that aim to deliver the right intervention components at the right times and locations to optimally support individuals’ health behaviors. Micro-randomized trials offer a way to optimize such interventions by enabling modeling of causal effects and time-varying effect moderation for individual intervention components within a JITAI.

Methods
The paper describes the micro-randomized trial design, enumerates research questions that this experimental design can help answer, and provides an overview of the data analyses that can be used to assess the causal effects of studied intervention components and investigate time-varying moderation of those effects.

Results
Micro-randomized trials enable causal modeling of proximal effects of the randomized intervention components and assessment of time-varying moderation of those effects.

Conclusions
Micro-randomized trials can help researchers understand whether their interventions are having intended effects, when and for whom they are effective, and what factors moderate the interventions’ effects, enabling creation of more effective JITAIs.},
	number = {0},
	urldate = {2021-11-08},
	journal = {Health psychology : official journal of the Division of Health Psychology, American Psychological Association},
	author = {Klasnja, Predrag and Hekler, Eric B. and Shiffman, Saul and Boruvka, Audrey and Almirall, Daniel and Tewari, Ambuj and Murphy, Susan A.},
	month = dec,
	year = {2015},
	pmid = {26651463},
	pmcid = {PMC4732571},
	pages = {1220--1228},
	file = {PubMed Central Full Text PDF:/Users/orsonxu/Zotero/storage/D4L7I8UM/Klasnja et al. - 2015 - Micro-Randomized Trials An Experimental Design fo.pdf:application/pdf},
}

@article{nahum-shani_just--time_2018,
	title = {Just-in-{Time} {Adaptive} {Interventions} ({JITAIs}) in {Mobile} {Health}: {Key} {Components} and {Design} {Principles} for {Ongoing} {Health} {Behavior} {Support}},
	volume = {52},
	issn = {0883-6612, 1532-4796},
	shorttitle = {Just-in-{Time} {Adaptive} {Interventions} ({JITAIs}) in {Mobile} {Health}},
	url = {https://academic.oup.com/abm/article/52/6/446/4733473},
	doi = {10.1007/s12160-016-9830-8},
	abstract = {Background The just-in-time adaptive intervention (JITAI) is an intervention design aiming to provide the right type/amount of support, at the right time, by adapting to an individual’s changing internal and contextual state. The availability of increasingly powerful mobile and sensing technologies underpins the use of JITAIs to support health behavior, as in such a setting an individual’s state can change rapidly, unexpectedly, and in his/her natural environment.},
	language = {en},
	number = {6},
	urldate = {2021-11-08},
	journal = {Annals of Behavioral Medicine},
	author = {Nahum-Shani, Inbal and Smith, Shawna N and Spring, Bonnie J and Collins, Linda M and Witkiewitz, Katie and Tewari, Ambuj and Murphy, Susan A},
	month = may,
	year = {2018},
	pages = {446--462},
	file = {Nahum-Shani et al. - 2018 - Just-in-Time Adaptive Interventions (JITAIs) in Mo.pdf:/Users/orsonxu/Zotero/storage/C7LXCJHJ/Nahum-Shani et al. - 2018 - Just-in-Time Adaptive Interventions (JITAIs) in Mo.pdf:application/pdf},
}

@article{goldstein_return_2017,
	title = {Return of the {JITAI}: {Applying} a {Just}-in-{Time} {Adaptive} {Intervention} {Framework} to the {Development} of m-{Health} {Solutions} for {Addictive} {Behaviors}},
	volume = {24},
	issn = {1070-5503, 1532-7558},
	shorttitle = {Return of the {JITAI}},
	url = {http://link.springer.com/10.1007/s12529-016-9627-y},
	doi = {10.1007/s12529-016-9627-y},
	abstract = {Purpose Lapses are strong indicators of later relapse among individuals with addictive disorders, and thus are an important intervention target. However, lapse behavior has proven resistant to change due to the complex interplay of lapse triggers that are present in everyday life. It could be possible to prevent lapses before they occur by using m-Health solutions to deliver interventions in real-time.
Method Just-in-time adaptive intervention (JITAI) is an intervention design framework that could be delivered via mobile app to facilitate in-the-moment monitoring of triggers for lapsing, and deliver personalized coping strategies to the user to prevent lapses from occurring. An organized framework is key for successful development of a JITAI.
Results Nahum-Shani and colleagues (2014) set forth six core elements of a JITAI and guidelines for designing each: distal outcomes, proximal outcomes, tailoring variables, decision points, decision rules, and intervention options. The primary aim of this paper is to illustrate the use of this framework as it pertains to developing a JITAI that targets lapse behavior among individuals following a weight control diet.
Conclusion We will detail our approach to various decision points during the development phases, report on preliminary findings where applicable, identify problems that arose during development, and provide recommendations for researchers who are currently undertaking their own JITAI development},
	language = {en},
	number = {5},
	urldate = {2021-11-08},
	journal = {International Journal of Behavioral Medicine},
	author = {Goldstein, Stephanie P. and Evans, Brittney C. and Flack, Daniel and Juarascio, Adrienne and Manasse, Stephanie and Zhang, Fengqing and Forman, Evan M.},
	month = oct,
	year = {2017},
	pages = {673--682},
	file = {Goldstein et al. - 2017 - Return of the JITAI Applying a Just-in-Time Adapt.pdf:/Users/orsonxu/Zotero/storage/A3XSXAVY/Goldstein et al. - 2017 - Return of the JITAI Applying a Just-in-Time Adapt.pdf:application/pdf},
}

@article{mishra_detecting_2021,
	title = {Detecting {Receptivity} for {mHealth} {Interventions} in the {Natural} {Environment}},
	volume = {5},
	issn = {2474-9567},
	url = {https://dl.acm.org/doi/10.1145/3463492},
	doi = {10.1145/3463492},
	abstract = {Just-In-Time Adaptive Intervention (JITAI) is an emerging technique with great potential to support health behavior by providing the right type and amount of support at the right time. A crucial aspect of JITAIs is properly timing the delivery of interventions, to ensure that a user is receptive and ready to process and use the support provided. Some prior works have explored the association of context and some user-specific traits on receptivity, and have built post-study machine-learning models to detect receptivity. For effective intervention delivery, however, a JITAI system needs to make in-the-moment decisions about a user's receptivity. To this end, we conducted a study in which we deployed machine-learning models to detect receptivity in the natural environment, i.e., in free-living conditions.
            We leveraged prior work regarding receptivity to JITAIs and deployed a chatbot-based digital coach - Ally - that provided physical-activity interventions and motivated participants to achieve their step goals. We extended the original Ally app to include two types of machine-learning model that used contextual information about a person to predict when a person is receptive: a static model that was built before the study started and remained constant for all participants and an adaptive model that continuously learned the receptivity of individual participants and updated itself as the study progressed. For comparison, we included a control model that sent intervention messages at random times. The app randomly selected a delivery model for each intervention message. We observed that the machine-learning models led up to a 40\% improvement in receptivity as compared to the control model. Further, we evaluated the temporal dynamics of the different models and observed that receptivity to messages from the adaptive model increased over the course of the study.},
	language = {en},
	number = {2},
	urldate = {2022-06-19},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Mishra, Varun and Künzler, Florian and Kramer, Jan-Niklas and Fleisch, Elgar and Kowatsch, Tobias and Kotz, David},
	month = jun,
	year = {2021},
	pages = {1--24},
	file = {Mishra et al. - 2021 - Detecting Receptivity for mHealth Interventions in.pdf:/Users/orsonxu/Zotero/storage/25B98QYD/Mishra et al. - 2021 - Detecting Receptivity for mHealth Interventions in.pdf:application/pdf},
}

@article{direito_mhealth_2017,
	title = {{mHealth} {Technologies} to {Influence} {Physical} {Activity} and {Sedentary} {Behaviors}: {Behavior} {Change} {Techniques}, {Systematic} {Review} and {Meta}-{Analysis} of {Randomized} {Controlled} {Trials}},
	volume = {51},
	issn = {0883-6612, 1532-4796},
	shorttitle = {{mHealth} {Technologies} to {Influence} {Physical} {Activity} and {Sedentary} {Behaviors}},
	url = {https://academic.oup.com/abm/article/51/2/226-239/4564158},
	doi = {10.1007/s12160-016-9846-0},
	abstract = {Methods A systematic review and meta-analysis following PRISMA guidelines was undertaken to identify randomized controlled trials (RCTs) comparing mHealth interventions with usual or minimal care among individuals free from conditions that could limit PA. Total PA, moderate-to-vigorous intensity physical activity (MVPA), walking and SB outcomes were extracted. Intervention content was independently coded following the 93-item taxonomy of BCTs.
Results Twenty-one RCTs (1701 participants—700 with objectively measured PA) met eligibility criteria. SB decreased more following mHealth interventions than after usual care (standardised mean difference (SMD) −0.26, 95 \% confidence interval (CI) −0.53 to −0.00). Summary effects across studies were small to moderate and non-significant for total PA (SMD 0.14, 95 \% CI −0.12 to 0.41); MVPA (SMD 0.37, 95 \% CI −0.03 to 0.77); and walking (SMD 0.14, 95 \% CI −0.01 to 0.29). BCTs were employed more frequently in intervention (mean = 6.9, range 2 to 12) than in comparator conditions (mean = 3.1, range 0 to 10). Of all BCTs, only 31 were employed in intervention conditions.
Conclusions Current mHealth interventions have small effects on PA/SB. Technological advancements will enable more comprehensive, interactive and responsive intervention delivery. Future mHealth PA studies should ensure that all the active ingredients of the intervention are reported in sufficient detail.},
	language = {en},
	number = {2},
	urldate = {2022-06-19},
	journal = {Annals of Behavioral Medicine},
	author = {Direito, Artur and Carraça, Eliana and Rawstorn, Jonathan and Whittaker, Robyn and Maddison, Ralph},
	month = apr,
	year = {2017},
	pages = {226--239},
	file = {Direito et al. - 2017 - mHealth Technologies to Influence Physical Activit.pdf:/Users/orsonxu/Zotero/storage/PW7CES2U/Direito et al. - 2017 - mHealth Technologies to Influence Physical Activit.pdf:application/pdf},
}

@article{aldenaini_trends_2020,
	title = {Trends in {Persuasive} {Technologies} for {Physical} {Activity} and {Sedentary} {Behavior}: {A} {Systematic} {Review}},
	volume = {3},
	issn = {2624-8212},
	shorttitle = {Trends in {Persuasive} {Technologies} for {Physical} {Activity} and {Sedentary} {Behavior}},
	url = {https://www.frontiersin.org/article/10.3389/frai.2020.00007/full},
	doi = {10.3389/frai.2020.00007},
	abstract = {Persuasive technology (PT) is increasingly being used in the health and wellness domain to motivate and assist users with different lifestyles and behavioral health issues to change their attitudes and/or behaviors. There is growing evidence that PT can be effective at promoting behaviors in many health and wellness domains, including promoting physical activity (PA), healthy eating, and reducing sedentary behavior (SB). SB has been shown to pose a risk to overall health. Thus, reducing SB and increasing PA have been the focus of much PT work. This paper aims to provide a systematic review of PTs for promoting PA and reducing SB. Speciﬁcally, we answer some fundamental questions regarding its design and effectiveness based on an empirical review of the literature on PTs for promoting PA and discouraging SB, from 2003 to 2019 (170 papers). There are three main objectives: (1) to evaluate the effectiveness of PT in promoting PA and reducing SB; (2) to summarize and highlight trends in the outcomes such as system design, research methods, persuasive strategies employed and their implementaions, behavioral theories, and employed technological platforms; (3) to reveal the pitfalls and gaps in the present literature that can be leveraged and used to inform future research on designing PT for PA and SB.},
	language = {en},
	urldate = {2022-06-19},
	journal = {Frontiers in Artificial Intelligence},
	author = {Aldenaini, Noora and Alqahtani, Felwah and Orji, Rita and Sampalli, Srinivas},
	month = apr,
	year = {2020},
	pages = {7},
	file = {Aldenaini et al. - 2020 - Trends in Persuasive Technologies for Physical Act.pdf:/Users/orsonxu/Zotero/storage/KIUGT3JN/Aldenaini et al. - 2020 - Trends in Persuasive Technologies for Physical Act.pdf:application/pdf},
}


@inproceedings{Amershi2019,
	address = {New York, New York, USA},
	title = {Guidelines for {Human}-{AI} {Interaction}},
	isbn = {978-1-4503-5970-2},
	url = {http://dl.acm.org/citation.cfm?doid=3290605.3300233},
	doi = {10.1145/3290605.3300233},
	abstract = {Advances in artifcial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of guidelines for human-AI interaction design.},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '19},
	publisher = {ACM Press},
	author = {Amershi, Saleema and Inkpen, Kori and Teevan, Jaime and Kikin-Gil, Ruth and Horvitz, Eric and Weld, Dan and Vorvoreanu, Mihaela and Fourney, Adam and Nushi, Besmira and Collisson, Penny and Suh, Jina and Iqbal, Shamsi and Bennett, Paul N.},
	year = {2019},
	keywords = {AI-infused systems, Design guidelines, Human-AI interaction},
	pages = {1--13},
	annote = {Point out the problem that AI interface is flushing out the traditional HCI design,

A survey paper about the AI-related design recommendation.

A design paper that propose 18 guidelines for human-AI interaction.},
	file = {Amershi et al. - 2019 - Guidelines for Human-AI Interaction.pdf:/Users/orsonxu/Zotero/storage/U3V4Q3BR/Amershi et al. - 2019 - Guidelines for Human-AI Interaction.pdf:application/pdf},
}

@article{Dellermann2019,
	title = {The {Future} of {Human}-{AI} {Collaboration}: {A} {Taxonomy} of {Design} {Knowledge} for {Hybrid} {Intelligence} {Systems}},
	volume = {6},
	doi = {10.24251/hicss.2019.034},
	abstract = {Recent technological advances, especially in the field of machine learning, provide astonishing progress on the road towards artificial general intelligence. However, tasks in current real-world business applications cannot yet be solved by machines alone. We, therefore, identify the need for developing socio-technological ensembles of humans and machines. Such systems possess the ability to accomplish complex goals by combining human and artificial intelligence to collectively achieve superior results and continuously improve by learning from each other. Thus, the need for structured design knowledge for those systems arises. Following a taxonomy development method, this article provides three main contributions: First, we present a structured overview of interdisciplinary research on the role of humans in the machine learning pipeline. Second, we envision hybrid intelligence systems and conceptualize the relevant dimensions for system design for the first time. Finally, we offer useful guidance for system developers during the implementation of such applications.},
	journal = {Proceedings of the 52nd Hawaii International Conference on System Sciences},
	author = {Dellermann, Dominik and Calma, Adrian and Lipusch, Nikolaus and Weber, Thorsten and Weigel, Sascha and Ebel, Philipp},
	year = {2019},
	note = {ISBN: 9780998133126},
	pages = {274--283},
	file = {Dellermann et al_2019_The Future of Human-AI Collaboration.pdf:/Users/orsonxu/Zotero/storage/A3AFVWX2/Dellermann et al_2019_The Future of Human-AI Collaboration.pdf:application/pdf;Dellermann et al_2019_The Future of Human-AI Collaboration.pdf:/Users/orsonxu/Zotero/storage/I7HF4TNN/Dellermann et al_2019_The Future of Human-AI Collaboration.pdf:application/pdf},
}

@inproceedings{inkpen_where_2019,
	address = {Glasgow Scotland Uk},
	title = {Where is the {Human}?: {Bridging} the {Gap} {Between} {AI} and {HCI}},
	isbn = {978-1-4503-5971-9},
	shorttitle = {Where is the {Human}?},
	url = {https://dl.acm.org/doi/10.1145/3290607.3299002},
	doi = {10.1145/3290607.3299002},
	abstract = {In recent years, AI systems have become both more powerful and increasingly promising for integration in a variety of application areas. Attention has also been called to the social challenges these systems bring, particularly in how they might fail or even actively disadvantage marginalised social groups, or how their opacity might make them difficult to oversee and challenge. In the context of these and other challenges, the roles of humans working in tandem with these systems will be important, yet the HCI community has been only a quiet voice in these debates to date. This workshop aims to catalyse and crystallise an agenda around HCI’s engagement with AI systems. Topics of interest include explainable and explorable AI; documentation and review; integrating artificial and human intelligence; collaborative decision making; AI/ML in HCI Design; diverse human roles and relationships in AI systems; and critical views of AI.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Extended {Abstracts} of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Inkpen, Kori and Chancellor, Stevie and De Choudhury, Munmun and Veale, Michael and Baumer, Eric P. S.},
	month = may,
	year = {2019},
	pages = {1--9},
	file = {Inkpen et al. - 2019 - Where is the Human Bridging the Gap Between AI a.pdf:/Users/orsonxu/Zotero/storage/PDJA9H2F/Inkpen et al. - 2019 - Where is the Human Bridging the Gap Between AI a.pdf:application/pdf},
}

@inproceedings{abdul_trends_2018,
	address = {Montreal QC Canada},
	title = {Trends and {Trajectories} for {Explainable}, {Accountable} and {Intelligible} {Systems}: {An} {HCI} {Research} {Agenda}},
	isbn = {978-1-4503-5620-6},
	shorttitle = {Trends and {Trajectories} for {Explainable}, {Accountable} and {Intelligible} {Systems}},
	url = {https://dl.acm.org/doi/10.1145/3173574.3174156},
	doi = {10.1145/3173574.3174156},
	abstract = {Advances in artificial intelligence, sensors and big data management have far-reaching societal impacts. As these systems augment our everyday lives, it becomes increasingly important for people to understand them and remain in control. We investigate how HCI researchers can help to develop accountable systems by performing a literature analysis of 289 core papers on explanations and explainable systems, as well as 12,412 citing papers. Using topic modeling, co-occurrence and network analysis, we mapped the research space from diverse domains, such as algorithmic accountability, interpretable machine learning, context-awareness, cognitive psychology, and software learnability. We reveal fading and burgeoning trends in explainable systems, and identify domains that are closely connected or mostly isolated. The time is ripe for the HCI community to ensure that the powerful new autonomous systems have intelligible interfaces built-in. From our results, we propose several implications and directions for future research towards this goal.},
	language = {en},
	urldate = {2022-07-11},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Abdul, Ashraf and Vermeulen, Jo and Wang, Danding and Lim, Brian Y. and Kankanhalli, Mohan},
	month = apr,
	year = {2018},
	pages = {1--18},
	file = {Abdul et al. - 2018 - Trends and Trajectories for Explainable, Accountab.pdf:/Users/orsonxu/Zotero/storage/EEB3L5XE/Abdul et al. - 2018 - Trends and Trajectories for Explainable, Accountab.pdf:application/pdf},
}

@inproceedings{wang_designing_2019,
	address = {Glasgow Scotland Uk},
	title = {Designing {Theory}-{Driven} {User}-{Centric} {Explainable} {AI}},
	isbn = {978-1-4503-5970-2},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300831},
	doi = {10.1145/3290605.3300831},
	abstract = {From healthcare to criminal justice, artificial intelligence (AI) is increasingly supporting high-consequence human decisions. This has spurred the field of explainable AI (XAI). This paper seeks to strengthen empirical applicationspecific investigations of XAI by exploring theoretical underpinnings of human decision making, drawing from the fields of philosophy and psychology. In this paper, we propose a conceptual framework for building humancentered, decision-theory-driven XAI based on an extensive review across these fields. Drawing on this framework, we identify pathways along which human cognitive patterns drives needs for building XAI and how XAI can mitigate common cognitive biases. We then put this framework into practice by designing and implementing an explainable clinical diagnostic tool for intensive care phenotyping and conducting a co-design exercise with clinicians. Thereafter, we draw insights into how this framework bridges algorithm-generated explanations and human decision-making theories. Finally, we discuss implications for XAI design and development.},
	language = {en},
	urldate = {2022-07-11},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Wang, Danding and Yang, Qian and Abdul, Ashraf and Lim, Brian Y.},
	month = may,
	year = {2019},
	pages = {1--15},
	file = {Wang et al. - 2019 - Designing Theory-Driven User-Centric Explainable A.pdf:/Users/orsonxu/Zotero/storage/23YWB6US/Wang et al. - 2019 - Designing Theory-Driven User-Centric Explainable A.pdf:application/pdf},
}

@inproceedings{horvitz_principles_1999,
	address = {Pittsburgh, Pennsylvania, United States},
	title = {Principles of mixed-initiative user interfaces},
	isbn = {978-0-201-48559-2},
	url = {http://portal.acm.org/citation.cfm?doid=302979.303030},
	doi = {10.1145/302979.303030},
	abstract = {Recent debate has centered on the relative promise of focusing user-interface research on developing new metaphors and tools that enhance users’ abilities to directly manipulate objects versus directing effort toward developing interface agents that provide automation. In this paper, we review principles that show promise for allowing engineers to enhance human-computer interaction through an elegant coupling of automated services with direct manipulation. Key ideas will be highlighted in terms of the Lookout system for scheduling and meeting management.},
	language = {en},
	urldate = {2022-07-11},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems the {CHI} is the limit - {CHI} '99},
	publisher = {ACM Press},
	author = {Horvitz, Eric},
	year = {1999},
	pages = {159--166},
	annote = {- RQs and Contributions
How to make a mixed-initiated UI
Provide an example system that helps people to send emails/calendar events.

- Methods
Simple SVM with a good grid analysis on 
P(Goal, Action)
P(not Goal, Action)
P(Goal, not Action)
P(not Goal, not Action)
},
	file = {Horvitz - 1999 - Principles of mixed-initiative user interfaces.pdf:/Users/orsonxu/Zotero/storage/NSSHBCPC/Horvitz - 1999 - Principles of mixed-initiative user interfaces.pdf:application/pdf},
}

@inproceedings{cimolino_two_2022,
	address = {New Orleans LA USA},
	title = {Two {Heads} {Are} {Better} {Than} {One}: {A} {Dimension} {Space} for {Unifying} {Human} and {Artificial} {Intelligence} in {Shared} {Control}},
	isbn = {978-1-4503-9157-3},
	shorttitle = {Two {Heads} {Are} {Better} {Than} {One}},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517610},
	doi = {10.1145/3491102.3517610},
	abstract = {Shared control is an emerging interaction paradigm in which a human and an AI partner collaboratively control a system. Shared control unifes human and artifcial intelligence, making the human’s interactions with computers more accessible, safe, precise, efective, creative, and playful. This form of interaction has independently emerged in contexts as varied as mobility assistance, driving, surgery, and digital games. These domains each have their own problems, terminology, and design philosophies. Without a common language for describing interactions in shared control, it is difcult for designers working in one domain to share their knowledge with designers working in another. To address this problem, we present a dimension space for shared control, based on a survey of 55 shared control systems from six diferent problem domains. This design space analysis tool enables designers to classify existing systems, make comparisons between them, identify higher-level design patterns, and imagine solutions to novel problems.},
	language = {en},
	urldate = {2022-07-11},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Cimolino, Gabriele and Graham, T.C. Nicholas},
	month = apr,
	year = {2022},
	pages = {1--21},
	file = {Cimolino and Graham - 2022 - Two Heads Are Better Than One A Dimension Space f.pdf:/Users/orsonxu/Zotero/storage/5GSSUTQA/Cimolino and Graham - 2022 - Two Heads Are Better Than One A Dimension Space f.pdf:application/pdf},
}

@inproceedings{cila_designing_2022,
	address = {New Orleans LA USA},
	title = {Designing {Human}-{Agent} {Collaborations}: {Commitment}, responsiveness, and support},
	isbn = {978-1-4503-9157-3},
	shorttitle = {Designing {Human}-{Agent} {Collaborations}},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517500},
	doi = {10.1145/3491102.3517500},
	abstract = {With the advancements in AI, agents (i.e., smart products, robots, software agents) are increasingly capable of working closely together with humans in a variety of ways while benefiting from each other. These human-agent collaborations have gained growing attention in the HCI community; however, the field lacks clear guidelines on how to design the agents’ behaviors in collaborations. In this paper, the qualities that are relevant for designers to create robust and pleasant human-agent collaborations were investigated. Bratman’s Shared Cooperative Activity framework was used to identify the core characteristics of collaborations and survey the most important issues in the design of human-agent collaborations, namely code-of-conduct, task delegation, autonomy and control, intelligibility, common ground, offering help and requesting help. The aim of this work is to add structure to this growing and important facet of HCI research and operationalize the concept of human-agent collaboration with concrete design considerations.},
	language = {en},
	urldate = {2022-07-11},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Cila, Nazli},
	month = apr,
	year = {2022},
	pages = {1--18},
	file = {Cila - 2022 - Designing Human-Agent Collaborations Commitment, .pdf:/Users/orsonxu/Zotero/storage/RBLC95IG/Cila - 2022 - Designing Human-Agent Collaborations Commitment, .pdf:application/pdf},
}

@article{mohseni_multidisciplinary_2021,
	title = {A {Multidisciplinary} {Survey} and {Framework} for {Design} and {Evaluation} of {Explainable} {AI} {Systems}},
	volume = {11},
	issn = {2160-6455, 2160-6463},
	url = {https://dl.acm.org/doi/10.1145/3387166},
	doi = {10.1145/3387166},
	abstract = {The need for interpretable and accountable intelligent systems grows along with the prevalence of
              artificial intelligence
              (
              AI
              ) applications used in everyday life.
              Explainable AI
              (
              XAI
              ) systems are intended to self-explain the reasoning behind system decisions and predictions. Researchers from different disciplines work together to define, design, and evaluate explainable systems. However, scholars from different disciplines focus on different objectives and fairly independent topics of XAI research, which poses challenges for identifying appropriate design and evaluation methodology and consolidating knowledge across efforts. To this end, this article presents a survey and framework intended to share knowledge and experiences of XAI design and evaluation methods across multiple disciplines. Aiming to support diverse design goals and evaluation methods in XAI research, after a thorough review of XAI related papers in the fields of machine learning, visualization, and human-computer interaction, we present a categorization of XAI design goals and evaluation methods. Our categorization presents the mapping between design goals for different XAI user groups and their evaluation methods. From our findings, we develop a framework with step-by-step design guidelines paired with evaluation methods to close the iterative design and evaluation cycles in multidisciplinary XAI teams. Further, we provide summarized ready-to-use tables of evaluation methods and recommendations for different goals in XAI research.},
	language = {en},
	number = {3-4},
	urldate = {2022-07-11},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Mohseni, Sina and Zarei, Niloofar and Ragan, Eric D.},
	month = dec,
	year = {2021},
	pages = {1--45},
	annote = {A very good summary of XAI system designs.
Design goal for End user:
Algorithm transparency, user trust,
[less common, maybe no need in AR] bias mitigation, privacy awareness

What to explain:
how (overall model, not important for end user), why, why not, what if, how to (counter factual), what else (example)

How to explain:
visual, textual, analytical
},
	file = {Mohseni et al. - 2021 - A Multidisciplinary Survey and Framework for Desig.pdf:/Users/orsonxu/Zotero/storage/GTAHMS2G/Mohseni et al. - 2021 - A Multidisciplinary Survey and Framework for Desig.pdf:application/pdf},
}

@inproceedings{eiband_bringing_2018,
	address = {Tokyo Japan},
	title = {Bringing {Transparency} {Design} into {Practice}},
	isbn = {978-1-4503-4945-1},
	url = {https://dl.acm.org/doi/10.1145/3172944.3172961},
	doi = {10.1145/3172944.3172961},
	abstract = {Intelligent systems, which are on their way to becoming mainstream in everyday products, make recommendations and decisions for users based on complex computations. Researchers and policy makers increasingly raise concerns regarding the lack of transparency and comprehensibility of these computations from the user perspective. Our aim is to advance existing UI guidelines for more transparency in complex realworld design scenarios involving multiple stakeholders. To this end, we contribute a stage-based participatory process for designing transparent interfaces incorporating perspectives of users, designers, and providers, which we developed and validated with a commercial intelligent ﬁtness coach. With our work, we hope to provide guidance to practitioners and to pave the way for a pragmatic approach to transparency in intelligent systems.},
	language = {en},
	urldate = {2022-07-23},
	booktitle = {23rd {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Eiband, Malin and Schneider, Hanna and Bilandzic, Mark and Fazekas-Con, Julian and Haug, Mareike and Hussmann, Heinrich},
	month = mar,
	year = {2018},
	pages = {211--223},
	annote = {

RQs and Contributions


Provide a stage-based participatory process for designing transparent interfaces incorporating perspectives of users, designers, and providers
Answer two main question:
1) what to recommend
2) how to recommend
},
	file = {Eiband et al. - 2018 - Bringing Transparency Design into Practice.pdf:/Users/orsonxu/Zotero/storage/6GD3YVZK/Eiband et al. - 2018 - Bringing Transparency Design into Practice.pdf:application/pdf},
}

@inproceedings{long_what_2020,
	address = {Honolulu HI USA},
	title = {What is {AI} {Literacy}? {Competencies} and {Design} {Considerations}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {What is {AI} {Literacy}?},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376727},
	doi = {10.1145/3313831.3376727},
	abstract = {Artificial intelligence (AI) is becoming increasingly integrated in user-facing technology, but public understanding of these technologies is often limited. There is a need for additional HCI research investigating a) what competencies users need in order to effectively interact with and critically evaluate AI and b) how to design learnercentered AI technologies that foster increased user understanding of AI. This paper takes a step towards realizing both of these goals by providing a concrete definition of AI literacy based on existing research. We synthesize a variety of interdisciplinary literature into a set of core competencies of AI literacy and suggest several design considerations to support AI developers and educators in creating learner-centered AI. These competencies and design considerations are organized in a conceptual framework thematically derived from the literature. This paper’s contributions can be used to start a conversation about and guide future research on AI literacy within the HCI community.},
	language = {en},
	urldate = {2022-07-21},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Long, Duri and Magerko, Brian},
	month = apr,
	year = {2020},
	pages = {1--16},
	file = {Long and Magerko - 2020 - What is AI Literacy Competencies and Design Consi.pdf:/Users/orsonxu/Zotero/storage/F7X455KW/Long and Magerko - 2020 - What is AI Literacy Competencies and Design Consi.pdf:application/pdf},
}

@inproceedings{roy_automation_2019,
	address = {Glasgow Scotland Uk},
	title = {Automation {Accuracy} {Is} {Good}, but {High} {Controllability} {May} {Be} {Better}},
	isbn = {978-1-4503-5970-2},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300750},
	doi = {10.1145/3290605.3300750},
	abstract = {When automating tasks using some form of artificial intelligence, some inaccuracy in the result is virtually unavoidable. In many cases, the user must decide whether to try the automated method again, or fix it themselves using the available user interface. We argue this decision is influenced by both perceived automation accuracy and degree of task “controllability” (how easily and to what extent an automated result can be manually modified). This relationship between accuracy and controllability is investigated in a 750-participant crowdsourced experiment using a controlled, gamified task. With high controllability, self-reported satisfaction remained constant even under very low accuracy conditions, and overall, a strong preference was observed for using manual control rather than automation, despite much slower performance and regardless of very poor controllability.},
	language = {en},
	urldate = {2022-07-21},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Roy, Quentin and Zhang, Futian and Vogel, Daniel},
	month = may,
	year = {2019},
	pages = {1--8},
	file = {Roy et al. - 2019 - Automation Accuracy Is Good, but High Controllabil.pdf:/Users/orsonxu/Zotero/storage/3XRB6925/Roy et al. - 2019 - Automation Accuracy Is Good, but High Controllabil.pdf:application/pdf},
}

@inproceedings{cai_impacts_2022,
	address = {New Orleans LA USA},
	title = {Impacts of {Personal} {Characteristics} on {User} {Trust} in {Conversational} {Recommender} {Systems}},
	isbn = {978-1-4503-9157-3},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517471},
	doi = {10.1145/3491102.3517471},
	abstract = {Conversational recommender systems (CRSs) imitate human advisors to assist users in fnding items through conversations and have recently gained increasing attention in domains such as media and e-commerce. Like in human communication, building trust in human-agent communication is essential given its signifcant infuence on user behavior. However, inspiring user trust in CRSs with a “one-size-fts-all” design is difcult, as individual users may have their own expectations for conversational interactions (e.g., who, user or system, takes the initiative), which are potentially related to their personal characteristics. In this study, we investigated the impacts of three personal characteristics, namely personality traits, trust propensity, and domain knowledge, on user trust in two types of text-based CRSs, i.e., user-initiative and mixed-initiative. Our between-subjects user study (N=148) revealed that users’ trust propensity and domain knowledge positively infuenced their trust in CRSs, and that users with high conscientiousness tended to trust the mixed-initiative system.},
	language = {en},
	urldate = {2022-07-21},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Cai, Wanling and Jin, Yucheng and Chen, Li},
	month = apr,
	year = {2022},
	pages = {1--14},
	file = {Cai et al. - 2022 - Impacts of Personal Characteristics on User Trust .pdf:/Users/orsonxu/Zotero/storage/VS3CFV9X/Cai et al. - 2022 - Impacts of Personal Characteristics on User Trust .pdf:application/pdf},
}

@article{schmidt_transparency_2020,
	title = {Transparency and trust in artificial intelligence systems},
	volume = {29},
	issn = {1246-0125, 2116-7052},
	url = {https://www.tandfonline.com/doi/full/10.1080/12460125.2020.1819094},
	doi = {10.1080/12460125.2020.1819094},
	abstract = {Assistive technology featuring artificial intelligence (AI) to support human decision-making has become ubiquitous. Assistive AI achieves accuracy comparable to or even surpassing that of human experts. However, often the adoption of assistive AI systems is limited by a lack of trust of humans into an AI’s prediction. This is why the AI research community has been focusing on rendering AI decisions more transparent by providing explanations of an AIs decision. To what extent these explanations really help to foster trust into an AI system remains an open question. In this paper, we report the results of a behavioural experiment in which subjects were able to draw on the support of an ML-based decision support tool for text classification. We experimentally varied the information subjects received and show that transparency can actually have a negative impact on trust. We discuss implications for decision makers employing assistive AI technology.},
	language = {en},
	number = {4},
	urldate = {2022-07-21},
	journal = {Journal of Decision Systems},
	author = {Schmidt, Philipp and Biessmann, Felix and Teubner, Timm},
	month = oct,
	year = {2020},
	pages = {260--278},
	file = {Schmidt et al. - 2020 - Transparency and trust in artificial intelligence .pdf:/Users/orsonxu/Zotero/storage/Q2YX3FS7/Schmidt et al. - 2020 - Transparency and trust in artificial intelligence .pdf:application/pdf},
}

@article{zanzotto_viewpoint_2019,
	title = {Viewpoint: {Human}-in-the-loop {Artificial} {Intelligence}},
	volume = {64},
	issn = {1076-9757},
	shorttitle = {Viewpoint},
	url = {https://jair.org/index.php/jair/article/view/11345},
	doi = {10.1613/jair.1.11345},
	abstract = {Little by little, newspapers are revealing the bright future that Artiﬁcial Intelligence (AI) is building. Intelligent machines will help everywhere. However, this bright future may have a possible dark side: a dramatic job market contraction before its unpredictable transformation. Hence, in a near future, large numbers of job seekers may need ﬁnancial support while catching up with these novel unpredictable jobs. This possible job market crisis has an antidote inside. In fact, the rise of AI is sustained by the biggest knowledge theft of the recent years. Many learning AI machines are extracting knowledge from unaware skilled or unskilled workers by analyzing their interactions. By passionately doing their jobs, many of these workers are shooting themselves in the feet.},
	language = {en},
	urldate = {2022-07-18},
	journal = {Journal of Artificial Intelligence Research},
	author = {Zanzotto, Fabio Massimo},
	month = feb,
	year = {2019},
	pages = {243--252},
	file = {Zanzotto - 2019 - Viewpoint Human-in-the-loop Artificial Intelligen.pdf:/Users/orsonxu/Zotero/storage/5BZYGL9X/Zanzotto - 2019 - Viewpoint Human-in-the-loop Artificial Intelligen.pdf:application/pdf},
}

@inproceedings{dhanorkar_who_2021,
	address = {Virtual Event USA},
	title = {Who needs to know what, when?: {Broadening} the {Explainable} {AI} ({XAI}) {Design} {Space} by {Looking} at {Explanations} {Across} the {AI} {Lifecycle}},
	isbn = {978-1-4503-8476-6},
	shorttitle = {Who needs to know what, when?},
	url = {https://dl.acm.org/doi/10.1145/3461778.3462131},
	doi = {10.1145/3461778.3462131},
	abstract = {The interpretability or explainability of AI systems (XAI) has been a topic gaining renewed attention in recent years across AI and HCI communities. Recent work has drawn attention to the emergent explainability requirements of in situ, applied projects, yet further exploratory work is needed to more fully understand this space. This paper investigates applied AI projects and reports on a qualitative interview study of individuals working on AI projects at a large technology and consulting company. Presenting an empirical understanding of the range of stakeholders in industrial AI projects, this paper also draws out the emergent explainability practices that arise as these projects unfold, highlighting the range of explanation audiences (who), as well as how their explainability needs evolve across the AI project lifecycle (when). We discuss the importance of adopting a sociotechnical lens in designing AI systems, noting how the “AI lifecycle” can serve as a design metaphor to further the XAI design field.},
	language = {en},
	urldate = {2022-07-15},
	booktitle = {Designing {Interactive} {Systems} {Conference} 2021},
	publisher = {ACM},
	author = {Dhanorkar, Shipi and Wolf, Christine T. and Qian, Kun and Xu, Anbang and Popa, Lucian and Li, Yunyao},
	month = jun,
	year = {2021},
	pages = {1591--1602},
	annote = {

RQs and Contributions


A qualitative study to understand the design of XAI systems by interviewing 30 technical developers, HCI researchers and designers.

Two cases when explanation is needed:


Expectation mismatch


Explanations in service of business actionability



Also mentioned the trade-off effect of simplicity/complexity explanation, and how much to explain
},
	file = {Dhanorkar et al. - 2021 - Who needs to know what, when Broadening the Expl.pdf:/Users/orsonxu/Zotero/storage/R2EMIPGU/Dhanorkar et al. - 2021 - Who needs to know what, when Broadening the Expl.pdf:application/pdf},
}

@article{jiang_who_2022,
	title = {Who needs explanation and when? {Juggling} explainable {AI} and user epistemic uncertainty},
	volume = {165},
	issn = {10715819},
	shorttitle = {Who needs explanation and when?},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581922000660},
	doi = {10.1016/j.ijhcs.2022.102839},
	abstract = {In recent years, AI explainability (XAI) has received wide attention. Although XAI is expected to play a positive role in decision-making and advice acceptance, various opposing effects have also been found. The opposing effects of XAI highlight the critical role of context, especially human factors, in understanding XAI’s impacts. This study investigates the effects of providing three types of post-hoc explanations (alternative advice, prediction confidence scores, and prediction rationale) on two context-specific user decision-making outcomes (AI advice acceptance and advice adoption). Our field experiment results show that users’ epistemic uncertainty matters when understanding XAI’s impacts. As users’ epistemic uncertainty increases, only providing prediction rationale is beneficial, whereas providing alternative advice and showing prediction confidence scores may hinder users’ advice acceptance. Our study contributes to the emerging literature on the human aspects of XAI by clarifying XAI and showing that XAI may not always be desirable. It also contributes by highlighting the importance of considering user profiles when pre­ dicting XAI’s impacts, designing XAI, and providing professional services with AI.},
	language = {en},
	urldate = {2022-07-14},
	journal = {International Journal of Human-Computer Studies},
	author = {Jiang, Jinglu and Kahai, Surinder and Yang, Ming},
	month = sep,
	year = {2022},
	pages = {102839},
	file = {Jiang et al. - 2022 - Who needs explanation and when Juggling explainab.pdf:/Users/orsonxu/Zotero/storage/TPQW9LKP/Jiang et al. - 2022 - Who needs explanation and when Juggling explainab.pdf:application/pdf},
}

@inproceedings{lim_assessing_2009,
	address = {Orlando Florida USA},
	title = {Assessing demand for intelligibility in context-aware applications},
	isbn = {978-1-60558-431-7},
	url = {https://dl.acm.org/doi/10.1145/1620545.1620576},
	doi = {10.1145/1620545.1620576},
	abstract = {Intelligibility can help expose the inner workings and inputs of context-aware applications that tend to be opaque to users due to their implicit sensing and actions. However, users may not be interested in all the information that the applications can produce. Using scenarios of four real-world applications that span the design space of context-aware computing, we conducted two experiments to discover what information users are interested in. In the first experiment, we elicit types of information demands that users have and under what moderating circumstances they have them. In the second experiment, we verify the findings by soliciting users about which types they would want to know and establish whether receiving such information would satisfy them. We discuss why users demand certain types of information, and provide design implications on how to provide different intelligibility types to make context-aware applications intelligible and acceptable to users.},
	language = {en},
	urldate = {2022-07-14},
	booktitle = {Proceedings of the 11th international conference on {Ubiquitous} computing},
	publisher = {ACM},
	author = {Lim, Brian Y. and Dey, Anind K.},
	month = sep,
	year = {2009},
	pages = {195--204},
	annote = {What to explain:

input, output, certainty
why, why not, what if, how to, what else
},
	file = {Lim and Dey - 2009 - Assessing demand for intelligibility in context-aw.pdf:/Users/orsonxu/Zotero/storage/MZ9XATEV/Lim and Dey - 2009 - Assessing demand for intelligibility in context-aw.pdf:application/pdf},
}

@inproceedings{dey_support_2009,
	address = {Boston MA USA},
	title = {Support for context-aware intelligibility and control},
	isbn = {978-1-60558-246-7},
	url = {https://dl.acm.org/doi/10.1145/1518701.1518832},
	doi = {10.1145/1518701.1518832},
	abstract = {Intelligibility and control are important user concerns in context-aware applications. They allow a user to understand why an application is behaving a certain way, and to change its behavior. Because of their importance to end users, they must be addressed at an interface level. However, often the sensors or machine learning systems that users need to understand and control are created long before a specific application is built, or created separately from the application interface. Thus, supporting interface designers in building intelligibility and control into interfaces requires application logic and underlying infrastructure to be exposed in some structured fashion. As context-aware infrastructures do not provide generalized support for this, we extended one such infrastructure with Situations, components that appropriately exposes application logic, and supports debugging and simple intelligibility and control interfaces, while making it easier for an application developer to build context-aware applications and facilitating designer access to application state and behavior. We developed support for interface designers in Visual Basic and Flash. We demonstrate the usefulness of this support through an evaluation of programmers, an evaluation of the usability of the new infrastructure with interface designers, and the augmentation of three common context-aware applications.},
	language = {en},
	urldate = {2022-07-14},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Dey, Anind K. and Newberger, Alan},
	month = apr,
	year = {2009},
	pages = {859--868},
	file = {Dey and Newberger - 2009 - Support for context-aware intelligibility and cont.pdf:/Users/orsonxu/Zotero/storage/SPSAH5UL/Dey and Newberger - 2009 - Support for context-aware intelligibility and cont.pdf:application/pdf},
}

@inproceedings{liao_questioning_2020,
	title = {Questioning the {AI}: {Informing} {Design} {Practices} for {Explainable} {AI} {User} {Experiences}},
	shorttitle = {Questioning the {AI}},
	url = {http://arxiv.org/abs/2001.02478},
	doi = {10.1145/3313831.3376590},
	abstract = {A surge of interest in explainable AI (XAI) has led to a vast collection of algorithmic work on the topic. While many recognize the necessity to incorporate explainability features in AI systems, how to address real-world user needs for understanding AI remains an open question. By interviewing 20 UX and design practitioners working on various AI products, we seek to identify gaps between the current XAI algorithmic work and practices to create explainable AI products. To do so, we develop an algorithm-informed XAI question bank in which user needs for explainability are represented as prototypical questions users might ask about the AI, and use it as a study probe. Our work contributes insights into the design space of XAI, informs efforts to support design practices in this space, and identifies opportunities for future XAI work. We also provide an extended XAI question bank and discuss how it can be used for creating user-centered XAI.},
	urldate = {2022-08-05},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Liao, Q. Vera and Gruen, Daniel and Miller, Sarah},
	month = apr,
	year = {2020},
	note = {arXiv:2001.02478 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Software Engineering},
	pages = {1--15},
	annote = {Comment: PublishedACM CHI Conference on Human Factors in Computing Systems (CHI 2020). Updated XAI Question Bank in September 2021},
	file = {arXiv Fulltext PDF:/Users/orsonxu/Zotero/storage/FM7TH38X/Liao et al. - 2020 - Questioning the AI Informing Design Practices for.pdf:application/pdf;arXiv.org Snapshot:/Users/orsonxu/Zotero/storage/L4QMZJ2U/2001.html:text/html},
}

@inproceedings{jeyakumar_how_2020,
	title = {How {Can} {I} {Explain} {This} to {You}? {An} {Empirical} {Study} of {Deep} {Neural} {Network} {Explanation} {Methods}},
	volume = {33},
	shorttitle = {How {Can} {I} {Explain} {This} to {You}?},
	url = {https://proceedings.neurips.cc/paper/2020/hash/2c29d89cc56cdb191c60db2f0bae796b-Abstract.html},
	abstract = {Explaining the inner workings of deep neural network models have received considerable attention in recent years. Researchers have attempted to provide human parseable explanations justifying why a model performed a specific classification. Although many of these toolkits are available for use, it is unclear which style of explanation is preferred by end-users, thereby demanding investigation. We performed a cross-analysis Amazon Mechanical Turk study comparing the popular state-of-the-art explanation methods to empirically determine which are better in explaining model decisions. The participants were asked to compare explanation methods across applications spanning image, text, audio, and sensory domains. Among the surveyed methods, explanation-by-example was preferred in all domains except text sentiment classification, where LIME's method of annotating input text was preferred. We highlight qualitative aspects of employing the studied explainability methods and conclude with implications for researchers and engineers that seek to incorporate explanations into user-facing deployments.},
	urldate = {2022-08-05},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Jeyakumar, Jeya Vikranth and Noor, Joseph and Cheng, Yu-Hsi and Garcia, Luis and Srivastava, Mani},
	year = {2020},
	pages = {4211--4222},
	file = {Full Text PDF:/Users/orsonxu/Zotero/storage/IAVRNZ2J/Jeyakumar et al. - 2020 - How Can I Explain This to You An Empirical Study .pdf:application/pdf},
}

@article{bellotti_intelligibility_2001,
	title = {Intelligibility and {Accountability}: {Human} {Considerations} in {Context}-{Aware} {Systems}},
	volume = {16},
	issn = {0737-0024, 1532-7051},
	shorttitle = {Intelligibility and {Accountability}},
	url = {https://www.tandfonline.com/doi/full/10.1207/S15327051HCI16234_05},
	doi = {10.1207/S15327051HCI16234_05},
	abstract = {This essay considers the problem of defining the context that context-aware systems should pay attention to from a human perspective. In particular, we argue that there are human aspects of context that cannot be sensed or even inferred by technological means, so context-aware systems cannot be designed simply to act on our behalf. Rather, they will have to be able to defer to users in an efficient and nonobtrusive fashion. Our point is particularly relevant for systems that are constructed such that applications are architecturally isolated from the sensing and inferencing that governs their behavior. We propose a design framework that is intended to guide thinking about accommodating human aspects of context. This framework presents four design principles that support intelligibility of system behavior and accountability of human users and a number of human-salient details of context that must be accounted for in context-aware system design.},
	language = {en},
	number = {2-4},
	urldate = {2022-08-25},
	journal = {Human–Computer Interaction},
	author = {Bellotti, Victoria and Edwards, Keith},
	month = dec,
	year = {2001},
	pages = {193--212},
	file = {Bellotti and Edwards - 2001 - Intelligibility and Accountability Human Consider.pdf:/Users/orsonxu/Zotero/storage/V53MK9PH/Bellotti and Edwards - 2001 - Intelligibility and Accountability Human Consider.pdf:application/pdf},
}

@inproceedings{zhu_explainable_2018,
	title = {Explainable {AI} for {Designers}: {A} {Human}-{Centered} {Perspective} on {Mixed}-{Initiative} {Co}-{Creation}},
	shorttitle = {Explainable {AI} for {Designers}},
	doi = {10.1109/CIG.2018.8490433},
	abstract = {Growing interest in eXplainable Artificial Intelligence (XAI) aims to make AI and machine learning more understandable to human users. However, most existing work focuses on new algorithms, and not on usability, practical interpretability and efficacy on real users. In this vision paper, we propose a new research area of eXplainable AI for Designers (XAID), specifically for game designers. By focusing on a specific user group, their needs and tasks, we propose a human-centered approach for facilitating game designers to co-create with AI/ML techniques through XAID. We illustrate our initial XAID framework through three use cases, which require an understanding both of the innate properties of the AI techniques and users' needs, and we identify key open challenges.},
	booktitle = {2018 {IEEE} {Conference} on {Computational} {Intelligence} and {Games} ({CIG})},
	author = {Zhu, Jichen and Liapis, Antonios and Risi, Sebastian and Bidarra, Rafael and Youngblood, G. Michael},
	month = aug,
	year = {2018},
	keywords = {Visualization, machine learning, human-computer interaction, Machine learning, Task analysis, Games, game design, explainable artificial intelligence, mixed-initiative co-creation, Neurons, Tools},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:/Users/orsonxu/Zotero/storage/UMZNM5C2/8490433.html:text/html;IEEE Xplore Full Text PDF:/Users/orsonxu/Zotero/storage/SCL2CAYE/Zhu et al. - 2018 - Explainable AI for Designers A Human-Centered Per.pdf:application/pdf},
}

@inproceedings{wolf_explainability_2019,
	address = {Marina del Ray California},
	title = {Explainability scenarios: towards scenario-based {XAI} design},
	isbn = {978-1-4503-6272-6},
	shorttitle = {Explainability scenarios},
	url = {https://dl.acm.org/doi/10.1145/3301275.3302317},
	doi = {10.1145/3301275.3302317},
	abstract = {Integral to the adoption and uptake of AI systems in real-world settings is the ability for people to make sense of and evaluate such systems, a growing area of development and design efforts known as XAI (Explainable AI). Recent work has advanced the state of the art, yet a key challenge remains in understanding unique requirements that might arise when XAI systems are deployed into complex settings of use. In helping envision such requirements, this paper turns to scenario-based design, a method that anticipates and leverages scenarios of possible use early on in system development. To demonstrate the value of the scenario-based design method to XAI design, this paper presents a case study of aging-in-place monitoring. Introducing the concept of “explainability scenarios” as resources in XAI design, this paper sets out a forward-facing agenda for further attention to the emergent requirements of explainability-in-use.},
	language = {en},
	urldate = {2022-11-22},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Wolf, Christine T.},
	month = mar,
	year = {2019},
	pages = {252--257},
	file = {Wolf - 2019 - Explainability scenarios towards scenario-based X.pdf:/Users/orsonxu/Zotero/storage/QHZJV6U7/Wolf - 2019 - Explainability scenarios towards scenario-based X.pdf:application/pdf},
}

@inproceedings{kaur_interpreting_2020,
	address = {Honolulu HI USA},
	title = {Interpreting {Interpretability}: {Understanding} {Data} {Scientists}' {Use} of {Interpretability} {Tools} for {Machine} {Learning}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {Interpreting {Interpretability}},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376219},
	doi = {10.1145/3313831.3376219},
	abstract = {Machine learning (ML) models are now routinely deployed in domains ranging from criminal justice to healthcare. With this newfound ubiquity, ML has moved beyond academia and grown into an engineering discipline. To that end, interpretability tools have been designed to help data scientists and machine learning practitioners better understand how ML models work. However, there has been little evaluation of the extent to which these tools achieve this goal. We study data scientists’ use of two existing interpretability tools, the InterpretML implementation of GAMs and the SHAP Python package. We conduct a contextual inquiry (N=11) and a survey (N=197) of data scientists to observe how they use interpretability tools to uncover common issues that arise when building and evaluating ML models. Our results indicate that data scientists over-trust and misuse interpretability tools. Furthermore, few of our participants were able to accurately describe the visualizations output by these tools. We highlight qualitative themes for data scientists’ mental models of interpretability tools. We conclude with implications for researchers and tool designers, and contextualize our ﬁndings in the social science literature.},
	language = {en},
	urldate = {2022-11-22},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Kaur, Harmanpreet and Nori, Harsha and Jenkins, Samuel and Caruana, Rich and Wallach, Hanna and Wortman Vaughan, Jennifer},
	month = apr,
	year = {2020},
	pages = {1--14},
	file = {Kaur et al. - 2020 - Interpreting Interpretability Understanding Data .pdf:/Users/orsonxu/Zotero/storage/QEDS36CI/Kaur et al. - 2020 - Interpreting Interpretability Understanding Data .pdf:application/pdf},
}


@article{Shrikumar2017,
	title = {Learning important features through propagating activation differences},
	volume = {7},
	abstract = {The purported "black box"' nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Deep Learning Important FeaTures), a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input. DeepLIFT compares the activation of each neuron to its 'reference activation' and assigns contribution scores according to the difference. By optionally giving separate consideration to positive and negative contributions, DeepLIFT can also reveal dependencies which are missed by other approaches. Scores can be computed efficiently in a single backward pass. We apply DeepLIFT to models trained on MNIST and simulated genomic data, and show significant advantages over gradient-based methods. A detailed video tutorial on the method is at http://goo.gl/qKb7pL and code is at http://goo.gl/RM8jvH.},
	journal = {34th International Conference on Machine Learning, ICML 2017},
	author = {Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
	year = {2017},
	note = {ISBN: 9781510855144},
	pages = {4844--4866},
	file = {Shrikumar et al_2017_Learning important features through propagating activation differences.pdf:/Users/orsonxu/Zotero/storage/SJNUF7A6/Shrikumar et al_2017_Learning important features through propagating activation differences.pdf:application/pdf;Shrikumar et al_2017_Learning important features through propagating activation differences.pdf:/Users/orsonxu/Zotero/storage/Y6NZD2BJ/Shrikumar et al_2017_Learning important features through propagating activation differences.pdf:application/pdf},
}

@article{Ribeiro2016,
	title = {"{Why} should i trust you?" {Explaining} the predictions of any classifier},
	volume = {13-17-Augu},
	doi = {10.1145/2939672.2939778},
	abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	year = {2016},
	note = {ISBN: 9781450342322},
	keywords = {Unread},
	pages = {1135--1144},
	file = {Ribeiro et al_2016_Why should i trust you.pdf:/Users/orsonxu/Zotero/storage/547JULV7/Ribeiro et al_2016_Why should i trust you.pdf:application/pdf;Ribeiro et al_2016_Why should i trust you.pdf:/Users/orsonxu/Zotero/storage/QJFHN79Y/Ribeiro et al_2016_Why should i trust you.pdf:application/pdf},
}

@article{Lee2020,
	title = {Explanation-{Based} {Tuning} of {Opaque} {Machine} {Learners} with {Application} to {Paper} {Recommendation}},
	url = {http://arxiv.org/abs/2003.04315},
	abstract = {Research in human-centered AI has shown the benefits of machine-learning systems that can explain their predictions. Methods that allow users to tune a model in response to the explanations are similarly useful. While both capabilities are well-developed for transparent learning models (e.g., linear models and GA2Ms), and recent techniques (e.g., LIME and SHAP) can generate explanations for opaque models, no method currently exists for tuning of opaque models in response to explanations. This paper introduces LIMEADE, a general framework for tuning an arbitrary machine learning model based on an explanation of the model's prediction. We apply our framework to Semantic Sanity, a neural recommender system for scientific papers, and report on a detailed user study, showing that our framework leads to significantly higher perceived user control, trust, and satisfaction.},
	author = {Lee, Benjamin Charles Germain and Lo, Kyle and Downey, Doug and Weld, Daniel S.},
	year = {2020},
	file = {Lee et al_2020_Explanation-Based Tuning of Opaque Machine Learners with Application to Paper Recommendation.pdf:/Users/orsonxu/Zotero/storage/PQV7AH7G/Lee et al_2020_Explanation-Based Tuning of Opaque Machine Learners with Application to Paper Recommendation.pdf:application/pdf;Lee et al_2020_Explanation-Based Tuning of Opaque Machine Learners with Application to Paper Recommendation.pdf:/Users/orsonxu/Zotero/storage/TAIACMZH/Lee et al_2020_Explanation-Based Tuning of Opaque Machine Learners with Application to Paper Recommendation.pdf:application/pdf},
}

@article{Lundberg2017,
	title = {A unified approach to interpreting model predictions},
	volume = {2017-Decem},
	issn = {10495258},
	abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
	number = {Section 2},
	journal = {Advances in Neural Information Processing Systems},
	author = {Lundberg, Scott M. and Lee, Su In},
	year = {2017},
	keywords = {Unread},
	pages = {4766--4775},
	file = {Lundberg_Lee_2017_A unified approach to interpreting model predictions.pdf:/Users/orsonxu/Zotero/storage/Z5RGT97L/Lundberg_Lee_2017_A unified approach to interpreting model predictions.pdf:application/pdf;Lundberg_Lee_2017_A unified approach to interpreting model predictions.pdf:/Users/orsonxu/Zotero/storage/KFHPZATU/Lundberg_Lee_2017_A unified approach to interpreting model predictions.pdf:application/pdf},
}

@article{Gordon2021,
	title = {The {Disagreement} {Deconvolution} : {Bringing} {Machine} {Learning} {Performance} {Metrics} {In} {Line} {With} {Reality}},
	journal = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems - CHI '21},
	author = {Gordon, Mitchell L and Zhou, Kaitlyn and Bernstein, Michael S},
	year = {2021},
	note = {ISBN: 9781450380966},
	annote = {- RQs and Contributions

incorporate an estimate ofhow contested each label will be into ML metrics in an interpretable way, producing metrics that ask not “What proportion ofground truth labels does the classifier agree with?” but “What proportion of the population does the classifier agree with?”

Disagreement deconvolution: transforms any ML classification metric to reflect the underlying distribution of popu- lation labels},
	file = {Gordon et al_2021_The Disagreement Deconvolution.pdf:/Users/orsonxu/Zotero/storage/AA5TMKD8/Gordon et al_2021_The Disagreement Deconvolution.pdf:application/pdf;Gordon et al_2021_The Disagreement Deconvolution.pdf:/Users/orsonxu/Zotero/storage/SY7LZ2L4/Gordon et al_2021_The Disagreement Deconvolution.pdf:application/pdf},
}

@inproceedings{mothilal_explaining_2020,
	address = {Barcelona Spain},
	title = {Explaining machine learning classifiers through diverse counterfactual explanations},
	isbn = {978-1-4503-6936-7},
	url = {https://dl.acm.org/doi/10.1145/3351095.3372850},
	doi = {10.1145/3351095.3372850},
	abstract = {Post-hoc explanations of machine learning models are crucial for people to understand and act on algorithmic predictions. An intriguing class of explanations is through counterfactuals, hypothetical examples that show people how to obtain a different prediction. We posit that effective counterfactual explanations should satisfy two properties: feasibility of the counterfactual actions given user context and constraints, and diversity among the counterfactuals presented. To this end, we propose a framework for generating and evaluating a diverse set of counterfactual explanations based on determinantal point processes. To evaluate the actionability of counterfactuals, we provide metrics that enable comparison of counterfactual-based methods to other local explanation methods. We further address necessary tradeoffs and point to causal implications in optimizing for counterfactuals. Our experiments on four real-world datasets show that our framework can generate a set of counterfactuals that are diverse and well approximate local decision boundaries, outperforming prior approaches to generating diverse counterfactuals. We provide an implementation of the framework at https://github.com/microsoft/DiCE.},
	language = {en},
	urldate = {2021-11-23},
	booktitle = {Proceedings of the 2020 {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Mothilal, Ramaravind K. and Sharma, Amit and Tan, Chenhao},
	month = jan,
	year = {2020},
	keywords = {Unread},
	pages = {607--617},
	file = {Mothilal et al. - 2020 - Explaining machine learning classifiers through di.pdf:/Users/orsonxu/Zotero/storage/25N37EPI/Mothilal et al. - 2020 - Explaining machine learning classifiers through di.pdf:application/pdf},
}

@article{barredo_arrieta_explainable_2020,
	title = {Explainable {Artificial} {Intelligence} ({XAI}): {Concepts}, taxonomies, opportunities and challenges toward responsible {AI}},
	volume = {58},
	issn = {15662535},
	shorttitle = {Explainable {Artificial} {Intelligence} ({XAI})},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1566253519308103},
	doi = {10.1016/j.inffus.2019.12.012},
	language = {en},
	urldate = {2021-11-30},
	journal = {Information Fusion},
	author = {Barredo Arrieta, Alejandro and Díaz-Rodríguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garcia, Salvador and Gil-Lopez, Sergio and Molina, Daniel and Benjamins, Richard and Chatila, Raja and Herrera, Francisco},
	month = jun,
	year = {2020},
	pages = {82--115},
	annote = {A very comprehensive summary of XAI, from the concept, definition to all kinds of methods in the domain.

A few highlights:


Three levels of transparency (the higher, the more transparent):


Simulatability


Decomposibility


Algorithmic Transparency




Two general types of models


Interpretable ML models


Linear/logistic regression


Decision Tree


KNN


Rule-based model


General linear/additive models


Bayesian Models




Post-hoc interpretability


Model-agnostic techniques


LIME


SHAP











},
	file = {Barredo Arrieta et al. - 2020 - Explainable Artificial Intelligence (XAI) Concept.pdf:/Users/orsonxu/Zotero/storage/MEXVF7WC/Barredo Arrieta et al. - 2020 - Explainable Artificial Intelligence (XAI) Concept.pdf:application/pdf},
}

@incollection{holzinger_explainable_2018,
	address = {Cham},
	title = {Explainable {AI}: {The} {New} 42?},
	volume = {11015},
	isbn = {978-3-319-99739-1 978-3-319-99740-7},
	shorttitle = {Explainable {AI}},
	url = {https://link.springer.com/10.1007/978-3-319-99740-7_21},
	abstract = {Explainable AI is not a new ﬁeld. Since at least the early exploitation of C.S. Pierce’s abductive reasoning in expert systems of the 1980s, there were reasoning architectures to support an explanation function for complex AI systems, including applications in medical diagnosis, complex multi-component design, and reasoning about the real world. So explainability is at least as old as early AI, and a natural consequence of the design of AI systems. While early expert systems consisted of handcrafted knowledge bases that enabled reasoning over narrowly well-deﬁned domains (e.g., INTERNIST, MYCIN), such systems had no learning capabilities and had only primitive uncertainty handling. But the evolution of formal reasoning architectures to incorporate principled probabilistic reasoning helped address the capture and use of uncertain knowledge.},
	language = {en},
	urldate = {2022-01-05},
	booktitle = {Machine {Learning} and {Knowledge} {Extraction}},
	publisher = {Springer International Publishing},
	author = {Goebel, Randy and Chander, Ajay and Holzinger, Katharina and Lecue, Freddy and Akata, Zeynep and Stumpf, Simone and Kieseberg, Peter and Holzinger, Andreas},
	editor = {Holzinger, Andreas and Kieseberg, Peter and Tjoa, A Min and Weippl, Edgar},
	year = {2018},
	doi = {10.1007/978-3-319-99740-7_21},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {295--303},
	annote = {- RQs and Contributions
A brief summary of recent advance on textual and visual interpretability on deep learning models
Directions:
Visual:
- Attentions Weights
- Differences in distributions like KL divergence
Text:
- Language generation as explanation
- Attention},
	file = {Goebel et al. - 2018 - Explainable AI The New 42.pdf:/Users/orsonxu/Zotero/storage/3KCB9T5W/Goebel et al. - 2018 - Explainable AI The New 42.pdf:application/pdf},
}

@article{zhang_explainable_2020,
	title = {Explainable {Recommendation}: {A} {Survey} and {New} {Perspectives}},
	volume = {14},
	issn = {1554-0669, 1554-0677},
	shorttitle = {Explainable {Recommendation}},
	url = {http://arxiv.org/abs/1804.11192},
	doi = {10.1561/1500000066},
	abstract = {Explainable recommendation attempts to develop models that generate not only high-quality recommendations but also intuitive explanations. The explanations may either be post-hoc or directly come from an explainable model (also called interpretable or transparent model in some contexts). Explainable recommendation tries to address the problem of why: by providing explanations to users or system designers, it helps humans to understand why certain items are recommended by the algorithm, where the human can either be users or system designers. Explainable recommendation helps to improve the transparency, persuasiveness, effectiveness, trustworthiness, and satisfaction of recommendation systems. It also facilitates system designers for better system debugging. In recent years, a large number of explainable recommendation approaches -- especially model-based methods -- have been proposed and applied in real-world systems. In this survey, we provide a comprehensive review for the explainable recommendation research. We first highlight the position of explainable recommendation in recommender system research by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation on three perspectives: 1) We provide a chronological research timeline of explainable recommendation. 2) We provide a two-dimensional taxonomy to classify existing explainable recommendation research. 3) We summarize how explainable recommendation applies to different recommendation tasks. We also devote a chapter to discuss the explanation perspectives in broader IR and AI/ML research. We end the survey by discussing potential future directions to promote the explainable recommendation research area and beyond.},
	number = {1},
	urldate = {2022-01-25},
	journal = {Foundations and Trends® in Information Retrieval},
	author = {Zhang, Yongfeng and Chen, Xu},
	year = {2020},
	note = {arXiv: 1804.11192},
	pages = {1--101},
	annote = {Comment: 101 pages, published in Foundations and Trends in Information Retrieval, 14(1), pp.1-101 (2020)},
	file = {Zhang_Chen_2020_Explainable Recommendation.pdf:/Users/orsonxu/Zotero/storage/IRQ5T486/Zhang_Chen_2020_Explainable Recommendation.pdf:application/pdf;Zhang_Chen_2020_Explainable Recommendation.pdf:/Users/orsonxu/Zotero/storage/SPBAXHQ7/Zhang_Chen_2020_Explainable Recommendation.pdf:application/pdf},
}

@article{adadi_peeking_2018,
	title = {Peeking {Inside} the {Black}-{Box}: {A} {Survey} on {Explainable} {Artificial} {Intelligence} ({XAI})},
	volume = {6},
	issn = {2169-3536},
	shorttitle = {Peeking {Inside} the {Black}-{Box}},
	doi = {10.1109/ACCESS.2018.2870052},
	abstract = {At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.},
	journal = {IEEE Access},
	author = {Adadi, Amina and Berrada, Mohammed},
	year = {2018},
	note = {Conference Name: IEEE Access},
	pages = {52138--52160},
	file = {Adadi_Berrada_2018_Peeking Inside the Black-Box.pdf:/Users/orsonxu/Zotero/storage/K44JIPFC/Adadi_Berrada_2018_Peeking Inside the Black-Box.pdf:application/pdf;Adadi_Berrada_2018_Peeking Inside the Black-Box.pdf:/Users/orsonxu/Zotero/storage/MCSS2YU6/Adadi_Berrada_2018_Peeking Inside the Black-Box.pdf:application/pdf},
}

@inproceedings{bansal_does_2021,
	address = {Yokohama Japan},
	title = {Does the {Whole} {Exceed} its {Parts}? {The} {Effect} of {AI} {Explanations} on {Complementary} {Team} {Performance}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {Does the {Whole} {Exceed} its {Parts}?},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445717},
	doi = {10.1145/3411764.3445717},
	language = {en},
	urldate = {2022-06-21},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Bansal, Gagan and Wu, Tongshuang and Zhou, Joyce and Fok, Raymond and Nushi, Besmira and Kamar, Ece and Ribeiro, Marco Tulio and Weld, Daniel},
	month = may,
	year = {2021},
	pages = {1--16},
	file = {Bansal et al. - 2021 - Does the Whole Exceed its Parts The Effect of AI .pdf:/Users/orsonxu/Zotero/storage/2KSFDWD3/Bansal et al. - 2021 - Does the Whole Exceed its Parts The Effect of AI .pdf:application/pdf},
}

@misc{urbansky_comparison_2020,
	title = {Comparison of 7 image classification {APIs} for food pictures},
	url = {https://ddsky.medium.com/comparison-of-7-image-classification-apis-for-food-pictures-1d61b7293285},
	abstract = {This article compares 7 online image recognition services in the context of food recognition. In particular, my goal was to find out which…},
	language = {en},
	urldate = {2022-06-27},
	journal = {Medium},
	author = {Urbansky, David},
	month = apr,
	year = {2020},
	file = {Snapshot:/Users/orsonxu/Zotero/storage/WRJYZ5PX/comparison-of-7-image-classification-apis-for-food-pictures-1d61b7293285.html:text/html},
}

@inproceedings{lim_why_2009,
	address = {Boston MA USA},
	title = {Why and why not explanations improve the intelligibility of context-aware intelligent systems},
	isbn = {978-1-60558-246-7},
	url = {https://dl.acm.org/doi/10.1145/1518701.1519023},
	doi = {10.1145/1518701.1519023},
	abstract = {Context-aware intelligent systems employ implicit inputs, and make decisions based on complex rules and machine learning models that are rarely clear to users. Such lack of system intelligibility can lead to loss of user trust, satisfaction and acceptance of these systems. However, automatically providing explanations about a system‟s decision process can help mitigate this problem. In this paper we present results from a controlled study with over 200 participants in which the effectiveness of different types of explanations was examined. Participants were shown examples of a system‟s operation along with various automatically generated explanations, and then tested on their understanding of the system. We show, for example, that explanations describing why the system behaved a certain way resulted in better understanding and stronger feelings of trust. Explanations describing why the system did not behave a certain way, resulted in lower understanding yet adequate performance. We discuss implications for the use of our findings in real-world context-aware applications.},
	language = {en},
	urldate = {2022-07-11},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Lim, Brian Y. and Dey, Anind K. and Avrahami, Daniel},
	month = apr,
	year = {2009},
	pages = {2119--2128},
	annote = {- RQs and Contributions
Show that providing interpretability (specifically, why and why not the system does it) in the context-aware scenario can help users to better understand and trust the system.

- Methods
211 online user study to study five types of explanation:
1. What: What did the system do?
2. Why: Why did the system do W?
3. Why Not: Why did the system not do X?
4. What If: What would the system do if Y happens?
5. How To: How can I get the system to do Z, given the current context?
The explanation was generated via some simple decision tree algorithms.
Then measure trust etc.
},
	file = {Lim et al. - 2009 - Why and why not explanations improve the in.pdf:/Users/orsonxu/Zotero/storage/HAWPC6QA/Lim et al. - 2009 - Why and why not explanations improve the in.pdf:application/pdf},
}

@article{bunt_are_2012,
	title = {Are explanations always important?: a study of deployed, low-cost intelligent interactive systems},
	abstract = {Intelligent interactive systems (IIS) have great potential to improve users' experience with technology by tailoring their behaviour and appearance to users’ individual needs; however, these systems, with their complex algorithms and dynamic behaviour, can also suffer from a lack of comprehensibility and transparency. We present the results of two studies examining the comprehensibility of, and desire for explanations with deployed, low-cost IIS. The first study, a set of interviews with 21 participants, reveals that i) comprehensibility is not always dependent on explanations, and ii) the perceived cost of viewing explanations tends to outweigh the anticipated benefits. Our second study, a two-week diary study with 14 participants, confirms these findings in the context of daily use, with participants indicating a desire for an explanation in only 7\% of diary entries. We discuss the implications of our findings for the design of explanation facilities.},
	language = {en},
	author = {Bunt, Andrea and Lount, Matthew and Lauzon, Catherine},
	year = {2012},
	pages = {10},
	file = {Bunt et al. - 2012 - Are explanations always important a study of dep.pdf:/Users/orsonxu/Zotero/storage/SUEFGDDA/Bunt et al. - 2012 - Are explanations always important a study of dep.pdf:application/pdf},
}

@article{langer_what_2021,
	title = {What do we want from {Explainable} {Artificial} {Intelligence} ({XAI})? – {A} stakeholder perspective on {XAI} and a conceptual model guiding interdisciplinary {XAI} research},
	volume = {296},
	issn = {00043702},
	shorttitle = {What do we want from {Explainable} {Artificial} {Intelligence} ({XAI})?},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0004370221000242},
	doi = {10.1016/j.artint.2021.103473},
	language = {en},
	urldate = {2022-07-15},
	journal = {Artificial Intelligence},
	author = {Langer, Markus and Oster, Daniel and Speith, Timo and Hermanns, Holger and Kästner, Lena and Schmidt, Eva and Sesing, Andreas and Baum, Kevin},
	month = jul,
	year = {2021},
	pages = {103473},
	file = {Langer et al. - 2021 - What do we want from Explainable Artificial Intell.pdf:/Users/orsonxu/Zotero/storage/8JNPLSLM/Langer et al. - 2021 - What do we want from Explainable Artificial Intell.pdf:application/pdf},
}

@inproceedings{lim_toolkit_2010,
	address = {Copenhagen Denmark},
	title = {Toolkit to support intelligibility in context-aware applications},
	isbn = {978-1-60558-843-8},
	url = {https://dl.acm.org/doi/10.1145/1864349.1864353},
	doi = {10.1145/1864349.1864353},
	abstract = {Context-aware applications should be intelligible so users can better understand how they work and improve their trust in them. However, providing intelligibility is nontrivial and requires the developer to understand how to generate explanations from application decision models. Furthermore, users need different types of explanations and this complicates the implementation of intelligibility. We have developed the Intelligibility Toolkit that makes it easy for application developers to obtain eight types of explanations from the most popular decision models of context-aware applications. We describe its extensible architecture, and the explanation generation algorithms we developed. We validate the usefulness of the toolkit with three canonical applications that use the toolkit to generate explanations for end-users.},
	language = {en},
	urldate = {2022-08-28},
	booktitle = {Proceedings of the 12th {ACM} international conference on {Ubiquitous} computing},
	publisher = {ACM},
	author = {Lim, Brian Y. and Dey, Anind K.},
	month = sep,
	year = {2010},
	pages = {13--22},
	file = {Lim and Dey - 2010 - Toolkit to support intelligibility in context-awar.pdf:/Users/orsonxu/Zotero/storage/CY8QQ6C8/Lim and Dey - 2010 - Toolkit to support intelligibility in context-awar.pdf:application/pdf},
}

@article{ribeiro_anchors_2018,
	title = {Anchors: {High}-{Precision} {Model}-{Agnostic} {Explanations}},
	volume = {32},
	issn = {2374-3468, 2159-5399},
	shorttitle = {Anchors},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/11491},
	doi = {10.1609/aaai.v32i1.11491},
	abstract = {We introduce a novel model-agnostic system that explains the behavior of complex models with high-precision rules called anchors, representing local, “sufﬁcient” conditions for predictions. We propose an algorithm to efﬁciently compute these explanations for any black-box model with high-probability guarantees. We demonstrate the ﬂexibility of anchors by explaining a myriad of different models for different domains and tasks. In a user study, we show that anchors enable users to predict how a model would behave on unseen instances with less effort and higher precision, as compared to existing linear explanations or no explanations.},
	language = {en},
	number = {1},
	urldate = {2022-11-22},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	month = apr,
	year = {2018},
	file = {Ribeiro et al. - 2018 - Anchors High-Precision Model-Agnostic Explanation.pdf:/Users/orsonxu/Zotero/storage/IUCP5G67/Ribeiro et al. - 2018 - Anchors High-Precision Model-Agnostic Explanation.pdf:application/pdf},
}

@inproceedings{mittelstadt_explaining_2019,
	address = {Atlanta GA USA},
	title = {Explaining {Explanations} in {AI}},
	isbn = {978-1-4503-6125-5},
	url = {https://dl.acm.org/doi/10.1145/3287560.3287574},
	doi = {10.1145/3287560.3287574},
	abstract = {Recent work on interpretability in machine learning and AI has focused on the building of simplified models that approximate the true criteria used to make decisions. These models are a useful pedagogical device for teaching trained professionals how to predict what decisions will be made by the complex system, and most importantly how the system might break. However, when considering any such model it’s important to remember Box’s maxim that "All models are wrong but some are useful." We focus on the distinction between these models and explanations in philosophy and sociology. These models can be understood as a "do it yourself kit" for explanations, allowing a practitioner to directly answer "what if questions" or generate contrastive explanations without external assistance. Although a valuable ability, giving these models as explanations appears more difficult than necessary, and other forms of explanation may not have the same trade-offs. We contrast the different schools of thought on what makes an explanation, and suggest that machine learning might benefit from viewing the problem more broadly.},
	language = {en},
	urldate = {2022-11-22},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Mittelstadt, Brent and Russell, Chris and Wachter, Sandra},
	month = jan,
	year = {2019},
	pages = {279--288},
	file = {Mittelstadt et al. - 2019 - Explaining Explanations in AI.pdf:/Users/orsonxu/Zotero/storage/N4PVKJFM/Mittelstadt et al. - 2019 - Explaining Explanations in AI.pdf:application/pdf},
}

@inproceedings{koh_understanding_2017,
	title = {Understanding {Black}-box {Predictions} via {Influence} {Functions}},
	url = {https://proceedings.mlr.press/v70/koh17a.html},
	abstract = {How can we explain the predictions of a black-box model? In this paper, we use influence functions — a classic technique from robust statistics — to trace a model’s prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.},
	language = {en},
	urldate = {2022-11-22},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Koh, Pang Wei and Liang, Percy},
	month = jul,
	year = {2017},
	note = {ISSN: 2640-3498},
	pages = {1885--1894},
	file = {Koh_Liang_2017_Understanding Black-box Predictions via Influence Functions.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Koh_Liang_2017_Understanding Black-box Predictions via Influence Functions.pdf:application/pdf;Supplementary PDF:/Users/orsonxu/Zotero/storage/CAZWQSVG/Koh and Liang - 2017 - Understanding Black-box Predictions via Influence .pdf:application/pdf},
}


@inproceedings{Suhara2017,
	address = {Republic and Canton of Geneva, Switzerland},
	title = {{DeepMood}: {Forecasting} {Depressed} {Mood} {Based} on {Self}-{Reported} {Histories} via {Recurrent} {Neural} {Networks}},
	isbn = {978-1-4503-4913-0},
	url = {http://dx.doi.org/10.1145/3038912.3052676},
	doi = {10.1145/3038912.3052676},
	abstract = {Depression is a prevailing issue and is an increasing problem in many people’s lives. Without observable diagnostic cri- teria, the signs of depression may go unnoticed, resulting in high demand for detecting depression in advance automati- cally. This paper tackles the challenging problem of forecast- ing severely depressed moods based on self-reported histo- ries. Despite the large amount of research on understanding individual moods including depression, anxiety, and stress based on behavioral logs collected by pervasive computing devices such as smartphones, forecasting depressed moods is still an open question. This paper develops a recurrent neu- ral network algorithm that incorporates categorical embed- ding layers for forecasting depression. We collected large- scale records from 2,382 self-declared depressed people to conduct the experiment. Experimental results show that our method forecast the severely depressed mood of a user based on self-reported histories, with higher accuracy than SVM. The results also showed that the long-term historical information of a user improves the accuracy of forecasting depressed mood.},
	booktitle = {Proceedings of the 26th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Suhara, Yoshihiko and Xu, Yinzhan and Pentland, Alex 'Sandy'},
	month = apr,
	year = {2017},
	keywords = {depression, mobile applications, neural networks},
	pages = {715--724},
	file = {Suhara et al_2017_DeepMood.pdf:/Users/orsonxu/Zotero/storage/HYUGTIVF/Suhara et al_2017_DeepMood.pdf:application/pdf;Suhara et al_2017_DeepMood.pdf:/Users/orsonxu/Zotero/storage/6Z6FTUK7/Suhara et al_2017_DeepMood.pdf:application/pdf},
}

@inproceedings{Rahman2020,
	address = {New York, NY, USA},
	title = {Assessing {Severity} of {Pulmonary} {Obstruction} from {Respiration} {Phase}-{Based} {Wheeze}-{Sensing} {Using} {Mobile} {Sensors}},
	isbn = {978-1-4503-6708-0},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376444},
	doi = {10.1145/3313831.3376444},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Chatterjee, Soujanya and Rahman, Md Mahbubur and Ahmed, Tousif and Saleheen, Nazir and Nemati, Ebrahim and Nathan, Viswam and Vatanparvar, Korosh and Kuang, Jilong},
	month = apr,
	year = {2020},
	pages = {1--13},
	file = {Chatterjee et al_2020_Assessing Severity of Pulmonary Obstruction from Respiration Phase-Based Wheeze-Sensing Using Mobile Sensors.pdf:/Users/orsonxu/Zotero/storage/TFFI5FFG/Chatterjee et al_2020_Assessing Severity of Pulmonary Obstruction from Respiration Phase-Based Wheeze-Sensing Using Mobile Sensors.pdf:application/pdf;Chatterjee et al_2020_Assessing Severity of Pulmonary Obstruction from Respiration Phase-Based Wheeze-Sensing Using Mobile Sensors.pdf:/Users/orsonxu/Zotero/storage/BUHLV4P2/Chatterjee et al_2020_Assessing Severity of Pulmonary Obstruction from Respiration Phase-Based Wheeze-Sensing Using Mobile Sensors.pdf:application/pdf},
}

@article{Visuri2019,
	title = {Understanding smartphone notifications’ user interactions and content importance},
	volume = {128},
	issn = {10959300},
	url = {https://doi.org/10.1016/j.ijhcs.2019.03.001},
	doi = {10.1016/j.ijhcs.2019.03.001},
	abstract = {We present the results of our experiment aimed to comprehensively understand the combination of 1) how smartphone users interact with their notifications, 2) what notification content is considered important, 3) the complex relationship between the interaction choices and content importance, and lastly 4) establish an intelligent method to predict user's preference to seeing an incoming notification. We use a dataset of notifications received by 40 anonymous users in-the-wild, which consists of 1) qualitative user-labelled information about their preferences on notification's contents, 2) notification source, and 3) the context in which the notification was received. We assess the effectiveness of personalised prediction models generated using a combination of self-reported content importance and contextual information. We uncover four distinct user types, based on the number of daily notifications and interaction choices. We showcase how usage traits of these groups highlight the requirement for notification filtering approaches, e.g., when specific users habitually neglect to manually filter out unimportant notifications. Our machine learning-based predictor, based on both contextual sensing and notification contents can predict the user's preference for successfully acknowledging an incoming notification with 91.1\% mean accuracy, crucial for time-critical user engagement and interventions.},
	number = {March},
	journal = {International Journal of Human Computer Studies},
	author = {Visuri, Aku and van Berkel, Niels and Okoshi, Tadashi and Goncalves, Jorge and Kostakos, Vassilis},
	year = {2019},
	note = {Publisher: Elsevier Ltd},
	keywords = {Interactions, Machine learning, Notifications, Semantic analysis, Smartphone},
	pages = {72--85},
	file = {Visuri et al_2019_Understanding smartphone notifications’ user interactions and content importance.pdf:/Users/orsonxu/Zotero/storage/BTDJGVF7/Visuri et al_2019_Understanding smartphone notifications’ user interactions and content importance.pdf:application/pdf;Visuri et al_2019_Understanding smartphone notifications’ user interactions and content importance.pdf:/Users/orsonxu/Zotero/storage/6EQRGRJ8/Visuri et al_2019_Understanding smartphone notifications’ user interactions and content importance.pdf:application/pdf},
}

@article{Lu2012,
	title = {{StressSense}: {Detecting} stress in unconstrained acoustic environments using smartphones},
	doi = {10.1145/2370216.2370270},
	abstract = {Stress can have long term adverse effects on individuals' physical and mental well-being. Changes in the speech production process is one of many physiological changes that happen during stress. Microphones, embedded in mobile phones and carried ubiquitously by people, provide the opportunity to continuously and non-invasively monitor stress in real-life situations. We propose StressSense for unobtrusively recognizing stress from human voice using smartphones. We investigate methods for adapting a one-size-fitsall stress model to individual speakers and scenarios. We demonstrate that the StressSense classifier can robustly identify stress across multiple individuals in diverse acoustic environments: using model adaptation StressSense achieves 81\% and 76\% accuracy for indoor and outdoor environments, respectively. We show that StressSense can be implemented on commodity Android phones and run in real-time. To the best of our knowledge, StressSense represents the first system to consider voice based stress detection and model adaptation in diverse real-life conversational situations using smartphones. Copyright 2012 ACM.},
	journal = {Proceedings of the ACM International Ubiquitous Computing},
	author = {Lu, Hong and Rabbi, Mashfiqui and Chittaranjan, Gokul T. and Frauendorfer, Denise and Mast, Marianne Schmid and Campbell, Andrew T. and Gatica-Perez, Daniel and Choudhury, Tanzeem},
	year = {2012},
	note = {ISBN: 9781450312240},
	keywords = {Stress, Mhealth, Model adaptation, Sensing, User modeling},
	pages = {351--360},
	file = {Lu et al_2012_StressSense.pdf:/Users/orsonxu/Zotero/storage/46J5T64S/Lu et al_2012_StressSense.pdf:application/pdf;Lu et al_2012_StressSense.pdf:/Users/orsonxu/Zotero/storage/CQHKF9EK/Lu et al_2012_StressSense.pdf:application/pdf},
}

@article{Madan2010b,
	title = {Social sensing for epidemiological behavior change},
	doi = {10.1145/1864349.1864394},
	abstract = {An important question in behavioral epidemiology and public health is to understand how individual behavior is affected by illness and stress. Although changes in individual behavior are intertwined with contagion, epidemiologists today do not have sensing or modeling tools to quantitatively measure its effects in real-world conditions. In this paper, we propose a novel application of ubiquitous computing. We use mobile phone based co-location and communication sensing to measure characteristic behavior changes in symptomatic individuals, reflected in their total communication, interactions with respect to time of day (e.g., late night, early morning), diversity and entropy of face-to-face interactions and movement. Using these extracted mobile features, it is possible to predict the health status of an individual, without having actual health measurements from the subject. Finally, we estimate the temporal information flux and implied causality between physical symptoms, behavior and mental health. © 2010 ACM.},
	journal = {Proceedings of the ACM Conference on Ubiquitous Computing},
	author = {Madan, Anmol and Cebrian, Manuel and Lazer, David and Pentland, Alex},
	year = {2010},
	note = {ISBN: 9781605588384},
	keywords = {mobile sensing, social computing, spatial epidemiology},
	pages = {291--300},
	file = {Madan et al_2010_Social sensing for epidemiological behavior change.pdf:/Users/orsonxu/Zotero/storage/32WU4GUC/Madan et al_2010_Social sensing for epidemiological behavior change.pdf:application/pdf;Madan et al_2010_Social sensing for epidemiological behavior change.pdf:/Users/orsonxu/Zotero/storage/745PLBR5/Madan et al_2010_Social sensing for epidemiological behavior change.pdf:application/pdf},
}

@article{Rabbi2015,
	title = {{MyBehavior}: {Automatic} {Personalized} {Health} {Feedback} from {User} {Behaviors} and {Preferences} using {Smartphones}},
	doi = {10.1145/2750858.2805840},
	abstract = {Mobile sensing systems have made significant advances in tracking human behavior. However, the development of personalized mobile health feedback systems is still in its infancy. This paper introduces MyBehavior, a smartphone application that takes a novel approach to generate deeply personalized health feedback. It combines state-of-the-art behavior tracking with algorithms that are used in recommendation systems. MyBehavior automatically learns a user's physical activity and dietary behavior and strategically suggests changes to those behaviors for a healthier lifestyle. The system uses a sequential decision making algorithm, Multi-armed Bandit, to generate suggestions that maximize calorie loss and are easy for the user to adopt. In addition, the system takes into account user's preferences to encourage adoption using the pareto-frontier algorithm. In a 14-week study, results show statistically significant increases in physical activity and decreases in food calorie when using MyBehavior compared to a control condition.{\textbackslash}r{\textbackslash}n},
	number = {September},
	journal = {Proceedings of the ACM International Joint Conference on Pervasive and Ubiquitous Computing},
	author = {Rabbi, Mashfiqui and Aung, Min Hane and Zhang, Mi and Choudhury, Tanzeem},
	year = {2015},
	note = {ISBN: 9781450317702},
	keywords = {archival format, proceedings, SIGCHI},
	pages = {707--718},
	file = {Rabbi et al_2015_MyBehavior.pdf:/Users/orsonxu/Zotero/storage/SQ8EWKTA/Rabbi et al_2015_MyBehavior.pdf:application/pdf;Rabbi et al_2015_MyBehavior.pdf:/Users/orsonxu/Zotero/storage/9VX6IEAH/Rabbi et al_2015_MyBehavior.pdf:application/pdf},
}

@article{Chen2018a,
	title = {{SPHA}: {Smart} {Personal} {Health} {Advisor} {Based} on {Deep} {Analytics}},
	volume = {56},
	issn = {01636804},
	doi = {10.1109/MCOM.2018.1700274},
	abstract = {© 2018 IEEE. According to a report by the World Health Organization, diseases caused by an unhealthy lifestyle represent the leading cause of death all over the world. Therefore, it is crucial to monitor and avoid users' unhealthy behaviors. Existing health monitoring approaches still face many challenges of limited intelligence due to insufficient healthcare data. Therefore, this article proposes a smart personal health advisor (SPHA) for comprehensive and intelligent health monitoring and guidance. The SPHA monitors both physiological and psychological states of the user. The SPHAScore model is proposed to evaluate the overall health status of the user. Finally, a testbed for verification of feasibility and applicability of the proposed system was developed. The experimental and simulation results have shown that the proposed approach is efficient for proper user state monitoring.},
	number = {3},
	journal = {IEEE Communications Magazine},
	author = {Chen, Min and Zhang, Yin and Qiu, Meikang and Guizani, Nadra and Hao, Yixue},
	year = {2018},
	note = {Publisher: IEEE},
	pages = {164--169},
	file = {Chen et al_2018_SPHA.pdf:/Users/orsonxu/Zotero/storage/YEIDJQEB/Chen et al_2018_SPHA.pdf:application/pdf;Chen et al_2018_SPHA.pdf:/Users/orsonxu/Zotero/storage/D378UFJN/Chen et al_2018_SPHA.pdf:application/pdf},
}

@article{Sun2017,
	title = {{SleepMonitor}: {Monitoring} {Respiratory} {Rate} and {Body} {Position} {During} {Sleep} {Using} {Smartwatch}},
	volume = {1},
	doi = {10.1145/3130969},
	number = {3},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Sun, Xiao and Qiu, Li and Wu, Yibo and Tang, Yeming and Cao, Guohong},
	year = {2017},
	keywords = {- Human-centered computing  -{\textgreater} Ubiquitous and mobi, Mobile devices},
	pages = {1--22},
	file = {Sun et al_2017_SleepMonitor.pdf:/Users/orsonxu/Zotero/storage/XCCELHU3/Sun et al_2017_SleepMonitor.pdf:application/pdf;Sun et al_2017_SleepMonitor.pdf:/Users/orsonxu/Zotero/storage/TGDS7Q64/Sun et al_2017_SleepMonitor.pdf:application/pdf},
}

@article{Madan2012,
	title = {Sensing the {Health} {State} of a {Community}},
	volume = {11},
	issn = {1536-1268},
	doi = {10.1109/MPRV.2011.79},
	abstract = {Mobile phones are a pervasive platform for opportunistic sensing of behaviors and opinions. We show that location and communication sensors can be used to model individual symptoms, long- term health outcomes, and diffusion of opinions in a community. For individuals, phone-based features can be used to predict changes in health, such as common colds, influenza, and stress, and automatically identify symptomatic days. For longer-term health outcomes such as obesity, we find that weight changes of participants are correlated with exposure to peers who gained weight in the same period, which is in direct contrast to currently accepted theories of social contagion. Finally, as a proxy for understanding health education we examine change in political opinions during the 2008 US presidential election campaign. We discover dynamic patterns of homophily and use topic models (Latent Dirchlet Allocation) to understand the link between specific behaviors and changes in political opinions.},
	number = {4},
	journal = {IEEE Pervasive Computing},
	author = {Madan, A. and Cebrian, M. and Moturu, S. and Farrahi, K. and Pentland, A.},
	year = {2012},
	note = {ISBN: 1536-1268 VO - 11},
	pages = {36--45},
	file = {Madan et al_2012_Sensing the Health State of a Community.pdf:/Users/orsonxu/Zotero/storage/5KRTV2B8/Madan et al_2012_Sensing the Health State of a Community.pdf:application/pdf;Madan et al_2012_Sensing the Health State of a Community.pdf:/Users/orsonxu/Zotero/storage/II8HSWHP/Madan et al_2012_Sensing the Health State of a Community.pdf:application/pdf},
}

@article{Doryab2019,
	title = {Modeling {Biobehavioral} {Rhythms} with {Passive} {Sensing} in the {Wild} : {A} {Case} {Study} to {Predict} {Readmission} {Risk} after {Pancreatic} {Surgery}},
	volume = {3},
	number = {1},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Doryab, Afsaneh and Dey, Anind K and Kao, Grace and Low, Carissa},
	year = {2019},
	keywords = {Cancer, Circadian Rhythm, Data Processing, Feature Extraction, Machine Learning, Mobile and Wearable Sensing, Patient Readmission},
	pages = {1--21},
	file = {Doryab et al_2019_Modeling Biobehavioral Rhythms with Passive Sensing in the Wild.pdf:/Users/orsonxu/Zotero/storage/RHTEDRLD/Doryab et al_2019_Modeling Biobehavioral Rhythms with Passive Sensing in the Wild.pdf:application/pdf;Doryab et al_2019_Modeling Biobehavioral Rhythms with Passive Sensing in the Wild.pdf:/Users/orsonxu/Zotero/storage/KENB3ABT/Doryab et al_2019_Modeling Biobehavioral Rhythms with Passive Sensing in the Wild.pdf:application/pdf},
}

@inproceedings{Wang2014,
	address = {New York, NY, USA},
	title = {{StudentLife}: {Assessing} {Mental} {Health}, {Academic} {Performance} and {Behavioral} {Trends} of {College} {Students} using {Smartphones}},
	isbn = {978-1-4503-2968-2},
	url = {https://dl.acm.org/doi/10.1145/2632048.2632054},
	doi = {10.1145/2632048.2632054},
	booktitle = {Proceedings of the 2014 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Wang, Rui and Chen, Fanglin and Chen, Zhenyu and Li, Tianxing and Harari, Gabriella and Tignor, Stefanie and Zhou, Xia and Ben-Zeev, Dror and Campbell, Andrew T.},
	month = sep,
	year = {2014},
	pages = {3--14},
	file = {Wang et al_2014_StudentLife.pdf:/Users/orsonxu/Zotero/storage/B7S2RQT3/Wang et al_2014_StudentLife.pdf:application/pdf;Wang et al_2014_StudentLife.pdf:/Users/orsonxu/Zotero/storage/4USESX99/Wang et al_2014_StudentLife.pdf:application/pdf},
}

@article{Wald2012,
	title = {Machine prediction of personality from {Facebook} profiles},
	volume = {2},
	doi = {10.1109/IRI.2012.6302998},
	abstract = {An increasing number of Americans use social networking sites such as Facebook, but few fully appreciate the amount of information they share with the world as a result. Although studies exist on the sharing of specific types of information (photos, posts, etc.), one area that has been less explored is how Facebook profiles can share personality information in a broad, machine-readable fashion. In this study, we apply data-mining and machine learning techniques to predict users' personality traits (specifically, the traits of the Big Five personality model) using only demographic and text-based attributes extracted from their profiles. We then use these predictions to rank individuals in terms of the five traits, predicting which users will appear in the top or bottom 5\% or 10\% of these traits. Our results show that when using certain models, we can find the top 10\% most Open individuals with nearly 75\% accuracy, and across all traits and directions, we can predict the top 10\% with at least 34.5\% accuracy (exceeding 21.8\%, which is the best accuracy when using just the best-performing profile attribute). These results have privacy implications in terms of allowing advertisers and other groups to focus on a specific subset of individuals based on their personality traits. © 2012 IEEE.},
	journal = {Proceedings of the IEEE International Conference on Information Reuse and Integration},
	author = {Wald, Randall and Khoshgoftaar, Taghi and Sumner, Chris},
	year = {2012},
	note = {ISBN: 9781467322843},
	keywords = {Big Five, data mining, Facebook, personality prediction, privacy},
	pages = {109--115},
	file = {Wald et al_2012_Machine prediction of personality from Facebook profiles.pdf:/Users/orsonxu/Zotero/storage/NFD92KQU/Wald et al_2012_Machine prediction of personality from Facebook profiles.pdf:application/pdf;Wald et al_2012_Machine prediction of personality from Facebook profiles.pdf:/Users/orsonxu/Zotero/storage/VQ86675L/Wald et al_2012_Machine prediction of personality from Facebook profiles.pdf:application/pdf},
}

@article{Nobles2018,
	title = {Identification of {Imminent} {Suicide} {Risk} {Among} {Young} {Adults} using {Text} {Messages}},
	doi = {10.1145/3173574.3173987},
	abstract = {© 2018 ACM. Suicide is the second leading cause of death among young adults but the challenges of preventing suicide are significant because the signs often seem invisible. Research has shown that clinicians are not able to reliably predict when someone is at greatest risk. In this paper, we describe the design, collection, and analysis of text messages from individuals with a history of suicidal thoughts and behaviors to build a model to identify periods of suicidality (i.e., suicidal ideation and non-fatal suicide attempts). By reconstructing the timeline of recent suicidal behaviors through a retrospective clinical interview, this study utilizes a prospective research design to understand if text communications can predict periods of suicidality versus depression. Identifying subtle clues in communication indicating when someone is at heightened risk of a suicide attempt may allow for more effective prevention of suicide.},
	journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	author = {Nobles, Alicia L. and Glenn, Jeffrey J. and Kowsari, Kamran and Teachman, Bethany A. and Barnes, Laura E.},
	year = {2018},
	note = {ISBN: 9781450356206},
	pages = {1--11},
	file = {Nobles et al_2018_Identification of Imminent Suicide Risk Among Young Adults using Text Messages.pdf:/Users/orsonxu/Zotero/storage/RUFWFJK5/Nobles et al_2018_Identification of Imminent Suicide Risk Among Young Adults using Text Messages.pdf:application/pdf;Nobles et al_2018_Identification of Imminent Suicide Risk Among Young Adults using Text Messages.pdf:/Users/orsonxu/Zotero/storage/J3X9F7LN/Nobles et al_2018_Identification of Imminent Suicide Risk Among Young Adults using Text Messages.pdf:application/pdf},
}

@article{Grunerbl2014,
	title = {Smartphone {Based} {Recognition} of {States} and {State} {Changes} in {Bipolar} {Disorder} {Patients}},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Grunerbl, Agnes and Muaremi, Amir and Osmani, Venet and Bahle, Gernot and Ohler, Stefan and Tr, Gerhard and Mayora, Oscar and Haring, Christian and Lukowicz, Paul},
	year = {2014},
	keywords = {Smartphone Based Recognition of States and State C},
	pages = {1--8},
	file = {Grunerbl et al_2014_Smartphone Based Recognition of States and State Changes in Bipolar Disorder Patients.pdf:/Users/orsonxu/Zotero/storage/RQ7VR57E/Grunerbl et al_2014_Smartphone Based Recognition of States and State Changes in Bipolar Disorder Patients.pdf:application/pdf;Grunerbl et al_2014_Smartphone Based Recognition of States and State Changes in Bipolar Disorder Patients.pdf:/Users/orsonxu/Zotero/storage/BNGT3QXL/Grunerbl et al_2014_Smartphone Based Recognition of States and State Changes in Bipolar Disorder Patients.pdf:application/pdf},
}

@article{Wang2016,
	title = {{CrossCheck}: {Toward} passive sensing and detection of mental health changes in people with schizophrenia},
	doi = {10.1145/2971648.2971740},
	abstract = {© 2016 ACM.Early detection of mental health changes in individuals with serious mental illness is critical for effective intervention. CrossCheck is the first step towards the passive monitoring of mental health indicators in patients with schizophrenia and paves the way towards relapse prediction and early intervention. In this paper, we present initial results from an ongoing randomized control trial, where passive smartphone sensor data is collected from 21 outpatients with schizophrenia recently discharged from hospital over a period ranging from 2-8.5 months. Our results indicate that there are statistically significant associations between automatically tracked behavioral features related to sleep, mobility, conversations, smartphone usage and self-reported indicators of mental health in schizophrenia. Using these features we build inference models capable of accurately predicting aggregated scores of mental health indicators in schizophrenia with a mean error of 7.6\% of the score range. Finally, we discuss results on the level of personalization that is needed to account for the known variations within people. We show that by leveraging knowledge from a population with schizophrenia, it is possible to train accurate personalized models that require fewer individual-specific data to quickly adapt to new users.},
	journal = {Proceedings of the ACM International Joint Conference on Pervasive and Ubiquitous Computing},
	author = {Wang, Rui and Aung, Min S. H. and Abdullah, Saeed and Brian, Rachel and Campbell, Andrew T. and Choudhury, Tanzeem and Hauser, Marta and Kane, John and Merrill, Michael and Scherer, Emily A. and Tseng, Vincent W. S. and Ben-Zeev, Dror},
	year = {2016},
	note = {ISBN: 9781450344616},
	pages = {886--897},
	file = {Wang et al_2016_CrossCheck.pdf:/Users/orsonxu/Zotero/storage/KUB9E8KN/Wang et al_2016_CrossCheck.pdf:application/pdf;Wang et al_2016_CrossCheck.pdf:/Users/orsonxu/Zotero/storage/I6HGJ393/Wang et al_2016_CrossCheck.pdf:application/pdf},
}

@article{Gong2019a,
	title = {Understanding behavioral dynamics of social anxiety among college students through smartphone sensors},
	volume = {49},
	issn = {15662535},
	url = {https://doi.org/10.1016/j.inffus.2018.09.002},
	doi = {10.1016/j.inffus.2018.09.002},
	abstract = {The way people use smartphones provides a window into the relationship between behaviors and mental health. This relationship is of particular significance to individuals with elevated social anxiety, as it helps to reveal when and where their stress increases in relation to social interactions, ultimately leading to more precise treatment delivery and interventions. In this collaboration between engineers and psychologists, we present the first study to use smartphone sensors to examine socially anxious individuals’ fine-grained behaviors around periods in which they engage in some form of social interaction, and how these behaviors differ as a function of location (e.g., at home, at work, or at an unfamiliar location). In a two-week study of 52 college students, we show that there is a significant difference in behaviors for individuals based on social anxiety levels and locations, in that individuals higher (vs. lower) in social anxiety symptoms exhibit more movement (as tracked by the accelerometer) around the time of phone calls, especially in an unfamiliar location (i.e., not home or at work). Finally, we discuss the implications of these findings for developing better interventions for socially anxious individuals.},
	number = {September 2018},
	journal = {Information Fusion},
	author = {Gong, Jiaqi and Huang, Yu and Chow, Philip I. and Fua, Karl and Gerber, Matthew S. and Teachman, Bethany A. and Barnes, Laura E.},
	year = {2019},
	note = {Publisher: Elsevier B.V.},
	keywords = {Behavioral dynamics, Sensor fusion, Smartphone use, Social anxiety},
	pages = {57--68},
	file = {Gong et al_2019_Understanding behavioral dynamics of social anxiety among college students through smartphone sensors.pdf:/Users/orsonxu/Zotero/storage/MMBBBTYA/Gong et al_2019_Understanding behavioral dynamics of social anxiety among college students through smartphone sensors.pdf:application/pdf;Gong et al_2019_Understanding behavioral dynamics of social anxiety among college students through smartphone sensors.pdf:/Users/orsonxu/Zotero/storage/8NBKPPKY/Gong et al_2019_Understanding behavioral dynamics of social anxiety among college students through smartphone sensors.pdf:application/pdf},
}

@article{Wang2017,
	title = {Predicting {Symptom} {Trajectories} of {Schizophrenia} {Using} {Mobile} {Sensing}},
	volume = {22},
	issn = {23750529},
	doi = {10.1145/3276145.3276157},
	abstract = {Continuously monitoring schizophrenia patients' psychiatric symptoms is crucial for in-time intervention and treatment adjustment. The Brief Psychiatric Rating Scale (BPRS) is a survey administered by clinicians to evaluate symptom severity in schizophrenia. The CrossCheck symptom prediction system is capable of tracking schizophrenia symptoms based on BPRS using passive sensing from mobile phones. We present results from an ongoing randomized control trial, where passive sensing data, self-reports, and clinician administered 7-item BPRS surveys are collected from 36 outpatients with schizophrenia recently discharged from hospital over a period ranging from 2-12 months. We show that our system can predict a symptom scale score based on a 7-item BPRS within ±1.45 error on average using automatically tracked behavioral features from phones (e.g., mobility, conversation, activity, smartphone usage, the ambient acoustic environment) and user supplied self-reports. Importantly, we show our system is also capable of predicting an individual BPRS score within ±1.59 error purely based on passive sensing from phones without any self-reported information from outpatients. Finally, we discuss how well our predictive system reflects symptoms experienced by patients by reviewing a number of case studies.},
	number = {2},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Wang, Rui and Scherer, Emily A. and Walsh, Megan and Wang, Weichen and Aung, Min Hane and Ben-Zeev, Dror and Brian, Rachel and Campbell, Andrew T. and Choudhury, Tanzeem and Hauser, Marta and Kane, John},
	year = {2017},
	keywords = {•Applied computing  Life and medical sciences, •Human-centered computing  Ubiquitous and mobile c},
	pages = {32--37},
	file = {Wang et al_2017_Predicting Symptom Trajectories of Schizophrenia Using Mobile Sensing.pdf:/Users/orsonxu/Zotero/storage/EPHRFIH3/Wang et al_2017_Predicting Symptom Trajectories of Schizophrenia Using Mobile Sensing.pdf:application/pdf;Wang et al_2017_Predicting Symptom Trajectories of Schizophrenia Using Mobile Sensing.pdf:/Users/orsonxu/Zotero/storage/AJHFV894/Wang et al_2017_Predicting Symptom Trajectories of Schizophrenia Using Mobile Sensing.pdf:application/pdf},
}

@article{Wahle2017,
	title = {Toward the {Design} of {Evidence}-{Based} {Mental} {Health} {Information} {Systems} for {People} {With} {Depression}: {A} {Systematic} {Literature} {Review} and {Meta}-{Analysis}},
	volume = {19},
	issn = {14388871},
	doi = {10.2196/jmir.7381},
	abstract = {Background: Existing research postulates a variety of components that show an impact on utilization of technology-mediated mental health information systems (MHIS) and treatment outcome. Although researchers assessed the effect of isolated design elements on the results of Web-based interventions and the associations between symptom reduction and use of components across computer and mobile phone platforms, there remains uncertainty with regard to which components of technology-mediated interventions for mental health exert the greatest therapeutic gain. Until now, no studies have presented results on the therapeutic benefit associated with specific service components of technology-mediated MHIS for depression. Objective: This systematic review aims at identifying components of technology-mediated MHIS for patients with depression. Consequently, all randomized controlled trials comparing technology-mediated treatments for depression to either waiting-list control, treatment as usual, or any other form of treatment for depression were reviewed. Updating prior reviews, this study aims to (1) assess the effectiveness of technology-supported interventions for the treatment of depression and (2) add to the debate on what components in technology-mediated MHIS for the treatment of depression should be standard of care. Methods: Systematic searches in MEDLINE, PsycINFO, and the Cochrane Library were conducted. Effect sizes for each comparison between a technology-enabled intervention and a control condition were computed using the standard mean difference (SMD). Chi-square tests were used to test for heterogeneity. Using subgroup analysis, potential sources of heterogeneity were analyzed. Publication bias was examined using visual inspection of funnel plots and Begg’s test. Qualitative data analysis was also used. In an explorative approach, a list of relevant components was extracted from the body of literature by consensus between two researchers. Results: Of 6387 studies initially identified, 45 met all inclusion criteria. Programs analyzed showed a significant trend toward reduced depressive symptoms (SMD –0.58, 95\% CI –0.71 to –0.45, P{\textless}.001). Heterogeneity was large (I2≥76). A total of 15 components were identified. Conclusions: Technology-mediated MHIS for the treatment of depression has a consistent positive overall effect compared to controls. A total of 15 components have been identified. Further studies are needed to quantify the impact of individual components on treatment effects and to identify further components that are relevant for the design of future technology-mediated interventions for the treatment of depression and other mental disorders. [J Med Internet Res 2017;19(5):e191]},
	number = {5},
	journal = {Journal of medical Internet research},
	author = {Wahle, Fabian and Bollhalder, Lea and Kowatsch, Tobias and Fleisch, Elgar},
	year = {2017},
	pmid = {28566267},
	note = {ISBN: 1438-8871},
	keywords = {depression, design feature, information systems, literature review, mental health},
	pages = {e191},
	file = {Wahle et al_2017_Toward the Design of Evidence-Based Mental Health Information Systems for People With Depression.pdf:/Users/orsonxu/Zotero/storage/HQSHQZ3F/Wahle et al_2017_Toward the Design of Evidence-Based Mental Health Information Systems for People With Depression.pdf:application/pdf;Wahle et al_2017_Toward the Design of Evidence-Based Mental Health Information Systems for People With Depression.pdf:/Users/orsonxu/Zotero/storage/9255WS9W/Wahle et al_2017_Toward the Design of Evidence-Based Mental Health Information Systems for People With Depression.pdf:application/pdf},
}

@article{Chow2017,
	title = {Using mobile sensing to test clinical models of depression, social anxiety, state affect, and social isolation among college students},
	volume = {19},
	issn = {14388871},
	doi = {10.2196/jmir.6820},
	abstract = {Background: Research in psychology demonstrates a strong link between state affect (moment-to-moment experiences of positive or negative emotionality) and trait affect (eg, relatively enduring depression and social anxiety symptoms), and a tendency to withdraw (eg, spending time at home). However, existing work is based almost exclusively on static, self-reported descriptions of emotions and behavior that limit generalizability. Despite adoption of increasingly sophisticated research designs and technology (eg, mobile sensing using a global positioning system [GPS]), little research has integrated these seemingly disparate forms of data to improve understanding of how emotional experiences in everyday life are associated with time spent at home, and whether this is influenced by depression or social anxiety symptoms. Objective: We hypothesized that more time spent at home would be associated with more negative and less positive affect. Methods: We recruited 72 undergraduate participants from a southeast university in the United States. We assessed depression and social anxiety symptoms using self-report instruments at baseline. An app (Sensus) installed on participants' personal mobile phones repeatedly collected in situ self-reported state affect and GPS location data for up to 2 weeks. Time spent at home was a proxy for social isolation. Results: We tested separate models examining the relations between state affect and time spent at home, with levels of depression and social anxiety as moderators. Models differed only in the temporal links examined. One model focused on associations between changes in affect and time spent at home within short, 4-hour time windows. The other 3 models focused on associations between mean-level affect within a day and time spent at home (1) the same day, (2) the following day, and (3) the previous day. Overall, we obtained many of the expected main effects (although there were some null effects), in which higher social anxiety was associated with more time or greater likelihood of spending time at home, and more negative or less positive affect was linked to longer homestay. Interactions indicated that, among individuals higher in social anxiety, higher negative affect and lower positive affect within a day was associated with greater likelihood of spending time at home the following day. Conclusions: Results demonstrate the feasibility and utility of modeling the relationship between affect and homestay using fine-grained GPS data. Although these findings must be replicated in a larger study and with clinical samples, they suggest that integrating repeated state affect assessments in situ with continuous GPS data can increase understanding of how actual homestay is related to affect in everyday life and to symptoms of anxiety and depression.},
	number = {3},
	journal = {Journal of Medical Internet Research},
	author = {Chow, Philip I. and Fua, Karl and Huang, Yu and Bonelli, Wesley and Xiong, Haoyi and Barnes, Laura E. and Teachman, Bethany A.},
	year = {2017},
	keywords = {Social anxiety, Affect, Depression, Homestay, Mental health, MHealth, Mobile health},
	pages = {1--12},
	file = {Chow et al_2017_Using mobile sensing to test clinical models of depression, social anxiety, state affect, and social isolation among college students.pdf:/Users/orsonxu/Zotero/storage/LAYC5EPS/Chow et al_2017_Using mobile sensing to test clinical models of depression, social anxiety, state affect, and social isolation among college students.pdf:application/pdf;Chow et al_2017_Using mobile sensing to test clinical models of depression, social anxiety, state affect, and social isolation among college students.pdf:/Users/orsonxu/Zotero/storage/83FMJ53A/Chow et al_2017_Using mobile sensing to test clinical models of depression, social anxiety, state affect, and social isolation among college students.pdf:application/pdf},
}

@article{Salekin2018a,
	title = {A {Weakly} {Supervised} {Learning} {Framework} {For} {Detecting} {Social} {Anxiety} {And} {Depression}},
	volume = {2},
	abstract = {Although social anxiety and depression are common, they are often underdiagnosed and undertreated, in part due to difficulties identifying and accessing individuals in need of services. Current assessments rely on client self-report and clinician judgment, which are vulnerable to social desirability and other subjective biases. Identifying objective, nonburdensome markers of these mental health problems, such as features of speech, could help advance assessment, prevention, and treatment approaches. Prior research examining speech detection methods has focused on fully supervised learning approaches employing strongly labeled data. However, strong labeling of individuals high in symptoms or state affect in speech audio data is impractical, in part because it is not possible to identify with high confidence which regions of a long speech indicate the person's symptoms or affective state. We propose a weakly supervised learning framework for detecting social anxiety and depression from long audio clips. Specifically, we present a novel feature modeling technique named NN2Vec that identifies and exploits the inherent relationship between speakers' vocal states and symptoms/affective states. Detecting speakers high in social anxiety or depression symptoms using NN2Vec features achieves F-1 scores 17\% and 13\% higher than those of the best available baselines. In addition, we present a new multiple instance learning adaptation of a BLSTM classifier, named BLSTM-MIL. Our novel framework of using NN2Vec features with the BLSTM-MIL classifier achieves F-1 scores of 90.1\% and 85.44\% in detecting speakers high in social anxiety and depression symptoms.},
	number = {2},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Salekin, Asif and Eberle, Jeremy W and Glenn, Jeffrey J and Teachman, Bethany A and Stankovic, John A},
	year = {2018},
	keywords = {depression, Social anxiety, anxiety, audio word embedding, feature modeling, mental disorder, multiple instance learning, speech, weakly labeled, weakly supervised learning},
	pages = {26},
	file = {Salekin et al_2018_A Weakly Supervised Learning Framework For Detecting Social Anxiety And Depression.pdf:/Users/orsonxu/Zotero/storage/LE78Y9YE/Salekin et al_2018_A Weakly Supervised Learning Framework For Detecting Social Anxiety And Depression.pdf:application/pdf;Salekin et al_2018_A Weakly Supervised Learning Framework For Detecting Social Anxiety And Depression.pdf:/Users/orsonxu/Zotero/storage/4RJBJXD5/Salekin et al_2018_A Weakly Supervised Learning Framework For Detecting Social Anxiety And Depression.pdf:application/pdf},
}

@article{Doryab2019a,
	title = {Identifying behavioral phenotypes of loneliness and social isolation with passive sensing: {Statistical} analysis, data mining and machine learning of smartphone and fitbit data},
	volume = {7},
	issn = {22915222},
	doi = {10.2196/13209},
	abstract = {Background: Feelings of loneliness are associated with poor physical and mental health. Detection of loneliness through passive sensing on personal devices can lead to the development of interventions aimed at decreasing rates of loneliness. Objective: The aim of this study was to explore the potential of using passive sensing to infer levels of loneliness and to identify the corresponding behavioral patterns. Methods: Data were collected from smartphones and Fitbits (Flex 2) of 160 college students over a semester. The participants completed the University of California, Los Angeles (UCLA) loneliness questionnaire at the beginning and end of the semester. For a classification purpose, the scores were categorized into high (questionnaire score{\textgreater}40) and low (≤40) levels of loneliness. Daily features were extracted from both devices to capture activity and mobility, communication and phone usage, and sleep behaviors. The features were then averaged to generate semester-level features. We used 3 analytic methods: (1) statistical analysis to provide an overview of loneliness in college students, (2) data mining using the Apriori algorithm to extract behavior patterns associated with loneliness, and (3) machine learning classification to infer the level of loneliness and the change in levels of loneliness using an ensemble of gradient boosting and logistic regression algorithms with feature selection in a leave-one-student-out cross-validation manner. Results: The average loneliness score from the presurveys and postsurveys was above 43 (presurvey SD 9.4 and postsurvey SD 10.4), and the majority of participants fell into the high loneliness category (scores above 40) with 63.8\% (102/160) in the presurvey and 58.8\% (94/160) in the postsurvey. Scores greater than 1 standard deviation above the mean were observed in 12.5\% (20/160) of the participants in both pre- and postsurvey scores. The majority of scores, however, fell between 1 standard deviation below and above the mean (pre=66.9\% [107/160] and post=73.1\% [117/160]). Our machine learning pipeline achieved an accuracy of 80.2\% in detecting the binary level of loneliness and an 88.4\% accuracy in detecting change in the loneliness level. The mining of associations between classifier-selected behavioral features and loneliness indicated that compared with students with low loneliness, students with high levels of loneliness were spending less time outside of campus during evening hours on weekends and spending less time in places for social events in the evening on weekdays (support=17\% and confidence=92\%). The analysis also indicated that more activity and less sedentary behavior, especially in the evening, was associated with a decrease in levels of loneliness from the beginning of the semester to the end of it (support=31\% and confidence=92\%). Conclusions: Passive sensing has the potential for detecting loneliness in college students and identifying the associated behavioral patterns. These findings highlight intervention opportunities through mobile technology to reduce the impact of loneliness on individuals’ health and well-being.},
	number = {7},
	journal = {JMIR mHealth and uHealth},
	author = {Doryab, Afsaneh and Villalba, Daniella K. and Chikersal, Prerna and Dutcher, Janine M. and Tumminia, Michael and Liu, Xinwen and Cohen, Sheldon and Creswell, Kasey and Mankoff, Jennifer and Creswell, John D. and Dey, Anind K.},
	year = {2019},
	keywords = {Machine learning, Mobile health, Data mining, Digital phenotyping, Loneliness, Statistical data analysis},
	pages = {1--19},
	file = {Doryab et al_2019_Identifying behavioral phenotypes of loneliness and social isolation with passive sensing.pdf:/Users/orsonxu/Zotero/storage/F5E4QH6D/Doryab et al_2019_Identifying behavioral phenotypes of loneliness and social isolation with passive sensing.pdf:application/pdf;Doryab et al_2019_Identifying behavioral phenotypes of loneliness and social isolation with passive sensing.pdf:/Users/orsonxu/Zotero/storage/F4XP6EFP/Doryab et al_2019_Identifying behavioral phenotypes of loneliness and social isolation with passive sensing.pdf:application/pdf},
}

@article{Onnela2016,
	title = {Harnessing {Smartphone}-{Based} {Digital} {Phenotyping} to {Enhance} {Behavioral} and {Mental} {Health}},
	volume = {41},
	issn = {1740634X},
	doi = {10.1038/npp.2016.7},
	number = {7},
	journal = {Neuropsychopharmacology},
	author = {Onnela, Jukka Pekka and Rauch, Scott L.},
	year = {2016},
	note = {Publisher: Nature Publishing Group},
	pages = {1691--1696},
	file = {Onnela_Rauch_2016_Harnessing Smartphone-Based Digital Phenotyping to Enhance Behavioral and Mental Health.pdf:/Users/orsonxu/Zotero/storage/RISNBVSA/Onnela_Rauch_2016_Harnessing Smartphone-Based Digital Phenotyping to Enhance Behavioral and Mental Health.pdf:application/pdf;Onnela_Rauch_2016_Harnessing Smartphone-Based Digital Phenotyping to Enhance Behavioral and Mental Health.pdf:/Users/orsonxu/Zotero/storage/7SBS2T6T/Onnela_Rauch_2016_Harnessing Smartphone-Based Digital Phenotyping to Enhance Behavioral and Mental Health.pdf:application/pdf},
}

@article{Torous2015,
	title = {Utilizing a {Personal} {Smartphone} {Custom} {App} to {Assess} the {Patient} {Health} {Questionnaire}-9 ({PHQ}-9) {Depressive} {Symptoms} in {Patients} {With} {Major} {Depressive} {Disorder}},
	volume = {2},
	issn = {2368-7959},
	doi = {10.2196/mental.3889},
	abstract = {BACKGROUND: Accurate reporting of patient symptoms is critical for diagnosis and therapeutic monitoring in psychiatry. Smartphones offer an accessible, low-cost means to collect patient symptoms in real time and aid in care.{\textbackslash}n{\textbackslash}nOBJECTIVE: To investigate adherence among psychiatric outpatients diagnosed with major depressive disorder in utilizing their personal smartphones to run a custom app to monitor Patient Health Questionnaire-9 (PHQ-9) depression symptoms, as well as to examine the correlation of these scores to traditionally administered (paper-and-pencil) PHQ-9 scores.{\textbackslash}n{\textbackslash}nMETHODS: A total of 13 patients with major depressive disorder, referred by their clinicians, received standard outpatient treatment and, in addition, utilized their personal smartphones to run the study app to monitor their symptoms. Subjects downloaded and used the Mindful Moods app on their personal smartphone to complete up to three survey sessions per day, during which a randomized subset of PHQ-9 symptoms of major depressive disorder were assessed on a Likert scale. The study lasted 29 or 30 days without additional follow-up. Outcome measures included adherence, measured by the percentage of completed survey sessions, and estimates of daily PHQ-9 scores collected from the smartphone app, as well as from the traditionally administered PHQ-9.{\textbackslash}n{\textbackslash}nRESULTS: Overall adherence was 77.78\% (903/1161) and varied with time of day. PHQ-9 estimates collected from the app strongly correlated (r=.84) with traditionally administered PHQ-9 scores, but app-collected scores were 3.02 (SD 2.25) points higher on average. More subjects reported suicidal ideation using the app than they did on the traditionally administered PHQ-9.{\textbackslash}n{\textbackslash}nCONCLUSIONS: Patients with major depressive disorder are able to utilize an app on their personal smartphones to self-assess their symptoms of major depressive disorder with high levels of adherence. These app-collected results correlate with the traditionally administered PHQ-9. Scores recorded from the app may potentially be more sensitive and better able to capture suicidality than the traditional PHQ-9.},
	number = {1},
	journal = {JMIR Mental Health},
	author = {Torous, John and Staples, Patrick and Shanahan, Meghan and Lin, Charlie and Peck, Pamela and Keshavan, Matcheri and Onnela, Jukka-Pekka},
	year = {2015},
	keywords = {depression, 1, 2015, e8, http, jmir, medical informatics, mental, mobile health, org},
	pages = {e8},
	file = {Torous et al_2015_Utilizing a Personal Smartphone Custom App to Assess the Patient Health Questionnaire-9 (PHQ-9) Depressive Symptoms in Patients With Major Depressive Disorder.pdf:/Users/orsonxu/Zotero/storage/IM4H2MAB/Torous et al_2015_Utilizing a Personal Smartphone Custom App to Assess the Patient Health Questionnaire-9 (PHQ-9) Depressive Symptoms in Patients With Major Depressive Disorder.pdf:application/pdf;Torous et al_2015_Utilizing a Personal Smartphone Custom App to Assess the Patient Health Questionnaire-9 (PHQ-9) Depressive Symptoms in Patients With Major Depressive Disorder.pdf:/Users/orsonxu/Zotero/storage/3AM2SSBP/Torous et al_2015_Utilizing a Personal Smartphone Custom App to Assess the Patient Health Questionnaire-9 (PHQ-9) Depressive Symptoms in Patients With Major Depressive Disorder.pdf:application/pdf},
}

@article{Aledavood2019,
	title = {Smartphone-{Based} {Tracking} of {Sleep} in {Depression}, {Anxiety}, and {Psychotic} {Disorders}},
	volume = {21},
	issn = {15351645},
	doi = {10.1007/s11920-019-1043-y},
	abstract = {Purpose of Review: Sleep is an important feature in mental illness. Smartphones can be used to assess and monitor sleep, yet there is little prior application of this approach in depressive, anxiety, or psychotic disorders. We review uses of smartphones and wearable devices for sleep research in patients with these conditions. Recent Findings: To date, most studies consist of pilot evaluations demonstrating feasibility and acceptability of monitoring sleep using smartphones and wearable devices among individuals with psychiatric disorders. Promising findings show early associations between behaviors and sleep parameters and agreement between clinic-based assessments, active smartphone data capture, and passively collected data. Few studies report improvement in sleep or mental health outcomes. Summary: Success of smartphone-based sleep assessments and interventions requires emphasis on promoting long-term adherence, exploring possibilities of adaptive and personalized systems to predict risk/relapse, and determining impact of sleep monitoring on improving patients’ quality of life and clinically meaningful outcomes.},
	number = {7},
	journal = {Current Psychiatry Reports},
	author = {Aledavood, Talayeh and Torous, John and Triana Hoyos, Ana Maria and Naslund, John A. and Onnela, Jukka Pekka and Keshavan, Matcheri},
	year = {2019},
	note = {Publisher: Current Psychiatry Reports},
	keywords = {Circadian rhythms, Mental illness, Psychotic disorders, Sleep, Smartphones, Wearable},
	file = {Aledavood et al_2019_Smartphone-Based Tracking of Sleep in Depression, Anxiety, and Psychotic Disorders.pdf:/Users/orsonxu/Zotero/storage/TH2ADUP3/Aledavood et al_2019_Smartphone-Based Tracking of Sleep in Depression, Anxiety, and Psychotic Disorders.pdf:application/pdf;Aledavood et al_2019_Smartphone-Based Tracking of Sleep in Depression, Anxiety, and Psychotic Disorders.pdf:/Users/orsonxu/Zotero/storage/QX4W5KRI/Aledavood et al_2019_Smartphone-Based Tracking of Sleep in Depression, Anxiety, and Psychotic Disorders.pdf:application/pdf},
}

@article{Yan2020,
	title = {Affect {Estimation} with {Wearable} {Sensors}},
	doi = {10.1007/s41666-019-00066-z},
	journal = {Journal of Healthcare Informatics Research},
	author = {Yan, Shen and Hosseinmardi, Homa and Kao, Te and Narayanan, Shrikanth and Ferrara, Emilio},
	year = {2020},
	note = {Publisher: Journal of Healthcare Informatics Research},
	file = {Yan et al_2020_Affect Estimation with Wearable Sensors.pdf:/Users/orsonxu/Zotero/storage/7DQBYN5H/Yan et al_2020_Affect Estimation with Wearable Sensors.pdf:application/pdf;Yan et al_2020_Affect Estimation with Wearable Sensors.pdf:/Users/orsonxu/Zotero/storage/33UJGGWT/Yan et al_2020_Affect Estimation with Wearable Sensors.pdf:application/pdf},
}

@article{Maher2019,
	title = {Passive data collection and use in healthcare: {A} systematic review of ethical issues},
	volume = {129},
	issn = {18728243},
	url = {https://doi.org/10.1016/j.ijmedinf.2019.06.015},
	doi = {10.1016/j.ijmedinf.2019.06.015},
	abstract = {Introduction: Passive data refers to data generated without the active participation of the subject. This includes data from global positioning systems and accelerometers or metadata on phone call and text activity. Although the potential healthcare applications are far-reaching, passive data raises numerous ethical challenges. Materials and Methods: We performed a systematic review to identify all ethical concerns, normative standpoints, and underlying arguments related to the use of passive data in healthcare. Results: Among the various challenges discussed in the ethical literature, informational privacy, informed consent, and data security were the primary focus of the current debate. Other topics of discussion were the evaluation and regulation of products, equity in access, vulnerable patient groups, ownership, and secondary use. Conclusion: No clear ethical framework has been established that stimulates passive data-driven innovation while protecting patient integrity. The consensus in the ethical literature, as well as the parallels with similar concerns and solutions in other fields, can lay a foundation for the construction of an ethical framework. The future debate should focus on conflicts between two or more ethical, technical, or clinical values to ensure a safe and effective implementation of passive data in healthcare.},
	number = {June},
	journal = {International Journal of Medical Informatics},
	author = {Maher, Nicole A. and Senders, Joeky T. and Hulsbergen, Alexander F.C. and Lamba, Nayan and Parker, Michael and Onnela, Jukka Pekka and Bredenoord, Annelien L. and Smith, Timothy R. and Broekman, Marike L.D.},
	year = {2019},
	note = {Publisher: Elsevier},
	keywords = {Smartphone, Ethics, Healthcare, Passive data, Personal digital devices, Systema, tic review},
	pages = {242--247},
	file = {Maher et al_2019_Passive data collection and use in healthcare.pdf:/Users/orsonxu/Zotero/storage/QBPCH4C8/Maher et al_2019_Passive data collection and use in healthcare.pdf:application/pdf;Maher et al_2019_Passive data collection and use in healthcare.pdf:/Users/orsonxu/Zotero/storage/IHBYXMNW/Maher et al_2019_Passive data collection and use in healthcare.pdf:application/pdf},
}

@article{Patterson2003,
	title = {Inferring {High}-{Level} {Behavior} from {Low}-{Level} {Sensors}},
	journal = {Proceedings of the International Conference on Ubiquitous Computing},
	author = {Patterson, Donald J and Liao, Lin and Fox, Dieter and Kautz, Henry},
	year = {2003},
	pages = {1--18},
	file = {Patterson et al_2003_Inferring High-Level Behavior from Low-Level Sensors.pdf:/Users/orsonxu/Zotero/storage/NAAKXPX7/Patterson et al_2003_Inferring High-Level Behavior from Low-Level Sensors.pdf:application/pdf;Patterson et al_2003_Inferring High-Level Behavior from Low-Level Sensors.pdf:/Users/orsonxu/Zotero/storage/NGI4I2GH/Patterson et al_2003_Inferring High-Level Behavior from Low-Level Sensors.pdf:application/pdf},
}

@article{Patterson2002,
	title = {The {Activity} {Compass}},
	abstract = {In this paper, we introduce the Activity Compass, a cognitive aide for early-state Alzheimer's patients.  This device has a simple user interface based on the metaphor of a traditional navigation compass.  By following an arrow and an icon, users who are disoriented or forgetful are assisted in reading their destination.  A server-based AI engine learns a model of routine user behavior, predicts their most likely destinations, and then directs the compass interface.  By leveraging historic behavior, the interface needs no configuration; the compass automatically improves its suggestions by observing user response over time.},
	journal = {First International Workshop on Ubiquitous Computing for Cognitive Aids},
	author = {Patterson, Donald J and Etzioni, Oren and Kautz, Henry},
	year = {2002},
	keywords = {alzheimer, artificial intelligence, assisted, behavior modeling, cognition, cognitive aid, s disease, ubiquitous},
	file = {Patterson et al_2002_The Activity Compass.pdf:/Users/orsonxu/Zotero/storage/V4EVRFDW/Patterson et al_2002_The Activity Compass.pdf:application/pdf;Patterson et al_2002_The Activity Compass.pdf:/Users/orsonxu/Zotero/storage/SCDF98FJ/Patterson et al_2002_The Activity Compass.pdf:application/pdf},
}

@article{Liao2006,
	title = {Building personal maps from {GPS} data},
	volume = {1093},
	issn = {17496632},
	doi = {10.1196/annals.1382.017},
	abstract = {In this article we discuss an assisted cognition information technology system that can learn personal maps customized for each user and infer his daily activities and movements from raw GPS data. The system uses discriminative and generative models for different parts of this task. A discriminative relational Markov network is used to extract significant places and label them; a generative dynamic Bayesian network is used to learn transportation routines, and infer goals and potential user errors at real time. We focus on the basic structures of the models and briefly discuss the inference and learning techniques. Experiments show that our system is able to accurately extract and label places, predict the goals of a person, and recognize situations in which the user makes mistakes, such as taking a wrong bus. © 2006 New York Academy of Sciences.},
	journal = {Annals of the New York Academy of Sciences},
	author = {Liao, Lin and Patterson, Donald J. and Fox, Dieter and Kautz, Henry},
	year = {2006},
	note = {ISBN: 1573316652},
	keywords = {Dynamic Bayesian network (DBN), GPS, Personal map, Relational Markov network (RMN)},
	pages = {249--265},
	file = {Liao et al_2006_Building personal maps from GPS data.pdf:/Users/orsonxu/Zotero/storage/WIXHJWM7/Liao et al_2006_Building personal maps from GPS data.pdf:application/pdf;Liao et al_2006_Building personal maps from GPS data.pdf:/Users/orsonxu/Zotero/storage/B9FFKL2K/Liao et al_2006_Building personal maps from GPS data.pdf:application/pdf},
}

@article{Perkowitz2004,
	title = {Mining models of human activities from the web},
	doi = {10.1145/988672.988750},
	abstract = {The ability to determine what day-to-day activity (such as cooking pasta, taking a pill, or watching a video) a person is performing is of interest in many application domains. A system that can do this requires models of the activities of interest, but model construction does not scale well: humans must specify low-level details, such as segmentation and feature selection of sensor data, and high-level structure, such as spatio-temporal relations between states of the model, for each and every activity. As a result, previous practical activity recognition systems have been content to model a tiny fraction of the thousands of human activities that are potentially useful to detect. In this paper, we present an approach to sensing and modeling activities that scales to a much larger class of activities than before. We show how a new class of sensors, based on Radio Frequency Identification (RFID) tags, can directly yield semantic terms that describe the state of the physical world. These sensors allow us to formulate activity models by translating labeled activities, such as "cooking pasta", into probabilistic collections of object terms, such as "pot". Given this view of activity models as text translations, we show how to mine definitions of activities in an unsupervised manner from the web. We have used our technique to mine definitions for over 20,000 activities. We experimentally validate our approach using data gathered from actual human activity as well as simulated data.},
	journal = {Thirteenth International World Wide Web Conference Proceedings},
	author = {Perkowitz, Mike and Philipose, Matthai and Fishkin, Kenneth and Patterson, Donald J.},
	year = {2004},
	note = {ISBN: 158113844X},
	keywords = {Activity inference, Activity models, RFID, Web mining},
	pages = {573--582},
	file = {Perkowitz et al_2004_Mining models of human activities from the web.pdf:/Users/orsonxu/Zotero/storage/Z8P9WEFB/Perkowitz et al_2004_Mining models of human activities from the web.pdf:application/pdf;Perkowitz et al_2004_Mining models of human activities from the web.pdf:/Users/orsonxu/Zotero/storage/EEN3CZTE/Perkowitz et al_2004_Mining models of human activities from the web.pdf:application/pdf},
}

@article{Althoff2016,
	title = {Influence of pokémon go on physical activity: {Study} and implications},
	volume = {18},
	issn = {14388871},
	doi = {10.2196/jmir.6759},
	abstract = {Background: Physical activity helps people maintain a healthy weight and reduces the risk for several chronic diseases. Although this knowledge is widely recognized, adults and children in many countries around the world do not get recommended amounts of physical activity. Although many interventions are found to be ineffective at increasing physical activity or reaching inactive populations, there have been anecdotal reports of increased physical activity due to novel mobile games that embed game play in the physical world. The most recent and salient example of such a game is Pokémon Go, which has reportedly reached tens of millions of users in the United States and worldwide. Objective: The objective of this study was to quantify the impact of Pokémon Go on physical activity. Methods: We study the effect of Pokémon Go on physical activity through a combination of signals from large-scale corpora of wearable sensor data and search engine logs for 32,000 Microsoft Band users over a period of 3 months. Pokémon Go players are identified through search engine queries and physical activity is measured through accelerometers. Results: We find that Pokémon Go leads to significant increases in physical activity over a period of 30 days, with particularly engaged users (ie, those making multiple search queries for details about game usage) increasing their activity by 1473 steps a day on average, a more than 25\% increase compared with their prior activity level (P{\textless}.001). In the short time span of the study, we estimate that Pokémon Go has added a total of 144 billion steps to US physical activity. Furthermore, Pokémon Go has been able to increase physical activity across men and women of all ages, weight status, and prior activity levels showing this form of game leads to increases in physical activity with significant implications for public health. In particular, we find that Pokémon Go is able to reach low activity populations, whereas all 4 leading mobile health apps studied in this work largely draw from an already very active population. Conclusions: Mobile apps combining game play with physical activity lead to substantial short-term activity increases and, in contrast to many existing interventions and mobile health apps, have the potential to reach activity-poor populations. Future studies are needed to investigate potential long-term effects of these applications.},
	number = {12},
	journal = {Journal of Medical Internet Research},
	author = {Althoff, Tim and White, Ryen W. and Horvitz, Eric},
	year = {2016},
	keywords = {Mobile health, Exergames, Games, mHealth, Mobile applications, Physical activity, Pokémon Go, Public health, Wearable devices},
	file = {Althoff et al_2016_Influence of pokémon go on physical activity.pdf:/Users/orsonxu/Zotero/storage/MNFR44PE/Althoff et al_2016_Influence of pokémon go on physical activity.pdf:application/pdf;Althoff et al_2016_Influence of pokémon go on physical activity.pdf:/Users/orsonxu/Zotero/storage/37NPK3HX/Althoff et al_2016_Influence of pokémon go on physical activity.pdf:application/pdf},
}

@article{Wyatt2005,
	title = {Unsupervised activity recognition using automatically mined common sense},
	volume = {1},
	abstract = {A fundamental difficulty in recognizing human activities is obtaining the labeled data needed to learn models of those activities. Given emerging sensor technology, however, it is possible to view activity data as a stream of natural language terms. Activity models are then mappings from such terms to activity names, and may be extracted from text corpora such as the web. We show that models so extracted are sufficient to automatically produce labeled segmentations of activity data with an accuracy of 42\% over 26 activities, well above the 3.8\% baseline. The segmentation so obtained is sufficient to bootstrap learning, with accuracy of learned models increasing to 52\%. To our knowledge, this is the first human activity inferencing system shown to learn from sensed activity data with no human intervention per activity learned, even for labeling. Copyright © 2005, American Association for Artificial Intelligence (www.aaai.org). All rights reserved.},
	journal = {Proceedings of the National Conference on Artificial Intelligence},
	author = {Wyatt, Danny and Philipose, Matthai and Choudhury, Tanzeem},
	year = {2005},
	pages = {21--27},
	file = {Wyatt et al_2005_Unsupervised activity recognition using automatically mined common sense.pdf:/Users/orsonxu/Zotero/storage/7LZZIMJ5/Wyatt et al_2005_Unsupervised activity recognition using automatically mined common sense.pdf:application/pdf;Wyatt et al_2005_Unsupervised activity recognition using automatically mined common sense.pdf:/Users/orsonxu/Zotero/storage/ANUE27DV/Wyatt et al_2005_Unsupervised activity recognition using automatically mined common sense.pdf:application/pdf},
}

@article{Lu2010,
	title = {The {Jigsaw} continuous sensing engine for mobile phone applications},
	doi = {10.1145/1869983.1869992},
	abstract = {Supporting continuous sensing applications on mobile phones is challenging because of the resource demands of long-termsensing, inference and communication algorithms. We present the design, implementation and evaluation of the Jigsaw continuous sensing engine, which balances the performance needs of the application and the resource demands of continuous sensing on the phone. Jigsaw comprises a set of sensing pipelines for the accelerometer, microphone and GPS sensors, which are built in a plug and play manner to support: i) resilient accelerometer data processing, which allows inferences to be robust to different phone hardware, orientation and body positions; ii) smart admission control and on-demand processing for the microphone and accelerometer data, which adaptively throttles the depth and sophistication of sensing pipelines when the input data is low quality or uninformative; and iii) adaptive pipeline processing, which judiciously triggers power hungry pipeline stages (e.g., sampling the GPS) taking into account the mobility and behavioral patterns of the user to drive down energy costs. We implement and evaluate Jigsaw on the Nokia N95 and the Apple iPhone, two popular smartphone platforms, to demonstrate its capability to recognize user activities and perform long term GPS tracking in an energy-efficientmanner. Copyright 2010 ACM.},
	journal = {Proceedings of the ACM Conference on Embedded Networked Sensor Systems},
	author = {Lu, Hong and Yang, Jun and Liu, Zhigang and Lane, Nicholas D. and Choudhury, Tanzeem and Campbell, Andrew T.},
	year = {2010},
	note = {ISBN: 9781450303446},
	keywords = {Machine learning, Activity recognition, Mobile phone sensing, Power management},
	pages = {71--84},
	file = {Lu et al_2010_The Jigsaw continuous sensing engine for mobile phone applications.pdf:/Users/orsonxu/Zotero/storage/7WTRZBXC/Lu et al_2010_The Jigsaw continuous sensing engine for mobile phone applications.pdf:application/pdf;Lu et al_2010_The Jigsaw continuous sensing engine for mobile phone applications.pdf:/Users/orsonxu/Zotero/storage/YM5DZY2P/Lu et al_2010_The Jigsaw continuous sensing engine for mobile phone applications.pdf:application/pdf},
}

@article{Philipose2004,
	title = {Inferring activities from interactions with objects},
	volume = {3},
	issn = {15361268},
	doi = {10.1109/MPRV.2004.7},
	number = {4},
	journal = {IEEE Pervasive Computing},
	author = {Philipose, Matthai and Fishkin, Kenneth P. and Perkowitz, Mike and Patterson, Donald J. and Fox, Dieter and Kautz, Henry and Hähnel, Dirk},
	year = {2004},
	pages = {50--57},
	file = {Philipose et al_2004_Inferring activities from interactions with objects.pdf:/Users/orsonxu/Zotero/storage/8S2WNFIK/Philipose et al_2004_Inferring activities from interactions with objects.pdf:application/pdf;Philipose et al_2004_Inferring activities from interactions with objects.pdf:/Users/orsonxu/Zotero/storage/2F9ZSU7P/Philipose et al_2004_Inferring activities from interactions with objects.pdf:application/pdf},
}

@article{Roman2005,
	title = {Routine {Activities} of {Youth} and {Neighborhood} {Violence}},
	doi = {10.4018/978-1-59140-453-8.ch017},
	number = {March 2019},
	journal = {Geographic Information Systems and Crime Analysis},
	author = {Roman, Caterina Gouvis},
	year = {2005},
	note = {ISBN: 9781591404538},
	pages = {293--310},
	file = {Roman_2005_Routine Activities of Youth and Neighborhood Violence.pdf:/Users/orsonxu/Zotero/storage/VR6YTUTH/Roman_2005_Routine Activities of Youth and Neighborhood Violence.pdf:application/pdf;Roman_2005_Routine Activities of Youth and Neighborhood Violence.pdf:/Users/orsonxu/Zotero/storage/526CGZHC/Roman_2005_Routine Activities of Youth and Neighborhood Violence.pdf:application/pdf},
}

@article{Liao2007,
	title = {Learning and inferring transportation routines},
	volume = {171},
	issn = {00043702},
	doi = {10.1016/j.artint.2007.01.006},
	abstract = {This paper introduces a hierarchical Markov model that can learn and infer a user's daily movements through an urban community. The model uses multiple levels of abstraction in order to bridge the gap between raw GPS sensor measurements and high level information such as a user's destination and mode of transportation. To achieve efficient inference, we apply Rao-Blackwellized particle filters at multiple levels of the model hierarchy. Locations such as bus stops and parking lots, where the user frequently changes mode of transportation, are learned from GPS data logs without manual labeling of training data. We experimentally demonstrate how to accurately detect novel behavior or user errors (e.g. taking a wrong bus) by explicitly modeling activities in the context of the user's historical data. Finally, we discuss an application called "Opportunity Knocks" that employs our techniques to help cognitively-impaired people use public transportation safely. © 2007 Elsevier B.V. All rights reserved.},
	number = {5-6},
	journal = {Artificial Intelligence},
	author = {Liao, Lin and Patterson, Donald J. and Fox, Dieter and Kautz, Henry},
	year = {2007},
	keywords = {Activity recognition, Hierarchical Markov model, Location tracking, Novelty detection, Rao-Blackwellized particle filters},
	pages = {311--331},
	file = {Liao et al_2007_Learning and inferring transportation routines.pdf:/Users/orsonxu/Zotero/storage/IXDRXF2Y/Liao et al_2007_Learning and inferring transportation routines.pdf:application/pdf;Liao et al_2007_Learning and inferring transportation routines.pdf:/Users/orsonxu/Zotero/storage/3SHJC7HY/Liao et al_2007_Learning and inferring transportation routines.pdf:application/pdf},
}

@article{Bregler1997,
	title = {Learning and recognizing human dynamics in video sequences},
	issn = {10636919},
	doi = {10.1109/cvpr.1997.609382},
	abstract = {This paper describes a probabilistic decomposition of human dynamics at multiple abstractions, and shows how to propagate hypotheses across space, time, and abstraction levels. Recognition in this framework is the succession of very general low level grouping mechanisms to increased specific and learned model based grouping techniques at higher levels. Hard decision thresholds are delayed and resolved by higher level statistical models and temporal context. Low-level primitives are areas of coherent motion found by EM clustering, mid-level categories are simple movements represented by dynamical systems, and high-level complex gestures are represented by Hidden Markov Models as successive phases of simple movements. We show how such a representation can be learned from training data, and apply it to the example of human gait recognition.},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	author = {Bregler, Christoph},
	year = {1997},
	pages = {568--574},
	file = {Bregler_1997_Learning and recognizing human dynamics in video sequences.pdf:/Users/orsonxu/Zotero/storage/IYT3UN68/Bregler_1997_Learning and recognizing human dynamics in video sequences.pdf:application/pdf},
}

@article{Macadam2003,
	title = {Understanding and {Modeling} the {Human} {Driver}},
	volume = {40},
	number = {734},
	journal = {Vehicle System Dynamics},
	author = {Macadam, Charles C},
	year = {2003},
	pages = {101--134},
	file = {Macadam_2003_Understanding and Modeling the Human Driver.pdf:/Users/orsonxu/Zotero/storage/MKHKST9Q/Macadam_2003_Understanding and Modeling the Human Driver.pdf:application/pdf;Macadam_2003_Understanding and Modeling the Human Driver.pdf:/Users/orsonxu/Zotero/storage/ZQY6DW4T/Macadam_2003_Understanding and Modeling the Human Driver.pdf:application/pdf},
}

@article{Bogomolov2014,
	title = {Once upon a crime: {Towards} crime prediction from demographics and mobile data},
	doi = {10.1145/2663204.2663254},
	abstract = {In this paper, we present a novel approach to predict crime in a geographic space from multiple data sources, in particular mobile phone and demographic data. The main contribution of the proposed approach lies in using aggregated and anonymized human behavioral data derived from mo- bile network activity to tackle the crime prediction problem. While previous research efforts have used either background historical knowledge or offenders' profiling, our findings sup- port the hypothesis that aggregated human behavioral data captured from the mobile network infrastructure, in combination with basic demographic information, can be used to predict crime. In our experimental results with real crime data from London we obtain an accuracy of almost 70\% when predicting whether a specific area in the city will be a crime hotspot or not. Moreover, we provide a discussion of the implications of our findings for data-driven crime analysis.},
	journal = {Proceedings of the International Conference on Multimodal Interaction},
	author = {Bogomolov, Andrey and Lepri, Bruno and Staiano, Jacopo and Oliver, Nuria and Pianesi, Fabio and Pentland, Alex},
	year = {2014},
	note = {ISBN: 9781450328852},
	keywords = {Crime prediction, Mobile sensing, Urban computing},
	pages = {427--434},
	file = {Bogomolov et al_2014_Once upon a crime.pdf:/Users/orsonxu/Zotero/storage/MSDBGAT3/Bogomolov et al_2014_Once upon a crime.pdf:application/pdf;Bogomolov et al_2014_Once upon a crime.pdf:/Users/orsonxu/Zotero/storage/IAC9VTBY/Bogomolov et al_2014_Once upon a crime.pdf:application/pdf},
}

@article{Oliver2004,
	title = {Layered representations for learning and inferring office activity from multiple sensory channels},
	volume = {96},
	issn = {10773142},
	doi = {10.1016/j.cviu.2004.02.004},
	abstract = {We present the use of layered probabilistic representations for modeling human activities, and describe how we use the representation to do sensing, learning, and inference at multiple levels of temporal granularity and abstraction and from heterogeneous data sources. The approach centers on the use of a cascade of Hidden Markov Models named Layered Hidden Markov Models (LHMMs) to diagnose states of a user's activity based on real-time streams of evidence from video, audio, and computer (keyboard and mouse) interactions. We couple these LHMMs with an expected utility analysis that considers the cost of misclassification. We describe the representation, present an implementation, and report on experiments with our layered architecture in a real-time office-awareness setting. © 2004 Elsevier Inc. All rights reserved.},
	number = {2 SPEC. ISS.},
	journal = {Computer Vision and Image Understanding},
	author = {Oliver, Nuria and Garg, Ashutosh and Horvitz, Eric},
	year = {2004},
	keywords = {Hidden markov models, Human behavior understanding, Multi-modal systems, Office activity recognition, Office awareness},
	pages = {163--180},
	file = {Oliver et al_2004_Layered representations for learning and inferring office activity from multiple sensory channels.pdf:/Users/orsonxu/Zotero/storage/AUYHRK69/Oliver et al_2004_Layered representations for learning and inferring office activity from multiple sensory channels.pdf:application/pdf;Oliver et al_2004_Layered representations for learning and inferring office activity from multiple sensory channels.pdf:/Users/orsonxu/Zotero/storage/LEMMDAKB/Oliver et al_2004_Layered representations for learning and inferring office activity from multiple sensory channels.pdf:application/pdf},
}

@article{Brand1997,
	title = {Coupled hidden {Markov} models for complex action recognition},
	issn = {10636919},
	doi = {10.1109/cvpr.1997.609450},
	abstract = {We present algorithms for coupling and training hidden Markov models (HMMs) to model interacting processes, and demonstrate their superiority to conventional HMMs in a vision task classifying two-handed actions. HMMs are perhaps the most successful framework in perceptual computing for modeling and classifying dynamic behaviors, popular because they offer dynamic time warping, a training algorithm, and a clear Bayesian semantics. However, the Markovian framework makes strong restrictive assumptions about the system generating the signal - that it is a single process having a small number of states and an extremely limited state memory. The single-process model is often inappropriate for vision (and speech) applications, resulting in low ceilings on model performance. Coupled HMMs provide an efficient way to resolve many of these problems, and offer superior training speeds, model likelihoods, and robustness to initial conditions.},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	author = {Brand, Matthew and Oliver, Nuria and Pentland, Alex},
	year = {1997},
	pages = {994--999},
	file = {Brand et al_1997_Coupled hidden Markov models for complex action recognition.pdf:/Users/orsonxu/Zotero/storage/3IGCEYNF/Brand et al_1997_Coupled hidden Markov models for complex action recognition.pdf:application/pdf},
}

@article{Clarkson1999,
	title = {Unsupervised {Clustering} of {Ambulatory} {Audio} and {Video}},
	journal = {IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings. ICASSP},
	author = {Clarkson, Brian and Pentland, Alex},
	year = {1999},
	note = {ISBN: 0780350413},
	pages = {3037--3040},
	file = {Clarkson_Pentland_1999_Unsupervised Clustering of Ambulatory Audio and Video.pdf:/Users/orsonxu/Zotero/storage/A7PPA6J6/Clarkson_Pentland_1999_Unsupervised Clustering of Ambulatory Audio and Video.pdf:application/pdf},
}

@article{Markkula2014,
	title = {Modeling driver control behavior in both routine and near-accident driving},
	volume = {2014-Janua},
	issn = {10711813},
	doi = {10.1177/1541931214581185},
	abstract = {Building on ideas from contemporary neuroscience, a framework is proposed in which drivers' steering and pedal behavior is modeled as a series of individual control adjustments, triggered after accumulation of sensory evidence for the need of an adjustment, or evidence that a previous or ongoing adjustment is not achieving the intended results. Example simulations are provided. Specifically, it is shown that evidence accumulation can account for previously unexplained variance in looming detection thresholds and brake onset timing. It is argued that the proposed framework resolves a discrepancy in the current driver modeling literature, by explaining not only the short-latency, well-tuned, closed-loop type of control of routine driving, but also the degradation into long-latency, ill-tuned open-loop control in more rare, unexpected, and urgent situations such as near-accidents.},
	journal = {Proceedings of the Human Factors and Ergonomics Society},
	author = {Markkula, Gustav},
	year = {2014},
	note = {ISBN: 9780945289456},
	pages = {879--883},
	file = {Markkula_2014_Modeling driver control behavior in both routine and near-accident driving.pdf:/Users/orsonxu/Zotero/storage/LS6C5ASN/Markkula_2014_Modeling driver control behavior in both routine and near-accident driving.pdf:application/pdf;Markkula_2014_Modeling driver control behavior in both routine and near-accident driving.pdf:/Users/orsonxu/Zotero/storage/A63PD7SZ/Markkula_2014_Modeling driver control behavior in both routine and near-accident driving.pdf:application/pdf},
}

@article{Zhang2004,
	title = {Modeling {Individual} {And} {Group} {Actions} {In} {Meetings}: {A} {Two}-layer {Hmm} {Framework}},
	journal = {Computer Vision and Pattern Recognition Workshop},
	author = {Zhang, Dong and Gatica-Perez, Daniel and Bengio, Samy and McCowan, Iain and Lathoud, Guillaume},
	year = {2004},
	pages = {1--13},
	file = {Zhang et al_2004_Modeling Individual And Group Actions In Meetings.pdf:/Users/orsonxu/Zotero/storage/R5XUNDMF/Zhang et al_2004_Modeling Individual And Group Actions In Meetings.pdf:application/pdf;Zhang et al_2004_Modeling Individual And Group Actions In Meetings.pdf:/Users/orsonxu/Zotero/storage/DVBME3ER/Zhang et al_2004_Modeling Individual And Group Actions In Meetings.pdf:application/pdf},
}

@article{Hong2014,
	title = {A smartphone-based sensing platform to model aggressive driving behaviors},
	doi = {10.1145/2556288.2557321},
	abstract = {Driving aggressively increases the risk of accidents. Assessing a person's driving style is a useful way to guide aggressive drivers toward having safer driving behaviors. A number of studies have investigated driving style, but they often rely on the use of self-reports or simulators, which are not suitable for the real-time, continuous, automated assessment and feedback on the road. In order to understand and model aggressive driving style, we construct an invehicle sensing platform that uses a smartphone instead of using heavyweight, expensive systems. Utilizing additional cheap sensors, our sensing platform can collect useful information about vehicle movement, maneuvering and steering wheel movement. We use this data and apply machine learning to build a driver model that evaluates drivers' driving styles based on a number of driving-related features. From a naturalistic data collection from 22 drivers for 3 weeks, we analyzed the characteristics of drivers who have an aggressive driving style. Our model classified those drivers with an accuracy of 90.5\% (violation-class) and 81\% (questionnaire-class). We describe how, in future work, our model can be used to provide real-time feedback to drivers using only their current smartphone. Copyright © ACM.},
	journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	author = {Hong, Jin Hyuk and Margines, Ben and Dey, Anind K.},
	year = {2014},
	note = {ISBN: 9781450324731},
	keywords = {Smartphone, Driving assessment, In-vehicle sensing platform},
	pages = {4047--4056},
	file = {Hong et al_2014_A smartphone-based sensing platform to model aggressive driving behaviors.pdf:/Users/orsonxu/Zotero/storage/UVKJELER/Hong et al_2014_A smartphone-based sensing platform to model aggressive driving behaviors.pdf:application/pdf;Hong et al_2014_A smartphone-based sensing platform to model aggressive driving behaviors.pdf:/Users/orsonxu/Zotero/storage/M87H7HBL/Hong et al_2014_A smartphone-based sensing platform to model aggressive driving behaviors.pdf:application/pdf},
}

@article{Davidoff2010,
	title = {How routine learners can support family coordination},
	volume = {4},
	doi = {10.1145/1753326.1753699},
	abstract = {Researchers have detailed the importance of routines in how people live and work, while also cautioning system designers about the importance of people's idiosyncratic behavior patterns and the challenges they would present to learning systems. We wish to take up their challenge, and offer a vision of how simple sensing technology could capture and model idiosyncratic routines, enabling applications to solve many real world problems. To identify how a simple routine learner can demonstrate this in support of family coordination, we conducted six months of nightly interviews with six families, focusing on how they make and execute plans. Our data reveals that only about 40\% of events unfold in a routine manner. When deviations do occur, family members often need but do not have access to accurate information about their routines. With about 90\% of their content concerning deviations, not routines, families do not rely on calendars to support them during these moments. We discuss how coordination tools, like calendars and reminder systems, would improve coordination and reduce stress when augmented with routine information, and how commercial mobile phones can support the automatic creation of routine models. © 2010 ACM.},
	journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	author = {Davidoff, Scott and Zimmerman, John and Dey, Anind K.},
	year = {2010},
	note = {ISBN: 9781605589299},
	keywords = {calendar, learning, location, mobile, planning, reminder},
	pages = {2461--2470},
	file = {Davidoff et al_2010_How routine learners can support family coordination.pdf:/Users/orsonxu/Zotero/storage/YJX9PIHP/Davidoff et al_2010_How routine learners can support family coordination.pdf:application/pdf;Davidoff et al_2010_How routine learners can support family coordination.pdf:/Users/orsonxu/Zotero/storage/WXKJA4WT/Davidoff et al_2010_How routine learners can support family coordination.pdf:application/pdf},
}

@article{Bulling2014,
	title = {A tutorial on human activity recognition using body-worn inertial sensors},
	volume = {46},
	issn = {03600300},
	doi = {10.1145/2499621},
	abstract = {The last 20 years have seen ever-increasing research activity in the field of human activity recognition. With activity recognition having considerably matured, so has the number of challenges in designing, implementing, and evaluating activity recognition systems. This tutorial aims to provide a comprehensive hands-on introduction for newcomers to the field of human activity recognition. It specifically focuses on activity recognition using on-body inertial sensors. We first discuss the key research challenges that human activity recognition shares with general pattern recognition and identify those challenges that are specific to human activity recognition. We then describe the concept of an Activity Recognition Chain (ARC) as a general-purpose framework for designing and evaluating activity recognition systems. We detail each component of the framework, provide references to related research, and introduce the best practice methods developed by the activity recognition research community. We conclude with the educational example problem of recognizing different hand gestures from inertial sensors attached to the upper and lower arm. We illustrate how each component of this framework can be implemented for this specific activity recognition problem and demonstrate how different implementations compare and how they impact overall recognition performance. © 2014 ACM.},
	number = {3},
	journal = {ACM Computing Surveys},
	author = {Bulling, Andreas and Blanke, Ulf and Schiele, Bernt},
	year = {2014},
	keywords = {Activity recognition, Activity Recognition Chain (ARC), Gesture recognition, On-body inertial sensors},
	pages = {1--33},
	file = {Bulling et al_2014_A tutorial on human activity recognition using body-worn inertial sensors.pdf:/Users/orsonxu/Zotero/storage/QL8436NK/Bulling et al_2014_A tutorial on human activity recognition using body-worn inertial sensors.pdf:application/pdf;Bulling et al_2014_A tutorial on human activity recognition using body-worn inertial sensors.pdf:/Users/orsonxu/Zotero/storage/86Q5Z8DQ/Bulling et al_2014_A tutorial on human activity recognition using body-worn inertial sensors.pdf:application/pdf},
}

@article{Ziebart2008,
	title = {Navigate like a cabbie: {Probabilistic} reasoning from observed context-aware behavior},
	doi = {10.1145/1409635.1409678},
	abstract = {We present PROCAB, an efficient method for Probabilistically Reasoning from Observed Context-Aware Behavior. It models the context-dependent utilities and underlying reasons that people take different actions. The model generalizes to unseen situations and scales to incorporate rich contextual information. We train our model using the route preferences of 25 taxi drivers demonstrated in over 100,000 miles of collected data, and demonstrate the performance of our model by inferring: (1) decision at next intersection, (2) route to known destination, and (3) destination given partially traveled route. © 2008 ACM.},
	journal = {Proceedings of the International Conference on Ubiquitous Computing},
	author = {Ziebart, Brian D. and Maas, Andrew L. and Dey, Anind K. and Bagnell, J. Andrew},
	year = {2008},
	note = {ISBN: 9781605581361},
	keywords = {Decision modeling, Route prediction, Vehicle navigation},
	pages = {322--331},
	file = {Ziebart et al_2008_Navigate like a cabbie.pdf:/Users/orsonxu/Zotero/storage/F2PMQVMX/Ziebart et al_2008_Navigate like a cabbie.pdf:application/pdf;Ziebart et al_2008_Navigate like a cabbie.pdf:/Users/orsonxu/Zotero/storage/PJAS54Q4/Ziebart et al_2008_Navigate like a cabbie.pdf:application/pdf},
}

@article{Krumm2006,
	title = {Predestination: {Inferring} {Destinations} from {Partial} {Trajectories}},
	volume = {4206},
	url = {http://dx.doi.org/10.1007/11853565_15},
	doi = {10.1007/11853565_15},
	abstract = {We describe a method called Predestination that uses a history of a driver’s destinations, along with data about driving behaviors, to predict where a driver is going as a trip progresses. Driving behaviors include types of destinations, driving efficiency, and trip times. Beyond considering previously visited destinations, Predestination leverages an open-world modeling methodology that considers the likelihood of users visiting previously unobserved locations based on trends in the data and on the background properties of locations. This allows our algorithm to smoothly transition between “out of the box” with no training data to more fully trained with increasing numbers of observations. Multiple components of the analysis are fused via Bayesian inference to produce a probabilistic map of destinations. Our algorithm was trained and tested on hold-out data drawn from a database of GPS driving data gathered from 169 different subjects who drove 7,335 different trips.},
	journal = {Proceedings of the International Conference on Ubiquitous Computing},
	author = {Krumm, John and Horvitz, Eric},
	year = {2006},
	note = {ISBN: 978-3-540-39634-5},
	pages = {243--260},
	file = {Krumm_Horvitz_2006_Predestination.pdf:/Users/orsonxu/Zotero/storage/MQRVC5D6/Krumm_Horvitz_2006_Predestination.pdf:application/pdf;Krumm_Horvitz_2006_Predestination.pdf:/Users/orsonxu/Zotero/storage/CG2VG52D/Krumm_Horvitz_2006_Predestination.pdf:application/pdf},
}

@article{Min2014,
	title = {Toss '{N}' turn: {Smartphone} as sleep and sleep quality detector},
	doi = {10.1145/2556288.2557220},
	abstract = {The rapid adoption of smartphones along with a growing habit for using these devices as alarm clocks presents an opportunity to use this device as a sleep detector. This adds value to UbiComp and personal informatics in terms of user context and new performance data to collect and visualize, and it benefits healthcare as sleep is correlated with many health issues. To assess this opportunity, we collected one month of phone sensor and sleep diary entries from 27 people who have a variety of sleep contexts. We used this data to construct models that detect sleep and wake states, daily sleep quality, and global sleep quality. Our system classifies sleep state with 93.06\% accuracy, daily sleep quality with 83.97\% accuracy, and overall sleep quality with 81.48\% accuracy. Individual models performed better than generally trained models, where the individual models require 3 days of ground truth data and 3 weeks of ground truth data to perform well on detecting sleep and sleep quality, respectively. Finally, the features of noise and movement were useful to infer sleep quality.},
	journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	author = {Min, Jun Ki and Doryab, Afsaneh and Wiese, Jason and Amini, Shahriyar and Zimmerman, John and Hong, Jason I.},
	year = {2014},
	note = {ISBN: 9781450324731},
	keywords = {Machine learning, Smartphone, Sleep, Sensors},
	pages = {477--486},
	file = {Min et al_2014_Toss 'N' turn.pdf:/Users/orsonxu/Zotero/storage/N8YY9W6Y/Min et al_2014_Toss 'N' turn.pdf:application/pdf;Min et al_2014_Toss 'N' turn.pdf:/Users/orsonxu/Zotero/storage/HHN3W2XG/Min et al_2014_Toss 'N' turn.pdf:application/pdf},
}

@article{Dumais2014,
	title = {Understanding {User} {Behavior} {Through} {Log} {Data} and {Analysis}},
	doi = {10.1007/978-1-4939-0378-8},
	abstract = {This textbook brings together both new and traditional research methods in Human Computer Interaction (HCI). Research methods include interviews and observations, ethnography, grounded theory and analysis of digital traces of behavior. Readers will gain an understanding of the type of knowledge each method provides, its disciplinary roots and how each contributes to understanding users, user behavior and the context of use. The background context, clear explanations and sample exercises make this an ideal textbook for graduate students, as well as a valuable reference for researchers and practitioners.},
	journal = {Ways of Knowing in HCI},
	author = {Dumais, Susan and Jeffries, Robin and Russell, Daniel M. and Tang, Diane and Teevan, Jaime},
	year = {2014},
	note = {ISBN: 9781493903788},
	pages = {1--472},
	file = {Dumais et al_2014_Understanding User Behavior Through Log Data and Analysis.pdf:/Users/orsonxu/Zotero/storage/J2VQFVCI/Dumais et al_2014_Understanding User Behavior Through Log Data and Analysis.pdf:application/pdf;Dumais et al_2014_Understanding User Behavior Through Log Data and Analysis.pdf:/Users/orsonxu/Zotero/storage/6PMXQMIH/Dumais et al_2014_Understanding User Behavior Through Log Data and Analysis.pdf:application/pdf},
}

@article{Bae2018,
	title = {Mobile phone sensors and supervised machine learning to identify alcohol use events in young adults: {Implications} for just-in-time adaptive interventions},
	volume = {83},
	issn = {18736327},
	doi = {10.1016/j.addbeh.2017.11.039},
	abstract = {Background: Real-time detection of drinking could improve timely delivery of interventions aimed at reducing alcohol consumption and alcohol-related injury, but existing detection methods are burdensome or impractical. Objective: To evaluate whether phone sensor data and machine learning models are useful to detect alcohol use events, and to discuss implications of these results for just-in-time mobile interventions. Methods: 38 non-treatment seeking young adult heavy drinkers downloaded AWARE app (which continuously collected mobile phone sensor data), and reported alcohol consumption (number of drinks, start/end time of prior day's drinking) for 28 days. We tested various machine learning models using the 20 most informative sensor features to classify time periods as non-drinking, low-risk (1 to 3/4 drinks per occasion for women/men), and high-risk drinking ({\textgreater} 4/5 drinks per occasion for women/men). Results: Among 30 participants in the analyses, 207 non-drinking, 41 low-risk, and 45 high-risk drinking episodes were reported. A Random Forest model using 30-min windows with 1 day of historical data performed best for detecting high-risk drinking, correctly classifying high-risk drinking windows 90.9\% of the time. The most informative sensor features were related to time (i.e., day of week, time of day), movement (e.g., change in activities), device usage (e.g., screen duration), and communication (e.g., call duration, typing speed). Conclusions: Preliminary evidence suggests that sensor data captured from mobile phones of young adults is useful in building accurate models to detect periods of high-risk drinking. Interventions using mobile phone sensor features could trigger delivery of a range of interventions to potentially improve effectiveness.},
	number = {July 2017},
	journal = {Addictive Behaviors},
	author = {Bae, Sangwon and Chung, Tammy and Ferreira, Denzil and Dey, Anind K. and Suffoletto, Brian},
	year = {2018},
	keywords = {Machine learning, Alcohol, AWARE app, Smartphone sensors},
	pages = {42--47},
	file = {Bae et al_2018_Mobile phone sensors and supervised machine learning to identify alcohol use events in young adults.pdf:/Users/orsonxu/Zotero/storage/YKLTV6HL/Bae et al_2018_Mobile phone sensors and supervised machine learning to identify alcohol use events in young adults.pdf:application/pdf;Bae et al_2018_Mobile phone sensors and supervised machine learning to identify alcohol use events in young adults.pdf:/Users/orsonxu/Zotero/storage/572ZXSW4/Bae et al_2018_Mobile phone sensors and supervised machine learning to identify alcohol use events in young adults.pdf:application/pdf},
}

@article{Biel2018,
	title = {Bites‘n’{Bits}: {Inferring} {Eating} {Behavior} from {Contextual} {Mobile} {Data}},
	volume = {1},
	doi = {10.1145/3161161},
	number = {4},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Biel, Joan-Isaac and Martin, Nathalie and Labbe, David and Gatica-Perez, Daniel},
	year = {2018},
	keywords = {Machine Learning, Eating Behavior, Mobile Crowdsensing, Physical Activity, Snack and Meal},
	pages = {1--33},
	file = {Biel et al_2018_Bites‘n’Bits.pdf:/Users/orsonxu/Zotero/storage/ZUMYSZC2/Biel et al_2018_Bites‘n’Bits.pdf:application/pdf;Biel et al_2018_Bites‘n’Bits.pdf:/Users/orsonxu/Zotero/storage/EA39WYXW/Biel et al_2018_Bites‘n’Bits.pdf:application/pdf},
}

@article{Chang2018,
	title = {{SleepGuard}: {Capturing} {Rich} {Sleep} {Information} {Using} {Smartwatch} {Sensing} {Data}},
	volume = {2},
	url = {https://doi.org/10.1145/3264908},
	doi = {10.1145/3264908},
	abstract = {Sleep is an important part of our daily routine-we spend about one-third of our time doing it. By tracking sleep-related events and activities, sleep monitoring provides decision support to help us understand sleep quality and causes of poor sleep. Wearable devices provide a new way for sleep monitoring, allowing us to monitor sleep from the comfort of our own home. However, existing solutions do not take full advantage of the rich sensor data provided by these devices. In this paper, we present the design and development of SleepGuard, a novel approach to track a wide range of sleep-related events using smartwatches. We show that using merely a single smartwatch, it is possible to capture a rich amount of information about sleep events and sleeping context, including body posture and movements, acoustic events, and illumination conditions. We demonstrate that through these events it is possible to estimate sleep quality and identify factors affecting it most. We evaluate our approach by conducting extensive experiments involved fifteen users across a 2-week period. Our experimental results show that our approach can track a richer set of sleep events, provide better decision support for evaluating sleep quality, and help to identify causes for sleep problems compared to prior work.},
	number = {98},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Chang, Liqiong and Lu, Jiaqi and Wang, J U and Chen, Xiaojiang and Fang, Dingyi and Tang, Zhany-Ong and Wang, Ju and Tang, Zhanyong and Nurmi, Petteri and Wang, Zheng},
	year = {2018},
	note = {ISBN: 24749567/2018/9},
	keywords = {mobile sensing, Additional Key Words and Phrases: Smartwatch sensi, CCS Concepts: • Human-centered computing → Ubiquit, sleep events, sleep monitoring ACM Reference Format:},
	pages = {34},
	file = {Chang et al_2018_SleepGuard.pdf:/Users/orsonxu/Zotero/storage/YA9Z5JEX/Chang et al_2018_SleepGuard.pdf:application/pdf;Chang et al_2018_SleepGuard.pdf:/Users/orsonxu/Zotero/storage/XFNE3MUQ/Chang et al_2018_SleepGuard.pdf:application/pdf},
}

@article{Vaizman2017,
	title = {Context {Recognition} {In}-the-{Wild}: {Unified} {Model} for {Multi}-{Modal} {Sensors} and {Multi}-{Label} {Classification}},
	volume = {1},
	issn = {24749567},
	url = {http://dl.acm.org/citation.cfm?doid=3178157.3161192},
	doi = {10.1145/3161192},
	abstract = {Automatic recognition of behavioral context (location, activities, body-posture etc.) can serve health monitoring, aging care, and many other domains. Recognizing context in-the-wild is challenging because of great variability in behavioral patterns, and it requires a complex mapping from sensor features to predicted labels. Data collected in-the-wild may be unbalanced and incomplete, with cases of missing labels or missing sensors. We propose using the multiple layer perceptron (MLP) as a multi-task model for context recognition. Based on features from multi-modal sensors, the model simultaneously predicts many diverse context labels. We analyze the advantages of the model's hidden layers, which are shared among all sensors and all labels, and provide insight to the behavioral patterns that these hidden layers may capture. We demonstrate how recognition of new labels can be improved when utilizing a model that was trained for an initial set of labels, and show how to train the model to withstand missing sensors. We evaluate context recognition on the previously published ExtraSensory Dataset, which was collected in-the-wild. Compared to previously suggested models, the MLP improves recognition, even with fewer parameters than a linear model. The ability to train a good model using data that has incomplete, unbalanced labeling and missing sensors encourages further research with uncontrolled, in-the-wild behavior.},
	number = {4},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Vaizman, Yonatan and Weibel, Nadir and Lanckriet, Gert},
	year = {2017},
	keywords = {Additional Key Words and Phrases, Behavioral context recognition, CCS Concepts, Multi-label classiication, Multi-modal sensing, Neural networks},
	pages = {1--22},
	file = {Vaizman et al_2017_Context Recognition In-the-Wild.pdf:/Users/orsonxu/Zotero/storage/TCNZJSRH/Vaizman et al_2017_Context Recognition In-the-Wild.pdf:application/pdf;Vaizman et al_2017_Context Recognition In-the-Wild.pdf:/Users/orsonxu/Zotero/storage/NU6S28EY/Vaizman et al_2017_Context Recognition In-the-Wild.pdf:application/pdf},
}

@article{Harari2017a,
	title = {Smartphone sensing methods for studying behavior in everyday life},
	volume = {18},
	issn = {23521546},
	doi = {10.1016/j.cobeha.2017.07.018},
	abstract = {Human behavior is the focus of many studies in the social, health, and behavioral sciences. Yet, few studies use behavioral observation methods to collect objective measures of behavior as it occurs in daily life, out in the real world — presumably the context of ultimate interest. Here, we provide a review of recent studies focused on measuring human behavior using smartphones and their embedded mobile sensors. To draw attention to current advances in the field of smartphone sensing, we describe the daily behaviors captured using these methods, which include movement behaviors (physical activity, mobility patterns), social behaviors (face-to-face encounters, computer-mediated communications), and other daily activities (non-mediated and mediated activities). We conclude by pointing to promising areas of future research for studies using Smartphone Sensing Methods (SSMs) in the behavioral sciences.},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Harari, Gabriella M. and Müller, Sandrine R. and Aung, Min SH and Rentfrow, Peter J.},
	year = {2017},
	pages = {83--90},
	file = {Harari et al_2017_Smartphone sensing methods for studying behavior in everyday life.pdf:/Users/orsonxu/Zotero/storage/XRG4CRIY/Harari et al_2017_Smartphone sensing methods for studying behavior in everyday life.pdf:application/pdf;Harari et al_2017_Smartphone sensing methods for studying behavior in everyday life.pdf:/Users/orsonxu/Zotero/storage/IAH2RFQ3/Harari et al_2017_Smartphone sensing methods for studying behavior in everyday life.pdf:application/pdf},
}

@article{Konstantinos2017,
	title = {Conquering the {City}: {Understanding} perceptions of {Mobility} and {Human} {Territoriality} in {Location}-based {Mobile} {Games}},
	volume = {1},
	issn = {02642751},
	doi = {10.1016/0264-2751(83)90005-7},
	abstract = {Choosing a title for the 1900 campaign in favour of the cities of Europe and for improving the quality of life in them was a difficult task for the experts of the Council of Europe. Before arriving at the rather weak term 'renaissance', alternatives ranging from 'renewal' to 'rehabilitation' and even 'reconquest' of the city were considered. This last term seems to me, in spite of its military connotations, to grasp the problem well enough. © 1983.},
	number = {2},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Konstantinos, Papangelis and Melvin, Metzger and Yiyeng, Sheng and Hai-Ning, Liang and Alan, Chamberlain and Ting, Cao},
	year = {2017},
	keywords = {acm reference format, game design, games, hybrid reality, hybrid spaces, image of space, location based services, location-based mobile games, locative media, multiplayer games, player mobility, playful spaces, territoriality},
	pages = {132--138},
	file = {Konstantinos et al_2017_Conquering the City.pdf:/Users/orsonxu/Zotero/storage/X7UVF7WF/Konstantinos et al_2017_Conquering the City.pdf:application/pdf;Konstantinos et al_2017_Conquering the City.pdf:/Users/orsonxu/Zotero/storage/2IQYJ74Y/Konstantinos et al_2017_Conquering the City.pdf:application/pdf},
}

@article{Dingler2017,
	title = {Building {Cognition}-{Aware} {Systems}: {A} {Mobile} {Toolkit} for {Extracting} {Time}-of-{Day} {Fluctuations} of {Cognitive} {Performance}},
	volume = {1},
	doi = {10.1145/3132025},
	number = {3},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Dingler, Tilman and Schmidt, Albrecht and Machulla, Tonja},
	year = {2017},
	keywords = {alertness, circadian rhythm, cognition-aware systems},
	pages = {1--15},
	file = {Dingler et al_2017_Building Cognition-Aware Systems.pdf:/Users/orsonxu/Zotero/storage/WF7A5KXF/Dingler et al_2017_Building Cognition-Aware Systems.pdf:application/pdf;Dingler et al_2017_Building Cognition-Aware Systems.pdf:/Users/orsonxu/Zotero/storage/8D8FLUYS/Dingler et al_2017_Building Cognition-Aware Systems.pdf:application/pdf},
}

@article{Mathur2017,
	title = {Moving {Beyond} {Market} {Research}: {Demystifying} {Smartphone} {User} {Behavior} in {India}},
	volume = {1},
	issn = {2474-9567},
	doi = {10.1145/3130947},
	abstract = {Large-scale mobile data studies can reveal valuable insights into user behavior, which in turn can assist system designers to create better user experiences. After a careful review of existing mobile data literature, we found that there have been no large-scale studies to understand smartphone usage behavior in India -- the second-largest and fastest growing smartphone market in the world. With the goal of understanding various facets of smartphone usage in India, we conducted a mixed-method longitudinal data collection study through an Android app released on Google Play. Our app was installed by 215 users, and logged 11.9 million data points from them over a period of 8 months. We analyzed this rich dataset along the lines of four broad facets of smartphone behavior -- how users use different apps, interact with notihcations, react to different contexts, and charge their smartphones -- to paint a holistic picture of smartphone usage behavior of Indian users. This quantitative analysis was complemented by a survey with 55 users and semi-structured interviews with 26 users to deeply understand their smartphone usage behavior. While our first-of-its-kind study uncovered many interesting facts about Indian smartphone users, we also found striking differences in usage behavior compared to past studies in other geographical contexts. We observed that Indian users spend significant time with their smartphones after midnight, continuously check notifications without attending to them and are extremely conscious about their smartphones’ battery. Perhaps the most dramatic finding is the nature of mobile consumerism of Indian users as shown by our results. Taken together, these and the rest of our findings demonstrate the unique characteristics that are shaping the smartphone usage behavior of Indian users.},
	number = {3},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Mathur, Akhil and Kalanadhabhatta, Lakshmi Manasa and Majethia, Rahul and Kawsar, Fahim},
	year = {2017},
	keywords = {- Human-centered computing  -{\textgreater} Empirical studies i},
	pages = {82:1--82:27},
	file = {Mathur et al_2017_Moving Beyond Market Research.pdf:/Users/orsonxu/Zotero/storage/QZC8WIUU/Mathur et al_2017_Moving Beyond Market Research.pdf:application/pdf;Mathur et al_2017_Moving Beyond Market Research.pdf:/Users/orsonxu/Zotero/storage/BMQZYBFE/Mathur et al_2017_Moving Beyond Market Research.pdf:application/pdf},
}

@article{Jeong2017,
	title = {Smartwatch {Wearing} {Behavior} {Analysis}: {A} {Longitudinal} {Study}},
	volume = {13},
	doi = {10.1145/3131892},
	abstract = {Smartwaches are the representative wearable or body-worn devices that provide convenient and easy information access. There is a growing body of research work on enabling novel interaction techniques and understanding user experiences of smartwatches. However, there is still lack of user experience research on wearing behaviors of smartwatches, which is critical for wearable device and service design. In this work, we investigate how college students wear smartwatches and what factors affect wearing behaviors by analyzing a longitudinal activity dataset collected from 50 smartwatch users for 203 days. Our results show that there are several temporal usage patterns and distinct groups of usage patterns. The factors affecting wearing behaviors are contextual, nuanced, and multifaceted. Our findings provide diverse design implications for improving wearability of smartwatches and leveraging smartwatches for behavioral changes.},
	number = {3},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Jeong, Hayeon and Heepyung Kim, Kaist and Rihun Kim, Kaist and Uichin Lee, Kaist and Yong Jeong, Kaist},
	year = {2017},
	keywords = {- Human-centered computing  -{\textgreater} Ubiquitous and mobi, Empirical studies in HCI, Empirical studies in ubiquitous and mobile computi},
	file = {Jeong et al_2017_Smartwatch Wearing Behavior Analysis.pdf:/Users/orsonxu/Zotero/storage/V2YG4MHW/Jeong et al_2017_Smartwatch Wearing Behavior Analysis.pdf:application/pdf;Jeong et al_2017_Smartwatch Wearing Behavior Analysis.pdf:/Users/orsonxu/Zotero/storage/SHS9WAZW/Jeong et al_2017_Smartwatch Wearing Behavior Analysis.pdf:application/pdf},
}

@article{Bae2017,
	title = {Detecting {Drinking} {Episodes} in {Young} {Adults} {Using} {Smartphone}-based {Sensors}},
	volume = {1},
	doi = {10.1145/3090051},
	abstract = {Alcohol use in young adults is common, with high rates of morbidity and mortality largely due to periodic, heavy drinking episodes (HDEs). Behavioral interventions delivered through electronic communication modalities (e.g., text messaging) can reduce the frequency of HDEs in young adults, but effects are small. One way to amplify these effects is to deliver support materials proximal to drinking occasions, but this requires knowledge of when they will occur. Mobile phones have built-in sensors that can potentially be useful in monitoring behavioral patterns associated with the initiation of drinking occasions. The objective of our work is to explore the detection of daily-life behavioral markers using mobile phone sensors and their utility in identifying drinking occasions. We utilized data from 30 young adults aged 21-28 with past hazardous drinking and collected mobile phone sensor data and daily Experience Sampling Method (ESM) of drinking for 28 consecutive days. We built a machine learning-based model that is 96.6\% accurate at identifying non-drinking, drinking and heavy drinking episodes. We highlight the most important features for detecting drinking episodes and identify the amount of historical data needed for accurate detection. Our results suggest that mobile phone sensors can be used for automated, continuous monitoring of at-risk populations to detect drinking episodes and support the delivery of timely interventions.},
	number = {2},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Bae, Sangwon and Ferreira, Denzil and Suffoletto, Brian and Puyana, Juan C. and Kurtz, Ryan and Chung, Tammy and Dey, Anind K.},
	year = {2017},
	pages = {1--36},
	file = {Bae et al_2017_Detecting Drinking Episodes in Young Adults Using Smartphone-based Sensors.pdf:/Users/orsonxu/Zotero/storage/LBHDAXU8/Bae et al_2017_Detecting Drinking Episodes in Young Adults Using Smartphone-based Sensors.pdf:application/pdf;Bae et al_2017_Detecting Drinking Episodes in Young Adults Using Smartphone-based Sensors.pdf:/Users/orsonxu/Zotero/storage/2JM4G2FB/Bae et al_2017_Detecting Drinking Episodes in Young Adults Using Smartphone-based Sensors.pdf:application/pdf},
}

@article{Aharony2011,
	title = {Social {fMRI}: {Investigating} and shaping social mechanisms in the real world},
	volume = {7},
	issn = {15741192},
	doi = {10.1016/j.pmcj.2011.09.004},
	abstract = {We introduce the Friends and Family study, a longitudinal living laboratory in a residential community. In this study, we employ a ubiquitous computing approach, Social Functional Mechanism-design and Relationship Imaging, or Social fMRI, that combines extremely rich data collection with the ability to conduct targeted experimental interventions with study populations. We present our mobile-phone-based social and behavioral sensing system, deployed in the wild for over 15 months. Finally, we present three investigations performed during the study, looking into the connection between individuals' social behavior and their financial status, network effects in decision making, and a novel intervention aimed at increasing physical activity in the subject population. Results demonstrate the value of social factors for choice, motivation, and adherence, and enable quantifying the contribution of different incentive mechanisms. © 2011 Elsevier B.V. All rights reserved.},
	number = {6},
	journal = {Pervasive and Mobile Computing},
	author = {Aharony, Nadav and Pan, Wei and Ip, Cory and Khayal, Inas and Pentland, Alex},
	year = {2011},
	keywords = {Mobile health, Mobile sensing, Rich data, Social computing, Social health},
	pages = {643--659},
	file = {Aharony et al_2011_Social fMRI.pdf:/Users/orsonxu/Zotero/storage/2WN68KYU/Aharony et al_2011_Social fMRI.pdf:application/pdf;Aharony et al_2011_Social fMRI.pdf:/Users/orsonxu/Zotero/storage/9CXZ6DA5/Aharony et al_2011_Social fMRI.pdf:application/pdf},
}

@article{Khan2013,
	title = {Mobile {Phone} {Sensing} {Systems} - {A} {Survey}},
	volume = {15},
	number = {1},
	author = {Khan, Wazir Zada and Xiang, Yang and Aalsalem, Mohammed Y and Arshad, Quratulain},
	year = {2013},
	pages = {402--427},
	file = {Khan et al_2013_Mobile Phone Sensing Systems - A Survey.pdf:/Users/orsonxu/Zotero/storage/L8DSMXJK/Khan et al_2013_Mobile Phone Sensing Systems - A Survey.pdf:application/pdf;Khan et al_2013_Mobile Phone Sensing Systems - A Survey.pdf:/Users/orsonxu/Zotero/storage/276Z92ZS/Khan et al_2013_Mobile Phone Sensing Systems - A Survey.pdf:application/pdf},
}

@inproceedings{SanChun2020,
	title = {Towards {Passive} {Assessment} of {Pulmonary} {Function} from {Natural} {Speech} {Recorded} {Using} a {Mobile} {Phone}},
	isbn = {978-1-72814-657-7},
	url = {https://ieeexplore.ieee.org/document/9127380/},
	doi = {10.1109/PerCom45495.2020.9127380},
	abstract = {Chronic obstructive pulmonary disease (COPD) and asthma are the most common respiratory diseases that impact millions of people worldwide annually. With advances in mobile computing and machine learning techniques, there has been increased interest in using mobile devices to monitor pulmonary diseases. Nevertheless, the current state-of-the-art technology requires active involvement and high-effort input from the users, impeding continuous monitoring of pulmonary conditions. In this work, two algorithms are proposed for passive assessment of pulmonary condition: one for detection of obstructive pulmonary disease and the other for estimation of the pulmonary function in terms of F EV1/F V C ratio, which is an established clinical metric. The algorithms were developed and validated using the data sets from two studies: research study (healthy=40, patholog-ical=91) and in-clinic study (healthy=10, pathological=60). From the cross-study validation where a classifier was trained on the research data set and tested on the in-clinic data set, the detection accuracy of the pathological class was obtained as 73.7\% and the F1 score was 84.5\% (87.2\% precision and 82.0\% recall). In our regression analysis, the F EV1/F V C ratio was predicted with a mean absolute error of 8.6\%. Our analysis shows promising results and this work presents a meaningful milestone towards the passive assessment of pulmonary functions from spontaneous speech collected from a mobile phone.},
	booktitle = {2020 {IEEE} {International} {Conference} on {Pervasive} {Computing} and {Communications} ({PerCom})},
	publisher = {IEEE},
	author = {Chun, Keum San and Nathan, Viswam and Vatanparvar, Korosh and Nemati, Ebrahim and Rahman, Md Mahbubur and Blackstock, Erin and Kuang, Jilong},
	month = mar,
	year = {2020},
	keywords = {Asthma, COPD, Index Terms-Mobile Computing, Inspiratory Sound, Natural Speech, Pulmonary Assessment},
	pages = {1--10},
	file = {Chun et al_2020_Towards Passive Assessment of Pulmonary Function from Natural Speech Recorded Using a Mobile Phone.pdf:/Users/orsonxu/Zotero/storage/ZIXB8254/Chun et al_2020_Towards Passive Assessment of Pulmonary Function from Natural Speech Recorded Using a Mobile Phone.pdf:application/pdf;Chun et al_2020_Towards Passive Assessment of Pulmonary Function from Natural Speech Recorded Using a Mobile Phone.pdf:/Users/orsonxu/Zotero/storage/C35VE5NQ/Chun et al_2020_Towards Passive Assessment of Pulmonary Function from Natural Speech Recorded Using a Mobile Phone.pdf:application/pdf},
}

@article{Rahman2020a,
	title = {Automated assessment of pulmonary patients using heart rate variability from everyday wearables},
	volume = {15},
	issn = {23526483},
	url = {https://doi.org/10.1016/j.smhl.2019.100081},
	doi = {10.1016/j.smhl.2019.100081},
	abstract = {Everyday wearables with enhanced computational capacity, good quality sensors, and machine learning/artificial intelligence enabled algorithms have the potential to play a key role not only in the fitness and wellness sector but also in the field of disease diagnostics and monitoring. The major challenges are a limited number of sensors, reliable data collection and processing, and deployment of computationally efficient algorithms. In this multi-cohort study, we have used everyday wearables such as chest band and smartwatch to investigate the heart rate variability (HRV) of 131 subjects which include 40 healthy controls, 69 asthma patients, 9 COPD patients and 13 patients with a co-morbidity of asthma and COPD. We aimed at a comprehensive investigation by exploring a total of 58 features including time domain, frequency domain, non-linear and entropy measures of HRV to identify the HRV indices that provide significant discriminatory information for classification between healthy and pulmonary patients. Feature ranking has been done by the area under the receiver operating characteristics curve. Classification of patients with the 15 top ranked features using data from the chest band heart rate sensor as well as estimated HRV parameters from smartwatch PPG signal have been investigated separately. Using the chest band data, a classification accuracy of 82.07\%, precision of 83.13\%, recall of 81.53\% and F-1 score of 81.7\% have been achieved; whereas using the smartwatch data, a classification accuracy of 80\%, precision of 79.9\%, recall of 80\% and F-1 score of 79.94\% have been achieved for the test set with an AdaBoost classifier. Heart rate variability metrics also showed significant correlation with disease severity and impact on health-related quality of life as measured by pulmonary function test, Asthma Symptoms Utility Index and COPD assessment test score respectively. The results indicate that HRV analysis using everyday wearables may be helpful in the assessment and management of asthma and COPD.},
	number = {November 2019},
	journal = {Smart Health},
	author = {Rahman, Md Juber and Nemati, Ebrahim and Rahman, Md Mahbubur and Nathan, Viswam and Vatanparvar, Korosh and Kuang, Jilong},
	month = mar,
	year = {2020},
	note = {Publisher: Elsevier Ltd},
	keywords = {Asthma, COPD, AdaBoost learning, Asthma symptoms utility index, COPD assessment test score, Heart rate variability, Wearables},
	pages = {100081},
	file = {Rahman et al_2020_Automated assessment of pulmonary patients using heart rate variability from everyday wearables.pdf:/Users/orsonxu/Zotero/storage/PVSP6GG7/Rahman et al_2020_Automated assessment of pulmonary patients using heart rate variability from everyday wearables.pdf:application/pdf;Rahman et al_2020_Automated assessment of pulmonary patients using heart rate variability from everyday wearables.pdf:/Users/orsonxu/Zotero/storage/JXTF3ZTA/Rahman et al_2020_Automated assessment of pulmonary patients using heart rate variability from everyday wearables.pdf:application/pdf},
}

@inproceedings{Viswanath2018,
	title = {{SpiroConfidence}: {Determining} the {Validity} of {Smartphone} {Based} {Spirometry} {Using} {Machine} {Learning}},
	isbn = {978-1-5386-3646-6},
	url = {https://ieeexplore.ieee.org/document/8513516/},
	doi = {10.1109/EMBC.2018.8513516},
	booktitle = {2018 40th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	publisher = {IEEE},
	author = {Viswanath, Varun and Garrison, Jake and Patel, Shwetak},
	month = jul,
	year = {2018},
	pages = {5499--5502},
}

@inproceedings{Rahman,
	title = {{ExhaleSense}: {Detecting} {High} {Fidelity} {Forced} {Exhalations} to {Estimate} {Lung} {Obstruction} on {Smartphones}},
	isbn = {978-1-72814-657-7},
	url = {https://ieeexplore.ieee.org/document/9127355/},
	doi = {10.1109/PerCom45495.2020.9127355},
	booktitle = {2020 {IEEE} {International} {Conference} on {Pervasive} {Computing} and {Communications} ({PerCom})},
	publisher = {IEEE},
	author = {Rahman, Md Mahbubur and Ahmed, Tousif and Nemati, Ebrahim and Nathan, Viswam and Vatanparvar, Korosh and Blackstock, Erin and Kuang, Jilong},
	month = mar,
	year = {2020},
	pages = {1--10},
	file = {Rahman et al_2020_ExhaleSense.pdf:/Users/orsonxu/Zotero/storage/QWQJP6W8/Rahman et al_2020_ExhaleSense.pdf:application/pdf;Rahman et al_2020_ExhaleSense.pdf:/Users/orsonxu/Zotero/storage/2C7Y93BP/Rahman et al_2020_ExhaleSense.pdf:application/pdf},
}

@article{Nemati2020a,
	title = {Estimation of the {Lung} {Function} {Using} {Acoustic} {Features} of the {Voluntary} {Cough}},
	journal = {EMBC},
	author = {Nemati, Ebrahim and Rahman, Juber and Blackstock, Erin and Nathan, Viswam and Rahman, Mahbubur and Vatanparvar, Korosh and Kuang, Jilong},
	year = {2020},
	file = {Nemati et al_2020_Estimation of the Lung Function Using Acoustic Features of the Voluntary Cough.pdf:/Users/orsonxu/Zotero/storage/RVMG3WVM/Nemati et al_2020_Estimation of the Lung Function Using Acoustic Features of the Voluntary Cough.pdf:application/pdf;Nemati et al_2020_Estimation of the Lung Function Using Acoustic Features of the Voluntary Cough.pdf:/Users/orsonxu/Zotero/storage/6Y4VANUT/Nemati et al_2020_Estimation of the Lung Function Using Acoustic Features of the Voluntary Cough.pdf:application/pdf},
}

@article{DeDomenico2013,
	title = {Interdependence and predictability of human mobility and social interactions},
	volume = {9},
	issn = {15741192},
	url = {http://dx.doi.org/10.1016/j.pmcj.2013.07.008},
	doi = {10.1016/j.pmcj.2013.07.008},
	abstract = {Previous studies have shown that human movement is predictable to a certain extent at different geographic scales. The existing prediction techniques exploit only the past history of the person taken into consideration as input of the predictors. In this paper, we show that by means of multivariate nonlinear time series prediction techniques it is possible to increase the forecasting accuracy by considering movements of friends, people, or more in general entities, with correlated mobility patterns (i.e., characterised by high mutual information) as inputs. Finally, we evaluate the proposed techniques on the Nokia Mobile Data Challenge and Cabspotting datasets. © 2013 Elsevier B.V. All rights reserved.},
	number = {6},
	journal = {Pervasive and Mobile Computing},
	author = {De Domenico, Manlio and Lima, Antonio and Musolesi, Mirco},
	month = dec,
	year = {2013},
	note = {Publisher: Elsevier B.V.},
	keywords = {Mobility prediction, Mutual information, Nonlinear time series analysis},
	pages = {798--807},
	file = {De Domenico et al_2013_Interdependence and predictability of human mobility and social interactions.pdf:/Users/orsonxu/Zotero/storage/9VJUCCKI/De Domenico et al_2013_Interdependence and predictability of human mobility and social interactions.pdf:application/pdf;De Domenico et al_2013_Interdependence and predictability of human mobility and social interactions.pdf:/Users/orsonxu/Zotero/storage/8KEHUF7E/De Domenico et al_2013_Interdependence and predictability of human mobility and social interactions.pdf:application/pdf},
}

@article{Ronao2016,
	title = {Human activity recognition with smartphone sensors using deep learning neural networks},
	volume = {59},
	issn = {09574174},
	url = {http://dx.doi.org/10.1016/j.eswa.2016.04.032},
	doi = {10.1016/j.eswa.2016.04.032},
	abstract = {Human activities are inherently translation invariant and hierarchical. Human activity recognition (HAR), a field that has garnered a lot of attention in recent years due to its high demand in various application domains, makes use of time-series sensor data to infer activities. In this paper, a deep convolutional neural network (convnet) is proposed to perform efficient and effective HAR using smartphone sensors by exploiting the inherent characteristics of activities and 1D time-series signals, at the same time providing a way to automatically and data-adaptively extract robust features from raw data. Experiments show that convnets indeed derive relevant and more complex features with every additional layer, although difference of feature complexity level decreases with every additional layer. A wider time span of temporal local correlation can be exploited (1 × 9-1 × 14) and a low pooling size (1 × 2-1 × 3) is shown to be beneficial. Convnets also achieved an almost perfect classification on moving activities, especially very similar ones which were previously perceived to be very difficult to classify. Lastly, convnets outperform other state-of-the-art data mining techniques in HAR for the benchmark dataset collected from 30 volunteer subjects, achieving an overall performance of 94.79\% on the test set with raw sensor data, and 95.75\% with additional information of temporal fast Fourier transform of the HAR data set.},
	journal = {Expert Systems with Applications},
	author = {Ronao, Charissa Ann and Cho, Sung-Bae},
	month = oct,
	year = {2016},
	note = {Publisher: Elsevier Ltd},
	keywords = {Smartphone, Sensors, Convolutional neural network, Deep learning, Human activity recognition},
	pages = {235--244},
	file = {Ronao_Cho_2016_Human activity recognition with smartphone sensors using deep learning neural networks.pdf:/Users/orsonxu/Zotero/storage/S9LRHRVZ/Ronao_Cho_2016_Human activity recognition with smartphone sensors using deep learning neural networks.pdf:application/pdf;Ronao_Cho_2016_Human activity recognition with smartphone sensors using deep learning neural networks.pdf:/Users/orsonxu/Zotero/storage/NBAT9AQR/Ronao_Cho_2016_Human activity recognition with smartphone sensors using deep learning neural networks.pdf:application/pdf},
}

@article{Wang2019b,
	title = {Deep learning for sensor-based activity recognition: {A} survey},
	volume = {119},
	issn = {01678655},
	url = {https://doi.org/10.1016/j.patrec.2018.02.010},
	doi = {10.1016/j.patrec.2018.02.010},
	abstract = {Sensor-based activity recognition seeks the profound high-level knowledge about human activities from multitudes of low-level sensor readings. Conventional pattern recognition approaches have made tremendous progress in the past years. However, those methods often heavily rely on heuristic hand-crafted feature extraction, which could hinder their generalization performance. Additionally, existing methods are undermined for unsupervised and incremental learning tasks. Recently, the recent advancement of deep learning makes it possible to perform automatic high-level feature extraction thus achieves promising performance in many areas. Since then, deep learning based methods have been widely adopted for the sensor-based activity recognition tasks. This paper surveys the recent advance of deep learning based sensor-based activity recognition. We summarize existing literature from three aspects: sensor modality, deep model, and application. We also present detailed insights on existing work and propose grand challenges for future research.},
	journal = {Pattern Recognition Letters},
	author = {Wang, Jindong and Chen, Yiqiang and Hao, Shuji and Peng, Xiaohui and Hu, Lisha},
	month = mar,
	year = {2019},
	note = {Publisher: Elsevier B.V.},
	keywords = {Activity recognition, Deep learning, Pattern recognition, Pervasive computing},
	pages = {3--11},
	file = {Wang et al_2019_Deep learning for sensor-based activity recognition.pdf:/Users/orsonxu/Zotero/storage/P3Q9FJGM/Wang et al_2019_Deep learning for sensor-based activity recognition.pdf:application/pdf;Wang et al_2019_Deep learning for sensor-based activity recognition.pdf:/Users/orsonxu/Zotero/storage/AF66Y6C3/Wang et al_2019_Deep learning for sensor-based activity recognition.pdf:application/pdf},
}

@article{Lane2011,
	title = {Enabling large-scale human activity inference on smartphones using {Community} {Similarity} {Networks} ({CSN})},
	doi = {10.1145/2030112.2030160},
	abstract = {Sensor-enabled smartphones are opening a new frontier in the development of mobile sensing applications. The recognition of human activities and context from sensor-data using classification models underpins these emerging applications. However, conventional approaches to training classifiers struggle to cope with the diverse user populations routinely found in large-scale popular mobile applications. Differences between users (e.g., age, sex, behavioral patterns, lifestyle) confuse classifiers, which assume everyone is the same. To address this, we propose Community Similarity Networks (CSN), which incorporates inter-person similarity measurements into the classifier training process. Under CSN every user has a unique classifier that is tuned to their own characteristics. CSN exploits crowd-sourced sensor-data to personalize classifiers with data contributed from other similar users. This process is guided by similarity networks that measure different dimensions of inter-person similarity. Our experiments show CSN outperforms existing approaches to classifier training under the presence of population diversity. © 2011 ACM.},
	journal = {UbiComp'11 - Proceedings of the 2011 ACM Conference on Ubiquitous Computing},
	author = {Lane, Nicholas D. and Xu, Ye and Lu, Hong and Hu, Shaohan and Choudhury, Tanzeem and Campbell, Andrew T. and Zhao, Feng},
	year = {2011},
	note = {ISBN: 9781450309103},
	keywords = {activity recognition, community learning, mobile phone sensing},
	pages = {355--364},
	file = {Lane et al_2011_Enabling large-scale human activity inference on smartphones using Community Similarity Networks (CSN).pdf:/Users/orsonxu/Zotero/storage/QPUJ7B99/Lane et al_2011_Enabling large-scale human activity inference on smartphones using Community Similarity Networks (CSN).pdf:application/pdf;Lane et al_2011_Enabling large-scale human activity inference on smartphones using Community Similarity Networks (CSN).pdf:/Users/orsonxu/Zotero/storage/SJS7EG6U/Lane et al_2011_Enabling large-scale human activity inference on smartphones using Community Similarity Networks (CSN).pdf:application/pdf},
}

@article{Abeßer2020,
	title = {A review of deep learning based methods for acoustic scene classification},
	volume = {10},
	issn = {20763417},
	doi = {10.3390/app10062020},
	abstract = {The number of publications on acoustic scene classification (ASC) in environmental audio recordings has constantly increased over the last few years. This was mainly stimulated by the annual Detection and Classification of Acoustic Scenes and Events (DCASE) competition with its first edition in 2013. All competitions so far involved one or multiple ASC tasks. With a focus on deep learning based ASC algorithms, this article summarizes and groups existing approaches for data preparation, i.e., feature representations, feature pre-processing, and data augmentation, and for data modeling, i.e., neural network architectures and learning paradigms. Finally, the paper discusses current algorithmic limitations and open challenges in order to preview possible future developments towards the real-life application of ASC systems.},
	number = {6},
	journal = {Applied Sciences (Switzerland)},
	author = {Abeßer, Jakob},
	year = {2020},
	keywords = {Acoustic scene classification, Deep neural networks, Machine listening},
	file = {Abeßer_2020_A review of deep learning based methods for acoustic scene classification.pdf:/Users/orsonxu/Zotero/storage/VVPVT4K7/Abeßer_2020_A review of deep learning based methods for acoustic scene classification.pdf:application/pdf;Abeßer_2020_A review of deep learning based methods for acoustic scene classification.pdf:/Users/orsonxu/Zotero/storage/BLJVBA57/Abeßer_2020_A review of deep learning based methods for acoustic scene classification.pdf:application/pdf},
}

@article{Mulry1984,
	title = {Experiencing the {Body} as {Play}},
	volume = {29},
	issn = {0002838X},
	abstract = {Chemical dependency is now recognized as a unified illness that includes alcoholism and other substance abuse syndromes. The chemically dependent person's primary relationship is with the experience of intoxication. The general course is loss of control, social disaster, denial and ethical deterioration. Treatment is best initiated at a resource that also offers a family treatment program. The denial system must be penetrated. Abstinence and group support, such as through Alcoholics Anonymous, facilitate ongoing recovery. An aftercare process is essential.},
	number = {3},
	journal = {Conference on Human Factors in Computing Systems},
	author = {Mueller, Florian ‘Floyd’ and Byrne, Richard and Andres, Josh and Patibanda, Rakesh},
	year = {2018},
	note = {ISBN: 9781450356206},
	pages = {285--290},
	file = {Mueller et al_2018_Experiencing the Body as Play.pdf:/Users/orsonxu/Zotero/storage/PGVQKM5P/Mueller et al_2018_Experiencing the Body as Play.pdf:application/pdf;Mueller et al_2018_Experiencing the Body as Play.pdf:/Users/orsonxu/Zotero/storage/4NK59PR9/Mueller et al_2018_Experiencing the Body as Play.pdf:application/pdf},
}

@article{Cohn2012,
	title = {Humantenna: {Using} the {Body} as an {Antenna} for {Real}-{Time} {Whole}-{Body} {Interaction}},
	doi = {10.1145/2207676.2208330},
	abstract = {Computer vision and inertial measurement have made it possible for people to interact with computers using whole-body gestures. Although there has been rapid growth in the uses and applications of these systems, their ubiquity has been limited by the high cost of heavily instrumenting either the environment or the user. In this paper, we use the human body as an antenna for sensing whole-body gestures. Such an approach requires no instrumentation to the environment, and only minimal instrumentation to the user, and thus enables truly mobile applications. We show robust gesture recognition with an average accuracy of 93\% across 12 whole-body gestures, and promising results for robust location classification within a building. In addition, we demonstrate a real-time interactive system which allows a user to interact with a computer using whole-body gestures.},
	author = {Cohn, Gabe and Morris, Daniel and Patel, Shwetak and Tan, Desney},
	year = {2012},
	note = {ISBN: 9781450310154},
	pages = {1901},
	file = {Cohn et al_2012_Humantenna.pdf:/Users/orsonxu/Zotero/storage/KD48VZHS/Cohn et al_2012_Humantenna.pdf:application/pdf;Cohn et al_2012_Humantenna.pdf:/Users/orsonxu/Zotero/storage/W6PF77VR/Cohn et al_2012_Humantenna.pdf:application/pdf},
}

@article{Adachi2013,
	title = {Human {SUGOROKU}: {Full}-body interaction system for students to learn vegetation succession},
	doi = {10.1145/2485760.2485830},
	abstract = {In this study, we developed a simulation game called "Human SUGOROKU" that consists of a full-body interaction system to enable elementary school students to enjoy and learn vegetation succession. The students' sense of immersion is improved by enabling them to play this game using their body movements. We conducted an experiment with the students and investigated the affects of the full-body interaction through interviews. The results showed that the full-body interaction promotes a sense of immersion in the game. This paper describes the structure of this system and the interview results. Copyright 2013 ACM.},
	journal = {ACM International Conference Proceeding Series},
	author = {Adachi, Takayuki and Goseki, Masafumi and Muratsu, Keita and Mizoguchi, Hiroshi and Namatame, Miki and Sugimoto, Masanori and Kusunoki, Fusako and Yamaguchi, Etsuji and Inagaki, Shigenori and Takeda, Yoshiaki},
	year = {2013},
	note = {ISBN: 9781450319188},
	keywords = {Embodiment, Interactive Content, Learning Support System, Ultrasonic Sensor},
	pages = {364--367},
	file = {Adachi et al_2013_Human SUGOROKU.pdf:/Users/orsonxu/Zotero/storage/RZVJVKZZ/Adachi et al_2013_Human SUGOROKU.pdf:application/pdf;Adachi et al_2013_Human SUGOROKU.pdf:/Users/orsonxu/Zotero/storage/WAFEEG7Z/Adachi et al_2013_Human SUGOROKU.pdf:application/pdf},
}

@article{Loke2013,
	title = {Moving and making strange: {An} {Embodied} {Approach} to {Movement}-{Based} {Interaction} {Design}},
	volume = {20},
	issn = {1073-0516},
	doi = {10.1145/2442106.2442113},
	abstract = {There is growing interest in designing for movement-based interactions with technology, now that various sensing technologies are available enabling a range of movement possibilities from gestural to whole-body interactions. We present a design methodology of Moving and Making Strange, an approach to movement-based interaction design that recognizes the central role of the body and movement in lived cognition. The methodology was developed through a series of empirical projects, each focusing on different conceptions of movement available within motion-sensing interactive, immersive spaces. The methodology offers designers a set of principles, perspectives, methods, and tools for exploring and testing movement-related design concepts. It is innovative for the inclusion of the perspective of the mover, together with the traditional perspectives of the observer and the machine. Making strange is put forward as an important tactic for rethinking how to approach the design of movement-based interaction.},
	number = {1},
	journal = {ACM Transactions on Computer-Human Interaction},
	author = {Loke, Lian and Robertson, Toni},
	year = {2013},
	pages = {1--25},
	file = {Loke_Robertson_2013_Moving and making strange.pdf:/Users/orsonxu/Zotero/storage/S2NQTEDM/Loke_Robertson_2013_Moving and making strange.pdf:application/pdf;Loke_Robertson_2013_Moving and making strange.pdf:/Users/orsonxu/Zotero/storage/NSF4R6DY/Loke_Robertson_2013_Moving and making strange.pdf:application/pdf},
}

@article{Fogtmann2008,
	title = {Kinesthetic {Interaction} - {Revealing} the bodily potential in interaction design},
	doi = {10.1145/1517744.1517770},
	abstract = {Within the Human-Computer Interaction community there is a growing interest in designing for the whole body in interaction design. The attempts aimed at addressing the body have very different outcomes spanning from theoretical arguments for understanding the body in the design process, to more practical examples of designing for bodily potential. This paper presents Kinesthetic Interaction as a unifying concept for describing the body in motion as a foundation for designing interactive systems. Based on the theoretical foundation for Kinesthetic Interaction, a conceptual framework is introduced to reveal bodily potential in relation to three design themes - kinesthetic development, kinesthetic means and kinesthetic disorder; and seven design parameters - engagement, sociality, movability, explicit motivation, implicit motivation, expressive meaning and kinesthetic empathy. The framework is a tool to be utilized when analyzing existing designs, as well as developing designs exploring new ways of designing kinesthetic interactions.},
	journal = {Proceedings of the 20th Australasian Conference on Computer-Human Interaction: Designing for Habitus and Habitat, OZCHI'08},
	author = {Fogtmann, Maiken Hillerup and Fritsch, Jonas and Kortbek, Karen Johanne},
	year = {2008},
	note = {ISBN: 0980306345},
	keywords = {Bodily movement, Interaction design, Interactive technologies, Kinesthesis, Kinesthetic experience, Kinesthetic interaction, Motor skills},
	pages = {89--96},
	file = {Fogtmann et al_2008_Kinesthetic Interaction - Revealing the bodily potential in interaction design.pdf:/Users/orsonxu/Zotero/storage/4THFPISI/Fogtmann et al_2008_Kinesthetic Interaction - Revealing the bodily potential in interaction design.pdf:application/pdf;Fogtmann et al_2008_Kinesthetic Interaction - Revealing the bodily potential in interaction design.pdf:/Users/orsonxu/Zotero/storage/PA5TA7DJ/Fogtmann et al_2008_Kinesthetic Interaction - Revealing the bodily potential in interaction design.pdf:application/pdf},
}

@article{Kjolberg2004,
	title = {Designing full body movement interaction using modern dance as a starting point},
	doi = {10.1145/1013115.1013178},
	abstract = {This paper presents an ongoing doctoral project that concerns design and development of computer interfaces supporting full body movement interaction. It combines theories and experiences from dance education and HCI. The main aim is to try out a new approach to develop concepts of movement-based interaction. The work consists of an explorative case study aiming at describing the learning process that HCI students and professionals experience when attending a course in Physical Expression, based on modern dance and improvisation. A second aim is to describe the possible reflection of this experience in the design outcome. The third aim is to develop an example of a full body movement-based environment. The study is using a qualitative approach and makes use of data as interviews, video, texts and design mock-ups. Preliminary results show that the course provides new perspectives on bodily communication and may function as a "mind opener".},
	journal = {DIS2004 - Designing Interactive Systems: Across the Spectrum},
	author = {Kjölberg, Jin},
	year = {2004},
	note = {ISBN: 1581137877},
	keywords = {Art, Full body movement interaction, Learning processes, Modern dance, Physical experience},
	pages = {353--356},
	file = {Kjölberg_2004_Designing full body movement interaction using modern dance as a starting point.pdf:/Users/orsonxu/Zotero/storage/QZUKER3P/Kjölberg_2004_Designing full body movement interaction using modern dance as a starting point.pdf:application/pdf;Kjölberg_2004_Designing full body movement interaction using modern dance as a starting point.pdf:/Users/orsonxu/Zotero/storage/QSF7ALQ8/Kjölberg_2004_Designing full body movement interaction using modern dance as a starting point.pdf:application/pdf},
}

@article{Daiber2009,
	title = {Whole body interaction with geospatial data},
	volume = {5531 LNCS},
	issn = {03029743},
	doi = {10.1007/978-3-642-02115-2_7},
	abstract = {Common Geographic Information Systems (GIS) require a high degree of expertise from its users, making them difficult to be operated by laymen. This paper describes novel approaches to easily perform typical basic spatial tasks within a GIS: e.g. pan-, zoom- and selection-operations by using multi-touch gestures in combination with foot gestures. We are interested in understanding how non-expert users interact with such multi-touch surfaces. We provide a categorization and a framework of multi-touch hand gestures for interacting with a GIS. This framework is based on an initial evaluation. We present results of a more detailed in situ-study mainly focusing on multi-user multi-touch interaction with geospatial data. Furthermore we extend our framework using a combination of multi-touch gestures with a small set of foot gestures to solve geospatial tasks. © 2009 Springer Berlin Heidelberg.},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Daiber, Florian and Schöning, Johannes and Krüger, Antonio},
	year = {2009},
	note = {ISBN: 364202114X},
	pages = {81--92},
	file = {Daiber et al_2009_Whole body interaction with geospatial data.pdf:/Users/orsonxu/Zotero/storage/RPJ7VAG5/Daiber et al_2009_Whole body interaction with geospatial data.pdf:application/pdf;Daiber et al_2009_Whole body interaction with geospatial data.pdf:/Users/orsonxu/Zotero/storage/SD8NIZQN/Daiber et al_2009_Whole body interaction with geospatial data.pdf:application/pdf},
}

@article{Gerling2012,
	title = {Full-body motion-based game interaction for older adults},
	doi = {10.1145/2207676.2208324},
	abstract = {Older adults in nursing homes often lead sedentary lifestyles, which reduces their life expectancy. Full-body motion-control games provide an opportunity for these adults to remain active and engaged; these games are not designed with age-related impairments in mind, which prevents the games from being leveraged to increase the activity levels of older adults. In this paper, we present two studies aimed at developing game design guidelines for full-body motion controls for older adults experiencing age-related changes and impairments. Our studies also demonstrate how full-body motion-control games can accommodate a variety of user abilities, have a positive effect on mood and, by extension, the emotional well-being of older adults. Based on our studies, we present seven guidelines for the design of full-body interaction in games. The guidelines are designed to foster safe physical activity among older adults, thereby increasing their quality of life. Copyright 2012 ACM.},
	journal = {Conference on Human Factors in Computing Systems},
	author = {Gerling, Kathrin M. and Livingston, Ian J. and Nacke, Lennart E. and Mandryk, Regan L.},
	year = {2012},
	note = {ISBN: 9781450310154},
	keywords = {Games, Design, Entertainment, Older adults},
	pages = {1873--1882},
	file = {Gerling et al_2012_Full-body motion-based game interaction for older adults.pdf:/Users/orsonxu/Zotero/storage/K4LGL523/Gerling et al_2012_Full-body motion-based game interaction for older adults.pdf:application/pdf;Gerling et al_2012_Full-body motion-based game interaction for older adults.pdf:/Users/orsonxu/Zotero/storage/4ZGQ42XF/Gerling et al_2012_Full-body motion-based game interaction for older adults.pdf:application/pdf},
}

@article{Schonauer2011,
	title = {Full body interaction for serious games in motor rehabilitation},
	doi = {10.1145/1959826.1959830},
	abstract = {Serious games and especially their use in healthcare applications are an active and rapidly growing area of research. A key aspect of games in rehabilitation is 3D input. In this paper we present our implementation of a full body motion capture (MoCap) system, which, together with a biosignal acquisition device, has been integrated in a game engine. Furthermore, a workow has been established that enables the use of acquired skeletal data for serious games in a medical environment. Finally, a serious game has been implemented, targeting rehabilitation of patients with chronic pain of the lower back and neck, a group that has previously been neglected by serious games. The focus of this work is on the full body MoCap system and its integration with biosignal devices and the game engine. A short overview of the application and prelimiary results are provided. Copyright 2011 ACM.},
	journal = {ACM International Conference Proceeding Series},
	author = {Schönauer, Christian and Pintaric, Thomas and Kaufmann, Hannes},
	year = {2011},
	note = {ISBN: 9781450304269},
	keywords = {Motion capture, Motor rehabilitation, Serious games},
	file = {Schönauer et al_2011_Full body interaction for serious games in motor rehabilitation.pdf:/Users/orsonxu/Zotero/storage/DAL8P3N5/Schönauer et al_2011_Full body interaction for serious games in motor rehabilitation.pdf:application/pdf;Schönauer et al_2011_Full body interaction for serious games in motor rehabilitation.pdf:/Users/orsonxu/Zotero/storage/P4DVHILI/Schönauer et al_2011_Full body interaction for serious games in motor rehabilitation.pdf:application/pdf},
}

@article{OSullivan2016,
	title = {Cyclops: {Wearable} and {Single}-{Piece} {Full}-{Body} {Gesture} {Input} {Devices}},
	doi = {10.1002/9781119257530.ch22},
	abstract = {Euripides' Cyclops is the only complete example we have of a genre known as satyr play, and retells the story, famously recounted by Homer in Book 9 of the Odyssey, of Odysseus' blinding of the man-eating, one-eyed monster, Polyphemos. During the Classical period at the City Dionysia these dramas, which featured a Chorus of part-animal, part-man followers of Dionysos known as satyrs, accompanied three tragedies to comprise an overall tetralogy and were written by the tragedians themselves. Satyr play was a highly self-conscious genre enagaging not only with the same sorts of myths as tragedy, but also with specific literary forms including epic and tragic poetry. Euripides' Cyclops embodies many of the tropes of satyric drama generally, many of which have been identified as folktale motifs. Euripides' Cyclops depicts a potentially more serious side to these paradoxical creatures, whose ambivalence is evident elsewhere in Greek literature and thought.},
	journal = {CHI},
	author = {Chan, Liwei and Hsieh, Chi-Hao and Chen, Yi-Ling and Yang, Shuo and Huang, Da-Yuan and Liang, Rong-Hao and Chen, Bing-Yu},
	year = {2015},
	note = {ISBN: 9781119257530},
	keywords = {Euripides, Greek literature, Homer, Odyssey, Polyphemos},
	pages = {313--333},
	file = {Chan et al_2015_Cyclops.pdf:/Users/orsonxu/Zotero/storage/VTN3WNEC/Chan et al_2015_Cyclops.pdf:application/pdf;Chan et al_2015_Cyclops.pdf:/Users/orsonxu/Zotero/storage/59XQT6IV/Chan et al_2015_Cyclops.pdf:application/pdf},
}

@article{Beckhaus,
	title = {{ChairIO} – {The} {Chair}-{Based} {Interface}},
	journal = {Concepts and technologies for pervasive games},
	author = {Beckhaus, Steffi and Blom, Kristopher J and Haringer, Matthias},
	year = {2007},
	file = {Beckhaus et al_2007_ChairIO – The Chair-Based Interface.pdf:/Users/orsonxu/Zotero/storage/IQA3BC3R/Beckhaus et al_2007_ChairIO – The Chair-Based Interface.pdf:application/pdf;Beckhaus et al_2007_ChairIO – The Chair-Based Interface.pdf:/Users/orsonxu/Zotero/storage/CARVHJRD/Beckhaus et al_2007_ChairIO – The Chair-Based Interface.pdf:application/pdf},
}

@article{Gubbiotti2017,
	title = {{TouchCam}: {Realtime} {Recognition} of {Location}-{Specific} {On}-{Body} {Gestures} to {Support} {Users} with {Visual} {Impairments}},
	volume = {1},
	doi = {10.1145/1234},
	number = {4},
	journal = {IMWUT},
	author = {Gubbiotti, G. and Malagò, P. and Fin, S. and Tacchi, S. and Giovannini, L. and Bisero, D. and Madami, M. and Carlotti, G.},
	year = {2017},
	keywords = {acm reference format, accessibility, blind and low-vision users, classi fi cation, computer vision applications, gesture recognition, on-body input, skin texture, skin texture classification, wearable sensors},
	pages = {1--4},
	file = {Gubbiotti et al_2017_TouchCam.pdf:/Users/orsonxu/Zotero/storage/3RLQ38JM/Gubbiotti et al_2017_TouchCam.pdf:application/pdf;Gubbiotti et al_2017_TouchCam.pdf:/Users/orsonxu/Zotero/storage/2P6G28E7/Gubbiotti et al_2017_TouchCam.pdf:application/pdf},
}

@article{Hoang2018,
	title = {Body as a {Canvas}: {An} {Exploration} on the {Role} of the {Body} as {Display} of {Digital} {Information}},
	doi = {10.1145/3196709.3196724},
	abstract = {Human body in HCI is often seen as an actuator for issuing commands and providing input to digital systems. We present the concept of the body as a canvas, in which the body acts as both an actuator and a display for information. Body as a canvas creates an interaction loop where interaction with information causes changes in the body, which in turn changes the display of information. Our qualitative study using an on-body projection system in a public exhibition investigates this concept with regards to body characteristics, types of body input, interactions between multiple bodies, and comparison to other display technologies. Our findings show that body as a canvas create connectedness between the body and information. Finally, we discuss how body characteristics and appearances can complement the information, when the body acts as a canvas.},
	journal = {DIS},
	author = {Hoang, Thuong N. and Ferdous, Hasan S. and Vetere, Frank and Reinoso, Martin},
	year = {2018},
	keywords = {Body as a canvas},
	pages = {253--263},
	file = {Hoang et al_2018_Body as a Canvas.pdf:/Users/orsonxu/Zotero/storage/V7HEP8CS/Hoang et al_2018_Body as a Canvas.pdf:application/pdf;Hoang et al_2018_Body as a Canvas.pdf:/Users/orsonxu/Zotero/storage/54ZA7WRR/Hoang et al_2018_Body as a Canvas.pdf:application/pdf},
}

@article{Amoh2016,
	title = {Deep {Neural} {Networks} for {Identifying} {Cough} {Sounds}},
	volume = {10},
	number = {5},
	journal = {IEEETransactions On Biomedical Circuits And Systems},
	author = {Amoh, Justice and Odame, Kofi},
	year = {2016},
	note = {Publisher: IEEE},
	pages = {1003--1011},
	file = {Amoh_Odame_2016_Deep Neural Networks for Identifying Cough Sounds.pdf:/Users/orsonxu/Zotero/storage/Y8I2J5KP/Amoh_Odame_2016_Deep Neural Networks for Identifying Cough Sounds.pdf:application/pdf;Amoh_Odame_2016_Deep Neural Networks for Identifying Cough Sounds.pdf:/Users/orsonxu/Zotero/storage/IC4XGATW/Amoh_Odame_2016_Deep Neural Networks for Identifying Cough Sounds.pdf:application/pdf},
}

@article{Rahman2014,
	title = {{BodyBeat}: {A} mobile system for sensing non-speech body sounds},
	doi = {10.1145/2594368.2594386},
	abstract = {In this paper, we propose BodyBeat, a novel mobile sensing system for capturing and recognizing a diverse range of non-speech body sounds in real-life scenarios. Non-speech body sounds, such as sounds of food intake, breath, laughter, and cough contain invaluable information about our dietary behavior, respiratory physiology, and affect. The BodyBeat mobile sensing system consists of a custom-built piezoelectric microphone and a distributed computational framework that utilizes an ARM microcontroller and an Android smartphone. The custom-built microphone is designed to capture subtle body vibrations directly from the body surface without being perturbed by external sounds. The microphone is attached to a 3D printed neckpiece with a suspension mechanism. The ARM embedded system and the Android smartphone process the acoustic signal from the microphone and identify non-speech body sounds. We have extensively evaluated the BodyBeat mobile sensing system. Our results show that BodyBeat outperforms other existing solutions in capturing and recognizing different types of important non-speech body sounds. © 2014 ACM.},
	journal = {MobiSys 2014 - Proceedings of the 12th Annual International Conference on Mobile Systems, Applications, and Services},
	author = {Rahman, Tauhidur and Adams, Alexander T. and Zhang, Mi and Cherry, Erin and Zhou, Bobby and Peng, Huaishu and Choudhury, Tanzeem},
	year = {2014},
	note = {ISBN: 9781450327930},
	keywords = {mobile sensing, acoustic signal processing, embedded systems, non-speech body sound},
	pages = {2--13},
	file = {Rahman et al_2014_BodyBeat.pdf:/Users/orsonxu/Zotero/storage/ABT6JRPP/Rahman et al_2014_BodyBeat.pdf:application/pdf;Rahman et al_2014_BodyBeat.pdf:/Users/orsonxu/Zotero/storage/83MYI8UD/Rahman et al_2014_BodyBeat.pdf:application/pdf},
}

@article{Ahmed2019a,
	title = {Deeplung: {Smartphone} convolutional neural network-based inference of lung anomalies for pulmonary patients},
	volume = {2019-Septe},
	issn = {19909772},
	doi = {10.21437/Interspeech.2019-2953},
	abstract = {DeepLung is an end-to-end deep learning based audio sensing and classification framework for lung anomaly (e.g. cough, wheeze) detection for pulmonary patients from streaming audio and inertial sensor data from a chest-held smartphone. We design and develop 1-D and 2-D convolutional neural networks for DeepLung, and train them using the Interspeech 2010 Paralinguistic Challenge features. Two different audio windowing schemes: i) real-time respiration cycle based natural windowing, and ii) static length windowing are compared and experimented with. Classifiers are developed considering 2 different system architectures: i) mobile-cloud hybrid architecture, and ii) mobile in-situ architecture. Patient privacy is preserved in the phone by filtering speech with a shallow classifier. To evaluate DeepLung, a novel and rigorous lung activity dataset is made by collecting audio and inertial sensor data from more than 131 real pulmonary patients and healthy subjects and annotated accurately by professional crowdsourcing. Experimental results show that the best combination of DeepLung convolutional neural network is 15-27\% more accurate when compared to a state-of-the-art smartphone based body sound detection system, with a best F1 score of 98\%.},
	journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
	author = {Ahmed, Mohsin Y. and Rahman, Md Mahbubur and Kuang, Jilong},
	year = {2019},
	keywords = {Smartphone, Convolutional neural network, Pulmonary diseases},
	pages = {2335--2339},
	file = {Ahmed et al_2019_Deeplung.pdf:/Users/orsonxu/Zotero/storage/WM9HCVB4/Ahmed et al_2019_Deeplung.pdf:application/pdf;Ahmed et al_2019_Deeplung.pdf:/Users/orsonxu/Zotero/storage/W5Q3HPAE/Ahmed et al_2019_Deeplung.pdf:application/pdf},
}

@article{Oord2016,
	title = {{WaveNet}: {A} {Generative} {Model} for {Raw} {Audio}},
	url = {http://arxiv.org/abs/1609.03499},
	abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
	author = {Oord, Aaron van den and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
	year = {2016},
	pages = {1--15},
	file = {Oord et al_2016_WaveNet.pdf:/Users/orsonxu/Zotero/storage/NK4MKNFF/Oord et al_2016_WaveNet.pdf:application/pdf;Oord et al_2016_WaveNet.pdf:/Users/orsonxu/Zotero/storage/MJUBEPZ3/Oord et al_2016_WaveNet.pdf:application/pdf},
}

@article{Saba2018,
	title = {Techniques for {Cough} {Sound} {Analysis}},
	url = {http://search.ebscohost.com/login.aspx?direct=true&db=ddu&AN=2FC8B44C93BACE56&site=ehost-live},
	abstract = {Coughing is a common symptom of pulmonary ailment and serves as a valuable measure when quantifying pulmonary health. This dissertation contains the results of the research and development of a set of techniques to enable researchers to investigate pulmonary health through cough sounds. A variety of signal processing and machine learning approaches are included, each with various performance and usability tradeoffs. We propose a novel algorithm that makes use of the best of the traditional signal processing approaches, combined with the recent advances in deep learning to provide new cough detection and classification results previously unattainable, especially when considered in the context of model runtime performance. We detail the construction a classifier for tuberculosis coughs, and develop a new tool to deal with bifurcated datasets we dub a discriminative adversarial network.},
	journal = {PhD Thesis},
	author = {Saba, Elliot},
	year = {2018},
	keywords = {Electrical engineering, Engineering},
	file = {Saba_2018_Techniques for Cough Sound Analysis.pdf:/Users/orsonxu/Zotero/storage/SGF64WDE/Saba_2018_Techniques for Cough Sound Analysis.pdf:application/pdf;Saba_2018_Techniques for Cough Sound Analysis.pdf:/Users/orsonxu/Zotero/storage/DF9HPBTR/Saba_2018_Techniques for Cough Sound Analysis.pdf:application/pdf},
}

@article{AlHossain2020,
	title = {{FluSense}: {A} {Contactless} {Syndromic} {Surveillance} {Platform} for {Influenza}-{Like} {Illness} in {Hospital} {Waiting} {Areas}},
	volume = {4},
	issn = {2474-9567},
	doi = {10.1145/3381014},
	abstract = {We developed a contactless syndromic surveillance platform FluSense that aims to expand the current paradigm of influenza-like illness (ILI) surveillance by capturing crowd-level bio-clinical signals directly related to physical symptoms of ILI from hospital waiting areas in an unobtrusive and privacy-sensitive manner. FluSense consists of a novel edge-computing sensor system, models and data processing pipelines to track crowd behaviors and influenza-related indicators, such as coughs, and to predict daily ILI and laboratory-confirmed influenza caseloads. FluSense uses a microphone array and a thermal camera along with a neural computing engine to passively and continuously characterize speech and cough sounds along with changes in crowd density on the edge in a real-time manner. We conducted an IRB-approved 7 month-long study from December 10, 2018 to July 12, 2019 where we deployed FluSense in four public waiting areas within the hospital of a large university. During this period, the FluSense platform collected and analyzed more than 350,000 waiting room thermal images and 21 million non-speech audio samples from the hospital waiting areas. FluSense can accurately predict daily patient counts with a Pearson correlation coefficient of 0.95. We also compared signals from FluSense with the gold standard laboratory-confirmed influenza case data obtained in the same facility and found that our sensor-based features are strongly correlated with laboratory-confirmed influenza trends.},
	number = {1},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Al Hossain, Forsad and Lover, Andrew and Corey, George and Reich, Nicholas and Rahman, Tauhidur},
	year = {2020},
	pages = {1--28},
	file = {Al Hossain et al_2020_FluSense.pdf:/Users/orsonxu/Zotero/storage/ZFLY6W8R/Al Hossain et al_2020_FluSense.pdf:application/pdf;Al Hossain et al_2020_FluSense.pdf:/Users/orsonxu/Zotero/storage/68247XGP/Al Hossain et al_2020_FluSense.pdf:application/pdf},
}

@article{Lane2015a,
	title = {{DeepEar}: {Robust} smartphone audio sensing in unconstrained acoustic environments using deep learning},
	doi = {10.1145/2750858.2804262},
	abstract = {Microphones are remarkably powerful sensors of human behavior and context. However, audio sensing is highly susceptible to wild fluctuations in accuracy when used in diverse acoustic environments (such as, bedrooms, vehicles, or cafes), that users encounter on a daily basis. Towards addressing this challenge, we turn to the field of deep learning; an area of machine learning that has radically changed related audio modeling domains like speech recognition. In this paper, we present DeepEar - the first mobile audio sensing framework built from coupled Deep Neural Networks (DNNs) that simultaneously perform common audio sensing tasks. We train DeepEar with a large-scale dataset including unlabeled data from 168 place visits. The resulting learned model, involving 2.3M parameters, enables DeepEar to significantly increase inference robustness to background noise beyond conventional approaches present in mobile devices. Finally, we show DeepEar is feasible for smartphones by building a cloud-free DSP-based prototype that runs continuously, using only 6\% of the smartphone's battery daily.},
	journal = {UbiComp 2015 - Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
	author = {Lane, Nicholas D. and Georgiev, Petko and Qendro, Lorena},
	year = {2015},
	note = {ISBN: 9781450335744},
	keywords = {Audio Sensing, Deep Learning, Mobile Sensing},
	pages = {283--294},
	file = {Lane et al_2015_DeepEar.pdf:/Users/orsonxu/Zotero/storage/DHHRRSI7/Lane et al_2015_DeepEar.pdf:application/pdf;Lane et al_2015_DeepEar.pdf:/Users/orsonxu/Zotero/storage/LUPYJR6Z/Lane et al_2015_DeepEar.pdf:application/pdf},
}

@article{Hao2013,
	title = {{iSleep}: {Unobtrusive} {Sleep} {Quality} {Monitoring} using {Smartphones}},
	doi = {10.1145/2517351.2517359},
	abstract = {iSleep uses the built-in microphone of the smart- phone to detect the events that are closely related to sleep quality, including body movement, couch and snore, and in- fers quantitative measures of sleep quality.},
	journal = {SenSys},
	author = {Hao, Tian and Xing, Guoliang and Zhou, Gang},
	year = {2013},
	note = {ISBN: 9781450311694},
	pages = {1--14},
	file = {Hao et al_2013_iSleep.pdf:/Users/orsonxu/Zotero/storage/W7FSK4BR/Hao et al_2013_iSleep.pdf:application/pdf;Hao et al_2013_iSleep.pdf:/Users/orsonxu/Zotero/storage/SZCBQG2M/Hao et al_2013_iSleep.pdf:application/pdf},
}

@article{Larson2011,
	title = {Accurate and privacy preserving cough sensing using a low-cost microphone},
	doi = {10.1145/2030112.2030163},
	abstract = {Audio-based cough detection has become more pervasive in recent years because of its utility in evaluating treatments and the potential to impact the quality of life for individuals with chronic cough. We critically examine the current state of the art in cough detection, concluding that existing approaches expose private audio recordings of users and bystanders. We present a novel algorithm for detecting coughs from the audio stream of a mobile phone. Our system allows cough sounds to be reconstructed from the feature set, but prevents speech from being reconstructed intelligibly. We evaluate our algorithm on data collected in the wild and report an average true positive rate of 92\% and false positive rate of 0.5\%. We also present the results of two psychoacoustic experiments which characterize the tradeoff between the fidelity of reconstructed cough sounds and the intelligibility of reconstructed speech. © 2011 ACM.},
	number = {3},
	journal = {UbiComp'11 - Proceedings of the 2011 ACM Conference on Ubiquitous Computing},
	author = {Larson, Eric C. and Lee, Tienjui and Liu, Sean and Rosenfeld, Margaret and Patel, Shwetak N.},
	year = {2011},
	note = {ISBN: 9781450309103},
	keywords = {privacy, cough detection, health, mobile phones, sensing, signal processing},
	pages = {375--384},
	file = {Larson et al_2011_Accurate and privacy preserving cough sensing using a low-cost microphone.pdf:/Users/orsonxu/Zotero/storage/JWHW9WZG/Larson et al_2011_Accurate and privacy preserving cough sensing using a low-cost microphone.pdf:application/pdf;Larson et al_2011_Accurate and privacy preserving cough sensing using a low-cost microphone.pdf:/Users/orsonxu/Zotero/storage/MURFIP8W/Larson et al_2011_Accurate and privacy preserving cough sensing using a low-cost microphone.pdf:application/pdf},
}

@article{Shin2009,
	title = {Automatic detection system for cough sounds as a symptom of abnormal health condition},
	volume = {13},
	issn = {10897771},
	doi = {10.1109/TITB.2008.923771},
	abstract = {The problem of attending to the health of the aged who live alone has became an important issue in developed countries. One way of solving the problem is to check their health condition by a remote-monitoring technique and support them with well-timed treatment. The purpose of this study is to develop an automatic system that can monitor a health condition in real time using acoustical information and detect an abnormal symptom. In this study, cough sound was chosen as a representative acoustical symptom of abnormal health conditions. For the development of the system distinguishing a cough sound from other environmental sounds, a hybrid model was proposed that consists of an artificial neural network (ANN) model and a hidden Markov model (HMM). The ANN model used energy cepstral coefficients obtained by filter banks based on human auditory characteristics as input parameters representing a spectral feature of a sound signal. Subsequently, an output of this ANN model and a filtered envelope of the signal were used for making an input sequence for the HMM that deals with the temporal variation of the sound signal. Compared with the conventional HMM using Mel-frequency cepstral coefficients, the proposed hybrid model improved recognition rates on low SNR from 5 dB down to -10 dB. Finally, a preliminary prototype of the automatic detection system was simply illustrated. © 2009 IEEE.},
	number = {4},
	journal = {IEEE Transactions on Information Technology in Biomedicine},
	author = {Shin, Sung Hwan and Hashimoto, Takeo and Hatano, Shigeko},
	year = {2009},
	keywords = {Automatic detection, Cough sound, Health monitoring, Hybrid model},
	pages = {486--493},
	file = {Shin et al_2009_Automatic detection system for cough sounds as a symptom of abnormal health condition.pdf:/Users/orsonxu/Zotero/storage/VVQ8K247/Shin et al_2009_Automatic detection system for cough sounds as a symptom of abnormal health condition.pdf:application/pdf;Shin et al_2009_Automatic detection system for cough sounds as a symptom of abnormal health condition.pdf:/Users/orsonxu/Zotero/storage/CVLIK24N/Shin et al_2009_Automatic detection system for cough sounds as a symptom of abnormal health condition.pdf:application/pdf},
}

@article{Sun2015,
	title = {{SymDetector}: {Detecting} sound-related respiratory symptoms using smartphones},
	doi = {10.1145/2750858.2805826},
	abstract = {This paper proposes SymDetector, a smartphone based application to unobtrusively detect the sound-related respiratory symptoms occurred in a user's daily life, including sneeze, cough, sniffle and throat clearing. SymDetector uses the builtin microphone on the smartphone to continuously monitor a user's acoustic data and uses multi-level processes to detect and classify the respiratory symptoms. Several practical issues are considered in developing SymDetector, such as users' privacy concerns about their acoustic data, resource constraints of the smartphone and different contexts of the smartphone. We have implemented SymDetector on Galaxy S3 and evaluated its performance in real experiments involving 16 users and 204 days. The experimental results show that SymDetector can detect these four types of respiratory symptoms with high accuracy under various conditions.},
	journal = {UbiComp 2015 - Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
	author = {Sun, Xiao and Lu, Zongqing and Hu, Wenjie and Cao, Guohong},
	year = {2015},
	note = {ISBN: 9781450335744},
	keywords = {Smartphone, Feature extraction, Microphone, Respiratory symptom detection},
	pages = {97--108},
	file = {Sun et al_2015_SymDetector.pdf:/Users/orsonxu/Zotero/storage/WHBUQHJ4/Sun et al_2015_SymDetector.pdf:application/pdf;Sun et al_2015_SymDetector.pdf:/Users/orsonxu/Zotero/storage/G5UY6XTA/Sun et al_2015_SymDetector.pdf:application/pdf},
}

@article{Imran2020,
	title = {{AI4COVID}-19: {AI} {Enabled} {Preliminary} {Diagnosis} for {COVID}-19 from {Cough} {Samples} via an {App}},
	url = {http://arxiv.org/abs/2004.01275},
	abstract = {Inability to test at scale has become Achille's heel in humanity's ongoing war against COVID-19 pandemic. An agile, scalable and cost-effective testing, deployable at a global scale, can act as a game changer in this war. To address this challenge, building on the promising results of our prior work on cough-based diagnosis of a motley of respiratory diseases, we develop an Artificial Intelligence (AI)-based test for COVID-19 preliminary diagnosis. The test is deployable at scale through a mobile app named AI4COVID-19. The AI4COVID-19 app requires 2-second cough recordings of the subject. By analyzing the cough samples through an AI engine running in the cloud, the app returns a preliminary diagnosis within a minute. Unfortunately, cough is common symptom of over two dozen non-COVID-19 related medical conditions. This makes the COVID-19 diagnosis from cough alone an extremely challenging problem. We solve this problem by developing a novel multi-pronged mediator centered risk-averse AI architecture that minimizes misdiagnosis. At the time of writing, our AI engine can distinguish between COVID-19 patient coughs and several types of non-COVID-19 coughs with over 90\% accuracy. AI4COVID-19's performance is likely to improve as more and better data becomes available. This paper presents a proof of concept to encourage controlled clinical trials and serves as a call for labeled cough data. AI4COVID-19 is not designed to compete with clinical testing. Instead, it offers a complementing tele-testing tool deployable anytime, anywhere, by anyone, so clinical-testing and treatment can be channeled to those who need it the most, thereby saving more lives.},
	journal = {arxiv},
	author = {Imran, Ali and Posokhova, Iryna and Qureshi, Haneya N. and Masood, Usama and Riaz, Sajid and Ali, Kamran and John, Charles N. and Nabeel, Muhammad and Hussain, Iftikhar},
	year = {2020},
	pages = {1--11},
	file = {Imran et al_2020_AI4COVID-19.pdf:/Users/orsonxu/Zotero/storage/HQI6WJ9I/Imran et al_2020_AI4COVID-19.pdf:application/pdf;Imran et al_2020_AI4COVID-19.pdf:/Users/orsonxu/Zotero/storage/2NL4HC4M/Imran et al_2020_AI4COVID-19.pdf:application/pdf},
}

@article{Chatterjee2019,
	title = {Mlung++: {Automated} characterization of abnormal lung sounds in pulmonary patients using multimodal mobile sensors},
	doi = {10.1145/3341162.3344850},
	abstract = {The design of computational methods for detection of abnormal lung sounds (e.g., wheeze) associated with the advent of a pulmonary attack (e.g., asthma) and subsequent characterization of the ‘severity’ or progressive exacerbation in pulmonary patients is a relevant problem in ubiquitous computing. While a few recent works have been done on on-body sensor and smartphone sensor based lung activity detection, designing a comprehensive architecture for the detection and characterization of abnormal lung sounds (e.g., wheeze) is an open issue. In this paper, we present mLung++, which is a comprehensive pulmonary care system for respiration cycle based detection and subsequent characterization of wheezing in chronic pulmonary patients using audio and inertial sensors embedded on a smartphone. For the design, training, and evaluation, we use audio and Inertial Measurement Unit (IMU) data collected by smartphone and watch from 131 human subjects (91 pulmonary patients, 40 healthy control). We show empirical evidence that the performance of mLung++ for characterizing abnormal lung sounds (accuracy 93.4\% and f1\_score 77.94\%) is comparable with that of high-quality on-body sensor based characterization, which is usually done in a hospital or clinical setup.},
	journal = {UbiComp/ISWC 2019- - Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers},
	author = {Chatterjee, Soujanya and Mahbubur Rahman, Md and Nemati, Ebrahim and Nathan, Viswam and Vatanparvar, Korosh and Kuang, Jilong},
	year = {2019},
	note = {ISBN: 9781450368698},
	keywords = {Machine Learning, Mobile Sensing, Internet-of-Things, Mobile Health, Pulmonary Health, Wheezing Severity},
	pages = {474--481},
	file = {Chatterjee et al_2019_Mlung++.pdf:/Users/orsonxu/Zotero/storage/QHF3EEAF/Chatterjee et al_2019_Mlung++.pdf:application/pdf;Chatterjee et al_2019_Mlung++.pdf:/Users/orsonxu/Zotero/storage/CP5HR5LE/Chatterjee et al_2019_Mlung++.pdf:application/pdf},
}

@article{Whitehill2019,
	title = {Whosecough: {In}-the-wild {Cougher} {Verification} {Using} {Multitask} {Learning}},
	journal = {ICASSP},
	author = {Whitehill, Matt and Garrison, Jake and Patel, Shwetak},
	year = {2019},
	file = {Whitehill et al_2019_Whosecough.pdf:/Users/orsonxu/Zotero/storage/KPZ2RAUF/Whitehill et al_2019_Whosecough.pdf:application/pdf;Whitehill et al_2019_Whosecough.pdf:/Users/orsonxu/Zotero/storage/JFBFZKV7/Whitehill et al_2019_Whosecough.pdf:application/pdf},
}

@article{Vatanparvar2020a,
	title = {Adapting to {Noise} in {Speech} {Obfuscation} by {Audio} {Profiling} {Using} {Generative} {Models} for {Passive} {Health} {Monitoring}},
	journal = {EMBC},
	author = {Vatanparvar, Korosh and Nathan, Viswam and Nemati, Ebrahim and Rahman, Mahbubur and Kuang, Jilong and Acm, Ieee},
	year = {2020},
	file = {Vatanparvar et al_2020_Adapting to Noise in Speech Obfuscation by Audio Profiling Using Generative Models for Passive Health Monitoring.pdf:/Users/orsonxu/Zotero/storage/HGICHQI5/Vatanparvar et al_2020_Adapting to Noise in Speech Obfuscation by Audio Profiling Using Generative Models for Passive Health Monitoring.pdf:application/pdf;Vatanparvar et al_2020_Adapting to Noise in Speech Obfuscation by Audio Profiling Using Generative Models for Passive Health Monitoring.pdf:/Users/orsonxu/Zotero/storage/BXBP68MX/Vatanparvar et al_2020_Adapting to Noise in Speech Obfuscation by Audio Profiling Using Generative Models for Passive Health Monitoring.pdf:application/pdf},
}

@article{Vatanparvar2019,
	title = {A generative model for speech segmentation and obfuscation for remote health monitoring},
	doi = {10.1109/BSN.2019.8771098},
	abstract = {The prevalence of smart devices has enabled remote health monitoring outside of conventional clinical settings, and has reduced health care delivery cost. Passive audio recording is an essential component in remote health monitoring, however, it poses major privacy issues for subjects in uncontrolled environments like their home. There are existing voice activity detection and speech classification methodologies to identify sound events and obfuscate the human speech. However, they result in frequent false positives \$({\textgreater} {\textbackslash}pmb\{94\}{\textbackslash}\%)\$ when distinguishing human speech from other sound events; their performance is limited to a controlled environment for a specific application; and require large amount of labeled data for training. In this paper, we present a novel speech privacy preservation methodology using generative adversarial networks to segment human speech in a recorded audio and generate human-like random speech to replace the original segment. We implemented our methodology and experimented on standard datasets of speech, environmental sounds, and cough samples generated from our internal mobile health study. Compared to current methodologies, our experimental results show much lower speech segmentation true positive rates of 17\% and 14\% for environmental sounds and cough datasets. Moreover, randomly generated audio samples to obfuscate the speech are shown to be likely indistinguishable from human speech (lower than 0.9\% error in spectral attributes).},
	journal = {2019 IEEE 16th International Conference on Wearable and Implantable Body Sensor Networks, BSN 2019 - Proceedings},
	author = {Vatanparvar, Korosh and Nathan, Viswam and Nemati, Ebrahim and Rahman, Md Mahbubur and Kuang, Jilong},
	year = {2019},
	note = {ISBN: 9781538674772},
	keywords = {Machine learning, Mobile health, Generative model, Obfuscation, Privacy, Remote health, Speech segmentation},
	file = {Vatanparvar et al_2019_A generative model for speech segmentation and obfuscation for remote health monitoring.pdf:/Users/orsonxu/Zotero/storage/I89W4DEC/Vatanparvar et al_2019_A generative model for speech segmentation and obfuscation for remote health monitoring.pdf:application/pdf;Vatanparvar et al_2019_A generative model for speech segmentation and obfuscation for remote health monitoring.pdf:/Users/orsonxu/Zotero/storage/2E6Y5S49/Vatanparvar et al_2019_A generative model for speech segmentation and obfuscation for remote health monitoring.pdf:application/pdf},
}

@article{Submission2020,
	title = {Automated {Time} {Synchronization} of {Multimodal} {Cough} {Events} from {Mobile} {Devices} {Anonymized} for {Submission}},
	journal = {ICMI - Submission},
	author = {Submission, Anonymized},
	year = {2020},
	keywords = {mobile health, cough data collection, time synchronization},
	file = {Submission_2020_Automated Time Synchronization of Multimodal Cough Events from Mobile Devices Anonymized for Submission.pdf:/Users/orsonxu/Zotero/storage/VXQFS4L8/Submission_2020_Automated Time Synchronization of Multimodal Cough Events from Mobile Devices Anonymized for Submission.pdf:application/pdf;Submission_2020_Automated Time Synchronization of Multimodal Cough Events from Mobile Devices Anonymized for Submission.pdf:/Users/orsonxu/Zotero/storage/4GGD6XTH/Submission_2020_Automated Time Synchronization of Multimodal Cough Events from Mobile Devices Anonymized for Submission.pdf:application/pdf},
}

@article{Nemati2020,
	title = {Private {Audio}-{Based} {Cough} {Sensing} for {In}-{Home} {Pulmonary} {Assessment} {Using} {Mobile} {Devices}},
	doi = {10.1007/978-3-030-29897-5_18},
	journal = {13th EAI International Conference on Body Area Networks},
	author = {Nemati, Ebrahim and Rahman, Md. Mahbubur and Nathan, Viswam and Kuang, Jilong},
	year = {2020},
	keywords = {asthma, copd, dom forest, hierarchical algorithm, lpc, majority voting, mfcc, ran-, speech obfuscation, std, svm},
	pages = {221--232},
	file = {Nemati et al_2020_Private Audio-Based Cough Sensing for In-Home Pulmonary Assessment Using Mobile Devices.pdf:/Users/orsonxu/Zotero/storage/S6FGSU2J/Nemati et al_2020_Private Audio-Based Cough Sensing for In-Home Pulmonary Assessment Using Mobile Devices.pdf:application/pdf;Nemati et al_2020_Private Audio-Based Cough Sensing for In-Home Pulmonary Assessment Using Mobile Devices.pdf:/Users/orsonxu/Zotero/storage/Q8ICHBP3/Nemati et al_2020_Private Audio-Based Cough Sensing for In-Home Pulmonary Assessment Using Mobile Devices.pdf:application/pdf},
}

@article{MdJuberRahmanEbrahimNematiMahbuburRahmanKoroshVatanparvarViswamNathan2020,
	title = {Toward {Early} {Severity} {Assessment} of {Obstructive} {Lung} {Disease} {Using} {Multi}-{Modal} {Wearable} {Sensor} {Data} {Fusion} {During} {Walking}},
	journal = {EMBC},
	author = {Rahman, Md Juber and Nemati, Ebrahim and Rahman, Mahbubur and Vatanparvar, Korosh and Nathan, Viswam and Kuang, Jilong},
	year = {2020},
	keywords = {6-minute walk test, heart rate variability},
	file = {Rahman et al_2020_Toward Early Severity Assessment of Obstructive Lung Disease Using Multi-Modal Wearable Sensor Data Fusion During Walking.pdf:/Users/orsonxu/Zotero/storage/RPMST5NM/Rahman et al_2020_Toward Early Severity Assessment of Obstructive Lung Disease Using Multi-Modal Wearable Sensor Data Fusion During Walking.pdf:application/pdf;Rahman et al_2020_Toward Early Severity Assessment of Obstructive Lung Disease Using Multi-Modal Wearable Sensor Data Fusion During Walking.pdf:/Users/orsonxu/Zotero/storage/L93SD4V2/Rahman et al_2020_Toward Early Severity Assessment of Obstructive Lung Disease Using Multi-Modal Wearable Sensor Data Fusion During Walking.pdf:application/pdf},
}

@article{Vatanparvar2020b,
	title = {{CoughMatch} – {Subject} {Verification} {Using} {Cough} for {Personal} {Passive} {Health} {Monitoring}},
	journal = {EMBC},
	author = {Vatanparvar, Korosh and Nemati, Ebrahim and Nathan, Viswam and Rahman, Mahbubur and Kuang, Jilong},
	year = {2020},
	file = {Vatanparvar et al_2020_CoughMatch – Subject Verification Using Cough for Personal Passive Health Monitoring.pdf:/Users/orsonxu/Zotero/storage/U6GYVJU9/Vatanparvar et al_2020_CoughMatch – Subject Verification Using Cough for Personal Passive Health Monitoring.pdf:application/pdf;Vatanparvar et al_2020_CoughMatch – Subject Verification Using Cough for Personal Passive Health Monitoring.pdf:/Users/orsonxu/Zotero/storage/2678VRIF/Vatanparvar et al_2020_CoughMatch – Subject Verification Using Cough for Personal Passive Health Monitoring.pdf:application/pdf},
}

@article{Ramesh2020,
	title = {{CoughGAN} : {Generating} {Synthetic} {Coughs} that {Improve} {Respiratory} {Disease} {Classification} *},
	journal = {EMBC},
	author = {Ramesh, Vishwajith and Vatanparvar, Korosh and Nemati, Ebrahim and Nathan, Viswam and Rahman, Md Mahbubur and Kuang, Jilong},
	year = {2020},
	file = {Ramesh et al_2020_CoughGAN.pdf:/Users/orsonxu/Zotero/storage/PY48NQDZ/Ramesh et al_2020_CoughGAN.pdf:application/pdf;Ramesh et al_2020_CoughGAN.pdf:/Users/orsonxu/Zotero/storage/P3ETGUPI/Ramesh et al_2020_CoughGAN.pdf:application/pdf},
}

@article{Nemati2019,
	title = {Poster {Abstract}: {A} {Comprehensive} {Approach} for {Cough} {Type} {Detection}},
	doi = {10.1109/CHASE48038.2019.00013},
	abstract = {Presence of sputum in pulmonary system is an important bio-marker, critical in determining the existence of many disease such as lung infection, pneumonia, cancer, etc. While there has been many reports of successful algorithms to automatically detect cough instances, there has been not much work in identifying the cough type, or equivalently detection of sputum presence. Cough type detection is traditionally done by physical examination through hearing patients coughs in a clinical visit which is subjective and costly. This work tries to provide an objective comprehensive approach for cough type detection using an extensive set of acoustic features applied to the recorded audio from a relatively large population of both healthy subjects and patient with various pulmonary diseases and healthy controls. A total number of 5971 coughs (5242 dry and 729 wet) were collected from 131 subjects using Smartphone. Annotation was done using a crowd-source platform. Classification sensitivity and specificity values of 86\% and 84\% was achieved respectively which is the highest in literature to the best of our knowledge.},
	journal = {Proceedings - 4th IEEE/ACM Conference on Connected Health: Applications, Systems and Engineering Technologies, CHASE 2019},
	author = {Nemati, Ebrahim and Rahman, Md Mahbubur and Nathan, Viswam and Vatanparvar, Korosh and Kuang, Jilong},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781728146874},
	keywords = {COPD, asthma, cough type detection, remote health monitoring},
	pages = {15--16},
	file = {Nemati et al_2019_Poster Abstract.pdf:/Users/orsonxu/Zotero/storage/VUNDT4TN/Nemati et al_2019_Poster Abstract.pdf:application/pdf;Nemati et al_2019_Poster Abstract.pdf:/Users/orsonxu/Zotero/storage/6XDU96ZW/Nemati et al_2019_Poster Abstract.pdf:application/pdf},
}

@article{Ahmed2019,
	title = {{MLung}: {Privacy}-preserving naturally windowed lung activity detection for pulmonary patients},
	doi = {10.1109/BSN.2019.8771072},
	abstract = {mLung is a privacy preserving, naturally windowed, mobile-cloud hybrid pulmonary care service for detecting unusual lung sounds like coughing and wheezing from streaming audio and inertial sensor data from a smartphone for pulmonary patients. mLung employs a combination of: (1) natural windowing of audio data from the patient respiration cycle captured by the inertial sensors, (2) in-phone speech detection and filtering by a lightweight classifier for patient privacy, and (3) in-cloud lung and confounding sound classification by a heavyweight and expert supervised classifier. This paper describes the design and architecture of mLung and using novel lung activity data collected by smartphone from 131 patients and healthy subjects, provides empirical evidence that mLung is 15\%-25\% more accurate in detecting lung sounds when compared to a state-of-the-art phone based internal body sound detection system using specialized microphone hardware, with a best f-1 score of 98\%.},
	number = {2},
	journal = {2019 IEEE 16th International Conference on Wearable and Implantable Body Sensor Networks, BSN 2019 - Proceedings},
	author = {Ahmed, Mohsin Y. and Rahman, Md Mahbubur and Nathan, Viswam and Nemati, Ebrahim and Vatanparvar, Korosh and Kuang, Jilong},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781538674772},
	keywords = {Smartphone, Pulmonary diseases, Privacy, Respiratory cycle},
	pages = {5--8},
	file = {Ahmed et al_2019_MLung.pdf:/Users/orsonxu/Zotero/storage/ZVK25QZZ/Ahmed et al_2019_MLung.pdf:application/pdf;Ahmed et al_2019_MLung.pdf:/Users/orsonxu/Zotero/storage/INYYTLQD/Ahmed et al_2019_MLung.pdf:application/pdf},
}

@article{Nathan2019,
	title = {Assessment of chronic pulmonary disease patients using biomarkers from natural speech recorded by mobile devices},
	doi = {10.1109/BSN.2019.8771043},
	abstract = {Chronic pulmonary disease is one of the leading causes of mortality in the United States. Continuous passive monitoring of subjects using mobile sensors can help detect disease, estimate severity, track progression over time, and predict adverse exacerbation events. One of the most convenient avenues to realize this goal is through analysis of passively recorded natural speech patterns. It has been previously established that diseases such as asthma and chronic obstructive pulmonary disease (COPD) affect pause patterns and prosodic features of speech. In this study we present an exploration of the feasibility of using speech features from natural speech to detect pulmonary disease. Experiments were conducted on a cohort of 131 subjects: 91 with asthma and/or COPD, and 40 healthy controls. Patients and healthy subjects were differentiable with 68\% accuracy; moreover, the subset of patients with the highest disease severity were detected with 89\% accuracy.},
	journal = {2019 IEEE 16th International Conference on Wearable and Implantable Body Sensor Networks, BSN 2019 - Proceedings},
	author = {Nathan, Viswam and Vatanparvar, Korosh and Rahman, Md Mahbubur and Nemati, Ebrahim and Kuang, Jilong},
	year = {2019},
	note = {Publisher: IEEE
ISBN: 9781538674772},
	keywords = {Asthma, COPD, Digital health, Mobile monitoring, Pulmonary disease, Speech processing},
	file = {Nathan et al_2019_Assessment of chronic pulmonary disease patients using biomarkers from natural speech recorded by mobile devices.pdf:/Users/orsonxu/Zotero/storage/P9QN7ILU/Nathan et al_2019_Assessment of chronic pulmonary disease patients using biomarkers from natural speech recorded by mobile devices.pdf:application/pdf;Nathan et al_2019_Assessment of chronic pulmonary disease patients using biomarkers from natural speech recorded by mobile devices.pdf:/Users/orsonxu/Zotero/storage/H827ARDX/Nathan et al_2019_Assessment of chronic pulmonary disease patients using biomarkers from natural speech recorded by mobile devices.pdf:application/pdf},
}

@article{Zhao2016a,
	title = {Urban human mobility data mining: {An} overview},
	doi = {10.1109/BigData.2016.7840811},
	abstract = {Understanding urban human mobility is crucial for epidemic control, urban planning, traffic forecasting systems and, more recently, various mobile and network applications. Nowadays, a variety of urban human mobility data have been gathered and published. Pervasive GPS data can be collected by mobile phones. A mobile operator can track people's movement in cities based on their cellular network location. This urban human mobility data contains rich knowledge about locations and can help in addressing many urban challenges such as traffic congestion or air pollution problems. In this article, we survey recent literature on urban human mobility from a data mining view: from the data collection and cleaning, to the mobility models and the applications. First, we summarize recent public urban human mobility data sets and how to clean and preprocess such data. Second, we describe recent urban human mobility models and predictors, e.g., the deep learning predictor, for predicting urban human mobility. Third, we describe how to evaluate the models and predictors. We conclude by considering how applications can utilize the mobility models and predictive tools for addressing city challenges.},
	journal = {Proceedings of IEEE International Conference on Big Data, Big Data},
	author = {Zhao, Kai and Tarkoma, Sasu and Liu, Siyuan and Vo, Huy},
	year = {2016},
	note = {Publisher: IEEE
ISBN: 9781467390040},
	keywords = {machine learning, human mobility, smart city, spatio-temporal data mining},
	pages = {1911--1920},
	file = {Zhao et al_2016_Urban human mobility data mining.pdf:/Users/orsonxu/Zotero/storage/ZCZUBJRD/Zhao et al_2016_Urban human mobility data mining.pdf:application/pdf;Zhao et al_2016_Urban human mobility data mining.pdf:/Users/orsonxu/Zotero/storage/NDWRLWKP/Zhao et al_2016_Urban human mobility data mining.pdf:application/pdf},
}

@article{Hess2015,
	title = {Data-driven human mobility modeling: {A} survey and engineering guidance for mobile networking},
	volume = {48},
	issn = {15577341},
	doi = {10.1145/2840722},
	abstract = {Over the last decades, modeling of user mobility has become increasingly important in mobile networking research and development. This has led to the adoption of modeling techniques from other disciplines such as kinetic theory or urban planning. Yet these techniques generate movement behavior that is often perceived as not "realistic" for humans or provides only a macroscopic view on mobility. More recent approaches infer mobility models from real traces provided by positioning technologies or by the marks the mobile users leave in the wireless network. However, there is no common framework for assessing and comparing mobilitymodels. In an attempt to provide a solid foundation for realistic mobility modeling in mobile networking research, we take an engineering approach and thoroughly discuss the required steps of model creation and validation. In this context, we survey how and to what extent existing mobility modeling approaches implement the proposed steps. This also summarizes helpful information for readers who do not want to develop a new model, but rather intend to choose among existing ones.},
	number = {3},
	journal = {ACM Computing Surveys},
	author = {Hess, Andrea and Hummel, Karin Anna and Gansterer, Wilfried N.},
	year = {2015},
	keywords = {Mobility modeling, Realistic models, Representativeness},
	pages = {1--39},
	file = {Hess et al_2015_Data-driven human mobility modeling.pdf:/Users/orsonxu/Zotero/storage/HAU22F75/Hess et al_2015_Data-driven human mobility modeling.pdf:application/pdf;Hess et al_2015_Data-driven human mobility modeling.pdf:/Users/orsonxu/Zotero/storage/6UCIFK86/Hess et al_2015_Data-driven human mobility modeling.pdf:application/pdf},
}

@article{Fu2020,
	title = {Sensing {Technology} for {Human} {Activity} {Recognition} : a {Comprehensive} {Survey}},
	doi = {10.1109/ACCESS.2020.2991891},
	journal = {IEEE Access},
	author = {Fu, Biying and Damer, Naser and Kirchbuchner, Florian and Kuijper, Arjan},
	year = {2020},
	file = {Fu et al_2020_Sensing Technology for Human Activity Recognition.pdf:/Users/orsonxu/Zotero/storage/95HZAZJV/Fu et al_2020_Sensing Technology for Human Activity Recognition.pdf:application/pdf;Fu et al_2020_Sensing Technology for Human Activity Recognition.pdf:/Users/orsonxu/Zotero/storage/6VZVYTZX/Fu et al_2020_Sensing Technology for Human Activity Recognition.pdf:application/pdf},
}

@article{Zhao2019,
	title = {{AppUsage2Vec} : {Modeling} {Smartphone} {App} {Usage} for {Prediction}},
	doi = {10.1109/ICDE.2019.00120},
	number = {December},
	journal = {Proceedings - International Conference on Data Engineering},
	author = {Zhao, Sha and Luo, Zhiling and Jiang, Ziwen and Wang, Haiyan and Xu, Feng and Li, Shijian and Yin, Jianwei and Pan, Gang},
	year = {2019},
	pages = {1322--1333},
	file = {Zhao et al_2019_AppUsage2Vec.pdf:/Users/orsonxu/Zotero/storage/YTH9HBME/Zhao et al_2019_AppUsage2Vec.pdf:application/pdf;Zhao et al_2019_AppUsage2Vec.pdf:/Users/orsonxu/Zotero/storage/P3ERDZQH/Zhao et al_2019_AppUsage2Vec.pdf:application/pdf},
}

@article{Chen2019,
	title = {{CAP} : {Context}-aware {App} {Usage} {Prediction} with {Heterogeneous} {Graph} {Embedding}},
	volume = {3},
	number = {1},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Chen, Xinlei and Wang, Yu and He, Jiayou and Pan, Shijia and Li, Yong and Zhang, Pei},
	year = {2019},
	keywords = {Application Usage, Behaviour Modeling, Context Aware, Graph Embedding},
	pages = {4},
	file = {Chen et al_2019_CAP.pdf:/Users/orsonxu/Zotero/storage/T2YMNP5S/Chen et al_2019_CAP.pdf:application/pdf;Chen et al_2019_CAP.pdf:/Users/orsonxu/Zotero/storage/MKRGPFJI/Chen et al_2019_CAP.pdf:application/pdf},
}

@article{Silva2018,
	title = {Discovering {Mobile} {Application} {Usage} {Patterns} from a {Large}-{Scale} {Dataset}},
	volume = {12},
	issn = {15564681},
	url = {http://dl.acm.org/citation.cfm?doid=3234931.3209669},
	doi = {10.1145/3209669},
	number = {5},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Silva, Fabrício A. and Domingues, Augusto C. S. A. and Silva, Thais R. M. Braga},
	year = {2018},
	pages = {1--36},
	file = {Silva et al_2018_Discovering Mobile Application Usage Patterns from a Large-Scale Dataset.pdf:/Users/orsonxu/Zotero/storage/BG6JG4J9/Silva et al_2018_Discovering Mobile Application Usage Patterns from a Large-Scale Dataset.pdf:application/pdf;Silva et al_2018_Discovering Mobile Application Usage Patterns from a Large-Scale Dataset.pdf:/Users/orsonxu/Zotero/storage/2P69N2UT/Silva et al_2018_Discovering Mobile Application Usage Patterns from a Large-Scale Dataset.pdf:application/pdf},
}

@article{MartaC.GonzalezCesarA.Hidalgo2008,
	title = {Understanding individual human mobility patterns - additional information},
	volume = {61},
	issn = {00085472},
	doi = {10.1038/nature},
	abstract = {We have shown previously that the AKT2 pathway is essential for cell survival and important in malignant transformation. In this study, we demonstrate elevated kinase levels of AKT2 and phosphatidylinositol-3-OH kinase (PI3K) in 32 of 80 primary breast carcinomas. The majority of the cases with the activation are estrogen receptor alpha (ERalpha) positive, which prompted us to examine whether AKT2 regulates ERalpha activity. We found that constitutively activated AKT2 or AKT2 activated by epidermal growth factor or insulin-like growth factor-1 promotes the transcriptional activity of ERalpha. This effect occurred in the absence or presence of estrogen. Activated AKT2 phosphorylates ERalpha in vitro and in vivo, but it does not phosphorylate a mutant ERalpha in which ser-167 was replaced by Ala. The PI3K inhibitor, wortmannin, abolishes both the phosphorylation and transcriptional activity of ERalpha induced by AKT2. However, AKT2-induced ERalpha activity was not inhibited by tamoxifen but was completely abolished by ICI 164,384, implicating that AKT2-activated ERalpha contributes to tamoxifen resistance. Moreover, we found that ERalpha binds to the p85alpha regulatory subunit of PI3K in the absence or presence of estradiol in epithelial cells and subsequently activates PI3K/AKT2, suggesting ERalpha regulation of PI3K/AKT2 through a nontranscriptional and ligand-independent mechanism. These data indicate that regulation between the ERalpha and PI3K/AKT2 pathway (ERalpha-PI3K/AKT2-ERalpha) may play an important role in pathogenesis of human breast cancer and could contribute to ligand-independent breast cancer cell growth.},
	number = {16},
	journal = {Nature},
	author = {Marta C. Gonz´alez, C´esar A. Hidalgo, Albert-L´aszl´o Barab´asi},
	year = {2008},
	pmid = {11507039},
	note = {ISBN: 0008-5472 (Print){\textbackslash}r0008-5472 (Linking)},
	pages = {5985--5991},
	file = {Marta C. Gonz´alez, C´esar A. Hidalgo_2008_Understanding individual human mobility patterns - additional information.pdf:/Users/orsonxu/Zotero/storage/W4HRA3H7/Marta C. Gonz´alez, C´esar A. Hidalgo_2008_Understanding individual human mobility patterns - additional information.pdf:application/pdf;Marta C. Gonz´alez, C´esar A. Hidalgo_2008_Understanding individual human mobility patterns - additional information.pdf:/Users/orsonxu/Zotero/storage/ZJMPLSYD/Marta C. Gonz´alez, C´esar A. Hidalgo_2008_Understanding individual human mobility patterns - additional information.pdf:application/pdf},
}

@article{Lin2018,
	title = {I'll {Be} {Back}: {On} the {Multiple} {Lives} of {Users} of a {Mobile} {Activity} {Tracking} {Application}},
	url = {http://arxiv.org/abs/1802.08972%0Ahttp://dx.doi.org/10.1145/3178876.3186062},
	doi = {10.1145/3178876.3186062},
	abstract = {Mobile health applications that track activities, such as exercise, sleep, and diet, are becoming widely used. While these activity tracking applications have the potential to improve our health, user engagement and retention are critical factors for their success. However, long-term user engagement patterns in real-world activity tracking applications are not yet well understood. Here we study user engagement patterns within a mobile physical activity tracking application consisting of 115 million logged activities taken by over a million users over 31 months. Specifically, we show that over 75\% of users return and re-engage with the application after prolonged periods of inactivity, no matter the duration of the inactivity. We find a surprising result that the re-engagement usage patterns resemble those of the start of the initial engagement period, rather than being a simple continuation of the end of the initial engagement period. This evidence points to a conceptual model of multiple lives of user engagement, extending the prevalent single life view of user activity. We demonstrate that these multiple lives occur because the users have a variety of different primary intents or goals for using the app. We find evidence for users being more likely to stop using the app once they achieved their primary intent or goal (e.g., weight loss). However, these users might return once their original intent resurfaces (e.g., wanting to lose newly gained weight). Based on insights developed in this work, including a marker of improved primary intent performance, our prediction models achieve 71\% ROC AUC. Overall, our research has implications for modeling user re-engagement in health activity tracking applications and has consequences for how notifications, recommendations as well as gamification can be used to increase engagement.},
	journal = {Proceedings of the 2018 World Wide Web Conference},
	author = {Lin, Zhiyuan and Althoff, Tim and Leskovec, Jure},
	year = {2018},
	note = {ISBN: 9781450356398},
	file = {Lin et al_2018_I'll Be Back.pdf:/Users/orsonxu/Zotero/storage/PII6NF6S/Lin et al_2018_I'll Be Back.pdf:application/pdf;Lin et al_2018_I'll Be Back.pdf:/Users/orsonxu/Zotero/storage/FCKUJXVL/Lin et al_2018_I'll Be Back.pdf:application/pdf},
}

@article{Jiang2016,
	title = {The {TimeGeo} modeling framework for urban mobility without travel surveys},
	volume = {113},
	issn = {0027-8424},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1616240113},
	doi = {10.1073/pnas.1616240113},
	abstract = {Well-established fine-scale urban mobility models today depend on detailed but cumbersome and expensive travel surveys for their calibration. Not much is known, however, about the set of mechanisms needed to generate complete mobility profiles if only using passive datasets with mostly sparse traces of individuals. In this study, we present a mechanistic modeling framework (TimeGeo) that effectively generates urban mobility patterns with resolution of 10 min and hundreds of meters. It ties together the inference of home and work activity locations from data, with the modeling of flexible activities (e.g., other) in space and time. The temporal choices are captured by only three features: the weekly home-based tour number, the dwell rate, and the burst rate. These combined generate for each individual: (i) stay duration of activities, (ii) number of visited locations per day, and (iii) daily mobility networks. These parameters capture how an individual deviates from the circadian rhythm of the population, and generate the wide spectrum of empirically observed mobility behaviors. The spatial choices of visited locations are modeled by a rank-based exploration and preferential return (r-EPR) mechanism that incorporates space in the EPR model. Finally, we show that a hierarchical multiplicative cascade method can measure the interaction between land use and generation of trips. In this way, urban structure is directly related to the observed distance of travels. This framework allows us to fully embrace the massive amount of individual data generated by information and communication technologies (ICTs) worldwide to comprehensively model urban mobility without travel surveys.},
	number = {45},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Jiang, Shan and Yang, Yingxiang and Gupta, Siddharth and Veneziano, Daniele and Athavale, Shounak},
	year = {2016},
	note = {ISBN: 1616240113},
	pages = {E7137--E7137},
	file = {Jiang et al_2016_The TimeGeo modeling framework for urban mobility without travel surveys.pdf:/Users/orsonxu/Zotero/storage/HYHU72QT/Jiang et al_2016_The TimeGeo modeling framework for urban mobility without travel surveys.pdf:application/pdf;Jiang et al_2016_The TimeGeo modeling framework for urban mobility without travel surveys.pdf:/Users/orsonxu/Zotero/storage/GPTBKHCK/Jiang et al_2016_The TimeGeo modeling framework for urban mobility without travel surveys.pdf:application/pdf},
}

@article{DiClemente2017,
	title = {Sequence of purchases in credit card data reveal life styles in urban populations},
	issn = {2041-1723},
	url = {http://arxiv.org/abs/1703.00409},
	doi = {10.1038/s41467-018-05690-8},
	abstract = {Zipf-like distributions characterize a wide set of phenomena in physics, biology, economics and social sciences. In human activities, Zipf-laws describe for example the frequency of words appearance in a text or the purchases types in shopping patterns. In the latter, the uneven distribution of transaction types is bound with the temporal sequences of purchases of individual choices. In this work, we define a new framework using a text compression technique on the sequences of credit card purchases to detect ubiquitous patterns of collective behavior. Clustering the consumers by their similarity in purchases sequences, we detect five consumer groups. Remarkably, post checking, individuals in each group are also similar in their age, total expenditure, gender, and the diversity of their social and mobility networks extracted by their mobile phone records. By properly deconstructing transaction data with Zipf-like distributions, this method uncovers sets of significant sequences that reveal insights on collective human behavior.},
	number = {2018},
	journal = {Nature Communications},
	author = {Di Clemente, Riccardo and Luengo-Oroz, Miguel and Travizano, Matias and Xu, Sharon and Vaitla, Bapu and González, Marta C.},
	year = {2017},
	pmid = {30127416},
	note = {Publisher: Springer US
ISBN: 4146701805},
	pages = {1--8},
	file = {Di Clemente et al_2017_Sequence of purchases in credit card data reveal life styles in urban populations.pdf:/Users/orsonxu/Zotero/storage/S6BNQ5AB/Di Clemente et al_2017_Sequence of purchases in credit card data reveal life styles in urban populations.pdf:application/pdf;Di Clemente et al_2017_Sequence of purchases in credit card data reveal life styles in urban populations.pdf:/Users/orsonxu/Zotero/storage/NW2PV4SC/Di Clemente et al_2017_Sequence of purchases in credit card data reveal life styles in urban populations.pdf:application/pdf},
}

@article{Kang2015,
	title = {My {Data} {Just} {Goes} {Everywhere}: {User} {Mental} {Models} of the {Internet} and {Implications} for {Privacy} and {Security}},
	journal = {SOUPS},
	author = {Kang, Ruogu and Dabbish, Laura and Fruchter, Nathaniel and Kiesler, Sara},
	year = {2015},
	pages = {39--52},
	file = {Kang et al_2015_My Data Just Goes Everywhere.pdf:/Users/orsonxu/Zotero/storage/6H7J3K4X/Kang et al_2015_My Data Just Goes Everywhere.pdf:application/pdf;Kang et al_2015_My Data Just Goes Everywhere.pdf:/Users/orsonxu/Zotero/storage/SGX3IDEE/Kang et al_2015_My Data Just Goes Everywhere.pdf:application/pdf},
}

@article{Li2014,
	title = {Providing efficient privacy-aware incentives for mobile sensing},
	doi = {10.1109/ICDCS.2014.29},
	abstract = {Mobile sensing relies on data contributed by users through their mobile device (e.g., smart phone) to obtain useful information about people and their surroundings. However, users may not want to contribute due to lack of incentives and concerns on possible privacy leakage. To effectively promote user participation, both incentive and privacy issues should be addressed. Existing work on privacy-aware incentive is limited to special scenario of mobile sensing where each sensing task needs only one data report from each user, and thus not appropriate for generic scenarios in which sensing tasks may require multiple reports from each user (e.g., in environmental monitoring applications). In this paper, we propose a privacy-aware incentive scheme for general mobile sensing, which allows each sensing task to collect one or multiple reports from each user as needed. Besides being more flexible in task management, our scheme has much lower computation and communication cost compared to the existing solution. Evaluations show that, when each node only contributes data for a small fraction of sensing tasks (e.g, due to the incapability or disqualification to generate sensing data for other tasks), our scheme runs at least one order of magnitude faster.},
	number = {March},
	journal = {Proceedings - International Conference on Distributed Computing Systems},
	author = {Li, Qinghua and Cao, Guohong},
	year = {2014},
	note = {ISBN: 9781479951680},
	pages = {208--217},
	file = {Li_Cao_2014_Providing efficient privacy-aware incentives for mobile sensing.pdf:/Users/orsonxu/Zotero/storage/ZMHBNTRT/Li_Cao_2014_Providing efficient privacy-aware incentives for mobile sensing.pdf:application/pdf;Li_Cao_2014_Providing efficient privacy-aware incentives for mobile sensing.pdf:/Users/orsonxu/Zotero/storage/RQ336B3D/Li_Cao_2014_Providing efficient privacy-aware incentives for mobile sensing.pdf:application/pdf},
}

@article{Liu2017,
	title = {Predicting the {Next} {Location} : {A} {Recurrent} {Model} with {Spatial} and {Temporal} {Contexts}},
	issn = {18766102},
	doi = {10.1016/j.egypro.2016.11.209},
	abstract = {Spatial and temporal contextual information plays a key role for analyzing user behaviors, and is helpful for pre-dicting where he or she will go next. With the growing ability of collecting information, more and more tem-poral and spatial contextual information is collected in systems, and the location prediction problem becomes crucial and feasible. Some works have been proposed to address this problem, but they all have their limitations. Factorizing Personalized Markov Chain (FPMC) is con-structed based on a strong independence assumption among different factors, which limits its performance. Tensor Factorization (TF) faces the cold start problem in predicting future actions. Recurrent Neural Networks (RNN) model shows promising performance compar-ing with PFMC and TF, but all these methods have problem in modeling continuous time interval and ge-ographical distance. In this paper, we extend RNN and propose a novel method called Spatial Temporal Recur-rent Neural Networks (ST-RNN). ST-RNN can model local temporal and spatial contexts in each layer with time-specific transition matrices for different time inter-vals and distance-specific transition matrices for differ-ent geographical distances. Experimental results show that the proposed ST-RNN model yields significant im-provements over the competitive compared methods on two typical datasets, i.e., Global Terrorism Database (GTD) and Gowalla dataset.},
	journal = {Thirtieth AAAI Conference on Artificial Intelligence},
	author = {Liu, Qiang and Wu, Shu and Wang, Liang and Tan, Tieniu},
	year = {2017},
	pmid = {19963286},
	note = {ISBN: 9781577357605},
	keywords = {Technical Papers: Artificial Intelligence and the},
	pages = {194--200},
	file = {Liu et al_2017_Predicting the Next Location.pdf:/Users/orsonxu/Zotero/storage/U3WRBQ8D/Liu et al_2017_Predicting the Next Location.pdf:application/pdf;Liu et al_2017_Predicting the Next Location.pdf:/Users/orsonxu/Zotero/storage/GLIRJJJB/Liu et al_2017_Predicting the Next Location.pdf:application/pdf},
}

@article{Benndorf2018,
	title = {The {Willingness} to {Sell} {Personal} {Data}},
	volume = {120},
	issn = {14679442},
	doi = {10.1111/sjoe.12247},
	abstract = {Abstract We assess the willingness of individuals to sell personal data in laboratory experiments. Our experiments are novel in that they are incentivized, the focus on privacy issues is salient, and the use of the data is transparent and unambiguous. We find considerable heterogeneity in the data. Roughly one in six participants refuse to sell personal data at all and a similar fraction sell their data for 2.50 euros or less. Our results contrast with those from hypothetical questionnaires. Those willing to sell, request, on average, 15 euros for their contact details and 19 euros for their Facebook data.},
	number = {4},
	journal = {Scandinavian Journal of Economics},
	author = {Benndorf, Volker and Normann, Hans Theo},
	year = {2018},
	note = {ISBN: 9783863041427},
	keywords = {privacy, Personal data, preference elicitation, social network},
	pages = {1260--1278},
	file = {Benndorf_Normann_2018_The Willingness to Sell Personal Data.pdf:/Users/orsonxu/Zotero/storage/WQ5ATTFT/Benndorf_Normann_2018_The Willingness to Sell Personal Data.pdf:application/pdf;Benndorf_Normann_2018_The Willingness to Sell Personal Data.pdf:/Users/orsonxu/Zotero/storage/R9LHXNE4/Benndorf_Normann_2018_The Willingness to Sell Personal Data.pdf:application/pdf},
}

@article{Kokolakis2017,
	title = {Privacy attitudes and privacy behaviour: {A} review of current research on the privacy paradox phenomenon},
	volume = {64},
	issn = {01674048},
	url = {http://dx.doi.org/10.1016/j.cose.2015.07.002},
	doi = {10.1016/j.cose.2015.07.002},
	abstract = {Do people really care about their privacy? Surveys show that privacy is a primary concern for citizens in the digital age. On the other hand, individuals reveal personal information for relatively small rewards, often just for drawing the attention of peers in an online social network. This inconsistency of privacy attitudes and privacy behaviour is often referred to as the “privacy paradox”. In this paper, we present the results of a review of research literature on the privacy paradox. We analyse studies that provide evidence of a paradoxical dichotomy between attitudes and behaviour and studies that challenge the existence of such a phenomenon. The diverse research results are explained by the diversity in research methods, the different contexts and the different conceptualisations of the privacy paradox. We also present several interpretations of the privacy paradox, stemming from social theory, psychology, behavioural economics and, in one case, from quantum theory. We conclude that current research has improved our understanding of the privacy paradox phenomenon. It is, however, a complex phenomenon that requires extensive further research. Thus, we call for synthetic studies to be based on comprehensive theoretical models that take into account the diversity of personal information and the diversity of privacy concerns. We suggest that future studies should use evidence of actual behaviour rather than self-reported behaviour.},
	journal = {Computers and Security},
	author = {Kokolakis, Spyros},
	year = {2017},
	pmid = {21675331},
	note = {Publisher: Elsevier Ltd
ISBN: 1120617163123},
	keywords = {Privacy, Information privacy, Personal information, Privacy behaviour, Privacy paradox},
	pages = {122--134},
	file = {Kokolakis_2017_Privacy attitudes and privacy behaviour.pdf:/Users/orsonxu/Zotero/storage/69J6WIET/Kokolakis_2017_Privacy attitudes and privacy behaviour.pdf:application/pdf;Kokolakis_2017_Privacy attitudes and privacy behaviour.pdf:/Users/orsonxu/Zotero/storage/5HBY8BJC/Kokolakis_2017_Privacy attitudes and privacy behaviour.pdf:application/pdf},
}

@article{Kapadia2009,
	title = {Opportunistic sensing: {Security} challenges for the new paradigm},
	doi = {10.1109/COMSNETS.2009.4808850},
	abstract = {We study the security challenges that arise in opportunistic people-centric sensing, a new sensing paradigm leveraging humans as part of the sensing infrastructure. Most prior sensor-network research has focused on collecting and processing environmental data using a static topology and an application-aware infrastructure, whereas opportunistic sensing involves collecting, storing, processing and fusing large volumes of data related to everyday human activities. This highly dynamic and mobile setting, where humans are the central focus, presents new challenges for information security, because data originates from sensors carried by people - not tiny sensors thrown in the forest or attached to animals. In this paper we aim to instigate discussion of this critical issue, because opportunistic people-centric sensing will never succeed without adequate provisions for security and privacy. To that end, we outline several important challenges and suggest general solutions that hold promise in this new sensing paradigm.},
	journal = {1st International Conference on Communication Systems and Networks and Workshops, COMSNETS 2009},
	author = {Kapadia, Apu and Kotz, David and Triandopoulos, Nikos},
	year = {2009},
	note = {ISBN: 9781424429127},
	file = {Kapadia et al_2009_Opportunistic sensing.pdf:/Users/orsonxu/Zotero/storage/ML8WWDLX/Kapadia et al_2009_Opportunistic sensing.pdf:application/pdf;Kapadia et al_2009_Opportunistic sensing.pdf:/Users/orsonxu/Zotero/storage/ISWDR8JU/Kapadia et al_2009_Opportunistic sensing.pdf:application/pdf},
}

@article{Guo2014a,
	title = {From participatory sensing to {Mobile} {Crowd} {Sensing}},
	doi = {10.1109/PerComW.2014.6815273},
	abstract = {The research on the efforts of combining human and machine intelligence has a long history. With the development of mobile sensing and mobile Internet techniques, a new sensing paradigm called Mobile Crowd Sensing (MCS), which leverages the power of citizens for large-scale sensing has become popular in recent years. As an evolution of participatory sensing, MCS has two unique features: (1) it involves both implicit and explicit participation; (2) MCS collects data from two user-participant data sources: mobile social networks and mobile sensing. This paper presents the literary history of MCS and its unique issues. A reference framework for MCS systems is also proposed. We further clarify the potential fusion of human and machine intelligence in MCS. Finally, we discuss the future research trends as well as our efforts to MCS.},
	journal = {2014 IEEE International Conference on Pervasive Computing and Communication Workshops, PERCOM WORKSHOPS 2014},
	author = {Guo, Bin and Yu, Zhiwen and Zhou, Xingshe and Zhang, Daqing},
	year = {2014},
	note = {Publisher: IEEE
ISBN: 9781479927364},
	keywords = {heterogeneous/cross-space data, Hybrid human-machine intelligence, mobile crowd sensing, participatory sensing},
	pages = {593--598},
	file = {Guo et al_2014_From participatory sensing to Mobile Crowd Sensing.pdf:/Users/orsonxu/Zotero/storage/IQC3NE4I/Guo et al_2014_From participatory sensing to Mobile Crowd Sensing.pdf:application/pdf;Guo et al_2014_From participatory sensing to Mobile Crowd Sensing.pdf:/Users/orsonxu/Zotero/storage/5QKZ63JU/Guo et al_2014_From participatory sensing to Mobile Crowd Sensing.pdf:application/pdf},
}

@article{Imai2018,
	title = {Early {Destination} {Prediction} with {Spatio}-temporal {User} {Behavior} {Patterns}},
	volume = {1},
	issn = {24749567},
	url = {http://dl.acm.org/citation.cfm?doid=3178157.3161197},
	doi = {10.1145/3161197},
	abstract = {Predicting user behavior makes it possible to provide services suitable for users. In behavior prediction, destination prediction (e.g. predicting a future location) can be applied to various practical applications. ï¿¿e problem is how to predict a destination with high accuracy in the early stage of movement. We call this problem " early destination prediction with trajectory tracking " . Currently, there are two destination prediction methods. One is Next Place Prediction(NPP), that is based on the staying paï¿¿ern such as at which location does a user frequently stay at a certain time of day. ï¿¿e other is prediction based on trajectory tracking. In the former, it is impossible to narrow down the destination by the route. In the laï¿¿er, it is diï¿¿cult to predict with high accuracy the early stage of movement. In this study, we proposed a novel prediction method suitable for " early destination prediction with trajectory tracking " by combining the above two methods. By comparing the accuracy of destination prediction for each percentage of completed movement for 100 users, we conï¿¿rmed that the proposed method is suitable for " early destination prediction with trajectory tracking " .},
	number = {4},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Imai, Ryo and Tsubouchi, Kota and Konishi, Tatsuya and Shimosaka, Masamichi},
	year = {2018},
	pages = {1--19},
	file = {Imai et al_2018_Early Destination Prediction with Spatio-temporal User Behavior Patterns.pdf:/Users/orsonxu/Zotero/storage/QIHLD5K5/Imai et al_2018_Early Destination Prediction with Spatio-temporal User Behavior Patterns.pdf:application/pdf;Imai et al_2018_Early Destination Prediction with Spatio-temporal User Behavior Patterns.pdf:/Users/orsonxu/Zotero/storage/LBJQY58J/Imai et al_2018_Early Destination Prediction with Spatio-temporal User Behavior Patterns.pdf:application/pdf},
}

@article{Tu2018,
	title = {Your {Apps} {Give} {You} {Away} : {Distinguishing} {Mobile} {Users} by {Their} {App} {Usage} {Fingerprints}},
	volume = {2},
	number = {3},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Tu, Zhen and Li, Runtong and Li, Yong},
	year = {2018},
	keywords = {Mobile Apps, Usage Patterns, User Privacy},
	file = {Tu et al_2018_Your Apps Give You Away.pdf:/Users/orsonxu/Zotero/storage/GWCT5XKA/Tu et al_2018_Your Apps Give You Away.pdf:application/pdf;Tu et al_2018_Your Apps Give You Away.pdf:/Users/orsonxu/Zotero/storage/FHPJFS69/Tu et al_2018_Your Apps Give You Away.pdf:application/pdf},
}

@article{Jiang2018,
	title = {Deep {ROI}-{Based} {Modeling} for {Urban} {Human} {Mobility} {Prediction}},
	volume = {2},
	issn = {24749567},
	url = {http://dl.acm.org/citation.cfm?doid=3200905.3191746},
	doi = {10.1145/3191746},
	abstract = {Rapidly developing location acquisition technologies have provided us with big GPS trajectory data, which offers a new means of understanding people's daily behaviors as well as urban dynamics. With such data, predicting human mobility at the city level will be of great significance for transportation scheduling, urban regulation, and emergency management. In particular, most urban human behaviors are related to a small number of important regions, referred to as Regions-of-Interest (ROIs). Therefore, in this study, a deep ROI-based modeling approach is proposed for effectively predicting urban human mobility. Urban ROIs are first discovered from historical trajectory data, and urban human mobility is designated using two types of ROI labels (ISROI and WHICHROI). Then, urban mobility prediction is modeled as a sequence classification problem for each type of label. Finally, a deep-learning architecture built with recurrent neural networks is designed as an effective sequence classifier. Experimental results demonstrate that the superior performance of our proposed approach to the baseline models and several real-world practices show the applicability of our approach to real-world urban computing problems.},
	number = {1},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Jiang, Renhe and Song, Xuan and Fan, Zipei and Xia, Tianqi and Chen, Quanjun and Chen, Qi and Shibasaki, Ryosuke},
	year = {2018},
	keywords = {big data, human mobility, urban computing, deep le},
	pages = {1--29},
	file = {Jiang et al_2018_Deep ROI-Based Modeling for Urban Human Mobility Prediction.pdf:/Users/orsonxu/Zotero/storage/RYF99JHX/Jiang et al_2018_Deep ROI-Based Modeling for Urban Human Mobility Prediction.pdf:application/pdf;Jiang et al_2018_Deep ROI-Based Modeling for Urban Human Mobility Prediction.pdf:/Users/orsonxu/Zotero/storage/6N7X7X6G/Jiang et al_2018_Deep ROI-Based Modeling for Urban Human Mobility Prediction.pdf:application/pdf},
}

@article{Fan2018,
	title = {Online {Deep} {Ensemble} {Learning} for {Predicting} {Citywide} {Human} {Mobility}},
	volume = {2},
	number = {3},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Fan, Zipei and Song, Xuan and Xia, TIanqi and Jiang, Renhe and Shibasaki, Ryosuke and Sakuramachi, Ritu},
	year = {2018},
	keywords = {deep learning, ensemble l, human mobility modeling},
	file = {Fan et al_2018_Online Deep Ensemble Learning for Predicting Citywide Human Mobility.pdf:/Users/orsonxu/Zotero/storage/W3IU8AL3/Fan et al_2018_Online Deep Ensemble Learning for Predicting Citywide Human Mobility.pdf:application/pdf;Fan et al_2018_Online Deep Ensemble Learning for Predicting Citywide Human Mobility.pdf:/Users/orsonxu/Zotero/storage/8YZEG45K/Fan et al_2018_Online Deep Ensemble Learning for Predicting Citywide Human Mobility.pdf:application/pdf},
}

@article{Yu2017,
	title = {Smartphone {App} {Usage} {Prediction} {Using} {Points} of {Interest}},
	volume = {0},
	issn = {24749567},
	url = {http://arxiv.org/abs/1711.09337},
	doi = {10.1145/3161413},
	abstract = {In this paper we present the first population-level, city-scale analysis of application usage on smartphones. Using deep packet inspection at the network operator level, we obtained a geo-tagged dataset with more than 6 million unique devices that launched more than 10,000 unique applications across the city of Shanghai over one week. We develop a technique that leverages transfer learning to predict which applications are most popular and estimate the whole usage distribution based on the Point of Interest (POI) information of that particular location. We demonstrate that our technique has an 83.0\% hitrate in successfully identifying the top five popular applications, and a 0.15 RMSE when estimating usage with just 10\% sampled sparse data. It outperforms by about 25.7\% over the existing state-of-the-art approaches. Our findings pave the way for predicting which apps are relevant to a user given their current location, and which applications are popular where. The implications of our findings are broad: it enables a range of systems to benefit from such timely predictions, including operating systems, network operators, appstores, advertisers, and service providers.},
	number = {0},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Yu, Donghan and Li, Yong and Xu, Fengli and Zhang, Pengyu and Kostakos, Vassilis},
	year = {2017},
	pages = {1--21},
	file = {Yu et al_2017_Smartphone App Usage Prediction Using Points of Interest.pdf:/Users/orsonxu/Zotero/storage/NGLMA8X5/Yu et al_2017_Smartphone App Usage Prediction Using Points of Interest.pdf:application/pdf;Yu et al_2017_Smartphone App Usage Prediction Using Points of Interest.pdf:/Users/orsonxu/Zotero/storage/6TVJG6Y3/Yu et al_2017_Smartphone App Usage Prediction Using Points of Interest.pdf:application/pdf},
}

@article{Nguyen2015,
	title = {I would hire you in a minute: {Thin} slices of nonverbal behavior in job interviews},
	doi = {10.1145/2818346.2820760},
	abstract = {In everyday life, judgments people make about others are based on brief excerpts of interactions, known as thin slices. Inferences stemming from such minimal information can be quite accurate, and nonverbal behavior plays an important role in the impression formation. Because protagonists are strangers, employment interviews are a case where both nonverbal behavior and thin slices can be predictive of outcomes. In this work, we analyze the predictive validity of thin slices of real job interviews, where slices are defined by the sequence of questions in a structured interview format. We approach this problem from an audio-visual, dyadic, and nonverbal perspective, where sensing, cue extraction, and inference are automated. Our study shows that although nonverbal behavioral cues extracted from thin slices were not as predictive as when extracted from the full interaction, they were still predictive of hirability impressions with R2 values up to 0.34, which was comparable to the predictive validity of human observers on thin slices. Applicant audio cues were found to yield the most accurate results.},
	journal = {ICMI 2015 - Proceedings of the 2015 ACM International Conference on Multimodal Interaction},
	author = {Nguyen, Laurent Son and Gatica-Perez, Daniel},
	year = {2015},
	note = {ISBN: 9781450339124},
	keywords = {Social computing, First impressions, Hirability, Job interview, Multimodal interaction, Nonverbal behavior, Thin slices},
	pages = {51--58},
	file = {Nguyen_Gatica-Perez_2015_I would hire you in a minute.pdf:/Users/orsonxu/Zotero/storage/T3HC8JXG/Nguyen_Gatica-Perez_2015_I would hire you in a minute.pdf:application/pdf;Nguyen_Gatica-Perez_2015_I would hire you in a minute.pdf:/Users/orsonxu/Zotero/storage/5GVNBKWE/Nguyen_Gatica-Perez_2015_I would hire you in a minute.pdf:application/pdf},
}

@article{Chen2014,
	title = {An initial analysis of structured video interviews by using multimodal emotion detection},
	doi = {10.1145/2668056.2668057},
	abstract = {Recently online video interviews have been increasingly used in the employment process. Though several automatic techniques have emerged to analyze the interview videos, so far, only simple emotion analyses have been attempted, e.g. counting the number of smiles on the face of an interviewee. In this paper, we report our initial study of applying advanced multimodal emotion detection approaches for the purpose of measuring performance on an interview task that elicits emotion. On an acted interview corpus we created, we performed our evaluations using a Speech-based Emotion Recognition (SER) system, as well as an off-The-shelf facial expression analysis toolkit (FACET). While the results obtained suggest the promise of using FACET for emotion detection, the benefits of employing the SER are somewhat limited.},
	journal = {ERM4HCI 2014 - Proceedings of the 2nd ACM International Workshop on Emotion Representations and Modelling in Human-Computer Interaction Systems, Co-located with ICMI 2014},
	author = {Chen, Lei and Yoon, Su Youn and Leong, Chee Wee and Martin, Michelle and Ma, Min},
	year = {2014},
	note = {ISBN: 9781450301244},
	keywords = {Emotion, Employment Interviews, Facial Expression, Job Applications, Multimodal Assessment, Speech},
	pages = {1--6},
	file = {Chen et al_2014_An initial analysis of structured video interviews by using multimodal emotion detection.pdf:/Users/orsonxu/Zotero/storage/VWN2ANUG/Chen et al_2014_An initial analysis of structured video interviews by using multimodal emotion detection.pdf:application/pdf;Chen et al_2014_An initial analysis of structured video interviews by using multimodal emotion detection.pdf:/Users/orsonxu/Zotero/storage/6Z7JKIQW/Chen et al_2014_An initial analysis of structured video interviews by using multimodal emotion detection.pdf:application/pdf},
}

@article{Iravantchi2019,
	title = {{BeamBand}: {Hand} {Gesture} {Sensing} with {Ultrasonic} {Beamforming}},
	url = {http://dl.acm.org/citation.cfm?doid=3290605.3300245},
	doi = {10.1145/3290605.3300245},
	journal = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI '19},
	author = {Iravantchi, Yasha and Goel, Mayank and Harrison, Chris},
	year = {2019},
	note = {ISBN: 9781450359702},
	keywords = {acoustic, hand gesture, hand input, interaction techniques, wearables, acoustic reflectrometry, all or part of, beamforming, or, or hard copies of, permission to make digital, this work for personal},
	pages = {1--10},
	file = {Iravantchi et al_2019_BeamBand.pdf:/Users/orsonxu/Zotero/storage/T89PSB6H/Iravantchi et al_2019_BeamBand.pdf:application/pdf;Iravantchi et al_2019_BeamBand.pdf:/Users/orsonxu/Zotero/storage/L2TLQF45/Iravantchi et al_2019_BeamBand.pdf:application/pdf},
}

@article{Lu2018a,
	title = {Inferring {Correlation} between {User} {Mobility} and {App} {Usage} in {Massive} {Coarse}-grained {Data} {Traces}},
	volume = {1},
	doi = {10.1145/3161171},
	abstract = {With the rapid growth in smartphone usage, it has been more and more important to understand the patterns of mobile data consumption by users. In this paper, we present an empirical study of the correlation between user mobility and app usage patterns. In particular, we focus on users' moving speed as the key mobility metric, and try to answer the following question: are there any notable relations between moving speed and the app usage patterns? Our study is based on a real-world, large-scale dataset of 2G phone network data request records. A critical challenge was that the raw data records are rather coarse-grained. More specifically, unlike GPS traces, the exact locations of users were not readily available. We inferred users' approximate locations according to their interactions with nearby cell towers, whose locations were known. We proposed a novel method to filter out noises and perform reliable speed estimation. We verify our methodology with out of sample data and show its improvement in speed estimation accuracy. We then examined several aspects of mobile data usage patterns, including the data volume, the access frequency, and the app categories, to reveal the correlation between these patterns and users' moving speed. Experimental results based on our large-scale real-world datasets revealed that users under different mobility categories not only have different smartphone usage motivations but also have different ways of using their smartphones.},
	number = {4},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Lu, Zheng and Feng, Yunhe and Zhou, Wenjun and Li, Xiaolin and Cao, Qing},
	year = {2018},
	pages = {1--21},
	file = {Lu et al_2018_Inferring Correlation between User Mobility and App Usage in Massive Coarse-grained Data Traces.pdf:/Users/orsonxu/Zotero/storage/R6B2336Y/Lu et al_2018_Inferring Correlation between User Mobility and App Usage in Massive Coarse-grained Data Traces.pdf:application/pdf;Lu et al_2018_Inferring Correlation between User Mobility and App Usage in Massive Coarse-grained Data Traces.pdf:/Users/orsonxu/Zotero/storage/H5FTW22R/Lu et al_2018_Inferring Correlation between User Mobility and App Usage in Massive Coarse-grained Data Traces.pdf:application/pdf},
}

@article{Guo2014,
	title = {Toward a {Group}-{Aware} {Smartphone} {Sensing} {System}},
	volume = {13},
	issn = {1536-1268},
	doi = {10.1109/mprv.2014.80},
	number = {4},
	journal = {IEEE Pervasive Computing},
	author = {Guo, Bin and Yu, Zhiwen and Zhang, Daqing and He, Huilei and Tian, Jilei and Zhou, Xingshe},
	year = {2014},
	note = {Publisher: IEEE},
	pages = {80--88},
	file = {Guo et al_2014_Toward a Group-Aware Smartphone Sensing System.pdf:/Users/orsonxu/Zotero/storage/BRH8KY6K/Guo et al_2014_Toward a Group-Aware Smartphone Sensing System.pdf:application/pdf;Guo et al_2014_Toward a Group-Aware Smartphone Sensing System.pdf:/Users/orsonxu/Zotero/storage/4WGV2T4N/Guo et al_2014_Toward a Group-Aware Smartphone Sensing System.pdf:application/pdf},
}

@article{Guo2015,
	title = {Mobile crowd sensing and computing: {The} review of an emerging human-powered sensing paradigm},
	volume = {48},
	issn = {03600300},
	url = {http://ci.nii.ac.jp/naid/110001104919/en/},
	doi = {10.1145/2794400},
	abstract = {With the surging of smartphone sensing, wireless networking, and mobile social networking techniques, Mobile Crowd Sensing and Computing (MCSC) has become a promising paradigm for cross-space and large- scale sensing. MCSC extends the vision of participatory sensing by leveraging both participatory sensory data from mobile devices (offline) and user-contributed data from mobile social networking services (online). Further, it explores the complementary roles and presents the fusion/collaboration of machine and human intelligence in the crowd sensing and computing processes. This article characterizes the unique features and novel application areas of MCSC and proposes a reference framework for building human-in-the-loop MCSC systems.We further clarify the complementary nature of human and machine intelligence and envision the potential of deep-fused human–machine systems. We conclude by discussing the limitations, open issues, and research opportunities of MCSC. Categories},
	number = {1},
	journal = {ACM Computing Surveys},
	author = {Guo, Bin and Wang, Zhu and Yu, Zhiwen and Wang, Yu and Yen, Neil Y and Huang, Runhe and Zhou, Xingshe},
	year = {2015},
	pages = {7},
	file = {Guo et al_2015_Mobile crowd sensing and computing.pdf:/Users/orsonxu/Zotero/storage/WZWZAG7K/Guo et al_2015_Mobile crowd sensing and computing.pdf:application/pdf;Guo et al_2015_Mobile crowd sensing and computing.pdf:/Users/orsonxu/Zotero/storage/F2ZUB94C/Guo et al_2015_Mobile crowd sensing and computing.pdf:application/pdf},
}

@article{Centellegher2018,
	title = {Mobile {Money}: {Understanding} and {Predicting} its {Adoption} and {Use} in a {Developing} {Economy}},
	volume = {2},
	url = {http://arxiv.org/abs/1812.03289},
	abstract = {Access to financial institutions is difficult in developing economies and especially for the poor. However, the widespread adoption of mobile phones has enabled the development of mobile money systems that deliver financial services through the mobile phone network. Despite the success of mobile money, there is a lack of quantitative studies that unveil which factors contribute to the adoption and sustained usage of such services. In this paper, we describe the results of a quantitative study that analyzes data from the world's leading mobile money service, M-Pesa. We analyzed millions of anonymized mobile phone communications and M-Pesa transactions in an African country. Our contributions are threefold: (1) we analyze the customers' usage of M-Pesa and report large-scale patterns of behavior; (2) we present the results of applying machine learning models to predict mobile money adoption (AUC=0.691), and mobile money spending (AUC=0.619) using multiple data sources: mobile phone data, M-Pesa agent information, the number of M-Pesa friends in the user's social network, and the characterization of the user's geographic location; (3) we discuss the most predictive features in both models and draw key implications for the design of mobile money services in a developing country. We find that the most predictive features are related to mobile phone activity, to the presence of M-Pesa users in a customer's ego-network and to mobility. We believe that our work will contribute to the understanding of the factors playing a role in the adoption and sustained usage of mobile money services in developing economies.},
	number = {4},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Centellegher, Simone and Miritello, Giovanna and Villatoro, Daniel and Parameshwar, Devyani and Lepri, Bruno and Oliver, Nuria},
	year = {2018},
	keywords = {Call Detail Records, Financi, M-Pesa, Mobile Money},
	file = {Centellegher et al_2018_Mobile Money.pdf:/Users/orsonxu/Zotero/storage/VZT4B87I/Centellegher et al_2018_Mobile Money.pdf:application/pdf;Centellegher et al_2018_Mobile Money.pdf:/Users/orsonxu/Zotero/storage/TBKTLYUU/Centellegher et al_2018_Mobile Money.pdf:application/pdf},
}

@article{Goyal2017,
	title = {Intelligent {Interruption} {Management} using {Electro} {Dermal} {Activity} based {Physiological} {Sensor} for {Collaborative} {Sensemaking}},
	volume = {1},
	doi = {10.1145/3130917},
	abstract = {Submarine channel avulsion is a fundamental process in the evolution of submarine fans that records abrupt changes in the sediment dispersal patterns, and the development of sand-rich splay deposits. On passive margins, changing flow conditions have been invoked to explain the location and timing of channel avulsion. On tectonically active basin margins, processes such as seismic activity, seabed faulting and folding and emplacement of mass-transport complexes (MTCs) are additional triggers. This study is based on the detailed mapping and interpretation of the first 1000m below seabed of a 1900km23D seismic volume in the southern Magdalena Fan, offshore Colombia, a tectonically-active margin. The emplacement of a large MTC deposit ({\textgreater}400km2in area and 200m in thickness) is interpreted to have controlled the avulsion node of a major channel-levee complex-set and influenced the evolution of the subsequent avulsion lobe complex-set. The basal surface of the MTC is highly erosional resulting in net degradation of the seascape. Substrate entrainment by the MTC left behind a narrow erosional remnant ridge that formed a bathymetric anomaly upon which a channel-levee complex-set developed. The irregular levee geometries above the remnant ridge led to instability and levee collapse prior to channel avulsion. Map view geometries and seismic amplitude extractions suggest that the initial avulsion lobes were mud-prone and relatively erratically distributed, and evolved to form well-defined sand-prone lobes. The distribution, morphology and evolution of the avulsion lobe complexes were strongly influenced by the bathymetric anomalies on the MTC top surface which, are generally coincident with protruding megaclasts. The role of MTC emplacement in triggering submarine channel avulsion and the development of sand-prone deposits in proximal locations has important implications for hydrocarbon exploration and production. This study serves as a high-resolution, shallow-subsurface analogue for less well-imaged avulsion cycles on tectonically-active basin margins that are prone to MTCs.},
	number = {3},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Goyal, Nitesh and Fussell, Susan R.},
	year = {2017},
	keywords = {-  Computing methodologies  -{\textgreater}  Cognitive science, -  Hardware  -{\textgreater}  Sensor applications and deploymen, -  Human-centered computing  -{\textgreater}  Human computer in, Collaborative and social computing},
	pages = {1--21},
	file = {Goyal_Fussell_2017_Intelligent Interruption Management using Electro Dermal Activity based Physiological Sensor for Collaborative Sensemaking.pdf:/Users/orsonxu/Zotero/storage/YY8HQPZT/Goyal_Fussell_2017_Intelligent Interruption Management using Electro Dermal Activity based Physiological Sensor for Collaborative Sensemaking.pdf:application/pdf;Goyal_Fussell_2017_Intelligent Interruption Management using Electro Dermal Activity based Physiological Sensor for Collaborative Sensemaking.pdf:/Users/orsonxu/Zotero/storage/G4UEK59G/Goyal_Fussell_2017_Intelligent Interruption Management using Electro Dermal Activity based Physiological Sensor for Collaborative Sensemaking.pdf:application/pdf},
}

@article{Xu2015a,
	title = {Quality of {Information} {Aware} {Incentive} {Mechanisms} for {Mobile} {Crowd} {Sensing} {Systems}},
	doi = {10.1145/2746285.2746310},
	abstract = {Recent years have witnessed the emergence of mobile crowd sens- ing (MCS) systems, which leverage the public crowd equipped with various mobile devices for large scale sensing tasks. In this paper, we study a critical problem in MCS systems, namely, incentivizing user participation. Different from existing work, we incorporate a crucial metric, called users’ quality of information (QoI), into our incentive mechanisms for MCS systems. Due to various fac- tors (e.g., sensor quality, noise, etc.) the quality of the sensory data contributed by individual users varies significantly. Obtaining high quality data with little expense is always the ideal of MCS platforms. Technically, we design incentive mechanisms based on reverse combinatorial auctions. We investigate both the single- minded and multi-minded combinatorial auction models. For the former, we design a truthful, individual rational and computation- ally efficient mechanism that approximately maximizes the social welfare with a guaranteed approximation ratio. For the latter, we design an iterative descending mechanism that achieves close-to- optimal social welfare while satisfying individual rationality and computational efficiency. Through extensive simulations, we vali- date our theoretical analysis about the close-to-optimal social wel- fare and fast running time of our mechanisms.},
	author = {Xu, Jinhui and Su, Lu and Nahrstedt, Klara and Jin, Haiming and Chen, Danyang},
	year = {2015},
	note = {ISBN: 9781450334891},
	keywords = {1329737, 1330142, and, cns-1329686, crowd sensing, in part by the, incentive mechanism, national science founda-, quality of information, this work was supported, tion under award numbers},
	pages = {167--176},
	file = {Xu et al_2015_Quality of Information Aware Incentive Mechanisms for Mobile Crowd Sensing Systems.pdf:/Users/orsonxu/Zotero/storage/R86J2CXI/Xu et al_2015_Quality of Information Aware Incentive Mechanisms for Mobile Crowd Sensing Systems.pdf:application/pdf;Xu et al_2015_Quality of Information Aware Incentive Mechanisms for Mobile Crowd Sensing Systems.pdf:/Users/orsonxu/Zotero/storage/HAS7B5L4/Xu et al_2015_Quality of Information Aware Incentive Mechanisms for Mobile Crowd Sensing Systems.pdf:application/pdf},
}

@article{Yang2012,
	title = {Crowdsourcing to {Smartphones} : {Incentive} {Mechanism} {Design} for {Mobile} {Phone} {Sensing} {Categories} and {Subject} {Descriptors}},
	abstract = {Mobile phone sensing is a new paradigm which takes ad-vantage of the pervasive smartphones to collect and ana-lyze data beyond the scale of what was previously possi-ble. In a mobile phone sensing system, the platform re-cruits smartphone users to provide sensing service. Existing mobile phone sensing applications and systems lack good incentive mechanisms that can attract more user participa-tion. To address this issue, we design incentive mechanisms for mobile phone sensing. We consider two system models: the platform-centric model where the platform provides a reward shared by participating users, and the user-centric model where users have more control over the payment they will receive. For the platform-centric model, we design an incentive mechanism using a Stackelberg game, where the platform is the leader while the users are the followers. We show how to compute the unique Stackelberg Equilibrium, at which the utility of the platform is maximized, and none of the users can improve its utility by unilaterally deviating from its current strategy. For the user-centric model, we design an auction-based incentive mechanism, which is com-putationally efficient, individually rational, profitable, and truthful. Through extensive simulations, we evaluate the performance and validate the theoretical properties of our incentive mechanisms.},
	journal = {Mobicom},
	author = {Yang, Dejun and Xue, Guoliang and Fang, Xi and Tang, Jian},
	year = {2012},
	note = {ISBN: 9781450311595},
	keywords = {mobile phone sensing, crowdsourcing, incentive mechanism},
	pages = {173--184},
	file = {Yang et al_2012_Crowdsourcing to Smartphones.pdf:/Users/orsonxu/Zotero/storage/88IBJK6B/Yang et al_2012_Crowdsourcing to Smartphones.pdf:application/pdf;Yang et al_2012_Crowdsourcing to Smartphones.pdf:/Users/orsonxu/Zotero/storage/UILXBQEE/Yang et al_2012_Crowdsourcing to Smartphones.pdf:application/pdf},
}

@article{Acquisti2010,
	title = {The {Economics} of {Personal} {Data} and {Privacy}: 30 {Years} after the {OECD} {Privacy} {Guidelines}},
	abstract = {This document has been prepared as background to for the Roundtable. It provides an overview of the economic analysis of the protection and revelation of personal data. In particular, it (1) describes the evolution of the economic theory of privacy, (2) examines privacy-related trade-offs for data subjects and data holders, and (3) highlight the current economic debate on privacy protection.},
	number = {1},
	journal = {The Economics of Personal Data and Privacy},
	author = {Acquisti, Alessandro},
	year = {2010},
	pages = {1--24},
	file = {Acquisti_2010_The Economics of Personal Data and Privacy.pdf:/Users/orsonxu/Zotero/storage/UXWH4AJT/Acquisti_2010_The Economics of Personal Data and Privacy.pdf:application/pdf;Acquisti_2010_The Economics of Personal Data and Privacy.pdf:/Users/orsonxu/Zotero/storage/Z2PWAMB2/Acquisti_2010_The Economics of Personal Data and Privacy.pdf:application/pdf},
}

@article{Acquisti2015,
	title = {The {Economics} of {Privacy}},
	volume = {54},
	issn = {0022-0515},
	doi = {10.2139/ssrn.2580411},
	abstract = {This article summarizes and draws connections among diverse streams of theoretical and empirical research on the economics of privacy. We focus on the economic value and consequences of protecting and disclosing personal information, and on consumers' understanding and decisions regarding the trade-offs associated with the privacy and the sharing of personal data. We highlight how the economic analysis of privacy evolved over time, as advancements in information technology raised increasingly nuanced and complex issues associated with the protection and sharing of personal information. We find and highlight three themes that connect diverse insights from the literature. First, characterizing a single unifying economic theory of privacy is hard, because privacy issues of economic relevance arise in widely diverse contexts. Second, there are theoretical and empirical situations where the protection of privacy can both enhance, and detract from, individual and societal welfare. Third, in digital economies, consumers' ability to make informed decisions about their privacy is severely hindered, because consumers are often in a position of imperfect or asymmetric information regarding when their data is collected, for what purposes, and with what consequences. We conclude the article by highlighting some of the ongoing issues in the privacy debate of interest to economists.},
	journal = {Ssrn},
	author = {Acquisti, Alessandro and Taylor, Curtis R. and Wagman, Liad},
	year = {2015},
	pmid = {17746758},
	note = {ISBN: 9781107590205},
	keywords = {Privacy, D04, D18, D23, D4, D52, D6, D8, D82, D86, Information Economics, L1, L2, L5, L51, Privacy Policies},
	pages = {442--492},
	file = {Acquisti et al_2015_The Economics of Privacy.pdf:/Users/orsonxu/Zotero/storage/D7U5VABT/Acquisti et al_2015_The Economics of Privacy.pdf:application/pdf;Acquisti et al_2015_The Economics of Privacy.pdf:/Users/orsonxu/Zotero/storage/AGQPMQLK/Acquisti et al_2015_The Economics of Privacy.pdf:application/pdf},
}

@article{Almuhimedi2015,
	title = {Your {Location} has been {Shared} 5,398 {Times}! {A} {Field} {Study} on {Mobile} {App} {Privacy} {Nudging}},
	doi = {10.1145/2702123.2702210},
	abstract = {Smartphone users are often unaware of the data collected by apps running on their devices. We report on a study that evaluates the benefits of giving users an app permission manager and sending them nudges intended to raise their awareness of the data collected by their apps. Our study provides both qualitative and quantitative evidence that these approaches are complementary and can each play a significant role in empowering users to more effectively control their privacy. For instance, even after a week with access to the permission manager, participants benefited from nudges showing them how often some of their sensitive data was be-ing accessed by apps, with 95\% of participants reassessing their permissions, and 58\% of them further restricting some of their permissions. We discuss how participants interacted both with the permission manager and the privacy nudges, analyze the effective-ness of both solutions, and derive some recommendations.},
	journal = {CHI},
	author = {Almuhimedi, Hazim and Schaub, Florian and Sadeh, Norman and Adjerid, Idris and Acquisti, Alessandro and Gluck, Joshua and Cranor, Lorrie and Agarwal, Yuvraj},
	year = {2015},
	note = {ISBN: 9781450331456},
	keywords = {archival format, proceedings, SIGCHI},
	pages = {787--796},
	file = {Almuhimedi et al_2015_Your Location has been Shared 5,398 Times.pdf:/Users/orsonxu/Zotero/storage/RDJIPLTD/Almuhimedi et al_2015_Your Location has been Shared 5,398 Times.pdf:application/pdf;Almuhimedi et al_2015_Your Location has been Shared 5,398 Times.pdf:/Users/orsonxu/Zotero/storage/74X6BJHK/Almuhimedi et al_2015_Your Location has been Shared 5,398 Times.pdf:application/pdf},
}

@article{Lin2014,
	title = {Modeling {Users}’ {Mobile} {App} {Privacy} {Preferences} : {Restoring} {Usability} in a {Sea} of {Permission} {Settings}},
	volume = {1},
	abstract = {In this paper, we investigate the feasibility of identifying a small set of privacy profiles as a way of helping users manage their mobile app privacy preferences. Our analysis does not limit itself to looking at permissions people feel comfortable granting to an app. Instead it relies on static code analysis to determine the purpose for which an app requests each of its permissions, distinguishing for instance between apps relying on particular permissions to deliver their core functionality and apps requesting these permissions to share information with advertising networks or social networks. Using privacy preferences that reflect people’s comfort with the purpose for which different apps request their permissions, we use clustering techniques to identify privacy profiles. A major contribution of this work is to show that, while people’s mobile app privacy preferences are diverse, it is possible to identify a small number of privacy profiles that collectively do a good job at capturing these diverse preferences.{\textbackslash}r{\textbackslash}n},
	journal = {Soups},
	author = {Lin, Jialiu and Liu, Bin and Sadeh, Norman and Hong, Jason I.},
	year = {2014},
	note = {ISBN: 978-1-931971-13-3},
	pages = {1--14},
	file = {Lin et al_2014_Modeling Users’ Mobile App Privacy Preferences.pdf:/Users/orsonxu/Zotero/storage/INMEX7K5/Lin et al_2014_Modeling Users’ Mobile App Privacy Preferences.pdf:application/pdf;Lin et al_2014_Modeling Users’ Mobile App Privacy Preferences.pdf:/Users/orsonxu/Zotero/storage/6U7MFBFX/Lin et al_2014_Modeling Users’ Mobile App Privacy Preferences.pdf:application/pdf},
}

@article{Cao2019,
	title = {Habit2vec: {Trajectory} {Semantic} {Embedding} for {Living} {Pattern} {Recognition} in {Population}},
	journal = {IEEE Transactions on Mobile Computing},
	author = {Cao, H. and Xu, F. and Sankaranarayanan, J. and Li, Y. and Samet, H.},
	year = {2019},
	file = {Cao et al_2019_Habit2vec.pdf:/Users/orsonxu/Zotero/storage/UWH3YDBE/Cao et al_2019_Habit2vec.pdf:application/pdf;Cao et al_2019_Habit2vec.pdf:/Users/orsonxu/Zotero/storage/C4XS925G/Cao et al_2019_Habit2vec.pdf:application/pdf},
}


@article{Apthorpe2018,
	title = {Discovering {Smart} {Home} {Internet} of {Things} {Privacy} {Norms} {Using} {Contextual} {Integrity}},
	volume = {2},
	url = {http://arxiv.org/abs/1805.06031%0Ahttp://dx.doi.org/10.1145/3214262},
	doi = {10.1145/3214262},
	abstract = {The proliferation of Internet of Things (IoT) devices for consumer "smart" homes raises concerns about user privacy. We present a survey method based on the Contextual Integrity (CI) privacy framework that can quickly and efficiently discover privacy norms at scale. We apply the method to discover privacy norms in the smart home context, surveying 1,731 American adults on Amazon Mechanical Turk. For \$2,800 and in less than six hours, we measured the acceptability of 3,840 information flows representing a combinatorial space of smart home devices sending consumer information to first and third-party recipients under various conditions. Our results provide actionable recommendations for IoT device manufacturers, including design best practices and instructions for adopting our method for further research.},
	number = {2},
	journal = {IMWUT},
	author = {Apthorpe, Noah and Shvartzshnaider, Yan and Mathur, Arunesh and Reisman, Dillon and Feamster, Nick},
	year = {2018},
	file = {Apthorpe et al_2018_Discovering Smart Home Internet of Things Privacy Norms Using Contextual Integrity.pdf:/Users/orsonxu/Zotero/storage/ZEBM27QN/Apthorpe et al_2018_Discovering Smart Home Internet of Things Privacy Norms Using Contextual Integrity.pdf:application/pdf;Apthorpe et al_2018_Discovering Smart Home Internet of Things Privacy Norms Using Contextual Integrity.pdf:/Users/orsonxu/Zotero/storage/S6W5ULZD/Apthorpe et al_2018_Discovering Smart Home Internet of Things Privacy Norms Using Contextual Integrity.pdf:application/pdf},
}

@article{Acquisti2013,
	title = {What {Is} {Privacy} {Worth}?},
	volume = {42},
	issn = {0047-2530},
	doi = {10.1086/671754},
	abstract = {Understanding the value that individuals assign to the protection of their personal data is of great importance for business, law, and public policy. We use a field experiment informed by behavioral economics and decision research to investigate individual privacy valuations and find evidence of endowment and order effects. Individuals assigned markedly different values to the privacy of their data depending on (1) whether they were asked to consider how much money they would accept to disclose otherwise private information or how much they would pay to protect otherwise public information and (2) the order in which they considered different offers for their data. The gap between such values is large compared with that observed in comparable studies of consumer goods. The results highlight the sensitivity of privacy valuations to contextual, nonnormative factors.},
	number = {2},
	journal = {The Journal of Legal Studies},
	author = {Acquisti, Alessandro and John, Leslie K. and Loewenstein, George},
	year = {2013},
	note = {ISBN: 9140231348},
	pages = {249--274},
	file = {Acquisti et al_2013_What Is Privacy Worth.pdf:/Users/orsonxu/Zotero/storage/7KS7ZV2N/Acquisti et al_2013_What Is Privacy Worth.pdf:application/pdf;Acquisti et al_2013_What Is Privacy Worth.pdf:/Users/orsonxu/Zotero/storage/JULGJANL/Acquisti et al_2013_What Is Privacy Worth.pdf:application/pdf},
}

@article{Beresford2012,
	title = {Unwillingness to pay for privacy: {A} field experiment},
	volume = {117},
	issn = {01651765},
	url = {http://dx.doi.org/10.1016/j.econlet.2012.04.077},
	doi = {10.1016/j.econlet.2012.04.077},
	abstract = {We measure willingness to pay for privacy in a field experiment. Participants bought at most one DVD from one of two competing online stores. One store consistently required more sensitive personal data than the other, but otherwise the stores were identical. In one treatment, DVDs were one Euro cheaper at the store requesting more personal information, and almost all buyers chose the cheaper store. Surprisingly, in the second treatment when prices were identical, participants bought from both shops equally often. © 2012 Elsevier B.V.},
	number = {1},
	journal = {Economics Letters},
	author = {Beresford, Alastair R. and Kübler, Dorothea and Preibusch, Sören},
	year = {2012},
	note = {Publisher: Elsevier B.V.},
	keywords = {Privacy, Field experiment, Willingness to pay},
	pages = {25--27},
	file = {Beresford et al_2012_Unwillingness to pay for privacy.pdf:/Users/orsonxu/Zotero/storage/FHCY98KZ/Beresford et al_2012_Unwillingness to pay for privacy.pdf:application/pdf;Beresford et al_2012_Unwillingness to pay for privacy.pdf:/Users/orsonxu/Zotero/storage/8WNLIXIY/Beresford et al_2012_Unwillingness to pay for privacy.pdf:application/pdf},
}

@article{Jaimes2015,
	title = {A {Survey} of {Incentive} {Techniques} for {Mobile} {Crowd} {Sensing}},
	volume = {2},
	issn = {23274662},
	doi = {10.1109/JIOT.2015.2409151},
	abstract = {Crowd Sensing (CS) is an approach to collecting many samples of a phenomena of interest by distributing the sampling across a large number of individuals. While any one individual may not provide sufficient samples, aggregating samples across many individuals provides high-quality, high-coverage measurements of the phenomena. Thus, for participatory sensing to be successful, one must motivate a large number of individuals to participate. In this work, we review a variety of incentive mechanisms that motivate people to contribute to a CS effort. We then establish a set of design constraints or minimum requirements that any incentive mechanism for CS must have. These design constrains are then used as metrics to evaluate those approaches and determine their advantages and disadvantages. We also contribute a taxonomy of CS incentive mechanisms and show how current systems fit within this taxonomy. We conclude with the identification of new types of incentive mechanisms that require further investigation.},
	number = {5},
	journal = {IEEE Internet of Things Journal},
	author = {Jaimes, Luis G. and Vergara-Laurens, Idalides J. and Raij, Andrew},
	year = {2015},
	note = {Publisher: IEEE},
	keywords = {Games, Crowd Sensing, Incentives, Reverse Auction},
	pages = {370--380},
	file = {Jaimes et al_2015_A Survey of Incentive Techniques for Mobile Crowd Sensing.pdf:/Users/orsonxu/Zotero/storage/Y26R9VUX/Jaimes et al_2015_A Survey of Incentive Techniques for Mobile Crowd Sensing.pdf:application/pdf;Jaimes et al_2015_A Survey of Incentive Techniques for Mobile Crowd Sensing.pdf:/Users/orsonxu/Zotero/storage/BXUT9QB4/Jaimes et al_2015_A Survey of Incentive Techniques for Mobile Crowd Sensing.pdf:application/pdf},
}

@article{Shilton2009,
	title = {Designing the {Personal} {Data} {Stream}: {Enabling} {Participatory} {Privacy} in {Mobile} {Personal} {Sensing}},
	number = {September},
	journal = {TPRC},
	author = {Shilton, Katie and Burke, Jeffrey A and Estrin, Deborah and Govindan, Ramesh and Hansen, Mark},
	year = {2009},
	pages = {25--27},
	file = {Shilton et al_2009_Designing the Personal Data Stream.pdf:/Users/orsonxu/Zotero/storage/MQMKS4UM/Shilton et al_2009_Designing the Personal Data Stream.pdf:application/pdf;Shilton et al_2009_Designing the Personal Data Stream.pdf:/Users/orsonxu/Zotero/storage/IMB4JCDA/Shilton et al_2009_Designing the Personal Data Stream.pdf:application/pdf},
}

@article{Kapadia2015,
	title = {Interrupt {Now} or {Inform} {Later}? - {Comparing} {Immediate} and {Delayed} {Privacy} {Feedback}},
	doi = {10.1145/2702123.2702165},
	journal = {CHI},
	author = {Kapadia, Apu and Lee, Adam J. and Hoyle, Roberto and Patil, Sameer and Schlegel, Roman},
	year = {2015},
	note = {ISBN: 978-1-4503-3145-6},
	pages = {1415--1418},
	file = {Kapadia et al_2015_Interrupt Now or Inform Later.pdf:/Users/orsonxu/Zotero/storage/433Z6C3J/Kapadia et al_2015_Interrupt Now or Inform Later.pdf:application/pdf;Kapadia et al_2015_Interrupt Now or Inform Later.pdf:/Users/orsonxu/Zotero/storage/3S4J9436/Kapadia et al_2015_Interrupt Now or Inform Later.pdf:application/pdf},
}

@article{Wang2019,
	title = {Modeling {Spatio}-{Temporal} {App} {Usage} for a {Large} {User} {Population}},
	volume = {3},
	doi = {10.1145/3314414},
	number = {1},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Wang, Huandong and Li, Yong and Zeng, Sihan and Wang, Gang and Zhang, Pengyu and Hui, Pan and Jin, Depeng},
	year = {2019},
	keywords = {app usage, Bayesian mixture model, spatio-temporal},
	pages = {1--23},
	file = {Wang et al_2019_Modeling Spatio-Temporal App Usage for a Large User Population.pdf:/Users/orsonxu/Zotero/storage/QHCVHHWP/Wang et al_2019_Modeling Spatio-Temporal App Usage for a Large User Population.pdf:application/pdf;Wang et al_2019_Modeling Spatio-Temporal App Usage for a Large User Population.pdf:/Users/orsonxu/Zotero/storage/53X3J8NN/Wang et al_2019_Modeling Spatio-Temporal App Usage for a Large User Population.pdf:application/pdf},
}

@article{Lin2012,
	title = {Expectation and {Purpose}: {Understanding} {Users}’ {Mental} {Models} of {Mobile} {App} {Privacy} through {Crowdsourcing}},
	doi = {10.1145/2370216.2370290},
	abstract = {Smartphone security research has produced many useful tools to analyze the privacy-related behaviors of mobile apps. However, these automated tools cannot assess people’s perceptions of whether a given action is legitimate, or how that action makes them feel with respect to privacy. For example, automated tools might detect that a blackjack game and a map app both use one’s location information, but people would likely view the map’s use of that data as more legitimate than the game. Our work introduces a new model for privacy, namely privacy as expectations. We report on the results of using crowdsourcing to capture users’ expectations of what sensitive resources mobile apps use. We also report on a new privacy summary interface that prioritizes and highlights places where mobile apps break people’s expectations. We conclude with a discussion of implications for employing crowdsourcing as a privacy evaluation technique.},
	journal = {Ubicomp},
	author = {Lin, Jialiu and Zhang, Joy and Amini, Shahriyar and Hong, Jason I. and Sadeh, Norman and Lindqvist, Janne},
	year = {2012},
	note = {ISBN: 9781450312240},
	pages = {501},
	file = {Lin et al_2012_Expectation and Purpose.pdf:/Users/orsonxu/Zotero/storage/94VT5SIS/Lin et al_2012_Expectation and Purpose.pdf:application/pdf;Lin et al_2012_Expectation and Purpose.pdf:/Users/orsonxu/Zotero/storage/FGMK68J3/Lin et al_2012_Expectation and Purpose.pdf:application/pdf},
}

@article{zhang_troika_2015,
	title = {{TROIKA}: {A} {General} {Framework} for {Heart} {Rate} {Monitoring} {Using} {Wrist}-{Type} {Photoplethysmographic} {Signals} {During} {Intensive} {Physical} {Exercise}},
	volume = {62},
	issn = {1558-2531},
	shorttitle = {{TROIKA}},
	doi = {10.1109/TBME.2014.2359372},
	abstract = {Heart rate monitoring using wrist-type photoplethysmographic signals during subjects' intensive exercise is a difficult problem, since the signals are contaminated by extremely strong motion artifacts caused by subjects' hand movements. So far few works have studied this problem. In this study, a general framework, termed TROIKA, is proposed, which consists of signal decomposiTion for denoising, sparse signal RecOnstructIon for high-resolution spectrum estimation, and spectral peaK trAcking with verification. The TROIKA framework has high estimation accuracy and is robust to strong motion artifacts. Many variants can be straightforwardly derived from this framework. Experimental results on datasets recorded from 12 subjects during fast running at the peak speed of 15 km/h showed that the average absolute error of heart rate estimation was 2.34 beat per minute, and the Pearson correlation between the estimates and the ground truth of heart rate was 0.992. This framework is of great values to wearable devices such as smartwatches which use PPG signals to monitor heart rate for fitness.},
	number = {2},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Zhang, Zhilin and Pi, Zhouyue and Liu, Benyuan},
	month = feb,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Biomedical Engineering},
	keywords = {Acceleration, Ambulatory monitoring, Estimation, Heart rate, heart rate monitoring, Monitoring, photoplethysmograph (PPG), signal decomposition, Signal resolution, singular spectrum analysis (SSA), sparse signal reconstruction (SSR), Spectral analysis, Time series analysis, wearable computing},
	pages = {522--531},
	file = {IEEE Xplore Abstract Record:/Users/orsonxu/Zotero/storage/K2GGGZFT/6905737.html:text/html;IEEE Xplore Full Text PDF:/Users/orsonxu/Zotero/storage/62357LGY/Zhang et al. - 2015 - TROIKA A General Framework for Heart Rate Monitor.pdf:application/pdf},
}

@article{mohr_personal_2017,
	title = {Personal {Sensing}: {Understanding} {Mental} {Health} {Using} {Ubiquitous} {Sensors} and {Machine} {Learning}},
	volume = {13},
	issn = {1548-5943, 1548-5951},
	shorttitle = {Personal {Sensing}},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-clinpsy-032816-044949},
	doi = {10.1146/annurev-clinpsy-032816-044949},
	abstract = {Sensors in everyday devices, such as our phones, wearables, and computers, leave a stream of digital traces. Personal sensing refers to collecting and analyzing data from sensors embedded in the context of daily life with the aim of identifying human behaviors, thoughts, feelings, and traits. This article provides a critical review of personal sensing research related to mental health, focused principally on smartphones, but also including studies of wearables, social media, and computers. We provide a layered, hierarchical model for translating raw sensor data into markers of behaviors and states related to mental health. Also discussed are research methods as well as challenges, including privacy and problems of dimensionality. Although personal sensing is still in its infancy, it holds great promise as a method for conducting mental health research and as a clinical tool for monitoring at-risk populations and providing the foundation for the next generation of mobile health (or mHealth) interventions.},
	language = {en},
	number = {1},
	urldate = {2021-10-30},
	journal = {Annual Review of Clinical Psychology},
	author = {Mohr, David C. and Zhang, Mi and Schueller, Stephen M.},
	month = may,
	year = {2017},
	pages = {23--47},
	file = {Mohr et al. - 2017 - Personal Sensing Understanding Mental Health Usin.pdf:/Users/orsonxu/Zotero/storage/TQYT5WN5/Mohr et al. - 2017 - Personal Sensing Understanding Mental Health Usin.pdf:application/pdf},
}

@article{ha_wistress_2021,
	title = {{WiStress}: {Contactless} {Stress} {Monitoring} {Using} {Wireless} {Signals}},
	volume = {5},
	issn = {2474-9567},
	shorttitle = {{WiStress}},
	url = {https://dl.acm.org/doi/10.1145/3478121},
	doi = {10.1145/3478121},
	abstract = {Stress plays a critical role in our lives, impacting our productivity and our long-term physiological and psychological well-being. This has motivated the development of stress monitoring solutions to better understand stress, its impact on productivity and teamwork, and help users adapt their habits toward more sustainable stress levels. However, today’s stress monitoring solutions remain obtrusive, requiring active user participation (e.g., self-reporting), interfering with people’s daily activities, and often adding more burden to users looking to reduce their stress. In this paper, we introduce WiStress, the first system that can passively monitor a user’s stress levels by relying on wireless signals. WiStress does not require users to actively provide input or to wear any devices on their bodies. It operates by transmitting ultra-low-power wireless signals and measuring their reflections off the user’s body. WiStress introduces two key innovations. First, it presents the first machine learning network that can accurately and robustly extract heartbeat intervals (IBI’s) from wireless reflections without constraints on a user’s daily activities. Second, it introduces a stress classification framework that combines the extracted heartbeats with other wirelessly captured stress-related features in order to infer a subject’s stress level. We built a prototype of WiStress and tested it on 22 different subjects across different environments in both stress-induced and free-living conditions. Our results demonstrate that WiStress has high accuracy (84\%-95\%) in inferring a person’s stress level in a fully-automated way, paving the way for ubiquitous sensing systems that can monitor stress and provide feedback to improve productivity, health, and well-being. CCS Concepts: • Human-centered computing → Ubiquitous and mobile computing systems and tools.},
	language = {en},
	number = {3},
	urldate = {2021-10-28},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Ha, Unsoo and Madani, Sohrab and Adib, Fadel},
	month = sep,
	year = {2021},
	pages = {1--37},
	file = {Ha et al. - 2021 - WiStress Contactless Stress Monitoring Using Wire.pdf:/Users/orsonxu/Zotero/storage/CKV9J292/Ha et al. - 2021 - WiStress Contactless Stress Monitoring Using Wire.pdf:application/pdf},
}

@inproceedings{hovsepian_cstress_2015,
	address = {Osaka, Japan},
	title = {{cStress}: towards a gold standard for continuous stress assessment in the mobile environment},
	isbn = {978-1-4503-3574-4},
	shorttitle = {{cStress}},
	url = {http://dl.acm.org/citation.cfm?doid=2750858.2807526},
	doi = {10.1145/2750858.2807526},
	abstract = {Recent advances in mobile health have produced several new models for inferring stress from wearable sensors. But, the lack of a gold standard is a major hurdle in making clinical use of continuous stress measurements derived from wearable sensors. In this paper, we present a stress model (called cStress) that has been carefully developed with attention to every step of computational modeling including data collection, screening, cleaning, ﬁltering, feature computation, normalization, and model training. More importantly, cStress was trained using data collected from a rigorous lab study with 21 participants and validated on two independently collected data sets — in a lab study on 26 participants and in a week-long ﬁeld study with 20 participants. In testing, the model obtains a recall of 89\% and a false positive rate of 5\% on lab data. On ﬁeld data, the model is able to predict each instantaneous self-report with an accuracy of 72\%.},
	language = {en},
	urldate = {2021-10-21},
	booktitle = {Proceedings of the 2015 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} - {UbiComp} '15},
	publisher = {ACM Press},
	author = {Hovsepian, Karen and al'Absi, Mustafa and Ertin, Emre and Kamarck, Thomas and Nakajima, Motohiro and Kumar, Santosh},
	year = {2015},
	pages = {493--504},
	file = {Hovsepian et al. - 2015 - cStress towards a gold standard for continuous st.pdf:/Users/orsonxu/Zotero/storage/HA9JWTAQ/Hovsepian et al. - 2015 - cStress towards a gold standard for continuous st.pdf:application/pdf},
}

@inproceedings{rahman_towards_2021,
	address = {Athens, Greece},
	title = {Towards {Motion}-{Aware} {Passive} {Resting} {Respiratory} {Rate} {Monitoring} {Using} {Earbuds}},
	isbn = {978-1-66540-362-7},
	url = {https://ieeexplore.ieee.org/document/9507016/},
	doi = {10.1109/BSN51625.2021.9507016},
	abstract = {Breathing rate is an important vital sign and an indicator of overall health and ﬁtness. Traditionally breathing is monitored using specialized devices such as chestband or spirometers which are uncomfortable for daily use. Recent works show the feasibility of estimating breathing rate using earbuds’ motion sensors. However, non-breathing head motion is one of the biggest challenges for breathing rate estimation using earbuds. In this paper, we propose algorithms to estimate breathing rate in presence of non-breathing head motion using inertial sensors embedded in commodity earbuds. Using the chestband as a reference device, we show that our algorithms can estimate breathing rate in resting positions with error rate 2.34 breaths per minute (BPM). Our algorithms can handle passive head motion and reduce the error by 27.78\%. Furthermore, our algorithms can handle active head motion and help reduce the error by 45.70\% when intentional non-breathing head motion is present in the data segment. It can be a big stride towards passive breathing monitoring in daily life using commodity earbuds.},
	language = {en},
	urldate = {2021-10-20},
	booktitle = {2021 {IEEE} 17th {International} {Conference} on {Wearable} and {Implantable} {Body} {Sensor} {Networks} ({BSN})},
	publisher = {IEEE},
	author = {Rahman, Md Mahbubur and Ahmed, Tousif and Ahmed, Mohsin Yusuf and Nemati, Ebrahim and Dinh, Minh and Folkman, Nathan and Hasan, Md Mehedi and Kuang, Jilong and Gao, Jun Alex},
	month = jul,
	year = {2021},
	pages = {1--4},
	file = {Rahman et al. - 2021 - Towards Motion-Aware Passive Resting Respiratory R.pdf:/Users/orsonxu/Zotero/storage/HPCPA4XJ/Rahman et al. - 2021 - Towards Motion-Aware Passive Resting Respiratory R.pdf:application/pdf},
}

@article{ahmed_rrmonitor_nodate,
	title = {{RRMonitor}: {A} {Resource}-{Aware} {End}-to-{End} {System} for {Continuous} {Monitoring} of {Respiration} {Rate} {Using} {Earbuds}},
	abstract = {Respiration rate is considered as a critical vital sign, and daily monitoring of respiration rate could provide helpful information about any acute condition in the human body. While researchers have been exploring mobile devices for respiration rate monitoring, passive and continuous monitoring is still not feasible due to many usability challenges (e.g., active participation) in existing approaches. This paper presents an end-to-end system called RRMonitor that leverages the movement sensors from commodity earbuds to continuously monitor the respiration rate in near real-time. While developing the systems, we extensively explored some key parameters, algorithms, and approaches from existing literature that are better suited for continuous and passive respiration rate monitoring. RRMonitor can passively track the respiration rate with a mean absolute error as low as 1.64 cycles per minute without requiring active participation from the user.},
	language = {en},
	author = {Ahmed, Tousif and Rahman, Mahbubur and Ahmed, Mohsin Yusuf and Nemati, Ebrahim and Dinh, Minh and Folkman, Nathan and Kuang, Jilong and Gao, Alex},
	pages = {5},
	file = {Ahmed et al. - RRMonitor A Resource-Aware End-to-End System for .pdf:/Users/orsonxu/Zotero/storage/C5JJWPN2/Ahmed et al. - RRMonitor A Resource-Aware End-to-End System for .pdf:application/pdf},
}

@article{shaffer_overview_2017,
	title = {An {Overview} of {Heart} {Rate} {Variability} {Metrics} and {Norms}},
	volume = {5},
	issn = {2296-2565},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5624990/},
	doi = {10.3389/fpubh.2017.00258},
	abstract = {Healthy biological systems exhibit complex patterns of variability that can be described by mathematical chaos. Heart rate variability (HRV) consists of changes in the time intervals between consecutive heartbeats called interbeat intervals (IBIs). A healthy heart is not a metronome. The oscillations of a healthy heart are complex and constantly changing, which allow the cardiovascular system to rapidly adjust to sudden physical and psychological challenges to homeostasis. This article briefly reviews current perspectives on the mechanisms that generate 24 h, short-term ({\textasciitilde}5 min), and ultra-short-term ({\textless}5 min) HRV, the importance of HRV, and its implications for health and performance. The authors provide an overview of widely-used HRV time-domain, frequency-domain, and non-linear metrics. Time-domain indices quantify the amount of HRV observed during monitoring periods that may range from {\textasciitilde}2 min to 24 h. Frequency-domain values calculate the absolute or relative amount of signal energy within component bands. Non-linear measurements quantify the unpredictability and complexity of a series of IBIs. The authors survey published normative values for clinical, healthy, and optimal performance populations. They stress the importance of measurement context, including recording period length, subject age, and sex, on baseline HRV values. They caution that 24 h, short-term, and ultra-short-term normative values are not interchangeable. They encourage professionals to supplement published norms with findings from their own specialized populations. Finally, the authors provide an overview of HRV assessment strategies for clinical and optimal performance interventions.},
	urldate = {2021-10-20},
	journal = {Frontiers in Public Health},
	author = {Shaffer, Fred and Ginsberg, J. P.},
	month = sep,
	year = {2017},
	pmid = {29034226},
	pmcid = {PMC5624990},
	pages = {258},
	file = {PubMed Central Full Text PDF:/Users/orsonxu/Zotero/storage/35GD7WCT/Shaffer and Ginsberg - 2017 - An Overview of Heart Rate Variability Metrics and .pdf:application/pdf},
}

@article{giannakakis_review_2019,
	title = {Review on psychological stress detection using biosignals},
	issn = {1949-3045},
	doi = {10.1109/TAFFC.2019.2927337},
	abstract = {This review investigates the effects of psychological stress on the human body measured through biosignals. When a potentially threatening stimulus is perceived, a cascade of physiological processes occurs mobilizing the body and nervous system to confront the imminent threat and ensure effective adaptation. Biosignals that can be measured reliably in relation to such stressors include physiological (EEG, ECG, EDA, EMG) and physical measures (respiratory rate, speech, skin temperature, pupil size, eye activity). A fundamental objective in this area of psychophysiological research is to establish reliable biosignal indices that reveal the underlying physiological mechanisms of the stress response. Motivated by the lack of comprehensive guidelines on the relationship between the multitude of biosignal features used in the literature and their corresponding behaviour during stress, in this paper, the impact of stress to multiple bodily responses is surveyed. Emphasis is put on the efficiency, robustness and consistency of biosignal data features across the current state of knowledge in stress detection. It is also explored multimodal biosignal analysis and modelling methods for deriving accurate stress correlates. This paper aims to provide a comprehensive review on biosignal patterns caused during stress conditions and reliable practical guidelines towards more efficient detection of stress.},
	journal = {IEEE Transactions on Affective Computing},
	author = {Giannakakis, Giorgos and Grigoriadis, Dimitris and Giannakaki, Katerina and Simantiraki, Olympia and Roniotis, Alexandros and Tsiknakis, Manolis},
	year = {2019},
	note = {Conference Name: IEEE Transactions on Affective Computing},
	keywords = {ECG, EDA, EEG, Computational complexity, Estimation, biosignals, Channel estimation, Direction-of-arrival estimation, Eigenvalues and eigenfunctions, HRV, MIMO communication, physiological measures, Principal component analysis, stress, stress response},
	pages = {1--1},
	file = {IEEE Xplore Abstract Record:/Users/orsonxu/Zotero/storage/BA5XLXAN/8758154.html:text/html;IEEE Xplore Full Text PDF:/Users/orsonxu/Zotero/storage/5UPQISLG/Giannakakis et al. - 2019 - Review on psychological stress detection using bio.pdf:application/pdf},
}

@article{kim_stress_2018,
	title = {Stress and {Heart} {Rate} {Variability}: {A} {Meta}-{Analysis} and {Review} of the {Literature}},
	volume = {15},
	issn = {1738-3684},
	shorttitle = {Stress and {Heart} {Rate} {Variability}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5900369/},
	doi = {10.30773/pi.2017.08.17},
	abstract = {Objective
Physical or mental imbalance caused by harmful stimuli can induce stress to maintain homeostasis. During chronic stress, the sympathetic nervous system is hyperactivated, causing physical, psychological, and behavioral abnormalities. At present, there is no accepted standard for stress evaluation. This review aimed to survey studies providing a rationale for selecting heart rate variability (HRV) as a psychological stress indicator.


Methods
Term searches in the Web of Science®, National Library of Medicine (PubMed), and Google Scholar databases yielded 37 publications meeting our criteria. The inclusion criteria were involvement of human participants, HRV as an objective psychological stress measure, and measured HRV reactivity.


Results
In most studies, HRV variables changed in response to stress induced by various methods. The most frequently reported factor associated with variation in HRV variables was low parasympathetic activity, which is characterized by a decrease in the high-frequency band and an increase in the low-frequency band. Neuroimaging studies suggested that HRV may be linked to cortical regions (e.g., the ventromedial prefrontal cortex) that are involved in stressful situation appraisal.


Conclusion
In conclusion, the current neurobiological evidence suggests that HRV is impacted by stress and supports its use for the objective assessment of psychological health and stress.},
	number = {3},
	urldate = {2021-10-20},
	journal = {Psychiatry Investigation},
	author = {Kim, Hye-Geum and Cheon, Eun-Jin and Bai, Dai-Seg and Lee, Young Hwan and Koo, Bon-Hoon},
	month = mar,
	year = {2018},
	pmid = {29486547},
	pmcid = {PMC5900369},
	pages = {235--245},
	file = {PubMed Central Full Text PDF:/Users/orsonxu/Zotero/storage/LNIHPVRI/Kim et al. - 2018 - Stress and Heart Rate Variability A Meta-Analysis.pdf:application/pdf},
}

@article{Christin2011,
	title = {A survey on privacy in mobile participatory sensing applications},
	volume = {84},
	issn = {01641212},
	url = {http://dx.doi.org/10.1016/j.jss.2011.06.073},
	doi = {10.1016/j.jss.2011.06.073},
	abstract = {The presence of multimodal sensors on current mobile phones enables a broad range of novel mobile applications. Environmental and user-centric sensor data of unprecedented quantity and quality can be captured and reported by a possible user base of billions of mobile phone subscribers worldwide. The strong focus on the collection of detailed sensor data may however compromise user privacy in various regards, e.g.; by tracking a user's current location. In this survey, we identify the sensing modalities used in current participatory sensing applications, and assess the threats to user privacy when personal information is sensed and disclosed. We outline how privacy aspects are addressed in existing sensing applications, and determine the adequacy of the solutions under real-world conditions. Finally, we present countermeasures from related research fields, and discuss their applicability in participatory sensing scenarios. Based on our findings, we identify open issues and outline possible solutions to guarantee user privacy in participatory sensing. © 2011 Elsevier Inc. All rights reserved.},
	number = {11},
	journal = {Journal of Systems and Software},
	author = {Christin, Delphine and Reinhardt, Andreas and Kanhere, Salil S. and Hollick, Matthias},
	year = {2011},
	note = {Publisher: Elsevier Inc.},
	keywords = {Mobile sensing, Privacy, Participatory sensing},
	pages = {1928--1946},
	file = {Christin et al_2011_A survey on privacy in mobile participatory sensing applications.pdf:/Users/orsonxu/Zotero/storage/IYAG2GPD/Christin et al_2011_A survey on privacy in mobile participatory sensing applications.pdf:application/pdf;Christin et al_2011_A survey on privacy in mobile participatory sensing applications.pdf:/Users/orsonxu/Zotero/storage/FA6BI9AF/Christin et al_2011_A survey on privacy in mobile participatory sensing applications.pdf:application/pdf},
}

@article{Guo2013,
	title = {Opportunistic {IoT}: {Exploring} the harmonious interaction between human and the internet of things},
	volume = {36},
	issn = {10848045},
	url = {http://dx.doi.org/10.1016/j.jnca.2012.12.028},
	doi = {10.1016/j.jnca.2012.12.028},
	number = {6},
	journal = {Journal of Network and Computer Applications},
	author = {Guo, Bin and Zhang, Daqing and Wang, Zhu and Yu, Zhiwen and Zhou, Xingshe},
	year = {2013},
	note = {Publisher: Elsevier},
	keywords = {Heterogeneous community orchestration, Human-centric sensing, Information dissemination, Opportunistic IoT, Opportunistic mobile social networking},
	pages = {1531--1539},
	file = {Guo et al_2013_Opportunistic IoT.pdf:/Users/orsonxu/Zotero/storage/W4A8HEI6/Guo et al_2013_Opportunistic IoT.pdf:application/pdf;Guo et al_2013_Opportunistic IoT.pdf:/Users/orsonxu/Zotero/storage/D2L45XEL/Guo et al_2013_Opportunistic IoT.pdf:application/pdf},
}

@article{Singh2013,
	title = {Predicting spending behavior using socio-mobile features},
	doi = {10.1109/SocialCom.2013.33},
	abstract = {Human spending behavior is essentially social. This work motivates and grounds the use of mobile phone based social interaction features for classifying spending behavior. Using a data set involving 52 adults (26 couples) living in a community for over a year, we find that social behavior measured via face-to-face interaction, call, and SMS logs, can be used to predict the spending behavior for couples in terms of their propensity to explore diverse businesses, become loyal customers, and overspend. Our results show that mobile phone based social interaction patterns can provide more predictive power on spending behavior than often-used personality based features. Obtaining novel insights on spending behavior using social-computing frameworks can be of vital importance to economists, marketing professionals, and policy makers. © 2013 IEEE.},
	number = {September 2016},
	journal = {Proceedings of the International Conference on Social Computing},
	author = {Singh, Vivek K. and Freeman, Laura and Lepri, Bruno and Pentland, Alex},
	year = {2013},
	note = {ISBN: 9780769551371},
	keywords = {Behavioral marketing, Customer Behavior, Reality Mining, Social behavior, Social Computing, Social spending, Spending behavior},
	pages = {174--179},
	file = {Singh et al_2013_Predicting spending behavior using socio-mobile features.pdf:/Users/orsonxu/Zotero/storage/N2YFQ9SF/Singh et al_2013_Predicting spending behavior using socio-mobile features.pdf:application/pdf;Singh et al_2013_Predicting spending behavior using socio-mobile features.pdf:/Users/orsonxu/Zotero/storage/CRF9IDU5/Singh et al_2013_Predicting spending behavior using socio-mobile features.pdf:application/pdf},
}

@article{Montjoye2015,
	title = {Unique in the shopping mall: {On} the reidentifiability of credit card metadata},
	volume = {347},
	number = {6221},
	journal = {Science},
	author = {Montjoye, Yves-Alexandre de and Radaelli, Laura and Singh, Vivek Kumar and Pentland, Alex "Sandy"},
	year = {2015},
	file = {Montjoye et al_2015_Unique in the shopping mall.pdf:/Users/orsonxu/Zotero/storage/KLEP5Y6Q/Montjoye et al_2015_Unique in the shopping mall.pdf:application/pdf;Montjoye et al_2015_Unique in the shopping mall.pdf:/Users/orsonxu/Zotero/storage/SSTB82SU/Montjoye et al_2015_Unique in the shopping mall.pdf:application/pdf},
}

@article{Singh2015,
	title = {Money walks: {Implicit} mobility behavior and financial well-being},
	volume = {10},
	issn = {19326203},
	doi = {10.1371/journal.pone.0136628},
	abstract = {Traditional financial decision systems (e.g. credit) had to rely on explicit individual traits like age, gender, job type, and marital status, while being oblivious to spatio-temporal mobility or the habits of the individual involved. Emerging trends in geo-aware and mobile payment systems, and the resulting "big data," present an opportunity to study human consumption patterns across space and time. Taking inspiration from animal behavior studies that have reported significant interconnections between animal spatio-temporal "foraging" behavior and their life outcomes, we analyzed a corpus of hundreds of thousands of human economic transactions and found that financial outcomes for individuals are intricately linked with their spatio-temporal traits like exploration, engagement, and elasticity. Such features yield models that are 30\% to 49\% better at predicting future financial difficulties than the comparable demographic models.},
	number = {8},
	journal = {PLoS ONE},
	author = {Singh, Vivek Kumar and Bozkaya, Burcin and Pentland, Alex},
	year = {2015},
	pmid = {26317339},
	pages = {1--17},
	file = {Singh et al_2015_Money walks.PDF:/Users/orsonxu/Zotero/storage/WDVE2TNR/Singh et al_2015_Money walks.PDF:application/pdf;Singh et al_2015_Money walks.PDF:/Users/orsonxu/Zotero/storage/GY2L6NXB/Singh et al_2015_Money walks.PDF:application/pdf},
}

@article{Saha2019,
	title = {Social {Media} as a {Passive} {Sensor} in {Longitudinal} {Studies} of {Human} {Behavior} and {Wellbeing}},
	journal = {Extended Abstracts of Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	author = {Saha, Koustuv and Bayraktaroglu, Ayse E. and Campbell, Andrew T. and Chawla, Nitesh V. and Choudhury, Munmun De and D’Mello, Sidney K. and Dey, Anind K. and Gao, Ge and Gregg, Julie M. and Jagannath, Krithika and Mark, Gloria and Martinez, Gonzalo J. and Mattingly, Stephen M. and Moskal, Edward and Sirigiri, Anusha and Striegel, Aaron and Yoo, Dong Whi},
	year = {2019},
	note = {ISBN: 9781450359719},
	keywords = {acm reference format, and, 2019, koustuv saha et al, multimodal sensing, passive sensing, passive sensor in longitudinal, personality traits, social media, social media as a, studies of human behavior, workplace},
	file = {Saha et al_2019_Social Media as a Passive Sensor in Longitudinal Studies of Human Behavior and Wellbeing.pdf:/Users/orsonxu/Zotero/storage/PW9KQSPA/Saha et al_2019_Social Media as a Passive Sensor in Longitudinal Studies of Human Behavior and Wellbeing.pdf:application/pdf;Saha et al_2019_Social Media as a Passive Sensor in Longitudinal Studies of Human Behavior and Wellbeing.pdf:/Users/orsonxu/Zotero/storage/6IC4UVDI/Saha et al_2019_Social Media as a Passive Sensor in Longitudinal Studies of Human Behavior and Wellbeing.pdf:application/pdf},
}

@article{Shmueli2014,
	title = {Sensing, understanding, and shaping social behavior},
	volume = {1},
	issn = {2329924X},
	doi = {10.1109/TCSS.2014.2307438},
	abstract = {The ability to understand social systems through the aid of computational tools is central to the emerging field of computational social systems. Such understanding can answer epistemological questions on human behavior in a data-driven manner, and provide prescriptive guidelines for persuading humans to undertake certain actions in real-world social scenarios. The growing number of works in this subfield has the potential to impact multiple walks of human life including health, wellness, productivity, mobility, transportation, education, shopping, and sustenance. The contribution of this paper is twofold. First, we provide a functional survey of recent advances in sensing, understanding, and shaping human behavior, focusing on real-world behavior of users as measured using passive sensors. Second, we present a case study on how trust, which is an important building block of computational social systems, can be quantified, sensed, and applied to shape human behavior. Our findings suggest that: 1) trust can be operationalized and predicted via computational methods (passive sensing and network analysis) and 2) trust has a significant impact on social persuasion; in fact, it was found to be significantly more effective than the closeness of ties in determining the amount of behavior change.},
	number = {1},
	journal = {IEEE Transactions on Computational Social Systems},
	author = {Shmueli, Erez and Singh, Vivek K. and Lepri, Bruno and Pentland, Alex},
	year = {2014},
	note = {Publisher: IEEE},
	keywords = {Mobile sensing, persuasive computing, social influence, social systems trust},
	pages = {22--34},
	file = {Shmueli et al_2014_Sensing, understanding, and shaping social behavior.pdf:/Users/orsonxu/Zotero/storage/PRYFBI7M/Shmueli et al_2014_Sensing, understanding, and shaping social behavior.pdf:application/pdf;Shmueli et al_2014_Sensing, understanding, and shaping social behavior.pdf:/Users/orsonxu/Zotero/storage/8W3HPIV2/Shmueli et al_2014_Sensing, understanding, and shaping social behavior.pdf:application/pdf},
}

@article{Mehrotra2017,
	title = {{MyTraces}: {Investigating} {Correlation} and {Causation} between {Users}’ {Emotional} {States} and {Mobile} {Phone} {Interaction}},
	volume = {1},
	issn = {24749567},
	url = {http://dl.acm.org/citation.cfm?doid=3139486.3130948},
	doi = {10.1145/3130948},
	abstract = {Most of the existing work concerning the analysis of emotional states and mobile phone interaction has been based on correlation analysis. In this paper, for the first time, we carry out a causality study to investigate the causal links between users’ emotional states and their interaction with mobile phones, which could provide valuable information to practitioners and researchers. The analysis is based on a dataset collected in-the-wild. We recorded 5,118 mood reports from 28 users over a period of 20 days. Our results show that users’ emotions have a causal impact on different aspects of mobile phone interaction. On the other hand, we can observe a causal impact of the use of specific applications, reflecting the external users’ context, such as socializing and traveling, on happiness and stress level. This study has profound implications for the design of interactive mobile systems since it identifies the dimensions that have causal effects on users’ interaction with mobile phones and vice versa. These findings might lead to the design of more effective computing systems and services that rely on the analysis of the emotional state of users, for example for marketing and digital health applications.},
	number = {3},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Mehrotra, Abhinav and Tsapeli, Fani and Hendley, Robert and Musolesi, Mirco},
	year = {2017},
	pmid = {397311},
	note = {ISBN: 9781450335492},
	keywords = {•Computing methodologies  Causal reasoning and dia, •Human-centered computing  Empirical studies in ub, HCI design and evaluation methods},
	pages = {1--21},
	file = {Mehrotra et al_2017_MyTraces.pdf:/Users/orsonxu/Zotero/storage/NBDE8X67/Mehrotra et al_2017_MyTraces.pdf:application/pdf;Mehrotra et al_2017_MyTraces.pdf:/Users/orsonxu/Zotero/storage/MD5X65M7/Mehrotra et al_2017_MyTraces.pdf:application/pdf},
}

@article{Shin2013,
	title = {Automatically detecting problematic use of smartphones},
	issn = {9781450317702},
	url = {http://dl.acm.org/citation.cfm?doid=2493432.2493443},
	doi = {10.1145/2493432.2493443},
	abstract = {Smartphone adoption has increased significantly and, with the increase in smartphone capabilities, this means that users can access the Internet, communicate, and entertain themselves anywhere and anytime. However, there is growing evidence of problematic use of smartphones that impacts both social and heath aspects of users’ lives. Currently, assessment of overuse or problematic use depends on one-time, self-reported behavioral information about phone use. Due to the known issues with self-reports in such types of assessments, we explore an automated, objective and repeatable approach for assessing problematic usage. We collect a wide range of phone usage data from smartphones, identify a number of usage features that are relevant to this assessment, and build detection models based on Adaboost with machine learning algorithms automatically detecting problematic use. We found that the number of apps used per day, the ratio of SMSs to calls, the number of event-initiated sessions, the number of apps used per event initiated session, and the length of non-event- initiated sessions are useful for detecting problematic usage. With these, a detection model can identify users with problematic usage with 89.6\% accuracy (F-score of .707).},
	journal = {Proceedings of the ACM International Joint Conference on Pervasive and Ubiquitous Computing},
	author = {Shin, Choonsung and Dey, Anind K.},
	year = {2013},
	note = {ISBN: 9781450317702},
	pages = {335},
	file = {Shin_Dey_2013_Automatically detecting problematic use of smartphones.pdf:/Users/orsonxu/Zotero/storage/VF3YG54H/Shin_Dey_2013_Automatically detecting problematic use of smartphones.pdf:application/pdf;Shin_Dey_2013_Automatically detecting problematic use of smartphones.pdf:/Users/orsonxu/Zotero/storage/333WFNUE/Shin_Dey_2013_Automatically detecting problematic use of smartphones.pdf:application/pdf},
}

@article{Zhao2016,
	title = {Discovering different kinds of smartphone users through their application usage behaviors},
	url = {http://dl.acm.org/citation.cfm?doid=2971648.2971696},
	doi = {10.1145/2971648.2971696},
	abstract = {Understanding smartphone users is fundamental for creating better smartphones, and improving the smartphone usage experience and generating generalizable and reproducible research. However, smartphone manufacturers and most of the mobile computing research community make a simplifying assumption that all smartphone users are similar or, at best, constitute a small number of user types, based on their behaviors. Manufacturers design phones for the broadest audience and hope they work for all users. Researchers mostly analyze data from smartphone-based user studies and report results without accounting for the many different groups of people that make up the user base of smartphones. In this work, we challenge these elementary characterizations of smartphone users and show evidence of the existence of a much more diverse set of users. We analyzed one month of application usage from 106,762 Android users and discovered 382 distinct types of users based on their application usage behaviors, using our own two-step clustering and feature ranking selection approach. Our results have profound implications on the reproducibility and reliability of mobile computing studies, design and development of applications, determination of which apps should be pre-installed on a smartphone and, in general, on the smartphone usage experience for different types of users.},
	journal = {Proceedings of the ACM International Joint Conference on Pervasive and Ubiquitous Computing},
	author = {Zhao, Sha and Ramos, Julian and Tao, Jianrong and Jiang, Ziwen and Li, Shijian and Wu, Zhaohui and Pan, Gang and Dey, Anind K.},
	year = {2016},
	note = {ISBN: 9781450344616},
	pages = {498--509},
	file = {Zhao et al_2016_Discovering different kinds of smartphone users through their application usage behaviors.pdf:/Users/orsonxu/Zotero/storage/9RSC3UZH/Zhao et al_2016_Discovering different kinds of smartphone users through their application usage behaviors.pdf:application/pdf;Zhao et al_2016_Discovering different kinds of smartphone users through their application usage behaviors.pdf:/Users/orsonxu/Zotero/storage/3QW87C8H/Zhao et al_2016_Discovering different kinds of smartphone users through their application usage behaviors.pdf:application/pdf},
}

@article{Lester2005,
	title = {A hybrid discriminative/generative approach for modeling human activities},
	issn = {10450823},
	doi = {10.1.1.77.5776},
	abstract = {Accurate recognition and tracking of human activities is an important goal of ubiquitous computing. Recent advances in the development of multi-modal wearable sensors enable us to gather rich datasets of human activities. However, the problem of automatically identifying the most useful features for modeling such activities remains largely unsolved. In this paper we present a hybrid approach to recognizing activities, which combines boosting to discriminatively select useful features and learn an ensemble of static classifiers to recognize different activities, with hidden Markov models (HMMs) to capture the temporal regularities and smoothness of activities. We tested the activity recognition system using over 12 hours of wearable-sensor data collected by volunteers in natural unconstrained environments. The models succeeded in identifying a small set of maximally informative features, and were able identify ten different human activities with an accuracy of 95\%.},
	journal = {IJCAI International Joint Conference on Artificial Intelligence},
	author = {Lester, Jonathan and Choudhury, Tanzeem and Kern, Nicky and Borriello, Gaetano and Hannaford, Blake},
	year = {2005},
	note = {ISBN: 978-963-9799-89-9},
	pages = {766--772},
	file = {Lester et al_2005_A hybrid discriminative-generative approach for modeling human activities.pdf:/Users/orsonxu/Zotero/storage/NJLESDTP/Lester et al_2005_A hybrid discriminative-generative approach for modeling human activities.pdf:application/pdf;Lester et al_2005_A hybrid discriminative-generative approach for modeling human activities.pdf:/Users/orsonxu/Zotero/storage/JVT6NW2F/Lester et al_2005_A hybrid discriminative-generative approach for modeling human activities.pdf:application/pdf},
}

@article{Althoff2017,
	title = {Large-scale physical activity data reveal worldwide activity inequality},
	volume = {547},
	issn = {14764687},
	url = {http://dx.doi.org/10.1038/nature23018},
	doi = {10.1038/nature23018},
	abstract = {A huge smartphone dataset of physical activity yields global insights, revealing that activity inequality predicts obesity better than does volume of activity and that much of the inequality is a result of reduced activity in females.},
	number = {7663},
	journal = {Nature},
	author = {Althoff, Tim and Sosič, Rok and Hicks, Jennifer L. and King, Abby C. and Delp, Scott L. and Leskovec, Jure},
	year = {2017},
	pmid = {28693034},
	note = {Publisher: Nature Publishing Group
ISBN: 1476-4687},
	pages = {336--339},
	file = {Althoff et al_2017_Large-scale physical activity data reveal worldwide activity inequality.pdf:/Users/orsonxu/Zotero/storage/MUIJ7PHL/Althoff et al_2017_Large-scale physical activity data reveal worldwide activity inequality.pdf:application/pdf;Althoff et al_2017_Large-scale physical activity data reveal worldwide activity inequality.pdf:/Users/orsonxu/Zotero/storage/HQZFDIZ7/Althoff et al_2017_Large-scale physical activity data reveal worldwide activity inequality.pdf:application/pdf},
}

@article{Pierson2017,
	title = {Modeling {Individual} {Cyclic} {Variation} in {Human} {Behavior}},
	url = {http://arxiv.org/abs/1712.05748},
	doi = {10.1145/3178876.3186052},
	abstract = {Cycles are fundamental to human health and behavior. However, modeling cycles in time series data is challenging because in most cases the cycles are not labeled or directly observed and need to be inferred from multidimensional measurements taken over time. Here, we present CyHMMs, a cyclic hidden Markov model method for detecting and modeling cycles in a collection of multidimensional heterogeneous time series data. In contrast to previous cycle modeling methods, CyHMMs deal with a number of challenges encountered in modeling real-world cycles: they can model multivariate data with discrete and continuous dimensions; they explicitly model and are robust to missing data; and they can share information across individuals to model variation both within and between individual time series. Experiments on synthetic and real-world health-tracking data demonstrate that CyHMMs infer cycle lengths more accurately than existing methods, with 58\% lower error on simulated data and 63\% lower error on real-world data compared to the best-performing baseline. CyHMMs can also perform functions which baselines cannot: they can model the progression of individual features/symptoms over the course of the cycle, identify the most variable features, and cluster individual time series into groups with distinct characteristics. Applying CyHMMs to two real-world health-tracking datasets -- of menstrual cycle symptoms and physical activity tracking data -- yields important insights including which symptoms to expect at each point during the cycle. We also find that people fall into several groups with distinct cycle patterns, and that these groups differ along dimensions not provided to the model. For example, by modeling missing data in the menstrual cycles dataset, we are able to discover a medically relevant group of birth control users even though information on birth control is not given to the model.},
	journal = {Proceedings of the World Wide Web Conference},
	author = {Pierson, Emma and Althoff, Tim and Leskovec, Jure},
	year = {2017},
	note = {ISBN: 9781450356398},
	file = {Pierson et al_2017_Modeling Individual Cyclic Variation in Human Behavior.pdf:/Users/orsonxu/Zotero/storage/SDARVQ58/Pierson et al_2017_Modeling Individual Cyclic Variation in Human Behavior.pdf:application/pdf;Pierson et al_2017_Modeling Individual Cyclic Variation in Human Behavior.pdf:/Users/orsonxu/Zotero/storage/EXT6XMS8/Pierson et al_2017_Modeling Individual Cyclic Variation in Human Behavior.pdf:application/pdf},
}

@article{Simini2012,
	title = {A universal model for mobility and migration patterns},
	volume = {484},
	issn = {00280836},
	doi = {10.1038/nature10856},
	abstract = {Nature 484, 96 (2012). doi:10.1038/nature10856},
	number = {7392},
	journal = {Nature},
	author = {Simini, Filippo and González, Marta C. and Maritan, Amos and Barabási, Albert László},
	year = {2012},
	pmid = {22367540},
	note = {ISBN: 1476-4687 (Electronic){\textbackslash}r0028-0836 (Linking)},
	pages = {96--100},
	file = {Simini et al_2012_A universal model for mobility and migration patterns.pdf:/Users/orsonxu/Zotero/storage/WSA77WKK/Simini et al_2012_A universal model for mobility and migration patterns.pdf:application/pdf;Simini et al_2012_A universal model for mobility and migration patterns.pdf:/Users/orsonxu/Zotero/storage/8LXUPUUM/Simini et al_2012_A universal model for mobility and migration patterns.pdf:application/pdf},
}

@article{ShanJiangGastonAFioreYingxiangYangJosephFerreiraJrEmilioFrazzoli2014,
	title = {A {Review} of {Urban} {Computing} for {Mobile} {Phone} {Traces} : {Current} {Methods} , {Challenges} and {Opportunities}},
	journal = {Proceedings of the ACM SIGKDD International Workshop on Urban Computing},
	author = {Jiang, Shan and Fiore, Gaston A and Yang, Yingxiang and Jr, Joseph Ferreira and Frazzoli, Emilio and González, Marta C},
	year = {2014},
	note = {ISBN: 9781450323314},
	file = {Jiang et al_2014_A Review of Urban Computing for Mobile Phone Traces.pdf:/Users/orsonxu/Zotero/storage/YUSCL678/Jiang et al_2014_A Review of Urban Computing for Mobile Phone Traces.pdf:application/pdf;Jiang et al_2014_A Review of Urban Computing for Mobile Phone Traces.pdf:/Users/orsonxu/Zotero/storage/SC8FY825/Jiang et al_2014_A Review of Urban Computing for Mobile Phone Traces.pdf:application/pdf},
}

@article{Zhang2017,
	title = {{MoodExplorer}: {Towards} {Compound} {Emotion} {Detection} via {Smartphone} {Sensing}},
	volume = {1},
	issn = {2474-9567},
	url = {https://doi.org/10.1145/3161414},
	doi = {10.1145/3161414},
	abstract = {Social psychology and neuroscience had confirmed that emotion state exerts a significant effect on human communication, perception, social behavior and decision making. With the wide availability of smartphones equipped with microphone, accelerometer, GPS, and other source of sensors, it is worthwhile to explore the possibility of automatic emotion detection via smartphone sensing. Particularly, we focus on a novel research problem that tries to detect the compound emotion (a set of multiple dimensional basic emotions) of smartphone users. We observe that users' self-reported emotional states have high correlation with their smartphone usage patterns and sensing data. Based on the observations, we exploit a feature extraction and selection algorithm to find the most significant features. We further adopt a factor graph model to tackle the correlations between features and emotion labels, and propose a machine learning algorithm for compound emotion detection based on the smartphone sensing data. The proposed mechanism is implemented as an APP called MoodExplorer in Android platform. Extensive experiments conducted on the smartphone data collected from 30 university students show that MoodExplorer can recognize users' compound emotions with 76.0\% exact match on average.},
	number = {176},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Zhang, Xiao and Li, Wenzhong and Chen, Xu and Lu, Sanglu},
	year = {2017},
	keywords = {Compound emotion, Emotion detection, Factor graph, Smartphone sensing},
	file = {Zhang et al_2017_MoodExplorer.pdf:/Users/orsonxu/Zotero/storage/GMRPRXI4/Zhang et al_2017_MoodExplorer.pdf:application/pdf;Zhang et al_2017_MoodExplorer.pdf:/Users/orsonxu/Zotero/storage/DUIRYFRE/Zhang et al_2017_MoodExplorer.pdf:application/pdf},
}

@article{Gonzalez2008,
	title = {Understanding individual human mobility patterns},
	volume = {453},
	issn = {14764687},
	doi = {10.1038/nature06958},
	abstract = {Despite their importance for urban planning, traffic forecasting and the spread of biological and mobile viruses, our understanding of the basic laws governing human motion remains limited owing to the lack of tools to monitor the time-resolved location of individuals. Here we study the trajectory of 100,000 anonymized mobile phone users whose position is tracked for a six-month period. We find that, in contrast with the random trajectories predicted by the prevailing L\{é\}vy flight and random walk models, human trajectories show a high degree of temporal and spatial regularity, each individual being characterized by a time-independent characteristic travel distance and a significant probability to return to a few highly frequented locations. After correcting for differences in travel distances and the inherent anisotropy of each trajectory, the individual travel patterns collapse into a single spatial probability distribution, indicating that, despite the diversity of their travel history, humans follow simple reproducible patterns. This inherent similarity in travel patterns could impact all phenomena driven by human mobility, from epidemic prevention to emergency response, urban planning and agent-based modelling.},
	number = {7196},
	journal = {Nature},
	author = {González, Marta C. and Hidalgo, César A. and Barabási, Albert László},
	year = {2008},
	pmid = {18528393},
	note = {ISBN: 1476-4687 (Electronic){\textbackslash}r0028-0836 (Linking)},
	pages = {779--782},
	file = {González et al_2008_Understanding individual human mobility patterns.pdf:/Users/orsonxu/Zotero/storage/545X336C/González et al_2008_Understanding individual human mobility patterns.pdf:application/pdf;González et al_2008_Understanding individual human mobility patterns.pdf:/Users/orsonxu/Zotero/storage/DG8UMFD9/González et al_2008_Understanding individual human mobility patterns.pdf:application/pdf},
}

@article{Cho2011,
	title = {Friendship and mobility: {User} {Movement} in {Location}-{Based} {Social} {Networks}},
	issn = {9781412946452},
	url = {http://dl.acm.org/citation.cfm?id=2020408.2020579},
	doi = {10.1145/2020408.2020579},
	abstract = {In this paper they create a model to explain location of check-ins in GoWall, BrightKite and Cell phone data. They create a spatial temporal model that uses mixture model to learn the density of the tweets. In the mixture model there are two components, one for work and one for home. The probability of belonging to each of the components is govern by time and then the location is govern by the spatial model learned. To add on top of that, this paper introduces a social explanation for check-ins that are not corralated with the two components. The idea is that if an individual is checking - in not according to the two components then there are social ties that explains that. To show results they compute both log-likelihood and also predictions experiments.},
	journal = {Proceedings of the ACM SIGKDD international conference on Knowledge discovery and data mining},
	author = {Cho, Eunjoon and Myers, Seth A. and Leskovec, Jure},
	year = {2011},
	note = {ISBN: 9781450308137},
	keywords = {human mobility, social networks, communication networks},
	pages = {1082--1090},
	file = {Cho et al_2011_Friendship and mobility.pdf:/Users/orsonxu/Zotero/storage/6SRF8VI7/Cho et al_2011_Friendship and mobility.pdf:application/pdf;Cho et al_2011_Friendship and mobility.pdf:/Users/orsonxu/Zotero/storage/RXUXWRPG/Cho et al_2011_Friendship and mobility.pdf:application/pdf},
}

@article{Eagle2006,
	title = {Reality mining: {Sensing} complex social systems},
	volume = {10},
	issn = {16174909},
	doi = {10.1007/s00779-005-0046-3},
	abstract = {We introduce a system for sensing complex social systems with data collected from 100 mobile phones over the course of 9 months. We demonstrate the ability to use standard Bluetooth-enabled mobile telephones to measure information access and use in different contexts, recognize social patterns in daily user activity, infer relationships, identify socially significant locations, and model organizational rhythms.},
	number = {4},
	journal = {Personal and Ubiquitous Computing},
	author = {Eagle, Nathan and Pentland, Alex},
	year = {2006},
	pmid = {8523550827479701167},
	note = {ISBN: 1617-4909{\textbackslash}r1617-4917},
	keywords = {User modeling, Wearable computing, Bluetooth, Complex social systems, Mobile phones},
	pages = {255--268},
	file = {Eagle_Pentland_2006_Reality mining.pdf:/Users/orsonxu/Zotero/storage/EPJLVQCK/Eagle_Pentland_2006_Reality mining.pdf:application/pdf;Eagle_Pentland_2006_Reality mining.pdf:/Users/orsonxu/Zotero/storage/APYTIST7/Eagle_Pentland_2006_Reality mining.pdf:application/pdf},
}

@article{Pentland1999,
	title = {Modeling and prediction of human behavior},
	volume = {11},
	issn = {0899-7667},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/9950731},
	doi = {10.1162/089976699300016890},
	abstract = {We propose that many human behaviors can be accurately described as a set of dynamic modes (e.g., Kalman filters) sequenced together by a Markov chain. We then use these dynamic Markov models to recognize human behaviors from sensory data and to predict human behaviors over a few seconds time. To test the power of this modeling approach, we report an experiment in which we were able to achieve 95\% accuracy at predicting automobile drivers' subsequent actions from their initial preparatory movements.},
	number = {1},
	journal = {Neural computation},
	author = {Pentland, Alex and Liu, Andrew},
	year = {1999},
	pmid = {9950731},
	note = {ISBN: 0899-7667},
	keywords = {Automobile Driving, Behavior, Behavior: physiology, Computer Simulation, Forecasting, Humans, Markov Chains, Models, Psychological, Statistical},
	pages = {229--42},
	file = {Pentland_Liu_1999_Modeling and prediction of human behavior.pdf:/Users/orsonxu/Zotero/storage/APFRWQ3K/Pentland_Liu_1999_Modeling and prediction of human behavior.pdf:application/pdf;Pentland_Liu_1999_Modeling and prediction of human behavior.pdf:/Users/orsonxu/Zotero/storage/S6U5INAW/Pentland_Liu_1999_Modeling and prediction of human behavior.pdf:application/pdf},
}

@article{Harari2017,
	title = {Patterns of behavior change in students over an academic term: {A} preliminary study of activity and sociability behaviors using smartphone sensing methods},
	volume = {67},
	issn = {07475632},
	url = {http://dx.doi.org/10.1016/j.chb.2016.10.027},
	doi = {10.1016/j.chb.2016.10.027},
	abstract = {The recent arrival of smartphone-sensing methods has made it possible to objectively track consequential everyday health-related behaviors rather than rely on self-reports. To evaluate the viability of using sensing methods to monitor such behaviors in detail, the present research used a smartphone-sensing application to describe the patterns of stability and change that characterize a cohort of students' activity and sociability behaviors over the course of a 10-week academic term. Data were collected from 48 students using a smartphone-sensing application, StudentLife, which was designed to track daily durations of activity (via the accelerometer sensor) and sociability (via the microphone sensor). Results showed stability estimates were moderate to high for activity (rmean= 0.66) and sociability (rmean= 0.72) across the 10 weeks. Students started the term with generally healthy levels of activity (M = 1.87 h) and sociability (M = 4.99 h), which then dropped (activity by 0.42 h, sociability by 0.90 h) over the first half of the term (i.e., before midterm exams). Over the second half of the term, activity levels did not change but sociability increased (by 0.88 h). Students’ ethnicity and academic class predicted variation in the activity and sociability trajectories. Discussion focuses on the implications of our results for designing mHealth interventions to address consequential student outcomes (e.g., mental health, physical health).},
	journal = {Computers in Human Behavior},
	author = {Harari, Gabriella M. and Gosling, Samuel D. and Wang, Rui and Chen, Fanglin and Chen, Zhenyu and Campbell, Andrew T.},
	year = {2017},
	pmid = {18605031},
	note = {Publisher: Elsevier Ltd
ISBN: 0747-5632},
	keywords = {mHealth, Physical activity, Mobile sensing, College students, Smartphone application, Sociability},
	pages = {129--138},
	file = {Harari et al_2017_Patterns of behavior change in students over an academic term.pdf:/Users/orsonxu/Zotero/storage/DPAP258U/Harari et al_2017_Patterns of behavior change in students over an academic term.pdf:application/pdf;Harari et al_2017_Patterns of behavior change in students over an academic term.pdf:/Users/orsonxu/Zotero/storage/3H5AUYB8/Harari et al_2017_Patterns of behavior change in students over an academic term.pdf:application/pdf},
}

@article{Ilse2018,
	title = {Attention-based {Deep} {Multiple} {Instance} {Learning}},
	volume = {5},
	url = {http://arxiv.org/abs/1802.04712},
	abstract = {Multiple instance learning (MIL) is a variation of supervised learning where a single class label is assigned to a bag of instances. In this paper, we state the MIL problem as learning the Bernoulli distribution of the bag label where the bag label probability is fully parameterized by neural networks. Furthermore, we propose a neural network-based permutation-invariant aggregation operator that corresponds to the attention mechanism. Notably, an application of the proposed attention-based operator provides insight into the contribution of each instance to the bag label. We show empirically that our approach achieves comparable performance to the best MIL methods on benchmark MIL datasets and it outperforms other methods on a MNIST-based MIL dataset and two real-life histopathology datasets without sacrificing interpretability.},
	number = {Mil},
	journal = {35th International Conference on Machine Learning, ICML 2018},
	author = {Ilse, Maximilian and Tomczak, Jakub M. and Welling, Max},
	month = feb,
	year = {2018},
	note = {ISBN: 9781510867963},
	pages = {3376--3391},
	file = {Ilse et al_2018_Attention-based Deep Multiple Instance Learning.pdf:/Users/orsonxu/Zotero/storage/ZA8M84C5/Ilse et al_2018_Attention-based Deep Multiple Instance Learning.pdf:application/pdf;Ilse et al_2018_Attention-based Deep Multiple Instance Learning.pdf:/Users/orsonxu/Zotero/storage/QMZA8NFH/Ilse et al_2018_Attention-based Deep Multiple Instance Learning.pdf:application/pdf},
}

@inproceedings{Ebrahimpour2020,
	title = {End-{To}-{End} {Auditory} {Object} {Recognition} {Via} {Inception} {Nucleus}},
	isbn = {978-1-5090-6631-5},
	url = {http://arxiv.org/abs/2005.12195},
	doi = {10.1109/ICASSP40776.2020.9054725},
	abstract = {Machine learning approaches to auditory object recognition are traditionally based on engineered features such as those derived from the spectrum or cepstrum. More recently, end-to-end classification systems in image and auditory recognition systems have been developed to learn features jointly with classification and result in improved classification accuracy. In this paper, we propose a novel end-to-end deep neural network to map the raw waveform inputs to sound class labels. Our network includes an "inception nucleus" that optimizes the size of convolutional filters on the fly that results in reducing engineering efforts dramatically. Classification results compared favorably against current state-of-the-art approaches, besting them by 10.4 percentage points on the Urbansound8k dataset. Analyses of learned representations revealed that filters in the earlier hidden layers learned wavelet-like transforms to extract features that were informative for classification.},
	booktitle = {{ICASSP} 2020 - 2020 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Ebrahimpour, Mohammad and Shea, Timothy and Danielescu, Andreea and Noelle, David and Kello, Chris},
	month = may,
	year = {2020},
	pages = {146--150},
	file = {Ebrahimpour et al_2020_End-To-End Auditory Object Recognition Via Inception Nucleus.pdf:/Users/orsonxu/Zotero/storage/ZTE3TZHY/Ebrahimpour et al_2020_End-To-End Auditory Object Recognition Via Inception Nucleus.pdf:application/pdf;Ebrahimpour et al_2020_End-To-End Auditory Object Recognition Via Inception Nucleus.pdf:/Users/orsonxu/Zotero/storage/YXKDIF94/Ebrahimpour et al_2020_End-To-End Auditory Object Recognition Via Inception Nucleus.pdf:application/pdf},
}

@article{Huang2018,
	title = {{AclNet}: efficient end-to-end audio classification {CNN}},
	url = {http://arxiv.org/abs/1811.06669},
	abstract = {We propose an efficient end-to-end convolutional neural network architecture, AclNet, for audio classification. When trained with our data augmentation and regularization, we achieved state-of-the-art performance on the ESC-50 corpus with 85:65\% accuracy. Our network allows configurations such that memory and compute requirements are drastically reduced, and a tradeoff analysis of accuracy and complexity is presented. The analysis shows high accuracy at significantly reduced computational complexity compared to existing solutions. For example, a configuration with only 155k parameters and 49:3 million multiply-adds per second is 81:75\%, exceeding human accuracy of 81:3\%. This improved efficiency can enable always-on inference in energy-efficient platforms.},
	author = {Huang, Jonathan J and Leanos, Juan Jose Alvarado},
	month = nov,
	year = {2018},
	file = {Huang_Leanos_2018_AclNet.pdf:/Users/orsonxu/Zotero/storage/M63SYHSX/Huang_Leanos_2018_AclNet.pdf:application/pdf;Huang_Leanos_2018_AclNet.pdf:/Users/orsonxu/Zotero/storage/9QC4JU3X/Huang_Leanos_2018_AclNet.pdf:application/pdf},
}

@inproceedings{Larson2012,
	address = {New York, New York, USA},
	title = {{SpiroSmart}: using a microphone to measure lung function on a mobile phone},
	isbn = {978-1-4503-1224-0},
	url = {http://dl.acm.org/citation.cfm?doid=2370216.2370261},
	doi = {10.1145/2370216.2370261},
	booktitle = {Proceedings of the 2012 {ACM} {Conference} on {Ubiquitous} {Computing} - {UbiComp} '12},
	publisher = {ACM Press},
	author = {Larson, Eric C. and Goel, Mayank and Boriello, Gaetano and Heltshe, Sonya and Rosenfeld, Margaret and Patel, Shwetak N.},
	year = {2012},
	pages = {280},
	file = {Larson et al_2012_SpiroSmart.pdf:/Users/orsonxu/Zotero/storage/4JP3DNFP/Larson et al_2012_SpiroSmart.pdf:application/pdf;Larson et al_2012_SpiroSmart.pdf:/Users/orsonxu/Zotero/storage/NIYLW6IR/Larson et al_2012_SpiroSmart.pdf:application/pdf},
}

@inproceedings{Goel2016,
	address = {New York, NY, USA},
	title = {Spirocall: {Measuring} lung function over a phone call},
	isbn = {978-1-4503-3362-7},
	url = {https://dl.acm.org/doi/10.1145/2858036.2858401},
	doi = {10.1145/2858036.2858401},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Goel, Mayank and Saba, Elliot and Stiber, Maia and Whitmire, Eric and Fromm, Josh and Larson, Eric C. and Borriello, Gaetano and Patel, Shwetak N.},
	month = may,
	year = {2016},
	pages = {5675--5685},
	file = {Goel et al_2016_Spirocall.pdf:/Users/orsonxu/Zotero/storage/9KQHVWQ5/Goel et al_2016_Spirocall.pdf:application/pdf;Goel et al_2016_Spirocall.pdf:/Users/orsonxu/Zotero/storage/5F5P5RKT/Goel et al_2016_Spirocall.pdf:application/pdf},
}

@inproceedings{Henpraserttae2011,
	title = {Accurate {Activity} {Recognition} {Using} a {Mobile} {Phone} {Regardless} of {Device} {Orientation} and {Location}},
	isbn = {978-1-4577-0469-7},
	url = {http://ieeexplore.ieee.org/document/5955295/},
	doi = {10.1109/BSN.2011.8},
	abstract = {This paper investigates two major issues in using a triaxial accelerometer-embedded mobile phone for continuous activity monitoring, i.e. the difference in orientations and locations of the device. Two experiments with a total of ten test subjects performed six daily activities were conducted in this study: one with a device fixed on the waist in sixteen different orientations and another with three different device locations (i.e., shirt-pocket, trouser-pocket and waist) in two different device orientations. For handling with varying device orientations, a projection-based method for device coordinate system estimation has been proposed. Based on the dataset with sixteen different device orientations, the experimental results have illustrated that the proposed method is efficient for rectifying the acceleration signals into the same coordinate system, yielding significantly improved activity recognition accuracy. After signal transformation, the recognition results of signals acquired from different device locations are compared. The experimental results show that when the sensor is placed on different rigid body, different models are required for certain activities. © 2011 IEEE.},
	booktitle = {2011 {International} {Conference} on {Body} {Sensor} {Networks}},
	publisher = {IEEE},
	author = {Henpraserttae, Apiwat and Thiemjarus, Surapa and Marukatat, Sanparith},
	month = may,
	year = {2011},
	keywords = {Activity recognition, Accelerometer, Device-location independent, Device-orientation independent, Mobile phone},
	pages = {41--46},
	file = {Henpraserttae et al_2011_Accurate Activity Recognition Using a Mobile Phone Regardless of Device Orientation and Location.pdf:/Users/orsonxu/Zotero/storage/XG8Y8TAW/Henpraserttae et al_2011_Accurate Activity Recognition Using a Mobile Phone Regardless of Device Orientation and Location.pdf:application/pdf;Henpraserttae et al_2011_Accurate Activity Recognition Using a Mobile Phone Regardless of Device Orientation and Location.pdf:/Users/orsonxu/Zotero/storage/ZIE8ZWR5/Henpraserttae et al_2011_Accurate Activity Recognition Using a Mobile Phone Regardless of Device Orientation and Location.pdf:application/pdf},
}

@article{Morales2017,
	title = {Physical activity recognition by smartphones, a survey},
	volume = {37},
	issn = {02085216},
	url = {http://dx.doi.org/10.1016/j.bbe.2017.04.004},
	doi = {10.1016/j.bbe.2017.04.004},
	abstract = {Human activity recognition (HAR) from wearable motion sensor data is a promising research field due to its applications in healthcare, athletics, lifestyle monitoring, and computer–human interaction. Smartphones are an obvious platform for the deployment of HAR algorithms. This paper provides an overview of the state-of-the-art when it comes to the following aspects: relevant signals, data capture and preprocessing, ways to deal with unknown on-body locations and orientations, selecting the right features, activity models and classifiers, metrics for quantifying activity execution, and ways to evaluate usability of a HAR system. The survey covers detection of repetitive activities, postures, falls, and inactivity.},
	number = {3},
	journal = {Biocybernetics and Biomedical Engineering},
	author = {Morales, Jafet and Akopian, David},
	year = {2017},
	note = {Publisher: Nalecz Institute of Biocybernetics and Biomedical Engineering of the Polish Academy of Sciences},
	keywords = {Smartphone, Activity recognition, Accelerometer, Gyroscope},
	pages = {388--400},
	file = {Morales_Akopian_2017_Physical activity recognition by smartphones, a survey.pdf:/Users/orsonxu/Zotero/storage/E44VUR4C/Morales_Akopian_2017_Physical activity recognition by smartphones, a survey.pdf:application/pdf;Morales_Akopian_2017_Physical activity recognition by smartphones, a survey.pdf:/Users/orsonxu/Zotero/storage/7REMEP8P/Morales_Akopian_2017_Physical activity recognition by smartphones, a survey.pdf:application/pdf},
}

@article{he-yueya_assessing_2020,
	title = {Assessing the relationship between routine and schizophrenia symptoms with passively sensed measures of behavioral stability},
	volume = {6},
	issn = {2334-265X},
	url = {http://www.nature.com/articles/s41537-020-00123-2},
	doi = {10.1038/s41537-020-00123-2},
	abstract = {Abstract
            Increased stability in one’s daily routine is associated with well-being in the general population and often a goal of behavioral interventions for people with serious mental illnesses like schizophrenia. Assessing behavioral stability has been limited in clinical research by the use of retrospective scales, which are susceptible to reporting biases and memory inaccuracies. Mobile passive sensors, which are less susceptible to these sources of error, have emerged as tools to assess behavioral patterns in a range of populations. The present study developed and examined a metric of behavioral stability from data generated by a passive sensing system carried by 61 individuals with schizophrenia for one year. This metric—the Stability Index—appeared orthogonal from existing measures drawn from passive sensors and matched the predictive performance of state-of-the-art features. Specifically, greater stability in social activity (e.g., calls and messages) were associated with lower symptoms, and greater stability in physical activity (e.g., being still) appeared associated with elevated symptoms. This study provides additional support for the predictive value of individualized over population-level data in psychiatric populations. The Stability Index offers also a promising tool for generating insights about the impact of behavioral stability in schizophrenia-spectrum disorders.},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {npj Schizophrenia},
	author = {He-Yueya, Joy and Buck, Benjamin and Campbell, Andrew and Choudhury, Tanzeem and Kane, John M. and Ben-Zeev, Dror and Althoff, Tim},
	month = dec,
	year = {2020},
	keywords = {Unread},
	pages = {35},
	file = {He-Yueya et al. - 2020 - Assessing the relationship between routine and sch.pdf:/Users/orsonxu/Zotero/storage/NFVTGTT9/He-Yueya et al. - 2020 - Assessing the relationship between routine and sch.pdf:application/pdf},
}

@article{Mohamed2017,
	title = {{HeartSense}: {Ubiquitous} {Accurate} {Multi}-{Modal} {Fusion}-based {Heart} {Rate} {Estimation} {Using} {Smartphones}},
	volume = {1},
	doi = {10.1145/3132028},
	abstract = {Heart rate is one of the most important vital signals for personal health tracking. A number of smartphone-based heart rate estimation systems have been proposed over the years. However, they either depend on special hardware sensors or suffer from the high noise due to the weakness of the heart signals, affecting their accuracy in many practical scenarios. Inspired by medical studies about the heart motion mechanics, we propose the HeartSense heart rate estimation system. Specifically, we show that the gyroscope sensor is the most sensitive sensor for measuring the heart rate. To further counter noise and handle different practical scenarios, we introduce a novel quality metric that allows us to fuse the different gyroscope axes in a probabilistic framework to achieve a robust and accurate estimate. We have implemented and evaluated our system on different Android phones. Results using 836 experiments on different subjects in practical scenarios with a side-by-side comparison with other systems show that HeartSense can achieve 1.03 bpm median absolute error for heart rate estimation. This is better than the state-of-the-art by more than 147\% in median error, highlighting HeartSense promise as a ubiquitous system for medical and personal well-being applications.},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Mohamed, Reham and Youssef, Moustafa},
	year = {2017},
	keywords = {- Human-centered computing  -{\textgreater} Ubiquitous and mobi},
	pages = {97},
	file = {Mohamed_Youssef_2017_HeartSense.pdf:/Users/orsonxu/Zotero/storage/NJX46FCH/Mohamed_Youssef_2017_HeartSense.pdf:application/pdf;Mohamed_Youssef_2017_HeartSense.pdf:/Users/orsonxu/Zotero/storage/F4F46CE6/Mohamed_Youssef_2017_HeartSense.pdf:application/pdf},
}

@article{Ma2020,
	title = {Practical device-free gesture recognition using {WiFi} signals based on metalearning},
	volume = {16},
	issn = {19410050},
	doi = {10.1109/TII.2019.2909877},
	abstract = {Device-free gesture recognition (DFGR) is a promising sensing technique, which can recognize a gesture by analyzing its influence on surrounding wireless signals. Most of the DFGR systems are designed based on machine learning. However, the recognition performance will drop dramatically when the testing condition is different with the training one. Inspired by the transferrable knowledge learning ability of humans, this paper develops a practical DFGR system based on metalearning to solve the aforementioned problem. Specifically, we design a deep network which could not only learn discriminative deep features, but also learn a transferrable similarity evaluation ability from the training set and apply the learned knowledge to the new testing conditions. Extensive experiments conducted by four users in two scenarios demonstrate that the proposed system could recognize new types of gestures, or gestures performed in new conditions, with an accuracy of more than 90\%, using very few number of new samples.},
	number = {1},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Ma, Xiaorui and Zhao, Yunong and Zhang, Liang and Gao, Qinghua and Pan, Miao and Wang, Jie},
	year = {2020},
	note = {Publisher: IEEE
ISBN: 3132019216},
	keywords = {machine learning, gesture recognition, Deep network, device-free, wireless sensing},
	pages = {228--237},
	file = {Ma et al_2020_Practical device-free gesture recognition using WiFi signals based on metalearning.pdf:/Users/orsonxu/Zotero/storage/BYMJYDME/Ma et al_2020_Practical device-free gesture recognition using WiFi signals based on metalearning.pdf:application/pdf;Ma et al_2020_Practical device-free gesture recognition using WiFi signals based on metalearning.pdf:/Users/orsonxu/Zotero/storage/4SKAQGBF/Ma et al_2020_Practical device-free gesture recognition using WiFi signals based on metalearning.pdf:application/pdf},
}

@article{Laput2019,
	title = {Sensing {Fine}-{Grained} {Hand} {Activity} with {Smartwatches}},
	url = {http://dl.acm.org/citation.cfm?doid=3290605.3300568},
	doi = {10.1145/3290605.3300568},
	abstract = {Capturing fine-grained hand activity could make computa- tional experiences more powerful and contextually aware. Indeed, philosopher Immanuel Kant argued, "the hand is the visible part of the brain." However, most prior work has fo- cused on detecting whole-body activities, such as walking, running and bicycling. In this work, we explore the feasi- bility of sensing hand activities from commodity smart- watches, which are the most practical vehicle for achieving this vision. Our investigations started with a 50 participant, in-the-wild study, which captured hand activity labels over nearly 1000 worn hours. We then studied this data to scope our research goals and inform our technical approach. We conclude with a second, in-lab study that evaluates our clas- sification stack, demonstrating 95.2\% accuracy across 25 hand activities. Our work highlights an underutilized, yet highly complementary contextual channel that could un- lock a wide range of promising applications.},
	journal = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems  - CHI '19},
	author = {Laput, Gierad and Harrison, Chris},
	year = {2019},
	note = {ISBN: 9781450359702},
	pages = {1--13},
	file = {Laput_Harrison_2019_Sensing Fine-Grained Hand Activity with Smartwatches.pdf:/Users/orsonxu/Zotero/storage/YPRVPHDT/Laput_Harrison_2019_Sensing Fine-Grained Hand Activity with Smartwatches.pdf:application/pdf;Laput_Harrison_2019_Sensing Fine-Grained Hand Activity with Smartwatches.pdf:/Users/orsonxu/Zotero/storage/U7FQA7EJ/Laput_Harrison_2019_Sensing Fine-Grained Hand Activity with Smartwatches.pdf:application/pdf},
}

@article{Jacobson2020,
	title = {Passive {Sensing} of {Prediction} of {Moment}-{To}-{Moment} {Depressed} {Mood} among {Undergraduates} with {Clinical} {Levels} of {Depression} {Sample} {Using} {Smartphones}},
	volume = {20},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/12/3572},
	doi = {10.3390/s20123572},
	abstract = {Prior research has recently shown that passively collected sensor data collected within the contexts of persons daily lives via smartphones and wearable sensors can distinguish those with major depressive disorder (MDD) from controls, predict MDD severity, and predict changes in MDD severity across days and weeks. Nevertheless, very little research has examined predicting depressed mood within a day, which is essential given the large amount of variation occurring within days. The current study utilized passively collected sensor data collected from a smartphone application to future depressed mood from hour-to-hour in an ecological momentary assessment study in a sample reporting clinical levels of depression (N = 31). Using a combination of nomothetic and idiographically-weighted machine learning models, the results suggest that depressed mood can be accurately predicted from hour to hour with an average correlation between out of sample predicted depressed mood levels and observed depressed mood of 0.587, CI [0.552, 0.621]. This suggests that passively collected smartphone data can accurately predict future depressed mood among a sample reporting clinical levels of depression. If replicated in other samples, this modeling framework may allow just-in-time adaptive interventions to treat depression as it changes in the context of daily life.},
	number = {12},
	journal = {Sensors},
	author = {Jacobson, Nicholas C. and Chung, Yeon Joo},
	month = jun,
	year = {2020},
	pmid = {32599801},
	keywords = {Machine learning, Digital phenotyping, Digital biomarkers, Ecological momentary assessment, Major depressive disorder},
	pages = {3572},
	file = {Jacobson_Chung_2020_Passive Sensing of Prediction of Moment-To-Moment Depressed Mood among Undergraduates with Clinical Levels of Depression Sample Using Smartphones.pdf:/Users/orsonxu/Zotero/storage/7ZVSDEFJ/Jacobson_Chung_2020_Passive Sensing of Prediction of Moment-To-Moment Depressed Mood among Undergraduates with Clinical Levels of Depression Sample Using Smartphones2.pdf:application/pdf;Jacobson_Chung_2020_Passive Sensing of Prediction of Moment-To-Moment Depressed Mood among Undergraduates with Clinical Levels of Depression Sample Using Smartphones.pdf:/Users/orsonxu/Zotero/storage/6TA5R2VE/Jacobson_Chung_2020_Passive Sensing of Prediction of Moment-To-Moment Depressed Mood among Undergraduates with Clinical Levels of Depression Sample Using Smartphones2.pdf:application/pdf;Jacobson_Chung_2020_Passive Sensing of Prediction of Moment-To-Moment Depressed Mood among Undergraduates with Clinical Levels of Depression Sample Using Smartphones.pdf:/Users/orsonxu/Zotero/storage/CGSG2NN7/Jacobson_Chung_2020_Passive Sensing of Prediction of Moment-To-Moment Depressed Mood among Undergraduates with Clinical Levels of Depression Sample Using Smartphones.pdf:application/pdf;Jacobson_Chung_2020_Passive Sensing of Prediction of Moment-To-Moment Depressed Mood among Undergraduates with Clinical Levels of Depression Sample Using Smartphones.pdf:/Users/orsonxu/Zotero/storage/4MNEPX7P/Jacobson_Chung_2020_Passive Sensing of Prediction of Moment-To-Moment Depressed Mood among Undergraduates with Clinical Levels of Depression Sample Using Smartphones.pdf:application/pdf},
}

@article{Doryab2014,
	title = {Detection of behavior change in people with depression},
	volume = {WS-14-08},
	abstract = {Major Depressive Disorder (MDD) is the most common mental health disorder and remains a leading cause of disability and lost productivity with huge costs for society. MDD has high rates of relapse and recurrence, and it has strong correlations with feelings of low social support and disrupted sleep. However, MDD is also commonly misdiagnosed by primary care providers, which leads to delayed treatment and unnecessary suffering. Changes in technology now make it possible to cheaply and effectively monitor social and sleep behaviors, offering the potential of early detection of the onset of MDD. We report on the design of Big Black Dog, a smartphone-based system for gathering data about social and sleep behaviors. We also report on the results of a pilot evaluation to understand the feasibility of gathering and using data from smartphones for inferring the onset of depression.},
	journal = {AAAI Workshop - Technical Report},
	author = {Doryab, Afsaneh and Min, Jun Ki and Wiese, Jason and Zimmerman, John and Hong, Jason},
	year = {2014},
	note = {ISBN: 9781577356691},
	pages = {12--16},
	file = {Doryab et al_2014_Detection of behavior change in people with depression.pdf:/Users/orsonxu/Zotero/storage/MMZ2DHG9/Doryab et al_2014_Detection of behavior change in people with depression.pdf:application/pdf;Doryab et al_2014_Detection of behavior change in people with depression.pdf:/Users/orsonxu/Zotero/storage/E9LTDC38/Doryab et al_2014_Detection of behavior change in people with depression.pdf:application/pdf},
}

@article{Montgomery2012,
	title = {Associating {Internet} {Usage} with {Depressive} {Behavior} {Among} {College} {Students}},
	volume = {31},
	issn = {0278-0097},
	url = {https://ieeexplore.ieee.org/document/6387969/},
	doi = {10.1109/MTS.2012.2225462},
	number = {4},
	journal = {IEEE Technology and Society Magazine},
	author = {Katikalapudi, Raghavendra and Chellappan, Sriram and Montgomery, Frances and Wunsch, Donald and Lutzen, Karl},
	year = {2012},
	pages = {73--80},
	file = {Katikalapudi et al_2012_Associating Internet Usage with Depressive Behavior Among College Students.pdf:/Users/orsonxu/Zotero/storage/FUI6WT87/Katikalapudi et al_2012_Associating Internet Usage with Depressive Behavior Among College Students.pdf:application/pdf;Katikalapudi et al_2012_Associating Internet Usage with Depressive Behavior Among College Students.pdf:/Users/orsonxu/Zotero/storage/U7H3BMM2/Katikalapudi et al_2012_Associating Internet Usage with Depressive Behavior Among College Students.pdf:application/pdf},
}

@article{huckins_causal_2020,
	title = {Causal {Factors} of {Anxiety} and {Depression} in {College} {Students}: {Longitudinal} {Ecological} {Momentary} {Assessment} and {Causal} {Analysis} {Using} {Peter} and {Clark} {Momentary} {Conditional} {Independence}},
	volume = {7},
	issn = {2368-7959},
	shorttitle = {Causal {Factors} of {Anxiety} and {Depression} in {College} {Students}},
	url = {https://mental.jmir.org/2020/6/e16684},
	doi = {10.2196/16684},
	abstract = {Background: Across college campuses, the prevalence of clinically relevant depression or anxiety is affecting more than 27\% of the college population at some point between entry to college and graduation. Stress and self-esteem have both been hypothesized to contribute to depression and anxiety levels. Although contemporaneous relationships between these variables have been well-defined, the causal relationship between these mental health factors is not well understood, as frequent sampling can be invasive, and many of the current causal techniques are not well suited to investigate correlated variables.},
	language = {en},
	number = {6},
	urldate = {2022-05-14},
	journal = {JMIR Mental Health},
	author = {Huckins, Jeremy F and DaSilva, Alex W and Hedlund, Elin L and Murphy, Eilis I and Rogers, Courtney and Wang, Weichen and Obuchi, Mikio and Holtzheimer, Paul E and Wagner, Dylan D and Campbell, Andrew T},
	month = jun,
	year = {2020},
	pages = {e16684},
	file = {Huckins et al. - 2020 - Causal Factors of Anxiety and Depression in Colleg.pdf:/Users/orsonxu/Zotero/storage/MCSTQ8SV/Huckins et al. - 2020 - Causal Factors of Anxiety and Depression in Colleg.pdf:application/pdf},
}

@article{huckins_mental_2020,
	title = {Mental {Health} and {Behavior} of {College} {Students} {During} the {Early} {Phases} of the {COVID}-19 {Pandemic}: {Longitudinal} {Smartphone} and {Ecological} {Momentary} {Assessment} {Study}},
	volume = {22},
	issn = {1438-8871},
	shorttitle = {Mental {Health} and {Behavior} of {College} {Students} {During} the {Early} {Phases} of the {COVID}-19 {Pandemic}},
	url = {http://www.jmir.org/2020/6/e20185/},
	doi = {10.2196/20185},
	abstract = {Background: The vast majority of people worldwide have been impacted by coronavirus disease (COVID-19). In addition to the millions of individuals who have been infected with the disease, billions of individuals have been asked or required by local and national governments to change their behavioral patterns. Previous research on epidemics or traumatic events suggests that this can lead to profound behavioral and mental health changes; however, researchers are rarely able to track these changes with frequent, near-real-time sampling or compare their findings to previous years of data for the same individuals.},
	language = {en},
	number = {6},
	urldate = {2022-05-14},
	journal = {Journal of Medical Internet Research},
	author = {Huckins, Jeremy F and daSilva, Alex W and Wang, Weichen and Hedlund, Elin and Rogers, Courtney and Nepal, Subigya K and Wu, Jialing and Obuchi, Mikio and Murphy, Eilis I and Meyer, Meghan L and Wagner, Dylan D and Holtzheimer, Paul E and Campbell, Andrew T},
	month = jun,
	year = {2020},
	pages = {e20185},
	file = {Huckins et al. - 2020 - Mental Health and Behavior of College Students Dur.pdf:/Users/orsonxu/Zotero/storage/Z47LUZ88/Huckins et al. - 2020 - Mental Health and Behavior of College Students Dur.pdf:application/pdf},
}

@inproceedings{nepal_covid_2022,
	address = {New Orleans LA USA},
	title = {{COVID} {Student} {Study}: {A} {Year} in the {Life} of {College} {Students} during the {COVID}-19 {Pandemic} {Through} the {Lens} of {Mobile} {Phone} {Sensing}},
	isbn = {978-1-4503-9157-3},
	shorttitle = {{COVID} {Student} {Study}},
	url = {https://dl.acm.org/doi/10.1145/3491102.3502043},
	doi = {10.1145/3491102.3502043},
	abstract = {The COVID-19 pandemic continues to afect the daily life of college students, impacting their social life, education, stress levels and overall mental well-being. We study and assess behavioral changes of N=180 undergraduate college students one year prior to the pandemic as a baseline and then during the frst year of the pandemic using mobile phone sensing and behavioral inference. We observe that certain groups of students experience the pandemic very differently. Furthermore, we explore the association of self-reported COVID-19 concern with students’ behavior and mental health. We fnd that heightened COVID-19 concern is correlated with increased depression, anxiety and stress. We evaluate the performance of different deep learning models to classify student COVID-19 concerns with an AUROC and F1 score of 0.70 and 0.71, respectively. Our study spans a two-year period and provides a number of important insights into the life of college students during this period.},
	language = {en},
	urldate = {2022-05-14},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Nepal, Subigya and Wang, Weichen and Vojdanovski, Vlado and Huckins, Jeremy F and daSilva, Alex and Meyer, Meghan and Campbell, Andrew},
	month = apr,
	year = {2022},
	pages = {1--19},
	file = {Nepal et al. - 2022 - COVID Student Study A Year in the Life of College.pdf:/Users/orsonxu/Zotero/storage/D7QRHWHR/Nepal et al. - 2022 - COVID Student Study A Year in the Life of College.pdf:application/pdf},
}

@article{chikersal_detecting_2021,
	title = {Detecting {Depression} and {Predicting} its {Onset} {Using} {Longitudinal} {Symptoms} {Captured} by {Passive} {Sensing}},
	volume = {28},
	issn = {1073-0516},
	url = {https://dl.acm.org/doi/10.1145/3422821},
	doi = {10.1145/3422821},
	abstract = {We present a machine learning approach that uses data from smartphones and fitness trackers of 138 college students to identify students that experienced depressive symptoms at the end of the semester and students whose depressive symptoms worsened over the semester. Our novel approach is a feature extraction technique that allows us to select meaningful features indicative of depressive symptoms from longitudinal data. It allows us to detect the presence of post-semester depressive symptoms with an accuracy of 85.7\% and change in symptom severity with an accuracy of 85.4\%. It also predicts these outcomes with an accuracy of {\textgreater}80\%, 11–15 weeks before the end of the semester, allowing ample time for pre-emptive interventions. Our work has significant implications for the detection of health outcomes using longitudinal behavioral data and limited ground truth. By detecting change and predicting symptoms several weeks before their onset, our work also has implications for preventing depression.},
	number = {1},
	journal = {ACM Transactions on Computer-Human Interaction},
	author = {Chikersal, Prerna and Doryab, Afsaneh and Tumminia, Michael and Villalba, Daniella K and Dutcher, Janine M and Liu, Xinwen and Cohen, Sheldon and Creswell, Kasey G. and Mankoff, Jennifer and Creswell, J. David and Goel, Mayank and Dey, Anind K.},
	month = jan,
	year = {2021},
	pages = {1--41},
	file = {Chikersal et al_2021_Detecting Depression and Predicting its Onset Using Longitudinal Symptoms Captured by Passive Sensing.pdf:/Users/orsonxu/Zotero/storage/XP938L7F/Chikersal et al_2021_Detecting Depression and Predicting its Onset Using Longitudinal Symptoms Captured by Passive Sensing.pdf:application/pdf;Chikersal et al_2021_Detecting Depression and Predicting its Onset Using Longitudinal Symptoms Captured by Passive Sensing.pdf:/Users/orsonxu/Zotero/storage/STQSP56B/Chikersal et al_2021_Detecting Depression and Predicting its Onset Using Longitudinal Symptoms Captured by Passive Sensing.pdf:application/pdf},
}

@article{zakaria_stressmon_2019,
	title = {Stressmon: {Scalable} detection of perceived stress and depression using passive sensing of changes in work routines and group interactions},
	volume = {3},
	issn = {25730142},
	doi = {10.1145/3359139},
	abstract = {Stress and depression are a common affliction in all walks of life. When left unmanaged, stress can inhibit productivity or cause depression. Depression can occur independently of stress. There has been a sharp rise in mobile health initiatives to monitor stress and depression. However, these initiatives usually require users to install dedicated apps or multiple sensors, making such solutions hard to scale. Moreover, they emphasise sensing individual factors and overlook social interactions, which plays a significant role in influencing stress and depression while being a part of a social system. We present StressMon, a stress and depression detection system that leverages single-attribute location data, passively sensed from the WiFi infrastructure. Using the location data, it extracts a detailed set of movement, and physical group interaction pattern features without requiring explicit user actions or software installation on client devices. These features are used in two different machine learning models to detect stress and depression. To validate StressMon, we conducted three different longitudinal studies at a university with different groups of students, totalling up to 108 participants. Our evaluation demonstrated StressMon detecting severely stressed students with a 96.01\% True Positive Rate (TPR), an 80.76\% True Negative Rate (TNR), and a 0.97 area under the ROC curve (AUC) score (a score of 1 indicates a perfect binary classifier) using a 6-day prediction window. In addition, StressMon was able to detect depression at 91.21\% TPR, 66.71\% TNR, and 0.88 AUC using a 15-day window. We end by discussing how StressMon can expand CSCW research, especially in areas involving collaborative practices for mental health management.},
	number = {CSCW},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Zakaria, Camellia and Balan, Rajesh and Lee, Youngki},
	year = {2019},
	keywords = {Stress, Depression, Mobility patterns, Small-group, Wi-Fi indoor localisation},
	file = {Zakaria et al_2019_Stressmon.pdf:/Users/orsonxu/Zotero/storage/VYW2LPPC/Zakaria et al_2019_Stressmon.pdf:application/pdf;Zakaria et al_2019_Stressmon.pdf:/Users/orsonxu/Zotero/storage/7S9NG7RB/Zakaria et al_2019_Stressmon.pdf:application/pdf},
}

@article{wang_tracking_2018,
	title = {Tracking {Depression} {Dynamics} in {College} {Students} {Using} {Mobile} {Phone} and {Wearable} {Sensing}},
	volume = {2},
	issn = {24749567},
	url = {http://dl.acm.org/citation.cfm?doid=3200905.3191775},
	doi = {10.1145/3191775},
	abstract = {The social phenomenon of familiar strangers was identified by Stanley Milgram in 1972 with a small-scale experiment. However, there has been limited research focusing on uncovering the phenomenon at a societal scale and simultaneously investigating the social relationships between familiar strangers. With the help of the large-scale mobile phone records, we empirically show the existence of the relationship in the country of Andorra. Built upon the temporal and spatial distributions, we investigate the mechanisms, especially collective temporal regularity and spatial structure that trigger this phenomenon. Moreover, we explore the relationship between social distances on the communication network and the number of encounters and show that larger number of encounters indicates shorter social distances in a social network. The understanding of the physical encounter network could have important implications to understand the phenomena such as epidemics spreading and information diffusion.},
	number = {1},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Wang, Rui and Wang, Weichen and daSilva, Alex and Huckins, Jeremy F. and Kelley, William M. and Heatherton, Todd F. and Campbell, Andrew T.},
	year = {2018},
	note = {ISBN: 2474-9567},
	keywords = {Mobile Sensing, Mental Health, Depression},
	pages = {1--26},
	file = {Wang et al_2018_Tracking Depression Dynamics in College Students Using Mobile Phone and Wearable Sensing.pdf:/Users/orsonxu/Zotero/storage/TE5LCHUF/Wang et al_2018_Tracking Depression Dynamics in College Students Using Mobile Phone and Wearable Sensing.pdf:application/pdf;Wang et al_2018_Tracking Depression Dynamics in College Students Using Mobile Phone and Wearable Sensing.pdf:/Users/orsonxu/Zotero/storage/I9XJ7HSP/Wang et al_2018_Tracking Depression Dynamics in College Students Using Mobile Phone and Wearable Sensing.pdf:application/pdf},
}

@article{mehrotra_using_2018,
	title = {Using {Autoencoders} to {Automatically} {Extract} {Mobility} {Features} for {Predicting} {Depressive} {States}},
	volume = {2},
	issn = {2474-9567},
	doi = {10.1145/3264937},
	abstract = {Recent studies have shown the potential of exploiting GPS data for passively inferring people's mental health conditions. However, feature extraction for characterizing human mobility remains a heuristic process that relies on the domain knowledge of the condition under consideration. Moreover, we do not have guarantees that these "hand-crafted" metrics are able to eï¿¿ectively capture mobility behavior of users. Indeed, informative emerging patterns in the data might not be characterized by them. This is also a complex and often time-consuming task, since it usually consists of a lengthy trial-and-error process. In this paper, we investigate the potential of using autoencoders for automatically extracting features from the raw input data. Through a series of experiments we show the eï¿¿ectiveness of autoencoder-based features for predicting depressive states of individuals compared to "hand-crafted" ones. Our results show that automatically extracted features lead to an improvement of the performance of the prediction models, while, at the same time, reducing the complexity of the feature design task. Moreover, through an extensive experimental performance analysis, we demonstrate the optimal conï¿¿guration of the key parameters at the basis of the proposed approach.},
	number = {3},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Mehrotra, Abhinav and Musolesi, Mirco},
	year = {2018},
	pages = {1--20},
	file = {Mehrotra_Musolesi_2018_Using Autoencoders to Automatically Extract Mobility Features for Predicting Depressive States.pdf:/Users/orsonxu/Zotero/storage/IC5B6C49/Mehrotra_Musolesi_2018_Using Autoencoders to Automatically Extract Mobility Features for Predicting Depressive States.pdf:application/pdf;Mehrotra_Musolesi_2018_Using Autoencoders to Automatically Extract Mobility Features for Predicting Depressive States.pdf:/Users/orsonxu/Zotero/storage/B3KTBMVV/Mehrotra_Musolesi_2018_Using Autoencoders to Automatically Extract Mobility Features for Predicting Depressive States.pdf:application/pdf},
}

@article{lu_joint_2018,
	title = {Joint {Modeling} of {Heterogeneous} {Sensing} {Data} for {Depression} {Assessment} via {Multi}-task {Learning}},
	volume = {2},
	issn = {24749567},
	url = {http://dl.acm.org/citation.cfm?doid=3200905.3191753},
	doi = {10.1145/3191753},
	abstract = {Depression is a common mood disorder that causes severe medical problems and interferes negatively with daily life. Identifying human behavior patterns that are predictive or indicative of depressive disorder is important. Clinical diagnosis of depression relies on costly clinician assessment using survey instruments which may not objectively reflect the fluctuation of daily behavior. Self-administered surveys, such as the Quick Inventory of Depressive Symptomatology (QIDS) commonly used to monitor depression, may show disparities from clinical decision. Smartphones provide easy access to many behavioral parameters, and Fitbit wrist bands are becoming another important tool to assess variables such as heart rates and sleep efficiency that are complementary to smartphone sensors. However, data used to identify depression indicators have been limited to a single platform either iPhone, or Android, or Fitbit alone due to the variation in their methods of data collection. The present work represents a large-scale effort to collect and integrate data from mobile phones, wearable devices, and self reports in depression analysis by designing a new machine learning approach. This approach constructs sparse mappings from sensing variables collected by various tools to two separate targets: self-reported QIDS scores and clinical assessment of depression severity. We propose a so-called heterogeneous multi-task feature learning method that jointly builds inference models for related tasks but of different types including classification and regression tasks. The proposed method was evaluated using data collected from 103 college students and could predict the QIDS score with an R2 reaching 0.44 and depression severity with an F1-score as high as 0.77. By imposing appropriate regularizers, our approach identified strong depression indicators such as time staying at home and total time asleep.},
	number = {1},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Lu, Jin and Bi, Jinbo and Shang, Chao and Yue, Chaoqun and Morillo, Reynaldo and Ware, Shweta and Kamath, Jayesh and Bamis, Athanasios and Russell, Alexander and Wang, Bing},
	year = {2018},
	pmid = {27438475},
	note = {ISBN: 9781450351980},
	keywords = {Depression assessment, Multi-task learning, Predic},
	pages = {1--21},
	file = {Lu et al_2018_Joint Modeling of Heterogeneous Sensing Data for Depression Assessment via Multi-task Learning.pdf:/Users/orsonxu/Zotero/storage/YGYHP2LD/Lu et al_2018_Joint Modeling of Heterogeneous Sensing Data for Depression Assessment via Multi-task Learning.pdf:application/pdf;Lu et al_2018_Joint Modeling of Heterogeneous Sensing Data for Depression Assessment via Multi-task Learning.pdf:/Users/orsonxu/Zotero/storage/G9SG5J7X/Lu et al_2018_Joint Modeling of Heterogeneous Sensing Data for Depression Assessment via Multi-task Learning.pdf:application/pdf},
}

@article{wahle_mobile_2016,
	title = {Mobile {Sensing} and {Support} for {People} {With} {Depression}: {A} {Pilot} {Trial} in the {Wild}},
	volume = {4},
	issn = {2291-5222},
	url = {http://mhealth.jmir.org/2016/3/e111/},
	doi = {10.2196/mhealth.5960},
	abstract = {Background: Depression is a burdensome, recurring mental health disorder with high prevalence. Even in developed countries, patients have to wait for several months to receive treatment. In many parts of the world there is only one mental health professional for over 200 people. Smartphones are ubiquitous and have a large complement of sensors that can potentially be useful in monitoring behavioral patterns that might be indicative of depressive symptoms and providing context-sensitive intervention support. Objective: The objective of this study is 2-fold, first to explore the detection of daily-life behavior based on sensor information to identify subjects with a clinically meaningful depression level, second to explore the potential of context sensitive intervention delivery to provide in-situ support for people with depressive symptoms. Methods: A total of 126 adults (age 20-57) were recruited to use the smartphone app Mobile Sensing and Support (MOSS), collecting context-sensitive sensor information and providing just-in-time interventions derived from cognitive behavior therapy. Real-time learning-systems were deployed to adapt to each subject's preferences to optimize recommendations with respect to time, location, and personal preference. Biweekly, participants were asked to complete a self-reported depression survey (PHQ-9) to track symptom progression. Wilcoxon tests were conducted to compare scores before and after intervention. Correlation analysis was used to test the relationship between adherence and change in PHQ-9. One hundred twenty features were constructed based on smartphone usage and sensors including accelerometer, Wifi, and global positioning systems (GPS). Machine-learning models used these features to infer behavior and context for PHQ-9 level prediction and tailored intervention delivery. Results: A total of 36 subjects used MOSS for ≥2 weeks. For subjects with clinical depression (PHQ-9≥11) at baseline and adherence ≥8 weeks (n=12), a significant drop in PHQ-9 was observed (P=.01). This group showed a negative trend between adherence and change in PHQ-9 scores (rho=−.498, P=.099). Binary classification performance for biweekly PHQ-9 samples (n=143), with a cutoff of PHQ-9≥11, based on Random Forest and Support Vector Machine leave-one-out cross validation resulted in 60.1\% and 59.1\% accuracy, respectively. Conclusions: Proxies for social and physical behavior derived from smartphone sensor data was successfully deployed to deliver context-sensitive and personalized interventions to people with depressive symptoms. Subjects who used the app for an extended period of time showed significant reduction in self-reported symptom severity. Nonlinear classification models trained on features extracted from smartphone sensor data including Wifi, accelerometer, GPS, and phone use, demonstrated a proof of concept for the detection of depression superior to random classification. While findings of effectiveness must be reproduced in a RCT to proof causation, they pave the way for a new generation of digital health interventions leveraging smartphone sensors to provide context sensitive information for in-situ support and unobtrusive monitoring of critical mental health states.},
	number = {3},
	journal = {JMIR mHealth and uHealth},
	author = {Wahle, Fabian and Kowatsch, Tobias and Fleisch, Elgar and Rufer, Michael and Weidt, Steffi},
	year = {2016},
	pmid = {27655245},
	note = {ISBN: doi:10.2196/mhealth.5960},
	pages = {e111},
	file = {Wahle et al_2016_Mobile Sensing and Support for People With Depression.pdf:/Users/orsonxu/Zotero/storage/ZXQUUMEB/Wahle et al_2016_Mobile Sensing and Support for People With Depression.pdf:application/pdf;Wahle et al_2016_Mobile Sensing and Support for People With Depression.pdf:/Users/orsonxu/Zotero/storage/JEIZ2QYS/Wahle et al_2016_Mobile Sensing and Support for People With Depression.pdf:application/pdf},
}

@inproceedings{farhan_behavior_2016,
	title = {Behavior vs. introspection: refining prediction of clinical depression via smartphone sensing data},
	isbn = {978-1-5090-3090-3},
	url = {https://ieeexplore.ieee.org/document/7764553/},
	doi = {10.1109/WH.2016.7764553},
	abstract = {Depression is a serious health disorder. In this study, we investigate the feasibility of depression screening using sensor data collected from smartphones. We extract various behavioral features from smartphone sensing data and investigate the efficacy of various machine learning tools to predict clinical diagnoses and PHQ-9 scores (a quantitative tool for aiding depression screening in practice). A notable feature of our study is that we leverage a dataset that includes clinical ground truth. We find that behavioral data from smartphones can predict clinical depression with good accuracy. In addition, combining behavioral data and PHQ-9 scores can provide prediction accuracy significantly exceeding each in isolation, indicating that behavioral data captures relevant features that are not reflected by PHQ-9 scores. Finally, we develop multi-feature regression models for PHQ-9 scores that achieve significantly improved accuracy compared to direct regression models based on single features.},
	booktitle = {2016 {IEEE} {Wireless} {Health} ({WH})},
	publisher = {IEEE},
	author = {Farhan, Asma Ahmad and Yue, Chaoqun and Morillo, Reynaldo and Ware, Shweta and Lu, Jin and Bi, Jinbo and Kamath, Jayesh and Russell, Alexander and Bamis, Athanasios and Wang, Bing},
	month = oct,
	year = {2016},
	pages = {1--8},
	file = {Farhan et al_2016_Behavior vs.pdf:/Users/orsonxu/Zotero/storage/RHW7TLSU/Farhan et al_2016_Behavior vs.pdf:application/pdf;Farhan et al_2016_Behavior vs.pdf:/Users/orsonxu/Zotero/storage/2Z6YMBPL/Farhan et al_2016_Behavior vs.pdf:application/pdf},
}

@article{canzian_trajectories_2015,
	title = {Trajectories of depression: {Unobtrusive} monitoring of depressive states by means of smartphone mobility traces analysis},
	doi = {10.1145/2750858.2805845},
	abstract = {One of the most interesting applications of mobile sensing is monitoring of individual behavior, especially in the area of mental health care. Most existing systems require an interaction with the device, for example they may require the user to input his/her mood state at regular intervals. In this paper we seek to answer whether mobile phones can be used to unobtrusively monitor individuals affected by depressive mood disorders by analyzing only their mobility patterns from GPS traces. In order to get ground-Truth measurements, we have developed a smartphone application that periodically collects the locations of the users and the answers to daily questionnaires that quantify their depressive mood. We demonstrate that there exists a significant correlation between mobility trace characteristics and the depressive moods. Finally, we present the design of models that are able to successfully predict changes in the depressive mood of individuals by analyzing their movements.},
	journal = {Proceedings of the ACM International Joint Conference on Pervasive and Ubiquitous Computing},
	author = {Canzian, Luca and Musolesi, Mirco},
	year = {2015},
	keywords = {Depression, Mobile Sensing, GPS Traces, Spatial Statistics},
	pages = {1293--1304},
	file = {Canzian_Musolesi_2015_Trajectories of depression.pdf:/Users/orsonxu/Zotero/storage/APBTJYSI/Canzian_Musolesi_2015_Trajectories of depression.pdf:application/pdf;Canzian_Musolesi_2015_Trajectories of depression.pdf:/Users/orsonxu/Zotero/storage/2SAA3AX5/Canzian_Musolesi_2015_Trajectories of depression.pdf:application/pdf},
}

@article{saeb_mobile_2015,
	title = {Mobile phone sensor correlates of depressive symptom severity in daily-life behavior: {An} exploratory study},
	volume = {17},
	issn = {14388871},
	doi = {10.2196/jmir.4273},
	abstract = {BACKGROUND: Depression is a common, burdensome, often recurring mental health disorder that frequently goes undetected and untreated. Mobile phones are ubiquitous and have an increasingly large complement of sensors that can potentially be useful in monitoring behavioral patterns that might be indicative of depressive symptoms. OBJECTIVE: The objective of this study was to explore the detection of daily-life behavioral markers using mobile phone global positioning systems (GPS) and usage sensors, and their use in identifying depressive symptom severity. METHODS: A total of 40 adult participants were recruited from the general community to carry a mobile phone with a sensor data acquisition app (Purple Robot) for 2 weeks. Of these participants, 28 had sufficient sensor data received to conduct analysis. At the beginning of the 2-week period, participants completed a self-reported depression survey (PHQ-9). Behavioral features were developed and extracted from GPS location and phone usage data. RESULTS: A number of features from GPS data were related to depressive symptom severity, including circadian movement (regularity in 24-hour rhythm; r=-.63, P=.005), normalized entropy (mobility between favorite locations; r=-.58, P=.012), and location variance (GPS mobility independent of location; r=-.58, P=.012). Phone usage features, usage duration, and usage frequency were also correlated (r=.54, P=.011, and r=.52, P=.015, respectively). Using the normalized entropy feature and a classifier that distinguished participants with depressive symptoms (PHQ-9 score ≥5) from those without (PHQ-9 score {\textless}5), we achieved an accuracy of 86.5\%. Furthermore, a regression model that used the same feature to estimate the participants’ PHQ-9 scores obtained an average error of 23.5\%. CONCLUSIONS: Features extracted from mobile phone sensor data, including GPS and phone usage, provided behavioral markers that were strongly related to depressive symptom severity. While these findings must be replicated in a larger study among participants with confirmed clinical symptoms, they suggest that phone sensors offer numerous clinical opportunities, including continuous monitoring of at-risk populations with little patient burden and interventions that can provide just-in-time outreach.},
	number = {7},
	journal = {Journal of Medical Internet Research},
	author = {Saeb, Sohrab and Zhang, Mi and Karr, Christopher J. and Schueller, Stephen M. and Corden, Marya E. and Kording, Konrad P. and Mohr, David C.},
	year = {2015},
	keywords = {Depression, Classification, Mobile health (mHealth), Activities of daily living, Cluster analysis},
	pages = {1--11},
	file = {Saeb et al_2015_Mobile phone sensor correlates of depressive symptom severity in daily-life behavior.pdf:/Users/orsonxu/Zotero/storage/L3UG446Y/Saeb et al_2015_Mobile phone sensor correlates of depressive symptom severity in daily-life behavior.pdf:application/pdf;Saeb et al_2015_Mobile phone sensor correlates of depressive symptom severity in daily-life behavior.pdf:/Users/orsonxu/Zotero/storage/EIK9M49P/Saeb et al_2015_Mobile phone sensor correlates of depressive symptom severity in daily-life behavior.pdf:application/pdf},
}

@article{stachl_predicting_2020,
	title = {Predicting personality from patterns of behavior collected with smartphones},
	volume = {117},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1920484117},
	doi = {10.1073/pnas.1920484117},
	abstract = {Smartphones enjoy high adoption rates around the globe. Rarely more than an arm’s length away, these sensor-rich devices can easily be repurposed to collect rich and extensive records of their users’ behaviors (e.g., location, communication, media consumption), posing serious threats to individual privacy. Here we examine the extent to which individuals’ Big Five personality dimensions can be predicted on the basis of six different classes of behavioral information collected via sensor and log data harvested from smartphones. Taking a machine-learning approach, we predict personality at broad domain (
              
                
                  
                    
                      r
                    
                    
                      median
                    
                  
                
              
              = 0.37) and narrow facet levels (
              
                
                  
                    
                      r
                    
                    
                      median
                    
                  
                
              
              = 0.40) based on behavioral data collected from 624 volunteers over 30 consecutive days (25,347,089 logging events). Our cross-validated results reveal that specific patterns in behaviors in the domains of 1) communication and social behavior, 2) music consumption, 3) app usage, 4) mobility, 5) overall phone activity, and 6) day- and night-time activity are distinctively predictive of the Big Five personality traits. The accuracy of these predictions is similar to that found for predictions based on digital footprints from social media platforms and demonstrates the possibility of obtaining information about individuals’ private traits from behavioral patterns passively collected from their smartphones. Overall, our results point to both the benefits (e.g., in research settings) and dangers (e.g., privacy implications, psychological targeting) presented by the widespread collection and modeling of behavioral data obtained from smartphones.},
	language = {en},
	number = {30},
	urldate = {2021-11-12},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Stachl, Clemens and Au, Quay and Schoedel, Ramona and Gosling, Samuel D. and Harari, Gabriella M. and Buschek, Daniel and Völkel, Sarah Theres and Schuwerk, Tobias and Oldemeier, Michelle and Ullmann, Theresa and Hussmann, Heinrich and Bischl, Bernd and Bühner, Markus},
	month = jul,
	year = {2020},
	pages = {17680--17687},
	file = {pnas.1920484117.sapp.pdf:/Users/orsonxu/Zotero/storage/SGCAUZPL/pnas.1920484117.sapp.pdf:application/pdf;Stachl et al. - 2020 - Predicting personality from patterns of behavior c.pdf:/Users/orsonxu/Zotero/storage/5KKBSSVR/Stachl et al. - 2020 - Predicting personality from patterns of behavior c.pdf:application/pdf},
}

@article{tamura_wearable_2014,
	title = {Wearable {Photoplethysmographic} {Sensors}—{Past} and {Present}},
	volume = {3},
	issn = {2079-9292},
	url = {http://www.mdpi.com/2079-9292/3/2/282},
	doi = {10.3390/electronics3020282},
	abstract = {Photoplethysmography (PPG) technology has been used to develop small, wearable, pulse rate sensors. These devices, consisting of infrared light-emitting diodes (LEDs) and photodetectors, offer a simple, reliable, low-cost means of monitoring the pulse rate noninvasively. Recent advances in optical technology have facilitated the use of high-intensity green LEDs for PPG, increasing the adoption of this measurement technique. In this review, we briefly present the history of PPG and recent developments in wearable pulse rate sensors with green LEDs. The application of wearable pulse rate monitors is discussed.},
	language = {en},
	number = {2},
	urldate = {2021-11-03},
	journal = {Electronics},
	author = {Tamura, Toshiyo and Maeda, Yuka and Sekine, Masaki and Yoshida, Masaki},
	month = apr,
	year = {2014},
	pages = {282--302},
	file = {Tamura et al. - 2014 - Wearable Photoplethysmographic Sensors—Past and Pr.pdf:/Users/orsonxu/Zotero/storage/MSUVE44H/Tamura et al. - 2014 - Wearable Photoplethysmographic Sensors—Past and Pr.pdf:application/pdf},
}

@article{castaneda_review_2018,
	title = {A review on wearable photoplethysmography sensors and their potential future applications in health care},
	volume = {4},
	issn = {2573-2838},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6426305/},
	doi = {10.15406/ijbsbe.2018.04.00125},
	abstract = {Photoplethysmography (PPG) is an uncomplicated and inexpensive optical measurement method that is often used for heart rate monitoring purposes. PPG is a non-invasive technology that uses a light source and a photodetector at the surface of skin to measure the volumetric variations of blood circulation. Recently, there has been much interest from numerous researchers around the globe to extract further valuable information from the PPG signal in addition to heart rate estimation and pulse oxymetry readings. PPG signal’s second derivative wave contains important health-related information. Thus, analysis of this waveform can help researchers and clinicians to evaluate various cardiovascular-related diseases such as atherosclerosis and arterial stiffness. Moreover, investigating the second derivative wave of PPG signal can also assist in early detection and diagnosis of various cardiovascular illnesses that may possibly appear later in life. For early recognition and analysis of such illnesses, continuous and real-time monitoring is an important approach that has been enabled by the latest technological advances in sensor technology and wireless communications. The aim of this article is to briefly consider some of the current developments and challenges of wearable PPG-based monitoring technologies and then to discuss some of the potential applications of this technology in clinical settings.},
	number = {4},
	urldate = {2021-11-03},
	journal = {International journal of biosensors \& bioelectronics},
	author = {Castaneda, Denisse and Esparza, Aibhlin and Ghamari, Mohammad and Soltanpur, Cinna and Nazeran, Homer},
	year = {2018},
	pmid = {30906922},
	pmcid = {PMC6426305},
	pages = {195--202},
	file = {PubMed Central Full Text PDF:/Users/orsonxu/Zotero/storage/R6KPSP8R/Castaneda et al. - 2018 - A review on wearable photoplethysmography sensors .pdf:application/pdf},
}


@inproceedings{xu_hulamove_2021,
	address = {Yokohama Japan},
	title = {{HulaMove}: {Using} {Commodity} {IMU} for {Waist} {Interaction}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {{HulaMove}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445182},
	doi = {10.1145/3411764.3445182},
	abstract = {We present HulaMove, a novel interaction technique that leverages the movement of the waist as a new eyes-free and hands-free input method for both the physical world and the virtual world. We frst conducted a user study (N=12) to understand users’ ability to control their waist. We found that users could easily discriminate eight shifting directions and two rotating orientations, and quickly confrm actions by returning to the original position (quick return). We developed a design space with eight gestures for waist interaction based on the results and implemented an IMU-based real-time system. Using a hierarchical machine learning model, our system could recognize waist gestures at an accuracy of 97.5\%. Finally, we conducted a second user study (N=12) for usability testing in both real-world scenarios and virtual reality settings. Our usability study indicated that HulaMove signifcantly reduced interaction time by 41.8\% compared to a touch screen method, and greatly improved users’ sense of presence in the virtual world. This novel technique provides an additional input method when users’ eyes or hands are busy, accelerates users’ daily operations, and augments their immersive experience in the virtual world.},
	language = {en},
	urldate = {2021-08-04},
	booktitle = {Proceedings of the {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Xu, Xuhai and Li, Jiahao and Yuan, Tianyi and He, Liang and Liu, Xin and Yan, Yukang and Wang, Yuntao and Shi, Yuanchun and Mankoff, Jennifer and Dey, Anind K},
	month = may,
	year = {2021},
	pages = {1--16},
	file = {Xu et al. - 2021 - HulaMove Using Commodity IMU for Waist Interactio.pdf:/Users/orsonxu/Zotero/storage/J773T8NJ/Xu et al. - 2021 - HulaMove Using Commodity IMU for Waist Interactio.pdf:application/pdf},
}

@article{xu_understanding_2021,
	title = {Understanding practices and needs of researchers in human state modeling by passive mobile sensing},
	issn = {2524-521X, 2524-5228},
	url = {https://link.springer.com/10.1007/s42486-021-00072-4},
	doi = {10.1007/s42486-021-00072-4},
	abstract = {Passive mobile sensing for the purpose of human state modeling is a fast-growing area. It has been applied to solve a wide range of behavior-related problems, including physical and mental health monitoring, affective computing, activity recognition, routine modeling, etc. However, in spite of the emerging literature that has investigated a wide range of application scenarios, there is little work focusing on the lessons learned by researchers, and on guidance for researchers to this approach. How do researchers conduct these types of research studies? Is there any established common practice when applying mobile sensing across different application areas? What are the pain points and needs that they frequently encounter? Answering these questions is an important step in the maturing of this growing sub-field of ubiquitous computing, and can benefit a wide range of audiences. It can serve to educate researchers who have growing interests in this area but have little to no previous experience. Intermediate researchers may also find the results interesting and helpful for reference to improve their skills. Moreover, it can further shed light on the design guidelines for a future toolkit that could facilitate research processes being used. In this paper, we fill this gap and answer these questions by conducting semi-structured interviews with ten experienced researchers from four countries to understand their practices and pain points when conducting their research. Our results reveal a common pipeline that researchers have adopted, and identify major challenges that do not appear in published work but that researchers often encounter. Based on the results of our interviews, we discuss practical suggestions for novice researchers and high-level design principles for a toolkit that can accelerate passive mobile sensing research.},
	language = {en},
	urldate = {2021-09-30},
	journal = {CCF Transactions on Pervasive Computing and Interaction},
	author = {Xu, Xuhai and Mankoff, Jennifer and Dey, Anind K.},
	month = jul,
	year = {2021},
	file = {Xu et al. - 2021 - Understanding practices and needs of researchers i.pdf:/Users/orsonxu/Zotero/storage/BCU75N2D/Xu et al. - 2021 - Understanding practices and needs of researchers i.pdf:application/pdf},
}

@inproceedings{sra_breathvr_2018,
	address = {Montreal QC Canada},
	title = {{BreathVR}: {Leveraging} {Breathing} as a {Directly} {Controlled} {Interface} for {Virtual} {Reality} {Games}},
	isbn = {978-1-4503-5620-6},
	shorttitle = {{BreathVR}},
	url = {https://dl.acm.org/doi/10.1145/3173574.3173914},
	doi = {10.1145/3173574.3173914},
	abstract = {With virtual reality head-mounted displays rapidly becoming accessible to mass audiences, there is growing interest in new forms of natural input techniques to enhance immersion and engagement for players. Research has explored physiological input for enhancing immersion in single player games through indirectly controlled signals like heart rate or galvanic skin response. In this paper, we propose breathing as a directly controlled physiological signal that can facilitate unique and engaging play experiences through natural interaction in single and multiplayer virtual reality games. Our study (N = 16) shows that participants report a higher sense of presence and ﬁnd the gameplay more fun and challenging when using our breathing actions. From study observations and analysis we present ﬁve design strategies that can aid virtual reality game designers interested in using directly controlled forms of physiological input.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Sra, Misha and Xu, Xuhai and Maes, Pattie},
	month = apr,
	year = {2018},
	pages = {1--12},
	file = {Sra et al. - 2018 - BreathVR Leveraging Breathing as a Directly Contr.pdf:/Users/orsonxu/Zotero/storage/V3G4LC5D/Sra et al. - 2018 - BreathVR Leveraging Breathing as a Directly Contr.pdf:application/pdf},
}

@article{xu_leveraging_2019,
	title = {Leveraging {Routine} {Behavior} and {Contextually}-{Filtered} {Features} for {Depression} {Detection} among {College} {Students}},
	volume = {3},
	issn = {2474-9567},
	url = {https://dl.acm.org/doi/10.1145/3351274},
	doi = {10.1145/3351274},
	abstract = {The rate of depression in college students is rising, which is known to increase suicide risk, lower academic performance and double the likelihood of dropping out of school. Existing work on fnding relationships between passively sensed behavior and depression, as well as detecting depression, mainly derives relevant unimodal features from a single sensor. However, co-occurrence of values in multiple sensors may provide better features, because such features can describe behavior in context. We present a new method to extract contextually fltered features from passively collected, time-series mobile data via association rule mining. After calculating traditional unimodal features from the data, we extract rules that relate unimodal features to each other using association rule mining. We extract rules from each class separately (e.g., depression vs. nondepression). We introduce a new metric to select a subset of rules that distinguish between the two classes. From these rules, which capture the relationship between multiple unimodal features, we automatically extract contextually fltered features. These features are then fed into a traditional machine learning pipeline to detect the class of interest (in our case, depression), defned by whether a student has a high BDI-II score at the end of the semester. The behavior rules generated by our methods are highly interpretable representations of diferences between classes. Our best model uses contextually-fltered features to signifcantly outperform a standard model that uses only unimodal features, by an average of 9.7\% across a variety of metrics. We further verifed the generalizability of our approach on a second dataset, and achieved very similar results. CCS Concepts: • Human-centered computing Ubiquitous and mobile computing; • Applied computing Life and medical sciences.},
	language = {en},
	number = {3},
	urldate = {2021-10-07},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Xu, Xuhai and Chikersal, Prerna and Doryab, Afsaneh and Villalba, Daniella K. and Dutcher, Janine M. and Tumminia, Michael J. and Althoff, Tim and Cohen, Sheldon and Creswell, Kasey G. and Creswell, J. David and Mankoff, Jennifer and Dey, Anind K.},
	month = sep,
	year = {2019},
	pages = {1--33},
	file = {Xu et al. - 2019 - Leveraging Routine Behavior and Contextually-Filte.pdf:/Users/orsonxu/Zotero/storage/UGVK8ESA/Xu et al. - 2019 - Leveraging Routine Behavior and Contextually-Filte.pdf:application/pdf},
}

@inproceedings{zhong_forceboard_2018,
	address = {Montreal QC Canada},
	title = {{ForceBoard}: {Subtle} {Text} {Entry} {Leveraging} {Pressure}},
	isbn = {978-1-4503-5620-6},
	shorttitle = {{ForceBoard}},
	url = {https://dl.acm.org/doi/10.1145/3173574.3174102},
	doi = {10.1145/3173574.3174102},
	abstract = {We present ForceBoard, a pressure-based input technique that enables text entry by subtle finger motion. To enter text, users apply pressure to control a multi-letter-wide sliding cursor on a one-dimensional keyboard with alphabetical ordering, and confirm the selection with a quick release. We examined the error model of pressure control for successive and error-tolerant input, which was incorporated into a Bayesian algorithm to infer user input. A user study showed that, after a 10-minute training, the average text entry rate reached 4.2 WPM (Words Per Minute) for character-level input, and 11.0 WPM for word-level input. Users reported that ForceBoard was easy to learn and interesting to use. These results demonstrated the feasibility of applying pressure as the main channel for text entry. We conclude by discussing the limitation, as well as the potential of ForceBoard to support interaction with constraints from form factor, social concern and physical environments.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Zhong, Mingyuan and Yu, Chun and Wang, Qian and Xu, Xuhai and Shi, Yuanchun},
	month = apr,
	year = {2018},
	pages = {1--10},
	file = {Zhong et al. - 2018 - ForceBoard Subtle Text Entry Leveraging Pressure.pdf:/Users/orsonxu/Zotero/storage/6TRSE72N/Zhong et al. - 2018 - ForceBoard Subtle Text Entry Leveraging Pressure.pdf:application/pdf},
}

@inproceedings{sra_vmotion_2018,
	address = {Hong Kong China},
	title = {{VMotion}: {Designing} a {Seamless} {Walking} {Experience} in {VR}},
	isbn = {978-1-4503-5198-0},
	shorttitle = {{VMotion}},
	url = {https://dl.acm.org/doi/10.1145/3196709.3196792},
	doi = {10.1145/3196709.3196792},
	abstract = {Physically walking in virtual reality can provide a satisfying sense of presence. However, natural locomotion in virtual worlds larger than the tracked space remains a practical challenge. Numerous redirected walking techniques have been proposed to overcome space limitations but they often require rapid head rotation, sometimes induced by distractors, to keep the scene rotation imperceptible. We propose a design methodology of seamlessly integrating redirection into the virtual experience that takes advantage of the perceptual phenomenon of inattentional blindness. Additionally, we present four novel visibility control techniques that work with our design methodology to minimize disruption to the user experience commonly found in existing redirection techniques. A user study (N = 16) shows that our techniques are imperceptible and users report signiﬁcantly less dizziness when using our methods. The illusion of unconstrained walking in a large area (16 × 8m) is maintained even though users are limited to a smaller (3.5 × 3.5m) physical space.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the {Designing} {Interactive} {Systems} {Conference}},
	publisher = {ACM},
	author = {Sra, Misha and Xu, Xuhai and Mottelson, Aske and Maes, Pattie},
	month = jun,
	year = {2018},
	pages = {59--70},
	file = {Sra et al. - 2018 - VMotion Designing a Seamless Walking Experience i.pdf:/Users/orsonxu/Zotero/storage/FXZU9YZT/Sra et al. - 2018 - VMotion Designing a Seamless Walking Experience i.pdf:application/pdf},
}

@inproceedings{xu_clench_2019,
	address = {Glasgow Scotland Uk},
	title = {Clench {Interface}: {Novel} {Biting} {Input} {Techniques}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {Clench {Interface}},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300505},
	doi = {10.1145/3290605.3300505},
	abstract = {People eat every day and biting is one of the most fundamental and natural actions that they perform on a daily basis. Existing work has explored tooth click location and jaw movement as input techniques, however clenching has the potential to add control to this input channel. We propose clench interaction that leverages clenching as an actively controlled physiological signal that can facilitate interactions. We conducted a user study to investigate users’ ability to control their clench force. We found that users can easily discriminate three force levels, and that they can quickly confirm actions by unclenching (quick release). We developed a design space for clench interaction based on the results and investigated the usability of the clench interface. Participants preferred the clench over baselines and indicated a willingness to use clench-based interactions. This novel technique can provide an additional input method in cases where users’ eyes or hands are busy, augment immersive experiences such as virtual/augmented reality, and assist individuals with disabilities.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Xu, Xuhai and Yu, Chun and Dey, Anind K. and Mankoff, Jennifer},
	month = may,
	year = {2019},
	pages = {1--12},
	file = {Xu et al. - 2019 - Clench Interface Novel Biting Input Techniques.pdf:/Users/orsonxu/Zotero/storage/E3NCFEGR/Xu et al. - 2019 - Clench Interface Novel Biting Input Techniques.pdf:application/pdf},
}

@inproceedings{yan_frownonerror_2020,
	address = {Honolulu HI USA},
	title = {{FrownOnError}: {Interrupting} {Responses} from {Smart} {Speakers} by {Facial} {Expressions}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {{FrownOnError}},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376810},
	doi = {10.1145/3313831.3376810},
	abstract = {In the conversations with smart speakers, misunderstandings of users’ requests lead to erroneous responses. We propose FrownOnError, a novel interaction technique that enables users to interrupt the responses by intentional but natural facial expressions. This method leverages the human nature that the facial expression changes when we receive unexpected responses. We conducted a ﬁrst user study (N=12) to understand users’ intuitive reactions to the correct and incorrect responses. Our results reveal the signiﬁcant difference in the frequency of occurrence and intensity of users’ facial expressions between two conditions, and frowning and raising eyebrows are intuitive to perform and easy to control. Our second user study (N=16) evaluated the user experience and interruption efﬁciency of FrownOnError and the third user study (N=12) explored suitable conversation recovery strategies after the interruptions. Our results show that FrownOnError can be accurately detected (precision: 97.4\%, recall: 97.6\%), provides the most timely interruption compared to the baseline methods of wake-up word and button press, and is rated as most intuitive and easiest to be performed by users.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Yan, Yukang and Yu, Chun and Zheng, Wengrui and Tang, Ruining and Xu, Xuhai and Shi, Yuanchun},
	month = apr,
	year = {2020},
	pages = {1--14},
	file = {Yan et al. - 2020 - FrownOnError Interrupting Responses from Smart Sp.pdf:/Users/orsonxu/Zotero/storage/YM9NFMSS/Yan et al. - 2020 - FrownOnError Interrupting Responses from Smart Sp.pdf:application/pdf},
}

@inproceedings{xu_earbuddy_2020,
	address = {Honolulu HI USA},
	title = {{EarBuddy}: {Enabling} {On}-{Face} {Interaction} via {Wireless} {Earbuds}},
	abstract = {Past research regarding on-body interaction typically requires custom sensors, limiting their scalability and generalizability. We propose EarBuddy, a real-time system that leverages the microphone in commercial wireless earbuds to detect tapping and sliding gestures near the face and ears. We develop a design space to generate 27 valid gestures and conducted a user study (N=16) to select the eight gestures that were optimal for both human preference and microphone detectability. We collected a dataset on those eight gestures (N=20) and trained deep learning models for gesture detection and classiﬁcation. Our optimized classiﬁer achieved an accuracy of 95.3\%. Finally, we conducted a user study (N=12) to evaluate EarBuddy’s usability. Our results show that EarBuddy can facilitate novel interaction and that users feel very positively about the system. EarBuddy provides a new eyes-free, socially acceptable input method that is compatible with commercial wireless earbuds and has the potential for scalability and generalizability.},
	language = {en},
	booktitle = {Proceedings of the {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Xu, Xuhai and Shi, Haitian and Yi, Xin and Liu, Wenjia and Yan, Yukang and Shi, Yuanchun and Mariakakis, Alex and Mankoff, Jennifer and Dey, Anind K},
	year = {2020},
	pages = {14},
	file = {Xu et al. - EarBuddy Enabling On-Face Interaction via Wireles.pdf:/Users/orsonxu/Zotero/storage/6BXBWNYE/Xu et al. - EarBuddy Enabling On-Face Interaction via Wireles.pdf:application/pdf},
}

@inproceedings{xu_hand_2018,
	address = {Barcelona Spain},
	title = {Hand range interface: information always at hand with a body-centric mid-air input surface},
	isbn = {978-1-4503-5898-9},
	shorttitle = {Hand range interface},
	url = {https://dl.acm.org/doi/10.1145/3229434.3229449},
	doi = {10.1145/3229434.3229449},
	abstract = {Most interfaces of our interactive devices such as phones and laptops are ﬂat and are built as external devices in our environment, disconnected from our bodies. Therefore, we need to carry them with us in our pocket or in a bag and accommodate our bodies to their design by sitting at a desk or holding the device in our hand. We propose Hand Range Interface, an input surface that is always at our ﬁngertips. This bodycentric interface is a semi-sphere attached to a user’s wrist, with a radius the same as the distance from the wrist to the index ﬁnger. We prototyped the concept in virtual reality and conducted a user study with a pointing task. The input surface can be designed as rotating with the wrist or ﬁxed relative to the wrist. We evaluated and compared participants’ subjective physical comfort level, pointing speed and pointing accuracy on the interface that was divided into 64 regions. We found that the interface whose orientation was ﬁxed had a much better performance, with 41.2\% higher average comfort score, 40.6\% shorter average pointing time and 34.5\% lower average error. Our results revealed interesting insights on user performance and preference of different regions on the interface. We concluded with a set of guidelines for future designers and developers on how to develop this type of new body-centric input surface.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Xu, Xuhai and Dancu, Alexandru and Maes, Pattie and Nanayakkara, Suranga},
	month = sep,
	year = {2018},
	pages = {1--12},
	file = {Xu et al. - 2018 - Hand range interface information always at hand w.pdf:/Users/orsonxu/Zotero/storage/LMMAF9QS/Xu et al. - 2018 - Hand range interface information always at hand w.pdf:application/pdf},
}

@inproceedings{xu_understanding_2020,
	address = {Taipei Taiwan},
	title = {Understanding {User} {Behavior} {For} {Document} {Recommendation}},
	isbn = {978-1-4503-7023-3},
	url = {https://dl.acm.org/doi/10.1145/3366423.3380071},
	doi = {10.1145/3366423.3380071},
	abstract = {Personalized document recommendation systems aim to provide users with a quick shortcut to the documents they may want to access next, usually with an explanation about why the document is recommended. Previous work explored various methods for better recommendations and better explanations in different domains. However, there are few efforts that closely study how users react to the recommended items in a document recommendation scenario. We conducted a large-scale log study of users’ interaction behavior with the explainable recommendation on one of the largest cloud document platforms office.com. Our analysis reveals a number of factors, including display position, file type, authorship, recency of last access, and most importantly, the recommendation explanations, that are associated with whether users will recognize or open the recommended documents. Moreover, we specifically focus on explanations and conduct an online experiment to investigate the influence of different explanations on user behavior. Our analysis indicates that the recommendations help users access their documents significantly faster, but sometimes users miss a recommendation and resort to other more complicated methods to open the documents. Our results suggest opportunities to improve explanations and more generally the design of systems that provide and explain recommendations for documents.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Proceedings of {The} {Web} {Conference}},
	publisher = {ACM},
	author = {Xu, Xuhai and Hassan Awadallah, Ahmed and T. Dumais, Susan and Omar, Farheen and Popp, Bogdan and Rounthwaite, Robert and Jahanbakhsh, Farnaz},
	month = apr,
	year = {2020},
	pages = {3012--3018},
	file = {Xu et al. - 2020 - Understanding User Behavior For Document Recommend.pdf:/Users/orsonxu/Zotero/storage/S6FXIJMC/Xu et al. - 2020 - Understanding User Behavior For Document Recommend.pdf:application/pdf},
}

@inproceedings{sra_galvr_2017,
	address = {Gothenburg Sweden},
	title = {{GalVR}: a novel collaboration interface using {GVS}},
	isbn = {978-1-4503-5548-3},
	shorttitle = {{GalVR}},
	url = {https://dl.acm.org/doi/10.1145/3139131.3141219},
	doi = {10.1145/3139131.3141219},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the 23rd {ACM} {Symposium} on {Virtual} {Reality} {Software} and {Technology}},
	publisher = {ACM},
	author = {Sra, Misha and Xu, Xuhai and Maes, Pattie},
	month = nov,
	year = {2017},
	pages = {1--2},
	file = {Sra et al. - 2017 - GalVR a novel collaboration interface using GVS.pdf:/Users/orsonxu/Zotero/storage/LH4W46S2/Sra et al. - 2017 - GalVR a novel collaboration interface using GVS.pdf:application/pdf},
}

@article{xu_recognizing_2020,
	title = {Recognizing {Unintentional} {Touch} on {Interactive} {Tabletop}},
	volume = {4},
	issn = {2474-9567},
	url = {https://dl.acm.org/doi/10.1145/3381011},
	doi = {10.1145/3381011},
	abstract = {A multi-touch interactive tabletop is designed to embody the benefits of a digital computer within the familiar surface of a physical tabletop. However, the nature of current multi-touch tabletops to detect and react to all forms of touch, including unintentional touches, impedes users from acting naturally on them. In our research, we leverage gaze direction, head orientation and screen contact data to identify and filter out unintentional touches, so that users can take full advantage of the physical properties of an interactive tabletop, e.g., resting hands or leaning on the tabletop during the interaction. To achieve this, we first conducted a user study to identify behavioral pattern differences (gaze, head and touch) between completing usual tasks on digital versus physical tabletops. We then compiled our findings into five types of spatiotemporal features, and train a machine learning model to recognize unintentional touches with an F1 score of 91.3\%, outperforming the state-of-the-art model by 4.3\%. Finally we evaluated our algorithm in a real-time filtering system. A user study shows that our algorithm is stable and the improved tabletop effectively screens out unintentional touches, and provide more relaxing and natural user experience. By linking their gaze and head behavior to their touch behavior, our work sheds light on the possibility of future tabletop technology to improve the understanding of users' input intention.},
	language = {en},
	number = {1},
	urldate = {2021-10-07},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Xu, Xuhai and Yu, Chun and Wang, Yuntao and Shi, Yuanchun},
	month = mar,
	year = {2020},
	pages = {1--24},
	file = {Xu et al. - 2020 - Recognizing Unintentional Touch on Interactive Tab.pdf:/Users/orsonxu/Zotero/storage/SNGMSGNT/Xu et al. - 2020 - Recognizing Unintentional Touch on Interactive Tab.pdf:application/pdf},
}

@inproceedings{jahanbakhsh_effects_2020,
	address = {Vancouver BC Canada},
	title = {Effects of {Past} {Interactions} on {User} {Experience} with {Recommended} {Documents}},
	isbn = {978-1-4503-6892-6},
	url = {https://dl.acm.org/doi/10.1145/3343413.3377977},
	doi = {10.1145/3343413.3377977},
	abstract = {Recommender systems are commonly used in entertainment, news, e-commerce, and social media. Document recommendation is a new and under-explored application area, in which both re-finding and discovery of documents need to be supported. In this paper we provide an initial exploration of users’ experience with recommended documents, with a focus on how prior interactions influence recognition and interest. Through a field study of more than 100 users, we investigate the effects of past interactions with recommended documents on users’ recognition of, prior intent to open, and interest in the documents. We examined different presentations of interaction history, and the recency and richness of prior interaction. We found that presentation only influenced recognition time. Our findings also indicate that people are more likely to recognize documents they had accessed recently and to do so more quickly. Similarly, documents that people had interacted with more deeply were also more frequently and quickly recognized. However, people were more interested in older documents or those with which they had less involved interactions. This finding suggests that in addition to helping users quickly access documents they intend to re-find, document recommendation can add value in helping users discover other documents. Our results offer implications for designing document recommendation systems that help users fulfil different needs.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the 2020 {Conference} on {Human} {Information} {Interaction} and {Retrieval}},
	publisher = {ACM},
	author = {Jahanbakhsh, Farnaz and Awadallah, Ahmed Hassan and Dumais, Susan T. and Xu, Xuhai},
	month = mar,
	year = {2020},
	pages = {153--162},
	file = {Jahanbakhsh et al. - 2020 - Effects of Past Interactions on User Experience wi.pdf:/Users/orsonxu/Zotero/storage/8HI89RYX/Jahanbakhsh et al. - 2020 - Effects of Past Interactions on User Experience wi.pdf:application/pdf},
}

@inproceedings{chen_understanding_2021,
	address = {Virtual Event USA},
	title = {Understanding the {Design} {Space} of {Mouth} {Microgestures}},
	isbn = {978-1-4503-8476-6},
	url = {https://dl.acm.org/doi/10.1145/3461778.3462004},
	doi = {10.1145/3461778.3462004},
	abstract = {As wearable devices move toward the face (i.e. smart earbuds, glasses), there is an increasing need to facilitate intuitive interactions with these devices. Current sensing techniques can already detect many mouth-based gestures; however, users’ preferences of these gestures are not fully understood. In this paper, we investigate the design space and usability of mouth-based microgestures. We first conducted brainstorming sessions (N=16) and compiled an extensive set of 86 user-defined gestures. Then, with an online survey (N=50), we assessed the physical and mental demand of our gesture set and identified a subset of 14 gestures that can be performed easily and naturally. Finally, we conducted a remote Wizard-of-Oz usability study (N=11) mapping gestures to various daily smartphone operations under a sitting and walking context. From these studies, we develop a taxonomy for mouth gestures, finalize a practical gesture set for common applications, and provide design guidelines for future mouth-based gesture interactions.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the {Designing} {Interactive} {Systems} {Conference}},
	publisher = {ACM},
	author = {Chen, Victor and Xu, Xuhai and Li, Richard and Shi, Yuanchun and Patel, Shwetak and Wang, Yuntao},
	month = jun,
	year = {2021},
	pages = {1068--1081},
	file = {Chen et al. - 2021 - Understanding the Design Space of Mouth Microgestu.pdf:/Users/orsonxu/Zotero/storage/3E7HILPB/Chen et al. - 2021 - Understanding the Design Space of Mouth Microgestu.pdf:application/pdf},
}

@inproceedings{he_pneufetch_2020,
	address = {Honolulu HI USA},
	title = {{PneuFetch}: {Supporting} {Blind} and {Visually} {Impaired} {People} to {Fetch} {Nearby} {Objects} via {Light} {Haptic} {Cues}},
	isbn = {978-1-4503-6819-3},
	shorttitle = {{PneuFetch}},
	url = {https://dl.acm.org/doi/10.1145/3334480.3383095},
	doi = {10.1145/3334480.3383095},
	abstract = {We present PneuFetch, a light haptic cue based wearable device that supports blind and visually impaired (BVI) people to fetch nearby objects in an unfamiliar environment. In our design, we generate friendly, non-intrusive, and gentle presses and drags to deliver direction and distance cues on BVI user’s wrist and forearm. As a concept of proof, we discuss our PneuFetch wearable prototype, contrast it with past work, and describe a preliminary user study.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Extended {Abstracts} {Proceedings} of the {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {He, Liang and Wang, Ruolin and Xu, Xuhai},
	month = apr,
	year = {2020},
	pages = {1--9},
	file = {He et al. - 2020 - PneuFetch Supporting Blind and Visually Impaired .pdf:/Users/orsonxu/Zotero/storage/URJFKBEZ/He et al. - 2020 - PneuFetch Supporting Blind and Visually Impaired .pdf:application/pdf},
}

@inproceedings{zhang_voicemoji_2021,
	address = {Yokohama Japan},
	title = {Voicemoji: {Emoji} {Entry} {Using} {Voice} for {Visually} {Impaired} {People}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {Voicemoji},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445338},
	doi = {10.1145/3411764.3445338},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Zhang, Mingrui Ray and Wang, Ruolin and Xu, Xuhai and Li, Qisheng and Sharif, Ather and Wobbrock, Jacob O.},
	month = may,
	year = {2021},
	pages = {1--18},
	file = {Zhang et al. - 2021 - Voicemoji Emoji Entry Using Voice for Visually Im.pdf:/Users/orsonxu/Zotero/storage/WQHDQZ76/Zhang et al. - 2021 - Voicemoji Emoji Entry Using Voice for Visually Im.pdf:application/pdf},
}

@article{morris_college_2021,
	title = {College from home during {COVID}-19: {A} mixed-methods study of heterogeneous experiences},
	volume = {16},
	issn = {1932-6203},
	shorttitle = {College from home during {COVID}-19},
	url = {https://dx.plos.org/10.1371/journal.pone.0251580},
	doi = {10.1371/journal.pone.0251580},
	abstract = {This mixed-method study examined the experiences of college students during the COVID19 pandemic through surveys, experience sampling data collected over two academic quarters (Spring 2019 n1 = 253; Spring 2020 n2 = 147), and semi-structured interviews with 27 undergraduate students. There were no marked changes in mean levels of depressive symptoms, anxiety, stress, or loneliness between 2019 and 2020, or over the course of the Spring 2020 term. Students in both the 2019 and 2020 cohort who indicated psychosocial vulnerability at the initial assessment showed worse psychosocial functioning throughout the entire Spring term relative to other students. However, rates of distress increased faster in 2020 than in 2019 for these individuals. Across individuals, homogeneity of variance tests and multi-level models revealed significant heterogeneity, suggesting the need to examine not just means but the variations in individuals’ experiences. Thematic analysis of interviews characterizes these varied experiences, describing the contexts for students’ challenges and strategies. This analysis highlights the interweaving of psychosocial and academic distress: Challenges such as isolation from peers, lack of interactivity with instructors, and difficulty adjusting to family needs had both an emotional and academic toll. Strategies for adjusting to this new context included initiating remote study and hangout sessions with peers, as well as self-learning. In these and other strategies, students used technologies in different ways and for different purposes than they had previously. Supporting qualitative insight about adaptive responses were quantitative findings that students who used more problem-focused forms of coping reported fewer mental health symptoms over the course of the pandemic, even though they perceived their stress as more severe. These findings underline the need for interventions oriented towards problem-focused coping and suggest opportunities for peer role modeling.},
	language = {en},
	number = {6},
	urldate = {2021-10-07},
	journal = {PLOS ONE},
	author = {Morris, Margaret E. and Kuehn, Kevin S. and Brown, Jennifer and Nurius, Paula S. and Zhang, Han and Sefidgar, Yasaman S. and Xu, Xuhai and Riskin, Eve A. and Dey, Anind K. and Consolvo, Sunny and Mankoff, Jennifer C.},
	editor = {Webster, Amanda A.},
	month = jun,
	year = {2021},
	pages = {e0251580},
	file = {Morris et al. - 2021 - College from home during COVID-19 A mixed-methods.pdf:/Users/orsonxu/Zotero/storage/WZWX4W9J/Morris et al. - 2021 - College from home during COVID-19 A mixed-methods.pdf:application/pdf},
}

@article{xu_listen2cough_2021,
	title = {{Listen2Cough}: {Leveraging} {End}-to-{End} {Deep} {Learning} {Cough} {Detection} {Model} to {Enhance} {Lung} {Health} {Assessment} {Using} {Passively} {Sensed} {Audio}},
	volume = {5},
	issn = {2474-9567},
	shorttitle = {{Listen2Cough}},
	url = {https://dl.acm.org/doi/10.1145/3448124},
	doi = {10.1145/3448124},
	abstract = {The prevalence of ubiquitous computing enables new opportunities for lung health monitoring and assessment. In the past few years, there have been extensive studies on cough detection using passively sensed audio signals. However, the generalizability of a cough detection model when applied to external datasets, especially in real-world implementation, is questionable and not explored adequately. Beyond detecting coughs, researchers have looked into how cough sounds can be used in assessing lung health. However, due to the challenges in collecting both cough sounds and lung health condition ground truth, previous studies have been hindered by the limited datasets. In this paper, we propose Listen2Cough to address these gaps. We first build an end-to-end deep learning architecture using public cough sound datasets to detect coughs within raw audio recordings. We employ a pre-trained MobileNet and integrate a number of augmentation techniques to improve the generalizability of our model. Without additional fine-tuning, our model is able to achieve an F1 score of 0.948 when tested against a new clean dataset, and 0.884 on another in-the-wild noisy dataset, leading to an advantage of 5.8\% and 8.4\% on average over the best baseline model, respectively. Then, to mitigate the issue of limited lung health data, we propose to transform the cough detection task to lung health assessment tasks so that the rich cough data can be leveraged. Our hypothesis is that these tasks extract and utilize similar effective representation from cough sounds. We embed the cough detection model into a multi-instance learning framework with the attention mechanism and further tune the model for lung health assessment tasks. Our final model achieves an F1-score of 0.912 on healthy v.s. unhealthy, 0.870 on obstructive v.s. non-obstructive, and 0.813 on COPD v.s. asthma classification, outperforming the baseline by 10.7\%, 6.3\%, and 3.7\%, respectively. Moreover, the weight value in the attention layer can be used to identify important coughs highly correlated with lung health, which can potentially provide interpretability for expert diagnosis in the future. CCS Concepts: • Human-centered computing → Ubiquitous and mobile computing; • Applied computing → Life and medical sciences.},
	language = {en},
	number = {1},
	urldate = {2021-10-07},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Xu, Xuhai and Nemati, Ebrahim and Vatanparvar, Korosh and Nathan, Viswam and Ahmed, Tousif and Rahman, Md Mahbubur and McCaffrey, Daniel and Kuang, Jilong and Gao, Jun Alex},
	month = mar,
	year = {2021},
	pages = {1--22},
	file = {Xu et al. - 2021 - Listen2Cough Leveraging End-to-End Deep Learning .pdf:/Users/orsonxu/Zotero/storage/ACPJMCBB/Xu et al. - 2021 - Listen2Cough Leveraging End-to-End Deep Learning .pdf:application/pdf},
}

@article{xu_leveraging_2021,
	title = {Leveraging {Collaborative}-{Filtering} for {Personalized} {Behavior} {Modeling}: {A} {Case} {Study} of {Depression} {Detection} among {College} {Students}},
	volume = {5},
	issn = {2474-9567},
	shorttitle = {Leveraging {Collaborative}-{Filtering} for {Personalized} {Behavior} {Modeling}},
	url = {https://dl.acm.org/doi/10.1145/3448107},
	doi = {10.1145/3448107},
	abstract = {The prevalence of mobile phones and wearable devices enables the passive capturing and modeling of human behavior at an unprecedented resolution and scale. Past research has demonstrated the capability of mobile sensing to model aspects of physical health, mental health, education, and work performance, etc. However, most of the algorithms and models proposed in previous work follow a one-size-fits-all (i.e., population modeling) approach that looks for common behaviors amongst all users, disregarding the fact that individuals can behave very differently, resulting in reduced model performance. Further, black-box models are often used that do not allow for interpretability and human behavior understanding. We present a new method to address the problems of personalized behavior classification and interpretability, and apply it to depression detection among college students. Inspired by the idea of collaborative-filtering, our method is a type of memory-based learning algorithm. It leverages the relevance of mobile-sensed behavior features among individuals to calculate personalized relevance weights, which are used to impute missing data and select features according to a specific modeling goal (e.g., whether the student has depressive symptoms) in different time epochs, i.e., times of the day and days of the week. It then compiles features from epochs using majority voting to obtain the final prediction. We apply our algorithm on a depression detection dataset collected from first-year college students with low data-missing rates and show that our method outperforms the state-of-the-art machine learning model by 5.1\% in accuracy and 5.5\% in F1 score. We further verify the pipeline-level generalizability of our approach by achieving similar results on a second dataset, with an average improvement of 3.4\% across performance metrics. Beyond achieving better classification performance, our novel approach is further able to generate personalized interpretations of the models for each individual. These interpretations are supported by existing depression-related literature and can potentially inspire automated and personalized depression intervention design in the future.},
	language = {en},
	number = {1},
	urldate = {2021-10-07},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Xu, Xuhai and Chikersal, Prerna and Dutcher, Janine M. and Sefidgar, Yasaman S. and Seo, Woosuk and Tumminia, Michael J. and Villalba, Daniella K. and Cohen, Sheldon and Creswell, Kasey G. and Creswell, J. David and Doryab, Afsaneh and Nurius, Paula S. and Riskin, Eve and Dey, Anind K. and Mankoff, Jennifer},
	month = mar,
	year = {2021},
	pages = {1--27},
	file = {Xu et al. - 2021 - Leveraging Collaborative-Filtering for Personalize.pdf:/Users/orsonxu/Zotero/storage/AX2ZQTNL/Xu et al. - 2021 - Leveraging Collaborative-Filtering for Personalize.pdf:application/pdf},
}

@inproceedings{wu_lightwrite_2021,
	address = {Yokohama Japan},
	title = {{LightWrite}: {Teach} {Handwriting} to {The} {Visually} {Impaired} with {A} {Smartphone}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {{LightWrite}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445322},
	doi = {10.1145/3411764.3445322},
	abstract = {Learning to write is challenging for blind and low vision (BLV) people because of the lack of visual feedback. Regardless of the drastic advancement of digital technology, handwriting is still an essential part of daily life. Although tools designed for teaching BLV to write exist, many are expensive and require the help of sighted teachers. We propose LightWrite, a low-cost, easy-to-access smartphone application that uses voice-based descriptive instruction and feedback to teach BLV users to write English lowercase letters and Arabian digits in a specifically designed font. A two-stage study with 15 BLV users with little prior writing knowledge shows that LightWrite can successfully teach users to learn handwriting characters in an average of 1.09 minutes for each letter. After initial training and 20-minute daily practice for 5 days, participants were able to write an average of 19.9 out of 26 letters that are recognizable by sighted raters.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Wu, Zihan and Yu, Chun and Xu, Xuhai and Wei, Tong and Zou, Tianyuan and Wang, Ruolin and Shi, Yuanchun},
	month = may,
	year = {2021},
	pages = {1--15},
	file = {Wu et al. - 2021 - LightWrite Teach Handwriting to The Visually Impa.pdf:/Users/orsonxu/Zotero/storage/7I53F874/Wu et al. - 2021 - LightWrite Teach Handwriting to The Visually Impa.pdf:application/pdf},
}

@inproceedings{liang_authtrack_2021,
	address = {Yokohama Japan},
	title = {Auth+{Track}: {Enabling} {Authentication} {Free} {Interaction} on {Smartphone} by {Continuous} {User} {Tracking}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {Auth+{Track}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445624},
	doi = {10.1145/3411764.3445624},
	abstract = {We propose Auth+Track, a novel authentication model that aims to reduce redundant authentication in everyday smartphone usage. By sparse authentication and continuous tracking of the user’s status, Auth+Track eliminates the "gap" authentication between fragmented sessions and enables "Authentication Free when User is Around". To instantiate the Auth+Track model, we present PanoTrack, a prototype that integrates body and near feld hand information for user tracking. We install a fsheye camera on the top of the phone to achieve a panoramic vision that can capture both user’s body and on-screen hands. Based on the captured video stream, we develop an algorithm to extract 1) features for user tracking, including body keypoints and their temporal and spatial association, near feld hand status, and 2) features for user identity assignment. The results of our user studies validate the feasibility of PanoTrack and demonstrate that Auth+Track not only improves the authentication efciency but also enhances user experiences with better usability.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Liang, Chen and Yu, Chun and Wei, Xiaoying and Xu, Xuhai and Hu, Yongquan and Wang, Yuntao and Shi, Yuanchun},
	month = may,
	year = {2021},
	pages = {1--16},
	file = {Liang et al. - 2021 - Auth+Track Enabling Authentication Free Interacti.pdf:/Users/orsonxu/Zotero/storage/JSZI8L3S/Liang et al. - 2021 - Auth+Track Enabling Authentication Free Interacti.pdf:application/pdf},
}

@inproceedings{liu_metaphys_2021,
	address = {Virtual Event USA},
	title = {{MetaPhys}: few-shot adaptation for non-contact physiological measurement},
	isbn = {978-1-4503-8359-2},
	shorttitle = {{MetaPhys}},
	url = {https://dl.acm.org/doi/10.1145/3450439.3451870},
	doi = {10.1145/3450439.3451870},
	abstract = {There are large individual differences in physiological processes, making designing personalized health sensing algorithms challenging. Existing machine learning systems struggle to generalize well to unseen subjects or contexts and can often contain problematic biases. Video-based physiological measurement is no exception. Therefore, learning personalized or customized models from a small number of unlabeled samples is very attractive as it would allow fast calibrations to improve generalization and help correct biases. In this paper, we present a novel meta-learning approach called MetaPhys for personalized video-based cardiac measurement for non-contact pulse and heart rate monitoring. Our method uses only 18-seconds of video for customization and works effectively in both supervised and unsupervised manners. We evaluate our approach on two benchmark datasets and demonstrate superior performance in cross-dataset evaluation with substantial reductions (42\% to 44\%) in errors compared with state-of-the-art approaches. We also find that our method leads to large reductions in bias due to skin type.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the {Conference} on {Health}, {Inference}, and {Learning}},
	publisher = {ACM},
	author = {Liu, Xin and Jiang, Ziheng and Fromm, Josh and Xu, Xuhai and Patel, Shwetak and McDuff, Daniel},
	month = apr,
	year = {2021},
	pages = {154--163},
	file = {Liu et al. - 2021 - MetaPhys few-shot adaptation for non-contact phys.pdf:/Users/orsonxu/Zotero/storage/6P28KGE9/Liu et al. - 2021 - MetaPhys few-shot adaptation for non-contact phys.pdf:application/pdf},
}

@article{wang_hearcough_2022,
	title = {{HearCough}: {Enabling} continuous cough event detection on edge computing hearables},
	volume = {205},
	issn = {1046-2023},
	shorttitle = {{HearCough}},
	url = {https://www.sciencedirect.com/science/article/pii/S1046202322001165},
	doi = {10.1016/j.ymeth.2022.05.002},
	abstract = {Cough event detection is the foundation of any measurement associated with cough, one of the primary symptoms of pulmonary illnesses. This paper proposes HearCough, which enables continuous cough event detection on edge computing hearables, by leveraging always-on active noise cancellation (ANC) microphones in commodity hearables. Specifically, we proposed a lightweight end-to-end neural network model — Tiny-COUNET and its transfer learning based traning method. When evaluated on our acted cough event dataset, Tiny-COUNET achieved equivalent detection performance but required significantly less computational resources and storage space than cutting-edge cough event detection methods. Then we implemented HearCough by quantifying and deploying the pre-trained Tiny-COUNET to a popular micro-controller in consumer hearables. Lastly, we evaluated that HearCough is effective and reliable for continuous cough event detection through a field study with 8 patients. HearCough achieved 2 Hz cough event detection with an accuracy of 90.0\% and an F1-score of 89.5\% by consuming an additional 5.2 mW power. We envision HearCough as a low-cost add-on for future hearables to enable continuous cough detection and pulmonary health monitoring.},
	language = {en},
	urldate = {2022-07-10},
	journal = {Methods},
	author = {Wang, Yuntao and Zhang, Xiyuxing and Chakalasiya, Jay M. and Xu, Xuhai and Jiang, Yu and Li, Yuang and Patel, Shwetak and Shi, Yuanchun},
	month = sep,
	year = {2022},
	pages = {53--62},
}

@inproceedings{xu_typeout_2022,
	address = {New Orleans LA USA},
	title = {{TypeOut}: {Leveraging} {Just}-in-{Time} {Self}-{Affirmation} for {Smartphone} {Overuse} {Reduction}},
	isbn = {978-1-4503-9157-3},
	shorttitle = {{TypeOut}},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517476},
	doi = {10.1145/3491102.3517476},
	abstract = {Smartphone overuse is related to a variety of issues such as lack of sleep and anxiety. We explore the application of Self-Afrmation Theory on smartphone overuse intervention in a just-in-time manner. We present TypeOut, a just-in-time intervention technique that integrates two components: an in-situ typing-based unlock process to improve user engagement, and self-afrmation-based typing content to enhance efectiveness. We hypothesize that the integration of typing and self-afrmation content can better reduce smartphone overuse. We conducted a 10-week within-subject feld experiment (N=54) and compared TypeOut against two baselines: one only showing the self-afrmation content (a common notifcation-based intervention), and one only requiring typing non-semantic content (a state-of-the-art method). TypeOut reduces app usage by over 50\%, and both app opening frequency and usage duration by over 25\%, all signifcantly outperforming baselines. TypeOut can potentially be used in other domains where an intervention may beneft from integrating self-afrmation exercises with an engaging just-in-time mechanism.},
	language = {en},
	urldate = {2022-07-10},
	booktitle = {Proceedings of the {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Xu, Xuhai and Zou, Tianyuan and Xiao, Han and Li, Yanzhang and Wang, Ruolin and Yuan, Tianyi and Wang, Yuntao and Shi, Yuanchun and Mankoff, Jennifer and Dey, Anind K},
	month = apr,
	year = {2022},
	pages = {1--17},
	file = {Xu et al. - 2022 - TypeOut Leveraging Just-in-Time Self-Affirmation .pdf:/Users/orsonxu/Zotero/storage/TA6VE4BN/Xu et al. - 2022 - TypeOut Leveraging Just-in-Time Self-Affirmation .pdf:application/pdf},
}

@inproceedings{xu_enabling_2022,
	address = {New Orleans LA USA},
	title = {Enabling {Hand} {Gesture} {Customization} on {Wrist}-{Worn} {Devices}},
	isbn = {978-1-4503-9157-3},
	url = {https://dl.acm.org/doi/10.1145/3491102.3501904},
	doi = {10.1145/3491102.3501904},
	abstract = {We present a framework for gesture customization requiring minimal examples from users, all without degrading the performance of existing gesture sets. To achieve this, we frst deployed a large-scale study (N=500+) to collect data and train an accelerometer-gyroscope recognition model with a cross-user accuracy of 95.7\% and a falsepositive rate of 0.6 per hour when tested on everyday non-gesture data. Next, we design a few-shot learning framework which derives a lightweight model from our pre-trained model, enabling knowledge transfer without performance degradation. We validate our approach through a user study (N=20) examining on-device customization from 12 new gestures, resulting in an average accuracy of 55.3\%, 83.1\%, and 87.2\% on using one, three, or fve shots when adding a new gesture, while maintaining the same recognition accuracy and false-positive rate from the pre-existing gesture set. We further evaluate the usability of our real-time implementation with a user experience study (N=20). Our results highlight the efectiveness, learnability, and usability of our customization framework.},
	language = {en},
	urldate = {2022-07-10},
	booktitle = {Proceedings of the {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Xu, Xuhai and Gong, Jun and Brum, Carolina and Liang, Lilian and Suh, Bongsoo and Gupta, Shivam Kumar and Agarwal, Yash and Lindsey, Laurence and Kang, Runchang and Shahsavari, Behrooz and Nguyen, Tu and Nieto, Heriberto and Hudson, Scott E and Maalouf, Charlie and Mousavi, Jax Seyed and Laput, Gierad},
	month = apr,
	year = {2022},
	pages = {1--19},
	file = {Xu et al. - 2022 - Enabling Hand Gesture Customization on Wrist-Worn .pdf:/Users/orsonxu/Zotero/storage/XUC3K2JT/Xu et al. - 2022 - Enabling Hand Gesture Customization on Wrist-Worn .pdf:application/pdf},
}

@inproceedings{nemati_ubilung_2022,
	title = {Ubilung: {Multi}-{Modal} {Passive}-{Based} {Lung} {Health} {Assessment}},
	shorttitle = {Ubilung},
	doi = {10.1109/ICASSP43922.2022.9746614},
	abstract = {Lung health assessment is traditionally done mainly through X-ray images and spirometry tests which are time-consuming, cumbersome, and costly. In this paper, we investigate the potential of passively recordable contents such as speech, cough and heart signal for such an assessment. Our regression model is the first in the literature to achieve mean absolute error (MAE) of 7.47\% for estimation of forced expiratory volume in 1 sec. (FEV1) over forced vital capacity (FVC) ratio using these contents. This is comparable to the state of the art active phone-based spirometry methods. Additionally our classification models achieve a F1-score of 0.982 for healthy v.s. diseased, 0.881 for obstructive v.s. non-obstructive, 0.854 for chronic obstructive pulmonary disease (COPD) v.s. asthma, and 0.892 for severe v.s. non-severe obstruction classification.},
	booktitle = {{ICASSP} 2022 - 2022 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Nemati, Ebrahim and Xu, Xuhai and Nathan, Viswam and Vatanparvar, Korosh and Ahmed, Tousif and Rahman, Md. Mahbubur and McCaffrey, Dan and Kuang, Jilong and Gao, Alex},
	month = may,
	year = {2022},
	note = {ISSN: 2379-190X},
	pages = {551--555},
}

@inproceedings{zhang_boldmove_2022,
	address = {New Orleans LA USA},
	title = {{BoldMove}: {Enabling} {IoT} {Device} {Control} on {Ubiquitous} {Touch} {Interfaces} by {Semantic} {Mapping} and {Sequential} {Selection}},
	isbn = {978-1-4503-9156-6},
	shorttitle = {{BoldMove}},
	url = {https://dl.acm.org/doi/10.1145/3491101.3519805},
	doi = {10.1145/3491101.3519805},
	abstract = {Recent advances in ultra-low-power ubiquitous touch interfaces make touch inputs possible anytime, anywhere. However, their functions are usually pre-determined, i.e., one button is only associated with one fixed function. BoldMove enables spontaneous and efficient association of touch inputs and IoT device functions with semantic-based function filtering and a wait-confirm sequential selection strategy. In this way, such touch interfaces become ubiquitous IoT device controllers. We proposed the semantic-based IoT function filtering to improve control efficiency, then designed the sequential selection mechanism for interfaces with constrained input and output resources. We implemented BoldMove on a custom-built touch interface with capacitive button inputs and a smartwatch display. We then conducted a user study to determine the design parameters for the sequential selection method. At last, we validated that BoldMove only takes 3.25 seconds to complete a selection task if the target function appears within the Top-3 displayed item. Even if the assumption is relaxed to Top-10, BoldMove is still estimated to be more efficient than the conventional selection method with device-based filtering and menu-navigated selection.},
	language = {en},
	urldate = {2022-07-10},
	booktitle = {Extended {Abstracts} {Proceedings} of the {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Zhang, Tengxiang and Zeng, Xin and Zhang, Yinshuai and Jiang, Xin and Xu, Xuhai and Dey, Anind K and Chen, Yiqiang},
	month = apr,
	year = {2022},
	pages = {1--7},
	file = {Zhang et al. - 2022 - BoldMove Enabling IoT Device Control on Ubiquitou.pdf:/Users/orsonxu/Zotero/storage/TH7P7844/Zhang et al. - 2022 - BoldMove Enabling IoT Device Control on Ubiquitou.pdf:application/pdf},
}

@article{zhang_impact_2022,
	title = {Impact of {Online} {Learning} in the {Context} of {COVID}-19 on {Undergraduates} with {Disabilities} and {Mental} {Health} {Concerns}},
	issn = {1936-7228, 1936-7236},
	url = {https://dl.acm.org/doi/10.1145/3538514},
	doi = {10.1145/3538514},
	abstract = {The COVID-19 pandemic upended college education and the experiences of students due to the rapid and uneven shift to online learning. This study examined the experiences of students with disabilities with online learning, with a consideration of surrounding stressors such as financial pressures. In a mixed method approach, we compared 28 undergraduate students with disabilities (including mental health concerns) to their peers during 2020, to assess differences and similarities in their educational concerns, stress levels and COVID-19 related adversities. We found that students with disabilities entered the Spring quarter of 2020 with significantly higher concerns about classes going online, and reported more recent negative life events than other students. These differences between the two groups diminished three months later with the exception of recent negative life events. For a fuller understanding of students’ experiences, we conducted qualitative analysis of open ended interviews. We examined both positive and negative experiences with online learning among students with disabilities and mental health concerns. We describe how online learning enabled greater access–e.g., reducing the need for travel to campus–alongside ways in which online learning impeded academic engagement–e.g., reducing interpersonal interaction. We highlight a need for learning systems to meet the diverse and dynamic needs of students with disabilities.},
	language = {en},
	urldate = {2022-10-01},
	journal = {ACM Transactions on Accessible Computing},
	author = {Zhang, Han and Morris, Margaret E. and Nurius, Paula S. and Mack, Kelly and Brown, Jennifer and Kuehn, Kevin S. and Sefidgar, Yasaman S. and Xu, Xuhai and Riskin, Eve A. and Dey, Anind K. and Mankoff, Jennifer},
	month = jul,
	year = {2022},
	pages = {3538514},
	file = {Zhang et al. - 2022 - Impact of Online Learning in the Context of COVID-.pdf:/Users/orsonxu/Zotero/storage/KSW3T3G8/Zhang et al. - 2022 - Impact of Online Learning in the Context of COVID-.pdf:application/pdf},
}

@inproceedings{zhang_how_2020,
	title = {How {Does} {COVID}-19 impact {Students} with {Disabilities}/{Health} {Concerns}?},
	url = {http://arxiv.org/abs/2005.05438},
	abstract = {The impact of COVID-19 on students has been enormous, with an increase in worries about fiscal and physical health, a rapid shift to online learning, and increased isolation. In addition to these changes, students with disabilities/health concerns may face accessibility problems with online learning or communication tools, and their stress may be compounded by additional risks such as financial stress or pre-existing conditions. To our knowledge, no one has looked specifically at the impact of COVID-19 on students with disabilities/health concerns. In this paper, we present data from a survey of 147 students with and without disabilities collected in late March to early April of 2020 to assess the impact of COVID-19 on these students' education and mental health. Our findings show that students with disabilities/health concerns were more concerned about classes going online than their peers without disabilities. In addition, students with disabilities/health concerns also reported that they have experienced more COVID-19 related adversities compared to their peers without disabilities/health concerns. We argue that students with disabilities/health concerns in higher education need confidence in the accessibility of the online learning tools that are becoming increasingly prevalent in higher education not only because of COVID-19 but also more generally. In addition, educational technologies will be more accessible if they consider the learning context, and are designed to provide a supportive, calm, and connecting learning environment.},
	urldate = {2022-10-01},
	booktitle = {{arXiv}},
	publisher = {arXiv},
	author = {Zhang, Han and Nurius, Paula and Sefidgar, Yasaman and Morris, Margaret and Balasubramanian, Sreenithi and Brown, Jennifer and Dey, Anind K. and Kuehn, Kevin and Riskin, Eve and Xu, Xuhai and Mankoff, Jen},
	month = may,
	year = {2020},
	note = {arXiv:2005.05438 [cs]},
	annote = {Comment: 15 pages},
	file = {Zhang et al_2021_How Does COVID-19 impact Students with Disabilities-Health Concerns.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Zhang et al_2021_How Does COVID-19 impact Students with Disabilities-Health Concerns.pdf:application/pdf},
}

@inproceedings{xu_globem_2022,
	title = {{GLOBEM} {Dataset}: {Multi}-{Year} {Datasets} for {Longitudinal} {Human} {Behavior} {Modeling} {Generalization}},
	abstract = {Recent research has demonstrated the capability of behavior signals captured by smartphones and wearables for longitudinal behavior modeling. However, there is a lack of a comprehensive public dataset that serves as an open testbed for fair comparison among algorithms. Moreover, prior studies mainly evaluate algorithms using data from a single population within a short period, without measuring the cross-dataset generalizability of these algorithms. We present the first multi-year passive sensing datasets, containing over 700 user-years and 497 unique users’ data collected from mobile and wearable sensors, together with a wide range of well-being metrics. Our datasets can support multiple cross-dataset evaluations of behavior modeling algorithms’ generalizability across different users and years. As a starting point, we provide the benchmark results of 18 algorithms on the task of depression detection. Our results indicate that both prior depression detection algorithms and domain generalization techniques show potential but need further research to achieve adequate cross-dataset generalizability. We envision our multi-year datasets can support the ML community in developing generalizable longitudinal behavior modeling algorithms.},
	language = {en},
	booktitle = {Thirty-sixth {Conference} on {Neural} {Information} {Processing} {Systems} {Datasets} and {Benchmarks} {Track}},
	author = {Xu, Xuhai and Zhang, Han and Sefidgar, Yasaman and Ren, Yiyi and Liu, Xin and Seo, Woosuk and Brown, Jennifer and Kuehn, Kevin and Merrill, Mike and Nurius, Paula and Patel, Shwetak and Althoff, Tim and Morris, Margaret E and Riskin, Eve and Mankoff, Jennifer and Dey, Anind K},
	year = {2022},
	pages = {18},
	file = {Xu et al. - GLOBEM Dataset Multi-Year Datasets for Longitudin.pdf:/Users/orsonxu/Zotero/storage/3K7MCSA6/Xu et al. - GLOBEM Dataset Multi-Year Datasets for Longitudin.pdf:application/pdf},
}

@article{xu_globem_2022-1,
	title = {{GLOBEM}: {Cross}-{Dataset} {Generalization} of {Longitudinal} {Human} {Behavior} {Modeling}},
	volume = {6},
	language = {en},
	number = {4},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Xu, Xuhai and Liu, Xin and Zhang, Han and Wang, Weichen and Nepal, Subgiya and Kuehn, Kevin S and Huckins, Jeremy and Morris, Margaret E and Nurius, Paula S and Riskin, Eve A and Patel, Shwetak and Althoff, Tim and Campell, Andrew and Dey, Anind K and Mankoff, Jennifer},
	year = {2022},
	pages = {32},
	file = {Xu et al. - GLOBEM Cross-Dataset Generalization of Longitudin.pdf:/Users/orsonxu/Zotero/storage/QURA3CEN/Xu et al. - GLOBEM Cross-Dataset Generalization of Longitudin.pdf:application/pdf},
}

@inproceedings{xu_xair_2023,
	title = {{XAIR}: {A} {Framework} of {Explainable} {AI} in {Everyday} {Augmented} {Reality}},
	booktitle = {Proceedings of the {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Xu, Xuhai and Yu, Anna and Jonker, Tanya and Todi, Kashyap and Lu, Feiyu and Qian, Xun and Belo, João Marcelo Evangelista and Wang, Tianyi and Li, Michelle and Mun, Aran and Wu, Te-Yen and Shen, Junxiao and Zhang, Ting and Kokhlikyan, Narine and Wang, Fulton and Sorenson, Paul and Kim, Sophie and Benko, Hrvoje},
	year = {2023},
}

@article{adiba_orzikulova_typeout_2023,
	title = {{TypeOut}+: {Transparent}, {Just}-in-{Time}, {Adaptive} {Intervention} for {Smartphone} {Overuse} {Reduction}},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {{Adiba Orzikulova} and {Han Xiao} and {Zhipeng Li} and {ZIhan Yan} and {Yukang Yan} and {Yuanchun Shi} and {Jennifer Mankoff} and {Sung-Ju Lee} and {Anind K. Dey} and {Yuntao Wang} and {Xuhai Xu}},
	year = {2023},
}

@inproceedings{sharif_unlockedmaps_2022,
	address = {Athens Greece},
	title = {{UnlockedMaps}: {Visualizing} {Real}-{Time} {Accessibility} of {Urban} {Rail} {Transit} {Using} a {Web}-{Based} {Map}},
	isbn = {978-1-4503-9258-7},
	shorttitle = {{UnlockedMaps}},
	url = {https://dl.acm.org/doi/10.1145/3517428.3550397},
	doi = {10.1145/3517428.3550397},
	abstract = {Current web-based maps do not provide visibility into real-time elevator outages at urban rail transit stations, disenfranchising commuters (e.g., wheelchair users) who rely on functioning elevators at transit stations. In this paper, we demonstrate UnlockedMaps, an open-source and open-data web-based map that visualizes the real-time accessibility of urban rail transit stations in six North American cities, assisting users in making informed decisions regarding their commute. Specifcally, UnlockedMaps uses a map to display transit stations, prominently highlighting their real-time accessibility status (accessible with functioning elevators, accessible but experiencing at least one elevator outage, or not-accessible) and surrounding accessible restaurants and restrooms. UnlockedMaps is the frst system to collect elevator outage data from 2,336 transit stations over 23 months and make it publicly available via an API. We report on results from our pilot user studies with fve stakeholder groups: (1) people with mobility disabilities; (2) pregnant people; (3) cyclists/stroller users/commuters with heavy equipment; (4) members of disability advocacy groups; and (5) civic hackers.},
	language = {en},
	urldate = {2022-11-16},
	booktitle = {The 24th {International} {ACM} {SIGACCESS} {Conference} on {Computers} and {Accessibility}},
	publisher = {ACM},
	author = {Sharif, Ather and Ramesh, Aneesha and Nguyen, Trung-Anh and Chen, Luna and Zeng, Kent Richard and Hou, Lanqing and Xu, Xuhai},
	month = oct,
	year = {2022},
	pages = {1--7},
	file = {Sharif et al. - 2022 - UnlockedMaps Visualizing Real-Time Accessibility .pdf:/Users/orsonxu/Zotero/storage/8X7C4P2S/Sharif et al. - 2022 - UnlockedMaps Visualizing Real-Time Accessibility .pdf:application/pdf},
}

@inproceedings{zhuang_reflectrack_2021,
	address = {Virtual Event USA},
	title = {{ReflecTrack}: {Enabling} {3D} {Acoustic} {Position} {Tracking} {Using} {Commodity} {Dual}-{Microphone} {Smartphones}},
	isbn = {978-1-4503-8635-7},
	shorttitle = {{ReflecTrack}},
	url = {https://dl.acm.org/doi/10.1145/3472749.3474805},
	doi = {10.1145/3472749.3474805},
	language = {en},
	urldate = {2022-11-16},
	booktitle = {Proceedings of {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Zhuang, Yuzhou and Wang, Yuntao and Yan, Yukang and Xu, Xuhai and Shi, Yuanchun},
	month = oct,
	year = {2021},
	pages = {1050--1062},
	file = {Zhuang et al. - 2021 - ReflecTrack Enabling 3D Acoustic Position Trackin.pdf:/Users/orsonxu/Zotero/storage/QHM9E2KR/Zhuang et al. - 2021 - ReflecTrack Enabling 3D Acoustic Position Trackin.pdf:application/pdf},
}

@inproceedings{rahman_detecting_2022,
	title = {Detecting {Physiological} {Responses} {Using} {Multimodal} {Earbud} {Sensors}},
	doi = {10.1109/EMBC48229.2022.9871569},
	abstract = {Continuous stress exposure negatively impacts mental and physical well-being. Physiological arousal due to stress affects heartbeat frequency, changes breathing pattern and peripheral temperature, among several other bodily responses. Traditionally stress detection is performed by collecting signals such as electrocardiogram (ECG), respiration, and skin conductance response using uncomfortable sensors such as a chestband. In this study, we use earbuds that passively measure photoplethysmography (PPG), core body temperature, and inertial measurements. We have conducted a lab study exposing 18 participants to an evaluated speech task and additional tasks aimed at increasing stress or promoting relaxation. We simultaneously collected PPG, ECG, impedance cardiography (ICG), and blood pressure using laboratory grade equipment as reference measurements. We show that the earbud PPG sensor can reliably capture heart rate and heart rate variability. We further show that earbud signals can be used to classify the physiological responses associated with stress with 91.30\% recall, 80.52\% precision, and 85.12\% F1-score using a random forest classifier with leave-one-subject-out cross-validation. The accuracy can further be improved through multi-modal sensing. These findings demonstrate the feasibility of using earbuds for passively monitoring users' physiological responses.},
	booktitle = {2022 44th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} \& {Biology} {Society} ({EMBC})},
	author = {Rahman, Md Mahbubur and Xu, Xuhai and Nathan, Viswam and Ahmed, Tousif and Ahmed, Mohsin Yusuf and McCaffrey, Dan and Kuang, Jilong and Cowell, Trevor and Moore, Julia and Mendes, Wendy Berry and Gao, Jun Alex},
	month = jul,
	year = {2022},
	note = {ISSN: 2694-0604},
	pages = {01--05},
	file = {Rahman et al_2022_Detecting Physiological Responses Using Multimodal Earbud Sensors.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Rahman et al_2022_Detecting Physiological Responses Using Multimodal Earbud Sensors.pdf:application/pdf},
}

@article{jin_earcommand_2022,
	title = {{EarCommand}: "{Hearing}" {Your} {Silent} {Speech} {Commands} {In} {Ear}},
	volume = {6},
	issn = {2474-9567},
	shorttitle = {{EarCommand}},
	url = {https://dl.acm.org/doi/10.1145/3534613},
	doi = {10.1145/3534613},
	abstract = {Intelligent speech interfaces have been developing vastly to support the growing demands for convenient control and interaction with wearable/earable and portable devices. To avoid privacy leakage during speech interactions and strengthen the resistance to ambient noise, silent speech interfaces have been widely explored to enable people's interaction with mobile/wearable devices without audible sounds. However, most existing silent speech solutions require either restricted background illuminations or hand involvement to hold device or perform gestures. In this study, we propose a novel earphone-based, hand-free silent speech interaction approach, named EarCommand. Our technique discovers the relationship between the deformation of the ear canal and the movements of the articulator and takes advantage of this link to recognize different silent speech commands. Our system can achieve a WER (word error rate) of 10.02\% for word-level recognition and 12.33\% for sentence-level recognition, when tested in human subjects with 32 word-level commands and 25 sentence-level commands, which indicates the effectiveness of inferring silent speech commands. Moreover, EarCommand shows high reliability and robustness in a variety of configuration settings and environmental conditions. It is anticipated that EarCommand can serve as an efficient, intelligent speech interface for hand-free operation, which could significantly improve the quality and convenience of interactions.},
	language = {en},
	number = {2},
	urldate = {2022-11-16},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Jin, Yincheng and Gao, Yang and Xu, Xuhai and Choi, Seokmin and Li, Jiyang and Liu, Feng and Li, Zhengxiong and Jin, Zhanpeng},
	month = jul,
	year = {2022},
	pages = {1--28},
	file = {Jin et al. - 2022 - EarCommand Hearing Your Silent Speech Commands .pdf:/Users/orsonxu/Zotero/storage/FWSMP8LK/Jin et al. - 2022 - EarCommand Hearing Your Silent Speech Commands .pdf:application/pdf},
}

@article{li_diversense_2022,
	title = {{DiverSense}: {Maximizing} {Wi}-{Fi} {Sensing} {Range} {Leveraging} {Signal} {Diversity}},
	volume = {6},
	issn = {2474-9567},
	shorttitle = {{DiverSense}},
	url = {https://dl.acm.org/doi/10.1145/3536393},
	doi = {10.1145/3536393},
	abstract = {The ubiquity of Wi-Fi infrastructure has facilitated the development of a range of Wi-Fi based sensing applications. Wi-Fi sensing relies on weak signal reflections from the human target and thus only supports a limited sensing range, which significantly hinders the real-world deployment of the proposed sensing systems. To extend the sensing range, traditional algorithms focus on suppressing the noise introduced by the imperfect Wi-Fi hardware. This paper picks a different direction and proposes to enhance the quality of the sensing signal by fully exploiting the signal diversity provided by the Wi-Fi hardware. We propose DiverSense, a system that combines sensing signal received from all subcarriers and all antennas in the array, to fully utilize the spatial and frequency diversity. To guarantee the diversity gain after signal combining, we also propose a time-diversity based signal alignment algorithm to align the phase of the multiple received sensing signals. We implement the proposed methods in a respiration monitoring system using commodity Wi-Fi devices and evaluate the performance in diverse environments. Extensive experimental results demonstrate that DiverSense is able to accurately monitor the human respiration even when the sensing signal is under noise floor, and therefore boosts sensing range to 40 meters, which is a 3x improvement over the current state-of-the-art. DiverSense also works robustly under NLoS scenarios, e.g., DiverSense is able to accurately monitor respiration even when the human and the Wi-Fi transceivers are separated by two concrete walls with wooden doors.},
	language = {en},
	number = {2},
	urldate = {2022-11-16},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Li, Yang and Wu, Dan and Zhang, Jie and Xu, Xuhai and Xie, Yaxiong and Gu, Tao and Zhang, Daqing},
	month = jul,
	year = {2022},
	pages = {1--28},
	file = {Li et al. - 2022 - DiverSense Maximizing Wi-Fi Sensing Range Leverag.pdf:/Users/orsonxu/Zotero/storage/A8RHQERV/Li et al. - 2022 - DiverSense Maximizing Wi-Fi Sensing Range Leverag.pdf:application/pdf},
}

@article{confalonieri2021historical,
  title={A historical perspective of explainable Artificial Intelligence},
  author={Confalonieri, Roberto and Coba, Ludovik and Wagner, Benedikt and Besold, Tarek R},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  volume={11},
  number={1},
  pages={e1391},
  year={2021},
  publisher={Wiley Online Library}
}

@article{hess1964pupil,
  title={Pupil size in relation to mental activity during simple problem-solving},
  author={Hess, Eckhard H and Polt, James M},
  journal={Science},
  volume={143},
  number={3611},
  pages={1190--1192},
  year={1964},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{chong2018connecting,
  title={Connecting gaze, scene, and attention: Generalized attention estimation via joint modeling of gaze and scene saliency},
  author={Chong, Eunji and Ruiz, Nataniel and Wang, Yongxin and Zhang, Yun and Rozga, Agata and Rehg, James M},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={383--398},
  year={2018}
}

@inproceedings{stappen2020x,
  title={X-aware: Context-aware human-environment attention fusion for driver gaze prediction in the wild},
  author={Stappen, Lukas and Rizos, Georgios and Schuller, Bj{\"o}rn},
  booktitle={Proceedings of the 2020 International Conference on Multimodal Interaction},
  pages={858--867},
  year={2020}
}

@inproceedings{huang2018predicting,
  title={Predicting gaze in egocentric video by learning task-dependent attention transition},
  author={Huang, Yifei and Cai, Minjie and Li, Zhenqiang and Sato, Yoichi},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={754--769},
  year={2018}
}

@inproceedings{fathi2011understanding,
  title={Understanding egocentric activities},
  author={Fathi, Alireza and Farhadi, Ali and Rehg, James M},
  booktitle={2011 international conference on computer vision},
  pages={407--414},
  year={2011},
  organization={IEEE}
}

@incollection{schroder2017deep,
  title={Deep learning for action recognition in augmented reality assistance systems},
  author={Schr{\"o}der, Matthias and Ritter, Helge},
  booktitle={ACM SIGGRAPH 2017 Posters},
  pages={1--2},
  year={2017}
}

@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}

@inproceedings{redmon2016you,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={779--788},
  year={2016}
}

@inproceedings{singh2016first,
  title={First person action recognition using deep learned descriptors},
  author={Singh, Suriya and Arora, Chetan and Jawahar, CV},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2620--2628},
  year={2016}
}

@article{liu2020deep,
  title={Deep learning for generic object detection: A survey},
  author={Liu, Li and Ouyang, Wanli and Wang, Xiaogang and Fieguth, Paul and Chen, Jie and Liu, Xinwang and Pietik{\"a}inen, Matti},
  journal={International journal of computer vision},
  volume={128},
  number={2},
  pages={261--318},
  year={2020},
  publisher={Springer}
}

@article{pan2019content,
  title={Content-based visual summarization for image collections},
  author={Pan, Xingjia and Tang, Fan and Dong, Weiming and Ma, Chongyang and Meng, Yiping and Huang, Feiyue and Lee, Tong-Yee and Xu, Changsheng},
  journal={IEEE transactions on visualization and computer graphics},
  volume={27},
  number={4},
  pages={2298--2312},
  year={2019},
  publisher={IEEE}
}

@article{bolanos2016toward,
  title={Toward storytelling from visual lifelogging: An overview},
  author={Bolanos, Marc and Dimiccoli, Mariella and Radeva, Petia},
  journal={IEEE Transactions on Human-Machine Systems},
  volume={47},
  number={1},
  pages={77--90},
  year={2016},
  publisher={IEEE}
}

@inproceedings{miech2020end,
  title={End-to-end learning of visual representations from uncurated instructional videos},
  author={Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9879--9889},
  year={2020}
}

@article{elliott2017living,
  title={Living systematic review: 1. Introduction—the why, what, when, and how},
  author={Elliott, Julian H and Synnot, Anneliese and Turner, Tari and Simmonds, Mark and Akl, Elie A and McDonald, Steve and Salanti, Georgia and Meerpohl, Joerg and MacLehose, Harriet and Hilton, John and others},
  journal={Journal of clinical epidemiology},
  volume={91},
  pages={23--30},
  year={2017},
  publisher={Elsevier}
}

@inproceedings{kapoor2015just,
  title={Just in time recommendations: Modeling the dynamics of boredom in activity streams},
  author={Kapoor, Komal and Subbian, Karthik and Srivastava, Jaideep and Schrater, Paul},
  booktitle={Proceedings of the eighth ACM international conference on web search and data mining},
  pages={233--242},
  year={2015}
}

@inproceedings{mehrotra2019jointly,
  title={Jointly leveraging intent and interaction signals to predict user satisfaction with slate recommendations},
  author={Mehrotra, Rishabh and Lalmas, Mounia and Kenney, Doug and Lim-Meng, Thomas and Hashemian, Golli},
  booktitle={The World Wide Web Conference},
  pages={1256--1267},
  year={2019}
}

@inproceedings{bhattacharya2017intent,
  title={Intent-aware contextual recommendation system},
  author={Bhattacharya, Biswarup and Burhanuddin, Iftikhar and Sancheti, Abhilasha and Satya, Kushal},
  booktitle={2017 IEEE International Conference on Data Mining Workshops (ICDMW)},
  pages={1--8},
  year={2017},
  organization={IEEE}
}

@inproceedings{stumpf2016explanations,
  title={Explanations considered harmful? user interactions with machine learning systems},
  author={Stumpf, Simone and Bussone, Adrian and O’sullivan, Dympna},
  booktitle={Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems},
  year={2016}
}

@article{robbins2019misdirected,
  title={A misdirected principle with a catch: explicability for AI},
  author={Robbins, Scott},
  journal={Minds and Machines},
  volume={29},
  number={4},
  pages={495--514},
  year={2019},
  publisher={Springer}
}

@inproceedings{chazette2019end,
  title={Do end-users want explanations? Analyzing the role of explainability as an emerging aspect of non-functional requirements},
  author={Chazette, Larissa and Karras, Oliver and Schneider, Kurt},
  booktitle={2019 IEEE 27th International Requirements Engineering Conference (RE)},
  pages={223--233},
  year={2019},
  organization={IEEE}
}

@inproceedings{wagner2020regulating,
  title={Regulating transparency? Facebook, twitter and the German network enforcement act},
  author={Wagner, Ben and Rozgonyi, Krisztina and Sekwenz, Marie-Therese and Cobbe, Jennifer and Singh, Jatinder},
  booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  pages={261--271},
  year={2020}
}


@article{mahbooba2021explainable,
  title={Explainable artificial intelligence (XAI) to enhance trust management in intrusion detection systems using decision tree model},
  author={Mahbooba, Basim and Timilsina, Mohan and Sahal, Radhya and Serrano, Martin},
  journal={Complexity},
  volume={2021},
  year={2021},
  publisher={Hindawi}
}

@article{kenny2021explaining,
  title={Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies},
  author={Kenny, Eoin M and Ford, Courtney and Quinn, Molly and Keane, Mark T},
  journal={Artificial Intelligence},
  volume={294},
  pages={103459},
  year={2021},
  publisher={Elsevier}
}

@article{da2020recommendation,
  title={Recommendation system based on deep learning methods: a systematic review and new directions},
  author={Da’u, Aminu and Salim, Naomie},
  journal={Artificial Intelligence Review},
  volume={53},
  number={4},
  pages={2709--2748},
  year={2020},
  publisher={Springer}
}

@inproceedings{ma2020temporal,
  title={Temporal-contextual recommendation in real-time},
  author={Ma, Yifei and Narayanaswamy, Balakrishnan and Lin, Haibin and Ding, Hao},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2291--2299},
  year={2020}
}

@inproceedings{manotumruksa2018contextual,
  title={A contextual attention recurrent architecture for context-aware venue recommendation},
  author={Manotumruksa, Jarana and Macdonald, Craig and Ounis, Iadh},
  booktitle={The 41st international ACM SIGIR conference on research \& development in information retrieval},
  pages={555--564},
  year={2018}
}

@article{qian2013personalized,
  title={Personalized recommendation combining user interest and social circle},
  author={Qian, Xueming and Feng, He and Zhao, Guoshuai and Mei, Tao},
  journal={IEEE transactions on knowledge and data engineering},
  volume={26},
  number={7},
  pages={1763--1777},
  year={2013},
  publisher={IEEE}
}

@article{cui2020personalized,
  title={Personalized recommendation system based on collaborative filtering for IoT scenarios},
  author={Cui, Zhihua and Xu, Xianghua and Fei, XUE and Cai, Xingjuan and Cao, Yang and Zhang, Wensheng and Chen, Jinjun},
  journal={IEEE Transactions on Services Computing},
  volume={13},
  number={4},
  pages={685--695},
  year={2020},
  publisher={IEEE}
}

@inproceedings{lakkaraju2019faithful,
  title={Faithful and customizable explanations of black box models},
  author={Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Leskovec, Jure},
  booktitle={Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={131--138},
  year={2019}
}

@article{felzmann2019robots,
  title={Robots and transparency: The multiple dimensions of transparency in the context of robot technologies},
  author={Felzmann, Heike and Fosch-Villaronga, Eduard and Lutz, Christoph and Tamo-Larrieux, Aurelia},
  journal={IEEE Robotics \& Automation Magazine},
  volume={26},
  number={2},
  pages={71--78},
  year={2019},
  publisher={IEEE}
}

@inproceedings{miller2014delegation,
  title={Delegation and transparency: Coordinating interactions so information exchange is no surprise},
  author={Miller, Christopher A},
  booktitle={International Conference on Virtual, Augmented and Mixed Reality},
  pages={191--202},
  year={2014},
  organization={Springer}
}

@inproceedings{zhao2007earpod,
  title={Earpod: eyes-free menu selection using touch input and reactive audio feedback},
  author={Zhao, Shengdong and Dragicevic, Pierre and Chignell, Mark and Balakrishnan, Ravin and Baudisch, Patrick},
  booktitle={Proceedings of the SIGCHI conference on Human factors in computing systems},
  pages={1395--1404},
  year={2007}
}

@inproceedings{fan2021just,
  title={Just Speak It: Minimize Cognitive Load for Eyes-Free Text Editing with a Smart Voice Assistant},
  author={Fan, Jiayue and Xu, Chenning and Yu, Chun and Shi, Yuanchun},
  booktitle={The 34th Annual ACM Symposium on User Interface Software and Technology},
  pages={910--921},
  year={2021}
}

@inproceedings{chen2017multimodal,
  title={Multimodal interaction in augmented reality},
  author={Chen, Zhaorui and Li, Jinzhu and Hua, Yifan and Shen, Rui and Basu, Anup},
  booktitle={2017 IEEE international conference on systems, man, and cybernetics (SMC)},
  pages={206--209},
  year={2017},
  organization={IEEE}
}

@article{nizam2018review,
  title={A review of multimodal interaction technique in augmented reality environment},
  author={Nizam, SS Muhammad and Abidin, Rimaniza Zainal and Hashim, Nurhazarifah Che and Lam, Meng Chun and Arshad, Haslina and Majid, NAA},
  journal={Int. J. Adv. Sci. Eng. Inf. Technol},
  volume={8},
  number={4-2},
  pages={1460},
  year={2018}
}

@inproceedings{bonanni2005attention,
  title={Attention-based design of augmented reality interfaces},
  author={Bonanni, Leonardo and Lee, Chia-Hsun and Selker, Ted},
  booktitle={CHI'05 extended abstracts on Human factors in computing systems},
  pages={1228--1231},
  year={2005}
}

@book{laviola20173d,
  title={3D user interfaces: theory and practice},
  author={LaViola Jr, Joseph J and Kruijff, Ernst and McMahan, Ryan P and Bowman, Doug and Poupyrev, Ivan P},
  year={2017},
  publisher={Addison-Wesley Professional}
}

@inproceedings{dai2017scannet,
  title={Scannet: Richly-annotated 3d reconstructions of indoor scenes},
  author={Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5828--5839},
  year={2017}
}

@inproceedings{diverdi2004level,
  title={Level of detail interfaces},
  author={DiVerdi, Stephen and Hollerer, Tobias and Schreyer, Richard},
  booktitle={Third IEEE and ACM International Symposium on Mixed and Augmented Reality},
  pages={300--301},
  year={2004},
  organization={IEEE}
}

@article{esteva2017dermatologist,
  title={Dermatologist-level classification of skin cancer with deep neural networks},
  author={Esteva, Andre and Kuprel, Brett and Novoa, Roberto A and Ko, Justin and Swetter, Susan M and Blau, Helen M and Thrun, Sebastian},
  journal={nature},
  volume={542},
  number={7639},
  pages={115--118},
  year={2017},
  publisher={Nature Publishing Group}
}

@inproceedings{coppers2018intellingo,
  title={Intellingo: An intelligible translation environment},
  author={Coppers, Sven and Van den Bergh, Jan and Luyten, Kris and Coninx, Karin and Van der Lek-Ciudin, Iulianna and Vanallemeersch, Tom and Vandeghinste, Vincent},
  booktitle={Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2018}
}

@article{qoc_1999,
author = {MacLean, Allan and Young, Richard M. and Bellotti, Victoria M. E. and Moran, Thomas P.},
title = {Questions, Options, and Criteria: Elements of Design Space Analysis},
year = {1991},
issue_date = {September 1991},
publisher = {L. Erlbaum Associates Inc.},
address = {USA},
volume = {6},
number = {3},
issn = {0737-0024},
url = {https://doi.org/10.1207/s15327051hci0603%264_2},
doi = {10.1207/s15327051hci0603%264_2},
abstract = {Design Space Analysis is an approach to representing design rationale. It uses a semiformal notation, called QOC (Questions, Options, and Criteria), to represent the design space around an artifact. The main constituents of QOC are Questions identifying key design issues, Options providing possible answers to the Questions, and Criteria for assessing and comparing the Options. Design Space Analysis also takes account of justifications for the design (and possible alternative designs) that reflect considerations such as consistency, models and analogies, and relevant data and theory. A Design Space Analysis does not produce a record of the design process but is instead a coproduct of design and has to be constructed alongside the artifact itself. Our work is motivated by the notion that a Design Space Analysis will repay the investment in its creation by supporting both the original process of design and subsequent work on redesign and reuse by (a) providing an explicit representation to aid reasoning about the design and about the consequences of changes to it and (b) serving as a vehicle for communication, for example, among members of the design team or among the original designers and later maintainers of a system. Our work to date emphasises the nature of the QOC representation over processes for creating it, so these claims serve as goals rather than objectives we have achieved. This article describes the elements of Design Space Analysis and illustrates them by reference to analyses of existing designs and to studies of the concepts and arguments used by designers during design discussions.},
journal = {Hum.-Comput. Interact.},
month = {sep},
pages = {201–250},
numpages = {50}
}

@article{arya2019one,
  title={One explanation does not fit all: A toolkit and taxonomy of ai explainability techniques},
  author={Arya, Vijay and Bellamy, Rachel KE and Chen, Pin-Yu and Dhurandhar, Amit and Hind, Michael and Hoffman, Samuel C and Houde, Stephanie and Liao, Q Vera and Luss, Ronny and Mojsilovi{\'c}, Aleksandra and others},
  journal={arXiv preprint arXiv:1909.03012},
  year={2019}
}

@misc{meta_ai,
title={AI system cards},
url={https://ai.facebook.com/tools/system-cards/},
journal={Meta AI},
year = {2022}
}

@misc{google_cloud_model_cards,
title={Google Cloud Model Cards},
url={https://modelcards.withgoogle.com/},
journal={Google Cloud},
publisher={Google},
year = {2022}
} 

@misc{gdpr_2019,
title={General Data Protection Regulation (GDPR)},
url={https://gdpr-info.eu/},
journal={Official Legal Text},
year={2019},
month={Sep}
} 

@article{gunning2019darpa,
  title={DARPA’s explainable artificial intelligence (XAI) program},
  author={Gunning, David and Aha, David},
  journal={AI magazine},
  volume={40},
  number={2},
  pages={44--58},
  year={2019}
}

@article{gunning2017explainable,
  title={Explainable artificial intelligence (xai)},
  author={Gunning, David},
  journal={Defense advanced research projects agency (DARPA), nd Web},
  volume={2},
  number={2},
  pages={1},
  year={2017}
}

@article{lipton2018mythos,
  title={The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery.},
  author={Lipton, Zachary C},
  journal={Queue},
  volume={16},
  number={3},
  pages={31--57},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{samek2017explainable,
  title={Explainable artificial intelligence: Understanding, visualizing and interpreting deep learning models},
  author={Samek, Wojciech and Wiegand, Thomas and M{\"u}ller, Klaus-Robert},
  journal={arXiv preprint arXiv:1708.08296},
  year={2017}
}

@article{yuan2019adversarial,
  title={Adversarial examples: Attacks and defenses for deep learning},
  author={Yuan, Xiaoyong and He, Pan and Zhu, Qile and Li, Xiaolin},
  journal={IEEE transactions on neural networks and learning systems},
  volume={30},
  number={9},
  pages={2805--2824},
  year={2019},
  publisher={IEEE}
}

@article{louizos2017causal,
  title={Causal effect inference with deep latent-variable models},
  author={Louizos, Christos and Shalit, Uri and Mooij, Joris M and Sontag, David and Zemel, Richard and Welling, Max},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{pope2019explainability,
  title={Explainability methods for graph convolutional neural networks},
  author={Pope, Phillip E and Kolouri, Soheil and Rostami, Mohammad and Martin, Charles E and Hoffmann, Heiko},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10772--10781},
  year={2019}
}

@inproceedings{belle2017logic,
  title={Logic meets Probability: Towards Explainable AI Systems for Uncertain Worlds.},
  author={Belle, Vaishak},
  booktitle={IJCAI},
  pages={5116--5120},
  year={2017}
}

@inproceedings{dovsilovic2018explainable,
  title={Explainable artificial intelligence: A survey},
  author={Do{\v{s}}ilovi{\'c}, Filip Karlo and Br{\v{c}}i{\'c}, Mario and Hlupi{\'c}, Nikica},
  booktitle={2018 41st International convention on information and communication technology, electronics and microelectronics (MIPRO)},
  pages={0210--0215},
  year={2018},
  organization={IEEE}
}

@inproceedings{chander2018working,
  title={Working with beliefs: AI transparency in the enterprise},
  author={Chander, Ajay and Srinivasan, Ramya and Chelian, Suhas and Wang, Jun and Uchino, Kanji},
  booktitle={IUI Workshops},
  year={2018}
}

@article{tickle1998truth,
  title={The truth will come to light: Directions and challenges in extracting the knowledge embedded within trained artificial neural networks},
  author={Tickle, Alan B and Andrews, Robert and Golea, Mostefa and Diederich, Joachim},
  journal={IEEE Transactions on Neural Networks},
  volume={9},
  number={6},
  pages={1057--1068},
  year={1998},
  publisher={IEEE}
}

@article{edwards2017slave,
  title={Slave to the algorithm: Why a right to an explanation is probably not the remedy you are looking for},
  author={Edwards, Lilian and Veale, Michael},
  journal={Duke L. \& Tech. Rev.},
  volume={16},
  pages={18},
  year={2017},
  publisher={HeinOnline}
}

@article{doshi2017towards,
  title={Towards a rigorous science of interpretable machine learning},
  author={Doshi-Velez, Finale and Kim, Been},
  journal={arXiv preprint arXiv:1702.08608},
  year={2017}
}

@inproceedings{holliday2016user,
  title={User trust in intelligent systems: A journey over time},
  author={Holliday, Daniel and Wilson, Stephanie and Stumpf, Simone},
  booktitle={Proceedings of the 21st international conference on intelligent user interfaces},
  pages={164--168},
  year={2016}
}

@inproceedings{pu2006trust,
  title={Trust building with explanation interfaces},
  author={Pu, Pearl and Chen, Li},
  booktitle={Proceedings of the 11th international conference on Intelligent user interfaces},
  pages={93--100},
  year={2006}
}

@article{huysmans2011empirical,
  title={An empirical evaluation of the comprehensibility of decision table, tree and rule based predictive models},
  author={Huysmans, Johan and Dejaeger, Karel and Mues, Christophe and Vanthienen, Jan and Baesens, Bart},
  journal={Decision Support Systems},
  volume={51},
  number={1},
  pages={141--154},
  year={2011},
  publisher={Elsevier}
}

@article{burrell2016machine,
  title={How the machine ‘thinks’: Understanding opacity in machine learning algorithms},
  author={Burrell, Jenna},
  journal={Big data \& society},
  volume={3},
  number={1},
  pages={2053951715622512},
  year={2016},
  publisher={Sage Publications Sage UK: London, England}
}

@misc{google_map_match_rate_2018,
title={Explore and eat your way around town with google maps}, url={https://www.blog.google/products/maps/explore-around-town-google-maps/}, journal={Google},
publisher={Google}, author={Lin, Sophia}, year={2018}, month={May}} 

@misc{google_glass,
title={Glass Glass},
url={https://www.google.com/glass/start/},
journal={Google},
publisher={Google},
year = {2022},
} 
 
@misc{microsoft_hololens,
title={Microsoft hololens: Mixed Reality Technology for Business}, url={https://www.microsoft.com/en-us/hololens}, journal={Microsoft HoloLens}, publisher={Microsoft},
year = {2022}
}

@misc{snap_spectacle,
 title={Spectacles by snap inc. - the next generation of spectacles}, url={https://www.spectacles.com/},
 journal={Spectacles by Snap Inc. The Next Generation of Spectacles},
 year = {2022}} 
 
@misc{magic_leap,
title={Enterprise augmented reality (AR) platform designed for business: Magic leap}, url={https://www.magicleap.com/en-us/}, journal={Enterprise augmented reality (AR) platform designed for business | Magic Leap},
year={2022}} 

@incollection{adomavicius2011context,
  title={Context-aware recommender systems},
  author={Adomavicius, Gediminas and Tuzhilin, Alexander},
  booktitle={Recommender systems handbook},
  pages={217--253},
  year={2011},
  publisher={Springer}
}

@inproceedings{admoni2016predicting,
  title={Predicting user intent through eye gaze for shared autonomy},
  author={Admoni, Henny and Srinivasa, Siddhartha},
  booktitle={2016 AAAI Fall Symposium Series},
  year={2016}
}

@inproceedings{xu2019explainable,
  title={Explainable AI: A brief survey on history, research areas, approaches and challenges},
  author={Xu, Feiyu and Uszkoreit, Hans and Du, Yangzhou and Fan, Wei and Zhao, Dongyan and Zhu, Jun},
  booktitle={CCF international conference on natural language processing and Chinese computing},
  pages={563--574},
  year={2019},
  organization={Springer}
}

@techreport{scott1977explanation,
  title={Explanation capabilities of production-based consultation systems},
  author={Scott, A Carlisle and Clancey, William J and Davis, Randall and Shortliffe, Edward H},
  year={1977},
  institution={STANFORD UNIV CA DEPT OF COMPUTER SCIENCE}
}

@incollection{swartout1985explaining,
  title={Explaining and justifying expert consulting programs},
  author={Swartout, William R},
  booktitle={Computer-assisted medical decision making},
  pages={254--271},
  year={1985},
  publisher={Springer}
}


@article{gregor1999explanations,
  title={Explanations from intelligent systems: Theoretical foundations and implications for practice},
  author={Gregor, Shirley and Benbasat, Izak},
  journal={MIS quarterly},
  pages={497--530},
  year={1999},
  publisher={JSTOR}
}

@inproceedings{poulin2006visual,
  title={Visual explanation of evidence with additive classifiers},
  author={Poulin, Brett and Eisner, Roman and Szafron, Duane and Lu, Paul and Greiner, Russell and Wishart, David S and Fyshe, Alona and Pearcy, Brandon and MacDonell, Cam and Anvik, John},
  booktitle={Proceedings of the National Conference on Artificial Intelligence},
  volume={21},
  number={2},
  pages={1822},
  year={2006},
  organization={Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999}
}

@article{preece2018stakeholders,
  title={Stakeholders in explainable AI},
  author={Preece, Alun and Harborne, Dan and Braines, Dave and Tomsett, Richard and Chakraborty, Supriyo},
  journal={arXiv preprint arXiv:1810.00184},
  year={2018}
}

@article{letham2015interpretable,
  title={Interpretable classifiers using rules and bayesian analysis: Building a better stroke prediction model},
  author={Letham, Benjamin and Rudin, Cynthia and McCormick, Tyler H and Madigan, David},
  journal={The Annals of Applied Statistics},
  volume={9},
  number={3},
  pages={1350--1371},
  year={2015},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{caruana2015intelligible,
  title={Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission},
  author={Caruana, Rich and Lou, Yin and Gehrke, Johannes and Koch, Paul and Sturm, Marc and Elhadad, Noemie},
  booktitle={Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1721--1730},
  year={2015}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@article{taylor2021artificial,
  title={Artificial cognition: How experimental psychology can help generate explainable artificial intelligence},
  author={Taylor, J Eric T and Taylor, Graham W},
  journal={Psychonomic Bulletin \& Review},
  volume={28},
  number={2},
  pages={454--475},
  year={2021},
  publisher={Springer}
}

@article{yarkoni2017choosing,
  title={Choosing prediction over explanation in psychology: Lessons from machine learning},
  author={Yarkoni, Tal and Westfall, Jacob},
  journal={Perspectives on Psychological Science},
  volume={12},
  number={6},
  pages={1100--1122},
  year={2017},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{hoffman2018metrics,
  title={Metrics for explainable AI: Challenges and prospects},
  author={Hoffman, Robert R and Mueller, Shane T and Klein, Gary and Litman, Jordan},
  journal={arXiv preprint arXiv:1812.04608},
  year={2018}
}

@article{miller2019explanation,
  title={Explanation in artificial intelligence: Insights from the social sciences},
  author={Miller, Tim},
  journal={Artificial intelligence},
  volume={267},
  pages={1--38},
  year={2019},
  publisher={Elsevier}
}

@article{lepri2018fair,
  title={Fair, transparent, and accountable algorithmic decision-making processes},
  author={Lepri, Bruno and Oliver, Nuria and Letouz{\'e}, Emmanuel and Pentland, Alex and Vinck, Patrick},
  journal={Philosophy \& Technology},
  volume={31},
  number={4},
  pages={611--627},
  year={2018},
  publisher={Springer}
}

@article{amershi2014power,
  title={Power to the people: The role of humans in interactive machine learning},
  author={Amershi, Saleema and Cakmak, Maya and Knox, William Bradley and Kulesza, Todd},
  journal={Ai Magazine},
  volume={35},
  number={4},
  pages={105--120},
  year={2014}
}

@article{vavra2017recent,
  title={Recent development of augmented reality in surgery: a review},
  author={V{\'a}vra, Petr and Roman, Jan and Zon{\v{c}}a, Pavel and Ihn{\'a}t, Peter and N{\v{e}}mec, Martin and Kumar, Jayant and Habib, Nagy and El-Gendi, Ahmed},
  journal={Journal of healthcare engineering},
  volume={2017},
  year={2017},
  publisher={Hindawi}
}

@article{nee2012augmented,
  title={Augmented reality applications in design and manufacturing},
  author={Nee, Andrew YC and Ong, SK and Chryssolouris, George and Mourtzis, Dimitris},
  journal={CIRP annals},
  volume={61},
  number={2},
  pages={657--679},
  year={2012},
  publisher={Elsevier}
}

@article{cipresso2018past,
  title={The past, present, and future of virtual and augmented reality research: a network and cluster analysis of the literature},
  author={Cipresso, Pietro and Giglioli, Irene Alice Chicchi and Raya, Mariano Alca{\~n}iz and Riva, Giuseppe},
  journal={Frontiers in psychology},
  pages={2086},
  year={2018},
  publisher={Frontiers}
}

@article{rese2017augmented,
  title={How augmented reality apps are accepted by consumers: A comparative analysis using scales and opinions},
  author={Rese, Alexandra and Baier, Daniel and Geyer-Schulz, Andreas and Schreiber, Stefanie},
  journal={Technological Forecasting and Social Change},
  volume={124},
  pages={306--319},
  year={2017},
  publisher={Elsevier}
}

@article{graesser1992mechanisms,
  title={Mechanisms that generate questions},
  author={Graesser, Arthur C and Person, Natalie and Huber, John},
  journal={Questions and information systems},
  volume={2},
  pages={167--187},
  year={1992}
}

@inproceedings{herlocker2000explaining,
  title={Explaining collaborative filtering recommendations},
  author={Herlocker, Jonathan L and Konstan, Joseph A and Riedl, John},
  booktitle={Proceedings of the 2000 ACM conference on Computer supported cooperative work},
  pages={241--250},
  year={2000}
}

@article{amini2022discovering,
  title={Discovering injury severity risk factors in automobile crashes: A hybrid explainable AI framework for decision support},
  author={Amini, Mostafa and Bagheri, Ali and Delen, Dursun},
  journal={Reliability Engineering \& System Safety},
  volume={226},
  pages={108720},
  year={2022},
  publisher={Elsevier}
}

@article{damen2022rescaling,
  title={Rescaling egocentric vision: collection, pipeline and challenges for epic-kitchens-100},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Furnari, Antonino and Kazakos, Evangelos and Ma, Jian and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  journal={International Journal of Computer Vision},
  volume={130},
  number={1},
  pages={33--55},
  year={2022},
  publisher={Springer}
}

@article{samadiani2019review,
  title={A review on automatic facial expression recognition systems assisted by multimodal sensor data},
  author={Samadiani, Najmeh and Huang, Guangyan and Cai, Borui and Luo, Wei and Chi, Chi-Hung and Xiang, Yong and He, Jing},
  journal={Sensors},
  volume={19},
  number={8},
  pages={1863},
  year={2019},
  publisher={MDPI}
}

@INPROCEEDINGS{lu_glanceable_2021,
  author={Lu, Feiyu},
  booktitle={2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={Glanceable AR: Towards an Always-on Augmented Reality Future}, 
  year={2021},
  volume={},
  number={},
  pages={717-718},
  doi={10.1109/VRW52623.2021.00241}}
  
  
@inproceedings{feiner1993windows,
  title={Windows on the world: 2D windows for 3D augmented reality},
  author={Feiner, Steven and MacIntyre, Blair and Haupt, Marcus and Solomon, Eliot},
  booktitle={Proceedings of the 6th annual ACM symposium on User interface software and technology},
  pages={145--155},
  year={1993}
}

@inproceedings{reitmayr2001mobile,
  title={Mobile collaborative augmented reality},
  author={Reitmayr, Gerhard and Schmalstieg, Dieter},
  booktitle={Proceedings IEEE and ACM International Symposium on Augmented Reality},
  pages={114--123},
  year={2001},
  organization={IEEE}
}

@article{lee1992trust,
  title={Trust, control strategies and allocation of function in human-machine systems},
  author={Lee, John and Moray, Neville},
  journal={Ergonomics},
  volume={35},
  number={10},
  pages={1243--1270},
  year={1992},
  publisher={Taylor \& Francis}
}

@article{buchner2022impact,
  title={The impact of augmented reality on cognitive load and performance: A systematic review},
  author={Buchner, Josef and Buntins, Katja and Kerres, Michael},
  journal={Journal of Computer Assisted Learning},
  volume={38},
  number={1},
  pages={285--303},
  year={2022},
  publisher={Wiley Online Library}
}

@inproceedings{ribeiro2018anchors,
  title={Anchors: High-precision model-agnostic explanations},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{lombrozo2009explanation,
  title={Explanation and categorization: How “why?” informs “what?”},
  author={Lombrozo, Tania},
  journal={Cognition},
  volume={110},
  number={2},
  pages={248--253},
  year={2009},
  publisher={Elsevier}
}

@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}

@inproceedings{lakkaraju2016interpretable,
  title={Interpretable decision sets: A joint framework for description and prediction},
  author={Lakkaraju, Himabindu and Bach, Stephen H and Leskovec, Jure},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1675--1684},
  year={2016}
}

@article{schoonderwoerd2021human,
  title={Human-centered XAI: Developing design patterns for explanations of clinical decision support systems},
  author={Schoonderwoerd, Tjeerd AJ and Jorritsma, Wiard and Neerincx, Mark A and Van Den Bosch, Karel},
  journal={International Journal of Human-Computer Studies},
  volume={154},
  pages={102684},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{cai2019human,
  title={Human-centered tools for coping with imperfect algorithms during medical decision-making},
  author={Cai, Carrie J and Reif, Emily and Hegde, Narayan and Hipp, Jason and Kim, Been and Smilkov, Daniel and Wattenberg, Martin and Viegas, Fernanda and Corrado, Greg S and Stumpe, Martin C and others},
  booktitle={Proceedings of the 2019 chi conference on human factors in computing systems},
  pages={1--14},
  year={2019}
}

@inproceedings{keane2019case,
  title={How case-based reasoning explains neural networks: A theoretical analysis of XAI using post-hoc explanation-by-example from a survey of ANN-CBR twin-systems},
  author={Keane, Mark T and Kenny, Eoin M},
  booktitle={International Conference on Case-Based Reasoning},
  pages={155--171},
  year={2019},
  organization={Springer}
}

@inproceedings{cai2019effects,
  title={The effects of example-based explanations in a machine learning interface},
  author={Cai, Carrie J and Jongejan, Jonas and Holbrook, Jess},
  booktitle={Proceedings of the 24th international conference on intelligent user interfaces},
  pages={258--262},
  year={2019}
}

@book{molnar2020interpretable,
  title={Interpretable machine learning},
  author={Molnar, Christoph},
  year={2020},
  publisher={Lulu. com}
}

@inproceedings{lim2019these,
  title={Why these explanations? Selecting intelligibility types for explanation goals.},
  author={Lim, Brian Y and Yang, Qian and Abdul, Ashraf M and Wang, Danding},
  booktitle={IUI Workshops},
  year={2019}
}

@article{liao2021human,
  title={Human-centered explainable ai (xai): From algorithms to user experiences},
  author={Liao, Q Vera and Varshney, Kush R},
  journal={arXiv preprint arXiv:2110.10790},
  year={2021}
}

@misc{dalex,
 title={Model interpretability with DALEX}, url={http://uc-r.github.io/dalex},
 journal={Model Interpretability with DALEX · UC Business Analytics R Programming Guide},
 year={2022}} 
 
@misc{h2oai,title={H2O driverless AI}, url={https://h2o.ai/platform/ai-cloud/make/h2o-driverless-ai/},
journal={H2O Driverless AI | H2O.ai}, year={2022}} 

@article{baumeister2017cognitive,
  title={Cognitive cost of using augmented reality displays},
  author={Baumeister, James and Ssin, Seung Youb and ElSayed, Neven AM and Dorrian, Jillian and Webb, David P and Walsh, James A and Simon, Timothy M and Irlitti, Andrew and Smith, Ross T and Kohler, Mark and others},
  journal={IEEE transactions on visualization and computer graphics},
  volume={23},
  number={11},
  pages={2378--2388},
  year={2017},
  publisher={IEEE}
}

@article{schneider2019personalized,
  title={Personalized explanation in machine learning: A conceptualization},
  author={Schneider, Johanes and Handali, Joshua},
  journal={arXiv preprint arXiv:1901.00770},
  year={2019}
}

@inproceedings{kouki2019personalized,
  title={Personalized explanations for hybrid recommender systems},
  author={Kouki, Pigi and Schaffer, James and Pujara, Jay and O'Donovan, John and Getoor, Lise},
  booktitle={Proceedings of the 24th International Conference on Intelligent User Interfaces},
  pages={379--390},
  year={2019}
}

@inproceedings{frauenberger2007survey,
  title={A survey on common practice in designing audio in the user interface},
  author={Frauenberger, Christopher and Stockman, Tony and Bourguet, Marie-Luce},
  booktitle={Proceedings of HCI 2007 The 21st British HCI Group Annual Conference University of Lancaster, UK 21},
  pages={1--9},
  year={2007}
}

@article{frauenberger2009auditory,
  title={Auditory display design—an investigation of a design pattern approach},
  author={Frauenberger, Christopher and Stockman, Tony},
  journal={International Journal of Human-Computer Studies},
  volume={67},
  number={11},
  pages={907--922},
  year={2009},
  publisher={Elsevier}
}

@inproceedings{kern2009design,
  title={Design space for driver-based automotive user interfaces},
  author={Kern, Dagmar and Schmidt, Albrecht},
  booktitle={Proceedings of the 1st International Conference on Automotive User Interfaces and Interactive Vehicular Applications},
  pages={3--10},
  year={2009}
}

@article{simonyan2013deep,
  title={Deep inside convolutional networks: Visualising image classification models and saliency maps},
  author={Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1312.6034},
  year={2013}
}

@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={European conference on computer vision},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@inproceedings{myers2006answering,
  title={Answering why and why not questions in user interfaces},
  author={Myers, Brad A and Weitzman, David A and Ko, Amy J and Chau, Duen H},
  booktitle={Proceedings of the SIGCHI conference on Human Factors in computing systems},
  pages={397--406},
  year={2006}
}


@inproceedings{evangelista2021xrgonomics,
  title={Xrgonomics: Facilitating the creation of ergonomic 3d interfaces},
  author={Evangelista Belo, Jo{\~a}o Marcelo and Feit, Anna Maria and Feuchtner, Tiare and Gr{\o}nb{\ae}k, Kaj},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--11},
  year={2021}
}

@inproceedings{zagermann2018studying,
  title={Studying eye movements as a basis for measuring cognitive load},
  author={Zagermann, Johannes and Pfeil, Ulrike and Reiterer, Harald},
  booktitle={Extended Abstracts of the 2018 CHI conference on human factors in computing systems},
  pages={1--6},
  year={2018}
}

@article{joseph2020potential,
  title={Potential eye tracking metrics and indicators to measure cognitive load in human-computer interaction research},
  author={Joseph, Antony William and Murugesh, Ramaswamy},
  journal={J. Sci. Res},
  volume={64},
  number={1},
  pages={168--175},
  year={2020}
}

@incollection{gjoreski2021head,
  title={Head-ar: Human activity recognition with head-mounted imu using weighted ensemble learning},
  author={Gjoreski, Hristijan and Kiprijanovska, Ivana and Stankoski, Simon and Kalabakov, Stefan and Broulidakis, John and Nduka, Charles and Gjoreski, Martin},
  booktitle={Activity and Behavior Computing},
  pages={153--167},
  year={2021},
  publisher={Springer}
}

@inproceedings{windau2016walking,
  title={Walking compass with head-mounted IMU sensor},
  author={Windau, Jens and Itti, Laurent},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={5542--5547},
  year={2016},
  organization={IEEE}
}

@inproceedings{leelasawassuk2015estimating,
  title={Estimating visual attention from a head mounted IMU},
  author={Leelasawassuk, Teesid and Damen, Dima and Mayol-Cuevas, Walterio W},
  booktitle={Proceedings of the 2015 ACM International Symposium on Wearable Computers},
  pages={147--150},
  year={2015}
}

@article{antonenko2010using,
  title={Using electroencephalography to measure cognitive load},
  author={Antonenko, Pavlo and Paas, Fred and Grabner, Roland and Van Gog, Tamara},
  journal={Educational psychology review},
  volume={22},
  number={4},
  pages={425--438},
  year={2010},
  publisher={Springer}
}

@article{vortmann2019eeg,
  title={EEG-based classification of internally-and externally-directed attention in an augmented reality paradigm},
  author={Vortmann, Lisa-Marie and Kroll, Felix and Putze, Felix},
  journal={Frontiers in human neuroscience},
  volume={13},
  pages={348},
  year={2019},
  publisher={Frontiers Media SA}
}

@article{xu2018review,
  title={Review on portable EEG technology in educational research},
  author={Xu, Jiahui and Zhong, Baichang},
  journal={Computers in Human Behavior},
  volume={81},
  pages={340--349},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{yan2022emoglass,
  title={EmoGlass: an End-to-End AI-Enabled Wearable Platform for Enhancing Self-Awareness of Emotional Health},
  author={Yan, Zihan and Wu, Yufei and Zhang, Yang and Chen, Xiang'Anthony'},
  booktitle={CHI Conference on Human Factors in Computing Systems},
  pages={1--19},
  year={2022}
}

@inproceedings{yong2019emotion,
  title={Emotion recognition in gamers wearing head-mounted display},
  author={Yong, Hwanmoo and Lee, Jisuk and Choi, Jongeun},
  booktitle={2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  pages={1251--1252},
  year={2019},
  organization={IEEE}
}

@article{wan2021wearable,
  title={A Wearable Head Mounted Display Bio-Signals Pad System for Emotion Recognition},
  author={Wan, Chunting and Chen, Dongyi and Huang, Zhiqi and Luo, Xi},
  journal={Sensors},
  volume={22},
  number={1},
  pages={142},
  year={2021},
  publisher={MDPI}
}

@article{soleymani2015analysis,
  title={Analysis of EEG signals and facial expressions for continuous emotion detection},
  author={Soleymani, Mohammad and Asghari-Esfeden, Sadjad and Fu, Yun and Pantic, Maja},
  journal={IEEE Transactions on Affective Computing},
  volume={7},
  number={1},
  pages={17--28},
  year={2015},
  publisher={IEEE}
}

@article{tsai2018augmented,
  title={Augmented reality display based on user behavior},
  author={Tsai, Chung-Hsien and Huang, Jiung-Yao},
  journal={Computer Standards \& Interfaces},
  volume={55},
  pages={171--181},
  year={2018},
  publisher={Elsevier}
}

@article{kim2016understanding,
  title={Understanding users’ continuance intention toward smartphone augmented reality applications},
  author={Kim, Keesung and Hwang, Jiyeon and Zo, Hangjung and Lee, Hwansoo},
  journal={Information development},
  volume={32},
  number={2},
  pages={161--174},
  year={2016},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{park2018high,
  title={High-precision depth estimation with the 3d lidar and stereo fusion},
  author={Park, Kihong and Kim, Seungryong and Sohn, Kwanghoon},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2156--2163},
  year={2018},
  organization={IEEE}
}


@article{dey_understanding_2001,
	title = {Understanding and {Using} {Context}},
	journal = {Proceedings of the 1st international symposium on Handheld and Ubiquitous Computing},
	author = {Dey, Anind K.},
	year = {2001},
	keywords = {context-awareness, application support, context, situation-awareness},
	pages = {304--307},
	file = {Dey_2001_Understanding and Using Context.pdf:/Users/orsonxu/Zotero/storage/LKW3IBPF/Dey_2001_Understanding and Using Context.pdf:application/pdf;Dey_2001_Understanding and Using Context.pdf:/Users/orsonxu/Zotero/storage/EASZ2FA4/Dey_2001_Understanding and Using Context.pdf:application/pdf},
}

@inproceedings{gotz2009behavior,
  title={Behavior-driven visualization recommendation},
  author={Gotz, David and Wen, Zhen},
  booktitle={Proceedings of the 14th international conference on Intelligent user interfaces},
  pages={315--324},
  year={2009}
}



@incollection{samek2019towards,
  title={Towards explainable artificial intelligence},
  author={Samek, Wojciech and M{\"u}ller, Klaus-Robert},
  booktitle={Explainable AI: interpreting, explaining and visualizing deep learning},
  pages={5--22},
  year={2019},
  publisher={Springer}
}

@inproceedings{brown1998utility,
  title={Utility theory-based user models for intelligent interface agents},
  author={Brown, Scott M and Santos, Eugene and Banks, Sheila B},
  booktitle={Conference of the Canadian Society for Computational Studies of Intelligence},
  pages={378--392},
  year={1998},
  organization={Springer}
}


@inproceedings{bercher2014plan,
  title={Plan, repair, execute, explain—how planning helps to assemble your home theater},
  author={Bercher, Pascal and Biundo, Susanne and Geier, Thomas and Hoernle, Thilo and Nothdurft, Florian and Richter, Felix and Schattenberg, Bernd},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={24},
  pages={386--394},
  year={2014}
}

@inproceedings{das2021explainable,
  title={Explainable ai for robot failures: Generating explanations that improve user assistance in fault recovery},
  author={Das, Devleena and Banerjee, Siddhartha and Chernova, Sonia},
  booktitle={Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction},
  pages={351--360},
  year={2021}
}

@inproceedings{brennen2020people,
  title={What Do People Really Want When They Say They Want" Explainable AI?" We Asked 60 Stakeholders.},
  author={Brennen, Andrea},
  booktitle={Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--7},
  year={2020}
}

@article{bertossi2020data,
  title={Data quality and explainable AI},
  author={Bertossi, Leopoldo and Geerts, Floris},
  journal={Journal of Data and Information Quality (JDIQ)},
  volume={12},
  number={2},
  pages={1--9},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@inproceedings{antifakos2005towards,
  title={Towards improving trust in context-aware systems by displaying system confidence},
  author={Antifakos, Stavros and Kern, Nicky and Schiele, Bernt and Schwaninger, Adrian},
  booktitle={Proceedings of the 7th international conference on Human computer interaction with mobile devices \& services},
  pages={9--14},
  year={2005}
}

@inproceedings{zhang2020effect,
  title={Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making},
  author={Zhang, Yunfeng and Liao, Q Vera and Bellamy, Rachel KE},
  booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  pages={295--305},
  year={2020}
}


@inproceedings{bunt2012explanations,
  title={Are explanations always important? A study of deployed, low-cost intelligent interactive systems},
  author={Bunt, Andrea and Lount, Matthew and Lauzon, Catherine},
  booktitle={Proceedings of the 2012 ACM international conference on Intelligent User Interfaces},
  pages={169--178},
  year={2012}
}

@article{shin2021effects,
  title={The effects of explainability and causability on perception, trust, and acceptance: Implications for explainable AI},
  author={Shin, Donghee},
  journal={International Journal of Human-Computer Studies},
  volume={146},
  pages={102551},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{berkovsky2017recommend,
  title={How to recommend? User trust factors in movie recommender systems},
  author={Berkovsky, Shlomo and Taib, Ronnie and Conway, Dan},
  booktitle={Proceedings of the 22nd international conference on intelligent user interfaces},
  pages={287--300},
  year={2017}
}

@inproceedings{bussone2015role,
  title={The role of explanations on trust and reliance in clinical decision support systems},
  author={Bussone, Adrian and Stumpf, Simone and O'Sullivan, Dympna},
  booktitle={2015 international conference on healthcare informatics},
  pages={160--169},
  year={2015},
  organization={IEEE}
}

@inproceedings{ribera2019can,
  title={Can we do better explanations? A proposal of user-centered explainable AI.},
  author={Ribera, Mireia and Lapedriza, Agata},
  booktitle={IUI Workshops},
  volume={2327},
  pages={38},
  year={2019}
}

@article{rai2020explainable,
  title={Explainable AI: From black box to glass box},
  author={Rai, Arun},
  journal={Journal of the Academy of Marketing Science},
  volume={48},
  number={1},
  pages={137--141},
  year={2020},
  publisher={Springer}
}


@inproceedings{gervasio2018explanation,
  title={Explanation to Avert Surprise.},
  author={Gervasio, Melinda T and Myers, Karen L and Yeh, Eric and Adkins, Boone},
  booktitle={IUI Workshops},
  volume={2068},
  year={2018}
}

@article{manheim2019artificial,
  title={Artificial intelligence: Risks to privacy and democracy},
  author={Manheim, Karl and Kaplan, Lyric},
  journal={Yale JL \& Tech.},
  volume={21},
  pages={106},
  year={2019},
  publisher={HeinOnline}
}

@article{datta2014automated,
  title={Automated experiments on ad privacy settings: A tale of opacity, choice, and discrimination},
  author={Datta, Amit and Tschantz, Michael Carl and Datta, Anupam},
  journal={arXiv preprint arXiv:1408.6491},
  year={2014}
}


@inproceedings{rader2018explanations,
  title={Explanations as mechanisms for supporting algorithmic transparency},
  author={Rader, Emilee and Cotter, Kelley and Cho, Janghee},
  booktitle={Proceedings of the 2018 CHI conference on human factors in computing systems},
  pages={1--13},
  year={2018}
}

@inproceedings{eslami2015always,
  title={" I always assumed that I wasn't really that close to [her]" Reasoning about Invisible Algorithms in News Feeds},
  author={Eslami, Motahhare and Rickman, Aimee and Vaccaro, Kristen and Aleyasen, Amirhossein and Vuong, Andy and Karahalios, Karrie and Hamilton, Kevin and Sandvig, Christian},
  booktitle={Proceedings of the 33rd annual ACM conference on human factors in computing systems},
  pages={153--162},
  year={2015}
}

@article{li2020survey,
  title={A survey of data-driven and knowledge-aware explainable ai},
  author={Li, Xiao-Hui and Cao, Caleb Chen and Shi, Yuhan and Bai, Wei and Gao, Han and Qiu, Luyu and Wang, Cong and Gao, Yuanyuan and Zhang, Shenjia and Xue, Xun and others},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={34},
  number={1},
  pages={29--49},
  year={2020},
  publisher={IEEE}
}

@inproceedings{lage2019human,
  title={Human evaluation of models built for interpretability},
  author={Lage, Isaac and Chen, Emily and He, Jeffrey and Narayanan, Menaka and Kim, Been and Gershman, Samuel J and Doshi-Velez, Finale},
  booktitle={Proceedings of the AAAI Conference on Human Computation and Crowdsourcing},
  volume={7},
  pages={59--67},
  year={2019}
}

@inproceedings{binns2018s,
  title={'It's Reducing a Human Being to a Percentage' Perceptions of Justice in Algorithmic Decisions},
  author={Binns, Reuben and Van Kleek, Max and Veale, Michael and Lyngs, Ulrik and Zhao, Jun and Shadbolt, Nigel},
  booktitle={Proceedings of the 2018 Chi conference on human factors in computing systems},
  pages={1--14},
  year={2018}
}

@inproceedings{krause2016interacting,
  title={Interacting with predictions: Visual inspection of black-box machine learning models},
  author={Krause, Josua and Perer, Adam and Ng, Kenney},
  booktitle={Proceedings of the 2016 CHI conference on human factors in computing systems},
  pages={5686--5697},
  year={2016}
}

@article{gedikli2014should,
  title={How should I explain? A comparison of different explanation types for recommender systems},
  author={Gedikli, Fatih and Jannach, Dietmar and Ge, Mouzhi},
  journal={International Journal of Human-Computer Studies},
  volume={72},
  number={4},
  pages={367--382},
  year={2014},
  publisher={Elsevier}
}


@misc{ttc_labs,
 title={People-centric approaches to algorithmic explainability}, url={https://www.ttclabs.net/report/people-centric-approaches-to-algorithmic-explainability},
 journal={TTC Labs},
 author={TTC Labs},
 year={2022},
} 
 
@article{liu2017analyzing,
  title={Analyzing the training processes of deep generative models},
  author={Liu, Mengchen and Shi, Jiaxin and Cao, Kelei and Zhu, Jun and Liu, Shixia},
  journal={IEEE transactions on visualization and computer graphics},
  volume={24},
  number={1},
  pages={77--87},
  year={2017},
  publisher={IEEE}
}

@article{strobelt2017lstmvis,
  title={Lstmvis: A tool for visual analysis of hidden state dynamics in recurrent neural networks},
  author={Strobelt, Hendrik and Gehrmann, Sebastian and Pfister, Hanspeter and Rush, Alexander M},
  journal={IEEE transactions on visualization and computer graphics},
  volume={24},
  number={1},
  pages={667--676},
  year={2017},
  publisher={IEEE}
}


@inproceedings{danry2020wearable,
  title={Wearable Reasoner: towards enhanced human rationality through a wearable device with an explainable AI assistant},
  author={Danry, Valdemar and Pataranutaporn, Pat and Mao, Yaoli and Maes, Pattie},
  booktitle={Proceedings of the Augmented Humans International Conference},
  pages={1--12},
  year={2020}
}

@article{ahmed2022artificial,
  title={From artificial intelligence to explainable artificial intelligence in industry 4.0: a survey on what, how, and where},
  author={Ahmed, Imran and Jeon, Gwanggil and Piccialli, Francesco},
  journal={IEEE Transactions on Industrial Informatics},
  volume={18},
  number={8},
  pages={5031--5042},
  year={2022},
  publisher={IEEE}
}

@article{zimmermann2022enhancing,
  title={Enhancing brick-and-mortar store shopping experience with an augmented reality shopping assistant application using personalized recommendations and explainable artificial intelligence},
  author={Zimmermann, Robert and Mora, Daniel and Cirqueira, Douglas and Helfert, Markus and Bezbradica, Marija and Werth, Dirk and Weitzl, Wolfgang Jonas and Riedl, Ren{\'e} and Auinger, Andreas},
  journal={Journal of Research in Interactive Marketing},
  year={2022},
  publisher={Emerald Publishing Limited}
}

@inproceedings{xie2020chexplain,
  title={CheXplain: enabling physicians to explore and understand data-driven, AI-enabled medical imaging analysis},
  author={Xie, Yao and Chen, Melody and Kao, David and Gao, Ge and Chen, Xiang'Anthony'},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2020}
}

@inproceedings{ehsan2021expanding,
  title={Expanding explainability: Towards social transparency in ai systems},
  author={Ehsan, Upol and Liao, Q Vera and Muller, Michael and Riedl, Mark O and Weisz, Justin D},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--19},
  year={2021}
}

@inproceedings{ehsan2019automated,
  title={Automated rationale generation: a technique for explainable AI and its effects on human perceptions},
  author={Ehsan, Upol and Tambwekar, Pradyumna and Chan, Larry and Harrison, Brent and Riedl, Mark O},
  booktitle={Proceedings of the 24th International Conference on Intelligent User Interfaces},
  pages={263--274},
  year={2019}
}

@article{ehsan2021explainable,
  title={The who in explainable ai: How ai background shapes perceptions of ai explanations},
  author={Ehsan, Upol and Passi, Samir and Liao, Q Vera and Chan, Larry and Lee, I and Muller, Michael and Riedl, Mark O and others},
  journal={arXiv preprint arXiv:2107.13509},
  year={2021}
}

@article{wintersberger2018fostering,
  title={Fostering user acceptance and trust in fully automated vehicles: Evaluating the potential of augmented reality},
  author={Wintersberger, Philipp and Frison, Anna-Katharina and Riener, Andreas and Sawitzky, Tamara von},
  journal={PRESENCE: Virtual and Augmented Reality},
  volume={27},
  number={1},
  pages={46--62},
  year={2018},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{chatzopoulos2016readme,
  title={Readme: A real-time recommendation system for mobile augmented reality ecosystems},
  author={Chatzopoulos, Dimitris and Hui, Pan},
  booktitle={Proceedings of the 24th ACM international conference on Multimedia},
  pages={312--316},
  year={2016}
}

@misc{spotify_blend_taste,
title={How Spotify's newest personalized experience, blend, creates a playlist for you and your bestie}, url={https://newsroom.spotify.com/2021-08-31/how-spotifys-newest-personalized-experience-blend-creates-a-playlist-for-you-and-your-bestie/},
journal={Spotify}, author={Spotify}, year={2022}, month={Jul}} 

@article{liu2021ai,
  title={In AI we trust? Effects of agency locus and transparency on uncertainty reduction in human--AI interaction},
  author={Liu, Bingjie},
  journal={Journal of Computer-Mediated Communication},
  volume={26},
  number={6},
  pages={384--402},
  year={2021},
  publisher={Oxford University Press}
}

@article{ibili2019effect,
  title={Effect of Augmented Reality Environments on Cognitive Load: Pedagogical Effect, Instructional Design, Motivation and Interaction Interfaces.},
  author={{\.I}bili, Emin},
  journal={International Journal of Progressive Education},
  volume={15},
  number={5},
  pages={42--57},
  year={2019},
  publisher={ERIC}
}

@article{arguel2017inside,
  title={Inside out: detecting learners’ confusion to improve interactive digital learning environments},
  author={Arguel, Ama{\"e}l and Lockyer, Lori and Lipp, Ottmar V and Lodge, Jason M and Kennedy, Gregor},
  journal={Journal of Educational Computing Research},
  volume={55},
  number={4},
  pages={526--551},
  year={2017},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{umemuro2003detection,
  title={Detection of user's confusion and surprise based on pupil dilation},
  author={Umemuro, Hiroyuki and Yamashita, Jun},
  journal={The Japanese Journal of Ergonomics},
  volume={39},
  number={4},
  pages={153--161},
  year={2003},
  publisher={Japan Ergonomics Society}
}

@inproceedings{abrash2021creating,
  title={Creating the future: augmented reality, the next human-machine interface},
  author={Abrash, Michael},
  booktitle={2021 IEEE International Electron Devices Meeting (IEDM)},
  pages={1--2},
  year={2021},
  organization={IEEE}
}


@inproceedings{li2020artificial,
  title={Artificial intelligence for HCI: a modern approach},
  author={Li, Yang and Kumar, Ranjitha and Lasecki, Walter S and Hilliges, Otmar},
  booktitle={Extended Abstracts of the 2020 CHI conference on human factors in computing systems},
  pages={1--8},
  year={2020}
}

@article{riedl2019human,
  title={Human-centered artificial intelligence and machine learning},
  author={Riedl, Mark O},
  journal={Human Behavior and Emerging Technologies},
  volume={1},
  number={1},
  pages={33--36},
  year={2019},
  publisher={Wiley Online Library}
}

@inproceedings{bhatt2020explainable,
  title={Explainable machine learning in deployment},
  author={Bhatt, Umang and Xiang, Alice and Sharma, Shubham and Weller, Adrian and Taly, Ankur and Jia, Yunhan and Ghosh, Joydeep and Puri, Ruchir and Moura, Jos{\'e} MF and Eckersley, Peter},
  booktitle={Proceedings of the 2020 conference on fairness, accountability, and transparency},
  pages={648--657},
  year={2020}
}

@article{cherry2014quantifying,
  title={Quantifying the creativity support of digital tools through the creativity support index},
  author={Cherry, Erin and Latulipe, Celine},
  journal={ACM Transactions on Computer-Human Interaction (TOCHI)},
  volume={21},
  number={4},
  pages={1--25},
  year={2014},
  publisher={ACM New York, NY, USA}
}


@article{bangor2008empirical,
  title={An empirical evaluation of the system usability scale},
  author={Bangor, Aaron and Kortum, Philip T and Miller, James T},
  journal={Intl. Journal of Human--Computer Interaction},
  volume={24},
  number={6},
  pages={574--594},
  year={2008},
  publisher={Taylor \& Francis}
}

@inproceedings{gupta2019lvis,
  title={Lvis: A dataset for large vocabulary instance segmentation},
  author={Gupta, Agrim and Dollar, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5356--5364},
  year={2019}
}

@inproceedings{shao2019objects365,
  title={Objects365: A large-scale, high-quality dataset for object detection},
  author={Shao, Shuai and Li, Zeming and Zhang, Tianyuan and Peng, Chao and Yu, Gang and Zhang, Xiangyu and Li, Jing and Sun, Jian},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={8430--8439},
  year={2019}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{zhou2022detecting,
  title={Detecting twenty-thousand classes using image-level supervision},
  author={Zhou, Xingyi and Girdhar, Rohit and Joulin, Armand and Kr{\"a}henb{\"u}hl, Phillip and Misra, Ishan},
  journal={arXiv preprint arXiv:2201.02605},
  year={2022}
}

@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}

@misc{spoonacular,
title={Free meal planner, food tracker, and Recipe Saver}, 
url={https://spoonacular.com/}, journal={spoonacular}, year={2022}} 

@inproceedings{gilpin2018explaining,
  title={Explaining explanations: An overview of interpretability of machine learning},
  author={Gilpin, Leilani H and Bau, David and Yuan, Ben Z and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
  booktitle={2018 IEEE 5th International Conference on data science and advanced analytics (DSAA)},
  pages={80--89},
  year={2018},
  organization={IEEE}
}

@inproceedings{mittelstadt2019explaining,
  title={Explaining explanations in AI},
  author={Mittelstadt, Brent and Russell, Chris and Wachter, Sandra},
  booktitle={Proceedings of the conference on fairness, accountability, and transparency},
  pages={279--288},
  year={2019}
}

@article{chen2020review,
  title={A review: Knowledge reasoning over knowledge graph},
  author={Chen, Xiaojun and Jia, Shengbin and Xiang, Yang},
  journal={Expert Systems with Applications},
  volume={141},
  pages={112948},
  year={2020},
  publisher={Elsevier}
}

@article{pielot2017beyond,
  title={Beyond interruptibility: Predicting opportune moments to engage mobile phone users},
  author={Pielot, Martin and Cardoso, Bruno and Katevas, Kleomenis and Serr{\`a}, Joan and Matic, Aleksandar and Oliver, Nuria},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={1},
  number={3},
  pages={1--25},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{fogarty2005predicting,
  title={Predicting human interruptibility with sensors},
  author={Fogarty, James and Hudson, Scott E and Atkeson, Christopher G and Avrahami, Daniel and Forlizzi, Jodi and Kiesler, Sara and Lee, Johnny C and Yang, Jie},
  journal={ACM Transactions on Computer-Human Interaction (TOCHI)},
  volume={12},
  number={1},
  pages={119--146},
  year={2005},
  publisher={ACM New York, NY, USA}
}

@book{braun2012thematic,
  title={Thematic analysis.},
  author={Braun, Virginia and Clarke, Victoria},
  year={2012},
  publisher={American Psychological Association}
}

@inproceedings{luo2022should,
  title={Where Should We Put It? Layout and Placement Strategies of Documents in Augmented Reality for Collaborative Sensemaking},
  author={Luo, Weizhou and Lehmann, Anke and Widengren, Hjalmar and Dachselt, Raimund},
  booktitle={CHI Conference on Human Factors in Computing Systems},
  pages={1--16},
  year={2022}
}

@inproceedings{muller2016taxonomy,
  title={A taxonomy for information linking in augmented reality},
  author={M{\"u}ller, Tobias and Dauenhauer, Ralf},
  booktitle={International Conference on Augmented Reality, Virtual Reality and Computer Graphics},
  pages={368--387},
  year={2016},
  organization={Springer}
}

@inproceedings{rzayev2020effects,
  title={Effects of position and alignment of notifications on AR glasses during social interaction},
  author={Rzayev, Rufat and Korbely, Susanne and Maul, Milena and Schark, Alina and Schwind, Valentin and Henze, Niels},
  booktitle={Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society},
  pages={1--11},
  year={2020}
}

@inproceedings{yeh2022guide,
  title={How to Guide Task-oriented Chatbot Users, and When: A Mixed-methods Study of Combinations of Chatbot Guidance Types and Timings},
  author={Yeh, Su-Fang and Wu, Meng-Hsin and Chen, Tze-Yu and Lin, Yen-Chun and Chang, XiJing and Chiang, You-Hsuan and Chang, Yung-Ju},
  booktitle={CHI Conference on Human Factors in Computing Systems},
  year={2022}
}



@inproceedings{schlegel2019towards,
  title={Towards a rigorous evaluation of xai methods on time series},
  author={Schlegel, Udo and Arnout, Hiba and El-Assady, Mennatallah and Oelke, Daniela and Keim, Daniel A},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)},
  pages={4197--4201},
  year={2019},
  organization={IEEE}
}

@inproceedings{casalicchio2018visualizing,
  title={Visualizing the feature importance for black box models},
  author={Casalicchio, Giuseppe and Molnar, Christoph and Bischl, Bernd},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={655--670},
  year={2018},
  organization={Springer}
}

@article{platt1998sequential,
  title={Sequential minimal optimization: A fast algorithm for training support vector machines},
  author={Platt, John},
  year={1998}
}

@article{bridle1989training,
  title={Training stochastic model recognition algorithms as networks can lead to maximum mutual information estimation of parameters},
  author={Bridle, John},
  journal={Advances in neural information processing systems},
  volume={2},
  year={1989}
}

@article{kim2014bayesian,
  title={The bayesian case model: A generative approach for case-based reasoning and prototype classification},
  author={Kim, Been and Rudin, Cynthia and Shah, Julie A},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{zhang2018interpreting,
  title={Interpreting neural network judgments via minimal, stable, and symbolic corrections},
  author={Zhang, Xin and Solar-Lezama, Armando and Singh, Rishabh},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{guidotti2018local,
  title={Local rule-based explanations of black box decision systems},
  author={Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Pedreschi, Dino and Turini, Franco and Giannotti, Fosca},
  journal={arXiv preprint arXiv:1805.10820},
  year={2018}
}

@article{wachter2017counterfactual,
  title={Counterfactual explanations without opening the black box: Automated decisions and the GDPR},
  author={Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
  journal={Harv. JL \& Tech.},
  volume={31},
  pages={841},
  year={2017},
  publisher={HeinOnline}
}

@incollection{nissenbaum2009privacy,
  title={Privacy in context},
  author={Nissenbaum, Helen},
  booktitle={Privacy in Context},
  year={2009},
  publisher={Stanford University Press}
}