\renewcommand{\arraystretch}{1.6}
\begin{table*}[t]
\vspace{-0.1cm}
\centering
\resizebox{1\textwidth}{!}{
\begin{tabular}{c|c|m{7.3cm}|m{7.3cm}}
\hline \hline
\multicolumn{2}{c|}{\makecell{\text{ }}} & \includegraphics[width=7.3cm]{figures/design_case2_example1.png} & \includegraphics[width=7.3cm]{figures/design_case2_example2.png}\\
\multicolumn{2}{c|}{\makecell{\textbf{Designer}}} & \makecell{\textbf{P5, HCI/AR Researcher}} & \makecell{\textbf{P9, Product Designer}} \\
 \hline
\multirow{3}{*}{\makecell[c]{\\\textbf{Platform-}\\\textbf{Agnostic}\\\textbf{Key Factors}}}  & \textbf{System Goal} & \multicolumn{2}{c}{\makecell[c]{\textbf{User Intent Assistance} (to find a good recipe for friends)\\\textbf{Error Management} (to calibrate the user's trust for mid-level recognition confidence)}} \\
 & \textbf{User Goal} & \multicolumn{2}{c}{\makecell[c]{\textbf{Resolve Confusion} (to understand why the recommendations are wrong)}} \\
 & \textbf{User Profile} & \multicolumn{2}{c}{\makecell[c]{\textbf{User Preference}: Meet-lovers (friends); \textbf{AI Literacy}: Expert, high}} \\ \hdashline
\multirow{2}{*}{\makecell[c]{\textbf{AR-Specific}\\\textbf{Key Factors}}} & \textbf{Contextual Info} & \multicolumn{2}{c}{\makecell[c]{\textbf{Location}: Kitchen; \textbf{Time}: Evening; \textbf{Environment}: Various ingredients in the fridge}} \\
 & \textbf{User State} & \multicolumn{2}{c}{\makecell[c]{\textbf{Activity}: Opening the fridge to make dinner; \textbf{Cognitive Load}: Low}} \\ \hline
\multirow{2}{*}{\makecell[c]{\\\\\textbf{XAI Designs}\\\textbf{in AR}: \colorwhen{\textbf{\textit{When}}}}} & \colorwhen{Availability} (\gone) & Always available & Same as P5\\
 & \colorwhen{Delivery} (\gtwo) & Auto-trigger, because both conditions were met given the \textit{System Goal} and \textit{User Goal} & Auto-trigger; Besides, a new tweak to always spotlight ingredients automatically, since it introduced \textit{``ultra-low cognitive cost''} \\ \hdashline
\multirow{3}{*}{\makecell[c]{\\\\\\\textbf{XAI Designs}\\\textbf{in AR}: \colorwhat{\textbf{\textit{What}}}}} & \colorwhat{Content} (\gfour) & Five Types: Input/Output, Why/Why-Not, How-To, Certainty, and How & Same as P5\\
 & \colorwhat{Detail - Concise} (\gfive) & An explanation merging Why, Input, Certainty (color-coding to show ingredient with a mid-level confidence), and How-To (selecting ingredients to change) & An explanation Why and How-To; Besides, Input explanations were shown by spotlighting ingredients, which can be selected and changed (How-To)\\
 & \colorwhat{Detail - Detailed} (\gsix) & A drop down menu of the five types & Same as P5\\ \hdashline
\multirow{3}{*}{\makecell[c]{\\\\\textbf{XAI Designs}\\\textbf{in AR}: \colorhow{\textbf{\textit{How}}}}} & \colorhow{Modality} (\gseven) & Visual modality & Same as P5\\
 & \colorhow{Paradigm - Format} (\geight) & Textual format & Textual format as the primary format; Graphic format (spotlighting boundaries) to denote ingredients\\
 & \colorhow{Paradigm - Pattern} (\gnine) & Explicit pattern, presenting texts in the same window as the recommendations & Explicit pattern for texts (same as P5); Implicit pattern for graphic spotlights\\
\hline \hline
\end{tabular}
}
\vspace{0.1cm}
\caption{Two Design Examples of Case 2: Wrong Recipe Recommendation.}
\label{tab:design_example_case2}
\Description{Two Design Examples of Case 2: Wrong Recipe Recommendation: Mary works in an AI company (high AI literacy) and has friends coming over for dinner, who are beef lovers. She opens the fridge and sees steak. However, the AR glasses mistakenly recognize steak as salmon with mid-level confidence, and recommend a few recipes using salmon. She is confused and wonders how she can correct them.
The examples are from P5 and P9. The comparison again indicates both consistency and variance between two designers' examples.
P5's design is as follows:
When. P5 speculated that the major changes between the two tasks include: the System Goal (User Intent Assistance for finding a good recipe for friends, and Error Management for mid-level confidence), the User Goal (Resolve Confusion), and the User Profile (Mary's high AI literacy, friends' food preference). Both conditions of G3 were fulfilled. Thus P5 chose to deliver explanations automatically.
What. According to the table in the what part of the framework, the three factors led to five categories, including Input/Output, Why/Why-Not, How-To, Certainty, and How. For default explanations, in addition to Why, P5 proposed to color-code the Input to emphasize the ingredient with the mid-level confidence (Certainty), and to add a simple selection-based way to allow Mary to change the salmon (How-To). For detailed explanations, P5 proposed using a drop-down menu to show the five categories.
How. P5 chose to use visual modality, textual format, and explicit pattern to present explanations.
P9's design is as follows:
When. P9 had a similar analysis of the System Goal and User Goal as P5. She further proposed an interesting tweak of delivery: always spotlighting ingredients by showing simple information around them (Input category, G4), since it introduced "ultra-low cognitive cost, thus didn't need to follow G2".
What. P9 proposed the consistent category list following G3, and thus suggested the same detailed explanations design as P5. She decided to present Why and How-To as the default explanations. Moreover, as mentioned in the when part, P9 also proposed to show names and recognition certainty on ingredients as "low-cost" explanations.
How. The three sub-questions in P9's design are closely related. Besides displaying main textual explanations explicitly with recommendations, P9's proposed to use simple graphics in an implicit pattern for low-cost explanations}
\vspace{-0.7cm}
% \vspace{-0.7cm}
\end{table*}
\renewcommand{\arraystretch}{1.0}