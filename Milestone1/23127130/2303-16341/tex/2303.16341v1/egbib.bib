@String{NIPS = {Advances in Neural Information Processing Systems}}
@String{ICLR = {International Conference on Learning Representations}}
@String{ICML = {International Conference on Machine Learning}}
@String{CVPR = {IEEE Conference on Computer Vision and Pattern Recognition}}
@String{ICCV = {IEEE International Conference on Computer Vision}}
@String{ECCV = {European Conference on Computer Vision}}
@String{PAMI = {IEEE Transactions on Pattern Analysis and Machine Intelligence}}
@String{IJCV = {International Journal of Computer Vision}}
@String{ICAIS = {International Conference on Artificial Intelligence and Statistics}}
@String{WACV = {IEEE Winter Conference on Applications of Computer Vision}}
@String{TMLR = {Transactions on Machine Learning Research}}
@String{TIP = {IEEE Transactions on Image Processing}}
@String{EMNLP = {Empirical Methods in Natural Language Processing}}
@String{AAAI = {AAAI Conference on Artificial Intelligence}}

@inproceedings{li2020hero,
  title={HERO: Hierarchical Encoder for Video+ Language Omni-representation Pre-training},
  author={Li, Linjie and Chen, Yen-Chun and Cheng, Yu and Gan, Zhe and Yu, Licheng and Liu, Jingjing},
  booktitle=EMNLP,
  pages={2046--2065},
  year={2020}
}

@article{luo2020univl,
  title={Univl: A unified video and language pre-training model for multimodal understanding and generation},
  author={Luo, Huaishao and Ji, Lei and Shi, Botian and Huang, Haoyang and Duan, Nan and Li, Tianrui and Li, Jason and Bharti, Taroon and Zhou, Ming},
  journal={arXiv preprint arXiv:2002.06353},
  year={2020}
}

@inproceedings{miech2019howto100m,
  title={Howto100m: Learning a text-video embedding by watching hundred million narrated video clips},
  author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
  booktitle=CVPR,
  pages={2630--2640},
  year={2019}
}

@inproceedings{akbari2021vatt,
  title={Vatt: Transformers for multimodal self-supervised learning from raw video, audio and text},
  author={Akbari, Hassan and Yuan, Liangzhe and Qian, Rui and Chuang, Wei-Hong and Chang, Shih-Fu and Cui, Yin and Gong, Boqing},
  booktitle=NIPS,
  volume={34},
  pages={24206--24221},
  year={2021}
}

@inproceedings{xu2021videoclip,
  title={VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding},
  author={Xu, Hu and Ghosh, Gargi and Huang, Po-Yao and Okhonko, Dmytro and Aghajanyan, Armen and Metze, Florian and Zettlemoyer, Luke and Feichtenhofer, Christoph},
  booktitle=EMNLP,
  year={2021}
}

@inproceedings{lei2021less,
  title={Less is more: Clipbert for video-and-language learning via sparse sampling},
  author={Lei, Jie and Li, Linjie and Zhou, Luowei and Gan, Zhe and Berg, Tamara L and Bansal, Mohit and Liu, Jingjing},
  booktitle=CVPR,
  pages={7331--7341},
  year={2021}
}

@inproceedings{bain2021frozen,
  title={Frozen in time: A joint video and image encoder for end-to-end retrieval},
  author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
  booktitle=ICCV,
  pages={1728--1738},
  year={2021}
}

@inproceedings{ge2022bridging,
  title={Bridging video-text retrieval with multiple choice questions},
  author={Ge, Yuying and Ge, Yixiao and Liu, Xihui and Li, Dian and Shan, Ying and Qie, Xiaohu and Luo, Ping},
  booktitle=CVPR,
  pages={16167--16176},
  year={2022}
}

@inproceedings{li2022align,
  title={Align and prompt: Video-and-language pre-training with entity prompts},
  author={Li, Dongxu and Li, Junnan and Li, Hongdong and Niebles, Juan Carlos and Hoi, Steven CH},
  booktitle=CVPR,
  pages={4953--4963},
  year={2022}
}

@article{fu2021violet,
  title={Violet: End-to-end video-language transformers with masked visual-token modeling},
  author={Fu, Tsu-Jui and Li, Linjie and Gan, Zhe and Lin, Kevin and Wang, William Yang and Wang, Lijuan and Liu, Zicheng},
  journal={arXiv preprint arXiv:2111.12681},
  year={2021}
}

@inproceedings{sun2019videobert,
  title={Videobert: A joint model for video and language representation learning},
  author={Sun, Chen and Myers, Austin and Vondrick, Carl and Murphy, Kevin and Schmid, Cordelia},
  booktitle=ICCV,
  pages={7464--7473},
  year={2019}
}

@inproceedings{xu2021vlm,
  title={VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding},
  author={Xu, Hu and Ghosh, Gargi and Huang, Po-Yao and Arora, Prahal and Aminzadeh, Masoumeh and Feichtenhofer, Christoph and Metze, Florian and Zettlemoyer, Luke},
  booktitle={Findings of the Association for Computational Linguistics},
  pages={4227--4239},
  year={2021}
}

@inproceedings{zhu2020actbert,
  title={Actbert: Learning global-local video-text representations},
  author={Zhu, Linchao and Yang, Yi},
  booktitle=CVPR,
  pages={8746--8755},
  year={2020}
}

@inproceedings{zellers2022merlot,
  title={Merlot reserve: Neural script knowledge through vision and language and sound},
  author={Zellers, Rowan and Lu, Jiasen and Lu, Ximing and Yu, Youngjae and Zhao, Yanpeng and Salehi, Mohammadreza and Kusupati, Aditya and Hessel, Jack and Farhadi, Ali and Choi, Yejin},
  booktitle=CVPR,
  pages={16375--16387},
  year={2022}
}

@inproceedings{cao2022locvtp,
  title={Locvtp: Video-text pre-training for temporal localization},
  author={Cao, Meng and Yang, Tianyu and Weng, Junwu and Zhang, Can and Wang, Jue and Zou, Yuexian},
  booktitle=ECCV,
  pages={38--56},
  year={2022},
}

@inproceedings{ge2022miles,
  title={Miles: visual bert pre-training with injected language semantics for video-text retrieval},
  author={Ge, Yuying and Ge, Yixiao and Liu, Xihui and Wang, Jinpeng and Wu, Jianping and Shan, Ying and Qie, Xiaohu and Luo, Ping},
  booktitle=ECCV,
  pages={691--708},
  year={2022},
}

@inproceedings{nagrani2022learning,
  title={Learning audio-video modalities from image captions},
  author={Nagrani, Arsha and Seo, Paul Hongsuck and Seybold, Bryan and Hauth, Anja and Manen, Santiago and Sun, Chen and Schmid, Cordelia},
  booktitle=ECCV,
  pages={407--426},
  year={2022},
}

@inproceedings{zhang2022unsupervised,
  title={Unsupervised pre-training for temporal action localization tasks},
  author={Zhang, Can and Yang, Tianyu and Weng, Junwu and Cao, Meng and Wang, Jue and Zou, Yuexian},
  booktitle=CVPR,
  pages={14031--14041},
  year={2022}
}

@article{ma2023temporal,
  title={Temporal Perceiving Video-Language Pre-training},
  author={Ma, Fan and Jin, Xiaojie and Wang, Heng and Huang, Jingjia and Zhu, Linchao and Feng, Jiashi and Yang, Yi},
  journal={arXiv preprint arXiv:2301.07463},
  year={2023}
}

@inproceedings{xu2022groupvit,
  title={Groupvit: Semantic segmentation emerges from text supervision},
  author={Xu, Jiarui and De Mello, Shalini and Liu, Sifei and Byeon, Wonmin and Breuel, Thomas and Kautz, Jan and Wang, Xiaolong},
  booktitle=CVPR,
  pages={18134--18144},
  year={2022}
}

@inproceedings{yu2022k,
  title={k-means Mask Transformer},
  author={Yu, Qihang and Wang, Huiyu and Qiao, Siyuan and Collins, Maxwell and Zhu, Yukun and Adam, Hartwig and Yuille, Alan and Chen, Liang-Chieh},
  booktitle=ECCV,
  pages={288--307},
  year={2022},
}

@inproceedings{yun2019cutmix,
  title={Cutmix: Regularization strategy to train strong classifiers with localizable features},
  author={Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
  booktitle=ICCV,
  pages={6023--6032},
  year={2019}
}

@inproceedings{chen2020uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle=ECCV,
  pages={104--120},
  year={2020},
}

@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@inproceedings{liu2022ts2,
  title={Ts2-net: Token shift and selection transformer for text-video retrieval},
  author={Liu, Yuqi and Xiong, Pengfei and Xu, Luhui and Cao, Shengming and Jin, Qin},
  booktitle=ECCV,
  pages={319--335},
  year={2022},
}

@inproceedings{miech2020end,
  title={End-to-end learning of visual representations from uncurated instructional videos},
  author={Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
  booktitle=CVPR,
  pages={9879--9889},
  year={2020}
}

@article{yan2021video,
  title={Video-text pre-training with learned regions},
  author={Yan, Rui and Shou, Mike Zheng and Ge, Yixiao and Wang, Alex Jinpeng and Lin, Xudong and Cai, Guanyu and Tang, Jinhui},
  journal={arXiv preprint arXiv:2112.01194},
  year={2021}
}

@article{cai2022revitalize,
  title={Revitalize region feature for democratizing video-language pre-training},
  author={Cai, Guanyu and Ge, Yixiao and Wang, Alex Jinpeng and Yan, Rui and Lin, Xudong and Shan, Ying and He, Lianghua and Qie, Xiaohu and Wu, Jianping and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2203.07720},
  year={2022}
}

@inproceedings{alwassel2021tsp,
  title={Tsp: Temporally-sensitive pretraining of video encoders for localization tasks},
  author={Alwassel, Humam and Giancola, Silvio and Ghanem, Bernard},
  booktitle=ICCV,
  pages={3173--3183},
  year={2021}
}

@inproceedings{feichtenhofer2019slowfast,
  title={Slowfast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle=ICCV,
  pages={6202--6211},
  year={2019}
}

@inproceedings{wang2016temporal,
  title={Temporal segment networks: Towards good practices for deep action recognition},
  author={Wang, Limin and Xiong, Yuanjun and Wang, Zhe and Qiao, Yu and Lin, Dahua and Tang, Xiaoou and Van Gool, Luc},
  booktitle=ECCV,
  pages={20--36},
  year={2016},
}

@inproceedings{bertasius2021space,
  title={Is space-time attention all you need for video understanding?},
  author={Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
  booktitle=ICML,
  volume={2},
  pages={4},
  year={2021}
}

@article{tran2014c3d,
  title={C3D: generic features for video analysis},
  author={Tran, Du and Bourdev, Lubomir D and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  journal={CoRR, abs/1412.0767},
  volume={2},
  pages={8},
  year={2014}
}

@inproceedings{ghiasi2022scaling,
  title={Scaling open-vocabulary image segmentation with image-level labels},
  author={Ghiasi, Golnaz and Gu, Xiuye and Cui, Yin and Lin, Tsung-Yi},
  booktitle=ECCV,
  pages={540--557},
  year={2022},
}

@inproceedings{fang2015captions,
  title={From captions to visual concepts and back},
  author={Fang, Hao and Gupta, Saurabh and Iandola, Forrest and Srivastava, Rupesh K and Deng, Li and Doll{\'a}r, Piotr and Gao, Jianfeng and He, Xiaodong and Mitchell, Margaret and Platt, John C and others},
  booktitle=CVPR,
  pages={1473--1482},
  year={2015}
}

@article{fukui2016multimodal,
  title={Multimodal compact bilinear pooling for visual question answering and visual grounding},
  author={Fukui, Akira and Park, Dong Huk and Yang, Daylen and Rohrbach, Anna and Darrell, Trevor and Rohrbach, Marcus},
  journal={arXiv preprint arXiv:1606.01847},
  year={2016}
}

@inproceedings{gupta2020contrastive,
  title={Contrastive learning for weakly supervised phrase grounding},
  author={Gupta, Tanmay and Vahdat, Arash and Chechik, Gal and Yang, Xiaodong and Kautz, Jan and Hoiem, Derek},
  booktitle=ECCV,
  pages={752--768},
  year={2020},
}

@inproceedings{rohrbach2016grounding,
  title={Grounding of textual phrases in images by reconstruction},
  author={Rohrbach, Anna and Rohrbach, Marcus and Hu, Ronghang and Darrell, Trevor and Schiele, Bernt},
  booktitle=ECCV,
  pages={817--834},
  year={2016},
}

@inproceedings{alayrac2020self,
  title={Self-supervised multimodal versatile networks},
  author={Alayrac, Jean-Baptiste and Recasens, Adria and Schneider, Rosalia and Arandjelovi{\'c}, Relja and Ramapuram, Jason and De Fauw, Jeffrey and Smaira, Lucas and Dieleman, Sander and Zisserman, Andrew},
  booktitle=NIPS,
  volume={33},
  pages={25--37},
  year={2020}
}

@inproceedings{amrani2021noise,
  title={Noise estimation using density estimation for self-supervised multimodal learning},
  author={Amrani, Elad and Ben-Ari, Rami and Rotman, Daniel and Bronstein, Alex},
  booktitle=AAAI,
  volume={35},
  pages={6644--6652},
  year={2021}
}

@inproceedings{yang2021taco,
  title={Taco: Token-aware cascade contrastive learning for video-text alignment},
  author={Yang, Jianwei and Bisk, Yonatan and Gao, Jianfeng},
  booktitle=ICCV,
  pages={11562--11572},
  year={2021}
}

@inproceedings{chen2021multimodal,
  title={Multimodal clustering networks for self-supervised learning from unlabeled videos},
  author={Chen, Brian and Rouditchenko, Andrew and Duarte, Kevin and Kuehne, Hilde and Thomas, Samuel and Boggust, Angie and Panda, Rameswar and Kingsbury, Brian and Feris, Rogerio and Harwath, David and others},
  booktitle=ICCV,
  pages={8012--8021},
  year={2021}
}

@article{patrick2020support,
  title={Support-set bottlenecks for video-text representation learning},
  author={Patrick, Mandela and Huang, Po-Yao and Asano, Yuki and Metze, Florian and Hauptmann, Alexander and Henriques, Joao and Vedaldi, Andrea},
  journal={arXiv preprint arXiv:2010.02824},
  year={2020}
}

@inproceedings{rouditchenko2020avlnet,
  title={Avlnet: Learning audio-visual language representations from instructional videos},
  author={Rouditchenko, Andrew and Boggust, Angie and Harwath, David and Chen, Brian and Joshi, Dhiraj and Thomas, Samuel and Audhkhasi, Kartik and Kuehne, Hilde and Panda, Rameswar and Feris, Rogerio and others},
  booktitle={Interspeech},
  year={2021}
}

@inproceedings{gabeur2020multi,
  title={Multi-modal transformer for video retrieval},
  author={Gabeur, Valentin and Sun, Chen and Alahari, Karteek and Schmid, Cordelia},
  booktitle=ECCV,
  pages={214--229},
  year={2020},
}

@inproceedings{xu2017video,
  title={Video question answering via gradually refined attention over appearance and motion},
  author={Xu, Dejing and Zhao, Zhou and Xiao, Jun and Wu, Fei and Zhang, Hanwang and He, Xiangnan and Zhuang, Yueting},
  booktitle={ACM International Conference on Multimedia},
  pages={1645--1653},
  year={2017}
}

@inproceedings{jang2017tgif,
  title={Tgif-qa: Toward spatio-temporal reasoning in visual question answering},
  author={Jang, Yunseok and Song, Yale and Yu, Youngjae and Kim, Youngjin and Kim, Gunhee},
  booktitle=CVPR,
  pages={2758--2766},
  year={2017}
}

@inproceedings{gao2018motion,
  title={Motion-appearance co-memory networks for video question answering},
  author={Gao, Jiyang and Ge, Runzhou and Chen, Kan and Nevatia, Ram},
  booktitle=CVPR,
  pages={6576--6585},
  year={2018}
}

@inproceedings{fan2019heterogeneous,
  title={Heterogeneous memory enhanced multimodal attention model for video question answering},
  author={Fan, Chenyou and Zhang, Xiaofan and Zhang, Shu and Wang, Wensheng and Zhang, Chi and Huang, Heng},
  booktitle=CVPR,
  pages={1999--2007},
  year={2019}
}

@inproceedings{huang2020location,
  title={Location-aware graph convolutional networks for video question answering},
  author={Huang, Deng and Chen, Peihao and Zeng, Runhao and Du, Qing and Tan, Mingkui and Gan, Chuang},
  booktitle=AAAI,
  volume={34},
  pages={11021--11028},
  year={2020}
}

@inproceedings{jiang2020reasoning,
  title={Reasoning with heterogeneous graph alignment for video question answering},
  author={Jiang, Pin and Han, Yahong},
  booktitle=AAAI,
  volume={34},
  pages={11109--11116},
  year={2020}
}

@inproceedings{jiang2020divide,
  title={Divide and conquer: Question-guided spatio-temporal contextual attention for video question answering},
  author={Jiang, Jianwen and Chen, Ziqiang and Lin, Haojie and Zhao, Xibin and Gao, Yue},
  booktitle=AAAI,
  volume={34},
  pages={11101--11108},
  year={2020}
}

@inproceedings{le2020hierarchical,
  title={Hierarchical conditional relation networks for video question answering},
  author={Le, Thao Minh and Le, Vuong and Venkatesh, Svetha and Tran, Truyen},
  booktitle=CVPR,
  pages={9972--9981},
  year={2020}
}

@inproceedings{seo2021look,
  title={Look before you speak: Visually contextualized utterances},
  author={Seo, Paul Hongsuck and Nagrani, Arsha and Schmid, Cordelia},
  booktitle=CVPR,
  pages={16877--16887},
  year={2021}
}

@inproceedings{kong2020cycle,
  title={Cycle-contrast for self-supervised video representation learning},
  author={Kong, Quan and Wei, Wenpeng and Deng, Ziwei and Yoshinaga, Tomoaki and Murakami, Tomokazu},
  booktitle=NIPS,
  volume={33},
  pages={8089--8100},
  year={2020}
}

@article{sun2019learning,
  title={Learning video representations using contrastive bidirectional transformer},
  author={Sun, Chen and Baradel, Fabien and Murphy, Kevin and Schmid, Cordelia},
  journal={arXiv preprint arXiv:1906.05743},
  year={2019}
}

@inproceedings{han2020memory,
  title={Memory-augmented dense predictive coding for video representation learning},
  author={Han, Tengda and Xie, Weidi and Zisserman, Andrew},
  booktitle=ECCV,
  pages={312--329},
  year={2020},
}

@inproceedings{han2020self,
  title={Self-supervised co-training for video representation learning},
  author={Han, Tengda and Xie, Weidi and Zisserman, Andrew},
  booktitle=NIPS,
  volume={33},
  pages={5679--5690},
  year={2020}
}

@inproceedings{huo2021compressed,
  title={Compressed video contrastive learning},
  author={Huo, Yuqi and Ding, Mingyu and Lu, Haoyu and Fei, Nanyi and Lu, Zhiwu and Wen, Ji-Rong and Luo, Ping},
  booktitle=NIPS,
  volume={34},
  pages={14176--14187},
  year={2021}
}

@inproceedings{alwassel2020self,
  title={Self-supervised learning by cross-modal audio-video clustering},
  author={Alwassel, Humam and Mahajan, Dhruv and Korbar, Bruno and Torresani, Lorenzo and Ghanem, Bernard and Tran, Du},
  booktitle=NIPS,
  volume={33},
  pages={9758--9770},
  year={2020}
}

@inproceedings{piergiovanni2020evolving,
  title={Evolving losses for unsupervised video representation learning},
  author={Piergiovanni, AJ and Angelova, Anelia and Ryoo, Michael S},
  booktitle=CVPR,
  pages={133--142},
  year={2020}
}

@article{chen2020improved,
  title={Improved baselines with momentum contrastive learning},
  author={Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  journal={arXiv preprint arXiv:2003.04297},
  year={2020}
}

@inproceedings{pan2021videomoco,
  title={Videomoco: Contrastive video representation learning with temporally adversarial examples},
  author={Pan, Tian and Song, Yibing and Yang, Tianyu and Jiang, Wenhao and Liu, Wei},
  booktitle=CVPR,
  pages={11205--11214},
  year={2021}
}

@inproceedings{chen2021rspnet,
  title={Rspnet: Relative speed perception for unsupervised video representation learning},
  author={Chen, Peihao and Huang, Deng and He, Dongliang and Long, Xiang and Zeng, Runhao and Wen, Shilei and Tan, Mingkui and Gan, Chuang},
  booktitle=AAAI,
  volume={35},
  pages={1045--1053},
  year={2021}
}

@inproceedings{wei2018learning,
  title={Learning and using the arrow of time},
  author={Wei, Donglai and Lim, Joseph J and Zisserman, Andrew and Freeman, William T},
  booktitle=CVPR,
  pages={8052--8060},
  year={2018}
}

@inproceedings{benaim2020speednet,
  title={Speednet: Learning the speediness in videos},
  author={Benaim, Sagie and Ephrat, Ariel and Lang, Oran and Mosseri, Inbar and Freeman, William T and Rubinstein, Michael and Irani, Michal and Dekel, Tali},
  booktitle=CVPR,
  pages={9922--9931},
  year={2020}
}

@inproceedings{xu2020g,
  title={G-tad: Sub-graph localization for temporal action detection},
  author={Xu, Mengmeng and Zhao, Chen and Rojas, David S and Thabet, Ali and Ghanem, Bernard},
  booktitle=CVPR,
  pages={10156--10165},
  year={2020}
}

@inproceedings{xu2021boundary,
  title={Boundary-sensitive pre-training for temporal localization in videos},
  author={Xu, Mengmeng and P{\'e}rez-R{\'u}a, Juan-Manuel and Escorcia, Victor and Martinez, Brais and Zhu, Xiatian and Zhang, Li and Ghanem, Bernard and Xiang, Tao},
  booktitle=ICCV,
  pages={7220--7230},
  year={2021}
}

@inproceedings{xu2021low,
  title={Low-fidelity video encoder optimization for temporal action localization},
  author={Xu, Mengmeng and Perez Rua, Juan Manuel and Zhu, Xiatian and Ghanem, Bernard and Martinez, Brais},
  booktitle=NIPS,
  volume={34},
  pages={9923--9935},
  year={2021}
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  pages={2556--2565},
  year={2018}
}

@inproceedings{krishna2017dense,
  title={Dense-captioning events in videos},
  author={Krishna, Ranjay and Hata, Kenji and Ren, Frederic and Fei-Fei, Li and Carlos Niebles, Juan},
  booktitle=ICCV,
  pages={706--715},
  year={2017}
}

@inproceedings{xu2016msr,
  title={Msr-vtt: A large video description dataset for bridging video and language},
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle=CVPR,
  pages={5288--5296},
  year={2016}
}

@inproceedings{heilbron2015activitynet,
  title={Activitynet: A large-scale video benchmark for human activity understanding},
  author={Heilbron, Fabian Caba and Escorcia, Victor and Ghanem, Bernard and Niebles, Juan Carlos},
  booktitle=CVPR,
  pages={961--970},
  year={2015},
}

@inproceedings{kuehne2011hmdb,
  title={HMDB: a large video database for human motion recognition},
  author={Kuehne, Hildegard and Jhuang, Hueihan and Garrote, Est{\'\i}baliz and Poggio, Tomaso and Serre, Thomas},
  booktitle=ICCV,
  pages={2556--2563},
  year={2011},
}

@article{soomro2012ucf101,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={arXiv preprint arXiv:1212.0402},
  year={2012}
}

@inproceedings{anderson2018bottom,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle=CVPR,
  pages={6077--6086},
  year={2018}
}

@inproceedings{qian2022teg,
  title={Exploring temporal granularity in self-supervised video representation learning},
  author={Qian, Rui and Li, Yeqing and Yuan, Liangzhe and Gong, Boqing and Liu, Ting and Brown, Matthew and Belongie, Serge and Yang, Ming-Hsuan and Adam, Hartwig and Cui, Yin},
  booktile={BMVC},
  year={2022}
}

@inproceedings{yuan2022contextualized,
  title={Contextualized spatio-temporal contrastive learning with self-supervision},
  author={Yuan, Liangzhe and Qian, Rui and Cui, Yin and Gong, Boqing and Schroff, Florian and Yang, Ming-Hsuan and Adam, Hartwig and Liu, Ting},
  booktitle={CVPR},
  pages={13977--13986},
  year={2022}
}