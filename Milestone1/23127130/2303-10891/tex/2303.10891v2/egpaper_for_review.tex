\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage[mathscr]{eucal}
\usepackage[ruled]{algorithm2e}
\usepackage[dvipsnames, svgnames, x11names]{xcolor}
\usepackage{colortbl}
\usepackage{arydshln}
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

% \def\iccvPaperID{3157} % *** Enter the ICCV Paper ID here
% \def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
\title{Non-Exemplar Online Class-incremental Continual Learning via \\ Dual-prototype Self-augment and Refinement}

\author{
   Fushuo~Huo$^1$,
   Wenchao~Xu$^1$,
   Jingcai~Guo$^1$,
   Haozhao~Wang$^2$,
   and~Yunfeng~Fan$^1$,
   Song~Guo$^1$\\
  \textsuperscript{1}Department of Computing, The Hong Kong Polytechnic University\\
  \textsuperscript{2}School of Computer Science and Technology, Huazhong University of Science and Technology\\
  % \texttt{yunfeng.fan@connect.polyu.hk}, \texttt{wenchao.xu@polyu.edu.hk}, \texttt{hz\_wang@hust.edu.cn}, \\
  % \texttt{junxiao.wang@polyu.edu.hk}, \texttt{song.guo@polyu.edu.hk}
}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi


%%%%%%%%% ABSTRACT
\begin{abstract}
%%%%%%%%%%%%This paper studies a novel and practical, but challenging problem called Offline-Online Class-incremental Continual Learning (NO-CL), which aims to preserve pre-trained (i.e., offline) base classes discernibility without buffering data examples, while efficiently learning novel classes continually from the single-pass (i.e., online) data stream. 
%
% We investigate Offline-Online Class-incremental Continual Learning (NO-CL), a novel and practical continual learning paradigm that aims to preserve the discernibility of pre-trained (i.e., offline) base classes without buffering data examples, and efficiently learning novel classes continuously in a single-pass (i.e., online) data stream.

This paper investigates a new, practical, but challenging problem named Non-exemplar Online Class-incremental continual Learning (NO-CL), which aims to preserve the discernibility of base classes \emph{without} buffering data examples and efficiently learn novel classes continuously in a \emph{single-pass} (i.e., online) data stream.
The challenges of this task are mainly two-fold: (1) Both base and novel classes suffer from severe catastrophic forgetting as no previous samples are available for replay. (2) As the online data can only be observed once, there is no way to fully re-train the whole model, e.g., re-calibrate the decision boundaries via prototype alignment or feature distillation.
In this paper, we propose a novel \underline{\textbf{D}}ual-prototype \underline{\textbf{S}}elf-augment and \underline{\textbf{R}}efinement method (DSR) for NO-CL problem, which consists of two strategies: 
1) Dual class prototypes: vanilla and high-dimensional prototypes are exploited to utilize the pre-trained information and obtain robust quasi-orthogonal representations rather than example buffers for both privacy preservation and memory reduction. 
2) Self-augment and refinement: Instead of updating the whole network, 
we optimize high-dimensional prototypes alternatively with the extra projection module based on self-augment vanilla prototypes, through a bi-level optimization problem. 
Extensive experiments demonstrate the effectiveness and superiority of the proposed DSR in NO-CL$\footnote{The source codes are attached in the supplementary material and will be released upon acceptance.}$.
%
% Meanwhile, privacy information should also be protected during the whole process. 
% Meanwhile, privacy leakage and computation overhead should also be considered during the online learning procedure. 
%
% This problem is challenging due to two difficulties. 
% Firstly, offline pre-trained base classes suffer from catastrophic forgetting due to lacking joint optimization of base and novel classes.
% % , even equipped with example buffer. 
% Secondly, Online Class-incremental continual Learning (OCL) is initially biased to base classes and sequentially over-fitting to novel classes, also causing forgetting and over-fitting issues. 
%
% This problem is challenging as 
%
%%%%%%%%%%%%The critical issue is that both base and novel classes suffer from severe catastrophic forgetting as no previous sample is available for replay.
% due to lacking example buffers to revisit. % 
% Besides, Online Class-incremental Continual Learning (OCL) on novel classes leaves no room to re-calibrate decision boundaries of learned classes.
%%%%%%%%%%%%Besides, As the online data can only be observed once, there is no way to re-train the model backbone, e.g., re-calibrate the decision boundaries via prototype alignment or knowledge distillation that heavily relied on raw data collection.  
% , even equipped with example buffer. 
% Secondly, Online Class-incremental continual Learning (OCL) is initially biased to base classes and sequentially over-fitting to novel classes, also causing forgetting and over-fitting issues. 
%
% Though employing a large example buffer can eliminate these problems to some extent, privacy leakage and computation overhead are also not negligible. 
%
%%%%%%%%%%%%
% The challenges of this task are mainly two-fold: 1) Catastrophic forgetting of both base and novel classes, due to the lack of example buffer; and 2) Confused decision boundary, due to the entangled nature of the data even between base and novel classes. 
% %
% In this paper, we propose a novel \underline{\textbf{D}}ual-prototype \underline{\textbf{S}}elf-augment and \underline{\textbf{R}}efinement method, dubbed DSR, to conduct effective training in NO-CL. 
% %
% Specifically, DSR consists of two strategies. First, we propose dual-class prototypes that exploit vanilla and hyper-dimensional prototypes to explore more robust class-wise quasi-orthogonal representations, rather than example buffers for both memory reduction and privacy preservation. 
% %
% Next, instead of updating the whole network, we propose the self-augmentation and refinement method to jointly optimize an extra projection module between the vanilla and projected hyper-dimensional prototype spaces, to refine the hyper-dimensional prototypes toward more accurate decision boundaries for both base and novel classes. 
% %
% %which consists of two strategies: 
% %1) Dual class prototypes: vanilla and hyper-dimensional prototypes are exploited to utilize the pre-trained information and obtain robust quasi-orthogonal representations rather than example buffers to prevent privacy leakage. 
% %2) Self-augment and refinement: Instead of updating the whole network, we jointly optimize the extra projection module with the self-augment vanilla prototypes from base and novel classes, gradually refining the hyper-dimensional prototypes to obtain accurate decision boundaries for both old and new classes. 
% % wenchao: I comment this on 8 Mar
% % In this paper, we propose a novel Dual-prototype Self-augment and Refinement (DSR) method consisting of two strategies: 
% % 1) Dual class prototypes: vanilla and hyper-dimensional prototypes are exploited to utilize the pre-trained information and obtain robust quasi-orthogonal representations rather than example buffers to prevent privacy leakage. 
% % 2) Self-augment and refinement: Instead of updating the whole network, we jointly optimize the extra projection module with the self-augment vanilla prototypes from base and novel classes, gradually refining the hyper-dimensional prototypes to have clear decision boundaries. 
% %
% Extensive experiments demonstrate the effectiveness and superiority of the proposed DSR in NO-CL~$\footnote{The source codes are attached in the supplementary material and will be released upon acceptance.}$.
   
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
With the ubiquitously prevalent personal smart devices, a massive amount of data are being continually generated, which requires adaptive machine learning models to learn new tasks without forgetting the old knowledge
% achieve the stability-plasticity trade-off 
\cite{survey1, ne-cl-da, ne-cl-ss}. In privacy-sensitive online scenarios, a practical Online Class-incremental continual Learning (OCL) system is expected to learn novel classes incrementally while keeping the prior knowledge without restoring any streaming data due to privacy and computation concerns. 
% Existing OCL methods \cite{ocm, sv, dvc, scr, rar} mainly focus on exploring the critical feature representation \cite{ocm, scr, dvc, rar} and developing strategies of selecting and retrieving proper samples from the data buffer \cite{sv, dvc} to re-calibrate the decision boundaries.
% However, existing OCL methods have two obvious drawbacks. 
% Firstly, online learning is required for privacy-sensitive and/or resource-constrained scenarios where the training data can only be observed once.
However, (1) existing OCL solutions heavily rely on the example buffer for replay to re-calibrate the decision boundaries, between data batches and tasks \cite{tl_ocl}.
% , which is frequently retrieved between data batches and tasks \cite{tl_ocl}. 
%
(2) OCL mainly concerns the setting of totally online continual learning, which is a relatively uncommon scenario for dynamic environments, and the state-of-the-art method \cite{dvc} achieves impractical low accuracy (\textbf{$<$20$\%$} for CIFAR100 with 1000 buffer size), which significantly hinders the deployment of OCL methods. 
% These settings somewhat make traditional OCL less practical for practical online applications.


\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{COCL}
\vspace{-0.2cm}
\caption{The overall concept of proposed NO-CL ($\emph{bottom}$), compared with OCL ($\emph{top}$) and NE-CL/FS-CL ($\emph{middle}$).}
\label{fig1_real1}
\vspace{-0.1cm}
\end{figure}



Considering dynamic continual learning scenarios, we investigate a new, practical, yet challenging protocol named Non-exemplar Online Class-incremental continual Learning (NO-CL), as demonstrated in Figure \ref{fig1_real1}(\emph{bottom}). Concretely, in practice, an intelligent system conducts online class-incremental learning without restoring stream examples, while utilizing and preserving the knowledge from previous training. Such under-explored practical settings are in line with Non-Exemplar Class-incremental continual Learning (NE-CL) \cite{ne-cl-sdc, ne-cl-da, ne-cl-ss} and Few-Shot Class-incremental Learning (FS-CL) \cite{fs-cl-sp, fs-cl-s3c, fs-cl-open}, as shown in Figure \ref{fig1_real1}(\emph{middle}), where base classes are well trained and retained, but novel classes need to be explored. However, NE-CL conducts class-incremental learning without example buffers in an offline fashion, which enables the network to align the prior information (i.e., prototypes and/or features) gradually like semantic drift compensation \cite{ne-cl-sdc}, dual augmentation \cite{ne-cl-da}, and prototype selection \cite{ne-cl-ss}. FS-CL aims to continually learn with few shot samples also in an offline way, like gradually refining the prototypes \cite{fs-cl-sp}, finetuning the classifier heads \cite{fs-cl-s3c}, or focusing on training robust embedding network \cite{fs-cl-open}. Therefore, NE-CL and FS-CL methods can hardly solve the  NO-CL problem. Figure \ref{fig2} demonstrates the brief quantitative comparisons of OCL, FS-CL, NE-CL, and the proposed method in \emph{the same NO-CL training protocols}.
 

% In the proposed NO-CL setting, the key is to conduct \textbf{online} class-incremental Continual Learning without forgetting the old knowledge to solve the stability-plasticity dilemma.
% As the data sample from new class is single-pass and previous data samples can not be revisited, the stability-plasticity dilemma is more severe in NO-CL.
% , while learning from data stream will cause class imbalance and forgetting pre-trained information \cite{luc, lscl}. 
% Previous Online Class-incremental continual Learning (OCL) restore and retrieve the example buffers to maintain the performance, which somewhat violates the OCL protocols \cite{tl_ocl}. 
To solve the proposed NO-CL problem, we devise a simple but effective method called Dual-prototype Self-augment and Refinement (DSR). 
As the single-pass data can not be revisited, unlike previous example-base continual learning methods, directly finetuning the feature extractor will cause severe catastrophic forgetting. Therefore, we freeze the pre-trained feature extractor and translate the NO-CL problem to bi-level optimizing \cite{bi-level} privacy-preserved prototypes with the extra projection module. Specifically, vanilla and high-dimensional prototypes (V-P and H-P) of base classes are restored to preserve learned information. For incremental sessions,  
direct calculation and reasoning V-P tends to accumulate errors and fails to fully explore online data. The project module is introduced to translate V-P to the high-dimensional embedding \cite{hd1, hd2, imhdc}, which has been proven robust to noise. In detail, a random vector from high-dimensional embedding is quasi-orthogonal to other vectors with high probability (the “curse” of dimensionality \cite{hd2}), and fine-tuning the prototype in the high-dimensional embedding provides a sufficiently large capacity to accommodate novel classes over time, with minimal interference with learned knowledge. 
Therefore, we formulate a bi-level optimization strategy to optimize the extra high-dimensional prototypes alternatively with the projection module, to refine the decision boundaries and re-calibrate projection module based on optimized prototypes.
% Then, to efficiently maintain the decision boundaries of base and novel classes, self-augment V-P of learned classes
% jointly optimize the projection module, re-calibrating the V-P to the refined high-dimensional prototypes. 
In summary, our contributions are as follows:

% which have clear decision boundaries calculated by frozen feature extractor and extra projection module are restored, where base classes have clear decision boundaries while incremental novel classes tend to confuse both novel and base classes. Therefore, to refine the dual prototypes of incremental classes, 

% We resort to privacy-preserved dual prototypes rather than cumbersome examples to revisit and explore base and novel classes. Instead of fine-tuning the whole network, the single-pass data stream are fed to the feature extractor and get the rough vanilla prototypes of each class. Unlike previous settings, as the raw data samples from current and/or previous tasks can not be revisited, modifying the feature extractor and vanilla prototypes causes the severe catastrophic forgetting. 

% To further self-augment and refine the rough prototypes, we then project them to the hyper-dimensional embedding \cite{hd1, hd2, imhdc}, which has been proven robust to noise. In detail, A randomly vector from hyper-dimensional embedding is quasi-orthogonal to other vectors with very high probability (the “curse” of dimensionality \cite{hd2}), and fine-tuning the prototype in the hyper-dimensional embedding provides a sufficiently large capacity to accommodate novel classes over time. Moreover, to efficiently learning the invariant information of the novel classes, self-augment vanilla prototype of base and novel classes based on class mean and variances jointly optimize the project head. In summary, our contributions are as follows:

\begin{itemize}
\item[1)] We propose a novel yet practical problem called Non-exemplar Online Class-incremental continual Learning (NO-CL), where an intelligent system with pre-trained base classes information can efficiently learn novel classes continually from the single-pass (i.e., online) data stream, without example buffers. Meanwhile, previous knowledge should also be preserved. 

\item[2)] We develop a novel Dual-prototype Self-augment and Refinement (DSR) method, which transfers training the whole network to bi-level optimizing prototypes and the extra projection module.
% Concretely, H-P rapidly accommodates novel classes due to its quasi-orthogonal attribute. Then, self-augment V-P jointly optimizes the projection module based on refined H-P to re-calibrate the decision boundaries of learned classes. 

\item[3)] Extensive quantitative results demonstrate DSR performs significantly better than existing OCL, NE-CL, and FS-CL methods under the \emph{same training protocols} of proposed NO-CL, both in accuracy and efficiency $\footnote{Brief comparisons can be referred to in Figure \ref{fig2}.}$.

\end{itemize}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{results}
\vspace{-0.3cm}
\caption{Class-wise accuracy, online training time, and memory overhead comparisons on the CIFAR100 with the \textbf{same protocols} of NO-CL. Stat-of-the-art OCL (SCR\cite{scr}, DVC\cite{dvc}, and OCM \cite{ocm}, all with 1000 example buffer), FS-CL (ALICE \cite{fs-cl-open}), and NE-CL (SSRE \cite{ne-cl-ss}) methods are illustrated. Online training batchsize is 10.}
\label{fig2}
\vspace{-0.2cm}
\end{figure}

\section{Related Work}

% \subsection{Continual Learning}
% With the development of deep learning technologies \cite{cifar100, imagenet, miniimagenet, resnet}, There is a growing need for continual learning of neural networks, which requires the network to learn new tasks without forgetting previous knowledge to achieve the stability-plasticity trade-off. Class-incremental Learning \cite{survey1, survey2} is a practical yet difficult setting in continual learning and has obtained much attention recently. 
%
\textbf{Class-incremental Learning (CL)}
Existing methods can be generally divided into three categories: regularization-based \cite{re1, re2, gem, agem}, structure-based \cite{st1, st2, st3}, and replay-based methods \cite{replay1, replay2}. The detailed review can refer to \cite{survey1, survey2}.
% Regularization-based methods aim to impose constraints on the parameter updating to eliminate catastrophic forgetting.
% Concretely, some \cite{re1, re2} devise regularization terms to penalize the update of parameters. Adjusting gradient \cite{gem, agem} during optimization is another way to preserve previous knowledge. Structure-based methods expand the network and freeze selected parameters to prevent forgetting. Specifically, according to whether adding new parameters, methods can be divided into fixed architecture \cite{st3} and dynamic architecture \cite{survey2, ace, gss, st1, st2}, where the former relies on selecting sub-network model that does not infringe upon others and the later focus on expanding networks for new tasks. Replay-based methods \cite{replay1, replay2} preserve examples of fixed memory size to maintain the distribution of old classes in the incremental phases. Selection and retrieval \cite{gss, dvc, sv} strategies for the buffer are also developed to preserve decision boundaries. 
Recently, some practical yet challenging settings of class-incremental learning, including Online Class-Incremental continual Learning (OCL), Non-Exemplar Class-incremental continual Learning (NE-CL), and Few-Shot Class-incremental Learning (FS-CL) are also proposed. Here we give a brief introduction.

\textbf{Online Class-incremental continual Learning (OCL)}
OCL aims to learn new classes continually from online data streams (each sample is seen only once). As the model needs to learn novel classes from the data stream while not forgetting previous classes, OCL methods \cite{survey2, ace, gss, scr, ocm, dvc, rar, ocl2023_1} follow replay-based protocols, where example buffers are stored and retrieved between data batches and tasks. Concretely, \cite{ocm, dvc} dig the critical information by maximizing their mutual information. \cite{rar} design augmentation strategies to address the underfitting-overfitting dilemma of online rehearsal. However, as pointed out by \cite{tl_ocl}, example buffers in OCL violate privacy and computation restrictions, especially in online learning scenarios. However, the example-free task-incremental online continual learning method \cite{tl_ocl} needs the prior task information. Also, even equipped with the example buffers, the state-of-the-art method  \cite{dvc} only achieves relatively low accuracy ($<$20$\%$ for CIFAR100 \cite{cifar100} with 1000 buffer size). Considering these problems, we proposed a novel yet practical setting called NO-CL, which aims to better preserve privacy and utilize pre-trained offline knowledge in practical online applications.

\textbf{Non-Exemplar Class-incremental Learning (NE-CL)}
% Due to computation burden or privacy security, some works \cite{ne-cl-sdc, ne-cl-ss, ne-cl-dd, ne-cl-pa} develop non-exemplar class-incremental learning methods, where no past data can be stored. \cite{ne-cl-sdc} estimates unknown semantic drifts of old classes via the drifts of current classes.
Due to computation burden or privacy security, some works \cite{ne-cl-sdc, ne-cl-ss, ne-cl-dd, ne-cl-pa} develop non-exemplar class-incremental learning methods where no past data can be stored. \cite{ne-cl-sdc} compensates unknown prototype drifts of old classes via the drifts of current data. \cite{ne-cl-pa} employs self-supervised learning to obtain more transferable features. Also, prototypes are also augmented to preserve the decision boundaries of previous classes. Recently, \cite{ne-cl-ss} considers to adjust the joint representation learning and distillation process. However, NE-CL needs to \emph{offline} train novel classes to adjust prototypes and \emph{gradually} distill features. Therefore, NE-CL methods fail to solve the proposed NO-CL problem as analysis and experiments below.

\textbf{Few-Shot Class-incremental Learning (FS-CL)}
Compared to NE-CL, FS-CL assumes that novel classes come with few reference images. State-of-the-art FS-CL methods are mainly divided into two types. Some methods \cite{fs-cl-sak, fs-cl-rkd, fs-cl-, fscl2023_1} update the backbone to accommodate new classes while preserving base class via gradual knowledge distillation \cite{fscl2}, meanwhile, heavily relying on complex example buffers to retain the learned information of the previous network. Some methods \cite{fs-cl-open, fs-cl-hd, fs-cl-s3c} freeze the backbone and re-adopt features from the base classes to recognize new classes. Therefore, contrastive learning \cite{fscl1}, meta-learning \cite{fs-cl-hd}, self-supervised learning \cite{fs-cl-s3c}, and data augmentation \cite{fs-cl-open, fs-cl-fact} strategies have been employed to obtain the backbone with high transferable representations. However, such FS-CL methods finetune the network \emph{offline} and/or do not \emph{fully} explore novel classes, leading to relatively poor performance on NO-CL. 

\textbf{Bi-level Optimization (BO) Problem} Bi-level optimization aims to solve a nested optimization problem, where the outer-level optimization is subjected to the result of the inner-level optimization \cite{bi-level, bi-level-survey}. It has been widely employed in machine learning areas like meta-learning and hyperparameter selection. For CL problems, \cite{bop1} uses BO to alternatively optimize the CL and the exemplar models. \cite{bop2} applies BO to learn the aggregation weights of the plastic and elastic branches of CL models. \cite{bop3} solves the bi-level optimization of the CL model and example compression model. For the proposed NO-CL problem, we formulate dual prototypes and bi-level optimize prototypes and the projection module. The optimization process quickly converges, as shown in Figure \ref{fig2} and Appendix E.

% As for the proposed \textbf{(NO-CL)} problem, there are two intractable obstacles. Firstly, example buffers are prohibited in online scenes. Secondly, without example buffers, how to fully explore single-pass data stream novel classes while preserving previous information. We avoid these issues systematically in NO-CL, where hyperdimensional quasi-orthogonal vectors are assigned to each and every class with the aim of reducing interference



\section{Problem Formulation}
As shown in Figure \ref{fig1_real1}, the NO-CL problem comprises base classes from pre-training data and novel classes from online training data. During online learning, only the raw data of the current classes is available, and the network aims to incrementally learn online new classes whilst retaining learned information before the current session.  
Concretely, assuming an $m$-step NO-CL problem, let $\{ \mathcal{D}_{train}^0,\mathcal{D}_{train}^1,...,\mathcal{D}_{train}^m\} $ and $\{ \mathcal{D}_{test}^0,\mathcal{D}_{test}^1,...,\mathcal{D}_{test}^m\} $ denote the training and testing data from sessions $\{0, 1,..., m\}$, respectively. Each training and testing sessions $i$ have the corresponding label sets denoted by $\mathcal{C}{^i_{train}}$ and $\mathcal{C}{^i_{test}}$. $\mathcal{C}{^i_{train}}$ are mutually exclusive across different training sets, i.e., $\forall i \ne j,\mathcal{C}_{train}^i \cap \mathcal{C}_{train}^j = \phi $. While during evaluation, the model will be tested on all seen classes so far, i.e., for session $i$, the corresponding label space is $\mathcal{C}_{test}^0 \cup \mathcal{C}_{test}^1... \cup \mathcal{C}_{test}^i$. Besides, the base session ($i=0$) provides a large number of classes and also allows offline pre-training. For the incremental sessions ($i>0$), the data comes in the online stream state without rehearsal. During incremental sessions, like NE-CL \cite{ne-cl-sdc, ne-cl-ss}, considering privacy and computation constraints, buffers with raw data are not permitted. 
% Next, we introduce the dataset partition and evaluation metrics. 

\textbf{Dataset Partition.} Similar to \cite{ne-cl-sdc, ne-cl-ss, fs-cl-sp, fs-cl-s3c, fs-cl-open}, the benchmark datasets are divided into ($60\%  + 4\%  \times 10$), where the base session contains $60\%$ classes for pre-training, and the rest classes are online incrementally learned within $10$ sessions. Also, the results of  ($40\%  + 6\%  \times 10$), ($80\%  + 2\%  \times 10$), and ($60\%  + 2\%  \times 20$) are also provided in \textit{\textbf{Appendix B}}.

% \textbf{Evaluation Metrics.} As the number of classes in the base and novel sessions are imbalanced, the traditional class-wise accuracy cannot reflect those which achieve high accuracies on both base and novel classes. Apart from class-wise accuracy, we also employ the harmonic accuracy (HM, i.e., $\rm{HM} = \frac{{2 \times {A_b} \times {A_n}}}{{{A_b} + {A_n}}}$, ${A_b}$ and ${A_n}$ denote the accuracy of base and novel classes) to evaluate the performance balance between base and novel classes.
% \textbf{Evaluation Metrics.}
% Following continual learning literature two standard metrics in the continual learning
% literature to measure performance: Average Accuracy and
% Average Forgetting. Average Accuracy measures the overall performance of testing sets from seen tasks, and Average Forgetting measures how much the learned knowledge the
% algorithm has forgotten.

\section{Methodology}
As for the proposed NO-CL problem, we aim to fully explore single-pass data stream novel classes while preserving previous information without example buffers. The stability-plasticity dilemma is intractable as the single-pass data stream results in the overfitting of novel classes while severely interfering with previously learned information. As NO-CL has no example buffers to rehearse between data batches and tasks to eliminate forgetting.
% Previous OCL \cite{ocm, sv, dvc, scr, rar} methods resort to large example buffers to rehearse between data batches and tasks to eliminate forgetting. 
% Inspired by NE-CL \cite{ne-cl-sdc, ne-cl-ss}, 
we transfer training the whole network to alternatively update the extra projection module and dual prototypes in the bi-level optimization problem. Figure \ref{fig3} shows the framework of the proposed DSR method. In the following section, we introduce the base session training protocol, Dual-prototype Self-augment and Refinement (DSR) for online continual learning, including vanilla-prototype self-augment, bi-level optimization procedure for dual prototypes and projection module.  
% Concretely, Self-augment vanilla prototypes drive the network to learn invariant information and hyperdimensional prototypes gradually push each prototypes away from other. Extra projection module, are  update push away novel class with base classes as well as hyperdimensional prototypes rapidly accommodate unified embeddings of base and novel classes due to its quasi-orthogonal attribute. 

% We avoid these issues of NO-CL systematically, where hyperdimensional quasi-orthogonal vectors are assigned to each and every class with the aim of reducing interference.

% We propose an novel Dual-prototype Self-augment and Refinement (DSR) method, which transfers training the whole network to optimize the extra projection module. Also, self-augment vanilla prototypes drive the
% network to learning invariant information and hyperdimensional embedding rapidly accommodates base
% and novel classes due to its quasi-orthogonal attribute.


\begin{figure*}[t]
\centering
\includegraphics[width=0.8\textwidth]{flow}
\vspace{-0.2cm}
\caption{\textbf{Overview of the proposed DSR method.} The base and novel sessions train in offline and online ways, respectively. V-P, SA-P, and H-P mean vanilla, self-augment, and high-dimensional prototypes. Backbone, projection module, V-P, and H-P are represented by $\theta_1$, $\theta_2$, $\varphi$, and $\phi$. \emph{hist}($\cdot
$) and $G\left( \cdot \right)$ denote histogram and feature transformation (Eq. (2)). \textcolor{yellow}{Yellow} and \textcolor{gray}{Gray} mean the learnable and frozen components, and \textcolor{red}{red} dotted lines represent the refined decision boundaries. 
% During the \emph{inference phase}, cosine similarities are computed between sample embeddings with H-P for classification.
}
\label{fig3}
% \vspace{-0.4cm}
\end{figure*}

\begin{figure}[t]
\centering
% \includegraphics[width=130, angle=-90]{prototype}
\includegraphics[width=1.05\columnwidth]{prototype8-3}
\vspace{-0.4cm}
\caption{t-SNE \cite{tsne} visualization of the feature embeddings. For better visualization, we train eight classes on the base session and incremental learn two classes (marked in \textcolor{green}{green} and \textcolor{red}{red} dots) sequentially. \textcolor{red}{Red circles} in H-P mean the confusion in novel classes and among base and novel classes. Best viewed in color.}
\label{fig4}
\vspace{-0.1cm}
\end{figure}


\subsection{Base Session Training}

For the base session pre-training, we aim to obtain vanilla- and high-dimensional prototypes for sequentially online sessions. Therefore, we employ loss regularizations on the outputs of the feature extractor and projection module: 
\begin{eqnarray}
L^{base}=L^{base}_{vp} + L^{base}_{hp}
\end{eqnarray}
where $L^{base}_{vp}=Loss(Proj_{vp}(\theta_{1}(x)), y)$ and $L^{base}_{vp}=Loss(Proj_{hp}(\theta{_2}(\theta_{1}(x))), y)$. $x$, $y$, $\theta_{1}$, and $\theta_{2}$ denote input samples, labels, feature extractor, and projection module. $Proj_{vp/hp}$ are linear layers to align vanilla- and high-dimensional prototypes for loss calculations. For loss functions ($Loss$), we adopt two variations: cross-entropy (CE) loss and supervised contrastive (SC) loss \cite{scl} (Details please refer to \emph{Appendix A}). To train the robust embedding, recent NE-CL, FS-CL, and OCL methods focus on training diverse features that are transferable across sessions, like data augmentation \cite{fs-cl-open, ne-cl-da, ne-cl-pa}, self-supervised learning \cite{ne-cl-pa, fs-cl-s3c}, mutual information regularization \cite{dvc, ocm}, supervised contrastive regularization \cite{scr, ocl2023_1}. Similarly, for the NO-CL problem, sophisticated pre-training strategies also improves the generalization and transfer ability of our method to accommodate online new classes (refer to Ablation studies with data augmentation \cite{fs-cl-open, il2a} (w/ DA) in Table 3 and Appendix C). 
As shown in Table 1, even the vanilla cross-entropy variation of our method surpasses other dedicated training methods. 


% As we focus on the online class-incremental learning as well as \emph{fair comparisons} with other OCL methods, we utilize the supervised contrastive learning (SCL) \cite{scl} loss in the base session. Note that SCL and its variations have also been used in recent OCL \cite{scr, dvc, ocm}. Concretely, SCL is formulated as:
% \begin{eqnarray}
% L^{scl}=\sum_{i\in I}{\frac{-1}{\left| P\left( i \right) \right|}}\sum_{p\in P\left( i \right)}{\log \frac{\exp \left( z_i\times z_p/\tau \right)}{\sum_{a\in A\left( i \right)}{\exp \left( z_i\times z_a/\tau \right)}}}
% \end{eqnarray}
% where $I$ is the set of indices of Batch ($B_{I}=\{x_{k}, y_{k}, Aug(x_{k}), y_{k}\}{_{k=1...b}}$), which consists of original batch and augmented ($Aug$) view with $2b$ samples. $A(i)=I\backslash \{ i\} $ means the set of indices of all samples in $B_{I}$ except for sample $i$.  $z_{i}=Proj(\rm{HD}$$_{ft})$.  $\rm{HD}$$_{ft}$ is the output features from highembedding projection and  $Proj$ is a multi-layer perceptron 
% % of size 2048 and output vector of 1024.
% with a single hidden layer. $P(i) \equiv \{ p \in A(i):{y_p} = {y_i}\} $ is the set of indices of all positives in the augmented batch distinct from $i$, where $|P(i)|$ is its cardinality. $\tau \in \mathcal{R}^+$ is an temperature parameter. 

% Our method freezes the backbone during online learning, therefore, relies on the embedding ability of the backbone. Compared to others, adding class augmentation and self-supervised learning bring obvious accuracy boosts, as shown in the ablation studies and \textit{\textbf{Appendix B}}.

\subsection{Dual-prototype Self-augment and Refinement}
\textbf{Overview.} After the base session training, the backbone maps the data from the input domain $\mathcal{X}$ to a feature space: ${\theta _1}:\mathcal{X}\rightarrow \mathbb{R}^{d_f}$. ${\theta _1}$ are parameters of backbone. The prototypes in $\mathbb{R}^{d_f}$ are computed and restored to retain previous knowledge. Previous example-free prototype-based methods \cite{ne-cl-sdc, ne-cl-da, ne-cl-pa} offline refine prototypes and/or features together with samples from novel classes to achieve the plasticity and stability trade-off. However, as for online learning, the single-pass data stream fails to gradually update the prototypes and network parameters. Besides, directly classifying novel classes based on frozen backbone fails to fully explore data samples of novel classes. Therefore, we devise dual prototypes strategy and optimize prototypes alternatively
with the projection module through bi-level optimization.
Specially, we introduce the vanilla-prototype self-augment, high-dimensional prototypes and projection module bi-level optimization procedure.


\textbf{Vanilla-prototype Self-augment.} 
We restore the vanilla prototype of the base and novel class to rehearse for retaining and calibrating learned and online information. However, vanilla retrieving previous prototypes will confuse the decision boundary. As a solution, \cite{ne-cl-pa} tries to augment prototypes via Gaussian noise when learning new classes. However, the distribution tends to skew to \emph{0} and loses the discriminative representation, due to the $\rm{relu}$ \cite{relu} activation function in the final layer of the backbone (i.e., ResNet \cite{resnet}). 
% The class-specific class means (i.e., prototypes) tend to cluster together and lose the discriminative representation. 
Therefore, to make feature distribution more Gaussian-like, we transform features similar to Tukey's Ladder of Powers Transformation \cite{tukey}, which is a kind of power transformation that can reduce the skewness of distributions. The  distribution is rectified and normalized as follows:
\begin{eqnarray}
G(x)=\begin{cases}
\frac{x}{\max(\lVert x \rVert_2, \epsilon)} &	if\ \lambda \ne 0\\
\frac{\mathrm{log} (x)}{\max(\lVert \mathrm{log} (x) \rVert_2, \epsilon)} &if\ \lambda =0\\
\end{cases}
\end{eqnarray}
% $v = \frac{v}{\max(\lVert v \rVert_p, \epsilon)}$
% \begin{eqnarray}
% G(x)=\begin{cases}
% {x^\lambda } &	if\ \lambda \ne 0\\
% {\mathrm{log} (x) } &if\ \lambda =0\\
% \end{cases}
% \end{eqnarray}
where $\epsilon=e^{-6}$ and $\lambda$ 
% where $\lambda$ 
is the hyper-parameter to control the distribution, i.e., decreasing $\lambda$ makes the distribution less positively skewed and vice
versa. The Gaussian-like rectification (denoted as $G\left( \cdot \right)$) are applied after the backbone ($\theta _1$) in both base and online sessions as $f=G({\theta _1}(x))$.
For class $i$ in the session $m$, the vanilla prototype ($vp$) and its relative variance ($v$) are computed as:
\begin{small}
\begin{eqnarray} 
vp_{i}^{m }=\frac{1}{|k_i|} {\textstyle\sum_{j=1}^{k_i}}{f_{j}^{m}},\ v _{i}^{ m}=\frac{1}{|k_i|}{\textstyle\sum_{j=1}^{k_i}}{\left( f_{j}^{m}-vp_{i}^{ m } \right)^2}
\end{eqnarray}
\end{small}
where $k_i$ represents the number of samples ($x$) of class $i$ in $\mathcal{D}_{train}^{m}$. Previous knowledge is retained by self-augmenting prototypes from the class-specific Gaussian distribution: 
% $  \hat{vp}_{i}^{\left( m \right)} \sim \mathcal{N}\left( vp_{i}^{\left( m \right)},v_{i}^{\left( m \right)} \right) $
 % $ \varphi^{m}_{i} \sim \mathcal{N}\left( vp_{i}^{\left( m \right)},v_{i}^{\left( m \right)} \right) $. 
$\mathbb{D}(\varphi_i^{m})=\left \{(\varphi_i^{m},i)| \sim \mathcal{N}\left( vp_{i}^{m},v_{i}^{m } \right)  \right \}. $
 Without example buffers, we freeze the backbone $\theta_1$ and translate online class-incremental learning into the bi-level optimization, where the high-dimensional embedding and projection module are proposed to facilitate prototype refinement and calibration.
 
%  However, without example buffers, we can not update the $\theta_1$ to calibrate learned and incremental prototypes like \cite{scr, ocl2023_1}. Thus, we introduce another high-dimensional embedding space, where high-dimensional prototypes are quasi-orthogonality, i.e., easy to differentiate \cite{hd2} that leaves the room to accommodate online
% classes with minimal interference. 
% However, for example-free online sessions, 
% the prototypes of novel classes calculated by frozen backbone tend to be noisy, leading degradation both in base and novel classes, as shown in Figure \ref{fig4} (Novel:V-P).
% % Meanwhile, data samples from previous classes can not be retrieved to adjust the learned prototypes and online classes under-fit the whole network. 
% Thus, we also calculate the high-dimensional prototypes of classes in another high-dimensional embedding space, where high-dimensional prototypes are quasi-orthogonality, i.e., easy to differentiate \cite{hd2} that leaves the room to accommodate online new classes with minimal interference.

% the prototypes of novel classes calculated by frozen backbone tend to be noisy, leading degradation both in base and novel classes, as shown in Figure \ref{fig4} (Novel:V-P).
% % Meanwhile, data samples from previous classes can not be retrieved to adjust the learned prototypes and online classes under-fit the whole network. 
% Thus, we also calculate the high-dimensional prototypes of classes in another high-dimensional embedding space, where high-dimensional prototypes are quasi-orthogonality, i.e., easy to differentiate \cite{hd2} that leaves the room to accommodate online new classes with minimal interference.

\textbf{High-dimensional Prototypes Refinement.}
Recently, Hyperdimensional Computing has been used in computer vision tasks like few shot learning \cite{hd-fsl}, out-of-distribution detection \cite{hd_ood}, and image translation \cite{hd-it}, which leverage quasi-orthogonal high-dimensional representations without inducing much training and inference overhead. As for NO-CL, we project vanilla prototypes into high-dimensional prototypes (H-P) to accommodate online new classes with minimal interference with learned knowledge. The initial H-P ($\phi^{m}$) in the $m$-th online session is obtained based on the single-pass raw data:
% , $i.e.$, $\phi^{m}=\frac{1}{k}\sum_{j=1}^{k}{\left( Proj_{\theta _2}\left( f_{j}^{m} \right) \right)}$, $Proj_{\theta _2}$ represents the projection module with parameters (${\theta _2}$).
% As for NO-CL problem, vanilla prototypes will result in confused decision boundaries as analysis above. Therefore, we project the vanilla prototypes into hyperdimensional space as:
\begin{eqnarray}
\phi^{m}_{i}=\frac{1}{|k_{i}|}{\textstyle\sum_{j=1}^{k_{i}}}{\left( Proj_{\theta _2}\left( f_{j}^{m} \right) \right)}
\end{eqnarray}
where $Proj_{\theta _2}$ represents the projection module with parameters (${\theta _2}$) and $k$ means the number of raw samples of class $i$. 
As we can see in Figure \ref{fig4} (Novel: H-P), though the prototypes have been clustered and separated to some extent in high-dimensional embedding, the overlaps among novel classes and between base and novel classes also exist. 
Therefore, we refine the high-dimensional prototypes of novel classes ($\phi_n$) and re-calibrate the projection module ($\theta_2$) based on refined online H-P ($\phi_{n}$), pre-computed base H-P ($\phi_{b}$), and V-P ($\varphi$). The bi-level optimization object is formulated as follows:
\begin{subequations}
\begin{align}
&\min_{\theta_{2}}[L_{1}(\theta _{2}; \varphi;\phi^\ast_n \cup \phi_b)] 
\\
&{\rm s.t.} \ \phi^\ast_n  = \arg\min\limits_{\phi_n }L _{2}(\phi_n ;\phi_b)
\end{align}
\end{subequations}

\begin{algorithm}[t]  %其中这里面不能有H不然会报错，不过不影响结果
	\caption{Training procedure of DSR.}%算法名字
	\LinesNumbered %要求显示行号
	\KwIn{Training data $\{ \mathcal{D}_{train}^0,\mathcal{D}_{train}^1,...,\mathcal{D}_{train}^m\} $, base epoch $n_1$, online iteration $T$}%输入参数
	\KwOut{Optimal $\theta _{1}$, $\theta _{2}$, and $\phi_n$}%输出
	\textbf{Initialize:} $\theta _{1}$, $\theta _{2}$; 
 
        \textbf{Base Session:} 
        \emph{// train $\theta _{1}^{0}$ and $\theta _{2}^{0}$}
        
	\While{epoch $< n_1$} {
        train $\theta _{1}^{0}$ and $\theta _{2}^{0}$ with Eq. (1).	
	}
        Obtain $\varphi^{0}$ and $\phi^{0}$ with Eq. (3)\&(4);  \\  
         \textbf{Online Session:} 
         \emph{// bi-level optimize $\theta _{2}$ and $\phi_n$}\\    
	\For {incremental sessions $M \in \{1,2...m\}$}{

        \KwIn{$\theta _{1}^{M-1}$, $\theta _{2}^{M-1}$, $\varphi^{M-1}$ $\phi^{M-1}$, $\mathcal{D}_{train}^M$.} \
        \KwOut{$\theta _{1}^{M}$, $\theta _{2}^{M}$, $\varphi^{M}$, $\phi^{M}$.}\
        $\theta _{1}^{M}\leftarrow \theta _{1}^{M-1}$; \\
        Obtain $\varphi^{M}$ and $\phi^{M}$ with Eq. (3)\&(4);  \\     
        \While{$t$ $< T$ or not converged}{
        \emph{--inner-level optimization--}\\ 
        Update $\phi^{M}$ with Eq. (9); \\
        \emph{--outer-level optimization--}\\ 
        Update $\theta_2^{M}$ with Eq. (11);
	}
        }
\end{algorithm}
% \vspace{-0.3cm}



In the following, we elaborate on the implementation details for the bi-level optimization. 

In the \textbf{inner-level optimization}, i.e., Eq. (5b), as analyzed above, to eliminate the overlaps in H-P ($\phi$), we refine $\phi_n$ by decreasing the cosine similarity of H-P among inter-novel classes ($L^{in}$), and between base and novel classes ($L^{bn}$), respectively. The formulas are as follows:

\begin{flalign}\label{equ1}
L _{2}(\phi_n ;\phi_b) = L^{in}(\phi_n)+L^{bn}(\phi_n, \phi_b)
\end{flalign}
\begin{flalign}\label{equ1}
L^{in}(\phi_n) =\sum_{i,j=1,s.t.\ i\ne j}^{|\phi_{n}|}{< \sigma (\phi_{n}^i) ,\sigma (\phi_{n}^j) >}
\end{flalign}
\begin{flalign}\label{equ1}
L^{bn}(\phi_n) ={\textstyle\sum_{i=1}^{|\phi_{n}|}}{{\textstyle\sum_{j=1}^{|\phi_{b}|}}{< \sigma \left( \phi_{n}^i \right) ,\sigma \left(\phi_{b}^j \right) >}}
\end{flalign}

where $<$$\cdot$,$\cdot$ $>$ and $\sigma$ mean cosine similarity and tanh activation function. Moreover,  to avoid significant deviations from the original representations, $\phi_n$ updates in the exponential moving average strategy (EMA):
\begin{flalign}\label{equ2}
\phi^\ast_n=\alpha \phi_n+\left( 1-\alpha \right) \left( \phi_n-\gamma \bigtriangledown _{\phi_n} L _{2}(\phi_n ;\phi_b) \right) 
\end{flalign}
where $\alpha$ is the momentum hyper-parameter($\alpha$ = 0.9 in this paper), and $\gamma$ is the learning rate. 


\begin{table*}[] \centering
{\fontsize{7.5pt}{8pt}\selectfont
\renewcommand\arraystretch{1.3}
\begin{tabular}{l|clcl|clclclcl}
\hline
{\textbf{Methods}} & \multicolumn{4}{c|}{\textbf{CORE-50}}                                                           & \multicolumn{4}{c|}{\textbf{CIFAR100}}                                                          & \multicolumn{4}{c}{\textbf{Mini-ImageNet}}                                                    \\ \hline
\textbf{Metrics} & \multicolumn{4}{c|}{\textbf{Acc}(base/novel)$|$\textbf{HM}}                                                & \multicolumn{4}{c|}{\textbf{Acc}(base/novel)$|$\textbf{HM}}                                               & \multicolumn{4}{c}{\textbf{Acc}(base/novel)$|$\textbf{HM}}                                               \\ \hline
FACT   & \multicolumn{4}{c|}{43.0(52.6 /28.7)$|$37.1}                                                & \multicolumn{4}{c|}{44.8(56.1/27.9)$|$37.2}                                               & \multicolumn{4}{c}{45.5(58.3/26.4)$|$36.3}                                               \\ 
ALICE   & \multicolumn{4}{c|}{41.5(50.6/27.8)$|$25.9}                                                & \multicolumn{4}{c|}{43.5(56.3/24.2)$|$33.8}                                             & \multicolumn{4}{c}{45.8(59.2/25.7)$|$35.8}                                             \\ 
\hline
PASS    & \multicolumn{4}{c|}{37.9(62.9/0.5)$|$1.0}                                                & \multicolumn{4}{c|}{38.6(63.7/0.9)$|$1.8}                                               & \multicolumn{4}{c}{39.4(64.9/1.2)$|$2.4}                                               \\
SSRE   & \multicolumn{4}{c|}{---}                                                                 & \multicolumn{4}{c|}{39.8(66.2/0.5)$|$1.0}                                               & \multicolumn{4}{c}{---}                                                                \\ \hline
\textbf{MS}      & \multicolumn{2}{c|}{\emph{1000}}            & \multicolumn{2}{c|}{\emph{2000}}           & \multicolumn{2}{c|}{\emph{1000}}           & \multicolumn{2}{c|}{\emph{2000}}           & \multicolumn{2}{c|}{\emph{1000}}           & \multicolumn{2}{c}{\emph{2000}}  \\ \hdashline
% GSS\cite{gss}     & \multicolumn{2}{c|}{18.4(19.3/17.1)$|$18.1} & \multicolumn{2}{c|}{20.8(22.3/18.6)$|$20.3} & \multicolumn{2}{c|}{21.5(22.7/19.8)$|$21.2} & \multicolumn{2}{c|}{23.4(24.2/22.1)$|$24.2} & \multicolumn{2}{c|}{18.9(19.8/17.6)$|$18.6} & \multicolumn{2}{c}{21.1(21.9/19.7)$|$20.7} \\
MIR     & \multicolumn{2}{c|}{22.6(24.6/19.7)$|$21.9}  & \multicolumn{2}{c|}{24.5(26.9/20.9)$|$23.5} & \multicolumn{2}{c|}{24.2(26.4/20.9)$|$23.3} & \multicolumn{2}{c|}{25.1(27.1/22.0)$|$24.3} & \multicolumn{2}{c|}{22.9(24.6/20.3)$|$22.2} & \multicolumn{2}{c}{23.8(25.7/21.0)$|$23.1} \\
GD  & \multicolumn{2}{c|}{25.8(27.0/23.9)$|$25.8}  & \multicolumn{2}{c|}{27.5(29.3/24.9)$|$26.9} & \multicolumn{2}{c|}{25.8(27.2/23.8)$|$25.4} & \multicolumn{2}{c|}{27.1(28.6/24.9)$|$26.6} & \multicolumn{2}{c|}{23.2(24.6/22.4)$|$23.1} & \multicolumn{2}{c}{24.4(25.1/23.3)$|$24.4} \\
% DER++   & \multicolumn{2}{c|}{27.5(28.7/25.8)$|$27.2}  & \multicolumn{2}{c|}{28.8(30.2/26.6)$|$28.3} & \multicolumn{2}{c|}{27.8(29.4/25.3)$|$27.2} & \multicolumn{2}{c|}{30.2(32.9/26.1)$|$29.1} & \multicolumn{2}{c|}{26.0(27.6/23.6)$|$25.4} & \multicolumn{2}{c}{28.6(29.9/26.7)$|$28.2} \\
ASER    & \multicolumn{2}{c|}{29.4(30.6/27.6)$|$29.0}  & \multicolumn{2}{c|}{31.4(33.6/28.0)$|$30.5} & \multicolumn{2}{c|}{30.7(31.4/29.6)$|$30.5} & \multicolumn{2}{c|}{33.6(34.9/31.6)$|$33.2} & \multicolumn{2}{c|}{25.4(27.8/21.7)$|$24.5} & \multicolumn{2}{c}{29.7(30.4/28.6)$|$29.5} \\
SCR     & \multicolumn{2}{c|}{39.4(38.0/41.5)$|$39.7}  & \multicolumn{2}{c|}{40.7(41.3/39.8)$|$40.5} & \multicolumn{2}{c|}{37.1(41.2/35.6)$|$38.3} & \multicolumn{2}{c|}{41.9(44.8/38.1)$|$41.1} & \multicolumn{2}{c|}{36.2(35.7/36.4)$|$36.1} & \multicolumn{2}{c}{38.8(44.2/30.9)$|$36.4} \\
SCR$_{ft}$      & \multicolumn{2}{c|}{39.6(46.2/29.8)$|$36.2}  & \multicolumn{2}{c|}{43.6(51.6/31.6)$|$39.2} & \multicolumn{2}{c|}{39.6(50.1/23.8)$|$32.3} & \multicolumn{2}{c|}{42.1(53.8/24.6)$|$33.8} & \multicolumn{2}{c|}{38.8(43.9/30.8)$|$36.2} & \multicolumn{2}{c}{42.8(47.8/35.6)$|$40.8} \\
OCM     & \multicolumn{2}{c|}{41.0(41.8/39.8)$|$40.8}  & \multicolumn{2}{c|}{42.5(43.1/41.6)$|$42.3} & \multicolumn{2}{c|}{37.3(37.8/36.6)$|$37.2} & \multicolumn{2}{c|}{41.6(42.6/40.1)$|$41.3} & \multicolumn{2}{c|}{37.2(36.3/38.6)$|$36.1} & \multicolumn{2}{c}{40.9(45.8/33.6)$|$38.8} \\
OCM $_{ft}$     & \multicolumn{2}{c|}{41.1(46.5/33.1)$|$38.7}  & \multicolumn{2}{c|}{43.7(48.1/37.2)$|$41.9} & \multicolumn{2}{c|}{40.8(46.3/32.6)$|$38.3} & \multicolumn{2}{c|}{42.3(46.9/35.4)$|$40.3} & \multicolumn{2}{c|}{39.0(40.6/36.8)$|$38.2} & \multicolumn{2}{c}{41.2(42.7/39.1)$|$40.8} \\
DVC     & \multicolumn{2}{c|}{39.9(39.6/40.5)$|$40.0}  & \multicolumn{2}{c|}{41.8(42.8/40.5)$|$41.6} & \multicolumn{2}{c|}{38.6(38.1/39.2)$|$38.9} & \multicolumn{2}{c|}{41.8(42.6/39.4)$|$41.2} & \multicolumn{2}{c|}{35.6(34.4/37.3)$|$35.9} & \multicolumn{2}{c}{38.4(36.9/41.2)$|$38.9} \\ 
DVC$_{ft}$     & \multicolumn{2}{c|}{41.9(48.2/32.6)$|$38.9}  & \multicolumn{2}{c|}{43.7(48.7/36.1)$|$41.5} & \multicolumn{2}{c|}{39.0(43.2/32.7)$|$37.2} & \multicolumn{2}{c|}{40.5(43.6/36.0)$|$39.4} & \multicolumn{2}{c|}{36.2(39.8/30.9)$|$34.8} & \multicolumn{2}{c}{39.3(40.8/37.0)$|$38.8} \\ \hline
\rowcolor{WhiteSmoke} \textbf{Ours(+CE)}  & \multicolumn{4}{c|}{46.8$\textcolor{red}{+3.1}$(47.6/45.7)$|${46.6}}                                              & \multicolumn{4}{c|}{{45.8$\textcolor{red}{+1.0}$}(50.0/39.6)$|${44.2}}                                             & \multicolumn{4}{c}{{47.7$\textcolor{red}{+1.9}$}(52.6/40.3)$|${45.6}}                                             \\  
\rowcolor{WhiteSmoke} \textbf{Ours(+SC)}  & \multicolumn{4}{c|}{\textbf{49.1$\textcolor{red}{+5.4}$}(49.6/48.4)$|$\textbf{50.0}}                                              & \multicolumn{4}{c|}{\textbf{48.6$\textcolor{red}{+3.8}$}(52.4/42.9)$|$\textbf{47.2}}                                             & \multicolumn{4}{c}{\textbf{50.7$\textcolor{red}{+4.9}$}(56.1/42.6)$|$\textbf{48.4}}                                             \\  \hline

\end{tabular}
% \vspace{-0.3cm}
\caption{Class-wise accuracy ($\textbf{Acc}$) by the end of the training of all classes, base classes, and novel classes. Harmonic accuracy (\textbf{HM}) is also illustrated. \textbf{MS} and $_{ft}$ mean the example memory size and finetuning versions. The best results are in \textbf{bold}.}
% \vspace{-0.1cm}
}
\end{table*}

The aim of the \textbf{outer-level optimization}, i.e., Eq. (5a), is to re-calibrate projection module ($\theta_2$) based on refined $\phi^\ast_n$ and $\phi_b$ by self-augmenting vanilla prototypes from pre-computed $\mathbb{D}(\varphi)$. The optimization of $\theta _{2}$ is as follows:
\begin{small}
\begin{eqnarray}
L _{1}(\theta _{2}; \varphi;\phi^\ast_n \cup \phi_b )=-{\textstyle\sum_{i=1}^{\mathcal{C}}}{\textstyle{\sum_{k=1}^K} <{\theta _{2}\left( \mathbb{D}(\varphi) \right) ,\phi^\ast_n \cup \phi_b >}}
\end{eqnarray}
\begin{eqnarray}
\theta _{2}=\theta _{2}-\beta \bigtriangledown _{\theta _{2}} L _{1}(\theta _{2}; \varphi;\phi^\ast_n \cup \phi_b)
\end{eqnarray}
\end{small}
where $\beta$ is the learning rate, $\mathcal{C}$ and $K$ are the number of learned classes and sampled prototypes, respectively. 

For inference, cosine similarities are computed between sample embeddings and H-P ($\phi$) of learned classes ($\mathcal{C}$) for classification: $\mathrm{pred} = \arg\max\limits_{i=1,.,\mathcal{C}}<\theta{_2}(G(\theta{_1}(x))), \phi{_i}>$.


 % Dual prototypes bi-level optimization has two benefits: firstly, for class-incremental learning, we avoid frequently retrieving previous example samples while jointly retraining augmented prototypes of all classes to eliminate class imbalance problem\cite{luc, lsil}. Secondly, for OCL, projecting the noisy V-P to high-dimensional embedding anchored in refined H-P makes the model easily and robustly accommodate online new classes. 



% Therefore, we propose a high-dimensional prototypes refinement method
% and jointly optimize the projection module via the augmented prototypes of learned classes to map the V-P to aligned H-P. The whole refinement procedure contains \textbf{three steps}. 





% \textbf{Firstly,} as the base classes are well trained, we only update H-P of novel classes by decreasing the cosine similarity of inter-novel classes ($L^{in}$), and between base and novel classes ($L^{bn}$), respectively. 
% \begin{flalign}\label{equ1}
% L^{hr}\left( hp^{\left( t \right)} \right) = L^{in}\left( hp^{\left( t \right)} \right)+L^{bn}\left( hp^{\left( t \right)} \right)
% \end{flalign}
% \begin{flalign}\label{equ1}
% L^{in}\left( hp^{\left( t \right)} \right) =\sum_{i,j=1,s.t.\ i\ne j}^{|hp_{novel}|}{\cos \left( \sigma \left( hp_{i}^{\left( t \right)} \right) ,\sigma \left( hp_{j}^{\left( t \right)} \right) \right)}
% \end{flalign}
% \begin{flalign}\label{equ1}
% L^{bn}\left( hp^{\left( t \right)} \right) =\sum_{i=1}^{|hp_{novel}|}{\sum_{j=1}^{|hp_{base}|}{\cos \left( \sigma \left( hp_{i}^{\left( t \right)} \right) ,\sigma \left( hp_{j}^{\left( t \right)} \right) \right)}}
% \end{flalign}
% where $t$ means the $T$ iterations. cos($\cdot$,$\cdot$) and $\sigma$ mean cosine similarity and hyperbolic tangent activation function. Moreover,  to avoid significant deviations from the original representations, $hp$ updates in the exponential moving average strategy (EMA):
% \begin{flalign}\label{equ2}
% hp^{\left( t+1 \right)}=\alpha hp^{\left( t \right)}+\left( 1-\alpha \right) \left( hp^{\left( t \right)}-\gamma \frac{\partial \left( L^{hr}\left( hp^{\left( t \right)} \right) \right)}{\partial \left( hp^{\left( t \right)} \right)} \right) 
% \end{flalign}
% where $\alpha$ is the momentum high-parameter to control the weight of fusion, generally close to 1 ($\alpha$ = 0.99 in this paper), and $\gamma$ is the learning rate. 

% \textbf{Secondly,} based on refined H-P, we sample from class-specific Gaussian distribution from V-P as augmented prototypes and jointly optimize the projection module ($Proj_{\theta _2}$) to fit the refined H-P. The projection module is used as:     
% \begin{eqnarray}
% L_{i-h}^{\left( t \right)}=\frac{-1}{|\mathcal{C}|}\sum_{i=1}^{|\mathcal{C}|}{\frac{1}{K}\sum_{k=1}^K{\cos \left( Proj_{\theta _{2}^{\left( t \right)}}\left( \hat{vp}_{i}^{k} \right) ,hp_i \right)}}
% \end{eqnarray}
% \begin{eqnarray}
% Proj_{\theta _{2}^{\left( t+1 \right)}}=Proj_{\theta _{2}^{\left( t \right)}}-\beta \frac{\partial L_{i-h}^{\left( t \right)}}{\partial Proj_{\theta _{2}^{\left( t \right)}}}
% \end{eqnarray}
% where $\beta$ is the learning rate, $|\mathcal{C}|$ and $K$ are the number of learned classes and sampled prototypes, respectively. The second step has two benefits: firstly, for class-incremental learning, we avoid frequently retrieving previous example samples while jointly retraining augmented prototypes of all classes to eliminate class imbalance problem\cite{luc, lsil}. Secondly, for OCL, projection the noisy V-P to high-dimensional embedding anchored in refined H-P makes the model easily and robustly accommodate online new classes. 

% \textbf{Thirdly,} as the initial H-P is directly inferred via the single pass data of novel classes, it lacks the interaction of base and novel classes though have been refined by Eq.(8). With the $Proj$$_{\theta _{2}}$, which has been well-trained via self-augment prototypes from all classes, the H-P of novel classes is updated in the exponential moving average strategy:
% \begin{flalign}\label{equ2}
% hp_{i}^{t+1}=\alpha hp_{i}^{t}+\left( 1-\alpha \right) \frac{1}{N}\sum_{n=1}^N{Proj_{\theta _2}\left( \hat{i}p_{i}^{n} \right)}
% \end{flalign}
% where $N$ is the number of samples from Gaussian distribution and $i\in\mathcal{C}_{novel}$ represents the novel classes. We optimize the $Proj$$_{\theta _{2}}$ and H-P with these three steps in a greedy way until reach the maximum iteration or cosine similarity convergence. \textbf{Algorithm 1} presents the pseudo-code of the whole procedure. As we train the lightweight projection module with prototypes rather than raw data, the whole procedure is efficient, as shown in Figure \ref{fig2} and \textit{\textbf{Appendix E}}.
% Finally, during the inference phase, by comparing the cosine similarities between a query ($x$) from the network and H-P. We compute the score $l_i$ for class $i \in \mathcal{C}$ as:
% \begin{flalign}\label{equ2}
% l_i=\cos \left( hp_i,Proj_{\theta _2}\left( G\left( B_{\theta _1}\left( x \right) \right) \right) \right) 
% \end{flalign}


\section{Experiments}
\textbf{Datasets and Evaluation Protocols.}
As mentioned in section 3, the benchmark datasets are divided into ($60\%  + 4\%  \times 10$), where the base session contains $60\%$ classes for base session training, and the rest of the classes are online incrementally learned within $10$ sessions. Other splits are also provided in \textbf{\textit{Appendix B}}. We conduct experiments on three widely used datasets, including CORE-50 \cite{core50}, CIFAR 100 \cite{cifar100}, and Mini-ImageNet \cite{miniimagenet}, which have 50, 100, and 100 classes, respectively.  
Following recent class-incremental learning methods \cite{survey1, survey2}, class-wise average accuracy (Acc) and average forgetting (A${_f}$) are applied to evaluate the performance. Meanwhile, for the NO-CL problem, the number of base and novel classes is unbalanced. To evaluate the overall performance of the stability-plasticity dilemma, we also employ harmonic metric 
% (HM, i.e., $\rm{HM}$ = $\frac{{2 \times {Acc_b} \times {Acc_n}}}{{{Acc_b} + {Acc_n}}}$, $\mathrm${Acc$_b$}  and $\mathrm${Acc${_n}$} denote the accuracy of base and novel classes) 
like \cite{fs-cl-s3c, fs-cl-open}.

\textbf{Comparison Methods.}
We compare DSR with three categories baselines: (1) OCL: GD\cite{gdumb}, MIR \cite{mir}, ASER \cite{sv}, SCR \cite{scr}, OCM \cite{ocm}, DVC \cite{dvc}. (2) NE-CL: PASS \cite{ne-cl-pa}, SSRE \cite{ne-cl-ss}. (3) FS-CL: FACT \cite{fs-cl-fact}, ALICE \cite{fs-cl-open}. All comparisons are trained and inferred in the \textbf{same protocols} of NO-CL.


\begin{figure}[t]
\centering
% \includegraphics[width=130, angle=-90]{prototype}
\includegraphics[width=1.0\columnwidth]{3-52}
\vspace{-0.3cm}
\caption{The line chart represents class-wise average accuracy of SOTA methods (DVC\cite{dvc}, OCM\cite{ocm}, PASS\cite{ne-cl-pa}, and ALICE \cite{fs-cl-open})  along the incremental sessions.}
\label{fig5}
\vspace{-0.2cm}
\end{figure}



\textbf{Implementation details.}
Following \cite{dvc, ocm}, we employ a reduced ResNet-18 as the backbone without pre-training. We use stochastic gradient descent with a learning rate of 0.1 with a batch size of 100 during the base session. The dimension of high-dimensional embedding is 2048, and $Proj_{\theta _2}$ is implemented as a two-layer MLP with a hidden layer of 512 dimensions with $\rm{relu}$ as the activation function. For other hyper-parameters, we set the base session training epoch $n_1$, online iteration $T$ to 100, 20, set online learning rate $\gamma$, $\beta$ all to 0.01, set feature transform coefficient $\lambda$ and the number of sampled prototypes $K$ to 0.5, 20. Analysis of hyper-parameters is performed in \textbf{\textit{Appendix D}}. As for compared methods, we adopt the \textbf{same training protocols} of NO-CL as ours and adopt the defaulted hyper-parameters of their methods (please refer to \textbf{\textit{Appendix A}}). We report the mean result of all methods over ten different runs.




\subsection{Results and Ablation Studies}
\textbf{Comparing with the State-of-the-art.} We compare our method (+CE and +SC loss versions) with other SOTA methods in the setting of the proposed NO-CL problem. The results are illustrated in Tables 1 and 2 and Figure \ref{fig5}, which give the following observations. \textbf{1).} 
Overall, in terms of class-wise accuracy, our method with CE and SC loss achieves pleasant results, especially with SC loss, which outperforms others by 5.4$\%$, 3.8$\%$, and 4.9$\%$ in CORE-50, CIFAR100, and Mini-ImageNet, respectively. Note that SOTA methods like FACT, ALICE, PASS SCR, OCM, and DVC adopt sophisticated pre-training strategies like self-supervised learning, supervised contrastive learning, data augmentation etc. For harmonic accuracy (HM), which measures the performance of stability-plasticity trade-offs, ours also exceed other methods by a large margin. Our method also outperforms OCL methods, which employ large example buffers, in most cases for average forgetting metrics.  \textbf{2).} Concretely. for OCL methods, though equipped with large example buffers and pre-trained information, the over-fitting and catastrophic forgetting problems are also severe compared to ours. To avoid these issues, similar to ours, we freeze the backbone after base session training and only jointly finetune the classifier head with online data and buffer samples (denoted as $_{ft}$). As we can see from SCR$_{ft}$, OCM$_{ft}$, and DVC$_{ft}$, simply freezing the backbone can not achieve the stability-plasticity trade-off that though base knowledge can be better preserved while damaging the ability to learn online novel classes. Although large example buffers and frequent rehearsal can eliminate these issues, which somewhat violate the online learning protocols. \textbf{3).} As for NE-CL methods, PASS and SSRE fail to learn the novel classes in online sessions. Due to the lack of old class samples, PASS and SSRE promote knowledge transfer in the progressive knowledge distillation process, while the distillation constraints hamper the online learning of novel classes. \textbf{4).} For the FS-CL methods, FACT and ALICE focus on training generalization feature representations during the base session. They directly infer novel classes based on robust embedding. However, without adjusting the representation, ALICE fails in a large number of sessions, as shown in the last few sessions in Figure \ref{fig5} and $60\%  + 2\%  \times 20$ configuration in \textit{\textbf{Appendix B}}. Note that NE-CL methods, i.e., PASS and SSRE, employ the more sophisticated pre-training strategy, which perform slightly better than ours in the base session. \textbf{3).} Moreover, as for computation overhead during online learning, which is usually considered in OCL scenarios \cite{tl_ocl}, as shown in Figure \ref{fig2}, our method only consumes $ \sim $ 35 seconds and minimal memory overhead in CIFAR100 dataset. More quantitative results of computation overhead are in \textbf{\textit{Appendix E}}. 

\begin{table}[]\centering 
\scriptsize
\begin{tabular}{l|cl|cl|cl}
\hline
\multicolumn{1}{c|}{\textbf{Method}} & \multicolumn{2}{c|}{\textbf{CORE-50}}   & \multicolumn{2}{c|}{\textbf{CIAFR 100}} & \multicolumn{2}{c}{\textbf{Mini-ImageNet}} \\ \hline
\textbf{MS}                          & \multicolumn{2}{c|}{\textit{1000/2000}} & \multicolumn{2}{c|}{\textit{1000/2000}} & \multicolumn{2}{c}{\textit{1000/2000}}     \\ \hline
SCR                                  & \multicolumn{2}{c|}{10.8/9.2}           & \multicolumn{2}{c|}{13.2/9.6}           & \multicolumn{2}{c}{15.3/12.3}              \\
SCR$_{ft}$                                & \multicolumn{2}{c|}{8.3/7.6}            & \multicolumn{2}{c|}{7.2/\textbf{6.7}}            & \multicolumn{2}{c}{9.3/8.4}                \\ \hline
OCM                                  & \multicolumn{2}{c|}{15.2/12.6}          & \multicolumn{2}{c|}{16.1/13.4}          & \multicolumn{2}{c}{16.9/12.3}              \\
OCM$_{ft}$                               & \multicolumn{2}{c|}{9.3/8.1}            & \multicolumn{2}{c|}{10.6/7.6}           & \multicolumn{2}{c}{11.7/9.1}               \\ \hline
DVC                                  & \multicolumn{2}{c|}{11.3/10.8}          & \multicolumn{2}{c|}{14.3/12.0}          & \multicolumn{2}{c}{16.9/13.4}              \\
DVC$_{ft}$                                & \multicolumn{2}{c|}{8.7/7.9}            & \multicolumn{2}{c|}{9.2/8.6}            & \multicolumn{2}{c}{11.8/9.7}               \\ \hline
\rowcolor{WhiteSmoke}\textbf{Ours(+CE)}                                 & \multicolumn{2}{c|}{{7.6}}       & \multicolumn{2}{c|}{7.8}       & \multicolumn{2}{c}{{9.0}}           \\ 
\rowcolor{WhiteSmoke}\textbf{Ours(+SC)}                                 & \multicolumn{2}{c|}{\textbf{7.3}}       & \multicolumn{2}{c|}{6.9}       & \multicolumn{2}{c}{\textbf{8.2}}           \\ \hline
\end{tabular}
% \vspace{-0.3cm}
\caption{ Average forgetting (\textbf{A$_f$}, lower is better) results.}
% \vspace{-0.3cm}
\end{table}


\textbf{Ablation Studies.}
\textbf{(1) The necessity of DSR strategy:} To overall validate the necessity of DSR strategy, we directly infer with the prototypes from the high-dimensional embedding (denoted as baseline). For example-free online sessions, Though quasi-orthogonal high-dimensional representations preserve the pre-trained information and accommodate online new classes to some extent, the baseline does not fully leverage the online data stream and fails in all class-wise accuracy and HM metrics. Moreover, based on the baseline, we directly optimize the H-P with the $L_2$ (Eq. (6)) function (baseline+$L_2$). Note that for the proposed NO-CL, we have no example buffer to re-calibrate the backbone ($\theta_1$). Direct optimization prototypes results in degrading performance.  
\textbf{(2) The effectiveness of each component:} We ablate Gaussian-like rectification (w/o $G\left( \cdot \right)$) and directly revisit the prototype without sampling repeatedly from Gaussian distributions (w/o SA-P). We can see that the Gaussian-like rectification brings $\sim$1.5$\%$ gains via reducing the skewness of distributions. Augmented prototypes significantly preserve the decision boundaries of previous classes while also being beneficial to the overall performance through joint optimization. To prove the effectiveness of amending prototypes in the high-dimensional embedding (w/o HD), we project the vanilla prototypes to low-dimensional embedding (256) instead of high dimension (2048). The performance of both base and novel classes degrades, particularly in novel classes. The reason is that prototypes in low-dimensional embedding require dedicated alignments, otherwise resulting in confusion both in base and novel classes, which is not suitable for NO-CL. More ablations can refer to \textit{\textbf{Appendix D}}.
\textbf{(3) The importance of the base session training:}  We adopt the data augmentation strategy (w/ DA) proposed by \cite{fs-cl-open, il2a} in the base training session to obtain diverse and transferable representations. More base session training strategies please refer to \textit{\textbf{Appendix C}}. We learn that the robust embedding improves our method by a large margin, both in preserving old classes and online accommodating novel classes, which provides a direction to solve the proposed NO-CL problem.     

% To validate the effectiveness of each module of our method, we perform ablation studies on CIFAR 100 and Mini-ImageNet datasets, as shown in Table 2. Concretely, \textbf{for vanilla-prototype self-augment stage}, we ablate Gaussian-like rectification (w/o $G\left( \cdot \right)$) and directly revisit the prototype without sampling repeatedly from Gaussian distributions (w/o SA-P). We can see that the Gaussian-like rectification brings 2.3$\%$ gains via reducing the skewness of distributions. Augmented prototypes significantly preserve the decision boundaries of previous classes while also being beneficial to the overall performance through joint optimization. \textbf{For high-dimensional prototypes refinement stage}, we remove the first refinement procedure (w/o 1\emph{st}) in Eq. (5). The performance degrades to some extent, especially for the novel classes. To prove the effectiveness of amending prototypes in the high-dimensional embedding (w/o HD), we project the vanilla prototypes to low-dimensional embedding (256) instead of high dimension (2048). The performance of both base and novel classes degrades, particularly in novel classes. The reason is that prototypes in low-dimensional embedding require dedicated alignments, otherwise resulting in confusion both in base and novel classes, which is not suitable for example-free OCL. Besides, we ablate the third step (w/o 3 $rd$) in Eq. (11). The performance of novel classes degrades more severely than base classes due to lacking prototypes alignment through the optimized projection layer. Moreover, all the ablation configurations also achieve comparative performance, even compared with OCL methods with large example buffers, which validates the effectiveness of the dual prototypes strategy. \textbf{To evaluate the overall performance}, we adopt the data augmentation strategy (w/ DA) proposed by \cite{fs-cl-open} in the base training session to obtain diverse and transferable representations. We can learn that the robust offline network improves our method by a large margin, both in preserving old classes and online accommodating novel classes, which validates the effectiveness of our method.       


\begin{table}[t] \centering
\scriptsize
\renewcommand\arraystretch{1.35}
\begin{tabular}{ll|cl|cl}
\hline
\multicolumn{2}{l|}{\textbf{Ablations}} & \multicolumn{2}{c|}{\textbf{CIFAR100}}    & \multicolumn{2}{c}{\textbf{Mini-ImageNet}} \\ \hline
\multicolumn{2}{l|}{\textbf{Metrics}}        & \multicolumn{2}{c|}{\textbf{Acc}(base/novel)$|$\textbf{HM}}   & \multicolumn{2}{c}{\textbf{Acc}(base/novel)$|$\textbf{HM}}     \\ \hline
\multicolumn{2}{l|}{baseline}                & \multicolumn{2}{c|}{43.4(54.2/27.4)$|$36.3} & \multicolumn{2}{c}{43.7(57.1/23.6)$|$33.4}   \\ 
\multicolumn{2}{l|}{baseline+$L_2$}                & \multicolumn{2}{c|}
{38.9(52.3/18.9)$|$27.8} & \multicolumn{2}{c}{40.2(54.9/18.1)$|$27.2}   \\ \hline
\multicolumn{2}{l|}{w/o $G\left( \cdot \right)$}   & \multicolumn{2}{c|}{47.1(51.0/41.3)$|$45.6} & \multicolumn{2}{c}{49.1(54.3/41.4)$|$47.0}   \\
\multicolumn{2}{l|}{w/o SA-P}                & \multicolumn{2}{c|}{46.2(50.5/39.7)$|$44.4} & \multicolumn{2}{c}{47.5(53.9/37.9)$|$44.5}   \\ 
\multicolumn{2}{l|}{w/o HD}                  & \multicolumn{2}{c|}{46.7(51.6/39.4)$|$44.7} & \multicolumn{2}{c}{48.5(54.7/39.3)$|$45.7}   \\ \hline
\rowcolor{WhiteSmoke}\multicolumn{2}{l|}{\textbf{Ours}}                    & \multicolumn{2}{c|}{48.6(52.4/42.9)$|$47.2} & \multicolumn{2}{c}{50.7(56.1/42.6)$|$48.4}   \\ \hline
\rowcolor{WhiteSmoke}\multicolumn{2}{l|}{\textbf{Ours w/ DA}}               & \multicolumn{2}{c|}{51.2(55.7/44.6)$|$49.5} & \multicolumn{2}{c}{53.2(58.2/45.8)$|$51.3}   \\ \hline
\end{tabular}
% \vspace{-0.3cm}
\caption{\textbf{Ablation studies} on CIFAR100 and Mini-ImageNet. Experiments are conducted with the SC loss.}
% \vspace{-0.1cm}
\end{table}


\section{Conclusion}

In this paper, we formulate a novel, practical, but challenging problem named Non-exemplar Online class-incremental Continual Learning (NO-CL), which aims to preserve pre-trained base classes information, while efficiently learning novel classes continually from the single-pass (i.e., online) data stream, without example buffers. To solve this problem, we have proposed a novel Dual-prototype Self-augment and Refinement (DSR) method, which presents two solutions: 1) Dual class prototypes: vanilla and high-dimensional prototypes (V-P and H-P) are maintained to utilize the pre-trained information and obtain robust quasi-orthogonal representations rather than example buffers for both privacy preservation and memory reduction. 
2) Self-augment and refinement: Without buffers and offline training to fully re-train the whole model, we bi-level optimize the extra high-dimensional prototypes alternatively with the projection module, to refine the decision boundaries and re-calibrate projection module based on optimized H-P and self-augment V-P. Extensive experiments with OCL, NE-CL, and FS-CL methods on three datasets demonstrate the effectiveness of DSR in handling the NO-CL problem.



{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}