\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage[mathscr]{eucal}
\usepackage[ruled]{algorithm2e}
\usepackage[dvipsnames, svgnames, x11names]{xcolor}
\usepackage{colortbl}
\usepackage{arydshln}
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{3157} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
\title{Offline-Online Class-incremental Continual Learning via \\ Dual-prototype Self-augment and Refinement}

\author{
   Fushuo~Huo$^1$,
   Wenchao~Xu$^1$,
   Jingcai~Guo$^1$,
   Haozhao~Wang$^2$,
   and~Yunfeng~Fan$^1$,
   Song~Guo$^1$\\
  \textsuperscript{1}Department of Computing, The Hong Kong Polytechnic University\\
  \textsuperscript{2}School of Computer Science and Technology, Huazhong University of Science and Technology\\
  % \texttt{yunfeng.fan@connect.polyu.hk}, \texttt{wenchao.xu@polyu.edu.hk}, \texttt{hz\_wang@hust.edu.cn}, \\
  % \texttt{junxiao.wang@polyu.edu.hk}, \texttt{song.guo@polyu.edu.hk}
}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi


%%%%%%%%% ABSTRACT
\begin{abstract}
%%%%%%%%%%%%This paper studies a novel and practical, but challenging problem called Offline-Online Class-incremental Continual Learning (O$^2$CL), which aims to preserve pre-trained (i.e., offline) base classes discernibility without buffering data examples, while efficiently learning novel classes continually from the single-pass (i.e., online) data stream. 
%
% We investigate Offline-Online Class-incremental Continual Learning (O$^2$CL), a novel and practical continual learning paradigm that aims to preserve the discernibility of pre-trained (i.e., offline) base classes without buffering data examples, and efficiently learning novel classes continuously in a single-pass (i.e., online) data stream.

This paper investigates a new, practical, but challenging problem named Offline-Online Class-incremental Continual Learning (O$^2$CL), which aims to preserve the discernibility of pre-trained (i.e., offline) base classes without buffering data examples, and efficiently learn novel classes continuously in a single-pass (i.e., online) data stream.
The challenges of this task are mainly two-fold: 1) Both base and novel classes suffer from severe catastrophic forgetting as no previous samples are available for replay. 2) As the online data can only be observed once, there is no way to fully re-train the whole model, e.g., re-calibrate the decision boundaries via prototype alignment or feature distillation.
In this paper, we propose a novel \underline{\textbf{D}}ual-prototype \underline{\textbf{S}}elf-augment and \underline{\textbf{R}}efinement method (DSR) for O$^2$CL problem, which consists of two strategies: 
1) Dual class prototypes: Inner and hyper-dimensional prototypes are exploited to utilize the pre-trained information and obtain robust quasi-orthogonal representations rather than example buffers for both privacy preservation and memory reduction. 
2) Self-augment and refinement: Instead of updating the whole network, we jointly optimize the extra projection module with the self-augment inner prototypes from base and novel classes, gradually refining the hyper-dimensional prototypes to obtain accurate decision boundaries for learned classes. 
Extensive experiments demonstrate the effectiveness and superiority of the proposed DSR in O$^2$CL~$\footnote{The source codes are attached in the supplementary material and will be released upon acceptance.}$.
%
% Meanwhile, privacy information should also be protected during the whole process. 
% Meanwhile, privacy leakage and computation overhead should also be considered during the online learning procedure. 
%
% This problem is challenging due to two difficulties. 
% Firstly, offline pre-trained base classes suffer from catastrophic forgetting due to lacking joint optimization of base and novel classes.
% % , even equipped with example buffer. 
% Secondly, Online Class-incremental continual Learning (OCL) is initially biased to base classes and sequentially over-fitting to novel classes, also causing forgetting and over-fitting issues. 
%
% This problem is challenging as 
%
%%%%%%%%%%%%The critical issue is that both base and novel classes suffer from severe catastrophic forgetting as no previous sample is available for replay.
% due to lacking example buffers to revisit. % 
% Besides, Online Class-incremental Continual Learning (OCL) on novel classes leaves no room to recalibrate decision boundaries of learned classes.
%%%%%%%%%%%%Besides, As the online data can only be observed once, there is no way to re-train the model backbone, e.g., re-calibrate the decision boundaries via prototype alignment or knowledge distillation that heavily relied on raw data collection.  
% , even equipped with example buffer. 
% Secondly, Online Class-incremental continual Learning (OCL) is initially biased to base classes and sequentially over-fitting to novel classes, also causing forgetting and over-fitting issues. 
%
% Though employing a large example buffer can eliminate these problems to some extent, privacy leakage and computation overhead are also not negligible. 
%
%%%%%%%%%%%%
% The challenges of this task are mainly two-fold: 1) Catastrophic forgetting of both base and novel classes, due to the lack of example buffer; and 2) Confused decision boundary, due to the entangled nature of the data even between base and novel classes. 
% %
% In this paper, we propose a novel \underline{\textbf{D}}ual-prototype \underline{\textbf{S}}elf-augment and \underline{\textbf{R}}efinement method, dubbed DSR, to conduct effective training in O$^2$CL. 
% %
% Specifically, DSR consists of two strategies. First, we propose dual-class prototypes that exploit inner and hyper-dimensional prototypes to explore more robust class-wise quasi-orthogonal representations, rather than example buffers for both memory reduction and privacy preservation. 
% %
% Next, instead of updating the whole network, we propose the self-augmentation and refinement method to jointly optimize an extra projection module between the inner and projected hyper-dimensional prototype spaces, to refine the hyper-dimensional prototypes toward more accurate decision boundaries for both base and novel classes. 
% %
% %which consists of two strategies: 
% %1) Dual class prototypes: Inner and hyper-dimensional prototypes are exploited to utilize the pre-trained information and obtain robust quasi-orthogonal representations rather than example buffers to prevent privacy leakage. 
% %2) Self-augment and refinement: Instead of updating the whole network, we jointly optimize the extra projection module with the self-augment inner prototypes from base and novel classes, gradually refining the hyper-dimensional prototypes to obtain accurate decision boundaries for both old and new classes. 
% % wenchao: I comment this on 8 Mar
% % In this paper, we propose a novel Dual-prototype Self-augment and Refinement (DSR) method consisting of two strategies: 
% % 1) Dual class prototypes: Inner and hyper-dimensional prototypes are exploited to utilize the pre-trained information and obtain robust quasi-orthogonal representations rather than example buffers to prevent privacy leakage. 
% % 2) Self-augment and refinement: Instead of updating the whole network, we jointly optimize the extra projection module with the self-augment inner prototypes from base and novel classes, gradually refining the hyper-dimensional prototypes to have clear decision boundaries. 
% %
% Extensive experiments demonstrate the effectiveness and superiority of the proposed DSR in O$^2$CL~$\footnote{The source codes are attached in the supplementary material and will be released upon acceptance.}$.
   
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
With the ubiquitously prevalent personal smart devices, a massive amount of data are being continually generated, which requires adaptive machine learning models to learn new tasks without forgetting the old knowledge
% achieve the stability-plasticity trade-off 
\cite{survey1, ne-cl-da, ne-cl-ss}. In privacy-sensitive online scenarios, a practical Online Class-incremental Continual Learning (OCL) system is expected to learn novel classes incrementally while keeping the prior knowledge without restoring any streaming data due to the privacy concerns and computation resource constraints. 
% However, a critical problem arise that such a sequential learning process faces the drawback of neural network called $\emph{catastrophic forgetting}$ \cite{cf}. 
Existing OCL methods \cite{ocm, sv, dvc, scr, rar} mainly focus on exploring the critical feature representation \cite{ocm, scr, dvc, rar} and developing strategies of selecting and retrieving proper samples from the data buffer \cite{sv, dvc} to re-calibrate the decision boundaries. However, these methods have two obvious drawbacks. %Firstly, Online learning are these privacy-sensitive and/or resource-constrained scenarios in which training data can not be stored.
%
Firstly, online learning is required for privacy-sensitive and/or resource-constrained scenarios where the training data can only be observed once. However, existing OCL solutions heavily rely on the example buffer for replay between data batches and tasks \cite{tl_ocl}.
% , which is frequently retrieved between data batches and tasks \cite{tl_ocl}. 
%
Secondly, OCL mainly concerns the setting of online training from scratch, and the state-of-the-art method \cite{dvc} achieves relatively low accuracy (\textbf{$<$20$\%$} for CIFAR100 \cite{cifar100} with 1000 buffer size), which significantly limits the OCL application to practical online scenarios. 
% These settings somewhat make traditional OCL less practical for practical online applications.


\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{COCL}
\caption{The overall concept of proposed Offline-Online Class-incremental continual Learning (CL) framework ($\emph{bottom}$), compared here with standard Online CL ($\emph{top}$).}
\label{fig1_real1}
\end{figure}



Considering practical scenarios, we investigate a feasible solution for the new, practical, yet challenging protocol named Offline-Online Class-incremental continual Learning (O${^2}$CL), as demonstrated in Figure \ref{fig1_real1}. Concretely, in practice, an intelligent system conducts online class-incremental learning without restoring stream examples, while utilizing and preserving the knowledge from previous training. Such under-explored practical settings are in line with Non-Exemplar Class-incremental continual Learning (NE-CL) \cite{ne-cl-sdc, ne-cl-da, ne-cl-ss}, Few-Shot Class-incremental Learning (FS-CL) \cite{fs-cl-sp, fs-cl-s3c, fs-cl-open}, and Continual Novel Class Discovery (C-NCD) \cite{ncd1, ncd2}, where base classes are well trained, and the knowledge are retained, but novel classes need to be explored. The most relative protocols are NE-CL and FS-CL problems. However, NE-CL conducts class-incremental learning without example buffers in an offline fashion, which enables the network to align the prior information (i.e., prototypes and/or features) multiple times like semantic drift compensation \cite{ne-cl-sdc}, dual augmentation \cite{ne-cl-da}, and prototype selection \cite{ne-cl-ss}. FS-CL aims to continually learn with few shot samples also in an offline way, like gradually refining the prototypes \cite{fs-cl-sp}, finetuning the classifier heads \cite{fs-cl-s3c}, or merely focusing on training robust embedding network \cite{fs-cl-open}. Therefore, NE-CL and FS-CL methods can hardly solve the  O${^2}$CL problem. Figure \ref{fig2} demonstrates the brief quantitative comparisons of OCL, FS-CL, NE-CL, and the proposed method in the same O$^2$CL setting.
 

In Offline-Online Class-incremental Continual Learning (O${^2}$CL), the key requirement is to conduct Online class-incremental Continual Learning without forgetting the old knowledge to solve the stability-plasticity dilemma.
% As the data sample from new class is single-pass and previous data samples can not be revisited, the stability-plasticity dilemma is more severe in O${^2}$CL.
% , while learning from data stream will cause class imbalance and forgetting pre-trained information \cite{luc, lscl}. 
% Previous Online Class-incremental continual Learning (OCL) restore and retrieve the example buffers to maintain the performance, which somewhat violates the OCL protocols \cite{tl_ocl}. 
In this paper, we devise a simple but effective method for O${^2}$CL problem called Dual-prototype Self-augment and Refinement (DSR). 
As the single-pass data can not be revisited, unlike previous example-base OCL methods, directly finetuning the feature extractor will cause severe catastrophic forgetting. Therefore, we freeze the offline-trained feature extractor and translate O${^2}$CL problem to optimizing privacy-preserved dual prototypes with the extra projection module. Specifically, inner and hyper-dimensional prototypes (I-P and H-P) of base classes are restored to preserve learned information. For incremental sessions, 
% two critical problems arise: how to online continually learn novel classes while eliminating the forgetting issue of base classes? We   
I-P of novel classes tends to disturb the classification of both novel and base classes.  We then project them to the hyper-dimensional embedding \cite{hd1, hd2, imhdc}, which has been proven robust to noise. In detail, a random vector from hyper-dimensional embedding is quasi-orthogonal to other vectors with high probability (the “curse” of dimensionality \cite{hd2}), and fine-tuning the prototype in the hyper-dimensional embedding provides a sufficiently large capacity to accommodate novel classes over time. Then, to efficiently maintain the decision boundaries of base and novel classes, self-augment I-P of learned classes
% based on class-wise mean and variances 
jointly optimize the projection module, to map the I-P to the refined hyper-dimensional prototypes. In summary, our contributions are as follows:

% which have clear decision boundaries calculated by frozen feature extractor and extra projection module are restored, where base classes have clear decision boundaries while incremental novel classes tend to confuse both novel and base classes. Therefore, to refine the dual prototypes of incremental classes, 

% We resort to privacy-preserved dual prototypes rather than cumbersome examples to revisit and explore base and novel classes. Instead of fine-tuning the whole network, the single-pass data stream are fed to the feature extractor and get the rough inner prototypes of each class. Unlike previous settings, as the raw data samples from current and/or previous tasks can not be revisited, modifying the feature extractor and inner prototypes causes the severe catastrophic forgetting. 

% To further self-augment and refine the rough prototypes, we then project them to the hyper-dimensional embedding \cite{hd1, hd2, imhdc}, which has been proven robust to noise. In detail, A randomly vector from hyper-dimensional embedding is quasi-orthogonal to other vectors with very high probability (the “curse” of dimensionality \cite{hd2}), and fine-tuning the prototype in the hyper-dimensional embedding provides a sufficiently large capacity to accommodate novel classes over time. Moreover, to efficiently learning the invariant information of the novel classes, self-augment inner prototype of base and novel classes based on class mean and variances jointly optimize the project head. In summary, our contributions are as follows:

\begin{itemize}
\item[1)] We study a novel yet practical problem called Offline-Online Class-incremental continual Learning (O${^2}$CL), where an intelligent system with pre-trained (i.e., offline) base classes information can efficiently learn novel classes continually from the single-pass (i.e., online) data stream. Meanwhile, previous knowledge and privacy information should also be preserved. 

\item[2)] We propose a novel Dual-prototype Self-augment and Refinement (DSR) method, which transfers training the whole network to optimizing the extra projection module. Concretely, H-P rapidly accommodates novel classes due to its quasi-orthogonal attribute. Then, self-augment I-P jointly optimizes the projection module based on refined H-P to re-calibrate the decision boundaries of learned classes. 

\item[3)] Extensive quantitative results demonstrate DSR performs significantly better than existing OCL, NE-CL, and FS-CL methods under the \emph{same protocols} of proposed O${^2}$CL, both in accuracy and efficiency $\footnote{Brief comparisons can be referred to in Figure \ref{fig2}.}$.

\end{itemize}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{results}
\caption{Class-wise accuracy, online training time, and memory overhead comparisons on the CIFAR100 dataset \cite{cifar100} with the \textbf{same protocols} of O${^2}$CL. Stat-of-the-art OCL (SCR\cite{scr}, DVC\cite{dvc}, and OCM \cite{ocm}, all with 1000 example buffer), FS-CL (ALICE \cite{fs-cl-open}), and NE-CL (SSRE \cite{ne-cl-ss}) methods are illustrated.}
\label{fig2}
\end{figure}

\section{Related Work}

% \subsection{Continual Learning}
With the development of deep learning technologies \cite{cifar100, imagenet, miniimagenet, resnet}, There is a growing need for continual learning of neural networks, which requires the network to learn new tasks without forgetting previous knowledge to achieve the stability-plasticity trade-off. Class-incremental Learning \cite{survey1, survey2} is a practical yet difficult setting in continual learning and has obtained much attention recently. 
%
Existing methods can be generally divided into three categories: regularization-based \cite{re1, re2, gem, agem}, structure-based \cite{st1, st2, st3}, and replay-based methods \cite{replay1, replay2}. Regularization-based methods aim to impose constraints on the parameter updating to eliminate catastrophic forgetting. Concretely, some \cite{re1, re2} devise regularization terms to penalize the update of parameters. Adjusting gradient \cite{gem, agem} during optimization is another way to preserve previous knowledge. Structure-based methods expand the network and freeze selected parameters to prevent forgetting. Specifically, according to whether adding new parameters, methods can be divided into fixed architecture \cite{st3} and dynamic architecture \cite{survey2, ace, gss, st1, st2}, where the former relies on selecting sub-network model that does not infringe upon others and the later focus on expanding networks for new tasks. Replay-based methods \cite{replay1, replay2} preserve examples of fixed memory size to maintain the distribution of old classes in the incremental phases. Selection and retrieval \cite{gss, dvc, sv} strategies for the buffer are also developed to preserve decision boundaries. Recently, some practical yet challenging settings of class-incremental learning, including Online Class-Incremental continual Learning (OCL), Non-Exemplar Class-incremental continual Learning (NE-CL), and Few-Shot Class-incremental Learning (FS-CL) are also proposed. Here we give a brief introduction.

\textbf{Online Class-incremental continual Learning (OCL)}
OCL aims to learn new classes continually from online data streams (each sample is seen only once). As the model needs to learn novel classes from the data stream while not forgetting previous classes, OCL methods \cite{survey2, ace, gss, scr, ocm, dvc, rar} follow replay-based protocols, where example buffers are stored and retrieved between data batches and tasks. Concretely, \cite{ocm, dvc} dig the critical information by maximizing their mutual information. \cite{rar} design augmentation strategies to address the underfitting-overfitting dilemma of online rehearsal. However, as pointed out by \cite{tl_ocl}, example buffers in OCL violate privacy and computation restrictions, especially in online learning scenarios. However, the example-free task-incremental online continual learning method \cite{tl_ocl} needs the task information. Also, even equipped with the example buffers, the state-of-the-art method  \cite{dvc} only achieves relatively low accuracy ($<$20$\%$ for CIFAR100 \cite{cifar100} with 1000 buffer size). Considering these problems, we proposed a novel yet practical setting called O${^2}$CL, which aims to better preserve privacy and utilize offline knowledge in practical online applications.

\textbf{Non-Exemplar Class-incremental Learning (NE-CL)}
% Due to computation burden or privacy security, some works \cite{ne-cl-sdc, ne-cl-ss, ne-cl-dd, ne-cl-pa} develop non-exemplar class-incremental learning methods, where no past data can be stored. \cite{ne-cl-sdc} estimates unknown semantic drifts of old classes via the drifts of current classes.
Due to computation burden or privacy security, some works \cite{ne-cl-sdc, ne-cl-ss, ne-cl-dd, ne-cl-pa} develop non-exemplar class-incremental learning methods where no past data can be stored. \cite{ne-cl-sdc} compensates unknown prototype drifts of old classes via the drifts of current data. \cite{ne-cl-pa} employs self-supervised learning to obtain more transferable features. Also, prototypes are also augmented to preserve the decision boundaries of previous classes. Recently, \cite{ne-cl-ss} considers to adjust the joint representation learning and distillation process. However, NE-CL pays attention to non-exemplar offline continual learning. They need to offline train novel classes to adjust prototypes and gradually distill features \cite{kd}. Therefore, NE-CL methods are not suitable for the proposed O${^2}$CL problem as analysis and experiments below.

\textbf{Few-Shot Class-incremental Learning (FS-CL)}
Compared to NE-CL, FS-CL assumes that novel classes come with few reference images. Current state-of-the-art FS-CL methods are mainly divided into two types. Some methods \cite{fs-cl-sak, fs-cl-rkd, fs-cl-} update the backbone to accommodate new classes while preserving base class via knowledge distillation technologies \cite{kd}. However, these methods heavily rely on complex example buffers to simulate the function of the previous network. Some methods \cite{fs-cl-open, fs-cl-hd, fs-cl-s3c} freeze the backbone and re-adopt features from the base classes to recognize new classes. Therefore, metric learning \cite{fs-cl-open}, meta-learning \cite{fs-cl-hd}, self-supervised learning \cite{fs-cl-s3c}, and class and data augmentation \cite{fs-cl-open} strategies have been employed to obtain the backbone with high transferable representations. However, such FS-CL methods finetune the network in an offline way and/or do not fully explore novel classes, leading to relatively poor performance on O${^2}$CL. 


% As for the proposed \textbf{(O${^2}$CL)} problem, there are two intractable obstacles. Firstly, example buffers are prohibited in online scenes. Secondly, without example buffers, how to fully explore single-pass data stream novel classes while preserving previous information. We avoid these issues systematically in O${^2}$CL, where hyperdimensional quasi-orthogonal vectors are assigned to each and every class with the aim of reducing interference



\section{Problem Formulation}
As shown in Figure \ref{fig1_real1}, O${^2}$CL problem comprises base classes from offline training data and novel classes from online training data. During online learning, only the raw data of the current classes is available, and the network aims to incrementally learn online new classes whilst retaining learned information before the current session.  
Concretely, assuming an $m$-step O${^2}$CL problem, let $\{ \mathcal{D}_{train}^0,\mathcal{D}_{train}^1,...,\mathcal{D}_{train}^m\} $ and $\{ \mathcal{D}_{test}^0,\mathcal{D}_{test}^1,...,\mathcal{D}_{test}^m\} $ denote the training and testing data from sessions $\{0, 1,..., m\}$, respectively. Each training and testing sessions $i$ have the corresponding label sets denoted by $\mathcal{C}{^i_{test}}$ and $\mathcal{C}{^i_{test}}$. $\mathcal{C}{^i_{train}}$ are mutually exclusive across different training sets, i.e., $\forall i \ne j,\mathcal{C}_{train}^i \cap \mathcal{C}_{train}^j = \phi $. While during evaluation, the model will be tested on all seen classes so far, i.e., for session i, the corresponding label space is $\mathcal{C}_{test}^0 \cup \mathcal{C}_{test}^1... \cup \mathcal{C}_{test}^i$. Besides, the base session ($i=0$) provides a large number of classes and also allows offline training. For the incremental sessions ($i>0$), the data comes in the online stream state without rehearsal. During offline and online sessions, like NE-CL \cite{ne-cl-sdc, ne-cl-ss}, considering privacy and computation constraints, buffers with raw data are not permitted. 
% Next, we introduce the dataset partition and evaluation metrics. 

\textbf{Dataset Partition.} Similar to \cite{ne-cl-sdc, ne-cl-ss, fs-cl-sp, fs-cl-s3c, fs-cl-open, ncd1, ncd2}, the benchmark datasets are divided into ($60\%  + 4\%  \times 10$), where the base session contains $60\%$ classes for offline learning and the rest classes are online incrementally learned within $10$ phases. Also, the results of  ($40\%  + 6\%  \times 10$), ($80\%  + 2\%  \times 10$), and ($60\%  + 2\%  \times 20$) are also provided in \textit{\textbf{Appendix A}}.

\textbf{Evaluation Metrics.} As the number of classes in the base and novel sessions are imbalanced, the traditional class-wise accuracy cannot reflect those which achieve high accuracies on both base and novel classes. Apart from class-wise accuracy, we also employ the harmonic accuracy (HM, i.e., $\rm{HM} = \frac{{2 \times {A_b} \times {A_n}}}{{{A_b} + {A_n}}}$, ${A_b}$ and ${A_n}$ denote the accuracy of base and novel classes) to evaluate the performance balance between base and novel classes.

\section{Methodology}
As for the proposed O${^2}$CL problem, we aim to fully explore single-pass data stream novel classes while preserving previous information without example buffers. The stability-plasticity  dilemma is intractable as the single-pass data stream results in the overfitting of novel classes while severely interfering with previously learned information. Previous OCL \cite{ocm, sv, dvc, scr, rar} methods resort to large example buffers to rehearse between data batches and tasks to eliminate forgetting. 
% Inspired by NE-CL \cite{ne-cl-sdc, ne-cl-ss}, 
To this end, we transfer training the whole network to optimize the extra projection module via greedily augmenting and updating dual prototypes. Figure \ref{fig3} shows the framework of the proposed DSR method. In the following section, we introduce the offline base session training protocol, Dual-prototype Self-augment and Refinement (DSR) for OCL, including self-augment inner prototypes, hyperdimensional prototype refinement, and whole optimization procedure.  
% Concretely, Self-augment inner prototypes drive the network to learn invariant information and hyperdimensional prototypes gradually push each prototypes away from other. Extra projection module, are  update push away novel class with base classes as well as hyperdimensional prototypes rapidly accommodate unified embeddings of base and novel classes due to its quasi-orthogonal attribute. 

% We avoid these issues of O${^2}$CL systematically, where hyperdimensional quasi-orthogonal vectors are assigned to each and every class with the aim of reducing interference.

% We propose an novel Dual-prototype Self-augment and Refinement (DSR) method, which transfers training the whole network to optimize the extra projection module. Also, self-augment inner prototypes drive the
% network to learning invariant information and hyperdimensional embedding rapidly accommodates base
% and novel classes due to its quasi-orthogonal attribute.

\subsection{Offline Base Session Training}
For the base session training, previous NE-CL and FS-CL \cite{fs-cl-open, ne-cl-da, ne-cl-pa, fs-cl-s3c} methods focus on training diverse features that are transferable across the base and incremental classes. Diverse class augmentation \cite{fs-cl-open, ne-cl-da, ne-cl-pa} and Self-Supervised Learning \cite{ne-cl-pa, fs-cl-s3c} methods are employed in the base session. Similarly, sophisticated offline training also improves the generalization and transfer ability of our method to accommodate online new classes (Ablation configuration of Ours w/ RT in Table 2). As we focus on the online class-incremental learning as well as \emph{fair comparisons} with other OCL methods, we utilize the supervised contrastive learning (SCL) \cite{scl} loss in the base session. Note that SCL and its variations have also been used in recent OCL \cite{scr, dvc, ocm}. Concretely, SCL is formulated as:
\begin{eqnarray}
L^{scl}=\sum_{i\in I}{\frac{-1}{\left| P\left( i \right) \right|}}\sum_{p\in P\left( i \right)}{\log \frac{\exp \left( z_i\times z_p/\tau \right)}{\sum_{a\in A\left( i \right)}{\exp \left( z_i\times z_a/\tau \right)}}}
\end{eqnarray}
where $I$ is the set of indices of Batch ($B_{I}=\{x_{k}, y_{k}, Aug(x_{k}), y_{k}\}{_{k=1...b}}$), which consists of original batch and augmented ($Aug$) view with $2b$ samples. $A(i)=I\backslash \{ i\} $ means the set of indices of all samples in $B_{I}$ except for sample $i$.  $z_{i}=Proj(\rm{HD}$$_{ft})$.  $\rm{HD}$$_{ft}$ is the output features from hyperembedding projection and  $Proj$ is a multi-layer perceptron 
% of size 2048 and output vector of 1024.
with a single hidden layer. $P(i) \equiv \{ p \in A(i):{y_p} = {y_i}\} $ is the set of indices of all positives in the augmented batch distinct from $i$, where $|P(i)|$ is its cardinality. $\tau \in \mathcal{R}^+$ is an temperature parameter. 

Our method freezes the backbone during online learning, therefore, relies on the embedding ability of the backbone. Compared to others, adding class augmentation and self-supervised learning bring obvious accuracy boosts, as shown in the ablation studies and \textit{\textbf{Appendix B}}.

\subsection{Dual-prototype Self-augment and Refinement}
After offline training, the backbone maps the data from the input domain $\mathcal{X}$ to a feature space: $f_{\theta _1}:\mathcal{X}\rightarrow \mathbb{R}^{d_f}$. ${\theta _1}$ are parameters of backbone. The prototypes in $\mathbb{R}^{d_f}$ are computed and restored to retain previous knowledge. Previous example-free prototype-based methods \cite{ne-cl-sdc, ne-cl-da, ne-cl-pa} offline refine prototypes and/or features together with samples from novel classes to achieve a trade-off between plasticity and stability. However, as for online learning, single-pass data stream results in insufficient data samples to gradually update the prototypes and network parameters. Besides, directly classifying novel classes based on frozen backbone fails to fully explore data samples of novel classes. Therefore, we devise dual prototypes strategy and refine the prototype in the hyperdimensional embedding space. Specially, we introduce the inner-prototype self-augment, hyperdimensional prototypes refinement, and the whole optimization procedure.


\begin{figure*}[t]
\centering
\includegraphics[width=0.8\textwidth]{flow}
\caption{\textbf{The overview of our method.} The base and novel sessions train in offline and online ways, respectively. I-P, SA-P, and H-P mean the inner, self-augment, and hyperdimensional prototypes. $hist(\cdot)$ and $G\left( \cdot \right)$ denote histogram and feature transformation (Eq. (2)). $\normalsize{\textcircled{\small{1}}}\normalsize$, $\normalsize{\textcircled{\small{2}}}\normalsize$, and $\normalsize{\textcircled{\small{3}}}\normalsize$ represent the three-step refinement procedure. Gray modules mean the frozen components, and red dotted lines represent the refined decision boundaries. During the inference phase, cosine similarities are computed between queries from the network with H-P to obtain the label.}
\label{fig3}
\vspace{-0.8em}
\end{figure*}

\begin{figure}[t]
\centering
% \includegraphics[width=130, angle=-90]{prototype}
\includegraphics[width=1.05\columnwidth]{prototype3-8}
\caption{t-SNE \cite{tsne} visualization of the feature embeddings. For better visualization, we train eight classes on the base session and incremental learn two classes (marked in green and red dots) sequentially. \textcolor{red}{Red circles} in H-P mean the confusion in novel classes and among base and novel classes. Best viewed in color.}
\label{fig4}
\end{figure}





\textbf{Inner-prototype Self-augment} 
We restore the inner prototype of the base and novel class to rehearse for retaining previous information. However, vanilla retrieving previous prototypes will confuse the decision boundary. As a solution, \cite{ne-cl-pa} tries to augment prototypes via Gaussian noise when learning new classes. However, the distribution mostly concentrated close to 0 due to the typical $\rm{relu}$ \cite{relu} activation function in ResNet \cite{resnet}. While class-specific class means (i.e., prototypes) tend to cluster together and lose the discriminative representation. Therefore, to make feature distribution more Gaussian-like, we transform features via Tukey's Ladder of Powers Transformation \cite{tukey}, which is a kind of power transformation that can reduce the skewness of distributions and make distributions more Gaussian-like. It can be formulated as:
\begin{eqnarray}
\tilde{x}=\begin{cases}
	x^{\lambda}&		if\ \lambda \ne 0\\
	\log \left( x \right)&		if\ \lambda =0\\
\end{cases}
\end{eqnarray}
where $\lambda$ is the hyperparameter to control the distribution i.e., decreasing $\lambda$ makes the distribution less positive skewed and vice
versa. The Gaussian-like rectification (denoted as $G\left( \cdot \right)$) are applied after the backbone ($B$) in both base and online sessions as $f=G(B_{\theta _1}(x))$.
For class $i$ in the session $m$, the inner prototype ($ip$) and its relative variance ($v$) are computed as:
\begin{eqnarray}
ip_{i}^{\left( m \right)}=\frac{1}{|k_i|}\sum_{j=1}^{k_i}{f_{j}^{m}},\ v _{i}^{\left( m \right)}=\frac{1}{|k_i|}\sum_{j=1}^{k_i}{\left( f_{j}^{m}-ip_{i}^{\left( m \right)} \right)^2}
\end{eqnarray}
where $k_i$ represents the index of samples ($x$) that belong to class $i$ in $\mathcal{D}_{train}^{(m)}$. Previous knowledge is retained by replaying features from the class-specific Gaussian distribution: $
 \hat{ip}_{i}^{\left( m \right)} \sim \mathcal{N}\left( ip_{i}^{\left( m \right)},v_{i}^{\left( m \right)} \right) 
$. However, the prototypes of novel classes calculated by frozen backbone tend to be noisy, leading degradation both in base and novel classes, as shown in Figure \ref{fig4} (Novel-I-P).
% Meanwhile, data samples from previous classes can not be retrieved to adjust the learned prototypes and online classes under-fit the whole network. 
Therefore, we also calculate the hyperdimensional prototypes of online classes in another hyperdimensional embedding space, where hyperdimensional prototypes are quasi-orthogonality, i.e., easy to differentiate \cite{hd2} that leaves the room to accommodate online new classes with minimal interference.

\textbf{Hyperdimensional Prototypes Refinement}
Recently, Hyperdimensional Computing has been used in computer vision tasks like few shot learning \cite{fs-cl-hd, hd-fsl}, out-of-distribution detection \cite{hd_ood}, and image translation \cite{hd-it}, which leverage quasi-orthogonal hyperdimensional representations without inducing much training and inference overhead. 
The initial  hyperdimensional prototype ($hp$) is obtained based on the single-pass raw data as:
% As for O$^2$CL problem, inner prototypes will result in confused decision boundaries as analysis above. Therefore, we project the inner prototypes into hyperdimensional space as:
\begin{eqnarray}
hp_{i}^{\left( m \right)}=\frac{1}{|k_i|}\sum_{j=1}^{k_i}{\left( Proj_{\theta _2}\left( f_{j}^{m} \right) \right)}
\end{eqnarray}
where $Proj_{\theta _2}$ represents the projection module with parameters (${\theta _2}$) and $hp_{i}^{\left( m \right)}$ is the hyperdimensional prototypes. As we can see in Figure \ref{fig4} (Novel H-P), though the prototypes have been clustered and separated to some extent in hyperdimensional embedding, the overlaps among novel classes and between base and novel classes also exist. Therefore, we propose a hyperdimensional prototypes refinement method
% after computing the inner and hyperdimensional prototypes (I-P and H-P) 
and jointly optimize the projection module via the augmented prototypes of learned classes to map the I-P to aligned H-P. The whole refinement procedure contains \textbf{three steps}. 


\begin{algorithm}[t]  %其中这里面不能有H不然会报错，不过不影响结果
	\caption{Training procedure of DSR.}%算法名字
	\LinesNumbered %要求显示行号
	\KwIn{Training data $\{ \mathcal{D}_{train}^0,\mathcal{D}_{train}^1,...,\mathcal{D}_{train}^m\} $, base epoch $n_1$, online iteration $T_0$, $T_1$, $T_2$}%输入参数
	\KwOut{Optimal $\theta _{1}$, $\theta _{2}$, and $hp$}%输出
	\textbf{Initialize:} $\theta _{1}$, $\theta _{2}$; 
 
        \textbf{Base Session:} 
        \emph{// offline train $\theta _{1}$ and $\theta _{2}$}
        
	\While{epoch $< n_1$} {
        train $\theta _{1}$ and $\theta _{2}$ with Eq. (1)	
	}
         \textbf{Online Session:} 
         \emph{// online train $\theta _{2}$ and update $hp$}    
	\For {incremental sessions $M \in \{1,2...m\}$}{

        \KwIn{$\theta _{1}^{M-1}$, $\theta _{2}^{M-1}$, $hp^{M-1}$, $\mathcal{D}_{train}^M$} \
        \KwOut{$\theta _{1}^{M}$, $\theta _{2}^{M}$, $hp^{M}$}\
        $\theta _{1}^{M}\leftarrow \theta _{1}^{M-1}$ 
        
        \While{$t_0$ $< T_0$ or not converged}{
        
        \While{$t_1$ $< T_1$ or not converged}{update $hp^{M(t_1)}_{t_0}$ with Eq. (8)}
         \While{$t_2$ $< T_2$ or not converged}{update $\theta _{2(t_0)}^{M(t_2)}$ with Eq. (10)}
         update $hp^{M(t_1)}_{t_0}$ with Eq. (11)
	}
        }
\end{algorithm}



\textbf{Firstly,} as the base classes are well trained, we only update H-P of novel classes by decreasing the cosine similarity of inter-novel classes ($L^{in}$), and between base and novel classes ($L^{bn}$), respectively. The formulas are as follows:
\begin{flalign}\label{equ1}
L^{hr}\left( hp^{\left( t \right)} \right) = L^{in}\left( hp^{\left( t \right)} \right)+L^{bn}\left( hp^{\left( t \right)} \right)
\end{flalign}
\begin{flalign}\label{equ1}
L^{in}\left( hp^{\left( t \right)} \right) =\sum_{i,j=1,s.t.\ i\ne j}^{|hp_{novel}|}{\cos \left( \sigma \left( hp_{i}^{\left( t \right)} \right) ,\sigma \left( hp_{j}^{\left( t \right)} \right) \right)}
\end{flalign}
\begin{flalign}\label{equ1}
L^{bn}\left( hp^{\left( t \right)} \right) =\sum_{i=1}^{|hp_{novel}|}{\sum_{j=1}^{|hp_{base}|}{\cos \left( \sigma \left( hp_{i}^{\left( t \right)} \right) ,\sigma \left( hp_{j}^{\left( t \right)} \right) \right)}}
\end{flalign}
where $t$ means the $T$ iterations. cos($\cdot$,$\cdot$) and $\sigma$ mean cosine similarity and hyperbolic tangent activation function. Moreover,  to avoid significant deviations from the original representations, $hp$ updates in the exponential moving average strategy (EMA):
\begin{flalign}\label{equ2}
hp^{\left( t+1 \right)}=\alpha hp^{\left( t \right)}+\left( 1-\alpha \right) \left( hp^{\left( t \right)}-\gamma \frac{\partial \left( L^{hr}\left( hp^{\left( t \right)} \right) \right)}{\partial \left( hp^{\left( t \right)} \right)} \right) 
\end{flalign}
where $\alpha$ is the momentum hyper-parameter to control the weight of fusion, generally close to 1 ($\alpha$ = 0.99 in this paper), and $\gamma$ is the learning rate. 

\textbf{Secondly,} based on refined H-P, we sample from class-specific Gaussian distribution from I-P as augmented prototypes and jointly optimize the projection module ($Proj_{\theta _2}$) to fit the refined H-P. The projection module is used as:     
\begin{eqnarray}
L_{i-h}^{\left( t \right)}=\frac{-1}{|\mathcal{C}|}\sum_{i=1}^{|\mathcal{C}|}{\frac{1}{K}\sum_{k=1}^K{\cos \left( Proj_{\theta _{2}^{\left( t \right)}}\left( \hat{ip}_{i}^{k} \right) ,hp_i \right)}}
\end{eqnarray}
\begin{eqnarray}
Proj_{\theta _{2}^{\left( t+1 \right)}}=Proj_{\theta _{2}^{\left( t \right)}}-\beta \frac{\partial L_{i-h}^{\left( t \right)}}{\partial Proj_{\theta _{2}^{\left( t \right)}}}
\end{eqnarray}
where $\beta$ is the learning rate, $|\mathcal{C}|$ and $K$ are the number of learned classes and sampled prototypes, respectively. The second step has two benefits: firstly, for class-incremental learning, we avoid frequently retrieving previous example samples while jointly retraining augmented prototypes of all classes to eliminate class imbalance problem\cite{luc, lsil}. Secondly, for OCL, projection the noisy I-P to hyperdimensional embedding anchored in refined H-P makes the model easily and robustly accommodate online new classes. 

\textbf{Thirdly,} as the initial H-P is directly inferred via the single pass data of novel classes, it lacks the interaction of base and novel classes though have been refined by Eq.(8). With the $Proj$$_{\theta _{2}}$, which has been well-trained via self-augment prototypes from all classes, the H-P of novel classes is updated in the exponential moving average strategy:
\begin{flalign}\label{equ2}
hp_{i}^{t+1}=\alpha hp_{i}^{t}+\left( 1-\alpha \right) \frac{1}{N}\sum_{n=1}^N{Proj_{\theta _2}\left( \hat{i}p_{i}^{n} \right)}
\end{flalign}
where $N$ is the number of samples from Gaussian distribution and $i\in\mathcal{C}_{novel}$ represents the novel classes. We optimize the $Proj$$_{\theta _{2}}$ and H-P with these three steps in a greedy way until reach the maximum iteration or cosine similarity convergence. \textbf{Algorithm 1} presents the pseudo-code of the whole procedure. As we train the lightweight projection module with prototypes rather than raw data, the whole procedure is efficient, as shown in Figure \ref{fig2} and \textit{\textbf{Appendix E}}.
Finally, during the inference phase, by comparing the cosine similarities between a query ($x$) from the network and H-P. We compute the score $l_i$ for class $i \in \mathcal{C}$ as:
\begin{flalign}\label{equ2}
l_i=\cos \left( hp_i,Proj_{\theta _2}\left( G\left( B_{\theta _1}\left( x \right) \right) \right) \right) 
\end{flalign}


\begin{table*}[]
\footnotesize
\renewcommand\arraystretch{1.3}
\begin{tabular}{l|clcl|clclclcl}
\hline
{\textbf{Methods}} & \multicolumn{4}{c|}{\textbf{CORE-50}}                                                           & \multicolumn{4}{c|}{\textbf{CIFAR100}}                                                          & \multicolumn{4}{c}{\textbf{Mini-ImageNet}}                                                    \\ \hline
\textbf{Metrics} & \multicolumn{4}{c|}{\textbf{Acc}(base/novel)$|$\textbf{HM}}                                                & \multicolumn{4}{c|}{\textbf{Acc}(base/novel)$|$\textbf{HM}}                                               & \multicolumn{4}{c}{\textbf{Acc}(base/novel)$|$\textbf{HM}}                                               \\ \hline
ALICE\cite{fs-cl-open}   & \multicolumn{4}{c|}{39.5(46.2/29.5)$|$36}                                                & \multicolumn{4}{c|}{42.5(53.5/25.9)$|$34.9}                                             & \multicolumn{4}{c}{41.1(51.4/25.7)$|$34.3}                                             \\ \hline
PASS\cite{ne-cl-pa}    & \multicolumn{4}{c|}{35.2(58.4/0.5)$|$1.0}                                                & \multicolumn{4}{c|}{37.9(62.6/0.9)$|$1.7}                                               & \multicolumn{4}{c}{37.4(61.5/1.2)$|$2.4}                                               \\
SSRE\cite{ne-cl-ss}   & \multicolumn{4}{c|}{---}                                                                 & \multicolumn{4}{c|}{39.8(66.2/0.5)$|$1.0}                                               & \multicolumn{4}{c}{---}                                                                \\ \hline
\textbf{MS}      & \multicolumn{2}{c|}{\emph{1000}}            & \multicolumn{2}{c|}{\emph{2000}}           & \multicolumn{2}{c|}{\emph{1000}}           & \multicolumn{2}{c|}{\emph{2000}}           & \multicolumn{2}{c|}{\emph{1000}}           & \multicolumn{2}{c}{\emph{2000}}  \\ \hdashline
GSS\cite{gss}     & \multicolumn{2}{c|}{18.4(19.3/17.1)$|$18.1} & \multicolumn{2}{c|}{20.8(22.3/18.6)$|$20.3} & \multicolumn{2}{c|}{21.5(22.7/19.8)$|$21.2} & \multicolumn{2}{c|}{23.4(24.2/22.1)$|$24.2} & \multicolumn{2}{c|}{18.9(19.8/17.6)$|$18.6} & \multicolumn{2}{c}{21.1(21.9/19.7)$|$20.7} \\
MIR\cite{mir}     & \multicolumn{2}{c|}{22.6(24.6/19.7)$|$21.9}  & \multicolumn{2}{c|}{24.5(26.9/20.9)$|$23.5} & \multicolumn{2}{c|}{24.2(26.4/20.9)$|$23.3} & \multicolumn{2}{c|}{25.1(27.1/22.0)$|$24.3} & \multicolumn{2}{c|}{22.9(24.6/20.3)$|$22.2} & \multicolumn{2}{c}{23.8(25.7/21.0)$|$23.1} \\
GD\cite{gdumb}  & \multicolumn{2}{c|}{25.8(27.0/23.9)$|$25.8}  & \multicolumn{2}{c|}{27.5(29.3/24.9)$|$26.9} & \multicolumn{2}{c|}{25.8(27.2/23.8)$|$25.4} & \multicolumn{2}{c|}{27.1(28.6/24.9)$|$26.6} & \multicolumn{2}{c|}{23.2(24.6/22.4)$|$23.1} & \multicolumn{2}{c}{24.4(25.1/23.3)$|$24.4} \\
DER++\cite{der++}   & \multicolumn{2}{c|}{27.5(28.7/25.8)$|$27.2}  & \multicolumn{2}{c|}{28.8(30.2/26.6)$|$28.3} & \multicolumn{2}{c|}{27.8(29.4/25.3)$|$27.2} & \multicolumn{2}{c|}{30.2(32.9/26.1)$|$29.1} & \multicolumn{2}{c|}{26.0(27.6/23.6)$|$25.4} & \multicolumn{2}{c}{28.6(29.9/26.7)$|$28.2} \\
ASER\cite{sv}    & \multicolumn{2}{c|}{29.4(30.6/27.6)$|$29.0}  & \multicolumn{2}{c|}{31.4(33.6/28.0)$|$30.5} & \multicolumn{2}{c|}{30.7(31.4/29.6)$|$30.5} & \multicolumn{2}{c|}{33.6(34.9/31.6)$|$33.2} & \multicolumn{2}{c|}{25.4(27.8/21.7)$|$24.5} & \multicolumn{2}{c}{29.7(30.4/28.6)$|$29.5} \\
SCR\cite{scr}     & \multicolumn{2}{c|}{39.4(38.0/41.5)$|$39.7}  & \multicolumn{2}{c|}{40.7(41.3/39.8)$|$40.5} & \multicolumn{2}{c|}{37.1(41.2/35.6)$|$38.3} & \multicolumn{2}{c|}{41.9(44.8/38.1)$|$41.1} & \multicolumn{2}{c|}{36.2(35.7/36.4)$|$36.1} & \multicolumn{2}{c}{38.8(44.2/30.9)$|$36.4} \\
SCR$_{ft}$     & \multicolumn{2}{c|}{39.6(46.2/29.8)$|$36.2}  & \multicolumn{2}{c|}{43.6(51.6/31.6)$|$39.2} & \multicolumn{2}{c|}{39.6(50.1/23.8)$|$32.3} & \multicolumn{2}{c|}{42.1(53.8/24.6)$|$33.8} & \multicolumn{2}{c|}{38.8(43.9/30.8)$|$36.2} & \multicolumn{2}{c}{42.8(47.8/35.6)$|$40.8} \\
OCM\cite{ocm}     & \multicolumn{2}{c|}{41.0(41.8/39.8)$|$40.8}  & \multicolumn{2}{c|}{42.5(43.1/41.6)$|$42.3} & \multicolumn{2}{c|}{37.3(37.8/36.6)$|$37.2} & \multicolumn{2}{c|}{41.6(42.6/40.1)$|$41.3} & \multicolumn{2}{c|}{37.2(36.3/38.6)$|$36.1} & \multicolumn{2}{c}{40.9(45.8/33.6)$|$38.8} \\
OCM$_{ft}$     & \multicolumn{2}{c|}{41.1(46.5/33.1)$|$38.7}  & \multicolumn{2}{c|}{43.7(48.1/37.2)$|$41.9} & \multicolumn{2}{c|}{40.8(46.3/32.6)$|$38.3} & \multicolumn{2}{c|}{42.3(46.9/35.4)$|$40.3} & \multicolumn{2}{c|}{39.0(40.6/36.8)$|$38.2} & \multicolumn{2}{c}{41.2(42.7/39.1)$|$40.8} \\
DVC\cite{dvc}     & \multicolumn{2}{c|}{39.9(39.6/40.5)$|$40.0}  & \multicolumn{2}{c|}{41.8(42.8/40.5)$|$41.6} & \multicolumn{2}{c|}{38.6(38.1/39.2)$|$38.9} & \multicolumn{2}{c|}{41.8(42.6/39.4)$|$41.2} & \multicolumn{2}{c|}{35.6(34.4/37.3)$|$35.9} & \multicolumn{2}{c}{38.4(36.9/41.2)$|$38.9} \\ 
DVC$_{ft}$     & \multicolumn{2}{c|}{41.9(48.2/32.6)$|$38.9}  & \multicolumn{2}{c|}{43.7(48.7/36.1)$|$41.5} & \multicolumn{2}{c|}{39.0(43.2/32.7)$|$37.2} & \multicolumn{2}{c|}{40.5(43.6/36.0)$|$39.4} & \multicolumn{2}{c|}{36.2(39.8/30.9)$|$34.8} & \multicolumn{2}{c}{39.3(40.8/37.0)$|$38.8} \\ \hline
\rowcolor{WhiteSmoke} \textbf{Ours}  & \multicolumn{4}{c|}{\textbf{50.9$\textcolor{red}{+7.2}$}(50.7/51.3)$|$\textbf{51.0}}                                              & \multicolumn{4}{c|}{\textbf{48.3$\textcolor{red}{+5.8}$}(52.2/42.6)$|$\textbf{46.5}}                                             & \multicolumn{4}{c}{\textbf{50.8$\textcolor{red}{+8.0}$}(56.7/42.3)$|$\textbf{48.1}}                                             \\  \hline 
\end{tabular}
\caption{Class-wise accuracy ($\textbf{Acc}$) by end of the training in terms of all classes, base classes, and novel classes. Harmonic accuracy (\textbf{HM}) is also illustrated. \textbf{MS} and $_{ft}$ mean the example memory size and finetuning versions. The best results are marked in \textbf{bold}.}
\vspace{-0.8em}
\end{table*}


\begin{figure}[t]
\centering
% \includegraphics[width=130, angle=-90]{prototype}
\includegraphics[width=1.05\columnwidth]{3-52}
\caption{The line chart represents class-wise average accuracy of representative methods (DVC\cite{dvc}, OCM\cite{ocm}, PASS\cite{ne-cl-pa}, and ALICE \cite{fs-cl-open})  along the incremental sessions.}
\label{fig5}
\vspace{-0.8em}
\end{figure}


\section{Experiments}
\textbf{Datasets and Evaluation Protocol}
As mentioned in section 3, the benchmark datasets are divided into ($60\%  + 4\%  \times 10$), where the base session contains $60\%$ classes for offline learning, and the rest of the classes are online incrementally learned within $10$ phases. Other splits are also provided in \textbf{\textit{Appendix A}}. We conduct experiments on three widely used datasets, including CORE-50 \cite{core50}, CIFAR 100 \cite{cifar100}, and Mini-ImageNet \cite{miniimagenet}, which have 50, 100, and 100 classes, respectively.  
Following recent class-incremental learning methods \cite{survey1, survey2}, class-wise average accuracy is applied to evaluate the performance. Meanwhile, as O$^2$CL contains online and offline training procedures and the number of their classes is unbalanced, to evaluate the balanced performance of base and novel classes, we also employ harmonic accuracy (HM).

\textbf{Comparison Methods}
We compare DSR with three categories baselines: (1) Online Class-incremental learning: GSS \cite{gss}, MIR \cite{mir}, GD\cite{gdumb}, DER++\cite{der++}, ASER \cite{sv}, SCR \cite{scr}, OCM \cite{ocm}, DVC \cite{dvc}. (2) Non-Exemplar Class-incremental continual Learning: PASS \cite{ne-cl-pa}, SSRE \cite{ne-cl-ss}. (3) Few-Shot Class-incremental Learning: ALICE \cite{fs-cl-open}. 

\textbf{Implementation details}
Following OCL methods \cite{scr, ocm, dvc}, we employ a reduced ResNet-18 as the backbone without pre-training. We use stochastic gradient descent with a learning rate of 0.1 with a batch size of 100 during the base session. The dimension of hyperdimensional embedding is 2048, and $Proj_{\theta _2}$ is implemented as a two-layer MLP with a hidden layer of 2048 dimension with $\rm{relu}$ as the activation function. For other hyper-parameters, we set offline epoch $n_1$, online iteration $T_0$, $T_1$, $T_2$ to 100, 20, 5, 5, set online learning rate $\gamma$, $\alpha$, $\beta$ all to 0.01, set feature transform coefficient $\lambda$ and the number of sampled prototypes $K$ and $N$ to 0.5, 20, and 1000. Analysis of hyper-parameters is performed in \textbf{\textit{Appendix C}}. As for compared methods, we adopt the \textbf{same training protocols} of O${^2}$CL as ours and adopt the defaulted hyper-parameters of their methods (see \textbf{\textit{Appendix D}}). We report the mean result of all methods over ten different runs.



\subsection{Comparisons with State-of-the-art Methods}
We compare our method with other SOTA methods in the setting of the proposed O${^2}$CL problem. The results are illustrated in Table 1 and Figure \ref{fig5}, which give the following observations. \textbf{1).} In terms of class-wise accuracy, our method outperforms others by 7.2$\%$, 5.8$\%$, and 8.0$\%$ in CORE-50, CIFAR100, and Mini-ImageNet, respectively. For harmonic accuracy (HM), which measures the performance balance between offline and incremental online classes, ours also exceed other methods by a large margin. \textbf{2).} For OCL methods, though equipped with large example buffers and offline pre-trained information, the over-fitting and catastrophic forgetting problems are also severe compared to ours. To avoid these issues, similar to ours, we freeze the backbone after offline learning and only jointly finetune the classifier head with online data and restored data samples (denoted as $_{ft}$). As we can see from SCR$_{ft}$, OCM$_{ft}$, and DVC$_{ft}$, simply freezing the backbone can not achieve the stability-plasticity trade-off that though base knowledge can be better preserved while damaging the ability to online learn the novel classes. Although large example buffers and frequent rehearsal can eliminate these issues, which somewhat violates the online learning protocols. \textbf{3).} As for NE-CL methods, PASS and SSRE fail to learn the novel classes in an online version. Due to the lack of old class samples, PASS and SSRE promote knowledge transfer in the progressive knowledge distillation process, while the distillation constraints can hamper online learning toward novel classes. \textbf{4).} For the FS-CL method, ALICE focuses on training generalization feature representations during the base session. They freeze all the parameters and directly infer novel classes based on robust embedding. However, without adjusting the representation, ALICE fails in a large number of sessions, as shown in the last few sessions in Figure \ref{fig5} and $60\%  + 2\%  \times 20$ configuration in \textit{\textbf{Appendix A}}. Note that NE-CL, PASS, and SSRE employ the more sophisticated ResNet-18 and pre-training strategy, which perform slightly better than ours in the base session. \textbf{Moreover}, as for computation overhead during online learning, which is usually considered in OCL scenarios \cite{tl_ocl}, as shown in Figure \ref{fig2}, our method only consumes $ \sim $ 35 seconds and minimal memory overhead in CIFAR100. More quantitative results of computation overhead are in \textbf{\textit{Appendix E}}. 







\subsection{Ablation Studies}
To validate the effectiveness of each module of our method, we perform ablation studies on CIFAR 100 and Mini-ImageNet datasets, as shown in Table 2. Concretely, \textbf{for inner-prototype self-augment stage}, we ablate Gaussian-like rectification (w/o $G\left( \cdot \right)$) and directly revisit the prototype without sampling repeatedly from Gaussian distributions (w/o SA-P). We can see that the Gaussian-like rectification brings 2.3$\%$ gains via reducing the skewness of distributions. Augmented prototypes significantly preserve the decision boundaries of previous classes while also being beneficial to the overall performance through joint optimization. \textbf{For hyperdimensional prototypes refinement stage}, we remove the first refinement procedure (w/o 1\emph{st}) in Eq. (5). The performance degrades to some extent, especially for the novel classes. To prove the effectiveness of amending prototypes in the hyperdimensional embedding (w/o HD), we project the inner prototypes to low-dimensional embedding (256) instead of high dimension (2048). The performance of both base and novel classes degrades, particularly in novel classes. The reason is that prototypes in low-dimensional embedding require dedicated alignments, otherwise resulting in confusion both in base and novel classes, which is not suitable for example-free OCL. Besides, we ablate the third step (w/o 3 $rd$) in Eq. (11). The performance of novel classes degrades more severely than base classes due to lacking prototypes alignment through the optimized projection layer. Moreover, all the ablation configurations also achieve comparative performance, even compared with OCL methods with large example buffers, which validates the effectiveness of the dual prototypes strategy. \textbf{To evaluate the overall performance}, we adopt the robust training strategy (w/ RT) proposed by \cite{fs-cl-open} in the base training session to obtain diverse and transferable representations. We can learn that the robust offline network improves our method by a large margin, both in preserving old classes and online accommodating novel classes, which validates the effectiveness of our method.       


\begin{table}[t]
\small
\renewcommand\arraystretch{1.35}
\begin{tabular}{ll|cl|cl}
\hline
\multicolumn{2}{l|}{\textbf{Ablations}} & \multicolumn{2}{c|}{\textbf{CIFAR100}}    & \multicolumn{2}{c}{\textbf{Mini-ImageNet}} \\ \hline
\multicolumn{2}{l|}{\textbf{Metrics}}        & \multicolumn{2}{c|}{\textbf{Acc}(base/novel)$|$\textbf{HM}}   & \multicolumn{2}{c}{\textbf{Acc}(base/novel)$|$\textbf{HM}}     \\ \hline
\multicolumn{2}{l|}{w/o $G\left( \cdot \right)$}   & \multicolumn{2}{c|}{46.0(50.2/39.7)$|$44.3} & \multicolumn{2}{c}{49.6(55.2/41.3)$|$47.2}   \\
\multicolumn{2}{l|}{w/o SA-P}                & \multicolumn{2}{c|}{43.4(45.4/40.4)$|$42.8} & \multicolumn{2}{c}{48.7(53.7/41.2)$|$46.6}   \\ \hline
\multicolumn{2}{l|}{w/o 1\emph{st}}            & \multicolumn{2}{c|}{46.2(50.9/39.1)$|$44.2} & \multicolumn{2}{c}{49.5(54.8/41.5)$|$47.2}   \\
\multicolumn{2}{l|}{w/o HD}                  & \multicolumn{2}{c|}{44.8(49.5/37.9)$|$42.9} & \multicolumn{2}{c}{47.4(53.6/38.1)$|$44.5}   \\
\multicolumn{2}{l|}{w/o 3\emph{rd}}            & \multicolumn{2}{c|}{46.7(51.3/39.8)$|$44.8} & \multicolumn{2}{c}{49.7(55.6/40.9)$|$47.1}   \\ \hline
\rowcolor{WhiteSmoke}\multicolumn{2}{l|}{Ours}                    & \multicolumn{2}{c|}{48.3(52.2/42.6)$|$46.9} & \multicolumn{2}{c}{50.8(56.7/42.3)$|$48.4}   \\
\rowcolor{WhiteSmoke}\multicolumn{2}{l|}{Ours w/ RT}               & \multicolumn{2}{c|}{52.8(56.2/47.8)$|$51.6} & \multicolumn{2}{c}{54.1(59.1/46.6)$|$52.1}   \\ \hline
\end{tabular}
\caption{\textbf{Ablation studies} on CIFAR100 and Mini-ImageNet.}
\end{table}


\section{Conclusion}

In this paper, we formulate a novel, practical, but challenging problem named Offline-Online class-incremental Continual Learning (O${^2}$CL), which aims to preserve pretrained (i.e., offline) base classes information, while efficiently learning novel classes continually from the single-pass (i.e., online) data stream, without example buffers. To solve this problem, we have proposed a novel Dual-prototype Self-augment and Refinement (DSR) method, which presents two solutions: 1) Dual class prototypes: Inner and hyper-dimensional prototypes are maintained to utilize the pre-trained information and obtain robust quasi-orthogonal representations rather than example buffers for both privacy preservation and memory reduction. 
2) Self-augment and refinement: Instead of updating the whole network, we jointly optimize the extra hyper-embedding module with the self-augment inner prototypes from base and novel classes, and refine the hyper-dimensional prototypes to obtain clear decision boundaries. Extensive experiments with OCL, NE-CL, and FS-CL methods on three benchmark datasets have demonstrated the effectiveness of DSR in handling O${^2}$CL problem.




{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}