\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[rebuttal]{iccv}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2021}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2021}

% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2021}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
% \usepackage{hyperref}       % hyperlinks

\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage[svgnames,table]{xcolor}         % colors
\usepackage[inline]{enumitem}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
% \usepackage{subfigure}
\usepackage{tabularx}
\usepackage{multirow}
% \usepackage[square,sort,comma,numbers]{natbib}
\usepackage{makecell}
\usepackage{verbatim}
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}
\usepackage{float}
\usepackage{soul}
% \usepackage{dblfloatfix} 

\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

\usepackage{color}
\newcommand{\PY}[1]{{\color{blue}PY: #1}}
\newcommand{\PYB}[1]{{\color{blue}[PY: #1]}}


% environments
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}[lemma]{Claim}
\newtheorem{proposition}{Proposition}
\newtheorem{fact}[lemma]{Fact}
\newtheorem{corollary}{Corollary}
\newtheorem{conjecture}{Conjecture}
\newtheorem{question}{Question}
\newtheorem{goal}{Goal}

% non-italicized environments
\theoremstyle{definition}
\newtheorem{construction}{Construction}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{example}[theorem]{Example}
\newtheorem{examples}[theorem]{Examples}
\newtheorem{problem}{Problem}

%commands
\newcommand{\real}{\mathbb{R}}
\newcommand{\ball}{\mathbb{B}}
\newcommand{\expect}{\mathbb{E}}


\newcommand{\Rone}{\textcolor{red}{{R1}}}
\newcommand{\Rtwo}{\textcolor{blue}{{R2}}}
\newcommand{\Rthree}{\textcolor{orange}{{R3}}}
\newcommand{\Rfour}{\textcolor{purple}{{R4}}}
% If you wish to avoid re-using figure, table, and equation numbers from
% the main paper, please uncomment the following and change the numbers
% appropriately.
%\setcounter{figure}{2}
%\setcounter{table}{1}
%\setcounter{equation}{2}

% If you wish to avoid re-using reference numbers from the main paper,
% please uncomment the following and change the counter for `enumiv' to
% the number of references you have in the main paper (here, 6).
%\let\oldthebibliography=\thebibliography
%\let\oldendthebibliography=\endthebibliography
%\renewenvironment{thebibliography}[1]{%
%     \oldthebibliography{#1}%
%     \setcounter{enumiv}{6}%
%}{\oldendthebibliography}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{2663} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2022}
\renewcommand{\baselinestretch}{0.94}
\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
%\title{\normalsize \textsf{DPGEN}: Differentially Private Generative Energy-Guided Network for High-Resolution Natural Image Synthesis} % **** Enter the paper title here
%\maketitle
%\thispagestyle{empty}
\appendix

%%%%%%%%% BODY TEXT - ENTER YOUR RESPONSE BELOW
We thank for constructive comments from all reviewers (\textbf{\Rone}, \textbf{\Rtwo}, \textbf{\Rthree}). We present responses for each reviewer in the following.  

\section{\textbf{\Rone} Response}

We would like to offer sincere appreciation for the vast amount of work and time that the reviewer has devoted, as well as the insightful comments that the reviewer holds which we will be discussing shortly in the following. 

\textbf{Does “reprogramming-FL” refer to the baseline that employs DP-SGD directly with prompt learning?} 

Yes, the reprogramming-FL [1] is the design where DP-SGD is deployed on VP (VP) parameters for better utility-privacy trade-off. While [1] primarily explores this under the federated learning setting, similar architecture was  also studied in [1] under a centralized setting.
 
\textbf{A portion of the private dataset is assumed to be “public unlabelled” and is used to train the student model ...  Exploring the boundaries of how VP enables generalization without directly using the private data distribution as a reference would be quite helpful}

PATE is designed to have access a certain amount of unlabelled public data. On the other hand, in [1] the Reprogrammable-FL framework is the direct consideration of applying VP in private cross-domain setting. Both results have demonstrated that applying VP under cross-domain settings greatly boosts performance under privacy consideration. However, we recognize and concur with the reviewer that VP could offer more when performing cross-domain generalization under both standard and private setting which could be one of the major exploration direction in VP.  

\textbf{The PATE framework should employ a data-dependent privacy analysis, while the computed privacy cost should be further sanitized for a fair comparison with baselines. This implementation detail seems not explicitly shown in the main paper. }

We thank the reviewer for such meticulous examination on the privacy budget and estimated bound for Prom-PATE. In fact, we utilize the same setting on budget as the scalable PATE [2] with data-dependent privacy budget. As a result, analogous to the original setting, the data-dependent bounds for privacy budget are identical to [2]. In details, we employ the same data-dependent bound using Proposition 7 and Theorem 6. 

Furthermore, in our experimental results, we ignore the  data-dependency overhead similar in [3] and present non-sanitized privacy budgets. For the reviewer's interest, we re-run the result in Table 4 with both non-sanitized and sanitized budgets revealed compared to existing works. Additionally, we will include the proof and implementation details into the revised version as the reviewer suggested




\section{\textbf{\Rtwo} Response}
We would like to sincerely thank the reviewer for offering compliment on our extensive experiments and relevant results. While some perspectives are different, we would try to resolve the difference in the following.  

\textbf{The only contribution of the paper is the use of VP train the teacher models. While this approach produces good results, it does not add anything new to our understanding of VP or PATE and lacks any technical/algorithmic novelty.}

We note that in this work we try to explore the benefit that VP brings to the privacy-preserving machine learning realm. On the other hand, while we do not present any theoretical novelty into the analysis of either PATE or VP, we empirically demonstrated the privacy-utility trade-off that VP+PATE would bring. For instance, it is notable that VP utilized in extreme private cross-domain setting could outperform traditional transfer learning and thus lead to reasonable privacy budget in real-world scenario.

On the other hand, we also discovered that via the ensemble and distillation learning that PATE provides, VP could better exert its influence on domain generalization. 

Lastly, we note that compared to existing work where the DP Fine-tuning trend excels by devising training tricks and data-specific epiphany. Our proposed solution is much simpler and accommodate a wide range of scenario, leading to a more elegant solution. 




\section{\textbf{\Rthree} Response}
We would like to first thank the reviewer for the generous time as well as precious and constructive comments that come along. Furthermore, we also find the idea of incorporating VP with privacy-preserving model to be an exhilarating trend. Here we aim to answer some follow-up questions that the reviewer has raised in the following.

\textbf{In Table 3, is the number of parameters fine-tuned in transfer learning similar to the number of prompting parameters? It’ll be great to compare the performance between learning a visual prompt vs. fine-tuning a similar number of parameters in both private and non-private settings.}

In the original baseline comparison, Prom-PATE possesses 49946 trainable parameters, including the VP and the label mapping layers. On the other hand, the fine-tuning baseline possesses around 10k trainable parameters. Here we note that due to the constraint of mapping between source and target data domain, VP naturally requires more trainable parameters then (partially) fine-tuning the pre-trained model itself under similar setting. 

Nevertheless, pertaining to the reviewer's request we increase the trainable parameter of fine-tuning baseline to roughly equal 50k \PYB{please be specific about how we do that; e.g. in the prev paragraph we can say the baseline only fine-tune the last FC layer, while here we further fine-tune which layer} and present the result as the following table in both private and non-private settings.

\textcolor{red}{Table Here}

As one can see from the above table, under similar amount of parameters in both settings. Prom-PATE outperforms the original fine-tuning baseline for roughly 1\%. On the other hand, we can see that under cross-domain setting such as Blood-MNIST, with similar number of trainable parameters. Prom-PATE ....  


\textcolor{red}{Table Here} 

 


\textbf{Another reservation about the paper is that the datasets evaluated are fairly limited}

Here we would like to note that for additional dataset, we've included both standard and cross-domain data in the Appendix. For instance, we've added SVHN, CelebA, and FFHQ for common scenario. As for cross-domain datasets, we've utilized MedMNIST and EuroSAT that are datasets of diverse difference in terms of domain gap to the pre-trained public dataset (i.e. ImageNet).

Nevertheless, we've managed to add one additional dataset, CIFAR-100, in our evaluation results and included the performance comparison in the following table. 

(Note that due to time constraint, we are only providing performance two reasonable privacy budgets and could offer more if the reviewer wishes)


\textcolor{red}{Table Here} 

As one can observe from the above table, Prom-PATE advances SOTA for roughly 1\% and .8\% respectively, again demonstrating the applicability in real-world data.



\end{document}
    