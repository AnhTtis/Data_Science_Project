% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%

\usepackage[ruled]{algorithm}
\usepackage{algpseudocode}
\usepackage[T1]{fontenc}
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{hyperref}

% \usepackage[style=alphabetic,maxnames=4,minnames=3,maxbibnames=99]{biblatex}
% \addbibresource{references.bib}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }
\usepackage{siunitx}
\usepackage{threeparttable}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{booktabs}
\usepackage{array}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcommand{\todo}[1]{\textcolor{red}{\textbf{\emph{TODO:~{#1}}}}}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\linespread{0.98}
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%
\begin{document}
%
\title{
MI-SegNet: Mutual Information-Based US Segmentation for Unseen Domain Generalization
}% Mutual Information Based Segmentation Network for Ultrasound Images
% Generalizing Ultrasound Segmentation Networks on Unseen Domains via Mutual Information Based Feature Disentanglement
%
\titlerunning{MI-SegNet: Mutual Information-Based US Segmentation}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Anonymous}
\author{Yuan Bi\inst{1} \and
Zhongliang Jiang\inst{1} \and
Ricarda Clarenbach\inst{2} \and
Reza Ghotbi\inst{2} \and
Angelos Karlas\inst{3,4}
Nassir Navab\inst{1}}
%
\authorrunning{Y. Bi et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
% \institute{Anonymous Organization\\
% \email{***@***}}
\institute{Chair for Computer-Aided Medical Procedures and Augmented Reality, Technical University of Munich, Munich, Germany \and
Clinic for Vascular Surgery, Helios Klinikum M{\"u}nchen West, Munich, Germany \and
Institute of Biological and Medical Imaging, Helmholtz Zentrum M{\"u}nchen, Neuherberg, Germany \and
Department for Vascular and Endovascular Surgery, rechts der Isar University Hospital, Technical University of Munich, Munich, Germany}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
Generalization capabilities of learning-based medical image segmentation across domains are currently limited by the performance degradation caused by the domain shift, particularly for ultrasound (US) imaging. The quality of US images heavily relies on carefully tuned acoustic parameters, which vary across sonographers, machines, and settings. To improve the generalizability on US images across domains, we propose MI-SegNet, a novel mutual information (MI) based framework to explicitly disentangle the anatomical and domain feature representations; therefore, robust domain-independent segmentation can be expected. Two encoders are employed to extract the relevant features for the disentanglement. The segmentation only uses the anatomical feature map for its prediction. In order to force the encoders to learn meaningful feature representations a cross-reconstruction method is used during training. Transformations, specific to either domain or anatomy are applied to guide the encoders in their respective feature extraction task. Additionally, any MI present in both feature maps is punished to further promote separate feature spaces.
We validate the generalizability of the proposed domain-independent segmentation approach on several datasets with varying parameters and machines.
Furthermore, we demonstrate the effectiveness of the proposed MI-SegNet serving as a pre-trained model by comparing it with state-of-the-art networks.\footnote{The code is available at: \url{https://github.com/starbucks-drinker/MI-SegNet}}
% Moreover, the performance of the proposed method as a pre-trained model after fine tuning is also evaluated by comparing it with state-of-the-art networks.

% Finally, how to exploit the MI directly as a metric to achieve feature-level disentanglement is carefully discussed.




% The performance drop caused by the domain shift severely hinders the wide use of deep learning-based medical segmentation networks. In this paper, we propose a novel mutual information (MI) based framework to increase the generalization ability of the ultrasound (US) segmentation network. Two independent encoders are designed to extract anatomical and domain features separately. The predicted segmentation masks are generated only based on the anatomical features so that the segmentation results are domain-independent. To achieve this, the disentanglement of these two representations is necessary. The feature disentanglement is realised by minimizing the MI between two feature representations. In order to guarantee that all the information of the input image is comprised, the anatomical and domain features are combined to reconstruct the original image. Besides, a cross reconstruction method is implemented to force each encoder to extract informative representations respectively. Two sets of features are extracted from two augmented images accordingly and paired in all four possible combinations to reconstruct the images. Then the experiments are conducted to demonstrate the high generalization ability of the proposed framework on unseen datasets. Moreover, the performance of the proposed method as a pre-trained model after fine tuning is also evaluated with other state-of-art networks. Finally, how to exploit the MI directly as a metrics to achieve feature-level disentanglement is carefully discussed.
% % By minimizing the MI between the two extracted representations, the feature 
% % In order to disentangle these two features, the MI between these respective representations is minimized 
% % By applying two independent encoders to extract anatomical and domain features separately and mini



\keywords{Ultrasound segmentation \and feature disentanglement \and domain generalization.}
\end{abstract}
%
%
%
\input{arxiv}

% \bibliographystyle{unsrt}
\bibliographystyle{splncs04}
\bibliography{references}

% \printbibliography


% \subsubsection{Sample Heading (Third Level)} Only two levels of
% headings should be numbered. Lower level headings remain unnumbered;
% they are formatted as run-in headings.

% \paragraph{Sample Heading (Fourth Level)}
% The contribution should contain no more than four levels of
% headings. Table~\ref{tab1} gives a summary of all heading levels.

% \begin{table}
% \caption{Table captions should be placed above the
% tables.}\label{tab1}
% \begin{tabular}{|l|l|l|}
% \hline
% Heading level &  Example & Font size and style\\
% \hline
% Title (centered) &  {\Large\bfseries Lecture Notes} & 14 point, bold\\
% 1st-level heading &  {\large\bfseries 1 Introduction} & 12 point, bold\\
% 2nd-level heading & {\bfseries 2.1 Printing Area} & 10 point, bold\\
% 3rd-level heading & {\bfseries Run-in Heading in Bold.} Text follows & 10 point, bold\\
% 4th-level heading & {\itshape Lowest Level Heading.} Text follows & 10 point, italic\\
% \hline
% \end{tabular}
% \end{table}


% \noindent Displayed equations are centered and set on a separate
% line.
% \begin{equation}
% x + y = z
% \end{equation}
% Please try to avoid rasterized images for line-art diagrams and
% schemas. Whenever possible, use vector graphics instead (see
% Fig.~\ref{fig1}).

% \begin{figure}
% \includegraphics[width=\textwidth]{fig1.eps}
% \caption{A figure caption is always placed below the illustration.
% Please note that short captions are centered, while long ones are
% justified by the macro package automatically.} \label{fig1}
% \end{figure}

% \begin{theorem}
% This is a sample theorem. The run-in heading is set in bold, while
% the following text appears in italics. Definitions, lemmas,
% propositions, and corollaries are styled the same way.
% \end{theorem}
% %
% % the environments 'definition', 'lemma', 'proposition', 'corollary',
% % 'remark', and 'example' are defined in the LLNCS documentclass as well.
% %
% \begin{proof}
% Proofs, examples, and remarks have the initial word in italics,
% while the following text appears in normal font.
% \end{proof}

% \subsubsection{Acknowledgements} Please place your acknowledgments at
% the end of the paper, preceded by an unnumbered run-in heading (i.e.
% 3rd-level heading).

%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%

%
% \begin{thebibliography}{8}
% \bibitem{ref_article1}
% Author, F.: Article title. Journal \textbf{2}(5), 99--110 (2016)

% \bibitem{ref_lncs1}
% Author, F., Author, S.: Title of a proceedings paper. In: Editor,
% F., Editor, S. (eds.) CONFERENCE 2016, LNCS, vol. 9999, pp. 1--13.
% Springer, Heidelberg (2016). \doi{10.10007/1234567890}

% \bibitem{ref_book1}
% Author, F., Author, S., Author, T.: Book title. 2nd edn. Publisher,
% Location (1999)

% \bibitem{ref_proc1}
% Author, A.-B.: Contribution title. In: 9th International Proceedings
% on Proceedings, pp. 1--2. Publisher, Location (2010)

% \bibitem{ref_url1}
% LNCS Homepage, \url{http://www.springer.com/lncs}. Last accessed 4
% Oct 2017
% \end{thebibliography}
\end{document}
