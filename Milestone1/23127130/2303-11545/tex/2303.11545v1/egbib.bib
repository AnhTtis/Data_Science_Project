@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}


% Pytorch
@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

% VGG
@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

% Otsu
@ARTICLE{4310076,
  author={Otsu, Nobuyuki},
  journal={IEEE Transactions on Systems, Man, and Cybernetics}, 
  title={A Threshold Selection Method from Gray-Level Histograms}, 
  year={1979},
  volume={9},
  number={1},
  pages={62-66},
  doi={10.1109/TSMC.1979.4310076}}

% Perceptual loss
@inproceedings{johnson2016perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={European conference on computer vision},
  pages={694--711},
  year={2016},
  organization={Springer}
}

% LPIPS
@inproceedings{zhang2018perceptual,
  title={The Unreasonable Effectiveness of Deep Features as a Perceptual Metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle={CVPR},
  year={2018}
}

% ArcFace
@inproceedings{deng2019arcface,
  title={Arcface: Additive angular margin loss for deep face recognition},
  author={Deng, Jiankang and Guo, Jia and Xue, Niannan and Zafeiriou, Stefanos},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4690--4699},
  year={2019}
}

% LSUN
@article{yu2015lsun,
  title={Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop},
  author={Yu, Fisher and Seff, Ari and Zhang, Yinda and Song, Shuran and Funkhouser, Thomas and Xiao, Jianxiong},
  journal={arXiv preprint arXiv:1506.03365},
  year={2015}
}

% blendgan
@article{liu2021blendgan,
  title={BlendGAN: Implicitly GAN Blending for Arbitrary Stylized Face Generation},
  author={Liu, Mingcong and Li, Qiang and Qin, Zekui and Zhang, Guoxin and Wan, Pengfei and Zheng, Wen},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

% Wikiart
@misc{wikiart,
  author = {Mohammed Innat},
  title = {Wiki-Art : Visual Art Encyclopedia},
  year = {2020},
  publisher = {Kaggle},
  journal = {Kaggle website},
  howpublished = {\url{www.kaggle.com/ipythonx/wikiart-gangogh-creating-art-gan}},
  note  = {Accessed Jan. 2022}
}

% FID
@article{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

% KID
@inproceedings{
binkowski2018demystifying,
title={Demystifying {MMD} {GAN}s},
author={Mikołaj Bińkowski and Dougal J. Sutherland and Michael Arbel and Arthur Gretton},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=r1lUOzWCW},
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% StyleGAN
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{karras2017progressive,
  title={Progressive growing of gans for improved quality, stability, and variation},
  author={Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Jaakko},
  journal={arXiv preprint arXiv:1710.10196},
  year={2017}
}

@inproceedings{karras2019style,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4401--4410},
  year={2019}
}

@inproceedings{karras2020analyzing,
  title={Analyzing and improving the image quality of stylegan},
  author={Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8110--8119},
  year={2020}
}

@inproceedings{Karras2020ada,
  title     = {Training Generative Adversarial Networks with Limited Data},
  author    = {Tero Karras and Miika Aittala and Janne Hellsten and Samuli Laine and Jaakko Lehtinen and Timo Aila},
  booktitle = {Proc. NeurIPS},
  year      = {2020}
}

@inproceedings{Karras2021,
  author = {Tero Karras and Miika Aittala and Samuli Laine and Erik H\"ark\"onen and Janne Hellsten and Jaakko Lehtinen and Timo Aila},
  title = {Alias-Free Generative Adversarial Networks},
  booktitle = {Proc. NeurIPS},
  year = {2021}
}

% CLIP
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}


@inproceedings{wu2022stylealign,
  title={StyleAlign: Analysis and Applications of Aligned Style{GAN} Models},
  author={Zongze Wu and Yotam Nitzan and Eli Shechtman and Dani Lischinski},
  booktitle={International Conference on Learning Representations},
  year={2022},
}


% Latent space
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Finding interpretable latent and manipluate image using it
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% ICCV 2019
@inproceedings{goetschalckx2019ganalyze,
  title={Ganalyze: Toward visual definitions of cognitive image properties},
  author={Goetschalckx, Lore and Andonian, Alex and Oliva, Aude and Isola, Phillip},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5744--5753},
  year={2019}
}

% ICLR 2020
@inproceedings{gansteerability,
  title={On the "steerability" of generative adversarial networks},
  author={Jahanian, Ali and Chai, Lucy and Isola, Phillip},
  booktitle={International Conference on Learning Representations},
  year={2020}
 }

% ICLR 2020
@inproceedings{Plumerault2020Controlling,
  title={Controlling generative models with continuous factors of variations},
  author={Antoine Plumerault and Hervé Le Borgne and Céline Hudelot},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

% IJCV 2021
@article{yang2021semantic,
  title={Semantic hierarchy emerges in deep generative representations for scene synthesis},
  author={Yang, Ceyuan and Shen, Yujun and Zhou, Bolei},
  journal={International Journal of Computer Vision},
  volume={129},
  number={5},
  pages={1451--1466},
  year={2021},
  publisher={Springer}
}

% PMLR 2020
@InProceedings{pmlr-v119-voynov20a,
  title = 	 {Unsupervised Discovery of Interpretable Directions in the {GAN} Latent Space},
  author =       {Voynov, Andrey and Babenko, Artem},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {9786--9796},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
}

% NeurIPS 2020
@inproceedings{harkonen2020ganspace,
  title     = {GANSpace: Discovering Interpretable GAN Controls},
  author    = {Erik Härkönen and Aaron Hertzmann and Jaakko Lehtinen and Sylvain Paris},
  booktitle = {Proc. NeurIPS},
  year      = {2020}
}

% CVPR 2020
@inproceedings{shen2020interpreting,
  title={Interpreting the latent space of gans for semantic face editing},
  author={Shen, Yujun and Gu, Jinjin and Tang, Xiaoou and Zhou, Bolei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9243--9252},
  year={2020}
}

% TPAMI 2020
@article{shen2020interfacegan,
  title={Interfacegan: Interpreting the disentangled face representation learned by gans},
  author={Shen, Yujun and Yang, Ceyuan and Tang, Xiaoou and Zhou, Bolei},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2020},
  publisher={IEEE}
}

% CVPR 2021
@inproceedings{shen2021closed,
  title={Closed-form factorization of latent semantics in gans},
  author={Shen, Yujun and Zhou, Bolei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1532--1540},
  year={2021}
}

% CVPR 2021
@inproceedings{wu2021stylespace,
  title={Stylespace analysis: Disentangled controls for stylegan image generation},
  author={Wu, Zongze and Lischinski, Dani and Shechtman, Eli},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12863--12872},
  year={2021}
}

% ICLR 2021
@inproceedings{spingarn2021gan,
  title={GAN ''Steerability'' without optimization}, author={Nurit Spingarn and Ron Banner and Tomer Michaeli},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

% ICCV 2021
@InProceedings{Lang_2021_ICCV,
    author    = {Lang, Oran and Gandelsman, Yossi and Yarom, Michal and Wald, Yoav and Elidan, Gal and Hassidim, Avinatan and Freeman, William T. and Isola, Phillip and Globerson, Amir and Irani, Michal and Mosseri, Inbar},
    title     = {Explaining in Style: Training a GAN To Explain a Classifier in StyleSpace},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {693-702}
}

% ICCV 2021
@inproceedings{patashnik2021styleclip,
  title={Styleclip: Text-driven manipulation of stylegan imagery},
  author={Patashnik, Or and Wu, Zongze and Shechtman, Eli and Cohen-Or, Daniel and Lischinski, Dani},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2085--2094},
  year={2021}
}

% ICCV 2021
@inproceedings{tzelepis2021warpedganspace,
  title={WarpedGANSpace: Finding non-linear RBF paths in GAN latent space},
  author={Tzelepis, Christos and Tzimiropoulos, Georgios and Patras, Ioannis},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6393--6402},
  year={2021}
}

 % MM 2021
@inproceedings{wang2021attribute,
  title={Attribute-specific Control Units in StyleGAN for Fine-grained Image Manipulation},
  author={Wang, Rui and Chen, Jian and Yu, Gang and Sun, Li and Yu, Changqian and Gao, Changxin and Sang, Nong},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={926--934},
  year={2021}
}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Image Manipulation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ICCV 2021
@inproceedings{yao2021latent,
  title={A latent transformer for disentangled face editing in images and videos},
  author={Yao, Xu and Newson, Alasdair and Gousseau, Yann and Hellier, Pierre},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={13789--13798},
  year={2021}
}

% ECCV 2020
@inproceedings{viazovetskyi2020stylegan2,
  title={Stylegan2 distillation for feed-forward image manipulation},
  author={Viazovetskyi, Yuri and Ivashkin, Vladimir and Kashin, Evgeny},
  booktitle={European Conference on Computer Vision},
  pages={170--186},
  year={2020},
  organization={Springer}
}

% CVPR 2020
@inproceedings{collins2020editing,
  title={Editing in style: Uncovering the local semantics of gans},
  author={Collins, Edo and Bala, Raja and Price, Bob and Susstrunk, Sabine},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5771--5780},
  year={2020}
}

% NeurIPS 2021
@article{ling2021editgan,
  title={EditGAN: High-Precision Semantic Image Editing},
  author={Ling, Huan and Kreis, Karsten and Li, Daiqing and Kim, Seung Wook and Torralba, Antonio and Fidler, Sanja},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

% CVPR 2021
@InProceedings{Lin_2021_CVPR,
    author    = {Lin, Ji and Zhang, Richard and Ganz, Frieder and Han, Song and Zhu, Jun-Yan},
    title     = {Anycost GANs for Interactive Image Synthesis and Editing},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {14986-14996}
}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Transfer learning StyleGAN with Preserving source feature
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Layer-swap
@article{pinkney2020resolution,
  title={Resolution dependent gan interpolation for controllable image synthesis between domains},
  author={Pinkney, Justin NM and Adler, Doron},
  journal={arXiv preprint arXiv:2010.05334},
  year={2020}
}

% FreezeG
@misc{lee2020freezeg,
  author = {Bryan Lee},
  title = {Freeze G},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{http://github.com/bryandlee/FreezeG}},
  commit = {40d2580b9082737331cefe7fe4dded120f457c5c},
  note  = { Accessed Jan. 2022}
}

% AgileGAN
@article{song2021agilegan,
  title={AgileGAN: stylizing portraits by inversion-consistent transfer learning},
  author={Song, Guoxian and Luo, Linjie and Liu, Jing and Ma, Wan-Chun and Lai, Chunpong and Zheng, Chuanxia and Cham, Tat-Jen},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={4},
  pages={1--13},
  year={2021},
  publisher={ACM New York, NY, USA}
}

% UI2I-StyleGAN
@article{kwong2021unsupervised,
  title={Unsupervised image-to-image translation via pre-trained stylegan2 network},
  author={Kwong, Sam and Huang, Jialu and Liao, Jing},
  journal={IEEE Transactions on Multimedia},
  year={2021},
  publisher={IEEE}
}

% DualStyleGAN
@inproceedings{yang2022pastiche,
  title={Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer},
  author={Yang, Shuai and Jiang, Liming and Liu, Ziwei and Loy, Chen Change},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7693--7702},
  year={2022}
}

% Vtoonify
@article{yang2022Vtoonify,
  title={VToonify: Controllable High-Resolution Portrait Video Style Transfer},
  author={Yang, Shuai and Jiang, Liming and Liu, Ziwei and Loy, Chen Change},
  journal={ACM Transactions on Graphics (TOG)},
  volume={41},
  number={6},
  articleno={203},
  pages={1--15},
  year={2022},
  publisher={ACM New York, NY, USA},
  doi={10.1145/3550454.3555437},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% StyleGAN Encoder
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Indomain gan inversion
@inproceedings{zhu2020indomain,
  title     = {In-domain GAN Inversion for Real Image Editing},
  author    = {Zhu, Jiapeng and Shen, Yujun and Zhao, Deli and Zhou, Bolei},
  booktitle = {Proceedings of European Conference on Computer Vision (ECCV)},
  year      = {2020}
}

% GH-Feat
@inproceedings{xu2021generative,
  title     = {Generative Hierarchical Features from Synthesizing Images},
  author    = {Xu, Yinghao and Shen, Yujun and Zhu, Jiapeng and Yang, Ceyuan and Zhou, Bolei},
  booktitle = {CVPR},
  year      = {2021}
}

% psp
@inproceedings{richardson2021encoding,
  title={Encoding in style: a stylegan encoder for image-to-image translation},
  author={Richardson, Elad and Alaluf, Yuval and Patashnik, Or and Nitzan, Yotam and Azar, Yaniv and Shapiro, Stav and Cohen-Or, Daniel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2287--2296},
  year={2021}
}

% e4e
@article{10.1145/3450626.3459838,
  author = {Tov, Omer and Alaluf, Yuval and Nitzan, Yotam and Patashnik, Or and Cohen-Or, Daniel},
  title = {Designing an Encoder for StyleGAN Image Manipulation},
  year = {2021},
  issue_date = {August 2021},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {40},
  number = {4},
  issn = {0730-0301},
  doi = {10.1145/3450626.3459838},
  journal = {ACM Trans. Graph.},
  month = {jul},
  articleno = {133},
  numpages = {14},
}

% hyperstyle
@misc{alaluf2021hyperstyle,
  title={HyperStyle: StyleGAN Inversion with HyperNetworks for Real Image Editing}, 
  author={Yuval Alaluf and Omer Tov and Ron Mokady and Rinon Gal and Amit H. Bermano},
  year={2021},
  eprint={2111.15666},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

% hyperinverter
@inproceedings{dinh2021hyperinverter,
    title={HyperInverter: Improving StyleGAN Inversion via Hypernetwork},
    author={Tan M. Dinh and Anh Tuan Tran and Rang Nguyen and Binh-Son Hua},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2022}
}

@inproceedings{wang2021HFGI,
  title={High-Fidelity GAN Inversion for Image Attribute Editing},
  author={Wang, Tengfei and Zhang, Yong and Fan, Yanbo and Wang, Jue and Chen, Qifeng},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{hu2022style,
  title={Style Transformer for Image Inversion and Editing},
  author={Hu, Xueqi and Huang, Qiusheng and Shi, Zhengyi and Li, Siyuan and Gao, Changxin and Sun, Li and Li, Qingli},
  journal={arXiv preprint arXiv:2203.07932},
  year={2022}
}

@inproceedings{moon2022interestyle,
  title={IntereStyle: Encoding an Interest Region for Robust StyleGAN Inversion},
  author={Moon, Seung-Jun and Park, Gyeong-Moon},
  booktitle={European Conference on Computer Vision},
  pages={460--476},
  year={2022},
  organization={Springer}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% GAN Inversion (optimization)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Image2StyleGAN
@InProceedings{Abdal_2019_ICCV,
author = {Abdal, Rameen and Qin, Yipeng and Wonka, Peter},
title = {Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
month = {October},
year = {2019}
}

% Image2StyleGAN++
@inproceedings{abdal2020image2stylegan++,
  title={Image2stylegan++: How to edit the embedded images?},
  author={Abdal, Rameen and Qin, Yipeng and Wonka, Peter},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8296--8305},
  year={2020}
}

@article{creswell2018inverting,
  title={Inverting the generator of a generative adversarial network},
  author={Creswell, Antonia and Bharath, Anil Anthony},
  journal={IEEE transactions on neural networks and learning systems},
  volume={30},
  number={7},
  pages={1967--1974},
  year={2018},
  publisher={IEEE}
}

@article{ma2018invertibility,
  title={Invertibility of convolutional generative networks from partial measurements},
  author={Ma, Fangchang and Ayaz, Ulas and Karaman, Sertac},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Transfer learning StyleGAN
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Freeze D
@article{mo2020freeze,
  title={Freeze the discriminator: a simple baseline for fine-tuning gans},
  author={Mo, Sangwoo and Cho, Minsu and Shin, Jinwoo},
  journal={arXiv preprint arXiv:2002.10964},
  year={2020}
}

% Few-shot GAN adaptation
@inproceedings{ojha2021few,
  title={Few-shot image generation via cross-domain correspondence},
  author={Ojha, Utkarsh and Li, Yijun and Lu, Jingwan and Efros, Alexei A and Lee, Yong Jae and Shechtman, Eli and Zhang, Richard},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10743--10752},
  year={2021}
}

@article{yang2021one,
  title={One-Shot Generative Domain Adaptation},
  author={Yang, Ceyuan and Shen, Yujun and Zhang, Zhiyi and Xu, Yinghao and Zhu, Jiapeng and Wu, Zhirong and Zhou, Bolei},
  journal={arXiv preprint arXiv:2111.09876},
  year={2021}
}

@article{xiao2022few,
  title={Few Shot Generative Model Adaption via Relaxed Spatial Structural Alignment},
  author={Xiao, Jiayu and Li, Liang and Wang, Chaofei and Zha, Zheng-Jun and Huang, Qingming},
  journal={arXiv preprint arXiv:2203.04121},
  year={2022}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Image to Image Translation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% style transfer
@inproceedings{gatys2016image,
  title={Image style transfer using convolutional neural networks},
  author={Gatys, Leon A and Ecker, Alexander S and Bethge, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2414--2423},
  year={2016}
}

% pix2pix
@inproceedings{isola2017image,
  title={Image-to-image translation with conditional adversarial networks},
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1125--1134},
  year={2017}
}

% UNIT
@article{liu2017unsupervised,
  title={Unsupervised image-to-image translation networks},
  author={Liu, Ming-Yu and Breuel, Thomas and Kautz, Jan},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

% BicycleGAN 
@article{zhu2017toward,
  title={Toward multimodal image-to-image translation},
  author={Zhu, Jun-Yan and Zhang, Richard and Pathak, Deepak and Darrell, Trevor and Efros, Alexei A and Wang, Oliver and Shechtman, Eli},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

% cyclegan
@inproceedings{zhu2017unpaired,
  title={Unpaired image-to-image translation using cycle-consistent adversarial networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2223--2232},
  year={2017}
}

% pix2pixHD
@inproceedings{wang2018high,
  title={High-resolution image synthesis and semantic manipulation with conditional gans},
  author={Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8798--8807},
  year={2018}
}

% MUNIT
@inproceedings{huang2018multimodal,
  title={Multimodal unsupervised image-to-image translation},
  author={Huang, Xun and Liu, Ming-Yu and Belongie, Serge and Kautz, Jan},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={172--189},
  year={2018}
}

% FUNIT
@inproceedings{liu2019few,
  title={Few-shot unsupervised image-to-image translation},
  author={Liu, Ming-Yu and Huang, Xun and Mallya, Arun and Karras, Tero and Aila, Timo and Lehtinen, Jaakko and Kautz, Jan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10551--10560},
  year={2019}
}

% stargan
@inproceedings{choi2018stargan,
  title={Stargan: Unified generative adversarial networks for multi-domain image-to-image translation},
  author={Choi, Yunjey and Choi, Minje and Kim, Munyoung and Ha, Jung-Woo and Kim, Sunghun and Choo, Jaegul},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8789--8797},
  year={2018}
}

% stargan v2
@inproceedings{choi2020stargan,
  title={Stargan v2: Diverse image synthesis for multiple domains},
  author={Choi, Yunjey and Uh, Youngjung and Yoo, Jaejun and Ha, Jung-Woo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8188--8197},
  year={2020}
}

% DRIT
@inproceedings{lee2018diverse,
  title={Diverse image-to-image translation via disentangled representations},
  author={Lee, Hsin-Ying and Tseng, Hung-Yu and Huang, Jia-Bin and Singh, Maneesh and Yang, Ming-Hsuan},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={35--51},
  year={2018}
}

% Smoothing Latent Space
@InProceedings{Liu_2021_CVPR,
    author    = {Liu, Yahui and Sangineto, Enver and Chen, Yajing and Bao, Linchao and Zhang, Haoxian and Sebe, Nicu and Lepri, Bruno and Wang, Wei and De Nadai, Marco},
    title     = {Smoothing the Disentangled Latent Style Space for Unsupervised Image-to-Image Translation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {10785-10794}
}

% CUT
@inproceedings{park2020cut,
  title={Contrastive Learning for Unpaired Image-to-Image Translation},
  author={Taesung Park and Alexei A. Efros and Richard Zhang and Jun-Yan Zhu},
  booktitle={European Conference on Computer Vision},
  year={2020}
}

% F-LSeSim
@inproceedings{zheng2021spatiallycorrelative,
  title={The Spatially-Correlative Loss for Various Image Translation Tasks},
  author={Zheng, Chuanxia and Cham, Tat-Jen and Cai, Jianfei},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2021}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Style Transfer
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% ADAIN
@inproceedings{huang2017arbitrary,
  title={Arbitrary style transfer in real-time with adaptive instance normalization},
  author={Huang, Xun and Belongie, Serge},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1501--1510},
  year={2017}
}

% stylebank
@inproceedings{chen2017stylebank,
  title={Stylebank: An explicit representation for neural image style transfer},
  author={Chen, Dongdong and Yuan, Lu and Liao, Jing and Yu, Nenghai and Hua, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1897--1906},
  year={2017}
}

@inproceedings{shen2018neural,
  title={Neural style transfer via meta networks},
  author={Shen, Falong and Yan, Shuicheng and Zeng, Gang},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8061--8069},
  year={2018}
}

@inproceedings{sanakoyeu2018style,
  title={A style-aware content loss for real-time hd style transfer},
  author={Sanakoyeu, Artsiom and Kotovenko, Dmytro and Lang, Sabine and Ommer, Bjorn},
  booktitle={proceedings of the European conference on computer vision (ECCV)},
  pages={698--714},
  year={2018}
}

@InProceedings{Sheng_2018_CVPR,
author = {Sheng, Lu and Lin, Ziyi and Shao, Jing and Wang, Xiaogang},
title = {Avatar-Net: Multi-Scale Zero-Shot Style Transfer by Feature Decoration},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Cartoonization
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% CartoonGAN
@inproceedings{chen2018cartoongan,
  title={Cartoongan: Generative adversarial networks for photo cartoonization},
  author={Chen, Yang and Lai, Yu-Kun and Liu, Yong-Jin},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={9465--9474},
  year={2018}
}

% Whitebox
@inproceedings{wang2020learning,
  title={Learning to Cartoonize Using White-Box Cartoon Representations},
  author={Wang, Xinrui and Yu, Jinze},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8090--8099},
  year={2020}
}

% U-GAT-IT
@article{kim2019u,
  title={U-GAT-IT: unsupervised generative attentional networks with adaptive layer-instance normalization for image-to-image translation},
  author={Kim, Junho and Kim, Minjae and Kang, Hyeonwoo and Lee, Kwanghee},
  journal={arXiv preprint arXiv:1907.10830},
  year={2019}
}

% Breaking cycle collegue
@inproceedings{nizan2020breaking,
  title={Breaking the cycle-colleagues are all you need},
  author={Nizan, Ori and Tal, Ayellet},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7860--7869},
  year={2020}
}

% AniGAN
@article{li2021anigan,
  title={AniGAN: Style-Guided Generative Adversarial Networks for Unsupervised Anime Face Generation},
  author={Li, Bing and Zhu, Yuanlue and Wang, Yitong and Lin, Chia-Wen and Ghanem, Bernard and Shen, Linlin},
  journal={IEEE Transactions on Multimedia},
  year={2021},
  publisher={IEEE}
}

% MangaGAN
@inproceedings{su2021mangagan,
  title={MangaGAN: Unpaired Photo-to-Manga Translation Based on The Methodology of Manga Drawing},
  author={Su, Hao and Niu, Jianwei and Liu, Xuefeng and Li, Qingfeng and Cui, Jiahe and Wan, Ji},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={2611--2619},
  year={2021}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Caricature generation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% CariGAN
@article{li2020carigan,
  title={Carigan: Caricature generation through weakly paired adversarial learning},
  author={Li, Wenbin and Xiong, Wei and Liao, Haofu and Huo, Jing and Gao, Yang and Luo, Jiebo},
  journal={Neural Networks},
  volume={132},
  pages={66--74},
  year={2020},
  publisher={Elsevier}
}

% WarpGAN
@inproceedings{shi2019warpgan,
  title={Warpgan: Automatic caricature generation},
  author={Shi, Yichun and Deb, Debayan and Jain, Anil K},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10762--10771},
  year={2019}
}

% Autotoon 
@inproceedings{gong2020autotoon,
  title={Autotoon: Automatic geometric warping for face cartoon generation},
  author={Gong, Julia and Hold-Geoffroy, Yannick and Lu, Jingwan},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={360--369},
  year={2020}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% makeup transfer
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% BeautyGAN
@inproceedings{li2018beautygan,
  title={Beautygan: Instance-level facial makeup transfer with deep generative adversarial network},
  author={Li, Tingting and Qian, Ruihe and Dong, Chao and Liu, Si and Yan, Qiong and Zhu, Wenwu and Lin, Liang},
  booktitle={Proceedings of the 26th ACM international conference on Multimedia},
  pages={645--653},
  year={2018}
}

% Pairedcyclegan
@inproceedings{chang2018pairedcyclegan,
  title={Pairedcyclegan: Asymmetric style transfer for applying and removing makeup},
  author={Chang, Huiwen and Lu, Jingwan and Yu, Fisher and Finkelstein, Adam},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={40--48},
  year={2018}
}

% LADN
@inproceedings{gu2019ladn,
  title={Ladn: Local adversarial disentangling network for facial makeup and de-makeup},
  author={Gu, Qiao and Wang, Guanzhi and Chiu, Mang Tik and Tai, Yu-Wing and Tang, Chi-Keung},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10481--10490},
  year={2019}
}

% PSGAN
@inproceedings{jiang2020psgan,
  title={Psgan: Pose and expression robust spatial-aware gan for customizable makeup transfer},
  author={Jiang, Wentao and Liu, Si and Gao, Chen and Cao, Jie and He, Ran and Feng, Jiashi and Yan, Shuicheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5194--5202},
  year={2020}
}

% SCGAN
@inproceedings{deng2021spatially,
  title={Spatially-invariant Style-codes Controlled Makeup Transfer},
  author={Deng, Han and Han, Chu and Cai, Hongmin and Han, Guoqiang and He, Shengfeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6549--6557},
  year={2021}
}