The Viterbi algorithm is a well-known approach for POS tagging, and it operates using the Markov model \cite{18}. Viterbi displays each word and sentence as a sequence of words and then calculates the score of each tag for each word according to the previous words and their scores by using emission and transition matrices. Finally, after calculating the scores for all tags, from the end of the sequence we choose the score that is maximized between the others for the last word and choose its tag then we continue backward until obtaining the first word’s tag. ACO-tagger is similar to Viterbi in that it views sentences as a sequence of words.\\
\begin{figure}
        \begin{center}
        \includegraphics[scale = 0.45, bb= 500 0 0 370]{trellis.pdf}
        \end{center}
	\caption{The Trellis structure.}
	\label{fig:fig1}
\end{figure}
The trellis graph used in this method is composed of 'n' segments, each representing a word in the sentence, with nodes in each segment representing one of the possible tags for the corresponding word. In figure (1) the structure of the trellis and the connections between blocks and nodes has shown. This graph is formed by using emission and transition matrices. Distance between nodes is important in this graph so when we have a higher value for emission and transition matrices between two nodes, we should have a smaller distance between that two nodes in this graph.
\begin{itemize}
	\item Emission matrix: representation of the probability of assigning a specific POS tag to each word in the vocabulary.
	\item Transition matrix: representation of the probability of transitioning between POS tags in a sequence of words.
\end{itemize}
For determining the distance between two nodes, the following equation is used:
    \begin{equation}
        D_{i.j}=\left({emission}_{i_.j}\right)^{log{{(transition}_{i_.j}})}
    \end{equation}

As transition and emission values are in the type of probabilities, they will always be within the range of 0 to 1. The value of $\log(transition_{i,j})$ will be less than 0 due to this reason, and as the probability of $transition_{i,j}$ and $emission_{i,j}$ increases, the length of $D_{i,j}$ will become shorter.

% As transition and emission values are of probability type, these values will always be between 0 and 1. For this reason, the higher the probability of emission, the lower the value of  ${\frac{1}{{\rm emission}_{i_.j}}$ is, and similarly for \log{({transition}_{i_.j}}).

When $emission_{i,j}$ is equal to zero, it indicates that the $tag_j$ is not associated with $word_i$. Similarly, if $transition_{i,j}$ is equal to zero , it indicates that $tag_j$ cannot appear after $tag_i$. To prevent assigning these tags to the words in the output response and potentially having impossible sequences of tags, their corresponding paths are assigned a cost of infinity. Hence, in equation (1) if ${emission}_{i_.j}=0$ or ${transition}_{i_.j}=0$ then the value of $D_{i_.j}$ is equal to $inf$. If the ant passes the path with the value of $inf$, the cost of the path traveled by that ant will always be equal to $inf$, and the answer produced by it will never be the final answer as an output.\\
After making the graph of a sentence, the next step is inserting ants into the graph. According to the ACO algorithm, ants randomly choose the ahead path based on a probability function. This probability is based on the pheromone on each branch. The following probability function is used to calculate the probability of choosing the path by the i-th ant:
\begin{equation}
    {P}_{i,d}\ =\ \frac{{c}_{{i},{d}}^{\alpha}\ .\ \eta_{{i},{d}}^{\beta}}{\sum_{{k = 1}}^{{B}}{({c}_{{i},{k}}^{\alpha}\ .\ \eta_{{i},{k}}^{\beta})}}     
\end{equation}
In this equation, the value $\eta$ is known as the heuristic value of the problem. A value is assigned to $\eta$ for each of the branches and paths. Also, $c_{i.j}$ expresses the amount of pheromone available in $branch_{i,j}$. At the beginning of the algorithm, the values of array $C$ are equal to zero because there is no pheromone on the branches of the graph. During the algorithm, depending on what the ants choose and where they move, these values are updated. The update takes place after all the ants of a generation have reached the last node, which is known as the food source. Changes in the pheromone of paths occur for two reasons:
\begin{enumerate}
    \item Reduction of available pheromone due to the evaporation over time
    \item The increase in pheromone due to the ant passing through it
\end{enumerate}
The amount of pheromone is updated at the end of each generation in the following way: 

\begin{equation}
c_{i,d}^{new}=\left(1-\rho\right)c_{i,d}\ + \sum_{j=1}^{M} \Delta c^{j}_{i,d}
\end{equation}
which $\rho$ is the evaporation rate of the pheromone.
At each stage, the ants of a generation choose the path and go through the nodes according to the amount of pheromone released by the previous generations. The best solution produced by each ant is equal to the shortest path traveled by them. Finally, after passing the path by all generations, the best solution produced is presented as the final solution.\\
In the following, we will discuss the algorithm in more detail by using an example. 
For example, the goal is to determine the tags for the words of the sentence "\FR{امروز هوا برفی است.}" where the table of emission, transition, and $\pi$ probabilities are shown in tables (1), (2), and (3) respectively.
\begin{table}
	\caption{Emission probabilities table}
	\centering
	\begin{tabular}{lccccc}
		\toprule

		&\FR{امروز}   & \FR{هوا} &\FR{برفی}  &\FR{است} &\FR{.} \\
            % \midrule
            \cmidrule(r){2-6}
		N	&0.1	&1.0	&0.2	&0.0	&0.0     \\
		V	&0.0	&0.0	&0.0	&1.0	&0.0  \\
		ADJ	&0.0	&0.0	&0.8	&0.0	&0.0\\
            ADV	&0.9	&0.0	&0.0	&0.0	&0.0\\
            DELM	&0.0	&0.0	&0.0	&0.0	&1.0\\
		\bottomrule
	\end{tabular}
	\label{tab:table}
\end{table}
\begin{table}
	\caption{Transition probabilities table}
	\centering
	\begin{tabular}{lccccc}
		\toprule
		&N	&V	&ADJ	&ADV	&DELM \\
            \cmidrule(r){2-6}
		N	&0.6	&0.05	&0.2	&0.05	&0.2     \\
		V	&0.7	&0.1	&0.2	&0.0	&0.0  \\
		ADJ	&0.5	&0.0	&0.1	&0.15	&0.25\\
            ADV	&0.35	&0.05	&0.3	&0.1	&0.2\\
            DELM	&0.2	&0.7	&0.05	&0.05	&0.0\\
		\bottomrule
	\end{tabular}
	\label{tab:table}
\end{table}
\begin{table}
	\caption{${\pi}$ probabilities table}
	\centering
	\begin{tabular}{lccccc}
		\toprule
		&N	&V	&ADJ	&ADV	&DELM \\
            \cmidrule(r){2-6}
		Ø	&0.6	&0.01	&0.04	&0.3	&0.05     \\
		\bottomrule
	\end{tabular}
	\label{tab:table}
\end{table}

First, we should calculate the probabilities of tags for the word "\FR{امروز}" which comes as the first word in the sentence by using equation (1). The initial stage is illustrated in figure (2-a) by starting with $\emptyset$ state. The result of the calculations of this section is the cost of the initial edges. According to equation (1) and the explanations surrounding it, as well as the probabilities of table (1) and table (3), the length of the initial edges which are the edges between the initial state and the first word are calculated as follows.

% \begin{figure}
%         \centering
% 	\includegraphics[scale = 0.35, bb= 0 0 350 370]{S0.pdf}
% 	\caption{The initial state of choosing the path.}	
% \end{figure}

\begin{figure}
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.38\linewidth]{S0.pdf}
  \caption{The initial state of choosing the path.}
  \label{fig:sfig1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.4\linewidth]{S1.pdf}
  \caption{Paths between \FR{امروز} $\mid$ N  and the next state.}
  \label{fig:sfig2}
\end{subfigure}
\caption{Illustrations of the relation between statuses and conditions}
\label{fig:fig}
\end{figure}

$D(\emptyset, $\FR{امروز}$ \mid N) =  emission( $\FR{امروز}$ \mid N) ^ {log \pi (N)} = 1.667$ \\
$D(\emptyset, $\FR{امروز}$ \mid V) =  emission( $\FR{امروز}$ \mid N) ^ {log \pi (N)} = inf $ \\
$D(\emptyset, $\FR{امروز}$ \mid ADJ) =  emission( $\FR{امروز}$ \mid N) ^ {log \pi (N)} = inf$ \\
$D(\emptyset, $\FR{امروز}$ \mid ADV) =  emission( $\FR{امروز}$ \mid N) ^ {log \pi (N)} = 1.057$ \\
$D(\emptyset, $\FR{امروز}$ \mid DELM) =  emission( $\FR{امروز}$ \mid N) ^ {log \pi (N)} = inf$ \\


In the same way, the distance between other nodes is calculated, with the difference that in the following steps, instead of the $\pi$ value, the transition probabilities in the table (2) are used.Also, the connections between one of the tags in the first word and the second word's tags are shown in figure (2-b).

% \begin{figure}
    
%         \begin{center}
%             \includegraphics[scale= 0.4, bb= 0 0 330 370]{S1.pdf}
% 	\end{center}
%         \caption{Paths between \FR{امروز} $\mid$ N  and the next state.}
% 	\label{fig:fig3}
% \end{figure}
$D( $\FR{امروز}$ \mid N, $\FR{هوا}$ \mid N) = emission( $\FR{هوا}$ \mid N) ^ {log (transition (N|N))} = 1 $ \\
$D( $\FR{امروز}$ \mid N, $\FR{هوا}$ \mid V) = emission( $\FR{هوا}$ \mid V) ^ {log (transition (V|N))} = inf $ \\
$D( $\FR{امروز}$ \mid N, $\FR{هوا}$ \mid ADJ) = emission( $\FR{هوا}$ \mid ADJ) ^ {log (transition (ADJ|N))} = inf $ \\
$D( $\FR{امروز}$ \mid N, $\FR{هوا}$ \mid ADV) = emission( $\FR{هوا}$ \mid ADV) ^ {log (transition (ADV|N))} = inf $ \\
$D( $\FR{امروز}$ \mid N, $\FR{هوا}$ \mid DELM) = emission( $\FR{هوا}$ \mid DELM) ^ {log (transition (DELM|N))} = inf $ \\


To create attractiveness in choosing shorter paths compared to longer paths, in this method, we put the $\eta_{i.j}$ value of each path equal to $\frac{1}{D_{i.j}}$ . As a result of this work, the smaller the distance between two vertices, the larger the value of $\eta_{i.j}$ will be, so, the probability of choosing that path, which is calculated according to equation (2), will be higher. This work will make the length of the path effective in the possibility of choosing the path by each ant, and an ant will choose according to the length of the path and the amount of pheromone available on it when making a decision. \\
The length of the path traveled by each ant is stored in each traversal, and finally, the best answer provided (the shortest path traveled) by the members of each generation is compared with the best solution produced by the members of the previous generations, and the least expensive path traveled is saved as the optimal answer. The nodes traveled in this path are the most probable answers for POS tagging.\\
In the ACO algorithm, various stopping parameters can be set to complete the calculations. To use this algorithm for tagging words, the number of ants’ generations is considered as the stop parameter, and the algorithm will stop after all $N$ generations of ants passed through, and the best answer produced during these $N$ generations will be the output and shows the final tags. 