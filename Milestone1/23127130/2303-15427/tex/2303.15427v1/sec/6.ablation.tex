\input{tab/loss_ablation}

\noindent \textbf{Loss ablation.} In order to demonstrate the effectiveness of each component and design of our system, we mainly test three aspects of our proposed method: 

\noindent (i) a video copying task is first undertaken, it consists in transferring a NeRF rendered reference video (20 keyframes) which the trajectory is known, under the same and different scenes, with same/close and different camera initialization positions. The objective is to demonstrate the robustness and characteristics of our two complementary cinematic losses across different scenes and influenced by different level of perturbations (\ie. initial position).

\noindent (ii) we carry out an experiment for retrieving correct timing and focal length information from images rendered with known parameters respectively. This experiment is to prove the ability of recovering these parameters by inverted optimization method on dynamic NeRF networks.

\noindent (iii) we investigate the influence of the guidance map by collecting the motion performance and memory usage of different sampling number (\ie number of pixels with gradient) to demonstrate that the guidance can help the convergence and mitigate the memory usage simultaneously.

Tab.~\ref{tab:loss_ablations} reports the ablation of losses for different setups: i) same/different target scenes to the reference to emphasize the cross-domain transfer ability; ii) same/different initial positions to highlight the robustness. Three metrics are computed: Absolute Trajectory Error (RMSE-ATE) reflects the quality of retrieved motion on $SE(3)$ similar to many tracking works~\cite{iMap,zhu2022nice}. To depict the on-screen composition similarity, we measure Pixel Error (PE) (for the same scene) and average Joint Error (JE) in pixel computed by Litepose (with a more accurate model).

We study several losses combinations: iNeRF~\cite{yen2021inerf}, \ie pixel loss with keypoint-driven sampling (w/o guidance map); pixel loss~\footnote{The difference to iNeRF is that the guidance map keeps gradient for selected pixels but the loss is computed on the entire image with \textit{all} pixels, whereas the iNeRF only computes loss on selected ones}, pose and flow loss followed by combination of flow and pose losses (\textit{flow+pose} in Tab.~\ref{tab:loss_ablations}).

According to Tab.~\ref{tab:loss_ablations}, we can observe:
i) iNeRF and pixel losses behave similarly: they both show good performance and robustness against perturbation for the same scene on motion (ATE) and composition qualities (PE, JE). However pixel-based methods fail frequently (\ie camera moving to non-defined area of the NeRF and yielding numerical error) under different scenes. For the barely succeeded experiments, the performances are low due to the misled pixel information by mismatched appearance from different scenes. ii) Comparing to pixel-based methods, the others (\textit{pose}, \textit{flow}, \textit{flow+pose}) show invariance against appearance changing. Nevertheless, they all act differently: (q) flow loss tends to drift heavily if the initialization position is far to the correct one (see JE and PE). The phenomenon is because of the fact that the flow focus on the inter-frame information and extracts no hint on the compositing; (b) in contrast, pose loss completely ignores the inter-frame motion and causes lower performance on ATE yet relatively better results in PE and JE on the same scene, suggesting possible ambiguities on similar human pose and different camera parameters. Heatmap pose feature also shows robustness against initial perturbation, with a small difference of ATE between the close and the different initializations; (c) by combining the two complementary losses: pose and flow, we achieve overall better performances than pose and flow separately, especially under different scene condition. Yet under the same scene, the performance is lower than pixel level tracking (iNeRF and pixel), reflecting on PE and ATE. This is due to less sharpen "convergence cone" (see Fig.~\ref{fig:loss distribution}), limited resolution on extracted heatmap from image, and possible heatmap ambiguities.

% ##################################################################################

\begin{figure}
  \includegraphics[width=0.47\textwidth]{fig/f-t-ablation_v2.png}
  \caption{Visualization of (i) temporal ablation, and (ii) focal length ablation. We show the initial and final frames of the six-frames clips used for ablation. The right column shows the error distribution on the ablated parameter (time and focal length) using our method (red) and a constant parameter setup (green).}
  \label{fig:f-t-ablation}
\end{figure}

\noindent \textbf{Parameter ablation.} We also undertake ablation for parameters: time $m$ and focal length $\phi$. The experiment is done by applying our method on 6-frames clips, where only time or focal length varies. Each experiment is run by 16 times with a random initial value for the studied parameters ($m$ or $\phi$). For each studied parameter, we show the distribution of the error between the prediction and the ground-truth (\textit{red}). We compare our results with the controlled case where the studied parameter remains constant, \ie equals to the random initial value, all along the 6-frames clips (\textit{blue}).

\noindent Fig~\ref{fig:f-t-ablation} (i) shows the result for the time ablation, where only the arms of the mutant waving and Fig~\ref{fig:f-t-ablation} (ii) shows the result for the focal length ablation, camera pose is fixed but the focal length varies. For both examples, our prediction error (\textit{red}) is smaller than the controlled one (\textit{blue}). Some large error values for our method are due to extreme random initial points, making the convergence harder, and also because we are optimizing \textit{all} cinematic parameters, some effects may have ambiguities by other parameters than the objective one: \eg zooming in and moving forward share similar yet different visual effects. 

% ##################################################################################

\input{tab/guidance_ablation}
\noindent \textbf{Guidance ablation.} Tab.~\ref{tab:guidance_ablations} shows the influence of the guidance map on the performance and memory usage. The ablation is done in similar methodology to the Tab.~\ref{tab:loss_ablations}, ATE are computed under the same scene with different initial position (see more in Suppl. Material). Low performances are reported when the sampling number is insufficient. An experimental optimal number is around 4000 which we used for our method. Higher std and memory usage can be noticed when the sampling number keeps increasing. The performance re-improves when including the gradient of \textit{all} pixel in the image (66752). The low-yield behavior of higher sampling numbers could be due to the confused the gradient direction by non-informative pixels, \eg false detection on the heatmap.