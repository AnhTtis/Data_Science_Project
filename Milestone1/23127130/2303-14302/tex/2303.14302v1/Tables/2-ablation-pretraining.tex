\begin{table}[t]
    \centering
    \setlength\tabcolsep{2pt}
    \small
    \begin{tabularx}{1\linewidth}{c|*{3}{>{\centering\arraybackslash}X}|*{3}{>{\centering\arraybackslash}X}}
    \Xhline{2\arrayrulewidth}
        &\multicolumn{3}{c|}{ZSL Ens. Prompts}
        &\multicolumn{3}{c}{w/ Our Adapter} \\
    \Xhline{1\arrayrulewidth}
        General Pretraining   &\cmark &       &\cmark &\cmark &       &\cmark \\
        Aesthetic Pretraining &       &\cmark &\cmark &       &\cmark &\cmark \\
    \Xhline{1\arrayrulewidth}
        SRCC                  & 0.228 & 0.265 & \textbf{0.657} & 0.746 & 0.566 & \textbf{0.774} \\
        PLCC                  & 0.228 & 0.276 & \textbf{0.663} & 0.750 & 0.575 & \textbf{0.774} \\
    \Xhline{2\arrayrulewidth}
    \end{tabularx}
    \vspace{-1mm}
    \caption{Effects of image-text pretraining on AVA. Different pretraining schema are employed for each column and two settings are reported: 1) ZSL using an ensemble of prompts; 2) further finetuned using our proposed rank-based adapter. }
    \label{tab:ava_captions_pretraining}
    \vspace{-2mm}
\end{table}

