@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}


@inproceedings{murray2012ava,
  title={AVA: A large-scale database for aesthetic visual analysis},
  author={Murray, Naila and Marchesotti, Luca and Perronnin, Florent},
  booktitle={2012 IEEE conference on computer vision and pattern recognition},
  pages={2408--2415},
  year={2012},
  organization={IEEE}
}

@article{yu2022coca,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}

@inproceedings{kong2016photo,
  title={Photo aesthetics ranking network with attributes and content adaptation},
  author={Kong, Shu and Shen, Xiaohui and Lin, Zhe and Mech, Radomir and Fowlkes, Charless},
  booktitle={European conference on computer vision},
  pages={662--679},
  year={2016},
  organization={Springer}
}

@article{murray2017deep,
  title={A deep architecture for unified aesthetic prediction},
  author={Murray, Naila and Gordo, Albert},
  journal={arXiv preprint arXiv:1708.04890},
  year={2017}
}

@article{talebi2018nima,
  title={NIMA: Neural image assessment},
  author={Talebi, Hossein and Milanfar, Peyman},
  journal={IEEE Transactions on Image Processing},
  volume={27},
  number={8},
  pages={3998--4011},
  year={2018},
  publisher={IEEE}
}

@article{zeng2019unified,
  title={A unified probabilistic formulation of image aesthetic assessment},
  author={Zeng, Hui and Cao, Zisheng and Zhang, Lei and Bovik, Alan C},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  pages={1548--1561},
  year={2019},
  publisher={IEEE}
}

@InProceedings{Hosu_2019_CVPR,
author = {Hosu, Vlad and Goldlucke, Bastian and Saupe, Dietmar},
title = {Effective Aesthetics Prediction With Multi-Level Spatially Pooled Features},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}

@InProceedings{Chen_2020_CVPR,
author = {Chen, Qiuyu and Zhang, Wei and Zhou, Ning and Lei, Peng and Xu, Yi and Zheng, Yu and Fan, Jianping},
title = {Adaptive Fractional Dilated Convolution Network for Image Aesthetics Assessment},
booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@InProceedings{Ke_2021_ICCV,
    author    = {Ke, Junjie and Wang, Qifei and Wang, Yilin and Milanfar, Peyman and Yang, Feng},
    title     = {MUSIQ: Multi-Scale Image Quality Transformer},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {5148-5157}
}

@article{niu2022comment,
  title={Comment-Guided Semantics-Aware Image Aesthetics Assessment},
  author={Niu, Yuzhen and Chen, Shanshan and Song, Bingrui and Chen, Zhixian and Liu, Wenxi},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2022},
  publisher={IEEE}
}

@inproceedings{he_2022_ijcai,
  title     = {Rethinking Image Aesthetics Assessment: Models, Datasets and Benchmarks},
  author    = {He, Shuai and Zhang, Yongchang and Xie, Rui and Jiang, Dongxiang and Ming, Anlong},
  booktitle = {Proceedings of the Thirty-First International Joint Conference on
               Artificial Intelligence, {IJCAI-22}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Lud De Raedt},
  pages     = {942--948},
  year      = {2022},
  month     = {7},
  note      = {Main Track},
  doi       = {10.24963/ijcai.2022/132},
  url       = {https://doi.org/10.24963/ijcai.2022/132},
}


@inproceedings{ghosal2022image,
  title={Image Aesthetics Assessment Using Graph Attention Network},
  author={Ghosal, Koustav and Smolic, Aljosa},
  booktitle={International Conference on Pattern Recognition (ICPR)},
  year={2022}
}


@inproceedings{karayev2013recognizing,
	title = {Recognizing Image Style},
	author = {Karayev, Sergey and Trentacoste, Matthew and Han, Helen and Agarwala, Aseem and Darrell, Trevor and Hertzmann, Aaron and Winnemoeller, Holger},
	year = {2014},
	booktitle = {Proceedings of the British Machine Vision Conference},
	publisher = {BMVA Press},
	editors = {Valstar, Michel and French, Andrew and Pridmore, Tony},
	doi = { http://dx.doi.org/10.5244/C.28.122 }
}

@inproceedings{lu2015deep,
  title={Deep multi-patch aggregation network for image style, aesthetics, and quality estimation},
  author={Lu, Xin and Lin, Zhe and Shen, Xiaohui and Mech, Radomir and Wang, James Z},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={990--998},
  year={2015}
}

@article{sun2017convolution,
  title={Convolution neural networks with two pathways for image style recognition},
  author={Sun, Tiancheng and Wang, Yulong and Yang, Jian and Hu, Xiaolin},
  journal={IEEE Transactions on Image Processing},
  volume={26},
  number={9},
  pages={4102--4113},
  year={2017},
  publisher={IEEE}
}

@article{ghosal2019geometry,
  title={A geometry-sensitive approach for photographic style classification},
  author={Ghosal, Koustav and Prasad, Mukta and Smolic, Aljosa},
  journal={arXiv preprint arXiv:1909.01040},
  year={2019}
}

@inproceedings{dosovitskiy2020image,
title	= {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author	= {Alexander Kolesnikov and Alexey Dosovitskiy and Dirk Weissenborn and Georg Heigold and Jakob Uszkoreit and Lucas Beyer and Matthias Minderer and Mostafa Dehghani and Neil Houlsby and Sylvain Gelly and Thomas Unterthiner and Xiaohua Zhai},
booktitle={International Conference on Learning Representations (ICLR)},
year	= {2021}
}


@inproceedings{vaswani2017attention,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Attention is All you Need},
 volume = {30},
 year = {2017}
}

@software{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.3.13},
  year = {2018},
}

@article{lee2018photographic,
  title={Photographic composition classification and dominant geometric element detection for outdoor scenes},
  author={Lee, Jun-Tae and Kim, Han-Ul and Lee, Chul and Kim, Chang-Su},
  journal={Journal of Visual Communication and Image Representation},
  volume={55},
  pages={91--105},
  year={2018},
  publisher={Elsevier}
}


@InProceedings{Ying_2020_CVPR,
author = {Ying, Zhenqiang and Niu, Haoran and Gupta, Praful and Mahajan, Dhruv and Ghadiyaram, Deepti and Bovik, Alan},
title = {From Patches to Pictures (PaQ-2-PiQ): Mapping the Perceptual Space of Picture Quality},
booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@InProceedings{Ren_2017_ICCV,
  author = {Ren, Jian and Shen, Xiaohui and Lin, Zhe and Mech, Radomir and Foran, David J.},
  title = {Personalized Image Aesthetics},
  booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
  month = {Oct},
  year = {2017}
}

@InProceedings{Fang_2020_CVPR,
author = {Fang, Yuming and Zhu, Hanwei and Zeng, Yan and Ma, Kede and Wang, Zhou},
title = {Perceptual Quality Assessment of Smartphone Photography},
booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@article{tang2013content,
  title={Content-based photo quality assessment},
  author={Tang, Xiaoou and Luo, Wei and Wang, Xiaogang},
  journal={IEEE Transactions on Multimedia},
  volume={15},
  number={8},
  pages={1930--1943},
  year={2013},
  publisher={IEEE}
}

@InProceedings{Yang_2022_CVPR,
    author    = {Yang, Yuzhe and Xu, Liwu and Li, Leida and Qie, Nan and Li, Yaqian and Zhang, Peng and Guo, Yandong},
    title     = {Personalized Image Aesthetics Assessment With Rich Attributes},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {19861-19869}
}

@InProceedings{Mai_2016_CVPR,
author = {Mai, Long and Jin, Hailin and Liu, Feng},
title = {Composition-Preserving Deep Photo Aesthetics Assessment},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@article{wang2019neural,
  title={Neural aesthetic image reviewer},
  author={Wang, Wenshan and Yang, Su and Zhang, Weishan and Zhang, Jiulong},
  journal={IET Computer Vision},
  volume={13},
  number={8},
  pages={749--758},
  year={2019},
  publisher={Wiley Online Library}
}

@inproceedings{zhou2016joint,
  title={Joint image and text representation for aesthetics analysis},
  author={Zhou, Ye and Lu, Xin and Zhang, Junping and Wang, James Z},
  booktitle={Proceedings of the 24th ACM international conference on Multimedia},
  pages={262--266},
  year={2016}
}

@inproceedings{yeo2021generating,
  title={Generating Aesthetic Based Critique For Photographs},
  author={Yeo, Yong-Yaw and See, John and Wong, Lai-Kuan and Goh, Hui-Ngo},
  booktitle={2021 IEEE International Conference on Image Processing (ICIP)},
  pages={2523--2527},
  year={2021},
  organization={IEEE}
}

@inproceedings{ghosal2019aesthetic,
  title={Aesthetic image captioning from weakly-labelled photographs},
  author={Ghosal, Koustav and Rana, Aakanksha and Smolic, Aljosa},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops},
  pages={0--0},
  year={2019}
}

@article{srivastava2012multimodal,
  title={Multimodal learning with deep boltzmann machines},
  author={Srivastava, Nitish and Salakhutdinov, Russ R},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@inproceedings{lee2019set,
  title={Set transformer: A framework for attention-based permutation-invariant neural networks},
  author={Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam and Choi, Seungjin and Teh, Yee Whye},
  booktitle={International conference on machine learning},
  pages={3744--3753},
  year={2019},
  organization={PMLR}
}

@article{kiros2014unifying,
  title={Unifying visual-semantic embeddings with multimodal neural language models},
  author={Kiros, Ryan and Salakhutdinov, Ruslan and Zemel, Richard S},
  journal = "Transactions of the Association for Computational Linguistics",
  year={2015}
}


@inproceedings{faghri2018vse++,
  title={VSE++: Improving Visual-Semantic Embeddings with Hard Negatives},
  author={Faghri, Fartash and Fleet, David J and Kiros, Jamie Ryan and Fidler, Sanja},
  booktitle = {Proceedings of the British Machine Vision Conference ({BMVC})},
  url = {https://github.com/fartashf/vsepp},
  year={2018}
}

@article{frome2013devise,
  title={Devise: A deep visual-semantic embedding model},
  author={Frome, Andrea and Corrado, Greg S and Shlens, Jon and Bengio, Samy and Dean, Jeff and Ranzato, Marc'Aurelio and Mikolov, Tomas},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
}


@inproceedings{chen2019uniter,
  title={Uniter: Learning universal image-text representations},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and Kholy, Ahmed El and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year={2020}
}


@inproceedings{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}


@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}


@inproceedings{su2019vlbert,
  title={Vl-bert: Pre-training of generic visual-linguistic representations},
  author={Su, Weijie and Zhu, Xizhou and Cao, Yue and Li, Bin and Lu, Lewei and Wei, Furu and Dai, Jifeng},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@inproceedings{tan-bansal-2019-lxmert,
    title = "{LXMERT}: Learning Cross-Modality Encoder Representations from Transformers",
    author = "Tan, Hao  and
      Bansal, Mohit",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/D19-1514",
    pages = "5100--5111",
}

@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@inproceedings{kim2021vilt,
  title={Vilt: Vision-and-language transformer without convolution or region supervision},
  author={Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle={International Conference on Machine Learning},
  pages={5583--5594},
  year={2021},
  organization={PMLR}
}

@article{wang2021vlmo,
  title={Vlmo: Unified vision-language pre-training with mixture-of-modality-experts},
  author={Wang, Wenhui and Bao, Hangbo and Dong, Li and Wei, Furu},
  journal={arXiv preprint arXiv:2111.02358},
  year={2021}
}

@InProceedings{Zhai_2022_CVPR,
    author    = {Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
    title     = {Scaling Vision Transformers},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {12104-12113}
}

@InProceedings{Zhou_2022_CVPR,
    author    = {Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
    title     = {Conditional Prompt Learning for Vision-Language Models},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {16816-16825}
}

@article{zhou2022learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={International Journal of Computer Vision},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}
@inproceedings{rouge2004package,
  title={A package for automatic evaluation of summaries},
  author={ROUGE, Lin CY},
  booktitle={Proceedings of Workshop on Text Summarization of ACL, Spain},
  year={2004}
}
@inproceedings{vedantam2015cider,
  title={Cider: Consensus-based image description evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4566--4575},
  year={2015}
}
@inproceedings{schuhmann2022laion,
  title={LAION-5B: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}
@inproceedings{shazeer2018adafactor,
  title={Adafactor: Adaptive learning rates with sublinear memory cost},
  author={Shazeer, Noam and Stern, Mitchell},
  booktitle={International Conference on Machine Learning},
  pages={4596--4604},
  year={2018},
  organization={PMLR}
}
@article{li2022ordinalclip,
  title={OrdinalCLIP: Learning Rank Prompts for Language-Guided Ordinal Regression},
  author={Li, Wanhua and Huang, Xiaoke and Zhu, Zheng and Tang, Yansong and Li, Xiu and Zhou, Jie and Lu, Jiwen},
  journal={arXiv preprint arXiv:2206.02338},
  year={2022}
}

@inproceedings{shin-etal-2020-autoprompt,
    title = "{A}uto{P}rompt: {E}liciting {K}nowledge from {L}anguage {M}odels with {A}utomatically {G}enerated {P}rompts",
    author = "Shin, Taylor  and
      Razeghi, Yasaman  and
      Logan IV, Robert L.  and
      Wallace, Eric  and
      Singh, Sameer",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2020.emnlp-main.346",
    pages = "4222--4235",
}

@article{jiang-etal-2021-know,
    title = "How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering",
    author = "Jiang, Zhengbao  and
      Araki, Jun  and
      Ding, Haibo  and
      Neubig, Graham",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "9",
    year = "2021",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    doi = "10.1162/tacl_a_00407",
    pages = "962--977",
}

@inproceedings{li-liang-2021-prefix,
    title = "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
    author = "Li, Xiang Lisa  and
      Liang, Percy",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2021.acl-long.353",
    pages = "4582--4597",
}

@inproceedings{petroni-etal-2019-language,
    title = "Language Models as Knowledge Bases?",
    author = {Petroni, Fabio  and
      Rockt{\"a}schel, Tim  and
      Riedel, Sebastian  and
      Lewis, Patrick  and
      Bakhtin, Anton  and
      Wu, Yuxiang  and
      Miller, Alexander},
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/D19-1250",
    pages = "2463--2473",
}

@inproceedings{zhong-etal-2021-factual,
    title = "Factual Probing Is [{MASK}]: Learning vs. Learning to Recall",
    author = "Zhong, Zexuan  and
      Friedman, Dan  and
      Chen, Danqi",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.398",
    doi = "10.18653/v1/2021.naacl-main.398",
    pages = "5017--5033",
}

@inproceedings{lester-etal-2021-power,
    title = "The Power of Scale for Parameter-Efficient Prompt Tuning",
    author = "Lester, Brian  and
      Al-Rfou, Rami  and
      Constant, Noah",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2021.emnlp-main.243",
    pages = "3045--3059",
}

@inproceedings{gao-etal-2021-making,
    title = "Making Pre-trained Language Models Better Few-shot Learners",
    author = "Gao, Tianyu  and
      Fisch, Adam  and
      Chen, Danqi",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2021.acl-long.295",
    pages = "3816--3830",
}

@article{cornia2018predicting,
  title={Predicting human eye fixations via an lstm-based saliency attentive model},
  author={Cornia, Marcella and Baraldi, Lorenzo and Serra, Giuseppe and Cucchiara, Rita},
  journal={IEEE Transactions on Image Processing},
  volume={27},
  number={10},
  pages={5142--5154},
  year={2018},
  publisher={IEEE}
}

@inproceedings{hii2017multigap,
  title={Multigap: Multi-pooled inception network with text augmentation for aesthetic prediction of photographs},
  author={Hii, Yong-Lian and See, John and Kairanbay, Magzhan and Wong, Lai-Kuan},
  booktitle={2017 IEEE International Conference on Image Processing (ICIP)},
  pages={1722--1726},
  year={2017},
  organization={IEEE}
}
@article{zhang2021mscan,
  title={MSCAN: Multimodal Self-and-Collaborative Attention Network for image aesthetic prediction tasks},
  author={Zhang, Xiaodan and Gao, Xinbo and He, Lihuo and Lu, Wen},
  journal={Neurocomputing},
  volume={430},
  pages={14--23},
  year={2021},
  publisher={Elsevier}
}

@article{french1999catastrophic,
  title={Catastrophic forgetting in connectionist networks},
  author={French, Robert M},
  journal={Trends in cognitive sciences},
  volume={3},
  number={4},
  pages={128--135},
  year={1999},
  publisher={Elsevier}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

@inproceedings{dhar2011high,
  title={High level describable attributes for predicting aesthetics and interestingness},
  author={Dhar, Sagnik and Ordonez, Vicente and Berg, Tamara L},
  booktitle={CVPR 2011},
  pages={1657--1664},
  year={2011},
  organization={IEEE}
}

@article{blei2003latent,
  title={Latent dirichlet allocation},
  author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  journal={Journal of machine Learning research},
  volume={3},
  number={Jan},
  pages={993--1022},
  year={2003}
}

@article{tu2022maxvit,
  title={MaxViT: Multi-Axis Vision Transformer},
  author={Tu, Zhengzhong and Talebi, Hossein and Zhang, Han and Yang, Feng and Milanfar, Peyman and Bovik, Alan and Li, Yinxiao},
  journal={European conference on computer vision},
  year={2022},
}

@article{koniq10k,
author={V. {Hosu} and H. {Lin} and T. {Sziranyi} and D. 
{Saupe}},
journal={IEEE Transactions on Image Processing},
title={KonIQ-10k: An Ecologically Valid Database for Deep 
Learning of Blind Image Quality Assessment},
year={2020},
volume={29},
pages={4041-4056}}


@article{mittal2012no,
  title={No-reference image quality assessment in the spatial domain},
  author={Mittal, Anish and Moorthy, Anush Krishna and Bovik, Alan Conrad},
  journal={IEEE Transactions on image processing},
  volume={21},
  number={12},
  pages={4695--4708},
  year={2012},
  publisher={IEEE}
}


@article{zhang2015feature,
  title={A feature-enriched completely blind image quality evaluator},
  author={Zhang, Lin and Zhang, Lei and Bovik, Alan C},
  journal={IEEE Transactions on Image Processing},
  volume={24},
  number={8},
  pages={2579--2591},
  year={2015},
  publisher={IEEE}
}


@article{xu2016blind,
  title={Blind image quality assessment based on high order statistics aggregation},
  author={Xu, Jingtao and Ye, Peng and Li, Qiaohong and Du, Haiqing and Liu, Yong and Doermann, David},
  journal={IEEE Transactions on Image Processing},
  volume={25},
  number={9},
  pages={4444--4457},
  year={2016},
  publisher={IEEE}
}


@article{kim2016fully,
  title={Fully deep blind image quality predictor},
  author={Kim, Jongyoo and Lee, Sanghoon},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={11},
  number={1},
  pages={206--220},
  year={2016},
  publisher={IEEE}
}


@article{bosse2017deep,
  title={Deep neural networks for no-reference and full-reference image quality assessment},
  author={Bosse, Sebastian and Maniry, Dominique and M{\"u}ller, Klaus-Robert and Wiegand, Thomas and Samek, Wojciech},
  journal={IEEE Transactions on image processing},
  volume={27},
  number={1},
  pages={206--219},
  year={2017},
  publisher={IEEE}
}

@article{zeng2017probabilistic,
  title={A probabilistic quality representation approach to deep blind image quality prediction},
  author={Zeng, Hui and Zhang, Lei and Bovik, Alan C},
  journal={arXiv preprint arXiv:1708.08190},
  year={2017}
}

@article{li2018has,
  title={Which has better visual quality: The clear blue sky or a blurry animal?},
  author={Li, Dingquan and Jiang, Tingting and Lin, Weisi and Jiang, Ming},
  journal={IEEE Transactions on Multimedia},
  volume={21},
  number={5},
  pages={1221--1234},
  year={2018},
  publisher={IEEE}
}


@article{zhang2018blind,
  title={Blind image quality assessment using a deep bilinear convolutional neural network},
  author={Zhang, Weixia and Ma, Kede and Yan, Jia and Deng, Dexiang and Wang, Zhou},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={30},
  number={1},
  pages={36--47},
  year={2018},
  publisher={IEEE}
}


@inproceedings{zhu2020metaiqa,
  title={MetaIQA: deep meta-learning for no-reference image quality assessment},
  author={Zhu, Hancheng and Li, Leida and Wu, Jinjian and Dong, Weisheng and Shi, Guangming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14143--14152},
  year={2020}
}


@inproceedings{su2020blindly,
  title={Blindly assess image quality in the wild guided by a self-adaptive hyper network},
  author={Su, Shaolin and Yan, Qingsen and Zhu, Yu and Zhang, Cheng and Ge, Xin and Sun, Jinqiu and Zhang, Yanning},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3667--3676},
  year={2020}
}


@article{hentschel2022clip,
  title={CLIP knows image aesthetics},
  author={Hentschel, Simon and Kobs, Konstantin and Hotho, Andreas},
  journal={Frontiers in Artificial Intelligence},
  volume={5},
  year={2022},
  publisher={Frontiers Media SA}
}

@inproceedings{wang2022exploring,
    author = {Wang, Jianyi and Chan, Kelvin CK and Loy, Chen Change},
    title = {Exploring CLIP for Assessing the Look and Feel of Images},
    booktitle = {AAAI},
    year = {2023}
}