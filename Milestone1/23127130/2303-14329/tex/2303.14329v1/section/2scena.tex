\section{Use cases and service scenarios}\label{sec_scena}
This section introduces use cases and service scenarios built with edge-based video analytics.
They are divided into three categories: \emph{Smart Cities}, \emph{Safety and Security}, and \emph{XR (including AR, VR, and MR)}.
%\begin{figure}
%  \centering
%  \includegraphics[width=0.35\textwidth]{./images/scena.eps}
%  \caption{Classification of edge-based video analytics use cases and service scenarios}
%\end{figure}

\subsection{Smart Services}

\subsubsection{Smart city}
The ``smart city" takes advantages of artificial intelligence into the urban construction for vehicle and human monitoring, city management and regulation of city flows and processes \cite{Jun2017SJ, Hu2018IOTJ}. Smart city applications include but are not limited to road traffic monitoring, road safety and security control, smart parking control, stolen cars search, etc. 
Specifically, Zhang \emph{et al.} \cite{Zhang2017nsdi} highlighted the resource-quality mapping correlation in smart city applications, including license plate reader, vehicle counter, crowd classifier and object tracker.
The core technology for most smart city applications is video analytics based on automated object detection \cite{Ananthanarayanan2019MobiSys}. However, it is tremendously high for the computation requirement for real-time object detection on live video streaming and the communication requirement for video uploading from cameras to the remote cloud server. Fortunately, it has been proved that the edge-based solution can help improve system efficiency and user experience when enjoying the smart city services. 
For example, Grassi \emph{et al.} \cite{Grassi2017SEC} proposed an edge-based in-vehicle video analytics system for monitoring parking spaces.
Xie \emph{et al.} \cite{Xie2018CyberC} proposed a video analytics-based intelligent indoor positioning system with the aid of edge computing.
With deep neural networks (DNNs), Barthelemy \emph{et al.} \cite{Barthelemy2019Sensors} designed an edge-based computer vision framework to monitor transportation while ensuring privacy of citizens. 
These works offer a novel way to analyze videos at edge to achieve bandwidth saving as well as data privacy. 


\subsubsection{Smart farming}
The ``smart farming" utilizes the technology of artificial intelligence to improve the quantity and quality of crops. By precisely improving the development of intellectual and automatic agriculture machine, farmers can significantly increase the efficiency of agricultural cultivation. Video analytics techniques can offer farmers an effective way to monitor the status and requirements of their animals or crops and adjust the planting methods correspondingly, thereby preventing animal and crop diseases and enhancing their health \cite{smartfarm}. The agricultural automation also presents a high requirement on the application latency, where the edge-based farming-related video analytics applications are expected to be tremendously focused in the near future. Recently, Alharbi \cite{Alharbi2021Access} proposed an integrated edge-cloud architectural paradigm to enhance the energy-efficiency of smart agriculture systems and diminish carbon emissions. 



\subsubsection{Smart health (e-Health)}
The public and personal health has always been the first place. In the year 2020, the World Health Organization declared the outbreak of COVID-19 as a pandemic.
To prevent the virus spread, it is a critically important issue to conduct a real-time temperature scanning on people in public areas and workplaces. 
Recently, many countries have deployed the AI thermal cameras for automated and contactless monitoring, especially for group temperature scanning. 
This can help implement strong protective measures while keeping the economy going. 

However, there are still some challenges for conducting efficient thermal video analytics. 
First and most important, it is essential for public health monitoring to run the accurate video analytics for temperature scanning and people tracking. 
Second, the temperature scanning results should be retrieved back in a real-time manner. 
Third, the cameras not only store temperature data but also personal identifiable thermal information, which might cause  privacy issues.
From the authors' perspective, the edge-based video analytics framework can better solve the above-mentioned issues than either the cloud-based video analytics and the in-situ video analytics. Specifically, a low latency performance can be achieved by placing the computation-intensive tasks (e.g., temperature scanning and people tracking) to the nearby edge servers. Meanwhile, the style of data storage at the edge brings information closer to the location, and it is tipped to improve privacy and security protection for  users.


\subsubsection{Smart business}
A key example for smart business is Amazon Go, which is a new kind of humanless stores without manual checkout.

Relied on computer vision techniques, the automated checkout system can map sales actions (e.g., picking products and checking out) to consumers, enabling the merchant to accurately charge customers for their picked products, e.g., \cite{Das2017CVPR}. In smart business system design, the video analytics technology has also been verified to be helpful in studies such as Cheng \emph{et al.} \cite{Cheng2018CoRR} and Xu \emph{et al.} \cite{Xu2019ISBN} where the former harnessed constrained resources in service industry via video analytics while the latter used autonomous cameras for object counting. 

Another popular business case is unmanned aerial vehicles (UAVs, also known as drones). Due to mobility and low cost, UAVs can help in various business applications such as express industry \cite{Wang2019IOTJ, Funabashi2019RTSS, Huang2020TITS}. Most drone-based delivery designs focused on the path scheduling problem aiming to minimize the total delivery time. 



\subsubsection{Smart education}
Smart education enables learners to learn by accessing digital resources through Internet.
Long \emph{et al.} \cite{Long2018FIE} presented a video analytics-based lecture framework that transforms literal teaching contents into visual formats, based on the lecture video system deployed at the University of Houston. 
Jang \emph{et al.} \cite{Jang2018SEC} implemented a smart conference system with two prototype video analytics applications (monitoring and tracking).
Tarasov \emph{et al.} \cite{Tarasov2018AIST} addressed the emotion classification application by utilizing video analytics in education systems.
Hu \emph{et al.} \cite{Hu2019TPDS} first designed an edge-based framework for the video analytics assisted education system design in the real-time manner.
The edge-based video analytics-assisted smart education applications have also been verified in practical system designs, e.g., the high-performance computing (HPC) education platform \cite{Wu2020PAAP_VBSSR, Wu2020PAAP}.


\subsection{Safety and Security}

\subsubsection{Surveillance}
In major public safety events (e.g., terrorist attacks in public transportation scenarios), law enforcement may want to track down the identified perpetrators \cite{Zhang2015MobiCom}. Across modern cities, a large amount of cameras are installed in public areas around us, including underground transportation networks, ground transportation networks, and air transportation networks. It is urgently required that law enforcement and counter-terrorism departments can realize the real-time tracking on the public threats \cite{Schindler2019MMM}.

By placing cameras in public places such as roads, public transport, retail stores, parks and libraries, relevant departments can help prevent, track and solve crime problems via video analytics technologies \cite{Khochare2019CCGRID}.
Many works focused on the video analytics-based surveillance applications.
For example, Yi \emph{et al.} \cite{Yi2017SEC_LAVEA} highlighted the low-latency video analytics requirements for public safety applications, such as counter-terrorism.
Jain \emph{et al.} \cite{Jain2019HotMobile} focused on applications based on multiple cameras, like crowd control and spotlight search. 
To sum up, the ``real-time" characteristic is one of the most essentially focused metrics in surveillance applications, where the edge computing technology can help boost the performance.


\subsubsection{Rescue applications}
Different from surveillance applications, rescue applications need to not only detect, but also identify and track the corresponding objects. 
In response to a disaster, the capabilities of a remotely controlled drone to search large areas quickly and efficiently with high definition cameras make rescue operations much more efficient and effective.
Chowdhery \emph{et al.} \cite{Chowdhery2018SECON} proposed a novel approach for drone video analytics based on model predictive compression methods.
Wang \emph{et al.} \cite{Wang2018SEC} built an adaptive video analytics pipeline for searching tasks in domains such as life search and rescue. 
George \emph{et al.} \cite{George2019HotMobile} investigated the use of drones for live rescue, where the key technical challenge lies in the ingest of live video streams, based on which the architectural plan can be timely updated.


\subsubsection{Road and traffic safety}
Given cameras installed along highways and city streets, the video analytics technologies can be used to re-identify and track the suspect's vehicle \cite{Lu2016SoCC_Optasia}. 
Qiu \emph{et al.} \cite{Qiu2018IoTDI} designed and implemented a video analytics system, named Kestrel, that tracks the vehicles' trajectories with the aid of a heterogeneous camera network. 

For the case of traffic monitoring, Chen \emph{et al.} \cite{Chen2016SEC} proposed an edge-based video analytics system to timely get the vehicle speed information and track speeding vehicles.
For urban traffic surveillance, Chen \emph{et al.} \cite{Chen2016BigMM} proposed a dynamic video stream processing scheme with the ability of real-time video processing and decision making. 
For the purpose of monitoring the mobility within a network, Barthelemy \emph{et al.} \cite{Barthelemy2019Sensors} designed a sensor that can detect and track objects of interest in real-time video feed with the aid of video analytics technologies. 



\subsection{XR (AR, VR, and MR)}
Extended reality (XR) technologies such as virtual reality (VR), augmented reality (AR), and mixed reality (MR) have emerged as methods to create simulated experiences that resemble the real world.
In the XR processing pipeline, a crucial task is the detection and tracking of real-world object positions, which enable accurate overlaying of virtual annotations on top of them \cite{Hu2021JNCA}.
For example, Jain \emph{et al.} \cite{Jain2015MobiSys_OverLay, Jain2016CoNEXT} proposed the first effort on end-to-end AR system implementation.
While commercial mixed reality platforms are capable of detecting surfaces and certain objects (e.g., a particular person) with the understand of 3D geometry of the scene, they often lack the capability to track and detect intricate and non-stationary objects.
In augmented vehicular reality system proposed in \cite{Qiu2018MobiSys_AVR}, vehicles exchange raw dynamic 3D sensor outputs (also named as point clouds).
Liu \emph{et al.} \cite{Liu2019MobiCom} designed a high accuracy object detection system for commodity AR/MR systems with 60fps. The system separates the rendering and offloading pipelines and employs a fast object tracking approach to ensure detection accuracy.


Zhang \emph{et al.} \cite{Zhang2017VR_ARNetwork} found that the latency lower bound to enable cloud-based mobile AR with acceptable QoE is around 250ms, which means that there exists room for further improvements.
Ran \emph{et al.} \cite{Ran2019HotNets} firstly provided a clear illustration of the information flow in multi-user augmented reality (AR). Specifically, they examined both Google ARCore\footnote{ARCore, a Google augmented reality SDK designed for Android system.} and Apple ARKit\footnote{ARKit, an Apple augmented reality SDK designed for iOS.}, and found that both of they employ either cloud-based or peer-to-peer architectures, where the edge-based architecture has not yet been taken into consideration. 
The battery capacity is the major constraint for executing XR applications.
Apicharttrisorn \emph{et al.} \cite{Apicharttrisorn2019SenSys} found that locally executing DNN-based object detection on mobile devices could significantly increase battery usage, which is a major concern for mobile users. They found that the screen, camera, and operating system already consume a considerable amount of battery (3-4W in their measurements), and the DNN executions can further drain a significant portion (1.7-3W) of the battery. 


To further compensate for the lack of bandwidth and computing capability, Qiao \emph{et al.} \cite{Qiao2018InternetComputing_WebAR} proposed a web AR service-provisioning framework with edge servers. Moreover, the collaboration among edge servers can enhance the XR system performance. 
Zhang \emph{et al.} \cite{Zhang2018HotMobile} enabled the coordination and collaboration of computation resources, e.g., sharing the results of computation intensive AR tasks, and annotating high quality AR modifications by users.



