\section{Observation and Analysis}
\label{sec:analysis}

In this section, we analyze the performance trend between global and local-only models as the query selector, with respect to the degree of class imbalance in local and global data distribution.
We synthetically adjust two indicators of inter-class diversity, $\alpha \in \{0.1, 1.0, \infty\}$ and $\rho \in \{1, 5, 10, 20\}$, on CIFAR-10 benchmark.
As $\alpha$ and $\rho$ get lower and higher, the levels of local heterogeneity and global imbalance increase, respectively (refer to Appendix\,\ref{sec:dataset_summary} for the detailed data distribution).
For both query selectors, we use Entropy sampling\cite{confidence_sampling} as an active learning algorithm, and the training set is progressively labeled with the query ratio of 10\% in each AL round.

\noindent\\
{\textbf{Comparison Metric.}}
We evaluate the superiority over AL rounds through pairwise comparison\cite{badge, alfa_mix}, widely used in conventional AL literature.
We repeat each experimental setup, a pair of $\alpha$ and $\rho$, with four different seeds and obtain a set of four accuracy results $a_{r}=\{a_{r,1},..., a_{r,4}\}$ at each round $r$. Then, we conduct a two-sided t-test, where $t$-score is defined by Definition\,\ref{def:t_score} for two given strategies $i$ and $j$. Note that the strategy denotes the combination of the sampling strategy and the type of query selector. 

\begin{definition}\!\!\!{\normalfont\cite{semenick1990tests}}\, Let $a_{r}^{i}$ and $a_{r}^{j}$ be the set of accuracies for two different FAL strategies $i$ and $j$. Then, $t$-score at AL round $r$ is formulated as:
\begin{equation}
\begin{gathered}
t_{r}^{ij} = \frac{\sqrt{4} \mu^{ij}_{r}}{\sigma^{ij}_{r}},\,\,\, \text{\normalfont where } \mu^{ij}_{r} \!= \!\frac{1}{4}\sum_{l=1}^{4} \big(a_{r,l}^{i} - a_{r,l}^{j}\big) \!\!\! \\ \text{\normalfont and}\,\,\, \sigma^{ij}_{r}=\sqrt{\frac{1}{3}\sum_{l=1}^{4} \Big(\big(a_{r,l}^{i} - a_{r,l}^{j}\big) - \mu^{ij}_{r}\Big)}.
\label{eq:t_score}
\end{gathered}
\end{equation}
\label{def:t_score}
\end{definition}
\vspace*{-0.4cm}
\noindent Here, the strategy $i$ is considered to beat the strategy $j$ if $t_r^{ij} >$ 2.776. Therefore, the \textit{winning rate} for all AL rounds is formulated as follows:
\begin{equation}
{\sf win}^{ij} =  \sum_{r=1}^{R} \frac{1}{R} \mathds{1}_{t_{r}^{ij} > \text{2.776}}.
\label{eq:cell_value}
\end{equation}
The value of winning rate becomes 1 if the strategy $i$ beats the strategy $j$ over all AL rounds.

\begin{figure}[t!]
\centering
\includegraphics[width=0.92\linewidth]{figure/analysis/cifar10_lt.pdf}
 \vspace*{-7pt}
\caption{Gap between the winning rate of global and local-only models by varying global imbalance ratio ($\rho$) and local heterogeneity ($\alpha$) on CIFAR-10 benchmark. The experimental setups for (a)-(d) are also compatible with Figure\,\ref{fig:obs2_cnt_acc} and Table\,\ref{tab:emd}.}
\vspace{-16pt}
\label{fig:cifar_lt}
\end{figure}


\begin{observation} 
The superiority of local-only and global query-selecting models varies according to the degree of local heterogeneity and global imbalance ratio.
\label{obs:obs1}
\end{observation}

In Figure\,\ref{fig:cifar_lt}, we summarize the performance gap between two query models depending on the local heterogeneity level\,(indicated by different shapes) and the global imbalance ratio\,(increased along x-axis).
The y-axis represents the gap of the winning rate in Eq.\,\eqref{eq:cell_value} between global and local-only models; thus, the value becomes positive up to +1 if the global model beats the local-only model, otherwise negative up to -1. 
At a glance, there is a clear and consistent superiority of two query models according to $\alpha$ and $\rho$, where the dominance has intensified toward both extremes (\eg, upper right and lower left).
This observation contradicts the previous findings that the global model has always outperformed the local-only model as the query selector in a FAL framework\cite{f_al}. 
We provide more in-depth analysis in following Obs.\,\ref{obs:obs2} and Obs.\,\ref{obs:obs3}. \qed

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[b]{0.47\linewidth}
    \centering
\includegraphics[width=\linewidth]{figure/analysis/obs2/rho1_alpha01_total.pdf}
    \caption{Low global imbalance ($\rho=1$) and high heterogeneity ($\alpha=0.1$).}     
    \end{subfigure}
    \hspace{15pt}
    \centering
    \begin{subfigure}[b]{0.47\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/analysis/obs2/rho1_alpha_inf_total.pdf}
    \caption{Low global imbalance ($\rho=1$) and low heterogeneity ($\alpha=\infty$).}       
    \end{subfigure}
    \begin{subfigure}[b]{0.47\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/analysis/obs2/rho20_alpha_01_total.pdf}
    \caption{High global imbalance ($\rho=20$) and high heterogeneity ($\alpha=0.1$).}
    \end{subfigure}
    \hspace{15pt}
    \begin{subfigure}[b]{0.47\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/analysis/obs2/rho20_alpha_inf_total.pdf}
    \caption{High global imbalance ($\rho=20$) and low heterogeneity ($\alpha=\infty$).}  
    \end{subfigure}
    \vspace*{-0.2cm}
    \caption{Matrices of data count\,(left) and class-wise accuracy\,(right) for CIFAR-10, with four combinations of $\rho=\{1, 20\}$ and $\alpha=\{0.1, \infty\}$. k1--10 denote ten clients, c1--10 are ten classes of CIFAR-10. 
    There are two types of data counts, \# of per-client local instances (1-10th rows) and aggregated instances over all clients (the last row). Similarly, the test accuracy is measured with local-only models (1-10th rows) and a global model (the last row). 
    (a)--(d) setups correspond to those of Figure\,\ref{fig:cifar_lt}. See Appendix\,\ref{sec:detail_analysis_matrices} for the more cases.
    }
    \vspace*{-0.2cm}
    \label{fig:obs2_cnt_acc}
\end{figure*}


\noindent \\
\vspace{-15pt}
\begin{observation} 
As local heterogeneity increases\,($\alpha \downarrow$), a local-only query selector is preferred due to the increased significance of local inter-class diversity. 
\label{obs:obs2}
\end{observation}


As the collapse of the local inter-class balance (\ie, lower $\alpha$) incurs severe performance degradation due to a weight divergence\cite{astraea, fedavg}, addressing local imbalance can improve the learning stability and performance.
Since the local-only models are separately trained on each client, in general, the local-only model has shown higher confidence for its own data distribution than the global model\cite{fedbabu, fedrep}.
In Figure\,\ref{fig:obs2_cnt_acc}, we visualized the number of class instances and the class-wise test accuracy in the first AL round (see the caption for details).
Specifically, we confirmed a high correlation between counts and accuracy in Figure\,\ref{fig:obs2_cnt_acc}-(a), such that the local-only models have higher accuracy than the global model for major classes of their data distribution.
Thus, by the nature of favoring low-confident instances in AL, the local-only model tends to select the instances with local minority classes as the query.




More precisely, we verify that the local-only model indeed queries the locally balanced set using earth mover's distance\,(EMD)\cite{emd_measure}. 
In Table\,\ref{tab:emd}, local EMD measures the mean of distance between class distribution of local query sets and a uniform distribution. The lower the value, the more balanced the locally queried instances.
As shown in Table\,\ref{tab:emd}-(a) with high local heterogeneity, the local EMD of the local-only model\,(L) is lower than that of the global model\,(G). 
That is, the local-only model queries more diverse instances than the global model with respect to the local inter-class diversity. 

% 
Meanwhile, in the case of (b), the global model, trained with more samples, has higher accuracy over the classes due to little distribution discrepancy.
Although the more accurate model is likely to have the higher prediction confidence, it does not mean that it is better at identifying the required instances based on the current local dataset, which the global model had not directly learned. 
In practice, the local-only model still chose the more locally balanced query set (Table\,\ref{tab:emd}-(b)), and we supposed this contradiction makes no sizeable winning gap of the case (b) in Figure\,\ref{fig:cifar_lt}. \qed


\begin{table}[t!]
    \small
    \renewcommand*{\arraystretch}{1}
    \addtolength{\tabcolsep}{-1pt}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|c|cccc|cccc}
         \toprule
        & & \multicolumn{4}{c|}{\bf Obs.\,\ref{obs:obs2}: Local EMD $(\downarrow)$} & \multicolumn{4}{c}{\bf Obs.\,\ref{obs:obs3}: Global EMD $(\downarrow)$} \\
        \cmidrule(l{2pt}r{2pt}){3-6} \cmidrule(l{2pt}r{2pt}){7-10}
        \multirow{-2.5}{*}{\!\!Case} & \multirow{-2.5}{*}{\!Model\,\!\!} & 10\% &  20\% & 30\% & 40\% &  10\% & 20\% & 30\% & 40\% \\
        \midrule
        \multirow{2}{*}{\!\!(a)} & G & 0.632 & 0.638 & 0.641 & 0.643 & 0.019 & 0.064 & 0.086 & 0.095  \\
        & L & 0.632 &  0.597 &  0.592 &  0.595 & 0.019 &  0.050 &  0.050 &  0.046  \\
        \hline
        \multirow{2}{*}{\!\!(b)} & G & 0.049 & 0.077 & 0.070 & 0.084 & 0.014 & 0.070 & 0.066 & 0.063  \\
        & L & 0.049 &  0.042 &  0.054 &  0.059 & 0.014 &  0.025 &  0.044 &  0.053  \\
        \hline
       \multirow{2}{*}{\!\!(c)}  & G & 0.692 & 0.680 & 0.676 & 0.674 & 0.377 &  0.300 &  0.294 &  0.294  \\
        & L & 0.692 &  0.641 &  0.633 &  0.636 & 0.377 & 0.334 & 0.326 & 0.321 \\\hline
        \multirow{2}{*}{\!\!(d)}  & G & 0.371 &  0.298 &  0.284 &  0.274 & 0.368 &  0.294 &  0.282 &  0.272 \\
        & L & 0.371 & 0.313 & 0.293 & 0.290 & 0.368 & 0.309 & 0.287 & 0.288  \\ \bottomrule
    \end{tabular}}
    \vspace*{-0.2cm}
    \caption{Local EMD and global EMD on CIFAR-10. We summarize the results of four AL rounds with the labeling budget of 10\% per round. (a)--(d) setups correspond to those of Figure \ref{fig:cifar_lt}. See Appendix\,\ref{sec:detail_analysis_emd} for EMDs of more cases.}
    \label{tab:emd}
    \vspace{-12pt}
\end{table}


\begin{observation}
As the degree of global class imbalance increases ($\rho \uparrow$), it is more advantageous to exploit a global model that alleviates the global class imbalance.
\label{obs:obs3}
\end{observation}

Based on Obs.\,\ref{obs:obs2}, the local-only model should outperform the global model in the case (c), but there is no clear superiority between them with respect to the winning rate in the case (c) of Figure \ref{fig:cifar_lt}.
The only answer for this conundrum is the presence of global minority classes due to the high global imbalance ratio.
The local heterogeneity is obviously a crucial factor by Obs.\,\ref{obs:obs2}, but global class imbalance is also another factor that significantly degrades the classification performance in the FAL framework.
Here, the major challenge is that neither the central server nor local clients cannot access any information of aggregated data due to privacy preservation.
The only way to address this problem, we should utilize the global model that implicitly learns the knowledge of the entire data distribution through the aggregation phase in Eq.\,\eqref{eq:reform_fl_loss}.

We introduce an additional global EMD, the indicator of measuring the inter-class diversity of the aggregated queried set over all clients. 
As can be seen in Table \ref{tab:emd}-(c), where the global imbalance ratio is high, we confirm that the global query selector\,(G) favors to query global minority classes. 
The global EMD of the global model is lower than that of the local-only model, \ie the more globally balanced query set, but the local EMD is the opposite. 

Meanwhile, in the case of (d), the minority classes are always the same from the global and local perspectives.
It is different from the case (b), where the minority classes with respect to the accuracy differ in each client depending on the informativeness of instances despite the same instance number.
Therefore, in this scenario, the global model has high confidence even in local datasets, leading to significantly overwhelming the local-only model in the case (d) of Figure \ref{fig:cifar_lt}.
In conclusion, the global inter-class diversity is an essential factor when global imbalance exists. \qed 

