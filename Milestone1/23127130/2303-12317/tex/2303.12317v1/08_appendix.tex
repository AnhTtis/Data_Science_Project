\appendix
\onecolumn
\addcontentsline{toc}{section}{Appendices}

\clearpage

\section{Detailed Local Data Distribution}
\label{sec:dataset_summary}

We adopt a Latent Dirichlet Allocation (LDA) strategy for Non-IID setting \cite{fedma, moon}, where each client $k$ is assigned the partition of classes by sampling $\mathbf{p}_k \sim Dir(\alpha \cdot \mathds{1})$, where $\mathds{1} \in \, \mathbb{R}^C$.
$\alpha$ is a concentration parameter that controls the local heterogeneity level. The smaller $\alpha$, the more heterogeneous data distribution.
Since we consider a fairness issue in the FAL framework, the total number of samples should be equally partitioned for all clients.
Therefore, we made a doubly stochastic matrix $P = [\tilde{\mathbf{p}}_1, \dots, \tilde{\mathbf{p}}_K]^\top$ by scaling $\mathbf{p}_k$ to $\tilde{ \mathbf{p}}_k$, when the number of client and class are same (i.e., $P$ is a square matrix).
Note that we set the sum of columns and rows to the proper values for a non-square matrix.
We visualized the examples of CIFAR-10 when the clients $K=10$ in Figure \ref{fig:data_dist}.

\begin{figure}[h!]
\centering
\begin{minipage}{0.94\linewidth}
    \begin{subfigure}[b]{0.32\linewidth}
    \includegraphics[width=\linewidth]{figure/data_distribution/rho1/dir0.1_rho1.pdf}
    \caption{\small {$\rho$ = 1 and $\alpha$ = 0.1}}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
    \includegraphics[width=\linewidth]{figure/data_distribution/rho1/dir1_rho1.pdf}
    \caption{\small {$\rho$ = 1 and $\alpha$ = 1.0}}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
    \includegraphics[width=\linewidth]{figure/data_distribution/rho1/dir10000_rho1.pdf}
    \caption{\small {$\rho$ = 1 and $\alpha$ = $\infty$}}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/data_distribution/rho5/dir0.1_rho5.pdf}
    \caption{\small {$\rho$ = 5 and $\alpha$ = 0.1}}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/data_distribution/rho5/dir1_rho5.pdf}
    \caption{\small {$\rho$ = 5 and $\alpha$ = 1.0}}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/data_distribution/rho5/dir10000_rho5.pdf}
    \caption{\small {$\rho$ = 5 and $\alpha$ = $\infty$}}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/data_distribution/rho10/dir0.1_rho10.pdf}
    \caption{\small {$\rho$ = 10 and $\alpha$ = 0.1}}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/data_distribution/rho10/dir1_rho10.pdf}
    \caption{\small {$\rho$ = 10 and $\alpha$ = 1.0}}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/data_distribution/rho10/dir10000_rho10.pdf}
    \caption{\small {$\rho$ = 10 and $\alpha$ = $\infty$}}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/data_distribution/rho20/dir0.1_rho20.pdf}
    \caption{\small {$\rho$ = 20 and $\alpha$ = 0.1}}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/data_distribution/rho20/dir1_rho20.pdf}
    \caption{\small {$\rho$ = 20 and $\alpha$ = 1.0}}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/data_distribution/rho20/dir10000_rho20.pdf}
    \caption{\small {$\rho$ = 20 and $\alpha$ = $\infty$}}
    \end{subfigure}
\end{minipage}
\caption{Visualization of the client data distribution on CIFAR-10. Each color represents a different class. The higher $\rho$ denotes the more global imbalanced distribution. The higher $\alpha$ denotes the more locally balanced data.}
\label{fig:data_dist}
\end{figure}

\clearpage

\section{Detailed Analysis Results}
\label{sec:detail_analysis}


\subsection{Detailed Matrices for Data Counts and Accuracy}
\label{sec:detail_analysis_matrices}

We summarized the detailed matrices for the combinations of $\rho$ = $\{$1, 5, 10, 20$\}$ and $\alpha$ = $\{$0.1, 1.0, $\infty \}$.

\begin{figure*}[!h]
\centering
\begin{minipage}{0.8\linewidth}
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/analysis/obs2/appendix/rho1_alpha01_total.pdf}
    \caption{$\rho$ = 1 and $\alpha$ = 0.1}         
    \end{subfigure}
    \hfill
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/analysis/obs2/appendix/rho1_alpha1_total_v.pdf}
    \caption{$\alpha$ = 1.0}       
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/analysis/obs2/appendix/rho1_alpha_inf_total.pdf}
    \caption{$\alpha$ = $\infty$}     
    \end{subfigure}
    \vspace*{-0.2cm}
\end{minipage}
\caption{Matrices of data count (top) and class-wise accuracy (down) when $\rho$ = 1.}
\vspace*{-0.2cm}
\label{fig:cnt_acc_rho1}
\end{figure*}

\vspace{-10pt}
\begin{figure*}[!h]
\centering
\begin{minipage}{0.8\linewidth}
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/analysis/obs2/appendix/rho5_alpha01_total.pdf}
    \caption{$\alpha$ = 0.1}         
    \end{subfigure}
    \hfill
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/analysis/obs2/appendix/rho5_alpha1_total.pdf}
    \caption{$\alpha$ = 1.0}       
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/analysis/obs2/appendix/rho5_alpha_inf_total.pdf}
    \caption{$\alpha$ = $\infty$}     
    \end{subfigure}
    \vspace*{-0.2cm}
\end{minipage}
\caption{Matrices of data count (top) and class-wise accuracy (down) when $\rho$ = 5.}
\vspace*{-0.2cm}
\label{fig:cnt_acc_rho5}
\end{figure*}

\newpage

\begin{figure*}[!h]
\centering
\begin{minipage}{0.8\linewidth}
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/analysis/obs2/appendix/rho10_alpha01_total.pdf}
    \caption{$\alpha$ = 0.1}         
    \end{subfigure}
    \hfill
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/analysis/obs2/appendix/rho10_alpha1_total.pdf}
    \caption{$\alpha$ = 1.0}       
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/analysis/obs2/appendix/rho10_alpha_inf_total.pdf}
    \caption{$\alpha$ = $\infty$}     
    \end{subfigure}
    \vspace*{-0.2cm}
\end{minipage}
\caption{Matrices of data count (top) and class-wise accuracy (down) when $\rho$ = 10.}
\vspace*{-0.2cm}
\label{fig:cnt_acc_rho10}
\end{figure*}


\begin{figure*}[!h]
\centering
\begin{minipage}{0.8\linewidth}
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/analysis/obs2/appendix/rho20_alpha_01_total.pdf}
    \caption{$\alpha$ = 0.1}         
    \end{subfigure}
    \hfill
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/analysis/obs2/appendix/rho20_alpha_1_total.pdf}
    \caption{$\alpha$ = 1.0}       
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figure/analysis/obs2/appendix/rho20_alpha_inf_total.pdf}
    \caption{$\alpha$ = $\infty$}     
    \end{subfigure}
    \vspace*{-0.2cm}
\end{minipage}
\caption{Matrices of data count (top) and class-wise accuracy (down) when $\rho$ = 20.}
\vspace*{-0.2cm}
\label{fig:cnt_acc_rho20}
\end{figure*}

\newpage
\subsection{Detailed Earth Mover Distance}
\label{sec:detail_analysis_emd}
Table \ref{tab:detail_emd} \ summarizes the detailed local and global EMD for the combinations of $\rho$ = $\{$1, 5, 10, 20$\}$ and $\alpha$ = $\{$0.1, 1.0, $\infty \}$.

\begin{table}[H]
\centering
\small
\renewcommand*{\arraystretch}{0.85}
\addtolength{\tabcolsep}{1pt}
\resizebox{0.8\linewidth}{!}{
\begin{tabular}{cc|c|ccccc|ccccc}
\toprule
\multirow{2}{*}{$\rho$} &
  \multirow{2}{*}{$\alpha$} &
  \multirow{2}{*}{model} &
  \multicolumn{5}{c|}{Local EMD $(\downarrow)$} &
  \multicolumn{5}{c}{Global EMD $(\downarrow)$} \\
\cmidrule(l{2pt}r{2pt}){4-8} \cmidrule(l{2pt}r{2pt}){8-13}
                   &                           &   & 10\%  & 20\%  & 30\%  & 40\%  & 50\%  & 10\%  & 20\%  & 30\%  & 40\%  & 50\%  \\
                   \midrule
\multirow{2}{*}{1} & \multirow{2}{*}{0.1}      & G & 0.632 & 0.638 & 0.641 & 0.643 & 0.646 & 0.019 & 0.064 & 0.086 & 0.095 & 0.091 \\
                   &                           & L & 0.632 & 0.597 & 0.592 & 0.595 & 0.601 & 0.019 & 0.050 & 0.050 & 0.046 & 0.055 \\ \midrule
\multirow{2}{*}{1} & \multirow{2}{*}{1.0}      & G & 0.297 & 0.297 & 0.300 & 0.300 & 0.300 & 0.017 & 0.066 & 0.079 & 0.084 & 0.083 \\
                   &                           & L & 0.297 & 0.248 & 0.232 & 0.235 & 0.241 & 0.017 & 0.053 & 0.065 & 0.068 & 0.074 \\ \midrule
\multirow{2}{*}{1} & \multirow{2}{*}{$\infty$} & G & 0.049 & 0.077 & 0.070 & 0.065 & 0.061 & 0.014 & 0.070 & 0.066 & 0.063 & 0.060 \\
                   &                           & L & 0.049 & 0.042 & 0.054 & 0.059 & 0.066 & 0.014 & 0.025 & 0.044 & 0.053 & 0.062 \\  \midrule
% Rho = 5

\multirow{2}{*}{5} & \multirow{2}{*}{0.1}      & G & 0.662 & 0.663 & 0.666 & 0.666 & 0.669 & 0.211 & 0.201 & 0.196 & 0.194 & 0.195 \\ 
                   &                           & L & 0.662 & 0.628 & 0.627 & 0.628 & 0.634 & 0.211 & 0.232 & 0.232 & 0.236 & 0.228 \\ \midrule
\multirow{2}{*}{5} & \multirow{2}{*}{1.0}      & G & 0.402 & 0.391 & 0.387 & 0.388 & 0.389 & 0.206 & 0.188 & 0.180 & 0.173 & 0.169 \\
                   &                           & L & 0.402 & 0.309 & 0.306 & 0.306 & 0.341 & 0.206 & 0.200 & 0.201 & 0.196 & 0.196 \\ \midrule
\multirow{2}{*}{5} & \multirow{2}{*}{$\infty$} & G & 0.213 & 0.190 & 0.178 & 0.168 & 0.165 & 0.206 & 0.185 & 0.174 & 0.162 & 0.163 \\
                   &                           & L & 0.213 & 0.179 & 0.176 & 0.180 & 0.180 & 0.206 & 0.176 & 0.173 & 0.178 & 0.180 \\ \midrule

\multirow{2}{*}{10} & \multirow{2}{*}{0.1}      & G & 0.692 & 0.685 & 0.687 & 0.685 & 0.685 & 0.280 & 0.268 & 0.267 & 0.265 & 0.267 \\
                    &                           & L & 0.692 & 0.652 & 0.650 & 0.654 & 0.660 & 0.280 & 0.270 & 0.277 & 0.282 & 0.281 \\ \midrule
\multirow{2}{*}{10} & \multirow{2}{*}{1.0}      & G & 0.491 & 0.463 & 0.459 & 0.456 & 0.455 & 0.297 & 0.263 & 0.247 & 0.244 & 0.242 \\
                    &                           & L & 0.491 & 0.408 & 0.402 & 0.405 & 0.415 & 0.297 & 0.256 & 0.257 & 0.255 & 0.255 \\ \midrule
\multirow{2}{*}{10} & \multirow{2}{*}{$\infty$} & G & 0.315 & 0.240 & 0.229 & 0.223 & 0.222 & 0.303 & 0.237 & 0.226 & 0.222 & 0.221 \\
                    &                           & L & 0.315 & 0.238 & 0.237 & 0.239 & 0.240 & 0.303 & 0.237 & 0.234 & 0.237 & 0.239 \\ \midrule

\multirow{2}{*}{20} & \multirow{2}{*}{0.1}      & G & 0.692 & 0.680 & 0.676 & 0.674 & 0.677 & 0.377 & 0.300 & 0.294 & 0.294 & 0.298 \\
                    &                           & L & 0.692 & 0.641 & 0.633 & 0.636 & 0.644 & 0.377 & 0.304 & 0.326 & 0.321 & 0.323 \\ \midrule
\multirow{2}{*}{20} & \multirow{2}{*}{1.0}      & G & 0.481 & 0.455 & 0.450 & 0.448 & 0.448 & 0.374 & 0.311 & 0.300 & 0.295 & 0.292 \\
                    &                           & L & 0.481 & 0.448 & 0.437 & 0.431 & 0.437 & 0.374 & 0.354 & 0.342 & 0.303 & 0.304 \\ \midrule
\multirow{2}{*}{20} & \multirow{2}{*}{$\infty$} & G & 0.371 & 0.298 & 0.284 & 0.274 & 0.276 & 0.368 & 0.294 & 0.282 & 0.271 & 0.272 \\
                    &                           & L & 0.371 & 0.313 & 0.293 & 0.290 & 0.289 & 0.368 & 0.309 & 0.287 & 0.288 & 0.289 \\
                   
                   
                   
                   \bottomrule
\end{tabular}}
    \caption{Local and global EMD on CIFAR-10 for 12 combinations of $\rho$ = $\{$1, 5, 10, 20$\}$ and $\alpha$ = $\{$0.1, 1.0, $\infty \}$.}
    \label{tab:detail_emd}
\end{table}

\clearpage
\section{Pseudo Algorithm of LoGo}
\label{sec:pseudo_algorithm}


Algorithm\,\ref{alg:logo} is the overall pipeline of the FAL framework.
Specifically, we summarize the detailed pseudocode of our \algname{} algorithm.

\begin{algorithm}[h]
\small
\caption{FAL framework with \algname{} algorithm}
\label{alg:logo}
\textbf{Input}: initialized parameter $\Theta$; unlabeled data $U^{\scaleto{1}{4pt}}$; sampling strategy $\mathcal{A}$; labeling budget $B$; clients number $K$; AL round $R$; \\
\textbf{Output}: trained parameter $\Theta^{\scaleto{R*}{4pt}}$ \\
\\
\textbf{\# Alternating AL and FL Procedure}
\begin{algorithmic}[1]
\FOR{$k=1, \dots, K$}
\STATE Randomly sample $L_{\scaleto{k}{4pt}}^{\scaleto{1}{4pt}}= \{ x_{\scaleto{1}{4pt}}, \dots, x_{\scaleto{B}{4pt}} \}$ from $U_{\scaleto{k}{4pt}}^{\scaleto{1}{4pt}}$, and $U_k^{2} = U_k^1 \setminus L_k^1$
\STATE Get the labeled set $D_{\scaleto{k}{4pt}}^{\scaleto{1}{4pt}}$\, from the oracles
\ENDFOR
\STATE $\Theta^{\scaleto{1*}{4pt}}=$\,\texttt{FedAvg}\,($\Theta$, $D^{\scaleto{1}{4pt}}, K$) \\
\, \\
\FOR{$r=2, \dots, R$}
\FOR{$k=1, \dots, K$}
\STATE $D^{r}_k, \,U_k^{r+1}=$\,\,\texttt{LoGo}\,($\Theta^{(r-1)*}$, $D^{r-1}_{\scaleto{k}{4pt}}, U_k^r$)
\ENDFOR
\STATE $\Theta^{r*}=$\,\texttt{FedAvg}\,($\Theta$, $D^{r}, K$)
\ENDFOR
\end{algorithmic}
\, \\
\textbf{Function}\,\,\texttt{LoGo}:
\begin{algorithmic}[1] 
\STATE \textbf{\# Macro Step}
\STATE 
Train a local-only model $\Theta^{(r-1)}_{k*}$ from the scratch only using $D_k^{r-1}$
\STATE  For each $x\in U_k^r$, calculate the gradient embedding $g_{\hat{y}}^x$  by Eq.\,\eqref{eq:gradient}
\STATE Cluster $U_k^r$ into $B$ clusters($\mathcal{C}_1,...,\mathcal{C}_B$) by Eq.\,\eqref{eq:kmeans} \\
\, \\
\STATE \textbf{\# Micro Step}
\STATE 
$L_k^r= \emptyset $
\FOR{$\mathcal{C}_{\scaleto{i}{4pt}}=\mathcal{C}_{\scaleto{1}{4pt}}, \dots, \mathcal{C}_{\scaleto{B}{4pt}}$}
\STATE $L_k^r = L_k^r \cup \{ \mathcal{A}(\mathcal{C}_{\scaleto{i}{4pt}}, \Theta^{(r-1)*}, 1) \}$
\STATE $D_k^r = D_k^{r-1} \cup D_k^r$\, and\, $U_{\scaleto{k}{4pt}}^{\scaleto{r+1}{4pt}} = U_{\scaleto{k}{4pt}}^{\scaleto{r}{3pt}} \setminus L_k^r$
\ENDFOR 
\STATE \textbf{return}  $D_k^r$, \,$U_k^{r+1}$
\end{algorithmic}
\, \\
\textbf{Function}\,\,\texttt{FedAvg}:
\begin{algorithmic}[1]
\FOR{$\,FL\,\,round$\,}
\STATE Distribute $\Theta$ to the all client
\FOR{$k = 1, \dots, K$}
\STATE Train $\Theta_k$ on $D_k^r$ by minimizing $\mathbb{E}_{D_k^r}[\ell(x,y; \Theta_k)]$
\ENDFOR
\STATE $\Theta = (\sum_k \Theta_k) / K$
\ENDFOR
\STATE \textbf{return} $\Theta$
\end{algorithmic}

\end{algorithm}

\clearpage
\section{Experimental Settings}
\label{sec:exp_settings}

\subsection{Datasets}
We mainly experimented on two natural image datasets (CIFAR-10\footnote{https://www.cs.toronto.edu/~kriz/cifar.html}, SVHN\footnote{http://ufldl.stanford.edu/housenumbers}) and three medical image datasets\footnote{https://medmnist.com/} (PathMNIST, DermaMNIST, OrganAMNIST). 
Table \ref{tab:dataset_summray} provides a summary of the five datasets.
For the details of partitioning data to each client, please refer to Appendix\,\ref{sec:dataset_summary}.

\input{table/dataset_summary}


\subsection{Implementation Details}
For the FL training pipeline, we set the number of FL rounds to 100 and local update epochs to 5.
We used a SGD optimizer with the initial learning rate of 0.01 and the momentum of 0.9.
The learning rate was decayed by 0.1 at half and three-quarters of federated learning rounds to ensure convergence, and we used a random horizontal flipping as data augmentation.
For training local-only models, we trained the model using the aforementioned settings for 50 epochs. However, the training was terminated if the training accuracy reached 99\%.
It should be noted that we averaged the classification accuracy of the last 5 epochs in each round and repeated all experiments with four different seeds.
All algorithms were implemented using PyTorch 1.11.0 and executed using NVIDIA RTX 3080 GPUs.




\subsection{Experimental Categories}
A total of six categories were considered in the evaluation:
\begin{enumerate}
\item {`Query selector'} of whether to use a local-only or global model with the six compared strategies. 
\item  {`Heterogeneity level'} of varying degree of class imbalance. We adopt a Latent Dirichlet Allocation (LDA) \cite{moon} strategy. 
For example, the smaller $\alpha$, the more heterogeneous the data distribution. 
\item  {`Imbalance ratio'} of used datasets. 
We classified five datasets for evaluation based on the imbalance ratio $\rho$.
CIFAR-10 and PathMNIST belong to a low imbalance ratio ($\rho<2$), and SVHN, DermaMNIST, and OrganAMNIST belong to a high imbalance ratio ($\rho\geq 2$).
\item  {`Model architecture.'} We employed four layers of convolution neural network for a base architecture and also experimented with ResNet-18 \cite{resnet} and MobileNet \cite{mobilenet}. 
\item  `{Budget size}' for labeling. We tested small (1\%), medium (5\%), and large (20\%) budget sizes for each round. 
\item  {`Model initialization'} of either learning from scratch (random) or from the checkpoint of the previous AL round (continue). \looseness=-1
\end{enumerate}

\newpage
\subsection{Combination of experimental settings}
We compared our algorithms and baselines in 38 comprehensive experimental settings, which are the combinations of the aforementioned six categories.
All the experimental combinations we performed are summarized in Table \ref{tab:setting_summary}.

\input{table/setting_summary}


\clearpage
\section{Computational Cost of Query Selection}
\label{sec:computational_cost}
In Table\,\ref{tab:time_cost}, we measured the wallclock time for various combinations of the algorithm, query selector, and labeling ratio.
We confirmed that as the percentage of labeled data increases, the time required to measure the importance score with the global model decreases due to the reduced amount of unlabeled data.
Conversly, the local-only model takes more time as it requires training on a larger number of labeled samples.
Our LoGo algorithm shows a comparable computational cost to the baselines that use the local-only model\,(L) for query selection.
Note that we used a simple Entropy sampling within LoGo algorithm to measure the uncertainty, and the only possible bottleneck is \textit{k}-means clustering in the Macro step.


\input{table/timecost}

\section{LoGo with Various FL Methods}
\label{sec:various_fl_algo}
We have further experimented with two federated learning algorithms, FedProx\cite{fedprox} and SCAFFOLD\cite{scaffold}, in conjunction with AL strategies.
Specifically, we compared our LoGo with baselines that demonstrated Top-1 or Top-2 performance more than once in Table\,\ref{tab:acc_comparision}. The experimental configurations are same to those used in Table\,\ref{tab:acc_comparision}.
As summarized in Table\,\ref{tab:compare_fedprox_scaffold}, LoGo consistently outperforms the baselines for both federated learning algorithms.
This observation suggests that LoGo is an orthogonal selection algorithm that can be integrated with any federated learning algorithm, having potential to improve the performance in various applications.

\input{table/fedrpox_scaffold}


\clearpage
\section{Detailed Experimental Results}
\label{sec:exp_detail_results}

In this Section, \ref{sec:detail_comp_matrix} summarizes all the comparison matrices results based on six categories: query selector, heterogeneity level, imbalance ratio, model architecture, budget size, and model initialization in Figure\,\ref{fig:bar_graph}. Figure\,\ref{fig:comp_selector}--\ref{fig:comp_model_init} are breakdowns of the matrix in Figure\,\ref{fig:comparision_matrix} into six categories.
\ref{sec:detail_comp_performance} provides comprehensive line plots for 38 experimental settings.
It can be seen that \algname{} overwhelms the baselines in most cases at both each category and detailed experimental setting level.


\subsection{Detailed Penalty Comparision Matrix}
\label{sec:detail_comp_matrix}

A maximum value of each matrix corresponds to Table\,\ref{tab:setting_summary}, and the bar plots in Figure\,\ref{fig:bar_graph} are calculated from these matrices.

\begin{figure*}[htb]
\centering
    \begin{subfigure}[b]{0.3\linewidth}
    \raggedleft
    \includegraphics[width=\linewidth]{figure/experiments/comparison/query_selector/global_comp.pdf}
    \caption{Global}
    \end{subfigure}
    \hspace{10pt}
    \begin{subfigure}[b]{0.3\linewidth}
    \raggedright
    \includegraphics[width=\linewidth]{figure/experiments/comparison/query_selector/local.pdf}
    \caption{Local-only}
    \end{subfigure}
    \caption{Pairwise penalty matrix for a query selector category. The maximum value of both matrices is 19.}
    \label{fig:comp_selector}
\end{figure*}

\vspace{-15pt}
\begin{figure*}[htb]
    \centering
    \begin{subfigure}[b]{0.3\linewidth}
    \includegraphics[width=\linewidth]{figure/experiments/comparison/dir/dir0_1.pdf}
    \caption{$\alpha = 0.1$}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.3\linewidth}
    \includegraphics[width=\linewidth]{figure/experiments/comparison/dir/dir1_0.pdf}
    \caption{$\alpha = 1.0$}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.3\linewidth}
    \includegraphics[width=\linewidth]{figure/experiments/comparison/dir/dir10_0.pdf}
    \caption{$\alpha = \infty$}
    \end{subfigure}
    \caption{Pairwise penalty matrix for a heterogeneity level category. The maximum value of three matrices is 30, 4, and 4.}
    \label{fig:comp_hetero}
\end{figure*}


\vspace{-15pt}
\begin{figure*}[htb]
    \centering
    \begin{subfigure}[b]{0.3\linewidth}
    \raggedleft
    \includegraphics[width=\linewidth]{figure/experiments/comparison/rho/rho_under2.pdf}
    \caption{$\rho <$ 2}
    \end{subfigure}
    \hspace{5pt}
    \begin{subfigure}[b]{0.3\linewidth}
    \raggedright
    \includegraphics[width=\linewidth]{figure/experiments/comparison/rho/rho_over2.pdf}
    \caption{$\rho \ge$ 2}
    \end{subfigure}
    \caption{Pairwise penalty matrix for imbalance ratio category. The maximum value of two matrices is 18 and 20, respectively.}
    \label{fig:comp_data_type}
\end{figure*}


\vspace{-15pt}
\begin{figure*}[!t]
    \centering
    \begin{subfigure}[b]{0.3\linewidth}
    \includegraphics[width=\linewidth]{figure/experiments/comparison/architecture/4cnn.pdf}
    \caption{Four Convolutional Neural Network}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.3\linewidth}
    \includegraphics[width=\linewidth]{figure/experiments/comparison/architecture/resnet.pdf}
    \caption{ResNet-18}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.3\linewidth}
    \includegraphics[width=\linewidth]{figure/experiments/comparison/architecture/mobilenet.pdf}
    \caption{MobileNet}
    \end{subfigure}
    \caption{Pairwise penalty matrix for a model architecture category. The maximum value of three matrices is 30, 4, and 4.}
    \label{fig:comp_model_arch}
\end{figure*}

\vspace{-15pt}
\begin{figure*}[!t]
    \centering
    \begin{subfigure}[b]{0.3\linewidth}
    \includegraphics[width=\linewidth]{figure/experiments/comparison/budget_size/budget_1.pdf}
    \caption{Budget 1\%}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.3\linewidth}
    \includegraphics[width=\linewidth]{figure/experiments/comparison/budget_size/budget_5.pdf}
    \caption{Budget 5\%}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.3\linewidth}
    \includegraphics[width=\linewidth]{figure/experiments/comparison/budget_size/budget_20.pdf}
    \caption{Budget 20\%}
    \end{subfigure}
    \caption{Pairwise penalty matrix for a budget size category. The maximum value of three matrices is 4, 30, and 4, respectively.}
    \label{fig:comp_budget_size}
\end{figure*}

% \vspace{-60pt}
\vspace{-15pt}
\begin{figure*}[!t]
    \centering
    \begin{subfigure}[b]{0.3\linewidth}
    \raggedleft
    \includegraphics[width=\linewidth]{figure/experiments/comparison/model_init/random.pdf}
    \caption{Random initialization}
    \end{subfigure}
    \hspace{10pt}
    \begin{subfigure}[b]{0.3\linewidth}
    \raggedright
    \includegraphics[width=\linewidth]{figure/experiments/comparison/model_init/continue.pdf}
    \caption{Continue initialization}
    \end{subfigure}
    \caption{Pairwise penalty matrix for a model initialization category. The maximum value of two matrices is 34 and 4.}
    \label{fig:comp_model_init}
\end{figure*}



\clearpage

\subsection{Detailed Performance Comparision}
\label{sec:detail_comp_performance}

For the line plots, we note that `Random' and `Ours' are independent of the query selector type.

\begin{figure*}[h!]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/cifar10_total.pdf}
    \caption{Test accuracy on CIFAR-10, four layers of CNN, $\alpha=0.1$,  medium budget size\,(5\%), and random initialization. }
    \label{fig:app_cifar10}
\end{figure*}

\vspace{-15pt}
\begin{figure*}[h!]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/svhn_total.pdf}
    \caption{Test accuracy on SVHN, four layers of CNN, $\alpha=0.1$,  medium budget size\,(5\%), and random initialization.}
    \label{fig:app_svhn}
\end{figure*}

\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/path_total.pdf}
    \caption{Test accuracy on PathMNIST, four layers of CNN, $\alpha=0.1$,  medium budget size\,(5\%), and random initialization.}
    \label{fig:app_pathmnist}
\end{figure*}

\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/derma_total.pdf}
    \caption{Test accuracy on DermaMNIST, four layers of CNN, $\alpha=0.1$,  medium budget size\,(5\%), and random initialization.}
    \label{fig:app_dermamnist}
\end{figure*}


\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/organ_total.pdf}
    \caption{Test accuracy on OrganAMNIST, four layers of CNN, $\alpha=0.1$,  medium budget size\,(5\%), and random initialization.}
    \label{fig:app_organmnist}
\end{figure*}


\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/cifar10_total_dir1.pdf}
    \caption{Test accuracy on CIFAR-10, four layers of CNN, \textbf{$\alpha=1.0$},  medium budget size\,(5\%), and random initialization.}
    \label{fig:app_cifar_dir1}
\end{figure*}

\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/svhn_total_dir1.pdf}
    \caption{Test accuracy on SVHN, four layers of CNN, \textbf{$\alpha=1.0$},  medium budget size\,(5\%), and random initialization.}
    \label{fig:app_svhn_dir1}
\end{figure*}

\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/cifar10_total_dir10.pdf}
    \caption{Test accuracy on CIFAR-10, four layers of CNN, \textbf{$\alpha=\infty$},  medium budget size\,(5\%), and random initialization.}
    \label{fig:app_cifar_dir10}
\end{figure*}



\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/svhn_total_dir10.pdf}
    \caption{Test accuracy on SVHN, four layers of CNN, \textbf{$\alpha=\infty$},  medium budget size\,(5\%), and random initialization.}
    \label{fig:app_svhn_dir10}
\end{figure*}



\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/cifar10_total_mobilenet.pdf}
    \caption{Test accuracy on CIFAR-10, MobileNet, $\alpha=0.1$,  medium budget size\,(5\%), and random initialization.}
    \label{fig:app_cifar10_mobile}
\end{figure*}



\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/svhn_total_mobilenet.pdf}
    \caption{Test accuracy on SVHN, MobileNet, $\alpha=0.1$,  medium budget size\,(5\%), and random initialization.}
    \label{fig:app_svhn_mobile}
\end{figure*}



\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/cifar10_resnet_total.pdf}
    \caption{Test accuracy on CIFAR-10, ResNet-18, $\alpha=0.1$,  medium budget size\,(5\%), and random initialization.}
    \label{fig:app_cifar10_resnet}
\end{figure*}



\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/svhn_resnet_total.pdf}
    \caption{Test accuracy on SVHN, ResNet-18, $\alpha=0.1$,  medium budget size\,(5\%), and random initialization.}
    \label{fig:app_svhn_resnet}
\end{figure*}


\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/cifar10_budget1_total.pdf}
    \caption{Test accuracy on CIFAR-10, four layers of CNN, $\alpha=0.1$,  small budget size\,(1\%), and random initialization.}
    \label{fig:app_cifar10_budget1}
\end{figure*}


\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/svhn_budget1_total.pdf}
    \caption{Test accuracy on SVHN, four layers of CNN, $\alpha=0.1$,  small budget size\,(1\%), and random initialization.}
    \label{fig:app_svhn_budget1}
\end{figure*}


\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/cifar10_total_budget20.pdf}
    \caption{Test accuracy on CIFAR-10, four layers of CNN, $\alpha=0.1$,  large budget size\,(20\%), and random initialization.}
    \label{fig:app_cifar10_budget20}
\end{figure*}


\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/svhn_total_budget20.pdf}
    \caption{Test accuracy on SVHN, four layers of CNN, $\alpha=0.1$,  large budget size\,(20\%), and random initialization.}
    \label{fig:app_svhn_budget20}
\end{figure*}

\newpage
\vspace{-15pt}
\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/cifar10_total_continue.pdf}
    \caption{Test accuracy on CIFAR-10, four layers of CNN, $\alpha=0.1$,  medium budget size\,(5\%), and continue initialization.}
    \label{fig:app_cifar10_cont}
\end{figure*}



\vspace{-15pt}
\begin{figure*}[t]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/experiments/appendix/svhn_total_continue.pdf}
    \caption{Test accuracy on SVHN, four layers of CNN, $\alpha=0.1$,  medium budget size\,(5\%), and continue initialization.}
    \label{fig:app_svhn_cont}
\end{figure*}

