\section{Convolutional Neural Network \label{sec:train}} 
%The neural network presented in this section was trained with the labelled data generated previously. Each training periodogram has an associated label 0 or 1 that represents whether the maximum peak corresponds to a planetary signal or not, so when it is used to predict over an unseen periodogram, the network will return a real number between 0 and 1 as well as with the FAP, a threshold has to be defined over this value to be able to use it to predict which of the two classes it belongs to. The training, parameter setting and thresholding process for this convolutional neural network is detailed below.

%Having generated each component of the input data, there is a wide variety of options on how to model the data using a neural network. For example, the produced time series could be used directly to infer the presence of periodic signals. We tried several options but finally settled for using the produced periodograms as input for a Convolutional Neural Network. The great advantage of the solution proposed here is that it allows for a direct comparison with the traditional method. In other words, the obtained algorithm could replace the computation of the FAP values, for a given periodogram.

%When facing this work, one of the most important things to decide was the type of questions to ask the network and, based on this, evaluate what type of it could be used. The problem is quite broad and, having generated each component of the input data, there is a wide variety of options at the moment of modeling. 

%\subsection{Convolutional Neural Network} 
The neural network (nicknamed \texttt{ExoplANNET}) was implemented using the Keras package for \texttt{python}, with Tensorflow as backend. It receives one GLS periodogram, represented in a one-dimensional array of data, together with two additional characteristics: the power and position of the largest peak in the 1D array. The input GLS periodogram was sampled in a grid of 990 frequencies. The frequency grid was fixed and was the same for all simulated velocity datasets. The output is a single value representing the probability that the data was originally created from a periodic signal (in addition to the activity signals). 

A natural solution in this setting is to use convolutional networks in one dimension.\footnote{In section \ref{apendix} there is a brief explanation of this type of network and its use in data that have a spatial relationship, such as images or periodograms.} The architecture is quite standard. The hidden layers will be composed of convolutional layers, interleaved with max pooling layers. Finally, a series of dense layers are implemented, interspersed in turn with dropout layers. All layers use ReLU activation functions except the output neuron which uses a sigmoid activation function for classification that returns a real value between 0 and 1.

The network is trained using the cross-entropy loss function,
$$
E = \sum_{i=1}^N \left[t_i \log(p_i) + (1 - t_i) \log(1 - p_i)\right]\;\;,
$$
where the sum is over all the instances (of a batch) of the dataset, $p_i$ is the predicted probability of belonging to the positive class, and $t_i$ is the target variable (1 if the data contains a periodic signal; 0 otherwise). In each training epoch the dataset is divided in batches of 128 periodograms, and the weights (parameters) of the model are adjusted using the Adam optimizer, with gradients computed based on the partial loss function. This is standard procedure in machine learning literature and has been shown to increase the performance and convergence of the optimization process \citep[see, for example,][]{bishop2007}.

%To check the performance of the network during training and validation, several metrics can be used, the most common is \textit{accuracy}, which is simply the percentage of correctly classified cases. However, as the set continues to present some imbalance it is not at all advisable to use it \footnote{Continuing with the example of cats and dogs, the \textit{accuracy} of this model that only predicts the dominant class will be 98 \% when, clearly, it is not a good solution.}.

The evolution of the training was monitored using the \textit{F-measure} (or F-score), which is the harmonic mean of precision ($P$) and recall ($R$), $F_1 = 2 (P R)/(P + R)$. In turn, precision and recall are defined:

\begin{itemize}
	\item{\textit{Precision}}: is the ratio of \textit{true} positive cases among those that were \textit{marked} as positive. In our case it would be:
	$$ P = \frac{\text{\{Real planets\}}\cap \text{\{Marked as planet\}}} {\text{\{Marked as planet\}}}$$

	\item{\textit{Recall}:} It is the ratio of \textit{true} positive cases detected among the positive \textit{existing}. 
	$$ R = \frac{\text{\{Real planets\}} \cap \text{\{Marked as planet\}}} {\text {\{Real planets\}}}$$
\end{itemize}
Unlike the \textit{accuracy}, the F-score is appropriate even in unbalanced cases.

% which, when evaluating performance, summarize concepts such as precision and completeness (defined in detail in \ref{lbl:performance}) that are more appropriate for the problem to be solved. For more detail, on this topic, you can see \cite{Brownlee:2020}.

Different network configurations were tested and evaluated with the validation set. The final architecture achieved an F-score of 0.88 in the validation set. A diagram of retained architecture is shown in figure \ref{fig:network}. The trained network is provided in h5 format in a GitHub repository\footnote{https://github.com/nicklessagus/ExoplANNET}, together with a sample of labelled periodograms for testing.

\begin{figure}
	\centering
	\includegraphics[width=0.55\linewidth]{network}
	\caption{Architecture of the ExoplANNET neural network. Blue cells represent convolutional layers; pale orange cells are MaxPooling lates, and dark red cells are fully connected layers. In addition, we show the single DropOut layer in yellow and the output layer in green.}
	\label{fig:network}
\end{figure}

