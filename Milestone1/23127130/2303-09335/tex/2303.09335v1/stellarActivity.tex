\section{Planet detection with GLS periodograms}
The radial velocity method consists of detecting variations in the line-of-sight projection of the star's velocity, induced by the presence of an unseen companion. 

\subsection{Periodograms}
\label{sec:periodograms}

Periodograms are often employed to find periodic signals in unevenly sampled time series as those typically obtained in RV surveys. The Lomb-Scargle periodogram \citep{periodogram, review_signal} has been used extensively to detect periodic signals in RV datasets. In its simplest form, it works in a Fourier-like fashion: the user defines a series of candidate frequencies $\{\omega_i\}$, with $i=1,...,N_f$, and the method fits the radial velocity data, $v(t)$, using a sine-cosine base at the candidate frequency. The better the model at this frequency fits the data (compared to a constant model without variability), the higher the power attributed to the candidate frequency \citep[for details, see][]{lomb1976, scargle1982, baluev-fap}. Indeed, the power at frequency $\omega_i$ is 

\begin{equation}
P(w_i) = \frac{\chi^2_0 - \chi^2_i}{\chi^2_0}\;\;,
\label{eq.power}
\end{equation}
where $\chi^2_i$ is the chi-square statistics for the model at frequency $w_i$. If we call $f_i(t)$ the model prediction at time $t$, 

$$
\chi^2_i = \sum_{j=1}^N \frac{\left(v(t_j) - f_i(t_j)\right)^2}{\sigma_j^2}\;\;,$$
where the sum runs over the $N$ data points in the time series.

A vector is generated with the power of each candidate frequency. The location of the highest power indicates the frequency of a potential periodicity present in the data. Figure \ref{fig:rv_pg} shows a time series (with a clear periodic signal) and the resulting periodogram. Note that the width of the peaks expressed in frequency depends solely on the time span of the observations $\Delta T$, and can be expressed 
$$
\Delta_\omega = 1/\Delta t\;\;.
$$

\begin{figure*}
     \centering
     \begin{subfigure}[b]{0.48\textwidth}
         \centering
 		    \includegraphics[width=1\linewidth]{../img/vel_rad_period_0}\hfill%
         \caption{Radial velocity measurements.}
         \label{fig:__}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.48\textwidth}
         \centering
			\includegraphics[width=1\linewidth]{../img/vel_rad_period_2}
         \caption{Periodogram. The red line marks the peak that represents the period with the highest power}
         \label{fig:__}
     \end{subfigure}
     \hfill
        \caption{Radial velocity measurements and their periodogram.}
        \label{fig:rv_pg}
\end{figure*}


\subsection{False alarm probability (FAP)}

Once the periodogram has been constructed, and a candidate period is identified, a tool is needed to help decide whether the observed peak is statistically significant to be considered a periodic signal. This question is traditionally framed as a null-hypothesis significance test, in which the null hypothesis ($H_0$, "there is no planet") is tested. More precisely, in the analysis of the Lomb-Scargle periodograms, the null hypothesis is often that the observations come from uncorrelated Gaussian noise (i.e., ``there is no planet''). The power of the largest peak is used as the test statistics, for which a $p$-value is computed\footnote{In the exoplanet literature, this is often referred to as False Alarm Probability (FAP). Although we deem this terminology misleading we will use $p$-value and FAP interchangeably.}. If the $p$-value is small enough, then the null hypothesis is rejected. The critical value below which a $p$-value is considered as evidence for rejecting the null hypothesis is usually between $10^{-3}$ and 0.1. In many planet search programmes, a FAP value of 0.01 is often used as a threshold below which detected peaks are considered significant \citep[e.g.][]{howard2010, bonfils2013}.  In this work, the critical value --which we call $ FAP_* $-- will be taken as 0.05 with $\log_{10} (FAP_*) $ rounded to -1.3.

To compute the $p$-value (FAP) one can take an analytical or numerical approach, using a Monte Carlo algorithm. The analytical expressions \citep[e.g.][]{scargle1982, baluev-fap, VanderPlas_2018} have the advantage of being much faster to compute than Monte Carlo approaches. However, these expressions rely on assumptions and approximations that are only reliable in certain regimes. For example, they often rely on the assumption that the errors are uncorrelated and normally distributed. Following the comments in \citet{baluev-fap} we considered that, if the $p$-value is greater than or equal to $log_{10}$ (0.01), the analytical expression is no longer reliable and the other method should be preferred. On the other hand, the Monte Carlo approach samples the data points keeping the observing times and is therefore probably more reliable even for situations where the assumptions on which analytical expressions are based do not hold. In this work, a number of noise realizations are sampled to compute the $p$-value of the largest peak power with this approach. As we work with simulations, the correct noise distribution is used. This is the most favourable situation which is rarely, if ever, given with real datasets. The Monte Carlo approach requires recomputing hundreds or thousands of periodograms, which makes it a much slower method than the analytical approach, especially when taking into account that we want to analyse a large amount of time series.%  The pseudocode for the Monte Carlo computation is given in Algorithm~\ref{alg:fap_monte_carlo}.

%\begin{algorithm}
%	\caption{Monte Carlo FAP}\label{alg:fap_monte_carlo}
%	\begin{algorithmic}[1]
%		\Procedure{MC\_FAP}{$rad\_vel\_params$, $pow\_max\_peak$} 
%		\State $N \gets 150$
%		\State$p\_max=[]$ 
%		\Loop {  $N$ times} 		
%		\State $rv\_noise \gets$ gen\_rad\_vel($rad\_vel\_params$) 
%		\State $pg \gets $ gen\_periodogram($rv\_noise$)
%		\If{max$(pg) > pow\_max\_peak$} 
%		\State $p\_max.$append(1)
%		\EndIf
%		\EndLoop
%		\State$ sum\_pg \gets$ add($p\_max$)
%		\State \textbf{return} $log\_10$($sum\_pg/N$)
%		\EndProcedure
%	\end{algorithmic}
%\end{algorithm}

As in any null-hypothesis significance test, we are exposed to type I and II errors \citep[e.g.][]{frodesen}. Type I, or ``false alarm errors'', occur when $ H_0 $ is incorrectly rejected (that is, we decided a peak is significant when it is not). Type II errors are when we fail to reject $ H_0 $ when in fact a planet is present. These errors are also often referred to as false positives and false negatives. 

When using this approach, one still needs to decide whether the detected signal is of planetary origin or caused by activity or systematic effects. Often, time series of activity indexes are employed to verify that the candidate frequency is not present in these series, which is regarded as evidence for the planetary interpretation of the signal. However, there is not a universally accepted way to decide whether a signal is produced by a planet.

