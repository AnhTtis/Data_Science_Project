\section{Introduction}
Federated Learning (FL) \cite{Li2020federated} allows distributed clients to collaboratively train a shared model without sharing data. 
However, FL faces severe dilemma of privacy leakage \cite{Kairouz2021Advances}.
Recent works show that a curious server can also infer clientsâ€™ privacy information such as membership and data features, by well-designed generative models and/or shadow models~\cite{Fredrikson2015model,Shokri2017membership,Melis2018inference,Nasr2019comprehensive,zhang2022fine}. To address this issue, differential privacy (DP) \cite{Dwork2014the} has been introduced in FL, which can protect every instance in any client's data (instance-level DP~\cite{Agarwal2018cpsgd,Hu2021federated, Sun2021federated,Sun2021practical}) or the information between clients (client-level DP~\cite{McMahan2018learning,Robin2017differentially,KairouzL2021the,wei2021user, Rui2022Federated,Anda2022differentially}). In general, client-level DP are more suitable to apply in the real-world setting due to a better model performance. For instance, a language prediction model with client-level DP \cite{geyer2017differentially, McMahan2018learning} has been applied on mobile devices by Google.
In general, the Gaussian noise perturbation-based method is commonly adopted for ensuring the strong client-level DP.
However, this method includes two operations in terms of clipping the $l_2$ norm of local updates to a sensitivity threshold $C$ and adding random noise proportional to the model size, whose standard deviation (STD) is also decided by $C$. These steps may cause severe performance degradation dilemma \cite{cheng2022differentially, hu2022federated}, especially on large-scale complex model \cite{simonyan2014very}, such as ResNet-18 \cite{he2016deep}, or with heterogeneous data.  

\begin{figure*}
\centering
\begin{minipage}[b]{0.55 \linewidth}
    \centering
    \includegraphics[width=1.0\linewidth]{figures/landscape1.pdf}
    \centerline{(a) Loss landscapes.}\medskip
% \vspace{-0.2cm}
\end{minipage}
\hfill
\begin{minipage}[b]{0.42\linewidth}
    \centering
    \includegraphics[width=1.0\linewidth]{figures/contour_c.pdf}
    \centerline{(b) Loss surface contours.}\medskip
    \label{contour_fedavg_dpfedavg}
% \vspace{-0.2cm}
\end{minipage}
\vspace{-0.35cm}
\caption{\small Loss landscapes and surface contours comparison between DP-FedAvg (left) and FedAvg (right), respectively.
}
\vspace{-0.4cm}
\label{landscape_fedavg_dpfedavg}
\end{figure*}

The reasons behind this issue may be two-fold: (i) The useful information is dropped due to the clipping operation especially on small $C$, which is contained in the local updates; (ii) The model inconsistency among local models is exacerbated as the addition of random noise severely damages local updates and leads to large variances between local models especially on large $C$ \cite{cheng2022differentially}. To overcome these issues, existing works improve the performance via restricting the norm of local update \cite{cheng2022differentially} and leveraging local update sparsification technique \cite{cheng2022differentially, hu2022federated} to reduce the adverse impacts of clipping and adding amount of random noise. However, the model performance degradation remains significantly severe compared with FL methods without considering the privacy, e.g., FedAvg \cite{mcmahan2017communication}. 

\noindent
\textbf{Motivation.} To further explore the reasons behind this phenomenon, we compare the structure of loss landscapes and surface contours \cite{li2018visualizing} for FedAvg \cite{mcmahan2017communication} and DP-FedAvg \cite{McMahan2018learning,Robin2017differentially} on partitioned CIFAR-10 dataset \cite{krizhevsky2009learning} with Dirichlet distribution ($\alpha =0.6$) and ResNet-18 backbone \cite{he2016deep} in Figure \ref{landscape_fedavg_dpfedavg} (a) and (b), respectively. Note that the convergence of DP-FedAvg is worse than FedAvg as its loss value is higher after a long communication round. Furthermore, FedAvg has a flatter landscape, whereas DP-FedAvg has a sharper one, resulting in poorer generalization ability (sharper minima, see Figure \ref{landscape_fedavg_dpfedavg} (a)) and weight perturbation robustness (see Figure \ref{landscape_fedavg_dpfedavg} (b)), which is caused by the clipped local update information and exacerbated model inconsistency, respectively. Based on these observations, an interesting research question is: \emph{can we further overcome the severe performance degradation via making landscape flatter? }


To answer this question, we propose DP-FedSAM via gradient perturbation to improve model performance. Specifically, a local flat model is generated by using SAM optimizer \cite{foret2021sharpnessaware} in each client, which leads to better stability. After that, a potentially global flat model can be generated by aggregating several flat local models, which results in higher generalization ability and better robustness to DP noise, thereby significantly improving the performance and achieving a better trade-off between performance and privacy. 
%We are the first to study the empirical performance and theoretical analysis of SAM in DPFL. 
Theoretically, we present a tighter bound  
% \begin{equation*}
% \small
%     \begin{split}
%     \small
%         & \frac{\sum\limits_{t=1}^T
%     \mathbb{E}\left[\overline{\alpha}^{t}\left\|\nabla f\left(\mathbf{w}^{t}\right)\right\|^{2}\right]}{T}   \!\leq\!  
%     \underbrace{\mathcal{O}\!\!\left(\!\!\frac{2L(f({\bf w}^{1})\!-\!f^{*})}{\sqrt{KT}} +  \frac{\sum\limits_{t=1}^T\overline{\alpha}^t L^2\rho^2 \sigma_{l}^2}{KT^2}\!\!\right)}_{\text{From FedSAM}}  \\ 
%     &\qquad\quad +
%     \underbrace{
%      \underbrace{\mathcal{O}\left(\sum_{t=1}^T( \frac{\overline{\alpha}^t  \sigma_{g}^2 }{T^2} + \frac{\tilde{\alpha}^t  L^2\rho^2 }{T} ) \right)}_{\text{Clipping}}
%     + \underbrace{ \mathcal{O}\left(\frac{L^2 \sqrt{T}\sigma^2C^2d}{m^2\sqrt{K}} \right)}_{\text{Adding noise}}
%     }_{\text{From operations for DP}}, 
%     \end{split}
% \end{equation*}
$\small \mathcal{O}(\frac{1}{\sqrt{KT}}+\frac{\sum_{t=1}^T(\overline{\alpha}^t\sigma_g^2 + \tilde{\alpha}^t  L^2)}{T^2} + \frac{L^2 \sqrt{T}\sigma^2C^2d}{m^2\sqrt{K}} )$ for DP-FedSAM in the stochastic non-convex setting, where both $\frac{1}{T}\sum_{t=1}^T\overline{\alpha}^t$ and $\frac{1}{T}\sum_{t=1}^T\tilde{\alpha}^t$ are bounded constant, $K$ and $T$ is local iteration steps and communication rounds, respectively. Meanwhile, we present how SAM mitigates the impact of DP. For the clipping operation, DP-FedSAM reduces the $l_2$ norm and the negative impact of the inconsistency among local updates on convergence. For adding noise operation, we obtain better weight perturbation robustness for reducing the performance damage caused by random noise, thereby having better robustness to DP noise. 
Empirically, we conduct extensive experiments on EMNIST, CIFAR-10,
and CIFAR-100 datasets in both the independently and identically distributed (IID) and Non-IID settings. Furthermore, we observe the loss landscape, surface contour, and the norm distribution of local updates for exploring the intrinsic effects of SAM with DP, which together with the theoretical analysis confirms the effect of DP-FedSAM.

\noindent
\textbf{Contribution.} The main contributions of our work are summarized as four-fold: \textbf{(i)} We propose a novel scheme DP-FedSAM in DPFL to alleviate performance degradation issue from the optimizer perspective.
\textbf{(ii)} We establish an improved convergence rate, which is tighter than the conventional bounds \cite{cheng2022differentially,hu2022federated} in the stochastic non-convex setting. Moreover, we provide rigorous privacy guarantees and sensitivity analysis.
\textbf{(iii)} We are the first to in-depth analyze the roles of the on-average norm of local updates $\overline{\alpha}^{t}$ and local update consistency among clients $\tilde{\alpha}^t$ on convergence.
\textbf{(iv)}
We conduct extensive experiments to verify the effect of DP-FedSAM, which could achieve state-of-the-art (SOTA) performance compared with several strong DPFL baselines.




% \begin{figure*}[t]
% \centering
% \begin{subfigure}{0.55\linewidth}
% (2023ICLR)Improving Model Consistency of Decentralized Federated Learning via Sharpness Aware Minimization and Multiple Gossip Approaches\includegraphics[width=1\textwidth]{figures/landscape.pdf}
% \caption{Loss landscape.}
%     \label{fig:land_compar}
% \end{subfigure}
% % \quad
% \begin{subfigure}{0.42\linewidth}
% \includegraphics[width=1\textwidth]{figures/contour_c.pdf}

% \caption{Loss surface contour.}
%     \label{fig:land_compar}
% \end{subfigure}
% \vspace{-0.35cm}
% \caption{\small Loss landscapes and surface contours comparison between DP-FedAvg (left) and FedAvg (right) in Figure (a) and (b) with the same setting, respectively. FedAvg has a more flat landscape, whereas DP-FedAvg has a sharper landscape than FedAvg with both poorer generalization ability (sharper minima, see Figure (a)) and weight perturbation robustness (see Figure (b)).
% }
\vspace{-0.15cm}
% \label{landscape_fedavg_dpfedavg}
% \end{figure*}
