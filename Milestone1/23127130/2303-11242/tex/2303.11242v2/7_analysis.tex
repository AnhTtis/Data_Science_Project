\section{Theoretical Analysis}\label{th}

In this section, we give a rigorous analysis of DP-FedSAM, including its sensitivity, privacy, and convergence rate. The detailed proof is placed in \textbf{Appendix} \ref{appendix_th}. Below, we first give several necessary assumptions.

\begin{assumption} \label{a1}
(Lipschitz smoothness). The function $F_i$ is differentiable and $\nabla F_i$ is $L$-Lipschitz continuous, $\forall i \in \{1,2,\ldots,M\}$, i.e.,
$\|\nabla F_i({\bf x}) - \nabla F_i({\bf y})\| \leq L \|{\bf x} - {\bf y}\|,$
for all ${\bf x}, {\bf y} \in \mathbb{R}^d$.
% The first-order Lipschitz assumption is commonly used in the ML community. Here, for simplicity, we suppose all functions enjoy the same Lipschitz constant $L$.
\end{assumption}

\begin{assumption} \label{a2}
(Bounded variance). The gradient of the function $f_i$ have $\sigma_l$-bounded variance, i.e.,
$\mathbb{E}_{\xi_i}\left\|\nabla F_i (\mathbf{w}^k(i);\xi_i ) -\nabla F_i (\mathbf{w}(i))\right  \|^2 \leq \sigma_l^2$, $\forall i \in \{1,2,\ldots,M\}, k \in \{1, ..., K-1\},$
the global variance is also bounded, i.e., $\frac{1}{M} \sum_{i=1}^M \|\nabla f_i({\bf w}) - \nabla f({\bf w})\|^2 \leq \sigma_{g}^2$ for all ${\bf w} \in \mathbb{R}^d$. It is not hard to verify that the $\sigma_g$ is smaller than the homogeneity parameter $\beta$, i.e., $\sigma_g^2 \leq \beta^2$.
\end{assumption}

\begin{assumption}\label{a3}
(Bounded gradient). For any $i \!\in\! \{1,2,\ldots,M\}$ and ${\bf w}\!\in\! \mathbb{R}^d$, we have $\|\nabla f_i({\bf w})\|\!\leq\! B $.
\end{assumption}

\begin{assumption}\label{a4}
(Unbiased Gradient Estimator). For any data sample $z$ from $\mathcal{D}_i$ and ${\bf w}\!\in\! \mathbb{R}^d$, the local gradient estimator is unbiased, i.e., $\mathbb{E}[\nabla f_i(\mathbf{w}; z)]= \mathbb{E}[\nabla f_i(\mathbf{w})]$.
\end{assumption}

Note that the above assumptions are mild and commonly used in characterizing the convergence rate of FL \cite{Sun2022Decentralized,shi2023improving,ghadimi2013stochastic,yang2021achieving,bottou2018optimization,reddi2020adaptive, huang2022achieving, Qu2022Generalized, cheng2022differentially,hu2022federated}. 
Furthermore, gradient clipping operation in DL is often used to prevent the gradient explosion phenomenon, thereby the gradient is bounded. 
The technical difficulty for DP-FedSAM lies in: (i) how SAM mitigates the impact of DP; (ii) how to analyze in detail the impacts of the consistency among clients and the on-average norm of local updates caused by clipping operation.  

%Below, we first state the theoretical result of the sensitivity analysis of the local update for each client.

\subsection{Sensitivity Analysis}
At first, we study the sensitivity of local update  $\Delta^t_i$ from any client $i \in \{1,2,..., M\}$ before clipping at $t$-th communication round in DP-FedSAM. This upper bound of sensitivity can roughly measure the degree of privacy protection.
% The operations for DP are mainly clipping of local updates and adding noise \cite{cheng2022differentially}, thus we start by studying the norm of local update $\|\Delta^t_i\|_2$ from any client $i \in \{1,2,...,M\}$ before clipping at $t$-th communication round.
% \begin{theorem}
% \rm ($l_2$ Norm). Under assumptions, $\|\Delta^t_i\|_2$ in our algorithm can be computed as follows:
% \begin{align}
%     \mathbb{E}\|\Delta^t_i\|^2_2  \leq 3\eta^2K(L^2\rho^2+\sigma_g^2+B^2),
% \end{align}
% \end{theorem} 
% Meanwhile, we present the norm of local update with SGD optimizer in DPFL, that is $\mathbb{E}\|\Delta^t_{i, SGD}\|^2_2  \leq3\eta^2K(B^2\sigma_l^2+\sigma_g^2+B^2)$. 
% The detailed proof is presented in Appendix \ref{appendix_th}. 
% \begin{remark}
% we can find the norm in our scheme is smaller than that in baselines. When the perturbation amplitude $\rho$
% proportional to the learning rate, e.g., $\rho = \mathcal{O}(\frac{1}{\sqrt{T}})$, $L^2\rho^2=\frac{L^2}{T}< B^2\sigma_l^2$. Therefore, the norm of local update in DP-FedSAM is smaller than that in baselines, which means that the impact of clipping is alleviated.
% \end{remark}
Under Definition \ref{sensitivity}, the sensitivity can be denoted by $\mathcal{S}_{\Delta_i^t}$ in client $i$ at $t$-th communication round. 
\begin{theorem} (Sensitivity).\label{th:sensitivity}
Denote $\Delta_i^t(\bf x)$ and $\Delta_i^t(\bf y)$ as the local update at $t$-th communication round, the model $\mathbf{x}(i)$ and $\mathbf{y}(i)$ is conducted on two sets which differ at only one sample. Assume the initial model parameter $\mathbf{w}^t(i)=\mathbf{x}^{t, 0}(i) =\mathbf{y}^{t, 0}(i)$. With the above assumptions, the expected squared  
sensitivity $\mathcal{S}^2_{\Delta_i^t}$ of local update is upper bounded,
\begin{align}
\small
    \mathbb{E}\mathcal{S}^2_{\Delta_i^t} \leq
     \frac{6\eta^2\rho^2KL^2(12K^2L^2\eta^2+ 10)}{1-2\eta^2L^2 K}
\end{align}
When the local adaptive learning rate satisfies $\eta=\mathcal{O}({1}/{L\sqrt{KT}})$ and the perturbation amplitude $\rho$
proportional to the learning rate, e.g., $\rho = \mathcal{O}(\frac{1}{\sqrt{T}})$, we have
\begin{align}
\small
    \mathbb{E}\mathcal{S}^2_{\Delta_i^t} \leq
    \mathcal{O}\left(\frac{1}{T^2}\right). 
\end{align}
For comparison, we also present the expected squared sensitivity of local update with SGD in DPFL, that is $ \mathbb{E}\mathcal{S}^2_{\Delta_i^t, SGD} \leq \frac{6\eta^2\sigma_l^2K}{1-3\eta^2KL^2}$.
% \begin{equation} 
% \small
%     \mathbb{E}\mathcal{S}^2_{\Delta_i^t, SGD} \leq \frac{6\eta^2\sigma_l^2K}{1-3\eta^2KL^2}.
% \end{equation}
Thus $\mathbb{E}\mathcal{S}^2_{\Delta_i^t, SGD} \leq \mathcal{O}(\frac{\sigma_l^2}{KL^2T})$ when $\eta=\mathcal{O}({1}/{L\sqrt{KT}})$.
\begin{remark}
It is clearly seen that the upper bound in $  \mathbb{E}\mathcal{S}^2_{\Delta_i^t, SAM}$ is tighter than that in $\mathbb{E}\mathcal{S}^2_{\Delta_i^t, SGD}$. From the perspective of privacy protection, it means DP-FedSAM has a better privacy guarantee than DP-FedAvg.
% \ls{Not SAM. It is DP-SAM better than DP-SGD. Should we mention that the DP-SAM is of independent interest.}.
Another perspective from local iteration, which means both better model consistency among clients and training stability.
\end{remark}
\end{theorem}

%----------------------------------------------------

\subsection{Privacy Analysis}
To achieve client-level privacy protection, we derive the sensitivity of the aggregation process at first after clipping the local updates.
% moments accountants are used to verify that it satisfies client-level DP. 
\begin{lemma}
The sensitivity of client-level DP in DP-FedSAM can be expressed as $C/m$.
\end{lemma}
\begin{proof}
Given two adjacent batches $\mathcal{W}^{t}$ and $\mathcal{W}^{t,\rm{adj}}$, that $\mathcal{W}^{t,\rm{adj}}$ has one more or less client, we have
\begin{equation} \small
\small
\left\Vert \frac{1}{m}\sum_{i\in \mathcal{W}^{t}}\Delta^{t}_{i}-\frac{1}{m}\sum_{j\in \mathcal{W}^{t,\rm{adj}}} \Delta^{t}_{j} \right\Vert_{2} = \frac{1}{m}\left\Vert \Delta^{t}_{j'} \right\Vert_{2}\leq \frac{C}{m},
\end{equation}
where $\Delta^{t}_{j'}$ is the local update of one more or less client.
\end{proof}
\begin{remark}
The value of this sensitivity can determine the amount of variance for adding random noise.
\end{remark}
After adding Gaussian noise, we calculate the accumulative privacy budget~\cite{Yousefpour2021Opacus} along with training as follows. 
\begin{theorem} \label{th:privacy}
After $T$ communication rounds, the accumulative privacy budget is calculated by:
\begin{equation} \small\label{eq:accumulative_eps}
\begin{aligned}
\epsilon = \overline{\epsilon} + \frac{(\alpha-1)\log(1-\frac{1}{\alpha})-\log(\alpha)-\log(\delta)}{\alpha-1},
\end{aligned}
\end{equation}
where
\begin{equation} \small
\begin{aligned}
\overline{\epsilon} &= \frac{T}{\alpha-1}\ln {\mathbb{E}_{z\sim \mu_{0}(z)}\left[\left(1-q+\frac{q \mu_{1}(z)}{\mu_{0}(z)}\right)^{\alpha}\right]},
\end{aligned}
\end{equation}
and $q$ is sample rate for client selection, $\mu_{0}(z)$ and $\mu_{1}(z)$ denote the Gaussian probability density function (PDF) of $\mathcal{N}(0,\sigma)$ and the mixture of two Gaussian distributions $q\mathcal{N}(1,\sigma)+(1-q)\mathcal{N}(0,\sigma)$, respectively, $\sigma$ is the noise STD, $\alpha$ is a selectable variable.
\end{theorem}
\begin{remark}
It can be seen that a small sampling rate $q$ can enhance the privacy guarantee by decreasing the privacy budget, but it may also degrade the training performance due to the number of participating clients being reduced in each communication round. So a better trade-off is needed.
\end{remark}
% \ls{it seems that the results in this subsection are unrelated to the DP-FedSAM.}
% \ls{some results are merely intermediate results. It is better to use "Lemma" or "Proposition"}

%----------------------------------------------------
\subsection{Convergence Analysis}
Below, we give a convergence analysis of how DP-FedSAM mitigates the negative impacts of DP. The technical contribution also is combining the impacts of the on-average norm of local updates $\overline{\alpha}^{t}$ and local update consistency among clients $\tilde{\alpha}^t$ on the rate. Moreover, we also empirically confirm these results in Section \ref{exper_DP}.

\begin{theorem}\label{th:conver}
Under assumptions 1-4, local learning rate satisfies $\eta=\mathcal{O}({1}/{L\sqrt{KT}})$ and $f^{*}$ is denoted as the minimal value of $f$, i.e., $f(x)\ge f(x^*)=f^*$ for all $x\in \mathbb{R}^{d}$. 
When the perturbation amplitude $\rho$ is
proportional to the learning rate, e.g., $\rho = \mathcal{O}(1/\sqrt{T})$,
the sequence of outputs $\{\mathbf{w}^t\}$ generated by Alg. \ref{DFedAvg_DP}, we have:
\begin{equation*}
\small
\begin{split}
\small
    & \frac{1}{T} \sum_{t=1}^T
    \mathbb{E}\left[\overline{\alpha}^{t}\left\|\nabla f\left(\mathbf{w}^{t}\right)\right\|^{2}\right]   \leq  
    \underbrace{\mathcal{O}\left(\frac{2L(f({\bf w}^{1})-f^{*})}{\sqrt{KT}} + \frac{ L^2\sigma_{l}^2}{KT^2}\right)}_{\text{From FedSAM}} \\ 
    &\qquad\quad +
    \underbrace{
     \underbrace{\mathcal{O}\left( \frac{\sum_{t=1}^T(\overline{\alpha}^t  \sigma_{g}^2 + \tilde{\alpha}^t  L^2  )}{T^2}  \right)}_{\text{Clipping}}
    + \underbrace{ \mathcal{O}\left(\frac{L^2 \sqrt{T}\sigma^2C^2d}{m^2\sqrt{K}} \right)}_{\text{Adding noise}}
    }_{\text{From operations for DP}} 
    \end{split}
\end{equation*}
where
\begin{equation} \small
\begin{split}
    \overline{\alpha}^{t} :=\frac{1}{M} \sum_{i=1}^{M} \alpha^t_i~~~ \text{and}  ~~~ \tilde{\alpha}^t :=\frac{1}{M}\sum_{i=1}^{M} |\alpha_i^t - \overline{\alpha_i^t}|, 
\end{split}
\end{equation}
with $\alpha^t_i = \min (1, \frac{C}{ \eta  \|  \sum_{k=0}^{K-1}  \tilde{\mathbf{g}}^{t,k}(i) \|} ) $, respectively. Note that $\overline{\alpha}^{t}$ and $\tilde{\alpha}^t$ measure the on-average norm of local updates and local update consistency among clients before clipping and adding noise operations in DP-FedSAM, respectively.
\end{theorem}
\begin{table*}
\caption{Averaged training accuracy (\%) and testing accuracy (\%) on two data in both IID and Non-IID settings for all compared methods.}
\vspace{-0.2cm}
\centering
% \small
\scriptsize
\renewcommand{\arraystretch}{0.5}
\label{table:all_baselines}
\resizebox{0.9\linewidth}{!}{
\begin{tabular}{cccccccc} 
\toprule
\multirow{2}{*}{\textbf{Task}} & \multirow{2}{*}{\textbf{Algorithm}} & \multicolumn{2}{c}{Dirichlet~0.3} & \multicolumn{2}{c}{Dirichlet~0.6} & \multicolumn{2}{c}{IID}  \\ 
\cmidrule{3-8}
                      &                            & Train         & Validation          & Train         & Validation          & Train      & Validation           \\ 
\midrule 
       & DP-FedAvg       & 99.28$\pm$0.02 & 73.10$\pm$0.16          & 99.55$\pm$0.02 & 82.20$\pm$0.35          & 99.66$\pm$0.40 & 81.90$\pm$0.86           \\
       & Fed-SMP-$\randk_k$ & 99.24$\pm$0.02 & 73.72$\pm$0.53          & 99.71$\pm$0.01 & 82.18$\pm$0.73          & 99.71$\pm$0.61 & 84.16$\pm$0.83           \\
       & Fed-SMP-$\topk_k $    & 99.31$\pm$0.04 & 75.75$\pm$0.35          & 99.72$\pm$0.02 & 83.41$\pm$0.91          & 99.73$\pm$0.40 & 83.32$\pm$0.52           \\
EMNIST & DP-FedAvg-$\blur$      & 99.12$\pm$0.02 & 73.71$\pm$0.02          & 99.66$\pm$0.00 & 83.20$\pm$0.01          & 99.67$\pm$0.03 & 82.92$\pm$0.49           \\
       & DP-FedAvg-$\blurs$     & 99.63$\pm$0.08 & 76.25$\pm$0.35          & 99.72$\pm$0.02 & 83.41$\pm$0.91          & 99.74$\pm$0.45 & 82.92$\pm$0.49           \\
       & DP-FedSAM       & 96.28$\pm$0.64 & 76.81$\pm$0.81          & 95.07$\pm$0.45 & 84.32$\pm$0.19 & 95.61$\pm$0.94 & 85.90$\pm$0.72           \\
       & DP-FedSAM-$\topk_k $  & 94.77$\pm$0.11 & \textbf{77.27$\pm$0.67} & 95.87$\pm$1.52 & \textbf{84.80$\pm$0.60 }         & 96.12$\pm$0.85 & \textbf{87.70$\pm$0.83}  \\
\midrule
                      & DP-FedAvg                  & 93.65$\pm$0.47    & 47.98$\pm$0.24          & 93.65$\pm$0.42    & 50.05$\pm$0.47          & 93.65$\pm$0.15 & 50.90$\pm$0.86           \\
                      & Fed-SMP-$\randk_k$              & 95.46$\pm$0.43    & 48.14$\pm$0.12          & 95.36$\pm$0.06    & 51.33$\pm$0.36          & 95.36$\pm$0.06 & 50.61$\pm$0.20           \\
                      & Fed-SMP-$\topk_k $           & 95.49$\pm$0.14    & 49.93$\pm$2.29          & 95.49$\pm$0.09    & 54.11$\pm$0.83          & 95.49$\pm$0.10 & 53.30$\pm$0.45           \\
CIFAR-10              & DP-FedAvg-$\blur$              & 95.47$\pm$0.12    & 47.66$\pm$0.01          & 99.66$\pm$0.42    & 51.05$\pm$0.01          & 94.50$\pm$0.05 & 52.56$\pm$0.47           \\
                      & DP-FedAvg-$\blurs$          & 96.79$\pm$0.51    & 51.23$\pm$0.66          & 99.72$\pm$0.09    & 54.11$\pm$0.83          & 96.45$\pm$0.30 & 53.48$\pm$0.76           \\
                      & DP-FedSAM                  & 90.38$\pm$0.90    & 53.92$\pm$0.55          & 90.83$\pm$0.15    & 54.14$\pm$0.60          & 90.83$\pm$0.16 & 55.58$\pm$0.50           \\
                      & DP-FedSAM-$\topk_k $            & 93.25$\pm$0.60    & \textbf{54.85$\pm$0.86} & 92.60$\pm$0.65    & \textbf{57.00$\pm$0.69} & 91.52$\pm$0.11 & \textbf{58.82$\pm$0.51}  \\
\bottomrule
\end{tabular}}
\vspace{-0.2cm}
\end{table*}


\begin{remark}
The proposed DP-FedSAM can achieve a tighter bound in general non-convex setting compared with previous work \cite{cheng2022differentially, hu2022federated} ($\small \mathcal{O}\left( \frac{1}{\sqrt{KT}} + \frac{6K\sigma_{g}^2 + \sigma_l^2}{T} + \frac{B^2\sum_{t=1}^T(\overline{\alpha}^t + \tilde{\alpha}^t)}{T}+\frac{L^2 \sqrt{T}\sigma^2C^2d}{m^2\sqrt{K}}\right)$ in \cite{cheng2022differentially} and $\small \mathcal{O}\left( \frac{1}{\sqrt{KT}} + \frac{3\sigma_{g}^2 + 2\sigma_l^2}{\sqrt{KT}} +\frac{4L^2 \sqrt{T}\sigma^2C^2d}{m^2\sqrt{K}}\right)$ in \cite{hu2022federated}) and reduce the impacts of the local and global variance $\sigma_l^2$, $\sigma_g^2$. 
Meanwhile, 
we are the first to theoretically analyze these two impacts of both the on-average norm of local updates $\overline{\alpha}^t$ and local update inconsistency among clients $\tilde{\alpha}^t$ on convergence. And the negative impacts of $\overline{\alpha}^t$ and $\tilde{\alpha}^t$ are also significantly mitigated upon convergence compared with previous work \cite{cheng2022differentially} due to local SAM optimizer being adopted.
It means that we effectively alleviate performance degradation caused by clipping operation in DP and achieve better performance under symmetric noise. This theoretical result has also been empirically verified on several real-world data (see Section \ref{eva} and \ref{exper_DP}).

\end{remark}
