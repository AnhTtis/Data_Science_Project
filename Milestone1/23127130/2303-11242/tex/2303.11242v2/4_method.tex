\section{Methodology}
% \ls{It seems that we should first introduce the SAM optimizer. Then, we extend the SAM to DP-FedSAM (describe the procedures in detail,  which may highly depends on the formulation of FedSAM)
% At last, summarize the proposed DP-FedSAM as Algorithm 1.}
%  \ls{reorganize this paragraph. DPFL is first introduced(Figure 1) and then we introduce SAM to solve the challenges, in which SAM is XXXXX. }

To revisit the severe performance degradation challenge in DPFL, we observe the loss landscapes and surface contours of FedAvg and DP-FedAvg in Figure \ref{landscape_fedavg_dpfedavg} (a) and (b), respectively. And we find that the DPFL method has a sharper landscape with both poorer generalization ability and weight perturbation robustness than the FL method.
It means that the DPFL method may result in poor flatness and make model sensitivity to noise perturbation. However, the study focusing on this issue remains unexplored.
Therefore, we plan to face this challenge from the optimizer perspective by adopting a SAM optimizer in each client, dubbed DP-FedSAM, whose local loss function is defined as:
\begin{equation} \small\label{Eq:sam}
\small
    f_i(\mathbf{w}) = \mathbb{E}_{\xi\sim \mathcal{D}_i}\max_{\|\delta_i\|_2 \leq \rho} F_i(\mathbf{w}^{t,k}(i) +\delta_i; \xi_i), \quad i \in \mathcal{N},
\end{equation}
where $\mathbf{w}^{t,k}(i) +\delta_i$ is viewed as the perturbed model, $\rho$ is a predefined constant controlling the radius of the perturbation and $\|\cdot\|_2$ is a $l_2$-norm.
Instead of searching for a solution via SGD \cite{bottou2010large,bottou2018optimization}, SAM \cite{foret2021sharpnessaware} aims to seek a solution in a flat region by adding a small perturbation, i.e., $w + \delta$ with more robust performance. 
% Furthermore, as shown in Figure \ref{landscape_fedavg_dpfedavg} (a) and (b),  
% In this paper, we extend to SAM optimizer into DPFL for investigating this issue
% In the traditional decentralization training, e.g., D-PSGD \citep{lian2017can}, merely a one-step local update is allowed during one communication round,  
Specifically, for each client $i\in\{1,2,...,M\}$, each local iteration $k \in \{0,1,...,K-1\}$ in each communication round $t \in \{0,1,...,T-1\}$, the $k$-th inner iteration in client $i$ is performed as:
\begin{gather}
\small
        \mathbf{w}^{t,k+1}(i)=\mathbf{w} ^{t,k}(i)-\eta \tilde{\mathbf{g}}^{t,k}(i),  \label{local iteration} \\
       \!\!\!\! \tilde{\mathbf{g}}^{t,k}(i)=\nabla F_i(\mathbf{w}^{t,k} + \delta(\mathbf{w}^{t,k});\xi),  \delta(\mathbf{w}^{t,k})=\frac{\rho \mathbf{g}^{t,k}}{\left \| \mathbf{g}^{t,k} \right \|_2} .\label{g} \!\!\!
\end{gather}
Where $\delta(\mathbf{w}^{t,k})$ is calculated by using first-order Taylor expansion around $\mathbf{w}^{t,k}$ \cite{foret2021sharpnessaware}.
After that,
% we use the sparse technique to reduce the noise size following existing work \cite{cheng2022differentially}. Specifically, we define a mask function to generate mask matrix $\mathbf{M}(\Delta_i^t, p)$, where $T_s(\Delta_{i,j}^t) = p \cdot \max |T(\Delta_{i,j}^t)|$ in \cite{cheng2022differentially} denotes the $s$-th largest value in the parameter of the $j$-th layer and $0<p\leq1$ is the sparsity ratio. 
we adopt a sampling mechanism, gradient clipping, and Gaussian noise adding to ensure client-level DP. Note that this sampling can amplify the privacy guarantee since it decreases the chances of leaking information about a particular individual \cite{Abadi2016Deep}. Specifically,
% Specifically, at the $t$-th round of training, we implement the following steps.
% , given $M$ clients,
after sampling $m$ clients with probability $q=m/M$ at each communication round, which is important for measuring privacy loss. 
Then, we clip the local updates first:
\begin{equation} \small
\small
\tilde{\Delta}^t_{i} = \Delta_{i}^{t}\cdot\min\left(1, \frac{C}{\Vert \Delta_{i}^{t}\Vert_2}\right). 
\end{equation}
After clipping, we add Gaussian noise to the local update for ensuring client-level DP as follows:
\begin{equation}\label{dp_c}
\small
\hat{\Delta}^t_{i} = \tilde{\Delta}^t_{i} + \mathcal{N}(0, \sigma^2C^2 \cdot \mathbf{I}_d/m).
\end{equation}
With a given noise variance $\sigma^2$, the accumulative privacy budget $\epsilon$ can be calculated based on the sampled Gaussian mechanism~\cite{Yousefpour2021Opacus}. 
Finally, we summarize the training procedures of DP-FedSAM in Algorithm \ref{DFedAvg_DP}.


\begin{algorithm}[ht]
\small
\caption{DP-FedSAM}
\label{DFedAvg_DP}
% \centering
\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up} \SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\Input{Total number of clients $M$, sampling ratio of clients $q$, total number of communication rounds $T$, the clipping threshold $C$, local learning rate $\eta$, and total number of the local iterates are $K$.} 
\Output{Generate global model $\mathbf{w}^{T}$.}
\textbf{Initialization:} Randomly initialize the global model $\mathbf{w}^{0}$.\\
% \BlankLine
\For{$t=0$ \KwTo $T-1$}{
    Sample a set of $m=qM $ clients at random without replacement, denoted by $\mathcal{W}^t $.
    
    \For{client $i=1$ \KwTo $m$ \emph{\textbf{in parallel}} }{
        \For{$k=0$ \KwTo $K-1$ }{
        Update the global parameter as the local parameter
        $\mathbf{w}^{t}(i) \gets \mathbf{w}^{t}$.
        
        Sample a batch of local data $\xi_i$ and calculate local gradient $\mathbf{g}^{t,k}(i)=\nabla F_i(\mathbf{w}^{t,k}(i);\xi_i)$.
        
        Gradient perturbation by Equation (\ref{g}).
        
        Local iteration update by Equation (\ref{local iteration}).
        }
        $ \Delta ^t_i = \mathbf{w}^{t,K}(i) - \mathbf{w}^{t,0}(i)$.
        
        Clip and add noise for DP by Equation (\ref{dp_c}).
        % $\tilde{\Delta} ^t(i) =\Delta ^t_i  \cdot \min(1, \frac{C}{\|\Delta ^t_i\|_2}) + \mathcal{N}(0, \sigma^2C^2 \cdot \mathbf{I}_d/m) $.
        
        \textbf{Return} $\hat{\Delta} ^t(i)$.
    }
    $\mathbf{w}^{t+1} \gets \mathbf{w}^{t} + \frac{1}{m}\sum_{i\in \mathcal{W}^t} \hat{\Delta} ^t(i) $.
}
\end{algorithm}
Compared with existing DPFL methods \cite{McMahan2018learning,hu2022federated,cheng2022differentially},
% DP-FedAvg \cite{McMahan2018learning}, Fed-SMP \cite{hu2022federated}, and DP-FedAvg with BLUR and LUS \cite{cheng2022differentially},
the benefits of DP-FedSAM lie in three-fold: (i) We introduce SAM into DPFL to alleviate severe performance degradation via seeking a flatness model in each client, which is caused by the exacerbated inconsistency of local models. Specifically, DP-FedSAM generates both better generalization ability and robustness to DP noise by making the global model flatter. 
% We also empirically confirm the effectiveness of flat loss landscape and weight perturbation ability along with the distribution of local update norm in all communication rounds;
(ii) In addition, we analyze in detail how DP-FedSAM mitigates the negative impacts of DP. Specifically, we theoretically analyze the convergence with the on-average norm of local updates $\overline{\alpha}^{t}$ and local update consistency among clients $\tilde{\alpha}^t$, and empirically confirm these results via observing the norm distribution and average norm of local updates (see Section \ref{exper_DP}). (iii) Meanwhile, we present the theories unifying the impacts of gradient perturbation $\rho$ in SAM, the on-average norm of local updates $\overline{\alpha}^{t}$, and local update consistency among clients $\tilde{\alpha}^t$ in clipping operation, and the variance of random noise $\sigma^2C^2/m$ upon the convergence rate in Section \ref{th}.