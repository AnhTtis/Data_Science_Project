\section{Related work}
\noindent
\textbf{Client-level DPFL.}
Client-level DPFL is the de-facto approach for protecting any client's data. DP-FedAvg \cite{dpfedavg} is the first to study in this setting, which trains a language prediction model in a mobile keyboard and ensures client-level DP guarantee by employing the Gaussian mechanism and composing privacy guarantees.
After that, the work in \cite{Kairouz2021TheDD,Thakkar2019adaclip} presents a comprehensive end-to-end system, which appropriately discretizes the data and adds discrete Gaussian noise before performing secure aggregation. Meanwhile, AE-DPFL \cite{Zhu2020VotingbasedAF} leverages the voting-based mechanism among the data labels instead of averaging the gradients to avoid dimension dependence
and significantly reduce the communication cost. Fed-SMP \cite{hu2022federated} uses Sparsified Model Perturbation (SMP) to mitigate the impact of privacy protection on model accuracy. Different from the aforementioned methods, a recent study \cite{cheng2022differentially} revisits this issue and leverages Bounded Local Update Regularization (BLUR) and Local Update Sparsification (LUS) to restrict the norm of local updates and reduce the noise size before executing operations that guarantee DP, respectively. Nevertheless, severe performance degradation remains. 
% 
% However, this issue remains severe compared with FL without considering privacy, e.g., FedAvg.

% The most recent works alleviate this issue via either local sparsification or controlling the norm of local updates. 


% noise perturbation-based method, which requires clipping the norm of model update or data and adding noise to the clipped vectors.
% Nevertheless, the clipping and noise perturbation steps inevitably interfere with the performance of the resulting model.
%  AE-DPLF does not need to clip the model or data, thereby relieving the accuracy degradation issue. 
% However, the AE-DPFL framework assumes that unlabeled data from the global distribution is available to the server, which is very hard to satisfy in practical applications. 
% Our work follows the paradigm of the noise perturbation methods but we aim to improve the training process by naturally bounding the local update norms.


\noindent
\textbf{Sharpness Aware Minimization (SAM).} 
SAM \cite{foret2021sharpnessaware} is an effective optimizer for training deep learning (DL) models, which leverages the flatness geometry of the loss landscape to improve model generalization ability. Recently, \cite{Andriushchenko2022Towards} study the properties of SAM and provide convergence results of SAM for non-convex objectives. As a powerful optimizer, SAM and its variants have been applied to various machine learning (ML) tasks \cite{Zhao2022Penalizing,kwon2021asam,du2021efficient,liu2022towards,Abbas2022Sharp-MAML,mi2022make,zhong2022improving, huangrobust,sunfedspeed,sun2023adasam,shi2023improving}. Specifically, \cite{Qu2022Generalized}, \cite{sunfedspeed} and \cite{Caldarola2022Improving} integrate SAM to improve the generalization, and thus mitigate the distribution shift problem and achieve a new SOTA performance for FL. However, to the best of our knowledge, no efforts have been devoted to the empirical performance and theoretical analysis of SAM in DPFL. 


The most related works to this paper are DP-FedAvg in \cite{McMahan2018learning}, Fed-SMP in \cite{hu2022federated}, and DP-FedAvg with LUS and BLUR \cite{cheng2022differentially}. However, these works still suffer from inferior performance due to the exacerbated model inconsistency issue among the clients caused by random noise. Therefore, different from existing works, we try to alleviate this issue by making the landscape flatter and weight perturbation ability more robust. Furthermore, another related work is FedSAM \cite{Qu2022Generalized}, which integrates SAM optimizer to enhance the flatness of the local model and achieves new SOTA performance for FL. On top of the aforementioned studies, we are the first to extend the SAM optimizer into the DPFL setting to effectively alleviate the performance degradation problem. Meanwhile, we provide the theoretical analysis for sensitivity, privacy, and convergence in the non-convex setting. Finally, we empirically confirm our theoretical results and the superiority of performance compared with existing SOTA methods in DPFL.
