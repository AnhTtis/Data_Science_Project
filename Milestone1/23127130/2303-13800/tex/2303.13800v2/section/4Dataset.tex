\section{Ikea Assembly in the Wild Dataset (\dataset)}
\label{sec:dataset}

In order to study the problem of understanding instructional videos,
we collected a large well-labeled dataset called the Ikea assembly in-the-wild (\dataset) dataset with annotations obtained using Amazon Mechanical Turk and a publicly available in-browser video annotation tool Vidat~\cite{zhang2020vidat}.
The \dataset dataset contains 420 Ikea furniture pieces from 14 common categories, e.g., sofa, bed, wardrobe, table, etc.
Each piece of furniture comes with one or more user instruction manuals,
which are first divided into pages and then further divided into independent steps cropped from each page (some pages contain more than one step and some pages do not contain instructions).
There are 8,568 pages and 8,263 steps overall, on average 20.4 pages and 19.7 steps for each piece of furniture.
We crawled YouTube to find videos corresponding to these instruction manuals and as such the conditions in the videos are diverse on many aspects,
e.g.,~duration, resolution, first- or third-person view, camera pose, background environment, number of assemblers, etc.
The IAW dataset contains 1,005 raw videos with a length of around 183 hours in total.
Among them, approximately 114 hours of content are labeled as 15,649 actions to match the corresponding step in the corresponding manual.

The dataset is split into a train, validation, and test set (with 30,876 segments, 6,871 segments and 11,103 segments, respectively) by using a greedy algorithm to balance the distribution with respect to all attributes including viewpoint, indoor or not, camera motion and number of assemblers involved, and it is guaranteed that all video in both validation and testing sets are unseen in the training set.
