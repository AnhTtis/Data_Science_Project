\begin{table}[!t]
\centering
\small
\renewcommand\arraystretch{0.9}
\begin{tabularx}{1.05\linewidth}{l y y y y}
\toprule
\textbf{Method} &\textbf{Type} &\textbf{Extra Data} &\textbf{Total Hours$^\dagger$} & \textbf{WER} (\%) \\ \midrule\midrule
MV-WAS~\cite{chung2017lip} &\multirow{13}{*}[-0.4em]{V} &\multirow{4}{*}[-0.1em]{\xmark} &\multirow{4}{*}[-0.1em]{223} &70.4 \\
TDNN~\cite{yu2020audio} & & & & 48.9 \\
CM-seq2seq~\cite{DBLP:journals/corr/abs-2102-06657} & & & &39.1 \\
CM-aux~\cite{ma2022visual} & & &  &32.9 \\
\cmidrule(lr){1-1} \cmidrule(lr){3-5}
CTC/Attention \cite{petridis2018audio} & &\multirow{9}{*}[-0.4em]{\cmark}  &380 &63.5 \\
KD\,+\,CTC  \cite{afouras2020asr} & & &995 &51.3 \\
KD-seq2seq~\cite{DBLP:conf/cvpr/RenDLHH21} & & &818 &49.2 \\
TM-seq2seq~\cite{afouras2018deep} & & &1\,391 &48.3 \\
CTC/Attention~\cite{pan2022leveraging} & & &60\,000 &43.2 \\
CM-aux~\cite{ma2022visual} & & &1\,459  &25.5 \\
VTP~\cite{prajwal2022sub} & & &2\,676 &22.6 \\
Ours& & &818 &\textbf{27.9} \\
Ours& & &3\,448 &\textbf{14.6} \\
\midrule
TDNN~\cite{yu2020audio}  &\multirow{5}{*}[-0.4em]{A} &\multirow{2}{*}[-0.1em]{\xmark} &\multirow{2}{*}[-0.1em]{223} &6.7 \\
CM-seq2seq~\cite{DBLP:journals/corr/abs-2102-06657} & & & &4.3 \\
\cmidrule(lr){1-1} \cmidrule(lr){3-5}
CTC/Attention~\cite{pan2022leveraging} & &\multirow{3}{*}[-0.1em]{\cmark} &60\,000 &2.7 \\
Ours& & &818 &\textbf{2.6} \\
Ours& & &3\,448 &\textbf{1.5} \\
\midrule
TDNN~\cite{yu2020audio}  &\multirow{6}{*}[-0.1em]{A+V} &\multirow{2}{*}[-0.1em]{\xmark} &\multirow{2}{*}[-0.1em]{223} &5.9 \\
CM-seq2seq~\cite{DBLP:journals/corr/abs-2102-06657} & & & &4.2 \\
\cmidrule(lr){1-1} \cmidrule(lr){3-5}
TM-seq2seq~\cite{afouras2018deep} & &\multirow{4}{*}[-0.1em]{\cmark} &1\,391 &8.3 \\
CTC/Attention \cite{petridis2018audio} & &  &380 &7.0 \\
CM-seq2seq~\cite{DBLP:journals/corr/abs-2102-06657}  & & &380 &3.9 \\
Ours& & &3\,448 &\textbf{1.5} \\
\bottomrule
\end{tabularx}
\caption{WER (\%) of our audio-only, visual-only and audio-visual models on the LRS2 dataset. $^\dagger$ The total hours are counted by including the datasets used for both pre-training and training. Our model trained on 818 hours uses LRW, LRS2 and LRS3. Our model trained on 3\,448 hours uses LRW, LRS2, LRS3, VoxCeleb2 and AVSpeech.}
\vspace{-4mm}
\label{tab:sota lrs2}
\end{table}