 % Template for ICASSP-2021 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{icassp2023_spconf,amsmath,graphicx}


\usepackage[mathscr]{eucal}

\usepackage{multirow}
\usepackage{makecell}
\usepackage{amssymb}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\usepackage{nccmath}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\U{{\mathbf U}}
\def\y{{\mathbf y}}
\def\z{{\mathbf z}}
\def\L{{\cal L}}
\def\eg{\emph{e.g}\onedot} \def\Eg{\emph{E.g}\onedot}
\def\ie{\emph{i.e}\onedot} \def\Ie{\emph{I.e}\onedot}
\def\cf{\emph{c.f}\onedot} \def\Cf{\emph{C.f}\onedot}
\def\etc{\emph{etc}\onedot} \def\vs{\emph{vs}\onedot}
\def\wrt{w.r.t\onedot} \def\dof{d.o.f\onedot}
\def\etal{{\em et al.~}}
\newcommand{\af}[1]{\textcolor{purple}{Adriana: #1}}
\newcommand{\hc}[1]{\textcolor{red}{Honglie: #1}}

%for comments
\makeatother
\usepackage[normalem]{ulem}
\usepackage{xcolor}
\newcommand{\ping}[1] {{\color{blue} \bf #1}}
\usepackage{hyperref} % for link

% break link
\usepackage{url}
\def\UrlBreaks{\do\/\do-}

% References
\usepackage[backend=bibtex,citestyle=numeric-comp,bibstyle=ieee,sorting=none,defernumbers=true,giveninits=true,doi=false,isbn=false,url=false,eprint=false,minbibnames=1,maxbibnames=1]{biblatex}
\addbibresource{icassp2023_ref.bib}

\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{ragged2e}
\usepackage{bm}
% Include other packages here, before hyperref.

\usepackage{hyphenat}
\usepackage{xurl}


\usepackage{boldline}
\def\tabularxcolumn#1{m{#1}}
\newcolumntype{C}{>{\Centering\arraybackslash}X}

\newcolumntype{u}{>{\raggedright\hsize=.7\hsize}X}
\newcolumntype{t}{>{\Centering\hsize=.6\hsize}X}
\newcolumntype{s}{>{\Centering\hsize=.5\hsize}X}
\newcolumntype{o}{>{\Centering\hsize=.4\hsize}X}
\newcolumntype{k}{>{\Centering\hsize=.3\hsize}X}
\newcolumntype{y}{>{\Centering\hsize=.2\hsize}X}
\newcolumntype{z}{>{\Centering\hsize=.1\hsize}X}
\newcolumntype{v}{>{\raggedright\hsize=.6\hsize}X}
\newcolumntype{e}{>{\raggedright\hsize=.5\hsize}X}
\newcolumntype{j}{>{\raggedright\hsize=.35\hsize}X}
\newcolumntype{f}{>{\raggedright\hsize=.3\hsize}X}
\newcolumntype{h}{>{\raggedright\hsize=.2\hsize}X}
\newcolumntype{q}{>{\raggedright\hsize=.8\hsize}X}
% Title.
\title{Auto-AVSR: Audio-Visual Speech Recognition with Automatic Labels}

\makeatletter

\def\@name{\emph{Pingchuan Ma$^{1}$,  Alexandros Haliassos$^{1}$, Adriana Fernandez-Lopez$^2$, Honglie Chen$^2$} \\ \emph{Stavros Petridis$^{1,2}$, Maja Pantic$^{1,2}$
    \thanks{Only non-Meta co-authors downloaded, accessed, and used the datasets. Only non-Meta authors conducted any of the dataset pre-processing (no dataset pre-processing took place on Metaâ€™s servers or facilities). Code and trained models are available at: \url{https://github.com/mpc001/Visual_Speech_Recognition_for_Multiple_Languages}
    }
    }
}

\makeatother

\address{$^1$Imperial College London, UK\\
$^2$Meta AI, UK}



\begin{document}

\ninept

\maketitle

% -- ABSTRACT
\begin{abstract}
\input{sec0_abstract}
\end{abstract}
%
\begin{keywords}
audio-visual speech recognition, unlabelled audio-visual data, automatically generated transcriptions
\end{keywords}
 
\section{Introduction}
\input{sec1_intro}

\input{figure/fig_architect}
\vspace{-1mm}
\section{Auto-AVSR}
\input{sec2_method}

\vspace{-1mm}
\section{Experimental Setup}
\input{sec3_setup}

\vspace{-1mm}
\section{Results}
\input{sec4_results}

\vspace{-1mm}
\section{Conclusions}
\input{sec5_conclusion}






% -------------------------------------------------------------------------
\newpage
\AtNextBibliography{\small}
\section{References}
\begingroup
\printbibliography[heading=none]
\endgroup



\end{document}
