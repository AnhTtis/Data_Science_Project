
@article{mohamed_survey_2019,
	title = {A {Survey} on {Odometry} for {Autonomous} {Navigation} {Systems}},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2929133},
	abstract = {The development of a navigation system is one of the major challenges in building a fully autonomous platform. Full autonomy requires a dependable navigation capability not only in a perfect situation with clear GPS signals but also in situations, where the GPS is unreliable. Therefore, selfcontained odometry systems have attracted much attention recently. This paper provides a general and comprehensive overview of the state of the art in the ﬁeld of self-contained, i.e., GPS denied odometry systems, and identiﬁes the out-coming challenges that demand further research in future. Self-contained odometry methods are categorized into ﬁve main types, i.e., wheel, inertial, laser, radar, and visual, where such categorization is based on the type of the sensor data being used for the odometry. Most of the research in the ﬁeld is focused on analyzing the sensor data exhaustively or partially to extract the vehicle pose. Different combinations and fusions of sensor data in a tightly/loosely coupled manner and with ﬁltering or optimizing fusion method have been investigated. We analyze the advantages and weaknesses of each approach in terms of different evaluation metrics, such as performance, response time, energy efﬁciency, and accuracy, which can be a useful guideline for researchers and engineers in the ﬁeld. In the end, some future research challenges in the ﬁeld are discussed.},
	language = {en},
	urldate = {2023-01-16},
	journal = {IEEE Access},
	author = {Mohamed, Sherif A. S. and Haghbayan, Mohammad-Hashem and Westerlund, Tomi and Heikkonen, Jukka and Tenhunen, Hannu and Plosila, Juha},
	year = {2019},
	pages = {97466--97486},
	file = {Mohamed et al. - 2019 - A Survey on Odometry for Autonomous Navigation Sys.pdf:/home/alessandro/Zotero/storage/RUTUB879/Mohamed et al. - 2019 - A Survey on Odometry for Autonomous Navigation Sys.pdf:application/pdf},
}

@article{wang2020approaches,
  title={Approaches, challenges, and applications for deep visual odometry: Toward complicated and emerging areas},
  author={Wang, Ke and Ma, Sai and Chen, Junlan and Ren, Fan and Lu, Jianbo},
  journal={IEEE Transactions on Cognitive and Developmental Systems},
  volume={14},
  number={1},
  pages={35--49},
  year={2020},
  publisher={IEEE}
}

@article{tardioli2019ground,
  title={Ground robotics in tunnels: Keys and lessons learned after 10 years of research and experiments},
  author={Tardioli, Danilo and Riazuelo, Luis and Sicignano, Domenico and Rizzo, Carlos and Lera, Francisco and Villarroel, Jos{\'e} L and Montano, Luis},
  journal={Journal of Field Robotics},
  volume={36},
  number={6},
  pages={1074--1101},
  year={2019},
  publisher={Wiley Online Library}
}

@article{seco2022robot,
  title={Robot localization in tunnels: Combining discrete features in a pose graph framework},
  author={Seco, Teresa and L{\'a}zaro, Mar{\'\i}a T and Espelos{\'\i}n, Jes{\'u}s and Montano, Luis and Villarroel, Jos{\'e} L},
  journal={Sensors},
  volume={22},
  number={4},
  pages={1390},
  year={2022},
  publisher={MDPI}
}

@article{eirale2022marvin,
  title={Marvin: An innovative omni-directional robotic assistant for domestic environments},
  author={Eirale, Andrea and Martini, Mauro and Tagliavini, Luigi and Gandini, Dario and Chiaberge, Marcello and Quaglia, Giuseppe},
  journal={Sensors},
  volume={22},
  number={14},
  pages={5261},
  year={2022},
  publisher={MDPI}
}

@article{eirale2022human,
  title={Human-Centered Navigation and Person-Following with Omnidirectional Robot for Indoor Assistance and Monitoring},
  author={Eirale, Andrea and Martini, Mauro and Chiaberge, Marcello},
  journal={Robotics},
  volume={11},
  number={5},
  pages={108},
  year={2022},
  publisher={MDPI}
}

@article{tamantini2021robotic,
  title={A robotic health-care assistant for COVID-19 emergency: A proposed solution for logistics and disinfection in a hospital environment},
  author={Tamantini, Christian and di Luzio, Francesco Scotto and Cordella, Francesca and Pascarella, Giuseppe and Agro, Felice Eugenio and Zollo, Loredana},
  journal={IEEE Robotics \& Automation Magazine},
  volume={28},
  number={1},
  pages={71--81},
  year={2021},
  publisher={IEEE}
}

@article{gupta2020corridor,
  title={Corridor segmentation for automatic robot navigation in indoor environment using edge devices},
  author={Gupta, Surbhi and Sangeeta, R and Mishra, Ravi Shankar and Singal, Gaurav and Badal, Tapas and Garg, Deepak},
  journal={Computer Networks},
  volume={178},
  pages={107374},
  year={2020},
  publisher={Elsevier}
}

@INPROCEEDINGS{martini2022,
  author={Martini, Mauro and Cerrato, Simone and Salvetti, Francesco and Angarano, Simone and Chiaberge, Marcello},
  booktitle={2022 IEEE 18th International Conference on Automation Science and Engineering (CASE)}, 
  title={Position-Agnostic Autonomous Navigation in Vineyards with Deep Reinforcement Learning}, 
  year={2022},
  volume={},
  number={},
  pages={477-484},
  doi={10.1109/CASE49997.2022.9926582}
}

@inproceedings{aghi2021deep,
  title={Deep semantic segmentation at the edge for autonomous navigation in vineyard rows},
  author={Aghi, Diego and Cerrato, Simone and Mazzia, Vittorio and Chiaberge, Marcello},
  booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={3421--3428},
  year={2021},
  organization={IEEE}
}

@inproceedings{borenstein_umbmark_1995,
	address = {Philadelphia, PA},
	title = {{UMBmark}: a benchmark test for measuring odometry errors in mobile robots},
	shorttitle = {{UMBmark}},
	doi = {10.1117/12.228968},
	abstract = {This paper introduces a method for measuring odometry errors in mobile robots and for expressing these errors quantitatively. When measuring odometry errors, one must distinguish between (1) systematic errors, which are caused by kinematic imperfections ofthe mobile robot (for example, unequal wheel-diameters), and (2) non-systematic errors, which may be caused by wheel-slippage or irregularities ofthe floor. Systematic errors are a property ofthe robot itself, and they stay almost constant over prolonged periods of time, while non-systematic errors are a function of the properties of the floor.},
	language = {en},
	urldate = {2023-01-16},
	author = {Borenstein, Johann and Feng, Liqiang},
	editor = {Wolfe, William J. and Kenyon, Chase H.},
	month = dec,
	year = {1995},
	pages = {113--124},
	file = {Borenstein and Feng - 1995 - UMBmark a benchmark test for measuring odometry e.pdf:/home/alessandro/Zotero/storage/V49F9AFD/Borenstein and Feng - 1995 - UMBmark a benchmark test for measuring odometry e.pdf:application/pdf},
}

@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667, 1530-888X},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals via recurrent backpropagation takes a very long time, mostly due to insu cient, decaying error back ow. We brie y review Hochreiter's 1991 analysis of this problem, then address it by introducing a novel, e cient, gradient-based method called {\textbackslash}Long Short-Term Memory" (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete time steps by enforcing constant error ow through {\textbackslash}constant error carrousels" within special units. Multiplicative gate units learn to open and close access to the constant error ow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with arti cial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with RTRL, BPTT, Recurrent Cascade-Correlation, Elman nets, and Neural Sequence Chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, arti cial long time lag tasks that have never been solved by previous recurrent network algorithms.},
	language = {en},
	number = {8},
	urldate = {2023-01-16},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = nov,
	year = {1997},
	pages = {1735--1780},
	file = {Hochreiter and Schmidhuber - 1997 - Long Short-Term Memory.pdf:/home/alessandro/Zotero/storage/KR3VWHY2/Hochreiter and Schmidhuber - 1997 - Long Short-Term Memory.pdf:application/pdf},
}

@article{gaudiano_unsupervised_1996,
	title = {An unsupervised neural network for low-level control of a wheeled mobile robot: noise resistance, stability, and hardware implementation},
	volume = {26},
	issn = {1083-4419, 1941-0492},
	shorttitle = {An unsupervised neural network for low-level control of a wheeled mobile robot},
	doi = {10.1109/3477.499798},
	abstract = {We have recently introduced a neural network mobile robot controller (NETMORC) that autonomously learns the forward and inverse odometry of a differential drive robot through an unsupervised learning-by-doing cycle. After an initial learning phase, the controller can move the robot to an arbitrary stationary or moving target while compensating for noise and other forms of disturbance, such as wheel slippage or changes in the robot’s plant. In addition, the forward odometric map allows the robot to reach targets in the absence of sensory feedback. The controller is also is able to adapt in response to long-term changes in the robot’s plant, such as a change in the radius of the wheels. In this article we review the NETMORC architecture and describe its simpliﬁed algorithmic implementation, we present new, quantitative results on NETMORC’s performance and adaptability under noise-free and noisy conditions, we compare NETMORC’s performance on a trajectory-following task with the performance of an alternative controller, and we describe preliminary results on the hardware implementation of NETMORC with the mobile robot ROBUTER.},
	language = {en},
	number = {3},
	urldate = {2023-01-16},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	author = {Gaudiano, P. and Zalama, E. and Coronado, J.L.},
	month = jun,
	year = {1996},
	pages = {485--496},
	file = {Gaudiano et al. - 1996 - An unsupervised neural network for low-level contr.pdf:/home/alessandro/Zotero/storage/EEHI5FUY/Gaudiano et al. - 1996 - An unsupervised neural network for low-level contr.pdf:application/pdf},
}

@inproceedings{onyekpe_learning_2020,
	address = {Miami, FL, USA},
	title = {Learning {Uncertainties} in {Wheel} {Odometry} for {Vehicular} {Localisation} in {GNSS} {Deprived} {Environments}},
	isbn = {978-1-72818-470-8},
	doi = {10.1109/ICMLA51294.2020.00121},
	abstract = {Inertial Navigation Systems (INS) are commonly used to localise vehicles in the absence of Global Navigation Satellite Systems (GNSS) signals. However, they are plagued by noises, which grow exponentially over time during the triple integration computation, leading to a poor navigation solution. We explore the wheel encoder as an alternative to the accelerometer of the INS for positional tracking, and for the first time investigate the capability of deep learning using the Long Short-Term Memory (LSTM) neural network to learn the uncertainty inherent in the wheel speed measurements. These uncertainties could be manifested as changes in the tyre size or pressure, or wheel slips as a result of worn out tyres or wet/muddy road drive. The proposed solution has less integration steps in its computation, therefore providing the potential for a more accurate positioning estimation. Through a performance evaluation on several challenging scenarios for vehicular driving, such as hard braking, quick changes in vehicular acceleration, and wet/muddy road driving, we show that the wheel speed-based positioning approach is able to achieve up to 81.46 \% improvement compared to the INS accelerometer approach.},
	language = {en},
	urldate = {2023-01-16},
	booktitle = {2020 19th {IEEE} {International} {Conference} on {Machine} {Learning} and {Applications} ({ICMLA})},
	publisher = {IEEE},
	author = {Onyekpe, Uche and Palade, Vasile and Kanarachos, Stratis and Christopoulos, Stavros-Richard G.},
	month = dec,
	year = {2020},
	pages = {741--746},
	file = {Onyekpe et al. - 2020 - Learning Uncertainties in Wheel Odometry for Vehic. Learning Uncertainties in Wheel Odometry for Vehicular Localisation in GNSS Deprived Environmentspdf:/home/alessandro/Zotero/storage/YNXA5JXT/Onyekpe et al. - 2020 - Learning Uncertainties in Wheel Odometry for Vehic. Learning Uncertainties in Wheel Odometry for Vehicular Localisation in GNSS Deprived Environmentspdf:application/pdf},
}

@article{martinelli_simultaneous_2006,
	title = {Simultaneous localization and odometry self calibration for mobile robot},
	volume = {22},
	issn = {0929-5593, 1573-7527},
	doi = {10.1007/s10514-006-9006-7},
	language = {en},
	number = {1},
	urldate = {2023-01-16},
	journal = {Autonomous Robots},
	author = {Martinelli, Agostino and Tomatis, Nicola and Siegwart, Roland},
	month = nov,
	year = {2006},
	pages = {75--85},
	file = {Martinelli et al. - 2006 - Simultaneous localization and odometry self calibr.pdf:/home/alessandro/Zotero/storage/R2USIS2C/Martinelli et al. - 2006 - Simultaneous localization and odometry self calibr.pdf:application/pdf},
}

@article{onyekpe_whonet_2021,
	title = {{WhONet}: {Wheel} {Odometry} neural {Network} for vehicular localisation in {GNSS}-deprived environments},
	volume = {105},
	issn = {09521976},
	shorttitle = {{WhONet}},
	doi = {10.1016/j.engappai.2021.104421},
	language = {en},
	urldate = {2023-01-16},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Onyekpe, Uche and Palade, Vasile and Herath, Anuradha and Kanarachos, Stratis and Fitzpatrick, Michael E.},
	month = oct,
	year = {2021},
	pages = {104421},
	file = {Onyekpe et al. - 2021 - WhONet Wheel Odometry neural Network for vehicula.pdf:/home/alessandro/Zotero/storage/JDHSMIPP/Onyekpe et al. - 2021 - WhONet Wheel Odometry neural Network for vehicula.pdf:application/pdf},
}

@article{onyekpe_r-whonet_nodate,
  title={R-WhONet: Recalibrated Wheel Odometry Neural Network for Vehicular Positioning using Transfer Learning},
  author={Onyekpe, Uche and Szkolnik, Alicja and Palade, Vasile and Kanarachos, Stratis and Fitzpatrick, Michael E},
  journal={arXiv preprint arXiv:2209.05877},
  year={2022}
}

@inproceedings{hidalgo-carrio_gaussian_2017,
	address = {Singapore, Singapore},
	title = {Gaussian process estimation of odometry errors for localization and mapping},
	isbn = {978-1-5090-4633-1},
	doi = {10.1109/ICRA.2017.7989670},
	abstract = {Since early in robotics the performance of odometry techniques has been of constant research for mobile robots. This is due to its direct inﬂuence on localization. The pose error grows unbounded in dead-reckoning systems and its uncertainty has negative impacts in localization and mapping (i.e. SLAM). The dead-reckoning performance in terms of residuals, i.e. the difference between the expected and the real pose state, is related to the statistical error or uncertainty in probabilistic motion models. A novel approach to model odometry errors using Gaussian processes (GPs) is presented. The methodology trains a GP on the residual between the non-linear parametric motion model and the ground truth training data. The result is a GP over odometry residuals which provides an expected value and its uncertainty in order to enhance the belief with respect to the parametric model. The localization and mapping beneﬁts from a comprehensive GP-odometry residuals model. The approach is applied to a planetary rover in an unstructured environment. We show that our approach enhances visual SLAM by efﬁciently computing image frames and effectively distributing keyframes.},
	language = {en},
	urldate = {2023-01-16},
	booktitle = {2017 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Hidalgo-Carrio, Javier and Hennes, Daniel and Schwendner, Jakob and Kirchner, Frank},
	month = may,
	year = {2017},
	pages = {5696--5701},
	file = {Hidalgo-Carrio et al. - 2017 - Gaussian process estimation of odometry errors for.pdf:/home/alessandro/Zotero/storage/3DXQTLAU/Hidalgo-Carrio et al. - 2017 - Gaussian process estimation of odometry errors for.pdf:application/pdf},
}

@article{abolfazli_esfahani_aboldeepio_2020,
	title = {{AbolDeepIO}: {A} {Novel} {Deep} {Inertial} {Odometry} {Network} for {Autonomous} {Vehicles}},
	volume = {21},
	issn = {1524-9050, 1558-0016},
	shorttitle = {{AbolDeepIO}},
	doi = {10.1109/TITS.2019.2909064},
	abstract = {Inertial measurement units (IMUs) suffer from bias and measurement noise, which makes it much more complicated to tackle the problem of inertial odometry (IO). Due to the error propagation over time, while estimating robot position, an inaccurate estimation or a small error will cause the odometry and a localization system unreliable and unusable in a split of seconds. This paper presents a novel triple-channel deep IO network architecture based on the physical and mathematical models of IMUs. The proposed method simulates the noise model in the training phase and becomes robust to noise during testing. Besides, the proposed network architecture also considers the time interval between two consecutive IMU readings (sampling time) so that it is robust to the change of IMU frequency and the missing of IMU information. To the best of our knowledge, this paper is the ﬁrst work reviewing and analyzing the existing IO methods used by the deep-learning-based visual-IO approaches. The proposed network architecture outperforms all the existing solutions on the IMU readings of the challenging Micro Aerial Vehicle dataset and improves the accuracy by approximately 25\%.},
	language = {en},
	number = {5},
	urldate = {2023-01-16},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Abolfazli Esfahani, Mahdi and Wang, Han and Wu, Keyu and Yuan, Shenghai},
	month = may,
	year = {2020},
	pages = {1941--1950},
	file = {Abolfazli Esfahani et al. - 2020 - AbolDeepIO A Novel Deep Inertial Odometry Network.pdf:/home/alessandro/Zotero/storage/N9U8DPDU/Abolfazli Esfahani et al. - 2020 - AbolDeepIO A Novel Deep Inertial Odometry Network.pdf:application/pdf},
}

@misc{chen_ionet_2018,
	title = {{IONet}: {Learning} to {Cure} the {Curse} of {Drift} in {Inertial} {Odometry}},
	shorttitle = {{IONet}},
	abstract = {Inertial sensors play a pivotal role in indoor localization, which in turn lays the foundation for pervasive personal applications. However, low-cost inertial sensors, as commonly found in smartphones, are plagued by bias and noise, which leads to unbounded growth in error when accelerations are double integrated to obtain displacement. Small errors in state estimation propagate to make odometry virtually unusable in a matter of seconds. We propose to break the cycle of continuous integration, and instead segment inertial data into independent windows. The challenge becomes estimating the latent states of each window, such as velocity and orientation, as these are not directly observable from sensor data. We demonstrate how to formulate this as an optimization problem, and show how deep recurrent neural networks can yield highly accurate trajectories, outperforming state-of-the-art shallow techniques, on a wide range of tests and attachments. In particular, we demonstrate that IONet can generalize to estimate odometry for non-periodic motion, such as a shopping trolley or baby-stroller, an extremely challenging task for existing techniques.},
	language = {en},
	urldate = {2023-01-16},
	publisher = {arXiv},
	author = {Chen, Changhao and Lu, Xiaoxuan and Markham, Andrew and Trigoni, Niki},
	month = jan,
	year = {2018},
	note = {arXiv:1802.02209 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics, Computer Science - Computer Vision and Pattern Recognition},
	file = {Chen et al. - 2018 - IONet Learning to Cure the Curse of Drift in Iner.pdf:/home/alessandro/Zotero/storage/3YIEMZZG/Chen et al. - 2018 - IONet Learning to Cure the Curse of Drift in Iner.pdf:application/pdf},
}

@article{brossard_ai-imu_2020,
	title = {{AI}-{IMU} {Dead}-{Reckoning}},
	volume = {5},
	issn = {2379-8904, 2379-8858},
	doi = {10.1109/TIV.2020.2980758},
	abstract = {In this paper, we propose a novel accurate method for dead-reckoning of wheeled vehicles based only on an Inertial Measurement Unit (IMU). In the context of intelligent vehicles, robust and accurate dead-reckoning based on the IMU may prove useful to correlate feeds from imaging sensors, to safely navigate through obstructions, or for safe emergency stops in the extreme case of exteroceptive sensors failure. The key components of the method are the Kalman ﬁlter and the use of deep neural networks to dynamically adapt the noise parameters of the ﬁlter. The method is tested on the KITTI odometry dataset, and our dead-reckoning inertial method based only on the IMU accurately estimates 3D position, velocity, orientation of the vehicle and self-calibrates the IMU biases. We achieve on average a 1.10\% translational error and the algorithm competes with top-ranked methods which, by contrast, use LiDAR or stereo vision.},
	language = {en},
	number = {4},
	urldate = {2023-01-16},
	journal = {IEEE Transactions on Intelligent Vehicles},
	author = {Brossard, Martin and Barrau, Axel and Bonnabel, Silvere},
	month = dec,
	year = {2020},
	pages = {585--595},
	file = {Brossard et al. - 2020 - AI-IMU Dead-Reckoning.pdf:/home/alessandro/Zotero/storage/763MSM9I/Brossard et al. - 2020 - AI-IMU Dead-Reckoning.pdf:application/pdf},
}

@article{borenstein_measurement_1996,
	title = {Measurement and correction of systematic odometry errors in mobile robots},
	volume = {12},
	issn = {1042296X},
	doi = {10.1109/70.544770},
	abstract = {Odometry is the most widely used method for determining the momentary position of a mobile robot. In most practical applications odometry provides easily accessible real-time positioning information in-between periodic absolute position measurements. The frequency at which the (usually costly and/or time-consuming) absolute measurements must be performed depends to a large degree on the accuracy of the odometry system.},
	language = {en},
	number = {6},
	urldate = {2023-01-16},
	journal = {IEEE Transactions on Robotics and Automation},
	author = {Borenstein, J. and {Liqiang Feng}},
	month = dec,
	year = {1996},
	pages = {869--880},
	file = {Borenstein and Liqiang Feng - 1996 - Measurement and correction of systematic odometry .pdf:/home/alessandro/Zotero/storage/D5UEM7D7/Borenstein and Liqiang Feng - 1996 - Measurement and correction of systematic odometry .pdf:application/pdf},
}

@inproceedings{xu_estimating_2009,
	address = {Miami, FL, USA},
	title = {Estimating the {Odometry} {Error} of a {Mobile} {Robot} by {Neural} {Networks}},
	isbn = {978-0-7695-3926-3},
	doi = {10.1109/ICMLA.2009.96},
	abstract = {Localization is the accurate estimation of robot’s current position and is critical for map building. Odometry modeling is one of the main approaches to solving the localization problem, the other being a sensor based correspondence solver. Currently few robot positioning systems support calibration of odometry errors in both feature rich indoor and landmark poor outdoor environments. To achieve good performance in various environments, the mobile robot has to be able to learn to localize in unknown environments, and reuse previously computed environment speciﬁc localization models.This paper presents a method combining the standard Back-Propagation technique and a feed-forward neural network model for odometry calibration for both synchronous and differential drive mobile robots. This novel method is compared with a generic localization module and an optimization based approach, and found to minimize odometry error because of its nonlinear input-output mapping ability. Experimental results demonstrate that the neural network approach incorporating Bayesian Regularization provides improved performance and relaxes constraints in the UMBmark method.},
	language = {en},
	urldate = {2023-01-16},
	booktitle = {2009 {International} {Conference} on {Machine} {Learning} and {Applications}},
	publisher = {IEEE},
	author = {Xu, Haoming and Collins, John James},
	month = dec,
	year = {2009},
	pages = {378--385},
	file = {Xu and Collins - 2009 - Estimating the Odometry Error of a Mobile Robot by.pdf:/home/alessandro/Zotero/storage/IRNUKKSW/Xu and Collins - 2009 - Estimating the Odometry Error of a Mobile Robot by.pdf:application/pdf},
}

@inproceedings{kelly_general_2001,
	address = {Maui, HI, USA},
	title = {General solution for linearized systematic error propagation in vehicle odometry},
	volume = {4},
	isbn = {978-0-7803-6612-1},
	doi = {10.1109/IROS.2001.976357},
	abstract = {Vehicle odometry is a nonlinear dynamical system in echelonform. Accordingly, a general solution can be written by solving the nonlinear equations in the correct ordel: Another implication of this structure is that a completely general solution to the linearized (perturbative)dynamics exists. The associated vector convolution integral is the general relationship between output error and both the input error and reference trajectory. Solutions for errors in individual coordinates are in the form of line integrals in state space. Response to initial conditions and translational scale errors, among others, is path independent and vanishes on all closed trajectories. Response to other errors is path dependent and can be reduced to expressions in error moments of the reference trajectory. These path dependent errors vanish on closed symmetric paths, among others, These theoretical results and the underlying error expressions have many uses in design, calibration, and evaluation of odometry systems.},
	language = {en},
	urldate = {2023-01-16},
	booktitle = {Proceedings 2001 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}. {Expanding} the {Societal} {Role} of {Robotics} in the the {Next} {Millennium} ({Cat}. {No}.{01CH37180})},
	publisher = {IEEE},
	author = {Kelly, A.},
	year = {2001},
	pages = {1938--1945},
	file = {Kelly - 2001 - General solution for linearized systematic error p.pdf:/home/alessandro/Zotero/storage/GPGWAZDL/Kelly - 2001 - General solution for linearized systematic error p.pdf:application/pdf},
}

@inproceedings{lima_neural_2017,
	address = {Pucon},
	title = {Neural network regularization of an inertial odometry estimation for position control of a mobile robot},
	isbn = {978-1-5386-3123-2},
	doi = {10.1109/CHILECON.2017.8229655},
	abstract = {Localization is one of the main tasks of autonomous mobile robots. There are many approaches on how to determine the robot’s position with reasonable precision, as with the use of sensor fusion (IMU, GPS, Image, LiDAR). Even though it is possible to achieve high precision with these sensors combined, a solution that requires less resources in terms of processing, energy consumption and yet provide a good enough estimation for position control is sought. This paper presents the application of an artificial neural network to improve position estimates from inertial measurement in a mobile robot navigating in an indoor environment.},
	language = {en},
	urldate = {2023-01-16},
	booktitle = {2017 {CHILEAN} {Conference} on {Electrical}, {Electronics} {Engineering}, {Information} and {Communication} {Technologies} ({CHILECON})},
	publisher = {IEEE},
	author = {Lima, Marcus V. P. and Silva, Pedro R. M. and Quiroz, Cesar H. C. and Kurka, Paulo R. G.},
	month = oct,
	year = {2017},
	pages = {1--6},
	file = {Lima et al. - 2017 - Neural network regularization of an inertial odome.jsp:/home/alessandro/Zotero/storage/G2QYKPUR/Lima et al. - 2017 - Neural network regularization of an inertial odome.jsp:application/pdf},
}

@inproceedings{zhang_learning_2021,
	address = {Tianjin, China},
	title = {Learning {End}-to-{End} {Inertial}-{Wheel} {Odometry} for {Vehicle} {Ego}-{Motion} {Estimation}},
	isbn = {978-1-66540-847-9},
	doi = {10.1109/CVCI54083.2021.9661121},
	abstract = {We present an end-to-end learning architecture for wheel speeds and inertial fusion for real-time ego-motion estimation. In contrast to the previous work, our method utilizes the neural network to learn the nonlinear vehicle model and reduce the modeling error in motion propagation. The network inputs are the wheel speeds and inertial measurements while the outputs are the 2D pose increments in vehicle frames. To enhance the learning efﬁciency of the network, we propose a data enhancement strategy and employ a large amount of data for training. A diversity of practical scenario tests have shown that our proposed method outperforms traditional methods in terms of accuracy and robustness, achieving an average translation error of less than 0.4m per 100m, which meets the practical application requirements and the trained model has been deployed as a front-end module for other systems on an autonomous vehicle.},
	language = {en},
	urldate = {2023-01-16},
	booktitle = {2021 5th {CAA} {International} {Conference} on {Vehicular} {Control} and {Intelligence} ({CVCI})},
	publisher = {IEEE},
	author = {Zhang, Zhihuang and Zhao, Jintao and Huang, Changyao and Li, Liang},
	month = oct,
	year = {2021},
	pages = {1--6},
	file = {Zhang et al. - 2021 - Learning End-to-End Inertial-Wheel Odometry for Ve.jsp:/home/alessandro/Zotero/storage/EKC3XHSZ/Zhang et al. - 2021 - Learning End-to-End Inertial-Wheel Odometry for Ve.jsp:application/pdf},
}

@inproceedings{chen_improved_2020,
	address = {Austin, TX, USA},
	title = {Improved {Window} {Segmentation} for {Deep} {Learning} {Based} {Inertial} {Odometry}},
	isbn = {978-1-72819-829-3},
	doi = {10.1109/IPCCC50635.2020.9391535},
	abstract = {The variety of sensors embedded in smartphones makes it possible to develop indoor navigation and localization systems on mobile terminals. However, these cheap sensors are plagued by bias and noise, leading to unbounded system drifts. Inspired by Expectation-Maximization algorithm, this paper proposes to combine zero-velocity detection with gated recurrent unit (GRU) neural networks, make full use of pedestrian motion characteristics, and naturally and accurately split the raw measurements into multiple weakly correlated windows step by step. The GRU is used to exploit dynamic context and predict the polar vector of each window. Several experiments were conducted to test the performance of proposed model, and IONet, a deep learning based inertial odometry model using fixed-size sliding window, was taken as a reference. The results show that the proposed model is able to generate smooth trajectories with high precision. Compared with IONet, the performance of proposed model in turning is better.},
	language = {en},
	urldate = {2023-01-16},
	booktitle = {2020 {IEEE} 39th {International} {Performance} {Computing} and {Communications} {Conference} ({IPCCC})},
	publisher = {IEEE},
	author = {Chen, Siyu and Zhu, Yu and Niu, Xiaoguang and Hu, Zhiyong},
	month = nov,
	year = {2020},
	pages = {1--7},
	file = {Chen et al. - 2020 - Improved Window Segmentation for Deep Learning Bas.pdf:/home/alessandro/Zotero/storage/G7ZY73HB/Chen et al. - 2020 - Improved Window Segmentation for Deep Learning Bas.pdf:application/pdf},
}

@inproceedings{jinglin_shen_localization_2011,
	address = {San Francisco, CA},
	title = {Localization through fusion of discrete and continuous epipolar geometry with wheel and {IMU} odometry},
	isbn = {978-1-4577-0081-1 978-1-4577-0080-4 978-1-4577-0079-8},
	doi = {10.1109/ACC.2011.5990946},
	abstract = {This paper describes a novel sensor fusion implementation to improve the accuracy of robot localization by combining multiple visual odometry approaches with wheel and IMU odometry. Discrete and continuous Homography Matrices are used to recover position, orientation, and velocity from image sequences of tracked feature points. An Inertial Measurement Unit (IMU) and wheel encoders also measure linear and angular velocity of mobile robot. A Kalman ﬁlter fuses the measurements from the visual and inertial measurement systems. Time varying matrices in the Kalman ﬁlter allow each sensor to receive higher or lower weight in situations where each is more or less accurate. Experiments are performed with a camera and a IMU (Wiimote controller) mounted on a mobile robot.},
	language = {en},
	urldate = {2023-01-16},
	booktitle = {Proceedings of the 2011 {American} {Control} {Conference}},
	publisher = {IEEE},
	author = {{Jinglin Shen} and Tick, David and Gans, Nicholas},
	month = jun,
	year = {2011},
	pages = {1292--1298},
	file = {Jinglin Shen et al. - 2011 - Localization through fusion of discrete and contin.pdf:/home/alessandro/Zotero/storage/ZFIP5HVX/Jinglin Shen et al. - 2011 - Localization through fusion of discrete and contin.pdf:application/pdf},
}

@inproceedings{kok_seng_chong_accurate_1997,
	address = {Albuquerque, NM, USA},
	title = {Accurate odometry and error modelling for a mobile robot},
	volume = {4},
	isbn = {978-0-7803-3612-4},
	doi = {10.1109/ROBOT.1997.606708},
	abstract = {This paper presents a low cost novel odometry design capable of achieving high accuracy dead-reckoning. It also develops a statistical error model for estimating position and orientation errors of a mobile robot using odometry. Previous work on propagating odometry error covariance relies on incrementally updating the covariance matrix in small time steps. The approach taken here sums the noise theoretically over the entire path length to produce simple closed form expressions, allowing efficient covariance matrix updating after the completion of path segments. Closed form error covariance matrix is developed for a general circular arc and two special cases : (I) straight line and (II) turning about the centre of axle of the robot. Other paths can be composed of short segments of constant curvature arcs without great loss of accuracy. The model assumes that wheel distance measurement errors are exclusively random zero mean white noise. Systematic errors due to wheel radius and wheel base measurement were first calibrated with UMBmark [BorFen94]. Experimental results show that, despite its low cost, our system’s performance, with regard to dead-reckoning accuracy, is comparable to some of the best, award-winning vehicles around. The statistical error model, on the other hand, needs to be improved in light of new insights.},
	language = {en},
	urldate = {2023-01-16},
	booktitle = {Proceedings of {International} {Conference} on {Robotics} and {Automation}},
	publisher = {IEEE},
	author = {{Kok Seng Chong} and Kleeman, L.},
	year = {1997},
	pages = {2783--2788},
	file = {Kok Seng Chong and Kleeman - 1997 - Accurate odometry and error modelling for a mobile.pdf:/home/alessandro/Zotero/storage/BZYY6HCT/Kok Seng Chong and Kleeman - 1997 - Accurate odometry and error modelling for a mobile.pdf:application/pdf},
}

@inproceedings{brossard_rins-w_2019,
	address = {Macau, China},
	title = {{RINS}-{W}: {Robust} {Inertial} {Navigation} {System} on {Wheels}},
	isbn = {978-1-72814-004-9},
	shorttitle = {{RINS}-{W}},
	doi = {10.1109/IROS40897.2019.8968593},
	abstract = {This paper proposes a real-time approach for longterm inertial navigation based only on an Inertial Measurement Unit (IMU) for self-localizing wheeled robots. The approach builds upon two components: 1) a robust detector that uses recurrent deep neural networks to dynamically detect a variety of situations of interest, such as zero velocity or no lateral slip; and 2) a state-of-the-art Kalman ﬁlter which incorporates this knowledge as pseudo-measurements for localization. Evaluations on a publicly available car dataset demonstrates that the proposed scheme may achieve a ﬁnal distance error of 20 m for a 21 km long trajectory of a vehicle driving for over an hour, equipped with an IMU of moderate precision (the gyro drift rate is 10 deg/h). To our knowledge, this is the ﬁrst paper which combines sophisticated deep learning techniques with state-ofthe-art ﬁltering methods for pure inertial navigation on wheeled vehicles and as such opens up for novel data-driven inertial navigation techniques. Moreover, albeit taylored for IMU-only based localization, our method may be used as a component for self-localization of wheeled robots equipped with a more complete sensor suite.},
	language = {en},
	urldate = {2023-01-16},
	booktitle = {2019 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	publisher = {IEEE},
	author = {Brossard, Martin and Barrau, Axel and Bonnabel, Silvere},
	month = nov,
	year = {2019},
	pages = {2068--2075},
	file = {Brossard et al. - 2019 - RINS-W Robust Inertial Navigation System on Wheel.pdf:/home/alessandro/Zotero/storage/SMUTAT79/Brossard et al. - 2019 - RINS-W Robust Inertial Navigation System on Wheel.pdf:application/pdf},
}

@inproceedings{roy_online_1999,
	address = {Detroit, MI, USA},
	title = {Online self-calibration for mobile robots},
	volume = {3},
	isbn = {978-0-7803-5180-6},
	doi = {10.1109/ROBOT.1999.770447},
	abstract = {This paper proposes a statistical method for calibrating the odometry of mobile robots. In contrast to previous approaches, which require explicit measurements of actual motion when calibrating a robot’s odometry, the algorithm proposed here uses the robot’s sensors to automatically calibrate the robot as it operates. An efﬁcient, incremental maximum likelihood algorithm enables the robot to adapt to changes in its kinematics on-line, as they occur. The appropriateness of the approach is demonstrated in two large-scale environments, where the amount of odometric error is reduced by an order of magnitude.},
	language = {en},
	urldate = {2023-01-16},
	booktitle = {Proceedings 1999 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({Cat}. {No}.{99CH36288C})},
	publisher = {IEEE},
	author = {Roy, N. and Thrun, S.},
	year = {1999},
	pages = {2292--2297},
	file = {Roy and Thrun - 1999 - Online self-calibration for mobile robots.pdf:/home/alessandro/Zotero/storage/TV2ISQVE/Roy and Thrun - 1999 - Online self-calibration for mobile robots.pdf:application/pdf},
}

@article{canbek_drift_2022,
	title = {Drift compensation of a holonomic mobile robot using recurrent neural networks},
	volume = {15},
	issn = {1861-2776, 1861-2784},
	doi = {10.1007/s11370-022-00430-w},
	abstract = {Mecanum wheeled robots can exhibit serious slippage problems because of the discontinuous contact between the wheels and the ground which negatively inﬂuences the overall navigation quality. Addressing this problem, the aim of this paper is to demonstrate how a learning-based method can be used for the estimation of the drifting error from multiple sensors with distinct measurement types. Here, a recurrent neural network (RNN)-based drift compensation algorithm is proposed for the estimation of the positioning drift. In order to improve the positioning performance in dead reckoning the estimated drift is used within the real-time control loop for proper modiﬁcation of the motion trajectory. During the training phase, the data acquired from the acceleration sensors attached to the robot chassis and the encoders of the wheels of the robot are used as the main features to train a gated recurrent unit-based RNN. The drift estimator is trained using the computergenerated reference position data, and the response position data which is measured using an optoelectronic motion tracking device. The performance of the proposed learning-based drift estimation and control algorithm is validated through a series of experiments. The responses obtained from the experiments are graphically illustrated and the improvements in the positioning performances are numerically evaluated. The results obtained from the experiments illustrate the effective performance of the proposed algorithm by considerably decreasing the positioning errors.},
	language = {en},
	number = {3},
	urldate = {2023-01-16},
	journal = {Intelligent Service Robotics},
	author = {Canbek, Kansu Oguz and Yalcin, Hulya and Baran, Eray A.},
	month = jul,
	year = {2022},
	pages = {399--409},
	file = {Canbek et al. - 2022 - Drift compensation of a holonomic mobile robot usi.pdf:/home/alessandro/Zotero/storage/DTGNI2C6/Canbek et al. - 2022 - Drift compensation of a holonomic mobile robot usi.pdf:application/pdf},
}

@article{botero_valencia_simple_2017,
	title = {A simple method to estimate the trajectory of a low cost mobile robotic platform using an {IMU}},
	volume = {11},
	issn = {1955-2513, 1955-2505},
	doi = {10.1007/s12008-016-0340-5},
	abstract = {In mobile robotics it is essential to know the location and orientation of the devices for proper operation of the algorithms. This task can be performed with different systems, such as GPS that sometimes may be inefﬁcient indoors, or also with image-based systems using peripheral cameras. Inertial Measurement Units (IMU) with nine degrees of freedom are a fusion made up of accelerometers, gyroscopes and triaxial magnetometers and have been widely used in the location and orientation applications, with easy acquisition and low computational costs to process the obtained data. For the use in mobile robotics, they present an inexpensive alternative to the above-mentioned systems. In this paper we present an algorithm to determine the trajectory and orientation of a low-cost robotic platform that follows the track of a preset geometric ﬁgure using a custom built IMU. The algorithm enables the estimation of the size and the shape of the path. The data obtained from the IMU was processed with a 1D Kalman ﬁlter to remove the Gaussian noise from the data on each channel. The results of estimating the shape of trajectory actually represent the reference system and determining the shape dimensions results in an error percentage lower than 10 \%.},
	language = {en},
	number = {4},
	urldate = {2023-01-16},
	journal = {International Journal on Interactive Design and Manufacturing (IJIDeM)},
	author = {Botero Valencia, J.-S. and Rico Garcia, M. and Villegas Ceballos, J.-P.},
	month = nov,
	year = {2017},
	pages = {823--828},
	file = {Botero Valencia et al. - 2017 - A simple method to estimate the trajectory of a lo.pdf:/home/alessandro/Zotero/storage/D8UFN27S/Botero Valencia et al. - 2017 - A simple method to estimate the trajectory of a lo.pdf:application/pdf},
}

@inproceedings{inthiam_self-localization_2014,
	address = {Bangkok, Thailand},
	title = {Self-localization and navigation of holonomic mobile robot using omni-directional wheel odometry},
	isbn = {978-1-4799-4075-2 978-1-4799-4076-9},
	doi = {10.1109/TENCON.2014.7022281},
	abstract = {This paper proposes a simple but effective selflocalization and navigation algorithm for the omni-directional mobile robot equipped with three driving and three odometry wheels. Not only can this technique locates the robot’s position, but it can also align its heading with respect to the selected target while navigating along the pre-defined trajectory. With a certain configuration of odometry omni-directional wheels, rotational readings from three encoders attached to these odometry wheels provide linear and angular velocities of the mobile robot. Integrating these velocities would result in position and heading of the mobile robot. As a result, the mobile robot becomes a complete holonomic system. Furthermore, navigation algorithm is illustrated for two cases namely point-to-point and multi-point schemes. Three experimental results are conducted to verify the effectiveness of this algorithm.},
	language = {en},
	urldate = {2023-01-16},
	booktitle = {{TENCON} 2014 - 2014 {IEEE} {Region} 10 {Conference}},
	publisher = {IEEE},
	author = {Inthiam, Jiraphan and Deelertpaiboon, Chirdpong},
	month = oct,
	year = {2014},
	pages = {1--5},
	file = {Inthiam and Deelertpaiboon - 2014 - Self-localization and navigation of holonomic mobi.pdf:/home/alessandro/Zotero/storage/MV2W3H2M/Inthiam and Deelertpaiboon - 2014 - Self-localization and navigation of holonomic mobi.pdf:application/pdf},
}

@article{dugne-hennequin_understanding_2021,
	title = {Understanding the {Behavior} of {Data}-{Driven} {Inertial} {Odometry} {With} {Kinematics}-{Mimicking} {Deep} {Neural} {Network}},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3062817},
	abstract = {In navigation, deep learning for inertial odometry (IO) has recently been investigated using data from a low-cost IMU only. The measurement of noise, bias, and some errors from which IO suffers is estimated with a deep neural network (DNN) to achieve more accurate pose estimation. While numerous studies on the subject highlighted the performances of their approach, the behavior of data-driven IO with DNN has not been clariﬁed. Therefore, this paper presents a quantitative analysis of kinematics-mimicking DNN-based IO from various aspects. First, the new network architecture is designed to mimic the kinematics and ensure comprehensive analyses. Next, the hyper-parameters of neural networks that are highly correlated to IO are identiﬁed. Besides, their role in the performances is investigated. In the evaluation, the analyses were conducted with publicly-available IO datasets for vehicles and drones. The results are introduced to highlight the remaining problems in IO and are considered a guideline to promote further research.},
	language = {en},
	urldate = {2023-01-16},
	journal = {IEEE Access},
	author = {Dugne-Hennequin, Quentin Arnaud and Uchiyama, Hideaki and Paulo Silva Do Monte Lima, Joao},
	year = {2021},
	pages = {36589--36619},
	file = {Dugne-Hennequin et al. - 2021 - Understanding the Behavior of Data-Driven Inertial.pdf:/home/alessandro/Zotero/storage/8FZQNQWT/Dugne-Hennequin et al. - 2021 - Understanding the Behavior of Data-Driven Inertial.pdf:application/pdf},
}

@article{du_mems_2016,
	title = {{MEMS} {IMU} {Error} {Mitigation} {Using} {Rotation} {Modulation} {Technique}},
	volume = {16},
	issn = {1424-8220},
	doi = {10.3390/s16122017},
	abstract = {Micro-electro-mechanical-systems (MEMS) inertial measurement unit (IMU) outputs are corrupted by signiﬁcant sensor errors. The navigation errors of a MEMS-based inertial navigation system will therefore accumulate very quickly over time. This requires aiding from other sensors such as Global Navigation Satellite Systems (GNSS). However, it will still remain a signiﬁcant challenge in the presence of GNSS outages, which are typically in urban canopies. This paper proposed a rotary inertial navigation system (INS) to mitigate navigation errors caused by MEMS inertial sensor errors when external aiding information is not available. A rotary INS is an inertial navigator in which the IMU is installed on a rotation platform. Application of proper rotation schemes can effectively cancel and reduce sensor errors. A rotary INS has the potential to signiﬁcantly increase the time period that INS can bridge GNSS outages and make MEMS IMU possible to maintain longer autonomous navigation performance when there is no external aiding. In this research, several IMU rotation schemes (rotation about X-, Y- and Z-axes) are analyzed to mitigate the navigation errors caused by MEMS IMU sensor errors. As the IMU rotation induces additional sensor errors, a calibration process is proposed to remove the induced errors. Tests are further conducted with two MEMS IMUs installed on a tri-axial rotation table to verify the error mitigation by IMU rotations.},
	language = {en},
	number = {12},
	urldate = {2023-01-16},
	journal = {Sensors},
	author = {Du, Shuang and Sun, Wei and Gao, Yang},
	month = nov,
	year = {2016},
	pages = {2017},
	file = {Du et al. - 2016 - MEMS IMU Error Mitigation Using Rotation Modulatio.pdf:/home/alessandro/Zotero/storage/8SFT2LFS/Du et al. - 2016 - MEMS IMU Error Mitigation Using Rotation Modulatio.pdf:application/pdf},
}

@misc{solin_inertial_2018,
	title = {Inertial {Odometry} on {Handheld} {Smartphones}},
	abstract = {Building a complete inertial navigation system using the limited quality data provided by current smartphones has been regarded challenging, if not impossible. This paper shows that by careful crafting and accounting for the weak information in the sensor samples, smartphones are capable of pure inertial navigation. We present a probabilistic approach for orientation and use-case free inertial odometry, which is based on doubleintegrating rotated accelerations. The strength of the model is in learning additive and multiplicative IMU biases online. We are able to track the phone position, velocity, and pose in realtime and in a computationally lightweight fashion by solving the inference with an extended Kalman ﬁlter. The information fusion is completed with zero-velocity updates (if the phone remains stationary), altitude correction from barometric pressure readings (if available), and pseudo-updates constraining the momentary speed. We demonstrate our approach using an iPad and iPhone in several indoor dead-reckoning applications and in a measurement tool setup.},
	language = {en},
	urldate = {2023-01-16},
	publisher = {arXiv},
	author = {Solin, Arno and Cortes, Santiago and Rahtu, Esa and Kannala, Juho},
	month = jun,
	year = {2018},
	note = {arXiv:1703.00154 [cs, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Applications},
	file = {Solin et al. - 2018 - Inertial Odometry on Handheld Smartphones.pdf:/home/alessandro/Zotero/storage/F6I2HNSZ/Solin et al. - 2018 - Inertial Odometry on Handheld Smartphones.pdf:application/pdf},
}

@article{kok_using_2017,
	title = {Using {Inertial} {Sensors} for {Position} and {Orientation} {Estimation}},
	volume = {11},
	issn = {1932-8346, 1932-8354},
	doi = {10.1561/2000000094},
	abstract = {In recent years, microelectromechanical system (MEMS) inertial sensors (3D accelerometers and 3D gyroscopes) have become widely available due to their small size and low cost. Inertial sensor measurements are obtained at high sampling rates and can be integrated to obtain position and orientation information. These estimates are accurate on a short time scale, but suﬀer from integration drift over longer time scales. To overcome this issue, inertial sensors are typically combined with additional sensors and models. In this tutorial we focus on the signal processing aspects of position and orientation estimation using inertial sensors. We discuss diﬀerent modeling choices and a selected number of important algorithms. The algorithms include optimization-based smoothing and ﬁltering as well as computationally cheaper extended Kalman ﬁlter and complementary ﬁlter implementations. The quality of their estimates is illustrated using both experimental and simulated data.},
	language = {en},
	number = {1-2},
	urldate = {2023-01-16},
	journal = {Foundations and Trends® in Signal Processing},
	author = {Kok, Manon and Hol, Jeroen D. and Schön, Thomas B.},
	year = {2017},
	note = {arXiv:1704.06053 [cs]},
	keywords = {Computer Science - Robotics, Electrical Engineering and Systems Science - Systems and Control},
	pages = {1--153},
	file = {Kok et al. - 2017 - Using Inertial Sensors for Position and Orientatio.pdf:/home/alessandro/Zotero/storage/UPZY7NZE/Kok et al. - 2017 - Using Inertial Sensors for Position and Orientatio.pdf:application/pdf},
}

@misc{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	language = {en},
	urldate = {2023-01-17},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	note = {arXiv:1706.03762 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {Vaswani et al. - 2017 - Attention Is All You Need.pdf:/home/alessandro/Zotero/storage/DW4W2I6G/Vaswani et al. - 2017 - Attention Is All You Need.pdf:application/pdf},
}

@misc{wang_basic_2018,
	title = {A {Basic} {Introduction} to {Separable} {Convolutions}},
	abstract = {Explaining spatial separable convolutions, depthwise separable convolutions, and the use of 1x1 kernels in a simple manner.},
	language = {en},
	urldate = {2023-01-17},
	journal = {Medium},
	author = {Wang, Chi-Feng},
	month = aug,
	year = {2018},
	file = {Snapshot:/home/alessandro/Zotero/storage/87I4UC5T/a-basic-introduction-to-separable-convolutions-b99ec3102728.html:text/html},
}

@article{angarano_robust_2021,
	title = {Robust {Ultra}-wideband {Range} {Error} {Mitigation} with {Deep} {Learning} at the {Edge}},
	volume = {102},
	issn = {09521976},
	doi = {10.1016/j.engappai.2021.104278},
	abstract = {Ultra-wideband (UWB) is the state-of-the-art and most popular technology for wireless localization. Nevertheless, precise ranging and localization in non-line-of-sight (NLoS) conditions is still an open research topic. Indeed, multipath effects, reﬂections, refractions, and complexity of the indoor radio environment can easily introduce a positive bias in the ranging measurement, resulting in highly inaccurate and unsatisfactory position estimation. This article proposes an efﬁcient representation learning methodology that exploits the latest advancement in deep learning and graph optimization techniques to achieve effective ranging error mitigation at the edge. Channel Impulse Response (CIR) signals are directly exploited to extract high semantic features to estimate corrections in either NLoS or LoS conditions. Extensive experimentation with different settings and conﬁgurations has proved the effectiveness of our methodology and demonstrated the feasibility of a robust and low computational power UWB range error mitigation.},
	language = {en},
	urldate = {2023-01-18},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Angarano, Simone and Mazzia, Vittorio and Salvetti, Francesco and Fantin, Giovanni and Chiaberge, Marcello},
	month = jun,
	year = {2021},
	note = {arXiv:2011.14684 [cs, eess]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing},
	pages = {104278},
	file = {Angarano et al. - 2021 - Robust Ultra-wideband Range Error Mitigation with .pdf:/home/alessandro/Zotero/storage/WWSBKZN6/Angarano et al. - 2021 - Robust Ultra-wideband Range Error Mitigation with .pdf:application/pdf},
}

@misc{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	abstract = {Deeper neural networks are more difﬁcult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [41] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classiﬁcation task. We also present analysis on CIFAR-10 with 100 and 1000 layers.},
	language = {en},
	urldate = {2023-01-18},
	publisher = {arXiv},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv:1512.03385 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:/home/alessandro/Zotero/storage/8THUY86I/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:application/pdf},
}

@misc{hu_squeeze-and-excitation_2019,
	title = {Squeeze-and-{Excitation} {Networks}},
	abstract = {The central building block of convolutional neural networks (CNNs) is the convolution operator, which enables networks to construct informative features by fusing both spatial and channel-wise information within local receptive ﬁelds at each layer. A broad range of prior research has investigated the spatial component of this relationship, seeking to strengthen the representational power of a CNN by enhancing the quality of spatial encodings throughout its feature hierarchy. In this work, we focus instead on the channel relationship and propose a novel architectural unit, which we term the “Squeeze-and-Excitation” (SE) block, that adaptively recalibrates channel-wise feature responses by explicitly modelling interdependencies between channels. We show that these blocks can be stacked together to form SENet architectures that generalise extremely effectively across different datasets. We further demonstrate that SE blocks bring signiﬁcant improvements in performance for existing state-of-the-art CNNs at slight additional computational cost. Squeeze-and-Excitation Networks formed the foundation of our ILSVRC 2017 classiﬁcation submission which won ﬁrst place and reduced the top-5 error to 2.251\%, surpassing the winning entry of 2016 by a relative improvement of ∼25\%. Models and code are available at https://github.com/hujie-frank/SENet.},
	language = {en},
	urldate = {2023-01-18},
	publisher = {arXiv},
	author = {Hu, Jie and Shen, Li and Albanie, Samuel and Sun, Gang and Wu, Enhua},
	month = may,
	year = {2019},
	note = {arXiv:1709.01507 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Hu et al. - 2019 - Squeeze-and-Excitation Networks.pdf:/home/alessandro/Zotero/storage/HVPSZS55/Hu et al. - 2019 - Squeeze-and-Excitation Networks.pdf:application/pdf},
}

@misc{woo_cbam_2018,
	title = {{CBAM}: {Convolutional} {Block} {Attention} {Module}},
	shorttitle = {{CBAM}},
	abstract = {We propose Convolutional Block Attention Module (CBAM), a simple yet eﬀective attention module for feed-forward convolutional neural networks. Given an intermediate feature map, our module sequentially infers attention maps along two separate dimensions, channel and spatial, then the attention maps are multiplied to the input feature map for adaptive feature reﬁnement. Because CBAM is a lightweight and general module, it can be integrated into any CNN architectures seamlessly with negligible overheads and is end-to-end trainable along with base CNNs. We validate our CBAM through extensive experiments on ImageNet-1K, MS COCO detection, and VOC 2007 detection datasets. Our experiments show consistent improvements in classiﬁcation and detection performances with various models, demonstrating the wide applicability of CBAM. The code and models will be publicly available.},
	language = {en},
	urldate = {2023-01-18},
	publisher = {arXiv},
	author = {Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
	month = jul,
	year = {2018},
	note = {arXiv:1807.06521 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Woo et al. - 2018 - CBAM Convolutional Block Attention Module.pdf:/home/alessandro/Zotero/storage/Q82FKR2S/Woo et al. - 2018 - CBAM Convolutional Block Attention Module.pdf:application/pdf},
}

@misc{szegedy_going_2014,
	title = {Going {Deeper} with {Convolutions}},
	abstract = {We propose a deep convolutional neural network architecture codenamed Inception, which was responsible for setting the new state of the art for classiﬁcation and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classiﬁcation and detection.},
	language = {en},
	urldate = {2023-01-18},
	publisher = {arXiv},
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	month = sep,
	year = {2014},
	note = {arXiv:1409.4842 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Szegedy et al. - 2014 - Going Deeper with Convolutions.pdf:/home/alessandro/Zotero/storage/AI6IC7V5/Szegedy et al. - 2014 - Going Deeper with Convolutions.pdf:application/pdf},
}

@misc{szegedy_going_2014-1,
	title = {Going {Deeper} with {Convolutions}},
	abstract = {We propose a deep convolutional neural network architecture codenamed Inception, which was responsible for setting the new state of the art for classiﬁcation and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classiﬁcation and detection.},
	language = {en},
	urldate = {2023-01-18},
	publisher = {arXiv},
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	month = sep,
	year = {2014},
	note = {arXiv:1409.4842 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Szegedy et al. - 2014 - Going Deeper with Convolutions.pdf:/home/alessandro/Zotero/storage/SBMGFCBD/Szegedy et al. - 2014 - Going Deeper with Convolutions.pdf:application/pdf},
}

@article{jain_review_2014,
	title = {A review of online learning in supervised neural networks},
	volume = {25},
	issn = {0941-0643, 1433-3058},
	doi = {10.1007/s00521-013-1534-4},
	abstract = {Learning in neural networks can broadly be divided into two categories, viz., off-line (or batch) learning and online (or incremental) learning. In this paper, a review of a variety of supervised neural networks with online learning capabilities is presented. Speciﬁcally, we focus on articles published in main indexed journals in the past 10 years (2003–2013). We examine a number of key neural network architectures, which include feedforward neural networks, recurrent neural networks, fuzzy neural networks, and other related networks. How the online learning methodologies are incorporated into these networks is exempliﬁed, and how they are applied to solving problems in different domains is highlighted. A summary of the review that covers different network architectures and their applications is presented.},
	language = {en},
	number = {3-4},
	urldate = {2023-02-08},
	journal = {Neural Computing and Applications},
	author = {Jain, Lakhmi C. and Seera, Manjeevan and Lim, Chee Peng and Balasubramaniam, P.},
	month = sep,
	year = {2014},
	pages = {491--509},
	file = {Jain et al. - 2014 - A review of online learning in supervised neural n.pdf:/home/alessandro/Zotero/storage/AE8I67TS/Jain et al. - 2014 - A review of online learning in supervised neural n.pdf:application/pdf},
}

@article{wilson_general_2003,
	title = {The general inefficiency of batch training for gradient descent learning},
	volume = {16},
	issn = {08936080},
	doi = {10.1016/S0893-6080(03)00138-2},
	abstract = {Gradient descent training of neural networks can be done in either a batch or on-line manner. A widely held myth in the neural network community is that batch training is as fast or faster and/or more ‘correct’ than on-line training because it supposedly uses a better approximation of the true gradient for its weight updates. This paper explains why batch training is almost always slower than on-line training—often orders of magnitude slower—especially on large training sets. The main reason is due to the ability of on-line training to follow curves in the error surface throughout each epoch, which allows it to safely use a larger learning rate and thus converge with less iterations through the training data. Empirical results on a large (20,000-instance) speech recognition task and on 26 other learning tasks demonstrate that convergence can be reached signiﬁcantly faster using on-line training than batch training, with no apparent difference in accuracy.},
	language = {en},
	number = {10},
	urldate = {2023-02-09},
	journal = {Neural Networks},
	author = {Wilson, D.Randall and Martinez, Tony R.},
	month = dec,
	year = {2003},
	pages = {1429--1451},
	file = {Wilson and Martinez - 2003 - The general inefficiency of batch training for gra.pdf:/home/alessandro/Zotero/storage/S3REX2I5/Wilson and Martinez - 2003 - The general inefficiency of batch training for gra.pdf:application/pdf},
}

@article{perez-sanchez_review_2018,
	title = {A review of adaptive online learning for artificial neural networks},
	volume = {49},
	issn = {0269-2821, 1573-7462},
	doi = {10.1007/s10462-016-9526-2},
	abstract = {In real applications learning algorithms have to address several issues such as, huge amount of data, samples which arrive continuously and underlying data generation processes that evolve over time. Classical learning is not always appropriate to work in these environments since independent and indentically distributed data are assumed. Taking into account the requirements of the learning process, systems should be able to modify both their structures and their parameters. In this survey, our aim is to review the developed methodologies for adaptive learning with artiﬁcial neural networks, analyzing the strategies that have been traditionally applied over the years. We focus on sequential learning, the handling of the concept drift problem and the determination of the network structure. Despite the research in this ﬁeld, there are currently no standard methods to deal with these environments and diverse issues remain an open problem.},
	language = {en},
	number = {2},
	urldate = {2023-03-16},
	journal = {Artificial Intelligence Review},
	author = {Pérez-Sánchez, Beatriz and Fontenla-Romero, Oscar and Guijarro-Berdiñas, Bertha},
	month = feb,
	year = {2018},
	pages = {281--299},
	file = {Pérez-Sánchez et al. - 2018 - A review of adaptive online learning for artificia.pdf:/home/alessandro/Zotero/storage/S9X7HIGC/Pérez-Sánchez et al. - 2018 - A review of adaptive online learning for artificia.pdf:application/pdf},
}

@inproceedings{brossard_learning_2019,
	title = {Learning {Wheel} {Odometry} and {IMU} {Errors} for {Localization}},
	doi = {10.1109/ICRA.2019.8794237},
	abstract = {Odometry techniques are key to autonomous robot navigation, since they enable self-localization in the environment. However, designing a robust odometry system is particularly challenging when camera and LiDAR are uninformative or unavailable. In this paper, we leverage recent advances in deep learning and variational inference to correct dynamical and observation models for state-space systems. The methodology trains Gaussian processes on the residual between the original model and the ground truth, and is applied on publicly available datasets for robot navigation based on two wheel encoders, a fiber optic gyro, and an Inertial Measurement Unit (IMU). We also propose to build an Extended Kalman Filter (EKF) on the learned model using wheel speed sensors and the fiber optic gyro for state propagation, and the IMU to update the estimated state. Experimental results clearly demonstrate that the (learned) corrected models and EKF are more accurate than their original counterparts.},
	booktitle = {2019 {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Brossard, Martin and Bonnabel, Silvère},
	month = may,
	year = {2019},
	note = {ISSN: 2577-087X},
	keywords = {Mobile robots, Wheels, Gaussian process, Gaussian processes, Kalman filter, Kernel, odometry estimation, Sensors, Training, variational inference},
	pages = {291--297},
	file = {IEEE Xplore Abstract Record:/home/alessandro/Zotero/storage/CIXPF5IH/stamp.html:text/html;IEEE Xplore Full Text PDF:/home/alessandro/Zotero/storage/882435L6/BROSSARD and BONNABEL - 2019 - Learning Wheel Odometry and IMU Errors for Localiz.pdf:application/pdf},
}

@article{chen_deep_2021,
	title = {Deep {Neural} {Network} {Based} {Inertial} {Odometry} {Using} {Low}-{Cost} {Inertial} {Measurement} {Units}},
	volume = {20},
	issn = {1558-0660},
	doi = {10.1109/TMC.2019.2960780},
	abstract = {Inertial measurement units (IMUs) have emerged as an essential component in many of today's indoor navigation solutions due to their low cost and ease of use. However, despite many attempts for reducing the error growth of navigation systems based on commercial-grade inertial sensors, there is still no satisfactory solution that produces navigation estimates with long-time stability in widely differing conditions. This paper proposes to break the cycle of continuous integration used in traditional inertial algorithms, formulate it as an optimization problem, and explore the use of deep recurrent neural networks for estimating the displacement of a user over a specified time window. By training the deep neural network using inertial measurements and ground truth displacement data, it is possible to learn both motion characteristics and systematic error drift. As opposed to established context-aided inertial solutions, the proposed method is not dependent on either fixed sensor positions or periodic motion patterns. It can reconstruct accurate trajectories directly from raw inertial measurements, and predict the corresponding uncertainty to show model confidence. Extensive experimental evaluations demonstrate that the neural network produces position estimates with high accuracy for several different attachments, users, sensors, and motion types. As a particular demonstration of its flexibility, our deep inertial solutions can estimate trajectories for non-periodic motion, such as the shopping trolley tracking. Further more, it works in highly dynamic conditions, such as running, remaining extremely challenging for current techniques.},
	number = {4},
	journal = {IEEE Transactions on Mobile Computing},
	author = {Chen, Changhao and Lu, Chris Xiaoxuan and Wahlström, Johan and Markham, Andrew and Trigoni, Niki},
	month = apr,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Mobile Computing},
	keywords = {Trajectory, deep neural network, inertial indoor localization, inertial measurement units, Inertial navigation, learning from mobile sensor data, Neural networks, Pedestrian navigation, Robot sensing systems, Tracking},
	pages = {1351--1364},
	file = {IEEE Xplore Abstract Record:/home/alessandro/Zotero/storage/BQQJXHLZ/stamp.html:text/html;IEEE Xplore Full Text PDF:/home/alessandro/Zotero/storage/LWVUZUGZ/Chen et al. - 2021 - Deep Neural Network Based Inertial Odometry Using .pdf:application/pdf},
}

@article{atsuzawa_robot_nodate,
	title = {Robot {Navigation} in {Outdoor} {Environments} using {Odometry} and {Convolutional} {Neural} {Network}},
	abstract = {This paper proposes navigation algorithms for mobile robot through the odometry approach. The proposed algorithms include the odometry-based algorithm which uses only odometry calculated from robot motions, and the visual-assisted algorithm that applies visual data to assist in the navigation. The visual-assisted algorithm takes the convolutional neural network with regression setups in addition to the odometry. Goal of the visual-assisted algorithm help localize the robot in navigation by recognizing the scene using camera images. Navigation algorithms were tested for outdoor navigation tasks in the specified route. The experiments consist of two situations for navigation on the same route: with obstacles and without obstacles. The results stated that the navigation using only odometry is sufficient for navigation in the experimental environments. The visual-assisted algorithm proved to be an interesting alternative way of improvement for odometry, in which a large number of improvements and optimizations for visual techniques of outdoor robot navigation are still available to be studied in future works.},
	language = {en},
	author = {Atsuzawa, Keisuke and Nilwong, Sivapong and Hossain, Delowar and Kaneko, Shin-ichiro and Capi, Genci},
	file = {Atsuzawa et al. - Robot Navigation in Outdoor Environments using Odo.pdf:/home/alessandro/Zotero/storage/P4MECYDC/Atsuzawa et al. - Robot Navigation in Outdoor Environments using Odo.pdf:application/pdf},
}

@inproceedings{li_neural_2020,
	title = {A neural network approach to indoor mobile robot localization},
	doi = {10.1109/DCABES50732.2020.00026},
	abstract = {In order to improve the real-time performance and accuracy of localization for mobile robot in indoor environment, a neural network data fusion approach is proposed to eliminate the affection caused by errors from environment or measurements. In the approach, the odometry data are firstly obtained by calculating the collected encoder data through the Dead Reckoning (DR), then we fuse the odometry data and the lidar data by inputting them into a three-layer neural network. Experimental results show that the trained network improved the robot localization performance and its position accurate is within 6cm with good real time response.},
	booktitle = {2020 19th {International} {Symposium} on {Distributed} {Computing} and {Applications} for {Business} {Engineering} and {Science} ({DCABES})},
	author = {Li, Huijun and Mao, Ying and You, Wei and Ye, Bin and Zhou, Xinyi},
	month = oct,
	year = {2020},
	note = {ISSN: 2473-3636},
	keywords = {Mobile robots, Robot kinematics, Wheels, Sensors, Training, Biological neural networks, indoor localization, mobile robot, neural network, Neurons, odometry},
	pages = {66--69},
	file = {IEEE Xplore Full Text PDF:/home/alessandro/Zotero/storage/SF28MB7H/Li et al. - 2020 - A neural network approach to indoor mobile robot l.pdf:application/pdf},
}

@misc{chen_survey_2020,
	title = {A {Survey} on {Deep} {Learning} for {Localization} and {Mapping}: {Towards} the {Age} of {Spatial} {Machine} {Intelligence}},
	shorttitle = {A {Survey} on {Deep} {Learning} for {Localization} and {Mapping}},
	abstract = {Deep learning based localization and mapping has recently attracted signiﬁcant attention. Instead of creating hand-designed algorithms through exploitation of physical models or geometric theories, deep learning based solutions provide an alternative to solve the problem in a data-driven way. Beneﬁting from ever-increasing volumes of data and computational power, these methods are fast evolving into a new area that offers accurate and robust systems to track motion and estimate scenes and their structure for real-world applications. In this work, we provide a comprehensive survey, and propose a new taxonomy for localization and mapping using deep learning. We also discuss the limitations of current models, and indicate possible future directions. A wide range of topics are covered, from learning odometry estimation, mapping, to global localization and simultaneous localization and mapping (SLAM). We revisit the problem of perceiving self-motion and scene understanding with on-board sensors, and show how to solve it by integrating these modules into a prospective spatial machine intelligence system (SMIS). It is our hope that this work can connect emerging works from robotics, computer vision and machine learning communities, and serve as a guide for future researchers to apply deep learning to tackle localization and mapping problems.},
	language = {en},
	urldate = {2023-02-22},
	publisher = {arXiv},
	author = {Chen, Changhao and Wang, Bing and Lu, Chris Xiaoxuan and Trigoni, Niki and Markham, Andrew},
	month = jun,
	year = {2020},
	note = {arXiv:2006.12567 [cs, eess]},
	keywords = {Computer Science - Robotics, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Chen et al. - 2020 - A Survey on Deep Learning for Localization and Map.pdf:/home/alessandro/Zotero/storage/IXWJQEN8/Chen et al. - 2020 - A Survey on Deep Learning for Localization and Map.pdf:application/pdf},
}

@book{atsuzawa_robot_2019,
	title = {Robot {Navigation} in {Outdoor} {Environments} using {Odometry} and {Convolutional} {Neural} {Network}},
	abstract = {This paper proposes navigation algorithms for mobile robot through the odometry approach. The proposed algorithms include the odometry-based algorithm which uses only odometry calculated from robot motions, and the visual-assisted algorithm that applies visual data to assist in the navigation. The visual-assisted algorithm takes the convolutional neural network with regression setups in addition to the odometry. Goal of the visual-assisted algorithm help localize the robot in navigation by recognizing the scene using camera images. Navigation algorithms were tested for outdoor navigation tasks in the specified route. The experiments consist of two situations for navigation on the same route: with obstacles and without obstacles. The results stated that the navigation using only odometry is sufficient for navigation in the experimental environments. The visual-assisted algorithm proved to be an interesting alternative way of improvement for odometry, in which a large number of improvements and optimizations for visual techniques of outdoor robot navigation are still available to be studied in future works.},
	author = {Atsuzawa, Keisuke and Nilwong, Sivapong and Hossain, Delowar and Kaneko, Shi and Capi, Genci},
	month = mar,
	year = {2019},
	file = {Full Text PDF:/home/alessandro/Zotero/storage/BIIHRLX8/Atsuzawa et al. - 2019 - Robot Navigation in Outdoor Environments using Odo.pdf:application/pdf},
}

@inproceedings{angarano2022ultra,
  title={Ultra-Low-Power Range Error Mitigation for Ultra-Wideband Precise Localization},
  author={Angarano, Simone and Salvetti, Francesco and Mazzia, Vittorio and Fantin, Giovanni and Gandini, Dario and Chiaberge, Marcello},
  booktitle={Intelligent Computing: Proceedings of the 2022 Computing Conference, Volume 2},
  pages={814--824},
  year={2022},
  organization={Springer}
}

@article{peretroukhin_dpc-net_2018,
	title = {{DPC}-{Net}: {Deep} {Pose} {Correction} for {Visual} {Localization}},
	volume = {3},
	issn = {2377-3766, 2377-3774},
	shorttitle = {{DPC}-{Net}},
	doi = {10.1109/LRA.2017.2778765},
	abstract = {We present a novel method to fuse the power of deep networks with the computational efﬁciency of geometric and probabilistic localization algorithms. In contrast to other methods that completely replace a classical visual estimator with a deep network, we propose an approach that uses a convolutional neural network to learn difﬁcult-to-model corrections to the estimator from ground-truth training data. To this end, we derive a novel loss function for learning SE(3) corrections based on a matrix Lie groups approach, with a natural formulation for balancing translation and rotation errors. We use this loss to train a Deep Pose Correction network (DPC-Net) that predicts corrections for a particular estimator, sensor and environment. Using the KITTI odometry dataset, we demonstrate signiﬁcant improvements to the accuracy of a computationally-efﬁcient sparse stereo visual odometry pipeline, that render it as accurate as a modern computationally-intensive dense estimator. Further, we show how DPC-Net can be used to mitigate the effect of poorly calibrated lens distortion parameters.},
	language = {en},
	number = {3},
	urldate = {2023-03-08},
	journal = {IEEE Robotics and Automation Letters},
	author = {Peretroukhin, Valentin and Kelly, Jonathan},
	month = jul,
	year = {2018},
	note = {arXiv:1709.03128 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {2424--2431},
	file = {Peretroukhin and Kelly - 2018 - DPC-Net Deep Pose Correction for Visual Localizat.pdf:/home/alessandro/Zotero/storage/TLZ4QLAT/Peretroukhin and Kelly - 2018 - DPC-Net Deep Pose Correction for Visual Localizat.pdf:application/pdf},
}

@misc{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	abstract = {We introduce Adam, an algorithm for ﬁrst-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efﬁcient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the inﬁnity norm.},
	language = {en},
	urldate = {2023-03-09},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv:1412.6980 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:/home/alessandro/Zotero/storage/QQ3DKDRT/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf},
}

@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}


@incollection{chen_fine-tuning_2017,
	address = {Cham},
	title = {Fine-{Tuning} {Deep} {Neural} {Networks} in {Continuous} {Learning} {Scenarios}},
	volume = {10118},
	isbn = {978-3-319-54525-7 978-3-319-54526-4},
	abstract = {The revival of deep neural networks and the availability of ImageNet laid the foundation for recent success in highly complex recognition tasks. However, ImageNet does not cover all visual concepts of all possible application scenarios. Hence, application experts still record new data constantly and expect the data to be used upon its availability. In this paper, we follow this observation and apply the classical concept of ﬁne-tuning deep neural networks to scenarios where data from known or completely new classes is continuously added. Besides a straightforward realization of continuous ﬁne-tuning, we empirically analyze how computational burdens of training can be further reduced. Finally, we visualize how the network’s attention maps evolve over time which allows for visually investigating what the network learned during continuous ﬁne-tuning.},
	language = {en},
	urldate = {2023-02-09},
	booktitle = {Computer {Vision} – {ACCV} 2016 {Workshops}},
	publisher = {Springer International Publishing},
	author = {Käding, Christoph and Rodner, Erik and Freytag, Alexander and Denzler, Joachim},
	editor = {Chen, Chu-Song and Lu, Jiwen and Ma, Kai-Kuang},
	year = {2017},
	doi = {10.1007/978-3-319-54526-4_43},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {588--605},
	file = {Käding et al. - 2017 - Fine-Tuning Deep Neural Networks in Continuous Lea.pdf:/home/alessandro/Zotero/storage/JURHE7YB/Käding et al. - 2017 - Fine-Tuning Deep Neural Networks in Continuous Lea.pdf:application/pdf},
}