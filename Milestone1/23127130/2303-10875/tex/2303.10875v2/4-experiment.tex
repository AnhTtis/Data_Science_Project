\section{Experiments}

\begin{figure*}[htb]
    \centering
    \includegraphics[width = 1\linewidth]{fig/pareto.pdf}
    \caption{Comparison between existing models and HGNAS across various devices.}
    \label{fig:pareto}
    \vspace{-6pt}
\end{figure*}

\subsection{Experimental Setup}

\textbf{Baselines and datasets.}
For evaluating HGNAS, we consider three baselines: the popular point cloud processing model DGCNN~\cite{wang2019dynamic}, and two manually optimized methods on the DGCNN architecture~\cite{li2021towards, tailor2021towards}.
Our experiments are conducted on the public benchmark ModelNet40~\cite{wu20153d} for classification task with $1024$ points, and following the default hyperparameter settings in~\cite{tailor2021towards}. 
In addition, all the experimental and profiling results are developed on PyTorch Geometric (PyG) framework~\cite{Fey/Lenssen/2019}, taking the average results of $10$ runs.

\textbf{HGNAS settings.}
We assign $12$ positions for the GNN supernet to cover DGCNN architectures. 
During the design space exploration, the max iteration is set to $1000$, while the population size of $EA$ is set as $20$. 
Searching and training of HGNAS are both conducted on Nvidia V100 GPU. 
During function search and operation search, the number of GNN supernet training epochs is set as $50$ and $500$, respectively.

\textbf{Predictor settings.} 
The predictor is trained for $250$ epochs on $30$K randomly sampled architectures ($21$K for training and $9$K for validation) in our fine-grained design space, with labels obtained from measurement results on various edge devices.
Mean absolute percentage error (MAPE) was used as the loss function during training. 

\textbf{Edge devices.}
We employ four edge devices for comparing HGNAS and competitors: (1) Nvidia RTX3080, (2) Intel i7-8700K, (3) Jetson TX2 with $8$GB memory, (4) Raspberry Pi 3B+ with a Cortex-A5 processor and $1$GB memory. The latency and peak memory usage are obtained by deploying the GNN models on the above devices for inference using the PyG framework.

\subsection{Exploration by HGNAS}

The models designed by HGNAS are comprehensively compared with baselines in terms of model size, accuracy, latency, and peak memory. 

\subsubsection{Accuracy vs. Latency}

\begin{figure}[t]
    \centering
    \includegraphics[width = 0.81\linewidth]{fig/tradeoff.pdf}
    \caption{The trade-off between accuracy and speedup (compare to DGCNN) by scaling factor $\alpha$ and $\beta$.}
    \label{fig:tradeoff}
    \vspace{-3pt}
\end{figure}

Fig.~\ref{fig:pareto} reports the exploration results of HGNAS. The ideal solution is located in the top-left corner, indicated by a star. 
The green points named Device\_Acc (e.g. RTX\_Acc) are the optimal architectures designed for the targeted device by HGNAS with no loss of accuracy, while the red points named Device\_Fast allow $1\%$ accuracy loss.
The results show that HGNAS consistently maintains a better performance frontier (higher accuracy and lower latency) on various devices, which is guaranteed by the accurate hardware performance prediction of the candidate architecture during the search.
By setting the scaling factors, HGNAS can easily achieve the tradeoff between hardware efficiency and task accuracy.
Specifically, when $\alpha / \beta$ is smaller, the search results are more in favor of lower latency than higher accuracy.
Conversely, when $\alpha / \beta$ is larger, the search results tend to emphasize more on accuracy.

\begin{table}[t]
  \centering
  \renewcommand\arraystretch{1.1}
  \caption{Comparison of HGNAS and existing models, where OA and mAcc denote overall and balanced accuracy, respectively.}
  \resizebox{\linewidth}{!}{
    \begin{tabular}{c|c|c|c|c|c|c}
    \hline
    Device & Network &Size [MB] & OA   & mAcc & Latency [ms] & Mem. [MB]   \\
    \hline
    \multirow{5}[2]{*}{RTX3080} & DGCNN & 1.81 & 92.9 & 88.9 & 51.8 & 144.0   \\
         & \cite{li2021towards}& - &   92.6   &  89.6   &  (2.0$\times$$\uparrow$)   &    (51.9\%$\downarrow$)   \\
         & \cite{tailor2021towards}& -  &  93.2    &    90.6  & (2.5$\times$$\uparrow$)     &    -  \\
         & RTX-Acc & 1.61 & 92.8 & 90.1 & 8.6 (6.0$\times$$\uparrow$) &   19.1 (86.7\%$\downarrow$)   \\
         & \textbf{RTX-Fast} &  \textbf{1.50} & \textbf{92.1} & \textbf{88.5} & \textbf{4.9 (10.6$\times$$\uparrow$)}  &   \textbf{17.1 (88.1\%$\downarrow$)}  \\
    \hline
    \multirow{5}[2]{*}{i7-8700K} & DGCNN &  1.81 & 92.9 & 88.9 & 234.2 & 643.0      \\
         & \cite{li2021towards} & 2.33&   92.6   &  89.6   &  217.4 (1.1$\times$$\uparrow$)   &   581.3 (9.6\%$\downarrow$)   \\
         & \cite{tailor2021towards} & 1.80 &   93.2   &    90.6  &  92.4 (2.5$\times$$\uparrow$)   &   454.6 (29.3\%$\downarrow$)   \\
         & Intel-Acc  & 1.60 &   92.8   &  89.3    &   77.6 (3.0$\times$$\uparrow$)  & 423.7 (34.1\%$\downarrow$)     \\
         & \textbf{Intel-Fast} & \textbf{1.50} &   \textbf{92.5}   &   \textbf{88.8}   &    \textbf{23.1 (10.2$\times$$\uparrow$)}  &  \textbf{439.2 (31.6\%$\downarrow$)}    \\
    \hline
    \multirow{5}[2]{*}{Jetson TX2} & DGCNN & 1.81  & 92.9 & 88.9 & 270.4 &   145.0    \\
         & \cite{li2021towards} & 2.33 &   92.6   &  89.6   &  109.9 (2.5$\times$$\uparrow$)   &   36.2 (75.2\%$\downarrow$)   \\
         & \cite{tailor2021towards} & 1.81 &  93.2    &    90.6  & 206.4 (1.3$\times$$\uparrow$)    & 29.5 (79.7\%$\downarrow$)      \\
         & TX2-Acc & 1.60 & 92.9 & 89.7 & 50.5 (5.3$\times$$\uparrow$) &   19.0 (86.9\%$\downarrow$)    \\
         & \textbf{TX2-Fast} &  \textbf{1.48} & \textbf{92.2} & \textbf{88.7} & \textbf{36.3 (7.5$\times$$\uparrow$)} &   \textbf{17.1 (88.2\%$\downarrow$)}   \\
    \hline
    \multirow{5}[2]{*}{Raspberry Pi}& DGCNN & 1.81  & 92.9 & 88.9 & 4139.1 &   457.8    \\
         & \cite{li2021towards} & 2.33 &   92.6   &  89.6   &  3466.0 (1.2$\times$$\uparrow$)   &   354.3 (22.6\%$\downarrow$)   \\
         & \cite{tailor2021towards} & 1.81 &  93.2    &    90.6  & 1961.7 (2.1$\times$$\uparrow$)      &   271.1 (40.8\%$\downarrow$)    \\
         & Pi-Acc & 1.50 &   92.8   &   89.3   &  1165.3 (3.6$\times$$\uparrow$)    &   270.2 (41.0\%$\downarrow$)   \\
         & \textbf{Pi-Fast} & \textbf{1.36} &    \textbf{92.1}  &    \textbf{88.3} &   \textbf{557.6 (7.4$\times$$\uparrow$)}  &  \textbf{257.8 (43.7\%$\downarrow$)}  \\
    \hline
    \end{tabular}
  \label{tab:total}
  }
  \vspace{-3pt}
\end{table}

\subsubsection{HGNAS over Existing Graph Neural Architectures}

As shown in Tab.~\ref{tab:total}, compared with the baselines, GNN models designed by HGNAS have better hardware efficiency across all edge computing platforms with similar accuracy.
Such remarkable results are due to the hardware awareness incorporated during exploration.
Compared to DGCNN, HGNAS achieves up to $10.6\times$, $10.2\times$, $7.5\times$ and $7.4\times$ speedup, while reducing $88.1\%$, $31.6\%$, $88.2\%$, $43.7\%$ peak memory usage across four devices.
Moreover, HGNAS on the resource-constrained Jetson TX2 attains the same hardware efficiency as DGCNN on the high-performance Nvidia RTX3080 platform, and reduces peak memory usage by $86.8\%$.
The above results clearly demonstrate that flexibility offered by the fine-grained design space in HGNAS enables the pursuit of exceptional GNN computation efficiency on edge.
For a fairer comparison with manual optimizations in~\cite{li2021towards,tailor2021towards}, we adopt their reported accuracy, inference speedup, and memory reduction as the baseline on the GPU platform.
For other edge platforms, we reproduce these baselines based on PyG, due to the lack of pre-trained models and evaluation results.
These results show that GNN models designed by HGNAS have outperformed the manual optimizations across all platforms, benefiting from the accurate prediction of hardware performance during model explorations.

\subsection{Evaluation on GNN Predictor}

\begin{figure}[t]
    \centering
    \includegraphics[width = 1\linewidth]{fig/scatter.pdf}
    \caption{Predictor accuracy on various edge devices. The measured latency denotes the results collected from real edge devices.}
    \label{fig:sactter}
    \vspace{-3pt}
\end{figure}

As shown in Fig.~\ref{fig:sactter}, our proposed hardware performance predictor achieves high prediction accuracy across various platforms.
Specifically, the MAPE of prediction results on RTX3080, Intel i7-8700K, and Jetson TX2 is about $6\%$, while this metric is around $19\%$ on Raspberry Pi due to fluctuations in latency measurement results.
The accuracy of GNN predictor is more than 80\% across devices with a 10\% error bound.
In practice, the GNN predictor obtains better performances for models with a faster inference speed, which assists HGNAS in more efficient design exploration.

\subsection{Ablation Studies}

\begin{figure}[t]
    \centering
    \includegraphics[width = 1\linewidth]{fig/ablation.pdf}
    \caption{(a) Performance comparison between real-time- and predictor-based search. (b) Search time reduction with the multi-stage strategy.}
    \label{fig:ablation}
    \vspace{-3pt}
\end{figure}

\textbf{Predictor vs. real-time measurement.} 
Fig.~\ref{fig:ablation}(a) shows the HGNAS search process leveraging GNN predictor or real-time measurement on Intel CPU and Nvidia GPU platforms. 
The results demonstrate that the GNN predictor can effectively improve the search efficiency, as the models searched with both methods obtain similar performances.
In particular, our predictor will play a crucial role when the real-time measurement is impossible (e.g., on Jetson TX2 and Raspberry Pi).

\textbf{Multi-stage vs. one-stage search strategy.}
As shown in Fig.~\ref{fig:ablation}(b), exploring with the traditional one-stage search strategy would often be entangled in the huge fine-grained design space.
In contrast, the multi-stage hierarchical search strategy greatly accelerates the exploration process, with the capability of finding an optimal GNN architecture within a few GPU hours.

\subsection{Insight from GNNs Designed by HGNAS}

\begin{figure}[t]
    \centering
    \includegraphics[width = 1\linewidth]{fig/GNNdesigned.pdf}
    \caption{Visualization of GNN models designed by HGNAS.}
    \label{fig:GNNdesigned}
    \vspace{-3pt}
\end{figure}

Fig.~\ref{fig:GNNdesigned} provides the visualization of GNNs designed by HGNAS.
Note that the adjacent KNN operations will be merged during execution due to duplicate graph construction.
The results clearly show that the hardware-efficient architectures designed by HGNAS are closely associated with the characteristics of the target device,
which are consistent with the characterization of GNN models in \textbf{Observation \raisebox{-0.1em}{\ding[1.3]{174}}}. 
For example, as KNN occupies the majority of execution time on RTX3080 and Jetson TX2, GNN models designed for these devices would comprise fewer valid KNN operations.
Moreover, the optimal model for Intel CPU has fewer aggregate operations, and models designed for Raspberry Pi tend to simplify each operation.