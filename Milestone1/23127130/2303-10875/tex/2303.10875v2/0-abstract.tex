\begin{abstract}

Graph neural networks (GNNs) have emerged as a popular strategy for handling non-Euclidean data due to their state-of-the-art performance.
However, most of the current GNN model designs mainly focus on task accuracy, lacking in considering hardware resources limitation and real-time requirements of edge application scenarios.
Comprehensive profiling of typical GNN models indicates that their execution characteristics are significantly affected across different computing platforms, which demands hardware awareness for efficient GNN designs.
In this work, HGNAS is proposed as the first \underline{H}ardware-aware \underline{G}raph \underline{N}eural \underline{A}rchitecture \underline{S}earch framework targeting resource constraint edge devices.
By decoupling the GNN paradigm, HGNAS constructs a fine-grained design space and leverages an efficient multi-stage search strategy to explore optimal architectures within a few GPU hours.
Moreover, HGNAS achieves hardware awareness during the GNN architecture design by leveraging a hardware performance predictor, which could balance the GNN model accuracy and efficiency corresponding to the characteristics of targeted devices.
Experimental results show that HGNAS can achieve about $10.6\times$ speedup and $88.2\%$ peak memory reduction with a negligible accuracy loss compared to DGCNN on various edge devices, including Nvidia RTX3080, Jetson TX2, Intel i7-8700K and Raspberry Pi 3B+.
 
\begin{IEEEkeywords}
Hardware-Aware, Graph Neural Network, Neural Architecture Search, Edge Devices
\end{IEEEkeywords}



% Graph neural networks (GNNs) have achieved state-of-the-art performance on various applications in non-Euclidean domain. However, most GNN designs only focus on accuracy, neglecting resource and real-time requirements in edge application scenarios. In this work, we propose HGNAS, the first Hardware-aware Graph Neural Architecture Search framework targeting edge devices. With a GNN hardware performance predictor, HGNAS can efficiently design GNNs with balanced accuracy and efficiency on target devices. Results show that GNNs designed by HGNAS can achieve 7.4~10.6x speedup and up to 8.5x peak memory reduction with negligible accuracy loss compared to DGCNN on various platforms (Jetson TX2, Raspberry Pi, etc.).







\end{abstract}