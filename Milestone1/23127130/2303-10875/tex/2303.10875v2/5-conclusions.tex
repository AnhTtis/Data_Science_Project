\section{Conclusions}

In this paper, we propose HGNAS, the first hardware-aware framework to explore efficient graph neural architecture for edge devices.
HGNAS can automatically search for optimal GNN architectures that maximize both task accuracy and computation efficiency.
HGNAS leverages the multi-stage hierarchical search strategy and GNN hardware performance predictor to efficiently explore the fine-grained GNN design space.
Extensive experiments show that GNN models generated by HGNAS consistently outperform SOTA GNNs, achieving about $10.6\times$ speedup and $88.2\%$ peak memory reduction across various edge platforms.
We believe that HGNAS has made pivotal progress in bringing GNNs to real-life edge applications.