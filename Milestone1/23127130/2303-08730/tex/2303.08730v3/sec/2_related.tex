\section{Related Work}
\label{sec:related}


\noindent\textbf{Anomaly Detection.\quad}Modern methods for anomaly detection encompass two main paradigms: feature embedding-based approaches~\cite{roth2022patchcore,deng2022rd4ad,cohen2020spade,defard2021padim,lee2022cfa,li2021cutpaste,zhang2023prn,liu2023simplenet,tien2023rd++} and generative model-based approaches~\cite{gudovskiy2022cflow,yu2021fastflow,rudolph2022csflow,zavrtanik2021draem,ristea2022sspcab}.

Methods based on feature embeddings typically extract features of normal samples through a model pre-trained on ImageNet and then perform anomaly estimation. Built on top of extracted features, knowledge distillation~\cite{bergmann2020us,salehi2021kdad,deng2022rd4ad,tien2023rd++} estimate anomalies by comparing the differences in anomaly region features between teacher and student networks. There are 
 also extensive studies ~\cite{cohen2020spade,defard2021padim,liu2023simplenet,lee2022cfa} estimating anomalies by measuring the distance between an anomalous sample and the feature space of normal samples.

On the other hand, generative model-based methods do not require additional data. The core idea of generative model-based approaches is to implicitly or explicitly learn the feature distribution of the anomaly-free training data. Generative models based on VAE~\cite{dehaene2019gvae,liu2020avae} introduce a multidimensional normal distribution in the latent space for normal samples and then estimate the anomaly by the negative log-likelihood of the established distribution. GAN-based generative models~\cite{schlegl2017gan,akcay2018ganomaly,yu2020cyclegan,gong2019memgan,hou2021dividegan} estimate anomalies through a discriminative network that compares the query image with randomly sampled samples from the latent space of the generative network. Besides, several works introduce proxy tasks based on the generative paradigm, such as image inpainting~\cite{zavrtanik2021draem,song2021anoseg} and attribute prediction~\cite{ristea2022sspcab,ye2020attribute,ulutas2020attribute}.
Normalizing Flow-based methods~\cite{rudolph2021differnet,gudovskiy2022cflow,rudolph2022csflow,yu2021fastflow} combine deep feature embeddings and generative models. These methods estimate accurate data likelihoods in the latent space by learning bijective transformations between normal sample distributions and specified densities.  


\vspace{0.05in}
\noindent\textbf{Diffusion Model.\quad}Diffusion models~\cite{ho2020ddpm,song2020ddim,song2020scoregm}, a class of generative models inspired by non-equilibrium thermodynamics~\cite{sohl2015nonequilibrium}, define a paradigm in which the forward process slowly adds random noise to the data, and the reverse constructs the desired data samples from the noise. Recently, a wide range of diffusion-based perception applications has emerged, such as image generation~\cite{dhariwal2021diffusionbeatgans,ho2020ddpm,song2020scoregm,rombach2022ldm}, image segmentation~\cite{kim2022diffusionseg,baranchukdiffusionseg,graikos2022diffusionseg,brempong2022denoisingseg}, object detection~\cite{chen2023diffusiondet}, etc. 
AnoDDPM~\cite{wyatt2022anoddpm} tentatively explores the application of diffusion models to reconstruct medical lesions in the brain.  
However, it measures unhealthy outliers by squared error, leading to a high false positive rate. 
In addition, the iterative denoising approach employed in AnoDDPM leads to a notably slow inference speed and substantial computational cost.