\section{Introduction}
\label{sec:intro}


Similar to how human perception and visual systems work, anomaly detection involves identifying and locating anomalies with little to no prior knowledge about them. Over the past decades, anomaly detection has been a mission-critical task and a spotlight in the computer vision community due to its wide range of applications~\cite{zou2022spd,roth2022patchcore,zavrtanik2021draem,liu2023simplenet}.

\begin{figure}[t]
  \centering
  \includegraphics[width=1.0\linewidth]{figs/teaser.pdf}
  \caption{Anomaly detection and localization examples (Rows 1 to 4) on MVTec~\cite{bergmann2019mvtec} and VisA~\cite{zou2022spd}. Compared to the previous autoencoder-based approach DRAEM~\cite{zavrtanik2021draem}, \ie, Col. 3 \& 5, our proposed DiffusionAD exhibits superior reconstruction quality consisting of anomaly-free recovery of anomalous regions and fine-grained reconstruction of normal regions. Moreover, DiffusionAD locates the various anomaly regions more accurately (Col. 4 \& 6).}
  \label{fig:main idea}
  \vspace{-0.2cm}
\end{figure}

Given its importance, a great number of work has been devoted to anomaly detection~(AD). Due to the limited number of anomaly samples and the labor-intensive labeling process, detailed anomaly samples are not available for training. As a result, most recent studies on anomaly detection have been performed without prior information about the anomaly, \ie, unsupervised paradigm~\cite{cohen2020spade,roth2022patchcore,deng2022rd4ad}. 
These methods include, but are not limited to, feature embeddings and generative models.
Feature embedding-based methods ~\cite{roth2022patchcore,deng2022rd4ad,cohen2020spade,liu2023simplenet,tien2023rd++}  often suffer from degraded performance when the distribution of industrial images differs significantly from the one used for feature extraction, as they rely on pre-trained feature extractors on extra datasets such as ImageNet.
Generative model-based methods ~\cite{akcay2018ganomaly,dehaene2020FAVAE,zavrtanik2021draem,ristea2022sspcab,liu2023dmad} require no extra data and are widely applicable in various scenarios. These approaches generally use autoencoder-based networks (AEs), based on the assumption that after the encoder has compressed the input image into a low-dimensional representation, the decoder will reconstruct the anomalous region as normal~\cite{baur2019medicalae,zavrtanik2021draem,gong2019memgan}.
However, as shown in \cref{fig:main idea}, the AE-based paradigm has limitations: 
\Rmnum{1}) it may result in an \textbf{invariant reconstruction of abnormal regions} as the low-dimensional representation compressed from the original image still contains anomalous information, leading to false negative detection. 
\Rmnum{2}) AEs may perform a \textbf{coarse reconstruction of normal regions} due to limited restoration capability and introduce many false positives, especially on datasets with complex structures or textures. 

To address the aforementioned issues, we propose a novel generative model-based framework consisting of a reconstruction sub-network and a segmentation sub-network for anomaly detection named DiffusionAD. 
Firstly, we reframe the reconstruction process as a \emph{noise-to-norm} paradigm by introducing Gaussian noise to perturb the input image, followed by a denoising model to predict the added noise. 
We implement noise addition and denoising via the diffusion model~\cite{ho2020ddpm} due to its excellent density estimation capability and high sampling quality.
The proposed paradigm offers two advantages, as shown in the fifth column of \cref{fig:main idea}: 
\Rmnum{1}) The anomalous regions are treated as noise after losing their distinguishable features, which enables a \textbf{anomaly-free reconstruction} of the anomalous regions instead of an invariant one. %
\Rmnum{2}) It aims to cover the whole distribution of normal appearance~\cite{dhariwal2021diffusionbeatgans,ho2020ddpm}, which enables \textbf{fine-grained reconstruction} instead of a coarse reconstruction. 
After that, the segmentation sub-network predicts the pixel-wise anomaly score by exploiting the inconsistencies and commonalities between the input image and its reconstruction.

Equipped with the \emph{noise-to-norm} paradigm, DiffusionAD reconstructs more satisfactory results and thus improves the performance of anomaly detection.
However, as a class of likelihood-based models, diffusion models~\cite{song2020ddim,ho2020ddpm} generally require a large number of denoising iterations (typically about 50 to 1000 steps) to obtain optimal reconstructions from randomly sampled Gaussian noise, which is much slower than the real-time requirements in practical AD scenarios as shown in \cref{fig:p-f-curves}.  
To address this issue, we introduce a \emph{one-step denoising} paradigm for anomaly detection that employs a diffusion model to predict the noise once and then directly predict the reconstruction result. 
This paradigm achieves hundreds of times faster inference speed than the conventional iterative denoising paradigm while maintaining comparable recovery quality.

Nonetheless, anomaly detection consistently poses a non-trivial challenge, mainly due to the inherent diversity in the representation of anomalies. These variants encompass subtle anomalies as well as more conspicuous ones, which are characterized by larger anomaly regions or semantic alterations.
We observe that different types of anomalies require different noise scales for efficient recovery, especially within the one-step denoising paradigm.
Specifically, when anomalies are relatively minor, a one-step prediction stemming from a smaller noise scale proves more advantageous, yielding superior pixel-level restoration quality.
For more pronounced anomalies, the strategic application of a larger noise scale to perturb them followed by a one-step reconstruction results in enhanced semantic-level restoration quality. 
Therefore, we further introduce a \emph{norm-guided} paradigm that leverages direct predictions from larger noise scales to guide the reconstruction of smaller noise scales, leading to superior reconstruction outcomes.
Ultimately, DiffusionAD achieves SOTA anomaly detection performance and fast inference speed compared to other diffusion-free paradigms, as demonstrated in \cref{fig:p-f-curves}.
This truly fulfills the effectiveness and efficiency requirements of real-world application scenarios.

The main contributions of this paper are summarized in the following:
\begin{itemize}

\item We propose DiffusionAD, a novel pipeline that reconstructs the input image to an anomaly-free restoration via the \emph{noise-to-norm} paradigm and further predicts pixel-wise anomaly scores by exploiting inconsistencies and commonalities between them. 

\item We propose a \emph{one-step denoising} paradigm to significantly speed up the denoising process. Moreover, we propose the \emph{norm-guided paradigm} to achieve superior reconstruction results.

\item We conduct comprehensive experiments on four datasets to demonstrate that DiffusionAD significantly outperforms the previous SOTA by a large margin in terms of anomaly detection and localization.

\end{itemize}


\begin{figure}[t]
  \centering
  \includegraphics[width=1.0\linewidth]{figs/p-f-curves.pdf}
  \caption{\textbf{Comparison of different algorithms on image AUROC and inference speed.} The Y-axis indicates the anomaly detection capability. The X-axis refers to the inference speed. These results are verified on the VisA~\cite{zou2022spd} dataset.}
  \label{fig:p-f-curves}
\end{figure}