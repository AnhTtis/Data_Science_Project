\subsection{Proof of Lemma~\ref{lm:qnndynamics}}
\label{subsec:qnndynamics_proof}

\qnndynamics*
\begin{proof}
  For succinctness, we drop the dependency on $\varytheta$ when there are no ambiguity.
    The unitary $\mlvec{U}_{r:p}(\mlvec\theta)$  depends on $\mlvec\theta_{l}$
    for $l\geq r$:
  \begin{align}
      \frac{\partial \mlvec{U}_{r:p}}{\partial\theta_{l}}
    = \mlvec{U}_{l:p}(\mlvec{\theta}) (-\compI\generatorH{l}) \mlvec{U}_{r:l-1}(\mlvec\theta)
    = -\compI\mlvec{U}_{l:p}\generatorH{l}\mlvec{U}_{l:p}^{\dagger}\mlvec{U}_{r:p}.
  \end{align}
  Therefore for all $l \in [p]$
  \begin{align}
    \frac{\partial \mlvec{M}(\mlvec{\theta}(t))}{\partial \theta_{l}}
    &=
    \mlvec{U}_{0}^{\dagger}
      \left(\partialtheta{\mlvec{U}_{1:p}}{l} \right)^{\dagger}\qnnmeasure\mlvec{U}_{{1:p}}\mlvec{U}_{0} + \mlvec{U}_{0}^{\dagger}\mlvec{U}_{1:p}^{\dagger}\qnnmeasure\partialtheta{\mlvec{U}_{{1:p}}}{l}\mlvec{U}_{0}, \\
    &=
      \compI(\mlvec{U}_{0}^{\dagger}\mlvec{U}_{1:p}^{\dagger}\mlvec{U}_{l:p}\generatorH{l}\mlvec{U}_{l:p}^{\dagger}\qnnmeasure \mlvec{U}_{1:p}\mlvec{U}_{0}) - \compI(\mlvec{U}_{0}^{\dagger}\mlvec{U}_{1:p}^{\dagger}\qnnmeasure \mlvec{U}_{l:p}\generatorH{l}\mlvec{U}_{l:p}^{\dagger}\mlvec{U}_{1:p}\mlvec{U}_{0}), \\
    &= \compI[\tildeH{l},\mlvec{M}(\mlvec{\theta}(t))].
  \end{align}
  By the chain rule with matrix parameters, we have
  \begin{align}
    \partialtheta{L(\mlvec{\theta}(t))}{l} = \tr\big(\nabla_{\mlvec{M}}L \partialtheta{\mlvec{M}}{l} \big) = \compI\tr(\nabla_{\mlvec{M}}L[\tildeH{l},\mlvec{M}(\mlvec{\theta}(t))]).
  \end{align}
  Furthermore, due to the gradient flow dynamics,
  \begin{align}
    \diffT{\paramM} &= \sum_{l=1}^{p}\diffT{\theta_{l}}\partialtheta{\mlvec{M}(\mlvec{\theta}(t))}{l} = - \eta\sum_{l=1}^{p}\partialtheta{L(\mlvec{\theta}(t))}{l} \partialtheta{\mlvec{M}(\mlvec{\theta}(t))}{l},\\
    &= \eta \sum_{l=1}^{p}\tr(\nabla_{\mlvec{M}}L[\tildeH{l},\mlvec{M}(\mlvec{\theta}(t))])[\tildeH{l},\mlvec{M}(\mlvec{\theta}(t))].
  \end{align}
By plugging in
$\nabla_{\mlvec{M}}L = -\frac{1}{m}\sum_{j=1}^{m}r_{j}\mlvec{\rho}_{j}$, we show
that the parameterized measurement
$\mlvec{M}(\mlvec\theta)=\mlvec{U}^{\dagger}(\mlvec\theta)\qnnmeasure\mlvec{U}(\mlvec\theta)$
follows the dynamics
\begin{align}
d\mlvec{M}(\mlvec\theta(t))/dt=
\frac{\eta}{m} \sum_{l=1}^{p}\tr\big(\sum_{j=1}^{m}r_{j}\mlvec\rho_{j} \compI[\tildeH{l}, \mlvec{M}(\mlvec{\theta}(t))]\big) \compI[\tildeH{l}, \mlvec{M}(\mlvec{\theta}(t))].
\end{align}
By definition $r_{i}:=y_{i}-\hat{y}_{i}$, and
    \begin{align}
      \diffT{r_{i}} &= -\diffT{\tr(\mlvec\rho_{i}\mlvec{M}(\mlvec{\theta}(t)))} = -\tr\big(\mlvec\rho_{i}\diffT{\paramM}\big)\\
                    &=  -\frac{\eta}{m} \sum_{l=1}^{p}\tr\big(\sum_{j=1}^{m}r_{j}\mlvec\rho_{j} \compI[\tildeH{l}, \mlvec{M}(\mlvec{\theta}(t))]\big) \tr\big(\mlvec{\rho_{i}}\compI[\tildeH{l}, \mlvec{M}(\mlvec{\theta}(t))]\big)\\
                    &= -\frac{\eta}{m} \sum_{j=1}^{m} r_{j} \big(\tr\big(\mlvec{\rho}_{i}\compI[\tildeH{l}, \mlvec{M}(\mlvec{\theta}(t))]\big)\tr\big(\mlvec{\rho}_{j}\compI[\tildeH{l}, \mlvec{M}(\mlvec{\theta}(t))]\big)\big)\\
      &= -\frac{\eta}{m} \sum_{j=1}^{m} r_{j} \big(\tr\big(\compI[\paramM,\mlvec{\rho}_{i}]\tildeH{l}\big)\tr\big(\compI[\paramM,\mlvec{\rho}_{j}]\tildeH{l}\big)\big).
    \end{align}
    The last equality is due to the cyclicity of the trace operation. Making the
    identification
    $K_{ij}(\paramM) = \big(\tr\big(\compI[\paramM,\mlvec{\rho}_{i}]\tildeH{l}\big)\tr\big(\compI[\paramM,\mlvec{\rho}_{j}]\tildeH{l}\big)\big)$,
    we have
    \begin{align}
    \frac{d\varyr}{dt}=-\frac{\eta}{m}\mlvec{K}(\varyM)\varyr.
    \end{align}
  \end{proof}

\subsection{Proof of Theorem~\ref{thm:sublinear-convergence}}
\label{subsec:slow_proof}

\begin{proof}
The mean squared loss function $L(\varytheta)$ can be expressed as
$\frac{1}{2m}\mlvec{r}(\varytheta)^{T}\mlvec{r}(\varytheta)$. Using
Lemma~\ref{lm:qnndynamics}, the rate of convergence can be lower-bounded as
\begin{align}
  &\frac{1}{\varyl}\frac{d\varyl}{dt}\\
  =&\frac{1}{\varyr^{T}\varyr}\frac{d}{dt}\varyr^{T}\varyr, \\
  =&-\frac{2\eta}{m}\cdot\frac{\varyr^{T}\mlvec{K}(\varytheta)\varyr}{\varyr^{T}\varyr}, \\
  \geq& -\frac{2\eta}{m} \lambda_{\max}(\mlvec{K}(\varytheta)).
\end{align}
The positive semi-definiteness of $\varyK$ suggests that
$\lambda_{\max}(\varyK) \leq \tr(\varyK)$. We now proceed to bound
$\tr(\varyK)$. Since the eigenvalues of $\qnnmeasure$ and $\mlvec{M}(\mlvec\theta)$ all lie
in $\{\pm 1\}$, $\mlvec{M}(\varytheta)$ decomposes into the difference of to
projections, $\mlvec{\Pi}_{+}(\varytheta)$ and $\mlvec{\Pi}_{-}(\varytheta)$,
projecting onto the subspaces associated with eigenvalues of $+1$ and $-1$
respectively. When $\hat{y}_{j}$ approaches $y_{j}$, the input state
$\mlvec{\rho}_{j}$ lies almost completely in one of the eigen-subspaces, leading to a
vanishing commutator $\compI[\varyM, \mlvec{\rho}_{j}]$ such that
$K_{jj}(\varytheta)$ approaches zero:

Let $\mlvec{v}_{j}$ be the statevector representation of the pure state
$\mlvec{\rho}_{j}$, such that
$\mlvec{\rho}_{j}=\mlvec{v}_{j}\mlvec{v}_{j}^{\dagger}$. Vector $\mlvec{v}_{j}$
decomposes into the components within the positive and negative
eigen-subspaces of $\varyM$:
$\mlvec{v}_{j} = \mlvec{u}_{j}(\varytheta) + \mlvec{w}_{j}(\varytheta)$, where
$\mlvec{u}_{j}(\varytheta) = \mlvec{\Pi}_{+}(\varytheta)\mlvec{v}_{j}$ and $\mlvec{w}_{j}(\varytheta) = \mlvec{\Pi}_{-}(\varytheta)\mlvec{v}_{j}$.
In the following we omit the arguments $\varytheta$ in $\mlvec{u}_{j}$ and $\mlvec{v}_{j}$ for succinctness, but the time dependence is to be implicitly understood.
The commutator between the parameterized measurement and the input state can be
written as
$[\varyM, \mlvec{\rho}_{j}] = 2(\mlvec{u}_{j}\mlvec{w}_{j}^{\dagger}-\mlvec{w}_{j}\mlvec{u}_{j}^{\dagger})$. Therefore
  \begin{align}
    |\tr(\compI[\mlvec{M},\mlvec{\rho}_{j}]\tildeH{l})| \le 4\opnorm{\tildeH{l}}\norm{\mlvec{u}_{j}}\norm{\mlvec{w}_{j}}.
  \end{align}
  Assume without loss of generality that the $j$-{th} label $y_{j}$ is $+1$. Then
  $\norm{\mlvec{u}_{j}}^{2} + \norm{\mlvec{w}_{j}}^{2} = \norm{\mlvec{v}_{j}}^{2} = 1$
  by definition, and
  $\norm{\mlvec{u}_{j}}^{2} - \norm{\mlvec{w}_{j}}^{2} = \tr(\varyM\mlvec{\rho}_{j}) = y_{j} - r_{j} = 1 - r_{j}$.
  Then
  $\norm{\mlvec{w}_{j}}^{2} = |r_{j}|/2$, and
  $\norm{\mlvec{u}_{j}}^{2}\norm{\mlvec{w}_{j}}^{2} = (1-|r_{j}|/2)|r_{j}|/2$.

  Therefore we have,
  \begin{align}
    K_{jj}(\mlvec\theta(t))
    =&\sum_{l=1}^{p}\tr^{2}(\compI[\varyM, \mlvec{\rho}_{j}]\mlvec{H}_{l})\\
    \leq& 16\sum_{l=1}^{p}\opnorm{\mlvec{H}_{l}}^{2}\frac{|r_{j}|}{2}(1-\frac{|r_{j}|}{2})\\
    \leq& 16\sum_{l=1}^{p}\opnorm{\mlvec{H}_{l}}^{2}\frac{|r_{j}|}{2}
  \end{align}
  As a result
  \begin{align}
    & \frac{1}{L(\varytheta)}\frac{d\varyl}{dt}\\
    & \geq -\frac{2\eta}{m} \tr(\mlvec{K}(\varytheta))\ge -\frac{2\eta}{m} \sum_{i=1}^{m}K_{ii}\\
    & \geq -\frac{16\eta}{m}\sum_{l=1}^{p}\opnorm{\mlvec{H}_{l}}^{2}\sum_{i=1}^{m}|r_{j}|\\
    & \ge - 16\sqrt{2} \eta \sum_{l=1}^{p}\opnorm{\mlvec{H}_{l}}^{2} \sqrt{L(\varytheta)}\\
    & = - 16\sqrt{2} \eta \sum_{l=1}^{p}\opnorm{\generatorH{l}}^{2} \sqrt{L(\varytheta)}.
  \end{align}
  Here we use the fact that
  $\sum_{j=1}^{m}|r_{j}|\leq \sqrt{m} \sqrt{\varyr^{T}\varyr} = \sqrt{2m^{2}\varyl}$.

  The theorem statement follows directly by integrating the inequality above:
  \begin{align}
    &\varyl^{-\frac{3}{2}}d\varyl \geq -24 \eta\sum_{l=1}^{p}\opnorm{\generatorH{l}}^{2} dt\\
    \implies& -2 d(\varyl^{-1/2}) \geq -24\eta\sum_{l=1}^{p}\opnorm{\generatorH{l}}^{2}dt\\
    \implies& L(\mlvec\theta(T))^{-\frac{1}{2}}-L(\mlvec\theta(0))^{-\frac{1}{2}} \leq 12\eta\sum_{l=1}^{p}\opnorm{\generatorH{l}}^{2}T\\
    \implies& L(\mlvec\theta(T))^{-\frac{1}{2}}-c_{0}\leq c_{1}T
  \end{align}
\end{proof}
Note that the same ``at most sublinear convergence'' holds for a measurement
$\mathbf{M}_{0}$ such that $\mathbf{M}_0 = \boldsymbol{\Pi}_+-\boldsymbol{\Pi}_-$ and $\boldsymbol{\Pi}_+ + \boldsymbol{\Pi}_- + \boldsymbol{\Pi}_0 = \mathbf{I}$ for some non-zero projection $\boldsymbol{\Pi}_0$. The proof still holds with the following modification: define $s_j:=\|\mathbf{u}_j\|^2 + \|\mathbf{w}_j\|^2 \leq 1$, we have
 \begin{align*}
   &\|\mathbf{u}_j\|^2\cdot\|\mathbf{w}_j\|^2\\
   =& (\frac{s_j-y_j+r_j}{2})(\frac{s_j+y_j-r_j}{2})\\
   =& \frac{s_j^2-(y_j-r_j)^2}{4}\\
   \leq& \frac{1-(y_j-r_j)^2}{4}\\
   =& \frac{(1-y_j)^2+2y_jr_j - r^2_j}{4}\\
   =& \frac{y_jr_j}{2} - \frac{r^2_j}{4}\leq \frac{y_jr_j}{2}\\
   = & \frac{|r_j|}{2}
 \end{align*}
 The last equality follows from the fact that  $r_j \geq 0$ (resp. $r_j\leq 0$) for $y_j=1$ (resp. $y_j=-1$).


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main.tex"
%%% End:
