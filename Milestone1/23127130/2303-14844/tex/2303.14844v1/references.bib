@article{anschuetz2022quantum,
  title={Quantum variational algorithms are swamped with traps},
  author={Anschuetz, Eric R and Kiani, Bobak T},
  journal={Nature Communications},
  volume={13},
  number={1},
  pages={1--10},
  year={2022},
  publisher={Nature Publishing Group}
}
@article{daley2022practical,
  title={Practical quantum advantage in quantum simulation},
  author={Daley, Andrew J and Bloch, Immanuel and Kokail, Christian and Flannigan, Stuart and Pearson, Natalie and Troyer, Matthias and Zoller, Peter},
  journal={Nature},
  volume={607},
  number={7920},
  pages={667--676},
  year={2022},
  publisher={Nature Publishing Group}
}
@article{preskill2018quantum,
  title={Quantum computing in the NISQ era and beyond},
  author={Preskill, John},
  journal={Quantum},
  volume={2},
  pages={79},
  year={2018},
  publisher={Verein zur F{\"o}rderung des Open Access Publizierens in den Quantenwissenschaften}
}

@article{anschuetz2022interpretable,
  title={Interpretable Quantum Advantage in Neural Sequence Learning},
  author={Anschuetz, Eric R and Hu, Hong-Ye and Huang, Jin-Long and Gao, Xun},
  journal={arXiv preprint arXiv:2209.14353},
  year={2022}
}
@book{horn2012matrix,
  title={Matrix analysis},
  author={Horn, Roger A and Johnson, Charles R},
  year={2012},
  publisher={Cambridge university press}
}
@article{canatar2021spectral,
  title={Spectral bias and task-model alignment explain generalization in kernel regression and infinitely wide neural networks},
  author={Canatar, Abdulkadir and Bordelon, Blake and Pehlevan, Cengiz},
  journal={Nature communications},
  volume={12},
  number={1},
  pages={1--12},
  year={2021},
  publisher={Nature Publishing Group}
}
@article{chen2020generalized,
  title={A generalized neural tangent kernel analysis for two-layer neural networks},
  author={Chen, Zixiang and Cao, Yuan and Gu, Quanquan and Zhang, Tong},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13363--13373},
  year={2020}
}
@article{bietti2019inductive,
  title={On the inductive bias of neural tangent kernels},
  author={Bietti, Alberto and Mairal, Julien},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}
@article{ourvqe2022,
  title={A Convergence Theory for Over-parameterized Variational Quantum Eigensolvers},
  author={Xuchen You and Shouvanik Chakrabarti and Xiaodi Wu},
  journal={arXiv:2205.12481},
  year={2022}
}

@article{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@inproceedings{arora2019exact,
 author = {Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Russ R and Wang, Ruosong},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {On Exact Computation with an Infinitely Wide Neural Net},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/dbc4d84bfcfe2284ba11beffb853a8c4-Paper.pdf},
 volume = {32},
 year = {2019}
}

@InProceedings{allenzhu2019convergence,
  title = 	 {A Convergence Theory for Deep Learning via Over-Parameterization},
  author =       {Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {242--252},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/allen-zhu19a/allen-zhu19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/allen-zhu19a.html},
  abstract = 	 {Deep neural networks (DNNs) have demonstrated dominating performance in many fields; since AlexNet, networks used in practice are going wider and deeper. On the theoretical side, a long line of works have been focusing on why we can train neural networks when there is only one hidden layer. The theory of multi-layer networks remains unsettled. In this work, we prove simple algorithms such as stochastic gradient descent (SGD) can find Global Minima on the training objective of DNNs in Polynomial Time. We only make two assumptions: the inputs do not degenerate and the network is over-parameterized. The latter means the number of hidden neurons is sufficiently large: polynomial in L, the number of DNN layers and in n, the number of training samples. As concrete examples, starting from randomly initialized weights, we show that SGD attains 100% training accuracy in classification tasks, or minimizes regression loss in linear convergence speed eps &nbsp; e^{-T}, with running time polynomial in n and L. Our theory applies to the widely-used but non-smooth ReLU activation, and to any smooth and possibly non-convex loss functions. In terms of network architectures, our theory at least applies to fully-connected neural networks, convolutional neural networks (CNN), and residual neural networks (ResNet).}
}

@article{oymak2020toward,
  title={Toward moderate overparameterization: Global convergence guarantees for training shallow neural networks},
  author={Oymak, Samet and Soltanolkotabi, Mahdi},
  journal={IEEE Journal on Selected Areas in Information Theory},
  volume={1},
  number={1},
  pages={84--105},
  year={2020},
  publisher={IEEE}
}
 @article{liu2022analytic,
  title={An analytic theory for the dynamics of wide quantum neural networks},
  author={Liu, Junyu and Najafi, Khadijeh and Sharma, Kunal and Tacchino, Francesco and Jiang, Liang and Mezzacapo, Antonio},
  journal={arXiv preprint arXiv:2203.16711},
  year={2022}
}

@article{abedi2022quantum,
  title={Quantum Lazy Training},
  author={Abedi, Erfan and Beigi, Salman and Taghavi, Leila},
  journal={arXiv preprint arXiv:2202.08232},
  year={2022}
}

@article{huang2021power,
  doi = {10.1038/s41467-021-22539-9},
  url = {https://doi.org/10.1038%2Fs41467-021-22539-9},
  year = 2021,
  month = {may},
  publisher = {Springer Science and Business Media {LLC}},
  volume = {12},
  number = {1},
  author = {Hsin-Yuan Huang and Michael Broughton and Masoud Mohseni and Ryan Babbush and Sergio Boixo and Hartmut Neven and Jarrod R. McClean},
  title = {Power of data in quantum machine learning},
  journal = {Nature Communications}
}

% Dumping the whole bib file from VQE for convenience

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%% concentration ineq %%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{tropp2015introduction,
  title={An introduction to matrix concentration inequalities},
  author={Tropp, Joel A},
  journal={arXiv preprint arXiv:1501.01571},
  year={2015}
}

@article{tropp2012user,
  title={User-friendly tail bounds for sums of random matrices},
  author={Tropp, Joel A},
  journal={Foundations of computational mathematics},
  volume={12},
  number={4},
  pages={389--434},
  year={2012},
  publisher={Springer}
}
@article{vershynin2010introduction,
  title={Introduction to the non-asymptotic analysis of random matrices},
  author={Vershynin, Roman},
  journal={arXiv preprint arXiv:1011.3027},
  year={2010}
}
@book{vershynin2018high,
  title={High-dimensional probability: An introduction with applications in data science},
  author={Vershynin, Roman},
  volume={47},
  year={2018},
  publisher={Cambridge university press}
}
@article{viens2007supremum,
  title={Supremum concentration inequality and modulus of continuity for sub-nth chaos processes},
  author={Viens, Frederi G and Vizcarra, Andrew B},
  journal={Journal of Functional Analysis},
  volume={248},
  number={1},
  pages={1--26},
  year={2007},
  publisher={Elsevier}
}

@article{baraud2010bernstein,
  title={A Bernstein-type inequality for suprema of random processes with applications to model selection in non-Gaussian regression},
  author={Baraud, Yannick},
  journal={Bernoulli},
  volume={16},
  number={4},
  pages={1064--1085},
  year={2010},
  publisher={Bernoulli Society for Mathematical Statistics and Probability}
}
@article{baraud2009bernstein,
  title={A Bernstein-type inequality for suprema of random processes with an application to statistics},
  author={Baraud, Yannick},
  journal={arXiv preprint arXiv:0904.3295},
  year={2009}
}

@article{arbel2020strict,
  title={On strict sub-Gaussianity, optimal proxy variance and symmetry for bounded random variables},
  author={Arbel, Julyan and Marchal, Olivier and Nguyen, Hien D},
  journal={ESAIM: Probability and Statistics},
  volume={24},
  pages={39--55},
  year={2020},
  publisher={EDP Sciences}
}

@article{mackey2014matrix,
  title={Matrix concentration inequalities via the method of exchangeable pairs},
  author={Mackey, Lester and Jordan, Michael I and Chen, Richard Y and Farrell, Brendan and Tropp, Joel A},
  journal={The Annals of Probability},
  volume={42},
  number={3},
  pages={906--945},
  year={2014},
  publisher={Institute of Mathematical Statistics}
}
@article{paulin2013deriving,
  title={Deriving matrix concentration inequalities from kernel couplings},
  author={Paulin, Daniel and Mackey, Lester and Tropp, Joel A},
  journal={arXiv preprint arXiv:1305.0612},
  year={2013}
}

% Classical overparameterization
@inproceedings{chizat2018lazy,
 author = {Chizat, Lenaic and Oyallon, Edouard and Bach, Francis},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {On Lazy Training in Differentiable Programming},
 url = {https://proceedings.neurips.cc/paper/2019/file/ae614c557843b1df326cb29c57225459-Paper.pdf},
 volume = {32},
 year = {2019}
}

% Classical papers on PCA
@inproceedings{xu2018convergence,
  title     = {Convergence Analysis of Gradient Descent for Eigenvector Computation},
  author    = {Zhiqiang Xu and Xin Cao and Xin Gao},
  booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
               Artificial Intelligence, {IJCAI-18}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  pages     = {2933--2939},
  year      = {2018},
  month     = {7},
  doi       = {10.24963/ijcai.2018/407},
  url       = {https://doi.org/10.24963/ijcai.2018/407},
}
% Lie Group
@article{brandao2016local,
  title={Local random quantum circuits are approximate polynomial-designs},
  author={Brandao, Fernando GSL and Harrow, Aram W and Horodecki, Micha{\l}},
  journal={Communications in Mathematical Physics},
  volume={346},
  number={2},
  pages={397--434},
  year={2016},
  publisher={Springer}
}
@article{varju2012random,
  title={Random walks in compact groups},
  author={Varj{\'u}, P{\'e}ter P{\'a}l},
  journal={arXiv preprint arXiv:1209.1745},
  year={2012}
}
@incollection{bourgain2017random,
  title={On random walks in large compact Lie groups},
  author={Bourgain, Jean},
  booktitle={Geometric Aspects of Functional Analysis},
  pages={55--63},
  year={2017},
  publisher={Springer}
}
@article{romero2018strategies,
  title={Strategies for quantum computing molecular energies using the unitary coupled cluster ansatz},
  author={Romero, Jonathan and Babbush, Ryan and McClean, Jarrod R and Hempel, Cornelius and Love, Peter J and Aspuru-Guzik, Al{\'a}n},
  journal={Quantum Science and Technology},
  volume={4},
  number={1},
  pages={014008},
  year={2018},
  publisher={IOP Publishing}
}

% Barren platuea
@article{grant2019initialization,
  title={An initialization strategy for addressing barren plateaus in parametrized quantum circuits},
  author={Grant, Edward and Wossnig, Leonard and Ostaszewski, Mateusz and Benedetti, Marcello},
  journal={Quantum},
  volume={3},
  pages={214},
  year={2019},
  publisher={Verein zur F{\"o}rderung des Open Access Publizierens in den Quantenwissenschaften}
}

@article{Patti2020,
abstract = {Hybrid quantum-classical variational algorithms are one of the most propitious implementations of quantum computing on near-term devices, offering classical machine learning support to quantum scale solution spaces. However, numerous studies have demonstrated that the rate at which this space grows in qubit number could preclude learning in deep quantum circuits, a phenomenon known as barren plateaus. In this work, we implicate random entanglement as the source of barren plateaus and characterize them in terms of many-body entanglement dynamics, detailing their formation as a function of system size, circuit depth, and circuit connectivity. Using this comprehension of entanglement, we propose and demonstrate a number of barren plateau ameliorating techniques, including: initial partitioning of cost function and non-cost function registers, meta-learning of low-entanglement circuit initializations, selective inter-register interaction, entanglement regularization, the addition of Langevin noise, and rotation into preferred cost function eigenbases. We find that entanglement limiting, both automatic and engineered, is a hallmark of high-accuracy training, and emphasize that as learning is an iterative organization process while barren plateaus are a consequence of randomization, they are not necessarily unavoidable or inescapable. Our work forms both a theoretical characterization and a practical toolbox; first defining barren plateaus in terms of random entanglement and then employing this expertise to strategically combat them.},
archivePrefix = {arXiv},
arxivId = {2012.12658},
author = {Patti, Taylor L and Najafi, Khadijeh and Gao, Xun and Yelin, Susanne F},
eprint = {2012.12658},
file = {:home/xucheny/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Patti et al. - Unknown - Entanglement Devised Barren Plateau Mitigation.pdf:pdf},
title = {{Entanglement Devised Barren Plateau Mitigation}},
url = {http://arxiv.org/abs/2012.12658},
year = {2020}
}

@misc{Zhou2018,
abstract = {The Quantum Approximate Optimization Algorithm (QAOA) is a hybrid quantum-classical variational algorithm designed to tackle combinatorial optimization problems. Despite its promise for near-term quantum applications, not much is currently understood about QAOA's performance beyond its lowest-depth variant. An essential but missing ingredient for understanding and deploying QAOA is a constructive approach to carry out the outer-loop classical optimization. We provide an in-depth study of the performance of QAOA on MaxCut problems by developing an efficient parameter-optimization procedure and revealing its ability to exploit non-adiabatic operations. Building on observed patterns in optimal parameters, we propose heuristic strategies for initializing optimizations to find quasi-optimal p-level QAOA parameters in O(poly(p)) time, whereas the standard strategy of random initialization requires 2O(p) optimization runs to achieve similar performance. We then benchmark QAOA and compare it with quantum annealing, especially on difficult instances where adiabatic quantum annealing fails due to small spectral gaps. The comparison reveals that QAOA can learn via optimization to utilize non-adiabatic mechanisms to circumvent the challenges associated with vanishing spectral gaps. Finally, we provide a realistic resource analysis on the experimental implementation of QAOA. When quantum fluctuations in measurements are accounted for, we illustrate that optimization will be important only for problem sizes beyond numerical simulations, but accessible on near-term devices. We propose a feasible implementation of large MaxCut problems with a few hundred vertices in a system of 2D neutral atoms, reaching the regime to challenge the best classical algorithms.},
archivePrefix = {arXiv},
arxivId = {1812.01041v2},
author = {Zhou, Leo and Wang, Sheng Tao and Choi, Soonwon and Pichler, Hannes and Lukin, Mikhail D},
booktitle = {arXiv},
eprint = {1812.01041v2},
file = {:home/xucheny/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2018 - Quantum Approximate Optimization Algorithm Performance, Mechanism, and Implementation on Near-Term Devices(2).pdf:pdf},
issn = {23318422},
title = {{Quantum Approximate Optimization Algorithm: Performance, Mechanism, and Implementation on Near-Term Devices}},
year = {2018}
}
@techreport{Skolik,
abstract = {With the increased focus on quantum circuit learning for near-term applications on quantum devices, in conjunction with unique challenges presented by cost function landscapes of parametrized quantum circuits, strategies for effective training are becoming increasingly important. In order to ameliorate some of these challenges, we investigate a layerwise learning strategy for parametrized quantum circuits. The circuit depth is incrementally grown during optimization, and only subsets of parameters are updated in each training step. We show that when considering sampling noise, this strategy can help avoid the problem of barren plateaus of the error surface due to the low depth of circuits, low number of parameters trained in one step, and larger magnitude of gradients compared to training the full circuit. These properties make our algorithm preferable for execution on noisy intermediate-scale quantum devices. We demonstrate our approach on an image-classification task on handwritten digits, and show that layerwise learning attains an 8{\%} lower generalization error on average in comparison to standard learning schemes for training quantum circuits of the same size. Additionally, the percentage of runs that reach lower test errors is up to 40{\%} larger compared to training the full circuit, which is susceptible to creeping onto a plateau during training.},
archivePrefix = {arXiv},
arxivId = {2006.14904v1},
author = {Skolik, Andrea and Mcclean, Jarrod R and Mohseni, Masoud and {Van Der Smagt}, Patrick and Leib, Martin},
eprint = {2006.14904v1},
file = {::},
keywords = {Quantum neural network,gate model quantum computing,parametrized quantum circuit,quantum machine learning},
title = {{Layerwise learning for quantum neural networks}},
year={2020}
}
@techreport{Verdon,
abstract = {Quantum Neural Networks (QNNs) are a promising variational learning paradigm with applications to near-term quantum processors, however they still face some significant challenges. One such challenge is finding good parameter initialization heuristics that ensure rapid and consistent convergence to local minima of the parameterized quantum circuit landscape. In this work, we train classical neural networks to assist in the quantum learning process, also know as meta-learning, to rapidly find approximate optima in the parameter landscape for several classes of quantum varia-tional algorithms. Specifically, we train classical recurrent neural networks to find approximately optimal parameters within a small number of queries of the cost function for the Quantum Approximate Optimization Algorithm (QAOA) for MaxCut, QAOA for Sherrington-Kirkpatrick Ising model, and for a Variational Quantum Eigensolver for the Hubbard model. By initializing other optimizers at parameter values suggested by the classical neural network, we demonstrate a significant improvement in the total number of optimization iterations required to reach a given accuracy. We further demonstrate that the optimization strategies learned by the neural network generalize well across a range of problem instance sizes. This opens up the possibility of training on small, classically simulatable problem instances, in order to initialize larger, classically intractably simulat-able problem instances on quantum devices, thereby significantly reducing the number of required quantum-classical optimization iterations.},
archivePrefix = {arXiv},
arxivId = {1907.05415v1},
author = {Verdon, Guillaume and Broughton, Michael and Mcclean, Jarrod R and Sung, Kevin J and Babbush, Ryan and Jiang, Zhang and Neven, Hartmut and Mohseni, Masoud},
eprint = {1907.05415v1},
file = {::},
title = {{Learning to learn with quantum neural networks via classical neural networks}},
year={2019}
}
@techreport{Volkoff,
abstract = {Scaling of variational quantum algorithms to large problem sizes requires efficient optimization of random parameterized quantum circuits. For such circuits with uncorrelated parameters, the presence of exponentially vanishing gradients in cost function landscapes is an obstacle to optimization by gradient descent methods. In this work, we prove that reducing the dimensionality of the parameter space by utilizing circuit modules containing spatially or temporally correlated gate layers can allow one to circumvent the vanishing gradient phenomenon. Examples are drawn from random separable circuits and asymptotically optimal variational versions of Grover's algorithm based on the quantum alternating operator ansatz (QAOA). In the latter scenario, our bounds on cost function variation imply a transition between vanishing gradients and efficient trainability as the number of layers is increased toward O(2 n/2), the optimal oracle complexity of quantum unstructured search.},
archivePrefix = {arXiv},
arxivId = {2005.12200v2},
author = {Volkoff, Tyler and Coles, Patrick J},
eprint = {2005.12200v2},
file = {::},
title = {{Large gradients via correlation in random parameterized quantum circuits}},
year={2021}
}
@article{Cerezo2020,
abstract = {Applications such as simulating large quantum systems or solving large-scale linear algebra problems are immensely challenging for classical computers due their extremely high computational cost. Quantum computers promise to unlock these applications, although fault-tolerant quantum computers will likely not be available for several years. Currently available quantum devices have serious constraints, including limited qubit numbers and noise processes that limit circuit depth. Variational Quantum Algorithms (VQAs), which employ a classical optimizer to train a parametrized quantum circuit, have emerged as a leading strategy to address these constraints. VQAs have now been proposed for essentially all applications that researchers have envisioned for quantum computers, and they appear to the best hope for obtaining quantum advantage. Nevertheless, challenges remain including the trainability, accuracy, and efficiency of VQAs. In this review article we present an overview of the field of VQAs. Furthermore, we discuss strategies to overcome their challenges as well as the exciting prospects for using them as a means to obtain quantum advantage.},
archivePrefix = {arXiv},
arxivId = {2012.09265},
author = {Cerezo, M and Arrasmith, Andrew and Babbush, Ryan and Benjamin, Simon C and Endo, Suguru and Fujii, Keisuke and McClean, Jarrod R. and Mitarai, Kosuke and Yuan, Xiao and Cincio, Lukasz and Coles, Patrick J},
eprint = {2012.09265},
file = {:home/xucheny/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cerezo et al. - 2020 - Variational Quantum Algorithms.pdf:pdf},
issn = {23318422},
title = {{Variational Quantum Algorithms}},
url = {http://arxiv.org/abs/2012.09265},
year = {2020}
}
@misc{Wiersema2020,
abstract = {Quantum variational algorithms are one of the most promising applications of near-term quantum computers; however, recent studies have demonstrated that unless the variational quantum circuits are configured in a problem-specific manner, optimization of such circuits will most likely fail. In this paper, we focus on a special family of quantum circuits called the Hamiltonian Variational Ansatz (HVA), which takes inspiration from the quantum approximation optimization algorithm and adiabatic quantum computation. Through the study of its entanglement spectrum and energy gradient statistics, we find that HVA exhibits favorable structural properties such as mild or entirely absent barren plateaus and a restricted state space that eases their optimization in comparison to the well-studied “hardware-efficient ansatz.” We also numerically observe that the optimization landscape of HVA becomes almost trap free, i.e., no sub-optimal minima, when the ansatz is overparameterized. We observe a size-dependent “computational phase transition as the number of layers in the HVA circuit is increased where the optimization crosses over from a hard to an easy region in terms of the quality of the approximations and speed of convergence to a good solution. In contrast with the analogous transitions observed in the learning of random unitaries which occur at a number of layers that grows exponentially with the number of qubits, our Variational Quantum Eigensolver experiments suggest that the threshold to achieve the over-parameterization phenomenon scales at most polynomially in the number of qubits for the transverse field Ising and XXZ models. Lastly, as a demonstration of its entangling power and effectiveness, we show that HVA can find accurate approximations to the ground states of a modified Haldane-Shastry Hamiltonian on a ring, which has long-range interactions and has a power-law entanglement scaling.},
archivePrefix = {arXiv},
arxivId = {2008.02941},
author = {Wiersema, Roeland and Zhou, Cunlu and de Sereville, Yvette and Carrasquilla, Juan Felipe and Kim, Yong Baek and Yuen, Henry},
booktitle = {arXiv},
doi = {10.1103/prxquantum.1.020319},
eprint = {2008.02941},
file = {:home/xucheny/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wiersema et al. - 2020 - Exploring entanglement and optimization within the Hamiltonian Variational Ansatz.pdf:pdf},
issn = {23318422},
keywords = {Barren plateau,Hamiltonian variational ansatz,Initialization,Over-parameterization,Quantum entanglement,Variational quantum eigensolver},
month = {aug},
publisher = {arXiv},
title = {{Exploring entanglement and optimization within the Hamiltonian variational Ansatz}},
url = {http://arxiv.org/abs/2008.02941 http://dx.doi.org/10.1103/PRXQuantum.1.020319},
year = {2020}
}
@techreport{Wiersema,
abstract = {Quantum variational algorithms are one of the most promising applications of near-term quantum computers; however, recent studies have demonstrated that unless the variational quantum circuits are configured in a problem-specific manner, optimization of such circuits will most likely fail. In this paper, we focus on a special family of quantum circuits called the Hamiltonian Variational Ansatz (HVA), which takes inspiration from the quantum approximation optimization algorithm and adiabatic quantum computation. Through the study of its entanglement spectrum and energy gradient statistics, we find that HVA exhibits favorable structural properties such as mild or entirely absent barren plateaus and a restricted state space that eases their optimization in comparison to the well-studied "hardware-efficient ansatz." We also numerically observe that the optimization landscape of HVA becomes almost trap free, i.e., no sub-optimal minima, when the ansatz is over-parameterized. We observe a size-dependent "computational phase transition as the number of layers in the HVA circuit is increased where the optimization crosses over from a hard to an easy region in terms of the quality of the approximations and speed of convergence to a good solution. In contrast with the analogous transitions observed in the learning of random unitaries which occur at a number of layers that grows exponentially with the number of qubits, our Variational Quantum Eigensolver experiments suggest that the threshold to achieve the over-parameterization phenomenon scales at most polynomially in the number of qubits for the transverse field Ising and XXZ models. Lastly, as a demonstration of its entangling power and effectiveness, we show that HVA can find accurate approximations to the ground states of a modified Haldane-Shastry Hamiltonian on a ring, which has long-range interactions and has a power-law entanglement scaling.},
annote = {HVA for TFIM and XXZ
1. plot the eigen spectrum of subsystem ;
2. no suboptimal minima; size-dependent computational phase transition at polynomial (I do not see this);
3. Haldan-Shastry Hamiltonian on a ring has highly entangled ground state, and can be efficiently found for p=N
4. No barren plateau with gradient statistics
1. Observations, the},
archivePrefix = {arXiv},
arxivId = {2008.02941v1},
author = {Wiersema, Roeland and Zhou, Cunlu and {De Sereville}, Yvette and Carrasquilla, Juan Felipe and Kim, Yong Baek and Yuen, Henry},
eprint = {2008.02941v1},
file = {:home/xucheny/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wiersema et al. - Unknown - Exploring entanglement and optimization within the Hamiltonian Variational Ansatz.pdf:pdf},
keywords = {Hamiltonian variational ansatz,barren plateau,initialization,over-parameterization,quantum entanglement,variational quantum eigensolver},
title = {{Exploring entanglement and optimization within the Hamiltonian Variational Ansatz}}
}
@article{Cerezo,
abstract = {Variational quantum algorithms (VQAs) optimize the parameters $\theta$ of a parametrized quantum circuit V($\theta$) to minimize a cost function C. While VQAs may enable practical applications of noisy quantum computers, they are nevertheless heuristic methods with unproven scaling. Here, we rigorously prove two results, assuming V($\theta$) is an alternating layered ansatz composed of blocks forming local 2-designs. Our first result states that defining C in terms of global observables leads to exponentially vanishing gradients (i.e., barren plateaus) even when V($\theta$) is shallow. Hence, several VQAs in the literature must revise their proposed costs. On the other hand, our second result states that defining C with local observables leads to at worst a polynomially vanishing gradient, so long as the depth of V($\theta$) is Oðlog nÞ. Our results establish a connection between locality and trainability. We illustrate these ideas with large-scale simulations, up to 100 qubits, of a quantum autoencoder implementation.},
author = {Cerezo, M and Sone, Akira and Volkoff, Tyler and Cincio, Lukasz and Coles, Patrick J},
doi = {10.1038/s41467-021-21728-w},
file = {:home/xucheny/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cerezo et al. - Unknown - Cost function dependent barren plateaus in shallow parametrized quantum circuits.pdf:pdf},
title = {{Cost function dependent barren plateaus in shallow parametrized quantum circuits}},
url = {https://doi.org/10.1038/s41467-021-21728-w}
}
@techreport{Hu,
abstract = {Classical shadow tomography provides an efficient method for predicting functions of an unknown quantum state from a few measurements of the state. It relies on a unitary channel that efficiently scrambles the quantum information of the state to the measurement basis. Facing the challenge of realizing deep unitary circuits on near-term quantum devices, we explore the scenario in which the unitary channel can be shallow and is generated by a quantum chaotic Hamiltonian via time evolution. We provide an unbiased estimator of the density matrix for all ranges of the evolution time. We analyze the sample complexity of the Hamiltonian-driven shadow tomography. For Pauli observables, we find that it can be more efficient than the unitary-2-design-based shadow tomography in a sequence of intermediate time windows that range from an order-1 scrambling time to a time scale of D 1/6 , given the Hilbert space dimension D. In particular, the efficiency of predicting diagonal Pauli observables is improved by a factor of D without sacrificing the efficiency of predicting off-diagonal Pauli observables. Introduction.-Quantum state tomography [1-6] is an essential quantum technology underlying the characterization of quantum devices and the discrimination of quantum states. It aims to reconstruct the density matrix from repeated measurements of identically prepared copies of a quantum system. While the complexity of exact tomography of the full density matrix scales exponentially with the system size due to the curse of dimensionality[7], approximate tomography with polynomial complexity has been developed with assumptions of the underlying quantum state, including matrix product state tomography[8-10], reduced density matrix tomography[11-16], and machine learning tomography[17-25]. Among various tomography schemes, shadow tomogra-phy[26-36] has recently attracted much research attention. Given a copy of a N-qubit quantum system described by the density matrix $\rho$, the shadow tomography protocol first performs a random unitary transformation U on the state $\rho$ → $\rho$ = U $\rho$U † , then measures the transformed state $\rho$ in the computational basis (i.e. simultaneously measuring the Pauli-Z operator on every qubit), as illustrated in Fig. 1. After the measurement, the system collapses to a pure state |b labeled by the bit-string b ∈ {\{}0, 1{\}} N of measurement outcomes. Classical snap-shotsˆ$\sigma$shotsˆ shotsˆ$\sigma$ = U † |bb|U of the quantum system can be collected through repeated measurements. Given the knowledge about the random ensemble of the unitary transformation U , the density matrix $\rho$ can be reconstructed as a particular linear combination of the ensemble average of classical snapshotsˆ$\sigma$snapshotsˆ snapshotsˆ$\sigma$, where the linear channel only depends on properties of the unitary ensemble. The unitary transformation U plays an important role in the protocol to scramble the quantum information, such that the computational basis measurement on the scrambled state $\rho$ is effectively a simultaneous measurement of a random set of N commuting operators {\{}U † Z i U {\}} N i=1 on the original state $\rho$. In this way, each measurement returns measurement outcomes for 2 N ob-servables (as products of arbitrary subsets of the com},
archivePrefix = {arXiv},
arxivId = {2102.10132v2},
author = {Hu, Hong-Ye and You, Yi-Zhuang},
eprint = {2102.10132v2},
file = {:home/xucheny/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu, You - Unknown - Hamiltonian-Driven Shadow Tomography of Quantum States.pdf:pdf},
title = {{Hamiltonian-Driven Shadow Tomography of Quantum States}}
}
@misc{You2018,
archivePrefix = {arXiv},
arxivId = {1803.10425},
author = {You, Yi Zhuang and Gu, Yingfei},
booktitle = {arXiv},
eprint = {1803.10425},
file = {:home/xucheny/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/You, Gu - Unknown - Entanglement Features of Random Hamiltonian Dynamics.pdf:pdf},
isbn = {1803.10425v2},
issn = {23318422},
title = {{Entanglement features of random hamiltonian dynamics}},
year = {2018}
}
@misc{Wang2020,
abstract = {Variational Quantum Algorithms (VQAs) may be a path to quantum advantage on Noisy Intermediate-Scale Quantum (NISQ) computers. A natural question is whether the noise on NISQ devices places any fundamental limitations on the performance of VQAs. In this work, we rigorously prove a serious limitation for noisy VQAs, in that the noise causes the training landscape to have a barren plateau (i.e., vanishing gradient). Specifically, for the local Pauli noise considered, we prove that the gradient vanishes exponentially in the number of layers L. This implies exponential decay in the number of qubits n when L scales as poly(n), for sufficiently large coefficients in the polynomial. These noise-induced barren plateaus (NIBPs) are conceptually different from noise-free barren plateaus, which are linked to random parameter initialization. Our result is formulated for an abstract ansatz that includes as special cases the Quantum Alternating Operator Ansatz (QAOA) and the Unitary Coupled Cluster Ansatz, among others. In the case of the QAOA, we implement numerical heuristics that confirm the NIBP phenomenon for a realistic hardware noise model.},
archivePrefix = {arXiv},
arxivId = {2007.14384},
author = {Wang, Samson and Fontana, Enrico and Cerezo, Marco and Sharma, Kunal and Sone, Akira and Cincio, Lukasz and Coles, Patrick J},
booktitle = {arXiv},
eprint = {2007.14384},
file = {:home/xucheny/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2020 - Noise-Induced Barren Plateaus in Variational Quantum Algorithms.pdf:pdf},
issn = {23318422},
title = {{Noise-Induced Barren Plateaus in Variational Quantum Algorithms}},
year = {2020}
}

@article{mixedkitaev2021,
  title={Benchmarking variational quantum eigensolvers for the square-octagon-lattice Kitaev model},
  author={Li, Andy CY and Alam, M Sohaib and Iadecola, Thomas and Jahin, Ammar and Kurkcuoglu, Doga Murat and Li, Richard and Orth, Peter P and {\"O}zg{\"u}ler, A Bar{\i}{\c{s}} and Perdue, Gabriel N and Tubman, Norm M},
  journal={arXiv preprint arXiv:2108.13375},
  year={2021}
}

@book{hall2003lie,
  title={Lie Groups, Lie Algebras, and Representations: An Elementary Introduction},
  author={Hall, B. and Hall, B.C.},
  isbn={9780387401225},
  lccn={03054237},
  series={Graduate Texts in Mathematics},
  url={https://books.google.com/books?id=m1VQi8HmEwcC},
  year={2003},
  publisher={Springer}
}

@article{liu2021representation,
  title={Representation learning via quantum neural tangent kernels},
  author={Liu, Junyu and Tacchino, Francesco and Glick, Jennifer R and Jiang, Liang and Mezzacapo, Antonio},
  journal={PRX Quantum},
  volume={3},
  number={3},
  pages={030323},
  year={2022},
  publisher={APS}
}

@misc{wiersema2022optimizing,
      title={Optimizing quantum circuits with Riemannian gradient-flow},
      author={Roeland Wiersema and Nathan Killoran},
      year={2022},
      eprint={2202.06976},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@misc{abedi2022quantum,
      title={Quantum Lazy Training},
      author={Erfan Abedi and Salman Beigi and Leila Taghavi},
      year={2022},
      eprint={2202.08232},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@inproceedings{anschuetz2022critical,
title={Critical Points in Quantum Generative Models},
author={Eric Ricardo Anschuetz},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=2f1z55GVQN}
}

@article{larocca2021theory,
  title={Theory of overparametrization in quantum neural networks},
  author={Larocca, Martin and Ju, Nathan and Garc{\'\i}a-Mart{\'\i}n, Diego and Coles, Patrick J and Cerezo, Marco},
  journal={arXiv preprint arXiv:2109.11676},
  year={2021}
}

@article{shirai2021quantum,
  title={Quantum tangent kernel},
  author={Shirai, Norihito and Kubo, Kenji and Mitarai, Kosuke and Fujii, Keisuke},
  journal={arXiv preprint arXiv:2111.02951},
  year={2021}
}

@article{kiani2020learning,
  title={Learning unitaries by gradient descent},
  author={Kiani, Bobak Toussi and Lloyd, Seth and Maity, Reevu},
  journal={arXiv preprint arXiv:2001.11897},
  year={2020}
}

@article{collins2006integration,
  title={Integration with respect to the Haar measure on unitary, orthogonal and symplectic group},
  author={Collins, Beno{\^\i}t and {\'S}niady, Piotr},
  journal={Communications in Mathematical Physics},
  volume={264},
  number={3},
  pages={773--795},
  year={2006},
  publisher={Springer}
}

@article{kandala2017hardware,
  title={Hardware-efficient variational quantum eigensolver for small molecules and quantum magnets},
  author={Kandala, Abhinav and Mezzacapo, Antonio and Temme, Kristan and Takita, Maika and Brink, Markus and Chow, Jerry M and Gambetta, Jay M},
  journal={Nature},
  volume={549},
  number={7671},
  pages={242--246},
  year={2017},
  publisher={Nature Publishing Group}
}
@article{russell2016quantum,
doi = {10.1088/1751-8121/aa6b77},
url = {https://dx.doi.org/10.1088/1751-8121/aa6b77},
year = {2017},
month = {apr},
publisher = {IOP Publishing},
volume = {50},
number = {20},
pages = {205302},
author = {Benjamin Russell and Herschel Rabitz and Re-Bing Wu},
title = {Control landscapes are almost always trap free: a geometric assessment},
journal = {Journal of Physics A: Mathematical and Theoretical},
abstract = {A proof is presented that almost all closed, finite dimensional quantum systems have trap free (i.e. free from local optima) landscapes for a large and physically general class of circumstances, which includes qubit evolutions in quantum computing. This result offers an explanation for why gradient-based methods succeed so frequently in quantum control. The role of singular controls is analyzed using geometric tools in the case of the control of the propagator, and thus in the case of observables as well. Singular controls have been implicated as a source of landscape traps. The conditions under which singular controls can introduce traps, and thus interrupt the progress of a control optimization, are discussed and a geometrical characterization of the issue is presented. It is shown that a control being singular is not sufficient to cause control optimization progress to halt, and sufficient conditions for a trap free landscape are presented. It is further shown that the local surjectivity (full rank) assumption of landscape analysis can be refined to the condition that the end-point map is transverse to each of the level sets of the fidelity function. This mild condition is shown to be sufficient for a quantum system’s landscape to be trap free. The control landscape is shown to be trap free for all but a null set of Hamiltonians using a geometric technique based on the parametric transversality theorem. Numerical evidence confirming this analysis is also presented. This new result is the analogue of the work of Altifini, wherein it was shown that controllability holds for all but a null set of quantum systems in the dipole approximation. These collective results indicate that the availability of adequate control resources remains the most physically relevant issue for achieving high fidelity control performance while also avoiding landscape traps.}
}
@article{wu2011role,
  title={Role of controllability in optimizing quantum dynamics},
  author={Wu, Re-Bing and Hsieh, Michael A and Rabitz, Herschel},
  journal={Physical Review A},
  volume={83},
  number={6},
  pages={062306},
  year={2011},
  publisher={APS}
}

@article {google-VQE,
	author = {Arute, Frank and Arya, Kunal and Babbush, Ryan and Bacon, Dave and Bardin, Joseph C. and Barends, Rami and Boixo, Sergio and Broughton, Michael and Buckley, Bob B. and Buell, David A. and Burkett, Brian and Bushnell, Nicholas and Chen, Yu and Chen, Zijun and Chiaro, Benjamin and Collins, Roberto and Courtney, William and Demura, Sean and Dunsworth, Andrew and Farhi, Edward and Fowler, Austin and Foxen, Brooks and Gidney, Craig and Giustina, Marissa and Graff, Rob and Habegger, Steve and Harrigan, Matthew P. and Ho, Alan and Hong, Sabrina and Huang, Trent and Huggins, William J. and Ioffe, Lev and Isakov, Sergei V. and Jeffrey, Evan and Jiang, Zhang and Jones, Cody and Kafri, Dvir and Kechedzhi, Kostyantyn and Kelly, Julian and Kim, Seon and Klimov, Paul V. and Korotkov, Alexander and Kostritsa, Fedor and Landhuis, David and Laptev, Pavel and Lindmark, Mike and Lucero, Erik and Martin, Orion and Martinis, John M. and McClean, Jarrod R. and McEwen, Matt and Megrant, Anthony and Mi, Xiao and Mohseni, Masoud and Mruczkiewicz, Wojciech and Mutus, Josh and Naaman, Ofer and Neeley, Matthew and Neill, Charles and Neven, Hartmut and Niu, Murphy Yuezhen and O{\textquoteright}Brien, Thomas E. and Ostby, Eric and Petukhov, Andre and Putterman, Harald and Quintana, Chris and Roushan, Pedram and Rubin, Nicholas C. and Sank, Daniel and Satzinger, Kevin J. and Smelyanskiy, Vadim and Strain, Doug and Sung, Kevin J. and Szalay, Marco and Takeshita, Tyler Y. and Vainsencher, Amit and White, Theodore and Wiebe, Nathan and Yao, Z. Jamie and Yeh, Ping and Zalcman, Adam},
	title = {Hartree-Fock on a superconducting qubit quantum computer},
	volume = {369},
	number = {6507},
	pages = {1084--1089},
	year = {2020},
	doi = {10.1126/science.abb9811},
	publisher = {American Association for the Advancement of Science},
	abstract = {Accurate electronic structure calculations are considered one of the most anticipated applications of quantum computing that will revolutionize theoretical chemistry and other related fields. Using the Google Sycamore quantum processor, Google AI Quantum and collaborators performed a variational quantum eigensolver (VQE) simulation of two intermediate-scale chemistry problems: the binding energy of hydrogen chains (as large as H12) and the isomerization mechanism of diazene (see the Perspective by Yuan). The simulations were performed on up to 12 qubits, involving up to 72 two-qubit gates, and show that it is possible to achieve chemical accuracy when VQE is combined with error mitigation strategies. The key building blocks of the proposed VQE algorithm are potentially scalable to larger systems that cannot be simulated classically.Science, this issue p. 1084; see also p. 1054The simulation of fermionic systems is among the most anticipated applications of quantum computing. We performed several quantum simulations of chemistry with up to one dozen qubits, including modeling the isomerization mechanism of diazene. We also demonstrated error-mitigation strategies based on N-representability that dramatically improve the effective fidelity of our experiments. Our parameterized ansatz circuits realized the Givens rotation approach to noninteracting fermion evolution, which we variationally optimized to prepare the Hartree-Fock wave function. This ubiquitous algorithmic primitive is classically tractable to simulate yet still generates highly entangled states over the computational basis, which allowed us to assess the performance of our hardware and establish a foundation for scaling up correlated quantum chemistry simulations.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/369/6507/1084},
	eprint = {https://science.sciencemag.org/content/369/6507/1084.full.pdf},
	journal = {Science}
}


@article {Zhong1460,
	author = {Zhong, Han-Sen and Wang, Hui and Deng, Yu-Hao and Chen, Ming-Cheng and Peng, Li-Chao and Luo, Yi-Han and Qin, Jian and Wu, Dian and Ding, Xing and Hu, Yi and Hu, Peng and Yang, Xiao-Yan and Zhang, Wei-Jun and Li, Hao and Li, Yuxuan and Jiang, Xiao and Gan, Lin and Yang, Guangwen and You, Lixing and Wang, Zhen and Li, Li and Liu, Nai-Le and Lu, Chao-Yang and Pan, Jian-Wei},
	title = {Quantum computational advantage using photons},
	volume = {370},
	number = {6523},
	pages = {1460--1463},
	year = {2020},
	doi = {10.1126/science.abe8770},
	publisher = {American Association for the Advancement of Science},
	abstract = {Quantum computational advantage or supremacy is a long-anticipated milestone toward practical quantum computers. Recent work claimed to have reached this point, but subsequent work managed to speed up the classical simulation and pointed toward a sample size{\textendash}dependent loophole. Quantum computational advantage, rather than being a one-shot experimental proof, will be the result of a long-term competition between quantum devices and classical simulation. Zhong et al. sent 50 indistinguishable single-mode squeezed states into a 100-mode ultralow-loss interferometer and sampled the output using 100 high-efficiency single-photon detectors. By obtaining up to 76-photon coincidence, yielding a state space dimension of about 1030, they measured a sampling rate that is about 1014-fold faster than using state-of-the-art classical simulation strategies and supercomputers.Science, this issue p. 1460Quantum computers promise to perform certain tasks that are believed to be intractable to classical computers. Boson sampling is such a task and is considered a strong candidate to demonstrate the quantum computational advantage. We performed Gaussian boson sampling by sending 50 indistinguishable single-mode squeezed states into a 100-mode ultralow-loss interferometer with full connectivity and random matrix{\textemdash}the whole optical setup is phase-locked{\textemdash}and sampling the output using 100 high-efficiency single-photon detectors. The obtained samples were validated against plausible hypotheses exploiting thermal states, distinguishable photons, and uniform distribution. The photonic quantum computer, Jiuzhang, generates up to 76 output photon clicks, which yields an output state-space dimension of 1030 and a sampling rate that is faster than using the state-of-the-art simulation strategy and supercomputers by a factor of ~1014.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/370/6523/1460},
	eprint = {https://science.sciencemag.org/content/370/6523/1460.full.pdf},
	journal = {Science}
}


@article{PhysRevA.97.022304,
  title = {Quantum approximate optimization algorithm for MaxCut: A fermionic view},
  author = {Wang, Zhihui and Hadfield, Stuart and Jiang, Zhang and Rieffel, Eleanor G.},
  journal = {Phys. Rev. A},
  volume = {97},
  issue = {2},
  pages = {022304},
  numpages = {11},
  year = {2018},
  month = {Feb},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevA.97.022304},
  url = {https://link.aps.org/doi/10.1103/PhysRevA.97.022304}
}


@article{PhysRevA.101.012320,
  title = {$XY$ mixers: Analytical and numerical results for the quantum alternating operator ansatz},
  author = {Wang, Zhihui and Rubin, Nicholas C. and Dominy, Jason M. and Rieffel, Eleanor G.},
  journal = {Phys. Rev. A},
  volume = {101},
  issue = {1},
  pages = {012320},
  numpages = {16},
  year = {2020},
  month = {Jan},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevA.101.012320},
  url = {https://link.aps.org/doi/10.1103/PhysRevA.101.012320}
}

@ARTICLE{2019arXiv191008187F,
       author = {{Farhi}, Edward and {Goldstone}, Jeffrey and {Gutmann}, Sam and
         {Zhou}, Leo},
        title = "{The Quantum Approximate Optimization Algorithm and the Sherrington-Kirkpatrick Model at Infinite Size}",
      journal = {arXiv e-prints},
     keywords = {Quantum Physics, Condensed Matter - Disordered Systems and Neural Networks, Condensed Matter - Statistical Mechanics},
         year = 2019,
        month = oct,
          eid = {arXiv:1910.08187},
        pages = {arXiv:1910.08187},
archivePrefix = {arXiv},
       eprint = {1910.08187},
 primaryClass = {quant-ph},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv191008187F},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{Preskill2018NISQ,
  title = {Quantum computing in the {NISQ} era and beyond},
  author = {Preskill, John},
  journal = {{Quantum}},
  issn = {2521-327X},
  publisher = {{Verein zur F{\"{o}}rderung des Open Access Publizierens in den Quantenwissenschaften}},
  volume = {2},
  pages = {79},
  year = {2018},
  eprint={1801.00862}
}

@article{NC-VQE,
  title={A variational eigenvalue solver on a photonic quantum processor},
  author={Peruzzo, Alberto and McClean, Jarrod and Shadbolt, Peter and Yung, Man-Hong and Zhou, Xiao-Qi and Love, Peter J. and Aspuru-Guzik, Al{\'a}n and O'brien, Jeremy L.},
  journal={Nature Communications},
  volume={5},
  pages={4213},
  year={2014},
  publisher={Nature Publishing Group}
}

@article{google-supremacy,
	Author = {Arute, Frank and Arya, Kunal and Babbush, Ryan and Bacon, Dave and Bardin, Joseph C. and Barends, Rami and Biswas, Rupak and Boixo, Sergio and Brandao, Fernando G. S. L. and Buell, David A. and Burkett, Brian and Chen, Yu and Chen, Zijun and Chiaro, Ben and Collins, Roberto and Courtney, William and Dunsworth, Andrew and Farhi, Edward and Foxen, Brooks and Fowler, Austin and Gidney, Craig and Giustina, Marissa and Graff, Rob and Guerin, Keith and Habegger, Steve and Harrigan, Matthew P. and Hartmann, Michael J. and Ho, Alan and Hoffmann, Markus and Huang, Trent and Humble, Travis S. and Isakov, Sergei V. and Jeffrey, Evan and Jiang, Zhang and Kafri, Dvir and Kechedzhi, Kostyantyn and Kelly, Julian and Klimov, Paul V. and Knysh, Sergey and Korotkov, Alexander and Kostritsa, Fedor and Landhuis, David and Lindmark, Mike and Lucero, Erik and Lyakh, Dmitry and Mandr{\`a}, Salvatore and McClean, Jarrod R. and McEwen, Matthew and Megrant, Anthony and Mi, Xiao and Michielsen, Kristel and Mohseni, Masoud and Mutus, Josh and Naaman, Ofer and Neeley, Matthew and Neill, Charles and Niu, Murphy Yuezhen and Ostby, Eric and Petukhov, Andre and Platt, John C. and Quintana, Chris and Rieffel, Eleanor G. and Roushan, Pedram and Rubin, Nicholas C. and Sank, Daniel and Satzinger, Kevin J. and Smelyanskiy, Vadim and Sung, Kevin J. and Trevithick, Matthew D. and Vainsencher, Amit and Villalonga, Benjamin and White, Theodore and Yao, Z. Jamie and Yeh, Ping and Zalcman, Adam and Neven, Hartmut and Martinis, John M.},
	Journal = {Nature},
	Number = {7779},
	Pages = {505--510},
	Title = {Quantum supremacy using a programmable superconducting processor},
	Volume = {574},
	Year = {2019}}

@ONLINE{IBM-53,
author = {Martin Giles},
title = {IBM's new 53-qubit quantum computer is the most powerful machine you can use},
month = {September},
year = {2019},
url = {https://www.technologyreview.com/f/614346/ibms-new-53-qubit-quantum-computer-is-the-most-powerful-machine-you-can-use/}
}

@article{biamonte2017quantum,
  title={Quantum machine learning},
  author={Biamonte, Jacob and Wittek, Peter and Pancotti, Nicola and Rebentrost, Patrick and Wiebe, Nathan and Lloyd, Seth},
  journal={Nature},
  volume={549},
  number={7671},
  pages={195},
  year={2017},
  publisher={Nature Publishing Group},
}
@article{schuld2019quantum,
  title={Quantum machine learning in feature Hilbert spaces},
  author={Schuld, Maria and Killoran, Nathan},
  journal={Physical review letters},
  volume={122},
  number={4},
  pages={040504},
  year={2019},
  publisher={APS}
}
@article{havlivcek2019supervised,
  title={Supervised learning with quantum-enhanced feature spaces},
  author={Havl{\'\i}{\v{c}}ek, Vojt{\v{e}}ch and C{\'o}rcoles, Antonio D and Temme, Kristan and Harrow, Aram W and Kandala, Abhinav and Chow, Jerry M and Gambetta, Jay M},
  journal={Nature},
  volume={567},
  number={7747},
  pages={209--212},
  year={2019},
  publisher={Nature Publishing Group}
}
@article{farhi2018classification,
  title={Classification with Quantum Neural Networks on Near Term Processors},
  author={Farhi, Edward and Neven, Hartmut and others},
  journal={Quantum Review Letters},
  volume={1},
  number={2 (2020)},
  pages={10--37686},
  year={2020},
  publisher={Web of Open Science}
}
@article{li2017hybrid,
  title={Hybrid quantum-classical approach to quantum optimal control},
  author={Li, Jun and Yang, Xiaodong and Peng, Xinhua and Sun, Chang-Pu},
  journal={Physical review letters},
  volume={118},
  number={15},
  pages={150503},
  year={2017},
  publisher={APS}
}
@article{benedetti2019parameterized,
  title={Parameterized quantum circuits as machine learning models},
  author={Benedetti, Marcello and Lloyd, Erika and Sack, Stefan and Fiorentini, Mattia},
  journal={Quantum Science and Technology},
  volume={4},
  number={4},
  pages={043001},
  year={2019},
  publisher={IOP Publishing}
}
@article{lloyd2020quantum,
  title={Quantum embeddings for machine learning},
  author={Lloyd, Seth and Schuld, Maria and Ijaz, Aroosa and Izaac, Josh and Killoran, Nathan},
  journal={arXiv preprint arXiv:2001.03622},
  year={2020}
}
@article{sweke2019stochastic,
  title={Stochastic gradient descent for hybrid quantum-classical optimization},
  author={Sweke, Ryan and Wilde, Frederik and Meyer, Johannes Jakob and Schuld, Maria and F{\"a}hrmann, Paul K and Meynard-Piganeau, Barth{\'e}l{\'e}my and Eisert, Jens},
  journal={Quantum},
  volume={4},
  pages={314},
  year={2020},
  publisher={Verein zur F{\"o}rderung des Open Access Publizierens in den Quantenwissenschaften}
}
@article{mcclean2018barren,
  title={Barren plateaus in quantum neural network training landscapes},
  author={McClean, Jarrod R and Boixo, Sergio and Smelyanskiy, Vadim N and Babbush, Ryan and Neven, Hartmut},
  journal={Nature communications},
  volume={9},
  number={1},
  pages={1--6},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{mitarai2018quantum,
  title={Quantum circuit learning},
  author={Mitarai, Kosuke and Negoro, Makoto and Kitagawa, Masahiro and Fujii, Keisuke},
  journal={Physical Review A},
  volume={98},
  number={3},
  pages={032309},
  year={2018},
  publisher={APS}
}
@article{farhi2014quantum,
  title={A quantum approximate optimization algorithm},
  author={Farhi, Edward and Goldstone, Jeffrey and Gutmann, Sam},
  journal={arXiv preprint arXiv:1411.4028},
  year={2014}
}
@article{ostaszewski2019qcsl,
  title={Quantum circuit structure learning},
  author={Ostaszewski, Mateusz and Grant, Edward and Benedetti, Marcello},
  journal={arXiv preprint arXiv:1905.09692},
  year={2019}
}

% quantum control
@article{rabitz2004quantum,
  title={Quantum optimally controlled transition landscapes},
  author={Rabitz, Herschel A and Hsieh, Michael M and Rosenthal, Carey M},
  journal={Science},
  volume={303},
  number={5666},
  pages={1998--2001},
  year={2004},
  publisher={American Association for the Advancement of Science}
}



@article{altafini2002controllability,
  title={Controllability of quantum mechanical systems by root space decomposition of su (N)},
  author={Altafini, Claudio},
  journal={Journal of Mathematical Physics},
  volume={43},
  number={5},
  pages={2051--2062},
  year={2002},
  publisher={American Institute of Physics}
}
@article{niu2019optimizing,
  title={Optimizing qaoa: Success probability and runtime dependence on circuit depth},
  author={Niu, Murphy Yuezhen and Lu, Sirui and Chuang, Isaac L},
  journal={arXiv preprint arXiv:1905.12134},
  year={2019}
}

% Supremacy
@article{harrow2017quantum,
  title={Quantum computational supremacy},
  author={Harrow, Aram W and Montanaro, Ashley},
  journal={Nature},
  volume={549},
  number={7671},
  pages={203--209},
  year={2017},
  publisher={Nature Publishing Group}
}
@article{lund2017quantum,
  title={Quantum sampling problems, BosonSampling and quantum supremacy},
  author={Lund, AP and Bremner, Michael J and Ralph, TC},
  journal={npj Quantum Information},
  volume={3},
  number={1},
  pages={1--8},
  year={2017},
  publisher={Nature Publishing Group}
}

% Quantum Learning
@article{bisio2010optimal,
  title={Optimal quantum learning of a unitary transformation},
  author={Bisio, Alessandro and Chiribella, Giulio and D’Ariano, Giacomo Mauro and Facchini, Stefano and Perinotti, Paolo},
  journal={Physical Review A},
  volume={81},
  number={3},
  pages={032324},
  year={2010},
  publisher={APS}
}

@article{killoran2019continuous,
  title={Continuous-variable quantum neural networks},
  author={Killoran, Nathan and Bromley, Thomas R and Arrazola, Juan Miguel and Schuld, Maria and Quesada, Nicol{\'a}s and Lloyd, Seth},
  journal={Physical Review Research},
  volume={1},
  number={3},
  pages={033063},
  year={2019},
  publisher={APS}
}
@article{mari2019transfer,
  title={Transfer learning in hybrid classical-quantum neural networks},
  author={Mari, Andrea and Bromley, Thomas R and Izaac, Josh and Schuld, Maria and Killoran, Nathan},
  journal={Quantum},
  volume={4},
  pages={340},
  year={2020},
  publisher={Verein zur F{\"o}rderung des Open Access Publizierens in den Quantenwissenschaften}
}

@book{watrous2018theory,
  title={The theory of quantum information},
  author={Watrous, John},
  year={2018},
  publisher={Cambridge University Press}
}
@misc{nielsen2002quantum,
  title={Quantum computation and quantum information},
  author={Nielsen, Michael A and Chuang, Isaac},
  year={2002},
  publisher={American Association of Physics Teachers}
}

@misc{liu2021variational,
  doi = {10.48550/ARXIV.2102.05566},
  url = {https://arxiv.org/abs/2102.05566},
  author = {Liu, Xiaoyuan and Angone, Anthony and Shaydulin, Ruslan and Safro, Ilya and Alexeev, Yuri and Cincio, Lukasz},
  keywords = {Quantum Physics (quant-ph), Data Structures and Algorithms (cs.DS), FOS: Physical sciences, FOS: Physical sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Layer VQE: A Variational Approach for Combinatorial Optimization on Noisy Quantum Computers},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{tilly2021variational,
  doi = {10.48550/ARXIV.2111.05176},
  url = {https://arxiv.org/abs/2111.05176},
  author = {Tilly, Jules and Chen, Hongxiang and Cao, Shuxiang and Picozzi, Dario and Setia, Kanav and Li, Ying and Grant, Edward and Wossnig, Leonard and Rungger, Ivan and Booth, George H. and Tennyson, Jonathan},
  keywords = {Quantum Physics (quant-ph), FOS: Physical sciences, FOS: Physical sciences},
  title = {The Variational Quantum Eigensolver: a review of methods and best practices},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{crooks2018performance,
  doi = {10.48550/ARXIV.1811.08419},

  url = {https://arxiv.org/abs/1811.08419},

  author = {Crooks, Gavin E.},

  keywords = {Quantum Physics (quant-ph), FOS: Physical sciences, FOS: Physical sciences},

  title = {Performance of the Quantum Approximate Optimization Algorithm on the Maximum Cut Problem},

  publisher = {arXiv},

  year = {2018},

  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{mbeng2019quantum,
  doi = {10.48550/ARXIV.1906.08948},

  url = {https://arxiv.org/abs/1906.08948},

  author = {Mbeng, Glen Bigan and Fazio, Rosario and Santoro, Giuseppe},

  keywords = {Quantum Physics (quant-ph), FOS: Physical sciences, FOS: Physical sciences, J.2, J.2},

  title = {Quantum Annealing: a journey through Digitalization, Control, and hybrid Quantum Variational schemes},

  publisher = {arXiv},

  year = {2019},

  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{you2021exponentially,
  title={Exponentially many local minima in quantum neural networks},
  author={You, Xuchen and Wu, Xiaodi},
  booktitle={International Conference on Machine Learning},
  pages={12144--12155},
  year={2021},
  organization={PMLR}
}

@inproceedings{livni2014on,
 author = {Livni, Roi and Shalev-Shwartz, Shai and Shamir, Ohad},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {On the Computational Efficiency of Training Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2014/file/3a0772443a0739141292a5429b952fe6-Paper.pdf},
 volume = {27},
 year = {2014}
}

@article{arora2018stronger,
  author    = {Sanjeev Arora and
               Rong Ge and
               Behnam Neyshabur and
               Yi Zhang},
  title     = {Stronger generalization bounds for deep nets via a compression approach},
  journal   = {CoRR},
  volume    = {abs/1802.05296},
  year      = {2018},
  url       = {http://arxiv.org/abs/1802.05296},
  eprinttype = {arXiv},
  eprint    = {1802.05296},
  timestamp = {Mon, 22 Nov 2021 14:32:01 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1802-05296.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% New references for QNN

@article{Dunjko_2018,
	doi = {10.1088/1361-6633/aab406},
	url = {https://doi.org/10.1088/1361-6633/aab406},
	year = 2018,
	month = {jun},
	publisher = {{IOP} Publishing},
	volume = {81},
	number = {7},
	pages = {074001},
	author = {Vedran Dunjko and Hans J Briegel},
	title = {Machine learning and artificial intelligence in the quantum domain: a review of recent progress},
	journal = {Reports on Progress in Physics},
	abstract = {Quantum information technologies, on the one hand, and intelligent learning systems, on the other, are both emergent technologies that are likely to have a transformative impact on our society in the future. The respective underlying fields of basic research—quantum information versus machine learning (ML) and artificial intelligence (AI)—have their own specific questions and challenges, which have hitherto been investigated largely independently. However, in a growing body of recent work, researchers have been probing the question of the extent to which these fields can indeed learn and benefit from each other. Quantum ML explores the interaction between quantum computing and ML, investigating how results and techniques from one field can be used to solve the problems of the other. Recently we have witnessed significant breakthroughs in both directions of influence. For instance, quantum computing is finding a vital application in providing speed-ups for ML problems, critical in our ‘big data’ world. Conversely, ML already permeates many cutting-edge technologies and may become instrumental in advanced quantum technologies. Aside from quantum speed-up in data analysis, or classical ML optimization used in quantum experiments, quantum enhancements have also been (theoretically) demonstrated for interactive learning tasks, highlighting the potential of quantum-enhanced learning agents. Finally, works exploring the use of AI for the very design of quantum experiments and for performing parts of genuine research autonomously, have reported their first successes. Beyond the topics of mutual enhancement—exploring what ML/AI can do for quantum physics and vice versa—researchers have also broached the fundamental issue of quantum generalizations of learning and AI concepts. This deals with questions of the very meaning of learning and intelligence in a world that is fully described by quantum mechanics. In this review, we describe the main ideas, recent developments and progress in a broad spectrum of research investigating ML and AI in the quantum domain.}
}

@article{Romero_2017,
	doi = {10.1088/2058-9565/aa8072},
	url = {https://doi.org/10.1088/2058-9565/aa8072},
	year = 2017,
	month = {aug},
	publisher = {{IOP} Publishing},
	volume = {2},
	number = {4},
	pages = {045001},
	author = {Jonathan Romero and Jonathan P Olson and Alan Aspuru-Guzik},
	title = {Quantum autoencoders for efficient compression of quantum data},
	journal = {Quantum Science and Technology},
	abstract = {Classical autoencoders are neural networks that can learn efficient low-dimensional representations of data in higher-dimensional space. The task of an autoencoder is, given an input x, to map x to a lower dimensional point y such that x can likely be recovered from y. The structure of the underlying autoencoder network can be chosen to represent the data on a smaller dimension, effectively compressing the input. Inspired by this idea, we introduce the model of a quantum autoencoder to perform similar tasks on quantum data. The quantum autoencoder is trained to compress a particular data set of quantum states, where a classical compression algorithm cannot be employed. The parameters of the quantum autoencoder are trained using classical optimization algorithms. We show an example of a simple programmable circuit that can be trained as an efficient autoencoder. We apply our model in the context of quantum simulation to compress ground states of the Hubbard model and molecular Hamiltonians.}
}

@article{Zoufal_2019,
	doi = {10.1038/s41534-019-0223-2},

	url = {https://doi.org/10.1038%2Fs41534-019-0223-2},

	year = 2019,
	month = {nov},

	publisher = {Springer Science and Business Media {LLC}
},

	volume = {5},

	number = {1},

	author = {Christa Zoufal and Aur{\'{e}}lien Lucchi and Stefan Woerner},

	title = {Quantum Generative Adversarial Networks for learning and loading random distributions},

	journal = {npj Quantum Information}
}

@article{chakrabarti2019wass,
  title={Quantum wasserstein generative adversarial networks},
  author={Chakrabarti, Shouvanik and Yiming, Huang and Li, Tongyang and Feizi, Soheil and Wu, Xiaodi},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{Schuld_2014,
	doi = {10.1007/s11128-014-0809-8},

	url = {https://doi.org/10.1007%2Fs11128-014-0809-8},

	year = 2014,
	month = {aug},

	publisher = {Springer Science and Business Media {LLC}
},

	volume = {13},

	number = {11},

	pages = {2567--2586},

	author = {Maria Schuld and Ilya Sinayskiy and Francesco Petruccione},

	title = {The quest for a Quantum Neural Network},

	journal = {Quantum Information Processing}
}

@article{Lloyd_2018,
	doi = {10.1103/physrevlett.121.040502},

	url = {https://doi.org/10.1103%2Fphysrevlett.121.040502},

	year = 2018,
	month = {jul},

	publisher = {American Physical Society ({APS})},

	volume = {121},

	number = {4},

	author = {Seth Lloyd and Christian Weedbrook},

	title = {Quantum Generative Adversarial Learning},

	journal = {Physical Review Letters}
}

@misc{schuld2021kernel,
  doi = {10.48550/ARXIV.2101.11020},

  url = {https://arxiv.org/abs/2101.11020},

  author = {Schuld, Maria},

  keywords = {Quantum Physics (quant-ph), Machine Learning (stat.ML), FOS: Physical sciences, FOS: Physical sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},

  title = {Supervised quantum machine learning models are kernel methods},

  publisher = {arXiv},

  year = {2021},

  copyright = {Creative Commons Attribution 4.0 International}
}


@article{cong2019quantum,
  title={Quantum convolutional neural networks},
  author={Cong, Iris and Choi, Soonwon and Lukin, Mikhail D},
  journal={Nature Physics},
  volume={15},
  number={12},
  pages={1273--1278},
  year={2019},
  publisher={Nature Publishing Group}
}
@article{pytorchcite,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
@article{ragone2022representation,
  title={Representation theory for geometric quantum machine learning},
  author={Ragone, Michael and Braccia, Paolo and Nguyen, Quynh T and Schatzki, Louis and Coles, Patrick J and Sauvage, Frederic and Larocca, Martin and Cerezo, M},
  journal={arXiv preprint arXiv:2210.07980},
  year={2022}
}
@article{wang2022symmetric,
  title={Symmetric Pruning in Quantum Neural Networks},
  author={Wang, Xinbiao and Liu, Junyu and Liu, Tongliang and Luo, Yong and Du, Yuxuan and Tao, Dacheng},
  journal={arXiv preprint arXiv:2208.14057},
  year={2022}
}
@article{du2022demystify,
  title={Demystify Problem-Dependent Power of Quantum Neural Networks on Multi-Class Classification},
  author={Du, Yuxuan and Yang, Yibo and Tao, Dacheng and Hsieh, Min-Hsiu},
  journal={arXiv preprint arXiv:2301.01597},
  year={2022}
}
