\section{Method}
\subsection{Problem Formulation}
Let $F=\{f^i | i=1,..,N\}$ be the set of semantic frames we wish to localize. Let $O=\{o^i|i=1,...,M\}$ be the collective set of all objects defined in the frame elements of all $f \in F$. Given observations $z_{0:T}$ and robot-state information $x_{0:T}$, we wish to maintain the belief over frame locations $P(F_{0:T} | x_{0:T}, z_{0:T}, O_{0:T})$. The resulting distribution will inform the robot where affordances are in the scene, and, thus, where the robot can take actions and effect change in the environment. We assume a room-level annotated metric map is given. SEAL describes the inference problem of localizing instances of semantic frames within the given map.

\subsection{SEAL} \label{sec:SeFM}
SEAL formalizes the frame location estimation problem via a Conditional Random Field (CRF) extending the work of Lorbach \cite{lorbach2014} and Zeng \cite{zeng2020}.  The CRF model includes object-affordance, affordance-affordance, and state-affordance relations as shown in Figure \ref{fig:CRF}. The full posterior probability of frame locations is

\begin{multline}
        p(F_{0:T}|x_{0:T}, z_{0:T}, O_{0:T}) =\\\frac{1}{Z} \prod_{t=0}^{T}\prod_{i=1}^{N}\phi_p(f^i_t, f^i_{t-1})\prod_{i,k}\phi_{m,\mathcal{B}(R_{ik}|x_t)}(f^i_t, o^k_t)\\\prod_{i,j}\phi_{c,\mathcal{B}(R_{ij}|x_t)}(f^i_t, f^j_t)
    \label{eq:full_posterior}
\end{multline}


where Z is a normalization constant, $\phi_p$ is the prediction potential, $\phi_m$ is the measurement potential, and $\phi_c$ is the context potential. We assume the robot remains localized in a metric map of the environment. Robot-state information $x_t$ informs the model about concepts regarding the robot itself: pose of the robot, whether an object is in its gripper, etc. Observations $z_t$ are RGB-D images of the environment taken by the robot as it navigates. Both $x_t$ and $z_t$ are known variables. 

The \textit{prediction potential}, $\phi_p(f^i_t, f^i_{t-1})$, models the temporal permanence of a frame. The value of this potential is category-dependent. Some frames, like ``\textit{Go} to couch", remain static over time. Others, like ``\textit{Grasp} cup", can move over time due to various external factors which we model as:

\begin{equation*}
    \phi_p(f^i_t, f^i_{t-1}) \sim \mathcal{N}(f^i_{t-1}, \Sigma^i)
    \label{eq:prediction}
\end{equation*}
The \textit{measurement potential} ,$\phi_{m,\mathcal{B}(R_{ik}|x_t)}(f^i_t, o^k_t)$, models object-frame relations parameterized by the belief --- $\mathcal{B}(R_{ik}|x_t)$ --- over a set of defined frame-object relations $R$ for frame $f^i$ and object $o^k$ conditioned on robot-state information $x_t$. We assume that frames are tightly coupled to the objects which afford them (i.e. ``\textit{Grasp} Spoon" is spatially close to a spoon). By parameterizing the belief over all frame elements, we are able to model the effect of state-transition on frame locations. For example, ``\textit{Stir} Mug" requires a spoon and the semantic frame explicitly encodes this with the precondition ``\textit{Grasp} spoon".  Therefore, if the robot does not yet have a spoon in its gripper ``\textit{Stir} Mug" should be localized close to a spoon; conversely, ``\textit{Stir} Mug" should be close to a mug if the robot is already holding a spoon. Additionally, because we model the relation over all frame elements ``\textit{Stir} Mug" is more likely to be in a room that has both spoons and mugs rather than a room that only has one or the other. Concretely, 
\begin{equation*}
    \phi_{m,\mathcal{B}(R_{ik}|x_t)} = \sum_r\sum_{k=0}^M \mathcal{B}(R_{ik} = r | x_t) \phi_{m,r}(f^i,o^k, R_{ik}=r)
    \label{eq:measurement}
\end{equation*}
where $r$ can be one of the following relation types \{\textit{Core}, \textit{Other}, \textit{Disjoint}\} and $\mathcal{B}(R_{ik} = r | x_t)$ is the belief that $r$ is relevant between a frame ($f^i$) and object ($o^k$) given the current state. For $r \in $ \{\textit{Core}, \textit{Other}\}, the measurement potential corresponds to a Gaussian distribution:
\begin{equation*}
    \phi_{m}(f_t^i, o_t^k) \sim \mathcal{N}(o^k_t, \Sigma)
\end{equation*}
where $\Sigma$ is always constant across frame-object pairs. A \textit{Core} object is the next object the robot would need to interact with to proceed with frame execution. Whereas \textit{Other} objects will eventually be necessary or are completely optional.
%and $\lVert \Sigma_{core} \rVert < \lVert \Sigma_{other} \rVert$ 
For $r = $ \textit{Disjoint} the measurement potential is 0 since the object is not involved in frame execution. In this work, object-frame relations are explicit in the semantic frame definition.

The \textit{context potential} ,$\phi_{c,\mathcal{B}(R_{ij})}(f^i_t, f^j_t, x_t)$, models inter-frame relations. In this work we only model the relation between a frame and its preconditions. Since the preconditions define a sequential list of actions to be completed, we can use the state information to inform our model about which preconditions have already been met and which precondition must be met next. From there, the context potential follows a similar model to the measurement potential 
\begin{equation*}
    \phi_{c,\mathcal{B}(R_{ij}|x_t)} = \sum_r\sum_{j=0}^M \mathcal{B}(R_{ij} = r | x_t) \phi_{c,r}(f^i,f^j, R_{ij}=r)
    \label{eq:context}
\end{equation*}
where $r$ can be one of two relation types \{\textit{Precondition}, \textit{Disjoint}\}. For $r = $ \textit{Precondition} the context potential corresponds to a Gaussian distribution:
\begin{equation*}
    \phi_{c}(f_t^i, f_t^j) \sim \mathcal{N}(f^j_t, \Sigma)
\end{equation*}
where $f^j$ is the precondition and $\Sigma$ is always constant. For $r = $ \textit{Disjoint} the context potential is 0. Again, these relations are explicit in the semantic frame definition.

\subsection{Semantic Frame Mapping} \label{sec:inference}
We implement a particle-based inference method, dubbed Semantic Frame Mapping, for maintaining belief over semantic frame locations, as shown in Algorithm \ref{algo:inference}. Object locations are inferred using the method defined in \cite{zeng2020} and we refer the reader to that paper for full implementation details. In our experiments, we use 200 particles for each object and semantic frame with heurisitics for particle reinvigoration. %Particle reinvigoration is implemented to deal with particle deprivation as well as to ensure we maintain belief over the entire environment.

\begin{algorithm}[!th]
    \caption{Inference of Semantic Frame Locations in SeFM}
    \label{algo:inference}
    \begin{algorithmic}
        \Require Observation $z_t$, Robot-State Vector $x_t$, Object location particle set $O_{t}$, particle set for each frame:\\
        $f^i_{t-1}=\{\langle f^{i(k)}_{t-1}, \alpha^{i(k)}_{t-1} \rangle | k=1,...,P \}, i \in 1:N$
        \State Resample P particles with probability proportional to $\alpha_{t-1}^{i(k)}$
        \For{$i=1,...,N$}
            \For{$k=1,...,P$}
                \State $f^{i(k)}_t \sim \phi_p(f^i_t, f^{i(k)}_{t-1})$
                \State $\displaystyle \alpha_t^{i(k)} \propto \! \prod_{j \in \Gamma(i)} \! \phi_{m}(f^{i(k)}_t, o^j_t) \prod_{l \in \Gamma(i)}  \! \phi_{c} (f^{i(k)}_t, f^l_t)$
                
                where, 
                $\displaystyle \phi_{m}= \sum_r\sum^P_{s=0}\mathcal{B}(r|x_t)\alpha_{t}^{j(s)}\phi_{m,r}(f^i_t, o^j_t,r) $
                
                and,
                $\displaystyle \phi_{c}= \sum_r\sum^P_{s=0}\mathcal{B}(r|x_t)\alpha_{t}^{l(s)}\phi_{c,r}(f^i_t, f^l_t,r)$
        \EndFor
    \EndFor
    \end{algorithmic}
\end{algorithm}

