\section{CONCLUSION}
We show that Semantic Frame Mapping can incorporate the structure of human environments as factors in a factor graph to efficiently and accurately localize semantic frames even with weak priors and under partial observability. We also show that by using particle based inference methods we are able to encode multi-modal belief distributions efficiently and without mode collapse. We explored the advantages of Semantic Frame decomposition of tasks compared to LLM and showed that LLM fail to grasp the subtleties of complex actions even when prompted with an example. This shortcoming led to 0\% success rate in tasks that SeFM was able to complete over 50\% of the time. When extending SeFM to the real world, we noticed that a majority of failures come from the encoded manipulation policies failing. With more refinement in this domain, we expect Semantic Frame Mapping to be a viable bridge from high-level command to robot actions. Further work remains to remove the necessity to explicitly define each component of a semantic frame; for instance, could we learn the frame elements, pre- and post- conditions from demonstrations? 