% !TeX spellcheck = en_US
\section{Mesoscopic Average Behavior}\label{sec:mesoscopic}

Now that we have analyzed the behavior of the individual user's response, we can step back and take a mesoscopic point of view, i.e., model the aggregate behavior resulting from the microscopic decisions. 

\subsection{Aggregate Decision}\label{sec:mesoscopic_aggregate}

At each time $t$, given Karma levels and reference probability distribution $\eta_t(k,k_\mathrm{ref})$, the probability of a traveling user with Karma level $k$ choosing arc $j \in \{1,\ldots,n\}$ is denoted by {$P(j | k,k_\mathrm{ref},\mathbf{p},\mathbf{x}^\mathrm{WE}(t))$} and is, under the conditions of Theorem~\ref{thm:brs}, given by
\begin{equation*}
	P(j|k,k_\mathrm{ref},\mathbf{p},\mathbf{x}^\mathrm{WE}(t)) = \!  \int\limits_{\gamma_{j}\left(k,k_\mathrm{ref},\mathbf{p},\mathbf{d}\left(\mathbf{x}^\mathrm{WE}(t)\right)\right)}^{\gamma_{j-1}\left(k,k_\mathrm{ref},\mathbf{p},\mathbf{d}\left(\mathbf{x}^\mathrm{WE}(t)\right)\right)} \rho(s)\,  \mathrm{d}s\,.
\end{equation*}
%\begin{equation*}
%	P_t(j|k,\mathbf{p},\mathbf{d}(\mathbf{x})) = \!  \int_{0}^{+\infty} \!\!\! \int_{\gamma_j(k,k_\mathrm{ref},\mathbf{p},\mathbf{d}(\mathbf{x}))}^{\gamma_{j-1}(k,k_\mathrm{ref},\mathbf{p},\mathbf{d(x)})} \!\!\!\!\!\!\!\!\!\!\!\!\\\rho(s)\eta_t(k,k_\mathrm{ref})\,  \mathrm{d}s\, \mathrm{d}k_{\mathrm{ref}} 
%\end{equation*}
Thus, the discrete-time evolution of the Karma level density function can be written as
\begin{equation*}
	\begin{split}
		&\eta_{t+1}(k,k_\mathrm{ref}) =  P_{\mathrm{home}}\eta_t(k,k_\mathrm{ref}) \\
		&+ P_{\mathrm{go}} \sum_{j = 1}^n P\left(j|k+\mathbf{p}_j,k_\mathrm{ref},\mathbf{p},\mathbf{x}^\mathrm{WE}(t)\right) \eta_t(k+\mathbf{p}_j,k_\mathrm{ref}),
	\end{split}
\end{equation*}
for $k, k_\mathrm{ref} \in \mathbb{R}_{\geq 0}$, and $t\in \mathbb{N}$. Moreover, the definition of the WE equilibrium in Definition~\ref{def:WE} can be rewritten as
\begin{equation}\label{eq:WE_cf} \small 
		\mathbf{x}^\mathrm{WE}_j(t) \!=\!
		P_\mathrm{go}\!\!\int\limits_{0}^\infty\! \!\int\limits_{0}^\infty \! \!P(j|k,k_\mathrm{ref},\mathbf{p},\mathbf{x}^\mathrm{WE}(t)) \eta_t(k,k_{\mathrm{ref}})\, \mathrm{d}k\,\mathrm{d}k_{\mathrm{ref}},\!\!
\end{equation}%
$j = 1,\ldots,n$.

It is important to point out two key aspects. First, note that only in the strict ordering conditions of Theorem~\ref{thm:brs}, it is possible to write a closed-form deterministic expression for $P_t(j|k,k_\mathrm{ref},\mathbf{p},\mathbf{d}(\mathbf{x}^\mathrm{WE}(t)))$. If they are not satisfied, it is only known that $P_t(j|k,k_\mathrm{ref},\mathbf{p},\mathbf{d}(\mathbf{x}^\mathrm{WE}(t)))$ is such that the aggregate decisions reconstruct the aggregate flows at the WE, which is portrayed in \eqref{eq:WE_cf}. Second, remark the discrete nature of the evolution of the Karma level density function, which is a linear combination of the previous density function shifted by $n$ fixed values that correspond to the arcs' prices. Thus, although continuous Karma levels were considered up to this point, a user $i$ with a given initial Karma level $k_0$, can only evolve to Karma levels that are of the form $k =k_0 + \sum_{j=1}^n m_j\mathbf{p}_j$ with $m_j \in \mathbb{N}_0$. This observation suggests that modeling the Karma level evolution of a single user as a Markov chain is appropriate.

{\color{black} Although there is a bounded attractive Karma level set, as mentioned earlier, the number of distinct Karma levels cannot be bounded even if $||\mathbf{p}||$ is bounded. Henceforth, to prevent that we consider that {$\mathbf{p}$ is a vector of integers, i.e.,} $\mathbf{p}\in \mathbb{Z}^n$. Nevertheless, it is important to recall that due to the positive scaling invariance of the prices and Karma levels on the user's decision, pointed out in Section~\ref{sec:bestresponse}, the precision of the prices can be chosen to be as high as desired by increasing $||\mathbf{p}||$, amounting to enforce $\mathbf{p}\in \mathbb{Q}^n$ in a computationally tractable manner.}

%However, the number of distinct Karma levels may grow infinitely large on the atractive Karma level set, depending on $\mathbf{p}$. To prevent that, henceforth, we consider that $\mathbf{p}\in \mathbb{N}^n$. 



\subsection{Stationary Markov Chain Model}

Consider a single user $i$ and assume that we are in the strict ordering conditions of Theorem~\ref{thm:brs}. Starting at a Karma level $k_0$, if $\mathbf{d}(\mathbf{x})$ is held constant, it is possible to propagate the possible Karma transitions and generate a finite Markov chain.  Let $\mathcal{K}(k_0,k^i_\mathrm{ref},\mathbf{p},\mathbf{x}) = \{k^i_1, \ldots, k^i_{|\mathcal{K}(k_0,k^i_\mathrm{ref},\mathbf{p},\mathbf{x})|}\}$ denote the state space of the chain and $\mathbf{A}(k_0,k^i_\mathrm{ref},\mathbf{p},\mathbf{x}) \in \mathbb{R}^{|\mathcal{K}(k_0,k^i_\mathrm{ref},\mathbf{p},\mathbf{x})| \times |\mathcal{K}(k_0,k^i_\mathrm{ref},\mathbf{p},\mathbf{x})| }$ the corresponding transition matrix in column-stochastic form, whereby the states are ordered by their corresponding Karma level. For the remainder of this subsection, the dependence of $\gamma_j$, $\mathcal{K}$, and $\mathbf{A}$ on $k_0$, $k^i_\mathrm{ref}$, $\mathbf{p}$, and $\mathbf{x}$ are dropped to alleviate the notation.
%Note that $k^i(0)$ need not be included in $\mathcal{K}(k^i(0),\mathbf{x})$. 

%For simplicity, assume, without loss of generality, that there is an unique communicating class in the Markov chain and consider the corresponding Markov subchain henceforth\footnote{If there is more than one communication class in the Markov chain, one can just consider multiple $k^i_\mathrm{ref}$, with the same value, but each with a distinct unique communication class,  each with a probability of occurrence }. Let $\mathcal{K}(k_0,k^i_\mathrm{ref},\mathbf{p},\mathbf{x}) = \{k^i_1, \ldots, k^i_{|\mathcal{K}(k_0,k^i_\mathrm{ref},\mathbf{p},\mathbf{x})|}\}$ denote the state space of the subchain and $\mathbf{A}(k_0,k^i_\mathrm{ref},\mathbf{p},\mathbf{x}) \in \mathbb{R}^{|\mathcal{K}(k_0,k^i_\mathrm{ref},\mathbf{p},\mathbf{x})| \times |\mathcal{K}(k_0,k^i_\mathrm{ref},\mathbf{p},\mathbf{x})| }$ the corresponding transition matrix in column-stochastic form, whereby the states are ordered by their corresponding Karma level. For the remainder of this subsection, the dependence of $\gamma_j$, $\mathcal{K}$, and $\mathbf{A}$ on $k_0$, $k^i_\mathrm{ref}$, $\mathbf{p}$, and $\mathbf{x}$ are dropped to alleviate the notation.
%Note that $k^i(0)$ need not be included in $\mathcal{K}(k^i(0),\mathbf{x})$. 

The entries of $\mathbf{A}$ can be expressed in closed-form by
\begin{equation*}
	\mathbf{A}_{uv}  = P_\mathrm{home}\mathbf{I} +  \begin{cases}
		0,  &\nexists j: k^i_v\!-\!k^i_u = \mathbf{p}_j\\
		P_\mathrm{go}\int\limits_{\gamma_{j}}^{\gamma_{j-1}} \rho(s)\,  \mathrm{d}s, & \exists j: k^i_v \!-\!k^i_u = \mathbf{p}_j\\
	\end{cases}.
\end{equation*}
Since $P_\mathrm{home}>0$,  the Markov chain is aperiodic. Note, however, that it is not necessarily irreducible, since there may exist more than one communication class. By the Perron-Frobenius Theorem \cite[Theorem~2.12]{Bullo2018}, it follows that the eigenvalue $\lambda=1$ is dominant but not necessarily simple. Denote the eigenvector associated with the eigenvalue $\lambda=1$ that corresponds to the stationary Karma distribution over  $\mathcal{K}$ of the Markov chain initialized in $k_0$ by $\boldsymbol{\pi}_{\infty}(k_0,k^i_\mathrm{ref},\mathbf{p},\mathbf{x})$. Notice that it corresponds to the limit of the power iteration of $\mathbf{A}$ initialized at the Karma level distribution with all probability concentrated in $k_0$. Finally, define the stationary arc selection matrix $\mathbf{P}(k_\mathrm{ref},\mathbf{p},\mathbf{x}) \in \mathbb{R}^{n \times |\mathcal{K}|}$ as the matrix whose entry $(u,v)$ is  given by $\mathbf{P}_{uv}(k_\mathrm{ref},\mathbf{p},\mathbf{x}) = P(u|k^i_v,k_\mathrm{ref},\mathbf{p},\mathbf{x})$. 

%Which is , is, thus, any column of the limit of the power iteration of $\mathbf{A}$  \cite[Theorem~2.13]{FB-LNS}. Notice that $\boldsymbol{\pi}_{\infty}(k_0,k^i_\mathrm{ref},\mathbf{p},\mathbf{x})$ is the stationary Karma distribution over  $\mathcal{K}$. 

%If the initial Karma level, $k_0$, is in $\mathcal{K}$, then it can reach every Karma level in that set. Furthermore, given that that Markov chain is a communicating class, it is irreducible. On top of that, if $P_\mathrm{home}>0$, then it is also aperiodic, and thus $\mathbf{A}$ is primitive. By the Perron-Frobenius Theorem \cite[Theorem~2.12]{FB-LNS}, it follows that the eigenvalue $\lambda=1$ is simple and dominant. The eigenvector associated with $\lambda=1$, denoted by $\boldsymbol{\pi}_{\infty}(k_0,k^i_\mathrm{ref},\mathbf{p},\mathbf{x})$, is, thus, any column of the limit of the power iteration of $\mathbf{A}$  \cite[Theorem~2.13]{FB-LNS}. Notice that $\boldsymbol{\pi}_{\infty}(k_0,k^i_\mathrm{ref},\mathbf{p},\mathbf{x})$ is the stationary Karma distribution over  $\mathcal{K}$. Finally define the stationary arc selection matrix $\mathbf{P}(k_\mathrm{ref},\mathbf{p},\mathbf{x}) \in \mathbb{R}^{n \times |\mathcal{K}|}$ as the matrix whose entry $(u,v)$ is  given by $\mathbf{P}_{uv}(k_\mathrm{ref},\mathbf{p},\mathbf{x}) = P(u|k^i_v,k_\mathrm{ref},\mathbf{p},\mathbf{x})$. 


\subsection{WE as an Aggregate Markov Chain}

In the previous subsection, we modeled the stationary behavior of a single user under the conditions of Theorem~\ref{thm:brs} as a Markov chain. Now, we analyze the aggregate of the Markov chains that model the stationary behavior of each user. More specifically, given that this model is distinct only for distinct $k_\mathrm{ref}$, the aggregate over the Karma reference distribution is taken. In that regard, on the Assumption~\ref{ass:WE_convergence}, in steady-state, \eqref{eq:WE_cf} can be rewritten as 
\begin{equation}\label{eq:WE_cf_mc}
	\begin{split}
		&\mathbf{x}^\mathrm{WE}_\infty \!=  \\
		&P_\mathrm{go} \!\int\limits_{0}^\infty \! \mathbf{P}(k_\mathrm{ref},\mathbf{p},\mathbf{x}^\mathrm{WE}_\infty)  \boldsymbol{\pi}_{\infty}(k_0,k_\mathrm{ref},\mathbf{p},\mathbf{x}^\mathrm{WE}_\infty)\theta_{\mathbf{p}}(k_{\mathrm{ref}})\, \mathrm{d}k_{\mathrm{ref}}.\!\!\!\!\!\!
	\end{split}
\end{equation}

\section{Pricing Design Problem}\label{sec:pricing_design}

The pricing design problem, formulated in Problem~\ref{prb:prices}, is now tackled on the following assumption:

\begin{assumption}\label{ass:ordering}
	Assume that, at the system optimum, there is an arc ordering such that  $\mathbf{d}_1(\mathbf{x}_1^\star) < \ldots < \mathbf{d}_n(\mathbf{x}_n^\star)$ is satisfied.
\end{assumption}

Under Assumptions~\ref{ass:WE}, \ref{ass:WE_convergence}, and \ref{ass:ordering}, the problem amounts to finding $\mathbf{p} = \mathbf{p}^\star$ such that \eqref{eq:WE_cf_mc} is satisfied for $\mathbf{x}^\mathrm{WE}_\infty = \mathbf{x}^\star$. Notice that without Assumption~\ref{ass:ordering}, neither $\mathbf{P}(k_\mathrm{ref},\mathbf{p},\mathbf{x}^\mathrm{WE}_\infty)$ nor  $\boldsymbol{\pi}_{\infty}(k_0,k_\mathrm{ref},\mathbf{p},\mathbf{x}^\mathrm{WE}_\infty)$ would be deterministic, which follows from the analysis in Section~\ref{sec:mesoscopic_aggregate}.
{It is important to} point out that first, the integer nature of $\mathbf{p}$, i.e. $\mathbf{p} \in \mathbb{Z}^n$, makes it challenging to solve \eqref{eq:WE_cf_mc}.
Second, the Karma reference distribution $\theta_\mathbf{p}(k_\mathrm{ref})$ depends on the pricing policy $\mathbf{p}$.
Third, not only do the entries of $\mathbf{P}(k_\mathrm{ref},\mathbf{p},\mathbf{x}^\mathrm{WE}_\infty)$ and  $\boldsymbol{\pi}_{\infty}(k_0,k_\mathrm{ref},\mathbf{p},\mathbf{x}^\mathrm{WE}_\infty)$ in  \eqref{eq:WE_cf_mc} depend nonlinearly on $\mathbf{p}$, but also the dimensions of the matrix and vector themselves change with $\mathbf{p}$.

To find the optimal prices, we enforce $\mathbf{1}^\top\mathbf{x}^{\star} = P_\mathrm{go}$, which via \eqref{eq:WE_cf_mc} only enforces {one constraint} on $\mathbf{p}$. The additional constraints stem from the fact that, at steady-state, the expected Karma level remains constant, hence $\mathbf{p}^{\star \top}\mathbf{x}^{\star} = 0$, and from the fact that the best response strategy is invariant on a positive scaling of prices and Karma distributions. Whilst these constraints were sufficient to design the optimal static prices for the 2-arc setting~\cite{SalazarPaccagnanEtAl2021}, for the general $n$-arc case under consideration we still need to find the optimal $\mathbf{p}^\star$ satisfying~\eqref{eq:WE_cf_mc} with $\mathbf{x}^\mathrm{WE}_\infty = \mathbf{x}^\star$, which, as mentioned above, is highly nonlinear and non-smooth. To the best of the authors' knowledge, these features make the derivation of a closed-form solution not feasible.


\subsection{Numerical Design Method}

{We leverage the structure of the problem to overcome the aforementioned difficulties and reframe the pricing design problem thoughtfully so that it can be solved efficiently. In this regard, we introduce three considerations to enable the numerical solution of~\eqref{eq:WE_cf_mc} for $\mathbf{p}$ with $\mathbf{x}^\mathrm{WE}_\infty = \mathbf{x}^\star$.} First, $\theta_\mathbf{p}(k_\mathrm{ref})$ has to be bounded and discrete to be numerically tractable. Note that this is a reasonable assumption since there is an attractive invariant Karma set and the Karma levels are discrete because $\mathbf{p}\in \mathbb{Z}^n$. Second, since $\mathbf{p} \in \mathbb{Z}^n$, the equality in \eqref{eq:WE_cf_mc} will not be achieved exactly. Instead, one may attempt to minimize {the deviation of the cost of the right-hand term w.r.t. the optimal aggregate flows.} Nevertheless, the larger $||\mathbf{p}||$ is allowed to be, the closer is the equality. Third, the constraint $(\mathbf{p}^\star)^\top\mathbf{x}^{\star} = 0$ may not be satisfied exactly if the entries of $\mathbf{x}^\star$ are irrational or if $||\mathbf{p}||$ is bounded. Thus, one can substitute it with a quantized  approximation $\mathbf{x}^\star_\mathrm{quant}$.

%\textcolor{red}{Maybe rephrase: remove greadient freee here / frame the probelmm ia way that it can  - bui d a story we Ã§evaerage the structure of the probelm - an the analytical analysis - the probelm is nonsmooth and nolinear -> one could leverage learning algorithms -> but scability - we fraem inb sucgh a way that instead of just say that we find the op+timum follows we find thw precise that results }Given the aforementioned difficulties, we employ a gradient-free numerical optimization method to thoughtfully solve~\eqref{eq:WE_cf_mc} for $\mathbf{p}$ with $\mathbf{x}^\mathrm{WE}_\infty = \mathbf{x}^\star$. 

Therefore, the proposed pricing design optimization problem {becomes:}

\begin{problem}[Numerical Pricing Design]\label{prb:prices_num}
	Given a desired system optimum $\mathbf{x}^\star$, select $\mathbf{p}$ as the solution to
\begin{equation}\label{eq:num_prob}
	\begin{split}
		%		&\mathop{\mathrm{minimize}}\limits_{\mathbf{p}\in \mathbb{N}^n}\\
		&	\!\!\!\!\!\!\!{\small \mathop{\mathrm{min}}\limits_{\mathbf{p}\in \mathbb{Z}^n} {C}\!\left(\!\!P_\mathrm{go}\!\!\!\!\!\sum\limits_{k_\mathrm{ref} = k_{\mathrm{ref}_{\mathrm{min}}}}^{k_{\mathrm{ref}_{\mathrm{max}}}}\!\!\!\!\!\!\! \mathbf{P}(k_\mathrm{ref},\mathbf{p},\mathbf{x}^\star) \boldsymbol{\pi}_{\infty}(k_0,k_\mathrm{ref},\mathbf{p},\mathbf{x}^\star)\theta_{\mathbf{p}}(k_{\mathrm{ref}})\! \!\right)}\\
		& \!\!\!\!\mathop{\mathrm{s.t.}}  \quad \mathbf{p}^\top\mathbf{x}^{\star}_\mathrm{quant} = 0\\
		& \!\!\!\! \phantom{\mathop{\mathrm{s.t.}}}\;\quad \mathbf{p}_j > \mathbf{p}_{j+1}, \, j = 1,\ldots, n-1\\
		& \!\!\!\!\phantom{\mathop{\mathrm{s.t.}}}\;\quad \mathbf{p}_1 > 0\\
		& \!\!\!\!\phantom{\mathop{\mathrm{s.t.}}}\;\quad \mathbf{p}_n < 0,
	\end{split}\!\!\!\!\!\!\!\!\!
\end{equation}
where $k_{\mathrm{ref}_{\mathrm{min}}}$ and $k_{\mathrm{ref}_{\mathrm{max}}}$ are the minimum and maximum values of the support of $\theta_\mathbf{p}$, respectively.
\end{problem}

Such a problem can be efficiently solved with gradient-free methods, as shown in Section~\ref{sec:num_res} below. Furthermore, a useful particularity of Problem~\ref{prb:prices_num} is that the minimum of the objective function is known and given by $C(\mathbf{x}^\star)$. Thus, it is easy to evaluate the suboptimality bound and stop the numerical method whenever it reaches a given threshold.
	
%	 the deviation of the cost of an iteration w.r.t. the minimum falling below a threshold can be employed as an effective stopping criterion.}
% 
% too hard setendce suboptimality bound

%\textcolor{blue}{A precise optimum criteria can be use to stop the iterations - also try x shot}
