% !TeX spellcheck = en_US
\section{Proof of Lemma~\ref{lem:feasibility}} \label{app:proof_feasibility}
%Problem~\ref{prb:individual} is feasible for a given karma level $k\geq 0$ iff there is at least one pair $(\mathbf{y},\bar{\mathbf{y}})$ that satisfies the constraints of the optimization problem.
If {\small $k \geq \max(0,k_\mathrm{ref}+(\min_j\mathbf{p}_j)(T+1))$}, then  $\mathbf{y} = \bar{\mathbf{y}} = \mathbf{e_{\mathop{\mathrm{argmin}}_j(\mathbf{p}_j)}}$ is feasible. Conversely, if the optimization problem is feasible, then there is at least one  pair $(\mathbf{y},\bar{\mathbf{y}})$ that satisfies the constraints. Given that {$ k-(T+1)\min_j\mathbf{p}_j \geq k-\mathbf{p}^\top \mathbf{y} - T\mathbf{p}^\top\bar{\mathbf{y}} \geq k_\mathrm{ref}$}
%\begin{equation*}
%k-(T+1)\min_j\mathbf{p}_j \geq k-\mathbf{p}^\top \mathbf{y} - T\mathbf{p}^\top\bar{\mathbf{y}} \geq k_\mathrm{ref}
% \end{equation*}
and $\min_j\mathbf{p}_j \leq \mathbf{p}^\top \mathbf{y} \leq k$,
%\begin{equation*}
%\min_j\mathbf{p}_j \leq \mathbf{p}^\top \mathbf{y} \leq k,
%\end{equation*}
the reciprocal is true and the result follows immediately.

\section{Proof of Theorem~\ref{thm:brs_general}} \label{app:proof_brs_general}

{Before proceeding with the proof it is worth pointing out the significance of sets $\mathcal{J}_u$ and $\mathcal{J}_e$. First, note that if, for a given arc $j$, there exists an arc $i$ with strictly lower discomfort and cost, then arc $j$ is never an integer solution, because choosing arc $i$ is still feasible and would always achieve lower cost. We denote the set of such unreasonable arcs as  $\mathcal{J}_u$. Second, note that the objective function of Problem~\ref{prb:individual} does not depend on the prices of the chosen arcs. In fact, if two arcs $i$ and $j$ have the same discomfort and both are feasible, then they are equally fit integer solutions. In that regard, one can attempt to consider only a set of arcs with unique discomforts and then extend the solution to the other equally fit arcs that have the same discomfort. In that regard, we define the set $\mathcal{J}_e$ of arcs that have repeated discomforts and have the highest prices. Thus, the set ${\{1,\ldots,n\} \setminus ( \mathcal{J}_u \cup  \mathcal{J}_e)}$ contains the arcs that are not unreasonable and have unique discomforts with the lowest price.}

Statement i) is proved by contradiction. Assume that $(\mathbf{e_{j^\star}},\bar{\mathbf{y}}^\star)$ is a solution with $j^\star \in \mathcal{J}_u$. It follows from the definition of $ \mathcal{J}_u$ that there is an arc $i \in \{1,\ldots,n\}$ such that $\mathbf{p}_i \leq \mathbf{p}_j$ and  $\mathbf{d}_i(\mathbf{x}_i) \!< \!\mathbf{d}_j(\mathbf{x}_j)$. Thus, since $(\mathbf{e_{j^\star}},\bar{\mathbf{y}}^\star)$ is feasible, $(\mathbf{e_i}, \bar{\mathbf{y}}^\star)$ must also be feasible. Additionally,  $s\, \mathbf{d}_i(\mathbf{x}_i)+ T\,\bar{s}\, \mathbf{d}(\mathbf{x})^\top \bar{\mathbf{y}}^\star < s\, \mathbf{d}_j(\mathbf{x}_j)+ T\,\bar{s}\, \mathbf{d}(\mathbf{x})^\top \bar{\mathbf{y}}^\star$, i.e., $(\mathbf{e_i}, \bar{\mathbf{y}}^\star)$ achieves a lower cost than $(\mathbf{e_{j^\star}}, \bar{\mathbf{y}}^\star)$, which is a contradiction.

% If \msmargin{$i,j \notin \mathcal{J}_u$}{explain what these sets are in words in the main text or here} and

To prove statement ii), consider $i,j \in \{1,\ldots,n\} : j<i$. Under the discomfort ordering assumption, $\mathbf{d}_i(\mathbf{x}_i) \geq  \mathbf{d}_j(\mathbf{x}_j)$. If $i,j \notin \mathcal{J}_u$ and $\mathbf{d}_i(\mathbf{x}_i) >  \mathbf{d}_j(\mathbf{x}_j)$, then $\mathbf{p}_i < \mathbf{p}_j$. If $i,j \notin \mathcal{J}_e$, then $\mathbf{d}_i(\mathbf{x}_i) >  \mathbf{d}_j(\mathbf{x}_j)$. Thus, if $i,j \notin \mathcal{J}_u \cup \mathcal{J}_e$, then $\mathbf{p}_i < \mathbf{p}_j$.

We now turn to the proof of statement iii). Assume that $(\mathbf{e_{q}}, \mathbf{\bar{y}^{q}})$ for some $q \in \{1,\ldots,Q\}$ is a solution to Problem~\ref{prb:individual} for aggregate flows $\{\mathbf{x}_j\}_{j\in \{1,\ldots,n\} \setminus ( \mathcal{J}_u \cup  \mathcal{J}_e) }$, and prices $\{\mathbf{p}_j\}_{j\in \{1,\ldots,n\} \setminus ( \mathcal{J}_u \cup  \mathcal{J}_e)}$, denoted for the remainder of this proof as the reduced problem. Then, the additional arcs available in Problem~\ref{prb:individual} for aggregate flows $\mathbf{x}$ and prices $\mathbf{p}$, denoted for the remainder of this proof as the original problem,  are those in the set $\mathcal{J}_u\cup\mathcal{J}_e$. Arcs in $\mathcal{J}_u$ were already proved to be unfeasible, according to statement i). Arcs in $\mathcal{J}_e$ have discomforts that are equal to the discomfort of one and only one arc in $\{1,\ldots,n\} \setminus ( \mathcal{J}_u \cup  \mathcal{J}_e)$, which has the lowest price due to the way $\mathcal{J}_e$ is defined. Thus, $(\mathbf{e_{q}}, \mathbf{\bar{y}^{q}})$ is also a solution to the original problem as well as any other arcs in $\mathcal{J}_e$ that achieve the same discomfort, i.e.,  $j\in \mathcal{J}_e: \mathbf{d}_j(\mathbf{x}_j) =\mathbf{d}_q(\mathbf{x}_q)$, and whose prices are still feasible, i.e., $j\in \mathcal{J}_e: k \geq \mathbf{p}_j \land k - \mathbf{p}_j -T\sum \nolimits_{i\in \{1,\ldots,n\} \setminus ( \mathcal{J}_u \cup  \mathcal{J}_e)} \mathbf{p}_i  \mathbf{\bar{y}^{q}}_i \geq k_{\mathrm{ref}}$. It remains to prove that all the solutions to the original problem are obtained, employing this procedure, from the solutions  $(\mathbf{e_{q}}, \mathbf{\bar{y}^{q}})$ with $q\in \{1,\ldots,Q\}$ to the reduced problem. Assume that $(\mathbf{e_{j^\star}},\mathbf{\bar{y}}^\star)$ is a solution to the original problem. It was already proved that $j^\star \notin \mathcal{J}_u$. Then, either $j^\star \in  \{1,\ldots,n\} \setminus ( \mathcal{J}_u \cup  \mathcal{J}_e) $ or $j^\star \in \mathcal{J}_e$. First, assume the former. It is immediate that $(\mathbf{e_{j^\star}},\mathbf{\bar{y}^q})$  is a solution of the reduced problem, where $\mathbf{\bar{y}^{q}}$ is obtained from $\mathbf{\bar{y}}^\star$ by adding together the entries corresponding to arcs with equal discomfort. Second, assume the latter, i.e., $j^\star \in \mathcal{J}_e$. Then, from the definition of $\mathcal{J}_e$, it follows that there is one and only one  $q^\star \in \{1, \ldots n\} \setminus ( \mathcal{J}_u \cup  \mathcal{J}_e) :\mathbf{d}_{q^\star}(\mathbf{x}_{q^\star}) = \mathbf{d}_j(\mathbf{x}_j) \land \mathbf{p}_{q^\star} \leq\mathbf{p}_j$. It follows that $(\mathbf{e_{q}}, \mathbf{\bar{y}^{q}})$ is a solution to the reduced problem, since the condition $\mathbf{p}_{q^\star} \leq\mathbf{p}_j$ ensures that it is feasible, where $\mathbf{\bar{y}^{q}}$ is obtained as previously described. 


\section{Proof of Theorem~\ref{thm:brs}} \label{app:proof_brs}

Problem~\ref{prb:design} is a mixed-integer linear programming (MILP) optimization problem. To obtain a closed-form solution, the following procedure is employed: We start by assuming the integer part of the solution is known, i.e, $\mathbf{y}^\star = \mathbf{e_j}$ for some $j\in \{1,\ldots,n\}$, and then we compute the optimal non-integer variables, denoted by $\mathbf{\bar{y}_j^\star}$, assuming that integer decision, which reduces to a linear programming (LP) optimization problem. The solution is, afterwards, given by the pair $(\mathbf{e_j},\mathbf{\bar{y}_j^\star})$ that achieves the lowest cost.

First, assume that $\mathbf{y}^\star = \mathbf{e_j}$ for some $j\in \{1,\ldots,n\}$. Note that all $j$ that do not satisfy $\mathbf{p}_j \leq k \land k \geq k(j,n)$ can be immediately discarded, because at least one of the constraints \eqref{eq:singleAgentAverage_c1} and  \eqref{eq:singleAgentAverage_c2} is not satisfied. The problem is, thus, reduced to an LP given by
\begin{subequations}\label{eq:singleAgentLP}
\begin{align}
	\mathbf{\bar{y}_j^\star} \in \mathop{\mathrm{argmin}}_{\bar{\mathbf{y}}  \in [0,1]^n} \;& \mathbf{d}(\mathbf{x})^\top \bar{\mathbf{y}}\\ \label{eq:singleAgentLP_c1}
	\mathrm{s.t.}\;\; &k-\mathbf{p}_j- T\mathbf{p}^\top\bar{\mathbf{y}} \geq k_\mathrm{ref}\\ \label{eq:singleAgentLP_c2}
	&\mathbf{1}^\top \bar{\mathbf{y}}  =  1  \,.%\\
	%&\bar{\mathbf{y}}  \in [0,1]^n\,.
\end{align}
\end{subequations}
Note that cost function of the LP is simply the inner product of $\mathbf{d}(\mathbf{x})$ and $\bar{\mathbf{y}}$. Introduce constraint $\mathbf{1}^\top\bar{\mathbf{y}} = 1$ to eliminate $\bar{\mathbf{y}}_a$, for some $a\in \{1,\ldots,n\}$, in the cost function and in the inequality \eqref{eq:singleAgentLP_c1}, which yields 
\begin{equation}\label{eq:proof_brs_karma_cost}
\mathbf{d}_a(\mathbf{x}_a) + \sum_{\substack{i = 1\\i\neq a}}^n \bar{\mathbf{y}}_i(\mathbf{d}_i(\mathbf{x}_i)-\mathbf{d}_a(\mathbf{x}_a))
\end{equation}
and
\begin{equation}\label{eq:proof_brs_karma_constr}
\sum_{\substack{i = 1\\i\neq a}}^n \bar{\mathbf{y}}_i(\mathbf{p}_i-\mathbf{p}_a) \leq  \frac{k-k(j,a)}{T},
\end{equation}
respectively. Now we disregard $\bar{\mathbf{y}}_a$ and solve the LP in the $n-1$ dimensional space of the remaining components of $\bar{\mathbf{y}}$. 

We start by noting that there is a solution $\mathbf{\bar{y}^\star_j}$ that has, at most, two non-zero entries. Equivalently, there exists at least one  $a \in \{1,\ldots,n\}$ such that the solution of the $n-1$ dimensional LP is along an axis in a Cartesian frame. This statement can be proved by contradiction. Assume that, for any $a \in \{1,\ldots,n\}$ no solution is along the axes. Consider only one, $a_1 \in \{1,\ldots,n\}$. Because it is an LP optimization problem, a solution must lie in one of the vertices of the  polytope whose faces are defined by $ \bar{\mathbf{y}}_i \geq 0, \forall i \in \{1,\ldots,n\}\setminus \{a_1\}$,  \eqref{eq:proof_brs_karma_constr}, and
\begin{equation}\label{eq:proof_brs_sum_constraint}
\sum_{\substack{i = 1\\i\neq a_1}}^n \bar{\mathbf{y}}_i \leq 1.
\end{equation}
A vertex is, thus, at the intersection of $n-1$ hyperplanes defined by the boundary of these constraints. The only combination of $n-1$ hyperplanes that yields a vertex that is not along the axis is of $n-3$ hyperplanes of the form $ \bar{\mathbf{y}}_i = 0,  i \in \{1,\ldots,n\}\setminus \{a_1\}$ and those defined by the boundaries of \eqref{eq:proof_brs_karma_constr} and \eqref{eq:proof_brs_sum_constraint}. Therefore, \eqref{eq:proof_brs_sum_constraint} is an active constraint of the solution, which is of the form 
\begin{equation}\label{eq:proof_brs_one_sol_contradiction}
\bar{\mathbf{y}}_i = \begin{cases}
	K,  &i = u\\
	1-K,  & i = v\\
	0,  &i\notin \{a_1,u,v\}
\end{cases}, i \in \{1,\ldots,n\}\setminus\{a_1\}
\end{equation}
for some $K\in (0,1)$, and some $u,v \in  \{1,\ldots,n\}\setminus\{a_1\}$. So the solution of the initial $n$ dimensional LP is given by \eqref{eq:proof_brs_one_sol_contradiction} and $\bar{\mathbf{y}}_{a_1} = 0$. Now consider $a_2 = u$. In the new $n-1$ dimensional LP obtained by eliminating $\bar{\mathbf{y}}_{a_2}$, the solution is along the axis of the Cartesian frame, which is a contradiction.

%Now that it is know that, for some $a \in \{1,\ldots,n\}$, a solution is in the axis of the Cartesian frame, 
Now, one can choose, for a given and fixed $j$, among all the vertices of the polytope along the axes for all  $a \in \{1,\ldots,n\}$ the one that yields the lowest cost, which is guaranteed to be a solution. For a given $a$ there can be three different types of vertices: at the origin and at the intersection of the boundary hyperplane of either \eqref{eq:proof_brs_karma_constr} or  \eqref{eq:proof_brs_sum_constraint} with the axes. The intersection of the boundary hyperplane \eqref{eq:proof_brs_sum_constraint} with an axis of coordinate $\bar{\mathbf{y}}_i$ would be the same solution as the origin in the $(n-1)$ dimensional LP with $a=i$, hence these types of vertices can be disregarded since they are captured for another $a$. Also, a vertex at the origin, for which constraint \eqref{eq:proof_brs_karma_constr} is not active, cannot be a solution if $a\neq 1$, because a non-null increase in $\bar{\mathbf{y}}_j$ with $j<i$ would still satisfy \eqref{eq:proof_brs_karma_constr} and decrease the cost \eqref{eq:proof_brs_karma_cost}. Nevertheless, if $a= 1$ and the origin satisfies \eqref{eq:proof_brs_karma_constr}, i.e., $k \geq k(j,1)$, then $\mathbf{\bar{y}_j^\star} = \mathbf{e_1}$. Henceforth, we are only interested in the intersections of the boundary hyperplane of  \eqref{eq:proof_brs_karma_constr} and the axes when $k \leq k(j,1)$. Such an intersection with  the axis of coordinate $\bar{\mathbf{y}}_i$ is defined by 
\begin{equation*}
\bar{\mathbf{y}}_i = \frac{( k-k(j,a))}{T(\mathbf{p}_i-\mathbf{p}_a)}.
\end{equation*}
Note that such intersection must satisfy 
\begin{equation}\label{eq:proof_brs_feas_region_a}
0 \leq  \frac{( k-k(j,a))}{T(\mathbf{p}_{i} -\mathbf{p}_a)} \leq 1.
\end{equation}
If $i < a$, \eqref{eq:proof_brs_feas_region_a} it is equivalent to $k(j,a)  \leq k \leq k(j,i)$. Conversely, if $i > a$  \eqref{eq:proof_brs_feas_region_a} it is equivalent to $ k(j,i) \leq  k \leq k(j,a)$. Given that $k(j,a) < k(j,i)$ for $i < a$ and $k(j,a) > k(j,i)$ for $i> a$, then  \eqref{eq:proof_brs_feas_region_a} is equivalent to $ \min(k(j,a),k(j,i)) \leq  k \leq \max(k(j,a),k(j,i))$. For fixed $a$, the cost \eqref{eq:proof_brs_karma_cost} is thus minimized at the intersection with the axis of the coordinate $\hat{j}_a$, given by \eqref{eq:j_hat}.
For $k < k(j,n)$, then the integer choice $j$ is unfeasible, according to Lemma~\ref{lem:feasibility}. Thus, for a fixed $j$, under feasibility, the solution to the LP  is 
\begin{equation*}
\mathbf{\bar{y}_j}^\star := \begin{cases}
	\mathbf{\bar{y}}^\star(j,\hat{a}), \, & k < k(j,1)\\
	\mathbf{e_1}, \, & k \geq k(j,1)
\end{cases},
\end{equation*}
where 
\begin{equation*}
\mathbf{\bar{y}}^\star({j,a}) :=    \frac{k-k(j,a)}{T(\mathbf{p}_{\hat{j}_a}-\mathbf{p}_a)}\mathbf{e_{\hat{j}_a}} -  \left(1-\frac{k-k(j,a)}{T(\mathbf{p}_{\hat{j}_a}-\mathbf{p}_a)} \right)\mathbf{e_a},
\end{equation*}
which can be rewritten as \eqref{eq:y_j_a_star}, and $\hat{a}$ is a component of $\bar{\mathbf{y}}$ that, when eliminated in the $n$ dimensional LP, places a solution along the axes of the space of the remaining variables. Therefore, $\hat{a}$ is given by \eqref{eq:a_hat}.

Now that, for each integer decision $\mathbf{y}^\star = \mathbf{e_j}$, 	a solution to the non-integer component is known and given by $\mathbf{\bar{y}_j}^\star$, the solution to the original MILP is the pair $(\mathbf{y}^\star = \mathbf{e_j},\mathbf{\bar{y}_j}^\star), j \in \{1,\ldots,n\}$ that achieves the lowest cost, which is given by \eqref{eq:singleAgentAverage_cost}. Consider two integer decisions $\mathbf{e_j}$ and $\mathbf{e_i}$ with $i,j\in\{1,\ldots,n\}: i<j$. If both are feasible, i.e., if $k \geq \max(0,\mathbf{p}_i,k(i,n))$, the decision of choosing $\mathbf{e_i}$ over $\mathbf{e_j}$ achieves lower or equal cost when $s/\bar{s} \leq \gamma_{i,j}$, where
\begin{equation*}
\gamma_{i,j} := \frac{T\mathbf{d}(\mathbf{x})^\top(\mathbf{\bar{y}_i}^\star-\mathbf{\bar{y}_j}^\star)}{\mathbf{d}_i(\mathbf{x}_i)-\mathbf{d}_j(\mathbf{x}_j)}.
\end{equation*}
If $k \geq \max(0,\mathbf{p}_i,k(i,n))$, the convention  $\gamma_{i,j} := \infty$ is adopted, yielding \eqref{eq:gamma_ij}. Then $\mathbf{e_{j^\star}}$ is an integer solution if $s/\bar{s}$ is such that $j$ is chosen over every $i \in \{j+1,\ldots,n\}$, i.e., $s/\bar{s} \geq \underline{\gamma}_j$, it is chosen over every $i \in \{1,\ldots,j-1\}$, i.e., $s/\bar{s} \leq  \bar{\gamma}_j $, and $\bar{\gamma}_j < \underline{\gamma}_j , s/\bar{s} < \underline{\gamma}_j$. This proves the sufficiency of the conditions for $j$ to be a solution. The necessity is immediate since, if $ \bar{\gamma}_j < \underline{\gamma}_j , s/\bar{s} < \underline{\gamma}_j$, or {$s/\bar{s} >  \bar{\gamma}_j$}, $\mathbf{e_j}$ cannot be an integer solution. 
%If $k \leq \min(0,k(i,n))$, the convention  $\gamma_{i,j} := +\infty$ is adopted, yielding \eqref{eq:gamma_ij}. Then $j^\star$ is a solution if $s/\bar{s}$ is such that $j$ is chosen over every $i \in \{j+1,\ldots,n\}$, i.e. $s/\bar{s} \geq \underline{\gamma}_j :=  \max_{i\in \{j+1,\ldots,n\}} \gamma_{j,i}$, it is chosen over every $i \in \{1,\ldots,j-1\}$, i.e. $s/s \leq  \bar{\gamma}_j :=\min_{i\in \{1, \ldots,j-1\}}  \gamma_{i,j}$, and $\bar{\gamma}_j < \underline{\gamma}_j , s/\bar{s} < \underline{\gamma}_j$. This proves the sufficiency of the conditions of ii) for $j$ to be a solution. The necessity is immediate since, if $ \bar{\gamma}_j < \underline{\gamma}_j , s/\bar{s} < \underline{\gamma}_j$, or $s/s \leq  \bar{\gamma}_j$, $j$ cannot be a solution. 

%\msmargin{$k \leq \min(0,k(i,n))$}{Are you sure? $k\geq 0$ by definition...},