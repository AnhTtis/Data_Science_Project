%\documentclass[main.tex]{subfiles}
\label{sec:results}
%\begin{document}

\subsection{Well-defined executions}

We start with a basic result on the consistency of an execution as defined by the algorithm.

\begin{lem}\label{lem:welldefined}
Any signal trace of an execution has at most finitely many value-changes within a finite time interval; it is thus a well-defined signal trace.
\end{lem}
\begin{proof}
Assume by contradiction that a signal trace has infinitely many value-changes within a finite interval $[t,t'] \subset \IR$.
By consistency of prefixes of executions, this implies that the algorithm returns
  an execution with infinitely many value-changes when setting $T = t'$.

In the algorithm, at any point in time $\tau$ there is at most one action per non-input signal in the set of scheduled actions and at most bounded many actions per input signal until time $T$.
Observing that there is a minimum propagation delay $d_{\min} > 0$ for signal values $0$, $1$, and $\meta$, any newly scheduled action must occur at earliest at time $\tau + d_{\min}$.
Thus, only bounded many actions occur within $[\tau,\tau + d_{\min}]$.
The statement follows.\qed
\end{proof}

\subsection{A transient-fault insertion tool}

To study the effect of short transient faults on the behavior of circuits we extend the algorithm from Section~\ref{sec:model} to allow the insertion of external events: signal transitions from a set of \emph{external events} are applied at the end of step~3.
Step~5 is changed to include external events when updating time~$t$ to the time of the next event.
A transient fault then corresponds to two subsequent signal transitions of the same signal in the set of external events in our model.
This is less general than transient faults in physical implementations, where a transient fault, e.g., induced by an additional charge due to a particle hit, can lead to a single early transition by happening just before a valid signal transition.
The assumption, however, is conservative in the sense that we assume that such a charge is small enough to lead to a pulse, i.e., double transition, potentially violating a gate's stability condition: in fact we will later in Section \ref{sec:equivalence-transient-faults} assume that transient faults are not necessarily full-swing binary pulses and have value $\meta$ in our model.

We have implemented the algorithm in Python and shall discuss results for a widely-used QDI circuit component, a linear pipeline, in the following.
% add when available: and made it available via (link).

\paragraph{Linear pipeline}
To study the susceptibility of QDI circuits to transient faults, we used the tool to insert short pulses (glitches) at different times.
As a prototypical QDI circuit, we used the linear 3-stage Muller pipeline shown in Figure~\ref{fig:muller3_linear}. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\columnwidth]{figs/muller3_linear.pdf}
    \caption{Linear Muller pipeline with 3 stages. The delays are set to 1 ({\tt INV2, INV3}), 5 (C gate), 4 (source delay = {\tt INV1}), and 4 (sink delay = {\tt INV4}).}
    \label{fig:muller3_linear}
\end{figure}

Delays have been uniformly set to 1 for the two pipeline inverters {\tt INV2} and {\tt INV3}, to 5 for all Muller C-elements ({\tt MCE1} to {\tt MCE3}), and 4 for the leftmost inverter {\tt INV1} and the rightmost inverter {\tt INV4}, which model the source and sink of the pipeline, respectively. 
%
Figure~\ref{fig:trace} shows an execution prefix until time $T=32$ in absence of transient faults, generated by our tool.
%
\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\columnwidth]{figs/trace-muller-linear.pdf}
    \caption{Execution prefix of linear 3-stage pipeline until time $T=32$.}
    \label{fig:trace}
\end{figure}
%
Figures~\ref{fig:trace-glitch} and \ref{fig:trace-glitch-ii} show execution prefixes of the same circuit until time $T=32$ when a glitch of width $0.1$ is inserted at the same signal, {\tt c2}, at different points in time:
  the intervals during which a signal has value $\meta$ are marked in red.
One observes that the behavior is different in presence of the glitch, as detailed in the following.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\columnwidth]{figs/trace-muller-linear-glitch.pdf}
    \caption{Execution prefix of linear 3-stage pipeline until time $T=32$ with glitch of width $0.1$ inserted at time $10$ at signal {\tt c2}.}
    \label{fig:trace-glitch}
\end{figure}

\emph{Non-masked glitch.} In Figure~\ref{fig:trace-glitch}, the glitch occurs at the input of the MCE while it is in storage mode, i.e., non-matching inputs. Since the other stable input {\tt en3} is at a different logic level than the MCE output {\tt c3}, the $\meta$ value is generated at the latter signal, and subsequently propagates through the circuit.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\columnwidth]{figs/trace-muller-linear-glitch-ii.pdf}
    \caption{Execution prefix of linear 3-stage pipeline until time $T=32$ with glitch of width $0.1$ inserted at time $22$ at signal {\tt c2}.}
    \label{fig:trace-glitch-ii}
\end{figure}

\emph{Masked glitch.} By contrast, the glitch in Figure~\ref{fig:trace-glitch-ii} occurs at the MCE input while in combinational mode, i.e., matching inputs. The glitch is masked at the output {\tt c3}, but the $\meta$ value appears for a short period of time at {\tt en1} (since an inverter propagates its input value). During this time span, the $\meta$ value appeared and disappeared while the other MCE was also in combinational mode, hence was prevented from propagating the unstable value further in the circuit. 


\paragraph{Susceptibility to transient faults}
The two different behaviors raise the question of when a QDI circuit like the linear pipeline can mask glitches successfully, and when it is susceptible to them.
To address that, we relate susceptibility to the occurrence of glitches at signals of particular interest (typically the output signals to the environment).
We call these signals of interest the \emph{monitored signals}.
For example, in the linear pipeline, signals {\tt c1} and {\tt c3} are the outputs to the environment represented by the source on the left and the sink on the right.

In general, let $C$ be a circuit, and $i$ an input signal trace.
Let $M \subseteq \calL \cup \calO$ be the set of monitored signals.
Then, $(C,i)$ is \emph{susceptible to a glitch (of width $w$) at signal $s \in \calI \cup \calL \cup \calO$ at time $t$}, if there exists a signal $m \in M$ and a time $t'$ such that in the execution, induced by the circuit $C$ and the input signal traces $i$ and with a glitch (of width $w$) at signal $s$ and time $t$, it is $m(t') = \meta$.

Revisiting the example of the linear pipeline, and letting $M = \{{\tt c1}, {\tt c3}\}$ be the set of monitored signals, the pipeline with its input is susceptible to a glitch (of width $0.1$) at signal {\tt c2} at time $10$, but not at time $22$ (see Figures \ref{fig:trace-glitch} and \ref{fig:trace-glitch-ii}).

This directly leads to the question of the sensitivity windows, i.e., the times when a circuit with an input is susceptible and when not.
Related, if combined with a probability measure on faults occurring at these times, one may ask how likely a transient fault is to cause a glitch at a monitored signal.
We address both questions in the following.


\subsection{Equivalence of transient faults}
\label{sec:equivalence-transient-faults}

While the previous tool allows one to sample the susceptibility at particular times, such an approach has several drawbacks: (i) it is time consuming to generate such sweeps and (ii) small susceptible windows may be overlooked.

In the following we present an alternative approach that relies on showing the equivalence between certain transient faults.
We begin the analysis with a definition.
We say \emph{signal $s$ has a pulse at time $t$ of width $w > 0$} if $s$ changes value at time $t$, remains constant within time $[t,t+w)$, and changes value at time $t+w$.
A $v$-pulse, with $v \in \BX$, is a pulse that has value $v$ during $[t,t+w)$.
We speak of a \emph{transient fault} as an $\meta$-pulse that has width of at most some predefined small $\gamma > 0$.

We are now ready to show a monotonicity property of the value $\meta$ in executions: If transient faults are added to a circuit's execution, the resulting execution differs from the original one at most by turning Boolean values into $\meta$.
For example, a transient fault may not result in a later 0-1 transition.

\begin{thm}[Monotonicity of $\meta$]\label{thm:monotonicity}
Let $C$ be a circuit and $i$ be input traces.
Let~$e$ be the execution induced by circuit~$C$
  and input traces~$i$,
  and $e'$ the execution induced by circuit $C$
  and input $i$ in presence of transient faults.
Then for all signals $s$ and times $t$,
if $s(t) \in \IB$ in~$e'$, then~$s(t)$
  is identical in~$e$ and~$e'$.
\end{thm}
\begin{proof}
Assume, by means of contradiction, that the statement does not hold and let $t$ be the smallest time at
which executions~$e$ and~$e'$ do not fulfill the theorem's statement.
Then there is a signal $s$ such that $s(t) = b \in \IB$
  in execution $e'$ and $s(t) = v \neq b$ in execution~$e$.
We distinguish between two cases for value~$v$:

\medskip

Case $v = \meta$.
If so, in execution $e$, signal $s$ was set to $\meta$
  at some time $\tau \leq t$, and not set again
  within $[\tau,t]$.
By minimality of $t$, and the definitions of $e$ and $e'$,
  $s$ was also set to $\meta$ in $e'$ at time $\tau$ (or earlier).
It follows that in execution $e'$,
  signal $s$ was set to $b$ within $(\tau,t]$.
This implies that a rule with guard $G$ and action $s = b$ was triggered at a time before $t$, and thus
$G$ was true in execution $e'$.
By minimality of $t$ and the definitions of $e$ and $e'$,
  $G$ must have been also true in $e$, resulting in the
  same action being scheduled also in $e$;
  a contradiction to the assumption that $v = \meta$.

\medskip

Case $v = \neg b$.
If so, $s$ was set via two different rules in~$e$ and~$e'$ and not set to another value until time $t$.
This implies that mutually exclusive guards have evaluated to $1$ in $e$ and $e'$ before time $t$; a contradiction to the minimality of $t$ in combination with the theorem's statement.

\medskip

The theorem's statement follows in both cases.\qed
\end{proof}

We next define time intervals that play a central role in a circuit's behavior in presence of transient faults.

Given a circuit $C$ and an execution $e$ of $C$,
the \emph{set of value switching times}, $V_{C}(e)$, is the set of times $\tau_0 = 0, \tau_1, \dots$ at which a signal in execution $e$ switches value.
A \emph{value region of execution $e$} is an interval $[t,t') \subset \IR$, where $t,t'$ are consecutive value switching times of execution $e$.
A \emph{postfix of a value region $[t,t')$} is a (potentially empty) interval $[t'',t') \subseteq [t,t')$.


\begin{thm}\label{thm:main}
Let $C$ be a circuit,
$i$ be input traces,
$\gamma > 0$ the width of a transient fault,
and $\varepsilon > 0$ the propagation delay of
  value $\meta$.
Let $e$ be the execution induced by circuit $C$
  and input traces~$i$.
  
Then, for a signal~$s$ of the circuit, 
  and a value region $R$ of execution $e$,
  the set $\Sigma_s(R)$ of times $t \in R$ such that $(C,i)$ is susceptible to a transient fault (of width $\gamma$) at signal $s$ at time $t \in R$ converges to a postfix of $R$ as $\varepsilon \to 0$ and $\gamma \to 0$.
\end{thm}

This means that every value region can be split into two intervals per signal: the left part of the region that contains the times at which the circuit
is not susceptible, and the right part where it is susceptible to faults.
Either part/interval can be empty.

\paragraph{Proof}
In the following fix $C$, $i$, $\gamma$, $\varepsilon$, execution $e$, signal $s$, and value region $R$ of execution $e$.
We first show a monotonicity property within a value region.

\begin{lem}\label{lem:tau1M-to-tau2M}
Let $R = [t,t')$ be a value region of execution $e$ and
  $s$ a signal.
Further, let $e_1$ and $e_2$ be executions of $C$
  with the same input traces as $e$, but with
  $e_1$ additionally having transient faults within $R$ at $s$ up to some time $\tau_1 \in R$ and $e_2$
  having at least one transient at a time $\tau_2 \in R$ at $s$, where $\tau_1 \leq \tau_2 \leq t' - |C| \varepsilon - \gamma$.

Then for all value regions $R'$ of execution $e$ and all signals $s'$, if~$s'$ has value $\meta$ at some time within $R'$ in execution $e_1$, then it does so at some time within $R'$ in execution $e_2$.
\end{lem}
\begin{proof}
Within the same value region, both transient faults
  cause the same signals to become $\meta$, given that $\tau_1,\tau_2$ are sufficiently far from the value region's boundary $t'$ to allow for propagation of $\meta$ with delay $\varepsilon$ (at most $|C|\varepsilon$ time):
  this follows from the fact that the circuit's signal
  values and set of scheduled actions are identical at the start of the first transient in $e_1$ and in $e_2$.

Further, a signal with value $\meta$ remains so unless it
  is set again to a Boolean value by a production rule.
This can only happen by its guard becoming true right after a transient fault.
Since, $\tau_1 \leq \tau_2$, and both times are in the same
  value region, any event scheduled (and not canceled) after the transient fault at $\tau_2$ must also be scheduled (and not canceled) after the transient faults that occur until time $\tau_1$:
  signals have the same Boolean values and remain stable for a longer time in $e_1$ than in $e_2$.

The argument is inductively repeated for each subsequent value region of execution $e$.\qed
\end{proof}

We are now in the position to show the section's main result.

\begin{proof}[Proof of Theorem \ref{thm:main}]
Letting $\varepsilon \to 0$ and $\gamma \to 0$, we have from Lemma \ref{lem:tau1M-to-tau2M} that if a transient fault at a signal $s$ at a time $\tau_1 \in R$
  that causes $\meta$ at a signal $s'$ then a transient fault at a signal $s$ at a time $\tau_2 \in R$, where $\tau_1 \leq \tau_2$, also causes $s'$ to become $\meta$ at some point in time.
The theorem's statement then follows from the definition of a postfix of $R$.\qed
\end{proof}

\subsection{Automated computation of susceptible regions}\label{sec:tool}

Theorem \ref{thm:main} directly leads to an algorithm that marks all
  sensitivity windows, i.e., susceptible times, within an execution prefix:
  for each non-output signal $s$, and for each value region $R$, it finds
  per bisection of repeatedly inserting transient faults
  the boundary of non-susceptible times (on the left within $R$)
  and susceptible times (on the right within $R$).
The algorithm's time complexity is determined by one bisection per region (with precision $\varepsilon > 0$), i.e., $\sum_R \log \frac{|R|}{\varepsilon}$, as opposed to a naive search that injects a fault every $\varepsilon > 0$ with a complexity inversely proportional to $\varepsilon$.
Moreover, the naive algorithm may miss susceptibility windows smaller than $\varepsilon$, while our algorithm provably finds all such windows.

To test the algorithm's use on typical circuit instances we have implemented it in Python \cite{github:async-and-faults}:
  %(add link when available)
  given a circuit, input traces, the set of monitored signals,
  as well as a time $T$ until which an execution
  prefix is to be generated, it outputs a figure with all
  susceptible windows highlighted in blue as well as the percentage of
  the length of the susceptible windows in the execution prefix
  (by default excluding the monitored signals, but with the possibility to include them).
This value corresponds to the probability of a transient fault causing
  an $\meta$ value at a monitored signal, i.e., \emph{the probability to fail} $P(\text{fail})$, given a uniform distribution
  of a single transient on all times in the execution prefix and
  on all signals that are not monitored signals (by default; alternatively on all signals).
Clearly, though, the uniform distribution can be easily
  replaced by a more involved distribution.
Towards this direction, the tool also outputs the probability per signal.
This allows one to compute a weighted average, e.g., depending on driver strength
  or shielding at certain signals.
Figure \ref{fig:trace-check} shows the tool's output for the previous example
  of the 3-stage linear pipeline with sensitivity windows marked in blue.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\columnwidth]{figs/trace-muller-linear-check.pdf}
    \caption{Execution prefix of linear 3-stage pipeline until time $T=32$ with sensitivity windows marked in blue. Monitored signals are {\tt c1} and {\tt c3}.
    Here, $P(\text{fail}) = 0.54375$.}
    \label{fig:trace-check}
\end{figure}

A fault occurring at any point of the blue sensitivity windows will drive one (or more) of the circuit's monitored signals to~$\meta$. A fault hitting any other region (excluding the monitored signals) will be masked and will not reach the monitored signals of the circuits.
Observe that in this example all sensitivity windows are trivial postfixes of regions: a region is either fully non-susceptible or susceptible; in general this does not necessarily hold.

\subsection{Comparison of fault-tolerance depending on speed}\label{sec:linear}

We next illustrate the use of our tool for a linear pipeline, where we vary the source and sink latencies.
Inverter delays are symmetric and normalized to~1 and Muller C-element latencies are set to~5 inverter delays.
The results are shown in Figure~\ref{fig:muller3_sweep_3dplot}, with cuts in Figures~\ref{fig:muller3-sweepSink} and~\ref{fig:muller3-sweepSource}. 
The length of the execution prefix has been chosen sufficiently high, to account for a sufficiently long time for $P(\text{fail})$ to be dominated by the periodic operation of the circuit rather than the initial transient phase: $T=500$ in the overview plot and $T=1000$ in the detailed sweeps.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.3\columnwidth]{figs/muller3_sweep_3dplot.png}
    \vspace{-0.2cm}\caption{Influence of source and sink speed on $P(\text{fail})$. Linear 3-stage pipeline with delays as follows: 1 ({\tt INV}), 5 ({\tt MCE}), varying source and sink delays. $T = 500$.}
    \label{fig:muller3_sweep_3dplot}
\end{figure}


\begin{figure}
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figs/muller3_sweepSink.png}
        % first figure itself
        \vspace{-0.2cm}\caption{Influence of sink speed on $P(\text{fail})$. Linear 3-stage pipeline with delays: 1 ({\tt INV}), 5 ({\tt MCE}), 4 different source delays, varying sink delay. $T=1000$.}
        \label{fig:muller3-sweepSink}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figs/muller3_sweepSource.png} 
        % second figure itself
        \vspace{-0.2cm}\caption{Influence of source speed on $P(\text{fail})$. Linear 3-stage pipeline with delays: 1 ({\tt INV}), 5 ({\tt MCE}), 4 different sink delays, varying source delay. $T=1000$.}
        \label{fig:muller3-sweepSource}
    \end{minipage}
\end{figure}


Figure~\ref{fig:muller3_sweep_3dplot} shows an overview of the behavior of the circuit under a stable environment, be it fast or slow, and how the circuit reacts when there is an unbalance between the speeds of source and sink. The $z$-axis displays the probability of an~$\meta$ value presence at any of the monitored signals. The $x$ and $y$-axes represent the speeds (latencies) of sink and source, respectively, in time units. The pattern of the plot is best visualized when having the latter axis inverted.
The diagonal of the frame where both sink and source latencies are equal to 1 (fast) to where they are both 25 (slow) represents the stable/balanced environment, i.e., the source provides \emph{tokens} with the same speed as the sink provides the \emph{acknowledgment}. The figure indicates that $P(\text{fail})$ is high when the environment is stable and fast, and decreases as it gets stable and slow. When the environment is balanced, the MCEs in the circuit are not waiting for either the \emph{data} or the \emph{ack} signals; both are supplied within short intervals of time from each other. Since the waiting phases are those where the MCE operates in the vulnerable storage mode (inputs mismatching), one observes that reducing the waiting period decreases $P(\text{fail})$.

The environment imbalance is divided further into 2 modes of operation. On the right side (for relatively low source delay) of the figure, the circuit is operating in \emph{bubble-limited} mode, where the sink's response to the source's new tokens is slow. On the left half of the figure, the sink's activity is faster than the source's, driving it in \emph{token-limited} mode.

 The vulnerability of the bubble-limited mode can be seen more clearly in Figure~\ref{fig:muller3-sweepSource}; this is where the system is most prone to failure. The probability $P(\text{fail})$ varies from around 60-80\%, where it reaches the maximum when the sink delay is equal to 22 while source delay is 1 (maximum imbalance).
Similarly, the token-limited mode falls near the sink latency of~1 in Figure~\ref{fig:muller3-sweepSink}, varying from around 40-60\%.
The latter figures show several cross-sections of the 3D-plot from Figure~\ref{fig:muller3_sweep_3dplot}. In addition to mapping the token-limited and the bubble-limited areas to these 2 graphs, we can also spot the points belonging to the \emph{balanced environment} diagonal in the frame in Figure~\ref{fig:muller3_sweep_3dplot}.
These points are where the abrupt changes of behavior of each line occur, and consequently we can pinpoint where one region of the mode of operation ends and the other starts.

Finally, Figure \ref{fig:p_per_sig} shows the fault probabilities per signal of the
  linear pipeline as reported by our tool for varying source and sink delays (fast, normal, and slow). It allows us to give a more detailed interpretation of our observations in Figure~\ref{fig:muller3-sweepSink}. 
The probabilities for the monitored signals {\tt c1} and {\tt c3} are always~$1.0$ as
  by definition of the fault probabilities.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.25\columnwidth]{figs/muller3-bar-1-1.pdf}
    \includegraphics[width=0.25\columnwidth]{figs/muller3-bar-1-4.pdf}
    \includegraphics[width=0.25\columnwidth]{figs/muller3-bar-1-25.pdf}\\
    \vspace{0.2cm}
    \includegraphics[width=0.25\columnwidth]{figs/muller3-bar-4-1.pdf}
    \includegraphics[width=0.25\columnwidth]{figs/muller3-bar-4-4.pdf}
    \includegraphics[width=0.25\columnwidth]{figs/muller3-bar-4-25.pdf}\\
    \vspace{0.2cm}
    \includegraphics[width=0.25\columnwidth]{figs/muller3-bar-25-1.pdf}
    \includegraphics[width=0.25\columnwidth]{figs/muller3-bar-25-4.pdf}
    \includegraphics[width=0.25\columnwidth]{figs/muller3-bar-25-25.pdf}
    \vspace{-0.1cm}
    \caption{Circuit fault probability per signal of the linear 3-stage pipeline with varying source and sink delays. Delays: 1 ({\tt INV}), 5 ({\tt MCE}), and 3 different source and sink delays indicated in the figure. $T=1000$.}\vspace{-0.5cm}
    \label{fig:p_per_sig}
\end{figure}

Interestingly, {\tt c2} has a high fault probability, too. For fast sink this can be explained as follows: {\tt MCE3} spends most of the time in the vulnerable storage mode, waiting for a transition on {\tt c2}. As soon as one occurs, it triggers a transition on {\tt c3} which, after the short sink delay, puts {\tt MCE3} back to storage mode. This only leaves a very short time window where {\tt MCE3} is masking faults at {\tt c2}. The enable signals, in turn, are only vulnerable during those short windows, thus showing low fault probability, especially when the source delay is high, see subplot ``source:25, sink:1''.

Recall that we have chosen a relatively large switching delay for the MCE, and our pessimistic model assumes the MCE to be vulnerable during the whole switching duration. This explains why in general $P(\text{fail})$ increases for faster operation speed: the proportion of the sensitive MCE switching phase increases. This can be most directly observed for the balanced cases.

For the other imbalanced extreme with ``source:1, sink:25'' we observe high fault probability for the enable signals. This is not surprising, since now the MCEs spend most of the time waiting for transitions on these signals. A fault probability of $1.0$ for {\tt c1} and {\tt c3} is also unsurprising, due to our definitions, as mentioned already. Quite unexpected, on the first glance, is the fact that {\tt c2} again shows high fault probability, even though we can assume good masking by {\tt MCE3} for that input. The reason here is that, via {\tt INV2}, faults from {\tt c2} directly propagate to {\tt en1} which is known to have low protection by masking. As a result, we see a generally high fault probability in this mode.

For additional simulations and larger circuits, we refer the reader to the appendix: a cyclic version of the Muller pipeline is discussed in Section~\ref{sec:ring} and higher-bit-width modules are discussed in Section~\ref{sec:multi}.
