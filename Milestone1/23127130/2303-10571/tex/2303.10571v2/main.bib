% Long form of conference & journal abbreviations -- especially for camera ready
@String(PAMI  = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV  = {Int. J. Comput. Vis.})
@String(CVPR  = {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV  = {Int. Conf. Comput. Vis.})
@String(ECCV  = {Eur. Conf. Comput. Vis.})
@String(NeurIPS = {Adv. Neural Inform. Process. Syst.})
@String(ICML  = {Int. Conf. Mach. Learn.})
@String(ICLR  = {Int. Conf. Learn. Represent.})
@String(ACCV  = {Asian Conf. Comput. Vis.})
@String(BMVC  = {Brit. Mach. Vis. Conf.})
@String(CVPRW = {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {IEEE Int. Conf. Image Process.})
@String(ICPR  = {Int. Conf. Pattern Recog.})
@String(ICASSP=	{ICASSP})
@String(ICME  = {Int. Conf. Multimedia and Expo})
@String(JMLR  = {J. Mach. Learn. Res.})
@String(TMLR  = {Trans. Mach. Learn Res.})
@String(TOG   = {ACM Trans. Graph.})
@String(TIP   = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TCSVT = {IEEE Trans. Circuit Syst. Video Technol.})
@String(TMM   = {IEEE Trans. Multimedia})
@String(ACMMM = {ACM Int. Conf. Multimedia})
@String(PR    = {Pattern Recognition})

@String(MNI	  = {Nature Mach. Intell.})
@String(SPL	  = {IEEE Sign. Process. Letters})
@String(VR    = {Vis. Res.})
@String(JOV	  = {J. Vis.})
@String(TVC   = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF   = {Comput. Graph. Forum})
@String(CVM   = {Computational Visual Media})


% Short form of conference & journal abbreviations -- especially for submission version
% if desired, remove these macros in favor of the above ones
@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NeurIPS = {NeurIPS})
@String(ICML  = {ICML})
@String(ICLR  = {ICLR})
@String(ACCV  = {ACCV})
@String(BMVC  =	{BMVC})
@String(CVPRW = {CVPRW})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {ICIP})
@String(ICPR  = {ICPR})
@String(ICASSP=	{ICASSP})
@String(ICME  =	{ICME})
@String(JMLR  = {JMLR})
@String(TMLR  = {TMLR})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(PR    = {PR})

@article{baumli2023vision,
  title={Vision-language models as a source of rewards},
  author={Baumli, Kate and Baveja, Satinder and Behbahani, Feryal and Chan, Harris and Comanici, Gheorghe and Flennerhag, Sebastian and Gazeau, Maxime and Holsheimer, Kristian and Horgan, Dan and Laskin, Michael and others},
  journal={arXiv preprint arXiv:2312.09187},
  year={2023}
}

@article{ma2023eureka,
  title={Eureka: Human-level reward design via coding large language models},
  author={Ma, Yecheng Jason and Liang, William and Wang, Guanzhi and Huang, De-An and Bastani, Osbert and Jayaraman, Dinesh and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2310.12931},
  year={2023}
}

@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@inproceedings{zhou2022extract,
  title={Extract free dense labels from clip},
  author={Zhou, Chong and Loy, Chen Change and Dai, Bo},
  booktitle={European Conference on Computer Vision},
  pages={696--712},
  year={2022},
  organization={Springer}
}

@article{li2023clip,
  title={Clip surgery for better explainability with enhancement in open-vocabulary tasks},
  author={Li, Yi and Wang, Hualiang and Duan, Yiqun and Li, Xiaomeng},
  journal={arXiv preprint arXiv:2304.05653},
  year={2023}
}

@article{haiminen2008algorithms,
  title={Algorithms for unimodal segmentation with applications to unimodality detection},
  author={Haiminen, Niina and Gionis, Aristides and Laasonen, Kari},
  journal={Knowledge and information systems},
  volume={14},
  pages={39--57},
  year={2008},
  publisher={Springer}
}

@article{xu2021videoclip,
  title={Videoclip: Contrastive pre-training for zero-shot video-text understanding},
  author={Xu, Hu and Ghosh, Gargi and Huang, Po-Yao and Okhonko, Dmytro and Aghajanyan, Armen and Metze, Florian and Zettlemoyer, Luke and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2109.14084},
  year={2021}
}

@misc{radford2022whisper,
  doi = {10.48550/ARXIV.2212.04356},
  url = {https://arxiv.org/abs/2212.04356},
  author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  title = {Robust Speech Recognition via Large-Scale Weak Supervision},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{guhr-EtAl:2021:fullstop,
  title={FullStop: Multilingual Deep Models for Punctuation Prediction},
  author    = {Guhr, Oliver  and  Schumann, Anne-Kathrin  and  Bahrmann, Frank  and  BÃ¶hme, Hans Joachim},
  booktitle      = {Proceedings of the Swiss Text Analytics Conference 2021},
  month          = {June},
  year           = {2021},
  address        = {Winterthur, Switzerland},
  publisher      = {CEUR Workshop Proceedings},  
  url       = {http://ceur-ws.org/Vol-2957/sepp_paper4.pdf}
}


@misc{mineflayer,
  title = {Mineflayer: Create Minecraft bots with a powerful, stable, and high level JavaScript API.},
  howpublished = {\url{https://github.com/PrismarineJS/mineflayer}},
}


@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{nottingham2023embodied,
  title={Do embodied agents dream of pixelated sheep?: Embodied decision making using language guided world modelling},
  author={Nottingham, Kolby and Ammanabrolu, Prithviraj and Suhr, Alane and Choi, Yejin and Hajishirzi, Hannaneh and Singh, Sameer and Fox, Roy},
  journal={arXiv preprint arXiv:2301.12050},
  year={2023}
}

@article{yuan2023plan4mc,
  title={Plan4mc: Skill reinforcement learning and planning for open-world minecraft tasks},
  author={Yuan, Haoqi and Zhang, Chi and Wang, Hongcheng and Xie, Feiyang and Cai, Penglin and Dong, Hao and Lu, Zongqing},
  journal={arXiv preprint arXiv:2303.16563},
  year={2023}
}

@article{wang2023voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@article{zhu2023ghost,
  title={Ghost in the Minecraft: Generally Capable Agents for Open-World Enviroments via Large Language Models with Text-based Knowledge and Memory},
  author={Zhu, Xizhou and Chen, Yuntao and Tian, Hao and Tao, Chenxin and Su, Weijie and Yang, Chenyu and Huang, Gao and Li, Bin and Lu, Lewei and Wang, Xiaogang and others},
  journal={arXiv preprint arXiv:2305.17144},
  year={2023}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}


@inproceedings{fan2022minedojo,
  title = {MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge},
  author = {Linxi Fan and Guanzhi Wang and Yunfan Jiang and Ajay Mandlekar and Yuncong Yang and Haoyi Zhu and Andrew Tang and De-An Huang and Yuke Zhu and Anima Anandkumar},
  booktitle = {Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks Track},
  year = {2022},
 
}

@inproceedings{oh2018self,
  title={Self-imitation learning},
  author={Oh, Junhyuk and Guo, Yijie and Singh, Satinder and Lee, Honglak},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2018},
  organization={PMLR}
}

@inproceedings{RadfordKHRGASAM21,
  author    = {Alec Radford and
               Jong Wook Kim and
               Chris Hallacy and
               Aditya Ramesh and
               Gabriel Goh and
               Sandhini Agarwal and
               Girish Sastry and
               Amanda Askell and
               Pamela Mishkin and
               Jack Clark and
               Gretchen Krueger and
               Ilya Sutskever},
  title     = {Learning Transferable Visual Models From Natural Language Supervision},
  booktitle = {International Conference on Machine Learning,
               {ICML}},
  year      = {2021},

}

@article{LuoJZCLDL22,
  author    = {Huaishao Luo and
               Lei Ji and
               Ming Zhong and
               Yang Chen and
               Wen Lei and
               Nan Duan and
               Tianrui Li},
  title     = {CLIP4Clip: An empirical study of {CLIP} for end to end video clip
               retrieval and captioning},
  journal   = {Neurocomputing},
  volume    = {508},
  pages     = {293--304},
  year      = {2022},
 
}

@article{abs-2301-10034,
  author    = {Shaofei Cai and
               Zihao Wang and
               Xiaojian Ma and
               Anji Liu and
               Yitao Liang},
  title     = {Open-World Multi-Task Control Through Goal-Aware Representation Learning
               and Adaptive Horizon Prediction},
  journal   = {arXiv preprint arXiv:2301.10034},
  year      = {2023},

}



@article{fang2021clip2video,
  title={CLIP2Video: Mastering Video-Text Retrieval via Image CLIP},
  author={Fang, Han and Xiong, Pengfei and Xu, Luhui and Chen, Yu},
  journal={arXiv preprint arXiv:2106.11097},
  year={2021}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}


@article{DevlinCLT19,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{
dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations (ICLR)},
year={2021}
}

@inproceedings{DzabraevKKP21,
  author    = {Maksim Dzabraev and
               Maksim Kalashnikov and
               Stepan Komkov and
               Aleksandr Petiushko},
  title     = {{MDMMT:} Multidomain Multimodal Transformer for Video Retrieval},
  booktitle = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  year={2021}
}

@inproceedings{Liu0QCDW21,
  author    = {Song Liu and
               Haoqi Fan and
               Shengsheng Qian and
               Yiru Chen and
               Wenkui Ding and
               Zhongyuan Wang},
  title     = {HiT: Hierarchical Transformer with Momentum Contrast for Video-Text
               Retrieval},
  booktitle = {{IEEE/CVF} International Conference on Computer Vision (ICCV)},
  year={2021}

}

@inproceedings{BainNVZ21,
  author    = {Max Bain and
               Arsha Nagrani and
               G{\"{u}}l Varol and
               Andrew Zisserman},
  title     = {Frozen in Time: {A} Joint Video and Image Encoder for End-to-End Retrieval},
  booktitle = {{IEEE/CVF} International Conference on Computer Vision (ICCV)},
  year={2021}
}

@inproceedings{oh2015action,
  title={Action-conditional video prediction using deep networks in atari games},
  author={Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard L and Singh, Satinder},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  year={2015}
}

@article{samvelyan2019starcraft,
  title={The starcraft multi-agent challenge},
  author={Samvelyan, Mikayel and Rashid, Tabish and De Witt, Christian Schroeder and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1902.04043},
  year={2019}
}

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Debiak, Przemyslaw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@article{SilverSSAHGHBLB17,
  author    = {David Silver and
               Julian Schrittwieser and
               Karen Simonyan and
               Ioannis Antonoglou and
               Aja Huang and
               Arthur Guez and
               Thomas Hubert and
               Lucas Baker and
               Matthew Lai and
               Adrian Bolton and
               Yutian Chen and
               Timothy P. Lillicrap and
               Fan Hui and
               Laurent Sifre and
               George van den Driessche and
               Thore Graepel and
               Demis Hassabis},
  title     = {Mastering the game of Go without human knowledge},
  journal   = {Nature},
  volume    = {550},
  number    = {7676},
  pages     = {354--359},
  year      = {2017}

}

@article{kaelbling1998planning,
  title={Planning and acting in partially observable stochastic domains},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Cassandra, Anthony R},
  journal={Artificial intelligence},
  volume={101},
  number={1-2},
  pages={99--134},
  year={1998}
}

@article{abs-2301-04104,
  author    = {Danijar Hafner and
               Jurgis Pasukonis and
               Jimmy Ba and
               Timothy P. Lillicrap},
  title     = {Mastering Diverse Domains through World Models},
  journal   = {arXiv preprint arXiv:2301.04104},
  year      = {2023}
}

@article{abs-2302-01560,
  author    = {Zihao Wang and
               Shaofei Cai and
               Anji Liu and
               Xiaojian Ma and
               Yitao Liang},
  title     = {Describe, Explain, Plan and Select: Interactive Planning with Large
               Language Models Enables Open-World Multi-Task Agents},
  journal   = {arXiv preprint arXiv:2302.01560},
  year      = {2023},

}

@article{abs-2202-10583,
  author    = {Anssi Kanervisto and
               Stephanie Milani and
               Karolis Ramanauskas and
               Nicholay Topin and
               Zichuan Lin and
               Junyou Li and
               Jianing Shi and
               Deheng Ye and
               Qiang Fu and
               Wei Yang and
               Weijun Hong and
               Zhongyue Huang and
               Haicheng Chen and
               Guangjun Zeng and
               Yue Lin and
               Vincent Micheli and
               Eloi Alonso and
               Fran{\c{c}}ois Fleuret and
               Alexander Nikulin and
               Yury Belousov and
               Oleg Svidchenko and
               Aleksei Shpilman},
  title     = {MineRL Diamond 2021 Competition: Overview, Results, and Lessons Learned},
  journal   = {arXiv preprint arXiv:2202.10583},
  year      = {2022},
}

@article{abs-2206-11795,
  author    = {Bowen Baker and
               Ilge Akkaya and
               Peter Zhokhov and
               Joost Huizinga and
               Jie Tang and
               Adrien Ecoffet and
               Brandon Houghton and
               Raul Sampedro and
               Jeff Clune},
  title     = {Video PreTraining {(VPT):} Learning to Act by Watching Unlabeled Online
               Videos},
  journal   = {arXiv preprint arXiv:2206.11795},
  year      = {2022}
}

@inproceedings{MaoWHMLWHLT21,
  author    = {Hangyu Mao and
               Chao Wang and
               Xiaotian Hao and
               Yihuan Mao and
               Yiming Lu and
               Chengjie Wu and
               Jianye Hao and
               Dong Li and
               Pingzhong Tang},
  title     = {{SEIHAI:} {A} Sample-Efficient Hierarchical {AI} for the MineRL Competition},
  booktitle = {International Conference on Distributed Artificial Intelligence (DAI)},
  year      = {2021},
}

@inproceedings{ShahWWMKGWWPMGF21,
  author    = {Rohin Shah and
               Steven H. Wang and
               Cody Wild and
               Stephanie Milani and
               Anssi Kanervisto and
               Vinicius G. Goecks and
               Nicholas R. Waytowich and
               David Watkins{-}Valls and
               Bharat Prakash and
               Edmund Mills and
               Divyansh Garg and
               Alexander Fries and
               Alexandra Souly and
               Jun Shern Chan and
               Daniel del Castillo and
               Tom Lieberum},
  title     = {Retrospective on the 2021 MineRL {BASALT} Competition on Learning
               from Human Feedback},
  booktitle = {Neural Information Processing Systems (NeurIPS) Competitions and Demonstrations Track},
  year = {2021}

}

@inproceedings{GussHTWCVS19,
  author    = {William H. Guss and
               Brandon Houghton and
               Nicholay Topin and
               Phillip Wang and
               Cayden Codel and
               Manuela Veloso and
               Ruslan Salakhutdinov},
  title     = {MineRL: {A} Large-Scale Dataset of Minecraft Demonstrations},
  booktitle = {International Joint Conference on
               Artificial Intelligence (IJCAI)},
 year={2019}
}

@inproceedings{johnson2016malmo,
  title={The Malmo Platform for Artificial Intelligence Experimentation.},
  author={Johnson, Matthew and Hofmann, Katja and Hutton, Tim and Bignell, David},
  booktitle={International Joint Conference on
               Artificial Intelligence (IJCAI)},
               year={2016}
}

@inproceedings{tessler2017deep,
  title={A deep hierarchical approach to lifelong learning in minecraft},
  author={Tessler, Chen and Givony, Shahar and Zahavy, Tom and Mankowitz, Daniel and Mannor, Shie},
  booktitle={AAAI conference on artificial intelligence (AAAI)},
  year={2017}
}

@inproceedings{
shu2018hierarchical,
title={Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning},
author={Tianmin Shu and Caiming Xiong and Richard Socher},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
}

@article{guss2021minerl,
  title={The minerl 2020 competition on sample efficient reinforcement learning using human priors},
  author={Guss, William H and Castro, Mario Ynocente and Devlin, Sam and Houghton, Brandon and Kuno, Noboru Sean and Loomis, Crissman and Milani, Stephanie and Mohanty, Sharada and Nakata, Keisuke and Salakhutdinov, Ruslan and others},
  journal={arXiv preprint arXiv:2101.11071},
  year={2021}
}

@article{guss2019neurips,
  title={NeurIPS 2019 competition: the MineRL competition on sample efficient reinforcement learning using human priors},
  author={Guss, William H and Codel, Cayden and Hofmann, Katja and Houghton, Brandon and Kuno, Noboru and Milani, Stephanie and Mohanty, Sharada and Liebana, Diego Perez and Salakhutdinov, Ruslan and Topin, Nicholay and others},
  journal={arXiv preprint arXiv:1904.10079},
  year={2019}
}

@article{lin2021juewu,
  title={Juewu-mc: Playing minecraft with sample-efficient hierarchical reinforcement learning},
  author={Lin, Zichuan and Li, Junyou and Shi, Jianing and Ye, Deheng and Fu, Qiang and Yang, Wei},
  journal={arXiv preprint arXiv:2112.04907},
  year={2021}
}

@article{cai2023open,
  title={Open-World Multi-Task Control Through Goal-Aware Representation Learning and Adaptive Horizon Prediction},
  author={Cai, Shaofei and Wang, Zihao and Ma, Xiaojian and Liu, Anji and Liang, Yitao},
  journal={arXiv preprint arXiv:2301.10034},
  year={2023}
}