% ----------------------------------------
% ** related work **
% ----------------------------------------
\subsection{Domain Adaptation and Domain Generalization}
As a special case of transfer learning \cite{pan2009survey}, domain adaptation (DA) \cite{ben2010theory} leverages labeled data from a source domain to learn a classifier for an unlabeled target domain with a different distribution, in the transductive learning manner \cite{joachims1999transductive}.
There are two major assumptions of domain shift \cite{quinonero2008dataset,moreno2012unifying}: \emph{covariate shift} in which the features cause the labels; and \emph{label shift} in which the labels cause the features.
We briefly introduce a few popular techniques and refer the reader to the existing literature on DA (\eg, \cite{csurka2017comprehensive,kouw2019review,wilson2020survey}) for further information.
DA methods rely on the existence of source data to bridge the domain gap, and existing techniques can be broadly divided into four categories, \ie, input-level translation \cite{bousmalis2017unsupervised,hoffman2018cycada}, feature-level alignment \cite{long2015learning,ganin2015unsupervised,tzeng2017adversarial}), output-level regularization \cite{chen2019domain,cui2020towards,jin2020minimum}, and prior estimation \cite{saerens2002adjusting,lipton2018detecting,azizzadenesheli2019regularized}.
If it is possible to generate training data from the source model \cite{li2020model}, then the SFDA problem can be addressed using standard DA methods.

% !!!! missing papers from test-time adaptation using source data
Specifically, one closely related topic is \textbf{one-shot domain adaptation} \cite{luo2020adversarial,wan2020one,varsavsky2020test,marsden2022gradual,zhang2022mixup}, which involves adapting to only one unlabeled instance while still requiring the source domain during adaptation.
Another closely related topic is \textbf{online domain adaptation} \cite{moon2020multi,yang2022burn}, which involves adapting to an unlabeled target domain with streaming data that is deleted immediately after adaptation.
Inspired by federated learning \cite{li2020federated}, several studies \cite{peng2020federated,feng2021kd3a,wu2021collaborative} on \textbf{federated domain adaptation} offer an alternative solution for test-time domain adaptation that acquires the feedback (\eg, gradients and model parameters) from the target domain to the source domain multiple times.
Nonetheless, this solution may not be feasible for certain scenarios due to the limited availability of training data and the high communication costs involved in transferring data across multiple devices, as compared to one-time model adaptation \cite{liang2020we,sun2020test,wang2021tent}.

Domain generalization (DG) \cite{li2018learning,li2019episodic,carlucci2019domain} aims to learn a model from one or multiple different but related domains that can generalize well on unseen testing domains. 
Researchers often develop specific training techniques to improve the generalization capability of the pre-trained model, which can be compatible with the studied TTA paradigm. 
For further information on this topic, we refer the reader to existing literature (\eg, \cite{zhou2022dg,wang2022generalizing}).

\subsection{Hypothesis Transfer Learning}
Hypothesis transfer learning (HTL) \cite{kuzborskij2018theory} is another special case of transfer learning where pre-trained models (source hypotheses) retain information about previously encountered tasks.
Shallow HTL methods \cite{yang2007cross,aytar2011tabula,tommasi2013learning,kuzborskij2013stability,orabona2009model,ahmed2020camera} generally assume that the optimal target hypothesis is closely related to these source hypotheses.
For example, Ahmed \etal \cite{ahmed2020camera} learn the optimal metric with labeled target data under the assumption that the target metric is a convex combination of source metrics.
Other methods \cite{ao2017fast,nelakurthi2018source} extend this approach to a semi-supervised scenario where unlabeled target data are also used for training.
Fine-tuning \cite{yosinski2014transferable} is a typical example of a deep HTL method that may update a partial set of parameters in the source model.
Although HTL methods assume no explicit access to the source domain or any knowledge about the relatedness of the source and target distributions, they still require a certain number of labeled data in the target domain.

\subsection{Continual Learning and Meta-Learning}
Continual learning (CL) \cite{de2021continual} aims at learning a model for multiple tasks in a sequence, where knowledge obtained from the preceding tasks is gradually accumulated for future tasks. 
There are three fundamental scenarios of CL \cite{van2022three}: task-incremental, domain-incremental, and class-incremental learning.
To name a few, several recent works \cite{kundu2020class,ambastha2023adversarial} consider incremental learning under domain shift.
Existing CL methods \cite{shin2017continual,smith2021always} fall into three main categories: rehearsal-based \cite{rebuffi2017icarl,rolnick2019experience}, parameter-based regularization \cite{kirkpatrick2017overcoming,zenke2017continual}, and generative-based \cite{shin2017continual,smith2021always,carta2022ex}.
Even though the latter two cases do not access the training data of previous tasks, CL methods focus more on the anti-forgetting ability after learning a supervised task.

Meta-learning \cite{hospedales2021meta} shares a similar assumption with continual learning, but with training data randomly drawn from a task distribution, while test data are tasks with few examples.
MAML \cite{finn2017model} is a representative approach that learns the initialization of a model's parameters to achieve optimal fast learning on a new task using a small number of samples and gradient steps.
Generally, meta-learning offers a straightforward solution for test-time adaptation without the incorporation of test data in the meta-training stage.

\subsection{Data-Free Knowledge Distillation}
Knowledge distillation (KD) \cite{gou2021knowledge} aims to transfer knowledge from a teacher model to a student model by matching the network outputs or intermediate features.
To address privacy and confidentiality concerns, the data-free KD paradigm \cite{liu2021data} is proposed without requiring access to the original training data.
Current data-free KD methods can be roughly divided into two categories: adversarial training \cite{micaelli2019zero,fang2019data,liu2021zero}, which focuses on generating worst-case synthetic samples for student learning, and data prior matching \cite{nayak2019zero,chen2019data,yin2020dreaming}, where synthetic samples are forced to satisfy priors like class prior, activation regularization, and batch normalization statistics. 
A recent work \cite{wang2021zero} even considers a challenging scenario, decision-based black-box KD, where the teacher model is not accessible but returns only one-hot predictions.
Compared with TTA, data-free KD performs knowledge transfer between models instead of distribution-shifted datasets.

\subsection{Self-Supervised and Semi-Supervised Learning} 
Self-supervised learning \cite{jing2020self} is a learning paradigm that focuses on how to learn from unlabeled data by obtaining supervisory signals from the data itself through pretext tasks that leverage its underlying structure. 
Early pretext tasks in the computer vision field include image colorization \cite{zhang2016colorful}, image inpainting \cite{pathak2016context}, image rotation \cite{gidaris2018unsupervised}, context prediction \cite{doersch2015unsupervised}, video prediction \cite{srivastava2015unsupervised}. 
Advanced pretext tasks like clustering \cite{caron2018deep,caron2020unsupervised} and contrastive learning \cite{he2020momentum,chen2020simple,grill2020bootstrap} have achieved remarkable success, even exceeding the performance of their supervised counterparts.
Self-supervised learning is also popular in other fields like natural language processing \cite{kenton2019bert}, speech processing \cite{baevski2020wav2vec}, and graph-structured data \cite{you2020graph}.
For TTA tasks, these self-supervised learning techniques can be utilized to help learn discriminative features \cite{liang2021source} or act as an auxiliary task \cite{sun2020test}. 

Semi-supervised learning \cite{chen2022semi} is another learning paradigm concerned with leveraging unlabeled data to reduce the reliance on labeled data.
A common objective for semi-supervised learning comprises two terms: a supervised loss over labeled data and an unsupervised loss over unlabeled data.
Regarding the latter term, there are three typical cases: self-training \cite{grandvalet2004semi,lee2013pseudo}, which encourages the model to produce confident predictions; consistency regularization under input variations \cite{miyato2018virtual,berthelot2019mixmatch,sohn2020fixmatch} and model variations \cite{laine2017temporal,tarvainen2017mean}, which forces networks to output similar predictions when inputs or models are perturbed; and graph-based regularization \cite{iscen2019label}, which seeks local smoothness by maximizing the pairwise similarities between nearby data points.
For TTA tasks, these semi-supervised learning techniques could be easily incorporated to unsupervisedly update the pre-trained model.

\subsection{Test-Time Augmentation}
Data augmentation techniques \cite{shorten2019survey}, such as geometric transformations and color space augmentations, can create modified versions of training images that improve the robustness of deep models against unknown perturbations.
Typically, data augmentation can also be employed during test time to boost prediction accuracy \cite{krizhevsky2012imagenet,he2016deep}, estimate uncertainty \cite{smith2018understanding}, and enhance robustness \cite{guo2018countering,perez2021enhancing}.
Ten-crop testing \cite{he2016deep} is a typical example of test-time augmentation, which obtains the final prediction via averaging predictions from ten different scaled versions of a test image.
Other aggregation strategies include selective augmentation \cite{kim2020learning} and learnable aggregation weights \cite{shanmugam2021better}.
Apart from data variation, Monte Carlo dropout \cite{gal2016dropout} enables dropout within the network during testing and performs multiple forward passes with the same input data, to estimate the model uncertainty.
Generally, test-time augmentation techniques do not explicitly consider distribution shifts but can be utilized by TTA methods.