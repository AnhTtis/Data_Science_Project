Previously, we have considered various test-time adaptation scenarios where pre-trained source models are adapted to a domain \cite{liang2020we,li2020model}, a mini-batch \cite{schneider2020improving,zhang2021adaptive}, or even a single instance \cite{sun2020test,zhang2022memo} at test time.
However, offline test-time adaptation typically requires a certain number of samples to form a mini-batch or a domain, which may be infeasible for streaming data scenarios where data arrives continuously and in a sequential manner.
To reuse past knowledge like online learning, TTT \cite{sun2020test} employs an online variant that does not optimize the model episodically for each input but instead retains the optimized model for the last input.

\subsection{Problem Definition}
\begin{definition}[Online Test-Time Adaptation, OTTA]
Given a well-trained classifier $f_\mathcal{S}$ on the source domain $\mathcal{D}_\mathcal{S}$ and a sequence of unlabeled mini-batches $\{\mathcal{B}_1, \mathcal{B}_2, \cdots\}$, \emph{online test-time adaptation} aims to leverage the labeled knowledge implied in $f_\mathcal{S}$ to infer labels of samples in $\mathcal{B}_i$ under distribution shift, in an online manner. 
In other words, the knowledge learned in previously seen mini-batches could be accumulated for adaptation to the current mini-batch.
\end{definition}

The above definition corresponds to the problem addressed in Tent \cite{wang2021tent}, where multiple mini-batches are sampled from a new data distribution that is distinct from the source data distribution.
Besides, it also encompasses the online test-time instance adaptation problem, as introduced in TTT-Online \cite{sun2020test} when the batch size equals 1.
However, samples at test time may come from a variety of different distributions, leading to new challenges such as error accumulation and catastrophic forgetting.
To address this issue, CoTTA \cite{wang2022continual} and EATA \cite{niu2022efficient} investigate the continual test-time adaptation problem that adapts the pre-trained source model to the continually changing test data. 
Such a non-stationary adaptation problem could be also viewed as a special case of the definition above, when each mini-batch may come from a different distribution.

\setlength{\tabcolsep}{4.0pt}
\begin{table}[!t]
\caption{A taxonomy on OTTA methods with representative strategies.}
\resizebox{0.49\textwidth}{!}{
    \begin{tabular}{ll}
        \toprule
        \textbf{Families} & \textbf{Representative Strategies}\\
        \midrule
        \textbf{batch normalization calibration} & DUA \cite{mirza2022norm}, DELTA \cite{zhao2023delta}\\
        \textbf{entropy minimization} & Tent \cite{wang2021tent}, SAR \cite{niu2023towards} \\
        \textbf{pseudo-labeling} & T3A \cite{iwasawa2021test}, TAST \cite{jang2022test}\\
        \textbf{consistency regularization} & CFA \cite{kojima2022robustifying}, LAME \cite{boudiaf2022parameter} \\
        \textbf{anti-forgetting regularization} & CoTTA \cite{wang2022continual}, EATA \cite{niu2022efficient} \\
        \bottomrule
\end{tabular}}
\end{table}

\subsection{Taxonomy on OTTA Algorithms}
\subsubsection{Batch Normalization Calibration} 
% Rectification calibration
As noted in the previous section, normalization layers such as batch normalization (BN) \cite{ioffe2015batch} are commonly employed in modern neural networks. 
Typically, BN layers can encode domain-specific knowledge into normalization statistics \cite{li2017revisiting}.
A recent work \cite{niu2023towards} further investigates the effects of different normalization layers under the test-time adaptation setting. In the following, we mainly focus on the BN layer due to its widespread usage in existing methods.

Tent \cite{wang2021tent} and RNCR \cite{hu2021fully} propose replacing the fixed BN statistics (\ie, mean and variance $\{\mu_s, \sigma^2_s\}$) in the pre-trained model with the estimated ones $\{\hat{\mu}_t, \hat{\sigma}^2_t\}$ from the $t$-th test batch.
CD-TTA \cite{song2022cdtta} develops a switchable mechanism that selects the most similar one from multiple BN branches in the pre-trained model using the Bhattacharya distance.
Besides, Core \cite{you2021test} calibrates the BN statistics by interpolating between the fixed source statistics and the estimated ones at test time, namely, $\mu_t = \rho \hat{\mu}_t + (1-\rho) \mu_s, \sigma_t = \rho \hat{\sigma}_t + (1-\rho) \sigma_s$, where $\rho \in [0,1]$ is a momentum hyper-parameter.

Similar to the running average estimation of BN statistics during training, ONDA \cite{mancini2018kitting} and two follow-up methods \cite{park2022robust,zhang2022unseen} propose initializing the BN statistics $\{\mu_0, \sigma_0\}$ as $\{\mu_s, \sigma_s\}$ and updating them for the $t$-th test batch,
\begin{equation}
    \begin{aligned}
    \mu_t &= \rho \hat{\mu}_t + (1-\rho) \mu_{t-1},\\
    \sigma_t^2 &= \rho \hat{\sigma}_t^2 + (1-\rho)\frac{n_t}{n_t-1}\sigma_{t-1}^2,
    \end{aligned}
    \label{eq:bn_ema}
\end{equation}
where $n_t$ denotes the number of samples in the batch, and $\rho$ is a momentum hyperparameter.
Instead of a constant value for $\rho$, MECTA \cite{hong2023mecta} considers a heuristic weight through computing the distance between $\{\mu_{t-1}, \sigma_{t-1}\}$ and $\{\hat{\mu}_t, \hat{\sigma}_t\}$.

To decouple the gradient backpropagation and the selection of BN statistics, GpreBN \cite{yang2022test} and DELTA \cite{zhao2023delta} adopt the following reformulation of batch re-normalization \cite{ioffe2017batch}, 
\begin{equation}
    \hat{x}_t = \gamma \cdot \frac{\frac{x_t-\hat{\mu}_t}{\hat{\sigma}_t} \cdot sg(\hat{\sigma}_t) + sg(\hat{\mu}_t) - \mu}{\sigma}+ \beta,
\end{equation}
where $sg(\cdot)$ denotes the stop-gradient operation, and $\{\gamma,\beta\}$ are the affine parameters in the BN layer.
To obtain stable BN statistics $\{\mu, \sigma\}$, these methods utilize the test-time dataset-level running statistics via the moving average like Eq.~(\ref{eq:bn_ema}).

For online adaptation with a single sample, MixNorm \cite{hu2021mixnorm} mixes the estimated IN statistics with the exponential moving average BN statistics at test time.
On the other hand, DUA \cite{mirza2022norm} adopts a decay strategy for the weighting hyper-parameter $\rho$ and forms a small batch from a single image to stabilize the online adaptation process.
To obtain more accurate estimates of test-time statistics, NOTE \cite{gong2022note} maintains a class-balanced memory bank that is utilized to update the BN statistics using an exponential moving average.
Additionally, NOTE proposes a selective mixing strategy that only calibrates the BN statistics for detected out-of-distribution samples.
TN-SIB \cite{zhang2022generalizable} also leverages a memory bank that provides samples with similar styles to the test sample, to estimate more accurate BN statistics. 

\subsubsection{Entropy Minimization}
Entropy minimization is a widely-used technique to handle unlabeled data. 
A pioneering approach, Tent \cite{wang2021tent}, proposes minimizing the mean entropy over the test batch to update the affine parameters $\{\gamma, \beta\}$ of BN layers in the pre-trained model, followed by various subsequent methods \cite{wang2021fighting,gong2022note,yang2022test}.
Notably, VMP \cite{jing2022variational} reformulates Tent in a probabilistic framework by introducing perturbations into the model parameters by variational Bayesian inference.
Several other methods \cite{park2022robust,tang2023neuro,yi2023temporal} also focus on minimizing the entropy at test time but utilize different combinations of learnable parameters.
BACS \cite{zhou2021bayesian} incorporates the entropy regularization for unlabeled data in the approximate Bayesian inference algorithm, and samples multiple model parameters to obtain the marginal probability for each sample.
In addition, TTA-PR \cite{sivaprasad2021test} proposes minimizing the average entropy of predictions under different augmentations. 
FEDTHE+ \cite{jiang2023test} employs the same adaptation scheme as MEMO \cite{zhang2022memo} that minimizes the entropy of the average prediction over different augmentations, while FTEA \cite{zhang2022unseen} fuses the predictions from different modalities.
MEMO-CL \cite{singh2022addressing} develops a filtering approach that selects partial augmentations for marginal entropy minimization.

To avoid overfitting to non-reliable and redundant test data, EATA \cite{niu2022efficient} develops a sample-efficient entropy minimization strategy that identifies samples with lower entropy values than the pre-defined threshold for model updates, which is also adopted by follow-up methods \cite{song2023ecotta,niu2023towards}.
CD-TTA \cite{song2022cdtta} leverages the similarity between feature statistics of the test sample and source running statistics as sample weights, instead of using discrete weights $\{0,1\}$.
Besides, DELTA \cite{zhao2023delta} derives a class-wise re-weighting approach that associates sample weights with corresponding pseudo labels to mitigate bias towards dominant classes.

There exist many alternatives to entropy minimization for adapting models to unlabeled test samples including class confusion minimization \cite{you2021test}, batch nuclear-norm maximization \cite{hu2021fully}, maximum squares loss \cite{song2022cdtta}, and mutual information maximization \cite{kingetsu2022multi,choi2022improving}.
In addition, MuSLA \cite{kingetsu2022multi} further considers the virtual adversarial training objective that enforces classifier consistency by adding a small perturbation to each sample.
SAR \cite{niu2023towards} encourages the model to lie in a flat area of the entropy loss surface and optimizes the minimax entropy objective below,
\begin{equation}
    \min_{\theta} \max_{\|\Delta_\theta\|_2 \leq \epsilon} \mathcal{H}(x;\theta + \Delta_\theta),
\end{equation}
where $\mathcal{H}(\cdot)$ denotes the entropy function, and $\Delta_\theta$ denotes the weight perturbation in a Euclidean ball with radius $\epsilon$.
Moreover, a few methods \cite{kundu2022uncertainty,yang2023auto} even employ entropy maximization for specific tasks, for example, AUTO \cite{yang2023auto} performs model updating for unknown samples at test time.

\subsubsection{Pseudo-labeling}
Unlike the unidirectional process of entropy minimization, many OTTA methods \cite{voigtlaender2017online,belli2022online,kingetsu2022multi,boudiaf2022parameter,song2022cdtta,mullapudi2019online} adopt pseudo labels generated at test time for model updates.
Among them, MM-TTA \cite{shin2022mmtta} proposes a selective fusion strategy to ensemble predictions from multiple modalities.
TTA-MDE \cite{li2023test} selects pseudo labels with a high consistency score across different models for further labeling.
Besides, DLTTA \cite{yang2022dltta} obtains soft pseudo labels by averaging the predictions of its nearest neighbors in a memory bank, and subsequently optimizes the symmetric KL divergence between the model outputs and these pseudo labels.
TAST \cite{jang2022test} proposes a similar approach that reduces the difference between predictions from a prototype-based classifier and a neighbor-based classifier.
Notably, SLR+IT \cite{mummadi2021test} develops a negative log-likelihood ratio loss instead of the commonly used cross-entropy loss, providing non-vanishing gradients for highly confident predictions.

Conjugate-PL \cite{goyal2022test} presents a way of designing unsupervised objectives for TTA by leveraging the convex conjugate function.
The resulting objective resembles self-training with specific soft labels, referred to as conjugate pseudo labels.
A recent work \cite{wang2023towards} theoretically analyzes the difference between hard and conjugate labels under gradient descent for a binary classification problem.
Motivated by the idea of negative learning \cite{kim2019nlnl}, ECL \cite{han2023rethinking} further considers complementary labels from the least probable categories.
Besides, T3A \cite{iwasawa2021test} proposes merely adjusting the classifier layer by computing class prototypes using online unlabeled data and classifying each unlabeled sample based on its distance to these prototypes.
MSLC-TSD \cite{wang2023feature} computes class prototypes using a dynamic memory bank, providing accurate pseudo labels for subsequent model updates.

\subsubsection{Consistency Regularization}
In the classic mean teacher \cite{tarvainen2017mean} framework, the pseudo labels under weak data augmentation obtained by the teacher network are known to be more stable.
Built on this framework, RMT \cite{dobler2022robust} pursues the teacher-student consistency in predictions through a symmetric cross-entropy measure, while OIL \cite{ye2022robust} only exploits highly confident samples during consistency maximization. 
VDP \cite{gan2023decorate} and its follow-up method \cite{yang2023exploring} also utilize this framework to update visual domain prompts with the pre-trained model being frozen. 
Moreover, CoTTA \cite{wang2022continual} further employs multiple augmentations to refine the pseudo labels from the teacher network, which is also applied in other methods \cite{brahma2022probabilistic,tomar2023tesla}.
Inspired by maximum classifier discrepancy \cite{saito2018maximum}, AdaODM \cite{zhang2022adaptive} proposes minimizing the prediction disagreement between two classifiers at test time to update the feature encoder.

Apart from the model variation above, several methods \cite{sivaprasad2021test,lin2022video,das2023transadapt,lumentut20223d,su2022revisiting,chen2023openworld} also enforce the consistency of the corresponding predictions among different augmentations.
In particular, SWR-NSP \cite{choi2022improving} introduces an additional nearest source prototype classifier at test time and minimizes the difference between predictions under two different augmentations.
FTEA \cite{zhang2022unseen} performs knowledge distillation from the fused multi-modality prediction to the prediction of each modality.
Besides, many methods \cite{guan2021bilevel,kuznietsov2022towards,kim2022ev,belli2022online,yi2023temporal} leverage the temporal coherence for video data and design a temporal consistency objective at test time.
For example, TeCo \cite{yi2023temporal} encourages adjacent frames to have semantically similar features to increase the robustness against corruption at test time. 
LAME \cite{boudiaf2022parameter} further exploits the neighbor consistency, forcing neighboring points in the feature space to have consistent assignments.

In contrast to the consistency constraints in the prediction space above, GAPGC \cite{chen2022graphtta} and FEDTHE+ \cite{jiang2023test} pursue consistency in the feature space.
Several other OTTA methods \cite{wu2021domainagnostic,dobler2022robust,su2022revisiting,su2023revisiting,wang2023feature}) even pursue consistency between test features and source or target prototypes in the feature space. 
CFA \cite{kojima2022robustifying} further proposes matching multiple central moments to achieve feature alignment. 
Furthermore, ACT-MAD \cite{mirza2022actmad} performs feature alignment by minimizing the discrepancy between the pre-computed training statistics and the estimates of test statistics.
ViTTA \cite{lin2022video} and TTAC \cite{su2022revisiting} calculate the online estimates of feature mean and variance at test time instead. 
Additionally, CAFA \cite{jung2022cafa} uses the Mahalanobis distance to achieve low intra-class variance and high inter-class variance for test data.

\subsubsection{Anti-forgetting Regularization}
Previous studies \cite{wang2022continual,niu2022efficient} find that the model optimized by TTA methods suffers from severe performance degradation (named forgetting) on original training samples.
To mitigate the forgetting issue, a natural solution is to keep a small subset of training data that is further learned at test time as regularization \cite{belli2022online,dobler2022robust,kuznietsov2022towards}. 
PAD \cite{wu2021domainagnostic} comes up with an alternative approach that keeps the relative relationship of irrelevant auxiliary data unchanged after test-time optimization.
AUTO \cite{yang2023auto} maintains a memory bank to store easily recognized samples for replay and prevents overfitting towards unknown samples at test time.

Another anti-forgetting solution lies in using merely a few parameters for test-time model optimization. 
For example, Tent \cite{wang2021tent} only optimizes the affine parameters in the BN layers for test-time adaptation, and AUTO \cite{yang2023auto} updates the last feature block in the pre-trained model.
SWR-NSP \cite{choi2022improving} divides the entire model parameters into shift-agnostic and shift-biased parameters and updates the former less and the latter more.
Recently, VDP \cite{gan2023decorate} fixes the pre-trained model but only optimizes the input prompts during adaptation.

Besides, CoTTA \cite{wang2022continual} proposes a stochastic restoration technique that randomly restores a small number of parameters to the initial weights in the pre-trained model.
PETAL \cite{brahma2022probabilistic} further selects parameters with smaller gradient norms in the entire model for restoration.
By contrast, EATA \cite{niu2022efficient} introduces an importance-aware Fisher regularizer to prevent excessive changes in model parameters. 
The importance is estimated from test samples with generated pseudo labels.
SAR \cite{niu2023towards} proposes a sharpness-aware and reliable optimization scheme, which removes samples with large gradients and encourages model weights to lie in a flat minimum. 
Further, EcoTTA \cite{song2023ecotta} presents a self-distilled regularization by forcing the output of the test model to be close to that of the pre-trained model.

\subsubsection{Miscellaneous Methods}
In addition, there are several other proposed solutions for the OTTA problem, such as meta-learning \cite{zhang2022generalizable,ambekar2023variational,wu2023learning}, Hebbian learning \cite{tang2023neuro}, and adversarial data augmentation \cite{chen2022graphtta,tomar2023tesla}.
Besides, ETLT \cite{fan2022simple} develops a test-time calibration approach that learns the linear relation between features and detection scores in an online manner.

\method{Remarks}
Besides, a recent work \cite{kerssies2022evaluating} studies two different distribution shifts---contextual shifts and semantic shifts---and compares three TTA methods including Tent \cite{wang2021tent} and CoTTA \cite{wang2022continual}.
Notably, several common pitfalls are identified from prior efforts based on a diverse set of distribution shifts and two comprehensive evaluation protocols \cite{zhao2023pitfalls}.
Among them, one important pitfall is choosing appropriate hyper-parameters is exceedingly difficult due to online batch dependency during adaptation.

\subsection{Learning Scenarios of OTTA Algorithms}
\method{Stationary \vs Dynamic}
As mentioned above, there are two categories of OTTA tasks. Vanilla OTTA \cite{wang2021tent} assumes the test data comes from a stationary distribution, while continual OTTA \cite{wang2022continual} assumes a continually changing distribution.

Other differences among OTTA algorithms are the same as those among TTBA algorithms, \ie, \textbf{instance \vs batch}, \textbf{customized \vs on-the-fly}, and \textbf{single \vs multiple}.
