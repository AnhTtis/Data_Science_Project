\section{Related work}
\label{sec:related}

Today's high-performance computing systems (in HPC or cloud centers) under-utilize memory resources because of over-provisioning~\cite{peng2020memory,shalf2020photonic}.
Future HPC systems will decouple compute and memory extensively, thus leading to disaggregated architectures, where multiple processing elements can potentially access a large pool of memory resources using a coherent interconnect fabric (e.g., CXL~\cite{van2019hoti}, Gen-Z~\cite{casey2017gen})~\cite{awadascr21}.
Locally attached memories to a CPU can act as a cache to the remote pool of memory.
Given the promise of memory pooling, there is an increased interest in research on disaggregated memory systems recently~\cite{wahlgren2022evaluating, maruf2022tpp, calciu2021rethinking, kommareddy2021deact}.
We anticipate more research in this direction in the near future.
Our work provides the appropriate flexibility to model and evaluate the previously mentioned systems. The evaluation methods and tools adopted by previous works to evaluate DRAM cache designs are generally private. The lack of such tools is one of the main motivations for our work to build a flexible simulation model for DRAM caches which can be a part of a widely used open-source simulator like \gem{}.

The evaluation strategies discussed in prior DRAM cache research~\cite{qureshi2012fundamental, jevdjic2013stacked, chou2015bear, young2018accord, jevdjic2014unison} lack in many ways compared to our simulation model.
Many previous research works on DRAM cache techniques use trace-based or functional-first simulators.
These simulators might not faithfully simulate the behavior of applications that take different paths depending on I/O or thread timings~\cite{eeckhout2010computer}.
Trace-based simulators cannot model the mis-speculated execution path and the micro-architectural impact on thread order.
Functional-first simulators allow the functional model to execute ahead of the timing model, and thus, to model mispredicted path, they need to rely on rollback of functional model state~\cite{eeckhout2010computer}.
However, the timing differences in the functional and the timing models can change the order in which the functional model acquires a lock and what is observed by the timing model~\cite{eeckhout2010computer}.
In contrast, execute-in-execute simulators like \gem{}, which functionally execute instructions at the simulated execute stage, can be more accurate.

Notably, most of the previous research on DRAM caches does not use full-system simulators and might fail to capture the OS impact. Work by Bin et al.~\cite{gao2022level} has shown that the OS kernel bottlenecks can degrade memory access latency on DRAM cache systems in disaggregated environments. We implement our DRAM cache simulation model in a full-system simulator and use full-system simulations for all the results presented in this paper.
% The workloads used for evaluation are also mostly not realistic.
Additionally, many previous works use multiple copies of the same benchmark to execute workload on multiple simulated cores, which might not capture the inter-thread dependency behavior exhibited by the real workloads on real systems. In contrast, we used multithreaded workloads to use all the simulated cores in this work.

In addition to simulation methodologies, some work exists on using analytical models for DRAM caches. For example, Gulur et al.~\cite{gulur2015comprehensive} presented an analytical performance model of different DRAM organizations. However, their work is agnostic to the micro-architectural and timing constraints of main memory technologies cooperating with DRAM cache,  and still leaves a gap for a full system DRAM cache simulation for detailed architectural analysis.
%Their model considers parameters such as DRAM Cache's and off-chip memory's timing values, cache block size, tag cache/predictor hit rate, and workload characteristic
%to estimate average miss penalty and bandwidth seen by the last level on-chip SRAM cache (LLSC). %Their work is based on a prior model called ANATOMY~\cite{gulur2014anatomy}, which is a trace-based analytical model. Their model estimates
%key workload characteristics like arrival rate, row-buffer hit rate, and request spread, which are used as inputs to the network-like queuing model to estimate memory performance statistically.
%Even though this work accounts for the timing constraints of DRAM for cache management, it is agnostic of the micro-architectural and timing constraints of main memory technologies cooperating with DRAM cache,  and still leaves a gap for a full system DRAM cache simulation for detailed architectural analysis.

% To the best of our knowledge, there is only one work discussing an analytical performance model of DRAM cache for in-SRAM and in-DRAM tag storage
% organizations~\cite{gulur2015comprehensive}. Gulur et al.~\cite{gulur2015comprehensive} proposed an analytical DRAM cache model to estimate the average miss penalty and the bandwidth seen by the last level (on-chip) cache. Though this work considers the timing constraints of DRAM for cache management, it is agnostic to the microarchitecture and timing constraints of main memory technologies cooperating with DRAM cache and still leaves a gap for a full-system DRAM cache simulation for detailed microarchitectural analysis.

%\note{Add notes on VANS/LENS}
%This work does not focus on the microarchitectural details of the main memory technologies cooperating with the DRAM cache. The default \gem{} DRAM models for main memory are reasonably accurate. However, the default NVM model in \gem{} is approximate. In our future work, we plan to use more detailed NVM models like VANS~\cite{wang2020characterizing}, which can be integrated with \gem{}. VANS, presented by Wang et al.~\cite{wang2020characterizing}, is a cycle-level NVRAM simulator that models the microarchitectural details of Optane DIMMs.
%However, their simulation model does not support using an NVRAM device as a backing memory of a DRAM cache.

