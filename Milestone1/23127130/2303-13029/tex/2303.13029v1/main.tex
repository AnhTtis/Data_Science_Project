\documentclass[10pt,conference,hidelinks]{IEEEtran}

\usepackage{url}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}
%\usepackage{subcaption}
\usepackage{multirow}
\usepackage{listings}
\usepackage{tabularx}
\usepackage{xcolor}
\usepackage{comment}
\usepackage{listings,newtxtt}
\lstset{basicstyle=\ttfamily, keywordstyle=\bfseries}

\usepackage{tikz}
\usepackage{xcolor}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,fill,inner sep=1pt] (char) {\textcolor{white}{#1}};}}


\usepackage{pbox}
\usepackage{comment}
\usepackage{csvsimple}
\usepackage{fancyhdr}
\usepackage{mathtools}
\usepackage{nicefrac}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{makecell}
\usepackage{pifont}
\usepackage{tikz}
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;}
%\usepackage[top=1in, bottom=1in, left=0.75in, right=0.75in]{geometry}
\usepackage{siunitx}
\sisetup{
    table-figures-decimal = 3,
    table-number-alignment=center-decimal-marker
}

\newcommand\Ayaz[1]{\textcolor{blue}{#1}}
\newcommand\note[1]{\textcolor{blue}{#1}}
\newcommand\Maryam[1]{\textcolor{red}{#1}}

%\pagenumbering{ roman }

\begin{document}

% Use these macros to cite our tools, etc.
% This ensures consistency.
\newcommand{\gem}{gem{5}}
\newcommand{\bear}{BEAR-Wr-Opt}
\newcommand{\oracle}{Oracle}

\title{Enabling Design Space Exploration of DRAM Caches in Emerging Memory Systems}

\author{
%\normalsize{Note: This work is submitted to ISPASS 2023 and is under review  -- This is a \emph{confidential draft} -- Do not distribute.}\\
\\\IEEEauthorblockN{Maryam Babaie, Ayaz Akram, Jason Lowe-Power}
\IEEEauthorblockA{Department of Computer Science,
University of California, Davis\\
Email: \{mbabaie, yazakram, jlowepower\}@ucdavis.edu}}

\maketitle
\thispagestyle{plain}
\pagestyle{plain}

\begin{abstract}
%%%% OLD VERSION
    % The increasing growth of applications' memory demands has led the CPU vendors to deploy large DRAM caches,
    % backed by large non-volatile memories like Intel Optane (e.g., Intel's Cascade Lake and Sapphire Rapids).
    % The existing memory simulators and computer architecture simulators do not provide support to
    % model and evaluate systems which use DRAM devices as a cache to the main memory.
    % In this work, we present a cycle-level DRAM cache model which is integrated with \gem{}.
    % % a general DRAM cache protocol for the aforementioned systems.
    % % We extend gem5 (widely used full-system simulator) with a unified DRAM cache and main memory controller
    % % (\textit{UDCC}) to implement the DRAM cache protocol. \textit{UDCC} controls two different memory devices at the same time,
    % % in which one of them caches data for the other one and data is kept consistent between the two.
    % This model leverages the flexibility of \gem{}'s memory devices models and full system support to enable  exploration of many different DRAM cache designs.
    % We demonstrate the usefulness of this new model by exploring the design space of a DRAM cache controller through several case studies including the impact of
    % scheduling policies, required buffering, combining different memory technologies (e.g., HBM, DDR3/4/5, 3DXPoint, High latency)
    % as the cache and main memory, and the effect of wear-leveling when DRAM cache is backed by NVM main memory.
    % We also perform experiments with real workloads in full-system simulations to validate the proposed model
    % and show the sensitivity of these workloads to the DRAM cache sizes.
    % % We address the complexities involved in timing and micro-architecture details of \textit{UDCC} that are vital to support the data
    % % consistency across DRAM cache and main memory and reason about the performance degradation caused by these complexities.
The increasing growth of applications' memory capacity and performance demands has led the CPU vendors to deploy heterogeneous memory systems either within a single system or via disaggregation.
For instance, systems like Intel's Knights Landing and Sapphire Rapids can be configured to use high bandwidth memory as a cache to main memory.
While there is significant research investigating the designs of DRAM caches, there has been little research investigating DRAM caches from a full system point of view, because
% As these new technologies emerge, further studies are required to support DRAM caches in these systems.
there is not a suitable model available to the community to accurately study large-scale systems with DRAM caches at a cycle-level.
In this work we describe a new cycle-level DRAM cache model in the \gem{} simulator which can be used for heterogeneous and disaggregated systems.
We believe this model enables the community to perform a design space exploration for future generation of memory systems supporting DRAM caches.


\end{abstract}

% \begin{IEEEkeywords}
% Heterogeneous Memories, Disaggregated Memories, DRAM Cache, \gem{}.
% \end{IEEEkeywords}


\input{new-intro}
%\input{background}
\input{new_design}
% \input{validation}
\input{new_method}
\input{cs1}
\input{cs2}
\input{cs3}
\input{related}

\section{Conclusion}

In this work, we described our detailed cycle-level DRAM cache
model implemented in \gem{}, which enables design space exploration for DRAM caches
in emerging memory systems.
The model presented in this work
can enable many interesting research works in the domain of heterogeneous and disaggregated memory systems.
For instance, using our DRAM cache model we can address questions such as: what is
the efficient data placement and data movement policy and mechanism in systems composed of fast and slow memories.
Since our model is implemented in a full system simulation platform, it can also enable the hardware and software co-design
research in such systems.

% Moreover, \gem{} is highly modular and allows composing a simulated system based on a variety of components.
% \textit{UDCC} can enable experimenting with different and new memory device models which might have features to be a better fit to be used as a cache to a backing memory.

%\section*{ACKNOWLEDGMENT}

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,references}

\end{document}
