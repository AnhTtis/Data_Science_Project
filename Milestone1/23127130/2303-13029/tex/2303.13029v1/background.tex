\section{Background}
\label{sec:background}

\subsection{Background on heterogeneous and disaggregated memory systems}

With the growing footprint of large scale applications, commercial products have been emerging in the market
to accommodate the memory requirements of the today's demanding workloads. Intel introduced Optane Data-Center
Persistent-Memory-Modules (NVRAM) and as a replacement for conventional DRAMs~\cite{hildebrand2021case}. Even though NVRAM provides much larger capacity than DRAM, it has 3x longer latency and
60\% lower bandwidth than DRAM ~\cite{izraelevitz2019basic}. Hardware caching through DRAM DIMMs, has been employed in Intel's
Cascade Lake product to hide the long latency of NVRAM. Intel has announced the release of the new generation of Xeon processor called Sapphire Rapid~\cite{sapphire}
which includes an HBM2 device capable of caching for DDR5 memory.

Memory interface/interconnect technologies like CXL~\cite{van2019hoti} enable disaggregated memory systems to utilize
available memory resources better~\cite{calciu2021rethinking,wahlgren2022evaluating}. CXL is reported to be included in Intel's Sapphire Rapids. Moreover, CXL is
anticipated to be highly employed in cloud servers where ...\Maryam{needs be completed}.
Directly attached memories can be a cache to a large (remote/disaggregated) memory pool
(connected via interconnects like CXL~\cite{van2019hoti}).
Our model allows to study such DRAM cache topologies. \Maryam{needs be completed}.

\subsection{Background on \gem{}'s memory subsystem}\Maryam{if needed space, shorten this part}

The \gem{} simulator is based on an event-driven full-system simulation engine.
It supports models of many system components, including a memory controller, a detailed DRAM model, an NVM model, and a model for different CPUs, caches, and others.
The memory controller module added to \gem{} by Hansson et al.~\cite{hansson2014simulating} focuses on modeling the state transitions of the memory bus and the memory banks.
While it is not ``cycle accurate'', it is \emph{cycle level}, and the memory controller is designed to enable fast and accurate memory system exploration.

The memory controller in \gem{} was refactored in ~\cite{gem5-workshop-presentation} where two components were defined to simulate a real memory controller.
(1) The \textit{memory controller} receives commands from the CPU and enqueues them into appropriate queues and manages their scheduling to the memory device.
(2) The \textit{memory interface} deals with device/media-specific timings, manages the device-specific operations and communicates with the memory controller.

Moreover, the most recent release of \gem{} further improves the flexibility and modularity of memory controller and interfaces~\cite{akram2022modeling}.
Most importantly, it provides support for HBM2 interface and memory controller, where each physical channel is consisted of
two pseudo-channels with peak theoretical bandwidth of 32 GB/s per channel.
The DRAM cache model presented in this work can employ any of these memory controller and interfaces of \gem{} without any modifications.
Like \gem's current memory controller, our DRAM cache model's goal is for cycle-level simulation to enable micro-architectural exploration and flexibility, not cycle-by-cycle accuracy to a single design.
