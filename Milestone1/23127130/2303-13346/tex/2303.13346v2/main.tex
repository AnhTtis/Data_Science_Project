%\documentclass[a4paper,11pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[12pt, titlepage]{article}
\usepackage[utf8]{inputenc}

\usepackage[comma,authoryear]{natbib}

%% PS paper
\renewcommand{\baselinestretch}{1.1}
\oddsidemargin=0in \evensidemargin=0in \textwidth=6.2in
\headheight=0pt \headsep=0pt \topmargin=0in \textheight=9in
\renewcommand{\baselinestretch}{1.1}

%% new
\usepackage[english]{babel}
\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}

%% other
\usepackage{mathrsfs,amsmath}   %The amsmath package is included for \xrightarrow
\usepackage{amsmath,amssymb}
\usepackage{bbm}
\usepackage{mathtools}

%%%%%
\usepackage{footnote}
\usepackage{footmisc}
\makesavenoteenv{tabular}
\makesavenoteenv{table}
\renewcommand{\thefootnote}{\alph{footnote}}

\newcommand{\astfootnote}[1]{
\let\oldthefootnote=\thefootnote
\setcounter{footnote}{0}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\footnote{#1}
\let\thefootnote=\oldthefootnote
}

\usepackage{commath}
\usepackage{nicefrac}
\usepackage{titling,lipsum}
\usepackage{algpseudocode}
\usepackage{algorithm}
%\usepackage{caption}
%\usepackage{subcaption}
%\usepackage{subfigure}
\usepackage{subfig}



%% hyper references and colors
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{sectsty}
\definecolor{MyBlue1}{rgb}{0,0,1}
\definecolor{MyBlue2}{rgb}{0.1,0.3,0.8}
\definecolor{MyBlue3}{rgb}{0.3,0.5,1}
\definecolor{MyGreen}{rgb}{0.4,1,0.4}
\definecolor{MyRed}{rgb}{1,0.4,0.4}
\hypersetup{
    colorlinks=true,
    linkcolor=MyBlue1,
    citecolor=MyBlue1,
    linkbordercolor=MyRed, % blue
    citebordercolor=MyGreen, %MyGreen
    }

%% title and authors
\title{ \bf
%on the trade-off between marginal and dependence fit in MLMs
%Dependence Structures and Derivative Pricing in L\'evy Markets
%Multivariate L\'evy Models for Derivative Pricing
Multivariate L\'evy Models: Calibration and Pricing
}
\author{
{\bf Giovanni Amici}  \\
       Department of Mathematical Sciences\\
       Politecnico di Torino\\
       giovanni.amici@polito.it\\[14pt]
{\bf Paolo Brandimarte}  \\
       Department of Mathematical Sciences\\
       Politecnico di Torino\\[14pt]
{\bf Francesco Messeri}  \\
       Model Development and Integration Senior Specialist\\
       Intesa Sanpaolo Risk Management IMI CIB\\[14pt]
{\bf Patrizia Semeraro}  \\
       Department of Mathematical Sciences\\
       Politecnico di Torino\\%[4pt]
       }
\date{}


%% CHECK
%\usepackage[toc,page]{appendix}
%\usepackage[nottoc,notlot,notlof]{tocbibind}




\begin{document}

\maketitle

%%%%%%%
%\thispagestyle{empty}
%\begin{titlingpage}
\begin{abstract}
The goal of this paper is to investigate how the marginal and dependence structures of a variety of multivariate L\'evy models affect calibration and pricing.
To this aim, we study the approaches of \cite{luciano2010multivariate} and \cite{ballotta2016multivariate} to construct multivariate processes.
%, by examining the theory of the resulting models in their constrained and unconstrained versions, and with Variance Gamma and Normal Inverse Gaussian underlying distributions.
%then
We explore several calibration methods that can be used to fine-tune the models, and that deal with the observed trade-off between marginal and correlation fit. 
%After describing the payoffs of actively-traded exotic derivatives,
We carry out a thorough empirical analysis to evaluate the ability of the models to fit market data, price exotic derivatives, and embed a rich dependence structure.
%the exotics
By merging theoretical aspects with the results of the empirical test, we provide tools to make suitable decisions about the models and calibration techniques to employ in a real context.
\vfil

%\vspace{0.5cm} 
\noindent \textbf{Keywords}: Multivariate L\'evy Processes, Calibration, Pricing, Dependence, Exotic Derivatives.

%\vspace{0.5cm} 
\noindent \textbf{Disclaimer}: The views and opinions expressed belong solely to the authors and do not necessarily reflect the views or positions of Intesa Sanpaolo SpA.

\end{abstract}







%\newpage
%%%%%%
\section{Introduction}

Over the last decades, many attempts have been made to perform a well-informed and efficient valuation of multi-asset derivatives. To achieve this, numerous  multivariate L\'evy processes able to reproduce the joint dynamics of financial returns have been introduced in the financial literature.
%To achieve this aim, it is crucial to build multivariate processes able to reproduce time series of financial instruments.
As opposed to their univariate versions, the construction of these processes is more challenging, as it needs to provide flexibility of marginal and dependence structures and deal with possible trade-offs between them.
These factors affect model performance in the calibration and pricing phases. Calibration, in particular, is a delicate procedure that depends on the model architecture and the optimization techniques used to fit the set of parameters.
As a result, pricing multi-asset products requires non-trivial choices regarding the models and calibration settings to use to carry out the task.


To address these issues, we explore two model constructions introduced by \cite{luciano2010multivariate} and \cite{ballotta2016multivariate}.
The process of Luciano and Semeraro is a multivariate version of famous one-dimensional time-changed Brownian motions, such as the Variance Gamma \citep{madan1990variance} or Normal Inverse Gaussian \citep{barndorff1995normal}, and is designed to keep one-dimensional  marginal returns in known distribution classes.
The construction is done by linear combination of subordinators, a technique that allows to model nonlinear dependence.
On the other hand, the model proposed by Ballotta and Bonfiglioli is constructed through a parsimonious two-factor linear representation of log-return dynamics.
As discussed by the proposers, building the multivariate log-return process via linear combinations provides a flexible characterization and an intuitive economic interpretation of the models, which are broken down into an idiosyncratic and a systematic part.


However, the model of Luciano and Semeraro and that of Ballotta and Bonfiglioli have core theoretical differences.
The former is built to preserve marginal processes in a given class.
The latter, in its general formulation, has marginal processes belonging to unspecified classes, although proper convolution conditions can be imposed to change this feature. 
Convolution conditions were initially imposed in the article where the model has been introduced, but then removed in subsequent works [see \citep{ballotta2017multivariate} and \citep{ballotta2019estimation}], as the authors asserted that such conditions were unnecessary to improve tractability.
Also, the model proposed by Luciano and Semeraro allows for nonlinear dependence. As such, its margins can be mutually uncorrelated but still dependent.
On the contrary, when the margins of Ballotta and Bonfiglioli model are uncorrelated processes, they are also independent.


Besides the natural constructions of \cite{luciano2010multivariate} and \cite{ballotta2016multivariate} models, we examine alternative formulations that could provide some advantages in terms of calibration.
In particular, we explore a version of Luciano and Semeraro process that relaxes convolution constraints on subordinators.
In this way, model parameters lose some interpretability, but extend to wider domains, making model fitting potentially easier.
This approach, that lets marginal log-return processes to be of unknown class, was taken for example by \cite{guillaume2013alpha}, which introduced an unconstrained version of the \textit{$\alpha$-Variance Gamma} model of \cite{semeraro2008multivariate}.
Also, in addition to considering the unconstrained Ballotta and Bonfiglioli model, in this work we study the original version that imposes margins to be of given class, noting that this construction can, for instance, reduce the computational effort of calibration.
Overall, we analyze processes with constrained and unconstrained structures, and with Variance Gamma and Normal Inverse Gaussian underlying laws, for a total of eight models.
%In this paper, we compare the two philosophies behind \cite{luciano2010multivariate} and \cite{ballotta2016multivariate} models by first assessing the calibration and pricing performances of the constrained versions of the models.
%Secondly, we evaluate advantages and limitations of preserving known marginal distributions by testing the unconstrained versions.


As anticipated, a crucial issue to consider is the calibration procedure.
It can be quite simple for constrained models, that allow for a two-step procedure: first, marginal parameters are fitted to liquid volatility surfaces, and then dependence parameters are found by matching model and market correlations.
This procedure has the practical advantage that marginal parameters can be estimated once and then applied to a range of different multi-asset products.
Also, handling multiple marginal calibrations is not heavy from a computational point of view.
However, marginal and dependence fits can be subject to a trade-off, especially in constrained models.
As such, we analyze some techniques that can be applied to distribute calibration errors on one side or the other.
Mainly, they consist of running \textit{joint} calibrations (i.e., calibrating correlation and marginals at the same time; see e.g., \citep{marena2018pricing}), or allowing convolution conditions to be satisfied just up to a least-square approximation.
%, possibly depending on the payoff of the exotic derivative priced by the model.


On the other hand, calibrating unconstrained models always requires the joint procedure, as dependence parameters are included in the marginal parametrization.
Joint calibration requires an optimization problem with a considerable number of variables, and can be then  more difficult to handle with respect to the two-step procedure.
However, as unconstrained models remove convolution restrictions on marginals, their joint calibration is relatively simplified by the exclusion of stricter constraints.
Most importantly, not only the more flexible parametrization of these models reduces the computational effort of joint calibration, it could also find solutions that would not be found in constrained models due to the restricted parameter domains.
To verify whether this happens, we assess the ability of unconstrained models to reduce the marginal vs correlation fitting trade-off in a real context.
Also, we discuss whether a more flexible parametrization justifies the suppression of convolution conditions from a global viewpoint. %aspect
%Also, even when trade-off gets actually lower, we discuss whether such benefit justifies


In designing the empirical test of the models, we consider a calibration setting tailored to our case study.
In particular, we extensively discuss our choices about the optimization algorithm, the market data, and the calibration procedures employed to fit processes.
As constrained models have more interpretable parametrizations and more homogeneous marginal structures among each other, we assess them primarily.
First, we calibrate such models at several trading dates, report marginal parameters, and provide a thorough comparison of the fitting performances.
Thereafter, we employ models to price selected \textit{worst-performance} derivatives issued by Intesa Sanpaolo bank and examine the ability of the models to replicate market-quoted prices.
We further perform a sensitivity analysis to show the effect of linear and nonlinear dependence on the valuation of exotics, rewarding models that better capture these features.
After that, we test unconstrained models and discuss their results alongside those of the constrained versions.
%and discuss the strengths and weaknesses of adopting such constructions as opposed to the constrained versions.


The remainder of the paper is outlined as follows.
In Section \ref{Model Theory}, we report the theory behind the multivariate models introduced in \citep{luciano2010multivariate} and \citep{ballotta2016multivariate} in their numerous versions.
In Section \ref{Calibration Methods}, we explore the risk-neutral calibration methods %and the optimization techniques
to fit multivariate processes.
In Section \ref{Worst Performance Derivatives}, we describe the exotic derivatives employed in the analysis.
We then design the empirical test and discuss results in Section \ref{Empirical Analysis}, and draw conclusions in Section \ref{Conclusions}.









%%%%%%%%%
\section{Log-Return Processes}\label{Model Theory}

This section analyzes the approaches proposed by Luciano and Semeraro and by Ballotta and Bonfiglioli to construct multivariate processes.
We present such models in their multiple versions, preserving or not well-known marginal laws, and embedding Variance Gamma or Normal Inverse Gaussian components.
For each multivariate process, we report its characteristic function, its marginal laws and the correlation coefficient, pointing out relevant features of the construction.
For sake of simplicity, for any stochastic process $\{A(t)\}_{t\geq0}$, we let $A := A(1)$ and recall that any L\'evy process has characteristic function fully derivable by their time-1 distribution.




%%%%%
\subsection{LS Models}\label{LS Models}

In this subsection we recap the main steps to build the factor-based processes introduced in \citep{luciano2010multivariate}, that we name \textit{LS processes}.
Let $\{\boldsymbol{B}(t)\}_{t\geq0}$ and $\{\boldsymbol{B}^{\rho}(t)\}_{t\geq0}$ be multivariate Brownian motions with L\'evy triplets $(\boldsymbol{\mu}, \boldsymbol{\Sigma}, \boldsymbol{0})$ and $(\boldsymbol{\mu}^{\rho}, \boldsymbol{\Sigma}^{\rho}, \boldsymbol{0})$, respectively. In particular,
%
%
$$
\boldsymbol{\mu}
=
\begin{pmatrix}
    \mu_1, ..., \mu_n
\end{pmatrix},
\hspace{20pt}
\boldsymbol{\Sigma}
=
\text{diag}
\begin{pmatrix}
    \sigma_1^2, ..., \sigma_n^2
\end{pmatrix},
\hspace{20pt}
\mu_j \in \mathbb{R},\: \sigma_j > 0,\: j=1,...,n.
$$
%
%
Consider further the multi-parameter $\boldsymbol{s}=(s_1,...,s_n)^T \in \mathbb{R}_+^n$ and the multi-parameter process introduced by \cite{barndorff2001multivariate}, corresponding to the above defined Brownian $\boldsymbol{B}(t)$, that is
\begin{equation}
\boldsymbol{B}(\boldsymbol{s})=\{(B_{1}(s_{1}),...,B_{n}(s_{n})),\boldsymbol{%
s}\in \mathbb{R}_{+}^{n}\},  \label{MultiBM}
\end{equation}%
with the partial order on $\mathbb{R}_+^n$,
\begin{equation*}
\boldsymbol{s}^{1}\preceq \boldsymbol{s}^{2}\,\,\,\Leftrightarrow
\,\,\,s_{j}^{1}\leq s_{j}^{2},\, \hspace{10pt} j=1,...n.
\end{equation*}%
Moreover, let $\{\boldsymbol{X}(t)\}_{t\geq0}$ be a multivariate subordinator, with independent components and $\{Z(t)\}_{t\geq0}$ be a subordinator, independent from $\boldsymbol{X}(t)$.


With these processes, we can then define the multivariate log-return process of Luciano and Semeraro as
%
%
\begin{equation}\label{Y}    
    \boldsymbol{Y}(t)
    =
    \boldsymbol{B} (\boldsymbol{X}(t)) +
    \boldsymbol{B}^{\rho} (Z(t))
    =
    \begin{pmatrix}
        B_1 (X_1(t)) + B^{\rho}_1 (Z(t))
        \\
        ...
        \\
        B_n (X_n(t)) + B^{\rho}_n (Z(t))
    \end{pmatrix},
\end{equation}
%
%
where $\boldsymbol{B}(\boldsymbol{X}(t))$ and $\boldsymbol{B}^{\rho}(Z(t))$ can be considered as the idiosyncratic and the systematic risk components of the dynamics of the assets. Also, we set
%
%
$$
\boldsymbol{\mu}^{\rho} =
\begin{pmatrix}
    \mu_1 \kappa_1, ..., \mu_n \kappa_n
\end{pmatrix}
$$
$$
\boldsymbol{\Sigma}^{\rho} =
\begin{pmatrix}
    \sigma_1^2 \kappa_1 & \rho_{12} \sigma_1 \sigma_2 \sqrt{\kappa_1} \sqrt{\kappa_2} & ... & \rho_{1n} \sigma_1 \sigma_n \sqrt{\kappa_1} \sqrt{\kappa_n}
    \\
    \rho_{12} \sigma_1 \sigma_2 \sqrt{\kappa_1} \sqrt{\kappa_2} & \sigma_2^2 \kappa_2 & ... & \rho_{2n} \sigma_2 \sigma_n \sqrt{\kappa_2} \sqrt{\kappa_n}
    \\
    ... & ... & ... & ...
    \\ 
    \rho_{1n} \sigma_1 \sigma_n \sqrt{\kappa_1} \sqrt{\kappa_n} & \rho_{2n} \sigma_2 \sigma_n \sqrt{\kappa_2} \sqrt{\kappa_n} & ... & \sigma_n^2 \kappa_n
\end{pmatrix},
$$
%
%
with $\kappa_j>0, j=1,...,n$,
in such a way that each marginal log-return process $j$ is a Brownian motion with drift $\mu_j$, diffusion $\sigma_j$, and subordinated
by a factor-based subordinator
\begin{equation}\label{G_j}
G_j(t) = X_j(t) + \kappa_j Z(t).
\end{equation}
In particular, \cite{luciano2010multivariate} proved that
\begin{equation}\label{Y_j}
Y_{j}(t) \overset{\text{d}}{=} \mu _{j}G_{j}(t)+\sigma _{j} \Tilde{B}_j(G_{j}(t)),
\end{equation}%
where $\Tilde{B}_j$ is a standard Brownian motion.


By means of Theorem 30.1 in \citep{ken1999levy}, and Theorem 3.3 in \citep{barndorff2001multivariate} for the multivariate case, we are able to derive the time-1 characteristic function of the subordinated process as
%
%
\begin{equation}\label{LS-CF}
\phi _{\boldsymbol{Y}}(\boldsymbol{u}) =
\exp \Bigg\{ \sum_{j=1}^{n}l_{X_{j}}(\psi _{B_{j}}(u_{j}))
+
l_{Z}(\psi _{\boldsymbol{B}^{\rho }}(\boldsymbol{u})) \Bigg\},
\hspace{10pt}
\boldsymbol{u} \in \mathbb{R}^n,
\end{equation}
%
%
where $l(\cdot)$ and $\psi(\cdot)$ are the Laplace exponent and the characteristic exponent, respectively.
Also, pairwise correlations are given by
$$
\rho_{\boldsymbol{Y}} (i,j)
=
\frac{
\mathbb{E} [B_i^{\rho}] \mathbb{E} [B_j^{\rho}] \mathbb{V} (Z)
+ \text{Cov} ( B_i^{\rho}, B_j^{\rho} ) \mathbb{E}[Z]
}{\sqrt{ \mathbb{V}(Y_i) \mathbb{V}(Y_j) }}
=
\frac{
\mu_i \mu_j \kappa_i \kappa_j \mathbb{V} (Z)
+ \rho_{ij} \sigma_i \sigma_j \sqrt{\kappa_i} \sqrt{\kappa_j} \mathbb{E}[Z]
}{
\sqrt{ \mathbb{V}(Y_i) \mathbb{V}(Y_j) }
},
$$
where $\mathbb{E}[\cdot]$, $\mathbb{V}(\cdot)$ and $\text{Cov}(\cdot, \cdot)$ denote the expectation, variance and covariance, respectively.






%%%%%%%
\subsubsection{Constrained LS-Variance Gamma}\label{LS-VG}

As it can be seen from the LS process construction, the L\'evy class of $Y_j(t)$ is given by the specifications of subordinators. Here we illustrate the case where each asset log-return follows a Variance Gamma process \citep{madan1990variance}.
Let $X_1(t), ..., X_n(t), Z(t)$ be Gamma processes such that
\begin{equation}\label{Gamma-Sub}
    X_j \sim \Gamma \left(\frac{1}{\kappa_j} - a, \frac{1}{\kappa_j} \right),
    \hspace{15pt}
    Z \sim \Gamma \left(a, 1 \right),
    \hspace{15pt}
    \text{with}
    \hspace{15pt}
    0 < a < \min_j \left( \frac{1}{\kappa_j} \right),
    \hspace{5pt}
    \kappa_j > 0.
\end{equation}
Then, by the closure property of convolution of Gamma distributions, and following Eq.\ \eqref{G_j}, we get 
$$
G_j \sim \Gamma \left(\frac{1}{\kappa_j}, \frac{1}{\kappa_j} \right).
$$
\cite{luciano2010multivariate} proved that the resulting one-dimensional margin $Y_j(t)$ follows a VG$(\mu_j, \sigma_j, \kappa_j)$, i.e.,
\begin{equation}\label{VG-CF}
    \phi_{Y_j} (u) = \left( 1 - i u \mu_j \kappa_j + \frac{1}{2} u^2 \sigma^2_j \kappa_j \right)
    %^{\nicefrac{1}{\kappa_j}},
    ^{-\kappa^{-1}_j},
    \hspace{15pt}
    u \in \mathbb{R}
    ,
\end{equation}
while the multivariate process $\boldsymbol{Y} (t)$ is an LS-VG 
process with parameters $( \boldsymbol{\mu}, \boldsymbol{\sigma}, \boldsymbol{\kappa}, a, \{ \rho_{ij} \}_{i \neq j} )$ and characteristic function
%inferred from (\ref{LS-CF}) and (\ref{Gamma-Sub}).
\begin{equation}\label{LS-VG-CF}
\phi _{\boldsymbol{Y}}(\boldsymbol{u})=
\prod_{j=1}^{n}\left[ 1-{\kappa_{j}\left(i\mu _{j}u_{j}-\frac{1}{2}\sigma _{j}^{2}u_{j}^{2}\right)}\right]
%^{-\left( \nicefrac{1}{\kappa _{j}}-a\right) }
^{-\left( \kappa^{-1}_j-a\right) }
\left[ 1-\left( i\boldsymbol{u}^{T} \boldsymbol{\mu }^{\rho }-\frac{1}{2}\boldsymbol{u}^{T}\boldsymbol{\Sigma }^{\rho }\boldsymbol{u}\right) \right] ^{-a}
\hspace{-8pt}
,
\hspace{1pt}
\boldsymbol{u} \in \mathbb{R}^n.
\end{equation}%
The number of parameters of the time-1 distribution is $1 + 3n + \frac{n(n-1)}{2}$ and the correlation, for each pair $(i,j)$ of assets, is given by
\begin{equation}\label{rhoY-LS-VG}
    \rho_{\boldsymbol{Y}} (i,j)
    =
    \frac{
    \mu_i \mu_j \kappa_i \kappa_j
    +
    \rho_{ij} \sigma_i \sigma_j \sqrt{\kappa_i} \sqrt{\kappa_j}
    }{
    \sqrt{ (\sigma^2_i + \mu^2_i \kappa_i)
    (\sigma^2_j + \mu^2_j \kappa_j) }
    } \: a.
\end{equation}
Bounds on the correlation coefficient are thoroughly discussed by \cite{marena2018pricing}.
They observed that the maximum achievable level of correlation is linked to the marginal with the highest $\kappa$ parameter. As $\kappa$ drives the kurtosis, there exists a trade-off between the kurtosis marginal fit and the correlation admissible range.
However, an interesting feature is that dependence structure allows for non-linear dependence, which can be easily observed in case of symmetric marginals (i.e., $\mu_i= \mu_j = 0$) and uncorrelated Brownian motions. In this circumstance, we would get the correlation coefficient equal to 0 but still have non-zero dependence regulated by parameter $a$.





%%%%%%%
\subsubsection{Unconstrained LS-Variance Gamma}\label{LS-VG-uncLS}

As can be seen from \eqref{Gamma-Sub}, %the correlation 
parameter $a$ is bounded above from a term related to $\kappa_j$, that is a driver of marginal kurtosis.
The constraint on $a$ comes from the convolution condition needed to exclude $a$ from the marginal parametrization and to get an unbiased gamma subordinator, as in the traditional VG process.
As $a$ drives part of correlation, this interconnection among parameters is a source of trade-off between marginal and joint fit.
To deal with this issue, the convolution restriction can be relaxed, at the expense that one-dimensional margins do not have the traditional VG parametrization.
To this aim, we can introduce a new parameter vector $\boldsymbol{\alpha} = (\alpha_1, ..., \alpha_n)$, that provides more modeling flexibility, as follows.
Let $X_1(t), ..., X_n(t), Z(t)$ be Gamma processes such that
\begin{equation}\label{Gamma-Sub-uncLS}
    X_j \sim \Gamma \left(\alpha_j , \frac{1}{\kappa_j} \right),
    \hspace{15pt}
    Z \sim \Gamma \left(a, 1 \right),
    \hspace{15pt}
    \text{with}
    \hspace{15pt}
    a, \alpha_j, \kappa_j > 0.
\end{equation}
%
Then, by the closure property of convolution of Gamma distributions, and following Eq.\ \eqref{G_j}, we get 
$$
G_j \sim \Gamma \left(\alpha_j + a, \frac{1}{\kappa_j} \right).
$$
%
As a consequence, the characteristic function of the marginal distribution is
\begin{equation}\label{VG-CF-uncLS}
    \phi_{Y_j} (u) = \left( 1 - i u \mu_j \kappa_j + \frac{1}{2} u^2 \sigma^2_j \kappa_j \right)
    %^{\nicefrac{1}{\kappa_j}},
    ^{-(\alpha_j+a)},
    \hspace{15pt}
    u \in \mathbb{R}
    .
\end{equation}
The characteristic function of the resulting multivariate process $\boldsymbol{Y}(t)$ follows from \eqref{LS-CF}, and the correlation, for each pair $(i,j)$ of assets, is given by
\begin{equation}\label{rhoY-LS-VG-uncLS}
    \rho_{\boldsymbol{Y}} (i,j)
    =
    \frac{
    \mu_i \mu_j \kappa_i \kappa_j
    +
    \rho_{ij} \sigma_i \sigma_j \sqrt{\kappa_i} \sqrt{\kappa_j}
    }{
    \sqrt{ \kappa_i (\alpha_i + a) (\sigma^2_i + \mu^2_i \kappa_i) \:
    \kappa_j (\alpha_j + a)(\sigma^2_j + \mu^2_j \kappa_j) }
    } \: a.
\end{equation}
%
Note that here $a$ does not impact on the correlation range as it does in the constrained LS-VG model, since it is part of the marginal parametrization and now also appears in the denominator of $\rho_{\boldsymbol{Y}} (i,j)$. Therefore, having removed the original upper bound on $a$ does not, per se, increase the correlation admissible range. However, we are still interested in checking whether the interaction between these unconstrained parameters can, in practice, produce a more flexible dependence structure.







%%%%%%%
\subsubsection{Constrained LS-Normal Inverse Gaussian}\label{LS-NIG}

Another well-known type of L\'evy process is given by Normal Inverse Gaussian process \citep{barndorff1995normal}. Here we show how an LS process can be built such that its margins are NIG processes. Let $X_1(t), ..., X_n(t), Z(t)$ be Inverse Gaussian processes,
\begin{equation}\label{IG-Sub}
    X_j \sim \text{IG} \left(1 - a \sqrt{\kappa_j}, \frac{1}{\sqrt{\kappa_j}} \right),
    \hspace{15pt}
    Z \sim \text{IG} \left(a, 1 \right),
    \hspace{15pt}
    \text{with}
    \hspace{15pt}
    0 < a < \min_j \left( \frac{1}{\sqrt{\kappa}_j} \right),
    \hspace{5pt}
    \kappa_j > 0.
\end{equation}
Then, by the closure property of convolution of Inverse Gaussian distributions, and following Eq.\ \eqref{G_j}, we get 
$$
G_j \sim \text{IG} \left(1, \frac{1}{\sqrt{\kappa_j}} \right).
$$
\cite{luciano2010multivariate} proved that the resulting one-dimensional margin $Y_j(t)$ follows a NIG$(\beta_j, \delta_j, \gamma_j)$, with $-\gamma_j<\beta_j<\gamma_j$, $\delta_j>0$, $\gamma_j>0$, i.e.,
\begin{equation}\label{NIG-CF}
    \phi_{Y_j} (u) = \exp \left\{ -\delta_j \left(\sqrt{\gamma^2_j - (\beta_j + i u)^2} - \sqrt{\gamma^2_j - \beta^2_j}\right) \right\}
    ,
    \hspace{15pt}
    u \in \mathbb{R}
    ,
\end{equation}
where, applying relations
$$
\mu_j = \beta_j \delta^2,
\hspace{3pt}
\sigma_j = \delta_j,
\hspace{3pt}
\kappa_j = [\delta_j^2 (\gamma_j^2 - \beta_j^2)]^{-1},
$$
we get the same expression of Eq.\ \eqref{Y_j}.
$\boldsymbol{Y} (t)$ is then a LS-NIG$( \boldsymbol{\beta}, \boldsymbol{\delta}, \boldsymbol{\gamma}, a, \{ \rho_{ij} \}_{i \neq j} )$ with $1 + 3n + \frac{n(n-1)}{2}$ parameters, time-1 characteristic function 
%\begin{equation*}
%\begin{split}
%\phi _{\boldsymbol{Y}}(\boldsymbol{u})=
%& \exp \left\{ -\sum_{j=1}^{n} \left(1-\frac{a}{\zeta _{j}} \right)\left( \sqrt{-2 \left(i\beta _{j}\delta _{j}^{2}u_{j}-\frac{1}{2}\delta _{j}^{2}u_{j}^{2} \right)+\zeta _{j}^{2}}-\zeta _{j}\right) \right\} \cdot
%\\
%& \cdot \exp \left\{ -a\left( \sqrt{-2 \left(i\boldsymbol{u}^{T}\boldsymbol{\mu}^{\rho}-\frac{1}{2}\boldsymbol{u}^{T}\boldsymbol{\Sigma}^{\rho}\boldsymbol{u}\right)+1}-1\right) \right\},
%\hspace{10pt}
%\boldsymbol{u} \in \mathbb{R}^n,
%\end{split}%
%\end{equation*}
%where $\zeta _{j}=\delta _{j}\sqrt{\gamma _{j}^{2}-\beta _{j}^{2}}$, and correlation coefficient
\begin{equation*}
\begin{split}
\phi _{\boldsymbol{Y}}(\boldsymbol{u})=
& \exp \left\{ -\sum_{j=1}^{n} \left(1-a\sqrt{\kappa_{j}} \right)\left( \sqrt{-2 \left(i\beta _{j}\delta _{j}^{2}u_{j}-\frac{1}{2}\delta _{j}^{2}u_{j}^{2} \right)+\frac{1}{\kappa_{j}}} - \frac{1}{\sqrt{\kappa_{j}}} \right) \right\} \cdot
\\
& \cdot \exp \left\{ -a\left( \sqrt{-2 \left(i\boldsymbol{u}^{T}\boldsymbol{\mu}^{\rho}-\frac{1}{2}\boldsymbol{u}^{T}\boldsymbol{\Sigma}^{\rho}\boldsymbol{u}\right)+1}-1\right) \right\},
\hspace{10pt}
\boldsymbol{u} \in \mathbb{R}^n,
\end{split}%
\end{equation*}
and correlation coefficient
\begin{equation}\label{rhoY-LS-NIG}
    \rho_{\boldsymbol{Y}} (i,j)
    =
    \frac{
    \beta_i \delta_i^2 \kappa_i
    \beta_j \delta_j^2 \kappa_j
    +
    \rho_{ij} \delta_i \sqrt{\kappa_i} \delta_j \sqrt{\kappa_j}
    }{
    \sqrt{
    \gamma_i^2 \delta_i (\gamma_i^2 - \beta_i^2)^{-3/2}
    \:
    \gamma_j^2 \delta_j (\gamma_j^2 - \beta_j^2)^{-3/2}
    }
    } \: a.
\end{equation}
As far as the  dependence structure is concerned, considerations
similar to those in Subsection \ref{LS-VG} can be made.





%%%%%%%
\subsubsection{Unconstrained LS-Normal Inverse Gaussian}\label{LS-NIG-uncLS}

As in the VG case, it is possible to weaken the constraints on $a$ to try to reduce the trade-off between marginal and dependence fit of the NIG specification.
Let $X_1(t), ..., X_n(t), Z(t)$ be Inverse Gaussian processes such that
\begin{equation}\label{IG-Sub-uncLS}
    X_j \sim \text{IG} \left(\alpha_j, \frac{1}{\sqrt{\kappa_j}} \right),
    \hspace{15pt}
    Z \sim \text{IG} \left(a, 1 \right),
    \hspace{15pt}
    \text{with}
    \hspace{15pt}
    a, \alpha_j, \kappa_j > 0.
\end{equation}
Then, by the closure property of convolution of Inverse Gaussian distributions, and following Eq.\ \eqref{G_j}, we get 
$$
G_j \sim \text{IG} \left(\alpha_j + a \sqrt{k_j}, \frac{1}{\sqrt{\kappa_j}} \right).
$$
As a consequence, the characteristic function of the marginal distribution is
\begin{equation}\label{NIG-CF-uncLS}
    \phi_{Y_j} (u) = \exp \left\{ -\delta_j \left(\sqrt{\gamma^2_j - (\beta_j + i u)^2} - \sqrt{\gamma^2_j - \beta^2_j}\right) \left( \alpha_j + a \sqrt{\kappa_j} \right) \right\}
    ,
    \hspace{15pt}
    u \in \mathbb{R}
    ,
\end{equation}
where $\kappa_j = [\delta_j^2 (\gamma_j^2 - \beta_j^2)]^{-1}$.
%
The characteristic function of the resulting multivariate process $\boldsymbol{Y}(t)$ follows from \eqref{LS-CF}, and the correlation coefficient is
\begin{equation}\label{rhoY-LS-NIG-uncLS}
    \rho_{\boldsymbol{Y}} (i,j)
    =
    \frac{
    \beta_i \delta_i^2 \kappa_i
    \beta_j \delta_j^2 \kappa_j
    +
    \rho_{ij} \delta_i \sqrt{\kappa_i} \delta_j \sqrt{\kappa_j}
    }{
    \sqrt{
    (\alpha_i + a \sqrt{\kappa_i})
    \gamma_i^2 \delta_i (\gamma_i^2 - \beta_i^2)^{-3/2}
    \:
    (\alpha_j + a \sqrt{\kappa_j})
    \gamma_j^2 \delta_j (\gamma_j^2 - \beta_j^2)^{-3/2}
    }
    } \: a.
\end{equation}




%%%%%%
\subsection{BB Models}

We are now ready to present the second class of models, introduced by \cite{ballotta2016multivariate}. The authors proposed a multivariate process constructed by a convolution of two L\'evy processes, without the need to pass through subordinators.
We call processes of this kind as \textit{BB processes}, that are of the form
$$
\boldsymbol{Y}(t)
=
\boldsymbol{X}(t) + \boldsymbol{b}
\hspace{2pt}
Z(t)
=
\begin{pmatrix}
    X_1(t) + b_1 Z(t)
    \\
    ...
    \\
    X_n(t) + b_n Z(t)
\end{pmatrix},
$$
where $\boldsymbol{b} \in \mathbb{R}^n$, and $X_1(t), ..., X_n(t), Z(t)$ are $\mathbb{R}$-valued mutually independent L\'evy processes. Time-1 characteristic function is then


\begin{equation}\label{BB-CF}
\phi_{\boldsymbol{Y}}(\boldsymbol{u})
=
\exp \left\{ \sum_{j=1}^{n} \psi_{X_{j}}(u_{j})
%\right\} \exp \left\{
+
\psi_Z \left( \sum_{j=1}^{n} b_j u_j \right) \right\},
\hspace{10pt}
\boldsymbol{u} \in \mathbb{R}^n,
\end{equation}%
where $\psi(\cdot)$ denotes the characteristic exponent.
Also in this case, it is natural to consider $\boldsymbol{X}(t)$ and $Z(t)$ as the idiosyncratic and the systematic risk factors, respectively.
The pairwise correlations are given by
$$
\rho_{\boldsymbol{Y}} (i,j)
=
\frac{
b_i b_j \mathbb{V} (Z)
}{
\sqrt{ \mathbb{V}(Y_i) \mathbb{V}(Y_j) }
}
.
$$
As opposed to LS, BB models do not necessarily suffer trade-offs between marginal and dependence fit.
However, to obtain one-dimensional margins belonging to a known class (e.g., VG, NIG), we would have to first set the distributions for $Y_j(t), j=1,...,n$, and then imposing the following convolution conditions on marginal distributions,
\begin{equation}\label{conv-conditions}
\psi_j (u) = \psi_{X_j} (u) + \psi_Z (b_j u)
,
\hspace{15pt}
j = 1, ..., n.
\end{equation}
Specifically, the fitting procedure of constrained BB models consists of first estimating $Y_j(t)$ parameters, and then finding combinations of $X_j(t)$, $b_j$ and $Z(t)$ parameters that reflect market correlation, while still being marginally distributed as $Y_j(t)$.
However, such convolution conditions can require restrictive constraints on parameters, likely to be satisfied only up to an approximation.





%%%%%%%%%
\subsubsection{Constrained BB-Variance Gamma}\label{BB-VG}

The construction of a BB model of VG type is made by assuming that each component follows a VG process. Getting the resulting process with VG margins requires some convolution conditions that follow from  Eq.\ \eqref{conv-conditions}, and that have been found by Ballotta and Bonfiglioli. In particular, let
$
Y_j \sim \text{VG} (\mu_j, \sigma_j, \kappa_j)
,
\hspace{3pt}
X_j \sim \text{VG} (\mu_{X_j}, \sigma_{X_j}, \kappa_{X_j})
,
\hspace{3pt}
Z \sim \text{VG} (\mu_Z, \sigma_Z, \kappa_Z)
$,
with characteristic functions as in Eq.\ \eqref{VG-CF}. Then, to satisfy convolution conditions \eqref{conv-conditions}, the following constraints must hold:
\begin{equation}\label{VG-conv-restrictions-1}
\begin{aligned}
    \kappa_j \mu_j = \kappa_Z b_j \mu_Z
    ,
    \hspace{15pt}
    j = 1, ..., n,
    \\
    \kappa_j \sigma^2_j = \kappa_Z b^2_j \sigma^2_Z
    ,
    \hspace{15pt}
    j = 1, ..., n,
\end{aligned}
\end{equation}
from which we obtain relations
\begin{equation}\label{VG-conv-restrictions-2}
    \mu_j = \mu_{X_j} + b_j \mu_Z
    ,
    \hspace{15pt}
    \sigma_j = \sqrt{ \sigma^2_{X_j} + b^2_j \sigma^2_Z }
    ,
    \hspace{15pt}
    \kappa_j = \frac{ \kappa_{X_j} \kappa_Z }{ \kappa_{X_j} + \kappa_Z }
    ,
    \hspace{15pt}
    j = 1, ..., n
    .
\end{equation}
The resulting multivariate process $\boldsymbol{Y}(t)$ is then a BB-VG$( \boldsymbol{\mu}_{X}, \boldsymbol{\sigma}_X, \boldsymbol{\kappa}_X, \boldsymbol{b}, \mu_Z, \sigma_Z, \kappa_Z )$ with $4n+3$ parameters, characteristic function 
%(\ref{BB-CF}) and (\ref{VG-CF-inBB}),
\begin{equation*}
\begin{split}
    \phi_{\boldsymbol{Y}} (\boldsymbol{u}) =
    & \prod_{j=1}^n \left( 1 - i u_j \mu_{X_j} \kappa_{X_j} + \frac{1}{2} u_j^2 \sigma^2_{X_j} \kappa_{X_j} \right)
    %^{\nicefrac{1}{\kappa_{X_j}}} \cdot
    ^{\kappa^{-1}_{X_j}} \cdot
    \\
    & \cdot \left[ 1 - i \mu_Z \kappa_Z \sum_{j=1}^n b_j u_j + \frac{1}{2} \sigma^2_Z \kappa_Z \left(\sum_{j=1}^n b_j u_j \right)^2 \right]
    %^{\nicefrac{1}{\kappa_Z}}
    ^{\kappa^{-1}_Z}
    ,
    \hspace{15pt}
    \boldsymbol{u} \in \mathbb{R}^n
    ,
    \end{split}
\end{equation*}
and correlation coefficient
\begin{equation}\label{rhoY-BB-VG}
    \rho_{\boldsymbol{Y}} (i,j)
    =
    \frac{
    b_i b_j (\sigma^2_Z + \mu^2_Z \kappa_Z)
    }{
    \sqrt{ (\sigma^2_i + \mu^2_i \kappa_i)
    (\sigma^2_j + \mu^2_j \kappa_j) }
    }.
\end{equation}





%%%%%%%%%
\subsubsection{Unconstrained BB-Variance Gamma}\label{BB-VG-uncBB}

Removing the convolution conditions in Eqs.\ \eqref{VG-conv-restrictions-1} and \eqref{VG-conv-restrictions-2}, we can simplify the BB-VG construction.
Let
$
X_j \sim \text{VG} (\mu_{X_j}, \sigma_{X_j}, \kappa_{X_j}),
\hspace{3pt}
Z \sim \text{VG} (\mu_Z, \sigma_Z, \kappa_Z)
$,
with characteristic functions as in Eq.\ \eqref{VG-CF}. Then, without making any further assumption, the characteristic function of $Y_j$ is given by
\begin{equation}\label{VG-CF-uncBB}
    \phi_{Y_j} (u) =
    \left( 1 - i u \mu_{X_j} \kappa_{X_j} + \frac{1}{2} u^2 \sigma^2_{X_j} \kappa_{X_j} \right)
    ^{-\kappa^{-1}_{X_j}}
    \hspace{1pt}
    \left( 1 - i u b_j \mu_Z \kappa_Z + \frac{1}{2} u^2 b_j^2 \sigma^2_Z \kappa_Z \right)
    ^{-\kappa^{-1}_Z},
\end{equation}
with $u \in \mathbb{R}$.
%
The characteristic function of the resulting multivariate process $\boldsymbol{Y}(t)$ follows from \eqref{BB-CF}, and the pairwise correlation coefficient is
\begin{equation}\label{rhoY-BB-VG-uncBB}
    \rho_{\boldsymbol{Y}} (i,j)
    =
    \frac{
    b_i b_j (\sigma^2_Z + \mu^2_Z \kappa_Z)
    }{
    \sqrt{
    \left[ \sigma^2_{X_i} + \mu^2_{X_i} \kappa_{X_i} + b_i^2 (\sigma^2_Z + \mu^2_Z \kappa_Z ) \right]
    \left[ \sigma^2_{X_j} + \mu^2_{X_j} \kappa_{X_j} + b_j^2 (\sigma^2_Z + \mu^2_Z \kappa_Z ) \right]
    }
    }.
\end{equation}









%%%%%%%%%
\subsubsection{Constrained BB-Normal Inverse Gaussian}\label{BB-NIG}

\cite{ballotta2016multivariate} originally formulated a multivariate NIG with unbiased subordinator, with parametrization similar to BB-VG.
Here, for sake of comparison with LS construction, we present a new version that keeps the same marginal distributions of the constrained LS-NIG.
Let $Y_j \sim \text{NIG} (\beta_j, \delta_j, \gamma_j), \hspace{3pt} X_j \sim \text{NIG} (\beta_{X_j}, \delta_{X_j}, \gamma_{X_j}), \hspace{3pt} Z \sim \text{NIG} (\beta_Z, \delta_Z, \gamma_Z)$,
with characteristic functions as in Eq.\ \eqref{NIG-CF}. Then, to satisfy the convolution conditions of Eq.\ \eqref{conv-conditions}, the following constraints must hold,
\begin{equation}\label{NIG-conv-restrictions-1}
\begin{aligned}
    \beta_j = b_j^{-1} \beta_Z
    ,
    \hspace{15pt}
    j = 1, ..., n,
    \\
    \gamma_j = b_j^{-1} \gamma_Z
    ,
    \hspace{15pt}
    j = 1, ..., n,
\end{aligned}
\end{equation}
from which we obtain the relationships
\begin{equation}\label{NIG-conv-restrictions-2}
    \beta_j = \beta_{X_j} = b_j^{-1} \beta_Z
    ,
    \hspace{15pt}
    \delta_j = \delta_{X_j} + b_j \delta_Z
    ,
    \hspace{15pt}
    \gamma_j = \gamma_{X_j} = b_j^{-1} \gamma_Z
    ,
    \hspace{15pt}
    j = 1, ..., n
    .
\end{equation}
The resulting multivariate process $\boldsymbol{Y}(t)$ is then a BB-NIG$( \boldsymbol{\beta}_{X}, \boldsymbol{\delta}_X, \boldsymbol{\gamma}_X, \boldsymbol{b}, \beta_Z, \delta_Z, \gamma_Z )$ with $4n+3$ parameters, characteristic function
%derived combining (\ref{BB-CF}) and (\ref{NIG-CF-inBB})
\begin{equation*}
\begin{split}
    \phi_{\boldsymbol{Y}} (\boldsymbol{u}) =
    & \prod_{j=1}^n
    \exp \left\{ -\delta_{X_j} \left(\sqrt{\gamma^2_{X_j} - \left(\beta_{X_j} + i u_j \right)^2} - \sqrt{\gamma^2_{X_j} - \beta^2_{X_j}}\right) \right\} \cdot
    \\
    & \cdot \exp \left\{ -\delta_Z \left(\sqrt{\gamma^2_Z - \left(\beta_Z + i \sum_{j=1}^n b_j u_j \right)^2} - \sqrt{\gamma^2_Z - \beta^2_Z} \right) \right\}
    ,
    \hspace{15pt}
    \boldsymbol{u} \in \mathbb{R}^n
    ,
\end{split}
\end{equation*}
and correlation coefficient
\begin{equation}\label{rhoY-BB-NIG}
    \rho_{\boldsymbol{Y}} (i,j)
    =
    \frac{
    b_i b_j \gamma^2_Z \delta_Z (\gamma^2_Z - \beta^2_Z)^{-3/2}
    }{
    \sqrt{ \gamma^2_i \delta_i (\gamma^2_i - \beta^2_i)^{-3/2}
    \:\:
    \gamma^2_j \delta_j (\gamma^2_j - \beta^2_j)^{-3/2} }
    }.
\end{equation}






%%%%%%%%%
\subsubsection{Unconstrained BB-Normal Inverse Gaussian}\label{BB-NIG-uncBB}

Also for the NIG case, the unconstrained version is simpler than the constrained one and it is reported here below.
Let
$
X_j \sim \text{NIG} (\beta_{X_j}, \delta_{X_j}, \gamma_{X_j}),
\hspace{3pt}
Z \sim \text{NIG} (\beta_Z, \delta_Z, \gamma_Z)
$,
with characteristic functions as in Eq.\ \eqref{NIG-CF}. Then, without making any further assumption, the characteristic function of $Y_j$ is given by
\begin{equation}\label{NIG-CF-uncBB}
\begin{split}
    \phi_{Y_j} (u) =
    & \exp \left\{ -\delta_{X_j} \left(\sqrt{\gamma^2_{X_j} - (\beta_{X_j} + i u)^2} - \sqrt{\gamma^2_{X_j} - \beta^2_{X_j}}\right) \right\} \cdot
    \\
    \cdot
    & \exp \left\{ -\delta_Z \left(\sqrt{\gamma^2_Z - (\beta_Z + i u b_j)^2} - \sqrt{\gamma^2_Z - \beta^2_Z}\right) \right\}
    ,
    \hspace{15pt}
    u \in \mathbb{R}
    ,
\end{split}
\end{equation}
with $u \in \mathbb{R}$.
%
The characteristic function of the resulting multivariate process $\boldsymbol{Y}(t)$ follows from \eqref{BB-CF}, and the pairwise correlation coefficient is
\begin{equation}\label{rhoY-BB-NIG-uncBB}
    \rho_{\boldsymbol{Y}} (i,j)
    =
    \frac{
    b_i b_j \gamma^2_Z \delta_Z (\gamma^2_Z - \beta^2_Z)^{-3/2}
    }{
    \sqrt{ v_i v_j }
    },
\end{equation}
$$
v_i = \gamma^2_{X_i} \delta_{X_i} (\gamma^2_{X_i} - \beta^2_{X_i})^{-3/2}
    + b_i^2
    \gamma^2_Z \delta_Z (\gamma^2_Z - \beta^2_Z)^{-3/2},
$$
$$
v_j = \gamma^2_{X_j} \delta_{X_j} (\gamma^2_{X_j} - \beta^2_{X_j})^{-3/2}
    + b_j^2
    \gamma^2_Z \delta_Z (\gamma^2_Z - \beta^2_Z)^{-3/2}.
$$

















%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%
\section{Calibration Methods}\label{Calibration Methods}

In this section, we illustrate the calibration methods that can be employed to fit multivariate models to market data.
In terms of asset prices, we calibrate an $\mathbb{R}^n$-valued asset price process $\{ \boldsymbol{S} (t) \}_{t \geq 0}$ with margins given by
$$
S_j (t) = \exp \{ (r - q_j + \omega_j) t + Y_j (t) \}
,
\hspace{15pt}
j = 1, ..., n
$$
where $Y_j(t)$ is the $j$-th marginal of any of the multivariate log-return processes $\{ \boldsymbol{Y} (t) \}_{t \geq 0}$ introduced in Section \ref{Model Theory}.
Also, $r$ is the risk-free rate, $q$ is the $j$-th continuously compounded dividend yield and $\omega_j = - \psi_{Y_j} (u = -i)$ is the $j$-th mean correction to assure the martingale condition, needed in the risk-neutral world.


As described by \cite{marena2018pricing} and \cite{ballotta2016multivariate}, when LS and BB models impose margins of known L\'evy class, they allow for a two-stage procedure: first, marginal parameters are calibrated by exploiting liquid volatility surfaces; then, dependence parameters are found by matching model and market correlations.
Marginal calibration consists of solving, for each asset $j=1,...,n$, the optimization problem:
%
%
\begin{equation}\label{marginal calibration}
\begin{aligned}
\mathcal{M}^*_j
=
\hspace{5pt}
& \underset{
\mathcal{M}_j
}{\text{argmin}}
& & \frac{1}{N_j} \sum_{l=1}^{N_{j}} \omega_l \big[ v_l^{\text{mod}} (\mathcal{M}_j) - v_l^{\text{mkt}} \big]^2
\\
& \text{subject to}
& & \mathcal{M}_j \in \overline{\mathcal{M}}
\end{aligned}
\end{equation}
%
%
where $v_l^{\text{mod}} (\mathcal{M}_j)$ and $v_l^{\text{mkt}}$ denote the $l$-th Black-Scholes implied volatilities from model and market prices, respectively.
Also, $N_j$ is the number of volatilities
%$\{ v_l \}_{l = 1, ..., N_j}$
chosen to fit the univariate process, $\{ \omega_l \}_{l=1,...,N_j}$ is an arbitrary set of weights, $\mathcal{M}_j$ is the set of marginal parameters, $\overline{\mathcal{M}} = \{\mu_j \in \mathbb{R}; \hspace{5pt} \sigma_j > 0; \hspace{5pt} \kappa_j > 0\}$ is the set of constraints when margins are VG, whereas $\overline{\mathcal{M}} = \{-\gamma_j < \beta_j < \gamma_j; \hspace{5pt} \delta_j > 0; \hspace{5pt} \gamma_j > 0\}$ is the set of constraints when margins are NIG.


Once the optimized marginals $\{ \mathcal{M}^*_1, ..., \mathcal{M}^*_n \}$ are obtained, dependence parameters $\mathcal{D}$ are fitted by
solving
\begin{equation}\label{dependence-calibration}
\begin{aligned}
\mathcal{D}^*
=
\hspace{5pt}
& \underset{
\mathcal{D}
}{\text{argmin}}
& & \frac{2}{n (n-1)}
\sum_{i=1}^n
\sum_{j>i}
\big[ \rho_{\boldsymbol{Y}}^{\text{mod}} (i, j, \mathcal{M}^*_i, \mathcal{M}^*_j, \mathcal{D}) - \rho_{\boldsymbol{Y}}^{\text{mkt}} (i,j) \big]^2
\\
& \text{subject to}
& & \mathcal{D} \in \overline{\mathcal{D}}
%\\
%&&& \mathcal{M}_j \in \mathcal{X}
\end{aligned}
\end{equation}
where $\overline{\mathcal{D}}$ is a model-specific feasible region to be specified in Subsection \ref{Model-Specific Calibrations}.
Also, assuming the availability of a single quoted price (for each pair of assets) from a liquidly-traded multi-name instrument, $\rho_{\boldsymbol{Y}}^{\text{mkt}} (i,j)$ is the Black-Scholes implied correlation from that quote.
Analogously, $\rho_{\boldsymbol{Y}}^{\text{mod}} (i, j, \mathcal{D})$ would be the implied correlation from the model price of the multi-name product.
Multiple correlations along strikes and maturities might be available, but it is more frequent to have only one, possibly derived from a quote estimated according to beliefs of traders, rather than an actual liquid quote.
Another common situation is to have no liquid prices at all, in which case $\rho_{\boldsymbol{Y}}^{\text{mkt}} (i,j)$ is approximated by historical correlation and $\rho_{\boldsymbol{Y}}^{\text{mod}} (i, j, \mathcal{D})$ by theoretical correlation as in, say, \eqref{rhoY-LS-VG}, abandoning the risk-neutral measure.








%%%%%%%%
\subsection{Model-Specific Calibrations}\label{Model-Specific Calibrations}

Having presented the commonly used two-step calibration, we now examine alternative formulations that can help models to reduce the observed trade-off between marginal and dependence fit.
To this aim, we show tailor-made calibration settings of constrained LS and BB processes. Also, we specify the only possible fitting procedure for unconstrained models, that are supposed to reduce trade-off by construction.
%Besides the commonly used two-step calibration, we examine alternative formulations that help constrained models to deal with the observed trade-off between marginal and dependence fit. Also, we specify the calibration setting for unconstrained processes, that do not admit two-step procedures. Such processes are thought to reduce trade-off by themselves.


In the constrained LS models (see Subsections \ref{LS-VG} and \ref{LS-NIG}), dependence parameters are  $\mathcal{D} = \left(a, \{ \rho_{ij} \}_{i \neq j}\right)$, while the feasible region is given by
$$
\overline{\mathcal{D}} = \Big\{ 0 < a < \min_j \Big( \kappa_j^{-m} \Big);
\hspace{5pt}
-1 \leq \rho_{ij} \leq 1, \forall i \neq j \Big\},
$$
where $m=1$ in the LS-VG case, and $m=0.5$ in LS-NIG.
As anticipated, the above bounds on $a$ lead to a potential trade-off between correlation range and marginal kurtosis fit.
As marginal parameters are calibrated before dependence ones, calibration error is likely to be concentrated on correlation.
To better distribute the error, \cite{marena2018pricing} propose to run a joint calibration instead, consisting of performing marginal fit of all the assets at the same time, while imposing a maximum level of correlation gap allowed, $\epsilon>0$.
In particular,
%
%
\begin{equation}\label{joint calibration}
\begin{aligned}
\{\mathcal{M}^*_1, ..., \mathcal{M}^*_n, \mathcal{D}^*\}
=
\hspace{5pt}
& \underset{
\mathcal{M}_1, ..., \mathcal{M}_n, \mathcal{D}
}{\text{argmin}}
& & \sum_{j = 1}^n
\frac{1}{N_j} \sum_{l=1}^{N_{j}} \big[ v_l^{\text{mod}} (\mathcal{M}_j) - v_l^{\text{mkt}} \big]^2
\\
& \text{subject to}
& & \mathcal{M}_1, ..., \mathcal{M}_n \in \overline{\mathcal{M}}%;
%\hspace{5pt}
%\mathcal{D} \in \overline{\mathcal{D}}
\\
&&& \mathcal{D} \in \overline{\mathcal{D}}
\\
&&& \abs{
\rho_{\boldsymbol{Y}}^{\text{mod}} (i, k, \mathcal{D}) - \rho^{\text{mkt}} (i,k)
}
< \epsilon
,
\hspace{10pt}
i \neq k.
\end{aligned}
\end{equation}
%
%


As it can be seen, Eq.\ \eqref{joint calibration} does not include dependence parameters in the objective function.
This might lead to situations where marginal kurtosis are already low, and we prevent calibration from finding a correlation error lower than $\epsilon$.
%, even if we could.
In practice, joint calibration is preferably run only after the (less expensive) two-stage calibration has failed to reach an acceptable correlation fit.
In such cases, the trade-off between marginals and correlation should push correlation error to get closer to $\epsilon$.
Another approach to deal with the mentioned trade-off can be to run the usual two-stage calibration, but adding a suitable upper bound on $\kappa_j$ to the feasible region $\overline{\mathcal{M}}_j$, $j=1...,n$.
This could avoid the need for a joint calibration, whose optimization problem could struggle with high dimensionality.
However, choosing such upper bound requires to have some previous knowledge of the market condition, which can be non-trivial.


Concerning the constrained BB-VG model (Subsection \ref{BB-VG}), dependence parameters are $\mathcal{D} = (b_1, ..., b_n, \mu_Z, \sigma_Z, \kappa_Z)$ and the feasible region is given by
%
%
\begin{equation}\label{BB-VG feasible region}
\begin{aligned}    
\overline{\mathcal{D}} =
& \: \{ b_j \in \mathbb{R}, \forall j;\: \mu_Z \in \mathbb{R};\: \sigma_Z>0;\: \kappa_Z>0 \}
\hspace{1pt}
\\ & \cap \: \{ \sigma_j^2 - b_j \sigma_Z^2 >0, \forall j;\: \kappa_Z - \kappa_j >0, \forall j \}
\hspace{1pt}
\\ & \cap \: \{ \kappa_j \mu_j = \kappa_Z b_j \mu_Z, \forall j;\: \kappa_j \sigma^2_j = \kappa_Z b^2_j \sigma^2_Z, \forall j \}.
\end{aligned}
\end{equation}
%
%
In the constrained BB-NIG model (Subsection \ref{BB-NIG}), dependence parameters are $\mathcal{D} = (b_1, ..., b_n, \beta_Z, \delta_Z, \gamma_Z)$, while the feasible region is
%
%
\begin{equation}\label{BB-NIG feasible region}
\begin{aligned}    
\overline{\mathcal{D}} =
& \: \{ b_j \in \mathbb{R}, \forall j;\: -\gamma_Z < \beta_Z < \gamma_Z;\: \delta_Z>0;\: \gamma_Z>0 \}
\hspace{1pt}
\\ & \cap \: \{ \delta_j - b_j \delta_Z >0, \forall j \}
\hspace{1pt}
\\ & \cap \: \{ \beta_j = b_j^{-1} \beta_Z, \forall j;\: \gamma_j = b_j^{-1} \gamma_Z, \forall j \}.
\end{aligned}
\end{equation}
%
%
The first and second sets of constraints of \eqref{BB-VG feasible region} and \eqref{BB-NIG feasible region} ensure that parameters of the systematic and the idiosyncratic components satisfy their domains.
The third sets, that we resume from \eqref{VG-conv-restrictions-1} and \eqref{NIG-conv-restrictions-1}, are needed to meet convolution conditions \eqref{conv-conditions}. \cite{ballotta2016multivariate} observed that such equality constraints are often satisfied only up to a least squares approximation.


In practice, dependence calibration of constrained BB models can be reformulated as a relaxed problem where restrictions \eqref{VG-conv-restrictions-1} or \eqref{NIG-conv-restrictions-1} are shifted to the objective function as follows:
%
%
\begin{equation}\label{BB dependence-calibration 2}
\begin{aligned}
\mathcal{D}^*
=
\hspace{5pt}
& \underset{
\mathcal{D}
}{\text{argmin}}
& & \frac{2}{n (n-1)}
\sum_{i=1}^n
\sum_{j>i}
\big[ \rho_{\boldsymbol{Y}}^{\text{mod}} (i, j, \mathcal{M}^*_i, \mathcal{M}^*_j, \mathcal{D}) - \rho_{\boldsymbol{Y}}^{\text{mkt}} (i,j) \big]^2
+
h \sum_{j=1}^n (c_{j,1}^2 + c_{j,2}^2)
\\
& \text{subj.\ to}
& & \mathcal{D} \in \overline{\mathcal{D}} \setminus \eqref{VG-conv-restrictions-1}, \eqref{NIG-conv-restrictions-1}
\end{aligned}
\end{equation}
%
%
%
where
$$
\begin{cases}
c_{j,1} = \kappa_j \mu_j - \kappa_Z b_j \mu_Z,\: c_{j,2} = \kappa_j \sigma_j^2 - \kappa_Z b_j^2 \sigma_Z^2
&
\text{for VG}
\\
c_{j,1} = \beta_j - b_j^{-1} \beta_Z,\: c_{j,2} = \gamma_j - b_j^{-1} \gamma_Z
&
\text{for NIG}
\end{cases}
$$
for some $h>0$.
%A viable approach can be, for example, to set a large $h$ and impose a maximum correlation error allowed $\epsilon$, in the spirit of LS joint calibration.
An alternative approach that avoids the arbitrary parameter $h$ is to consider an objective function that only includes the convolution-related penalty term, while the correlation term is expressed as a constraint.
The optimization problem would then become
%
%
\begin{equation}\label{BB dependence-calibration}
\begin{aligned}
\mathcal{D}^*
=
\hspace{5pt}
& \underset{
\mathcal{D}
}{\text{argmin}}
& & \sum_{j=1}^n (c_{j,1}^2 + c_{j,2}^2)
\\
& \text{subj.\ to}
& & \mathcal{D} \in \overline{\mathcal{D}} \setminus \eqref{VG-conv-restrictions-1}, \eqref{NIG-conv-restrictions-1}
\\
&&& \abs{
\rho_{\boldsymbol{Y}}^{\text{mod}} (i, k, \mathcal{D}) - \rho^{\text{mkt}} (i,k)
}
< \epsilon
,
\hspace{10pt}
i \neq k.
\end{aligned}
\end{equation}
Although a trade-off between marginal and dependence fit is not apparent in BB theoretical construction, it is still possible to encounter it in practice, when we try to meet convolution conditions.
For this reason, either the penalty coefficient $h$ in \eqref{BB dependence-calibration 2} or the maximum correlation error allowed $\epsilon$ in \eqref{BB dependence-calibration} should be suitable tuned to shift calibration error on one side or the other.
The resulting convolution errors of \eqref{BB dependence-calibration 2} or \eqref{BB dependence-calibration} can be then measured as differences between marginal moments of the laws of $Y_j$ and $X_j + b_j Z$, $j=1, ..., n$, or comparing calibration fits of the these two distributions.


With regards to the unconstrained versions of LS and BB models, dependence parameters enter the marginal parametrization.
A two-stage calibration to fit these models is then improper, since each marginal calibration would subsequently change the value of a dependence parameter.
The only way to estimate these processes is by means of a joint calibration as in \eqref{joint calibration},
with the important difference that the feasible region $\overline{\mathcal{D}}$ only includes domain-related restrictions.









%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%
% \subsection{Optimization Techniques}\label{Optimization Techniques}

% We conclude this section with a short review of algorithms and methods that can be used to deal with a nonlinear optimization problem, as calibration normally is.
% By so doing, we report some widespread techniques to perform an efficient and stable calibration, in order to provide the reader with tools to make well-informed decisions depending on the context.


% The aim of calibrating a pricing model is to find a set of model parameters for which prices of liquid instruments computed by the same model corresponds to market prices.
% In practice, calibration turns out to be an \textit{ill-posed} problem, i.e., it can either have no solutions or multiple solutions.
% The existence of a solution is de facto guaranteed by defining model calibration as an optimization problem. Taking MSE as error measure, we find model parameters $\mathcal{P}$ that minimize the objective function $f$ as
% \begin{equation}\label{min-OF}
%     \mathcal{P}^*
%     =
%     \underset{\mathcal{P}}{\text{argmin}}
%     \hspace{3pt}
%     f (\mathcal{P})
%     :=
%     \underset{\mathcal{P}}{\text{argmin}}
%     \hspace{3pt}
%     \sum_j \omega_j (z_j^{\text{mod}} (\mathcal{P}) - z_j^{\text{mkt}})^2
%     \end{equation}
% where $z_j^{\text{mod}}$ and $z_j^{\text{mkt}}$ are model and market prices, respectively (or similarly implied volatilities, or implied correlations).
% However, due to a limited number of liquid instruments, the solution to these problems is not unique.
% In particular, objective functions are non-convex and could display multiple global minima, meaning that parameters are not able to uniquely identify the model \citep{cont2010model}.
% Research then focuses on finding algorithms that could help converging to near-optimal solutions (in a feasible amount of time) and tools to improve problem stability.

% A natural choice for calibration problems are \textit{stochastic search} algorithms. They do not require convexity nor differentiability of the objective function, making them very flexible, although convergence to the optimum is relatively slow. Examples are Simulated Annealing \citep{kirkpatrick1983optimization} and Differential Evolution \citep{storn1997differential}, while an application to model calibration can be found, for example, in \citep{cont2004recovering}.

% Another family of techniques relies on \textit{multi-start} search,
% whereby local optimization solvers are started from different initial points, so that they converge to possibly different local optima. 
% In other words, the set of feasible solutions is conceptually partitioned into basins of attraction, i.e., subregions associated with a local minimum, such that a local solver converges to that specific local minimum, when the starting point is contained in that basin of attraction. 
% Critical choices are the selection of starting points, 
% which may rely on naive grids or clever exploration,
% as well as the selection of the local solver.
% Examples are steepest descent, conjugate gradient and Newton's method. See the textbook \citep{jan2018practical}  for a general treatment, and \citep{cont2004nonparametric} or \citep{alfeus2020regularization} for an application to model calibration problems.
% The speed and reliability of these techniques
% also depend on the objective function, whose gradients could be easy to compute or not.

% An alternative to these two strategies would be to use \textit{surrogate} optimization, based on approximating the objective function by a global metamodel.
% This strategy is particularly suitable when the evaluation
% of the objective function is computationally heavy, and its reliability depend on the assumption that the objective function is smooth enough.
% Examples are Gaussian Process Regression and Artificial Neural Networks (ANN). See the textbook \citep{kochenderfer2019algorithms} for details on the surrogate approach, and \citep{ruf2019neural} for a literature review of ANN for pricing models.

% %%%%%%%%%%%
% A common approach to deal with the non-identifiability of parameters is \textit{regularization}, consisting of adding a convex penalty term to the objective function, to shrink the solution towards some prior guesses.
% In particular, the objective function becomes
% \begin{equation}\label{OF-Reg}
%     f_{\lambda, \mathcal{P}_0} (\mathcal{P})
%     =
%     f (\mathcal{P}) +
%     \lambda
%     \cdot
%     R (\mathcal{P}, \mathcal{P}_0)
% \end{equation}
% where $R (\mathcal{P}, \mathcal{P}_0)$ is the regularization function and $\lambda$ is the regularization parameter.
% The former can be, for example, a squared distance between the parameter vector and its prior guess,
% $
% R (\mathcal{P}, \mathcal{P}_0)
% =
% \sum_i (\mathcal{P}^{(i)} - \mathcal{P}_0^{(i)} )^2
% $,
% known as Tikhonov regularization (see \citep{tikhonov1963solution} and financial applications e.g., in \citep{egger2005tikhonov}, \citep{crepey2010tikhonov}, \citep{dai2016calibration}, \citep{alfeus2020regularization}).
% An alternative regularization term is relative entropy, i.e.,
% $
% R (\mathcal{P}, \mathcal{P}_0)
% =
% H ( \mathbb{Q}^{\mathcal{P}} \mid \mathbb{Q}^{\mathcal{P}_0} )
% $,
% where $\mathbb{Q}^{\mathcal{P}_0}$ is a prior guess of the distribution (see e.g., \citep{cont2004nonparametric} and \citep{cont2006retrieving} for details on the approach).
% The hyperparameter $\lambda$ controls the trade-off between the desired accuracy of the solution and the regularity of the problem. For instance, \cite{crepey2010tikhonov} reports common practices to choose such parameter, based on market data noise.
% As far as $\mathcal{P}_0$ is concerned, \cite{cont2004nonparametric} note that it can derive for example from a previous calibration, an historical estimation of the process, our views on the market, or an average between calibrations of different periods (representing a proxy of long-term values of parameters).












%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%
\section{Worst-Performance Derivatives}\label{Worst Performance Derivatives}

Before testing the calibration and pricing skills of the models, we describe the exotic products to be priced in the analysis, whose payoffs are also relevant to make suitable calibration choices.
We consider three multi-asset derivatives issued by Intesa Sanpaolo bank: \textit{Standard Long Barrier Plus Worst Of Certificates}; \textit{Standard Long Barrier Digital Worst Of Certificates}; \textit{Standard Long Autocallable Barrier Digital Worst Of Certificates with Memory Effect}.
From now on we call them \textit{WP1}, \textit{WP2}, \textit{WP3}, respectively, as their payoffs depend on the \textit{worst performance} (WP) among underlyings. 
Also, they can be seen as a strategy involving a long position in a coupon bond and a short one in a down-and-in put option. Payoff details are described in what follows, while a graphical representation of the payoff at maturity is depicted in Fig.\ \ref{fig:WP_payoff}. 


Let $\{t_0, ..., t_m\}$ be a set of relevant contract dates and $\mathbf{S} = (S_1, ..., S_n)$ be a vector of underlying assets, so that $\{\mathbf{S} (t)\}_{t \geq 0}$ represents the joint process of the assets. Let also the performance vector be defined as
$$
\mathbf{P} (t_i) = (P_1(t_i), ..., P_n(t_i)) = \Bigg( \frac{ S_1(t_i) }{ S_1(t_0) } - 1, ..., \frac{S_n(t_i)}{ S_n(t_0)} - 1 \Bigg)
,
\hspace{15pt}
i = 1, ..., m,
$$
along with the associated worst-performance assets
$$
w_i = \underset{j \in \{1, ..., n\} }{ \text{argmin}} \{P_j (t_i)\}
,
\hspace{15pt}
i = 1, ..., m
.
$$
Define also the barrier events as
\begin{equation*}
\begin{aligned}
%&   
E &= \{ S_{w_m}(t_m) < B \},
%&&&&
&&&
B &= b \, S_{w_m}(t_0)
&
\\
%&
E_{d,i} &= \{ S_{w_i}(t_i) < B_{d,i} \},
%&&&&
&&&
B_{d,i} &= b_{d,i} \: S_{w_i}(t_0),
&&
i = 1, ..., m
\\
%&
E_{r,i} &= \{ S_{w_i}(t_i) > B_{r,i} \},
%&&&&
&&&
B_{r,i} &= b_{r,i} \: S_{w_i}(t_0),
&&
i = 1, ..., m
\end{aligned}
\end{equation*}
where $b, b_{d,1}, ..., b_{d,m}, b_{r,1}, ..., b_{r,m}$ are predefined percentages.
Denoting by  $I$ the issue price and by $k$ the periodic coupon payment, we get WP1 and WP2 payoffs respectively as
\begin{equation*}
\begin{aligned}
&
\Pi_{\text{WP1}} = m k + \pi_m
\\
&
\Pi_{\text{WP2}} = k \sum_{i = 1}^m \mathbbm{1}_{E_{d,i}^c} + \pi_m
\end{aligned}
\end{equation*}
where
$$
\pi_m =
I \: \mathbbm{1}_{E^c}
+
\frac{S_{w_m} (t_m) }{ S_{w_m} (t_0)} I \: \mathbbm{1}_E
,
$$
and the superscript $c$ denotes the complement event.
Note that the payoff presented here assumes we are pricing the derivative at the issuing date, while it is often the case we buy it at a future date, missing some intermediate earnings (e.g., coupons). 

WP3 keeps a similar structure as WP2, but it adds a \textit{memory effect} and \textit{redemption} features.
The first means that at each date $i$, provided that performance is above the barrier $B_i^d$, the investor gains the current coupon plus the previous coupons that have not been paid.
The second implies that at the first date on which the event $E_{r,i}$ is verified, if it does happen, the investor receives the issue price and the contract expires. For sake of completeness, we report the algorithm needed to compute the discounted WP3  payoff for a single Monte Carlo trajectory in Appendix \ref{app:WP3 algorithm}.

\begin{figure}
    \centering
%    \includegraphics[width=10cm]{WP_payoff.png}
    \includegraphics[width=8cm]{./plots/WP_payoff.png}
    \caption{Payoff structure at settlement date of the three WP products, excluding the last coupon and a possible early redemption.
    It can be seen as a strategy involving a long position in a bond and a short one in a down-and-in put option.
    $I$ = issue price. $b$ = percentage level to determine the barrier.}
    \label{fig:WP_payoff}
\end{figure}














%%%%%%%%
\section{Empirical Analysis}\label{Empirical Analysis}

At this point, we have all the elements to perform an empirical test of the analyzed L\'evy models, with the aim of evaluating the ability of such models to fit market data and produce a fair valuation of the exotic derivatives.

%We outline the organization of this section as follows. First of all, we introduce the dataset employed in the analysis.
%Afterwards, In Subsection \ref{Calibration Choices}
%we report some preliminary considerations and decisions needed to design a suitable calibration setting for the models.
%In Subsection \ref{Calibration}, after fitting constrained models to market data, we illustrate the statistics of the resulting marginal parameters of VG and NIG univariate distributions, and we then discuss the calibration performance of the employed models.
%In Subsection \ref{Pricing}, having computed WP prices with the fitted models, we report and compare such prices between each other and against market benchmarks.
%Furthermore, we run a sensitivity analysis to linear and nonlinear dependence and examine, in Subsection \ref{Sensitivities}, the effect of such features on prices.
%Finally, in Subsection \ref{Constrained vs Unconstrained Margins} we show calibration and pricing performances of unconstrained models, comparing results with those of constrained models and making due remarks about the strengths and weaknesses of preserving constraints.


%%%%%%%%
%\subsection{Dataset}\label{Dataset}
%As previously said, we start this section by describing our dataset. 
We start this section by describing our dataset. 
Regarding calibration data, as it is generally the case, quotes of liquid multivariate instruments are not available. As a consequence, calibration data includes two distinct parts.
The first consists of liquid implied volatility surfaces of single-asset options, needed to fit marginal laws. 
The second involves an estimate of market correlation between log-returns of the assets. For each pair of assets, only a single market implied correlation is available, that is assumed to be constant over maturities and moneyness. Also, such correlation is implied by an ideal price estimated by traders, rather than the market price of a liquidly traded product.
We consider such calibration data for 13 monthly-distanced calibration dates (from 30/11/2021 to 30/11/2022), in order to assess model performance under various market conditions.

Concerning pricing data, the actively-traded WP derivatives that we price with L\'evy models have the following characteristics, besides the payoff features described in Section \ref{Worst Performance Derivatives}:
\begin{itemize}
    \item  WP1 is written on EURO STOXX 50 and FTSE MIB indexes, it has been issued in 28/03/2019 and expires in 28/03/2023.
    \item WP2 is written on EURO STOXX 50 and FTSE MIB indexes, it has been issued in 30/03/2020 and expires in 30/03/2026.
    \item WP3 is written on RWE AG, \'Electricit\'e de France SA and Iberdrola SA shares, it has been issued in 16/11/2021 and expires in 18/11/2024.
\end{itemize}
For these instruments, market bid prices are available at all dates where models are calibrated, even if the liquidity of WP products is relatively scarce.
As a consequence, it is possible to compare WP prices computed by the models with benchmarks provided by market data.


 






%%%%%%%
\subsection{Calibration Choices}\label{Calibration Choices}

As a starting point for our calibration analysis, we report some preliminary decisions on the adopted strategies to fit models.
Depending on the specific cases, such choices derive from theoretical considerations and/or a \textit{first run} of calibration and pricing, useful to get a flavour of the dataset.

%Concerning the optimization techniques employed in the calibration problem (see Subsection \ref{Optimization Techniques}), we decide to use a versatile stochastic search algorithm to fit model parameters, namely Differential Evolution (available in \textit{scipy} Python library), followed by a run with a local optimizer in order to refine the solution provided by the pure DE.
%In fact, as non-Gaussian L\'evy distributions are likely to display a highly non-convex objective function (see VG case in \cite{cont2004nonparametric}), using a multi-start algorithm risks to excessively depend on the grid choice.
%Moreover, employing surrogate optimization does not seem necessary, as objective function only consists, for marginals, of computing a few prices via Fast Fourier Transform algorithm and their implied volatilities. 
%Still, a surrogate-like method such as Artificial Neural Networks would have the benefit to shift computational burden \textit{offline}, but this would be more needed in a context of frequent recalibrations, while our study just involves a few time-distanced calibrations.
%For analogous reasons, we also decide not to employ regularization techniques, as these are generally desired in presence of frequent recalibrations.
%To be even surer that regularization is not strictly needed, we apply small data perturbations to a first run of calibration, finding out that results are stable enough to such perturbations.


Concerning the optimization techniques employed in the calibration problem, we decide to use a stochastic search algorithm to fit model parameters, as done for example by \cite{cont2004recovering}.
Specifically, we use a versatile Differential Evolution algorithm \citep{storn1997differential}, available in \textit{scipy} Python library.
We then refine the solution provided by the pure DE by employing a local optimizer.
Differently, other authors (e.g., \cite{cont2004nonparametric} and \cite{alfeus2020regularization}) employ multi-start methods for the calibration problems.
As these algorithms exploit the gradient of the objective function, they can often converge to solutions relatively quickly.
However, as non-Gaussian L\'evy distributions are likely to display a highly non-convex objective function (see VG case in \cite{cont2004nonparametric}), using a multi-start algorithm risks to excessively depend on the grid choice.
Another approach adopted by researchers is to fit models via surrogate-like optimization (see \citep{ruf2019neural} for a literature review of Artificial Neural Networks for pricing applications).
These techniques are normally used when objective function is computationally expensive.
However, in our case objective function only consists, for marginals, of computing a few prices via Fast Fourier Transform algorithm and their implied volatilities.
Still, ANNs have the benefit to shift computational burden \textit{offline}, but this can be more desired in a context of frequent recalibrations, while our study just involves a few time-distanced calibrations.
Similarly, we decide not to employ regularization techniques (see e.g., \citep{cont2006retrieving},
\citep{egger2005tikhonov}, \citep{crepey2010tikhonov}, \citep{dai2016calibration}), as these are more needed in presence of frequent recalibrations.
To be surer that regularization can be avoided, we apply small data perturbations to a first run of calibration, finding out that results are stable enough to such perturbations.




A second important decision regards the points of the volatility surfaces to use for model fitting.
As WP payoffs are largely linked to the underlying asset prices at settlement date, it can be convenient to assign larger weights (see Eq.\ \eqref{marginal calibration}) to calibration points close to WP settlement dates.
In fact, as L\'evy process have i.i.d.\ increments, we cannot expect them to perfectly fit whole volatility surfaces, as such surfaces reflect the well-known non-stationarity of realized log-returns. As a consequence, concentrating calibration effort on a lower number of volatility surface points seems reasonable.
After these preliminary considerations and looking at a first run of calibration and pricing, we actually notice that the best strategy is to just calibrate models on 2-3 volatility smiles close to WP settlement dates. Indeed, although intermediate contract payments risk to be poorly predicted by the so-calibrated processes, we evidence that the overall pricing performance of the models benefit from our strategy.


Another calibration choice lies in the context of dependence fit.
That is, we decide to use \textit{theoretical} correlation (see, for example, Eq.\ \eqref{rhoY-LS-VG} in the case of constrained LS-VG) as a proxy of \textit{model-implied} correlation (i.e., Black-Scholes implied correlation from model price).
In fact, as market correlation is implied from an estimated market price (see the introduction of Section \ref{Empirical Analysis}), the most natural calibration choice would be to employ model-implied correlation to fit dependence structure.
However, we notice that using either model-implied or theoretical correlations yields nearly the same exotic prices produced by the calibrated models.
Therefore, as the computational time required to calculate theoretical correlation is substantially lower than that of model-implied correlation, we use the former.
%especially necessary in joint calibrations

To conclude the set of preliminary choices, we report our decisions concerning the calibration methods employed to fit the specific L\'evy models, discussed in the introduction of Section \ref{Calibration Methods} and in Subsection \ref{Model-Specific Calibrations}.
Regarding constrained LS models, as two-step calibration is normally faster than joint calibration, we first employ the former, and only when trade-off between marginal and dependence fit is strong, we perform a joint calibration to distribute calibration errors proportionally (similarly to \citep{marena2018pricing}).
For constrained BB models, as their correlation coefficients do not make the trade-off clear from a theoretical perspective, we first set a tiny maximum correlation error allowed (see Eq.\ \eqref{BB dependence-calibration} and the discussion below), and when this strategy leads to excessively large convolution errors, we let correlation error increase.
Finally, as the theoretical structure of unconstrained models requires joint calibrations as in Eq.\ \eqref{joint calibration}, for this models we always follow the joint procedure, initially imposing a low bound on correlation error and increasing it if necessary.










%%%%%%%
\subsection{Calibration Results}\label{Calibration}

Having introduced the calibration setting, we are now ready to report results.
In order to show the variety of market conditions encountered in the analysis and to provide useful benchmarks to future researchers, we illustrate some statistics of the calibrated marginal parameters of constrained models in Table \ref{tab:Marginal Parameters}.
Such parameters belong to well-known univariate laws such as Variance Gamma and Normal Inverse Gaussian, which are embedded by both LS and BB constrained models, as such models preserve margins of known classes by construction.
Note though that BB processes are subject to convolution errors in the second stage of the two-step calibration, so parameters of Table \ref{tab:Marginal Parameters} only approximately represent BB marginal distributions.


Going into detail, Table \ref{tab:Marginal Parameters} reports the minimum, mean and maximum values of marginal parameters over the 13 calibration dates of the analysis.
A relevant point comes from observing that minima (or maxima) are sometimes similar across underlying assets.
This happens because we arbitrarily restrict parameters to take values in reasonably narrow ranges.
According to the aforementioned first run of calibration, we notice that such an approach is useful for at least a couple of reasons.
First, and not surprisingly, it increases the stability and convergence speed of the calibration algorithm.
Secondly, it often reduces the overall calibration error, as correlation and convolution fit are likely to suffer from too small, or too large, values of marginal parameters.
Although tightening parameter bounds might seem a strong limitation to marginal fit, the non-identifiability of parameters, typical of non-Gaussian L\'evy distributions, is likely to help models to still find combinations of parameters that well-reflect market data.


%%%%
\begin{table}[]
\scriptsize
\centering
\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{3}{|c|}{$\mu$} & \multicolumn{3}{|c|}{$\sigma$} & \multicolumn{3}{|c|}{$\kappa$}
\\
\hline
Underlying & min & mean & max & min & mean & max & min & mean & max
\\
\hline
EURO STOXX 50 &
-0.3062 & -0.1922 & -0.1223 & 0.1665 & 0.203 & 0.2196 & 0.7068 & 1.7768 & 2.997
\\
FTSE MIB (a) &
-0.3326 & -0.2206 & -0.1318 & 0.1669 & 0.2238 & 0.2586 & 0.4452 & 1.562 & 2.9988
\\
EURO STOXX S.D. 30 &
-0.1559 & -0.1484 & -0.1364 & 0.0061 & 0.0628 & 0.1602 & 2.9917 & 2.9986 & 2.9998
\\
FTSE MIB (b) &
-0.1902 & -0.1706 & -0.1504 & 0.0059 & 0.0525 & 0.1866 & 2.997 & 2.9991 & 3.0
\\
\'ELEC.\ DE FRANCE SA &
-1.0136 & -0.2551 & -0.1782 & 0.1204 & 0.2984 & 0.3545 & 0.0865 & 0.6599 & 1.7835
\\
IBERDROLA SA &
-0.1929 & -0.1538 & -0.1299 & 0.1898 & 0.2184 & 0.2457 & 0.8713 & 1.5145 & 2.592
\\
RWE AG &
-0.8346 & -0.1337 & -0.0798 & 0.0055 & 0.3155 & 0.3865 & 0.1194 & 1.874 & 2.9927
\\
\hline
\hline
& \multicolumn{3}{|c|}{$\beta$} & \multicolumn{3}{|c|}{$\delta$} & \multicolumn{3}{|c|}{$\gamma$}
\\
\hline
Underlying & min & mean & max & min & mean & max & min & mean & max
\\
\hline
EURO STOXX 50 &
-4.9999 & -4.7559 & -3.7211 & 0.1 & 0.1594 & 0.2359 & 4.7087 & 6.1767 & 6.6663
\\
FTSE MIB (a) &
-4.9998 & -4.346 & -2.3517 & 0.1013 & 0.1934 & 0.322 & 3.0398 & 5.8379 & 6.6664
\\
EURO STOXX S.D. 30 &
-4.6967 & -4.1135 & -3.6941 & 0.1 & 0.1 & 0.1001 & 4.7693 & 5.2626 & 5.7746
\\
FTSE MIB (b) &
-3.1203 & -2.7794 & -2.1365 & 0.1 & 0.102 & 0.1095 & 2.9566 & 3.6037 & 3.9245
\\
\'ELEC.\ DE FRANCE SA &
-3.335 & -2.2754 & -1.4409 & 0.2406 & 0.3686 & 0.4997 & 2.9628 & 4.4852 & 5.9827
\\
IBERDROLA SA &
-4.9961 & -3.5964 & -2.2539 & 0.1282 & 0.1759 & 0.2221 & 3.4076 & 5.3033 & 6.6655
\\
RWE AG &
-2.7009 & -1.0942 & -0.7129 & 0.1616 & 0.2203 & 0.2812 & 1.6059 & 2.5039 & 3.7091
\\
\hline
\end{tabular}
\caption{VG and NIG marginal parameters of underlying assets. We report their minimum, average and maximum over the 13 calibration dates.}
\label{tab:Marginal Parameters}
\end{table}



After displaying the statistics of marginal parameters, we can now present the calibration errors of constrained LS and BB models, in order to evaluate their fitting performances and explore a possible trade-off between marginal and dependence structure.
We display the average root mean square error (RMSE) between model and market implied volatilities of WP underlying assets in the left-hand side of Figs.\ \ref{fig:VG calibration errors} and \ref{fig:NIG calibration errors}, and between model and market correlation, in the right-hand side.
In our first calibration and pricing run, we notice that the effect of correlation error on the exotic price is of the order of magnitude of about one tenth of volatility error.
As a consequence, we keep this ratio of scales between marginal and dependence plots of Figs.\ \ref{fig:VG calibration errors} and \ref{fig:NIG calibration errors}, so that the reader can assign nearly the same importance to all error bars.


According to Figs.\ \ref{VG marginal calibration errors WP1}, \ref{VG marginal calibration errors WP2} and \ref{VG marginal calibration errors WP3}, marginal calibration of multivariate VG models normally yields lower errors for LS-VG than for BB-VG.
This is expected, as BB adds convolution errors to the marginal calibration errors outputted by the first part of the two-step calibration (note, however, that in some cases convolution error could accidentally improve marginal fit).
However, we notice in Figs.\ \ref{VG dependence calibration errors WP1} and \ref{VG dependence calibration errors WP3} that the better marginal calibration of LS-VG comes at the expense of correlation fit, that become significant in a few cases, remarking the presence of fitting trade-off.
On the other hand, the exceptionally good dependence calibration of BB-VG, coming from setting a small $\epsilon=0.01$ in the optimization problem of Eq.\ \eqref{BB dependence-calibration}, seems to offset the excess marginal error in most cases.
To summarize, while the results on WP1- and WP2-linked calibrations are somewhat ambiguous, BB-VG performs better than LS-VG in WP3 case.


Concerning calibration results of multivariate NIG models, some considerations can be made by observing Fig.\ \ref{fig:NIG calibration errors}.
Similarly to VG case, we detect a poorer marginal fit of BB-NIG with respect to LS-NIG. This is particularly evident in the WP3-linked marginal calibration errors of Fig.\ \ref{NIG marginal calibration errors WP3}, where we still use a calibration method that imposes a maximum correlation error allowed of 0.01.
In WP1- and WP2-linked calibrations, in order to avoid huge marginal errors, we are forced to relax the constraint on correlation fit.
The effect of such decision is clear from Figs.\ \ref{NIG dependence calibration errors WP1} and \ref{NIG dependence calibration errors WP2}, where BB dependence calibration errors get considerably larger than the other cases.
To sum up, we observe an overall better fit of LS-NIG model with respect to BB-NIG. Also, while LS-VG and LS-NIG enjoy relatively similar results among each other, we evidence a significant difference between BB-VG and BB-NIG fitting performances.
Such outcome is likely to be due to the sensitivity of BB model construction to the marginal law assigned to the process.
In fact, as can be seen from Eqs.\ \eqref{VG-conv-restrictions-1}, \eqref{VG-conv-restrictions-2}, \eqref{NIG-conv-restrictions-1} and \eqref{NIG-conv-restrictions-2}, the convolution conditions needed to preserve marginal laws can be quite different between VG and NIG cases, so is the ability of BB models to satisfy such conditions.

An important and more general consideration is that a trade-off between marginal and dependence fit exists in practice and can even be strong in some cases.
As trade-off is, at least in part, produced by the convolution conditions of constrained LS and BB models (recall, for example, the bounds on correlation parameter $a$ in Eqs.\ \eqref{Gamma-Sub} and \eqref{IG-Sub}), we then decide to test unconstrained versions of LS and BB models in Subsection \ref{Constrained vs Unconstrained Margins}, to find out whether they can significantly improve calibration fit.


%%%%
\begin{figure}%[tbp]%[ph]
\centering
\subfloat[Marginal calibration errors of WP1 underlyings.
\label{VG marginal calibration errors WP1}
]{\includegraphics[scale=0.5]{./plots/ErrMrg_XS1945967153_VG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP1 underlyings.
\label{VG dependence calibration errors WP1}
]{\includegraphics[scale=0.5]{./plots/ErrDep_XS1945967153_VG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP2 underlyings.
\label{VG marginal calibration errors WP2}
]{\includegraphics[scale=0.5]{./plots/ErrMrg_XS2115185295_VG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP2 underlyings.
\label{VG dependence calibration errors WP2}
]{\includegraphics[scale=0.5]{./plots/ErrDep_XS2115185295_VG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP3 underlyings.
\label{VG marginal calibration errors WP3}
]{\includegraphics[scale=0.5]{./plots/ErrMrg_XS2402145127_VG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP3 underlyings.
\label{VG dependence calibration errors WP3}
]{\includegraphics[scale=0.5]{./plots/ErrDep_XS2402145127_VG_Rho-inf.png}}
\caption{Constrained LS-VG and BB-VG calibration errors for the 13 considered times to maturity. Left-hand side figures represent average RMSEs between model and market volatilities of the basket of underlyings of each WP. Right-hand side figures represent average RMSEs between model and market correlations of the set of underlying pairs of each WP.}
\label{fig:VG calibration errors}
\end{figure}

%%%%
\begin{figure}%[tbp]%[ph]
\centering
\subfloat[Marginal calibration errors of WP1 underlyings.
\label{NIG marginal calibration errors WP1}
]{\includegraphics[scale=0.5]{./plots/ErrMrg_XS1945967153_NIG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP1 underlyings.
\label{NIG dependence calibration errors WP1}
]{\includegraphics[scale=0.5]{./plots/ErrDep_XS1945967153_NIG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP2 underlyings.
\label{NIG marginal calibration errors WP2}
]{\includegraphics[scale=0.5]{./plots/ErrMrg_XS2115185295_NIG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP2 underlyings.
\label{NIG dependence calibration errors WP2}
]{\includegraphics[scale=0.5]{./plots/ErrDep_XS2115185295_NIG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP3 underlyings.
\label{NIG marginal calibration errors WP3}
]{\includegraphics[scale=0.5]{./plots/ErrMrg_XS2402145127_NIG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP3 underlyings.
\label{NIG dependence calibration errors WP3}
]{\includegraphics[scale=0.5]{./plots/ErrDep_XS2402145127_NIG_Rho-inf.png}}
\caption{Constrained LS-NIG and BB-NIG calibration errors for the 13 considered times to maturity. Left-hand side figures represent average RMSEs between model and market volatilities of the basket of underlyings of each WP. Right-hand side figures represent average RMSEs between model and market correlations of the set of underlying pairs of each WP.}
\label{fig:NIG calibration errors}
\end{figure}








%%%%%
%\clearpage
\subsection{Pricing}\label{Pricing}

%%%Ask prices are not available except for a few cases of WP3, where bid-ask spread is often around 1\% but can also reach more than 10\%, pointing out a relatively scarce liquidity of these instruments.

Having calibrated the constrained models, we are now ready to price WP instruments, in order to investigate the ability of the models to produce a fair valuation of such derivatives.
Because of the exotic features of WP contracts, valuations are carried out via Monte Carlo methods, simulating enough sample paths to get suitably small MC errors.
As previously said, for sake of completeness we report the MC algorithm needed to price WP3 in Appendix \ref{app:WP3 algorithm}.
As market bid quotes of WP products are available, we display them together with model prices in the left-hand side of Fig.\ \ref{fig:prices}.
The right-hand side shows instead the percentage differences between model and market prices.


As a first level of comparison, we look at the differences between L\'evy prices.
It is clear from the plots that models enjoy comparable results among each other.
Also, percentage differences of the four models seem to follow a similar path over valuation dates, evidencing a homogeneity between model results.
However, an observation concerns WP2 pricing (see Figs.\ \ref{fig:prices 2} and \ref{fig:percentage differences 2}), where LS-VG replicates benchmarks particularly well, while BB-NIG produce the worst results among models.
Such evidence is, in fact, consistent with the results shown in the calibration plots (Figs.\ \ref{fig:VG calibration errors} and \ref{fig:NIG calibration errors}) and the related discussion, remarking the link between calibration and pricing.
Overall, although LS and BB models have different theoretical constructions, they preserve a similar ability to price exotics.


On the other hand, clearer evidences can be captured by comparing L\'evy models as a whole against market quotes.
Apart from short-maturity cases, we observe a tendency of the models to underestimate bid prices.
This is partly due to the calibrated model correlation not reaching the market level, that leads to a higher value of the embedded put option of the contract (recall WP payoff structure from Fig.\ \ref{fig:WP_payoff}), and so a lower overall price.
Whenever correlation enjoys a good fit, the overestimate of the put does not completely disappear.
This is possibly due to L\'evy distributions bearing fatter tails than those assumed by valuation models that concur in forging benchmark quotes.


Looking in detail at the specific contracts, models enjoy the best results when pricing WP1 (see Figs.\ \ref{fig:prices 1} and \ref{fig:percentage differences 1}), where market bid quotes are replicated quite accurately, even with a slight and desirable high bias. 
Such good performance is consistent with the well-known ability of jump processes to price short-term options, even far from at-the-money positions.
Concerning the other contracts, WP2 is priced at longer times to maturity (see Figs.\ \ref{fig:prices 2} and \ref{fig:percentage differences 2}), making the correlation mismatch more effective.
As a result, percentage (absolute) differences increase. 
Also, differently from WP1, WP2 payoff contains some path-dependency (see Section \ref{Worst Performance Derivatives}), which is another source of inaccuracy if we price via stationary processes such as L\'evy ones (as observed, for example, by \cite{ballotta2016multivariate}).
Regarding WP3 (Figs.\ \ref{fig:prices 3} and \ref{fig:percentage differences 3}), model and market prices diverge more for all models, for at least two reasons.
First, the exotic features of the contract increase substantially (as can be observed from the pricing algorithm in Appendix \ref{alg:WP3-payoff}).
Second, WP3 underlyings are stocks, with more irregular and less liquid volatility surfaces with respect to the underlying indexes of WP1 and WP3.
As a consequence, the link between calibration data and exotic quotes is more prone to mismatches.

Overall, except some pricing inaccuracy coming from the path-dependent features of the exotics, a significant source of error is likely to be calibration fit.
Especially if we look at the connection between LS-VG good pricing performance of WP2 product (Fig.\ \ref{fig:percentage differences 2}) and its relatively accurate fit (comparing all WP2-related calibrations in Figs.\ \ref{VG marginal calibration errors WP2}, \ref{VG dependence calibration errors WP2}, \ref{NIG marginal calibration errors WP2} and \ref{NIG dependence calibration errors WP2}), it seems logic to try to improve model fitting to produce more accurate valuations. This again points to test unconstrained models in Subsection \ref{Constrained vs Unconstrained Margins}, and check whether these models can better replicate market quotes.

%%%On a general level, as L\'evy processes assume identically distributed increments, it is common to observe a reduced calibration fit when we try to fit models to volatility smiles over multiple maturities together. This is due to the well-known non-stationarity of stock log-returns and is especially evidenced if some of these smiles have medium-long term maturities, as observed by \cite{ballotta2016multivariate}.


%%%%
\begin{figure}%[tbp]%[ph]
\centering
\subfloat[WP1 prices.
\label{fig:prices 1}
]{\includegraphics[scale=0.5]{./plots/Prices_XS1945967153_Rho-inf.png}}
\hfill
\subfloat[WP1 percentage differences.
\label{fig:percentage differences 1}
]{\includegraphics[scale=0.5]{./plots/PercDiff_XS1945967153_Rho-inf.png}}
\newline
\subfloat[WP2 prices.
\label{fig:prices 2}
]{\includegraphics[scale=0.5]{./plots/Prices_XS2115185295_Rho-inf.png}}
\hfill
\subfloat[WP2 percentage differences.
\label{fig:percentage differences 2}
]{\includegraphics[scale=0.5]{./plots/PercDiff_XS2115185295_Rho-inf.png}}
\newline
\subfloat[WP3 prices.
\label{fig:prices 3}
]{\includegraphics[scale=0.5]{./plots/Prices_XS2402145127_Rho-inf.png}}
\hfill
\subfloat[WP3 percentage differences.
\label{fig:percentage differences 3}
]{\includegraphics[scale=0.5]{./plots/PercDiff_XS2402145127_Rho-inf.png}}
\caption{Prices and percentage differences between model and market prices, on the 13 considered times to maturity. Prices are expressed as percentage of the issue price. Percentage differences are computed as (Price $-$ Market Price) / Market Price $\times$ 100.}
\label{fig:prices}
\end{figure}






%%%%%
%\clearpage
\subsection{Sensitivities}\label{Sensitivities}

In order to have a better understanding of WP payoffs and to get the importance of making an accurate dependence calibration, we run a sensitivity-to-correlation analysis, by observing correlation effect on price in Fig.\ \ref{fig:correlation-effect}. 
As exotic products have comparable payoffs, we restrict the analysis to WP1 instrument.
Also, we just consider constrained LS-VG model, since models enjoy mutually similar sensitivities.
Furthermore, we fix marginal parameters to $\mu_j=-0.15,\: \sigma_j=0.25,\: \kappa_j=1.60,\: j=1,2$, representing a commonly-observed market situation according to Table \ref{tab:Marginal Parameters}.
Looking at Figs.\ \ref{fig:correlation-effect 1}, \ref{fig:correlation-effect 2}, \ref{fig:correlation-effect 3}, as expected from the payoffs of WP products, the price sensitivity to correlation increases for higher maturities and when moneyness gets closer to one. 
Moreover, in all instances sensitivity rises for very high correlation levels (commonly observed in the index market), evidencing a nonlinear effect on price and the importance of using models and calibration methods able to capture wide dependence ranges.
On a general level, it is clear from the plots that correlation has a large effect on WP1 price, remarking the need to distribute calibration errors in a proportionate way between marginal and correlation parameters.


%%%%
\begin{figure}[hbt!]%[H]%[tbp]%[ph]
\centering
\subfloat[Correlation effect on WP1 price for time to maturity 1.0 and moneyness 2.0, 1.6, 1.2.
\label{fig:correlation-effect 1}
]{\includegraphics[scale=0.5]{./plots/corr_T10.png}}
\hfill
\subfloat[Correlation effect on WP1 price for time to maturity 2.5 and moneyness 2.0, 1.6, 1.2.
\label{fig:correlation-effect 2}
]{\includegraphics[scale=0.5]{./plots/corr_T25.png}}
\newline
\subfloat[Correlation effect on WP1 price for time to maturity 4.0 and moneyness 2.0, 1.6, 1.2.
\label{fig:correlation-effect 3}
]{\includegraphics[scale=0.5]{./plots/corr_T40.png}}
\hfill
\subfloat[Correlation effect on WP1 price for time to maturity 4.0 and moneyness 2.0.
\label{fig:correlation-effect 4}
]{\includegraphics[scale=0.5]{./plots/corr_T40_MN20.png}}
\caption{
Correlation effect on WP1 price, using constrained LS-VG model and fixed marginal distributions $\mu_j=-0.15, \sigma_j=0.25, \kappa_j=1.60, \: j=1,...,n$. In Figs.\ (a)-(c),
%each colored set of points displays percentage differences between prices and the average price between all prices with the same moneyness,
%(of the same set),
each point represents the percentage difference between a price - with a certain combination of correlation and moneyness - and the average price between those with the same moneyness,
as a function of $\rho_{\boldsymbol{Y}}$. Fig.\ (d) shows prices as a function of $\rho_{\boldsymbol{Y}}$ in the realistic case where T=4.0 and MN=2.0, that is where WP1 is valued close to issue date. T = time to maturity. MN = moneyness (initial underlying price divided by strike).
}
\label{fig:correlation-effect}
\end{figure}


To explore the effect of nonlinear dependence on the valuation of exotics, we examine the price sensitivity to such feature in Fig.\ \ref{fig:nonlinear-dependence-effect},
recalling that it can only be observed in LS models. %(see Subsection \ref{LS-VG}).
Again, we just consider %We use the same setting of the sensitivity-to-correlation analysis, that is by just considering
WP1 product, constrained LS-VG model and fixed marginal laws with $\mu_j=-0.15,\: \sigma_j=0.25,\: \kappa_j=1.60, \: j=1,2$.
We observe the effect of nonlinear dependence by computing WP1 price for multiple values of parameter $a$
(see e.g., %(recall such parameter from, for example, the characteristic function in
Eq.\ \eqref{LS-VG-CF}).
$a$ is the only parameter that affects nonlinear dependence in constrained LS models, but it also drives part of the correlation.
As a consequence, in order to isolate the effect of nonlinear dependence, we move $a$ while keeping $\rho_{\boldsymbol{Y}}$ (from Eq.\ \eqref{rhoY-LS-VG}) constant, by changing accordingly the other correlation drivers $\rho_{ij}, \forall i \neq j$.
The calculation is repeated for different correlation values, and for different levels of moneyness, as shown in Figs.\ \ref{fig:nonlinear-dependence-effect 1}, \ref{fig:nonlinear-dependence-effect 2}, \ref{fig:nonlinear-dependence-effect 3}.
%
%
We observe that when underlying asset prices are far from the barrier (Fig.\ \ref{fig:nonlinear-dependence-effect 1}),
%for underlying prices far from the barrier,
there is a negative relationship between $a$ and prices when $\rho_{\boldsymbol{Y}}$ is very high, while relationship flattens and even become positive as we progress towards lower correlations.
As moneyness decreases (Fig.\ \ref{fig:nonlinear-dependence-effect 3}), we observe a clearer negative dependence for each level of $\rho_{\boldsymbol{Y}}$.
As a first point, we then establish that there exists some link between nonlinear dependence and WP1 price.
However, as $\rho_{\boldsymbol{Y}}$ increases, we note that the domain of $a$ shrinks, because we cannot set high correlations without a high $a$.
This eliminates the possibility to observe the whole relationship between nonlinear dependence and price.
In general, as expected, the order of magnitude of the effect of nonlinear dependence on price is much lower with respect to that of correlation, as can be seen comparing Figs.\ \ref{fig:correlation-effect 4} and \ref{fig:nonlinear-dependence-effect 4}.
On the one hand, the visible link between nonlinear dependence and price rewards LS models for their ability to capture such feature. Also, the small admissible range of parameter $a$ encourages to try to construct models that can accommodate larger nonlinear dependence ranges.


%%%%
\begin{figure}[hbt!]%[tbp]%[ph]
\centering
\subfloat[Nonlinear dep.\ effect on WP1 price for moneyness 1.6, correlation 0.6, 0.7, 0.8, 0.9.
\label{fig:nonlinear-dependence-effect 1}
]{\includegraphics[scale=0.5]{./plots/nonlin_MN16.png}}
\hfill
\subfloat[Nonlinear dep.\ effect on WP1 price for moneyness 1.4, correlation 0.6, 0.7, 0.8, 0.9.
\label{fig:nonlinear-dependence-effect 2}
]{\includegraphics[scale=0.5]{./plots/nonlin_MN14.png}}
\newline
\subfloat[Nonlinear dep.\ effect on WP1 price for moneyness 1.2, correlation 0.6, 0.7, 0.8, 0.9.
\label{fig:nonlinear-dependence-effect 3}
]{\includegraphics[scale=0.5]{./plots/nonlin_MN12.png}}
\hfill
\subfloat[Nonlinear dep.\ effect on WP1 price for moneyness 1.2, correlation 0.9.
\label{fig:nonlinear-dependence-effect 4}
]{\includegraphics[scale=0.5]{./plots/nonlin_MN12_rho09.png}}
\hspace{0.6cm}
\caption{
Nonlinear dependence effect on WP1 price, using constrained LS-VG model and fixed marginal distributions $\mu_j=-0.15, \sigma_j=0.25, \kappa_j=1.60, \: j=1,...,n$.
In Figs.\ (a)-(c),
%each colored set of points displays percentage differences between prices and the average price (of the same set),
each point represents the percentage difference between a price - with a certain combination of correlation and moneyness - and the average price between those with the same moneyness,
as a function of $a$. In Fig.\ (d) we plot prices as a function of $a$ for one of the considered instances, where price is relatively sensitive to nonlinear dependence. T = time to maturity. MN = moneyness (initial underlying price divided by strike).
}
\label{fig:nonlinear-dependence-effect}
\end{figure}







%%%%%
%\clearpage
\subsection{Constrained vs Unconstrained Margins}\label{Constrained vs Unconstrained Margins}

Having shown results for constrained LS and BB models, it is now time to calibrate unconstrained L\'evy models and produce the respective prices of the exotic products.
This test has the aim of investigating the ability of unconstrained models to reduce the fitting trade-off between marginal and dependence structures.
%Also, once the results are presented, we point out the strengths and weaknesses of preserving marginal laws and derive due considerations on which models are best to use in practice.
As anticipated, the calibration of unconstrained models requires a joint procedure as described in Eq.\ \eqref{joint calibration}, because of the increased interconnection between marginal and dependence parameters.
Also, according to our first run of calibration, we choose to mostly set $\epsilon=0.1$, and when marginal fit results too poor, we use $\epsilon=0.2$.
Note that joint calibration can hardly set lower maximum correlation errors allowed, such as the $\epsilon=0.01$ of the dependence calibration of constrained BB models (Eq.\ \eqref{BB dependence-calibration}), because it is a high-dimensional problem with computationally expensive objective functions.


In order to provide a visible comparison between constrained and unconstrained models, each calibration plot displays fitting errors of a constrained L\'evy model and its unconstrained version, as shown in Figs.\ \ref{fig:VGuLS calibration errors}, \ref{fig:VGuBB calibration errors}, \ref{fig:NIGuLS calibration errors} and \ref{fig:NIGuBB calibration errors}. 
As can be seen, in most cases the two approaches produce comparable performances, which is also evidenced by the pricing results of Fig.\ \ref{fig:prices constrained vs unconstrained}.
However, a notable exception is given by BB-NIG, whose calibration plots (Fig.\ \ref{fig:NIGuBB calibration errors}) show a better fit of its unconstrained version.
%To summarize,
In essence, the goal of unconstrained models to reduce the marginal vs dependence trade-off on LS models does not appear to be reached.
However, the results of BB models seem to reward the unconstrained structure, at least from the point of view of pure model fitting.
As a matter of fact, not only the authors of BB processes started preferring the unconstrained versions of their model in recent works (as \citep{ballotta2017multivariate} and \citep{ballotta2019estimation}), but the convenience of choosing such construction also has theoretical explanations.
In fact, constrained BB embeds exigent restrictions (see Eqs.\ \eqref{VG-conv-restrictions-1} and \eqref{NIG-conv-restrictions-1}) to preserve known marginal laws, as opposed to the simpler bounds on parameter $a$ for LS models (see Eqs.\ \eqref{Gamma-Sub} and \eqref{IG-Sub}).
%
Overall, removing constraints in BB models looks a more valid choice than it is for LS models.



%Having shown the calibration and pricing outputs, we are still left with the question of whether the unconstrained approach present some advantages from a global point of view.
%Said it differently, is it worth to remove convolution restrictions in order to remove some fitting trade-off? Also, independently of trade-off, do unconstrained models provide some operational advantages?
%To answer these questions, we list some strengths and weaknesses of removing marginal constraints.
%The first advantage is that taking out constraints allows parameters to adopt wider ranges of values, increasing the flexibility of the model parametrization.
%Secondly, joint calibrations are relatively faster than those of the constrained models, because the optimization problems reach convergence to a suitable solution vector more easily.
%Furthermore, the need to make joint calibrations removes the decision burden on which fitting procedure to apply, so that calibration becomes more homogeneous.


%Concerning the drawbacks of using unconstrained models, the first one is that we cannot fit such processes in two stages, separating marginal and dependence parameters. In fact, two-step calibration is generally faster than the joint method, because the multiple optimization problems used to fit marginals require to find solution vectors of only three parameters (both in VG and NIG cases); in contrast, joint calibration has a much large number of variables, even assuming a small number of underlying assets.
%Secondly, marginal calibrations can be reused for multiple dependence calibrations. This can save much computational effort if we are interested to price a variety of multi-asset products with similar underlying baskets.
%Last but not least, the increased interconnection between marginal and dependence parameters decreases the interpretability of parameters, that is instead quite strong for the well-known univariate VG and NIG processes.


%Overall, this empirical test shows that unconstrained models provide reasonable alternatives to the constrained LS and BB processes.
%However, the high interpretability of parameters and the option to carry out two-stage calibrations seem strong arguments in favour of constrained models, making them reliable choices.
%It is though important to notice that the exigent constraints of BB models can be problematic, especially in high dimensions.
%Even if here we only study low-dimensional cases, a flavour of such problem is given by the calibration results of the two BB-NIG versions (Fig.\ \ref{fig:NIGuBB calibration errors}), where removing constraints appears to reduce the trade-off between marginal and dependence fit.
%In contrast, the constrained LS models scale better than the constrained BB models in high dimensions, in terms of marginal constraints.
%Therefore, removing constraints in BB models looks a more valid choice than it is for LS models.



%%%%
\begin{figure}%[tbp]%[ph]
\centering
\subfloat[Marginal calibration errors of WP1 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrMrg_uLS_XS1945967153_VG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP1 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrDep_uLS_XS1945967153_VG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP2 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrMrg_uLS_XS2115185295_VG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP2 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrDep_uLS_XS2115185295_VG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP3 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrMrg_uLS_XS2402145127_VG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP3 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrDep_uLS_XS2402145127_VG_Rho-inf.png}}
\caption{LS-VG (constrained) and LS-VGu (unconstrained) calibration errors for the 13 considered times to maturity. Left-hand side figures represent average RMSEs between model and market volatilities of the basket of underlyings of each WP. Right-hand side figures represent average RMSEs between model and market correlations of the set of underlying pairs of each WP.}
\label{fig:VGuLS calibration errors}
\end{figure}

%%%%
\begin{figure}%[tbp]%[ph]
\centering
\subfloat[Marginal calibration errors of WP1 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrMrg_uBB_XS1945967153_VG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP1 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrDep_uBB_XS1945967153_VG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP2 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrMrg_uBB_XS2115185295_VG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP2 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrDep_uBB_XS2115185295_VG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP3 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrMrg_uBB_XS2402145127_VG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP3 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrDep_uBB_XS2402145127_VG_Rho-inf.png}}
\caption{BB-VG (constrained) and BB-VGu (unconstrained) calibration errors for the 13 considered times to maturity. Left-hand side figures represent average RMSEs between model and market volatilities of the basket of underlyings of each WP. Right-hand side figures represent average RMSEs between model and market correlations of the set of underlying pairs of each WP.}
\label{fig:VGuBB calibration errors}
\end{figure}

%%%%
\begin{figure}%[tbp]%[ph]
\centering
\subfloat[Marginal calibration errors of WP1 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrMrg_uLS_XS1945967153_NIG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP1 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrDep_uLS_XS1945967153_NIG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP2 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrMrg_uLS_XS2115185295_NIG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP2 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrDep_uLS_XS2115185295_NIG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP3 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrMrg_uLS_XS2402145127_NIG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP3 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrDep_uLS_XS2402145127_NIG_Rho-inf.png}}
\caption{LS-NIG (constrained) and LS-NIGu (unconstrained) calibration errors for the 13 considered times to maturity. Left-hand side figures represent average RMSEs between model and market volatilities of the basket of underlyings of each WP. Right-hand side figures represent average RMSEs between model and market correlations of the set of underlying pairs of each WP.}
\label{fig:NIGuLS calibration errors}
\end{figure}

%%%%
\begin{figure}%[tbp]%[ph]
\centering
\subfloat[Marginal calibration errors of WP1 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrMrg_uBB_XS1945967153_NIG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP1 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrDep_uBB_XS1945967153_NIG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP2 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrMrg_uBB_XS2115185295_NIG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP2 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrDep_uBB_XS2115185295_NIG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP3 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrMrg_uBB_XS2402145127_NIG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP3 underlyings.
]{\includegraphics[scale=0.5]{./plots/ErrDep_uBB_XS2402145127_NIG_Rho-inf.png}}
\caption{BB-NIG (constrained) and BB-NIGu (unconstrained) calibration errors for the 13 considered times to maturity. Left-hand side figures represent average RMSEs between model and market volatilities of the basket of underlyings of each WP. Right-hand side figures represent average RMSEs between model and market correlations of the set of underlying pairs of each WP.}
\label{fig:NIGuBB calibration errors}
\end{figure}

%%%%
\begin{figure}%[tbp]%[ph]
\centering
\subfloat[WP1 price percentage differences of constrained models.
]{\includegraphics[scale=0.5]{./plots/PercDiff_XS1945967153_Rho-inf.png}}
\hfill
\subfloat[WP1 price percentage differences of unconstrained models.
]{\includegraphics[scale=0.5]{./plots/PercDiff_u_XS1945967153_Rho-inf.png}}
\newline
\subfloat[WP2 price percentage differences of constrained models.
]{\includegraphics[scale=0.5]{./plots/PercDiff_XS2115185295_Rho-inf.png}}
\hfill
\subfloat[WP2 price percentage differences of unconstrained models.
]{\includegraphics[scale=0.5]{./plots/PercDiff_u_XS2115185295_Rho-inf.png}}
\newline
\subfloat[WP3 price percentage differences of constrained models.
]{\includegraphics[scale=0.5]{./plots/PercDiff_XS2402145127_Rho-inf.png}}
\hfill
\subfloat[WP3 price percentage differences of unconstrained models.
]{\includegraphics[scale=0.5]{./plots/PercDiff_u_XS2402145127_Rho-inf.png}}
\caption{Percentage differences between model and market prices, on the 13 considered times to maturity. Percentage differences are computed as (Price $-$ Market Price) / Market Price $\times$ 100.}
\label{fig:prices constrained vs unconstrained}
\end{figure}










%%%%%%
%\clearpage
\section{Conclusions}\label{Conclusions}

In this paper we investigate several multivariate L\'evy models following the constructions of \cite{luciano2010multivariate} and \cite{ballotta2016multivariate}, and we study calibration methods to fit them.
We perform an extensive empirical analysis to test the ability of the models to fit market data, give a fair valuation to exotic contracts, and suitably capture
dependence features.
Our results suggest that constrained LS models are a more stable choice than constrained BB models, as BB construction seems sensitive to model-specific convolution conditions.
Also, the ability of LS processes to embed nonlinear dependence makes them richer constructions, better suited to fit the joint dynamics of log-returns.
On the other hand, the unconstrained BB models prove to be able to reduce the trade-off between marginal and correlation fit observed in constrained models.
Still, while unconstrained processes retain a flexible structure, they also have less interpretable parameters and do not allow for two-step calibrations.
As a consequence, choosing to remove marginal restrictions should depend on the priorities of the user, with regards to model fitting, computational effort and interpretability.


As prices computed by L\'evy models tend to lose accuracy on path-dependent products with medium-long maturity, future research could focus on additive non-stationary processes.
For example, it would be relevant to assess and compare versions of LS and BB models that embed Sato margins (studied by \cite{marena2018multivariate} and \cite{boen2019building}).
However, as these processes keep the same dependence structure of the stationary versions, a further direction for research can be to test models that allow for more realistic time-dependent correlations (see, e.g., \citep{semeraro2022multivariate}).%, that are more consistent with market data.







%In this paper we present a variety of multivariate L\'evy models following the constructions of \cite{luciano2010multivariate} and \cite{ballotta2016multivariate}, focusing on their different versions with constrained and unconstrained margins, and with Variance Gamma and Normal Inverse Gaussian underlying laws.
%We analyze the theoretical structures of the models and the multiple ways to calibrate them in a risk-neutral environment.
%After describing an actively-traded type of exotic options, we perform an extensive empirical analysis to test the ability of the models to fit market data, give a fair valuation to exotic contracts and well-capture dependence features.
%By examining the results of the test, we provide insights to choose appropriate models and calibration techniques in a practical context, with special regard to the marginal vs dependence fitting trade-off.


%From the empirical analysis, we observe that although LS and BB constructions follow different approaches, their calibration performances are driven by analogous issues linked to the fitting trade-off, and produce comparable results.
%However, from calibration plots we can observe that in the case of VG, constrained BB performs slightly better than constrained LS, while considering NIG margins we observe the opposite.
%Such behaviour is likely to result from the sensitivity of BB construction to the model-specific ease to satisfy convolution conditions.
%Also, the exigent constraints imposed by BB models suggest a possible increase of fitting issues in higher dimensions, while LS construction scales better from a theoretical viewpoint.
%As a result, if the user desires to use a multivariate model that preserve well-known marginal laws, LS can be considered as a more stable choice.


%Overall, as calibration presents uniform outcomes, the capability of constrained models to replicate exotic quotes is similar. %among each other.
%Nonetheless, comparing model prices as a whole against market benchmarks, we evidence a solid performance of L\'evy models on short maturities and some lost of accuracy on longer-maturity contracts.
%Such behaviour is caused by an imperfect correlation calibration, but also by the stationary nature of L\'evy models, suggesting to employ non-stationary processes to price long-maturity exotic derivatives.
%Moreover, the sensitivity analysis to dependence features of the models evidences the strong relation between correlation and payoffs of the products, remarking the need to employ calibration methods able to distribute fitting errors proportionately between margins and correlation.
%It also highlights the moderate but nonetheless existent effect of nonlinear dependence on the valuation of the exotics, rewarding LS construction for being able to control the nonlinear dependence feature.


%Concerning the test on unconstrained models, we notice that such versions of LS and BB processes are valid alternatives to the constrained ones, in terms of calibration performance.
%However, their primary goal to reduce the marginal vs dependence trade-off can be considered reached just for BB construction, where marginal constraints can be exigent in some instances.
%Also, the higher interpretability of parameters and the possibility to carry out two-step calibrations seem strong arguments in favour of constrained models.
%As a consequence, constrained LS can be considered as the preferred choice with respect to its unconstrained counterpart.
%On the other hand, the great flexibility brought by removing convolution conditions of BB models tends to make unconstrained BB a more viable design than constrained BB.
%Overall, it is clear that the choice of using LS or BB models stands on the preference of the user about preserving or not known marginal laws, with all the due consequences.






%%%% Compliance with Ethical Standards
\section*{Compliance with Ethical Standards}
Authors declare that they have no conflict of interest.







%%% Biblio
\clearpage
%\typeout{}
\bibliographystyle{apalike}
%\bibliographystyle{unsrt}
\bibliography{Biblio}








%%%
\clearpage
\appendix
\section{WP3 Discounted Payoff Algorithm}\label{app:WP3 algorithm}

\begin{algorithm}
\caption{WP3 Discounted Payoff Algorithm}\label{alg:WP3-payoff}
\begin{algorithmic}[1]
\State Initialize discounted payoff: $\Pi \gets 0$
\State Initialize counter: $c \gets 0$
\For{$i = 1,...,m$}
    \State $P_j (t_i) \gets S_j (t_i) / S_l (t_0) - 1$, $\forall j = 1,...,n$
    \State $w_i \gets \underset{j \in \{1, ..., n\} }{ \text{argmin}} \{P_j (t_i)\}$
    \State $B_{d,i} \gets b_{d,i} \: S_{w_i} (t_0)$
    \If{$S_{w_i} (t_i) \geq B_{d,i}$}
        \State $\Pi \gets \Pi + e^{-r t_i} (c+1) k$
        \State $c \gets 0$
    \Else
        \State $c \gets c + 1$
    \EndIf
    \State $B_{r,i} \gets b_{r,i} \: S_{w_i} (t_0)$
    \If{$S_{w_i} (t_i) \geq B_{r,i}$}
        \State $\Pi \gets \Pi + e^{-r t_i} I$
        \State \Return $\Pi$
        %and go directly to step \ref{end0}.
    \EndIf
\EndFor
\State $P_j (t_m) \gets S_l (t_m) / S_j (t_0) - 1$, $\forall j = 1,...,n$
\State $w_N \gets \underset{j \in \{1, ..., n\} }{ \text{argmin}} \{P_j (t_N)\}$
\State $B = b \: S_{w_m} (t_0)$

\If{$S_{w_m} (t_m) \geq B$}
    \State $\Pi \gets \Pi + e^{-r t_m} I$
\Else
    \State $\Pi \gets \Pi + e^{-r t_m} \frac{S_w (t_m) }{ S_w (t_0)} I$
\EndIf
\State \Return $\Pi$
%\State Store $\Pi$ \label{end0}
\end{algorithmic}
\end{algorithm}




\end{document}