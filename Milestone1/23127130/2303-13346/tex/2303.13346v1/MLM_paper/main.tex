%\documentclass[a4paper,11pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[12pt, titlepage]{article}
\usepackage[utf8]{inputenc}

\usepackage[comma,authoryear]{natbib}

%% PS paper
\renewcommand{\baselinestretch}{1.1}
\oddsidemargin=0in \evensidemargin=0in \textwidth=6.2in
\headheight=0pt \headsep=0pt \topmargin=0in \textheight=9in
\renewcommand{\baselinestretch}{1.1}

%% new
\usepackage[english]{babel}
\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}

%% other
\usepackage{mathrsfs,amsmath}   %The amsmath package is included for \xrightarrow
\usepackage{amsmath,amssymb}
\usepackage{bbm}
\usepackage{mathtools}

%%%%%
\usepackage{footnote}
\usepackage{footmisc}
\makesavenoteenv{tabular}
\makesavenoteenv{table}
\renewcommand{\thefootnote}{\alph{footnote}}

\newcommand{\astfootnote}[1]{
\let\oldthefootnote=\thefootnote
\setcounter{footnote}{0}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\footnote{#1}
\let\thefootnote=\oldthefootnote
}

\usepackage{commath}
\usepackage{nicefrac}
\usepackage{titling,lipsum}
\usepackage{algpseudocode}
\usepackage{algorithm}
%\usepackage{caption}
%\usepackage{subcaption}
%\usepackage{subfigure}
\usepackage{subfig}



%% hyper references and colors
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{sectsty}
\definecolor{MyBlue1}{rgb}{0,0,1}
\definecolor{MyBlue2}{rgb}{0.1,0.3,0.8}
\definecolor{MyBlue3}{rgb}{0.3,0.5,1}
\definecolor{MyGreen}{rgb}{0.4,1,0.4}
\definecolor{MyRed}{rgb}{1,0.4,0.4}
\hypersetup{
    colorlinks=true,
    linkcolor=MyBlue1,
    citecolor=MyBlue1,
    linkbordercolor=MyRed, % blue
    citebordercolor=MyGreen, %MyGreen
    }

%% title and authors
\title{ \bf
Multivariate Lévy Models: Calibration and Pricing
}
\author{
{\bf Giovanni Amici}  \\
       Department of Mathematical Sciences\\
       Politecnico di Torino\\
       giovanni.amici@polito.it\\[14pt]
{\bf Paolo Brandimarte}  \\
       Department of Mathematical Sciences\\
       Politecnico di Torino\\[14pt]
{\bf Francesco Messeri}  \\
       Model Development and Integration Senior Specialist\\
       Intesa Sanpaolo Risk Management IMI CIB\\[14pt]
{\bf Patrizia Semeraro}  \\
       Department of Mathematical Sciences\\
       Politecnico di Torino\\%[4pt]
       }
\date{}



%%%%%% HESTON PAPER
%\usepackage{amsmath,amssymb,amsthm,amsfonts}    % AMS math packages
%\usepackage{mathrsfs,bm}                        % Bold math symbols
%\usepackage{dsfont}
%\usepackage{eurosym}                            % Euro symbol
%\usepackage{xcolor}                             % Color text management
%\usepackage{url,hyperref}                       % Urls and hypertexts (for online files) management
%\usepackage{float}                              % Floating objects management
%\usepackage[small,bf]{caption}                  % Advanced caption management
%\usepackage{graphicx}
%\usepackage{epstopdf}                           % Figures management
%\usepackage{subfigure}
%\usepackage{psfrag}                             % Allows to overlay EPS figures with arbitrary LaTeX constructions
%\usepackage{epsfig}                             % Encapsulated postscript management
%%%\graphicspath{{./Figures/}}                     % Figures path
%\usepackage{booktabs,multirow,longtable}        % Advanced table management
%\usepackage{tabularx}        					% Advanced table management
%\usepackage[english]{babel}
%\usepackage{mathtools}
%\usepackage{makecell}
%\usepackage[margin=0.5in]{geometry}
%\usepackage{booktabs}
%\setcounter{MaxMatrixCols}{10} 
%\textheight		   25cm 
%\topmargin		   -2cm
%\textwidth		   16cm 
%\oddsidemargin 	 -0.0cm 
%\evensidemargin		2cm
%\makeatletter \@addtoreset{equation}{section} \makeatother
%\renewcommand{\theequation}{\thesection.\arabic{equation}}
%\interfootnotelinepenalty=10000
%%%\graphicspath{{plots}}

%% CHECK
%\usepackage[toc,page]{appendix}
%\usepackage[nottoc,notlot,notlof]{tocbibind}




\begin{document}

\maketitle

%%%%%%%
%\thispagestyle{empty}

%\begin{titlingpage}
\begin{abstract}
In this research we employ a range of multivariate asset models based on Lévy processes to price exotic derivatives. We compare their ability to fit market data and replicate price benchmarks, and evaluate their flexibility in terms of parametrization and dependence structure.
We review recent risk-neutral calibration approaches and techniques in the multivariate setting, and provide tools to make well-informed decisions in a practical context.
A special focus is given to the ability of the models to capture linear and nonlinear dependence, with implications on their pricing performance.
Given the exotic features of the analyzed derivatives, valuation is carried out through Monte Carlo methods.
%\end{titlingpage}
\vfil

%\vspace{0.5cm} 
\noindent \textbf{Keywords}: Multivariate Lévy Processes, Calibration, Pricing, Dependence, Exotic Derivatives.

%\vspace{0.5cm} 
\noindent \textbf{Disclaimer}: The views and opinions expressed belong solely to the authors and do not necessarily reflect the views or positions of Intesa Sanpaolo SpA.

\end{abstract}







%\newpage
%%%%%%
\section{Introduction}

Over the last decades, many attempts have been made to perform a well-informed and efficient valuation of multi-name derivatives.
To achieve this, it is crucial to build multivariate processes able to reproduce time series of financial instruments. As opposed to their univariate versions, the construction of these processes is more challenging as it needs to provide flexibility of marginal and dependence structures, and deal with possible trade-offs between them.
These factors affect model performance in the calibration and pricing phases. Calibration, in particular, is a delicate procedure that depends on model architecture and the optimization techniques used to find the solution vector.


Two different approaches to construct multivariate Lévy processes have been presented by \cite{luciano2010multivariate} and \cite{ballotta2016multivariate}, based on linear combinations of univariate processes of the same class. We call these two \textit{LS models} and \textit{BB models}, respectively. In LS models, linear combination is performed on subordinators, while in BB models, it is directly applied on the log-return process, with implications on dependence range and how easy it is to satisfy convolution conditions.
Calibration procedures for these models generally consist of a two-step procedure, where first marginal parameters are fitted to liquid volatility surfaces, and then dependence parameters are found by matching model and market correlations. As marginal and dependence fit could suffer a trade-off, techniques can be applied that distribute calibration errors on one side or the other, possibly depending on the payoff of the exotic derivative priced by the model.
As calibration is an optimization problem, its implementation is identified by the choice of its objective function, its constraints and the algorithm used. Algorithms for such global minimization problems are heuristic methods of mainly three types, i.e., stochastic search, multi-start and surrogate (see e.g., \cite{pinter2006global} and \cite{kochenderfer2019algorithms} textbooks), while objective function can be modified to include penalty terms if a regularization of the problem is desired (see e.g., \cite{tikhonov1963solution}). These choices are necessarily model-dependent, as each log-return distribution can lead to different levels of non-convexity of the objective function.


On the one hand, this work is a guide for valuing multi-name derivatives in practical circumstances. On the other hand, it compares different classes of Lévy models, further providing tools to make appropriate decisions on the calibration problem.
To this aim, we review the literature of two known types of multivariate Lévy models and the ways to efficiently estimate their parameters. We then calibrate models on market data and employ them to price \textit{worst-performance} derivatives issued by Intesa Sanpaolo bank, comparing results with quoted benchmarks. We further show the effect of linear and nonlinear dependence on prices, with possible implications on the choice of the most appropriate model and calibration setting to use.

The paper is structured as follows. In Section \ref{Model Theory}, we report the theory behind \cite{luciano2010multivariate} and \cite{ballotta2016multivariate} multivariate models. In Section \ref{Calibration Methods}, we show the related risk-neutral calibration methods. In Section \ref{Worst Performance Derivatives}, we describe the exotic derivatives employed in the analysis. We then report and discuss the empirical results in Section \ref{Empirical Analysis} and draw conclusions in Section \ref{Conclusions}.









%%%%%%%%%
\section{Log-Return Processes}\label{Model Theory}
%\cite{AmeBia09}
In the last years, much research has been focused on building multidimensional processes with tractable characteristic functions, parsimonious numbers of parameter and rich dependence structures, to model joint log-returns.
This section introduces two approaches, developed by \cite{luciano2010multivariate} and \cite{ballotta2016multivariate}, based on linear combinations of Lévy processes that deal with this matter, with both Variance Gamma and Normal Inverse Gaussian specifications. For sake of notation, for any stochastic process $\{A(t)\}_{t\geq0}$, we let $A := A(1)$, and further recall that any Lévy process has characteristic function fully derivable by their time-1 distribution.



%%%%%
\subsection{LS Models}\label{LS Models}

In this subsection, we recap the main steps to build the factor-based processes introduced in \cite{luciano2010multivariate}, that we name \textit{LS processes}.
To construct the multivariate log-return process $\{ \boldsymbol{Y}(t) \}_{t\geq0}$, we start by defining a class of factor-based multivariate subordinators $\{ \boldsymbol{G}(t) \}_{t\geq0}$ given by
\begin{equation}\label{G_j}
\boldsymbol{G}(t)=(X_{1}(t)+\kappa _{1}Z(t),...,X_{n}(t)+\kappa
_{n}Z(t)),\quad \kappa _{j}>0, \hspace{5pt} j=1,...,n,
\end{equation}%
where $\{\boldsymbol{X}(t)\}_{t\geq0}$ is a multivariate subordinator, with independent components acting as idiosyncratic factors of trading volume, and $\{Z(t)\}_{t\geq0}$ is a subordinator, independent from $\boldsymbol{X}(t)$, representing the systematic factor.
Let also $\{\boldsymbol{B}(t)\}_{t\geq0}$ and $\{\boldsymbol{B}^{\rho}(t)\}_{t\geq0}$ be multivariate Brownian motions with Lévy triplets $(\boldsymbol{\mu}, \boldsymbol{\Sigma}, \boldsymbol{0})$ and $(\boldsymbol{\mu}^{\rho}, \boldsymbol{\Sigma}^{\rho}, \boldsymbol{0})$, respectively. In particular,
$$
\boldsymbol{\mu}
=
\begin{pmatrix}
    \mu_1, ..., \mu_n
\end{pmatrix},
\hspace{20pt}
\boldsymbol{\Sigma}
=
\text{diag}
\begin{pmatrix}
    \sigma_1^2, ..., \sigma_n^2
\end{pmatrix}.
$$
Consider further the multi-parameter $\boldsymbol{s}=(s_1,...,s_n)^T \in \mathbb{R}_+^n$ and the multi-parameter process introduced by \cite{barndorff2001multivariate}, corresponding to the above defined Brownian $\boldsymbol{B}(t)$, that is
\begin{equation}
\boldsymbol{B}(\boldsymbol{s})=\{(B_{1}(s_{1}),...,B_{n}(s_{n})),\boldsymbol{%
s}\in \mathbb{R}_{+}^{n}\}  \label{MultiBM}
\end{equation}%
with the partial order on $\mathbb{R}_+^n$,
\begin{equation*}
\boldsymbol{s}^{1}\preceq \boldsymbol{s}^{2}\,\,\,\Leftrightarrow
\,\,\,s_{j}^{1}\leq s_{j}^{2},\, \hspace{10pt} j=1,...n.
\end{equation*}%


We can then define the multivariate log-return process as
\begin{equation}\label{Y}    
    \boldsymbol{Y}(t)
    =
    \boldsymbol{B} (\boldsymbol{X}(t)) +
    \boldsymbol{B}^{\rho} (Z(t))
    =
    \begin{pmatrix}
        B_1 (X_1(t)) + B^{\rho}_1 (Z(t))
        \\
        ...
        \\
        B_n (X_n(t)) + B^{\rho}_n (Z(t))
    \end{pmatrix},
\end{equation}
where $\boldsymbol{B}(\boldsymbol{X}(t))$ and $\boldsymbol{B}^{\rho}(Z(t))$ can be considered as the idiosyncratic and the systematic risk components of the dynamics of the assets. Also, we set
$$
\boldsymbol{\mu}^{\rho} =
\begin{pmatrix}
    \mu_1 \kappa_1, ..., \mu_n \kappa_n
\end{pmatrix}
$$
$$
\boldsymbol{\Sigma}^{\rho} =
\begin{pmatrix}
    \sigma_1^2 \kappa_1 & \rho_{12} \sigma_1 \sigma_2 \sqrt{\kappa_1} \sqrt{\kappa_2} & ... & \rho_{1n} \sigma_1 \sigma_n \sqrt{\kappa_1} \sqrt{\kappa_n}
    \\
    \rho_{12} \sigma_1 \sigma_2 \sqrt{\kappa_1} \sqrt{\kappa_2} & \sigma_2^2 \kappa_2 & ... & \rho_{2n} \sigma_2 \sigma_n \sqrt{\kappa_2} \sqrt{\kappa_n}
    \\
    ... & ... & ... & ...
    \\
    \rho_{1n} \sigma_1 \sigma_n \sqrt{\kappa_1} \sqrt{\kappa_n} & \rho_{2n} \sigma_2 \sigma_n \sqrt{\kappa_2} \sqrt{\kappa_n} & ... & \sigma_n^2 \kappa_n
\end{pmatrix},
$$
in such a way that each marginal log-return process $j$ is a Brownian motion with drift $\mu_j$, diffusion $\sigma_j$ and subordinated by $G_j(t)$.
In particular, \cite{luciano2010multivariate} proved that
\begin{equation}\label{Y_j}
Y_{j}(t) \overset{\text{d}}{=} \mu _{j}G_{j}(t)+\sigma _{j} \Tilde{B}_j(G_{j}(t),
\end{equation}%
where $\Tilde{B}_j$ is a standard Brownian motion.


By means of Theorem 30.1 in \cite{ken1999levy}, and Theorem 3.3 in \cite{barndorff2001multivariate} for the multivariate case, we are able to derive the time-1 characteristic function of the subordinated process as
\begin{equation}\label{LS-CF}
\phi _{\boldsymbol{Y}}(\boldsymbol{u}) =
\exp \Bigg\{ \sum_{j=1}^{n}l_{X_{j}}(\psi _{B_{j}}(u_{j})) \Bigg\}
\exp \Bigg\{ l_{Z}(\psi _{\boldsymbol{B}^{\rho }}(\boldsymbol{u})) \Bigg\},
\hspace{10pt}
\boldsymbol{u} \in \mathbb{R}^n,
\end{equation}%
where $l(\cdot)$ is the Laplace exponent.
Also, pairwise correlations turn out to be
$$
\rho_{\boldsymbol{Y}} (i,j)
=
\frac{
\mathbb{E} [B_i^{\rho}] \mathbb{E} [B_j^{\rho}] \mathbb{V} (Z)
+ \text{Cov} ( B_i^{\rho}, B_j^{\rho} ) \mathbb{E}[Z]
}{\sqrt{ \mathbb{V}(Y_i) \mathbb{V}(Y_j) }}
=
\frac{
\mu_i \mu_j \kappa_i \kappa_j \mathbb{V} (Z)
+ \rho_{ij} \sigma_i \sigma_j \sqrt{\kappa_i} \sqrt{\kappa_j} \mathbb{E}[Z]
}{
\sqrt{ \mathbb{V}(Y_i) \mathbb{V}(Y_j) }
},
$$
where $\mathbb{E}[\cdot]$, $\mathbb{V}(\cdot)$ and $\text{Cov}(\cdot, \cdot)$ denote the expectation, variance and covariance, respectively.






%%%%%%%
\subsubsection{LS-Variance Gamma}\label{LS-VG}

As it can be seen from LS process construction, the Lévy class of $Y_j(t)$ is given by the specifications of subordinators. Here we illustrate the case where each asset log-return follows a Variance Gamma process (\cite{madan1990variance}).
Let $X_1(t), ..., X_n(t), Z(t)$ be Gamma processes such that
\begin{equation}\label{Gamma-Sub}
    X_j \sim \Gamma \left(\frac{1}{\kappa_j} - a, \frac{1}{\kappa_j} \right),
    \hspace{15pt}
    Z \sim \Gamma \left(a, 1 \right),
    \hspace{15pt}
    \text{with}
    \hspace{15pt}
    0 < a < \min_j \left( \frac{1}{\kappa_j} \right),
    \hspace{5pt}
    \kappa_j > 0.
\end{equation}
Then, by the closure property of convolution of Gamma distributions, and following Eq.\ (\ref{G_j}), we get 
$$
G_j \sim \Gamma \left(\frac{1}{\kappa_j}, \frac{1}{\kappa_j} \right).
$$
\cite{luciano2010multivariate} proved that the resulting 1-dimensional margin $Y_j(t)$ follows a VG$(\mu_j, \sigma_j, \kappa_j)$, i.e.,
\begin{equation}\label{VG-CF}
    \phi_{Y_j} (u) = \left( 1 - i u \mu_j \kappa_j + \frac{1}{2} u^2 \sigma^2_j \kappa_j \right)
    %^{\nicefrac{1}{\kappa_j}},
    ^{\kappa^{-1}_j},
    \hspace{15pt}
    u \in \mathbb{R}
    ,
\end{equation}
while the multivariate process $\boldsymbol{Y} (t)$ is a LS-VG with parameters $( \boldsymbol{\mu}, \boldsymbol{\sigma}, \boldsymbol{\kappa}, a, \{ \rho_{ij} \}_{i \neq j} )$ and characteristic function
%inferred from (\ref{LS-CF}) and (\ref{Gamma-Sub}).
\begin{equation*}
\phi _{\boldsymbol{Y}}(\boldsymbol{u})=
\prod_{j=1}^{n}\left[ 1-{\kappa_{j}\left(i\mu _{j}u_{j}-\frac{1}{2}\sigma _{j}^{2}u_{j}^{2}\right)}\right]
%^{-\left( \nicefrac{1}{\kappa _{j}}-a\right) }
^{-\left( \kappa^{-1}_j-a\right) }
\left[ 1-\left( i\boldsymbol{u}^{T} \boldsymbol{\mu }^{\rho }-\frac{1}{2}\boldsymbol{u}^{T}\boldsymbol{\Sigma }^{\rho }\boldsymbol{u}\right) \right] ^{-a}
\hspace{-8pt}
,
\hspace{1pt}
\boldsymbol{u} \in \mathbb{R}^n.
\end{equation*}%
The number of parameters of the time-1 distribution is $1 + 3n + \frac{n(n-1)}{2}$ and correlation, for each pair $(i,j)$ of assets, is given by
\begin{equation}\label{rhoY-LS-VG}
    \rho_{\boldsymbol{Y}} (i,j)
    =
    \frac{
    \mu_i \mu_j \kappa_i \kappa_j
    +
    \rho_{ij} \sigma_i \sigma_j \sqrt{\kappa_i} \sqrt{\kappa_j}
    }{
    \sqrt{ (\sigma^2_i + \mu^2_i \kappa_i)
    (\sigma^2_j + \mu^2_j \kappa_j) }
    } \: a.
\end{equation}
Bounds on the correlation coefficient are thoroughly discussed in \cite{marena2018pricing}.
They observed that the maximum achievable level of correlation is linked to the marginal with the highest $\kappa$ parameter. As $\kappa$ drives the kurtosis, there exists a trade-off between the kurtosis marginal fit and the correlation admissible range.
However, an interesting feature is that dependence structure allows for non-linear dependence, which can be easily observed in case of symmetric marginals (i.e., $\mu_i, \mu_j = 0$) and uncorrelated Brownian motions. In this circumstance, we would get the correlation coefficient equal to 0 but still have non-zero dependence regulated by parameter $a$.




%%%%%%%
\subsubsection{LS-Normal Inverse Gaussian}\label{LS-NIG}

Another well-known type of Lévy process is given by Normal Inverse Gaussian process (\cite{barndorff1995normal}). Here we show how a LS process can be built such that its margins are NIG processes. Let $X_1(t), ..., X_n(t), Z(t)$ be Inverse Gaussian processes,
\begin{equation}\label{IG-Sub}
    X_j \sim \text{IG} \left(1 - a \sqrt{\kappa_j}, \frac{1}{\sqrt{\kappa_j}} \right),
    \hspace{15pt}
    Z \sim \text{IG} \left(a, 1 \right),
    \hspace{15pt}
    \text{with}
    \hspace{15pt}
    0 < a < \min_j \left( \frac{1}{\sqrt{\kappa}_j} \right),
    \hspace{5pt}
    \kappa_j > 0.
\end{equation}
Then, by the closure property of convolution of Inverse Gaussian distributions, and following Eq.\ (\ref{G_j}), we get 
$$
G_j \sim \text{IG} \left(1, \frac{1}{\sqrt{\kappa_j}} \right).
$$
\cite{luciano2010multivariate} proved that the resulting 1-dimensional margin $Y_j(t)$ follows a NIG$(\beta_j, \delta_j, \gamma_j)$, with $-\gamma_j<\beta_j<\gamma_j$, $\delta_j>0$, $\gamma_j>0$, i.e.,
\begin{equation}\label{NIG-CF}
    \phi_{Y_j} (u) = \exp \left\{ -\delta_j \left(\sqrt{\gamma^2_j - (\beta_j + i u)^2} - \sqrt{\gamma^2_j - \beta^2_j}\right) \right\}
    ,
    \hspace{15pt}
    u \in \mathbb{R}
    ,
\end{equation}
where, applying relations
$$
\mu_j = \beta_j \delta^2,
\hspace{3pt}
\sigma_j = \delta_j,
\hspace{3pt}
\kappa_j = [\delta_j^2 (\gamma_j^2 - \beta_j^2)]^{-1},
$$
we get the same expression of Eq.\ (\ref{Y_j}).
$\boldsymbol{Y} (t)$ is then a LS-NIG$( \boldsymbol{\beta}, \boldsymbol{\delta}, \boldsymbol{\gamma}, a, \{ \rho_{ij} \}_{i \neq j} )$ with $1 + 3n + \frac{n(n-1)}{2}$ parameters, time-1 characteristic function 
%derived from (\ref{LS-CF}) and (\ref{IG-Sub}).
\begin{equation*}
\begin{split}
\phi _{\boldsymbol{Y}}(\boldsymbol{u})=
& \exp \left\{ -\sum_{j=1}^{n} \left(1-\frac{a}{\zeta _{j}} \right)\left( \sqrt{-2 \left(i\beta _{j}\delta _{j}^{2}u_{j}-\frac{1}{2}\delta _{j}^{2}u_{j}^{2} \right)+\zeta _{j}^{2}}-\zeta _{j}\right) \right\} \cdot
\\
& \cdot \exp \left\{ -a\left( \sqrt{-2 \left(i\boldsymbol{u}^{T}\boldsymbol{\mu}^{\rho}-\frac{1}{2}\boldsymbol{u}^{T}\boldsymbol{\Sigma}^{\rho}\boldsymbol{u}\right)+1}-1\right) \right\},
\hspace{10pt}
\boldsymbol{u} \in \mathbb{R}^n,
\end{split}%
\end{equation*}
where $\zeta _{j}=\delta _{j}\sqrt{\gamma _{j}^{2}-\beta _{j}^{2}}$, and correlation coefficient
\begin{equation}\label{rhoY-LS-NIG}
    \rho_{\boldsymbol{Y}} (i,j)
    =
    \frac{
    \beta_i (\delta_i^2 / \zeta_i^2)
    \beta_j (\delta_j^2 / \zeta_j^2)
    +
    \rho_{ij} (\delta_i / \zeta_i) (\delta_j / \zeta_j)
    }{
    \sqrt{
    \gamma_i^2 \delta_i (\gamma_i^2 - \beta_i^2)^{-3/2}
    \:
    \gamma_j^2 \delta_j (\gamma_j^2 - \beta_j^2)^{-3/2}
    }
    } \: a.
\end{equation}
On dependence structure, similar considerations of Subsection \ref{LS-VG} can be made.











%%%%%%
\subsection{BB Models}

\cite{ballotta2016multivariate} proposed a multivariate process constructed by a convolution of two Lévy processes, without the need to pass through subordinators, that we call \textit{BB processes}. They are of the form
$$
\boldsymbol{Y}(t)
=
\boldsymbol{X}(t) + \boldsymbol{b}
\hspace{2pt}
Z(t)
=
\begin{pmatrix}
    X_1(t) + b_1 Z(t)
    \\
    ...
    \\
    X_n(t) + b_n Z(t)
\end{pmatrix},
$$
where $\boldsymbol{b} \in \mathbb{R}^n$, and $X_1(t), ..., X_n(t), Z(t)$ are $\mathbb{R}$-valued mutually independent Lévy processes. Time-1 characteristic function is then


\begin{equation}\label{BB-CF}
\phi_{\boldsymbol{Y}}(\boldsymbol{u})
=
\exp \left\{ \sum_{j=1}^{n} \psi_{X_{j}}(u_{j}) \right\}
\exp \left\{ \psi_Z \left( \sum_{j=1}^{n} b_j u_j \right) \right\},
\hspace{10pt}
\boldsymbol{u} \in \mathbb{R}^n.
\end{equation}%
Also in this case, it is natural to consider $\boldsymbol{X}(t)$ and $Z(t)$ as the idiosyncratic and the systematic risk factors, respectively.
The pairwise correlation are given by
$$
\rho_{\boldsymbol{Y}} (i,j)
=
\frac{
b_i b_j \mathbb{V} (Z)
}{
\sqrt{ \mathbb{V}(Y_i) \mathbb{V}(Y_j) }
}
.
$$
As opposed to LS, BB models do not necessarily suffer trade-offs between marginal and dependence fit.
However, to obtain 1-dimensional margins belonging to a known class (e.g., VG, NIG), we have to impose the following convolution conditions on marginal distributions,
\begin{equation}\label{conv-conditions}
\psi_j (u) = \psi_{X_j} (u) + \psi_Z (b_j u)
,
\hspace{15pt}
j = 1, ..., n,
\end{equation}
that are not satisfied a priori, but require exigent constraints on parameters, likely fulfilled only up to an approximation. The idea behind BB approach is to first estimate $\boldsymbol{Y}(t)$ parameters, and then find combinations of $\boldsymbol{X}(t)$, $\boldsymbol{b}$ and $Z(t)$ parameters in order to reflect market correlation, while still being marginally distributed as $\boldsymbol{Y}(t)$.





%%%%%%%%%
\subsubsection{BB-Variance Gamma}
Let
$
Y_j \sim \text{VG} (\mu_j, \sigma_j, \kappa_j)
,
\hspace{3pt}
X_j \sim \text{VG} (\mu_{X_j}, \sigma_{X_j}, \kappa_{X_j})
,
\hspace{3pt}
Z \sim \text{VG} (\mu_Z, \sigma_Z, \kappa_Z)
$,
with characteristic functions as in Eq.\ (\ref{VG-CF}). Then, to satisfy convolution conditions (\ref{conv-conditions}), the following constraints must hold:
\begin{equation}\label{VG-conv-restrictions-1}
\begin{aligned}
    \kappa_j \mu_j = \kappa_Z b_j \mu_Z
    ,
    \hspace{15pt}
    j = 1, ..., n,
    \\
    \kappa_j \sigma^2_j = \kappa_Z b^2_j \sigma^2_Z
    ,
    \hspace{15pt}
    j = 1, ..., n,
\end{aligned}
\end{equation}
from which we obtain relations
\begin{equation}\label{VG-conv-restrictions-2}
    \mu_j = \mu_{X_j} + b_j \mu_Z
    ,
    \hspace{15pt}
    \sigma_j = \sqrt{ \sigma^2_{X_j} + b^2_j \sigma^2_Z }
    ,
    \hspace{15pt}
    \kappa_j = \frac{ \kappa_{X_j} \kappa_Z }{ \kappa_{X_j} + \kappa_Z }
    ,
    \hspace{15pt}
    j = 1, ..., n
    .
\end{equation}
The resulting multivariate process $\boldsymbol{Y}(t)$ is then a BB-VG$( \boldsymbol{\mu}_{X}, \boldsymbol{\sigma}_X, \boldsymbol{\kappa}_X, \boldsymbol{b}, \mu_Z, \sigma_Z, \kappa_Z )$ with $4n+3$ parameters, characteristic function 
%(\ref{BB-CF}) and (\ref{VG-CF-inBB}),
\begin{equation*}
\begin{split}
    \phi_{\boldsymbol{Y}} (\boldsymbol{u}) =
    & \prod_{j=1}^n \left( 1 - i u_j \mu_{X_j} \kappa_{X_j} + \frac{1}{2} u_j^2 \sigma^2_{X_j} \kappa_{X_j} \right)
    %^{\nicefrac{1}{\kappa_{X_j}}} \cdot
    ^{\kappa^{-1}_{X_j}} \cdot
    \\
    & \cdot \left[ 1 - i \mu_Z \kappa_Z \sum_{j=1}^n b_j u_j + \frac{1}{2} \sigma^2_Z \kappa_Z \left(\sum_{j=1}^n b_j u_j \right)^2 \right]
    %^{\nicefrac{1}{\kappa_Z}}
    ^{\kappa^{-1}_Z}
    ,
    \hspace{15pt}
    \boldsymbol{u} \in \mathbb{R}^n
    ,
    \end{split}
\end{equation*}
and correlation coefficient
\begin{equation}\label{rhoY-BB-VG}
    \rho_{\boldsymbol{Y}} (i,j)
    =
    \frac{
    b_i b_j (\sigma^2_Z + \mu^2_Z \kappa_Z)
    }{
    \sqrt{ (\sigma^2_i + \mu^2_i \kappa_i)
    (\sigma^2_j + \mu^2_j \kappa_j) }
    }.
\end{equation}






%%%%%%%%%
\subsubsection{BB-Normal Inverse Gaussian}
\cite{ballotta2016multivariate} originally formulated a multivariate NIG with unbiased subordinator, with parametrization similar to BB-VG. Here, for comparison purposes, we present a new version that keeps the same marginal distributions of LS-NIG.
Let $Y_j \sim \text{NIG} (\beta_j, \delta_j, \gamma_j), \hspace{3pt} X_j \sim \text{NIG} (\beta_{X_j}, \delta_{X_j}, \gamma_{X_j}), \hspace{3pt} Z \sim \text{NIG} (\beta_Z, \delta_Z, \gamma_Z)$,
with characteristic functions as in Eq.\ (\ref{NIG-CF}). Then, to satisfy convolution conditions (\ref{conv-conditions}), the following constraints must hold,
\begin{equation}\label{NIG-conv-restrictions-1}
\begin{aligned}
    \beta_j = b_j^{-1} \beta_Z
    ,
    \hspace{15pt}
    j = 1, ..., n,
    \\
    \gamma_j = b_j^{-1} \gamma_Z
    ,
    \hspace{15pt}
    j = 1, ..., n,
\end{aligned}
\end{equation}
from which we obtain relations
\begin{equation}\label{NIG-conv-restrictions-2}
    \beta_j = \beta_{X_j} = b_j^{-1} \beta_Z
    ,
    \hspace{15pt}
    \delta_j = \delta_{X_j} + b_j \delta_Z
    ,
    \hspace{15pt}
    \gamma_j = \gamma_{X_j} = b_j^{-1} \gamma_Z
    ,
    \hspace{15pt}
    j = 1, ..., n
    .
\end{equation}
The resulting multivariate process $\boldsymbol{Y}(t)$ is then a BB-NIG$( \boldsymbol{\beta}_{X}, \boldsymbol{\delta}_X, \boldsymbol{\gamma}_X, \boldsymbol{b}, \beta_Z, \delta_Z, \gamma_Z )$ with $4n+3$ parameters, characteristic function
%derived combining (\ref{BB-CF}) and (\ref{NIG-CF-inBB})
\begin{equation*}
\begin{split}
    \phi_{\boldsymbol{Y}} (\boldsymbol{u}) =
    & \prod_{j=1}^n
    \exp \left\{ -\delta_{X_j} \left(\sqrt{\gamma^2_{X_j} - \left(\beta_{X_j} + i u_j \right)^2} - \sqrt{\gamma^2_{X_j} - \beta^2_{X_j}}\right) \right\} \cdot
    \\
    & \cdot \exp \left\{ -\delta_Z \left(\sqrt{\gamma^2_Z - \left(\beta_Z + i \sum_{j=1}^n b_j u_j \right)^2} - \sqrt{\gamma^2_Z - \beta^2_Z} \right) \right\}
    ,
    \hspace{15pt}
    \boldsymbol{u} \in \mathbb{R}^n
    ,
\end{split}
\end{equation*}
and correlation coefficient
\begin{equation}\label{rhoY-BB-NIG}
    \rho_{\boldsymbol{Y}} (i,j)
    =
    \frac{
    b_i b_j \gamma^2_Z \delta_Z (\gamma^2_Z - \beta^2_Z)^{-3/2}
    }{
    \sqrt{ \gamma^2_i \delta_i (\gamma^2_i - \beta^2_i)^{-3/2}
    \:\:
    \gamma^2_j \delta_j (\gamma^2_j - \beta^2_j)^{-3/2} }
    }.
\end{equation}















%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%
\section{Calibration Methods}\label{Calibration Methods}

In this section, we introduce the calibration methods needed to fit models to market data. Define an $\mathbb{R}^n$-valued asset price process $\{ \boldsymbol{S} (t) \}_{t \geq 0}$ with margins given by
$$
S_j (t) = \exp \{ (r - q_j + \omega_j) t + Y_j (t) \}
,
\hspace{15pt}
j = 1, ..., n
$$
where $r$ is the risk-free rate, $q$ is the $j$-th continuously compounded dividend yield and $\omega_j = - \psi_{Y_j} (u = -i)$ is the $j$-th mean correction to assure the martingale condition, needed in the risk-neutral world.
The aim is then to calibrate such process to market quotes.




%%%%%
%\subsection{Common Framework}

\cite{marena2018pricing} and \cite{ballotta2016multivariate} designed the risk-neutral calibration settings to estimate suitable values of LS and BB model parameters. Both models allow for a 2-step procedure: first, marginal parameters are calibrated exploiting liquid volatility surfaces; then, dependence parameters are found matching model and market correlations.
Marginal calibration consists of solving for each asset $j=1,...,n$, the optimization problem


\begin{equation*}
\begin{aligned}
\mathcal{M}^*_j
=
\hspace{5pt}
& \underset{
\mathcal{M}_j
}{\text{argmin}}
& & \frac{1}{N_j} \sum_{l=1}^{N_{j}} \omega_l \big[ v_l^{\text{mod}} (\mathcal{M}_j) - v_l^{\text{mkt}} \big]^2
\\
& \text{subject to}
& & \mathcal{M}_j \in \overline{\mathcal{M}}
%\\
%&&& \mathcal{M}_j \in \mathcal{X}
\end{aligned}
\end{equation*}
where $N_j$ is the number of implied volatilities $\{ v_l \}_{l = 1, ..., N_j}$ chosen to fit the univariate process, $\{ \omega_l \}_{l=1,...,N_j}$ is an arbitrary set of weights, $\mathcal{M}_j$ is the set of marginal parameters and $\overline{\mathcal{M}} = \{\mu_j \in \mathbb{R}; \hspace{5pt} \sigma_j > 0; \hspace{5pt} \kappa_j > 0\}$ or $\overline{\mathcal{M}} = \{-\gamma_j < \beta_j < \gamma_j; \hspace{5pt} \delta_j > 0; \hspace{5pt} \gamma_j > 0\}$ the set of constraints.
Once the optimized marginals $\{ \mathcal{M}^*_1, ..., \mathcal{M}^*_n \}$ are obtained, dependence parameters $\mathcal{D}$ are found by
solving
\begin{equation}\label{dependence-calibration}
\begin{aligned}
\mathcal{D}^*
=
\hspace{5pt}
& \underset{
\mathcal{D}
}{\text{argmin}}
& & \frac{2}{n (n-1)}
\sum_{i=1}^n
\sum_{j>i}
\big[ \rho_{\boldsymbol{Y}}^{\text{mod}} (i, j, \mathcal{M}^*_i, \mathcal{M}^*_j, \mathcal{D}) - \rho_{\boldsymbol{Y}}^{\text{mkt}} (i,j) \big]^2
\\
& \text{subject to}
& & \mathcal{D} \in \overline{\mathcal{D}}
%\\
%&&& \mathcal{M}_j \in \mathcal{X}
\end{aligned}
\end{equation}
where $\overline{\mathcal{D}}$ is a model-specific feasible region and, assuming the availability of a single quote (for each pair of assets) from a liquidly traded multi-name instrument, $\rho_{\boldsymbol{Y}}^{\text{mkt}} (i,j)$ and $\rho_{\boldsymbol{Y}}^{\text{mod}} (i, j, \mathcal{D})$ are the Black-Scholes implied correlations from that market and model price, respectively.
Multiple correlations along strikes and maturities might be available, but it is more frequent to have only one, likely derived from a quote estimated according to beliefs of traders, more than an actual liquid quote.
Another common situation is to have no liquid prices at all, in which case $\rho_{\boldsymbol{Y}}^{\text{mkt}} (i,j)$ is approximated by historical correlation and $\rho_{\boldsymbol{Y}}^{\text{mod}} (i, j, \mathcal{D})$ by theoretical correlation as in (\ref{rhoY-LS-VG}), (\ref{rhoY-LS-NIG}), (\ref{rhoY-BB-VG}), (\ref{rhoY-BB-NIG}), abandoning the risk-neutral measurement.








%%%%%%%%
%\subsection{LS-Specific Model Calibration}
\subsection{Model-Specific Calibrations}

In LS models, dependence parameters are  $\mathcal{D} = (a, \{ \rho_{ij} \}_{i \neq j})$, while the feasible region is given by
$$
\overline{\mathcal{D}} = \Big\{ 0 < a < \min_j \Big( \kappa_j^{-m} \Big);
\hspace{5pt}
-1 \leq \rho_{ij} \leq 1, \forall i \neq j \Big\},
$$
where $m=1$ in the LS-VG case and $m=0.5$ in LS-NIG.
As anticipated, the above bounds on $a$ lead to a potential trade-off between correlation range and marginal kurtosis fit. As marginal parameters are calibrated before dependence ones, calibration error is likely concentrated on correlation. To better distribute the error, \cite{marena2018pricing} propose to run a joint calibration instead, consisting of performing marginal fit of all the assets at the same time, while imposing a maximum level of correlation gap allowed, $\epsilon>0$. In particular,

\begin{equation*}
\begin{aligned}
\{\mathcal{M}^*_1, ..., \mathcal{M}^*_n, \mathcal{D}^*\}
=
\hspace{5pt}
& \underset{
\mathcal{M}_1, ..., \mathcal{M}_n, \mathcal{D}
}{\text{argmin}}
& & \sum_{j = 1}^n
\frac{1}{N_j} \sum_{l=1}^{N_{j}} \big[ v_l^{\text{imp}} (\mathcal{M}_j) - v_l^{\text{imp}} \big]^2
\\
& \text{subject to}
& & \mathcal{M}_1, ..., \mathcal{M}_n \in \overline{\mathcal{M}}
\\
&&& \abs{
\rho_{\boldsymbol{Y}}^{\text{theo}} (i, k, \mathcal{D}) - \rho^{\text{hist}} (i,k)
}
< \epsilon
,
\hspace{10pt}
i \neq k
\end{aligned}
\end{equation*}
As it can be seen, the above problem does not include dependence parameters in the objective function. This might lead to situations where marginal kurtosis are already low, and we prevent calibration from finding a correlation error lower than $\epsilon$, even if we could.
In practice, joint calibration is preferably run only after the, less expensive, 2-step calibration has failed to reach an acceptable correlation fit. In such cases, the trade-off between marginals and correlation should push correlation error to approach $\epsilon$.
Another strategy to deal with the mentioned trade-off is instead to run the usual 2-step calibration, adding a suitable upper bound on $\kappa_j$ to the feasible region $\overline{\mathcal{M}}_j$, $j=1...,n$. This should prevent us to need a joint calibration, whose optimization problem could struggle high dimensions.





%%%%%%%%%
%\subsection{Model-Specific Calibrations}

In BB models, dependence parameters are $\mathcal{D} = (b_1, ..., b_n, \mu_Z, \sigma_Z, \kappa_Z)$, while feasible region is given by

$$
%\footnotesize
\overline{\mathcal{D}} =
\begin{cases}
\{ b_j \in \mathbb{R}, \forall j;\: \mu_Z \in \mathbb{R};\: \sigma_Z>0;\: \kappa_Z>0 \}
\hspace{1pt} \cup \hspace{1pt} (\ref{VG-conv-restrictions-1})
\hspace{1pt} \cup \hspace{1pt} \{ \sigma_j^2 - b_j \sigma_Z^2 >0;\: \kappa_Z - \kappa_j >0, \forall j \}
%\hspace{15pt}
%&
%\text{for VG}
\\
\{ b_j \in \mathbb{R}, \forall j;\: -\gamma_Z < \beta_Z < \gamma_Z;\: \delta_Z>0;\: \gamma_Z>0 \}
\hspace{1pt} \cup \hspace{1pt} (\ref{NIG-conv-restrictions-1})
\hspace{1pt} \cup \hspace{1pt} \{ \delta_j - b_j \delta_Z >0, \forall j \}
%\hspace{15pt}
%&
%\text{for NIG}
\end{cases}
$$
for VG and NIG, respectively.
The first and the third set of constraints ensure that parameters of the systematic and the idiosyncratic components satisfy their domains, while (\ref{VG-conv-restrictions-1}) and (\ref{NIG-conv-restrictions-1}) are needed to meet convolution conditions (\ref{conv-conditions}). \cite{ballotta2016multivariate} observed that such equality constraints are often satisfied only up to a least squares approximation. In practice, dependence calibration can be reformulated as a relaxed problem where (\ref{VG-conv-restrictions-1}) or (\ref{NIG-conv-restrictions-1}) enter the objective function to get


\begin{equation*}
\begin{aligned}
\mathcal{D}^*
=
\hspace{5pt}
& \underset{
\mathcal{D}
}{\text{argmin}}
& & \frac{2}{n (n-1)}
\sum_{i=1}^n
\sum_{j>i}
\big[ \rho_{\boldsymbol{Y}}^{\text{mod}} (i, j, \mathcal{M}^*_i, \mathcal{M}^*_j, \mathcal{D}) - \rho_{\boldsymbol{Y}}^{\text{mkt}} (i,j) \big]^2
+
h \sum_{j=1}^n (c_{j,1}^2 + c_{j,2}^2)
\\
& \text{subj.\ to}
& & \mathcal{D} \in \overline{\mathcal{D}} \setminus (\ref{VG-conv-restrictions-1}), (\ref{NIG-conv-restrictions-1})
%\\
%&&& \mathcal{M}_j \in \mathcal{X}
\end{aligned}
\end{equation*}
where
$$
\begin{cases}
c_{j,1} = \kappa_j \mu_j - \kappa_Z b_j \mu_Z,\: c_{j,2} = \kappa_j \sigma_j^2 - \kappa_Z b_j^2 \sigma_Z^2
&
\text{for VG}
\\
c_{j,1} = \beta_j - b_j^{-1} \beta_Z,\: c_{j,2} = \gamma_j - b_j^{-1} \gamma_Z
&
\text{for NIG}
\end{cases}
$$
and for an arbitrary constant $h>0$. Although a trade-off between marginal and dependence fit is not apparent in BB models, it is still possible to encounter it when we try to meet convolution conditions. For this reason, we suggest the user to employ multiplier $h$ to shift calibration error on one side or the other.
A viable approach can be for example to set a large $h$ and impose a maximum correlation error allowed $\epsilon$, in the spirit of LS joint calibration.
To evaluate convolution errors, we can measure the differences between marginal moments of $Y_j$ and $X_j + b_j Z$, $j=1, ..., n$, or even compare fits of the two processes to market implied volatilities.
As a final consideration, one could even avoid constraints (\ref{VG-conv-restrictions-1}) and (\ref{NIG-conv-restrictions-1}) by setting up the model without imposing the same Lévy class to the convoluted process $\boldsymbol{Y}$. However, this would result in a significantly different approach, outside the scope of this paper.









%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%
\subsection{Optimization Techniques}

We end this section with a short review of algorithms and methods used to perform an efficient and stable calibration, in order to provide the reader with tools to make well-informed decisions depending on problem features.

The aim of calibrating a pricing model is to find a set of model parameters for which prices of liquid instruments computed by the same model corresponds to market prices.
In practice, calibration results to be an \textit{ill-posed} problem, i.e., it can either have no solutions or multiple solutions.
The existence of a solution is de facto guaranteed by defining model calibration as an optimization problem. Taking MSE as error measure, we find model parameters $\mathcal{P}$ that minimize the objective function $f$ as
\begin{equation}\label{min-OF}
    \mathcal{P}^*
    =
    \underset{\mathcal{P}}{\text{argmin}}
    \hspace{3pt}
    f (\mathcal{P})
    :=
    \underset{\mathcal{P}}{\text{argmin}}
    \hspace{3pt}
    \sum_j \omega_j (z_j^{\text{mod}} (\mathcal{P}) - z_j^{\text{mkt}})^2
    \end{equation}
where $z_j^{\text{mod}}$ and $z_j^{\text{mkt}}$ are model and market prices, respectively (or similarly implied volatilities, or implied correlations).
However, due to a limited number of liquid instruments, solution to these problems is not unique. In particular, objective functions are non-convex and could display multiple global minima, meaning that parameters are not able to uniquely identify the model (\cite{cont2010model}). Research then focuses on finding algorithms that could help converging to close-to-optimal solutions (in a feasible amount of time) and tools to improve problem stability.

A natural choice for calibration problems are \textit{stochastic search} algorithms. They do not require convexity nor differentiability of the objective function, making them very flexible, although convergence to the optimum is relatively slow. Examples are Simulated Annealing (\cite{kirkpatrick1983optimization}) and Differential Evolution (\cite{storn1997differential}), while an application to model calibration can be seen, for example, in \cite{cont2004recovering}.
Another technique comprises the \textit{multi-start} approach, consisting of evaluating the objective function on a grid of points of the solution space, and then applying a, usually gradient-based, local optimizer starting from the best point. Their speed and reliability highly depend on the grid choice and the objective function expression, whose gradients could or could not be easy to compute.
Examples are Steepest Descent, Conjugate Gradient and Newton's Method (see \cite{jan2018practical} textbook for a general treatment and \cite{cont2004nonparametric} and \cite{alfeus2020regularization} for model calibration problems).
An alternative to these two would be to use \textit{surrogate} optimization, based on approximating the objective function.
It is particularly useful if evaluating the objective function is computationally heavy, and its reliability depend on the assumption that solution space is smooth enough.
Examples are Gaussian Process Regression and Artificial Neural Networks (see \cite{kochenderfer2019algorithms} textbook for details on the surrogate approach and \cite{ruf2019neural} for a literature review of ANN for pricing models).

%%%%%%%%%%%
A common approach to deal with the non-identifiability of parameters is \textit{regularization}, consisting of adding a convex penalty term to the objective function, to shrink the solution towards some prior guesses.
In particular, the objective function becomes
\begin{equation}\label{OF-Reg}
    f_{\lambda, \mathcal{P}_0} (\mathcal{P})
    =
    f (\mathcal{P}) +
    \lambda
    \cdot
    R (\mathcal{P}, \mathcal{P}_0)
\end{equation}
where $R (\mathcal{P}, \mathcal{P}_0)$ is the regularization function and $\lambda$ is the regularization parameter.
The former can be, for example, a squared distance between the parameter vector and its prior guess,
$
R (\mathcal{P}, \mathcal{P}_0)
=
\sum_i (\mathcal{P}^{(i)} - \mathcal{P}_0^{(i)} )^2
$,
known as Tikhonov regularization (see \cite{tikhonov1963solution} and financial applications e.g., in \cite{egger2005tikhonov}, \cite{crepey2010tikhonov}, \cite{dai2016calibration}, \cite{alfeus2020regularization}).
An alternative regularization term is relative entropy, i.e.,
$
R (\mathcal{P}, \mathcal{P}_0)
=
H ( \mathbb{Q}^{\mathcal{P}} \mid \mathbb{Q}^{\mathcal{P}_0} )
$,
where $\mathbb{Q}^{\mathcal{P}_0}$ is a prior guess of the distribution (see e.g., \cite{cont2004nonparametric} and \cite{cont2006retrieving} for details on the approach).
$\lambda$ regulates instead the trade-off between the desired accuracy of the solution and the regularity of the problem (\cite{crepey2010tikhonov} reports common practices to choose such parameter, based on market data noise).
As far as $\mathcal{P}_0$ is concerned, \cite{cont2004nonparametric} note that it can derive for example from a previous calibration, an historical estimation of the process, our views on the market, or an average between calibrations of different periods (representing then a proxy of long-term values of parameters).












%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%
\section{Worst-Performance Derivatives}\label{Worst Performance Derivatives}

To test the pricing ability of the analyzed models, we consider three exotic derivatives issued by Intesa Sanpaolo bank: \textit{Standard Long Barrier Plus Worst Of Certificates}; \textit{Standard Long Barrier Digital Worst Of Certificates}; \textit{Standard Long Autocallable Barrier Digital Worst Of Certificates with Memory Effect}.
From now on we call them \textit{WP1}, \textit{WP2}, \textit{WP3}, respectively, as their payoffs depend on the \textit{worst performance} (WP) among underlyings. Also, they can be seen as a strategy involving a long position in a coupon bond and a short one in a put option. Payoff details are described in what follows, while a graphical representation of the payoff at maturity can be seen in Fig.\ \ref{fig:WP_payoff}. 


Let $\{t_0, ..., t_m\}$ be a set of relevant contract dates and $\mathbf{S} = (S_1, ..., S_n)$ be a vector of underlying assets, so that $\{\mathbf{S} (t)\}_{t \geq 0}$ represents the joint process of the assets. Let also the performance vector be defined as
$$
\mathbf{P} (t_i) = (P_1(t_i), ..., P_n(t_i)) = \Bigg( \frac{ S_1(t_i) }{ S_1(t_0) } - 1, ..., \frac{S_n(t_i)}{ S_n(t_0)} - 1 \Bigg)
,
\hspace{15pt}
i = 1, ..., m,
$$
with the associated worst-performance assets
$$
w_i = \underset{j \in \{1, ..., n\} }{ \text{argmin}} \{P_j (t_i)\}
,
\hspace{15pt}
i = 1, ..., m
.
$$
Define also the barrier events as
\begin{equation*}
\begin{aligned}
&   
E = \{ S_{w_m}(t_m) < B \}
&&&&
B = b \: S_{w_m}(t_0)
&
\\
&
E_{d,i} = \{ S_{w_i}(t_i) < B_{d,i} \}
&&&&
B_{d,i} = b_{d,i} \: S_{w_i}(t_0)
&&
i = 1, ..., m
\\
&
E_{r,i} = \{ S_{w_i}(t_i) > B_{r,i} \}
&&&&
B_{r,i} = b_{r,i} \: S_{w_i}(t_0)
&&
i = 1, ..., m
\end{aligned}
\end{equation*}
where $b, b_{d,1}, ..., b_{d,m}, b_{r,1}, ..., b_{r,m}$ are percentages.
Calling $I$ the issue price and $k$ the periodic coupon payment, we get WP1 and WP2 payoffs respectively as
\begin{equation*}
\begin{aligned}
&
\Pi_{\text{WP1}} = m k + \pi_m
\\
&
\Pi_{\text{WP2}} = k \sum_{i = 1}^m \mathbbm{1}_{E_{d,i}^c} + \pi_m
\end{aligned}
\end{equation*}
where
$$
\pi_m =
I \: \mathbbm{1}_{E^c}
+
\frac{S_{w_m} (t_m) }{ S_{w_m} (t_0)} I \: \mathbbm{1}_E
,
$$
and the superscript $c$ denotes the complement event.
Note that the payoff presented here assumes we are pricing the derivative at the issue date, while it is often the case we buy it at a future date, loosing some intermediate earnings (e.g., coupons). 

WP3 keeps a similar structure of WP2, but adds \textit{memory effect} and \textit{redemption} features.
The first means that at each date $i$, provided that performance is above the \textit{digital} barrier $B_i^d$, the investor gains the current coupon plus the previous coupons that have not been paid.
The second implies that at the first date in which the event $E_{r,i}$ is verified, if it does happen, the investor receives the issue price and the contract expires. For sake of completeness, we report the algorithm needed to compute WP3 discounted payoff for a single Monte Carlo trajectory in appendix \ref{app:WP3 algorithm}.

\begin{figure}
    \centering
    \includegraphics[width=10cm]{WP_payoff.png}
    \caption{Payoff structure at settlement date of the three WP products, excluding the last coupon and a possible early redemption. $I$ = issue price. $b$ = percentage level to determine the barrier.}
    \label{fig:WP_payoff}
\end{figure}














%%%%%%%%
\section{Empirical Analysis}\label{Empirical Analysis}

The specific WP derivatives used in the analysis have the following characteristics. WP1 is written on EURO STOXX 50 and FTSE MIB indexes, it has been issued in 28/03/2019 and expires in 28/03/2023. WP2 is written on EURO STOXX 50 and FTSE MIB indexes, it has been issued in 30/03/2020 and expires in 30/03/2026. WP3 is written on RWE AG, Électricité de France SA and Iberdrola SA shares, it has been issued in 16/11/2021 and expires in 18/11/2024.
The dataset for marginal calibration consists of implied volatility surfaces of the underlying assets at each end of the month, from 30/11/2021 to 30/11/2022, for a total of $13 \times 7 = 91$ marginal calibrations, applied to both VG and NIG cases.

As jump processes likely display a highly non-convex solution space during calibration (see VG case in \cite{cont2004nonparametric}), using a multi-start algorithm risks to be too dependent on the grid choice. Also, objective function evaluation is not excessively heavy, as it consists, for marginals, of computing a few prices with a Fast Fourier Transform algorithm and their implied volatilities, making it not much necessary to use surrogate optimization (still, ANNs have the benefit of shifting computational burden \textit{off-line}, but for sake of model comparison, it is sufficient to perform less demanding online calibrations).
After these preliminary considerations and some trials, we have decided to calibrate through Differential Evolution algorithm (available in \textit{scipy} Python package), supported by a local optimizer once the optimum has been initially reached by the pure DE. Also, we have found the algorithm to be enough stable to small data perturbations so that regularization is not strictly required, and we further reduce the probability of instabilities by imposing suitable bounds to parameters. Regularization would be still preferred if we were to reprice daily, where market conditions likely suffer small changes, improving both stability and speed of convergence to a suitable parameter vector. As our study involves a few time-distanced calibrations, we focus on calibration accuracy more than stability.

The time required to calibrate each model is nearly identical (except for the joint calibration case), as the heavy part is given by marginal calibration, which is performed in the same way. As market correlation, we use a single one for each pair of assets, implied from a multi-name derivative price, estimated according to beliefs of traders instead of an actively traded instrument, due to lack of liquidity. As model correlation, we note that using an implied correlation or the theoretical correlation leads to comparable exotic price predictions (with respect to market benchmarks), but the latter involves a much faster calibration, so we use it as a proxy of model implied correlation.

Model comparison is undertaken at three levels. We first observe marginal and dependence errors, after calibrating models with suitable methods illustrated in Section \ref{Calibration Methods}. Secondly, we report WP prices computed with LS-VG, LS-NIG, BB-VG, BB-NIG models, and the related market bid quotes (in all cases, prices are expressed as percentage of the issue price).
Ask prices are not available except for a few cases of WP3, where bid-ask spread is often around 1\% but can also reach more than 10\%, remarking a relatively scarce liquidity of these instruments.
%and prices calculated with Dupire local volatility model (\cite{dupire1994pricing}), commonly used by the industry for path-dependent derivatives.
Valuations are carried out with enough sample paths to get negligible Monte Carlo errors. Finally, since parametrization of LS models is able to capture nonlinear dependence, we analyse the related price sensitivity by computing prices for different combinations of dependence parameters, keeping $\rho_{\boldsymbol{Y}}$ constant. As a further analysis, we also show price sensitivity to correlation to remark the importance of a good correlation fit in WP derivatives.
 





%%%%%%%
\subsection{Calibration}

As a first calibration result, we show the minimum, average and maximum of marginal parameters over the 13 valuation dates, in Table \ref{tab:Marginal Parameters}.
As it can be seen, minima and maxima are sometimes similar across underlying assets. This is because we arbitrarily restrict parameters to take values in reasonable ranges.
This is in fact useful to both increase convergence speed of the calibration algorithm and to reduce correlation and convolution errors of the two model classes. Although tightening parameter bounds might seem a strong limitation to marginal fit, it is often the case that non-identifiability of parameters, typical of non-Gaussian Lévy distributions, lets models find different combinations of parameters that produce comparable errors to relaxed-ranges cases. On the other hand, this approach often leads to a significant improvement of calibration accuracy as a whole.
Overall, the variability of parameter values can be traced back to the different asset classes (indexes or stocks), different calibration points, as settlement dates of WPs are quite different among each other, and actual changes in market conditions, well visible in price plots reported in the next subsection.


%%%%
\begin{table}[]
\scriptsize
\centering
\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{3}{|c|}{$\mu$} & \multicolumn{3}{|c|}{$\sigma$} & \multicolumn{3}{|c|}{$\kappa$}
\\
\hline
Underlying & min & mean & max & min & mean & max & min & mean & max
\\
\hline
EURO STOXX 50 &
-0.3062 & -0.1922 & -0.1223 & 0.1665 & 0.203 & 0.2196 & 0.7068 & 1.7768 & 2.997
\\
FTSE MIB (a) &
-0.3326 & -0.2206 & -0.1318 & 0.1669 & 0.2238 & 0.2586 & 0.4452 & 1.562 & 2.9988
\\
EURO STOXX S.D. 30 &
-0.1559 & -0.1484 & -0.1364 & 0.0061 & 0.0628 & 0.1602 & 2.9917 & 2.9986 & 2.9998
\\
FTSE MIB (b) &
-0.1902 & -0.1706 & -0.1504 & 0.0059 & 0.0525 & 0.1866 & 2.997 & 2.9991 & 3.0
\\
ÉLEC.\ DE FRANCE SA &
-1.0136 & -0.2551 & -0.1782 & 0.1204 & 0.2984 & 0.3545 & 0.0865 & 0.6599 & 1.7835
\\
IBERDROLA SA &
-0.1929 & -0.1538 & -0.1299 & 0.1898 & 0.2184 & 0.2457 & 0.8713 & 1.5145 & 2.592
\\
RWE AG &
-0.8346 & -0.1337 & -0.0798 & 0.0055 & 0.3155 & 0.3865 & 0.1194 & 1.874 & 2.9927
\\
\hline
\hline
& \multicolumn{3}{|c|}{$\beta$} & \multicolumn{3}{|c|}{$\delta$} & \multicolumn{3}{|c|}{$\gamma$}
\\
\hline
Underlying & min & mean & max & min & mean & max & min & mean & max
\\
\hline
EURO STOXX 50 &
-4.9999 & -4.7559 & -3.7211 & 0.1 & 0.1594 & 0.2359 & 4.7087 & 6.1767 & 6.6663
\\
FTSE MIB (a) &
-4.9998 & -4.346 & -2.3517 & 0.1013 & 0.1934 & 0.322 & 3.0398 & 5.8379 & 6.6664
\\
EURO STOXX S.D. 30 &
-4.6967 & -4.1135 & -3.6941 & 0.1 & 0.1 & 0.1001 & 4.7693 & 5.2626 & 5.7746
\\
FTSE MIB (b) &
-3.1203 & -2.7794 & -2.1365 & 0.1 & 0.102 & 0.1095 & 2.9566 & 3.6037 & 3.9245
\\
ÉLEC.\ DE FRANCE SA &
-3.335 & -2.2754 & -1.4409 & 0.2406 & 0.3686 & 0.4997 & 2.9628 & 4.4852 & 5.9827
\\
IBERDROLA SA &
-4.9961 & -3.5964 & -2.2539 & 0.1282 & 0.1759 & 0.2221 & 3.4076 & 5.3033 & 6.6655
\\
RWE AG &
-2.7009 & -1.0942 & -0.7129 & 0.1616 & 0.2203 & 0.2812 & 1.6059 & 2.5039 & 3.7091
\\
\hline
\end{tabular}
\caption{VG and NIG marginal parameters of underlying assets. We plot their minimum, average and maximum over the 13 calibration dates.}
\label{tab:Marginal Parameters}
\end{table}



%\subsubsection{Calibration}
Marginal and dependence calibration errors are presented in figures \ref{fig:VG calibration errors} and \ref{fig:NIG calibration errors}.
LS models are normally calibrated with the 2-step approach, which results to be quite fast and give acceptable results in most situations. In the few cases where a huge trade-off between marginals and correlation is observed, we run a joint calibration to better distribute the error over all parameters.
On BB models, we follow two strategies: the first consists of placing a larger weight on satisfying convolution restrictions and leaving correlation at the risk of being inaccurate; the second further sets a bound $\epsilon>0$ on correlation errors. BB-NIG performs better with the first strategy in WP1 and WP2 cases and the second strategy in WP3 case, stressing the impact of different volatility surfaces to the ease of satisfying convolution. BB-VG enjoys a better fit with the second strategy in almost all cases. In particular, it is convenient to set a very low $\epsilon$, e.g., 0.01, since by increasing such threshold, marginal calibration does not improve significantly.

Except the above mentioned suggestion on setting suitable parameter ranges, there is a more specific remark that can be made. That is, correlation average RMSE have comparable impact on exotic price to a marginal average RMSE about ten times lower. For this reason, we keep these ratio of scales in the plots and argue that an acceptable fit is normally obtained if marginal and correlation bars are either of similar height or below 0.02 and 0.2, respectively. In cases where marginal (correlation) errors are particularly low or even disappeared, it means that correlation (marginal) errors could not be reduced without worsening the overall fit.

%%%%
\begin{figure}%[tbp]%[ph]
\centering
\subfloat[Marginal calibration errors of WP1 underlyings.
]{\includegraphics[scale=0.5]{ErrMrg_XS1945967153_VG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP1 underlyings.
]{\includegraphics[scale=0.5]{ErrDep_XS1945967153_VG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP2 underlyings.
]{\includegraphics[scale=0.5]{ErrMrg_XS2115185295_VG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP2 underlyings.
]{\includegraphics[scale=0.5]{ErrDep_XS2115185295_VG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP3 underlyings.
]{\includegraphics[scale=0.5]{ErrMrg_XS2402145127_VG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP3 underlyings.
]{\includegraphics[scale=0.5]{ErrDep_XS2402145127_VG_Rho-inf.png}}
\caption{LS-VG and BB-VG calibration errors for the 13 considered times to maturity. Left-hand side figures represent average RMSEs between model and market volatilities of the basket of underlyings of each WP. Right-hand side figures represent average RMSEs between model and market correlations of the set of underlying pairs of each WP.}
\label{fig:VG calibration errors}
\end{figure}

%%%%
\begin{figure}%[tbp]%[ph]
\centering
\subfloat[Marginal calibration errors of WP1 underlyings.
]{\includegraphics[scale=0.5]{ErrMrg_XS1945967153_NIG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP1 underlyings.
]{\includegraphics[scale=0.5]{ErrDep_XS1945967153_NIG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP2 underlyings.
]{\includegraphics[scale=0.5]{ErrMrg_XS2115185295_NIG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP2 underlyings.
]{\includegraphics[scale=0.5]{ErrDep_XS2115185295_NIG_Rho-inf.png}}
\newline
\subfloat[Marginal calibration errors of WP3 underlyings.
]{\includegraphics[scale=0.5]{ErrMrg_XS2402145127_NIG_Rho-inf.png}}
\hfill
\subfloat[Dependence calibration errors of WP3 underlyings.
]{\includegraphics[scale=0.5]{ErrDep_XS2402145127_NIG_Rho-inf.png}}
\caption{LS-NIG and BB-NIG calibration errors for the 13 considered times to maturity. Left-hand side figures represent average RMSEs between model and market volatilities of the basket of underlyings of each WP. Right-hand side figures represent average RMSEs between model and market correlations of the set of underlying pairs of each WP.}
\label{fig:NIG calibration errors}
\end{figure}








%%%%%
\subsection{Pricing and Sensitivities}

Prices and percentage differences between model and market prices are displayed in Fig.\ \ref{fig:prices}.
Except in WP1 case, we observe a tendency of Lévy models to underestimate bid prices.
This is partly due to model correlation not reaching the market level, leading to a higher put value, and so a lower WP price. Whenever correlation enjoys good fit, the phenomenon does not completely disappear, possibly because of Lévy distributions bearing fatter tails than those assumed by valuation models used to forge benchmark quotes.

In the specific cases, WP1 prices are those where Lévy models are more similar to bid quotes, even with a slight and desirable high bias. This is consistent with the well-known ability of Lévy processes to price short term options, even far from at-the-money positions.
Concerning WP2, price differences are more evident, likely because of the higher time to maturity, that evidences the mentioned fatter-tail effect. 
Regarding WP3, valuation diverges more for all models, possibly due to more irregular and less liquid volatility surfaces (as WP3 underlyings are shares) and the exotic features of the product.
Overall, Lévy models enjoy comparable results among each other.

On a general level, as Lévy processes assume identically distributed increments, it is common to observe a reduced calibration fit when we try to fit models to volatility smiles over multiple maturities together. This is due to the well-known non-stationarity of stock log-returns and is especially evidenced if some of these smiles have medium-long term maturities, as observed by \cite{ballotta2016multivariate}.
As WP2 and WP3 are both path-dependent and evaluated at relatively high maturities, calibrating models for their valuation should produce a poorer fit with respect to WP1 case.
However, as payoff is concentrated at settlement date, it could be convenient to place lower calibration weights on volatilities quoted at intermediate maturities, leading to a better calibration fit on crucial maturities, although intermediate contract payments would be poorly predicted by the calibrated process.
In practice, we observe that exotic quotes are better replicated if we only calibrate on 2-3 nearly-spaced smiles close to settlement date.
As a result, this strategy produces a similar fitting accuracy among the three WP-related calibrations. On the other hand, as expected, some valuation accuracy is lost on WP2 and WP3 prices.

%%%%
\begin{figure}%[tbp]%[ph]
\centering
\subfloat[WP1 prices.
]{\includegraphics[scale=0.5]{Prices_XS1945967153_Rho-inf.png}}
\hfill
\subfloat[WP1 percentage differences.
]{\includegraphics[scale=0.5]{PercDiff_XS1945967153_Rho-inf.png}}
\newline
\subfloat[WP2 prices.
]{\includegraphics[scale=0.5]{Prices_XS2115185295_Rho-inf.png}}
\hfill
\subfloat[WP2 percentage differences.
]{\includegraphics[scale=0.5]{PercDiff_XS2115185295_Rho-inf.png}}
\newline
\subfloat[WP3 prices.
]{\includegraphics[scale=0.5]{Prices_XS2402145127_Rho-inf.png}}
\hfill
\subfloat[WP3 percentage differences.
]{\includegraphics[scale=0.5]{PercDiff_XS2402145127_Rho-inf.png}}
\caption{Prices and percentage differences between model and market prices, on the 13 considered times to maturity. Prices are expressed as percentage of the issue price. Percentage differences are computed as (Price - Market Price) / Market Price $\times$ 100.}
\label{fig:prices}
\end{figure}






%%%%%
%\subsubsection{Sensitivities}

Effects of both linear and nonlinear dependence on price can be observed in figures \ref{fig:correlation-effect} and \ref{fig:nonlinear-dependence-effect}, respectively.
In both cases, we restrict the analysis to WP1 instrument, LS-VG model with fixed marginal distributions $\mu_j=-0.15, \sigma_j=0.25, \kappa_j=1.60, \: j=1,...,n$, representing a common market condition according to Table \ref{tab:Marginal Parameters}.
Concerning correlation, as expected from the payoffs of WPs, price sensitivity increases for higher maturities and when moneyness gets closer to one. Moreover, in all instances, such sensitivity rises for very high correlations (commonly observed in the index market), evidencing a nonlinear effect on price and the importance of using models and calibration methods able to capture wide dependence ranges. On a general level, it is clear from the plots that correlation has a large effect on prices, remarking the need to avoid completely concentrating calibration error on dependence parameters.

Regarding nonlinear dependence, we observe its effect on price for multiple values of parameter $a$, while keeping $\rho_{\boldsymbol{Y}}$ constant. The calculation is repeated for different correlation levels.
As $\rho_{\boldsymbol{Y}}$ increases, the domain of $a$ narrows because we cannot reach large correlations without a high $a$, that in fact controls part of the linear dependence as well.
We observe that for underlying prices far from the barrier, there is a negative relationship between $a$ and prices when $\rho_{\boldsymbol{Y}}$ is very high, while relationship flattens and even become positive as we progress towards lower correlations. As moneyness decreases, we observe a clearer negative dependence for each level of $\rho_{\boldsymbol{Y}}$.
In general, there seems to be little change in price produced by the allowed levels of $a$, although it is clear that nonlinear dependence affects price in some way. On the one hand, this rewards LS models for their ability to capture such dependence. On the other hand, it encourages to try to construct models that can accommodate larger nonlinear dependence ranges.

%%%%
\begin{figure}%[tbp]%[ph]
\centering
\subfloat[Correlation effect on WP1 price for time to maturity 1.0 and moneyness 2.0, 1.6, 1.2.
]{\includegraphics[scale=0.5]{corr_T10.png}}
\hfill
\subfloat[Correlation effect on WP1 price for time to maturity 2.5 and moneyness 2.0, 1.6, 1.2.
]{\includegraphics[scale=0.5]{corr_T25.png}}
\newline
\subfloat[Correlation effect on WP1 price for time to maturity 4.0 and moneyness 2.0, 1.6, 1.2.
]{\includegraphics[scale=0.5]{corr_T40.png}}
\hfill
\subfloat[Correlation effect on WP1 price for time to maturity 4.0 and moneyness 2.0.
]{\includegraphics[scale=0.5]{corr_T40_MN20.png}}
\caption{
Correlation effect on WP1 price, using LS-VG model and fixed marginal distributions $\mu_j=-0.15, \sigma_j=0.25, \kappa_j=1.60, \: j=1,...,n$. In figs.\ (a)-(c), each colored set of points displays percentage differences between prices and the average price (of the same set), as a function of $\rho_{\boldsymbol{Y}}$. Fig.\ (d) shows prices as a function of $\rho_{\boldsymbol{Y}}$ in the realistic case where T=4.0 and MN=2.0, that is where WP1 is valued close to issue date. T = time to maturity. MN = moneyness (initial underlying price divided by strike).
}
\label{fig:correlation-effect}
\end{figure}


%%%%
\begin{figure}%[tbp]%[ph]
\centering
\subfloat[Nonlinear dep.\ effect on WP1 price for moneyness 1.6, correlation 0.6, 0.7, 0.8, 0.9.
]{\includegraphics[scale=0.5]{nonlin_MN16.png}}
\hfill
\subfloat[Nonlinear dep.\ effect on WP1 price for moneyness 1.4, correlation 0.6, 0.7, 0.8, 0.9.
]{\includegraphics[scale=0.5]{nonlin_MN14.png}}
\newline
\subfloat[Nonlinear dep.\ effect on WP1 price for moneyness 1.2, correlation 0.6, 0.7, 0.8, 0.9.
]{\includegraphics[scale=0.5]{nonlin_MN12.png}}
\hfill
\subfloat[Nonlinear dep.\ effect on WP1 price for moneyness 1.2, correlation 0.9.
]{\includegraphics[scale=0.5]{nonlin_MN12_rho09.png}}
\hspace{0.6cm}
\caption{
Nonlinear dependence effect on WP1 price, using LS-VG model and fixed marginal distributions $\mu_j=-0.15, \sigma_j=0.25, \kappa_j=1.60, \: j=1,...,n$.
In figs.\ (a)-(c), each colored set of points displays percentage differences between prices and the average price (of the same set), as a function of $a$. In Fig.\ (d) we plot prices as a function of $a$ for one of the considered instances, where price is relatively sensitive to nonlinear dependence. T = time to maturity. MN = moneyness (initial underlying price divided by strike).
}
\label{fig:nonlinear-dependence-effect}
\end{figure}









%%%%%%
\newpage
\section{Conclusions}\label{Conclusions}

In this paper, we present a variety of multivariate Lévy models. We highlight their features and drawbacks in an empirical test, comparing their ability to fit market data and price exotic derivatives.
We provide tools to decide appropriate models, calibration methods and techniques to employ in a practical context, according to market conditions and the payoff features of the exotic product to be priced.

From the empirical analysis, we observe that although LS and BB model constructions follow different approaches, their calibration performances are driven by analogous issues and produce similar results. 
As a consequence, their capability to replicate exotic quotes is comparable. However, from calibration plots we can observe that in the case of VG, BB performs slightly better, while in NIG we observe the opposite, as a result of the sensitivity of BB construction to the model-specific ease to satisfy convolution conditions.
Sensitivity analysis evidences the strong relation between dependence structure and product payoffs. It also highlights the moderate but nonetheless existent effect of nonlinear dependence on the valuation of actively traded exotic derivatives.
Overall, the empirical findings in this study provide a better understanding of the issues linked to pricing multi-name contracts. Also, this paper points out the connection between model calibration performance and the theoretical aspects of several multivariate Lévy processes.

Future research could investigate models with a more flexible nonlinear dependence structure, to explore its potential on derivative prices.
Another area of study could be to compare LS and BB models in higher dimensions, where presumably BB would struggle to satisfy all the convolution restrictions. In this case, it could be desirable to use an unconstrained version of BB model, where the log-return process is of an unknown class.
Moreover, it would be meaningful to compare versions of LS and BB models that embed Sato margins. Such processes, studied by \cite{marena2018multivariate} and \cite{boen2019building}, allow for non-stationary increments and are thus better suited to value path-dependent contracts.
%However, as these processes keep the same dependence structure of the original versions, a further direction for research could be to empirically assess models that allow for more realistic, time-dependent correlations. While \cite{semeraro2022multivariate} introduces a class of subordinated Brownians with multivariate Sato subordinators that accomplishes this feature, an application to derivative pricing has yet to be developed.
However, as these processes keep the same dependence structure of the original versions, a further direction for research could be to empirically assess models that allow for time-dependent correlations (see e.g., \cite{semeraro2022multivariate}), that are more consistent with market data.






%%% Biblio
\clearpage
%\typeout{}
\bibliographystyle{apalike}
%\bibliographystyle{unsrt}
\bibliography{Biblio}








%%%
\clearpage
\appendix
\section{WP3 Discounted Payoff Algorithm}\label{app:WP3 algorithm}

\begin{algorithm}
\caption{WP3 Discounted Payoff Algorithm}\label{alg:WP3-payoff}
\begin{algorithmic}[1]
\State Initialize discounted payoff: $\Pi \gets 0$
\State Initialize counter: $c \gets 0$
\For{$i = 1,...,m$}
    \State $P_j (t_i) \gets S_j (t_i) / S_l (t_0) - 1$, $\forall j = 1,...,n$
    \State $w_i \gets \underset{j \in \{1, ..., n\} }{ \text{argmin}} \{P_j (t_i)\}$
    \State $B_{d,i} \gets b_{d,i} \: S_{w_i} (t_0)$
    \If{$S_{w_i} (t_i) \geq B_{d,i}$}
        \State $\Pi \gets \Pi + e^{-r t_i} (c+1) k$
        \State $c \gets 0$
    \Else
        \State $c \gets c + 1$
    \EndIf
    \State $B_{r,i} \gets b_{r,i} \: S_{w_i} (t_0)$
    \If{$S_{w_i} (t_i) \geq B_{r,i}$}
        \State $\Pi \gets \Pi + e^{-r t_i} I$
        \State \Return $\Pi$
        %and go directly to step \ref{end0}.
    \EndIf
\EndFor
\State $P_j (t_m) \gets S_l (t_m) / S_j (t_0) - 1$, $\forall j = 1,...,n$
\State $w_N \gets \underset{j \in \{1, ..., n\} }{ \text{argmin}} \{P_j (t_N)\}$
\State $B = b \: S_{w_m} (t_0)$

\If{$S_{w_m} (t_m) \geq B$}
    \State $\Pi \gets \Pi + e^{-r t_m} I$
\Else
    \State $\Pi \gets \Pi + e^{-r t_m} \frac{S_w (t_m) }{ S_w (t_0)} I$
\EndIf
\State \Return $\Pi$
%\State Store $\Pi$ \label{end0}
\end{algorithmic}
\end{algorithm}




\end{document}