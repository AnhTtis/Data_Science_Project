\section{Related Work}

In this section, we provide a brief introduction to continual and lifelong learning and summarize previous methods for domain adaptation of learning-based visual odometry.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\parskip=5pt
\noindent\textit{Continual Learning:}
Deep learning-based models are commonly trained for a specific task, which is defined a priori, using a fixed set of training data. During inference, the model is then employed on previously unseen data from the same domain without further updates of the network weights. However, in many real-world scenarios, this assumption does not hold true, \eg, the initially used training data might not well represent the data seen during inference, thus leading to a domain gap and suboptimal performance. Additionally, the objective of the task can change over time.
Continual learning (CL) and lifelong learning~\cite{thrun1995is} aim to overcome these challenges by enabling a method to continually learn additional tasks given new training data. In contrast to vanilla domain adaptation~\cite{besic2022unsupervised}, CL methods should maintain the capability to solve previously learned tasks, \ie, avoiding catastrophic forgetting. Ideally, learning a task also yields improved performance on previous tasks (\textit{positive backward transfer}) as well as on yet unknown future tasks (\textit{positive forward transfer})~\cite{lopez2017gradient}.
The majority of CL approaches can be categorized into three strategies. First, experience replay directly tackles catastrophic forgetting from a data-driven perspective. For instance, both CoMoDA~\cite{kuznietsov2021comoda} and CL-SLAM~\cite{voedisch2023continual} store images in a replay buffer and combine online data with replay samples when updating the network weights. Second, regularization techniques such as knowledge distillation~\cite{valverde2021there} preserve information on a more abstract feature level. Finally, architectural methods prevent forgetting by using certain network structures, \eg, LSTMs~\cite{li2020self} and dual-network architectures~\cite{voedisch2023continual}, or by directly freezing internal model parameters.
Online continual learning~\cite{lunayach2022lifelong, wang2021wanderlust} describes an extension of CL by considering a setting, where the model is continuously updated on a stream of data during inference time. Online CL also includes scenarios, which gradually change from one domain to another~\cite{taufique2022unsupervised}.
In this work, we employ online CL with experience replay for learning-based visual-inertial odometry estimation.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/overview.pdf}
    % \vspace*{-.5cm}
    \caption{Our proposed \net performs online continual learning on a stream of RGB images leveraging unsupervised monocular depth estimation as an auxiliary task. In each update step, the image triplet consisting of the current and the two previous frames is combined with samples from a replay buffer and then fed to the networks to update their weights via backpropagation. The estimated camera motion between the previous and the current image corresponds to the generated VO output. The replay buffer is optionally updated if the current frame is sufficiently different from the existing content.}
    \label{fig:overview}
    % \vspace*{-.3cm}
\end{figure*}

{\parskip=5pt
\noindent\textit{Adaptive Visual Odometry:}
Online adaptation of learning-based visual odometry (VO) and simultaneous localization and mapping (SLAM) aims to enhance performance on the fly allowing robotic systems to operate more reliably in previously unseen environments.
Most commonly, learning-based VO relies on monocular depth estimation as an auxiliary task enabling joint training of a DepthNet and a PoseNet in an unsupervised manner~\cite{godard2019digging}.
In an early work on adaptive VO,  Luo~\etal~\cite{luo2019real} accumulate images from an online camera stream and leverage the unsupervised training scheme to update both networks. Different to experience replay in CL, the buffer of accumulated images is emptied after the update step, \ie, each sample is only seen once.
Li~\etal~\cite{li2020self} propose an architectural CL technique, replacing the standard convolutional layers with LSTM variants to prevent forgetting. During deployment, the networks are continuously trained using only the online data. In a follow-up work by the same authors~\cite{li2021generalizing}, the PoseNet is substituted with optical flow-based point matching.
Similarly, GeoRefine~\cite{ji2022georefine} combines online depth refinement with dense visual mapping. While the DepthNet is updated following the aforementioned works, GeoRefine uses a non-adaptive odometry and tracking module based on optical flow.
Loo~\etal~\cite{loo2021online} propose an adaptive visual SLAM system that combines experience replay with a variant of elastic weight consolidation (EWC) to further regularize the weight updates of both the DepthNet and the PoseNet.
Finally, to avoid catastrophic forgetting in a multi-domain adaptation setting, \mbox{CL-SLAM}~\cite{voedisch2023continual} exploits a dual-network architecture, which is composed of an expert to perform effective online adaptation to the new domain and a generalizer to retain previously acquired knowledge by leveraging experience replay.
In this work, we propose an adaptive method for visual-inertial odometry built on \mbox{CL-SLAM} that explicitly addresses its shortcomings as outlined in \cref{sec:introduction}.
}
