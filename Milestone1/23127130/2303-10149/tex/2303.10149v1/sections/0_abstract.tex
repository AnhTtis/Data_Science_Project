Visual odometry is a fundamental task for many applications on mobile devices and robotic platforms. Since such applications are oftentimes not limited to predefined target domains and learning-based vision systems are known to generalize poorly to unseen environments, methods for continual adaptation during inference time are of significant interest.
In this work, we introduce \net for online continual learning of visual-inertial odometry. \net effectively adapts to new domains while mitigating catastrophic forgetting by exploiting experience replay. In particular, we propose a novel sampling strategy to maximize image diversity in a fixed-size replay buffer that targets the limited storage capacity of embedded devices. We further provide an asynchronous version that decouples the odometry estimation from the network weight update step enabling continuous inference in real time.
We extensively evaluate \net on various real-world datasets demonstrating that it successfully adapts to new domains while outperforming previous methods.
The code of our work is publicly available at \mbox{\small \url{http://continual-slam.cs.uni-freiburg.de}}.
