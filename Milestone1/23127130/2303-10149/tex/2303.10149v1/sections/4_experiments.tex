\section{Experimental Evaluation}

In this section, we present extensive experimental results on the efficiency and efficacy of our proposed \net, compared to previous works. We further conduct multiple ablation studies to demonstrate the effect of newly introduced hyperparameters and to justify certain design choices.

Throughout all experiments, we report the translation error $t_\mathit{err}$ (in \%) and the rotation error $r_\mathit{err}$ (in \degree/m) as proposed by Geiger~\etal~\cite{geiger2012are}. These metrics evaluate the error as a function of the trajectory length. To ensure a fair comparison with the base work CL-SLAM~\cite{voedisch2023continual}, we further utilize the set of network weights that is provided by the authors and was pretrained on the Cityscapes Dataset~\cite{cordts2016the}. We also follow CL-SLAM and only consider new frames when the IMU measures a driven distance of at least \SI{0.2}{\meter}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Datasets}

We employ our method on various datasets simulating a diverse set of environments. In particular, we initialize \net with network weights trained on Cityscapes~\cite{cordts2016the} and perform online continual learning on sequences from the KITTI odometry benchmark~\cite{geiger2012are}, the Oxford RobotCar Dataset~\cite{maddern2017the}, and in-house data.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\parskip=3pt
\noindent\textit{Cityscapes:}
The Cityscapes Dataset~\cite{cordts2016the} is a large-scale autonomous driving dataset that contains RGB images and vehicle metadata such as velocity. It was recorded in 50 cities in Germany, France, and Switzerland. In this work, we use network weights pretrained on Cityscapes that are provided by Vödisch~\etal~\cite{voedisch2023continual}.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\parskip=3pt
\noindent\textit{KITTI:}
The KITTI Dataset~\cite{geiger2012are} is a pioneering autonomous driving dataset that was recorded in Karlsruhe, Germany. For continual learning of new domains, we use images and ground truth poses of multiple sequences from the odometry benchmark and combine them with the respective IMU data from the raw dataset.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\parskip=3pt
\noindent\textit{Oxford RobotCar:}
The Oxford RobotCar Dataset~\cite{maddern2017the} provides multiple recordings of the same route that were captured across one year. We use the included RGB images and the IMU data. To compute the error metrics, we exploit the separately released RTK ground truth positions~\cite{maddern2020real}.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\parskip=3pt
\noindent\textit{In-House:}
Finally, we employ \net on an in-house dataset recorded in Freiburg, Germany. Our robotic platform includes forward-facing RGB cameras and an inertial navigation system (INS), that we use to compute the velocity supervision loss.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Evaluation of Online Continual Learning}

In this section, we conduct a series of experiments including both simple online domain adaptation from a source~$\mathcal{S}$ to a target domain $\mathcal{T}$ and online continual learning from $\mathcal{S}$ to a sequence of target domains $\{ \mathcal{T}_1, \mathcal{T}_2, \dots \}$. Based on the ablation studies in \cref{ssec:ablation-studies}, we use a replay buffer size of $|\mathbf{B}| = 100$, an update batch size of $|\mathbf{b}_t|=3$, and $c = 5$ backpropagation steps allowing a fair comparison with the base work CL-SLAM~\cite{voedisch2023continual}. We set a similarity threshold of $\theta_\mathit{th} = 0.95$ for the diversity-based update scheme of the replay buffer. For the loss weights, we follow CL-SLAM and use $\gamma = 0.001$ and $\lambda = 0.05$. To compare with other methods, we do not use the asynchronous version but the same learning scheme as in CL-SLAM.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}
    \centering
    \captionsetup[subfigure]{justification=centering, font=small}
    \subfloat[Seq. 04]{%
        \includegraphics[width=.20\linewidth]{figures/kitti_04.pdf}}
    \hfill
    \subfloat[Seq. 05]{%
        \includegraphics[width=.20\linewidth]{figures/kitti_05.pdf}}
    \hfill
    \subfloat[Seq. 06]{%
        \includegraphics[width=.20\linewidth]{figures/kitti_06.pdf}}
    \hfill
    \subfloat[Seq. 07]{%
        \includegraphics[width=.20\linewidth]{figures/kitti_07.pdf}}
    \hfill
    \subfloat[Seq. 10]{%
        \includegraphics[width=.20\linewidth]{figures/kitti_10.pdf}}
    \hfill
    \vspace{0.1cm}
    \includegraphics[width=.25\linewidth]{figures/kitti_legend.pdf}
    \vspace{-0.1cm}
    \caption{Online continual learning results on the KITTI odometry benchmark after pretraining on the Cityscapes dataset.}
    \label{fig:results-kitti}
    % \vspace*{-.3cm}
\end{figure*}

\begin{table*}
\footnotesize
\centering
\caption{Comparison of continual odometry estimation on the KITTI odometry benchmark.}
\label{tab:results-baselines}
\setlength\tabcolsep{11pt}
\begin{threeparttable}
    \begin{tabular}{ l | cc | cc | cc | cc | cc }
         \toprule
         \multirow{2}{*}{Method} & \multicolumn{2}{c|}{Seq. 04} & \multicolumn{2}{c|}{Seq. 05} & \multicolumn{2}{c|}{Seq. 06} & \multicolumn{2}{c|}{Seq. 07} & \multicolumn{2}{c}{Seq. 10} \\
         & t\textsubscript{err} & r\textsubscript{err} & t\textsubscript{err} & r\textsubscript{err} & t\textsubscript{err} & r\textsubscript{err} & t\textsubscript{err} & r\textsubscript{err} & t\textsubscript{err} & r\textsubscript{err} \\
         \midrule
         ORB-SLAM~\cite{murartal2015orbslam} & 0.62 & 0.11 & 2.51 & 0.25 & 7.80 & 0.35 & 1.53 & 0.35 & 2.96 & 0.52 \\
         \midrule
         Only target & 10.72 & 1.69 & 34.55 & 11.88 & 15.20 & 5.62 & 12.77 & 6.80 & 55.27 & 9.50 \\
         DeepSLAM~\cite{li2021deepslam} & 5.22 & 2.27 & \underline{4.04} & 1.40 & 5.99 & 1.54 & 4.88 & 2.14 & \underline{10.77} & 4.45 \\
         \midrule
         Only source & 28.94 & 4.64 & 46.13 & 19.20 & 49.57 & 20.79 & 37.75 & 25.42 & 30.91 & 15.28 \\
         CL-SLAM~\cite{voedisch2023continual} & \underline{4.37} & \textbf{0.51} & 4.30 & \underline{1.01} & \underline{2.53} & \underline{0.63} & \textbf{2.10} & \textbf{0.83} & 11.18 & \underline{1.74} \\
         \net \textit{(ours)} & \textbf{2.11} & \underline{0.53} & \textbf{2.88} & \textbf{0.94} & \textbf{2.13} & \textbf{0.47} & \underline{3.19} & \underline{1.26} & \textbf{3.71} & \textbf{1.55} \\
         \bottomrule
    \end{tabular}
    Comparison of the translation and rotation errors of our \net with baseline methods evaluated on the KITTI odometry benchmark. ``Only target'' and DeepSLAM are trained on sequences \{00, 01, 02, 08, 09\} without further adaptation. ``Only source'', CL-SLAM, and \net are trained on Cityscapes. Both CL-SLAM and \net perform online adaptation on the respective KITTI sequence. 
    The values of CL-SLAM and ``only target'' are reported by Vödisch~\etal~\cite{voedisch2023continual}.
    The errors of the paths predicted by ORB-SLAM are based on ground truth scaling and hence not directly comparable to the other methods.
    The smallest and second smallest errors across the methods producing metric predictions are shown in \textbf{bold} and \underline{underlined}.
\end{threeparttable}
\end{table*}

\subsubsection{Cityscapes to KITTI}
We use our proposed \net to perform online continual adaptation from Cityscapes to KITTI and compare its performance to other methods shown in \cref{tab:results-baselines}. In detail, we compare with the traditional ORB-SLAM~\cite{murartal2015orbslam} as well as the following learning-based methods: ``Only target'' and DeepSLAM~\cite{li2021deepslam} are trained on the KITTI sequences \{00, 01, 02, 08, 09\} without further adaptation; ``only source'', CL-SLAM~\cite{voedisch2023continual}, and \net are trained on Cityscapes with online adaptation to KITTI for both \mbox{CL-SLAM} and \net. Generally, the difference between ``only source'' and ``only target'' demonstrates the domain gap that online adaptation aims to overcome. Our proposed \net outperforms the base method CL-SLAM on the majority of sequences and also improves performance compared to offline training on the target domain. We visualize the predicted and ground truth odometry in \cref{fig:results-kitti}. Note that, unlike CL-SLAM and DeepSLAM, we do not include loop closures in \net.

We further perform online continual learning on all sequences in a sequential manner, \ie, after pretraining on Cityscapes, adapt to sequence 04, then sequence 05, etc., and list the results in \cref{tab:results-continual-learning}. In particular, we compute the translation and rotation errors after each step on all sequences to determine both forward and backward transfer, \ie, the effect on previous and yet unseen future sequences. Since all the sequences of a dataset could be considered to represent similar domains, \eg, the same camera parameters and comparable environments, we observe a general trend of positive forward transfer. Although the performance on previous sequences cannot be fully retained, \net successfully mitigates catastrophic forgetting compared to the initial performance after pretraining on the source domain.



\begin{table*}
\footnotesize
\centering
\caption{Continual odometry estimation results on the KITTI odometry benchmark.}
% \vspace{-0.2cm}
\label{tab:results-continual-learning}
% \setlength\tabcolsep{2.7pt}
\begin{threeparttable}
    \begin{tabular}{ c c | cc | cc | cc | cc | cc | cc }
        \toprule
        Sequence & Images & t\textsubscript{err} & r\textsubscript{err} & t\textsubscript{err} & r\textsubscript{err} & t\textsubscript{err} & r\textsubscript{err} & t\textsubscript{err} & r\textsubscript{err} & t\textsubscript{err} & r\textsubscript{err} & t\textsubscript{err} & r\textsubscript{err} \\
        \midrule
        & & \multicolumn{12}{c}{Cityscapes $\xrightarrow{\hspace*{0.8cm}}$ Seq. 04 $\xrightarrow{\hspace*{0.8cm}}$ Seq. 05 $\xrightarrow{\hspace*{0.8cm}}$ Seq. 06 $\xrightarrow{\hspace*{0.8cm}}$ Seq. 07 $\xrightarrow{\hspace*{0.8cm}}$ Seq. 10} \\
        & \\[-1.5ex]
        Seq. 04 & 269 & 28.94 &  4.64 & \cellcolor{Gray}2.11 & \cellcolor{Gray}0.53 &  7.66 &  7.05 &  8.21 &  1.48 &  7.88 &  3.41 &  9.80 & 3.82 \\
        Seq. 05 & 2676 & 46.13 & 19.20 & 59.51 & 16.99 & \cellcolor{Gray}2.85 & \cellcolor{Gray}1.05 &  8.49 &  3.77 &  6.84 &  3.64 & 13.73 & 5.36 \\
        Seq. 06 & 1099 & 49.57 & 20.79 & 65.39 & 22.33 & 20.01 & 10.83 & \cellcolor{Gray}3.08 & \cellcolor{Gray}1.16 &  7.77 &  4.25 &  5.76 & 1.92 \\
        Seq. 07 & 993 & 37.75 & 25.42 & 67.67 & 29.85 &  7.26 &  4.93 &  7.13 &  3.38 & \cellcolor{Gray}6.05 & \cellcolor{Gray}3.53 &  9.60 & 5.33 \\
        Seq. 10 & 1127 & 30.91 & 15.28 & 35.37 & 10.18 & 11.13 &  9.48 &  5.08 &  2.47 & 17.53 &  7.73 & \cellcolor{Gray}2.65 & \cellcolor{Gray}1.15 \\
        \bottomrule
    \end{tabular}
    We continually employ \net on five KITTI sequences after initialization on Cityscapes. The number of images corresponds to the number of update batches of a sequence. The cells highlighted in gray denote the results of the current adaptation step. Along one row, we can measure forward and backward transfer.
\end{threeparttable}
\end{table*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Cityscapes to In-House Data}
Next, we utilize \net to estimate visual odometry on an in-house dataset, after pretraining on Cityscapes. In \cref{fig:results-inhouse}, we provide a qualitative comparison of \net to CL-SLAM~\cite{voedisch2023continual} with disabled loop closure detection, no online adaptation, and the measured GNSS position. Since we do not have access to highly accurate RTK readings, we omit computing error metrics for this dataset. However, as demonstrated in \cref{fig:results-inhouse}, \net is able to maintain accurate odometry tracking for a longer distance than CL-SLAM.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/freiburg.pdf}
    % \vspace*{-.5cm}
    \caption{Continual odometry estimation results on in-house data.}
    \label{fig:results-inhouse}
    \vspace*{-.5cm}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Cityscapes to KITTI and RobotCar}
We further investigate the capability of \net to retain knowledge in a multi-target setting. In detail, we perform the same experiment as conducted by CL-SLAM~\cite{voedisch2023continual}. After initialization on Cityscapes, we sequentially deploy \net to KITTI sequence 09, a sequence from RobotCar, KITTI sequence 10, and another sequence from RobotCar. For further details on the RobotCar sequences, we refer the reader to \cite{voedisch2023continual}. In \cref{tab:adaptation-retention-quality}, we report the adaptation quality (AQ) and the retention quality (RQ) as introduced by Vödisch~\etal~\cite{voedisch2023continual}. Broadly, the AQ score measures the ability of a method to adapt to a previously unseen environment, whereas the RQ measures the ability to retain long-term knowledge when being redeployed to a previously seen domain. Compared to CL-SLAM, \net improves the AQ score and, with a high margin, the RQ with respect to the translation error. Although RQ\textsubscript{rot} suffers from a small decrease, the absolute rotation errors on the four considered sequences are smaller than those of CL-SLAM, hence smaller differences between with and without an intermediate domain influence the RQ more strongly.

\begin{table}
\footnotesize
\centering
\caption{Comparison of adaptation and retention quality.}
\label{tab:adaptation-retention-quality}
\setlength\tabcolsep{4pt}
\begin{threeparttable}
    \begin{tabular}{ cc | cc cc }
        \toprule
        Previous & Current & \multicolumn{2}{c}{CL-SLAM~\cite{voedisch2023continual}} & \multicolumn{2}{c}{\net \textit{(ours)}} \\
        sequences & sequence & t\textsubscript{err} & r\textsubscript{err} & t\textsubscript{err} & r\textsubscript{err} \\
        \midrule
        $c_t$ & $k_9$ & \textbf{2.50} & \textbf{0.37} & 3.89 & 1.49 \\
        $c_t$ & $r_1$ & 28.94 & 5.63 & \textbf{6.62} & \textbf{2.61} \\
        $c_t \shortto r_1$ & $k_9$ & \textbf{3.24} & \textbf{0.54} & 4.09 & 1.18 \\
        $c_t \shortto k_9$ & $r_1$ & 30.13 & 5.87 & \textbf{11.00} & \textbf{3.44} \\
        \midrule
        \multicolumn{2}{c|}{$\Rightarrow$ AQ\textsubscript{trans} / AQ\textsubscript{rot}} & 0.85 & 0.98 & \textbf{0.94} & \textbf{0.99} \\
        \midrule
        \midrule
        $c_t \shortto k_9 \shortto r_1$ & $k_{10}$ & 4.85 & 1.59 & \textbf{1.86} & \textbf{0.70} \\
        $c_t \shortto k_9 \shortto r_1 \shortto k_{10}$ & $r_2$ & 20.50 & 4.77 & \textbf{5.66} & \textbf{3.99} \\
        $c_t \shortto k_9$ & $k_{10}$ & 7.48 & 1.63 & \textbf{1.43} & \textbf{0.73} \\
        $c_t \shortto k_9 \shortto r_1$ & $r_2$ & 16.41 & 4.58 & \textbf{7.67} & \textbf{3.42} \\
        \midrule
        \multicolumn{2}{c|}{$\Rightarrow$ RQ\textsubscript{trans} / RQ\textsubscript{rot} $\times 10^{-3}$} & -7.30 & \textbf{-0.42} & \textbf{7.89} & -1.53 \\
        \bottomrule
    \end{tabular}
    Adaptation quality (AQ) and retention quality (RQ)~\cite{voedisch2023continual} with respect to the translation and rotation errors.
    $c_t$ denotes the Cityscapes training set, $k_9$ and $k_{10}$ refer to sequences 09 and 10 of the KITTI odometry benchmark, and $r_1$ and $r_2$ correspond to sequences~\cite{voedisch2023continual} from RobotCar.
    The values of CL-SLAM are reported by the authors.
    The best scores in each category are shown in \textbf{bold}.
\end{threeparttable}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Ablation studies

\subsection{Ablation Study}
\label{ssec:ablation-studies}

In this section, we present the results of various ablation studies substantiating the design choices for the sizes of the update batch $\mathbf{b}_t$ and the replay buffer $\mathbf{B}$. We further demonstrate that \net is less sensitive to the number of backpropagation steps per update batch than a previous method. In the following studies, we always report the translation and rotation errors of sequences 04 and 06.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Size of the Update Batch}
We first investigate the effect of varying sizes of the update batch, \ie, the number of replay samples. In \cref{tab:ablation-batch-size}, we list the errors for batch sizes $\mathbf{b}_t = \{ 1, 2, 3, 4, 5 \}$ given an unlimited replay buffer. Note that $\mathbf{b} = 1$ implies that experience replay is disabled. Therefore, this strategy corresponds to CL-SLAM~\cite{voedisch2023continual} for source-to-target domain adaptation. Generally, the translation error can be reduced by using replay data, whereas the rotation error is the smallest when only training with the current sample. As we deem the translation error more important in terms of mapping and localization accuracy, we select $\mathbf{b} = 3$.

\begin{table}[t]
\footnotesize
\centering
\caption{Ablation study on the size of the update batch.}
\label{tab:ablation-batch-size}
\setlength\tabcolsep{9pt}
\begin{threeparttable}
    \begin{tabular}{c | cc | cc }
        \toprule
        \multirow{2}{*}{Batch size} & \multicolumn{2}{c|}{Seq. 04} & \multicolumn{2}{c}{Seq. 06} \\
        & t\textsubscript{err} & r\textsubscript{err} & t\textsubscript{err} & r\textsubscript{err} \\
        \midrule
        1 & 3.56 & \textbf{0.15} & 2.30 & \textbf{0.18} \\
        2 & 2.97 & 0.59 & \textbf{1.81} & \underline{0.50} \\
        \rowcolor{Gray}
        3 & \textbf{2.79} & \underline{0.54} & \underline{1.98} & 0.59 \\
        4 & \underline{2.89} & 0.73 & 1.99 & 0.54 \\
        5 & \underline{2.89} & 0.63 & 2.46 & 0.70 \\
        \bottomrule
    \end{tabular}
    In this study, we use a replay buffer of infinite size.
    Batch sizes greater than 1 imply using replay data in addition to the online image, \ie, the first row corresponds to the strategy of CL-SLAM.
    The smallest and second smallest errors are shown in \textbf{bold} and \underline{underlined}, respectively.
\end{threeparttable}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Size of the Replay Buffer}
In the next study, we restrict the size of the replay buffer to address both scalability of the method and the limited storage capacity on mobile devices and robotic platforms. In detail, we report the error for buffer sizes $|\mathbf{B}| = \{ 10, 25, 50, 100, \infty \}$ in \cref{tab:ablation-buffer-size}. For all the buffers of limited size, we both enable and disable our proposed diversity-based updating mechanism. Interestingly, the positive effect of enforcing a high diversity is more pronounced for sequence 04, where \net generally yields smaller translation errors with fewer samples in the buffer. It should further be noted that due to the length of the sequences, the diversity-based buffer contains the same samples for $|\mathbf{B}_\text{Seq. 04}| = \{ 25, 50, 100\}$ and $|\text{B}_\text{Seq. 06}| = \{ 50, 100\}$. For \net, we select $|\mathbf{B}| = 100$ to account for the increased storage requirements in a multi-target setting.

\begin{table}
\footnotesize
\centering
\caption{Ablation study on the size of replay buffer.}
\label{tab:ablation-buffer-size}
% \setlength\tabcolsep{3.7pt}
\begin{threeparttable}
    \begin{tabular}{ c | c | cc | cc }
        \toprule
        Buffer & Diversity & \multicolumn{2}{c|}{Seq. 04} & \multicolumn{2}{c}{Seq. 06} \\
        size & update & t\textsubscript{err} & r\textsubscript{err} & t\textsubscript{err} & r\textsubscript{err} \\
        \midrule
        $\infty$ &   & 2.79 & 0.54 & 1.98 & 0.59 \\
        \midrule
        100 &        & 2.62 & 0.52 & \textbf{1.75} & \underline{0.48} \\
        \rowcolor{Gray}
        100 & \cmark & \textbf{2.11} & 0.53 & 2.13 & \textbf{0.47} \\
        50 &         & 2.64 & 0.42 & 2.72 & 0.91 \\
        50 & \cmark  & \textbf{2.11} & 0.53 & 2.13 & \textbf{0.47} \\
        25 &         & 2.51 & \underline{0.40} & 2.42 & 0.77 \\
        25 & \cmark  & \textbf{2.11} & 0.53 & 2.20 & 0.50 \\
        10 &         & 2.82 & \textbf{0.33} & \underline{2.08} & 0.64 \\
        10 & \cmark  & \underline{2.12} & 0.56 & 2.21 & 0.59 \\
        \bottomrule
    \end{tabular}
    In this study, we use a batch size of 3.
    The effectively used buffer size of sequence 04 is the same for 25, 50, and 100. Similarly, in sequence 06 the same number of samples is added when buffer sizes of 50 and 100 are available.
    The first row corresponds to the strategy of CL-SLAM.
    The smallest and second smallest errors are shown in \textbf{bold} and \underline{underlined}, respectively.
\end{threeparttable}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table}
\footnotesize
\centering
\caption{Ablation study on the number of update cycles.}
\label{tab:ablation-update-cycles}
\setlength\tabcolsep{9.5pt}
\begin{threeparttable}
    \begin{tabular}{ c | cc | cc }
        \toprule
        \multirow{2}{*}{Update cycles} & \multicolumn{2}{c|}{Seq. 04} & \multicolumn{2}{c}{Seq. 06} \\
        & t\textsubscript{err} & r\textsubscript{err} & t\textsubscript{err} & r\textsubscript{err} \\
        \midrule
        1 & 3.13 & 1.65 & 4.07 & 1.14 \\
        2 & 2.80 & 1.06 & 2.62 & 0.64 \\
        3 & 2.49 & 0.77 & 2.61 & 0.63 \\
        4 & 2.29 & 0.61 & 2.31 & 0.52 \\
        \rowcolor{Gray}
        5 & \underline{2.11} & \underline{0.53} & \textbf{2.13} & \textbf{0.47} \\
        6 & \textbf{1.98} & \textbf{0.50} & \underline{2.15} & \underline{0.49} \\
        \bottomrule
    \end{tabular}
    For a fair comparison, we use the same number of update cycles $c=5$ as CL-SLAM~\cite{voedisch2023continual}.
    The smallest and second smallest errors are shown in \textbf{bold} and \underline{underlined}, respectively.
\end{threeparttable}
\end{table}

\subsubsection{Number of Update Cycles}
Lastly, we report the sensitivity of \net with respect to the number of backpropagation steps $c$ for a single update batch. As shown in \cref{tab:ablation-update-cycles}, more steps decrease both the errors confirming the results of CL-SLAM~\cite{voedisch2023continual}. However, in contrast to the performance reported for CL-SLAM, \net is noticeably less sensitive and already yields relatively small errors for $c = 1$. We conclude that this is caused by using experience replay also for the online learner. To enable direct comparison with CL-SLAM, we use the same value $c = 5$.
