
\section{Related Work}
\label{sec_2}


\textbf{Diffusion models (DMs)}.\
In the past few years, denoising diffusion probabilistic models~\cite{ho2020denoising,sohl2015deep} and score-based Langevin dynamics~\cite{song2019generative,song2020improved} have shown great promise in image generation.
Song \etal~\cite{song2021score} unify these two generative learning approaches, also known as DMs, through the lens of stochastic differential equations. Later, much progress has been made such as speeding up sampling~\cite{lu2022dpm,song2021denoising}, optimizing model parametrization and noise schedules~\cite{Karras2022edm,kingma2021variational}, and applications in text-to-image generation~\cite{ramesh2022hierarchical,rombach2022high}.
After the release of Stable Diffusion to the public~\cite{rombach2022high}, personalization techniques for DMs are proposed by finetuning the embedding space~\cite{gal2022texture_inversion} or the full model~\cite{ruiz2022dreambooth}.

\textbf{Watermarking discriminative models}.\
For decades, watermarking technology has been utilized to protect or identify multimedia contents~\cite{cox2002digital,podilchuk2001digital}. Due to the expensive training and data collection procedures, large-scale machine learning models (\eg, deep neural networks) are regarded as new intellectual properties in recent years~\cite{brown2020language,rombach2022high}. To claim copyright and make them detectable, numerous watermarking techniques are proposed for deep neutral networks~\cite{li2021survey}.
% large-scale machine learning models (especially deep neural networks), which are considered new intellectual properties.
% as their training process can be time-consuming and expensive.
Several methods attempt to embed watermarks directly into model parameters~\cite{chen2019deepmarks,cortinas2020adam,fan2019rethinking,li2021spread,tartaglione2021delving,uchida2017embedding,wang2020watermarking,wang2019robust}, but require white-box access to inspect the watermarks.
Another category of watermarking techniques uses predefined inputs as triggers during training~\cite{adi2018turning,chen2019blackmarks,darvish2019deepsigns,guo2018watermarking,guo2019evolutionary,jia2021entangled,kwon2022blindnet,le2020adversarial,li2019persistent,li2019prove,lukas2019deep,namba2019robust,szyller2021dawn,tekgul2021waffle,wu2020watermarking,zhang2018protecting,zhao2021watermarking}, thereby eliciting unusual predictions that can be used to identify models (\eg, illegitimately stolen instances) in black-box scenarios.


% thereby evoking unusual predictions that can be used to identify the models (\eg, illegitimate stolen instances) in black-box scenarios.
% Similar techniques can also backdooring~\cite{adi2018turning,li2022backdoor}, where the triggers are adversarially injected for malicious purpose.


\textbf{Watermarking generative models}.\
In contrast to discriminative models, generative models contain internal randomness and sometimes require no input (\ie, unconditional generation), making watermarking more challenging. Several methods investigate GANs by watermarking all generated images~\cite{fei2022supervised,ong2021protecting,yu2021artificial_finger}.
For example, Yu \etal~\cite{yu2021artificial_finger} propose embedding binary strings within training images using a watermark encoder before training GANs. Similar techniques have not, however, been examined on DMs, which contain multiple stochastic steps and exhibit greater diversity.
% Recently, watermarking large language model (\eg, ChatGPT) has attracted ~\cite{kirchenbauer2023watermark,mitchell2023detectgpt}.