

\section{Preliminary}
\label{sec_3}
A typical framework of DMs involves a \emph{forward} process gradually diffusing the data distribution $q(\boldsymbol{x},\boldsymbol{c})$ towards a noisy distribution $q_{t}(\boldsymbol{z}_{t},\boldsymbol{c})$ for $t\in(0,T]$. Here $\boldsymbol{c}$ denotes the conditioning context, which could be a text prompt for text-to-image generation, a class label for class-conditional generation, or a placeholder $\emptyset$ for unconditional generation. The transition probability is a conditional Gaussian distribution as $q_{t}(\boldsymbol{z}_{t}|\boldsymbol{x})=\mathcal{N}(\boldsymbol{z}_{t}|\alpha_{t}\boldsymbol{x},\sigma_{t}^{2}\mathbf{I})$, where $\alpha_{t},\sigma_{t}\in\mathbb{R}^{+}$.


It has been proved that there exist \emph{reverse} processes starting from $q_{T}(\boldsymbol{z}_{T},\boldsymbol{c})$ and sharing the same marginal distributions $q_{t}(\boldsymbol{z}_{t},\boldsymbol{c})$ as the forward process \cite{song2021score}. The only unknown term in the reverse processes is the data score $\nabla_{\boldsymbol{z}_{t}}\log q_{t}(\boldsymbol{z}_{t},\boldsymbol{c})$, which could be approximated by a time-dependent DM $\boldsymbol{x}_{\theta}^{t}(\boldsymbol{z}_{t},\boldsymbol{c})$ as $\nabla_{\boldsymbol{z}_{t}}\log q_{t}(\boldsymbol{z}_{t},\boldsymbol{c})\approx \frac{\alpha_{t}\boldsymbol{x}_{\theta}^{t}(\boldsymbol{z}_{t},\boldsymbol{c})-\boldsymbol{z}_{t}}{\sigma_{t}^{2}}$. The training objective of $\boldsymbol{x}_{\theta}^{t}(\boldsymbol{z}_{t},\boldsymbol{c})$ is
\begin{equation}
    \mathbb{E}_{\boldsymbol{x}, \boldsymbol{c}, \boldsymbol{\epsilon},t}\left[\eta_{t}\|\boldsymbol{x}^{t}_{\theta}(\alpha_{t}\boldsymbol{x}+\sigma_{t}\boldsymbol{\epsilon},\boldsymbol{c})-\boldsymbol{x}\|_{2}^{2}\right]\textrm{,}
    \label{equ1}
\end{equation}
where $\eta_{t}$ is a weighting function, the data $\boldsymbol{x},\boldsymbol{c}\sim q(\boldsymbol{x},\boldsymbol{c})$, the noise $\boldsymbol{\epsilon}\sim\mathcal{N}(\boldsymbol{\epsilon}|\mathbf{0},\mathbf{I})$ is a standard Gaussian, and the time step $t\sim \mathcal{U}([0,T])$ follows a uniform distribution.


During the inference phase, the trained DMs are sampled via stochastic solvers \cite{bao2022analytic,ho2020denoising} or deterministic solvers \cite{lu2022dpm,song2021denoising}. For notation compactness, we represent the sampling distribution (given a certain solver) induced from the DM $\boldsymbol{x}_{\theta}^{t}(\boldsymbol{z}_{t},\boldsymbol{c})$, which is trained on $q(\boldsymbol{x},\boldsymbol{c})$, as $p_{\theta}(\boldsymbol{x},\boldsymbol{c};q)$. Any sample $\boldsymbol{x}$ generated from the DM follows $\boldsymbol{x}\sim p_{\theta}(\boldsymbol{x},\boldsymbol{c};q)$.