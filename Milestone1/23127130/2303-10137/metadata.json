{
    "arxiv_id": "2303.10137",
    "paper_title": "A Recipe for Watermarking Diffusion Models",
    "authors": [
        "Yunqing Zhao",
        "Tianyu Pang",
        "Chao Du",
        "Xiao Yang",
        "Ngai-Man Cheung",
        "Min Lin"
    ],
    "submission_date": "2023-03-17",
    "revised_dates": [
        "2023-03-20"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.CR",
        "cs.LG"
    ],
    "abstract": "Recently, diffusion models (DMs) have demonstrated their advantageous potential for generative tasks. Widespread interest exists in incorporating DMs into downstream applications, such as producing or editing photorealistic images. However, practical deployment and unprecedented power of DMs raise legal issues, including copyright protection and monitoring of generated content. In this regard, watermarking has been a proven solution for copyright protection and content monitoring, but it is underexplored in the DMs literature. Specifically, DMs generate samples from longer tracks and may have newly designed multimodal structures, necessitating the modification of conventional watermarking pipelines. To this end, we conduct comprehensive analyses and derive a recipe for efficiently watermarking state-of-the-art DMs (e.g., Stable Diffusion), via training from scratch or finetuning. Our recipe is straightforward but involves empirically ablated implementation details, providing a solid foundation for future research on watermarking DMs. Our Code: https://github.com/yunqing-me/WatermarkDM.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10137v1"
    ],
    "publication_venue": "23 pages, 22 figures"
}