\section{Related Work}
While learning 3D scene representations from images is a topic with a wide array of classic techniques\cite{tomasi1993shape, hartley2000multiple}, our work builds on techniques that train neural networks to learn a volumetric scene representation. While there are different neural network-based techniques\cite{sitzmann2019scene,lombardi2019neural,mildenhall2019local}, we focus on Neural Radiance Fields.\\

\textbf{Neural Radiance Fields (NeRF)}~~~ as first introduced by Mildenhall \etal \cite{vanilla} learn to produce novel views of a scene from photographs with intrinsic and extrinsic camera parameters. For this, they use a multilayer perceptron (MLP) that should map a position in a scene together with a view direction to a colour and a density value. Treating each pixel as the result of a ray going through the scene, they train the MLP such that volume ray marching on samples of the ray returns the correct pixel colour. Barron \etal \cite{mip} propose mip-NeRF, adapting this formulation to treat pixels as the result of cones going through the scene instead of rays. This better captures volume and helps to combat aliasing effects, synthesising more realistic and sharper views, in particular for datasets that contain images with varying distances to objects. Mip-NeRF 360 \cite{mip360} further improves performance and quality on unbounded scenes by using a non-linear scene parametrisation and by efficiently learning a prior for sampling. Similar scene parametrisations can be found in \cite{donerfdepthoracle, nerf++}. To deal with sparse sets of images, \eg pixelNeRF \cite{pixelnerf} utilizes additional features collected by a CNN. Further work specialises on different aspects:\\
\textbf{Large-Scale Distributed NeRFs}~~~ try to reduce the parameter count of NeRFs for large scenes by breaking the scene into multiple different local NeRFs. This technique enables learning areas spanning multiple hundreds of metres in planar directions \cite{blocknerfwaymo} and can be parallelised during training \cite{meganerf}. Other approaches employ disentanglement to better capture large regions, either by disentangling environment parameters \cite{martin2021nerf}, disentangling the scene itself \cite{zhang2020nerf++, Niemeyer_2021_CVPR}, or by re-parameterising scenes \cite{Park_2021_ICCV, hex}. 

\textbf{Interactive Framerates for NeRFs}~~~ can be achieved by learning a conventional NeRF and then storing the learned opacities and specular features in a sparse voxel grid structure \cite{liu2020neuralsparsevoxelfields, hedman2021snerg}. Thereby, spherical harmonics can be used as a view independent feature representation \cite{yu2021plenoctrees}. While these approaches enable real-time inference rendering by removing costly querying of large networks, they require training a large NeRF beforehand. Rebain \textit{et al.} \cite{derfdecomposed} use a differentiable Voronoi diagram as scene decomposition into many small MLPs to decrease inference time. KiloNeRF \cite{kilonerf} learns a grid of tiny MLPs, enabling real-time rendering. A distillation step from a conventional NeRF is used to avoid artifacts. Kurz \textit{et al.} \cite{kurz2022adanerf} use an efficient sample placement to reduce the number of NeRF evaluations, resulting in real-time capabilities.\\
\textbf{Fast Training of NeRFs}~~~ is a major task in NeRF research, as training can take up to multiple days to reach reasonable output quality. Point-NeRF \cite{pointnerf} generates a point cloud of image features near the surface geometry by using a depth estimation during preprocessing. These local features are then used as prior for fast NeRF training. Other approaches utilise networks trained on tasks like depth prediction to speed up training\cite{deng2022depth, roessle2022dense}. Sun \textit{et al.} \cite{Sun_2022_CVPR} learn a voxel grid of latent features combined with a shallow network to bring down convergence time into the order of minutes. This could be further improved by storing the latent features in a learnable hash table \cite{muller2022instant}.

%--- End 07.03.2023

% ---- julias notes
%mip-NeRF360 \cite{mip360} further improves performance and quality on unbounded scenes using scene parametrization and regularization. To deal with sparse sets of images, pixelNeRF \cite{pixelnerf} is additionally assisted by a feature extracting CNN. NeRF++ \cite{nerf++} uses regularization techniques to mitigate frequent problems in NeRFs.\\
% ----

%\textbf{Interactive Framerates for NeRFs}~~~ can be achieved by [..., e.g. kilonerf, \cite{kurz2022adanerf}] [Key contribution at the end]: We use the idea of splitting a NeRF up for faster querying of points, but avoid the costly distillation process and unwanted artefacts.\\

% ---- julias notes
%Interactive frame rates for NeRFs are mainly achieved by speeding up the network evaluation when dividing the scene into smaller subspaces \cite{kilonerf}, or by reducing the amount of required query points on the rays \cite{kurz2022adanerf}.

%Voxel-based distribution:\\
%The following approaches all slowly train a NeRF and sample features into efficient data structures to perform rendering in real-time.
%Hedman \etal \cite{hedman2021snerg} train a large NeRF and then store colours, densities, and specular features in a sparse voxel grid (paper: Baking Neural Ra-
%diance Fields for Real-Time View Synthesis). Yu \etal \cite{yu2021plenoctrees} use an octree-based 3D representation and preserve view-dependent features using spherical harmonic representation of radiance (paper: PlenOctrees for Real-time Rendering of Neural Radiance Fields).\\
%Sun \etal \cite{sunSC22} adopt voxel grids to store features and opacity (latent code based; paper: Direct Voxel Grid Optimization: Super-fast Convergence for Radiance Fields Reconstruction).\\

%Point-based distribution:\\
%Point-NeRF \cite{pointnerf} distributes a point cloud near scene surfaces, where each point stores image features. DeRF \cite{derfdecomposed} train multiple local NeRFs using Voronoi cells. Block-NeRF \cite{blocknerfwaymo} distributes several NeRFs across the scene, while their viewing radii overlap with the radiii of neighbouring networks.\\

%Hash-table based distribution:\\
%M\"uller \etal \cite{muller2022instant} store the encoded input in a hash table of trainable feature vectors, that enables the use of smaller NeRFs, without losing quality. This approach is currently SOTA.
% ----

\textbf{Voronoi Diagrams}~~~ can partition a volume into cells, with points being easily assignable to the according cell. While traditionally used in geometry, optimising Voronoi diagrams can be done \eg to re-create images or shapes\cite{sven, xiao2018optimal, lecot2006ardeco}. Such a partitioning offers a compact and structure-sensitive representation of the underlying information with a high degree of flexibility. The underlying flexibility can also be used to partition a scene for NeRFs, as is done by \cite{derf}.\\
\textbf{Applications}~~~ With widespread use, the applications for NeRF become ever more complex, increasing the demand for faster training. Examples for complex applications are Text-to-NeRF approaches\cite{dreamfusion, jain2022zero, lin2022magic3d} or NeRF-based Text-to-Video approaches\cite{singer2023text}. Other applications include \eg classic tasks from robotics, like localisation and mapping \cite{rosinol2022nerf}. These applications show the need for techniques to consider both speed in training and inference.\\
Our work uses Voronoi diagrams to combine the advantages of approaches that provide interactive framerates at inference together with ideas for large-scale distributed NeRFs.