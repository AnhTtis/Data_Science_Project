\section{Conclusion}
We propose an easy to use extension for Neural Radiance Fields that allows us to bring the quicker inference times from distributed approaches to training. We achieve this through considering the scene to be a (nested) Voronoi diagram that is adaptively refined through the training process. We build this diagram through exploiting the geometric information learned while training and reduce artifacts by obtaining a prior for a coherent shape from passing down parameters from a global to a local scale. Our approach achieves high speed from subdivision of the scene into networks that are fast to query, achieves high quality from geometry-sensitive adaptive space partitioning, and uses inheritance initialisation to avoid artifacts. As this solution is agnostic to architecture, sampling, and even conceptual differences in aspects like considering rays or cones, our approach works with many different NeRF variants. It can improve approaches that are built for speed and push the qualitative boundaries for existing approaches. With its dynamic adaptivity in refining detail, it offers flexibility and speed for \eg large datasets, an area where NeRFs usually require costly hardware and hand-tailored solutions. With our approach, we provide a simple extension to bring the field closer to the masses on a hardware level, while its applicability to many different kinds of NeRF approaches and its simplicity make it accessible not only to experts in the field.
For future work, we see possibilities to use our geometry prior even more adaptively: For dynamic scenes with an initialisation, these would become easy to adapt, as only the Voronoi cell(s) with the ongoing change would need to be updated. We also see that our approach could be used for formulations that learn \eg signed distance functions.