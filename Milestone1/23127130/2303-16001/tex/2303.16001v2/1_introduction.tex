\section{Introduction}\label{sec:intro}
Neural Radiance Fields (NeRF)\cite{vanilla} and their derivatives have become one of the most promising areas of research in learning 3D scenes from images. Their key to success lies in using the flexibility of MLPs to learn a volumetric function, guided by the pixel colours of images taken in the scene. For this, pixels are assumed to be the result of integrating a volumetric function over samples from a ray traced through the scene. However, computing even a single pixel requires sampling many times along a ray, \ie many evaluations of the function learning the scene. With larger or more detailed scenes, the complexity of the function must also increase, resulting slower queries for a point. While other approaches often try to improve sampling strategies, our approach takes geometric complexity into account and thus allows for faster convergence and real-time evaluation strategies. Our method can be used complementary to most other techniques and is based on combining three key observations:
\begin{enumerate}
    \item Evaluating a complex function in $k$ places can be much slower than to $k$ times evaluate one of $m$ less complex functions, if choosing the right function to evaluate is cheap enough
    \item Learning a lightweight representation of a scene is a good indicator for what parts of a scene are geometrically complex while having an guidance for the coherence of the scene
    \item Voronoi diagrams can partition a volume into convex cell sections that can be easily evaluated and offer a high degree of flexibility; cells can be easily adjusted to optimise a desired objective
\end{enumerate}
We propose to first learn a simple scene representation that is fast to evaluate for training. This representation is then used to optimise a Voronoi diagram that divides the scene in multiple subsections with roughly the same geometric complexity. The initial simple scene representation then also works as initial representation for the subsections defined by the Voronoi diagram. With this global prior, we are able to avoid coherence problems of approaches that focus on fast evaluation through subdividing a scene and can otherwise be only circumvented with more costly training. This allows us not only to have the speed advantage of distributed scenes for evaluating a learned scene, but to also bring that speed advantage to learning the scene itself.\\
As a result, for a more complex scene, we can use multiple small functions instead of increasing the complexity of one large function. As each sample along a ray through the scene gets evaluated by one function, and we only introduce more low-complexity functions instead of making the function more complex, we can obtain more precise information for a ray sample point without increasing the number of parameters to evaluate for it. This important characteristic is key for large-scale datasets or possibly even real-time approaches in domains such as autonomous driving.\\
As our geometry-aware approach does not alter any of the underlying maths, it is in general compatible with most common variants of NeRFs. While these qualities make our approach particularly more effective with larger amounts of data, it also improves small-scale scenes. It can be implemented as an extension within few lines of simple code, and will be released on GitHub.