
\section{Related Work} \label{sec:related}

Traffic incident impact prediction has been considered an important topic in traffic management for decades. Traditional studies considered it as a 1-D propagation task and designed deterministic queuing diagrams~\cite
{Ben2001network} and shockwave theory~\cite{motamedidehkordi2016shockwave}.~\cite{tang2020statistical} summarizes statistical and machine learning methods arguing that quantile regression (QR), finite mixture (FM), and random parameters hazard-based duration (RPHD) perform the best.
% A queuing model is constructed to measure the queue lengths and wait times. The traffic shockwave theory determines the delay time by measuring the difference between the average traffic flow and density. 

\textbf{Grid-based Representation Learning.} With the development of machine learning methods, more complex factors are considered in traffic incident impact prediction models. For example, Zou~\etal~\cite{zou2021application} utilize Bayesian Model Averaging (BMA) to merge the prediction results of multiple machine learning models. Meanwhile, Match-Net~\cite{kalair2021dynamic} gradually updates its prediction as new data is acquired and performs interpretability analysis using Shapley values. 

%% more about analyzing accident records, no need to be included
%~\cite{GRIGOREV2022incident} provides three traffic incident datasets. The datasets contain auxiliary information and support two incident-duration-based tasks: long/short-term classification and incident duration prediction.~\cite{zhang2022analysis} labels traffic incidents with speed-changing rates and analyzes how road attributes affect congestion durations.~\cite{li2021online} defines incident post-impact prediction as a task performing classification, duration prediction, and accumulative queue length prediction.~\cite{lee2022quantifying} discusses the relations between incident report time and congestion occurring time. 

Some studies consider traffic data with regular data structure.
Huang~\etal~\cite{huang2020using} utilize a generative adversarial network (GAN) to predict incident impacts by directly learning speed heatmaps. Lin~\etal~\cite{lin2020real} gradually update incident duration predictions with a decision tree as new speed measurements are acquired. Similarly, Zhu and Wu~\cite{zhu2021dynamic} propose a model that updates incident duration prediction every five minutes. However, these models fail to consider the complexity of road networks, instead considering only one road.

\textbf{GNN-RNN Dynamic Graph Representation Learning.} Some researchers consider traffic forecasting as a downstream task of dynamic graph representation learning. For example, RadNet~\cite{tuli2022radnet} considers incident prediction as an anomaly detection problem and utilizes a transformer and GCN.
 % However, this study did not include experiments on real incident record data.
 PrePCT~\cite{bai2021prepct} proposes a new method of mapping road networks to grid cells and utilizes a CNN and LSTM for congestion prediction. DIGC-Net~\cite{xie2020deep} predicts traffic flow speeds by considering incident records and similarities among flow segments in the same time window. SLCNN~\cite{zhang2020spatio} utilizes static and dynamic graphs and top-K attention to perform a C3D-like~\cite{tran2015learning} temporal convolution. Finally, Yoo~\etal~\cite{yoo2021conditional} propose a covariance loss considering both the basis function space and the targeted variable space. 

\textbf{Attentive Dynamic Graph Representation Learning.} The attention mechanism is now one of the most popular methods of learning relations between graph nodes through their feature similarities. STAWnet~\cite{tian2021spatial} utilizes attention to extract spatial relations among road segments and employs gated TCN to extract temporal dependencies. 
% ADN~\cite{drakulic2022structured} merges the spatial and temporal dimensions with attention across all elements. Tygesen~\etal~\cite{tygesen2022unboxing} perform traffic prediction with neural relational inference techniques. 
Other studies have utilized transformers for spatiotemporal
 data mining. ~\cite{wu2021representing, rong2020self, zhang2020graph} consider a GNN as an auxiliary module for transformers. Except for GNN, graph structure and position features can also be utilized by transformers through position encoding~\cite{xu2020spatial, zhang2020graph,
 ying2021transformers}. For example, GraphGPS~\cite{rampavsek2022recipe} encodes graph structures and node positions in three different ways. ~\cite
 {dwivedi2020generalization, min2022masked} considers adjacent matrices as masks of attention. GraphiT~\cite{mialon2021graphit} turns an adjacent matrix into a kernel matrix. Other dynamic graph representation learning
 models are also efficient in traffic flow forecasting tasks; these include Graph WaveNet~\cite{wu2019graph}, AGCRN~\cite
 {bai2020adaptive}, and DMSTGCN~\cite{han2021dynamic}. However, these methods above are designed for either node-level or whole-graph tasks, and their abilities to extract
 important subgraphs have not yet been explored.

\textbf{Task-Specific Dynamic Graph Representation Learning.} Some studies have addressed the ``subgraph extraction'' problem and approached the solution through aggregation or denoising techniques. Titan~\cite{fu2019titan} considers the impact prediction on each road as an individual task and performs the prediction with a shared-parameter multitask model~\cite{fu2021hierarchical}. Meng~\etal~\cite{meng2022early} compare the performances of a CNN-based model and traditional traffic incident impact models. The results show that proper graph aggregation and kernel techniques improve the performance of dynamic graph learning models for traffic incident impact prediction tasks. Nevertheless, the three models above only consider the temporal impact of incidents and ignore the importance of spatial impact prediction.

As the survey above demonstrates, we can see that there has not been a formal
definition of the problem of spatiotemporal traffic incident impact prediction in the context of dynamic graph representation learning. Therefore, a new problem
definition, benchmark datasets, and directions for exploring subgraph impacts are required.
