\section{Experiment}
\label{sec:experiment}
In this section, we first introduce our datasets and our method for data
cleansing and labeling. Then, we compare DG-Trans with state-of-the-art
baselines and evaluate our proposed model from three perspectives: prediction
precision, module-level effectiveness, and execution efficiency of the
spatial attention module. Next, we perform a case study to examine whether DG-Trans can correctly extract spatiotemporal features. Finally, we propose several basic methods of incorporating new data into DG-Trans. These methods may help to broaden the problem domain of traffic incident impact prediction.

\subsection{Dataset} 
The traffic loop sensor data used for this research are collected from the Caltrans Performance Measurement System (PeMS)\footnote{\url{https://pems.dot.ca.gov/}}; The incident record data are from RITIS \footnote{\url{https://www.ritis.org/}}; The road networks are
downloaded from Tiger Priscroads \footnote{\url
{https://www2.census.gov/geo/tiger/}}. Based on the location of sensors and incidents, we selected several freeway segments in Los Angeles and San Bernardino regions, which have well-constructed and complex road networks. 

In addition to the data used in this research (i.e., sensor measurements, adjacency information, and incident impact records), we also provided auxiliary data to broaden the potential problem domain. Specifically, our datasets
contain three basic elements: roads, sensors, and incidents. For roads, we provide a matrix indicating whether two roads intersect each other and the location of the intersections (in the form of the distance from the start point of the road). For sensors, we collect their positions on the roads and
their five-minute speed and occupancy measurements. As the rate of missing records is less than 0.005\%, we simply filled those values with daily average
speed/occupancy. Finally, for incidents, we provide the position on the road,
the DateTime (number of five minutes from 2019/09/01 00:00:00), the incident
category, the impact duration, and the impact length. 

Since we lacked the ground truth of impact length, we acquired the label with three
steps. We first extracted the regular weekly traffic pattern by averaging the
speeds from 2019/08/01 to 2019/10/31. In this case, a speed lower than the
regular pattern is considered an indicator of non-recurrent congestion. The second step is to split the impacted sensor measurements from the others. We performed a binary 1D k-means classification to extract low speed measurements, then looked for the closest upstream sensor that detected no
congestion during the incident clearance process. If the selected sensor is the closest sensor to the incident, the impact length is zero. Otherwise, the impacted length is defined by the distance from the incident to the upstream sensor before the picked sensor.

To construct properly scaled datasets, we selected several inter-state freeways as illustrated in Figure~\ref{fig:p7_road} and~\ref{fig:p8_road}. The time span was set to one month (2019/09/01 -- 2019/09/30). Sensors and incidents not on the chosen freeways were filtered out. We also removed incidents with a duration of fewer than 30 minutes due to their limited temporal impact. Figure~\ref{fig:p8_dis} shows the distribution of impact duration and length. The orange dashed lines indicate the fluctuations of log event counts across different durations and impact lengths. The shades of the bars show the magnitude of event counts. All the label values follow power-law distributions except that
the impact length in the San Bernardino region is relatively noisy compared
with the others. Finally, we present two traffic incident impact
prediction datasets: Incident-LA and Incident-SB. The detailed attributes of
the two dynamic networks are illustrated in Table~\ref{tab:pems_dist}. 

% \begin{figure*}
% \centering
% \begin{subfigure}{.33\linewidth}
%     \centering
%     \includegraphics[width=\linewidth]{figures/pems07.pdf}
%     \caption{Covered Freeways with Incident Locations (Incident-LA)}\label{fig:p7_road}
% \end{subfigure}
%     \hfill
% \begin{subfigure}{.65\linewidth}
%     \centering
%     \includegraphics[width=.99\linewidth,height=.4\linewidth]{figures/distribution_PEMS-07_1.png}
%     \caption{Distribution of Event Duration/Impact Length/ Non-Zero Impact Length (Incident-LA)}\label{fig:p7_dis}
% \end{subfigure}
% \bigskip
% \begin{subfigure}{.33\linewidth}
%     \centering
%     \includegraphics[width=\linewidth]{figures/pems08.pdf}
%     \caption{Covered Freeways with Incident Locations (Incident-SB)}\label{fig:p8_road}
% \end{subfigure}
%    \hfill
% \begin{subfigure}{.65\linewidth}
%     \centering
%     \includegraphics[width=.99\linewidth,height=.4\linewidth]{figures/distribution_PEMS-08_1.png}
%     \caption{Distribution of Event Duration/Impact Length/ Non-Zero Impact Length (Incident-SB)}\label{fig:p8_dis}
% \end{subfigure}
% \caption{Basic Dataset Information}
% \label{fig:dataset_intro}
% \end{figure*}

\begin{figure}
\centering
\begin{subfigure}{.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/pems07.pdf}
    \caption{Included freeways with incident locations (Incident-LA)}\label{fig:p7_road}
\end{subfigure}
\begin{subfigure}{.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/pems08.pdf}
    \caption{Included freeways with incident locations (Incident-SB)}\label{fig:p8_road}
\end{subfigure}
\bigskip
\begin{subfigure}{\linewidth}
    \centering
    \includegraphics[width=\linewidth,height=.4\linewidth]{figures/distribution_all_2.png}
    \caption{Distribution of event duration/impact length/ non-zero impact length (Incident-SB)}\label{fig:p8_dis}
\end{subfigure}
\caption{Basic Dataset Information}
\label{fig:dataset_intro}
\end{figure}

\begin{table}[h]
\small
  \centering
  \begin{tabular}{cllll}
    \toprule
    Dataset & \# event & \# node & \# edge & \# 0 length \\
    & & (R/S) & (R-R/S-S) & \\
    \midrule
    Incident-LA & 5,668 & 32/1,663 & 142/869,640 & 2,062\\
    Incident-SB & 1,452 & 28/1,150 & 140/390,822 & 454\\
    
  \bottomrule
\end{tabular}
  \caption{Dataset Properties}
  \label{tab:pems_dist}
\end{table}

\subsection{Baselines} To evaluate the efficiency of DG-Trans, nine representative models are chosen to perform the same task. Considering that only a few models target similar tasks, we choose the two most recently
 published incident impact prediction models, two conventional models, and
five state-of-the-art traffic forecasting models. Among the latter five models, two leverage attentive graph representation learning techniques, while the other three use graph convolution.
\begin{itemize}
    \item \textbf{L-1 regularized linear regression (LASSO)~\cite{tibshirani1996regression}.} As LASSO only takes one-dimensional features as inputs, we examined different feature aggregation methods. These include (1) averaging over both the spatiotemporal dimensions, (2) picking the closest upstream/downstream sensor and averaging over the temporal dimension, and (3) picking the closest upstream/downstream sensor and the five minutes immediately after the validation time. For parameter selection, we examined $\lambda$ values of $0.1$, $1.0$, $10.0$, and $100.0$. 
    \item \textbf{Support vector regression (SVR)~\cite{tibshirani1996regression}.} Similar to LASSO, we examined three different feature aggregation methods. We used the default parameters ($C=1, \epsilon=0.1$) in the sklearn~\cite{scikit-learn} package of Python.
    \item \textbf{HastGCN~\cite{fu2021hierarchical}.} HastGCN is a spatiotemporal attention model designed for incident duration prediction. We reproduce the model with the help of the author. Some features used in~\cite{fu2021hierarchical} are removed because they are not provided in our datasets. All the other settings are the same as the original model.
    \item \textbf{AGWN~\cite{meng2022early}.} AGWN preprocesses the adjacency matrix with a wavelet filter before the graph convolution operation. The model utilizes only one timestamp immediately after the validation time. To allow a fair comparison, we attached our Importance Score Transformer and pooling module to it. All the hyperparameters are the same as in the original paper.
    \item \textbf{STTN~\cite{xu2020spatial}.} STTN utilizes transformers for both spatial and temporal message-passing. The model is designed for node-level speed  forecasting. In this case, we attach our pooling module to the original STTN. The experiment code is extracted from the STTN github repository \footnote{\url{https://github.com/wubin5/STTN}}. All the hyperparameters remain the same as is mentioned in the paper.
    \item \textbf{STAWnet~\cite{tian2021spatial}.} STAWnet utilizes attentive graph message-passing and gated temporal convolution networks (TCN). It is also a node-level speed forecasting model and requires our pooling module to fit our incident impact prediction task. We utilized the official code \footnote{\url{https://github.com/CYBruce/STAWnet}} and left the hyperparameters unchanged.
    \item \textbf{DMSTGCN~\cite{han2021dynamic}.} DMSTGCN decomposes the adjacency matrix into four trainable embeddings for graph convolution. The temporal information is merged with gated TCN. Our pooling module was attached to the model to obtain the desired output. All the hyperparameters are the same as in the original paper \footnote{\url{https://github.com/liangzhehan/DMSTGCN}}.
    \item \textbf{Graph WaveNet~\cite{wu2019graph}.} Graph WaveNet contains a self-adaptive graph convolution module and a dilated temporal convolution module. Our pooling module was attached to the model to obtain the desired output. All the hyperparameters are the same as in the original paper \footnote{\url{https://github.com/nnzhan/Graph-WaveNet}}.
    \item \textbf{AGCRN~\cite{bai2020adaptive}.} AGCRN performs node-adaptive graph convolution and GRU-like temporal message-passing. Our pooling module was attached to the model to obtain the desired output. All the hyperparameters are the same as in the original paper \footnote{\url{https://github.com/LeiBAI/AGCRN}}.
\end{itemize} 

\subsection{Hyperparameter and Metrics}
In the problem settings of this paper, we assume that the objective is to predict the incident's impact within a short time after the event. To do so, nine timestamps (six for ``before-validation'' and three for ``after-validation'') were adopted. As a result, the model could not see the full traffic pattern during the incident.

For the training process of DG-Trans, we adopted a batch size of 8 due to the GPU memory limitation. The learning rate was 0.0005 with a 0.001 weight decay. The number of attention heads was 4. The LeakyReLU factor was set to 0.2, and the dropout rate was 0.1. In the loss function (Equation~\ref{eq:loss}), the prediction loss weight $\psi$ was 1.0, and $\omega$ was equal to the epoch.

Following our previous works~\cite{fu2019titan, fu2021hierarchical,meng2022early}, we adopted root mean squared error (RMSE) and mean absolute
error (MAE) as metrics. However, the impact length introduces labels of zero
value making mean absolute percentage error (MAPE) invalid. Therefore, we replaced MAPE with symmetric mean absolute percentage error (sMAPE). Based
on the definition ($RMSE=\sqrt{\frac{1}{N}\sum_{i=1}^N(y_i-\hat
{y}_i)^2}$, $MAE=\frac{1}{N}sum_{i=1}^N|y_i-\hat{y}_i|$, $sMAPE=\frac{1}
{N}sum_{i=1}^N|\frac{2|y_i-\hat{y}_i|}{|y_i|+|\hat{y}_i|}|$), RMSE penalizes
large gaps more harshly than MAE, while sMAPE focuses more on the magnitude of the differences from the true values.

\begin{table*}[t]
  \small
  \centering
  \begin{tabular}{c lll lll lll lll lll}
    \toprule
    &\multicolumn{3}{c}{Incident-LA (dur (min))} & 
     \multicolumn{3}{c}{Incident-LA (len (mile))} &
     \multicolumn{3}{c}{Incident-SB (dur (min))} &
     \multicolumn{3}{c}{Incident-SB (len (mile))}\\
     & RMSE & MAE & sMAPE & RMSE & MAE & sMAPE & RMSE & MAE & sMAPE & RMSE & MAE & sMAPE\\
    \midrule
    
    LASSO~\cite{tibshirani1996regression}&  59.773& 51.776& 0.760& 8.270& 6.794& 1.211& 58.921& 51.263& 0.757& 10.743& 8.934& 1.112\\
    SVR~\cite{tibshirani1996regression}& 60.073& 50.763& 0.743& 8.559& 6.300& 1.299& 59.560& 50.924& 0.761& 11.632 & 8.812 & 1.218\\
    HastGCN~\cite{fu2021hierarchical} & 31.719& 20.372& 0.319& 8.421& 6.402& 1.272& 35.936& 25.078& 0.381& 13.053& 9.299& 1.350 \\
    AGWN~\cite{meng2022early} & 31.934& 20.720& 0.341& 10.840& 6.594& 0.874& 32.864& 22.391& 0.365& 11.730& 8.736& 0.743 \\
    
    STTN~\cite{xu2020spatial}& 31.826& 21.098& 0.322& 9.644& 6.317& 0.893& 31.235& 20.631& 0.326& 12.346& 9.025& 0.812 \\
    STAWnet~\cite{tian2021spatial}& 31.400& 20.315& 0.318 & 8.619
& 6.311& 1.310 & 29.280& 20.212& 0.320& 11.994& 8.945& 1.260\\  
    DMSTGCN~\cite{han2021dynamic}& 31.555 & 20.342 & 0.319 & 10.638 & 7.784 & 0.880 & 29.810 & 20.263 & 0.312 & 12.929 & 9.846 & 0.791 \\
    Graph WaveNet~\cite{wu2019graph} & 31.880&20.415&0.320&10.489&7.672&0.861& 30.765&20.455&0.324& 14.093&10.807& 0.914 \\
    AGCRN~\cite{bai2020adaptive} & 31.253&20.363&0.319& 8.662&6.212&0.899& 30.905&20.652&0.324&12.808&9.093&1.172 \\
    \midrule
    \textbf{DG-Trans} & \textbf{31.413}& \textbf{20.310}& \textbf{0.318}& \textbf{9.494}& \textbf{6.226}& \textbf{1.477}& \textbf{29.726}& \textbf{20.140}& \textbf{0.319}& \textbf{11.731}& \textbf{8.818}& \textbf{1.235} \\
    \bottomrule
  \end{tabular}
  \caption{\textbf{RMSE, MAE, and sMAPE for Duration and Impact Length Prediction of Incident-LA and Incident-SB.} This table lists the performance of nine state-of-the-art baselines and our proposed model.}
  \label{tab:baseline}
\end{table*}

\subsection{Prediction Result Analysis}
The input to the models includes the adjacent matrices and sensor measurements one hour before and half an hour after the validation time. The output is the impact duration and length. We evaluated the duration and length separately as they are of different units.

Table~\ref{tab:baseline} illustrates the performance of DG-Trans against the baselines. 

\textbf{Conventional baselines.} For LASSO and SVR, the best performance is
 achieved with the closest upstream sensor and the first timestamp after the
 validation time as inputs. The results appeared to be insensitive to
 hyperparameters. As shown in Table~\ref{tab:baseline}, even though they
 produced competitive results in RMSE and MAE impact length prediction, LASSO
 and SVR performed poorly in predicting impact duration prediction.  This result matches our hypothesis that the ``closest'' sensors and timestamps are not optimal for prediction. 

\textbf{Spatiotemporal neural network baselines.} DG-Trans surpasses the other baselines (i.e., spatiotemporal neural networks) in most of the metrics and achieves competitive performance on the other metrics if it is not the best. Specifically, DG-Trans outperforms another spatiotemporal transformer, STTN, by about 10\% in duration prediction and 5\% in length prediction. DG-Trans also beats previous incident impact prediction models, HastGCN and AGWN, by approximately 10\% in performance.

 We find that DG-Trans cannot beat the other models in all metrics. To prove the efficiency of our model, we rank all ten models by each criterion and list the average rank in Table~\ref{tab:rank}. The table shows that our model performs the best on average.

 %  This part of the experiment shows that models designed specifically for
 % incidents (i.e., focus on locating incidents and denoising) perform better
 % than models evenly treat every spatiotemporal feature.
 \begin{table}[h]
\small
  \centering
  \begin{tabular}{clllll}
    \toprule
    Model&\textbf{DG-Trans}&STTN&STAW.&DMST.&AGCRN\\
    \midrule
    Rank & \textbf{3.58}&3.75&4.08&5.25&5.25\\
    \midrule
    Model &AGWN&G.W.&LASSO&Hast.&SVR\\
    \midrule
    Rank &5.75&6.67&6.83& 6.92&6.92\\
    
  \bottomrule
\end{tabular}
  \caption{\textbf{Average rank of baseline and DG-Trans performance.} Abbreviated model names are used due to the limited space. The smaller the number, the higher the average rank.}
  \label{tab:rank}
\end{table}

 
\subsection{Ablation Study}

\begin{table*}[t]
  \small
  \centering
  \begin{tabular}{c lll lll lll lll lll}
    \toprule
    &\multicolumn{3}{c}{Incident-LA (dur (min))} & 
     \multicolumn{3}{c}{Incident-LA (len (mile))} &
     \multicolumn{3}{c}{Incident-SB (dur (min))} &
     \multicolumn{3}{c}{Incident-SB (len (mile))}\\
     & RMSE & MAE & sMAPE & RMSE & MAE & sMAPE & RMSE & MAE & sMAPE & RMSE & MAE & sMAPE\\
    
    \midrule
    No-STrans & 31.245& 20.320& 0.319& 9.608& 6.251& 1.503& 28.793& 21.240& 0.338& 11.922& 8.877& 1.255 \\
    No-TTrans & 31.674& 20.371& 0.319& 9.496 & 6.215& 1.570& 32.024& 27.265& 0.422& 12.432& 8.903& 1.344 \\
    No-Road & 31.611& 20.351& 0.319& 9.909& 6.345& 1.616& 28.568& 20.928& 0.333& 13.240& 9.286& 1.496 \\
    No-Score & 31.846& 20.321& 0.319& 9.496& 6.215& 1.473& 30.000& 20.236& 0.320& 14.000& 9.743& 1.688 \\

    \midrule
    \textbf{DG-Trans} & \textbf{31.413}& \textbf{20.310}& \textbf{0.318}& \textbf{9.494}& \textbf{6.226}& \textbf{1.477}& \textbf{29.726}& \textbf{20.140}& \textbf{0.319}& \textbf{11.731}& \textbf{8.818}& \textbf{1.235} \\
    \bottomrule
  \end{tabular}
  \caption{\textbf{RMSE, MAE, and sMAPE for Duration and Impact Length Prediction of Incident-LA and Incident-SB.} The results of the ablation study include our model without the S-Transformer (No-STrans), our model without the T-Transformer (No-TTrans), our model without the road anchors (No-Road), and our model without the importance score (No-Score).}
  \label{tab:ablation}
\end{table*}

We conducted four ablation experiments to evaluate the contributions of each component of the DG-Trans model. The result is shown in Table~\ref{tab:ablation}. For the ``No-STrans'' and ``No-TTrans'' experiments, we simply removed the corresponding modules. For ``No-Score'', we skipped the concatenation steps in Equation~\ref{eq:score_1} and ~\ref{eq:score_2} and removed the reconstruction losses during training. For ``No-Road'', we replaced the Dual-Level S-Transformer with the transformer used in STTN. Initially, we assumed that ``No-Road'' would outperform DG-Trans as our graph had too many edges removed. However, the results in Table~\ref{tab:ablation} show that our model cannot achieve its performance without any of its components. We observed that the performance drops less in ``No-Score'' and ``No-TTrans'' than in ``No-Road'' and ``No-STrans''. This may be because the number of timestamps in the input is too small for a transformer to work.  
% \subsection{Graph Attention Efficiency.} 

% We also compared the execution time
%  of S-Transformer with the same modules in the baselines. Based on our
%  observation, HastGCN leverages three linear transformations to perform the
%  attention while STTN and STAWnet utilize the vanilla attention mechanism. As
%  suggested by Table~\ref{tab:pems_efficient}, S-Transformer executes $2$ to
%  $5$ times faster than the vanilla attention and also faster than the linear
%  transformation attention. 

% The execution times of STAWnet on the two datasets are the same, as we cut off
% some nodes from Incident-LA to remove the OOM issue. We also observe that the
% execution time is not linearly related to the number of sensors in DG-Trans.
% The reason is that the number of computations is also related to the number
% of roads. As the numbers of roads are similar in the two datasets, the
% execution times are the same as well.

% \begin{table}[h]
% \small
%   \centering
%   \begin{tabular}{cllll}
%     \toprule
%     Dataset & HastGCN & STTN & STAWnet & \textbf{DG-Trans} \\
%     \midrule
%     Incident-LA & 0.0021 & 0.0050 & 0.0080 & \textbf{0.0015}\\
%     Incident-SB & 0.0019 & 0.0025 & 0.0080  & \textbf{0.0013}\\
    
%   \bottomrule
% \end{tabular}
%   \caption{Average execution time of the graph attention module in second}
%   \label{tab:pems_efficient}
% \end{table}

\subsection{Case Study} To examine whether our importance score truly helps to
 identify incidents, we explored several incident cases. One example is
 incident \#18693 (Figure~\ref{fig:score}). The map plots the
 five-minute average speed immediately after the validation time and the importance
 scores within the same time slot. It is obvious that sensors that detect
 lower speeds also have higher importance scores, while high importance
 scores cluster around the incident (red star). However, we also observe that
 incident-irrelevant speed drops lead to high importance scores as well. This is why the model utilizes both the score and the embedded features for prediction.
\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/score_map2.jpg}
  \caption{\textbf{Case study of incident \#18693 on the Freeway I--10.} This is the map of an incident and the surrounding traffic loop sensors on I--10 in the Incident-LA dataset. The red star indicates the location of the incident, and the yellow--green--blue dots are sensors colored according to speed measurements. The orange--red ``X''s indicate the importance scores assigned by DG-Trans. } % describe the architecture
  \label{fig:score}
\end{figure}

\noindent
\textbf{Beyond This Task.} We believe that the other parts of the dataset,
 (i.e., the data not used in this paper), can be used to increase the
 prediction accuracy. We examined simple methods of merging the
 auxiliary information into the traffic network, such as adding an incident
 classification task, using road and sensor position for position encoding,
 and embedding incident metadata. While none of those methods worked, all of these attempts are also uploaded to our GitHub repository \footnote{\url{https://github.com/styxsys0927/DG-Trans.git}} for others to investigate.