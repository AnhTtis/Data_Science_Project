\section{Experiment}
\label{sec:experiment}
In this section, we first introduce our datasets and our method for data
cleansing and labeling. Then, we compare DG-Trans with state-of-the-art
baselines and evaluate our proposed model from three perspectives: prediction
precision, module-level effectiveness, and execution efficiency of the
spatial attention module. Next, we perform a case study to examine if
DG-Trans can correctly extract spatiotemporal features. Finally, we propose
several basic methods incorporating new data into DG-Trans, which potentially
helps with broadening the problem domain of traffic incident impact
prediction.

\subsection{Dataset} 
The traffic loop sensor data used for this research are collected from the
Caltrans Performance Measurement System (PeMS)\footnote{\url
{https://pems.dot.ca.gov/}} ; The incident record data are from
RITIS\footnote{\url{https://www.ritis.org/}}; The road networks are
downloaded from Tiger Priscroads\footnote{\url
{https://www2.census.gov/geo/tiger/}}. Based on the location of sensors and
incidents, we pulled several freeway segments in the Los Angeles Region and
the San Bernardino region, because the road networks are well constructed and
complex in these two regions. 

Even though we only used the sensor measurements, adjacency information, and
incident impact records for this research, we decided to provide auxiliary
data to broaden the potential problem domain. Specifically, our datasets
contain three basic elements, roads, sensors, and incidents. For roads, we
provide a matrix indicating if two roads intersect each other and the
location of the intersections (in the form of the distance from the start
point of the road). For sensors, we collect their positions on the roads and
their five-minute speed and occupancy measurements. The record missing rate
is less than 0.005\%, so we simply filled those values with daily average
speed/occupancy. Finally, for incidents, we provide the position on the road,
the DateTime (number of five minutes from 2019/09/01 00:00:00), the incident
category, the impact duration, and the impact length. 

Due to lacking ground truth of impact length, we acquired the label with three
steps. We first extracted the regular weekly traffic pattern by averaging the
speeds from 2019/08/01 to 2019/10/31. In this case, a speed lower than the
regular pattern is considered an indicator of non-recurrent congestion. The
second step is to split impacted sensor measurements from the others. We
performed a binary 1D K-means classification to extract low speed
measurements and looked for the closest upstream sensor that detected no
congestion during the incident clearance process. Finally, if the picked
sensor is the closest sensor to the incident, the impact length is zero.
Otherwise, the impacted length is defined by the distance from the incident
to the upstream sensor before the picked sensor.

To construct datasets of proper scales, we pulled out several inter-state
freeways as illustrated in Figure~\ref{fig:p7_road} and~\ref
{fig:p8_road}. The time span was set to be one month
(2019/09/01 -- 2019/09/30). Sensors and incidents not on the chosen freeways
are filtered out. We also removed incidents with a duration of fewer than 30
minutes due to their limited temporal impact. Figure~\ref
{fig:p7_dis} and~\ref{fig:p8_dis} show the distribution of impact duration
and length. All the label values follow power-law distributions except that
the impact length in the San Bernardino region is relatively noisy compared
with the others. Finally, we present you the the two traffic incident impact
prediction datasets: Incident-LA and Incident-SB. The detailed attributes of
the two dynamic networks are illustrated in Table~\ref{tab:pems_dist}. 

\begin{figure*}
\centering
\begin{subfigure}{.3\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/pems07.pdf}
    \caption{Covered Freeways with Incident Locations (Incident-LA)}\label{fig:p7_road}
\end{subfigure}
    \hfill
\begin{subfigure}{.68\linewidth}
    \centering
    \includegraphics[width=.9\linewidth]{figures/distribution_PEMS-07.png}
    \caption{Distribution of Event Duration/Impact Length/ Non-Zero Impact Length (Incident-LA)}\label{fig:p7_dis}
\end{subfigure}
\bigskip
\begin{subfigure}{.3\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/pems08.pdf}
    \caption{Covered Freeways with Incident Locations (Incident-SB)}\label{fig:p8_road}
\end{subfigure}
   \hfill
\begin{subfigure}{.68\linewidth}
    \centering
    \includegraphics[width=.9\linewidth]{figures/distribution_PEMS-08.png}
    \caption{Distribution of Event Duration/Impact Length/ Non-Zero Impact Length (Incident-SB)}\label{fig:p8_dis}
\end{subfigure}
\caption{Basic Dataset Information}
\label{fig:dataset_intro}
\end{figure*}

\begin{table}[h]
\small
  \centering
  \begin{tabular}{cllll}
    \toprule
    Dataset & \# event & \# node & \# edge & \# 0 length \\
    & & (R/S) & (R-R/S-S) & \\
    \midrule
    Incident-LA & 5,668 & 32/1,663 & 142/869,640 & 2,062\\
    Incident-SB & 1,452 & 28/1,150 & 140/390,822 & 454\\
    
  \bottomrule
\end{tabular}
  \caption{Dataset Properties}
  \label{tab:pems_dist}
\end{table}

\subsection{Baselines and Metrics} To evaluate the efficiency of DG-Trans, six
 models are chosen to perform the same task. Considering that only a few
 models are targeting similar tasks, we choose the two most recently
 published incident impact prediction models, two conventional models, and
 two state-of-the-art traffic forecasting models. 
\begin{itemize}
    \item \textbf{L-1 regularized linear regression (LASSO)~\cite{tibshirani1996regression}:} As LASSO only takes one-dimensional features as inputs, we examined different feature aggregation methods, including (1) averaging over both the spatiotemporal dimensions, (2) picking the closest upstream/downstream sensor and averaging over temporal dimension, and (3) picking the closest upstream/downstream sensor and the five minutes right after the validation time. For parameter selection, we examined $\lambda$ of $\{0.1, 1.0, 10.0, 100.0\}$. 
    \item \textbf{Support vector regression (SVR)~\cite{tibshirani1996regression}:} Similar as LASSO, we examined three different feature aggregation methods. The default parameter ($C=1, \epsilon=0.1$) in the sklearn~\cite{scikit-learn} package of Python.
    \item \textbf{STTN~\cite{xu2020spatial}:} STTN is designed for node-level speed forecasting. In this case, we attach our pooling module to the original STTN. The experiment code is extracted from\footnote{\url{https://github.com/wubin5/STTN}}. All the hyperparameters remain the same as mentioned in the paper.
    \item \textbf{STAWnet~\cite{tian2021spatial}:} STAWnet is also a node-level speed forecasting model and requests our pooling module to fit our incident impact prediction task. We utilized to official code\footnote{\url{https://github.com/CYBruce/STAWnet}} and remained the hyperparameters unchanged.
    \item \textbf{HastGCN~\cite{fu2021hierarchical}:} HastGCN is a spatiotemporal attention model designed for incident duration prediction. We reproduce the model with the help of the author. Some features used in~\cite{fu2021hierarchical} are removed because they are not provided in our datasets. All the other settings are the same as the original model.
    \item \textbf{AGWN~\cite{meng2022early}:} AGWN utilizes only one timestamp right after the validation time. To be fair, we attached our Importance Score Transformer and pooling module to it. All the hyperparameters are the same as in the original paper.
    \item \textbf{DMSTGCN~\cite{han2021dynamic}:} AGWN utilizes only one timestamp right after the validation time. To be fair, we attached our Importance Score Transformer and pooling module to it. All the hyperparameters are the same as in the original paper.
\end{itemize} 
Following our previous works~\cite{fu2019titan, fu2021hierarchical,
meng2022early}, we adopt root mean squared error (RMSE) and mean absolute
error (MAE) as metrics. However, the impact length introduces labels of zero
value and makes mean absolute percentage error (MAPE) invalid. In this case,
we replaced MAPE with symmetric mean absolute percentage error (sMAPE). Based
on the definition ($RMSE=\sqrt{\frac{1}{N}\sum_{i=1}^N(y_i-\hat
{y}_i)^2}$, $MAE=\frac{1}{N}sum_{i=1}^N|y_i-\hat{y}_i|$, $sMAPE=\frac{1}
{N}sum_{i=1}^N|\frac{2|y_i-\hat{y}_i|}{|y_i|+|\hat{y}_i|}|$), RMSE penalizes
large gaps more harshly than MAE while sMAPE focuses more on the significance
of the differences to the true values.

\begin{table*}[t]
  \small
  \centering
  \begin{tabular}{c lll lll lll lll lll}
    \toprule
    &\multicolumn{3}{c}{Incident-LA (Dur (min))} & 
     \multicolumn{3}{c}{Incident-LA (Len (mile))} &
     \multicolumn{3}{c}{Incident-SB (Dur (min))} &
     \multicolumn{3}{c}{Incident-SB (Len (mile))}\\
     & RMSE & MAE & MAPE & RMSE & MAE & MAPE & RMSE & MAE & MAPE & RMSE & MAE & MAPE\\
    \midrule
    
    LASSO~\cite{tibshirani1996regression}&  59.773& 51.776& 0.760& 8.270& 6.794& 1.211& 58.921& 51.263& 0.757& 10.743& 8.934& 1.112\\
    SVR~\cite{tibshirani1996regression}& 60.073& 50.763& 0.743& 8.559& 6.300& 1.299& 59.560& 50.924& 0.761& 11.632 & 8.812 & 1.218\\
    STTN~\cite{xu2020spatial}& 31.826& 21.098& 0.322& 9.644& 6.317& 0.893& 31.235& 20.631& 0.326& 12.346& 9.025& 0.812 \\
    STAWnet~\cite{tian2021spatial}& 56.586& 48.155& 1.242& 9.289& 6.862& 0.739& 54.224& 45.982& 1.129& 15.397& 12.102& 1.128\\
    HastGCN~\cite{fu2021hierarchical} & 31.719& 20.372& 0.319& 8.421& 6.402& 1.272& 35.089& 23.333& 0.364& 11.509& 8.782& 1.210 \\
    AGWN~\cite{meng2022early} & 31.934& 20.720& 0.341& 10.840& 6.594& 0.874& 32.864& 22.391& 0.365& 11.730& 8.736& 0.743 \\
    DMSTGCN~\cite{han2021dynamic}& 31.555 & 20.342 & 0.319 & 10.638 & 7.784 & 0.880 & 29.810 & 20.263 & 0.312 & 12.929 & 9.846 & 0.791 \\
    Graph Wavelet~\cite{wu2019graph} & 31.880&20.415&0.320&10.489&7.672&0.861& 30.765&20.455&0.324& 14.093&10.807& 0.914 \\
    AGCRN~\cite{bai2020adaptive} & 31.253&20.363&0.319& 8.662&6.212&0.899& 30.905&20.652&0.324&12.808&9.093&1.172 \\
    \midrule
    STrans & 31.769& 20.382& 0.319& 9.458& 6.265& 0.896& 33.062& 22.087& 0.360& 11.917& 8.868& 0.632 \\
    No-Score & 67.537& 24.229& 0.338& 19.106& 7.042& 0.909& 33.636& 22.539& 0.373& 12.210& 8.917& 0.756 \\
    \textbf{DG-Trans} & \textbf{31.665}& \textbf{20.353}& \textbf{0.319}& \textbf{9.248}& \textbf{6.224}& \textbf{0.862}& \textbf{32.093}& \textbf{21.308}& \textbf{0.341}& \textbf{12.099}& \textbf{8.933}& \textbf{0.702} \\
    \bottomrule
  \end{tabular}
  \caption{\textbf{RMSE, MAE, and sMAPE for Duration and Impact Length Prediction of Incident-LA and Incident-SB.} The upper part is the performance of baselines. The lower part is the result of the ablation study, including our model without the S-Transformer, our model without the Importance Score Transformer, and the complete version of our model.}
  \label{tab:baseline}
\end{table*}

\subsection{Prediction Result Analysis}
The input to the models includes the adjacent matrices and sensor measurements
one hour before and half an hour after the validation time. The output is the
impact duration and length. We evaluated the duration and length separately
as they are of different units.

Table~\ref{tab:baseline} illustrates the performance of DG-Trans against the
baselines and itself with the critical module removed. 

\textbf{Conventional baselines.} For LASSO and SVR, the best performance is
 achieved with the closest upstream sensor and the first timestamp after the
 validation time as inputs. The results appeared to be insensitive to
 hyperparameters. As shown in Table~\ref{tab:baseline}, even though they
 produced competitive results in RMSE and MAE impact length prediction, LASSO
 and SVR performed poorly in impact duration prediction. Besides, the MAPE of
 length is much higher than most of the other models', which means that these
 two models made more mistakes in predicting low-impact lengths. This result
 matches our hypothesis that manually selecting the ``most relevant'' sensors
 and timestamps is not an optimal option. 

\textbf{Spatiotemporal neural network baselines.} For the other baselines,
 \ie, spatiotemporal neural networks, DG-Trans beats them in most of the
 metrics and shows competitive performance on the other metrics if it is not
 the best. Specifically, DG-Trans outperforms STAWnet by about 40\% in
 duration prediction and 10\% in length prediction. DG-Trans is also
 approximately 10\% better than STTN in Incident-LA duration and all length
 prediction tasks. HastGCN and AGWN show similar performance as our model,
 which means that the differences in performance are less than 5\% overall.
 This part of the experiments shows that models designed specifically for
 incidents (\ie, focus on locating incidents and denoising) perform better
 than models evenly treat every spatiotemporal feature.

\textbf{Ablation study.} Based on the lower part of Table~\ref
 {tab:baseline}, we can see that the Importance Score Transformer module is
 essential, as removing it leads to a huge performance drop. However,
 removing the S-Transformer module does not apparently affect the
 performance. The reason behind this is that the Importance Score Transformer
 module also extracts spatial information by assigning affected sensors
 higher scores. 

\subsection{Graph Attention Efficiency.} We also compared the execution time
 of S-Transformer with the same modules in the baselines. Based on our
 observation, HastGCN leverages three linear transformations to perform the
 attention while STTN and STAWnet utilize the vanilla attention mechanism. As
 suggested by Table~\ref{tab:pems_efficient}, S-Transformer executes $2$ to
 $5$ times faster than the vanilla attention and also faster than the linear
 transformation attention. 

The execution times of STAWnet on the two datasets are the same, as we cut off
some nodes from Incident-LA to remove the OOM issue. We also observe that the
execution time is not linearly related to the number of sensors in DG-Trans.
The reason is that the number of computations is also related to the number
of roads. As the numbers of roads are similar in the two datasets, the
execution times are the same as well.

\begin{table}[h]
\small
  \centering
  \begin{tabular}{cllll}
    \toprule
    Dataset & HastGCN & STTN & STAWnet & \textbf{DG-Trans} \\
    \midrule
    Incident-LA & 0.0021 & 0.0050 & 0.0080 & \textbf{0.0015}\\
    Incident-SB & 0.0019 & 0.0025 & 0.0080  & \textbf{0.0013}\\
    
  \bottomrule
\end{tabular}
  \caption{Average execution time of the graph attention module in second}
  \label{tab:pems_efficient}
\end{table}

\noindent
\textbf{Case Study.} To examine if our importance score truly helps to
 identify incidents, we explored some incident cases. One example is
 incident \#18693, as presented in Figure~\ref{fig:score}. The map plots the
 five-minute average speed right after the validation time and the importance
 scores within the same time slot. It is obvious that sensors that detect
 lower speeds are also of higher importance scores, while high importance
 scores cluster around the incident (red star). However, we also observe that
 incident-irrelevant speed drops also lead to high importance scores. This is
 why the model utilizes both the score and the embedded features for
 prediction.
\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/score_map2.jpg}
  \caption{\textbf{Case study of incident \#18693 on the Freeway I--10.} This is the map of an incident and the surrounding traffic loop sensors on I--10 in the Incident-LA dataset. The red star indicates the location of the incident, and the yellow--green--blue dots are sensors colored with speed measurements. The orange--red ``X''s indicate the importance scores assigned by DG-Trans. } % describe the architecture
  \label{fig:score}
\end{figure}

\noindent
\textbf{Beyond This Task.} We believe that the other parts of the dataset,
 \ie, the data not used in this paper, can be used to increase the
 prediction accuracy. However, we examined simple methods of merging the
 auxiliary information into the traffic network, such as adding an incident
 classification task, using road and sensor position for position encoding,
 and embedding incident metadata, while none of those methods worked. All of
 these attempts are also uploaded to our GitHub repository\footnote{\url{https://github.com/styxsys0927/DG-Trans.git}} for others to investigate.