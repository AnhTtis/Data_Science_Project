% !TEX root = ../main.tex
\section{Related Works}
\label{sec:related_works}


\noindent\textbf{Video Highlight Detection.} 
This task aims to identifying the interesting moments from untrimmed videos. 
In recent years, the videos studied for this task extend from domain-specific sport videos~\cite{Detectinghighlightsinsports} to general videos such as social media videos~\cite{RankingDomainspecificECCV2014}, news~\cite{TVSumCVPR2015}, first-person videos~\cite{HDPDCVPR2016} and vlog~\cite{QVHighlightsNIPS2021} . 
Most of previous works~\cite{Video2gifCVPR2016,HDPDCVPR2016,Threedimensional2018} interpret the video highlight detection task as a segment-level ranking problem. 
% They compare pairwise segments from same domain video in order to learn a model that assigns highlight scores to these segments which the highlight segments receive higher scores than the non-highlight segments.
They compare pairwise segments from same domain video in order to learn a model that assigns highlight scores to these segments where the highlight segments receive higher scores than the non-highlight segments. % rqiao 1111
% MINI-Net~\cite{MININetECCV2020} propose casting weakly supervised video highlight detection modeling for a given specific event as a multiple instance ranking network learning which  consider each video as a bag of segments to enforce a higher highlight score for a positive bag.
%MINI-Net~\cite{MININetECCV2020} propose casting highlight detection as a multiple instance ranking network learning.
MINI-Net~\cite{MININetECCV2020} proposes to cast highlight detection as multiple instance ranking network learning. % rqiao 1111
% CC[] explore the highlight detection problem through Unsupervised Domain Adaptation (UDA) [] in which one seeks to adapt the knowledge learned from the labeled source domain to the unlabeled target domain.
% SL-Module~\cite{CrosscategoryICCV2021} explore the highlight detection problem through Unsupervised Domain Adaptation (UDA) ~\cite{Asurvey2010} in which one can derive an effective highlight detector on target video category by transferring the highlight knowledge acquired from source video category to the target one.  
SL-Module~\cite{CrosscategoryICCV2021} explores the highlight detection problem through Unsupervised Domain Adaptation (UDA) ~\cite{Asurvey2010}.
UMT~\cite{UMTCVPR2022} integrates highlight detection and moment retrieval into a unified framework and conduct joint optimization.
% PLD~\cite{LearningPixelLevelCVPR2022} cast the video highlight detection into a new task: pixel-level distinction estimation which indicates whether or not each pixel in one video belongs to an interesting section.
% PLD~\cite{LearningPixelLevelCVPR2022} cast the video highlight detection into  pixel-level distinction estimation task.
PLD~\cite{LearningPixelLevelCVPR2022} models the video highlight detection into a  pixel-level distinction estimation task.
% In this work, we claim that  highlight detection should be regarded as learning with noisy labels.
% Due to the subjective nature of highlight moments, different annotators may be interested in different clips,  which bring noise to annotation.
% We propose to model the highlight detection task as Learning with Noisy Labels (LNL).
% Joint-VA~\cite{JointVisualandAudioICCV2021} also considers video highlight detection from the perspective of noise that introduces a noise sentinel that allows our model to “look-away” from a modality by attending to the noise sentinel instead.
In this work, we regard highlight detection as learning with noisy labels.
Joint-VA~\cite{JointVisualandAudioICCV2021} also considers video highlight detection from the perspective of noise.
However, it focuses on noise in features, such as videos having noisy audio when the microphone constantly has water splashing against it. 
% We focus on annotation noise which is specific in video highlight detection while feature noise is widespread existing in all video-understanding tasks.
We focus on specific annotation noise in video highlight detection. %while feature noise is widespread existing in all video-understanding tasks. % rqiao 1111

\noindent\textbf{Studies on Movies and Trailers.} 
% Studies on movies and trailers have been on increased interest in research.
Studies on movies and trailers have received increased attention in research. % rqiao 111
~\cite{MovieNetECCV2020} introduces a comprehensive dataset for movie understanding. 
~\cite{Learninglatent2014,MovieGraphsCVPR2018} try to model the relationships among the movie characters.
~\cite{LGSSCVPR2020,ShotContrastiveCVPR2021,SceneConsistencyCVPR2022} focus on breaking the storylines of movies into semantically cohesive parts.
% Besides the studies on movies, there are also efforts to develop trailer understanding.
Besides the studies on movies, efforts have been made to develop trailer understanding.
~\cite{Qualityevaluation2015} presents a movie summarization system and composes movie summaries in terms of user experience evaluation. 
~\cite{MMTF14KACM2018} designs a movie trailer dataset for the evaluation of video-based recommender systems.
% but it also supports the exploration of other multimedia tasks such as popularity prediction, genre classification, and auto-tagging.
~\cite{Fromtrailerstostorylines2018} is the first approach that bridges trailers and movies and allows knowledge learned from trailers to be transferred to full movie analysis.
In ~\cite{LeziWangECCV2020}, the visual module and the temporal analysis module are respectively trained on trailers and movies.
% ~\cite{LeziWangECCV2020} propose an alternative way to learn models for movie understanding, where the visual module and the temporal analysis module are respectively trained on trailers and movies, using meta-data and self-supervised learning. 
Because of the inaccessibility of public trailer-related benchmarks, we construct a new dataset (MovieLights) to detect the highlight moments in movies.
%

\noindent\textbf{Learning with Noisy Labels.} 
Learning with noisy labels has been a long-standing problem in computer vision.
% There are three main efforts for this problem.
There are three kinds of approaches to this problem. % rqiao
One of the most common strategies for tackling label noise is to capture the transition probabilities between noisy labels and clean labels~\cite{AreAnchorNIPS2019,ConfidentJAIR2019,PartdependentsNIPS2020,MetaLabelAAAI2021,EstimatingInstanceCVPR2022,PNPCVPR2022}.
Another solution is to design robust loss functions for model training against noisy labels~\cite{GCENIPS2018,SymmetricCrossEntropyICCV2019,DivideMixICLR2020,NormalizedLossICML2020,PeerLossICML2020,LearningwithinstancedependentICLR2021}.
% A popular method that deploys a pre-designed process to select clean samples or give lower weight for noise samples in training set to eliminate noise negative~\cite{ MentorNetICML2018,CoteachingNeurIPS2018,O2UNetICCV2019,AsymmetricCoTeachingAAAI2020,CombatingnoisylabelsCVPR2020,WeblySupervisedICCV2021}.
A popular method is to design a mechanism to select clean samples or give lower weight for noise samples in the training set to reduce impact of noise~\cite{ MentorNetICML2018,CoteachingNeurIPS2018,O2UNetICCV2019,AsymmetricCoTeachingAAAI2020,CombatingnoisylabelsCVPR2020,WeblySupervisedICCV2021}. % rqiao 1111
% In this paper, we try to solve the problem in terms of multi-modalities.
In this paper, we attempt to solve the problem by exploiting multi-modalities nature of movies.
% Specifically, we introduce a multi-modality cleaning (MMC) mechanism designed to filter out the noisy label which exploits audio-visual signals during training.
