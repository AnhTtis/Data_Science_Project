\section{Conclusions}\label{sec:conclus}

In this paper, we introduce a new task called freestyle layout-to-image synthesis (FLIS), which aims to generate unseen semantics described by text onto a given layout. To that end, we propose to leverage the generative prior from pre-trained text-to-image diffusion models. After inserting the proposed Rectified Cross-Attention (RCA) module, the pre-trained model is armed with the FLIS capability, breaking the in-distribution limit that hinders the applicability of previous LIS models. We demonstrate a plethora of applications by translating a single layout into high-fidelity images with a variety of novel semantics using our FreestyleNet.

\noindent\textbf{Acknowledgments.} \small{This work was funded by the Singapore MOE Academic Research Fund Tier 1 grant (MSS21C002). It was also supported by ``the Fundamental Research Funds for the Central Universities'', 111 Project, China under Grants B07022 and (Sheitc) 150633, and Shanghai Key Laboratory of Digital Media Processing and Transmissions, China. It was also funded by the A*STAR under its AME YIRG Grant (Project No.A20E6c0101).}