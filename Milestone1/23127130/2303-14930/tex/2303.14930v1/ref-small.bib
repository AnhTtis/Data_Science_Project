@Article{renFasterRCNNRealTime2017,
  author     = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  title      = {Faster {{R-CNN}}: {{Towards Real-Time Object Detection}} with {{Region Proposal Networks}}},
  doi        = {10/gc7rmb},
  issn       = {0162-8828, 2160-9292},
  number     = {6},
  pages      = {1137--1149},
  url        = {http://ieeexplore.ieee.org/document/7485869/},
  urldate    = {2021-06-21},
  volume     = {39},
  abstract   = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [7] and Fast R-CNN [5] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully-convolutional network that simultaneously predicts object bounds and objectness scores at each position. RPNs are trained end-to-end to generate highquality region proposals, which are used by Fast R-CNN for detection. With a simple alternating optimization, RPN and Fast R-CNN can be trained to share convolutional features. For the very deep VGG-16 model [19], our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007 (73.2\% mAP) and 2012 (70.4\% mAP) using 300 proposals per image. Code is available at https://github.com/ShaoqingRen/faster\_rcnn.},
  file       = {/home/david/Zotero/storage/ZDTJ9IU4/Ren et al. - 2017 - Faster R-CNN Towards Real-Time Object Detection w.pdf},
  journal    = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  langid     = {english},
  month      = jun,
  shorttitle = {Faster {{R-CNN}}},
  year       = {2017},
}

@InProceedings{linFeaturePyramidNetworks2017,
  author    = {Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  title     = {Feature {{Pyramid Networks}} for {{Object Detection}}},
  doi       = {10/gc7rk2},
  pages     = {936--944},
  abstract  = {Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But pyramid representations have been avoided in recent object detectors that are based on deep convolutional networks, partially because they are slow to compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A top-down architecture with lateral connections is developed for building high-level semantic feature maps at all scales. This architecture, called a Feature Pyramid Network (FPN), shows significant improvement as a generic feature extractor in several applications. Using a basic Faster R-CNN system, our method achieves state-of-the-art single-model results on the COCO detection benchmark without bells and whistles, surpassing all existing single-model entries including those from the COCO 2016 challenge winners. In addition, our method can run at 5 FPS on a GPU and thus is a practical and accurate solution to multi-scale object detection. Code will be made publicly available.},
  file      = {/home/david/onedrive-qut/Notes/Zotfiles/Lin et al_2017_Feature Pyramid Networks for Object Detection.pdf;/home/david/Zotero/storage/RJIKCZAJ/8099589.html},
  issn      = {1063-6919},
  keywords  = {Computer architecture,Detectors,Feature extraction,Object detection,Proposals,Robustness,Semantics},
  month     = jul,
  year      = {2017},
}

@InProceedings{dhamijaOverlookedElephantObject2020a,
  author     = {Dhamija, Akshay Raj and G{\"u}nther, Manuel and Ventura, Jonathan and Boult, Terrance E.},
  booktitle  = {2020 {{IEEE Winter Conference}} on {{Applications}} of {{Computer Vision}} ({{WACV}})},
  title      = {The {{Overlooked Elephant}} of {{Object Detection}}: {{Open Set}}},
  doi        = {10.1109/WACV45572.2020.9093355},
  pages      = {1010--1019},
  abstract   = {Even though object detection is a popular area of research that has found considerable applications in the real world, it has some fundamental aspects that have never been formally discussed and experimented. One of the core aspects of evaluating object detectors has been the ability to avoid false detections. While major datasets like PASCAL VOC or MSCOCO extensively test the detectors on their ability to avoid false positives, they do not differentiate between their closed-set and open-set performance. Despite systems being trained to reject everything other than the classes of interest, unknown objects from the open world end up being incorrectly detected as known objects, often with very high confidence. This paper is the first to formalize the problem of open-set object detection and propose the first open-set object detection protocol. Moreover, the paper provides a new evaluation metric to analyze the performance of some state-of-the-art detectors and discusses their performance differences.},
  file       = {/home/david/onedrive-qut/Notes/Zotfiles/Dhamija et al_2020_The Overlooked Elephant of Object Detection2.pdf;/home/david/Zotero/storage/R5LDZSHV/9093355.html},
  issn       = {2642-9381},
  keywords   = {Detectors,Object detection,Object recognition,Proposals,Protocols,Training,Training data},
  month      = mar,
  shorttitle = {The {{Overlooked Elephant}} of {{Object Detection}}},
  year       = {2020},
}

@InProceedings{linMicrosoftCOCOCommon2014,
  author     = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C. Lawrence},
  booktitle  = {Computer {{Vision}} \textendash{} {{ECCV}} 2014},
  title      = {Microsoft {{COCO}}: {{Common Objects}} in {{Context}}},
  doi        = {10/gfvksh},
  editor     = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
  isbn       = {978-3-319-10602-1},
  pages      = {740--755},
  publisher  = {{Springer International Publishing}},
  series     = {Lecture {{Notes}} in {{Computer Science}}},
  abstract   = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
  address    = {{Cham}},
  file       = {/home/david/onedrive-qut/Notes/Zotfiles/Lin et al_2014_Microsoft COCO.pdf},
  keywords   = {Common Object,Object Category,Object Detection,Object Instance,Scene Understanding},
  langid     = {english},
  shorttitle = {Microsoft {{COCO}}},
  year       = {2014},
}

@Article{frenchCatastrophicForgettingConnectionist1999,
  author   = {French, Robert M.},
  title    = {Catastrophic Forgetting in Connectionist Networks},
  doi      = {10.1016/S1364-6613(99)01294-2},
  issn     = {1364-6613},
  number   = {4},
  pages    = {128--135},
  url      = {https://www.sciencedirect.com/science/article/pii/S1364661399012942},
  urldate  = {2022-02-27},
  volume   = {3},
  abstract = {All natural cognitive systems, and, in particular, our own, gradually forget previously learned information. Plausible models of human cognition should therefore exhibit similar patterns of gradual forgetting of old information as new information is acquired. Only rarely does new learning in natural cognitive systems completely disrupt or erase previously learned information; that is, natural cognitive systems do not, in general, forget `catastrophically'. Unfortunately, though, catastrophic forgetting does occur under certain circumstances in distributed connectionist networks. The very features that give these networks their remarkable abilities to generalize, to function in the presence of degraded input, and so on, are found to be the root cause of catastrophic forgetting. The challenge in this field is to discover how to keep the advantages of distributed connectionist networks while avoiding the problem of catastrophic forgetting. In this article the causes, consequences and numerous solutions to the problem of catastrophic forgetting in neural networks are examined. The review will consider how the brain might have overcome this problem and will also explore the consequences of this solution for distributed connectionist networks.},
  file     = {/home/david/onedrive-qut/Notes/Zotfiles/French_1999_Catastrophic forgetting in connectionist networks.pdf},
  journal  = {Trends in Cognitive Sciences},
  keywords = {Catastrophic forgetting,Connectionism,Connectionist networks,Interference,Learning,Memory},
  langid   = {english},
  month    = apr,
  year     = {1999},
}

@InProceedings{hintonDistillingKnowledgeNeural2015a,
  author    = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeffrey},
  booktitle = {{{NIPS Deep Learning}} and {{Representation Learning Workshop}}},
  title     = {Distilling the {{Knowledge}} in a {{Neural Network}}},
  url       = {http://arxiv.org/abs/1503.02531},
  urldate   = {2022-11-12},
  file      = {/home/david/onedrive-qut/Notes/Zotfiles/Hinton et al_2015_Distilling the Knowledge in a Neural Network2.pdf},
  year      = {2015},
}

@Article{kirkpatrickOvercomingCatastrophicForgetting2017,
  author    = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and {Grabska-Barwinska}, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
  title     = {Overcoming Catastrophic Forgetting in Neural Networks},
  number    = {13},
  pages     = {3521--3526},
  url       = {http://arxiv.org/abs/1612.00796},
  urldate   = {2021-02-18},
  volume    = {114},
  abstract  = {The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Neural networks are not, in general, capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks which they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on the MNIST hand written digit dataset and by learning several Atari 2600 games sequentially.},
  file      = {/home/david/onedrive-qut/Notes/Zotfiles/Kirkpatrick et al_2017_Overcoming catastrophic forgetting in neural networks.pdf;/home/david/Zotero/storage/UX2FK96D/1612.html},
  ids       = {kirkpatrickOvercomingCatastrophicForgetting2017a},
  isbn      = {0027-8424},
  journal   = {Proceedings of the national academy of sciences},
  keywords  = {⛔ No DOI found,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  publisher = {{National Acad Sciences}},
  year      = {2017},
}

@Misc{maCATLoCalizationIdentificAtion2023,
  author        = {Ma, Shuailei and Wang, Yuefeng and Fan, Jiaqi and Wei, Ying and Li, Thomas H. and Liu, Hongli and Lv, Fanbing},
  title         = {{{CAT}}: {{LoCalization}} and {{IdentificAtion Cascade Detection Transformer}} for {{Open-World Object Detection}}},
  doi           = {10.48550/arXiv.2301.01970},
  eprint        = {arXiv:2301.01970},
  url           = {http://arxiv.org/abs/2301.01970},
  urldate       = {2023-03-08},
  abstract      = {Open-world object detection (OWOD), as a more general and challenging goal, requires the model trained from data on known objects to detect both known and unknown objects and incrementally learn to identify these unknown objects. The existing works which employ standard detection framework and fixed pseudo-labelling mechanism (PLM) have the following problems: (i) The inclusion of detecting unknown objects substantially reduces the model's ability to detect known ones. (ii) The PLM does not adequately utilize the priori knowledge of inputs. (iii) The fixed selection manner of PLM cannot guarantee that the model is trained in the right direction. We observe that humans subconsciously prefer to focus on all foreground objects and then identify each one in detail, rather than localize and identify a single object simultaneously, for alleviating the confusion. This motivates us to propose a novel solution called CAT: LoCalization and IdentificAtion Cascade Detection Transformer which decouples the detection process via the shared decoder in the cascade decoding way. In the meanwhile, we propose the self-adaptive pseudo-labelling mechanism which combines the model-driven with input-driven PLM and self-adaptively generates robust pseudo-labels for unknown objects, significantly improving the ability of CAT to retrieve unknown objects. Comprehensive experiments on two benchmark datasets, i.e., MS-COCO and PASCAL VOC, show that our model outperforms the state-of-the-art in terms of all metrics in the task of OWOD, incremental object detection (IOD) and open-set detection.},
  archiveprefix = {arxiv},
  file          = {/home/david/onedrive-qut/Notes/Zotfiles/Ma et al_2023_CAT.pdf;/home/david/Zotero/storage/3G7JUJUZ/2301.html},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition},
  month         = mar,
  number        = {arXiv:2301.01970},
  publisher     = {{arXiv}},
  shorttitle    = {{{CAT}}},
  year          = {2023},
}

@InProceedings{saito2022learning,
  author       = {Saito, Kuniaki and Hu, Ping and Darrell, Trevor and Saenko, Kate},
  booktitle    = {Computer {{Vision}}\textendash{{ECCV}} 2022: 17th European Conference, Tel Aviv, Israel, October 23\textendash 27, 2022, Proceedings, Part {{XXIV}}},
  title        = {Learning to Detect Every Thing in an Open World},
  organization = {{Springer}},
  pages        = {268--284},
  year         = {2022},
}

@InProceedings{millerEvaluatingMergingStrategies2019a,
  author    = {Miller, Dimity and Dayoub, Feras and Milford, Michael and S{\"u}nderhauf, Niko},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  title     = {Evaluating {{Merging Strategies}} for {{Sampling-based Uncertainty Techniques}} in {{Object Detection}}},
  doi       = {10.1109/ICRA.2019.8793821},
  pages     = {2348--2354},
  abstract  = {There has been a recent emergence of sampling-based techniques for estimating epistemic uncertainty in deep neural networks. While these methods can be applied to classification or semantic segmentation tasks by simply averaging samples, this is not the case for object detection, where detection sample bounding boxes must be accurately associated and merged. A weak merging strategy can significantly degrade the performance of the detector and yield an unreliable uncertainty measure. This paper provides the first in-depth investigation of the effect of different association and merging strategies. We compare different combinations of three spatial and two semantic affinity measures with four clustering methods for MC Dropout with a Single Shot Multi-Box Detector. Our results show that the correct choice of affinity-clustering combination can greatly improve the effectiveness of the classification and spatial uncertainty estimation and the resulting object detection performance. We base our evaluation on a new mix of datasets that emulate near open-set conditions (semantically similar unknown classes), distant open-set conditions (semantically dissimilar unknown classes) and the common closed-set conditions (only known classes).},
  file      = {/home/david/onedrive-qut/Notes/Zotfiles/Miller et al_2019_Evaluating Merging Strategies for Sampling-based Uncertainty Techniques in2.pdf;/home/david/Zotero/storage/T3IECEXI/8793821.html},
  issn      = {2577-087X},
  keywords  = {Clustering methods,Detectors,Measurement uncertainty,Object detection,Robots,Semantics,Uncertainty},
  month     = may,
  year      = {2019},
}

@Article{renClassincrementalObjectDetection,
  author   = {Ren, Sheng and He, Yan and Xiong, Neal N and Guo, Kehua},
  title    = {Towards {{Class-incremental Object Detection}} with {{Nearest Mean}} of {{Exemplars}}},
  pages    = {32},
  abstract = {Object detection has been widely used in the field of Internet, and deep learning plays a very important role in object detection. However, the existing object detection methods need to be trained in the static setting, which requires obtaining all the data at one time, and it does not support training in the way of class-incremental. In this paper, an object detection framework named class-incremental object detection (CIOD) is proposed. CIOD divides object detection into two stages. Firstly, the traditional OpenCV cascade classifier is improved in the object candidate box generation stage to meet the needs of class increment. Secondly, we use the concept of prototype vector on the basis of deep learning to train a classifier based on class-incremental to identify the generated object candidate box, so as to extract the real object box. A large number of experiments on CIOD have been carried out to verify that CIOD can detect the object in the way of class-incremental and can control the training time and memory capacity.},
  file     = {/home/david/Zotero/storage/DBPW94GG/Ren et al. - Towards Class-incremental Object Detection with Ne.pdf},
  langid   = {english},
}

@Misc{wu2019detectron2,
  author = {Wu, Yuxin and Kirillov, Alexander and Massa, Francisco and Lo, Wan-Yen and Girshick, Ross},
  title  = {Detectron2},
  url    = {https://github.com/facebookresearch/detectron2},
  year   = {2019},
}

@InProceedings{guptaOWDETROpenworldDetection2022,
  author     = {Gupta, Akshita and Narayan, Sanath and Joseph, K J and Khan, Salman and Khan, Fahad Shahbaz and Shah, Mubarak},
  booktitle  = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  title      = {{{OW-DETR}}: {{Open-world Detection Transformer}}},
  doi        = {10.1109/CVPR52688.2022.00902},
  isbn       = {978-1-66546-946-3},
  pages      = {9225--9234},
  publisher  = {{IEEE}},
  url        = {https://ieeexplore.ieee.org/document/9879305/},
  urldate    = {2022-10-20},
  abstract   = {Open-world object detection (OWOD) is a challenging computer vision problem, where the task is to detect a known set of object categories while simultaneously identifying unknown objects. Additionally, the model must incrementally learn new classes that become known in the next training episodes. Distinct from standard object detection, the OWOD setting poses significant challenges for generating quality candidate proposals on potentially unknown objects, separating the unknown objects from the background and detecting diverse unknown objects. Here, we introduce a novel end-to-end transformer-based framework, OW-DETR, for open-world object detection. The proposed OW-DETR comprises three dedicated components namely, attention-driven pseudo-labeling, novelty classification and objectness scoring to explicitly address the aforementioned OWOD challenges. Our OW-DETR explicitly encodes multi-scale contextual information, possesses less inductive bias, enables knowledge transfer from known classes to the unknown class and can better discriminate between unknown objects and background. Comprehensive experiments are performed on two benchmarks: MS-COCO and PASCAL VOC. The extensive ablations reveal the merits of our proposed contributions. Further, our model outperforms the recently introduced OWOD approach, ORE, with absolute gains ranging from 1.8\% to 3.3\% in terms of unknown recall on MS-COCO. In the case of incremental object detection, OW-DETR outperforms the state-of-theart for all settings on PASCAL VOC. Our code is available at https://github.com/akshitac8/OW-DETR.},
  address    = {{New Orleans, LA, USA}},
  annotation = {bibtex[ids=guptaOWDETROpenworldDetection2022a,guptaOWDETROpenworldDetection2022]},
  file       = {/home/david/onedrive-qut/Notes/Zotfiles/Gupta et al_2022_OW-DETR.pdf;/home/david/Zotero/storage/RJDQZZE6/Gupta et al. - 2022 - OW-DETR Open-world Detection Transformer.pdf;/home/david/Zotero/storage/YHYGTTK8/2112.html},
  keywords   = {Computer Science - Computer Vision and Pattern Recognition},
  langid     = {english},
  month      = jun,
  shorttitle = {{{OW-DETR}}},
  year       = {2022},
}

@InProceedings{tianFCOSFullyConvolutional2019,
  author     = {Tian, Zhi and Shen, Chunhua and Chen, Hao and He, Tong},
  booktitle  = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  title      = {{{FCOS}}: {{Fully Convolutional One-Stage Object Detection}}},
  pages      = {9627--9636},
  url        = {https://openaccess.thecvf.com/content_ICCV_2019/html/Tian_FCOS_Fully_Convolutional_One-Stage_Object_Detection_ICCV_2019_paper.html},
  urldate    = {2021-06-21},
  file       = {/home/david/onedrive-qut/Notes/Zotfiles/Tian et al_2019_FCOS.pdf;/home/david/Zotero/storage/T4ETLQTF/Tian_FCOS_Fully_Convolutional_One-Stage_Object_Detection_ICCV_2019_paper.html},
  shorttitle = {{{FCOS}}},
  year       = {2019},
}

@InProceedings{lampertIncrementalClassifierRepresentation,
  author    = {Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H.},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  title     = {{{iCaRL}}: {{Incremental Classifier}} and {{Representation Learning}}},
  isbn      = {1-5386-0457-4},
  pages     = {5533--5542},
  publisher = {{IEEE Computer Society}},
  file      = {/home/david/onedrive-qut/Notes/Zotfiles/Lampert_Incremental Classiﬁer and Representation Learning.pdf},
  keywords  = {⛔ No DOI found},
  year      = {2017},
}

@InProceedings{shmelkovIncrementalLearningObject2017,
  author    = {Shmelkov, Konstantin and Schmid, Cordelia and Alahari, Karteek},
  booktitle = {Proceedings of the {{IEEE}} International Conference on Computer Vision ({{ICCV}})},
  title     = {Incremental Learning of Object Detectors without Catastrophic Forgetting},
  urldate   = {2021-02-16},
  abstract  = {Despite their success for object detection, convolutional neural networks are ill-equipped for incremental learning, i.e., adapting the original model trained on a set of classes to additionally detect objects of new classes, in the absence of the initial training data. They suffer from "catastrophic forgetting" - an abrupt degradation of performance on the original set of classes, when the training objective is adapted to the new classes. We present a method to address this issue, and learn object detectors incrementally, when neither the original training data nor annotations for the original classes in the new training set are available. The core of our proposed solution is a loss function to balance the interplay between predictions on the new classes and a new distillation loss which minimizes the discrepancy between responses for old classes from the original and the updated networks. This incremental learning can be performed multiple times, for a new set of classes in each step, with a moderate drop in performance compared to the baseline network trained on the ensemble of data. We present object detection results on the PASCAL VOC 2007 and COCO datasets, along with a detailed empirical analysis of the approach.},
  file      = {/home/david/onedrive-qut/Notes/Zotfiles/Shmelkov et al_2017_Incremental Learning of Object Detectors without Catastrophic Forgetting.pdf;/home/david/Zotero/storage/7LLL3FJD/1708.html},
  ids       = {Shmelkov_2017_ICCV},
  keywords  = {⛔ No DOI found,Computer Science - Computer Vision and Pattern Recognition},
  month     = oct,
  year      = {2017},
}

@InProceedings{wu2022uc,
  author       = {Wu, Zhiheng and Lu, Yue and Chen, Xingyu and Wu, Zhengxing and Kang, Liwen and Yu, Junzhi},
  booktitle    = {Computer {{Vision}}\textendash{{ECCV}} 2022: 17th European Conference, Tel Aviv, Israel, October 23\textendash 27, 2022, Proceedings, Part {{X}}},
  title        = {{{UC-OWOD}}: {{Unknown-classified}} Open World Object Detection},
  organization = {{Springer}},
  pages        = {193--210},
  year         = {2022},
}

@InProceedings{josephOpenWorldObject2021,
  author        = {Joseph, K. J. and Khan, Salman and Khan, Fahad Shahbaz and Balasubramanian, Vineeth N.},
  booktitle     = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  title         = {Towards {{Open World Object Detection}}},
  eprint        = {2103.02603},
  pages         = {5830--5840},
  url           = {http://arxiv.org/abs/2103.02603},
  urldate       = {2021-06-27},
  abstract      = {Humans have a natural instinct to identify unknown object instances in their environments. The intrinsic curiosity about these unknown instances aids in learning about them, when the corresponding knowledge is eventually available. This motivates us to propose a novel computer vision problem called: `Open World Object Detection', where a model is tasked to: 1) identify objects that have not been introduced to it as `unknown', without explicit supervision to do so, and 2) incrementally learn these identified unknown categories without forgetting previously learned classes, when the corresponding labels are progressively received. We formulate the problem, introduce a strong evaluation protocol and provide a novel solution, which we call ORE: Open World Object Detector, based on contrastive clustering and energy based unknown identification. Our experimental evaluation and ablation studies analyze the efficacy of ORE in achieving Open World objectives. As an interesting by-product, we find that identifying and characterizing unknown instances helps to reduce confusion in an incremental object detection setting, where we achieve state-of-the-art performance, with no extra methodological effort. We hope that our work will attract further research into this newly identified, yet crucial research direction.},
  archiveprefix = {arxiv},
  file          = {/home/david/onedrive-qut/Notes/Zotfiles/Joseph et al_2021_Towards Open World Object Detection2.pdf;/home/david/Zotero/storage/VN56M2T5/2103.html},
  ids           = {josephOpenWorldObject2021b},
  keywords      = {⛔ No DOI found,Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  year          = {2021},
}

@Misc{zoharPROBProbabilisticObjectness2022,
  author        = {Zohar, Orr and Wang, Kuan-Chieh and Yeung, Serena},
  title         = {{{PROB}}: {{Probabilistic Objectness}} for {{Open World Object Detection}}},
  doi           = {10.48550/arXiv.2212.01424},
  eprint        = {arXiv:2212.01424},
  url           = {http://arxiv.org/abs/2212.01424},
  urldate       = {2023-03-08},
  abstract      = {Open World Object Detection (OWOD) is a new and challenging computer vision task that bridges the gap between classic object detection (OD) benchmarks and object detection in the real world. In addition to detecting and classifying seen/labeled objects, OWOD algorithms are expected to detect novel/unknown objects - which can be classified and incrementally learned. In standard OD, object proposals not overlapping with a labeled object are automatically classified as background. Therefore, simply applying OD methods to OWOD fails as unknown objects would be predicted as background. The challenge of detecting unknown objects stems from the lack of supervision in distinguishing unknown objects and background object proposals. Previous OWOD methods have attempted to overcome this issue by generating supervision using pseudo-labeling - however, unknown object detection has remained low. Probabilistic/generative models may provide a solution for this challenge. Herein, we introduce a novel probabilistic framework for objectness estimation, where we alternate between probability distribution estimation and objectness likelihood maximization of known objects in the embedded feature space - ultimately allowing us to estimate the objectness probability of different proposals. The resulting Probabilistic Objectness transformer-based open-world detector, PROB, integrates our framework into traditional object detection models, adapting them for the open-world setting. Comprehensive experiments on OWOD benchmarks show that PROB outperforms all existing OWOD methods in both unknown object detection (\$\textbackslash sim 2\textbackslash times\$ unknown recall) and known object detection (\$\textbackslash sim 10\textbackslash\%\$ mAP). Our code will be made available upon publication at https://github.com/orrzohar/PROB.},
  archiveprefix = {arxiv},
  file          = {/home/david/onedrive-qut/Notes/Zotfiles/Zohar et al_2022_PROB.pdf;/home/david/Zotero/storage/VP4JCQTA/2212.html},
  keywords      = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  month         = dec,
  number        = {arXiv:2212.01424},
  publisher     = {{arXiv}},
  shorttitle    = {{{PROB}}},
  year          = {2022},
}

@InProceedings{wuTwobranchObjectnesscentricOpen2022,
  author    = {Wu, Yan and Zhao, Xiaowei and Ma, Yuqing and Wang, Duorui and Liu, Xianglong},
  booktitle = {Proceedings of the 3rd {{International Workshop}} on {{Human-Centric Multimedia Analysis}}},
  title     = {Two-Branch {{Objectness-centric Open World Detection}}},
  doi       = {10.1145/3552458.3556453},
  isbn      = {978-1-4503-9492-5},
  pages     = {35--40},
  publisher = {{Association for Computing Machinery}},
  series    = {{{HCMA}} '22},
  url       = {https://doi.org/10.1145/3552458.3556453},
  urldate   = {2023-03-08},
  abstract  = {In recent years, with the development of deep learning, object detection has made great progress and has been widely used in many tasks. However, the previous models are all performed on closed sets, while there are many unknown categories in the real open world. Directly applying a model trained on known categories to the unknown classes will lead to misclassification. In this paper, we propose a two-branch objectness-centric open world object detection framework consisting of the bias-guided detector and the objectness-centric calibrator to effectively capture the objectness of both known and unknown instances and make the accurate prediction for known classes. The bias-guided detector trained with the known labels can predict the classes and boxes for known classes accurately. While the objectness-centric calibrator can localize the instances of any class, and does not affect the classification and regression of known classes. In the inference stage, we use the objectness-centric affirmation to confirm the results for known classes and predict the unknown instances. Comprehensive experiments conducted on the open world object detection benchmark validate the effectiveness of our method compared to state-of-the-art open world object detection approaches.},
  address   = {{New York, NY, USA}},
  file      = {/home/david/onedrive-qut/Notes/Zotfiles/Wu et al_2022_Two-branch Objectness-centric Open World Detection.pdf},
  keywords  = {object detection,objectness-centric affirmation,objectness-centric calibrator,open world},
  month     = oct,
  year      = {2022},
}

@Misc{pengSIDIncrementalLearning2020,
  author        = {Peng, Can and Zhao, Kun and Maksoud, Sam and Li, Meng and Lovell, Brian C.},
  title         = {{{SID}}: {{Incremental Learning}} for {{Anchor-Free Object Detection}} via {{Selective}} and {{Inter-Related Distillation}}},
  eprint        = {arXiv:2012.15439},
  url           = {http://arxiv.org/abs/2012.15439},
  urldate       = {2022-09-25},
  abstract      = {Incremental learning requires a model to continually learn new tasks from streaming data. However, traditional fine-tuning of a well-trained deep neural network on a new task will dramatically degrade performance on the old task -- a problem known as catastrophic forgetting. In this paper, we address this issue in the context of anchor-free object detection, which is a new trend in computer vision as it is simple, fast, and flexible. Simply adapting current incremental learning strategies fails on these anchor-free detectors due to lack of consideration of their specific model structures. To deal with the challenges of incremental learning on anchor-free object detectors, we propose a novel incremental learning paradigm called Selective and Inter-related Distillation (SID). In addition, a novel evaluation metric is proposed to better assess the performance of detectors under incremental learning conditions. By selective distilling at the proper locations and further transferring additional instance relation knowledge, our method demonstrates significant advantages on the benchmark datasets PASCAL VOC and COCO.},
  archiveprefix = {arxiv},
  file          = {/home/david/onedrive-qut/Notes/Zotfiles/Peng et al_2020_SID.pdf;/home/david/Zotero/storage/HSFMAYV6/2012.html},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition},
  month         = dec,
  number        = {arXiv:2012.15439},
  publisher     = {{arXiv}},
  shorttitle    = {{{SID}}},
  year          = {2020},
}

@Article{liuIncDetDefenseElastic2020,
  author     = {Liu, Liyang and Kuang, Zhanghui and Chen, Yimin and Xue, Jing-Hao and Yang, Wenming and Zhang, Wayne},
  title      = {{{IncDet}}: {{In Defense}} of {{Elastic Weight Consolidation}} for {{Incremental Object Detection}}},
  doi        = {10/gk79qx},
  issn       = {2162-2388},
  pages      = {1--14},
  abstract   = {Elastic weight consolidation (EWC) has been successfully applied for general incremental learning to overcome the catastrophic forgetting issue. It adaptively constrains each parameter of the new model not to deviate much from its counterpart in the old model during fine-tuning on new class data sets, according to its importance weight for old tasks. However, the previous study demonstrates that it still suffers from catastrophic forgetting when directly used in object detection. In this article, we show EWC is effective for incremental object detection if with critical adaptations. First, we conduct controlled experiments to identify two core issues why EWC fails if trivially applied to incremental detection: 1) the absence of old class annotations in new class images makes EWC misclassify objects of old classes in these images as background and 2) the quadratic regularization loss in EWC easily leads to gradient explosion when balancing old and new classes. Then, based on the abovementioned findings, we propose the corresponding solutions to tackle these issues: 1) utilize pseudobounding box annotations of old classes on new data sets to compensate for the absence of old class annotations and 2) adopt a novel Huber regularization instead of the original quadratic loss to prevent from unstable training. Finally, we propose a general EWC-based incremental object detection framework and implement it under both Fast R-CNN and Faster R-CNN, showing its flexibility and versatility. In terms of either the final performance or the performance drop with respect to the upper bound of joint training on all seen classes, evaluations on the PASCAL VOC and COCO data sets show that our method achieves a new state of the art.},
  file       = {/home/david/onedrive-qut/Notes/Zotfiles/Liu et al_2020_IncDet.pdf;/home/david/Zotero/storage/T2FRKJW6/9127478.html},
  journal    = {IEEE Transactions on Neural Networks and Learning Systems},
  keywords   = {Adaptation models,Annotations,Bayesian online learning,catastrophic forgetting,incremental detection,Object detection,object detection.,Predictive models,Task analysis,Training},
  shorttitle = {{{IncDet}}},
  year       = {2020},
}

@InProceedings{prabhuGDumbSimpleApproach2020,
  author     = {Prabhu, Ameya and Torr, Philip H. S. and Dokania, Puneet K.},
  booktitle  = {Computer {{Vision}} \textendash{} {{ECCV}} 2020},
  title      = {{{GDumb}}: {{A Simple Approach}} That {{Questions Our Progress}} in {{Continual Learning}}},
  doi        = {10/ghnnbk},
  editor     = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},
  isbn       = {978-3-030-58536-5},
  pages      = {524--540},
  publisher  = {{Springer International Publishing}},
  series     = {Lecture {{Notes}} in {{Computer Science}}},
  abstract   = {We discuss a general formulation for the Continual Learning (CL) problem for classification\textemdash a learning task where a stream provides samples to a learner and the goal of the learner, depending on the samples it receives, is to continually upgrade its knowledge about the old classes and learn new ones. Our formulation takes inspiration from the open-set recognition problem where test scenarios do not necessarily belong to the training distribution. We also discuss various quirks and assumptions encoded in recently proposed approaches for CL. We argue that some oversimplify the problem to an extent that leaves it with very little practical importance, and makes it extremely easy to perform well on. To validate this, we propose GDumb that (1) greedily stores samples in memory as they come and; (2) at test time, trains a model from scratch using samples only in the memory. We show that even though GDumb is not specifically designed for CL problems, it obtains state-of-the-art accuracies (often with large margins) in almost all the experiments when compared to a multitude of recently proposed algorithms. Surprisingly, it outperforms approaches in CL formulations for which they were specifically designed. This, we believe, raises concerns regarding our progress in CL for classification. Overall, we hope our formulation, characterizations and discussions will help in designing realistically useful CL algorithms, and GDumb will serve as a strong contender for the same.},
  address    = {{Cham}},
  file       = {/home/david/onedrive-qut/Notes/Zotfiles/Prabhu et al_2020_GDumb.pdf},
  keywords   = {Baseline,Class Incremental,Classification,Continual learning},
  langid     = {english},
  shorttitle = {{{GDumb}}},
  year       = {2020},
}

@InProceedings{dhamijaOverlookedElephantObject2020,
  author     = {Dhamija, Akshay Raj and G{\"u}nther, Manuel and Ventura, Jonathan and Boult, Terrance E.},
  booktitle  = {2020 {{IEEE Winter Conference}} on {{Applications}} of {{Computer Vision}} ({{WACV}})},
  title      = {The {{Overlooked Elephant}} of {{Object Detection}}: {{Open Set}}},
  doi        = {10/gk79q9},
  pages      = {1010--1019},
  abstract   = {Even though object detection is a popular area of research that has found considerable applications in the real world, it has some fundamental aspects that have never been formally discussed and experimented. One of the core aspects of evaluating object detectors has been the ability to avoid false detections. While major datasets like PASCAL VOC or MSCOCO extensively test the detectors on their ability to avoid false positives, they do not differentiate between their closed-set and open-set performance. Despite systems being trained to reject everything other than the classes of interest, unknown objects from the open world end up being incorrectly detected as known objects, often with very high confidence. This paper is the first to formalize the problem of open-set object detection and propose the first open-set object detection protocol. Moreover, the paper provides a new evaluation metric to analyze the performance of some state-of-the-art detectors and discusses their performance differences.},
  file       = {/home/david/Zotero/storage/MKAHFE8N/9093355.html},
  issn       = {2642-9381},
  keywords   = {Detectors,Object detection,Object recognition,Proposals,Protocols,Training,Training data},
  month      = mar,
  shorttitle = {The {{Overlooked Elephant}} of {{Object Detection}}},
  year       = {2020},
}

@InProceedings{millerDropoutSamplingRobust2018,
  author    = {Miller, Dimity and Nicholson, Lachlan and Dayoub, Feras and S{\"u}nderhauf, Niko},
  booktitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  title     = {Dropout Sampling for Robust Object Detection in Open-Set Conditions},
  doi       = {10/ghsxh2},
  pages     = {3243--3249},
  publisher = {{IEEE}},
  file      = {/home/david/Zotero/storage/UHRVGAE5/8460700.html},
  year      = {2018},
}

@Article{millerUncertaintyIdentifyingOpenSet2022,
  author   = {Miller, Dimity and S{\"u}nderhauf, Niko and Milford, Michael and Dayoub, Feras},
  title    = {Uncertainty for {{Identifying Open-Set Errors}} in {{Visual Object Detection}}},
  doi      = {10.1109/LRA.2021.3123374},
  issn     = {2377-3766},
  number   = {1},
  pages    = {215--222},
  volume   = {7},
  abstract = {Deployed into an open world, object detectors are prone to open-set errors, false positive detections of object classes not present in the training dataset.We propose GMM-Det, a real-time method for extracting epistemic uncertainty from object detectors to identify and reject open-set errors. GMM-Det trains the detector to produce a structured logit space that is modelled with class-specific Gaussian Mixture Models. At test time, open-set errors are identified by their low log-probability under all Gaussian Mixture Models. We test two common detector architectures, Faster R-CNN and RetinaNet, across three varied datasets spanning robotics and computer vision. Our results show that GMM-Det consistently outperforms existing uncertainty techniques for identifying and rejecting open-set detections, especially at the low-error-rate operating point required for safety-critical applications. GMM-Det maintains object detection performance, and introduces only minimal computational overhead. We also introduce a methodology for converting existing object detection datasets into specific open-set datasets to evaluate open-set performance in object detection.},
  file     = {/home/david/onedrive-qut/Notes/Zotfiles/Miller et al_2022_Uncertainty for Identifying Open-Set Errors in Visual Object Detection.pdf;/home/david/Zotero/storage/Q7YH359B/9591346.html},
  journal  = {IEEE Robotics and Automation Letters},
  keywords = {deep learning for visual perception,Detectors,Gaussian mixture model,Object detection,Object detection; segmentation and categorization,Semantics,Statistics,Training,Uncertainty},
  month    = jan,
  year     = {2022},
}

@Article{kimLearningOpenWorldObject2022,
  author   = {Kim, Dahun and Lin, Tsung-Yi and Angelova, Anelia and Kweon, In So and Kuo, Weicheng},
  title    = {Learning {{Open-World Object Proposals Without Learning}} to {{Classify}}},
  doi      = {10.1109/LRA.2022.3146922},
  issn     = {2377-3766},
  number   = {2},
  pages    = {5453--5460},
  volume   = {7},
  abstract = {Object proposals have become an integral pre-processing step of many vision pipelines including object detection, weakly supervised detection, object discovery, tracking, etc. Compared to the learning-free methods, learning-based proposals have become popular recently due to the growing interest in object detection. The common paradigm is to learn object proposals from data labeled with a set of object regions and their corresponding categories. However, this approach often struggles with novel objects in the open world that are absent in the training set. In this letter, we identify that the problem is that the binary classifiers in existing proposal methods tend to overfit to the training categories. Therefore, we propose a classification-free Object Localization Network (OLN) which estimates the objectness of each region purely by how well the location and shape of a region overlap with any ground-truth object (e.g., centerness and IoU). This strategy learns generalizable objectness and outperforms existing proposals on cross-category generalization on COCO. We further explore more challenging cross-dataset generalization onto RoboNet and EpicKitchens dataset, and long-tail detection on LVIS dataset. We demonstrate clear improvement over the state-of-the-art object detectors and object proposers. The code is publicly available at https://github.com/mcahny/object\_localization\_network.},
  file     = {/home/david/onedrive-qut/Notes/Zotfiles/Kim et al_2022_Learning Open-World Object Proposals Without Learning to Classify.pdf;/home/david/Zotero/storage/K5PPGSAY/9697381.html},
  journal  = {IEEE Robotics and Automation Letters},
  keywords = {Detectors,Location awareness,Object detection,Open-world detection/segmentation,Proposals,Standards,Training,Visualization},
  month    = apr,
  year     = {2022},
}

@InProceedings{wang2022open,
  author    = {Wang, Weiyao and Feiszli, Matt and Wang, Heng and Malik, Jitendra and Tran, Du},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF}} Conference on Computer Vision and Pattern Recognition},
  title     = {Open-World Instance Segmentation: {{Exploiting}} Pseudo Ground Truth from Learned Pairwise Affinity},
  pages     = {4422--4432},
  year      = {2022},
}

@Article{everinghamPascalVisualObject2010,
  author    = {Everingham, Mark and Gool, Luc Van and Williams, Christopher K. I. and Winn, John and Zisserman, Andrew},
  title     = {The {{Pascal Visual Object Classes}} ({{VOC}}) {{Challenge}}},
  doi       = {10/cszzrf},
  issn      = {1573-1405},
  number    = {2},
  pages     = {303--338},
  url       = {https://link.springer.com/article/10.1007/s11263-009-0275-4},
  urldate   = {2021-06-21},
  volume    = {88},
  abstract  = {The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection.This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension.},
  copyright = {2009 Springer Science+Business Media, LLC},
  file      = {/home/david/onedrive-qut/Notes/Zotfiles/Everingham et al_2010_The Pascal Visual Object Classes (VOC) Challenge.pdf;/home/david/Zotero/storage/ZQ942S2F/10.html},
  journal   = {International Journal of Computer Vision},
  langid    = {english},
  month     = jun,
  publisher = {{Springer US}},
  year      = {2010},
}

@Article{maltoniContinuousLearningSingleIncrementalTask2019,
  author        = {Maltoni, Davide and Lomonaco, Vincenzo},
  title         = {Continuous {{Learning}} in {{Single-Incremental-Task Scenarios}}},
  eprint        = {1806.08568},
  url           = {http://arxiv.org/abs/1806.08568},
  urldate       = {2021-09-21},
  abstract      = {It was recently shown that architectural, regularization and rehearsal strategies can be used to train deep models sequentially on a number of disjoint tasks without forgetting previously acquired knowledge. However, these strategies are still unsatisfactory if the tasks are not disjoint but constitute a single incremental task (e.g., class-incremental learning). In this paper we point out the differences between multi-task and single-incremental-task scenarios and show that well-known approaches such as LWF, EWC and SI are not ideal for incremental task scenarios. A new approach, denoted as AR1, combining architectural and regularization strategies is then specifically proposed. AR1 overhead (in term of memory and computation) is very small thus making it suitable for online learning. When tested on CORe50 and iCIFAR-100, AR1 outperformed existing regularization strategies by a good margin.},
  archiveprefix = {arxiv},
  file          = {/home/david/onedrive-qut/Notes/Zotfiles/Maltoni_Lomonaco_2019_Continuous Learning in Single-Incremental-Task Scenarios2.pdf;/home/david/Zotero/storage/CBPKECWT/1806.html},
  journal       = {arXiv:1806.08568 [cs, stat]},
  keywords      = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  month         = jan,
  primaryclass  = {cs, stat},
  year          = {2019},
}

@Article{lopez-pazGradientEpisodicMemory2017,
  author        = {{Lopez-Paz}, David and Ranzato, Marc'Aurelio},
  title         = {Gradient {{Episodic Memory}} for {{Continual Learning}}},
  eprint        = {1706.08840},
  pages         = {6467--6476},
  url           = {http://arxiv.org/abs/1706.08840},
  urldate       = {2021-04-11},
  volume        = {30},
  abstract      = {One major obstacle towards AI is the poor ability of models to solve new problems quicker, and without forgetting previously acquired knowledge. To better understand this issue, we study the problem of continual learning, where the model observes, once and one by one, examples concerning a sequence of tasks. First, we propose a set of metrics to evaluate models learning over a continuum of data. These metrics characterize models not only by their test accuracy, but also in terms of their ability to transfer knowledge across tasks. Second, we propose a model for continual learning, called Gradient Episodic Memory (GEM) that alleviates forgetting, while allowing beneficial transfer of knowledge to previous tasks. Our experiments on variants of the MNIST and CIFAR-100 datasets demonstrate the strong performance of GEM when compared to the state-of-the-art.},
  archiveprefix = {arxiv},
  file          = {/home/david/onedrive-qut/Notes/Zotfiles/Lopez-Paz_Ranzato_2017_Gradient Episodic Memory for Continual Learning.pdf;/home/david/Zotero/storage/V4DTE5AN/1706.html},
  ids           = {lopez-pazGradientEpisodicMemory2017a},
  journal       = {Advances in neural information processing systems},
  keywords      = {⛔ No DOI found,Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  year          = {2017},
}
