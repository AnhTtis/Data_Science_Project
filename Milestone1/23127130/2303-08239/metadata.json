{
    "arxiv_id": "2303.08239",
    "paper_title": "Facilitating deep acoustic phenotyping: A basic coding scheme of infant vocalisations preluding computational analysis, machine learning and clinical reasoning",
    "authors": [
        "Tomas Kulvicius",
        "Sigrun Lang",
        "Claudius AA Widmann",
        "Nina Hansmann",
        "Daniel Holzinger",
        "Luise Poustka",
        "Dajie Zhang",
        "Peter B Marschik"
    ],
    "submission_date": "2023-03-14",
    "revised_dates": [
        "2025-02-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.SD",
        "eess.AS"
    ],
    "abstract": "Theoretical background: early verbal development is not yet fully understood, especially in its formative phase. Research question: can a reliable, easy-to-use coding scheme for the classification of early infant vocalizations be defined that is applicable as a basis for further analysis of language development? Methods: in a longitudinal study of 45 neurotypical infants, we analyzed vocalizations of the first 4 months of life. Audio segments were assigned to 5 classes: (1) Voiced and (2) Voiceless vocalizations; (3) Defined signal; (4) Non-target; (5) Nonassignable. Results: Two female coders with different experience achieved high agreement without intensive training. Discussion and Conclusion: The reliable scheme can be used in research and clinical settings for efficient coding of infant vocalizations, as a basis for detailed manual and machine analyses.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.08239v1"
    ],
    "publication_venue": "This paper is in German",
    "doi": "10.1026/0942-5403/a000418"
}