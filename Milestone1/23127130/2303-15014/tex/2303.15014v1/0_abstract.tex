\begin{abstract}
Dramatic demand for manpower to label pixel-level annotations triggered the advent of unsupervised semantic segmentation.
Although the recent work employing the vision transformer~(ViT) backbone shows exceptional performance, there is still a lack of consideration for task-specific training guidance and local semantic consistency.
% However, as it is challenging to capture pixel-level semantics from the scratch, currently, the use of a vision transformer~(VIT) backbone is showing exceptional performance.
% In this paper, thus, we present a novel approach to use pretrained weights as the positive set miner for the contrastive objective.
% Specifically, we utilize the inferred positive set to learn rich semantic relationships and ensure semantic consistency in the local regions.
To tackle these issues, we leverage contrastive learning by excavating hidden positives to learn rich semantic relationships and ensure semantic consistency in local regions.
Specifically, we first discover two types of global hidden positives, task-agnostic and task-specific ones for each anchor based on the feature similarities defined by a fixed pre-trained backbone and a segmentation head-in-training, respectively.
% Specifically, we first discover two types of global hidden positives based on task-agnostic and task-specific reference pools.
% Task-agnostic reference pool initially guides the model to search for the global hidden positives for each anchor patch, and the task-specific reference pool serves the same role as training proceeds.
A gradual increase in the contribution of the latter induces the model to capture task-specific semantic features.
% \textcolor{blue}{
% Likewise, a gradual increase in engagement of task-specific positives lets the training to be stable.
% }
% Therefore, as training progresses, positive samples for each anchor are gradually more utilized for learning.
In addition, we introduce a gradient propagation strategy to learn semantic consistency between adjacent patches, under the inherent premise that nearby patches are highly likely to possess the same semantics.
Specifically,
% to ensure the model learns the tendency of semantically consistent along the local patches, 
we add the loss propagating to local hidden positives, semantically similar nearby patches, in proportion to the predefined similarity scores.
With these training schemes, our proposed method achieves new state-of-the-art~(SOTA) results in COCO-stuff, Cityscapes, and Potsdam-3 datasets.
Our code is available at: \href{https://github.com/hynnsk/HP}{https://github.com/hynnsk/HP}.
% Our exhaustive experiments validate the merits of employing the pretrained model to provide the initial training direction and learning semantic consistency.
\end{abstract}

