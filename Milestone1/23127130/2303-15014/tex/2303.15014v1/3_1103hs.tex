\section{Method}
% [preliminary]
%: contrastive loss 소개

% [external hidden positive 구하기]
% positive가 많으면 뭐가 좋은데 기존에는 하나만쓴다
% pseudo positive 고르는법
% additional positive도 구하기

% [이걸로 contrastive learning ]
% loss function

% [inner positive]
%: backward 할 시 inner positive
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% [inner positive 구하기]
% locality가 이러이러하다 고려해야된다. 기존에는 고려안했다
% inner positive 구하는법

% [앞에 구한거들로 contrastive loss function + gradient propagation]
% loss function 선언하기
% backward할때 inner locality 고려하기
% (weighted mean으로 똑같은 loss 구하는거임)

In this section, we introduce how we discover hidden positive pairs and leverage these to improve the contrastive learning objective.
Particularly, as we compute the contrastive objective with the inferred global positives and ensure the locality by propagating the loss to the local positives, we sequentially illustrate the process; we describe global positive selection strategy, and locality-aware loss propagation in Sec.~\ref{sec_global_positive} and Sec.~\ref{sec_loss_propagation}, respectively.






% In this section, we introduce how we our locality-aware pseudo positive based contrastive learning which can help embedding features form semantic-preserving clusters.
% First, we introduce an elaborated pseudo positive selection strategy to formulate contrastive objective in Sec.~\ref{sec_contrastive_loss}. In Sec.~\ref{sec_loss_propagation}, we propose the gradient propagation strategy considering the local resemblance. Finally, we describe our final objective function and introduce a model architecture that can formulate the objective function relative to the task in Sec.~\ref{sec_model}.


\subsection{Preliminary.}
In unsupervised semantic segmentation, the model utilizes unlabeled image set $X=\{x_i\}_{i=1}^N$ where $N$ is the number of training data in the mini-batch. During training, feature extractor $\mathcal{F}$ extracts the general feature $f_i=\mathcal{F}(x_i)$, which is divided into $H*W$ patch features $f_{i,h,w}\in \mathbb{R}^{C}$.
Subsequently, segmentation model $\mathcal{S}$ extracts the corresponding segmentation feature $s_{i,h,w}\in \mathbb{R}^{K}$ and followed by the projection head $\mathcal{Z}$ to produce the projected vector $z_{i,h,w}$ to formulate contrastive loss function.

In self-supervised settings given the two arbitrary augmented data pair ($\dot{x}_i$, $\ddot{x}_i$) and the corresponding projected features ($\dot{z_i}$, $\ddot{z_i}$), the conventional contrastive loss~\cite{simclr} is defined as follows:
\begin{equation}
\label{eq_contrastive_loss}
    L^{\text{self}}_i = - \text{log} \frac{\text{exp}(\text{sim}(\dot{z_i},\ddot{z_i}) / \tau)}{\sum_{n=1}^{2N} \mathbbm{1}_{[n \neq i]} \text{exp}(\text{sim}(\dot{z_i},\ddot{z_i}) / \tau)},
\end{equation}
where the indicator function $\mathbbm{1}_{[n \neq i]}$ ensures the identical instance be ignored in negative set, $\tau$ denotes the scalar temperature parameter, and $\text{sim}(\cdot,\cdot)$ is cosine similarity between two vectors.


In the following, we introduce our objective function specialized in segmentation built upon the basis of contrastive loss.
Note that, we design the objective function on the patch-level features different from Eq~\ref{eq_contrastive_loss} that is formulated with image-level features.
For readability, we denote the patch-level as $*_i$ instead of $*_{i,h,w}$ in the rest of the paper.

 
\subsection{Global hidden positive}
\label{sec_global_positive}
% We tailor the contrastive loss to unsupervised semantic segmentation task by modeling patch-level objective function based on multiple pseudo positives, utilizing unsupervised pre-trained vision transformer~\cite{dino}.
% The main difference from the conventional contrastive loss is that we gather a positive set for each feature to learn semantic invariance instead of using a single positive to learn augmentation invariance.
As stated in Sec.~\ref{sec_introduction}, we model the patch-level objective function based on global hidden positives to tailor the contrastive loss to unsupervised semantic segmentation task.
To obtain the global hidden positive set, we construct a feature reference pool used to define whether the features throughout the mini-batch are global hidden positives.
% To this end, we first design a memory module in which stored features \textcolor{red}{naming} are used as criteria to threshold whether to be positive.
Specifically, we collect a certain amount of random patch features $\{f_{m}\}_{m=1}^{M}$ by forwarding the corresponding dataset through the feature extractor $\mathcal{F}$ and maintain them throughout the training, which being stored in the reference pool $Q$ as follows:
\begin{equation}
\label{eq_reference_pool}
    Q = \{q_m\}_{m=1}^{M},
\end{equation}
where $M$ is the number of patch features from $M$ random images, i.e., one patch feature per an image. This is to ensure the semantic randomness of stored features.
Thereby such features stored in the reference pool show prototypicality of data distribution.

In that order, we select the closest feature in the reference pool for each anchor feature to produce a reference point that is used as a criterion whether the features throughout the mini-batch to be the positive.
Based on the reference pool defined above, we compute the cosine similarity $c_{i}$ between the anchor feature $f_{i}$ and the closest features of the reference pool $Q$, to be the criterion whether to be positive as follows:
\begin{equation}
\label{eq_select_criterion}
    c_{i} = \max_{q_m\in Q} \text{sim}(q_m, f_{i}).
\end{equation}

After a reference point is designated, for each anchor, features within the mini-batch closer than the reference point are chosen to be global hidden positives.
Therefore, the global hidden positive set $P^{\text{pre}}_{i}$ for each anchor $f_{i}$ are defined as follows:
\begin{equation}
    P_{i}^{\text{pre}} = \{z_{j}\mid \text{sim}(f_{i}, f_{j}) < c_{i}\},
\end{equation}
where $f_{j}$ indicates different patch feature in mini-batch, and $z_j$ represents the projected vector obtained by forwarding $f_j$ through the segmentation model $\mathcal{S}$ and the projection head $\mathcal{Z}$ sequentially.
Accordingly, such distribution-awareness nature of the reference pool allows the global hidden positive set to be selected adaptively.
Therefore, the global hidden positive set $P_{i}^{\text{pre}}$ being contains semantically analogous features.
However, although one sample can be designated as positive by another sample, not entirely vice versa. Therefore, we enhance the quality of the global hidden positive set by making the conversion always true.
For each anchor $f_{i}$, we define extra global hidden positive set $P_{i}^{\text{extra}}$ that takes the samples designating the anchor as positive, which is defined as:
\begin{equation}
    P_{i}^{\text{extra}} = \{z_{j}\mid z_{i} \in P_{j} \}.
\end{equation}
Therefore, overall global hidden positive set $P_{i}$ for the anchor $f_{i}$ is defined by unifying $P_{i}^\text{extra}$ with the predefined global hidden positive set $P_{i}^{\text{pre}}$ as follows:
\begin{equation}
\label{eq_positive_f}
    P_{i} = P_{i}^{\text{pre}} \cup P_{i}^{\text{extra}}.
\end{equation}

However, although this reference pool built upon the features from unsupervised pretrained network can serve as an appropriate basis for positivity, this lacks task-specificity. 
We argue that the features of the segmentation model may have a deeper understanding of semantic similarity than those of task-agnostic feature extractor, thereby such intellectual features are obviously beneficial in selecting the global hidden positive set.
Therefore, along with the global hidden positive set defined in Eq~\ref{eq_positive_f}, we construct additional task-specific global hidden positive set based on the features from the segmentation model.
Specifically, task-specific global hidden positive set is constructed based on the features ${s^\prime}_i$ forwarded through momentum updated segmentation model ${\mathcal{S}^\prime}$, which guarantees the task-specificity and stability of the features~\cite{ema, sessd}.

To this end, we first construct additional data reference pool $Q^\prime$ storing the segmentation features $\{s_{m^\prime}^\prime\}_{m^\prime=1}^M$.
Then we carry out the same positive excavation process from Eq~\ref{eq_select_criterion} to Eq~\ref{eq_positive_f} by substituting using $f_i$ as $s^\prime_i$.
Accordingly, we define the task-specific global hidden positive set $P^\prime_i$.
Note that, the task-specific reference pool $Q^\prime$ keeps updating as the training progresses.


\subsection{Objective function}
\label{sec_objective_function}
Through our global hidden positive excavation process, the set $P_{i}$ and $P^\prime_i$ being contain semantically analogous features with $i$-th instance.
With the both sets, we thus, we expand the contrastive loss in Eq~\ref{eq_contrastive_loss} to formulate our objective function.
Meanwhile, the negative set $A_i$ is defined by random $\rho\%$ of the remaining samples in the mini-batch excluding the global hidden positive set. Since, though the representation capability improves as the size of the negative set for contrastive loss increases in self-supervised learning~\cite{moco}, too many negatives can disturb the model training for a particular task~\cite{eisnet}.

Given the above, therefore, the objective function is formulated with the projected vector $z_{i}$ of the anchor feature.
Under the task-agnostic global hidden positive set $P_i$, objective function for each anchor is formulated as follows:
\begin{equation}
\label{eq_contrastive_loss_global_task_agnostic}
    \hat{l}_{i}^{\text{global}} = \frac{-1}{|P_{i}|} \sum_{p=1}^{|P_{i}|} \text{log} \frac{\text{exp}(\text{sim}(z_{i},z_p) / \tau)}{\sum_{a=1}^{|A_{i}|} \text{exp}(\text{sim}(z_{i},z_a) / \tau)},
\end{equation}
where $z_p$ and $z_a$ are $p$-th positive sample in $P_i$ and $a$-th negative sample in $A_i$, respectively.

Likewise, additional objective function with task-specific global hidden positive set $P^\prime_i$ is formulated as follows:
\begin{equation}
\label{eq_contrastive_loss_global_task_specific}
    \tilde{l}_{i}^{\text{global}} = \frac{-1}{|P^\prime_{i}|} \sum_{p=1}^{|P^\prime_{i}|} \text{log} \frac{\text{exp}(\text{sim}(z_{i},z_p) / \tau)}{\sum_{a=1}^{|A^\prime_{i}|} \text{exp}(\text{sim}(z_{i},z_a) / \tau)}.
\end{equation}

% Meanwhile, rather than naively expanding the contrastive loss, we rather design our objective function more elaborately taking into account several challenges.
% % Although we can simply construct the contrastive loss using the predefined pseudo-positive set by reference to Eq.~\ref{eq_contrastive_loss}, we rather design our objective function more elaborately taking into account several challenges.
% Despite the beneficial effect of our data-driven hidden positive excavation strategy, a bias problem can occur in the scale of loss if the number of positive set for each anchor varies. We tackle this problem by loss re-weighting scheme~\cite{cui2019class} based on the number of positive samples, inspired by long-tailed learning~\cite{kubat1997addressing, cui2019class, lin2017focal, cao2019learning}.
% Therefore, before defining objective function, we set the weighting factor $\Phi_{i}$ to balance the scale of losses, defined as follows:
% \begin{equation}
%     \Phi_{i} = \frac{NHW |P_{i}|^\eta}{\sum_{i=1}^{NHW}|P_{i}|^\eta}.
% \end{equation}

In this way, the two objective functions are constructed under task-agnostic and task-specific global hidden positive sets, respectively.
Therefore, the overall objective function considering the both global hidden positive is defined by combining Eq~\ref{eq_contrastive_loss_global_task_agnostic} and Eq~\ref{eq_contrastive_loss_global_task_specific}.
\begin{equation}
\label{eq_contrastive_loss_global_overall}
    L_{i}^{\text{global}} = \hat{l}_{i}^{\text{global}} + \lambda \tilde{l}_{i}^{\text{global}},
\end{equation}
where $\lambda$ controls the contribution of the second term, which gradually increases from $0$ to $1$ throughout the training.
Note that, the samples with zero positive is excluded from training although this rarely exists.


\subsection{Gradient propagation to local hidden positive}
\label{sec_local_positive}
While learning from contrastive loss in Eq.~\ref{eq_contrastive_loss_global_overall} can be useful in forming patch-wise semantic-preserving clusters, there is a lack of explicit design considering locality.
In other words, we should consider the property of locality which is an inherent premise that nearby patches are highly likely to have analogous semantics.

To this end, we propagate the loss gradient to the surrounding patches in proportion to the corresponding attention score.
However, there should be no room for the possibility that the adjacent features with definitely different semantics have the same objective.
In other words, it can be harmful to have the same objective even if the corresponding attention score is very low.
Therefore, we neglect the harmful features having lower attention scores than the appropriate border from the periphery.

Given $z_{i}$, we first define a set of surrounding vectors $G_{i}$ as follows:
\begin{equation}
    G_{i}=\{g_{i}^{u}\}_{u=1}^{U}\cup \{z_{i}\}.
\end{equation}

In addition, for each anchor, by defining $\bar{T}_{i}$ as a set of attention score of all the H$\cdot$W patch features, we initialize the surrounding attention score $T_{i}$ corresponding to the surrounding vectors $G_{i}$ as follows:
\begin{equation}
    T_{i}=\{t_{i}^u\}^{U+1}_{u=1},
\end{equation}
where $U$ is the number of surrounding vectors.
Then, we filter out the harmful vectors by making the corresponding attention score zero, as follows:
\begin{equation}
    T_i := \{t_i^u \mid t_{i}^u<\text{Avg}(\text{Softmax}(\bar{T}_{i}))\}_{u=1}^{U+1}
\end{equation}
where Avg($\cdot$) indicates the function that averaging the global attention score.

Back to the point, to give the loss gradient to the surrounding vectors proportional to individual attention score, we obtain mixed vector $v_{i}$ that made by attentional average of the surrounding vectors calculated as:
\begin{equation}
    v_{i} = \frac{1}{U+1} \sum_{u=1}^{U+1} g_{i}^u t_{i}^u.
\end{equation}
Then, by simply substitute $z_{i}$ with the mixed vector $v_{i}$, we reformulate the Eq.~\ref{eq_contrastive_loss_global_task_agnostic} as follows:
\begin{equation}
\label{eq_contrastive_loss_local_tas_agnostic}
    l_{i}^{\text{local}} = \frac{-1}{|P_{i}|} \sum_{p=1}^{|P_{i}|} \text{log} \frac{\text{exp}(\text{sim}(v_{i},z_p) / \tau)}{\sum_{a=1}^{|A_{i}|} \text{exp}(\text{sim}(v_{i},z_a) / \tau)},
\end{equation}
% where $P_i$ and $A_i$ signify that it adopts the same positive and negative sets as the global hidden positive sets.
This objective function allows the surrounding vectors of $z_i$ to have the same objective as $z_i$.

Moreover, additional objective function $\tilde{l}_i^{local}$ with task-specific global hidden positive set $P^\prime_i$ is formulated in the same manner as Eq~\ref{eq_contrastive_loss_global_task_specific}, thereby the objective function for local hidden positive is defined as:
\begin{equation}
\label{eq_contrastive_loss_local_overall}
    L_{i}^{\text{local}} = \hat{l}_{i}^{\text{local}} + \lambda \tilde{l}_{i}^{\text{local}}.
\end{equation}

As a result, by combining Eq.~\ref{eq_contrastive_loss_global_overall}, overall objective function for a patch is described as follows:
\begin{equation}
\label{eq_contrastive_loss_all}
    {L}_{i} = L_{i}^{\text{global}} + L_{i}^{\text{local}}.
\end{equation}

% 근처애들 중 비슷한 semantic을 가진 애들을, 비슷한 정도만큼 같은 objective를 가해 주기 위해 local grouping을 수행한다.
% weight는 vision transformer 의 12 block의 attention map을 가져오는데 class token을 제외하고 softmax 를 취한다.
% 그리고 average보다 작은 애들은 0으로 버린다. 왜냐하면 우리는 average 보다 작은 애들을 다른 semantic을 가지고 있다고 가정하여 동일한 objective를 가하지 않도록 하기 위해서다.
% 식 ->
% 그러면 기존 크기와 같은 feauture가 만들어지는데, 각각의 instance는 주변부와의 weighted sum이다.
% notation: v
% 이를 가운데 instance의 positive negative set으로 contrastive learning을 수행한다.
% 식 ->
% 이를 통해 주변부에서 비슷한 semantic인 애들을 그만큼의 weight만큼 동일한 objective를 수행하도록 한다.
% 따라서 local resemblance를 유지하도록 학습이 된다.

% feature extractor, segmentation model 뭔지 써야함