\section{Preference-Aware Constrained Multi-Objective Bayesian Optimization}

The general strategy behind the BO process is to employ an acquisition function to iteratively select a candidate input (i.e., design parameters) to evaluate using the information provided by the surrogate models. The surrogate models are updated based on new training examples (design parameters as input, and evaluations of objectives and constraints from function evaluations as output). 

\noindent {\bf Overview of PAC-MOO.} PAC-MOO algorithm is an instance of the BO framework, which takes as input the input space $\mathfrak{X}$, preferences over objectives $p$, expensive objective functions and constraints evaluator, and produces a Pareto set of candidate inputs as per the preferences after $T$ iterations of PAC-MOO as shown in Algorithm \ref{alg:PAC-MOO}. In each iteration $t$, PAC-MOO selects a candidate input design $\vec{x}_t \in \mathfrak{X}$ to perform a function evaluation. Consequently, the surrogate models for both objective functions and constraints are updated based on training data from the function evaluations.

\subsection {Surrogate Modeling} 

Gaussian Processes (GPs) \cite{williams2006gaussian} are suitable for solving black-box optimization problems with expensive function evaluations since they are rich and flexible models which can mimic any complex objective function. Intuitively, two candidate design parameters that are close to each other will potentially exhibit approximately similar performance in terms of output objectives. We model the objective functions and black-box constraints by independent GP models $\mathcal{GP}_{f_1}, \cdots, \mathcal{GP}_{f_K}, \mathcal{GP}_{c_1}, \cdots, \mathcal{GP}_{c_K}$ with zero mean and i.i.d. observation noise. Let $\mathcal{D} = \{(\vec{x}_i, \vec{y}_i)\}_{i=1}^{t{-1}}$ be the training data from past $t{-1}$ function evaluations, where $\vec{x}_i \in \mathfrak{X}$ is a candidate design and $\vec{y}_i = \{y_{f_1}^i, \cdots, y_{f_K}^i, y_{c_1}^i, \cdots, y_{c_L}^i\}$ is the output vector resulting from evaluating the objective functions and constraints at $\vec{x}_i$.

\subsection{Acquisition Function}
\label{appendix_acq}

The state-of-the-art MESMO approach for solving MOO problems \cite{belakaria2019max} proposed to select the input that maximizes the information gain about the optimal {\bf Pareto front} for evaluation. However, this approach did not address the challenge of handling black-box constraints which can be evaluated only through expensive function evaluators. To overcome this challenge, MESMOC \cite{belakaria2020max} maximizes the information gain between the next candidate input for evaluation $\vec{x}$ and the optimal constrained Pareto front $\mathcal{Y}^*$:


\begin{align}
        \alpha(\vec{x}) &= I(\{\vec{x}, \vec{y}\}, \mathcal{Y}^* \mid D) = H(\vec{y} \mid D, \vec{x}) - \mathbb{E}_{\mathcal{Y}^*} [H(\vec{y} \mid D,   \vec{x}, \mathcal{Y}^*)] \label{eqn_symmetric_mesmo1}
\end{align}

In this case, the output vector $\vec{y}$ is $K+L$ dimensional: $\vec{y}$ = $(y_{f_1}, y_{f_2},\cdots,y_{f_K},y_{c_1} \cdots y_{c_L})$ where $y_{f_j} = f_j(x) \forall j \in \{1,2, \cdots, K\}$ and $y_{c_i}$ = $C_i(x)\forall i \in \{1,2, \cdots, L\}$.
Consequently, the first term in Equation (\ref{eqn_symmetric_mesmo1}), entropy of a factorizable $(K+L)$-dimensional Gaussian distribution $P(\vec{y}\mid D, \vec{x})$, can be computed in closed form as shown below:


\begin{align}
    H(\vec{y} \mid D, \vec{x}) = \frac{(K+C)(1+\ln(2\pi))}{2} +  \sum_{j = 1}^K  \ln (\sigma_{f_j}(\vec{x}))+  \sum_{i = 1}^L  \ln (\sigma_{c_i}(\vec{x})) \label{eqn_unconditioned_entropy1}
\end{align}

where $\sigma_{f_j}^2(\vec{x})$ and  $\sigma_{c_i}^2(\vec{x})$ are the predictive variances of $j^{th}$ function and $i^{th}$ constraint GPs respectively at input $\vec{x}$. The second term in Equation (\ref{eqn_symmetric_mesmo1}) is an expectation over the Pareto front $\mathcal{Y}^*$. We can approximately compute this term via Monte-Carlo sampling as shown below: 

% \vspace{-0.2cm}
\begin{align}
 \mathbb{E}_{\mathcal{Y}^*} [H(\vec{y} \mid D, \vec{x}, \mathcal{Y}^*)] \simeq \frac{1}{S} \sum_{s = 1}^S [H(\vec{y} \mid D, \vec{x}, \mathcal{Y}^*_s)] \label{eqn_summation}
\end{align}
% \vspace{-0.2cm}


where $S$ is the number of samples and $\mathcal{Y}^*_s$ denote a sample Pareto front. There are two key algorithmic steps to compute this part of the equation: 1) How to compute constrained Pareto front samples $\mathcal{Y}^*_s$?; and 2) How to compute the entropy with respect to a given constrained Pareto front sample $\mathcal{Y}^*_s$? We provide solutions for these two questions below.

\hspace{2.0ex} {\bf 1) Computing constrained Pareto front samples via cheap multi-objective optimization.} To compute a constrained Pareto front sample $\mathcal{Y}^*_s$, we first sample functions and constraints from the posterior GP models via random Fourier features \cite{PES,random_fourier_features} and then solve a cheap constrained multi-objective optimization over the $K$ sampled functions and $L$ sampled constraints.

\hspace{2.5ex}{\em Cheap MO solver.} We sample $\Tilde{f}_i$ from GP model $\mathcal{GP}_{f_j}$ for each of the $K$ functions and $\Tilde{C}_j$ from GP model $\mathcal{GP}_{c_j}$ for each of the $L$ constraints. A {\em cheap} constrained multi-objective optimization problem over the $K$ sampled functions  $\Tilde{f}_1,\Tilde{f}_2,\cdots,\Tilde{f}_k$ and the $L$ sampled constraints  $\Tilde{C}_1,\Tilde{C}_2,\cdots,\Tilde{C}_L$ is solved to compute the sample Pareto front $\mathcal{Y}^*_s$. Note that we refer to this optimization problem as cheap because it is performed over sampled functions and constraints, which are cheaper to evaluate than performing expensive function evaluations. We employ the popular constrained NSGA-II algorithm \cite{deb2002nsga,deb2002fast} to solve the constrained MO problem with cheap sampled objective functions and constraints.

\hspace{2.0ex}{\bf 2) Entropy computation with a sample constrained Pareto front.}
Let $\mathcal{Y}^*_s = \{\vec{v}^1, \cdots, \vec{v}^l \}$ be the sample constrained Pareto front,  where $l$ is the size of the Pareto front and each $\vec{v}^i$ is a $(K+L)$-vector evaluated at the $K$ sampled functions and $L$ sampled constraints $\vec{v}^i = \{v^i_{f_1},\cdots,v^i_{f_K},v^i_{c_1},\cdots,v^i_{c_L}\}$. The following inequality holds for each component $y_j$ of the $(K+L)$-vector $\vec{y} = \{y_{f_1},\cdots,y_{f_K},y_{c_1},\cdots y_{c_L}\}$ in the entropy term $H(\vec{y} \mid D,   \vec{x}, \mathcal{Y}^*_s)$:


% \vspace{-0.45cm}
\begin{align}
 y_j &\leq \max \{v^1_j, \cdots v^l_j \} \quad \forall j \in \{f_1,\cdots,f_K,c_1,\cdots,c_L\} \label{inequality1}
\end{align}
% \vspace{-0.35cm}

The inequality essentially says that the $j^{th}$ component of $\vec{y}$ (i.e., $y_j$) is upper-bounded by a value obtained by taking the maximum of $j^{th}$ components of all $l$ $(K+L)$-vectors in the Pareto front $\mathcal{Y}^*_s$. This inequality had been proven by a contradiction for MESMO \cite{belakaria2019max} for all objective functions $j \in \{f_1,\cdots,f_K\}$. We assume the same  for all constraints $j \in \{c_1,\cdots,c_L\}$.

By combining the inequality (\ref{inequality1}) and the fact that each function is modeled as an independent GP, we can approximate each component $y_j$ as a truncated Gaussian distribution since the distribution of $y_j$ needs to satisfy $ y_j \leq \max \{v^1_j, \cdots v^l_j \}$. Let $y_s^{c_i*} = \max \{v^1_{c_i}, \cdots v^l_{c_i} \}$ and $y_s^{f_j*} = \max \{v^1_{f_j}, \cdots v^l_{f_j} \}$. Furthermore, a common property of entropy measure allows us to decompose the entropy of a set of independent variables into a sum over entropies of individual variables \cite{information_theory}:

% \vspace{-0.1cm}
\begin{align}
H(\vec{y} \mid D,   \vec{x}, \mathcal{Y}^*_s) = \sum_{j=1}^K H(y_{f_j}|D, \vec{x}, y_s^{f_j*}) +\sum_{i=1}^L H(y_{c_i}|D, \vec{x}, y_s^{c_i*})  \label{eqn_sep_ineq1}
\end{align}
% \vspace{-ex}
The r.h.s is a summation over entropies of  $(K+L)$-variables $\vec{y} = \{y_{f_1},\cdots,y_{f_K},y_{c_1},\cdots y_{c_L}\}$.
The differential entropy for each $y_j$ is the entropy of a truncated Gaussian distribution \cite{entropy_handbook} and is given by the following equations:

\begin{align}
H(y_{f_j} \mid D, \vec{x}, y_s^{f_j*}) \simeq [\frac{(1 + \ln(2\pi))}{2}+  \ln(\sigma_{f_j}(\vec{x})) +  \ln \Phi(\gamma_s^{f_j}(\vec{x})) - \frac{\gamma_s^{f_j}(\vec{x}) \phi(\gamma_s^{f_j}(\vec{x}))}{2\Phi(\gamma_s^{f_j}(\vec{x}))}] \label{eqn_entropy_fj}
  \end{align}

\begin{align}
H(y_{c_i}|D, \vec{x}, y_s^{c_i*}) \simeq 
[\frac{(1 + \ln(2\pi))}{2}+  \ln(\sigma_{c_i}(\vec{x})) +  \ln \Phi(\gamma_s^{c_i}(\vec{x})) - \frac{\gamma_s^{c_i}(\vec{x}) \phi(\gamma_s^{c_i}(\vec{x}))}{2\Phi(\gamma_s^{c_i}(\vec{x}))}]    
    \label{eqn_entropy_cj}
\end{align} 

Consequently, we have: 
\begin{align}
    & H(\vec{y} \mid D,   \vec{x}, \mathcal{Y}^*_s) \simeq \nonumber
    \sum_{j=1}^K \left[\frac{(1 + \ln(2\pi))}{2}+  \ln(\sigma_{f_j}(\vec{x})) +  \ln \Phi(\gamma_s^{f_j}(\vec{x})) - \frac{\gamma_s^{f_j}(\vec{x}) \phi(\gamma_s^{f_j}(\vec{x}))}{2\Phi(\gamma_s^{f_j}(\vec{x}))}\right] \nonumber\\
& \hspace{2.0cm} + \sum_{i=1}^L \left[\frac{(1 + \ln(2\pi))}{2}+  \ln(\sigma_{c_i}(\vec{x})) +  \ln \Phi(\gamma_s^{c_i}(\vec{x})) - \frac{\gamma_s^{c_i}(\vec{x}) \phi(\gamma_s^{c_i}(\vec{x}))}{2\Phi(\gamma_s^{c_i}(\vec{x}))}\right]    
    \label{eqn_entropy_closed1}
\end{align}


where $\gamma_s^{c_i}(x) = \frac{y_s^{c_i*} - \mu_{c_i}(\vec{x})}{\sigma_{c_i}(\vec{x})}$, $\gamma_s^{f_j}(x) = \frac{y_s^{f_j*} - \mu_{f_j}(\vec{x})}{\sigma_{f_j}(\vec{x})}$, 
$\phi$ and $\Phi$ are the p.d.f and c.d.f of a standard normal distribution respectively. By combining equations (\ref{eqn_unconditioned_entropy1}) and (\ref{eqn_entropy_closed1}) with equation (\ref{eqn_symmetric_mesmo1}), we get the final form of our acquisition function as shown below:
\begin{align}
\alpha(\vec{x}) \simeq \sum_{i\in \mathcal{I}} AF(i,x) ~\text{with} ~ i \in \mathcal{I} ~\text{and} ~ \mathcal{I}=\{c_1 \cdots c_L,f_1 \cdots f_K\} \label{eqn_final1} 
\end{align} 

And 
\begin{equation}
    AF(i,x)= \sum_{s=1}^S \frac{\gamma_s^{i}(\vec{x}) \phi(\gamma_s^{i}(\vec{x}))}{2\Phi(\gamma_s^{i}(\vec{x}))} - \ln \Phi(\gamma_s^{i}(\vec{x})) \label{component_mes}
\end{equation}


\subsection{Convex Combination for Preferences} \label{convex_preference}

We now describe how to incorporate preference specification (when available) into the acquisition function. The derivation of the acquisition function proposed in Equation \ref{eqn_final1} resulted in a function in the form of a summation of an entropy term defined for each of the objective functions and constraints as $AF(i,x)$. Given this expression, the algorithm will select an input while giving the same importance to each of the functions and constraints. However, as an example, in problems such as circuit design optimization, efficiency is typically the most important objective function. The designer would like to find a trade-off between the objectives. Nevertheless, candidate circuits with high voltage and very low efficiency might be useless in practice. Therefore, we propose to inject preferences from the designer into our algorithm by associating different weights to each of the objectives. A principled approach would be to assign appropriate preference weights resulting in a convex combination of the individual components of the summation $AF(i,x)$. Let $p_i$ be the preference weight associated with each individual component. The preference-based acquisition function is defined as follows (see Algorithm 2): %shows the complete pseudo-code: 
\begin{align} \label{AF_final}
    &\alpha_{pref}(\vec{x}) \simeq \sum_{i\in \mathcal{I}} p_i\times AF(i,x) ~\text{with} ~ i \in \mathcal{I} & s.t \sum_{i\in \mathcal{I}} p_i =1
\end{align}
It is important to note that in practice if a candidate design does not satisfy the constraints, the optimization will fail regardless of the preferences over objectives. Therefore, the cumulative weights assigned to the constraints have to be at least equal to the total weight assigned to the objective functions:
\begin{align}
 \sum_{i\in \{c_1\cdots c_L\}} p_i =  \sum_{i\in \{f_1, \cdots, f_K\}} p_i =\frac{1}{2}
\end{align}
Given that satisfying all the constraints is equally important, the weights over the constraints would be equal. Finally, only the weights over the functions will need to be explicitly specified. 

% \vspace{0.2cm}
\begin{algorithm}[h]
\caption{PAC-MOO Algorithm}
\label{alg:PAC-MOO}
\scriptsize
\small{Inputs}: {Input space $\mathcal{X}$, black-box functions $\{f_1,...,f_{\mathbf{K}}\}$, constraint functions $\{c_1,...,c_L\}$, preferences $\vec{p}=\{p_{f_1},\cdots,p_{f_K},p_{c_1},\cdots,p_{c_L}\}$, number of initial points $\mathcal{N}_0$, number of iterations $T$}\
\begin{algorithmic}[1] 
\STATE Initialize Gaussian processes for functions $\mathcal{M}_{f_1},\cdots,\mathcal{M}_{f_\mathcal{K}}$ and constraints  $\mathcal{M}_{c_1},\cdots, \mathcal{M}_{c_\mathcal{L}}$ by evaluating them on $\mathcal{N}_0$ initial design parameters
\FOR{ each iteration t = $\mathcal{N}_0$ to T+$\mathcal{N}_0$ }

\IF{feasible design parameters $\vec{x}_{feasible} \notin \mathcal{D}$} 
\STATE Select design parameters $\vec{x}_{t} \leftarrow \arg max_{\vec{x}\in \mathcal{X}} \hspace{2 mm} \alpha_{prob}(\vec{x}) $ \textit{\# eq. \ref{alpha_prod}}
\ELSE
\STATE Select design parameters $\vec{x}_{t} \leftarrow \arg max_{\vec{x}\in \mathcal{X}} \hspace{2 mm} \alpha_{pref}(\vec{x},\vec{p}) $ in Algorithm \ref{alg:pefMESMOC} \\
    \qquad \qquad \qquad \qquad \qquad \qquad \textbf{s.t} $(\mu_{c_1}\geq 0, \cdots,\mu_{c_L}\geq 0 )$
\ENDIF
\STATE Perform function evaluations using the selected design parameters \\  
\qquad $\vec{x}_{t}$: $\vec{y}_{t} \leftarrow (f_1(\vec{x}_{t}),\cdots,f_K(\vec{x}_{t}),C_1(\vec{x}_{t}),\cdots,C_L(\vec{x}_{t}))$ 
\STATE Aggregate data: $\mathcal{D} \leftarrow \mathcal{D} \cup \{(\vec{x}_{t}, \vec{y}_{t})\}$ 
\STATE Update models $\mathcal{M}_{f_1},\cdots, \mathcal{M}_{f_K}$ and $\mathcal{M}_{c_1},\cdots, \mathcal{M}_{c_L}$ using $\mathcal{D}$
\ENDFOR
\STATE \textbf{return} the Pareto set of feasible design parameters from $\mathcal{D}$
\end{algorithmic}
\end{algorithm}


\begin{algorithm}[H]
\caption{Preference based Acquisition function ($\alpha_{pref}$)}\label{alg:pefMESMOC}
\small
\begin{flushleft}
\textbf{$\alpha_{pref}(\vec{x},\vec{p})$ }
\end{flushleft}
\begin{algorithmic}[1] 

\FOR{Each sample $s \in \{1,\cdots,S\}$} %(repeat and average)}
\STATE Sample functions $\Tilde{f}_j \sim \mathcal{M}_{f_j}, \quad \forall{j \in \{1,\cdots, K\}} $
\STATE  Sample constraints $\Tilde{C}_i \sim \mathcal{M}_{c_i}, \quad \forall{i \in \{1,\cdots, L\}} $
\STATE  Solve {\em cheap} MOO over $(\Tilde{f}_1, \cdots, \Tilde{f}_K)$ {constrained by} $(\Tilde{C}_1, \cdots, \Tilde{C}_L)$\\
\qquad  \qquad  $\mathcal{Y}_s^* \leftarrow \arg max_{x \in \mathcal{X}} (\Tilde{f}_1, \cdots, \Tilde{f}_K)$ \\ \qquad \qquad \textbf{s.t} $(\Tilde{C}_1\geq 0, \cdots, \Tilde{C}_L\geq 0)$
\ENDFOR
\FOR{$i \in \mathcal{I} ~\text{and} ~ \mathcal{I}=\{c_1 \cdots c_L,f_1 \cdots f_K\}$} 
\STATE Compute $AF(i,x)$ based on $S$ samples of $\mathcal{Y}_s^*$ via Equation \ref{component_mes}
\ENDFOR
\STATE \textbf{Return $\sum_{i\in \mathcal{I}} p_i\times AF(i,x)$} 
\end{algorithmic}
\end{algorithm}

\noindent {\bf Finding Feasible Regions of Design Space}

The acquisition function defined in equation \ref{AF_final} will build constrained Pareto front samples $\mathcal{Y}_s^*$ by sampling functions and constraints from the Gaussian process posterior. The posterior of the GP is built based on the current training data $\mathcal{D}$. The truncated Gaussian approximation defined in Equations \ref{eqn_entropy_fj} and \ref{eqn_entropy_cj} requires the upper bound $y_s^{f_j*}$ and $y_s^{c_i*}$ to be defined. 
However, in the early Bayesian optimization iterations of the algorithm, the configurations evaluated may not include any feasible design parameters. This is especially true for scenarios where the fraction of feasible design configurations in the entire design space is very small. In such cases, the sampling process of the constrained Pareto fronts $\mathcal{Y}_s^*$ is susceptible to failure because the surrogate models did not gather any knowledge about feasible regions of the design space \textit{yet}. Consequently, the upper bounds $y_s^{f_j*}$ and $y_s^{c_i*}$ are not well-defined and the acquisition function in  \ref{AF_final} is not well-defined.
Intuitively, the algorithm should first aim at identifying feasible design configurations by maximizing the probability of satisfying all the constraints. We define a special case of our acquisition function for such challenging scenarios as shown below: 

\begin{align}
    \alpha_{prob}(x)=\prod_{i=1}^{L} Pr(c_i(x)\geq0) \label{alpha_prod}
\end{align}

This acquisition function enables an efficient feasibility search due to its exploitation characteristics \cite{gardner2014bayesian}. Given that the probability of constraint satisfaction is binary (0 or 1), the algorithm will be able to quickly prune unfeasible regions of the design space and move to other promising regions until it identifies feasible design configurations. This approach will enable a more efficient search over feasible regions later and accurate computation of the acquisition function. The complete pseudo-code of PAC-MOO is given in Algorithm \ref{alg:PAC-MOO}. 
