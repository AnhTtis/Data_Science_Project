\section{Related Work}

There are three families of approaches for solving constrained multi-objective optimization problems with expensive black-box functions. First, we can employ heuristic search algorithms such as multi-objective variants of simulated annealing \cite{vanLaarhoven1987, gielen1990analog, goodrick2021systematic}, genetic algorithms \cite{10.5555/534133,golonek2007genetic}, and particle swarm optimization \cite{Kennedy,fakhfakh2010analog,thakker2009low,vural2010component} to solve them. The main drawback of this family of methods is that they require a large number of expensive function evaluations. 
Second, Bayesian optimization (BO) methods employ surrogate statistical models to overcome the drawbacks of the previous families of approaches. The surrogate models are initialized using a small set of randomly sampled training data, i.e., input-output pairs of design parameters and objective evaluations. They are iteratively refined during the optimization process to actively collect a new training example in each iteration through an acquisition function (e.g., expected improvement). There is a large body of work on BO for single-objective optimization \cite{DU2022155,NEURIPS2019_6c990b7a}. Standard BO methods have been applied to a variety of problems including solving simple analog circuit design optimization and synthesis problems \cite{9401205,Lyu2018BatchBO,9181162,Zhang_2019,10.1145/3394885.3431543,8465872,9586172, 8116661,torun2018global}. 

Multi-objective BO (MOBO) is a relatively less-studied problem setting compared to the single-objective problem. Some of the recent work on MOBO include Predictive Entropy Search for Multi-objective Bayesian Optimization (PESMO) \cite{PESMO}, Max-value Entropy Search for Multi-Objective Bayesian optimization (MESMO) \cite{belakaria2019max}, Uncertainty-aware Search framework for Multi-Objective Bayesian Optimization (USEMO)\cite{Usemo}, Pareto-Frontier Entropy Search (PFES) \cite{suzuki2020multi}, and Expected Hypervolume Improvement \cite{daulton2020differentiable, emmerich2008computation}. Each of these methods has been shown to perform well on a variety of MOO problems. MESMO \cite{belakaria2019max} is one of the state-of-the-art algorithms that is based on the principle of output space entropy search, which is low-dimensional compared to the input space. 

Recent work extended existing approaches to the multi-objective constrained setting to account for black box constraints, notably PESMOC \cite{garrido2019predictive}, MESMOC \cite{belakaria2020max,belakaria2021output}, USEMOC \cite{belakaria2020uncertainty}. 
Existing algorithms can handle constraints that are evaluated using expensive function evaluations. However, they might not perform well when the fraction of feasible designs in the input space is small because they are hard to locate.  Additionally, none of them supports preference specifications over the output objectives. 

A parallel line of work includes several proposed approaches to incorporate preferences between different objectives \cite{abdolshah2019multi,lin2022preference}. However, simultaneously handling constraints and preferences was not well-studied. The goal of this paper is to fill this gap motivated by real-world problems in analog circuit design and electric power systems design.


