\section{Introduction}

A large number of engineering design problems involve making design choices to optimize multiple objectives. Some examples include electric power systems design \cite{wang2018research,belakaria2020PSD}, design of aircrafts \cite{wang2014multi}, and design of analog circuits \cite{nicosia2008evolutionary,ACDesign}, and nanoporous materials discovery \cite{MOF}. The common challenges in such constrained multi-objective optimization (MOO) problems include the following. 1) The objective functions are unknown and we need to perform expensive experiments to evaluate each candidate design choice. 2) The objectives are conflicting in nature and all of them cannot be optimized simultaneously. 3) The constraints need to be satisfied, but we cannot evaluate them for a given input design without performing experiments. 4) Only a small fraction of the input design space is feasible. Therefore, we need to find the Pareto optimal set of solutions from the subset of feasible inputs (i.e., satisfies constraints). Additionally, in several real-world applications, the practitioners have specific preferences over the objectives. For example, the designer prefers efficiency over settling time when optimizing analog circuits.


\begin{figure*}[]
\includegraphics[width=\textwidth]{figures/new-pacmoo.png}
\caption{A high-level overview of the PAC-MOO algorithm. It takes as input the input space $\mathfrak{X}$ and preferences over objectives $p$, and produces a Pareto set of candidate points as per the preferences after $T$ iterations of PAC-MOO. In each iteration $t$, PAC-MOO selects a candidate point $\vec{x}_t \in \mathfrak{X}$ to perform expensive function evaluations and the surrogate models for both objective functions and constraints are updated based on training data from the evaluated point.}\label{PACMOO_overview} 
\end{figure*}


Bayesian optimization (BO) is an efficient framework to solve black-box optimization problems with expensive objective function evaluations \cite{7352306,Jones1998}. There are no BO algorithms for simultaneously handling the challenges of black-box constraints, a large fraction of input space is invalid (doesn't satisfy all constraints), and preferences over objectives. To fill this important gap, we propose a novel and efficient information-theoretic approach referred to as {\em {\bf P}reference-{\bf A}ware {\bf C}onstrained {\bf M}ulti-{\bf O}bjective Bayesian {\bf O}ptimization (PAC-MOO)}. PAC-MOO builds surrogate models for both output objectives and constraints based on the training data from past function evaluations. PAC-MOO employs an acquisition function in each iteration to select a candidate input design for performing the expensive function evaluation. The selected input design maximizes the information gain about the constrained optimal Pareto front while factoring in the designer preferences over objectives. The experimental results on two real-world analog circuit design benchmarks demonstrate that PAC-MOO was able to find circuit configurations with higher preferred objective values (efficiency) as intended by sacrificing the overall Pareto hypervolume indicator.

\noindent {\bf Contributions.} Our key contribution is the development and evaluation of the PAC-MOO algorithm to  solve a general constrained multi-objective optimization problem. Specific contributions include: 
\begin{itemize}
    \item A tractable acquisition function based on information gain to select candidate points for performing expensive function evaluations.
    \item Approaches to increase the chances of finding feasible candidate designs and to incorporate preferences over objectives.
    \item Evaluation of PAC-MOO on two challenging analog circuit design problems and comparison with prior methods.
\end{itemize}

