\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx,psfrag,epsf}
\usepackage{psfrag,epsf}
\usepackage{enumitem}
\usepackage{natbib}
\usepackage{url} % not crucial - just used below for the URL 
\usepackage[titletoc,title]{appendix}
\usepackage{array}
\usepackage{bm}
\usepackage{color}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage[letterpaper, portrait, margin=1in]{geometry}
\usepackage{lipsum}
\usepackage{listings}
\usepackage{fancyref}
\usepackage{float}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\usepackage{color}	
\usepackage{lscape}
\usepackage{mathtools}

\usepackage{xr}
\externaldocument{iv_post_append}

\usepackage{xcite}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage[normalem]{ulem}

\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{assumption}{Assumption}[section]
\newtheorem{result}{Result}[section]

\usepackage{setspace}


 
\newtheorem*{remark}{Remark}

\newcommand{\ind}[1]{\b1_{\left\{#1\right\}}}
\newcommand*\ITT{\text{ITT}}
\newcommand*\CACE{\tau}

\newcommand\cmnt[2]{\qquad{{\color{red} \em #1---#2} \qquad}}
\newcommand\cmntP[1]{\cmnt{#1}{Pashley}}
\newcommand\cmntM[1]{\cmnt{#1}{Miratrix}}
\newcommand\cmntK[1]{\cmnt{#1}{Keele}}

\title{Improving instrumental variable estimators with post-stratification}
\author{  Nicole E. Pashley\\Department of Statistics, Rutgers University \and Luke Keele \\Departments of Surgery and Biostatistics, University of Pennsylvania\and Luke W. Miratrix\\Graduate School of Education, Harvard University }



\begin{document}
\maketitle

\begin{abstract}
Experiments studying get-out-the-vote (GOTV) efforts estimate the causal effect of various mobilization efforts on voter turnout. However, there is often substantial noncompliance in these studies. A usual approach is to use an instrumental variable (IV) analysis to estimate impacts for compliers, here being those actually contacted by the investigators. Unfortunately, popular IV estimators can be unstable in studies with a small fraction of compliers. We explore post-stratifying the data (e.g., taking a weighted average of IV estimates within each stratum) using variables that predict complier status (and, potentially, the outcome) to mitigate this. We present the benefits of post-stratification in terms of bias, variance, and improved standard error estimates, and provide a finite-sample asymptotic variance formula. We also compare the performance of different IV approaches and discuss the advantages of our design-based post-stratification approach over incorporating compliance-predictive covariates into the two-stage least squares estimator. In the end, we show that covariates predictive of compliance can increase precision, but only if one is willing to make a bias-variance trade-off by down-weighting or dropping strata with few compliers. By contrast, standard approaches such as two-stage least squares fail to use such information. We finally examine the benefits of our approach in two GOTV applications.
\end{abstract}

\noindent%
{\it Keywords:} Blocking; Compliance; Instrumental Variables; Post-stratification; Randomization Inference; Voter mobilization.
\vfill


\doublespacing

\section{Introduction}

In United States elections, political parties often focus on voter mobilization, encouraging their partisans to vote via appeals made prior to an election. Voter mobilization contact is usually a simple reminder to vote, but may also convey information such as the day of the election and the location of polling places. A key question for political parties is what types of get-out-the-vote (GOTV) efforts (e.g., door-to-door canvasing, phone calls, texts, and so forth) are most effective. However, judging the effectiveness of GOTV methods is complicated by the fact that those voters most receptive to contact by political parties are already more likely to vote on election day. In ground-breaking research, \citet{Gerber:2000} used a randomized control trial (RCT) design to evaluate GOTV approaches, randomly allocating voters to different GOTV approaches and comparing voting behavior using public records. Gerber and Green spawned a new area of research based on using RCTs to identify best practices for increasing voter turnout rates \citep{Nickerson:2006,arceneaux2012get,green2017much,coppock2022does,mann2020negatively,Green:2003a,Gerber:2008}.
See \citet{green2019get,green2016voter,green2013field,Nickerson:2009} for overviews and meta-analyses of this literature.

Despite the merits of these experiments in terms of their ability to quantify causal quantities, GOTV RCTs are often subject to significant noncompliance. For example, \citet{Green:2003a} was designed to gauge the effectiveness of door-to-door canvassing by having volunteers knock on doors urging people to vote in an upcoming election in six cities (Bridgeport, Columbus, Detroit, Minneapolis, Raleigh, and St. Paul). In each city, voters in households were randomized to either receive face-to-face contact from local staffers, i.e. treatment, or were not contacted, i.e. control. In the study, using official lists of registered voters, voters were grouped into small geographic areas called turfs. Within each turf, voters were randomly assigned to treatment or control. Canvassers were then given the names and addresses of voters within each turf and instructed to only contact voters selected for treatment. However, only around 30\% of the voters assigned to treatment were actually contacted. In RCTs of this type, rates of contact often range between 10 to 30\% \citep{Green:2003a}. 


When there is noncompliance, one strategy is to focus on the causal effect of the treatment assignment on the outcome, which is referred to as an intention-to-treat (ITT) analysis. However, there is also substantial interest in the causal effect of the treatment actually received. That is, we might wish to estimate the causal effect of actually being contacted rather than just the effect of being assigned to contact. When noncompliance is present, treatment assignment can be used as an instrumental variable (IV), which is a variable that affects exposure to treatment but does not directly affect the outcome \citep{AngImbRub96,Hernan:2006}. For a variable to be an instrument the following three core assumptions must hold: (1) the IV must have a nonzero effect on treatment exposure, (2) the IV must be randomly or as-if randomly assigned, (3) the IV must itself not have a direct effect on the outcome \citep{AngImbRub96}. If these assumptions hold in addition to a monotonicity assumption on the effect of assigning treatment on treatment receipt, an IV design provides a consistent estimate of the causal effect of the exposure on the outcome for so-called \emph{compliers} \citep[those who only take treatment upon encouragement,][]{AngImbRub96}, even in the presence of unobserved confounding between the treatment and the outcome.

In the original analysis of \cite{Green:2003a}, the authors first focused on ITT effects. They then used IV methods to estimate the effect of exposure on voter turnout. In RCT designs of this type, the IV assumptions are plausible. That is, (1) one can easily verify that treatment assignment causes treatment exposure, (2) the IV is randomly assigned by the study design, and (3) it is unlikely that being assigned to household contact has any direct effect on voting except through the exposure of a face-to-face appeal to vote. Unfortunately, even if the IV assumptions are met, if the instrument has only a small impact on the proportion of subjects who take treatment, such as with these GOTV experiments, the instrument is said to be weak \citep{Bound:1995,Staiger:1997}, and inference can be hard. In particular, with a weak instrument, IV estimates may be biased and the associated confidence intervals can have poor coverage. As such, analysts generally test for the presence of a weak instrument as an initial step in an IV analysis \citep{Stock:2005}. One interesting question is how analysts might improve GOTV and other studies where the instrument manages to pass a weak instrument test, but is still not strong. In this study, we focus on how to use baseline covariates (i.e., covariates measured pre-intervention or otherwise known to not be impacted by treatment) to improve IV estimates in applications and contexts such as these.

Specifically, we outline how post-stratification based on baseline covariates (hereafter referred to simply as ``covariates'') that are predictive of \emph{compliance} can improve IV analyses. Generally, the literature has not focused on how to exploit covariates only predictive of compliance. We show that covariates predictive of compliance do not benefit an analysis the same way as covariates that improve precision. In particular, we demonstrate that classic IV estimation methods such as two-stage least squares (2SLS) provide minimal gains with complier-predictive covariates. We therefore propose a method based on post-stratification, where we stratify units based on baseline covariates, estimate a separate IV estimator within each stratum, and then take their average, weighting by the estimated number of compliers. If some strata are estimated to have zero compliers, we drop them from our overall estimate. The goal is to concentrate our compliers into a few strata where we can estimate impacts more easily. The strata with only a few compliers can be down-weighted, as they would be less relevant for the overall impact estimate.

Our proposal adds to the extensive literature on how to use covariates in IV contexts. For example, covariates can be used to bound effects when the exclusion restriction, a key IV assumption, does not hold \citep{mealli2013using,miratrix2018bounding}. Covariates also play a vital role in the principal scores literature \citep{ding2017principal, feller2017principal}, which relaxes the exclusion restriction with a weaker principal ignorability assumption. Covariates are also routinely used in Bayesian principal stratification to reduce model dependence and improve precision \citep{imbens1997bayesian, hirano2000assessing, mealli2012refreshing}.
\citet{schochet2024design} derives design-based finite-population central limit theorems for instrumental variable estimators adjusted for covariates through regression, focusing on strong instrument settings. \citet{ten2004causal} used covariates to predict compliance classes to target the intention-to-treat (ITT) estimand. Our proposed post-stratification methods also connect to, for a continuous IV case, matching methods where units different in terms of their exposure to the IV are matched on covariates \citep{Small:2008,baiocchi2012near,keele2016strong}. This matching IV literature proposes using an estimator similar to one of our post-stratified IV estimators. However, the goal in the matching IV literature is to mitigate bias from confounders in the observational setting and to match units that are far apart in terms of the instrument. We, on the other hand, focus on the use of post-stratification (which is more general than standard pairwise matching) to reduce variation, and we also discuss how modifications of the natural post-stratified IV estimator can lead to better precision gains.

Ideally, the post-stratification strategy would give a more precise estimator if the covariates used for stratification are predictive of the outcome or compliance, due to inherently more stable estimates within each group. Surprisingly, we find that although this estimator does take advantage of stratification variables predictive of outcome, it can fail to take advantage of covariates predictive of compliance. Furthermore, most gains are driven by dropping empty strata, because of the precision boost from eliminating unstable IV estimators that are just contributing noise to the overall estimator. However, as we show, if we are not able to separate compliers and non-compliers cleanly enough to reliably drop any strata, our post-stratified estimator is identical to the ratio of a post-stratified estimate of the ITT effect and a post-stratified estimate of the compliance proportion, which in turn is very similar to the ineffective 2SLS estimator. As such, we explore other stratification estimators that more aggressively drop or down-weight those strata with few compliers to obtain further gains. Dropping or down-weighting strata does come at a cost of some additional bias, however, leaving us with a bias-variance tradeoff when using complier-predictive covariates.

In sum, we outline how post-stratification estimators can provide three potential benefits for impact estimation: (1) a reduction in the variance, (2) a reduction in the bias, and (3) a reduction in the variability of the estimated standard error. We first provide theoretical derivations for the behavior of this estimator. We then study the properties of the post-stratification IV estimator using a detailed simulation study. We find that post-stratification shows improvement in overall precision with covariates predictive of outcome, and that the versions that drop low weight strata can also achieve precision gains at the cost of a small amount of bias. We then apply these methods to two GOTV examples. We conclude with a discussion of when post-stratification IV estimators could be usefully employed and the implications of our findings for future GOTV study planning.


\section{The IV Framework}

We have $N$ units, and use the potential outcomes framework as introduced for RCTs in \citet{SplawaNeyman:1990ux}; see \citet{gerber2012field} for a more modern overview.
Under this framework, each unit has treatment indicator $Z_i \in \{0,1\}$ and associated potential outcomes under treatment and control, $Y_i(1)$ and $Y_i(0)$.
We also have indicators for actual treatment receipt when assigned to treatment $z$, $D_i(z) \in \{0,1\}$.
$D_i$ and $Y_i$ will be the observed values for unit $i$ after treatment assignment.
We also denote observed baseline covariates as $\bm X_i$.

Following the traditional Neyman-style causal inference framework, we assume the stable unit treatment value assumption (SUTVA) \citep{rubin_1980}.
Under SUTVA, both the potential treatments received $D(z)$ and potential outcomes $Y(z)$, $Y(z,d)$, for $z, d=0,1$, depend solely on the value $z$ of the instrument, and $d$ of the treatment for $Y(z,d)$, for each individual.
That is, there is only one version of the instrument and treatment, and $D_i(z)$, $Y_i(z)$, and $Y_i(z,d)$ are not affected by the value of $(Z_{i'}, D_{i'})$ for $i'\neq i$. These two components of SUTVA are often referred to as the consistency and no-interference assumptions, respectively. Next, we make the three core IV assumptions are \citep{AngImbRub96}:

\begin{assumption}\label{assump:iv} The three core IV assumptions:

\begin{enumerate}[wide=\parindent, label={\textbf{Part~\Alph*:}},
  ref={assumption~\theassumption.\Alph*}]

	\item Effective random assignment: $Z_i$ is independent of $D_i(z)$ and $Y_i(z)$, given  $\bm X$, for $z = 0,1$. More narrowly, we assume there are $n_1$ units randomly assigned to treatment according to complete randomization, leaving $n_0 = N-n_1$ units in control. We take $p =n_1/N$ with $p \in (0,1)$ as fixed.\footnote{For asymptotic arguments, this can be relaxed to just ensure that $n_1/N \to p$ and $N \to \infty$.} This implies  $Z$ is independent of $D_i(z)$ and $Y_i(z)$ unconditionally.
\item Exclusion restriction: $Z_i$ only impacts $Y_i$ through $D_i$, meaning there are no treatment impacts on anyone but the compliers, so $Y_i(1) = Y_i(0)$ if $D_i(1) = D_i(0)$.
	\item Relevance: $Z_i$ has a nonzero effect on $D_i$, i.e., we have at least some compliers in our dataset.
\end{enumerate} 
\end{assumption}
\noindent We note that under Assumption~\ref{assump:iv}, part A, the assumption of positivity: $0<P(Z=1) < 1$, is satisfied trivially.

Critically, under these assumptions, a causal quantity such as the average treatment effect is not point identified. There are two primary ways to achieve point identification. One way is to invoke some form of a homogeneity assumption and place a restriction on how the effects of $D_i$ and $Z_i$ vary from unit to unit in the study population. See \citet{hernan2019} and \citet{wang2018} for examples. Alternatively, one can invoke an assumption known as monotonicity:
\begin{assumption}
\label{assump:mono}
Monotonicity: $D_i(1) \geq D_i(0)$.
\end{assumption}
\noindent Monotonicity is best understood within a principal stratification framework \citep{Frangakis:2002}---but see \citet{AngImbRub96} for IV in particular. The principal stratification framework identifies that the members of our study population fall into distinct latent groups depending on their treatment exposure due to treatment assignment.
Under principal stratification unit $i$ is classified according to the following rules:
\begin{align*}
\text{complier} & \text{ if } D_i(1) = 1, D_i(0)=0,\\
\text{always-taker} & \text{ if } D_i(1) = 1, D_i(0)=1,\\
\text{never-taker} & \text{ if } D_i(1) = 0, D_i(0)=0,\\
\text{defier} & \text{ if } D_i(1) = 0, D_i(0)=1.
\end{align*}
Under the monotonicity assumption, we rule out the presence of ``defiers,'' or those who do the opposite of their assigned status.
The monotonicity assumption is integral to the methods we develop.

Next, let $\pi_c$ be the true proportion of compliers. Further let $n_c = \pi_cN$ be the number of compliers and $n_{c,z}$ be the number of compliers under treatment $z$. We use analogous notation for quantities related to always-takers and never-takers (e.g., $\pi_a$ and $\pi_n$ for the proportion of always-takes and never-takers, respectively). Define an indicator for being a complier as $C_i = 1$ if $D_i(1) = 1, D_i(0) = 0$, and $C_i = 0$ otherwise. Under monotonicity, we focus on the complier average causal effect (CACE) estimand:
\[ 
\CACE = \overline{Y}_c(1) - \overline{Y}_c(0) \mbox{ where } \overline{Y}_c(z) = \frac{1}{n_c}\sum_{i=1}^N C_i Y_i(z).
\]
One strength of the monotonicity assumption is that it does not impose any treatment effect homogeneity assumptions.
Specifically, the CACE only focuses on the effect among the complier population.
Under the exclusion restriction, the always-takers and never-takers have no measured impact as their treatment take-up does not change under random assignment.

Another useful causal quantity is the intention-to-treat effect. The ITT is $\overline{Y}(1) - \overline{Y}(0)$ with $\overline{Y}(z) = \frac{1}{N}\sum_{i=1}^N Y_i(z)$.
Due to the exclusion restriction and monotonicity we have
\[ 
\ITT = \frac{1}{N} \sum_{i=1}^N\left[ Y_i(1) - Y_i(0) \right]= \frac{1}{N} \sum_{i: C_i = 1} \left[Y_i(1) - Y_i(0) \right]+ \frac{1}{N} \sum_{i: C_i \neq 1} \left[Y_i(1) - Y_i(0)\right] = \pi_c \tau .
\] 

We treat both the CACE and ITT as finite-population quantities, meaning they are defined only with respect to the units in the experiment, the $n_c$ compliers and the $N$ units, respectively. We take potential outcomes to be fixed and, in the following section, estimators are random due solely to random assignment of units into treatment groups (as assumed given under Part A of Assumption~\ref{assump:iv}).
Thus expectations and variance are taken over the random treatment assignment process.


\subsection{IV Point and Variance Estimation}\label{sec:standard_iv_est}

The standard IV estimator for the CACE is
\[ 
\widehat{\CACE}_{\text{IV}} = \frac{ \widehat{\ITT} }{ \widehat{f} } ,
\]
where the ITT estimator of $\widehat{\ITT} = \overline{Y}^{obs}_1 - \overline{Y}^{obs}_0$, with
\[
\overline{Y}^{obs}_z = \frac{1}{n_z}\sum_{i: Z_i=z}Y_i(z), 
\]
is the numerator and the estimated proportion of compliers, $\pi_c$, is the denominator.
We can estimate $\pi_c$ via
\[
\widehat{f} =\overline{D}^{obs}_1 - \overline{D}^{obs}_0= \frac{1}{n_1}\sum_{i=1}^NZ_iD_i(1) - \frac{1}{n_0}\sum_{i=1}^N(1-Z_i)D_i(0). 
\]
Because $E[  \widehat{\ITT} ] = \pi_c \tau $ and $E[ \widehat{f} ] = \pi_c$, $\widehat{\CACE}_{\text{IV}}$ provides a reasonable estimate of $\tau$.
That being said, $\widehat{\CACE}_{\text{IV}}$, as a ratio estimator, will not be fully unbiased because $E[ A / B] \neq E[ A ]/ E[B]$ in general.

We can approximate the variance of $\widehat{\CACE}_{\text{IV}}$ using the delta method.
To define the finite-sample asymptotic variance, we require the following regularity assumptions:

\begin{assumption}\label{assump:IV_CLT}
Let $c(z) = \max_{1 \leq i \leq N} \left(Y_i(z) - \overline{Y}(z)\right)^2$. As $N \to \infty$,
\[\max_{z\in \{0,1\}}\frac{1}{n_z^2}\frac{c(z)}{n_0^{-1}S^2_Y(0) + n_1^{-1}S^2_Y(1) - N^{-1}S^2_Y(01)}\]
\end{assumption}

\begin{assumption}\label{assump:IV_CLT_uptake}
$\pi_{c}$, $\pi_{a}$, and $\pi_{n}$ have asymptotic limiting values such that at least two of those proportions are nonzero.\footnote{See Supplementary Material~\ref{app:var_cond_simple} for why this condition is sufficient for obtaining a central limit theorem result for treatment uptake. }
\end{assumption}

\begin{assumption}\label{assump:delta}
$N\text{var}(\widehat{\ITT})$ has a finite limiting value, to help ensure $\widehat{\ITT} - \ITT \overset{p}{\to} 0 $.
\end{assumption}
Next, we define the following variance expressions:
\[S^2_Y(z) = \frac{1}{N-1}\sum_{i=1}^N \left(Y_i(z) - \overline{Y}(z) \right)^2\]
and
\[S^2_Y(01) = \frac{1}{N-1}\sum_{i=1}^N \left(Y_i(1) -Y_i(0)  - \overline{Y}(1) + \overline{Y}(0) \right)^2.\]
\begin{align*}
S^2_D(1) &= \frac{N}{N-1}\pi_{n}(\pi_{c} + \pi_{a}),\\
S^2_D(0) &= \ \frac{N}{N-1}\pi_{a}(\pi_{c} + \pi_{n}),
\end{align*}
and
\begin{align*}
S^2_D(01) = \frac{N}{N-1}\pi_{c}(\pi_{a} + \pi_{n}).
\end{align*}

We can apply the finite-population Central Limit Theorem (CLT) framework to our $\widehat{\ITT} $ estimator under Assumption~\ref{assump:IV_CLT} based on Theorem 4 of \cite{LiDin17}. Similarly, we can obtain a finite-population CLT for treatment uptake, $\widehat{f}$, under Assumption~\ref{assump:IV_CLT_uptake}. 
By combining the CLT with Assumption~\ref{assump:delta} and an asymptotic  version of the relevance assumption (Assumption~\ref{assump:iv}.3), where $\pi_c$ has a nonzero limiting value, we can use the finite-population delta method to derive an asymptotic variance for $\widehat{\tau}_{\text{IV}}$ \citep{pashley2019note}. The formal expression for the asymptotic variance for $\widehat{\tau}_{\text{IV}}$ is
\begin{align}
\text{asyVar}\left(\widehat{\CACE}_{\text{IV}} \right) &=\frac{1}{\pi_c^2}\textrm{var}(\widehat{\ITT}) +\CACE^2\frac{1}{\pi_c^2}\textrm{var}(\widehat{f}) -2\CACE\frac{1}{\pi_c^2}\textrm{cov}(\widehat{\ITT}, \widehat{f}). \label{eq:delta_variance}
\end{align}
If all units are compliers, Equation~\ref{eq:delta_variance} collapses to $\textrm{var}(\widehat{\ITT})$.
We can rewrite the asymptotic variance as follows:
\begin{align*}
\text{asyVar}(\widehat{\CACE}_{\text{IV}})=&\frac{1}{\pi_c^2}\textrm{var}\left(\widehat{\ITT}- \CACE \widehat{f}\right) \\
=& \frac{1}{\pi_c^2}\frac{1}{(N-1)}\Bigg \{ \frac{1}{n_0}\sum_{i=1}^N\left( \tilde{Y}_i(0) - \overline{\tilde{Y}}(0) \right)^2 
  + \frac{1}{n_1}\sum_{i=1}^N \left(\tilde{Y}_i(1) - \overline{\tilde{Y}}(1) \right)^2 \\
& - \frac{1}{N}\sum_{i=1}^N \left(\widetilde{ITT}_i -  \widetilde{ITT}\right)^2  \Bigg \} ,
\end{align*}
where $\tilde{Y}_i(z) = Y_i(z) - \tau D_i(z)$ is an adjusted potential outcome based on $Y_i(z)$ and $D_i(z)$, so that $\widetilde{ITT}_i = Y_i(1) - Y_i(0) - \tau \left[D_i(1) -D_i(0) \right]$ and $\widetilde{ITT} = \tau\left[1-\pi_c\right]$.
In other words, the variance of our CACE estimate is equivalent to a $1/\pi_c^2$ scaling of the variance of an experiment where the average complier treatment impact has been subtracted off according to uptake behavior.
While the $\tilde{Y}_i(z)$ are always unobserved due to dependence on the estimand $\tau$, this formulation is important for further derivations detailed below and helps build intuition as to sources of variance for our CACE estimators.
Additional details on the asymptotic result are provided in Supplementary Material~\ref{append:iv_var}. 

Under the delta method, standard errors are estimated by plugging in estimates of all the terms in Equation~\ref{eq:delta_variance} \citep[see, e.g.,][chapter 23]{CausalInferenceText} as follows: 
\begin{align*}
\widehat{\text{var}}_{\text{DELTA}} \left(\widehat{\CACE}_{\text{IV}}\right) &= \frac{\widehat{\text{var}}\left(\widehat{\ITT}\right)}{\widehat{f}^2}+ \frac{\widehat{\ITT}^2\widehat{\text{var}}\left(\widehat{f}\right)}{\widehat{f}^4} - 2\frac{\widehat{\ITT}\widehat{\text{cov}}\left(\widehat{\ITT}, \widehat{f}\right)}{\widehat{f}^3}\\
&= \frac{1}{\widehat{f}^2}  \left( \frac{s_Y^2(1)}{n_1} + \frac{s_Y^2(0)}{n_0} \right)  
     + \frac{1}{\widehat{f}^4} \widehat{\ITT}^2\left(\frac{s_D^2(1)}{n_1} + \frac{s_D^2(0)}{n_0}\right) 
      - \frac{2}{\widehat{f}^3} \widehat{\ITT} \left(\frac{s_{Y,D}(1)}{n_1} + \frac{s_{Y,D}(0)}{n_0}\right)  
\end{align*}
where
\[s_{A,B}(z) = \frac{1}{n_z-1}\sum_{i:Z_i=z}\left(A_i(z) - \overline{A}^{obs}_z\right)\left(B_i(z) - \overline{B}^{obs}_z\right),
\]
and $s_A^2(z) = s_{A,A}(z)$, for $A= Y, D$ and $B= Y, D$.

One alternative method for estimating the IV standard error is the Bloom method (also sometimes called the Wald method), which essentially treats the denominator of our IV estimators as fixed \citep{Bloom:1984}. The Bloom method uses just the first term in the delta method expansion as the nominal variance of our estimator:
\begin{align*}
\text{var}\left(\widehat{\CACE}_{\text{IV}} \right) &\approx \frac{1}{\pi_c^2}\textrm{var}(\widehat{\ITT}).
\end{align*}
The plug-in estimate for this is then
\begin{align*}
\widehat{\text{var}}_{\text{BLOOM}}\left(\widehat{\CACE}_{\text{IV}}\right) 
    = \frac{\widehat{\text{var}}\left(\widehat{\ITT}\right)}{\widehat{f}^2}
    = \frac{1}{\widehat{f}^2} \left( \frac{s_Y^2(1)}{n_1} + \frac{s_Y^2(0)}{n_0} \right)  .
\end{align*}
The Bloom method will perform well if the second and third terms are small and/or cancel out. See \citet{Keele:2017fiv} for a detailed comparison of the delta and Bloom methods. 

\section{Post-stratification}

In many cases we might have a covariate that we believe to be predictive of complier status, or outcome, or both.
We would want to use this covariate to improve the precision of our IV estimator.
Motivated by the intuition that if we could isolate most of our compliers into a subset of our data then we could more reliably estimate impacts for those compliers as the instrument within that subset would be stronger, we turn to post stratification.

To implement post stratification, after randomization, we separate the units into $G$ groups based on some categorical (baseline) covariate that ideally predicts compliance (or outcome). Because we only consider stratifying on covariates unaffected by treatment, group assignments are invariant to treatment assignment. Note that the predictive potential of the covariates for compliance will not be used at an individual level to predict whether any single unit is a complier or to estimate a compliance probability function, but rather to form groups such that some groups have high compliance and some have low compliance.
Let $s_i = g$ if unit $i$ is assigned to group $g$. Let there be $N_g$ units in group $g$ with $N_{g,z}$ assigned to treatment $z$. We assume that $N_{g,z} \geq 1$ for $z\in\{0,1\}$ and $g = 1,\dots, G$.\footnote{In practice, the $N_{g,z}$ are random, and could be 0, depending on the treatment assignment. We discuss this further below.}
We can then apply each of the above estimators to each group $g$:
\begin{align*}
 \widehat{\ITT}_g= \frac{1}{N_{g,1}}\sum_{i:s_i=g}Z_iY_i(1) - \frac{1}{N_{g,0}}\sum_{i:s_i=g}(1-Z_i)Y_i(0),\\
 \widehat{f}_g = \frac{1}{N_{g,1}}\sum_{i:s_i=g}Z_iD_i(1) - \frac{1}{N_{g,0}}\sum_{i:s_i=g}(1-Z_i)D_i(0).
 \end{align*}

We initially offer two different estimators for a post-stratified CACE. First, we can post-stratify, followed by IV estimation within each stratum, with $\widehat{\tau}_g = \widehat{ITT}_g / \widehat{f}_g$. These $G$ IV estimators are then combined to estimate the overall CACE by weighting by the estimated number of compliers. Formally, this estimator is our ``IV-within'' estimator of
\begin{align}
\widehat{\CACE}_{\text{IV-w}} = \sum_{g=1}^G \frac{\widehat{f}_gN_g}{\sum_{k=1}^G\widehat{f}_k N_k} \frac{\widehat{\ITT}_g}{\widehat{f}_g}. \label{eq:IV-w}
\end{align}
If $\widehat{f}_g = 0$ then $\widehat{\tau}_g = \widehat{ITT}_g / \widehat{f}_g$ is undefined, but the weight $\widehat{f}_g N_g = 0$. 
We therefore define $\widehat{\CACE}_{\text{IV-w}}$ by dropping all strata where $\widehat{f}_g = 0$.
That is, we drop those portions of the experimental sample that we estimate as having no compliers from the analysis.
We also drop any strata $g$ that don't have at least 2 treatment and 2 control units (i.e., if $N_{g,z} \leq 1$ for $z = 0$ or 1), as we have no ability to estimate impact (if $N_{g,z}=0$) or standard errors (if $N_{g,z}=1$) otherwise.
The chance of $N_{g,z} \leq 1$ decays exponentially as sample size grows, making the bias of dropping such strata negligible. A stratum with 50 units in an RCT with treatment probability $0.3$ would have around a 1 in a million chance of being dropped, for example. See \citet{miratrix2013adjusting} for further discussion.


If $\hat{f}_g < 0$, then we have more always-takers in the treatment arm than control, and our $\hat{\tau}_g$ is based on a contrast of means not really related to the compliers, and, furthermore, the weight given to $\hat{\tau}_g$ is negative;
this motivates dropping all strata with 0 or non-negative weight. We explore these types of modifications further in Section~\ref{sec:weighting} and in the simulation study.

An alternate approach to post-stratification is to use the usual IV estimator, plugging in post-stratified estimates of the numerator term, $\widehat{\ITT}$, and denominator term, $\widehat{f}$.
This gives our ``IV-across'' estimator of:
\begin{align}
\widehat{\CACE}_{\text{IV-a}} & =  \frac{ \widehat{\ITT}_{\text{PS}}}{\widehat{f}_{\text{PS}}} =  \frac{ \sum_{g=1}^G\frac{N_g}{N}\widehat{\ITT}_g}{\sum_{g=1}^G\frac{N_g}{N}\widehat{f}_g}. \label{eq:IV-a}
\end{align}
We again drop strata with too few units to estimate standard errors or point estimates, as with $\text{IV-w}$.
Our first estimator, $\text{IV-w}$, calculates IV estimates \emph{within} the strata, and the second, $\text{IV-a}$, calculates one IV estimate \emph{across} the strata.
These estimators are related to each other and to a version of two-stage least squares, as the following two lemmas show.

First, Lemma~\ref{lemma:2sls_connection} outlines the equivalence between $\text{IV-a}$ and a two-stage weighted least squares estimation strategy.

\begin{lemma}\label{lemma:2sls_connection}
$\widehat{\CACE}_{\text{IV-a}}$ will equal $\hat{\beta}_{1, S2}$, the coefficient for predicted compliance in the second stage of a two-stage weighted least squares regression (with weighting in both stages) with weights $w_i = \frac{N_{g}}{N_{g,z}}\frac{n_z}{N}$ for unit $i$ in strata $g \in \{1,\dots,G\}$ assigned to treatment $z \in \{0,1\}$.
\end{lemma}
\noindent See Supplementary Material~\ref{append:2sls} for proof. 
With large strata, these weights are all approximately 1 given, for unit $i$ in group $g$, 
\begin{align*}
w_i = \frac{N_g}{N_{g,z}}\frac{n_z}{N} = \frac{1}{p_g} p \approx 1 ,	
\end{align*}
as random assignment will ensure each strata has roughly the same proportion treated, with $p_g \approx p$.
This suggests that in large samples with large strata, the weighted 2SLS estimate will generally be close to the usual, unweighted, 2SLS.
See \citet{schochet2024design} for an in depth look at regression adjusted instrumental variable estimators, which are shown to have similar asymptotic variances to our estimators if strata are not dropped.


Second, Lemma~\ref{lemma:w_a_connection} shows that $\widehat{IV}_w$ and $\widehat{IV}_a$ are equivalent when all strata have non-zero estimated proportions of compliers:

\begin{lemma}\label{lemma:w_a_connection}
If $\widehat{f}_g \neq 0$ for all $g = 1,\dots, G$, then the estimator in Equation~\ref{eq:IV-w} is mathematically equivalent to the estimator in Equation~\ref{eq:IV-a}:
\begin{align}
\widehat{\CACE}_{\text{IV-w}} &= \sum_{g=1}^G \frac{\widehat{f}_gN_g}{\sum_{k}\widehat{f}_k N_k} \frac{\widehat{\ITT}_g}{\widehat{f}_g} \nonumber\\
&= \sum_{g=1}^G  \left( \frac{N_g}{\sum_{k }N_k\widehat{f}_k} \right) \widehat{\ITT}_g \label{eq:weighted_ITT}\\
&=  \frac{ \sum_{g=1}^G\frac{N_g}{N}\widehat{\ITT}_g}{\sum_{k=1}^G\frac{N_k}{N}\widehat{f}_k} = \widehat{\CACE}_{\text{IV-a}} . \nonumber
\end{align}
\end{lemma}

The equivalence between $\widehat{\CACE}_{\text{IV-a}} $ and $\widehat{\CACE}_{\text{IV-w}}$ whenever $\hat{f}_g \neq 0$ for all $g=1,\dots,G$ allows us to use either representation to derive the asymptotic results.
Later, we find in simulations (with a fixed, finite sample) that $\widehat{\CACE}_{\text{IV-w}}$, which drops strata estimated to have zero compliers (as well as the variant that drops all non-positive estimates), has better properties than $\widehat{\CACE}_{\text{IV-a}}$.
This finding motivates estimators that weight those strata with more compliers more heavily as a means of achieving greater performance gains; see Section~\ref{sec:weighting}.

\subsection{Asymptotic Variance for Post-stratification Estimators}

Derivation of the asymptotic variance of $\widehat{\tau}_{IV-a}$ and $\widehat{\tau}_{IV-w}$ requires several finite-population central limit theorem results, which we include in the Supplemental Materials.
Let $W_i(g) = 1$ if $s_i = g$ and $W_i(g) = 0$ if $s_i \neq g$.
Then we can define variance components within each stratum:
\[S^2_{g,Y}(z) = \frac{1}{N_g-1}\sum_{i=1}^N W_i(g)\left(Y_i(z) - \overline{Y}_g(z) \right)^2,\]
\[S^2_{g,Y}(1,0)=  \frac{1}{N_g-1}\sum_{i=1}^NW_i(g)\left(Y_i(1) - \overline{Y}_g(1)\right)\left(Y_i(0) - \overline{Y}_g(0)\right),\]
and
\[S^2_{g, Y}(01) = \frac{1}{N_g-1}\sum_{i=1}^N W_i(g)\left(Y_i(1) - Y_i(0) -\left[ \overline{Y}_g(1) - \overline{Y}_g(0) \right]\right)^2.\]

Based on the conditions in the Supplemental Materials and using results from \cite{schochet2023design}, we get the asymptotic variance as given in the following theorem:

\begin{theorem}\label{thm:main_clt}
If we have Assumptions \ref{assump:iv}, \ref{assump:mono}, \ref{assump:strata_prop}, \ref{assump:li_ding_cond_main}, \ref{assump:clt_cond2_main}, \ref{assump:delta_post_strat}, and \ref{assump:clt_cond_d}, we have an asymptotic variance of
\begin{align*}
\text{asyVar}(\widehat{\CACE}_{\text{IV-a}}) =&\frac{1}{\pi_c^2}\text{asyVar}\left(\widehat{\ITT}_{\text{PS}}\right) +\CACE^2\frac{1}{\pi_c^2}\textrm{asyVar}(\widehat{f}_{\text{PS}}) -2\CACE\frac{1}{\pi_c^2}\textrm{asyCov}(\widehat{\ITT}_{\text{PS}}, \widehat{f}_{\text{PS}})
\end{align*}
where
\begin{align*}
\text{asyVar}\left(\widehat{\ITT}_{\text{PS}}\right) 
& =  \sum_{g=1}^N\frac{N_g}{N}\frac{N_g-1}{N-1}\left[\frac{S^2_{g,Y}(0)}{(1-p)N_g} +\frac{S^2_{g,Y}(1)}{pN_g} - \frac{S^2_{g, Y}(01)}{N_g}\right]\\
& \approx  \sum_{g=1}^N\frac{N_g^2}{N^2}\left[\frac{S^2_{g,Y}(0)}{(1-p)N_g} +\frac{S^2_{g,Y}(1)}{pN_g} - \frac{S^2_{g, Y}(01)}{N_g}\right]
\end{align*}
and 
\begin{align*}
\text{asyVar}(\widehat{f}_{\text{PS}}) 
&= \sum_{g=1}^G\frac{N_g}{N(N-1)}\left[(1-p)^{-1}\left(\pi_{g,c} + \pi_{g,a}\right)\pi_{g,n} + p^{-1}\left(\pi_{g,c} + \pi_{g,n}\right)\pi_{g,a} - \left(\pi_{g,a} + \pi_{g,n}\right)\pi_{g,c}\right]
\end{align*}
\label{thm:aymp_var_PS}
\end{theorem}
Theorem~\ref{thm:aymp_var_PS} comes from two finite-population central limit theorem results being combined with a finite-population delta method argument \citep{pashley2019note, schochet2023design}.
See Supplementary Material~\ref{append:clt_itt} for details along with finite-population CLT results for the ITT estimators. 

The asymptotic covariance term can similarly be approximated by a blocked covariance expression (see Supplementary Material~\ref{append:two_sided_bias}):
\begin{align*}
\textrm{asyCov}(\widehat{\ITT}_{\text{PS}}, \widehat{f}_{\text{PS}})
& \approx  \sum_{g=1}^N\frac{N_g^2}{N^2}\Bigg[\frac{\pi_{g,n}\pi_{g,c}}{p(N_g-1)}\left(\overline{Y}_{g,c}(1) - \overline{Y}_{g,n}(0)\right) + \frac{\pi_{g,n}\pi_{g,a}}{p(1-p)(N_g-1)}\left(\overline{Y}_{g,a}(1) - \overline{Y}_{g,n}(0)\right)\\
& \qquad \qquad \qquad + \frac{\pi_{g,a}\pi_{g,c}}{(1-p)(N_g-1)}\left(\overline{Y}_{g,a}(1) - \overline{Y}_{g,c}(0)\right) - \frac{\pi_{g,c}(1-\pi_{g,c})}{N_g-1}\CACE_g\Bigg],
\end{align*}
where $\overline{Y}_{g,t}(z)$ is the average potential outcome for units of compliance type $t \in \{a, c, n\}$ in stratum $g$ under treatment $z$.

Similar to the standard IV estimator, we can rewrite the above asymptotic variance expression for the stratified IV estimator as 
$$ \text{asyVar}(\widehat{\CACE}_{\text{IV-a}})  = \frac{1}{\pi_c^2}\textrm{var}\left(\widehat{\ITT}_{\text{PS}} - \CACE \widehat{f}_{\text{PS}}\right),$$
which corresponds to the post-stratified variance of a completely randomized experiment with potential outcomes $\tilde{Y}_i(z) = Y_i(z) - D_i(z)\tau$, where $\tau$ is the true CACE (across strata).

Due to the correspondence between $\widehat{\CACE}_{\text{IV-w}}$ and $\widehat{\CACE}_{\text{IV-a}}$, we further have $\text{asyVar}(\widehat{\CACE}_{\text{IV-w}}) = \text{asyVar}(\widehat{\CACE}_{\text{IV-a}})$ if we have constants $c_g >0$ such that $f_g \to c_g$ as $n \to \infty$ for all $g \in \{1,\dots,G\}$, guaranteeing that (asymptotically) IV-w does not drop any strata.

The Bloom approximation for the post-stratified estimator is 
\begin{align*}
\text{asyVar}\left(\widehat{\CACE}_{\text{IV-a}} \right) = \text{asyVar}\left(\widehat{\CACE}_{\text{IV-w}} \right) &\approx \frac{1}{\pi_c^2}\textrm{var}(\widehat{\ITT}_{\text{PS}}).
\end{align*}

\subsection{Estimating precision}

Standard errors for $\widehat{\CACE}_{\text{IV-w}}$ and $\widehat{\CACE}_{\text{IV-a}}$ are obtained by estimating variances within each stratum and aggregating.
For the Bloom method, for example, the across strata estimator is
\begin{align*}
\widehat{\text{var}}_{\text{BLOOM}}\left(\widehat{\CACE}_{\text{IV-a}} \right) &\approx \frac{1}{\widehat{f}_{\text{PS}}^2}\sum_{g=1}^G\frac{N_g^2}{N^2}\widehat{\textrm{var}}(\widehat{\ITT}_{g}).
\end{align*}
For each stratum $g$, we can estimate $\widehat{\textrm{var}}(\widehat{\ITT}_{g})$ if there are at least two units assigned to treatment and two units assigned to control.
If not, blocked variance estimators for blocks with only a single treated or control unit would need to be employed \citep{pashley2021insights}.

Although asymptotically equivalent, the delta method suggests different variance estimators for $\widehat{\CACE}_{\text{IV-a}}$ and $\widehat{\CACE}_{\text{IV-w}}$ where we drop strata with zero estimated compliers when estimating the variance for $\widehat{\CACE}_{\text{IV-w}}$.
If $N_{g,z} \geq 2$ for all $g=1,\dots,G$ and $z \in\{0,1\}$, the variance estimator for $\widehat{\CACE}_{\text{IV-a}}$ is:
\begin{align*}
&\widehat{\text{var}}_{\text{DELTA}} \left(\widehat{\CACE}_{\text{IV-a}}\right)\\
&=\frac{1}{\widehat{f}_{\text{PS}}^2} \sum_{g=1}^G\frac{N_g^2}{N^2}\Bigg(\frac{s_{Y,g}^2(1)}{N_{g,1}} + \frac{s_{Y,g}^2(0)}{N_{g,0}} + \left(\widehat{\CACE}_{\text{IV-a}}\right)^2\left(\frac{s_{D,g}^2(1)}{N_{g,1}} + \frac{s_{D,g}^2(0)}{N_{g,0}}\right) - 2\widehat{\CACE}_{\text{IV-a}}\left(\frac{s_{Y,D,g}(1)}{N_{g,1}} + \frac{s_{Y,D,g}(0)}{N_{g,0}}\right)\Bigg).
\end{align*}
\noindent This estimator is based on the modified potential outcome representation within strata, and summing across strata with weights $N_g^2/N^2$. A variance estimator for $\widehat{\CACE}_{\text{IV-w}}$ is the following weighted sum of stratum-level IV variance estimates:
\begin{align*}
&\widehat{\text{var}}_{\text{DELTA}}(\widehat{\CACE}_{\text{IV-w}})=\sum_{g=1}^G\frac{\hat{f}_g^2N_g^2}{N^2\widehat{f}_{\text{PS}}^2}\widehat{\textrm{var}}\left(\widehat{\CACE}_{\text{IV, g}}\right)\\
&= \sum_{g=1}^G\frac{\mathbb{I}(\hat{f}_g \neq 0)N_g^2}{N^2\widehat{f}_{\text{PS}}^2}\Bigg(\frac{s_{Y,g}^2(1)}{N_{g,1}} + \frac{s_{Y,g}^2(0)}{N_{g,0}} + \widehat{\CACE}_{\text{IV-w}}^2\left(\frac{s_{D,g}^2(1)}{N_{g,1}} + \frac{s_{D,g}^2(0)}{N_{g,0}}\right) - 2\widehat{\CACE}_{\text{IV-w}}\left(\frac{s_{Y,D,g}(1)}{N_{g,1}} + \frac{s_{Y,D,g}(0)}{N_{g,0}}\right)\Bigg),
\end{align*}
where $\mathbb{I}(\hat{f}_g \neq 0) = 1$ if $\hat{f}_g \neq 0$ and is 0 otherwise.
It is straightforward to see that $\widehat{\text{var}}_{\text{DELTA}}(\widehat{\CACE}_{\text{IV-a}}) = \widehat{\text{var}}_{\text{DELTA}}(\widehat{\CACE}_{\text{IV-w}})$ whenever all $\hat{f}_g$ are nonzero.
Again, if there are not enough units per stratum to estimate variance within each, a combined blocked variance estimator would be necessary \citep{pashley2021insights}.

\section{Benefits of Post-stratification for IV estimates}

In this section we analytically derive three potential benefits from post-stratification for IV estimators. Specifically, we focus on when post-stratification (1) reduces variance, (2) increases precision of the estimated standard errors, and (3) reduces bias. 

\subsection{Variance Reduction and Standard Errors}

Post-stratification on a covariate predictive of either complier status or the outcome would ideally reduce the variance of our IV estimator. 
However, covariates predictive of compliance and those predictive of outcome are not equal in terms of their ability to increase precision, especially if we are not dropping low-compliance strata from the analysis.

Compare the delta-method asymptotic variances for the IV estimator before and after post-stratification:
\begin{align*}
\text{asyVar}(\widehat{\CACE}_{\text{IV}}) &= \frac{1}{\pi_c^2}\textrm{var}\left(\widehat{\ITT}- \frac{\ITT}{\pi_c}\widehat{f}\right) \mbox{ and } \\
\text{asyVar}(\widehat{\CACE}_{\text{IV-a}}) &= \frac{1}{\pi_c^2}\textrm{var}\left(\widehat{\ITT}_{\text{PS}} - \frac{\ITT}{\pi_c}\widehat{f}_{\text{PS}}\right) .
\end{align*}
As shown above, we can view both these asymptotic variances as exactly the (scaled) variances we would get from running a completely randomized experiment with potential outcomes $\tilde{Y}_i(z) = Y_i(z) - \frac{\ITT}{\pi_c}D_i(z)$, either unadjusted or with post-stratification, respectively.

The comparison of asymptotic variance for $\widehat{\CACE}_{\text{IV}}$ vs $\widehat{\CACE}_{\text{IV-a}}$ therefore amounts to whether post-stratification would be beneficial in an experiment with potential outcomes $\tilde{Y}_i(z) = Y_i(z) - \frac{\ITT}{\pi_c}D_i(z)$.
Based on \citet{miratrix2013adjusting}, we should expect (informally) for post-stratification to be beneficial in terms of variance reduction the more the variability of $\tilde{Y}_i(1)$ and $\tilde{Y}_i(0)$ is between strata than within.
From this result, to reduce variability through post-stratification we might consider reducing within stratum variability via either of the two pieces of $\tilde{Y}_i(z)$: make units within each stratum similar in terms of potential outcomes, $Y_i(z)$, without regard to the compliance aspect, or make units within each stratum similar in terms of $D_i(z)$ (compliance type).\footnote{A third option would be to target the entire expression $Y_i(z) - \frac{\ITT}{\pi_c}D_i(z)$, but we believe that it would be difficult to find covariates to do this directly.}
We expect reducing overall variation by targeting variation in compliance to be difficult for at least two reasons.
First, because the $D_i(z)$ terms are multiplied by the CACE in the $\tilde{Y}_i(z)$ expressions, if the CACE is small relative to overall variation in $Y_i(z)$, the impact of targeting $D_i(z)$ will likely be minor.
Second, if compliance is relatively rare, then the number of units that are actually differentially adjusted across treatment arms will be few, again making the impact of the second term minor.
Put differently, if the CACE is 0, then even if we stratify perfectly on compliance, we will only have gains if this stratification were effective for the original $Y_i(z)$, meaning our stratification variable was predictive of the original $Y$s as well.


Regarding the precision of standard errors, we can again use our post-stratification results for the modified potential outcomes.
In particular, if we reduce the true variance of our estimator, we should also expect to reduce the variance in our estimate of that variance \citep{pashley2020block}.
In our simulation study, we explore the extent of improvement in the standard error estimates.

Note that we focused here on the comparison of $\widehat{\CACE}_{\text{IV}}$ with $\widehat{\CACE}_{\text{IV-a}}$ rather than $\widehat{\CACE}_{\text{IV-w}}$.
Recall  $\widehat{\CACE}_{\text{IV-a}}$ and $\widehat{\CACE}_{\text{IV-w}}$ are the same when there are no strata with zero estimated compliers.
Our simulations in Section~\ref{sec:sims} demonstrate that the feature of $\widehat{\CACE}_{\text{IV-w}}$ of dropping strata with no estimated compliers reduces variability, and that these benefits can be even greater when we drop or down-weight strata more aggressively, as we will discuss in Section~\ref{sec:weighting}.


\subsection{Bias}

Post-stratification can also reduce the bias in the IV estimates that comes from the ratio estimator.
Critically, the bias reduction depends on whether noncompliance is one or two-sided.
That is, in some applications controls are unable to access treatment receipt such that $P(D_i = 0|Z_i=0) = 1$.
This is referred to as one-sided noncompliance. When this does not hold, there is two-sided noncompliance. 

In our calculations below, bias is with respect to the finite-population CACE under Assumptions~\ref{assump:iv} and \ref{assump:mono}.
The bias exists even under these assumptions (including when the IV is randomized) due to the random denominator in the IV estimator.
If the desired target of inference is the average effect for the full sample of $N$ units (assuming some hypothetical intervention in which noncompliers could be forced to comply) or a larger population from which the units were sampled, there would be additional generalizability bias.
For estimators that potentially drop or down-weight strata (e.g., $\widehat{\CACE}_{\text{IV-w}}$), we can have within-sample generalizability bias if the compliers in the dropped strata have systematically different treatment effects than the compliers in the kept strata; we discuss this in detail when we extend our family of estimators further in Section~\ref{sec:weighting}.



We first more precisely characterize the possible bias reduction due to post-stratification with one-sided noncompliance.
Under one-sided noncompliance, $\hat{f}$ is the observed proportion of those who took treatment in the treatment group.
When noncompliance is one-sided, we can write the bias in the standard IV estimator as:
\begin{align}
E\left[\widehat{\CACE}_{\text{IV}}\right] - \CACE 
&=  \frac{1}{1-p}\left(1  - E\left[ \frac{1}{\hat{f}}\right]E[\hat{f}]\right)\left( \overline{Y}_c(0)-\overline{Y}_n(0)\right) = \frac{1}{1-p}\text{cov}\left(\hat{f},  \frac{1}{\hat{f}}\right)\left( \overline{Y}_c(0)-\overline{Y}_n(0)\right) . \label{eq:bias}
\end{align}
\noindent The derivation of this result can be found in Supplementary Material~\ref{append:one_sided_bias}.

The dependence of Equation~\ref{eq:bias} on the covariance between $\hat{f}$ and $1/\hat{f}$ and a further Taylor approximation given in Supplementary Material~\ref{append:one_sided_bias} reveals that the bias depends on the magnitude of the $\text{var}(\hat{f})$. 
As such, reducing the variance of $\hat{f}$ can also reduce bias in the estimator. Therefore, the variance reduction properties of post-stratification can reduce bias as well. We can also characterize the direction of the bias reduction.
The bias reduction depends on the relative averages of outcomes of the compliers under control and the never-takers (under control or treatment).
We can express this quantity as $\Delta = \overline{Y}_c(0)-\overline{Y}_n(0)$, where $\overline{Y}_c(z)$ is the average potential outcome for all compliers in the sample under treatment $z$, and $\overline{Y}_a(z)$ and $\overline{Y}_n(z)$ are averages for the always- and never-takers.
A negative $\Delta$ implies the bias will be positive, and a positive $\Delta$ implies the bias will be negative.

When noncompliance is two-sided, we can express the bias in the standard IV estimator as
\begin{align*}
E\left[\frac{\widehat{\ITT}}{\hat{f}}\right] - \CACE & \approx  \frac{1}{\pi_c^2} \left[ \CACE \text{var}(\hat{f})- \textrm{cov}(\widehat{\ITT}, \hat{f}) \right] \\
& = \frac{1}{\pi_c^2(N-1)}\Bigg[ \frac{\pi_n((1-p)\pi_c + \pi_a)}{p(1-p)}(\overline{Y}_n(0) - \overline{Y}_c(0)) + \frac{\pi_a(p\pi_c + \pi_n)}{p(1-p)}(\overline{Y}_c(1) -\overline{Y}_a(1) )\Bigg]
\end{align*}
\noindent See Supplementary Material~\ref{append:two_sided_bias} for the derivation. In this context, the bias again depends upon the magnitude of the variance of $\hat{f}$. However, characterizing the direction of the bias is more complicated than in the one-sided noncompliance case.
The direction of the bias now depends on the relative group means of compliers, always-takers, and never-takers.
The relative differences between these three groups can either offset or increase the bias terms. Specifically, there will be a positive bias if $\overline{Y}_n(0) > \overline{Y}_c(0)$ and $\overline{Y}_c(1) >\overline{Y}_a(1)$, and there will be a negative bias if $\overline{Y}_n(0) < \overline{Y}_c(0)$ and $\overline{Y}_c(1) <\overline{Y}_a(1)$.


In this section, we focused on the possibility of bias reduction due to reducing variability.
However, the story is more complicated if, as we do with $IV_w$, we drop or re-weight strata, which can \emph{introduce} bias.
In particular, if some strata have higher chances of being dropped or down-weighted than others, then this can cause bias with respect to the overall CACE estimand.
See Section~\ref{sec:weighting} for further discussion.
Additionally, if our assumptions do not hold, additional bias can enter through post-stratification.
In particular, we show in Supplementary Material~\ref{supsubsec:er} that post-stratification can amplify bias if the exclusion restriction does not hold.

\section{Alternative post-stratification strategies}
\label{sec:weighting}

The original intuition of our post-stratification approach was that if we could isolate compliers into a few strata, we could benefit by the improved estimation in those strata.
The story turns out to be more complex than this, in that strata with few compliers are so unstable that, even though they have less overall weight in the final estimate, they are so variable that they can undo the precision gains achieved by having a greater proportion of compliers in the high-complier-rate strata.

To see this, consider the second line of Equation~\ref{eq:weighted_ITT} (Lemma~\ref{lemma:w_a_connection}): this line shows $IV_a$ (and thus $IV_w$ with no strata dropped) as a weighted average of ITT estimates, with the weights of the strata not dependent on the number of compliers, but instead the overall strata sizes.
This weighting by strata size means our strategy to upweight complier-rich strata is ineffective. 
In particular, even if stratum $g$ has few compliers, it will contribute just the same to the overall CACE estimate as it would to an ITT estimate!

If we are willing to possibly incur some further bias (beyond the normal bias of an IV estimator), we could decrease the weight of those strata with fewer compliers to potentially achieve precision gains by avoiding the weak instrument problem.
In this section we discuss two strategies for achieving this that build upon post-stratification.
The first strategy is to outright prune those strata with few compliers, similar to trimming an observational study of hard-to-match units.
The second strategy is to weight strata roughly proportional to complier prevalence or CACE estimator precision.

The $IV_w$ estimator already drops strata when $\widehat{f}_g = 0$ and, as we will see in the simulation study, even this limited pruning can stabilize the overall estimator.
If, however, $\widehat{f}_g \approx 0$ then we would include the stratum estimate of $\widehat{\ITT}_g/\widehat{f}_g$, which will be quite unstable due to the small denominator, in the overall weighted average.
We can avoid including such unstable estimates by thresholding at something other than exactly 0.
For example, we could drop any strata with estimated compliance less than 2\% (or any threshold of our choosing); we call this estimator the ``Drop-Small-Strata'' (DSS) estimator.
An alternative version of this estimator, which we call the ``Drop-Small-F'' (DSF) estimator, drops any stratum from the estimator where we fail the weak instrument test \citep{Stock:2005} for that stratum based on the F statistic for the importance of $Z$ in predicting $D$.
In particular, following common practice for IV estimation, we drop those strata where $F < 10$.

Dropping strata with low compliance has two benefits: first, we avoid unstable and potentially very large estimates from the low-compliance strata.
In other words, we focus our weighted average of ITT estimates on those strata with more compliers, and thus on those with more information on the treatment effect of compliers.
Second, we avoid odd behavior in the two-sided noncompliance case when $\widehat{f}_g < 0$.
For a stratum with $\widehat{f}_g < 0$, the estimate of the ITT is a function of the overabundance of always-takers in the control side, and a sign flip due to the negative compliance rate, neither of which have anything to do with treatment impact for the compliers in the stratum.
Given this observation, we introduce the Drop-Small-Strata-less-than-0 (DSS0) estimator, which just drops all strata with $\hat{f}_g \leq 0$.

For an alternate approach, consider that post-stratification is a weighted average of subgroup estimates. 
We saw that we weighted the CACE estimates for $\widehat{\CACE}_{\text{IV-w}}$ by the estimated number of compliers within each stratum, and the component parts of $\widehat{\CACE}_{\text{IV-a}}$ by the number of individuals within each stratum.
We might naturally wonder about other weightings of these component parts.
In particular, we might weight by the (estimated) precision of each strata using a Precision Weighted IV estimator (PWIV).
The PWIV estimator has a form similar to $\widehat{\CACE}_{\text{IV-w}}$ but weights by the (Bloom) estimated precision of each stratum: 
\[
\widehat{\tau}_{\text{PWIV}} = \frac{1}{W}\sum_{g=1}^G \frac{\widehat{f}_g^2}{\widehat{\text{var}}(\widehat{\ITT}_g)} \widehat{\CACE}_{g} \mbox{ with } W = \sum_{h=1}^G \frac{\widehat{f}_h^2}{\widehat{\text{var}}(\widehat{\ITT}_h)}.
\]
This estimator more heavily weights strata with higher estimated proportion of compliers than $IV_w$ (see the $\hat{f}^2_g$ term in the weight, vs. $\hat{f}_g$ in $IV_w$).



\noindent \textbf{Impact of treatment effect heterogeneity}

 Either by dropping strata or reweighting them, the overall goal is to discount those strata with low proportions of compliers, as their associated estimates are very unstable, and focus attention on strata where, in principle, estimating the complier average impact is easier.
This can incur bias: this process will shift our estimand away from the overall CACE, and towards a reweighted CACE tilted towards the average effect of those compliers in strata that tend to be kept or upweighted.
If these compliers have, for example, higher impacts in general, our overall estimates will tend to be larger than the true overall CACE.
That being said, if the CACE is homogenous across strata, or if the proportion of compliers left out of the overall estimate is small, than this bias will be minimal.
Especially considering we are targeting dropping strata with few compliers, it seems reasonable that our biased CACE may not be too far off the true overall CACE target.
In other words, the more homogenous the treatment effect is across all units (in the sample or population that is the target of inference), the smaller any generalizability bias.
As such, a useful diagnostic would be to consider the possibility of  treatment effect heterogeneity among the compliers. In general, this will consist of qualitative arguments, since the compliers are unobserved. 
That being said, it may be difficult to reason about treatment effect heterogeneity among the compliers when multiple categorical variables are combined to create relatively smaller strata.


As an additional problem, we are dropping or down-weighting strata based on \emph{estimated} compliance rates.
 This can create difficulties; for example, under one-sided noncompliance, we only drop those strata with no compliers randomized to the treatment assignment arm, as that is where we estimate the compliance rate, but keep strata if there are no compliers on the control side.
This asymmetry in our estimation approach again opens the door to bias.
The practical implications of all of these biases are explored further in the simulation section.

 

As a further advantage of these estimators, focusing attention on the complier-rich strata could partially control bias in contexts where the exclusion restriction is violated.
In particular, in the strata with more compliers, the bias caused by violation of the exclusion restriction via treatment impact on the noncompliers would be attenuated, as there are fewer noncompliers in the ITT estimate.
The bias is, in other words, isolated into the low-compliance strata, which are then discounted in the overall estimate.
This is illustrated in the final additional simulation in the supplementary materials.


\section{Simulation Study}
\label{sec:sims}

We explore the analytic results using a simulation study to compare the different estimation strategies.
We investigate $\widehat{\CACE}_{\text{IV-a}}$ and $\widehat{\CACE}_{\text{IV-w}}$, the two stratification approaches described above.
Of course, as we have mathematically shown, these estimators are identical except when some strata have $\hat{f}_g = 0$; we will examine which estimator tends to perform better overall, including when this event occurs.
We also include the variant of $\widehat{\CACE}_{\text{IV-w}}$ where we drop all strata with $\hat{f}_g \leq 0$, the Drop-Small-F (DSF), the Drop-Small-Strata-less-than-0 (DSS0), and the Precision Weighted IV (PWIV) estimators from Section~\ref{sec:weighting}.

As a baseline we consider the simple IV estimator that ignores the covariate entirely. We also include the usual two-stage least squares estimator \citep[as implemented by the AER package in R,][]{aer}, using the stratification category as a covariate. We finally include an Oracle estimator of the simple difference in means estimate applied to the subset of compliers; this represents a best-case context where we know complier status perfectly.

For each estimator (save the Oracle and 2SLS) we have two methods for calculating a standard error: (1) the Bloom approach, where we consider the proportion of compliers as fixed, and (2) the delta method approach, which accounts for the uncertainty in estimating the compliance rate.
We compare the performance of these two standard error estimators along with the performance of the point estimators.

For each simulated dataset, we generate four strata, in line with our empirical example.
We vary several simulation factors of interest:

\begin{enumerate}
	\item Overall size of the experiment ($N = 500, 1000, 2000$).
	\item Overall proportion of compliers (5\%, 7.5\%, and 10\%).
	\item One-sided noncompliance, and two-sided noncompliance with two-thirds of the noncompliers being always-takers.
	\item Whether group membership predicts complier status or not.
	\item Whether group membership predicts the outcome or not.
	\item Whether the mean of the never-takers is below, equal to, or above the mean of the compliers' control potential outcomes. (We leave the always-takers mean in line with the compliers.)
	\item Whether the treatment impact is different across strata, or constant.
\end{enumerate}

The above factors result in 432 distinct scenarios that we explore.
For each iteration of our simulation, we generate all the potential outcomes for all units, and then randomize 30\% of the units into treatment, leaving the rest as controls.
We then apply our suite of estimators to the resulting data, and record the point estimate along with the two standard error estimates from the Bloom and Delta method approaches.
See Supplementary Materials~\ref{app:simulation} for further details on the data generating process.


In running our simulation, given the low compliance rates, some of the estimators could give extreme values, especially in the two-sided noncompliance case.
For example, the baseline unstratified estimator is undefined if the compliance rate is estimated at precisely 0, and can be of very large magnitude if the difference in treatment take-up in the two arms is a single unit.
The DSF estimator would often drop all strata in many of the two-sided noncompliance cases.
The 2SLS estimator similarly evidenced unstable behavior.
We therefore dropped all undefined trials and windsorized all impact estimates to $\pm 10$ standard deviations.
Overall, we dropped less than a tenth of a percent of our estimates (other than the DSF which was near 31\%), and windsorized a bit over 1\% of the remaining observations for 2SLS, $IV_a$, and the baseline, around 0.75\% of $IV_w$, and less for the remaining estimators.

The standard errors are also susceptible to low complier estimates, and can be too large.
In the two-sided noncompliance case, in particular, the asymmetrical treatment assignment means the estimated proportion of compliers can be very close to zero without being exactly zero, creating serious instabilities in the delta-method standard errors.\footnote{For example, consider a strata with 231 units, 76 treated and 155 control. Of the 76, 51 take treatment, and of the 155, 104 take treatment.  The estimated complier rate is then $51/76 - 104/155 \approx 8.5 \times 10^-5$, making the CACE estimate 11,780 times the ITT estimate for that strata, which is massive and implausible.  This extreme estimate would then get averaged, weighted by strata size, ruining the overall estimate. The unstratified estimator can also have this behavior.}
We thus windsorized the standard errors to $\pm 10$ standard deviations as well. Underscoring the instability in uncertainty estimation, around 5\% of the two-sided simulation trials were thus windsorized for each estimator other than DSF and PWIV.




\subsection{Results}

Overall performance characteristics across all simulation scenarios are shown in Figure~\ref{fig:overall_performance}, with the top row being one-sided noncompliance and the bottom row being two-sided noncompliance.
We average the performance metrics across all the scenarios of a given sample size to get average trends across the other specifications.
In general, the post-stratified estimators have less bias, lower standard errors, and lower RMSEs than doing a standard unstratified analysis.
The 2SLS and $IV_a$ estimators basically coincide, as anticipated, in terms of performance; the lines are over-plotted in the figure.
The $IV_w$ estimator substantially outperforms the $IV_a$ estimator on average, and the weighting estimators are in turn outperforming $IV_w$ in terms of precision and overall RMSE.
The DSS0 estimator further outperforms $IV_w$ indicating that it is sensible to drop strata with zero or negative estimated proportion of compliers (which would indicate zero or negligible compliers under monotonicity), although the two estimators will always coincide in the case of one-sided noncompliance.
Relative to the standard error, the bias is negligible, although there is notably more bias for the two-sided non-compliance scenarios.
Overall, two-sided non-compliance is a harder estimation problem; bias, SE, and RMSE are all notably higher.

We verified that our two versions of post-stratification, $IV_a$ and $IV_w$, give identical point estimates if all strata are defined, as anticipated.
Notably, dropping strata estimated to be have zero compliers does impact \emph{overall} performance, allowing $IV_w$ to improve over $IV_a$.
Note how, in Figure~\ref{fig:overall_performance}, the average standard error and RMSE of $IV_{a}$ (IV across, using adjusted numerator and denominator for the overall ratio) is larger than that for $IV_{w}$ (IV within and then average).
We calculated the ratio of the RMSEs of $IV_{w}$ vs. $IV_{a}$ for all scenarios, and found that $IV_w$ can easily be more than 30\% smaller (with a 13\% average reduction across all scenarios) with the gains being correlated to the chance of dropped strata.
As a point of reference, across the simulation scenarios, one or more strata had zero estimated compliers (and were thus dropped) about half of the time due to a mix of small strata, small sample size, and low overall compliance.


\begin{figure}[hbt]
  \includegraphics[width=\textwidth]{figures/overall_performance_plot_pool_dual.pdf}
  \caption{Overall performance characteristics of the point estimators with absolute bias, true Standard Error, and RMSE averaged across the different simulation scenarios grouped by overall sample size. Top row is one-sided noncompliance, bottom row is two-sided. Legend orders estimators by overall height of the lines. In particular, all considered estimators lie between the unstratified (top line) and oracle (bottom line) in performance.}
  \label{fig:overall_performance}
\end{figure}

\subsubsection{Variance reduction}

We next examine which factors drive the degree of improvement in the standard errors.
To contextualize the uncertainty, we compare the standard error of $IV_a$ and $IV_w$ to the unstratified standard error for each simulation scenario.
A ratio of 75\% for $IV_{w}$, for example, would represent a 25\% reduction in the variance if one post-stratifies using $IV_{w}$ vs. using the unstratified IV.
Figure~\ref{fig:variance_ratio_plot} shows that stratifying by a covariate predictive of $Y$ (outcome) or $C$ (compliance status) both help.
It is clear that using covariates predictive of outcome can substantially improve precision.
For covariates predictive of compliance, gains are largest in the cases of low compliance and smaller sample sizes.
This is driven by dropping strata with 0 estimated compliers; see the second row for $IV_a$ that show no real gains of compliance-predictive covariates for $IV_a$ (and thus, by extension 2SLS).

For $IV_w$, we actually see a benefit even when the covariate is neither predictive of compliance status nor outcome, when $\pi_c$ and sample size is low (see top left of figure).
This stems from the benefits of dropping those strata with no observed compliers, which adds substantial stability to the estimator, providing benefits well beyond the bias incurred.
We unpack this surprising finding in the supplementary materials.
It is related to the discussion of why a complier-predictive covariate fails to provide much gains for 2SLS, which we discuss further in Section~\ref{sec:complier_predictive_covariate}


\begin{figure}[hbt]
  \includegraphics[width=\textwidth]{figures/variance_ratio_plot_v2_pool_dual.pdf}
  \caption{Ratio of variance of $IV_{w}$ to unstratified IV.}
  \label{fig:variance_ratio_plot}
\end{figure}



\subsubsection{Bias}


\begin{figure}[hbt]
  \includegraphics[width=\textwidth]{figures/bias_ntshift_plot_pool_dual.pdf}
\caption{Bias of estimators for heterogenous treatment effect scenarios only. Scenarios grouped by overall compliance rate ($x$-axis), sample size (color of line) and one- (top row) vs two-sided (bottom row) noncompliance.}
  \label{fig:bias}
\end{figure}

For the scenarios considered, bias is a much smaller share of the overall RMSE than variance; see the low range of biases on Figure~\ref{fig:overall_performance}, relative to the SEs.
We plot the biases again on Figure~\ref{fig:bias}, to clarify the bias trends.
For one-sided noncompliance, $IV_w$ has much less bias, as anticipated.  The instability it faces in the two-sided noncompliance case seems to erase bias gains, however (see bottom row).
As expected, DSF and PWIV have elevated levels of bias: they are estimating the CACE of the kept strata in the first case, and weighting the higher-compliance more heavily in the second case, which shifts their respective estimands. 
$IV_w$ and DSS0, in principle, do the same by dropping low-compliance strata when the estimated compliance is precisely 0 (or negative).
Even so, the bias reduction due to stratification for this estimator cause it to generally be the least biased of all the estimators considered.
$IV_a$ (and by extension 2SLS) can have less bias than the simple IV, but the relative improvement is negligible across scenarios.


\subsubsection{Standard error estimation}

A standard error estimator is well calibrated if it is, on average, equal to the true standard error in a given context.
To assess this we calculate the square root of the ratio of the average of the squared standard error estimates to the true squared standard error (the estimator variance) for each context.\footnote{We calculate the ratio of variances because usual standard error estimators generally give unbiased variance, not SE, estimates. The outer square root brings the ratio back to the scale of standard error.}
Unfortunately, the standard error estimates, especially from the Delta method, have a very strong right skew, with fairly common extreme values.
We windsorized at a fairly large 10 standard deviations, but even so around 20\% of the standard errors were windsorized for some scenarios for the primary estimators.
This process will substantially reduce the average estimated standard error, which will play a role in interpreting the ratio of average to estimated true standard error.

Calibration results are on Figure~\ref{fig:se_estimator_plot}.
For one-sided noncompliance, the delta method for calculating standard errors can give standard errors that are a bit too high (15\% or more for many scenarios when $N=500$, for example), while the simpler Bloom estimator generally performs well, although they can be anti-conservative when sample sizes are small.
The 2SLS standard errors are also somewhat inflated for small sample size.
The DSF estimator, and to a lesser extent the PWIV estimator, tend to have overly large Bloom standard errors for some scenarios.
Two-sided noncompliance is a much worse story---note the $y$-axis has different scales in the top and bottom row of the figure---even with windsorizing, the average standard error regularly being 3 or 4 times too large.

Figure~\ref{fig:se_estimator_plot} is driven by the outliers; the ratio of the median estimated standard error to the true standard error (see supplement) is generally slightly below 100\%, indicating that, more often than not, the estimated standard error is too low. 
In Supplementary Material~\ref{sec:se_stability} we show that, for one-sided noncompliance, the stability of the estimated standard errors for the post-stratified estimators, relative to their true standard errors, is about the same as for the unstratified estimators.

Overall, these results underscore the difficulty of estimating uncertainty in weak instrument contexts.
That being said, the Bloom estimator does appear to be less vulnerable to extreme estimates and has decent overall properties.


\begin{figure}[hbt]
\center
  \includegraphics{figures/se_estimator_plot_pool_dual.pdf}
  \caption{Relative percent change of average estimated standard error to true standard error, calculated as the square root of the mean estimated squared standard error divided by true variance (as estimated across simulation trials) for both the delta method and Bloom standard errors. Each point is a specific simulation scenario. Points above 100\% indicate standard errors systematically too large, and below systematically too small.}
  \label{fig:se_estimator_plot}
\end{figure}



\subsection{Complier Predictive Covariates}
\label{sec:complier_predictive_covariate}


\begin{figure}[hbt]
\centering
  \includegraphics[width=\textwidth]{figures/predC_Bias_SE_RMSE}
 \caption{Simulation results with compliers increasingly concentrated in the upper strata. Unstratified, $IV_a$ and 2SLS are all overplotted, as their performances are essentially the same.}
  \label{fig:pred_C_only}
\end{figure}


To explore the tension between increased instability in strata with few compliers and their having less weight, we conducted a second set of simulations where we generated a series of datasets with the same overall compliance rate (15\%), but an ever-increasingly predictive predictor of compliance ranging from the compliers being evenly distributed across the strata (no prediction) to all the compliers being in the same stratum (perfect prediction).
We have substantial treatment heterogeneity across strata, with $CACE=0$ in the lowest strata and an $CACE$ of $4\sigma$ in the fourth.
Results are in Figure~\ref{fig:pred_C_only}.

The middle plot of Figure~\ref{fig:pred_C_only} shows the relative size of the true SE of an estimator to the unstratified baseline on the $y$ axis. The $x$-axis shows the $R^2$ of a regression of compliance onto the strata variable.
Even when we have near 100\% $R^2$ (perfect prediction of compliance) the $IV_a$ estimator has virtually no gains.
For $IV_w$ and DSS0, we do see precision gains but only at very high values of $R^2$, with DSS0 having slightly larger gains.
The DSF estimator, more aggressive than $IV_w$ in dropping strata, more quickly realizes gains in the standard errors.
The PWIV estimator has an even sharper drop off in variance, but also is the most biased (see left hand column of plots).

Figure~\ref{fig:pred_C_only} also allows for comparing all estimators to an oracle (the bottom line) of the simple difference in means of the known compliers.
This estimator could be achieved if we knew the complier status of all units.
Such knowledge would be extremely beneficial; the oracle has a standard error less than half of the unstratified estimator.
For one-sided noncompliance, only when we have perfect prediction do $IV_w$, DSF, and PWIV converge to this oracle.
For two-sided noncompliance, if we are not actively discounting or dropping the strata with always-takers, we do not as easily obtain the benefits of our predictor--random imbalance of always-takers makes the other strata still have weight, which introduces instability into the overall estimate.
The DSF and PWIV, by dropping and down-weighting these strata, can achieve the oracle's performance.

When we have even only a few compliers across all strata, we immediately are faced with countervailing forces: on one hand, we can down-weight those strata that we know represent a small fraction of the compliers.
On the other hand, the low compliance rates in those strata generate extremely unstable estimates, and so weighting by estimated number of compliers still allow those extreme values to destabilize the overall weighted average. 
When we \emph{drop} small strata, however, this destabilization does not occur, and we see benefits.
PWIV's down-weighting unstable strata more heavily here is a type of ``soft dropping.''

Dropping strata or re-weighting does open the door for bias, however.
In our simulation, the treatment impact is higher for compliers in the higher strata, and for scenarios where the compliers are concentrated in the higher strata, the lower strata get dropped either by random 0 estimates of compliance rate (for $IV_w$ and DSS0) or when failing the F-test (for DSF), thus inflating the estimated treatment impact.
For PWIV, the re-weighting of strata introduces bias when there is treatment effect heterogeneity across strata because we are no longer weighting to the sample average, but rather the precision weighted average.
However, the bias is relatively small: the PWIV line in the RMSE plot is only modestly raised over the corresponding line in the SE plot, showing bias is a small fraction of overall error.
For at least these simulations, the drawbacks of introducing bias appear to be more than offset by the benefits of increasing precision.


\subsection{Discussion}

In our simulations, we considered two properties, prediction of the outcome and prediction of compliance, of variables that can be used for post-stratification. Post-stratifying can directly improve precision when using covariates predictive of outcome. To gain from a complier-predictive covariate, however, we have to do more than post-stratify: we have to down-weight or drop the ``empty'' or low compliance rate strata. The stability gained from dropping such strata is general: in fact, as we show in the supplementary materials, precision gains can be achieved even if stratifying on covariates completely unrelated to compliance or outcome, although this comes with associated bias gains.
The standard errors of the post-stratified estimators tend to be relatively well calibrated for one-sided but not two-sided noncompliance, with the delta approach---that nominally takes into account all forms of uncertainty---performing notably worse than Bloom approach for many of the contexts we explored.

These results imply that to exploit a variable predictive of compliance, analysts need to create multiple strata, and some of those strata need to have a small fraction of compliers. A stratification variable of this type provides a better chance of having estimated compliance rates of zero or close to zero in some strata, which is where the gains come from. As such, a single binary variable is unlikely to be useful unless it can nearly perfectly separate compliers and noncompliers.
One strategy could be to combine multiple binary variables to create many strata, which may result in some strata with few compliers in them.

\section{GOTV Applications}

Next, we employ our post-stratification methods to re-analyze data from two GOTV experiments. In our first analysis, we use data from an RCT designed to compare the effectiveness of three methods of voter contact: door-to-door canvassing, phone calls, and sending mailers \citep{Gerber:2000}. This RCT was conducted in New Haven, Connecticut ahead of the November 1998 election. Households with one or two registered voters were randomized to receive some combination (or none) of the three practices. To simplify the analysis, we focus on door-to-door canvasing, where households either received face-to-face contact from canvassers encouraging them to vote, i.e. treatment, or were not contacted, i.e. control. The outcome of interest is whether either household member voted in the 1998 election. In addition to outcome and treatment assignment, the data also contain covariates on household members such as age and whether they voted in the 1996 election. We use the version of the data \cite{gg_gotv_data} used in \cite{hansen2009attributing}.

In the original analysis, the analysts estimated the CACE using two-stage regression \citep{Gerber:2000}. We follow the original analysis and do not consider the exposure as time varying.
This is reasonable given our focus on the in-person canvasing condition, though might be a concern in the other conditions.
For mailers, the investigators varied how many fliers (up to three) were sent to individuals.
Further, in the phone call condition, multiple contact attempts were made if the initial contact was not successful.
Exploring the use of our methodology with time-varying exposure, which typically makes standard instrumental variable methods perform poorly \citep{Hernan:2006}, would be an interesting direction for future exploration.

We post-stratify based on age, vote in 1996, and household size. Age and household size are likely predictors of compliance (in this case, being home and answering the door if assigned to door-to-door canvasing), and thus should serve as compliance-predictive covariates. Prior vote behavior is likely predictive of future vote behavior (the outcome), and thus is expected to improve precision via either post-stratification or two-stage least squares. In our analysis, we computed the average age by household and split the variable into four approximately equal size groups. Vote in 1996 is defined here as whether either household member voted in two-voter households. This resulted in 23,450 households across 17 strata defined as all realized combinations of these covariates plus a strata for those with missing block variables. Estimated compliance rates across the strata range from about 16\% to 43\%, providing some indication that we are stratifying in a meaningful way in terms of compliance. Estimated CACEs similarly varied across strata from about -0.19 to 0.43.

Table~\ref{tab:outcomes1} contains CACE estimates based on an unstratified estimator and the proposed stratification methods.
We see an approximately 14\% reduction in standard errors from the post-stratified estimators, except for PWIV, which has approximately an 18\% reduction. Put another way, this means an experiment with only 75\% of the sample size, but using post-stratification, would have similar levels of power to the original; this is a substantial reduction in total effort. This indicates appreciable gains in precision by using post-stratification: we are taking advantage of the complier-predictive nature of our covariates. Similar results in terms of standard error reduction with post-stratification were found using a factorial analysis on the full range of treatment options estimating the Marginal Average Complier Effect, as defined in \cite{blackwellpashley}.
Except for PWIV, the different post-stratification methods result in the same point and variance estimates because no stratum has an estimated 2\% or fewer compliers and no stratum failed the F-test. This illustrates that the extra advantages of the stratification methods that drop strata with low compliance can only be realized when strata are small enough and correlated enough with compliance to result in low compliance strata. We expect PWIV to introduce potential bias for estimating the average effect among compliers, moving the estimator to target those individuals who are more likely to comply. In this example, this means up-weighting individuals who are older, have previously voted, and come from larger households.
The potential bias will be larger if the effect of door-to-door canvasing among those individuals differs from the effect among the types of individuals who are less likely to comply. For example, it is plausible that individuals who have voted previously are likely to vote again, whether they receive a canvaser or not, leading to smaller estimated effects when those individuals are up-weighted.


\begin{table}[ht]
\centering
\caption{Results from unstratified and various post-stratified IV estimators for door-to-door canvassing GOTV experiment.  Bloom SEs reported.  ``\% SE'' is percent change of SE relative to Unstratified}
\label{tab:outcomes1}
\begin{tabular}{lrrrrrr}
  \toprule
Method & $\widehat{\pi}_c$  & $\widehat{CACE}$ & $\widehat{SE}$ & \% SE & $n$ & p-value\\ 
  \midrule
UNSTRAT & 0.296 & 0.084 & 0.0275 & 100 & 23,450 & 0.0024 \\ 
  $IV_w$ & 0.298 & 0.095 & 0.0238 & 86.2 & 23,450 & 0.0001 \\ 
  $IV_a$ & 0.298 & 0.095 & 0.0238 & 86.2 & 23,450 & 0.0001 \\ 
  DSS (2\%) & 0.298 & 0.095 & 0.0238 & 86.2 & 23,450 & 0.0001 \\ 
  PWIV  & 0.298 & 0.092 & 0.0226& 82.0& 23,450 & 0.0000 \\ 
  DSF  & 0.298 & 0.095 & 0.0238 & 86.2 & 23,450 & 0.0001 \\
   \bottomrule
\end{tabular}
\end{table}


The second study we analyze is the evaluation of door-to-door canvasing described in the introduction \citep{Green:2003a}. In the study, 8,580 votes were assigned to the treatment condition and 10,081 we assigned to control. Turfs (randomization blocks) ranged in size from 16 voters to 535 voters, with an average size of 124 voters. We use these 150 turfs as strata, since compliance rates differed significantly across each turf. We find the estimated compliance rates varied from 5\% to 69\% with an average compliance rate of 30\%. Moreover, turnout rates also varied substantially by turf (estimates from a multilevel logistic model suggest true voting rates ranged from 6\% to 61\%), showing this stratification covariate is also predictive of the outcome.

Table~\ref{tab:outcomes2} contains CACE estimates based on an unstratified estimator and the proposed stratification methods. The unstratified estimate indicates that exposure to canvassing increased voter turnout by 8\%. The estimates from the stratified methods are all between 4 and 5\%, nearly 50\% smaller. In this case the precision gains are more modest, with reductions of around 4\%.  There were no strata with estimated 2\% compliance or less, leading to $IV_w$, $IV_a$, and DSS having the same estimates. However, not all strata passed the F-test, so DSF results in a different estimate. One interesting feature of the analysis is that, while the DSF estimator had a notable reduction in sample size (close to 15\% reduction), the standard error estimate is not any larger than for the unstratified estimator. This emphasizes that for IV estimates, not all data are useful.

\begin{table}[ht]
\centering
\caption{Results from unstratified and various post-stratified IV estimators for door-to-door canvassing GOTV experiment.  Bloom SEs reported.  ``\% SE'' is percent change of SE relative to Unstratified}
\label{tab:outcomes2}
\begin{tabular}{lrrrrrr}
  \toprule
Method & $\widehat{\pi}_c$  & $\widehat{CACE}$ & $\widehat{SE}$ & \% SE & $n$ & p-value\\ 
  \midrule
UNSTRAT & 0.29 & 0.082 & 0.023 & 100 & 18,661 & 0.00 \\ 
  $IV_w$ & 0.30 & 0.055 & 0.022 & 96 & 18,661 & 0.01 \\ 
  $IV_a$ & 0.30 & 0.055 & 0.022 & 96 & 18,661 & 0.01 \\ 
  DSS (2\%) & 0.30 & 0.055 & 0.022 & 96 & 18,661 & 0.01 \\ 
  PWIV & 0.30 & 0.042 & 0.020 & 86 & 18,661 & 0.03 \\ 
  DSF & 0.32 & 0.047 & 0.022 & 97 & 16,010 & 0.03 \\
   \bottomrule
\end{tabular}
\end{table}

\section{Conclusion}
 
We have explored the benefits of combining IV estimators with post-stratification. We outlined the gains that are possible both analytically and through a series of simulations. We largely focused on how to use post-stratification to take advantage of a baseline covariate predictive of compliance behavior, rather than the outcome. Classic IV estimation methods are not designed to exploit the information from covariates of this type. Post-stratification on these covariates, by isolating compliers in some strata and dropping the rest, can, however, provide important precision gains. We also studied the post-stratified IV estimator more broadly. The theoretical advantages of this approach include lower bias, lower variance, and lower variability of the SE estimates, especially when stratifying on a covariate predictive of outcome.

In practice, researchers will need to make choices on how to stratify and which method to use for estimation with post-stratification.
While stratifying on covariates predictive of outcome will give a boost to precision, stratifying on covariates predictive of compliance only improves precision if we are able to drop or down-weight lower compliance strata. Therefore, when considering which covariates to use in post-stratification with IV, it is advantageous that covariates believed to be predictive of compliance are not too coarse (e.g., not binary), or that several such covariates are combined. This will allow greater variation of compliance proportions across the strata, increasing the likelihood that we can drop strata with no or very few compliers.
However, there is a trade-off with strata that are too fine: We risk ending up with one or fewer treated or control units in a stratum, making inference for that stratum infeasible. It would therefore be advantageous for researchers to pick stratification variables that yield large enough groups that the risk of a singleton treated or control unit within a stratum is very low. This may mean focusing on covariates predictive of outcome when covariates predictive of compliance would be too coarse. To maintain the validity of inferences after post-stratification, researchers should choose these stratification variables and the method of stratification prior to seeing the data, ideally in a publicly available pre-analysis plan. Researchers should also state their intended method for evaluation prior to seeing the data, including the criteria for droppings strata if using methods such as DSS or DSF. Overall, our results show that $IV_W$ (and in the two-sided case, DSS0 which also drops strata with negative estimated compliers) should generally be preferred to $IV_A$, and that methods that further drop strata or down-weight low-compliance strata, such as PWIV, may be preferable based on a researcher's tolerance of the bias-variance tradeoff.


As we noted above, IV post-stratification methods have the widest applicability in contexts where the instrument passes the classic weak instrument test but compliance is relatively low. Such a pattern is typical for RCTs on the effectiveness of GOTV methods. Given the difficulties of directly contacting voters---by any method---generally creates instances with relatively low levels of compliance. However, other areas of research that use RCTS face similar compliance patterns. For example, the evaluation of youth education and outreach efforts also often have low levels of compliance \citep{guryan2023not, heller2014summer}.

In addition, it must be the case that the data contain variables for post-stratification. Specifically, analysts need to identify a variable in which some strata have few compliers. Ideally, post-stratification can be built into the design phase of the experiment. That is, as we observed, combining geographic identifiers with age performed well as a stratification variable.
Collection of these data can be apart of the design phase of future GOTV RCTs. In addition, better stratification variables might be identified in the future. GOTV RCTs are regularly conducted during election cycles \citep{green2019get}. Future iterations of GOTV RCTs could be used to identify additional variables for post-stratification.
More generally, data from any similar experimental design could be used to identify post-stratification variables for use in future experiments.






\clearpage

\bibliographystyle{apalike}
\bibliography{iv_ref,gotv}{}


\begin{appendices}
\include{iv_post_append}
\end{appendices}




\end{document}