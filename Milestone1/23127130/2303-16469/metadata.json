{
    "arxiv_id": "2303.16469",
    "paper_title": "Learning Complicated Manipulation Skills via Deterministic Policy with Limited Demonstrations",
    "authors": [
        "Liu Haofeng",
        "Chen Yiwen",
        "Tan Jiayi",
        "Marcelo H Ang"
    ],
    "submission_date": "2023-03-29",
    "revised_dates": [
        "2023-03-30"
    ],
    "latest_version": 1,
    "categories": [
        "cs.RO",
        "cs.AI"
    ],
    "abstract": "Combined with demonstrations, deep reinforcement learning can efficiently develop policies for manipulators. However, it takes time to collect sufficient high-quality demonstrations in practice. And human demonstrations may be unsuitable for robots. The non-Markovian process and over-reliance on demonstrations are further challenges. For example, we found that RL agents are sensitive to demonstration quality in manipulation tasks and struggle to adapt to demonstrations directly from humans. Thus it is challenging to leverage low-quality and insufficient demonstrations to assist reinforcement learning in training better policies, and sometimes, limited demonstrations even lead to worse performance.\n  We propose a new algorithm named TD3fG (TD3 learning from a generator) to solve these problems. It forms a smooth transition from learning from experts to learning from experience. This innovation can help agents extract prior knowledge while reducing the detrimental effects of the demonstrations. Our algorithm performs well in Adroit manipulator and MuJoCo tasks with limited demonstrations.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16469v1"
    ],
    "publication_venue": null
}