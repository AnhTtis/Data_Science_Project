@misc{siemensprescan,
	title        = {Lidar simulation and validation for autonomous vehicles},
	author       = {{Siemens}},
	howpublished = {\url{https://www.plm.automation.siemens.com/global/en/webinar/lidar-simulation/87062}},
	note         = {Accessed Sep. 10, 2021},
    year         = {2021},
	editor       = {{Siemens}}
}
@misc{ansys,
	title        = {Ansys AVxcelerate Sensors Test and Validate Sensors for Self-Driving Cars},
	author       = {{ANSYS Inc}},
	howpublished = {\url{https://www.ansys.com/de-de/products/av-simulation/ansys-avxcelerate-sensors}},
	note         = {Accessed Sep. 10, 2021},
    year         = {2021},
	editor       = {ANSYS Inc}
}
@misc{dyna4,
	title        = {Vector and DYNA4: Environment Perception for ADAS and Autonomous Driving},
	author       = {{Vector Informatik}},
	howpublished = {\url{https://www.vector.com/int/en/products/products-a-z/software/dyna4/sensor-simulation/}},
	note         = {Accessed Sep. 10, 2021},
    year         = {2021},
	editor       = {Vector Informatik}
}
@inproceedings{Quigley2009,
   author = {Morgan Quigley and Brian Gerkey and Ken Conley and Josh Faust and Tully Foote and Jeremy Leibs and Eric Berger and Rob Wheeler and Andrew Ng},
   journal = {Intl. Conf. on Robotics and Automation 2009 (ICRA)},
   month = {1},
   title = {ROS: an open-source Robot Operating System},
   year = {2009},
}
@misc{vtd,
	title        = {Vires and VTD, Sensor modeling in Autonomous Driving},
	author       = {{VIRES}},
	howpublished = {\url{https://vires.mscsoftware.com/solutions/sensors/}},
	note         = {Accessed Sep. 10, 2021},
    year         = {2021},
	editor       = {VIRES Simulationstechnologie}
}
@misc{driveworks,
	title        = {DriveWorks SDK},
	author       = {{NVIDIA}},
	howpublished = {\url{https://developer.nvidia.com/drive/driveworks}},
	note         = {Accessed Sep. 10, 2021},
    year         = {2021},
	editor       = {NVIDIA}
}
@misc{rfpro,
	title        = {{ADAS {\&} Autonomous}},
	author       = {{rFpro}},
	howpublished = {\url{https://www.rfpro.com/virtual-test/adas-and-autonomous/}},
	note         = {Accessed Sep. 10, 2021},
    year         = {2021},
	editor       = {rFpro}
}
@misc{aurelion,
	title        = {{AURELION Lidar Model}},
	author       = {{dSPACE}},
	howpublished = {\url{https://www.dspace.com/fr/fra/home/products/sw/experimentandvisualization/aurelion_sensor-realistic_sim/aurelion_lidar.cfm}},
	note         = {Accessed Sep. 10, 2021},
    year         = {2021},
	editor       = {dSPACE}
}
@inproceedings{Shah2017AirSimVehicles,
	title        = {{AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles}},
	author       = {Shah, Shital and Dey, Debadeepta and Lovett, Chris and Kapoor, Ashish},
	year         = 2018,
	booktitle    = {Field and Service Robotics},
	publisher    = {Springer International Publishing},
	address      = {Cham},
	pages        = {621--635},
	isbn         = {978-3-319-67361-5},
	editor       = {Hutter, Marco and Siegwart, Roland},
	abstract     = {Developing and testing algorithms for autonomous vehicles in real world is an expensive and time consuming process. Also, in order to utilize recent advances in machine intelligence and deep learning we need to collect a large amount of annotated training data in a variety of conditions and environments. We present a new simulator built on Unreal Engine that offers physically and visually realistic simulations for both of these goals. Our simulator includes a physics engine that can operate at a high frequency for real-time hardware-in-the-loop (HITL) simulations with support for popular protocols (e.g. MavLink). The simulator is designed from the ground up to be extensible to accommodate new types of vehicles, hardware platforms and software protocols. In addition, the modular design enables various components to be easily usable independently in other projects. We demonstrate the simulator by first implementing a quadrotor as an autonomous vehicle and then experimentally comparing the software components with real-world flights.}
}
@inproceedings{Rong2020LGSVLDriving,
	title        = {LGSVL Simulator: A High Fidelity Simulator for Autonomous Driving},
	author       = {Rong, Guodong and Shin, Byung Hyun and Tabatabaee, Hadi and Lu, Qiang and Lemke, Steve and Možeiko, Mārtiņš and Boise, Eric and Uhm, Geehoon and Gerow, Mark and Mehta, Shalin and Agafonov, Eugene and Kim, Tae Hyung and Sterner, Eric and Ushiroda, Keunhae and Reyes, Michael and Zelenkovsky, Dmitry and Kim, Seonman},
	year         = 2020,
	booktitle    = {2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)},
	volume       = {},
	number       = {},
	pages        = {1--6},
	doi          = {10.1109/ITSC45102.2020.9294422}
}
@misc{webots,
	title        = {Webots: Open-source Mobile Robot Simulation Software},
	author       = {{Cyberbotics Ltd.}},
	howpublished = {\url{http://www.cyberbotics.com}},
	note         = {Accessed Sep. 10, 2021},
    year         = {2021},
	editor       = {Cyberbotics Ltd.}
}
@inproceedings{Dosovitskiy2017CARLA:Simulator,
	title        = {{CARLA}: {An} Open Urban Driving Simulator},
	author       = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},
	year         = 2017,
	booktitle    = {Proceedings of the 1st Annual Conference on Robot Learning},
	pages        = {1--16}
}
@article{Gusmao2020DevelopmentRaycasting,
	title        = {Development and Validation of LiDAR Sensor Simulators Based on Parallel Raycasting},
	author       = {Gusmão, Guilherme Ferreira and Barbosa, Carlos Roberto Hall and Raposo, Alberto Barbosa},
	year         = 2020,
	journal      = {Sensors},
	volume       = 20,
	number       = 24,
	doi          = {10.3390/s20247186},
	issn         = {1424-8220},
	article-number = 7186,
	abstract     = {Three-dimensional (3D) imaging technologies have been increasingly explored in academia and the industrial sector, especially the ones yielding point clouds. However, obtaining these data can still be expensive and time-consuming, reducing the efficiency of procedures dependent on large datasets, such as the generation of data for machine learning training, forest canopy calculation, and subsea survey. A trending solution is developing simulators for imaging systems, performing the virtual scanning of the digital world, and generating synthetic point clouds from the targets. This work presents a guideline for the development of modular Light Detection and Ranging (LiDAR) system simulators based on parallel raycasting algorithms, with its sensor modeled by metrological parameters and error models. A procedure for calibrating the sensor is also presented, based on comparing with the measurements made by a commercial LiDAR sensor. The sensor simulator developed as a case study resulted in a robust generation of synthetic point clouds in different scenarios, enabling the creation of datasets for use in concept tests, combining real and virtual data, among other applications.}
}
@inproceedings{Manivasagam2020LiDARsim:World,
	title        = {LiDARsim: Realistic LiDAR Simulation by Leveraging the Real World},
	author       = {Manivasagam, Sivabalan and Wang, Shenlong and Wong, Kelvin and Zeng, Wenyuan and Sazanovich, Mikita and Tan, Shuhan and Yang, Bin and Ma, Wei-Chiu and Urtasun, Raquel},
	year         = 2020,
	booktitle    = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	volume       = {},
	number       = {},
	pages        = {11164--11173},
	doi          = {10.1109/CVPR42600.2020.01118}
}
@article{Fang2018AugmentedDriving,
	title        = {Augmented LiDAR Simulator for Autonomous Driving},
	author       = {Fang, Jin and Zhou, Dingfu and Yan, Feilong and Zhao, Tongtong and Zhang, Feihu and Ma, Yu and Wang, Liang and Yang, Ruigang},
	year         = 2020,
	journal      = {IEEE Robotics and Automation Letters},
	volume       = 5,
	number       = 2,
	pages        = {1931--1938},
	doi          = {10.1109/LRA.2020.2969927}
}
}
@inproceedings{Hanke2018GenerationSystems,
	title        = {Generation and validation of virtual point cloud data for automated driving systems},
	author       = {Hanke, Timo and Schaermann, Alexander and Geiger, Matthias and Weiler, Konstantin and Hirsenkorn, Nils and Rauch, Andreas and Schneider, Stefan-Alexander and Biebl, Erwin},
	year         = 2017,
	booktitle    = {2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC)},
	volume       = {},
	number       = {},
	pages        = {1--6},
	doi          = {10.1109/ITSC.2017.8317864}
}
@article{Wang2009,
	title        = {{Segmentation of LiDAR point clouds for building extraction}},
	author       = {Wang, Jun and Shan, Jie},
	year         = 2009,
	journal      = {American Society for Photogrammetry and Remote Sensing Annual Conference 2009, ASPRS 2009},
	volume       = 2,
	pages        = {870--882},
	isbn         = 9781615673223
}
@inproceedings{Vasstein2020AutoferryShips,
	title        = {{Autoferry Gemini: A real-time simulation platform for electromagnetic radiation sensors on autonomous ships}},
	author       = {Vasstein, K. and Brekke, E. F. and Mester, R. and Eide, E.},
	year         = 2020,
	month        = 11,
	booktitle    = {IOP Conference Series: Materials Science and Engineering},
	publisher    = {IOP Publishing Ltd},
	volume       = 929,
	number       = 1,
	doi          = {10.1088/1757-899X/929/1/012032},
	issn         = {1757899X}
}
@article{Koenig2004DesignSimulator,
	title        = {{Design and use paradigms for Gazebo, an open-source multi-robot simulator}},
	author       = {Koenig, Nathan and Howard, Andrew},
	year         = 2004,
	journal      = {2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
	volume       = 3,
	pages        = {2149--2154},
	doi          = {10.1109/IROS.2004.1389727}
}
@misc{mathworksautomation,
	title        = {{MATLAB: Automated Driving Toolbox}},
	author       = {{The MathWorks Inc.}},
	howpublished = {\url{https://mathworks.com/products/automated-driving.html}},
	note         = {Accessed Sep. 10, 2021},
    year         = {2021},
	editor       = {The MathWorks Inc.}
}
@article{Muckenhuber2020AutomotiveCapabilities,
	title        = {{Automotive Lidar Modelling Approach Based on Material Properties and Lidar Capabilities}},
	author       = {Muckenhuber, Stefan and Holzer, Hannes and Bockaj, Zrinka},
	year         = 2020,
	month        = 6,
	journal      = {Sensors},
	publisher    = {MDPI AG},
	volume       = 20,
	number       = 11,
	pages        = 3309,
	doi          = {10.3390/s20113309},
	issn         = {1424-8220},
	keywords     = {Automotive, Lidar, Material reflectance, Sensor model, Virtual testing}
}
@article{Nicodemus1965DirectionalSurface,
	title        = {{Directional Reflectance and Emissivity of an Opaque Surface}},
	author       = {Nicodemus, Fred E.},
	year         = 1965,
	month        = 7,
	journal      = {Applied Optics},
	publisher    = {Optica Publishing Group},
	volume       = 4,
	number       = 7,
	pages        = {767--775},
	doi          = {10.1364/AO.4.000767},
	issn         = {2155-3165},
	keywords     = {Diffuse reflectance, Emissivity, Light wavelength, Opacity, Optical materials, Refractive index}
}
@misc{Cosys-AirSimRepository,
	title        = {Cosys-AirSim Github Repository},
	author       = {{Cosys-Lab}},
        year         = {2022},
	howpublished = {\url{https://github.com/Cosys-Lab/Cosys-AirSim}},
        note         = {Accessed Sep. 10, 2021},
}
@misc{Cosys-AirSimRepositoryBlinded,
	title        = {Open-Source Repository of Simulation Framework, Self-Reference Removed for Double-Blind Review},
	author       = {{Authors}},
        publisher    = {Self-Reference Removed for Double-Blind Review},
        year         = {20XX},
	howpublished = {\url{https://affiliation.com/simulator}},
        note         = {Accessed January. 1, 2023},
}
@article{Schouten2021SimulationSLAM,
	title        = {{Simulation of Pulse-Echo Radar for Vehicle Control and SLAM}},
	author       = {Schouten, Girmi and Jansen, Wouter and Steckel, Jan},
	year         = 2021,
	month        = 1,
	journal      = {Sensors 2021},
	publisher    = {Multidisciplinary Digital Publishing Institute},
	volume       = 21,
	number       = 2,
	pages        = 523,
	doi          = {10.3390/S21020523},
	issn         = {1424-8220},
	pmid         = 33450957,
	keywords     = {SLAM, biologically, inspired, radar, simulation, vehicle control}
}
@inproceedings{Schouten2021SimulationSLAMBlinded,
	title        = {{Pulse-Echo Simulation Publication}},
	author       = {Authors},
	year         = {20XX},
        booktitle={Self-Reference Removed for Double-Blind Review}, 
}
@misc{EpicGamesUnrealOverview,
	title        = {Unreal Engine Documentation - Rendering Overview},
	author       = {{Epic Games}},
	howpublished = {\url{https://docs.unrealengine.com/4.26/en-US/RenderingAndGraphics/Overview/}},
	note         = {Accessed Sep. 10, 2021},
    year         = {2021},
}
@inproceedings{QiuUnrealCV:Engine,
	title        = {UnrealCV: Connecting Computer Vision to Unreal Engine},
	author       = {Qiu, Weichao and Yuille, Alan},
	year         = 2016,
	booktitle    = {Computer Vision -- ECCV 2016 Workshops},
	publisher    = {Springer International Publishing},
	address      = {Cham},
	pages        = {909--916},
	isbn         = {978-3-319-49409-8},
	editor       = {Hua, Gang and J{\'e}gou, Herv{\'e}},
	abstract     = {Computer graphics can not only generate synthetic images and ground truth but it also offers the possibility of constructing virtual worlds in which: (i) an agent can perceive, navigate, and take actions guided by AI algorithms, (ii) properties of the worlds can be modified (e.g., material and reflectance), (iii) physical simulations can be performed, and (iv) algorithms can be learnt and evaluated. But creating realistic virtual worlds is not easy. The game industry, however, has spent a lot of effort creating 3D worlds, which a player can interact with. So researchers can build on these resources to create virtual worlds, provided we can access and modify the internal data structures of the games. To enable this we created an open-source plugin UnrealCV (Project website: http://unrealcv.github.io) for a popular game engine Unreal Engine 4 (UE4). We show two applications: (i) a proof of concept image dataset, and (ii) linking Caffe with the virtual world to test deep network algorithms.}
}
@article{Qiu2017UnrealCV:Vision,
	title        = {UnrealCV: Virtual Worlds for Computer Vision},
	author       = {Weichao Qiu and Fangwei Zhong and Yi Zhang and Siyuan Qiao and Zihao Xiao and Tae Soo Kim and Yizhou Wang and Alan Yuille},
	year         = 2017,
	journal      = {ACM Multimedia Open Source Software Competition},
	doi          = {10.1145/3123266.3129396},
	isbn         = 9781450349062
}
@inproceedings{lidarsim2022jansen,
  author={Jansen, Wouter and Huebel, Nico and Steckel, Jan},
  booktitle={2022 IEEE Sensors}, 
  title={Physical LiDAR Simulation in Real-Time Engine}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  doi={10.1109/SENSORS52175.2022.9967197}}
}
@inproceedings{lidarsim2022jansenBlinded,
  author={Authors},
  booktitle={Self-Reference Removed for Double-Blind Review}, 
  title={LiDAR Simulation Publication}, 
  year={20XX}
}
@article{Goodin2019PredictingADAS,
    title = {{Predicting the influence of rain on LIDAR in ADAS}},
    year = {2019},
    journal = {Electronics (Switzerland)},
    author = {Goodin, Christopher and Carruth, Daniel and Doude, Matthew and Hudson, Christopher},
    number = {1},
    month = {1},
    volume = {8},
    publisher = {MDPI AG},
    doi = {10.3390/electronics8010089},
    issn = {20799292},
    keywords = {Dynamic path-planning algorithms, Obstacle detection and classification, Perception in challenging conditions}
}
@article{Lewandowski2009Lidar-basedEvidence,
    title = {{Lidar-based estimation of small-scale rainfall: Empirical evidence}},
    year = {2009},
    journal = {Journal of Atmospheric and Oceanic Technology},
    author = {Lewandowski, Piotr A. and Eichinger, William E. and Kruger, Anton and Krajewski, Witold F.},
    number = {3},
    pages = {656--664},
    volume = {26},
    doi = {10.1175/2008JTECHA1122.1},
    issn = {07390572}
}
@article{Dannheim2014WeatherSystems,
    title = {{Weather detection in vehicles by means of camera and LIDAR systems}},
    year = {2014},
    journal = {Proceedings - 6th International Conference on Computational Intelligence, Communication Systems and Networks, CICSyN 2014},
    author = {Dannheim, Clemens and Icking, Christian and Mader, Markus and Sallis, Philip},
    month = {3},
    pages = {186--191},
    publisher = {Institute of Electrical and Electronics Engineers Inc.},
    isbn = {9781479950768},
    doi = {10.1109/CICSYN.2014.47},
    keywords = {LIDAR, collaborative driver assistant functions, remote sensing, spatial resolution, weather detection}
}

@misc{JetPropulsionLaboratoryECOSTRESS1.0,
	title        = {ECOSTRESS Spectral Library—Version 1.0},
	author       = {{JPL} and {Caltech}},
	howpublished = {\url{https://ecostress.jpl.nasa.gov/}},
	note         = {Accessed Sep. 10, 2021},
    year         = {2021},
}
@misc{OS0Lidar,
	title        = {OS0 Ultra-Wide View High-Resolution Imaging Lidar Datasheet},
	author       = {{Ouster}},
	howpublished = {\url{https://data.ouster.io/downloads/datasheets/datasheet-rev05-v2p1-os0.pdf}},
	note         = {Accessed Sep. 10, 2021},
    year         = {2021},
}
@article{ZhouOpen3D:Processing,
	title        = {{Open3D}: {A} Modern Library for {3D} Data Processing},
	author       = {Qian-Yi Zhou and Jaesik Park and Vladlen Koltun},
	year         = 2018,
	journal      = {arXiv:1801.09847}
}
@article{qi2017pointnetplusplus,
    title={PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space},
    author={Qi, Charles R and Yi, Li and Su, Hao and Guibas, Leonidas J},
    journal={arXiv preprint arXiv:1706.02413},
    year={2017}
}
@inproceedings{8579077,
  author={Li, Jiaxin and Chen, Ben M. and Lee, Gim Hee},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={SO-Net: Self-Organizing Network for Point Cloud Analysis}, 
  year={2018},
  volume={},
  number={},
  pages={9397-9406},
  doi={10.1109/CVPR.2018.00979}
  }
  @inproceedings{NEURIPS2018_f5f8590c,
 author = {Li, Yangyan and Bu, Rui and Sun, Mingchao and Wu, Wei and Di, Xinhan and Chen, Baoquan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {PointCNN: Convolution On X-Transformed Points},
 url = {https://proceedings.neurips.cc/paper/2018/file/f5f8590cd58a54e94377e6ae2eded4d9-Paper.pdf},
 volume = {31},
 year = {2018}
}
@article{Jhaldiyal2022SemanticSO,
  title={Semantic segmentation of 3D LiDAR data using deep learning: a review of projection-based methods},
  author={Alok Jhaldiyal and Navendu Chaudhary},
  journal={Applied Intelligence},
  year={2022}
}
@inproceedings{geiger2012cvpr,
  author = {A. Geiger and P. Lenz and R. Urtasun},
  title = {{Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite}},
  booktitle = {Proc.~of the IEEE Conf.~on Computer Vision and Pattern Recognition (CVPR)},
  pages = {3354--3361},
  year = {2012}
}@inproceedings{behley2019iccv,
  author = {J. Behley and M. Garbade and A. Milioto and J. Quenzel and S. Behnke and C. Stachniss and J. Gall},
  title = {{SemanticKITTI: A Dataset for Semantic Scene Understanding of LiDAR Sequences}},
  booktitle = {Proc. of the IEEE/CVF International Conf.~on Computer Vision (ICCV)},
  year = {2019}
}
@article{behley2021ijrr,
  author = {J. Behley and M. Garbade and A. Milioto and J. Quenzel and S. Behnke and J. Gall and C. Stachniss},
  title = {{Towards 3D LiDAR-based semantic scene understanding of 3D point cloud sequences: The SemanticKITTI Dataset}},
  journal = {The International Journal on Robotics Research},
  volume = {40},
  number = {8-9},
  pages = {959-967},
  year = {2021},
  doi = {10.1177/02783649211006735}
}
@inproceedings{behley2019iccv,
  author = {J. Behley and M. Garbade and A. Milioto and J. Quenzel and S. Behnke and C. Stachniss and J. Gall},
  title = {{SemanticKITTI: A Dataset for Semantic Scene Understanding of LiDAR Sequences}},
  booktitle = {Proc. of the IEEE/CVF International Conf.~on Computer Vision (ICCV)},
  year = {2019}
}