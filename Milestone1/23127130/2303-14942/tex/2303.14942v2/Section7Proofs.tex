\subsection{\texorpdfstring{$L^{q}-$}~embedding property of the interpolation space}

% Using Theorem \ref{reiteration theorem} and Lemma \ref{cong of lorentz} to Lorentz space and we have the following lemma.
Before introducing the $L^{q}$-embedding property of the interpolation space $[\mathcal{H}]^{s}$, we first prove the following lemma, which characterizes the real interpolation between two $ L^{p}$ spaces with Lorentz space $L^{p,q}(\mathcal{X}, \mu)$. We refer to Appendix A for details of \textit{real interpolation} and \textit{Lorentz spaces}.
\begin{lemma}\label{Lp interpolation}
  For $ 1 < p_{1} \neq p_{2} < \infty$, $ 1 \le q \le \infty$ and $ 0 < \theta < 1$, we have
  \begin{displaymath}
      \left( L^{p_{1}}(\mathcal{X},\mu), L^{p_{2}}(\mathcal{X},\mu) \right)_{\theta, q} = L^{p_{\theta},q}(\mathcal{X},\mu) ,\quad  \frac{1}{p_{\theta}} = \frac{1-\theta}{p_{1}} + \frac{\theta}{p_{2}},
  \end{displaymath}
  where $L^{p_{\theta},q}(\mathcal{X}, \mu)$ is the Lorentz space.
\end{lemma}
\begin{proof}
  Denote $L^{p}(\mathcal{X},\mu), L^{p,q}(\mathcal{X},\mu)$ as $L^{p}, L^{p,q}$ for brevity. Using Lemma \ref{cong of lorentz}, we know that $ L^{p_{i}} \cong L^{p_{i},p_{i}} = \left(L^{1}, L^{\infty}\right)_{\frac{1}{p_{i}^{\prime}}, p_{i}}$, where $\frac{1}{p_{i}^{\prime}} + \frac{1}{p_{i}} = 1, i=1,2.$ Since $1 < p_{i} <\infty, i=1,2$, Lemma \ref{mono of RI} implies that
  \begin{align}
      \left(L^{1}, L^{\infty}\right)_{\frac{1}{p_{1}^{\prime}}, 1} &\subset L^{p_{1}} \subset \left(L^{1}, L^{\infty}\right)_{\frac{1}{p_{1}^{\prime}}, \infty}; \notag \\
      \left(L^{1}, L^{\infty}\right)_{\frac{1}{p_{2}^{\prime}}, 1} &\subset L^{p_{2}} \subset \left(L^{1}, L^{\infty}\right)_{\frac{1}{p_{2}^{\prime}}, \infty}. \notag
  \end{align}
  Using the Reiteration theorem (Theorem \ref{reiteration theorem}), we have
  \begin{equation}\label{1.10-1}
      \left( L^{p_{1}}, L^{p_{2}} \right)_{\theta, q} = \left(L^{1}, L^{\infty}\right)_{\eta, q},
  \end{equation}
  where $ \eta = \frac{1 - \theta}{p_{1}^{\prime}} + \frac{\theta}{p_{2}^{\prime}}$. Simple calculations show that 
  \begin{align}
      1 - \eta = \frac{1 - \theta}{p_{1}} + \frac{\theta}{p_{2}} := \frac{1}{p_{\theta}}. \notag
  \end{align}
  So by the definition of Lorentz space, we have 
  \begin{displaymath}
      \left(L^{1}, L^{\infty}\right)_{\eta, q} = L^{\frac{1}{1-\eta},q} = L^{p_{\theta},q}.
  \end{displaymath}
  Together with \eqref{1.10-1}, we finish the proof.
\end{proof}


Based on Lemma \ref{Lp interpolation}, the following theorem gives the $L^{q}$-embedding property of the interpolation space of an RKHS $\mathcal{H}$, which is crucial for proving the upper bound. 
\begin{theorem}[$L^{q}$-embedding property]\label{integrability of Hs}
  Suppose that the RKHS $\mathcal{H}$ has embedding index $\alpha_{0}$, then for any $0 < s \le \alpha_{0}$, we have
  \begin{align}
      [\mathcal{H}]^{s} \hookrightarrow L^{q_{s}}(\mathcal{X}, \mu),\quad q_{s} = \frac{2 \alpha}{\alpha - s}, \quad \forall \alpha > \alpha_{0}. \notag
  \end{align}
  where $\hookrightarrow $ denotes the continuous embedding.
\end{theorem}
\begin{proof}
  % Since the embedding index is $ \alpha_{0}$, we know that $ [\mathcal{H}]^{\alpha} \hookrightarrow L^{\infty}(\mathcal{X}, \mu), \forall \alpha > \alpha_{0}$. In addition, \eqref{inter relation} shows that
  % \begin{align}
  %     [\mathcal{H}]^{s} = \big[ \left[ \mathcal{H} \right]^{\alpha}\big]^{\frac{s}{\alpha}} \cong \left(L^{2}(\mathcal{X}, \mu),\left[ \mathcal{H} \right]^{\alpha} \right)_{\frac{s}{\alpha},2}. \notag
  % \end{align}
  % So using Lemma \ref{Lp interpolation}, we have
  % \begin{align}
  %      [\mathcal{H}]^{s} \hookrightarrow \left(L^{2}(\mathcal{X}, \mu), L^{\infty}(\mathcal{X}, \mu) \right)_{\frac{s}{\alpha},2} \cong L^{p_{s},2}(\mathcal{X}, \mu), \notag
  % \end{align}
  % where $ \frac{1}{p_{s}} = \frac{1- \frac{s}{\alpha}}{2} + \frac{\frac{s}{\alpha}}{\infty} = \frac{\alpha-s}{2\alpha}$. Further, since $0<s\le \alpha_{0} < \alpha$ thus $p_{s} > 2$, using Lemma \ref{mono of RI} and Lemma \ref{cong of lorentz}, we have
  % \begin{displaymath}
  %     L^{p_{s},2}(\mathcal{X}, \mu) \hookrightarrow L^{p_{s},p_{s}}(\mathcal{X}, \mu) \cong L^{p_{s}}(\mathcal{X}, \mu).
  % \end{displaymath}
  % We finish the proof.

  Since the embedding index is $ \alpha_{0}$, we know that $ [\mathcal{H}]^{\alpha^{\prime}} \hookrightarrow L^{\infty}(\mathcal{X}, \mu), \forall \alpha^{\prime} > \alpha_{0}$. In addition, \eqref{inter relation} shows that
  \begin{align}
      [\mathcal{H}]^{s} = \big[ \left[ \mathcal{H} \right]^{\alpha^{\prime}}\big]^{\frac{s}{\alpha^{\prime}}} \cong \left(L^{2}(\mathcal{X}, \mu),\left[ \mathcal{H} \right]^{\alpha^{\prime}} \right)_{\frac{s}{\alpha^{\prime}},2}. \notag
  \end{align}
  
  So using Lemma \ref{Lp interpolation}, for any $ 0 < M < \infty$, we have
  \begin{align}
       [\mathcal{H}]^{s} \hookrightarrow \left(L^{2}(\mathcal{X}, \mu), L^{M}(\mathcal{X}, \mu) \right)_{\frac{s}{\alpha^{\prime}},2} \cong L^{q_{s}^{\prime},2}(\mathcal{X}, \mu), \notag
  \end{align}
  where $ \frac{1}{q_{s}^{\prime}} = \frac{1- \frac{s}{\alpha^{\prime}}}{2} + \frac{\frac{s}{\alpha^{\prime}}}{M} = \frac{\alpha^{\prime}-s}{2\alpha^{\prime}} + \frac{s}{\alpha^{\prime} M}$. 
  
  For any $ \alpha > \alpha_0$, we can choose the above $ \alpha^{\prime} \in \left( \alpha_0, \alpha \right)$ and $M$ large enough such that $ \frac{\alpha^{\prime}-s}{2\alpha^{\prime}} + \frac{s}{\alpha^{\prime} M} < \frac{\alpha-s}{2 \alpha} $. Letting $ q_s = \frac{2 \alpha}{\alpha - s}$, we have $ q_{s}^{\prime} > q_{s}$. Further, since $0 < s\le \alpha_{0} < \alpha$ thus $ q_{s}^{\prime} > q_{s} > 2$, using Lemma \ref{mono of RI} and Lemma \ref{cong of lorentz}, we have
  \begin{displaymath}
      L^{q_{s}^{\prime},2}(\mathcal{X}, \mu) \hookrightarrow L^{q_{s}^{\prime},q_{s}^{\prime}}(\mathcal{X}, \mu) \cong L^{q_{s}^{\prime}}(\mathcal{X}, \mu) \hookrightarrow L^{q_{s}}(\mathcal{X}, \mu).
  \end{displaymath}
  We finish the proof.

  
  
\end{proof}




\subsection{Some bounds}
Throughout the proof, we denote 
\begin{displaymath}
   T_{\nu} = T + \nu^{-1};~~ T_{X \nu} = T_{X} + \nu^{-1},
\end{displaymath}
where $\nu$ is the regularization parameter. We use $\| \cdot \|_{\mathscr{B}(B_1,B_2)}$ to denote the operator norm of a bounded linear operator from a Banach space $B_1$ to $B_2$, i.e., $ \| A \|_{\mathscr{B}(B_1,B_2)} = \sup\limits_{\|f\|_{B_1}=1} \|A f\|_{B_2} $. Without bringing ambiguity, we will briefly denote the operator norm as $\| \cdot \|$. In addition, we use $\text{tr}A$ and $\| A \|_{1}$ to denote the trace and the trace norm of an operator. We use $\| A \|_{2}$ to denote the Hilbert-Schmidt norm. In addition, we denote $ L^{2}(\mathcal{X},\mu)$ as $ L^{2}$, $ L^{\infty}(\mathcal{X},\mu)$ as $ L^{\infty}$ for brevity throughout the proof.  We use $a_n \asymp b_n$ to denote that there exist constants $c$ and $C$ such that $c a_{n} \le b_{n} \le C a_{n}, \forall n=1,2,\cdots$; use $ a_n \lesssim b_n$ to denote that there exists an constant $C$ such that $a_{n} \le C b_{n}, \forall n=1,2,\cdots$ 

In addition, denote the effective dimension as
\begin{align}
    \mathcal{N}(\nu) = \text{tr}\big(T (T + \nu^{-1})^{-1}\big) = \sum\limits_{i \in N} \frac{\lambda_{i}}{\lambda_{i} + \nu^{-1}}. \notag
\end{align}
Since the EDR of $\mathcal{H}$ is $\beta$, Lemma \ref{lemma of effect} shows that $\mathcal{N}(\nu) \asymp \nu^{\frac{1}{\beta}} $. 

Recall that we have define the sample basis function $ g_{Z}$ and the spectral algorithm $ \hat{f}_{\nu}$ in Section \ref{section spectral algorithms}. We also need the following notations:
define the expectation of $g_{Z}$ as
\begin{displaymath}
    g = \mathbb{E} g_{Z} = \int_{\mathcal{X}} k(x,\cdot) f_{\rho}^{*}(x) d\mu(x) = S_{k}^{*} f_{\rho}^* \in \mathcal{H},
\end{displaymath}
and
\begin{displaymath}
    f_{\nu} = \varphi_{\nu}(T) g = \varphi_{\nu}(T) S_{k}^{*} f_{\rho}^{*}.
\end{displaymath}

The following theorem bounds the $[\mathcal{H}]^{\gamma}$-norm of $f_\nu -  f_{\rho}^*$ when $0 \le \gamma \le s $. 
\begin{theorem}\label{theorem of approximation error}
   Suppose that Assumption \ref{ass source condition} holds for $ 0 < s \le 2 \tau$. Then for any $\nu >0$ and $0 \le \gamma \le s $, we have 
   \begin{equation}\label{prop appr 1}
       \left\|f_\nu-f_{\rho}^*\right\|_{[\mathcal{H}]^{\gamma}} \le F_{\tau} R \nu^{-\frac{s-\gamma}{2}}.
   \end{equation}
\end{theorem}
\begin{proof}
  Suppose that $f_{\rho}^{*} = L_{k}^{\frac{s}{2}} g_{0}$ for some $g_{0} \in L^{2}$. Note that 
\begin{align}
    \left\| f_\nu-f_{\rho}^* \right\|_{[\mathcal{H}]^{\gamma}} &= \left\|L_{k}^{-\frac{\gamma}{2}} \left( S_{k} \varphi_{\nu}(T) S_{k}^{*} f_{\rho}^{*} - f_{\rho}^* \right) \right\|_{L^{2}} \notag \\
    &= \left\|L_{k}^{-\frac{\gamma}{2}} \left( \varphi_{\nu}(L_{k}) L_{k} - I \right) L_{k}^{\frac{s}{2}} g_{0} \right\|_{L^{2}} \notag \\
    &\le \left\|L_{k}^{\frac{s - \gamma}{2}} \psi_{\nu}(L_{k})\right\| R \notag \\
    &\le F_{\tau} R \nu^{-\frac{s-\gamma}{2}}, \notag
\end{align}
where we use the property of the filter function (\ref{prop2}) and $\left\| g_{0} \right\|_{L^{2}} = \| f_{\rho}^{*} \|_{[\mathcal{H}]^{s}} \le R$ for the last inequality.
\end{proof}

The following lemma bounds the $L^{\infty}$-norm of $f_{\nu} $ when $s \le \alpha_{0}$.
\begin{lemma}\label{prop infty norm}
   Suppose that Assumption \ref{ass EDR}, \ref{assumption embedding} and \ref{ass source condition} hold for $ 0 < s \le \alpha_{0}$ and $\frac{1}{\beta} \le \alpha_{0} < 1$. Then for any $\nu >0$ and any $\alpha_{0} < \alpha \le 1$, we have 
   \begin{equation}\label{prop appr 2}
       \| f_{\nu} \|_{L^{\infty}} \le M_{\alpha} E R \nu^{\frac{\alpha - s}{2}}.
   \end{equation}
\end{lemma}
\begin{proof}
    Since $s \le \alpha_{0}$ and $\alpha > \alpha_{0} $, we have 
    \begin{align}
      \left\| f_{\nu} \right\|_{[\mathcal{H}]^\alpha} &= \left\| L_{k}^{-\frac{\alpha}{2}} S_{k} \varphi_{\nu}(T) S_{k}^{*} f_{\rho}^{*}  \right\|_{[\mathcal{H}]^\alpha} \notag \\
      &= \left\| L_{k}^{-\frac{\alpha}{2}}  \varphi_{\nu}(L_{k}) L_{k} L_{k}^{\frac{s}{2}} g_{0}  \right\|_{L^{2}} \notag \\
      &= \left\| L_{k}^{1-\frac{\alpha -s}{2}}  \varphi_{\nu}(L_{k})  g_{0}  \right\|_{L^{2}} \notag \\
      &= \left\| L_{k}^{1-\frac{\alpha -s}{2}}  \varphi_{\nu}(L_{k}) \right\| \left\| g_{0}  \right\|_{L^{2}} \notag \\
      &\le E R  \nu^{\frac{\alpha - s}{2}}, \notag
\end{align}
where we use the property of the filter function (\ref{prop1}) for the last inequality. Further, using $\| [\mathcal{H}]^{\alpha} \hookrightarrow L^{\infty}(\mathcal{X}, \mu) \| = M_{\alpha} $ by Assumption \ref{assumption embedding}, we have $ \| f_{\nu} \|_{L^{\infty}} \le M_{\alpha} \| f_{\nu} \|_{[\mathcal{H}]^\alpha} \le M_{\alpha} E R  \nu^{\frac{\alpha - s}{2}}$.
\end{proof}

The following lemma will be frequently used in our proof.
\begin{lemma}\label{due embedding bound}
  Suppose that the RKHS $\mathcal{H}$ has embedding index $\alpha_{0}$. For any $\alpha_{0} < \alpha \le 1$, we have 
   \begin{align}\label{bound of Tk}
      \|T_{\nu}^{-\frac{1}{2}} k(x,\cdot) \|_{\mathcal{H}}^{2} \le M_{\alpha}^{2} \nu^{\alpha}, \quad \mu \text {-a.e. } x \in \mathcal{X}.
  \end{align}
\end{lemma}
\begin{proof}
   Recalling the definition of the embedding index, for any $\alpha_{0} < \alpha \le 1$, 
   \begin{displaymath}
    \sum_{i \in N} \lambda_i^\alpha e_i^2(x) \leq M_{\alpha}, \quad \mu \text {-a.e. } x \in \mathcal{X}.
   \end{displaymath}
   So, we have
   \begin{align}
      \|T_{\nu}^{-\frac{1}{2}} k(x,\cdot) \|_{\mathcal{H}}^{2} &= \Big\| \sum\limits_{i \in N} ( \frac{1}{\lambda_{i} + \nu^{-1}})^{\frac{1}{2}} \lambda_{i} e_{i}(x) e_{i}(\cdot)  \Big\|_{\mathcal{H}}^{2} \notag \\
      &=  \sum\limits_{i \in N}  \frac{\lambda_{i}}{\lambda_{i} + \nu^{-1}} e_{i}^{2}(x) \notag \\
      &= \big[ \sum\limits_{i \in N}  \lambda_{i}^{\alpha} e_{i}^{2}(x) \big] \sup\limits_{i \in N} \frac{\lambda_{i}^{1-\alpha}}{\lambda_{i} + \nu^{-1}} \notag \\
      & \le M_{\alpha}^{2} \nu^{\alpha}, \quad \mu \text {-a.e. } x \in \mathcal{X}. \notag
  \end{align}
  where we use Lemma \ref{basic ineq} for the last inequality and we finish the proof.
\end{proof}

Lemma \ref{due embedding bound} has a direct corollary.
\begin{lemma}\label{emb norm}
   Suppose that the RKHS $\mathcal{H}$ has embedding index $\alpha_{0}$. For any $\alpha_{0} < \alpha \le 1$, we have
\begin{displaymath}
    \| T_{\nu}^{-\frac{1}{2}} T_{x} T_{\nu}^{-\frac{1}{2}}\| \le M_{\alpha}^{2} \nu^{\alpha}, \quad \mu \text {-a.e. } x \in \mathcal{X}.
\end{displaymath}
\end{lemma}
\begin{proof}
  Note that for any $f \in \mathcal{H}$,
  \begin{align}
      T_{\nu}^{-\frac{1}{2}} T_{x} T_{\nu}^{-\frac{1}{2}} f &= T_{\nu}^{-\frac{1}{2}} K_{x} K_{x}^{*}  T_{\nu}^{-\frac{1}{2}} f \notag \\
      &= T_{\nu}^{-\frac{1}{2}} K_{x} \langle k(x,\cdot), T_{\nu}^{-\frac{1}{2}} f \rangle_{\mathcal{H}} \notag \\
      &= T_{\nu}^{-\frac{1}{2}} K_{x} \langle T_{\nu}^{-\frac{1}{2}} k(x,\cdot),  f \rangle_{\mathcal{H}} \notag \\
      &=  \langle T_{\nu}^{-\frac{1}{2}} k(x,\cdot),  f \rangle_{\mathcal{H}} \cdot T_{\nu}^{-\frac{1}{2}} k(x,\cdot). \notag
  \end{align}
  So $\| T_{\nu}^{-\frac{1}{2}} T_{x} T_{\nu}^{-\frac{1}{2}} \| = \sup\limits_{\| f\|_{\mathcal{H}}=1} \| T_{\nu}^{-\frac{1}{2}} T_{x} T_{\nu}^{-\frac{1}{2}} f\|_{\mathcal{H}} = \sup\limits_{\| f\|_{\mathcal{H}}=1} \langle T_{\nu}^{-\frac{1}{2}} k(x,\cdot),  f \rangle_{\mathcal{H}} \cdot \|T_{\nu}^{-\frac{1}{2}} k(x,\cdot) \|_{\mathcal{H}} = \|T_{\nu}^{-\frac{1}{2}} k(x,\cdot) \|_{\mathcal{H}}^{2}$. 
  Using Lemma \ref{due embedding bound}, we finish the proof.
\end{proof}

The following lemma is a corollary of Lemma \ref{bernstein}, which is also used in \citet[Lemma 5.5]{lin2018_OptimalRates} and \citet{Smale2007LearningTE}. 
\begin{lemma}\label{concentra of operator}
  Let $ 0 <\delta < \frac{1}{2}$, it holds with probability at least $1-\delta$
  \begin{displaymath}
    \left\|T_X-T\right\| \le \left\|T_X-T\right\|_2 \le \frac{8 \sqrt{2} \kappa^2}{\sqrt{n}} \ln \frac{2}{\delta},
  \end{displaymath}
  where $ \| \cdot \|$ denotes the operator norm and $ \| \cdot \|_{2}$ denotes the Hilbert-Schmidt norm.
\end{lemma}
\begin{proof}
  Define $\xi(x) = T_{x}$, then we have 
  \begin{displaymath}
     T_{X} - T  = \frac{1}{n} \sum\limits_{i=1}^{n} \xi(x_{i}) - \mathbb{E}\xi(x).
  \end{displaymath}
  Since $\sup\limits_{x \in \mathcal{X}} k(x,x) \le \kappa^{2}$, the Hilbert-Schmidt norm of $ \xi(x)$ satisfies that 
  \begin{displaymath}
      \left\| \xi(x) \right\|_{2} \le \kappa^{2}, \quad \forall x \in \mathcal{X}. 
  \end{displaymath}
  Applying Lemma \ref{bernstein} with $ L = \sigma = \kappa^{2}$, with probability at least $1-\delta$, we have
  \begin{displaymath}
      \left\| T_{X} - T \right\|_{2} \le 4 \sqrt{2} \ln{\frac{2}{\delta}} \left( \frac{\kappa^{2}}{n} + \frac{\kappa^{2}}{\sqrt{n}} \right) \le \frac{8 \sqrt{2} \kappa^2}{\sqrt{n}} \ln \frac{2}{\delta}.
  \end{displaymath}
  The first inequality follows from the fact that $ \left\|T_X-T\right\| \le \left\|T_X-T\right\|_2 $.
\end{proof}


\subsection{Upper bound}
\begin{lemma}\label{lemma4.6}
   Suppose that the RKHS $\mathcal{H}$ has embedding index $\alpha_{0}$. Then for any $\alpha_{0} < \alpha \le 1$ and all $\delta \in (0,1)$, with probability at least $1 - \delta$, we have
   \begin{displaymath}
        \Vert T_\nu^{-\frac{1}{2}} (T - T_X) T_\nu^{-\frac{1}{2}} \Vert
        \le \frac{4 M_{\alpha}^{2} \nu^{\alpha}}{3n} B + \sqrt {\frac{2 M_{\alpha}^{2} \nu^{\alpha}}{n} B},
   \end{displaymath}
   where 
   \begin{displaymath}
       B = \ln{\frac{4 \mathcal{N}(\nu) (\|T\| + \nu^{-1}) }{\delta \|T\|}}.
   \end{displaymath}
\end{lemma}
\begin{proof}
  Denote $A_{i} = T_\nu^{-\frac{1}{2}} (T - T_{x_{i}}) T_\nu^{-\frac{1}{2}} $, using Lemma \ref{emb norm}, we have 
  \begin{displaymath}
      \| A_{i} \| = \| T_\nu^{-\frac{1}{2}} T T_\nu^{-\frac{1}{2}} \| + \| T_\nu^{-\frac{1}{2}} T_{x_{i}} T_\nu^{-\frac{1}{2}} \| \le 2 M_{\alpha}^{2} \nu^{\alpha}, \quad \mu \text {-a.e. } x \in \mathcal{X}.
  \end{displaymath}
  We use $ A \preceq B$ to denote that $ A-B$ is a positive semi-definite operator. Using the fact that $\mathbb{E}(B-\mathbb{E} B)^2 \preceq \mathbb{E} B^2$ for a self-adjoint operator $B$, we have
  \begin{displaymath}
    \mathbb{E} A_{i}^{2} \preceq \mathbb{E}\left[T_\nu^{-\frac{1}{2}} T_{x_{i}} T_\nu^{-\frac{1}{2}}\right]^2.
    \end{displaymath}
  In addition, Lemma \ref{emb norm} shows that $0 \preceq T_\nu^{-\frac{1}{2}} T_{x_{i}} T_\nu^{-\frac{1}{2}} \preceq M_{\alpha}^{2}\nu^{\alpha}, \mu \text {-a.e. } x \in \mathcal{X}$. So we have
  \begin{displaymath}
     \mathbb{E} A_{i}^{2}  \preceq \mathbb{E} \left[T_\nu^{-\frac{1}{2}} T_{x_{i}} T_\nu^{-\frac{1}{2}}\right]^{2} \preceq \mathbb{E}\left[ M_{\alpha}^{2} \nu^{\alpha} \cdot T_\nu^{-\frac{1}{2}} T_{x_{i}} T_\nu^{-\frac{1}{2}}\right] = M_{\alpha}^{2}\nu^{\alpha} T_{\nu}^{-1} T,
  \end{displaymath}
  Define an operator $V := M_{\alpha}^{2} \nu^{\alpha} T_{\nu}^{-1} T$, we have  
  \begin{align}
      \| V \| &= M_{\alpha}^{2} \nu^{\alpha} \frac{\lambda_{1}}{\lambda_{1} + \nu^{-1}} = M_{\alpha}^{2} \nu^{\alpha} \frac{\|T\|}{\|T\| + \nu^{-1}} \le M_{\alpha}^{2} \nu^{\alpha}; \notag \\
      \text{tr}V &= M_{\alpha}^{2} \nu^{\alpha} \mathcal{N}(\nu); \notag \\
      \frac{\text{tr}V}{ \| V \|} &= \frac{\mathcal{N}(\nu) (\|T\| + \nu^{-1})}{\|T\|}. \notag
  \end{align}
  Use Lemma \ref{lemma concentration of operator} to $A_{i}$, $V$ and we finish the proof.
\end{proof}

\begin{lemma}\label{lemma 4.7}
   Suppose that the RKHS $\mathcal{H}$ has embedding index $\alpha_{0}$. For any $\alpha_{0} < \alpha \le 1$, if $\nu $ and $n$ satisfy that
   \begin{equation}\label{require 3.10}
    \frac{M_{\alpha}^{2} \nu^{\alpha}}{n} \ln \frac{4 \kappa^2 \mathcal{N}(\nu)\left(\|T\|+\nu^{-1}\right)}{\delta\|T\|} \leq \frac{1}{8},
    \end{equation}
   then for all $\delta \in (0,1)$, with probability at least $1 - \delta$, we have
   \begin{displaymath}
   \left\|T_\nu^{-\frac{1}{2}} T_{X \nu}^{\frac{1}{2}}\right\|^2 \leq 2, \quad\left\|T_\nu^{\frac{1}{2}} T_{X \nu}^{-\frac{1}{2}}\right\|^2 \leq 3.
   \end{displaymath}
\end{lemma}
\begin{proof}
   Define 
   \begin{displaymath}
      u = \frac{M_{\alpha}^{2} \nu^{\alpha}}{n} \ln \frac{4 \kappa^2 \mathcal{N}(\nu)\left(\|T\|+\nu^{-1}\right)}{\delta\|T\|} \le \frac{1}{8}.
   \end{displaymath}
   Using Lemma \ref{lemma4.6}, with probability at least $1 - \delta$, we have
   \begin{displaymath}
       a := \Vert T_\nu^{-\frac{1}{2}} (T - T_X) T_\nu^{-\frac{1}{2}} \Vert \le \frac{4}{3} u + \sqrt{2 u} \le \frac{2}{3}.
   \end{displaymath}
   So we have
   \begin{align}
   \left\|T_\nu^{-\frac{1}{2}} T_{X \nu}^{\frac{1}{2}}\right\|^2 & =\left\|T_\nu^{-\frac{1}{2}} T_{X \nu} T_\nu^{-\frac{1}{2}}\right\|=\left\|T_\nu^{-\frac{1}{2}}\left(T_X+\nu^{-1}\right) T_\nu^{-\frac{1}{2}}\right\| \notag \\ & =\left\|T_\nu^{-\frac{1}{2}}\left(T_X-T+T+\nu^{-1}\right) T_\nu^{-\frac{1}{2}}\right\| \notag \\ 
   & =\left\|T_\nu^{-\frac{1}{2}}\left(T_X-T\right) T_\nu^{-\frac{1}{2}}+I\right\| \notag\\ 
   & \leq a+1 \leq 2; \notag
   \end{align}
   and
   \begin{align}
    \left\|T_\nu^{\frac{1}{2}} T_{X \nu}^{-\frac{1}{2}}\right\|^2 & =\left\|T_\nu^{\frac{1}{2}} T_{X \nu}^{-1} T_\nu^{\frac{1}{2}}\right\|=\left\|\left(T_\nu^{-\frac{1}{2}} T_{X \nu} T_\nu^{-\frac{1}{2}}\right)^{-1}\right\| \notag \\
    &= \left\|\left(I - T_{\nu}^{-\frac{1}{2}} (T_{X}-T) T_{\nu}^{-\frac{1}{2}} \right)^{-1}\right\| \notag \\
    &\le \sum\limits_{k=0}^{\infty} \left\| T_{\nu}^{-\frac{1}{2}} (T_{X}-T) T_{\nu}^{-\frac{1}{2}} \right\|^{k}  \notag \\
    &\le \sum\limits_{k=0}^{\infty} \left(\frac{2}{3}\right)^{k} \le 3. \notag
    \end{align}
\end{proof}

The following theorem is an application of the classical Bernstein inequality but considering a truncation version of $f_{\rho}^{*}$, which will bring refined analysis when handling those $f_{\rho}^{*} \notin L^{\infty} $.
\begin{theorem}\label{theorem 4.9 boundness}
  Suppose that Assumption \ref{ass EDR}, \ref{assumption embedding}, \ref{ass source condition} and \ref{ass mom of error} hold for $ 0 < s \le 2 \tau$ and $\frac{1}{\beta} \le \alpha_{0} < 1$. Denote $\xi_{i} = \xi(x_{i},y_{i}) =  T_{\nu}^{-\frac{1}{2}}(K_{x_{i}} y_{i} - T_{x_{i}} f_{\nu}) $ and $ \Omega_{0} = \{x \in \mathcal{X}: |f_{\rho}^{*}(x)| \le t \}$. Then for any $\alpha_{0} < \alpha \le 1$ and all $\delta \in (0,1)$, with probability at least $1 - \delta$, we have
  \begin{displaymath}
    \left\| \frac{1}{n} \sum\limits_{i=1}^{n} \xi_{i}I_{x_{i} \in \Omega_{0}} - \mathbb{E}\xi_{x}I_{x \in \Omega_{0}} \right\|_{\mathcal{H}} \leq \ln \frac{2}{\delta}\left(\frac{C_1 \nu^{\frac{\alpha}{2}}}{n} \cdot \tilde{M} + \frac{C_2 \mathcal{N}^{\frac{1}{2}}(\nu)}{\sqrt{n}}+\frac{C_3 \nu^{\frac{\alpha-s}{2}}}{\sqrt{n}}\right),
    \end{displaymath}
    where $\tilde{M} = M_{\alpha} (E + F_{\tau}) R \nu^{\frac{\alpha - s}{2}} + t + L$ and $L$ is the constant in (\ref{ass mom of error}). $C_{1} = 8\sqrt{2} M_{\alpha}, C_{2} = 8\sigma, C_{3} = 8\sqrt{2} M_{\alpha} F_{\tau} R$.
\end{theorem}
\begin{proof}
   Note that $f_{\rho}^{*}$ can represent a $\mu$-equivalence class in $L^{2}(\mathcal{X},\mu)$. When defining the set $ \Omega_{0}$, we actually denote $f_{\rho}^{*}$ as the representative $f_{\rho}^{*}(x) = \int_{\mathcal{Y}} y \mathrm{d} \rho(y|x).$ 
   
   To use Lemma \ref{bernstein}, we need to bound the m-th moment of $ \xi(x,y) I_{x \in \Omega_{0}} $.
   \begin{align}\label{proof of 4.9-1}
       \mathbb{E} \left\| \xi(x,y) I_{x \in \Omega_{0}} \right\|_{\mathcal{H}}^{m} &= \mathbb{E} \left\| T_{\nu}^{-\frac{1}{2}} K_{x}(y - f_{\nu}(x))I_{x \in \Omega_{0}} \right\|_{\mathcal{H}}^{m} \notag \\
       &\le \mathbb{E} \Big( \left\| T_{\nu}^{-\frac{1}{2}} k(x,\cdot)\right\|_{\mathcal{H}}^{m}  \mathbb{E} \big( \left|(y - f_{\nu}(x)) I_{x \in \Omega_{0}} \right|^{m} ~\big|~ x\big) \Big). 
   \end{align}
Using the inequality $(a+b)^m \leq 2^{m-1}\left(a^m+b^m\right)$, we have 
\begin{align}\label{proof-plug}
    \left|y - f_\nu(x)\right|^m & \leq 2^{m-1}\left(\left|f_\nu(x)-f_{\rho}^{*}(x)\right|^m+\left|f_{\rho}^{*}(x)-y\right|^m\right) \notag \\
    & =2^{m-1}\left(\left|f_\nu(x)-f_{\rho}^{*}(x)\right|^m+|\epsilon|^m\right).
\end{align}
Plugging \eqref{proof-plug} into \eqref{proof of 4.9-1}, we have
\begin{align}
  \mathbb{E} \left\| \xi(x,y)I_{x \in \Omega_{0}} \right\|_{\mathcal{H}}^{m} ~\le~ &2^{m-1} \mathbb{E} \Big( \left\| T_{\nu}^{-\frac{1}{2}} k(x,\cdot)\right\|_{\mathcal{H}}^{m} \left|(f_{\nu}(x) - f_{\rho}^{*}(x)) I_{x \in \Omega_{0}} \right|^{m}\Big) \label{proof of 4.9-2} \\
  &+ 2^{m-1} \mathbb{E} \Big( \left\| T_{\nu}^{-\frac{1}{2}} k(x,\cdot)\right\|_{\mathcal{H}}^{m}  \mathbb{E} \big( \left| \epsilon~ I_{x \in \Omega_{0}} \right|^{m} ~\big|~ x \big) \Big) \label{proof of 4.9-3}
\end{align}

Now we begin to bound (\ref{proof of 4.9-3}). Note that we have proved in Lemma \ref{due embedding bound} that for $\mu$-almost $x \in \mathcal{X}$,
\begin{displaymath}
  \left\| T_{\nu}^{-\frac{1}{2}} k(x,\cdot)\right\|_{\mathcal{H}} \le M_{\alpha} \nu^{\frac{\alpha}{2}};  
\end{displaymath}
In addition, we also have
\begin{align}
    \mathbb{E} \left\|T_\nu^{-\frac{1}{2}} k(x,\cdot)\right\|_\mathcal{H}^{2} &= \mathbb{E}
    \Big\| \sum\limits_{i \in N} ( \frac{1}{\lambda_{i} + \nu^{-1}})^{\frac{1}{2}} \lambda_{i} e_{i}(x) e_{i}(\cdot)  \Big\|_{\mathcal{H}}^{2} \notag \\
    &= \mathbb{E} \Big( \sum\limits_{i \in N}  \frac{\lambda_{i}}{\lambda_{i} + \nu^{-1}} e_{i}^{2}(x) \Big) \notag \\
    &= \sum\limits_{i \in N}  \frac{\lambda_{i}}{\lambda_{i} + \nu^{-1}} \notag \\
    &=\mathcal{N}(\nu). \notag
\end{align}
So we have 
% \sup_{x \in \mathcal{X}} \left\|T_\nu^{-\frac{1}{2}} k(x,\cdot)\right\|_{\mathcal{H}}
\begin{displaymath}
    \mathbb{E}\left\|T_\nu^{-\frac{1}{2}} k(x,\cdot) \right\|_{\mathcal{H}}^m \leq \left(M_{\alpha} \nu^{\frac{\alpha}{2}}\right)^{m-2} \cdot \mathbb{E}\left\|T_\nu^{-\frac{1}{2}} k(x,\cdot)\right\|_{\mathcal{H}}^2 = \big( M_{\alpha} \nu^{\frac{\alpha}{2}} \big)^{m-2} \mathcal{N}(\nu).
\end{displaymath}
Using Assumption \ref{ass mom of error}, we have
\begin{displaymath}
    \mathbb{E}\left(|\epsilon I_{x \in \Omega_{0}}|^m  \mid x\right) \le \mathbb{E}\left(|\epsilon|^m \mid x\right) \leq \frac{1}{2} m ! \sigma^2 L^{m-2}, \quad \mu \text {-a.e. } x \in \mathcal{X},
\end{displaymath}
so we get the upper bound of (\ref{proof of 4.9-3}), i.e., 
\begin{displaymath}
     (\ref{proof of 4.9-3}) \le \frac{1}{2} m !\left(\sqrt{2} \sigma \mathcal{N}^{\frac{1}{2}}(\nu)\right)^2(2 M_{\alpha} \nu^{\frac{\alpha}{2}} L)^{m-2}.
\end{displaymath}

Now we begin to bound (\ref{proof of 4.9-2}).
\begin{itemize}
    \item[(1)] When $s \le \alpha_{0}$, using the definition of $\Omega_{0}$ and Lemma \ref{prop infty norm}, we have 
    \begin{equation}\label{M-1}
    \| (f_{\nu} - f_{\rho}^{*}) I_{x \in \Omega_{0}} \|_{L^{\infty}} \le \| f_{\nu}  \|_{L^{\infty}} + \| f_{\rho}^{*} I_{x \in \Omega_{0}} \|_{L^{\infty}} \le M_{\alpha} E R \nu^{\frac{\alpha - s}{2}} + t.
    \end{equation}
    \item[(2)] When $ s > \alpha_{0} $, without loss of generality, we assume $\alpha_{0} < \alpha \le s$. using Theorem \ref{theorem of approximation error} for $\gamma = \alpha$, we have 
    \begin{equation}\label{M-2}
    \| (f_{\nu} - f_{\rho}^{*}) I_{x \in \Omega_{0}} \|_{L^{\infty}} \le M_{\alpha} \| f_{\nu}  - f_{\rho}^{*} \|_{[\mathcal{H}]^{\alpha}} \le M_{\alpha} F_{\tau} R \nu^{\frac{\alpha - s}{2}}.
    \end{equation}
\end{itemize}
Therefore, \eqref{M-1} and \eqref{M-2} imply that for all $0 < s \le 2$ we have 
\begin{align}\label{def of M}
    \| (f_{\nu} - f_{\rho}^{*}) I_{x \in \Omega_{0}} \|_{L^{\infty}} \le M_{\alpha} (E + F_{\tau}) R \nu^{\frac{\alpha - s}{2}} + t := M.
\end{align}
In addition, using Theorem \ref{theorem of approximation error} for $\gamma=0$, we also have 
\begin{displaymath}
    \mathbb{E} | (f_{\nu}(x) - f_{\rho}^{*}(x)) I_{x\in \Omega_{0}} |^{2} \le \mathbb{E} | f_{\nu}(x) - f_{\rho}^{*}(x)|^{2} \le (F_{\tau} R \nu^{-\frac{s}{2}})^{2}.
\end{displaymath}
So we get the upper bound of (\ref{proof of 4.9-2}), i.e.,
\begin{align}
    (\ref{proof of 4.9-2}) &\le 2^{m-1} (M_{\alpha} \nu^{\frac{\alpha}{2}})^{m} \cdot  \| (f_{\nu} - f_{\rho}^{*}) I_{x \in \Omega_{0}} \|_{L^{\infty}}^{m-2} \cdot \mathbb{E} | (f_{\nu}(x) - f_{\rho}^{*}(x)) I_{x\in \Omega_{0}} |^{2} \notag \\
    &\le 2^{m-1} (M_{\alpha} \nu^{\frac{\alpha}{2}})^{m} \cdot M^{m-2} \cdot (F_{\tau} R \nu^{-\frac{s}{2}})^{2} \notag \\
    &\le \frac{1}{2} m! \big( 2 M_{\alpha} \nu^{\frac{\alpha}{2}} M \big)^{m-2} \big( 2 M_{\alpha} F_{\tau} R \nu^{\frac{\alpha - s}{2}}\big)^{2}. \notag
\end{align}
Denote 
\begin{align}
    \tilde{L} &= 2 M_{\alpha} (M + L) \nu^{\frac{\alpha}{2}} \notag \\
    \tilde{\sigma} &= 2 M_{\alpha} F_{\tau} R \nu^{\frac{\alpha-s}{2}} + \sqrt{2} \sigma \mathcal{N}^{\frac{1}{2}}(\nu), \notag 
\end{align}
then the bounds of \eqref{proof of 4.9-2} and \eqref{proof of 4.9-3} show that $\mathbb{E} \left\| \xi(x,y) I_{x\in \Omega_{0}} \right\|_{\mathcal{H}}^{m} \le \frac{1}{2} m! \tilde{\sigma}^{2} \tilde{L}^{m-2} $. Using Lemma \ref{bernstein}, we finish the proof.
\end{proof}
\begin{remark}
  In fact, when we later applying Theorem \ref{theorem 4.9 boundness} in the proof of Theorem \ref{theorem 4.9}, the truncation in this theorem is necessary only in the $ s \le \alpha_{0}$ case. But for the completeness and consistency of our proof, we also include $s > \alpha_{0}$ in this theorem.
\end{remark}


Based on Theorem \ref{theorem 4.9 boundness}, the following theorem will give an upper bound of
\begin{displaymath}
    \left\|T_\nu^{-\frac{1}{2}}\left[\left(g_Z-T_X f_\nu\right)-\left(g-T f_\nu\right)\right]\right\|_{\mathcal{H}}.
\end{displaymath}

\begin{theorem}\label{theorem 4.9}
  Suppose that Assumption \ref{ass EDR}, \ref{assumption embedding}, \ref{ass source condition} and \ref{ass mom of error} hold for $ 0 < s \le 2 \tau$ and $\frac{1}{\beta} \le \alpha_{0} < 1$.
  \begin{itemize}
      \item In the case of $s + \frac{1}{\beta} > \alpha_{0}$, by choosing $ \nu \asymp n^{\frac{ \beta}{s \beta + 1}}$, for any fixed $\delta \in (0,1)$, when $n$ is sufficiently large, with probability at least $ 1- \delta$ , we have    
      \begin{equation}\label{goal of theorem 4.9}
          \left\|T_\nu^{-\frac{1}{2}}\left[\left(g_Z-T_X f_\nu\right)-\left(g-T f_\nu\right)\right]\right\|_{\mathcal{H}} \le \ln{\frac{2}{\delta}} C \frac{\nu^{\frac{1}{2 \beta}}}{\sqrt{n}} = \ln{\frac{2}{\delta}} C n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}},
      \end{equation}
      where $C$ is a constant independent of $n$ and $\delta$.
      \item In the case of $s + \frac{1}{\beta} \le \alpha_{0} $, for any $ \alpha_{0} < \alpha \le 1$, by choosing $\nu \asymp (\frac{n}{\ln^{r}(n)})^{\frac{1}{\alpha}}$, for some $r > 1$, for any fixed $\delta \in (0,1)$, when $n$ is sufficiently large, with probability at least $1 - \delta$, we have
      \begin{equation}\label{goal of theorem 4.9-2}
          \left\|T_\nu^{-\frac{1}{2}}\left[\left(g_Z-T_X f_\nu\right)-\left(g-T f_\nu\right)\right]\right\|_{\mathcal{H}} \le \ln{\frac{2}{\delta}} C \frac{\nu^{\frac{\alpha-s}{2}}}{\sqrt{n}} \le \ln{\frac{2}{\delta}} C \left(\frac{n}{\ln^{r}(n)}\right)^{-\frac{1}{2} \frac{s}{\alpha}},
      \end{equation}
      where $C$ is a constant independent of $n$ and $\delta$.
  \end{itemize}
\end{theorem}
\begin{proof}
\paragraph{The $ \bm{s + \frac{1}{\beta} > \alpha_{0}} $ case:}

Denote $ \xi_{i} = \xi(x_{i},y_{i}) = T_{\nu}^{- \frac{1}{2}} (K_{x_{i}} y_{i} - T_{x_i}f_{\nu} )$, (\ref{goal of theorem 4.9}) is equivalent to
   \begin{equation}\label{equivalent goal}
       \left\| \frac{1}{n} \sum\limits_{i=1}^{n} \xi_{i} - \mathbb{E}\xi_{x} \right\|_{\mathcal{H}} \le \ln{\frac{2}{\delta}} C \frac{\nu^{\frac{1}{2 \beta}}}{\sqrt{n}} = \ln{\frac{2}{\delta}} C n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}}.
   \end{equation}
Consider the subset $\Omega_{1} = \{x \in \mathcal{X}: |f_{\rho}^{*}(x)| \le t \}$ and $\Omega_{2} = \mathcal{X} \backslash \Omega_{1}$, where $t$ will be chosen appropriately later. Assume that for some $ q \ge 2$, 
\begin{displaymath}
    [\mathcal{H}]^{s} \hookrightarrow L^{q}(\mathcal{X},\mu).
\end{displaymath}
Then Assumption \ref{ass source condition} shows that there exists $0 < C_{q} < \infty$ such that $\| f_{\rho}^{*} \|_{L^{q}(\mathcal{X},\mu)} \le C_{q}$. Using the Markov inequality, we have
\begin{displaymath}
       P(x \in \Omega_{2}) = P\Big(|f_{\rho}^{*}(x)| > t \Big) \le \frac{\mathbb{E} |f_{\rho}^{*}(x)|^{q}}{t^{q}} \le \frac{(C_{q})^{q}}{t^{q}}.
\end{displaymath}
Decompose $\xi_{i}$ as $\xi_{i} I_{x_{i} \in \Omega_{1} } +  \xi_{i} I_{x_{i} \in \Omega_{2} }$ and we have
\begin{align}\label{decomposition}
    \left\|\frac{1}{n} \sum_{i=1}^n \xi_i-\mathbb{E} \xi_x\right\|_\mathcal{H} \le \left\|\frac{1}{n} \sum_{i=1}^n \xi_i I_{x_{i} \in \Omega_{1}}-\mathbb{E} \xi_x I_{x \in \Omega_{1}} \right\|_\mathcal{H} + \| \frac{1}{n} \sum_{i=1}^n \xi_i I_{x_{i} \in \Omega_{2}} \|_{_\mathcal{H}} + \| \mathbb{E} \xi_x I_{x \in \Omega_{2}} \|_{_\mathcal{H}}.
\end{align}
 For the first term in (\ref{decomposition}), denoted as \text{\uppercase\expandafter{\romannumeral1}}, Theorem \ref{theorem 4.9 boundness} shows that there exists $ \alpha_{0} < \alpha^{\prime} < s + \frac{1}{\beta}$ such that with probability at least $1-\delta$, we have
\begin{equation}\label{lead terms 2}
  \text{\uppercase\expandafter{\romannumeral1}} \leq \ln \frac{2}{\delta}\left(\frac{C_1 \nu^{\frac{\alpha^{\prime}}{2}}}{n} \cdot \tilde{M} +\frac{C_2 \nu^{\frac{1}{2 \beta}}}{\sqrt{n}}+\frac{C_3 \nu^{\frac{\alpha^{\prime} - s}{2}}}{\sqrt{n}}\right),
\end{equation}
where $\tilde{M} = M_{\alpha^{\prime}} (E + F_{\tau}) R \nu^{\frac{ \alpha^{\prime} - s}{2}} + t + L$. Recalling that $ \mathcal{N}(\nu) \asymp \nu^{\frac{1}{\beta}}$, simple calculation shows that by choosing $ \nu = n^{\frac{\beta}{s \beta + 1}}$,
\begin{itemize}
    \item the second term in \eqref{lead terms 2}:
    \begin{align}\label{1.2-4}
        \frac{C_2 \mathcal{N}^{\frac{1}{2}}(\nu)}{\sqrt{n}} \asymp \frac{\nu^{\frac{1}{2 \beta}}}{\sqrt{n}} = n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}};  
    \end{align}
    \item the third term in \eqref{lead terms 2}:
    \begin{equation}\label{1.2-5}
        \frac{C_3 \nu^{\frac{\alpha^{\prime} - s}{2}}}{\sqrt{n}} \asymp  n^{\frac{1}{2}(\frac{\alpha^{\prime}}{s + 1 / \beta} - 1)} \cdot n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}} \lesssim  n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}};
    \end{equation}
    \item the first term in \eqref{lead terms 2}:
    \begin{align}\label{1.2-6}
        \frac{C_1 \nu^{\frac{\alpha^{\prime}}{2}}}{n}\cdot \tilde{M} &\asymp \frac{\nu^{\frac{\alpha^{\prime}}{2}}}{n} \nu^{\frac{\alpha^{\prime} - s}{2}} + \frac{\nu^{\frac{\alpha^{\prime}}{2}}}{n} \cdot t + \frac{\nu^{\frac{\alpha^{\prime}}{2}}}{n} \cdot L.
    \end{align}
\end{itemize}
Further calculations show that
\begin{displaymath}
    \frac{\nu^{\frac{\alpha^{\prime}}{2}}}{n} \nu^{\frac{\alpha^{\prime} - s}{2}} = n^{\frac{\alpha^{\prime}}{s + 1 / \beta} - 1} \cdot n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}} \lesssim  n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}},
\end{displaymath}
and 
\begin{displaymath}
    \frac{\nu^{\frac{\alpha^{\prime}}{2}}}{n} = n^{\frac{1}{2} \frac{\alpha^{\prime}\beta - s \beta -2}{s \beta +1}} \cdot n^{-\frac{1}{2}  \frac{s \beta}{s \beta +1}} \lesssim  n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}}.
\end{displaymath}
To make $\eqref{1.2-6} \lesssim n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}}$ when $ \nu = n^{\frac{\beta}{s \beta + 1}}$, letting $ \frac{\nu^{\frac{\alpha^{\prime}}{2}}}{n} \cdot t \le n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}}$, we have the first restriction of $t$:
\begin{equation}\label{restrict1}
    \textbf{(R1)}:\quad t \le n^{\frac{1}{2} (1+\frac{1-\alpha^{\prime} \beta}{s \beta + 1})}.
\end{equation}
That is to say, if we choose $ t \le n^{\frac{1}{2} (1+\frac{1-\alpha^{\prime} \beta}{s \beta + 1})} $, we have 
\begin{displaymath}
    \text{\uppercase\expandafter{\romannumeral1}} \le \ln{\frac{2}{\delta}} C \frac{\nu^{\frac{1}{2 \beta}}}{\sqrt{n}} = \ln{\frac{2}{\delta}} C n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}}.
\end{displaymath}
For the second term in (\ref{decomposition}), denoted as $\text{\uppercase\expandafter{\romannumeral2}}$, we have 
\begin{align}
    \tau_{n} := P(\text{\uppercase\expandafter{\romannumeral2}} > \frac{ \nu^{\frac{1}{2 \beta}}}{\sqrt{n}}) 
    &\le P\Big( ~\exists x_{i} ~\text{s.t.}~ x_{i} \in \Omega_{2}, \Big) = 1 - P\Big(x_{i} \notin \Omega_{2}, \forall x_{i},i=1,2,\cdots,n \Big) \notag \\
    &= 1 - P\Big(x \notin \Omega_{2}\Big)^{n} \notag \\
    &= 1 - P\Big( |f_{\rho}^{*}(x)| \le t\Big)^{n} \notag \\
    & \le 1 - \Big( 1 - \frac{(C_q)^{q}}{t^{q}}\Big)^{n}. \notag
\end{align}
Letting $\tau_{n} := P(\text{\uppercase\expandafter{\romannumeral2}} > \frac{ \nu^{\frac{1}{2 \beta}}}{\sqrt{n}}) \to 0$, we have $ \displaystyle{t^{q}} \gg n$, i.e. $t \gg n^{\frac{1}{q}} $. This gives the second restriction of $t$, i.e., 
\begin{equation}\label{restrict2}
   \textbf{(R2)}:\quad t \gg n^{\frac{1}{q}}, ~\text{or}~ n^{\frac{1}{q}} = o(t).
\end{equation}
For the third term in (\ref{decomposition}), denoted as $\text{\uppercase\expandafter{\romannumeral3}}$. Since Lemma \ref{due embedding bound} implies that $\| T_{\nu}^{-\frac{1}{2}} k(x,\cdot)\|_{\mathcal{H}} \le M_{\alpha^{\prime}} \nu^{\frac{\alpha^{\prime}}{2}}, \mu \text {-a.e. } x \in \mathcal{X},$  so
\begin{align}\label{third term}
    \text{\uppercase\expandafter{\romannumeral3}} &\le \mathbb{E}\| \xi_{x} I_{x\in\Omega_{2}} \|_{\mathcal{H}} \le \mathbb{E}\Big[ \| T_{\nu}^{-\frac{1}{2}} k(x,\cdot) \|_{\mathcal{H}} \cdot \big| \big(y-f_{\nu}(x) \big) I_{x\in\Omega_{2}}\big| \Big] \notag \\
    &\le M_{\alpha^{\prime}} \nu^{\frac{\alpha^{\prime}}{2}} \mathbb{E} \big| \big(y-f_{\nu}(x) \big) I_{x\in\Omega_{2}}\big| \notag \\
    &\le M_{\alpha^{\prime}} \nu^{\frac{\alpha^{\prime}}{2}} \Big( \mathbb{E} \big| \big(f_{\rho}^{*}(x)-f_{\nu}(x) \big) I_{x\in\Omega_{2}}\big| +  \mathbb{E} \big| \big(f_{\rho}^{*}(x)-y \big) I_{x\in\Omega_{2}}\big| \Big) \notag \\
    &\le M_{\alpha^{\prime}} \nu^{\frac{\alpha^{\prime}}{2}} \Big( \mathbb{E} \big| \big(f_{\rho}^{*}(x)-f_{\nu}(x) \big) I_{x\in\Omega_{2}}\big| +  \mathbb{E} \big| \epsilon \cdot I_{x\in\Omega_{2}}\big| \Big) .
\end{align}
Using Cauchy-Schwarz and the bound of approximation error (Theorem \ref{theorem of approximation error}), we have
\begin{align}\label{1.2-1}
    \mathbb{E} \big| \big(f_{\rho}^{*}(x)-f_{\nu}(x) \big) I_{x\in\Omega_{2}}\big| \le \left( \left\|f_{\rho}^*-f_\nu\right\|_{L^{2}}\right)^{\frac{1}{2}} \cdot \left(P(x \in \Omega_{2})\right)^{\frac{1}{2}} \le R \nu^{-\frac{s}{2}} C_{q}^{\frac{q}{2}} t^{-\frac{q}{2}}.
\end{align}
In addition, we have
\begin{align}\label{1.2-2}
    \mathbb{E} \big| \epsilon \cdot I_{x\in\Omega_{2}}\big| = \mathbb{E} \left( \mathbb{E} \big| \epsilon \cdot I_{x\in\Omega_{2}}\big| ~\Big|~ x\right) \le \sigma \mathbb{E} \left| I_{x\in\Omega_{2}}\right| \le \sigma (C_{q})^{q} t^{-q}.
\end{align}
Plugging \eqref{1.2-1} and \eqref{1.2-2} into \eqref{third term}, we have
\begin{equation}\label{1.2-3}
    \text{\uppercase\expandafter{\romannumeral3}} \le M_{\alpha^{\prime}} R C_{q}^{\frac{q}{2}} \nu^{\frac{\alpha^{\prime} - s }{2}} t^{-\frac{q}{2}} + M_{\alpha^{\prime}} \sigma (C_{q})^{q}  \nu^{\frac{\alpha^{\prime}}{2}} t^{-q}.
\end{equation}
Comparing (\ref{1.2-3}) with $C_3 \frac{ \nu^{\frac{\alpha^{\prime} - s}{2}}}{\sqrt{n}}$ and $C_1 \frac{\nu^{\frac{\alpha^{\prime}}{2}}}{n}$ in (\ref{lead terms 2}). We know that if $ t \ge n^{\frac{1}{q}}$, (\ref{third term}) $\le C \frac{\nu^{\frac{1}{2 \beta}}}{\sqrt{n}} = C n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}}$. So the third term will not give further restriction of $t$.

To sum up, if we choose $t$ such that restrictions (\ref{restrict1}) and (\ref{restrict2}) are satisfied, then we can prove that (\ref{equivalent goal}) is satisfied with probability at least $ 1 - \delta - \tau_{n}, (\tau_{n} \to 0)$. Since for a fixed $\delta \in (0,1)$, when $n$ is sufficiently large, $\tau_{n}$ is sufficiently small such that, e.g., $\tau_{n} < \frac{\delta}{10}$. Without loss of generality, we say \eqref{equivalent goal} is satisfied with probability at least $ 1 - \delta$.  

Recalling restrictions (\ref{restrict1}) and (\ref{restrict2}), such $t$ exists if and only if $ [\mathcal{H}]^{s} \hookrightarrow L^{q}(\mathcal{X}, \mu)$ for some $q$ satisfying
\begin{equation}\label{require of q}
    \frac{1}{q} < \frac{1}{2} (1+\frac{1-\alpha^{\prime} \beta}{s \beta + 1}) \Longleftrightarrow q > \frac{2(s \beta + 1)}{2 + (s-\alpha^{\prime}) \beta}.
\end{equation}
If $s > \alpha_{0}$, $[\mathcal{H}]^{s} \hookrightarrow L^{\infty}(\mathcal{X}, \mu) $, hence \eqref{require of q} holds naturally. If $s \le \alpha_{0}$, Theorem \ref{integrability of Hs} shows that there exists $ \alpha_{0} < \alpha^{\prime \prime} < \alpha^{\prime} < s + \frac{1}{\beta}$ such that
\begin{displaymath}
    [\mathcal{H}]^{s} \hookrightarrow L^{q_{s}}(\mathcal{X}, \mu),\quad q_{s} = \frac{2 \alpha^{\prime \prime}}{\alpha^{\prime \prime} - s}.
\end{displaymath}
Further, $ \alpha^{\prime} > \alpha^{\prime \prime}$ and $ s + \frac{1}{\beta} > \alpha^{\prime}$ imply that
\begin{displaymath}
    \frac{2 \alpha^{\prime \prime}}{\alpha^{\prime \prime} - s} > \frac{2 \alpha^{\prime }}{\alpha^{\prime} - s} > \frac{2(s \beta + 1)}{2 + (s-\alpha^{\prime}) \beta}.
\end{displaymath}
So \eqref{require of q} holds for all $s + \frac{1}{\beta} > \alpha_{0}$ and we finish the proof of this case.

\vspace{15pt}
\paragraph{The $ \bm{s + \frac{1}{\beta} \le \alpha_{0}} $ case:}
Denote $ \xi_{i} = \xi(x_{i},y_{i}) = T_{\nu}^{- \frac{1}{2}} (K_{x_{i}} y_{i} - T_{x_i}f_{\nu} )$, for any fixed $\alpha_{0} < \alpha \le 1$, (\ref{goal of theorem 4.9-2}) is equivalent to
   \begin{equation}\label{equivalent goal-2}
       \left\| \frac{1}{n} \sum\limits_{i=1}^{n} \xi_{i} - \mathbb{E}\xi_{x} \right\|_{\mathcal{H}} \le \ln{\frac{2}{\delta}} C \frac{\nu^{\frac{\alpha-s}{2}}}{\sqrt{n}} \le \ln{\frac{2}{\delta}} C \left(\frac{n}{\ln^{r}(n)}\right)^{-\frac{1}{2} \frac{s}{\alpha}}, 
   \end{equation}
We also consider the subset $\Omega_{1} = \{x \in \Omega: |f_{\rho}^{*}(x)| \le t \}$ and $\Omega_{2} = \mathcal{X} \backslash \Omega_{1}$. Assume that for some $ q \ge 2$, 
\begin{displaymath}
    [\mathcal{H}]^{s} \hookrightarrow L^{q}(\mathcal{X},\mu).
\end{displaymath}
Similarly, decompose $\xi_{i}$ as $\xi_{i} I_{x_{i} \in \Omega_{1} } +  \xi_{i} I_{x_{i} \in \Omega_{2} }$ and we have
\begin{align}\label{decomposition-2}
    \left\|\frac{1}{n} \sum_{i=1}^n \xi_i-\mathbb{E} \xi_x\right\|_\mathcal{H} \le \left\|\frac{1}{n} \sum_{i=1}^n \xi_i I_{x_{i} \in \Omega_{1}}-\mathbb{E} \xi_x I_{x \in \Omega_{1}} \right\|_\mathcal{H} + \| \frac{1}{n} \sum_{i=1}^n \xi_i I_{x_{i} \in \Omega_{2}} \|_{_\mathcal{H}} + \| \mathbb{E} \xi_x I_{x \in \Omega_{2}} \|_{_\mathcal{H}}.
\end{align}
For the first term in (\ref{decomposition-2}), denoted as \text{\uppercase\expandafter{\romannumeral1}}, Theorem \ref{theorem 4.9 boundness} shows that there for this $\alpha > \alpha_{0} $, with probability at least $1-\delta$, we have
\begin{equation}\label{lead terms 2-2}
  \text{\uppercase\expandafter{\romannumeral1}} \leq \ln \frac{2}{\delta}\left(\frac{C_1 \nu^{\frac{\alpha}{2}}}{n} \cdot \tilde{M} +\frac{C_2 \nu^{\frac{1}{2 \beta}}}{\sqrt{n}}+\frac{C_3 \nu^{\frac{\alpha - s}{2}}}{\sqrt{n}}\right),
\end{equation}
where $\tilde{M} = M_{\alpha} (E+F_{\tau}) R \nu^{\frac{ \alpha - s}{2}} + t + L$. Simple calculation shows that by choosing $ \nu = (\frac{n}{\ln^{r}(n)})^{\frac{1}{\alpha}}$,
\begin{itemize}
    \item the second term in \eqref{lead terms 2-2}:
    \begin{align}\label{1.2-4-2}
        \frac{C_2 \mathcal{N}^{\frac{1}{2}}(\nu)}{\sqrt{n}} \asymp \frac{\nu^{\frac{1}{2 \beta}}}{\sqrt{n}} \lesssim \frac{\nu^{\frac{\alpha - s}{2}}}{\sqrt{n}};  
    \end{align}
    \item the third term in \eqref{lead terms 2-2}:
    \begin{equation}\label{1.2-5-2}
        \frac{C_3 \nu^{\frac{\alpha - s}{2}}}{\sqrt{n}} \asymp  n^{-\frac{1}{2}} n^{\frac{1}{2}-\frac{s}{2\alpha}} \left(\frac{1}{\ln^{r}(n)}\right)^{\frac{1}{2} - \frac{s}{2 \alpha}} \lesssim \left(\frac{n}{\ln^{r}(n)}\right)^{-\frac{1}{2} \frac{s}{\alpha}}.
    \end{equation}
    \item the first term in \eqref{lead terms 2-2}:
    \begin{align}\label{1.2-6-2}
        \frac{C_1 \nu^{\frac{\alpha}{2}}}{n}\cdot \tilde{M} &\asymp \frac{\nu^{\frac{\alpha}{2}}}{n} \nu^{\frac{\alpha - s}{2}} + \frac{\nu^{\frac{\alpha}{2}}}{n} \cdot t + \frac{\nu^{\frac{\alpha}{2}}}{n} \cdot L.
    \end{align}
    
\end{itemize}
Further calculations show that
\begin{displaymath}
    \frac{\nu^{\frac{\alpha}{2}}}{n} \nu^{\frac{\alpha - s}{2}} = \frac{\nu^{\frac{\alpha - s}{2}}}{\sqrt{n}} \cdot \frac{\nu^{\frac{\alpha}{2}}}{\sqrt{n}} = \frac{\nu^{\frac{\alpha - s}{2}}}{\sqrt{n}} \cdot \left(\frac{1}{\ln^{r}(n)}\right)^{\frac{\alpha}{2}} \lesssim \frac{\nu^{\frac{\alpha-s}{2}}}{\sqrt{n}}.
\end{displaymath}
and 
\begin{displaymath}
    \frac{\nu^{\frac{\alpha}{2}}}{n} \lesssim \frac{\nu^{\frac{\alpha-s}{2}}}{\sqrt{n}},
\end{displaymath}
To make $\eqref{1.2-6-2} \lesssim  \left(\frac{n}{\ln^{r}(n)}\right)^{-\frac{1}{2} \frac{s}{\alpha}}$ when $ \nu = (\frac{n}{\ln^{r}(n)})^{\frac{1}{\alpha}}$, letting $\frac{\nu^{\frac{\alpha}{2}}}{n} \cdot t \le  \frac{\nu^{\frac{\alpha-s}{2}}}{\sqrt{n}}$, we have the first restriction of $t$ (ignoring the $\log$ term):
\begin{equation}\label{restrict1-less}
    \textbf{(R1-2)}:\quad t \le n^{\frac{1}{2}\left(1 - \frac{s}{\alpha} \right)}.
\end{equation}
For the second and third terms in \eqref{decomposition-2}, we repeat the procedure as the case $ s +\frac{1}{\beta} > \alpha_{0}$, therefore the other restriction of $t$ remains unchanged, i.e.,  
\begin{equation}\label{restrict2-less}
   \textbf{(R2)}:\quad t \gg n^{\frac{1}{q}}, ~\text{or}~ n^{\frac{1}{q}} = o(t).
\end{equation}
These restrictions (\ref{restrict1-less}) and (\ref{restrict2-less}) shows that such $t$ exists if and only if $ [\mathcal{H}]^{s} \hookrightarrow L^{q}(\mathcal{X}, \mu)$ for some $q$ satisfying
\begin{equation}\label{1.9-1}
    \frac{1}{q} < \frac{1}{2}\left(1 - \frac{s}{\alpha} \right) \Longleftrightarrow q > \frac{2\alpha}{\alpha-s}.
\end{equation}
Recalling that $ \alpha > \alpha_{0}$ and $s +\frac{1}{\beta} \le \alpha_{0} $ implies $ s \le \alpha_{0}$, Theorem \ref{integrability of Hs} shows that there exists $\alpha_{0} < \alpha^{\prime} < \alpha$ such that
\begin{displaymath}
    [\mathcal{H}]^{s} \hookrightarrow L^{q_{s}}(\mathcal{X}, \mu),\quad q_{s} = \frac{2 \alpha^{\prime}}{\alpha^{\prime} - s},
\end{displaymath}
and
\begin{displaymath}
    \frac{2 \alpha^{\prime}}{\alpha^{\prime} - s} > \frac{2 \alpha}{\alpha - s}.
\end{displaymath}
So \eqref{1.9-1} holds for all $ s + \frac{1}{\beta} \le \alpha_{0}$ and we finish the proof of this case.
\end{proof}


\begin{theorem}[bound of estimation error]\label{estimation error thm}
  Suppose that Assumption \ref{ass EDR},\ref{assumption embedding}, \ref{ass source condition} and \ref{ass mom of error} hold for $ 0 < s \le 2 \tau$ and $\frac{1}{\beta} \le \alpha_{0} < 1$. Let $\hat{f}_{\nu}$ be the estimator defined by \eqref{SA estimator}. Then for $0 \le \gamma \le 1$ with $\gamma \le s$:
  \begin{itemize}[leftmargin = 18pt]
      \item In the case of $s + \frac{1}{\beta} > \alpha_{0} $, by choosing $\nu \asymp n^{\frac{\beta }{s \beta + 1}}$, for any fixed $\delta \in (0,1)$, when $n$ is sufficiently large, with probability at least $1 - \delta$, we have
      \begin{equation}\label{3.10-2}
          \left\|\hat{f}_\nu-f_{\nu}\right\|_{[\mathcal{H}]^{\gamma}}^2 \leq\left(\ln \frac{6}{\delta}\right)^2 C n^{-\frac{(s-\gamma) \beta}{s \beta+1}},
      \end{equation}
      where $C$ is a constant independent of $n$ and $\delta$.
      
      \item In the case of $s + \frac{1}{\beta} \le \alpha_{0} $, for any $ \alpha_{0} < \alpha \le 1$, by choosing $\nu \asymp (\frac{n}{\ln^{r}(n)})^{\frac{1}{\alpha}}$, for some $r > 1$, for any fixed $\delta \in (0,1)$, when $n$ is sufficiently large, with probability at least $1 - \delta$, we have
      \begin{equation}\label{3.10-3}
          \left\|\hat{f}_\nu-f_{\nu}\right\|_{[\mathcal{H}]^{\gamma}}^2 \leq \left(\ln \frac{6}{\delta}\right)^2 C \left(\frac{n}{\ln ^r(n)}\right)^{-\frac{s-\gamma}{\alpha}},
      \end{equation}
      where $C$ is a constant independent of $n$ and $\delta$.
  \end{itemize}
\end{theorem}
\begin{proof}
Using Lemma \ref{lemma 4.7}, Theorem \ref{theorem 4.9} and Lemma \ref{concentra of operator} for $ \frac{\delta}{3} \in (0,\frac{1}{3})$, with probability at least $1-\delta $, we have the following results hold simultaneously
\begin{equation}\label{3bounds-1}
   \left\|T_\nu^{-\frac{1}{2}} T_{X \nu}^{\frac{1}{2}}\right\|^2 \leq 2, \quad\left\|T_\nu^{\frac{1}{2}} T_{X \nu}^{-\frac{1}{2}}\right\|^2 \leq 3;
\end{equation}
\begin{displaymath}
    \eqref{goal of theorem 4.9} ~\text{and}~ \eqref{goal of theorem 4.9-2};
\end{displaymath}
\begin{equation}\label{3bounds-3}
    \left\|T_X-T\right\| \le \frac{8 \sqrt{2} \kappa^2}{\sqrt{n}} \ln \frac{6}{\delta}.
\end{equation}
Note that when choosing $\nu$ as in \eqref{3.10-2} or \eqref{3.10-3}, the condition \eqref{require 3.10} required in Lemma \ref{lemma 4.7} is always satisfied when $ n $ is sufficiently large. 

$ $\\
\textbf{Step 1}:
First, we rewrite the estimation error as follows,
\begin{align}\label{proof of 3.1-1}
    \left\|\hat{f}_\nu-f_\nu\right\|_{[\mathcal{H}]^{\gamma}} & =\left\|L_{k}^{-\frac{\gamma}{2}} S_{k} \left(\hat{f}_\nu-f_\nu\right)\right\|_{L^{2}} \notag \\
    & =\left\|L_{k}^{-\frac{\gamma}{2}} S_{k} T_\nu^{-\frac{1}{2}} \cdot T_\nu^{\frac{1}{2}} T_{X \nu}^{-\frac{1}{2}} \cdot T_{X \nu}^{\frac{1}{2}}\left(\hat{f}_\nu-f_\nu\right)\right\|_{L^{2}} \notag \\
    &\leq \left\|L_{k}^{-\frac{\gamma}{2}} S_{k} T_\nu^{-\frac{1}{2}}\right\|_{\mathscr{B}\left(\mathcal{H},L^{2}\right)} \cdot \left\|T_\nu^{\frac{1}{2}} T_{X \nu}^{-\frac{1}{2}}\right\|_{\mathscr{B}(\mathcal{H})} \cdot \left\|T_{X \nu}^{\frac{1}{2}}\left(\hat{f}_\nu-f_\nu\right)\right\|_{\mathcal{H}} .
\end{align}
For any $f \in \mathcal{H}$ and $\|f\|_{\mathcal{H}}=1$, suppose that $f = \sum\limits_{i \in N} a_{i} \lambda_{i}^{1/2} e_{i}$ satisfying that $ \sum\limits_{i \in N} a_{i}^{2} = 1$. So for the first term in \eqref{proof of 3.1-1}, we have
\begin{align}
    \left\|L_{k}^{-\frac{\gamma}{2}} S_{k} T_\nu^{-\frac{1}{2}}\right\|_{\mathscr{B}\left(\mathcal{H},L^{2}\right)} &= \sup_{\|f\|_{\mathcal{H}}=1} \left\|L_{k}^{-\frac{\gamma}{2}} S_{k} T_\nu^{-\frac{1}{2}} f\right\|_{L^{2}} \notag \\
    &\le \sup_{\|f\|_{\mathcal{H}}=1} \left\|\sum\limits_{i \in N} \frac{\lambda_{i}^{\frac{1-\gamma}{2}}}{(\lambda_{i}+\nu^{-1})^{\frac{1}{2}}} a_{i} e_{i} \right\|_{L^{2}} \notag \\
    &\le  \sup_{i \in N} \frac{\lambda_{i}^{\frac{1-\gamma}{2}}}{(\lambda_{i}+\nu^{-1})^{\frac{1}{2}}} \cdot \sup_{\|f\|_{\mathcal{H}}=1} \left\|\sum\limits_{i \in N} a_{i} e_{i} \right\|_{L^{2}} \notag \\
    &\le \nu^{\frac{\gamma}{2}}, \notag 
\end{align}
where we use Lemma \ref{basic ineq} for the last inequality. For the second term in (\ref{proof of 3.1-1}), \eqref{3bounds-1} shows that
\begin{displaymath}
  \left\|T_\nu^{\frac{1}{2}} T_{X \nu}^{-\frac{1}{2}}\right\|_{\mathscr{B}(\mathcal{H})} \le 3.
\end{displaymath}
For the third term in (\ref{proof of 3.1-1}), noticing that $z \varphi_\nu + \psi_\nu=1$, we have
  \begin{align}
    \hat{f}_\nu-f_\nu & =\varphi_\nu\left(T_X\right) g_Z-\left(T_X \varphi_\nu\left(T_X\right)+\psi_\nu\left(T_X\right)\right) f_\nu \notag \\
    & =\varphi_\nu\left(T_X\right)\left(g_Z-T_X f_\nu\right)-\psi_\nu\left(T_X\right) f_\nu \notag 
  \end{align}
So for the third term in (\ref{proof of 3.1-1}),
  \begin{equation}\label{third decompose}
      \left\|T_{X \nu}^{\frac{1}{2}}\left(\hat{f}_\nu-f_\nu\right)\right\|_{\mathcal{H}} \le \left\|T_{X \nu}^{\frac{1}{2}} \varphi_\nu\left(T_X\right)\left(g_Z-T_X f_\nu\right)\right\|_{\mathcal{H}} + \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) f_\nu\right\|_{\mathcal{H}}.
  \end{equation}
$ $\\
\textbf{Step 2}: Now we begin to bound the first term in (\ref{third decompose}), i.e., 
\begin{align}\label{third decompose rewrite}
    \left\|T_{X \nu}^{\frac{1}{2}} \varphi_\nu\left(T_X\right)\left(g_Z-T_X f_\nu\right)\right\|_{\mathcal{H}}= & \left\|T_{X \nu}^{\frac{1}{2}} \varphi_\nu\left(T_X\right) T_{X \nu}^{\frac{1}{2}} \cdot T_{X \nu}^{-\frac{1}{2}} T_\nu^{\frac{1}{2}} \cdot T_\nu^{-\frac{1}{2}}\left(g_Z-T_X f_\nu\right)\right\|_{\mathcal{H}} \notag \\
    \leq & \left\|T_{X \nu}^{\frac{1}{2}} \varphi_\nu\left(T_X\right) T_{X \nu}^{\frac{1}{2}}\right\|_{\mathscr{B}(\mathcal{H})} \cdot \left\|T_{X \nu}^{-\frac{1}{2}} T_\nu^{\frac{1}{2}}\right\|_{\mathscr{B}(\mathcal{H})} \cdot \left\|T_\nu^{-\frac{1}{2}}\left(g_Z-T_X f_\nu\right)\right\|_{\mathcal{H}}.
  \end{align}
   The property of filter function (\ref{prop1}) shows that $z \varphi_\nu(z) \leq E$ and $\varphi_\nu(z) \leq E \nu$. So we have 
   \begin{equation}\label{proof 3.1 mid-1}
       \left\|T_{X \nu}^{\frac{1}{2}} \varphi_\nu\left(T_X\right) T_{X \nu}^{\frac{1}{2}}\right\|_{\mathscr{B}(\mathcal{H})} = \left\|\left(T_X+\nu^{-1}\right) \varphi_\nu\left(T_X\right)\right\|_{\mathscr{B}(\mathcal{H})} \leq 2 E;
   \end{equation}
   \eqref{3bounds-1} shows that 
   \begin{equation}\label{proof 3.1 mid-2}
       \left\|T_{X \nu}^{-\frac{1}{2}} T_\nu^{\frac{1}{2}}\right\|_{\mathscr{B}(\mathcal{H})} \le 2;
   \end{equation}
   In addition, recalling that at the beginning we have assumed that \eqref{goal of theorem 4.9} and \eqref{goal of theorem 4.9-2} hold, therefore we have
   \begin{itemize}
      \item In the case of $s + \frac{1}{\beta} > \alpha_{0}$, by choosing $ \nu \asymp n^{\frac{ \beta}{s \beta + 1}}$, we have
      \begin{align}\label{proof 3.1 mid-3}
       \left\|T_\nu^{-\frac{1}{2}}\left(g_Z-T_X f_\nu\right)\right\|_{\mathcal{H}} &\le \left\|T_\nu^{-\frac{1}{2}}\left[\left(g_Z-T_X f_\nu\right)-\left(g-T f_\nu\right)\right]\right\|_{\mathcal{H}} + \left\|T_\nu^{-\frac{1}{2}}\left(g -T f_\nu\right)\right\|_{\mathcal{H}} \notag \\
       &\le \ln(\frac{6}{\delta}) C n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}} + \left\|T_\nu^{-\frac{1}{2}} \left( S_{k}^{*} f_{\rho}^{*} - S_{k}^{*} S_{k} f_\nu\right)\right\|_{\mathcal{H}} \notag \\
       &\le \ln(\frac{6}{\delta}) C n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}} + \left\|T_\nu^{-\frac{1}{2}} S_{k}^{*}\right\|_{\mathscr{B}(L^{2},\mathcal{H})} \|  f_{\rho}^{*} - f_{\nu}  \|_{L^{2}} \notag \\
       &\le \ln(\frac{6}{\delta}) C n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}} + \|  f_{\rho}^{*} - f_{\nu}  \|_{L^{2}} \notag \\ 
       &\le \ln(\frac{6}{\delta}) C n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}} + F_{\tau} R n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}}. \notag \\
       &\le \ln(\frac{6}{\delta}) C n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}},
   \end{align}
   where we use the fact that $\left\|T_\nu^{-\frac{1}{2}} S_{k}^{*}\right\|_{\mathscr{B}(L^{2},\mathcal{H})} \le 1$ and use Theorem \ref{theorem of approximation error} with $\gamma = 0$ to bound $\|  f_{\rho}^{*} - f_{\nu}  \|_{L^{2}}$.
      \item In the case of $s + \frac{1}{\beta} \le \alpha_{0} $, for any $ \alpha_{0} < \alpha \le 1$, by choosing $\nu \asymp (\frac{n}{\ln^{r}(n)})^{\frac{1}{\alpha}}$, for some $r > 1$, we have
      \begin{align}\label{proof 3.1 mid-4}
           \left\|T_\nu^{-\frac{1}{2}}\left(g_Z-T_X f_\nu\right)\right\|_{\mathcal{H}} &\le \left\|T_\nu^{-\frac{1}{2}}\left[\left(g_Z-T_X f_\nu\right)-\left(g-T f_\nu\right)\right]\right\|_{\mathcal{H}} + \left\|T_\nu^{-\frac{1}{2}}\left(g -T f_\nu\right)\right\|_{\mathcal{H}} \notag \\
           &\le \ln{\frac{6}{\delta}} C \left(\frac{n}{\ln^{r}(n)}\right)^{-\frac{1}{2} \frac{s}{\alpha}} + F_{\tau} R \left(\frac{n}{\ln^{r}(n)}\right)^{-\frac{1}{2} \frac{s}{\alpha}} \notag \\
           &\le \ln{\frac{6}{\delta}} C \left(\frac{n}{\ln^{r}(n)}\right)^{-\frac{1}{2} \frac{s}{\alpha}}.
      \end{align}
  \end{itemize}
Therefore, plugging \eqref{proof 3.1 mid-1} \eqref{proof 3.1 mid-2} \eqref{proof 3.1 mid-3} \eqref{proof 3.1 mid-4} into \eqref{third decompose rewrite}, we get the desired upper bounds of the first term in \eqref{third decompose}. Specifically, the bound in \eqref{proof 3.1 mid-3} determines the bound of \eqref{third decompose rewrite} in the the case of $s + \frac{1}{\beta} > \alpha_{0}$; and \eqref{proof 3.1 mid-4} determines the case of $s + \frac{1}{\beta} \le \alpha_{0}$.

$ $\\
\textbf{Step 3}: Now we begin to bound the second term in (\ref{third decompose}), i.e., 
\begin{equation}\label{step3 goal}
    \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) f_\nu\right\|_{\mathcal{H}}.
\end{equation}
We discuss three conditions of $s$.
\begin{itemize}[leftmargin = 18pt]
    \item $0 < s < 1$: Since $ (a+b)^{p} \le a^{p} + b^{p}$ for $ p \in [0,1]$, we have
    \begin{displaymath}
        \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right)\right\|_{\mathscr{B}(\mathcal{H})} \le \sup_{z \in [0, \kappa^{2}]} (z + \nu^{-1})^{\frac{1}{2}} \psi_{\nu}(z) \le \sup_{z \in [0, \kappa^{2}]} (z^{\frac{1}{2}} + \nu^{-\frac{1}{2}}) \psi_{\nu}(z).
    \end{displaymath}
    Using the property of filter function (\ref{prop2}), we have 
    \begin{equation}\label{1.8-8}
        \sup_{z \in [0, \kappa^{2}]} (z^{\frac{1}{2}} + \nu^{-\frac{1}{2}}) \psi_{\nu}(z) \le F_{\tau}\nu^{-\frac{1}{2}} + \nu^{-\frac{1}{2}} F_{\tau} \le 2 F_{\tau}\nu^{-\frac{1}{2}}.
    \end{equation}
    Furthermore, using the property of filter function \eqref{prop1} and recalling that
    \begin{displaymath}
      f_{\nu} = \varphi_\nu(T) S_{k}^{*} L_{k}^{\frac{s}{2}} g_{0} = \varphi_\nu(T) T^{\frac{s}{2}} S_{k}^{*} g_{0},
  \end{displaymath}
  for some $g_{0} \in L^{2}$ with $\|g_{0}\|_{L^{2}} \le R$, we have 
  \begin{align}\label{58-2}
    \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) f_\nu\right\|_{\mathcal{H}} & \leq\left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right)\right\|_{\mathscr{B}(\mathcal{H})}  \left\|\varphi_\nu(T) T^{\frac{s}{2}} S_{k}^{*} g_{0}\right\|_{\mathcal{H}} \notag \\
    &\le 2 F_\tau \nu^{-\frac{1}{2}} \cdot \left\|\varphi_\nu(T) T^{\frac{s}{2}} S_{k}^{*} \right\| \left\|g_{0}  \right\|_{L^{2}} \notag \\
    &= 2 F_\tau \nu^{-\frac{1}{2}} \cdot \left\|\varphi_\nu(T) T^{\frac{s}{2}} T^{\frac{1}{2}} \right\| \left\|g_{0}  \right\|_{L^{2}} \notag \\
    &\le 2 F_\tau \nu^{-\frac{1}{2}} \cdot \left\|T^{\frac{1 + s}{2}} \varphi_{\nu}(T)\right\|_{\mathscr{B}(\mathcal{H})}  \left\|g_{0}  \right\|_{L^{2}}  \notag \\
    &\le 2 F_\tau \nu^{-\frac{1}{2}} E \nu^{\frac{1-s}{2}} R \notag \\
    &= 2 F_{\tau} E R \nu^{-\frac{s}{2}}.
  \end{align}
  
  \item $1 \le s \le 2$: We can rewrite \eqref{step3 goal} as follows,
    \begin{align}\label{1.8-1}
        \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) f_\nu\right\|_{\mathcal{H}} &= \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) \varphi_\nu(T) T^{\frac{s}{2}} S_{k}^{*} g_{0} \right\|_{\mathcal{H}} \notag \\
        &= \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) \varphi_\nu(T) T^{\frac{s}{2}} S_{k}^{*}\right\| \left\| g_{0} \right\|_{L^{2}} \notag \\
        &= \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) \varphi_\nu(T) T^{\frac{s}{2}} T^{\frac{1}{2}}\right\| \left\| g_{0} \right\|_{L^{2}} \notag \\
        & \leq\left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right)  \varphi_\nu(T) T^{\frac{s+1}{2}} \right\| R.
    \end{align}
    Next, we can further decompose \eqref{1.8-1} as follows
    \begin{align}\label{1.8-2}
        \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) \varphi_\nu(T) T^{\frac{s+1}{2} }\right\| &=\left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) T_{X \nu}^{\frac{s-1}{2}} \cdot T_{X \nu}^{-\frac{s-1}{2}} T_\nu^{\frac{s-1}{2}} \cdot T_\nu^{-\frac{s-1}{2}} T^{\frac{s-1}{2}} \cdot T^{-\frac{s-1}{2}} \varphi_\nu(T) T^{\frac{s+1}{2}}\right\| \notag \\
        &= \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) T_{X \nu}^{\frac{s-1}{2}}\right\|\left\|T_{X \nu}^{-\frac{s-1}{2}} T_\nu^{\frac{s-1}{2}}\right\|\left\|T_\nu^{-\frac{s-1}{2}} T^{\frac{s-1}{2}}\right\|\left\|T^{-\frac{s-1}{2}} \varphi_\nu(T) T^{\frac{s+1}{2}}\right\| \notag \\
        &= \left\|T_{X \nu}^{\frac{s}{2}} \psi_\nu\left(T_X\right) \right\| \left\|T_{X \nu}^{-\frac{s-1}{2}} T_\nu^{\frac{s-1}{2}}\right \|  \left\|T_\nu^{-\frac{s-1}{2}} T^{\frac{s-1}{2}}\right\|\left\|T \varphi_\nu(T) \right\|.
    \end{align}
    Next, we need to bound the four terms in \eqref{1.8-2}. For the first term in \eqref{1.8-2}, using the inequality $ (a+b)^{p} \le a^{p} + b^{p}$ for $ p \in [0,1]$ again, we have
    \begin{equation}\label{1.8-3}
        \left\|T_{X \nu}^{\frac{s}{2}} \psi_\nu\left(T_X\right)\right\|_{\mathscr{B}(\mathcal{H})} \le \sup_{z \in [0, \kappa^{2}]} (z + \nu^{-1})^{\frac{s}{2}} \psi_{\nu}(z) \le \sup_{z \in [0, \kappa^{2}]} (z^{\frac{s}{2}} + \nu^{-\frac{s}{2}}) \psi_{\nu}(z) \le 2 F_{\tau} \nu^{-\frac{s}{2}}.
    \end{equation}
    For the second term in \eqref{1.8-2}, using Lemma \ref{cordes} and \eqref{3bounds-1}, we have,
    \begin{equation}\label{1.8-4}
        \left\|T_{X \nu}^{-\frac{s-1}{2}} T_\nu^{\frac{s-1}{2}}\right\| \le \left\|T_{X \nu}^{-\frac{1}{2}} T_\nu^{\frac{1}{2}}\right\|^{s-1} \le 3^{s-1} \le 3.
    \end{equation}
    For the third term in \eqref{1.8-2}, 
    \begin{equation}\label{1.8-5}
        \left\|T_\nu^{-\frac{s-1}{2}} T^{\frac{s-1}{2}}\right\| = \sup_{i \in N} \left(\frac{\lambda_{i}}{\lambda_{i} + \nu^{-1}}\right)^{\frac{s-1}{2}} \le 1.
    \end{equation}
    For the fourth term in \eqref{1.8-2}, using the property of filter function \eqref{prop1}, we have
    \begin{equation}\label{1.8-6}
        \left\|T \varphi_\nu(T) \right\| \le E.
    \end{equation}
    Plugging \eqref{1.8-3} \eqref{1.8-4} \eqref{1.8-5} \eqref{1.8-6} into \eqref{1.8-2}, we obtain the bound
    \begin{align}\label{condition s 2}
        \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) f_\nu\right\|_{\mathcal{H}} \le 6 E F_{\tau} R \nu^{-\frac{s}{2}}.
    \end{align}
    
    \item $s > 2$: Recalling \eqref{1.8-1}, we have
    \begin{align}\label{3.10-4}
        \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) f_\nu\right\|_{\mathcal{H}} & \leq\left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right)  \varphi_\nu(T) T^{\frac{s+1}{2}} \right\| R \notag \\
        &\le \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) T^{\frac{s-1}{2}} \right\| \left\|T \varphi_\nu(T)  \right\| R\notag \\
        &\le \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) T^{\frac{s-1}{2}} \right\| E R. 
    \end{align}
    Further, we can have the following decomposition
    \begin{displaymath}
        T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) T^{\frac{s-1}{2}}=T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right)\left(T^{\frac{s-1}{2}}-T_X^{\frac{s-1}{2}}\right) + T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) T_X^{\frac{s-1}{2}}.
    \end{displaymath}
    So we have 
    \begin{equation}\label{1.8-7}
        \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) T^{\frac{s-1}{2}} \right\| \le \left\| T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) \right\| \left\| T^{\frac{s-1}{2}}-T_X^{\frac{s-1}{2}} \right\| + \left\| T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) T_X^{\frac{s-1}{2}} \right\|.
    \end{equation}
    For the first term in \eqref{1.8-7}, using Lemma \ref{lemma phi operator} and the fact that $ \left\|T_X\right\|,\|T\| \leq \kappa^2$, we have
    \begin{equation}\label{1.8-9}
      \left\|T^{\frac{s-1}{2}}-T_X^{\frac{s-1}{2}}\right\| \leq \begin{cases}\left\|T-T_X\right\|^{\frac{s-1}{2}} & s \in(2,3], \\ \frac{s-1}{2} \kappa^{s-3}\left\|T-T_X\right\| & s \geq 3 .\end{cases}
    \end{equation}
    In addition, \eqref{3bounds-3} shows that
    \begin{equation}\label{1.8-10}
      \left\|T_X-T\right\| \leq\left\|T_X-T\right\|_2 \leq \frac{8 \sqrt{2} \kappa^2}{\sqrt{n}} \ln \frac{6}{\delta}.
    \end{equation}
    Further, recalling \eqref{1.8-8}, we have 
    \begin{equation}\label{1.8-11}
        \left\| T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) \right\| \le 2 F_{\tau} \nu^{-\frac{1}{2}}.
    \end{equation}
    In addition, similarly as \eqref{1.8-3}, we have
    \begin{align}\label{1.8-12}
       \left\| T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) T_X^{\frac{s-1}{2}} \right\| &\le \left\| T_{X}^{\frac{1}{2}} \psi_\nu\left(T_X\right) T_X^{\frac{s-1}{2}} \right\| + \nu^{-\frac{1}{2}} \left\| \psi_\nu\left(T_X\right) T_X^{\frac{s-1}{2}} \right\| \notag \\
       &= \left\| T_{X}^{\frac{s}{2}} \psi_\nu\left(T_X\right) \right\| + \nu^{-\frac{1}{2}} \left\|T_X^{\frac{s-1}{2}}  \psi_\nu\left(T_X\right) \right\| \notag \\
       &\le F_{\tau} \nu^{-\frac{s}{2}} + \nu^{-\frac{1}{2}} F_{\tau} \nu^{\frac{1-s}{2}} \notag \\
       &= 2 F_{\tau} \nu^{-\frac{s}{2}}.
    \end{align}
    To sum up, denote 
    \begin{displaymath}
      \Delta_0 := 2 E F_\tau R \nu^{-\frac{1}{2}} \kappa^{s-1} \cdot \begin{cases}n^{-\frac{s-1}{4}}\left(8 \sqrt{2} \ln \frac{6}{\delta}\right)^{\frac{s-1}{2}} & s \in(2,3], \\ n^{-\frac{1}{2}} \cdot \frac{s-1}{2} \cdot 8 \sqrt{2} \ln \frac{6}{\delta}, & s \geq 3 .\end{cases}
    \end{displaymath}
    Then plugging \eqref{1.8-9} $\sim$ \eqref{1.8-12} into \eqref{1.8-7} and use \eqref{3.10-4}, we have 
    \begin{align}
        \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) f_\nu\right\|_{\mathcal{H}} \le \Delta_0 + 2 E F_{\tau} R \nu^{-\frac{s}{2}}. \notag
    \end{align}
    Without loss of generality, we assume that $\ln \frac{6}{\delta} >1 $. Simple calculation shows that, 
    \begin{equation}\label{Delta1}
      \Delta_0 \leq 32 \max \left(\frac{s-1}{2}, 1\right) E F_\tau R \kappa^{s-1} \nu^{-\frac{1}{2}} n^{-\frac{\min (s, 3)-1}{4}} \ln \frac{6}{\delta} := \Delta_{1} .
    \end{equation}
    Then we have 
    \begin{align}\label{condition s 3}
        \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) f_\nu\right\|_{\mathcal{H}} \le \Delta_1 + 2 E F_{\tau} R \nu^{-\frac{s}{2}}.
    \end{align}
\end{itemize}

Combining the bounds of three conditions of $s$, i.e., \eqref{58-2} \eqref{condition s 2} \eqref{condition s 3}, we finally bound the goal of Step 3, i.e., \eqref{step3 goal} by
\begin{displaymath}
    \left\|T_{X \nu}^{\frac{1}{2}} \psi_\nu\left(T_X\right) f_\nu\right\|_{\mathcal{H}} \le 6 F_{\tau} E R \nu^{-\frac{s}{2}} + \Delta_1 I_{s > 2}.
\end{displaymath}

$ $\\
\textbf{Step 4}: Now we are able to use the results of Step1 $\sim$ Step3 to finish the proof of the estimation error. Still, we consider two cases, $s +\frac{1}{\beta} > \alpha_{0} $ and $s +\frac{1}{\beta} \le \alpha_{0} $. 

\begin{itemize}
    \item $s +\frac{1}{\beta} > \alpha_{0}: $ Plugging the results of Step2 and Step3 into \eqref{third decompose} and using the decomposition \eqref{proof of 3.1-1}, by choosing $ \nu \asymp n^{\frac{ \beta}{s \beta + 1}}$, we have
    \begin{align}
        \left\|\hat{f}_\nu-f_\nu\right\|_{[\mathcal{H}]^{\gamma}} &\le 3 \nu^{\frac{\gamma}{2}} \left( \ln(\frac{6}{\delta}) C n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}} + 6 F_{\tau} E R \nu^{-\frac{s}{2}}  + \Delta_{1} I_{s > 2} \right) \notag \\
        &= 3 n^{\frac{1}{2} \frac{\gamma \beta}{s \beta +1}} \left( \ln(\frac{6}{\delta}) C n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}} + 6 F_{\tau} E R n^{-\frac{1}{2} \frac{s \beta}{s \beta +1}} + \Delta_{1} I_{s > 2} \right). \notag
    \end{align}
    Recalling the expression of $\Delta_{1}$ in \eqref{Delta1}, when $ 2 < s \le 3$,
    \begin{displaymath}
        \Delta_{1} \asymp n^{-\frac{r_{0}}{2}},
    \end{displaymath}
    where 
    \begin{displaymath}
        r_{0} = \frac{\beta}{s \beta + 1} + \frac{s-1}{2}.
    \end{displaymath}
    Since $ s > 2$ implies $ s + \frac{1}{\beta} > 2$, so we have
    \begin{displaymath}
        r_{0} - \frac{s \beta }{s \beta +1} = \frac{s-1}{2} - \frac{s-1}{s +\frac{1}{\beta}} > 0.
    \end{displaymath}
    So we have $\Delta_{1} \lesssim n^{-\frac{1}{2} \frac{s \beta}{s \beta + 1}}$.
    
    When $s > 3$, we also have $r_{0} = \frac{\beta}{s \beta + 1} + 1 > \frac{s \beta }{s \beta +1}$. Therefore, we know that 
    \begin{displaymath}
        \Delta_{1} I_{s > 2} \le C \ln\frac{6}{\delta} n^{-\frac{1}{2} \frac{s \beta}{s \beta + 1}}.
    \end{displaymath}
    To sum up, we prove that when $s +\frac{1}{\beta} > \alpha_{0}$, the estimation error satisfies that
    \begin{equation}\label{final esti error-1}
        \left\|\hat{f}_\nu-f_{\nu}\right\|_{[\mathcal{H}]^{\gamma}} \leq \ln \frac{6}{\delta} C n^{-\frac{1}{2} \frac{(s-\gamma) \beta}{s \beta+1}}.
    \end{equation}
    
    \item $s + \frac{1}{\beta} \le \alpha_{0}:$ In this case, $s \le 1$. Similarly, for some fixed $\alpha_{0} < \alpha \le 1$, by choosing $\nu \asymp (\frac{n}{\ln^{r}(n)})^{\frac{1}{\alpha}}$, we have 
    \begin{align}\label{final esti error-2}
        \left\|\hat{f}_\nu-f_\nu\right\|_{[\mathcal{H}]^{\gamma}} &\le 3 \nu^{\frac{\gamma}{2}} \left( \ln{\frac{6}{\delta}} C \left(\frac{n}{ \ln^{r}(n)}\right)^{-\frac{1}{2} \frac{s}{\alpha}}  + 6 F_{\tau} E R \nu^{-\frac{s}{2}} \right) \notag \\
        &= 3 \left(\frac{n}{ \ln^{r}(n)}\right)^{\frac{\gamma}{2 \alpha} } \left( \ln{\frac{6}{\delta}} C \left(\frac{n}{ \ln^{r}(n)}\right)^{-\frac{1}{2} \frac{s}{\alpha}} + 6 F_{\tau} E R \left(\frac{n}{ \ln^{r}(n)}\right)^{-\frac{1}{2} \frac{s}{\alpha}} \right) \notag \\
        &\le \ln \frac{6}{\delta} C \left(\frac{n}{\ln ^r(n)}\right)^{-\frac{s-\gamma}{2 \alpha}}.
    \end{align}
\end{itemize}
Then, the proof of Theorem \ref{estimation error thm} follows from \eqref{final esti error-1} and \eqref{final esti error-2}.
\end{proof}


\paragraph{Proof of Theorem \ref{main theorem}}
We first decompose the $[\mathcal{H}]^{\gamma}$-norm generalization error into two terms, which are often referred to as the approximation error and the estimation error:
\begin{equation}\label{error decompose}
    \left\|\hat{f}_\nu-f_{\rho}^{*}\right\|_{[\mathcal{H}]^{\gamma}} = \left\|f_\nu-f_{\rho}^{*}\right\|_{[\mathcal{H}]^{\gamma}} + \left\|\hat{f}_\nu-f_{\nu}\right\|_{[\mathcal{H}]^{\gamma}}.
\end{equation}
For the approximation error, Theorem \ref{theorem of approximation error} proves that
\begin{itemize}
    \item By choosing $ \nu \asymp n^{\frac{ \beta}{s \beta + 1}}$, 
    \begin{equation}\label{plug appr 1}
        \left\|f_\nu-f_{\rho}^{*}\right\|_{[\mathcal{H}]^{\gamma}} \le F_{\tau} R n^{- \frac{1}{2}\frac{(s-\gamma) \beta}{s \beta+1}};
    \end{equation}
    \item by choosing $\nu \asymp (\frac{n}{\ln^{r}(n)})^{\frac{1}{\alpha}}$, for some $r > 1$,
    \begin{equation}\label{plug appr 2}
        \left\|f_\nu-f_{\rho}^{*}\right\|_{[\mathcal{H}]^{\gamma}} \le F_{\tau} R \left(\frac{n}{\ln ^r(n)}\right)^{-\frac{s-\gamma}{2 \alpha}}.
    \end{equation}
\end{itemize}
Then the proof follows from plugging \eqref{plug appr 1}, \eqref{plug appr 2} and the bounds of estimation error in Theorem \ref{estimation error thm} into \eqref{error decompose}.



\subsection{Lower bound}
The following lemma is a standard approach to derive the minimax lower bound, which can be found in \citet[Theorem 2.5]{tsybakov2009_IntroductionNonparametric}. 
\begin{lemma}\label{lower prop from tsy}
Suppose that there is a non-parametric class of functions $ \Theta$ and a (semi-)distance $d(\cdot,\cdot)$ on $ \Theta$. $\left\{ P_{\theta}, \theta \in \Theta \right\}$ is a family of probability distributions indexed by $\Theta$. Assume that $M \ge 2$ and suppose that $ \Theta$ contains elements $ \theta_0, \theta_1, \cdots, \theta_M$ such that, 
\begin{itemize}
    \item[(1)] $ d\left(\theta_j, \theta_k\right) \geq 2 s>0, \quad \forall 0 \leq j<k \leq M$;
    \item[(2)] $P_j \ll P_0, \quad \forall j=1, \cdots, M$, and 
    \begin{displaymath}
        \frac{1}{M } \sum_{j=1}^M K\left(P_j, P_0\right) \leq a \log M,
    \end{displaymath}
\end{itemize}
    with $ 0<a<1 / 8$ and $ P_j=P_{\theta_j}, j=0,1, \cdots, M$. Then
    \begin{displaymath}
    \inf _{\hat{\theta}} \sup _{\theta \in \Theta} P_\theta(d(\hat{\theta}, \theta) \geq s) \geq \frac{\sqrt{M}}{1+\sqrt{M}}\left(1-2 a-\sqrt{\frac{2 a}{\log M}}\right).
    \end{displaymath}
\end{lemma}

\begin{lemma}\label{lemma of KL}
   Suppose that $\mu$ is a distribution on $\mathcal{X}$ and $f_{i} \in L^{2}(\mathcal{X},\mu)$. Suppose that
   \begin{displaymath}
       y=f_i(x)+\epsilon, \quad i=1,2,
   \end{displaymath}
   where $\epsilon \sim \mathcal{N}(0,\sigma^{2})$ are independent Gaussian random error. Denote the two corresponding distributions on $ \mathcal{X} \times \mathcal{Y}$ as $ \rho_{i}, i=1,2$. The KL divergence of two probability distributions on $\Omega$ is 
   \begin{displaymath}
       K\left(P_1, P_2\right) \coloneqq \int_{\Omega} \log \left(\frac{\mathrm{d} P_1}{\mathrm{~d} P_2}\right) \mathrm{d} P_1,
   \end{displaymath}
   if $P_1 \ll P_2$ and otherwise $K\left(P_1, P_2\right) \coloneqq \infty $.
   Then we have 
   \begin{displaymath}
       \mathrm{KL}\left(\rho_1^n, \rho_2^n\right)=n \mathrm{KL}\left(\rho_1, \rho_2\right)=\frac{n}{2 \sigma^2}\left\|f_1-f_2\right\|_{L^2(\mathcal{X}, d \mu)}^2,
   \end{displaymath}
   where $ \rho_{i}^{n} $ denotes the independent product of $n$ distributions $\rho_{i}, i=1,2$.
\end{lemma}
\begin{proof}
The lemma directly follows from the definition of KL divergence and the fact that 
\begin{displaymath}
    \mathrm{KL}\left(N\left(f_1(x), \sigma^2\right), N\left(f_2(x), \sigma^2\right)\right) = \frac{1}{2 \sigma^2}\left|f_1(x)-f_2(x)\right|^2.
\end{displaymath}

\end{proof}


The following lemma is a result from \citet[Lemma 2.9]{tsybakov2009_IntroductionNonparametric}
\begin{lemma}\label{lemma of ham}
   Denote $\Omega=\left\{\omega=\left(\omega_1, \cdots, \omega_m\right), \omega_i \in\{0,1\}\right\}=\{0,1\}^m$. Let $m\ge 8$, there exists a subset $\left\{\omega^{(0)}, \cdots, \omega^{(M)}\right\} $ of ~$ \Omega$ such that $\omega^{(0)}=(0, \cdots, 0)$,
   \begin{displaymath}
       d_{\text {Ham }}\left(\omega^{(i)}, \omega^{(j)}\right) \coloneqq \sum_{k=1}^m\left|\omega_k^{(i)}-\omega_k^{(j)}\right| \geq \frac{m}{8}, \quad \forall 0 \leq i<j \leq M,
   \end{displaymath}
   and $M \geq 2^{m / 8}$.
\end{lemma}


Now we are ready to prove the minimax lower bound given by Theorem \ref{prop information lower bound}.
\paragraph{Proof of Theorem \ref{prop information lower bound}}
We will construct a family of probability distributions on $ \mathcal{X} \times \mathcal{Y}$ and apply Lemma \ref{lower prop from tsy}. Recall that $\mu$ is a probability distribution on $\mathcal{X}$ such that Assumption \ref{ass EDR} is satisfied. Denote the class of functions 
\begin{displaymath}
    B^{s}(R)=\left\{f \in[\mathcal{H}]^s: \|f\|_{[\mathcal{H}]^{s}} \leq R\right\},
\end{displaymath}
and for every $f \in B^{s}(R)$, define the probability distribution $\rho_{f}$ on $\mathcal{X} \times \mathcal{Y}$ such that
\begin{displaymath}
    y = f(x) + \epsilon, ~~ x \sim \mu, 
\end{displaymath}
where $\epsilon \sim \mathcal{N}(0,\bar{\sigma}^{2})$ and $\bar{\sigma} = \min(\sigma, L) $. It is easy to show that such $\rho_{f}$ falls into the family $\mathcal{P}$ in Lemma \ref{prop information lower bound}. (Assumption \ref{ass EDR} and \ref{ass source condition} are satisfied obviously. Assumption \ref{ass mom of error} follows from results of moments of Gaussian random variables, see, e.g., \citet[Lemma 21]{fischer2020_SobolevNorm}).

Using Lemma \ref{lemma of ham}, for $m = n^{\frac{1}{s\beta + 1}}$, there exists $ \omega^{(0)}, \cdots, \omega^{(M)} \in \{0,1\}^{m}$ for some $M \ge 2^{m/8} $ such that
\begin{equation}\label{proof lower-2}
    \sum_{k=1}^m\left|\omega_k^{(i)}-\omega_k^{(j)}\right| \geq \frac{m}{8}, \quad \forall 0 \leq i<j \leq M.
\end{equation}
For $\epsilon = C_{0} m^{- (s-\gamma)\beta - 1}$, define the functions $ f_i, i=1,2,\cdots, M $ as 
\begin{displaymath}
    f_i:=\epsilon^{1 / 2} \sum_{k=1}^m \omega_k^{(i)} \lambda_{m+k}^{\frac{\gamma}{2}} e_{m+k}.
\end{displaymath}
Since
\begin{align}\label{proof lower-1}
    \left\|f_i\right\|_{[\mathcal{H}]^{s}} &= \epsilon \sum_{k=1}^m \lambda_{m+k}^{\gamma-s}\left(\omega_k^{(i)}\right)^2  \notag
    \le \epsilon \sum_{k=1}^m \lambda_{2m}^{\gamma-s} \\ &\leq 2^{(s-\gamma)\beta} c \epsilon \sum_{k=1}^m m^{(s-\gamma) \beta} \le 2^{(s-\gamma)\beta} c \epsilon m^{(s-\gamma) \beta+1} = 2^{(s-\gamma)\beta} c C_{0},
\end{align}
Where $c$ in \eqref{proof lower-1} only depends on the constants in Assumption \ref{ass EDR}. So if $C_{0}$ is small such that 
\begin{equation}\label{C0-1}
    2^{(s-\gamma)\beta} c C_{0} \le R, 
\end{equation}
then we have  $f_{i} \in B^{s}(R), i=1,2,\cdots,M.$

Using Lemma \ref{lemma of KL}, we have 
\begin{align}
    \mathrm{KL}\left(\rho_{f_{i}}^n, \rho_{f_{0}}^n\right) &=\frac{n}{2 \bar{\sigma}^{2}}\left\|f_i\right\|_{L^2(\mathcal{X}, \mu)}^2 \notag \\
    &=\frac{n \epsilon}{2 \bar{\sigma}^{2}} \sum_{k=1}^m \lambda_{m+k}^{\gamma}\left(\omega_k^{(i)}\right)^2 \notag \\
    &\leq \frac{n \epsilon C m^{-\gamma \beta + 1} }{2 \bar{\sigma}^{2}}  = \frac{ n }{2 \bar{\sigma}^{2}} C C_{0} m^{-s\beta}, \notag
\end{align}
Where $C$ only depends on the constants in Assumption \ref{ass EDR}.
Recall that $ M \ge 2^{m/8}$ implies $ \ln M \geq \frac{\ln 2}{8} m$. For a fixed $a\in(0,\frac{1}{8})$, since $m = n^{\frac{1}{s \beta +1}}$, letting
\begin{equation}\label{proof 2.8-1}
  \mathrm{KL}\left(\rho_{f_{i}}^n, \rho_{f_{0}}^n\right) \le \frac{ n }{2 \bar{\sigma}^{2}}C C_{0} m^{-s\beta} \leq a \frac{\ln 2}{8} m \le a \ln M,
\end{equation}
we have 
\begin{equation}\label{C0-2}
    C_{0} \le \frac{\bar{\sigma}^{2} \ln 2 }{4C} a.
\end{equation}
So we can choose $C_{0} = c^{\prime} a$ such that \eqref{C0-1} and \eqref{C0-2} are satisfied, where $c^{\prime}$ only depends on the constants in Assumption \ref{ass EDR}.

Denote $ \left\{ \rho_{f_{i}}^n , f_{i} \in B^{s}(R)\right\}$ as a family of probability distribution index by $ f_{i} $, then \eqref{proof 2.8-1} implies the second condition in Lemma \ref{lower prop from tsy} holds. Further, using \eqref{proof lower-2}, we have 
\begin{equation}\label{proof 2.8-2}
    d \left(f_i, f_j\right)^2=\left\|f_i-f_j \right\|_{[\mathcal{H}]^{\gamma}}^2=\epsilon \sum_{k=1}^m\left(\omega_{k}^{(i)} - \omega_{k}^{(j)} \right)^2 \geq \frac{\epsilon m}{8}=\frac{c^{\prime}a}{8} m^{- (s-\gamma) \beta} \geq c^{\prime} a n^{-\frac{(s-\gamma) \beta}{s \beta + 1}},
\end{equation}
where $c^{\prime}$ only depends on the constants in Assumption \ref{ass EDR}.

Applying Lemma \ref{lower prop from tsy} to \eqref{proof 2.8-1} and \eqref{proof 2.8-2}, we have
\begin{equation}\label{proof lower-3}
\inf _{\hat{f}_n} \sup _{f \in B^s(R)} \mathbb{P}_{\rho_f}\left\{\left\|\hat{f}_n-f\right\|_{[\mathcal{H}]^{\gamma}}^2 \geq c^{\prime} a n^{-\frac{(s-\gamma) \beta}{s \beta + 1}}\right\} \geq \frac{\sqrt{M}}{1+\sqrt{M}}\left(1-2 a-\sqrt{\frac{2 a}{\ln M}}\right).
\end{equation}
When $n$ is sufficiently large so that $M$ is sufficiently large, the probability in the R.H.S. of \eqref{proof lower-3} is larger than $ 1- 3a $. For $\delta \in (0,1)$, choose $ a = \frac{\delta}{3}$, without loss of generality we assume $ a \in (0,\frac{1}{8})$. Then \eqref{proof lower-3} shows that there exists a constant $C$ only depends on the constants in Assumption \ref{ass EDR}, for all estimator $\hat{f}, $ we can find a function $f \in B^{s}(R)$ and the corresponding distribution $\rho_{f} \in \mathcal{P}$ such that, with probability at least $1-\delta$,
\begin{displaymath}
    \left\| \hat{f} - f \right\|_{[\mathcal{H}]^{\gamma}}^{2} \ge  C \delta n^{-\frac{(s-\gamma) \beta}{s \beta +1}}.
\end{displaymath}
So we finish the proof. (In fact, it can be argued that the constant $C$ only depends on the constants in \ref{ass EDR}, in dependent of $s$).

\subsection{Shift-invariant kernels}\label{section proof invariant}
Let $\mu$ be the uniform measure on $[-\pi,\pi)^d$.
It is well known that the Fourier basis
\begin{align*}
    \phi_{\bm{m}}(x) \coloneqq \exp(i \langle \bm{m},x \rangle) 
    % = \exp\left(i \sum_{j=1}^d k_j x_j\right),
\end{align*}
are orthonormal in $L^2([-\pi,\pi)^d,\mu)$:
\begin{align*}
    \int_{[-\pi,\pi)^d} \phi_{\bm{m}}(x) \phi_{\bm{m}'}(x) \mathrm{d}\mu(x) = 
    \frac{1}{(2\pi)^d} \int_{[-\pi,\pi)^d} \phi_{\bm{m}}(x) \phi_{\bm{m}'}(x) \mathrm{d}x = \bm{1}_{\{\bm{m} = \bm{m}'\}}.
\end{align*}
Now suppose $k$ is a kernel on $[-\pi,\pi)^d$ satisfying 
\begin{align*}
    k(x,y) = g\big( (x - y) \bmod [-\pi,\pi)^d\big).
\end{align*}
Then, noticing that $\phi_{\bm{m}}(x)$ is periodic, we have
\begin{align*}
    \int_{[-\pi,\pi)^d} k(x,y) \phi_{\bm{m}}(x) \mathrm{d}\mu(x) &= 
    \int_{[-\pi,\pi)^d} g\big( (x - y) \bmod [-\pi,\pi)^d\big)\exp(i \langle \bm{m},x \rangle)  \mathrm{d}\mu(x) \\
    &= \int_{[-\pi,\pi)^d} g\big( z \big)\exp(i \langle \bm{m}, y+z \rangle)  \mathrm{d}\mu(z) \\
    &= \exp(i \langle \bm{m}, y \rangle) \int_{[-\pi,\pi)^d} g\big( z \big)\exp(i \langle \bm{m}, z \rangle)  \mathrm{d}\mu(z).
\end{align*}
It shows that $\phi_{\bm{m}}(x)$ is an eigenfunction of the integral operator $T$ associated with $k$.
Since $|{\phi_{\bm{m}}(x)}| \leq 1,$ that is, the eigenfunctions are uniformly bounded, we conclude that the embedding index $\alpha_0 = \frac{1}{\beta}$.


\subsection{Spherical harmonics and dot-product kernels}\label{section proof sphere}

Let us consider the unit $d$-sphere $\mathbb{S}^d = \{ x \in \mathbb{R}^{d+1} ~|~ \|x\| = 1 \}$ and denote by $\sigma$ the uniform measure on $\mathbb{S}^d$.
The eigen-system of spherical Laplacian $\Delta_{\mathbb{S}^d}$ yields an orthogonal decomposition
\begin{align*}
    L^2(\mathbb{S}^d, \sigma) = \bigoplus_{n = 0}^\infty \mathcal{H}_n(\mathbb{S}^d),
\end{align*}
where $\mathcal{H}_n(\mathbb{S}^d)$ is the subspace of homogenenous harmonic polynomials of degree $n$ and each $Y_n \in \mathcal{H}_n(\mathbb{S}^d)$ is an eigenfunction of $\Delta_{\mathbb{S}^d}$ corresponding to eigenvalue $-n(n+d-1)$.
In particular, we can take an orthonormal basis 
\begin{align*}
    \{Y_{n,l}, l = 1,\dots,a_n,~n=0,1,\dots\},
\end{align*}
where $Y_{n,l} \in \mathcal{H}_n(\mathbb{S}^d)$ and 
\begin{align*}
  a_n \coloneqq \dim \mathcal{H}_n(\mathbb{S}^d) = \binom{n+d}{n} - \binom{n-2+d}{n-2}.
\end{align*}
Such an orthonormal basis is often referred to as the \textit{spherical harmonics}.
Although the specific choice of $Y_{n,l}$ can vary, the sum
\begin{displaymath}
    Z_n(x,y) = \sum_{l=1}^{a_n} Y_{n,l}(x)Y_{n,l}(y)
\end{displaymath}
is invariant. 
Moreover, $Z_n(x,y)$ depends only on $\langle x,y \rangle$ and satisfies~\citep[Corollary 1.2.7]{dai2013_ApproximationTheory}
\begin{displaymath}
    |Z_n(x,y)| \leq Z_n(x,x) = a_n,\quad \forall x,y \in \mathbb{S}^d.
\end{displaymath}

The following Funk-Hecke formula is important, see also \citet[Theorem 1.2.9]{dai2013_ApproximationTheory}.

\begin{theorem}[Funk-Hecke formula]
  \label{thm:FunkFormula}
  Let $d \geq 3$ and $f$ be an integrable function such that $\int_{-1}^1 |f(t)| (1-t^2)^{d/2-1} \mathrm{d} t$ is finite.
  Then for every $Y_n \in \mathcal{H}_n(\mathbb{S}^d)$,
  \begin{align}
    \label{eq:C_FunkHecke}
    \frac{1}{\omega_d}\int_{\mathbb{S}^d} f(\langle{x,y}\rangle) Y_n(y) \mathrm{d} \sigma(y) = \mu_k(f) Y_n(x),\quad \forall x \in \mathbb{S}^{d}, 
  \end{align}
  where $\mu_n(f)$ is a constant defined by
  \begin{align}
    \mu_n(f) = \omega_d \int_{-1}^1 f(t) \frac{C_n^\lambda(t)}{C_n^\lambda(1)} (1-t^2)^{\frac{d-2}{2}} \mathrm{d} t, \notag
  \end{align}
  and $\omega_d$ is the surface area of $\mathbb{S}^d$.
\end{theorem}

Suppose $k$ is a dot-product kernel. 
Recalling the definition of the integral operator $T$ associated with $k$, 
\eqref{eq:C_FunkHecke} shows that elements in $\mathcal{H}_n(\mathbb{S}^d)$, in particular $Y_{n,l}$, are eigenfunctions of $T$.
Therefore, we obtain the following Mercer's decomposition:
\begin{align}
\label{eq:MercerSphere}
  k(x,y) = \sum_{n=0}^{\infty} \mu_n \sum_{l=1}^{a_n} Y_{n,l}(x)Y_{n,l}(y).
\end{align}

\begin{proposition}
    \label{prop:EMBIdx_Sphere}
    Let $k$ be an dot-product kernel satisfying $\mu_n \asymp n^{-d\beta}$ for some $\beta>1$, where $\mu_n$ is defined in \eqref{eq:MercerSphere}.
    Then, the EDR of the corresponding RKHS is $\beta$ and the embedding index $\alpha_0 = \beta^{-1}$.
\end{proposition}
\begin{proof}
    Notice that $\mu_n$ is an eigenvalue of multiplicity $a_n$.
    Then, the eigenvalue decay rate is easily obtained by the estimation $a_n \asymp n^{d-1}$ and $\sum_{r=0}^n a_r \asymp n^d$.
    Considering the equivalent definition of the embedding property~\eqref{eq:EMB_Eigenvalues}, we have
    \begin{align*}
        \sum_{n=0}^{\infty} \mu_n^\alpha \sum_{l=1}^{a_n} Y_{n,l}(x)^2 & = \sum_{n=0}^{\infty} \mu_n^\alpha Z_n(x,x) 
        \leq \sum_{n=0}^{\infty} a_n \mu_n^\alpha \\
        & \leq \sum_{n=0}^{\infty} C n^{d-1} n^{- \alpha d \beta} =  C \sum_{n=0}^{\infty} n^{-1 - d (\alpha \beta - 1)} \\
        & < \infty \quad \text{if} \quad \alpha > \frac{1}{\beta}.
    \end{align*}
\end{proof}