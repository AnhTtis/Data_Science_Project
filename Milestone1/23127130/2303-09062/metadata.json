{
    "arxiv_id": "2303.09062",
    "paper_title": "Knowledge Transfer for Pseudo-code Generation from Low Resource Programming Language",
    "authors": [
        "Ankita Sontakke",
        "Kanika Kalra",
        "Manasi Patwardhan",
        "Lovekesh Vig",
        "Raveendra Kumar Medicherla",
        "Ravindra Naik",
        "Shrishti Pradhan"
    ],
    "submission_date": "2023-03-16",
    "revised_dates": [
        "2023-03-17"
    ],
    "latest_version": 1,
    "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
    ],
    "abstract": "Generation of pseudo-code descriptions of legacy source code for software maintenance is a manually intensive task. Recent encoder-decoder language models have shown promise for automating pseudo-code generation for high resource programming languages such as C++, but are heavily reliant on the availability of a large code-pseudocode corpus. Soliciting such pseudocode annotations for codes written in legacy programming languages (PL) is a time consuming and costly affair requiring a thorough understanding of the source PL. In this paper, we focus on transferring the knowledge acquired by the code-to-pseudocode neural model trained on a high resource PL (C++) using parallel code-pseudocode data. We aim to transfer this knowledge to a legacy PL (C) with no PL-pseudocode parallel data for training. To achieve this, we utilize an Iterative Back Translation (IBT) approach with a novel test-cases based filtration strategy, to adapt the trained C++-to-pseudocode model to C-to-pseudocode model. We observe an improvement of 23.27% in the success rate of the generated C codes through back translation, over the successive IBT iteration, illustrating the efficacy of our approach.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.09062v1"
    ],
    "publication_venue": "11 pages, 1 figure, 5 tables"
}