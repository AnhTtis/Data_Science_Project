@article{obermeyer2019dissecting,
  title={Dissecting racial bias in an algorithm used to manage the health of populations},
  author={Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
  journal={Science},
  volume={366},
  number={6464},
  pages={447--453},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@article{li2023geographvis,
  title={GeoGraphVis: A Knowledge Graph and Geovisualization Empowered Cyberinfrastructure to Support Disaster Response and Humanitarian Aid},
  author={Li, Wenwen and Wang, Sizhe and Chen, Xiao and Tian, Yuanyuan and Gu, Zhining and Lopez-Carr, Anna and Schroeder, Andrew and Currier, Kitty and Schildhauer, Mark and Zhu, Rui},
  journal={ISPRS International Journal of Geo-Information},
  volume={12},
  number={3},
  pages={112},
  year={2023},
  publisher={MDPI}
}

@article{janowicz2022know,
  title={Know, Know Where, KnowWhereGraph: A densely connected, cross-domain knowledge graph and geo-enrichment service stack for applications in environmental intelligence},
  author={Janowicz, Krzysztof and Hitzler, Pascal and Li, Wenwen and Rehberger, Dean and Schildhauer, Mark and Zhu, Rui and Shimizu, Cogan and Fisher, Colby and Cai, Ling and Mai, Gengchen and others},
  journal={AI Magazine},
  volume={43},
  number={1},
  pages={30--39},
  year={2022}
}

@article{li2012semantic,
  title={Semantic similarity measurement based on knowledge mining: An artificial neural net approach},
  author={Li, Wenwen and Raskin, Robert and Goodchild, Michael F},
  journal={International Journal of Geographical Information Science},
  volume={26},
  number={8},
  pages={1415--1435},
  year={2012},
  publisher={Taylor \& Francis}
}

@article{dw2019darpa,
  title={DARPA’s explainable artificial intelligence program},
  author={Gunning, David and Aha, D. Aha},
  journal={AI Magazine},
  volume={40},
  number={2},
  pages={44},
  year={2019}
}

@article{phillips2020four,
  title={Four principles of explainable artificial intelligence},
  author={Phillips, P Jonathon and Hahn, Carina A and Fontana, Peter C and Broniatowski, David A and Przybocki, Mark A},
  journal={Gaithersburg, Maryland},
  year={2020}
}

@incollection{li2022geoai,
  title={{{GeoAI}} and the future of spatial analytics},
  author={Li, Wenwen and Arundel, Samantha T},
  booktitle={New thinking in GIScience},
  pages={151--158},
  year={2022},
  publisher={Springer}
}

@article{adebayo2018sanity,
  title = {Sanity Checks for Saliency Maps},
  author = {Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
  year = {2018},
  journal = {Advances in neural information processing systems},
  volume = {31},
  file = {/Users/cyh/Google Drive/Zotero/Sanity_Checks_for_Saliency_Maps_Adebayo_et_al.pdf}
}

@article{buscombe2018landscape,
  title = {Landscape Classification with Deep Neural Networks},
  author = {Buscombe, Daniel and Ritchie, Andrew C.},
  year = {2018},
  journal = {Geosciences},
  volume = {8},
  number = {7},
  pages = {244},
  publisher = {{Multidisciplinary Digital Publishing Institute}}
}

@book{charlton2007fundamentals,
  title = {Fundamentals of Fluvial Geomorphology},
  author = {Charlton, Ro},
  year = {2007},
  publisher = {{Routledge}},
  isbn = {0-203-37108-9}
}

@inproceedings{chattopadhay2018gradcam,
  title = {Grad-Cam++: {{Generalized}} Gradient-Based Visual Explanations for Deep Convolutional Networks},
  booktitle = {2018 {{IEEE}} Winter Conference on Applications of Computer Vision ({{WACV}})},
  author = {Chattopadhay, Aditya and Sarkar, Anirban and Howlader, Prantik and Balasubramanian, Vineeth N.},
  year = {2018},
  pages = {839--847},
  publisher = {{IEEE}},
  isbn = {1-5386-4886-5}
}

@article{duckham2022explainable,
  title = {Explainable Spatiotemporal Reasoning for Geospatial Intelligence Applications},
  author = {Duckham, Matt and Gabela, Jelena and Kealy, Allison and Khan, Mustafizur and Legg, Jonathan and Moran, Bill and Rumi, Shakila Khan and Salim, Flora D. and Sharmeen, Shaila and Tao, Yaguang},
  year = {2022},
  journal = {Transactions in GIS},
  publisher = {{Wiley Online Library}},
  isbn = {1361-1682}
}

@article{erion2021improving,
  title = {Improving Performance of Deep Learning Models with Axiomatic Attribution Priors and Expected Gradients},
  author = {Erion, Gabriel and Janizek, Joseph D. and Sturmfels, Pascal and Lundberg, Scott M. and Lee, Su-In},
  year = {2021},
  journal = {Nature Machine Intelligence},
  pages = {1--12},
  publisher = {{Nature Publishing Group}},
  isbn = {2522-5839}
}

@article{fong2017interpretable,
  title = {Interpretable {{Explanations}} of {{Black Boxes}} by {{Meaningful Perturbation}}},
  author = {Fong, Ruth and Vedaldi, Andrea},
  year = {2017},
  month = oct,
  journal = {2017 IEEE International Conference on Computer Vision (ICCV)},
  eprint = {1704.03296},
  eprinttype = {arxiv},
  pages = {3449--3457},
  doi = {10.1109/ICCV.2017.371},
  abstract = {As machine learning algorithms are increasingly applied to high impact yet high risk tasks, such as medical diagnosis or autonomous driving, it is critical that researchers can explain how such algorithms arrived at their predictions. In recent years, a number of image saliency methods have been developed to summarize where highly complex neural networks ``look'' in an image for evidence for their predictions. However, these techniques are limited by their heuristic nature and architectural constraints.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/cyh/Google Drive/Zotero/2017_Interpretable_Explanations_of_Black_Boxes_by_Meaningful_Perturbation_Fong_Vedaldi.pdf}
}

@inproceedings{fong2019understanding,
  title = {Understanding {{Deep Networks}} via {{Extremal Perturbations}} and {{Smooth Masks}}},
  booktitle = {2019 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Fong, Ruth and Patrick, Mandela and Vedaldi, Andrea},
  year = {2019},
  month = oct,
  pages = {2950--2958},
  publisher = {{IEEE}},
  address = {{Seoul, Korea (South)}},
  doi = {10.1109/ICCV.2019.00304},
  abstract = {The problem of attribution is concerned with identifying the parts of an input that are responsible for a model's output. An important family of attribution methods is based on measuring the effect of perturbations applied to the input.In this paper, we discuss some of the shortcomings of existing approaches to perturbation analysis and address them by introducing the concept of extremal perturbations, which are theoretically grounded and interpretable. We also introduce a number of technical innovations to compute extremal perturbations, including a new area constraint and a parametric family of smooth perturbations, which allow us to remove all tunable hyper-parameters from the optimization problem. We analyze the effect of perturbations as a function of their area, demonstrating excellent sensitivity to the spatial properties of the deep neural network under stimulation. We also extend perturbation analysis to the intermediate layers of a network. This application allows us to identify the salient channels necessary for classification, which, when visualized using feature inversion, can be used to elucidate model behavior.},
  isbn = {978-1-72814-803-8},
  langid = {english},
  file = {/Users/cyh/Zotero/storage/EEXWVUK3/Fong et al. - 2019 - Understanding Deep Networks via Extremal Perturbat.pdf}
}

@article{gebru2017using,
  title = {Using Deep Learning and {{Google Street View}} to Estimate the Demographic Makeup of Neighborhoods across the {{United States}}},
  author = {Gebru, Timnit and Krause, Jonathan and Wang, Yilun and Chen, Duyun and Deng, Jia and Aiden, Erez Lieberman and {Fei-Fei}, Li},
  year = {2017},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {114},
  number = {50},
  pages = {13108--13113},
  publisher = {{National Acad Sciences}},
  issn = {0027-8424}
}

@article{goodchild2021replication,
  title = {Replication across Space and Time Must Be Weak in the Social and Environmental Sciences},
  author = {Goodchild, Michael F. and Li, Wenwen},
  year = {2021},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {118},
  number = {35},
  publisher = {{National Acad Sciences}},
  isbn = {0027-8424}
}

@article{helber2019eurosat,
  title = {Eurosat: {{A}} Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification},
  author = {Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian},
  year = {2019},
  journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume = {12},
  number = {7},
  pages = {2217--2226},
  publisher = {{IEEE}},
  isbn = {1939-1404}
}

@article{hesse2021fast,
  title = {Fast {{Axiomatic Attribution}} for {{Neural Networks}}},
  author = {Hesse, Robin and {Schaub-Meyer}, Simone and Roth, Stefan},
  year = {2021},
  journal = {Advances in Neural Information Processing Systems},
  volume = {34},
  file = {/Users/cyh/Google Drive/Zotero/2021_Fast_Axiomatic_Attribution_for_Neural_Networks_Hesse_et_al.pdf}
}

@article{koo2022how,
  title = {How Are Neighborhood and Street-Level Walkability Factors Associated with Walking Behaviors? A Big Data Approach Using Street View Images},
  author = {Koo, Bon Woo and Guhathakurta, Subhrajit and Botchwey, Nisha},
  year = {2022},
  journal = {Environment and Behavior},
  volume = {54},
  number = {1},
  pages = {211--241},
  publisher = {{SAGE Publications Sage CA: Los Angeles, CA}},
  issn = {0013-9165}
}

@incollection{kurakin2018adversarial,
  title = {Adversarial {{Examples}} in the {{Physical World}}},
  booktitle = {Artificial {{Intelligence Safety}} and {{Security}}},
  author = {Kurakin, Alexey and Goodfellow, Ian J. and Bengio, Samy},
  editor = {Yampolskiy, Roman V.},
  year = {2018},
  month = jul,
  edition = {First},
  pages = {99--112},
  publisher = {{Chapman and Hall/CRC}},
  address = {{First edition. | Boca Raton, FL : CRC Press/Taylor \& Francis Group, 2018.}},
  doi = {10.1201/9781351251389-8},
  abstract = {Most existing machine learning classifiers are highly vulnerable to adversarial examples. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake. Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model. Up to now, all previous work have assumed a threat model in which the adversary can feed data directly into the machine learning classifier. This is not always the case for systems operating in the physical world, for example those which are using signals from cameras and other sensors as an input. This paper shows that even in such physical world scenarios, machine learning systems are vulnerable to adversarial examples. We demonstrate this by feeding adversarial images obtained from cell-phone camera to an ImageNet Inception classifier and measuring the classification accuracy of the system. We find that a large fraction of adversarial examples are classified incorrectly even when perceived through the camera.},
  isbn = {978-1-351-25138-9},
  langid = {english},
  file = {/Users/cyh/Zotero/storage/HFFGSKZU/Kurakin et al. - 2018 - Adversarial Examples in the Physical World.pdf}
}

@inproceedings{kurth2018exascale,
  title = {Exascale Deep Learning for Climate Analytics},
  booktitle = {{{SC18}}: {{International Conference}} for {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}}},
  author = {Kurth, Thorsten and Treichler, Sean and Romero, Joshua and Mudigonda, Mayur and Luehr, Nathan and Phillips, Everett and Mahesh, Ankur and Matheson, Michael and Deslippe, Jack and Fatica, Massimiliano},
  year = {2018},
  pages = {649--660},
  publisher = {{IEEE}},
  isbn = {1-5386-8384-9}
}

@article{li2020automated,
  title = {Automated Terrain Feature Identification from Remote Sensing Imagery: A Deep Learning Approach},
  shorttitle = {Automated Terrain Feature Identification from Remote Sensing Imagery},
  author = {Li, Wenwen and Hsu, Chia-Yu},
  year = {2020},
  month = apr,
  journal = {International Journal of Geographical Information Science},
  volume = {34},
  number = {4},
  pages = {637--660},
  issn = {1365-8816, 1362-3087},
  doi = {10.1080/13658816.2018.1542697},
  abstract = {Terrain feature detection is a fundamental task in terrain analysis and landscape scene interpretation. Discovering where a specific feature (i.e. sand dune, crater, etc.) is located and how it evolves over time is essential for understanding landform processes and their impacts on the environment, ecosystem, and human population. Traditional induction-based approaches are challenged by their inefficiency for generalizing diverse and complex terrain features as well as their performance for scalable processing of the massive geospatial data available. This paper presents a new deep learning (DL) approach to support automatic detection of terrain features from remotely sensed images. The novelty of this work lies in: (1) a terrain feature database containing 12,000 remotely sensed images (1,000 original images and 11,000 derived images from data augmentation) that supports data-driven model training and new discovery; (2) a DL-based object detection network empowered by ensemble learning and deep and deeper convolutional neural networks to achieve high-accuracy object detection; and (3) fine-tuning the model's characteristics and behaviors to identify the best combination of hyperparameters and other network factors. The introduction of DL into geospatial applications is expected to contribute significantly to intelligent terrain analysis, landscape scene interpretation, and the maturation of spatial data science.},
  langid = {english},
  file = {/Users/cyh/Google Drive/Zotero/2020_Automated_terrain_feature_identification_from_remote_sensing_imagery_Li_Hsu.pdf}
}

@article{li2020geoai,
  title = {{{GeoAI}}: {{Where}} Machine Learning and Big Data Converge in {{GIScience}}},
  author = {Li, Wenwen},
  year = {2020},
  journal = {Journal of Spatial Information Science},
  number = {20},
  pages = {71--77},
  isbn = {1948-660X}
}

@article{li2021tobler,
  title = {Tobler's {{First Law}} in {{GeoAI}}: {{A}} Spatially Explicit Deep Learning Model for Terrain Feature Detection under Weak Supervision},
  author = {Li, Wenwen and Hsu, Chia-Yu and Hu, Maosheng},
  year = {2021},
  journal = {Annals of the American Association of Geographers},
  volume = {111},
  number = {7},
  pages = {1887--1905},
  publisher = {{Taylor \& Francis}},
  issn = {2469-4452},
  file = {/Users/cyh/Google Drive/Zotero/2021_Tobler’s_First_Law_in_GeoAI_Li_et_al.pdf}
}

@article{li2022extracting,
  title = {Extracting Spatial Effects from Machine Learning Model Using Local Interpretation Method: {{An}} Example of {{SHAP}} and {{XGBoost}}},
  author = {Li, Ziqi},
  year = {2022},
  journal = {Computers, Environment and Urban Systems},
  volume = {96},
  pages = {101845},
  publisher = {{Elsevier}},
  isbn = {0198-9715}
}


@article{li2022geoaia,
  title = {{{GeoAI}} for large-Scale Image Analysis and Machine Vision: {{Recent}} Progress of {{Artificial Intelligence}} in Geography},
  author = {Li, Wenwen and Hsu, Chia-Yu},
  year = {2022},
  journal = {ISPRS International Journal of Geo-Information},
  volume = {11},
  number = {7},
  pages = {385},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  isbn = {2220-9964}
}

@inproceedings{lin2014network,
  title = {Network {{In Network}}.},
  booktitle = {2nd {{International Conference}} on {{Learning Representations}}, {{ICLR}} 2014, {{Banff}}, {{AB}}, {{Canada}}, {{April}} 14-16, 2014, {{Conference Track Proceedings}}},
  author = {Lin, Min and Chen, Qiang and Yan, Shuicheng},
  year = {2014}
}

@article{lundberg2017unified,
  title = {A Unified Approach to Interpreting Model Predictions},
  author = {Lundberg, Scott M. and Lee, Su-In},
  year = {2017},
  journal = {Advances in neural information processing systems},
  volume = {30}
}

@inproceedings{nguyen2015deep,
  title = {Deep Neural Networks Are Easily Fooled: {{High}} Confidence Predictions for Unrecognizable Images},
  shorttitle = {Deep Neural Networks Are Easily Fooled},
  booktitle = {2015 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
  year = {2015},
  month = jun,
  pages = {427--436},
  publisher = {{IEEE}},
  address = {{Boston, MA, USA}},
  doi = {10.1109/CVPR.2015.7298640},
  abstract = {Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study [30] revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-theart DNNs believe to be recognizable objects with 99.99\% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call ``fooling images'' (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.},
  isbn = {978-1-4673-6964-0},
  langid = {english},
  file = {/Users/cyh/Google Drive/Zotero/2015_Deep_neural_networks_are_easily_fooled_Nguyen_et_al.pdf}
}

@inproceedings{petsiuk2018rise,
  title = {{{RISE}}: {{Randomized Input Sampling}} for {{Explanation}} of {{Black-box Models}}.},
  booktitle = {British {{Machine Vision Conference}} 2018, {{BMVC}} 2018, {{Newcastle}}, {{UK}}, {{September}} 3-6, 2018},
  author = {Petsiuk, Vitali and Das, Abir and Saenko, Kate},
  year = {2018},
  pages = {151},
  file = {/Users/cyh/Zotero/storage/PUXAIWZE/Petsiuk - RISE Randomized Input Sampling for Explanation of.pdf}
}

@article{qi2020visualizing,
  title = {Visualizing {{Deep Networks}} by {{Optimizing}} with {{Integrated Gradients}}},
  author = {Qi, Zhongang and Khorram, Saeed and Fuxin, Li},
  year = {2020},
  month = apr,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {34},
  number = {07},
  pages = {11890--11898},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v34i07.6863},
  abstract = {Understanding and interpreting the decisions made by deep learning models is valuable in many domains. In computer vision, computing heatmaps from a deep network is a popular approach for visualizing and understanding deep networks. However, heatmaps that do not correlate with the network may mislead human, hence the performance of heatmaps in providing a faithful explanation to the underlying deep network is crucial. In this paper, we propose I-GOS, which optimizes for a heatmap so that the classification scores on the masked image would maximally decrease. The main novelty of the approach is to compute descent directions based on the integrated gradients instead of the normal gradient, which avoids local optima and speeds up convergence. Extensive experiments show that the heatmaps produced by our approach are more correlated with the decision of the underlying deep network, in comparison with other state-of-the-art approaches.},
  langid = {english},
  keywords = {cvpr19,visualization,xDL},
  file = {/Users/cyh/Google Drive/Zotero/2020_Visualizing_Deep_Networks_by_Optimizing_with_Integrated_Gradients_Qi_et_al.pdf;/Users/cyh/Google Drive/Zotero/Qi_et_al_2019_Visualizing_Deep_Networks_by_Optimizing_with_Integrated_Gradients.pdf}
}

@inproceedings{ribeiro2016why,
  title = {"{{Why Should I Trust You}}?": {{Explaining}} the {{Predictions}} of {{Any Classifier}}},
  shorttitle = {"{{Why Should I Trust You}}?},
  booktitle = {Proceedings of the 22nd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  year = {2016},
  month = aug,
  pages = {1135--1144},
  publisher = {{ACM}},
  address = {{San Francisco California USA}},
  doi = {10.1145/2939672.2939778},
  abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
  isbn = {978-1-4503-4232-2},
  langid = {english},
  file = {/Users/cyh/Google Drive/Zotero/2016_Why_Should_I_Trust_You_Ribeiro_et_al.pdf}
}

@inproceedings{rieger2020interpretations,
  title = {Interpretations Are Useful: Penalizing Explanations to Align Neural Networks with Prior Knowledge},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Rieger, Laura and Singh, Chandan and Murdoch, William and Yu, Bin},
  year = {2020},
  pages = {8116--8126},
  publisher = {{PMLR}},
  isbn = {2640-3498}
}

@article{selvaraju2020gradcam,
  title = {Grad-{{CAM}}: {{Visual Explanations}} from {{Deep Networks}} via {{Gradient-based Localization}}},
  shorttitle = {Grad-{{CAM}}},
  author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  year = {2020},
  month = feb,
  journal = {International Journal of Computer Vision},
  volume = {128},
  number = {2},
  eprint = {1610.02391},
  eprinttype = {arxiv},
  pages = {336--359},
  issn = {0920-5691, 1573-1405},
  doi = {10.1007/s11263-019-01228-7},
  abstract = {We propose a technique for producing `visual explanations' for decisions from a large class of Convolutional Neural Network (CNN)-based models, making them more transparent and explainable.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/cyh/Google Drive/Zotero/2020_Grad-CAM_Selvaraju_et_al.pdf}
}

@inproceedings{shrikumar2017learning,
  title = {Learning {{Important Features Through Propagating Activation Differences}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Machine Learning}}},
  author = {Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
  year = {2017},
  month = jul,
  pages = {3145--3153},
  publisher = {{PMLR}},
  issn = {2640-3498},
  abstract = {The purported ``black box'' nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Deep Learning Important FeaTures), a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input. DeepLIFT compares the activation of each neuron to its `reference activation' and assigns contribution scores according to the difference. By optionally giving separate consideration to positive and negative contributions, DeepLIFT can also reveal dependencies which are missed by other approaches. Scores can be computed efficiently in a single backward pass. We apply DeepLIFT to models trained on MNIST and simulated genomic data, and show significant advantages over gradient-based methods. Video tutorial: http://goo.gl/qKb7pL code: http://goo.gl/RM8jvH},
  langid = {english},
  file = {/Users/cyh/Zotero/storage/DIZ8NEU7/Shrikumar et al. - 2017 - Learning Important Features Through Propagating Ac.pdf;/Users/cyh/Zotero/storage/KCRULZSB/Shrikumar et al. - 2017 - Learning Important Features Through Propagating Ac.pdf}
}

@inproceedings{simonyan2014deep,
  title = {Deep inside Convolutional Networks: {{Visualising}} Image Classification Models and Saliency Maps},
  booktitle = {In {{Workshop}} at {{International Conference}} on {{Learning Representations}}},
  author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  year = {2014},
  publisher = {{Citeseer}},
  file = {/Users/cyh/Google Drive/Zotero/2014_Deep_inside_convolutional_networks_Simonyan_et_al.pdf}
}

@article{simonyan2014very,
  title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  author = {Simonyan, Karen and Zisserman, Andrew},
  year = {2014},
  journal = {arXiv preprint arXiv:1409.1556},
  eprint = {1409.1556},
  eprinttype = {arxiv},
  archiveprefix = {arXiv}
}

@inproceedings{springenberg2015striving,
  title = {Striving for {{Simplicity}}: {{The All Convolutional Net}}.},
  booktitle = {3rd {{International Conference}} on {{Learning Representations}}, {{ICLR}} 2015, {{San Diego}}, {{CA}}, {{USA}}, {{May}} 7-9, 2015, {{Workshop Track Proceedings}}},
  author = {Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin A.},
  year = {2015},
  file = {/Users/cyh/Google Drive/Zotero/2015_Striving_for_Simplicity_Springenberg_et_al.pdf}
}

@inproceedings{sundararajan2017axiomatic,
  title = {Axiomatic {{Attribution}} for {{Deep Networks}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Machine Learning}}},
  author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  year = {2017},
  month = jul,
  pages = {3319--3328},
  publisher = {{PMLR}},
  issn = {2640-3498},
  abstract = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms\textemdash Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.},
  langid = {english},
  file = {/Users/cyh/Google Drive/Zotero/2017_Axiomatic_Attribution_for_Deep_Networks_Sundararajan_et_al.pdf}
}

@inproceedings{wang2020scorecam,
  title = {Score-{{CAM}}: {{Score-weighted}} Visual Explanations for Convolutional Neural Networks},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF}} Conference on Computer Vision and Pattern Recognition Workshops},
  author = {Wang, Haofan and Wang, Zifan and Du, Mengnan and Yang, Fan and Zhang, Zijian and Ding, Sirui and Mardziel, Piotr and Hu, Xia},
  year = {2020},
  pages = {24--25}
}

@article{wang2021geoai,
  title = {{{GeoAI}} in Terrain Analysis: {{Enabling}} Multi-Source Deep Learning and Data Fusion for Natural Feature Detection},
  author = {Wang, Sizhe and Li, Wenwen},
  year = {2021},
  journal = {Computers, Environment and Urban Systems},
  volume = {90},
  pages = {101715},
  publisher = {{Elsevier}},
  issn = {0198-9715}
}

@article{xing2021integratinga,
  title = {Integrating {{XAI}} and {{GeoAI}}},
  author = {Xing, Jin and Sieber, Renee},
  year = {2021},
  journal = {GIScience 2021 Short Paper Proceedings. 11th International Conference on Geographic Information Science. September 27-30},
  volume = {2021. Pozna\'n},
  pages = {Poland (Online).},
  publisher = {{eScholarship, University of California}},
  doi = {10.25436/E23014},
  keywords = {Geographic Information Science}
}

@inproceedings{li2017recognizing,
  title={Recognizing terrain features on terrestrial surface using a deep learning model: An example with crater detection},
  author={Li, Wenwen and Zhou, Bin and Hsu, Chia-Yu and Li, Yixing and Ren, Fengbo},
  booktitle={Proceedings of the 1st Workshop on Artificial Intelligence and Deep Learning for Geographic Knowledge Discovery},
  pages={33--36},
  year={2017}
}

@article{arundel2020geonat,
  title={GeoNat v1. 0: A dataset for natural feature mapping with artificial intelligence and supervised learning},
  author={Arundel, Samantha T and Li, Wenwen and Wang, Sizhe},
  journal={Transactions in GIS},
  volume={24},
  number={3},
  pages={556--572},
  year={2020},
  publisher={Wiley Online Library}
}

@article{li2022geoimagenet,
  title={{{GeoImageNet}}: a multi-source natural feature benchmark dataset for {{GeoAI}} and supervised machine learning},
  author={Li, Wenwen and Wang, Sizhe and Arundel, Samantha T and Hsu, Chia-Yu},
  journal={GeoInformatica},
  pages={1--22},
  year={2022},
  publisher={Springer}
}


@inproceedings{zeiler2014visualizing,
  title = {Visualizing and Understanding Convolutional Networks},
  booktitle = {European Conference on Computer Vision},
  author = {Zeiler, Matthew D. and Fergus, Rob},
  year = {2014},
  pages = {818--833},
  publisher = {{Springer}},
  file = {/Users/cyh/Google Drive/Zotero/2014_Visualizing_and_understanding_convolutional_networks_Zeiler_Fergus.pdf}
}

@inproceedings{zhang2019application,
  title = {Application of Multi-Channel {{3D-cube}} Successive Convolution Network for Convective Storm Nowcasting},
  booktitle = {2019 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  author = {Zhang, Wei and Han, Lei and Sun, Juanzhen and Guo, Hanyang and Dai, Jie},
  year = {2019},
  pages = {1705--1710},
  publisher = {{IEEE}},
  isbn = {1-72810-858-6}
}

@inproceedings{zhou2016learning,
  title = {Learning {{Deep Features}} for {{Discriminative Localization}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  year = {2016},
  month = jun,
  pages = {2921--2929},
  publisher = {{IEEE}},
  address = {{Las Vegas, NV, USA}},
  doi = {10.1109/CVPR.2016.319},
  abstract = {In this work, we revisit the global average pooling layer proposed in [13], and shed light on how it explicitly enables the convolutional neural network (CNN) to have remarkable localization ability despite being trained on imagelevel labels. While this technique was previously proposed as a means for regularizing training, we find that it actually builds a generic localizable deep representation that exposes the implicit attention of CNNs on an image. Despite the apparent simplicity of global average pooling, we are able to achieve 37.1\% top-5 error for object localization on ILSVRC 2014 without training on any bounding box annotation.We demonstrate in a variety of experiments that our network is able to localize the discriminative image regions despite just being trained for solving classification task1.},
  isbn = {978-1-4673-8851-1},
  langid = {english},
  file = {/Users/cyh/Google Drive/Zotero/2016_Learning_Deep_Features_for_Discriminative_Localization_Zhou_et_al.pdf}
}

% crater
@book{mcewen1983usgs,
  title={USGS Digital Cartographic Data Standards},
  author={McEwen, Robert B and Witmer, Richard E and Ramey, Benjamin S},
  volume={2},
  year={1983},
  publisher={US Department of the Interior, Geological Survey}
}

% river
@misc{wiki:River,
   author = "Wikipedia",
   title = "{River} --- {W}ikipedia{,} The Free Encyclopedia",
   year = "2022",
   howpublished = {\url{http://en.wikipedia.org/w/index.php?title=River&oldid=1123171885}},
   note = "[Online; accessed 22-November-2022]"
 }

 @misc{schumm2020,
    author = {Schumm, Stanley A. and Ritter, Dale F. and Dury, George Harry and Lustig, Lawrence K.},
    title = "{river} --- {E}ncyclopedia {B}ritannica",
    howpublished = {\url{https://www.britannica.com/science/river}},
    year = {2022},
    month = dec,    
    note = "[Online; accessed 10-December-2022]"
 }


 % meander
 @misc{wiki:Meander,
   author = "Wikipedia",
   title = "{Meander} --- {W}ikipedia{,} The Free Encyclopedia",
   year = "2022",
   howpublished = {\url{http://en.wikipedia.org/w/index.php?title=Meander&oldid=1121852800}},
   note = "[Online; accessed 22-November-2022]"
 }

@inproceedings{li2022real,
  title={Real-time {{GeoAI}} for high-resolution mapping and segmentation of arctic permafrost features: the case of ice-wedge polygons},
  author={Li, Wenwen and Hsu, Chia-Yu and Wang, Sizhe and Witharana, Chandi and Liljedahl, Anna},
  booktitle={Proceedings of the 5th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
  pages={62--65},
  year={2022}
}

@article{kedron2021reproducibility,
  title={Reproducibility and replicability: opportunities and challenges for geospatial research},
  author={Kedron, Peter and Li, Wenwen and Fotheringham, Stewart and Goodchild, Michael},
  journal={International Journal of Geographical Information Science},
  volume={35},
  number={3},
  pages={427--445},
  year={2021},
  publisher={Taylor \& Francis}
}

@article{hsu2021knowledge,
  title={Knowledge-driven GeoAI: Integrating spatial knowledge into multi-scale deep learning for Mars Crater detection},
  author={Hsu, Chia-Yu and Li, Wenwen and Wang, Sizhe},
  journal={Remote Sensing},
  volume={13},
  number={11},
  pages={2116},
  year={2021},
  publisher={MDPI}
}

@article{li2022geoai2,
  title={{{GeoAI}} in social science},
  author={Li, Wenwen},
  journal={Handbook of Spatial Analysis in the Social Sciences},
  pages={291--304},
  year={2022},
  publisher={Edward Elgar Publishing}
}

 @article{kasvi2017flow,
  title={Flow patterns and morphological changes in a sandy meander bend during a flood—spatially and temporally intensive ADCP measurement approach},
  author={Kasvi, Elina and Laamanen, Leena and Lotsari, Eliisa and Alho, Petteri},
  journal={Water},
  volume={9},
  number={2},
  pages={106},
  year={2017},
  publisher={MDPI}
}

 % volcano 
 @misc{wiki:Volcano,
   author = "Wikipedia",
   title = "{Volcano} --- {W}ikipedia{,} The Free Encyclopedia",
   year = "2022",
   howpublished = {\url{http://en.wikipedia.org/w/index.php?title=Volcano&oldid=1121909395}},
   note = "[Online; accessed 22-November-2022]"
 }

 @article{borgia2010volcano,
  title={What is a volcano?},
  author={Borgia, Andrea and Aubert, Maurice and Merle, Olivier and Van Wyk De Vries, B},
  journal={What is a volcano},
  pages={1--9},
  year={2010}
}
 
 % iceberg tongue
 @book{herzfeld2004atlas,
  title={Atlas of Antarctica: Topographic Maps from Geostatistical Analysis of Satellite Radar Altimeter Data: with 169 Figures},
  author={Herzfeld, Ute Christina},
  year={2004},
  publisher={Springer Science \& Business Media}
}

% lake
 @book{purcell_2018, place={Hamilton, New Zealand}, title={Basic biology: An introduction}, publisher={Basic Biology Ltd}, author={Purcell, Adam}, year={2018}} 
 
 
 % hill
 % % A hill is a piece of land that rises higher than everything surrounding it.
  @misc{hill_ngs, title={Hill}, url={https://education.nationalgeographic.org/resource/hill}, author={NationalGeographic}, year={2022}, journal={National Geographic Society}} 
  
 
 % dunes
  @misc{EarthEclipse_2022, title={What is a sand dune: Formation and types of sand dunes}, url={https://eartheclipse.com/science/geology/sand-dune-formation-types.html}, journal={Earth Eclipse}, author={EarthEclipse}, year={2022}, month={Jul}} 

@inproceedings{kim2018interpretability,
  title={Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)},
  author={Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and others},
  booktitle={International conference on machine learning},
  pages={2668--2677},
  year={2018},
  organization={PMLR}
}

