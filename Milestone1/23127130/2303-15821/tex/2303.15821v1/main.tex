\documentclass[12pt]{article}
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet} % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{graphicx}  % DO NOT CHANGE THIS
\frenchspacing  % DO NOT CHANGE THIS
\newcommand{\picspace}{0.24}
\newcommand{\picwidth}{1.8}
\newcommand{\lpicwidth}{2}
\newcommand{\expwidth}{1.6}
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}

\topmargin 0.0cm
\oddsidemargin 0.2cm
\textwidth 16cm 
\textheight 21cm
\footskip 1.0cm

% 直接copy
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{graphicx}
\usepackage[american]{babel}
\usepackage{microtype}
\usepackage{multirow}
\usepackage{diagbox}
\usepackage{thmtools}
\usepackage{thm-restate}
\usepackage{booktabs}
\usepackage{color}
\usepackage{xcolor}
% \definecolor{Green}{RGB}{#4c886b}
\definecolor{Green}{RGB}{76, 136, 107}
\usepackage{footnote}
% \usepackage{slashbox}
% \usepackage{makecell}
\usepackage{subfigure} %subfigure会报错
\usepackage{epsfig}
\usepackage{dcolumn}
\usepackage{enumitem}
%\usepackage{float,dblfloatfix}
\usepackage{mathrsfs}
\usepackage{threeparttable}
%\diagbox[]{}{}
% 缩小公式大小（small）的同时保持标号不动
\makeatletter
\renewcommand{\maketag@@@}[1]{\hbox{\m@th\normalsize\normalfont#1}}%
\makeatother
\usepackage{bbding} % ✔ or X
\usepackage{pifont} % X 带圈数字
\usepackage{nomencl} % 术语表
\makenomenclature
\usepackage{adjustbox}

\usepackage{algorithm}
\usepackage{algorithmic}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Procedure:}}
\newenvironment{cmd}{\fontfamily{TeX Gyre Cursor}\selectfont} % 伪代码局部注释用字体

\usepackage{amssymb}
\usepackage{bm}
\usepackage{textcomp} %命令\textacutedbl的包,二阶导符号
\newenvironment{sciabstract}{% abstract
\begin{quote} \baselineskip14pt\small\hfil {\bf Abstract} \hfil\\[3pt]}
{\end{quote}\vspace{6pt}}% abstract

\makeatletter
\newif\if@restonecol
\makeatother
% \let\algorithm\relax
% \let\endalgorithm\relax
% \usepackage[linesnumbered,ruled,vlined]{algorithm2e}%[ruled,vlined]{
% \usepackage{algpseudocode}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}} %
% % 处理表格单元格内换行
\renewcommand\arraystretch{1.3} % 调整单元格的高度

% % \newtheorem{property}{Property}
% % \newtheorem{observation}{Observation}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
% % \newtheorem{condition}{Condition}
% \newtheorem{proof}{Proof}
\newtheorem{theorem}{Theorem}
\newtheorem{assumption}{Assumption}
\newtheorem{remark}{Remark}
\title{Scaling Multi-Objective Security Games Provably via Space Discretization Based Evolutionary Search}

\author{
Yu-Peng Wu$^{1}$, Hong Qian$^{1,*}$, Rong-Jun Qin$^{3,4}$, Yi Chen$^{5}$, Aimin Zhou$^{1,2}$\\
\small{
$^{1}$School of Computer Science and Technology, East China Normal University, Shanghai, China}\\
\small{
$^{2}$Shanghai Institute of AI for Education, East China Normal University, Shanghai, China}\\
\small{
$^{3}$National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China}\\
\small{
$^{4}$Polixir Technologies, Nanjing, China}\\
\small{
$^{5}$Department of Computer Science and Artificial Intelligence, Wenzhou University, Wenzhou, China}\\
\small{
51215901031@stu.ecnu.edu.cn,\ hqian@cs.ecnu.edu.cn,}\\
\small{
qinrj@lamda.nju.edu.cn,\ kenyoncy2016@gmail.com,\ amzhou@cs.ecnu.edu.cn}\\
\small{$^*$Corresponding Author}
}

\date{}

%\setlength{\parindent}{0pt}

\begin{document}

\baselineskip16pt

\maketitle 

\begin{sciabstract}
In the field of security, multi-objective security games (MOSGs) allow defenders to simultaneously protect targets from multiple heterogeneous attackers. MOSGs aim to simultaneously maximize all the heterogeneous payoffs, e.g., life, money, and crime rate, without merging heterogeneous attackers. 
In real-world scenarios, the number of heterogeneous attackers and targets to be protected may exceed the capability of most existing state-of-the-art methods, i.e., MOSGs are limited by the issue of scalability.
To this end, this paper proposes a general framework called SDES based on many-objective evolutionary search to scale up MOSGs to large-scale targets and heterogeneous attackers. SDES consists of four consecutive key components, i.e., discretization, optimization, restoration and evaluation, and refinement. 
Specifically, SDES first discretizes the originally high-dimensional continuous solution space to the low-dimensional discrete one by the maximal indifference property in game theory. This property helps evolutionary algorithms (EAs) bypass the high-dimensional step function and ensure a well-convergent Pareto front. 
Then, a many-objective EA is used for optimization in the low-dimensional discrete solution space to obtain a well-spaced Pareto front.
To evaluate solutions, SDES restores solutions back to the original space via bit-wisely optimizing a novel solution divergence.
Finally, the refinement in SDES boosts the optimization performance with acceptable cost. 
Theoretically, we prove the optimization consistency and convergence of SDES.
Experiment results show that SDES is the first linear-time MOSG algorithm for both large-scale attackers and targets. SDES is able to solve up to 20 attackers and 100 targets MOSG problems, while the state-of-the-art (SOTA) methods can only solve up to 8 attackers and 25 targets ones. Ablation study verifies the necessity of all components in SDES.
\end{sciabstract}

% \keywords{Security Games, Stackelberg Games, Scalability, Many-objective Optimization, Optimization Consistency}

\section{Introduction} \label{sec:introduction}
%Please use this sample as a guide for preparing your letter. Please read all of the following manuscript preparation instructions carefully and in their entirety. The manuscript must be in good scientific American English; this is the author's responsibility. All files will be submitted through our online electronic submission system at \url{https://mc03.manuscriptcentral.com/scis}.

Security games (SGs) study how to efficiently use limited resources to defend targets against potential attackers in the security field. SGs have facilitated a variety of successful applications, including ARMOR, IRIS, and GUARDS for airport protection~\citep{ARMOR, IRIS, GUARDS}, TRUSTS for transit system protection~\citep{TRUSTS}, PROTECT for coastal protection~\citep{PROTECT} and others~\citep{otherApplication}. SGs can be modeled as Stackelberg games~\citep{StackelberGame}, where the solution concept, Strong Stackelberg Equilibrium (SSE), a refinement of the Nash Equilibrium, always exists~\citep{SSE}. Traditional SG work usually uses scalar-based decision-making methods, e.g., Bayesian SGs algorithms~\citep{MultiLPs, DOBSS, ERASER}. 
%
However, the scalar-based methods are not suitable for handing heterogeneous SGs, which involves multiple non-mergeable attackers. For instance, the loss of property and life is not of the same magnitude~\citep{MOSG}. 

% means good diversity and distribution
This yields multi-objective security games (MOSGs)~\citep{MOSG,extended-MOSG}, which aims to find a well-convergent and well-spaced Pareto front (PF). Herein, ``well-spaced'' refers to good diversity and distribution~\citep{MOEA-survey}.
% , herein well-sapced means good diversity and distribution. 
MOSGs model heterogeneous, possibly conflicting, attackers by multi-objective optimization. 
% MOSGs treat each loss caused by heterogeneous attackers as an independent optimization objective.
% , which are promising directions developed on the basis of SGs.
%
% and there is a core limitation: the assumption of the combination of multiple attackers in the scalar-based method is contradictory to the problem setting of heterogeneous attackers.
%
% E.g., property theft and loss of life should not be uniformly represented as the same type of benefit as economic benefits~\citep{MOSG,extended-MOSG}. Therefore, multi-objective security games (MOSGs)~\citep{MOSG,extended-MOSG}, treating each loss caused by heterogeneous attackers as an independent optimization goal, are promising directions developed based on SGs. 
%
% MOSG is a model that is developed for real-world scenarios of heterogeneous attackers. MOSG is a generalization of the classic defender-attackers SG, so it is important to understand how to deal with heterogeneous attackers independently.
%%
In MOSGs, each attacker maximizes its own payoff by attacking an appropriate target, while the defender maximizes payoffs from defending against all heterogeneous attackers. 
% 
% 多目标建模的好处
Modeling security games as multi-objective optimization has the benefits of a PF for decision-makers, and less prior knowledge demands such as probability distribution over potential attackers or historical attack data~\citep{extended-MOSG}.
% MOSGs have the following properties: (i) MOSGs treat heterogeneous attackers equally and optimize all objectives simultaneously, as mentioned above. (ii) Multi-objective modeling can provide a well-convergent and well-spaced Pareto front (PF) and use analysis tools (such as visualization) to show the tradeoff between objectives. Users can also observe the properties of specific problems by observing tradeoffs. (iii) MOSGs require less prior knowledge such as probability distribution over potential attackers or historical attack data~\citep{extended-MOSG}. Meanwhile, if decision-makers have prior (not necessarily complete), they can convert prior into preference information to make informed decisions from PF~\citep{preference}. 
% 
% Index Terms
% The existing representative work~\citep{MOSG,extended-MOSG} can solve large-scale target problems with small attackers, and the gap between the approximation of the Pareto set and the reference of the Pareto set is guaranteed by an upper bound. And they are applied to the Los Angeles Sheriff’s Department (LASD) and other real environments~\citep{MOSG,extended-MOSG}. 
With the deepening of MSOGs research, real-world problems present simultaneous large-scale requirements in attackers (e.g., a wide variety of crime types) and targets (e.g., massive infrastructure in public safety field).
% there is a big challenge: The problem scale supported by existing methods does not satisfy the requirements shown in the real world.

% 补一个优点
% The main reason that existing MOSG methods fail to solve large-scale real-world scenarios is the curse of dimensionality that happened on the target and heterogeneous attacker dimensions. 
% Traditional methods solve MOSG problem of large-scale targets at the cost of sharply decreasing the number of attackers. 
The existing methods address MOSG problems with large-scale targets at the cost of greatly reducing the number of attackers they are able to handle.
% Therefore, there are many studies devoted to overcoming the impact of target and heterogeneous attacker dimensions:
Specifically, a faster convergence with the large target number is achieved by ORIGAMI algorithm (optimizing resources in games using maximal indifference)~\citep{ERASER}, which uses the maximal indifference property to address fully rational adversary games. The maximal indifference property focuses on the most attractive targets so as to make the large-scale target MOSG tractable. ORIGAMI-M and ORIGAMI-A~\citep{MOSG} extend ORIGAMI~\citep{ERASER} from single-objective optimization to multi-objective optimization and they are insensitive to the target dimension. 
% 分布性良好的PF的样本复杂度是关于N是指数级的 
However, the sample complexity of ORIGAMI-M and ORIGAMI-A finding out a well-spaced PF is exponentially with the number of attackers.
% However, the complexity of ORIGAMI-M grows exponentially with the number of attackers. 
Some pruning-based methods are then proposed to reduce the algorithmic complexity via pre-skipping inferior policy~\citep{MOSG,extended-MOSG}. However, they are still restricted by the number of attackers. The reason is that they adopt the $\epsilon$-constraint framework, which optimizes the convergence and diversity of the solution simultaneously~\citep{DMOEA-eC}. As the number of attackers increase, $\epsilon$-constraint framework requires exponential solutions to guarantee a well-spaced PF. 
% E.g., in the 5-attacker scenario, the traditional state-of-the-art (SOTA) method produces 1w solutions, but the user does not need so many solutions.
Meanwhile, MOSG problem of large-scale attackers are in demand in the real world. 
For example, in the field of public security, the criminal justice system covers a wide range of criminal offenses. Even according to their pertinence, there are more than ten kinds of heterogeneous attack types, including drug crimes, homicide, inchoate crimes, cybercrimes, juvenile crimes, sex crimes, etc.~\footnote{\url{https://www.justia.com/criminal/offenses/}} 
% \textcolor[RGB]{202,12,22}{/ Even in the specific application of LASD, the heterogeneous attackers that police need to combat are in essence large-scale problems, including but not limited to drug smuggling, poaching of rare species, cult activities, and cybercrimes. }
% \textcolor[rgb]{0.5,0.6,0.7}{Specifically, drugs are not only harmful to the individual but also cause huge social losses; rare species are a kind of natural resources that cannot be measured in money; cult activities are potential damage to the individual and society; cybercrimes are a new kind of crime type. }
Therefore, it is urgent and important to design a method that can handle MOSG problem of large-scale heterogeneous attackers without losing the large number of targets.

% 1.0版本
% From the perspective of optimization, extending the objective to large-scale scenarios means changing from a multi-objective optimization problem (MOP) to a many-objective optimization problem (MaOP). 
% (i.e., the PF with good uniformity and convergence.)
% If MOSG is directly optimized on resource allocation (continuous variable space),  the defender's utility (objective space) is a $T$-dimensional step function with frequent changes (generally $25\leq T\leq1000$). The violent solution does not make full use of the game properties of SGs.
% \textcolor[rgb]{0.5,0.6,0.7}{In our work, the fast convergence is guaranteed by the key game property maximal indifference.}
% 2.0版本
% 第一部分
% 一句话说明自己的方法做了什么
% 直接点名用现有的MaOP算法是不行的（1-2句） % 下面是老版本
% EA is the widely recognized method in the many-objective optimization problem (MaOP)~\citep{MOEA-survey}. However, even for small-scale MOSG problems, the general heuristic algorithms such as EAs cannot solve well. 
% This is not because of the insufficient search ability of those heuristic algorithms, but because of the complexity of MOSG optimization.
% 为什么不行（Step func会导致hard to converge，进而导致）
% 第二部分
% 缺少一个头：经典的方法能收敛，但是想达到well-spaced。演化算法可能能找到well-spaced，但是hard to converge（优化step func））
% 我们的目标是实现fast converge的同时保证well-spaced
% 下面的组件需要对应fast converge
% For fast convergence部分的修改
% 算法名字SDES
% To this end, this paper proposes a framework termed space discretization based evolutionary search (SDES) that is able to simultaneously extend targets and heterogeneous attackers to the large-scale scenario to meet the real-world demand. Directly applying heuristic algorithms such as evolutionary algorithms (EAs) is not suitable to scale up MOSGs. This is because it encounters a high-dimensional step function whose landscape changes frequently. EAs cannot converge well, although it may find a well-spaced PF within limited time, while exact algorithms for MOSGs such as ORIGAMI-M converge rapidly but fail to find a well-spaced PF. 
% %
% % To retain the advantage of fast convergence like ORIGAMI, 
% In order to make the best of both worlds, namely, finding a well-convergent and well-spaced PF, SDES decouples this goal into convergence and distribution. In SDES, the optimization component aims to achieve a well-spaced PF, while the restoration and refinement components aim to make the well-space PF well convergent.
% % Finally, solutions after convergence are improved by refinement component.
% %\textcolor[rgb]{0.5,0.6,0.7}{Specifically, SDES proposes four components discretization, optimization, restoration and evaluation, and refinement.}
% Specifically, the discretization component transforms the high-dimensional continuous solution space into the low-dimensional discrete one by the maximal indifference property. This game property can guarantee solution convergence and avoid directly optimizing the high-dimensional step function.
% %
% The optimization component searches a set of low-dimensional solutions by many-objective EAs (e.g., NSGA-III~\citep{NSGA-III}) and an adaptive reference direction set generator (e.g., Riesz~\citep{ref-dirs-energy}).
% % 缺少一句联系restoration和convergence assumption
% In the restoration component, the low-dimensional solutions are restored to the high-dimensional ones via bit-wise optimization, which uses a novel solution divergence proposed in this paper.
% % The evaluation component evaluates the solutions' fitness in the high-dimensional space.
% % to approximately solve the combinatorial optimization problem, 
% % the low-dimensional solutions by bit-wise optimization,
% This component can find out solutions to approximate the true PF under the convergence assumption.
% % 下面说不满足假设，我们需要refinement改善解精度。
% % Fourthly, the refinement component adjusts the subroutine of traditional methods termed MINCOV~\citep{MOSG,extended-MOSG} applies to NSGA-III.
% If a MOSG problem is too complex to satisfy the convergence assumption, the refinement component tries to improve the solution convergence generated before. 

To this end, this paper proposes a framework termed space discretization based evolutionary search (SDES) that is able to simultaneously extend targets and heterogeneous attackers to the large-scale scenario to meet the real-world demand. 
% EAs cannot converge well, although it may find a well-spaced PF within limited time, while exact algorithms for MOSGs such as ORIGAMI-M converge rapidly but fail to find a well-spaced PF. 
%
In the large-scale scenario, traditional methods~\citep{MOSG,extended-MOSG} fail to find a well-convergent and well-spaced PF, since they optimize the convergence and diversity of the solution simultaneously. 
However, directly applying heuristic algorithms such as evolutionary algorithms (EAs) is not suitable to scale up MOSGs. This is because it encounters a high-dimensional step function whose landscape changes frequently. 
In SDES, the goal of the well-convergent and well-spaced PF is decoupled into the convergence and distribution of the solution. 
SDES achieves these two goals separately by the proposed discretization, optimization, restoration and refinement components.
% In order to make the best of both worlds, namely, finding a well-convergent and well-spaced PF, SDES decouples this goal into convergence and distribution by the proposed discretization, optimization, restoration and refinement components.
The optimization component aims to achieve a well-spaced PF, while the restoration and refinement components aim to make the well-spaced PF well converge. Specifically, the discretization component transforms the high-dimensional continuous solution space into the low-dimensional discrete one by the maximal indifference property. This game property can guarantee solution convergence and avoid directly optimizing the high-dimensional step function.
%
The optimization component searches a set of low-dimensional solutions by many-objective EAs (e.g., NSGA-III~\citep{NSGA-III}) and an adaptive reference direction set generator (e.g., Riesz~\citep{ref-dirs-energy}).
% 缺少一句联系restoration和convergence assumption
In the restoration component, the low-dimensional solutions are restored to the high-dimensional ones via bit-wise optimization.
% which uses a novel solution divergence.
% The evaluation component evaluates the solutions' fitness in the high-dimensional space.
% to approximately solve the combinatorial optimization problem, 
% the low-dimensional solutions by bit-wise optimization,
This component can find out solutions to approximate the true PF under the convergence assumption.
% 下面说不满足假设，我们需要refinement改善解精度。
% Fourthly, the refinement component adjusts the subroutine of traditional methods termed MINCOV~\citep{MOSG,extended-MOSG} applies to NSGA-III.
If a MOSG problem is too complex to satisfy the convergence assumption, the refinement component tries to improve the solution convergence. 

% 把复杂度提上来，关于N是线性的for fixed T。
% SDES can accomplish large-scale MSOGs in linear complexity, while other traditional methods run exponentially in heterogeneous attackers. 
% SDES decouples convergence and uniformity. On the one hand, the optimization component aims to find a uniform PF by EA with a fixed population size in all MOSG scales. On the other hand, the restoration component aims to find solutions on the PF by the maximal indifference property, which is the core of the exact algorithm ORIGAMI~\citep{ERASER}. 
To the best of our knowledge, SDES is the first linear sample complexity framework if either the number of targets or attackers is fixed.
% 一致性指两者能找到相同的最优解，收敛性保障
Theoretically, we prove the consistency of bit-wise optimization. Furthermore, a sufficient convergence condition for the SDES framework is disclosed.
% Indeed, when a MOSG problem does not meet this assumption, the refinement component comes in handy.
% 实验部分要点 1.线性 2.在某某benchmark 3. 大规模的极限 4.
Empirically, on the widely-used MOSG benchmark, the linearity of the SDES framework is verified if either the number of targets or attackers is fixed. The results show that SDES outperforms the state-of-the-art (SOTA) methods in terms of scalability, time efficiency, and effectiveness. Specifically, SDES can solve up to 20 attackers and 100 targets MOSG problems, while the SOTA methods can only solve up to 8 attackers and 25 targets MOSG problems. Ablation study verifies the necessity of all components in SDES.


% 实验部分要点 1.线性 2.在某某benchmark 3. 大规模的极限 4.
% Empirically, on the widely used MOSG benchmark, the linearity of SDES of algorithm is verified when either target number or attacker number is fixed, and results show that SDES still outperforms SOTA methods in terms of solution quality, scalability, and time efficiency. Specifically, SDES can solve up to 20 attackers and 100 targets MOSG problems, while the SOTA method can only solve up to 8 attackers and 25 targets MOSG problems.
% 
% 写我们替换了目标, 同时证明了新目标(solution divergence)与原目标在目标空间中都能找到相同的PF, 同时给出了我们逐位选择算法的收敛条件.
% Theoretically, SDES proposes a novel solution divergence (between feasible solutions and the constructed ideal solution). This measure aims to replace the original goal of MOSG problems. 
% Meanwhile, our paper shows the consistency of optimizing solution divergence and optimizing the original MOSG problems. 
% Theoretically, we propose a novel solution divergence to replace the original goal of MOSG problems, and the consistency of this replacement is proved. 
% In addition, we provide a specific assumption for the convergence of SDES. Indeed, when a MOSG problem does not meet this assumption, the refinement component comes in handy.
%
% To the best of knowledge, SDES is the first linear-time MOSG algorithm for both large-scale attackers and targets.

% \textcolor[rgb]{0.5,0.6,0.7}{In addition, we analyze the advantages of our method theoretically and experimentally: }

% \textcolor[rgb]{0.5,0.6,0.7}{From the theoretical perspective, Lemma~\ref{pro:property1.2} and~\ref{pro:property1.1} shows the reason why the general heuristic or gradient-based methods can not solve MOSGs by searching resource allocation $c$ directly like traditional programming-based methods do, even for small-scale problems. Therefore, this paper proposes to optimize MOSGs on $\Gamma(c)$, hereinafter abbreviated as $\Gamma$. Lemma~\ref{pro:property2} indicates the change rules of $\Gamma$. At the same time, Theorem~\ref{obs:observation1} details the optimal expansion rule mentioned in Lemma~\ref{pro:property2}. The solution coded by $\Gamma$ is corresponding to several feasible strategies. In solution evaluation, we define the ideal solution, and Lemma~\ref{obs:algorithm1} proves that the ideal solution corresponds to the upper bound of all feasible strategies. Definition~\ref{def:sim_mea} and~\ref{def:dis_mea} defines the distance measure between $\Gamma$ and $\Gamma_{s}$ (the set of $\Gamma$), which supports the calculation of similarity. Theorem~\ref{obs:algorithm2} and~\ref{obs:algorithm3} shows that the higher the similarity with the ideal solution, the higher the payoff of the feasible solution. Theorem~\ref{obs:val_ana1} gives the condition that the payoff of the feasible solution and the ideal solution (upper bound) are equal. 
% Finally, our paper proposes a solution evaluation algorithm in $O(NT)$ time, while the complexity of SOTA is $O(NT^3)$.}

% \textcolor[rgb]{0.5,0.6,0.7}{From the experimental perspective, the time efficiency experiments show that our method can easily solve the MOSG problem with 20 heterogeneous attackers, while most of the comparison methods timeout after 5 heterogeneous attackers. }
% \textcolor[RGB]{202,12,22}{Meanwhile, our method performs better than SOTA on the multi-objective indicators, e.g., \textit{IGD}$^+$ and \textit{HV}. (In the multi-objective performance indicator experiments, under 13 scale scenarios, our method achieves 11 rank-1 in \textit{HV} and 9 rank-1 in \textit{IGD}$^+$.) }
% \textcolor[rgb]{0.5,0.6,0.7}{In ablation study, first, our EA (based on novel coding) outperforms naive EA (based on traditional coding) in both convergence speed and convergence effect. At the same time, the suboptimal Pareto set found in the first stage of our method outperforms more than half of all comparison methods. }


The rest of the paper is organized as follows. Section~\ref{sec:rel_wor} reviews the related work. Section~\ref{sec:pre} introduces the preliminaries of SGs and MOSGs. Section~\ref{sec:met} presents the framework and sample complexity of SDES. Section~\ref{sec:val_ana} further analyses the theoretical guarantee of SDES. Section~\ref{sec:exp} shows the experiment results of SDES compared with other SOTA methods with respect to scalability, time efficiency, effectiveness and others. Finally, Section~\ref{sec:conclusion} concludes the paper.
%  and limitations

% \textbf{Contributions}
% \begin{enumerate}
%     \item We summarize two properties of $\it{attack\ set\ \Gamma}$ under fully rational attacker behavior assumption and show that it is tricky\qinrj{What does the word tricky mean here?} to optimize the goal of the game, defender payoff, directly on $\it{coverage\ vectors}\ \bm{c}$ for heuristic and gradient-based approaches.
    
%     \item This paper proposes a novel optimization framework based on implicit variables $\gamma (c)$ for heuristic algorithms, which provides\qinrj{allows $\rightarrow$ provides?} the convergence of heuristic algorithms (e.g., taking evolutionary algorithm as an example in the experiment, it is equal to or even better than traditional exact programming-based methods in multi-objective optimization indicators).
    
%     \item The proposed $I$-code to $\Gamma$-code to $\bm{c}$-code decoding scheme for our optimization framework solves the problem that the hidden variables $\gamma$ is not directly indicative of $coverage\ vectors$ $\bm{c}$, and realizes the conversion between $\Gamma$ and $\bm{c}$ without losing information.
    
%     \item Our MOSG-solving framework can simultaneously extend target and heterogeneous attacker to large-scale scenarios. (Instead of facing \textit{the  curse of dimensionality} like traditional methods on the objective dimension, our paper proposes a heuristic fast search operator with $O(NT)$ complexity to replace the traditional $O(N^T)$ methods).
    
%     \item (to provide a novel solution coding ($I$-code), a heuristic operator for decoding (the whole coding framework is called Lcode2ccode), and to adapt the MIN-COV to apply it in EAs.)
% \end{enumerate}

% 单多+它们的大规模研究进展
\section{Related Work}
\label{sec:rel_wor}
% MaOEA的related work 比如为什么用NSGA-iii 比如用什么指标 到实验部分再说明 
% The main research lines related to this paper include multi-objective security games (MOSG) and large-scale security games. 
Modeling SG can be roughly categorized into single-objective and multi-objective methods, where Bayesian Stackelberg games and multi-objective security games (MOSGs) are their representative approaches respectively. This section first introduces those two research lines separately, followed by their corresponding work on large-scale problems.
% involves (i) the single-objective optimization modeling Bayesian Stackelberg games, (ii) the multi-objective optimization modeling MOSGs, and (iii) large-scale SGs.}

% 首先讲传统SG，引出MOSG
% 最后讲大规模SG时，提到EA做的大规模SG，指出和我们工作的不同
% \textbf{EA for Security Games.}
% In game theory, evolutionary algorithms (EAs) are well studied for solving sequential games and simultaneous games because of the population's ability to represent the game player~\cite{RNESGA,EASG}. In sequential games, EASG~\cite{EASG} provides a time-efficient EA-based algorithm, a large game-independent approach, applying to a wide range of SGs with slight alterations. A class of fitness assignment methods~\cite{Calvete08,Hejazi02} additionally considers followers' best response. Another group of methods, the bi-level nested GA~\cite{bi-level-Nested-GA}, utilizes populations to simulate players separately by nesting the follower's GA into the leader's GA. In simultaneous games, all players make decisions simultaneous without the knowledge of others’ decisions. There are two types of approaches, one develops Nash dominance concept~\cite{Nash-dominance-concept} to define the dominance relationships between strategy profiles, and the other adopts multiple populations to simulate each player and calculate fitness depending on direct payoff values like NashGA~\cite{NashGA} or indirect regret information like RNESGA~\cite{RNESGA}.

% 一段已经弃用的related work(又启用了)
% \subsection{Multi-Objective Security Games}
\textbf{Bayesian Stackelberg Games.}
The initial research studies on the Bayesian Stackelberg games primarily investigate the optimal resource allocation yielding the best defender rewards~\cite{MultiLPs, DOBSS, ERASER}. MultiLPs~\cite{MultiLPs} can transform the game tables of different attackers into a large standard game table through Harsanyi transformation to solve the Bayesian Stackelberg game. However, the idea of MultiLPs is to enumerate linear program problems of all possible strategy profiles, its complexity varies exponentially with the attacker dimension. Although the SSE of Bayesian Stackelberg has been proved to be an NP-hard problem~\cite{MultiLPs}, researchers can utilize some characteristics of the problem to design more sophisticated algorithms, e.g., the independence of attackers. DOBSS~\cite{DOBSS}, the first algorithm successfully applied to ARMOR~\cite{ARMOR} system, takes advantage of the independence of attackers to convert several linear program problems into a mixed-integer linear program problem that can be solved by effectively programming-based approaches. In addition, ERASER~\cite{ERASER} directly solves SGs in mixed-integer linear program formulation and makes the target dimension no longer affect the solving efficiency. Although such Bayesian Stackelberg game methods can yield accurate optimal resource allocation, their single-objective optimization modeling limited their performance in SG problems with heterogeneous attackers.
% Although such Bayesian Stackelberg game methods can yield accurate optimal resource allocation, the objective dimension is still their bottleneck, which greatly affects the real-world scaling applications of SGs.

\textbf{Multi-Objective Security Games.}
% This research line shifts from single-objective optimization modeling like Bayesian Stackelberg games to multi-objective optimization modeling like MOSGs.
Compared with Bayesian Stackelberg games, MOSGs can better meet the real-world needs of heterogeneous attackers~\citep{MOSG,extended-MOSG}. The concept of MOSG formulation is systematically proposed in~\citep{MOSG} for the first time by a multi-objective optimization framework combining the $\epsilon$-constraint framework and lexicographic method. Similar to MultiLPs~\citep{MultiLPs}, the idea of~\citep{MOSG} is to enumerate all strategy profiles and call ERASER solver~\citep{ERASER} several times to yield a PF. Although~\citep{MOSG} pre-skips some policy profiles with pruning techniques, the attacker dimension is still a bottleneck. Later, on the basis of~\citep{MOSG}, an extended study~\citep{extended-MOSG} systematically introduces various pruning methods, but it still fails to eradicate the curse of dimensionality brought in attacker dimension by $\epsilon$-constraint framework and lexicographic method. Meanwhile, solution distribution and convergence are two key indicators in multi-objective task solution evaluation, which are coupled by $\epsilon$-constraint methods~\citep{MOSG,extended-MOSG}. To ensure solution uniformity, those methods face the curse of dimensionality in the exponentially growing objective space. To our knowledge, although the performance of the existing algorithm is no longer affected by the target dimension, the attacker dimension is still the bottleneck limiting most traditional methods. In this paper, our work handle large-scale problem in both target and heterogeneous attacker dimensions by decoupling solution distribution and convergence.  

% 第一句：要说明相关方法和自己的区别(他不是多目标设定下)
% 最后一句：要说明不同，
\textbf{Large-Scale Security Games.} Although there are a lot of works focusing on large-scale SGs, most methods cannot deal with the general large-scale MOSGs well. In~\citep{patroller-PSG}, researchers solve specific large-scale security games, but this work cannot be easily applied to the general large-scale problem. N. Basilico et al.~\citep{patroller-PSG} study an extensive-form infinite-horizon underlying game for patrolling security games under specific assumptions about attacker behavior. 
% L. Xiao et al.~\citep{wireless-network} provide a robust security system against collusion attacks for large-scale wireless networks by applying the indirect reciprocity principle. 
In EASG~\citep{EASG}, the researches provides a large-scale game-independent EA-based algorithm, which is tailored to sequential SGs. 
At the same time, programming-based methods like~\citep{ERASER} can deal with large-scale target or resource scenarios, which generally merge the loss of attackers and violate the problem setting of heterogeneous attackers. Besides, most programming-based algorithms cannot solve large-scale problems of multi-dimension simultaneously, e.g., targets and attackers. In addition, a large number of studies have focused on network security games (NSGs)~\citep{NSGZero,NFSP}. 
% NSGs can get more information than normal SGs, e.g., the attacker's path. That means NSGs can represent SGs with graphs, which can be modeled by deep-learning methods. For example, 
NSGZero~\citep{NSGZero} and NFSP~\citep{NFSP} solve the large-scale extensive-form NSGs and large-scale resources NSGs by deep-learning methods respectively. However, some real-world problems cannot be modeled as NSGs. For example, RAND~\citep{Scale-up-Approximation-ARA-RAND} proposes a unified model of large-scale SGs to solve the deployed federal air marshals and threat screening problem. This paper handles large-scale MOSGs by space discretization, which transforms solution representation from the high-dimensional continuous space to the low-dimensional discrete one. The proposed SDES is the first linear sample complexity EA-based framework for MOSGs if either the number of targets or attackers is fixed, which simultaneously extends targets and attackers to the large-scale scenario.

% 一段已经弃用的related work
% In addition, research studies related to MOSGs include: the bounded rational models~\citep{end2end,reg-block-GF}, adversary behavior learning models~\citep{end2end,NSGZero,deception}, and multi-defender security games~\citep{Multi-defender18,Multi-defender21}. 

% % itemize
% \begin{itemize}
% 	\itemsep 0pt
% 	\item  [i)] Bounded Rational Models: Existing MOSG methods usually assume that the attackers are fully rational~\citep{ERASER}, which is common in political games and career planning~\citep{politics-and-career}and career. However, in other security game scenarios such as green security games, bounded rationality is an important way to model the uncertainty in historical data~\citep{end2end}.

% 	\item  [ii)] Adversary Behavior Models: Existing MOSG methods usually adopted optimistic assumptions about the attacker's tie-breaking behavior. Some works still assume that they know attacker preference but are devoted to the pessimistic behavior~\citep{Multi-defender18}. Another works like the adversary learning behavior models attempt to learn preferences from historical attack data. However, such methods still perform poorly in specific scenarios with unbalanced historical data, huge networks, and rich resources~\citep{end2end, NSGZero}. At the same time, these methods often lead to false preferences that are biased from historical data due to deception by informed attackers~\citep{deception}. 

% 	\item  [iii)] Multi-defender Security Games: Unlike MOSGs, which analyze heterogeneous attackers independently at the modeling level, multi-defender security games analyze heterogeneous defenders independently.

% \end{itemize}
% With only slight modifications, our proposed MOSGs game framework can be extended to these three research directions: For the multi-defender scenario, we can recalculate the payoff of all defenders and attackers by referring to the coalition formation proposed by~\citep{Multi-defender21}; For the adversary behavior unknown scenario, although the assumption that the payoff of attackers is known is failed, it does not affect our MOSGs solving framework. For the bounded rational scenario, the solver ERASER~\citep{ERASER} used in this paper assumes that attackers are fully rational, so we only need to replace other solvers that support bounded rational attackers (e.g., the widely used and efficient model SUQR~\citep{SUQR}).

\section{Preliminaries}
\label{sec:pre}
\subsection{Security Game (SG)}
SG, a special kind of \textit{defender-attackers} Stackelberg game, consists of one \textit{defender} $\mathcal{D}$ and $N$ heterogeneous \textit{attackers} $\mathcal{A}_i$, $T$ targets and a resource ratio $r\in[0,1]$, where $i\in[N]$ and $[N]=\{1,\ldots,N\}$ for a positive integer $N$. All notations in this paper is summarized in Appendix~\ref{app:notation}. The continuous strategy of defender $\mathcal{D}$ can be represented as the coverage vector $\bm {c}=(c_1, \ldots, c_T) \in [0, 1]^T$, where $\sum_{t=1}^T {c_t} \leq r \cdot T$ and $c_t$ represents both the resources allocated to the $t$-th target (in the paper we call it target $t$ for simplicity) and the probability of successfully covering target $t$~\citep{Multi-defender21}. 
The strategy of $\mathcal{A}_i$ can be represented as the attack vector 
$\bm {a}_i=(a_{i1}, \ldots, a_{iT}) \in \{0, 1\}^T$, where $\sum_{t=1}^T {a_{it}} = 1$ and $a_{it}=1$ means that $t$ is the \textit{attacked target} of $\mathcal{A}_i$, denoted as $at_i$. 
Since multiple heterogeneous attackers do not interfere with each other and pursue their payoff maximization, the $N$-attacker SG is often transformed into $N$ two-player Stackelberg games. Given the strategy profile $(\bm{c}, \bm{a}_i)$, each player's payoff can be expressed as the payoff structure $\bm{U}=(U_1,\ldots,U_N)$, cf. Equation~\eqref{equ:equation2} and~\eqref{equ:equation2-2}. 

In a two-player Stackelberg game, $U_i$ consists of $\mathcal{A}_i$'s payoff $U_i^a(\bm {c}, \bm {a}_i)$ and $\mathcal{D}$'s payoff $U_i^d(\bm {c}, \bm {a}_i)$. 
% Since the expression about $\mathcal{A}_i$ and $\mathcal{D}$ are symmetric, their expressions can be expressed uniformly, e.g., $U_i^{a}(\bm {c}, \bm {a}_i)$ and  $U_i^{d}(\bm {c}, \bm {a}_i)$ are represented as  $U_i^{a/d}(\bm {c}, \bm {a}_i)$. 
If the attacked target $at_i$ is fully covered (i.e., $c_t=1$), $\mathcal{A}_i$'s or $\mathcal{D}$'s payoff is denoted as $U_i^{c,a}(t)$ or $U_i^{c,d}(t)$. If $at_i$ is completely uncovered (i.e., $c_t=0$), $\mathcal{A}_i$'s or $\mathcal{D}$'s payoff is denoted as $U_i^{u,a}(t)$ or $U_i^{u,d}(t)$. Since $c_t$ is the cover probability, $\mathcal{A}_i$'s or $\mathcal{D}$'s payoff on $t$ is
% for protecting one target $t$ can be expressed as $U_i^{a/d}(c_t)$

% equation1
\begin{equation} 
\label{equ:equation1}
U_i^{a}(c_t)=c_t U_i^{c,a}(t) + (1-c_t) U_i^{u,a}(t)\,,
\end{equation}
\begin{equation} 
\label{equ:equation1-2}
U_i^{d}(c_t)=c_t U_i^{c,d}(t) + (1-c_t) U_i^{u,d}(t)\,.
\end{equation}
Equation~\eqref{equ:equation1} and \eqref{equ:equation1-2} show $U_i^{a}(c_t)\propto {c_t}$, $U_i^{d}(c_t)\propto {\frac {1}{c_t}}$, since all $U_i^c$ and $U_i^u$ follow the assumption $U_i^{c,a} \leq U_i^{u,a}$, $U_i^{c,d} \geq U_i^{u,d}$. This means that $\mathcal{A}_i$ does not want $at_i$ to be covered, while the defender does the opposite. Finally, given the strategy profile $( \bm {c}, \bm {a}_i )$, $\mathcal{A}_i$'s or $\mathcal{D}$'s payoff for $T$ targets is
% can be expressed as $U_i^{a/d}(\bm {c}, \bm {a}_i)$

%equation2
\begin{equation} \label{equ:equation2}
U_i^{a}(\bm {c}, \bm {a}_i) = \sum_{t=1}^T {a_{it} U_i^{a}(c_t)}\,,
\end{equation}
\begin{equation} \label{equ:equation2-2}
U_i^{d}(\bm {c}, \bm {a}_i) = \sum_{t=1}^T {a_{it} U_i^{d}(c_t)}\,.
\end{equation}

% 篇幅原因省略
% In SSE, $\mathcal{A}$ chooses strategies that favor $\mathcal{D}$ to break the tie, which means $\mathcal{D}$ can make \textit{best response} to $\mathcal{A}$’s tie-breaking behaviors. 
% 这里尝试对fully rational SGs做现实意义解释，不知道用那个解释：1、理性的攻击者只关心能否给自己带来收益最大胡；2、防御者能够通过掩饰资源部署策略子啊一定范围内诱导攻击者。
% The SSE hypothesis is also reasonable in the real world because the fully rational $\mathcal{A}$s who just want to maximize their rewards are easily induced by the deception of $\mathcal{D}$~\citep{deception}.

In fully rational SGs, given $\bm{c}$, the \textit{best response} of $\mathcal{A}_i$ and $\mathcal{D}$ are defined as the strategy set that maximizes their utilities. Specifically, the best response of $\mathcal{A}_i$, ${BR}^a_i(\bm {c})$, selects the most attractive targets from $T$ targets, while the best response of $\mathcal{D}$, ${BR}^d(\bm {c})$, picks the optimistic target from ${BR}^a_i(\bm {c})$.

% equationBRa
\begin{equation}
\label{equ:equationBRa}
% {BR}_i^a(\bm {c})=\left\{t\mid\mathop{\arg\max}_{t\in T}U^a_i(c_t)\right\}\,,
{BR}_i^a(\bm {c})=\left\{t\mid U^a_i(c_t)\geq U^a_i(c_{t'})\forall t'\in [T]\right\}\,,
\end{equation}
\begin{equation}
\label{equ:equationBRd}
% {BR}^d_i(\bm {c})={BR}^d_i({BR}_i^a(\bm {c}))=\left\{t\mid\mathop{\arg\max}_{t\in {BR}_i^a(\bm {c})}U^d_i(c_t)\right\}\,,
{BR}^d_i(\bm {c})=\left\{t\mid U^d_i(c_t)\geq U^d_i(c_{t'})\forall t'\in BR_i^a(\bm{c})\right\}\,.
\end{equation}
% 不知道隐变量的解释是否合适
% Equation~\eqref{equ:equationBRa} and~\eqref{equ:equationBRd} show that ${BR}^a_i, {BR}^d_i$ is affected by $c_t$. However, ${BR}^d_i$ is actually influenced by the implicit variable ${BR}^a_i$, and the $\max$ function is non-differentiable. 
%As Section~\ref{sec:property} the properties of the attacker set $\Gamma$ is discussed more, we find that it is difficult to optimize $U^d_i$ directly in solution space $C$.

Equation~\eqref{equ:equation1}-\eqref{equ:equation2-2} describe the relation between the strategy and the payoff for $\mathcal{A}_i$ and $\mathcal{D}$. Equation~\eqref{equ:equationBRa} and~\eqref{equ:equationBRd} describe the best response of $\mathcal{A}_i$ and $\mathcal{D}$ against each other. Under fully rational assumption, the full SG process is

\begin{enumerate}
    \item [(1)] $\mathcal{D}$ allocates coverage vector $\bm{c}$ on $T$ targets.
    \item[(2)] $\mathcal{A}_i$ attacks $t\in BR^a_i(\bm{c})$ that returning $\max_{t\in[T]} U_i^a(c_t)$. The target set $BR^a_i(\bm{c})$ is also called $\Gamma_i$.
    \item [(3)] $\mathcal{A}_i$'s payoff is $\max_{t\in[T]}U_i^a(c_t)$.
    \item [(4)] After $\mathcal{A}_i$ takes the best response, $\mathcal{D}$ selects $t\in BR_i^d(\bm{c})$ from $\Gamma_i$ to get $\max_{t\in[T]}U^d_i(c_t)$, where $\mathcal{A}_i$'s selected target is called attacked target $at_i$.
    \item [(5)] $\mathcal{D}$'s payoff is $\max_{t\in[T]}U_i^d(c_t)$.
\end{enumerate}

\subsection{Multi-Objective Security Games (MOSGs)}
\label{sec:Problem_Definition}
In MOSGs, $\mathcal{D}$ wants to defend the targets against multiple heterogeneous attackers with limited resources. The large-scale definition of MOSGs for the attacker dimension is roughly as follows: the lower bound is generally $4$, while the upper bound is not clear. Apart from special occasions, researchers are more concerned about the range of $10\sim 15$~\citep{NSGA-III}. The large-scale MOSGs become many-objective optimizations (MaOPs).

% （用括号表达或）的表述是否正确
Under the fully rational attacker behavior assumption, $\bm {a}_i$ is deterministic, thus the player's payoff $U_i^{a}(\bm {c}, \bm {a}_i)$ or $U_i^{d}(\bm {c}, \bm {a}_i)$ can be reformulated as $U_i^{a}(\bm {c})$ or $U_i^{d}(\bm {c})$. The objective function of MOSGs can be expressed as

% equationOptFunc
\begin{equation}
\label{equ:equationOptFunc}
\max_{\bm{c}\in C}\bm {F}(\bm {c})=\left\{ U_1^{d}(\bm {c}),\ldots,U_N^{d}(\bm {c}) \right\}\,,
\end{equation}
where $\bm {c}\in\mathbb{R}^T$ belongs to the high-dimensional continuous solution space $C$, and the objective function $\bm {F}: \mathbb {R}^T\rightarrow \mathbb {R}^N$.

MaOPs can obtain multiple solutions, which are particularly concerning
% , and the definition of the Pareto dominance relation is widely used in solution comparison. . 
dominance relation and Pareto optimality, cf. Definition~\ref{def:Pareto}.

\begin{definition}[Dominance Relation and Pareto optimality]\label{def:Pareto}
% \definition[Pareto optimality and Pareto solutions]\label{def:Pareto} 
% {
$\bm{c}$ \textbf{dominates} $\bm{c}'$ if $U_i^d(\bm{c})\leq U_i^d(\bm{c}')$, $\forall i\in[N]$ and $U_j^d(\bm{c})<U_j^d(\bm{c}')$, $\exists j\in[N]$, denoted as $\bm{c}\succeq \bm{c}'$.
The \textit{coverage vector} $\bm{c}$ is $Pareto\ solution$ if there is no other $\bm{c}'\in C$ satisfying $\bm{c}\succeq \bm{c}'$. The set of non-dominant $coverage\ vectors$ is called \textbf{Pareto set}.
% and the image of the corresponding payoff vector set in objective space is called \textbf{Pareto front}.
% }
\end{definition}

% In fully rational assumption, the difficulty of solving MOSGs is to find best response set $C_{PF}$ with well-spaced distribution and convergence rather than single non-dominated $\bm{c}$. In Stackelberg games, \citep{pure-strategy} has proved that each attacker has at least one pure strategy $\bm {a}$. In the full SG process, $\mathcal{A}_i$ selects $at_i\in {BR}_i^a(\bm {c})$, while $\mathcal{D}$ adjust  ${RB}_i^d(\bm {c})$ and try to cover $at_i$. Therefore, $\mathcal{D}$ can predict all $\bm {at}$ because of the fully rational assumption, and there is no need to design a probability distribution over $\bm {c}$ to deal with irrational attackers whose goals are not firm. \textcolor[rgb]{0.5,0.6,0.7}{This paper introduces a large-scale MOSG-solving framework for quickly finding $C_{PF}$ with well-spaced distribution and convergence.}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\columnwidth]{figures/framework_1.pdf}
\caption{The framework of SDES. SDES consists of discretization, optimization, restoration, evaluation and refinement components. SDES evaluates solutions in the high-dimensional continuous space $\bm{X}$ and optimizes solutions in the low-dimensional discrete space $\bm{X}'$. The objective space of $\bm{X}$ and $\bm{X'}$ is the same, i.e, $\bm{Y}$. $\bm{y}'$ is the fitness of low-dimensional solution $\bm{x}'$, while $\bm{y}$ is the fitness of the corresponding high-dimensional solution $\bm{x}$, and $\bm{y}'$ equals $\bm{y}$. If the stop criterion is met, the refinement component refines high-dimensional solutions and returns an approximate PF.}
\label{fig:framework}
\end{figure}

\section{The Proposed Method}
\label{sec:met}
The proposed SDES framework consists of discretization, optimization, restoration, evaluation, and refinement components, as depicted in Figure~\ref{fig:framework}. Traditional methods for MOSGs mainly focus on high-dimensional continuous solution space $\bm{c}$. However, the discretization component shows that searching on low-dimensional discrete solution space \textit{attack set} $\Gamma(\bm{c})$ (defined below) is better.
Therefore, SDES does optimization on $\Gamma(\bm{c})$ space, and does evaluation on $\bm{c}$ space by the restoration component. Finally, the refinement component attempts to improve solutions with acceptable cost, since MSOGs may not meet the convergence assumption.
% In the second stage, we adjust the refinement algorithm  to suit EAs.
% equation4
% \begin{equation}
% \label{equ:equation4}
% \Gamma_i(\bm {c})={BR}_i^a(\bm {c})=\left\{t\mid\mathop{\arg\max}_{t\in T}U^a_i(c_t)\right\}\,,
% \end{equation}


$\Gamma_i(\bm{c})$ is defined as the set of targets that can provide the maximum expected payoffs for $\mathcal{A}_i$,
% In heterogeneous attackers setting, different $\mathcal{A}_i$ corresponds to different $\Gamma_i(\bm{c})$, 
where $\Gamma_i={BR}_i^a(\bm {c})$, cf. Equation~\eqref{equ:equationBRa}. $\Gamma_i(\bm{c})$ is hereinafter abbreviated as $\Gamma_i$. All targets in $\Gamma_i$ have the same attraction to $\mathcal{A}_i$, while the attraction of targets outside $\Gamma_i$ is 0. The realistic meaning of $\Gamma_i$ is narrowing the solution space and guaranteeing the optimal solution, cf. Theorem~\ref{obs:observation1}.

% 先说结论，然后引Lemma \GammaS(
% 第二个融到第一个，在former提我们要做离散化
\subsection{Discretization}
\label{sec:dis}
\subsubsection{Why Discretization}
\label{sec:property}
 In the fully rational SGs, since $U^d_i$ is a function of $\bm {c}$ in Equation~\eqref{equ:equation1}, many programming-based methods optimize the problem on resource allocation $\bm {c}$ directly. 
 However, general heuristic algorithms cannot solve MOSG problem well by searching $\bm{c}$ directly, as disclosed in Lemma~\ref{pro:property1.2} and~\ref{pro:property1.1}. 
 This section reveals two properties of $\Gamma$, i.e., the vulnerability of $\Gamma$ and the determinism of optimal expansion of $\Gamma$. The former shows that it is very difficult for the general heuristic or gradient-based optimization algorithms to search high-dimensional $\bm {c}$ directly, resulting in discretization. The latter provides the way of discretization and the theoretical support for searching in low-dimensional discrete space $\Gamma$.

\textbf{Vulnerability of $\Gamma$.}
% \subsubsection{Vulnerability of $\Gamma$}
\label{sec:property1}
This section shows that general heuristic and gradient optimization algorithms cannot search $\bm {c}$ directly in high-dimensional continuous solution space, because there are lots of step areas and flat areas in the optimization space of $\bm {c}$. The following illustrates the vulnerability of $\Gamma$ from the perspectives of security game as Lemma~\ref{pro:property1.2} and optimization as Lemma~\ref{pro:property1.1}. The proof details are shown in Appendix~\ref{app:proof:method}.

\begin{restatable}[Vulnerability of $\Gamma$ from Security Game Perspective]{lemma}{lemmaSGperspective}\label{pro:property1.2}
% \begin{property}[Vulnerability of $\Gamma$ - from the security game perspective]\label{pro:property1.2}
% \property[Vulnerability of $\Gamma$ - from the security game perspective]\label{pro:property1.2}
% {
Given $\Gamma(\bm {c})$, $\Gamma(\bm {c}+\bm{v})$, where $\bm{c},\bm{v}\in\mathbb{R}^T$ and $\bm{v}$ is a zero vector except the $t'$-th component $v_{t'}$, and $v_{t'}$ is a small perturbation, one has that
\begin{equation}
\begin{cases}
{\Gamma(\bm{c}+\bm{v})=\Gamma(\bm{c}),}&{\text{if}}\ {t'\notin \Gamma(\bm{c})},
\\
{\Gamma(\bm {c}+\bm{v})=\Gamma(\bm {c})\setminus \{t'\},}&{\text{if}}\ {t'\in \Gamma(\bm{c})\ \text{and}\ v_{t'}>0},
\\
{\Gamma(\bm {c}+\bm{v})=\{t'\},}&{\text{if}}\ {t'\in \Gamma(\bm{c})\ \text{and}\ v_{t'}<0}.
\end{cases}
\end{equation}
% If $t'\notin \Gamma(\bm{c})$, no matter what $v_{t'}$ is, $\Gamma(\bm{c}+\bm{v})=\Gamma(\bm{c})$. If $t'\in\Gamma(\bm{c})$,  according to the relation between $v_{t'}$ and 0, $\Gamma(\bm {c}+\bm{v})$ has three possible variations: 
% (i) If $v_{t'}>0$, $\Gamma(\bm {c}+\bm{v})=\Gamma(\bm {c})\setminus \{t'\}$. 
% (ii) If $v_{t'}<0$, $\Gamma(\bm {c}+\bm{v})=\{t'\}$. 
% (iii) If $v_{t'}=0$, $\Gamma(\bm{c}+\bm{v})=\Gamma(\bm{c})$.
% }
% \end{property}
\end{restatable}

From a security game perspective, the reason for Lemma~\ref{pro:property1.2} is that allocating resources to $t\notin \Gamma$ does not increase the payoff since $\mathcal{A}$ only attack $t\in\Gamma$. Specifically, the actual $\vert\Gamma_i\vert$ is far less than $T$ due to limited resources. Large-scale target scenarios only provide sparse feedback for optimization algorithms. Furthermore, the change of $\Gamma$ causes a drastic function value jump. Figure~\ref{fig:Ua_Ud} shows the existence of a large number of flat regions and jump regions.

\begin{restatable}[Vulnerability of $\Gamma$ from Optimization Perspective]{lemma}{lemmaoptperspective}\label{pro:property1.1}
% \begin{property}[Vulnerability of $\Gamma$ - from the optimization perspective]\label{pro:property1.1}
% \property[Vulnerability of $\Gamma$ - from the optimization perspective]\label{pro:property1.1}
% 微小量用a minor variation a slight change 是否合适？
% {
For each $\mathcal{A}_i$, given the same $\Gamma(\bm{c})$, $\Gamma(\bm{c}+\bm{v})$ as in Lemma~\ref{pro:property1.2} and the attacked target $at_i$ corresponding to $\Gamma(\bm{c})$, if $at_i\in\Gamma(\bm{c}+\bm{v})$, then $U_i^d(\bm {c})$$=$$U^d_i(\bm{c}+\bm{v})$. Otherwise, $U_i^d(\bm{c}+\bm{v})-U_i^d(\bm{c})\geq gap_i$, where $gap_i=\max_{t\in\Gamma(\bm{c})}U^d_i(c_t) - \max_{t\in\{\Gamma(\bm{c})\setminus\{at\}\}}U^d_i(c_t)$.
% }
% \end{property}
\end{restatable}

From an optimization perspective, as shown in Figure~\ref{fig:Ua_Ud}, $U_i^d(\bm {c})$ does not change smoothly due to jump and flat areas. Meanwhile, $\bm{c}$ may reach thousands of non-differentiable dimensions, making the problem hard to converge.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\columnwidth]{figures/Ud_heatmap_0.5.pdf}
\caption{The heatmap of $\mathcal{D}$'s payoff $U^d_i(\bm{c})$. It is an illustration in the small-scale $N=T=2$ MOSG problem. The axes mean the resources allocated on $t_1$ and $t_2$. The defender payoff optimization is a maximum task, whose goal is to find the darkest area, e.g., $2.2$. 
% There are many flat areas paralleling the x-axis or y-axis, and many jump areas located at the boundaries, e.g., coordination $(0.3, 0.1)$. 
The payoff of the area whose total resources violate the constraint, i.e., $\Vert\bm{c}\Vert_1\leq1$, equals the global minimum, e.g., $-3.0$.}
\label{fig:Ua_Ud}
\end{figure}

\textbf{Determinism of Optimal Expansion of $\Gamma$.}
% \subsubsection{Determinism of Optimal Expansion of $\Gamma$}
% \label{sec:property2}
This Lemma can be derived from fully rational SGs. This kind of game indicates that $\mathcal{A}_i$ chooses the target with $\max({U^a_i})$. Meanwhile, when $\mathcal{A}_i$ has multiple choices, $\mathcal{A}_i$ breaks the tie for $\mathcal{D}$~\citep{SSE}. This kind of game is widely used in political games and career planning scenarios with cautious decision-makers~\citep{politics-and-career}. Lemma~\ref{pro:property2} shows that the optimal changing process of $\Gamma_i(\bm{c})$ can be known in advance.

\begin{restatable}[Determinism of Optimal Expansion of $\Gamma$]{lemma}{lemmaoptimalexpansion}\label{pro:property2}
% \begin{property}[Determinism of Optimal Expansion of $\Gamma$]\label{pro:property2}
% \property[Determinism of Optimal Expansion of $\Gamma$]\label{pro:property2}
% {
For each $\mathcal{A}_i$, 
% the initial size of $\Gamma_i$ equals 1 when $\bm{c}=\bm{0}$.
the optimal expansion rule of $\Gamma_i$ is adding $t$ in the descending order of $U^a_i(c_t)$.
% }
% \end{property}
% \end{lemma}
\end{restatable}

Lemma~\ref{pro:property2} is the core of the exact algorithm ORIGAMI~\citep{ERASER}. The expansion of $\Gamma_i$ refers to the process of adding targets outside $\Gamma_i$ to $\Gamma_i$ without affecting the original $\Gamma_i$. The expansion rules of $\Gamma_i$ describes the \textit{target order} of the adding targets into $\Gamma_i$ from $\vert\Gamma_i\vert=1$ to $\vert\Gamma_i\vert=T$ by allocating more resources. 
% Since the resource is limited, the optimal expansion rule of $\Gamma_i$ refers to the prioritization maximizing $\vert\Gamma_i\vert$. The specific rule is the descending order of $U^a_i(c_t)$.

% 这个property证明描述不来，实际上作图挺好理解的（就是要先覆盖对攻击者吸引力高的target）.
% 目前做法是: 简单说明了Property意味着什么，Property的重要性。
% \begin{proof}
% ...
% \end{proof}

The significance of Lemma~\ref{pro:property2} is to determine the optimal \textit{target order} in advance, which has the following advantages.
It formulates the optimal \textit{target order} expansion problem as \textit{target order}.
The global optimal solution is retained while the solution space is reduced.
The search algorithm no longer needs to care about $\Gamma_i$  anymore, but only $\vert\Gamma_i\vert$, i.e., the algorithm only needs to use the one-dimensional integer to represent $\Gamma_i$.
% , which reduces the difficulty of algorithm optimization.

% 本节最后部分的Lamma1 2和3的总结
% ``Vulnerability of $\Gamma$" (Lemma~\ref{pro:property1.2} and~\ref{pro:property1.1}) and ``Determinism of Optimal Expansion of $\Gamma$" (Lemma~\ref{pro:property2}) show that directly optimizing $U^d_i(\bm {c})$ is difficult, but optimizing $U^d_i(\Gamma_i(\bm {c}))$ may be feasible. The former optimizes $U^d_i$ in continuous space $\bm{C}$, while the latter optimizes $U^d_i$ in discrete space $\Gamma_i, i\in [N]$. Section~\ref{sec:ind_rep} detail how to represent $\Gamma_i(\bm {c})$ in discrete spaces and Section~\ref{sec:ind_eva} details how to search $\Gamma_i(\bm {c}^*)$.

% \subsection{Solution Representation: Algorithm}
\subsubsection{How to Realize Discretization}
\label{sec:ind_rep}
According to Lemma~\ref{pro:property2}, 
$T$-length \textit{continuous} solution representation $\bm{c}$ termed \textbf{$\bm{c}$-code} can be discretized into $N$-length \textit{integral} (\textit{discrete}) solution representation $\bm{I}$ termed \textbf{$\bm{I}$-code}, generally $N\ll T$.

% 这里想表达所有\Gamma最多只有T个可能，能被表达成{{Des}, ..., {t_{(i)}}}，但是这个形式在论文别的地方不会出现第二次
\begin{restatable}{theorem}{theoremdiscretization}\label{obs:observation1}
% \begin{theorem}\label{obs:observation1}
% \begin{observation}\label{obs:observation1}
% \observation\label{obs:observation1}
% {
For each $\mathcal{A}_i$, suppose that $t_{(1)},\cdots,t_{(T)}$ is the order of all targets in descending order of $U^a_i(c_t)$, the optimal $\Gamma$ satisfies $\Gamma\in
\{\{t_{(i)}\}_{i=1}^1,\ldots,\{t_{(i)}\}_{i=1}^T\}$.
% }
% \end{observation}
% \end{theorem}
\end{restatable}

\begin{remark}
    Theorem~\ref{obs:observation1} indicates that $c$-code for defending $\mathcal{A}_i$ can be discretized as one-dimensional $I$-code $I_i=\vert\Gamma_i\vert$. Similarly, in $N$-attacker SG, $c$-code can be discretized as N-dimensional $I$-code. The set of all $\Gamma_i$ is defined as \textit{attack group} $\Gamma_{s}$, where $\Gamma_{s}=\{\Gamma_1,\ldots,\Gamma_N\}$. Figure~\ref{fig:sol_rep} gives an illustration of $\Gamma_{s}$.
\end{remark}

% In two-player scenario, the optimal $\Gamma_i$ for defending $\mathcal{A}_i$ mentioned in Theorem~\ref{obs:observation1} can be encoded as 1-dimension integer $\Gamma_i=\{Des_{t_j},j\in[L_i]\}$. In the $N$ attackers scenario, the set of optimal $\Gamma_i$ (named attack group) can be encoded as $N$-dimensions integer ($I$-code), denoted as $\Gamma_s$

% \begin{equation}
% \label{equ:L-code}
% \Gamma_i=\{Des_{t_j},j\in [L_i]\},i\in[N]\,.
% \end{equation}
% 同时介绍变量I(I-code), 理想解, 可行解, attack set, attack group的概念, 即solution representation的所有概念(Caption of Figure2也说明了)
% To induce $\Gamma_s$, $N$ solutions are needed. Usually, $\Gamma_s$ is unreachable because only one fixed solution, named the feasible solution $\tilde{\bm{c}}$, can be selected in real SGs.
% From Equation~\eqref{equ:att_gro}, $N$ strategies $\bm{c}^i$ is needed for $N$ optimal $\Gamma_i$. However, only one fixed strategy ,named feasible solution $\tilde{\bm{c}}$, can be selected in real SGs. 
% Therefore, $\{\bm{\hat{c}}^{1},\ldots,\bm{\hat{c}}^{N}\}$ is named the ideal solution. 
Observe that all $\Gamma_i\in\Gamma_s$ may not be reached simultaneously, because different $\Gamma_i$ is derived from different strategy $\hat{\bm{c}}^i$ but only a fixed strategy is available. The unreachable $\{\bm{\hat{c}}^{1},\ldots,\bm{\hat{c}}^{N}\}$ is denoted as ideal solution, and the fixed strategy $\tilde{\bm{c}}$ is denoted as feasible solution.
The attacked target, attack set and attack group corresponding to ideal solution are denoted as $\hat{\bm{at}}$, $\hat{\Gamma}_i$ and $\hat{\Gamma}_s$, respectively. Those variables corresponding to feasible solution are denoted as $\tilde{\bm{at}}$, $\tilde{\Gamma}_i$ and $\tilde{\Gamma}_s$.

\begin{figure}[!t]
\centering
\includegraphics[width=0.6\columnwidth]{figures/SolutionRepresentation_1.pdf}
\caption{The solution representation about $I$-code. It is an illustration introducing \textit{attacker set} $\Gamma$, and \textit{attacker group} $\Gamma_s$ in the $N=2, T=4$ MOSG problem. 
$I_i$ means the size of $\Gamma_i$, also denoted as $\vert\Gamma_i\vert$. 
$I_i$ uniquely determines $\Gamma_i$, that is, $\Gamma_i$ consists of the first $I_i$ targets in the decreasing order of $\bm{U}^a_i(\hat{\bm{c}}^i)$.
% The solution representation, $I$-code, is $\bm{I}=(1,1,1,2)$ in this illustration. 
All $\Gamma_i$ make up $\Gamma_s$, so $\bm{I}=(1, 2)$ indicates $\Gamma_s=\{\{t_4\}$, $\{t_1, t_4\}\}$. Since $\mathcal{A}$ only attacks one target, $\bm{I}$ can induce 2 possible $\bm{at}$, i.e., $(t_4, t_1)$ or $(t_4, t_4)$. 
% In addition, observe that all $\Gamma_i\in\Gamma_s$ may not be reached simultaneously, because different $\Gamma_i$ is derived from different strategy $\hat{\bm{c}}^i$ but only fixed strategy is available. In this paper, the unreachable $\{\bm{\hat{c}}^{1},\ldots,\bm{\hat{c}}^{N}\}$ is denoted as ideal solution, the fixed strategy $\tilde{\bm{c}}$ is denoted as feasible solution.
} 
\label{fig:sol_rep}
\end{figure}

% 第一句说明优化组件的目标
% 第二句说明之前的离散化组件的变化。在Dis后，原来高维连续空间映射到低维离散空间，每个低维解对于数个高维解c tilde。
% 第三句说明优化组件实现目标的手段（）。提分治然后说我们在每个空间中找一个最优的，组成C*。很显然，如果空间划分是均匀的，那么最终结果是均匀的。
% 第二段说明优化组件的具体实现方式。为实现解集的均匀性，我们推荐配合使用多目标演化算法NSGA-III和基于能量的自适应参考向量生成器R。NSGA-III是应用广泛并且稳定的EAs，而R能为EAs提供一组自定义的均匀参考向量。
\subsection{Optimization}
% method 部分就需要点NSGA-III，告诉大家想实现这个框架可以怎么选择算法（stable）
\label{sec:opt}
The goal of MOSGs, cf. Equation~\eqref{equ:equationOptFunc}, is to find a solution set $C^*\subseteq C$ that corresponds to a well-spaced PF. 
% The well-spaced PF is achieved by maintaining a set of well-spaced solutions in the objective space during the optimization process of many-objective EAs.
% After discretization, the whole high-dimensional solution space $C$ is divided into several subspaces $\Theta$s by $I$-code. Each $\Theta$ consists of several $\tilde{\bm{c}}$. 
After discretization, solutions are mapped from the high-dimensional continuous space to the low-dimensional discrete space. It is natural that a feasible discrete solution corresponds to a set of feasible continuous solutions $\tilde{\bm{c}}$, termed $\tilde{C}$.
To find a well-spaced PF, we can utilize a many-objective optimization algorithm if it maintains a set of widely-distributed populations, and then we can select the optimal solutions from these populations to form a well-spaced PF.
% To find a well-spaced PF, the optimization component maintains several well-spaced $\tilde{C}$s and selects an optimal solution $\bm{c}^*_i$ from each $\tilde{C}_i$. 
This process is formulated as the transformation from Equation~\eqref{equ:equationOptFunc} to~\eqref{equ:equationBi-OptFunc}.
% To maintain several well-spaced $\tilde{C}$s
%双层优化
\begin{equation}
\label{equ:equationBi-OptFunc}
\begin{aligned}
& \max_{\bm {c}\in C^*}\bm {F}(\bm {c})=\max_{\bm {c}\in C^*}\left\{ U_1^{d}(\bm {c}),\ldots,U_N^{d}(\bm {c}) \right\} \,,\\
& s.t.\ C^*\!=\left\{\bm{c}^*_i\mid\bm{c}^*_i\succeq \bm{c}'_i, \bm{c}^*_i\in\tilde{C}_i, \bm{c}'_i\in\tilde{C}_i\setminus\{\bm{c}^*_i\}, i\in [\vert\tilde{C}\vert]\right\}\,.
% & s.t.\ C^*\!=\left\{\hat{\bm{c}}\mid\hat{c}_i =\mathop{\arg\max}_{\tilde{\bm{c}}\in\tilde{C}_i}\bm{F}(\tilde{\bm{c}}), i\in[\vert\tilde{C}\vert]\right\}\,.
\end{aligned}
\end{equation}
% The intuition of Equation~\eqref{equ:equationBi-OptFunc} is that the inner-layer task divides $C$ into several $\Theta$ and finds $C^*$ by searching a non-dominant solution from each subspace $\Theta$, and the outer-layer task finds the Pareto set from $C^*$. In general, the divide and conquer reduces the search space of MOSG.
% In Equation~\eqref{equ:equationBi-OptFunc}, $\tilde{\bm{c}}$ represents feasible solutions in $\tilde{C}$ and $\hat{\bm{c}}$ represents optimal solution in $\tilde{C}$. 
Equation~\eqref{equ:equationBi-OptFunc} focuses on the diversity and distribution of solutions. The convergence of found $\bm{c}^*_i$ is detailed in Section\ref{sec:rat_sim}.
% Equation~\eqref{equ:equationBi-OptFunc} suggests picking $\bm{c}^{*}\in\Theta$ to represent $\Theta$. 
% To achieve the same effect, our paper proposes to find a $\tilde{\bm{c}}$ that is most similar to $\hat{\bm{c}}$.
% % $\tilde{\bm{c}}$ is described in Figure~\ref{fig:sol_rep}) and 
% The solution divergence is described below. Meanwhile, the theoretical support is provided in Section~\ref{sec:rat_sim}: (i) The payoff of $\hat{\bm{c}}$ is the upper bound to all $\tilde{\bm{c}}\in\Theta$. (ii) The closer the similarity of $\tilde{\bm{c}}$ is to $\hat{\bm{c}}$, the closer the benefit of $\tilde{\bm{c}}$ is to $\hat{\bm{c}}$ (the upper bound).

% In this section, EA aims to search PF with well-spaced distribution. 

% To find a well-spaced solution set,
For the implementation of optimization component, we use a stable many-objective evolutionary algorithm NSGA-III~\citep{NSGA-III} and an energy-based adaptive reference direction set generator Riesz~\citep{ref-dirs-energy}. We should point out that NSGA-III and Riesz are not the only options.
% the implementation of optimization component is not fixed.
% NSGA-III is a widely used and stable EAs, and Riesz can provide a customized well-spaced reference direction set. 
Specifically, all solution set $\tilde{C}$ is divided by Riesz with given population size. For NSGA-III, $\vert\tilde{C}\vert$ is defined as the population size. NSGA-III maintains diversity among the population by adaptively updating well-spaced reference directions from Riesz. 
NSGA-III defines a set of problem-independent reference vectors in advance, which are uniformly distributed in the objective space and invariant throughout the evolution process. In each iteration of optimization, the many-objective evolutionary algorithm assigns at least one solution to each reference vector to maintain a set of well-spaced solutions.
Finally, NASG-III returns one non-dominant solution $c_i^*$ from each $\tilde{C}_i$. More details is shown in Appendix~\ref{app:NSGA-III}.
% to represent $\Theta$ (i.e., $\bm{Fitness}(\Theta)= ( U^d_i(\bm {c}^*), i\in[N])$). 
% Finally, if all $\Theta$s are well-spaced, then all non-dominant solutions from each $\Theta$ are well-spaced.

% \textbf{Problem Transformation.}
% \subsubsection{Problem Transformation}
% \label{sec:pro_tra}
% G函数即闭式解， indifferent function
% The goal of $\Theta$ is to find the best $\tilde{\bm{c}}$, *. Finally, $\bm{c}^*$ from all $\Theta$ make up $C^*$.



\subsection{Restoration and Evaluation}
\label{sec:eva}
\subsubsection{Why Restoration}
% 这里面要讲清楚Restoration是为了更好的评估
In each iteration of the optimization component in SDES, the low-dimensional parent population gets the low-dimensional offspring population with unknown fitness through general many-objective EA operators. 
Although low-dimensional solution representation of $I$-code is convenient, the solution evaluation faces the combinatorial explosion, which needs to restore $I$-code to $c$-code. 
% $I$-code stands for $O(N^T)$ possible $c$-code solutions. 
An illustration is shown in Figure~\ref{fig:L-code}. To bypass combinatorial explosion and evaluate low-dimensional solutions, we first count the alternative set of each component, and then bit-wisely optimize each component.


% \subsection{Solution Evaluation: Algorithm}
\subsubsection{How to Realize Restoration and Evaluation}
\label{sec:ind_eva}
% Figure~\ref{fig:L-code} mainly talking about how to get $\bm{c}^*$ and return $\bm {U}^d(\bm{c}^*)$. 
Figure~\ref{fig:L-code} illustrates the process of $I$-code evaluation.
This process includes the following steps: the step 1 is counting alternative set; the step 2.1 definites the divergence between solutions for bit-wise optimization, and the step 2.2 is finding optimal $c$-code by bit-wise optimization and evaluating optimal $c$-code.
% (i) from $I$-code to $c$-code, and (ii) from $c$-code to $\bm{c}^*$ and evaluate $\bm{c}^*$.
% '总'的一种详细表达
% The main work of this section is: first decoding the integer $I$-code solution to float $c$-code solution, then decoding $c$ strategy solution to $\bm{c}^*$ and returning $\bm {U}^d(\bm{c}^*)$.

% Figure (The $I$-code2$\bm{c}$-code framework.) %编码变换的过程
\begin{figure}[!t]
\centering
\includegraphics[width=0.7\textwidth]{figures/SolutionEvaluation_1.pdf}
\caption{The solution evaluation. It is an illustration of in the $N=2, T=4$ MOSG problem. The evaluation process includes 2 steps. In the step 1, $I_i$ is decoded to $\hat{\Gamma}_i$, 
% (the $i$-th row of a binary matrix $\bm{\gamma}$)
then $\hat{\Gamma}_i$ is decoded to $\hat{\bm{c}}^i$, and then all $\hat{\bm{c}}^i$ are transformed into $\tilde{\bm{c}}\in\tilde{C}$.
% (the $i$-th row of a continuous matrix $\bm{\pi}$)
% All non-zero and non-repeat $\bm{\pi}$ components in the same color column are selected as one block in \ding{175} . 
The \ding{172}$\sim$\ding{175} process is formally described as Equation~(\ref{equ:c_gamma}). In the step 2, the size of search space of $\bm{c}^*$ $\vert\tilde{C}\vert$ is $O(N^T)$, i.e., combinatorial optimization.
% , which equals to the cumulative multiplication of 4 blocks in this illustration 
Therefore, the bit-wise optimization is used to find  $\bm{c}^*$. }
\label{fig:L-code}
\end{figure}

% This section mainly talks about decoding $I$-code to $\bm{c}$.
\textbf{Step 1: Counting Alternative Set.}
% \subsubsection{Decoding Step 1 - $I$-code$\to$$\Gamma$$\to$$\bm{c}$}
% \label{sec:dec_step1}
% $I$-code and $c$-code are connected by $\Gamma$, i.e., $I$-code$\to$$\Gamma$$\to$$c$-code. 
The $c$-code has $T$ independent components. $I$-code provides at most $N$ non-zero and non-repeat alternatives for each component. Step 1 counts the alternative set of each component.

% In the left part of Figure~\ref{fig:L-code}, Step 1 is divided into two parts (i) $I$-code$\to$$\Gamma$ and (ii) $\Gamma$$\to$$c$-code. As for $I$-code$\to$$\Gamma$, 
From \ding{172} to \ding{173}, as the meaning of $I$-code component shown in Figure~\ref{fig:sol_rep}, a binary vector $\bm {\gamma}$ is used to represent the relation between target $t$ and $\Gamma_i$. If $t\notin\Gamma_i$, $\gamma_t^i=0$. Otherwise, $\gamma_t^i=1$.
From \ding{173} to \ding{174}, a float vector $\pi^i$ is used to represent the relation between $\Gamma_i$ and resource demands of all targets. If $\gamma_{t}^i=0$, then $\pi_{c_t}^i=0$, because $t\notin\Gamma_i$ is not attractive. Otherwise, $\pi_{c_t}^i\neq0$, and ORIGAMI~\citep{ERASER} provides an indifference equation $\pi_{c_t}^i=\frac{U^a(c_{t'})-U^{u,a}_i(t)}{U^{c,a}_i(t)-U^{u,a}_i(t)}$, where $t'\in\Gamma_i$ and it comes from Equation~\eqref{equ:equation1}.
% Overall, the process $I$-code$\to$$\Gamma$$\to$$c$-code is summarized as
Overall, \ding{172}$\sim$\ding{175} is summarized as

% 注释的部分原本一行两个公式,后续放不下将两个公式合并成一个
% \begin{small}
\begin{equation}
\label{equ:c_gamma}
% {\gamma_t^i}=
% \begin{cases}
% 1,&{\text{if}}\ {t\notin\hat{\Gamma}_i},\\
% {0,}&{\text{otherwise.}}
% \end{cases}
% ,
% \,,
{\pi_{c_t}^i}=
\begin{cases}
\frac{U^a(c_{t'})-U^{u,a}_i(t)}{U^{c,a}_i(t)-U^{u,a}_i(t)},&{\text{if}}\ {\gamma_t^i=1},\\
    {0,}                                        &{\text{otherwise.}}
\end{cases}
% c_t^*\in\{\pi_{c_t}^i,i\in[N]\} \,.
\end{equation}
% \end{small}
% Contribution
% 贡献点看起来不是自己的
Theorem~\ref{obs:observation1} shows that the alternative set $\pi_{c_t}$ must contain $\bm{c}^*_t$. Therefore, Equation~\eqref{equ:c_gamma} guarantees that the single Pareto solution obtained by the restoration component is the exact optimal solution~\citep{ERASER}, which provides a convergence guarantee for the SDES framework.
% overcomes the defect that the general heuristic algorithm lacks theoretical guarantee~\citep{MOSG,extended-MOSG}. 

% 表示pi内一定包含最优的c*t
% $\pi_{c_t}$ is a $N$ size set that must contain the component of $\bm{c}^*$ (i.e., $c_t^*\in\pi_{c_t}$, supported by Theorem~\ref{obs:observation1}). Therefore, the search space of $\bm{c}^*$ (i.e., $\tilde{C}$) is the permutation of $\pi_{c_t}, t\in[T]$. 

% Step 2.1 and 2.2, discuss how to find $\bm{c}^*\in\tilde{C}$ by optimizing solution divergence bit by bit.

\textbf{Step 2.1: Measuring the Solution Divergence for Bit-wise Optimization.}
% \subsubsection{divergence about $\Gamma$}
% \label{sec:sim_mea}
This step mainly introduces the solution divergence measurement for bit-wise optimization. Specifically, Definition~\ref{def:sim_mea} and~\ref{def:dis_mea} measure divergence not by comparing all elements in the set $\Gamma$, but by comparing attacked target ($at$). The intuition is that fitness is only affected by $at$.

For each $\mathcal{A}_i$, given two attack sets $\Gamma^a_i$, $\Gamma^b_i$ different in elements, their semantics may be the same as long as they both contain the same $at_i$. The divergence between $\Gamma_i$ is defined as
% Definition~\ref{def:sim_mea}.

\begin{definition}[Divergence between $\Gamma_i$]\label{def:sim_mea}
% \definition[divergence between $\Gamma_i$]\label{def:sim_mea}
% {
For each $\mathcal{A}_i$, given $\Gamma^a_i$, $\Gamma^b_i$ and their attacked target $at_i^a$ and $at_i^b$, if $at_i^a=at_i^b$, then $\Gamma^a_i$ and $\Gamma^b_i$ are not divergent. Otherwise, $\Gamma^a_i$ and $\Gamma^b_i$ are divergent. The divergence between $\Gamma_i$ and $\Gamma_s$ is defined as a discrete metric, cf. Equation~\eqref{equ:sim_equ}.
% }
\end{definition}

% The core of Definition~\ref{def:sim_mea} is $\Gamma$'s $at$, which is different under different assumptions of attacker behavior. Under the assumption of fully rational attacker, $at=\mathop{\arg\max}_{t\in[T]} U^d(c_t)$. For each $\mathcal{A}_i$, $K(\Gamma^a_i,\Gamma^b_i)$ is defined as the discrete metric:

\begin{equation}  
% divergence equation between Gamma
\label{equ:sim_equ}
{K(\Gamma^a_i,\Gamma^b_i)}=
\begin{cases}
0, & {\text{if}}\ at^a_i = at^b_i,\\
{1,} & {\text{otherwise.}}
\end{cases}
\end{equation}

% Equation~\eqref{equ:sim_equ} shows that $at$ determines the semantic of $\Gamma$.
% In MOSGs, coverage vector $\bm{c}$ affects $N$ $\Gamma$s simultaneously, $\Gamma_s=\{\Gamma_1,\ldots,\Gamma_N\}$. 
% Furthermore, since $\bm{c}$ affects $\Gamma_1,\ldots,\Gamma_N$ simultaneously, the divergence between different $\Gamma_{s}$ is defined as Definition \ref{def:dis_mea}.

\begin{definition}[Divergence between $\Gamma_{s}$]\label{def:dis_mea}
% \definition[divergence between $\Gamma_{s}$]\label{def:dis_mea}
% {
% Each $\Gamma_i$ in  $\Gamma_{s}$ is equally important. 
The divergence of $\Gamma_s^a$ and $\Gamma_s^b$ is the sum of $N$ divergences of $\Gamma_i^a$ and $\Gamma_i^b$, which is defined as $K_s(\Gamma_s^a,\Gamma_s^b)=\sum_{i=1}^NK(\Gamma_i^a,\Gamma_i^b)$.
\end{definition}

% 距离度量的三角不等式公理没系统证明，感觉上满足
Definition~\ref{def:dis_mea} extends the Definition~\ref{def:sim_mea} from SGs to MOSGs. The smaller the value of $K_s(\cdot,\cdot)$, the lower the divergence. In addition, as a metric, Definition~\ref{def:dis_mea} has non-negativity and holds the axioms of symmetry and triangle inequality, but without the identity of indiscernibles axiom. The reason is Definition~\ref{def:sim_mea} and~\ref{def:dis_mea} only focus on $at$, but not all targets in $\Gamma$.

\textbf{Step 2.2: Finding $\bm{c}^*$ by Bit-wise Optimization and Evaluating $\bm{c}^*$.}
% \subsubsection{Decoding Step 2 - Searching $\bm{c}^*$ from $\Theta$}
% \label{sec:dec_step2}
$K_s(\cdot,\cdot)$ in Definition~\ref{def:dis_mea} uses the divergence between ideal solution $\{\bm{\hat{c}}^{1},\ldots,\bm{\hat{c}}^{N}\}$ and feasible solution $\tilde{\bm{c}}$ to measure the fitness of $\tilde{\bm{c}}$. The process of searching $\bm{c}^*$ is
\begin{equation}
\label{equ:inner-layer-OptFunc}
\begin{aligned}
& \bm {c}^* =\mathop{\arg\min}_{\tilde{\bm{c}}\in\tilde{C}}K_s(\tilde{\Gamma}_s, \hat{\Gamma}_s) \,,\\
s.t.\ &\tilde{\Gamma}_s=\Gamma_s(\tilde{\bm{c}})=\{\Gamma_1(\tilde{\bm{c}}),\ldots,\Gamma_N(\tilde{\bm{c}})\}\,,\\
&\hat{\Gamma}_s=\Gamma_s(\hat{\bm{c}})=\{\Gamma_1(\hat{\bm{c}}^1),\ldots,\Gamma_N(\hat{\bm{c}}^N)\}\,,\\
&\tilde{\bm{c}}=( \tilde{c}_1,\ldots,\tilde{c}_T),\ \text{where}\ \tilde{c}_t\in\pi_{c_t}\ \text{and}\ t\in[T] \,.
\end{aligned}
\end{equation}
Note that the traversal of $\tilde{\bm{c}}\in\tilde{C}$ encounters the combinatorial explosion, cf. Figure~\ref{fig:L-code}. 
% E.g., since each component of $\bm{c}$ of length $T$ has $N$ alternatives $\pi_{c_t}^i,i\in[N]$, the search space of $\Theta$ is $O(N^T)$. 
Inspired by Lemma~\ref{pro:property1.2}, our paper proposes to optimize Equation~\eqref{equ:inner-layer-OptFunc} bit by bit to avoid the combinatorial explosion. In Section~\ref{sec:rat_bit}, the convergence assumption of bit-wise optimization is introduced.

Overall, the process of restoration and evaluation components is shown in Algorithm~\ref{alg:pseudo1}.
For Step 1, necessary information, $\bm{\hat{at}}$, $P$ and $S$, is prepared in Line~\ref{code:alg1:7}-\ref{code:alg1:18}. $P$ and $S$ are used for recording the attract relationship. $P$ records all $obj$ attracted by each target ($obj$ and $\mathcal{A}$ have the same meaning). $S$ counts the number of attracted $obj$ for each target. Ideal attacked target calculation (IATC) at Line~\ref{code:alg1:ORIGAMI} uses the maximal indifference property~\citep{ERASER} to calculate $\bm{\hat{at}}$. For Step 2, in Line~\ref{code:alg1:BSM_begin}-\ref{code:alg1:24}, the bit-wise optimization (BitOpt) repeats $T$ times to form the optimal resources vector $\bm {c}^*$. Thirdly, in Line~\ref{code:alg1:fitness}, solution fitness represents the payoff $\bm {U}^d(\bm{c})=( U^d_1(\bm{c}),\ldots,U^d_N(\bm{c}))$. The pseudocode of IATC and BitOpt is shown in Appendix~\ref{app:fra_pseu_BSM}.


\begin{algorithm}[htbp]
\caption{$I$-code Solution Evaluation.}
\label{alg:pseudo1}
\begin{algorithmic}[1]
    \REQUIRE $\bm{I}$, $\bm{A}$, $resource$. \small\textcolor{Green}{\% $I_i$ is the size of attack set $\vert\Gamma_i\vert$. The $i$-th row of $\bm{A}$ is an index vector of the targets in decreasing order of $U_i^{u,a}(c_t)$}
    \ENSURE
    \STATE$\bm{c}\gets$ the zero coverage vector.
    \STATE$\bm {c}^*\gets$ the zero best coverage vector.
    \STATE$\bm{\hat{at}}\gets$ the zero ideal attacked target vector.
    \STATE$P\gets$ the empty attraction set.
    \STATE$\bm{S}\gets$ the zero counter vector.
    \FOR{$0\leq obj < N$}\label{code:alg1:7}
        \STATE$\Gamma_{obj} = \bm{A}_{obj}[:I_{obj}]$.
        \small \textcolor{Green}{\% $[:N]$ selects the top $N$ targets}
        \STATE$\hat{\bm{at}}_{obj}=IATC(U_{obj}^{u,a}, \Gamma_{obj})$, cf. Algorithm~\ref{alg:at_cal} in Appendix.\label{code:alg1:ORIGAMI}
        \FOR{$t \in \Gamma_{obj}$}
            \STATE$\bm{S}_t = \bm{S}_t + 1$.
            $P[t] = P[t]\cup \{obj\}$.
        \ENDFOR\label{code:alg1:12}
        
        % \STATE$\bm{\hat{c}}\gets$ the zero ideal coverage vector;
        % \STATE$x = U^{u,a}_{obj}(\Gamma_{obj}[-1])$ // payoff of the last target in $\Gamma_{obj}$;
    
        % \STATE$\hat{\bm{c}}[\Gamma_{obj}[:-1]] = \frac{x-U_{obj}^{u,a}(\Gamma_{obj}[:-1])}{U_{obj}^{c,a}(\Gamma_{obj}[:-1])-U^{u,a}_{obj}(\Gamma_{obj}[:-1])}$ //\ adjust $\hat{\bm{c}}$ so that all targets' $U^a_{obj}$ equals $x$;
    
        % \STATE Calculate $( U^a_{obj}(\hat{c}_t),t\in\Gamma_{obj})$;
    
        % \STATE$\hat{\bm{at}}_{obj} = \Gamma_{obj}[\mathop{\arg\max}_t ( U^a_{obj}(\hat{c}_t),t\in\Gamma_{obj})]$;
    \ENDFOR\label{code:alg1:18}
    \FOR{$t$, $count_1$ in enumerate($\bm{S}$)}\label{code:alg1:BSM_begin}
        \STATE$\bm{c}^*_t=BitOpt(count_1, P, t, \bm{I} ,\bm{A}, \hat{\bm{at}})$, cf. Algorithm~\ref{alg:pseudo2} in Appendix.

        \IF{$\Vert\bm{c}^*\Vert_1 > resource$}
            \STATE\textbf{return} $infeasible$.
        \ENDIF
    \ENDFOR\label{code:alg1:24}
    \STATE\textbf{return} $\bm{U}^d(\bm{c}^*)$. 
    \small \textcolor{Green}{\% $\mathcal{D}$'s payoff for defending all $\mathcal{A}_i$s}\label{code:alg1:fitness}
    % \color{green}
\end{algorithmic}
\end{algorithm}

% \subsection{Refining EA's Suboptimal Pareto set by MIN-COV}
\subsection{Refinement}
After the iterations of above components, SDES calls the MIN-COV~\citep{MOSG} subroutine once to refine solutions. MIN-COV is a lightweight adjustment part, and all comparison methods mentioned in~\citep{MOSG,extended-MOSG} use MIN-COV. For $\mathcal{A}_i$, MIN-COV tries to find a better solution that yields no decrease in payoff and consumes fewer resources. Specifically, MIN-COV accepts the current optimal resource allocation scheme $\bm{c}$ and the lower bound constraint $\bm{b}$, and attempts to find $\bm{c}'$ where $\Vert\bm{c}'\Vert_1\leq\Vert\bm{c}\Vert_1$ and $U_i^a(\bm{c}')\geq\bm{b}$. Since MIN-COV is designed for the $\epsilon$-constraint framework, it cannot directly be used, because $\bm{b}$ represents the lower bound for incremental updates that do not exist in many-objective EAs. Therefore, the refinement component adopts the following adjustments. $\bm{c}$ represents $\bm{c}^*$ found in solution evaluation, while $\bm{b}$ represents the solution’s fitness corresponding to $\bm{c}$, i.e., $\bm{b}=U_i^a(\bm{c})$. The meaning of MIN-COV for many-objective EAs is to find a new non-dominant solution with fewer resources. Then redistribute the remaining resources to try to find further payoff growth.

% 实验部分写the implementation of SDES
\subsection{SDES Framework and Sample Complexity Analysis}\label{sec:fra_com}


\begin{algorithm}
\caption{The SDES Framework.}
\label{alg:who_fra}
\begin{algorithmic}[1]
    \REQUIRE $T$-length continuous solution initialization.
    % \REQUIRE $\mathcal{P}\gets$ Integer Random Sampling Initialization.
    \ENSURE \quad
    
    % \textbf{The first stage}
    \STATE Discretizing $T$-length high-dimensional continuous solutions into $N$-length low-dimensional discrete solutions, $N\ll T$.
    
    % \STATE$\mathcal{P}\gets$ Integer Random Sampling Population Initialization;
    
    \WHILE{Terminal criteria not satisfy}

        \STATE Optimizing low-dimensional solutions by NSGA-III.
        % \STATE $\mathcal{O}\gets$ Tournament Selection($\mathcal{P}$). \small\textcolor{Green}{\% optimizing in $I$-code}

        \STATE Restoring low-dimensional solutions to high-dimensional solutions by bit-wise optimization.
        % \STATE $\mathcal{O}\gets$ Simulated Binary Crossover($\mathcal{O}$).

        \STATE Evaluating high-dimensional solutions and returning fitness to the optimization component.
        % \STATE $\mathcal{O}\gets$ Integer Polynomial Mutation($\mathcal{O}$).
        
        % \STATE Solution Evaluation($\mathcal{O}$) in $O(NT)$. \small\textcolor{Green}{\% evaluating in $c$-code}

        % \STATE $\mathcal{P}\gets$ Non-dominated-sort($\mathcal{P}\bigcup\mathcal{O}$).

    \ENDWHILE
    
    % \textbf{The second stage}

    \STATE Refining high-dimensional solutions.
    % \STATE$\mathcal{S}\gets$ Refinement($\mathcal{P}$). \small\textcolor{Green}{\% refining in $c$-code}

    \STATE\textbf{return} high-dimensional solutions.
    % \STATE\textbf{return} $\mathcal{S}$.

\end{algorithmic}
\end{algorithm}

From the procedure of Algorithm~\ref{alg:pseudo1}, we can conclude that the sample complexity of SDES is $O(NT)$. If BitOpt algorithm meets Assumption~\ref{asp:BitOpt} for all $T$ iterations, BitOpt algorithm is able to find a solution on the true PF.
The whole SDES framework is shown as Algorithm~\ref{alg:who_fra}.
% $\mathcal{P}$, $\mathcal{O}$ and $\mathcal{S}$ stand for parent, offspring, and the optimal solutions for MOSGs respectively. 
Algorithm~\ref{alg:who_fra} explains why SDES can solve large-scale MOSGs in linear time if either the number of targets or attackers is fixed.
% ORIGAMI-M, a representative MOSG work, evaluates a single solution with $O(NT^3)$ complexity, while the number of solutions $k$ under $\epsilon$-constraint framework varies exponentially with $N$. Although ORIGAMI-A mitigates the exponential change of $k$ by pruning, ORIGAMI-A still evaluates a single solution with $O(NT^3)$ complexity. For SDES, the evaluation complexity of a single solution is $O(NT)$, cf. Algorithm~\ref{alg:pseudo1}. Moreover, the $k$ in EAs can be customized as a constant, while the $k$ in traditional methods varies exponentially with $N$.
Specifically, the methods based on $\epsilon$-constraint framework like ORIGAMI-M find a solution satisfying the bound constraint in $O(NT^3)$, where $O(T^2)$ is used to refine the accelerate the convergence of bound constraint. SDES reduces the sample complexity to $O(NT)$ by the restoration component. 
% In this work, SDES splits this process and only keeps. 
The many-objective EA works because it does not need bound constraint and the discretization component is shown that the discretized solutions can converge to the true PF by restoration component.
Moreover, SDES calls the refinement component in constant times, while traditional methods call it exponential times with respect to the number of attackers~\citep{MOSG, extended-MOSG}.
% To the best of our knowledge, SDES is the first linear-time algorithm for large-scale MOSG problems if either the number of targets or attackers is fixed.

\section{Theoretical Analysis}
\label{sec:val_ana}
\subsection{Optimization Consistency}
\label{sec:rat_sim}
This section proves the consistency of the combinatorial optimization and the proposed bit-wise optimization in the restoration component. It involves (i) Optimizing the similairity of ideal solution $\{\bm{\hat{c}}^{1},\ldots,\bm{\hat{c}}^{N}\}$ and feasible solution $\tilde{\bm{c}}$ can also find the solutions on the true PF of the MOSG problems.
% (i) The ideal solution $\{\bm{\hat{c}}^{1},\ldots,\bm{\hat{c}}^{N}\}$ can dominate all feasible solution $\tilde{\bm{c}}$, and . 
% (ii) In a two-player game, the higher the similarity of $\Gamma$, the closer the payoff of the solutions. 
(ii) The lower the divergence of $\Gamma_s$, the closer payoff of the solutions. The proof detail is shown in Appendix~\ref{app:proof:3}.

% 注释部分为Lemma其他论文的原版,本文作了修改(结论不变) 
\begin{restatable}{lemma}{lemmaTheoAnal}\label{lem:lemma1}
% \begin{lemma}\label{lem:lemma1}
% \lemma\label{lem:lemma1}
% {If $\Gamma(\bm{c})\subseteq\Gamma(\bm{c}')$ and $c_t=c_t',t\in\Gamma(\bm{c})$, then $U^d(\bm{c})\leq U^d(\bm{c}')$.}
% {
If $\Gamma$ is constructed from the optimal expansion rule in Lemma~\ref{pro:property2} and $\Gamma(\bm{c})\subseteq\Gamma(\bm{c}')$, then $U^d(\bm{c})\leq U^d(\bm{c}')$.
% }
% \end{lemma}
\end{restatable}

%  重提L-code和其他变量之间的关系
\begin{restatable}{lemma}{obsalgorithmfir}\label{obs:algorithm1}
% \begin{theorem}\label{obs:algorithm1}
% \begin{observation}\label{obs:algorithm1}
% \observation\label{obs:algorithm1}
% {
% 这一部分不用说明，恒成立。if $\sum\tilde{\bm{c}}\leq\sum\hat{\bm{c}}^i$, then $\Gamma_i(\bm{\tilde{c}})\subseteq\Gamma_i(\bm{\hat{c}}^{i})$,
The ideal solution $\{\bm{\hat{c}}^{1},\ldots,\bm{\hat{c}}^{N}\}$ satisfies $U_i^d(\bm{\tilde{c}})\leq U_i^d(\bm{\hat{c}}^{i}), \forall i\in[N]$ and $(U_i^d(\bm{\hat{c}}^{1}),\ldots,\\U_i^d(\bm{\hat{c}}^{N}))$ cannot be dominated by any solution on the PF. 
% }
% \end{observation}
% \end{theorem}
\end{restatable}

\begin{remark}
    Lemma~\ref{lem:lemma1} shows that $\Gamma$ must not be worse than its subset.  Lemma~\ref{obs:algorithm1} indicates that (i) the ideal solution is an upper bound on $\forall\tilde{\bm{c}}\in\Theta$ and it is non-inferior to the solution on the PF, and (ii) the purpose of ideal solution construction is to replace finding the true PF of the MOSG problem.
\end{remark}

% Because $\Gamma_i(\hat{\bm{c}}^i)$ is the optimal expansion form, $\bm{\tilde{c}}\in\Theta$ gains less than $\hat{\bm{c}}^i$ as long as $\sum\tilde{\bm{c}}\leq\sum\hat{\bm{c}}^i$. In other words, from EA's perspective, Lemma~\ref{obs:algorithm1} means $\forall\tilde{\bm{c}}\in\Theta$ cannot dominate $\hat{\bm{c}}^i$.

% \begin{restatable}{theorem}{obsalgorithmsec}\label{obs:algorithm2}
% \begin{theorem}\label{obs:algorithm2}
% \begin{observation}\label{obs:algorithm2}
% \observation\label{obs:algorithm2}
% {
% From the attack set perspective, the similarity $K(\tilde{\Gamma}_{i}, \hat{\Gamma}_{i})$ is not entirely determined by all elements of $\tilde{\Gamma}_i$, it is essentially determined by their attacked target (i.e., $\tilde{at}_i$ and $\hat{at}_i$). From the attack group perspective, the similarity of $\tilde{\bm{at}}$ and $\hat{\bm{at}}$ affects the similarity $K_s(\tilde{\Gamma}_{s}$, $\hat{\Gamma}_{s})$.
% }
% \end{observation}
% \end{theorem}
% \end{restatable}

% 跟在上个推论(Theorem)后的简单描述,篇幅原因省略,和下面的Theorem一起说
% Theorem~\ref{obs:algorithm2} shows that the size of $\Gamma$ cannot completely determine the superiority of $\Gamma$. 

\begin{restatable}[Optimization Consistency]{theorem}{obsalgorithmthi}\label{obs:algorithm3}
% \begin{theorem}\label{obs:algorithm3}
% \begin{observation}\label{obs:algorithm3}
% \observation\label{obs:algorithm3}
% {
% From the attack set perspective, if $\tilde{\Gamma}_i$ is similar to $\hat{\Gamma}_i$, then $U_i^d(\bm{\tilde{c}})=U_i^d(\bm{\hat{c}}^{i})$. From the attack group perspective, 
If $\tilde{\Gamma}_{s}$ is similar to $\hat{\Gamma}_{s}$, i.e., $K_s(\tilde{\Gamma}_{s},\hat{\Gamma}_{s})=0$, then $U^d(\bm{\tilde{c}})$ is on the PF and $U_i^d(\bm{\tilde{c}})=U_i^d(\bm{\hat{c}}^{i})$, $\forall i\in[N]$. 
% and the $\tilde{\bm{c}}$ corresponding to $\tilde{\Gamma}_s$ is a well-convergent solution.
% }
% \end{observation}
% \end{theorem}
\end{restatable}

% \Gamma_{i}(\bm{\tilde{c}})  \Gamma_{i}(\bm{\hat{c}}^{i})
% 这里说明上文修改Lemma4的原因，lemma来自的文献加入了ct=ct' t\in\Gamma的条件，但是本文不能加这个条件
% 在本文c^feasible和c^ideal满足不了这个条件,
% 所以介绍lemma时把ct=ct'这个条件去掉了
\begin{remark}
    Theorem~\ref{obs:algorithm3} shows that optimizing $K_s(\cdot,\cdot)$ between the ideal solution and feasible solution is consistent to directly optimizing MOSG problems via bit-wise optimization. Meanwhile, Lemma~\ref{lem:lemma1} has been supplemented by Theorem~\ref{obs:algorithm3}.
    % Meanwhile, Theorem~\ref{obs:algorithm3} gives a convergence guarantee for a single solution. 
\end{remark}

% Theorem~\ref{obs:algorithm2} and~\ref{obs:algorithm3} describe the $\tilde{\Gamma}_i\subseteq\hat{\Gamma}_i$ scenario, but $\tilde{\Gamma}_i$ and $\hat{\Gamma}_i$ make the same payoff. In other words, 
% 内容和Theorem4重复
% Meanwhile, in Theorem~\ref{obs:algorithm3}, for attack set, if $\Gamma_i(\bm{\tilde{c}})$ and $\Gamma_i(\bm{\hat{c}}^{i})$ is similar, then $U_i^d(\bm{\tilde{c}})=U_i^d(\bm{\hat{c}}^{i})$. For attack group, if $\Gamma_i(\bm{\tilde{c}})$ is similar to $\Gamma_i(\bm{\hat{c}}^{i})$, $\forall i\in[N]$, then $\tilde{\Gamma}_{s}$ and $\hat{\Gamma}_{s}$ can yield the same payoff ($U^d(\bm{\tilde{c}})=(U^d(\bm{\hat{c}}^{i})$). 

\subsection{Convergence Guarantee of Bit-wise Optimization}
\label{sec:rat_bit}
% \textbf{Rationality of bit-wise optimization}
Bit-wise optimization is a greedy algorithm, and its intuition comes from the following SGs property. $\mathcal{D}$ allocates $c_t, t\in[T]$ independently, as long as $\sum_{t=1}^T{c_t}\leq r\cdot T$.
% the total number of resources does not violate the constraint,
That is, the resource allocation on each target $c_t$ does not affect each other. Therefore, convergence guarantee is induced under Assumption~\ref{asp:BitOpt}.
% Although the bit-wise optimization is greedy, it has the following theoretical guarantees. 
The proof is shown in Appendix~\ref{app:fra_pseu_BSM}.

\begin{restatable}[Split Assumption]{assumption}
{splitassumption}\label{asp:BitOpt}
% \begin{assumption}[Split Assumption]
% \label{asp:BitOpt}
% \begin{observation}\label{obs:val_ana2}
% \observation\label{obs:val_ana2}
% {
In the $t$-th iteration, $\pi_{c_t}^j$ is selected, $t\in\Gamma_i$ for all $i\in[N]$ satisfies $\pi_{c_t}^i\geq\pi_{c_t}^j$.
% 完整的假设
% During the process of BitOpt, suppose $\pi_{c_t}^j$ is selected. For all $\pi_{c_t}^i$ less than $\pi_{c_t}^j$, $\Gamma_i$ of $\mathcal{A}_i$ does not contain $t$, and for all $\pi_{c_t}^i$ greater than $\pi_{c_t}^j$, $\Gamma_i$ of $\mathcal{A}_i$ contains $t$.
% For all $\pi_{c_t}^i$ less than $\pi_{c_t}^j$, $at_i$ of $\mathcal{A}_i$ is not $t$, and for all $\pi_{c_t}^i$ greater than $\pi_{c_t}^j$, $at_i$ of $\mathcal{A}_i$ is $t$. 
\end{restatable}


\begin{restatable}[Convergence Guarantee]{theorem}{theoremRatBitbybit}\label{obs:val_ana1}
% \begin{theorem}\label{obs:val_ana1}
% \begin{observation}\label{obs:val_ana1}
% \observation\label{obs:val_ana1}
% {
Under Assumption~\ref{asp:BitOpt}, the result of bit-wise optimization $\tilde{\bm{c}}$ converges to the PF, i.e., $U_i^d(\bm{\tilde{c}})=U_i^d(\bm{\hat{c}}^{i}),\forall i\in[N]$. 
% Suppose bit-wise optimization found a optimal \textit{converge vector} $\bm {c}^*=(\pi_{c_{t}}^{*},t\in[T])$ and its attack set is $\Gamma(\bm{c}^*)$. From attacker set perspective, if $at_i$ not affected by $\bm{c}^*$, then $at_i\in\Gamma(\bm{c}^*)$, $U^d_i(\bm {c}^*)=U^d_i(\bm{\hat{c}}^i)$, $i\in[N]$. From attack group perspective, if $\Gamma(\bm{c}^*)$ contains all $at_i, i\in[N]$, then $U^d(\bm {c}^*)=(U^d_i(\bm{\hat{c}}^i), i\in[N])$ and $\bm {c}^*$ is a well-convergent solution for MOSG problems.
% }
% \end{observation}
% \end{theorem}
\end{restatable}
\begin{remark}
    Theorem~\ref{obs:val_ana1} gives a solution convergence guarantee for Bit-wise Optimization under Assumption~\ref{asp:BitOpt}, which means that bit-wise optimization select the smallest alternative when there are multiple $\mathcal{A}$ attracted by $t$.
    % Theorem~\ref{obs:val_ana1} describes the conditions for our bit-wise optimization to achieve the upper bound $(U_i^d(\bm{\hat{c}}^i,i\in[N]))$. 
\end{remark}

\section{Experiments}
\label{sec:exp}
\subsection{Experiment Setup}
\label{sec:secCon_eva}
\textbf{Experiment Environment.} The experimental environment is consistent with~\citep{MOSG,extended-MOSG}, including (i) the randomly-generated security games, i.e., $\mathcal{D}$'s and $\mathcal{A}$'s payoff obey the uniform integral distribution of [1, 10], while the defender and attacker payoffs obey the uniform integral distribution of [-10, -1], (ii) the problem scale is divided into three dimensions: the attacker number $N$, the target needed to be protected number $T$, and the resource ratio $r$, satisfying the following constraint: $N\geq3$, $T=[25, 50, 75, 100, 200, 400, 600, 800, 1000]$, $r=0.2$, the resource equals $r\cdot T$, 
where $r$ is generally much less than $1$ due to the limited resources,
and (iii) the maximum cap of the runtime $M$ is set to $30$ minutes (mins) for clock time. The programming language is Python, and the hardware conditions are AMD Ryzen Threadripper 2990WX 32-Core Processor, 3600 CPU MHz.

\textbf{Comparison Algorithms.} All MOSG problems below are represented as minimization tasks. This paper compares 6 algorithms simultaneously, including 4 algorithms based on $\epsilon$-constraint framework and two general many-objective EAs.
The $\epsilon$-constraint algorithms include ORIGAMI-M and ORIGAMI-A~\citep{MOSG}, ORIGAMI-M-BS and DIRECT-MIN-COV~\citep{extended-MOSG}.
All $\epsilon$-constraint algorithms use step $\epsilon=1$. ORIGAMI-A uses the threshold $\alpha=0.001$ for binary search termination. 
The general many-objective EAs include $c$-code EA with continuous solution representation, $I$-code EA with integral solution representation. Furthermore, in the large-scale scenario, even SOTA many-objective EAs cannot converge well due to Lemma~\ref{pro:property1.2} and~\ref{pro:property1.1}. Therefore, we do not consider those algorithms for comparison.

% 如果EA不是重点的话就放到附录？
\textbf{Implementation Details of many-objective EAs in SDES.} Many-objective EAs, the most common one in solving MaOPs, are used as the solution method in this paper. The solution method can also be replaced by other zeroth-order optimization methods. More specifically, we use NSGA-III~\citep{NSGA-III}, the reference set based EA, for the following important reasons. (i) The reference set based method can easily customize the reference direction set, so many-objective EAs can better adapt to different problem scales. (ii) NSGA-III is enough for low-dimensional discrete space optimization after discretization. Therefore, we choose a classical many-objective EA as the solution method. The termination criterion $max\_{}gen$ is fixed to $300$, and the population size $pop\_{}size$ is fixed to $400$, except $N=3$ case, i.e., $max\_{}gen=pop\_{}size=50$, because this problem scale is simple for NSGA-III. The additional sensitivity analysis in Appendix~\ref{app:more_sen_ana} shows that SDES is insensitive to $pop\_{}size$.
The implementation of NSGA-III uses an open-source framework: multi-objective optimization in Python (PyMOO)~\citep{pymoo}. More implementation details about NSGA-III can be found in Appendix~\ref{app:NSGA-III}.
All experiments are repeated 30 times. Observe that NSGA-III uses Riesz~\citep{ref-dirs-energy} instead of the traditional das-Dennis or multi-layer Das-Dennis method~\citep{das-Dennis}. The Das-Dennis-based approach is greatly affected by the increasing number of attackers, while Riesz can generate a customized number of well-spaced reference direction sets by energy-based approaches.

\textbf{Quality Measurement.}
% \label{sec:qua_mea}
For MaOPs, an ideal algorithm can obtain an approximate solution set satisfying that all solutions in the approximate solution set are as convergent as possible and as diverse as possible to the PF~\citep{MOEA-survey}. The quality measurements of convergence and diversity are
% ~\citep{indicator-survey}: 
% (i) All solutions in the approximate solution set are as close as possible to the PF. 
% (ii) All solutions are as diverse as possible in the approximate solution set. 
% (iii) All solutions cover PF as fully as possible.

Hypervolume Metric (\textit{HV}).
% \label{sec:HV}
The hypervolume indicator~\citep{HV}, describes the volume of the space dominated by the Pareto set approximation to the reference point in the objective space and can be expressed as

\begin{equation}
\label{equ:equHV}
    HV(A,\bm{r})=\mathcal{L}\left(\cup_{\bm{a}\in A}\left\{\bm{b}\mid\bm{a}\succeq \bm{b}\succeq \bm{r}\right\}\right)\,,
\end{equation}
where $A$ represents the Pareto set approximation to be evaluated, $\bm{r}$ is a reference point prepared in advance, $\mathcal{L}(\cdot)$ represents the Lebesgue measure of a set $\mathcal{L}(B)=\int_{\bm{b}\in B}\bm{1}_B(\bm{b})\,\mathrm{d}\bm{b}$. $\bm{1}_B$ is the characteristic function of $B$ that $\bm{1}_B(\bm{b})=1$ if $\bm{b}\in B$, otherwise $\bm{1}_B(\bm{b})=0$, and $\bm{a}\succeq\bm{b}$ denotes $\bm{a}$ dominates $\bm{b}$.
% , cf. Definition~\ref{def:Pareto}.

Modified Inverted Generational Distance (IGD$^+$).
% \label{sec:IGD+}
\textit{IGD}$^+$~\citep{IGD+} is the improved version of
$IGD$.
% (A)=\frac{1}{\vert Z\vert}\left(\sum^{\vert Z\vert}_{i=1}\hat{d_i}^p\right)^{1/p}$.
$IGD$ measures the Euclidean distance from the reference point set $Z$ to the Pareto set approximation $A$. 
% In detail, $IGD$ assigns the nearest point in $A$ to all points in $Z$ respectively and calculates the Euclidean distance of all point pairs. 
\textit{IGD}$^+$ is

\begin{equation}
    IGD^+(A) = \frac{1}{\vert Z\vert}\left(\sum_{i=1}^{\vert Z\vert}{d^+_i}^2\right)^{1/2}\,,
\end{equation}
where $d^+_i=\max\{a_i-z_i,0\}$ and $a_i$, $z_i$ are the $i$-th component of $\bm{a}$, $\bm{z}$. $\bm{d^+}=(d^+_1,\ldots,d^+_{\vert Z\vert})$ calculates only the positive component of contributes. 
% , while $IGD$ cannot.

\subsection{Scalability}
The scalability of all five algorithms across all problem scales within $M=30$ mins is shown in Table~\ref{tab:runtime:all}.
% Since comparison algorithms use $\epsilon$-constraint framework, an entire result of comparison algorithms is obtained after the full runtime. Our method SDES is an iterative algorithm.    
Table~\ref{tab:runtime:all} reveals that only ORIGAMI-M and ORIGAMI-M-BS can complete the task of $T=1000, N=3$, but SDES is less affected by the increasing number of $T$. Furthermore, with the increasing number of $N$, The maximum number of $T$ of comparison algorithms drops rapidly when $N$ increases, while the maximum number of $T$ of SDES decreases slowly. The comparison methods can only complete the large-scale tasks of $T=25$, but SDES can still work on the problem with large $T$. Notably, SDES can solve $N=20$ problems with ease.
% TODO 下面的表简单这么展示, 当然也有另外的方式,待讨论
% \begin{table*}[]
% \centering
% \caption{An overview of whether each algorithm can complete MOSG problems of various scales within maximum time M. The correspondences between symbols and methods are $\star$-SDES, $\wedge$-ORIGAMI-M, $\circ$-ORIGAMI-A, $\dagger$-ORIGAMI-M-BS, $\triangleleft$-DIRECT-MIN-COV. E.g., $\star\wedge\circ\dagger\triangleleft$ in the top-left cell indicates that all algorithms complete $N=3$, $T=25$ MOSG problem on time.}
% % \protect\footnotemark[1]
% \label{tab:runtime:all}
% \begin{minipage}{\textwidth}
% \centering
% % \begin{tabular}{c|c|c|c|c|c|c|c|c|c}
% \begin{tabular}{c|l|l|l|l|l|l|l|l}
% \toprule
%         \diagbox{$\#$Target}{$\#$Obj.}
%         & 3& 4& 5& 6& 7& 8& 9$\sim$18& 19$\sim$20\\  
%         \midrule
%         25 & $\star\wedge\circ\dagger\triangleleft$ & $\star\wedge\circ\dagger\triangleleft$ & $\star\wedge\circ\dagger\triangleleft$ & $\star\ \ \circ\dagger\;\triangleleft$ & $\star\ \ \;\ \dagger\;\triangleleft$ & $\star\ \ \circ\ \ \triangleleft$ & $\star\ \ \ \ \ \ \ \ $ & $\star\ \ \ \ \ \ \ \ $\\  
%         50 & $\star\wedge\circ\dagger\triangleleft$ & $\star\wedge\circ\dagger\triangleleft$ & $\star\wedge\circ\dagger\triangleleft$ & $\star\ \ \ \ \dagger\,\triangleleft$ & $\star\ \ \ \ \dagger\,\triangleleft$ & $\star$ & $\star$ & $\star$ \\  
%         75 & $\star\wedge\circ\dagger\triangleleft$ & $\star\wedge\circ\dagger\triangleleft$ & $\star\wedge\circ\dagger\triangleleft$ & $\star\ \ \ \ \dagger\,\triangleleft$ & $\star$ & $\star$ & $\star$ & $\star$ \\  
%         100 & $\star\wedge\circ\dagger\triangleleft$ & $\star\wedge\circ\dagger\triangleleft$ & $\star\wedge\ \ \dagger\;\triangleleft$ & $\star\ \ \ \ \ \;\;\,\triangleleft$ & $\star$ & $\star$ & $\star$ & $\star$ \\  
%         200 & $\star\wedge\circ\dagger\triangleleft$ & $\star\wedge\ \ \dagger\;\triangleleft$ & $\star$ & $\star$ & $\star$ & $\star$ & $\star$ & ~ \\  
%         400 & $\star\wedge\ \ \dagger\;\triangleleft$ & $\star\;\wedge$ & $\star$ & ~ & ~ & ~ & ~ & ~ \\  
%         600 & $\star\wedge\ \ \dagger\;\triangleleft$ & $\star$ & ~ & ~ & ~ & ~ & ~ & ~ \\  
%         800 & $\star\wedge\ \ \dagger\;$ & $\star$ & ~ & ~ & ~ & ~ & ~ & ~ \\  
%         1000 & $\star\wedge\ \ \dagger\;$ & $\star$ & ~ & ~ & ~ & ~ & ~ & ~ \\ 
% \bottomrule
% \end{tabular}
% \footnotesize
% % \footnotetext{.}
% \end{minipage}
% \end{table*}

\begin{table}[htbp]
\caption{The scalability of SDES and comparison algorithms. The maximum number of targets of each algorithm is shown when the number of attackers ranges from 3 to 20. The symbol ``--'' means that the algorithm cannot complete the MOSG problem under the corresponding number of attackers and targets within maximum time $M=30$ mins.}
\label{tab:runtime:all}
    \centering
    \begin{tabular}{c|c|c|c|c|c|c|c|c}
    \toprule
    \diagbox{Method}{$\#$Attacker} & 3& 4& 5& 6& 7& 8& 9$\sim$18& 19$\sim$20\\  \midrule
    SDES & 1000 & 1000 & 400 & 200 & 200 & 200 & 200 & 100\\
    DIRECT-MIN-COV & 600 & 200 & 100 & 100 & 50 & 25 & --& --\\
    ORIGAMI-A & 200 & 100 & 75 & 25 & -- & 25 & -- & --\\
    ORIGAMI-M-BS & 1000 & 200 & 100 & 75 & 50 & -- & -- & --\\
    ORIGAMI-M & 1000 & 400 & 100 & -- & -- & -- & -- & --\\
    \toprule
    \end{tabular}
\end{table}

% \begin{table*}[htbp]
% \caption{The ablation result of SDES in $N=5, T=50$ MOSG problem.}
%     \centering
%     \begin{tabular}{c|l|l|l|l|l|l|l|l}
%     \toprule
%     Methods & $N=3$& $N=4$& $N=5$& $N=6$& $N=7$& $N=8$& $N=9\sim18$& $19\sim20$\\  \midrule
%     SDES & 1000 & 1000 & 400 & 200 & 200 & 200 & 200 & 100\\
%     DIRECT-MIN-COV & 600 & 200 & 100 & 100 & 50 & 25 & --& --\\
%     ORIGAMI-A & 200 & 100 & 75 & 25 & -- & 25 & -- & --\\
%     ORIGAMI-M-BS & 1000 & 200 & 100 & 75 & 50 & -- & -- & --\\
%     ORIGAMI-M & 1000 & 400 & 100 & -- & -- & -- & -- & --\\
%     \toprule
%     \end{tabular}
% \end{table*}

\subsection{Time Efficiency}
\label{sec:Runtime}
We show that SDES not only has the ability to accomplish large-scale MOSGs, but also is more time-efficient than comparison methods. The time efficiency experiments (only results completed within $M=30$ mins are displayed) include (i) Fix $N=3$ and scale up $T=200\sim 1000$. We set $T\geq200$ since all algorithms can solve $T<200$ problems quickly, cf. Figure~\ref{fig:runtime:all}(a). (ii) Fix $T=25$ and scale up $N=3\sim9$, since no comparison methods can complete $N>9$ task even $T$ only equals $25$, cf. Figure~\ref{fig:runtime:all}(b).

% \begin{figure}[!t]
%   \centering
%     \begin{minipage}{0.49\linewidth}\centering
%       \includegraphics[width=\textwidth]{figures/Time-indicator_N3T200-1000_2.pdf}\\
%       (a) Scaling up targets.
%     \end{minipage} \\
%         \begin{minipage}{0.49\linewidth}\centering
%       \includegraphics[width=\textwidth]{figures/Time-indicator_N3-11T25_2.pdf}\\
%       (b) Scaling up objectives.
%     \end{minipage} 
%   \caption{The runtime indicator of SDES and comparison algorithms.}\label{fig:runtime:all}
% \end{figure}

\begin{figure}[!t]
\centering
\begin{minipage}[l]{\columnwidth}\centering
\includegraphics[width=0.49\textwidth]{figures/Time-indicator_N3T200-1000_2.pdf}
\includegraphics[width=0.49\textwidth]{figures/Time-indicator_N3-11T25_2.pdf}\\
\quad\qquad(a) Scaling up targets.\qquad\qquad\qquad
(b) Scaling up objectives.
\caption{The runtime indicator of SDES and comparison algorithms.}
\label{fig:runtime:all}
\end{minipage}
\end{figure}

Figure~\ref{fig:runtime:all}(a) and (b) show that SDES increases slowly. Furthermore, Figure~\ref{fig:runtime:all}(b) shows that all comparison methods fail as the number of attackers increases. Although DIRECT-MIN-COV is the most efficient method which can complete $N=8$, $T=25$ task in $M=30$ mins, DIRECT-MIN-COV is one of the worst methods with respect to both \textit{HV} and \textit{IGD}$^+$ performance indicators, cf. Figure~\ref{fig:Rankbar}. Meanwhile, although the runtime of ORIGAMI-M-BS also increases slowly in medium-scale MOSGs, it fails when $N>7$. SDES can easily accomplish $N=8$, $T=25$ task, and the performance of SDES is satisfactory.
% More information can be observed from Figure~\ref{fig:runtime:all}(b): 
The runtime of SDES varies steadily with the number of attackers, while the runtime of other methods mainly depends on the problem-solving difficulty. For example, when $N=6$ or $N=9$, the runtime of almost all comparison methods is reduced since those problems are less difficult than $N=5$ or $N=7$ problem. 
% 据我所知没有讨论MOSG问题难度的文章（SG倒是有），当然不说这句话完全不影响文章其他部分
% In addition, there is currently no literature that specifically analyzes the way to measure the MOSG problem difficulty in detail.

% Figure
\begin{figure}[h!t]
\centering
% \includegraphics[width=.4\textwidth]{figures/Time-indicator_SDESF_N5-19T25-1000_2.pdf}
\includegraphics[width=0.5\linewidth]{figures/TimeIndicator-3.pdf}
% \includegraphics[width=.4\textwidth]{figures/TimeIndicator-4.pdf}
\caption{The runtime of SDES for larger problem scales. The runtime of SDES increases linearly with the increasing number of attackers and targets when one of them is fixed.
% The runtime of SDES varies linearly with both target and heterogeneous attacker. E.g., fix $N=5$, the runtime changes at equal intervals for $T=[25, 50, 75, 100]$ (4 bottom lines) and $T=[200, 400, 600, 800, 1000]$ (5 top lines). 
}
\label{fig:Runtime:SDESF:larger}
\end{figure}

% 注释的部分本来想说25 50 75 100和200 400 600 800 1000分别是两组等差数列（为了证明本段最后一句话：我们的算法在Target维度上也是线性变化的）
% 后面将说明放到Figure的caption中
Figure~\ref{fig:runtime:all}(b) presents that all comparison algorithms fail when $N>8$, $T>25$, but SDES still works. Figure~\ref{fig:Runtime:SDESF:larger} shows the scalability boundary of SDES. In Figure~\ref{fig:Runtime:SDESF:larger}, SDES can handle $N=20$, $T=100$ problems within $M=30$ mins. 
% All methods in legend are divided into two groups according to the different steps of target change.
%: the first group is composed of the first four lines with 25 steps. The second group consists of the last five lines in 200 steps. 
% SDES can complete the $N=12$, $T=25$ problem on time, while 
% SDES can easily complete $N\leq20$, $T\leq100$ problems. 
% In addition, we can also derive the following information: i. The runtime of SDES increases exponentially, not because of objective dimension, but $pop\_{}size$, e.g., the complexity of the crossover operator varies exponentially with ${pop\_{}size}$. SDESF shows that when the $pop\_{}size$ is fixed, the runtime varies linearly with the objective. ii. 
In addition, the runtime of SDES increases linearly with the increasing number of targets when the number of attackers is fixed. Also, the same goes for attackers.
% the runtime of SDES increases linearly with the increasing number of  when the number of targets is fixed.

% \subsection{Quantitative Analysis of Performance}
\subsection{Effectiveness}
\label{sec:effe}
% TODO 标题有待调整, 取决于绘制Fig5时是否要将对比算法画出来(图中水平虚线).  值得注意的是, 自己的方法在N=5T=50子问题没有SOTA好(最小化问题) 
% TODO 作这个实验的原本目的是展示算法收敛速度与收敛效果 
\subsubsection{Convergence Speed and Effect}
\label{sec:effe:part1}
Lemma~\ref{pro:property1.2} and~\ref{pro:property1.1} have shown that $U_i^d(\bm{c})$ is $T$-dimensional step function that heuristic and gradient-based algorithms are difficult to directly optimize on the $C$ space, cf. Figure~\ref{fig:Ua_Ud} for an illustration.
% TODO 比较尴尬的是,由于选取的问题规模不对,自己的方法并不是最好. 下面的表述可以改成收敛速度与收敛效果; (然后不画对比算法?)
To verify the superiority of SDES over the naive $c$-code EA and other comparison algorithms, see Figure~\ref{fig:convergence_curve}, we plot the convergence of \textit{IGD}$^+$ performance indicator with the number of iterations (\textit{IGD}$^+$ instead of \textit{HV} is selected due to its high calculation cost).

% Figure
\begin{figure}[h!t]
\centering
\includegraphics[width=0.5\linewidth]{figures/ConvergenceCurve.pdf}
\caption{The convergence curve. SDES converges fast, and it is comparable with other traditional methods. Since the comparison algorithms are based on the $\epsilon$-constraint framework and \textit{IGD}$^+$ score is returned after fully running, the comparison algorithms are plotted as the dotted line parallel to the x-axis.
% $I$-code EA and $c$-code EA are the naive many-objective EAs searching solutions in the continuous and discrete space respectively. 
% In addition, SDES calls the refinement component for each round of \textit{IGD}$^+$ evaluation.
}
\label{fig:convergence_curve}
\end{figure}

% Lcode2ccode框架实际上结合了精确算法，因此能保证收敛到不错的结果，这点在Equa11（solution evaluation部分提到过）
% 也算contribution之一
As shown in Figure~\ref{fig:convergence_curve}, the performance of SDES in the initialization stage outperforms the converged performance of $I$-code and $c$-code EAs, and its convergence speed is faster. SDES finally obtains comparable results to the SOTA methods. Meanwhile, the exact algorithm ORIGAMI~\citep{ERASER} is embedded in the iteration of SDES. Therefore, only initialization can guarantee a well performance with respect to \textit{IGD}$^+$ and \textit{HV} indicators. 
% Our method can converge within 150 iterations, while $\bm{c}$-code EA needs 300 iterations to converge. 
% In a nutshell, SDES, incorporating exact algorithms, can overcome the bottleneck mentioned in~\citep{MOSG,extended-MOSG}: heuristic algorithms with randomness, such as EAs, lacks theoretical guarantee of stability.

\subsubsection{Multi-objective Performance Indicators of All Scales}
\label{sec:effe:part2}
The multi-objective performance indicators \textit{HV}, \textit{IGD}$^+$ can measure convergence and diversity of the approximate PF. 
From Table~\ref{tab:runtime:all}, there are a total of 26 MOSG problems that at least one comparison algorithm can complete.
% The range of MOSG problem scale is $3\geq N\geq8$, $25\geq T\geq1000$, which can be accomplished by any comparison method, cf. Table~\ref{tab:runtime:all}.

% TODO 希望用rank-图/表格表示算法求解质量的优势R
\begin{figure}[h!t]
  \centering
  \includegraphics[width=0.5\linewidth]{figures/Rankbar.pdf}
  \caption{The rank distribution of 5 methods in 26 MOSG problems. SDES achieves most of rank-1 in both \textit{HV} (left bar) and \textit{IGD}$^+$ (right bar) indicator experiments. The SOTA methods ORIGAMI-M and ORIGAMI-A time out in many MOSG problems, while other efficient methods ORIGAMI-N-BS and DIRECT-MIN-COV are not effective. }
    \label{fig:Rankbar}
\end{figure}

SDES has a clear advantage in solution quality. Figure~\ref{fig:Rankbar} shows summarization results about all methods over 26 MOSG problems. In addition, Appendix~\ref{app:vis_ana} shows the excellent performance of SDES on each objective by visualization. Among 26 problems, SDES achieves 24 rank-1 in \textit{HV} indicator, and 22 rank-1 in \textit{IGD}$^+$ indicator. The score and rank result details are put in Appendix~\ref{app:more_eff_exp}. 
Although SOTA algorithms like ORIGAMI-M can provide well-convergent solutions, many-objective optimization task also requires well-spaced (good diversity and distribution) solutions, which makes these methods poor performance in the multi-objective indicator. 
% In addition, compared with other SOTA algorithms, our method can achieve a better PF more stably. Take $HV$ indicator experiments as an example, 12 problem scales can be accomplished by both ORIGAMI-M and ORIGAMI-A. Of the 12 experiments, ORIGAMI-M wins only 6 of them.

\subsection{Ablation Studies}
\label{sec:Ablation}

% \subsubsection{Ablation Study of Every Component}
The ablation study is conducted to analyze the effects of the three key parts discretization, restoration and refinement. Five scenarios are designed as Table~\ref{tab:ablation:our_method}. 
For discretization, \ding{53} means many-objective EA searches in the high-dimensional continuous space $c$-code, while $\checkmark$ means many-objective EA searches in the low-dimensional discrete space $I$-code. For restoration, \ding{53} means solutions are restored in random, while $\checkmark$ means solutions are restored by solution divergence. For refinement, \ding{53} and $\checkmark$ mark whether the PF approximation found by many-objective EA is refined or not.
% The first scenario (Num 1) is the baseline model, naive $c$-code EA, and the last four scenarios are all $I$-code EAs. They are: (Num 2) the naive EA based on $I$-code without any improvements, (Num 3) the degraded version of only BSM is retained (also called SDES without MIN-COV), (Num 4) the degraded version of only the MIN-COV is retained (also called as SDES without BSM), (Num 5) and complete algorithm SDES with BSM and MIN-COV. Specifically, Num 3 directly uses the convergent result as PF without MIN-COV final adjustments. Num 4 uses random selection to replace BSM. 
The representative problem scale is $N=5, T=50$.
The reason of $T=50$ is that SDES and SOTA methods behave similarly, cf. Figure~\ref{fig:convergence_curve}. The reason of $N=5$ is that all methods perform well. 
% Otherwise, the PF is inaccurate, which is needed for the evaluation of the ablation study. 

\begin{table}[!tbp]
\caption{The ablation result of SDES in $N=5, T=50$ MOSG problem.}
\label{tab:ablation:our_method}
    \centering
    \begin{tabular}{c|ccc|ll}
    \toprule
        Num & Dis & Res & Ref & HV/Rank & IGD$^+$/Rank\\ \midrule
        1 & \ding{53} &\ding{53}&\ding{53}&3.68e5{\scriptsize $\pm$4.04e3}/4 & 1.31{\scriptsize $\pm$.02}/3 \\
        2 & $\checkmark$&\ding{53}&\ding{53}&\textbf{3.41e5}{\scriptsize $\pm$9.75e3}/5 & \textbf{2.45}{\scriptsize$\pm$.11}/5 \\
        3 & $\checkmark$&\ding{53}&$\checkmark$&4.02e5{\scriptsize $\pm$4.49e4}/3 & 2.39{\scriptsize$\pm$.15}/4 \\ 
        4 & $\checkmark$&$\checkmark$&\ding{53}&\textbf{5.58e5}{\scriptsize $\pm$1.73e3}/2 & \textbf{0.57}{\scriptsize $\pm$.01}/2 \\
        5 & $\checkmark$&$\checkmark$&$\checkmark$&5.61e5{\scriptsize $\pm$1.23e5}/1 & 0.50{\scriptsize $\pm$.06}/1 \\ \bottomrule
    \end{tabular}
\end{table}
% \begin{table}[htbp]
% \caption{The ablation result of our method}
% \label{tab:ablation:our_method}
%     \centering
%     \begin{tabular}{l|rr}
%     \toprule
%         \textbf{$N=5$, $pop\_{}size=400$} & \multicolumn{2}{c}{\textbf{$T=50$}} \\ 
%         $Method-Num$ & $HV$/\textit{rank} & $IGD^+$/\textit{rank} \\ \midrule
%         \textbf{$c$-code$-1$} & \textbf{3.68e5}{\scriptsize $\pm$4.04e3}/8 & \textbf{1.31}{\scriptsize $\pm$.02}/7 \\
%         \textbf{$I$-code$-2$} & 3.41e5{\scriptsize $\pm$9.75e3}/9 & 2.45{\scriptsize$\pm$.11}/9 \\
%         \textbf{$I$-code with BSM$-3$} & \textbf{5.58e5}{\scriptsize $\pm$1.73e3}/3 & \textbf{0.57}{\scriptsize $\pm$.01}/3 \\
%         \textbf{$I$-code with MIN-COV$-4$} & 4.02e5{\scriptsize $\pm$4.49e4}/7 & 2.39{\scriptsize$\pm$.15}/8 \\ 
%         \textbf{SDES$-5$} & 5.617e5{\scriptsize $\pm$1.23e5}/1 & 0.50{\scriptsize $\pm$.06}/2 \\
%         ORIGAMI-M & 5.27e5/5 & 0.57/3 \\ 
%         ORIGAMI-A & 5.59e5/2 & 0.40/1 \\ 
%         ORIGA-M-BS & 4.52e5/6 & 1.23/6 \\
%         DIRECT-MIN-COV & 5.57e5/4 & 0.64/5 \\
%         PF & 7.73e5/- & 0/- \\ \bottomrule
%     \end{tabular}
% \end{table}

From the ablation results, the following key questions are answered:

(i) Can MOSGs be solved simply by naive many-objective EA or discretization? The term ``naive" means the many-objective EA only uses the common EA operator but without discretization, restoration, and refinement components proposed in our paper. Num 1 and Num 2 indicate that both methods fail to converge and are inferior to SDES and all comparison algorithms. Furthermore, The naive EA with discretization is even inferior to the naive EA. The reason why naive EA fails is the $O(N^T)$ sample complexity in combinatorial optimization, and the reason why naive discretization fails is the need of the restoration component after the discretization component. In general, neither naive many-objective EA nor discretization can handle large-scale MOSGs well. 
% of $c$-code EA is illustrated in Figure~\ref{fig:Ua_Ud}. While the difficulty of $I$-code EA is the  bi-level problem, cf. Equation~\eqref{equ:equationBi-OptFunc}. The searching space of the inner-layer task is $O(N^T)$, $25\leq T\leq1000$. Therefore, Simple coding does not allow heuristic algorithms to deal with security game problems.
    
% \textcolor[rgb]{0.5,0.6,0.7}{(ii) Can the naive $I$-code EA get better performance than the naive $c$-code EA?  Table~\ref{tab:ablation:our_method} shows  This is because the optimization of $I$-code is more difficult than $c$-code. $I$-code optimization represents a bi-level task in $O(N^T)$, which is solved by our BSM algorithm. In general, The naive $I$-code EA cannot handle the $O(N^T)$ complexity inner-layer task with random selection alone.}

(ii) How much improvement does the restoration component bring? The results from Num 2 to Num 4 in black show that the restoration component can greatly improve solutions' quality. 
% There are two cases that can reflect the effect of BSM in Table~\ref{tab:ablation:our_method}: (i) Num 4 compared to Num 2. (ii) Num 5 compared to Num 3. 
% In the first case, the performance of Num 2 is the worst among all methods (achieves double rank-9 in \textit{HV} and \textit{IGD}$^+$ indicator), but Num 3, cf. the bold line can achieve double rank-3, even better than ORIGAMI-M and ORIGAMI-M-BS and DIRECT-MIN-COV. In the second case, the BSM can help the rank of Num 4 change from rank-7 and rank-8 to rank-1 and rank-2. 
% Note that the restoration component uses a bit-wise optimization to pursue smaller sample complexity $O(NT)$. 
% It is a worthy research direction to study a novel optimization way that pursues accuracy because we show that 
If Assumption~\ref{asp:BitOpt} is not satisfied, the well-converged PF may not be found, where the refinement component is needed.

% 
(iii) How much improvement does the refinement component bring? The results from Num 2 to Num 3 or from Num 4 to Num 5 show that clear gains can be obtained from the lightweight refinement. Observe that the refinement component works well and that there is a lot of room for the accuracy improvement of bit-wise optimization in the evaluation component.
% There are also two cases reflecting the MIN-COV in Table~\ref{tab:ablation:our_method}: (i) Num 4 compared to Num 2. (ii) Num 5 compared to Num3. In the first case, MIN-COV helps the rank of Num 2 change from double rank-9 to rank-7 and rank-8. In the second case, our method is improved from double rank=3 (Num 3) to rank-1 and rank-2 (Num 5). 
% Observe that both cases indicated that MIN-COV contributed more to \textit{HV}, which measures the convergence and diversity of the PF.


% 提出了，理论上，实验上（贡献）
% 工作的不足 未来的工作 价值：提供了可行的方案（线性的多目标）+未来的工作 + 缺陷：理论保证难以达到
\section{Conclusion}
\label{sec:conclusion}
% 主要缺陷：在不满足可达性条件时bit-wise optimization的精度任有很大的优化空间。
%In this paper, the framework of general heuristic algorithms, named SDES, for solving MOSG problems is given, which solves the challenge that general heuristic algorithms cannot converge even on low-dimensional MOSG problems. 
This paper proposes the first linear sample complexity EA-based framework SDES for MOSGs if either the number of targets or attackers is fixed, which simultaneously extends targets and heterogeneous attackers to large-scale scenarios.
The contribution includes proposing a high-dimensional evaluation and low-dimensional optimization framework, theoretically disclosing the optimization consistency and convergence guarantee, and empirically verifying the superiority of SDES with respect to scalablity, time efficiency, and effectiveness. 
%
% 条件是否可以放松，存在没分析完的理论继续分析
The limitation of SDES is that it greedily solves combinatorial optimization problems bit by bit, whose convergence assumption may become difficult to meet with the increase of the number of targets. Therefore, as traditional methods~\citep{MOSG,extended-MOSG}, SDES provides refinement components to ensure convergence. An important future work is to design a framework with theoretical guarantees for the monotonicity of the quality of the solution. 
%Furthermore, the performance of SDES framework equipped with other many-objective evolution algorithms, e.g., MOEA/D, is also worth investigating.

\section*{Acknowledgement}
% The authors would like to thank the anonymous reviewers for their constructive and valuable suggestions. 
This work is supported by the Scientific and Technological Innovation 2030 Major Projects (No. 2018AAA0100902), the National Natural Science Foundation of China (No. 62106076), and the Natural Science Foundation of Shanghai (No. 21ZR1420300). The data and code of algorithms are available at \url{https://github.com/1589864500/SDES}.





%% The file named.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{named}
\bibliography{mybibliography}

\newpage
% \begin{appendices}
% Summary paragraph of the appendix.
\section*{Appendix} 
The appendix consists of three parts: (i) additional details of the methodology, (ii) proof details of theoretical analysis and (iii) additional experimental details and results. In the first part, Section~\ref{app:notation} first summarizes the variables, parameters, and symbols in this paper. Then, Section~\ref{app:protra} introduces the significance of the discretization and optimization components of our framework, mentioned in Section~\ref{sec:dis} and~\ref{sec:opt}. Furthermore, Section~\ref{app:IatC} introduces the pseudocode of ideal attacked target calculation IATC mentioned in Algorithm~\ref{alg:pseudo1}. Finally, Section~\ref{app:fra_pseu_BSM} introduces another pseudocode of the boolean scoring mechanism BSM mentioned in Algorithm~\ref{alg:pseudo1}. In the second part, we present the proof details about Lemmas and Theorems mentioned in Section~\ref{sec:met} and~\ref{sec:val_ana}. In the third part, firstly, Section~\ref{app:expset} introduces more experimental setup details, including hyperparameter setup, implementation setup of NSGA-III in the optimization component of SDES, solution initialization of SDES. Then, Section~\ref{app:more_eff_exp} exhibits the comprehensive results of the performance of all methods mentioned in Seciton~\ref{sec:effe:part2}. In addition, Section~\ref{app:more_time_effi} analyzes the effect of population size on the runtime of SDES. Seciton~\ref{app:more_sen_ana} displays additional sensitivity analysis of population size in SDES. Finally, combined with the performance result details, Section~\ref{app:vis_ana} further analyzes the characteristics of SDES and SOTA methods by visualization.

\section{Additional Details of Methodology}
% 本节期望解释本文用到的方法的根和更多解释,包含:1.Ud搜索空间复杂的原因;2.文中方法Problem Transformation从EA角度的理解;3.
\subsection{Notations}
The definitions of variables, parameters, and symbols involved in this paper is listed in Table~\ref{app:tab:notion}. 
\label{app:notation}

\begin{table*}[]
\caption{The notions involved in this paper.}
\label{app:tab:notion}
\begin{adjustbox}{width=\textwidth}
    \centering
    \begin{tabular}{c|l}
    \toprule
        Notation & Definition\\ \midrule
        {$\succeq$} & $\bm{c}\succeq\bm{c}'$ means that $\bm{c}$ dominates $\bm{c}'$. \\
        {$\setminus$} & The set difference symbol. \\
        {$\Vert\cdot\Vert_1$} & The L1 norm of a vector. \\
        {$[\cdot]$} & $[N]=\{1,\ldots,N\}$ for a positive integer $N$. \\
        {$\mathcal{A}_i$, $\mathcal{D}$} & The $i$-th attacker and defender in the multi-objective security games. \\
        {$N$, $T$} & The number of attackers and targets. \\ 
        {$r$} & {The resource ratio. The total resource is $r\cdot  T$.} \\
        $t$ & The $t$-th target in all $T$ targets.  \\
        {$\bm{c}$, $\tilde{\bm{c}}$, $\hat{\bm{c}}$, $\bm{c}^*$} & The coverage vector (solution), the feasible solution, the ideal solution, \\
        {} & {and the optimal solution, respectively.}\\
        {$\bm{v}$} & A zero coverage vector except the $t'$-th component. \\
        % {} &   \\
        % {} & {} \\
        {$C$, $C^*$, $\tilde{C}$} & The whole space of all solutions, the space of all optimal solutions, and    \\
        {} & {the space of all feasible solutions, respectively.}\\
        % {} & .  \\
        {$\bm{F}(\bm{c})$} & {The fitness of solution $\bm{c}$.}  \\
        {$\bm{a}_i$} & The attack vector of $\mathcal{A}_i$.  \\
        {$at_i$} & The target being attacked by $\mathcal{A}_i$.  \\
        $U_i^{u,a}(t)$, $U_i^{c,a}(t)$ & $\mathcal{A}_i$'s payoff on target $t$ if $t$ is \textit{uncovered} and \textit{covered}.\\
        $U_i^{u,d}(t)$, $U_i^{c,d}(t)$ & $\mathcal{D}$'s payoff for target $t$ if $t$ is \textit{uncovered} and \textit{covered}.\\
        $U_i^a(c_t)$, $U_i^d(c_t)$ & $\mathcal{A}_i$'s and $\mathcal{D}$'s payoff for one target targets with respect to the resources $c_t$.\\
        $U_i^a(\bm{c}, \bm{a}_i)$,, $U_i^d(\bm{c}, \bm{a}_i)$ & $\mathcal{A}_i$'s and $\mathcal{D}$'s payoff for $T$ targets with respect to the given strategy profile  \\
        {} & {$(\bm{c}, \bm{a}_i)$.}\\
        {$\bm{U}$} & The payoff structure, including  $U_i^a(\bm{c}, \bm{a}_i)$ and $U_i^d(\bm{c}, \bm{a}_i)$.\\
        {$t_{(1)},\ldots,t_{(T)}$} & {The order of all targets in descending order of $U_i^a(c_t)$.}  \\
        {$BR_i^a(\bm{c})$, $BR_i^d(\bm{c})$} & The best response of $\mathcal{A}_i$ and $\mathcal{D}$.  \\
        {$\Gamma_i(\bm{c})$} & {The attack set, a set of targets that can provide the maximum expected payoffs}  \\
        {} & {for $\mathcal{A}_i$ with the given $\bm{c}$, also denoted as $\Gamma_i$.}\\
        {$gap_i$} & The difference of the payoff if the coverage is changed from $\bm{c}$ to $\bm{c}$+$\bm{v}$ for $\mathcal{A}_i$. \\
        {$\Gamma_s(\bm{c})$} & {The attack group, a set of all $\Gamma_i(\bm{c})$, also denoted as $\Gamma_s$.}  \\
        {$\tilde{\bm{at}}$, $\tilde{\Gamma}_i$, $\tilde{\Gamma}_s$} & The attacked target, attack set and attack group of the feasible solution.  \\
        {$\hat{\bm{at}}$, $\hat{\Gamma}_i$, $\hat{\Gamma}_s$} & The attacked target, attack set, and attack group of the ideal solution.  \\
        {$\bm{\gamma}$, $\bm{\bm{\pi}}$} & A binary matrix and a continuous matrix.  \\
        % {} & .  \\
        {$K(\cdot,\cdot)$, $K_s(\cdot,\cdot)$} & The divergence between $\Gamma_i$ and $\Gamma_s$, respectively.  \\
        % {} & The divergence between .  \\
        % {$\bm{A}$} & The $i$-th row of $\bm{A}$ is an index vector of the targets in decreasing order of $U_i^{u,a}(c_t)$.  \\
        % {$P$} & The attraction set  \\
        % {$\bm{S}$} & The counter vector  \\
        {$max\_{}gen$} & The maximum generation in EAs.  \\
        {$pop\_size$} & The population size in EAs.  \\
        \bottomrule
    \end{tabular}
\end{adjustbox}
\end{table*}

\subsection{Details about Benefits of Discretization and Optimization}
\label{app:protra}

% 解释MOSG很难直接搜索的原因, 进而解释我们方法作问题转换的意义所在
MOSG is modeled by the leader-followers Stackelberg game, which is easy to generalize to a wide range of real-world problems. 
Lemma~\ref{pro:property1.2} and~\ref{pro:property1.1} explains the difficulty of MOSG optimization briefly. Here we further analyze the high difficulty of MOSG optimization. 
Firstly, under the fully rational attacker behavior assumption, $\mathcal{D}$'s payoff becomes a high-dimensional step function. Meanwhile, no feedback returns if the $\mathcal{D}$ allocates resources out of $\Gamma_i$. E.g., Figure~\ref{fig:Ua_Ud} shows the complex landscape with many flat and jump areas even in small-scale MOSG optimization. 
Secondly, the leader-followers Stackelberg game allows the attackers always go first, thus the behavior of $\mathcal{D}$ is limited to $\Gamma_i$ of $\mathcal{A}_i$, which means MOSG is constrained by $N$ conflicting constraints. Thirdly, the priority action of attackers results in $\mathcal{D}$'s payoff $U^d_i$ being affected by the $\mathcal{A}_i$'s payoff $U^a_i$, cf. $\bm{a}_i$ in Equation~\eqref{equ:equation2}, but we cannot control $U^a_i$ directly.  Figure~\ref{app:fig:Ua_Ud} displays a smooth landscape of $U_i^a$. For $U^d$ optimization, strategy $\bm{c}$ affects $U^d$ and $U^a$ simultaneously, and $U^a$ also affects $U^d$. The $U^d$ optimization becomes very complex because of the divergence in the optimization direction.

This paper proposes SDES with linear complexity for MOSG if either the number of targets or attackers is fixed, which models security games with many heterogeneous attackers. 
To solve large-scale MOSG problems, we use the discretization component transforms solution representation from high-dimensional continuous $c$-code to low-dimensional discrete $I$-code. Specifically, on the one hand, the transformation from $I$-code to $\bm{c}$-code eliminates the influence of hidden variables like $U^a$ by shifting search space from high-dimensional continuous $\bm{c}$ to low-dimensional discrete $\Gamma$. In addition, searching $\Gamma$ directly also eliminates the negative effect of priority action of $\mathcal{A}_i$. On the other hand, the original problem as Equation~\eqref{equ:equationOptFunc}) is transformed to a combinatorial optimization problem as Equation~\eqref{equ:equationBi-OptFunc} and use bit-wise optimization to solve the combinatorial optimization problem.
% divides the original whole solution space $C$ into several subspaces $\tilde{C}$s. The parameter $pop\_{}size$ determines the granularity of partitioning. 
% $pop\_{}size$ is a constant, which can eliminate the curse of dimensionality and provide a well-spaced PF.

\label{app:payoff}
\begin{figure}[]
\centering
\includegraphics[width=.6\columnwidth]{figures/Ua_heatmap.pdf}
\caption{The heatmap of attacker payoff $U^a_i(\bm{c})$. $\bm{c}$ directly affects continuous smooth $U^a_i$, which is easy to optimize. However, the goal of security games is not $\min_{t\in[T]}U^a_i(c_t)$, but $\max_{t\in[T]}U^d_i(c_t)$. To make matter worse, the optimization direction of $U^a$ can misdirect the optimization direction of $U^d$. }
\textbf{\label{app:fig:Ua_Ud}}
\end{figure}

\subsection{The Pseudocode of Ideal Attacked Target Calculation (IATC)}
\label{app:IatC}

Algorithm~\ref{alg:at_cal} aims to determine $\mathcal{A}$'s final attacked target by the maximal indifference property~\citep{ERASER} under the fully rational assumption. Line~\ref{code:IatC:line2}-~\ref{code:IatC:line3} describe the resources needed to keep $U^{u,a}_{obj}(t)$ the same, $\forall t\in\Gamma_{obj}$.   $x$ in Line~\ref{code:IatC:line2} is the adjusting goal. Line~\ref{code:IatC:line3} comes from setting $x$ equal to $U^{u,a}_{obj}(t)$ according to Equation~\eqref{equ:equation1}: $x=c_tU_{obj}^{c,u}(t)+(1-c_t)U_i^{u,a}(t)$~\citep{ERASER}. $U_{obj}^a$ calculation in Line~\ref{code:IatC:line4} comes from Equation~\eqref{equ:equation2}. Line~\ref{code:IatC:line5} comes from the fully rational assumption (i.e., $\mathcal{A}$ prefers to attack the target returning best payoff).

\begin{algorithm}
    \caption{Ideal Attacked Target Calculation (IATC)}
    \label{alg:at_cal}
    \begin{algorithmic}[1]
        \REQUIRE $U_{obj}^{u,a}$, $\Gamma_{obj}$.
        \ENSURE 
        
        \STATE$\bm{\hat{c}}\gets$ the zero ideal coverage vector.
        \STATE$x = U^{u,a}_{obj}(\Gamma_{obj}[-1])$. \small\textcolor{Green}{\% payoff of the last target in $\Gamma_{obj}$}\label{code:IatC:line2}
    
        \STATE$\hat{\bm{c}}[\Gamma_{obj}[:-1]] = \frac{x-U_{obj}^{u,a}(\Gamma_{obj}[:-1])}{U_{obj}^{c,a}(\Gamma_{obj}[:-1])-U^{u,a}_{obj}(\Gamma_{obj}[:-1])}$. \small\textcolor{Green}{\% adjust $\hat{\bm{c}}$ so that all targets' $U^a_{obj}$ equals $x$}\label{code:IatC:line3}
    
        \STATE Calculate $( U^a_{obj}(\hat{c}_t),t\in\Gamma_{obj})$.\label{code:IatC:line4}
    
        \STATE$\hat{\bm{at}}_{obj} = \Gamma_{obj}[\mathop{\arg\max}_{t\in[T]} ( U^a_{obj}(\hat{c}_t),t\in\Gamma_{obj})]$.\label{code:IatC:line5}
        \STATE \textbf{return} $\hat{\bm{at}}_{obj}$. \small\textcolor{Green}{\% the attacked target of $\mathcal{A}_{obj}$}
    \end{algorithmic}
\end{algorithm}

\subsection{The Framework and Pseudocode of Bit-wise Optimization (BitOpt)}
\label{app:fra_pseu_BSM}
By Theorem~\ref{obs:algorithm3}, BitOpt divides the process of solution restoration into $T$ bit-problems to bypass the combinatorial optimization. However, there is the negative effect of bit-wise optimization: $c^*_{i+1}\sim c^*_{T}$ is unknown when optimizing $\tilde{c}_i$. 
Inspired by Lemma~\ref{fig:heuristic_operator}, the boolean scoring mechanism (BSM) is proposed to solve each sub-problem and overcome negative influences, which can find $\bm{c}^*$ with little influence on the $c^*_{i+1}\sim c^*_{T}$ bit-problems in the $i$-th iteration.
%
The implementation details of BSM is introduced below:

\subsubsection{Implementation Details of BSM}

BSM in Algorithm~\ref{alg:pseudo2} Line~\ref{code:alg2:12}-\ref{code:alg2:20} is the core of BitOpt. If the whole of $\tilde{\bm{c}}$ is unknown in optimization, $\tilde{\Gamma}_s$ needed in $K_s(\cdot,\cdot)$ cannot be obtained directly, cf. Equation~\eqref{equ:inner-layer-OptFunc}. 
Fortunately, the calculation $K_s(\cdot,\cdot)$ does not need the whole $\tilde{\Gamma}_s$, but only $\tilde{\bm{at}}$ is needed.
According to $K_s(\cdot,\cdot)$, BSM optimizes $c_i^*$ by the comparison of $\tilde{\bm{at}}$ and $\hat{\bm{at}}$.
Specifically, the process of Algorithm~\ref{alg:pseudo2} Line~\ref{code:alg2:12}-\ref{code:alg2:20} can be seen from the $Count$ calculation part in the last step of the bottom half of Figure~\ref{fig:heuristic_operator}. The $\pi_{c_2}^{i},i\in[M]$ scoring problem can be regarded as a binary string matching problem, $(\bm{1}_{t_2}(\hat{at}_i),i\in[M])$ is a fixed binary string with no rules, while $(\bm{1}_{t_2}(\tilde{at}_i),i\in[M])$ is a regular binary string. If $\pi_{t_2}^{j}$ is chosen, the binary string consists of $j-1$ consecutive 0 and $M+ 1-j$ consecutive 1. $Count(\cdot)$ measures the difference between $\tilde{\Gamma}_{s}$ and  $\hat{\Gamma}_{s}$. The goal is to find $\pi_{c_2}^{j},j\in[M]$ that minimizes $Count(\cdot)$. 

% \textcolor[rgb]{0.5,0.6,0.7}{ For each component $c_t$, assuming there are $M$ non-zero and non-repeated $\pi_{c_t}^{j},j\in[M]$. $\pi_{c_t}^j$ corresponds to a proprietary plan for $\mathcal{A}_j$. If $\pi_{c_t}^j$ is selected, then all $\mathcal{A}_i$ ($i$$\neq$$j$) are affected.  (An illustration in Figure~\ref{fig:heuristic_operator} is $t_2$). Theorem below describes what happens to the \textit{attacked set} of all $\mathcal{A}_i$, $i$$\neq$$j$ if an $\pi_{c_t}^j$ is selected:}
\begin{figure*}[!t]
\centering
\includegraphics[width=.8\textwidth]{figures/heuristic_operator.pdf}
\caption{The illustration and visualization of Lemma~\ref{pro:property1.2} at the top and BSM details at the bottom. As shown in the top half, assume the coverage vector allocated on targets in $\Gamma$ is $(c_1,\ldots,c_{\vert\Gamma\vert})$, and all elements are incrementally sorted by $c_i$. If an allocation $c_2$ changes to $c_2'$, the $\Gamma$ changes to $\Gamma\setminus \{t_2\}$ or $\{t_2\}$ according to the value of $c_2$ and $c_2'$. 
As shown in the bottom half, the right part analyzes the $\bm{\tilde{at}}$ corresponding to $\bm{\pi}^j$, the left part calculates $\bm{\hat{at}}$, and the $Count(\cdot)$ calculates the distance between $\bm{\hat{at}}$ and $\bm{\tilde{at}}$. Specifically, suppose $M$ attackers provide target $t_2$ with $M$ alternatives $( \pi_{c_2}^1,\ldots,\pi_{c_2}^M)$ by ascending order. 
If $\mathcal{D}$ finally selects $\pi_{c_{2}}^{j}$ (orange) as $c_{2}^*$, the $\Gamma$ of each $\mathcal{A}_i$ changes depending the rule described in the top half. E.g., the $\Gamma$ of all $\mathcal{A}_i$ in yellow becomes $\Gamma\setminus \{t_2\}$, since $\pi_{c_2}^j>\pi_{c_2}^i$.
% then the $\Gamma$ corresponding to $\mathcal{A}_j$ (orange) remains unchanged, and then the $\Gamma$ corresponding to all $\mathcal{A}_i$ (yellow) to the left of $\mathcal{A}_j$ become $\Gamma= \Gamma\setminus \{t_2\}$ and the $\Gamma$ corresponding to the right of $\mathcal{A}_j$ (green) becomes $\Gamma=\{t_2\}$. 
In addition, if $\mathcal{A}_i$'s attacked target is $t_2$, then $\bm{1}_{t_2}(at_i)=1$. Otherwise, then $\bm{1}_{t_2}(at_i)=0$. According to Lemma~\ref{pro:property1.2}, the $\Gamma$ of each $\mathcal{A}_i$ in yellow must not contain $t_2$, while the $\Gamma$ of each $\mathcal{A}_i$ in orange and green must contain $t_2$. Therefore, the $\bm{1}_{t2}(\cdot)$ value of blue area equals 0 while the $\bm{1}_{t2}(\cdot)$ value of red and green areas equals 1.}
\label{fig:heuristic_operator}
\end{figure*}

% pseudo-code
\begin{algorithm}
\caption{Bit-wise Optimization (BitOpt)}
\label{alg:pseudo2} 
\begin{algorithmic}[1]
    \REQUIRE $count_1$, $P$, $t$, $\bm{I}$, $\bm{A}$, $\bm{\hat{at}}$.
    \ENSURE 
    \STATE$\bm{c}^*\gets\ 0$.
    
    \small\textcolor{Green}{\% If there's only one $alternative$ (i.e., $\vert\bm{\pi_{c_t}}\vert=1$), choose it as $\bm{c}^*$. Otherwise, choose the one most similar to $\bm{\hat{at}}$.}
    \IF{$count_1=1$}
        \STATE$obj = P[t][0]$.
        \STATE$x = U^{u,a}_{obj}(\bm{A}_{[obj]}[I[obj]-1])$.
        \STATE$\bm{c}^* = \frac{x-U_{obj}^{u,a}(t)}{U_{obj}^{c,a}(t)-U^{u,a}_{obj}(t)}$.
    \ELSIF{$count_1>1$}
        \STATE$\pi_{obj}:List[int] = P[t]$.
        % $\bm{\pi_{L}}:List[int] = I[\pi_{obj}]$.
        \STATE$\bm{x} = ( U^{u,a}_{obj}(\bm{A}_{[obj]}
        [I[obj]-1]),obj\in\pi_{obj})$.
        \STATE$\pi_{c_t} = (\frac{x[obj]-U_{obj}^{u,a}(t)}{U_{obj}^{c,a}(t)-U^{u,a}_{obj}(t)},obj\in\pi_{obj})$.
        % $U^a(alternatives_{\hat{c}})$, where $\hat{c}$ is the unreachable coverage vector
        \STATE sort $\bm{\hat{at},\pi_{c_t}}$ in ascending order of value by $\pi_{c_t}$.
        \STATE$\bm{count}_2:shapelike(\pi_{c_t})\gets$ the zero distance counter between $\tilde{\Gamma}_{s}$ and $\hat{\Gamma}_{s}$.
        %, whose shape is as same as $alternatives_{c}$.

        \small\textcolor{Green}{\% Boolean Scoring Mechanism (BSM) part.}\\
        \small\textcolor{Green}{\% Update $\bm{count}_2[obj]$ based on $target$'s relationship to $\hat{\bm{at}}[obj-1]$ and $\hat{\bm{at}}[obj]$.}
        \FOR{$1\leq obj < \vert\pi_{obj}\vert$} \label{code:alg2:12}
            \STATE$count_2[obj] = \bm{count}_2[obj - 1]$.
            \IF{$\hat{\bm{at}}[obj-1]\neq t$}
                \STATE$\bm{count}_2[obj]\ +=\ 1$.
            \ENDIF
            \IF{$\hat{\bm{at}}[obj]\neq t$}
                \STATE$\bm{count}_2[obj]\ -=\ 1$.
            \ENDIF
        \ENDFOR \label{code:alg2:20}
        \STATE$c^*=\pi^{idx}_{c_t}, idx=\mathop{\arg\min}_i \bm{count}_2[i]$.
    \ENDIF
    \STATE\textbf{return} $\bm{c}^*$. \small\textcolor{Green}{\% the best alternative for component $c_t$}
\end{algorithmic}
\end{algorithm}

\section{Proof Details}
% In this section, 
\label{app:proof}
\subsection{The Proof of Lemmas and Theorems in Section~\ref{sec:met}}
\label{app:proof:method}
\lemmaSGperspective*
Lemma~\ref{pro:property1.2} shows that $\bm{v}$ in $\bm{c}$ may cause a sharp change in $\Gamma(\bm{c})$. Since the resource allocation between different targets is independent, we only discuss $\bm{v}$ with one non-zero component $v_{t'}$. Note that if $\bm{v}$ is a zero vector, $\Gamma$ does not change, i.e., $\Gamma(\bm{c})=\Gamma(\bm{c}+\bm{v})$. In SGs, $\mathcal{A}_i$ only attacks the most attractive target $at_i$ ($at\in\Gamma(\bm{c})$). The reason for Lemma~\ref{pro:property1.2} is two-fold: 
% at表示attacked target，单个英文符号基本都被用了，如果不合适就换成希腊字母
(i) If the resource allocation is adjusted so that $at$ is no longer the most attractive target (i.e., $at\notin \Gamma(\bm {c}+\bm{v})$), then $U_i^d(\bm {c}+\bm{v})$ changes dramatically. 
% 式子指防御者的最佳响应
(ii) Although the targets that can not return the maximum $U_i^d$ are moved out of $\Gamma$, since the nature of Max function, $U_i^d(\bm {c}+\bm{v})$ would not change. The proof detail of Lemma~\ref{pro:property1.2} is
\begin{proof}\label{pro:property1.2 proof}
% \proof\label{pro:property1.2 proof}
% {
% In the proof, Equation~\eqref{equ:equation1} and~\eqref{equ:equationBRa} are often used to calculate $U_i^a(c_t)$ and $\Gamma(\bm{c})$. We call the resources' minor variation $\bm{v}$, the index of the non-zero component $t'$ (if $\bm{v}$ has), and the $\Gamma(\bm{c})$ size $\vert\Gamma\vert$. 
We categorize the cases into (i) If $v_{t'}$ is allocated to the target $t'\notin\Gamma(\bm{c})$, then $\Gamma$ does not be affected. (ii) Otherwise, the change rules of $\Gamma(\bm{c})$ can be formally described.

If $t'\notin\Gamma(\bm{c})$, since the best responses of all $\mathcal{A}_i$ and $\mathcal{D}$ only come from $\Gamma(\bm{c})$, any minor variation $v_{t'}$ dose not influence $\Gamma$ calculation, i.e., $\Gamma(\bm{c}+\bm{v})=\Gamma(\bm{c})$. 

If $t'\in\Gamma(\bm{c})$, 
    % 最后一张图
an illustration is given in the top of Figure~\ref{fig:heuristic_operator}. 
% The resources allocated on $\Gamma(\bm{c})$ are denoted as $\bm{c}' = ( \bm{c}'_i, i \in [\vert\Gamma\vert])$. 
Note that according to the definition of $\Gamma(\bm{c})$ in Equation~\eqref{equ:equationBRa}, $\Gamma$ be $U_i^a(c_j) = U_i^a(c_i)$, $\forall j,i\in[\vert\Gamma\vert]$. If $v_{t'}\neq0$, then $U_i^a(c_{t'})\neq U_i^a(c_i),\forall i\in[\vert\Gamma\vert],i\neq t'$.
    
In general, we summarize how $v_{t'}$ changes $\Gamma$. If $v_{t'}>0$, $\mathcal{D}$ allocates more resources on $t'$, so $\mathcal{A}_i$ gains less, i.e., $U_i^a(c_{t'}+v_{t'})<U_i^a(c_j),j\in[\vert\Gamma\vert]$, $j\neq t'$. Therefore,  $\Gamma (\bm{c} + \bm{v}) = \Gamma(\bm{c}) \setminus\{t'\}$. Similarly, if $v_{t'}<0$, $\mathcal{A}_i$ gains more, i.e., $U_i^a(c_{t'})>U_i^a(c_j),j\in[\vert\Gamma\vert]$, $j\neq t'$. Therefore, $\Gamma(\bm{c}+\bm{v})=\{t'\}$.
% }
\end{proof}

% \subsection{The Proof of Lemma~\ref{pro:property1.1}}
% \label{app:proof:2}
\lemmaoptperspective*
\begin{proof}\label{pro:property1.1 proof}
Two parts are used to proof Lemma~\ref{pro:property1.1}. In the first part, we categorize the cases based on whether $at_i$ still in $\Gamma(\bm{c}+\bm{v})$ after the resource changes from $\bm{c}$ to $\bm{c}+\bm{v}$. In the second part, if defender payoff changes, then the lower bound of the change $gap_i$ is provided.
% , where $gap_i$ is defined as $gap_i=|U^d_i(\bm{c})-U^d_i(\bm{c}+\bm{v})|$.

For the first part, from Equation~\eqref{equ:equationBRd}, $\mathcal{D}$'s payoff $U^d_i(\bm{c})$ is yielded by only one target $at_i\in\Gamma(\bm{c})$. Therefore, if $at_i$ still in $\Gamma(\bm{c}+\bm{v})$ when $\bm{c}$ changes to $\bm{c}+\bm{v}$, then $U_i^d(\bm{c}+\bm{v})$$=$$U_i^d(\bm{c})$. While if $at_i$ is no longer in $\Gamma(\bm{c}+\bm{v})$, then $U_i^d(\bm{c}+\bm{v})\neq U_i^d(\bm{c})$.
    
Lemma~\ref{pro:property1.2} has discussed in detail how $\Gamma$ changes as \textit{converge vector} from $\bm{c}$ to $\bm{c}+\bm{v}$. $\Gamma(\bm{c}+\bm{v})$ can be mathematically described with $\Gamma(\bm{c})$ and $t'$ ($v_{t'}\neq0$): 
If $t'\notin\Gamma(\bm{c})$, then $U^d_i(\bm{c}+\bm{v})=U^d_i(\bm{c})$; If $t'\in\Gamma(\bm{c})$ and $at_i\in\Gamma(\bm{c}+\bm{v})$, then $U^d_i(\bm{c}+\bm{v})=U^d_i(\bm{c})$; If $t'\in\Gamma(\bm{c}+\bm{v})$ and $at_i\notin\Gamma(\bm{c}+\bm{v})$, then $U^d_i(\bm{c}+\bm{v})\neq U^d_i(\bm{c})$.

In general, if $t'\in\Gamma_i(\bm{c})$ and $v_{t'}\neq 0$, then $\Gamma(\bm{c}+\bm{v})\neq\Gamma(\bm{c})$, and if  $t'\notin\Gamma_i(\bm{c})$, then $\Gamma(\bm{c}+\bm{v})=\Gamma(\bm{c})$. Note that if $v_{t'}=0$, then $\Gamma(\bm{c}+\bm{v})=\Gamma(\bm{c})$ because $\bm{v}$ is a zero vector.

For the second part, given $\Gamma(\bm{c})$, its $at_i=\mathop{\arg\max}_{t\in\Gamma(\bm{c})} U^d_i(c_t)$, and $\Gamma(\bm{c}+\bm{v})$, firstly, $\Gamma(\bm{c}+\bm{v})\subseteq\Gamma(\bm{c})$ because of the ideal solution $\{\bm{\hat{c}}^{1},\ldots,\bm{\hat{c}}^{N}\}$. Secondly, $U^d_i(\bm{c})=\max_{t\in\Gamma(\bm{c})} U^d_i(c_t)=U^d_i(c_{at})$, because $\mathcal{D}$ can induce $\mathcal{A}_i$ to attack any target in $\Gamma(\bm{c})$. Finally, $U^d_i(\bm{c}+\bm{v})\neq U^d_i(\bm{c})$ means that the original $at_i$ no longer in $\Gamma(\bm{c}+\bm{v})$. Therefore, $U^d_i(\bm{c}+\bm{v})$ satisfies: 
    
\begin{equation}
U^d_i(\bm{c}+\bm{v}) =\max_{t\in\Gamma(\bm{c}+\bm{v})} U^d_i(c_t) \leq\max_{t\in\{\Gamma(\bm{c})\setminus\{at\}\}}U^d_i(c_t)\,.
\end{equation}

If $U^d_i(\bm{c}+\bm{v})\neq U^d_i(\bm{c})$, then $U^d_i(\bm{c})=\max_{t\in\Gamma(\bm{c})}U^d_i(c_t)$, $U^d_i(\bm{c}+\bm{v})$ $\leq$ $\max_{t\in\{\Gamma(\bm{c})\setminus\{at\}\}}U^d_i(c_t)$, and $gap_i$ satisfy:

\begin{equation}
gap_i = \max_{t\in\Gamma(\bm{c})}U^d_i(c_t) - \max_{t\in\{\Gamma(\bm{c})\setminus\{at\}\}}U^d_i(c_t)\,.
\end{equation}
\end{proof}

\lemmaoptimalexpansion*
\theoremdiscretization*
The proof of Theorem~\ref{obs:observation1} can be derived from the optimal expansion rules in Lemma~\ref{pro:property2}~\citep{ERASER}. 
In the Stackelberg game with multiple heterogeneous attackers, each attacker ultimately attacks only one target (without loss of generality because SSE always exists). In the fully rational SGs, $\mathcal{A}_i$ only focus on targets returning the maximal $U^a_i$, which is defined as $\Gamma_i$. 
% Meanwhile, based on SSE, the maximal indifference property points out that attackers choose the optimal strategy that favors the defender to break the tie. 
Namely, the attacker's intentions are predictable. 

The optimal expansion rule can provide $N$ candidate attack sets with sizes from 1 to $T$, in which an optimal attack set always exists no matter how many resources the defender owns because of SSE~\citep{SSE}.

\subsection{The Proof of Lemmas and Theorems in Section~\ref{sec:val_ana}}
\label{app:proof:3}
\lemmaTheoAnal*
\begin{proof}
From SSE assumption, there is an observation from~\citep{ERASER}. The optimal $\mathcal{D}$'s payoff for defending $\mathcal{A}$ is derived from the target in $\mathcal{A}$'s $\Gamma$, thus if $\Gamma(\bm{c})\subseteq\Gamma(\bm{c}')$ and $c_t=c_t'$, $\forall t\in\Gamma(\bm{c})$, then $U_i^d(\bm{c})\leq U_i^d(\bm{c}')$.

For Lemma~\ref{lem:lemma1}, since $\Gamma$ is constructed from the optimal expansion rule (i.e., add $t$ to $\Gamma$ in descending order of $U_i^a(c_t)$), if $\Gamma(\bm{c}')$ is larger than $\Gamma(\bm{c})$, then we have $\Gamma(\bm{c})\subseteq\Gamma(\bm{c}')$ and $c'_t\geq c_t,\forall t\in\Gamma(\bm{c})$. Let's discuss them in categories (i) $c'_t=c_t$ and (ii) $c'_t>c_t$. 

\begin{itemize}
    \item [(i)]  
    According to the observation in~\citep{ERASER}, if $\Gamma(\bm{c})\subseteq\Gamma(\bm{c}')$ and $c_t=c_t'$, $\forall t\in\Gamma(\bm{c})$, then $U_i^d(\bm{c})\leq U_i^d(\bm{c}')$.
    
    \item[(ii)] If $c'_t>c_t$, since the more resources allocated to $t$ the higher the payoff of the defender ($U^d$), the observation in~\citep{ERASER} still holds.
\end{itemize}
\end{proof}

\obsalgorithmfir*
% \begin{proof}
Since both $\tilde{\bm{c}}$ and $\hat{\bm{c}}^i$ are constructed from the optimal expansion rule according to Lemma~\ref{pro:property2}, the size of $\Gamma$ corresponds to the content of $\Gamma$ (i.e., the content of $\Gamma$ must be in descending order by $U_i^a(c_t)$). $\Vert\tilde{\bm{c}}\Vert_1\leq\Vert\hat{\bm{c}}^i\Vert_1$ means that $\hat{\bm{c}}^i$ has more resources and $\mathcal{D}$ can protect more targets (i.e., $\Gamma$ becomes larger). Therefore, if $\Vert\tilde{\bm{c}}\Vert_1\leq\Vert\hat{\bm{c}}^i\Vert_1$, then $\Gamma_i(\bm{\tilde{c}})\subseteq\Gamma_i(\bm{\hat{c}}^{i})$, because of the optimal expansion rule. Meanwhile, if $\Vert\tilde{\bm{c}}\Vert_1\leq\Vert\hat{\bm{c}}^i\Vert_1$ and $\Gamma_i(\bm{\tilde{c}})\subseteq\Gamma_i(\bm{\hat{c}}^{i})$, then $U_i^d(\bm{\tilde{c}})\leq U_i^d(\bm{\hat{c}}^{i})$, according to Lemma~\ref{lem:lemma1}. Finally, since each component $U_i^d(\hat{\bm{c}})$ is constructed by using all resources to defending $\mathcal{A}_i$, $U_i^d(\hat{\bm{c}})$ is the upper bound of any strategy for defending $\mathcal{A}_i$. Therefore, $(U_i^d(\hat{\bm{c}}^1),\ldots,U_i^d(\hat{\bm{c}}^N))$ cannot be dominated by any strategy on the PF.
% \end{proof}

% \obsalgorithmsec*
\obsalgorithmthi*
\begin{proof}
The difference of \textit{attack set} and \textit{attack group} lies in model type of SGs. Attack set focuses on single-objective modeling with one attacker, while attack group focuses on multi-objective modeling with multiple attackers. Conclusions in attack set perspective can easily be extended to conclusions in attack group perspective, because the attackers are independent of each other. The discussion below focuses on conclusions in the attack set perspective.

Under SSE assumption, $\mathcal{A}_i$ finally attacks only one target $at_i$ returning best payoff. $at_i\in\Gamma_i$ means that $at_i$ is protected by $\mathcal{D}$. $\tilde{\Gamma}_i$, $\hat{\Gamma}_i$ correspond to the attack set of feasible solution $\tilde{\bm{c}}$ and ideal solution $\{\bm{\hat{c}}^{1},\ldots,\bm{\hat{c}}^{N}\}$ respectively. $at_i\in\tilde{\Gamma}_i$ and $at_i\in\hat{\Gamma}_i$ means that both $\tilde{\bm{c}}$ and $\hat{\bm{c}}^i$ can protect $at_i$. Therefore, the divergence $K(\tilde{\Gamma}_i, \hat{\Gamma}_i)$ calculation is determined by $at_i$ but not all elements of $\tilde{\Gamma}_i$, $\hat{\Gamma}_i$.

As for Theorem~\ref{obs:algorithm3}, $\tilde{\Gamma}_i$ is similar to $\hat{\Gamma}_i$ means that both $\tilde{\bm{c}}$ and $\hat{\bm{c}}^i$ allow $\mathcal{D}$ to protect $c_i$ from $\mathcal{A}_i$. Meanwhile, since $\tilde{\bm{c}}$ and $\hat{\bm{c}}^i$ are constructed according to the optimal expansion rule, the feasible solution obtains the same payoff as ideal solution if $at_i\in\tilde{\Gamma}_i$ and $at_i\in\hat{\Gamma}_i$. Finally, from Lemma~\ref{obs:algorithm1}, $(U_i^d(\hat{\bm{c}}^1),\ldots,U_i^d(\hat{\bm{c}}^N))$ cannot be dominated by any feasible strategy. If there is a feasible strategy $\tilde{\bm{c}}$ can achieve $(U_i^d(\hat{\bm{c}}^1),\ldots,U_i^d(\hat{\bm{c}}^N))$, then $\tilde{\bm{c}}$ is the solution on the PF.

Meanwhile, Lemma~\ref{lem:lemma1} has been supplemented by Theorem~\ref{obs:algorithm3}. In detail, even though $\tilde{\Gamma}_i\subseteq\hat{\Gamma}_i$, if they have the same $at_i$, then they are similar and have the same payoff. Namely, the feasible solution $\tilde{\bm{c}}$ can achieve the upper bound, i.e., $(U_i^d(\hat{\bm{c}}^1),\ldots,U_i^d(\hat{\bm{c}}^N))$.
\end{proof}


\splitassumption*
\theoremRatBitbybit*
\begin{proof}
Theorem~\ref{obs:val_ana1} shows that the upper bound $(U_i^d(\hat{\bm{c}}^1),\ldots,U_i^d(\hat{\bm{c}}^N))$ can be achieved by $\tilde{\bm{c}}$ as long as $\tilde{\Gamma}$ contains all $\mathcal{A}$'s attacked targets $\bm{at}$. In the top half of Figure~\ref{fig:heuristic_operator}, it describes what happened to the $\Gamma$ when the resources on $t\in\Gamma$ changes. Specifically, suppose $c_2$ changes to $c_2'$. If $c_2'>c_2$, then $\Gamma=\Gamma\setminus \{t_2\}$. If $c_2'<c_2$, then $\Gamma=\{t_2\}$. In the bottom half of Figure~\ref{fig:heuristic_operator}, it describes what happened to $\Gamma$ when choosing $\pi_{c_2}^j$ from $\pi_{c_2}$. Suppose $\pi_{c_2}$ is sorted in increasing order. If $\pi_{c_2}^j$ is selected, the $\Gamma$ corresponding to all $\pi_{c_2}^i$ less than $\pi_{c_2}^j$ is $\Gamma=\Gamma\setminus \{t_2\}$, and the $\Gamma$ corresponding to all $\pi_{c_2}^i$ greater than $\pi_{c_2}^j$ is $\Gamma=\{t_2\}$. To ensure $\Gamma$ contains all $\bm{at}$, we summarize the following conditions
% \begin{Assumption}\label{obs:val_ana2}
% % \begin{observation}\label{obs:val_ana2}
% % \observation\label{obs:val_ana2}
% % {
% During the process of BitOpt, suppose $\pi_{c_t}^j$ is selected. For all $\pi_{c_t}^i$ less than $\pi_{c_t}^j$, $at_i$ of $\mathcal{A}_i$ is not $t$, and for all $\pi_{c_t}^i$ greater than $\pi_{c_t}^j$, $at_i$ of $\mathcal{A}_i$ is $t$. 
% % }
% % \end{observation}
% \end{Assumption}

If BitOpt subjects to Assumption~\ref{asp:BitOpt}, all $\bm{at}$ dose not affected. As longe as all $\bm{at}$ dose not affected when searching each $c_i^*\in\{\pi_{c_i}^1,\ldots,\pi_{c_i}^N\}$, $\bm{c}^*$ can achieve the upper bound by Theorem~\ref{obs:algorithm3}.  Finally, by Theorem~\ref{obs:algorithm3}, the solutions found by BitOpt must on the true PF.
% Specially, 
% In Appendix~\ref{app:fra_pseu_BSM}, we illustrates the influence details of $\pi_{c_t}$ on $\bm{at}$ in Figure~\ref{fig:heuristic_operator} and displays the solution convergence conditions of bit-wise optimization in Theorem~\ref{obs:val_ana2}.

\end{proof}

\section{Additional Experimental Details and Results}
\subsection{More Details about Experiment Setup}
\label{app:expset}
\subsubsection{Hyperparameter Setup}

% 还要说明迭代论数和种群大小的影响
SDES has a few hyperparameters needed to tune, including $max\_{}gen$ and $pop\_{}size$. On the one hand, we set $max\_{}gen=300$ in all MOSG problems. Figure~\ref{fig:convergence_curve} shows the fast convergence speed of our method (within 50 iterations), so 300 iterations are able to ensure algorithm convergence. Meanwhile, SDES is insensitive to $max\_{}gen$ because of the linear complexity with both target and heterogeneous attacker dimensions. On the other hand, $pop\_{}size$ determines the granularity of the subspace, i.e., $\vert\tilde{C}\vert$. The larger $pop\_{}size$, the better the space distribution. Although solution quality is guaranteed, the relationship between $pop\_{}size$ and runtime is undetermined. Section~\ref{app:more_time_effi} further analyze the effect of increasing $pop\_{}size$ on runtime.

\subsubsection{Implementation Setup of NSGA-III in the Optimization Component of SDES}
\label{app:NSGA-III}
The basic configuration of NSGA-III includes sampling=Int Random Sampling, selection=Tournament Selection, crossover=Simulated Binary Crossover or Half Uniform Crossover (we choose SBX in this paper), Mutation=Int Polynomial Mutation. The implementation of NSGA-III uses an open-source framework: multi-objective optimization in Python\footnote{The document and code are available at \url{https://pymoo.org/index.html}.}~\citep{pymoo} (PyMOO). In PyMOO, crossover rate, mutation rate, and other hyperparameter use default values, and the final result saves all non-dominated solutions in the iteration process. The pseudocode of each generation of NSGA-III is shown in Algorithm~\ref{app:alg:NSGA-III}~\citep{NSGA-III}.

In addition, the NSGA-III in the optimization component of SDES uses fixed population size and generation number. Specifically, since Riesz can adaptively provide a set of well-spaced reference direction, the many-objective EA with a fixed but sufficiently large population size is still able to find a well-spaced PF. Meanwhile, the ORIGAMI method is shown to converge a single solution in constant generations~\citep{MOSG}.

\begin{algorithm}
    \caption{Generation $t$ of NSGA-III Procedure}
    \label{app:alg:NSGA-III}
    \begin{algorithmic}[1]
        \REQUIRE $H$ structured reference points $Z^s$ or supplied aspiration points $Z^a$, parent population $P_t$.
        \ENSURE
        
        \STATE $S_t=\emptyset$, $i=1$.
        \STATE $Q_t=$ Crossover+Mutation$(P_t)$.
        \STATE $R_t=P_t\cup Q_t$
        \STATE $(F_1,F_2,\ldots)=$ Non-dominated-sort$(R_t)$.
        \REPEAT
        \STATE $S_t=S_t\cup F_i$ and $i=i+1$.
        \UNTIL{$\vert S_t\vert\geq N$} 
        \STATE Last front to be included: $F_l=F_i$.
        \IF{$\vert S_t\vert=N$}
        \STATE $P_{t+1}=S_t$, \textbf{return} $P_{t+1}$.
        \ELSE
        \STATE $P_{t+1}=\cup_{j=1}^{l-1}F_j$.
        \STATE Points to be chosen from $F_l$: $K=N-\vert P_{t+1}\vert$.
        \STATE Normalize objectives and create reference set $Z^r$: $Normalize(\bm{\mathrm{f}}^n,S_t,Z^r,Z^s,Z^a)$.
        \STATE Associate each member $\bm{s}$ of $S_t$ with a reference point: $[\pi_{\bm{s}},d(\bm{s})]=Associate(S_t,Z^r)$.  \small \textcolor{Green}{\% $\pi(\bm{s})$: closest reference point, $d$: distance between $\bm{s}$ and $\pi(\bm{s})$}
        \STATE Compute niche count of reference point $j\in Z^r$: $\rho_j=\sum_{\bm{s}\in S_t/F_l}((\pi(\bm{s})=j)\,?\,1:0)$. \small \textcolor{Green}{\% $((\cdot)\,?\,1:0)$: if $(\cdot)$ is true then return $1$, otherwise return $0$}
        \STATE Choose $K$ members one at a time from $F_l$ to construct $P_{t+1}$: $Niching(K,\rho_j,\pi,d,Z^r,F_l,P_{t+1})$
        \ENDIF
        \STATE \textbf{return} $P_{t+1}$.
    \end{algorithmic}
\end{algorithm}


\subsubsection{Solution Initialization of SDES}
The initialization of solutions is also the result of the discretization component of SDES. According to the definition of $\Gamma_s$, the solution initialization can be defined as a $N$-integers random vector $\bm{I}$, $I_i\in[T]$. However, due to limited resources and other reasons, the scenario $I_i=T$ (all targets are added to $\Gamma_i$) generally does not appear in real problems. Therefore, we can optimize the initialization with redundancy as follows: Firstly, calculate the maximum attack set  $\vert\Gamma_i\vert_{max}$ that can be obtained by allocating all resources for defending $\mathcal{A}_i$. Secondly, initialize $I_i\in[\vert\Gamma_i\vert_{max}]$. Each component of $\bm{I}$ means the size of attacker set $\Gamma$.


\subsection{More Details about Effectiveness Experiments}
\label{app:more_eff_exp}

% 说明为什么把N=3也考虑进来
We show the details of the effectiveness experiment, cf. Section~\ref{sec:effe:part2}, in Table~\ref{app:tab:performance:N=3},~\ref{app:tab:performance:N=4},~\ref{app:tab:performance:N=5},~\ref{app:tab:performance:N=6},~\ref{app:tab:performance:N=7}, and~\ref{app:tab:performance:N=8}, including \textit{HV}, \textit{IGD}$^+$ scores and ranks of all methods and the constructed PF. The problem scale is $N=[3,\ldots,8]$, $T=[25,\ldots,1000]$. We further consider the $N=3$ case, although it does not conform to the provisions of MaOPs ($N>3$). That is because all the comparison algorithms fail successively When the objective dimension increases. Specially, comparison algorithms fail when $T\geq600$ in $N=4$ case, $T\geq100$ in $N=5,6$ case, $T\geq50$ in $N=7$ case, and $T\geq25$ in $N=8$ case. The exponential growth in time consumption of comparison algorithms limited the content we could analyze, so we also showed the experiment with $N=3$. 

Table~\ref{app:tab:performance:N=3},~\ref{app:tab:performance:N=4},~\ref{app:tab:performance:N=5},~\ref{app:tab:performance:N=6},~\ref{app:tab:performance:N=7}, and~\ref{app:tab:performance:N=8},  show the \textit{HV} and \textit{IGD}$^+$ indicators of SDES and comparison algorithms on different problem scales. \textit{HV} and \textit{IGD}$^+$ are relative indicators: the larger \textit{HV}, the better the algorithm, while \textit{IGD}$^+$ is the opposite. As result, when the problem size is small, all the algorithms can complete within the maximum time $M=30$ mins. However, as the problem scale grows, methods fail in sequence: 
ORIGAMI-M-BS $\prec$ ORIGAMI-A $\prec$ ORIGAMI-M $\prec$ DIRECT-MIN-COV $\prec$ SDES. 
The symbol - means the runtime of the corresponding algorithm is out of $M$ in Table~\ref{app:tab:performance:N=3}$\sim$~\ref{app:tab:performance:N=8}. 

As results, SDES achieve rank-1 in all MOSG problems in $N=3,4,6,7,8$ cases, except $N=5$. In $N=5$ case, SDES achieve 2 rank-1, 3 rank-2, 2 rank-3, 1 rank-4. The reason for the poor performance of SDES is (i) the SOTA methods are exact algorithms. Although they face the curse of dimension, they performance very well in medium-scale problems. (ii) $N=5$ happens to be the last problem scale for the SOTA methods to time out. They produce enough high-quality solutions in a limited time. However, they cannot accomplish larger problem scales because of the curse of dimensionality.

\begin{table*}[]
\caption{Multi-objective performance indicator of SDES and comparison algorithms across all problem scales in $N=3$}
\label{app:tab:performance:N=3}
\begin{adjustbox}{width=\textwidth}
\centering
\begin{tabular}{lrrrrrrrr}
\toprule
        \multicolumn{1}{c}{\textbf{$N=3$}} & \multicolumn{2}{c}{\textbf{$T=25$}} & \multicolumn{2}{c}{\textbf{$T=50$}} & \multicolumn{2}{c}{\textbf{$T=75$}} & \multicolumn{2}{c}{\textbf{$T=100$}} \\  
        \multicolumn{1}{c}{\textbf{$\bm{Method}$}} & $HV$/Rank & $IGD^{+}$/Rank & $HV$/Rank & $IGD^{+}$/Rank & $HV$/Rank & $IGD^{+}$/Rank & $HV$/Rnak & $IGD^{+}$/Rank \\ 
        \midrule
        PF & 243 & 0 & 1480 & 0 & 2163 & 0 & 2201 & 0 \\  
        %\tabincell{l}{SDES \\heuristic operator} & 172 & 1.25 & 147 & 1.88 & 114 & 1.13 & 94 & 2.31 \\  
        \textbf{SDES} & \textbf{180}{\scriptsize $\pm$2}/1 &  \textbf{0.27}{\scriptsize $\pm$0.00}/1 & \textbf{680}{\scriptsize $\pm$514}/1 & \textbf{0.69}{\scriptsize $\pm$0.46}/1 & \textbf{868}{\scriptsize $\pm$512}/1 & \textbf{0.74}{\scriptsize $\pm$0.33}/1 & \textbf{754}{\scriptsize $\pm$492}/1 &  \textbf{0.97}{\scriptsize $\pm$0.39}/1 \\  
        ORIGAMI-M & 172/4 & 0.48/3 & 318/3 & 1.57/3 & 377/2 & 1.78/3 & 403/2 & 1.54/3 \\  
        ORIGAMI-A & 179/2 & 0.45/2 & 323/2 & 1.54/2 & 365/3 & 1.74/2 & 397/4 & 1.52/2 \\  
        ORIGAMI-M-BS & 148/5 & 0.78/5 & 232/5 & 1.89/5 & 286/5 & 2.25/4 & 279/5 & 2.26/5 \\  
        DIRECT-MIN-COV & 174/3 & 0.57/4 & 293/4 & 1.87/4 & 323/4 & 2.43/5 & 401/3 & 1.79/4 \\
        \textbf{RANK(OURS)}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}\\
        
        \midrule
        \multicolumn{1}{c}{\textbf{$N=3$}} & \multicolumn{2}{c}{\textbf{$T=200$}} & \multicolumn{2}{c}{\textbf{$T=400$}} & \multicolumn{2}{c}{\textbf{$T=600$}} & \multicolumn{2}{c}{\textbf{$T=800$}} \\ \midrule
        PF & 1161 & 0 & 1642 & 0  &1549  &0&1209 &0\\  
        %\tabincell{l}{SDES without \\heuristic operator} & 48 & 4.06 & 41 & 3.06  & ~ & ~ & ~ & ~ \\  
        \textbf{SDES} & \textbf{640}{\scriptsize $\pm$230}/1 & 1.07{\scriptsize $\pm$0.43}/1 & \textbf{1107}{\scriptsize $\pm$298}/1 & \textbf{0.57}{\scriptsize $\pm$0.40}/1  & \textbf{863}{\scriptsize $\pm$497}/1 & \textbf{0.53}{\scriptsize $\pm$0.49}/1 & \textbf{728}{\scriptsize $\pm$199}/1 & \textbf{0.57}{\scriptsize $\pm$0.36}/1\\  
        ORIGAMI-M & 457/3 & 1.19/2 & 557/3 & 1.80/3  &290/2 &1.58/3 & 447/2 & 1.70/3\\  
        ORIGAMI-A & 426/4 & 1.32/3 & \multicolumn{2}{c}{--}&\multicolumn{2}{c}{--}&\multicolumn{2}{c}{--}\\  
        ORIGAMI-M-BS & 415/5 & 1.47/5 & 535/4 & 2.02/4  & 265/4 & 1.57/2  & 388/3 &1.63/2\\  
        DIRECT-MIN-COV & 483/2 & 1.36/4 & 655/2 & 1.66/2  & 267/3 &1.89/4 &\multicolumn{2}{c}{--}\\ 
        \textbf{RANK(OURS)}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1} &\textbf{1}\\

        \midrule
        \multicolumn{1}{c}{\textbf{$N=3$}} & \multicolumn{2}{c}{\textbf{$T=1000$}}\\ \midrule
        PF & 609 & 0 &  &  &  &&\\  
        %\tabincell{l}{SDES without \\heuristic operator} & 48 & 4.06 & 41 & 3.06  & ~ & ~ & ~ & ~ \\  
        \textbf{SDES} & \textbf{355}{\scriptsize $\pm$58}/1 & \textbf{0.72}{\scriptsize $\pm$0.27}/1 & &  & &&\\  
        ORIGAMI-M &\multicolumn{2}{c}{--} & & & &&\\  
        ORIGAMI-A & \multicolumn{2}{c}{--}&  &  & &&\\  
        ORIGAMI-M-BS & 212/2 & 1.69/2 &  & & && \\  
        DIRECT-MIN-COV &\multicolumn{2}{c}{--} & &  & && \\ 
        \textbf{RANK(OURS)}&\textbf{1}&\textbf{1}& & &&&\\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table*}


\begin{table*}[]
\caption{Multi-objective performance indicator of SDES and comparison algorithms across all problem scales in $N=4$}
\label{app:tab:performance:N=4}
\begin{adjustbox}{width=\textwidth}
\centering
\begin{tabular}{lrrrrrrrr}
\toprule
        \multicolumn{1}{c}{\textbf{$N=4$}} & \multicolumn{2}{c}{\textbf{$T=25$}} & \multicolumn{2}{c}{\textbf{$T=50$}} & \multicolumn{2}{c}{\textbf{$T=75$}} & \multicolumn{2}{c}{\textbf{$T=100$}} \\
        \multicolumn{1}{c}{\textbf{$\bm{Method}$}} & $HV$/Rank & $IGD^{+}$/Rank & $HV$/Rank & $IGD^{+}$/Rank & $HV$/Rank & $IGD^{+}$/Rank & $HV$/Rnak & $IGD^{+}$/Rank \\
        \midrule
        PF & 6.42e4 & 0 & 3.66e4 & 0 & 9.25e4 & 0 & 1.05e5 & 0 \\  
        %\tabincell{l}{SDES without \\heuristic operator} & 4366 & 1.06 & 9508 & 1.93 & 5063 & 2.77 & 34706 & 2.85 \\  
        \textbf{SDES} & \textbf{3.12e4}{\scriptsize $\pm$6018}/1 & \textbf{0.47}{\scriptsize $\pm$0.08}/1 & \textbf{2.31e4}{\scriptsize $\pm$3709}/1 & \textbf{0.52}{\scriptsize $\pm$0.13}/1 & \textbf{4.73e4}{\scriptsize $\pm$7691}/1 & \textbf{0.64}{\scriptsize $\pm$0.12}/1 & \textbf{5.15e4}{\scriptsize $\pm$9247}/1 & \textbf{0.56}{\scriptsize $\pm$0.14}/1 \\  
        ORIGAMI-M & 2.84e4/2 & 0.56/2 & 1.85e4/3 & 0.89/2 & 4.03e4/2 & 0.86/3 & 4.37e4/3 & 0.86/3 \\  
        ORIGAMI-A & 2.76e4/3 & 0.67/3 & 1.88e4/2 & 0.93/3 & 3.95e4/3 & 0.73/2 & 4.42e4/2 & 0.70/2 \\  
        ORIGAMI-M-BS & 2.38e4/5 & 1.06/4 & 1.61e4/5 & 1.30/4 & 3.45e4/4 & 1.24/4 & 3.85e4/4 & 1.06/4 \\  
        DIRECT-MIN-COV & 2.46e4/4 & 1.63/5 & 1.63e4/4 & 1.71/5 & 3.42e4/5 & 1.63/5 & 3.75e4/5 & 2.33/5 \\ 
        \textbf{RANK(OURS)}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}\\
        \midrule
        \multicolumn{1}{c}{\textbf{$N=4$}} & \multicolumn{2}{c}{\textbf{$T=200$}} & \multicolumn{2}{c}{\textbf{$T=400$}} &  \multicolumn{4}{c}{${T\geq600}$ $\textbf{TIMEOUT}$}\\  
        %\textbf{Method} & $\bm{HV}$/rank & $\bm{IGD^{+}}$/rank & $\bm{HV}$/rank & $\bm{IGD^{+}}$/rank & $\bm{HV}$/rank & $\bm{IGD^{+}}$/rank & \multicolumn{2}{c}{--} \\ 
        \midrule
        PF & 3.71e4 & 0 & 4.96e4 & 0 & \multicolumn{4}{c}{--} \\  
        %\tabincell{l}{SDES without \\heuristic operator} & 402660 & 1.66 & 125921 & 2.63 & 347040 & 2.53  & ~ & ~ \\  
        $\textbf{SDES}$ & \textbf{2.71e4}{\scriptsize $\pm$4658}/1 & \textbf{0.50}{\scriptsize $\pm$0.17}/1 & \textbf{3.04e4}{\scriptsize $\pm$4589}/1 & \textbf{0.86}{\scriptsize $\pm$0.18}/1 &  \multicolumn{4}{c}{--} \\  
        ORIGAMI-M & 2.06e4/2 & 0.66/2 & 2.56e4/2 & 1.01/2 & \multicolumn{4}{c}{--}\\  
        ORIGAMI-A & \multicolumn{2}{c}{--} & \multicolumn{2}{c}{--} & \multicolumn{4}{c}{--} \\  
        ORIGAMI-M-BS & 1.58e4/4 & 1.41/4 & \multicolumn{2}{c}{--} & \multicolumn{4}{c}{--} \\  
        DIRECT-MIN-COV & 1.97e4/3 & 1.25/3 & \multicolumn{2}{c}{--} & \multicolumn{4}{c}{--} \\ 
        \textbf{RANK(OURS)}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\multicolumn{4}{c}{--}\\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table*}

\begin{table*}[]
\caption{Multi-objective performance indicator of SDES and comparison algorithms across all problem scales in $N=5$}
\label{app:tab:performance:N=5}
\begin{adjustbox}{width=\textwidth}
\centering
\begin{tabular}{lrrrrrrrr}
\toprule
        \multicolumn{1}{c}{\textbf{$N=5$}} & \multicolumn{2}{c}{\textbf{$T=25$}} & \multicolumn{2}{c}{\textbf{$T=50$}} & \multicolumn{2}{c}{\textbf{$T=75$}} & \multicolumn{2}{c}{$T=100$}\\  
        \multicolumn{1}{c}{\textbf{$\bm{Method}$}} & $HV$/Rank & $IGD^{+}$/Rank & $HV$/Rank & $IGD^{+}$/Rank & $HV$/Rank & $IGD^{+}$/Rank & $HV$/Rnak & $IGD^{+}$/Rank \\
        \midrule
        PF & 6.46e4 & 0 & 7.73e4 & 0 & 2.30e6 & 0 & 1.59e6&0 \\  
        %\tabincell{l}{SDES without \\heuristic operator} & 402660 & 1.66 & 125921 & 2.63 & 347040 & 2.53  & ~ & ~ \\  
        $\textbf{SDES}$ & 5.03e5{\scriptsize $\pm$2.59e4}/3 & 0.85{\scriptsize $\pm$0.03}/4 & \textbf{5.61e5}{\scriptsize $\pm$1.23e5}/1 & 0.50{\scriptsize $\pm$0.06}/2 & 7.68e5{\scriptsize $\pm$2.27e4}/3 & 0.55{\scriptsize $\pm$0.01}/2 & \textbf{7.55e5}{\scriptsize $\pm$1.57e5}/1 & 0.63{\scriptsize $\pm$0.10}/2 \\  
        ORIGAMI-M & \textbf{5.20e5}/1 & \textbf{0.49}/1 & 5.27e5/4 & 0.57/3 & 7.29e5/4 & 0.63/3 & 6.92e5/2 & \textbf{0.55}/1\\  
        ORIGAMI-A & 5.02e5/4 & \textbf{0.49}/1 & 5.59e5/2 & \textbf{0.40}/1 & \textbf{8.10e5}/1 & \textbf{0.36}/1  & \multicolumn{2}{c}{--} \\  
        ORIGAMI-M-BS & 4.32e5/5 & 1.56/5 & 4.52e5/5 & 1.23/5 & 6.57e5/5 & 1.12/5 & 5.97e5/4&1.05/3 \\  
        DIRECT-MIN-COV & 5.17e5/2 & 0.61/3 & 5.57e5/3 & 0.64/4 & 7.81e5/2 & 0.79/4  & 6.37e5/3&1.68/4 \\ 
        \textbf{RANK(OURS)}&\textbf{3}&\textbf{4}&\textbf{1}&\textbf{2}&\textbf{3}&\textbf{2}&\textbf{1}&\textbf{2}\\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table*}

\begin{table*}[]
\caption{Multi-objective performance indicator of SDES and comparison algorithms across all problem scales in $N=6$}
\label{app:tab:performance:N=6}
\begin{adjustbox}{width=\textwidth}
\centering
\begin{tabular}{lrrrrrrrr}
\toprule
        \multicolumn{1}{c}{\textbf{$N=6$}} & \multicolumn{2}{c}{\textbf{$T=25$}} & \multicolumn{2}{c}{\textbf{$T=50$}} & \multicolumn{2}{c}{\textbf{$T=75$}} & \multicolumn{2}{c}{\textbf{$T=100$}}\\  
        \multicolumn{1}{c}{\textbf{$\bm{Method}$}} & $HV$/Rank & $IGD^{+}$/Rank & $HV$/Rank & $IGD^{+}$/Rank & $HV$/Rank & $IGD^{+}$/Rank & $HV$/Rnak & $IGD^{+}$/Rank \\
        \midrule
        PF & 5.40e7 & 0 & 6.10e6 & 0 & 3.46e7 & 0 & 1.15e7&0 \\  
        %\tabincell{l}{SDES without \\heuristic operator} & 402660 & 1.66 & 125921 & 2.63 & 347040 & 2.53  & ~ & ~ \\  
        $\textbf{SDES}$ & \textbf{9.45e6}{\scriptsize $\pm$9.02e6}/1 & \textbf{0.29}{\scriptsize $\pm$0.13}/1 & \textbf{4.78e6}{\scriptsize $\pm$1.73e5}/1 & \textbf{0.32}{\scriptsize $\pm$0.02}/1 & \textbf{1.00e7}{\scriptsize $\pm$3.78e6}/1 & \textbf{0.42}{\scriptsize $\pm$0.10}/1 & \textbf{7.91e6}{\scriptsize $\pm$5.36e5}/1 & \textbf{0.41}{\scriptsize $\pm$0.02}/1 \\  
        ORIGAMI-M & \multicolumn{2}{c}{--} & \multicolumn{2}{c}{--} & \multicolumn{2}{c}{--} & \multicolumn{2}{c}{--}\\  
        ORIGAMI-A & 5.58e6/2 & 0.66/2 & \multicolumn{2}{c}{--} & \multicolumn{2}{c}{--}  & \multicolumn{2}{c}{--} \\  
        ORIGAMI-M-BS & 5.16e6/3 & 0.90/3 & 4.34e6/2 & 0.92/2 & \multicolumn{2}{c}{--} & \multicolumn{2}{c}{--} \\  
        DIRECT-MIN-COV & 4.22e6/4 & 1.66/4 & 3.08e6/3 & 2.48/3 & 5.64e6/2 & 3.05/2  & 5.23e6/2&2.85/2 \\ 
        \textbf{RANK(OURS)}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}\\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table*}

\begin{table*}[]
\caption{Multi-objective performance indicator of SDES and comparison algorithms across all problem scales in $N=7$}
\label{app:tab:performance:N=7}
\begin{adjustbox}{width=\textwidth}
\centering
\begin{tabular}{lrrrrrrrr}
\toprule
        \multicolumn{1}{c}{\textbf{$N=7$}} & \multicolumn{2}{c}{\textbf{$T=25$}} & \multicolumn{2}{c}{\textbf{$T=50$}} & \multicolumn{4}{c}{${T\geq75}$ $\textbf{TIMEOUT}$}\\  
        \multicolumn{1}{c}{\textbf{$\bm{Method}$}} & $HV$/Rank & $IGD^{+}$/Rank & $HV$/Rank & $IGD^{+}$/Rank & \multicolumn{4}{c}{--} \\
        \midrule
        PF & 2.21e8 & 0 & 3.37e8 & 0 & \multicolumn{4}{c}{--} \\  
        %\tabincell{l}{SDES without \\heuristic operator} & 402660 & 1.66 & 125921 & 2.63 & 347040 & 2.53  & ~ & ~ \\  
        $\textbf{SDES}$ & \textbf{8.81e7}{\scriptsize $\pm$3.43e7}/1 &  \textbf{0.39}{\scriptsize $\pm$0.04}/1 & \textbf{1.64e8}{\scriptsize $\pm$4.82e7}/1 & \textbf{0.39}{\scriptsize $\pm$0.04}/1 & \multicolumn{4}{c}{--} \\  
        ORIGAMI-M & \multicolumn{2}{c}{--} & \multicolumn{2}{c}{--}  & \multicolumn{4}{c}{--}\\  
        ORIGAMI-A & 6.95e7/2 & 0.45/2 & \multicolumn{2}{c}{--}  & \multicolumn{4}{c}{--} \\  
        ORIGAMI-M-BS & 5.66e7/3 & 1.17/3 & 1.14e8/2 & 1.25/2& \multicolumn{4}{c}{--} \\  
        DIRECT-MIN-COV & 5.28e7/4 & 1.58/4 & 1.03e8/3 & 2.04/3  & \multicolumn{4}{c}{--} \\ 
        \textbf{RANK(OURS)}&\textbf{1}&\textbf{1}&\textbf{1}&\textbf{1}&\multicolumn{4}{c}{--}\\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table*}

\begin{table}[]
\caption{Multi-objective performance indicator of SDES and comparison algorithms across all problem scales in $N=8$}
\label{app:tab:performance:N=8}
\centering
% \begin{adjustbox}{width=0.5\textwidth}
\begin{tabular}{lrrrrrrrr}
\toprule
        \multicolumn{1}{c}{\textbf{$N=8$}} & \multicolumn{2}{c}{\textbf{$T=25$}}  & \multicolumn{6}{c}{${T\geq50}$ $\textbf{TIMEOUT}$}\\  
        \multicolumn{1}{c}{\textbf{$\bm{Method}$}} & $HV$/Rank & $IGD^{+}$/Rank & \multicolumn{6}{c}{--} \\
        \midrule
        PF & 4.75e9 & 0 &  \multicolumn{6}{c}{--} \\  
        %\tabincell{l}{SDES without \\heuristic operator} & 402660 & 1.66 & 125921 & 2.63 & 347040 & 2.53  & ~ & ~ \\  
        $\textbf{SDES}$ & \textbf{1.56e9}{\scriptsize $\pm$4.98e8}/1 & \textbf{0.37}{\scriptsize $\pm$0.05}/1 & \multicolumn{6}{c}{--} \\  
        ORIGAMI-M & \multicolumn{2}{c}{--} &  \multicolumn{6}{c}{--}\\  
        ORIGAMI-A & 4.94e8/2 & 0.80/2 & \multicolumn{6}{c}{--} \\  
        ORIGAMI-M-BS &\multicolumn{2}{c}{--} &\multicolumn{6}{c}{--} \\  
        DIRECT-MIN-COV & 4.71e8/3 & 2.16/3 &\multicolumn{6}{c}{--} \\ 
        \textbf{RANK(OURS)}&\textbf{1}&\textbf{1}&\multicolumn{6}{c}{--}\\
\bottomrule
\end{tabular}
% \end{adjustbox}
\end{table}

\subsection{Additional Experiments about Time Efficiency}
\label{app:more_time_effi}
% Experiments
% 放到More Time Efficiency实验中
% 首先介绍原方法固定种群大小的合理性
% 然后分析不固定种群大小的影响
Section~\ref{sec:Runtime} shows the linear complexity of our method SDES with fixed $pop\_{}size$ in both target and heterogeneous attacker dimensions. SDES is designed to deal with the following requirements: high-dimensional problems in limited time but does not require so many solutions. Other algorithms often fail to complete tasks on time (within the maximum runtime cup $M$) by providing too many solutions, while the general user does not need thousands of solutions. For example, the SOTA algorithm ORIGAMI-M provides about 10000 non-dominant solutions when $N=6$, $T=50$, which cannot accomplish MOSG problems in time. Meanwhile, the effectiveness experiment displays a good performance of our method in multi-objective indicators compared with SOTA algorithms. Therefore, SDES with fixed $pop\_{}size$ can handle more large-scale problems and can provide users with a considerable amount of non-dominated solutions. Those solutions can form a better distributed solution set than other SOTA algorithms.

\begin{figure}[!t]
\centering
\includegraphics[width=.6\textwidth]{figures/Time-indicator_ORIGAMI-G_N3-12T25-1000.pdf}
\caption{The runtime of SDES with increasing $pop\_{}size$. The $pop\_{}size$ is an approximate arithmetic progression $[50, 200, 400,\ldots,1800]$ corresponding to the number of attackers $[3, 4, 5,\ldots, 12]$. The time efficiency of SDES with increasing $pop\_{}size$ is still better than comparison algorithms.}
\label{app:fig:Runtime:SDESF:larger}
\end{figure}
% ~\ref{fig:Runtime:SDES:larger}

Here we further analyze the influence of $pop\_{}size$ on runtime. In the addition experiment, the population growth of SDES is an increasing sequence with constant steps, cf. Figure~\ref{app:fig:Runtime:SDESF:larger}. As the number of attacker scale up, the runtime of SDES with increasing $pop\_{}size$ exhibits sub-linear growth, which is still faster than all traditional comparison methods. As targets scale up, since $pop\_{}size$ is fixed when the number of attacker is fixed, the runtime of SDES with increasing $pop\_size$ still exhibits linear growth.


% \section{More Ablation Study}
% \label{app:more_abl_stu}
% The results of ablation experiment in $N=5$, $T=75$ scenario (Table~\ref{tab:ablation:our_method:T=75}) is the $N=5$, $T=50$ scenario (Table~\ref{tab:ablation:our_method}) are consistent:
% i. The performance of Num 1 and Num 2 show that both naive $I$-code and $c$-code methods with other heuristic operator fail to converge and are inferior to all existing algorithms. 
% ii. The performance of Num 1 and Num 2 also show that the naive $I$-code EA is even inferior to the naive $c$-code EA because of the difficulty of $I$-code solution evaluation. 
% iii. The BSM component can greatly improve the quality of the solution, regardless of the optimized algorithm. 
% iv. While the MIN-COV can be effective only when the optimized algorithm converges well.
% \begin{table}[htbp]
% \caption{More ablation result of our method in N=5, T=75}
% \label{tab:ablation:our_method:T=75}
%     \centering
%     \begin{tabular}{lrr}
%     \toprule
%         \textbf{$N=5$, $pop\_{}size=400$} & \multicolumn{2}{c}{\textbf{$T=75$}} \\ 
%         $\bm{(Num) Method}$ & $HV$/\textit{rank} & $IGD^+$/\textit{rank} \\ \midrule
%         PF & 1693188/- & 0/- \\
%         \textbf{(1) $c$-code} & 500407/9 & 1.37/6 \\
%         \textbf{(2) $I$-code} & 502114/8 & 2.69/9 \\
%         \textbf{(3) $I$-code with BSM} & \textbf{709572/4} & \textbf{0.33/2} \\
%         \textbf{(4) $I$-code with MIN-COV} & 509010/7 & 2.68/8 \\ 
%         \textbf{(5) SDES} & 1394577/1 & 0.2/1 \\
%         ORIGAMI-M & 679223/5 & 0.64/4 \\ 
%         ORIGAMI-A & 756757/2 & 0.44/3 \\ 
%         ORIGA-M-BS & 611041/6 & 1.48/7 \\
%         DIRECT-MIN-COV & 728453/3 & 0.74/5 \\ \bottomrule
%     \end{tabular}
% \end{table}


\subsection{Additional Experiments about Sensitivity Analysis of Population Size in SDES}
\label{app:more_sen_ana}
% Combined with Figure~\ref{app:fig:Sensitivity:N=5} about the experiment on $N=5$ and $T=[25, 50]$ MOSG problem, we draw more conclusions from sensitivity experiment on $N=5$ and $T=[75, 100]$ MOSG problem in Figure~\ref{app:fig:Sensitivity:N=5}. 

\begin{figure}[!hb]
\centering
\begin{minipage}[l]{\columnwidth}\centering
\includegraphics[width=0.34\textwidth]{figures/barlineN5_1.pdf}
\includegraphics[width=0.34\textwidth]{figures/barlineN5_2.pdf}
\includegraphics[width=0.34\textwidth]{figures/barlineN5_3.pdf}
\includegraphics[width=0.34\textwidth]{figures/barlineN5_4.pdf}
\caption{Sensitivity Analysis of SDES. The range of population size is $[350, 400, 450, 500]$. The range of problem scale is $N=5$, $T=[25, 50, 75, 100]$. }
\label{app:fig:Sensitivity:N=5}
\end{minipage}
\end{figure}

We analyze how the performance of SDES varies with the population size $pop\_{}size$ and the result is shown in Figure~\ref{app:fig:Sensitivity:N=5}. It is measured by the maximization indicator \textit{HV} and minimization indicator \textit{IGD}$^+$. 
Ideally, the larger $pop\_{}size$, the lower \textit{IGD}$^+$ and higher \textit{HV}. Figure~\ref{app:fig:Sensitivity:N=5} shows that SDES's sensitivity to $pop\_{}size$ depends mainly on the problem difficulty and the randomness of many-objective EAs. 
For MOSGs, Figure~\ref{app:fig:Sensitivity:N=5} illustrates that $pop\_{}size$ has little influence on multi-objective performance indicators. Furthermore, increasing $pop\_{}size$ has less effect on \textit{HV} and \textit{IGD}$^+$ indicators, and \textit{HV} indicator may be reduced by large $pop\_{}size$. In addition, Increasing $pop\_{}size$ does not reduce the standard deviation of the indicator. 
The more difficult the problem, the more sensitive SDES is to $pop\_{}size$. On the one hand, when $T=25$ or $T=50$, \textit{HV} and \textit{IGD}$^+$ show stable changes on the whole and SDES has low sensitivity to $pop\_{}size$. On the other hand, SDES is more sensitive to $pop\_{}size$ when $T=100$ (a harder problem). 
Furthermore, the performance of SDES is more influenced by the randomness of many-objective EAs. There is no obvious connection between the value of \textit{IGD}$^+$ or \textit{HV} and $pop\_{}size$.

\subsection{Additional Experiments about Visualization Analysis}
\label{app:vis_ana}

\begin{figure}[!th]
\centering
\includegraphics[width=.6\textwidth]{figures/visualization/ScatterPlot/SEED29N3T1000Indihv-scatter-ORIGAMI-M-BSORIGAMI-G_2.pdf}
\caption{PSP visualization of $N=3, T=1000$ MOSG problem. Compared with ORIGAMI-M-BS, SDES can find a well-spaced PF.}
\label{app:fig:visualization:N=3}
\end{figure}

\begin{figure}[!th]
\centering
\includegraphics[width=.6\textwidth]{figures/visualization/ScatterPlot/SEED15N4T400Indihv-scatter-ORIGAMI-MSDES.pdf}
\caption{PSP visualization of $N=4, T=400$ MOSG problem. MOSG is a minimum task. The closer and more diverse the result to the original, the better the result. From the first column subplots ($f_{2,3,4}$, $f_1$), SDES has the potential to widen the boundaries. From other subplots, SDES is comparable to ORIGAMI-M.}
\label{app:fig:visualization:N=4}
\end{figure}

\begin{figure}[!th]
\centering
\includegraphics[width=.6\textwidth]{figures/visualization/ScatterPlot/SEED7N5T100Indihv-scatter-ORIGAMI-MSDES.pdf}
\caption{PSP visualization of $N=5, T=100$ MOSG problem. In general, there is no significant difference between SDES and ORIGAMI-M in middle-scale MOSG problems. Since the bottom left PF of both methods is similar, the convergence ability of both methods is similar, but the capability of boundary exploration of different methods is different. }
\label{app:fig:visualization:N=5}
\end{figure}

The visualization method can show the PF distribution information that cannot be reflected by performance indicators. The commonly used visualization methods of MaOPs are Pairwise Scatter Plots (PSP) and Parallel Coordinate Plots (PCP). PSP is a classic visualization method to demonstrate the distribution and the breadth of exploration of the PF in the objective space, and PCP is a powerful technique to analyze the PF distribution on each coordinate in the objective space. PSP and PCP can not only judge the optimization difficulty of each target through the optimal value but also analyze the optimization preference of different algorithms through the distribution density. 

We display all visualization results about large-scale MOSG problems by PSP (responsible for $N\leq 5$) and PCP (responsible for $N>5$). The visualization shows the performance of both SDES and the SOTA method (depending on the $HV$ indicator). The SOTA method is drawn in red and SDES is drawn in blue. The table ticks of axes represent the defender payoff $(U_1^d(\bm{c}),\ldots,U_N^d(\bm{c}))$. MOSG problem aims to find the minimum defender loss. 

\begin{figure}[!bh]
\centering
\includegraphics[width=.5\textwidth]{figures/visualization/PCP/parallel_coordinate_plots-N7T25IndihvSEED0--ORIGAMI-A-ORIGAMI-G.pdf}
\caption{PCP visualization of $N=6, T=100$ MOSG problem. On the one hand, since the ideal solution (dotted lines) and the nadir solution (solid lines) of SDES (blue lines) and DIRECT-MIN-COV (red lines) cannot completely include each other, the ability of boundary exploration of SDES and DIRECT-MIN-COV is comparable. On the other hand, compared with DIRECT-MIN-COV, SDES can find a well-spaced PF. }
\label{app:fig:visualization:N=6T=100}
\end{figure}


\begin{figure}[!bh]
\centering
\includegraphics[width=.5\textwidth]{figures/visualization/PCP/parallel_coordinate_plots-N7T25IndihvSEED0--ORIGAMI-A-ORIGAMI-G.pdf}
\caption{PCP visualization of $N=7, T=25$ MOSG problem. When $N$ scales up to 7, the superiority of SDES is revealed both in the ability of boundary exploration and the uniformity and diversity of PF results.}
\label{app:fig:visualization:N=7T=25}
\end{figure}

\begin{figure}[!bh]
\centering
\includegraphics[width=.5\textwidth]{figures/visualization/PCP/parallel_coordinate_plots-N7T50IndihvSEED0--ORIGAMI-M-BS-ORIGAMI-G.pdf}
\caption{PCP visualization of $N=7, T=50$ MOSG problem. When $N$ scales up to 7, the superiority of SDES is revealed both in the ability of boundary exploration and the uniformity and diversity of PF results.}
\label{app:fig:visualization:N=7T=50}
\end{figure}

\begin{figure}[!bh]
\centering
\includegraphics[width=.5\textwidth]{figures/visualization/PCP/parallel_coordinate_plots-N8T25IndihvSEED0--ORIGAMI-A-ORIGAMI-G.pdf}
\caption{PCP visualization of $N=8, T=25$ MOSG problem. When $N$ scales up to 8, although ORIGAMI-A is one of the SOTA methods in middle-scale MOSG problems, the exploration range of ORIGAMI-A is limited in large-scale MOSG problems. The performance of our methods SDES is satisfactory in both solution distribution and convergence. }
\label{app:fig:visualization:N=8T=25}
\end{figure}

% 说明如何看图
In PSP, as shown in Figure~\ref{app:fig:visualization:N=3},~\ref{app:fig:visualization:N=4}, and~\ref{app:fig:visualization:N=5}, the closer and more diverse the PF found by the method to the origin, the better the method.
PSP is used in medium-scale MOSG problem visualization, e.g., $N=3, 4$. As for $N=3$, PSP is a 3D figure displayed from a 45-degree viewing angle, e.g., Figure~\ref{app:fig:visualization:N=3}. As for $N>3$, PSP is symmetrical, we only need to observe the lower triangle, e.g., Figure~\ref{app:fig:visualization:N=4}. 
% 结果分析
When analyzing, we use coordinates to refer to subplots, for example, the subplot of Figure~\ref{app:fig:visualization:N=4} in the lower right corner is called $(f_4, f_1)$. Figure~\ref{app:fig:visualization:N=4} illustrates (i) Compared with the SOTA comparison method, SDES usually can find a better PF. (ii) SDES can explore larger boundaries (e.g., the boundary point at the first column subplots ($f_{2,3,4}$, $f_1$) of Figure~\ref{app:fig:visualization:N=4}). More visualization analysis details in the figure captions.
% i. The exploration capabilities of the two algorithms for conventional solutions are equivalent (the lower left corners of all subplots are covered to an equal extent), but their ability to explore boundary solutions for different objectives is different. SDES can return more boundary solutions related to objective $1\sim4$. Whereas ORIGAMI-A performs better on subplots involving objective 5, cf. last row of subplots. ii. The PF distribution provided by SDES is grid-like. Taking subplot$(f_5, f_3)$ as an example, the optimal solution varies uniformly along the axis. The grid-like PF maintains uniformity while limiting the number of configuration solutions. A small set of non-dominated solutions is particularly important for EA, as it guarantees evolutionary dynamics. Conversely, if the non-dominated solution occupies most of the population, the population convergence rate will become slow.

% 说明怎么看图
In PCP, cf. Figure~\ref{app:fig:visualization:N=6T=100},~\ref{app:fig:visualization:N=7T=25},
~\ref{app:fig:visualization:N=7T=50}, and~\ref{app:fig:visualization:N=8T=25}, the thin lines depict the distribution of the PF found by SDES and the SOTA method in the objective space, and the thick lines at the top and bottom of the figure depict the exploration capability of methods. The more diverse the thin lines, the better the method, and the wider the distance between the top thick line to the bottom thick line, the better the method. The top thick lines are also called ideal lines, composed of the optimal values of all objectives, and the bottom thick lines are also called nadir lines, composed of the worst values of all objectives.
All PCP figures illustrate (i) The blue thin lines (SDES) are basically covered by the red lines (SOTA comparison method), indicating that the PF returned by SDES is better than others in distribution. (ii) The Ideal and Nadir of SDES basically surround the SOTA comparison method, which means that the width of the PF returned by SDES is also better than others. More details of visualization analysis are described in the figures' captions.
% \end{appendices}
\end{document}

