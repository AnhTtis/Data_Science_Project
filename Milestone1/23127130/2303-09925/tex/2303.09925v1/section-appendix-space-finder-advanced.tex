% % !TEX options=--shell-escape
% \documentclass[12pt]{iopart}
% \pdfoutput=1 % go for pdflatex

% % == Standard packages ==
% \usepackage{iopams}
% \input{packages}

% % == Theorem environments ==
% \theoremstyle{definition}
% % A definition introduces a new concept rigorously:
% \newtheorem{definition}{Definition}[section]
% % A remark introduces tangential considerations: 
% \newtheorem{remark}{Remark}[section]
% % A theorem is a key result:
% \newtheorem{theorem}{Theorem}[section]
% % A proposition is a result requiring explicit proof:
% \newtheorem{proposition}[theorem]{Proposition}
% % A lemma is an intermediate result for a theorem or a proposition, requiring explicit proof:
% \newtheorem{lemma}[theorem]{Lemma}
% % An observation is a result not requiring explicit proof:
% \newtheorem{observation}[theorem]{Observation}
% % A corollary is a result directly following from a previous result:
% \newtheorem{corollary}[theorem]{Corollary}

% % == Macros ==
% \input{macros}
% \newcommand{\TODO}[1]{{\marginpar{\color{gray}\textsf{[TODO]}} \color{gray}\textsf{[#1]}}}
% \newcommand{\NOTE}[1]{{\marginpar{\color{gray}\textsf{[NOTE]}} \color{gray}\textsf{[#1]}}}

% \begin{document}

% % == Dummy Sections ==

% \section{Introduction}
% \label{section: introduction}

% \section{Causal orders}
% \label{section:causal-orders}

% \section{Spaces of input histories}
% \label{section:spaces}

% \section{The topology of causality}
% \label{section:topology-causality}

% \section{The geometry of causality}
% \label{section:geometry-causality}

% \section{Conclusions}
% \label{section:conclusions}

% % == Dummy Biblio ==

% % \bibliographystyle{iopart-num}
% % \bibliography{biblio}
% % \nocite{*}

% \appendix

% \section{Causally Complete Spaces on 3 Events with Binary Inputs}
% \label{appendix:all-spaces-ABC}

% \section{Algorithm to Find Causally Complete Spaces}
% \label{appendix:space-finder-algo}
% \subsection{Utilities for the \mintinline{python}{SpaceFinder} Class}
% \label{appendix:space-finder-algo:section:utilities}

% \newpage

% === COMMENT ABOVE BEFORE COMPILING MAIN FILE ===


\section{Advanced Algorithm to Find Causally Complete Spaces}
\label{appendix:space-finder-algo-adv}

This Appendix presents an advanced version of the \mintinline{python}{SpaceFinder} class from \ref{appendix:space-finder-algo}, including state serialisation features and symmetry-based reduction of the children history subsets at top-level.
We resume our story from \ref{appendix:space-finder-algo:section:utilities}, which in the advanced version includes further utility functions.

\subsection{More Utilities for the \mintinline{python}{SpaceFinder} Class}

\noindent Given a file handler (as a \mintinline{python}{BinaryIO} instance) and a collection of bitvectors for sets of histories, the \mintinline{python}{write_hsets} function serializes the bitvectors in a compact form, using the minimum number of bytes for each one.

\begin{minted}[firstnumber=331]{python}
HistorySet = Bitvec
""" Type alias for a set of histories, as a bitvector. """

def write_hsets(f: BinaryIO, hsets: Collection[HistorySet]) -> int:
    """ Writes a collection of history sets (as bitvectors) to a given file. """
    num_hsets = len(hsets)
    f.write(num_hsets.to_bytes(8, byteorder="big"))
    num_bytes_written = 8
    for hs in hsets:
        num_bytes = max(int(ceil(hs.bit_length()/8)), 1)
        f.write(num_bytes.to_bytes(2, byteorder="big"))
        hs_bytes = hs.to_bytes(num_bytes, byteorder="big")
        f.write(hs_bytes)
        num_bytes_written += num_bytes + 2
    return num_bytes_written
\end{minted}

\noindent Given a file handler (as a \mintinline{python}{BinaryIO} instance), the \mintinline{python}{_read_hsets} function iterates through all history set bitvectors serialised in the file by the \mintinline{python}{write_hsets} function.

\begin{minted}[firstnumber=last]{python}
def _read_hsets(f: BinaryIO) -> Iterator[HistorySet]:
    num_spaces = int.from_bytes(f.read(8), byteorder="big")
    for _ in range(num_spaces):
        num_space_bytes = int.from_bytes(f.read(2), byteorder="big")
        space = int.from_bytes(f.read(num_space_bytes), byteorder="big")
        assert max(int(ceil(space.bit_length()/8)), 1) == num_space_bytes
        yield space
\end{minted}

\noindent Given a file handler (as a \mintinline{python}{BinaryIO} instance), the \mintinline{python}{read_hsets_set} function returns the \mintinline{python}{set} of all history set bitvectors serialised in the file by the \mintinline{python}{write_hsets} function.

\begin{minted}[firstnumber=last]{python}
def read_hsets_set(f: BinaryIO) -> set[HistorySet]:
    """
    
    Reads a set of history sets (as bitvectors) from a given file.
    Returns a :obj:`list` or :obj:`set` depending on the value of ``mode``.
    
    """
    spaces_set: set[Bitvec] = set(_read_hsets(f))
    return spaces_set
\end{minted}

\noindent Given a file handler (as a \mintinline{python}{BinaryIO} instance), the \mintinline{python}{read_hsets_set} function returns the \mintinline{python}{list} of all history set bitvectors serialised in the file by the \mintinline{python}{write_hsets} function.

\begin{minted}[firstnumber=last]{python}
def read_hsets_list(f: BinaryIO) -> list[HistorySet]:
    """
    
    Reads a list of history sets (as bitvectors) from a given file.
    Returns a :obj:`list` or :obj:`set` depending on the value of ``mode``.
    
    """
    spaces_list: list[Bitvec] = list(_read_hsets(f))
    return spaces_list
\end{minted}


\subsection{More on the \mintinline{python}{SpaceFinder} Class}

The \mintinline{python}{SpaceFinder} class encapsulates the data and code necessary to search for causally complete spaces on a given number of events.
An object of the class is instantiated by passing a number \mintinline{python}{num_events} of events---exposed by the homonymous property---and the constructor pre-computes certain data for use during the search.
The optional \mintinline{python}{verbose} keyword argument (kwarg) determines whether status updates will be printed/logged;
the optional \mintinline{python}{update_period} kwarg determines the frequency of the updates (as a minimum number of equivalence classes discovered in between updates);
the optional \mintinline{python}{filename} kwarg determines whether the finder state will be saved to a file (at least once, at the end);
the optional \mintinline{python}{save_period} kwarg determines whether how frequently the finder state will be saved (as a minimum number of equivalence classes discovered in between updates);
the optional \mintinline{python}{logger} kwarg can be used to supply a logger for use when printing updates (which are then both printed to console and logger using the logger).

\begin{minted}[linenos=false]{python}
class SpaceFinder:
    def __init__(self, num_events: int, *,
                 verbose: bool = True,
                 update_period: Optional[int] = None,
                 filename: Optional[str] = None,
                 save_period: Optional[int] = None,
                 logger: Optional[Logger] = None) -> None:
        ...
    @property
    def num_events(self) -> int:
        ...
    ...
\end{minted}

\noindent Calling the \mintinline{python}{blank_state} method initialises the finder for a new search, while calling the \mintinline{python}{load_state} method loads previously saved search state from a file.

\begin{minted}[linenos=false]{python}
class SpaceFinder:
    ...
    def blank_state(self) -> None:
        ...
    def load_state(self, filename: str) -> None:
        ...
    ...
\end{minted}


\subsection{More on the \mintinline{python}{SpaceFinder} Class -- Constructor}

\begin{minted}[firstnumber=371]{python}

class SpaceFinder:
    # pylint: disable = too-many-instance-attributes
    """
    An instance of this class encapsulates all the data used in the
    search for causally complete spaces on a given number of events.
    """

    # Options:
    _num_events: int
    _verbose: bool
    _update_period: Optional[int]
    _toplevel_opt_depth: Optional[int]
    _save_options: Optional[tuple[str, Optional[int], bool]]
    _logger: Optional[Logger]

    # Pre-computed data:
    _events: tuple[Event, ...]
    _max_histories: Sequence[History]
    _perm_group: tuple[PermGroupEl, ...]
    _histories_perm_dict: dict[PermGroupEl, dict[History, History]]
    _children_set: dict[History, frozenset[History]]
    _children: dict[History, tuple[History, ...]]
    _parents: dict[History, frozenset[History]]
    _domsize: dict[History, int]
    _max_space_size: int
    _initialised: bool
    _fixed_memsize: int

    def __init__(self, num_events: int,
                 *, verbose: bool = True,
                 update_period: Optional[int] = None,
                 filename: Optional[str] = None,
                 save_period: Optional[int] = None,
                 logger: Optional[Logger] = None) -> None:
        """
        Creates a new space finder instance, which will search for causally
        complete spaces on the given number of events.

        :param num_events: the number of events
        :param verbose: whether to print status updates, defaults to True
        :param update_period: how frequently to print status updates
                              (min number of equivalence classes discovered
                              between updates), defaults to None (print update
                              after every each top-level cycle)
        :param filename: internal state is regularly saved to a binary file with
                         this name, defaults to None (don't save internal state)
        :param save_period: how frequently to save internal state (min number of
                            equivalence classes discovered between saves),
                            defaults to None (save only once, at the end)
        """
        assert update_period is None or update_period > 0
        self._num_events = num_events
        self._verbose = verbose
        self._update_period = update_period
        self._toplevel_opt_depth = None # search to arbitrary depth
        if filename is not None:
            save_backup: bool = True
            self._save_options = (filename, save_period, save_backup)
        else:
            self._save_options = None
        self._logger = logger
        self._max_histories = max_histories(num_events)
        self._events = tuple(idx2event(idx) for idx in range(num_events))
        self._perm_group = tuple(iter_perm_group(self._events))
        hs = sorted(sub_histories(self._max_histories),
                    key=history_sort_key)
        _histories_perm_dict = {
            h: dict(history_perms(h, self._perm_group))
            for h in hs
        }
        self._histories_perm_dict = {
            p: {
                h: _histories_perm_dict[h][p]
                for h in hs
            }
            for p in self._perm_group
        }
        self._children_set = {
            h: frozenset(child_histories(h))
            for h in hs
        }
        self._children = {
            h: tuple(sorted(self._children_set[h]))
            for h in hs
        }
        self._parents = parents(hs)
        self._domsize = {h: domsize(h) for h in hs}
        self._max_space_size = sys.getsizeof(2**(2**(2*len(self._events)))-1)
        self._initialised = False
        self._fixed_memsize = getsize(self)
\end{minted}


\subsection{More on the \mintinline{python}{SpaceFinder} Class -- Search Metrics}

In the advanced algorithm, the subsets of children being iterated over at the top level are obtained in two steps: we iterate through ``fixed'' subsets of children, and for each such ``fixed'' subset we iterate through all possible subsets of the corresponding ``variable'' children.
The list of ``fixed'' subsets is stored in \mintinline{python}{self._child_choices_list}, and the index of the ``fixed'' subset currently being explored is stored in \mintinline{python}{self._fix_child_choice_idx}.
A coarser estimate of search completion can be obtained by considering the fraction of ``fixed'' subsets that have been completely explored.

\begin{minted}[firstnumber=last]{python}
    _fix_child_choice_idx: int
    _child_choices_list: list[HistorySet]

    @property
    def fixed_toplevel_subsets_perc_completed(self) -> float:
        """
        Percent of top-level fixed child history subsets explored.
        """
        return self._fix_child_choice_idx/len(self._child_choices_list)
\end{minted}

\noindent The list of ``variable'' children subsets corresponding to the ``fixed'' subsets above is stored in \mintinline{python}{self._remaining_children_list}, the number of children in each subset is stored in \mintinline{python}{self._num_remaining_children} and the index of the ``variable'' subset currently being explored is stored in \mintinline{python}{self._var_child_subset_bitvec}.
An estimate of completion for each ``fixed'' child subset is given by the the fraction of corresponding ``variable'' child subsets that have been completely explored (out of \mintinline{python}{2**self._num_remaining_children[self._fix_child_choice_idx]} total).

\begin{minted}[firstnumber=last]{python}
    _var_child_subset_bitvec: int
    _remaining_children_list: list[HistorySet]
    _num_remaining_children: list[int]

    @property
    def var_toplevel_subsets_perc_completed(self) -> float:
        """
        Percent of top-level variable child history subsets explored
        for the current fixed child history subset.
        """
        if self._fix_child_choice_idx == len(self._child_choices_list):
            return 1.0
        curr_rem_ch = self._num_remaining_children[self._fix_child_choice_idx]
        return self._var_child_subset_bitvec/(2.0**curr_rem_ch)
\end{minted}

\noindent In the search for causally complete spaces on 2-event, there are 4 ``fixed'' subsets: the first and second with 2 ``variable'' subsets each, the third and fourth with 1 ``variable'' subset each, for a total of $2+2+1+1 = 6$ top level subsets to explore.
For concision, we print the history bitvectors rather than their full form: bitvector $1=2^0$ is $\hist{A/0}$, bitvector $2=2^1$ is $\hist{A/1}$, bitvector $4=2^2$ is $\hist{B/0}$ and bitvector $8=2^3$ is $\hist{B/1}$.

\begin{minted}[linenos=false]{python}
print(f"       Fixed | Variable  ->  Top-level subset")
for mand_subs_bv, rem_child_bv in zip(finder2._child_choices_list,
                                      finder2._remaining_children_list):
    mandatory_subset = bitvec2set(mand_subs_bv)
    remaining_children = list(iter_bitvec(rem_child_bv))
    num_opt_subsets = 2**len(remaining_children)
    for subs_indicator in range(num_opt_subsets):
        optional_subset = {
            h for i, h in enumerate(remaining_children)
            if 2**i&subs_indicator > 0
        }
        toplevel_subset = mandatory_subset|optional_subset
        optional_subset_str = ('{}' if not optional_subset
                               else str(optional_subset))
        print(f"{str(mandatory_subset): >12}"
              f" | {optional_subset_str: <8}"
              f"  ->  {str(toplevel_subset): <16}")
\end{minted}

\begin{minted}{text}
       Fixed | Variable  ->  Top-level subset
   {8, 1, 4} | {}        ->  {8, 1, 4}       
   {8, 1, 4} | {2}       ->  {8, 1, 2, 4}    
      {1, 4} | {}        ->  {1, 4}          
      {1, 4} | {2}       ->  {1, 2, 4}       
   {8, 1, 2} | {}        ->  {8, 1, 2}       
      {1, 2} | {}        ->  {1, 2}          
\end{minted}

\noindent Below is part of the printout from the search of causally complete spaces on 2 events: setting \mintinline{python}{update_period=None} forces the finder to print the current search status when it has finished exploring each ``variable'' subset at top level.

\begin{minted}{text}
Iterating over 6 top-level child history subsets.
      time       spaces    eq. cls     memory  completed fts compl. vts compl.
    2.91ms            4          1   10.35KiB   16.6667%    0.0000%   50.0000%
    3.41ms            5          2   10.38KiB   33.3333%   25.0000%  100.0000%
    3.83ms            5          2   10.38KiB   50.0000%   25.0000%   50.0000%
    5.76ms            5          2   10.38KiB   66.6667%   50.0000%  100.0000%
    6.58ms            5          2   10.38KiB   83.3333%   75.0000%  100.0000%
    7.29ms            7          3   10.41KiB  100.0000%  100.0000%  100.0000%
Found 7 spaces in 3 equivalence classes.
\end{minted}

\noindent The printout describes the following search progression:

\begin{enumerate}
    \item The 1st equivalence class is discovered while exploring $\{8, 1, 4\}$ at top-level: that's $50\%$ (1 out of 2) of the top-level subsets for mandatory subset $\{8, 1, 4\}$, and $16.666\%$ (1 out of 6) of all top-level subsets.
    \item The 2nd equivalence class is discovered while exploring $\{8, 1, 2, 4\}$ at top-level: that's $100\%$ (2 out of 2) of the top-level subsets for mandatory subset $\{8, 1, 4\}$, and $33.333\%$ (2 out of 6) of all top-level subsets. It also completes the search for $25\%$ (1 out of 4) of all mandatory subsets.
    \item No equivalence class is discovered while exploring $\{1, 4\}$ at top-level: that's $50\%$ (1 out of 2) of the top-level subsets for mandatory subset $\{1, 4\}$, and $50\%$ (3 out of 6) of all top-level subsets.
    \item No equivalence class is discovered while exploring $\{1, 2, 4\}$ at top-level: that's $100\%$ (2 out of 2) of the top-level subsets for mandatory subset $\{1, 4\}$, and $66.666\%$ (4 out of 6) of all top-level subsets. It also completes the search for $50\%$ (2 out of 4) of all mandatory subsets.
    \item No equivalence class is discovered while exploring $\{8, 1, 2\}$ at top-level: that's $100\%$ (1 out of 1) of the top-level subsets for mandatory subset $\{8, 1, 2\}$, and $83.333\%$ (5 out of 6) of all top-level subsets. It also completes the search for $75\%$ (3 out of 4) of all mandatory subsets.
    \item The 3rd equivalence class is discovered while exploring $\{1, 2\}$ at top-level: that's $100\%$ (1 out of 1) of the top-level subsets for mandatory subset $\{1, 2\}$, and $100\%$ (6 out of 6) of all top-level subsets. It also completes the search for $100\%$ (4 out of 4) of all mandatory subsets.
\end{enumerate}

\noindent This irregular progression, where many spaces are discovered while exploring the first few ``variable'' subsets and then few or none are discovered while exploring later ones, is typical of the algorithm and becomes significantly more marked for higher number of events.
For example, below is a selection of the initial part of the printout for the search on 3 events, showing all equivalence classes discovered by exploring top-level subsets originating from the first ``fixed'' subset (out of 922 total).

\begin{minted}{text}
Iterating over 922 top-level child history subsets.
      time       spaces    eq. cls     memory  completed fts compl. vts compl.
   38.23ms           48          1   82.88KiB    0.2169%    0.0000%    6.2500%
   57.58ms          439         14   83.87KiB    0.3254%    0.0000%    9.3750%
   67.41ms          583         20   85.62KiB    0.6508%    0.0000%   18.7500%
   73.10ms          619         22   86.26KiB    1.0846%    0.0000%   31.2500%
   78.23ms          622         23   86.37KiB    1.6269%    0.0000%   46.8750%
   80.07ms          634         24   86.44KiB    1.7354%    0.0000%   50.0000%
   88.90ms          694         28   86.61KiB    1.8438%    0.0000%   53.1250%
   92.54ms          718         30   86.72KiB    2.0607%    0.0000%   59.3750%
   ...
\end{minted}

\noindent The progression over ``fixed'' subsets is similarly irregular, with $96\%$ of the equivalence classes (98 out of 102) being discovered while exploring the first $50.1\%$ of subsets (462 out of 922).

\begin{minted}{text}
      time       spaces    eq. cls     memory  completed fts compl. vts compl.
   ...
  346.47ms         2617         98   98.40KiB   54.3384%   50.0000%   16.4062%
  396.66ms         2623         99   98.61KiB   95.9870%   87.5000%    0.0000%
  401.19ms         2644        102   98.75KiB   96.3124%   91.6667%   50.0000%
  407.92ms         2644        102   98.75KiB  100.0000%  104.1667%  100.0000%
Found 2644 spaces in 102 equivalence classes.
\end{minted}

\noindent Finally, here are the utility functions to print and log all status data.

\begin{minted}[firstnumber=last]{python}
    def _print(self, *args: str, **kwargs: Any) -> None:
        """ Prints to console, or logs to logger. """
        print(*args, **kwargs)
        if self._logger is not None:
            self._logger.info(*args)

    def _print_status_header(self) -> None:
        if self._verbose:
            header = (f"{'time': >10} {'spaces': >12} {'eq. cls': >10}"
                      f" {'memory': >10} {'completed': >10}"
                      f" {'fts compl.' :>10} {'vts compl.' :>10}")
            self._print(header, flush=True)

    def _print_status_line(self) -> None:
        if self._verbose:
            time = time_str(self.time_elapsed)
            spaces = str(self.num_spaces)
            eq_classes = str(self.num_eq_classes)
            memory = memory_str(self.memsize)
            completed = f"{self.perc_completed:.4%}"
            fts_completed = f"{self.fixed_toplevel_subsets_perc_completed:.4%}"
            vts_completed = f"{self.var_toplevel_subsets_perc_completed:.4%}"
            line = (f"{time: >10} {spaces: >12} {eq_classes: >10}"
                    f" {memory: >10} {completed: >10}"
                    f" {fts_completed: >10} {vts_completed: >10}")
            self._print(line, flush=True)

    def _describe(self) -> None:
        """
            If in verbose mode,
            prints a summary description of the search results (so far).
        """
        if self._verbose:
            self._print(f"Found {self.num_spaces} spaces in "
                       f"{self.num_eq_classes} equivalence classes.")
\end{minted}


\subsection{More on the \mintinline{python}{SpaceFinder} Class -- State Serialisation}

All data structures altered by the search constitute the ``search state'': this can be either initialised to blank (for new searches) or loaded from file (when continuing an existing search).
Persistent serialisation of search state was made necessary by the large amount of time and computational resources required by the search for causally complete spaces on 4 events, where it was deemed likely---at the time when the code was written---that the search might be stopped (intentionally or accidentally) and then have to resume without significant loss of progress.
The \mintinline{python}{blank_state} method sets the state for a new search: number of spaces found set to 0, no spaces visited, no equivalence classes found; it clears data about top-level subsets, if any.

\begin{minted}[firstnumber=last]{python}
    def blank_state(self) -> None:
        """
            Initialise the space finder in a blank state.
        """
        self._num_spaces = 0
        self._partial_spaces_visited = set()
        self._eq_classes = set()
        if hasattr(self, "_num_done"):
            del self._num_done
        if hasattr(self, "_num_todo"):
            del self._num_todo
        if hasattr(self, "_fix_child_choice_idx"):
            del self._fix_child_choice_idx
        if hasattr(self, "_var_child_subset_bitvec"):
            del self._var_child_subset_bitvec
        if hasattr(self, "_child_choices_list"):
            del self._child_choices_list
        if hasattr(self, "_remaining_children_list"):
            del self._remaining_children_list
        self._initialised = True
\end{minted}

\noindent The private \mintinline{python}{write} method actually performs the state writing to binary IO, dictating the binary encoding scheme used by \mintinline{python}{load_state} above.

\begin{minted}[firstnumber=last]{python}
    def _write_state(self, f: BinaryIO) -> int:
        num_bytes_written = 0
        f.write(self._num_spaces.to_bytes(8, byteorder="big"))
        f.write(self._num_done.to_bytes(8, byteorder="big"))
        f.write(self._num_todo.to_bytes(8, byteorder="big"))
        f.write(self._fix_child_choice_idx.to_bytes(8, byteorder="big"))
        f.write(self._var_child_subset_bitvec.to_bytes(8, byteorder="big"))
        num_bytes_written += 40
        num_bytes_written += write_hsets(f, self._partial_spaces_visited)
        num_bytes_written += write_hsets(f, self._eq_classes)
        num_bytes_written += write_hsets(f, self._child_choices_list)
        num_bytes_written += write_hsets(f, self._remaining_children_list)
        return num_bytes_written
\end{minted}

\noindent The \mintinline{python}{load_state} method loads the state information from a binary file by given name.

\begin{minted}[firstnumber=last]{python}
    def load_state(self, filename: str) -> None:
        """
            Load space finder state from a binary file.
        """
        with open(filename, "rb") as f:
            self._num_spaces = int.from_bytes(f.read(8), byteorder="big")
            self._num_done = int.from_bytes(f.read(8), byteorder="big")
            self._num_todo = int.from_bytes(f.read(8), byteorder="big")
            self._fix_child_choice_idx = int.from_bytes(f.read(8),
                                                         byteorder="big")
            self._var_child_subset_bitvec = int.from_bytes(f.read(8),
                                                         byteorder="big")
            self._partial_spaces_visited = read_hsets_set(f)
            self._eq_classes = read_hsets_set(f)
            self._child_choices_list = read_hsets_list(f)
            self._remaining_children_list = read_hsets_list(f)
        self._initialised = True
\end{minted}

\noindent The \mintinline{python}{save_state} method saves the state information to a binary file by given name (as well as an identical backup file).

\begin{minted}[firstnumber=last]{python}
    def save_state(self, filename: str, *, save_backup: bool = True) -> None:
        """
        Saves the state to a given file, with optional backup.
        """
        if self._save_options is not None:
            filename, _, save_backup = self._save_options
            num_bytes_written = 0
            if self._verbose:
                self._print(f"Saving to '{filename}'...", end=" ", flush=True)
            with open(filename, "wb") as f:
                num_bytes_written += self._write_state(f)
            if save_backup:
                backup_filename = filename+".bak"
                if self._verbose:
                    self._print(f"saving to '{backup_filename}'...", end=" ",
                               flush=True)
                with open(backup_filename, "wb") as f:
                    num_bytes_written += self._write_state(f)
            if self._verbose:
                self._print(f"done ({memory_str(num_bytes_written)} written).",
                           flush=True)
\end{minted}

\noindent The logic determining whether to save state at a given point of the search is encapsulated by the \mintinline{python}{_consider_saving_state} and \mintinline{python}{_save_state} private methods.

\begin{minted}[firstnumber=last]{python}
    _num_eq_classes_since_last_save: int
    def _consider_saving_state(self) -> None:
        if self._save_options is not None:
            _, save_period, _ = self._save_options
            if (save_period is not None
                and self._num_eq_classes_since_last_save >= save_period):
                self._num_eq_classes_since_last_save = 0
                self._save_state()
                self._print_status_line()
    def _save_state(self) -> None:
        if self._save_options is not None:
            filename, _, save_backup = self._save_options
            self.save_state(filename, save_backup=save_backup)
\end{minted}


\subsection{More on \mintinline{python}{SpaceFinder._find_eq_classes}}

\begin{minted}[firstnumber=691]{python}
    def _find_eq_classes(self, new_hs: Sequence[History],
                         hs: Sequence[History] = tuple(),
                         hs_rest: Sequence[History] = tuple(),
                         level: int = 0) -> Iterator[HistorySet]:
        # pylint: disable = too-many-locals
        hs_so_far = tuple(chain(new_hs, hs))
        hs_perm_dict = self._histories_perm_dict
        partial_spaces_visited = self._partial_spaces_visited
        spaces_visited = self._eq_classes
        if level == 0:
            iter_child_subsets = self._iter_child_subsets_toplevel
        else:
            iter_child_subsets = self._iter_child_subsets
        for child_subset in iter_child_subsets(new_hs):
            child_subset_sorted = sorted(child_subset, key=history_sort_key)
            hs_so_far_rest = list(chain(new_hs, hs_rest))
            for k in child_subset_sorted:
                for j, h in enumerate(hs_so_far):
                    if is_subset(k, h):
                        hs_so_far_rest[j] = sub(hs_so_far_rest[j], k)
            winnowed_hs = tuple(h for j, h in enumerate(hs_so_far)
                                       if hs_so_far_rest[j])
            winnowed_hs_rest = tuple(
                h for h in hs_so_far_rest if h)
            partial_space = set(chain(child_subset_sorted, winnowed_hs))
            partial_space_bitvec = bitvec(partial_space)
            already_seen = (partial_space_bitvec in partial_spaces_visited
                            or partial_space_bitvec in spaces_visited)
            if not already_seen:
                eq_class = set()
                for p in self._perm_group:
                    p_action = hs_perm_dict[p]
                    perm_partial_space_bitvec = bitvec(p_action[h]
                                                       for h in partial_space)
                    eq_class.add(perm_partial_space_bitvec)
                    if (perm_partial_space_bitvec in partial_spaces_visited
                        or perm_partial_space_bitvec in spaces_visited):
                        already_seen = True
                        break
            if not already_seen:
                if all(self._domsize[h] == 1 for h in child_subset_sorted):
                    self._num_spaces += len(eq_class)
                    yield partial_space_bitvec
                else:
                    partial_spaces_visited.add(partial_space_bitvec)
                    yield from self._find_eq_classes(child_subset_sorted,
                                                     winnowed_hs,
                                                     winnowed_hs_rest,
                                                     level+1)
\end{minted}

\noindent At the start of the method, the sequence \mintinline{python}{hs_so_far} of all current candidate input histories is computed, and some persistent data structures are accessed and given shorter names.

\begin{minted}[firstnumber=696]{python}
        hs_so_far = tuple(chain(new_hs, hs))
        hs_perm_dict = self._histories_perm_dict
        partial_spaces_visited = self._partial_spaces_visited
        spaces_visited = self._eq_classes
\end{minted}

\noindent The rest of the method iterates over all subsets of child histories for the histories in \mintinline{python}{new_hs}.
Two different methods are used: the symmetry-optimised \mintinline{python}{self._iter_child_subsets_toplevel} is used at top-level (\mintinline{python}{level=0}), while the general purpose \mintinline{python}{self._iter_child_subsets} is used for all other levels.
In principle, the \mintinline{python}{self._iter_child_subsets} method could be used to iterate over child subsets at all levels, but the added efficiency of the \mintinline{python}{self._iter_child_subsets_toplevel} is helpful in the search on 4 events (plus, the symmetry argument is interesting in itself).
Each child subset yielded is sorted to make the search deterministic.

\begin{minted}[firstnumber=700]{python}
        if level == 0:
            iter_child_subsets = self._iter_child_subsets_toplevel
        else:
            iter_child_subsets = self._iter_child_subsets
        for child_subset in iter_child_subsets(new_hs, level):
            child_subset_sorted = sorted(child_subset, key=history_sort_key)
\end{minted}


\subsection{More on \mintinline{python}{SpaceFinder.find_eq_classes}}

\begin{minted}[firstnumber=740]{python}
    def find_eq_classes(self) -> None:
        """
            Start the search for equivalence classes.
        """
        if not self._initialised:
            raise Exception("Must initialise using blank_state() "
                            "or load_state(file).")
        update_period = self._update_period
        self._start_time = perf_counter()
        self._num_eq_classes_since_last_save = 0
        init_histories = max_histories(self.num_events)
        for eq_class_repr in self._find_eq_classes(init_histories):
            self._eq_classes.add(eq_class_repr)
            self._num_eq_classes_since_last_save += 1
            if (update_period is not None
                and self.num_eq_classes % update_period == 0):
                self._print_status_line()
        if update_period is not None:
            self._print_status_line()
        self._partial_spaces_visited.clear()
        self._save_state()
        self._describe()
\end{minted}


\subsection{More on \mintinline{python}{SpaceFinder._child_subset}}

\begin{minted}[firstnumber=last]{python}
    def _child_subset(self,
                      hs: Sequence[History],
                      child_hists: Sequence[History],
                      child_subset_bitvec: int,
                      hs_already_covered: frozenset[History] = frozenset(),
                      children_already_chosen: frozenset[History] = frozenset()
                      ) -> Optional[set[History]]:
        # pylint: disable = too-many-arguments
        hs_still_to_cover = set(hs)-hs_already_covered
        child_subset = set(children_already_chosen)
        idx = 0
        while child_subset_bitvec > 0:
            child_subset_bitvec, b = divmod(child_subset_bitvec, 2)
            if b:
                k = child_hists[idx]
                child_subset.add(k)
                if hs_still_to_cover:
                    hs_still_to_cover -= self._parents[k]
            idx += 1
        if not hs_still_to_cover:
            return child_subset
        return None
\end{minted}

\noindent The method starts by creating a set \mintinline{python}{hs_to_cover} of histories in \mintinline{python}{hs} still to be ``covered''---i.e. where at least one child has to yet appear in the subets---and a set \mintinline{python}{child_subset} of children extracted from the bitvector; the optional arguments \mintinline{python}{hs_already_covered} and \mintinline{python}{children_already_chosen} (empty by default) are used by the symmetry-optimized algorithm of method \mintinline{python}{_iter_child_subsets_toplevel} to modify these initial sets (because, in its logic, some histories are already known to be covered and some children are already known to be included in the subset to be yielded).


\subsection{\mintinline{python}{SpaceFinder._iter_child_subsets_toplevel}}

The private \mintinline{python}{_iter_child_subsets_toplevel} method implements a symmetry-optimized version of \mintinline{python}{_iter_child_subsets}, for use by the 4-event search.
Since we are only interested in finding equivalence classes of causally complete spaces under event-input permutation symmetry, the symmetry itself can be used to fix some redundant degrees of freedom in the child history subsets at the top level (\mintinline{python}{level=0}) of the search, because the set of parent histories \mintinline{python}{hs} at top level---the maximal extended input histories---is stabilised by the whole event-input permutation symmetry group.

\begin{minted}[firstnumber=796]{python}
    def _iter_child_subsets_toplevel(self,
                                     hs: Sequence[History]
                                     ) -> Iterator[set[History]]:
        if hasattr(self, "_fix_child_choice_idx"): # loaded previous state
            assert hasattr(self, "_num_todo")
            assert hasattr(self, "_num_done")
            assert hasattr(self, "_child_choices_list")
            assert hasattr(self, "_remaining_children_list")
            assert hasattr(self, "_fix_child_choice_idx")
            assert hasattr(self, "_var_child_subset_bitvec")
            ch_choices_list = tuple(
                frozenset(iter_bitvec(child_choice_bitvec))
                for child_choice_bitvec in self._child_choices_list)
            remaining_ch_list = tuple(
                set(iter_bitvec(rem_children_bv))
                for rem_children_bv in self._remaining_children_list)
        else:
            opt_fix_ch_choices = self._opt_fix_child_choices(hs,
                                                             self._perm_group)
            ch_choices_list, num_todo, remaining_ch_list = opt_fix_ch_choices
            self._num_todo = num_todo
            self._num_done = 0
            self._child_choices_list = [bitvec(child_choice)
                                        for child_choice in ch_choices_list]
            self._remaining_children_list = [bitvec(remaining_children)
                                             for remaining_children
                                             in remaining_ch_list]
            self._fix_child_choice_idx = 0
            self._var_child_subset_bitvec = 0
        self._num_remaining_children = [len(remaining_children)
                                        for remaining_children
                                        in remaining_ch_list]
        if self._verbose:
            self._print(f"Iterating over {self._num_todo} "
                        "top-level child history subsets.")
        self._print_status_header()
        fix_child_choice_idx = self._fix_child_choice_idx
        for child_choice, remaining_children in islice(zip(ch_choices_list,
                                                           remaining_ch_list),
                                                       fix_child_choice_idx,
                                                       None):
            rem_children_sorted = sorted(remaining_children, key=history_sort_key)
            hs_already_covered = frozenset(
                h for h in hs if child_choice&self._children_set[h])
            num_child_subsets = 2**len(rem_children_sorted)
            for child_subset_bitvec in range(self._var_child_subset_bitvec,
                                                num_child_subsets):
                child_subset = self._child_subset(hs, rem_children_sorted,
                                                  child_subset_bitvec,
                                                  hs_already_covered,
                                                  child_choice)
                self._num_done += 1
                if child_subset is not None:
                    yield child_subset
                if child_subset is not None and self._update_period is None:
                    self._print_status_line()
                self._var_child_subset_bitvec += 1
                if child_subset is not None:
                    self._consider_saving_state()
            self._var_child_subset_bitvec = 0
            self._fix_child_choice_idx += 1
\end{minted}

\noindent At the start of the method, we check whether the data structures associated to symmetry-optimised search already exist: if they do, it means that we are resuming a previous search, and we don't need to create them.

\begin{minted}[firstnumber=799]{python}
        if hasattr(self, "_fix_child_choice_idx"): # loaded previous state
            assert hasattr(self, "_num_todo")
            assert hasattr(self, "_num_done")
            assert hasattr(self, "_child_choices_list")
            assert hasattr(self, "_remaining_children_list")
            assert hasattr(self, "_fix_child_choice_idx")
            assert hasattr(self, "_var_child_subset_bitvec")
            ch_choices_list = tuple(
                frozenset(iter_bitvec(child_choice_bitvec))
                for child_choice_bitvec in self._child_choices_list)
            remaining_ch_list = tuple(
                set(iter_bitvec(rem_children_bv))
                for rem_children_bv in self._remaining_children_list)
\end{minted}

\noindent If the necessary data structures don't exist, we create them instead.
The \mintinline{python}{_opt_fix_child_choices} returns a triple:
\begin{itemize}
    \item A list \mintinline{python}{ch_choices_list} of ``fixed'' children subsets, where event-input permutation symmetry has been used to remove unnecessary choices.
    \item The number \mintinline{python}{num_todo} of top-level children subsets that will need to be iterated over.
    \item A list \mintinline{python}{remaining_ch_list} of largest ``variable'' children subsets corresponding to each ``fixed'' children subset in \mintinline{python}{ch_choices_list} (which has the same length). For each ``fixed'' children subset, all subsets of the corresponding largest ``variable'' children subset will be iterated over.
\end{itemize}
We store the bitvectors for the two lists above for search state serialisation.
We initialise two counters: the \mintinline{python}{_fix_child_choice_idx} index, tracking the current ``fixed'' child subset, and the \mintinline{python}{_var_child_subset_bitvec} bitvector, tracking the current ``variable'' children subset.

\begin{minted}[firstnumber=812]{python}
        else:
            opt_fix_ch_choices = self._opt_fix_child_choices(hs,
                                                             self._perm_group)
            ch_choices_list, num_todo, remaining_ch_list = opt_fix_ch_choices
            self._num_todo = num_todo
            self._num_done = 0
            self._child_choices_list = [bitvec(child_choice)
                                        for child_choice in ch_choices_list]
            self._remaining_children_list = [bitvec(remaining_children)
                                             for remaining_children
                                             in remaining_ch_list]
            self._fix_child_choice_idx = 0
            self._var_child_subset_bitvec = 0
\end{minted}

\noindent Regardless of whether this is a new search or a resumed search, we store a list of sizes of the maximal ``variable'' child subsets, for use when computing completion percentages in search status printouts.
If required, we then print the number of top-level child subsets that will be iterated over, as well as the header for the search status metric table.

\begin{minted}[firstnumber=825]{python}
        self._num_remaining_children = [len(remaining_children)
                                        for remaining_children
                                        in remaining_ch_list]
        if self._verbose:
            self._print(f"Iterating over {self._num_todo} "
                        "top-level child history subsets.")
        self._print_status_header()
\end{minted}

\noindent After the setup, we proceed to iterate through all possible ``fixed'' children subsets \mintinline{python}{child_choice}, and the corresponding maximal ``variable'' children subsets \mintinline{python}{remaining_children}; we start from index \mintinline{python}{fix_child_choice_idx}, which might be non-zero if our search was resumed from loaded state.
For each pair, we sort the remaining children (to make the search deterministic), compute the set \mintinline{python}{hs_already_covered} of histories in \mintinline{python}{hs} that have a child in the ``fixed'' children subset, and proceed to iterate through the bitvectors of all ``variable'' children subsets, i.e. all possible subsets of \mintinline{python}{remaining_children}.

\begin{minted}[firstnumber=832]{python}
        fix_child_choice_idx = self._fix_child_choice_idx
        for child_choice, remaining_children in islice(zip(ch_choices_list,
                                                           remaining_ch_list),
                                                       fix_child_choice_idx,
                                                       None):
            rem_children_sorted = sorted(remaining_children, key=history_sort_key)
            hs_already_covered = frozenset(
                h for h in hs if child_choice&self._children_set[h])
            num_child_subsets = 2**len(rem_children_sorted)
            for child_subset_bitvec in range(self._var_child_subset_bitvec,
                                                num_child_subsets):
\end{minted}

\noindent For each bitvector, the \mintinline{python}{_child_subset} method is called to obtain the corresponding ``variable'' children subset \mintinline{python}{child_subset}, or \mintinline{python}{None} if some history in \mintinline{python}{hs} doesn't have a child in that subset.
If the subset is not \mintinline{python}{None}, we yield it; we also consider adding a line to the search status table (if required) and saving the search state (if required).
Before state serialisation, we increase the ``variable'' children subset bitvector counter \mintinline{python}{_var_child_subset_bitvec} by 1, thus moving to the next bitvector.

\begin{minted}[firstnumber=843]{python}
                child_subset = self._child_subset(hs, rem_children_sorted,
                                                  child_subset_bitvec,
                                                  hs_already_covered,
                                                  child_choice)
                self._num_done += 1
                if child_subset is not None:
                    yield child_subset
                if child_subset is not None and self._update_period is None:
                    self._print_status_line()
                self._var_child_subset_bitvec += 1
                if child_subset is not None:
                    self._consider_saving_state()
\end{minted}

\noindent When all ``fixed'' children subsets have been iterated over, we reset the corresponding bitvector counter and we increase the ``fixed'' children subset index counter by 1, thus moving to the next ``fixed'' subset.

\begin{minted}[firstnumber=855]{python}
            self._var_child_subset_bitvec = 0
            self._fix_child_choice_idx += 1
\end{minted}


\subsection{\mintinline{python}{SpaceFinder._fix_child_choices}}

The private \mintinline{python}{_fix_child_choices} method implements the core logic for the symmetry optimisation.
It takes a sequence \mintinline{python}{hs} of histories and a subgroup \mintinline{python}{stab} of the event-input permutation group.
It returns a list of pairs \mintinline{python}{(children_to_include, children_to_avoid)}, where \mintinline{python}{children_to_include} is a ``fixed'' children subset and \mintinline{python}{children_to_avoid} is used by \mintinline{python}{_opt_fix_child_choices} to compute the corresponding maximal ``variable'' children subset.
The method's logic is recusive, with a \mintinline{python}{depth} kwarg to keep track of recursion depth and a \mintinline{python}{max_depth} kwarg specifying a recursion cutoff (with \mintinline{python}{None} indicating no maximum depth).
The \mintinline{python}{children_to_include} and \mintinline{python}{children_to_avoid} optional arguments are used by the recursive calls (see later).
At the first call (\mintinline{python}{depth=0}), \mintinline{python}{hs} is set to the maximal extended input histories and \mintinline{python}{stab} is set to the entirety of the event-input permutation group.

\begin{minted}[firstnumber=857]{python}
    def _fix_child_choices(self,
                           hs: Sequence[History],
                           perm_group: Sequence[PermGroupEl],
                           children_to_include: frozenset[History]=frozenset(),
                           children_to_avoid: frozenset[History]=frozenset(), *,
                           depth: int = 0,
                           max_depth: Optional[int] = None
                           ) -> list[tuple[frozenset[History],
                                           frozenset[History]]]:
        # pylint: disable = too-many-locals, too-many-branches
        if (len(perm_group) == 1
            or not hs
            or (max_depth is not None and depth > max_depth)
            ):
            return [(frozenset(), frozenset())]
        def select_h_child_subset(s: Set[History],
                                  h_children_to_include: Set[History]) -> bool:
            if s&children_to_avoid:
                return False
            if h_children_to_include <= s:
                return True
            return False
        best: Optional[tuple[History,
                             Mapping[frozenset[History],
                                     list[PermGroupEl]]]] = None
        hs_new_fixed = []
        for h in hs:
            h_children = self._children[h]
            h_children_to_include = children_to_include&self._children_set[h]
            h_children_sel_subsets = sorted(
                (s for t in powerset(h_children)
                 if select_h_child_subset(s:=frozenset(t),
                                          h_children_to_include)),
                key=lambda s: (-len(s), sorted(s, key=history_sort_key)))
            h_children_subsets = {}
            h_children_subsets_seen = set()
            for ks in h_children_sel_subsets:
                if (not ks) or ks in h_children_subsets_seen:
                    continue
                ks_stab = []
                for p in perm_group:
                    p_action = self._histories_perm_dict[p]
                    ks_perm = frozenset(p_action[k] for k in ks)
                    if ks == ks_perm:
                        ks_stab.append(p)
                    h_children_subsets_seen.add(ks_perm)
                h_children_subsets[ks] = ks_stab
            if len(h_children_subsets) >= 1:
                if best is None or len(h_children_subsets) < len(best[1]):
                    best = (h, h_children_subsets)
            else:
                hs_new_fixed.append(h)
        if best is None:
            return [(frozenset(), frozenset())]
        best_h, best_h_children_subsets = best
        hs_new_fixed.append(best_h)
        new_hs = tuple(h for h in hs if h not in hs_new_fixed)
        seen = set()
        child_choices = []
        for ks, ks_stab in best_h_children_subsets.items():
            new_children_to_include = children_to_include|ks
            new_children_to_avoid = (children_to_avoid
                                     |frozenset(self._children[best_h])-ks)
            rec_child_choices = self._fix_child_choices(new_hs, ks_stab,
                                                        new_children_to_include,
                                                        new_children_to_avoid,
                                                        depth=depth+1,
                                                        max_depth=max_depth)
            for rec_child_choice in rec_child_choices:
                rec_children_to_include, rec_children_to_avoid = rec_child_choice
                child_choice = (rec_children_to_include|ks,
                                new_children_to_avoid|rec_children_to_avoid)
                if child_choice not in seen:
                    seen.add(child_choice)
                    child_choices.append(child_choice)
        return child_choices
\end{minted}

\noindent At the start of the method, we perform some termination checks:
\begin{enumerate}
    \item if \mintinline{python}{hs} is empty, we have no further histories to consider
    \item if \mintinline{python}{perm_group} is the trivial subgroup, we have no further symmetries available to reduce our subsets
    \item if we exceeded the max recursion depth, we terminate our search
\end{enumerate}
Whatever the case may be, we return an empty set of children to include and an empty subset of children to avoid.

\begin{minted}[firstnumber=867]{python}
        if (len(perm_group) == 1
            or not hs
            or (max_depth is not None and depth > max_depth)
            ):
            return [(frozenset(), frozenset())]
\end{minted}

\noindent We then create a small utility function \mintinline{python}{select_h_child_subset}, checking whether a given set \mintinline{python}{s} of child histories includes another given set \mintinline{python}{h_children_to_include} of child histories and is disjoint from the set \mintinline{python}{children_to_avoid}.

\begin{minted}[firstnumber=872]{python}
        def select_h_child_subset(s: Set[History],
                                  h_children_to_include: Set[History]) -> bool:
            if s&children_to_avoid:
                return False
            if h_children_to_include <= s:
                return True
            return False
\end{minted}

\noindent We will shortly be iterating over all \mintinline{python}{h in hs}, looking for a best \mintinline{python}{h} to select in this iteration.
If not \mintinline{python}{None}, \mintinline{python}{best} will contain the pair \mintinline{python}{(h, h_children_subsets)} of the current best \mintinline{python}{h in hs} and a mapping of each selected subset of the children of \mintinline{python}{h} to the corresponding stabiliser subgroup of \mintinline{python}{perm_group}.
Along the way, we will also grow a list \mintinline{python}{hs_new_fixed} of histories \mintinline{python}{h in hs} for which no selected subsets are available (i.e. the choice of subset of children histories is uniquely fixed by previous choices).

\begin{minted}[firstnumber=879]{python}
        best: Optional[tuple[History,
                             Mapping[frozenset[History],
                                     list[PermGroupEl]]]] = None
        hs_new_fixed = []
\end{minted}

\noindent For each \mintinline{python}{h in hs}, we compute the list of selected subsets.
These are subsets of the hildren of \mintinline{python}{h} which include at least all child histories of \mintinline{python}{h} that are in \mintinline{python}{children_to_include}, and include no child histories of \mintinline{python}{h} that are in \mintinline{python}{children_to_avoid}.
To make the search deterministic, the selected subsets are sorted first by decreasing length, and then by content.

\begin{minted}[firstnumber=883]{python}
        for h in hs:
            h_children = self._children[h]
            h_children_to_include = children_to_include&self._children_set[h]
            h_children_sel_subsets = sorted(
                (s for t in powerset(h_children)
                 if select_h_child_subset(s:=frozenset(t),
                                          h_children_to_include)),
                key=lambda s: (-len(s), sorted(s, key=history_sort_key)))
\end{minted}

\noindent We then proceed to look at the orbits of the selected subsets in \mintinline{python}{h_children_sel_subsets} under the permutation group \mintinline{python}{perm_group}: we select a representative from each orbit and store it in the dictionary \mintinline{python}{h_children_subsets}, together with the associated stabiliser subgroup of \mintinline{python}{perm_group}.

\begin{minted}[firstnumber=891]{python}
            h_children_subsets = {}
            h_children_subsets_seen = set()
            for ks in h_children_sel_subsets:
                if (not ks) or ks in h_children_subsets_seen:
                    continue
                ks_stab = []
                for p in perm_group:
                    p_action = self._histories_perm_dict[p]
                    ks_perm = frozenset(p_action[k] for k in ks)
                    if ks == ks_perm:
                        ks_stab.append(p)
                    h_children_subsets_seen.add(ks_perm)
                h_children_subsets[ks] = ks_stab
\end{minted}

\noindent If there were no non-empty selected subsets of children, it means that the choice of children subset for history \mintinline{python}{h} was fixed by previous choices, so we add \mintinline{python}{h} to \mintinline{python}{hs_new_fixed}.
Otherwise, we check whether the children subsets for \mintinline{python}{h} have fewer orbits under the permutation group than the previous best choice (if any): if this is the case, we store \mintinline{python}{h}, the orbit representatives and the associated stabiliser subgroups as our new best choice.

\begin{minted}[firstnumber=904]{python}
            if len(h_children_subsets) >= 1:
                if best is None or len(h_children_subsets) < len(best[1]):
                    best = (h, h_children_subsets)
            else:
                hs_new_fixed.append(h)
\end{minted}

\noindent If \mintinline{python}{best=None} at the end of the previous loop, it means that all histories are fixed, so we terminate the same way as we would at the start of the method for the case where \mintinline{python}{hs} is empty.
Otherwise, we add the best history \mintinline{python}{best_h} to the list of fixed histories---it's the one that we're fixing at this particular call.
The histories \mintinline{python}{new_hs} that will be passed to the recursive calls to \mintinline{python}{_fix_child_choices} are those histories in \mintinline{python}{hs} the subsets of which have not yet been completely fixed (i.e. those in \mintinline{python}{hs_new_fixed}).

\begin{minted}[firstnumber=909]{python}
        if best is None:
            return [(frozenset(), frozenset())]
        best_h, best_h_children_subsets = best
        hs_new_fixed.append(best_h)
        new_hs = tuple(h for h in hs if h not in hs_new_fixed)
\end{minted}

\noindent Next, we iterate through each orbit representative \mintinline{python}{ks} for the subsets of child histories of \mintinline{python}{best_h}, with associated stabiliser subgroup \mintinline{python}{ks_stab}.
The representative \mintinline{python}{ks} is exactly the set of children of \mintinline{python}{best_h} that will be included by all top-level child subsets added in this step of the iteration, while its complement \mintinline{python}{frozenset(self._children[best_h])-ks} is exactly the set of children of \mintinline{python}{best_h} that will be excluded by all top-level child subsets added in this step of the iteration.

We make a recursive call to \mintinline{python}{_fix_child_choices} to obtain a list of children to include/avoid for the histories in \mintinline{python}{hs}, where the subset \mintinline{python}{ks} is added to the previous children to be included and its complement \mintinline{python}{frozenset(self._children[best_h])-ks} is added to the previous children to be avoided.

\begin{minted}[firstnumber=914]{python}
        for ks, ks_stab in best_h_children_subsets.items():
            new_children_to_include = children_to_include|ks
            new_children_to_avoid = (children_to_avoid
                                     |frozenset(self._children[best_h])-ks)
            rec_child_choices = self._fix_child_choices(new_hs, ks_stab,
                                                        new_children_to_include,
                                                        new_children_to_avoid,
                                                        depth=depth+1,
                                                        max_depth=max_depth)
\end{minted}

\noindent We take each recursively computed pair of children to include \mintinline{python}{rec_children_to_include} and children to avoid \mintinline{python}{rec_children_to_avoid}, we add \mintinline{python}{ks} to the former and \mintinline{python}{new_children_to_avoid} to obtain a new pair \mintinline{python}{child_choice} of children to include/avoid, and we add it to \mintinline{python}{child_choices} if it doesn't yet appear in it.

\begin{minted}[firstnumber=925]{python}
            for rec_child_choice in rec_child_choices:
                rec_children_to_include, rec_children_to_avoid = rec_child_choice
                child_choice = (rec_children_to_include|ks,
                                rec_children_to_avoid|new_children_to_avoid)
                if child_choice not in seen:
                    seen.add(child_choice)
                    child_choices.append(child_choice)
\end{minted}

\noindent At the end, we return the list \mintinline{python}{child_choices}.
As an example, below is the first branch of recursion for the call to \mintinline{python}{_fix_child_choices} performed by the search on 3 events.
We start at depth 0, with the maximal extended input histories as \mintinline{python}{hs} and with the full event-input permutation symmetry group as \mintinline{python}{perm_group}.
There are no children to include and no children to avoid at depth 0.

The algorithm selects the history \hist{A/0,B/0,C/0}: it has 7 selected children subsets, falling into 3 orbits (in fact, all choices at depth 0 give the same result, because of symmetry).
A representative for each orbit is displayed below, along with the size of its stabiliser within the 48-element group \mintinline{python}{perm_group}.

\begin{minted}[linenos=false]{text}
->initial call at depth 0
  perm_group (size 48):
    whole event-input symmetry group
  children to include:
    none
  children to avoid:
    none
  best_h: {'A': 0, 'B': 0, 'C': 0}
  children: [{'A': 0, 'B': 0}, {'A': 0, 'C': 0}, {'B': 0, 'C': 0}]
  number of selected children subsets: 7
  representatives for children subset orbits: 
    0: {{'A': 0, 'C': 0}, {'B': 0, 'C': 0}, {'A': 0, 'B': 0}}, stab size 6
    1: {{'A': 0, 'C': 0}, {'A': 0, 'B': 0}}, stab size 2
    2: {{'A': 0, 'B': 0}}, stab size 4
\end{minted}

\noindent We consider representative $\{\hist{A/0,C/0}, \hist{B/0, C/0}, \hist{A/0, B/0}\}$ from depth 0 above and look at the corresponding recursive call.
The permutation group \mintinline{python}{perm_group} used by the recursive call is the 6-element stabiliser subgroup for the chosen representative, within the 48-element permutation group used by the previous call.
The child histories in the chosen representatives appear now as children to include for the recursive call, while their complement (the empty subset) appears as children to avoid for the recursive call.

At depth 1, the algorithm selects the history \hist{A/0,B/0,C/1}: it has 4 selected children subsets, falling into 3 orbits.
A representative for each orbit is displayed below, along with the size of its stabiliser within the 6-element group \mintinline{python}{perm_group}.

\begin{minted}[linenos=false]{text}
  ->recursive call at depth 1 (path=0)
    perm_group (size 6):
      (('A', 'B', 'C'), (0, 0, 0))
      (('A', 'C', 'B'), (0, 0, 0))
      (('B', 'A', 'C'), (0, 0, 0))
      (('B', 'C', 'A'), (0, 0, 0))
      (('C', 'A', 'B'), (0, 0, 0))
      (('C', 'B', 'A'), (0, 0, 0))
    children to include:
      {'A': 0, 'C': 0}
      {'B': 0, 'C': 0}
      {'A': 0, 'B': 0}
    children to avoid:
      none
    best_h: {'A': 0, 'B': 0, 'C': 1}
    children: [{'A': 0, 'B': 0}, {'A': 0, 'C': 1}, {'B': 0, 'C': 1}]
    number of selected children subsets: 4
    representatives for children subset orbits: 
      00: {{'A': 0, 'C': 1}, {'B': 0, 'C': 1}, {'A': 0, 'B': 0}}, stab size 2
      01: {{'A': 0, 'C': 1}, {'A': 0, 'B': 0}}, stab size 1
      02: {{'A': 0, 'B': 0}}, stab size 2
\end{minted}

\noindent We consider representative $\{\hist{A/0,C/1}, \hist{B/0, C/1}, \hist{A/0, B/0}\}$ from depth 1 above and look at the corresponding recursive call.
The permutation group \mintinline{python}{perm_group} used by the recursive call is the 2-element stabiliser subgroup for the chosen representative, within the 6-element permutation group used by the previous call.
The child histories in the chosen representatives are added to the children to include for the recursive call, while their complement (the empty subset) is added to the children to avoid for the recursive call.

At depth 2, the algorithm selects the history \hist{A/0,B/1,C/0}: it has 4 selected children subsets, falling into 4 orbits.
A representative for each orbit is displayed below, along with the size of its stabiliser within the 6-element group \mintinline{python}{perm_group}.
Because all stabilisers have size 1, no further steps are taken in this recursive branch.

\begin{minted}[linenos=false]{text}
    ->recursive call at depth 2 (path=00)
      perm_group (size 2):
        (('A', 'B', 'C'), (0, 0, 0))
        (('B', 'A', 'C'), (0, 0, 0))
      children to include:
        {'A': 0, 'C': 0}
        {'A': 0, 'C': 1}
        {'B': 0, 'C': 0}
        {'A': 0, 'B': 0}
        {'B': 0, 'C': 1}
      children to avoid:
        none
      best_h: {'A': 0, 'B': 1, 'C': 0}
      children: [{'A': 0, 'B': 1}, {'A': 0, 'C': 0}, {'B': 1, 'C': 0}]
      number of selected children subsets: 4
      representatives for children subset orbits: 
        000: {{'B': 1, 'C': 0}, {'A': 0, 'B': 1}, {'A': 0, 'C': 0}}, stab size 1
        001: {{'A': 0, 'B': 1}, {'A': 0, 'C': 0}}, stab size 1
        002: {{'B': 1, 'C': 0}, {'A': 0, 'C': 0}}, stab size 1
        003: {{'A': 0, 'C': 0}}, stab size 1
\end{minted}

\noindent As an alternative example, we consider representative $\{\hist{A/0,C/0}, \hist{A/0, B/0}\}$ from depth 0 instead, and look again at the corresponding recursive call.
The permutation group \mintinline{python}{perm_group} used by the recursive call is the 2-element stabiliser subgroup for the chosen representative, within the 48-element permutation group used by the previous call.
The child histories in the chosen representatives appear now as children to include for the recursive call, while their complement appears as children to avoid for the recursive call.

At depth 1, the algorithm selects the history \hist{A/1,B/0,C/0}: it has 3 selected children subsets, falling into 2 orbits.
A representative for each orbit is displayed below, along with the size of its stabiliser within the 2-element group \mintinline{python}{perm_group}.

\begin{minted}[linenos=false]{text}
  ->recursive call at depth 1 (path=1)
    perm_group (size 2):
      (('A', 'B', 'C'), (0, 0, 0))
      (('A', 'C', 'B'), (0, 0, 0))
    children to include:
      {'A': 0, 'C': 0}
      {'A': 0, 'B': 0}
    children to avoid:
      {'B': 0, 'C': 0}
    best_h: {'A': 1, 'B': 0, 'C': 0}
    children: [{'A': 1, 'B': 0}, {'A': 1, 'C': 0}, {'B': 0, 'C': 0}]
    number of selected children subsets: 3
    representatives for children subset orbits: 
      10: {{'A': 1, 'C': 0}, {'A': 1, 'B': 0}}, stab size 2
      11: {{'A': 1, 'B': 0}}, stab size 1
\end{minted}

\noindent We consider representative $\{\hist{A/1,C/0}, \hist{A/1, B/0}\}$ from depth 1 above and look at the corresponding recursive call.
The permutation group \mintinline{python}{perm_group} used by the recursive call is the full 2-element permutation group used by the previous call.
The child histories in the chosen representatives are added to the children to include for the recursive call, while their complement (the empty subset) is added to the children to avoid for the recursive call.

At depth 2, the algorithm selects the history \hist{A/0,B/0,C/1}: it has 4 selected children subsets, falling into 4 orbits.
A representative for each orbit is displayed below, along with the size of its stabiliser within the 2-element group \mintinline{python}{perm_group}.
Because all stabilisers have size 1, no further steps are taken in this recursive branch either.

\begin{minted}[linenos=false]{text}
    ->recursive call at depth 2 (path=10)
      perm_group (size 2):
        (('A', 'B', 'C'), (0, 0, 0))
        (('A', 'C', 'B'), (0, 0, 0))
      children to include:
        {'A': 0, 'C': 0}
        {'A': 1, 'C': 0}
        {'A': 0, 'B': 0}
        {'A': 1, 'B': 0}
      children to avoid:
        {'B': 0, 'C': 0}
      best_h: {'A': 0, 'B': 0, 'C': 1}
      children: [{'A': 0, 'B': 0}, {'A': 0, 'C': 1}, {'B': 0, 'C': 1}]
      number of selected children subsets: 4
      representatives for children subset orbits: 
        100: {{'A': 0, 'C': 1}, {'B': 0, 'C': 1}, {'A': 0, 'B': 0}}, stab size 1
        101: {{'A': 0, 'C': 1}, {'A': 0, 'B': 0}}, stab size 1
        102: {{'B': 0, 'C': 1}, {'A': 0, 'B': 0}}, stab size 1
        103: {{'A': 0, 'B': 0}}, stab size 1
\end{minted}

\noindent Finally, below is the full printout for a recursive path reaching down to depth 7.

\begin{minted}[linenos=false]{text}
->initial call at depth 0
  perm_group (size 48):
    whole event-input symmetry group
  children to include:
    none
  children to avoid:
    none
  best_h: {'A': 0, 'B': 0, 'C': 0}
  children: [{'A': 0, 'B': 0}, {'A': 0, 'C': 0}, {'B': 0, 'C': 0}]
  number of selected children subsets: 7
  representatives for children subset orbits: 
    0: {{'A': 0, 'C': 0}, {'B': 0, 'C': 0}, {'A': 0, 'B': 0}}, stab size 6
    1: {{'A': 0, 'C': 0}, {'A': 0, 'B': 0}}, stab size 2
    2: {{'A': 0, 'B': 0}}, stab size 4
  ->recursive call at depth 1 (path=2)
    perm_group (size 4):
      (('A', 'B', 'C'), (0, 0, 0))
      (('A', 'B', 'C'), (0, 0, 1))
      (('B', 'A', 'C'), (0, 0, 0))
      (('B', 'A', 'C'), (0, 0, 1))
    children to include:
      {'A': 0, 'B': 0}
    children to avoid:
      {'A': 0, 'C': 0}
      {'B': 0, 'C': 0}
    best_h: {'A': 0, 'B': 0, 'C': 1}
    children: [{'A': 0, 'B': 0}, {'A': 0, 'C': 1}, {'B': 0, 'C': 1}]
    number of selected children subsets: 4
    representatives for children subset orbits: 
      20: {{'A': 0, 'C': 1}, {'B': 0, 'C': 1}, {'A': 0, 'B': 0}}, stab size 2
      21: {{'A': 0, 'C': 1}, {'A': 0, 'B': 0}}, stab size 1
      22: {{'A': 0, 'B': 0}}, stab size 4
    ->recursive call at depth 2 (path=22)
      perm_group (size 4):
        (('A', 'B', 'C'), (0, 0, 0))
        (('A', 'B', 'C'), (0, 0, 1))
        (('B', 'A', 'C'), (0, 0, 0))
        (('B', 'A', 'C'), (0, 0, 1))
      children to include:
        {'A': 0, 'B': 0}
      children to avoid:
        {'A': 0, 'C': 0}
        {'B': 0, 'C': 0}
        {'B': 0, 'C': 1}
        {'A': 0, 'C': 1}
      best_h: {'A': 0, 'B': 1, 'C': 0}
      children: [{'A': 0, 'B': 1}, {'A': 0, 'C': 0}, {'B': 1, 'C': 0}]
      number of selected children subsets: 3
      representatives for children subset orbits: 
        220: {{'B': 1, 'C': 0}, {'A': 0, 'B': 1}}, stab size 1
        221: {{'A': 0, 'B': 1}}, stab size 2
        222: {{'B': 1, 'C': 0}}, stab size 1
      ->recursive call at depth 3 (path=221)
        perm_group (size 2):
          (('A', 'B', 'C'), (0, 0, 0))
          (('A', 'B', 'C'), (0, 0, 1))
        children to include:
          {'A': 0, 'B': 1}
          {'A': 0, 'B': 0}
        children to avoid:
          {'A': 0, 'C': 0}
          {'A': 0, 'C': 1}
          {'B': 0, 'C': 0}
          {'B': 0, 'C': 1}
          {'B': 1, 'C': 0}
        best_h: {'A': 0, 'B': 1, 'C': 1}
        children: [{'A': 0, 'B': 1}, {'A': 0, 'C': 1}, {'B': 1, 'C': 1}]
        number of selected children subsets: 2
        representatives for children subset orbits: 
          2210: {{'B': 1, 'C': 1}, {'A': 0, 'B': 1}}, stab size 1
          2211: {{'A': 0, 'B': 1}}, stab size 2
        ->recursive call at depth 4 (path=2211)
          perm_group (size 2):
            (('A', 'B', 'C'), (0, 0, 0))
            (('A', 'B', 'C'), (0, 0, 1))
          children to include:
            {'A': 0, 'B': 1}
            {'A': 0, 'B': 0}
          children to avoid:
            {'A': 0, 'C': 0}
            {'A': 0, 'C': 1}
            {'B': 0, 'C': 0}
            {'B': 0, 'C': 1}
            {'B': 1, 'C': 0}
            {'B': 1, 'C': 1}
          best_h: {'A': 1, 'B': 0, 'C': 0}
          children: [{'A': 1, 'B': 0}, {'A': 1, 'C': 0}, {'B': 0, 'C': 0}]
          number of selected children subsets: 3
          representatives for children subset orbits: 
            22110: {{'A': 1, 'C': 0}, {'A': 1, 'B': 0}}, stab size 1
            22111: {{'A': 1, 'B': 0}}, stab size 2
            22112: {{'A': 1, 'C': 0}}, stab size 1
          ->recursive call at depth 5 (path=22111)
            perm_group (size 2):
              (('A', 'B', 'C'), (0, 0, 0))
              (('A', 'B', 'C'), (0, 0, 1))
            children to include:
              {'A': 0, 'B': 1}
              {'A': 0, 'B': 0}
              {'A': 1, 'B': 0}
            children to avoid:
              {'A': 0, 'C': 0}
              {'A': 0, 'C': 1}
              {'A': 1, 'C': 0}
              {'B': 0, 'C': 0}
              {'B': 0, 'C': 1}
              {'B': 1, 'C': 0}
              {'B': 1, 'C': 1}
            best_h: {'A': 1, 'B': 1, 'C': 0}
            children: [{'A': 1, 'B': 1}, {'A': 1, 'C': 0}, {'B': 1, 'C': 0}]
            number of selected children subsets: 1
            representatives for children subset orbits: 
              221110: {{'A': 1, 'B': 1}}, stab size 2
            ->recursive call at depth 6 (path=221110)
              perm_group (size 2):
                (('A', 'B', 'C'), (0, 0, 0))
                (('A', 'B', 'C'), (0, 0, 1))
              children to include:
                {'A': 0, 'B': 1}
                {'A': 1, 'B': 1}
                {'A': 0, 'B': 0}
                {'A': 1, 'B': 0}
              children to avoid:
                {'A': 0, 'C': 1}
                {'B': 0, 'C': 1}
                {'B': 1, 'C': 1}
                {'A': 0, 'C': 0}
                {'A': 1, 'C': 0}
                {'B': 0, 'C': 0}
                {'B': 1, 'C': 0}
              best_h: {'A': 1, 'B': 0, 'C': 1}
              children: [{'A': 1, 'B': 0}, {'A': 1, 'C': 1}, {'B': 0, 'C': 1}]
              number of selected children subsets: 2
              representatives for children subset orbits: 
                2211100: {{'A': 1, 'C': 1}, {'A': 1, 'B': 0}}, stab size 1
                2211101: {{'A': 1, 'B': 0}}, stab size 2
              ->recursive call at depth 7 (path=2211101)
                perm_group (size 2):
                  (('A', 'B', 'C'), (0, 0, 0))
                  (('A', 'B', 'C'), (0, 0, 1))
                children to include:
                  {'A': 0, 'B': 0}
                  {'A': 1, 'B': 0}
                  {'A': 0, 'B': 1}
                  {'A': 1, 'B': 1}
                children to avoid:
                  {'A': 0, 'C': 1}
                  {'A': 1, 'C': 1}
                  {'B': 0, 'C': 1}
                  {'B': 1, 'C': 1}
                  {'A': 0, 'C': 0}
                  {'A': 1, 'C': 0}
                  {'B': 0, 'C': 0}
                  {'B': 1, 'C': 0}
                best_h: {'A': 1, 'B': 1, 'C': 1}
                children: [{'A': 1, 'B': 1}, {'A': 1, 'C': 1}, {'B': 1, 'C': 1}]
                number of selected children subsets: 1
                representatives for children subset orbits: 
                  22111010: {{'A': 1, 'B': 1}}, stab size 2
\end{minted}


\subsection{\mintinline{python}{SpaceFinder._opt_fix_child_choices}}

The private \mintinline{python}{_opt_fix_child_choices} method runs at various maximum depths to obtain a sequence of ``fixed'' children subset choices which minimises the number of top-level children subsets to be iterated over.
It does so by progressively increasing the maximum depth, stopping at the point where the overall number of top-level children subsets starts to increase (i.e. it stops at the first local minimum).

The method takes a sequence \mintinline{python}{hs} of histories and a subgroup \mintinline{python}{stab} of the event-input permutation group.
In the current implementation, where the method is called only at top-level, \mintinline{python}{hs} is always the sequence of maximum extended input histories for the given number of events, while \mintinline{python}{stab} is always the full event-input permutation group.
However, this method could also be applied at lower levels, using as \mintinline{python}{stab} the subgroup of permutations which stabilise the set of input histories \mintinline{python}{set(hs)}.

\begin{minted}[firstnumber=933]{python}
    def _opt_fix_child_choices(self, hs: Sequence[History],
                               perm_group: Sequence[PermGroupEl]
                              ) -> tuple[tuple[frozenset[History], ...],
                                         int,
                                         tuple[set[History], ...]]:
        child_hists_set = {k for h in hs for k in self._children[h]}
        toplevel_opt_depth = self._toplevel_opt_depth
        if toplevel_opt_depth is None:
            toplevel_opt_depth = len(hs)
        if self._verbose:
            self._print(f"Brute-forcing complexity: {2**len(child_hists_set)}"
                         " top-level child history subsets.")
            if toplevel_opt_depth >= 0:
                self._print("Optimising top-level child history subsets"
                            f" (max depth {toplevel_opt_depth}).")
        best: Optional[tuple[list[tuple[frozenset[History],
                                        frozenset[History]]],
                             int,
                             list[set[History]]
                            ]] = None
        for max_depth in range(-1, toplevel_opt_depth+1):
            fixed_child_choices = self._fix_child_choices(hs, perm_group,
                                                          max_depth=max_depth)
            num_todo = 0
            remaining_children_list = []
            for child_choice, children_to_avoid in fixed_child_choices:
                remaining_children = (child_hists_set
                                      -(child_choice|children_to_avoid))
                num_todo += 2**len(remaining_children)
                remaining_children_list.append(remaining_children)
            if best is None or num_todo <= best[1]:
                if self._verbose:
                    if max_depth >= 0:
                        self._print(f"  {num_todo} subsets at "
                                   f"optimisation depth {max_depth}")
                best = (fixed_child_choices, num_todo, remaining_children_list)
            else:
                break
        assert best is not None
        return (tuple(child_choice for child_choice, _ in best[0]),
                best[1], tuple(best[2]))
\end{minted}

\noindent At the start, we create the set of child histories for all histories in \mintinline{python}{hs}, set the maximum optimisation depth to the length of \mintinline{python}{hs} if not already set, and print some information about the optimisation process (if required).

\begin{minted}[firstnumber=938]{python}
        child_hists_set = {k for h in hs for k in self._children[h]}
        toplevel_opt_depth = self._toplevel_opt_depth
        if toplevel_opt_depth is None:
            toplevel_opt_depth = len(hs)
        if self._verbose:
            self._print(f"Brute-forcing complexity: {2**len(child_hists_set)}"
                         " top-level child history subsets.")
            if toplevel_opt_depth >= 0:
                self._print("Optimising top-level child history subsets"
                            f" (max depth {toplevel_opt_depth}).")
\end{minted}

\noindent

\begin{minted}[firstnumber=948]{python}
        best: Optional[tuple[list[tuple[frozenset[History],
                                        frozenset[History]]],
                             int,
                             list[set[History]]
                            ]] = None
\end{minted}

\noindent We then iterate through maximum depths from \mintinline{python}{-1} (meaning no symmetry optimisation) to \mintinline{python}{toplevel_opt_dept} (included), computing the list of children to include/avoid for each max depth.

\begin{minted}[firstnumber=953]{python}
        for max_depth in range(-1, toplevel_opt_depth+1):
            fixed_child_choices = self._fix_child_choices(hs, perm_group,
                                                          max_depth=max_depth)
\end{minted}

\noindent For each choice of children to include (the ``fixed'' children subset) and to avoid, we compute the maximum ``variable'' children subset \mintinline{python}{remaining_children}, and we increase the total number of top-level children subsets to iterate over by the number of non-empty subsets of \mintinline{python}{remaining_children}.

\begin{minted}[firstnumber=956]{python}
            num_todo = 0
            remaining_children_list = []
            for child_choice, children_to_avoid in fixed_child_choices:
                remaining_children = (child_hists_set
                                      -(child_choice|children_to_avoid))
                num_todo += 2**len(remaining_children)
                remaining_children_list.append(remaining_children)
\end{minted}

\noindent If the total number of top-level children subsets to iterate over is not greater than the current best, we store this as the new best choice; otherwise, we break (so that the best choice is the first local minimum encountered).

\begin{minted}[firstnumber=963]{python}
            if best is None or num_todo <= best[1]:
                if self._verbose:
                    if max_depth >= 0:
                        self._print(f"  {num_todo} subsets at "
                                   f"optimisation depth {max_depth}")
                best = (fixed_child_choices, num_todo, remaining_children_list)
            else:
                break
\end{minted}

\noindent We return a triple with the list of ``fixed'' children subsets, the total number of top-level children subsets, and the the list of maximum ``variable'' children subsets, obtained from the best maximum depth.

\begin{minted}[firstnumber=971]{python}
        assert best is not None
        return (tuple(child_choice for child_choice, _ in best[0]),
                best[1], tuple(best[2]))
\end{minted}


\noindent As a practical example, we look at the search for causally complete spaces on 3-events.
The following (immutable) set contains the bitvectors for all children of maximal extended input histories \mintinline{python}{hs} passed to \mintinline{python}{_fix_child_choices}:

\begin{minted}[linenos=false]{python}
frozenset({5, 6, 9, 10, 17, 18, 20, 24, 33, 34, 36, 40})
\end{minted} 

\noindent Below is the list \mintinline{python}{child_choices} obtained from the main call to \mintinline{python}{_fix_child_choices} in the 3-event search, at the optimal \mintinline{python}{max_depth=8}.

\begin{minted}[linenos=false]{python}
[(frozenset({5, 9, 17, 20, 24, 33, 36}), frozenset()),
 (frozenset({5, 9, 17, 20, 33, 36}), frozenset({24})),
 (frozenset({5, 17, 20, 24, 33, 36}), frozenset({9})),
 (frozenset({5, 17, 20, 33, 36}), frozenset({9, 24})),
 (frozenset({5, 17, 20, 33}), frozenset({36})),
 (frozenset({5, 9, 17, 20, 40}), frozenset({33, 36})),
 (frozenset({5, 9, 17, 20}), frozenset({33, 36, 40})),
 (frozenset({5, 17, 20, 40}), frozenset({9, 33, 36})),
 (frozenset({5, 6, 17, 18, 33, 36}), frozenset({20})),
 (frozenset({5, 6, 17, 18, 33}), frozenset({20, 36})),
 (frozenset({5, 6, 17, 18, 36}), frozenset({20, 33})),
 (frozenset({5, 6, 17, 18}), frozenset({20, 33, 36})),
 (frozenset({5, 6, 17}), frozenset({18, 20})),
 (frozenset({5, 9, 24, 33, 36}), frozenset({17, 20})),
 (frozenset({5, 9, 33, 36}), frozenset({17, 20, 24})),
 (frozenset({5, 24, 33, 36}), frozenset({9, 17, 20})),
 (frozenset({5, 33}), frozenset({17, 20, 36})),
 (frozenset({5, 9, 24}), frozenset({17, 20, 33, 36})),
 (frozenset({5, 9, 40}), frozenset({17, 20, 24, 33, 36})),
 (frozenset({5, 6, 9, 18}), frozenset({17, 20, 24, 33, 36, 40})),
 (frozenset({5, 6, 9, 10, 34}), frozenset({17, 18, 20, 24, 33, 36, 40})),
 (frozenset({5, 6, 9, 10}), frozenset({17, 18, 20, 24, 33, 34, 36, 40})),
 (frozenset({5, 9, 18}), frozenset({6, 17, 20, 24, 33, 36, 40})),
 (frozenset({5, 24}), frozenset({9, 17, 20, 33, 36}))]
\end{minted}

\noindent Consider, for example, the pair \mintinline{python}{(frozenset({5, 9, 17, 20}), frozenset({33, 36, 40}))} (at index 6 in the list).
The ``fixed'' children subset here is $\{5, 9, 17, 20\}$, while the children to avoid are $\{33, 36, 40\}$, so that the maximum ``variable'' children subset is:
\[
\begin{array}{rl}
&\{5, 6, 9, 10, 17, 18, 20, 24, 33, 34, 36, 40\}\\
&\backslash
\left(\{5, 9, 17, 20\}\cup\{33, 36, 40\}\right)\\
=&
\{6, 10, 18, 24, 34\}
\end{array}
\]
This gives $2^6 = 32$ of the 922 top-level children subsets, obtained by union of $\{5, 9, 17, 20\}$ with all possible subsets of $\{6, 10, 18, 24, 34\}$.



% === COMMENT BELOW BEFORE COMPILING MAIN FILE ===

% \end{document}
