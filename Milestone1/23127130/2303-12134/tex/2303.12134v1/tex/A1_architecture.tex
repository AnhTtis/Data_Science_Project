\section{Network Architectures}

In our proposed visual-inertial depth estimation pipeline, the ScaleMapLearner (SML) network that performs dense scale alignment on globally-aligned metric depth maps is based on the MiDaS-small architecture. This is one of the more mobile-friendly models within the robust and generalizable MiDaS\cite{Ranftl2020} family of monocular depth estimation models. 

\mypara{MiDaS-small.} Figure~\ref{fig:midas-small} shows an architecture diagram for the MiDaS-small network. The encoder incorporates an EfficientNet-Lite3~\cite{Tan2019EfficientNetRM} backbone, with skip connections propagating out features at four levels. The decoder consists of four FeatureFusion blocks that progressively upsample and merge features from the encoder and the skip connections.

\begin{figure*}[!htb]
  \centering
  \includegraphics[width=1.0\linewidth]{suppl/MiDaS-small.pdf}
  % \vspace{5mm}
  \caption{\textit{Top:} MiDaS-small\cite{Ranftl2020} architecture, designed for monocular depth estimation. \textit{Bottom:} Diagrams of the FeatureFusion block structure and the ResidualConvUnit used within it. These blocks are parametrized by the number of input (IF) and output (OF) features.}
  \vspace{18pt}
  \label{fig:midas-small}
\end{figure*}

\mypara{ScaleMapLearner (SML).} Figure~\ref{fig:sml-network} shows the SML architecture using MiDaS-small blocks. While MiDaS-small outputs affine-invariant depth maps, our SML network outputs metric depth maps. By default, SML regresses only scale residuals with a single OutputConv head. For ablation experiments where we regress dense shift in addition to scale residuals, a second identical OutputConv head is used; the encoder and feature fusion blocks remain common to both regression tasks.

\begin{figure*}[!htb]
  \centering
  \includegraphics[width=1.0\linewidth]{suppl/SML-network.pdf}
  % \vspace{5mm}
  \caption{Our ScaleMapLearner (SML) network using MiDaS-small architecture blocks.}
  \vspace{18pt}
  \label{fig:sml-network}
\end{figure*}

