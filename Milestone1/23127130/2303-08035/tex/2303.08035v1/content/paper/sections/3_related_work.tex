\section{Related Work}
\label{section:related_work}

\import{tables/}{sota_comparison}

There have been many work focusing on fault injection for \titlecaseabbreviationpl{dnn}, focusing on the tools required for fault injection as well as the different sampling models. We show a comparison in Table \ref{table:sota_comparison}.
enpheeph \cite{colucciEnpheephFaultInjection2022a}, TensorFI \cite{liTensorFIConfigurableFault2018} and LLTFI \cite{agarwalLLTFIFrameworkAgnostic2022} focus on providing innovative fault injection frameworks to speed up the overhead of running fault injection compared to normal \titlecaseabbreviation{dnn} execution. However, they do not employ any specific algorithm for sampling, resorting to random uniform sampling. At the same time, they are able to cover the whole search space, as they do not filter the possible faults.
On the other hand, BinFI \cite{chenBinFIEfficientFault2019} and AVFI \cite{jhaMLBasedFaultInjection2019} provide improved fault models, not focusing on how the fault injection is executed as the previous works, but how to choose the faults using external knowledge, in their case human knowledge. However, they still employ random uniform sampling, but as they decrease the extension of the fault search space, they reach higher precision than the previous tools.
\emphasizedworkname{} employs a novel sampling method based on importance sampling, hence it is capable of achieving similar precision while still requiring no human knowledge and without reducing the fault search space.