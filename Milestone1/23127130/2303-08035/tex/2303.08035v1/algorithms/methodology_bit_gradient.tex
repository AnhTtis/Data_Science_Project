\begin{figure}[h]
    \begin{algorithm}[H]
        \begin{footnotesize}
        \captionsetup{font=footnotesize}
        \caption{Gradient Computation for FloatingPoint32 Tensor Bits}
        \label{algorithm:methodology_bit_gradient}
        \begin{algorithmic}[1]
            % \LComment{each $injection$ in the input list is either a fault or a monitor}
            % \LComment{each $injection$ is a structure containing the necessary information}
            \Procedure{ComputeBitGradients}{$tensor$, $attribution$}
                \LComment{each bit in the list is a tensor with gradient accumulation}
                \State $list_{bits}$ $\gets$ bits from $tensor$, Least Significant Bit at the 0-index
                \State $bits_{sign}$ $\gets$ Most Significant Bit from $list_{bits}$
                \State $bits_{exponent}$ $\gets$ 8 bits from MSB to LSB from $list_{bits}$
                \State $bits_{mantissa}$ $\gets$ 23 remaining bits, reaching LSB, from $list_{bits}$
                \State $sign$ $\gets$ $-2 \times bits_{sign} + 1$
                \State $exponent$ $\gets$ $-127$
                \For{$index$, $bit$ in $bits_{exponent}$}
                    \State $exponent$ $\gets$ $exponent + 2^{index} \times bit$
                \EndFor
                \State $mantissa$ $\gets$ $1$
                \For{$index$, $bit$ in $bits_{mantissa}$}
                    \State $mantissa$ $\gets$ $mantissa + 2^{index - 23} \times bit$
                \EndFor
                \If{$\ms{all}\left(bits_{exponent} == 0\right)$} \label{algorithm:line:flag_start}
                    \State $flag_{infinity-nan}$ $\gets$ $0$
                    \If{$\ms{all}\left(bits_{mantissa} == 0\right)$}
                        \LComment{zero representations}
                        \State $flag_{notzero}$ $\gets$ $0$
                    \Else
                        \LComment{denormalized numbers}
                        \State $flag_{notzero}$ $\gets$ $1$
                        \State $exponent$ $\gets$ $exponent + 1$
                        \State $mantissa$ $\gets$ $mantissa - 1$
                    \EndIf
                \ElsIf{$\ms{all}\left(bits_{exponent} == 1\right)$}
                    \LComment{infinity or not-a-number representations}
                    \LComment{we cannot use infinite numbers, }
                    \LComment{otherwise gradient would be not-a-number}
                    \State $flag_{notzero}$ $\gets$ $1$
                    \State $flag_{infinity-nan}$ $\gets$ $1$
                    % \If{$\ms(all)\left(bits_{mantissa} == 0\right)$}
                    %     \LComment{infinity representations}
                    %     \State $flag_{infinity}$ $\gets$ $1$
                    %     \State $flag_{nan}$ $\gets$ $0$
                    % \Else
                    %     \LComment{not-a-number representation}
                    %     \State $flag_{infinity}$ $\gets$ $0$
                    %     \State $flag_{nan}$ $\gets$ $1$
                    % \EndIf
                \Else
                    \State $flag_{notzero}$ $\gets$ $1$
                    \State $flag_{infinity-nan}$ $\gets$ $0$
                \EndIf \label{algorithm:line:flag_end}
                \State $value$ $\gets$ $sign \times 2^{exponent} \times mantissa$ 
                \State $value$ $\gets$ $value \times flag_{notzero}$ \label{algorithm:line:flag_multiply_zero}
                \If{$flag_{infinity-nan} == 1$}
                    \State $value$ $\gets$ $value \div value \div 33 \times float_{max~representable}$ \label{algorithm:line:flag_multiply_inf}
                \EndIf
                \State $value.grad$ $\gets$ $attribution$
                \State Process auto-differentation on $value$
                \State \Return list of gradient values for each bit
            \EndProcedure
        \end{algorithmic}
        \end{footnotesize}
    \end{algorithm}
\end{figure}

% \begin{figure}[h]
%     \begin{algorithm}[H]
%         \begin{footnotesize}
%         \captionsetup{font=footnotesize}
%         \caption{PyTorch Implementation of the Injection Handler Setup}
%         \label{algorithm:methodology_example}
%         \begin{algorithmic}[1]
%             \LComment{each $injection$ in the input list is either a fault or a monitor}
%             \LComment{each $injection$ is a structure containing the necessary information}
%             \Procedure{InjectionHandlerSetup}{$model$, $list_{injections}$}
%                 \For{$injection$ in $list_{injections}$}
%                     \LComment{the layer with the same name as in the $injection$ is selected}
%                     \State $module$ $\gets$ layer from $model$ using $injection.layerName$
                    
%                     \LComment{the correct $target$ is selected based on the injection type}
%                     \If{$injection.target$ $==$ $output$}
%                         \State $target$ $\gets$ $module.output$
%                     \ElsIf{$injection.target$ $==$ $weight$}
%                         \State $target$ $\gets$ $module.weight$
%                     \EndIf
                    
%                     \If{$injection.type$ $==$ $fault$}
%                         \LComment{if we have a fault we create a $mask$}
%                         \LComment{from the type of fault and}
%                         \LComment{expand it to the $target$ size}
%                         \State $maskElement$ $\gets$ $injection.faultType$ \label{algorithm:line:mask_creation}
%                         \State $mask$ $\gets$ expand $maskElement$ to $target.shape$
%                         \LComment{an execution hook is added to the $module$}
%                         \LComment{to update the $target$}
%                         \LComment{the update involves the $mask$ to force the injection}
%                         \State add exec. hook in $module$, $target$ $\gets$ $target + mask$ \label{algorithm:line:hook_fault}
%                     \ElsIf{$injection.type$ $==$ $monitor$}
%                         \LComment{a similar hook is added to the $module$}
%                         \LComment{if we are running a monitor,}
%                         \LComment{in order to save the $target$}
%                         \State add execution hook in $module$, to save $target$ \label{algorithm:line:hook_monitor}
%                     \EndIf
%                 \EndFor
%             \EndProcedure
%         \end{algorithmic}
%         \end{footnotesize}
%     \end{algorithm}
% \end{figure}


% \begin{table}[h]
%     \begin{algorithm}[H]
%         \begin{footnotesize}
%         \captionsetup{font=footnotesize}
%         \caption{Top-level algorithm of a t\textbf{raining pass}.}
%         \label{alg:full_training_pass}
%             \begin{algorithmic}[1]
%             \vspace*{-1mm}
%             \LineComment{The hardware parameters are extracted from the synthesis}
%             \LineComment{The hardware configuration is the set of possible values}
%             \LineComment{which can be configured for the hardware, passed in the}
%             \LineComment{variable $HW_{info}$}
%             \Procedure{SimTrainPass}{$HW_{info}$, $model$}
%             \LineComment{Compute forward, backward and update estimations via model}
%             \LineComment{analysis based on hardware configuration and parameters,}
%             \LineComment{called $HW_{info}$}
%             \State $res_{forward} \gets SimForwardPass\left(HW_{info}, model\right)$ \label{alg:training:fwd}
%             \State $res_{backward} \gets SimBackwardPass\left(HW_{info}, model\right)$
%             \State $res_{update} \gets SimUpdate\left(HW_{info}, model\right)$ \label{alg:training:update}
%             \State \textbf{return} $res_{forward} + res_{backward} + res_{update}$
%             \EndProcedure
%             \vspace*{0mm}
%             \end{algorithmic}
%         \end{footnotesize}
%     \end{algorithm}
%     \vspace*{-8pt}
% \end{table}

% \begin{table}[h]
%     \begin{algorithm}[H]
%         \begin{footnotesize}
%         \captionsetup{font=footnotesize}
%         \caption{}
%         \label{alg:}
%             \begin{algorithmic}[1]
%                 \Procedure{}{$ $}
%                     \LineComment{}
%                     \LineComment{analysis based on hardware configuration and parameters,}
%                     \LineComment{called $HW_{info}$}
%                     \State $res_{forward} \gets SimForwardPass\left(HW_{info}, model\right)$ \label{alg:training:fwd}
%                     \State $res_{backward} \gets SimBackwardPass\left(HW_{info}, model\right)$
%                     \State $res_{update} \gets SimUpdate\left(HW_{info}, model\right)$ \label{alg:training:update}
%                     \State \textbf{return} $res_{forward} + res_{backward} + res_{update}$
%                 \EndProcedure
%             \end{algorithmic}
%         \end{footnotesize}
%     \end{algorithm}
% \end{table}

% \begin{figure}[h]
% \vspace*{-6mm}
% \begin{algorithm}[H]
% \begin{footnotesize}
% \captionsetup{font=footnotesize}
% \caption{Model search for fitting the \acrlong*{pe} model}
% \label{alg:pe_model_search}
% \begin{algorithmic}[1]
% \vspace*{-2mm}
% \Procedure{ModelSearch}{$input$, $accuracy_{thr}$, $list_{models}$}
% \LineComment{We initialize $accuracy_{best}$ to the worst case value, which is $-\infty$}
% \LineComment{Higher $accuracy$ is better}
% \LineComment{$model_{best}$ is initialized to a dummy one, returning a random value}
% \State init $accuracy_{best}$, $model_{best}$
% \LineComment{split $input$ into $training$ and $testing$ data}
% \State $training$, $testing$ $\gets$ split($input$)
% \LineComment{We cycle through all the models}
% \For{$model$ in $list_{models}$} \label{alg:pe_model_search_for_loop}
% \LineComment{After training the $model$, we test it and check its accuracy}
%     \State train($model$, $training$)
%     \State $accuracy$ $\gets$ test($model$, $testing$)
%     \If{$accuracy$ $>$ $accuracy_{best}$}
%         \State $accuracy_{best}$ $\gets$ $accuracy$
%         \State $model_{best}$ $\gets$ $model$
%     \EndIf
%     \If{$accuracy_{best}$ $>$ $accuracy_{thr}$}
%         \State \textbf{break for loop}
%     \EndIf
% \EndFor
% \State \textbf{return} $model_{best}$, $accuracy_{best}$
% \EndProcedure
% \vspace*{0mm}
% \end{algorithmic}
% \end{footnotesize}
% \end{algorithm}
% \vspace*{-6mm}
% \end{figure}