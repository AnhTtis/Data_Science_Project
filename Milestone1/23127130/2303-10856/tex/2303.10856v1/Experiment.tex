% In this section, we first demonstrate the differences on the settings between source-free domain adaptation and test-time training. 
% Source-free domain adaptation setting is an offline adaptation setting, on which these approaches\cite{pmlr-v119-liang20a, liu2021ttt++} are allowed to adapt their model on the target dataset by multiple epoches. Yet test-time training setting is an online adaptation setting, which allows these approaches\cite{ioffe2015batch, sun2020test, wang2020tent, iwasawa2021test} 

In the experiment section, we first compare against existing methods on different test-time training protocols based on the two key factors. We then ablate the effectiveness of each component in TTAC++. Further analysis on the cumulative performance, qualitative insights, etc. are provided at the end of this section. 

% \vspace{-0.2cm}
\subsection{Datasets}
We evaluate on five test-time training datasets and report the classification error rate~($\%$) throughout the experiment section. To evaluate the test-time training efficacy on corrupted target images, we use \textbf{CIFAR10-C/CIFAR100-C}~\cite{hendrycks2018benchmarking}, each consisting of 10/100 classes with 50,000 training samples of clean data and 10,000 corrupted test samples.   %\textcolor{red}{Additionally, for the large-scale experiments, we choose \textbf{ImageNet-C}~\cite{ILSVRC15}, which has 1,000 classes and 15 types of corruption test set generated with 50,000 samples from original evaluation set.}
We further evaluate test-time training on hard target domain samples with \textbf{CIFAR10.1}~\cite{pmlr-v97-recht19a}, which contains around 2,000 difficult testing images sampled over years of research on the original CIFAR-10 dataset.
%To evaluate the adaptation capability facing the normal domain shift, \textbf{CIFAR10.1}~\cite{pmlr-v97-recht19a}, which contains roughly 2,000 new test images that were sampled after multiple years of research on the original CIFAR-10 dataset, is chosen.
To demonstrate the ability to do test-time training for synthetic data to real data transfer we further use \textbf{VisDA-C}~\cite{VisDA}, which is a challenging large-scale synthetic-to-real object classification dataset, consisting of 12 classes, 152,397 synthetic training images and 55,388 real testing images. To evaluate large-scale test-time training, we use \textbf{ImageNet-C}~\cite{hendrycks2018benchmarking} which consists of 1,000 classes and 15 types of corruptions on the 50,000 testing samples. Some qualitative examples of common corruptions on ImageNet-C are illustrated in Fig.~\ref{fig:corruptedimages}.
% Finally, to evaluate test-time training on 3D point cloud data, we choose \textbf{ModelNet40-C}~\cite{ModelNet40-C}, which consists of 15 common and realistic corruptions of point cloud data, with 9,843 training samples and 2,468 test samples.
Finally, we also evaluate the effectiveness of test-time training against adversarial attacks by implementing TTT on generated \textbf{adversarial samples} on CIFAR-10 dataset, which is referred to as CIFAR-10-adv throughout this work. 

\begin{figure}
    \centering
    \resizebox{1.0\linewidth}{!}{
        \includegraphics{Figure/CorruptedImages.pdf}
    }
    \caption{Illustration of corruptions on target domain images. Examples are selected from the ImageNet-C dataset.}
    \label{fig:corruptedimages}
\end{figure}

% \vspace{-0.2cm}
\subsection{Experiment Settings}
% Under \noindent\textbf{TTT}~\cite{sun2020test,ioffe2015batch,wang2020tent,iwasawa2021test} setting, test samples are sequentially streamed and predictions must be made instantly upon the arrival of a new test sample. Test-time training (\textbf{TTT-R})~\cite{sun2020test} jointly trains the rotation-based self-supervised task and the classification task in the source domain, and then only train the rotation-based self-supervised task in the streaming test samples and make the predictions instantly. Different from TTT-R, \cite{ioffe2015batch,wang2020tent,iwasawa2021test} needn't re-train the model in the source domain for the auxiliary branch, where test-time normalization (\textbf{BN})~\cite{ioffe2015batch} moving average updates the batch normalization statistics according to streaming data, test-time entropy minimization (\textbf{TENT})~\cite{wang2020tent} updates the parameters of all batch normalization by minimizing the entropy of the model predictions in the streaming data, test-time classifier adjustment (\textbf{T3A})~\cite{iwasawa2021test} computes a pseudo-prototype representation for each category using streaming data and make the predictions for streaming data according to these pseudo-prototype representations. 

% \noindent\textbf{sTTT} setting is a more realistic TTT setting. Similarly to common TTT setting, sTTT is also sequential streaming, belongs to one-pass adaptation. The approaches under the common TTT setting usually adapt the model by the predictions of individual samples without constraining the global/category-wise feature distributions of multiple samples in streaming data, which is prone to trivial solutions. To solve this problem, the sTTT setting leverages some simple statistics from the source domain (e.g. the first and second order statistics) to regularize the adapted model during the test-time adaptation procedure, these source domain statistics can be calculated offline and stored as constants. Under the sTTT setting, some SFDA approaches~\cite{pmlr-v119-liang20a, liu2021ttt++} can be leveraged to deal with the test-time training. Source Hypothesis Transfer (\textbf{SHOT})~\cite{pmlr-v119-liang20a} freezes the linear classification head and trains the target-specific feature extraction module by exploiting both information maximization and self-supervised pseudo-labeling in the target domain. \textbf{TTT++}~\cite{liu2021ttt++} aligns source domain feature distribution, whose statistics are calculated offline, and target domain feature distribution by minimizing the F-norm between the mean covariance. Although these approaches appear in the SFDA setting, these approaches are able to be utilized under the sTTT setting with a few modifications. We cache the latest thousands of samples, which reflect the approximate distribution of latest steaming data, and the prediction of the current test sample is made instantly after iteratively training in the cache. \textbf{Ours} 

% \noindent\textbf{Multi-pass adaptation.}
% Instead of above one-pass adaptations, 

\subsubsection{Hyperparameters}
We use the ResNet-50~\cite{he2016deep} as backbone network for fair comparison with existing methods. In addition, ViT~\cite{dosovitskiy2020vit} was adopted as backbone for evaluation on the compatibility with transformer architectures.
%for image datasets and the DGCNN~\cite{wang2019dynamic} on ModelNet40-C. 
We train the backbone network $f(\cdot)$ by SGD optimizer with momentum on all datasets. On CIFAR10-C/CIFAR100-C and CIFAR10.1, we set the batchsize to 256 and the learning rate to 0.01, 0.0001 and 0.01 respectively. On VisDA-C we set the batchsize to 128 and the learning rate to 0.0001. Hyperparameters are shared across multiple TTT protocols except for $N_C$ and $N_{itr}$ which are only applicable under one-pass adaptation protocols. 
 $\alpha_k$ and $\beta_k$ respectively represent the prevalence of each category, here we set them to 1 over the number of categories. $N_C$ indicates the length of the testing sample queue $C$ under the sTTT protocol, and $N_{itr}$ controls the update epochs on this queue. $\tau_{TC}$ and $\tau_{PP}$ are the thresholds used for  pseudo label filtering. $N_{clip}$ and $N_{clip\_k}$ are the upper bounds of sample counts in the iterative updating of global statistics and target cluster statistics respectively. Finally $\lambda_1$ and $\lambda_2$ are the coefficients of $\mathcal{L}_{ga}$ and $\mathcal{L}_{cr}$ respectively, which are 1 and 10 respectively. The details of each individual hyperparamter are found in Table.~\ref{tab:hyperparameters}. When source domain distribution information is not available, we estimate source domain distributions by minimizing Eq.~\ref{eq:learnproto} with RMSprop optimizer, learning rate 0.001 and weight decay 0.001. We choose $\gamma=max(svdvals(\Sigma_{\mu sk}))/30.$ for the fixed covariance matrix. Wall-Clock times for competing methods are recorded under PyTorch 1.10.2 framework, CUDA 11.3 and a single NVIDIA RTX 3090 GPU. 


\begin{table}[]
    \centering
    \caption{Hyper-parameters used on different datasets.}
          \setlength\tabcolsep{4pt} % default value: 6pt
    \resizebox{\linewidth}{!}{
        \begin{tabular}{l|cccccccccccc}
        \toprule
          Dataset & $\alpha_k$ & $\beta_k$ & $N_C$ & $N_{itr}$ & $\xi$ & $\tau_{TC}$ & $\tau_{PP}$ & $\tau_{cr}$ & $N_{clip}$ & $N_{clip\_k}$ & $\lambda_1$ & $\lambda_2$\\
        \midrule
          CIFAR10-C  &  0.1 & 0.1 & 4096 & 4 & 0.9 & 0.95 & -0.001 & 0.9 & 1280 & 128 & 1.0 & 10.0\\
          CIFAR100-C  & 0.01  & 0.01 & 4096 & 4 & 0.9 & 0.95 & -0.001 & 0.9 & 1280 & 64 & 1.0 & 10.0\\
          CIFAR10.1 & 0.1 & 0.1 & 4096 & 4 & 0.9 & 0.95 & -0.001 & 0.9 & 1280 & 128 & 1.0 & 10.0\\
          VisDA-C & $\frac{1}{12}$ & $\frac{1}{12}$ & 4096 & 4 & 0.9 & 0.95 & -0.01 & 0.9 & 1536 & 128 & 1.0 & 10.0\\
          % ModelNet40-C & 0.025 & 0.025 & 4096 & 6 & 0.9 & -0.1 & 0.5 & 1280 & 128 & 1.0\\
          ImageNet-C & 0.001 & 0.001 & 4096 & 2 & 0.9 & 0.95 & -0.01 & 0.9 & 1280 & 64 & 1.0 & 10.0\\
        \bottomrule
        \end{tabular}
    }
    \label{tab:hyperparameters}
\end{table}


\subsubsection{Test-Time Training Protocols}
We categorize test-time training protocols based on two key factors. First, whether the training objective must be changed during training on the source domain, we use Y and N to indicate if training objective is allowed to be changed or not respectively. Second, whether testing data is sequentially streamed and predicted, we use O to indicate a sequential \textbf{O}ne-pass inference and M to indicate non-sequential inference, a.k.a. \textbf{M}ulti-pass inference. With the above criteria, we summarize 4 test-time training protocols, namely N-O, Y-O, N-M and Y-M, and the strength of the assumption increases from the first to the last protocols. 
Ours sTTT setting  makes the weakest assumption, i.e. N-O. Existing methods are categorized by the four TTT protocols, we notice that some methods can operate under multiple protocols.

\noindent\textbf{Source-Free Test-Time Training}.
The proposed TTAC++ relies on aligning the source and target domain distributions. It is often realistic to assume having access to the source domain data distributions, which are light-weight and there is no risk of privacy leakage. Nevertheless, for a fair comparison with existing methods that are strictly \textbf{source-free}, we adopt inferring the source domain statistics from source domain model weights only as introduced in Section~\ref{sect:SFTTT}. Therefore, we differentiate the source-free~(SF) approach from the source-light~(SL) approach in the TTT evaluation protocol. We summarize all protocols evaluated in this work in Table.~\ref{tab:TTTProtocols}.


\begin{table}[!htb]
    \centering
    \caption{The used components under different TTT protocols.}
    \resizebox{0.95\linewidth}{!}{
        \begin{tabular}{c|ccc}
        \toprule
        Protocol & Source Domain Statistics & Contrastive Branch & Multiple Passes \\
        \midrule
        N-O-SF & - & - & - \\
        N-O-SL & \checkmark & - & - \\
        Y-O-SL & \checkmark & \checkmark & - \\
        N-M-SF & - & - & \checkmark \\
        N-M-SL & \checkmark & - & \checkmark \\
        Y-M-SL & \checkmark & \checkmark & \checkmark \\
        \bottomrule
        \end{tabular}
    }
    \label{tab:TTTProtocols}
\end{table}

\begin{table*}[!htb]
    \centering
    %\caption{Different Methods are performed under different Domain Adaptation Settings (e.g. N represents no need to modify network, Y represents need to modify network, O represents one pass to adapt and M represents multiple passes to adapt) and different benchmark datasets (e.g. CIFAR10-C, CIFAR100-C, ModelNet40-C). Also, we give out the assumption strengths for different settings. From the below table, our model performs the state-of-the-art under whichever DA Setting    and whichever dataset.}
   \caption{Comparison under different TTT protocols. Y/N indicates modifying source domain training objective or not. O/M indicate one pass or multiple passes test-time training. SF/SL indicate source-free and source-light respectively. C10-C, C100-C and C10.1 refer to CIFAR10-C, CIFAR100-C and CIFAR10.1 datasets respectively. All numbers indicate error rate in percentage ($\%$).}
    \resizebox{0.5\linewidth}{!}{
        \begin{tabular}{l|cc|ccc}
        \toprule
        Method  & TTT Protocol & Assum. Strength & C10-C & C100-C & C10.1 \\
        \midrule
        TEST &  - & - & 29.15 & 60.34 & 12.10  \\
        \midrule
        BN~\cite{ioffe2015batch} &  N-O-SF & Weak & 15.49 & 43.38 & 14.00 \\
        TENT~\cite{wang2020tent} &  N-O-SF & Weak & 14.27 & 40.72 & 14.40 \\
        T3A~\cite{iwasawa2021test} &  N-O-SF & Weak & 15.44 & 42.72 & 13.50 \\
        SHOT~\cite{pmlr-v119-liang20a} &  N-O-SF & Weak & 13.95 & 39.10 & 13.70 \\
        Conjugate PL~\cite{goyal2022test} & N-O-SF & Weak & 13.21 & 39.39 & 14.20\\
        Self-Training~\cite{sohn2020fixmatch} &  N-O-SF & Weak & 14.66 & 39.25 & \textbf{12.85}\\
        TTAC++~(Ours) & N-O-SF & Weak & \textbf{11.62} & \textbf{37.76} & \textbf{12.85}\\
        \midrule
        TTT++~\cite{liu2021ttt++} &  N-O-SL & Weak & 13.69 & 40.32 & 13.65 \\
        TTAC~\cite{su2022revisiting}  &  N-O-SL & Weak & 10.94 & 36.64 & 12.80 \\
        TTAC+SHOT~\cite{su2022revisiting} & N-O-SL & Weak & 10.99  & 36.39 & 12.40 \\
        TTAC++~(Ours) & N-O-SL & Weak & \textbf{9.78} & \textbf{35.48} & \textbf{12.20} \\
        \midrule
        TTT++~\cite{liu2021ttt++} & Y-O-SL & Medium & 13.00 & 35.23 & 12.60 \\
        TTAC~\cite{su2022revisiting} & Y-O-SL & Medium & 10.69 & 34.82 & 12.00 \\
        TTAC++~(Ours) & Y-O-SL & Medium & \textbf{10.05} & \textbf{34.30} & \textbf{11.55} \\
        % TTAC++ (Contrastive Branch) \\
        \midrule
        BN~\cite{ioffe2015batch} & N-M-SF & Medium & 15.70 & 43.30 & 14.10 \\
        TENT~\cite{wang2020tent} & N-M-SF & Medium & 12.60 & 36.30 & 13.65 \\
        SHOT~\cite{pmlr-v119-liang20a} & N-M-SF & Medium & 14.70 & 38.10 & 14.25 \\
        TTAC++~(Ours) & N-M-SF & Medium & \textbf{9.14} & \textbf{34.43} & \textbf{10.60} \\
        \midrule
        TTT++~\cite{liu2021ttt++} & N-M-SL & Medium & 11.87 & 37.09 & 11.95 \\
        TTAC~\cite{su2022revisiting} & N-M-SL & Medium & 9.42 & 33.55 & 11.00 \\
        TTAC+SHOT~\cite{su2022revisiting} & N-M-SL & Medium & 9.54 & 32.89 & 11.30 \\
        TTAC++~(Ours) & N-M-SL & Medium & \textbf{7.23} & \textbf{29.23} & \textbf{9.00} \\
        \midrule
        TTT-R~\cite{sun2020test} & Y-M-SL & Strong & 14.30 & 40.40 & 11.00 \\ 
        TTT++~\cite{liu2021ttt++} & Y-M-SL & Strong & 9.80 & 34.10 & 9.50 \\
        TTAC~\cite{su2022revisiting} & Y-M-SL & Strong & 8.52 & 30.57 & 9.20 \\
        TTAC++~(Ours) & Y-M-SL & Strong & \textbf{7.57} & \textbf{29.08} & \textbf{8.90} \\
        \bottomrule
        \end{tabular}
    }
    \label{tab:categorization_table}
\end{table*}


\begin{table*}[ht]
    \caption{Test-time training on ImageNet-C under the sTTT~(N-O) protocol. }%TTAC$^\dagger$ indicates TTAC with weak augmentation.}
    \centering
    \resizebox{\linewidth}{!}{
        \begin{tabular}{c|ccccccccccccccc|c}
        \toprule
        Method & Brit & Contr & Defoc & Elast & Fog & Frost & Gauss & Glass & Impul & Jpeg & Motn & Pixel & Shot & Snow & Zoom & Avg \\
        \midrule
        TEST & 38.82 & 89.55 & 82.23 & 87.13 & 64.84 & 76.83 & 97.34 & 90.50 & 97.76 & 68.31 & 83.60 & 80.37 & 96.74 & 82.22 & 74.31 & 80.70 \\
        BN (N-O-SF) & 32.33 & 50.93 & 81.28 & 52.98 & 42.21 & 64.13 & 83.25 & 83.64 & 82.52 & 59.18 & 66.23 & 49.45 & 82.59 & 62.34 & 52.51 & 63.04 \\
        TENT (N-O-SF) & 31.39 & 40.27 & 75.68 & 42.03 & 35.38 & 64.32 & 84.92 & 84.96 & 81.43 & 46.84 & 49.48 & 39.77 & 84.21 & 49.23 & 43.49 & 56.89 \\
        SHOT (N-O-SF) & {30.69} & 37.69 & 61.97 & 41.30 & 34.74 & 54.19 & 76.33 & 71.94 & 74.24 & 46.50 & 47.98 & 38.88 & 70.60 & 46.09 & {40.74} & 51.59 \\
        Conjugate PL (N-O-SF) & \textbf{30.62} & \textbf{34.28} & {61.12} & {40.40} & {34.43} & {51.80} & {65.61} & {67.75} & {63.71} & \textbf{44.61} & {45.70} & \textbf{38.41} & {63.07} & {45.83} & 41.27 & {48.57} \\
        
        Self-Training (N-O-SF) & 31.57 & 37.62 & 79.68 & 42.84 & 35.27 & 54.18 & 88.76 & 91.93 & 81.22 & 51.97 & 50.29 & 39.73 & 88.67 & 48.52 & 47.07 & 57.95 \\
        TTAC++ (N-O-SF) & 31.61 & {36.55} & \textbf{60.39} & \textbf{38.79} & \textbf{34.20} & \textbf{49.02} & \textbf{61.62} & \textbf{62.67} & \textbf{59.37} & {45.25} & \textbf{44.73} & {38.43} & \textbf{58.32} & \textbf{43.60} & \textbf{39.99} & \textbf{46.97} \\
        \midrule
        
        TTAC (N-O-SL) & {30.36} & 38.84 & 69.06 & {39.67} & 36.01 & {50.20} & 66.18 & 70.17 & 64.36 & {45.59} & 51.77 & 39.72 & {62.43} & {44.56} & 42.80 & 50.11 \\
        
        %TTAC$^\dagger$ (N-O-SL) & 30.40 & \textbf{34.01} & {61.60} & 39.95 & {35.42} & 51.55 & {65.83} & {68.58} & {64.11} & 45.77 & {46.33} & {39.60} & 63.29 & 45.62 & {40.71} & {48.85} \\
        
        TTAC++ (N-O-SL) & \textbf{29.78} & \textbf{34.37} & \textbf{58.08} & \textbf{37.68} & \textbf{32.97} & \textbf{47.96} & \textbf{60.51} & \textbf{62.24} & \textbf{58.65} & \textbf{43.61} & \textbf{43.58} & \textbf{36.89} & \textbf{57.33} & \textbf{42.40} & \textbf{38.82} & \textbf{45.66} \\
        \bottomrule
    \end{tabular}
    }
    \label{tab:ImageNet}
    \vspace{-0.2cm}
\end{table*}

\subsubsection{Competing Methods}
We compare the following test-time training methods. Direct testing (\textbf{TEST}) without adaptation simply do inference on target domain with source domain model.
Test-time training (\textbf{TTT-R})~\cite{sun2020test} jointly trains the rotation-based self-supervised task and the classification task in the source domain, and then only train the rotation-based self-supervised task in the streaming test samples and make the predictions instantly. The default method is classified into the Y-M protocol.
Test-time normalization (\textbf{BN})~\cite{ioffe2015batch} moving average updates the batch normalization statistics by streamed data. The default method follows N-M protocol and can be adapted to N-O protocol.
Test-time entropy minimization (\textbf{TENT})~\cite{wang2020tent} updates the parameters of all batch normalization by minimizing the entropy of the model predictions in the streaming data. By default, TENT follows the N-O protocol and can be adapted to N-M protocol.
Test-time classifier adjustment (\textbf{T3A})~\cite{iwasawa2021test} computes target prototype representation for each category using streamed data and make predictions with updated prototypes. T3A follows the N-O protocol by default.
Source Hypothesis Transfer (\textbf{SHOT})~\cite{pmlr-v119-liang20a} freezes the linear classification head and trains the target-specific feature extraction module by exploiting balanced category assumption and self-supervised pseudo-labeling in the target domain. SHOT by default follows the N-M protocol and we adapt it to N-O protocol.
\textbf{TTT++}~\cite{liu2021ttt++} aligns source domain feature distribution, whose statistics are calculated offline, and target domain feature distribution by minimizing the F-norm between the mean covariance. TTT++ follows the Y-M protocol and we adapt it to N-O (removing contrastive learning branch) and Y-O protocols. 
\textbf{AdaContrast}~\cite{chen2022contrastive} approaches TTT from a self-training perspective. Pseudo labels on target domain testing samples are generated from a weak augmentation branch and used for supervising a strong augmentation branch.
\textbf{Conjugate PL}~\cite{goyaltest2022} proposed to learn the best TTT objective through meta-learning. This approach discovered a loss similar to the entropy loss adopted by Tent when source domain is trained with cross-entropy loss.
\textbf{Self-Training}~\cite{sohn2020fixmatch}, a.k.a. FixMatch, was originally developed for semi-supervised learning by estimating pseudo labels on the unlabeled data and supervise model training with pseudo labels. We adapt FixMatch to TTT by adopting the self-training component alone and refer to it as Self-Training~(ST).
\textbf{TTAC}~\cite{su2022revisiting} aligns the source and target domain feature distributions for TTT. It requires a single pass on the target domain and does not have to modify the source training objective. TTAC was originally implemented for all TTT protocols. TTAC was further augmented with additional diversity loss and entropy minimization loss introduced in SHOT~\cite{pmlr-v119-liang20a}, denoted as TTAC+SHOT~\cite{su2022revisiting}. Finally, we evaluate our proposed method, \textbf{TTAC++}, under all TTT protocols. For Y-O and Y-M protocols we incorporate an additional contrastive learning branch introduced in~\cite{liu2021ttt++}. %\textcolor{red}{For Yongyi: Please briefly introduce Conjugate PL and AdaContrast.}

% \vspace{-0.4cm}

\subsection{Test-Time Training Evaluations}\label{sect:ttt_eval}
We evaluate test-time training on four types of target domain data, including images with corruptions, manually selected hard images, synthetic to real adaptation and adversarial samples.

\subsubsection{TTT on Corrupted Target Domain}
We present the test-time training results on CIFAR10/100-C datasets in Tab.~\ref{tab:categorization_table}, {and the results on ImageNet-C dataset in Tab.~\ref{tab:ImageNet}.} For ImageNet-C, we only evaluate under the realistic sTTT~(N-O) protocol. We make the following observations from the results.

\noindent\textbf{sTTT (N-O) Protocol}. 
We first analyze the results under the proposed sTTT (N-O) protocol. Our method outperforms all competing ones by a large margin both with source domain statistics~(N-O-SL) and without source domain statistics~(N-O-SF). Under the most strict N-O-SF protocol, TTAC++ leads the benchmark with a large margin. It outperforms Conjugate PL by $1.6\%$ on CIFAR10-C and SHOT by $1.4\%$ on CIFAR100-C. When source domain statistics are available, TTAC++ gains additional advantage. Compared with TTT++, we achieved $4\%$ and $5\%$ improvements on CIFAR10-C and CIFAR100-C datasets respectively. TTAC++ also improves upon TTAC+SHOT where the latter adopts a class balance assumption. On ImageNet-C dataset, TTAC++ demonstrates its superiority under both N-O-SF and N-O-SL protocols. Without source domain statistics, TTAC++ outperforms Conjugate PL on 11 out of 15 types of corruptions. When source domain statitics are available, TTAC++ consistently outperforms TTAC with similar data augmentation.




% For example, $3\%$ improvement is observed on both CIFAR10-C and CIFAR100-C from the previous best (TTT++) under N-O-SL and
% {5-13\% improvement is observed on ImageNet-C compared with BN and TENT under N-O-SF, and TTAC++ is superior in average accuracy and outperforms on 11 out of 15 types of corruptions compared with ConjugatePL on ImageNet-C}. 

%We further combine TTAC with the class balance assumption made in SHOT (TTAC+SHOT). With the stronger assumptions out method can further improve upon TTAC alone, in particular on ModelNet40-C dataset. This result demonstrates TTAC's compatibility with existing methods.

\begin{table*}[htbp]
    \centering
    \caption{Test-time training on the VisDA-C dataset.} 
    % The numbers for competing methods are inherited from \cite{liu2021ttt++}.
    % \renewcommand{\arraystretch}{1.2}
          \setlength\tabcolsep{3pt} % default value: 6pt
    \resizebox{0.68\linewidth}{!}{
        \begin{tabular}{c|c|cccccccccccc|cc}
        \toprule
        Method & Protocol & Plane & Bcycl & Bus & Car & Horse & Knife & Mcycl & Person & Plant & Sktbrd & Train & Truck & Avg\\
        \midrule
        - & TEST & 56.52 & 88.71 & 62.77 & 30.56 & 81.88 & 99.03 & 17.53 & 95.85 & 51.66 & 77.86 & 20.44 & 99.51 & 65.19\\
        \midrule
        \multirow{4}{*}{N-O-SF} 
        & TENT &  19.75 & 81.99 & 17.78 & 40.03 & 21.64 & 19.04 & 11.66 & 38.18 & 23.15 & 77.33 & 35.88 & 98.31 & 40.40 \\
        & SHOT & 10.81 & \textbf{18.62} & 27.08 & 59.65 & 11.13 & 56.43 & 27.29 & 26.22 & 13.76 & 47.35 & 22.26 & \textbf{61.18} & 31.82 \\
        & Self-Training & \textbf{4.69} & 21.12 & \textbf{13.67} & \textbf{16.00} & \textbf{4.03} & 89.64 & \textbf{6.19} & 86.35 & \textbf{3.17} & 88.82 & \textbf{15.18} & 98.05 & 37.24 \\
        & TTAC++ & 11.63 & 22.42 & 18.49 & 33.47 & 9.57 & \textbf{18.89} & 10.28 & \textbf{21.92} & 10.75 & \textbf{24.46} & 18.51 & 90.37 & \textbf{24.23} \\
        \midrule
        
        \multirow{2}{*}{N-O-SL} 
        & TTAC & 18.54 & 40.20 & 35.84 & 63.11 & 23.83 & 39.61 & 15.51 & 41.35 & 22.97 & 46.56 & 25.24 & 67.81 & 36.71 \\
        %& TTAC$^\dagger$ & 22.87 & 41.15 & 34.14 & 61.78 & 24.13 & 50.46 & 16.86 & 42.08 & 25.02 & 45.51 & 23.04 & 67.77 & 37.90\\
        & TTAC++ & \textbf{7.13} & \textbf{31.34} & \textbf{21.79} & \textbf{43.07} & \textbf{7.57} & \textbf{13.25} & \textbf{7.52} & \textbf{27.95} & \textbf{8.33} & \textbf{32.00} & \textbf{14.16} & \textbf{63.66} & \textbf{23.15} \\
        \midrule
        
        \multirow{2}{*}{Y-O-SL} 
        & TTAC & 7.19 & 29.99 & 22.52 & 56.58 & 8.14 & 18.41 & 8.25 & 22.28 & 10.18 & \textbf{23.98} & 13.55 & \textbf{67.02} & 24.01 \\
        & TTAC++ & \textbf{4.85} & \textbf{26.45} & \textbf{20.98} & \textbf{44.01} & \textbf{5.41} & \textbf{7.47} & \textbf{6.90} & \textbf{21.95} & \textbf{6.53} & 27.49 & \textbf{12.58} & 68.91 & \textbf{21.13}\\
        \midrule
        
        \multirow{6}{*}{N-M-SF} 
        & BN & 44.38 & 56.98 & 33.24 & 55.28 & 37.45 & 66.60 & 16.55 & 59.02 & 43.55 & 60.72 & 31.07 & 82.98 & 48.99\\
        & TENT & 13.43 & 77.98 & 20.17 & 48.15 & 21.72 & 82.45 & 12.37 & 35.78 & 21.06 & 76.41 & 34.11 & 98.93 & 45.21\\
        & SHOT & 5.73 & \textbf{13.64} & 23.33 & 42.69 & 7.93 & 86.99 & 19.17 & 19.97 & 11.63 & \textbf{11.09} & 15.06 & \textbf{43.26} & 25.04 \\
        & Self-Training & 4.44 & 26.91 & 16.25 & \textbf{22.87} & \textbf{3.45} & 60.53 & \textbf{5.59} & 53.50 & \textbf{4.31} & 61.25 & 17.68 & 95.04 & 30.99 \\
        & AdaContrast & \textbf{4.28} & 14.65 & 22.52 & 27.58 & 4.24 & \textbf{7.23} & 13.77 & \textbf{13.00} & 6.05 & 87.46 & \textbf{9.28} & 51.98 & 21.84 \\
        & TTAC++ & 7.62 & 17.93 & \textbf{15.69} & 27.17 & 5.27 & 9.73 & 7.32 & 21.28 & 7.19 & 21.35 & 15.18 & 92.93 & \textbf{20.72} \\
        \midrule
        
        
        \multirow{3}{*}{N-M-SL} 
        & TTT++ & 28.25 & 32.03 & 33.67 & 64.77 & 20.49 & 56.63 & 22.52 & 36.30 & 24.84 & 35.20 & 25.31 & 64.24 & 37.02 \\
        & TTAC & 14.43 & 36.52 & 34.90 & 61.94 & 21.34 & 45.06 & 13.41 & 39.12 & 17.48 & 42.83 & 25.24 & 65.36 & 34.80 \\
        %& TTAC$^\dagger$ & 18.02 & 34.27 & 30.47 & 58.74 & 19.42 & 54.41 & 14.82 & 39.58 & 16.42 & 41.60 & 25.14 & 65.50 & 34.87\\
        & TTAC++ & \textbf{5.46} & \textbf{27.02} & \textbf{18.14} & \textbf{38.19} & \textbf{5.69} & \textbf{11.47} & \textbf{7.18} & \textbf{28.77} & \textbf{7.50} & \textbf{13.28} & \textbf{13.17} & \textbf{59.82} & \textbf{19.64} \\
        \midrule
        
        \multirow{3}{*}{Y-M-SL} 
        & TTT++ & 4.13 & 26.20 & 21.60 & \textbf{31.70} & 7.43 & 83.30 & 7.83 & 21.10 & 7.03 & 7.73 & \textbf{6.91} & \textbf{51.40} & 23.03\\
        & TTAC & 2.74 & 17.73 & 18.91 & 43.12 & 5.54 & 12.24 & \textbf{4.66} & \textbf{15.90} & 4.77 & 10.78 & 9.75 & 62.45 & 17.38 \\
        & TTAC++ & \textbf{2.61} & \textbf{16.86} & \textbf{16.82} & 38.41 & \textbf{4.28} & \textbf{2.89} & 4.93 & 18.20 & \textbf{4.29} & \textbf{6.27} & 8.78 & 62.76 & \textbf{15.59}\\
        \bottomrule
        \end{tabular}
    }
    \label{tab:visda}
\end{table*}

\noindent\textbf{Alternative Protocols}.
We further compare different methods under N-M, Y-O and Y-M protocols. Under the Y-O protocol, TTT++~\cite{liu2021ttt++} modifies the source domain training objective by incorporating a contrastive learning branch~\cite{chen2020simple}. To compare with TTT++, we also include the contrastive branch and observe a clear improvement on both CIFAR10-C and CIFAR100-C datasets. Other TTT methods are adapted to the N-M protocol by allowing training on the whole target domain data multiple epochs. Specifically, we compared with BN, TENT and SHOT. With TTAC alone we observe substantial improvement on all three datasets and TTAC can be further combined with SHOT demonstrating additional improvement. Finally, under the Y-M protocol, we demonstrate very strong performance compared to TTT-R and TTT++. It is also worth noting that TTAC under the N-O protocol can already yield results close to TTT++ under the Y-M protocol, suggesting the strong test-time training ability of TTAC even under the most challenging TTT protocol.

%We first introduce the Sequential Test-Time Training setting, which corresponds to the N-O domain adaptation setting in Table.~\ref{tab:categorization_table}. Under this setting, the training objective no need to be modified while training in the source domain, so that we can use the official pretrained model prepared in advance on the common classification task. Additionally, a streaming adaptation mode is utilized under this setting, more in tune with the demands of realistic use. Because of no modification required training objective and the streaming adaptation mode, sTTT (N-O setting) makes the weakest assumption compared with other settings. From Table.~\ref{tab:categorization_table}, we can make the following observations, i. our method outperforms other sota methods by a large margin on multiple datasets, ii. our method can be compatible with other methods (e.g. SHOT) and gives better performance on CIFAR100-C and ModelNet40-C.
% Describe the N-O setting and analyze the results in Table 1.

% \noindent\textbf{Alternative TTT settings}. Instead of the N-O setting, we also construct the experiments under the following similar settings in Table.~\ref{tab:categorization_table}. The Y-O setting allows the approaches to modify the training objective and re-train in the source domain and perform adaptation sequentially streamedly in target domain. Under this setting, we conduct experiments leveraging our method combined with self-supervised branch (OURS + SSB), in which the self-supervised branch (SSB) need to be re-train in the source domain. As the comparable method, TTT++ also contains a self-supervised branch. We can observe that our method combined with self-supervised branch under the Y-O setting still performs the state-of-the-art. The N-M setting allows the approaches to train for multiple epochs in target domain, whose training style is more like SFDA approaches. Under the N-M setting, we leverage the same models with multi-epoch training, and the results of these approaches again demonstrate the enhanced superiority of our approach. Under the Y-M setting, its assumption strength is the strongest among these four setting, since it allows modification training objective and multi-epoch training style in target domain. The original TTT++ method~\cite{liu2021ttt++} is performed under this setting, yet the performances of our method with or without self-supervised branch both surpass its. 

% Analyze the results on Y-O, N-M and Y-M settings.

% We first categorize test-time training based on two criteria. First, whether the training objective must be changed during training on the source domain (Y/N indicate changed and not changed respectively). Second, whether test data is sequentially streamed and predicted (O/M indicate sequential one-pass and M indicate non-sequential multi-pass). With the above criteria, we conclude 4 test-time training protocols, namely N-O, Y-O, N-M and Y-M, and the strength of the assumption increases from the first to the last protocols. Ours sTTT setting only makes the weakest assumption, i.e. N-O. We further categorize the competing methods into the four TTT settings, we notice that some methods, as well as ours, can operate under multiple settings.



% \begin{table*}[htbp]
%     \centering
%     %\caption{Different Methods are performed under different Domain Adaptation Settings (e.g. N represents no need to modify network, Y represents need to modify network, O represents one pass to adapt and M represents multiple passes to adapt) and different benchmark datasets (e.g. CIFAR10-C, CIFAR100-C, ModelNet40-C). Also, we give out the assumption strengths for different settings. From the below table, our model performs the state-of-the-art under whichever DA Setting    and whichever dataset.}
%    \caption{Comparison under different TTT protocols. Y/N indicates modifying source domain training objective or not. O/M indicate one pass or multiple passes test-time training. C10-C, C100-C and MN40-C refer to CIFAR10-C, CIFAR100-C and ModelNet40-C datasets respectively. All numbers indicate error rate in percentage.}
%     \resizebox{0.75\linewidth}{!}{
%         \begin{tabular}{l|cc|ccc}
%         \toprule
%         Method  & TTT Protocol & Assum. Strength & C10-C & C100-C & MN40-C \\
%         \midrule
%         TEST &  - & - & 29.15 & 60.34 & 34.62 \\
%         \midrule
%         BN~\cite{ioffe2015batch} &  N-O & Weak & 15.49 & 43.38 & 26.53 \\
%         TENT~\cite{wang2020tent} &  N-O & Weak & 14.27 & 40.72 & 26.38 \\
%         T3A~\cite{iwasawa2021test} &  N-O & Weak & 15.44 & 42.72 & 24.57 \\
%         SHOT~\cite{pmlr-v119-liang20a} &  N-O & Weak & 13.95 & 39.10 & 19.71 \\
%         TTT++~\cite{liu2021ttt++} &  N-O & Weak & 13.69 & 40.32 & - \\
%         TTAC  &  N-O & Weak & 10.94 & 36.64 & 22.30 \\
%         TTAC+SHOT & N-O & Weak & 10.99  & 36.39 & \textbf{19.21} \\
%         TTAC++ & N-O & Weak & \textbf{9.78} & \textbf{35.48} \\
%         \midrule
%         TTT++~\cite{liu2021ttt++} & Y-O & Medium & 13.00 & 35.23 & -  \\
%         TTAC & Y-O & Medium & \textbf{10.69} & \textbf{34.82} & - \\
%         % TTAC++ (Contrastive Branch) \\
%         \midrule
%         BN~\cite{ioffe2015batch} & N-M & Medium & 15.70 & 43.30 & 26.49 \\
%         TENT~\cite{wang2020tent} & N-M & Medium & 12.60 & 36.30 & 21.23 \\
%         SHOT~\cite{pmlr-v119-liang20a} & N-M & Medium & 14.70 & 38.10 & 15.99 \\
%         % TTT++ w/o SSL & N-M & Medium & 11.87 & - & - \\
%         TTAC & N-M & Medium & 9.42 & 33.55 & 16.77 \\
%         TTAC+SHOT & N-M & Medium & 9.54 & 32.89 & \textbf{15.04} \\
%         TTAC++~(Ours) & N-M & Medium & \textbf{7.23} & \textbf{29.23} \\
%         \midrule
%         TTT-R~\cite{sun2020test} & Y-M & Strong & 14.30 & 40.40 & - \\ 
%         TTT++~\cite{liu2021ttt++} & Y-M & Strong & 9.80 & 34.10 & - \\
%         TTAC & Y-M & Strong & \textbf{8.52} & \textbf{30.57} & - \\
%         % TTAC++ (Contrastive Branch) \\
%         \bottomrule
%         \end{tabular}
%     }
%     \label{tab:categorization_table}
% \end{table*}




% \begin{table*}[htbp]
%     \centering
%     %\caption{Different Methods are performed under different Domain Adaptation Settings (e.g. N represents no need to modify network, Y represents need to modify network, O represents one pass to adapt and M represents multiple passes to adapt) and different benchmark datasets (e.g. CIFAR10-C, CIFAR100-C, ModelNet40-C). Also, we give out the assumption strengths for different settings. From the below table, our model performs the state-of-the-art under whichever DA Setting    and whichever dataset.}
%    \caption{Comparison under different TTT protocols. Y/N indicates modifying source domain training objective or not. O/M indicate one pass or multiple passes test-time training. C10-C, C100-C and MN40-C refer to CIFAR10-C, CIFAR100-C and ModelNet40-C datasets respectively. All numbers indicate error rate in percentage.}
%     \resizebox{0.75\linewidth}{!}{
%         \begin{tabular}{l|cc|ccc}
%         \toprule
%         Method  & TTT Protocol & Assum. Strength & C10-C & C100-C & MN40-C \\
%         \midrule
%         TEST &  - & - & 29.15 & 60.34 & 34.62 \\
%         \midrule
%         BN~\cite{ioffe2015batch} &  N-O-SF & Weak & 15.49 & 43.38 & 26.53 \\
%         TENT~\cite{wang2020tent} &  N-O-SF & Weak & 14.27 & 40.72 & 26.38 \\
%         T3A~\cite{iwasawa2021test} &  N-O-SF & Weak & 15.44 & 42.72 & 24.57 \\
%         SHOT~\cite{pmlr-v119-liang20a} &  N-O-SF & Weak & 13.95 & 39.10 & 19.71 \\
%         TTAC++ & N-O-SF & Weak & \textbf{11.62} & \textbf{37.76} \\
%         \midrule
%         TTT++~\cite{liu2021ttt++} &  N-O-SL & Weak & 13.69 & 40.32 & - \\
%         TTAC  &  N-O-SL & Weak & 10.94 & 36.64 & 22.30 \\
%         TTAC+SHOT & N-O-SL & Weak & 10.99  & 36.39 & \textbf{19.21} \\
%         TTAC++ & N-O-SL & Weak & \textbf{9.78} & \textbf{35.48} \\
%         \midrule
%         TTT++~\cite{liu2021ttt++} & Y-O-SL & Medium & 13.00 & 35.23 & -  \\
%         TTAC & Y-O-SL & Medium & 10.69 & 34.82 & - \\
%         TTAC++ & Y-O-SL & Medium & \textbf{10.05} & \textbf{34.30} & - \\
%         % TTAC++ (Contrastive Branch) \\
%         \midrule
%         BN~\cite{ioffe2015batch} & N-M-SF & Medium & 15.70 & 43.30 & 26.49 \\
%         TENT~\cite{wang2020tent} & N-M-SF & Medium & 12.60 & 36.30 & 21.23 \\
%         SHOT~\cite{pmlr-v119-liang20a} & N-M-SF & Medium & 14.70 & 38.10 & 15.99 \\
%         TTAC++ & N-M-SF & Medium & \textbf{9.14} & \textbf{34.43} & xxx \\
%         % TTT++ w/o SSL & N-M & Medium & 11.87 & - & - \\
%         \midrule
%         TTAC & N-M-SL & Medium & 9.42 & 33.55 & 16.77 \\
%         TTAC+SHOT & N-M-SL & Medium & 9.54 & 32.89 & \textbf{15.04} \\
%         TTAC++ & N-M-SL & Medium & \textbf{7.23} & \textbf{29.23} \\
%         \midrule
%         TTT-R~\cite{sun2020test} & Y-M-SL & Strong & 14.30 & 40.40 & - \\ 
%         TTT++~\cite{liu2021ttt++} & Y-M-SL & Strong & 9.80 & 34.10 & - \\
%         TTAC & Y-M-SL & Strong & 8.52 & 30.57 & - \\
%         TTAC++ & Y-M-SL & Strong & \textbf{7.57} & \textbf{29.08} \\
%         % TTAC++ (Contrastive Branch) \\
%         \bottomrule
%         \end{tabular}
%     }
%     \label{tab:categorization_table}
% \end{table*}




% \begin{table*}[ht]
%     \caption{Test-time training on ImageNet-C under the sTTT~(N-O) protocol. TTAC$^\dagger$ indicates TTAC with weak augmentation.}
%     \centering
%     \resizebox{\linewidth}{!}{
%         \begin{tabular}{c|ccccccccccccccc|c}
%         \toprule
%         Method & Brit & Contr & Defoc & Elast & Fog & Frost & Gauss & Glass & Impul & Jpeg & Motn & Pixel & Shot & Snow & Zoom & Avg \\
%         \midrule
%         TEST & 38.82 & 89.55 & 82.23 & 87.13 & 64.84 & 76.83 & 97.34 & 90.50 & 97.76 & 68.31 & 83.60 & 80.37 & 96.74 & 82.22 & 74.31 & 80.70 \\
%         BN (N-O) & 32.33 & 50.93 & 81.28 & 52.98 & 42.21 & 64.13 & 83.25 & 83.64 & 82.52 & 59.18 & 66.23 & 49.45 & 82.59 & 62.34 & 52.51 & 63.04 \\
%         TENT (N-O) & 31.39 & 40.27 & 75.68 & 42.03 & 35.38 & 64.32 & 84.92 & 84.96 & 81.43 & 46.84 & 49.48 & 39.77 & 84.21 & 49.23 & 43.49 & 56.89 \\
%         SHOT (N-O) & 30.69 & 37.69 & 61.97 & 41.30 & {34.74} & 54.19 & 76.33 & 71.94 & 74.24 & 46.50 & 47.98 & {38.88} & 70.60 & 46.09 & 40.74 & 51.59 \\
%         TTAC (N-O) & \underline{30.36} & 38.84 & 69.06 & \underline{39.67} & 36.01 & \underline{50.20} & 66.18 & 70.17 & 64.36 & \underline{45.59} & 51.77 & 39.72 & \underline{62.43} & \underline{44.56} & 42.80 & 50.11 \\
%         \midrule
%         TTAC$^\dagger$ (N-O) & 30.40 & \textbf{34.01} & \underline{61.60} & 39.95 & 35.42 & 51.55 & \underline{65.83} & \underline{68.58} & \underline{64.11} & 45.77 & \underline{46.33} & 39.60 & 63.29 & 45.62 & \underline{40.71} & \underline{48.85} \\
%         Self-Training (N-O) & 31.57 & 37.62 & 79.68 & 42.84 & 35.27 & 54.18 & 88.76 & 91.93 & 81.22 & 51.97 & 50.29 & 39.73 & 88.67 & 48.52 & 47.07 & 57.95 \\
%         % TTAC++ (N-O) & \textbf{29.80} & \underline{34.55} & \textbf{57.96} & \textbf{37.74} & \textbf{32.91} & \textbf{47.98} & \textbf{60.51} & \textbf{62.25} & \textbf{58.72} & \textbf{43.67} & \textbf{43.73} & \textbf{36.85} & \textbf{57.42} & \textbf{42.44} & \textbf{38.79} & \textbf{45.69} \\
%         TTAC++ (N-O) & \textbf{29.78} & \underline{34.37} & \textbf{58.08} & \textbf{37.68} & \textbf{32.97} & \textbf{47.96} & \textbf{60.51} & \textbf{62.24} & \textbf{58.65} & \textbf{43.61} & \textbf{43.58} & \textbf{36.89} & \textbf{57.33} & \textbf{42.40} & \textbf{38.82} & \textbf{45.66} \\
%         \bottomrule
%     \end{tabular}
%     }
%     \label{tab:ImageNet}
%     \vspace{-0.2cm}
% \end{table*}



% \subsection{Additional Datasets}

\subsubsection{TTT on Selected Hard Samples as Target Domain}

CIFAR10.1 contains roughly 2,000 new test images that were re-sampled after the research on original CIFAR-10 dataset, which consists of some hard samples and reflects the normal domain shift in our life. Evaluation of TTT methods on CIFAR10.1 is widely adopted to verify the benefit of adapting to hard target domain samples. We present the results on CIFAR10.1 in Table.~\ref{tab:categorization_table}. Again, we observe a strong performance of TTAC++ under all TTT protocols. 

% Describe CIFAR-10.1

\subsubsection{TTT on Synthetic Source to Real Target Domains}

VisDA-C is a large-scale benchmark of synthetic-to-real object classification dataset. We demonstrate on this dataset the ability of TTT to adapt model trained on synthetic source domain to realistic target domain data. %The setting of training on a synthetic dataset and testing on real data fits well with the real application scenario. 
On this dataset, we conduct experiments under the N-O, Y-O, N-M and Y-M protocols with results presented in Table.~\ref{tab:visda}. We make the following observations from the results. First, our proposed method, TTAC++, outperforms all competing methods under all evaluation protocols. In particular, the improvement for TTAC++ is very significant under the N-O~(sTTT) protocol regardless of access to source domain statistics. For example, TTAC++ outperforms the previous best method, the SHOT, by $7\%$ under N-O-SF and, the TTAC, by $13\%$ under N-O-SL. Moreover, TTAC++ also demonstrates very competitive performance when multiple passes on the target domain is allowed~(N-M-SF), a.k.a. source-free domain adaptation.



% First, our method (TTAC Y-O)
% outperforms all methods except TTT++ under the Y-M protocol. This suggests TTAC is able to be deployed in the realistic test-time training protocol. Moreover, if training on the whole target data is allowed, TTAC (Y-M) further beats TTT++ by a large margin, suggesting the effectiveness of TTAC under a wide range of TTT protocols. %ii. although under the more realistic sequential test-time training setting, our method still make an impressive performance with 24.01\% under the Y-O setting near TTT++'s 23.03\% under the Y-M setting and with 36.71\% under the N-O setting over many approaches under the N-M setting. \textcolor{red}{wait until the N-M results.}



% Describe VisDA-C ...


% \begin{table}[htbp]
%  \begin{minipage}{0.47\textwidth}
%     \centering
%     \caption{Test-time training on CIFAR10.1.}
%         \resizebox{1\linewidth}{!}{
%     \begin{tabular}{cccccccc}
%     \toprule
%     TEST & BN & TTT-R & TENT & SHOT & TTT++ & TTAC & TTAC++ \\
%     \midrule
%     12.1 & 14.1 & 11.0 & 13.4 & 11.1 & 9.5 & \textbf{9.2} \\ 
%     \bottomrule
%     \end{tabular}
%     }
%     \label{tab:cifar101}
%           \end{minipage}
%  \hfill
%         \begin{minipage}{0.53\textwidth}
%          \centering
%   \caption{Source-free sTTT on CIFAR10-C.}
%   \resizebox{1\linewidth}{!}{
%     \begin{tabular}{cccccccc}
%     \toprule
%     TEST  & BN & TENT  & T3A & SHOT & TTAC & TTAC+SHOT & TTAC++ \\
%     \midrule
%     29.15 & 15.49 & 14.27 & 15.44 & 13.95 & 13.74 & \textbf{13.35} \\
%     \bottomrule
%     \end{tabular}%
%     }
%   \label{tab:source_blind}%
%   \end{minipage}
% \end{table}



% Table generated by Excel2LaTeX from sheet 'Sheet3'
% \begin{table}[htbp]
%   \centering
%   \caption{Add caption}
%     \begin{tabular}{ccccccc}
%     \toprule
%     TEST  & BN~\cite{ioffe2015batch} & TENT  & T3A~\cite{iwasawa2021test} & SHOT~\cite{pmlr-v119-liang20a} & sTTT (Ours) & sTTT+SHOT (Ours) \\
%     \midrule
%     29.15 & 15.49 & 14.27 & 15.44 & 13.95 & 13.74 & \textbf{13.35} \\
%     \bottomrule
%     \end{tabular}%
%   \label{tab:addlabel}%
% \end{table}%


% \vspace{-0.5cm}

% \begin{table*}[htbp]
%     \centering
%     \caption{Test-time training on VisDA. The numbers for competing methods are inherited from \cite{liu2021ttt++}.}
%     \resizebox{\linewidth}{!}{
%         \begin{tabular}{l|cccccccccccc|cc}
%         \toprule
%         Method & Plane & Bcycl & Bus & Car & Horse & Knife & Mcycl & Person & Plant & Sktbrd & Train & Truck & Per-class\\
%         \midrule
%         TEST & 56.52 & 88.71 & 62.77 & 30.56 & 81.88 & 99.03 & 17.53 & 95.85 & 51.66 & 77.86 & 20.44 & 99.51 & 65.19\\
%         BN (N-M)~\cite{ioffe2015batch} & 44.38 & 56.98 & 33.24 & 55.28 & 37.45 & 66.60 & 16.55 & 59.02 & 43.55 & 60.72 & 31.07 & 82.98 & 48.99\\
%         TENT (N-M)~\cite{wang2020tent} & 13.43 & 77.98 & 20.17 & 48.15 & 21.72 & 82.45 & 12.37 & 35.78 & 21.06 & 76.41 & 34.11 & 98.93 & 45.21\\
%         SHOT (N-M)~\cite{pmlr-v119-liang20a} & 5.73 & \textbf{13.64} & 23.33 & 42.69 & 7.93 & 86.99 & 19.17 & 19.97 & 11.63 & 11.09 & 15.06 & \textbf{43.26} & 25.04 \\
%         TFA (N-M)~\cite{liu2021ttt++} & 28.25 & 32.03 & 33.67 & 64.77 & 20.49 & 56.63 & 22.52 & 36.30 & 24.84 & 35.20 & 25.31 & 64.24 & 37.02 \\
%         TTT++ (Y-M)~\cite{liu2021ttt++} & 4.13 & 26.20 & 21.60 & \textbf{31.70} & 7.43 & 83.30 & 7.83 & 21.10 & 7.03 & \textbf{7.73} & \textbf{6.91} & 51.40 & 23.03\\
%         \midrule
        
%         TENT~(N-O) & 19.75 & 81.99 & 17.78 & 40.03 & 21.64 & 19.04 & 11.66 & 38.18 & 23.15 & 77.33 & 35.88 & 98.31 & 40.40 \\
%         SHOT~(N-O) & 10.81 & 18.62 & 27.08 & 59.65 & 11.13 & 56.43 & 27.29 & 26.22 & 13.76 & 47.35 & 22.26 & 61.18 & 31.82 \\
%         \midrule
%         TTAC~(N-O) & 18.54 & 40.20 & 35.84 & 63.11 & 23.83 & 39.61 & 15.51 & 41.35 & 22.97 & 46.56 & 25.24 & 67.81 & 36.71 \\
%         TTAC~(N-M) & 14.43 & 36.52 & 34.90 & 61.94 & 21.34 & 45.06 & 13.41 & 39.12 & 17.48 & 42.83 & 25.24 & 65.36 & 34.80 \\
%         TTAC~(Y-O) & 7.19 & 29.99 & 22.52 & 56.58 & 8.14 & 18.41 & 8.25 & 22.28 & 10.18 & 23.98 & 13.55 & 67.02 & 24.01 \\
%         TTAC~(Y-M) & \textbf{2.74} & 17.73 & \textbf{18.91} & 43.12 & \textbf{5.54} & \textbf{12.24} & \textbf{4.66} & \textbf{15.90} & \textbf{4.77} & 10.78 & 9.75 & 62.45 & \textbf{17.38} \\
%         \midrule
%         TTAC$^\dagger$~(N-O) & 22.87 & 41.15 & 34.14 & 61.78 & 24.13 & 50.46 & 16.86 & 42.08 & 25.02 & 45.51 & 23.04 & 67.77 & 37.90\\
%         TTAC$^\dagger$~(N-M) & 18.02 & 34.27 & 30.47 & 58.74 & 19.42 & 54.41 & 14.82 & 39.58 & 16.42 & 41.60 & 25.14 & 65.50 & 34.87\\
%         Self-Training~(N-O) & 4.69 & 21.12 & 13.67 & 16.00 & 4.03 & 89.64 & 6.19 & 86.35 & 3.17 & 88.82 & 15.18 & 98.05 & 37.24 \\
%         Self-Training~(N-M) & 4.44 & 26.91 & 16.25 & 22.87 & 3.45 & 60.53 & 5.59 & 53.50 & 4.31 & 61.25 & 17.68 & 95.04 & 30.99 \\
%         TTAC++~(N-O) & 7.13 & 31.34 & 21.79 & 43.07 & 7.57 & 13.25 & 7.52 & 27.95 & 8.33 & 32.00 & 14.16 & 63.66 & 23.15 \\
%         TTAC++~(N-M) & 5.46 & 27.02 & 18.14 & 38.19 & 5.69 & 11.47 & 7.18 & 28.77 & 7.50 & 13.28 & 13.17 & 59.82 & 19.64 \\
%         \toprule
%         \end{tabular}
%     }
%     \label{tab:visda}
% \end{table*}



\subsubsection{TTT on Adversarial Target Domain}

The existing test-time training/adaptation works often evaluate adaptation to the target domain with hand-crafted corruptions. In this section, we investigate the robustness of test-time training subject to stronger out-of-distribution data, i.e. adversarial samples.

This evaluation reveals that simple test-time training can substantially improve model's robustness to adversarial testing samples. In specific, we generate adversarial samples on the testing set of CIFAR-10 dataset by $L^\infty$ PGD~\cite{madry2018towards} attack with $\epsilon=8/255$, 40 iterations and attack step size $0.01$. The adversarial testing samples are then frozen for TTT evaluation. We extensively evaluated existing TTT methods and present the results in Tab.~\ref{tab:AdversarialSample}. We make the following observations from the results. First, without any test-time adaptation, direct testing with source domain model yields very poor performance ($93.07\%$). This is consistent with previous investigations into adversarial attacks. Furthermore, existing test-time training methods which do not consider self-training, e.g. BN, TENT and SHOT, performs relatively poor compared with methods equipped with self-training, e.g. Self-Training, TTT++ and TTAC++. We attribute the performance gap to the fact that the data augmentation applied during self-training is able to smooth out the adversarial noise. Self-training is able to exploit the pseudo labels predicted on smoothed testing samples and improve the accuracy. Finally, we observe that distribution matching is complementary to purely self-training, suggested by the improvement of TTAC++ from Self-Training under N-O-SF and N-M-SF protocols. Overall, we demonstrate that TTAC++ is a strong test-time training paradigm, it owns the ability to adapt to adversarial corruption which is stronger than hand-crafted natural corruptions.

% \noindent\textbf{TTT on Adversarial Samples}. \textcolor{red}{For Yongyi: Please describe how we generated the adversarial samples.}
% To evaluate the robustness on adversarial samples, we generate the adversarial samples on CIFAR10 test set by Projected Gradient Descent (PGD)~\cite{madry2018towards}. Specifically, referring to Advertorch\footnote{https://github.com/BorealisAI/advertorch}, we leverage the $L^\infty$ order PGD attack algorithm and set the maximum distortion $\epsilon$ to $8/255$, the number of iterations to $40$, and the attack step size to $0.01$.

\begin{table*}[htbp]
    \centering
    \caption{Evaluations on test-time training for adversarial samples of CIFAR10 dataset. Each number in the table indicates error rate in percentage.} %TTAC$^\dagger$ aligns source and target distribution with weakly augmented samples.}
          \setlength\tabcolsep{3pt} % default value: 6pt
    \resizebox{0.61\linewidth}{!}{
    
        \begin{tabular}{c|c|cccccccccc|c}
            \toprule
            Protocol & Method & Airpl. & Automob. & Bird & Cat & Deer & Dog & Frog & Horse & Ship & Truck & Avg \\
            \midrule
            - & TEST & 97.00 & 84.90 & 95.20 & 93.20 & 95.70 & 96.30 & 95.00 & 95.70 & 88.80 & 88.90 & 93.07 \\
            \midrule
            \multirow{5}{*}{N-O-SF} 
            & BN & 95.80 & 62.30 & 89.50 & 90.60 & 91.70 & 79.60 & 78.10 & 73.60 & 83.10 & 67.20 & 81.15 \\
            & TENT & 96.70 & 65.60 & 92.10 & 92.80 & 93.20 & 86.40 & 82.40 & 78.70 & 90.50 & 73.00 & 85.14\\
            & SHOT & 97.50 & 50.60 & 90.80 & 93.50 & 93.90 & 74.30 & 78.00 & 67.60 & 85.00 & 65.50 & 79.67\\
            & Self-Training & {43.10} & \textbf{12.20} & {48.20} & \textbf{53.00} & {45.30} & {45.90} & 48.40 & 42.30 & {29.20} & {35.00} & {40.26} \\
            & TTAC++ & \textbf{36.70} & 14.70 & \textbf{45.80} & 60.70 & \textbf{37.80} & \textbf{40.70} & \textbf{23.40} & \textbf{33.30} & \textbf{25.60} & \textbf{27.60} & \textbf{34.63} \\
            \midrule
            \multirow{3}{*}{N-O-SL} 
            & TTT++ & 89.60 & 46.60 & 79.90 & 86.00 & 83.80 & 66.40 & 60.80 & 47.90 & 72.70 & 56.10 & 68.98\\
            & TTAC & 60.20 & 26.30 & 58.60 & 68.20 & 62.10 & 47.10 & {41.40} & {29.70} & 36.90 & 37.20 & 46.77\\
            %TTAC$^\dagger$ & N-O-SL & 54.60 & 32.90 & 60.40 & 74.20 & 60.80 & 62.90 & 44.20 & 42.40 & 39.10 & 39.90 & 51.14 \\
            & TTAC++ & \textbf{23.90} & \textbf{12.60} & \textbf{32.00} & \textbf{53.50} & \textbf{34.60} & \textbf{33.90} & \textbf{20.20} & \textbf{15.90} & \textbf{17.20} & \textbf{18.80} & \textbf{26.26} \\
            \midrule
            \multirow{3}{*}{Y-O-SL} 
            & TTT++ & 37.80 & 15.00 & 47.70 & 58.50 & 41.80 & 38.60 & 26.10 & 20.20 & 19.00 & 21.90 & 32.66 \\
            & TTAC & 32.40 & 14.50 & 42.60 & 58.80 & 42.10 & 37.50 & 23.20 & 18.70 & 16.00 & 23.00 & 30.88\\
            %TTAC$^\dagger$ & Y-O-SL & 31.00 & 17.10 & 39.80 & 56.80 & 41.20 & 40.80 & 26.30 & 24.00 & 15.70 & 21.60 & 31.43\\
            & TTAC++ & \textbf{23.30} & \textbf{11.20} & \textbf{32.30} & \textbf{54.10} & \textbf{31.70} & \textbf{30.90} & \textbf{17.80} & \textbf{15.10} & \textbf{14.70} & \textbf{18.60} & \textbf{24.97}\\
            \midrule
            \multirow{5}{*}{N-M-SF} 
            & BN & 96.20 & 59.10 & 87.90 & 90.90 & 90.70 & 79.80 & 74.80 & 72.30 & 82.90 & 64.70 & 79.93 \\
            & TENT & 96.00 & 66.60 & 91.50 & 92.20 & 93.90 & 83.20 & 81.20 &	76.90 &	87.10 &	71.50 &	84.01 \\
            & SHOT & 96.70 & 48.10 & 89.50 & 93.50 & 93.00 & 75.30 & 78.60 & 43.40 & 80.60 & 64.70 & 76.34 \\
            & Self-Training & 30.70 & \textbf{4.40} & 35.90 & 54.30 & 39.10 & \textbf{18.50} & 45.80 & \textbf{30.30} & \textbf{19.90} & 26.90 & 30.58 \\
            & TTAC++ & \textbf{23.10} & {8.10} & \textbf{36.60} & \textbf{36.90} & \textbf{29.50} & 41.20 & \textbf{16.90} & 50.30 & 26.50 & \textbf{20.30} & \textbf{28.94}\\
            \midrule
            \multirow{3}{*}{N-M-SL} 
            & TTT++ & 74.90 & 28.50 & 68.00 & 78.30 & 71.40 & 51.70 & 47.70 & 31.10 & 52.70 & 40.90 & 54.52 \\
            & TTAC & 36.60 & 15.10 & 46.30 & 54.40 & 47.60 & 39.10 & 28.90 & 21.90 & 21.30 & 22.10 & 33.33 \\
            %TTAC$^\dagger$ & N-M-SL & {14.80} & 8.30 & {23.90} & {35.50} & {23.90} & {26.40} & {14.50} & {13.30} & {9.10} & {13.30} & {18.30} \\
            & TTAC++ & \textbf{11.10} & \textbf{5.60} & \textbf{15.40} & \textbf{28.90} & \textbf{14.50} & \textbf{17.40} & \textbf{9.30} & \textbf{7.00} &	\textbf{6.20} & \textbf{10.10} & \textbf{12.55} \\
            \midrule
            \multirow{3}{*}{Y-M-SL} 
            & TTT++ & 19.30 & 6.80 & 30.10 & 41.90 & 25.60 & 27.50 & 14.20 & 10.60 & 7.80 & 11.60 & 19.54\\
            % TTT++ & Y-M-SL & \\
            & TTAC & 18.50 & 6.90 & 31.40 & 43.20 & 29.00 & 32.00 & 16.50 & 11.70 & 6.90 & 12.20 & 20.83\\
            %TTAC$^\dagger$ & Y-M-SL & 11.90 & 5.90 & 19.70 & 30.40 & 17.60 & 21.00 & 10.60 & 9.80 & 6.70 & 10.30 & 14.39\\
            & TTAC++ & \textbf{11.20} & \textbf{3.90} & \textbf{15.70} & \textbf{26.50} & \textbf{14.50} & \textbf{17.10} & \textbf{7.60} & \textbf{7.40} & \textbf{5.60} & \textbf{9.50} & \textbf{11.90}\\
            \bottomrule
        \end{tabular}
    }
    
    \label{tab:AdversarialSample}
\end{table*}

% \begin{table}[htbp]
%     \centering
%     \caption{Caption}
%     \begin{tabular}{c|ccccccc}
%         \toprule
%         Protocol & TEST & BN & TENT & SHOT & TTT++ & TTAC & TTAC++ \\
%         \midrule
%         N-O & \\
%         N-M & \\
%         \bottomrule
%     \end{tabular}
%     \label{tab:AdversarialSample}
% \end{table}


\subsubsection{TTT Cumulative Performance}
A good test-time training framework should benefit from  seeing more testing samples and the performance on the target domain is expected to be gradually increasing. In this section, we compare different test-time training methods by illustrating the cumulative error rate on CIFAR10/100-C and ImageNet-C~(\textit{Gaussian Blur} corruption) under the sTTT protocols~(N-O-SF/SL) in Fig.~\ref{fig:cifar_cumulative} and Fig.~\ref{fig:imagenet_cumulative}, respectively. As we observe from the figure, some existing TTT methods do not benefit from seeing more testing samples.  For example, BN and T3A's performance stabilize after 2000 testing samples on CIFAR10/100-C.  The performance of TENT and Self-Training~(ST) even degrade after observing 10000 to 20000 testing samples on ImageNet-C. This empirical evaluation also suggest applying self-training alone for TTT is prone to confirmation bias and may harm the performance. In contrast, TTAC++~(pink solid line) exhibits the fastest drop of error rate among all source-free methods. Compared with all methods requiring access to source domain statistics or changing source domain training objectives, TTAC++ is is consistently lower in error rate along the TTT procedure. More importantly, the trend~(sharp slope) shows higher potential for TTAC++ should more testing samples are available in the target domain.


 % For both datasets TTAC outperforms competing methods from the early stage of test-time training. The advantage is consistent throughout the TTT procedure.

\begin{figure*}[!htb]
    \centering
    \includegraphics[width=0.9\linewidth]{./Figure/CIFAR_CUMULATIVE.pdf}
    \caption{Test-time cumulative error rate on CIFAR10/100-C datasets.}
    \label{fig:cifar_cumulative}
\end{figure*}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{./Figure/IMAGENET_CUMULATIVE.pdf}
    \caption{Test-time cumulative error on ImageNet-C dataset with Gaussian Blur corruption.}
    \label{fig:imagenet_cumulative}
\end{figure}

\begin{figure}
    \subfloat[TTAC Feature]{\includegraphics[width=0.5\linewidth]{./Figure/TTAC_TSNE.pdf}}
    \subfloat[TTAC++ Feature]{\includegraphics[width=0.5\linewidth]{./Figure/TTAC++_TSNE.pdf}}

    \centering
    \caption{To reduce the computation, we select 10,000 samples on VisDA-C dataset to draw the T-SNE visualizations. (a) T-SNE visualization of TTAC feature embedding. (b) T-SNE visualization of TTAC++ feature embedding.}\label{fig:tsne}
\end{figure}



\subsubsection{TSNE Visualization of TTAC++ features}
We provide qualitative results for test-time training by visualizing the adapted features through T-SNE~\cite{van2008visualizing}. In Fig.~\ref{fig:tsne}~(a) and Fig.~\ref{fig:tsne}~(b), we compare the features learned by TTAC~\cite{su2022revisiting} and TTAC++. We observe a better separation between classes by TTAC++, implying an improved classification accuracy.

% \newpage
% \vspace{-0.4cm}
\subsection{Ablation Study}
% \vspace{-0.1cm}
% We ablate the models under two TTT settings ...
% Introduce A.C., PLF and GA. Analyze table 4

In this section, we validate the effectiveness of individual components, including anchored clustering, pseudo label filtering, global feature alignment, self-training and finally the compatibility with contrastive branch~\cite{liu2021ttt++}, on CIFAR10-C dataset.
%We conduct ablation study on CIFAR10-C dataset for individual components, including anchored clustering, pseudo label filtering, global feature alignment and finally the compatibility with contrastive branch. 
For anchored clustering alone, we use all testing samples to update cluster statistics. For pseudo label filtering alone, we implement as predicting pseudo labels followed by filtering, then pseudo labels are used for self-training. We make the following observations from Tab.~\ref{tab:ablation}. Under both N-O and N-M protocols, introducing anchored clustering or pseudo label filtering alone improves over the baseline, e.g. under N-O $29.15\%\rightarrow 14.32\%$ for anchored clustering and $29.15\%\rightarrow15.00\%$ for pseudo label filtering. When anchored clustering is combined with pseudo label filtering, we observe a significant boost in performance. This is due to more accurate estimation of category-wise cluster in the target domain.  We further evaluate aligning global features alone with KL-Divergence. This achieves relatively good performance and obviously outperforms the L2 distance alignment adopted in \cite{liu2021ttt++}. Next, when self-training is turned on in conjunction with other components, we observe a consistent improvement under all TTT protocols. Finally, we combine all components with additional contrastive branch and the full model yields the best performance under both Y-O-SL and Y-M-SL protocols. %When contrast learning branch is included, TTAC achieves even better results.

%To analyse the effectiveness of each module, including Anchor Clustering (A.C.), Pseudo Label Filter (P.L.F.) and Global Alignment (G.A.), we conduct adequate ablation experiments under the N-O and N-M setting on CIFAR10-C. In Table.~\ref{tab:ablation_study}, we firstly compare the results of the different module combinations under the N-O setting, where EM Algo. in the column of P.L.F. indicates that we utilize an EM algorithm to update the GMMs of target domain feature, only pseudo label filter indicates directly using pseudo label after filter to perform self-training. Under the N-M setting, we compare the use of KL-Divergence in global feature alignment module with the L2 distance leveraged in TTT++, and we can observe that the KL-Divergence is superior for handling distribution alignment tasks. Additionally, we observe that the anchored clustering module can't be performed without pseudo label filter and all the modules together can have a mutually reinforcing effect and get the optimal result.




% KLDivergence
% Sym KLD
% Multi Gaussian
% Pseudo Labeling

% Below table shows the differences between TTT++'s feature alignment module and KL Divergence module, between Single Gaussian Distribution and Multi Gaussian Distribution.
% TEST
% 


% \vspace{-0.5cm}

% Table generated by Excel2LaTeX from sheet 'Sheet2'
\begin{table*}[htbp]
  \centering
  \caption{Ablation study for individual components on CIFAR10-C dataset.}
    \resizebox{1\linewidth}{!}{
    \begin{tabular}{c|c|cccccc|cc|cccccc|cc}
    \toprule
    TTT Protocol & 
         \multicolumn{1}{c}{}
    & \multicolumn{6}{c}{N-O-SL} 
    & \multicolumn{2}{c}{Y-O-SL} 
    & \multicolumn{6}{c}{N-M-SL} 
    & \multicolumn{2}{c}{Y-M-SL}\\
    
    % \cmidrule(lr){1-1} \cmidrule(lr){2-2} \cmidrule(lr){3-8} \cmidrule(lr){9-10} \cmidrule(lr){11-16} \cmidrule(lr){17-18}
    \midrule
    
    Anchored Cluster. &
    -     
    & \checkmark & -     & \checkmark & -     & \checkmark & \checkmark
    & \checkmark & \checkmark
    & \checkmark & \checkmark & - & - & \checkmark & \checkmark
    & \checkmark & \checkmark\\
    
    Pseudo Label Filter. & 
    -     
    & - & \checkmark & \checkmark & - & \checkmark & \checkmark
    & \checkmark & \checkmark
    & - & \checkmark & - & - & \checkmark & \checkmark
    & \checkmark & \checkmark\\
    
    Global Feat. Align. & 
    - 
    & - & - & - & KLD & KLD & KLD
    & KLD & KLD
    & - & - & L2 Dist.\cite{liu2021ttt++} & KLD & KLD & KLD
    & KLD & KLD \\
    
    Self-Training & 
    -
    & - & - & - & - & - & \checkmark
    & - & \checkmark
    & - & - & - & - & - & \checkmark
    & - & \checkmark\\
    
    Contrast. Branch~\cite{liu2021ttt++} & 
    -
    & - & - & - & - & - & -
    & \checkmark & \checkmark
    & - & - & - & - & - & -
    & \checkmark & \checkmark \\
    
    Avg Acc & 
    29.15 
    & 14.32 & 15.00 & 11.33 & 11.72 & 10.94 & \textbf{9.78}
    & 10.69 & \textbf{10.05}
    & 11.11 & 10.01 & 11.87 & 10.8  & 9.42 & \textbf{7.23}
    & 8.52 & \textbf{7.57} \\
    \bottomrule
    \end{tabular}%
    }
  \label{tab:ablation}%
\end{table*}%
% \vspace{-0.5cm}



% \begin{table}[htbp]
%     \centering
%     \caption{A.C indicates Anchored Clustering module, P.L.F. indicates Pseudo Label Filter module, and G.A. indicates Global Alignment module.}
%     \resizebox{\linewidth}{!}{
%         \renewcommand{\arraystretch}{1.2}
%         \begin{tabular}{c|ccc|ccccccccccccccc|c}
%         \toprule
%         TTT Protocol & A.C. & P.L.F. & G.A. & Bird & Contr & Defoc & Elast & Fog & Frost & Gauss & Glass & Impul & Jpeg & Motn & Pixel & Shot & Snow & Zoom & Avg  \\
%         \midrule
%         - & - & - & - & 7.00 & 13.28 & 11.84 & 23.38 & 29.42 & 28.25 & 48.73 & 50.79 & 57.01 & 19.46 & 23.38 & 47.88 & 44.00 & 21.93 & 10.84 & 29.15 \\
%         \midrule
%         \multirow{7}{*}{N-O} & - & - & KLD & 6.63 & 7.60 & 8.50 & 15.62 & 11.98 & 11.27 & 13.83 & 19.83 & 18.60 & 11.59 & 9.97 & 10.11 & 12.46 & 10.95 & 6.84 & 11.72 \\
%         & \checkmark & - & - & 7.21 & 8.50 & 8.68 & 17.58 & 12.23 & 12.11 & 19.61 & 31.19 & 26.59 & 12.05 & 10.98 & 13.59 & 15.46 & 11.44 & 7.58 & 14.32 \\
%         & - & \checkmark & - & 7.95 & 8.13 & 9.65 & 18.94 & 18.82 & 13.43 & 17.31 & 24.99 & 26.69 & 13.76 & 13.6 & 12.27 & 16.23 & 15.39 & 7.80 & 15.00 \\
%         & \checkmark & \checkmark & - & 6.27 & 9.06 & 7.81 & 14.80 & 11.13 & 10.66 & 13.72 & 19.05 & 18.26 & 10.98 & 9.55 & 9.59 & 11.81 & 10.66 & 6.66 & 11.33 \\
%         & \checkmark & - & KLD & 7.19 & 8.98 & 9.29 & 17.28 & 11.90 & 11.72 & 17.19 & 22.47 & 20.83 & 12.27 & 10.11 & 12.39 & 13.85 & 11.56 & 7.97 & 13.00 \\
%         & \checkmark & EM Algo. & KLD & 6.77 & 8.02 & 7.93 & 14.77 & 10.87 & 10.68 & 13.65 & 18.69 & 17.58 & 11.26 & 9.33 & 9.54 & 11.70 & 10.56 & 6.93 & 11.22 \\
%         & \checkmark & \checkmark & KLD & 6.41 & 8.05 & 7.85 & 14.81 & 10.28 & 10.51 & 13.06 & 18.36 & 17.35 & 10.80 & 8.97 & 9.34 & 11.61 & 10.01 & 6.68 & \textbf{10.94} \\
%         \midrule
%         \multirow{6}{*}{N-M} & - & - & L2 Dist.\cite{liu2021ttt++} & 7.44 & 7.40 & 8.89 & 15.73 & 12.82 & 11.49 & 12.94 & 18.46 & 19.13 & 11.66 & 10.77 & 9.93 & 12.67 & 11.73 & 7.03 & 11.87 \\
%         & - & - & KLD & 6.50 & 6.60 & 8.15 & 14.66 & 10.61 & 10.55 & 12.61 & 18.19 & 16.62 & 11.25 & 8.97 & 9.09 & 11.60 & 10.23 & 6.38 & 10.80 \\
%         & \checkmark & -  & - & 6.18 & 6.40 & 7.53 & 14.13 & 10.46 & 11.06 & 13.97 & 19.28 & 18.30 & 10.89 & 9.10 & 9.65 & 13.13 & 10.23 & 6.39 & 11.11\\
%         & \checkmark & \checkmark & - & 5.86 & 5.93 & 7.05 & 13.53 & 8.88 & 9.62 & 12.40 & 16.59 & 17.48 & 10.06 & 7.97 & 8.26 & 11.07 & 9.31 & 6.17 & 10.01\\
%         & \checkmark & - & KLD & 5.94 & 5.91 & 7.24 & 13.67 & 9.73 & 9.71 & 12.35 & 17.85 & 16.47 & 10.41 & 8.30 & 8.56 & 11.14 & 9.60 & 6.26 & 10.21 \\
%         & \checkmark & \checkmark & KLD & 5.65 & 5.69 & 6.85 & 12.85 & 8.41 & 8.76 & 11.58 & 15.92 & 15.45 & 9.75 & 7.49 & 8.02 & 10.29 & 8.80 & 5.83 & \textbf{9.42}\\
%         \bottomrule
%         \end{tabular}
%     }
%     \label{tab:ablation_study}
% \end{table}


% \begin{table}[htbp]
%     \centering
%     \caption{Clustering strategy. The below experiments are made under the N-O setting on CIFAR10-C.}
%     \resizebox{\linewidth}{!}{
%         \begin{tabular}{c|ccccccccccccccc|c}
%         \toprule
%         Method & Bird & Contr & Defoc & Elast & Fog & Frost & Gauss & Glass & Impul & Jpeg & Motn & Pixel & Shot & Snow & Zoom & Avg \\
%         \midrule
%         w/o clustering & 6.64 & 7.66 & 8.52 & 15.59 & 11.99 & 11.26 & 13.80 & 19.84 & 18.60 & 11.61 & 9.97 & 10.09 & 12.48 & 10.96 & 6.84 & 11.72\\
%         \midrule
%         w/o filter & 7.19 & 8.98 & 9.29 & 17.28 & 11.90 & 11.72 & 17.19 & 22.47 & 20.83 & 12.27 & 10.11 & 12.39 & 13.85 & 11.56 & 7.97 & 13.00\\
%         posterior as weight & 6.77 & \textbf{8.02} & 7.93 & \textbf{14.77} & 10.87 & 10.68 & 13.65 & 18.69 & 17.58 & 11.26 & 9.33 & 9.54 & 11.70 & 10.56 & 6.93 & 11.22\\
%         OURS & \textbf{6.41} & 8.05 & \textbf{7.85} & 14.81 & \textbf{10.28} & \textbf{10.51} & \textbf{13.06} & \textbf{18.36} & \textbf{17.35} & \textbf{10.80} & \textbf{8.97}  & \textbf{9.34}  & \textbf{11.61} & \textbf{10.01} & \textbf{6.68} & \textbf{10.94}\\
%         \bottomrule
%         \end{tabular}
%     }
%     \label{tab:my_label}
% \end{table}

% \begin{table}[htbp]
%     \centering
%     \begin{tabular}{c|c}
%          &  \\
%          & 
%     \end{tabular}
%     \caption{Caption}
%     \label{tab:my_label}
% \end{table}

% \textcolor{red}{Below table shows the differences between symmetric KL Divergence and asymmetric KL Divergence.}
%%%% TODO: The experiments are need performed on CIFAR10-C

% \textcolor{red}{Below table shows the differences among different pseudo label strategies.}
%%%% TODO: The experiments are need performed on CIFAR10-C


\subsection{Additional Analysis}

In this section, we provide additional investigations into additional the designs that affect computation efficiency, compatibility with additional backbones, randomness, and alternative designs, etc.


% describe figure 2

% \begin{figure*}
% \centering
% \subfloat[Test-time cumulative error on CIFAR datasets]{\includegraphics[width=0.57\linewidth]{./Figure/CIFAR_CUMULATIVE.pdf}}
% \subfloat[Test-time cumulative error on ImageNet dataset]{\includegraphics[width=0.43\linewidth]{./Figure/IMAGENET_CUMULATIVE.pdf}}
% % \subfloat[TTT++ Feature]{\includegraphics[width=0.25\linewidth]{./Figure/GlobalAlignmentTSNE.png}}
% % \subfloat[TTAC Feature]{\includegraphics[width=0.25\linewidth]{./Figure/OursTSNE.png}}

% \caption{Comparison of test-time cumulative error under one-pass protocol.}\label{fig:add_study}
% % \vspace{-0.5cm}

% \end{figure*}
% \begin{figure*}
%     \centering
%     \includegraphics[width=0.9\linewidth]{./Figure/CIFAR_CUMULATIVE.pdf}
%     \caption{Test-time cumulative error on CIFAR10/100-C datasets.}
%     \label{fig:cifar_cumulative}
% \end{figure*}




% \begin{figure}
%     \begin{minipage}[t]{0.44\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{./Figure/OnePass4.pdf}
%         \caption{Test-time cumulative error under one-pass protocol.}
%         \label{fig:onepass_perf}
%     \end{minipage}
%      \hfill
%     \begin{minipage}[t]{0.26\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{./Figure/GlobalAlignmentTSNE.png}
%         \caption{The feature distribution visulization of TTT++ via TSNE.}
%         \label{fig:tsne1}
%     \end{minipage}
%      \hfill
%     \begin{minipage}[t]{0.26\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{./Figure/OursTSNE.png}
%         \caption{The feature distribution visulization of sTTT (Ours) via TSNE.}
%         \label{fig:tsne2}source_blind
%     \end{minipage}
% \end{figure}


% \begin{table}[htbp]
%  \begin{minipage}{0.46\textwidth}
%     \centering
%     \caption{Test-time training on CIFAR10.1.}
%         \resizebox{1\linewidth}{!}{
%     \begin{tabular}{ccccccc}
%     \toprule
%     TEST & BN & TTT-R & TENT & SHOT & TTT++ & sTTT \\
%     \midrule
%     12.1 & 14.1 & 11.0 & 13.4 & 11.1 & 9.5 & \textbf{9.2} \\ 
%     \bottomrule
%     \end{tabular}
%     }
%     \label{tab:cifar101}
%           \end{minipage}
%  \hfill
%         \begin{minipage}{0.56\textwidth}
%          \centering
%   \caption{Source-free sequential TTT.}
%   \resizebox{1\linewidth}{!}{
%     \begin{tabular}{ccccccc}
%     \toprule
%     TEST  & BN & TENT  & T3A & SHOT & sTTT & sTTT+SHOT \\
%     \midrule
%     29.15 & 15.49 & 14.27 & 15.44 & 13.95 & 13.74 & \textbf{13.35} \\
%     \bottomrule
%     \end{tabular}%
%     }
%   \label{tab:source_blind}%
%   \end{minipage}
% \end{table}





% \begin{figure}
%     \centering
%     % \includegraphics[width=1\linewidth]{./Figure/TSNE.pdf}
%     \subfigure[The T-SNE illustration using global alignment module.]{
%         \includegraphics[width=0.3\linewidth]{./Figure/GlobalAlignmentTSNE.png}
%     }
%     \hspace{0.05\linewidth}
%     \subfigure[The T-SNE illustration of anchored clustering module combined with global alignment module.]{
%         \includegraphics[width=0.3\linewidth]{./Figure/OursTSNE.png}
%     }
%     \caption{T-SNE visualization.}
%     \label{fig:tsne}
% \end{figure}
% % \newpage

% \subsubsection{Source-Free Test-Time Training}
% TTT aims to adapt model to target domain data by doing simultaneous training and sequential inference. It has been demonstrated some light-weight information, e.g. statistics, from source domain will greatly improve the efficacy of TTT. Nevertheless, under a more strict scenario where source domain information is strictly blind, TTAC can still exploit classifier prototypes to facilitate anchored clustering. Specifically, we normalize the category-wise weight vector with the norm of corresponding target domain cluster center as prototypes. Then, we build source domain mixture of Gaussians by taking prototypes as mean with a fixed covariance matrix. The results on CIFAR10-C are presented in Tab.~\ref{tab:source_blind}. It is clear that even without any statistical information from source domain, TTAC still outperforms all competing methods.

\begin{table*}[!htb]
    \centering
    \caption{Evaluating compatibility with ViT backbone on CIFAR10-C dataset.}
    \resizebox{\linewidth}{!}{
        \begin{tabular}{l|ccccccccccccccc|cc}
        \toprule
            Method & Brit & Contr & Defoc & Elast & Fog & Frost & Gauss & Glass & Impul & Jpeg & Motn & Pixel & Shot & Snow & Zoom & Avg & Std\\
        \midrule
            TEST & 2.29 & 16.24 & 4.83 & 9.45 & 13.60 & 6.73 & 24.52 & 18.23 & 24.48 & 12.63 & 7.63 & 14.57 & 23.02 & 5.29 & 3.50 & 12.47 & 7.36 \\
            BN    & 2.29 & 16.24 & 4.83 & 9.45 & 13.60 & 6.73 & 24.52 & 18.23 & 24.48 & 12.63 & 7.63 & 14.57 & 23.02 & 5.29 & 3.50 & 12.47 & 7.36  \\
            TENT  & 1.84 & 3.55  & \textbf{3.31} & 7.01 & 5.57 & 4.09 & 60.97 & 10.20 & 61.12 & 9.72  & 4.93 & 3.87  & 22.47 & 4.55 & 2.64 & 13.72 & 19.19 \\
            SHOT  & 2.00 & 3.13  & 3.46 & 6.63 & 5.79  & 4.06 & 11.65 & 9.39  & 10.58 & 9.69  & 5.03 & 3.63  & 10.05 & 4.35 & 2.70 & 6.14  & 3.15  \\
            TTT++ & 1.91 & 4.14  & 3.88 & 6.58 & 6.27  & 4.00    & 10.08 & 8.59  & 8.85  & 9.66  & 4.68 & \textbf{3.62} & 9.17  & 4.28 & 2.74 & 5.90  & 2.64  \\
            TTAC & 2.15 & 4.05  & 3.91 & 6.62 & 5.67  & 3.75 & 9.26  & 7.95  & \textbf{7.97}  & 8.55 & 4.75 & 3.87  & 8.24  & 3.93 & 2.94 & 5.57 & \textbf{2.24} \\
            TTAC++ & \textbf{1.59} & \textbf{3.01} & 3.70 & \textbf{6.19} & \textbf{4.45} & \textbf{3.25} & \textbf{9.14} & \textbf{7.76} & 8.02 & \textbf{7.84} & \textbf{4.14} & 3.64 & \textbf{7.80} & \textbf{3.38} & \textbf{2.47} & \textbf{5.09} & 2.36\\
        \bottomrule
        \end{tabular}
    }
    \label{tab:ViT}
\end{table*}

\subsubsection{Test Sample Queue and Update Epochs.}
{
Under the sTTT protocol, we allow all competing methods to maintain the same test sample queue and multiple update epochs on the queue. To analyze the significance of the sample queue and update epochs, we evaluate BN, TENT, SHOT, TTAC and TTAC++ on CIFAR10-C and ImageNet-C level 5 snow corruption evaluation set under different number of update epochs on test sample queue and under a without queue protocol, i.e. only update model w.r.t. the current test sample batch. As the results presented in Tab.~\ref{tab:QueueAccuracyAnalysis}, we make the following observations. i) Maintaining a sample queue can substantially improve the performance of methods that estimate target distribution, e.g. TTAC++~($11.18\rightarrow10.31$), TTAC~($11.91\rightarrow10.88$ on CIFAR10-C) and SHOT~($15.18\rightarrow13.96$ on CIFAR10-C). This is due to more test samples giving a better estimation of true distribution. ii) Consistent improvement can be observed with increasing update epochs for SHOT, TTAC and TTAC++. We ascribe this to iterative pseudo labeling benefiting from more update epochs. These observations also provide insights for deploying TTT for real-world practice. By considering memory constraint and demand for real-time model update, one can adjust the queue length and number of update epochs to strike a balance between efficiency and performance.
}


\begin{table}[!ht]
% \vspace{-0.4cm}
    \caption{Comparing with and without test sample queue and different numbers of model update epochs. w/ Queue maintains a test sample queue with 4096 samples; w/o Queue maintains a single mini-batch with 256 and 128 samples on CIFAR10-C and ImageNet-C respectively.}
    \centering
    \resizebox{0.99\linewidth}{!}{
    \begin{tabular}{c|cccc|c|cc|c}
    \toprule
         & \multicolumn{5}{c|}{CIFAR10-C} & \multicolumn{3}{c}{ImageNet-C} \\
    \midrule
         & \multicolumn{4}{c|}{w/ Queue } & \multicolumn{1}{c|}{w/o Queue} & \multicolumn{2}{c|}{w/ Queue} & w/o Queue \\
    \midrule
        \#Epochs & 1 & 2 & 3 & 4* & 1 & 1 & 2* & 1 \\
    \midrule
        BN & 15.84 & 15.99 & 16.04 & 16.00 & 15.44 & 62.34 & 62.34 & 62.59\\
        TENT & 13.35 & 13.83 & 13.85 & 13.87 & 13.48 & 47.82 & 49.23 & 48.39\\
        SHOT & 13.96 & 13.93 & 13.83 & 13.75 & 15.18 & 46.91 & 46.09 & 51.46\\
        TTAC & 10.88 & 10.80 & 10.58 & 10.01 & 11.91 & 45.44 & 44.56 & 46.64\\
        TTAC++ & \textbf{10.31} & \textbf{9.40} & \textbf{9.08} & \textbf{8.82} & \textbf{11.18} & \textbf{43.49} & \textbf{42.40} & \textbf{46.01}\\
    \bottomrule
    \end{tabular}
    }
    \label{tab:QueueAccuracyAnalysis}
\end{table}

\begin{table}[!ht]
% \vspace{-0.3cm}
    \caption{The per-sample wall time (measured in seconds) on CIFAR10-C under sTTT protocol.}
    \centering
    \resizebox{0.95\linewidth}{!}{
    \begin{tabular}{c|cccc|c}
    \toprule
         & \multicolumn{4}{c|}{w/ Queue } & \multicolumn{1}{c}{w/o Queue}\\
    \midrule
        \#Epochs & 1 & 2 & 3 & 4 & 1 \\
    \midrule
        BN & 0.0136 & 0.0220 & 0.0293 & 0.0362 & 0.0030\\
        TENT & 0.0269 & 0.0399 & 0.0537 & 0.0663 & 0.0041\\
        SHOT & 0.0479 & 0.0709 & 0.0942 & 0.1183 & 0.0067\\
        TTAC & 0.0516 & 0.0822 & 0.1233 & 0.1524 & 0.0083\\
        TTAC++ & 0.0706 & 0.1076 & 0.1591 & 0.1963 & 0.0090 \\
    \midrule
        Inference & 0.0030 & 0.0030 & 0.0030 & 0.0030 & 0.0030\\
    \bottomrule
    \end{tabular}
    }
    \label{tab:QueueTimeAnalysis}
\end{table}

\begin{table*}[!htb]
    \centering
    \caption{The performance of TTAC under different data streaming orders. }
    \resizebox{0.75\linewidth}{!}{
        \begin{tabular}{l|cccccccccc|cc}
        \toprule
           Random Seed & 0 & 10 & 20 & 200 & 300 & 3000 & 4000 & 40000 & 50000 & 500000 & Avg \\
        \midrule
           Error ($\%$) & 8.82 & 8.80 & 9.38 & 9.13 & 8.88 & 8.87 & 9.07 & 8.93 & 9.02 & 8.68 & 8.96$\pm$0.19 \\
        \bottomrule
        \end{tabular}
    }
    \label{tab:stream_order}
\end{table*}

\begin{table*}[!htb]
    \centering
    \caption{Comparison of alternative strategies for updating target domain clusters.  }
    \resizebox{0.9\linewidth}{!}{
        \begin{tabular}{l|ccccccccccccccc|c}
        \toprule
            Strategy & Brit & Contr & Defoc & Elast & Fog & Frost & Gauss & Glass & Impul & Jpeg & Motn & Pixel & Shot & Snow & Zoom & Avg \\
        \midrule
            i. Without filtering & 6.01 & 7.21 & 8.13 & 13.87 & 9.03 & 9.82 & 13.13 & 18.22 & 15.66 & 11.47 & 9.26 & 9.29 & 11.68 & 9.19 & 6.79 & 10.58 \\
            ii. Soft Assignment & 5.91 & 6.52 & 8.05 & 13.25 & 9.08 & 9.76 & 13.14 & 17.19 & 15.45 & 11.41 & 8.88 & 9.10 & 11.53 & 9.13 & 6.83 & 10.35 \\
            Filtering~(Ours)  & \textbf{5.59} & \textbf{6.28} & \textbf{7.53} & \textbf{12.99} & \textbf{8.95} & \textbf{9.22} & \textbf{12.13} & \textbf{15.79} & \textbf{14.37} & \textbf{10.65} & \textbf{8.70} & \textbf{8.60} & \textbf{10.70} & \textbf{8.82} & \textbf{6.37} & \textbf{9.78}\\
        \bottomrule
        \end{tabular}
    }
    \label{tab:target_clust_update}
\end{table*}

\subsubsection{Computation Cost Measured in Wall-Clock Time}
{
Test sample queue and multiple update epochs introduce additional computation overhead. To investigate the impact on efficiency, we measure the overall wall time as the time elapsed from the beginning to the end of test-time training, including all I/O overheads. The per-sample wall time is then calculated as the overall wall time divided by the number of test samples. 
We report the per-sample wall time (in seconds) for BN, TENT, SHOT, TTAC and TTAC++ in Tab.~\ref{tab:QueueTimeAnalysis} under different update epoch settings and without queue setting.
The Inference row indicates the per-sample wall-clock 
time in a single forward pass including data I/O overhead.
We observe that, under the same experiment setting, BN and TENT are more computational efficient, but TTAC++ is only 2 to 3 times more expensive than BN and TENT if no test sample queue is preserved (0.0090 v.s. 0.0030/0.0041) while the performance of TTAC++ w/o queue is still better than TENT (11.18 v.s. 13.48).
In summary, TTAC++
is able to strike a balance between computation efficiency and performance depending on how much computation resource is available. This suggests allocating a separate device for model weights update is only necessary when securing best performance is the priority.
}




\subsubsection{Evaluation of compatibility with Transformer Backbone}
In this section, we provide additional evaluation of TTAC++ with a transformer backbone, ViT~\cite{dosovitskiy2020vit}. In specific, we pre-train ViT on CIFAR10 clean dataset and then follow the sTTT protocol to do test-time training on CIFAR10-C testing set. The results are presented in Tab.~\ref{tab:ViT}. We report the average~(Avg) and standard deviation~(Std) of accuracy over all 15 categories of corruptions. Again, TTAC++ consistently outperform all competing methods with transformer backbone.



% \subsubsection{Impact of TTAC Update Epochs on Cached Testing Sample}
% Under the sTTT protocol, we perform multiple iterations of adaptation on cached testing sample queue. Preserving a history of testing samples is a commonly practice in test-time training. For example, T3A~\cite{iwasawa2021test} preserves a support set, which contains testing samples and the pseudo labels, to update classifier prototypes. TTT++~\cite{liu2021ttt++} preserves a testing sample queue to estimate global feature distribution. For these methods, both raw testing samples and features must be cached simultaneously, in comparison, we only cache the raw data samples and target domain clusters are estimated in an online fashion.

% Here, we analyze the impact of TTAC update epochs on cached testing samples. The results are presented in Tab.~\ref{tab:iterations}, where we make the following observations. First, the error rate is decreasing as the number of epochs increases, while at the cost of more computation time. But this can be solved by allocating a separate device for model adaptation. Second, the error rate saturates at $N_{itr}=4$ suggesting only a few epochs is necessary to achieve good test-time training on target domain.

% \begin{table*}[htbp]
%     \centering
%     \caption{The impact of TTAC update epochs under the sTTT protocol.}
%     \resizebox{\linewidth}{!}{
%         % \renewcommand{\arraystretch}{1.2}
%         \begin{tabular}{c|ccccccccccccccc|c}
%             \toprule
%             $N_{itr}$ & Brit & Contr & Defoc & Elast & Fog & Frost & Gauss & Glass & Impul & Jpeg & Motn & Pixel & Shot & Snow & Zoom & Avg \\
%             \midrule
%              1 & 6.57 & 8.20 & 8.57 & 15.82 & 11.61 & 11.60 & 17.46 & 22.66 & 20.99 & 11.97 & 10.44 & 13.79 & 15.40 & 10.96 & 7.49 & 12.90\\
%             % \cline{1-17}
%              2 & 6.82 & 8.12 & 8.77 & 15.96 & 11.79 & 11.17 & 15.49 & 23.53 & 19.78 & 12.28 & 10.19 & 13.22 & 16.28 & 10.84 & 7.49 & 12.78 \\
%             % \cline{1-17}
%             3 & 6.80 & 8.11 & 8.53 & 15.94 & 11.36 & 10.89 & 14.87 & 22.67 & 18.94 & 11.77 & 9.83 & 12.51 & 15.91 & 10.58 & 7.35 & 12.40 \\
%             % \cline{1-17}
%             \textbf{4} & \textbf{6.41} & 8.05 & \textbf{7.85} & 14.81 & \textbf{10.28} & \textbf{10.51} & \textbf{13.06} & 18.36 & \textbf{17.35} & \textbf{10.80} & 8.97  & \textbf{9.34}  & \textbf{11.61} & \textbf{10.01} & \textbf{6.68} & \textbf{10.94} \\
%             % \cline{1-17}
%             6 & 6.42 & \textbf{7.64} & 7.97 & \textbf{14.66} & 10.66 & 10.59 & 13.30 & \textbf{18.29} & 17.61 & 10.86 & \textbf{8.94}  & 9.36  & 11.76 & 10.03 & 6.73 & 10.98\\
%             % & 10 \\
%             \bottomrule
%         \end{tabular}
%     }
%     \label{tab:iterations}
% \end{table*}


\subsubsection{Impact of Data Streaming Order}
The proposed sTTT protocols assumes test samples arrive in a stream and inference is made instantly on each test sample. The result for each test sample will not be affected by any following ones. In this section, we investigate how the data streaming order will affect the results. Specifically, we randomly shuffle all testing samples in CIFAR10-C for 10 times with different seeds and calculate the mean and standard deviation of test accuracy under sTTT protocol. The results in Tab.~\ref{tab:stream_order} suggest TTAC++ maintains consistent performance regardless of data streaming order.

% \begin{table*}[]
%     \centering
%     \caption{The performance of TTAC under different data streaming orders. }
%     \resizebox{\linewidth}{!}{
%         \begin{tabular}{l|cccccccccc|cc}
%         \toprule
%            Random Seed & 0 & 10 & 20 & 200 & 300 & 3000 & 4000 & 40000 & 50000 & 500000 & Avg \\
%         \midrule
%            Error ($\%$) & 10.01 & 10.06 & 10.05 & 10.29 & 10.20 & 10.03 & 10.31 & 10.36 & 10.37 & 10.13 & 10.18$\pm$0.13 \\
%         \bottomrule
%         \end{tabular}
%     }
%     \label{tab:stream_order}
% \end{table*}



\subsubsection{Sensitivity to Hyperparameters}
We evaluate the sensitivity to two thresholds during pseudo label filtering, namely the temporal smoothness threshold $\tau_{TC}$ and posterior threshold $\tau_{PP}$. In particular, $\tau_{TC}$ controls how much the maximal probability deviate from the historical exponential moving average~(ema). If the current value is lower than the ema below a threshold, we believe the prediction is not confident and the sample should be excluded from estimating target domain cluster. $\tau_{PP}$ controls the the minimal maximal probability and below this threshold is considered as not confident enough. We evaluate $\tau_{TC}$in the interval between 0 and -1.0 and $\tau_{PP}$ in the interval from 0.5 to 0.95 with results on CIFAR10-C level 5 glass blur corruption presented in Tab.~\ref{tab:Thresholds}. We draw the following conclusions on the evaluations. First, there is a wide range of hyperparameters that give stable performance, e.g. $\tau_{TC}\in[0.5,0.0.9]$ and $\tau_{PP}\in[-0.0001,-0.01]$. Second, when temporal consistency filtering is turn off, i.e. $\tau_{TC}=-1.0$, because the probability is normalized to between 0 and 1, the performance drops substantially, suggesting the necessity to apply temporal consistency filtering.

\begin{table}[!htb]
    \centering
    \caption{Evaluation of pseudo labeling thresholds on CIFAR10-C level 5 glass blur corruption. Numbers are reported as classification error (\%).}
        \resizebox{0.85\linewidth}{!}{
    \begin{tabular}{c|ccccccc}
    \toprule
        $\tau_{TC}\backslash \tau_{PP}$ & 0.5 & 0.6 & 0.7 & 0.8 & 0.9 & 0.95 \\
        \midrule
        0.0 & 23.03 & 22.26 & 21.96 & 22.50 & 21.14 & 28.55 \\
        -0.0001 & 20.03 & 20.53 & 20.45 & 20.40 & 19.49 & 27.00 \\
        -0.001 & 19.66 & 20.51 & 19.49 & 20.48 & \textbf{19.42} & 26.83 \\
        -0.01 & 20.71 & 20.78 & 20.73 & 20.65 & 20.29 & 27.58 \\
        -0.1 & 24.10 & 21.47 & 21.46 & 22.36 & 21.45 & 28.71 \\
        -1.0 & 30.75 & 24.08 & 23.40 & 24.33 & 22.21 & 28.77 \\
    \bottomrule
    \end{tabular}
    }
    \label{tab:Thresholds}
\end{table}

\subsubsection{Alternative Strategies for Updating Target Domain Clusters
}
In Sect.~\ref{sect:cluster_pl}, we presented target domain clustering through pseudo labeling. A temporal consistency approach is adopted to filter out confident samples to update target clusters. In this section, we discuss two alternative strategies for updating target domain clusters. Firstly, each target cluster can be updated with all samples assigned with respective pseudo label~(without Filtering). This strategy will introduce many noisy samples into cluster updating and potentially harm test-time feature learning. Secondly, we use a soft assignment of testing samples to each target cluster to update target clusters~(Soft Assignment). This strategy is equivalent to fitting a mixture of Gaussian through EM algorithm. We compare these two alternative strategies with our temporal consistency based filtering approach. The results are presented in Tab.~\ref{tab:target_clust_update}. We find the results with temporal consistency based filtering outperforms the other two strategies on 13 out of 15 categories of corruptions, suggesting pseudo label filtering is necessary for estimating more accurate target clusters.
% Strategy i represents using all samples according to the pseudo labels with equivalent weight to update the corresponding component Gaussian, strategy ii represents using all samples with Bayes Posterior Probability weight to update all component Gaussian, and strategy iii (TTAC) represents only using samples after filtering with equivalent weight to update the corresponding component Gaussian.

% \begin{table*}[]
%     \centering
%     \caption{Comparison of alternative strategies for updating target domain clusters.  }
%     \resizebox{\linewidth}{!}{
%         \begin{tabular}{l|ccccccccccccccc|c}
%         \toprule
%             Strategy & Brit & Contr & Defoc & Elast & Fog & Frost & Gauss & Glass & Impul & Jpeg & Motn & Pixel & Shot & Snow & Zoom & Avg \\
%         \midrule
%             i. Without filtering & 7.19 & 8.98 & 9.29 & 17.28 & 11.90 & 11.72 & 17.19 & 22.47 & 20.83 & 12.27 & 10.11 & 12.39 & 13.85 & 11.56 & 7.97 & 13.00 \\
%             ii. Soft Assignment & 6.77 & \textbf{8.02} & 7.93 & \textbf{14.77} & 10.87 & 10.68 & 13.65 & 18.69 & 17.58 & 11.26 & 9.33 & 9.54 & 11.70 & 10.56 & 6.93 & 11.22 \\
%             Filtering~(Ours)  & \textbf{6.41} & 8.05 & \textbf{7.85} & 14.81 & \textbf{10.28} & \textbf{10.51} & \textbf{13.06} & \textbf{18.36} & \textbf{17.35} & \textbf{10.80} & \textbf{8.97} & \textbf{9.34} & \textbf{11.61} & \textbf{10.01} & \textbf{6.68} & \textbf{10.94} \\
%         \bottomrule
%         \end{tabular}
%     }
%     \label{tab:target_clust_update}
% \end{table*}








% \subsubsection{Improvement by KL-Divergence}
% Minimizing KL-Divergence between two Gaussian distributions is equivalent to matching the first two moments of the true distributions~\cite{7528140}. TFA or TTT++ aligns the first two moments through minimizing the L2/F-norm, referred to as L2 alignment hereafter. Although L2 alignment is derived from Central Moment Discrepancy~\cite{ZELLINGER2019174}, the original CMD advocates a higher order moment matching and the weight applied to each moment is hard to estimate on real-world datasets. An empirical weight could be applied to balance the mean and covariance terms in TTT++, at the cost of introducing additional hyperparameters. We further provide a comparison between KL-Divergence and L2 alignment on CIFAR10-C level 5 snow corruption in Tab.~\ref{tab:KLDvsL2} using the original code released by TTT++. The performance gap empirically demonstrates the superiority of KL-Divergence. %Nevertheless, we believe a theoretical analysis into why KL-Divergence is superior under test-time training would be inspirational and we leave it for future work.

% \begin{table}[ht]
%     \caption{Comparing KL-Divergence and L2-norm as test-time training loss with the original code released by TTT++ (Y-M) on CIFAR10  level 5 snow corruption.}
%     \centering
%     \begin{tabular}{c|c}
%     \toprule
%     Feature Alignment Strategy & Error (\%) \\
%     \midrule
%         L2 alignment (original TTT++) & 9.85 \\
%         KL-Divergence & 8.43 \\
%     \bottomrule
%     \end{tabular}
%     \label{tab:KLDvsL2}
% \end{table}

\subsubsection{Alternative Design for Inferring Source Domain Distributions}
 In this work, we develop a solution to infer the source distributions in Sect.~\ref{sect:SFTTT}. Alternative to learning the distribution mean, an alternative solution is developed by re-scaling the classifier weight~\cite{ding2022source}. In this section, we compare the two options for estimating source domain statistics with results presented in Tab.~\ref{tab:estimated_source_distribution}.
 We conclude from the comparison that learning source domain statistics~(TTAC++) is clearly better than re-scaling classifier weights~\cite{ding2022source}. We attribute the advantage of TTAC++ to the fact that backbone features are obtained after ReLu activation, thus being all positive. The classifier weights are trained without any constraints and could have negative weights. The mismatch between classifier weights and backbone features might lead to inferior results by using re-scaled classifier weights as source domain distribution mean.
 % , we found that learned source distribution is more explainable and effective than directly re-scaling the classifier weight. One common situation, where the data features are all positive obtained after the ReLU~\cite{glorot2011deep} activation function while classifier weights may be negative, naturally contradicts the assumption that means and weights have the same direction. The specific experiments are conducted in Tab.~\ref{tab:estimated_source_distribution}.

\begin{table}[ht]
    \centering
    \caption{Comparing alternative methods to estimate source domain distributions.}%The choice of the mean of estimated source distribution. Weight denotes the re-scaling weight of the classifier, TTAC++(SF) leverages the learned prototypes, and TTAC++(SL) leverages the statistics calculated from source data. These results are averaged error rates above all level-5 corrupted sets on CIFAR10-C dataset. }
    \resizebox{0.45\linewidth}{!}{
    \begin{tabular}{c|c}
    \toprule
        Method &  Error (\%) \\
    \midrule
        Class. Weights~\cite{ding2022source} & 13.79\\
        TTAC++~(SF) & 11.62\\
    % \midrule
        % TTAC++(SL) & 9.78\\
    \bottomrule
    \end{tabular}
    }
    \label{tab:estimated_source_distribution}
\end{table}


\subsubsection{Limitations and Failure Cases}

Finally, we discuss the limitations of TTAC++ from two perspectives. First, we point out that TTAC++ requires backpropagation to update models at testing stage, therefore additional computation overhead is required. As shown in Tab.~\ref{tab:QueueTimeAnalysis}, TTAC++ is 2-5 times computationally more expensive than BN and TENT. However, contrary to usual expectation, BN and TENT are also very expensive compared with no adaptation at all. Eventually, most test-time training methods might require an additional device for test-time adaptation. 

We further discuss the limitations on test-time training under more severe corruptions. Specifically, we evaluate TENT, SHOT, TTAC, and TTAC++ under 1-5 levels of corruptions on CIFAR10-C with results reported in Tab.~\ref{tab:CorruptLevel}. We observe generally a drop of performance from 1-5 level of corruption. Despite consistently outperforming TENT and SHOT at all levels of corruptions, TTAC++'s performance at higher corruption levels are relatively worse, suggesting future attention must be paid to more severely corrupted scenarios. 

\begin{table}[ht]
    \caption{Classification error under different levels of snow corruption on CIFAR10-C dataset.}
    \centering
        \resizebox{0.7\linewidth}{!}{
    \begin{tabular}{c|ccccc}
    \toprule
        Level & 1 & 2 & 3 & 4 & 5 \\
    \midrule
        TEST & 9.46 & 18.34 & 16.89 & 19.31 & 21.93 \\
        TENT & 8.76 & 11.39 & 13.37 & 15.18 & 13.93 \\
        SHOT & 8.70 & 11.21 & 13.16 & 15.12 & 13.76 \\
        TTAC & 6.54 & 8.19 & 9.82 & 10.61 & 10.01 \\
        TTAC++ & \textbf{6.05} & \textbf{7.83} & \textbf{8.47} & \textbf{9.43} & \textbf{8.82}\\
    \midrule
    \end{tabular}
    }
    \label{tab:CorruptLevel}
\end{table}

\vspace{-0.5cm}

%The results in Tab.~\ref{tab:modelnet40c} demonstrates another adaptation challenge which is performed on point cloud data where TTAC achieves the best performance overall.










% \vspace{-0.5cm}


% \begin{table}[]
%     \centering
%     \caption{Comparisons of our method, under no information from source domain setting, with competing methods.}
%     \resizebox{\linewidth}{!}{
%         \begin{tabular}{l|ccccccccccccccc|c}
%         \toprule
%             Method & Bird & Contr & Defoc & Elast & Fog & Frost & Gauss & Glass & Impul & Jpeg & Motn & Pixel & Shot & Snow & Zoom & Avg \\
%         \midrule
%             TEST & 7.00 & 13.28 & 11.84 & 23.38 & 29.42 & 28.25 & 48.73 & 50.79 & 57.01 & 19.46 & 23.38 & 47.88 & 44.00 & 21.93 & 10.84 & 29.15\\
%             BN~\cite{ioffe2015batch} & 8.21 & 8.36 & 9.73 & 19.43 & 20.16 & 13.72 & 17.46 & 26.34 & 28.11 & 14.00 & 13.90 & 12.22 & 16.64 & 16.00 & 8.03 & 15.49\\
%             T3A~\cite{iwasawa2021test} & 8.33 & 8.70 & 9.70 & 19.51 & 20.26 & 13.83 & 17.27 & 25.61 & 27.63 & 14.05 & 14.26 & 12.12 & 16.37 & 15.78 & 8.13 & 15.44\\
%             SHOT~\cite{pmlr-v119-liang20a} & \textbf{7.58} & \textbf{7.78} & \textbf{9.12} & 17.76 & 16.90 & 12.56 & 15.99 & 23.30 & 24.99 & 13.19 & 12.59 & \textbf{11.37} & 14.85 & 13.75 & 7.51 & 13.95\\
%             sTTT (Ours) & 8.05 & 7.80 & 9.15 & \textbf{17.15} & 16.34 & 12.70 & \textbf{15.54} & 22.60 & 23.99 & \textbf{12.80} & 12.69 & 11.49 & 14.74 & 13.69 & \textbf{7.42} & 13.74\\
%             sTTT+SHOT (Ours) & 7.87 & 8.23 & 9.43 & 17.32 & \textbf{13.41} & \textbf{12.44} & 15.90 & \textbf{22.17} & \textbf{22.12} & 13.19 & \textbf{11.43} & 11.52 & \textbf{14.18} & \textbf{13.29} & 7.79 & \textbf{13.35}\\
%         \bottomrule
%         \end{tabular}
%     }
%     \label{tab:source_blind}
% \end{table}