In this section we first introduce the anchored clustering objective for test-time training through pseudo labeling and then describe an efficient iterative updating strategy. {We then introduce the solution to infer source distribution when source domain data is strictly absent, and self-training for TTT.} For simplicity, We denote the source and target domain datasets as $\set{D}_s=\{x_i,y_i\}_{i=1\cdots N_s}$ and $\set{D}_t=\{x_i\}_{i=1\cdots N_t}$ where a minibatch of target test samples at time stamp $t$ is defined as $\set{B}^t=\{x_i\}_{i=tN_B\cdots (t+1)N_B}$. We further denote the posterior prediction for $x_i$ at time stamp $t$ as $q^t_i=\delta(h(z_i;\vect{w})),\; s.t.\;z_i=f(x_i;\matr{\Theta})$, where $\delta(\cdot)$, $h(\cdot;\vect{w})$ and $f(\cdot;\matr{\Theta})$ denote the a standard softmax function, the classifier head and backbone network, respectively. The $D$ dimensional feature representation is defined as the output of backbone network $z_i=f(x_i;\matr{\Theta})\in\set{R}^{+D}$ due to ReLu activation. An overview of the proposed pipeline is illustrated in Fig.~\ref{fig:overview}.

\begin{figure*}[!htb]
    \centering
    \includegraphics[width=0.99\linewidth]{./Figure/TTAC++_pipeline.pdf}
    \caption{Overview of TTAC++. i) In the source domain offline stage, we calculate or infer category-wise and global distributions in the source domain as anchors. ii) In the test-time stage, testing samples are sequentially streamed and pushed into a fixed-length queue. We apply self-training to testing samples to adapt model weights. Anchored clustering is employed to regularize self-training by aligning source and target domain distributions.}  %for stronger Clusters in target domain are identified through anchored clustering with pseudo label filtering. Target clusters are then matched to the anchors in source domain to achieve test-time training.}
    %\caption{Overview of the proposed test-time anchored clustering (TTAC) pipeline. Our pipeline consists of four parts: offline stage, sequential sample generator, a fix-length sample queue and our proposed method TTAC. (i) At the offline stage, we count the distributions of each category and the global in the feature space using our proposed iterative updating approach in the source domain, whose distributions will become the anchors to regularize the adaptation performing in the target domain. (ii) During the test stage in the target domain, the sequential sample generator, simulating the situation that the test-time training approach is deployed in the realistic scenarios, generates the streaming test sample of target domain. (iii) Under the sTTT setting, we allocate a memory space, as shown as the Fixed-Length Queue in the figure, to store the recent test samples to accelerate the adaptation. This module is non-required facing the high-speed streaming data. (iv) Our proposed method TTAC adopts the preprocessed source-domain category-wise distributions as anchors to cluster the feature in the target domain, in where the pseudo label fitlering module is leveraged to find out the more accuracy samples to help count the category-wise distributions. Using the iteratively updating approach effectively relieves memory perssure without the need for a feature queue. Our proposed method demonstrates strong compatibility with present adaptation approach since there is no need to modify any modules.}
    %\caption{Overview of the proposed test-time anchored clustering (TTAC) pipeline. Our pipeline consists of four parts: offline stage, sequential sample generator, a fix-length sample queue and our proposed method TTAC. (i) At the offline stage, we count the distributions of each category and the global in the feature space using our proposed iterative updating approach in the source domain, whose distributions will become the anchors to regularize the adaptation performing in the target domain. (ii) During the test stage in the target domain, the sequential sample generator simulates the situation that the test-time training approach is deployed at the   }
    \label{fig:overview}
\end{figure*}

\subsection{Anchored Clustering for Test-Time Training}

%Feature alignment demonstrated effectiveness for test-time training, however we discover in this work that aligning target testing data feature to source training ones, which is called global feature alignment hereafter, is still suboptimal. First, global feature alignment describes the source and target distributions with two multi-variate Gaussian distributions respectively. In a high dimension feature space with multiple feature clusters, each may correspond to one category, a single-modal Gaussian distribution is insufficient to describe the complex distribution. Moreover, aligning global feature distribution does not guarantee the target data are correctly embedded near the classifier prototype. To tackle these issues, we propose to align feature distribution at a more fine-grained level. Specifically, a mixture of Gaussian is adopted to describe the training and testing feature distributions as,

Inspired by the success of discovering cluster structures in the target domain for unsupervised domain adaptation~\cite{tang2020unsupervised}, we develop an anchored clustering on the test data alone as the initial module for test-time training. %Under the sTTT protocol without the regularization from source labeled data, learningsimultaneously learning cluster center and feature embedding is prone to trivial solution and does not guarantee the reusability of models trained on source data. 
% To tackle this challenge, 
We first use a mixture of Gaussians to model the clusters in the target domain, here each component Gaussian represents one discovered cluster. 
We further use the distributions of each category in the source domain as anchors for the target distribution to match against. In this way, test data features can simultaneously form clusters and the clusters are associated with source domain categories, resulting in improved generalization to target domain. Formally, we first denote the mixture of Gaussians in the source and target domains as,
\begin{equation}
\begin{split}
p_s(z)=\sum_k \alpha_k \mathcal{N}(\mu_{sk},\Sigma_{sk}),\\
p_t(z)=\sum_k \beta_k \mathcal{N}(\mu_{tk},\Sigma_{tk})
\end{split}
\end{equation}
where $\{\mu_k\in\mathbb{R}^d,\Sigma_k\in\mathbb{R}^{d\times d}\}$ represent one cluster in the source/target domain and $d$ is the dimension of feature embedding. Both $\mu_{sk}$ and $\Sigma_{sk}$ can be readily estimated from $\set{D}_s$ through MLE.
Anchored clustering can be achieved by matching the above two distributions and one may directly minimize the KL-Divergence between the two distribution.
%Matching the two distributions without knowing the association between component Gaussians is non-trivial because a good distribution measurement, KL-Divergence, between two mixture of Gaussians does not have 
Nevertheless, this is non-trivial because the KL-Divergence between two mixture of Gaussians has no closed-form solution which prohibits efficient gradient-based optimization. Despite some approximations exist~\cite{hershey2007approximating}, without knowing the semantic labels for each Gaussian component, even a good match between two mixture of Gaussians does not guarantee target clusters are aligned to the correct source ones and this will severely harm the performance of test-time training. %Moreover, fitting a mixture of Gaussian on source data can be achieved in an offline manner, but dynamically fitting a mixture of Gaussian on target data through EM algorithm is subject to erroenous assignment, i.e. data points could be assigned to cluster.
In light of these challenges, we propose a category-wise alignment.  Specifically, we allocate the same number of clusters in both source and target domains, each corresponding to one semantic class, and each target cluster is assigned to one source cluster. We can then minimize the KL-Divergence between each pair of clusters as in Eq.~\ref{eq:KLD}. 
% \vspace{-0.5cm}

\begin{equation}\label{eq:KLD}
\resizebox{0.9\linewidth}{!}{
$
\begin{split}
    \mathcal{L}_{ac}&=\sum_k D_{KL}(\mathcal{N}(\mu_{sk},\Sigma_{sk})||\mathcal{N}(\mu_{tk},\Sigma_{tk}))\\
    &=\sum_k -H(\mathcal{N}(\mu_{sk},\Sigma_{sk})) + H(\mathcal{N}(\mu_{sk},\Sigma_{sk}),\mathcal{N}(\mu_{tk},\Sigma_{tk}))
\end{split}
$
}
\end{equation}

The KL-Divergence can be further decomposed into the entropy $H(\mathcal{N}(\mu_{sk},\Sigma_{sk}))$ and cross-entropy $H(\mathcal{N}(\mu_{sk},\Sigma_{sk}),\mathcal{N}(\mu_{tk},\Sigma_{tk}))$. It is commonly true that the source reference distribution $p_s(z)$ is fixed thus the entropy term is a constant $C$ and only the cross-entropy term is to be optimized.
Given the closed-form solution to the KL-Divergence between two Gaussian distributions, we now write the anchored clustering objective as,

\begin{equation}\label{eq:anchored_clustering_loss}
\resizebox{0.9\linewidth}{!}{
$
\begin{split}
    \mathcal{L}_{ac}= &\sum_k \{\log \sqrt{2\pi^d|\Sigma_{tk}|} + \frac{1}{2}(\mu_{tk}-\mu_{sk})^\top\Sigma_{tk}^{-1}(\mu_{tk}-\mu_{sk})  \\ &+ tr(\Sigma_{tk}^{-1}\Sigma_{sk})\} + C
\end{split}
$
}
\end{equation}

The source cluster parameters, mean and covariance, can be readily estimated in an offline manner by running through the training samples. These information will not cause any privacy leakage and only introduces a small computation and storage overheads. Nevertheless, one might encounter a more constrained scenario where distributional information on the source domain is prohibited, e.g. downstream user can only have access to model architecture and weights. In the following section, we shall introduce a strict source-free anchored clustering method by inferring source domain clusters. To differentiate the settings, we refer to the former one as source-light TTT, where statistical information on source domain is still available, and the latter one as source-free TTT, where no information on source domain is available. %In the next section, we elaborate clustering in the target domain.


% \noindent\textbf{Learning Prototype}

\subsection{Clustering through Pseudo Labeling}\label{sect:cluster_pl}

In order to test-time train network with anchored clustering loss, one must obtain target cluster parameters $\{\mu_{tk},\Sigma_{tk}\}$. 
For a minibatch of target test samples $\set{B}^t=\{x_i\}_{i=tN_B\dots (t+1)N_B}$ at timestamp $t$, %we first denote the predicted posterior as $P^t=softmax(h(f(x_i)))\in[0,1]^{B\times K}$ where $softmax(\cdot)$, $h(\cdot)$ and $f(\cdot)$ respectively denote a standard softmax function, the classifier head and backbone network. 
the pseudo labels are obtained via $\hat{y}_i=\arg\max_k q_{ik}^t$. Given the predicted pseudo labels we could estimate the mean and covariance for each component Gaussian with the pseudo labeled testing samples.
% \begin{equation}\label{eq:naiveupdate}
% \begin{split}
%     \mu_{tk} = \frac{\sum_{i} \mathbbm{1}(\hat{y}_i=k)f(x_i)}{\sum_i \mathbbm{1}(\hat{y}_i=k)},\quad
%     \Sigma_{tk} = \frac{\sum_i \mathbbm{1}(\hat{y}_i=k) (f(x_i)-\mu_{tk})^\top(f(x_i)-\mu_{tk})}{\sum_i\mathbbm{1}(\hat{y}_i=k)}
% \end{split}
% \end{equation}
However, pseudo labels are always subject to model's discrimination ability. The error rate for pseudo labels is often high when the domain shift between source and target is large, directly updating the component Gaussian is subject to erroneous pseudo labels, a.k.a. confirmation bias~\cite{arazo2020pseudo}. To reduce the impact of incorrect pseudo labels, we first adopt a light-weight temporal consistency (TC) pseudo label filtering approach. Compared to co-teaching~\cite{han2018co} or meta-learning~\cite{li2019learning} based methods, this light-weight method does not introduce additional computation overhead and is therefore more suitable for test-time training.
% Specifically, we denote a queue of test time trained models up to a fixed past steps $\{\Theta_t,\Omega_t\}_{t=T-T_w,\cdots T}$, the temporal consistency is defined as,
Specifically, to alleviate the impact from the noisy predictions, we calculate the temporal exponential moving averaging posteriors $\tilde{q}^t \in [0,1]^{N \times K}$ as below,

% \begin{equation}
%     % P^t_i = softmax(h(f(X_i))),\quad 
%     \tilde{P}^t_i = 
%     \left\{
%         \begin{array}{lr}
%             P^t_i & newcomers \\
%             (1 - \alpha) * \tilde{P}^{t-1}_i + \alpha * P^t_i & others
%         \end{array}
%     \right.
% \end{equation}
% \vspace{-0.5cm}

\begin{equation}
    % P^t_i = softmax(h(f(X_i))),\quad 
    \tilde{q}^t_i = 
            (1 - \xi) * \tilde{q}^{t-1}_i + \xi * q^t_i,\quad s.t.\quad\tilde{q}^{0}_i=q^0_i
\end{equation}

The temporal consistency filtering is realized as in Eq.~\ref{eq:tc_filter} where $\tau_{TC}$ is a threshold determining the maximally allowed difference in the most probable prediction over time. If the posterior deviate from historical value too much, it will be excluded from target domain clustering.
% \vspace{-0.2cm}

\begin{equation}\label{eq:tc_filter}
    F_i^{TC} = \mathbbm{1}((q_{i\hat{y}}^t - \tilde{q}^{t-1}_{i\hat{y}}) > \tau_{TC}),\; s.t. \; \hat{y} = \arg\max_k(q_{ik}^t)
\end{equation}

% For those testing samples which do not have a historical predictions, we also incorporate an additional filter based on entropy (\textcolor{red}{is this correct?}) as,

Due to the sequential inference, test samples without enough historical predictions may still pass the TC filtering.  So, we further introduce an additional pseudo label filter directly based on the posterior probability as,
% \vspace{-0.5cm}

\begin{equation}
    F_i^{PP}=\mathbbm{1}(\tilde{q}^{t}_{i\hat{k}}>\tau_{PP})
\end{equation}

By filtering out potential incorrect pseudo labels, we update the component Gaussian only with the leftover target samples as below.
% \vspace{-0.5cm}

\begin{equation}
\centering
\resizebox{0.9\linewidth}{!}{
$
\begin{split}
    &\mu_{tk} = \frac{\sum\limits_{i} F^{TC}_iF^{PP}_i\mathbbm{1}(\hat{y}_i=k)z_i}{\sum\limits_i F^{TC}_iF^{PP}_i\mathbbm{1}(\hat{y}_i=k)},\\
    &\Sigma_{tk} = \frac{\sum\limits_i F^{TC}_iF^{PP}_i\mathbbm{1}(\hat{y}_i=k) (z_i-\mu_{tk})^\top(z_i-\mu_{tk})}{\sum\limits_i F^{TC}_iF^{PP}_i\mathbbm{1}(\hat{y}_i=k)}
\end{split}
$
}
\end{equation}
% \vspace{-0.5cm}

\subsection{Global Feature Alignment}

As discussed above, test samples that do not pass the filtering will not contribute to the estimation of target clusters. Hence, anchored clustering may not reach its full potential without the filtered test samples. To exploit all available test samples, we propose to align global target data distribution to the source one. We approximate the global feature distribution of the source data as $\hat{p}_s(x)=\mathcal{N}(\mu_s,\Sigma_s)$ and the target data as $\hat{p}_t(x)=\mathcal{N}(\mu_t,\Sigma_t)$. To align two distributions, we again minimize the KL-Divergence as,
\vspace{-0.5cm}

\begin{equation}\label{eq:global_loss}
    \mathcal{L}_{ga}=D_{KL}(\hat{p}_s(x)||\hat{p}_t(x))
\end{equation}

Similar idea has appeared in~\cite{liu2021ttt++} which directly matches the moments between source and target domains~\cite{zellinger2017central} by minimizing the F-norm for the mean and covariance, i.e. $||\mu_t-\mu_s||^2_2+||\Sigma_t-\Sigma_s||^2_F$. However, designed for matching complex distributions represented as drawn samples, central moment discrepancy~\cite{zellinger2017central} requires summing infinite central moment discrepancies and the ratios between different order moments are hard to estimate.  For matching two parameterized Gaussian distributions KL-Divergence is more convenient with good explanation from a probabilistic point of view. Finally, we add a small constant to the diagonal of $\Sigma$ for both source and target domains to increase the condition number for better numerical stability.


% This approach is subject to larger norm in the covariance term, due to the higher dimension of $\Sigma\in\mathca{R}^{d\times d}$, and choosing appropriate weight between the two terms would introduce another hyper-parameter. In contrast, minimizing KL-Divergence is hyper-parameter efficient and has better explanation from a probabilistic point of view. 


\subsection{Source-Free TTT by Inferring Source Domain Distributions}\label{sect:SFTTT}

%The proposed anchored clustering approach requires access to light-weight source domain cluster information as anchors. Although the light-weight information does not risk privacy leakage, collecting source domain statistics may not be always feasible when these statistic information are not collected during the training stage. 
In order to enable test-time training under strict source-free setting, we propose to infer the necessary source domain statistical information, i.e. the class-wise mean and covariance matrix, from network weights only. W.o.l.g., we write the classifier head as a linear classifier $h({z}_i;\vect{w})=\vect{w}^\top {z}_i$ by omitting the bias term, which though can still be preserved in a homogeneous coordinate. Without knowing the true class-wise distribution, we hypothesize that each class $k$ is subject to a uni-modal Gaussian distribution $p_{sk}(z)=\mathcal{N}({\mu}_{sk},{\Sigma}_{sk})$ as given in the previous section. Given a model well trained on the source domain we could expect the following class-wise risk being minimized w.r.t. classifier weights.

% \begin{equation}
% \mathcal{L}_{CE}=-\frac{1}{|\set{D}_s|}\sum_{x_i,y_i\in\set{D}_s}\log\sum_k[y_i=k]\sigma(w_kz_i)
% \end{equation}
\begin{equation}
\begin{split}
    \mathcal{L}_{sk}(\vect{w},\matr{\Theta})=&\mathbbm{E}_{z\sim p_{sk}(z)}[-\log\delta(\vect{w}_k^\top z)]\\
    =&\mathbbm{E}_{\tilde{z}\sim \mathcal{N}(\vect{0},\vect{I})}[-\log\delta(\vect{w}_k^\top(\mu_{sk}+\matr{A}_{sk}\tilde{z}))]
\end{split}
\end{equation}
where $\matr{A}_{sk}\matr{A}_{sk}^\top=\matr{\Sigma}_{sk}$ satisfies a Cholesky decomposition. When source domain feature distribution is unknown while the classifier head $\vect{w}$ is available, we could rewrite the above optimization by substituting the optimization variables to source domain class-wise distribution as below, where the lower bound is derived according to Jensen inequality, as $-\log\delta(\cdot)$ is a convex function. The equality holds when $\matr{A}_{sk}=\matr{0}$.
% \begin{equation}\label{eq:learnproto}
\begin{align}
    \hat{\mathcal{L}}_{sk}(\mu_{sk},\matr{A}_{sk})=&\mathbbm{E}_{\tilde{z}\sim \mathcal{N}(\vect{0},\vect{I})}[-\log\delta(\vect{w}_k^\top(\mu_{sk}+\matr{A}_{sk}\tilde{z}))]\label{eq:learnproto}\\
    \geq&-\log\delta(\mathbbm{E}_{\tilde{z}\sim\mathcal{N}(\matr{0},\matr{I})}[\vect{w}_k^\top(\mu_{sk}+\matr{A}_{sk}\tilde{z})])\\
    =&-\log\delta(\vect{w}_k^\top\vect{\mu}_{sk})\label{eq:lowerbound}
\end{align}
% \end{equation}


% \begin{equation}
% \resizebox{0.9\linewidth}{!}{$
% \begin{aligned}
% \hat{\mathcal{L}}{sk}(\mu{sk},\matr{A}{sk})=&\mathbbm{E}{\tilde{z}\sim \mathcal{N}(\vect{0},\vect{I})}[-\log\delta(\vect{w}k^\top(\mu{sk}+\matr{A}{sk}\tilde{z}))]\label{eq:learnproto}\\
% \geq&-\log\delta(\mathbbm{E}{\tilde{z}\sim\mathcal{N}(\matr{0},\matr{I})}[\vect{w}k^\top(\mu{sk}+\matr{A}_{sk}\tilde{z})])\\
% =&-\log\delta(\vect{w}k^\top\vect{\mu}{sk})\label{eq:lowerbound}
% \end{aligned}
% $}
% \end{equation}


We interpret this problem as discovering the source domain class-wise distribution such that samples drawn from these distributions can be correctly classified. We argue that directly optimizing Eq.~\ref{eq:learnproto} without any constraint on $\matr{A}_{sk}$ is equivalent to optimizing the lower bound, Eq.~\ref{eq:lowerbound}. Because any non-zero $\matr{A}_{sk}$ enables the inequality and without constraining $\matr{A}_{sk}$, a trivial solution with $\matr{A}_{sk}=\matr{0}$ exists. %i.e. $\matr{A}_{sk}=\matr{0}$, because any non-zero $\matr{A}_{sk}$ enables the inequality. %, we defer the proof to the Appendix. 
Alternatively, one could fix the covariance matrix, $\matr{\Sigma}_{sk}$, and only update class-wise mean, $\vect{\mu}_{sk}$, and this requires Monte Carlo sampling from a standard multi-variate Gaussian distribution should Eq.~\ref{eq:learnproto} be the objective to optimize. To get rid of the excessive computation of sampling, we empirically figure out an efficient way to infer source-domain distributions by fixing $\matr{\Sigma}_{sk}=\gamma\matr{I}$ and optimizing the lower bound, Eq.~\ref{eq:lowerbound}, to estimate $\vect{\mu}_{sk}$. Moreover, since all backbone features $z_i$ are positive due to ReLu activation, $\mu$ should be all positive so that it may overlap with the true distribution of source domain features. For this purpose, we parameterize $\mu=\hat{\mu}^2$ where $\hat{\mu}$ is unconstrained, and add weight decay to $\hat{\mu}$ to limit the norm of $\mu$.%We choose a is chosen to be 
%For distribution alignment, both category-wise and global mean and covariance are necessary information. 
%We Given the feature representations are taken from the last layer of backbone network after ReLu activation, the 
% Given a inferred source-domain distribution which can be correctly by the source domain classifier, $\mathcal{N}(\tilde{\mu}_{sk},\tilde{\Sigma}_{sk})$, multiplying the distribution mean with an arbitrary scale will further decrease the risk~(cross entropy loss) in Eq.~\ref{eq:learnproto}.%, we defer the proof to the Appendix. 
%To avoid estimating overly large norm for $\mu_{sk}$, we add a weight decay for $\mu_{sk}$. %Considering that the norm of estimated mean may differ from source domainIn anchored clustering, we normalize Normalize norm
%$z_i = \frac{z_i||\mu_k||}{||z_i||}$

The global feature distribution is approximated by a uni-modal Gaussian distribution. Therefore, to infer the global feature distribution, we  use a single Gaussian distribution $\mathcal{N}(\mu_s,\Sigma_s)$ to approximate the mixture of per-category Gaussians. Specifically, the following KL-Divergence is minimized with a closed-form solution~\cite{hershey2007approximating}. 

\begin{equation}
\centering
\resizebox{0.89\linewidth}{!}{
$
\begin{split}
    &\mu_{s}^*,\Sigma_{s}^* = \arg\min_{\mu_{s},\Sigma_{s}} D_{KL}(\mathcal{N}(\mu_s,\Sigma_s)||\sum_k\frac{1}{K}\mathcal{N}(\mu_{sk},\Sigma_{sk}))\\
    &\Rightarrow\mu_s^* = \sum_k\frac{1}{K} \mu_{sk}\\
    &\Rightarrow\Sigma_s^* = \sum_k \frac{1}{K}(\Sigma_{sk}+(\mu_{sk}-\mu_s)(\mu_{sk}-\mu_s)^\top) %= \Sigma_{sk} + \Sigma_{\mu sk}
\end{split}
$
}
\end{equation}
%where we denote $\sum_k \frac{1}{K}(\mu_{sk}-\mu_s)(\mu_{sk}-\mu_s)^\top$ as $\Sigma_{\mu sk}$ for the covariance of all class-wise means $\mu_{sk}$.

\subsection{Efficient Iterative Updating}

% We choose to model the feature distribution via a single multi-variate Gaussian distribution for the simplicity of Cross-Entropy loss. 

Despite the distribution for source data can be trivially estimated from all available training data in a totally offline manner, estimating the distribution for target domain data is not equally trivial, in particular under the sTTT protocol.
In a related research~\cite{liu2021ttt++}, a dynamic queue of test data features are preserved to dynamically estimate the statistics, which will introduce additional memory footprint~\cite{liu2021ttt++}. %Moreover, as the gradient only exists for the current mini-batch, a long queue would vanish the learning gradient, i.e. $1/N_q$-th the original loss where $N_q$ is the length of queue.
To alleviate the memory cost we propose to iteratively update the running statistics for Gaussian distribution. 
%Formally, we define $t$-th test minibatch as $\set{B}^t=\{x_i\}_{i=1\cdots N_{B}}$. 
Denoting the running mean and covariance at time stamp $t$ as $\mu^t$ and $\Sigma^t$, we present the rules to update the mean and covariance in Eq.~\ref{eq:runningstatistics}. More detailed derivations and update rules for per cluster statistics are deferred to the Supplementary. 

% \vspace{-0.5cm}
\begin{equation}\label{eq:runningstatistics}
    \resizebox{0.89\linewidth}{!}{
    $
\begin{split}
% &\mu^t = \mu^{t-1}+\sum_{x_i\in\set{B}}\alpha_i(f(x_i)-\mu^{t-1}), \\
    % &N^t = N^{t-1} + |\set{B}^t|,\quad
    % \delta^t=\frac{1}{N^t}{\sum\limits_{x_i\in\set{B}}(f(x_{i}) - \mu^{t-1})},\\
    % &\Sigma^t=\Sigma^{t-1}+\sum_{x_i\in\set{B}}\alpha_i^2(f(x_i)-\mu^{t-1})^\top(f(x_i)-\mu^{t-1})-\Sigma^{t-1} - \delta^{t-1}^\top\delta^t
    % &\sigma_{mn}[t]=\sigma_{mn}[t-1] + \frac{\sum\limits_{i=N_{t-1}}^{N_t}([f_m(X_i)_{i} - \mu_m[t-1]][f_n(X_i) - \mu_n[t-1]] - \sigma_{mn}[t-1])}{N_t} - \delta_m[t]\cdot\delta_n[t]
    %
    & \mu^t = \mu^{t-1} + \delta^t, \\
    &\Sigma^t=\Sigma^{t-1}+a^t{\sum_{x_i\in\set{B}}\{(z_i-\mu^{t-1})^\top(z_i-\mu^{t-1})-\Sigma^{t-1}\}} \\
    &- {\delta^t}^\top\delta^t \\
    & \delta^t=a^t{\sum\limits_{x_i\in\set{B}}(z_i - \mu^{t-1})},\quad 
    N^t = N^{t-1} + |\set{B}^t|, \quad 
    a^t = \frac{1}{N^t}, 
\end{split}
$
}
\end{equation}

% Furthermore, the running mean and covariance for the $k^{th}$ component Gaussian are denoted as $\mu_k^t$ and $\Sigma_k^t$ respectively. Eq.~\ref{eq:category-wise-runningstatistics} are the rules to update them.

% \begin{equation}\label{eq:category-wise-runningstatistics}
% \begin{split}
%     & \delta_k^t=a_k^t{\sum_{x_i\in\set{B}}F^{TC}_iF^{PP}_i\mathbbm{1}(\hat{y}_i=k)(f(x_i)-\mu_k^{t-1})}, \\
%     & N_k^t = N_k^{t-1} + \sum_{x_i\in\set{B}}F^{TC}_iF^{PP}_i\mathbbm{1}(\hat{y}_i=k), \quad 
%     a_k^t = \frac{1}{N_k^t},\\
%     & \mu_k^t = \mu_k^{t-1} + \delta_k^t, \\
%     &\Sigma_k^t=\Sigma_k^{t-1}+a_k^t{\sum_{x_i\in\set{B}}\{F^{TC}_iF^{PP}_i\mathbbm{1}(\hat{y}_i=k)(f(x_i)-\mu_k^{t-1})^\top(f(x_i)-\mu_k^{t-1})-\Sigma_k^{t-1}\}} - {\delta_k^t}^\top\delta_k^t
% \end{split}
% \end{equation}

Since $N^t$ grows larger overtime, new test samples will have smaller contribution to the update of target domain statistics when $N^t$ is large enough. As a result, the gradient calculated from current minibatch will vanish. To alleviate this issue, we impose a clip on the value of $\alpha^t$ as below. As such, the gradient can maintain a minimal scale even if $N^t$ is very large. 

% change the coefficients $a_k^t$ and $a^t$ to constants while they are less than thresholds as,

% New-come test samples thus obtain few weight of updating the corresponding mean and covariance, since $a^t$ and $a_k^t$ are too small. It's the situation that the new features generated by the adapted model have the same weight and the relatively incorrect old features generated by the pre-adapted model, which impacts the estimation of the real time distribution of target domain feature. To alleviate this situation, we change the coefficients $a_k^t$ and $a^t$ to constants while they are less than thresholds as,
% \vspace{-0.3cm}

\begin{equation}
% \begin{split}
    a^t = \left \{
        \begin{array}{lcl}
            \frac{1}{N^t} & & N^t < N_{clip} \\
            \frac{1}{N_{clip}} & & others
        \end{array}
        \right.
    % a_k^t = \left \{
    %     \begin{array}{lcl}
    %         \frac{1}{N_k^t} & & N_k^t < n_{category} \\
    %         \frac{1}{n_{categroy}} & & others
    %     \end{array}
    %     \right.
% \end{split}
\end{equation}
% \vspace{-0.4cm}
% \begin{equation}
% \begin{split}
%     &\mu^t = \frac{N_{t-1}}{N_{t}}\mu^{t-1} + \frac{\sum_{i=N_{t-1}}^{N_t}f(X_i)}{N_t},\\ 
%     &\delta[t]=\frac{\sum_{i=N_{t-1}}^{N_t}(f(X_{i}) - \mu[t-1])}{N_t},\\
%     &\sigma_{mn}[t]=\sigma_{mn}[t-1] + \frac{\sum\limits_{i=N_{t-1}}^{N_t}([f_m(X_i)_{i} - \mu_m[t-1]][f_n(X_i) - \mu_n[t-1]] - \sigma_{mn}[t-1])}{N_t} - \delta_m[t]\cdot\delta_n[t]
% \end{split}
% \end{equation}\label{eq:runningstatistics}



% \subsection{Minimizing KL-Divergence for Anchored Clustering}
% Aligning feature distribution between source and target domains have been proven to be effective to test-time training~\cite{wang2020tent,liu2021ttt++}. In this section, we describe a more principled way to align the feature distribution between source and target domains. W.l.o.g., we define the feature distribution of the source data as $P_s(X)$ and the target data as $P_t(X)$. To align two distributions, we use the KL-Divergence defined as below where $H(P)$ and $H(P,Q)$ are the entropy and cross-entropy respectively.

% \begin{equation}
% \begin{split}
%     KLD(P||Q)&=\int P_s(X)\log(\frac{P_s(X)}{P_t(X)}) dX = \int P_s(X)\log P_s(X)) dX - \int P_s(X)\log P_t(X)dX\\
%     &=-H(P_s) + H(P_s,P_t)
% \end{split}
% \end{equation}

% Minimizing the KL-Divergence as training objective requires a closed-form solution to the above integration. It is commonly true that the source reference distribution $P_s(X)$ is fixed and the only term to be optimized is the cross-entropy $H(P_s,P_t)$. When a single Gaussian distribution is employed to model the global feature distribution~\cite{liu2021ttt++}, we first respectively write the source and target data distributions as $N(\mu_s,\Sigma_s)$ and $N(\mu_t,\Sigma_t)$ and then the closed-form solution exists for Cross-Entropy between two Gaussian distributions as below. We defer the derivation to the Appendix.

\subsection{Self-Training for TTT}

%Matching the distribution between source and target domains regularizes the network to extract features on target domain to reuse the source domain classifiers. However, optimizing the distribution matching loss alone does not impose a strong constraint on the correctness of classification. Therefore, we propose to adopt self-training~(ST) on the test data to impose stronger test-time adaptation. 
Self-training~(ST) has been widely adopted in semi-supervised learning where predictions on unlabeled data are admitted as pseudo labels, and model is trained with the pseudo labels~\cite{berthelot2019mixmatch,sohn2020fixmatch}. In this work, we explore employing self-training for TTT. Blindly taking all pseudo labels for training has been demonstrated to deteriorate the performance as incorrect pseudo labels act as noisy labels and a high percentage of noisy label is harmful for model training. This phenomenon is also referred to as confirmation bias~\cite{arazo2020pseudo}. As demonstrated in the empirical evaluations in Sect.~\ref{sect:ttt_eval}, self-training alone is not guaranteed to outperform competing methods. The performance may even degrades after observing enough testing samples as shown in Fig.~\ref{fig:imagenet_cumulative}.
To reduce the impact of confirmation bias, we first propose to employ anchored clustering as regularization. As anchored clustering allows better alignment between source and target feature distributions, self-training is able to benefit from more accurate pseudo labels and the model is less likely to be harmed by the wrong pseudo labels. This can be achieved by simultaneously optimizing anchored clustering losses and self-training loss. In addition, we further take an approach similar to \cite{sohn2020fixmatch} by filtering out less confident pseudo labels for self-training as in Eq.~\ref{eq:selftraining}. 

% In this work, we adopt a The self-training module uses the pseudo label predicted on target domain testing sampler and utilizes it to supervise network's prediction with cross-entropy loss.

% With the helps of anchored clustering and global feature alignment, to some certain extend, the feature distribution in target domain has been regularized to one in source domain. However, when two distributions are relatively close, the constraints of above components are very weak, especially for each sample. To further enhance the robustness and effectiveness of the test-time adaptation model, we propose the self-training module. The self-training module is consisted of the consistency regularization proposed in FixMatch~\cite{sohn2020fixmatch}, which generates an artificial label by the weakly-augmented version of a given test sample and utilizes it to supervises the strongly-augmented version of the same sample with the cross-entropy loss. Instead of a supervised loss used for labeled data in FixMatch, we leverage the anchored clustering and global feature alignment modules to alleviate the feature collapse during test-time. We formulas the consistency regularization as below,

\begin{equation}\label{eq:selftraining}
\resizebox{0.91\linewidth}{!}{
$
    \mathcal{L}_{st} = \frac{1}{|\set{B}_t|}\sum\limits_{x_i\in\set{B}_t}{\mathbbm{1}(\max\limits_k(q_k(\mathcal{W}(x_i))) \ge \tau_{st})H(\hat{y}_i, q(\mathcal{A}(x_i)))}
$
}
\end{equation}
where $q(\cdot) = \sigma(h(f(\cdot)))$ denotes the probabilistic posterior, $\hat{y}_i = \arg\max_k(q(\mathcal{W}(x_i)))$ denotes the predicted pseudo label, $\mathcal{W}(\cdot)$ denotes a weak augmentation operation consisting of RandomHorizontalFlip and RandomResizedCrop, $\mathcal{A}(\cdot)$ denotes a strong augmentation operation implemented as RandAugment~\cite{RandAugment}, and $\tau_{cr}$ denotes the confidence threshold.




\subsection{TTAC++ Training Algorithm}
We summarize the training algorithm for the TTAC++ in Algo.~\ref{alg:main}. For effective clustering in target domain, we allocate a fixed length memory space, denoted as testing time queue $\set{C} \in \set{R}^{N_{C} \times H \times W \times \texttt{3}}$, to store the recent testing samples. In the sTTT protocol, we first make instant prediction on each testing sample, and only update the model when $N_B$ testing samples are accumulated. TTAC++ can be efficiently implemented, e.g. with two devices, one is for continuous inference and another is for model updating.%The number of the iterations performed in each adaptation stage is denoted as $n$.

% \vspace{-0.4cm}
\begin{algorithm}
% \setstretch{1.2}
\caption{TTAC++ Algorithm }\label{alg:main}
% \begin{algorithmic}
% \Require $n \geq 0$
% \Ensure $y = x^n$
% \State $y \gets 1$
% \State $X \gets x$
% \State $N \gets n$
% \While{$N \neq 0$}
% \If{$N$ is even}
%     \State $X \gets X \times X$
%     \State $N \gets \frac{N}{2}$  \Comment{This is a comment}
% \ElsIf{$N$ is odd}
%     \State $y \gets y \times X$
%     \State $N \gets N - 1$
% \EndIf
% \EndWhile
\SetKwInOut{Input}{input}
\SetKwInOut{Return}{return}
\Input{A new testing sample batch $\set{B}^t=\{x_i\}_{i=tN_B\dots (t+1)N_B}$.}

\textcolor{gray}{\# Update the testing sample queue $\set{C}$.}

$\set{C}^t=\set{C}^{t-1}\setminus \set{B}^{t-N_C/N_B}$,\quad
$\set{C}^t=\set{C}^t\bigcup \set{B}^{t}$

\For{$ 1 $ \KwTo $N_{itr}$}
{
    \For{minibatch $\{x^t_i\}^N_{i=1}$ in  $\set{C}^t$}
    {
        \textcolor{gray}{\# Generate weak and strong augmented samples}
        
         $\mathcal{W}(x^t_i), \quad \mathcal{A}(x^t_i)$

        \textcolor{gray}{\# Obtain the predicted posterior and pseudo labels}
        
        $q(\mathcal{W}(x_i^t))=\sigma(h(f(\mathcal{W}(x_i^t))))$
        
        $\hat{y}_i=\arg\max_k(q(\mathcal{W}(x_i^t)))$
        
        \textcolor{gray}{\# Update the global and per-cluster running mean and covariance by Eq.~\ref{eq:runningstatistics} with $\mathcal{W}({x_i^t})$}
        
        $\mu^t$,\quad $\Sigma^t$,\quad $\{\mu_k^t\}$,\quad $\{\Sigma_k^t\}$
        
        % $\Sigma^t=\Sigma^{t-1}+a^t{\sum_{x^t_i\in\set{B}^{t}}\{(f^t_i-\mu^{t-1})^\top(f^t_i-\mu^{t-1})-\Sigma^{t-1}\}} - {\delta^t}^\top\delta^t$
        
        % \textcolor{gray}{\# calculate the running mean and covariance of each cluster (in Eq.~\ref{eq:category-wise-runningstatistics})}
        
        % $\mu_k^t = \mu_k^{t-1} + \delta_k^t$
        
        % $\Sigma_k^t=\Sigma_k^{t-1}+a_k^t{\sum_{x_i\in\set{B}}\{F^{TC}_iF^{PP}_i\mathbbm{1}(\hat{y}_i=k)(f^t_i-\mu_k^{t-1})^\top(f^t_i-\mu_k^{t-1})-\Sigma_k^{t-1}\}} - {\delta_k^t}^\top\delta_k^t$
        
        \textcolor{gray}{\# Calculate the anchored clustering losses according to Eq.~\ref{eq:anchored_clustering_loss} and Eq.~\ref{eq:global_loss}}
        
        $\mathcal{L}_{ac}+\lambda_1\mathcal{L}_{ga}$

        \textcolor{gray}{\# Calculate self-training loss according to  Eq.~\ref{eq:selftraining}}
        
        $\mathcal{L}_{st}$%$ = \frac{1}{N_B}\sum_{i=1}^{N_B}{\mathbbm{1}(max(q(a^t_i)) \ge \tau_{cr})H(\hat{q}(a^t_i), q(b^t_i))}$

       \textcolor{gray}{\# One step gradient descent on the total loss}
       
       $\mathcal{L}_{ac} + \lambda_1\mathcal{L}_{ga}+ \lambda_2\mathcal{L}_{st}$
        
        %update network $f$ to minimize $\mathcal{L}$
    }
}



% \Return{backbone network $f(\cdot)$}
% \Return{the prediction result of the latest test sample $argmax_k(h(f(\set{B}^t)))$}

% \end{algorithmic}
\end{algorithm}
% \vspace{-0.5cm}



% \subsection{Additional Feature Alignment}

% The proposed anchored clustering aims to match the clusters discovered in the target domain to the source domain clusters so that the classifiers can be reused. This strategy is mainly effective when enough target domain data are observed and may not perform well at the beginning of test-time training. To improve the TTT performance at the early stage, we can further align the global feature distributions to enhance the feature alignment. The objective is similar to the feature alignment proposed in~\cite{liu2021ttt++}, but we adopt the KL-Divergence between source and target global feature distributions as the objective to optimize as below.

% \begin{equation}
% H(P_s,P_t)= \log \sqrt{2\pi^d|\Sigma_t|} + \frac{1}{2}(\mu_t-\mu_s)^\top\Sigma_t^{-1}(\mu_t-\mu_s) + tr(\Sigma_t^{-1}\Sigma_s)
% \end{equation}

% The above Cross-Entropy objective is better than directly minimizing the F-norm between the mean and covariance, i.e. $||\mu_t-\mu_s||^2_2+||\Sigma_t-\Sigma_s||^2_F$, as adopted by ~\cite{liu2021ttt++} in that the mean and covariance are properly weighted in accordance with distribution matching while direct minimizing the F-norm is subject to larger norm in the covariance term and choosing appropriate weight between the two terms would introduce another hyper-parameter. The advantage of using Cross-Entropy loss is also demonstrated via empirical evaluation on multiple test-time training datasets.
