{
    "arxiv_id": "2303.16433",
    "paper_title": "A Bandit Learning Method for Continuous Games under Feedback Delays with Residual Pseudo-Gradient Estimate",
    "authors": [
        "Yuanhanqing Huang",
        "Jianghai Hu"
    ],
    "submission_date": "2023-03-29",
    "revised_dates": [
        "2023-03-30"
    ],
    "latest_version": 1,
    "categories": [
        "math.OC"
    ],
    "abstract": "Learning in multi-player games can model a large variety of practical scenarios, where each player seeks to optimize its own local objective function, which at the same time relies on the actions taken by others. Motivated by the frequent absence of first-order information such as partial gradients in solving local optimization problems and the prevalence of asynchronicity and feedback delays in multi-agent systems, we introduce a bandit learning algorithm, which integrates mirror descent, residual pseudo-gradient estimates, and the priority-based feedback utilization strategy, to contend with these challenges. We establish that for pseudo-monotone plus games, the actual sequences of play generated by the proposed algorithm converge a.s. to critical points. Compared with the existing method, the proposed algorithm yields more consistent estimates with less variation and allows for more aggressive choices of parameters. Finally, we illustrate the validity of the proposed algorithm through a thermal load management problem of building complexes.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16433v1"
    ],
    "publication_venue": null
}