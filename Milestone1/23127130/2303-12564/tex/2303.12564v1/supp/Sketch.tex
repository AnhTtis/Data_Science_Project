\section{Details of Sketch-based Modeling}

\noindent\textbf{Data preparation.} We first sample 12,000 shape vectors randomly and feed them to \textit{RaBit} to generate 3D cartoon characters with diversified shapes. Then the suggestive contour~\cite{decarlo2003suggestive, han2017deepsketch2face} is applied to render the front-view sketches with different abstraction levels and obtain 108,000 sketch-model pairs. Fig.~\ref{fig_sketch_data} shows examples of rendered sketches. 

\input{supp_figure/fig_sketch_data}

\noindent\textbf{Implementations.} As shown in Fig.~\ref{fig_sketch_pipeline}, we first adopt one ResNet-50 module and three MLPs as the encoder-decoder architecture, mapping the input sketch $512 \times 512$ to 100-dimensional shape parameters. Then the generated shape parameters are fed to \textit{RaBit} to reconstruct the corresponding 3D model. We train the network with a batch size of $100$ and a learning rate of $3 \times 10^{-4}$ with the Adam optimizer. Moreover, we use the $L_1$ loss to measure the difference between the predicted shape parameters and the ground truth. Our sketch-based modeling interface is implemented with the QT framework. CGAL is adopted for 3D geometry processing. As shown in the video, running on a personal computer with an Intel i7-7700 CPU, 16GB RAM, and a single Nvidia GTX 2080Ti GPU, our modeling application supports real-time feedback. 

\input{supp_figure/fig_sketch_pipeline}