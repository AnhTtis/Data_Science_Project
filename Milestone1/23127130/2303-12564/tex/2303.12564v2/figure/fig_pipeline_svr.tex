% \begin{figure*}[htbp]
%   \centering
%   \includegraphics[width=0.92 \linewidth]{image/fig_pipeline2.pdf}
%   \caption{%The architecture of our baseline method. 
%   \textbf{Single view reconstruction baseline.}
%   Given an image as input, we firstly adopt two CNNs and three MLPs as the encoders, mapping the input to three low-dimension latent codes respectively, i.e., the parameters of shape, pose and texture. Then these three parameters are fed into our \textit{SMCL} model to generate the predicted mesh with texture and pose. Finally, we take the ground truth model from \textit{3DBiCar} as supervision to train our neural network. Our \textit{SMCL} is not only responsible for the shape, pose and texture generation, but also takes charge of the eyes computing.
%   %Overview of our baseline pipeline: Input images are fed to the encoder, and output shape, pose, and texture parameters. With \textit{SMBL}, posed textured models are reconstructed with predicted parameters.} %In our pipeline, we invlove in prevent shape and pose parameter from influencing mutually
%   }
%   \label{reconstruction:pipeline}
% \end{figure*}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=.96\linewidth]{image/pipeline_svr.pdf}
  \caption{\textit{\textbf{BiCarNet}.} Given a masked image, we first map it to the parametric vectors. The vectors are then fed to our \textit{RaBit} to generate a posed body mesh, two eyeballs, and a global UV texture. A part-sensitive reasoner is utilized to perceive local regions and generate the detailed UV texture map. Finally, a vivid 3D cartoon character is obtained with our \textit{BiCarNet}.}
  \label{fig_pipeline_svr}
\end{figure}