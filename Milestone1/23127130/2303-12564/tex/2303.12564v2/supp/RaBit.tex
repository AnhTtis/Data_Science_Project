\section{Details of \textit{RaBit}}

\noindent\textbf{Shape Space.} As illustrated in Fig.~\ref{rec}, \textit{RaBit} is able to express the \textit{basic geometry} of diverse shapes in \textit{3DBiCar} with \textit{low-dimensional vectors} (100 in our experiments). Such ability of \textit{RaBit} can well facilitate the construction of learning-based regression methods for inferring reasonable shapes from images or sketches, as demonstrated in our downstream tasks. Biped cartoon is known as a popular character style in gaming and filming. \textit{RaBit} spans a wider range of species than existing human model~\cite{SMPL:2015,SMPL-X:2019}. However, due the use of the holistic PCA model, \textit{RaBit} may struggle to represent local geometric details and may result in undesirable entanglement, as shown in Fig.~\ref{axis}. Conducting parametric modeling for diverse shapes is a fundamental problem, but it has received little methodological evolution in the past due to the lack of data. We hope that our proposed dataset can inspire further research in this area.

% We agree that the specific type limits the usability (new types require new designs, i.e., quadruped), while this in contrast provides feasibility for parametric modeling. Even so, the problem is still very challenging. Biped cartoon is known as a popular character style in gaming and filming. Our model spans a wider range of species than existing human model. We hopes to take a small step in this field.  
%our experiments show that L-PCA is able to express the \textit{basic geometry} of diverse shapes with \textit{low-dimensional vectors} (100 in our experiments), which is verified by Fig.~\ref{rec}. %The first two shape principal components of shape are shown in .
\input{rebuttal_figure/fig_rec}

\input{rebuttal_figure/fig_axis}

\noindent\textbf{Visualization of Topological Consistency.} Good correspondence of training data is essential for constructing a linear shape model and preserving the topological consistency of reconstructed models. Getting topological consistency in manual modeling is intrinsically challenging. To do so, we put much effort to construct \textit{3DBiCar}, including template designing, landmark guidance, review committee for careful checking. In Fig.~\ref{correspondence}, we use checkboard texture mapping for visualizing the correspondence of representative examples sampled from \textit{RaBit}'s shape space.

\input{rebuttal_figure/fig_correspondance}

\noindent\textbf{Eyeball Reconstruction.}
In our implementation, we approximate an eyeball as a sphere. Generally, a sphere is determined by its center and radius. As shown in the Fig.~\ref{eyeball}, in \textit{RaBit}, an eyeball's center $\mathbf{o_{e}}$ and radius $r_{e}$ is computed as follows,

\begin{equation}
    r_{e} = c_1 r_s,
\end{equation}
\begin{equation}
    d_{e} = c_2 r_s,
\end{equation}
\begin{equation}
    \mathbf{o_e} = \mathbf{o_s} - d_{e} \mathbf{n},
\end{equation}
where $r_s$ and $\mathbf{o_s}$ is the radius and the center of the 3D circle, computed by the least square fitting with the landmark points of the eye socket. $d_e$ denotes the Euclidean Distance between $\mathbf{o_s}$ and $\mathbf{o_e}$ and $\mathbf{n}$ the normal of the 3D circle. $c_1$ is the mean value of ${d_e}/{r_s}$ of all models in \textit{3DBiCar},  while $c_2$ is the mean value of ${r_e}/{r_s}$. Both $c_1$ and $c_2$ are precomputed constant values.

\input{supp_figure/eye_ball}

\noindent\textbf{Implementations.} The shape model of \textit{RaBit} is learned from 1,050 models of \textit{3DBiCar} using PCA~\cite{pedregosa2011scikit,SMPL:2015}.
For pose modeling, \textit{RaBit} utilizes the consistent skeleton and skinning weight matrix defined in \textit{3DBiCar}. Note that both \textit{3DBiCar} and \textit{RaBit} currently does not support the animation of tails, which will be explored in our future work. As for texture modeling, 1,050 raw textures from \textit{3DBiCar} were adopted and extended to 21,000 training data with image-level augmentations (e.g., flipping, and adjusting HSV). \textit{Rabit}'s texture generator follows the architecture of StyleGAN2~\cite{karras2020analyzing} and is trained with the following setting:  the dimensionality of $Z$ with $512$, the output resolution with $1024 \times 1024 \times 3$, the learning rate with $3 \times 10^{-4}$, the batch size with 32, the Adam optimizer with $\beta_1=0$, $\beta_2=0.99$, $\epsilon=10^{-8}$. The training is performed on a server with 4 Nvidia RTX 3090Ti GPUs.