\label{sec:appendix}
\section{Parameterization of SMCL}
\label{sec:experiment-sampleing}
% Sample on mesh: Interpolated Sample,Sample one specific axis, part aware sample % Sample on pose: pose sample 
% This section shows several sampling methods to show the capacity and \textit{SMCL}.

To demonstrate the generalization of \textit{SMCL}, we sample on parameter $(B,e,\Theta,T)$ as equation shows in section \ref{sec:algorithm}. 

\begin{equation}
\begin{split}
    M =& F(B, e, \Theta, T)\\
      =& F_T(F_P(F_S(B,e),\Theta), T)
\label{eq:1}
\end{split}
\end{equation}

We first sample shape parameter $B$ of \textit{SMCL} in Fig. \ref{fig_interpolation}. Interpolations of two models in the dataset building reasonable models shows the stability of our parameterization on mesh. 

Next, we adopt part-aware sampling in Fig. \ref{fig_assemble} through concating parameters of differents parts. It can be seen that \textit{SMCL} can generate diverse models with fully decoupled parts.

%Part-aware sampling in Fig. \ref{fig_assemble} aims t to generate the hybrids derived from various models. This sampling method suggests that \textit{SMCL} can generate diverse models with fully decoupled parts.

We further adopt poses from Human3.6M\cite{Ionescu2014Human36M} to our pose parameter  space $\Theta$ as Fig~\ref{fig_poseaug}. Notice that we can generate an animation video from a pose sequence.

%As for pose sampling, a similar skeleton structure allows us to transfer the poses from other human body datasets to our model (Fig. \ref{fig_poseaug}). Moreover, with a sequence pose and a specific model, we can output an animation video for corresponding model.

In the end, we interpolate the parameter $T$ in textures of two samples. The UV maps and models with UV map are shown in Fig. \ref{fig_uv_interpolation}, which demonstrates the capability of our texture parameterization.
% \section{}
% \input{supp_figure/fig_interpolation}
\input{supp_figure/fig_assemble}
% \input{supp_figure/fig_poseaug}
\input{supp_figure/fig_uv_interpolation}