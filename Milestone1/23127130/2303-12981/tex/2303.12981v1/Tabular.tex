\section{Connected Superlevel Set Under Tabular Policy}\label{sec:tabular}

We consider the infinite horizon, average reward MDP characterized by $\Mcal=(\Scal,\Acal,\Pcal,r)$. $\Scal$ and $\Acal$ denote the state and action spaces, which we assume are finite. $\Pcal:\Scal\times\Acal\rightarrow \Delta_{\Scal}$ is the transition probability kernel, where $\Delta_{\Scal}$ denotes the probability simplex over $\Scal$. $r:\Scal\times\Acal\rightarrow[0,U_r]$ is the bounded reward function for some positive constant $U_r$ and can also be represented as a vector in $\mathbb{R}^{|\Scal|\times|\Acal|}$. We use $P^{\pi}\in\mathbb{R}^{\Scal\times\Scal}$ to represent the state transition probability matrix under policy $\pi\in\Delta_{\Acal}^{\Scal}$, where $\Delta_{\Acal}^{\Scal}$ is the collection of probability simplexes over $\Acal$ across the state space
\begin{align}
    P^{\pi}_{s',s}=\sum_{a\in\Acal}\Pcal(s'\mid s,a)\pi(a\mid s),\quad\forall s',s\in\Scal.\label{eq:transition_matrix}
\end{align}
% $\mu_{\pi}\in\Delta_{\Scal}$ denotes the stationary distribution of the states induced by policy $\pi$. It is well-known that $\mu_{\pi}$ is an eigenvector of $P^{\pi}$ with the associated eigenvalue equal to $1$, i.e. $\mu_{\pi}=P^{\pi}\mu_{\pi}$. 

We consider the following ergodicity assumption in the rest of the paper, which is commonly made in the RL literature \citep{wang2017primal,wei2020model,wu2020finite}.
\begin{assump}\label{assump:ergodicity}
Given any policy $\pi$, the Markov chain formed under the transition probability matrix $P^{\pi}$ is ergodic, i.e. irreducible and aperiodic.
\end{assump}
Let $\mu_{\pi}\in\Delta_{\Scal}$ denote the stationary distribution of the states induced by policy $\pi$. As a consequence of Assumption~\ref{assump:ergodicity}, the stationary distribution $\mu_{\pi}$ is unique and uniformly bounded away from $0$ under any $\pi$. In addition, $\mu_{\pi}$ is the unique eigenvector of $P^{\pi}$ with the associated eigenvalue equal to $1$, i.e. $\mu_{\pi}=P^{\pi}\mu_{\pi}$. 
Let $\widehat{\mu}_{\pi}\in\Delta_{\Scal\times\Acal}$ denote the state-action stationary distribution induced by $\pi$, which can be expressed as
\begin{align}
    \widehat{\mu}_{\pi}(s,a)\triangleq\mu_{\pi}(s)\pi(a\mid s).\label{eq:mu_hat}
\end{align}

We measure the performance of a policy $\pi$ under reward function $r$ by the average cumulative reward $J_r(\pi)$
\begin{align*}
    J_r(\pi)\triangleq\lim_{K \rightarrow \infty} \frac{\sum_{k=0}^{K} r(s_k, a_k)}{K}=\mathbb{E}_{s\sim\mu_{\pi}, a\sim \pi}[r(s_k,a_k)]=\sum_{s,a}r(s,a)\widehat{\mu}_{\pi}(s,a).
\end{align*}

The objective of the policy optimization problem is to find the policy $\pi$ that maximizes the average cumulative reward
\begin{align}
    \max_{\pi\in\Delta_{\Acal}^{\Scal}}J_r(\pi).\label{eq:obj}
\end{align}

The superlevel set of $J_r$ is the set of policies that achieve a value function greater than or equal to a specified level. Formally, given $\lambda\in\mathbb{R}$, the $\lambda$-superlevel set (or superlevel set) under reward $r$ is defined as
\[
    \Ucal_{\lambda,r}\triangleq\{\pi\in\Delta_{\Acal}^{\Scal}\mid J_r(\pi)\geq \lambda\}.
\]

The main focus of this section is to study the connectedness of this set $\Ucal_{\lambda,r}$, which requires us to formally define a connected set.
\begin{definition}\label{def:connectedset}
A set $\Ucal$ is connected if for any $x,y\in\Ucal$ there exists a continuous map $p:[0,1]\rightarrow\Ucal$ such that $p(0)=x$ and $p(1)=y$.
\end{definition}
We say that a function is connected if its superlevel sets are connected at all levels. We also introduce the definition of equiconnected functions. 
\begin{definition}\label{def:equiconnectedfunc}
Given two spaces $\Xcal$ and $\Ycal$, the collection of functions $\{f_y:\Xcal\rightarrow\mathbb{R}\}_{y\in\Ycal}$ is said to be equiconnected if for every $x_1,x_2\in\Xcal$, there exists a continuous path map $p:[0,1]\rightarrow\Xcal$ such that
\begin{align*}
    p(0)=x_1,\quad p(1)=x_2,\quad f_y(p(\alpha))\geq\min\{f_y(x_1),f_y(x_2)\},
\end{align*}
for all $\alpha\in[0,1]$ and $y\in\Ycal$.
\end{definition}
Conceptually, the collection of functions $\{f_y:\Xcal\rightarrow\mathbb{R}\}_{y\in\Ycal}$ being equiconnected requires 1) that $f_y(\cdot)$ is a connected function for all $y\in\Ycal$ (or equivalently, the set $\{x\in\Xcal:f_y(x)\geq\lambda\}$ is connected for all $\lambda\in\mathbb{R}$ and $y\in\Ycal$) and 2) that the path map constructed to prove the connectedness of $\{x\in\Xcal:f_y(x)\geq\lambda\}$ is independent of $y$.


We now present our first main result of the paper, which states that the superlevel set $\Ucal_{\lambda,r}$ is always connected.
\begin{thm}\label{thm:connected_tabular}
    Under Assumption \ref{assump:ergodicity}, the superlevel set $\Ucal_{\lambda,r}$ is connected for any $\lambda\in\mathbb{R}$ and $r\in\mathbb{R}^{|\Scal||\Acal|}$.
    In addition, the collection of functions $\{J_r(\cdot):\Delta_{\Acal}^{\Scal}\rightarrow\mathbb{R}\}_{r\in\mathbb{R}^{|\Scal|\times|\Acal|}}$ is equiconnected.
\end{thm}

The claim in Theorem~\ref{thm:connected_tabular} on the equiconnectedness of $\{J_r\}_{r\in\mathbb{R}^{|\Scal|\times|\Acal|}}$ is a slightly stronger result than the connectedness of $\Ucal_{\lambda,r}$, and plays an important role in the application to minimax theorems discussed later in Section~\ref{sec:application}.

We note that the proof, presented below, is mainly based on the fact that the value function $J_r(\pi)$ is linear in the state-action stationary distribution $\widehat{\mu}_{\pi}$ and that there is a special connection (though nonlinear and nonconvex) between $\widehat{\mu}_{\pi}$ and the policy $\pi$, which we take advantage of to construct the continuous path map for the analysis.
% We take advantage of this connection to construct a continuous path map $p:[0,1]\rightarrow\Ucal_{\lambda,r}$ such that $p(0)=x_1$ and $p(1)=x_2$ for any $x_1,x_2\in\Ucal_{\lambda,r}$, which we present in the proof below.


\noindent\textbf{Proof (of Theorem~\ref{thm:connected_tabular}):}
We note that there exists a bijective map between $\pi$ and $\widehat{\mu}_{\pi}$ where $\widehat{\mu}_{\pi}$ is induced by $\pi$ according to \eqref{eq:mu_hat} and conversely
\begin{align}
    \pi(a\mid s)=\frac{\widehat{\mu}_{\pi}(s,a)}{\mu_{\pi}(s)}=\frac{\widehat{\mu}_{\pi}(s,a)}{\sum_{a\in\Acal}\widehat{\mu}_{\pi}(s,a)},\label{thm:connected_tabular:proof_eq1}
\end{align}
provided that $\mu_{\pi}(s)\neq 0$, which is guaranteed by Assumption \ref{assump:ergodicity}. \eqref{thm:connected_tabular:proof_eq1} inspires the construction of the path map.


To prove that the superlevel set is connected, we show that for any $\lambda\in\mathbb{R}$ and $\pi_1,\pi_2\in \Ucal_{\lambda,r}$, there exists a continuous path map $p:[0,1]\rightarrow \Ucal_{\lambda,r}$ such that $p(0)=\pi_1$ and $p(1)=\pi_2$. 
We now construct the path function $p$ by defining
\begin{align*}
    p(\alpha)(a\mid s) = \frac{\alpha \mu_{\pi_1}(s)\pi_1(a\mid s)+(1-\alpha)\mu_{\pi_2}(s)\pi_2(a\mid s)}{\alpha \mu_{\pi_1}(s)+(1-\alpha)\mu_{\pi_2}(s)},
\end{align*}
which is well-defined for all $\alpha\in[0,1]$ as $\mu_1(s),\mu_2(s)$ are positive for all $s\in\Scal$.
Note that the construction of $p$ does not depend on the reward function $r$.
It is easy to see that $p(\alpha)\in\Delta_{\Acal}^{\Scal}$ is a continuous in $\alpha$. 
To stress that $p(\alpha)$ is in the policy space, we denote $\pi_{\alpha}=p(\alpha)$.

Recall the definition of the transition probability matrix in \eqref{eq:transition_matrix}. We define $B\in\mathbb{R}^{|\Scal|}$ as
\begin{align*}
    B=P^{\pi_{\alpha}}\cdot\left(\alpha\mu_{\pi_1}+(1-\alpha)\mu_{\pi_2}\right).
\end{align*}

Each entry of $B$ can be expressed as
\begin{align*}
    B(s') &= \sum_{s,a}\Pcal(s'\mid s,a)\pi_{\alpha}(a\mid s)\left(\alpha\mu_{\pi_1}(s)+(1-\alpha)\mu_{\pi_2}(s)\right)\notag\\
    &=\sum_{s,a}\Pcal(s'\mid s,a)\frac{\alpha \mu_{\pi_1}(s)\pi_1(a\mid s)+(1-\alpha)\mu_{\pi_2}(s)\pi_2(a\mid s)}{\alpha \mu_{\pi_1}(s)+(1-\alpha)\mu_{\pi_2}(s)}\left(\alpha\mu_{\pi_1}(s)+(1-\alpha)\mu_{\pi_2}(s)\right)\notag\\
    &=\sum_{s,a}\Pcal(s'\mid s,a)\alpha \mu_{\pi_1}(s)\pi_1(a\mid s)+\sum_{s,a}\Pcal(s'\mid s,a)(1-\alpha)\mu_{\pi_2}(s)\pi_2(a\mid s)\notag\\
    &=\alpha\sum_{s,a}P^{\pi_1}_{s',s} \mu_{\pi_1}(s)+(1-\alpha)\sum_{s,a}P^{\pi_2}_{s',s}\mu_{\pi_2}(s)\notag\\
    &=\alpha\mu_{\pi_1}(s')+(1-\alpha)\mu_{\pi_2}(s'),
\end{align*}
which implies
\begin{align}
    P^{\pi_{\alpha}}\cdot\left(\alpha\mu_{\pi_1}+(1-\alpha)\mu_{\pi_2}\right)=\alpha\mu_{\pi_1}+(1-\alpha)\mu_{\pi_2}.\label{thm:connected_tabular:proof_eq1.5}
\end{align}
A consequence of Assumption \ref{assump:ergodicity} is that for any policy $\pi$ there is a unique eigenvector of $P^{\pi}$ associated with the eigenvalue $1$, and this eigenvector (properly normalized) is the stationary distribution. Therefore, \eqref{thm:connected_tabular:proof_eq1.5} means that $\alpha\mu_{\pi_1}+(1-\alpha)\mu_{\pi_2}$ has to be the stationary distribution under policy $\pi_{\alpha}$, i.e.\looseness=-1
\begin{align*}
    \mu_{\pi_{\alpha}} = \alpha\mu_{\pi_1}+(1-\alpha)\mu_{\pi_2}.
\end{align*}
As a result, for all $s\in\Scal,a\in\Acal$
\begin{align*}
    \widehat{\mu}_{\pi_{\alpha}}(s,a) &= \mu_{\pi_{\alpha}}(s)\pi_{\alpha}(a\mid s)\\
    &=\left(\alpha\mu_{\pi_1}(s)+(1-\alpha)\mu_{\pi_2}(s)\right)\frac{\alpha \mu_{\pi_1}(s)\pi_1(a\mid s)+(1-\alpha)\mu_{\pi_2}(s)\pi_2(a\mid s)}{\alpha \mu_{\pi_1}(s)+(1-\alpha)\mu_{\pi_2}(s)}\\
    &=\alpha \mu_{\pi_1}(s)\pi_1(a\mid s)+(1-\alpha)\mu_{\pi_2}(s)\pi_2(a\mid s)\\
    &=\alpha\widehat{\mu}_{\pi_1}(s,a)+(1-\alpha)\widehat{\mu}_{\pi_2}(s,a).
\end{align*}

Note that $J_r(\pi) = \sum_{s\in\Scal,a\in\Acal}r(s,a)\widehat{\mu}_{\pi}(s,a)$.
Since $\pi_{\pi_1},\pi_{\pi_2}\in \Ucal_{\lambda,r}$, we know
\begin{align*}
    \sum_{s\in\Scal,a\in\Acal}r(s,a)\widehat{\mu}_{\pi_1}(s,a)\geq \lambda,\quad\sum_{s\in\Scal,a\in\Acal}r(s,a)\widehat{\mu}_{\pi_2}(s,a)\geq \lambda.
\end{align*}
Therefore, we have for any $\alpha\in[0,1]$
\[
    J_r(\pi_{\alpha})=\sum_{s\in\Scal,a\in\Acal}r(s,a)\widehat{\mu}_{\pi_{\alpha}}(s,a)=\sum_{s\in\Scal,a\in\Acal}r(s,a)\left(\alpha\widehat{\mu}_{\pi_1}(s,a)+(1-\alpha)\widehat{\mu}_{\pi_2}(s,a)\right)\geq \lambda,
\]
which implies $\pi_{\alpha}\in \Ucal_{\lambda,r}$. So far we have verifed that the constructed path map $p$ is indeed continuous and maps $\alpha\in[0,1]$ to $\Ucal_{\lambda,r}$ with $p(0)=\pi_1$ and $p(1)=\pi_2$. This concludes the proof on the connectedness of the superlevel set $\Ucal_{\lambda,r}$. The claim on the equiconnectedness simply follows from the fact that the construction of the path map $p$ does not depend on the reward function.

\qed
