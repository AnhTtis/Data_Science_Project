In this section, we describe a schema optimization problem for time-dependent workloads on NoSQL databases, in particular on extensible record stores~\cite{Cattell2011}.

\subsection{Extensible Record Store}\label{ssec:ERS}
An extensible record store, such as Apache Cassandra, is a general type of NoSQL databases that achieves high scalability by partitioning database in distributed multiple nodes. 
Extensible record stores utilize column families (CFs) for expressing database schema.
We treat CFs as physical schema, which is derived from conceptual schema expressed with an entity graph~\cite{Mior2017} (simplified ER model).
CFs contain three types of columns, \emph{partition  key}, \emph{clustering  key}, and \emph{value}. 
\emph{partition key} is a key used for database (range or hash) partitioning over multiple nodes. 
$clustering \: key$ is a sorting key used inside for each node. 
Other columns are treated as $values$.
CF is expressed in the following notation:
\begin{equation}
  [\mathit{partition \: keys}][\mathit{clustering \: keys}] \rightarrow [\mathit{values}] \nonumber
 \label{Equation:CF}
\end{equation}
The notation indicates a functional dependency from (\emph{partition keys}, \emph{clustering keys}) pair to \emph{values}.

\subsection{Time-dependent Workloads}\label{ssec:TDWorkload}
We focus on predictable or pre-scheduled time-dependent workload patterns, such as cycles, growth and spikes, and workload evolution~\cite{Ma2018}, 
which are common patterns in automated IoT applications and scientific analysis.
In such workloads, all the queries and update operations are often known or predictable beforehand.
A time-depended workload $W$ denotes a collection of SQL statements, queries $Q$ and update operations $U$, on a conceptual (relational) schema
and only the frequency of each query/update operation changes over time\footnote{A new query appears if its frequency is changed from zero.}. 
Since the frequencies of queries/update change, we may need database migrations for reducing the total cost of the workload execution and the migration. 
%Since the frequencies change over time, an optimum physical schema (column families) at different time step can be different from those at other time steps. 
For example, a more denormalized schema should be chosen when the workload is read-intensive. 
This motivates us to optimize time-series physical schema over time-dependent workloads on extensible record stores.

\subsection{Problem statement}
Given a time-dependent workload, a conceptual schema, and a maximum storage size as a constraint, we identify an optimized time-series physical schema (set of column families) by minimizing the total cost of the workload execution and database migration.
As a result of schema optimization, we also output optimized query plans using the physical schema at each time step and migration plans between the schemas of different time steps.
A query plan is expressed on a physical schema, which is generated from a SQL statement in a workload $W$: it consists of multiple steps using filtering, sorting, and aggregation.
A migration plan transforms old column families into a new column family, which is generated from a migration query. Notice that we generate migration queries from workload queries $Q$, since database migration is usually made for reducing query cost by materializing query results (See migration plan enumeration in Section~\ref{Section:EnumerateMirgatePlan} for more detail).
In addition, new column families are incrementally maintained and workload continues execution during database migration. 

\subsection{Query/migration plan group}\label{ssec:QueryPlanAndMigrationPlan}
\begin{figure}[t]
  \begin{center}
    \includegraphics[scale = 0.65,bb = 0 0 382.08 315.12]{figs/query_plan_example.pdf}
    \caption{An example of schema design obtained from a conceptual schema for two queries, $q_1, q_2$.
A query plan group is generated on the column families enumerated from the columns used in each query.}
    \label{SchemaDesignExample}
  \end{center}
\end{figure}

\begin{figure}[t]
    \includegraphics[scale = 0.51,bb = 0 0 497 103.92]{figs/td_query_plan_example.pdf}
    \caption{An example of changing query plans (the orange arrows indicate the chosen plan). The workload execution cost is reduced by changing the query plan according to the query frequency changes at each time step.\todo{crop}}
    \label{TdQueryPlanExample}
\end{figure}

We introduce query plan groups, a collection of query plans that are transformed from each SQL query in the workload\footnote{We similarly treat update operations as queries in the workload.}.
We choose a single optimized query plan in a query plan group at every time step by schema optimization.
We express a query plan as a path of steps (serialized from a typical query plan tree) where each step represents an operation, \texttt{Get} which fetches data from a column family. We call these steps \texttt{Get} steps for simplicity. 
Query plans in prior work~\cite{Mior2017} not only have \texttt{Get} steps but also has an \texttt{ORDER BY} step on column families at the server side additionally with join/filtering/sort steps that are executed at the application side.
We also express a query plan group using a tree structure which nodes with the same parent share a prefix of their query plans.
% Each query plan in a query plan group forms a path from the root node with following steps (parallelograms in the figure), where each step represents a get operation on its column family. 
We call a query plan with a single \texttt{Get} step a \emph{materialized view (MV) plan} and also call one with multiple \texttt{Get} steps a \emph{join plan}.
MV plans are efficient for query processing since they don't need join operations between column families.
In contrast, join plans use multiple normalized column families so they are efficient for update processing and saving storage size. However, they require expensive join operations between the column families, since extensible record stores do not support join operations at the server side so the join operations need to be made at the application side.

Next, we introduce migration plan groups, a collection of migration plans that are transformed from a migration query.
A migration plan generates a new column family at the next time step using schema at the current time step.
We choose a single optimized migration plan among multiple migration plan groups obtained from migration queries by schema optimization.

\subsection{Examples of optimizing time-series schema}
Figure~\ref{SchemaDesignExample} depicts an example of schema design obtained from a conceptual schema for two queries, $q_1, q_2$.
A query plan group is generated on the column families enumerated from the columns used in each query.
In Figure~\ref{SchemaDesignExample}, $p_{1, 1}$ and $p_{2, 1}$ are MV plans, and $p_{1, 2}$ and $p_{2, 2}$ are join plans.
For example, query plan $p_{1, 2}$ first extracts records from $\mathit{CF}2$ using an equality predicate on $item.name$ in query $q1$ and then extracts records from $\mathit{CF}3$ using $user.id$ as the join key from $\mathit{CF}2$ to $\mathit{CF}3$. 
Since join operations need to be made at the application side, the join plan $p_{1,2}$ is significantly slower than the MV plan $p_{1,1}$.
However, the join plan $p_{1, 2}$ requires less storage size than the MV plan $p_{1,1}$, since $p_{1, 2}$ uses denormalized schema, $\mathit{CF}2$, $\mathit{CF}3$.

Next, Figure~\ref{TdQueryPlanExample} depicts an example of changing query plans for a time-dependent workload. 
We assume that 
1) MV plans cannot be chosen both for $q_1$ and $q_2$ because of insufficient storage size, and 
2) $q_1$'s frequency is larger than $q_2$'s at time $t$ and they are reversed at time $t+1$; $q_1$'s frequency becomes smaller than $q_2$'s.
In this case, a join plan is chosen for $q_2$ at time $t$ and it is switched to a MV plan at time $t+1$ due to the query frequency change.
Such query plan changes reduce the workload execution cost at every time step, however they require the additional cost of database migrations.
Therefore, we need to choose an optimized time-series schema by considering the trade-off between workload execution cost and migration cost.
% 頻繁にマイグレーションを実行するとマイグレーションコストが増加するため，ワークロードのコストとマイグレーションのコストのトレードオフを踏まえたスキーマ設計が重要である．
