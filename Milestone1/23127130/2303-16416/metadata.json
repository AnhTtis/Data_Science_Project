{
    "arxiv_id": "2303.16416",
    "paper_title": "Zero-shot Clinical Entity Recognition using ChatGPT",
    "authors": [
        "Yan Hu",
        "Iqra Ameer",
        "Xu Zuo",
        "Xueqing Peng",
        "Yujia Zhou",
        "Zehan Li",
        "Yiming Li",
        "Jianfu Li",
        "Xiaoqian Jiang",
        "Hua Xu"
    ],
    "submission_date": "2023-03-29",
    "revised_dates": [
        "2023-05-17"
    ],
    "latest_version": 2,
    "categories": [
        "cs.CL"
    ],
    "abstract": "In this study, we investigated the potential of ChatGPT, a large language model developed by OpenAI, for the clinical named entity recognition task defined in the 2010 i2b2 challenge, in a zero-shot setting with two different prompt strategies. We compared its performance with GPT-3 in a similar zero-shot setting, as well as a fine-tuned BioClinicalBERT model using a set of synthetic clinical notes from MTSamples. Our findings revealed that ChatGPT outperformed GPT-3 in the zero-shot setting, with F1 scores of 0.418 (vs.0.250) and 0.620 (vs. 0.480) for exact- and relaxed-matching, respectively. Moreover, prompts affected ChatGPT's performance greatly, with relaxed-matching F1 scores of 0.628 vs.0.541 for two different prompt strategies. Although ChatGPT's performance was still lower than that of the supervised BioClinicalBERT model (i.e., relaxed-matching F1 scores of 0.620 vs. 0.888), our study demonstrates the great potential of ChatGPT for clinical NER tasks in a zero-shot setting, which is much more appealing as it does not require any annotation.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16416v1",
        "http://arxiv.org/pdf/2303.16416v2"
    ],
    "publication_venue": "7 pages, 5 tables, 1 figure"
}