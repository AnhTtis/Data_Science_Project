\section{Evaluation}
\label{sec:evaluation}

% Q: How to evaluate clustering?

% \subsection{Unsupervised Evaluation}

% Evaluating unsupervised algorithms is challenging. Most of the traditional metrics, such as intra- and inter- SSE, applied in supervised learning do not make sense when the data does not have labels. Thus, we need alternative metrics to discern model qualities. When looking into clustering results, we can take some factors that do not rely on labels into account, as described in~\cite{Palacio-Nino2019EvaluationAlgorithms}, such as: the clustering tendency (as opposed to a random structure), the number of clusters, use internal information to assess the quality of the clustering, and comparing clustering solutions among themselves.\hl{In our case, we aim to find anomaly data points as mentioned in our problem definition. These standard evaluation methods can only provide us  how compact a cluster is and how distinct a cluster can be. Hence we eventually utilize the straightforward way by defining the outliers as anomaly data points and count them.}

% Measures of cohesion and separation of clusters are used to assess how close the nodes of one cluster are to each other, and how far they are to nodes in other clusters respectively. Generally, a clustering is considered good when it has a high separation between clusters and a high cohesion within clusters.

% These metrics give us a good sense of how our clustering performs, but there is still one question yet to be answered: how do we answer the meaning of these clusters? Do they correspond to the pattern that we would like to detect, separating "anomalous" from "normal" behavior? In order to answer that, we need to obtain a dataset with labels and perform a supervised evaluation.

\subsection{Experiments Setup}

In the case that we find a properly labeled dataset to evaluate TET, we can use more commonly found metrics to compare our results in an anomaly-detection problem. We probably will not use accuracy of classification directly, however. That is because anomaly datasets in general are heavily skewed towards the normal behavior, thus, any classifier that labeled them all as normal would achieve an accuracy close to 100\%. Thus, we focus our report in the F1-score, precision, and recall achieved in the baseline executions and compare them against Egonet. The experiments shown in Table 1 shown here were carried out on the synthetic dataset described in \autoref{sec:synth-dataset}.

\subsection{Baselines}
In order to assess the quality of our method, we will compare against competing methods and apply the same unsupervised learning methods later on.% Potential dynamic anomaly detection methods to test against include:
% \begin{itemize}
%     \item \textbf{Count-Min Sketch Based Outlier Detection\cite{ranshous2016scalable}}: Utilizes Count-Min sketch to approximate properties to generate outlier detection model based on global and local structure of a stream. 
%     \item \textbf{NetWalk\cite{yu2018netwalk}}: Finds anomalies with a dynamic clustering model. 
%     \item \textbf{Outlier Detection in Graph Streams\cite{aggarwal2011outlier}}: Uses a structural connectivity model to define outliers in graph streams. 
% \end{itemize}

% Additionally, we could test against different network embedding methods such as: 
\begin{itemize}

    \item[$\cdot$] \textbf{Spectral Clustering~\cite{liu2013spectral}}: is closely related to nonlinear dimension reduction, and dimension reduction techniques such as locally-linear embedding can be used to reduce errors from noise. By calculating the Laplacian of the graph and obtaining the first eigenvectors and corresponding eigenvalues of the Laplacian, this method output embedding nodes. Spectral Clustering has no assumption on the shapes of the clusters and can thus model complex scenarios. 
    
    \item[$\cdot$] \textbf{DeepWalk~\cite{perozzi2014deepwalk}}: generalizes on language modeling from sequences of words to graphs by using local information from sequences of vertices(Random Walk and SkipGram) in the graph and learning representations by treating them equivalently to sentences. Here the input is an edge list file and the output of DeepWalk is 64 dimensions by default. In order to visualize it, the output is manually set to 2 dimensions. 
    % The embedded node graph with our synthetic dataset is shown in \hl{fig ???}, which will later be fed forward to unsupervised machine learning model-DBSCAN for later clustering and display our outliers as our anomaly data points.
    
    \item[$\cdot$] \textbf{Node2Vec~\cite{grover2016node2vec}}: is a useful method for extracting the continuous-feature representations for nodes in graph networks. By using a biased random walk procedure, Node2Vec maps of nodes to a lower-dimensional space of features while preserving their locality.
    % \item \textbf{Structural Deep Network Embedding (SDNE)\cite{wang2016structural}}: Semi-supervised deep model with layers of non-linear functions which uses first and second order proximity to capture the global network structure. 
    
\end{itemize}

The baselines mentioned above do not take dynamic graphs into account without a remodeling of the input data and multiple executions, making it a challenging task to represent the evolution of the graph over time. In our case temporal graphs into account, which significantly lowers to their implementation complexity. All of the output of embedding methods (including the output of Egonet) are later fed forward to the same pipeline of DBSCAN for outlier detection. The results are displayed in Figures 1, 2, and 3. The images also point the frequency distribution among the classes found by DBSCAN. As opposed to k-means, DBSCAN attempts to find the optimal number of classes, so the number of clusters is highly dependent on the embedding dataset.

\begin{figure}[hb]
    % \label{fig:dw_dbscan}
    \centering
    \includegraphics[width=\linewidth]{figures/dw_dbscan.pdf}
    \caption{Results of the clustering after DeepWalk node embedding on the synthetically generated dataset.}
\end{figure}

\begin{figure}[hb]
    % \label{fig:n2v_dbscan}
    \centering
    \includegraphics[width=\linewidth]{figures/n2v_dbscan.pdf}
    \caption{Results of the clustering after Node2Vec node embedding on the synthetically generated dataset.}
\end{figure}

\begin{figure}[hb]
    % \label{fig:sc_dbscan}
    \centering
    \includegraphics[width=\linewidth]{figures/sc_dbscan.pdf}
    \caption{Results of the clustering after Spectral Clustering node embedding on the synthetically generated dataset.}
\end{figure}
