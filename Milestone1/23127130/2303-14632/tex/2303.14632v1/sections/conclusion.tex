\subsection{Future Work}
In addition to the clustering techniques mentioned above, the Extreme Value Machine (EVM) \cite{rudd2017extreme} could be used to classify extracted embeddings.  

The EVM is a scalable nonlinear classifier which supports open-set classification, where the models are assumed to have incomplete knowledge of their operating context and can reject inputs that are beyond the support of the training set. The EVM relies on a strong feature representation and every represented sample in the feature representation becomes a point. EVM utilizes bins which groups all the points in their feature representation by their correspondent label. These bins are utilized to create a 1 vs. rest EVM classifier for each known class or in our case each of the known clusters. The EVM generates a classifier where a Weibull distribution is fit on the data for each known class and is made to avoid the negative data points (unknown classes) or outliers for our application.  This is repeated for all the known classes/clusters.  When a coordinate point which is a sample encoded by its feature representation as a vector is provided to the EVM, the points are mapped to the feature space as a probability of belonging to a representative class, or if it falls below a threshold of inclusion, labeled as an outlier. 

The analysis of our approach for extracting embeddings and clustering with DBSCAN proved to be successful on the synthetically generated data, however, real world data may be more complex and difficult to detect outliers in. Thus, using an approach like the EVM and forming distributions that take into account the input space distance distributions may provide strong understanding of the nature of the data and prove to be an effective means of capturing anomalous nodes based off the embeddings. 

