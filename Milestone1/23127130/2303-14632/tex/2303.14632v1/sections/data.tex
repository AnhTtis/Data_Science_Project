\section{Data Sources}
\label{sec:data-sources}

We are focused on modeling behavior over time from graph-structured data, so we need datasets with the following attributes:
\begin{enumerate}
    \item Nodes with persistent IDs.
    \item Interactions (directed or undirected) between nodes.
    \item Timestamps for the interactions.
\end{enumerate}

\subsection{Available Datasets}\label{sec:datasets}
Although we initially wanted to tackle node classification problems using TET, we ran into problems finding datasets which had both timestamped edges and ground-truth labels for the nodes.
Most of the datasets with ground-truth we found had labels for the edges instead.
Therefore, we are considering unsupervised tasks like clustering for testing the quality of our node embeddings.
%\hl{The main issue for our method for classification is that we are looking for node's ground-truth. However, most of ground-truth in the temporal graph dataset we found are either related to activities, events, or edges instead of nodes. Hence we decided to perform unsupervised learning with clustering to detect anomaly behaviour.
We describe some of the datasets we found below.

% \subsubsection{\href{https://snap.stanford.edu/data/soc-sign-bitcoin-alpha.html}{For Reputation: Snap-Bitcoin OTC and Snap-Bitcoin Alpha}}
% These datasets record who-rate-whom-when bitcoin  transaction. The data format contains:
% \begin{itemize}
%     \item SOURCE: a node id of source
%     \item TARGET: a node id of target
%     \item RATING: a source node rates target node from -10 to +10
%     \item TIME: when this transaction happen
% \end{itemize}

% \subsubsection{\href{https://www.kaggle.com/ntnu-testimon/paysim1}{For Suspicion: Kaggle-Paysim synthetic dataset of mobile money transactions}}
% This dataset contains some key features that we can use:
% \begin{itemize}
%     \item NameOrg: customer that started the transaction
%     \item NameDest: customer that receive the transaction
%     \item Amount: the total amount of transaction
%     \item Step: when this transaction happen (each digit represents a hour)
% \end{itemize}

\subsubsection{Enron Emails\footnote{\texorpdfstring{\scriptsize\url{http://odds.cs.stonybrook.edu/enroninc-dataset/}}{hi}}}
The nodes of this dataset represent email addresses and directed edges depict sent/received relations. Enron email network dataset contains a total of 80, 884 nodes and 700 timestamp in total.
% \begin{itemize}
%     \item[$\cdot$] Source IP: a source node id of an user
%     \item[$\cdot$] Destination IP: a target node id of an user
%     \item[$\cdot$] timestamp: timestamp in dates
% \end{itemize}


\subsubsection{College Messages\footnote{\texorpdfstring{\scriptsize\url{https://snap.stanford.edu/data/CollegeMsg.html}}{hi}}}

This is a dataset containing private messages at an online social network at the University of California, Irvine. Here an edge (u, v, t) means that during time t, an user u sent a message to an user v.

% \begin{itemize}
%     \item[$\cdot$] SRC: a source node id of an user
%     \item[$\cdot$] TGT: a target node id of an user
%     \item[$\cdot$] UNIXTS: timestamp in seconds.
% \end{itemize}


\subsubsection{EU Emails\footnote{\texorpdfstring{\scriptsize\url{https://snap.stanford.edu/data/email-Eu-core-temporal.html}}{hi}}}

This dataset contains 986 nodes and 332,334 temporal edges, with the timestamp of 803 in total.
% truncated version of this dataset for first experiments
% \begin{itemize}
%     \item[$\cdot$] SRC: a source node id of an user
%     \item[$\cdot$] TGT: a target node id of an user
%     \item[$\cdot$] TS: timestamp in seconds(started from 0).
% \end{itemize}

% \subsection{Data Preprocessing}

% \hl{do we still need this section, since we are no longer using real-world data and the synthetic data doesn't require any preprocessing? same question about the previous section. it would make sense to keep these sections if we're still planning on including the real-world dataset results that we presented in class.} - dan

% Our model makes the assumption that the data is structured as a sequence of graphs $G_1, G_2, \dots G_T$ on a shared node set $V$,so that nodes' egonet subgraph transitions are well-defined and sufficiently nontrivial.
% However, the datasets described in Section~\ref{sec:datasets} represent temporal graphs as a continuous stream of timestamped interactions between nodes.

% The first step in processing these datasets is to discretize the time dimension using \emph{binning}.
% If the first timestamp in a given dataset is $t_0$, the last timestamp is $t_k$, and the range is given by $\Delta = t_k - t_0$, we divide the range $[t_0, t_k]$ into $T$ equally-sized chunks $[t_0, t_0+\Delta), [t_0+\Delta, t_0+2\Delta), \dots [t_k-\Delta, t_k]$ and distribute each edge into the appropriate bin according to its timestamp.
% Each bin then becomes one of the graphs in the sequence $G_1, G_2, \dots G_T$.

% After the temporal discretization is done, the final step in the preprocessing is to construct a shared node set for all of the graphs in the sequence.
% This is simply done by asserting that each graph's vertex set is the union of all of the vertex sets of all the graphs in the sequence.


\subsection{Synthetic Dataset}
\label{sec:synth-dataset}

In order to test our model's ability to properly distinguish between nodes with different temporal behavior in the embedding space, we need a dataset which:

\begin{enumerate}
    \item represents interactions between different objects,
    \item is temporal (i.e., interactions occur at known points in time, which may repeat),
    \item has ground truth labels on the \emph{nodes} indicating whether those nodes are anomalous or not.
\end{enumerate}

There are many public temporal graph datasets that immediately satisfy the first two requirements.

Among those, there are a few that also include some ground truth information regarding authentic/suspicious/anomalous edges in the graph.
However, since we are attempting to characterize \emph{nodes} as anomalous or not, edge-centric ground truth labels are unhelpful.
Since a dataset satisfying all three criteria is unavailable to us, we could go out into the world and collect, mine, or survey a sufficiently high-quality dataset on our own.

We elected to not pursue this idea not only because of time constraints, but also because building a real-world dataset satisfying those three criteria by hand would require a level of description, analysis, and methodological detail that might be more appropriate for its own paper.

Therefore, we elected to generate a synthetic temporal graph with ground truth node labels.

The data consists of a discrete sequence of five graphs $G_1, G_2, \dots G_5$ on a shared set of $500$ nodes $V$, representing five snapshots of interactions between the nodes in $V$.

The nodes are split between \emph{authentic} and \emph{anomalous} nodes, labels which persist through the different graphs in the sequence.
For each time $t \in {0, \dots 4}$ authentic nodes' edges are generated by an Erdos-Renyi random process \cite{erdos_random_1959};

specifically, between any two authentic nodes $u$ and $v$, an edge $e = \left\{u, v\right\}$ exists with probability $p \in [0, 1]$.
The anomalous nodes are connected together in the following way:
for $t \in \left\{0, 2, 4\right\}$, all of the anomalous nodes form the empty subgraph; for $t \in \left\{1, 3, 5\right\}$, the anomalous nodes form a clique.

%It is worth noting that there will never be an edge between an authentic and an anomalous node in this dataset.
%Although this might seem like a strong indicator for which nodes are anomalous, TET would not 

The free parameters for generating this dataset are the connection probability $p$ for the authentic nodes, the total number of nodes $n$, and the percentage of the total nodes that is designated as anomalous.
In the future, we can experiment with different ways of connecting the anomalous nodes together to create more-varied temporal patterns.
