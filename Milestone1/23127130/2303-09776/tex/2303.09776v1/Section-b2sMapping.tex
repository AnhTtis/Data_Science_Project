Once we have geometrically optimized a constellation $(\ket{s_i})_{i=1}^M$ to reduce %minimize
 the symbol errors, we seek to minimize bit errors by optimizing the bit-to-symbol mapping. In commonly-used modulation formats, such as $M$-PAM, $M$-PSK,  $M$-QAM on a square lattice, and its generalization to cubic lattices of any dimension, this task is achieved via \emph{Gray coding} \cite{AgrellGrayCoding}. Unfortunately, in  general, no such labeling readily exists for the MVM format. 


Given a bit encoding $({\bf b}_m)_{m=1}^M$, where the length of each bit sequence ${\bf b}_m$ is $k=\log_2(M)$, we use the union bound \eqref{eq:UBgeneralForm} %Corollary \ref{cor:UBsumExact}
 to find that the \emph{average bit error probability} ${P}_{e|b}$  at a symbol SNR $\gamma_s$  is bounded by
\begin{equation}
    \label{eq:UBbitErrorProb}
    {P}_{e|b} \leq \frac{1}{kM} \sum_{m=1}^M \sum_{m'\neq m} \Pbin h_{mm'},  
\end{equation}
where $h_{mm'}$ denotes the \emph{Hamming distance}\nomenclature[$hmm$]{$h_{mm'}$}{Hamming distance between bit sequences ${\bf b}_m$ and ${\bf b}_{m'}$} between ${\bf b}_m$ and ${\bf b}_{m'}$. This is based on the observation that the expected number of bit errors corresponding to mistakenly receiving $\ket{s_{m'} }$ when $\ket{s_m}$ was transmitted is $\Pbin h_{mm'}$. Using the right side of  \eqref{eq:UBbitErrorProb}, we arrive at an objective function $\xi$ for evaluating various bit encodings:
\begin{align}
    \label{eq:SimulatedAnnealObjective}
    \xi &= \xi\left( (\ket{s_m} )_{m=1}^M, ({\bf b}_m)_{m=1}^M, \nvar \right) \notag \\
    &= \frac{1}{kM}  \sum_{m=1}^M \sum_{m'\neq m} \Pbin  h_{mm'}.
\end{align}
\nomenclature[$xi$]{$\xi$}{Simulated annealing objective function}

% Letting $P(\ket{s_j} \mid \ket{s_i})$ denote the conditional probability of coherently detecting symbol $j$ when $i$ was transmitted, we asymptotically expand the Union Bound for large $d_{ij}$ to find that (see Appendix \ref{app:tnl})
% \begin{equation}
%     P(\ket{s_i} \mid \ket{s_j}) \propto d_{ij}^{-1} \exp\left( - \frac{d_{ij}^2}{8 \sigma^2}\right),
% \end{equation}
% in the presence of Gaussian noise with variance $\sigma^2$. Letting $b_i$ denote the bit sequence assigned to $\ket{s_i}$ and using $h_{ij}$ for the \emph{Hamming distance} between $b_i$ and $b_j$, we arrive at the objective function
% \begin{align*}
%     \xi &= \xi \left( (\ket{s_i})_{i=1}^M, (b_i)_{i=1}^M, \sigma \right)
%     := \sum_{i=1}^M \sum_{j\neq i}^M \frac{h_{ij}}{d_{ij}} \exp\left( - \frac{d_{ij}^2}{8 \sigma^2} \right). \addtag
% \end{align*}
Finding a bit encoding $({\bf b}_m)_{m=1}^M$ that minimizes $\xi$ at a symbol SNR $\gamma_s$ serves as a proxy for minimizing bit errors for a given constellation and, thus, finding the optimal bit-to-symbol mapping. With $M!$ possible encodings, the sheer number of combinations prohibits brute-force solutions for all but the smallest constellations. This optimization problem can be viewed as a type of \emph{Quadratic Assignment Problem} \cite{Garey1979}, i.e., the optimal assignment of $\{1, 2, \dots, M\}$ (in binary) to $(\ket{s_m})_{m=1}^M$ with pairwise distances given by $\frac{1}{kM}\Pbin$ and pairwise weights given by Hamming distances $h_{mm'}$. Quadratic Assignment Problems are known to be NP-hard \cite{SahniPcomplete} and encompass the classical \emph{Traveling Salesman Problem} as a special case. 

Given these rapidly scaling combinatorics, we turn to numerical minimization. In particular, \emph{simulated annealing} has a long history of use for combinatorial optimization problems \cite{KirkpatrickSimulAnneal}, and lie within the broader class of \emph{Metropolis-Hastings algorithms}. Inspired by metallurgy, simulated annealing algorithms work by stochastically exploring the search space, helping prevent the algorithm from becoming entrapped near local minima. 

Our implementation begins with an initial bit-to-symbol mapping $({\bf b}_m)_{m=1}^M$ (either randomly selected or the current best known encoding) and a sequence of \emph{temperatures} $(T_n)$ per a selected \emph{cooling schedule} \cite{KirkpatrickSimulAnneal}.
In each iteration, a new candidate encoding $({\bf b}_m')_{m=1}^M$ is generated by randomly swapping the bit encodings for two symbols. We then compare $\xi \left( (b_m')_{m=1}^M \right)$ against $\xi\left( ({\bf b}_m)_{m=1}^M \right)$. If $\xi \left( ({\bf b}_m')_{m=1}^M \right) < \xi\left( ({\bf b}_m)_{m=1}^M \right)$, then $({\bf b}_m')_{m=1}^M$ is automatically accepted. Otherwise, $({\bf b}_m')_{m=1}^M$ is probabilistically accepted or rejected  by comparing $\exp\left( \left( \xi\left(({\bf b}_m)_{m=1}^M \right) - \xi\left( ({\bf b}_m')_{m=1}^M \right) \right)/T_n \right)$ against a uniformly randomly generated value in $[0,1]$. The initial high temperatures values give a higher probability of accepting a candidate encoding $({\bf b}_m')_{m=1}^M$ in order to explore the search space, while final low temperatures exploit local optimizations.

Implementing a simulated annealing optimization algorithm inherently requires significant tuning of parameters. Choices such as initial and final temperatures, cooling schedule, and number of iterations must all be carefully selected for the specific problem in order to properly balance exploration versus exploitation. After an investigation of  various cooling schedules, we established that a classic exponential cooling schedule of $T_n = \alpha^n T_0$ was well-suited to this problem. 
With further experimentation, we found that setting the initial temperature $T_0$ as the standard deviation of $\xi$ for a random sample of bit encodings gave acceptable performance across a wide range of constellation sizes $M$, without the need for extensively tuning this parameter. 

We remark that an efficient implementation will leverage that the constellation $(\ket{s_m})_{m=1}^M$ is static and hence the $\Pbin$ terms in \eqref{eq:SimulatedAnnealObjective} need only be computed once at the outset and then stored for all future evaluations of $\xi$.

Finally, we note that $h_{mm'}$ is trivially bounded by $k$ for all $m \neq m'$. Hence the performance increase that can possibly be achieved by optimizing the bit-to-symbol mapping $({\bf b}_m)_{m=1}^M$ is limited by a factor of $k$ (cf. Fig. \ref{fig:BERvRandom}), in contrast to the several orders of magnitude of performance that can be obtained by geometrically optimizing the constellation $(\ket{s_m})_{m=1}^M$ (cf. Fig. \ref{fig:potential comparison}). Therefore, the allocation of computation time when generating an $(N,M)$-MVM format should place greater emphasis on geometric optimization, while not completely neglecting to optimize the bit-to-symbol mapping.
