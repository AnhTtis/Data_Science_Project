% \begin{table*}[ht]
%  \footnotesize \centering\addtolength{\tabcolsep}{-1pt}
 
%  \begin{tabularx}{1.0\textwidth}{ l |cc|cc|cc|cc|cc }
% \toprule
% \multirow{4}{*}{Method} & \multicolumn{2}{c|}{\multirow{2.8}{*}{Resolution}}  & \multicolumn{4}{c|}{IoU = 0.5} & \multicolumn{4}{c}{IoU = 0.7} \\ 
% \cmidrule(r){4-11}
% &  &   & \multicolumn{2}{c|}{Car} & \multicolumn{2}{c|}{Big Vehicle} & \multicolumn{2}{c|}{Car} & \multicolumn{2}{c}{Big Vehicle} \\ 
% \cmidrule(r){2-11}
% & Input &  BEV & AP$_{\text{3D}{|\text{R40}}}$ & Rope$_\text{score}$ & AP$_{\text{3D}{|\text{R40}}}$ & Rope$_\text{score}$  & AP$_{\text{3D}{|\text{R40}}}$ & Rope$_\text{score}$ & AP$_{\text{3D}{|\text{R40}}}$ & Rope$_\text{score}$\\ 

% \midrule

% M3D-RPN-R34~\cite{brazil2019m3d} & -&- 
% &54.19 & 62.65	&33.05 &  44.94 &16.75 & 32.90 &6.86  &  24.19 \\

% Kinematic3D-Dense121~\cite{brazil2020kinematic} & - & -  &50.57  & 58.86&	37.60&  48.08 &17.74  & 32.9 &   6.10&   22.88\\

% MonoDLE-DLA34~\cite{ma2021delving} & -&- 
%  & 51.70 & 60.36 & 40.34 & 50.07  & 13.58 & 29.46 &9.63 &25.80\\


% MonoFlex-DLA34~\cite{zhang2021objects} & -& 	- & 60.33 & 66.86&	37.33 &47.96   & 33.78 & 46.12 &  10.08 &26.16\\

% BEVFormer-R101~\cite{li2022bevformer} &	864x1536&	150x150	&50.62&	58.78&	34.58&	45.16&	24.64&	38.71	&10.05&	25.56\\

% BEVDepth-R50~\cite{li2022bevdepth}&	864x1536&	256x256	&69.63&	74.70&	45.02&	54.64&	42.56&	53.05	&21.47	&35.82\\

% \midrule
% BEVHeight-R50(Ours)&	864x1536&	256x256	& 74.60& 78.72& 48.93& 57.70& 45.73& 55.62& 23.07& 37.04 \\							
% \bottomrule

% \end{tabularx}

% % \caption{Overall performance of the monocular 3D object detection approaches on the Rope3D Dataset with IoU = 0.5 and 0.7. $(G)$ denotes adapting the ground plane.}
% \caption{\textbf{Comparison on the Rope3D val set under the Homologous setting.}}
% \label{tab_performance_overall}
% \end{table*}

\begin{table}[t]
\footnotesize
  \centering\addtolength{\tabcolsep}{-3.8pt}
\caption{\textbf{Results on the Rope3D val set.} Here, we follow~\cite{ye2022rope3d} to report the results on vehicles. Our method on average surpasses the state-of-the-art method over a margin of 3\% in both average precision and $Rope_{score}$ metric.
% \Tao{more caption}
}
\vspace{-0.2cm}
 \begin{tabularx}{1.\linewidth}{ l |cc|cc|cc|cc }
\toprule
\multirow{4}{*}{Method}   & \multicolumn{4}{c|}{IoU = 0.5} & \multicolumn{4}{c}{IoU = 0.7} \\ 
\cmidrule(r){2-9}
  & \multicolumn{2}{c|}{Car} & \multicolumn{2}{c|}{Big Vehicle} & \multicolumn{2}{c|}{Car} & \multicolumn{2}{c}{Big Vehicle} \\ 
\cmidrule(r){2-9}
&AP & Rope &
AP & Rope &
AP & Rope &
AP & Rope \\
% &AP$_{\text{3D}{|\text{R40}}}$ & Rope$_\text{score}$ & AP$_{\text{3D}{|\text{R40}}}$ & Rope$_\text{score}$  & AP$_{\text{3D}{|\text{R40}}}$ & Rope$_\text{score}$ & AP$_{\text{3D}{|\text{R40}}}$ & Rope$_\text{score}$\\ 

\midrule

M3D-RPN~\cite{brazil2019m3d} 
&54.19 & 62.65	&33.05 &  44.94 &16.75 & 32.90 &6.86  &  24.19 \\

Kinematic3D~\cite{brazil2020kinematic}  &50.57  & 58.86&	37.60&  48.08 &17.74  & 32.9 &   6.10&   22.88\\

MonoDLE~\cite{ma2021delving} 
 & 51.70 & 60.36 & 40.34 & 50.07  & 13.58 & 29.46 &9.63 &25.80\\


MonoFlex~\cite{zhang2021objects} & 60.33 & 66.86&	37.33 &47.96   & 33.78 & 46.12 &  10.08 &26.16\\

BEVFormer~\cite{li2022bevformer}	&50.62&	58.78&	34.58&	45.16&	24.64&	38.71	&10.05&	25.56\\

BEVDepth~\cite{li2022bevdepth}	&69.63&	74.70&	45.02&	54.64&	42.56&	53.05	&21.47	&35.82\\

\midrule
 \rowcolor{cyan!30} BEVHeight & \textbf{74.60}& \textbf{78.72}& \textbf{48.93}& \textbf{57.70}& \textbf{45.73}& \textbf{55.62}& \textbf{23.07}& \textbf{37.04} \\							
\bottomrule
\multicolumn{9}{l}{\footnotesize{AP and Rope denote AP$_{\text{3D}{|\text{R40}}}$ and Rope$_\text{score}$ respectively.}}
\end{tabularx}
% }
% \caption{Overall performance of the monocular 3D object detection approaches on the Rope3D Dataset with IoU = 0.5 and 0.7. $(G)$ denotes adapting the ground plane.}
 \vspace{-0.50cm}
\label{tab_performance_overall}
\end{table}



