\documentclass[preprint,11pt]{article}
\makeatletter
\def\blfootnote{\gdef\@thefnmark{}\@footnotetext}
\makeatother
\usepackage{fullpage}
\ifdefined\usebigfont
\renewcommand{\mddefault}{bx}
\usepackage{times}
\usepackage[fontsize=13pt]{scrextend}
\usepackage[left=1.56in,right=1.56in,top=1.74in,bottom=1.74in]{geometry}
\pagenumbering{gobble}
\else
\fi

%==========
\usepackage{amssymb,amsfonts,amsmath,amsthm,amscd,dsfont,mathrsfs}
\usepackage{graphicx,float,psfrag,epsfig,amssymb}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\definecolor{darkgreen}{rgb}{0.0,0,0.9}
\RequirePackage{algorithm}
\usepackage[pagebackref,letterpaper=true,colorlinks=true,pdfpagemode=none,citecolor=OliveGreen,linkcolor=BrickRed,urlcolor=BrickRed,pdfstartview=FitH]{hyperref}
\usepackage{wrapfig}
\usepackage{relsize}
\usepackage{color}
\usepackage{pict2e}
\usepackage[tight]{subfigure}
\usepackage{caption}
\usepackage{nameref}
\usepackage{makecell}
\usepackage[font={small}]{caption} 
\usepackage{float}
\usepackage{bbm}
\usepackage{tikz}
\usepackage{multirow}
\usepackage{adjustbox}
\usepackage{csvsimple,longtable,booktabs}
\usepackage{graphicx}
\usepackage{cases}
\usepackage{mathtools}
\usepackage{dcolumn,booktabs}
\newcolumntype{d}[1]{D{.}{.}{#1}}
\newcommand\mc[1]{\multicolumn{1}{c}{#1}}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{lscape}
\usepackage{gensymb}
\usepackage{natbib}



%%================  Algorithm Package
%
%%\usepackage{algorithm}

\let\chapter\section
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{accents}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage[noend]{algorithmic} 

\usepackage{graphicx}
\usepackage{comment}
\newcommand{\bigzero}{\mbox{\normalfont\Large\bfseries 0}}
\newcommand{\rvline}{\hspace*{-\arraycolsep}\vline\hspace*{-\arraycolsep}}

\newcommand\inner[2]{\langle #1, #2 \rangle}
\usepackage[english]{babel}
\newcommand{\ryan}[1]{\textcolor{blue}{~Ryan:~#1}}
\usepackage{comment}
\newcommand{\ty}[1]{\textcolor{blue}{~Tong:~#1}}
\newcommand{\sukim}[1]{\textcolor{blue}{~Sukim:~#1}}
\newcommand{\adel}[1]{\textcolor{red}{~Adel:~#1}}
\newcommand{\rb}[1]{\textcolor{blue}{~Rashmi:~#1}}
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%\newenvironment{policy}[1][htb]
%  {\renewcommand{\algorithmcfname}{Table}% Update algorithm name
%   \begin{algorithm}[#1]%
%  }{\end{algorithm}}
  
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage{bm}
\newcommand{\ex}{\mathbb{E}}
\newcommand{\thetawa}{\theta}
\newcommand{\Thetawa}{\Theta}
\newcommand{\thetaap}{\lambda}
\newcommand{\Thetaap}{\Lambda}
\newcommand{\pl}{\omega}
\newcommand{\KL}{{\sf KL}}
\newcommand*\samethanks[1][\value{footnote}]{\footnotemark[#1]}

%====================== Title and authors ==========================
\title{Structured Dynamic Pricing: Optimal Regret in a Global Shrinkage Model}

\author{%
Rashmi Ranjan Bhuyan\thanks{Data Science and Operations Department, Marshall School of Business, University of Southern California} 
\quad\,
Adel Javanmard\samethanks[1] 
\quad\,
Sungchul Kim\thanks{Adobe Research}\\
Gourab Mukherjee\samethanks[1] 
\quad\,
Ryan A. Rossi\samethanks[2]
\quad\,
Tong Yu\samethanks[2]
\quad\,
Handong Zhao\samethanks[2]
}

\begin{document}

\maketitle


\blfootnote{A. Javanmard is partially supported by the Sloan Research Fellowship in mathematics, Adobe Data Science
Faculty Research Awards and the NSF CAREER Award DMS-1844481. G. Mukherjee is partially supported by an Adobe Data Science
Faculty Research Award.}

\begin{abstract}
 We consider dynamic pricing strategies in a streamed longitudinal data set-up where the objective is to maximize, over time, the cumulative profit across a large number of customer segments. We consider a dynamic probit model with the consumers' preferences as well as price sensitivity varying over time. Building on the well-known finding that consumers sharing similar characteristics act in similar ways, we consider a global shrinkage structure, which assumes that the consumers' preferences across the different segments can be well approximated by a spatial autoregressive (SAR) model. 
In such a streamed longitudinal set-up, we measure the performance of a dynamic pricing policy via regret, which is the expected revenue loss compared to a clairvoyant that knows the sequence of model parameters in advance. We propose a pricing policy based on penalized stochastic gradient descent (PSGD) and explicitly characterize its regret as functions of time, the temporal variability
in the model parameters as well as the strength of the auto-correlation network structure spanning the varied customer segments. Our regret analysis results not only demonstrate asymptotic optimality of the proposed policy but also show that for policy planning it is essential to incorporate available structural information as policies based on unshrunken models are highly sub-optimal in the aforementioned set-up.  
\end{abstract}
\section{Introduction}\label{sec:intro}
% \ty{We may discuss the limitations of previous works, which motivate this work in the early part of the introduction?}
% \sukim{I agree with Tong that motivation would be a good start for both the abstract and introduction. In addition, it seems that the introduction is too long. Would it be possible to split it into introduction and related work? You can refer to Adel's previous papers, which have a nice structure}.
Due to the ubiquitous reach of digital marketing, dynamic pricing settings are extensively studied by firms that sell a significant fraction of their inventories over online marketplaces and through digital advertisements (see \citealp{cohen2016feature,keskin2016chasing,ban2017personalized,bimpikis2019spatial,javanmard2017perishability,leme2018contextual,javanmard2019dynamic} and the references therein). As such it is a vibrant topic of research in online machine-learning \citep{zhou2019learning,cesa2015regret}, operations research \citep{golrezaei2017dynamic,cheung2017dynamic}, information \citep{cui2021informational}, marketing \citep{schwartz2017customer,choi2020online} and management sciences \citep{farias2010dynamic,broder2012dynamic,den2013simultaneously}. For fuller references see Sec~1.3.  

In this work, we study the problem of a firm selling a product to customers who arrive over time. The firm has the opportunity to set different prices not only over time $t$ but also for different customer segments $l=1,\ldots,L$. We consider setting the prices across these customer segments in a dynamic manner such that the expected cumulative revenue, aggregated over the customer segments as well as time is maximized. As a motivational example, consider the digital marketing problem \citep{liu2019decade} where an advertisement of the product priced at $p_{lt}$ is shown to $n_{lt}$ 
% \adel{or $n_{lt}$?}\rb{The citation is just to talk about the digital marketing problem. It doesn't have any specific model/pricing for that matter. Changed to $n_{lt}$.} 
customers in segment $l$ at time $t$. Let $y_{ltk}, k=1,\ldots,n_l$ denote the binary variables corresponding to conversion based on the advertisement, i.e.,  $y_{ltk}=1$ if the $k$th advertisement in the $l$th segment at time $t$ led to a purchase, and $y_{ltk}=0$ otherwise. Often in these problems, the firm also has the opportunity to access other covariates $\bm{x}_{lt}$ such as demographic information for the customer segment $l$ at time $t$. 

As time $t$ progresses, the goal is to explore and set prices $p_{lt}$ optimally based on the current covariates $x_{lt}$ as well as on the previous customer responses $\{y_{lsk}:1\leq s < t\}$ and their associated prices and covariate information. The goal is to optimize the agglomerative revenue
\begin{align}\label{eq.1}
\sum_{t=1}^T\sum_{l=1}^L y_{lt}\, p_{lt} \text{ where, } y_{lt}=\sum_{k=1}^{n_l}y_{ltk}.
\end{align}

% Nedelec, T., El Karoui, N., and Perchet, V. Learning to bid in revenue-maximizing auctions. In International Conference on Machine Learning, pp. 4781â€“4789, 2019.

%\sukim{I wonder if we could put the summary of our contributions here (with a brief explanation of the additive model if needed) and move the section 1.1 and 1.2 to the next section.}


\subsection{Streamed Longitudinal Probit Set-up}
 Demand heterogeneity \citep{bimpikis2019spatial,chintagunta2002market} is traditionally tackled by segmenting consumers who have similar purchasing propensity as well as similar responses to price changes. Though truly homogeneous segments of consumers do not exist, the approximation provides a reasonable interface to design differential pricing strategies that optimally target each customer segments. Modern online trading platforms, marketplaces and lead generation systems, facilitate implementing price differential strategies across a wide range of segments. Often advertisers have access to the geographical location of the consumer and these segments based on zip-codes of the consumers \citep{train2009discrete}. Another popular choice is segmenting customers based on the different marketing channels by which they were approached \citep{berman2018planning}.   
In accordance with these modern applications, we consider the number of segments $L$ to be large. In the existing literature \citep{javanmard2017perishability}, the overall revenue in \eqref{eq.1} is optimized for probability models based on rational choice theory, which assumes that consumers are rational and make choices that maximize their utility.

% \ty{Might it be good to provide some rationale about the additive model? e.g., following some previous papers} 
Let the utility function $U_{ltk}$ for the $k$th customer in the $l$th segment at time $t$ be given by the following additive model:   
\begin{align}\label{eq:2}
U_{ltk}=\alpha_{lt}+\beta_{t}\,p_{lt}+\bm{x}_{lt}' \bm{\mu}_{t} + \sigma Z_{ltk}
\end{align}
where $k=1,\ldots,n_{lt}$; $\alpha$s 
% \ty{might be a bit more specific? e.g.,$\alpha_{lt}$} 
are the preferences of the customers that vary across both time and segments; $\beta$s are the price-sensitivities of the customer. $\bm{\mu}$s are coefficients corresponding to the non-priced covariates and vary over time but invariant across segments. $Z$s are independent and identically distributed from a noise distribution that is symmetric around its mean $0$ and has variance $1$. Based on rational choice theory, if $U_{ltk}>0$ then a sale occurs, i.e., $Y_{ltk}=1$; else, $Y_{ltk}=0$. Let $Y_{lt}=\sum_{k=1}^{n_l}Y_{ltk}$ be the count of sales for segment $l$ at time $t$. Then,
$$Y_{lt}\sim \text{Binomial}(n_{lt},q_{lt})\,,$$
% \text{where, } \ty{remove `,'?}
where $q_{lt}=F(\sigma^{-1}(\alpha_{lt}+\beta_{t} p_{lt}+\bm{x}_{lt}' \bm{\mu}_{t}))$ and  
$F$ is the cumulative distribution function of the noise. Note, that $q_{lt}$ is only a function of the model parameters but also depends on the price. 

Throughout, we use capital letters for random variables, small letters for the values a random variable takes, and boldface letters for vectors and matrices.

The joint log-likelihood across all segments at time $t$ is given by 
% \adel{Let's keep }\rb{Made the required changes. Should I mention it somewhere that this is the norm we are following?}
\begin{align}\label{eq:2.1}
\ell_t(\bm{\thetaap})=\sum_{l=1}^L y_{lt} \log q_{lt} + (n_{lt}-y_{lt})\log (1-q_{lt}),
\end{align}
where $\bm{\thetaap}=\{\bm{\thetaap}_t:=(\bm{\alpha}_t,\beta_t,\bm{\mu}_t): t=1,\ldots,T\}$ and $\bm{\alpha}_t=(\alpha_{1t},\ldots,\alpha_{Lt})$. 
The expected revenue from segment $l$ subjected to price $p_{lt}$ at time $t$ is,
\begin{align*}
    \text{Rev}(\bm{\thetaap},l,t,p_{lt})&= p_{lt}\,\ex_{\bm{\thetaap}}(Y_{lt}) = n_{lt}\, p_{lt}\, q_{lt}\\
    &=n_{lt}p_{lt}F\big(\sigma^{-1}(\bm{\alpha}_{lt}+\beta_{t} p_{lt}+\bm{x}_{lt}'\bm{\mu}_{t})\big),
\end{align*}
and the goal is to maximize the cumulative revenue
$$\text{Rev}(\bm{\thetaap},\bm{p})=\sum_{l=1}^L\sum_{t=1}^T\text{Rev}(\bm{\thetaap},l,t,p_{lt})$$
over the prices $\bm{p}=\{p_{lt}: 1\leq l \leq L, 1\leq t \leq T\}$ that the firm can set. 
Conditioned on the parameters $\bm{\thetaap}$, maximizing $\text{Rev}(\bm{\thetaap},\bm{p})$ decouples into separate maximization of the revenue of each segment at each time point. The first-order condition for optimal price $p_{lt}^*$ conditional on the set of parameters is given by 
\begin{align}\label{eq:2.2}
   p_{lt}^*  = -\sigma \,\beta_{t}^{-1} \cdot \frac{F(\sigma^{-1}(\alpha_{lt}+{\beta}_{t}\,p_{lt}^*+\bm{x}_{lt}' \bm{\mu}_{t}))}{ f(\sigma^{-1}(\alpha_{lt}+{\beta}_{t}\,p_{lt}^*+\bm{x}_{lt}' \bm{\mu}_{t}))}~.
\end{align}
As $p_{lt}^*$ depends on the unknown model parameters $\bm{\thetaap}_t$, we call this the oracle price and $\text{Rev}(\bm{\thetaap},\bm{p}^*)$ imposes the highest theoretically achievable upper bound on the revenue. For any other pricing policy $\bm{p}$ we define its regret over the oracle strategy as: 
$$\mathcal{R}(\bm{\thetaap},\bm{p}) = \sum_{l=1}^L\sum_{t=1}^T \mathcal{R}_{lt}(\bm{\thetaap},\bm{p}), \text{ where }$$
$$\mathcal{R}_{lt}(\bm{\thetaap},\bm{p})=\text{Rev}(\bm{\thetaap},l,t,p^*_{lt})-\text{Rev}(\bm{\thetaap},l,t,\hat p_{lt}).$$

\subsection{SAR based global Shrinkage Structures}
We impose the following regularity condition on the temporal changes in the price sensitivity and the covariate effects: 
\begin{align}\label{eq:3}
\sum_{t=1}^{T-1}|\beta_{t+1}-\beta_t|\leq C_\beta^* \text{ and } \sum_{t=1}^{T-1}\|\bm{\mu}_{t+1}-\bm{\mu}_t\|_2\leq C_\mu^*,
\end{align}
where $C_\beta^*$ and $C_\mu^*$ are constants.  
Unlike the price sensitivity, the preference coefficients $\bm{\alpha}_t$ however greatly depends on the state of the current inventory and can highly fluctuate over time. However, it is well known that people who are close to each other in some networks often reflect highly corrected preferences. Spatial models provide a natural way to model this correlation between different units of analysis based on their contiguity in a network \citep{banerjee2014hierarchical,gelfand2010handbook,lesage2004family}.
Geographic closeness is a proxy for many socio-demographic variables like income, education, wealth and property values, which are also related to consumer purchase behavior, and has been the primary 
focus of a large number of existing pricing models \citep{yang2003modeling,jank2005understanding,bimpikis2019spatial}. Networks based on non-geographic 
metrics can also capture preference similarities among customers \citep{karmakar2021}. Consider the following \textit{Spatially Autoregressive} (SAR) structure (see ch. 6 of \citealp{anselin2013spatial} and ch. 2 of \citealp{banerjee2014hierarchical}) on the $\alpha_{lt}$:
\begin{align}\label{eq:4}
 \alpha_{lt}= \rho_t \sum_{j=1}^L w_{lj} \alpha_{jt} + \tau \epsilon_{lt},
 \end{align}
where $w_{lj}\geq 0$, $\epsilon_{lt}$ are i.i.d $N(0,1)$ and $\tau >0$. In its most basic form, \eqref{eq:4} imposes a global hierarchical structure with the auto-correlation parameter $\rho_t$ regulating the level of global spillovers (and hence connectedness) among the units. Relation \eqref{eq:4} implies having the following hierarchical prior on the preference parameters: 
\begin{align}\label{eq:5}
\bm{\alpha}_t\sim N_L(\bm{0},\,\tau^2\, (\bm I-\rho_t \bm W)^{-2})\,.
\end{align}


Consider the network structure and hence the associated contiguity matrix $\bm W$ to be invariant over time. The autocorrelation parameter $\rho_t$ can vary over time but not wildly and satisfies the regularity condition 
\begin{align}\label{eq:6}
\sum_{t=1}^{T-1}|\rho_{t+1}-\rho_t|\leq C_\rho^*, 
\end{align}
where $C_\rho^*$ is a constant. Let $\bm{\lambda}_{\alpha}=\{\bm{\alpha}_t: 1\leq t \leq T\}$, $\bm{\rho}=\{\rho_t: 1\leq t \leq T\}$ and $\bm{\thetawa}=\bm{\rho}\cup\bm{\thetaap}\setminus\bm{\lambda}_{\alpha}$. Then, the  \textit{Bayes regret} of any pricing policy ${\bm p}$ is given by:
\begin{align}\label{eq:7}
\mathcal{B}(\bm{\thetawa},\bm{p})=\ex_{\bm{\lambda}_{\alpha}}\{\mathcal{R}(\bm{\thetaap},\bm{p})\},
\end{align}
where the expectation is over the distribution of $\alpha_t$ governed by \eqref{eq:5}. Let $\Theta$ be a set of parameter $\bm{\thetawa}$ satisfying \eqref{eq:3} and \eqref{eq:6}. For this set of parameters, we consider developing dynamic pricing strategies $\bm{p}$ that minimize the Bayes regret in \eqref{eq:7}.  

\newcommand{\bigo}{\mathcal{O}}

% \subsection{Related Work and Our Contributions}
\subsection{Our Contributions and Related Work}
% \ty{Do we propose a novel problem setting? If so, we may also claim the problem formulation contribution?}
We develop a Projected Stochastic Gradient Descent (PSGD) algorithm based on the logarithm of the marginal likelihood $\ell_t(\bm{\thetawa})=\log\{\ex_{\bm{\theta}_\alpha}\{\exp \ell_t(\bm{\thetaap})\}\}$ which is the convolution of the likelihood in \eqref{eq:2.1} with the prior in \eqref{eq:5}. We show that the proposed algorithm controls the Bayes regret at the order of $\bigo(\sqrt{T})$. We also show that for any data-driven pricing strategy the Bayes regret can not be of the lower order of $\bigo(\sqrt{T})$. Thus, as $T \to \infty$, the proposed algorithm is asymptotically rate-optimal. Our main result, Theorem~\ref{thm.1} is provided in Section 3. 

An important attribute of Theorem~\ref{thm.1} is that, we provide an explicit characterization of the Bayes regret of the proposed PSGD algorithm in terms of not only time $T$ but also as functions of the model parameters and the underlying heterogeneity (difference in the $n_{lt}$) in the data.  We show how the regret of the proposed algorithm depends on temporal variability in the model parameters as well as on the strength of correlation among the segments. Our upper-bound on the regret of the prescribed method (see~\eqref{eq:23}) depends on the spectral radius of the SAR structure in \eqref{eq:7}. It is sensitive to the magnitude of the autocorrelation parameter and greatly contracts as the correlation increases. 

In Corollary~\ref{cor.1}, we show that any unshrunken pricing policy that does not borrow strength across the customer segments is highly sub-optimal with respect to the proposed strategy. This is in accordance with classical statistical shrinkage theory results \citep{fourdrinier2018shrinkage} that are based on non-dynamic set-ups. To see the connections consider the penalized likelihood criterion: 
\begin{align}\label{eq:8} 
\text{PL}(\bm{\thetaap};\pl)=\sum_{t=1}^T \big\{\ell_t(\bm{\thetaap}) + \,\pl \|(\bm I-\rho_t \bm W)\bm{\alpha}_t\|_2^2 \,\big\}.
\end{align}
Running a vanilla stochastic gradient descent (with projection on $\Thetawa$) based on this penalized criteria is asymptotically equivalent to applying the proposed PSGD algorithm on the marginal log-likelihood. However, the same algorithm based on the unpenalized likelihood $\text{PL}(\bm{\thetaap};0)$ will have higher estimation error in the estimates of $\alpha_t$ when $L$ is large, which would in turn yield a significantly higher regret. In this context, it is crucial for any decent pricing policy to shrink its $\bm{\alpha}_t$ estimates towards the ellipsoids $\{\bm{\alpha}_t:\|(\bm I-\rho_t \bm W)\bm{\alpha}_t\|_2\leq s_{\omega}\}$. Figure~1 shows the schematic for this essential shrinkage effect on the $\bm{\alpha}_t$. The rigorous mathematical proof is provided in Corollary~\ref{cor.1}. 


Our research is connected to and builds on recent works in statistical shrinkage theory, online machine learning and econometrics theory on demand modeling. Next, we list the relevant literature in these research and also briefly mention our contributions.  
\begin{figure*}[t]
            \centering
            \includegraphics[width=0.8\textwidth]{RegularizationCurves.png}
            \vspace{-3em}
            \caption{Schematic on the working principle of proposed PSGD. The red path are the PSGD updates on the marginal likelihood with penalty.  
            %\ty{Some terminologies (e.g., regularization region, likelihood curves) only appear in this figure and not in the paper. The paper may add these concepts in the text, so it is easier to map the figure to the text? May provide more details about what is the red trajectory?}
            }
            \label{fig:pl}
        \end{figure*}
\begin{description}
\item [1) Dynamic Pricing with Online Learning] There exists a growing body of research on dynamic pricing with learning~\cite{den2015dynamic,farias2010dynamic, harrison2012bayesian, cesa2015regret, ferreira2016online, cheung2017dynamic}. The classical formulations of this problem~\cite{broder2012dynamic, den2013simultaneously,besbes2009dynamic} consider parametric model for the demand-price curve, which is unknown and the learner aims to learn, via exploration-exploitation of prices, while aiming to obtain a low regret in revenue. These works focus on non-contextual settings (no features for customers), and are relevant to applications where a seller is offering an unlimited supply of a single product to the market. Recently, there was significant interest in contextual-models, which use the customers and products attributes to model willingness-to-pay of the buyers for the products, potentially in a heterogeneous
way and offer personalized pricing~\cite{leme2018contextual, cohen2016feature,ban2017personalized,javanmard2019dynamic,lobel2016multidimensional,GolrezaeiJM21}. In addition, some of the recent work in this area~\cite{javanmard2017perishability,keskin2017chasing} aims to model the temporal behavior of buyers, by considering time-dependent demand models. 

Closer to our analysis is the notion of dynamic regret, which has been used in online convex optimization to evaluate the performance of a learner against a dynamic target~\cite{zinkevich2003online,yang2016tracking,jadbabaie2015online,besbes2015non}. However, the general framework of online optimization does not directly apply to our setting, since in the former framework, after taking an action each step the learner observes the incurred loss (or some first order information on it), which can be used in next rounds. In contrast, in our setting the firm only observes the count of sales at each segment, and not the utility of customers. 

Our work is the first to propose and analyze a dynamic contextual demand model, which accounts for temporal behavior of consumers as well as the network effect among them via spatially autoregressive structure.


\item [2) Dynamic Hierarchical modeling.] Hierarchical modeling provides an effective tool for pooling information across similar units and is one of the most popular approaches for modeling large and complex data sets \citep{fourdrinier2018shrinkage,banerjee2014hierarchical,kou2017optimal}. Here, \eqref{eq:5} imposes a dynamic hierarchical structure on the customer preference coefficients that are linked through a time-invariant non-exchangeable network structure in the second-level prior on \eqref{eq:2}. Recent applications of hierarchical modeling to consumer responses in digital products \cite{banerjeejoint2022,mukhopadhyay2022,banerjee2021improved} have been very successful in analyzing structured longitudinal data-sets abet in a non-dynamic set-up.  Here, we provide an extensive characterization on the operational characteristics of PSGD in a streamed longitudinal set-up and thereby provide theoretical support for the popular PSGD approach for hierarchical modeling in dynamic set-ups.    

\item [3) Modeling Demand Heterogeneity.] Spatial models are very popular in operations management and information sciences to capture non-stationarity in demand \citep{karmakar2021,bimpikis2019spatial,jank2005understanding}. In \eqref{eq:2}-\eqref{eq:5} we have a dynamic spatial model that is governed by changes in the auto-correlation parameter. An important feature of our contributions is that we show PSGD is able to track the variation of the auto-correlation parameter over time and yield asymptotically rate-optimal regret in a dynamic spatial model. 

\item [4) Shrinkage prediction under heterogeneity.] 
It is now commonplace to use notions of shrinkage as it often leads to substantial improvements in performances of algorithms trained on multi-parametric set-ups \citep{hastie2009elements,efron2021computer}.  
Recent results of \citet{xie2012sure,tan2015improved,weinstein2018group,brown2018empirical}  have brought to light new shrinkage phenomena in heteroscedastic models. Here, we study shrinkage prediction in a heteroscedastic dynamic set-up; $n_{lt}$ -- the number of customers in segment $l$ approached at time $t$ can greatly vary over $l$ and $t$. This is an important aspect of our model. It entertains high imbalance across the design matrix but greatly increases applicability. Particularly, in ``pull" marketing systems unlike ``push" systems \citep{peter2000preface} the firm has no control on the number of customers who visits the site/store and does a price check. Thus, $n_{lt}$ will be large in some zip-codes/demographics and quite low in others. Due to the SAR structure in \eqref{eq:5} it is possible to learn the preferences $\alpha_{lt}$ with high precision even in segments with very low $n_{lt}$s. In the results presented in Section 3, we illustrate the impact of the heterogeneous $n_{lt}$s on the regret bounds. 
\item [5) Spatial models and applications.]
Spatial models provide a natural way to model the correlation between different units of analysis based on how close they are in a similarity space. Spatial models based on correlated customer preferences have been successfully employed in marketing and economics to model real-world sales data with high predictive accuracy. \cite{jank2005understanding} used a spatially correlated preference model to model consumer choices of two product forms of a book --print or PDF. \cite{yang2003modeling} estimate a binary choice model akin to ours in which consumer preferences for a vehicle's country-of-origin (Japanese/nonJapanese) are spatially correlated based on the distance and demographic similarity between consumers. \cite{ma2015latent} models consumers' decision of whether or not to purchase a callback ringtone. In several non-marketing data applications also, spatial autoregressive (SAR) models have been very successful in assimilating spatial network information in real-world datasets \citep{manski1993identification,  anselin2013spatial}. \cite{bramoulle2009identification} used SAR to model consumption of recreational services such as participation in artistic, sports and social activities by secondary school students, whereas \cite{hsieh2016social} used SAR to incorporate the friendship networks of high school students to predict academic performance. \cite{zhou2017estimating} used SAR to model user activity on social media regarding transportation services in China. Based on this existing literature  which shows that SAR can well capture the correlation among customers and users in economic and social real-world data, we feel that the proposed model will be good for real-world applications in dynamic set-up. 
\end{description}


\section{Proposed PSGD Algorithm}
\subsection{Assumptions}\label{sec:assumption}
%\ty{Might it be good to add some details to justify the assumptions, so that they are realistic and not very restrictive? For example, provide some references or discuss them in the context of the real-world problem scenario?}
We make some assumptions on the covariate and the parameter space to simplify the presentation of our results. The covariates are normalized such that $\|\bm{x}_{lt}\| \leq 1$. Similarly the parameters $\bm\mu_t$ are such that $\|\bm\mu_t\| \leq C_{\bm\mu}$  where $C_{\bm\mu}$ is a known constant. This gives a ball  of radius $C_{\bm\mu}$ in which the parameters reside. We can even allow the parameter to belong in any convex set $\Theta_\mu$. The results would then depend on the size of the parameter space up to a constant factor.

Based on \eqref{eq:2}, we also assume that the price sensitivity $\beta_t$ should be negative i.e. an increment in price decreases the utility of the product for the consumer. We also make an assumption on the lower and the upper bound on the magnitude of price sensitivity $c_\beta \leq |\beta_t| \leq C_\beta$. These restrictions inherently create the restricted space $\Theta_{\bm\mu}$ and $\Theta_\beta$ for our model parameters. 
% These assumptions are standard in the dynamic pricing literature \citep{javanmard2017perishability}.

We also make two key assumptions on the SAR structure and auto-correlation parameter.

\begin{assumption}\label{assump.1}
$W$ is a symmetric, PSD kernel e.g. RBF kernel.
\end{assumption} 

\begin{assumption}\label{assump.2}
 The interaction parameter $\rho_t$ for all time periods is positive and uniformly bounded away from the reciprocal of the maximum eigenvalue of the interaction matrix i.e. $\exists\varepsilon \geq 0$, such that $\rho_t \leq ({1 - \varepsilon})/\omega^* $, where $\omega^*$ is the largest eigenvalue of the known interaction matrix $\bm W$.
\end{assumption} 


The second assumption \ref{assump.2} ensures that $\bm I - \rho_t \bm W$ is positive semidefinite and the hierarchical prior in \eqref{eq:5} is proper.

For ease of analysis, we also assume the noise distribution $F$ in the utility model to be standard normal. This converts our utility model \eqref{eq:2} to the dynamic probit model where customer preferences and price sensitivity changes over time.


\subsection{Reparameterization}
%\ty{It seems to be the first time (and the only time) where `Reparameterization' appears (not in the abstract and introduction). Might provide a bit more details to motivate this Reparameterization? If it is important, it may also appear in the abstract and introduction? Or probably it is just some matter of terminology?}
The hierarchical prior in \eqref{eq:5} can be used to write the explicit value of $\alpha_{lt}$ in terms of prior hyperparameters $\rho_t$, $\tau$ and standard multivariate normal noise $\epsilon$. 
% \adel{change $e_l$ to $\bm e_l$ throughout. Mover $\bm e_l$ to right side} \rb{Done}
\begin{align}\label{eq:10.1}
\alpha_{lt} = \tau\inner{\bm e_l}{(\bm I - \rho_t \bm W)^{-1}\epsilon},
\end{align}
where $\bm e_l$ denotes the $l^{th}$ basis vector.
Substituting $\alpha_{lt}$ in the utility model , we can rewrite \eqref{eq:2} in terms of $\bm\thetawa$ as 
%
\begin{align}\label{eq:11.1}
\begin{split}
U_{ltk}&= \beta_{t}\,p_{lt}+\bm{x}_{lt}' \bm{\mu}_{t} + \sigma Z_{ltk} \\ &\quad+ \tau\inner{\bm e_l}{(\bm I - \rho_t \bm W)^{-1}\epsilon}.
\end{split}
\end{align}
This produces a marginalized model, where the utility for each segment $l$ can be described as a normal distribution with variance $V^2_{lt} = \| (\bm I - \rho_t \bm W)^{-1} \bm e_l\|^2\tau^2 + \sigma^2$. By going one-step further and normalizing the utility to have unit variance we create the reparameterized utility model and the corresponding loss function 
%
\begin{align}\label{eq:12.1}
  \Tilde{U}_{ltk}= b_{lt}\,p_{lt}+\bm{x}_{lt}' \bm m_{lt} + Z_{ltk},
\end{align}
where $b_{lt} = \beta_{t}/V_{lt}$ and $\bm m_{lt} = \bm\mu_t/V_{lt}$. We use this marginal utility model for designing our pricing policy. 

\subsection{Optimal Pricing}\label{sec:2.3}
%As described previously, we want to maximize the expected revenue across all customers. The expected revenue of each consumer in segment $l$ at time $t$ is $p_{lt}q_{lt}$. Since conditioned on the parameters the utilities defined in \eqref{eq:12.1} are independent, we can simply optimize the revenue for each consumer to obtain the optimal prices. With the assumption that noises are distributed as standard Gaussian, we can write the expected revenue for each consumer in the $l^{th}$ segment at  time $t$ as $p_{lt}\Phi(\Tilde{\beta}_{lt}\,p_{lt}+\bm{x}_{lt}' \Tilde{\bm{\mu}}_{lt} )$. The optimal price $p_{lt}^*$ is then the solution to the equation
%
Under the assumption that noises are distributed as standard Gaussian, from \eqref{eq:2.2} it follows that the optimal price $p_{lt}^*$ is the solution to the equation:
\begin{align}\label{eq:15}
     p_{lt}^*  = -{b}_{lt}^{-1}\frac{\Phi\left({b}_{lt}\,p_{lt}^* +\bm{x}_{lt}' {\bm m}_{lt}\right)}{\phi\left({b}_{lt}\,p_{lt}^* +\bm{x}_{lt}' {\bm m}_{lt}\right)}~.
\end{align}
The optimality condition in \eqref{eq:15} can be restructured as 
\[\varphi(-{b}_{lt}\,p_{lt}^* - \bm{x}_{lt}' {\bm m}_{lt}) + \bm{x}_{lt}' {\bm m}_{lt} = 0\]
 where $\varphi(v) = v - {\Phi(-v)}/{\phi(v)}$ is the virtual valuation function \citep{myerson1981optimal}. 
 
 With the use of the valuation function, we can explicitly describe the optimal price $p_{lt}^*$ as a function of the utility model parameters 
 \begin{align}\label{eq:16}
    p_{lt}^* := g(b_{lt}, \bm m_{lt}) =  -\frac{\varphi^{-1}(-\bm{x}_{lt}' {\bm m}_{lt}) + \bm{x}_{lt}' {\bm m}_{lt}}{b_{lt}} ~.
 \end{align}
Setting $p_{lt}=0$ in \eqref{eq:12.1}, it follows that $\bm{x}_{lt}' {\bm m}_{lt}$ is the fixed cost of the product, which is always non-negative. 

 \begin{proposition}\label{prop.1}
Consider the definition of marginal variance $V^2_{lt} = \| (\bm I - \rho_t \bm W)^{-1}\bm e_l\|^2\tau^2 + \sigma^2$. Under Assumptions \ref{assump.1} and \ref{assump.2}, the variance  $V^2_{lt}$ satisfies
\[c_V \leq V_{lt} \leq C_V\,,\]
where $c^2_V = \tau^2 + \sigma^2$ and $C^2_V = \tau^2/\varepsilon^2  + \sigma^2$.
In addition, the optimal prices satisfy $p^*_{lt}\le M$, where $M = {c_\beta}^{-1}C_V({C_\mu c_V^{-1} - 0.5\phi(0)})$.
 \end{proposition}

 % Proposition \ref{prop.1} along with \eqref{eq:16} create an upper bound $M$ on the price $p$, where $M = {c_\beta}^{-1}C_V({C_\mu c_V^{-1} - 0.5\phi(0)})$.
 
 

\subsection{Pricing policy}
\begin{algorithm}[tb]
   \caption{PSGD based Dynamic Pricing Policy}
   \label{alg.1}
   \label{alg:DP-SGD}
\begin{algorithmic}
   \STATE \textbf{Data } $\bm{W}$ : known segment structure
\STATE \textbf{Initialize} $p_{l1} = c$, , $\hat{b}_{l1} \in \Theta_{b}$ and $\hat{\bm m}_{1t} \in \Theta_{m}$ $\forall l$
\FOR{$t=1, 2, \dots$}
\STATE \textbf{Data} $y_{lt}$, $\bm{x}_{l,t+1}$ : Longitudinal data stream
\STATE 1. Compute the gradient $\mathcal{L}_{lt}'(\hat{\bm m}_{lt},\hat{b}_{lt})$  \eqref{eq:15.1} for each segment $l$
\STATE 2. Update parameters by moving in the opposite direction of gradient with step size $\eta_t$ and then projecting onto the restricted space \eqref{eq:18}
\begin{align*}
    \hat{b}_{l,t+1} &= \Pi_{\Theta_{b}}(\hat{b}_{lt} - \eta_t \nabla \mathcal{L}_{lt}^{b})\\
    \hat{\bm m}_{l,t+1} &= \Pi_{\Theta_{ m}}(\hat{\bm m}_{lt} - \eta_t \nabla \mathcal{L}_{lt}^{\bm m} ) 
\end{align*}
\STATE 3. Set price $p_{l,t+1}$  using the optimal pricing function
\begin{align*}
    p_{l,t+1}  = g(\hat{b}_{l, t+1}, \hat{\bm m}_{l,t+1}) 
\end{align*}
\ENDFOR
\end{algorithmic}
\end{algorithm}
We propose a pricing policy based on a projected stochastic gradient descent on the loss function described in \eqref{eq:14.1}. With the PSGD, we aim to estimate the reparameterized parameter set $(b_{lt},\bm m_{lt})$ for every segment.

Based on the assumptions $\|\bm\mu_t\| \leq C_{\bm\mu}$ and $|\beta_t| \leq C_\beta$ we first define $\Theta_b := \{\beta/c_V:\beta \in \Theta_\beta\}$ and $\Theta_{m} := \{\bm\mu/c_V:\bm\mu \in \Theta_\mu\}$, the restricted space of the new parameters $b, \bm m$. These are natural extensions to the assumptions since $b_{lt} = \beta_t/V_{lt}$ and $c_V$ is the lower bound on $V_{lt}$. 

We next define the loss function as the negative of the log-likelihood function for the utility model \eqref{eq:12.1}. 
%
\begin{align}\label{eq:14.1}
\mathcal{L}_t(\bm{\thetaap})= - \sum_{l=1}^L y_{lt} \log q_{lt} + (n_{lt}-y_{lt})\log (1-q_{lt}),
\end{align}
%
 with $q_{lt} = \Phi(b_{lt}\,p_{lt}+\bm{x}_{lt}' \bm m_{lt})$ and $\Phi$ the cumulative distribution function of standard normal. Each summand in the loss \eqref{eq:14.1} is the loss for a specific segment $l$. Let $\mathcal{L}_{lt}$ denote these losses, $$\mathcal{L}_{lt} = - y_{lt} \log q_{lt} - (n_{lt}-y_{lt})\log (1-q_{lt}).$$ 
%
 We compute the gradient of these loss functions $\mathcal{L}_{lt}$ for each segment as
 \begin{align}\label{eq:15.1}
     \begin{split}
      &\mathcal{L}_{lt}'(b_{lt},\bm m_{lt}) = (\nabla \mathcal{L}_{lt}^{(b)}, \nabla \mathcal{L}_{lt}^{(m)}) \\
      &\nabla \mathcal{L}_{lt}^{(b)} = \left(- y_{lt} \frac{\phi(u_{lt}^0)}{\Phi(u_{lt}^0)}+ (n_{lt}- y_{lt})\frac{\phi(-u_{lt}^0)}{\Phi(-u_{lt}^0)}\right)p_{lt}\\
      &\nabla \mathcal{L}_{lt}^{(m)} = \left(- y_{lt} \frac{\phi(u_{lt}^0)}{\Phi(u_{lt}^0)}+ (n_{lt}- y_{lt})\frac{\phi(-u_{lt}^0)}{\Phi(-u_{lt}^0)}\right)\bm x_{lt}
     \end{split}
 \end{align}
% and $u_{lt}^0 = b_{lt}\,p_{lt}+\bm{x}_{lt}' \bm m_{lt}$ is the noiseless utility.

% \adel{not sure about above gradients. Shouldn't it be $p_{lt}$ instead of $b_{lt}$ and $x_{lt}$ instead of $\bm m$} \rb{Correct, changed.}
Then, at every time period $t$, with a step size $\eta_t$, we move in the opposite direction of the gradient. The parameters are then projected onto the restricted space $\Theta_b,\Theta_{\bm m}$  based on the assumptions on the size of the parameters to get an estimate for the parameters for the next time. This projected gradient descent step can be written as 
 %
 % \adel{we have both $L$ and $\mathcal{L}$ notations. should be consistent.} \rb{Chnaged.}
\begin{align}
    \hat{b}_{l,t+1} &= \Pi_{\Theta_{b}}(\hat{b}_{lt} - \eta_t \nabla \mathcal{L}_{lt}^{b})\label{eq:18}\\
    \hat{\bm m}_{l,t+1} &= \Pi_{\Theta_{ m}}(\hat{\bm m}_{lt} - \eta_t \nabla \mathcal{L}_{lt}^{\bm m} )\label{eq:19}
\end{align}
%
where $\Pi_{\Theta_b}(.)$ and $\Pi_{\Theta_m}(.)$ are the projection functions on to the convex set $\Theta_b$ and $\Theta_m$ respectively. 

The policy finally uses the estimated parameters and the optimal pricing function $g(\cdot, \cdot)$ defined in \eqref{eq:16} to set the price for the next period. 



\section{Main Results: Regret Bounds}\label{sec.3}
% \section{Theoretical Results}
In this section, we provide the bounds on the regret for the dynamic pricing policy we employ. We show that under regularity conditions on the temporal nature of the parameters $\beta$, $\bm \mu$ and $\rho$, the regret as defined in \eqref{eq:7} has order square root of the time horizon $T$. We also show the optimality of the bound by showing that no policy can achieve a worst-case regret better than the same rate. 


\subsection{Upper Bound on Regret of the Proposed Algorithm}
We present an upper bound on the regret of the proposed pricing policy in terms of the reparameterized model parameters in \eqref{eq:12.1}. Later, through lemma~\ref{lemma.1}, we create a link between the actual parameters and the reparameterized ones. Finally, we show that when the step sizes $\eta_t \propto 1/\sqrt{t}$, we achieve $\mathcal{O}(\sqrt{T})$ regret.
\begin{theorem}\label{thm.1}
For any $\bm{\theta} \in \Theta$ defined below \eqref{eq:7}, the regret of our proposed policy satisfies: 
\begin{align}
\mathcal{B}(\bm{\thetawa},\bm{p})\leq \mathcal{R}_1 + \mathcal{R}_2 + \mathcal{R}_3 + \mathcal{R}_4 + \mathcal{O}(\log T), \text{where},\label{eq.thm.1}
\end{align}
 \begin{itemize}
     \item [ ] $\mathcal{R}_1 = C_1 \sum_{t = 1}^T \sum_{l = 1}^L \eta_{t}^{-1}|b_{l,t+1} - b_{l,t}|$~,
     \item [ ] $\mathcal{R}_2 = C_2 \sum_{t = 1}^T \sum_{l = 1}^L \eta_{t}^{-1}\|\bm m_{l,t+1} - \bm m_{l,t}\|_2$~,
      \item [ ] $\mathcal{R}_3 = C_3 \sum_{t = 1}^T \sum_{l = 1}^L \eta_{t}   {n_{lt}^2} \leq C_3 \sum_{t = 1}^T \eta_t n_{t}^2$, and,
     \item [ ] $\mathcal{R}_4 = C_4~ \eta_{T+1}^{-1} \, L $.
 \end{itemize}
 and $C_1$, $C_2$, $C_3$ and $C_4$ are constants independent of $T$, $n$, $L$ and the model parameters. 
\end{theorem}

The detailed proof of the  theorem is presented in the Appendix. We present a brief overview of its proof in Section 4. We next concentrate on further explaining the terms on the right side of \eqref{eq.thm.1}. 
We simplify the first two terms $\mathcal{R}_1$, $\mathcal{R}_2$ in theorem \ref{thm.1} and provide a key lemma \ref{lemma.1}. For ease of notation we define  $\delta_{t\nu} = \|\nu_{t+1} - \nu_t\|$ for any parameter $\nu$. This helps us transform our regret from the reparameterized quantities $b$, $\bm m$ to the original parameters $\beta$, $\bm \mu$ and $\rho$. 

\begin{lemma}\label{lemma.1}
    Let $\omega_*$ be the smallest eigenvalue of $\bm W$, then under Assumptions \ref{assump.1} and \ref{assump.2}, the variation across the parameters in the utility model \eqref{eq:12.1}, can be bounded as 
    \begin{align}
       |b_{l,t+1} - b_{l,t}| \leq {\tau}^{-1}({1 - \rho_t\omega_*}){\delta_{t\beta}} + C_5 {\delta_{t\rho}}~,\\
       \|\bm m_{l,t+1} - \bm m_{l,t}\|_2  \leq {\tau}^{-1}({1 - \rho_t\omega_*}){\delta_{t\mu}} + C_5 {\delta_{t\rho}}.
    \end{align}
\end{lemma}

Next, we demonstrate the implications of the above result in a simplified setup with any network structure $\bm W$. The goal is to understand the effect of the network structure and the auto-correlation $(\rho_t)$ on the upper bound of the regret in \eqref{eq.thm.1}. We provide the following corollary that explicitly shows the relation of regret with the auto-correlation parameter. 

\begin{corollary}\label{cor.2}
If $\eta_t \propto 1/\sqrt{t}$, and $\rho_t = \rho$ for all $t$, then the dynamic pricing policy based on Algorithm \ref{alg.1} has regret
\begin{align}\label{eq:23}
   \mathcal{B}(\bm{\thetawa},\bm{p})\leq  {C}_6 {\tau}^{-1}({1 - \rho\omega_*})\sum_{t = 1}^T\sqrt{t}({\delta_{t\beta} + \delta_{t\mu}}) + \mathcal{O}(\sqrt{T}).
\end{align}
\end{corollary}

Corollary \ref{cor.2} shows that the regret has two parts, one with order $\sqrt{T}$, while the other part depends on the temporal nature of price sensitivity and customer preferences. The regret occurred in this part depends on the strength of the network inversely, i.e, higher the strength of the network (higher the $\rho$) lower the regret and vice-versa.    

Note that if $\rho_t$ was varying across time, we can extend the bound in Corollary~\ref{cor.2}. Assume that $\rho_* = \min_t \rho_t$, then the bound on regret can be modified as
\begin{align}
   \mathcal{B}(\bm{\thetawa},\bm{p})\leq  &{C}_6 {\tau}^{-1}({1 - \rho_{*}\omega_*})\sum_{t = 1}^T\sqrt{t}({\delta_{t\beta} + \delta_{t\mu}})  + C_7 \sum_{t = 1}^T \sqrt{t}\delta_{t\rho} + \mathcal{O}(\sqrt{T}).\label{eq:23.1}
\end{align}
where $C_6$ and $C_7$ are constants. The bound above behaves similarly to Corollary~\ref{cor.2} if the temporal changes across auto-correlation is small.




\subsection{Lower Bound on Regret of Any Data-driven Policy}
We show that the bound in corollary \ref{cor.2} is indeed tight in terms of dependence on the time horizon. In the next theorem we show that there exists parameters in the space $\Thetawa$ such that under the demand model with these parameters, the regret  of any policy is of the order at least $\sqrt{T}$. The detailed proof is provided in the Appendix. 

\begin{theorem}\label{thm.2}
    Consider the utility model \eqref{eq:12.1} and let $N_T:=\sum_{t=1}^T \sum_{l=1}^L n_{lt}$ be the total number of costumers across all segment and times up to $T$. For any fixed graph $\bm W$, the worst-case risk of any data driven pricing policy $\hat{\bm p}$ satisfies
    \[\min_{\hat{\bm p}}\max_{\bm\theta \in \Theta}\mathcal{B}(\bm{\thetawa},\bm{p}) \geq C_8 \sqrt{T} (1+\log(N_T/T))\,,\]
    for some constant $C_8$.
    In particular, if $n_{lt}\ge 1$ for all $l, t$, we have
    \[\min_{\hat{\bm p}}\max_{\bm\theta \in \Theta}\mathcal{B}(\bm{\thetawa},\bm{p}) \geq C_8 \sqrt{T} (1+\log(L))\,.\]
\end{theorem}
%\ryan{maybe add symbols to the above to make it a bit more clear?}
% \adel{for any $n_{lt}$? what if they are all zero?} \rb{Assumed that all $n_{lt}$'s are non-zero, if $n_{lt} = 0$, the node of }

Theorem \ref{thm.2} along with \eqref{eq:23.1} implies that our pricing policy in algorithm~\ref{alg.1}, is optimal, if the temporal changes across the price sensitivity, customer preferences and auto-correlation is of the order $\sqrt{T}$, i.e. if $\sum_{t = 1}^T\sqrt{t}(\delta_{t\beta} + \delta_{t\mu} + \delta_{t\rho}) = \mathcal{O}(\sqrt{T})$, then our policy is order optimal.

\subsection{Sub-optimality of Unshrunken Pricing Policies}
Next, we consider unshrunken policies that do not incorporate the structure \eqref{eq:5} on the $\bm{\alpha}_t$s.
Such unshrunken policies suffer from severe noise accumulation in estimating $\bm{\alpha}_t$ as free parameters at every time point. The following result whose proof is provided in Section \ref{append.cor.1} of the appendix shows that the Bayes regret from any unshrunken pricing policies based on the unpenalized likelihood is highly sub-optimal as compared to the proposed strategy $\bm p$. Consider a parametric space $\bar{\Theta}$ such that any $\bm \theta \in \bar{\Theta}$ satisfies that $\sum_{t = 1}^T \sqrt{t}\delta_{t\beta}$, $\sum_{t = 1}^T \sqrt{t}\delta_{t\mu}$ and $\sum_{t = 1}^T \sqrt{t}\delta_{t\rho}$ are $\mathcal{O}(\sqrt{T})$. The following result shows sub-optimality of unshrunken pricing policies over $\bar{\Theta}$.

%Unlike the other results in this section, here we concentrate on an asymptotic set-up where $T$ diverges to $\infty$. The number of segments $L:=L(T)$ also diverges to $\infty$ as $T \to \infty$ but $\lim_{T \to \infty}L(T)/T \to 0$. Recall the notation $\bm{\thetaap}=\{\bm{\thetaap}_t:=(\bm{\alpha}_t,\beta_t,\bm{\mu}_t): t=1,\ldots,T\}$ and let $\bm \Lambda$ be the set of feasible $\bm \lambda$ (satisfying the boundedness assumptions discussed in Section~\ref{sec:assumption}). In this asymptotic set-up, we show  that there exists $\bm\lambda \in \bm \Lambda$ such that the regret from any unshrunken pricing policies is highly sub-optimal as compared to the regret of the proposed strategy. The proof is provided in Section \ref{append.cor.1} of the appendix.  

\begin{lemma}\label{cor.1}
For any $\bm\theta \in \bar{\Theta}$, the regret of any data-driven policy $\bm{p}_U$ based on the unpenalized likelihood in \eqref{eq:8} satisfies:
$$\mathcal{B}(\bm{\theta},\bm{p}_U)\big/ \mathcal{B}(\bm{\theta},\bm{p}) = \Omega(\sqrt{T}).$$
\end{lemma}


% \section{Sketch of the Proof}
\section{Outline of Proofs and Overview of Techniques}

For the detailed proofs of all the results, we refer to the appendix. In this section,  we delve into the intuition and the intermediate steps used in proving the two main results in Section~\ref{sec.3}. 
% \adel{We keep moving between $\hat{\bm p}$ and $\bm p$ to denote a policy. Make it consistent.}\rb{Changed all $\hat{\bm{p}}$ to ${\bm{p}}$.}

\subsection{Proof Sketch of Theorem \ref{thm.1}}
The crucial idea is to bound the revenue loss (regret) with the parameters in the model. To achieve that consider the revenue function with the utility model \eqref{eq:12.1}
\begin{align}\label{eq:Rev-mod}
    \text{Rev}_{lt}(p_{lt}) = n_{lt}p_{lt}\Phi(b_{lt}p_{lt} + \bm x_{lt}'\bm m_{lt}).
\end{align}

The revenue loss using our policy is then the difference between $\text{Rev}_{lt}(p_{lt}^*)$ and $\text{Rev}_{lt}(p_{lt})$ where $p_{lt}^*$ is the optimal price for the model true parameters and $p_{lt}$ is the price posted with the dynamic pricing policy. 

\begin{proposition}\label{prop.2}
    There exists a constant $C_9$ such that the regret of our policy on segment $l$ at time $t$ can be bounded as 
    \begin{align}\label{eq:25}
        \mathcal{R}_{lt} = {\rm Rev}_{lt}(p_{lt}^*) - {\rm Rev}_{lt}(p_{lt}) \leq C_9 n_{lt}(p_{lt} - p_{lt}^*)^2\,,
    \end{align}
    where $p_{lt}$ is our posted price and $p_{lt}^*$ is the optimal price that maximizes the revenue under known parameters.
\end{proposition}

We simplify the regret bound term $(p_{lt} - p_{lt}^*)^2$ on the right hand side of \eqref{eq:25} in our next lemma. The idea is to use the optimal pricing function $g(\cdot,\cdot)$ defined in section~\ref{sec:2.3}. The prices $p_{lt}^*$ and $p_{lt}$ can then be defined as $p_{lt}^* = g(b_{lt}, \bm m_{lt})$, the optimal price based on the true parameters and $p_{lt} = g(\hat{b}_{lt}, \hat{\bm m}_{lt})$, the optimal price with respect to the estimated parameters that our proposed policy posts. The lemma then hinges on the fact that the function $g(\cdot,\cdot)$ defined in \eqref{eq:16} is Lipschitz. 
% \adel{Check that both constants in the next lemma are equal.}\rb{Checked.}

\begin{lemma}\label{lemma.2}
 For model \eqref{eq:12.1}, under the true parameters $b_{lt}, \bm{m}_{lt}$ and the output $\hat{b}_{lt}, \hat{\bm{m}}_{lt}$ from our PSGD pricing policy, the following holds true: 
%
 \begin{equation}
     (p_{lt} - p_{lt}^*)^2 \leq C_{10} \langle\bm{x}_{lt}, \bm m_{lt} - \hat{\bm m}_{lt}\rangle^2 + C_{10} p_{lt}^2(b_{lt} - \hat{b}_{lt})^2
 \end{equation}
 for some constant $C_{10}>0$. 
\end{lemma}

The $\mathcal{R}_{lt}$ terms in \eqref{eq:25} are the building blocks for our total regret $\mathcal{B}(\bm{\thetawa},\bm{p})$ as in \eqref{eq:7} where $\mathcal{B}(\bm{\thetawa},\bm{p}) = \sum_{t = 1}^T\sum_{l = 1}^L\mathcal{R}_{lt}$. The above two lemmas relate the revenue regret occurred by the policy with the estimation error of the parameters in the model \eqref{eq:12.1}. The final step involves creating a link between this estimation error and the temporal nature of the parameters to achieve the regret bound as in Theorem ~ \ref{thm.1}.

\subsection{Proof Sketch of Theorem \ref{thm.2}}
For the lower bound, we want to find worst case scenarios in terms of parameters. In this case, we use the idea of ``uninformative prices" \citep{broder2012dynamic}. These are prices where the purchase probability curves for all different sets of parameters intersect. Such prices do not reveal any information about the parameters since  all the purchase curves contain the point. These uninformative prices become an issue when they are also the optimal prices for some set of parameters. If a policy wants to learn the parameters fast, they need to do exploration away from these uninformative prices. But during the process of exploration it chooses parameters farther from the actual parameters and thus increases regret.

The general idea of such proofs is to create a setting where these optimal prices are indeed uninformative. In the proof, we show existence of such parameters and their corresponding optimal ``uninformative prices". Calling these parameters $\gamma_0$, the proof hinges on two relations, one showing that learning the utility model parameters closely is expensive in terms of regret: 
\begin{align}\label{eq:KL-LB}
\text{Reg}_T^{\pi,\gamma_0} \geq \frac{C_{12}}{(\gamma_0 - \gamma)^2}\KL\left(f_T^{\pi, \gamma_0} ; f_T^{\pi, \gamma}\right)
\end{align}
where $f_t^{\pi, \gamma}$ is the density of purchases for all consumers until time $t$, provided that the policy $\pi$ is employed. An interpretation of the KL-divergence $\KL\left(f_t^{\pi, \gamma_0} ; f_t^{\pi, \gamma}\right)$ is the certainty level of the policy $\pi$ about the true model parameters $\gamma_0$, over some other counterfactual parameter $\gamma$. So the above bound implies that increasing certainty about the underlying model is costly. 

The next bound shows that if the policy can not differentiate between two parameters that are ``close" to each other (in other words to increase its confidence in one), then again it incurs a large regret. Specifically, if $\gamma_1 = \gamma_0 + 1/(4T^{1/4})$,
\begin{align}\label{eq:KL-LB2}
\text{Reg}_T^{\pi,\gamma_0} + \text{Reg}_T^{\pi,\gamma_1} \geq C_{13}\sqrt{T}e^{-\KL\left(f_T^{\pi, \gamma_0} ; f_T^{\pi, \gamma_1}\right)}.
\end{align}

Intuitively, the first equation shows that exploitation is necessary (choosing the optimal parameter $\gamma_0$ to have small KL-divergence) and the second one asks for exploration to stay away from uninformative prices, so as to gain information about the model parameters and increase the certainty about it, as measured by KL-divergence. 


\section{Numerical Experiments}
We study the performance of our pricing policy with a simulation study. We set the number of customer segments $L = 10$, with $5$ segments of size $50$ and the other $5$ segments with $200$ customers each, for all time periods. To generate the network matrix $\bm W$ across different customer segments, we use an RBF kernel of width one with independent standard Gaussian feature vectors, drawn from input space $\mathbb{R}^{10}$. 
% \adel{What is the width?} \adel{You mean covaraites are Gaussian? what is the dimension?}. 
The covariates $\bm x_{lt}$ have dimension 2 and are generated using standard exponential distribution. We also set $\tau = 1$ and $\sigma = 1$, the random shock parameters for the utility and the auto regressive model respectively. The auto-correlation parameter of the regularization structure $\rho_t$ is set to $0.5$.

The price sensitivity and the customer preferences are assumed as $\beta_1 = -0.4$ and $\bm\mu_1 = (0.1, 0.15)$. With change in time the parameters change as follows,
\[\beta_{t+1} = \beta_t + \delta_{t\beta}; \quad \bm\mu_{t+1} = \bm\mu_t + \bm\delta_{t\mu}\]
where $\delta_{t\beta} = t^{-b}\tilde{Z_t}/(10|\tilde{Z_t}|)$ and $\bm\delta_{t\mu} = t^{-b}\bar{\bm Z_t}/(10\|\bar{\bm Z_t}\|)$ where $\tilde{Z_t}$ and $\bar{\bm Z_t}$ are standard Gaussian random variables of dimension 1 and 2 respectively.

We consider three cases, $b=0.5, 1, \infty$, for the temporal variations across $\beta_t$ and $\bm \mu_t$. Note that the case of $b=\infty$ corresponds to the scenario where the parameters do not change over time.  Following from Corollary~\ref{cor.2}, the regret for the two cases of $b = 1, \infty$ should be of order $O(\sqrt{T})$, while the regret for $b = 0.5$ should be $\mathcal{O}(T)$. In Figure~\ref{fig:b_vary}, we plot the regret (cumulative revenue lost to the oracle policy) for the three cases. In the first case with $b = 0.5$, we can see that the regret eventually grows linearly. 
% \adel{rewrite: eventually has a linear growth} 
To better verify the regret rate in the other two cases, we plot $\log({\rm Regret})$ versus $\log(T)$ for these cases with a line of slope $0.5$ in Figure~\ref{fig:regret_log}. 
% As expected, the regret for the first two cases is $\mathcal{O}(\sqrt{T})$ and that of for the last case is $\mathcal{O}(T)$.


\begin{figure}[t]
            \centering
            \includegraphics[width=0.46\textwidth]{b.png}
            
            \includegraphics[width=0.18\textwidth]{b_legend.png}
            \caption{Regret of the proposed policy for different values of b.
            }
            \label{fig:b_vary}
        \end{figure}

        
\begin{figure}[!htb]
    \subfigure[]{\includegraphics[width=0.46\textwidth]{b1_log.png}}
    \subfigure[]{\includegraphics[width=0.46\textwidth]{binf_log.png}}
    \caption{log(Regret) vs log(T) for (a) $b = 1$ and (b) $b = \infty$}
    \label{fig:regret_log}
\end{figure}


Next we compare the regret performance with respect to the auto-correlation parameter $\rho$. We compare three settings with $\rho = 0.1, 0.3$ and $0.5$. Note that only the first two terms $\mathcal{R}_1$ and $\mathcal{R}_2$ in Theorem~\ref{thm.1} depend on $\rho$ while the third term $\mathcal{R}_3$ increases with $n_{lt}$. This means that as $n_{lt}$'s increase, $\mathcal{R}_3$ grows very large and the effect of $\mathcal{R}_1$ and $\mathcal{R}_2$ (effect of $\rho$) on the regret is significantly less. %\adel{previous sentence is vague.}
Hence, to see the effect of $\rho_t$, we consider a simpler setting with only 4 segments with 50 customers each and $b = 1$ as in second case above. We plot the regret in Figure~\ref{fig:rho_vary} and see a significant improvement in terms of regret as $\rho$ increases gradually.

\begin{figure}[!htb]
            \centering
            \includegraphics[width=0.46\textwidth]{rho_vary.png}
            
            \includegraphics[width=0.18\textwidth]{rho_vary_legend.png}
            \caption{Regret of proposed policy under varying values of auto-correlation parameter $\rho$.}
            \label{fig:rho_vary}
        \end{figure}

We also compare our policy with an unshrunken policy which assumes no correlation across the segment of customers. Assuming no correlation would imply that the marginal utility model in \eqref{eq:12.1} is simply 
\begin{align*}
  \Tilde{U}_{ltk}= b_{t}\,p_{lt}+\bm{x}_{lt}' \bm m_{t} + Z_{ltk}
\end{align*}
where $b_{t} = \beta_t/V_t$ and $\bm m_t = \bm \mu_t/V_t$ and $V_t = \sqrt{\tau^2 + \sigma^2}$.

The unshrunken policy aims to estimate the parameters of the above marginal model and set the optimal price w.r.t the estimated parameters. 
% \adel{rewrite it in terms of unshrunken estimator} 
In Figure~\ref{fig:rho0} we see the comparison of regret of the two policies. While our policy gives us $\mathcal{O}(\sqrt{T})$ regret, the regret of the unshrunken policy is linear.

\begin{figure}[!htb]
            \centering
            \includegraphics[width=0.46\textwidth]{rho0.png}
            \vspace{0.5em}
            
            \includegraphics[width=0.32\textwidth]{rho0_legend.png}
            \caption{Regret of proposed policy vs an unshrunken policy.}
            \label{fig:rho0}
        \end{figure}

        
% \section{Discussion}
\section{Discussion and Conclusion}
% ADD A SUMMARY HERE! \adel{Ryan, please add this part.}
This work studied dynamic pricing strategies in the streaming longitudinal data setting where the goal is to maximize the cumulative profit over time across a large number of customer segments.
We proposed a pricing policy based on penalized stochastic gradient descent and provided regret bounds demonstrating the asymptotic optimality of the proposed policy.
In particular, we showed that our PSGD algorithm controls the regret at the order of $\bigo(\sqrt{T})$ and that for any pricing policy, the Bayes regret cannot be of the lower order of $\bigo(\sqrt{T})$.
Hence, as $T \rightarrow \infty$, the proposed algorithm is asymptotically rate-optimal.
Our results show that for policy planning it is essential to incorporate available structural information as policies given by unshrunken models are highly sub-optimal.
% Furthermore, we show that any unshrunken policy that does not leverage the strength across customer segments is highly sub-optimal with respect to the proposed strategy.

There are several important future directions of our work.
In future work, it will be useful to derive the regret of the proposed algorithm when the noise is not Gaussian but heavy-tailed as such noise characteristics are often associated with observed demand data. Theoretically, it will be interesting to calculate the benefits of a batched version of the proposed algorithm~1 that is equipped for price exploration within segments though it might not be practically feasible due to spill-over effects.  Also, here we have considered global spatial structure in the form of the SAR model in \eqref{eq:5}. In the future, it will be interesting to study the performance of PSGD in the presence of local shrinkage structures such as geographically weighted regression  models \citep{fotheringham2003geographically}.  Finally, it will be useful to evaluate the optimal regret in time-varying networks where the contiguity matrix $\bm{W}$ also changes over time.   
% \section{Discussion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\section{Proof of Theorems}
\subsection{Proof of Theorem~\ref{thm.1}}

The total regret $\mathcal{B}(\bm\theta,{\bm p})$ can be written down as the sum of regrets over all the segments and time period:

\[\mathcal{B}(\bm\theta,{\bm p}) = \sum_{t = 1}^T\sum_{l = 1}^L \mathcal{R}_{lt}\,.\]

Using Proposition~\ref{prop.2} and Lemma~\ref{lemma.2}, we can bound the regret as 

\[\mathcal{B}(\bm\theta,{\bm p}) = C_9C_{10}\sum_{t = 1}^T\sum_{l = 1}^L n_{lt}\langle\bm{x}_{lt}, \bm m_{lt} - \hat{\bm m}_{lt}\rangle^2 + C_9C_{10}\sum_{t = 1}^T\sum_{l = 1}^L n_{lt}\big(p_{lt}(b_{lt} - \hat{b}_{lt})\big)^2\,.\]

Taking a maximum on the constants, we can rather bound the sum of the two terms  $\sum_{t = 1}^T\sum_{l = 1}^L n_{lt}\langle\bm{x}_{lt}, \bm m_{lt} - \hat{\bm m}_{lt}\rangle^2$ and $\sum_{t = 1}^T\sum_{l = 1}^L n_{lt}\big(p_{lt}(b_{lt} - \hat{b}_{lt})\big)^2$ to get a final bound on the regret.

We do the analysis for a fixed segment $l$ first and then combine the regret across all the segments.  

\begin{lemma}\label{lemma.app.1}
     Consider model \eqref{eq:12.1}, true parameters $ \bm{m}_{lt}$, $ b_{lt}$ and the output $ \hat{\bm{m}}_{lt}$, $ \hat{b}_{lt}$ from our PSGD pricing policy, the following holds with probability at least $1 - \tfrac{1}{T^2}$ 
     \begin{align*}
             \sum_{t = 1}^T n_{lt} \Big(\langle\bm{x}_{lt}, \bm m_{lt} - \hat{\bm m}_{lt}\rangle^2 + \big(p_{lt}(b_{lt} - \hat{b}_{lt})\big)^2\Big)\leq & {C}_1\sum_{t = 1}^T \frac{1}{\eta_t} \|\bm m_{l,t+1} - \bm m_{lt}\|_2 + {C}_2\sum_{t = 1}^T \frac{1}{\eta_t} |b_{l,t+1} - b_{lt}|
\\&+ {C}_3\sum_{t = 1}^T{\eta_t} n_{lt}^2 + \frac{{C}_4}{\eta_{T+1}} + \mathcal{O}(\log T)\,.
     \end{align*}
\end{lemma}


With this lemma we have with probability at least $1 -L/T^2$, 
\begin{align*}
    \sum_{t = 1}^T \sum_{l = 1}^L n_{lt} \Big(\langle\bm{x}_{lt}, \bm m_{lt} - \hat{\bm m}_{lt}\rangle^2 + \big(p_{lt}(b_{lt} - \hat{b}_{lt})\big)^2\Big)\leq & {C}_1\sum_{t = 1}^T \sum_{l = 1}^L\frac{1}{\eta_t} \|\bm m_{l,t+1} - \bm m_{lt}\|_2 + {C}_2\sum_{t = 1}^T \sum_{l = 1}^L\frac{1}{\eta_t} |b_{l,t+1} - b_{lt}|\\
    &+ {C}_3\sum_{t = 1}^T\sum_{l = 1}^L{\eta_t} n_{lt}^2 + \frac{{C}_4L}{\eta_{T+1}} + \mathcal{O}(\log T)\,.
\end{align*}

Define the RHS as $I$.

Consider $\mathcal{G}$ to be the probabilistic event that the above is true, then $\mathbb P (\mathcal{G}^C) = L/T^2$.

Also, since the maximum price is $M$ and we set a positive price, hence the maximum revenue lost on the event $\mathcal{G}^C$ is $\sum_{t = 1}^T n_{t}M$. Assuming that $N_T = \max_{t\leq T}n_T$, we have the maximum regret in the event $\mathcal{G}^C$ is $T M N_T$.

The total regret is thus,

\[\mathcal{B}(\bm\theta,{\bm p}) = \mathcal{B}(\bm\theta,{\bm p}|\mathcal{G}) + \mathcal{B}(\bm\theta,{\bm p}|\mathcal{G}^C)\leq I \mathbb P(\mathcal{G}) + T N_T \mathbb P(\mathcal{G}^C) \leq A + \frac{ML N_T}{T}\,.\]

Since the last term is $ \mathcal{O}(1/T)$, we have the required terms of the regret bound.

\subsection{Proof of Lemma~\ref{lemma.app.1}}
Let ${\bm{\psi}}_{lt} = (\bm m_{lt}, b_{lt})$ be the combined parameter space and $\bm{Q}_{lt} = (\bm x_{lt}, p_{lt})$ be the covariates and the price posted.

     By Taylor expansion of the loss function we get, for some $\Tilde{\bm{\psi}}_{l,t}$ between $\hat{\bm{\psi}}_{l,t}$ and $\bm{\psi}_{lt}$,
     \begin{equation}\label{eq:12}
         \mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt}) - \mathcal{L}_{lt}(\bm{\psi}_{lt}) = \inner{\nabla \mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt})}{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}} - \frac{1}{2}\inner{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}}{\nabla^2 \mathcal{L}_{lt}(\Tilde{\bm{\psi}}_{l,t})(\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt})}\,.
     \end{equation}

Simplifying the loss function in terms of $\bm{\psi}_{lt}$ and $\bm{Q}_{lt}$ gives us $$\mathcal{L}_{lt}(\bm{\psi}) = - \left( y_{lt} \log \Phi(\bm{Q}_{lt}\bm{\psi}) + \tilde{ y}_{lt}\log {\Phi}(-\bm{Q}_{lt}\bm{\psi})\right),$$ where $\tilde{ y}_{lt} = n_{lt} - y_{lt}$.
The second derivative of the loss function can thus be computed as 
     \[\nabla^2 \mathcal{L}_{lt}(\bm{\psi}) = - \left(y_{lt}\bm{Q}_{lt}\bm{Q}_{lt}^T \frac{\partial}{\partial \zeta^2}\log \Phi(\zeta)|_{\zeta = \bm{Q}_{lt}\bm{\psi}} + \tilde{ y}_{lt}\bm{Q}_{lt}\bm{Q}_{lt}^T \frac{\partial}{\partial \zeta^2}\log \Phi(\zeta)|_{\zeta = -\bm{Q}_{lt}\bm{\psi}}\right)\,.\]
     
     Let $c_\mathcal{L} = \min\left\{-\frac{\partial}{\partial \zeta^2}\log \Phi(\zeta)|_{\zeta = \bm{Q}_{lt}\bm{\psi}}, -\frac{\partial}{\partial \zeta^2}\log \Phi(\zeta)|_{\zeta = -\bm{Q}_{lt}\bm{\psi}}\right\}$.
     % \adel{Why is $c_{\mathcal{L}}>0?$ We had $Y_{lt}$ not $y_{lt}$. What is $\tilde{y}_{lt}$? Definition of $c_{\mathcal{L}}$ is not correct, it should be $\partial/\partial x^2 \log\Phi(x)|_{x= \bm{Q}_{lt}\bm{\psi}}$}. 
     Based on our assumptions, $\bm{Q}_{lt}$ and $\bm{\psi}$ are bounded and so there exists $c$ such that $|\bm{Q}_{lt}\bm{\psi}|<c$. Since $\Phi$ is log-concave hence the second derivative is negative and $-\frac{\partial}{\partial \zeta^2}\log \Phi(\zeta) > 0$. Particularly since the second derivative only approaches $0$ when $\zeta$ goes to $\infty$ or $-\infty$, hence on the bounded set with $|\zeta| < c$, second derivative is bounded away from zero implying $c_{\mathcal{L}}>0$.
     
     Then,
     \begin{align*}
         \nabla^2 \mathcal{L}_{lt}(\bm{\psi}) &= - \left(y_{lt}\bm{Q}_{lt}\bm{Q}_{lt}^T \frac{\partial}{\partial \zeta^2}\log \Phi(\zeta)|_{\zeta = \bm{Q}_{lt}\bm{\psi}} + \tilde{ y}_{lt}\bm{Q}_{lt}\bm{Q}_{lt}^T\frac{\partial}{\partial \zeta^2}\log \Phi(\zeta)|_{\zeta = -\bm{Q}_{lt}\bm{\psi}}\right)\\
         &= \left(y_{lt}\bm{Q}_{lt}\bm{Q}_{lt}^T \left(-\frac{\partial}{\partial \zeta^2}\log \Phi(\zeta)|_{\zeta = \bm{Q}_{lt}\bm{\psi}}\right) + \tilde{ y}_{lt}\bm{Q}_{lt}\bm{Q}_{lt}^T \left(-\frac{\partial}{\partial \zeta^2}\log \Phi(\zeta)|_{\zeta = -\bm{Q}_{lt}\bm{\psi}}\right)\right)\\
         &\geq (y_{lt} + \tilde{ y}_{lt})\bm{Q}_{lt}\bm{Q}_{lt}^T \min\left\{-\frac{\partial}{\partial \zeta^2}\log \Phi(\zeta)|_{\zeta = \bm{Q}_{lt}\bm{\psi}}, -\frac{\partial}{\partial \zeta^2}\log \Phi(\zeta)|_{\zeta = -\bm{Q}_{lt}\bm{\psi}}\right\}\\
         &= n_{lt}\bm{Q}_{lt}\bm{Q}_{lt}^T c_{\mathcal{L}}\,.
     \end{align*}
     Where the last equality follows since  $y_{lt} + \tilde{ y}_{lt} = n_{lt}$.
    % \adel{Where is $n_{lt}$ coming from?} \rb{Addressed}
    
    Using this in \eqref{eq:12}

     \begin{align}\label{eq:28}
     \begin{split}
          \mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt}) - \mathcal{L}_{lt}(\bm{\psi}_t) &\leq \inner{\nabla \mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt})}{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}} - \frac{1}{2}\inner{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}}{n_{lt}c_\mathcal{L} \bm{Q}_{lt}\bm{Q}_{lt}^T(\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt})}\\
          &= \inner{\nabla \mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt})}{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}} - \frac{n_{lt}c_\mathcal{L}}{2}\inner{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}}{ \bm{Q}_{lt}}^2\\
          &= \inner{\nabla \mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt})}{\hat{\bm{\psi}}_{l,t+1} - \bm{\psi}_{lt}} + \inner{\nabla \mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt})}{\hat{\bm{\psi}}_{lt} - \hat{\bm{\psi}}_{l,t+1}} - \frac{n_{lt}c_\mathcal{L}}{2}\inner{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}}{ \bm{Q}_{lt}}^2\,.
     \end{split}
     \end{align}
Our update rules in \eqref{eq:18} and \eqref{eq:19}, gives us
 \begin{align*}
    \hat{b}_{l,t+1} &= \Pi_{\Theta_{b}}(\hat{b}_{lt} - \eta_t \nabla \mathcal{L}_{lt}^{b})\,,\\
    \hat{\bm m}_{l,t+1} &= \Pi_{\Theta_{\bm m}}(\hat{\bm m}_{lt} - \eta_t \nabla \mathcal{L}_{lt}^{\bm m} )\,.
\end{align*}
     The updates defined are common OMD updates and can be rewritten as

    \[\hat{\bm{\psi}}_{l,t+1} = \arg\min_{\bm{\psi} }
 \inner{\nabla \mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt})}{\bm{\psi}}  + \frac{1}{2 \eta_{t}}\|\bm{\psi} - \hat{\bm{\psi}}_{lt}\|^2\,.\]

Since the above loss function is convex and $\hat{\bm{\psi}}_{l,t+1}$ is the minimizer, we get

\[\inner{\bm{\psi}-\hat{\bm{\psi}}_{l,t+1}}{\eta_t\nabla\mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt}) + \hat{\bm{\psi}}_{l,t+1} - \hat{\bm{\psi}}_{lt}} \geq 0\,.\]
 
 Putting $\bm{\psi} = \bm{\psi}_{lt}$ above, we get $\inner{\hat{\bm{\psi}}_{l,t+1} - \bm{\psi}_{lt}}{\eta_{t}\nabla \mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt})} \leq \inner{\bm{\psi}_{lt} - \hat{\bm{\psi}}_{l,t+1}}{\hat{\bm{\psi}}_{l,t+1} - \hat{\bm{\psi}}_{lt}}$.

Also, note that 
 \begin{equation*}\
   \inner{\bm{\psi}_{lt} - \hat{\bm{\psi}}_{l,t+1}}{\hat{\bm{\psi}}_{l,t+1} - \hat{\bm{\psi}}_{lt}} = \frac{1}{2}\left(\|\bm{\psi}_{lt} - \hat{\bm{\psi}}_{lt}\|^2 - \|\bm{\psi}_{lt} -  \hat{\bm{\psi}}_{l,t+1}\|^2 - \| \hat{\bm{\psi}}_{l,t+1}- \hat{\bm{\psi}}_{lt}\|^2\right) \,. 
 \end{equation*}

With the above two equations the first term in \eqref{eq:28} is bounded as:
% \adel{Change $\bm{\psi}_{l,t+1}$ to $\bm{\psi}_{l,t+1}$ throughout}
\[\inner{\nabla \mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt})}{\hat{\bm{\psi}}_{l,t+1} - \bm{\psi}_{lt}} \leq \frac{1}{2\eta_t}\left(\|\bm{\psi}_{lt} - \hat{\bm{\psi}}_{lt}\|^2 - \|\bm{\psi}_{lt} -  \hat{\bm{\psi}}_{l,t+1}\|^2 - \| \hat{\bm{\psi}}_{l,t+1}- \hat{\bm{\psi}}_{lt}\|^2\right)\,. \]


Using the inequality $ab\le (a^2+b^2)/2$, the second term in \eqref{eq:28} can be bounded as,
     \begin{equation}\label{eq:14}
         \inner{\nabla \mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt})}{\hat{\bm{\psi}}_{lt} - \hat{\bm{\psi}}_{l,t+1}}  \leq \frac{1}{2\eta_{t}}\|\hat{\bm{\psi}}_{lt} - \hat{\bm{\psi}}_{l,t+1}\|^2 + \frac{\eta_{t}}{2}\|\nabla \mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt})\|^2\,.
     \end{equation}

     Also, $\nabla \mathcal{L}_{lt}(\bm{\psi}) = -\left(y_{lt}\bm{Q}_{lt}\frac{\partial}{\partial \zeta^2}\log \Phi(\zeta)|_{\zeta = \bm{Q}_{lt}\bm{\psi}} - \Tilde{y}_{lt}\bm{Q}_{lt}\frac{\partial}{\partial \zeta^2}\log \Phi(\zeta)|_{\zeta = -\bm{Q}_{lt}\bm{\psi}}\right)$. 
     
     Let $C_{\mathcal{L}} = \max\{-\frac{\partial}{\partial \zeta^2}\log \Phi(\zeta)|_{\zeta = \bm{Q}_{lt}\bm{\psi}}, \frac{\partial}{\partial \zeta^2}\log \Phi(\zeta)|_{\zeta = -\bm{Q}_{lt}\bm{\psi}}\}$ in the restricted space. Hence, $\|\nabla \mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt})\|^2 \leq {C_{\mathcal{L}}^2 n_{lt}^2}\|\bm{Q}_{lt}\|^2$. 


Combining all the parts we have,

\[\mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt}) - \mathcal{L}_{lt}(\bm{\psi}_t) \leq \frac{1}{2\eta_t}\|\bm{\psi}_{lt} - \hat{\bm{\psi}}_{lt}\|^2 - \frac{1}{2\eta_t}\|\bm{\psi}_{lt} -  \hat{\bm{\psi}}_{l,t+1}\|^2 + \frac{\eta_t}{2}{C_{\mathcal{L}}^2 n_{lt}^2}\|\bm{Q}_{lt}\|^2- \frac{n_{lt}c_\mathcal{L}}{2}\inner{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}}{ \bm{Q}_{lt}}^2\,.\]

Adding and subtracting $\|\bm{\psi}_{l,t+1} - \hat{\bm{\psi}}_{l,t+1}\|^2$ to above we get
%
\begin{align}
    \mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt}) - \mathcal{L}_{lt}(\bm{\psi}_t) &\leq \frac{1}{2\eta_t}\left(\|\bm{\psi}_{lt} - \hat{\bm{\psi}}_{lt}\|^2 - \|\bm{\psi}_{l,t+1} - \hat{\bm{\psi}}_{l,t+1}\|^2\right)\nonumber\\ &\quad+ \frac{1}{2\eta_t}\left(\|\bm{\psi}_{l,t+1} - \hat{\bm{\psi}}_{l,t+1}\|^2 - \|\bm{\psi}_{lt} -  \hat{\bm{\psi}}_{l,t+1}\|^2\right) \nonumber\\
& \quad+ \frac{\eta_t}{2}{C_{\mathcal{L}}^2 n_{lt}^2}\|\bm{Q}_{lt}\|^2- \frac{n_{lt}c_\mathcal{L}}{2}\inner{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}}{ \bm{Q}_{lt}}^2\,.\label{eq:telescope}
\end{align}
The second term can be simplified as 
\[\|\bm{\psi}_{l,t+1} - \hat{\bm{\psi}}_{l,t+1}\|^2 - \|\bm{\psi}_{lt} -  \hat{\bm{\psi}}_{l,t+1}\|^2 = \inner{\bm{\psi}_{l,t+1}+ \bm{\psi}_{lt} - 2\hat{\bm{\psi}}_{l,t+1}}{\bm{\psi}_{l,t+1} - \bm{\psi}_{lt}}\leq 4C_{\bm{\psi}} \|\bm{\psi}_{l,t+1} - \bm{\psi}_{lt}\|_2\,,\]
where $C_{\bm{\psi}}$ is $\max\|\bm{\psi}\|$ and $C_{\bm{\psi}} \leq 2C_b + 2C_m$, since $\bm{\psi} = (\bm m, b)$.

Summing the both sides of~\eqref{eq:telescope} over $t=1,\dotsc,T$, we get
%
\begin{align*}
    \sum_{t = 1}^T\left(\mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt}) - \mathcal{L}_{lt}(\bm{\psi}_t)\right) \leq \frac{\|\bm{\psi}_{l1} - \hat{\bm{\psi}}_{l1}\|^2}{2\eta_1} &+ \sum_{t = 2}^T\|\bm{\psi}_{lt} - \hat{\bm{\psi}}_{lt}\|^2\left(\frac{1}{2\eta_{t+1}} - \frac{1}{2\eta_t}\right) + 4C_{\bm{\psi}}\sum_{t = 1}^T \frac{1}{2\eta_t} \|\bm{\psi}_{l,t+1} - \bm{\psi}_{lt}\|_2 \\
&+ \sum_{t = 1}^T \frac{\eta_t}{2}{C_{\mathcal{L}}^2 n_{lt}^2}\|\bm{Q}_{lt}\|^2- \sum_{t = 1}^T \frac{n_{lt}c_\mathcal{L}}{2}\inner{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}}{ \bm{Q}_{lt}}^2\,.
\end{align*}

 Under the assumption that $\eta_t$ are non-decreasing, 
 %
\[\frac{\|\bm{\psi}_{l1} - \hat{\bm{\psi}}_{l1}\|^2}{2\eta_1} + \sum_{t = 2}^T\|\bm{\psi}_{lt} - \hat{\bm{\psi}}_{lt}\|^2\left(\frac{1}{2\eta_{t+1}} - \frac{1}{2\eta_t}\right) \leq \frac{4C_{\bm{\psi}}^2}{2\eta_1} + 4C_{\bm{\psi}}^2\sum_{t = 2}^T\left(\frac{1}{2\eta_{t+1}} - \frac{1}{2\eta_t}\right) = \frac{4C_{\bm{\psi}}^2}{2\eta_{T+1}}\,.\]

Hence, we finally have 
%
\begin{align*}
    \sum_{t = 1}^T\left(\mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt}) - \mathcal{L}_{lt}(\bm{\psi}_t)\right) \leq  &\frac{4C_{\bm{\psi}}^2}{2\eta_{T+1}} + 4C_{\bm{\psi}}\sum_{t = 1}^T \frac{1}{2\eta_t} \|\bm{\psi}_{l,t+1} - \bm{\psi}_{lt}\|_2 \nonumber\\
&+ \sum_{t = 1}^T \frac{\eta_t}{2}{C_{\mathcal{L}}^2 n_{lt}^2}\|\bm{Q}_{lt}\|^2- \sum_{t = 1}^T \frac{n_{lt}c_\mathcal{L}}{2}\inner{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}}{ \bm{Q}_{lt}}^2\,.
\end{align*}

Define 
\begin{align}\label{eq:Adef}
A:= \frac{4C_{\bm{\psi}}^2}{2\eta_{T+1}} + 4C_{\bm{\psi}}\sum_{t = 1}^T \frac{1}{2\eta_t} \|\bm{\psi}_{l,t+1} - \bm{\psi}_{lt}\|_2 
+ \sum_{t = 1}^T \frac{\eta_t}{2}{C_{\mathcal{L}}^2 n_{lt}^2}\|\bm{Q}_{lt}\|^2.
\end{align}

% \adel{All equations should finish with '.' or ','}

Since, $\|\bm{\psi}_{l,t+1} - \bm{\psi}_{lt}\|_2 \leq 2 (\|\bm m_{l,t+1} - \bm m_{lt}\|_2 + |b_{l,t+1} - b_{lt}|)$ and $\|\bm{Q}_{lt}\|^2$ is bounded, we can simplify $A$ as 
\[A:= \Tilde{C}_1\sum_{t = 1}^T \frac{1}{\eta_t} \|\bm m_{l,t+1} - \bm m_{lt}\|_2 + \Tilde{C}_2\sum_{t = 1}^T \frac{1}{\eta_t} |b_{l,t+1} - b_{lt}|
+ \Tilde{C}_3\sum_{t = 1}^T{\eta_t} n_{lt}^2 + \frac{\Tilde{C}_4}{\eta_{T+1}}\,. \]

Note that in order to prove the lemma we need to show a bound on  $\sum_{t = 1}^T n_{lt} \Big(\langle\bm{x}_{lt}, \bm m_{lt} - \hat{\bm m}_{lt}\rangle^2 + \big(p_{lt}(b_{lt} - \hat{b}_{lt})\big)^2\Big)$ which is same as showing a bound on $\sum_{t = 1}^T {n_{lt}}\inner{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}}{ \bm{Q}_{lt}}^2$, since $\bm{\psi}_{lt} = (\bm m_{lt},b_{lt})$ and $\bm{Q}_{lt} = (\bm x_{lt},p_{lt})$.


We next provide a lower bound on the cumulative difference $\sum_{t = 1}^T\left(\mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt}) - \mathcal{L}_{lt}(\bm{\psi}_t)\right) $. Write
%
\begin{align}\label{eq:Dtk}
 \mathcal{L}_{ltk}({\bm{\psi}}_{lt}) - \mathcal{L}_{ltk}(\hat{\bm{\psi}}_{lt}) \leq \inner{\nabla\mathcal{L}_{ltk}(\bm{\psi}_{lt})}{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}}:=D_{tk}\,,
 \end{align}
using convexity of the loss $\mathcal{L}_{ltk}$. We also have
\begin{align*}
    \nabla \mathcal{L}_{ltk}(\bm{\psi}) &= -(y_{ltk}\frac{\partial}{\partial\bm{\psi}}\log \Phi(\bm{Q}_{lt}\bm{\psi}) - (1 - y_{ltk})\frac{\partial}{\partial\bm{\psi}}\log \Phi(-\bm{Q}_{lt}\bm{\psi}))\\ 
    &= \bm{Q}_{lt}\left(-y_{ltk}\frac{\phi(\bm{Q}_{lt}\bm{\psi})}{\Phi(\bm{Q}_{lt}\bm{\psi})}+ (1-{y}_{ltk})\frac{\phi(-\bm{Q}_{lt}\bm{\psi})}{\Phi(-\bm{Q}_{lt}\bm{\psi})}\right)\,.
\end{align*}
% \adel{Why do we have $\bm{\psi}$ above?} \rb{The loss is a function of $\bm{\psi} := (\bm m, b)$.}

Let $\mathcal{F}_t$ be the $\sigma$-field generated by the noise till time $t$. Then, since $\hat{\bm{\psi}}_{lt}$ only depends on noise till time $t$,
$\mathbb{E}[D_{tk}|\mathcal{F}_{t-1}] =  \inner{\mathbb{E}[\nabla\mathcal{L}_{ltk}|\mathcal{F}_{t-1}]}{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}}$. In addition, $E[\nabla\mathcal{L}_{ltk}|\mathcal{F}_{t-1}]=0$ using the fact that $\mathbb P(Y_{ltk} = 1) = \Phi(\bm{Q}_{lt}\bm{\psi})$ and $\mathbb P(Y_{ltk} = 0) = \Phi(-\bm{Q}_{lt}\bm{\psi}))$. Therefore, the partial sums of $D_{tk}$ is a martingale with respect to the filtration $\mathcal{F}_t$.

Also, as described above $\left(-y_{ltk}\frac{\phi(\bm{Q}_{lt}\bm{\psi})}{\Phi(\bm{Q}_{lt}\bm{\psi})}+ (1-{y}_{ltk})\frac{\phi(-\bm{Q}_{lt}\bm{\psi})}{\Phi(-\bm{Q}_{lt}\bm{\psi})}\right)$ is bounded above with $C_\mathcal{L}$. Hence $|D_{tk}| \leq \beta_t:=C_\mathcal{L}|\inner{\bm{Q}_{lt}}{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}}|$. Using convexity of $e^{\lambda z}$, for any $\lambda \in \mathbb R$ we have

\begin{align*}
\mathbb{E}\left[e^{\lambda D_{tk}} \mid \mathcal{F}_{t-1}\right] & \leq \mathbb{E}\left[\frac{\beta_t-D_{tk}}{2 \beta_t} e^{-\lambda \beta_t}+\frac{\beta_t+D_{tk}}{2 \beta_t} e^{\lambda \beta_t} \mid \mathcal{F}_{t-1}\right] \\
& =\mathbb{E}\left[\frac{e^{-\lambda \beta_t}+e^{\lambda \beta_t}}{2}\right]+\mathbb{E}\left[D_{tk} \mid \mathcal{F}_{t-1}\right]\left(\frac{e^{-\lambda \beta_t}+e^{\lambda \beta_t}}{2 \beta_t}\right)=\cosh \left(\lambda \beta_t\right) \leq e^{\lambda^2 \beta_t^2 / 2}\,.
\end{align*}

where $\beta_t = C_\mathcal{L}|\inner{\bm{Q}_{lt}}{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}}|$. We next use the following result from \citep[Proposition C.1]{javanmard2017perishability}.


\begin{proposition} \citep[Proposition C.1]{javanmard2017perishability}
    Consider a martingale difference sequence $D_t$ adapted to a filtration $\mathcal{F}_t$, such that for any $\lambda \geq 0, \mathbb{E}\left[e^{\lambda D_t} \mid \mathcal{F}_{t-1}\right] \leq e^{\lambda^2 \sigma_t^2 / 2}$. Then, for $D(T)=\sum_{t=1}^T D_t$, the following holds true:
$$
\mathbb{P}(D(T) \geq \xi) \leq e^{-\xi^2 /\left(2 \sum_{t=1}^T \sigma_t^2\right)}\,.
$$
\end{proposition}
We apply the above theorem with $D(T) = \sum_{t = 1}^T\sum_{k = 1}^{n_{lt}}D_{tk}$. Invoking~\eqref{eq:Dtk}, this gives us, 
\[\mathbb{P}\left( \sum_{t = 1}^T\left(\mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt}) - \mathcal{L}_{lt}(\bm{\psi}_t)\right) \leq -2C_\mathcal{L} \sqrt{\log T}\left\{\sum_{t=1}^Tn_{lt}\left\langle \bm{Q}_{lt}, \bm{\psi}_{lt}-\hat{\bm{\psi}}_{lt}\right\rangle^2\right\}^{1 / 2}\right)\leq \frac{1}{T^2}\,.\]

Hence with probability at least $1 - 1/T^2$, 
\[\sum_{t = 1}^T\left(\mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt}) - \mathcal{L}_{lt}(\bm{\psi}_t)\right) \geq -2C_\mathcal{L} \sqrt{\log T}\left\{\sum_{t=1}^Tn_{lt}\left\langle \bm{Q}_{lt}, \bm{\psi}_{lt}-\hat{\bm{\psi}}_{lt}\right\rangle^2\right\}^{1 / 2}\,.\]

Let $B = \sum_{t = 1}^T {n_{lt}}\inner{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}}{ \bm{Q}_{lt}}^2$, then with the complete analysis till now we have

\[-2C_\mathcal{L} \sqrt{B \log T} \leq \sum_{t = 1}^T\left(\mathcal{L}_{lt}(\hat{\bm{\psi}}_{lt}) - \mathcal{L}_{lt}(\bm{\psi}_t)\right) \leq A - \frac{c_\mathcal{L}}{2}B\,.\]

Hence, $B - (4 C_\mathcal{L}/c_\mathcal{L})\sqrt{B\log T}\leq (2/c_\mathcal{L})A$. Consider two cases:
%

Case 1: $\sqrt{B\log T} \leq (c_\mathcal{L}/8C_\mathcal{L}) B$, then $B \leq 4A/c_\mathcal{L}$.

Case 2: $\sqrt{B\log T} \geq (c_\mathcal{L}/8C_\mathcal{L}) B$, then $B \leq (8 C_\mathcal{L}/c_{\mathcal{L}})^2\log T$.


Combining the two cases, we have 
\[B \leq \frac{4A}{c_\mathcal{L}} + \mathcal{O}(\log T)\,.\]

Substituting for 
\[B = \sum_{t = 1}^T {n_{lt}}\inner{\hat{\bm{\psi}}_{lt} - \bm{\psi}_{lt}}{ \bm{Q}_{lt}}^2 = \sum_{t = 1}^T {n_{lt}} \left(\inner{\bm x_{lt}}{\bm m_{lt} - \hat{\bm m}_{lt}}^2+ p_{lt}^2(b_{lt} - \hat b_{lt})^2\right)\,,\]
 and $A$ from~\eqref{eq:Adef} we obtain the desired result.


\subsection{Proof of Theorem~\ref{thm.2}}
Recall the variance of segment $l$ in the utility model given by $V_{lt}^2 = \|(\bm I - \rho_t \bm W)^{-1} \bm e_l\|^2\tau^2+\sigma^2$. We assume that we have a known fixed $\rho$, the auto-correlation parameter, and so the variances do not change over time. 

Indicate the variances of segments by $V_{1}, V_{2}, \cdots, V_{L}$. Our utility model is thus 
\[\Tilde{U}_{ltk}= \frac{\beta_{t}}{V_{l}}\,p_{lt}+\bm{x}_{lt}' \frac{\bm\mu_{t}}{V_{l}} + Z_{ltk}\,.\]

Without loss of generality, assume that $\bm x_{lt}$ is of dimension one. We would give a small variation that would work for any dimension as well. Let $v_{1}, v_{2}, \cdots, v_{L}$ be the inverse of the fixed variances. The model is thus, 

\[\Tilde{U}_{ltk}= {\beta_{t}}{v_{l}}\,p_{lt}+{x}_{lt} {\mu_{t}}{v_{l}} + Z_{ltk\,.}\]


Assume that $-\beta_t = \mu_t = \gamma$, i.e. the parameters do not change over time and are negative of each other. In this setup $U^0_{ltk} = v_l\gamma(x_{lt} - p_{lt} )$, the noiseless utility. Here setting $p_{lt} = x_{lt}$ would be uninformative since we would just observe noise, and we cannot get any information about the unknown parameter $\gamma$. In addition, in our model a price $p^*_{lt}$ is optimum if it satisfies
\[p^*_{lt} = -\frac{1}{\beta_t v_l}\frac{\Phi({\beta_{t}}{v_{l}}\,p^*_{lt}+{x}_{lt} {\mu_{t}}{v_{l}})}{\phi({\beta_{t}}{v_{l}}\,p^*_{lt}+{x}_{lt} {\mu_{t}}{v_{l}})}\,.\]
Under the assumption that $-\beta_t = \mu_t = \gamma$, this reduces to
\[p^*_{lt} = \frac{1}{\gamma v_l}\frac{\Phi(v_l\gamma(x_{lt} - p^*_{lt}))}{\phi(v_l\gamma(x_{lt} - p^*_{lt}))}\,.\]

Therefore, for $\gamma_0:= (v_l x_{lt})^{-1} \Phi(0)/\phi(0)$, the uninformative price is optimal prices, i.e., $p^*_{lt}(\gamma_0) = x_{lt}$. 

Note that if $x_{lt}$ was of higher dimension, we could set $\bm x_{lt} = (a/d, a/d, a/d, \cdots, a/d)$ with $ d$ the dimension of $\bm x_{lt}$ and set $\bm \mu_t = (\gamma, \gamma, \gamma, \cdots, \gamma)$ to get the exactly same result: $p^*_{lt}(\gamma_0) = a$ for $\gamma_0= (v_l a)^{-1}\Phi(0)/\phi(0)$ is an uninformative price. 

Now that we know the existence of a setting where the uninformative prices are optimal prices, we can show that the regret is at least of the order of $\sqrt{T}$.

% \adel{You use `uninformative' and `non-informative'. Stay with one.}\rb{Will change to uninformative}

We construct a problem class $(\Gamma, \{\mathcal{P}_{lt}\})$, for $l=1,\dotsc, L$, $t=1,\dotsc, T$ as follows. Recall $\gamma_0$ the parameter for which the optimal price is uninformative. We use the shorthand $r_{lt}(p,\gamma)$ to denote the expected revenue obtained from a typical customer from segment $l$ at time $t$, if the model parameter is $\gamma$. Therefore, recalling our utility model $U_{ltk} = v_l\gamma(x_{lt}-p_{lt})+Z_{ltk}$, we have $r_{lt}(p,\gamma) = p(\Phi(v_l\gamma(x_{lt} - p)))$. By optimality of $p^*_{lt}(\gamma_0)$, we have $r''_{lt}(p^*_{lt}(\gamma_0),\gamma_0) <-2c$ for some constant $c>0$, and by continuity of $r''_{lt}$ we can find a neighborhood $\mathcal{P}_{lt}$ around $p^*_{lt}(\gamma_0)$ such that $r''_{lt}(p,\gamma_0)<-c$ for all $p\in\mathcal{P}_{lt}$. 
We next consider the mapping $\gamma\mapsto p^*_{lt}(\gamma)$. By continuity of this mapping, we can find a small enough neighborhood $\Gamma_{lt}$ around $\gamma_0$ such that the  optimal prices $p^*_{lt}(\gamma)\in \mathcal{P}_{lt}$ for all $\gamma\in \Gamma_{lt}$. Finally, we take $\Gamma: = \cap_{t=1}^T \cap_{l=1}^L \Gamma_{lt}$. Note that $\Gamma$ is non-empty because $\gamma_0\in \Gamma$. Furthermore, by our construction we have the following properties for the problem class $(\Gamma, \{\mathcal{P}\}_{lt})$, for $l=1,\dotsc, L$ and $t=1,\dotsc, T$:
\begin{itemize}
\item For all $\gamma\in \Gamma$, we have $p^*_{lt}(\gamma)\in \mathcal{P}_{lt}$.
\item For all prices $p\in\mathcal{P}_{lt}$, we have $r''_{lt}(p,\gamma_0)<-c$\,. 
\end{itemize}

% Consider the problem class $\gamma \in \Gamma := (\gamma_{\min},\gamma_{\max})$, such that the parameter for which the optimal price is uninformative exists in $\Gamma$ i.e. $1 \in \Gamma$. The set $\Gamma$ is such that if $\gamma \in \Gamma$, then the optimal price for $\gamma$ satisfies 
% \[p \leq \frac{2\phi(v_l\gamma(x_{lt} - p))}{\phi'(v_l\gamma(x_{lt} - p))v_l\gamma}.\]

% Since this is trivially true for $\gamma_0$ and all the functions are continuous, hence such a set always exists. The condition means that for any optimal price $p$, $r''(p)$ is negative where $r(p) = p(\Phi(v_l\gamma(x_{lt} - p)))$ is the revenue function. \adel{I don't understand the above paragraph.}

% Also, consider $\mathcal{P}$ as the set of prices which are optimal for some $\gamma$. Formally,
% \[\mathcal{P} = \left\{p: \text{ for some } \gamma \in \Gamma, p \text{ is solution to the equation } p^* = \frac{1}{\gamma v_l}\cdot\frac{\Phi(v_l\gamma(x_{lt} - p^*))}{\phi(v_l\gamma( x_{lt} - p^*))} \right\}\,.\]

% This set is bounded since the set $\Gamma$ is bounded and the function $g(\cdot,\cdot)$ which maps parameter space to price is continuous. The idea is to show that for this problem class $(\Gamma, \mathcal{P})$, there exists a parameter $\gamma$ such that  any pricing policy that sets price in the set $\mathcal{P}$ has regret at least $\sqrt{T}$.

For any pricing policy $\pi$ and a parameter $\gamma \in \Gamma$, let $f_{t}^{\pi, \gamma} : \{0,1\}^{N_t} \rightarrow [0,1]$ be the probability distribution function for all the consumers purchase responses $\bm Y= (Y_{ljk}, \ell = 1,\dotsc, L, j=1,\dotsc, t, k=1,\dotsc, n_{lj})$ until time $t$. Here, $N_t = \sum_{j = 1}^t\sum_{l = 1}^L n_{lj}$, under policy $\pi$ and model parameter $\gamma$. 
The pricing policy uses all the sales data till time $t-1$ to give a price $p_{lt}^*$. We use $\bm y_{t}\in\{0,1\}^{N_t}$ to denote all sales data till time $t$. So, if the pricing policy gives the prices $p_{lt} := \pi(\bm y_{t-1})$ for all the time periods, then 
\[f_t^{\pi, \gamma}(\bm y_t) = \prod_{j = 1}^t\prod_{l = 1}^L\prod_{k = 1}^{n_{lj}} q_{lj}(p_{lj}, \gamma)^{y_{ljk}}(1 - q_{lj}(p_{lj}, \gamma))^{1 - y_{ljk}}\,,\]
where $q_{lj}(p_{lj}, \gamma) = \Phi(v_l\gamma(x_{lj} - p_{lj} ))$. We next want to show that for $\gamma_0$, the  parameter for which the uninformative price is optimal, any policy incurs a large regret if it tries to learn $\gamma_0$. Formally, we aim to show that

    \[\mathcal{R}^\pi_t(\gamma_0) \geq C\frac{1}{(\gamma_0 - \gamma)^2} \KL(f_t^{\pi, \gamma_0},f_t^{\pi, \gamma})\,.\]


We employ the chain rule for KL divergence \citep{cover1991information},

\begin{align*}
\KL\left(f_t^{\pi, \gamma_0} ; f_t^{\pi, \gamma}\right) & =\sum_{s=1}^t \KL\left(f_t^{\pi, \gamma_0} ; f_t^{\pi, \gamma} | \bm {Y}_{s-1}\right) \\
& =\sum_{s=1}^t \sum_{\mathbf{y}_s \in\{0,1\}^{N_s}} f_s^{\pi, \gamma_0}\left(\mathbf{y}_s\right) \log \left(\frac{f_s^{\pi, \gamma_0}\left(y_{lsk} \mid \mathbf{y}_{s-1}\right)}{f_s^{\pi, \gamma}\left(y_{lsk} \mid \mathbf{y}_{s-1}\right)}\right) \\
& =\sum_{s=1}^t \sum_{\mathbf{y}_{s-1} \in\{0,1\}^{N_{s-1}}} f_{s-1}^{\pi, \gamma_0}\left(\mathbf{y}_{s-1}\right) \sum_{l = 1}^L \sum_{k = 1}^{n_{ls}}\sum_{y_{lsk} \in\{0,1\}} f_s^{\pi, \gamma_0}\left(y_{lsk} \mid \mathbf{y}_{s-1}\right) \log \left(\frac{f_s^{\pi, \gamma_0}\left(y_{lsk} \mid \mathbf{y}_{s-1}\right)}{f_s^{\pi, \gamma}\left(y_{lsk} \mid \mathbf{y}_{s-1}\right)}\right) \\
& =\sum_{s=1}^t \sum_{\mathbf{y}_{s-1} \in\{0,1\}^{N_{s-1}}} f_{s-1}^{\pi, \gamma_0}\left(\mathbf{y}_{s-1}\right) \sum_{l = 1}^L \sum_{k = 1}^{n_{ls}}\KL\Big(f_s^{\pi, \gamma_0}\left(y_{lsk} \mid \mathbf{y}_{s-1}\right) ; f_s^{\pi, \gamma}\left(y_{lsk} \mid \mathbf{y}_{s-1}\right)\Big)\,.
\end{align*}

Based on the definition of $f_t^{\pi, \gamma}$, $f_s^{\pi,\gamma_0}(y_{lsk})$ is distributed as Bernoulli $q_{ls}(p_{ls}, \gamma_0)$ and  $f_s^{\pi,\gamma}(y_{lsk})$ is distributed as Bernoulli $q_{ls}(p_{ls}, \gamma)$. Using the fact that for Bernoulli random variables $B_1\sim {\sf Bern}(q_1), B_2\sim {\sf Bern}(q_2)$, we have $\KL(B_1, B_2) \leq \frac{(q_1 - q_2)^2}{q_2(1 - q_2)}$, we get

\begin{align}\label{eq:KL}
\KL\left(f_t^{\pi, \gamma_0} ; f_t^{\pi, \gamma}\right) \leq \sum_{s=1}^t \sum_{\mathbf{y}_{s-1} \in\{0,1\}^{N_{s-1}}} f_{s-1}^{\pi, \gamma_0}\left(\mathbf{y}_{s-1}\right) \sum_{l = 1}^L \sum_{k = 1}^{n_{ls}}\frac{(q_{ls}(p_{ls}, \gamma_0) - q_{ls}(p_{ls}, \gamma))^2}{q_{ls}(p_{ls}, \gamma)(1 - q_{ls}(p_{ls}, \gamma))}\,.
\end{align}

Since the prices and the parameters are bounded, and $q_{lt}$ is the normal distribution function, $q_{lt}$ is bounded away from zero. Hence, there exists constant $C$ such that $q_{ls}(1- q_{ls}) \geq C$.

Also, $q_{ls}(p_{ls}^*, \gamma) = \Phi(v_l\gamma(x_{ls} - p_{ls}^* ))$ and $q_{ls}(p_{ls}^*, \gamma_0) = \Phi(v_l\gamma_0(x_{ls} - p_{ls}^* ))$. Since we are working on a bounded set, the distribution function $\Phi$ is Lipschitz as well. Hence,
\begin{align*}
    q_{ls}(p_{ls}, \gamma_0) - q_{ls}(p_{ls}, \gamma) &= \Phi(v_l\gamma_0(x_{ls} - p_{ls} )) - \Phi(v_l\gamma(x_{ls} - p_{ls} ))\\
    &\leq C (v_l\gamma_0(x_{ls} - p_{ls} ) - v_l\gamma(x_{ls} - p_{ls}))\\
    &=C v_l (\gamma_0 - \gamma)(x_{ls} - p_{ls} )\\
    &= C v_l (\gamma_0 - \gamma)(p_{ls}^*(\gamma_0) - p_{ls} )\,,
\end{align*}

where $p^*_{ls}(\gamma_0)$ is the optimal price for when the parameter is $\gamma_0$. Recall that by the definition of $\gamma_0$, the optimal price for $\gamma_0$ is $x_{lt}$. We thus have \[(q_{ls}(p_{ls}, \gamma_0) - q_{ls}(p_{ls}, \gamma))^2 \leq C(\gamma_0 - \gamma)^2(p^*_{ls}(\gamma_0) - p_{ls} )^2\,.\]

Using the above bound in~\eqref{eq:KL}, we get 
\[\KL\left(f_t^{\pi, \gamma_0} ; f_t^{\pi, \gamma}\right) \leq C (\gamma - \gamma_0)^2\sum_{s=1}^t   \sum_{l = 1}^L \sum_{k = 1}^{n_{ls}}\sum_{\mathbf{y}_{s-1} \in\{0,1\}^{N_{s-1}}}f_{s-1}^{\pi, \gamma_0}\left(\mathbf{y}_{s-1}\right)(p_{ls}^*(\gamma_0) - p_{ls} )^2\,.\]

The inner summation is indeed the expectation with respect to $\gamma_0$, by noting that $p_{ls}$ is a measurable function of $\bm y_{s-1}$. Hence, we have 
\begin{align}
\KL\left(f_t^{\pi, \gamma_0} ; f_t^{\pi, \gamma}\right) &\leq C (\gamma - \gamma_0)^2\sum_{s=1}^t   \sum_{l = 1}^L \sum_{k = 1}^{n_{ls}}\mathbb{E}_{\gamma_0}(p_{ls}^* (\gamma_0)-p_{ls})^2\nonumber\\
&= C (\gamma - \gamma_0)^2\sum_{s=1}^t   \sum_{l = 1}^Ln_{ls}\mathbb{E}_{\gamma_0}(p_{ls}^*(\gamma_0) - p_{ls} )^2\,.\label{eq:KL0}
\end{align}


By the construction of problem class $(\Gamma, \{\mathcal{P}_{lt}\})$, we have $r''_{lt}(p,\gamma_0)\le -c$, for $\gamma\in\Gamma$ and $p\in\mathcal{P}_{lt}$. Therefore, by Taylor expansion of $r_{ls}(p,\gamma)$ around $p^*_{ls}$, we obtain
\[
r_{ls}(p_{ls},\gamma_0) = r_{ls}(p^*_{ls}(\gamma_0),\gamma_0) + r'_{ls}(p^*_{ls}(\gamma_0),\gamma_0)(p_{ls} - p^*_{ls}(\gamma_0))+\frac{1}{2} r''_{ls}(\tilde{p},\gamma_0)(p_{ls} - p^*_{ls}(\gamma_0))^2\,,
\]
for some $\tilde{p}$ between $p_{ls}$ and $p^*_{ls}$.
By optimality of $p^*_{ls}$ we have $r'_{ls}(p^*_{ls}(\gamma_0),\gamma_0)=0$. In addition, since $\tilde{p}\in\mathcal{P}_{ls}$, we have $r''_{ls}(\tilde{p},\gamma_0)<-c$, which implies that
\[
(p_{ls} - p^*_{ls}(\gamma_0))^2\le \frac{2}{c}\Big(r_{ls}(p^*_{ls}(\gamma_0),\gamma_0) - r_{ls}(p_{ls},\gamma_0)\Big)\,.
\]
Using the above bound in~\eqref{eq:KL0}, we arrive at
\begin{align}\label{eq:KL-Bound1}
\KL\left(f_t^{\pi, \gamma_0} ; f_t^{\pi, \gamma}\right) \le  C (\gamma - \gamma_0)^2\sum_{s=1}^t   \sum_{l = 1}^L  n_{ls}\mathbb{E}_{\gamma_0}[r_{ls}(p_{ls}^*(\gamma_0),\gamma_0) - r_{ls}(p_{ls},\gamma_0)] \leq C (\gamma - \gamma_0)^2\text{ Reg}_t\,,
\end{align}
which completes the proof~\eqref{eq:KL-LB}.
% since the double derivative of the revenue function is always negative. Let $r''(p) \leq -c$, then $(p_{ls}(\gamma_0) - p_{ls}^* )^2 \leq c(r((p_{ls}(\gamma_0)) - r(p_{ls}^*))$.

% We thus have, $\KL\left(f_t^{\pi, \gamma_0} ; f_t^{\pi, \gamma}\right) \leq C (\gamma - \gamma_0)^2\sum_{s=1}^t   \sum_{l = 1}^L  n_{lt}\mathbb{E}_{\gamma_0}(r((p_{ls}(\gamma_0)) - r(p_{ls}^*)) \leq C (\gamma - \gamma_0)^2\text{ Reg}_t$

We next proceed with our proof for bound~\eqref{eq:KL-LB2}. Recall the optimality condition

\[v_l \gamma p^*_{lt}(\gamma) = \frac{\Phi(v_l\gamma(x_{lt} - p^*_{lt}(\gamma)))}{\phi(v_l\gamma(x_{lt} - p^*_{lt}(\gamma)))}\,.\]

Differentiating with respect to $\gamma$ on both sides we get,

\[v_l p^*_{lt}(\gamma) + v_l \gamma \frac{d}{d\gamma}p^*_{lt}(\gamma) = v_l \left(x_{lt} - p^*_{lt}(\gamma) - \gamma\frac{d}{d\gamma}p^*_{lt}(\gamma)\right) \kappa(\gamma)\,, \]
where 
\[
\kappa(\gamma) = \frac{\phi^2(v_l\gamma(x_{lt} - p^*_{lt}(\gamma))) - \Phi(v_l\gamma(x_{lt} - p^*_{lt}(\gamma)))\phi'(v_l\gamma(x_{lt} - p^*_{lt}(\gamma))) }{\phi^2(v_l\gamma(x_{lt} - p^*_{lt}(\gamma)))}\,.
\]
By rearranging the terms we have
% \[p(\gamma)+ \gamma \frac{d}{d\gamma}p(\gamma) = k(\gamma)\left(x_{lt} - p(\gamma) - \gamma\frac{d}{d\gamma}p(\gamma)\right).\]

% We can bound $\frac{d}{d\gamma}p(\gamma)$ with
% \adel{check if it is $-p^*_{lt}$ below}\rb{Yes it is $-p^*_{lt}$, changed it here.}
\[
\frac{d}{d\gamma}p^*_{lt}(\gamma) = 
\frac{1}{\gamma}\left(-p^*_{lt}(\gamma) + \frac{k(\gamma)}{1 + k(\gamma)}\right).\] Since we are working on finite sets, we can restrict the problem class $\Gamma$, such that $|\frac{d}{d\gamma}p(\gamma)| > C$, for some constant $C$ and all $\gamma\in\Gamma$. 
Therefore, by an application of the Mean Value Theorem, we have
\[
|p^*_{lt}(\gamma) - p^*_{lt}(\gamma_0)|
\geq C|\gamma - \gamma_0|\,.
\]
Let $\gamma_1 := \gamma_0 + 1/(4T^{1/4})$. Using the above bound, the optimal prices for $\gamma_0$ and $\gamma_1$ are apart by at least $C/(4T^{1/4})$. 

Consider two disjoint sets $D_1$ and $D_0$ of prices, as follows:
\[D_{\gamma_0} := \left\{p: |p - p^*_{lt}(\gamma_0)| \leq \frac{C}{10T^{1/4}}\right\}\,, \quad \quad D_{\gamma_1} := \left\{p: |p - p^*_{lt}(\gamma_1)| \leq \frac{C}{10T^{1/4}}\right\}.\]
Note that $D_{\gamma_0}$ and $D_{\gamma_1}$ are disjoint since $|p^*_{lt}(\gamma_1)-p^*_{lt}(\gamma_0)|\ge C/(4T^{1/4})$.

For $\gamma\in\{\gamma_0,\gamma_1\}$, if the posted price $p_{lt}$ is not in the set $D_{\gamma}$, then the instantaneous regret is at least 
\[
r_{lt}(p^*_{lt}(\gamma),\gamma) - r_{lt}(p_{lt},\gamma) \ge \frac{c}{2} (p^*_{lt}(\gamma) - p_{lt})\ge \left(\frac{cC}{20}\right)^2\frac{1}{\sqrt{T}}\,.
\]
 Hence following a similar proof strategy as in \citep[Lemma 3.4]{broder2012dynamic},
we have
\[\text{Reg}_T^{\pi,\gamma_0} + \text{Reg}_T^{\pi,\gamma_1} \geq \left(\frac{cC}{20}\right)^2\frac{1}{\sqrt{T}}\sum_{t = 1}^T\sum_{l = 1}^L n_{lt}\left(\mathbb P_{\gamma_0}(p_{lt} \notin D_{\gamma_0}) + \mathbb P_{\gamma_1}(p_{lt} \notin D_{\gamma_1})\right)\,.\]
Note that $p_{lt}$ is measurable with respect to measure $f^{\pi,\gamma}_{t-1}$ under the model $\gamma$. Therefore, by using
a standard result on the minimum error in a simple hypothesis test~\citep[Theorem 2.2]{tsybakov2004introduction}, we have
\begin{align}
\text{Reg}_T^{\pi,\gamma_0} + \text{Reg}_T^{\pi,\gamma_1} &\geq \frac{C_1}{\sqrt{T}}\sum_{t = 1}^T\sum_{l = 1}^L n_{lt} e^{-\KL\left(f_{t-1}^{\pi, \gamma_0} ; f_{t-1}^{\pi, \gamma_1}\right) }\nonumber\\
&\ge \frac{C_1}{\sqrt{T}}N_T e^{-\KL\left(f_{T}^{\pi, \gamma_0} ; f_{T}^{\pi, \gamma_1}\right) }\,,\label{eq:KL-Bound2}
\end{align}
where in the second step we used the fact that $\KL\left(f_{t}^{\pi, \gamma_0} ; f_{t}^{\pi, \gamma_1}\right)$ is non-decreasing in $t$ and $N_T:= \sum_{t=1}^T \sum_{l=1}^L n_{lt}$. 
Previously we established the lower bound~\eqref{eq:KL-Bound1}, which reads as \[\text{Reg}_T^{\pi,\gamma_0} \geq \frac{C_2}{(\gamma_0 - \gamma)^2}\KL\left(f_t^{\pi, \gamma_0} ; f_t^{\pi, \gamma}\right)\,.\]

Putting, $\gamma = \gamma_1 = \gamma_0 + 1/4T^{1/4}$ we get $\text{Reg}_T^{\pi,\gamma_0} \geq {C_2}\sqrt{T}\KL\left(f_t^{\pi, \gamma_0} ; f_t^{\pi, \gamma_1}\right)$. Combining this bound with~\eqref{eq:KL-Bound2}, we get
\begin{align*}
\max_{\gamma\in\{\gamma_0,\gamma_1\}}\text{Reg}_T^{\pi,\gamma} &\ge \frac{1}{2} \left(\text{Reg}_T^{\pi,\gamma_0}+ \text{Reg}_T^{\pi,\gamma_1}\right) \\
&\ge C\sqrt{T} \left( \KL\left(f_t^{\pi, \gamma_0} ; f_t^{\pi, \gamma_1}\right) + \frac{N_T}{T} e^{-\KL\left(f_{T}^{\pi, \gamma_0} ; f_{T}^{\pi, \gamma_1}\right) }\right)\nonumber\\
&\ge C\sqrt{T} \left(1+\log(N_T/T)\right)\,,
\end{align*}
where in the last step we used the inequality $ae^{-b} + b \ge 1+\log(a)$.

% Using the fact that $u+e^{-u} \geq 0$ for all $u\geq 0$, we get the desired $\sqrt{T}$ lower bound.

\section{Proof of Lemmas and Technical Intermediate Steps}
%\section{Propositions}
\subsection{Proof of Proposition~\ref{prop.1}}\label{proof.prop.1}
Recall that $V^2_{lt} = \| (\bm I - \rho_t \bm W)^{-1}\bm e_l\|^2\tau^2 + \sigma^2$. Since $W\succeq \bm 0$, and $\rho_t\ge0$, we have $\bm I -\rho_t \bm W\preceq \bm I$. In addition, by Assumption~\ref{assump.2}, we have $\bm I - \rho_t\bm W \succeq \varepsilon \bm I$.
Therefore, since $\|\bm e_l\| = 1$, 
\[
1\le \|(I-\rho_t \bm W)^{-1}\bm e_l\| \le \frac{1}{\varepsilon}\,,
\]
from which we obtain the result.

Next, to prove the upper bound on the optimal prices, we recall that 
$$0\le \bm x'_{lt} \bm m_{lt} \le \|\bm x_{lt}\| \|\bm{m}_{lt}\|\le \frac{\|\bm \mu_t\|}{V_{lt}}\le \frac{C_{\mu}}{c_V}\,.$$

Invoking relation~\eqref{eq:16}, and noting that $\beta_t$ and so $b_t$ are negative, we arrive at
\[
p^*_{lt} = \frac{1}{-b_{lt}} \left(\varphi^{-1}(-\bm x_{lt}'\bm m_{lt}) + \bm x_{lt}' \bm m_{lt}\right) \le c_{\beta}^{-1} C_V (C_\mu c_V^{-1} -0.5 \phi(0))\,, 
\]
where we used that $\varphi^{-1}$ is increasing, $\bm x_{lt} \ge 0$, and $\varphi^{-1}(0) = -0.5/\phi(0)$.


% Let's first analyze the term $\bm e_l (\bm I - \rho_t \bm W)^{-1}$. 

% Using assumption ~\ref{assump.1}, since $\bm W$ is a symmetric PSD matrix, we can write its singular value decomposition as $\bm W = \bm U \Lambda \bm U'$, where $\bm U$ is an orthonormal matrix and $\Lambda$ is a diagonal matrix containing all the eigenvalues of $\bm W$.

% Thus,
% \begin{align*}
%     (\bm I - \rho_t \bm W) &= \bm U \bm U' - \bm U \rho_t\Lambda \bm U'\\
%     &= \bm U (\bm I - \rho_t\Lambda) \bm U'
% \end{align*}
% Using this, we can write $\bm e_l (\bm I - \rho_t \bm W)^{-1} = \bm u_{l}'(\bm I - \rho_t\Lambda)^{-1} \bm U'$, where $\bm u_{l}$ is the $l^{th}$ row of $\bm U$.

% Hence,
% \begin{align*}
%     \|\bm e_l (\bm I - \rho_t \bm W)^{-1}\|^2 &= \bm u_{l}'(\bm I - \rho_t\Lambda)^{-1} \bm U' \bm U(\bm I - \rho_t\Lambda)^{-1}\bm u_{l}\\
%     &= \bm u_{l}'(\bm I - \rho_t\Lambda)^{-2}\bm u_{l}\\
%     &= \sum_{j = 1}^L \frac{u_{jl}^2}{(1 - \rho_t \lambda_j)^2}
% \end{align*}

% Since all the eigenvalues of $\bm W$ are positive and $\rho_t$ is positive, we have $ 1-\rho_t\lambda_j \le 1$. Also $1 - \rho_t\lambda_j \geq \varepsilon$ using Assumption ~\ref{assump.2}, by which we get $(1-\rho_t\lambda_j)^2\le 1$. Hence, $\|\bm e_l (\bm I - \rho_t \bm W)^{-1}\|^2 \geq \sum_{j = 1}^L {u_{jl}^2} = 1$.

% Finally, again using Assumption ~\ref{assump.2}, $1 - \rho_t\lambda_j \geq \varepsilon$, hence $\|\bm e_l (\bm I - \rho_t \bm W)^{-1}\|^2 \leq \sum_{j = 1}^L {u_{jl}^2}/{\varepsilon^2} = 1/\varepsilon^2$. Since, $V^2_{lt} = \|\bm e_l (\bm I - \rho_t \bm W)^{-1}\|^2\tau^2 + \sigma^2$, we get the required bounds.
%===================================
\subsection{Proof of Lemma~\ref{lemma.1}}
% Using intermediate results from proof of proposition~\ref{prop.1} in \ref{proof.prop.1}, we know that 
% \begin{align*}
%     \|\bm e_l (\bm I - \rho_t \bm W)^{-1}\|^2 
%     &= \sum_{j = 1}^L \frac{u_{jl}^2}{(1 - \rho_t \lambda_j)^2}
% \end{align*}

By definition, $V^2_{lt} = \| (\bm I - \rho_t \bm W)^{-1}\bm e_l\|^2\tau^2 + \sigma^2$. Hence, if $\omega_*$ is the smallest eigenvalue of $\bm W$, then $V^2_{lt} \geq \tau^2/(1 - \rho_t \omega_{*})^2$.

We want to bound the $|b_{l,t+1} - b_{l,t}|$ and $\|\bm m_{l,t+1} - \bm m_{l t}\|_2$.

\begin{align*}
   \|\bm m_{l,t+1} - \bm m_{l t}\|_2 &= \left\|\frac{\bm \mu_{t+1}}{V_{l,t+1}} - \frac{\bm \mu_{t}}{V_{lt}}\right\|_2\\
   &\leq \left\|\frac{\bm \mu_{t+1} - \bm \mu_{t}}{V_{l,t+1}}\right\|_2 + \bm\mu_{t}\left\{\frac{1}{V_{l,t+1}} - \frac{1}{V_{lt}}\right\}\\
   &\leq \frac{\delta_{t\mu}}{\tau/(1 - \rho_t \omega_{*})} + C_\mu \left\{\frac{1}{V_{l,t+1}} - \frac{1}{V_{lt}}\right\}\,.
\end{align*}

Further, the second term can be simplified as 
\begin{align*}
\left\{\frac{1}{V_{l,t+1}} - \frac{1}{V_{lt}}\right\} = \frac{V_{lt} - V_{l,t+1}}{V_{l,t+1}V_{lt}} &= \frac{V_{lt}^2 - V_{l,t+1}^2}{V_{l,t+1}V_{lt}(V_{lt}+V_{l,t+1})}\nonumber\\
&\leq \frac{1}{2c_V^3} (V_{lt}^2 - V_{l,t+1}^2)\nonumber\\
&\le\frac{\tau^2}{2c_V^3} (\| (\bm I - \rho_t \bm W)^{-1}\bm e_l\|^2-\| (\bm I - \rho_{t+1} \bm W)^{-1}\bm e_l\|^2)\le C\delta_{t\rho}\,.
%
% \sum_{j = 1}^L u_{jl}^2 \left(\frac{1}{(1-\rho_{t}\lambda_{j})^2} - \frac{1}{(1-\rho_{t+1}\lambda_j)^2}\right) \leq C\delta_{t\rho}
\end{align*}

The same analysis can be done for $|b_{l,t+1} - b_{lt}|$ as well.
%===============
%\section{Corollary}
\subsection{Proof of Corollary~\ref{cor.2}}

The corollary follows directly by applying the results from Lemma~\ref{lemma.1} in Theorem~\ref{thm.1}. Since $\rho_t = \rho$ for all $t$, hence $\delta_{t\rho} = 0$.

Since $\eta_t\propto 1/\sqrt{t}$, we get 
\begin{itemize}
    \item $\mathcal{R}_1 = LC_1C\tau^{-1}(1 - \rho \omega_*)\sum_{t = 1}^T \sqrt{t}\delta_{t\beta}$,
    \item $\mathcal{R}_2 = LC_1C\tau^{-1}(1 - \rho \omega_*)\sum_{t = 1}^T \sqrt{t}\delta_{t\mu}$,
    \item $\mathcal{R}_3 = C_3C\sum_{t = 1}^Tn_t^2/\sqrt{t} = \mathcal{O}(\sqrt{T})$,
    \item $\mathcal{R}_4 = C_4CL(C_b + C_m)\sqrt{T+1} = \mathcal{O}(\sqrt{T})$\,.
\end{itemize}

Changing the constants appropriately gives us the corollary.

%================
\subsection{Proof of Lemma~\ref{cor.1}}\label{append.cor.1}
Consider the particular set-up when $\bm{\mu}_t=0$, $\beta_t=\beta$, $\rho_t=\rho$ and $\sigma=1$ in \eqref{eq:2}. 
Further, assume $n_{lt}=n$ for all $l, t$ and $n \to \infty$.  
The proof can easily be extended to the generic set-up. Under these parametric assumptions, first note that, $\text{Rev}(\bm{\lambda},l,t,p_{lt})=n p_{lt}\Phi(\alpha_{lt}+\beta p_{lt})$.
The optimal pricing strategy $p_{lt}^*$ maximizes $\text{Rev}(\bm{\lambda},l,t,p_{lt})$ over $p_{lt}$ for any fixed $\bm{\lambda}$. 

Now, consider an arbitrary pricing policy ${\bm{p}}$ based on the unpenalized likelihood $\text{PL}(\bm{\lambda},0)$. Such a policy will be dominated by its oracle counter-part ${\bm{p}}^{\text{or}}$ which already knows the price coefficient $\beta$ and also, knows the latent utility $U_{lt}$. Note that, the revenue of any pricing policy ${\bm{p}}$ based on the unpenalized likelihood is always dominated by the revenue of this oracle strategy, i.e., 
$\text{Rev}(\bm{\lambda},{\bm{p}})\leq \text{Rev}(\bm{\lambda},{{\bm{p}}}^{\text{or}})$. Subsequently,  the oracle strategy ${{\bm{p}}}^{\text{or}}$ will have a lower regret.    
Next, we concentrate on the regret of ${\bm{p}}^{\text{or}}$. 

For this calculation note that based on model \eqref{eq:2}, the only unknown parameters for the oracle strategy 
$\bm{p}^{\text{or}}$ are the $\alpha_{lt}$s. Under this framework consider $\alpha_{lt}$s being best estimated by $\hat{\alpha}_{lt}^{\text{or}}$. 

Now, note that as we do not have any structural assumption between $\bm{\alpha}_t$ and $\bm{\alpha}_{t+1}$ over $t=1,\ldots,T$, for any $t$,  $\hat{\alpha}_{lt}^{\text{or}}$ will be estimated based on $\{U_{ltk}:l=1,\ldots,L; k=1,\ldots,n\}$. 
As the prices $p_{lt}$ are known (based on the filtration $\mathcal{F}_{t-1}$ which contains all information up to time $t-1$) this further reduces to estimating the the $L$ means $\bm{\alpha}_{t}$ from  uncorrelated $L$ dimensional Gaussian location model where we observe $n^{-1}\sum_{k=1}^n U_{ltk}-\beta p_{lt}$ for $l=1,\ldots,L$. From the Cramer-Rao lower bound for Gaussian family, it follows that for all $l=1,\ldots,L$, we will have the following error bound on any estimate $\hat{\alpha}_{lt}$: 
$$\mathbb{E}_{\bm{\lambda}}(\hat{\alpha}_{lt}-\alpha_{lt})^2 \geq n^{-1}.$$
As such consider the $\alpha_{lt}$s under the oracle framework to be estimated by the MLE. Let $\hat{\delta}_{lt}=\hat{\alpha}_{lt}^{\text{or}}-\alpha_{lt}$. Then, noting that the MLE is asymptotically rotation invariant in this case, we have for any $\bm{\lambda}$: 
\begin{align}\label{temp.11}
\mathbb{E}_{\bm{\lambda}}\,\hat{\bm{\delta}}_{t}\hat{\bm{\delta}}_{t}^T= n^{-1} I_L~ \text{ and } \mathbb{E}_{\bm{\lambda}}\,\hat{\bm{\delta}}_{t} \to \bm{0} \text{ as } n \to \infty.
\end{align}
%
Now, note that for the oracle strategy, 
$$\text{Rev}(\bm{\lambda},l,t,p_{lt}^{\text{or}})= \max_{p\geq 0} n p\, \Phi(\hat{\alpha}_{lt}^{\text{or}}+\beta p)= \max_{p\geq 0} n p\, \Phi(\hat{\delta}_{lt} +{\alpha}_{lt}+\beta p)~.$$
Let $f(l,t,p)= n p\, \Phi(\hat{\delta}_{lt} +{\alpha}_{lt}+\beta p)$. Consider Taylor-Series expansion: 
$$ f(l,t,p)= n p\, \Phi({\alpha}_{lt}+\beta p) + n \,\hat{\delta}_{lt}\, p\, \phi({\alpha}_{lt}+\beta p) + 2^{-1} n p\, \hat{\delta}_{lt}^2 \phi'({\alpha}_{lt}+\beta p)+r(l,t,p),$$
where $r(l,t,p)$ contains third and higher order terms. Now, we have ${L}^{-1}\sum_l f(l,t,p_{lt})$ converges in probability to 
$$\frac{1}{L}\sum_l n p_{lt}\, \Phi({\alpha}_{lt}+\beta p_{lt}) + \frac{1}{L}\sum_l n \, p_{lt} \phi({\alpha}_{lt}+\beta p_{lt}) \mathbb{E}_{\bm{\lambda}} \hat{\delta}_{lt} + \frac{1}{2L}\sum_l   n p_{lt}  \phi'({\alpha}_{lt}+\beta p_{lt}) \mathbb{E}_{\bm{\lambda}} \hat{\delta}_{lt}^2,$$
as $L^{-1}\sum_l r(l,t,p_{lt}) \to 0$ in probability as $n\, \mathbb{E}_{\bm{\lambda}} \hat{\delta}_{lt}^{2+m}=O(n^{-m/2})$, for $m\geq 1$. Using \eqref{temp.11}, the second term in the above expression vanishes and the third term gets further simplified, resulting in the following asymptotic result: 
$$\frac{1}{L}\sum_l f(l,t,p_{lt})=n \bigg[\frac{1}{L}\sum_l  p_{lt}\, \Phi({\alpha}_{lt}+\beta p_{lt})\bigg]
+ \frac{1}{2L}\sum_l   p_{lt}  \phi'({\alpha}_{lt}+\beta p_{lt})+{o}(1)~.$$
Thus, the regret of ${\bm{p}}^{\text{or}}$ at time $t$ is given by
 \begin{align}\label{temp12}
 L^{-1}\sum_{l=1}^L\mathcal{R}_{lt}(\bm{\lambda},{\bm{p}}^{\text{or}})\geq (\mathcal{A} -\mathcal{B})/L +o(1),
 \end{align}
where, 
\begin{align*}
\mathcal{A}&=\max_{p_{lt}: l=1,\ldots,L} \bigg[\sum_l n p_{lt}\, \Phi({\alpha}_{lt}+\beta p_{lt})\bigg], \text{ and } \\
\mathcal{B}&=\max_{p_{lt}: l=1,\ldots,L} \bigg[ \sum_l n p_{lt}\, \Phi({\alpha}_{lt}+\beta p_{lt})
- 2^{-1}\sum_l   p_{lt} ({\alpha}_{lt}+\beta p_{lt}) \phi({\alpha}_{lt}+\beta p_{lt})\bigg].
\end{align*}
Note that, the expression in $\mathcal{B}$ is simplified using $\phi'(u) = -u\phi(u)$. Now recall that $\beta$, being the price sensitivity, is negative. 
Based on model \eqref{eq:2}, for the utilities to be positive we have the following assumption of the price: ${\alpha}_{lt}+\beta p_{lt}>0$ for all $l$ and $t$. Let the prices be selected such that $\inf_{l} {\alpha}_{lt}+\beta p_{lt}>\epsilon_0$ for some prefixed small $\epsilon_0 >0$. By Proposition~\ref{prop.1}, the optimal prices are bounded and so are $\sup_l \alpha_{lt}+\beta p_{lt}<M_0$.  Then, 
$$\mathcal{A}-\mathcal{B}\geq 2^{-1} \epsilon \sum_l p_{lt}^*,$$
where $p_{lt}^*$ is the optimal price based on criterion $\mathcal{B}$, and $\epsilon = \min_{\epsilon_0<|u|<M'} u\phi(u)$. 
Thus, the cumulative regret of ${\bm{p}}^{\text{or}}$ over time is given by %\adel{It is strange that it is $O(T)$. I expect it to be $O(\sqrt{T})$ based on our other bounds.}
 \begin{align*}
 \mathcal{R}(\bm{\lambda},{\bm{p}}^{\text{or}})=\sum_{t=1}^T\sum_{l=1}^L\mathcal{R}_{lt}(\bm{\lambda},{\bm{p}}^{\text{or}})= \Omega(LT).
 \end{align*}
 Thus, we have, 
 \begin{align*}
 \mathcal{B}(\bm{\theta},{\bm{p}}_U)= \Omega(LT). 
 \end{align*}
Now, consider the regret from the proposed strategy. Based on \eqref{eq:23.1}, we have
\begin{align*}
   \mathcal{B}(\bm{\theta},\bm{p})\leq  &{C}_6 {\tau}^{-1}({1 - \rho_{*}\omega_*})\sum_{t = 1}^T\sqrt{t}({\delta_{t\beta} + \delta_{t\mu}})  + C_7 \sum_{t = 1}^T \sqrt{t}\delta_{t\rho} + \mathcal{O}(\sqrt{T})=\mathcal{O}(\sqrt{T}),
\end{align*}
where, the second asymptotic result follows as 
$\sum_{t = 1}^T \sqrt{t}\delta_{t\beta}$, $\sum_{t = 1}^T \sqrt{t}\delta_{t\mu}$ and
$\sum_{t = 1}^T \sqrt{t}\delta_{t\rho}$ are all bounded above by $\mathcal{O}(\sqrt{T})$. Comparing the above two displays the result follows. 
\begin{comment}
For the proposed strategy, $\beta$ being invariant over time will be estimated with very high precision. As such $\ex_{\bm{\lambda}} (\hat \beta_t -\beta)^2=O((nLt)^{-1})$. 
Using the $n \to \infty$ asymptotic for curved exponential families it follows that the estimates $\hat{\bm{\alpha}}_t$ based on the proposed strategy follows: 
\begin{align}\label{temp13}
\hat{\bm{\alpha}}_t \stackrel{d}{=} N_L(\bm{\alpha},n^{-1}\tau^2(I-\rho W)^{-1}\mathbb{V} \,(I-\rho W)^{-1}),
\end{align}
where $\mathbb{V}$ is a diagonal matrix with $\mathbb{V}_{ll}= \{q_{lt}(1-q_{lt})\}^{-1/2}$ where $q_{lt}=\Phi(\alpha_{lt}+\beta p_{lt})$. Let $\hat{\bm{\eta}}_t=\hat{\bm{\alpha}}_t-\bm{\alpha}_t$. Then, by an exactly similar calculation as above, we get that the regret of the proposed strategy is:  
 \begin{align*}
L^{-1}\sum_{l=1}^L\mathcal{R}_{lt}(\lambda,\hat{\bm{p}})\leq (\mathcal{A} -\mathcal{C})/L +o(1),
 \end{align*}
where, 
\begin{align*}
\mathcal{C}&= \sum_l n \tilde p_{lt}\, \Phi({\alpha}_{lt}+\beta \tilde p_{lt})
- 2^{-1} \ex_{\lambda} [\hat{\bm{\eta}}_t^T \mathbb{D} \hat{\bm{\eta}}_t],
\end{align*}
where $D$ is a diagonal matrix with $D_{ll}=\tilde p_{lt} ({\alpha}_{lt}+\beta \tilde p_{lt}) \phi({\alpha}_{lt}+\beta \tilde p_{lt})$, and $\tilde p_{lt}$ are the prices based on the algorithm which uses the filtration $\mathcal{F}_{t-1}$. Based on \eqref{temp13}, we have
$$\mathcal{C}= \sum_l n \tilde p_{lt}\, \Phi({\alpha}_{lt}+\beta \tilde p_{lt})
- 2^{-1} \tau^2  \text{tr}((I-\rho W)^{-1}\mathbb{V}(I-\rho W)^{-1}\mathbb{D}).$$ 
The second term on the right side above is upper bounded by $c_0\, \tau^2\,\text{tr}(I-\rho W)^{-2}$, where $c_0$ is a constant. As $t$ increases, the prices $\tilde p_{lt}$ are close to $p_{lt}^*$  in this asymptotic regime which implies $\mathcal{A}-\mathcal{C}\leq c_0\, \tau^2 \text{tr}\{(I-\rho W)^{-2}\}$. Thus, the regret of the proposed strategy is \adel{I do not follow the above calculations as it is written cryptic. But I feel that in the bound below an inverse and power are off. I expect it to be $\tau^{-1} \sqrt{T} \text{tr}\{(I-\rho W)\}$, based on Corollary~\ref{cor.2}. Please take a look and also update the Lemma statement to the most rigorous result.}

$$\mathcal{R}(\bm{\lambda},\hat{\bm{p}})\leq c_0 \tau^2 T \, \text{tr}\{(I-\rho W)^{-2}\},$$
where $c_0$ is a constant independent of $T$, $L$ and $n$. Given that $L:=L(T)$ diverges as $T\to\infty$, the result follows when $\tau^2 \text{tr}\{(I-\rho W)^{-2}\}/L \to 0$ as $T \to \infty$. 
\end{comment}
%================
\subsection{Proof of Proposition~\ref{prop.2}}


    Consider the revenue function given by~\eqref{eq:Rev-mod}, $\text{Rev}_{lt}(p) = n_{lt}p\Phi(b_{lt}p + \bm x_{lt}'\bm m_{lt})$. By definition, $p_{lt}^*$ is the maximizer of $\text{Rev}_{lt}(p)$ and hence $\text{Rev}_{lt}'(p_{lt}^*) = 0$. Using Taylor series expansion around $p_{lt}^*$, we get
    \[\mathcal{R}_{lt} = \text{Rev}_{lt}(p_{lt}^*) - \text{Rev}_{lt}(p_{lt}) = \frac{1}{2}\text{Rev}''_{lt}(p)(p_{lt} - p_{lt}^*)^2,\]
    for some $p$ between $p_{lt}$ and $p_{lt}^*$. The second derivative can be bounded as 
    
     \[\frac{1}{2}\text{Rev}_{lt}''(p) = n_{lt} \frac{2b_{lt} \phi(b_{lt}p + \bm x_{lt}'\bm m_{lt}) + p b_{lt}^2 \phi'(b_{lt}p + \bm x_{lt}'\bm m_{lt})}{2} \leq \left(C_b \phi(0) + M C_b^2 \frac{\phi(0)}{\sqrt{2}}\right) n_{lt}.\]

Setting $C_9 =  C_b \phi(0) + M C_b^2 \frac{\phi(0)}{\sqrt{2}}$ completes the proof.


% The final lemma we use creates the link between the estimation error in Lemma ~ \ref{lemma.2} and the components of the regret in Theorem ~ \ref{thm.1}. 

%========================
\subsection{Proof of Lemma~\ref{lemma.2}}

We have the true parameters $b_{lt}, \bm{m}_{lt}$ and the output $\hat{b}_{lt}, \hat{\bm{m}}_{lt}$ from our PSGD pricing policy. Also, $p_{lt}$ and $p_{lt}^*$ are the price based on our policy and the optimal price based on the true parameters, respectively. 

As discussed in section~\ref{sec:2.3}, we can write the prices in terms of the utility model parameters using the function $g(\cdot,\cdot)$, as follows: 
%
\begin{align*}
    p_{lt}^* := g(b_{lt}, \bm m_{lt}) =  -\frac{\varphi^{-1}(-\bm{x}_{lt}' {\bm m}_{lt}) + \bm{x}_{lt}' {\bm m}_{lt}}{b_{lt}} ~,\\
    p_{lt} := g(\hat{b}_{lt}, \hat{\bm m}_{lt}) =  -\frac{\varphi^{-1}(-\bm{x}_{lt}' \hat{\bm m}_{lt}) + \bm{x}_{lt}' \hat{\bm m}_{lt}}{\hat{b}_{lt}} ~.
 \end{align*}
    Now we can bound $(p_{lt} - p_{lt}^*)^2$ as
    \begin{align*}
        &(p_{lt} - p_{lt}^*)^2 \\
        &= \left(\frac{\varphi^{-1}(-\bm{x}_{lt}' {\bm m}_{lt}) + \bm{x}_{lt}' {\bm m}_{lt}}{b_{lt}}-\frac{\varphi^{-1}(-\bm{x}_{lt}' \hat{\bm m}_{lt}) + \bm{x}_{lt}' \hat{\bm m}_{lt}}{\hat{b}_{lt}}\right)^2\\
        &= \left(\frac{\varphi^{-1}(-\bm{x}_{lt}' {\bm m}_{lt}) + \bm{x}_{lt}' {\bm m}_{lt}}{b_{lt}} -\frac{\varphi^{-1}(-\bm{x}_{lt}' \hat{\bm m}_{lt}) + \bm{x}_{lt}' \hat{\bm m}_{lt}}{b_{lt}} + \left(\varphi^{-1}(-\bm{x}_{lt}' \hat{\bm m}_{lt}) + \bm{x}_{lt}' \hat{\bm m}_{lt}\right)\left(\frac{1}{b_{lt}} - \frac{1}{\hat{b}_{lt}}\right)\right)^2\\
        &\leq 2\left(\frac{\varphi^{-1}(-\bm{x}_{lt}' {\bm m}_{lt}) + \bm{x}_{lt}' {\bm m}_{lt}}{b_{lt}} -\frac{\varphi^{-1}(-\bm{x}_{lt}' \hat{\bm m}_{lt}) + \bm{x}_{lt}' \hat{\bm m}_{lt}}{b_{lt}}\right)^2 + 2\left(\varphi^{-1}(-\bm{x}_{lt}' \hat{\bm m}_{lt}) + \bm{x}_{lt}' \hat{\bm m}_{lt}\right)^2\left(\frac{1}{b_{lt}} - \frac{1}{\hat{b}_{lt}}\right)^2\\
        &\leq \frac{2 C_V^2}{c_\beta^2}\left(({\varphi^{-1}(-\bm{x}_{lt}' {\bm m}_{lt}) + \bm{x}_{lt}' {\bm m}_{lt}}) - ({\varphi^{-1}(-\bm{x}_{lt}' \hat{\bm m}_{lt}) + \bm{x}_{lt}' \hat{\bm m}_{lt}})\right)^2 + 2p_{lt}^2 \left(\frac{b_{lt}-\hat{b}_{lt}}{b_{lt}} \right)^2\,,
    \end{align*}
    where we used the bound $|b_{lt}|= |\beta_t|/V_{lt}\ge c_\beta/C_V$ and the policy rule $p_{lt} = g(\hat{b}_{lt}, \hat{\bm m}_{lt})$.
    
  Since, $\varphi^{-1}(-v)+v$ is 1-Lipschitz, we have 
  \[\left(({\varphi^{-1}(-\bm{x}_{lt}' {\bm m}_{lt}) + \bm{x}_{lt}' {\bm m}_{lt}}) - ({\varphi^{-1}(-\bm{x}_{lt}' \hat{\bm m}_{lt}) + \bm{x}_{lt}' \hat{\bm m}_{lt})}\right)^2  \leq \inner{\bm x_{lt}} {\bm m_{lt} - \hat{\bm m}_{lt}}^2\,. \]

Therefore, we have
\begin{align*}
(p_{lt} - p_{lt}^*)^2 \le 
\frac{2C_V^2}{c_\beta^2} \inner{\bm x_{lt}}{\bm m_{lt}-\hat{\bm{m}}_{lt}}^2 
+\frac{2C_V^2}{c_\beta^2}p_{lt}^2(b_{lt}-\hat{b}_{lt})^2\,.
\end{align*}
% Assuming that the value of the product $\bm x_{lt}'\bm m_{lt}$ is positive, price can be lower bounded as $\varphi^{-1}(0)/C_b$. With this the second term $\left(\tfrac{1}{b_{lt}} - \tfrac{1}{\hat{b}_{lt}}\right)^2$ can be bounded as 

% \[\left(\frac{1}{b_{lt}} - \frac{1}{\hat{b}_{lt}}\right)^2 \leq \left(\frac{C_b}{c_b\varphi^{-1}(0)}\right)^2(p_{lt}(b_{lt} - \hat{b}_{lt}))^2.\]

Setting $C_{10} = \frac{2C_V^2}{c_\beta^2}$ proves the lemma.


%\end{proof}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\bibliography{Bibliography-MM-MC,robust_learning_bib}
\bibliographystyle{agsm}
\end{document}