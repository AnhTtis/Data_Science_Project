\section{Related Work}
The base of our work is the neural radiance field (NeRF) formulation initially introduced in~\cite{mildenhall2020nerf}. This work describes a trainable radiance field parameterized with a neural network. Subsequent works have addressed the main limitations of the original approach, such as the slow training speed~\cite{mueller2022instant}, anti-aliasing effects or the ability to model unbounded scenes~\cite{barron2022mipnerf360}. Another main caveat of the original formulation is the lack of accurate underlying geometry, mostly caused by the fact that NeRFs are optimized exclusively for visual consistency. This gives way for the network to create occupancy regions to support the volumetric rendering process even when particular parts of the space are not occupied by an underlying surface. Additional supervision signals, such as depth~\cite{kangle2021dsnerf, roessle2022depthpriorsnerf} are effective in regularizing the geometry, but require additional input modalities which might be difficult to source. In contrast, our work relies on NeRF networks trained from images.

An alternative to radiance fields is to learn a Signed Distance Function (SDF)~\cite{wang2021neus, oechsle2021unisurf, yariv2021volume}. A high-quality mesh can be extracted by means of marching cubes or similar approaches.  \cite{munkberg2021nvdiffrec} combines this approach with a tetrahedral grid that is optimized during training, followed by differentiable rasterizer to recover materials and lighting. However, this method is constrained by the choice of the grid resolution at training time. Compared to \cite{munkberg2021nvdiffrec}, our method does not rely on a fixed grid template during training, enabling us to reconstruct at any arbitrary resolution afterwards.  Similarly, \cite{yariv2020multiview} uses an SDF with sphere tracing to determine the intersection with the surface.  In this work, we are mainly interested in obtaining a unique and geometrically accurate 3D mesh surface from NeRF methods. We exploit the adaptive power of NeRFs to be able to robustly represent 3D scenes in a range of conditions and environments. In particular, we do not require any changes to the NeRF architecture in order to compute a surface. Also differentiable mesh rasterizers often suffer from optimization issues which are easily avoidable in differentiable volumetric rendering adopted by the NeRF methods.


Recent approaches advance speed and geometric accuracy of NeRFs. SNeRG~\cite{hedman2021snerg} has achieved real-time rendering of radiance fields by restructuring the original NeRF architecture to precompute the predicted density, view-independent colors and feature vectors in a sparse voxel grid. A separate  view-dependent network runs online to compute the final color. It results in a real-time visualization with a good trade-off in image quality, however, the underlying geometry is not well defined. MobileNeRF~\cite{chen2022mobilenerf} builds on a similar principle, but relies on a triangle mesh that is optimized during training as the underlying geometry. However, the final geometry is far from being accurate. As the method relies on a single resolution grid at training time, the faces from the triangle soup cannot fit detailed regions. Moreover, multiple layers of faces can sometimes describe the same surface during optimization leading to inaccurate geometry to support the rendering loss. Voxel grids are also a viable alternative to efficiently store geometry ~\cite{yu2021plenoctrees,yu_and_fridovichkeil2021plenoxels} and have efficient renderings. However, they are inherently constrained by the grid resolution and can suffer from discretization artifacts.
