{
    "arxiv_id": "2303.11793",
    "paper_title": "OTJR: Optimal Transport Meets Optimal Jacobian Regularization for Adversarial Robustness",
    "authors": [
        "Binh M. Le",
        "Shahroz Tariq",
        "Simon S. Woo"
    ],
    "submission_date": "2023-03-21",
    "revised_dates": [
        "2023-10-16"
    ],
    "latest_version": 2,
    "categories": [
        "cs.CV"
    ],
    "abstract": "The Web, as a rich medium of diverse content, has been constantly under the threat of malicious entities exploiting its vulnerabilities, especially with the rapid proliferation of deep learning applications in various web services. One such vulnerability, crucial to the fidelity and integrity of web content, is the susceptibility of deep neural networks to adversarial perturbations, especially concerning images - a dominant form of data on the web. In light of the recent advancements in the robustness of classifiers, we delve deep into the intricacies of adversarial training (AT) and Jacobian regularization, two pivotal defenses. Our work {is the} first carefully analyzes and characterizes these two schools of approaches, both theoretically and empirically, to demonstrate how each approach impacts the robust learning of a classifier. Next, we propose our novel Optimal Transport with Jacobian regularization method, dubbed~\\SystemName, jointly incorporating the input-output Jacobian regularization into the AT by leveraging the optimal transport theory. In particular, we employ the Sliced Wasserstein (SW) distance that can efficiently push the adversarial samples' representations closer to those of clean samples, regardless of the number of classes within the dataset. The SW distance provides the adversarial samples' movement directions, which are much more informative and powerful for the Jacobian regularization. Our empirical evaluations set a new standard in the domain, with our method achieving commendable accuracies of 51.41\\% on the ~\\CIFAR-10 and 28.49\\% on the ~\\CIFAR-100 datasets under the AutoAttack metric. In a real-world demonstration, we subject images sourced from the Internet to online adversarial attacks, reinforcing the efficacy and relevance of our model in defending against sophisticated web-image perturbations.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.11793v1",
        "http://arxiv.org/pdf/2303.11793v2"
    ],
    "publication_venue": null
}