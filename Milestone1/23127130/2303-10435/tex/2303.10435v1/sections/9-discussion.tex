\section{Modeling the Trade-off of Privacy Preservation and Activity Recognition}
\label{sec:discussion}

In this paper, our goal is to present a method to model the trade-off between privacy preservation and machine recognition. We have obtained the estimation results of the main components in Equation~\ref{eq:problem}. In this section, we take all these results into consideration and explain how we can utilize them to model the trade-off between privacy preservation and machine recognition. Based on our modeling results, we further present how to apply our model to applications.

\subsection{Build the Model Using the Parameters from the Studies}

To summarize, we have investigated users' perceived importance of different privacy features under high or low image resolutions in section~\ref{sec:study1}. We chose users' rating of these privacy features under high-resolution image condition as the importance weight $\omega_i$ in the model, which was shown in Table~\ref{tab:privacy_importance}. 
Next, we examined both human's and the machine's recognition performance under varying resolutions in order to obtain an approximation of the evaluation function $L_T$ and $L_P$ in our formulation.
% Section~\ref{sec:dataset} described the dataset we used to explore the effect of image resolution on human's and the machine's performance. 
% In section~\ref{sec:study2}, we conducted a user study to understand human performance in recognizing main activities and privacy features. 
% In section~\ref{sec:study3}, we utilized open-access cutting-edge deep learning methods to explore the machine's recognition abilities on the same tasks. 
In realistic environments, intelligent applications may rely on either humans or machines to obtain private information from raw images. Therefore, we take both human and machine recognizers into consideration to preserve privacy features in a comprehensive way. For the main recognition task $T$, which is activity recognition in our implementation, the Vision Transformer outperforms all other models including humans even on extremely low-resolution videos from the dataset. Therefore, we choose the Vision Transformer as our final recognition function $f_T$ and the evaluation results of the Vision Transformer $L_T$ have been demonstrated in Table~\ref{tab:us3_result}. For each privacy feature $P_i$ including nudity, identifiable face, valuable property, and relationship, we found that humans are generally more effective recognizers compared with machines, especially on ultra-low-resolution videos from the dataset. Therefore, we consider humans as the final $f_{P_i}$ in our calculation. The evaluation results of each  $L_{P_i}$ we are going to use has been depicted in Figure~\ref{fig:us2_result}.

\subsection{Calculating the Objective Function}

Based on the results of $L_T$, $L_{P_i}$, and $\omega_i$ we have discussed above, we can calculate the objective function $S(r)$ in Equation~\ref{eq:problem} for each resolution we have sampled. Figure~\ref{fig:calculation_result} illustrates how the values of our objective function $S(r)$ change with resolutions $r$. The scaling factor $\lambda$ in our formulation indicates the sensitivity ratio of privacy preservation over activity recognition which can be flexibly adjusted according to the deployment environment or user experience. Here we have only shown the cases for three different lambda values, including $0.75$, $1.00$, and $1.25$. 

As is demonstrated in Figure~\ref{fig:calculation_result}, the value of the objective function $S(r)$ shows a trend of first increasing and then decreasing with the increase of resolution $r$. For the case where lambda is $1.00$, the objective function takes its maximum value at a resolution between $20\times 20$ and $30\times 30$, which indicates a proper resolution for balancing privacy preservation and activity recognition. Such an image resolution value can be easily extended to a certain image resolution range where the trade-off result is also acceptable. However, the objective function takes a low value when the resolution is too low (e.g., $15\times 15$) or too high (e.g., $240\times 240$). The reason behind this is also consistent with our expectations. When the image resolution is too low, although the privacy features can be better preserved, the machine's ADLs recognition performance is far from satisfactory. On the contrary, high image resolution may greatly increase the risk of privacy feature leakage except for improving ADLs recognition performance. 

Here we also noticed that as the scaling factor $\lambda$ increases, the maximum point of the objective function is also shifted to the left in Figure~\ref{fig:calculation_result}. Such a finding shows that a lower resolution of the image sensor is required if users are more concerned with privacy preservation compared with activity recognition performance. 

\subsection{Applying the Model and the Modeling Method to Applications}
In this section, we present how to apply our method and model to privacy-preserving machine recognition applications.

\subsubsection{Deployment to a Real Scenario Application}
When deploying a real scenario application based on our method, one can install an ultra-low-resolution (e.g., $20 \times 20$ pixels) image sensor with an edge computer running a machine learning method for ADLs recognition at home. To apply our framework for quantifying the trade-off between privacy preservation and activity recognition, one first needs to determine the sensitivity indicator $\lambda$ in Equation~\ref{eq:problem}, which is closely related to deployment environment and user experience. In our ADLs recognition example, the bathroom is a more visual privacy-sensitive location than the kitchen. Therefore, we would expect the image sensor in the bathroom having a lower resolution to preserve more visual privacy. 
Second, with the development of computer vision technologies, the performance of machine recognition on both activities and privacy features will exceed the current results stated in this paper. Future designers just need to fine-tune the results of the evaluation function $L_T$ and $L_P$ by selecting better recognizers $f_T$ and $f_P$ to consider the results of these technological advances.  
Third, one can leverage activities' probability distribution regarding the different environments in a home environment which may have an effect on the results of the evaluation function $L_T$ and $L_P$ in our formulation. For instance, personal and toilet hygiene is highly possible to happen in the restroom, while feeding is highly possible to occur in the kitchen. Future designers need to modify their training and evaluation data set according to the probability distribution of activities of daily living (ADLs) in different scenarios.

\subsubsection{Generalization to Other Applications}
For other computer vision based applications in a real scenario, we believe that our pipeline and method can be easily adapted. For instance, using an always-on low-resolution camera on AR glasses for activity recognition, or using a low-resolution smartphone camera for hand gesture recognition, etc. Even though different applications have their own usage scenarios with different visual privacy features, our method's key idea and basic framework can still be used efficiently. 
Although low-resolution image sensors can preserve visual privacy from the hardware level, deploying the hardware itself costs a large of human labor and money. Instead of purchasing the low-resolution image sensor, we can simply update the firmware to limit the camera's resolution, turning them to low-resolution image sensors. Further, we can attach an additional layer or lens on top of available commercial RGB cameras. For instance, we can add a piece of frosted glass, or a lens built for the Passive Infrared (PIR) motion sensor to the commodity cameras ~\footnote{https://en.wikipedia.org/wiki/Passive\_infrared\_sensor}. Most of these camera system parameter selection issues can be discussed and solved in a more generalized way of our methods.

\input{figures/result_score.tex}
