
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{
bose2022controllable,
title={Controllable Generative Modeling via Causal Reasoning},
author={Joey Bose and Ricardo Pio Monti and Aditya Grover},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2022},
url={https://openreview.net/forum?id=Z44YAcLaGw},
note={}
}

@misc{
bose2022cage,
title={{CAGE}: Probing Causal Relationships in Deep Generative Models},
author={Joey Bose and Ricardo Pio Monti and Aditya Grover},
year={2022},
url={https://openreview.net/forum?id=VCD05OEn7r}
}

@inproceedings{
kocaoglu2018causalgan,
title={Causal{GAN}: Learning Causal Implicit Generative Models with Adversarial Training},
author={Murat Kocaoglu and Christopher Snyder and Alexandros G. Dimakis and Sriram Vishwanath},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=BJE-4xW0W},
}

@article{
kunzel2019,
author = {Sören R. Künzel  and Jasjeet S. Sekhon  and Peter J. Bickel  and Bin Yu },
title = {Metalearners for estimating heterogeneous treatment effects using machine learning},
journal = {Proceedings of the National Academy of Sciences},
volume = {116},
number = {10},
pages = {4156-4165},
year = {2019},
doi = {10.1073/pnas.1804597116},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1804597116},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1804597116},
abstract = {There is growing interest in estimating and analyzing heterogeneous treatment effects in experimental and observational studies. We describe a number of metaalgorithms that can take advantage of any supervised learning or regression method in machine learning and statistics to estimate the conditional average treatment effect (CATE) function. Metaalgorithms build on base algorithms—such as random forests (RFs), Bayesian additive regression trees (BARTs), or neural networks—to estimate the CATE, a function that the base algorithms are not designed to estimate directly. We introduce a metaalgorithm, the X-learner, that is provably efficient when the number of units in one treatment group is much larger than in the other and can exploit structural properties of the CATE function. For example, if the CATE function is linear and the response functions in treatment and control are Lipschitz-continuous, the X-learner can still achieve the parametric rate under regularity conditions. We then introduce versions of the X-learner that use RF and BART as base learners. In extensive simulation studies, the X-learner performs favorably, although none of the metalearners is uniformly the best. In two persuasion field experiments from political science, we demonstrate how our X-learner can be used to target treatment regimes and to shed light on underlying mechanisms. A software package is provided that implements our methods.}}




@article{
athey2016,
author = {Susan Athey  and Guido Imbens },
title = {Recursive partitioning for heterogeneous causal effects},
journal = {Proceedings of the National Academy of Sciences},
volume = {113},
number = {27},
pages = {7353-7360},
year = {2016},
doi = {10.1073/pnas.1510489113},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1510489113},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1510489113},
abstract = {In this paper we propose methods for estimating heterogeneity in causal effects in experimental and observational studies and for conducting hypothesis tests about the magnitude of differences in treatment effects across subsets of the population. We provide a data-driven approach to partition the data into subpopulations that differ in the magnitude of their treatment effects. The approach enables the construction of valid confidence intervals for treatment effects, even with many covariates relative to the sample size, and without “sparsity” assumptions. We propose an “honest” approach to estimation, whereby one sample is used to construct the partition and another to estimate treatment effects for each subpopulation. Our approach builds on regression tree methods, modified to optimize for goodness of fit in treatment effects and to account for honest estimation. Our model selection criterion anticipates that bias will be eliminated by honest estimation and also accounts for the effect of making additional splits on the variance of treatment effect estimates within each subpopulation. We address the challenge that the “ground truth” for a causal effect is not observed for any individual unit, so that standard approaches to cross-validation must be modified. Through a simulation study, we show that for our preferred method honest estimation results in nominal coverage for 90\% confidence intervals, whereas coverage ranges between 74\% and 84\% for nonhonest approaches. Honest estimation requires estimating the model with a smaller sample size; the cost in terms of mean squared error of treatment effects for our preferred method ranges between 7–22\%.}
}

@article{holland86,
 ISSN = {01621459},
 URL = {http://www.jstor.org/stable/2289064},
 abstract = {Problems involving causal inference have dogged at the heels of statistics since its earliest days. Correlation does not imply causation, and yet causal conclusions drawn from a carefully designed experiment are often valid. What can a statistical model say about causation? This question is addressed by using a particular model for causal inference (Holland and Rubin 1983; Rubin 1974) to critique the discussions of other writers on causation and causal inference. These include selected philosophers, medical researchers, statisticians, econometricians, and proponents of causal modeling.},
 author = {Paul W. Holland},
 journal = {Journal of the American Statistical Association},
 number = {396},
 pages = {945--960},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Statistics and Causal Inference},
 urldate = {2023-03-12},
 volume = {81},
 year = {1986}
}

@incollection{hill2015,
title = {Causal Inference: Overview},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social \& Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {255-260},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.42095-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868420957},
author = {Jennifer Hill and Elizabeth A. Stuart},
keywords = {Causal inference, Common support, Ignorability, Observational studies, Overlap, Potential outcomes, Propensity scores, Quasi-experiments, Randomized experiments, Regression, SUTVA},
abstract = {This article discusses causal inference in statistics. It describes the theoretical framework and notation needed to formally define causal effects and the assumptions required to identify them nonparametrically. This involves definition of potential outcomes that represent the potential value of the outcome across different treatment exposures. Designs that allow researchers to satisfy or weaken these assumptions are briefly described. Then common parametric assumptions used to model effects and more current approaches that require weaker assumptions are discussed.}
}

 @article{geroIndividual, title={Individual, unit and vocal clan level identity cues in sperm whale codas},
  volume={3},
   DOI={10.1098/rsos.150372},
   number={1}, journal={Royal Society Open Science},
   author={Gero, Shane and Whitehead, Hal and Rendell, Luke},
   year={2016}, pages={150372}
  } 


  @inproceedings{deepcausal,
author = {Louizos, Christos and Shalit, Uri and Mooij, Joris and Sontag, David and Zemel, Richard and Welling, Max},
title = {Causal Effect Inference with Deep Latent-Variable Models},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Learning individual-level causal effects from observational data, such as inferring the most effective medication for a specific patient, is a problem of growing importance for policy makers. The most important aspect of inferring causal effects from observational data is the handling of confounders, factors that affect both an intervention and its outcome. A carefully designed observational study attempts to measure all important confounders. However, even if one does not have direct access to all confounders, there may exist noisy and uncertain measurement of proxies for confounders. We build on recent advances in latent variable modeling to simultaneously estimate the unknown latent space summarizing the confounders and the causal effect. Our method is based on Variational Autoencoders (VAE) which follow the causal structure of inference with proxies. We show our method is significantly more robust than existing methods, and matches the state-of-the-art on previous benchmarks focused on individual treatment effects.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {6449–6459},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}


@misc{deepcausal1,
  doi = {10.48550/ARXIV.1705.08821},
  
  url = {https://arxiv.org/abs/1705.08821},
  
  author = {Louizos, Christos and Shalit, Uri and Mooij, Joris and Sontag, David and Zemel, Richard and Welling, Max},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Causal Effect Inference with Deep Latent-Variable Models},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@article{integratedgrads,
  author    = {Mukund Sundararajan and
               Ankur Taly and
               Qiqi Yan},
  title     = {Axiomatic Attribution for Deep Networks},
  journal   = {CoRR},
  volume    = {abs/1703.01365},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.01365},
  eprinttype = {arXiv},
  eprint    = {1703.01365},
  timestamp = {Mon, 13 Aug 2018 16:48:32 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SundararajanTY17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{lightgbm,
 author = {Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {LightGBM: A Highly Efficient Gradient Boosting Decision Tree},
 url = {https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf},
 volume = {30},
 year = {2017}
}



@article{bronsteinWhale,
title = "Deep Machine Learning Techniques for the Detection and Classification of Sperm Whale Bioacoustics",
abstract = "We implemented Machine Learning (ML) techniques to advance the study of sperm whale (Physeter macrocephalus) bioacoustics. This entailed employing Convolutional Neural Networks (CNNs) to construct an echolocation click detector designed to classify spectrograms generated from sperm whale acoustic data according to the presence or absence of a click. The click detector achieved 99.5% accuracy in classifying 650 spectrograms. The successful application of CNNs to clicks reveals the potential of future studies to train CNN-based architectures to extract finer-scale details from cetacean spectrograms. Long short-term memory and gated recurrent unit recurrent neural networks were trained to perform classification tasks, including (1) “coda type classification” where we obtained 97.5% accuracy in categorizing 23 coda types from a Dominica dataset containing 8,719 codas and 93.6% accuracy in categorizing 43 coda types from an Eastern Tropical Pacific (ETP) dataset with 16,995 codas; (2) “vocal clan classification” where we obtained 95.3% accuracy for two clan classes from Dominica and 93.1% for four ETP clan types; and (3) “individual whale identification” where we obtained 99.4% accuracy using two Dominica sperm whales. These results demonstrate the feasibility of applying ML to sperm whale bioacoustics and establish the validity of constructing neural networks to learn meaningful representations of whale vocalizations.",
author = "Bermant, {Peter C.} and Bronstein, {Michael M.} and Wood, {Robert J.} and Shane Gero and Gruber, {David F.}",
note = "Publisher Copyright: {\textcopyright} 2019, The Author(s).",
year = "2019",
month = dec,
day = "1",
doi = "10.1038/s41598-019-48909-4",
language = "אנגלית",
volume = "9",
journal = "Scientific Reports",
issn = "2045-2322",
publisher = "Nature Publishing Group",
number = "1",
}


@misc{lundbergSHAPtree,
  doi = {10.48550/ARXIV.1802.03888},
  url = {https://arxiv.org/abs/1802.03888},
  author = {Lundberg, Scott M. and Erion, Gabriel G. and Lee, Su-In},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Consistent Individualized Feature Attribution for Tree Ensembles},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{lundbergSHAPtree2,
  title={From local explanations to global understanding with explainable AI for trees},
  author={Lundberg, Scott M. and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M. and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In},
  journal={Nature Machine Intelligence},
  volume={2},
  number={1},
  pages={2522-5839},
  year={2020},
  publisher={Nature Publishing Group}
}




@inproceedings{lundbergSHAP,
 author = {Lundberg, Scott M and Lee, Su-In},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {A Unified Approach to Interpreting Model Predictions},
 url = {https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf},
 volume = {30},
 year = {2017}
}



@article{andreas22,
title = {Toward understanding the communication in sperm whales},
journal = {iScience},
volume = {25},
number = {6},
pages = {104393},
year = {2022},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2022.104393},
url = {https://www.sciencedirect.com/science/article/pii/S2589004222006642},
author = {Jacob Andreas and Gašper Beguš and Michael M. Bronstein and Roee Diamant and Denley Delaney and Shane Gero and Shafi Goldwasser and David F. Gruber and Sarah {de Haas} and Peter Malkin and Nikolay Pavlov and Roger Payne and Giovanni Petri and Daniela Rus and Pratyusha Sharma and Dan Tchernov and Pernille Tønnesen and Antonio Torralba and Daniel Vogt and Robert J. Wood},
keywords = {Ethology, Artificial intelligence, Natural language processing, Linguistics},
abstract = {Summary
Machine learning has been advancing dramatically over the past decade. Most strides are human-based applications due to the availability of large-scale datasets; however, opportunities are ripe to apply this technology to more deeply understand non-human communication. We detail a scientific roadmap for advancing the understanding of communication of whales that can be built further upon as a template to decipher other forms of animal and non-human communication. Sperm whales, with their highly developed neuroanatomical features, cognitive abilities, social structures, and discrete click-based encoding make for an excellent model for advanced tools that can be applied to other animals in the future. We outline the key elements required for the collection and processing of massive datasets, detecting basic communication units and language-like higher-level structures, and validating models through interactive playback experiments. The technological capabilities developed by such an undertaking hold potential for cross-applications in broader communities investigating non-human communication and behavioral research.}
}

@book{whitehead03,
author = {Whitehead, Hal.},
address = {Chicago},
booktitle = {Sperm whales : social evolution in the ocean},
isbn = {0226895173},
keywords = {Cachalot},
language = {eng},
lccn = {2002155088},
publisher = {University of Chicago Press},
title = {Sperm whales : social evolution in the ocean },
year = {2003},
abstract = {Famed in story as "the great leviathans," sperm whales are truly creatures of extremes. Giants among all whales, they also have the largest brains of any creature on Earth. Males can reach a length of sixty-two feet and can weigh upwards of fifty tons. With this book, Hal Whitehead gives us a clearer picture of the ecology and social life of sperm whales than we have ever had before. Based on almost two decades of field research, Whitehead describes their biology, behavior, and habitat; how they organize their societies and how their complex lifestyles may have evolved in this unique environment. Among the many fascinating topics he explores is the crucial role that culture plays in the life of the sperm whale, and he traces the consequences of this argument for both evolution and conservation. Finally, drawing on these findings, Whitehead builds a general model of how the ocean environment influences social behavior and cultural evolution among mammals as well as other animals. The definitive portrait of a provocative creature, Sperm Whales will interest animal behaviorists, conservationists, ecologists, and evolutionary biologists as well as marine mammalogists.},
}



@article{watwood06,
author = {Watwood, Stephanie L. And Miller, Patrick J. O. And Johnson, Mark And Madsen, Peter T. And Tyack, Peter L.},
title = {Deep-diving foraging behaviour of sperm whales (Physeter macrocephalus)},
journal = {Journal of Animal Ecology},
volume = {75},
number = {3},
pages = {814-825},
keywords = {diving behaviour, echolocation, foraging behaviour, Physeter macrocephalus, sperm whales},
doi = {https://doi.org/10.1111/j.1365-2656.2006.01101.x},
url = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2656.2006.01101.x},
eprint = {https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2656.2006.01101.x},
abstract = {Summary 1 Digital tags were used to describe diving and vocal behaviour of sperm whales during 198 complete and partial foraging dives made by 37 individual sperm whales in the Atlantic Ocean, the Gulf of Mexico and the Ligurian Sea. 2 The maximum depth of dive averaged by individual differed across the three regions and was 985 m (SD = 124·3), 644 m (123·4) and 827 m (60·3), respectively. An average dive cycle consisted of a 45 min (6·3) dive with a 9 min (3·0) surface interval, with no significant differences among regions. On average, whales spent greater than 72\% of their time in foraging dive cycles. 3 Whales produced regular clicks for 81\% (4·1) of a dive and 64\% (14·6) of the descent phase. The occurrence of buzz vocalizations (also called ‘creaks’) as an indicator of the foraging phase of a dive showed no difference in mean prey capture attempts per dive between regions [18 buzzes/dive (7·6)]. Sperm whales descended a mean of 392 m (144) from the start of regular clicking to the first buzz, which supports the hypothesis that regular clicks function as a long-range biosonar. 4 There were no significant differences in the duration of the foraging phase [28 min (6·0)] or percentage of the dive duration in the foraging phase [62\% (7·3)] between the three regions, with an overall average proportion of time spent actively encountering prey during dive cycles of 0·53 (0·05). Whales maintained their time in the foraging phase by decreasing transit time for deeper foraging dives. 5 Similarity in foraging behaviour in the three regions and high diving efficiencies suggest that the success of sperm whales as mesopelagic predators is due in part to long-range echolocation of deep prey patches, efficient locomotion and a large aerobic capacity during diving.},
year = {2006}
}

@inproceedings{begusZhouInterspeech,
  author={Ga\v{s}per Begu\v{s} and Alan Zhou},
  title={{Modeling speech recognition and synthesis simultaneously: Encoding and decoding lexical and sublexical semantic information into speech with no direct access to speech data}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={5298--5302},
  doi={10.21437/Interspeech.2022-11219}
}

@article{stokes20,
title = {A Deep Learning Approach to Antibiotic Discovery},
journal = {Cell},
volume = {180},
number = {4},
pages = {688-702.e13},
year = {2020},
issn = {0092-8674},
doi = {https://doi.org/10.1016/j.cell.2020.01.021},
url = {https://www.sciencedirect.com/science/article/pii/S0092867420301021},
author = {Jonathan M. Stokes and Kevin Yang and Kyle Swanson and Wengong Jin and Andres Cubillos-Ruiz and Nina M. Donghia and Craig R. MacNair and Shawn French and Lindsey A. Carfrae and Zohar Bloom-Ackermann and Victoria M. Tran and Anush Chiappino-Pepe and Ahmed H. Badran and Ian W. Andrews and Emma J. Chory and George M. Church and Eric D. Brown and Tommi S. Jaakkola and Regina Barzilay and James J. Collins},
keywords = {antibiotics, antibiotic resistance, antibiotic tolerance, machine learning, drug discovery},
abstract = {Summary
Due to the rapid emergence of antibiotic-resistant bacteria, there is a growing need to discover new antibiotics. To address this challenge, we trained a deep neural network capable of predicting molecules with antibacterial activity. We performed predictions on multiple chemical libraries and discovered a molecule from the Drug Repurposing Hub—halicin—that is structurally divergent from conventional antibiotics and displays bactericidal activity against a wide phylogenetic spectrum of pathogens including Mycobacterium tuberculosis and carbapenem-resistant Enterobacteriaceae. Halicin also effectively treated Clostridioides difficile and pan-resistant Acinetobacter baumannii infections in murine models. Additionally, from a discrete set of 23 empirically tested predictions from >107 million molecules curated from the ZINC15 database, our model identified eight antibacterial compounds that are structurally distant from known antibiotics. This work highlights the utility of deep learning approaches to expand our antibiotic arsenal through the discovery of structurally distinct antibacterial molecules.}
}


@article{jumper21,
	Abstract = {Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort1--4, the structures of around 100,000 unique proteins have been determined5, but this represents a small fraction of the billions of known protein sequences6,7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence---the structure prediction component of the `protein folding problem'8---has been an important open research problem for more than 50 years9. Despite recent progress10--14, existing methods fall far short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.},
	Author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v Z}{\'\i}dek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
	Da = {2021/08/01},
	Date-Added = {2023-02-10 00:02:57 +0000},
	Date-Modified = {2023-02-10 00:02:57 +0000},
	Doi = {10.1038/s41586-021-03819-2},
	Id = {Jumper2021},
	Isbn = {1476-4687},
	Journal = {Nature},
	Number = {7873},
	Pages = {583--589},
	Title = {Highly accurate protein structure prediction with AlphaFold},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/s41586-021-03819-2},
	Volume = {596},
	Year = {2021},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41586-021-03819-2}}



@article{davies21,
	Abstract = {The practice of mathematics involves discovering patterns and using these to formulate and prove conjectures, resulting in theorems. Since the 1960s, mathematicians have used computers to assist in the discovery of patterns and formulation of conjectures1, most famously in the Birch and Swinnerton-Dyer conjecture2, a Millennium Prize Problem3. Here we provide examples of new fundamental results in pure mathematics that have been discovered with the assistance of machine learning---demonstrating a method by which machine learning can aid mathematicians in discovering new conjectures and theorems. We propose a process of using machine learning to discover potential patterns and relations between mathematical objects, understanding them with attribution techniques and using these observations to guide intuition and propose conjectures. We outline this machine-learning-guided framework and demonstrate its successful application to current research questions in distinct areas of pure mathematics, in each case showing how it led to meaningful mathematical contributions on important open problems: a new connection between the algebraic and geometric structure of knots, and a candidate algorithm predicted by the combinatorial invariance conjecture for symmetric groups4. Our work may serve as a model for collaboration between the fields of mathematics and artificial intelligence (AI) that can achieve surprising results by leveraging the respective strengths of mathematicians and machine learning.},
	Author = {Davies, Alex and Veli{\v c}kovi{\'c}, Petar and Buesing, Lars and Blackwell, Sam and Zheng, Daniel and Toma{\v s}ev, Nenad and Tanburn, Richard and Battaglia, Peter and Blundell, Charles and Juh{\'a}sz, Andr{\'a}s and Lackenby, Marc and Williamson, Geordie and Hassabis, Demis and Kohli, Pushmeet},
	Da = {2021/12/01},
	Date-Added = {2023-02-09 23:55:02 +0000},
	Date-Modified = {2023-02-09 23:55:02 +0000},
	Doi = {10.1038/s41586-021-04086-x},
	Id = {Davies2021},
	Isbn = {1476-4687},
	Journal = {Nature},
	Number = {7887},
	Pages = {70--74},
	Title = {Advancing mathematics by guiding human intuition with AI},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/s41586-021-04086-x},
	Volume = {600},
	Year = {2021},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41586-021-04086-x}}


@misc{ceti_roadmap,
  doi = {10.48550/ARXIV.2104.08614},

  url = {https://arxiv.org/abs/2104.08614},

  author = {Andreas, Jacob and Beguš, Gašper and Bronstein, Michael M. and Diamant, Roee and Delaney, Denley and Gero, Shane and Goldwasser, Shafi and Gruber, David F. and de Haas, Sarah and Malkin, Peter and Payne, Roger and Petri, Giovanni and Rus, Daniela and Sharma, Pratyusha and Tchernov, Dan and Tønnesen, Pernille and Torralba, Antonio and Vogt, Daniel and Wood, Robert J.},

  keywords = {Sound (cs.SD), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Machine Learning (cs.LG), Robotics (cs.RO), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},

  title = {Cetacean Translation Initiative: a roadmap to deciphering the communication of sperm whales},

  publisher = {arXiv},

  year = {2021},

  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}

 @techreport{ding_causal_2021,
    title = {A First Course in Causal Inference},
    urldate = {2022-11-20},
    institution = {University of California, Berkeley},
    author = {Ding, Peng},
    year = {2021},
}



@article{imbens_propensity,
 ISSN = {00063444},
 URL = {http://www.jstor.org/stable/2673642},
 abstract = {Estimation of average treatment effects in observational studies often requires adjustment for differences in pre-treatment variables. If the number of pre-treatment variables is large, standard covariance adjustment methods are often inadequate. Rosenbaum & Rubin (1983) propose an alternative method for adjusting for pre-treatment variables for the binary treatment case based on the so-called propensity score. Here an extension of the propensity score methodology is proposed that allows for estimation of average casual effects with multi-valued treatments.},
 author = {Guido W. Imbens},
 journal = {Biometrika},
 number = {3},
 pages = {706--710},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {The Role of the Propensity Score in Estimating Dose-Response Functions},
 urldate = {2022-12-16},
 volume = {87},
 year = {2000}
}



@misc{yu_incremental,
  doi = {10.48550/ARXIV.1907.13258},

  url = {https://arxiv.org/abs/1907.13258},

  author = {Rothenhäusler, Dominik and Yu, Bin},

  keywords = {Methodology (stat.ME), FOS: Computer and information sciences, FOS: Computer and information sciences},

  title = {Incremental causal effects},

  publisher = {arXiv},

  year = {2019},

  copyright = {arXiv.org perpetual, non-exclusive license}
}



 @article{kennedy_2016, title={Non‐parametric methods for doubly robust estimation of continuous treatment effects}, volume={79}, DOI={10.1111/rssb.12212}, number={4}, journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)}, author={Kennedy, Edward H. and Ma, Zongming and McHugh, Matthew D. and Small, Dylan S.}, year={2016}, pages={1229–1245}}

 @unpublished{canary21,
  TITLE = {{What does the Canary Say? Low-Dimensional GAN Applied to Birdsong}},
  AUTHOR = {Pagliarini, Silvia and Trouvain, Nathan and Leblois, Arthur and Hinaut, Xavier},
  URL = {https://hal.inria.fr/hal-03244723},
  NOTE = {working paper or preprint},
  YEAR = {2021},
  MONTH = Nov,
  KEYWORDS = {Birdsong ; Sound generation ; Latent space ; Generative Adversarial Networks ; Reservoir Computing ; Canary ; Low-dimensional},
  PDF = {https://hal.inria.fr/hal-03244723v2/file/Pagliarini2021_canary_GAN__HAL-v2.pdf},
  HAL_ID = {hal-03244723},
  HAL_VERSION = {v2},
}

@TECHREPORT{atheyML,
title = {Machine Learning for Estimating Heterogeneous Causal Effects},
author = {Athey, Susan and Imbens, Guido},
year = {2015},
institution = {Stanford University, Graduate School of Business},
type = {Research Papers},
abstract = {In this paper we study the problems of estimating heterogeneity in causal effects in experimental or observational studies and conducting inference about the magnitude of the differences in treatment effects across subsets of the population. In applications, our method provides a data-driven approach to determine which subpopulations have large or small treatment effects and to test hypotheses about the differences in these effects. For experiments, our method allows researchers to identify heterogeneity in treatment effects that was not specified in a pre-analysis plan, without concern about invalidating inference due to multiple testing. In most of the literature on supervised machine learning (e.g. regression trees, random forests, LASSO, etc.), the goal is to build a model of the relationship between a unit's attributes and an observed outcome. A prominent role in these methods is played by cross-validation which compares predictions to actual outcomes in test samples, in order to select the level of complexity of the model that provides the best predictive power. Our method is closely related, but it differs in that it is tailored for predicting causal effects of a treatment rather than a unit's outcome. The challenge is that the "ground truth" for a causal effect is not observed for any individual unit: we observe the unit with the treatment, or without the treatment, but not both at the same time. Thus, it is not obvious how to use cross-validation to determine whether a causal effect has been accurately predicted. We propose several novel cross-validation criteria for this problem and demonstrate through simulations the conditions under which they perform better than standard methods for the problem of causal effects. We then apply the method to a large-scale field experiment re-ranking results on a search engine.},
url = {https://EconPapers.repec.org/RePEc:ecl:stabus:3350}
}

@article{lin2013,
author = {Winston Lin},
title = {{Agnostic notes on regression adjustments to experimental data: Reexamining Freedman’s critique}},
volume = {7},
journal = {The Annals of Applied Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {295 -- 318},
keywords = {Analysis of covariance, covariate adjustment, program evaluation, Randomization inference, robust standard errors, sandwich estimator, social experiments},
year = {2013},
doi = {10.1214/12-AOAS583},
URL = {https://doi.org/10.1214/12-AOAS583}
}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@incollection{nisbett02,
author = {Richard E. Nisbett and Ara Norenzayan},
publisher = {American Cancer Society},
isbn = {9780471214427},
title = {Culture and Cognition},
booktitle = {Stevens' Handbook of Experimental Psychology},
chapter = {},
pages = {},
doi = {10.1002/0471214426.pas0213},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/0471214426.pas0213},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/0471214426.pas0213},
year = {2002},
keywords = {Culture, folkbiology, holistic thinking, language and thought, logical reasoning, mathematical thinking},
abstract = {Abstract We review evidence for the mutual interdependence of cultural and cognitive processes. Some cognitive content, assumed by many psychologists to be infinitely variable, appears to be universal, including theories of mechanics, biology, and mind. These domain-specific theories constrain the diversity of human thought and the range of cultures possible. On the other hand, many cognitive processes assumed to be universal are highly susceptible to cultural variation. We consider recent developments regarding cultural variation in mathematical and folkbiological reasoning, deductive reasoning in traditional societies, as well as the linguistic relativity hypothesis, field dependence, and situated cognition. We then examine recent research on marked cultural differences in holistic vs. analytic modes of reasoning primarily between East Asian and Western cultures.}
}

@article{Abdel-HamidCNN,
	author = {Abdel-Hamid, Ossama and Mohamed, Abdel-rahman and Jiang, Hui and Deng, Li and Penn, Gerald and Yu, Dong},
	title = {{Convolutional Neural Networks for Speech Recognition}},
	journal = {IEEE/ACM Trans. Audio Speech Lang. Process.},
	volume = {22},
	number = {10},
	pages = {1533--1545},
	year = {2014},
	month = {Jul},
	issn = {2329-9304},
	publisher = {IEEE},
	doi = {10.1109/TASLP.2014.2339736}
}

@incollection{LietoCNN,
	author = {Lieto, A. and Moro, D. and Devoti, F. and Parera, C. and Lipari, V. and Bestagini, P. and Tubaro, S.},
	title = {{"Hello? Who Am I Talking to?" A Shallow CNN Approach for Human vs. Bot Speech Classification}},
	booktitle = {{ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}},
	journal = {ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages = {2577--2581},
	year = {2019},
	month = {May},
	issn = {2379-190X},
	publisher = {IEEE},
	doi = {10.1109/ICASSP.2019.8682743}
}

@INPROCEEDINGS{newatia18,
  author={Newatia, Sourav and Aggarwal, R.K.},
  booktitle={2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA)}, 
  title={Convolutional Neural Network for ASR}, 
  year={2018},
  volume={},
  number={},
  pages={638-642},
  doi={10.1109/ICECA.2018.8474688}}

@inproceedings{palaz13,
  author={Dimitri Palaz and Ronan Collobert and Mathew Magimai-Doss},
  title={{Estimating phoneme class conditional probabilities from raw speech signal using convolutional neural networks}},
  year=2013,
  booktitle={Proc. Interspeech 2013},
  pages={1766--1770},
  doi={10.21437/Interspeech.2013-438}
}

@inproceedings{zhang16b_interspeechCNN,
  author={Ying Zhang and Mohammad Pezeshki and Philémon Brakel and Saizheng Zhang and César Laurent and Yoshua Bengio and Aaron Courville},
  title={{Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks}},
  year=2016,
  booktitle={Proc. Interspeech 2016},
  pages={410--414},
  doi={10.21437/Interspeech.2016-1446}
}

@article{Lipton2017Feb,
	author = {Lipton, Zachary C. and Tripathi, Subarna},
	title = {{Precise Recovery of Latent Vectors from Generative Adversarial Networks}},
	journal = {arXiv},
	year = {2017},
	month = {Feb},
	eprint = {1702.04782},
	url = {https://arxiv.org/abs/1702.04782v2}
}

@article{Keyes2020Oct,
	author = {Keyes, Andrew and Bayat, Nicky and Khazaie, Vahid Reza and Mohsenzadeh, Yalda},
	title = {{Latent Vector Recovery of Audio GANs}},
	journal = {arXiv},
	year = {2020},
	month = {Oct},
	eprint = {2010.08534},
	url = {https://arxiv.org/abs/2010.08534v1}
}

@article{begusZhou,
  author    = {Ga\v{s}per Begu\v{s} and
               Alan Zhou},
  title     = {Interpreting intermediate convolutional layers of {CNN}s trained on
               raw speech},
  journal   = {CoRR},
  volume    = {abs/2104.09489},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.09489},
  archivePrefix = {arXiv},
  eprint    = {2104.09489},
  timestamp = {Mon, 26 Apr 2021 17:25:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-09489.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{finley11,
title = "The privileged status of locality in consonant harmony",
journal = "Journal of Memory and Language",
volume = "65",
number = "1",
pages = "74 - 83",
year = "2011",
issn = "0749-596X",
doi = "https://doi.org/10.1016/j.jml.2011.02.006",
url = "http://www.sciencedirect.com/science/article/pii/S0749596X11000192",
author = "Sara Finley"
}

@book{hansson10,
  title={Consonant harmony: Long-distance interactions in phonology},
  author={Hansson, Gunnar {\'O}lafur},
  year={2010},
  location={Berkeley, CA},
  publisher={University of California Press}
}

@inproceedings{smolensky16,
  title={Gradient Symbolic Representations in Grammar: The case of French Liaison},
  author={Paul Smolensky and Matthew Goldrick},
  year={2016},
  booktitle={Rutgers Optimality Archive 1552, Rutgers University.}
}

@article{bybee17, title={Grammatical and lexical factors in sound change: A usage-based approach}, volume={29}, DOI={10.1017/S0954394517000199}, number={3}, journal={Language Variation and Change}, publisher={Cambridge University Press}, author={Bybee, Joan}, year={2017}, pages={273–300}}

@inproceedings{smolensky19,
  title={Learning a gradient grammar of {F}rench liaison},
  author={Paul Smolensky and Eric Rosen and Matthew Goldrick},
  year={2019},
  booktitle={Proceedings of the 2019 Annual Meeting on Phonology}
}

@article{aryal16,
title = {Data driven articulatory synthesis with deep neural networks},
journal = {Computer Speech \& Language},
volume = {36},
pages = {260-273},
year = {2016},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2015.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0885230815000200},
author = {Sandesh Aryal and Ricardo Gutierrez-Osuna},
keywords = {Articulatory synthesis, Electromagnetic articulography, Deep learning, Gaussian mixture models},
abstract = {The conventional approach for data-driven articulatory synthesis consists of modeling the joint acoustic-articulatory distribution with a Gaussian mixture model (GMM), followed by a post-processing step that optimizes the resulting acoustic trajectories. This final step can significantly improve the accuracy of the GMM frame-by-frame mapping but is computationally intensive and requires that the entire utterance be synthesized beforehand, making it unsuited for real-time synthesis. To address this issue, we present a deep neural network (DNN) articulatory synthesizer that uses a tapped-delay input line, allowing the model to capture context information in the articulatory trajectory without the need for post-processing. We characterize the DNN as a function of the context size and number of hidden layers, and compare it against two GMM articulatory synthesizers, a baseline model that performs a simple frame-by-frame mapping, and a second model that also performs trajectory optimization. Our results show that a DNN with a 60-ms context window and two 512-neuron hidden layers can synthesize speech at four times the frame rate – comparable to frame-by-frame mappings, while improving the accuracy of trajectory optimization (a 9.8\% reduction in Mel Cepstral distortion). Subjective evaluation through pairwise listening tests also shows a strong preference toward the DNN articulatory synthesizer when compared to GMM trajectory optimization.}
}

@inproceedings{bocquelet14,
  author={Florent Bocquelet and Thomas Hueber and Laurent Girin and Pierre Badin and Blaise Yvert},
  title={{Robust articulatory speech synthesis using deep neural networks for BCI applications}},
  year=2014,
  booktitle={Proc. Interspeech 2014},
  pages={2288--2292},
  doi={10.21437/Interspeech.2014-449}
}

@inproceedings{georges22,
  author={Marc-Antoine Georges and Jean-Luc Schwartz and Thomas Hueber},
  title={{Self-supervised speech unit discovery from articulatory and acoustic features using VQ-VAE}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={774--778},
  doi={10.21437/Interspeech.2022-10876}
}

@inproceedings{baevski20,
title={vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations},
author={Alexei Baevski and Steffen Schneider and Michael Auli},
booktitle={International Conference on Learning Representations},
year={2020},
pages={1-12},
url={https://openreview.net/forum?id=rylwJxrYDS}
}

@article{dunbar20,
   title={The Zero Resource Speech Challenge 2020: Discovering Discrete Subword and Word Units},
   url={http://dx.doi.org/10.21437/interspeech.2020-2743},
   DOI={10.21437/interspeech.2020-2743},
   journal={Interspeech 2020},
   publisher={ISCA},
   author={Dunbar, Ewan and Karadayi, Julien and Bernard, Mathieu and Cao, Xuan-Nga and Algayres, Robin and Ondel, Lucas and Besacier, Laurent and Sakti, Sakriani and Dupoux, Emmanuel},
   year={2020},
   month={Oct}
}

@article{niekerk20,
   title={Vector-Quantized Neural Networks for Acoustic Unit Discovery in the {ZeroSpeech} 2020 Challenge},
   url={http://dx.doi.org/10.21437/interspeech.2020-1693},
   DOI={10.21437/interspeech.2020-1693},
   journal={Interspeech 2020},
   publisher={ISCA},
   author={Niekerk, Benjamin van and Nortje, Leanne and Kamper, Herman},
   year={2020},
   month={Oct}
}

@inproceedings{chung20,
  author={Yu-An Chung and Hao Tang and James Glass},
  title={{Vector-Quantized Autoregressive Predictive Coding}},
  year=2020,
  booktitle={Proc. Interspeech 2020},
  pages={3760--3764},
  doi={10.21437/Interspeech.2020-1228},
  url={http://dx.doi.org/10.21437/Interspeech.2020-1228}
}


@inproceedings{hu20,
  author={Yushi Hu and Shane Settle and Karen Livescu},
  title={{Multilingual Jointly Trained Acoustic and Written Word Embeddings}},
  year=2020,
  booktitle={Proc. Interspeech 2020},
  pages={1052--1056},
  doi={10.21437/Interspeech.2020-2828},
  url={http://dx.doi.org/10.21437/Interspeech.2020-2828}
}


@INPROCEEDINGS{kamper14,
  author={H. {Kamper} and A. {Jansen} and S. {King} and S. {Goldwater}},
  booktitle={2014 IEEE Spoken Language Technology Workshop (SLT)}, 
  title={Unsupervised lexical clustering of speech segments using fixed-dimensional acoustic embeddings}, 
  year={2014},
  volume={},
  number={},
  pages={100-105},
  doi={10.1109/SLT.2014.7078557}}
  
  @INPROCEEDINGS{kamper19,
  author={H. {Kamper}},
  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Truly Unsupervised Acoustic Word Embeddings Using Weak Top-down Constraints in Encoder-decoder Models}, 
  year={2019},
  volume={},
  number={},
  pages={6535-3539},
  doi={10.1109/ICASSP.2019.8683639}}
  
  @ARTICLE{chorowski19,
  author={J. {Chorowski} and R. J. {Weiss} and S. {Bengio} and A. {van den Oord}},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Unsupervised Speech Representation Learning Using {WaveNet} Autoencoders}, 
  year={2019},
  volume={27},
  number={12},
  pages={2041-2053},
  doi={10.1109/TASLP.2019.2938863}}
  
  
@misc{brugiapaglia20,
      title={Generalizing Outside the Training Set: When Can Neural Networks Learn Identity Effects?}, 
      author={Simone Brugiapaglia and Matthew Liu and Paul Tupper},
      year={2020},
      eprint={2005.04330},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}  
  

@INPROCEEDINGS{dunbar17,
  author={E. {Dunbar} and X. N. {Cao} and J. {Benjumea} and J. {Karadayi} and M. {Bernard} and L. {Besacier} and X. {Anguera} and E. {Dupoux}},
  booktitle={2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={The zero resource speech challenge 2017}, 
  year={2017},
  volume={},
  number={},
  pages={323-330},
  doi={10.1109/ASRU.2017.8268953}}
  
  @inproceedings{dunbar19,
  author={Ewan Dunbar and Robin Algayres and Julien Karadayi and Mathieu Bernard and Juan Benjumea and Xuan-Nga Cao and Lucie Miskic and Charlotte Dugrain and Lucas Ondel and Alan W. Black and Laurent Besacier and Sakriani Sakti and Emmanuel Dupoux},
  title={{The Zero Resource Speech Challenge 2019: TTS Without T}},
  year=2019,
  booktitle={Proc. Interspeech 2019},
  pages={1088--1092},
  doi={10.21437/Interspeech.2019-2904},
  url={http://dx.doi.org/10.21437/Interspeech.2019-2904}
}

  
  @inproceedings{chung16,
author={Yu-An Chung and Chao-Chung Wu and Chia-Hao Shen and Hung-Yi Lee and Lin-Shan Lee},
title={Audio Word2Vec: Unsupervised Learning of Audio Segment Representations Using Sequence-to-Sequence Autoencoder},
year=2016,
booktitle={Interspeech 2016},
doi={10.21437/Interspeech.2016-82},
url={http://dx.doi.org/10.21437/Interspeech.2016-82},
pages={765--769}
}

@incollection{macmahon13,
      author = "Michael K. C. MacMahon",
      editor={Keith Allan},
      title = "Orthography and the Early History of Phonetics",
      year = "2013",
      month = "07",
      booktitle={The Oxford Handbook of the History of Linguistics},
      publisher = "Oxford University Press",
      location={Oxford},
      isbn = "9780199585847",
      pages =      "105-122",
      doi="10.1093/oxfordhb/9780199585847.013.0006",
      url = "https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199585847.001.0001/oxfordhb-9780199585847-e-6"
}


@incollection{allan13,
      author = "Michael K. C. MacMahon",
      editor={Keith Allan},
      title = "Orthography and the Early History of Phonetics",
      year = "2013",
      month = "07",
      booktitle={The Oxford Handbook of the History of Linguistics},
      publisher = "Oxford University Press",
      location={Oxford},
      isbn = "9780199585847",
      pages=     "105-122",
      doi="10.1093/oxfordhb/9780199585847.013.0006",
      url = "https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199585847.001.0001/oxfordhb-9780199585847-e-6"
}

@book{inkelas05, place={Cambridge}, series={Cambridge Studies in Linguistics}, title={Reduplication: Doubling in Morphology}, DOI={10.1017/CBO9780511627712}, publisher={Cambridge University Press}, author={Inkelas, Sharon and Zoll, Cheryl}, year={2005}, collection={Cambridge Studies in Linguistics}}

@misc {urbanczyk17,
      author = "Suzanne Urbanczyk",
      title = "Phonological and Morphological Aspects of Reduplication",
      year = "2017",
      month = "03",
      publisher = "Oxford University Press",
      doi = "10.1093/acrefore/9780199384655.013.80",
      url = "https://oxfordre.com/linguistics/view/10.1093/acrefore/9780199384655.001.0001/acrefore-9780199384655-e-80"
}

@unpublished{begusCatalysis,
author = {Ga\v{s}per Begu\v{s}},
note = {Submitted ms., UC Berkeley},
title = {Distinguishing cognitive from historical influences in phonology},
year = {2020},
}

@incollection{hulst13,
      author = "Harry van der Hulst",
      editor={Keith Allan},
      title = "Discoverers of the Phoneme",
      year = "2013",
      month = "07",
      booktitle={The Oxford Handbook of the History of Linguistics},
      publisher = "Oxford University Press",
      location={Oxford},
      pages=      "167-191",
      doi="10.1093/oxfordhb/9780199585847.013.0009"
}

@article{rose04,
 ISSN = {00978507, 15350665},
 URL = {http://www.jstor.org/stable/4489721},
 abstract = {This article presents a typology of consonant harmony or Long Distance Consonant Agreement that is analyzed as arising through correspondence relations between consonants rather than feature spreading. The model covers a range of agreement patterns (nasal, laryngeal, liquid, coronal, dorsal) and offers several advantages. Similarity of agreeing consonants is central to the typology and is incorporated directly into the constraints driving correspondence. Agreement by correspondence without feature spreading captures the neutrality of intervening segments, which neither block nor undergo. Case studies of laryngeal agreement and nasal agreement are presented, demonstrating the model's capacity to capture varying degrees of similarity crosslinguistically.},
 author = {Sharon Rose and Rachel Walker},
 journal = {Language},
 number = {3},
 pages = {475--531},
 publisher = {Linguistic Society of America},
 title = {A Typology of Consonant Agreement as Correspondence},
 volume = {80},
 year = {2004}
}

@book{marcus01,
  title={The algebraic mind: Integrating connectionism and cognitive science},
  author={Marcus, Gary F.},
  year={2001},
  publisher={MIT press},
  location={Cambridge, MA}
}

@inproceedings{dolatian18,
    title = "Modeling Reduplication with 2-way Finite-State Transducers",
    author = "Dolatian, Hossep  and
      Heinz, Jeffrey",
    booktitle = "Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-5807",
    doi = "10.18653/v1/W18-5807",
    pages = "66--77",
    abstract = "This article describes a novel approach to the computational modeling of reduplication. Reduplication is a well-studied linguistic phenomenon. However, it is often treated as a stumbling block within finite-state treatments of morphology. Most finite-state implementations of computational morphology cannot adequately capture the productivity of unbounded copying in reduplication, nor can they adequately capture bounded copying. We show that an understudied type of finite-state machines, two-way finite-state transducers (2-way FSTs), captures virtually all reduplicative processes, including total reduplication. 2-way FSTs can model reduplicative typology in a way which is convenient, easy to design and debug in practice, and linguistically-motivated. By virtue of being finite-state, 2-way FSTs are likewise incorporable into existing finite-state systems and programs. A small but representative typology of reduplicative processes is described in this article, alongside their corresponding 2-way FST models.",
}



@Book{turner41,
author = { Lister-Turner, R. and Chatterton, Percy and Clark, J. B. },
title = { A grammar of the Motu language of Papua},
edition = { 2nd ed. / edited by Percy Chatterton. },
publisher = { Government Printer Sydney },
pages = { 91 p. ; },
year = { 1941 },
type = { Book },
language = { Papiamento },
subjects = { Motu language -- Grammar.; Motu language -- Dictionaries -- English.; English language -- Dictionaries -- Motu.; Australian },
life-dates = { 1940 - 1949 },
catalogue-url = { https://nla.gov.au/nla.cat-vn1093080 },
}


@article {marcus99,
	author = {Marcus, G. F. and Vijayan, S. and Bandi Rao, S. and Vishton, P. M.},
	title = {Rule Learning by Seven-Month-Old Infants},
	volume = {283},
	number = {5398},
	pages = {77--80},
	year = {1999},
	doi = {10.1126/science.283.5398.77},
	publisher = {American Association for the Advancement of Science},
	abstract = {A fundamental task of language acquisition is to extract abstract algebraic rules. Three experiments show that 7-month-old infants attend longer to sentences with unfamiliar structures than to sentences with familiar structures. The design of the artificial language task used in these experiments ensured that this discrimination could not be performed by counting, by a system that is sensitive only to transitional probabilities, or by a popular class of simple neural network models. Instead, these results suggest that infants can represent, extract, and generalize abstract algebraic rules.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/283/5398/77},
	eprint = {https://science.sciencemag.org/content/283/5398/77.full.pdf},
	journal = {Science}
}



@inproceedings{alishahi17,
    title = "Encoding of phonology in a recurrent neural model of grounded speech",
    author = "Alishahi, Afra  and
      Barking, Marie  and
      Chrupa{\l}a, Grzegorz",
    booktitle = "Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/K17-1037",
    doi = "10.18653/v1/K17-1037",
    pages = "368--378",
    abstract = "We study the representation and encoding of phonemes in a recurrent neural network model of grounded speech. We use a model which processes images and their spoken descriptions, and projects the visual and auditory representations into the same semantic space. We perform a number of analyses on how information about individual phonemes is encoded in the MFCC features extracted from the speech signal, and the activations of the layers of the model. Via experiments with phoneme decoding and phoneme discrimination we show that phoneme representations are most salient in the lower layers of the model, where low-level signals are processed at a fine-grained level, although a large amount of phonological information is retain at the top recurrent layer. We further find out that the attention mechanism following the top recurrent layer significantly attenuates encoding of phonology and makes the utterance embeddings much more invariant to synonymy. Moreover, a hierarchical clustering of phoneme representations learned by the network shows an organizational structure of phonemes similar to those proposed in linguistics.",
}


@book{brownlee19,
  title={Generative Adversarial Networks with Python: Deep Learning Generative Models for Image Synthesis and Image Translation},
  author={Brownlee, Jason},
  year={2019},
  publisher={Machine Learning Mastery}
}

	
@misc{adlam19,
    title={Investigating Under and Overfitting in Wasserstein Generative Adversarial Networks},
    author={Ben Adlam and Charles Weill and Amol Kapoor},
    year={2019},
    eprint={1910.14137},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@article{arnold17,
    author = {Arnold, Denis AND Tomaschek, Fabian AND Sering, Konstantin AND Lopez, Florence AND Baayen, R. Harald},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Words from spontaneous conversational speech can be recognized with human-like accuracy by an error-driven learning algorithm that discriminates between meanings straight from smart acoustic features, bypassing the phoneme as recognition unit},
    year = {2017},
    month = {04},
    volume = {12},
    url = {https://doi.org/10.1371/journal.pone.0174623},
    pages = {1-16},
    abstract = {Sound units play a pivotal role in cognitive models of auditory comprehension. The general consensus is that during perception listeners break down speech into auditory words and subsequently phones. Indeed, cognitive speech recognition is typically taken to be computationally intractable without phones. Here we present a computational model trained on 20 hours of conversational speech that recognizes word meanings within the range of human performance (model 25%, native speakers 20–44%), without making use of phone or word form representations. Our model also generates successfully predictions about the speed and accuracy of human auditory comprehension. At the heart of the model is a ‘wide’ yet sparse two-layer artificial neural network with some hundred thousand input units representing summaries of changes in acoustic frequency bands, and proxies for lexical meanings as output units. We believe that our model holds promise for resolving longstanding theoretical problems surrounding the notion of the phone in linguistic theory.},
    number = {4},
    doi = {10.1371/journal.pone.0174623}
}

  @Book{nnet,
    title = {Modern Applied Statistics with S},
    author = {W. N. Venables and B. D. Ripley},
    publisher = {Springer},
    edition = {Fourth},
    address = {New York},
    year = {2002},
    note = {ISBN 0-387-95457-0},
    url = {http://www.stats.ox.ac.uk/pub/MASS4},
  }


@article{kamper17,
title = "A segmental framework for fully-unsupervised large-vocabulary speech recognition",
journal = "Computer Speech \& Language",
volume = "46",
pages = "154 - 174",
year = "2017",
issn = "0885-2308",
doi = "https://doi.org/10.1016/j.csl.2017.04.008",
url = "http://www.sciencedirect.com/science/article/pii/S0885230816301905",
author = "Herman Kamper and Aren Jansen and Sharon Goldwater",
keywords = "Unsupervised speech processing, Representation learning, Segmentation, Clustering, Language acquisition"
}

@article{rasanen12,
title = "Computational modeling of phonetic and lexical learning in early language acquisition: Existing models and future directions",
journal = "Speech Communication",
volume = "54",
number = "9",
pages = "975 - 997",
year = "2012",
issn = "0167-6393",
doi = "https://doi.org/10.1016/j.specom.2012.05.001",
url = "http://www.sciencedirect.com/science/article/pii/S0167639312000672",
author = "Okko R{\"a}s{\"a}nen",
keywords = "Language acquisition, Distributional learning, Computer simulation, Phonetic learning, Lexical learning",
abstract = "This work reviews a number of existing computational studies concentrated on the question of how spoken language can be learned from continuous speech in the absence of linguistically or phonetically motivated background knowledge, a situation faced by human infants when they first attempt to learn their native language. Specifically, the focus is on how phonetic categories and word-like units can be acquired purely on the basis of the statistical structure of speech signals, possibly aided by some articulatory or visual constraints. The outcomes and shortcomings of the existing work are reflected onto findings from experimental and theoretical studies. Finally, some of the open questions and possible future research directions related to the computational models of language acquisition are discussed."
}



@article{lee15,
    title = "Unsupervised Lexicon Discovery from Acoustic Input",
    author = "Lee, Chia-ying  and
      O{'}Donnell, Timothy J.  and
      Glass, James",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "3",
    year = "2015",
    url = "https://www.aclweb.org/anthology/Q15-1028",
    doi = "10.1162/tacl_a_00146",
    pages = "389--403",
    abstract = "We present a model of unsupervised phonological lexicon discovery{---}the problem of simultaneously learning phoneme-like and word-like units from acoustic input. Our model builds on earlier models of unsupervised phone-like unit discovery from acoustic data (Lee and Glass, 2012), and unsupervised symbolic lexicon discovery using the Adaptor Grammar framework (Johnson et al., 2006), integrating these earlier approaches using a probabilistic model of phonological variation. We show that the model is competitive with state-of-the-art spoken term discovery systems, and present analyses exploring the model{'}s behavior and the kinds of linguistic structures it learns.",
}

@inproceedings{bajestan18,
  author={Elnaz Shafaei-Bajestan and R. Harald Baayen},
  title={Wide Learning for Auditory Comprehension},
  year=2018,
  booktitle={Proc. Interspeech 2018},
  pages={966--970},
  doi={10.21437/Interspeech.2018-2420},
  url={http://dx.doi.org/10.21437/Interspeech.2018-2420}
}

@inproceedings{eloff19,
author = {Eloff, Ryan and Nortje, André and van Niekerk, Benjamin and Govender, Avashna and Nortje, Leanne and Pretorius, Arnu and Biljon, Elan and van der Westhuizen, Ewald and Staden, Lisa and Kamper, Herman},
year = {2019},
month = {09},
pages = {1103-1107},
title = {Unsupervised Acoustic Unit Discovery for Speech Synthesis Using Discrete Latent-Variable Neural Networks},
  booktitle={Proc. Interspeech 2019},
doi = {10.21437/Interspeech.2019-1518}
}

@article{baayen19,
  title={The discriminative lexicon: A unified computational model for the lexicon and lexical processing in comprehension and production grounded not in (de) composition but in linear discriminative learning},
  author={Baayen, R Harald and Chuang, Yu-Ying and Shafaei-Bajestan, Elnaz and Blevins, James P},
  journal={Complexity},
  volume={2019},
  year={2019},
  publisher={Hindawi},
  doi = {10.1155/2019/4895891},
}

@incollection{chen16InfoGAN,
title = {{InfoGAN}: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets},
author = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
booktitle = {Advances in Neural Information Processing Systems 29},
editor = {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon and R. Garnett},
pages = {2172--2180},
year = {2016},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/6399-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets.pdf}
}



@article{kuhl10,
	Author = {Kuhl, Patricia K. },
	Booktitle = {Neuron},
	Date = {2010/09/09},
	Date-Added = {2019-06-27 09:19:54 +0000},
	Date-Modified = {2019-06-27 09:19:54 +0000},
	Doi = {10.1016/j.neuron.2010.08.038},
	Isbn = {0896-6273},
	Journal = {Neuron},
	M3 = {doi: 10.1016/j.neuron.2010.08.038},
	Month = {2019/06/27},
	Number = {5},
	Pages = {713--727},
	Publisher = {Elsevier},
	Title = {Brain Mechanisms in Early Language Acquisition},
	Ty = {JOUR},
	Url = {https://doi.org/10.1016/j.neuron.2010.08.038},
	Volume = {67},
	Year = {2010},
	Year1 = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuron.2010.08.038}}





@inbook{saffran06,
author = {Saffran, Jenny R. and Werker, Janet F. and Werner, Lynne A.},
publisher = {American Cancer Society},
isbn = {9780470147658},
title = {The Infant's Auditory World: Hearing, Speech, and the Beginnings of Language},
booktitle = {Handbook of Child Psychology},
chapter = {2},
pages = {},
doi = {10.1002/9780470147658.chpsy0202},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470147658.chpsy0202},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470147658.chpsy0202},
year = {2007},
keywords = {hearing, infants, language, speech, words},
abstract = {Abstract The focus of this chapter is on how infants perceive, process, and learn from their auditory environments. We focus on mechanism of hearing, speech perception, and early language learning, with the goal of elucidating recent progress in this field and its historical context. The literature reviewed includes studies of hearing development in young infants, the beginnings of speech perception and tuning to the native language, word segmentation, word learning, phonological acquisition, and the early stages of language acquisition. Throughout, we focus on current controversies along with theoretical and methodological innovations.}
}

@article {saffran96,
	author = {Saffran, Jenny R. and Aslin, Richard N. and Newport, Elissa L.},
	title = {Statistical Learning by 8-Month-Old Infants},
	volume = {274},
	number = {5294},
	pages = {1926--1928},
	year = {1996},
	doi = {10.1126/science.274.5294.1926},
	publisher = {American Association for the Advancement of Science},
	abstract = {Learners rely on a combination of experience-independent and experience-dependent mechanisms to extract information from the environment. Language acquisition involves both types of mechanisms, but most theorists emphasize the relative importance of experience-independent mechanisms. The present study shows that a fundamental task of language acquisition, segmentation of words from fluent speech, can be accomplished by 8-month-old infants based solely on the statistical relationships between neighboring speech sounds. Moreover, this word segmentation was based on statistical learning from only 2 minutes of exposure, suggesting that infants have access to a powerful mechanism for the computation of statistical properties of the language input.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/274/5294/1926},
	eprint = {https://science.sciencemag.org/content/274/5294/1926.full.pdf},
	journal = {Science}
}


@misc{tensorflow,
title={{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={http://tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dan~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

@misc{clark19,
    title={What Does BERT Look At? An Analysis of BERT's Attention},
    author={Kevin Clark and Urvashi Khandelwal and Omer Levy and Christopher D. Manning},
    year={2019},
    eprint={1906.04341},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@incollection{goodfellow14GAN,
title = {Generative Adversarial Nets},
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
booktitle = {Advances in Neural Information Processing Systems 27},
editor = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
pages = {2672--2680},
year = {2014},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf}
}


@article{finley12,
author = { Sara   Finley },
title = {Typological asymmetries in round vowel harmony: Support from artificial grammar learning},
journal = {Language and Cognitive Processes},
volume = {27},
number = {10},
pages = {1550-1562},
year  = {2012},
publisher = {Routledge},
doi = {10.1080/01690965.2012.660168},

URL = { 
        https://doi.org/10.1080/01690965.2012.660168
    
},
eprint = { 
        https://doi.org/10.1080/01690965.2012.660168
    
}

}




@article{finley09,
title = "Artificial language learning and feature-based generalization",
journal = "Journal of Memory and Language",
volume = "61",
number = "3",
pages = "423 - 437",
year = "2009",
issn = "0749-596X",
doi = "https://doi.org/10.1016/j.jml.2009.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S0749596X09000564",
author = "Sara Finley and William Badecker",
keywords = "Vowel harmony, Phonological features, Artificial grammar learning",
abstract = "Abstract representations such as subsegmental phonological features play such a vital role in explanations of phonological processes that many assume that these representations play an equally prominent role in the learning process. This assumption is tested in three artificial grammar experiments involving a mini language with morpho-phonological alternations based on back vowel harmony. In Experiments 1 and 2, adult participants were trained using positive data from four vowels in a six-vowel inventory: the two remaining vowels appeared at test only. If participants use subsegmental phonological features and natural classes for learning, they should generalize to the novel test segments. Results support a subsegmental feature-based learning strategy that makes use of phonetic information and knowledge of phonological principles. A third experiment (Experiment 3) tests for generalizations to novel suffixes, providing further evidence for the generality of learning."
}

@article{wang73,
author = {Wang, Marilyn D.  and Bilger, Robert C. },
title = {Consonant confusions in noise: a study of perceptual features},
journal = {The Journal of the Acoustical Society of America},
volume = {54},
number = {5},
pages = {1248-1266},
year = {1973},
doi = {10.1121/1.1914417},

URL = { 
        https://doi.org/10.1121/1.1914417
    
},
eprint = { 
        https://doi.org/10.1121/1.1914417
    
}

}



@article{miller55,
author = {Miller, George A.  and Nicely, Patricia E. },
title = {An Analysis of Perceptual Confusions Among Some {E}nglish Consonants},
journal = {The Journal of the Acoustical Society of America},
volume = {27},
number = {2},
pages = {338-352},
year = {1955},
doi = {10.1121/1.1907526},

URL = { 
        https://doi.org/10.1121/1.1907526
    
},
eprint = { 
        https://doi.org/10.1121/1.1907526
    
}

}




@incollection{hall07, place={Cambridge}, series={Cambridge Handbooks in Language and Linguistics}, title={Segmental features}, DOI={10.1017/CBO9780511486371.014}, booktitle={The Cambridge Handbook of Phonology}, publisher={Cambridge University Press}, author={Hall, T. A.}, editor={Paul de Lacy}, year={2007}, pages={311-334}, collection={Cambridge Handbooks in Language and Linguistics}}

@article{reali09,
title = "The evolution of frequency distributions: Relating regularization to inductive biases through iterated learning",
journal = "Cognition",
volume = "111",
number = "3",
pages = "317 - 328",
year = "2009",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2009.02.012",
url = "http://www.sciencedirect.com/science/article/pii/S0010027709000432",
author = "Florencia Reali and Thomas L. Griffiths",
keywords = "Iterated learning, Bayesian models, Frequency distributions, Word learning, Language acquisition",
abstract = "The regularization of linguistic structures by learners has played a key role in arguments for strong innate constraints on language acquisition, and has important implications for language evolution. However, relating the inductive biases of learners to regularization behavior in laboratory tasks can be challenging without a formal model. In this paper we explore how regular linguistic structures can emerge from language evolution by iterated learning, in which one person’s linguistic output is used to generate the linguistic input provided to the next person. We use a model of iterated learning with Bayesian agents to show that this process can result in regularization when learners have the appropriate inductive biases. We then present three experiments demonstrating that simulating the process of language evolution in the laboratory can reveal biases towards regularization that might not otherwise be obvious, allowing weak biases to have strong effects. The results of these experiments suggest that people tend to regularize inconsistent word-meaning mappings, and that even a weak bias towards regularization can allow regular languages to be produced via language evolution by iterated learning."
}



@article{cross12,
author = {Cross, Ian},
title = {Cognitive Science and the Cultural Nature of Music},
journal = {Topics in Cognitive Science},
volume = {4},
number = {4},
pages = {668-677},
keywords = {Music, Learning, Processing, Ethnomusicology, Culture},
doi = {10.1111/j.1756-8765.2012.01216.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2012.01216.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1756-8765.2012.01216.x},
abstract = {Abstract The vast majority of experimental studies of music to date have explored music in terms of the processes involved in the perception and cognition of complex sonic patterns that can elicit emotion. This paper argues that this conception of music is at odds both with recent Western musical scholarship and with ethnomusicological models, and that it presents a partial and culture-specific representation of what may be a generic human capacity. It argues that the cognitive sciences must actively engage with the problems of exploring music as manifested and conceived in the broad spectrum of world cultures, not only to elucidate the diversity of music in mind but also to identify potential commonalities that could illuminate the relationships between music and other domains of thought and behavior.},
year = {2012}
}


@article{tessier12,
author = { Anne-Michelle   Tessier },
title = {Testing for {OO}-Faithfulness in the Acquisition of Consonant Clusters},
journal = {Language Acquisition},
volume = {19},
number = {2},
pages = {144-173},
year  = {2012},
publisher = {Routledge},
doi = {10.1080/10489223.2012.660552},

URL = { 
        https://doi.org/10.1080/10489223.2012.660552
    
},
eprint = { 
        https://doi.org/10.1080/10489223.2012.660552
    
}

}


@inproceedings{goldwater03,
  author =       {Sharon Goldwater and Mark Johnson},
  title =        "{Learning OT constraint rankings using a maximum entropy model}",
  pages =        {111--20},
  booktitle = {Proceedings of the Workshop on Variation within Optimality Theory},
  year = "2003",
  publisher= {Stockholm University},
  address= {Stockholm},
  editor={Jennifer Spenader and Anders Eriksson and \"Osten Dahl },
}

	
	@article{hayes08,
	Author = {Bruce Hayes and Colin Wilson},
	Journal = {Linguistic Inquiry},
	Pages = {379--440},
	Title = {A Maximum Entropy model of phonotactics and phonotactic learning},
	Number = {3},
	Volume = {39},
	Year = {2008}}
	
	
	
	@incollection{legendre06,
  author =       {G\'eraldine Legendre and Antonella Sorace and Paul Smolensky},
  title =        "The {Optimality Theory}---{Harmonic Grammar} connection",
  pages =        {339--402},
  booktitle = {The Harmonic Mind: From Neural Computation to Optimality-Theoretic Grammar},
  year = "2006",
  publisher= {MIT Press},
  address= {Cambridge, MA},
  editor={Paul Smolensky and G\'eraldine Legendre},
}



@article{mpp17,
author = {Elliott Moreton  and Joe Pater and  Katya Pertsova},
title = {Phonological Concept Learning},
journal = {Cognitive Science},
volume = {41},
number = {1},
pages = {4-69},
keywords = {Phonotactic learning, Concept learning, Implicit learning, Inductive bias, Complexity, Maximum Entropy, Replicator Equation},
doi = {10.1111/cogs.12319},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12319},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12319},
abstract = {Abstract Linguistic and non-linguistic pattern learning have been studied separately, but we argue for a comparative approach. Analogous inductive problems arise in phonological and visual pattern learning. Evidence from three experiments shows that human learners can solve them in analogous ways, and that human performance in both cases can be captured by the same models. We test GMECCS (Gradual Maximum Entropy with a Conjunctive Constraint Schema), an implementation of the Configural Cue Model (Gluck \& Bower, ) in a Maximum Entropy phonotactic-learning framework (Goldwater \& Johnson, ; Hayes \& Wilson, ) with a single free parameter, against the alternative hypothesis that learners seek featurally simple algebraic rules (“rule-seeking”). We study the full typology of patterns introduced by Shepard, Hovland, and Jenkins () (“SHJ”), instantiated as both phonotactic patterns and visual analogs, using unsupervised training. Unlike SHJ, Experiments 1 and 2 found that both phonotactic and visual patterns that depended on fewer features could be more difficult than those that depended on more features, as predicted by GMECCS but not by rule-seeking. GMECCS also correctly predicted performance differences between stimulus subclasses within each pattern. A third experiment tried supervised training (which can facilitate rule-seeking in visual learning) to elicit simple rule-seeking phonotactic learning, but cue-based behavior persisted. We conclude that similar cue-based cognitive processes are available for phonological and visual concept learning, and hence that studying either kind of learning can lead to significant insights about the other.},
year = {2017}
}


@inproceedings{baljekar15,
  author={Pallavi Baljekar and Sunayana Sitaram and Prasanna Kumar Muthukumar and Alan W. Black},
  title={{Using articulatory features and inferred phonological segments in zero resource speech processing}},
  year=2015,
  booktitle={Proc. Interspeech 2015},
  pages={3194--3198},
  doi={10.21437/Interspeech.2015-643}
}



@inproceedings{moretonpertsova17,
 author = "Moreton, Elliott and Katya Pertsova",
 title = "Implicit and explicit processes in phonotactic learning",
 booktitle = "Proceedings of the 40th Boston University Conference on Language Acquisition ({BUCLD} 40)",
 editor = "Jennifer Scott and Deb Waugtal",
 pages = "277--290",
 year = "2017",
}

@inproceedings{feldman09,
 author = "Feldman, N. H. and Griffiths, T. L. and  Morgan, J. L.",
 title = "Learning phonetic categories by learning a lexicon",
 booktitle = "Proceedings of the 31st Annual Conference of the Cognitive Science Society.",
 editor = "Jennifer Scott and Deb Waugtal",
 pages = "2208-2213",
 year = "2009",
}

 (2009). "Learning phonetic categories by learning a lexicon." Proceedings of the 31st Annual Conference of the Cognitive Science Society.

@article{griffiths08,
author = {Thomas L Griffiths  and Michael L Kalish  and Stephan Lewandowsky },
title = {Theoretical and empirical evidence for the impact of inductive biases on cultural evolution},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
volume = {363},
number = {1509},
pages = {3503-3514},
year = {2008},
doi = {10.1098/rstb.2008.0146},
URL = {https://royalsocietypublishing.org/doi/abs/10.1098/rstb.2008.0146},
eprint = {https://royalsocietypublishing.org/doi/pdf/10.1098/rstb.2008.0146},
    abstract = { The question of how much the outcomes of cultural evolution are shaped by the cognitive capacities of human learners has been explored in several disciplines, including psychology, anthropology and linguistics. We address this question through a detailed investigation of transmission chains, in which each person passes information to another along a chain. We review mathematical and empirical evidence that shows that under general conditions, and across experimental paradigms, the information passed along transmission chains will be affected by the inductive biases of the people involved—the constraints on learning and memory, which influence conclusions from limited data. The mathematical analysis considers the case where each person is a rational Bayesian agent. The empirical work consists of behavioural experiments in which human participants are shown to operate in the manner predicted by the Bayesian framework. Specifically, in situations in which each person's response is used to determine the data seen by the next person, people converge on concepts consistent with their inductive biases irrespective of the information seen by the first member of the chain. We then relate the Bayesian analysis of transmission chains to models of biological evolution, clarifying how chains of individuals correspond to population-level models and how selective forces can be incorporated into our models. Taken together, these results indicate how laboratory studies of transmission chains can provide information about the dynamics of cultural evolution and illustrate that inductive biases can have a significant impact on these dynamics. }
}

@inproceedings{wu22,
  author={Peter Wu and Shinji Watanabe and Louis Goldstein and Alan W Black and Gopala Krishna Anumanchipalli},
  title={{Deep Speech Synthesis from Articulatory Representations}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={779--783},
  doi={10.21437/Interspeech.2022-10892}
}

@article {Bashivaneaav9436,
	author = {Bashivan, Pouya and Kar, Kohitij and DiCarlo, James J.},
	title = {Neural population control via deep image synthesis},
	volume = {364},
	number = {6439},
	elocation-id = {eaav9436},
	year = {2019},
	doi = {10.1126/science.aav9436},
	publisher = {American Association for the Advancement of Science},
	abstract = {To what extent are predictive deep learning models of neural responses useful for generating experimental hypotheses? Bashivan et al. took an artificial neural network built to model the behavior of the target visual system and used it to construct images predicted to either broadly activate large populations of neurons or selectively activate one population while keeping the others unchanged. They then analyzed the effectiveness of these images in producing the desired effects in the macaque visual cortex. The manipulations showed very strong effects and achieved considerable and highly selective influence over the neuronal populations. Using novel and non-naturalistic images, the neural network was shown to reproduce the overall behavior of the animals{\textquoteright} neural responses.Science, this issue p. eaav9436INTRODUCTIONThe pattern of light that strikes the eyes is processed and re-represented via patterns of neural activity in a {\textquotedblleft}deep{\textquotedblright} series of six interconnected cortical brain areas called the ventral visual stream. Visual neuroscience research has revealed that these patterns of neural activity underlie our ability to recognize objects and their relationships in the world. Recent advances have enabled neuroscientists to build ever more precise models of this complex visual processing. Currently, the best such models are particular deep artificial neural network (ANN) models in which each brain area has a corresponding model layer and each brain neuron has a corresponding model neuron. Such models are quite good at predicting the responses of brain neurons, but their contribution to an understanding of primate visual processing remains controversial.RATIONALEThese ANN models have at least two potential limitations. First, because they aim to be high-fidelity computerized copies of the brain, the total set of computations performed by these models is difficult for humans to comprehend in detail. In that sense, each model seems like a {\textquotedblleft}black box,{\textquotedblright} and it is unclear what form of understanding has been achieved. Second, the generalization ability of these models has been questioned because they have only been tested on visual stimuli that are similar to those used to {\textquotedblleft}teach{\textquotedblright} the models. Our goal was to assess both of these potential limitations through nonhuman primate neurophysiology experiments in a mid-level visual brain area. We sought to answer two questions: (i) Despite these ANN models{\textquoteright} opacity to simple {\textquotedblleft}understanding,{\textquotedblright} is the knowledge embedded in them already useful for a potential application (i.e., neural activity control)? (ii) Do these models accurately predict brain responses to novel images?RESULTSWe conducted several closed-loop neurophysiology experiments: After matching model neurons to each of the recorded brain neural sites, we used the model to synthesize entirely novel {\textquotedblleft}controller{\textquotedblright} images based on the model{\textquoteright}s implicit knowledge of how the ventral visual stream works. We then presented those images to each subject to test the model{\textquoteright}s ability to control the subject{\textquoteright}s neurons. In one test, we asked the model to try to control each brain neuron so strongly as to activate it beyond its typically observed maximal activation level. We found that the model-generated synthetic stimuli successfully drove 68\% of neural sites beyond their naturally observed activation levels (chance level is 1\%). In an even more stringent test, the model revealed that it is capable of selectively controlling an entire neural subpopulation, activating a particular neuron while simultaneously inactivating the other recorded neurons (76\% success rate; chance is 1\%).Next, we used these non-natural synthetic controller images to ask whether the model{\textquoteright}s ability to predict the brain responses would hold up for these highly novel images. We found that the model was indeed quite accurate, predicting 54\% of the image-evoked patterns of brain response (chance level is 0\%), but it is clearly not yet perfect.CONCLUSIONEven though the nonlinear computations of deep ANN models of visual processing are difficult to accurately summarize in a few words, they nonetheless provide a shareable way to embed collective knowledge of visual processing, and they can be refined by new knowledge. Our results demonstrate that the currently embedded knowledge already has potential application value (neural control) and that these models can partially generalize outside the world in which they {\textquotedblleft}grew up.{\textquotedblright} Our results also show that these models are not yet perfect and that more accurate ANN models would produce even more precise neural control. Such noninvasive neural control is not only a potentially powerful tool in the hands of neuroscientists but also could lead to a new class of therapeutic applications.Collection of images synthesized by a deep neural network model to control the activity of neural populations in primate cortical area V4.We used a deep artificial neural network to control the activity pattern of a population of neurons in cortical area V4 of macaque monkeys by synthesizing visual stimuli that, when applied to the subject{\textquoteright}s retinae, successfully induced the experimenter-desired neural response patterns.Particular deep artificial neural networks (ANNs) are today{\textquoteright}s most accurate models of the primate brain{\textquoteright}s ventral visual stream. Using an ANN-driven image synthesis method, we found that luminous power patterns (i.e., images) can be applied to primate retinae to predictably push the spiking activity of targeted V4 neural sites beyond naturally occurring levels. This method, although not yet perfect, achieves unprecedented independent control of the activity state of entire populations of V4 neural sites, even those with overlapping receptive fields. These results show how the knowledge embedded in today{\textquoteright}s ANN models might be used to noninvasively set desired internal brain states at neuron-level resolution, and suggest that more accurate ANN models would produce even more accurate control.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/364/6439/eaav9436},
	eprint = {https://science.sciencemag.org/content/364/6439/eaav9436.full.pdf},
	journal = {Science}
}

@article{pasley12,
    author = {Pasley, Brian N. AND David, Stephen V. AND Mesgarani, Nima AND Flinker, Adeen AND Shamma, Shihab A. AND Crone, Nathan E. AND Knight, Robert T. AND Chang, Edward F.},
    journal = {PLOS Biology},
    publisher = {Public Library of Science},
    title = {Reconstructing Speech from Human Auditory Cortex},
    year = {2012},
    month = {01},
    volume = {10},
    url = {https://doi.org/10.1371/journal.pbio.1001251},
    pages = {1-13},
    abstract = {Direct brain recordings from neurosurgical patients listening to speech reveal that the acoustic speech signals can be reconstructed from neural activity in auditory cortex.},
    number = {1},
    doi = {10.1371/journal.pbio.1001251}
}

@article{young08,
author = {Eric D Young },
title = {Neural representation of spectral and temporal information in speech},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
volume = {363},
number = {1493},
pages = {923-945},
year = {2008},
doi = {10.1098/rstb.2007.2151},

URL = {https://royalsocietypublishing.org/doi/abs/10.1098/rstb.2007.2151},
eprint = {https://royalsocietypublishing.org/doi/pdf/10.1098/rstb.2007.2151}
,
    abstract = { Speech is the most interesting and one of the most complex sounds dealt with by the auditory system. The neural representation of speech needs to capture those features of the signal on which the brain depends in language communication. Here we describe the representation of speech in the auditory nerve and in a few sites in the central nervous system from the perspective of the neural coding of important aspects of the signal. The representation is tonotopic, meaning that the speech signal is decomposed by frequency and different frequency components are represented in different populations of neurons. Essential to the representation are the properties of frequency tuning and nonlinear suppression. Tuning creates the decomposition of the signal by frequency, and nonlinear suppression is essential for maintaining the representation across sound levels. The representation changes in central auditory neurons by becoming more robust against changes in stimulus intensity and more transient. However, it is probable that the form of the representation at the auditory cortex is fundamentally different from that at lower levels, in that stimulus features other than the distribution of energy across frequency are analysed. }
}



@article {mesgarani14,
	author = {Mesgarani, Nima and Cheung, Connie and Johnson, Keith and Chang, Edward F.},
	title = {Phonetic Feature Encoding in Human Superior Temporal Gyrus},
	volume = {343},
	number = {6174},
	pages = {1006--1010},
	year = {2014},
	doi = {10.1126/science.1245994},
	publisher = {American Association for the Advancement of Science},
	abstract = {Consonants and vowels represent basic building blocks of human language. How their characteristics are extracted from acoustic speech input is not well understood. Directly recording from the superior temporal gyrus of patients as part of their clinical evaluation for epilepsy surgery, Mesgarani et al. (p. 1006, published online 30 January; see the Perspective by Grodzinsky and Nelken) investigated neural responses while the subjects listened to continuous speech. The findings reveal how both vowels and consonants of different phonetic categories are encoded. During speech perception, linguistic elements such as consonants and vowels are extracted from a complex acoustic speech signal. The superior temporal gyrus (STG) participates in high-order auditory processing of speech, but how it encodes phonetic information is poorly understood. We used high-density direct cortical surface recordings in humans while they listened to natural, continuous speech to reveal the STG representation of the entire English phonetic inventory. At single electrodes, we found response selectivity to distinct phonetic features. Encoding of acoustic properties was mediated by a distributed population response. Phonetic features could be directly related to tuning for spectrotemporal acoustic cues, some of which were encoded in a nonlinear fashion or by integration of multiple cues. These findings demonstrate the acoustic-phonetic representation of speech in human STG.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/343/6174/1006},
	eprint = {https://science.sciencemag.org/content/343/6174/1006.full.pdf},
	journal = {Science}
}




@book{a77,
address = {Lisse},
author = {Adelaar, Willem F. H.},
publisher = {The Peter de Ridder Press},
title = {Tarma {Q}uechua: Grammar, Texts, Dictionary},
year = {1977},
}

@book{smolensky06,
  title={The harmonic mind: From neural computation to optimality-theoretic grammar (Cognitive architecture), Vol. 1 \& 2},
  author={Smolensky, Paul and Legendre, G{\'e}raldine},
  year={2006},
  publisher={MIT press}
}

@article{alderete13,
title = "Phonological constraint induction in a connectionist network: learning OCP-Place constraints from data",
journal = "Language Sciences",
volume = "37",
pages = "52 - 69",
year = "2013",
issn = "0388-0001",
doi = "https://doi.org/10.1016/j.langsci.2012.10.002",
url = "http://www.sciencedirect.com/science/article/pii/S0388000112001210",
author = "John Alderete and Paul Tupper and Stefan A. Frisch",
keywords = "Constraint induction, Connectionism, Parallel distributed processing, Optimality Theory, Arabic, Dissimilation",
abstract = "A significant problem in computational language learning is that of inferring the content of well-formedness constraints from input data. In this article, we approach the constraint induction problem as the gradual adjustment of subsymbolic constraints in a connectionist network. In particular, we develop a multi-layer feed-forward network that learns the constraints that underlie restrictions against homorganic consonants, or ‘OCP-Place constraints’, in Arabic roots. The network is trained using standard learning procedures in connection science with a representative sample of Arabic roots. The trained network is shown to classify actual and novel Arabic roots in ways that are qualitatively parallel to a psycholinguistic study of Arabic. Statistical analysis of network behavior also shows that activations of nodes in the hidden layer correspond well with violations of symbolic well-formedness constraints familiar from generative phonology. In sum, it is shown that at least some constraints operative in phonotactic grammar can be learned from data and do not have to be stipulated in advance of learning."
}

  @Article{mgcv,
    title = {Fast stable restricted maximum likelihood and marginal 
likelihood estimation of semiparametric generalized linear models},
    journal = {Journal of the Royal Statistical Society (B)},
    volume = {73},
    number = {1},
    pages = {3-36},
    year = {2011},
    author = {S. N. Wood},
  }

@article{adh79,
author = {Ali, Latif and Ray Daniloff and Robert Hammarberg},
journal = {Phonetica},
pages = {85-97},
title = {Intrusive stops in nasal-fricative clusters: {A}n aerodynamic and acoustic investigation},
volume = {36},
year = {1979},
}

@article{davis06,
author = {Stuart Davis and Mi-Hui Cho},
journal = {Linguistic},
pages = {607-652},
title = {The distribution of aspirated stops and /h/ in {American English and Korean}: an alignment approach with typological implications},
volume = {41},
number={4},
year = {2006},
doi={10.1515/ling.2003.020}
}


@article{kim70,
author = {Kim, C.-W.},
journal = {Phonetica},
pages = {107-116},
title = {A Theory of Aspiration},
volume = {21},
year = {1970},
}

@article{peters63,
author = {Peters, Robert W. },
title = {Dimensions of Perception for Consonants},
journal = {The Journal of the Acoustical Society of America},
volume = {35},
number = {12},
pages = {1985-1989},
year = {1963},
doi = {10.1121/1.1918876},

URL = { 
        https://doi.org/10.1121/1.1918876
    
},
eprint = { 
        https://doi.org/10.1121/1.1918876
    
}

}


@article{phatak08,
author = {Phatak,Sandeep A.  and Lovitt,Andrew  and Allen,Jont B. },
title = {Consonant confusions in white noise},
journal = {The Journal of the Acoustical Society of America},
volume = {124},
number = {2},
pages = {1220-1233},
year = {2008},
doi = {10.1121/1.2913251},

URL = { 
        https://doi.org/10.1121/1.2913251
    
},
eprint = { 
        https://doi.org/10.1121/1.2913251
    
}

}




@article{mohr68,
author = {Mohr, B. and Wang, W. S.-Y. },
journal = {Phonetica},
pages = {31-45},
title = {Perceptual Distance and the Specification of Phonological Features},
volume = {18},
year = {1968},
doi={10.1159/000258597}
}



@article{a81,
author = {Anderson, Stephen R.},
journal = {Linguistic Inquiry},
number = {4},
pages = {493-539},
title = {Why phonology isn't ``natural''},
volume = {12},
year = {1981},
}

@book{ap94,
address = {Cambridge, MA},
author = {Archangeli, Diana and Douglas Pulleyblank},
publisher = {Massachusetts Institute of Technology Press},
title = {Grounded Phonology},
year = {1994},
}

@incollection{bh72,
address = {Bloomington},
author = {Bach, Emmon and Robert T. Harms},
booktitle = {Linguistic Change and Generative Theory},
editor = {Robert Stockwell and Ronald Macaulay},
pages = {1-21},
publisher = {Indiana University Press},
title = {How do languages get crazy rules?},
year = {1972},
}

@incollection{bh72,
address = {Bloomington},
author = {Bach, Emmon and Robert T. Harms},
booktitle = {Linguistic Change and Generative Theory},
editor = {Robert Stockwell and Ronald Macaulay},
pages = {1-21},
publisher = {Indiana University Press},
title = {How do languages get crazy rules?},
year = {1972},
}


@phdthesis{b02,
author = {Barnes, Jonathan},
school = {University of California, Berkeley},
title = {Positional neutralization: A phonologization approach to typological patterns},
year = {2002},
}


@mastersthesis{suhadolc13,
author = {Barbara Suhadolc},
school = {University of Ljubljana},
title = {Statisti\v{c}na analiza slovenskih besedil [{S}tatistic analysis of {S}lovenian texts]},
year = {2013},
url={eprints.fri.uni-lj.si/2157/}
}


@book{b61,
address = {Berlin},
author = {Bartholomae, Christian},
publisher = {Walter de Gruyter},
title = {Altiranisches {W}\"orterbuch},
year = {1961},
}

@article{bkn11,
author = {Becker, Michael and Nihan Ketrez and Andrew Nevins},
journal = {Language},
number = {1},
pages = {84-125},
title = {The surfeit of the stimulus: Analytic biases filter lexical statistics in {T}urkish laryngeal alternations},
volume = {87},
year = {2011},
}

@article{odden13,
author = {David Odden},
journal = {Nordlyd},
number = {1},
pages = {249-273},
title = {Formal Phonology},
volume = {40},
year = {2013},
doi={10.7557/12.2476}
}

2013  David  Odden. Nordlyd40.1:  249-273,  special  issue  ‘A  Festschrift  on  the  Occasion  of X  Years  of  CASTL Phonology and Curt Rice’s LthBirthday’ed. by Sylvia Blaho, Martin Krämer and Bruce Morén-Duolljá. University of Tromsø

@article{b09,
author = {Beddor, Patrice S.},
journal = {Language},
number = {4},
pages = {785-821},
title = {A coarticulatory path to sound change},
volume = {85},
year = {2009},
}

@phdthesis{b70,
author = {Bell, Alan},
school = {Stanford University},
title = {A state-process approach to syllabicity and syllabic structure},
year = {1970},
}

@article{b71,
author = {Bell, Alan},
journal = {Working Papers on Language Universals},
pages = {23-138},
title = {Some patterns of the occurrence and formation of syllabic structure},
volume = {6},
year = {1971},
}

@book{b04,
address = {Cambridge},
author = {Blevins, Juliette},
publisher = {Cambridge University Press},
title = {Evolutionary Phonology},
year = {2004},
}

@article{blevins07,
author = {Blevins, Juliette},
journal = {Linguistic Typology},
pages = {107-113},
title = {The importance of typology in explaining recurrent sound patterns},
volume = {11},
year = {2007},
}

@incollection{b08a,
address = {Amsterdam},
author = {Blevins, Juliette},
booktitle = {Naturalness and Iconicity in Language},
editor = {Klaas Willems and Ludovic De Cuypere},
pages = {121-148},
publisher = {Benjamins},
title = {Natural and unnatural sound patterns: A pocket field guide},
year = {2008},
}

@incollection{marvin18,
address = {Ljubljana},
author = {Tatjana Marvin and Jure Derganc and Samo Begu\v{s} and Saba Battelino},
booktitle = {Zbornik konference Jezikovne tehnologije in digitalna humanistika },
editor = {Darja Fi\v{s}er and Andrej Pan\v{c}ur},
pages = {181-187},
publisher = {Znanstvena zalo\v{z}ba {F}ilozofske fakultete v {L}jubljani},
title = {Word Selection in the {S}lovenian Sentence Matrix Test for Speech Audiometry},
year = {2018},
url={www.sdjt.si/wp/dogodki/konference/jtdh-2018/zbornik-jtdh-2018/}
}

@article{kessler97,
title = "Syllable Structure and the Distribution of Phonemes in {E}nglish Syllables",
journal = "Journal of Memory and Language",
volume = "37",
number = "3",
pages = "295 - 311",
year = "1997",
issn = "0749-596X",
doi = "https://doi.org/10.1006/jmla.1997.2522",
url = "http://www.sciencedirect.com/science/article/pii/S0749596X97925225",
author = "Brett Kessler and Rebecca Treiman",
abstract = "In describing the phonotactics (patterning of phonemes) of English syllables, linguists have focused on absolute restrictions concerning which phonemes may occupy which slots of the syllable. To determine whether probabilistic patterns also exist, we analyzed the distributions of phonemes in a reasonably comprehensive list of uninflected English CVC (consonant–vowel–consonant) words, some 2001 words in all. The results showed that there is a significant connection between the vowel and the following consonant (coda), with certain vowel–coda combinations being more frequent than expected by chance. In contrast, we did not find significant associations between the initial consonant (onset) and the vowel. These findings support the idea that English CVC syllables are composed of an onset and a vowel–coda rime. Implications for lexical processing are discussed."
}


@article{davidson16,
title = "Variability in the implementation of voicing in {American English} obstruents",
abstract = "Previous research has shown that in languages like English, the implementation of voicing in voiced obstruents is affected by linguistic factors such as utterance position, stress, and the adjacent sound. The goal of the current study is to extend previous findings in two ways: (1) investigate the production of voicing in connected read speech instead of in isolation/carrier sentences, and (2) understand the implementation of partial voicing by examining where in the constriction voicing appears or dies out. The current study examines the voicing of stops and fricatives in the connected read speech of 37 speakers. Results confirm that phrase position, word position, lexical stress, and the manner and voicing of the adjacent sound condition the prevalence of voicing, but they have different effects on stops and fricatives. The analysis of where voicing is realized in the constriction interval shows that bleed from a preceding sonorant is common, but voicing beginning partway through the constriction interval (i.e., negative voice onset time) is much rarer. The acoustic, articulatory, and aerodynamic sources of the patterns of phonation found in connected speech are discussed.",
keywords = "American English, Connected speech, Fricatives, Stops, Voicing",
author = "Lisa Davidson",
year = "2016",
month = "1",
day = "1",
doi = "10.1016/j.wocn.2015.09.003",
language = "English (US)",
volume = "54",
pages = "35--50",
journal = "Journal of Phonetics",
issn = "0095-4470",
publisher = "Academic Press Inc.",
}

@article{hayden50,
author = {Rebecca E. Hayden},
title = {The Relative Frequency of Phonemes in {General-American English}},
journal = {Word},
volume = {6},
number = {3},
pages = {217-223},
year  = {1950},
publisher = {Routledge},
doi = {10.1080/00437956.1950.11659381},
}

@article{lisker84,
author = {Leigh Lisker},
title ={How Is the Aspiration of English /p, t, k/ "Predictable"?},
journal = {Language and Speech},
volume = {27},
number = {4},
pages = {391-394},
year = {1984},
doi = {10.1177/002383098402700409},

URL = { 
        https://doi.org/10.1177/002383098402700409
    
},
eprint = { 
        https://doi.org/10.1177/002383098402700409
    
}
,
    abstract = { Aspiration as a phonetic property of the English stop categories is usually said to be non-distinctive on the ground that its occurrence can be accounted for by context-sensitive rules. The word-pair pin -spin is often cited by way of example. The word-initial voiceless stop is aspirated; the post-/s/ voiceless stop is not. But the presence of aspiration is "predicted" only for some voiceless stops - namely those that are "spelled" phonologically /p/ and are either word-initial or in a position where the next vowel is stressed and in the same word. Initial stops that are spelled /b/, as in bin, may also be voiceless, so that a rule which predicts aspiration from the voicelessness of an initial stop will not work, since bin is never aspirated. Thus the knowledge on which the prediction is based is not the voicelessness of the stop, or indeed on any other ascertainable phonetic property. We know that in some words voiceless initial stops can be freely replaced by voiced stops without semantic effect, and that those voiceless stops are never aspirated, while in other words there are initial voiceless stops that are regularly aspirated, and cannot be freely replaced by voiced stops. In other words, we know whether a voiceless stop is to be aspirated or not if we know how it is spelled phonologically. }
}


@article{iverson95,
 ISSN = {09526757, 14698188},
 URL = {http://www.jstor.org/stable/4420084},
 author = {Gregory K. Iverson and Joseph C. Salmons},
 journal = {Phonology},
 number = {3},
 pages = {369--396},
 publisher = {Cambridge University Press},
 title = {Aspiration and Laryngeal Representation in Germanic},
 volume = {12},
 year = {1995}
}



@article{mines78,
author={Mines, M. Ardussi  and Barbara F.  Hanson  and June E. Shoup},
year={1978},
month={Jul 01},
title={Frequency of Occurrence of Phonemes in Conversational {E}nglish},
journal={Language and speech},
volume={21},
number={3},
pages={221-241},
note={Last updated - 2013-02-23},
keywords={Linguistics/Philology},
isbn={0023-8309},
url={http://search.proquest.com.ezp-prod1.hul.harvard.edu/docview/1299110032?accountid=11311},
}

@incollection{b08b,
address = {Oxford},
author = {Blevins, Juliette},
booktitle = {Language Universals and Language Change},
editor = {Jeff Good},
pages = {79-107},
publisher = {Oxford University Press},
title = {Consonant epenthesis: Natural and unnatural histories},
year = {2008},
}

@incollection{blevins13,
address = {Oxford},
author = {Blevins, Juliette},
booktitle = {Handbook of Historical Phonology},
editor = {Patrick Honeybone and Joseph Salmons},
publisher = {Oxford University Press},
title = {{Evolutionary Phonology}: A holistic approach to sound change typology},
year = {2013},
}

@article{bg98,
author = {Blevins, Juliette and Andrew Garrett},
journal = {Language},
number = {3},
pages = {508-556},
title = {The origins of consonant-vowel metathesis},
volume = {74},
year = {1998},
}

@article{b74,
author = {Blust, Robert},
journal = {The Sarawak Museum Journal},
number = {43},
pages = {153-189},
title = {A {M}urik vocabulary, with a note on the linguistic position of {M}urik},
volume = {22},
year = {1974},
}

@article{b05,
author = {Blust, Robert},
journal = {Diachronica},
number = {2},
pages = {219-269},
title = {Must sound change be linguistically motivated?},
volume = {22},
year = {2005},
}


@Misc{beckers02,
author =   {Beckers, Gabriel J. L.},
title =    {rms equalize. Praat script.},
url = {www.gbeckers.nl/pages/praat\_scripts/rms\_equalize.praat\_script},
year = {2002}
}


@Misc{rentz17,
author =   {Bradley Rentz},
title =    {spectral\_moments.praat. Praat script.},
url = {https://github.com/rentzb/praat-scripts/blob/master/spectral\_moments.praat},
year = {2017},
}

@ARTICLE{baayen16,
       author = {{Baayen}, R. Harald  and {van Rij}, Jacolien and {de Cat}, Cecile and
         {Wood}, Simon N.},
        title = "{Autocorrelated errors in experimental data in the language sciences: Some solutions offered by Generalized Additive Mixed Models}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Applications},
         year = "2016",
        month = "Jan",
          eid = {arXiv:1601.02043},
        pages = {arXiv:1601.02043},
archivePrefix = {arXiv},
       eprint = {1601.02043},
 primaryClass = {stat.AP},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv160102043H},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@Misc{lennes03,
author =   {Mietta Lennes},
title =   {f0-F1-F2-intensity\_praat\_script. Praat script.},
note={Modified by Dan McCloy, Esther Le Gr\'esauze, and Ga\v{s}per Begu\v{s}},
url = {https://depts.washington.edu/phonlab/resources/f0-F1-F2-intensity\_praat\_script.praat},
year = {2003}
}


@Misc{pbase,
author =   {Jeff Mielke},
title =    {{PBase}: A database of phonological patterns},
url = {http://pbase.phon.chass.ncsu.edu},
year = {2018}
}




@book{gos,
author =   { Verdonik, Darinka and  Zwitter Vitez, Ana},
title =    {Slovenski govorni korpus {Gos}},
publisher="Trojina, zavod za uporabno slovenistiko",
url = {www.korpus-gos.net},
year = {2011},
address="Ljubljana"
}



@Misc{becker13,
author =   {Michael Becker and Jonathan Levine},
title =    {Experigen -- an online experiment platform},
url = {http://becker.phonologist.org/experigen},
year = {2013}
}


 @Article{lme4,
    title = {Fitting Linear Mixed-Effects Models Using {lme4}},
    author = {Douglas Bates and Martin M{\"a}chler and Ben Bolker and Steve Walker},
    journal = {Journal of Statistical Software},
    year = {2015},
    volume = {67},
    number = {1},
    pages = {1--48},
    doi = {10.18637/jss.v067.i01},
  }

@book{prince9304,
title = {{Optimality Theory}: Constraint Interaction in Generative Grammar},
year = "1993/2004",
author = {Alan Prince and Paul Smolensky},
address={Malden, MA},
publisher = {Blackwell},
note={First published in 1993, Tech. Rep. 2, Rutgers University Center for Cognitive Science},
}

@incollection{bybee99,
  title={Usage-based phonology},
  author={Bybee, Joan},
  booktitle={Functionalism and formalism in linguistics},
  editor = {Darnell, M. and Moravcsik, E. and Newmeyer, F. and Noonan, M. and Wheatley, K.},
  volume={1},
  url={https://www.unm.edu/~jbybee/downloads/Bybee1999UsageBasedPhonology.pdf},
  pages={211--242},
  year={1999},
  publisher={John Benjamins},
  location={Amsterdam},
}


@article{baroni19,
author = {Baroni, Marco },
title = {Linguistic generalization and compositionality in modern artificial neural networks},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
volume = {375},
number = {1791},
pages = {20190307},
year = {2020},
doi = {10.1098/rstb.2019.0307},

URL = {https://royalsocietypublishing.org/doi/abs/10.1098/rstb.2019.0307},
eprint = {https://royalsocietypublishing.org/doi/pdf/10.1098/rstb.2019.0307}
,
    abstract = { In the last decade, deep artificial neural networks have achieved astounding performance in many natural language-processing tasks. Given the high productivity of language, these models must possess effective generalization abilities. It is widely assumed that humans handle linguistic productivity by means of algebraic compositional rules: are deep networks similarly compositional? After reviewing the main innovations characterizing current deep language-processing networks, I discuss a set of studies suggesting that deep networks are capable of subtle grammar-dependent generalizations, but also that they do not rely on systematic compositional rules. I argue that the intriguing behaviour of these devices (still awaiting a full understanding) should be of interest to linguists and cognitive scientists, as it offers a new perspective on possible computational strategies to deal with linguistic productivity beyond rule-based compositionality, and it might lead to new insights into the less systematic generalization patterns that also appear in natural language. This article is part of the theme issue ‘Towards mechanistic models of meaning composition’. }
}

@article{hockett59,
 ISSN = {00187143, 15346617},
 URL = {http://www.jstor.org/stable/41449227},
 author = {Charles F. Hockett},
 journal = {Human Biology},
 number = {1},
 pages = {32--39},
 publisher = {Wayne State University Press},
 title = {ANIMAL "LANGUAGES" AND HUMAN LANGUAGE},
 volume = {31},
 year = {1959}
}




@article{piantadosi17,
    author = {Piantadosi, Steven T. and Fedorenko, Evelina},
    title = "{Infinitely productive language can arise from chance under communicative pressure}",
    journal = {Journal of Language Evolution},
    volume = {2},
    number = {2},
    pages = {141-147},
    year = {2017},
    month = {04},
    abstract = "{Human communication is unparalleled in the animal kingdom. The key distinctive feature of our language is productivity: we are able to express an infinite number of ideas using a limited set of words. Traditionally, it has been argued or assumed that productivity emerged as a consequence of very specific, innate grammatical systems. Here we formally develop an alternative hypothesis: productivity may have rather solely arisen as a consequence of increasing the number of signals (e.g. sentences) in a communication system, under the additional assumption that the processing mechanisms are algorithmically unconstrained. Using tools from algorithmic information theory, we examine the consequences of two intuitive constraints on the probability that a language will be infinitely productive. We prove that under maximum entropy assumptions, increasing the complexity of a language will not strongly pressure it to be finite or infinite. In contrast, increasing the number of signals in a language increases the probability of languages that have—in fact—infinite cardinality. Thus, across evolutionary time, the productivity of human language could have arisen solely from algorithmic randomness combined with a communicative pressure for a large number of signals.}",
    issn = {2058-4571},
    doi = {10.1093/jole/lzw013},
    url = {https://doi.org/10.1093/jole/lzw013},
    eprint = {https://academic.oup.com/jole/article-pdf/2/2/141/29093162/lzw013.pdf},
}





@article{chuang20,
	Abstract = {Pseudowords have long served as key tools in psycholinguistic investigations of the lexicon. A common assumption underlying the use of pseudowords is that they are devoid of meaning: Comparing words and pseudowords may then shed light on how meaningful linguistic elements are processed differently from meaningless sound strings. However, pseudowords may in fact carry meaning. On the basis of a computational model of lexical processing, linear discriminative learning (LDL Baayen et al., Complexity, 2019, 1--39, 2019), we compute numeric vectors representing the semantics of pseudowords. We demonstrate that quantitative measures gauging the semantic neighborhoods of pseudowords predict reaction times in the Massive Auditory Lexical Decision (MALD) database (Tucker et al., 2018). We also show that the model successfully predicts the acoustic durations of pseudowords. Importantly, model predictions hinge on the hypothesis that the mechanisms underlying speech production and comprehension interact. Thus, pseudowords emerge as an outstanding tool for gauging the resonance between production and comprehension. Many pseudowords in the MALD database contain inflectional suffixes. Unlike many contemporary models, LDL captures the semantic commonalities of forms sharing inflectional exponents without using the linguistic construct of morphemes. We discuss methodological and theoretical implications for models of lexical processing and morphological theory. The results of this study, complementing those on real words reported in Baayen et al., (Complexity, 2019, 1--39, 2019), thus provide further evidence for the usefulness of LDL both as a cognitive model of the mental lexicon, and as a tool for generating new quantitative measures that are predictive for human lexical processing.},
	Author = {Chuang, Yu-Ying and Vollmer, Marie Lenka and Shafaei-Bajestan, Elnaz and Gahl, Susanne and Hendrix, Peter and Baayen, R. Harald},
	Da = {2020/05/06},
	Date-Added = {2020-05-16 23:24:55 +0000},
	Date-Modified = {2020-05-16 23:24:55 +0000},
	Doi = {10.3758/s13428-020-01356-w},
	Id = {Chuang2020},
	Isbn = {1554-3528},
	Journal = {Behavior Research Methods},
	Title = {The processing of pseudoword form and meaning in production and comprehension: A computational modeling approach using linear discriminative learning},
	Ty = {JOUR},
	Url = {https://doi.org/10.3758/s13428-020-01356-w},
	Year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.3758/s13428-020-01356-w}}



@article{gahl06,
      author = "Susanne Gahl and Alan C. L. Yu",
      title = "Introduction to the special issue on exemplar-based models in linguistics",
      journal = "The Linguistic Review",
      year = "2006",
      publisher = "De Gruyter Mouton",
      address = "Berlin, Boston",
      volume = "23",
      number = "3",
      pages=      "213 - 216",
      url = "https://www.degruyter.com/view/journals/tlir/23/3/article-p213.xml"
}


@book{silverman17,
  title={A critical introduction to phonology: Functional and usage-based perspectives},
  author={Silverman, Daniel},
  year={2017},
  publisher={Bloomsbury Publishing}
}

@incollection{johnson07,
  title={Decisions and mechanisms in exemplar-based phonology},
  author={Johnson, Keith},
  booktitle={Experimental approaches to phonology},
  editor={Maria-Josep Sol\'e and Patrice Speeter Beddor and Manjari Ohala},
  pages={25--40},
  year={2007},
  publisher={Oxford University Press},
  location={Oxford}
}

@article{lipton17,
  author    = {Zachary C. Lipton and
               Subarna Tripathi},
  title     = {Precise Recovery of Latent Vectors from Generative Adversarial Networks},
  journal   = {CoRR},
  volume    = {abs/1702.04782},
  year      = {2017},
  url       = {http://arxiv.org/abs/1702.04782},
  archivePrefix = {arXiv},
  eprint    = {1702.04782},
  timestamp = {Mon, 13 Aug 2018 16:49:16 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LiptonT17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{donahue17,
  author    = {Chris Donahue and
               Akshay Balsubramani and
               Julian J. McAuley and
               Zachary C. Lipton},
  title     = {Semantically Decomposing the Latent Spaces of Generative Adversarial
               Networks},
  journal   = {CoRR},
  volume    = {abs/1705.07904},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.07904},
  archivePrefix = {arXiv},
  eprint    = {1705.07904},
  timestamp = {Mon, 22 Jul 2019 19:11:01 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/DonahueBML17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@Misc{boersma15,
author =   {Paul Boersma and David Weenink},
title =    {Praat: doing phonetics by computer [Computer program]. Version 5.4.06.},
howpublished = {Retrieved 21 February 2015 from http://www.praat.org/},
year = {2015}
}

@Misc{sskj,
author =   {Anton Bajec and others},
publisher={Slovenska akademija znanosti in umetnosti and {Znanstvenoraziskovalni center Slovenske akademije znanosti in umetnosti, In\v{s}titut za slovenski jezik Frana Ramov\v{s}a ZRC SAZU}},
address = "Ljubljana",
title =    {Slovar slovenskega knji\v{z}nega jezika},
url = {http://bos.zrc-sazu.si/sskj.html},
year = {2000}
}



  @Manual{emmeans,
    title = {emmeans: Estimated Marginal Means, aka Least-Squares Means},
    author = {Russell Lenth},
    year = {2018},
    note = {R package version 1.3.0},
    url = {https://CRAN.R-project.org/package=emmeans},
  }

  @Manual{r,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2018},
    url = {https://www.R-project.org/},
  }



@ARTICLE{vijver14,
  
AUTHOR={van de Vijver, Ruben and Baer-Henney, Dinah},   
	 
TITLE={Developing biases},      
	
JOURNAL={Frontiers in Psychology},      
	
VOLUME={5},      

PAGES={634},     
	
YEAR={2014},      
	  
URL={https://www.frontiersin.org/article/10.3389/fpsyg.2014.00634},       
	
DOI={10.3389/fpsyg.2014.00634},      
	
ISSN={1664-1078},   
   
ABSTRACT={German nouns may alternate from singular to plural in two different ways. Some singular forms that end in a voiceless obstruent have a plural in which this obstruent is voiced. Another alternation concerns the vowel. Some singular forms with a back vowel have a plural form in which this back vowel is front. For each noun it has to be established individually whether it alternates or not. The voicing alternation is phonetically grounded, but the vowel alternation is not.

Knowledge about such alternations involves two things. First, it involves knowledge of which words alternate and which words do not and second, it involves the ability to extend the alternations to novel words. We studied the knowledge of which words alternate and the proportion to which they alternate in two corpus studies. We studied the knowledge of speakers concerning which words alternate and what generalizations can be based upon these words by means of a production study. The production study involved words and nonces. We asked twenty 5 year-olds, twenty 7 year-olds and tenth adults to produce the plural for a given singular word and a plural for a given singular nonce.

In the corpus study we found that both alternations occur with the same frequency. In the production of alternations in words we found that participants in all age groups make few mistakes. With respect to the production of alternations in nonce words, we found that the proportion of voicing alternations decreases with age, while the proportion of vowel alternations increases. 

We explain this change in the ability to generalize the alternations to nonces on the basis of the confidence speakers can have in a generalization. Young children have a small lexicon and they can form relatively unreliable generalizations on lexical distributions, but they can have more confidence in their knowledge of phonetics. Adults have a large lexicon and can therefore confidently form based on their lexicon.}
}




@article{futrell17,
    title = "A Generative Model of Phonotactics",
    author = "Futrell, Richard  and
      Albright, Adam  and
      Graff, Peter  and
      O{'}Donnell, Timothy J.",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "5",
    year = "2017",
    url = "https://www.aclweb.org/anthology/Q17-1006",
    doi = "10.1162/tacl\_a\_00047",
    pages = "73--86",
    abstract = "We present a probabilistic model of phonotactics, the set of well-formed phoneme sequences in a language. Unlike most computational models of phonotactics (Hayes and Wilson, 2008; Goldsmith and Riggle, 2012), we take a fully generative approach, modeling a process where forms are built up out of subparts by phonologically-informed structure building operations. We learn an inventory of subparts by applying stochastic memoization (Johnson et al., 2007; Goodman et al., 2008) to a generative process for phonemes structured as an and-or graph, based on concepts of feature hierarchy from generative phonology (Clements, 1985; Dresher, 2009). Subparts are combined in a way that allows tier-based feature interactions. We evaluate our models{'} ability to capture phonotactic distributions in the lexicons of 14 languages drawn from the WOLEX corpus (Graff, 2012). Our full model robustly assigns higher probabilities to held-out forms than a sophisticated N-gram model for all languages. We also present novel analyses that probe model behavior in more detail.",
}

@book{b13,
address = {Canberra},
author = {Blust, Robert},
publisher = {Asia-Pacific Linguistics},
title = {The {A}ustronesian Languages},
year = {2013},
}

@book{toporisic04,
address = {Maribor},
author = {Jo\v{z}e Topori\v{s}i\v{c}},
publisher = {Obzorja},
title = {Slovenska slovnica},
year = {2004}
}

@article{sustarsic95, 
title={Slovene}, 
volume={25}, DOI={10.1017/S0025100300005211}, 
number={2}, 
journal={Journal of the International Phonetic Association}, 
publisher={Cambridge University Press}, 
author={Rastislav \v{S}u\v{s}tar\v{s}i\v{c} and Smiljana Komar and Bojan Petek}, 
year={1995}, pages={86–90}
}


@article{blust17,
author = {Blust, Robert},
journal = {Journal of Historical Linguistics},
number = {3},
pages = {322-371},
title = {Odd conditions: Context-sensitive sound change in unexpected contexts},
volume = {7},
year = {2017},
}

@article{bg92,
author = {Browman, Catherine P. and Louis Goldstein},
journal = {Phonetica},
pages = {155-180},
title = {Articulatory phonology: An overview},
volume = {49},
year = {1992},
}

@article{brown17,
author = {Brown, Jason},
journal = {Oceanic Linguistics},
number = {1},
pages = {267-277},
title = {Postnasal devoicing in {N}asioi},
volume = {56},
year = {2017},
}

@article{b00,
author = {Buckley, Eugene},
journal = {{Proceedings from the Second {W}orkshop on {A}merican Indigenous Languages. UCSB Working Papers in Linguistics}},
pages = {1-14},
title = {On the naturalness of unnatural rules},
volume = {9},
year = {2000},
}

@incollection{bd18,
address = {Berlin},
author = {Burkard, Monja and Kristina Dziallas},
booktitle = {{Proceedings of the Conference on Phonetics \& Phonology in {G}erman-speaking Countries 13}},
editor = {Malte Belz and Christine Mooshammer and Susanne Fuchs and Stefanie Jannedy and Oksana Rasskazova and Marzena \.{Z}ygis},
publisher = {Humboldt-Universit\"at zu Berlin},
title = {Final /d/ in the varieties of {M}adrid, {B}arcelona and {S}eville: Regional and stylistic variation},
year = {2018},
}

@phdthesis{b14,
author = {Burkhardt, J\"urgen M.},
school = {Johann-Wolfgang-Goethe-Universit\"at zu Frankfurt am Main},
title = {The reconstruction of the phonology of {Proto-Berawan}},
year = {2014},
}

@incollection{busa07,
address = {Oxford},
author = {Bus\`a, M. Grazia},
booktitle = {Experimental Approaches to Phonology},
editor = {Maria-Josep Sol\'e and Patrice Speeter},
pages = {155-174},
publisher = {Oxford University Press},
title = {Coarticulatory nasalization and phonological developments: data from {I}talian and {E}nglish nasal-fricative sequences},
year = {2007},
}

@book{b01,
address = {Cambridge},
author = {Bybee, Joan},
publisher = {Cambridge University Press},
title = {Phonology and Language Use},
year = {2001},
}

@article{boersma01,
author = {Boersma, Paul and Hayes, Bruce},
title = {Empirical Tests of the Gradual Learning Algorithm},
journal = {Linguistic Inquiry},
volume = {32},
number = {1},
pages = {45-86},
year = {2001},
doi = {10.1162/002438901554586},

URL = { 
        https://doi.org/10.1162/002438901554586
    
},
eprint = { 
        https://doi.org/10.1162/002438901554586
    
}
,
    abstract = { The Gradual Learning Algorithm (Boersma 1997) is a constraint-ranking algorithm for learning optimality-theoretic grammars. The purpose of this article is to assess the capabilities of the Gradual Learning Algorithm, particularly in comparison with the Constraint Demotion algorithm of Tesar and Smolensky (1993, 1996, 1998, 2000), which initiated the learnability research program for Optimality Theory. We argue that the Gradual Learning Algorithm has a number of special advantages: it can learn free variation, deal effectively with noisy learning data, and account for gradient well-formedness judgments. The case studies we examine involve Ilokano reduplication and metathesis, Finnish genitive plurals, and the distribution of English light and dark /l/. }
}


@article{c10,
author = {Carpenter, Angela C.},
journal = {Phonology},
number = {3},
pages = {345-392},
title = {A naturalness bias in learning stress},
volume = {27},
year = {2010},
}

@misc{chockler21,
  doi = {10.48550/ARXIV.2103.03622},
  
  url = {https://arxiv.org/abs/2103.03622},
  
  author = {Chockler, Hana and Kroening, Daniel and Sun, Youcheng},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Explanations for Occluded Images},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@incollection{c72,
address = {The Hague},
author = {Catford, John C.},
booktitle = {{Proceedings of the Seventh {I}nternational Congress of Phonetic Sciences}},
editor = {Andr\'e Rigault and Ren\'e Charbonneau},
pages = {679-682},
publisher = {Mouton},
title = {Labialization in {C}aucasian languages, with special reference to {A}bkhaz},
year = {1972},
}

@inproceedings{chen74,
crossref = {cls},
author = {Chen, Matthew Y.},
pages = {21-29},
title = {Natural phonology from the diachronic vantage point},
year = {1974},
}





@book{cls,
address = {Chicago, IL},
title = {Papers from the {Parasession on Natural Phonology}},
editor = {Anthony Bruck and Robert A. Fox and Michael W. LaGaly},
publisher = {Chicago Linguistic Society},
year = {1974},
}

@inproceedings{c74,
author = {Catford, John C.},
crossref = {cls},
pages = {21-29},
title = {Natural sound changes: Some questions of directionality and diachronic phonetics},
year = {1974},
}

@inproceedings{c15,
address = {Amherst, MA},
author = {Cathcart, Chundra A.},
booktitle = {{Proceedings of the {F}orty-Fifth Annual Meeting of the {N}orth {East Linguistic Society}}},
editor = {Thuy Bui and Deniz \"Ozy\i ld\i z},
note = {Volume 1},
pages = {145-150},
publisher = {GLSA},
title = {A probabilistic model of {Evolutionary Phonology}},
year = {2015},
}

@inproceedings{inkelas17,
address = {Washington, DC},
author = {Sharon Inkelas and Stephanie S. Shih},
booktitle = {{Proceedings of the {F}orty-Fifth Annual Meeting of the {N}orth {East Linguistic Society}}},
editor = { Karen Jesney and Charlie O'Hara and Caitlin Smith and Rachel Walker},
pages = {1-18},
publisher = {Linguistic Society of America},
title = {Looking into Segments},
year = {2017},
}


@Article{gauvain95,
author="Mary Gauvain",
title="Thinking in Niches: Sociocultural Influences on Cognitive Development",
journal="Human Development",
year="1995",
volume="38",
number="1",
pages="25-45",
doi="10.1159/000278297",
}



@article{sankoff07,
 ISSN = {00978507, 15350665},
 URL = {http://www.jstor.org/stable/40070902},
 abstract = {We address the articulation between language change in the historical sense and language change as experienced by individual speakers through a trend and panel study of the change from apical to dorsal /r/ in Montreal French. The community as a whole rapidly advanced its use of dorsal [R]. Most individual speakers followed across time were stable after the critical period, with phonological patterns set by the end of adolescence. A sizeable minority, however, made substantial changes. The window of opportunity for linguistic modification in later life may be expanded with rapid change in progress when linguistic variables take on social significance.},
 author = {Gillian Sankoff and H\'el\`ene Blondeau},
 journal = {Language},
 number = {3},
 pages = {560--588},
 publisher = {Linguistic Society of America},
 title = {Language Change across the Lifespan: /r/ in {Montreal French}},
 volume = {83},
 year = {2007}
}

@article{kong12,
title = "Voice onset time is necessary but not always sufficient to describe acquisition of voiced stops: The cases of {G}reek and {J}apanese",
journal = "Journal of Phonetics",
volume = "40",
number = "6",
pages = "725 - 744",
year = "2012",
issn = "0095-4470",
doi = "https://doi.org/10.1016/j.wocn.2012.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S0095447012000526",
author = "Eun Jong Kong and Mary E. Beckman and Jan Edwards",
abstract = "The age at which children master adult-like voiced stops can generally be predicted by voice onset time (VOT): stops with optional short lag are early, those with obligatory lead are late. However, Japanese voiced stops are late despite having a short lag variant, whereas Greek voiced stops are early despite having consistent voicing lead. This cross-sectional study examines the acoustics of word-initial stops produced by English-, Japanese-, and Greek-speaking children aged 2–5, to investigate how these seemingly exceptional mastery patterns relate to use of other phonetic correlates. Productions were analyzed for VOT, f0 and spectral tilt (H1−H2) in Japanese and English, and for amplitude trajectory in Greek and Japanese. Japanese voiceless stops have intermediate lag VOT values, so other “secondary” cues are needed to differentiate them from the voiced short lag VOT variant. Greek voiced stops are optionally prenasalized, and the amplitude trajectory for the voice bar during closure suggests that younger children use a greater degree of nasal venting to create the aerodynamic conditions necessary for voicing lead. Taken together, the findings suggest that VOT must be supplemented by measurements of other language-specific acoustic properties to explain the mastery pattern of voiced stops in some languages."
}

@incollection{clark86,
 author = "Eve V. Clark and Melissa Bowerman",
 title = "On the acquisition of final voiced stops",
pages = "51-68",
 booktitle  = "The Fergusonian Impact: In Honor of Charles A. Ferguson on the Occasion of his 65th Birthday.",
 address = "Berlin",
 publisher = "De Gruyter",
 volume="1",
 year = "1986",
 editor="J. A. Fishman."
}

@inproceedings{thiollire15,
  title={A hybrid dynamic time warping-deep neural network architecture for unsupervised acoustic modeling},
  author={Roland Thiolli{\`e}re and Ewan Dunbar and Gabriel Synnaeve and Maarten Versteegh and Emmanuel Dupoux},
  booktitle={Proceedings of Interspeech},
  year={2015}
}


@inproceedings{lee12,
    title = "A Nonparametric {B}ayesian Approach to Acoustic Model Discovery",
    author = "Lee, Chia-ying  and
      Glass, James",
    booktitle = "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2012",
    address = "Jeju Island, Korea",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P12-1005",
    pages = "40--49",
}


@article{martin12,
author = {Martin, Andrew and Peperkamp, Sharon and Dupoux, Emmanuel},
title = {Learning Phonemes With a Proto-Lexicon},
journal = {Cognitive Science},
volume = {37},
number = {1},
pages = {103-124},
keywords = {First language acquisition, Statistical learning, Phonemes, Allophonic rules},
doi = {10.1111/j.1551-6709.2012.01267.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1551-6709.2012.01267.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1551-6709.2012.01267.x},
abstract = {Abstract Before the end of the first year of life, infants begin to lose the ability to perceive distinctions between sounds that are not phonemic in their native language. It is typically assumed that this developmental change reflects the construction of language-specific phoneme categories, but how these categories are learned largely remains a mystery. Peperkamp, Le Calvez, Nadal, and Dupoux (2006) present an algorithm that can discover phonemes using the distributions of allophones as well as the phonetic properties of the allophones and their contexts. We show that a third type of information source, the occurrence of pairs of minimally differing word forms in speech heard by the infant, is also useful for learning phonemic categories and is in fact more reliable than purely distributional information in data containing a large number of allophones. In our model, learners build an approximation of the lexicon consisting of the high-frequency n-grams present in their speech input, allowing them to take advantage of top-down lexical information without needing to learn words. This may explain how infants have already begun to exhibit sensitivity to phonemic categories before they have a large receptive lexicon.},
year = {2013}
}


@article{dupoux18,
title = "Cognitive science in the era of artificial intelligence: A roadmap for reverse-engineering the infant language-learner",
journal = "Cognition",
volume = "173",
pages = "43 - 59",
year = "2018",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2017.11.008",
url = "http://www.sciencedirect.com/science/article/pii/S0010027717303013",
author = "Emmanuel Dupoux",
keywords = "Artificial intelligence, Speech, psycholinguistics, Computational modeling, Corpus analysis, Early language acquisition, Infant development, Language bootstrapping, Machine learning",
abstract = "Spectacular progress in the information processing sciences (machine learning, wearable sensors) promises to revolutionize the study of cognitive development. Here, we analyse the conditions under which ’reverse engineering’ language development, i.e., building an effective system that mimics infant’s achievements, can contribute to our scientific understanding of early language development. We argue that, on the computational side, it is important to move from toy problems to the full complexity of the learning situation, and take as input as faithful reconstructions of the sensory signals available to infants as possible. On the data side, accessible but privacy-preserving repositories of home data have to be setup. On the psycholinguistic side, specific tests have to be constructed to benchmark humans and machines at different linguistic levels. We discuss the feasibility of this approach and present an overview of current results."
}


@unpublished{albright19,
 author = "Albright, Adam and Youngah Do",
 title = "Three biases in learning phonological alternation",
 note="Ms., MIT and University of Hong Kong. Accessed on January 12, 2019.",
url="https://yd79.files.wordpress.com/2014/06/threebiases.pdf",
 year = "2019"
}

@unpublished{vaux02,
 author = "Bert Vaux",
 title = "Aspiration in {E}nglish",
 note="Ms., Harvard University. Accessed on June 27, 2019.",
url="https://www.academia.edu/300605/Aspiration\_In\_English",
 year = "2002"
}
 
1

, Harvard University


@incollection{broselow18,
 author = "Ellen Broselow",
 title = "Laryngeal contrasts in second language phonology",
 booktitle = "Phonological typology",
editor={Larry M. Hyman and Frans Plank},
 address = "Berlin",
 publisher = "De Gruyter",
 pages = "312--340",
 year = 2018
}

@article{efron79,
title = {Bootstrap Methods: Another Look at the Jackknife},
journal = "{The Annals of Statistics}",
volume = "7",
number = "1",
pages = "1--26",
year = "1979",
author = {Bradley Efron},
}

@article{efron87,
author = { Bradley   Efron },
title = {Better Bootstrap Confidence Intervals},
journal = {Journal of the American Statistical Association},
volume = {82},
number = {397},
pages = {171-185},
year  = {1987},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.1987.10478410},
}





@incollection{altarriba93,
title = "The Influence of Culture on Cognitive Processes",
editor = "Jeanette Altarriba",
series = "Advances in Psychology",
publisher = "North-Holland",
volume = "103",
pages = "379 - 384",
year = "1993",
booktitle = "Cognition and Culture",
issn = "0166-4115",
doi = "https://doi.org/10.1016/S0166-4115(08)61673-8",
url = "http://www.sciencedirect.com/science/article/pii/S0166411508616738",
author = "Jeanette Altarriba",
abstract = "Publisher Summary
Culture has been defined in various ways throughout history. The most useful definition of culture was proposed by Edward Burnett Tylor in his work, Primitive Culture, published in 1871. Tylor defined culture as “that complex whole that includes knowledge, belief, art, morals, customs, and any other capabilities and habits acquired by man as a member of society.” In contrast, Ruth Fulton Benedict, in her work Patterns of Culture, emphasized the differences between cultural traditions and the effects of cultures on the individuals experiencing them. Since the late 1800's, several researchers have tried to identify and describe the link between culture and cognition by examining the results of cross-cultural studies. Although all of these works describe the relationship between cultural variables and cognitive processes, they typically review ethnographic and observational studies conducted from an anthropological perspective. Very few books, with the exception of Segall et al., contain comprehensive, theoretical reviews of the literature from the perspective of cognitive, experimental psychology. All of the existing volumes are also permitted in scope, typically focusing on issues relating to problem solving, memory, and cognitive development. The present chapter is an attempt at filling this void by organizing a set of current readings in anthropology, cognitive psychology, cross-cultural psychology, and linguistics that are empirical in nature."
}


@article{pater09,
title = {Weighted Constraints in Generative Linguistics},
journal = "Cognitive Science",
volume = "33",
pages = "999--1035",
year = "2009",
author = {Joe Pater},
}

@Article{kuo09,
author="Kuo, Li-Jen",
title="The Role of Natural Class Features in the Acquisition of Phonotactic Regularities",
journal="Journal of Psycholinguistic Research",
year="2009",
month="Apr",
day="01",
volume="38",
number="2",
pages="129--150",
abstract="Previous research has shown that phonotactic regularities can be acquired through recent production or auditory experience (e.g., Dell et  al., Journal of Experimental Psychology: Learning, Memory, and Cognition, 26(6), 1355--1367, 2000; Onishi et al., Cognition, 83(1), B13--B23, 2002). However, little is known about the role of phonological natural classes in this learning process. This study addressed this question by investigating the acquisition of a contingency relationship between onsets and medial glides by Mandarin speakers. The experiments involved the manipulation of three types of phonotactic regularities. In the Laryngeal version, onsets that preceded the same glide shared a voicing feature. In the Place version, onsets that preceded same glide shared a place feature. In the Neither version, onsets associated with the same glide shared neither a voicing feature nor a place feature. Results showed the Place version and the Laryngeal version were more easily acquired than the Neither version in terms of the amount of exposure needed to acquire the experimentally manipulated phonotactic schema and the sustainability of the acquired schema. The results suggest that the statistical learning mechanism that guides our processing of speech input prefers phonological regularities that follow certain natural class features. This preference may account for the way natural languages are structured phonologically.",
issn="1573-6555",
doi="10.1007/s10936-008-9090-2",
url="https://doi.org/10.1007/s10936-008-9090-2"
}


@article{skoruppa11,
author = {Skoruppa, Katrin and Peperkamp, Sharon},
title = {Adaptation to Novel Accents: Feature-Based Learning of Context-Sensitive Phonological Regularities},
journal = {Cognitive Science},
volume = {35},
number = {2},
pages = {348-366},
keywords = {Speech perception, Phonological learning, Dialects, Accents, Features},
doi = {10.1111/j.1551-6709.2010.01152.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1551-6709.2010.01152.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1551-6709.2010.01152.x},
abstract = {Abstract This paper examines whether adults can adapt to novel accents of their native language that contain unfamiliar context-dependent phonological alternations. In two experiments, French participants listen to short stories read in accented speech. Their knowledge of the accents is then tested in a forced-choice identification task. In Experiment 1, two groups of listeners are exposed to newly created French accents in which certain vowels harmonize or disharmonize, respectively, to the rounding of the preceding vowel. Despite the cross-linguistic predominance of vowel harmony over disharmony, the two groups adapt equally well to both accents, suggesting that this typological difference is not reflected in perceptual learning. Experiment 2 further explores the mechanism underlying this type of phonological learning. Participants are exposed to an accent in which some vowels harmonize and others disharmonize, yielding an increased featural complexity. They adapt less well to this regularity, showing that adaptation to novel accents involves feature-based inferences.},
year = {2011}
}

 @unpublished{seidl07,
title = {Complexity trumps naturalness},
year = "2007",
author = {Seidl, Amanda and Eugene Buckley and Alejandrina Cristi\`a},
note = {Talk presented at the 81st \textit{Annual Meeting of the Linguistic Society of America},  Anaheim, CA, January 4-7, 2007},
}

  @unpublished{glewwe17,
title = {Substantive Bias in Phonotactic Learning: Positional Extension of an Obstruent Voicing Contrast},
year = "2017",
author = {Eleanor Glewwe},
note = {Talk presented at the 53rd meeting of \textit{Chicago Linguistic Society}, Chicago, IL, May 25-27, 2017},
}

  @unpublished{glewwe18,
title = {Substantive bias and word-final voiced obstruents: An artificial grammar learning study},
year = "2017",
author = {Eleanor Glewwe and Jesse Zymet and Jacob Adams and Rachel Jacobson and Anthony Yates and Ann Zeng and Robert Daland},
note = {Talk presented at the 92nd {Annual Meeting of the Linguistic Society of America}, Salt Lake City, UT, January 4-7, 2018.}
}

  @unpublished{do16,
title = {Naturalness and frequency in implicit phonological learning},
year = "2016",
author = {Youngah Do and Elizabeth Zsiga and Jonathan Havenhill},
note = {Talk presented at the 90th \textit{Annual Meeting of the Linguistic Society of America}, Washington, DC, January 7-10, 2016},
}



@inproceedings{pycha03,
address = {Somerville, MA},
author = {Anne Pycha and Pawel Nowak and Eurie Shin and Ryan Shosted},
booktitle = {{Proceedings of the 22nd West Coast Conference on Formal Linguistics}},
editor = {Gina Garding and Mimu Tsujimura},
pages = {101-114},
publisher = {Cascadilla Press},
title = {Phonological rule-learing and its implications for a theory of vowel harmony},
year = {2003},
}


@inproceedings{kapatsinski11,
author = {Vsevolod  Kapatsinski},
booktitle = {{Proceedings of the {XVII}th {I}nternational {C}ongress of {P}honetic {S}ciences}},
title = {The link between separability of features and learnability of dependencies between them},
year = {2011},
pages={1022-1025}
}

@book{kapatsinski18,
address = {Cambridge},
author = {Vsevolod  Kapatsinski},
publisher = {MIT Press},
title = {Changing Minds Changing Tools: From Learning Theory to Language Acquisition to Language Change},
year = {2018},
}


@book{ch68,
address = {New York},
author = {Chomsky, Noam and Morris Halle},
publisher = {Harper \& Row},
title = {The Sound Pattern of {E}nglish},
year = {1968},
}

@article{cp10,
author = {Coetzee, Andries W. and Rigardt Pretorius},
journal = {Journal of Phonetics},
pages = {404-421},
title = {Phonetically grounded phonology and sound change: The case of {T}swana labial plosives},
volume = {38},
year = {2010},
}

@book{trubetzkoy39,
series = {Travaux de Cercle linguistique de Prague ; 7},
publisher = {[s.n.] ;},
year = {1939},
title = {Grundz\"uge der Phonologie},
language = {fre},
address = {Prague},
author = {Trubetzkoy, Nikolai Sergeyevich},
keywords = {Grammar, Comparative and general -- Phonology.}
}



@inproceedings{clp07,
address = {Saarbr\"ucken},
author = {Coetzee, Andries W. and Susan Lin and Rigardt Pretorius},
booktitle = {{Proceedings of the 16th {I}nternational Congress of Phonetic Sciences}},
editor = {J\"urgen Trouvain and William J. Barry},
pages = {861-864},
title = {Post-nasal devoicing in {T}swana},
year = {2007},
}

@incollection{c06,
address = {Oxford},
author = {Cohn, Abigail C.},
booktitle = {Gradience in Grammar: Generative Perspectives},
editor = {G. Fanselow and C. F\'ery and M. Schlesewsky},
pages = {25-44},
publisher = {Oxford University Press},
title = {Is there gradient phonology?},
year = {2006},
}

@article{d16,
author = {Davidson, Lisa},
journal = {Journal of Phonetics},
pages = {35-50},
title = {Variability in the implementation of voicing in {A}merican {E}nglish obstruents},
volume = {54},
year = {2016},
}



@article{khatami20,
	Abstract = {The auditory neural code is resilient to acoustic variability and capable of recognizing sounds amongst competing sound sources, yet, the transformations enabling noise robust abilities are largely unknown. We report that a hierarchical spiking neural network (HSNN) optimized to maximize word recognition accuracy in noise and multiple talkers predicts organizational hierarchy of the ascending auditory pathway. Comparisons with data from auditory nerve, midbrain, thalamus and cortex reveals that the optimal HSNN predicts several transformations of the ascending auditory pathway including a sequential loss of temporal resolution and synchronization ability, increasing sparseness, and selectivity. The optimal organizational scheme enhances performance by selectively filtering out noise and fast temporal cues such as voicing periodicity, that are not directly relevant to the word recognition task. An identical network arranged to enable high information transfer fails to predict auditory pathway organization and has substantially poorer performance. Furthermore, conventional single-layer linear and nonlinear receptive field networks that capture the overall feature extraction of the HSNN fail to achieve similar performance. The findings suggest that the auditory pathway hierarchy and its sequential nonlinear feature extraction computations enhance relevant cues while removing non-informative sources of noise, thus enhancing the representation of sounds in noise impoverished conditions.},
	Author = {Khatami, Fatemeh AND Escab{\'\i}, Monty A.},
	Doi = {10.1371/journal.pcbi.1007558},
	Journal = {PLOS Computational Biology},
	Month = {06},
	Number = {6},
	Pages = {1-27},
	Publisher = {Public Library of Science},
	Title = {Spiking network optimized for word recognition in noise predicts auditory system hierarchy},
	Url = {https://doi.org/10.1371/journal.pcbi.1007558},
	Volume = {16},
	Year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.1371/journal.pcbi.1007558}}



@article{smith21,
	Abstract = {Broad organizational features of the auditory pathway have been replicated by artificial neural networks trained on diverse and naturalistic stimuli. It is credible that neural network analogues could also reveal specific neural computations underlying targeted auditory phenomena. This remains to be established. Here, we examined a modified autoencoder (a deep neural network akin to symbolic regression) trained to imitate an auditory behavior rooted in the binaural system. The behavior promoted the use of split-second interaural timing cues to improve the detection of a tone presented in noise. In the optimal network, we observed the emergence of specialized computations with prominent similarities to animal models. Artificial neurons developed a sensitivity to temporal delays that increased deeper into the network and were widely distributed in preference (extending to delays beyond the range permitted by head width), and the ensuing dynamics were consistent with a binaural cross-correlation mechanism. Our results attest to the generality of these solutions for performing signal detection at low frequencies. Moreover, this is a primary demonstration that deep learning methods can be used to infer tangible mechanisms underlying auditory perception.AUTHOR SUMMARY Do artificial intelligence (AI) systems process sounds in a similar way to the brain? If so, they represent a vital resource with which to investigate sensory systems. Here, we report an AI system that automatically developed auditory computations similar to those described in animal neurophysiology. The network learnt to use subtle discrepancies across its {\textquotedblleft}two ears{\textquotedblright} to better detect a signal amongst a background noise. In the process, tuning to timing cues and established mechanisms of binaural hearing (relating to the use of both ears) developed internally. The results offer insight into computations occurring in deep brain structures that are difficult to measure with non-invasive techniques. Further, the results endorse informed associations made between AI systems and the auditory brain.Competing Interest StatementThe authors have declared no competing interest.},
	Author = {Smith, Samuel S. and Sollini, Joseph and Akeroyd, Michael A.},
	Doi = {10.1101/2021.01.05.425246},
	Elocation-Id = {2021.01.05.425246},
	Eprint = {https://www.biorxiv.org/content/early/2021/05/13/2021.01.05.425246.full.pdf},
	Journal = {bioRxiv},
	Publisher = {Cold Spring Harbor Laboratory},
	Title = {Inferring the neural basis of binaural phenomena with a modified autoencoder},
	Url = {https://www.biorxiv.org/content/early/2021/05/13/2021.01.05.425246},
	Year = {2021},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/early/2021/05/13/2021.01.05.425246},
	Bdsk-Url-2 = {https://doi.org/10.1101/2021.01.05.425246}}


@article{koumura19,
	Abstract = {The auditory system converts the physical properties of a sound waveform to neural activities and processes them for recognition. During the process, the tuning to amplitude modulation (AM) is successively transformed by a cascade of brain regions. To test the functional significance of the AM tuning, we conducted single-unit recording in a deep neural network (DNN) trained for natural sound recognition. We calculated the AM representation in the DNN and quantitatively compared it with those reported in previous neurophysiological studies. We found that an auditory-system-like AM tuning emerges in the optimized DNN. Better-recognizing models showed greater similarity to the auditory system. We isolated the factors forming the AM representation in the different brain regions. Because the model was not designed to reproduce any anatomical or physiological properties of the auditory system other than the cascading architecture, the observed similarity suggests that the AM tuning in the auditory system might also be an emergent property for natural sound recognition during evolution and development.SIGNIFICANCE STATEMENT This study suggests that neural tuning to amplitude modulation may be a consequence of the auditory system evolving for natural sound recognition. We modeled the function of the entire auditory system; that is, recognizing sounds from raw waveforms with as few anatomical or physiological assumptions as possible. We analyzed the model using single-unit recording, which enabled a fair comparison with neurophysiological data with as few methodological biases as possible. Interestingly, our results imply that frequency decomposition in the inner ear might not be necessary for processing amplitude modulation. This implication could not have been obtained if we had used a model that assumes frequency decomposition.},
	Author = {Koumura, Takuya and Terashima, Hiroki and Furukawa, Shigeto},
	Doi = {10.1523/JNEUROSCI.2914-18.2019},
	Eprint = {https://www.jneurosci.org/content/39/28/5517.full.pdf},
	Issn = {0270-6474},
	Journal = {Journal of Neuroscience},
	Number = {28},
	Pages = {5517--5533},
	Publisher = {Society for Neuroscience},
	Title = {Cascaded Tuning to Amplitude Modulation for Natural Sound Recognition},
	Url = {https://www.jneurosci.org/content/39/28/5517},
	Volume = {39},
	Year = {2019},
	Bdsk-Url-1 = {https://www.jneurosci.org/content/39/28/5517},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.2914-18.2019}}


@article{d17,
author = {Davidson, Lisa},
journal = {Journal of the International Phonetic Association},
pages = {1-26},
title = {Phonation and laryngeal specification in {A}merican {E}nglish voiceless obstruents},
year = {2017},
}

@article{davidson18, title={Phonation and laryngeal specification in American English voiceless obstruents}, volume={48}, DOI={10.1017/S0025100317000330}, number={3}, journal={Journal of the International Phonetic Association}, publisher={Cambridge University Press}, author={Davidson, Lisa}, year={2018}, pages={331–356}}


@article{kell18,
	Annote = {doi: 10.1016/j.neuron.2018.03.044},
	Author = {Kell, Alexander J. E. and Yamins, Daniel L. K. and Shook, Erica N. and Norman-Haignere, Sam V. and McDermott, Josh H.},
	Booktitle = {Neuron},
	Date = {2018/05/02},
	Date-Added = {2021-06-22 12:56:10 +0000},
	Date-Modified = {2021-06-22 12:56:10 +0000},
	Doi = {10.1016/j.neuron.2018.03.044},
	Isbn = {0896-6273},
	Journal = {Neuron},
	M3 = {doi: 10.1016/j.neuron.2018.03.044},
	Month = {2021/06/22},
	Number = {3},
	Pages = {630--644.e16},
	Publisher = {Elsevier},
	Title = {A Task-Optimized Neural Network Replicates Human Auditory Behavior, Predicts Brain Responses, and Reveals a Cortical Processing Hierarchy},
	Ty = {JOUR},
	Url = {https://doi.org/10.1016/j.neuron.2018.03.044},
	Volume = {98},
	Year = {2018},
	Year1 = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuron.2018.03.044}}


@article{schrimpf20,
	Abstract = {The ability to share ideas through language is our species{\textquoteright} signature cognitive skill, but how this feat is achieved by the brain remains unknown. Inspired by the success of artificial neural networks (ANNs) in explaining neural responses in perceptual tasks (Kell et al., 2018; Khaligh-Razavi \&amp; Kriegeskorte, 2014; Schrimpf et al., 2018; Yamins et al., 2014; Zhuang et al., 2017), we here investigated whether state-of-the-art ANN language models (e.g. Devlin et al., 2018; Pennington et al., 2014; Radford et al., 2019) capture human brain activity elicited during language comprehension. We tested 43 language models spanning major current model classes on three neural datasets (including neuroimaging and intracranial recordings) and found that the most powerful generative transformer models (Radford et al., 2019) accurately predict neural responses, in some cases achieving near-perfect predictivity relative to the noise ceiling. In contrast, simpler word-based embedding models (e.g. Pennington et al., 2014) only poorly predict neural responses (\&lt;10\% predictivity). Models{\textquoteright} predictivities are consistent across neural datasets, and also correlate with their success on a next-word-prediction task (but not other language tasks) and ability to explain human comprehension difficulty in an independent behavioral dataset. Intriguingly, model architecture alone drives a large portion of brain predictivity, with each model{\textquoteright}s untrained score predictive of its trained score. These results support the hypothesis that a drive to predict future inputs may shape human language processing, and perhaps the way knowledge of language is learned and organized in the brain. In addition, the finding of strong correspondences between ANNs and human representations opens the door to using the growing suite of tools for neural network interpretation to test hypotheses about the human mind.Competing Interest StatementThe authors have declared no competing interest.},
	Author = {Schrimpf, Martin and Blank, Idan and Tuckute, Greta and Kauf, Carina and Hosseini, Eghbal A. and Kanwisher, Nancy and Tenenbaum, Joshua and Fedorenko, Evelina},
	Doi = {10.1101/2020.06.26.174482},
	Elocation-Id = {2020.06.26.174482},
	Eprint = {https://www.biorxiv.org/content/early/2020/06/27/2020.06.26.174482.full.pdf},
	Journal = {bioRxiv},
	Publisher = {Cold Spring Harbor Laboratory},
	Title = {Artificial Neural Networks Accurately Predict Language Processing in the Brain},
	Url = {https://www.biorxiv.org/content/early/2020/06/27/2020.06.26.174482},
	Year = {2020},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/early/2020/06/27/2020.06.26.174482},
	Bdsk-Url-2 = {https://doi.org/10.1101/2020.06.26.174482}}



@article{yamins16,
	Abstract = {Recent computational neuroscience developments have used deep neural networks to model neural responses in higher visual areas. This Perspective describes key algorithmic underpinnings in computer vision and artificial intelligence that have contributed to this progress and outlines how deep networks could drive future improvements in understanding sensory cortical processing.},
	Author = {Yamins, Daniel L K and DiCarlo, James J},
	Da = {2016/03/01},
	Date-Added = {2021-06-22 09:34:51 +0000},
	Date-Modified = {2021-06-22 09:34:51 +0000},
	Doi = {10.1038/nn.4244},
	Id = {Yamins2016},
	Isbn = {1546-1726},
	Journal = {Nature Neuroscience},
	Number = {3},
	Pages = {356--365},
	Title = {Using goal-driven deep learning models to understand sensory cortex},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/nn.4244},
	Volume = {19},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1038/nn.4244}}



@article{d91,
author = {de Jong, Kenneth},
journal = {Phonetica},
number = {1},
pages = {1-17},
title = {An articulatory study of consonant-induced vowel duration changes in {E}nglish},
volume = {48},
year = {1991},
}

@article{d04,
author = {de Jong, Kenneth},
journal = {Journal of Phonetics},
number = {4},
pages = {493-516},
title = {Stress, lexical focus, and segmental focus in {E}nglish: Patterns of variation in vowel duration},
volume = {32},
year = {2004},
}

@article{prickett19, title={Learning biases in opaque interactions}, volume={36}, DOI={10.1017/S0952675719000320}, number={4}, journal={Phonology}, publisher={Cambridge University Press}, author={Prickett, Brandon}, year={2019}, pages={627–653}}

@article{heinz13,
author = {Heinz, Jeffrey and Idsardi, William},
title = {What Complexity Differences Reveal About Domains in Language},
journal = {Topics in Cognitive Science},
volume = {5},
number = {1},
pages = {111-131},
keywords = {Phonology, Syntax, Computational complexity, Language learning},
doi = {10.1111/tops.12000},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12000},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/tops.12000},
abstract = {Abstract An important distinction between phonology and syntax has been overlooked. All phonological patterns belong to the regular region of the Chomsky Hierarchy, but not all syntactic patterns do. We argue that the hypothesis that humans employ distinct learning mechanisms for phonology and syntax currently offers the best explanation for this difference.},
year = {2013}
}


@article{heinz11,
author = {Heinz, Jeffrey},
title = {Computational Phonology – Part II: Grammars, Learning, and the Future},
journal = {Language and Linguistics Compass},
volume = {5},
number = {4},
pages = {153-168},
doi = {10.1111/j.1749-818X.2011.00268.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1749-818X.2011.00268.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1749-818X.2011.00268.x},
abstract = {Abstract Computational phonology studies sound patterns in the world's languages from a computational perspective. This article shows that the similarities between different generative theories outweigh the differences, and discusses stochastic grammars and learning models within phonology from a computational perspective. Also, it shows how the hypothesis that all sound patterns are subregular can be investigated, pointing the direction for future research. Taken together, these contributions show computational phonology is identifying stronger and stronger universal properties of phonological patterns, which are reflected in the grammatical formalisms phonologists employ. This article is intended primarily for phonologists who are curious about computational phonology, but do not have a rigorous background in mathematics or computation. However, it is also informative for readers with a background in computation and the basics of phonology, and who are curious about what computational analysis offers phonological theory.},
year = {2011}
}


@article{abramson17,
title = "Voice Onset Time (VOT) at 50: Theoretical and practical issues in measuring voicing distinctions",
journal = "Journal of Phonetics",
volume = "63",
pages = "75 - 86",
year = "2017",
issn = "0095-4470",
doi = "https://doi.org/10.1016/j.wocn.2017.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S0095447016301048",
author = "Arthur S. Abramson and D.H. Whalen",
keywords = "VOT (Voice Onset Time), Voicing, Consonants, Stops, Duration",
abstract = "Just over fifty years ago, Lisker and Abramson proposed a straightforward measure of acoustic differences among stop consonants of different voicing categories, Voice Onset Time (VOT). Since that time, hundreds of studies have used this method. Here, we review the original definition of VOT, propose some extensions to the definition, and discuss some problematic cases. We propose a set of terms for the most important aspects of VOT and a set of Praat labels that could provide some consistency for future cross-study analyses. Although additions of other aspects of realization of voicing distinctions (F0, amplitude, duration of voicelessness) could be considered, they are rejected as adding too much complexity for what has turned out to be one of the most frequently used metrics in phonetics and phonology."
}

@inbook{albright11,
author = {Albright, Adam and Hayes, Bruce},
publisher = {Wiley},
isbn = {9781444343069},
title = {Learning and Learnability in Phonology},
booktitle = {The Handbook of Phonological Theory},
chapter = {20},
pages = {661-690},
doi = {10.1002/9781444343069.ch20},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781444343069.ch20},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781444343069.ch20},
year = {2011},
keywords = {learning and learnability in phonology - children, acquiring patterns in their native language, formal approaches, modeling the path - learning phonological grammars of natural languages, theory of how children learn phonological systems - characterizing knowledge to be acquired, speakers of languages - knowledge of phonological alternations, subset problem - in phonotactic learning, phonological alternations - phonotactic learning, not the only task learners face, theories for learning alternations - approaches using surface mappings, learnability studies, complementing experimental work - direct evidence for UG principles, challenges, that learners face - in analyzing phonological distributions and alternations, computational resources, and power expanding - proposals, subject to realistic testing},
abstract = {Summary This chapter contains sections titled: Chapter Content Defining the Problem Learning Phonotactics Phonological Alternations What Doesn't Have to be Learned? The Issue of UG Conclusion}
}

@article{dk13,
author = {de Lacy, Paul and John Kingston},
journal = {Natural Language and Linguistic Theory},
number = {2},
pages = {287-355},
title = {Synchronic explanation},
volume = {31},
year = {2013},
}

@article{dell93,
title = "Structure and content in language production: A theory of frame constraints in phonological speech errors",
journal = "Cognitive Science",
volume = "17",
number = "2",
pages = "149 - 195",
year = "1993",
issn = "0364-0213",
doi = "https://doi.org/10.1016/0364-0213(93)90010-6",
url = "http://www.sciencedirect.com/science/article/pii/0364021393900106",
author = "Gary S. Dell and Cornell Juliano and Anita Govindjee",
abstract = "Theories of language production propose that utterances are constructed by a mechanism that separates linguistic content from linguistic structure, Linguistic content is retrieved from the mental lexicon, and is then inserted into slots in linguistic structures or frames. Support for this kind of model at the phonological level comes from patterns of phonological speech errors. W present an alternative account of these patterns using a connectionist or parallel distributed proceesing (PDP) model that learns to produce sequences of phonological features. The model's errors exhibit some of the properties of human speech errors, specifically, properties that have been attributed to the action of phonological rules, frames, or other structural generalizations."
}

@ARTICLE{kawamoto15,
  
AUTHOR={Kawamoto, Alan H. and Liu, Qiang and Kello, Christopher T.},   
	 
TITLE={The segment as the minimal planning unit in speech production and reading aloud: evidence and implications},      
	
JOURNAL={Frontiers in Psychology},      
	
VOLUME={6},      

PAGES={1457},     
	
YEAR={2015},      
	  
URL={https://www.frontiersin.org/article/10.3389/fpsyg.2015.01457},       
	
DOI={10.3389/fpsyg.2015.01457},      
	
ISSN={1664-1078},   
   
ABSTRACT={Speech production and reading aloud studies have been treated as relatively distinct research enterprises for many years, but there has recently been increasing recognition that they have much in common, especially the last stages involved in producing a response.  The issue that we focus on in this review is the minimal planning unit (MPU) in articulation.  Many researchers once assumed that the MPU was the phonological word, although most researchers now assume that it is the syllable.  However, there have also been a few researchers who have assumed that the MPU is smaller than the syllable.  We present evidence based on absolute response latencies and initial segment durations in phonological priming and speeded naming studies that the MPU is at least as small as the segment, and discuss why such evidence was not found in earlier studies.  Next, we rebut the argument that the segment MPU cannot account for anticipatory coarticulation.   Finally, we argue that the segment MPU is important not only in its own right, but also because it provides an alternative explanation of results implicated in the serial vs. parallel processing debate.}
}

@book{legendre90,
  title={Harmonic grammar: A formal multi-level connectionist theory of linguistic well-formedness: Theoretical foundations},
  author={Legendre, G{\'e}raldine and Miyata, Yoshiro and Smolensky, Paul},
  year={1990},
  publisher={University of Colorado, Boulder. ICS Technical Report \#90-5.}
}

@article{whitesundara14,
title = "Biased generalization of newly learned phonological alternations by 12-month-old infants",
journal = "Cognition",
volume = "133",
number = "1",
pages = "85 - 90",
year = "2014",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2014.05.020",
url = "http://www.sciencedirect.com/science/article/pii/S0010027714001097",
author = "James White and Megha Sundara",
keywords = "Phonological alternations, Infant speech perception, Language acquisition, Learning biases, Phonetic similarity",
abstract = "Previous work has suggested that learners are sensitive to phonetic similarity when learning phonological patterns (e.g., Steriade, 2001/2008, White, 2014). We tested 12-month-old infants to see if their willingness to generalize newly learned phonological alternations depended on the phonetic similarity of the sounds involved. Infants were exposed to words in an artificial language whose distributions provided evidence for a phonological alternation between two relatively dissimilar sounds ([p∼v] or [t∼z]). Sounds at one place of articulation (labials or coronals) alternated whereas sounds at the other place of articulation were contrastive. At test, infants generalized the alternation learned during exposure to pairs of sounds that were more similar ([b∼v] or [d∼z]). Infants in a control group instead learned an alternation between similar sounds ([b∼v] or [d∼z]). When tested on dissimilar pairs of sounds ([p∼v] or [t∼z]), the control group did not generalize their learning to the novel sounds. The results are consistent with a learning bias favoring alternations between similar sounds over alternations between dissimilar sounds."
}


@article{yin18,
title = "Neutralization and homophony avoidance in phonological learning",
journal = "Cognition",
volume = "179",
pages = "89 - 101",
year = "2018",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2018.05.023",
url = "http://www.sciencedirect.com/science/article/pii/S0010027718301495",
author = "Sora Heng Yin and James White",
keywords = "Phonology, Language change, Learning bias, Functional load, Neutralization, Artificial language",
abstract = "Previous research has suggested that homophony avoidance plays a role in constraining language change; in particular, phonological contrasts are less likely to be neutralized if doing so would greatly increase the amount of homophony in the language. Most of the research on homophony avoidance has focused on the history of real languages, comparing attested and unattested (hypothetical) phonological changes. In this study, we take a novel approach by focusing on the language learner. Using an artificial language learning paradigm, we show that learners are less likely to acquire neutralizing phonological rules compared to non-neutralizing rules, but only if the neutralizing rules create homophony between lexical items encountered during learning. The results indicate that learners are biased against phonological patterns that create homophony, which could have an influence on language change. The results also suggest that lexical learning and phonological learning are highly integrated."
}

@article{d84,
author = {Dickens, Patrick J.},
journal = {Journal of African Languages and Linguistics},
pages = {97-125},
title = {The history of so-called strengthening in {T}swana},
volume = {6},
year = {1984},
}

@book{d77,
address = {Cambridge},
author = {Dixon, Robert M. W.},
publisher = {Cambridge University Press},
title = {A grammar of {Y}idin},
year = {1977},
}

@article{kamper15,
  title={Unsupervised neural network based feature extraction using weak top-down constraints},
  author={Herman Kamper and Micha Elsner and Aren Jansen and Sharon Goldwater},
  journal={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2015},
  pages={5818-5822}
}

@article{feldman13,
  title={A role for the developing lexicon in phonetic category acquisition.},
  author={Feldman, Naomi H and Griffiths, Thomas L and Goldwater, Sharon and Morgan, James L},
  journal={Psychological review},
  volume={120},
  number={4},
  pages={751},
  year={2013},
  publisher={American Psychological Association}
}




@unpublished{barry19,
    title = "{InfoWaveGAN}: Informative Latent Spaces for Waveform Generation",
    author = "Shaun M. Barry and Youngmoo E. Kim",
    year = {2019},
note = {Poster at the North East Music Information Special Interest Group},
url={http://nemisig2019.nemisig.org/images/kimSlides.pdf},
    }

@inproceedings{elsner13,
    title = "A Joint Learning Model of Word Segmentation, Lexical Acquisition, and Phonetic Variability",
    author = "Elsner, Micha  and
      Goldwater, Sharon  and
      Feldman, Naomi  and
      Wood, Frank",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D13-1005",
    pages = "42--54",
}

@article{goldwater09,
title = "A Bayesian framework for word segmentation: Exploring the effects of context",
journal = "Cognition",
volume = "112",
number = "1",
pages = "21 - 54",
year = "2009",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2009.03.008",
url = "http://www.sciencedirect.com/science/article/pii/S0010027709000675",
author = "Sharon Goldwater and Thomas L. Griffiths and Mark Johnson",
keywords = "Computational modeling, Bayesian, Language acquisition, Word segmentation",
abstract = "Since the experiments of Saffran et al. [Saffran, J., Aslin, R., & Newport, E. (1996). Statistical learning in 8-month-old infants. Science, 274, 1926–1928], there has been a great deal of interest in the question of how statistical regularities in the speech stream might be used by infants to begin to identify individual words. In this work, we use computational modeling to explore the effects of different assumptions the learner might make regarding the nature of words – in particular, how these assumptions affect the kinds of words that are segmented from a corpus of transcribed child-directed speech. We develop several models within a Bayesian ideal observer framework, and use them to examine the consequences of assuming either that words are independent units, or units that help to predict other units. We show through empirical and theoretical results that the assumption of independence causes the learner to undersegment the corpus, with many two- and three-word sequences (e.g. what’s that, do you, in the house) misidentified as individual words. In contrast, when the learner assumes that words are predictive, the resulting segmentation is far more accurate. These results indicate that taking context into account is important for a statistical word segmentation strategy to be successful, and raise the possibility that even young infants may be able to exploit more subtle statistical patterns than have usually been considered."
}

@INPROCEEDINGS{heymann13, author={J. {Heymann} and O. {Walter} and R. {Haeb-Umbach} and B. {Raj}}, booktitle={2013 IEEE Workshop on Automatic Speech Recognition and Understanding}, title={Unsupervised word segmentation from noisy input}, year={2013}, volume={}, number={}, pages={458-463},}



@inproceedings{faruqui16,
    title = "Morphological Inflection Generation Using Character Sequence to Sequence Learning",
    author = "Faruqui, Manaal  and
      Tsvetkov, Yulia  and
      Neubig, Graham  and
      Dyer, Chris",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N16-1077",
    doi = "10.18653/v1/N16-1077",
    pages = "634--643",
}


@inproceedings{silfverberg18,
    title = "Sound Analogies with Phoneme Embeddings",
    author = "Silfverberg, Miikka P.  and
      Mao, Lingshuang  and
      Hulden, Mans",
    booktitle = "Proceedings of the Society for Computation in Linguistics ({SC}i{L}) 2018",
    year = "2018",
    url = "https://www.aclweb.org/anthology/W18-0314",
    doi = "10.7275/R5NZ85VD",
    pages = "136--144",
}

@article{dresher15,
   author = "Dresher, B. Elan",
   title = "The motivation for contrastive feature hierarchies in phonology", 
   journal= "Linguistic Variation",
   year = "2015",
   volume = "15",
   number = "1",
   pages = "1-40",
   doi = "https://doi.org/10.1075/lv.15.1.01dre",
   url = "https://www.jbe-platform.com/content/journals/10.1075/lv.15.1.01dre",
   publisher = "John Benjamins",
   issn = "2211-6834",
   type = "Journal Article",
   abstract = "The notion that phonological features are organized into contrastive hierarchies has been entertained at different times in the history of linguistics. My main focus will be on the motivation for such hierarchies: what principles govern the ordering of the features? I will show that they have been motivated by three different principles: a) Activity: to identify the contrastive features that are relevant to the phonological computation, b) Minimality: to minimize redundancy in phonological representations and to maximize the amount of information conveyed by each feature, and c) Universality: to express universal tendencies in the nature of phonological inventories and the order of acquisition of feature contrasts. These principles do not necessarily conflict in every case, but in practice situations arise where they lead in different directions. To some extent Jakobson and Halle (Jakobson &amp; Halle 1956; Halle 1959) and Clements (2001; 2003; 2009) appeal to all these principles, though they do so with differing emphases: Jakobson began by appealing to Activity, Halle came to stress Minimality, and Clements focused on Universality. I will argue on behalf of the centrality of Activity, which I understand to be the original and most compelling motivation for feature hierarchies.",
  }
  
  
 @INPROCEEDINGS{chen21,
  author={Chen, Yu-Wen and Hung, Kuo-Hsuan and Chuang, Shang-Yi and Sherman, Jonathan and Huang, Wen-Chin and Lu, Xugang and Tsao, Yu},
  booktitle={2021 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={EMA2S: An End-to-End Multimodal Articulatory-to-Speech System}, 
  year={2021},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ISCAS51556.2021.9401485}} 
  
@article{rasanen16,
	Abstract = {Infants' speech perception adapts to the phonemic categories of their native language, a process assumed to be driven by the distributional properties of speech. This study investigates whether deep neural networks (DNNs), the current state-of-the-art in distributional feature learning, are capable of learning phoneme-like representations of speech in an unsupervised manner. We trained DNNs with unlabeled and labeled speech and analyzed the activations of each layer with respect to the phones in the input segments. The analyses reveal that the emergence of phonemic invariance in DNNs is dependent on the availability of phonemic labeling of the input during the training. No increased phonemic selectivity of the hidden layers was observed in the purely unsupervised networks despite successful learning of low-dimensional representations for speech. This suggests that additional learning constraints or more sophisticated models are needed to account for the emergence of phone-like categories in distributional learning operating on natural speech.},
	An = {29359204},
	Author = {R{\"a}s{\"a}nen, Okko and Nagamine, Tasha and Mesgarani, Nima},
	Date = {2016/08/},
	Date-Added = {2020-04-04 07:59:02 +0000},
	Date-Modified = {2020-04-04 07:59:02 +0000},
	Db = {PubMed},
	J2 = {Cogsci},
	Journal = {CogSci ... Annual Conference of the Cognitive Science Society. Cognitive Science Society (U.S.). Conference},
	Keywords = {categorical perception; connectionism; distributional learning; language acquisition; phonemic categories; speech perception; statistical learning},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5775908/},
	La = {eng},
	Month = {08},
	Pages = {1757--1762},
	Title = {Analyzing Distributional Learning of Phonemic Categories in Unsupervised Deep Neural Networks},
	Ty = {JOUR},
	U1 = {29359204{$[$}pmid{$]$}},
	U2 = {PMC5775908{$[$}pmcid{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/29359204},
	Volume = {2016},
	Year = {2016},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/29359204}}

@article{richmond11,
   title={Announcing the Electromagnetic Articulography (Day 1) Subset of the mngu0 Articulatory Corpus},
   journal={Interspeech 2011},
   publisher={ISCA},
   author={Korin Richmond and Phil Hoole and Simon King},
   year={2011},
   pages={1505–1508},
}

@article{browman92,
url = {https://doi.org/10.1159/000261913},
title = {Articulatory Phonology: An Overview},
title = {},
author = {Catherine P. Browman and Louis Goldstein},
pages = {155--180},
volume = {49},
number = {3-4},
journal = {Phonetica},
doi = {doi:10.1159/000261913},
year = {1992},
lastchecked = {2022-09-20}
}


@inproceedings{shain19,
    title = "Measuring the perceptual availability of phonological features during language acquisition using unsupervised binary stochastic autoencoders",
    author = "Shain, Cory  and
      Elsner, Micha",
    booktitle = "Proceedings of the 2019 NAACL-HLT, Volume 1",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/N19-1007",
    pages = "69--85",
    abstract = "In this paper, we deploy binary stochastic neural autoencoder networks as models of infant language learning in two typologically unrelated languages (Xitsonga and English). We show that the drive to model auditory percepts leads to latent clusters that partially align with theory-driven phonemic categories. We further evaluate the degree to which theory-driven phonological features are encoded in the latent bit patterns, finding that some (e.g. [+-approximant]), are well represented by the network in both languages, while others (e.g. [+-spread glottis]) are less so. Together, these findings suggest that many reliable cues to phonemic structure are immediately available to infants from bottom-up perceptual characteristics alone, but that these cues must eventually be supplemented by top-down lexical and phonotactic information to achieve adult-like phone discrimination. Our results also suggest differences in degree of perceptual availability between features, yielding testable predictions as to which features might depend more or less heavily on top-down cues during child language acquisition.",
}

@article{shane20,
title = "Ease of learning explains semantic universals",
journal = "Cognition",
volume = "195",
pages = "104076",
year = "2020",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2019.104076",
url = "http://www.sciencedirect.com/science/article/pii/S0010027719302495",
author = "Shane Steinert-Threlkeld and Jakub Szymanik",
abstract = "Semantic universals are properties of meaning shared by the languages of the world. We offer an explanation of the presence of such universals by measuring simplicity in terms of ease of learning, showing that expressions satisfying universals are simpler than those that do not according to this criterion. We measure ease of learning using tools from machine learning and analyze universals in a domain of function words (quantifiers) and content words (color terms). Our results provide strong evidence that semantic universals across both function and content words reflect simplicity as measured by ease of learning."
}


@article{clements85, title={The geometry of phonological features}, volume={2}, DOI={10.1017/S0952675700000440}, number={1}, journal={Phonology Yearbook}, publisher={Cambridge University Press}, author={Clements, G. N.}, year={1985}, pages={225–252}}

@book{hayes09,
address = {Malden, MA},
author = {Bruce Hayes},
publisher = {Wiley-Blackwell},
title = {Introductory Phonology},
year = {2009},
}

@incollection{ds79,
address = {Bloomington},
author = {Donegan, Patricia J. and David Stampe},
booktitle = {Current Approaches to Phonological Theory},
editor = {Daniel Dinnsen},
pages = {126-173},
publisher = {Indiana University Press},
title = {The study of Natural Phonology},
year = {1979},
}

@incollection{alderete18,
  title={Connectionist approaches to generative phonology},
  author={Alderete, John and Tupper, Paul},
  booktitle={The Routledge Handbook of Phonological Theory},
  pages = {360-390},
publisher = {Routledge},
address = {New York},
  year={2018},
editor = {Anna Bosch and S. J. Hannahs}

}

@inproceedings{d74,
author = {Dressler, Wolfgang},
pages = {21-29},
crossref = {cls},
title = {Diachronic puzzles for natural phonology},
year = {1974},
}

@book{f11,
address = {Munich},
author = {Fenwick, Rohan S. H.},
publisher = {Lincom Europa},
title = {A Grammar of {U}bykh},
year = {2011},
}

@book{f91,
address = {Paris},
author = {Ferry, Marie-Paule},
publisher = {Soci\'et\'e des Etudes Linguistiques et Anthropologiques de France},
series = {Langues et cultures africaines},
title = {Thesaurus tenda: dictionnaire ethnolinguistique de langues s\'en\'egalo-guinn\'eennes (bassari, bedik, konyagi)},
year = {1991},
}

@article{fp86,
author = {Fourakis, Marios and Robert Port},
journal = {Journal of Phonetics},
number = {2},
pages = {197-221},
title = {Stop epenthesis in {E}nglish},
volume = {14},
year = {1986},
}

@article{f16,
author = {Fruehwald, Josef},
journal = {Language},
number = {2},
pages = {376-410},
title = {The early influence of phonology on a phonetic change},
volume = {92},
year = {2016},
}

@article{timit,
author = { Garofolo, J. S. and Lamel, Lori and M Fisher, W and Fiscus, Jonathan and S. Pallett, D and L. Dahlgren, N and Zue, V},
year = {1993},
month = {11},
pages = {},
title = {{TIMIT} Acoustic-phonetic Continuous Speech Corpus},
journal = {Linguistic Data Consortium}
}

@article{finley11,
title = "The privileged status of locality in consonant harmony",
journal = "Journal of Memory and Language",
volume = "65",
number = "1",
pages = "74 - 83",
year = "2011",
issn = "0749-596X",
doi = "https://doi.org/10.1016/j.jml.2011.02.006",
url = "http://www.sciencedirect.com/science/article/pii/S0749596X11000192",
author = "Sara Finley"
}

@inproceedings{kello03,
author = {Kello, Christopher and Plaut, David},
year = {2003},
month = {04},
title = {The interplay of perception and production in phonological development: Beginnings of a connectionist model trained on real speech},
booktitle={{5th International Congress of Phonetic Sciences, Barcelona, Spain, August 3-9, 2003}},
editor={M. J. Sol\'e and D. Recasens and J. Romero},
pages= {297-300},
url={http://www.internationalphoneticassociation.org/icphs/icphs2003}
}


@article{abramson64,
author = {Leigh Lisker and Arthur S. Abramson},
title = {A Cross-Language Study of Voicing in Initial Stops: Acoustical Measurements},
journal = {Word},
volume = {20},
number = {3},
pages = {384-422},
year  = {1964},
publisher = {Routledge},
doi = {10.1080/00437956.1964.11659830},

URL = { 
        https://doi.org/10.1080/00437956.1964.11659830
    
},
eprint = { 
        https://doi.org/10.1080/00437956.1964.11659830
    
}

}




@article{gaskell95,
title = "A connectionist model of phonological representation in speech perception",
journal = "Cognitive Science",
volume = "19",
number = "4",
pages = "407 - 439",
year = "1995",
issn = "0364-0213",
doi = "https://doi.org/10.1016/0364-0213(95)90007-1",
url = "http://www.sciencedirect.com/science/article/pii/0364021395900071",
author = "M.Gareth Gaskell and Mary Hare and William D. Marslen-Wilson",
abstract = "A number of recent studies have examined the effects of phonological variation on the perception of speech. These studies show that both the lexical representations of words and the mechanisms of lexical access are organized so that natural, systematic variation is tolerated by the perceptual system, while a general intolerance of random deviation is maintained. Lexical abstraction distinguishes between phonetic features that form the invariant core of a word and those that are susceptible to variation. Phonological inference relies on the context of surface changes to retrieve the underlying phonological form. In this article we present a model of these processes in speech perception, based on connectionist learning techniques. A simple recurrent network was trained on the mapping from the variant surface form of speech to the underlying form. Once trained, the network exhibited features of both abstraction and inference in its processing of normal speech, and predicted that similar behavior will be found in the perception of nonsense words. This prediction was confirmed in subsequent research (Gaskell & Marslen-Wilson, 1994)."
}


@inbook{plaut99,
	Address = {Mahwah,  NJ,  US},
	Author = {Plaut, David C. and Kello, Christopher T.},
	Booktitle = {The emergence of language.},
	Date-Added = {2020-01-19 23:44:22 +0000},
	Date-Modified = {2020-01-19 23:44:22 +0000},
	Id = {1999-02258-014},
	Isbn = {0-8058-3010-3 (Hardcover); 0-8058-3011-1 (Paperback)},
	Keywords = {*Articulation (Speech); *Comprehension; *Neural Networks; *Phonology; *Speech Development; Connectionism; Infant Development},
	N2 = {Outlines a general framework, based on connectionist-parallel distributed processing principles, for understanding how the infant copes with the difficulties of speech comprehension and production, and presents a connectionist simulation that illustrates a close interplay between comprehension and production in phonological development. The simulation learned to comprehend, imitate, and intentionally name a corpus of 400 monosyllabic words. Moreover, the speech errors produced by the network showed similar tendencies as those of young children. Much of the chapter is focused on the nature of the computational problems posed by phonological development and on the formulation of a particular approach for solving these problems. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	Pages = {381--415},
	Publisher = {Lawrence Erlbaum Associates Publishers},
	Title = {The emergence of phonology from the interplay of speech comprehension and production: A distributed connectionist approach.},
	Ty = {CHAP},
	Year = {1999}}


@article{mccleland86,
title = "The TRACE model of speech perception",
journal = "Cognitive Psychology",
volume = "18",
number = "1",
pages = "1 - 86",
year = "1986",
issn = "0010-0285",
doi = "https://doi.org/10.1016/0010-0285(86)90015-0",
url = "http://www.sciencedirect.com/science/article/pii/0010028586900150",
author = "James L McClelland and Jeffrey L Elman",
abstract = "We describe a model called the TRACE model of speech perception. The model is based on the principles of interactive activation. Information processing takes place through the excitatory and inhibitory interactions of a large number of simple processing units, each working continuously to update its own activation on the basis of the activations of other units to which it is connected. The model is called the TRACE model because the network of units forms a dynamic processing structure called “the Trace,” which serves at once as the perceptual processing mechanism and as the system's working memory. The model is instantiated in two simulation programs. TRACE I, described in detail elsewhere, deals with short segments of real speech, and suggests a mechanism for coping with the fact that the cues to the identity of phonemes vary as a function of context. TRACE II, the focus of this article, simulates a large number of empirical findings on the perception of phonemes and words and on the interactions of phoneme and word perception. At the phoneme level, TRACE II simulates the influence of lexical information on the identification of phonemes and accounts for the fact that lexical effects are found under certain conditions but not others. The model also shows how knowledge of phonological constraints can be embodied in particular lexical items but can still be used to influence processing of novel, nonword utterances. The model also exhibits categorical perception and the ability to trade cues off against each other in phoneme identification. At the word level, the model captures the major positive feature of Marslen-Wilson's COHORT model of speech perception, in that it shows immediate sensitivity to information favoring one word or set of words over others. At the same time, it overcomes a difficulty with the COHORT model: it can recover from underspecification or mispronunciation of a word's beginning. TRACE II also uses lexical information to segment a stream of speech into a sequence of words and to find word beginnings and endings, and it simulates a number of recent findings related to these points. The TRACE model has some limitations, but we believe it is a step toward a psychologically and computationally adequate model of the process of speech perception."
}

@inproceedings{white18,
  title={Preference for locality is affected by the prefix/suffix asymmetry},
  author={James White and Andrew Nevins and Krisztina Polg{\'a}rdi and Alexander Martin and Rene Kager and Tal Linzen and Sharon Peperkamp and Ioanna Topintzi and Giorgos Markopoulos and Ruben van de Vijver},
  booktitle={{NELS 48: Proceedings of the Forty-Eighth Annual Meeting of the North East Linguistic Society}},
  pages={207-220},
  editor= "Sherry Hucklebridge and Max Nelson",
    year={2018},
    location={Amherst, MA},
    publisher={GLSA}
}


@InProceedings{arjovsky17,
  title = 	 {{W}asserstein Generative Adversarial Networks},
  author = 	 {Martin Arjovsky and Soumith Chintala and L{\'e}on Bottou},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {214--223},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a.pdf},
  url = 	 {http://proceedings.mlr.press/v70/arjovsky17a.html},
  abstract = 	 {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to different distances between distributions.}
}

@incollection{gulrajani17,
title = {Improved Training of Wasserstein GANs},
author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {5767--5777},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7159-improved-training-of-wasserstein-gans.pdf}
}


@incollection{g14,
address = {New York},
author = {Garrett, Andrew},
booktitle = {The {R}outledge Handbook of Historical Linguistics},
editor = {Claire Bowern and Bethwyn Evans},
pages = {227-248},
publisher = {Routledge},
title = {Sound change},
year = {2015},
}

@book{yu13,
address = {Oxford},
title = {Origins of Sound Change: Approaches to Phonologization},
editor = {Alan C. L. Yu},
publisher = {Oxford University Press},
year = {2013},
}

@incollection{yu13a,
address = {Oxford},
title={Individual differences in socio-cognitive processing and the actuation of sound change},
title = {Origins of Sound Change: Approaches to Phonologization},
editor = {Alan C. L. Yu},
publisher = {Oxford University Press},
year = {2013},
pages={201-227},
}

@incollection{gj13,
author = {Garrett, Andrew and Keith Johnson},
pages = {51-97},
address = {Oxford},
booktitle = {Origins of Sound Change: Approaches to Phonologization},
editor = {Alan C. L. Yu},
publisher = {Oxford University Press},
title = {Phonetic bias in sound change},
year = {2013},
}

@incollection{g07,
address = {Ann Arbor, MI},
author = {Goddard, Ives},
booktitle = {Verba Docenti: Studies in Historical and {Indo-European} Linguistics Presented to {Jay H. Jasanoff} by Students, Colleagues and Friends},
editor = {Alan J. Nussbaum},
pages = {115-130},
publisher = {Beech Stave Press},
title = {Phonetically unmotivated sound change},
year = {2007},
}

@phdthesis{g76,
author = {Goldsmith, John},
school = {Massachusetts Institute of Technology},
title = {Autosegmental phonology},
year = {1976},
}

@article{gzb11,
author = {Gouskova, Maria and Elizabeth Zsiga and One Tlale Boyer},
journal = {Lingua},
number = {15},
pages = {2120-2152},
title = {Grounded constraints and the consonants of {S}etswana},
volume = {121},
year = {2011},
}

@incollection{g78,
address = {Stanford, CA},
author = {Greenberg, Joseph H.},
booktitle = {Universals of Human Language},
editor = {Joseph H. Greenberg},
note = {Volume I: Method \& Theory},
pages = {61-92},
publisher = {Stanford University Press},
title = {Diachrony, synchrony, and language universals},
year = {1978},
}

@phdthesis{g96,
author = {Guion, Susan G.},
school = {University of Texas at Austin},
title = {Velar palatalization: Coarticulation, perception, and sound change},
year = {1996},
}

@incollection{h07,
address = {Cambridge},
author = {Hall, T. Alan},
booktitle = {The {C}ambridge Handbook of Phonology},
editor = {Paul de Lacy},
pages = {311-333},
publisher = {Cambridge University Press},
title = {Segmental features},
year = {2007},
}

@incollection{hf09,
address = {Amsterdam},
author = {Hamed, Mah\'e B. and S\'ebastien Flavier},
booktitle = {Historical Linguistics 2007: Selected Papers from the 18th {I}nternational Conference on Historical Linguistics, {M}ontreal, {A}ugust 2007},
editor = {Monique Dufresne and Fernande Dupuis and Etleva Vocaj},
pages = {6-11},
publisher = {John Benjamins},
title = {UNIDIA: A database for deriving diachronic universals},
year = {2009},
}

@article{h08,
author = {Hansson, Gunnar},
journal = {Language and Linguistics Compass},
pages = {859-893},
title = {Diachronic explanations of sound patterns},
volume = {2},
year = {2008},
}

@article{hpwl15,
author = {Hay, Jennifer B. and Janet B. Pierrehumbert and Abby J. Walker and Patrick LaShell},
journal = {Cognition},
pages = {83-91},
title = {Tracking word frequency effects through 130 years of sound change},
volume = {139},
year = {2015},
}


@misc{plotneuralnet,
  author       = {Haris Iqbal},
  title        = {HarisIqbal88/PlotNeuralNet v1.0.0},
  month        = dec,
  year         = 2018,
  publisher    = {Zenodo},
  version      = {v1.0.0},
  doi          = {10.5281/zenodo.2526396},
  url          = {https://doi.org/10.5281/zenodo.2526396}
}

@article{peterson18,
author = {Peterson, Joshua C. and Abbott, Joshua T. and Griffiths, Thomas L.},
title = {Evaluating (and Improving) the Correspondence Between Deep Neural Networks and Human Representations},
journal = {Cognitive Science},
volume = {42},
number = {8},
pages = {2648-2669},
keywords = {Artificial intelligence, Similarity, Categorization, Neural networks},
doi = {10.1111/cogs.12670},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12670},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12670},
abstract = {Abstract Decades of psychological research have been aimed at modeling how people learn features and categories. The empirical validation of these theories is often based on artificial stimuli with simple representations. Recently, deep neural networks have reached or surpassed human accuracy on tasks such as identifying objects in natural images. These networks learn representations of real-world stimuli that can potentially be leveraged to capture psychological representations. We find that state-of-the-art object classification networks provide surprisingly accurate predictions of human similarity judgments for natural images, but they fail to capture some of the structure represented by people. We show that a simple transformation that corrects these discrepancies can be obtained through convex optimization. We use the resulting representations to predict the difficulty of learning novel categories of natural images. Our results extend the scope of psychological experiments and computational modeling by enabling tractable use of large natural stimulus sets.},
year = {2018}
}


@book{h95,
address = {Chicago},
author = {Hayes, Bruce},
publisher = {The University of Chicago Press},
title = {Metrical Stress Theory: Principles and Case Studies},
year = {1995},
}

@book{paul80,
address = {Halle},
author = {Paul, Hermann},
publisher = {Max Niemeyer},
title = {Principien der {S}prachgeschichte.},
year = {1880},
}






@article{miller75,
 ISSN = {00243892, 15309150},
 URL = {http://www.jstor.org/stable/4177867},
 author = {D. Gary Miller},
 journal = {Linguistic Inquiry},
 number = {1},
 pages = {171--177},
 publisher = {The MIT Press},
 title = {All Rules Precede All Syntagmatic Natural Processes?},
 volume = {6},
 year = {1975}
}

@article{tifrit16,
doi = {http://doi.org/10.5334/gjgl.55},
 author = {Ali Tifrit and Laurence Voeltzel},
 journal = {Glossa: A Journal of General Linguistics},
 number = {10},
 title = {All Rules Precede All Syntagmatic Natural Processes?},
 volume = {1},
 year = {2016}
}

@article{stevens19,
doi = {http://doi.org/10.5334/gjgl.620},
 author = {Stevens, M. and Harrington, J. and Schiel, F.},
 journal = {Glossa: A Journal of General Linguistics},
 number = {1},
 pages = {8},
 title = {Associating the origin and spread of sound change using agent-based modelling applied to /s/-retraction in English},
 volume = {4},
 year = {2019}
}


@article{baker08,
author = {Baker, Adam},
title = {Computational Approaches to the Study of Language Change},
journal = {Language and Linguistics Compass},
volume = {2},
number = {2},
pages = {289-307},
doi = {10.1111/j.1749-818X.2008.00054.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1749-818X.2008.00054.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1749-818X.2008.00054.x},
abstract = {Abstract The article reviews computational studies of language change. Computer models of change are helpful because of the complexity of the behavior involved: an entire population of complex, interacting agents must be accounted for. Computational studies frequently bring to light hidden implications of theories, which make them relevant to the theoretical development of both acquisition and change. Studies of language change have focused on discovering mathematical properties of dynamical systems, or on simulating populations of speakers that interact with one another and change their internal states as a result. Models of lexical (including phonological) and syntactic change are considered. Computational models of change have proved useful tools for testing theories of language change, and will prove more useful as the field matures to include more systematic studies of the effects of varying model parameters in complex simulations.},
year = {2008}
}


@misc{signnet,
  author = {Sergey Rodionov},
  title = {info-wgan-gp},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/singnet/semantic-vision/tree/master/experiments/concept_learning/gans/info-wgan-gp}},
  commit = {4f57d6a0e4c030202a07a60bc1bb1ed1544bf679}
}


@article{radford15,
  title={Unsupervised representation learning with deep convolutional generative adversarial networks},
  author={Radford, Alec and Metz, Luke and Chintala, Soumith},
  journal={ArXiv},
  year={2015}
}

@misc{feldman19,
 title={Early phonetic learning without phonetic categories -- Insights from machine learning},
 url={psyarxiv.com/fc4wh},
 DOI={10.31234/osf.io/fc4wh},
 publisher={PsyArXiv},
 author={Schatz, Thomas and Feldman, Naomi and Goldwater, Sharon and Cao, Xuan Nga and Dupoux, Emmanuel},
 year={2019},
 month={May}
}

@inproceedings{donahue19,
  author    = {Chris Donahue and
               Julian J. McAuley and
               Miller S. Puckette},
  title     = {Adversarial Audio Synthesis},
  booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
               New Orleans, LA, USA, May 6-9, 2019},
  publisher = {OpenReview.net},
  year      = {2019},
  url       = {https://openreview.net/forum?id=ByMVTsR5KQ},
  timestamp = {Thu, 25 Jul 2019 14:25:58 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/DonahueMP19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@incollection{h99,
address = {Amsterdam},
author = {Hayes, Bruce},
booktitle = {Functionalism and Formalism in Linguistics, Volume I: General Papers},
editor = {Michael Darnell and Edith Moravscik},
pages = {243-285},
publisher = {John Benjamins},
title = {Phonetically-driven phonology: The role of {Optimality Theory} and inductive grounding},
year = {1999},
}

@incollection{h04,
address = {Cambridge},
author = {Hayes, Bruce},
booktitle = {Constraints in Phonological Acquisition},
editor = {R. Kager and J. Pater and W. Zonneveld},
pages = {153-208},
publisher = {Cambridge University Press},
title = {Phonological acquisition in {Optimality Theory}: The early stages},
year = {2004},
}

@article{hw13,
author = {Hayes, Bruce and James White},
journal = {Linguistic Inquiry},
number = {1},
pages = {45-75},
title = {Phonological naturalness and phonotactic learning},
volume = {44},
year = {2013},
}


@article{jarosz19,
author = {Jarosz, Gaja},
title = {Computational Modeling of Phonological Learning},
journal = {Annual Review of Linguistics},
volume = {5},
number = {1},
pages = {67-90},
year = {2019},
doi = {10.1146/annurev-linguistics-011718-011832},

URL = { 
        https://doi.org/10.1146/annurev-linguistics-011718-011832
    
},
eprint = { 
        https://doi.org/10.1146/annurev-linguistics-011718-011832
    
}
,
    abstract = { Recent advances in computational modeling have led to significant discoveries about the representation and acquisition of phonological knowledge and the limits on language learning and variation. These discoveries are the result of applying computational learning models to increasingly rich and complex natural language data while making increasingly realistic assumptions about the learning task. This article reviews the recent developments in computational modeling that have made connections between fully explicit theories of learning, naturally occurring corpus data, and the richness of psycholinguistic and typological data possible. These advances fall into two broad research areas: (a) the development of models capable of learning the quantitative, noisy, and inconsistent patterns that are characteristic of naturalistic data and (b) the development of models with the capacity to learn hidden phonological structure from unlabeled data. After reviewing these advances, the article summarizes some of the most significant consequent discoveries. }
}


@INPROCEEDINGS{harwath19,  author={Harwath, David and Glass, James},  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={Towards Visually Grounded Sub-word Speech Unit Discovery},   year={2019},  volume={},  number={},  pages={3017-3021},  doi={10.1109/ICASSP.2019.8682666}}

@InProceedings{mahalunkar18,
author="Mahalunkar, Abhijit
and Kelleher, John D.",
editor="K{\r{u}}rkov{\'a}, V{\v{e}}ra
and Manolopoulos, Yannis
and Hammer, Barbara
and Iliadis, Lazaros
and Maglogiannis, Ilias",
title="Using Regular Languages to Explore the Representational Capacity of Recurrent Neural Architectures",
booktitle="Artificial Neural Networks and Machine Learning -- ICANN 2018",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="189--198",
abstract="The presence of Long Distance Dependencies (LDDs) in sequential data poses significant challenges for computational models. Various recurrent neural architectures have been designed to mitigate this issue. In order to test these state-of-the-art architectures, there is growing need for rich benchmarking datasets. However, one of the drawbacks of existing datasets is the lack of experimental control with regards to the presence and/or degree of LDDs. This lack of control limits the analysis of model performance in relation to the specific challenge posed by LDDs. One way to address this is to use synthetic data having the properties of subregular languages. The degree of LDDs within the generated data can be controlled through the k parameter, length of the generated strings, and by choosing appropriate forbidden strings. In this paper, we explore the capacity of different RNN extensions to model LDDs, by evaluating these models on a sequence of SPk synthesized datasets, where each subsequent dataset exhibits a longer degree of LDD. Even though SPk are simple languages, the presence of LDDs does have significant impact on the performance of recurrent neural architectures, thus making them prime candidate in benchmarking tasks.",
isbn="978-3-030-01424-7"
}


@article{pater19,
  title={Generative linguistics and neural networks at 60: Foundation, friction, and fusion},
  author={Pater, Joe},
  journal={Language},
  year={2019},
  publisher={Linguistic Society of America}
}

@inproceedings{weber18a,
    title = "The Fine Line between Linguistic Generalization and Failure in {S}eq2{S}eq-Attention Models",
    author = "Weber, Noah  and Shekhar, Leena  and  Balasubramanian, Niranjan",
    booktitle = "Proceedings of the Workshop on Generalization in the Age of Deep Learning",
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-1004",
    doi = "10.18653/v1/W18-1004",
    pages = "24--27",
    abstract = "Seq2Seq based neural architectures have become the go-to architecture to apply to sequence to sequence language tasks. Despite their excellent performance on these tasks, recent work has noted that these models typically do not fully capture the linguistic structure required to generalize beyond the dense sections of the data distribution (Ettinger et al., 2017), and as such, are likely to fail on examples from the tail end of the distribution (such as inputs that are noisy (Belinkov and Bisk, 2018), or of different length (Bentivogli et al., 2016)). In this paper we look at a model{'}s ability to generalize on a simple symbol rewriting task with a clearly defined structure. We find that the model{'}s ability to generalize this structure beyond the training distribution depends greatly on the chosen random seed, even when performance on the test set remains the same. This finding suggests that model{'}s ability to capture generalizable structure is highly sensitive, and more so, this sensitivity may not be apparent when evaluating the model on standard test sets.",
}

@article{heinz10,
author = {Heinz, Jeffrey},
title = {Learning Long-Distance Phonotactics},
journal = {Linguistic Inquiry},
volume = {41},
number = {4},
pages = {623-661},
year = {2010},
doi = {10.1162/LING/\_a\_00015},
URL = {https://doi.org/10.1162/LING\_a\_00015}
        }



@inproceedings{avcu17,
  author = {Enes Avcu and Chihiro Shibata and Jeffrey Heinz},
  title = {Subregular Complexity and Deep Learning},
  pages = {20-33},
  booktitle = {{CLASP} Papers in Computational Linguistics: Proceedings of the Conference on Logic and Machine Learning in Natural Language (LaML 2017), Gothenburg, 12 --13 June},
  year = {2017},
  editor = {Dobnik, Simon and Lappin, Shalom},
  pdf-url = {http://jeffreyheinz.net/papers/Avcu-Shibata-Heinz-2017-SCDL.pdf}
}

@article{rawski19,
  title={No free lunch in linguistics or machine learning: Response to Pater},
  author={Rawski, Jonathan and Heinz, Jeffrey},
  journal={Language},
  year={2019},
  publisher={Linguistic Society of America}
}

@article{hszl09,
author = {Hayes, Bruce and P\'eter Sipt\'ar and Kie Zuraw and Zsuzsa Londe},
journal = {Language},
number = {4},
pages = {822-863},
title = {Natural and unnatural constraints in {H}ungarian vowel harmony},
volume = {85},
year = {2009},
}

@unpublished{hs00,
author = {Hayes, Bruce and Tanya Stivers},
title = {Postnasal Voicing},
year = {2000},
note = {Ms., University of California, Los Angeles. \url{http://linguistics.ucla.edu/people/hayes/Phonet/NCPhonet.pdf} (accessed 9 May 2018)},
}

@article{alhama18,
  title={Pre-Wiring and Pre-Training: What Does a Neural Network Need to Learn Truly General Identity Rules?},
  author={Raquel G. Alhama and Willem H. Zuidema},
  journal={Journal of Artificial Intelligence Res.},
  year={2018},
  volume={61},
  pages={927-946},
  doi={10.1613/jair.1.11197}
}

@article{endress07,
title = "Perceptual constraints and the learnability of simple grammars",
journal = "Cognition",
volume = "105",
number = "3",
pages = "577 - 614",
year = "2007",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2006.12.014",
url = "http://www.sciencedirect.com/science/article/pii/S0010027706002605",
author = "Ansgar D. Endress and Ghislaine Dehaene-Lambertz and Jacques Mehler",
keywords = "Grammar acquisition, Perceptual primitives, Symbol manipulation, Statistical learning, Modularity, Learnability, Connectionism, Rule learning",
abstract = "Cognitive processes are often attributed to statistical or symbolic general-purpose mechanisms. Here we show that some spontaneous generalizations are driven by specialized, highly constrained symbolic operations. We explore how two types of artificial grammars are acquired, one based on repetitions and the other on characteristic relations between tones (“ordinal” grammars). Whereas participants readily acquire repetition-based grammars, displaying early electrophysiological responses to grammar violations, they perform poorly with ordinal grammars, displaying no such electrophysiological responses. This outcome is problematic for both general symbolic and statistical models, which predict that both types of grammars should be processed equally easily. This suggests that some simple grammars are acquired using perceptual primitives rather than general-purpose mechanisms; such primitives may be elements of a “toolbox” of specialized computational heuristics, which may ultimately allow constructing a psychological theory of symbol manipulation."
}


@article{mcclelland99,
title = "Does generalization in infant learning implicate abstract algebra-like rules?",
journal = "Trends in Cognitive Sciences",
volume = "3",
number = "5",
pages = "166 - 168",
year = "1999",
issn = "1364-6613",
doi = "https://doi.org/10.1016/S1364-6613(99)01320-0",
url = "http://www.sciencedirect.com/science/article/pii/S1364661399013200",
author = "James L McClelland and David C Plaut",
keywords = "Rules, Neural networks, Statistical learning, Generalization, Connectionist models, Infancy"
}

@TECHREPORT{gasser93,
    author = {Michael Gasser},
    title = {Learning words in time: Towards a modular connectionist account of the acquisition of receptive morphology},
    institution = {Indiana University, Bloomington},
    url={http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.73.6474},
    year = {1993}
}

@inproceedings{wilson18,
  author = {Colin Wilson},
  title = {Modeling morphological affixation with interpretable recurrent networks: sequential rebinding controlled by hierarchical attention},
  pages = {2693--2698},
  booktitle = {CogSci 2018},
  editor = {Chuck Kalish and Martina Rau and Jerry Zhu and Timothy Rogers},
  year = {2018},
  month = {July}
}

@article{hayes06, title={Stochastic phonological knowledge: the case of Hungarian vowel harmony}, volume={23}, DOI={10.1017/S0952675706000765}, number={1}, journal={Phonology}, publisher={Cambridge University Press}, author={Hayes, Bruce and Londe, Zsuzsa Cziráky}, year={2006}, pages={59–104}}


@article{hussain20,
author = {Hussain,Qandeel  and Mielke,Jeff },
title = {An acoustic and articulatory study of laryngeal and place contrasts of Kalasha (Indo-Aryan, Dardic)},
journal = {The Journal of the Acoustical Society of America},
volume = {147},
number = {4},
pages = {2873-2890},
year = {2020},
doi = {10.1121/10.0000999},

URL = { 
        https://doi.org/10.1121/10.0000999
    
},
eprint = { 
        https://doi.org/10.1121/10.0000999
    
}

}


@inproceedings{krug18,
  title={Neuron Activation Profiles for Interpreting Convolutional Speech Recognition Models},
  author={A. Krug and Ren{\'e} Knaebel and S. Stober},
  booktitle={NeurIPS Workshop on Interpretability and Robustness in Audio, Speech, and Language},
  year={2018},
  url={https://openreview.net/pdf?id=Bylpgfjen7}
}


@INPROCEEDINGS{muckenhirn17,
  author={H. {Muckenhirn} and M. {Magimai-Doss} and S. {Marcel}},
  booktitle={2017 IEEE International Joint Conference on Biometrics (IJCB)}, 
  title={End-to-End convolutional neural network-based voice presentation attack detection}, 
  year={2017},
  volume={},
  number={},
  pages={335-341},
  doi={10.1109/BTAS.2017.8272715}}

@INPROCEEDINGS{palaz15,
         author = {Palaz, Dimitri and Magimai.-Doss, Mathew and Collobert, Ronan},
          title = {Analysis of {CNN}-based Speech Recognition System using Raw Speech as Input},
      booktitle = {Proceedings of Interspeech},
           year = {2015},
          pages = {11-15},
      publisher = {ISCA},
       location = {Dresden},
   organization = {ISCA},
           issn = {1990-9770},}
           
@INPROCEEDINGS{huang15,
  author={J. {Huang} and J. {Li} and Y. {Gong}},
  booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={An analysis of convolutional neural networks for speech recognition}, 
  year={2015},
  volume={},
  number={},
  pages={4989-4993},
  doi={10.1109/ICASSP.2015.7178920}}




@INPROCEEDINGS{muckenhirn18,
  author={H. {Muckenhirn} and M. {Magimai.-Doss} and S. {Marcell}},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Towards Directly Modeling Raw Speech Signal for Speaker Verification Using CNNS}, 
  year={2018},
  volume={},
  number={},
  pages={4884-4888},
  doi={10.1109/ICASSP.2018.8462165}}

@inproceedings{muckenhirn19,
  author={Hannah Muckenhirn and Vinayak Abrol and Mathew Magimai-Doss and Sébastien Marcel},
  title={{Understanding and Visualizing Raw Waveform-Based CNNs}},
  year=2019,
  booktitle={Proc. Interspeech 2019},
  pages={2345--2349},
  doi={10.21437/Interspeech.2019-2341},
  url={http://dx.doi.org/10.21437/Interspeech.2019-2341}
}


@inproceedings{krug18introspection,
    title = "Introspection for convolutional automatic speech recognition",
    author = "Krug, Andreas  and
      Stober, Sebastian",
    booktitle = "Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP}",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-5421",
    doi = "10.18653/v1/W18-5421",
    pages = "187--199",
    abstract = "Artificial Neural Networks (ANNs) have experienced great success in the past few years. The increasing complexity of these models leads to less understanding about their decision processes. Therefore, introspection techniques have been proposed, mostly for images as input data. Patterns or relevant regions in images can be intuitively interpreted by a human observer. This is not the case for more complex data like speech recordings. In this work, we investigate the application of common introspection techniques from computer vision to an Automatic Speech Recognition (ASR) task. To this end, we use a model similar to image classification, which predicts letters from spectrograms. We show difficulties in applying image introspection to ASR. To tackle these problems, we propose normalized averaging of aligned inputs (NAvAI): a data-driven method to reveal learned patterns for prediction of specific classes. Our method integrates information from many data examples through local introspection techniques for Convolutional Neural Networks (CNNs). We demonstrate that our method provides better interpretability of letter-specific patterns than existing methods.",
}


@article{begusLocal,
	Abstract = {This paper argues that training Generative Adversarial Networks (GANs) on local and non-local dependencies in speech data offers insights into how deep neural networks discretize continuous data and how symbolic-like rule-based morphophonological processes emerge in a deep convolutional architecture. Acquisition of speech has recently been modeled as a dependency between latent space and data generated by GANs in Begu{\v s} (2020b), who models learning of a simple local allophonic distribution. We extend this approach to test learning of local and non-local phonological processes that include approximations of morphological processes. We further parallel outputs of the model to results of a behavioral experiment where human subjects are trained on the data used for training the GAN network. Four main conclusions emerge: (i) the networks provide useful information for computational models of speech acquisition even if trained on a comparatively small dataset of an artificial grammar learning experiment; (ii) local processes are easier to learn than non-local processes, which matches both behavioral data in human subjects and typology in the world's languages. This paper also proposes (iii) how we can actively observe the network's progress in learning and explore the effect of training steps on learning representations by keeping latent space constant across different training steps. Finally, this paper shows that (iv) the network learns to encode the presence of a prefix with a single latent variable; by interpolating this variable, we can actively observe the operation of a non-local phonological process. The proposed technique for retrieving learning representations has general implications for our understanding of how GANs discretize continuous speech data and suggests that rule-like generalizations in the training data are represented as an interaction between variables in the network's latent space.},
	Author = {Ga\v{s}per Begu\v{s}},
	Doi = {https://doi.org/10.1016/j.csl.2021.101244},
	Issn = {0885-2308},
	Journal = {Computer Speech \& Language},
	Keywords = {Neural networks, Behavioral experiments, Machine learning, Learning biases, Speech, Morphology},
	Pages = {101244},
	Title = {Local and non-local dependency learning and emergence of rule-like representations in speech data by Deep Convolutional Generative Adversarial Networks},
	Url = {https://www.sciencedirect.com/science/article/pii/S0885230821000516},
	Year = {2021},
}

@article{begusCiw,
	Abstract = {How can deep neural networks encode information that corresponds to words in human speech into raw acoustic data? This paper proposes two neural network architectures for modeling unsupervised lexical learning from raw acoustic inputs: ciwGAN (Categorical InfoWaveGAN) and fiwGAN (Featural InfoWaveGAN). These combine Deep Convolutional GAN architecture for audio data (WaveGAN; Donahue et al., 2019) with the information theoretic extension of GAN -- InfoGAN (Chen et al., 2016) -- and propose a new latent space structure that can model featural learning simultaneously with a higher level classification and allows for a very low-dimension vector representation of lexical items. In addition to the Generator and Discriminator networks, the architectures introduce a network that learns to retrieve latent codes from generated audio outputs. Lexical learning is thus modeled as emergent from an architecture that forces a deep neural network to output data such that unique information is retrievable from its acoustic outputs. The networks trained on lexical items from the TIMIT corpus learn to encode unique information corresponding to lexical items in the form of categorical variables in their latent space. By manipulating these variables, the network outputs specific lexical items. The network occasionally outputs innovative lexical items that violate training data, but are linguistically interpretable and highly informative for cognitive modeling and neural network interpretability. Innovative outputs suggest that phonetic and phonological representations learned by the network can be productively recombined and directly paralleled to productivity in human speech: a fiwGAN network trained on suit and dark outputs innovative start, even though it never saw start or even a [st] sequence in the training data. We also argue that setting latent featural codes to values well beyond training range results in almost categorical generation of prototypical lexical items and reveals underlying values of each latent code. Probing deep neural networks trained on well understood dependencies in speech bears implications for latent space interpretability and understanding how deep neural networks learn meaningful representations, as well as potential for unsupervised text-to-speech generation in the GAN framework.},
  Author = {Ga\v{s}per Begu\v{s}},
	Doi = {https://doi.org/10.1016/j.neunet.2021.03.017},
	Issn = {0893-6080},
	Journal = {Neural Networks},
	Keywords = {Artificial intelligence, Generative adversarial networks, Speech, Lexical learning, Neural network interpretability, Acoustic word embedding},
	Pages = {305-325},
	Title = {Ciw{GAN} and fiw{GAN}: Encoding information in acoustic data to model lexical learning with {G}enerative {A}dversarial {N}etworks},
	Url = {https://www.sciencedirect.com/science/article/pii/S0893608021001052},
	Volume = {139},
	Year = {2021},
}


@article{savitch89,
author = {Savitch, Walter J.},
title = {A Formal Model for Context-Free Languages Augmented with Reduplication},
year = {1989},
issue_date = {December 1989},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {15},
number = {4},
issn = {0891-2017},
abstract = {A model is presented to characterize the class of languages obtained by adding reduplication to context-free languages. The model is a pushdown automaton augmented with the ability to check reduplication by using the stack in a new way. The class of languages generated is shown to lie strictly between the context-free languages and the indexed languages. The model appears capable of accommodating the sort of reduplications that have been observed to occur in natural languages, but it excludes many of the unnatural constructions that other formal models have permitted.},
journal = {Computational Linguistics},
month = dec,
pages = {250–261},
numpages = {12}
}


@article{dolatian20,
	Abstractnote = {This article describes a novel approach to the computational modeling of reduplication. Reduplication is often treated as a stumbling block within finite-state treatments of morphology because they cannot adequately capture the productivity of unbounded copying (total reduplication) and because they cannot describe bounded copying (partial reduplication) without a large increase in the number of states. We provide a comprehensive typology of reduplicative processes and show that an understudied type of finite-state machine, 2-way deterministic finite-state transducers (2-way D-FSTs), captures virtually all of them. Furthermore, the 2-way D-FSTs have few states, are in practice easy to design and debug, and are linguistically motivated in terms of the transducer's origin semantics or segment alignment. Most of these processes, and their corresponding 2-way D-FSTs, are available in an online database of reduplication (RedTyp). We classify these 2- way D-FSTs according to the concatenation of known subclasses of regular relations and show that the majority fall into the Concatenated Output Strictly Local (C-OSL) class. Other cases require higher subclasses but are still definable by 2-way D-FSTs.},
	Author = {Dolatian, Hossep and Heinz, Jeffrey},
	Doi = {10.15398/jlm.v8i1.245},
	Journal = {Journal of Language Modelling},
	Month = {Sep.},
	Number = {1},
	Pages = {179--250},
	Title = {Computing and classifying reduplication with 2-way finite-state transducers},
	Url = {https://jlm.ipipan.waw.pl/index.php/JLM/article/view/245},
	Volume = {8},
	Year = {2020},
}



@article{begus2020identity,
    title = "Identity-Based Patterns in Deep Convolutional Networks: Generative Adversarial Phonology and Reduplication",
    author = {Ga\v{s}per Begu\v{s}},
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "9",
    year = "2021",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2021.tacl-1.70",
    doi = "10.1162/tacl_a_00421",
    pages = "1180--1196",
    abstract = "Abstract This paper models unsupervised learning of an identity-based pattern (or copying) in speech called reduplication from raw continuous data with deep convolutional neural networks. We use the ciwGAN architecture (Begu{\v{s}}, 2021a) in which learning of meaningful representations in speech emerges from a requirement that the CNNs generate informative data. We propose a technique to wug-test CNNs trained on speech and, based on four generative tests, argue that the network learns to represent an identity-based pattern in its latent space. By manipulating only two categorical variables in the latent space, we can actively turn an unreduplicated form into a reduplicated form with no other substantial changes to the output in the majority of cases. We also argue that the network extends the identity-based pattern to unobserved data. Exploration of how meaningful representations of identity-based patterns emerge in CNNs and how the latent space variables outside of the training range correlate with identity-based patterns in the output has general implications for neural network interpretability.",
}


@article{nelson20,
  title={Probing RNN Encoder-Decoder Generalization of Subregular Functions using Reduplication},
  author={Nelson, Max and Dolatian, Hossep and Rawski, Jonathan and Prickett, Brandon},
  journal={Proceedings of the Society for Computation in Linguistics},
  volume={3},
  number={1},
  pages={31--42},
  year={2020}
}

@inproceedings{prickett18,
    title = "{S}eq2{S}eq Models with Dropout can Learn Generalizable Reduplication",
    author = "Prickett, Brandon  and
      Traylor, Aaron  and
      Pater, Joe",
    booktitle = "Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-5810",
    doi = "10.18653/v1/W18-5810",
    pages = "93--100",
    abstract = "Natural language reduplication can pose a challenge to neural models of language, and has been argued to require variables (Marcus et al., 1999). Sequence-to-sequence neural networks have been shown to perform well at a number of other morphological tasks (Cotterell et al., 2016), and produce results that highly correlate with human behavior (Kirov, 2017; Kirov {\&} Cotterell, 2018) but do not include any explicit variables in their architecture. We find that they can learn a reduplicative pattern that generalizes to novel segments if they are trained with dropout (Srivastava et al., 2014). We argue that this matches the scope of generalization observed in human reduplication.",
}

  @Book{car,
    title = {An {R} Companion to Applied Regression},
    edition = {Third},
    author = {John Fox and Sanford Weisberg},
    year = {2019},
    publisher = {Sage},
    address = {Thousand Oaks {CA}},
    url = {https://socialsciences.mcmaster.ca/jfox/Books/Companion/},
  }

@unpublished{kirov17,
author = {Christo Kirov},
title = {Recurrent Neural Networks as a Strong Baseline for Morphophonological Learning},
year = {2017},
note = {Poster, presented at  2017 Meeting of the Linguistic Society of America,  Austin, TX.\url{https://ckirov.github.io/papers/lsa2017.pdf} (accessed 7 Oct 2019)},
}


@article{h78,
author = {Hellberg, Staffan},
journal = {Journal of Linguistics},
number = {2},
pages = {157-177},
title = {Unnatural phonology},
volume = {14},
year = {1978},
}

@book{h86,
address = {Berlin},
author = {Herbert, Robert K.},
publisher = {Mouton de Gruyter},
title = {Language universals, markedness theory, and natural phonetic processes},
year = {1986},
}

@book{h91,
address = {Berlin},
author = {Hock, Hans H.},
publisher = {De Gruyter Mouton},
title = {Principles of Historical Linguistics},
year = {1991},
}

@article{h16,
author = {Honeybone, Patrick},
journal = {Papers in Historical Phonology},
pages = {316-358},
title = {Are there impossible changes? $\theta$ $>$ f but f $\ngtr$ $\theta$},
volume = {1},
year = {2016},
}

@article{hbswmpb15,
author = {Hruschka, Daniel J. and Simon Branford and Eric D. Smith and Jon Wilkins and Andrew Meade and Mark Pagel and Tanmoy Bhattacharya},
journal = {Current Biology},
number = {1},
pages = {1-9},
title = {Detecting regular sound changes in linguistics as events of concerted evolution},
volume = {25},
year = {2015},
}

@article{hh70,
author = {Hurd, Conrad and Phyllis Hurd},
journal = {Oceanic Linguistics},
pages = {37-78},
title = {Nasioi verbs},
volume = {9},
year = {1970},
}

@article{h72,
author = {Hyman, Larry M.},
journal = {Studies in African Linguistics},
pages = {167-206},
title = {Nasals and nasalization in {K}wa},
volume = {4},
year = {1972},
}

@book{h75,
address = {New York},
author = {Hyman, Larry M.},
publisher = {Holt, Rinehart \& Winston},
title = {Phonology: Theory and Analysis},
year = {1975},
}

@incollection{h76,
address = {Saratoga, CA},
author = {Hyman, Larry M.},
booktitle = {Linguistic studies presented to {Joseph H. Greenberg}},
editor = {A. Juilland},
pages = {407-418},
publisher = {Anna Libri},
title = {Phonologization},
year = {1976},
}

@incollection{manning03,
address = {Cambridge, MA:},
author = {Manning, C. D.},
booktitle = {robabilistic linguistics},
editor = {R. Bod and J. Hay and S. Jannedy},
pages = {289-342},
publisher = {MIT Pres},
title = {Probabilistic syntax},
year = {2003},
}


@book{rumelhart86,
	Address = {Cambridge, MA},
	title = {Parallel distributed processing: Explorations in the microstructure of cognition},
	Date = {1986},
	author={David E. Rumelhart and James L. McClelland and PDP Research Group},
	Publisher = {MIT Press},
	volume={1},
	subtitle={Foundations},
	Year = {1986}}
	
	@book{mcclelland86,
	Address = {Cambridge, MA},
	title = {Parallel distributed processing: Explorations in the microstructure of cognition},
	Date = {1986},
	author={James L. McClelland and David E. Rumelhart  and PDP Research Group},
	Publisher = {MIT Press},
	volume={2},
		subtitle={Psychological and Biological Models},
	Year = {1986}}


@article{fodor88,
	Abstract = {This paper explores differences between Connectionist proposals for cognitive architecture and the sorts of models that have traditionally been assumed in cognitive science. We claim that the major distinction is that, while both Connectionist and Classical architectures postulate representational mental states, the latter but not the former are committed to a symbol-level of representation, or to a `language of thought': i.e., to representational states that have combinatorial syntactic and semantic structure. Several arguments for combinatorial structure in mental representations are then reviewed. These include arguments based on the `systematicity' of mental representation: i.e., on the fact that cognitive capacities always exhibit certain symmetries, so that the ability to entertain a given thought implies the ability to entertain thoughts with semantically related contents. We claim that such arguments make a powerful case that mind/brain architecture is not Connectionist at the cognitive level. We then consider the possibility that Connectionism may provide an account of the neural (or `abstract neurological') structures in which Classical cognitive architecture is implemented. We survey a number of the standard arguments that have been offered in favor of Connectionism, and conclude that they are coherent only on this interpretation.
R{\'e}sum{\'e}
Cet article{\'e}tudie les diff{\'e}rences entre mod{\`e}les connectionistes et mod{\`e}les classiques de la structure cognitive. Nous pensons que, bien que les deux types de mod{\`e}les stipulent l'existence d'{\'e}tats mentaux repr{\'e}sentationnels, la diff{\'e}rence essentielle est que seuls les mod{\`e}les classiques requi{\`e}rent l'existence d'un niveau de repr{\'e}sentation symbolique---un ``langage de la pens{\'e}e''---, c'est-{\`a}-dire d'{\'e}tats repr{\'e}sentationnels poss{\'e}dant une structure syntaxique et s{\'e}mantique. Nous examinons ensuite diff{\'e}rents arguments qui militent en faveur de l'existence de repr{\'e}sentations mentales ayant ces propri{\'e}t{\'e}s. Certains de ces arguments reposent sur la ``syst{\'e}maticit{\'e}'' des repr{\'e}sentations mentales, c'est-{\`a}-dire sur le fait que les capacit{\'e}s cognitives exhibent toujours certaines sym{\'e}tries, de sorte que la capacit{\'e}d'entretenir certaines pens{\'e}es implique la capacit{\'e}d'entretenir d'autres pens{\'e}es apparent{\'e}es par leur contenu s{\'e}mantique. Nous pensons que ces arguments montrent de mani{\`e}re convainquante que l'architecture de l'esprit/du cerveau n'est pas connectioniste au niveau cognitif. Nous nous demandons ensuite s'il est possible d'interpr{\'e}ter le connectionisme comme une analyse des structures neuronales (ou des structures neurologiques ``abstraites'') dans lesquelles est r{\'e}alis{\'e}e l'architecture cognitive classique. Nous examinons plusieurs des arguments avanc{\'e}s habituellement en d{\'e}fense du connectionisme, et en concluons que ceux-ci n'ont de sens que dans cette interpr{\'e}tation.},
	Author = {Jerry A. Fodor and Zenon W. Pylyshyn},
	Doi = {https://doi.org/10.1016/0010-0277(88)90031-5},
	Issn = {0010-0277},
	Journal = {Cognition},
	Number = {1},
	Pages = {3-71},
	Title = {Connectionism and cognitive architecture: A critical analysis},
	Url = {https://www.sciencedirect.com/science/article/pii/0010027788900315},
	Volume = {28},
	Year = {1988},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/0010027788900315},
	Bdsk-Url-2 = {https://doi.org/10.1016/0010-0277(88)90031-5}}


@incollection{dyer91,
	Abstract = {Symbolic processing rests on a computational technology that includes dynamic memory management, virtual pointers to created structured objects, and the use of variables to propagate bindings. Connectionist models have lacked these features, but create distributed representations that are ``rich,'' i.e., that encode numerous statistically based expectations, acquired from experience. It is argued here that a synthesis of both symbolic and connectionist features will make important contributions to our understanding of high-level cognition. In what follows, a motivation is given for the need of such a synthesis, along with several, novel techniques used in connectionist systems designed to perform high-level, language-related processing tasks.},
	Address = {Dordrecht},
	Author = {Dyer, Michael G.},
	Booktitle = {Connectionism and the Philosophy of Mind},
	Doi = {10.1007/978-94-011-3524-5_17},
	Editor = {Horgan, Terence and Tienson, John},
	Isbn = {978-94-011-3524-5},
	Pages = {382--416},
	Publisher = {Springer Netherlands},
	Title = {Connectionism Versus Symbolism in High-Level Cognition},
	Url = {https://doi.org/10.1007/978-94-011-3524-5_17},
	Year = {1991},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-94-011-3524-5_17}}


@article{minsky91,
	Abstractnote = {Engineering and scientific education condition us to expect everything, including intelligence, to have a simple, compact explanation. Accordingly, when people new to AI ask &quot;What's AI all about,&quot; they seem to expect an answer that defines AI in terms of a few basic mathematical laws. Today, some researchers who seek a simple, compact explanation hope that systems modeled on neural nets or some other connectionist idea will quickly overtake more traditional systems based on symbol manipulation. Others believe that symbol manipulation, with a history that goes back millennia, remains the only viable approach. Marvin Minsky subscribes to neither of these extremist views. Instead, he argues that AI must use many approaches. AI is not like circuit theory and electromagnetism. There is nothing wonderfully unifying like Kirchhoff's laws are to circuit theory or Maxwell's equations are to electromagnetism. Instead of looking for a &quot;right way,&quot; the time has come to build systems out of diverse components, some connectionist and some symbolic, each with its own diverse justification.&quot; - Patrick Winston},
	Author = {Minsky, Marvin L.},
	Doi = {10.1609/aimag.v12i2.894},
	Journal = {AI Magazine},
	Month = {Jun.},
	Number = {2},
	Pages = {34},
	Title = {Logical Versus Analogical or Symbolic Versus Connectionist or Neat Versus Scruffy},
	Url = {https://ojs.aaai.org/index.php/aimagazine/article/view/894},
	Volume = {12},
	Year = {1991},
	Bdsk-Url-1 = {https://ojs.aaai.org/index.php/aimagazine/article/view/894},
	Bdsk-Url-2 = {https://doi.org/10.1609/aimag.v12i2.894}}



@inproceedings{maruyama21,
	Abstract = {There are two types of approaches to Artificial Intelligence, namely Symbolic AI and Statistical AI. The symbolic and statistical paradigms of cognition may be considered to be in conflict with each other; the recent debate between Chomsky and Norvig exemplifies a fundamental tension between the two paradigms (esp. on language), which is arguably in parallel with a conflict on interpretations of quantum theory as seen between Bohr and Einstein, one side arguing for the probabilist or empiricist view and the other for the universalist or rationalist view. In the present paper we explicate and articulate the fundamental discrepancy between them, and explore how a unifying theory could be developed to integrate them, and what sort of cognitive r{\^o}les Integrated AI could play in comparison with present-day AI. We give, inter alia, a classification of Integrated AI, and argue that Integrated AI serves the purpose of humanising AI in terms of making AI more verifiable, more explainable, more causally accountable, more ethical, and thus closer to general intelligence. We especially emphasise the ethical advantage of Integrated AI. We also briefly touch upon the Turing Test for Ethical AI, and the pluralistic nature of Turing-type Tests for Integrated AI. Overall, we believe that the integrated approach to cognition gives the key to the next generation paradigm for AI and Cognitive Science in general, and that Categorical Integrated AI or Categorical Integrative AI Robotics would be arguably the most promising approach to it.},
	Address = {Cham},
	Author = {Maruyama, Yoshihiro},
	Booktitle = {Software Engineering and Formal Methods. SEFM 2020 Collocated Workshops},
	Editor = {Cleophas, Loek and Massink, Mieke},
	Isbn = {978-3-030-67220-1},
	Pages = {129--146},
	Publisher = {Springer International Publishing},
	Title = {Symbolic and Statistical Theories of Cognition: Towards Integrated Artificial Intelligence},
	Year = {2021}}


 

@incollection{h01,
address = {San Diego, CA},
author = {Hyman, Larry M.},
booktitle = {The Role of Speech Perception in Phonology},
editor = {Elizabeth Hume and Keith Johnson},
pages = {141-186},
publisher = {Academic Press},
title = {The limits of phonetic determinism in phonology: *{NC} revisited},
year = {2001},
}

@incollection{h13,
author = {Hyman, Larry M.},
pages = {3-28},
address = {Oxford},
booktitle = {Origins of Sound Change: Approaches to Phonologization},
editor = {Alan C. L. Yu},
publisher = {Oxford University Press},
title = {Enlarging the scope of phonologization},
year = {2013},
}

@article{hs74,
author = {Hyman, Larry M. and Russell G. Schuh},
journal = {Linguistic Inquiry},
number = {1},
pages = {81-115},
title = {Universals of tone rules: Evidence from {West Africa}},
volume = {5},
year = {1974},
}

@incollection{is11,
address = {Malden, MA},
author = {Iverson, Gregory K. and Joseph C. Salmons},
booktitle = {The {B}lackwell Companion to Phonology: Suprasegmental and Prosodic Phonology},
editor = {Marc van Oostendorp and Colin J. Ewen and Elizabeth Hume and Keren Rice},
note = {Volume 2},
pages = {1622-1643},
publisher = {Wiley-Blackwell},
title = {Final devoicing and final laryngeal neutralization},
year = {2011},
}

@article{j91,
author = {Janson, Tore},
journal = {Sprache und Geschichte in Afrika},
pages = {1-44},
title = {Southern {B}antu and {M}akua},
volume = {12/13},
year = {1991/1992},
}


@article{lowenstein08,
author = {Lowenstein,Joanna H.  and Nittrouer,Susan },
title = {Patterns of acquisition of native voice onset time in English-learning children},
journal = {The Journal of the Acoustical Society of America},
volume = {124},
number = {2},
pages = {1180-1191},
year = {2008},
doi = {10.1121/1.2945118},

URL = { 
        https://doi.org/10.1121/1.2945118
    
},
eprint = { 
        https://doi.org/10.1121/1.2945118
    
}

}

@article{gilbert77, title={A voice onset time analysis of apical stop production in 3-year-olds}, volume={4}, DOI={10.1017/S0305000900000507}, number={1}, journal={Journal of Child Language}, publisher={Cambridge University Press}, author={Gilbert, John H. V.}, year={1977}, pages={103–110}}


@article{hare95,
title = "Learning and morphological change",
journal = "Cognition",
volume = "56",
number = "1",
pages = "61 - 98",
year = "1995",
issn = "0010-0277",
doi = "https://doi.org/10.1016/0010-0277(94)00655-5",
url = "http://www.sciencedirect.com/science/article/pii/0010027794006555",
author = "Mary Hare and Jeffrey L. Elman",
abstract = "An account is offered to change over time in English verb morphology, based on a connectionist approach to how morphological knowledge is acquired and used. A technique is first described that was developed for modeling historical change in connectionist networks, and that technique is applied to model English verb inflection as it developed from the highly complex past tense system of Old English towards that of the modern language, with one predominant “regular” inflection and a small number of irregular forms. The model relies on the fact that certain input-output mappings are easier than others to learn in a connectionist network. Highly frequent patterns, or those that share phonological regularities with a number of others, are learned more quickly and with lower error than low-frequency, highly irregular patterns. A network is taught a data set representative of the verb classes of Old English, but learning is stopped before reaching asymptote, and the output of this network is used as the teacher of a new net. As a result, the errors in the first network were passed on to become part of the data set of the second. Those patterns that are hardest to learn led to the most errors, and over time are “regularized” to fit a more dominant pattern. The results of the networks simulations were highly consistent with the major historical developments. These results are predicted from well-understood aspects of network dynamics, which therefore provide a rationale for the shape of the attested changes."
}

@article{yang18, title={Development of stop consonants in three- to six-year-old Mandarin-speaking children}, volume={45}, DOI={10.1017/S0305000918000090}, number={5}, journal={Journal of Child Language}, publisher={Cambridge University Press}, author={Yang, Jing}, year={2018}, pages={1091–1115}}


@InProceedings{deboer03,
author="de Boer, Bart",
editor="Banzhaf, Wolfgang
and Ziegler, Jens
and Christaller, Thomas
and Dittrich, Peter
and Kim, Jan T.",
title="Conditions for Stable Vowel Systems in a Population",
booktitle="Advances in Artificial Life",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="415--424",
abstract="This paper describes an investigation of two computer models of how vowel systems can be transferred from one generation to the next. Humans tend to reduce the articulation of the vowels (and other speech sounds) they produce. If infants would learn on the basis of these reduced signals, vowel systems would collapse rapidly over time. As this is not observed in practice, some mechanism must be present to counter it. Two candidate mechanisms are investigated in this paper: compensatory expansion of articulations learned on the basis of reduced speech sounds and learning on the basis of more carefully articulated speech. It turns out that larger vowel systems with central vowels can only remain stable when learning is based on carefully articulated speech.",
isbn="978-3-540-39432-7"
}


@incollection{livingstone02,
author="Livingstone, Daniel",
editor="Cangelosi, Angelo
and Parisi, Domenico",
title="The Evolution of Dialect Diversity",
bookTitle="Simulating the Evolution of Language",
year="2002",
publisher="Springer London",
address="London",
pages="99--117",
abstract="Observations on dialect diversity have been recorded for thousands of years, including Old Testament stories and early writings and literature from around the globe. Language diversity remains the subject of much study today --- largely in the related fields of socio-linguistics, historical linguistics and dialectology. One key question is why is there so much difference in dialects. To some the question was irrelevant as diversity was somehow obviously a natural feature of human language, one not requiring much explanation --- it simply was. Currently the question of why diversity should exist to the degree that it does has been taken quite seriously, with strong differences of opinion apparent.",
isbn="978-1-4471-0663-0",
doi="10.1007/978-1-4471-0663-0_5",
url="https://doi.org/10.1007/978-1-4471-0663-0_5"
}

@article{zellou14,
title = "Nasal coarticulation changes over time in Philadelphia English",
journal = "Journal of Phonetics",
volume = "47",
pages = "18 - 35",
year = "2014",
issn = "0095-4470",
doi = "https://doi.org/10.1016/j.wocn.2014.09.002",
url = "http://www.sciencedirect.com/science/article/pii/S0095447014000734",
author = "Georgia Zellou and Meredith Tamminga",
keywords = "Coarticulation, Sound change, Phonetic variation, Lexical frequency, Spontaneous speech corpus",
abstract = "This study examines change over time in coarticulatory vowel nasality in both real and apparent time in Philadelphia English. We measure nasal-adjacent vowels in words from a corpus of conversational speech and find systematic, community-level changes in degree of nasal coarticulation over time in Philadelphia. Specifically, in all speakers who were under the age of 25 when interviewed, there is an overall trend of increasing nasality in people born between 1950 and 1965, yet people born after 1965 move towards less nasality than speakers born earlier; finally, those born after 1980 reverse this change, moving again toward greater nasal coarticulation. This finding adds nasality to the set of phonetic dimensions that are demonstrably susceptible to diachronic change in a speech community. The observation that the degree of nasal coarticulation changes towards increased coarticulation at one time period and decreased coarticulation at a different time period adds to the growing body of evidence that subphonemic variation is not universally determined, suggesting instead that it is learned and encoded. Furthermore, the changes in nasality are independent from an observed frequency effect. These empirical patterns suggest that language-internal factors, such as lexical frequency, are independent from language external factors, such as community-level phonetic change over time."
}

@incollection{dimex,
	author = {Pineda, Luis A. and Pineda, Luis Villase{\ifmmode\tilde{n}\else\~{n}\fi}or and Cu{\ifmmode\acute{e}\else\'{e}\fi}tara, Javier and Castellanos, Hayde and L{\ifmmode\acute{o}\else\'{o}\fi}pez, Ivonne},
	title = {{DIMEx100: A New Phonetic and Speech Corpus for Mexican Spanish}},
	booktitle = {{Advances in Artificial Intelligence {\textendash} IBERAMIA 2004}},
	journal = {SpringerLink},
	pages = {974--983},
	year = {2004},
	month = {Nov},
	isbn = {978-3-540-23806-5},
	publisher = {Springer},
	address = {Berlin, Germany},
	doi = {10.1007/978-3-540-30498-2_97}
}

@inproceedings{tamminga15,
author = {Tamminga, Meredith and Zellou, Georgia},
year = {2015},
month = {08},
pages = {},
title = {Cross-dialectal differences in nasal coarticulation in American English},
journal = {Proceedings of the 18th International Congress of Phonetic Sciences (ICPhS XVIII, Glasgow)}
}

@phdthesis{kiparsky65,
author = {Paul Kiparsky},
school = {Massachusetts Institute of Technology},
title = {Phonological change},
year = {1965},
}

@incollection{bermudez03,
author="Berm{\'u}dez-Otero, Ricardo
and Hogg, Richard M.",
editor="Holt, D. Eric",
title="The Actuation Problem in Optimality Theory",
bookTitle="Optimality Theory and Language Change",
year="2003",
publisher="Springer Netherlands",
address="Dordrecht",
pages="91--119",
abstract="This chapter outlines Optimality Theory's contribution to research into the actuation of phonological change. We examine both phonetically-driven innovation and analogical change (particularly rule inversion and rule loss).",
isbn="978-94-010-0195-3",
doi="10.1007/978-94-010-0195-3_4",
url="https://doi.org/10.1007/978-94-010-0195-3_4"
}



@phdthesis{j93,
author = {Janssens, Baudouin},
school = {Universit\'e libre de Bruxelles, Facult\'e de Philosophie et Lettres, Bruxelles},
title = {Doubles r\'eflexes consonantiques: quatre \'etudes sur le bantou de zone A (bubi, nen, bafia, ewondo)},
year = {1993},
}

@phdthesis{zymet18,
author = {Jesse Zymet},
school = {University of California, Los Angeles},
title = {Lexical propensities in phonology: corpus and experimental evidence, grammar, and learning.},
year = {2018},
}


@phdthesis{chandlee14,
author = {Chandlee, Jane},
school = {University of Delaware},
title = {Strictly local phonological processes},
year = {2014},
}


@unpublished{kaplan08,
author = {Kaplan, Abby},
note = {Ms., University of California, Santa Cruz},
title = {Perceptual, Articulatory, and Systemic Influences on Lenition},
year = {2008},
}

@phdthesis{k10,
author = {Kaplan, Abby},
school = {University of California, Santa Cruz},
title = {Phonology shaped by phonetics: The case of intervocalic lenition},
year = {2010},
}

@phdthesis{katzir08,
author = {Katzir Cozier, Franz.},
school = {Massachusetts Institute of Technology},
title = {The Role of Perception in Phonotactic Constraints: Evidence from {T}rinidad {E}nglish},
year = {2008},
}

@book{kk77,
address = {New York},
author = {Kenstowicz, Michael J. and Charles W. Kisseberth},
publisher = {Academic Press},
title = {Topics in Phonological Theory},
year = {1977},
}

@article{km69,
author = {Kent, Raymond D. and Kenneth L. Moll},
journal = {Journal of the Acoustical Society of America},
number = {6},
pages = {1549-1555},
title = {Vocal tract characteristics of the stop consonants},
volume = {46},
year = {1969},
}

@article{kcs74,
author = {Kent, Raymond D. and Patrick J. Carney and Larry R. Severeid},
journal = {Journal of Speech Language and Hearing Research},
number = {3},
pages = {470-488},
title = {Velar movement and timing: Evaluation of a model for binary control},
volume = {17},
year = {1974},
}

@incollection{ks01,
address = {Cambridge, MA},
author = {Keyser, Samuel J. and Kenneth N. Stevens},
booktitle = {Ken Hale: A Life in Language},
editor = {Michael Kenstowicz},
pages = {271-291},
publisher = {Massachusetts Institute of Technology},
title = {Enhancement revisited},
year = {2001},
}

@article{ks06,
author = {Keyser, Samuel J. and Kenneth N. Stevens},
journal = {Language},
number = {1},
pages = {33-63},
title = {Enhancement and overlap in the speech chain},
volume = {82},
year = {2006},
}

@article{kd94,
author = {Kingston, John and Randy L. Diehl},
journal = {Language},
number = {3},
pages = {419-454},
title = {Phonetic knowledge},
volume = {70},
year = {1994},
}

@incollection{k71,
address = {College Park},
author = {Kiparsky, Paul},
booktitle = {A Survey of Linguistic Science},
editor = {William O. Dingwall},
pages = {576-642},
publisher = {University of Maryland Linguistics Program},
title = {Historical linguistics},
year = {1971},
}

@incollection{k73,
address = {Tokyo},
author = {Kiparsky, Paul},
booktitle = {Three Dimensions of Linguistic Theory},
editor = {Osamu Fujimura},
pages = {57-86},
publisher = {TEC},
title = {Abstractness, opacity, and global rules},
year = {1973},
}

@incollection{k95,
address = {Oxford},
author = {Kiparsky, Paul},
booktitle = {Handbook of Phonological Theory},
editor = {John Goldsmith},
pages = {640-670},
publisher = {Blackwell, 1995},
title = {The phonological basis of sound change},
year = {1995},
}

@article{kiparsky06,
author = {Kiparsky, Paul},
journal = {Theoretical Linguistics},
number = {2},
pages = {217-236},
title = {Amphichronic program vs. {Evolutionary Phonology}},
volume = {32},
year = {2006},
}

@incollection{kiparsky08,
address = {Oxford},
author = {Kiparsky, Paul},
booktitle = {Linguistic universals and language change},
editor = {Jeff Good},
pages = {23-53},
publisher = {Oxford University Press},
title = {Universals constrain change, change results in typological generalizations},
year = {2008},
}

@incollection{k15,
address = {Newcastle upon Tyne},
author = {Kiparsky, Paul},
booktitle = {Capturing Phonological Shades Within and Across Languages},
editor = {Yuchau E.~Hsiao and Lian-Hee Wee},
pages = {2-44},
publisher = {Cambridge Scholars Publishing},
title = {Stratal {OT}: A synopsis and {FAQ}s},
year = {2015},
}

@article{k00,
author = {Kirchner, Robert},
journal = {Language},
number = {3},
pages = {509-545},
title = {Geminate inalterability and lenition},
volume = {76},
year = {2000},
}

@unpublished{kummel06,
author = {K\"ummel, Martin},
title = {Einf\"uhrung ins {O}stmitteliranische},
year = {2006},
note = {\url{www.academia.edu/30130317} (accessed 30 March 2018)},
}

@book{k07,
address = {Wiesbaden},
author = {K\"ummel, Martin},
publisher = {Reichert},
title = {Konsonantenwandel},
year = {2007},
}

@book{l94,
address = {Oxford},
author = {Labov, William},
note = {Volumes 1 \& 2},
publisher = {Blackwell},
title = {Principles of Linguistic Change},
year = {1994},
}


@book{phoible,
  address   = {Leipzig},
  editor    = {Steven Moran and Daniel McCloy and Richard Wright},
  publisher = {Max Planck Institute for Evolutionary Anthropology},
  title     = {PHOIBLE Online},
  url       = {https://phoible.org/},
  year      = {2014}
}

@book{lm96,
address = {Oxford},
author = {Ladefoged, Peter and Ian Maddieson},
publisher = {Blackwell},
title = {The Sounds of the World's Languages},
year = {1996},
}

@article{rafferty13,
title = "Greater learnability is not sufficient to produce cultural universals",
journal = "Cognition",
volume = "129",
number = "1",
pages = "70 - 87",
year = "2013",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2013.05.003",
url = "http://www.sciencedirect.com/science/article/pii/S0010027713000966",
author = "Anna N. Rafferty and Thomas L. Griffiths and Marc Ettlinger",
keywords = "Cultural universals, Iterated learning, Learnability bias, Cultural evolution, Vowel harmony",
abstract = "Looking across human societies reveals regularities in the languages that people speak and the concepts that they use. One explanation that has been proposed for these “cultural universals” is differences in the ease with which people learn particular languages and concepts. A difference in learnability means that languages and concepts possessing a particular property are more likely to be accurately transmitted from one generation of learners to the next. Intuitively, this difference could allow languages and concepts that are more learnable to become more prevalent after multiple generations of cultural transmission. If this is the case, the prevalence of languages and concepts with particular properties can be explained simply by demonstrating empirically that they are more learnable. We evaluate this argument using mathematical analysis and behavioral experiments. Specifically, we provide two counter-examples that show how greater learnability need not result in a property becoming prevalent. First, more learnable languages and concepts can nonetheless be less likely to be produced spontaneously as a result of transmission failures. We simulated cultural transmission in the laboratory to show that this can occur for memory of distinctive items: these items are more likely to be remembered, but not generated spontaneously once they have been forgotten. Second, when there are many languages or concepts that lack the more learnable property, sheer numbers can swamp the benefit produced by greater learnability. We demonstrate this using a second series of experiments involving artificial language learning. Both of these counter-examples show that simply finding a learnability bias experimentally is not sufficient to explain why a particular property is prevalent in the languages or concepts used in human societies: explanations for cultural universals based on cultural transmission need to consider the full set of hypotheses a learner could entertain and all of the kinds of errors that can occur in transmission."
}

@unpublished{l18,
author = {Lapierre, Myriam},
note = {Ms., University of California, Berkeley},
title = {A sound change from {ND} to {NT}: Post-oralized and devoiced nasals in {P}anar\'a ({J}\^e)},
year = {2018},
}

@unpublished{begusbsc,
author = {Ga\v{s}per Begu\v{s}},
note = {Submitted ms., University of Washington},
url={ling.auf.net/lingbuzz/004299},
title = {Bootstrapping sound changes},
year = {2018},

}

@unpublished{begusnazarov,
author = {Ga\v{s}per Begu\v{s} and Aleksei Nazarov},
note = {Ms., University of Washington, University of Toronto},
title = {Lexicon against Naturalness: Unnatural Gradient Phonotactic Restrictions and Their Origins},
year = {2017},
}



@article{baer12,
title = "On the role of substance, locality, and amount of exposure in the acquisition of morphophonemic alternations",
author="Dinah Baer-Henney and Ruben van de Vijver",
journal = "Laboratory Phonology",
volume = "3",
number = "2",
pages = "221-249",
year = "2012",
doi = "https://doi.org/10.1515/lp-2012-0013",

}

@article{soskuthy17,
      title={Generalised additive mixed models for dynamic analysis in linguistics: a practical introduction}, 
      author={M\'arton S\'oskuthy},
      year={2017},
      journal={ArXiv},
      volume={abs/1703.05339}
}

@article{soskuthy15,
title = "Understanding change through stability: A computational study of sound change actuation",
journal = "Lingua",
volume = "163",
pages = "40 - 60",
year = "2015",
issn = "0024-3841",
doi = "https://doi.org/10.1016/j.lingua.2015.05.010",
url = "http://www.sciencedirect.com/science/article/pii/S0024384115001011",
author = "M\'arton S\'oskuthy",
keywords = "Sound change, Actuation problem, Phonetic bias, Contrast maintenance, Computational simulation",
abstract = "Many approaches to sound change attempt to derive common patterns of sound change from universal pressures, such as physiological and psychoacoustic constraints on speech. Accounts of this type face the following problem: it is not clear why universal pressures only lead to changes in some languages, but not in others. This issue is part of the so-called actuation problem. The question of sound change actuation is usually addressed by referring to social factors and individual differences that may inhibit or encourage the spread of a sound change in a community. While this paper acknowledges the importance of such explanations, it argues that some aspects of sound change actuation can also be approached by looking at structural factors that are typically associated with the initiation of sound change. I use computational simulations to investigate the evolution of sound systems under multiple pressures. The simulated sound systems evolve towards stable states in adaptive landscapes defined partly by universal pressures (e.g. phonetic biases and contrast maintenance) and partly by language-specific factors (e.g. the relative frequency of specific phonetic environments). The former create common pathways of change, while the latter lead to cross-linguistic variation. As it will be shown, this approach can account both for stability and change. The simulations also demonstrate how language-specific factors can be used to make predictions about the stable states towards which sound systems converge."
}

@article{begus19,
author={Begu\v{s}, Ga\v{s}per},   
title={Generative Adversarial Phonology: Modeling Unsupervised Phonetic and Phonological Learning With Neural Networks},      	
journal={Frontiers in Artificial Intelligence},      
volume={3},      
pages={44},     	
year={2020},      	  
URL={https://www.frontiersin.org/article/10.3389/frai.2020.00044},       	
DOI={10.3389/frai.2020.00044},      	
ISSN={2624-8212},   
}

@article{nettle99,
title = "Using Social Impact Theory to simulate language change",
journal = "Lingua",
volume = "108",
number = "2",
pages = "95 - 117",
year = "1999",
issn = "0024-3841",
doi = "https://doi.org/10.1016/S0024-3841(98)00046-1",
url = "http://www.sciencedirect.com/science/article/pii/S0024384198000461",
author = "Daniel Nettle",
keywords = "Language change, Social networks, Actuation problem, Computer simulation",
abstract = "This paper presents a framework for simulating language change in social networks derived from Social Impact Theory. In this framework, the language learner samples the speech of individuals from right across his speech community, though he may weight their input differentially according to their social position. This conceptualisation is argued to be more realistic than that provided by other models. Computer simulations are used to investigate the effects on language change of different social structures and biases in language acquisition. From the results of these simulations, it is argued that the fundamental engine driving language change is the combination of inherent variation in language acquisition and differences between individuals in local social influence. Functional biases attaching to different linguistic variants influence the direction of language change."
}

@inproceedings{duran17,
  author={Daniel Duran and Jagoda Bruni and Grzegorz Dogil and Justus Roux},
  title={The Social Life of Setswana Ejectives},
  year=2017,
  booktitle={Proc. Interspeech 2017},
  pages={3787--3791},
  doi={10.21437/Interspeech.2017-922},
  url={http://dx.doi.org/10.21437/Interspeech.2017-922}
}

@article{warlaumont16,
    author = {Warlaumont, Anne S. AND Finnegan, Megan K.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Learning to Produce Syllabic Speech Sounds via Reward-Modulated Neural Plasticity},
    year = {2016},
    month = {01},
    volume = {11},
    url = {https://doi.org/10.1371/journal.pone.0145096},
    pages = {1-30},
    abstract = {At around 7 months of age, human infants begin to reliably produce well-formed syllables containing both consonants and vowels, a behavior called canonical babbling. Over subsequent months, the frequency of canonical babbling continues to increase. How the infant’s nervous system supports the acquisition of this ability is unknown. Here we present a computational model that combines a spiking neural network, reinforcement-modulated spike-timing-dependent plasticity, and a human-like vocal tract to simulate the acquisition of canonical babbling. Like human infants, the model’s frequency of canonical babbling gradually increases. The model is rewarded when it produces a sound that is more auditorily salient than sounds it has previously produced. This is consistent with data from human infants indicating that contingent adult responses shape infant behavior and with data from deaf and tracheostomized infants indicating that hearing, including hearing one’s own vocalizations, is critical for canonical babbling development. Reward receipt increases the level of dopamine in the neural network. The neural network contains a reservoir with recurrent connections and two motor neuron groups, one agonist and one antagonist, which control the masseter and orbicularis oris muscles, promoting or inhibiting mouth closure. The model learns to increase the number of salient, syllabic sounds it produces by adjusting the base level of muscle activation and increasing their range of activity. Our results support the possibility that through dopamine-modulated spike-timing-dependent plasticity, the motor cortex learns to harness its natural oscillations in activity in order to produce syllabic sounds. It thus suggests that learning to produce rhythmic mouth movements for speech production may be supported by general cortical learning mechanisms. The model makes several testable predictions and has implications for our understanding not only of how syllabic vocalizations develop in infancy but also for our understanding of how they may have evolved.},
    number = {1},
    doi = {10.1371/journal.pone.0145096}
}

@article{boer00,
	Author = {de Boer, Bart},
	Date-Added = {2020-04-28 20:25:16 +0000},
	Date-Modified = {2020-04-28 20:25:16 +0000},
	Journal = {Journal of Phonetics},
	Pages = {441--465},
	Title = {Self-organization in vowel systems},
	Ty = {JOUR},
	Volume = {28},
	Year = {2000}}
	
	@article{adam19,
  title={Investigating Under and Overfitting in Wasserstein Generative Adversarial Networks},
  author={Ben Adlam and Charles Weill and Amol Kapoor},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.14137}
}

@incollection{kaplan17,
      author={Abby Kaplan},
     date={28 April 2020},
     year={2017},
      title = "Exemplar-Based Models in Linguistics",
      booktitle={Oxford Bibliographies in Linguistics},
      publisher={Oxford University Press},
      url = "https://www.oxfordbibliographies.com/view/document/obo-9780199772810/obo-9780199772810-0201.xml"
}


@inbook{johnson97,
	Address = {San Diego, CA},
	Author = {Johnson, Keith},
        title = {Speech perception without speaker normalization: An exemplar model},
	Date-Added = {2020-04-28 20:20:06 +0000},
	Date-Modified = {2020-04-28 20:20:06 +0000},
	Isbn = {9780123865601},
	Pages = {145--165},
	Publisher = {Academic Press},
	booktitle = {Talker variability in speech processing},
	Ty = {CHAP},
	Year = {1997}}


@ARTICLE{kirby15,
       author = {{Kirby}, James and {Sonderegger}, Morgan},
        title = "{Bias and population structure in the actuation of sound change}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language, Physics - Physics and Society},
         year = 2015,
        month = Jul,
          eid = {arXiv:1507.04420},
        pages = {arXiv:1507.04420},
archivePrefix = {arXiv},
       eprint = {1507.04420},
 primaryClass = {cs.CL},
       adsurl = {https://ui.adsabs.harvard.edu/\#abs/2015arXiv150704420K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@article{kongetal12,
title = "Voice onset time is necessary but not always sufficient to describe acquisition of voiced stops: The cases of {Greek} and {Japanese}",
journal = "Journal of Phonetics",
volume = "40",
number = "6",
pages = "725 - 744",
year = "2012",
issn = "0095-4470",
doi = "https://doi.org/10.1016/j.wocn.2012.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S0095447012000526",
author = "Eun Jong Kong and Mary E. Beckman and Jan Edwards",
abstract = "The age at which children master adult-like voiced stops can generally be predicted by voice onset time (VOT): stops with optional short lag are early, those with obligatory lead are late. However, Japanese voiced stops are late despite having a short lag variant, whereas Greek voiced stops are early despite having consistent voicing lead. This cross-sectional study examines the acoustics of word-initial stops produced by English-, Japanese-, and Greek-speaking children aged 2–5, to investigate how these seemingly exceptional mastery patterns relate to use of other phonetic correlates. Productions were analyzed for VOT, f0 and spectral tilt (H1−H2) in Japanese and English, and for amplitude trajectory in Greek and Japanese. Japanese voiceless stops have intermediate lag VOT values, so other “secondary” cues are needed to differentiate them from the voiced short lag VOT variant. Greek voiced stops are optionally prenasalized, and the amplitude trajectory for the voice bar during closure suggests that younger children use a greater degree of nasal venting to create the aerodynamic conditions necessary for voicing lead. Taken together, the findings suggest that VOT must be supplemented by measurements of other language-specific acoustic properties to explain the mastery pattern of voiced stops in some languages."
}

@book{bybee01, place={Cambridge}, series={Cambridge Studies in Linguistics}, title={Phonology and Language Use}, DOI={10.1017/CBO9780511612886}, publisher={Cambridge University Press}, author={Bybee, Joan}, year={2001}, collection={Cambridge Studies in Linguistics}}

@article{weber18,
author = {Cutler,Anne  and Weber,Andrea  and Smits,Roel  and Cooper,Nicole },
title = {Patterns of English phoneme confusions by native and non-native listeners},
journal = {The Journal of the Acoustical Society of America},
volume = {116},
number = {6},
pages = {3668-3678},
year = {2004},
doi = {10.1121/1.1810292},

URL = { 
        https://doi.org/10.1121/1.1810292
    
},
eprint = { 
        https://doi.org/10.1121/1.1810292
    
}

}


@article {kirby07,
	author = {Kirby, Simon and Dowman, Mike and Griffiths, Thomas L.},
	title = {Innateness and culture in the evolution of language},
	volume = {104},
	number = {12},
	pages = {5241--5245},
	year = {2007},
	doi = {10.1073/pnas.0608222104},
	publisher = {National Academy of Sciences},
	abstract = {Human language arises from biological evolution, individual learning, and cultural transmission, but the interaction of these three processes has not been widely studied. We set out a formal framework for analyzing cultural transmission, which allows us to investigate how innate learning biases are related to universal properties of language. We show that cultural transmission can magnify weak biases into strong linguistic universals, undermining one of the arguments for strong innate constraints on language learning. As a consequence, the strength of innate biases can be shielded from natural selection, allowing these genes to drift. Furthermore, even when there is no natural selection, cultural transmission can produce apparent adaptations. Cultural transmission thus provides an alternative to traditional nativist and adaptationist explanations for the properties of human languages.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/104/12/5241},
	eprint = {https://www.pnas.org/content/104/12/5241.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}


@article{ferdinand19,
title = "The cognitive roots of regularization in language",
journal = "Cognition",
volume = "184",
pages = "53 - 68",
year = "2019",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2018.12.002",
url = "http://www.sciencedirect.com/science/article/pii/S0010027718303135",
author = "Vanessa Ferdinand and Simon Kirby and Kenny Smith",
keywords = "Regularisation, Frequency learning, Domain generality, Domain specificity, Language evolution",
abstract = "Regularization occurs when the output a learner produces is less variable than the linguistic data they observed. In an artificial language learning experiment, we show that there exist at least two independent sources of regularization bias in cognition: a domain-general source based on cognitive load and a domain-specific source triggered by linguistic stimuli. Both of these factors modulate how frequency information is encoded and produced, but only the production-side modulations result in regularization (i.e. cause learners to eliminate variation from the observed input). We formalize the definition of regularization as the reduction of entropy and find that entropy measures are better at identifying regularization behavior than frequency-based analyses. Using our experimental data and a model of cultural transmission, we generate predictions for the amount of regularity that would develop in each experimental condition if the artificial language were transmitted over several generations of learners. Here we find that the effect of cognitive constraints can become more complex when put into the context of cultural evolution: although learning biases certainly carry information about the course of language evolution, we should not expect a one-to-one correspondence between the micro-level processes that regularize linguistic datasets and the macro-level evolution of linguistic regularity."
}


@article{kirby08,
title = "Iterated learning and the evolution of language",
journal = "Current Opinion in Neurobiology",
volume = "28",
pages = "108 - 114",
year = "2014",
note = "SI: Communication and language",
issn = "0959-4388",
doi = "https://doi.org/10.1016/j.conb.2014.07.014",
url = "http://www.sciencedirect.com/science/article/pii/S0959438814001421",
author = "Simon Kirby and Tom Griffiths and Kenny Smith",
abstract = "Iterated learning describes the process whereby an individual learns their behaviour by exposure to another individual's behaviour, who themselves learnt it in the same way. It can be seen as a key mechanism of cultural evolution. We review various methods for understanding how behaviour is shaped by the iterated learning process: computational agent-based simulations; mathematical modelling; and laboratory experiments in humans and non-human animals. We show how this framework has been used to explain the origins of structure in language, and argue that cultural evolution must be considered alongside biological evolution in explanations of language origins."
}

@article{wang60,
Abstract = {Presents a study on the disagreement among the various frequency counts which have been made of English consonants. Discussion on the relative frequencies of the first order probabilities of English sounds; Interpretation of previous studies which were examined for the research; Affirmation that the relative frequency of consonants in English is not seriously affected by the style of literary content or by the dialect of the sample and that a relatively small sample yields typical values.},
Author = {Wang, William S.-Y. and Crawford, John},
ISSN = {00238309},
Journal = {Language \& Speech},
Keywords = {PHONOLOGY (Grammar), CONSONANTS, PHONETICS, SPEECH perception, VERBAL ability, ORAL communication, SPEECH},
Number = {3},
Pages = {131 - 139},
Title = {Frequency studies of {English} consonants},
Volume = {3},
Year = {1960},
}



@book{lacy06b, place={Cambridge}, series={Cambridge Studies in Linguistics}, title={Markedness: Reduction and Preservation in Phonology}, DOI={10.1017/CBO9780511486388}, publisher={Cambridge University Press}, author={de Lacy, Paul}, year={2006}, collection={Cambridge Studies in Linguistics}}

@Article{lacy13,
author="de Lacy, Paul
and Kingston, John",
title="Synchronic explanation",
journal="Natural Language {\&} Linguistic Theory",
year="2013",
month="May",
day="01",
volume="31",
number="2",
pages="287--355",
abstract="The aim of this article is to show that synchronic cognitive constraints are responsible for some restrictions on human speech sound patterns; not all markedness asymmetries can be ascribed to Performance-based mechanisms of diachronic change. We identify evidence for synchronic constraints in sound patterns that are desirable from a Performance perspective yet are not attested. We also discuss recent experiments that provide evidence for psychologically and even neurophysiologically active restrictions; these patterns can be distinguished from statistical generalizations across the lexicon. We also argue that there is evidence that language learning and adult well-formedness judgments are determined by innate predispositions. Finally, we examine the methodology behind choosing a synchronic or diachronic account for a particular sound pattern when both potentially offer an explanation.",
issn="1573-0859",
doi="10.1007/s11049-013-9191-y",
url="https://doi.org/10.1007/s11049-013-9191-y"
}


@article{begus18, title={Post-nasal devoicing and the blurring process}, DOI={10.1017/S002222671800049X}, journal={Journal of Linguistics}, publisher={Cambridge University Press}, author={Begu\v{s}, Ga\v{s}per}, pages={1–65},year={2018}}

@inproceedings{begusnazarov1,
address = {Amherst, MA},
author = {Ga\v{s}per Begu\v{s} and Aleksei Nazarov},
booktitle = {{Proceedings of the 48th {M}eeting of the {North East Linguistic Society}}},
publisher = {GLSA},
editor = {Sherry Hucklebridge and Max Nelson },
title = {Gradient trends against phonetic naturalness: The case of {Tarma Quechua}},
year = {To appear},
}

@book{l97,
address = {Cambridge},
author = {Lass, Roger},
publisher = {Cambridge University Press},
title = {Historical Linguistics and Language Change},
year = {1997},
}

@book{lsf15,
address = {Dallas, TX},
edition = {21st},
editor = {Gary F. Simons and Charles D. Fennig},
note = {\url{www.ethnologue.com} (accessed 13 October 2018)},
publisher = {SIL International},
title = {Ethnologue: Languages of the World},
year = {2018},
}


@incollection{l86,
address = {Orlando},
author = {Lindblom, Bj\"orn},
booktitle = {Experimental Phonology},
editor = {John J. Ohala and Jeri J. Jaeger},
pages = {13-44},
publisher = {Academic Press},
title = {Phonetic universals in vowel systems},
year = {1986},
}

@incollection{bullinaria97,
address = {Bristol},
author = {Bullinaria, John},
booktitle = {Neural Network Analysis, Architectures and Algorithms},
editor = {A. Browne},
pages = {3-26},
publisher = {Institute of Physics Press},
title = {Analyzing the internal representations of trained neural networks.},
year = {1997},
}

@article{tourville11,
author = { Jason A.   Tourville  and  Frank H.   Guenther },
title = { The DIVA model: A neural theory of speech acquisition and production},
journal = {Language and Cognitive Processes},
volume = {26},
number = {7},
pages = {952-981},
year  = {2011},
publisher = {Routledge},
doi = {10.1080/01690960903498424},
    note ={PMID: 23667281},

URL = { 
        https://doi.org/10.1080/01690960903498424
    
},
eprint = { 
        https://doi.org/10.1080/01690960903498424
    
}

}

@book{hale08,
  title={The phonological enterprise},
  author={Hale, Mark and Reiss, Charles},
  year={2008},
  publisher={Oxford University Press},
  location={Oxford},
}

@Article{randomforest,
    title = {Classification and Regression by randomForest},
    author = {Andy Liaw and Matthew Wiener},
    journal = {R News},
    year = {2002},
    volume = {2},
    number = {3},
    pages = {18-22},
    url = {https://CRAN.R-project.org/doc/Rnews/},
  }

@Article{glmnet,
    title = {Regularization Paths for Cox's Proportional Hazards Model via Coordinate Descent},
    author = {Noah Simon and Jerome Friedman and Trevor Hastie and Rob Tibshirani},
    journal = {Journal of Statistical Software},
    year = {2011},
    volume = {39},
    number = {5},
    pages = {1--13},
    url = {http://www.jstatsoft.org/v39/i05/},
  }

@article{guenther12,
title = "A neural theory of speech acquisition and production",
journal = "Journal of Neurolinguistics",
volume = "25",
number = "5",
pages = "408 - 422",
year = "2012",
note = "Is a neural theory of language possible? Issues from an interdisciplinary perspective",
issn = "0911-6044",
doi = "https://doi.org/10.1016/j.jneuroling.2009.08.006",
url = "http://www.sciencedirect.com/science/article/pii/S0911604409000682",
author = "Frank H. Guenther and Tony Vladusich",
keywords = "Speech production, Motor control, Neural model, fMRI, Mirror system",
abstract = "This article describes a computational model, called DIVA, that provides a quantitative framework for understanding the roles of various brain regions involved in speech acquisition and production. An overview of the DIVA model is first provided, along with descriptions of the computations performed in the different brain regions represented in the model. Particular focus is given to the model's speech sound map, which provides a link between the sensory representation of a speech sound and the motor program for that sound. Neurons in this map share with “mirror neurons” described in monkey ventral premotor cortex the key property of being active during both production and perception of specific motor actions. As the DIVA model is defined both computationally and anatomically, it is ideal for generating precise predictions concerning speech-related brain activation patterns observed during functional imaging experiments. The DIVA model thus provides a well-defined framework for guiding the interpretation of experimental results related to the putative human speech mirror system."
}

@inproceedings{haraguchi03,
  title={The acquisition of aspiration of voiceless stops and intonation patterns of English learners: Pilot study},
  author={Haraguchi, Yuko},
  booktitle={Proceeding of the 8th conference of Pan-Pacific Association of Applied Linguistics},
  pages={83--91},
  year={2003}
}


@article{macken81,
author = {Macken, Marlys A. and Ferguson, Charles A.},
title = {PHONOLOGICAL UNIVERSALS IN LANGUAGE ACQUISITION*},
journal = {Annals of the New York Academy of Sciences},
volume = {379},
number = {1},
pages = {110-129},
doi = {10.1111/j.1749-6632.1981.tb42002.x},
url = {https://nyaspubs.onlinelibrary.wiley.com/doi/abs/10.1111/j.1749-6632.1981.tb42002.x},
eprint = {https://nyaspubs.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1749-6632.1981.tb42002.x},
year = {1981}
}


@article{barlow01,
author = {Jessica A. Barlow },
title = {Case Study},
journal = {Language, Speech, and Hearing Services in Schools},
volume = {32},
number = {4},
pages  = {242-256},
year = {2001},
doi = {10.1044/0161-1461(2001/022)},

URL = {https://pubs.asha.org/doi/abs/10.1044/0161-1461\%282001/022\%29},
eprint = {https://pubs.asha.org/doi/pdf/10.1044/0161-1461\%282001/022\%29}
,
    abstract = { Recently, the development of the constraint-based framework of optimality theory has been adopted and applied to the assessment and treatment of children with phonological disorders. This paper provides a demonstration of the application of optimality theory to the assessment and treatment of a single child with a phonological disorder. First, a tutorial of the theory is provided. Then, several prototypical error patterns evident in the child's productions are analyzed within the framework. These errors are accounted for by assuming that constraints against marked structure are ranked over constraints that require faithfulness to input forms within the child’s grammar. Following that, a demonstration of how optimality theory accounts for different types of variation in the child’s productions is provided. These different types of variation are revealing of the true nature of certain error patterns, particularly an apparent pattern of cluster reduction. Finally, the results of the analysis lead to suggestions for treatment that focus on the demotion of markedness constraints below faithfulness constraints. }
}

@article{aldereteWIRE,
author = {Alderete, John and Tupper, Paul},
title = {Phonological regularity, perceptual biases, and the role of phonotactics in speech error analysis},
journal = {Wiley Interdisciplinary Reviews: Cognitive Science},
volume = {9},
number = {5},
pages = {e1466},
keywords = {frequency, markedness, perceptual biases, phonotactics, speech errors},
doi = {10.1002/wcs.1466},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wcs.1466},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/wcs.1466},
abstract = {Speech errors involving manipulations of sounds tend to be phonologically regular in the sense that they obey the phonotactic rules of well-formed words. We review the empirical evidence for phonological regularity in prior research, including both categorical assessments of words and regularity at the granular level involving specific segments and contexts. Since the reporting of regularity is affected by human perceptual biases, we also document this regularity in a new data set of 2,228 sublexical errors that was collected using methods that are demonstrably less prone to bias. These facts validate the claim that sound errors are overwhelmingly regular, but the new evidence suggests speech errors admit more phonologically ill-formed words than previously thought. Detailed facts of the phonological structure of errors, including this revised standard, are then related to model assumptions in contemporary theories of phonological encoding. This article is categorized under: Linguistics > Linguistic Theory Linguistics > Computational Models of Language Psychology > Language},
year = {2018}
}








@incollection{l90,
address = {Dordrecht},
author = {Lindblom, Bj\"orn},
booktitle = {Speech Production and Speech Modelling},
editor = {William J. Hardcastle and Alain Marchai},
pages = {403-439},
publisher = {Kluwer},
title = {Explaining phonetic variation: A sketch of the {H}\&{H} theory},
year = {1990},
}

@article{lghmw95,
author = {Lindblom, Bj\"orn and Susan Guion and Susan Hura and Seung-Jae Moon and Raquel Willerman},
journal = {Rivista di Linguistica},
pages = {5-36},
title = {Is sound change adaptive?},
volume = {7},
year = {1995},
}

@book{l83,
address = {New York},
author = {Locke, John},
publisher = {Academic Press},
title = {Phonological Acquisition and Change},
year = {1983},
}

@book{m84,
address = {Cambridge},
author = {Maddieson, Ian},
publisher = {Cambridge University Press},
title = {Patterns of Sounds},
year = {1984},
}

@article{m09,
author = {Makalela, Leketi},
journal = {International Multilingual Research Journal},
number = {2},
pages = {120-133},
title = {Harmonizing {South African S}otho language varieties: Lessons from reading proficiency assessment},
volume = {3},
year = {2009},
}

@article{mccarthy08,
author = {McCarthy, John},
journal = {Natural Language and Linguistic Theory},
pages = {499-546},
title = {The serial interaction of stress and syncope},
volume = {26},
year = {2008},
}

@unpublished{m14,
author = {Merrill, John},
note = {Ms., University of California, Berkeley},
title = {A historical account of the {Fula and Sereer} consonant mutation and noun class systems},
year = {2014},
}

@unpublished{m16a,
author = {Merrill, John},
note = {Talk presented at the \emph{90th Annual Meeting of the Linguistic Society of America}, Washington, DC, January 7-10, 2016},
title = {Consonant mutation and initial prominence: The historical loss of lexical contrastiveness},
year = {2016},
}

@unpublished{m16b,
author = {Merrill, John},
note = {Ms., University of California, Berkeley},
title = {Konyagi post-nasal devoicing?},
year = {2016},
}

@phdthesis{m75,
author = {Mills, Frederick R.},
school = {University of Michigan, Ann Arbor},
title = {{Proto South Sulawesi and Proto Austronesian} Phonology},
year = {1975},
}

@phdthesis{alanazi18,
author = {Alanazi, Sami},
school = {University of Essex},
title = {{The Acquisition of English stops by Saudi L2 Learners}},
year = {2018},
}


@article{lowenstein08,
author = {Lowenstein, Joanna H.  and Nittrouer, Susan },
title = {Patterns of acquisition of native voice onset time in English-learning children},
journal = {The Journal of the Acoustical Society of America},
volume = {124},
number = {2},
pages = {1180-1191},
year = {2008},
doi = {10.1121/1.2945118},

URL = { 
        https://doi.org/10.1121/1.2945118
    
},
eprint = { 
        https://doi.org/10.1121/1.2945118
    
}

}


@incollection{gibson12,
      author = "Kathleen R. Gibson and Maggie Tallerman and Peter F. MacNeilage",
      title = "The evolution of phonology",
      year = "2012",
      month = "09",
      publisher = "Oxford University Press",
      location="Oxford",
      isbn = "9780199541119",
      url = "https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199541119.001.0001/oxfordhb-9780199541119-e-46",
      booktitle={The Oxford Handbook of Language Evolution},
}

@incollection{yildiz05,
author = {Yildiz, Yasemin},
year = {2005},
booktitle = {Developmental Paths in Phonological Acquisition},
pages = {163-187},
editor={Marina Tzakosta and Claartje Levelt and Jeroen van der Weijer},
title = {The structure of initial/s/-clusters: evidence from {L1} and {L2} acquisition},
note= {Special issue of Leiden Papers in Linguistics 2.1}
}



@article{md71,
author = {Moll, Kenneth L. and Raymond G. Daniloff},
journal = {Journal of the Acoustical Society of America},
number = {2B},
pages = {678-684},
title = {Investigation of the timing of velar movements during speech},
volume = {50},
year = {1971},
}

@article{moreton08,
author = {Moreton, Elliott},
journal = {Phonology},
number = {1},
pages = {83-127},
title = {Analytic bias and phonological typology},
volume = {25},
year = {2008},
}

@article{mp12a,
author = {Moreton, Elliott and Joe Pater},
journal = {Language and Linguistics Compass},
number = {11},
pages = {686-701},
title = {Structure and substance in artificial-phonology learning. {Part I, Structure}},
volume = {6},
year = {2012},
}

@article{mp12b,
author = {Moreton, Elliott and Joe Pater},
journal = {Language and Linguistics Compass},
number = {11},
pages = {702-718},
title = {Structure and substance in artificial-phonology learning. {Part II, Substance}},
volume = {6},
year = {2012},
}

@article{m12,
author = {Morley, Rebecca L.},
journal = {Language Dynamics and Change},
pages = {59-97},
title = {The emergence of epenthesis: An incremental model of grammar change},
volume = {2},
year = {2012},
}

@article{morley14,
author = {Morley, Rebecca L.},
journal = {Language and Speech},
number = {1},
pages = {3-41},
title = {Implications of an exemplar-theoretic model of phoneme genesis: A velar palatalization case study},
volume = {57},
year = {2014},
}

@article{m15,
author = {Morley, Rebecca L.},
journal = {Language},
number = {2},
pages = {e40-e70},
title = {Can phonological universals be emergent? {M}odeling the space of sound change, lexical distribution, and hypothesis selection},
volume = {91},
year = {2015},
}

@article{m90,
author = {Mouguiama-Daouda, P.},
journal = {Pholia},
pages = {121-146},
title = {Esquisse d'une phonologie diachronique du Mpongwe},
volume = {5},
year = {1990},
}

@unpublished{m02,
author = {Myers, Scott},
note = {Ms., University of Texas, Austin. ROA},
title = {Gaps in factorial typology: the case of voicing in consonant clusters},
year = {2002},
}

@unpublished{n08,
author = {Nazarov, Aleksei},
note = {Ms., Leiden University},
title = {Stop voicing in {Tarma Quechua}},
year = {2008},
}

@article{begusEff,
author = {Begu\v{s}, Ga\v{s}per},
title = {Effects of ejective stops on preceding vowel duration},
journal = {Journal of the Acoustical Society of America},
volume = {142},
number = {4},
pages = {2168-2184},
year = {2017},




}


@article{n17,
author = {Nikulin, Andrey},
journal = {Journal of Language Relationship},
number = {3},
pages = {147-180},
title = {A phonological reconstruction of {Proto-Cerrado (J\^e} family)},
volume = {15},
year = {2017},
}

@incollection{n55,
address = {Canberra},
author = {Noorduyn, Jacobus},
booktitle = {{Bugis and M}akasar: Two short grammars},
editor = {Campbell Macknight},
note = {Translated by Campbell Macknight},
pages = {33-55},
publisher = {Karuda Press},
title = {The {B}ugis language},
year = {2012/1955},
}

@book{n10,
address = {Prague},
author = {Nov\'ak, L'ubom\'{\i}r},
publisher = {Univerzita Karlova v Praze, Filozofick\'a fakulta},
title = {Jaghn\'obsko-\v{c}esk\'y slovn\'\i k s p\v{r}ehledem jaghn\'obsk\'e grammatiky},
year = {2010},
}


@book{guenther16,
  title={Neural control of speech},
  author={Guenther, Frank H},
  year={2016},
  publisher={MIT Press},
  location={Cambridge, MA},
}

@article{vaux05, title={Laryngeal markedness and aspiration}, volume={22}, DOI={10.1017/S0952675705000667}, number={3}, journal={Phonology}, publisher={Cambridge University Press}, author={Vaux, Bert and Samuels, Bridget}, year={2005}, pages={395–436}}

@article{catts83,
author = {Hugh W. Catts  and Paul J. Jensen },
title = {Speech Timing of Phonologically Disordered Children},
journal = {Journal of Speech, Language, and Hearing Research},
volume = {26},
number = {4},
pages  = {501-510},
year = {1983},
doi = {10.1044/jshr.2604.501},

URL = {https://pubs.asha.org/doi/abs/10.1044/jshr.2604.501},
eprint = {https://pubs.asha.org/doi/pdf/10.1044/jshr.2604.501}
,
    abstract = { Speech timing of nine phonologically disordered and nine normally developing children was investigated for the voicing contrasts of word-initial and word-final stop consonants. Measurements of voice onset time, vowel duration, consonant closure duration, and voicing during consonant closure were made from spectrograms. In addition, listener transcriptions were employed for perceptual analysis. Results indicated that some phonologically disordered subjects failed to differentiate VOT in word-initial voiced and voiceless stops, whereas others produced much longer VOTs for voiceless stops than did control subjects. In the word-final voicing contrast, the phonologically disordered children evidenced longer consonant closure durations and less voicing during consonant closure than did normal subjects. However, like normal subjects, they demonstrated differential vowel and consonant closure durations in voiced and voiceless contexts. Perceptual analysis indicated significantly more voicing errors in the initial and final stops of phonologically disordered children. These various results are interpreted to mean that some phonologically disordered children may have less mature speech timing control. The implications of these data for the description of voicing errors also are discussed. }
}

@inproceedings{mcleod96,
  title={Homonyms and cluster reduction in the normal development of children's speech},
  author={McLeod, S and van Doorn, J and Reed, V},
  booktitle={Proceedings of the Sixth Australian International Conference on Speech Science \& Technology},
  pages={331--336},
  year={1996}
}


@inproceedings{oudeyer01,
author = {Oudeyer, Pierre-Yves},
year = {2001},
pages = {1171-1176},
booktitle={Proceedings of the {I}nternational conference on artificial neural networks. Lecture notes in computer science},
note={Volume: 2130},
title = {Coupled Neural Maps for the Origins of Vowel Systems},
doi = {10.1007/3-540-44668-0\_163},
location={Berlin},
publisher={Springer}
}

@inproceedings{oudeyer02,
          editor = { B. Hallam and D. Floreano and J. Hallam and G. Hayes and J-A. Meyer Hallam},
           title = {Phonemic Coding Might Result From Sensory-Motor Coupling Dynamics},
           booktitle={From animals to animats 7: Proceedings of the Seventh International Conference on Simulation of Adaptive Behavior},
          author = {Pierre-Yves Oudeyer},
       publisher = {MIT Press},
            year = {2002},
           pages = {406-416},
             url = {http://cogprints.org/2658/},
}

@article{oudeyer05,
title = "The self-organization of speech sounds",
journal = "Journal of Theoretical Biology",
volume = "233",
number = "3",
pages = "435 - 449",
year = "2005",
issn = "0022-5193",
doi = "https://doi.org/10.1016/j.jtbi.2004.10.025",
url = "http://www.sciencedirect.com/science/article/pii/S0022519304005053",
author = "Pierre-Yves Oudeyer",
keywords = "Origins of speech sounds, Self-organization, Evolution, Forms, Artificial systems, Agents, Phonetics, Phonology",
abstract = "The speech code is a vehicle of language: it defines a set of forms used by a community to carry information. Such a code is necessary to support the linguistic interactions that allow humans to communicate. How then may a speech code be formed prior to the existence of linguistic interactions? Moreover, the human speech code is discrete and compositional, shared by all the individuals of a community but different across communities, and phoneme inventories are characterized by statistical regularities. How can a speech code with these properties form? We try to approach these questions in the paper, using the “methodology of the artificial”. We build a society of artificial agents, and detail a mechanism that shows the formation of a discrete speech code without pre-supposing the existence of linguistic capacities or of coordinated interactions. The mechanism is based on a low-level model of sensory–motor interactions. We show that the integration of certain very simple and non-language-specific neural devices leads to the formation of a speech code that has properties similar to the human speech code. This result relies on the self-organizing properties of a generic coupling between perception and production within agents, and on the interactions between agents. The artificial system helps us to develop better intuitions on how speech might have appeared, by showing how self-organization might have helped natural selection to find speech."
}

@inproceedings{begusscil,
    title = "Modeling unsupervised phonetic and phonological learning in {Generative Adversarial Phonology}",
    author = "Ga\v{s}per Begu\v{s}",
    booktitle = "Proceedings of the Society for Computation in Linguistics ({SC}i{L}) 2020",
    year = "2020",
    url = "https://doi.org/10.7275/nbrf-1a27",
    doi = "10.7275/nbrf-1a27",
    pages = "138--148",
}



@inproceedings{wilson20,
    title = "Re(current) reduplication: Interpretable neural network models of morphological copying",
    author = "Wilson, Colin",
    booktitle = "Proceedings of the Society for Computation in Linguistics ({SC}i{L}) 2020",
    year = "2020",
    url = "https://doi.org/10.7275/6s01-2n43",
    doi = "https://doi.org/10.7275/6s01-2n43",
    pages = "379-380",
    volume="2",
}


Wilson, Colin (2019) "Re(current) reduplication: Interpretable neural network models of morphological copying," Proceedings of the Society for Computation in Linguistics: Vol. 2 , Article 56.


@article{bond81, title={A note concerning /s/ plus stop clusters in the speech of language-delayed children}, volume={2}, DOI={10.1017/S0142716400000655}, number={1}, journal={Applied Psycholinguistics}, publisher={Cambridge University Press}, author={Bond, Z. S.}, year={1981}, pages={55–63}}

@book{oudeyer06,
series = {Studies in the evolution of language ; 6},
abstract = {"Speech is the principal supporting medium of language. In this book Pierre-Yves Oudeyer considers how it first emerged. He presents an original and integrated view of the interactions between self-organization and natural selection, reformulates questions about the origins of speech, and puts forward what at first sight appears to be a startling proposal - that speech can be spontaneously generated by the coupling of evolutionarily simple neural structures connecting perception and production. He explores this hypothesis by constructing a computational system to model the effects of linking auditory and vocal neural nets. He shows that a population of agents which used holistic and unarticulated vocalizations at the outset are inexorably led to a state in which their vocalizations have become discrete, combinatorial, and categorized in the same way by all the group members. Furthermore, the simple syntactic rules that have emerged to regulate the combinations of sounds exhibit the fundamental properties of modern human speech systems."--Jacket.},
publisher = {Oxford University Press},
isbn = {019928914X},
year = {2006},
title = {Self-organization in the evolution of speech},
address = {Oxford},
author = {Oudeyer, Pierre-Yves},
}

@article{buchwald12,
author = {Adam Buchwald  and Michele Miozzo },
title = {Phonological and Motor Errors in Individuals With Acquired Sound Production Impairment},
journal = {Journal of Speech, Language, and Hearing Research},
volume = {55},
number = {5},
pages  = {S1573-S1586},
year = {2012},
doi = {10.1044/1092-4388(2012/11-0200)},

URL = {https://pubs.asha.org/doi/abs/10.1044/1092-4388\%282012/11-0200\%29},
eprint = {https://pubs.asha.org/doi/pdf/10.1044/1092-4388\%282012/11-0200\%29}

}


@article{berent13,
title = "The phonological mind",
journal = "Trends in Cognitive Sciences",
volume = "17",
number = "7",
pages = "319 - 327",
year = "2013",
issn = "1364-6613",
doi = "https://doi.org/10.1016/j.tics.2013.05.004",
url = "http://www.sciencedirect.com/science/article/pii/S1364661313001034",
author = "Iris Berent",
keywords = "phonology, core knowledge, algebraic rules, language universals, universal grammar, animal communication, language evolution, reading",
abstract = "Humans weave phonological patterns instinctively. We form phonological patterns at birth, we spontaneously generate them de novo, and we impose phonological design on both our linguistic communication and cultural technologies—reading and writing. Why are humans compelled to generate phonological patterns? Why are phonological patterns intimately grounded in their sensorimotor channels (speech or gesture) while remaining partly amodal and fully productive? And why does phonology shape natural communication and cultural inventions alike? Here, I suggest these properties emanate from the architecture of the phonological mind, an algebraic system of core knowledge. I evaluate this hypothesis in light of linguistic evidence, behavioral studies, and comparative animal research that gauges the design of the phonological mind and its productivity."
}

@article{bond80,
	Abstract = {Young children frequently substitute stops for fricative-stop clusters. In this paper, we report acoustic measurements for children's intended voiced and voiceless stops, and for stops substituting for clusters. Judging from voice-onset time measurements, children employ various strategies for assigning phonological status to the substituted stops.},
	Author = {Bond, Z. S. and Wilson, H. F.},
	Date-Added = {2019-07-02 21:20:50 +0000},
	Date-Modified = {2019-07-02 21:20:50 +0000},
	Doi = {10.1159/000259988},
	Isbn = {0031-8388},
	Journal = {Phonetica},
	Journal1 = {Phonetica},
	Number = {3},
	Pages = {149--158},
	Title = {/s/ plus Stop Clusters in Children's Speech},
	Ty = {JOUR},
	Url = {https://www.karger.com/DOI/10.1159/000259988},
	Volume = {37},
	Year = {1980},
	Bdsk-Url-1 = {https://www.karger.com/DOI/10.1159/000259988},
	Bdsk-Url-2 = {https://doi.org/10.1159/000259988}}


@article{syrika11,
author = {Asimina Syrika and Katerina Nicolaidis and Jan Edwards and Mary E. Beckman},
title ={Acquisition of Initial /s/-stop and stop-/s/ Sequences in {G}reek},
journal = {Language and Speech},
volume = {54},
number = {3},
pages = {361-386},
year = {2011},
doi = {10.1177/0023830911402597},
    note ={PMID: 22070044},

URL = { 
        https://doi.org/10.1177/0023830911402597
    
},
eprint = { 
        https://doi.org/10.1177/0023830911402597
    
}
,
    abstract = { Previous work on children’s acquisition of complex sequences points to a tendency for affricates to be acquired before clusters, but there is no clear evidence of a difference in order of acquisition between clusters with /s/ that violate the Sonority Sequencing Principle (SSP), such as /s/ followed by stop in onset position, and other clusters that obey the SSP. One problem with studies that have compared the acquisition of SSP-obeying and SSP-violating clusters is that the component sounds in the two types of sequences were different. This paper examines the acquisition of initial /s/-stop and stop-/s/ sequences by sixty Greek children aged 2 through 5 years. Results showed greater accuracy for the /s/-stop relative to the stop-/s/ sequences, but no difference in accuracy between /ts/, which is usually analyzed as an affricate in Greek, and the other stop-/s/ sequences. Moreover, errors for the /s/-stop sequences and /ts/ primarily involved stop substitutions, whereas errors for /ps/ and /ks/ were more variable and often involved fricative substitutions, a pattern which may have a perceptual explanation. Finally, /ts/ showed a distinct temporal pattern relative to the stop-/s/ clusters /ps/ and /ks/, similar to what has been reported for productions of Greek adults. }
}



@article{pouplier14,
author = {Marianne Pouplier  and Stefania Marin  and Susanne Waltl },
title = {Voice Onset Time in Consonant Cluster Errors: Can Phonetic Accommodation Differentiate Cognitive From Motor Errors?},
journal = {Journal of Speech, Language, and Hearing Research},
volume = {57},
number = {5},
pages  = {1577-1588},
year = {2014},
doi = {10.1044/2014\_JSLHR-S-12-0412},
URL = {https://pubs.asha.org/doi/abs/10.1044/2014\_JSLHR-S-12-0412}
}




@article{catts84,
author = {Hugh W. Catts  and Alan G. Kamhi },
title = {Simplification of /s/ + Stop Consonant Clusters},
journal = {Journal of Speech, Language, and Hearing Research},
volume = {27},
number = {4},
pages  = {556-561},
year = {1984},
doi = {10.1044/jshr.2704.556},

URL = {https://pubs.asha.org/doi/abs/10.1044/jshr.2704.556},
eprint = {https://pubs.asha.org/doi/pdf/10.1044/jshr.2704.556}
,
    abstract = { This longitudinal study examined individual patterns and changes in /s/ + stop cluster simplifications of six normally developing children. Subjects produced selected words containing initial voiced and voiceless stops and /s/+ stop clusters at monthly intervals. Speech samples were transcribed phonetically, and voice onset times (VOT) of the stop consonants were measured. The results revealed that subjects reduced clusters most frequently to stop consonants with short-lag VOTs. However, two children also occasionally employed prevoicing, and one subject used long-lag VOTs in cluster-reduced stops. Because cluster-reduced stops and voiced singleton stops were generally produced with similar VOTs, it was concluded that subjects represented clustered stops most frequently as phonemically voiced. }
}



@article{nguyen15,
title = "Role of imitation in the emergence of phonological systems",
journal = "Journal of Phonetics",
volume = "53",
pages = "46 - 54",
year = "2015",
note = "On the cognitive nature of speech sound systems",
issn = "0095-4470",
doi = "https://doi.org/10.1016/j.wocn.2015.08.004",
url = "http://www.sciencedirect.com/science/article/pii/S0095447015000698",
author = "Noël Nguyen and Véronique Delvaux",
keywords = "Imitation, Emergence, Phonological systems",
abstract = "The issue we address in this review paper is to what extent mutual adaptation plays a role in the emergence and evolution of phonological systems. Adaptation to the interlocutor has been shown to take many forms and to embrace all the levels of spoken language, from adjustments in vocal intensity to changes in word forms over the course of a conversational exchange, as well as lexical and syntactic alignment across speakers, to name but a few examples. Phonetic convergence, that is, the tendency for two speakers engaged in a conversational exchange to sound more like each other, is one important aspect of between-speaker adaptation. Empirical evidence has recently accumulated that shows that phonetic convergence is a recurrent phenomenon in mature speakers. This phenomenon relies on sensory-motor abilities that infants may already possess at birth. Phonetic convergence affects the way in which both speakers speak after their interaction has ended, and may build up over long periods of time. It may also be a driving mechanism in the acquisition of the phonology and phonetics of a second language. In this paper, (i) we outline the role of imitation in modern speech and language; (ii) we review the evidence provided by experimental and modeling studies for the potential role of imitation in the emergence and evolution of phonological systems; and (iii) we discuss how the resulting hypotheses could be tested in the framework provided by the multi-agent computational COSMO model."
}


@article{zuidema09,
title = "The evolution of combinatorial phonology",
journal = "Journal of Phonetics",
volume = "37",
number = "2",
pages = "125 - 144",
year = "2009",
issn = "0095-4470",
doi = "https://doi.org/10.1016/j.wocn.2008.10.003",
url = "http://www.sciencedirect.com/science/article/pii/S0095447008000624",
author = "Willem Zuidema and Bart de Boer",
abstract = "A fundamental, universal property of human language is that its phonology is combinatorial. That is, one can identify a set of basic, distinct units (phonemes, syllables) that can be productively combined in many different ways. In this paper, we develop a methodological framework based on evolutionary game theory for studying the evolutionary transition from holistic to combinatorial signal systems, and use it to evaluate a number of existing models and theories. We find that in all problematic linguistic assumptions are made or crucial components of evolutionary explanations are omitted. We present a novel model to investigate the hypothesis that combinatorial phonology results from optimizing signal systems for perceptual distinctiveness. Our model differs from previous models in three important respects. First, signals are modeled as trajectories through acoustic space; hence, both holistic and combinatorial signals have a temporal structure. Second, acoustic distinctiveness is defined in terms of the probability of confusion. Third, we show a path of ever increasing fitness from unstructured, holistic signals to structured signals that can be analyzed as combinatorial. On this path, every innovation represents an advantage even if no-one else in a population has yet obtained it."
}


@article{macken80, title={The acquisition of the voicing contrast in {E}nglish: a study of voice onset time in word-initial stop consonants}, volume={7}, DOI={10.1017/S0305000900007029}, number={1}, journal={Journal of Child Language}, publisher={Cambridge University Press}, author={Macken, Marlys A. and Barton, David}, year={1980}, pages={41-74}}


@inbook{ernestus11,
author = {Ernestus, Mirjam},
publisher = {American Cancer Society},
isbn = {9781444335262},
title = {Gradience and Categoricality in Phonological Theory},
booktitle = {The Blackwell Companion to Phonology},
chapter = {89},
pages = {1-22},
doi = {10.1002/9781444335262.wbctp0089},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781444335262.wbctp0089},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781444335262.wbctp0089},
year = {2011},
keywords = {phonology, functional grammar, generative grammar},
abstract = {Within phonological theory, important roles are assigned to the notions of “gradience” and “categoricality.” The opposition qualifies sounds and sound patterns, and is crucial both for the definition of the phonological and the phonetic components of generative grammar, and for the development of alternative types of grammatical models. This chapter discusses the assumptions generative phonology and its direct successors (including Optimality Theory) have made about the role of gradience. Moreover, it presents data supporting or contradicting these assumptions, and discusses new models accounting for the conflicting data.}
}

@article{ohala99,
title = "The influence of sonority on children's cluster reductions",
journal = "Journal of Communication Disorders",
volume = "32",
number = "6",
pages = "397 - 422",
year = "1999",
issn = "0021-9924",
doi = "https://doi.org/10.1016/S0021-9924(99)00018-0",
url = "http://www.sciencedirect.com/science/article/pii/S0021992499000180",
author = "Diane K Ohala",
keywords = "Language acquisition, Phonology, Phonological analysis",
abstract = "Two studies of consonant cluster reduction in children with normal language development were performed. Children ranged in age from 1;1 to 3;2. Both investigations tested a hypothesis of consonant cluster reduction based on the Sonority Theory. This hypothesis predicted that children would reduce clusters to whichever consonant would result in the least complex syllable as defined by sonority. More specifically, the hypothesis predicted that children would reduce initial clusters to whichever consonant produced the greatest rise in sonority and final clusters to whichever consonant produced a minimal sonority descent. Results of both studies support this sonority-driven account of cluster reduction."
}

@phdthesis{n13,
author = {Nov\'ak, L'ubom\'{\i}r},
school = {Charles University in Prague},
title = {Problem of archaism and innovation in the {Eastern I}ranian languages},
year = {2013},
}

@phdthesis{gerlach10,
author = { Gerlach, Sharon Ruth},
school = {University of Minnesota},
title = {The acquisition of consonant feature sequences: Harmony, metathesis and deletion patterns in phonological development},
year = {2010},
}






@unpublished{n14,
author = {Nov\'ak, L'ubom\'{\i}r},
title = {Historical phonology of {Yaghn\=ob\={\i} and S}ogdian},
year = {2014},
note={Ms., National Museum, Prague/ Charles University in Prague},
url = {10.13140/RG.2.2.19663.28326},
}

@incollection{begusCauc,
address = {Oxford},
author = {Ga\v{s}per Begu\v{s}},
booktitle = {The {O}xford Handbook of Languages of the {C}aucasus},
editor = {Maria Polinsky},
publisher = {Oxford University Press},
title = {Segmental phonetics and phonology},
year = {To appear},
note = {\url{faculty.washington.edu/begus/files/caucasian.pdf}  (accessed 9 Oct 2018)},
}


@incollection{o81,
address = {Chicago},
author = {Ohala, John J.},
booktitle = {Papers from the Parasession on Language and Behavior},
editor = {Carrie S. Masek and Roberta A. Hendrick and Mary Frances Miller},
pages = {178-203},
publisher = {Chicago Linguistic Society},
title = {The listener as a source of sound change},
year = {1981},
}

@incollection{o83,
address = {New York},
author = {Ohala, John J.},
booktitle = {The Production of Speech},
editor = {Peter F. MacNeilage},
pages = {189-216},
publisher = {Springer},
title = {The origin of sound patterns in vocal tract constraints},
year = {1983},
}

@incollection{o89,
address = {Berlin},
author = {Ohala, John J.},
booktitle = {Language Change: Contributions to the study of its causes},
editor = {L. E. Breivik and E. H. Jahr},
pages = {173-198},
publisher = {Mouton de Gruyter},
title = {Sound change is drawn from a pool of synchronic variation},
year="1989",
}

@incollection{o93,
address = {London},
author = {Ohala, John J.},
booktitle = {Historical Linguistics: Problems and Perspectives},
editor = {Charles Jones},
pages = {237-278},
publisher = {Longman},
title = {The phonetics of sound change},
year = {1993},
}

@article{fruehwald17,
author = {Fruehwald, Josef },
title = {The Role of Phonology in Phonetic Change},
journal = {Annual Review of Linguistics},
volume = {3},
number = {1},
pages = {25-42},
year = {2017},
doi = {10.1146/annurev-linguistics-011516-034101},

URL = { 
        https://doi.org/10.1146/annurev-linguistics-011516-034101
    
},
eprint = { 
        https://doi.org/10.1146/annurev-linguistics-011516-034101
    
}
,
    abstract = { This article reviews the role phonology plays in phonetic changes. After first establishing what kinds of changes qualify as phonetic changes for the purposes of discussion, and laying out the theoretical outlook that is adopted here, I review the most obvious cases in which phonology plays a role in phonetic change. These include (a) the way phonological contrast can lead to phonetic dispersion, (b) the way phonological natural classes can define a set of segments to undergo a parallel phonetic shift, and (c) how phonological biases may lead to instances of underphonologization. Throughout, I discuss alternative approaches to these phenomena. }
}


@article{smith97,
title = "The devoicing of /z/ in {American English}: Effects of local and prosodic context",
journal = "Journal of Phonetics",
volume = "25",
number = "4",
pages = "471 - 500",
year = "1997",
issn = "0095-4470",
doi = "https://doi.org/10.1006/jpho.1997.0053",
url = "http://www.sciencedirect.com/science/article/pii/S009544709790053X",
author = "Caroline L. Smith",
abstract = "Voiced fricatives are often taken as an example of sound that is ‘difficult’ to produce. It might therefore be expected that speakers would choose to simplify them. In English, the most common simplification is devoicing, especially for voiced sibilants. The nature of this process was examined in productions of /z/ and /s/ by four speakers of American English. These were recorded in matched word and phrase positions using acoustic, airflow, and electroglottographic (EGG) data. Although many tokens of /z/ showed little or no vocal fold vibration in the EGG signal, durational and aerodynamic differences maintained the distinction between /z/ and /s/. The speakers varied in overall frequency of devoicing, but showed similar rank orderings for frequency of devoicing in different contexts. Devoicing was most frequent in two kinds of environments: those where it could be viewed as assimilation to an adjacent voiceless context, and those where articulatory and aerodynamic effort tends to be reduced. These contexts (unstressed syllables, and ends of words or phrases) have been shown to favor other kinds of prosodically-structured lenition."
}



@inproceedings{o97,
address = {Seoul},
author = {Ohala, John J.},
booktitle = {{Proceedings of the 4th {S}eoul International Conference on Linguistics ({SICOL})}},
pages = {84-91},
publisher = {Linguistic Society of Korea},
title = {Emergent stops},
year = {1997},
}


@inproceedings{ohala97,
address = {Seoul},
author = {Ohala, John J.},
booktitle = {{Proceedings of the 4th {S}eoul International Conference on Linguistics ({SICOL})}},
pages = {84-91},
publisher = {Linguistic Society of Korea},
title = {Aerodynamics of phonology},
year = {1997},
}

@Article{betareg,
    title = {Extended Beta Regression in {R}: Shaken, Stirred, Mixed, and Partitioned},
    author = {Bettina Gr\"un and Ioannis Kosmidis and Achim Zeileis},
    journal = {Journal of Statistical Software},
    year = {2012},
    volume = {48},
    number = {11},
    pages = {1--25},
    url = {http://www.jstatsoft.org/v48/i11/},
  }
  

@ARTICLE{lillicrap19,
       author = {{Lillicrap}, Timothy P. and {Kording}, Konrad P.},
        title = "{What does it mean to understand a neural network?}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Quantitative Biology - Neurons and Cognition, Statistics - Machine Learning},
         year = "2019",
        month = "Jul",
          eid = {arXiv:1907.06374},
        pages = {arXiv:1907.06374},
archivePrefix = {arXiv},
       eprint = {1907.06374},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190706374L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@inproceedings{avcu18,
address = {Somerville, MA},
author = {Avcu, Enes},
editor={William G. Bennett and Lindsay Hracs and Dennis Ryan Storoshenko},
booktitle = {{Proceedings of the 35th West Coast Conference on Formal Linguistics}},
pages = {77-86},
publisher = {Cascadilla},
title = {Experimental investigation of the {Subregular Hypothesis}},
year = {2018},
}



@incollection{o06,
address = {Oxford},
author = {Ohala, John J.},
booktitle = {Encyclopedia of Language \& Linguistics},
editor = {Keith Brown},
note = {Second Edition},
pages = {684-689},
publisher = {Elsevier},
title = {Speech aerodynamics},
year = {2006},
}

@article{ohala11,
author = {Ohala, John J.},
journal = {{Proceedings of the 17th International Congress of Phonetic Sciences}},
pages = {64-67},
title = {Accommodation to the aerodynamic voicing constraint and its phonological relevance},
volume = {17},
year = {2011},
}

@incollection{or79,
address = {New York},
author = {Ohala, John J. and Carol J. Riordan},
booktitle = {Speech Communication Papers},
editor = {J. J. Wolf and D. H. Klatt},
pages = {89-92},
publisher = {Acoustical Society of America},
title = {Passive vocal tract enlargement during voiced stops},
year = {1979},
}

@incollection{oo93,
address = {San Diego, CA},
author = {Ohala, John J. and Manjari Ohala},
booktitle = {Nasals, Nasalization, and the Velum},
editor = {Marie K. Huffman and Rena A. Krakow},
pages = {225-249},
publisher = {Academic Press},
title = {The phonetics of nasal phonology: Theorems and data},
year = {1993},
}

@book{o11,
address = {Munich},
author = {Onishi, Masayuki},
publisher = {Lincom Europa},
title = {A grammar of {M}otuna},
year = {2011},
}

@incollection{p99,
address = {Cambridge},
author = {Pater, Joe},
booktitle = {The Prosody-Morphology Interface},
editor = {Ren\'e Kager and  Harry van der Hulst and Wim Zonneveld},
pages = {310-343},
publisher = {Cambridge University Press},
title = {Austronesian nasal substitution and other {NC} effects},
year = {1999},
}


@incollection{pater04,
address = {Malden, MA},
author = {Pater, Joe},
booktitle = {Optimality Theory in Phonology: A Reader},
editor = {John J. McCarthy},
pages = {271-289},
publisher = {Blackwell},
title = {Austronesian nasal substitution and other {N\textsubring{C}} effects},
year = {2004},
}

@incollection{pt06,
address = {Amsterdam},
author = {Pater, Joe and Anne-Michelle Tessier},
booktitle = {Inquiries in linguistic development: Studies in honor of {Lydia White}},
editor = {Roumyana Slabakova and Silvina A. Montrul and Philippe Pr\'evost},
pages = {115-131},
publisher = {Benjamins},
title = {L1 phonotactic knowledge and the L2 acquisition of alternations},
year = {2006},
}

@incollection{pamtt10,
author = {Paul, Daniel and Elisabeth Abbess and Katja M\"uller and Calvin Tiessen and Gabriela Tiessen},
booktitle = {{SIL Electronic Survey Report} 2010-017, {M}ay 2010},
note = {\url{www-01.sil.org/silesr/2010/silesr2010-017.pdf} (accessed 23 August 2017)},
publisher = {SIL International.},
title = {The ethnolinguistic vitality of {Y}aghnobi},
year = {2010},

}

@book{p94,
address = {Montreal},
author = {Picard, Marc},
publisher = {McGill-Queen's University Press},
title = {Principles and Methods in Historical Phonology: From {Proto-Algonkian to Arapaho}},
year = {1994},
}

@incollection{p01,
address = {Amsterdam},
author = {Pierrehumbert, Janet},
booktitle = {Frequency Effects and the Emergence of Lexical Structure},
editor = {Joan L. Bybee and Paul J. Hopper},
pages = {137-157},
publisher = {John Benjamins},
title = {Exemplar dynamics: Word frequency, lenition, and contrast},
year = {2001},
}

@inproceedings{schijndel19,
    title = "Quantity doesn{'}t buy quality syntax with neural language models",
    author = "van Schijndel, Marten  and
      Mueller, Aaron  and
      Linzen, Tal",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1592",
    doi = "10.18653/v1/D19-1592",
    pages = "5831--5837",
    abstract = "Recurrent neural networks can learn to predict upcoming words remarkably well on average; in syntactically complex contexts, however, they often assign unexpectedly high probabilities to ungrammatical words. We investigate to what extent these shortcomings can be mitigated by increasing the size of the network and the corpus on which it is trained. We find that gains from increasing network size are minimal beyond a certain point. Likewise, expanding the training corpus yields diminishing returns; we estimate that the training corpus would need to be unrealistically large for the models to match human performance. A comparison to GPT and BERT, Transformer-based models trained on billions of words, reveals that these models perform even more poorly than our LSTMs in some constructions. Our results make the case for more data efficient architectures.",
}

@article{velde96, title={The devoicing of fricatives in Standard Dutch: A real-time study based on radio recordings}, volume={8}, DOI={10.1017/S0954394500001125}, number={2}, journal={Language Variation and Change}, publisher={Cambridge University Press}, author={van de Velde, Hans and Gerritsen, Marinel and van Hout, Roeland}, year={1996}, pages={149–175}}


@book{ladefoged03,
  title={Phonetic Data Analysis: An Introduction to Fieldwork and Instrumental Techniques},
  address={Malden, MA},
  author={Peter Ladefoged},
  year={2003},
  publisher={Blackwell}
}


@book{ps93,
address = {Malden, MA},
author = {Prince, Alan and Paul Smolensky},
note = {First published in Tech. Rep. 2, Rutgers University Center for Cognitive Science},
publisher = {Blackwell},
title = {{Optimality Theory}: Constraint Interaction in Generative Grammar},
year = {1993/2004},
}

@article{lacy06a,
 author = "de Lacy, Paul",
 title = "Transmissibility and the role of the phonological component: {A} theoretical synopsis of {Evolutionary} {Phonology}",
 journal = "Theoretical Linguistics",
 volume = "32",
 number="2",
 year = "2006",
 doi="10.1515/TL.2006.012",
 pages={185-196}
}


@phdthesis{p13,
author = {Pucilowski, Anna},
school = {University of Oregon},
title = {Topics in Ho Morphophonology and Morphosyntax},
year = {2013},
}

@phdthesis{d02,
author = {de Lacy, Paul},
school = {University of Massachusetts,  Amherst},
title = {The formal expression of markedness},
year = {2002},
}



@book{pb77,
address = {Lima},
author = {Puente Baldoceda, Blas},
publisher = {Universidad Nacional Mayor de San Marcos, Centro de Investigaci\'on de Ling\"u\'\i stica Aplicada},
title = {Fonolog\'\i a del quechua tarme\~no},
year = {1977},
}

@article{p76,
author = {Pullum, Geoffrey K.},
journal = {Journal of Linguistics},
pages = {83-102},
title = {The Duke of York gambit},
volume = {12},
year = {1976},
}

@article{r12,
author = {Recasens, Daniel},
journal = {Journal of the International Phonetic Association},
number = {1},
pages = {65-90},
title = {The phonetic implementation of underlying and epenthetic stops in word final clusters in {Valencian C}atalan},
volume = {42},
year = {2012},
}

@book{rrnr06,
address = {Kuching, Sarawak},
author = {Rensch, Calvin R. and Carolyn M. Rensch and Jonas Noeb and Robert S. Ridu},
publisher = {Dayak Bidayuh National Association},
title = {The {B}idayuh language: Yesterday, today, and tomorrow},
year = {2006},
}

@incollection{r49,
address = {Bern},
author = {Rohlfs, Gerhard},
booktitle = {{Historische Grammatik der Italienischen Sprache und ihrer Mundarten}},
note = {Volume 1},
publisher = {Francke},
title = {Lautlehre},
year = {1949},
}

@book{r68,
address = {Basel},
author = {Rothenberg, Martin},
publisher = {S. Karger},
title = {The Breath-Stream Dynamics of Simple-Released-Plosive Production},
year = {1968},
}

@book{r75,
address = {Stanford, CA},
author = {Ruhlen, Merritt},
publisher = {Language Universals Project},
title = {A Guide to Languages of the World},
year = {1975},
}

@book{s96,
address = {Paris},
author = {Santos, Rosine},
publisher = {Universit\'e Paris III},
title = {Le Mey: langue ouest-atlantique de {G}uin\'ee},
year = {1996},
}

@incollection{s87,
address = {Wiesbaden},
author = {Sims-Williams, Nicholas},
booktitle = {Compendium Linguarum Iranicarum},
editor = {R\"udiger Schmitt},
pages = {173-192},
publisher = {Ludwig Reichert Verlag},
title = {Sogdian},
year = {1987},
}

@book{s83,
address = {Moscow},
author = {Sirk, \"Ulo},
publisher = {Nauka},
title = {The {B}uginese Language},
year = {1983},
}

@incollection{s07,
address = {Oxford},
author = {Sol\'e, Maria-Josep},
booktitle = {Experimental Approaches to Phonology},
editor = {Maria-Josep Sol\'e and Patrice Beddor},
pages = {302-321},
publisher = {Oxford University Press},
title = {Controlled and mechanical properties in speech: A review of the literature},
year = {2007},
}

@incollection{s12,
address = {Amsterdam},
author = {Sol\'e, Maria-Josep},
booktitle = {The Initiation of Sound Change: Perception, Production, and Social Factors},
editor = {Maria-Josep Sol\'e and Daniel Recasens},
pages = {123-145},
publisher = {John Benjamins},
title = {Natural and unnatural patterns of sound change?},
year = {2012},
}

@article{shm10,
author = {Sol\'e, Maria-Josep and Larry M. Hyman and Kemmonye C. Monaka},
journal = {Journal of Phonetics},
number = {4},
pages = {299-319},
title = {More on post-nasal devoicing: The case of {S}hekgalagari},
volume = {38},
year = {2010},
}

@phdthesis{s73,
author = {Stampe, David},
school = {University of Chicago},
title = {A Dissertation on Natural Phonology},
year = {1973},
}

@article{s16a,
author = {Stanton, Juliet},
journal = {Natural Language \& Linguistic Theory},
number = {3},
pages = {1089-1133},
title = {Predicting distributional restrictions on prenasalized stops},
volume = {34},
year = {2016},
}



@inproceedings{s16b,
address = {Amherst, MA},
author = {Stanton, Juliet},
booktitle = {{Proceedings of the 46th {M}eeting of the {North East Linguistic Society}}},
editor = {Christopher Hammerly and Brandon Prickett},
note = {Volume 3},
pages = {193-206},
publisher = {GLSA},
title = {Effects of allophonic vowel nasalization on {NC} clusters: A contrast-based analysis},
year = {2016},
}

@article{s18a,
author = {Stanton, Juliet},
journal = {Phonology},
pages = {39-78},
title = {Environmental shielding is contrast preservation},
volume = {35},
year = {2018},
}

@unpublished{s18b,
author = {Stanton, Juliet},
note = {Ms., New York University},
title = {Constraints on contrast motivate nasal cluster dissimilation},
year = {2018},
}

@article{sj12,
author = {Stausland Johnsen, Sverre},
journal = {Phonology},
pages = {505-531},
title = {A diachronic account of phonological unnaturalness},
volume = {29},
year = {2012},
}

@incollection{s93,
address = {San Diego},
author = {Steriade, Donca},
booktitle = {Phonetics and Phonology. Volume 5: Nasals, Nasalization, and the Velum},
editor = {Marie K. Huffman and Rena A. Krakow},
pages = {401-470},
publisher = {Academic Press},
title = {Closure, release, and nasal contours},
year = {1993},
}

@unpublished{steriade01,
title = {The Phonology of Perceptibility Effects: The {P-map} and its Consequences for Constraint Organization},
year = "2001",
author = {Donca Steriade},
note = {Ms., University of California, Los Angeles},
}

@unpublished{s97,
author = {Steriade, Donca},
note = {Ms., University of California, Los Angeles},
title = {Phonetics in phonology: The case of laryngeal neutralization},
year = {1997},
}

@book{ts00,
address = {Cambridge, MA},
author = {Tesar, Bruce and Paul Smolensky},
publisher = {Massachusetts Institute of Technology Press},
title = {Learnability in {Optimality Theory}},
year = {2000},
}

@unpublished{v14,
author = {Valls, David},
title = {A grammar sketch of the {B}ugis language},
year = {2014},
note = {Ms. \url{www.academia.edu/23400897/A_grammar_sketch_of_the_Bugis_language} (accessed 31 August 2017)},
}

@article{w68,
author = {Wang, William S-y.},
journal = {Language},
number = {4},
pages = {695-708},
title = {Vowel features, paired variables, and the {E}nglish vowel shift},
volume = {44},
year = {1968},
}

@article{ww01,
author = {Warner, Natasha and Andrea Weber},
journal = {Journal of Phonetics},
number = {1},
pages = {53-87},
title = {Perception of epenthetic stops},
volume = {29},
year = {2001},
}

@article{w12,
author = {Wedel, Andrew},
journal = {Language and Cognition},
number = {4},
pages = {319-355},
title = {Lexical contrast maintenance and the organization of sublexical contrast systems},
volume = {4},
year = {2012},
}

@article{wedel06,
author = {Wedel, Andrew},
journal = {The Linguistic Review},
number = {3},
pages = {247--274},
title = {Exemplar models, evolution and language change},
volume = {23},
year = {2006},
doi={10.1515/TLR.2006.010},
url={https://www.degruyter.com/view/j/tlir.2006.23.issue-3/tlr.2006.010/tlr.2006.010.xml}
}


@article{wkj13,
author = {Wedel, Andrew and Abby Kaplan and Scott Jackson},
journal = {Cognition},
number = {2},
pages = {179-186},
title = {High functional load inhibits phonological contrast loss: A corpus study},
volume = {128},
year = {2013},
}

@article{wk86,
author = {Westbury, John R. and Patricia A. Keating},
journal = {Journal of Linguistics},
number = {1},
pages = {145-166},
title = {On the naturalness of stop consonant voicing},
volume = {22},
year = {1986},
}

@article{white14,
title = "Evidence for a learning bias against saltatory phonological alternations",
journal = "Cognition",
volume = "130",
number = "1",
pages = "96 - 115",
year = "2014",
issn = "0010-0277",
doi = "https://doi.org/10.1016/j.cognition.2013.09.008",
url = "http://www.sciencedirect.com/science/article/pii/S0010027713001923",
author = "James White",
}

@article{w37,
author = {Whatmough, Joshua},
journal = {Acta Jutlandica},
pages = {45-56},
title = {The development of {Indo-European} labiovelars},
volume = {9},
year = {1937},
}

@phdthesis{w13,
author = {White, James},
school = {UCLA},
title = {Bias in phonological learning: Evidence from saltation},
year = {2013},
}


@article{wh13,
author = {Hayes, Bruce and White, James},
title = {Phonological Naturalness and Phonotactic Learning},
journal = {Linguistic Inquiry},
volume = {44},
number = {1},
pages = {45-75},
year = {2013},
doi = {10.1162/LING\_a\_00119},
    abstract = { We investigate whether the patterns of phonotactic well-formedness internalized by language learners are direct reflections of the phonological patterns they encounter, or reflect in addition principles of phonological naturalness. We employed the phonotactic learning system of Hayes and Wilson (2008) to search the English lexicon for phonotactic generalizations and found that it learned many constraints that are evidently unnatural, having no typological or phonetic basis. We tested 10 such constraints by obtaining native-speaker ratings of 40 nonce words: 10 violated our unnatural constraints, 10 violated natural constraints assigned comparable weights by the learner, and 20 were control forms. Violations of the natural constraints had a powerful effect on ratings, violations of the unnatural constraints at best a weak one. We assess various hypotheses intended to explain this disparity, and conclude in favor of a learning bias account. }
}



@phdthesis{begusDiss,
author = {Ga\v{s}per Begu\v{s}},
school = {Harvard University},
title = {Unnatural phonology: A synchrony-diachrony interface approach},
year = {2018},
}



@article{w17,
author = {White, James},
journal = {Language},
number = {1},
pages = {1-36},
title = {Accounting for the learnability of saltation in phonological theory: A maximum entropy model with a {P}-map bias},
volume = {93},
year = {2017},
}

@article{w06,
author = {Wilson, Colin},
journal = {Cognitive Science},
pages = {945-982},
title = {Learning Phonology with Substantive Bias: An Experimental and Computational Study of Velar Palatalization},
volume = {30},
year = {2006},
}

@book{x72,
address = {Moscow},
author = {Xromov, Al'bert},
publisher = {Nauka},
title = {Jagnobskij jazyk},
year = {1972},
}

@incollection{x87,
author = {Xromov, Al'bert},
booktitle = {Osnovy iranskogo jazykoznanija: Novoiranskie jazyki: vosto\v{c}naja gruppa},
pages = {644-701},
publisher = {Moscow: Nauka},
title = {Jagnobskij jazyk},
year = {1987},
}

@article{yb03,
author = {Yoo, Isaiah WonHo and Barbara Blankenship},
journal = {Journal of the International Phonetic Association},
number = {2},
pages = {153-164},
title = {Duration of epenthetic [t] in polysyllabic {A}merican {E}nglish words},
volume = {33},
year = {2003},
}

@incollection{y16,
author = {Yoshida, Yutaka},
booktitle = {Encyclop{\ae}dia Iranica},
publisher = {Online edition},
title = {Sogdian language: i. Description},
year = {2016},
note = {\url{www.iranicaonline.org/articles/sogdian-language-01} (accessed 11 November 2016)},
}

@article{y04,
author = {Yu, Alan C. L.},
journal = {Language},
pages = {73-97},
title = {Explaining final obstruent voicing in {L}ezgian: Phonetics and history},
volume = {80},
year = {2004},
}

@article{yu11,
 ISSN = {09526757, 14698188},
 URL = {http://www.jstor.org/stable/41475374},
 abstract = {Much debate in recent years has focused on the relative contribution of analytic and channel biases in shaping the typology of sound. Moretón (2008) argues forcefully for the strength of analytic bias, such as Universal Grammar and other non-modality-specific cognitive biases that facilitate the learning of some phonological patterns and inhibit that of others, in creating typological asymmetries on its own, unassisted by the robustness of phonetic precursors. This article focuses on the assessment of phonetic precursor robustness. The main goal of this article is two-fold: (i) to establish the inadequacy of Moreton's method of evaluating relative phonetic precursor robustness and to offer an alternative to his approach ; (ii) to report the results of a cross-linguistic study comparing the nature of vowel-to-vowel coarticulation and the interaction between obstruent voicing and vowel height with the same languages -no previous studies have directly compared these two phonetic precursors.},
 author = {Alan C. L. Yu},
 journal = {Phonology},
 number = {3},
 pages = {491--518},
 publisher = {Cambridge University Press},
 title = {On measuring phonetic precursor robustness : a response to {Moreton}},
 volume = {28},
 year = {2011}
}





@incollection{zgt06,
address = {Amherst, MA},
author = {Zsiga, Elizabeth and Maria Gouskova and One Tlale},
booktitle = {{Proceedings of the 36th {A}nnual {M}eeting of the {North East Linguistic Society}}},
editor = {Christopher Davis and Amy Rose},
pages = {721-734},
publisher = {GLSA},
title = {On the status of voiced stops in {T}swana: Against *{ND}},
year = {2006},
}


@InProceedings{zeiler14,
author="Zeiler, Matthew D.
and Fergus, Rob",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Visualizing and Understanding Convolutional Networks",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="818--833",
abstract="Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.",
isbn="978-3-319-10590-1"
}


@article{chowdhury20,
  title={{DeepVOX}: Discovering Features from Raw Audio for Speaker Recognition in Degraded Audio Signals},
  author={Anurag Chowdhury and A. A. Ross},
  journal={ArXiv},
  year={2020},
  volume={abs/2008.11668}
}

@article{krug19,
  title={Visualizing Deep Neural Networks for Speech Recognition with Learned Topographic Filter Maps},
  author={Andreas Krug and Sebastian Stober},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.04067}
}


@article{ravanelli19,
  title={Interpretable Convolutional Filters with {SincNet}},
  author={Mirco Ravanelli and Yoshua Bengio},
  journal={ArXiv},
  year={2018},
  volume={abs/1811.09725}
}


@inproceedings{golik15,
  title={Convolutional neural networks for acoustic modeling of raw time signal in {LVCSR}},
  author={Pavel Golik and Z. T{\"u}ske and R. Schl{\"u}ter and H. Ney},
  booktitle={Interspeech},
  year={2015},
  pages={26-30,}
}


@article{millet21,
  title={Inductive biases, pretraining and fine-tuning jointly account for brain responses to speech},
  author={Juliette Millet and J. R. King},
  journal={ArXiv},
  year={2021},
  volume={abs/2103.01032}
}

@inproceedings{belinkov17,
author = {Belinkov, Yonatan and Glass, James},
title = {Analyzing Hidden Representations in End-to-End Automatic Speech Recognition Systems},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Neural networks have become ubiquitous in automatic speech recognition systems. While
neural networks are typically used as acoustic models in more complex systems, recent
studies have explored end-to-end speech recognition systems based on neural networks,
which can be trained to directly predict text from input acoustic features. Although
such systems are conceptually elegant and simpler than traditional systems, it is
less obvious how to interpret the trained models.In this work, we analyze the speech
representations learned by a deep end-to-end model that is based on convolutional
and recurrent layers, and trained with a connectionist temporal classification (CTC)
loss. We use a pre-trained model to generate frame-level features which are given
to a classifier that is trained on frame classification into phones. We evaluate representations
from different layers of the deep model and compare their quality for predicting phone
labels. Our experiments shed light on important aspects of the end-to-end model such
as layer depth, model complexity, and other design choices.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {2438–2448},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@article{Schulz08,
  title={Overlapping and matching of codas in vocal interactions between sperm whales: Insights into communication function},
  author={Schulz, T.M. and Hal Whitehead and Shane Gero and Luke Rendell},
  journal={Animal Behaviour},
  year={2008},
  volume={76},
  pages={1977-1988}
}

@article{Watkins77,
  title={Sperm whale codas},
  author={Watkins, W.A. and Schevill, W.E.},
  journal={Animal Behaviour},
  year={1977},
  volume={62},
  pages={1485-1490,}
}

@article{Rendell2003,
  title={Vocal clans in sperm whales (Physeter macrocephalus)},
  author={Rendell, L.E. and Hal Whitehead},
  journal={Proceedings of the Royal Society of London. Series B: Biological Sciences},
  year={2003},
  volume={270},
  pages={225-231,}
}

@article{Hersh2022,
  title={Evidence from sperm whale clans of symbolic marking in non-human cultures},
  author={Hersh, Taylor A. and Shane Gero and Luke Rendell and Maurício Cantor and Lindy Weilgart and Masao Amano and Stephen M. Dawson and Elisabeth Slooten and Christopher M. Johnson and Iain Kerr and Roger Payne and Andy Rogan and Ricardo Antunes and Olive Andrews and Elizabeth L. Ferguson and Cory Ann Hom-Weaver and Thomas F. Norris and Yvonne M. Barkley and Karlina P. Merkens and Erin M. Oleson and Thomas Doniol-Valcroze and James F. Pilkington and Jonathan Gordon and Manuel Fernandes and Marta Guerra and Leigh Hickmott and Hal Whitehead},
  journal={Proceedings of the National Academy of Sciences},
  year={2022},
  volume={119},
  pages={e2201692119,}
}

@article{Rendell2012,
  title={Can genetic differences explain vocal dialect variation in sperm whales, Physeter macrocephalus?},
  author={Rendell, Luke E. and Sarah L. Mesnick and Merel L. Dalebout and Jessica Burtenshaw and Hal Whitehead},
  journal={Behavior Genetics},
  year={2012},
  volume={42},
  pages={332-343,}
}

@book{CulturalLives,
address = {Chicago},
author = {Whitehead, Hal and Luke Rendell},
publisher = {University of Chicago Press},
title = {The cultural lives of whales and dolphins},
year = {2014},
}

@article{madsen23,
author = {Peter T. Madsen  and Ursula Siebert  and Coen P. H. Elemans },
title = {Toothed whales use distinct vocal registers for echolocation and communication},
journal = {Science},
volume = {379},
number = {6635},
pages = {928-933},
year = {2023},
doi = {10.1126/science.adc9570},
URL = {https://www.science.org/doi/abs/10.1126/science.adc9570},
eprint = {https://www.science.org/doi/pdf/10.1126/science.adc9570},
abstract = {Echolocating toothed whales (odontocetes) capture fast-moving prey in dark marine environments, which critically depends on their ability to generate powerful, ultrasonic clicks. How their supposedly air-driven sound source can produce biosonar clicks at depths of \&gt;1000 meters, while also producing rich vocal repertoires to mediate complex social communication, remains unknown. We show that odontocetes possess a sound production system based on air driven through nasal passages that is functionally analogous to laryngeal and syringeal sound production. Tissue vibration in different registers produces distinct echolocation and communication signals across all major odontocete clades, and thus provides a physiological basis for classifying their vocal repertoires. The vocal fry register is used by species from porpoises to sperm whales for generating powerful, highly air-efficient echolocation clicks. Odontocete (“toothed”) whales are well known for using echolocation to forage underwater, but they also produce a wide array of sounds used for social communication. Precisely how all of these sounds are produced was characterized by Madsen et al. in living animals (see the Perspective by Ravignani and Herbst). The authors found that the wide array of sounds are produced through the nasal passages but in a way analogous to laryngeal and syringeal sound production. Using the nasal passages facilitates complex sound production at depth, where laryngeal sound would be hampered by pressure. Furthermore, they found that odontocetes use different vocal registers, such as those we associate with falsetto or vocal fry in humans, to convey information. —SNV A nasal sound source operates at different vocal registers for biosonar-based prey capture from porpoises to sperm whales.}}


@article{Whitehead1991,
  title={Patterns of visually observable behavior and vocalizations in groups of female sperm whales},
  author={Whitehead, Hal and Lindy Weilgart},
  journal={Behaviour},
  year={1991},
  volume={118},
  pages={332-343,}
}

@article{Madsen2002,
  title={Sperm whale sound production studied with ultrasound-time-depth-recording tags},
  author={Madsen, Peter T. and Roger Payne and N.U. Kristiansen and Iain Kerr and Bertle M\o{}hl},
  journal={Journal of Experimental Biology},
  year={2002},
  volume={205},
  pages={1899-1906,}
}

@article{Dtag2003,
  title={A digital acoustic recording tag for measuring the response of wild marine mammals to sound},
  author={Johnson, Mark P. and Peter L. Tyack},
  journal={IEEE Journal of Oceanic Engineering},
  year={2003},
  volume={28},
  pages={3-12,}
}

@article{Gero2014,
  title={Behavior and social structure of the sperm whales of Dominica, West Indies},
  author={Gero, Shane and Marina Milligan and Caroline Rinaldi and Pernell Francis and Jonathan Gordon and Carole Carlson and Andrea Steffen and Peter Tyack and Peter Evans and and Hal Whitehead},
  journal={Marine Mammal Science},
  year={2003},
  volume={30},
  pages={905-922,}
}


@article{Gero2016clans,
  title={Socially segregated, sympatric sperm whale clans in the Atlantic Ocean},
  author={Gero, Shane and Anne Bøttcher and Hal Whitehead and and Peter Teglberg Madsen},
  journal={Royal Society Open Science},
  year={2016},
  volume={3},
  pages={160061,}
}

