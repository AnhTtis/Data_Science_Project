\beginsupp

\noindent
{\Large {\textbf{Supplementary materials}}}
\\

We present 
empirical validation about the classifier weights biased on discriminative dimensions in Section~\ref{sec:bias},
the impact of different clustering and similarity methods in Section~\ref{sec:similarity},
the analysis on the number of samples in clustering in Section~\ref{sec:num_samples},
ablation study on the MS~COCO dataset in Section~\ref{sec:ablation} supplementing for Table~\ref{table_ablation} (main paper), 
Sensitivity analysis on VOC in Section~\ref{sec:sensitivity} supplementing for Figure~\ref{fig_sensitivity} (main paper), and more qualitative results in Section~\ref{sec:qualitative} supplementing for Figure~\ref{fig_vis} (main paper).


\section{Biased Classifier}
\label{sec:bias}
\begin{figure}[ht]
\begin{center}
\includegraphics[width=0.46\textwidth]{figures/figure_bias.pdf}
\end{center}
  \caption{Empirical validation about the classifier weights biased on discriminative dimensions. We show the indices of the top 10 dimensions with the highest value for local region features ($f(\bm{x_1)}$: ``head'' and $f(\bm{x_2})$: ``tail'') and the classifier weight of ``bird'' ($\mathbf{w}_{bird}$).}
\label{fig:bias}
\end{figure}
We empirically validate that the classifier weights biased on the discriminative dimensions. This is to supplement for Section~\ref{sec_justfication} in the main paper.

In Figure~\ref{fig:bias} We show the indices of the top 10 dimensions with the highest value for local region features ($f(\bm{x_1)}$: ``head'' and $f(\bm{x_2})$: ``tail'') and the classifier weight of ``bird'' ($\mathbf{w}_{bird}$). The number of overlap dimensions between $\mathbf{w}_{bird}$ and $f(\bm{x_1)}$ is 8, but only 2 between $\mathbf{w}_{bird}$ and $f(\bm{x_2})$. This validate that the classifier weight of ``bird'' ($\mathbf{w}_{bird}$) biased on the dimensions of discriminative feature ``head''.


\section{Impact of clustering and similarity methods}
\label{sec:similarity}
We study the impact of different clustering and similarity methods.
1)~For clustering, we use K-Means and Hierarchical clustering. 
On VOC, the seed mask quality (mIoU) of Hierarchical clustering is 55.1\% (slightly higher than the 54.9\% of K-Means in Table~\ref{table_plugin}), but the running time is around 5 times longer.
2)~For similarity, we evaluate Euclidean and Cosine similarities in K-Means. The seed mask quality (mIoU) of using Euclidean on VOC dataset is 54.4\%, which is close to that of Cosine (54.9\% in Table~\ref{table_plugin}).

\section{Number of samples in clustering}
\label{sec:num_samples}
\begin{wrapfigure}{r}{4.5cm}
    \vspace{-1mm}
    \centering
    \includegraphics[width=0.9\linewidth]{figures/figure_samples.pdf}
    \caption{The seed mask quality (mIoU) of LPCAM regarding the number of images per class on MS~COCO.}
    \label{fig:samples}
    \vspace{-4mm}
\end{wrapfigure}
As mentioned in Section~\ref{sec_datasets} of the main paper: for k-Means clustering on MS~COCO, we sample $100$ images per class, rather than using the whole dataset of each class (to control the time costs for clustering). Here We study the impact of the number of images per class on the seed mask quality (mIoU) of LPCAM and show the results in Figure~\ref{fig:samples}. There is little performance gain after $100$. The possible reason is that for the common object on MS~COCO, $100$ samples can cover the variants of local features in the class.


\section{Ablation Study on MS~COCO}
\label{sec:ablation}

\setlength{\tabcolsep}{2.2mm}{
\renewcommand\arraystretch{1.1}
\begin{table}[ht]
    \centering
    \scalebox{0.8}{
      \begin{tabular}{lccccc}
        \toprule
                      & FP    & FN    & mIoU  & Prec. & Recall\\ 
        \midrule
        \texttt{CAM}          & 45.7                   & 21.9                   & 33.1                   & 43.8                   & 64.6  \\
        \texttt{LPCAM-F}      & 49.7\scriptsize{+4.0}  & 16.9\scriptsize{-5.0}  & 33.9\scriptsize{+0.8}  & 42.2\scriptsize{-1.6}  & 68.5\scriptsize{+3.9}  \\
        \texttt{LPCAM}        & 43.5\scriptsize{-2.2}  & 21.2\scriptsize{-0.7}  & 35.4\scriptsize{+2.3}  & 47.1\scriptsize{+3.3}  & 64.7\scriptsize{+0.1}  \\
        \bottomrule
      \end{tabular}
    }
    \caption{An ablation study on MS~COCO dataset. ``-F'' denotes only the ``Foreground'' term $\bm{FG}_n$ is used in Eq.~\ref{eq:LPCAM} (main paper).}
    \label{table_ablation_coco}
\end{table}
}

We conduct an ablation study on the MS~COCO dataset to evaluate the two terms of LPCAM in Eq.~\ref{eq:LPCAM} (main paper): foreground term $\bm{FG}_n$ and background term $\bm{BG}_n$ that accord to class and context prototypes, respectively. This is to supplement for Table~\ref{table_ablation} in the main paper. In Table~\ref{table_ablation_coco}, we show the mIoU results (of seed masks), false positive (FP), false negative (FN), precision, and recall. We can see that our method of using class prototypes (LPCAM-F) greatly improve the recalls---$3.9\%$ higher than CAM, and thus reduces the rates of FN a lot. This validates the ability of our methods to capture non-discriminative regions of the image. We also notice that LPCAM-F increases the rate of FP over CAM. The reason is that confusing context features (e.g., ``railroad'' for ``train'') may be wrongly taken as class features. Fortunately, when we explicitly resolve this issue by applying the negative context term $-\bm{BG}_n$ in LPCAM, this rate can be reduced (by $6.2\%$ for MS~COCO), and the overall performance (mIoU) can be improved (by $1.5\%$ for MS~COCO).  


\begin{figure}[ht]
    \begin{center}
    \includegraphics[width=0.47\textwidth]{figures/figure_sensitivity_mscoco.pdf}
    \end{center}
    \caption{Sensitivity analysis on MS~COCO, in terms of (a) $\tau$ for dividing foreground and background local features, (b) $\mu_f$ for selecting class prototypes and $\mu_b$ for selecting context prototypes, (c) the number of clusters $K$ in k-Means, and (d) the threshold used to generate 0-1 seed masks from heatmaps.}
    \label{fig:sensitivity_mscoco}
\end{figure}
\section{Sensitivity Analysis on MS~COCO}
\label{sec:sensitivity}
In Figure~\ref{fig:sensitivity_mscoco}, we show the quality (mIoU) of generated seed masks when plugging LPCAM in AMN on VOC dataset. We perform hyperparameter sensitivity analyses by changing the values of (a) the threshold $\tau$ for dividing foreground and background local features, (b) the threshold $\mu_f$ for selecting class prototypes and the threshold $\mu_b$ for selecting context prototypes, (c) the number of clusters $K$ in K-Means, and (d) the threshold used to generate 0-1 seed mask (a common hyperparameter in all CAM-based methods). Figure~\ref{fig:sensitivity_mscoco}(a) shows that the optimal value of $\tau$ is $0.25$. Adding a small change does not make any significant effect on the results, e.g., the drop is less than $1\%$ if decreasing $\tau$ to $0.15$. We use a higher $\tau$ on MS COCO because the quality of CAM on MS COCO is poorer (than VOC) and a higher value can filter out noisy activation. Figure~\ref{fig:sensitivity_mscoco}(b) shows that the optimal values of $\mu_f$ and $\mu_b$ are $0.9$ and $0.5$, respectively. The gentle curves show that LPCAM is little sensitive to $\mu_f$ and $\mu_b$. This is because classification models (trained in the first step of WSSS) often produce overconfident (sharp) predictions, i.e., output probabilities are often close to $0$ or $1$. It is easy to set thresholds ($\mu_f$ and $\mu_b$) on such sharp values. In Figure~\ref{fig:sensitivity_mscoco}(c), the best mIoU of seed mask is $42.5\%$ when $K$=$20$, and it drops by only $0.8$ percentage points when $K$ goes up to $30$. In Figure~\ref{fig:sensitivity_mscoco}(d), LPCAM shows much gentler slopes than CAM around their respective optimal points, indicating its lower sensitivity to the changes of this threshold.

\begin{figure*}[t]
    \includegraphics[width=0.98\textwidth]{figures/figure_vis_voc.pdf}
    \caption{Qualitative results on VOC. In each example pair, the left is heatmap and the right is seed mask. }
    \label{fig:qualitative}
\end{figure*}
\section{Qualitative Results on VOC}
\label{sec:qualitative}
Figure~\ref{fig:qualitative} shows qualitative examples where LPCAM leverages both discriminative and non-discriminative local features to generate heatmaps and 0-1 masks on VOC dataset. In both single-object images (``cow'', ``boat'', ``car'', and ``bird'') and multi-objects images (``horse'' and ``cat''), CAM focuses on only discriminative features e.g., the ``head'' regions of ``cow'', while our LPCAM has better coverage on the non-discriminative feature, e.g., the ``body'' and ``leg'' regions. In the ``car'' example, the context prototype term $-\bm{BG}_n$ in Eq.~\ref{eq:LPCAM} (main paper) helps to remove the context ``plants''. In the last two examples, we show two failure cases: LPCAM succeeds in capturing more object parts of ``train'' and ``TV Monitor'' but unnecessarily covers more on the context ``railroad'' and ``keyboard''. We think the reason is the strong co-occurrence of  ``train'' and ``railroad'' in the images of ``train'' (``TV Monitor'' and ``keyboard'' in the image of ``TV Monitor''). 