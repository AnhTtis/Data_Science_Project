@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

% cvpr review references

@inproceedings{zeng2022lion,
    title={LION: Latent Point Diffusion Models for 3D Shape Generation},
        author={Xiaohui Zeng and Arash Vahdat and Francis Williams and Zan Gojcic and Or Litany and Sanja Fidler and Karsten Kreis},
        booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
        year={2022}
}


@article{SPAGHETTI,
author = {Hertz, Amir and Perel, Or and Giryes, Raja and Sorkine-Hornung, Olga and Cohen-Or, Daniel},
title = {SPAGHETTI: Editing Implicit Shapes through Part Aware Generation},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3528223.3530084},
doi = {10.1145/3528223.3530084},
abstract = {Neural implicit fields are quickly emerging as an attractive representation for learning based techniques. However, adopting them for 3D shape modeling and editing is challenging. We introduce a method for Editing Implicit Shapes Through Part Aware GeneraTion, permuted in short as SPAGHETTI. Our architecture allows for manipulation of implicit shapes by means of transforming, interpolating and combining shape segments together, without requiring explicit part supervision. SPAGHETTI disentangles shape part representation into extrinsic and intrinsic geometric information. This characteristic enables a generative framework with part-level control. The modeling capabilities of SPAGHETTI are demonstrated using an interactive graphical interface, where users can directly edit neural implicit shapes. Our code, editing user interface demo and pre-trained models are available at github.com/amirhertz/spaghetti.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {106},
numpages = {20},
keywords = {shape synthesis, shape modeling, neural networks}
}

@inproceedings{zheng2022sdf,
  title={SDF-StyleGAN: Implicit SDF-Based StyleGAN for 3D Shape Generation},
  author={Zheng, X and Liu, Yang and Wang, P and Tong, Xin},
  booktitle={Computer Graphics Forum},
  volume={41},
  pages={52--63},
  year={2022},
  organization={Wiley Online Library}
}
@inproceedings{gao2022get3d,
  title={Get3d: A generative model of high quality 3d textured shapes learned from images},
  author={Gao, Jun and Shen, Tianchang and Wang, Zian and Chen, Wenzheng and Yin, Kangxue and Li, Daiqing and Litany, Or and Gojcic, Zan and Fidler, Sanja},
  booktitle={Advances In Neural Information Processing Systems},
  year={2022}
}

@inproceedings{zhao2021point,
  title={Point transformer},
  author={Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Torr, Philip HS and Koltun, Vladlen},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={16259--16268},
  year={2021}
}

@article{guo2021pct,
  title={Pct: Point cloud transformer},
  author={Guo, Meng-Hao and Cai, Jun-Xiong and Liu, Zheng-Ning and Mu, Tai-Jiang and Martin, Ralph R and Hu, Shi-Min},
  journal={Computational Visual Media},
  volume={7},
  pages={187--199},
  year={2021},
  publisher={Springer}
}


@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}


@inproceedings{xiang2021snowflakenet,
  title={Snowflakenet: Point cloud completion by snowflake point deconvolution with skip-transformer},
  author={Xiang, Peng and Wen, Xin and Liu, Yu-Shen and Cao, Yan-Pei and Wan, Pengfei and Zheng, Wen and Han, Zhizhong},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={5499--5509},
  year={2021}
}

@inproceedings{hui2022neural,
  title={Neural wavelet-domain diffusion for 3d shape generation},
  author={Hui, Ka-Hei and Li, Ruihui and Hu, Jingyu and Fu, Chi-Wing},
  booktitle={SIGGRAPH Asia 2022 Conference Papers},
  pages={1--9},
  year={2022}
}

% Implicits
@inproceedings{park2019deepsdf,
  title={Deepsdf: Learning continuous signed distance functions for shape representation},
  author={Park, Jeong Joon and Florence, Peter and Straub, Julian and Newcombe, Richard and Lovegrove, Steven},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={165--174},
  year={2019}
}

@inproceedings{dai2017shape,
  title={Shape completion using 3d-encoder-predictor cnns and shape synthesis},
  author={Dai, Angela and Ruizhongtai Qi, Charles and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5868--5877},
  year={2017}
}

@inproceedings{chen2021learning,
  title={Learning continuous image representation with local implicit image function},
  author={Chen, Yinbo and Liu, Sifei and Wang, Xiaolong},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8628--8638},
  year={2021}
}

@article{schwarz2020graf,
  title={Graf: Generative radiance fields for 3d-aware image synthesis},
  author={Schwarz, Katja and Liao, Yiyi and Niemeyer, Michael and Geiger, Andreas},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20154--20166},
  year={2020}
}


@article{mildenhall2021nerf,
  title={Nerf: Representing scenes as neural radiance fields for view synthesis},
  author={Mildenhall, Ben and Srinivasan, Pratul P and Tancik, Matthew and Barron, Jonathan T and Ramamoorthi, Ravi and Ng, Ren},
  journal={Communications of the ACM},
  volume={65},
  number={1},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{niemeyer2021giraffe,
  title={Giraffe: Representing scenes as compositional generative neural feature fields},
  author={Niemeyer, Michael and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11453--11464},
  year={2021}
}
@inproceedings{mescheder2019occupancy,
  title={Occupancy networks: Learning 3d reconstruction in function space},
  author={Mescheder, Lars and Oechsle, Michael and Niemeyer, Michael and Nowozin, Sebastian and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4460--4470},
  year={2019}
}

@inproceedings{valsesia2019learning,
  title={Learning localized generative models for 3d point clouds via graph convolution},
  author={Valsesia, Diego and Fracastoro, Giulia and Magli, Enrico},
  booktitle={International conference on learning representations},
  year={2019}
}

@inproceedings{atzmon2020sal,
  title={Sal: Sign agnostic learning of shapes from raw data},
  author={Atzmon, Matan and Lipman, Yaron},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2565--2574},
  year={2020}
}
@inproceedings{peng2020convolutional,
  title={Convolutional occupancy networks},
  author={Peng, Songyou and Niemeyer, Michael and Mescheder, Lars and Pollefeys, Marc and Geiger, Andreas},
  booktitle={European Conference on Computer Vision},
  pages={523--540},
  year={2020},
  organization={Springer}
}
@article{sitzmann2020implicit,
  title={Implicit neural representations with periodic activation functions},
  author={Sitzmann, Vincent and Martel, Julien and Bergman, Alexander and Lindell, David and Wetzstein, Gordon},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7462--7473},
  year={2020}
}

@inproceedings{sarmad2022photo,
  title={Photo-Realistic Continuous Image Super-Resolution with Implicit Neural Networks and Generative Adversarial Networks},
  author={Sarmad, Muhammad and Ruspini, Leonardo and Lindseth, Frank},
  booktitle={Proceedings of the Northern Lights Deep Learning Workshop},
  volume={3},
  year={2022}
}

@inproceedings{luo2021diffusion,
  title={Diffusion probabilistic models for 3d point cloud generation},
  author={Luo, Shitong and Hu, Wei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2837--2845},
  year={2021}
}

@inproceedings{yang2019pointflow,
  title={Pointflow: 3d point cloud generation with continuous normalizing flows},
  author={Yang, Guandao and Huang, Xun and Hao, Zekun and Liu, Ming-Yu and Belongie, Serge and Hariharan, Bharath},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4541--4550},
  year={2019}
}
@inproceedings{yan2022shapeformer,
  title={Shapeformer: Transformer-based shape completion via sparse representation},
  author={Yan, Xingguang and Lin, Liqiang and Mitra, Niloy J and Lischinski, Dani and Cohen-Or, Daniel and Huang, Hui},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6239--6249},
  year={2022}
}


@inproceedings{chen2019learning,
  title={Learning implicit fields for generative shape modeling},
  author={Chen, Zhiqin and Zhang, Hao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5939--5948},
  year={2019}
}
@article{kleineberg2020adversarial,
  title={Adversarial generation of continuous implicit shape representations},
  author={Kleineberg, Marian and Fey, Matthias and Weichert, Frank},
  journal={arXiv preprint arXiv:2002.00349},
  year={2020}
}

@article{Hanocka_2020,
	doi = {10.1145/3386569.3392415},
  
	url = {https://doi.org/10.1145%2F3386569.3392415},
  
	year = 2020,
	month = {aug},
  
	publisher = {Association for Computing Machinery ({ACM})},
  
	volume = {39},
  
	number = {4},
  
	author = {Rana Hanocka and Gal Metzer and Raja Giryes and Daniel Cohen-Or},
  
	title = {Point2Mesh},
  
	journal = {{ACM} Transactions on Graphics}
}

%%

@inproceedings{esser2021taming,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12873--12883},
  year={2021}
}

@article{chibane2020neural,
  title={Neural unsigned distance fields for implicit function learning},
  author={Chibane, Julian and Pons-Moll, Gerard and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21638--21652},
  year={2020}
}


## Explicit surface
@misc{Explicit,
  doi = {10.48550/ARXIV.2007.10294},
  
  url = {https://arxiv.org/abs/2007.10294},
  
  author = {Poursaeed, Omid and Fisher, Matthew and Aigerman, Noam and Kim, Vladimir G.},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Coupling Explicit and Implicit Surface Representations for Generative 3D Modeling},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

## image based representation
@article{image_based,
  doi = {10.48550/ARXIV.2110.08861},
  
  url = {https://arxiv.org/abs/2110.08861},
  
  author = {Shi, Zai and Meng, Zhao and Xing, Yiran and Ma, Yunpu and Wattenhofer, Roger},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {3D-RETR: End-to-End Single and Multi-View 3D Reconstruction with Transformers},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}
  
## 3D GANs voxels
@misc{3DGANs,
  doi = {10.48550/ARXIV.1610.07584},
  
  url = {https://arxiv.org/abs/1610.07584},
  
  author = {Wu, Jiajun and Zhang, Chengkai and Xue, Tianfan and Freeman, William T. and Tenenbaum, Joshua B.},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

## 3D auto encoders voxels
@misc{voxel_autoencoder,
  doi = {10.48550/ARXIV.1604.03755},
  
  url = {https://arxiv.org/abs/1604.03755},
  
  author = {Sharma, Abhishek and Grau, Oliver and Fritz, Mario},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {VConv-DAE: Deep Volumetric Shape Learning Without Object Labels},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

## PointNet
@misc{PointNet,
  doi = {10.48550/ARXIV.1612.00593},
  
  url = {https://arxiv.org/abs/1612.00593},
  
  author = {Qi, Charles R. and Su, Hao and Mo, Kaichun and Guibas, Leonidas J.},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

## point cloud to voxels
@misc{pc_voxels,
  doi = {10.48550/ARXIV.1803.10091},
  
  url = {https://arxiv.org/abs/1803.10091},
  
  author = {Atzmon, Matan and Maron, Haggai and Lipman, Yaron},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Point Convolutional Neural Networks by Extension Operators},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

##PCT 
@article{pct,
	doi = {10.1007/s41095-021-0229-5},
  
	url = {https://doi.org/10.1007%2Fs41095-021-0229-5},
  
	year = 2021,
	month = {apr},
  
	publisher = {Springer Science and Business Media {LLC}
},
  
	volume = {7},
  
	number = {2},
  
	pages = {187--199},
  
	author = {Meng-Hao Guo and Jun-Xiong Cai and Zheng-Ning Liu and Tai-Jiang Mu and Ralph R. Martin and Shi-Min Hu},
  
	title = {{PCT}: Point cloud transformer},
  
	journal = {Computational Visual Media}
}

## occupancy functions
@misc{occupancy,
  doi = {10.48550/ARXIV.1812.03828},
  
  url = {https://arxiv.org/abs/1812.03828},
  
  author = {Mescheder, Lars and Oechsle, Michael and Niemeyer, Michael and Nowozin, Sebastian and Geiger, Andreas},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Occupancy Networks: Learning 3D Reconstruction in Function Space},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

##DeepSDF
@misc{DeepSDF,
  doi = {10.48550/ARXIV.1901.05103},
  
  url = {https://arxiv.org/abs/1901.05103},
  
  author = {Park, Jeong Joon and Florence, Peter and Straub, Julian and Newcombe, Richard and Lovegrove, Steven},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

##IF-Nets
@misc{IF-Nets,
  doi = {10.48550/ARXIV.2008.03897},
  
  url = {https://arxiv.org/abs/2008.03897},
  
  author = {Chen, Po-Heng and Luo, Zhao-Xu and Huang, Zu-Kuan and Yang, Chun and Chen, Kuan-Wen},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Image and Video Processing (eess.IV), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  
  title = {IF-Net: An Illumination-invariant Feature Network},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

##AE
@Article{AE,
AUTHOR = {Sublime, Jérémie and Kalinicheva, Ekaterina},
TITLE = {Automatic Post-Disaster Damage Mapping Using Deep-Learning Techniques for Change Detection: Case Study of the Tohoku Tsunami},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1123},
URL = {https://www.mdpi.com/2072-4292/11/9/1123},
ISSN = {2072-4292},
DOI = {10.3390/rs11091123}
}

##VAE
@misc{VAE,
  doi = {10.48550/ARXIV.1312.6114},
  
  url = {https://arxiv.org/abs/1312.6114},
  
  author = {Kingma, Diederik P and Welling, Max},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Auto-Encoding Variational Bayes},
  
  publisher = {arXiv},
  
  year = {2013},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

## Variational Lossy Autoencoder
@misc{VAE_generation,
  doi = {10.48550/ARXIV.1611.02731},
  
  url = {https://arxiv.org/abs/1611.02731},
  
  author = {Chen, Xi and Kingma, Diederik P. and Salimans, Tim and Duan, Yan and Dhariwal, Prafulla and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Variational Lossy Autoencoder},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

## Shapenet dataset
@misc{Shapenet:Dataset,
  doi = {10.48550/ARXIV.1512.03012},
  url = {https://arxiv.org/abs/1512.03012},
  author = {Chang, Angel X. and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and Xiao, Jianxiong and Yi, Li and Yu, Fisher},
  keywords = {Graphics (cs.GR), Artificial Intelligence (cs.AI), Computational Geometry (cs.CG), Computer Vision and Pattern Recognition (cs.CV), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {ShapeNet: An Information-Rich 3D Model Repository},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

## Text_summarization
@article{Text_summarization,
author = {Huang, Weihao and Chen, Jiaojiao and Cai, Qianhua and Liu, Xuejie and Zhang, Yudong and Hu, Xiaohui},
year = {2022},
month = {01},
pages = {1-16},
title = {Hierarchical Hybrid Neural Networks With Multi-Head Attention for Document Classification},
volume = {18},
journal = {International Journal of Data Warehousing and Mining},
doi = {10.4018/IJDWM.303673}
}

##Image_Transformer
@misc{Image_Transformer,
  doi = {10.48550/ARXIV.1802.05751},
  
  url = {https://arxiv.org/abs/1802.05751},
  
  author = {Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Łukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Image Transformer},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

## SeqTrans_generation
@misc{SeqTrans_generation,
  doi = {10.48550/ARXIV.2111.12480},
  
  url = {https://arxiv.org/abs/2111.12480},
  
  author = {Ibing, Moritz and Kobsik, Gregor and Kobbelt, Leif},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Octree Transformer: Autoregressive 3D Shape Generation on Hierarchically Structured Sequences},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@article{Attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

##Diffusion for video generation
@misc{Diff_video,
  doi = {10.48550/ARXIV.2203.09481},
  
  url = {https://arxiv.org/abs/2203.09481},
  
  author = {Yang, Ruihan and Srivastava, Prakhar and Mandt, Stephan},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Diffusion Probabilistic Modeling for Video Generation},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

##Diffusion for Image generation
@misc{Diff_image,
  doi = {10.48550/ARXIV.2006.11239},
  
  url = {https://arxiv.org/abs/2006.11239},
  
  author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Denoising Diffusion Probabilistic Models},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

## Diffusion Point clouds
@misc{Diff_PC,
  doi = {10.48550/ARXIV.2103.01458},
  
  url = {https://arxiv.org/abs/2103.01458},
  
  author = {Luo, Shitong and Hu, Wei},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Diffusion Probabilistic Models for 3D Point Cloud Generation},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}




## OpenAI GPT
@article{GPT,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

#Music generation
@inproceedings{Music,
  title={Interacting with GPT-2 to generate controlled and believable musical sequences in ABC notation},
  author={Geerlings, Carina and Merono-Penuela, Albert},
  booktitle={Proceedings of the 1st Workshop on NLP for Music and Audio (NLP4MusA)},
  pages={49--53},
  year={2020}
}

## Thermodynamics
@InProceedings{Thermodynamics,
  title = 	 {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  author = 	 {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {2256--2265},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/sohl-dickstein15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/sohl-dickstein15.html},
  abstract = 	 {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.}
}

## point cloud representation
@book{Linsen2001_372001,
    author       = {Linsen, Lars},
    year         = {2001},
    title        = {Point cloud representation},
    language     = {english},
    note         = {Karlsruhe 2001. (Interner Bericht. Fakult{\"{a}}t f{\"{u}}r Informatik, Universit{\"{a}}t Karlsruhe. 2001,3.)}
}

## unsigned distance fields

@inproceedings{chibane2020implicit,
  title={Implicit feature networks for texture completion from partial 3d data},
  author={Chibane, Julian and Pons-Moll, Gerard},
  booktitle={European Conference on Computer Vision},
  pages={717--725},
  year={2020},
  organization={Springer}
}

@article{lorensen1987marching,
  title={Marching cubes: A high resolution 3D surface construction algorithm},
  author={Lorensen, William E and Cline, Harvey E},
  journal={ACM siggraph computer graphics},
  volume={21},
  number={4},
  pages={163--169},
  year={1987},
  publisher={ACM New York, NY, USA}
}

@inproceedings{d2021convit,
  title={Convit: Improving vision transformers with soft convolutional inductive biases},
  author={d’Ascoli, St{\'e}phane and Touvron, Hugo and Leavitt, Matthew L and Morcos, Ari S and Biroli, Giulio and Sagun, Levent},
  booktitle={International Conference on Machine Learning},
  pages={2286--2296},
  year={2021},
  organization={PMLR}
}

@inproceedings{shu20193d,
  title={3d point cloud generative adversarial network based on tree structured graph convolutions},
  author={Shu, Dong Wook and Park, Sung Woo and Kwon, Junseok},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={3859--3868},
  year={2019}
}

@inproceedings{NIPS2017_8a1d6947,
 author = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
 url = {https://proceedings.neurips.cc/paper/2017/file/8a1d694707eb0fefe65871369074926d-Paper.pdf},
 volume = {30},
 year = {2017}
}


## Neural discrete representation
@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

## PyTorch
@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@inproceedings{mnih2014neural,
  title={Neural variational inference and learning in belief networks},
  author={Mnih, Andriy and Gregor, Karol},
  booktitle={International Conference on Machine Learning},
  pages={1791--1799},
  year={2014},
  organization={PMLR}
}

@article{chen2016variational,
  title={Variational lossy autoencoder},
  author={Chen, Xi and Kingma, Diederik P and Salimans, Tim and Duan, Yan and Dhariwal, Prafulla and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1611.02731},
  year={2016}
}

##Gradient copy approach
@misc{Gradient_approach,
  doi = {10.48550/ARXIV.1308.3432},
  
  url = {https://arxiv.org/abs/1308.3432},
  
  author = {Bengio, Yoshua and Léonard, Nicholas and Courville, Aaron},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation},
  
  publisher = {arXiv},
  
  year = {2013},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
## Transformer in generation
@misc{Transimage,
  doi = {10.48550/ARXIV.1802.05751},
  
  url = {https://arxiv.org/abs/1802.05751},
  
  author = {Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Łukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Image Transformer},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
## Sequenceimage
@misc{Sequenceimage,
  doi = {10.48550/ARXIV.1601.06759},
  
  url = {https://arxiv.org/abs/1601.06759},
  
  author = {Oord, Aaron van den and Kalchbrenner, Nal and Kavukcuoglu, Koray},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Pixel Recurrent Neural Networks},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



% Related works ( might contain some repititions

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@inproceedings{optimtrick1,
author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron},
title = {Improved Training of Wasserstein GANs},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only poor samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models with continuous generators. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {5769–5779},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}


@InProceedings{optimtrick,
  title = 	 {{W}asserstein Generative Adversarial Networks},
  author =       {Martin Arjovsky and Soumith Chintala and L{\'e}on Bottou},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {214--223},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/arjovsky17a.html},
  abstract = 	 {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to different distances between distributions.}
}

@inproceedings{modelcollapse,
  title={Photo-realistic single image super-resolution using a generative adversarial network},
  author={Ledig, Christian and Theis, Lucas and Husz{\'a}r, Ferenc and Caballero, Jose and Cunningham, Andrew and Acosta, Alejandro and Aitken, Andrew and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and others},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4681--4690},
  year={2017}
}

@inproceedings{thanh2020catastrophic,
  title={Catastrophic forgetting and mode collapse in GANs},
  author={Thanh-Tung, Hoang and Tran, Truyen},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--10},
  year={2020},
  organization={IEEE}
}

@article{hyvarinen2005estimation,
  title={Estimation of non-normalized statistical models by score matching.},
  author={Hyv{\"a}rinen, Aapo and Dayan, Peter},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={4},
  year={2005}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{song2019generative,
  title={Generative modeling by estimating gradients of the data distribution},
  author={Song, Yang and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}

@article{saharia2021image,
  title={Image super-resolution via iterative refinement},
  author={Saharia, Chitwan and Ho, Jonathan and Chan, William and Salimans, Tim and Fleet, David J and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:2104.07636},
  year={2021}
}

@inproceedings{cai2020learning,
  title={Learning gradient fields for shape generation},
  author={Cai, Ruojin and Yang, Guandao and Averbuch-Elor, Hadar and Hao, Zekun and Belongie, Serge and Snavely, Noah and Hariharan, Bharath},
  booktitle={European Conference on Computer Vision},
  pages={364--381},
  year={2020},
  organization={Springer}
}

@article{chen2020wavegrad,
  title={WaveGrad: Estimating gradients for waveform generation},
  author={Chen, Nanxin and Zhang, Yu and Zen, Heiga and Weiss, Ron J and Norouzi, Mohammad and Chan, William},
  journal={arXiv preprint arXiv:2009.00713},
  year={2020}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@InProceedings{pmlr-v32-rezende14,
  title = 	 {Stochastic Backpropagation and Approximate Inference in Deep Generative Models},
  author = 	 {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
  pages = 	 {1278--1286},
  year = 	 {2014},
  editor = 	 {Xing, Eric P. and Jebara, Tony},
  number =       {2},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Bejing, China},
  month = 	 {22--24 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v32/rezende14.pdf},
  url = 	 {https://proceedings.mlr.press/v32/rezende14.html},
  abstract = 	 {We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning.   Our algorithm introduces a recognition model to represent an approximate posterior distribution and uses this for optimisation of a variational lower bound.  We develop stochastic backpropagation – rules for gradient backpropagation through stochastic variables – and   derive an algorithm that allows for joint optimisation of the parameters of both the generative and recognition models.  We demonstrate on several real-world data sets that by using stochastic backpropagation and variational inference, we obtain models that are able to  generate realistic samples of data, allow for accurate imputations of missing data, and provide a useful tool for high-dimensional data visualisation.}
}


@article{oord2016conditional,
  title={Conditional image generation with pixelcnn decoders},
  author={Oord, Aaron van den and Kalchbrenner, Nal and Vinyals, Oriol and Espeholt, Lasse and Graves, Alex and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1606.05328},
  year={2016}
}

@article{razavi2019,
  title={Generating diverse high-fidelity images with vq-vae-2},
  author={Razavi, Ali and van den Oord, Aaron and Vinyals, Oriol},
  journal={Advances in neural information processing systems},
  pages={14866--14876},
  year={2019}
}

@article{parmar2018image,
  title={Image transformer},
  author={Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Lukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},
  journal={International Conference on Machine Learning},
  pages={4055--4064},
  year={2018},
  organization={PMLR}
}

@inproceedings{chen2020generative,
  title={Generative pretraining from pixels},
  author={Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={1691--1703},
  year={2020},
  organization={PMLR}
}

