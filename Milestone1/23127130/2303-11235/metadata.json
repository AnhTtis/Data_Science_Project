{
    "arxiv_id": "2303.11235",
    "paper_title": "FullFormer: Generating Shapes Inside Shapes",
    "authors": [
        "Tejaswini Medi",
        "Jawad Tayyub",
        "Muhammad Sarmad",
        "Frank Lindseth",
        "Margret Keuper"
    ],
    "submission_date": "2023-03-20",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Implicit generative models have been widely employed to model 3D data and have recently proven to be successful in encoding and generating high-quality 3D shapes. This work builds upon these models and alleviates current limitations by presenting the first implicit generative model that facilitates the generation of complex 3D shapes with rich internal geometric details. To achieve this, our model uses unsigned distance fields to represent nested 3D surfaces allowing learning from non-watertight mesh data. We propose a transformer-based autoregressive model for 3D shape generation that leverages context-rich tokens from vector quantized shape embeddings. The generated tokens are decoded into an unsigned distance field which is rendered into a novel 3D shape exhibiting a rich internal structure. We demonstrate that our model achieves state-of-the-art point cloud generation results on popular classes of 'Cars', 'Planes', and 'Chairs' of the ShapeNet dataset. Additionally, we curate a dataset that exclusively comprises shapes with realistic internal details from the `Cars' class of ShapeNet and demonstrate our method's efficacy in generating these shapes with internal geometry.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.11235v1"
    ],
    "publication_venue": null
}