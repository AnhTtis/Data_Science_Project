
\section{Stability analysis}
To this point, we have constructed the following control problem in a new coordinate after a feedback linearization:
\begin{subequations}
	\begin{align}
&\ddot \bsig=[\ddot x,\ddot y, \ddot z]^\top=\bv\label{eq:lin_sys_a} \\
&\text{subject to: }\bv \in \tilde{\mathcal{V}}.\label{eq:lin_sys_b}
	\end{align}
\label{eq:lin_sys}
\end{subequations}
For further implementation, let us consider the Rungeâ€“Kutta fourth-order with sampling time $T_s$ of \eqref{eq:lin_sys} as follows:
\begin{subequations}
	\begin{align}
&\bxi_{k+1} =A_d\bxi_{k}+B_d\bv_k\label{eq:linearized_disa} \\
&\text{subject to: }\bv_k \in \tilde{\mathcal{V}}.
\label{eq:linearized_disb}
	\end{align}
\label{eq:linearized_dis}
\end{subequations}\\
where $\xi_k\triangleq[x_k,y_k,z_k,\dot x_k,\dot y_k,\dot z_k]^\top$ denotes the states and $\bv_k\triangleq [v_{1k},v_{2k},v_{3k}]^\top$ collects the virtual input at step $k$.


Then with the dynamics \eqref{eq:linearized_disa} and input constraint \eqref{eq:linearized_disb}, we proceed by considering the following LMPC problem.
Consider the following stage cost $V_s(\bx,\bv)$, terminal cost $V_f(\bx)$ and the open-loop optimization problem:

\be
\begin{aligned}
\underset{\bv(\cdot|k)}{\arg \min }\;  V_f(\bx(N_p,k))+ \sum_{i=0}^{N_p-1} V_s(\bx(i|k),\bv(i|k))\\
\text{subject to:}
\begin{cases}
\bx(i+1|k)=A\bx(i|k)+B\bv(i|k) \\
\bv(i|k) \in \Tilde{\mathcal{V}}_c, \, i\in\{0,1,...,N_p\} \\
\bx(N_p|k)\in \mathcal{X}_f
\end{cases}
\end{aligned}
\label{eq:opti_prob}
\ee 

with the prediction horizon $N_p$. 
The predicted state and input 
sequences computed from the optimization problem \eqref{eq:opti_prob} at time
step $k$ are denoted by $\bx(\cdot|k) \triangleq [\bx(0|k) \cdots \bx(N|k)]$ and
$\bv(\cdot|k) \triangleq [\bv(0|k) \cdots  \bv( N_p - 1|k)]$ respectively.  $\mathcal{X}_f\subset \R^6$ is the terminal region, which will be defined in the following section.
The stage cost and terminal cost are defined as:
\be 
\begin{cases}
V_s(\bx,\bv)&=\| \bv-\bv_e\|_R^2+
\| \bx-\bx_e\|_Q^2\\
V_f(\bx)&=\| \bx-\bx_e\|_P^2
\end{cases}
\ee

where $Q,P \succ 0$ and $R\succeq 0$. While $Q,R$ are the weighting matrices penalizing the cost function $V_s(\cdot)$ and defined by user, $P$ is a solution of a Lyapunov equation later solved as a stability proof for the controller design. 

Let us assume the \eqref{eq:opti_prob} is successfully solved with the optimal solution $\left( x^*(\cdot|k),\bv^*(\cdot|k) \right)$, then the control action applied to the system \eqref{eq:linearized_disa} will be:

\be 
\bv(\bx_k)=\bv^*(0|k).
\label{eq:controllerMPC}
\ee 

In order to show that $\bx_e$ is asymptotically stable under the controller \eqref{eq:controllerMPC} and the optimization problem \eqref{eq:opti_prob} is recursively feasible. It is necessary to show that $\forall \bx_k \,\in \mathcal{X}_f$, there exists an admissible control $\bv_{loc}(\bx_k)\in \tilde{\mathcal{V}}_c$ such that the two conditions below holds \cite{rawlings2012postface}:
\begin{subequations}
    \begin{align}
    &\bx_{k+1}\in\mathcal{X}_f \;\,\forall \bx_{k} \in\mathcal{X}_f \label{eq:conditions_a}\\
    &V_f(\bx_{k+1})+V_s(\bx_k,\bv_{loc}(\bx_k))-V_f(\bx_{k})\leq 0.
    \label{eq:conditions_b}
    \end{align}
    \label{eq:conditions}
\end{subequations}  

Therefore, as a proposition for finding such controller $\bv_{loc}(\bx_k)$ and region $\mathcal{X}_f$, let us consider the following control design:

\be 
\begin{aligned}
v_{qk}(\bx_k)&=K_{1q}q_k  + K_{2q} \dot q_k\;\forall\; q\in \{x,y,z\}, \\
\bv_{loc}(\bx_k)&=[v_{xk}(\bx_k)\;\;v_{yk}(\bx_k)\;\;v_{zk}(\bx_k)]^\top.
\end{aligned}
\ee 
where $K_{1q},K_{2q}\in\R$ denote the controller's gains. Then the closed-loop under $\bv=\bv_{loc}(\bx_k)\triangleq K\bx_k$ yields:

\be 
\bx_{k+1}=A_{cl}\bx_k
\label{eq:closed_linear}
\ee 

where $A_{cl}=(A+BK)$, $K=[\text{diag}(K_{1x},K_{1y},K_{1z}),$ diag $(K_{2x},K_{2y},K_{2z})]$. Moreover, the Routh-Hurwitz criterion for the asymptotic stability  is as following:
\be 
\frac{-2}{T_s}<K_{2q}<\frac{T_s}{2}K_{1q}<0
\ee 

Let us assume the matrix $Q,R\text{ and }K$ are suitably chosen, then the construction of the terminal region $\mathcal{X}_f$ and matrx $P$ can be considered as the following proposition.
\begin{prop}
Let us consider the design procedure as follow:
\begin{subequations}
\begin{align}
&\bullet Q^*=Q+\lambda_{max}(R)K^\top K, \label{eq:design_lmpc_a}\\
&\bullet \text{Choose: } M\succeq Q^*\succ 0,\\
&\bullet \text{Find } P \text{ such that: } A_{cl}^\top P A_{cl}=P-M, \\
%
&\bullet 
\begin{cases}
 \text{Find } \mathcal{X}_f=\{\bx  \in \R^6 \;|\; \bx^\top P \bx \leq \alpha^2\},& \\
%
 \text{subject to:}\;\; \bv_{loc}(\bx_k)=K\bx_k \in  \tilde{\mathcal{V}}_c  \;\forall \bx_k\in\mathcal{X}_f. &
\end{cases} \label{eq:design_lmpc_d}
%
\end{align}
\label{eq:design_lmpc}
\end{subequations}
Then with such $P $ and $\mathcal X_f$,  the conditions \eqref{eq:conditions} hold under the controller $\bv_{loc}(\bx_k)=K\bx_k\forall\;\bx_k\in\mathcal{X}_f$, hence does the asymptotic stability of \eqref{eq:linearized_disa} under \eqref{eq:controllerMPC}.
\end{prop}

\begin{proof}
First, let us consider the condition \eqref{eq:conditions_a}, on one hand, we have:

\be 
\begin{aligned}
&\frac{\|\bx_k\|_M^2}{\lambda_{min}(M)}\geq \|\bx_k\|_2^2 \geq \frac{\|\bx_k\|_P^2}{\lambda_{max}(P)},\\
\Rightarrow & \|\bx_k\|_P^2-\|\bx_k\|_M^2 \leq \left(1-\dfrac{\lambda_{min}(M)}{\lambda_{max}(P)} \right)\|\bx_{k}\|_P^2.
\end{aligned}
\ee 
On the other hand,
\be 
\begin{aligned}
\|\bx_{k+1}\|_P^2&=\bx_{k}^\top (A_{cl}^\top PA_{cl})\bx_{k}\\ 
&=\bx_{k}^\top (P-M)\bx_{k}\\
%
& =\|\bx_k\|_P^2-\|\bx_k\|_M^2 \\
%
\Rightarrow \|\bx_{k+1}\|_P^2&\leq \left(1-\dfrac{\lambda_{min}(M)}{\lambda_{max}(P)} \right)\|\bx_{k}\|_P^2
\end{aligned}
\ee 
Thus, if $\|\bx_{k}\|_P^2\leq\alpha^2$ then $\|\bx_{k+1}\|_P^2\leq\alpha^2$ or equivalently, $\bx_{k+1}\in\mathcal{X}_f \;\,\forall \bx_{k} \in\mathcal{X}_f$. Hence \eqref{eq:conditions_a} is validated.

Second, let us consider \eqref{eq:conditions_b} with the design in \eqref{eq:design_lmpc}:
\be 
\begin{aligned}
&V_f(\bx_{k+1})+V_s(\bx_k,\bv_{loc\,k})-V_f(\bx_{k}) \\
&=\bx_{k}^\top (A_{cl}^\top PA_{cl})\bx_{k}+\bx_{k}^\top Q\bx_{k}+\bx_{k}^\top K^\top R K\bx_{k}-
\bx_{k}^\top P \bx_{k}\\
&=\bx_{k}^\top \left(A_{cl}^\top PA_{cl}+Q+K^\top R K-P\right)\bx_{k}\\
&=\bx_{k}^\top \left(-M+Q+K^\top R K\right)\bx_{k}\\
&\leq \bx_{k}^\top (-M+Q^*)\bx_{k}\leq 0
\end{aligned}
\ee 
Thus \eqref{eq:conditions_b} is satisfied.
\end{proof}

The remaining problem now is to find $\mathcal{X}_f $ or equivalently, to find $\alpha$ as in \eqref{eq:design_lmpc_d}. For this problem, let us adapt the problem of finding the maximum volume ellipsoid subject to a collection of linear constraints \cite{boyd2004convex} as following. First, let us consider the following representation of the ellipsoid $\mathcal{X}_f=\{\bx  \in \R^6 \;|\; \bx^\top P \bx \leq \alpha^2\}$:

\be 
\mathcal{X}_f=\{\bx=\alpha E \br\in \R^6 \;|\;\; \|\br\|_2^2\leq 1\}
\ee 
where $E$ is the solution of $E^2=P$. Then the problem of maximization of the volume of $\mathcal{X}_f $ satisfying \eqref{eq:design_lmpc_d} can be rewritten as \cite{boyd2004convex}: 
\be 
	\begin{aligned}
		\alpha^*    & =\underset{                     
		\alpha 
		}{\arg\operatorname{min}}
		\left[
		-\log{(\det E)}
		\right],\\
		\text{s.t }     &    
		\|\alpha E a_{iK}\|_2 \leq b_{iv_c}
	\end{aligned}
	\label{eq:find_alpha}
\ee 
where $b_{iv_c}$ denotes the $i$-row of $b_{v_c}$ which comes from the half-space representation of $\tilde{\mathcal{V}}_c$: 
$$\tilde{\mathcal{V}}_c=\{\bv\in\R^3\;|\; A_{v_c}\bv\leq b_{v_c}\}$$
and $a_{iK}$ is $i$-row of the matrix $A_K=A_{v_c}K$.















