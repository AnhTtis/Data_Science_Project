@book{steele1998draw,
  title={Draw me a story: An illustrated exploration of drawing-as-language},
  author={Steele, Bob},
  year={1998},
  publisher={Portage \& Main Press}
}

@book{kellogg1969analyzing,
  title={Analyzing children's art},
  author={Kellogg, Rhoda},
  year={1969},
  publisher={Mayfield Pub Co}
}

@article{lowenfeld1957creative,
  title={Creative and mental growth},
  author={Lowenfeld, Viktor},
  year={1957},
  publisher={Macmillan}
}

@book{jolley2009children,
  title={Children and pictures: Drawing and understanding},
  author={Jolley, Richard P},
  year={2009},
  publisher={John Wiley \& Sons}
}

@book{willats2006making,
  title={Making sense of children's drawings},
  author={Willats, John},
  year={2006},
  publisher={Psychology Press}
}

@article{willats1992representation,
  title={The representation of extendedness in children's drawings of sticks and discs},
  author={Willats, John},
  journal={Child Development},
  volume={63},
  number={3},
  pages={692--710},
  year={1992},
  publisher={Wiley Online Library}
}

@book{malchiodi1998understanding,
  title={Understanding children's drawings},
  author={Malchiodi, Cathy A},
  year={1998},
  publisher={Guilford Press}
}

@book{matthews2003drawing,
  title={Drawing and painting: Children and visual representation},
  author={Matthews, John},
  year={2003},
  publisher={Sage}
}

@book{cox2013children,
  title={Children's drawings of the human figure},
  author={Cox, Maureen V},
  year={2013},
  publisher={Psychology Press}
}

@inproceedings{chen2022transfer,
  title={Transfer Learning for Pose Estimation of Illustrated Characters},
  author={Chen, Shuhong and Zwicker, Matthias},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={793--802},
  year={2022}
}

@article{eitz2012hdhso,
author={Eitz, Mathias and Hays, James and Alexa, Marc},
title={How Do Humans Sketch Objects?},
journal={ACM Trans. Graph. (Proc. SIGGRAPH)},
year={2012},
volume={31},
number={4},
pages = {44:1--44:10}
}


%%%%%%%%%%%%%%%5% Synthetic Data Generation %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{GANNIPS2014,
 author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K. Q. Weinberger},
 pages = {2672--2680},
 publisher = {Curran Associates, Inc.},
 title = {Generative Adversarial Nets},
 url = {https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf},
 volume = {27},
 year = {2014}
}



@article{pix2pix2017,
  title={Image-to-Image Translation with Conditional Adversarial Networks},
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  journal={CVPR},
  year={2017}
}

@inproceedings{CycleGAN2017,
  title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={Computer Vision (ICCV), 2017 IEEE International Conference on},
  year={2017}
}

@incollection{MultiModalPix2PixNIPS2017_6650,
title = {Toward Multimodal Image-to-Image Translation},
author = {Zhu, Jun-Yan and Zhang, Richard and Pathak, Deepak and Darrell, Trevor and Efros, Alexei A and Wang, Oliver and Shechtman, Eli},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {465--476},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/6650-toward-multimodal-image-to-image-translation.pdf}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Human Pose Estimation %%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
@article{openpose19,
  author = {Z. {Cao} and G. {Hidalgo Martinez} and T. {Simon} and S. {Wei} and Y. A. {Sheikh}},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title = {OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},
  year = {2019}
}

@inproceedings{fang2017rmpe,
                   title={RMPE: Regional Multi-person Pose Estimation},
                   author={Fang, Hao-Shu and Xie, Shuqin and Tai, Yu-Wing and Lu, Cewu},
                   booktitle={ICCV},
                   year={2017}
                  }
                
                
@inproceedings{xiao2018simplebaselines,
    author={Xiao, Bin and Wu, Haiping and Wei, Yichen},
    title={Simple Baselines for Human Pose Estimation and Tracking},
    booktitle = {European Conference on Computer Vision (ECCV)},
    year = {2018}
}

@INPROCEEDINGS{deepcut16,
  author={L. {Pishchulin} and E. {Insafutdinov} and S. {Tang} and B. {Andres} and M. {Andriluka} and P. {Gehler} and B. {Schiele}},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={DeepCut: Joint Subset Partition and Labeling for Multi Person Pose Estimation}, 
  year={2016},
  volume={},
  number={},
  pages={4929-4937},
  doi={10.1109/CVPR.2016.533}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Object Detection %%%%%%%%%%%%%%%%%%%%%%%
@article{Liu2019DeepLF,
  title={Deep Learning for Generic Object Detection: A Survey},
  author={Li Liu and Wanli Ouyang and X. Wang and P. Fieguth and J. Chen and Xinwang Liu and M. Pietik{\"a}inen},
  journal={International Journal of Computer Vision},
  year={2019},
  volume={128},
  pages={261-318}
}
@inproceedings{MaskRCNNhe2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}

@misc{wu2019detectron2,
  author =       {Yuxin Wu and Alexander Kirillov and Francisco Massa and
                  Wan-Yen Lo and Ross Girshick},
  title =        {Detectron2},
  howpublished = {\url{https://github.com/facebookresearch/detectron2}},
  year =         {2019}
}

@misc{sermanet2014overfeat,
      title={OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks}, 
      author={Pierre Sermanet and David Eigen and Xiang Zhang and Michael Mathieu and Rob Fergus and Yann LeCun},
      year={2014},
      eprint={1312.6229},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{RCNNgirshick2014rich,
      title={Rich feature hierarchies for accurate object detection and semantic segmentation}, 
      author={Ross Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik},
      year={2014},
      eprint={1311.2524},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{ren2016fasterRCNN,
      title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}, 
      author={Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun},
      year={2016},
      eprint={1506.01497},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{detectornet2013,
author = {Szegedy, Christian and Toshev, Alexander and Erhan, Dumitru},
title = {Deep Neural Networks for Object Detection},
year = {2013},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Deep Neural Networks (DNNs) have recently shown outstanding performance on image classification tasks [14]. In this paper we go one step further and address the problem of object detection using DNNs, that is not only classifying but also precisely localizing objects of various classes. We present a simple and yet powerful formulation of object detection as a regression problem to object bounding box masks. We define a multi-scale inference procedure which is able to produce high-resolution object detections at a low cost by a few network applications. State-of-the-art performance of the approach is shown on Pascal VOC.},
booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2},
pages = {2553–2561},
numpages = {9},
location = {Lake Tahoe, Nevada},
series = {NIPS'13}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Animation %%%%%%%%%%%%%%%%%%

@article{igarashi2005asrigidaspossible,
  title={As-rigid-as-possible shape manipulation},
  author={Igarashi, Takeo and Moscovich, Tomer and Hughes, John F},
  journal={ACM transactions on Graphics (TOG)},
  volume={24},
  number={3},
  pages={1134--1141},
  year={2005},
  publisher={ACM New York, NY, USA}
}


@ARTICLE{botsch2008,
  author={M. {Botsch} and O. {Sorkine}},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={On Linear Variational Surface Deformation Methods}, 
  year={2008},
  volume={14},
  number={1},
  pages={213-230},
  doi={10.1109/TVCG.2007.1054}}

@article{jacobson2011bbw,
author = {Jacobson, Alec and Baran, Ilya and Popovi\'{c}, Jovan and Sorkine, Olga},
title = {Bounded Biharmonic Weights for Real-Time Deformation},
year = {2011},
issue_date = {July 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/2010324.1964973},
doi = {10.1145/2010324.1964973},
abstract = {Object deformation with linear blending dominates practical use as the fastest approach for transforming raster images, vector graphics, geometric models and animated characters. Unfortunately, linear blending schemes for skeletons or cages are not always easy to use because they may require manual weight painting or modeling closed polyhedral envelopes around objects. Our goal is to make the design and control of deformations simpler by allowing the user to work freely with the most convenient combination of handle types. We develop linear blending weights that produce smooth and intuitive deformations for points, bones and cages of arbitrary topology. Our weights, called bounded biharmonic weights, minimize the Laplacian energy subject to bound constraints. Doing so spreads the influences of the controls in a shape-aware and localized manner, even for objects with complex and concave boundaries. The variational weight optimization also makes it possible to customize the weights so that they preserve the shape of specified essential object features. We demonstrate successful use of our blending weights for real-time deformation of 2D and 3D shapes.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {78},
numpages = {8},
keywords = {generalized barycentric coordinates, articulated character animation, shape deformation, linear blend skinning}
}

%%%%Synthetic data%%%%%%5
@article{Chen2016Synthesizing3DPose,
  title={Synthesizing Training Images for Boosting Human 3D Pose Estimation},
  author={W. Chen and Hongxia Wang and Yangyan Li and H. Su and Z. Wang and C. Tu and D. Lischinski and D. Cohen-Or and B. Chen},
  journal={2016 Fourth International Conference on 3D Vision (3DV)},
  year={2016},
  pages={479-488}
}

@INPROCEEDINGS{varol17_surreal,
  title     = {Learning from Synthetic Humans},
  author    = {Varol, G{\"u}l and Romero, Javier and Martin, Xavier and Mahmood, Naureen and Black, Michael J. and Laptev, Ivan and Schmid, Cordelia},
  booktitle = {CVPR},
  year      = {2017}
}

@INPROCEEDINGS{Kuhnke2019,
  author={F. {Kuhnke} and J. {Ostermann}},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Deep Head Pose Estimation Using Synthetic Images and Partial Adversarial Domain Adaption for Continuous Label Spaces}, 
  year={2019},
  volume={},
  number={},
  pages={10163-10172},
  doi={10.1109/ICCV.2019.01026}}
  
  @INPROCEEDINGS{wu2018poseEstimator,
  author={J. {Wu} and B. {Zhou} and R. {Russell} and V. {Kee} and S. {Wagner} and M. {Hebert} and A. {Torralba} and D. M. S. {Johnson}},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Real-Time Object Pose Estimation with Pose Interpreter Networks}, 
  year={2018},
  volume={},
  number={},
  pages={6798-6805},
  doi={10.1109/IROS.2018.8593662}}
  
%%%%%%%%%%
@inproceedings{benchen2009varharmonicmap,
author = {Ben-Chen, Mirela and Weber, Ofir and Gotsman, Craig},
title = {Variational Harmonic Maps for Space Deformation},
year = {2009},
isbn = {9781605587264},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1576246.1531340},
doi = {10.1145/1576246.1531340},
abstract = {A space deformation is a mapping from a source region to a target region within Euclidean space, which best satisfies some userspecified constraints. It can be used to deform shapes embedded in the ambient space and represented in various forms -- polygon meshes, point clouds or volumetric data. For a space deformation method to be useful, it should possess some natural properties: e.g. detail preservation, smoothness and intuitive control. A harmonic map from a domain ω ⊂ Rd to Rd is a mapping whose d components are harmonic functions. Harmonic mappings are smooth and regular, and if their components are coupled in some special way, the mapping can be detail-preserving, making it a natural choice for space deformation applications. The challenge is to find a harmonic mapping of the domain, which will satisfy constraints specified by the user, yet also be detail-preserving, and intuitive to control. We generate harmonic mappings as a linear combination of a set of harmonic basis functions, which have a closed-form expression when the source region boundary is piecewise linear. This is done by defining an energy functional of the mapping, and minimizing it within the linear span of these basis functions. The resulting mapping is harmonic, and a natural "As-Rigid-As-Possible" deformation of the source region. Unlike other space deformation methods, our approach does not require an explicit discretization of the domain. It is shown to be much more efficient, yet generate comparable deformations to state-of-the-art methods. We describe an optimization algorithm to minimize the deformation energy, which is robust, provably convergent, and easy to implement.},
booktitle = {ACM SIGGRAPH 2009 Papers},
articleno = {34},
numpages = {11},
keywords = {harmonic maps, space deformation, shape editing},
location = {New Orleans, Louisiana},
series = {SIGGRAPH '09}
}


@inproceedings{botsch2006primo,
author = {Botsch, Mario and Pauly, Mark and Gross, Markus and Kobbelt, Leif},
title = {PriMo: Coupled Prisms for Intuitive Surface Modeling},
year = {2006},
isbn = {3905673363},
publisher = {Eurographics Association},
address = {Goslar, DEU},
abstract = {We present a new method for 3D shape modeling that achieves intuitive and robust deformations by emulating physically plausible surface behavior inspired by thin shells and plates. The surface mesh is embedded in a layer of volumetric prisms, which are coupled through non-linear, elastic forces. To deform the mesh, prisms are rigidly transformed to satisfy user constraints while minimizing the elastic energy. The rigidity of the prisms prevents degenerations even under extreme deformations, making the method numerically stable. For the underlying geometric optimization we employ both local and global shape matching techniques. Our modeling framework allows for the specification of various geometrically intuitive parameters that provide control over the physical surface behavior. While computationally more involved than previous methods, our approach significantly improves robustness and simplifies user interaction for large, complex deformations.},
booktitle = {Proceedings of the Fourth Eurographics Symposium on Geometry Processing},
pages = {11–20},
numpages = {10},
location = {Cagliari, Sardinia, Italy},
series = {SGP '06}
}
@article{hecker2008realtimeRetargeting,
author = {Hecker, Chris and Raabe, Bernd and Enslow, Ryan W. and DeWeese, John and Maynard, Jordan and van Prooijen, Kees},
title = {Real-Time Motion Retargeting to Highly Varied User-Created Morphologies},
year = {2008},
issue_date = {August 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/1360612.1360626},
doi = {10.1145/1360612.1360626},
abstract = {Character animation in video games---whether manually keyframed or motion captured---has traditionally relied on codifying skeletons early in a game's development, and creating animations rigidly tied to these fixed skeleton morphologies. This paper introduces a novel system for animating characters whose morphologies are unknown at the time the animation is created. Our authoring tool allows animators to describe motion using familiar posing and key-framing methods. The system records the data in a morphology-independent form, preserving both the animation's structural relationships and its stylistic information. At runtime, the generalized data are applied to specific characters to yield pose goals that are supplied to a robust and efficient inverse kinematics solver. This system allows us to animate characters with highly varying skeleton morphologies that did not exist when the animation was authored, and, indeed, may be radically different than anything the original animator envisioned.},
journal = {ACM Trans. Graph.},
month = aug,
pages = {1–11},
numpages = {11},
keywords = {inverse kinematics, motion retargeting, games, procedural animation, user generated content, character animation}
}

@inproceedings{yamne2010animatingnonhumanoid,
author = {Yamane, Katsu and Ariki, Yuka and Hodgins, Jessica},
title = {Animating Non-Humanoid Characters with Human Motion Data},
year = {2010},
publisher = {Eurographics Association},
address = {Goslar, DEU},
abstract = {This paper presents a method for generating animations of non-humanoid characters from human motion capture data. Characters considered in this work have proportion and/or topology significantly different from humans, but are expected to convey expressions and emotions through body language that are understandable to human viewers. Keyframing is most commonly used to animate such characters. Our method provides an alternative for animating non-humanoid characters that leverages motion data from a human subject performing in the style of the target character. The method consists of a statistical mapping function learned from a small set of corresponding key poses, and a physics-based optimization process to improve the physical realism. We demonstrate our approach on three characters and a variety of motions with emotional expressions.},
booktitle = {Proceedings of the 2010 ACM SIGGRAPH/Eurographics Symposium on Computer Animation},
pages = {169–178},
numpages = {10},
location = {Madrid, Spain},
series = {SCA '10}
}

@inproceedings{10.1145/1457515.1409068,
author = {Assa, Jackie and Cohen-Or, Daniel and Yeh, I-Cheng and Lee, Tong-Yee},
title = {Motion Overview of Human Actions},
year = {2008},
isbn = {9781450318310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1457515.1409068},
doi = {10.1145/1457515.1409068},
abstract = {During the last decade, motion capture data has emerged and gained a leading role in animations, games and 3D environments. Many of these applications require the creation of expressive overview video clips capturing the human motion, however sufficient attention has not been given to this problem. In this paper, we present a technique that generates an overview video based on the analysis of motion capture data. Our method is targeted for applications of 3D character based animations, automating, for example, the action summary and gameplay overview in simulations and computer games. We base our method on quantum annealing optimization with an objective function that respects the analysis of the character motion and the camera movement constraints. It automatically generates a smooth camera control path, splitting it to several shots if required. To evaluate our method, we introduce a novel camera placement metric which is evaluated against previous work and conduct a user study comparing our results with the various systems.},
booktitle = {ACM SIGGRAPH Asia 2008 Papers},
articleno = {115},
numpages = {10},
keywords = {animation summary, mocap, salient action, animation, viewpoint selection, camera},
location = {Singapore},
series = {SIGGRAPH Asia '08}
}

@article{elor2017bringingPortraits,
author = {Hadar Averbuch-Elor and  Daniel Cohen-Or and Johannes Kopf and Michael F. Cohen},
title = {Bringing Portraits to Life},
journal = {ACM Transactions on Graphics (Proceeding of SIGGRAPH Asia 2017)},
volume = {36},
number = {6},
pages = {196},
year = {2017},
publisher={ACM}
}

@article{Hornung2007anim2Dpicmotion,
author = {Hornung, Alexander and Dekkers, Ellen and Kobbelt, Leif},
title = {Character Animation from 2D Pictures and 3D Motion Data},
year = {2007},
issue_date = {January 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {1},
issn = {0730-0301},
url = {https://doi.org/10.1145/1189762.1189763},
doi = {10.1145/1189762.1189763},
abstract = {This article presents a new method to animate photos of 2D characters using 3D motion capture data. Given a single image of a person or essentially human-like subject, our method transfers the motion of a 3D skeleton onto the subject's 2D shape in image space, generating the impression of a realistic movement. We present robust solutions to reconstruct a projective camera model and a 3D model pose which matches best to the given 2D image. Depending on the reconstructed view, a 2D shape template is selected which enables the proper handling of occlusions. After fitting the template to the character in the input image, it is deformed as-rigid-as-possible by taking the projected 3D motion data into account. Unlike previous work, our method thereby correctly handles projective shape distortion. It works for images from arbitrary views and requires only a small amount of user interaction. We present animations of a diverse set of human (and nonhuman) characters with different types of motions, such as walking, jumping, or dancing.},
journal = {ACM Trans. Graph.},
month = jan,
pages = {1–es},
numpages = {9},
keywords = {3D motion data, as-rigid-as-possible shape manipulation with perspective correction, 2D character animation, camera and model pose determination}
}

@Inbook{Pan2011,
author="Pan, Junjun
and Zhang, Jian J.",
editor="Pan, Zhigeng
and Cheok, Adrian David
and M{\"u}ller, Wolfgang",
title="Sketch-Based Skeleton-Driven 2D Animation and Motion Capture",
bookTitle="Transactions on Edutainment VI",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="164--181",
abstract="We present a novel sketch-based 2D animation technique, which allows the user to produce 2D character animations efficiently. It consists of two parts, sketch-based skeleton-driven 2D animation production and 2D motion capture. The user inputs one image of the character and sketches the skeleton for each subsequent frame. The system deforms the character and creates animations automatically. To perform 2D shape deformation, a variable-length needle model is introduced to divide the deformation into two stages: skeleton driven deformation and nonlinear deformation in joint areas. It preserves the local geometric features and global area. Compared with existing approaches, it reduces the computation complexity and produces plausible results. Because our technique is skeleton-driven, the motion of character can be captured by tracking joints position and retargeted to a new character. This facilitates the reuse of motion characteristics contained in existing moving images, making the cartoon generation easy for artists and novices alike.",
isbn="978-3-642-22639-7",
doi="10.1007/978-3-642-22639-7_17",
url="https://doi.org/10.1007/978-3-642-22639-7_17"
}

@InProceedings{Siarohin_2019_CVPR,
  author={Siarohin, Aliaksandr and Lathuilière, Stéphane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu},
  title={Animating Arbitrary Objects via Deep Motion Transfer},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2019}
}

@InProceedings{Siarohin_2019_NeurIPS,
  author={Siarohin, Aliaksandr and Lathuilière, Stéphane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu},
  title={First Order Motion Model for Image Animation},
  booktitle = {Conference on Neural Information Processing Systems (NeurIPS)},
  month = {December},
  year = {2019}
}

@inproceedings{kazi2014draco,
  title={Draco: bringing life to illustrations with kinetic textures},
  author={Kazi, Rubaiat Habib and Chevalier, Fanny and Grossman, Tovi and Zhao, Shengdong and Fitzmaurice, George},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={351--360},
  year={2014}
}

@inproceedings{su2018livesketch,
  title={Live sketch: Video-driven dynamic deformation of static drawings},
  author={Su, Qingkun and Bai, Xue and Fu, Hongbo and Tai, Chiew-Lan and Wang, Jue},
  booktitle={Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2018}
}

@article{jain:2012,
author = {Jain, Eakta and Sheikh, Yaser and Mahler, Moshe and Hodgins, Jessica},
title = {Three-dimensional proxies for hand-drawn characters},
journal = {ACM Trans. Graph.},
issue_date = {January 2012},
volume = {31},
number = {1},
month = feb,
year = {2012},
pages = {8:1--8:16},
articleno = {8},
numpages = {16}
}

@Article{Dvoroznak18-SIG,
    author    = "Marek Dvoro\v{z}\v{n}\'{a}k and Wilmot Li and Vladimir G. Kim and Daniel S\'{y}kora",
    title     = "{ToonSynth}: {Example}-Based Synthesis of Hand-Colored Cartoon Animations",
    journal   = "ACM Transactions on Graphics",
    volume    = "37",
    number    = "4",
    articleno = "167",
    year      = "2018",
}

@InProceedings{Zheng_2020_CVPR,
author = {Zheng, Qingyuan and Li, Zhuoru and Bargteil, Adam},
title = {Learning to Shadow Hand-Drawn Sketches},
booktitle = {The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@article{eitz2012humans,
  title={How do humans sketch objects?},
  author={Eitz, Mathias and Hays, James and Alexa, Marc},
  journal={ACM Transactions on graphics (TOG)},
  volume={31},
  number={4},
  pages={1--10},
  year={2012},
  publisher={Acm New York, NY, USA}
}

@article{lee2011shadowdraw,
  title={Shadowdraw: real-time user guidance for freehand drawing},
  author={Lee, Yong Jae and Zitnick, C Lawrence and Cohen, Michael F},
  journal={ACM Transactions on Graphics (TOG)},
  volume={30},
  number={4},
  pages={1--10},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@article{DBLP:journals/corr/abs-2001-02600,
  author    = {Peng Xu},
  title     = {Deep Learning for Free-Hand Sketch: {A} Survey},
  journal   = {CoRR},
  volume    = {abs/2001.02600},
  year      = {2020},
  url       = {http://arxiv.org/abs/2001.02600},
  archivePrefix = {arXiv},
  eprint    = {2001.02600},
  timestamp = {Mon, 13 Jan 2020 12:40:17 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2001-02600.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{davis2006sketching,
  title={A sketching interface for articulated figure animation},
  author={Davis, James and Agrawala, Maneesh and Chuang, Erika and Popovi{\'c}, Zoran and Salesin, David},
  booktitle={Acm siggraph 2006 courses},
  pages={15--es},
  year={2006}
}

@article{bregler2002turning,
  title={Turning to the masters: Motion capturing cartoons},
  author={Bregler, Christoph and Loeb, Lorie and Chuang, Erika and Deshpande, Hrishi},
  journal={ACM Transactions on Graphics (TOG)},
  volume={21},
  number={3},
  pages={399--407},
  year={2002},
  publisher={ACM New York, NY, USA}
}

@article{ha2017neural,
  title={A neural representation of sketch drawings},
  author={Ha, David and Eck, Douglas},
  journal={arXiv preprint arXiv:1704.03477},
  year={2017}
}

@inproceedings{choi2012retrieval,
  title={Retrieval and visualization of human motion data via stick figures},
  author={Choi, Myung Geol and Yang, Kyungyong and Igarashi, Takeo and Mitani, Jun and Lee, Jehee},
  booktitle={Computer Graphics Forum},
  volume={31},
  number={7},
  pages={2057--2065},
  year={2012},
  organization={Wiley Online Library}
}

@inproceedings{zhang2018context,
  title={Context-based sketch classification},
  author={Zhang, Jianhui and Chen, Yilan and Li, Lei and Fu, Hongbo and Tai, Chiew-Lan},
  booktitle={Proceedings of the Joint Symposium on Computational Aesthetics and Sketch-Based Interfaces and Modeling and Non-Photorealistic Animation and Rendering},
  pages={1--10},
  year={2018}
}

@book{kellogg1967rhoda,
  title={Rhoda Kellogg child art collection},
  author={Kellogg, Rhoda},
  year={1967},
  publisher={Microcard Editions}
}

 @INPROCEEDINGS{7780494,
  author={H. {Zhang} and S. {Liu} and C. {Zhang} and W. {Ren} and R. {Wang} and X. {Cao}},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={SketchNet: Sketch Classification with Web Images}, 
  year={2016},
  volume={},
  number={},
  pages={1105-1113},
  doi={10.1109/CVPR.2016.125}}
  
  @inproceedings{10.1145/2911996.2912067,
author = {Ye, Yuxiang and Lu, Yijuan and Jiang, Hao},
title = {Human's Scene Sketch Understanding},
year = {2016},
isbn = {9781450343596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2911996.2912067},
doi = {10.1145/2911996.2912067},
abstract = {Human's sketch understanding is important. It has many applications in human computer interaction, multimedia, and computer vision. Recognizing human sketches is also challenging. Previous methods focus on single-object sketch recognition. Understanding human's scene sketch that involves multiple objects and their complex interactions has not been explored. In this paper, we tackle this new problem. We create the first scene sketch dataset "Scene250" and propose a deep learning method to understand human scene sketches. We propose "Scene-Net", a new deep convolutional neural network (CNN) structure, based on which we build a novel scene sketch recognition system. Our system has been tested on the collected scene sketch dataset and compared with other state-of-the-art CNNs and sketch recognition approaches. Our experimental results demonstrate that our method achieves the state of art.},
booktitle = {Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval},
pages = {355–358},
numpages = {4},
keywords = {sketch understanding, scene sketch, deep learning},
location = {New York, New York, USA},
series = {ICMR '16}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@misc{IndianaS55:online,
author = {Bradford B. Venable},
title = {Web Archive of Children's Art},
howpublished = {\url{http://childart.indstate.edu/}},
month = {11},
year = {2022},
note = {(Accessed on 11/26/2022)}
}

@inproceedings{DBLP:conf/siggraph/Ebihara98,
  author    = {Kazuyuki Ebihara},
  editor    = {Scott Crisson and
               Janet McAndless},
  title     = {Shall we dance?},
  booktitle = {{ACM} {SIGGRAPH} 98 Conference Abstracts and Applications, Orlando,
               Florida, USA, July 19-24, 1998},
  pages     = {124},
  publisher = {{ACM}},
  year      = {1998},
  url       = {https://doi.org/10.1145/280953.281328},
  doi       = {10.1145/280953.281328},
  timestamp = {Tue, 06 Nov 2018 16:59:13 +0100},
  biburl    = {https://dblp.org/rec/conf/siggraph/Ebihara98.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{huang2019mask,
  title={Mask scoring r-cnn},
  author={Huang, Zhaojin and Huang, Lichao and Gong, Yongchao and Huang, Chang and Wang, Xinggang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6409--6418},
  year={2019}
}

@article{dziurawiec1992twisted,
  title={‘Twisted perspective’ in young children's drawings},
  author={Dziurawiec, S and Deregowski, JB},
  journal={British Journal of Developmental Psychology},
  volume={10},
  number={1},
  pages={35--49},
  year={1992},
  publisher={Wiley Online Library}
}

@article{mmdetection,
  title   = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark},
  author  = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and
             Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and
             Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and
             Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and
             Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong
             and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},
  journal= {arXiv preprint arXiv:1906.07155},
  year={2019}
}

@misc{mmpose2020,
    title={OpenMMLab Pose Estimation Toolbox and Benchmark},
    author={MMPose Contributors},
    howpublished = {\url{https://github.com/open-mmlab/mmpose}},
    year={2020}
}

@book{gonzalez2008digital,
  abstract = {Completely self-contained-and heavily illustrated-this introduction to basic concepts and methodologies for digital image processing is written at a level that truly is suitable for seniors and first-year graduate students in almost any technical discipline. The leading textbook in its field for more than twenty years, it continues its cutting-edge focus on contemporary developments in all mainstream areas of image processing-e.g., image fundamentals, image enhancement in the spatial and frequency domains, restoration, color image processing, wavelets, image compression, morphology, segmentation, image description, and the fundamentals of object recognition. It focuses on material that is fundamental and has a broad scope of application.},
  added-at = {2014-07-10T10:50:48.000+0200},
  address = {Upper Saddle River, N.J.},
  author = {Gonzalez, Rafael C. and Woods, Richard E.},
  biburl = {https://www.bibsonomy.org/bibtex/2bd73f6e1350f31aa5da16268e2b1e694/alex_ruff},
  description = {Digital Image Processing (3rd Edition): Rafael C. Gonzalez, Richard E. Woods: 9780131687288: Amazon.com: Books},
  interhash = {74494247f343d0cedb198c4b4f0c31eb},
  intrahash = {bd73f6e1350f31aa5da16268e2b1e694},
  isbn = {9780131687288 013168728X 9780135052679 013505267X},
  keywords = {book image_processing},
  publisher = {Prentice Hall},
  refid = {137312858},
  timestamp = {2014-07-10T10:50:48.000+0200},
  title = {Digital image processing},
  url = {http://www.amazon.com/Digital-Image-Processing-3rd-Edition/dp/013168728X},
  year = 2008
}

@article{chen2020improved,
  title={Improved baselines with momentum contrastive learning},
  author={Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  journal={arXiv preprint arXiv:2003.04297},
  year={2020}
}

@article{picard2014ipads,
  title={iPads at school? A quantitative comparison of elementary schoolchildren's pen-on-paper versus finger-on-screen drawing skills},
  author={Picard, Delphine and Martin, Perrine and Tsao, Raphaele},
  journal={Journal of Educational Computing Research},
  volume={50},
  number={2},
  pages={203--212},
  year={2014},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}
  
  @misc{animateddrawings,
    author = "Meta",
    title = "Animated Drawings",
    year = "2022",
    url = "https://sketch.metademolab.com",
    note = "[Online; accessed 16-August-2022]"
  }  
  
  @article{DeepHistory,
author = {Ysique-Neciosup, Jose and Mercado-Chavez, Nilton and Ugarte, Willy},
title = {DeepHistory: A convolutional neural network for automatic animation of museum paintings},
journal = {Computer Animation and Virtual Worlds},
volume = {n/a},
number = {n/a},
pages = {e2110},
keywords = {convolutional neural network, image animation, keypoints, U-Net, video super-resolution},
doi = {https://doi.org/10.1002/cav.2110},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cav.2110},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cav.2110},
abstract = {Abstract Deep learning models have shown that it is possible to train neural networks to dispense, to a lesser or greater extent, with the need for human intervention for the task of image animation, which helps to reduce not only the production time of these audiovisual pieces, but also presents benefits with respect to the economic investment they require to be made. However, these models suffer from two common problems: the animations they generate are of very low resolution and they require large amounts of training data to generate good results. To deal with these issues, this article introduces the architectural modification of a state-of-the-art image animation model integrated with a video super-resolution model to make the generated videos more visually pleasing to viewers. Although it is possible to train the animation models with higher resolution images, the time it would take to train them would be much longer, which does not necessarily benefit the quality of the animation, so it is more efficient to complement it with another model focused on improving the animation resolution of the generated video as we demonstrate in our results. We present the design and implementation of a convolutional neural network based on an state-of-art model focused on the image animation task, which is trained with a set of facial data from videos extracted from the YouTube platform. To determine which of all the modifications to the selected state-of-the-art model architecture is better, the results are compared with different metrics that evaluate the performance in image animation and video quality enhancement tasks. The results show that modifying the architecture of the model focused on the detection of characteristic points significantly helps to generate more anatomically and visually attractive videos. In addition, perceptual testing with users shows that using a super-resolution video model as a plugin helps generate more visually appealing videos.}
}

@inproceedings{weng2019photo,
  title={Photo wake-up: 3d character animation from a single photo},
  author={Weng, Chung-Yi and Curless, Brian and Kemelmacher-Shlizerman, Ira},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5908--5917},
  year={2019}
}

@article{yaniv2019face,
  title={The face of art: landmark detection and geometric style in portraits},
  author={Yaniv, Jordan and Newman, Yael and Shamir, Ariel},
  journal={ACM Transactions on graphics (TOG)},
  volume={38},
  number={4},
  pages={1--15},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{Fan:2018:TAL,
   author = "Xinyi Fan and Amit H. Bermano and Vladimir G. Kim and Jovan Popovi{\'c}
      and Szymon Rusinkiewicz",
   title = "{ToonCap}: A Layered Deformable Model for Capturing Poses From Cartoon
      Characters",
   booktitle = "Expressive",
   year = "2018",
   month = aug
}

@inproceedings{poursaeed2020neural,
  title={Neural puppet: Generative layered cartoon characters},
  author={Poursaeed, Omid and Kim, Vladimir and Shechtman, Eli and Saito, Jun and Belongie, Serge},
  booktitle={The IEEE Winter Conference on Applications of Computer Vision},
  pages={3346--3356},
  year={2020}
}

@article{magnenat2015live,
  title={Live texturing of augmented reality characters from colored drawings},
  author={Magnenat, St{\'e}phane and Ngo, Dat Tien and Z{\"u}nd, Fabio and Ryffel, Mattia and Noris, Gioacchino and Rothlin, Gerhard and Marra, Alessia and Nitti, Maurizio and Fua, Pascal and Gross, Markus and others},
  journal={IEEE transactions on visualization and computer graphics},
  volume={21},
  number={11},
  pages={1201--1210},
  year={2015},
  publisher={IEEE}
}

@incollection{barnes2008video,
  title={Video puppetry: a performative interface for cutout animation},
  author={Barnes, Connelly and Jacobs, David E and Sanders, Jason and Goldman, Dan B and Rusinkiewicz, Szymon and Finkelstein, Adam and Agrawala, Maneesh},
  booktitle={ACM SIGGRAPH Asia 2008 papers},
  pages={1--9},
  year={2008}
}

@article{ArtiSketch,
author = {Levi, Zohar and Gotsman, Craig},
title = {ArtiSketch: A System for Articulated Sketch Modeling},
journal = {Computer Graphics Forum},
volume = {32},
number = {2pt2},
pages = {235-244},
doi = {https://doi.org/10.1111/cgf.12043},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12043},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.12043},
abstract = {Abstract We present ArtiSketch – a system which allows the conversion of a wealth of existing 2D content into 3D content by users who do not necessarily possess artistic skills. Using ArtiSketch, a novice user may describe a 3D model as a set of articulated 2D sketches of a shape from different viewpoints. ArtiSketch then automatically converts the sketches to an articulated 3D object. Using common interactive tools, the user provides an initial estimate of the 3D skeleton pose for each frame, which ArtiSketch refines to be consistent between frames. This skeleton may then be manipulated independently to generate novel poses of the 3D model.},
year = {2013}
}

@inproceedings{hinz2022charactergan,
  title={CharacterGAN: Few-Shot Keypoint Character Animation and Reposing},
  author={Hinz, Tobias and Fisher, Matthew and Wang, Oliver and Shechtman, Eli and Wermter, Stefan},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1988--1997},
  year={2022}
}

@inproceedings{held20123d,
  title={3D puppetry: a kinect-based interface for 3D animation.},
  author={Held, Robert and Gupta, Ankit and Curless, Brian and Agrawala, Maneesh},
  booktitle={UIST},
  volume={12},
  pages={423--434},
  year={2012},
  organization={Citeseer}
}

@ARTICLE{6682899,  author={Ionescu, Catalin and Papava, Dragos and Olaru, Vlad and Sminchisescu, Cristian},  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},   title={Human3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments},   year={2014},  volume={36},  number={7},  pages={1325-1339},  doi={10.1109/TPAMI.2013.248}}

@article{chen2020monocular,
  title={Monocular human pose estimation: A survey of deep learning-based methods},
  author={Chen, Yucheng and Tian, Yingli and He, Mingyi},
  journal={Computer Vision and Image Understanding},
  volume={192},
  pages={102897},
  year={2020},
  publisher={Elsevier}
}

@INPROCEEDINGS{6126221,  author={Chen, Yu and Kim, Tae-Kyun and Cipolla, Roberto},  booktitle={2011 International Conference on Computer Vision},   title={Silhouette-based object phenotype recognition using 3D shape priors},   year={2011},  volume={},  number={},  pages={25-32},  doi={10.1109/ICCV.2011.6126221}}

@article{gall2010optimization,
  title={Optimization and filtering for human motion capture},
  author={Gall, Juergen and Rosenhahn, Bodo and Brox, Thomas and Seidel, Hans-Peter},
  journal={International journal of computer vision},
  volume={87},
  number={1},
  pages={75--92},
  year={2010},
  publisher={Springer}
}

@inproceedings{chen2022bizarre,
    title={Transfer Learning for Pose Estimation of Illustrated Characters},
    author={Chen, Shuhong and Zwicker, Matthias},
    booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
    year={2022}
}

@article{brodt2022sketch2pose,
    author = {Kirill Brodt and Mikhail Bessmeltsev},
    title = {Sketch2Pose: Estimating a 3D Character Pose from a Bitmap Sketch},
    journal = {ACM Transactions on Graphics},
    year = {2022},
    month = {7},
    volume = {41},
    number = {4},
    doi = {10.1145/3528223.3530106},
}

@inproceedings{sapp2010cascaded,
  title={Cascaded models for articulated pose estimation},
  author={Sapp, Benjamin and Toshev, Alexander and Taskar, Ben},
  booktitle={European conference on computer vision},
  pages={406--420},
  year={2010},
  organization={Springer}
}

@INPROCEEDINGS{6909866,
  author={Andriluka, Mykhaylo and Pishchulin, Leonid and Gehler, Peter and Schiele, Bernt},
  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={2D Human Pose Estimation: New Benchmark and State of the Art Analysis}, 
  year={2014},
  volume={},
  number={},
  pages={3686-3693},
  doi={10.1109/CVPR.2014.471}}
  
@incollection{ramanan2011part,
  title={Part-based models for finding people and estimating their pose},
  author={Ramanan, Deva},
  booktitle={Visual Analysis of Humans},
  pages={199--223},
  year={2011},
  publisher={Springer}
}
  
  @inproceedings{10.1145/3011549.3011552,
author = {Khungurn, Pramook and Chou, Derek},
title = {Pose Estimation of Anime/Manga Characters: A Case for Synthetic Data},
year = {2016},
isbn = {9781450347846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3011549.3011552},
doi = {10.1145/3011549.3011552},
abstract = {2D articulated pose estimation is the task of locating the body joint positions of a human figure in an image. A pose estimator that works on anime/manga images could be an important component of an automatic system to create 3D animation from existing manga or anime, which could significantly the lower cost of media production. To create an accurate pose estimator, however, a sizable and high-quality dataset is needed, and such a dataset can be expensive to create.To alleviate data scarcity, we propose using a database of 3D character models and poses to generate synthetic training data for 2D pose estimators of anime/manga characters based on convolutional neural networks (CNN). We demonstrate that a high-performing estimator can be obtained by pretraining a network on a large synthetic dataset and then fine-tuning it on a small dataset of drawings. We also show that the approach yields a pose estimator competitive with many previous works when applied to a photograph-based dataset, establishing our synthetic data's usefulness beyond the intended domain.},
booktitle = {Proceedings of the 1st International Workshop on CoMics ANalysis, Processing and Understanding},
articleno = {3},
numpages = {6},
keywords = {pose estimation, synthetic data},
location = {Cancun, Mexico},
series = {MANPU '16}
}

@book{luquet1913dessins,
  title={Les dessins d'un enfant: {\'e}tude psychologique},
  author={Luquet, Georges Henri},
  year={1913},
  publisher={Alcan}
}

@book{sully2021studies,
  title={Studies of childhood},
  author={Sully, James},
  year={2021},
  publisher={Good Press}
}

@article{barnes1892study,
  title={A study on children's drawings},
  author={Barnes, Earl},
  journal={The pedagogical seminary},
  volume={2},
  number={3},
  pages={455--463},
  year={1892},
  publisher={Taylor \& Francis}
}

@article{clark1897child,
  title={The child's attitude towards perspective problems},
  author={Clark, Arthur B},
  journal={Studies in education},
  volume={1},
  number={18},
  pages={283--294},
  year={1897},
  publisher={Stanford University Press Stanford, CA}
}

@book{buhler2013mental,
  title={The mental development of the child: A summary of modern psychological theory},
  author={Buhler, Karl},
  year={2013},
  publisher={Routledge}
}

@article{wilson1982case,
  title={The case of the disappearing two-eyed profile: Or how little children influence the drawings of little children},
  author={Wilson, Marjorie and Wilson, Brent},
  journal={Review of research in visual arts education},
  pages={19--32},
  year={1982},
  publisher={JSTOR}
}

@book{cox2014drawings,
  title={Drawings of people by the under-5s},
  author={Cox, Maureen V and Cox, Maureen},
  year={2014},
  publisher={Routledge}
}

@book{piaget1956,
  title={The Child's Conception of Space},
  author={Piaget, J. \& Inhelder, B},
  year={1956},
  publisher={Routledge \& Kegan Paul}
}

@article{marr1982vision,
  title={Vision: A computational investigation into the human representation and processing of visual information, henry holt and co},
  author={Marr, David},
  journal={Inc., New York, NY},
  volume={2},
  number={4.2},
  year={1982}
}

@article{doi:10.1080/01443410500344167,
    author = { Isabelle D.   Cherney  and  Clair S.   Seiwert  and  Tara M.   Dickey  and  Judith D.   Flichtbeil },
    title = {Children’s Drawings: A mirror to their minds},
    journal = {Educational Psychology},
    volume = {26},
    number = {1},
    pages = {127-142},
    year  = {2006},
    publisher = {Routledge},
    doi = {10.1080/01443410500344167},
    URL = {https://doi.org/10.1080/01443410500344167},
    eprint = {https://doi.org/10.1080/01443410500344167}
    }

@book{goodenough1926measurement,
  title={Measurement of Intelligence by Drawings},
  author={Goodenough, F.L.},
  isbn={9780598637451},
  lccn={26018644},
  series={Classics in child development},
  url={https://books.google.com/books?id=lrmcAAAAMAAJ},
  year={1926},
  publisher={World book Company}
}

@article{chambers1983stereotypic,
  title={Stereotypic images of the scientist: The draw-a-scientist test},
  author={Chambers, David Wade},
  journal={Science education},
  volume={67},
  number={2},
  pages={255--265},
  year={1983},
  publisher={Hoboken}
}

@book{geist2002they,
  title={They still draw pictures: Children's art in wartime from the Spanish Civil War to Kosovo},
  author={Geist, Anthony L and Carroll, Peter N},
  year={2002},
  publisher={University of Illinois Press}
}

@article {AWebbasedDatabaseforDrawingsofGods,
      author = "Zhargalma Dandarova Robert and Grégory Dessart and Olga Serbaeva and Camelia Puzdriac and Mohammad Khodayarifard and Saeed Akbari Zardkhaneh and Saeid Zandi and Elena Petanova and Kevin L. Ladd and Pierre-Yves Brandt",
      title = "A Web-based Database for Drawings of Gods: When the Digitals Go Multicultural",
      journal = "Archive for the Psychology of Religion",
      year = "2016",
      publisher = "Brill",
      address = "Leiden, The Netherlands",
      volume = "38",
      number = "3",
      doi = "https://doi.org/10.1163/15736121-12341326",
      pages=      "345 - 352",
      url = "https://brill.com/view/journals/arp/38/3/article-p345_5.xml"
}


@inproceedings{toshev2014deeppose,
  title={Deeppose: Human pose estimation via deep neural networks},
  author={Toshev, Alexander and Szegedy, Christian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1653--1660},
  year={2014}
}

@inproceedings{guler2018densepose,
  title={Densepose: Dense human pose estimation in the wild},
  author={ G{\"u}ler, R{\i}za Alp and Neverova, Natalia and Kokkinos, Iasonas},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7297--7306},
  year={2018}
}

@article{alphapose,
  author = {Fang, Hao-Shu and Li, Jiefeng and Tang, Hongyang and Xu, Chao and Zhu, Haoyi and Xiu, Yuliang and Li, Yong-Lu and Lu, Cewu},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title = {AlphaPose: Whole-Body Regional Multi-Person Pose Estimation and Tracking in Real-Time},
  year = {2022}
}