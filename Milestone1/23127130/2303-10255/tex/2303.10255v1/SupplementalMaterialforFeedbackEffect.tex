\beginsupplement

\appendix
\onecolumn % 

\section*{Supplemental Material for ``How the Feedback Effect Shapes User Behavior with Intelligent Assistants''}
\section{Observational Study on IA's Helpfulness and users Engagement}
\subsection{Balancing Weights}
Li \citeSM{li2018balancing} proposed a family of balancing weights which enjoys balanced weighted distributions of covariates among treatment groups. , which enjoys balanced weighted distributions of covariates among treatment groups. Inverse-probability weights (IPW) is a special case of this family. Let $f(x)$ denotes the covariates distribution of the population, and $f_0(x), f_1(x)$ as the control or treatment group distribution respectively. 

With the balancing weights and tilting function $h(x)$, the weighted distributions for different treatment groups are evened out.
\begin{equation*}
    f_1(x)w_1(x)=f_0(x)w_0(x)=f(x)h(x),
\end{equation*}
The tilting function defines the target population and the estimands of interest, and also determined the weights accordingly. \begin{equation}\label{eq:balancingWt}
        \begin{cases}     w^{h}_1(x) \propto \frac{h(x)}{e(x)},& \text{for }Z=  1\\      w^{h}_0(x) \propto \frac{h(x)}{1-e(x)},& \text{for }Z=0. \end{cases}
\end{equation}
The population level causal estimands of interest, the weighted average treatment effect (WATE) shown in Eq.\eqref{eq:WATEfull}, is based on the balancing weights.
\begin{equation}\label{eq:WATEfull}
    \hat{\tau}=\hat{\mu}_1-\hat{\mu}_0=\frac{\sum_{i=1}^Nz^{h}_1(\bf{x_i})Z_iY_i}{\sum_{i=1}^Nz^{h}_1(\bf{x_i})Z_i} - \frac{\sum_{i=1}^Nz^{h}_0(\bf{x_i})Z_iY_i}{\sum_{i=1}^Nz^{h}_0(\bf{x_i})Z_i}.
\end{equation}
When $h(x)=1$, it is the inverse-probability weights (IPW). As the name suggested, the inverse of the probability that a unit is assigned to the observed group is the weight, and the corresponding estimand is ATE.

In Table~\ref{tab:balance}, it summarizes some weights from the balancing weights family.
\begin{table}[ht]
\centering
\begin{tabular}{@{}lll@{}}
\toprule
Method  & Target population & Tilting function $h(x)$                                                                                                              \\ \midrule
IPW     & Combined          & $1$                                                                                                                   \\
OW      & Overlapped        & $e(x)(1-e(x))$                                                                                                      \\
Entropy & Entropy based     & \begin{tabular}[c]{@{}l@{}} $e(x)\log(e(x))$ \\ - $(1-e(x))\log(1-e(x))$\end{tabular} \\ \bottomrule
\end{tabular}
\caption{Target population, tilting functions comparison for the balancing weights methods}\label{tab:balance}
\end{table}

\subsection{Outcome: time-to-next-engagement}
We have summarized our analysis pipeline in Algorithm~\ref{algo:causalSurvival}. Starting from estimating the pseudo-observations and propensity scores, then combining together to obtain the final weighted causal effect, re-engagement probability difference.
\begin{algorithm}[h]
\SetAlgoLined
{\bf Input:} Confounding variables $\Xmat$, IA helpfulness indicator $\Zmat$, observed time-to-next-engagement or censored time $\tilde{T}$ with censoring indicator $\Delta$.\\
\For{$t \in (0, t_{max}]$}{
{\bf Step 1:} Obtain pseudo-observations $\hat{\theta}_i(t)$\\
{\bf Step 2:} Estimate propensity score $\hat{e}(x)$\\
{\bf Step 3:} Calculate balancing weights $w_1(x), w_0(x)$ Eq.~\eqref{eq:OverlapWeight}\\
{\bf Step 4:} Derive the causal estimands of re-engagement probability difference (RPCE) $\hat{\tau}^w(t)$ Eq.~\eqref{eq:pseudo-survival}\\
}
 \caption{Causal discoveries of IA helpfulness on users time-to-next-engagement.}
 \label{algo:causalSurvival}
\end{algorithm}

Apart from the OW results presented in the main context, the IPW-weighted RPCE implies similar conclusions, as presented in Figure~\ref{fig:IPWtime2next}. The IPW results yield a significant difference in the time window between hours 16-50 with $p$-values $<0.05$. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=.8\linewidth]{causalResults/IPWtime2next.png}
    \caption{The re-engagement probability causal estimands (RPCE) as a function of time after the annotated interaction, with associated 95\% confidence interval (shaded gray). 
    The dotted horizontal line represents the difference is 0.
    The average re-engagement probability in \emph{Unhelpful} cohort is lower than \emph{Helpful} cohort in the following 336 hours (2 weeks) period. The significant gap happens around the $8 \sim 65$ hours with p-value $<0.05$.
    }
    \label{fig:IPWtime2next}
\end{figure}



\section{Language Convergence}
\subsection{Discussions on Different Language Complexity Metrics}
Sentence complexity provides a linguistic measurement of user requests. Some simple metrics of sentence complexity are the number of tokens and the number of distinct N-grams per request \citeSM{xu2018diversity}. These are quite intuitive but hardly reveal deep insights into the requests \citeSM{evans2009myth}. To compare the sentence complexity of new requests with existing ones, there are three common metrics. Two of them, the selfBlEU score and the Jaccard similarity, are pairwise metrics based on overlapping N-grams between target and reference sentences \citeSM{zhu2018texygen,niwattanakul2013using}. The third one, word embedding diversity (WED) measures cosine distances of word embeddings of sentences in comparison.
Yet, these metrics are computationally inefficient owning to the enumeration of sentences in large datasets. On the other hand, the perplexity score (PP) is a scalable and informative metric that reveals both the syntactic complexity and the lexical diversity of a new request within a given text based on a trained language model \citeSM{holtzman2019curious}. Researches have also shown that the PP score of user requests inversely correlates with the success of the subsequent IA response: the higher the PP score, the more complex the request, the less likely the subsequent IA response is going to be successful \citeSM{adiwardana2020towards}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=.7\linewidth]{causalResults/pavlovHighvsLow.png}
    \caption{Language diversity for helpful utterances and unhelpful utterances. The bootstrapping results have shown that the unhelpful group has greater diversity with all three diversity metrics.}
    \label{fig:pairDiv}
\end{figure}

We first quantify the diversity with three widely used pairwise-based metrics without considering domain specific PP scores, i) selfBLEU: measures the diversity within the utterances cluster, i.e., average (1-pairwise BLEU score) ii) Jaccard similarity: average (1- pairwise word overlap) within the group iii) Word Embedding Diversity (WED): average (1- pairwise cosine distance) among embeddings of vectors in the utterances set. From Table~\ref{fig:pairDiv}, the unhelpful interactions have significantly larger diversities than the helpful group in general.
Also, to check the language diversity changing over time, we have run the above analysis on a group of likely new users (non-habitual) against a group of habitual users (in Figure ~\ref{fig:userDivPair}). From the exploratory analysis, the unhelpful interactions cohort and new users cohort share a high diversity in common.

\begin{figure}[ht]
    \centering
    \includegraphics[width=.7\linewidth]{causalResults/NEWvsEXISTING.png}
    \caption{Language diversity for new and existing users cohort. Obviously the new group has greater diversity.}
    \label{fig:userDivPair}
\end{figure}

 Revisiting the datasets described in Section~\ref{sec:causalData}, we further studied the correlation between language perplexity and the human-label review of helpfulness. 
As illustrated in the $2\times 2$ contingency table (Table ~\ref{tab:helpfulness-preplexity}), roughly 20\% of high perplexity requests are unhelpful, on the contrary, only 6\% of low perplexity ones are unhelpful. The association between perplexity score and IA helpfulness is statistically significant with p-value less than $0.0001$. 

% \begin{wraptable}{l}{.45\columnwidth}
\begin{table}[t]
\centering
%\vspace{-8pt}
\resizebox{.5\columnwidth}{!}{
\begin{tabular}{ccc|c}
\hline
          & High Perplexity & Low Perplexity & Total \\ \hline
Helpful   & 1245            & 11592          & 12837 \\
Unhelpful & 308             & 839            & 1147  \\ \hline
Total     & 1553            & 12431          & 13984 \\ \hline
\end{tabular}
}
    \caption{Contingency table of IA Quality (helpful vs.\ unhelpful) and PP score, with a statistically significant correlation. 
    % The association is statistically significant: IA responses to High Perplexity requests are more likely to be unhelpful.
    }
    \label{tab:helpfulness-preplexity}
    \vspace{-2.5em}
\end{table}
% \end{wraptable}
%


Revisiting the datasets described in Section~\ref{sec:causalData}, we studied the correlation between language perplexity and the human-label review of helpfulness. 
% As illustrated in the $2\times 2$ contingency table (Table ~\ref{tab:helpfulness-preplexity}), 
About 20\% of high perplexity requests are unhelpful, compared to 6\% of low perplexity ones. 
The association between perplexity score and IA helpfulness is statistically significant with $p$-value $< 1\mathrm{e}{-4}$ with the Chi-squared test (Table ~\ref{tab:helpfulness-preplexity}).


\vspace{-0.8em}
\subsection{Evaluation Metrics for Request Complexity}

% For any user request, complexity can be evaluated along the following dimensions:
We evaluate user requests complexity along the following dimensions:
\begin{enumerate}
    \item \textbf{Syntactic complexity.} The same intent can be expressed in numerous ways, using varying levels of complexity of sentence structure. For example, ``call mom'' and ``place a telephone call to my mom please'' express the same intent, but the latter is more complex structurally. 
    \item  \textbf{Sub-intents entanglement within a request.} The level of detail required to address a user request may vary, with more complex intents requiring more detailed answers. For example, a simple request could be ``Is it going to snow today?'' and a more complex one could be ``How many inches of snow are we expecting over the next 7 days?''.
    \item  \textbf{Lexical and semantic diversity of the request.} Unlike common topics within a domain, infrequent topics are more difficult for the IA to handle. For example, within the weather domain, users commonly ask about the \emph{weather}, \emph{temperature}, and \emph{rain}, while diverse items include topics like \emph{wind}, \emph{tide}, \emph{barometric}, \emph{moon}, and \emph{tornado}. 
\end{enumerate}
%

% \ZX{\cite{adiwardana2020towards} for superior of perplexity score}

% \textbf{Model based language perplexity.} 
% 
Task-oriented IA systems often have a list of predefined domains: \textit{Weather}, \textit{Payment}, \textit{Phone}, \textit{Music}, \textit{LocalBusiness}, etc. Consequently, requests in a specific domain often share typical recurrent linguistic patterns. 
% \YHZ{consider "share a typical recurrent linguistic pattern"?}. 
As a consequence, it is important to examine language diversity on a by-domain level, rather than on the dataset as a whole. This is because different domains may have different vocabulary sizes and high frequency tokens. 
% If we only consider the marginal language diversities 
% \YHZ{marginal again} 
% in different cohorts of users, true signals can be buried underneath.
To evaluate the complexity and diversity of a request, a simple metric like vocabulary size may be helpful in some utility domains (\EG, timer, alarm), but it could be misleading in communication domains (\EG,, phone call, SMS). Specifically, in communication domains, vocabulary size may be biased by the request's content (or payload) rather than the sophistication with which users express their intent. For example, if a user sends a longer message, the vocabulary size will increase accordingly, but the way they ask the IA to send the message may remain the same. 
Pairwise comparison metrics such as the previously mentioned selfBLEU, Jaccard, and WED are sensitive to keywords and topics, but they do not distinguish payload from non-payload content.
% where we expect much greater diversity of content due to the prevalence of payloads. Specifically, vocabulary diversity measures may be sensitive to the content (or payload) of the request rather than to the sophistication with which users express their request. Further, if a user sends a longer message, the vocabulary size increases accordingly. 
% The euclidean distance derived from sentence embeddings tends to be sensitive to keyword and topics, but they do not distinguish payload from non-payload content. Lastly, user-level domain and intent distribution are vulnerable to data scarcity from low usage users. For all these reasons, properly capturing user request complexity at a global level is challenging. 
% \YHZ{I am a little confused by what message this paragraph wants to convey. The points this paragraph intends to convey might be a little too many.}



% \subsection*{References}
\break
\bibliographystyleSM{splncs04}
\bibliographySM{FeedbackEffect-Full}