{
    "arxiv_id": "2303.10255",
    "paper_title": "Feedback Effect in User Interaction with Intelligent Assistants: Delayed Engagement, Adaption and Drop-out",
    "authors": [
        "Zidi Xiu",
        "Kai-Chen Cheng",
        "David Q. Sun",
        "Jiannan Lu",
        "Hadas Kotek",
        "Yuhan Zhang",
        "Paul McCarthy",
        "Christopher Klein",
        "Stephen Pulman",
        "Jason D. Williams"
    ],
    "submission_date": "2023-03-17",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.HC",
        "cs.CL"
    ],
    "abstract": "With the growing popularity of intelligent assistants (IAs), evaluating IA quality becomes an increasingly active field of research. This paper identifies and quantifies the feedback effect, a novel component in IA-user interactions: how the capabilities and limitations of the IA influence user behavior over time. First, we demonstrate that unhelpful responses from the IA cause users to delay or reduce subsequent interactions in the short term via an observational study. Next, we expand the time horizon to examine behavior changes and show that as users discover the limitations of the IA's understanding and functional capabilities, they learn to adjust the scope and wording of their requests to increase the likelihood of receiving a helpful response from the IA. Our findings highlight the impact of the feedback effect at both the micro and meso levels. We further discuss its macro-level consequences: unsatisfactory interactions continuously reduce the likelihood and diversity of future user engagements in a feedback loop.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10255v1"
    ],
    "publication_venue": "PAKDD 2023"
}