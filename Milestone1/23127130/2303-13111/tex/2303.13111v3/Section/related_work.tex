\section{Related Work}
\label{sec:related}
% ------------------------------------------
\subsection{CNN-Based Networks.} 
Since the groundbreaking introduction of the UNet~\cite{ronneberger2015u}, CNN-based networks have achieved state-of-the-art results on various 2D and 3D MedSeg tasks~\cite{dou20163d,liu2018ahnet,falk2019unet,dong2022mnet}.
These methods use CNNs as the backbone to extract image features, and combine some elaborate tricks (\eg, skip connection, multi-scale representation, feature interaction) for feature enhancement. 
Compared to 2D methods, 3D approaches directly utilize the full volumetric image represented by a sequence of 2D slices or modalities.
Despite their success, CNN-based networks exhibit a constraint in effectively learning global context and long-range spatial dependencies, resulting in sub-optimal performance for challenging tasks.

\subsection{Transformer-Based Networks.} 
Vision Transformers have been applied in MedSeg to establish long-range dependence and capture context information. 
For example, UNETR~\cite{hatamizadeh2022unetr} leverages Transformer as the encoder to learn sequence representations, which captures the global multi-scale information. 
Due to high computational costs, many architectures have been proposed to reduce the cost. 
Peiris~\textit{et al.} introduces VT-UNet~\cite{peiris2022robust} that leverages a hierarchical vision Transformer which gradually decreases the resolution of features in Transformer layers and utilizes sub-sampled attention modules. 
Chen~\textit{et al.} proposes TransUNet~\cite{chen2021transunet} which uses CNN to efficiently extract local information and employs a Transformer to model global features. 
Tang~\textit{et.al} proposes SwinUNETR~\cite{tang2022swinunetr} that calculates the attention weight between different tokens in shifted local windows, reducing the computational cost from quadratic to linear complexity. 
However, the self-attention mechanism is still computationally expensive and relatively slow on GPUs.

\subsection{MLP-Based Networks.} 
Acknowledging the substantial computational cost of attention blocks in Transformer, simple and efficient modules that consist of only MLPs are proposed. 
Notably, MLP-Mixer~\cite{tolstikhin2021mixer} uses token-mixing MLP and channel-mixing MLP to capture the relationship between tokens and channels, respectively.  
CycleMLP~\cite{chen2022cyclemlp} introduces a hierarchical cycle fully connected layer to aggregate spatial context and improve performance. 
WaveMLP~\cite{tang2022wave} represents each token as a wave function with amplitude and phase to dynamically aggregate features according to the semantic contents of input images. 
In MedSeg field, UNeXt~\cite{valanarasu2022unext} shifts tokens along vertical and horizontal directions to get an axial receptive field of 2D images to increase efficiency. 
However, the effects of MLPs in Vol-MedSeg remains unexplored.
To the best of our knowledge, it is the first attempt to investigate the effectiveness of integrating CNNs and MLPs in Vol-MedSeg.