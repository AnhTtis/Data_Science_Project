\section{Experiments}

This section presents an empirical study of PGKD on several popular graph benchmarks.
% This section, we perform an empirical study of PGKD on several popular graph benchmarks.
% We further do the ablation studies.

\subsection{Datasets}
To evaluate the performance of PGKD, we consider six popular benchmarks, including four homophilous graph datasets, namely, Cora \cite{DBLP:journals/aim/SenNBGGE08}, Citeseer \cite{DBLP:journals/aim/SenNBGGE08}, Pubmed \cite{namata2012query}, and A-computer \cite{DBLP:journals/corr/abs-1811-05868}, and two heterophilous graph datasets, namely, Penn94 \cite{DBLP:conf/nips/LimHLHGBL21} and Twitch-gamer \cite{DBLP:conf/nips/LimHLHGBL21}.
Table \ref{tab: dataset} shows the dataset details.
We split these datasets for train/validation/test following GLNN \cite{DBLP:conf/iclr/ZhangLSS22} for fair comparison.
For the metric, we report the average accuracy on test data over five runs with different random seeds.

\input{tables/dataset}

\subsection{Implementation}
\paragraph{GNN Teacher.} To evaluate the ability on different backbones, we select four popular GNNs as the teacher model: GraphSAGE \cite{DBLP:conf/nips/HamiltonYL17}, GAT \cite{DBLP:journals/corr/abs-1710-10903}, GCN \cite{DBLP:conf/iclr/KipfW17} and APPNP \cite{DBLP:conf/iclr/KlicperaBG19}, and perform experiments under both transductive and inductive settings.



\paragraph{Baselines.} For baselines, we do not compare with the regularization methods since these methods utilize the graph edges as extra inputs.
In real-world applications, these graph edges may be unavailable such as in federated graph learning.
Therefore, we conduct all experiments in the edge-free setting.
For fairness, we select the edge-free GLNN \cite{DBLP:conf/iclr/ZhangLSS22} as our baseline, which adapts vanilla logit-base KD from GNNs to MLPs.

\paragraph{Hyper-parameters.} We distill the two-layer GNN teacher to MLP student with two layers~(on Cora, Citeseer, and A-computer) or three layers~(on Pumbed, Penn94, and Twitch-gamer).
For PGKD, we employ grid search to train the MLPs, where $\lambda_1$ is searched in $\{0.1, 0.2, 0.4\}$ and $\lambda_2$ in $\{0.05, 0.1\}$.
We set $\tau_1$ and $\tau_2$ as 1 and 10, respectively.
The hidden state dimension is 128 for both GNNs and MLPs.
On all the datasets, the MLPs are trained for 500 epochs with early stopping.

\subsection{Main Results}

\input{tables/main_res}

We conduct the experiments on six benchmarks and select SAGE as GNN teachers for small datasets~(Cora, Citeseer and A-computer) and GCN for large datasets~(Penn94, Pubmed and Twitch-gamer).
Meanwhile, we reproduce GLNN from its official codes.
Table \ref{tab: main_res} reports the accuracy results.
Some observations are in place:
\begin{enumerate}
    \item PKGD outperforms GLNN on all six benchmarks with higher average scores under both transductive and inductive settings, thus demonstrating the effectiveness of PGKD in capturing graph structural information for the MLPs.
    In particular, PGKD achieves 76.35\% on Pubmed under inductive setting, which is 1.86\% higher than GLNN.
    PKGD can even outperform GNN teachers on some datasets~(Citeseer and Pubmed). 
    \item The standard deviations of PGKD are smaller than GLNN for almost all datasets, showing the stability and robustness of PGKD.
    For instance, PGKD gets 0.39\% on A-computer under transductive setting, which is approximately 3$\times$ smaller than the 1.04\% of GLNN.
\end{enumerate}


\subsection{Ablation Studies}
To better understand PGKD, we conduct ablation experiments on intra-class loss and inter-class loss.
Without loss of generality, we select SAGE, GAT, GCN, APPNP as GNN teachers and compare the performance on Citeseer under inductive setting and Cora under transductive setting.


Table \ref{tab:abaltion}\&\ref{tab:abaltion2} show the experiment results.
From the tables, we find that the performance drops when either intra-class loss or inter-class loss is removed, indicating that both intra-class information and inter-class information are vital.
In general, removing the intra-class loss would lead to a larger drop than the inter-class loss under the transductive setting, but a smaller drop under the inductive setting.
Moreover, it is quite interesting to find that PGKD with one loss exclusively would perform worse than GLNN, but is better than GLNN with two losses together.
For example, PGKD gets 68.62\% and 68.23\%~(APPNP as GNN teacher) on Citeseer with one loss exclusively, which are lower than 69.23\% of GLNN.
However, PGKD would get a higher 69.78\% than GLNN with two losses.
Adopting SAGE as the GNN teacher on Citeseer also leads to a similar situation.
Such phenomenon indicates that simultaneously capturing both intra-class information and inter-class information is crucial for the MLP training.

\input{tables/abalation}

\input{tables/abalation2}