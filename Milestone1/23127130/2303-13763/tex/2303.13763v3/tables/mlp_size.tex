\begin{table}[t]
\centering
%\tableindent 
% \renewcommand\arraystretch{1.2}

\resizebox{0.5\textwidth}{!}
{%
\begin{tabular}{lllcccc}
\hline
\textbf{\#L} & \textbf{\#H} & \textbf{Params} & \textbf{MLP} & \textbf{GLNN} & \textbf{PGKD} &  $\Delta$\textbf{GLNN} \\ \hline
2 & 64 & 0.09M                & 53.40        & 73.30         & 74.00  & \textbf{$\uparrow$0.70}       \\
2 & 128 & 0.18M              & 59.48        & 71.66         & 74.71 & \textbf{$\uparrow$3.05}        \\
3 & 128 & 0.20M               & 54.33        & 73.07         & 74.24 & \textbf{$\uparrow$1.17}        \\
2 & 512 & 0.73M               & 56.21        & 73.54         & 74.47  & \textbf{$\uparrow$0.92}       \\
3 & 512 & 1.00M               & 54.57        & 72.83         & 74.00   & \textbf{$\uparrow$1.17}      \\ \hline
\end{tabular}
}

\caption{
Comparisons for vanilla MLP, distilled MLP students via GLNN and PGKD with different MLP settings on \textbf{Cora} under \textit{inductive} setting.
We report the average test accuracy (\%).
\textbf{\#L} denotes the layers and \textbf{\#H} denotes dimension of hidden state.
}
\label{tab:mlp_impact}
\end{table}