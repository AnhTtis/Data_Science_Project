\section{Methodology}

\subsection{Model Overview}
We propose Xplainer, an explainable zero-shot classification-by-description approach for diagnosing pathologies from X-Ray scans. Given an image $i$ and a list of clinical observations $o_{p_{1-n}}$ per pathology $p$, the goal is to make a multi-label prediction indicating the diagnosis for the patient. 

Our zero-shot approach leverages the alignment of image and text embeddings provided by contrastive language-image pretraining (CLIP) \cite{radford2021CLIP}. We built upon BioVil \cite{boecking2022biovil}, a CLIP model pretrained on pairs of radiology reports and images. Employing the text and image encoders from BioVil, we calculate the cosine similarity between an X-ray image and each of $N$ pre-defined clinical observations $o_{p_{1-N}}$ describing a pathology. Then we calculate observation probabilities $P_{pos}(o_{p_{i}})$ for every observation. Analogously, we calculate probabilities for the absence of all observations $P_{neg}(o_{p_{i}})$ by defining negated prompts for all observations. Using the softmax over the positive and negative probability, we calculate the final probability of the presence of an observation $P(o_{p_{i}})$. Given these observation probabilities $P(o_{p_{i}}), i\in{1,...,N}$, we estimate a joined probability to determine the likelihood of the presence of a pathology $P(p)$:

\begin{equation}
    P(p) = \sum_{i=1}^{N} log(P(o_{p_{i}})) \div N
\end{equation}

\noindent We repeat this process for all pathologies we want to diagnose in the image. As the prediction of a pathology diagnosis is directly extracted from the observation probabilities, our method is explainable by design, producing a diagnosis prediction and the detected X-ray observations leading to that prediction. Moreover, the observation probabilities show which observations the model mainly considers for its diagnosis. Figure \ref{model_overview} shows an overview of our framework.

\begin{figure}[tb]
\centering
\includegraphics[width=\textwidth]{figures/model_overview.pdf}
\caption{Overview of Xplainer: In the first step, observation probabilities are calculated based on contrastive CLIP prompting. These are then used to make an explainable diagnosis prediction. The figure depicts an example for Pneumonia.}
\label{model_overview}
\end{figure}

To integrate multiple images of one patient, we calculate positive and negative observation probabilities for each image and average them before calculating the pathology probability.

\subsection{Prompt Engineering}

Successful zero-shot inference relies on a good alignment between the contrastive pretraining and the downstream task \cite{radford2021CLIP}. As BioVil \cite{boecking2022biovil} was trained on pairs of radiological images and reports, we need to keep our observation prompts close to the style of medical reports. To initialize our prompts, we employ ChatGPT \cite{chatgpt} and query it to describe observations in X-ray images that would occur in a radiology report indicating specific pathologies. We further refined the prompts with the help of an experienced radiologist, who manually verified and adapted the descriptors. We provide a complete list of the descriptors in the supplementary.\looseness=-1

Radiology reports often include both presence and absence of particular observations. When comparing a prompt with an image embedding, it is hard for the model to differentiate between an observation's positive and negative occurrence, as their formulation can be very similar. Previous work \cite{seibold2022breaking,tiu2022chexzero} has shown that introducing negative prompts can circumvent this problem. Therefore, instead of thresholding the similarity between a positive prompt and an image, we prompt the model with both a positive and a negated version of each observation prompt and compare their probabilities. We adapt our prompts in two additional steps to align them with the text in radiology reports. First, we add a disease indication, as radiology reports usually contain observations paired with conclusions. Further, this reduces the ambiguity of our prompts, as in radiology, one sign (e.g., Lung Opacity) can indicate multiple pathologies (e.g., Pneumonia, Atelectasis, or Edema). Additionally, we frame all our observations in a sentence structure sounding more like an actual report by adding "There is/are" before every observation. Putting all of this together, we define the following prompt structure: "There is/are (no) <observation> indicating <pathology>."  Lastly, we define contrastive pathology-based prompts to compare to our observation-based prompting. In this setting, only two prompts, one positive and one negative prompt, are used per pathology. Overall, we compare the following styles of prompting to show the benefit of observation-based, contrastive prompting with disease indication and report style:

\noindent $\bullet$ \textbf{Pathology-based:} (No) <pathology>\\
$\bullet$ \textbf{Basic:} Only positive prompt per pathology: <observation>\\
$\bullet$ \textbf{Contrastive:} (No) <observation>\\
$\bullet$ \textbf{Pathology Indication:} (No) <observation> indicating <pathology>\\
$\bullet$ \textbf{Report Style:} There is/are (no) <observation> indicating <pathology>





