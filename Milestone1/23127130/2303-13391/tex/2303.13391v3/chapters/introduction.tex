\section{Introduction}
Computer-aided diagnosis systems have become a prominent tool in medical diagnosis. Yet, their adoption is limited by the need for large amounts of annotated data for training, which hinders their scalability and adaptability to new clinical findings \cite{qin2018computer,fink2020potential}. Moreover, adapting to a new reporting template or clinical protocol necessitates new annotations, further reducing their feasibility in clinical settings. Recently, zero-shot \cite{huang2021gloria,boecking2022biovil,seibold2022breaking,tiu2022chexzero,wang2022medclip} and few-shot \cite{huang2021gloria,boecking2022biovil,keicher2022few} learning methods have been proposed as a potential solution, utilizing contrastive pretraining \cite{zhang2022contrastive,radford2021CLIP} on pairs of radiology reports and images, and achieving performance on par with radiologists \cite{tiu2022chexzero}. However, these methods lack the level of detail of radiology reports and inherent explainability, impeding their adoption in clinical settings \cite{kayser2022explaining}. Particularly, explaining the diagnosis with image descriptors is crucial to increase trust in the system and allow radiologists to verify the results \cite{mcinerney2023chill}.\looseness=-1
 
Inspired by the success of using large language models to predict image descriptors in natural images \cite{menon2022visual}, we introduce Xplainer, a novel framework that enhances the explainability of zero-shot diagnosis in the clinical setting. Xplainer leverages the classification-by-description approach \cite{menon2022visual} of vision-language models and adapts it to the multi-label medical diagnosis task. Specifically, we task the model to classify the existence of descriptive observations, which a radiologist would examine on an X-Ray scan, instead of directly predicting a diagnosis. This model design imbues our framework with intrinsic explainability, as the final diagnosis prediction is predicated on the underlying descriptor predictions.

We evaluate Xplainer on two chest X-ray datasets, CheXpert \cite{irvin2019chexpert} and ChestX-ray14 \cite{wang2017chestx}, and demonstrate its efficacy in enhancing the performance and explainability of zero-shot diagnosis in the clinical setting. Our results highlight that Xplainer provides a more comprehensive understanding of the diagnosis prediction process, thereby serving as a valuable tool for clinical decision-making. In summary, Xplainer presents a novel framework for zero-shot diagnosis that not only improves explainability and accuracy but also provides an invaluable tool for computer-aided diagnosis.