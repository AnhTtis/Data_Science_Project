% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{https://doi.org/10.48550/arxiv.2301.08745,
  doi = {10.48550/ARXIV.2301.08745},
  
  url = {https://arxiv.org/abs/2301.08745},
  
  author = {Jiao, Wenxiang and Wang, Wenxuan and Huang, Jen-tse and Wang, Xing and Tu, Zhaopeng},

  title = {Is ChatGPT A Good Translator? A Preliminary Study},
  
  journal = {arXiv preprint},
  
  year = {2023},
}


@inproceedings{DBLP:conf/emnlp/MichelN18,
  author    = {Paul Michel and
               Graham Neubig},
  editor    = {Ellen Riloff and
               David Chiang and
               Julia Hockenmaier and
               Jun'ichi Tsujii},
  title     = {{MTNT:} {A} Testbed for Machine Translation of Noisy Text},
  pages     = {543--553},
  year      = {2018},
  url       = {https://doi.org/10.18653/v1/d18-1050},
}

@article{DBLP:journals/tacl/GoyalGCCWJKRGF22,
  author    = {Naman Goyal and
               Cynthia Gao and
               Vishrav Chaudhary and
               Peng{-}Jen Chen and
               others},
  title     = {The Flores-101 Evaluation Benchmark for Low-Resource and Multilingual
               Machine Translation},
  journal   = {TACL},
  year      = {2022},
  url       = {https://doi.org/10.1162/tacl\_a\_00474},
}

@misc{https://doi.org/10.48550/arxiv.2212.02437,
  doi = {10.48550/ARXIV.2212.02437},
  
  url = {https://arxiv.org/abs/2212.02437},
  
  author = {Agrawal, Sweta and Zhou, Chunting and Lewis, Mike and Zettlemoyer, Luke and Ghazvininejad, Marjan},
  
  title = {In-context Examples Selection for Machine Translation},
  
  publisher = {arXiv},
  
  year = {2022},

}

@article{DBLP:journals/corr/abs-2203-02155,
  author    = {Long Ouyang and
               Jeff Wu and
               Xu Jiang and
               Diogo Almeida and
               Carroll L. Wainwright and
               Pamela Mishkin and
               Chong Zhang and
               others},
  title     = {Training language models to follow instructions with human feedback},
  journal   = {arXiv preprint},
  year      = {2022},
  url       = {https://doi.org/10.48550/arXiv.2203.02155},
}

@article{https://doi.org/10.48550/arxiv.2302.09210,
  doi = {10.48550/ARXIV.2302.09210},
  
  url = {https://arxiv.org/abs/2302.09210},
  
  author = {Hendy, Amr and Abdelrehim, Mohamed and Sharaf, Amr and others},
  
  title = {How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation},
  
  journal = {arXiv preprint},
  
  year = {2023},
}

@article{DBLP:journals/corr/abs-2302-11521,
  author    = {Simeng Sun and
               Yang Liu and
               Dan Iter and
               Chenguang Zhu and
               Mohit Iyyer},
  title     = {How Does In-Context Learning Help Prompt Tuning?},
  journal   = {CoRR},
  volume    = {abs/2302.11521},
  year      = {2023},
  url       = {https://doi.org/10.48550/arXiv.2302.11521},
  }

@article{DBLP:journals/csur/LiuYFJHN23,
  author    = {Pengfei Liu and
               Weizhe Yuan and
               Jinlan Fu and
               Zhengbao Jiang and
               Hiroaki Hayashi and
               Graham Neubig},
  title     = {Pre-train, Prompt, and Predict: {A} Systematic Survey of Prompting
               Methods in Natural Language Processing},
  journal   = {{ACM} Comput. Surv.},
  year      = {2023},
  url       = {https://doi.org/10.1145/3560815},
}

@inproceedings{DBLP:conf/nips/BrownMRSKDNSSAA20,
  author    = {Tom B. Brown and
               Benjamin Mann and
               Nick Ryder and
               Melanie Subbiah and
               Jared Kaplan and
               others},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {Language Models are Few-Shot Learners},
  booktitle = {NeurIPS},
  year      = {2020},
  url       = {https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html},
}

@article{DBLP:journals/corr/abs-2206-08082,
  author    = {Hyuhng Joon Kim and
               Hyunsoo Cho and
               Junyeob Kim and
               Taeuk Kim and
               Kang Min Yoo and
               Sang{-}goo Lee},
  title     = {Self-Generated In-Context Learning: Leveraging Auto-regressive Language
               Models as a Demonstration Generator},
  journal   = {CoRR},
  year      = {2022},
  url       = {https://doi.org/10.48550/arXiv.2206.08082},
}


@inproceedings{DBLP:conf/wmt/BawdenCGJKKMNNS19,
  author    = {Rachel Bawden and
               Kevin Bretonnel Cohen and
               Cristian Grozea and
               others},
  title     = {Findings of the {WMT} 2019 Biomedical Translation Shared Task: Evaluation
               for {MEDLINE} Abstracts and Biomedical Terminologies},
  booktitle = {WMT},
  year      = {2019},
  url       = {https://doi.org/10.18653/v1/w19-5403},
}

@inproceedings{DBLP:conf/wmt/BarraultBCFFGHH19,
  author    = {Lo{\"{\i}}c Barrault and
               Ondrej Bojar and
               Marta R. Costa{-}juss{\`{a}} and
               others},
  title     = {Findings of the 2019 Conference on Machine Translation {(WMT19)}},
  booktitle = {WMT},
  year      = {2019},
  url       = {https://doi.org/10.18653/v1/w19-5301},
}

@inproceedings{DBLP:conf/acl/PapineniRWZ02,
  author    = {Kishore Papineni and
               Salim Roukos and
               Todd Ward and
               Wei{-}Jing Zhu},
  title     = {Bleu: a Method for Automatic Evaluation of Machine Translation},
  booktitle = {Proceedings of the 40th Annual Meeting of the Association for Computational
               Linguistics, July 6-12, 2002, Philadelphia, PA, {USA}},
  pages     = {311--318},
  publisher = {{ACL}},
  year      = {2002},
  url       = {https://aclanthology.org/P02-1040/},
}

@inproceedings{rei-etal-2020-comet,
    title = "{COMET}: A Neural Framework for {MT} Evaluation",
    author = "Rei, Ricardo  and
      Stewart, Craig  and
      Farinha, Ana C  and
      Lavie, Alon",
    booktitle = "EMNLP",
    year = "2020",
    url = "https://aclanthology.org/2020.emnlp-main.213",
}

@inproceedings{DBLP:conf/wmt/Post18,
  author    = {Matt Post},
  title     = {A Call for Clarity in Reporting {BLEU} Scores},
  booktitle = {WMT},
  year      = {2018},
  url       = {https://doi.org/10.18653/v1/w18-6319},
}

@misc{https://doi.org/10.48550/arxiv.2302.04023,
  doi = {10.48550/ARXIV.2302.04023},
  url = {https://arxiv.org/abs/2302.04023},
  author = {Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and Do, Quyet V. and Xu, Yan and Fung, Pascale},
  title = {A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity},
  publisher = {arXiv},
  year = {2023},
}

@inproceedings{freitag-etal-2022-results,
    title = "Results of {WMT}22 Metrics Shared Task: Stop Using {BLEU} {--} Neural Metrics Are Better and More Robust",
    author = "Freitag, Markus  and
      Rei, Ricardo  and
      Mathur, Nitika  and
      others",
    booktitle = "WMT",
    year = "2022",
    url = "https://aclanthology.org/2022.wmt-1.2"
}

@article{DBLP:journals/corr/abs-2211-09102,
  author    = {David Vilar and
               Markus Freitag and
               Colin Cherry and
               Jiaming Luo and
               Viresh Ratnakar and
               George F. Foster},
  title     = {Prompting PaLM for Translation: Assessing Strategies and Performance},
  journal   = {arXiv preprint},
  year      = {2022},
  url       = {https://doi.org/10.48550/arXiv.2211.09102},
}

@article{DBLP:journals/corr/abs-2301-07069,
  author    = {Biao Zhang and
               Barry Haddow and
               Alexandra Birch},
  title     = {Prompting Large Language Model for Machine Translation: {A} Case Study},
  journal   = {CoRR},
  volume    = {abs/2301.07069},
  year      = {2023},
  url       = {https://doi.org/10.48550/arXiv.2301.07069},
  doi       = {10.48550/arXiv.2301.07069},
}

@misc{https://doi.org/10.48550/arxiv.2212.06800,
  
  url = {https://arxiv.org/abs/2212.06800},
  
  author = {Levy, Itay and Bogin, Ben and Berant, Jonathan},
  
  title = {Diverse Demonstrations Improve In-context Compositional Generalization},
  
  year = {2022},
  
}

@article{https://doi.org/10.48550/arxiv.2301.00234,
  doi = {10.48550/ARXIV.2301.00234},
  url = {https://arxiv.org/abs/2301.00234},
  author = {Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Li, Lei and Sui, Zhifang},
  title = {A Survey on In-context Learning},
  journal = {arXiv preprint},
  year = {2023},
  
}

@article{DBLP:journals/corr/abs-2211-01910,
  author    = {Yongchao Zhou and
               Andrei Ioan Muresanu and
               Ziwen Han and
               Keiran Paster and
               Silviu Pitis and
               Harris Chan and
               Jimmy Ba},
  title     = {Large Language Models Are Human-Level Prompt Engineers},
  journal   = {arXiv preprint},
  year      = {2022},
  url       = {https://doi.org/10.48550/arXiv.2211.01910},
}

@article{qin2023chatgpt,
    title={Is ChatGPT a General-Purpose Natural Language Processing Task Solver?},
    author={Chengwei Qin and Aston Zhang and Zhuosheng Zhang and Jiaao Chen and Michihiro Yasunaga and Diyi Yang},
    year={2023},
    journal={arXiv preprint},
    url={https://arxiv.org/abs/2302.06476},
}

@article{zhong2023chat,
  title={Can ChatGPT Understand Too? A Comparative  Study on ChatGPT and Fine-tuned BERT},
  author={Zhong, Qihuang and Ding, Liang and Liu, Juhua and Du, Bo and Tao, Dacheng},
  journal={arXiv preprint},
  year={2023},
  url={https://arxiv.org/pdf/2302.10198.pdf},
}

@article{wang2023summarize,
  title={Cross-Lingual Summarization via ChatGPT},
  author={Wang, Jiaan and Liang, Yunlong and Meng, Fandong and Li, Zhixu and Qu, Jianfeng and Zhou, Jie},
  journal={arXiv preprint},
  url={https://arxiv.org/abs/2302.14229},
  year={2023}
}

@article{Lu2023EAPrompt,
  title={Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models: A Case Study on ChatGPT},
  author={Lu, Qingyu and Qiu, Baopu and Ding, Liang and Xie, Liping and Tao, Dacheng},
  journal={arXiv preprint},
  url={https://github.com/Coldmist-Lu/ErrorAnalysis_Prompt/blob/main/sources/report.pdf},
  year={2023}
}

@article{DBLP:journals/corr/abs-2201-11903,
  author    = {Jason Wei and
               Xuezhi Wang and
               Dale Schuurmans and
               Maarten Bosma and
               Ed H. Chi and
               Quoc Le and
               Denny Zhou},
  title     = {Chain of Thought Prompting Elicits Reasoning in Large Language Models},
  journal   = {arXiv preprint},
  year      = {2022},
  url       = {https://arxiv.org/abs/2201.11903},
}

@inproceedings{DBLP:journals/corr/abs-2205-11916,
  author    = {Takeshi Kojima and
               Shixiang Shane Gu and
               Machel Reid and
               Yutaka Matsuo and
               Yusuke Iwasawa},
  title     = {Large Language Models are Zero-Shot Reasoners},
  booktitle   = {NeurIPS},
  year      = {2022},
  url       = {https://doi.org/10.48550/arXiv.2205.11916},
}

@inproceedings{popovic-2015-chrf,
    title = "chr{F}: character n-gram {F}-score for automatic {MT} evaluation",
    author = "Popovi{\'c}, Maja",
    booktitle = "WMT",
    year = "2015",
    url = "https://aclanthology.org/W15-3049"
}

@article{agrawal2022context,
  title={In-context Examples Selection for Machine Translation},
  author={Agrawal, Sweta and Zhou, Chunting and Lewis, Mike and Zettlemoyer, Luke and Ghazvininejad, Marjan},
  journal   = {arXiv preprint},
  year      = {2022},
  url={https://arxiv.org/abs/2212.02437}
}


@article{kocmi2023large,
  title={Large Language Models Are State-of-the-Art Evaluators of Translation Quality},
  author={Kocmi, Tom and Federmann, Christian},
  journal={arXiv preprint},
  year={2023},
  url={https://arxiv.org/pdf/2302.14520v1.pdf}
}

@inproceedings{koehn-knowles-2017-six,
    title = "Six Challenges for Neural Machine Translation",
    author = "Koehn, Philipp  and
      Knowles, Rebecca",
    booktitle = "WMT",
    year = "2017",
    url = "https://aclanthology.org/W17-3204"
}

@inproceedings{ippolito-etal-2019-comparison,
    title = "Comparison of Diverse Decoding Methods from Conditional Language Models",
    author = "Ippolito, Daphne  and
      Kriz, Reno  and
      Sedoc, Jo{\~a}o  and
      Kustikova, Maria  and
      Callison-Burch, Chris",
    booktitle = "ACL",
    year = "2019",
    url = "https://aclanthology.org/P19-1365"
}

@inproceedings{zens2002phrase,
  title={Phrase-based statistical machine translation},
  author={Zens, Richard and Och, Franz Josef and Ney, Hermann},
  booktitle={KI},
  url={https://link.springer.com/content/pdf/10.1007/3-540-45751-8.pdf#page=29},
  year={2002}
}

@book{koehn2009statistical,
  title={Statistical machine translation},
  author={Koehn, Philipp},
  year={2009},
  publisher={Cambridge University Press},
  url={https://www.cambridge.org/core/books/statistical-machine-translation/94EADF9F680558E13BE759997553CDE5}
}

@article{nagao1984framework,
  title={A framework of a mechanical translation between Japanese and English by analogy principle},
  author={Nagao, Makoto},
  journal={Artificial and human intelligence},
  year={1984},
  url={https://aclanthology.org/www.mt-archive.info/70/Nagao-1984.pdf}
}

@inproceedings{papineni-etal-2002-bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "ACL",
    year = "2002",
    url = "https://aclanthology.org/P02-1040",
}

@article{vilar2022prompting,
  title={Prompting PaLM for Translation: Assessing Strategies and Performance},
  author={Vilar, David and Freitag, Markus and Cherry, Colin and Luo, Jiaming and Ratnakar, Viresh and Foster, George},
  journal={arXiv preprint},
  url={https://arxiv.org/abs/2211.09102},
  year={2022}
}


@article{gao2023design,
  title={How to Design Translation Prompts for ChatGPT: An Empirical Study},
  author={Gao, Yuan and Wang, Ruili and Hou, Feng},
  journal={arXiv e-prints},
  url={https://arxiv.org/abs/2304.02182},
  year={2023}
}

@article{he2023exploring,
  title={Exploring Human-Like Translation Strategy with Large Language Models},
  author={He, Zhiwei and Liang, Tian and Jiao, Wenxiang and Zhang, Zhuosheng and Yang, Yujiu and Wang, Rui and Tu, Zhaopeng and Shi, Shuming and Wang, Xing},
  journal={arXiv preprint},
  url={https://arxiv.org/abs/2305.04118},
  year={2023}
}

@article{lu2023chain,
  title={Chain-of-Dictionary Prompting Elicits Translation in Large Language Models},
  author={Lu, Hongyuan and Huang, Haoyang and Zhang, Dongdong and Yang, Haoran and Lam, Wai and Wei, Furu},
  journal={arXiv preprint},
  url={https://arxiv.org/abs/2305.06575},
  year={2023}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint},
  url={https://arxiv.org/abs/2303.18223},
  year={2023}
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "NAACL",
    year = "2019",
    url = "https://aclanthology.org/N19-1423",
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  year={2019},
  url={https://insightcivic.s3.us-east-1.amazonaws.com/language-models.pdf}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint},
  url={https://arxiv.org/abs/1907.11692},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={NeurIPS},
  url={https://arxiv.org/abs/2005.14165},
  year={2020}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={NeurIPS},
  url={https://arxiv.org/abs/2203.02155},
  year={2022}
}

@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint},
  url={https://arxiv.org/abs/2206.07682},
  year={2022}
}

@article{DBLP:journals/jmlr/RaffelSRLNMZLL20,
  author       = {Colin Raffel and
                  Noam Shazeer and
                  Adam Roberts and
                  Katherine Lee and
                  Sharan Narang and
                  Michael Matena and
                  Yanqi Zhou and
                  Wei Li and
                  Peter J. Liu},
  title        = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text
                  Transformer},
  journal      = {JMLR},
  year         = {2020},
  url          = {http://jmlr.org/papers/v21/20-074.html},
}

@inproceedings{DBLP:conf/iclr/WeiBZGYLDDL22,
  author       = {Jason Wei and
                  Maarten Bosma and
                  Vincent Y. Zhao and
                  Kelvin Guu and
                  Adams Wei Yu and
                  Brian Lester and
                  Nan Du and
                  Andrew M. Dai and
                  Quoc V. Le},
  title        = {Finetuned Language Models are Zero-Shot Learners},
  booktitle    = {ICLR},
  year         = {2022},
  url          = {https://openreview.net/forum?id=gEZrGCozdqR},
}

@article{costa2022no,
  title={No language left behind: Scaling human-centered machine translation},
  author={Costa-juss{\`a}, Marta R and Cross, James and {\c{C}}elebi, Onur and Elbayad, Maha and Heafield, Kenneth and Heffernan, Kevin and Kalbassi, Elahe and Lam, Janice and Licht, Daniel and Maillard, Jean and others},
  journal={arXiv preprint},
  year={2022},
  url={https://arxiv.org/abs/2207.04672}
}

@article{zan2022bridging,
  title={Bridging cross-lingual gaps during leveraging the multilingual sequence-to-sequence pretraining for text generation},
  author={Zan, Changtong and Ding, Liang and Shen, Li and Cao, Yu and Liu, Weifeng and Tao, Dacheng},
  journal={arXiv preprint},
  year={2022},
  url={https://arxiv.org/abs/2204.07834}
}

@article{zan2023unlikelihood,
  title={Unlikelihood Tuning on Negative Samples Amazingly Improves Zero-Shot Translation},
  author={Zan, Changtong and Ding, Liang and Shen, Li and Lei, Yibin and Zhan, Yibing and Liu, Weifeng and Tao, Dacheng},
  journal={arXiv preprint},
  year={2023},
  url={https://arxiv.org/abs/2309.16599}
}

@article{wang2023recursively,
  title={Recursively summarizing enables long-term dialogue memory in large language models},
  author={Wang, Qingyue and Ding, Liang and Cao, Yanan and Tian, Zhiliang and Wang, Shi and Tao, Dacheng and Guo, Li},
  journal={arXiv preprint},
  year={2023},
  url={https://arxiv.org/abs/2308.15022}
}

@inproceedings{ding-etal-2020-self,
    title = "Self-Attention with Cross-Lingual Position Representation",
    author = "Ding, Liang  and
      Wang, Longyue  and
      Tao, Dacheng",
    booktitle = "ACL",
    year = "2020",
    url = "https://aclanthology.org/2020.acl-main.153"
}

@article{du2017pre,
  title={Pre-reordering for neural machine translation: Helpful or harmful?},
  author={Du, Jinhua and Way, Andy},
  journal={Prague Bulletin of Mathematical Linguistics},
  year={2017},
  url={http://archive.sciendo.com/PRALIN/pralin.2017.108.issue-1/pralin-2017-0018/pralin-2017-0018.pdf}
}

@article{feng2018neural,
  title={Neural phrase-to-phrase machine translation},
  author={Feng, Jiangtao and Kong, Lingpeng and Huang, Po-Sen and Wang, Chong and Huang, Da and Mao, Jiayuan and Qiao, Kan and Zhou, Dengyong},
  journal={arXiv preprint},
  year={2018},
  url={https://arxiv.org/abs/1811.02172}
}

@inproceedings{ding-etal-2021-progressive,
    title = "Progressive Multi-Granularity Training for Non-Autoregressive Translation",
    author = "Ding, Liang  and
      Wang, Longyue  and
      Liu, Xuebo  and
      Wong, Derek F.  and
      Tao, Dacheng  and
      Tu, Zhaopeng",
    booktitle = "Findings of ACL",
    year = "2021",
    url = "https://aclanthology.org/2021.findings-acl.247"
}

@inproceedings{kaplan1989translation,
  title={Translation by structural correspondences},
  author={Kaplan, Ronald M and Netter, Klaus and Wedekind, Jurgen and Zaenen, Annie},
  booktitle={EACL},
  year={1989},
  url={https://aclanthology.org/E89-1037.pdf}
}

@article{zhong2022toward,
  title={Toward efficient language model pretraining and downstream adaptation via self-evolution: A case study on superglue},
  author={Zhong, Qihuang and Ding, Liang and Zhan, Yibing and Qiao, Yu and Wen, Yonggang and Shen, Li and Liu, Juhua and Yu, Baosheng and Du, Bo and Chen, Yixin and others},
  journal={arXiv preprint},
  year={2022},
  url={https://arxiv.org/abs/2212.01853}
}

@inproceedings{lewis-etal-2020-bart,
    title = "{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    author = "Lewis, Mike  and
      Liu, Yinhan  and
      Goyal, Naman  and
      Ghazvininejad, Marjan  and
      Mohamed, Abdelrahman  and
      Levy, Omer  and
      Stoyanov, Veselin  and
      Zettlemoyer, Luke",
    booktitle = "ACL",
    year = "2020",
    url = "https://aclanthology.org/2020.acl-main.703"
}

@inproceedings{zan-etal-2022-vega,
    title = "Vega-{MT}: The {JD} Explore Academy Machine Translation System for {WMT}22",
    author = "Zan, Changtong  and
      Peng, Keqin  and
      Ding, Liang  and
      Qiu, Baopu  and
      Liu, Boan  and
      He, Shwai  and
      Lu, Qingyu  and
      Zhang, Zheng  and
      Liu, Chuang  and
      Liu, Weifeng  and
      Zhan, Yibing  and
      Tao, Dacheng",
    booktitle = "WMT",
    year = "2022",
    url = "https://aclanthology.org/2022.wmt-1.37"
}

@inproceedings{kocmi-etal-2022-findings,
    title = "Findings of the 2022 Conference on Machine Translation ({WMT}22)",
    author = "Kocmi, Tom  and
      Bawden, Rachel  and
      Bojar, Ond{\v{r}}ej  and
      Dvorkovich, Anton  and
      Federmann, Christian  and
      Fishel, Mark  and
      Gowda, Thamme  and
      Graham, Yvette  and
      Grundkiewicz, Roman  and
      Haddow, Barry  and
      Knowles, Rebecca  and
      Koehn, Philipp  and
      Monz, Christof  and
      Morishita, Makoto  and
      Nagata, Masaaki  and
      Nakazawa, Toshiaki  and
      Nov{\'a}k, Michal  and
      Popel, Martin  and
      Popovi{\'c}, Maja",
    booktitle = "WMT",
    year = "2022",
    url = "https://aclanthology.org/2022.wmt-1.1",
}

@inproceedings{liu-etal-2022-makes,
    title = "What Makes Good In-Context Examples for {GPT}-3?",
    author = "Liu, Jiachang  and
      Shen, Dinghan  and
      Zhang, Yizhe  and
      Dolan, Bill  and
      Carin, Lawrence  and
      Chen, Weizhu",
    booktitle = "DeeLIO",
    year = "2022",
    url = "https://aclanthology.org/2022.deelio-1.10",
}

@inproceedings{peng-etal-2023-token,
    title = "Token-Level Self-Evolution Training for Sequence-to-Sequence Learning",
    author = "Peng, Keqin  and
      Ding, Liang  and
      Zhong, Qihuang  and
      Ouyang, Yuanxin  and
      Rong, Wenge  and
      Xiong, Zhang  and
      Tao, Dacheng",
    booktitle = "ACL",
    year = "2023",
    url = "https://aclanthology.org/2023.acl-short.73",
}