% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
%\usepackage[]{ACL2023}
\usepackage[]{EMNLP2023}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{makecell}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}
\usepackage{ascii}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{bm}
\usepackage{bbm}
\usepackage{booktabs}
\usepackage{balance}
\usepackage{color,colortbl}
\usepackage{CJKutf8}
\usepackage{graphicx} 
\usepackage{graphics}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{paralist}
\usepackage{subfig}
\usepackage{textcomp}
\usepackage{threeparttable}
\usepackage[normalem]{ulem}
\usepackage{arydshln}
\usepackage{enumitem}
\usepackage{colortbl}
\usepackage{pifont}

\def\emojihappy{\raisebox{-0.55ex}{\includegraphics[width=1.3em]{figures/happy.jpeg}}}
\def\emojisad{\raisebox{-0.55ex}{\includegraphics[width=1.3em]{figures/sad.jpeg}}}
\def\emojineutral{\raisebox{-0.55ex}{\includegraphics[width=1.3em]{figures/neutral.jpeg}}}
\def\emojithink{\raisebox{-0.55ex}{\includegraphics[width=1.3em]{figures/think.jpeg}}}
\def\emojiwarning{\raisebox{-0.55ex}{\includegraphics[width=1.3em]{figures/attention.jpeg}}}
\def\emojitemperature{\raisebox{-0.55ex}{\includegraphics[width=1.3em]{figures/temperature.jpeg}}}
\def\emojitask{\raisebox{-0.55ex}{\includegraphics[width=1.3em]{figures/task.jpeg}}}
\def\emojidomain{\raisebox{-0.55ex}{\includegraphics[width=1.3em]{figures/domain.jpeg}}}
\def\emojipin{\raisebox{-0.55ex}{\includegraphics[width=1.3em]{figures/pushpin.jpeg}}}
\def\openai{\raisebox{-0.55ex}{\includegraphics[width=1.3em]{figures/openai.png}}}
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Towards Making the Most of ChatGPT for Machine Translation}

\author{Keqin~Peng$^{\diamondsuit, \Re}$\thanks{~~Work was done when Keqin was interning at JD Explore Academy.},
\ \textbf{
\ Liang Ding$^{\Re}$\thanks{~~Corresponding Author.},
\ Qihuang Zhong$^{\sharp}$,
\ Li Shen$^{\Re}$} \\
\ \textbf{
\ Xuebo Liu$^{\flat}$,
\ Min Zhang$^{\flat}$,
\ Yuanxin Ouyang$^{\diamondsuit}$,
\ Dacheng Tao$^{\heartsuit}$} \\
\ $^{\diamondsuit}$Beihang University
\ $^{\Re}$JD Explore Academy
\ $^{\sharp}$Wuhan University \\
\ $^{\heartsuit}$The University of Sydney
\ $^{\flat}$Harbin Institute of Technology, Shenzhen\\
\includegraphics[scale=0.15]{figures/mail.png} \texttt{keqin.peng@buaa.edu.cn}, \texttt{liangding.liam@gmail.com}\\
\includegraphics[scale=0.09]{figures/tool.jpeg} \url{https://github.com/Romainpkq/ChatGPT4MT}
}

\begin{document}
\maketitle
\begin{abstract}
ChatGPT shows remarkable capabilities for machine translation (MT). Several prior studies have shown that it achieves comparable results to commercial systems for high-resource languages, but lags behind in complex tasks, e.g., low-resource and distant-language-pairs translation. However, \textbf{they usually adopt simple prompts which can not fully elicit the capability of ChatGPT}. In this paper, we aim to further mine ChatGPT's translation ability by revisiting several aspects: {\emojitemperature temperature}, {\emojitask~task information}, and {\emojidomain~domain information}, and correspondingly propose {an optimal temperature setting} and two \textit{\textcolor{red}{(simple but effective)}} prompts: \textit{Task-Specific Prompts} (TSP) and \textit{Domain-Specific Prompts} (DSP).  
We show that: \ding{182} The performance of ChatGPT depends largely on temperature, and a lower temperature usually can achieve better performance; \ding{183} Emphasizing the task information can further improve ChatGPT's performance, particularly in complex MT tasks; \ding{184} Introducing domain information can elicit ChatGPT's generalization ability and improve its performance in the specific domain; \ding{185} ChatGPT tends to generate hallucinations for non-English-centric MT tasks, which can be partially addressed by our proposed prompts but still need to be highlighted for the MT/NLP community.
We also explore the effects of advanced in-context learning strategies and find a \textit{\textcolor{red}{(negative but interesting)}} observation: the powerful chain-of-thought prompt leads to word-by-word translation behavior, thus bringing significant translation degradation. 
%The project can be found in \url{https://github.com/Romainpkq/ChatGPT4MT}. 
\end{abstract}

\section{Introduction}
Recently, the emergence of ChatGPT\footnote{\url{https://chat.openai.com}} has brought remarkable influence on natural language processing (NLP) tasks. ChatGPT is a large-scale language model developed by OpenAI, based on InstructGPT~\cite{DBLP:journals/corr/abs-2203-02155}, that has been trained to follow instructions with human feedback. ChatGPT possesses diverse abilities of NLP, including question answering, dialogue generation, code debugging, generation evaluation, and so on~\cite{qin2023chatgpt,zhong2023chat,wang2023summarize,kocmi2023large,Lu2023EAPrompt,wang2023recursively}. We are particularly interested in how well ChatGPT can perform on the machine translation task. 

Previous studies~\cite{https://doi.org/10.48550/arxiv.2301.08745,https://doi.org/10.48550/arxiv.2302.09210} on translation tasks have found that ChatGPT performs competitively with commercial translation products (e.g., Google Translate and Microsoft Translator) on high-resource languages, but has limited capabilities for low-resource and distant languages. However, they only adopt simple prompts and basic settings regardless of the significant influence of the prompts' quality~\cite{DBLP:journals/corr/abs-2211-01910}, which may limit ChatGPT's performance. In this paper, we aim to further elicit the capability of ChatGPT by revisiting the following three aspects and correspondingly propose {an optimal temperature setting} and two simple but effective prompts: \textit{Task-Specific Prompts} (TSP) and \textit{Domain-Specific Prompts} (DSP).

\paragraph{\emojitemperature~Temperature.} Temperature is an important parameter to ensure ChatGPT generates varied responses to human queries. Basically, decoding with higher temperatures displays greater linguistic variety, while the low one generates grammatically correct and deterministic text~\cite{ippolito-etal-2019-comparison}.
However, for tasks with a high degree of certainty, such as machine translation, we argue, a diverse generation may impede its translation quality. We evaluate the performance of ChatGPT at different temperatures to verify its effect and find the optimal temperature setting for the following experiments.
%find the best setting.

\paragraph{\emojitask~Task Information.} 
ChatGPT is fine-tuned on high-quality chat datasets and thus essentially a conversational system that has a certain distance from the translation system, we argue that the task inconsistency will limit its translation ability to a certain degree. In response to this problem, we proposed \textit{Task-Specific Prompts} (TSP) to further emphasize the task information to bridge the task gap, i.e., conversation and translation.

\paragraph{\emojidomain~Domain Information.} Compared with traditional machine translation systems, ChatGPT can incorporate additional information, like human interactions, through the input prompts~\cite{https://doi.org/10.48550/arxiv.2301.00234}. We argue that such flexible interaction may alleviate some classical MT challenges, e.g., cross-domain generalization~\cite{koehn-knowles-2017-six}.
We, therefore, propose \textit{Domain-Specific Prompts} (DSP) to introduce the domain navigation information to elicit ChatGPT's generalization ability across different domains.

Through extensive experiments, we find that:
\begin{itemize}
    \item[\emojipin] ChatGPT's performance largely depends on the temperatures, especially in difficult languages. Generally, setting a lower temperature can result in higher performance.
    
    \item[\emojipin] Emphasizing the task information in prompts can further improve ChatGPT's performance, especially in complex tasks.

    \item[\emojipin]  Introducing the correct domain information consistently improves ChatGPT's performance while wrong domain information leads to significant degradation in performance.

    \item[\emojiwarning] When tackling the non-English-centric tasks (both the input and expected output are non-English), ChatGPT may generate hallucinations, which should be paid more attention to by the MT/NLP community.
    
\end{itemize}
Furthermore, we explore the effects of several advanced in-context learning strategies~\cite{DBLP:conf/nips/BrownMRSKDNSSAA20}. Specifically, we investigate ChatGPT's few-shot in-context learning (ICL) and chain-of-thought (CoT)~\cite{DBLP:journals/corr/abs-2201-11903,DBLP:journals/corr/abs-2205-11916} abilities on MT tasks. Experimental results show that few-shot ICL can further improve ChatGPT's performance, which is identical to the findings of \citet{https://doi.org/10.48550/arxiv.2302.09210}, and we also find a negative but interesting observation: CoT leads to word-by-word translation behavior, thus bringing significant translation degradation.
Also, we call for improving ICL and CoT for MT upon ChatGPT by incorporating the philosophy of example-based and statistical MT~\cite{nagao1984framework,koehn2009statistical}.


The remainder of this paper is designed as follows. We present the evaluation settings in Section~\ref{sec:evaluation}. In Section~\ref{sec:zs-result}, we {revisit the performance of ChatGPT from three aspects (temperature, task, and domain information)} and show the zero-shot translation performance of ChatGPT with our proposed advanced prompt recipes. Section~\ref{sec:fs-result} summarizes the few-shot in-context learning and chain-of-thought results. Section~\ref{sec:conclusion} presents conclusions.

\section{Evaluation Setting}
\label{sec:evaluation}
We provide a brief introduction of the evaluation setting, which mainly includes the used models, test set, and evaluation metrics.

\paragraph{Models.} We mainly compare ChatGPT\footnote{\url{https://chat.openai.com/chat}} with the commercial translation product Google Translator\footnote{\url{https://translate.google.com}}, which supports translation in 133 languages. By default, the results in this paper come from the \textit{gpt-3.5-turbo-0301} models, which power the ChatGPT.

\paragraph{Data.} For multilingual translation and in-context learning, we evaluate the performance of the models on the Flores-200~\cite{DBLP:journals/tacl/GoyalGCCWJKRGF22}\footnote{\url{https://github.com/facebookresearch/flores}} test sets, which consists of 1012 sentences translated into 204 languages. To evaluate the effect of cross-domain translation, we adopt the test set of WMT19 Biomedical~\cite{DBLP:conf/wmt/BawdenCGJKKMNNS19}, News Translation Task~\cite{DBLP:conf/wmt/BarraultBCFFGHH19} and WMT22 E-Commerce task~\cite{kocmi-etal-2022-findings}. Table~\ref{tab:info-test-sets} lists the statistics of these test sets. We test all samples through OpenAI API.

\begin{table}[t]
\setlength{\tabcolsep}{2pt}
    \centering
    \resizebox{1.0\columnwidth}{!}{
    \begin{tabular}{l ccr}
    \toprule
     \bf  Test Set & \bf Direction & \bf Domain & \bf Size \\
     \midrule
     Flores-200 & Any & General & 1,012 \\
     \hline
     \multirow{2}{*}{WMT19 News} & En$\Rightarrow$Zh & \multirow{2}{*}{News} & 2,001 \\
      & En$\Rightarrow$De &  & 3,004 \\
     \hdashline
     \multirow{2}{*}{WMT19 Bio} & En$\Rightarrow$Zh & \multirow{2}{*}{Biomedical} & 224 \\
      & Zh$\Rightarrow$En &  & 241 \\
      \hdashline
      WMT22 E-Commerce & En$\Rightarrow$Zh & E-Commerce & 530 \\
    \bottomrule
    \end{tabular}
    }\caption{Data statistics and descriptions.}
    \label{tab:info-test-sets}
\vspace{-10pt}
\end{table}

\paragraph{Metric.} The translation metrics shared task~\cite{freitag-etal-2022-results} recommends using neural network-based metrics since they have demonstrated a high correlation with human evaluation and are resilient to domain shift. Hence, we adopt the mostly used \textbf{COMET}~\cite{rei-etal-2020-comet} as our primary metric and use the default parameters of "comet-compare" for significance test\footnote{\url{https://github.com/Unbabel/COMET}}. Specifically, we use the reference-based metric COMET-20 (\textit{wmt20-COMET-da}). Additionally, we also report BLEU scores~\cite{papineni-etal-2002-bleu} and \textbf{ChrF}~\cite{popovic-2015-chrf} using \textbf{SacreBLEU}~\cite{DBLP:conf/wmt/Post18} for completeness, but notably, we mainly analyze the performance in terms of model-based metric COMET.

\section{Zero-Shot Translation}
\label{sec:zs-result}
In this section, we explore the performance of ChatGPT from three aspects: \textsc{temperature}, \textsc{task information}, and \textsc{domain information}, and correspondingly propose {an optimal temperature setting and} two simple and effective prompts to improve ChatGPT's performance.

\subsection{The Effect of Temperature~\emojitemperature}
ChatGPT is a chatting machine designed to provide fluent and diverse responses to a wide range of human requests. 
It is intuitive that the diversity of responses may hinder its performance on tasks with a high degree of certainty, such as machine translation, to some extent. 

To investigate the influence of diversity, we compare the performance of ChatGPT in different temperature settings, including 0, 0.2, 0.4, 0.6, 0.8, and 1, across three translation directions: English$\Rightarrow$Romanian, English$\Rightarrow$Chinese, and English$\Rightarrow$German. 
%Figure~\ref{fig:temp_com} and ~\ref{fig:temp_bleu} show the relationship between temperature and ChatGPT' perofmr.
The relationship between temperature and performance of ChatGPT is shown in Figure~\ref{fig:temp_com} and ~\ref{fig:temp_bleu}.

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.45\textwidth]{figures/COMET.pdf}
    \caption{The relationship between temperature and ChatGPT's performance (in terms of COMET scores) when translating from English to other languages.}
    \label{fig:temp_com}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.47\textwidth]{figures/BLEU.pdf}
    \caption{The relationship between temperature and ChatGPT's performance (in terms of BLEU scores) when translating from English to other languages.}
    \label{fig:temp_bleu}
\end{figure}


\begin{table}[t]
\setlength{\tabcolsep}{4pt}
\centering
\resizebox{1\columnwidth}{!}{
\begin{tabular}{l p{7cm}}
\toprule
\bf Method & \multicolumn{1}{c}{\bf Translation Prompt} \\
\midrule
\textbf{ChatGPT} & \texttt{"role": "user", "content": "Please provide the [TGT] translation for the following sentence:"} \\
\hdashline
\textbf{ChatGPT + TSP} & \texttt{"role": "system", "content": "You are a machine translation system.", "role": "user", "content": "Please provide the [TGT] translation for the following sentence:"} \\
\bottomrule
\end{tabular}
}
\caption{Multilingual translation prompts.}
\label{tab:multi_prompts}
\end{table}

\begin{table*}[t]
\centering
% \captionsetup{font=small}
% \vspace{-0.8em}
\resizebox{0.8\linewidth}{!}{
\begin{tabular}{l c c c  c c c}
\toprule
\multicolumn{1}{c}{\textbf{System}} &  \textbf{COMET}  & \textbf{BLEU}  & \textbf{ChrF} &
\textbf{COMET}  & \textbf{BLEU}  & \textbf{ChrF} \\
\cmidrule(r){1-4} \cmidrule(l){5-7}
& \multicolumn{3}{c}{DE$\Rightarrow$EN} &   \multicolumn{3}{c}{EN$\Rightarrow$DE} \\ \cmidrule(lr){2-4} \cmidrule(lr){5-7}
Google Translator & \textbf{77.7} &	\textbf{47.4} & \textbf{70.5} & \textbf{70.5} & \textbf{44.4} & \textbf{68.9} \\
\hdashline
%ChatGPT(default) & 76.6 & 42.2 & 68.7 & 67.9 & 38.3 & 65.6 \\
ChatGPT & 77.2 & 43.5 & 69.4 & 69.3 & \underline{40.6} & \underline{67.1} \\
ChatGPT + TSP & \underline{77.5$^\dagger$} & \underline{44.1} & \underline{69.7} & \underline{69.4} & 40.4 & 67.0 \\
\midrule
& \multicolumn{3}{c}{ZH$\Rightarrow$EN} &  \multicolumn{3}{c}{\cellcolor{lightgray}{EN$\Rightarrow$ZH}} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7}
Google Translator & \textbf{73.5} & \textbf{33.5} & \textbf{61.2} & \textbf{68.5} & \textbf{48.8} & \textbf{43.8} \\
\hdashline
%ChatGPT(default) & 66.4 & 23.8	& 56.0 & 59.1 & 36.6 & 31.5 \\
ChatGPT & 71.3 & 26.4 & 58.3 & 66.4 & 45.1 & 39.0 \\
ChatGPT + TSP & \underline{71.5} & \underline{26.7} & \underline{58.4} & \underline{67.2$^\dagger$} & \underline{45.3} & \underline{39.3} \\\midrule

& \multicolumn{3}{c}{RO$\Rightarrow$EN} &   \multicolumn{3}{c}{\cellcolor{lightgray}{EN$\Rightarrow$RO}} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7}
Google Translator & \textbf{82.4} & \textbf{48.0} &	\textbf{71.2} & 91.6 & \textbf{43.3} &  \textbf{67.0} \\
\hdashline
%ChatGPT(default) & 80.3 & 40.9	& 68.3 & 90.4 & 37.2 & 63.4 \\
ChatGPT & 80.6 & 41.8	& 68.8 & 92.4 & 40.6 & 65.5 \\
ChatGPT + TSP & \underline{80.8}	& \underline{41.9}	& \underline{69.0} & \underline{\textbf{92.9}$^\dagger$} & \underline{40.8}	& \underline{65.7} \\
\midrule

& \multicolumn{3}{c}{\cellcolor{green}{ZH$\Rightarrow$RO}} &   \multicolumn{3}{c}{\cellcolor{green}{RO$\Rightarrow$ZH}} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7}
Google Translator & 73.9 & \textbf{25.8} & \textbf{53.9} & \textbf{62.3} & \textbf{42.3} & \textbf{37.8} \\
\hdashline
%ChatGPT(default) & 68.8 & 18.2	& 49.2 & 55.8 & 35.1 & 31.0 \\
ChatGPT & 73.8 & 20.9 & \underline{51.5}  & 58.9 & 37.7 & 33.3  \\
ChatGPT + TSP & \textbf{\underline{74.1}$^\dagger$} & \underline{21.0} & 51.3 & \underline{59.1$^\dagger$} & \underline{38.0} & \underline{33.7} \\
\bottomrule
\end{tabular}}
\caption{Performance with different prompts on 4 language pairs from Flores-200. 
``TSP'' denotes our proposed task-specific prompting method.
% , and ``*'' denotes that the improvement over vanilla ChatGPT is higher than 0.5.
The best scores across different systems are marked in \textbf{bold} and the best scores of ChatGPT are \underline{underlined}. Notably, we set the temperature as 0 for ChatGPT in this experiment. 
We can see that our TSP method consistently boosts the performance of ChatGPT in most settings. \colorbox{lightgray}{Shadowed} areas mean difficult English-centric translation tasks, \colorbox{green}{Green} areas mean non English-centric translation tasks. ``$^\dagger$'' indicates a statistically significant difference from the ChatGPT baseline ($p<0.05$). 
}
\label{tab:TSP}
% \vspace{-1.5em}
\end{table*}

\paragraph{Results.} Figure~\ref{fig:temp_com} and ~\ref{fig:temp_bleu} show that ChatGPT's performance largely depends on the value of temperatures, and as the temperature rises, there is a clear degradation both in COMET and BLEU scores. Furthermore, it is noteworthy that ChatGPT's sensitivity to the temperature varies depending on the language pair: the impact of temperature is relatively small when translating to high-resource languages, e.g., German, while for complex languages, e.g., Chinese, it has a large degradation in performance ($-4.3$ COEMT points and $-3.7$ BLEU points for Chinese) when the temperature changes from 0 to 1. We speculate that the huge resource variance in training data leads to differences in the confidence of languages, which partially explains the different performances. 
% In the following experiments, we adopt $T = 0$ as our default setting to make the most of ChatGPT and ensure the stability of generation.
In the following experiments, we adopt $T = 0$ as our default setting to make the most of ChatGPT and ensure the stability of generation to avoid a result of noise.

\subsection{The Effect of Task Information~\emojitask}
Previous studies~\citep{https://doi.org/10.48550/arxiv.2301.08745,https://doi.org/10.48550/arxiv.2302.09210} have shown that ChatGPT can achieve exceptional performance in conversational domain translation, which is attributed to its ability to generate more natural and diverse spoken language. However, given that ChatGPT is deliberately designed as a general task solver~\cite{qin2023chatgpt}, when asking the ChatGPT to perform as a specific task engine, there will arise a task gap. This task inconsistency may limit ChatGPT's effectiveness in translation tasks other than the spoken domain.
% when asking the ChatGPT to perform as a general MT engine, there will arise a task gap. This task inconsistency may limit ChatGPT's effectiveness in translation tasks other than the spoken domain. 

To bridge the task gap and generate more translation-like sentences, we propose \textit{Task-Specific Prompts} (TSP) to emphasize the translation task information. 
Specifically, we prepend the sentence \textit{"You are a machine translation system."} to the best translation template in ~\citet{https://doi.org/10.48550/arxiv.2301.08745}, and adopt it to query ChatGPT. The templates of prompts present in Table~\ref{tab:multi_prompts}, and \texttt{[TGT]} represents the target languages of translation.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.46\textwidth]{figures/PE_n.pdf}
    \caption{Number of Post-Edited sentences in non-English-centric language pairs, where a higher value means the translation contains more hallucinations. RO represents the translation for ZH$\Rightarrow$RO, while ZH represents the translation for ZH$\Rightarrow$RO.}
    \label{fig:num_PE}
\end{figure}

We have compared the performance of various models on four language pairs, covering eight distinct translation directions. These languages comprise 1) German, which is one of the most non-English languages in the GPT training data, 2) Romanian, a less frequently encountered non-English language in the GPT training data, and 3) Chinese, a large-scale language with a script distinct from English. We also adopt Chinese-Romanian as a non-English-centric use case.
Table~\ref{tab:TSP} lists the full results, where we list both English-centric and non-English-centric language directions (marked with \colorbox{green}{green}), and also, among English-centric directions, we highlight the difficult pairs (EN-ZH and EN-RO with \colorbox{lightgray}{shadow}) in terms of their resources and language distance. 

\subsubsection{English-Centric Language Pairs}
We first consider the performance of ChatGPT in English-centric translation language pairs. Specifically, we conduct experiments in three language pairs: German$\Leftrightarrow$English (high-resource), Romanian$\Leftrightarrow$English (low-resource), and Chinese$\Leftrightarrow$English (distant language).  

\paragraph{Results.} Our results presented in Table~\ref{tab:TSP} show that our TSP method achieves comparable results on COMET score compared to Google Translator and even outperforms it in some language pairs, e.g., English$\Rightarrow$Romanian (92.9 v.s. 91.6). We also observe that our TSP method consistently improves the performance of vanilla ChatGPT, especially when translating to low-resource or distant languages. Specifically, our TSP method brings $+0.8$ and $+0.5$ COMET score improvements in English$\Rightarrow$Chinese and English$\Rightarrow$Romanian, respectively, and $+0.2$ on average when translating to English. 
We speculate that the high-resource training data can help the model better understand the specific task from a few task-related navigations, thereby reducing the need for additional task-specific information. Although our proposed TSP consistently improves the performance in terms of semantic metric, i.e., COMTE, notably, we have not consistently bridged the task gap in terms of lexical metrics (BLEU and ChrF), which is consistent with similar findings from~\citet{vilar2022prompting} on PALM-540B model.

\subsubsection{Non-English-Centric Language Pairs} We also evaluate the performance of ChatGPT in non-English-centric language pairs (since the pretraining process was dominated by the English tokens and the multilingual MT community argues it may harm the non-English-centric performance~\cite{costa2022no,zan2022bridging,zan2023unlikelihood}.). We have an important finding that, \textbf{\emojiwarning~when tackling non-English-centric MT language pairs, ChatGPT tends to generate translation hallucinations}, that is, some unrelated information obeyed some patterns followed the translation, such as \textit{"Translation may vary depending on context"}, which will greatly affect the MT performance. We used a post-processing method to remove irrelevant information from the generated text. Specifically, we summarize some templates about irrelevant sentences and remove them from the generation texts. Some templates are shown in Table~\ref{tab:templates} and the number of post-processed sentences is presented in Figure~\ref{fig:num_PE}. 

\begin{table}[t]
\setlength{\tabcolsep}{4pt}
\centering
\resizebox{1\columnwidth}{!}{
\begin{tabular}{l p{7cm}}
\toprule
\bf Target Language & \multicolumn{1}{c}{\bf Template} \\
\midrule
\textbf{Chinese} & \texttt{[Ro] would be translated to: [Zh]; [Zh] (Note: ...)} \\
\hdashline
\textbf{Romanian} & \texttt{[Zh] can be translated into Romanian as [Ro]; [Ro] (Note: ...)} \\
\bottomrule
\end{tabular}
}
\caption{Some templates about irrelevant information in generated sentences for Chinese$\Leftrightarrow$Romanian. Semicolon is used to separate different templates. [Ro] represents the sentence in Romanian while [Zh] represents that in Chinese.}
\label{tab:templates}
\end{table}

\paragraph{Results.} Figure~\ref{fig:num_PE} shows that lower temperature can reduce the number of hallucinations (especially in distant languages, e.g., Chinese)
and our TSP method can further reduce its number, which suggests that our method can help ChatGPT to better serve as a machine translation system. 
The full results on Romanian$\Leftrightarrow$Chinese lists are in Table~\ref{tab:TSP}. 
As seen, our TSP method can only slightly improve ChatGPT's performance, which could be due to the difficulty in both understanding and generating the language pairs. 
%Although 
Meanwhile, our used post-editing approach could only roughly remove the hallucination patterns, \textbf{\textit{the NLP/MT community should pay more attention to the potential hallucination when using ChatGPT to tackle the non-English text}}.

The subsequent experiments will use ChatGPT with TSP as the default setting. 


\begin{table}[t]
\setlength{\tabcolsep}{4pt}
\centering
\resizebox{1.0\columnwidth}{!}{
\begin{tabular}{l p{7cm}}
\toprule
\multicolumn{1}{l}{\bf Method} & \multicolumn{1}{c}{\bf Translation Prompt} \\
\midrule
\textbf{ChatGPT} & \texttt{"role": "system", "content": "You are a machine translation system.", "role": "user", "content": 'Please provide the [TGT] translation for the following sentence: '} \\
\hdashline
\textbf{ChatGPT+DSP} & \texttt{"role": "system", "content": "You are a machine translation system that translates sentences in the [DOM] domain.", "role": "user", "content": 'Please provide the [TGT] translation for the following sentence: '} \\
\hdashline
\textbf{ChatGPT+F-DSP} & \texttt{"role": "system", "content": "You are a machine translation system that translates sentences in the [FDOM] domain.", "role": "user", "content": 'Please provide the [TGT] translation for the following sentence: '} \\
\bottomrule
\end{tabular}
}
\caption{Domain-Specific translation prompts. ``\texttt{[DOM]}'' and ``\texttt{[FDOM]}'' denote the correct and incorrect domain instructions, respectively.}
\label{tab:rob_prompts}
\end{table}

\subsection{The Effect of Domain Information~\emojidomain}
Compared with traditional machine translation systems, ChatGPT can incorporate additional information through the prompts to further improve its performance. While previous studies have shown that ChatGPT has great robust translation capabilities~\cite{https://doi.org/10.48550/arxiv.2302.09210}, we believe that we can further enhance its performance by incorporating domain-specific guidance. 


\begin{table*}[t]
%\setlength{\tabcolsep}{4pt}
\centering
\resizebox{1\linewidth}{!}{
\begin{tabular}{l cccccccccc}
\toprule
\multirow{2}{*}{\bf System}
& \multicolumn{4}{c}{\bf WMT19 Bio}
& \multicolumn{4}{c}{\bf WMT19 News}
& \multicolumn{2}{c}{\bf WMT22 E-Commerce} \\
\cmidrule(lr){2-5}\cmidrule(lr){6-9} \cmidrule(lr){10-11}
& \multicolumn{2}{c}{EN$\Rightarrow$ZH} & \multicolumn{2}{c}{ZH$\Rightarrow$EN} & \multicolumn{2}{c}{EN$\Rightarrow$ZH} & \multicolumn{2}{c}{EN$\Rightarrow$DE} & \multicolumn{2}{c}{EN$\Rightarrow$ZH} \\
\cmidrule(lr){2-3}\cmidrule(lr){4-5}\cmidrule(lr){6-7}\cmidrule(lr){8-9}\cmidrule(lr){10-11}
&  \textbf{COMET}  & \textbf{BLEU} &  \textbf{COMET}  & \textbf{BLEU} &  \textbf{COMET}  & \textbf{BLEU} &  \textbf{COMET}  & \textbf{BLEU} &  \textbf{COMET}  & \textbf{BLEU}  \\
\cmidrule(r){1-5} \cmidrule(l){6-9} \cmidrule(l){10-11}
Google Translator  & \textbf{59.4} & \textbf{38.8} & 59.4 & \textbf{36.1} & 59.3 & \textbf{43.4} & \textbf{64.1} & \textbf{33.7} & \textbf{71.7} & \textbf{48.0} \\
ChatGPT  & 58.6 & 35.5 & 58.7 & 31.1 & 58.8 & 39.6 & 63.1 & 31.3 & 68.2 & 43.5 \\
\hdashline
ChatGPT + DSP  & \underline{58.9} & \underline{35.8} & \textcolor[RGB]{0,176,80}{\textbf{\underline{59.6}$^\dagger$}} & \underline{31.3} & \textcolor[RGB]{0,176,80}{\textbf{\underline{59.6}$^\dagger$}} & \underline{39.8} & \underline{63.2} & \underline{31.5} & \underline{68.6} & \underline{43.8} \\
ChatGPT + F-DSP  & 58.6 & 35.6 & \textcolor{red}{58.4} & \underline{31.3} & \textcolor{red}{57.9} & 39.0 & \textcolor{red}{62.0} & 31.2 & \textcolor{red}{67.1} & 43.3 \\
\bottomrule
\end{tabular}}
\caption{Performance of ChatGPT on translation robustness, i.e., different domains. ``DSP'' denotes our proposed domain-specific prompting method, while ``F-DSP'' denotes the false domain-specific prompting, i.e., we specify wrong/unrelated domain information in the prompt. The results in \textcolor[RGB]{0,176,80}{green} denote that ``DSP'' improves ChatGPT by a clear margin (0.5 ($\uparrow$) score), while the \textcolor{red}{red} results denote the significant performance drops caused by ``F-DSP''. ``$^\dagger$'' indicates a statistically significant difference from the ChatGPT baseline ($p<0.05$).}
\label{tab:bleu-robust-chatgpt}
\end{table*}



\begin{table*}[t]
%\setlength{\tabcolsep}{4pt}
\centering
\begin{tabular}{l cccccc}
\toprule
\multirow{2}{*}{\bf System}
& \multicolumn{2}{c}{\bf EN $\Rightarrow$ DE}
& \multicolumn{2}{c}{\bf EN $\Rightarrow$ ZH}
& \multicolumn{2}{c}{\bf EN $\Rightarrow$ RO}\\
\cmidrule(lr){2-3}\cmidrule(lr){4-5}\cmidrule(lr){6-7}
& \multicolumn{1}{c}{\bf COMET} & \multicolumn{1}{c}{\bf BLEU} & \multicolumn{1}{c}{\bf COMET} & \multicolumn{1}{c}{\bf BLEU} & \multicolumn{1}{c}{\bf COMET} & \multicolumn{1}{c}{\bf BLEU} \\
\midrule
%Tencent & 31.31 & 23.72 & -- & -- & 29.69 & 46.06 \\
Google Translator & \textbf{70.5} & \textbf{44.4} & 68.5 & \textbf{48.8} & 91.6 & \textbf{43.3} \\
\hline
ChatGPT & 69.4 & 40.4 & 67.2 & 45.3 & 92.9 & 40.8  \\
\hdashline
\multicolumn{7}{l}{\textit{Random Sampling few-shot prompting}} \\
\quad -w/ 1-shot & 69.8 & 40.6 & 67.6 & 45.4 & 93.1 & 40.7 \\
\quad -w/ 3-shot & 70.0 & 40.7 & 68.3 & \underline{45.9} & 93.6 & 40.9 \\
\hdashline
\multicolumn{7}{l}{\textit{TopK Sampling few-shot prompting}} \\
\quad -w/ 1-shot & 69.8 & \underline{41.0} & 68.4 & 45.8 & 93.1 & 40.7 \\
\quad -w/ 3-shot & \underline{\textbf{70.5}} & 40.9 & \underline{\textbf{68.8}} & 45.8 & \underline{\textbf{94.0}} & \underline{41.2} \\
\bottomrule
\end{tabular}
\caption{
Few-shot translation performance of ChatGPT on Flores-200. In the random sampling few-shot prompting setting, we randomly sample 1/3 examples from the development set with 3 runs. The best scores across different systems are marked in \textbf{bold} and the best scores of ChatGPT are \underline{underlined}.
}
\label{tab:few-shot}
\end{table*}

To this end, we propose Domain-Specific Prompts (DSP) that identify the domain information of translated sentences in prompts to facilitate ChatGPT's generalization. Specifically, we ask ChatGPT with the following prompts \textit{"You are a machine translation system that translates sentences in the [DOM] domain"}, as shown in Table~\ref{tab:rob_prompts}. Here, \texttt{[DOM]} represents the correct domain of the translated sentence, while \texttt{[FDOM]} represents the wrong domain of that, which is used to verify whether the improvement comes from domain information. 
For example, for a biomedical sentence, \texttt{[DOM]} is \textit{biomedical}, while \texttt{[FDOM]} can be any field except \textit{biomedical}.

We evaluate our method on the WMT19 Bio and News datasets followed ~\citet{https://doi.org/10.48550/arxiv.2301.08745}, which allows us to examine domain bias's impact. For example, the WMT19 Bio test set comprises Medline abstracts that require domain-specific knowledge, while the WMT19 News dataset features news-style texts that are significantly different from dialogues. To further prove the effectiveness of our method, we conduct our method on WMT22 English-Chinese E-Commerce test set, which is less likely to overlap with the GPT training data.

\paragraph{Results.} The results are listed in Table~\ref{tab:bleu-robust-chatgpt}. Obviously, the original ChatGPT does not perform as well as Google Translator in both COMET and lexical metrics (e.g., BLEU). However, our DSP method can consistently improve the performance of ChatGPT in terms of COMET score and even outperforms Google Translator in two datasets (WMT19 Bio Chinese $\Rightarrow$ English and WMT19 News English $\Rightarrow$ Chinese). This finding indicates that our method can further improve the generalization ability of ChatGPT and narrow the gap with one of the most advanced commercial systems -- Google Translator. Nonetheless, our method's impact on BLEU is inconsistent, and it still lags significantly behind Google Translator's performance. 

To verify that the observed improvement is indeed due to the introduction of the domain information, we deliberately provided incorrect domain information for each sentence, namely \textit{F-DSP}, to attack the improvement brought by the DSP strategy. Specifically, We exchange domain information for the biomedical sentences and the news sentences. We expect that the wrong domain guidance (F-DSP) will under-perform the DSP, and even perform worse than the vanilla ChatGPT.
The results of these experiments are shown in the last row of Table~\ref{tab:bleu-robust-chatgpt}, which clearly shows a consistent degradation in COMET, proving that the domain information is the key to the success of our method.

All the above DSP and F-DSP results confirm the importance of domain-specific prompting guidance in using ChatGPT for MT tasks.


\begin{table}[t]
\setlength{\tabcolsep}{4pt}
\centering
\resizebox{1.0\columnwidth}{!}{
\begin{tabular}{l p{7cm}}
\toprule
\multicolumn{1}{l}{\bf Method} & \multicolumn{1}{c}{\bf Translation Prompt} \\
\midrule
\textbf{Zero-Shot CoT} & \texttt{"role": "system", "content": "You are a machine translation system.", "role": "user", "content": 'Please provide the German translation for the following sentence step by step and then provide the complete sentence: '} \\
\midrule
\textbf{1-Shot CoT} & \texttt{"role": "system", "content": "You are a machine translation system.", "role": "user", "content": 'Please provide the German translation for the following sentence step by step and then provide the complete sentence: [S] 1. [S\_1] - [T\_1] 2. [S\_2] - [T\_2] ... n. [S\_n] - [T\_n]  The complete sentence in [TGT] is: [T] Please provide the German translation for the following sentence step by step and then provide the complete sentence:'} \\
\bottomrule
\end{tabular}
}
\caption{The templates of Zero-Shot CoT and 1-shot CoT. \texttt{[S\_n]} represents the \textit{n}-th token in source demonstration \texttt{[S]}, \texttt{[T\_n]} represents the \textit{n}-th token in target demonstration \texttt{[T]}.}
\label{tab:ZSCoT_prompts}
\end{table}


\section{Few-shot Machine Translation}
\label{sec:fs-result}
In this section, we simply explore the effects of advanced in-context learning (ICL) strategies, specifically, we investigate ChatGPT’s few-shot ICL and Chain-of-Thought (CoT) abilities on MT tasks.

\subsection{Few-Shot In-Context learning} In-context learning~\cite{DBLP:conf/nips/BrownMRSKDNSSAA20} has shown its remarkable ability for many NLP tasks~\cite{DBLP:journals/csur/LiuYFJHN23}. To further explore the capabilities of the ChatGPT, we conduct experiments with different sample selection strategies. Specifically, we evaluate the performance of few-shot machine translation in the following three directions: English$\Rightarrow$Chinese, English$\Rightarrow$Romanian, and English$\Rightarrow$German in Flores-200. 
%\textcolor{red}{We conducted experiments with randomly sampled demonstrations from development sets with 3 runs in the 1-shot and 3-shot settings, and we also adopted the advanced sample-selection strategy TopK, }
We conducted experiments with randomly and TopK~\cite{liu-etal-2022-makes} sampled demonstrations from development sets in the 1-shot and 3-shot settings.

\paragraph{Results.} Our results are listed in Table~\ref{tab:few-shot}. As seen, in-context learning with random examples consistently improves the performance in both lexical metric (BLEU) and COMET score compared to the zero-shot approach, and increasing the number of shots can lead to further improvement, which is consistent with previous finding~\cite{https://doi.org/10.48550/arxiv.2302.09210}. 
The advanced sample-selection strategy like TopK, which chooses test-sample similar examples as demonstrations, can further improve the performance, even outperform Google Translator in some language pairs, e.g., English$\Rightarrow$Romanian (94.0 v.s. 91.6) and English$\Rightarrow$Chinese (68.8 v.s. 68.5).
% Furthermore, we observed that the 1-shot approach achieved decent results, but further increasing the number of shots does not lead to any improvement, it may be because ChatGPT is powerful enough to learn from one demonstration.

We encouragingly find that the advanced sample-selection strategy for in-context learning for MT tasks upon ChatGPT is extremely similar to the design philosophy of example-based machine translation (EBMT,~\citealp[]{nagao1984framework}{}), where the EBMT is often characterized by its use of a bilingual corpus as its main knowledge base, at run-time. It is worthy of designing better ICL strategies inspired by EBMT in future work.


\subsection{Chain-of-Thought} Chain-of-Thought (CoT) prompting ~\cite{DBLP:journals/corr/abs-2201-11903} has been demonstrated to be effective in eliciting the reasoning ability of large language models. Previous studies have shown that CoT can improve the ChatGPT's performance in natural language understanding tasks~\cite{zhong2023chat}, but \textbf{its influence on machine translation tasks has hardly been investigated}. 

To investigate this further, we randomly select 20 samples from the test set and adopt the zero-shot CoT technique~\cite{DBLP:journals/corr/abs-2205-11916} and the 1-shot CoT technique. Specifically, as shown in Table~\ref{tab:ZSCoT_prompts}, for zero-shot CoT, we use the prompt \texttt{"Please provide the [TGT] translation for the following sentence step by step"} to extract step-by-step translation. We also add the sentence `\texttt{and then provide the complete sentence:}' to the end of the prompting to ensure that ChatGPT can generate the complete translation. While for the 1-shot CoT, we provide the manual intermediate reasoning steps inspired by zero-shot CoT, as shown in Table~\ref{tab:ZSCoT_prompts}. Here, [S] and [T] represent the corresponding source and target sentence in the demonstration, respectively, and [S\_i] and [T\_i] are the i-th matching tokens in the source and target sentence.


\begin{table}[t]
\centering
\resizebox{1.0\columnwidth}{!}{
\begin{tabular}{lcccc}
\toprule
              \multirow{2}{*}{\bf Method}                    & \multicolumn{2}{c}{\bf EN$\Rightarrow$DE} & \multicolumn{2}{c}{\bf EN$\Rightarrow$ZH} \\ 
                                  \cmidrule(lr){2-3}\cmidrule(lr){4-5}
                                  &\bf  COMET        &\bf  BLEU       &\bf  COMET        &\bf  BLEU       \\ 
                                  \midrule
\multicolumn{1}{l}{ChatGPT}     & 72.4         & 36.5       & 68.3         & 41.4       \\ 
\hdashline
\multicolumn{1}{l}{\quad -w zero-shot CoT} & 69.3 \textcolor{red}{($\downarrow$3.1)}        & 35.1 \textcolor{red}{($\downarrow$1.4)}       & 59.5 \textcolor{red}{($\downarrow$8.8)}          & 36.2 \textcolor{red}{($\downarrow$5.2)}        \\ 
\multicolumn{1}{l}{\quad -w 1-shot CoT} & 69.6 \textcolor{red}{($\downarrow$2.8)}        & 37.0 \textcolor[RGB]{0,176,80}{($\uparrow$0.5)}       & 61.1 \textcolor{red}{($\downarrow$7.2)}          & 37.6 \textcolor{red}{($\downarrow$3.8)}        \\ 
\bottomrule
\end{tabular}}
\caption{Performance of ChatGPT equipped with CoT prompting methods on randomly selected 20 samples from English$\Rightarrow$German and English$\Rightarrow$Chinese.}
\label{tab:ZS_CoT}
\end{table}
\paragraph{Results.} We conduct experiments in the following two translation directions: English$\Rightarrow$German and English$\Rightarrow$Chinese. The results are listed in Table~\ref{tab:ZS_CoT}, which shows that there is a significant degradation in COMET score with zero-shot CoT setting, especially in English$\Rightarrow$Chinese, which drops 8.8 COMET points. 1-shot CoT prompting can consistently outperform zero-shot CoT but still lags behind zero-shot prompting on COMET. 

We looked in detail at the sentences generated by different prompts, presented in Table~\ref{tab:example}, and we have a negative but interesting observation: \textbf{\textit{the CoT prompt leads to word-by-word translation behavior, which is the main reason for the significant translation degradation}}. 

For more CoT variants designed with different principles inspired by the philosophy in statistical MT~\cite{zens2002phrase,koehn2009statistical} will be explored in the future. For example, word-by-word and then reordering the translation~\cite{du2017pre,ding-etal-2020-self}, phrase-to-phrase~\cite{feng2018neural,ding-etal-2021-progressive} and then reordering the translation, and structure-to-structure translation~\cite{kaplan1989translation}. 

\section{Related Work}
\paragraph{Large Language Models.} Large language models (LLMs) usually refer to language models with hundreds of billions of parameters, which are trained on massive text data~\cite{zhao2023survey}. LLMs usually can be classified into three groups based on model architectures: 1) encoder-only LLMs~\cite{devlin-etal-2019-bert,liu2019roberta,zhong2022toward}, usually used for NLU tasks; 2) decoder-only LLMs~\cite{radford2019language,brown2020language}, more suitable for NLG tasks; and 3) encoder-decoder LLMs~\cite{DBLP:journals/jmlr/RaffelSRLNMZLL20,lewis-etal-2020-bart,zan-etal-2022-vega,peng-etal-2023-token}, which can achieve better performance on conditional text generation tasks. 

% \noindent 
Traditionally, these PLMs can achieve remarkable performance in various natural language processing (NLP) tasks through fine-tuning on specific tasks. But with the scaling up and the development of LLMs~\cite{brown2020language,ouyang2022training}, decoder-only LLMs exhibit remarkable zero-shot and few-shot abilities, denoted emergent abilities~\cite{wei2022emergent}, and achieve comparable results with other LLMs in NLU and conditional NLG tasks. Especially the emergency of ChatGPT, developed by OpenAI, takes LLMs a big step forward in both academia and industry. ChatGPT possesses diverse abilities of NLP and can generate human-like responses by instruction-tuning~\cite{DBLP:conf/iclr/WeiBZGYLDDL22} and Reinforcement Learning from Human Feedback (RLHF) technique~\cite{ouyang2022training}.

%It possesses diverse abilities of NLP, including question answering, dialogue generation, code debugging, generation evaluation, and so on, which has attracted widespread attention from society. 
\paragraph{ChatGPT for Machine Translation.}
The ability of ChatGPT has been widely studied in various domains~\cite{qin2023chatgpt,zhong2023chat}, but its ability on machine translation tasks has not been fully investigated. ~\citet{https://doi.org/10.48550/arxiv.2301.08745} and  ~\citet{https://doi.org/10.48550/arxiv.2302.09210} first provided an evaluation on the performance of ChatGPT for machine translation, they found that ChatGPT can perform competitively with commercial translation products on high-resource European languages but lags behind significantly on low resource or distant languages. However, they usually adopt simple prompts and basic settings which cannot fully exploit the capabilities of ChatGPT, we first proposed that ChatGPT can achieve comparable results with  proper settings and investigate how to make the most of ChatGPT for machine translation. 

% \noindent 
Subsequent work follows our work to further explore the performance of ChatGPT, ~\citet{gao2023design} and ~\citet{lu2023chain} introduce new information (e.g., POS or multilingual dictionaries), ~\citet{he2023exploring} proposed a CoT-like framework to generation human-like translation.

%e.g. better translation prompts~\cite{gao2023design,lu2023chain} and CoT prompts~\cite{he2023exploring}. 

\section{Conclusion}
\label{sec:conclusion}
% We investigate how to further mine ChatGPT's translation ability from three perspectives, namely temperature, task \& domain information, and we correspondingly propose two simple but effective prompts. Through quantitative studies, we summarize some interesting findings and useful recipes to make the most of ChatGPT for MT.
In this paper, we investigate how to further mine ChatGPT's translation ability from three perspectives, namely temperature, task, and domain information, and correspondingly propose an optimal temperature setting and two simple but effective prompts. We empirically demonstrated that there is a high correlation between temperature and ChatGPT's performance, and a lower temperature usually can achieve better performance. Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts. We further explore the effectiveness of advanced in-context learning strategies for ChatGPT, we find that the few-shot in-context learning method can consistently improve ChatGPT's performance, while conventional Chain-of-Thought (CoT) prompting will degrade its performance because of its word-by-word translation behavior.

In future work, besides the aforementioned explorations (EBMT-inspired prompts designing, statistical MT-inspired chain-of-thought designing), we would like to investigate how to further elicit the ability of ChatGPT by designing more effective prompts (e.g., design human-like CoT to navigate the LLMs, and better demonstration selection algorithms in few-shot ICL) and investigate the ability of ChatGPT for more MT settings (e.g., document translation). 

%In future work, besides the aforementioned explorations (EBMT-inspired prompts designing, statistical MT-inspired chain-of-thought designing), we would like to investigate the ability of ChatGPT for more MT settings, e.g., document translation. 

\section*{Limitations}
Our work has several potential limitations. First, we only propose some simple prompts that have not been carefully designed to investigate the capabilities of ChatGPT, which may not sufficiently elicit the power of ChatGPT. Second, we have not fully studied the performance of ChatGPT in few-shot scenarios, especially the effect of Chain-Of-Thought in machine translation. In future work, we would like to design different types of prompts to further improve ChatGPT's performance in machine translation and conduct more in-depth analyses and discussions.

\section*{Ethics Statement}
We take ethical considerations very seriously and strictly adhere to the EMNLP Ethics Policy. This paper focuses on exploring the translation ability of ChatGPT on open-sourced machine translation datasets, not involving any ethics problem. Both the compared models and evaluation datasets used in this paper are publicly available and have been widely adopted by researchers. Therefore, we believe that this research will not pose ethical issues.


\bibliography{custom}
\bibliographystyle{acl_natbib}

% \appendix
\begin{table*}[]
    \centering
    %\vspace{2.8mm}
    \begin{tabular}{p{0.94\linewidth}}
    \toprule
\textit{~Zero-shot prompting} \\
\vspace{-1mm}
\textbf{System:} You are a machine translation system. \\ 
\textbf{User:} \textbf{Please provide the German translation for the following sentence:} Sadly, as newer methods of writing have emerged, the pencil has been relegated to lesser status and uses. \\
\openai\textbf{Response:} Leider wurde der Bleistift durch neuere Schreibmethoden in eine geringere Position und Verwendung gedrängt.
\\\midrule
\textit{~Zero-shot CoT prompting} \\
\vspace{-1mm}
\textbf{System:} You are a machine translation system. \\
\textbf{User:} \textbf{Please provide the German translation for the following sentence step by step and then provide the complete sentence:} Sadly, as newer methods of writing have emerged, the pencil has been relegated to lesser status and uses. \\
\openai\textbf{Response:} \textcolor{red}{1. Sadly - Bedauerlicherweise 2. as newer methods of writing have emerged - da neuere Schreibmethoden aufgetaucht sind 3. the pencil - der Bleistift 4. has been relegated - wurde zurückgestuft 5. to lesser status and uses - zu geringerem} Status und Verwendungszwecken  Bedauerlicherweise wurde der Bleistift aufgrund neuerer Schreibmethoden zu geringerem Status und Verwendungszwecken zurückgestuft.
\\\midrule
\textit{~1-shot CoT prompting} \\
\vspace{-1mm}
\textbf{System:} You are a machine translation system. \\
\textbf{User:} \textcolor{blue}{Please provide the German translation for the following sentence step by step and then provide the complete sentence: That said, expect to be out of breath, and take care in the steeper portions, especially when wet, as it can become dangerous quickly.
1. That said - jedoch damit 2. expect - Rechnen sie 3. to be - zu sein 4. out of breath - außer Atem 5. and - und 6. take care - vorsichtig 7. in the steeper portions -  in den steileren Abschnitten 8. especially - besonders 9. when wet - wenn es nass ist 10. become - werden 11. dangerous - gefährlich 12. quickly - schnell The complete sentence in German is: Rechnen Sie jedoch damit, außer Atem zu sein, und seien Sie in den steileren Abschnitten vorsichtig, besonders wenn es nass ist, da es dort schnell gefährlich werden kann.} \textbf{Please provide the German translation for the following sentence step by step and then provide the complete sentence:} Sadly, as newer methods of writing have emerged, the pencil has been relegated to lesser status and uses. \\
\openai\textbf{Response:} \textcolor{red}{1. Sadly - Leider 2. as - da 3. newer methods - neuere Methoden 4. of writing - des Schreibens 5. have emerged - aufgetaucht sind 6. the pencil - der Bleistift 7. has been relegated - wurde zurückgestuft 8. to lesser status - zu einem geringeren Status 9. and uses - und Verwendungen.} The complete sentence in German is: Leider wurde der Bleistift aufgrund des Auftauchens neuerer Methoden des Schreibens zu einem geringeren Status und Verwendungen zurückgestuft.
\\\bottomrule
\end{tabular}
\caption{Examples of zero-shot and 1-shot CoT prompting on English$\Rightarrow$German. The sentences in \textcolor{red}{red} are the reasoning step for CoT and those in \textcolor{blue}{blue} are the one-shot example. Sentences in \textbf{bold} are the instruction of CoT.}
\label{tab:example}
\end{table*}


% \clearpage
% \onecolumn
% \noindent ChatGPT shows remarkable capabilities for machine translation (MT). Several prior studies have shown that it achieves comparable results to commercial systems for high-resource languages, but lags behind in complex tasks, e.g, low-resource and distant-language-pairs translation. However, \textbf{they usually adopt simple prompts which can not fully elicit the capability of ChatGPT}. In this report, we aim to further mine ChatGPT's translation ability by revisiting several aspects: {\emojitemperature temperature}, {\emojitask~task information}, and {\emojidomain~domain information}, and correspondingly propose two \textit{\textcolor{red}{(simple but effective)}} prompts: \textit{Task-Specific Prompts} (TSP) and \textit{Domain-Specific Prompts} (DSP).  
% We show that: \ding{182} The performance of ChatGPT depends largely on temperature, and a lower temperature usually can achieve better performance; \ding{183} Emphasizing the task information further improves ChatGPT's performance, particularly in complex MT tasks; \ding{184} Introducing domain information can elicit ChatGPT's generalization ability and improve its performance in the specific domain; \ding{185} ChatGPT tends to generate hallucinations for non-English-centric MT tasks, which can be partially addressed by our proposed prompts but still need to be highlighted for the MT/NLP community.
% We also explore the effects of advanced in-context learning strategies and find a \textit{\textcolor{red}{(negative but interesting)}} observation: the powerful chain-of-thought prompt leads to word-by-word translation behavior, thus bringing significant translation degradation.
\end{document}
