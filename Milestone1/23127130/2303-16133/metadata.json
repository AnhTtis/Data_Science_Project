{
    "arxiv_id": "2303.16133",
    "paper_title": "Exposing and Addressing Cross-Task Inconsistency in Unified Vision-Language Models",
    "authors": [
        "Adyasha Maharana",
        "Amita Kamath",
        "Christopher Clark",
        "Mohit Bansal",
        "Aniruddha Kembhavi"
    ],
    "submission_date": "2023-03-28",
    "revised_dates": [
        "2023-03-29"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
    ],
    "abstract": "As general purpose vision models get increasingly effective at a wide set of tasks, it is imperative that they be consistent across the tasks they support. Inconsistent AI models are considered brittle and untrustworthy by human users and are more challenging to incorporate into larger systems that take dependencies on their outputs. Measuring consistency between very heterogeneous tasks that might include outputs in different modalities is challenging since it is difficult to determine if the predictions are consistent with one another. As a solution, we introduce a benchmark dataset, COCOCON, where we use contrast sets created by modifying test instances for multiple tasks in small but semantically meaningful ways to change the gold label, and outline metrics for measuring if a model is consistent by ranking the original and perturbed instances across tasks. We find that state-of-the-art systems suffer from a surprisingly high degree of inconsistent behavior across tasks, especially for more heterogeneous tasks. Finally, we propose using a rank correlation-based auxiliary objective computed over large automatically created cross-task contrast sets to improve the multi-task consistency of large unified models, while retaining their original accuracy on downstream tasks. Project website available at https://adymaharana.github.io/cococon/",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16133v1"
    ],
    "publication_venue": "Project Website: https://adymaharana.github.io/cococon/"
}