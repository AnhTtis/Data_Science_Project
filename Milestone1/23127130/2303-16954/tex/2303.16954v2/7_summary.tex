\section{Concluding remarks} 
\label{sec:summary} 

% Interpret findings at a higher level of abstraction 
We presented a hierarchical Bayesian approach for inferring parameter vectors from MMVs that promotes joint sparsity. 
The method involves using separate conditionally Gaussian priors for each parameter vector and common hyper-parameters to enforce a common sparsity profile among the parameter vectors. 
Based on this joint-sparsity-promoting hierarchy, new algorithms, MMV-IAS and MMV-GSBL, were developed and demonstrated to outperform existing IAS and GSBL algorithms in several test cases.
% To what extent did we succeed in addressing the need stated in the introduction? 
% What do the findings mean to the reader? 
Our findings show that incorporating joint sparsity into the current hierarchical Bayesian methodology can significantly improve its performance. 
The concept of joint-sparsity-promoting priors is flexible and can be extended beyond the conditionally Gaussian priors and (generalized) gamma hyper-priors used in the present study.

% Include perspective; including open questions and problems 
Future work will explore the potential of the proposed joint-sparsity-promoting approach by extending it to other hierarchical prior models, such as horseshoe \cite{carvalho2009handling,uribe2022horseshoe} and neural network priors \cite{neal1996priors,asim2020invertible,li2021bayesian}.
The generalization to non-linear data models, hybrid-like MAP estimation \cite{calvetti2020sparsity,si2022path}, and other inference strategies will also be addressed.
The open problem of automatic selection of the hyper-prior parameters (also noted in \cite{glaubitz2022generalized,xiao2023sequential}) will be tackled in forthcoming works. 
The promising results in our parallel MRI example suggest the proposed MMV approach can also be helpful in applications. 
Future work will consider applications such as synthetic aperture radar (SAR) and electron tomography imaging. 
In both cases, previous investigations have demonstrated that compressive sensing techniques that exploit joint sparsity of MMVS are effective in recovering point estimates, \cite{sanders2017composite,scarnati2018joint}, suggesting that the MMV-IAS or MMV-GSBL might provide an effective Bayesian approach. 
Employing various sparse transform operators $R_1,\dots,R_L$ may be appropriate in this regard.
The case of changing sparsity profiles over time will also be considered, with promising initial results already reported for sequential signaling/imaging \cite{xiao2022sequential,xiao2023sequential}.