
\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2022


% ready for submission
\usepackage[nonatbib,preprint]{neurips_2022}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2022}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2022}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2022}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{float}
\usepackage{subfig}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{bbding}
\usepackage{framed}
\usepackage{setspace}
\usepackage{pifont}
\usepackage{graphicx}
\usepackage{threeparttable}
\usepackage{times}
\usepackage{amsmath}
\usepackage{soul}
\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{amsmath, bm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{etoc}
\usepackage[most]{tcolorbox}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{float}
\usepackage{amsthm}
\usepackage{comment}
\usepackage{mathrsfs}
\usepackage{multicol}
\usepackage{appendix}
\usepackage{amssymb}
\usepackage{wrapfig}
\usepackage{bbm}
\usepackage{bbding}
\usepackage{framed}
\usepackage{setspace}
\usepackage{pifont}
\usepackage{algorithmic}
\usepackage{url}
\usepackage{color,xcolor}
\usepackage{xspace}
\newcommand{\ours}[0]{BEEF\xspace}  
\newcommand{\fair}[0]{\textrm{fair}}
\newcommand{\greedy}[0]{G-fair-Prompting\xspace}
\newcommand{\topk}[0]{T-fair-Prompting\xspace}
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}

\newcommand{\Comment}[1]{\hfill $\vartriangleright$ {#1}}
\newcommand{\BComment}[1]{\Comment{\textcolor{blue}{#1}}}
\newcommand{\RComment}[1]{\Comment{\textcolor{red}{#1}}}
\newcommand{\GComment}[1]{\Comment{\textcolor{green}{#1}}}
\newcommand{\best}[1]{\bm{\textcolor{brown}{#1}}}
\newcommand{\view}[1]{\emph{\textcolor{brown}{#1}}}
\newcommand{\improve}[0]{\textcolor{green}{\blacktriangle}}
\newcommand*{\affaddr}[1]{#1} % No op here. Customize it for different styles.
\newcommand*{\affmark}[1][*]{\textsuperscript{#1}}
\newcommand*{\email}[1]{\small{\texttt{#1}}}
\newcommand*\samethanks[1][\value{footnote}]{\footnotemark[#1]}
% \renewcommand{\qedsymbol}{$\blacksquare$}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
% \newtheorem{lemma}[theorem]{Lemma}
% \newtheorem{corollary}[theorem]{Corollary}
% \theoremstyle{definition}
% \newtheorem{definition}[theorem]{Definition}
% \newtheorem{assumption}[theorem]{Assumption}
% \theoremstyle{remark}
% \newtheorem{remark}[theorem]{Remark}

\title{Fairness-guided Few-shot Prompting for Large Language Models}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.



\author{%
Huan Ma\affmark[1,]\affmark[2]\thanks{The project was conducted during the internship in AI Lab, Tencent}, ~Changqing Zhang\affmark[2]\samethanks[2], ~Yatao Bian\affmark[1], Lemao Liu\affmark[1], Zhirui Zhang\affmark[1], \\ \textbf{Peilin Zhao\affmark[1], Shu Zhang\affmark[1], Huazhu Fu\affmark[3], Qinghua Hu\affmark[2], Bingzhe Wu\affmark[1]\thanks{Corresponding author}} \\ 
\affaddr{\affmark[1] AI Lab, Tencent, Shenzhen, China}\\
\affaddr{\affmark[2] College of Intelligence and Computing, Tianjin University, Tianjin, China}\\
\affaddr{\affmark[3] Institute of High Performance Computing, A*STAR, Singapore}
\\
\email{\affmark[2] \href{mailto:zhanchangqing@tju.edu.cn}{zhanchangqing@tju.edu.cn}};\; \email{\affmark[1] \href{mailto:wubingzheagent@gmail.com}{bingzhewu@tencent.com}}
}




\begin{document}


\maketitle


\begin{abstract}
Large language models have demonstrated surprising ability to perform in-context learning, i.e., these models can be directly applied to solve numerous downstream tasks by conditioning on a prompt constructed by a few input-output examples. However, prior research has shown that in-context learning can suffer from high instability due to variations in training examples, example order, and prompt formats. Therefore, the construction of an appropriate prompt is essential for improving the performance of in-context learning. 
In this paper,  we revisit this problem from the view of predictive bias. Specifically, we introduce a metric to evaluate the predictive bias of a fixed prompt against labels or a given attributes. Then we empirically show that prompts with higher bias always lead to unsatisfactory predictive quality. Based on this observation, we propose a novel search strategy based on the greedy search to identify the near-optimal prompt for improving the performance of in-context learning. 
We perform comprehensive experiments with state-of-the-art mainstream models such as GPT-3 on various downstream tasks. 
Our results indicate that our method can enhance the model's in-context learning performance in an effective and interpretable manner. Code is available at: \href{https://github.com/MaHuanAAA/g_fair_prompting}{https://github.com/MaHuanAAA.} 
   %Neural autoregressive language models (LMs) have been demonstrated to have the capability to perform tasks with few-shot learning through in-context learning and exhibit significant potential. However, the performance of these pre-trained LMs can vary depending on the prompt used, and finding an appropriate prompt remains a challenge. This paper presents an innovative metric to evaluate prompts and accordingly proposes a gradient-free strategy for selecting the best prompt. The proposed metric enables users to find a prompt that generates the fairest predictions and is a generalizable tool that can assist other methods in finding an improved prompt. Through comprehensive experiments, we provide evidence of the rationality of the metric and the effectiveness of the proposed prompt-selection strategy in classification scenarios. Our results demonstrate that the proposed method can enhance the accuracy of the model without requiring any modifications to the model.
\end{abstract}


\input{secs/intro.tex}
\input{secs/rela_wor.tex}
\input{secs/method.tex}
\input{secs/exp.tex}
% \input{secs/disc.tex}



\section{Conclusion}
In this paper, we revisit the sensitivity of large language model across prompts, and analyse the issue from a predictive bias perspective. Accordingly, we employ a "content-free" strategy as a metric termed as fairness to evaluate the predictive bias of a fixed prompt and show that model's performance is highly consistency with fairness. Then, we propose two strategy to search the most fair prompt in the original space. We conduct extensive experiments on current famous LLMs, and validate the effectiveness of the proposed strategy. Moreover, in addition to fairness adopted in this paper, there would be more metrics for prompt searching in the future for different scenarios. 

\bibliographystyle{unsrt}
\bibliography{reference}



\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section*{Checklist}


% %%% BEGIN INSTRUCTIONS %%%
% The checklist follows the references.  Please
% read the checklist guidelines carefully for information on how to answer these
% questions.  For each question, change the default \answerTODO{} to \answerYes{},
% \answerNo{}, or \answerNA{}.  You are strongly encouraged to include a {\bf
% justification to your answer}, either by referencing the appropriate section of
% your paper or providing a brief inline description.  For example:
% \begin{itemize}
%   \item Did you include the license to the code and datasets? \answerYes{See Section~\ref{gen_inst}.}
%   \item Did you include the license to the code and datasets? \answerNo{The code and the data are proprietary.}
%   \item Did you include the license to the code and datasets? \answerNA{}
% \end{itemize}
% Please do not modify the questions and only use the provided macros for your
% answers.  Note that the Checklist section does not count towards the page
% limit.  In your paper, please delete this instructions block and only keep the
% Checklist section heading above along with the questions/answers below.
% %%% END INSTRUCTIONS %%%


% \begin{enumerate}


% \item For all authors...
% \begin{enumerate}
%   \item Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?
%     \answerTODO{}
%   \item Did you describe the limitations of your work?
%     \answerTODO{}
%   \item Did you discuss any potential negative societal impacts of your work?
%     \answerTODO{}
%   \item Have you read the ethics review guidelines and ensured that your paper conforms to them?
%     \answerTODO{}
% \end{enumerate}


% \item If you are including theoretical results...
% \begin{enumerate}
%   \item Did you state the full set of assumptions of all theoretical results?
%     \answerTODO{}
%         \item Did you include complete proofs of all theoretical results?
%     \answerTODO{}
% \end{enumerate}


% \item If you ran experiments...
% \begin{enumerate}
%   \item Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)?
%     \answerTODO{}
%   \item Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)?
%     \answerTODO{}
%         \item Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)?
%     \answerTODO{}
%         \item Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)?
%     \answerTODO{}
% \end{enumerate}


% \item If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
% \begin{enumerate}
%   \item If your work uses existing assets, did you cite the creators?
%     \answerTODO{}
%   \item Did you mention the license of the assets?
%     \answerTODO{}
%   \item Did you include any new assets either in the supplemental material or as a URL?
%     \answerTODO{}
%   \item Did you discuss whether and how consent was obtained from people whose data you're using/curating?
%     \answerTODO{}
%   \item Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content?
%     \answerTODO{}
% \end{enumerate}


% \item If you used crowdsourcing or conducted research with human subjects...
% \begin{enumerate}
%   \item Did you include the full text of instructions given to participants and screenshots, if applicable?
%     \answerTODO{}
%   \item Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable?
%     \answerTODO{}
%   \item Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation?
%     \answerTODO{}
% \end{enumerate}


% \end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\input{secs/appendix.tex}




\end{document}
