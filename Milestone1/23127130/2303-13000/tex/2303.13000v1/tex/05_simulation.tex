\section{Simulation Based Evaluation}
We first evaluate with simulation by observing 10,000 scenarios (parameter combinations) for an exhaustive evaluation. The following section describes our real-world evaluation. 

\subsection{Source, Event and Taskset}
This section describes the synthetic energy source, event, and data processing pipeline. 

\parlabel{Synthetic Energy Source Generation}
For the simulation, we generate synthetic energy traces guided by real-world measurements. The synthetic traces reflect two types of energy sources -- solar and radio-frequency (RF). For solar, we have measured the available energy in indoor and outdoor scenarios at different lighting conditions (e.g., sunny vs. rainy day). For RF, we measured energy loss for various distances and obstacles (e.g., wood, metal, wall, human) between the RF receiver and transmitter operating at 900Hz. We further utilize different RF energy path loss models and motion trajectories. We move the source in these trajectories at a wide range of speed to change its distance from the nodes and line of sight parameters.

These energy traces ensures the presence of three energy conditions, where the available energy is (1) greater than, (2) smaller than, or (3) equal to the required operating energy. When the available energy is more than the required energy, the system stores residual energy for the future when there is insufficient available energy. The energy storage capacity is randomly selected from valid capacitor sizes ranging from 2.2 nF to 1 F. This limited storage size ensures an energy overflow reflecting real-world energy constraints. In the beginning, $t = 0$, all energy storage is empty. 

We simulate two main energy availability scenarios when the available energy -- (1) is constant over time but is different at each node and (2) is variable across time and different for every node. 


\parlabel{Synthetic Event Generation}
We aims to successfully monitor stochastic events or rapidly varying environmental stimuli (e.g., a bell ring, a car passing a pedestrian). Thus the synthetic event dataset contains 1,000 sporadic events where the range of period (the minimum difference between two consecutive events) and event duration are input to the random event generator. We avoid simultaneous event occurrence by making the period the upper bound for the event duration.

\parlabel{Synthetic Computing Task Generation}
All intermittent nodes perform the same task when they capture the event. We choose the task duration and energy consumption from a bin of 15 tasks -- RSA encryption, signal processing-based speaker detection, KNN-based audio classification, DNN-based audio classification, DNN-based keyword spotting, DNN-based image classification, Decision Tree based image classification, temperature anomaly detection with local outlier factor (LOF), signal processing-based shape detection, activity recognition, cuckoo filtering, blowfish encryption, bit count, DNN-based visual wake word, and DNN-based image recognition. We measure these tasks' runtime and energy consumption executing on an MSP430FR5994 microcontroller. Additional sensors consume more energy to operate; hence, we also consider the power consumption during sensor activation. During one iteration, this duration is constant and the same for all the nodes.

\parlabel{Simulating Clock Drift and Charging Time}
We consider the clock drift time and time to charge the capacitor for a realistic simulation. We emulate the clock drift of a battery-free timekeeper~\cite{dereliable} by considering its error bound. We design a software-controlled cascading capacitor array (Section~\ref{sec:hardware}) to reduce the capacitor charging time. We measure the time to charge the capacitor array at different energy rates to simulate the capacitor charging time and utilize these measurements.

\parlabel{Node Configuration}
We rely on the period of events to determine the total number of nodes during each simulation iteration. We first calculate the events' hyperperiod and the total number of primes and co-primes, $N$, within that hyperperiod. The simulator then simulates $N$ number of nodes. For fairness, all algorithms are evaluated on N nodes for each iteration. 

\subsection{Performance Analysis}
This section analyzes the performance of \Sys with various duty cycle selection algorithms.

\begin{figure}
    \centering
    \includegraphics[width=0.45\textwidth]{plot/const_unbal.pdf}
    \caption{The average capture and process success rate for various algorithms when the available energy is constant over time but varies for each node. The fixed duty cycle algorithm can successfully capture and process 82\% of events. PCP determines custom and required duty cycles for each node and performs similarly to the oracle algorithm.}
    \label{fig:const_unbal_CPSR}
\end{figure}

\parlabel{Available Energy is Constant over Time but is Different for Each Node}
Figure~\ref{fig:const_unbal_CPSR} demonstrates different algorithms' capture and process success rate ($\zeta$) when the available energy is invariant over time but differs at each node. The X-axis of Figure~\ref{fig:const_unbal_CPSR}  represents the number of days the nodes were operating, and the Y-axis is the capture and process success rate, $\zeta$, defined in Section~\ref{sec:metric}. 

The Oracle (ORCL) algorithm can successfully capture and process 99.97\% of the data on average. Some $\zeta$ drop happens due to the failure to process all the sensed tasks rather than miss the events. The mean $\zeta$ of single-node operating greedily, GRDY(1), is 43\%, and it randomly varies with time as the event occurrence and energy availability are unsynchronized. To see whether having just N nodes increases the $\zeta$, we investigate N nodes executing the greedy algorithm, GRDY(N). We see a 13\% mean $\zeta$ increase in the system with a single node. Even though these nodes are not synchronized and lack a collective goal, they have a variable amount of energy available. Thus, they require a different amount of time to accumulate enough energy to turn on. It organically creates some desynchronization extending the $\zeta$.  

Next, we observe that when N nodes have the same pre-defined duty cycle, the $\zeta$ is 82\% on average. This performance is lower than the Oracle because each node requires various amounts of time to recharge the energy storage, and some nodes thus can not be active when they were supposed to be active. We also find that this performance drops over time as the coarse time synchronization among the nodes drifts. Note that all algorithms have the same number of nodes (besides the single cases) determined by the Prime-Co-Prime algorithm for a fair comparison. This is fair, as having more than the required nodes does not negatively impact the capture and process success rate. DC can achieve the $\zeta$ of the Oracle if it considers the minimum available harvestable energy to determine the duty cycle and the number of nodes at the cost of a higher number of nodes.

On the other hand, though a single node with the ACES algorithm, ACES(1), performs worse than the greedy algorithm on the first day, over time, it learns the energy distribution and increases the performance by 16\% in 30 days. A swarm of nodes executing ACES, ACES(N),  has higher $\zeta$ as each node randomly updates its action (duty-cycle) using reinforcement learning. It captures and processes 68\% of the events on average. 

The node-specific duty cycles determined by the Prime-Co-Prime (PCP) algorithm capture and process 96\% of the events on average. Though we observe a 3\% performance drop over the 30 days, in the first 14 days, the performance drop is only 2\%. The clock drift is responsible for this error, and we observed that without the random counter drifts, the performance dropped over 30 days become 8\%.

% \begin{figure*}[!htb]
% \begin{minipage}{0.48\textwidth}
% \centering
%     \includegraphics[width=\linewidth]{plot/const_unbal.pdf}
%     \caption{The average capture and process success rate for various algorithms when the available energy is constant over time but varies for each node. The fixed duty cycle algorithm can successfully capture and process 82\% of events. PCP determines custom and required duty cycles for each node and performs similarly to the oracle algorithm.}
%     \label{fig:const_unbal_CPSR}
% \end{minipage}
% \hspace{0.7em}
% \begin{minipage}{0.48\textwidth}
% \centering
%     \includegraphics[width=\linewidth]{plot/const_unbal_red.pdf}
%     \caption{Average redundant active time for various algorithms when the available energy is constant over time but varies for each node. The duty cycle and Prime-Co-Prime algorithm have some redundant active time due to the clock drift.}
%     \label{fig:const_unbal_red}
% \end{minipage}
% % \vspace{-2em}
% \end{figure*}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.45\textwidth]{plot/const_unbal_red.pdf}
    \caption{Average redundant active time for various algorithms when the available energy is constant over time but varies for each node. The duty cycle and Prime-Co-Prime algorithm have some redundant active time due to the clock drift.}
    \label{fig:const_unbal_red}
\end{figure}

In Figure~\ref{fig:const_unbal_red}, X-axis is various algorithms, and Y-axis is the redundant active time in percentage. The single-node algorithms --GRDY(1) and ACES(1)--have no redundant active time as they have only one node in the system. The Oracle has less than 1\% redundant active time, while the greedy swarm of nodes has 43.87\% redundant active time. There is no collaborative notion for the greedy swarm, and multiple nodes are often active simultaneously. The pre-defined fixed duty cycle algorithm has less than 3\% of redundant active time, often caused by clock drifts. Despite the lower redundant active time, this algorithm has a lower $\zeta$ because this system has 22.5\% idle time (no node was on) and failed to process 7.25\% of the captured events. ACES(N) also have higher redundant active time because the nodes have no collaborative notion. However, it is better than the greedy swarm as each node is using reinforcement learning to improve its performance, contributing to the comparatively lower redundant active time. Finally, the system with PCP has only 2.5\% redundant active time because a time value can be multiplication of more than one prime or co-prime numbers making all those nodes active at that time. PCP has only 1.89\% idle time and fails to process 7.28\% of captured samples, which contributes to reducing $\zeta$. 


% \begin{figure*}[!htb]
% \begin{minipage}{0.48\textwidth}
% \centering
%     \includegraphics[width=\linewidth]{plot/vat_unbal_cpsr.pdf}
%     \caption{The capture and process success rate for various algorithms when the available energy is constant over time but varies for each node.}
%     \label{fig:var_unbal_CPSR}
% \end{minipage}
% \hspace{0.7em}
% \begin{minipage}{0.48\textwidth}
% \centering
%     \includegraphics[width=\linewidth]{plot/vat_unbal_red.pdf}
%     \caption{Redundant active time for various algorithms when the available energy varies over time and at each node. The swarm of greedy and ACES experiences increased redundant active time as the energy to harvest varies over time.}
%     \label{fig:var_unbal_red}
% \end{minipage}
% % \vspace{-2em}
% \end{figure*}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.45\textwidth]{plot/vat_unbal_cpsr.pdf}
    \caption{The capture and process success rate for various algorithms when the available energy varies over time and at each node.}
    \label{fig:var_unbal_CPSR}
\end{figure}

\parlabel{Available Energy Varies over Time and at Each Node}
Next, we look at the most exciting and practical scenario where the available energy varies over time, and every node gets a different amount of energy. Figure~\ref{fig:var_unbal_CPSR} shows different algorithms' capture and process success rate over 30 days. We observe that even the Oracle does not have a 100\% $\zeta$. The unknown variability of available energy causes energy scarcity for nodes, and thus, the system fails to process 9.34\% of captured events contributing to the total 11.27\% $\zeta$ drop. This variation is also responsible for the performance drop of the PCP algorithm. The PCP algorithm determines the tailored duty cycle for each node at the compile time. However, as the energy source varies over time, these duty cycles can not be maintained, resulting in long (30.72\%) idle time. 
With the Randomized Binary Search (RBS) heuristic of the DEC-POMDP formulation, we can successfully capture and process 10\% more events than the PCP. The Suboptimal Reinforcement Learning (SRL) based heuristic achieves higher $\zeta$ and can capture and process only 3\% fewer events than the Oracle. 
Using the prior knowledge about the relation of the available energy among the nodes and continuously learning from the feedback, SRL achieves this significant improvement. 

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.45\textwidth]{plot/vat_unbal_red.pdf}
    \caption{Redundant active time for various algorithms when the available energy varies over time and at each node. The swarm of greedy and ACES experiences increased redundant active time as the energy to harvest varies over time.}
    \label{fig:var_unbal_red}
\end{figure}

Figure~\ref{fig:var_unbal_red} shows the redundant active time when the energy varies over time and across nodes. Similar to the previous scenario, we observe that the Oracle and PCP have negligible redundant active time, while a swarm of greedy and ACES has higher redundant active time. Despite having a lower redundant active time, PCP's lower capture and process success rate is due to the 23.32\% idle time where the nodes fail to wake up despite their duty cycle. Though the RBS heuristic has 23\% redundant active time, it has a higher $\zeta$ than the PCP algorithm as it dynamically changes each node duty cycle. Using the prior knowledge about the relation of the available energy among the nodes and continuously learning from the feedback, SRL achieves even lower redundant active time. 