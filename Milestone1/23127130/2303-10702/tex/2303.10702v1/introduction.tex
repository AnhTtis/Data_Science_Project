The demand for edge inference is growing and neural networks are prime candidates due to their success across a large variety of application domains. However, state-of-the-art deep neural network models, especially convolution neural networks, require a large amount of memory and computational resources. For example, the standard ResNet-18 model~\cite{he2016deep} for image classification on ImageNet has around 11M parameters and requires approximately 1 GMACs for an inference which is prohibitive for ARM Cortex-M microcontrollers. Thus, designing efficient neural network architectures is a major topic in the embedded AI community. In the search for efficient neural network architectures, several alternatives to convolution have been proposed, but few of them are practically implemented on deployment libraries for 32-bit microcontrollers. This work focuses on the implementation and characterization of state-of-the-art convolution primitives for ARM Cortex-M MCUs.
\textbf{Our contributions are as follow:}
\begin{itemize}
\item We implement three state-of-the-art convolution primitives for ARM Cortex-M MCUs and when possible, we propose another implementation which makes use of the SIMD\footnote{\url{https://www.keil.com/pack/doc/CMSIS/Core/html/group\_\_intrinsic\_\_SIMD\_\_gr.html}} instructions (\textit{Single Instruction, Multiple Data}).
\item We characterize the latency and energy consumption of five primitives, including the standard convolution, against different parameters such as kernel or input size.
\item We provide insights on the performance of different primitives, especially for our implementations using SIMD instructions to help machine learning practitioners to design, develop and deploy efficient models according to their requirements. \end{itemize}