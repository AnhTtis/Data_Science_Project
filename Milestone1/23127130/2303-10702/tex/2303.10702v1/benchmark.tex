The experiments are carried out on a typical 32-bit MCU platform, the Nucleo STM32F401-RE, based on Cortex-M4 that supports SIMD instructions. Unless specified, the compiler is arm-none-eabi-gcc (version 10.3) with the optimization level sets to \texttt{Os} and the MCU's frequency is fixed at 84 MHz. The software STM32CubeMonitor-Power\footnote{\url{https://www.st.com/en/development-tools/stm32cubemonpwr.html}} is used to measure the electric current of the MCU. We multiply it by the supply voltage (i.e. 3.3 V) and integrate it over the duration of an inference to obtain the inference's energy consumption.

\subsection{Influence of the primitive parameters}
\subsubsection{Protocol}

To evaluate the influence of a parameter (i.e. kernel size, input width...), we consider a layer with every other parameters fixed excepted the concerned one. The experiment plan is defined in table \ref{tab2}. We measure the latency and energy consumption over 50 inferences (average) with randomized inputs. Results are presented in Fig.\ref{benchmark}.

\subsubsection{Results without SIMD instructions}
We observe in Fig. \ref{benchmark}.a-c that our implementation fits the theory (Table~\ref{Primtive_resume}). For example, the theoretical MACs, latency and energy consumption increase quadratically with the kernel size (Fig \ref{benchmark}.2.a, Fig \ref{benchmark}.2.b and Fig \ref{benchmark}.2.c). More specifically, there is a linear relationship between the MACs, latency and consumption. A linear regression leads to scores of 0.995 and 0.999 respectively. Add convolutions are slightly less efficient than convolutions despite the same number of MACs. This is explained by the quantization scheme of add convolution and the additional batch normalization layer.


\begin{table}[h!]
\centering
\begin{tabular}{cccccc}
\toprule
Experiment & Groups & Kernel size & Input width & Input channel & Filters \\ 
\midrule
1          & 1-32   & 3           & 10          & 128           & 64      \\ 
2          & 2      & 1-11        & 32          & 16            & 16      \\ 
3          & 2      & 3           & 8-32        & 16            & 16      \\ 
4          & 2      & 3           & 32          & 4-32          & 16      \\ 
5          & 2      & 3           & 32          & 16            & 4-32    \\ \bottomrule
\\
\end{tabular}
\caption{Primitive parameters for the different experiments.}
\end{table}

\begin{figure}
\includegraphics[width=\textwidth]{figure/influence_of_layer_parameters.eps}
\vspace{-20pt}
\caption{Influence of the 1) number of groups, 2) kernel size, 3) input width, 4) number of input channels and 5) filters on a) theoretical MACs, b) latency without SIMD instructions, c) energy consumption without SIMD instructions, d) latency with SIMD instructions and e) energy consumption with SIMD instructions and f) speedup for different primitives. The different implementations fit the theory. Using SIMD instructions enables faster and less energy consuming inferences. The speedup of the im2col algorithm varies according to the primitives and their parameters.} \label{benchmark}
\end{figure}

\subsubsection{Effect of SIMD instructions}

Using SIMD instructions decreases the latency (Fig \ref{benchmark}.d) and energy consumption (Fig \ref{benchmark}.e) of the different primitives. Our implementation with SIMD instructions also fits the theory. But latency is more relevant to estimate the layerâ€™s energy consumption (regression score of 0.999) than theoretical MACS (regression score of 0.932). This loss of linearity is related to the varying speedup of the im2col algorithm with respect to the primitives and their parameters (Fig \ref{benchmark}.f). A possible explanation is in the data reuse exploitation by the im2col algorithm. To verify this, we measure the number of memory access in those programs. Fig. \ref{ratio} shows the variation of the ratio of memory access without SIMD instructions by the memory access with SIMD instructions (normalized by MAC) for different parameters and primitives. We observe in Fig. \ref{ratio} the same variations as in Fig. \ref{benchmark}.f . Thus, data reuse contributes strongly to the speed up of algorithms using SIMD instructions. However, convolutions and grouped convolutions have similar ratio in Fig. \ref{ratio} but different speedup in Fig. \ref{benchmark}.f . Other factors such as memory access continuity and padding are to be taken into account to explain the performance of these programs.

\begin{figure}
\includegraphics[width=\textwidth]{figure/all_ratiomemoryaccess.eps}
\vspace{-10pt}
\caption{Influence of the a) number of groups, b) kernel size, c) input width, d) number of input channels and e) filters on the ratio of memory access without SIMD instructions by the memory access with SIMD instructions (normalized by MACs) for different primitives.} \label{ratio}
\end{figure}
\vspace{-12pt}

\subsection{Influence of other factors}
For the following experiments, we fix the number of groups at 2, the kernel size at 3, the input width at 32, the input channel at 3 and the filters at 32.

\begin{figure}[t!]
\includegraphics[width=\textwidth]{figure/influence_of_frequency.eps}
\vspace{-10pt}
\caption{Influence of the MCU frequency on latency, energy consumption without SIMD instructions (a and b) and with SIMD instructions (c and d).} \label{frequency}
\end{figure}

\subsubsection{Influence of frequency}
We perform inferences on a frequency range from 10 to 80 Mhz (see Figure \ref{frequency}). Latency is inversely proportional to the frequency as expected. Power consumption increases with frequency (see Table \ref{tab2}) but to a lesser degree than the decrease of latency. Thus, using the maximum frequency of ARM Cortex-M MCUs lowers the inference's energy consumption.
\vspace{-10pt}
\input{table/tab2}
\vspace{-40pt}

\subsubsection{Influence of optimization level}
We perform a convolution inference with two different optimization levels (\texttt{O0} and \texttt{Os}). As seen in table \ref{tab3}, the compiler optimization has an important effect on the layer performance. Using \texttt{Os} level accelerates the inference by a factor 1.52. This impact is emphasized with the use of SIMD instructions (factor 9.81). Without optimization, the use of SIMD instructions can even increase the layer's energy consumption as using SIMD instructions increases the average power consumption.
\vspace{-10pt}
\input{table/tab3}
\vspace{-40pt}