
\note[Francesco]{I would prefer NOT to have a section devoted to preliminary definitions. I would prefer to introduce the needed notions in the part where it is needed.}

Here we introduce terminologies and notations to be used in this survey.


\subsection{Sets}
Let $\mathbb{R}$ and $\mathbb{Z}$ be the sets of reals and integers, respectively.
Let $\mathbb{R}_+$ and $\mathbb{Z}_+$ be the sets of nonnegative reals and nonnegative integers, respectively.


\subsection{Graphs}
Let $G=(V,E)$ be a simple, undirected graph consisting of $n=|V|$ vertices and $m=|E|$ edges.
For $S\subseteq V$, let $G[S]$ be the subgraph induced by $S$, i.e., $G[S]=(S,E[S])$, where $E[S]=\{\{u,v\}\mid u,v\in S\}$.
We denote by $\deg_S(v)$ the degree of $v$ in $G[S]$, i.e., $\deg_S(v)=|\{\{u,v\}\in E\mid u\in S\}|$.
When $S=V$, we just write $\deg(v)$.


\subsection{Submodular and supermodular functions}
Let $V$ be a finite set.
A function $f: 2^V\rightarrow \mathbb{R}$ is said to be \emph{submodular} if $f(X)+f(Y)\geq f(X\cup Y)+f(X\cap Y)$ holds for any $X,Y\subseteq V$.
There is a well-known equivalent definition of the submodularity:
A function $f$ is submodular if and only if $f(X\cup \{v\})-f(X)\geq f(Y\cup \{v\})-f(Y)$ holds for any $X\subseteq Y$ and $v\in V\setminus Y$,
which is called the \emph{diminishing marginal return property}.
A function $f: 2^V\rightarrow \mathbb{R}$ is said to be \emph{supermodular} if $-f$ is submodular.
The submodularity and supermodularity play an important role in discussing the densest subgraph problem and its variants.


\subsection{Approximation algorithms}
Let us consider a maximization problem.
Let $\text{OPT}$ be the optimal value of the problem.
For $\alpha \in [0,1]$, a feasible solution of the problem is said to be \emph{$\alpha$-approximate}
if it has an objective function value greater than or equal to $\alpha \cdot \text{OPT}$.
An algorithm for the problem is called an \emph{$\alpha$-approximation algorithm} if it outputs an $\alpha$-approximate solution for any instance.
For a minimization problem, the counterparts of the above can be defined similarly using $\alpha \in [1,\infty)$.
It should be noted that we sometimes violate the above rule:
we could use $\alpha \in [1,\infty)$ in an $\alpha$-approximate solution or an $\alpha$-approximation algorithm for a maximization problem.
In that case, readers can replace $\alpha$ by $1/\alpha$ appropriately. This is just for the sake of simplicity.

