In this section, we review the literature that has investigated the densest subgraph problem in computational frameworks distinct from those considered thus far. Section~\ref{subsec:private} is devoted to DSP in the differential privacy framework, while Section~\ref{subsec:streaming} presents findings on DSP in streaming and MapReduce, along with solutions suitable for distributed and parallel computational environments.

\subsection{Private graphs}\label{subsec:private}

Differential privacy is a mathematical framework for quantifying the privacy guarantees of algorithms that operate on sensitive data. It is often used to ensure that the output of a data analysis algorithm does not reveal sensitive information about individual data points in the input dataset.

In this context, the most common setup is the edge-privacy model \cite{blocki2013edgeprivacy}, which operates as follows.
Given a graph $G$, we denote with $V(G)$ and $E(G)$ respectively the sets of vertices and edges. We consider two graphs $G$ and $G'$ as neighbors ($G \sim G'$) if they differ in exactly one edge.
A (randomized) algorithm $M: G \rightarrow R$ is $(\epsilon, \delta)$-differentially private ($\epsilon > 0, \delta \in [0,1]$) if for any $S \subset R$ of its output space, and for any couple of graphs $(G, G')$, if $G \sim G'$ we have $P(M(G) \in S) \leq e^{\epsilon} P(M(G') \in S) + \delta$.

Nguyen and Vullikanti~\cite{nguyen2021differentially} were the first to present a solution to the problem of finding the densest subgraph in the edge-privacy model adapting the classical greedy peeling algorithm using the exponential mechanism iteratively, and providing an $(\epsilon, \delta)$-differentially private algorithm which outputs a $(2, O(\log n))$-approximate\footnote{Given a graph $G=(V,E)$, a subset of nodes $S\subseteq V$ is an $(\alpha, \beta)$-approximate solution for DSP if $d(S)=\frac{e[S]}{|S|} \geq \frac{d(S^*)}{\alpha} - \beta$, where $S^*$ is an optimal solution for DSP, $\alpha \geq 1$, and $\beta \geq 0$.} solution with high probability.
Farhadi, Hajiaghayi, and Shi~\cite{farhadi2022differentially} improved such result, proposing a linear time $(\epsilon, 0)$-differentially private algorithm algorithm that achieves $\left(2, \bigO(\frac{1}{\epsilon}\log^{2.5}n)\right)$-approximation.
Dhulipala et al.~\cite{dhulipala2022differential} propose another $(\epsilon, 0)$-differentially private algorithm, that runs in $\bigO((n+m)\log^3 n)$, and returns a solution that is a $\left(1 + \eta, \bigO\left(\frac{log^4n}{\epsilon}\right)\right)$-approximation for any constant $\eta > 0$, building it upon the multiplicative weight updates (MWU) algorithm.





\subsection{Streaming, distributed, parallel, and MapReduce}\label{subsec:streaming}
Bahmani, Kumar and Vassilvitskii~\cite{bahmani} were the first to study DSP in a streaming scenario.
The authors designed algorithms for DSP, DDS (Section \ref{subsec:directed}), and Dal$k$S (Section \ref{sec:size}) under the semi-streaming model of computation, where the set of vertices is known ahead of time and can fit into the main memory, while the edges arrive one by one.
The proposed algorithm is based on the approach of \cite{Charikar2000} (Algorithm~\ref{alg:peeling}),
making $\bigO(\log_{1+\epsilon} n)$ passes over the data, giving in output a $2(1+\epsilon)$-approximation for DSP; the adapted version of the algorithm for the DDS provides the same guarantees.
A slightly modified version of this method gives a $3(1+\epsilon)$-approximation for Dal$k$S, always performing $\bigO(\log_{1+\epsilon} n)$ passes over the input.
The authors also proved that any
$p$-pass streaming
$\alpha$-approximation ($\alpha \geq 2$) algorithm for DSP needs
$\Omega\left( \frac{n}{p\alpha^2} \right)$
space.
The authors also demonstrate how the algorithm can be easily parallelized by providing a MapReduce implementation.

Tsourakakis~\cite{Tsourakakis15} exploited these algorithmic techniques and efficient triangle counting algorithms in MapReduce\cite{suri2011Counting} to address the $k$-clique DSP.
The author gave a
$3(1+\epsilon)$-approximation algorithm
for $3$-clique DSP requiring
$\bigO(\log_{1+\epsilon} n)$ rounds.
Shi, Dhulipala, and Shun~\cite{shi2021parallel} addressed DSP under the \textit{workspan model} \cite{jeje1992introduction,cormen2022introduction},
where
the work W of an algorithm is the total number of operations, the span S is the longest dependency path, and with P processors available, the time for executing a parallel computation is
$\frac{W}{P}+S$.
The authors provided a parallel algorithm that
computes a
$k(1+\epsilon)$-approximation
for $k$-clique DSP running in
$\bigO\left(m\alpha^{k-2}\right)$ work,
$\bigO\left(k\log^2 n\right)$ span w.h.p, and requiring
$\bigO\left(m+P\alpha \right)$ space; $\alpha$ is the arboricity of the input graph\footnote{A graph has arboricity $\alpha$ if the minimum number of spanning forests needed to cover the graph is $\alpha$}.


Das Sarma et al.~\cite{dassarma2012dynamic} were the first to study DSP in a fully decentralized distributed computing peer-to-peer network model; the CONGEST~\cite{peleg2000distributed} model.
The authors gave a distributed algorithm
that w.h.p. in
$\bigO(D\log_{1+\epsilon} n)$ time provides a
$(2+\epsilon)$-approximation
for DSP and adoen
$(3+\epsilon)$-approximation
for Dal$k$S; where $D$ is the diameter of the graph.


Bahmani, Goel and Munagala \cite{bahmani2014efficient} presented primal-dual algorithms, working in the MapReduce framework,
that provide a
$(1+\epsilon)$-approximation
for both DSP and DDS, and run in
$\bigO\left(m\frac{\log n}{\epsilon^2}\right)$
time for DSP and $\bigO\left(m\frac{\log^2 n}{\epsilon^3}\right)$ for DDS
, by taking
$\bigO\left(\frac{\log n}{\epsilon^2}\right)$
MapReduce phases.
The total running time and shuffle size in each phase is $\bigO(m)$ and the reduce-key-complexity is $\bigO(d_{max})$, where $d_{max}$ is the maximum degree of a vertex in the graph.
The provided algorithm for DDS is obtained by combining the approach used for DSP with the linear program formulation for DDS provided in~\cite{Charikar2000}.

Ghaffari, Lattanzi, and Mitrovi\'{c}~\cite{ghaffari2019improved} studied DSP under the Massively Parallel Computation (MPC) model, a theoretical abstraction suitable for MapReduce.
The authors provided an algorithm that w.h.p. in
$\bigO\left(\sqrt{\log n}\,\log \log n\right)$
rounds computes a
$(1+\epsilon)$-approximation
for DSP.
The algorithm requires
$\tilde\bigO\left(n^\delta\right)$ memory per machine and a total memory of
$\tilde\bigO\left(max\{m, n^{1+\delta}\} \right)$;
for an arbitrary constant
$\delta \in (0,1)$.


Epasto, Lattanzi and Sozio~\cite{epasto2015dynamic} studied DSP in two dynamic graph models.
When edges can be added adversarially, the authors designed an algorithm that maintains at any point in time a
$2(1 + \epsilon)^2$-approximation
of the densest subgraph, performing
$\bigO\left(m\frac{\log^2 n}{\epsilon^2}\right)$
operations
%up to any point in time,
and requiring
$\bigO\left(m+n\right)$ space.

When edges can be added adversarially and removed uniformly at random, the authors proposed an algorithm that maintains at any point in time a
$2(1 + \epsilon)^6$-approximation
of the densest subgraph, performing
$\bigO\left(\frac{A\log A \log^2 n}{\epsilon^2} + \frac{R\log A \log^3 n}{\epsilon^4}\right)$~\footnote{$A$ and $R$ are the numbers of edge insertions and removals, respectively.}
operations with high probability and requiring
$\bigO\left(m+n\right)$ space.
For both algorithms, all results remain valid even in the presence of vertex insertions.

Ahmadian and Haddadan~\cite{ahmadian2021wedge} experimentally showed an improvement in the execution time by embedding this method in their framework at the cost of having a
$4(1 + \epsilon)^2$-approximation for DSP.


In the presence of both edge insertions and deletions,  Bhattacharya et al.~\cite{bhattacharya2015dynamic} designed an algorithm able to provide a $(4+\epsilon)$-approximation for DSP.
The algorithm requires $\tilde\bigO(n)$~
\footnote{Both factors of $\frac{1}{\epsilon}$, and $\poly\log n$ are hidden in the $\tilde\bigO$ notation}
space, it has an amortized time of $\tilde\bigO(1)$ for both insertion and deletion of an edge, and a query time of $\tilde\bigO(1)$ for obtaining the declared approximation of the densest subgraph at any point in time.
The authors also show how increasing the query time to
$\tilde\bigO(n)$ yields a $(2+\epsilon)$-approximation for DSP.
When the graph is represented by an incident list, the proposed algorithm
provides a $(2+\epsilon)$-approximation for DSP
by reading $\tilde\bigO(n)$
edges, requiring
$\tilde\bigO(n)$
query time, and $\tilde\bigO(n)$ space.
The authors also show the tightness up to a poly-logarithmic factor of this running time, providing a lower bound for the problem.
The authors also show the algorithm's applicability to the distributed streaming model defined in Cormode et al.~\cite{Cormode2010optimal},
showing that the algorithm computes a $(2+\epsilon)$-approximate solution for DSP using
$\tilde\bigO(k+n)$ bits of communications; where the space required by the coordinator is $\tilde\bigO(n)$ and the space required by each site is $\tilde\bigO(1)$.
The authors also extended the $(4+\epsilon)$-approximation algorithm for DSP to the DDS problem, obtaining a
$(8+\epsilon)$-approximation; the extended algorithm requires $\tilde\bigO(m+n)$ space, an amortized time of $\tilde\bigO(1)$ for both insertion and deletion of an edge, and a query time of $\bigO(1)$.

McGregor et al.~\cite{mcgregor2015dynamic} provide a single-pass algorithm that returns a $(1+\epsilon)$-approximation for DSP with high probability; their algorithm uses
%$\bigO(\frac{n\poly\log n}{\epsilon^2})$
$\tilde\bigO(n)$
space,
%$\bigO(\poly\log n)$
$\tilde\bigO(1)$
time for each edge insertion and deletion, and
$\bigO(\poly n)$
query time.
The space used by the algorithm matches the lower bound defined in \cite{bahmani} up to a poly-logarithmic factor for constant $\epsilon$. At the same time, the polynomial query time follows by using any exact algorithm for DSP on the subgraph generated by the algorithm.

Esfandiari, Hajiaghayi and Woodruff \cite{esfandiari2016dynamic} also provided a single-pass algorithm that returns a $(1+\epsilon)$-approximation for DSP with high probability:
using
$\tilde\bigO(m)$ space,
$\tilde\bigO(1)$
time for each edge insertion and deletion, and
$\bigO(\poly n)$
query time.
Their algorithm is based on sampling (and storing) edges from the input graph uniformly at random without replacement.
As in McGregor et al.~\cite{mcgregor2015dynamic}, even in this case polynomial query time follows by using any exact algorithm for DSP on the subgraph generated by the algorithm.
The authors also proved that using the classical greedy peeling algorithm~\cite{Charikar2000}(Algorithm~\ref{alg:peeling}) at query time,
and using an oracle that provides direct access to a uniformly sampled edge,
the proposed algorithm gives a
$(2+\epsilon)$-approximation for DSP with high probability
running in
$\tilde\bigO(n)$ time.
The authors prove that the generality of their algorithmic framework provides a
$(1+\epsilon)$-approximation for DDS with high probability:
using
$\tilde\bigO(n^{\frac{3}{2}})$ space,
$\tilde\bigO(1)$
time for each edge insertion and deletion, and
$\bigO(\poly n)$
query time for solving DDS exactly.

Su and Vu~\cite{su2020distributed} gave a distributed algorithm under the CONGEST~\cite{peleg2000distributed} model that w.h.p. in
$\bigO\left(D+\frac{\log^4 n}{\epsilon^4}\right)$ time provides a
$(1+\epsilon)$-approximation
for DSP; where $D$ is the diameter of the graph.

Sawlani and Wang~\cite{sawlani2020dynamic}
gave a deterministic algorithm providing a
$(1+\epsilon)$-approximation for DSP,
with
$\bigO\left(\frac{\log^4 n}{\epsilon^6}\right)$
worst-case time per edge insertion or deletion, and
$\bigO(1)$ worst-case query time.
The author also give a deterministic algorithm providing a
$(1+\epsilon)$-approximation for DDS,
with
$\bigO\left(\frac{\log^5 n}{\epsilon^7}\right)$
worst-case time per edge insertion or deletion, and
$\bigO\left(\frac{\log n}{\epsilon}\right)$ worst-case query time.
Moreover, for both DSP and DDS, at any point in time, the corresponding algorithms can output the approximate densest subgraph in time
$\bigO(|S| + \log n)$, where $S$ is the set of vertices in the output.

Christiansen et al.~\cite{christiansen2022adaptive}  improved the result of Sawlani and Wang~\cite{sawlani2020dynamic}
giving a deterministic algorithm providing a
$(1+\epsilon)$-approximation for DSP,
with
$\bigO\left(\frac{\log^2 n \log \rho^*}{\epsilon^4}\right)$
worst-case time per edge insertion or deletion,
where $\rho^*$ is the density of the densest subgraph, and
$\bigO(1)$ worst-case query time.
At any point in time, the algorithms can output the approximate densest subgraph in time
$\bigO(|S|)$, where $S$ is the set of vertices in the output.

Independently form Christiansen et al.~\cite{christiansen2022adaptive}, Chekuri and Quanrud~\cite{chekuri2022dynamic} also improved the result of Sawlani and Wang~\cite{sawlani2020dynamic}
giving a deterministic algorithm providing a
$(1+\epsilon)$-approximation for DSP,
with
$\bigO\left(\frac{\log^2 n}{\epsilon^4}\right)$ amortized time and
$\bigO\left(\frac{\log^3 n \log\log n}{\epsilon^6}\right)$
worst-case time per edge insertion or deletion,
and
$\bigO(1)$ worst-case query time.
At any point in time, the algorithms can output the approximate densest subgraph in time
$\bigO(|S|)$, where $S$ is the set of vertices in the output.


Henzinger, Paz and Sricharan~\cite{henzinger2022fine}
showed that for DSP
on graphs with a maximum degree less equal to seven, constant-degree graphs, expanders, and power-law graphs
there is no dynamic algorithm which achieves both
$\bigO\left(n^{\frac{1}{4}-\epsilon}\right)$ amortized edge update time, and
$\bigO\left(n^{\frac{1}{2}-\epsilon}\right)$ amortized query time.
This conditional lower bound is weaker than the one for general graphs:
$\bigO\left(n^{\frac{1}{2}-\epsilon}\right)$ amortized edge update time, and
$\bigO\left(n^{1-\epsilon}\right)$ amortized query time.

Chu et al.~\cite{chu2022hierarchical} presented a parallel algorithm that in time
$\bigO\left( n\sqrt{p} + m\alpha(n) + F\right)$
computes a $2$-approximate solution for DSP requiring $\bigO\left(n\right)$ additional space to the input storage, where $p$ is the number of threads, $F$ is the number of failures, and $\alpha(n)$ is the inverse of the Ackermann function.
The authors stated that for practical input, the dominant term is
$m\alpha(n) \leq 4m$;
consequently, the time complexity reduces to
$\bigO\left(m\right)$.

The first contribution tackling DSP on hypergraphs in a streaming scenario was by Hu, Wu, and Chan.~\cite{hu2017dynamicsub}. The authors developed two dynamic algorithms for DSH (see Section \ref{subsec:hyper})  by extending to hypergraphs the pioneering algorithm of Bahmani, Kumar and Vassilvitskii~\cite{bahmani}.
With only arbitrary edge insertions, the authors give a dynamic algorithm providing a
$r(1+\epsilon)$-approximation for DSH\footnote{Here $r$ denotes the maximum cardinality of a hyperedge.},
with
$\bigO\left(\poly\left(\frac{r}{\epsilon} \log n \right)\right)$ amortized time per edge insertion, and
requiring
$\bigO(n)$ extra space in addition to the input hypergraph.
When both arbitrary edge insertions and deletions are allowed, the authors gave a dynamic algorithm providing a
$r^2(1+\epsilon)$-approximation for DSH,
with
$\bigO\left(\poly\left(\frac{r}{\epsilon} \log n \right)\right)$ amortized time for each edge insertion and deletion, and
requiring
$\bigO\left(r m \poly\left(\frac{r}{\epsilon} \log n \right)\right)$ extra space in addition to the input hypergraph.

Bera et al.~\cite{bera2022dynamicsub} addressed the weighted densest hypersubgraph problem on  in a streaming scenario giving
a randomized fully dynamic algorithm providing a
$(1+\epsilon)$-approximation for the problem.
For both edge insertion and deletion the worst-case time is
$\bigO\left(\frac{r^2 \log^3 n \log^2 m }{\epsilon^7} \right)$,
while the query worst-case time is
$\bigO\left( \log \epsilon^{-1} + \log\log m \right)$ and
$\bigO(|S| + \log n)$
worst-case time is required to output the approximate weighted densest hypersubgraph, where $S$ is the set of vertices in the output.
The algorithm also needs a preprocessing step requiring
$\bigO\left(\frac{w_{max} \log w_{max} \log m}{\epsilon^2} \right)$ time,
where $w_{max}$ is the max-weight of a hyperedge.

Chekuri and Quanrud~\cite{chekuri2022dynamic} presented a deterministic algorithm providing a
$(1+\epsilon)$-approximation for DSH,
with
$\bigO\left(\frac{r^2 \log^2 n}{\epsilon^4}\right)$ amortized time and
$\bigO\left( \frac{r\log(n) \log(\rho^*)}{\epsilon^4} + \frac{r^2\log^3(n) \left(\log\log(n) + \log \epsilon^{-1} \right)}{\epsilon^6} \right)$
worst-case time per hyperedge insertion or deletion (where $\rho^*$ is the density of the densest subhypergraph),
and
$\bigO(1)$ worst-case query time.
At any point in time, the algorithms can output the approximate densest subhypergraph in time
$\bigO(|S|)$, where $S$ is the set of vertices in the output.




