This section delves into different variants of DSP, defined by means of constraints.
We will begin covering size-constrained problems, which set limits on the desired size of the output subgraph.
Next, we will investigate seed-set problems, where an initial set of nodes - referred to as seed set - influences the final outcome. These problems enable to exploit prior knowledge and information about the network structure to guide the search for the densest subgraph.
Finally, we will examine problems with connectivity constraints, where the output subgraph must meet specific requirements in terms of connectivity, to prevent potential vertex/edge failures.


\subsection{Size constraints}
\label{sec:size}

Size-constrained versions of DSP are well-known in literature, as they can be useful in certain applications where the size of the solution needs to be controlled. There are variants of DSP that require the output to contain exactly $k$ nodes, at least $k$ nodes, and at most $k$ nodes. While DSP is polynomial-time solvable, adding size constraints make the problem hard.
In the rest of this section we review these variants.


\subsubsection{Densest $k$-subgraph problem}\label{subsubsec:DkS}
Given a simple undirected graph $G=(V,E)$ and a positive integer $k$ the densest $k$-subgraph problem (D$k$S) requires to find a vertex subset $S\subseteq V$ that maximizes $d(S)=e[S]/|S|$ subject to $|S|=k$.
Note that as the size of solutions is fixed by the constraint $|S|=k$, the objective function $d(S)$ can be reduced to $e[S]$.
It is easy to see that the maximum clique problem can be reduced to D$k$S; therefore, the problem is \NP-hard.
D$k$S is known not only as a variant of DSP but also as one of the most fundamental combinatorial optimization problems, and would deserve a survey of its own. Indeed, a large body of work has been devoted to designing effective algorithms for the problem and to provide some hardness results beyond the \NP-hardness.

There are a lot of polynomial-time approximation algorithms for D$k$S.
Feige, Kortsarz, and Peleg~\cite{FPK01} proposed a combinatorial polynomial-time $O(n^{1/3-\delta})$-approximation algorithm for some tiny $\delta >0$,
based on a polynomial-time $O(n^{0.3885})$-approximation algorithm in its preliminary version~\cite{Kortsarz1993choosing}.
They first presented an algorithm that outputs the best solution among the three found by one trivial procedure and two greedy procedures,
and proved that the algorithm has an approximation ratio of $O(n^{1/3})$.
Then, to improve the approximation ratio, they showed that there are only two cases where the above algorithm fails to obtain an $O(n^{1/3-\delta})$-approximate solution,
and introduced two additional procedures, each of which can get a better solution for one of the two cases.
Later, Goldstein and Langberg~\cite{Goldstein2009dense} estimated the above approximation ratio of $O(n^{1/3-\delta})$ and concluded that it is approximately equal to $O(n^{0.3226})$.
In addition, they presented an algorithm with a slightly better approximation ratio of $O(n^{0.3159})$.
The breakthrough result in this line of research is due to Bhaskara et al.~\cite{Bhaskara+10}:
They proposed an $O(n^{1/4+\epsilon})$-approximation algorithm running in $n^{O(1/\epsilon)}$ time, for any $\epsilon >0$.
This approximation ratio is the current state-of-the-art for D$k$S, and therefore it is an open problem its improvement.
The algorithm is based on a clever procedure that distinguishes random graphs from random graphs with planted dense subgraphs.
In addition, there are some algorithms with an approximation ratio depending on the parameter $k$.
Asahiro et al.~\cite{Asahiro2000} demonstrated that the straightforward application of the greedy peeling algorithm attains the approximation ratio of $O(n/k)$.
Later, Feige and Langberg~\cite{FL01} employed semidefinite programming (SDP) and achieved an approximation ratio somewhat better than $O(n/k)$.

There are some approximation algorithms for D$k$S with some specific instances.
Arora, Karger, and Karpinski~\cite{AKK95} proved that there exists a polynomial-time approximation scheme (PTAS) for D$k$S on $G$ with $m=\Omega(n^{2})$ and $k=\Omega(n)$.
Ye and Zhang~\cite{Ye2003approximation} developed an SDP-based polynomial-time $1.7048$-approximation algorithm for D$k$S with $k=n/2$,
which improves some previous results, e.g., a trivial randomized $4$-approximation, $2$-approximation algorithm using LP~\cite{Goemans1996mathematical} or SDP~\cite{Feige1997densest}.
Liazi, Milis, and Zissimopoulos~\cite{Liazi2008constant} presented a polynomial-time $3$-approximation algorithm for D$k$S with chordal graphs.
Later, Chen, Fleischer, and Li~\cite{Chen2010densest} developed a polynomial-time constant-factor approximation algorithm for D$k$S with a variety of classes of intersection graphs, including chordal graphs and claw-free graphs.
They also proposed a PTAS for D$k$S on unit disk graphs, which improves the previous $1.5$-approximation for D$k$S on proper interval graphs, a special case of unit disk graphs~\cite{Backer2010constant}.
Papailiopoulos et al.~\cite{Papailiopoulos2014finding} designed an algorithm for D$k$S that looks into a low-dimensional space of dense subgraphs. The approximation guarantee depends on the graph spectrum, which is effective for many graphs in applications. The algorithm runs in nearly-linear time under some mild assumptions of the graph spectrum, and is highly parallelizable.
Khanna and Louis~\cite{khanna2020planted} introduced semi-random models of instances with a planted dense subgraphs and studied the approximability of D$k$S.
They showed that approximation ratios better than $O(n^{1/4+\epsilon})$ can be achieved for a wide range of parameters of the models.

On the other hand, there are several inapproximability results for D$k$S.
It is known that D$k$S has no PTAS assuming some reasonable computational complexity assumptions.
For example, Feige~\cite{Feige02} assumed that random 3-SAT formulas are hard to refute,
Khot~\cite{Khot06} assumed that \NP does not have any randomized algorithm running in subexponential time,
and Raghavendra and Steurer~\cite{raghavendra2010expansion} assumed a strengthened version of the unique games conjecture (UGC).
Moreover, Manurangsi~\cite{Manurangsi2017Almost} proved that D$k$S cannot be approximated up to a factor of $n^{\frac{1}{\left(\log \log n\right)^c}}$, for some $c>0$ assuming the exponential time hypothesis (ETH)~\cite{Impagliazzo2001Complexity}.
Braverman et al.~\cite{braverman2017eth} ruled out a PTAS in terms of the additive approximation, assuming ETH.
The inapproximability results for D$k$S have been used for showing some inapproximability results for other important optimization problems.
For example, Huchette et al.~\cite{huchette2020contextual} proved that there exists no polynomial-time exact algorithm for a reserve price optimization problem in auctions, under ETH, by constructing an approximation-preserving reduction from D$k$S to the problem.

Apart from the approximability and inapproximability, the parameterized complexity of D$k$S has also been studied
(see e.g., \cite{Cygan2015parameterized,Niedermeier2006invitation} for the concepts of the parameterized complexity).
Cai~\cite{Cai2008parameterized} proved that D$k$S is $\text{W}[1]$-hard with respect to the parameter $k$, meaning that there exists no fixed-parameter tractable algorithm for D$k$S parameterized by $k$, unless $\ensuremath{\mathrm{P}} = \NP$.
Bourgeois et al.~\cite{Bourgeois2013exact} showed that D$k$S can be solved exactly in $2^\texttt{tw}\cdot n^{O(1)}$ time, where $\texttt{tw}$ is the tree-width of the input graph.
Broersma, Golovach, and Patel~\cite{Broersma2013tight} demonstrated that D$k$S can be solved in $k^{O(\texttt{cw})}\cdot n$ time, where $\texttt{cw}$ is the clique-width of the input graph, but it cannot be solved in $2^{o(\texttt{cw}\log k)}\cdot n^{O(1)}$ time, unless ETH fails.
Recently, Mizutani and Sullivan~\cite{Mizutani2022parameterized} proved that D$k$S can be solved in any of $f(\texttt{nd})\cdot n^{O(1)}$ time and $O(2^\texttt{cd}\cdot k^2n)$ time, where \texttt{nd} and \texttt{cd} denote the neighborhood diversity and the cluster deletion number, respectively, of the input graph, and $f$ is some computable function.
Hanaka~\cite{Hanaka2023computing} independently showed that D$k$S is fixed parameter tractable when parameterized by the neighborhood diversity, as well as the block deletion number, distance-hereditary deletion number, and cograph deletion number.

There are some other exact algorithms for D$k$S,
based on mathematical programming, heuristic search, or graph-theoretic methods.
Billionnet, Elloumi, and Plateau~\cite{Billionnet2009improving} devised a reformulation technique that is applicable to a wide range of quadratic programming problems, including D$k$S.
Malick and Roupin~\cite{Malick2012solving} presented a branch-and-bound method based on SDP relaxations of D$k$S.
Later, Krislock, Malick, and Roupin~\cite{Krislock2016computational} improved the above branch-and-bound method using a better bounding procedure.
Komusiewicz and Sommer~\cite{komusiewicz2020fixcon} devised an enumeration-based exact algorithm for a special case of D$k$S, where the subgraph obtained should be connected. To avoid enumerating all connected subgraphs with $k$ vertices, they employed some generic pruning rules and a generic heuristic for computing a lower bound for the objective function value.
Gonzales and Migler~\cite{gonzales2019densest} designed an $O(nk^2)$-time exact algorithm for D$k$S on outerplanar graphs.

Furthermore, there are some algorithms that can compute an optimal solution to D$k$S for some value of $k$ determined \emph{a posteriori}.
As a densest subgraph is an optimal solution to D$k$S with $k$ equal to its size, an exact algorithm for DSP is a trivial example.
Kawase and Miyauchi~\cite{Kawase-Miyauchi18} introduced the concept of dense-frontier points of a graph.
Given $G=(V,E)$, let us plot all the points contained in $\{(|S|,e[S])\mid S\subseteq V\}$.
They referred to the extreme points of the upper convex hull of the above set as the dense frontier points of $G$.
Note that the densest subgraph and the entire graph are typical vertex subsets corresponding to dense frontier points.
Kawase and Miyauchi~\cite{Kawase-Miyauchi18} designed an LP-based algorithm that computes a corresponding vertex subset for every dense frontier point, in polynomial time.
An algorithm designed by Nagano, Kawahara, and Aihara~\cite{Nagano+11} can also be used to obtain a corresponding vertex subset for every dense frontier point.
Their algorithm is based on the computation of a minimum norm base of a submodular polyhedron.

There are some effective heuristics for D$k$S.
Sotirov~\cite{sotirov2020solving} developed coordinate descent heuristics for D$k$S, with a special emphasis on the simultaneous update of a lot of coordinates.
The computational experiments showed that the heuristics are highly effective for large graphs.
Bombina and Ames~\cite{bombina2020convex} introduced a novel convex programming relaxation for D$k$S using the nuclear norm relaxation of a low-rank and sparse decomposition of the adjacency matrices of subgraphs with $k$ vertices. Using the relaxation, they proved that an optimal solution can be obtained if the input is sampled randomly from a distribution of random graphs constructed to contain a highly dense subgraphs with $k$ vertices with high probability.
Konar and Sidiropoulos~\cite{konar2021exploring} presented another novel convex programming relaxation for D$k$S. Specifically, they reformulated D$k$S as a submodular function minimization subject to a cardinality constraint, and introduced the relaxation as a Lov\'asz extension minimization over the convex hull of the cardinality constraint. They proposed an effective heuristic for D$k$S by developing a highly scalable algorithm for the relaxation, based on the alternating direction method of multipliers (ADMM), followed by simple rounding procedures.


There are some papers dealing with the edge-weighted version of D$k$S with some specific edge weights, where the edge weights are nonnegative.
Ravi, Rosenkrantz, and Tayi~\cite{Ravi1994heuristic} presented a polynomial-time $4$-approximation algorithm for the problem with edge weights satisfying the triangle inequality.
Later, Hassin, Rubinstein, and Tamir~\cite{Hassin1997approximation} proposed an algorithm with a better approximation ratio of $2$.
Recently, Chang et al.~\cite{chang2020hardness} considered a generalized setting, where edge weights only satisfy a relaxed variant of the triangle inequality.
They demonstrated that the problem is \NP-hard for any degree of relaxation of the triangle inequality and extended the above $2$-approximation algorithm to the generalized setting.

Barman~\cite{barman2018approximating} studied a slight variant of D$k$S called the normalized densest $k$-subgraph problem (ND$k$S), where the objective function is normalized to be at most 1, i.e., $e[S]/|S|^2$ is considered. As $|S|$ is fixed to $k$, the inapproximability in terms of the multiplicative approximation is inherited from D$k$S.
Instead, Barman~\cite{barman2018approximating} focused on an additive approximation for ND$k$S, and developed an $\epsilon$-additive approximation algorithm running in $n^{O\left(\frac{\log \Delta}{\epsilon^2}\right)}$ time, where $\Delta$ is the maximum degree of $G$.
Barman~\cite{barman2018approximating} also gave an $\epsilon$-additive approximation algorithm for a bipartite graph variant of ND$k$S called the densest $k$-bipartite subgraph problem (D$k$BS).
Braverman et al.~\cite{braverman2017eth} studied the inapproximability in terms of the additive approximation of ND$k$S:
They ruled out an additive PTAS for ND$k$S under ETH.
Hazan and Krauthgamer~\cite{Hazan2011how} showed that there exits no PTAS for D$k$BS under some computational complexity assumptions.


\subsubsection{Densest at-least-$k$-subgraph problem and densest at-most-$k$-subgraph problem}
There are two relaxations of D$k$S, introduced by Andersen and Chellapilla~\cite{AndersenChellapilla}.
The two problems are called the densest at-least-$k$ subgraph problem (Dal$k$S) and the densest at-most-$k$ subgraph problem (Dam$k$S).
As suggested by the names, Dal$k$S and Dam$k$S ask vertex subsets $S\subseteq V$ that maximizes $d(S)$ subject to $|S|\geq k$ and $|S|\leq k$, respectively.
Obviously, similar to D$k$S, Dam$k$S is \NP-hard.
The \NP-hardness of Dal$k$S is not trivial, but it was proved by Khuller and Saha~\cite{Khuller2009Dense} by reducing D$k$S to Dal$k$S.

Andersen and Chellapilla~\cite{AndersenChellapilla} presented a linear-time $3$-approximation algorithm for Dal$k$S
using the greedy peeling algorithm for DSP.
The analysis of the approximation ratio of $3$ is based on the relationship between subgraphs with large density and subgraphs with large minimum degree,
which can be viewed as a generalization of the analysis of $2$-approximation for DSP by Kortsarz and Peleg~\cite{Kortsarz-Peleg94}.
Andersen and Chellapilla~\cite{AndersenChellapilla} also mentioned the hardness of approximation of Dam$k$S:
In particular, they proved that if there exists a polynomial-time $\gamma$-approximation algorithm for Dam$k$S ($\gamma\geq 1$),
then there exists a polynomial-time $8\gamma^2$-approximation algorithm for D$k$S.

Later, Khuller and Saha~\cite{Khuller2009Dense} improved the approximability of Dal$k$S and the hardness of approximation of Dam$k$S.
For Dal$k$S, they designed an LP-based $1/2$-approximation algorithm.
Their basic algorithm first solves $n-k+1$ LPs, each of which is indexed by the size guess $\ell$ of an optimal solution ($\ell=k,k+1,\dots, n$).
Then the algorithm constructs $n-k+1$ candidate solutions from the optimal solutions to the LPs and finally outputs the best among them.
Their analysis of the approximation ratio of $2$ is based on the analysis by Charikar~\cite{Charikar2000}
that DSP can be solved exactly by the LP-based algorithm.
The algorithm proposed by Khuller and Saha~\cite{Khuller2009Dense} offers a significant improvement over Andersen and Chellapilla's~\cite{AndersenChellapilla} in terms of approximation ratio, presenting a noteworthy challenge for future advancements. However, its time complexity is significantly impacted by the increased number of LPs that must be solved.
To mitigate this, Khuller and Saha~\cite{Khuller2009Dense} suggested incorporating the algorithm by Andersen and Chellapilla into (a lighter version of) the above algorithm.
Specifically, the resulting algorithm outputs the best solution among the two:
one is the output of the algorithm by Andersen and Chellapilla~\cite{AndersenChellapilla}
and the other is the candidate solution constructed from the optimal solution to the LP with $\ell=k$.
Therefore, the algorithm needs to solve just one LP.
As for the inapproximability of Dam$k$S, Khuller and Saha~\cite{Khuller2009Dense} proved that
if there exists a polynomial-time $\gamma$-approximation algorithm for Dam$k$S ($\gamma\geq 1$),
then there exists a polynomial-time $4\gamma$-approximation algorithm for D$k$S,
which improves the above hardness result by Andersen and Chellapilla~\cite{AndersenChellapilla} and implies that Dam$k$S is as hard to approximate as D$k$S within a constant factor.
Due to the aforementioned inapproximability of D$k$S by Manurangsi~\cite{Manurangsi2017Almost}, Dam$k$S cannot be approximated up to a factor of $n^{\frac{1}{\left(\log \log n\right)^c}}$, for some $c>0$ assuming ETH~\cite{Impagliazzo2001Complexity}.

Recently, Zhang and Liu~\cite{zhang2021approximating} developed a randomized bicriteria approximation algorithm for Dam$k$S.
Specifically, their algorithm, in expected polynomial time, returns $S\subseteq V$ that achieves in expectation the objective function value at least $\frac{1}{4}\left(1+\left(\frac{k-1}{n}\right)^2\right)$ times the optimal value and has in expectation at most $(n-k+1)/e$ extra vertices beyond $k$.


\subsection{Seed set}

Seed-set problems, are specific variants of DSP that incorporates an initial set of nodes known as the seed set. The seed set serves as a starting point for finding the densest subgraph and provides a way to leverage prior knowledge and information about the network structure to guide the search process.


Dai, Qiao, and Chang~\cite{dai2022anchored} defined and studied the problem of anchored densest subgraph search (ADS). Given a graph $G=(V,E)$, a reference node set $R$ and an anchored node set $A$, with $A \subseteq R \subseteq V$, the ADS problem consists in finding a set of nodes $S$, that contains all nodes in $A$ ($A \subseteq S \subseteq V$), and that maximises the following quantity:
$\frac{2 e[S] - \sum_{v \in S \setminus R} \deg(v)}{|S|}$.
The authors designed an exact algorithm for the ADS problem based on a modified version of the Goldberg~\cite{goldberg1984finding} reduction to
$O\left(\log \sum_{v \in R} \deg(v) \right)$
instances of maximum-flow.
The complexity of the proposed method is bounded by a polynomial of $\sum_{v \in R} \deg(v)$, and is independent of the size of the input graph.

Sozio and Gionis~\cite{Sozio} defined and studied the \textit{``cocktail party''} problem:
given a graph $G=(V,E)$,
and a set of query nodes $Q \subseteq V$,
the problem consists in finding
a set of nodes $S$ containing all query nodes ($Q\subseteq S$),
witch induced subgraph
maximizes
a node-monotone non-increasing function
satisfying
a set of monotone non-increasing properties.
The authors considered the minimum degree as the node-monotone non-increasing function to maximize
and a condition on the maximum allowed distance between the solution set $S$ and the query set $Q$ as the monotone non-increasing property to satisfy.
The author proved that a direct adaptation to the \textit{``cocktail party''} problem of the Charikar greedy peeling algorithm (Algorithm~\ref{alg:peeling}) always returns an optimum solution for the problem.

Tsourakakis et al.~\cite{tsourakakis2013denser} proposed heuristic methods to extract dense subgraphs containing a set of pre-specified vertices.
Instead of maximising the average degree, the authors focused on finding optimal quasi-cliques containing a given set of input vertices.

Fazzone et al.~\cite{Fazzone2022} defined the Dense Subgraphs with Attractors and Repulsers Problem (DSAR), whose goal is to find
a dense cluster of nodes $S$, where each node in $S$ is simultaneously close to
to a given set $A$ of nodes (Attractors) and far from a given set $R$ of nodes (Repulsers). Fazzone et al. proved that DSAR is a special instance of a generalization of DSP on weighted graphs, which was first introduced by Goldberg in his seminal 1984 paper~\cite{goldberg1984finding}, and which was
dubbed Heavy and Dense Subgraph Problem (HDSP) in \cite{Fazzone2022}.


\subsection{Connectivity constraints}
Connectivity constraints on DSP require the output subgraph to satisfy specific requirements in terms of connectivity between the vertices.
These problems are motivated by the fact that densest subgraphs have a structural drawback, that is, they may not be robust to vertex/edge failure, thus not reliable in real-world applications such as network design, transportation, and telecommunications, to name a few.
Indeed, densest subgraphs may not be well-connected, which implies that they may be disconnected by removing only a few vertices/edges within it.
As a toy example, consider a barbell graph consisting of two equally-sized large cliques bridged by only one edge.
In the classical DSP setup, the entire graph would be the densest subgraph, but the failure of the edge connecting the 2 cliques would disconnect the entire graph.

In this spirit, Bonchi et al.~\cite{bonchi2021finding} introduced two related optimization problems: the densest $k$-vertex-connected subgraph problem and the densest $k$-edge-connected subgraph problem.
In the densest $k$-vertex/edge-connected subgraph problem,
give an undirected graph $G=(V,E)$ and a positive integer $k$, we seek a vertex subset $S\subseteq V$ that maximizes $d(S)$ subject to the constraint that $G[S]$ is $k$-vertex/edge-connected, i.e., the subgraph would be still connected with the removal of any subset of $k$ different vertices/edges.
Bonchi et al.~\cite{bonchi2021finding} first designed polynomial-time $\left(4/\gamma,1/\gamma\right)$-bicriteria approximation algorithms
with parameter $\gamma\in [1,2]$ for these problems.
Note that setting $\gamma=1$, we can obtain $4$-approximation algorithms for the problems.
The algorithms are designed based on a well-known theorem in extremal graph theory, proved by Mader~\cite{Mader72}.
They then designed polynomial-time $19/6$-approximation algorithms for the problems,
which improves the above approximation ratio of $4$ derived directly from the bicriteria approximation ratio.

