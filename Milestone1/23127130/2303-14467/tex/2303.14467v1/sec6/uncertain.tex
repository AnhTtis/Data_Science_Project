\subsection{Uncertain graphs}

Zou~\cite{zou2013polynomial} studied the densest subgraph problem on uncertain graphs.
An uncertain graph is a pair of $G=(V,E)$ and $p\colon E\rightarrow [0,1]$,
where $e\in E$ is present with probability $p(e)$ whereas $e\in E$ is absent with probability $1-p(e)$ \cite{PotamiasBGK10,BonchiGKV14}.
In the problem, given an uncertain graph $G=(V,E)$ with $p$, we seek $S\subseteq V$ that maximizes the expected density.
Zou~\cite{zou2013polynomial} showed that this problem can be reduced to DSP on edge-weighted graphs,
and designed a polynomial-time exact algorithm based on the reduction.

Miyauchi and Takeda~\cite{miyauchi2018robust} considered the uncertainty of edge weights rather than the existence of edges.
To model that, they assumed that there is an edge-weight space $I=\times_{e\in E}[l_e,r_e]\subseteq \times_{e\in E}[0,\infty)$
that contains the unknown true edge weight $w$.
To evaluate the performance of $S\subseteq V$ without any concrete edge weight,
they employed a well-known measure in the field of robust optimization, called the robust ratio.
In their scenario, the robust ratio of $S\subseteq V$ under $I$ is defined as the multiplicative gap between the density of $S$ in terms of edge weight $w'$ and the density of $S^*_{w'}$ in terms of edge weight $w'$ under the worst-case edge weight $w'\in I$, where $S^*_{w'}$ is a densest subgraph on $G$ with $w'$.
Intuitively, $S\subseteq V$ with a large robust ratio has a density close to the optimal value even on $G$ with the edge weight selected adversarially from $I$.
Using the robust ratio, they introduced the robust densest subgraph problem:
Given an undirected graph $G=(V,E)$ and an edge-weight space $I=\times_{e\in E}[l_e,r_e]\subseteq \times_{e\in E}[0,\infty)$,
we are asked to find $S\subseteq V$ that maximizes the robust ratio under $I$.
They designed an algorithm that returns $S\subseteq V$ with a robust ratio at least $\frac{1}{\max_{e\in E}\frac{r_e}{l_e}}$
under some mild condition.
Moreover, they proved that the lower bound on the robust ratio achieved by the above algorithm is the best possible except for the constant factor.
In addition, they also introduced the robust densest subgraph problem with sampling oracle,
where we have access to an oracle that accepts $e\in E$ and outputs a value drawn from a distribution on $[l_e, r_e]$
in which the expected value is equal to the unknown true edge weight.
For this problem, they designed a pseudo-polynomial-time algorithm with a strong quality guarantee.

Tsourakakis et al.~\cite{tsourakakis2019novel} introduced an optimization problem
called the risk-averse dense subgraph discovery problem.
The problem adopts a more general form of uncertain graphs introduced by Tsourakakis et al.~\cite{tsourakakis2018risk}.
An uncertain graph here is defined as a pair of $G=(V,E)$ and $(g_e(\theta_e))_{e\in E}$,
where the weight $w(e)$ of each edge $e\in E$ is drawn independently from the rest
according to some probability distribution $g_e$ with parameter $\theta_e$.
Each probability distribution $g_e$ is assumed to have a finite mean $\mu_e$ and a finite variance $\theta^2_e$.
Roughly speaking, their risk-averse variant aims to find $S\subseteq V$
that maximizes $\frac{\sum_{e\in E[S]}\mu_e}{|S|}$ but minimizes $\frac{\sum_{e\in E[S]}\sigma^2_e}{|S|}$.
Specifically, in the risk-averse dense subgraph discovery problem,
given an uncertain graph $G=(V,E)$ and $(g_e(\theta_e))_{e\in E}$,
we are asked to find $S\subseteq V$ that maximizes
$f(S)=\frac{\sum_{e\in E[S]}\mu_e+\lambda_1|S|}{\sum_{e\in E[S]}\sigma^2_e+\lambda_2|S|}$,
where $\lambda_1, \lambda_2 \geq 0$ are positive parameters, controlling the size of outputs.
Tsourakakis et al.~\cite{tsourakakis2019novel} showed that this problem reduces to DSP on negatively-weighted graphs,
and designed an efficient approximation algorithm based on the reduction.

Recently, Kuroki et al.~\cite{Kuroki+20} pointed out that
the sampling procedure used in Miyauchi and Takeda~\cite{miyauchi2018robust},
where all edges are repeatedly queried by a sampling oracle that returns an individual edge weight,
is often quite costly or sometimes impossible.
To overcome this issue, they introduced a novel framework called the densest subgraph bandits (DS bandits),
by incorporating the concept of stochastic combinatorial bandits~\cite{chen2013combinatorial,chen2014combinatorial} into DSP.
In DS bandits, a learner is given an undirected graph $G=(V,E)$,
whose edge-weights are associated with unknown probability distributions.
During the exploration period, the learner chooses a subset of edges (rather than only single edge, unlike Miyauchi and Takeda~\cite{miyauchi2018robust}) to sample,
and observes the sum of noisy edge weights in a queried subset.
They investigate DS bandits with the objective of best arm identification;
that is, the learner must report one subgraph that (s)he believes to be optimal after the exploration period.
Their first algorithm is designed based on the technique of linear bandits,
for which they presented an upper bound on the number of samples required to identify a $(1+\epsilon)$-approximate solution
with probability at least $1-\delta$ for $\epsilon>0$ and $\delta \in (0,1)$.
Their second algorithm is scalable and parameter free,
designed by combining the successive reject strategy~\cite{audibert2010best} for the multi-armed bandits
and the greedy peeling algorithm~\cite{Charikar2000} for DSP.
They proved that an upper bound on the probability that DS-SR outputs a solution whose density is less than half of the optimal value.

Sun et al. \cite{sun2021efficient} applied their probabilistic truss indexing framework to perform for the first time the triangle densest subgraph detection in uncertain graphs.

The most recent contribution in this context is due to Saha et al. \cite{Saha2022most}, that defined DSP problem in uncertain graphs with an alternative notion of density, called Densest Subgraph Probability (DSPr).
DSPr of a node set $U \subseteq V$ is the summation of the probabilities of all instances in which $U$ represent the densest subgraph (with any density's notion).
They design the Most Probable Densest Subgraph (MPDS) problem considering edge density, clique density and pattern density, and for each of them, their top-$k$ variants.
Their principal contribution is the edge density-based MPDS algorithm, that is built on independent sampling of possible worlds (e.g., via Monte-Carlo sampling) and, in each of them, efficient enumeration of all edge-densest subgraphs.


