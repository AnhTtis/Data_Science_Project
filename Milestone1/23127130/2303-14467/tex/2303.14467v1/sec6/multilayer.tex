\subsection{Multilayer networks}\label{subsec:multilayer}

Multilayer networks are a generalization of the ordinary (i.e., single-layer) graphs.
For positive integer $\ell$, let $[\ell]=\{1,2,\dots, \ell\}$.
Mathematically, a multilayer network is defined as a tuple $(V,(E_i)_{i\in [\ell]})$,
where $V$ is the set of vertices and each $E_i$ ($i=1,2,\dots, \ell$) is a set of edges on $V$.
That is, a multilayer network has a number of edge sets (called layers),
which may encode different types of connections and/or time-dependent connections over the same set of vertices.
Similarly to other graph mining primitives, dense subgraph discovery, particularly DSP, has been extended to multilayer networks.
As the density value of $S\subseteq V$ varies layer by layer,
there would be several ways to define the objective function of multilayer-network counterparts of DSP.
For $S\subseteq V$ and $i\in [\ell]$, we denote by $d_i(S)$ the density of $S$ in terms of the layer $i$.

Jethava and Beerenwinkel~\cite{jethava2015relational} introduced the first optimization problem for dense subgraph discovery in multilayer networks,
which they referred to as the densest common subgraph problem.
In the problem, given a multilayer network $G=(V,(E_i)_{i\in [\ell]})$, we seek a vertex subset $S\subseteq V$ that maximizes
the minimum density over layers, i.e., $\min_{i\in [\ell]} d_i(S)$.
For the problem, Jethava and Beerenwinkel~\cite{jethava2015relational} devised an LP-based polynomial-time heuristic and a $2\ell$-approximation algorithm based on the greedy peeling.
Reinthal et al.~\cite{reinthal2016finding} studied which algorithm, the simplex method or the interior-point method,
is more suitable for the use in the above LP-based heuristic, and observed that employing the interior-point method can shorten the computation time in practice.
Later, Charikar, Naamad, and Wu~\cite{charikar2018common} designed two combinatorial polynomial-time algorithms with approximation ratios
$O(\sqrt{n\log \ell})$ and $O(n^{2/3})$ (irrespective of $\ell$), respectively.
Moreover, they showed some strong inapproximability results for the problem, based on some computational complexity assumptions.
Specifically, they showed that the densest common subgraph problem is at least as hard to approximate as \textsc{MinRep}, a well-studied minimization version of \textsc{Label Cover}, which implies that the problem cannot be approximated to within a factor of $2^{\log^{1-\epsilon}n}$, unless $\NP \subseteq \text{DTIME}(n^{\textsf{polylog}(n)})$.
They also showed that if the planted dense subgraph conjecture is true, the problem cannot be approximated to within a factor of $n^{1/4-\epsilon}$ and even for $\ell=2$, the problem cannot be approximated to within $n^{1/8-\epsilon}$.

Later, Galimberti et al.~\cite{galimberti2017core,galimberti2020core} introduced a generalization of the densest common subgraph problem,
which they refer to as the multilayer densest subgraph problem.
This problem exploits a trade-off between the minimum density value over layers and the number of layers having such a density value.
Specifically, in the problem, given a multilayer network $G_i=(V,(E_i)_{i\in [\ell]})$ and $\beta \geq 0$,
we are asked to find $S\subseteq V$ that maximizes $\max_{I\subseteq [\ell]}\min_{i\in I}\frac{|E_i[S]|}{|S|}|I|^\beta$.
For this problem, they proposed an exponential-time $O(2\ell^\beta)$-approximation algorithm using a core decomposition technique for multilayer networks.


Recently, Hashemi, Behrouz, and Lakshmanan~\cite{hashemi2022firmcore} designed a sophisticated core decomposition algorithm for multilayer networks,
which they call the FirmCore decomposition algorithm.
For $k\in \mathbb{Z}_+$ and $\lambda\in [\ell]$, a subgraph $H=(S,(E_i[S])_{i\in [\ell]})$ is called a $(k,\lambda)$-FirmCore
if it is a maximal subgraph in which every vertex has degree no less than $k$ in the subgraph for at least $\lambda$ layers.
They devised a polynomial-time algorithm for finding the set of $(k,\lambda)$-FirmCores for all possible $k$ and $\lambda$.
They proved that the FirmCore decomposition unfolds an approximate solution to the multilayer densest subgraph problem,
with a better approximation ratio than that obtained by Galimberti, Bonchi, and Gullo~\cite{galimberti2017core} for many instances.

Semertzidis et al.~\cite{semertzidis2019finding} introduced another generalization of the densest common subgraph problem, called the Best Friends Forever (BFF) problem,
in the context of evolving graphs with a number of snapshots.
The BFF problem is a series of optimization problems that maximize an \emph{aggregate density} over snapshots,
where the aggregate density is set to be the average/minimum value of the average/minimum degree of vertices over layers.
Similarly to the multilayer densest subgraph problem,
they also considered the variant called the On--Off BFF ($\text{O}^2$BFF) problem, which only asks the output to be dense for a part of snapshots.
They investigated the computational complexity of the problems and designed some approximation or heuristic algorithms.

Very recently, Kawase, Miyauchi, and Sumita~\cite{kawase2023stochastic} studied stochastic solutions to dense subgraph discovery in multilayer networks.
Their novel optimization problem asks to find a stochastic solution, i.e., a probability distribution over the family of vertex subsets, rather than a single vertex subset,
whereas it can also be used for obtaining a single vertex subset.
The quality of stochastic solutions is measured using the expectation of the following three metrics, the density, the robust ratio, and the regret,
on the layer selected by the adversary.
Therefore, their optimization problem can be seen as (a generalization of) the stochastic version of the densest common subgraph problem by Jethava and Beerenwinkel~\cite{jethava2015relational}.
Unlike the densest common subgraph problem, their optimization problem can be solved exactly in polynomial time;
indeed, they designed an LP-based polynomial-time exact algorithm.
They proved that the output of the proposed algorithm has a useful structure;
the family of vertex subsets with positive probabilities has a hierarchical structure.
This leads to several practical benefits, e.g., the largest size subset contains all the other subsets and the optimal solution obtained by the algorithm has support size at most $n$.
Moreover, they also demonstrated that the support size of the output can be upper bounded by $\ell$.
For the practical use of the above exact algorithm, they then devised a simple, scalable preprocessing algorithm,
which often reduces the size of the input networks significantly and results in a substantial speed-up.

Finally, we take a look at a very special case of multilayer networks called dual networks, i.e., the case of $\ell=2$ in multilayer networks.
Wu et al.~\cite{wu2015dual,Wu+16} introduced an optimization problem of detecting a dense and connected subgraph in dual networks:
Given a dual network $G=(V,(E_1,E_2))$, we are asked to find a vertex subset $S\subseteq V$ that maximizes $d_1(S)$, i.e., the density on the first layer,
under the constraint that $(S,E_2[S])$ is connected.
They proved that the problem is \NP-hard and designed a scalable heuristic.
Later, Chen et al.~\cite{Chen+22} considered a variant of the above problem,
where $k\in \mathbb{Z}_+$ is given as an additional input, and we seek $S\subseteq V$ that maximizes the minimum degree of vertices on the first layer,
under the constraint that $(S,E_2[S])$ is $k$-edge-connected.
Therefore, this problem enables us to control the strength of connectivity on the second layer.
Owing to the use of the minimum degree, this problem can be solved exactly in polynomial time, unlike the above problem by Wu et al.~\cite{wu2015dual,Wu+16}.

A recent line of research in dual networks is that of contrast subgraphs, i.e. subgraphs that maximize the difference in density between the respective induced subgraphs in the first and second network.
Yang et al. \cite{yang2018mining} proposed the density contrast subgraph problem: given two networks, find the subset of nodes that maximizes the difference in terms of average degree between the 2 networks. They reduce the problem to an instance of DSP in a graph with either positive or negative edge weights, proving that the problem is \NP-hard and cannot be approximated within $O(n^{1-\epsilon})$ for any $\epsilon > 0$. They solve the problem via a variant of the classical greedy peeling algorithm, providing a $O(n)$-approximation guarantee for the final solution.
Lanciano, Bonchi and Gionis \cite{lanciano2020contrast} proposed a variant of this problem, by maximizing the difference in terms of number of edges, subject to an input penalty term that controls the output of the solution. They showed that this problem can be mapped to an instance of the Generalized Optimal Quasi Clique problem defined in \cite{cadena2016dense}, then providing an updated version of their algorithm.
Finally, Feng et al. \cite{feng2021specgreedy} included in their generalized framework for DSP the possibility to include in the denominator the density of a second graph, that makes the solution less attractive if it is dense in both the input graph.



