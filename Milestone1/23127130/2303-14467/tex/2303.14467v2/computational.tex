

Bahmani et al.~\cite{bahmani} were the first to study DSP in a streaming scenario.
The authors designed algorithms for DSP, DDS (Section \ref{subsec:directed}), and Dal$k$S (Section \ref{sec:size}) under the semi-streaming model of computation, where the set of vertices is known ahead of time and can fit into the main memory, while the edges arrive one by one.
The proposed algorithm is based on the \rev{greedy peeling algorithm},
making $\bigO(\log_{1+\epsilon} n)$ passes over the data \rev{and outputting a $2(1+\epsilon)$-approximate solution} for DSP; the adapted version of the algorithm for the DDS provides the same guarantees.
A slightly modified version of this method gives a $3(1+\epsilon)$-approximation for Dal$k$S, always performing $\bigO(\log_{1+\epsilon} n)$ passes over the input.
The authors also proved that any
$p$-pass streaming
$\alpha$-approximation ($\alpha \geq 2$) algorithm for DSP needs
$\Omega(n / p\alpha^2)$
space.
The authors also demonstrated how the algorithm can be easily parallelized by providing a MapReduce implementation.

Tsourakakis~\cite{Tsourakakis15} exploited these algorithmic techniques and efficient triangle counting algorithms in MapReduce~\cite{suri2011Counting} to address the $k$-clique DSP.
The author gave a
$3(1+\epsilon)$-approximation algorithm
for the \rev{triangle} DSP requiring
$\bigO(\log_{1+\epsilon} n)$ rounds.
Shi \rev{et al.}~\cite{shi2021parallel} addressed DSP under the \textit{workspan model} \cite{jeje1992introduction,cormen2022introduction},
where
the work $W$ of an algorithm is the total number of operations, the span $S$ is the longest dependency path, and $P$ \rev{is the number of processors} available, 
and the time for executing a parallel computation is $\frac{W}{P}+S$.
The authors provided a parallel algorithm that
computes a
$k(1+\epsilon)$-\rev{approximate solution}
for \rev{the} $k$-clique DSP running in
$\bigO(m\alpha^{k-2})$ work \rev{and}
$\bigO(k\log^2 n)$ span w.h.p., \rev{using}
$\bigO(m+P\alpha)$ space, \rev{where} $\alpha$ is the arboricity of the input graph, i.e.,  the minimum number of spanning forests needed to cover the graph.


Das Sarma et al.~\cite{dassarma2012dynamic} were the first to study DSP in a fully decentralized distributed computing peer-to-peer network model, \rev{i.e.,} the CONGEST~\cite{peleg2000distributed} model.
The authors gave a distributed algorithm
that w.h.p. in
$\bigO(D\log_{1+\epsilon} n)$ time provides a
$(2+\epsilon)$-approximation
for DSP and \rev{a} 
$(3+\epsilon)$-approximation
for Dal$k$S, where $D$ is the diameter of the graph.


Bahmani et al. \cite{bahmani2014efficient} presented primal-dual algorithms, working in the MapReduce framework,
that provide a
$(1+\epsilon)$-approximation
for both DSP and DDS, and run in
$\bigO(m(\log n / \epsilon^2))$
time for DSP and $\bigO(m(\log^2 n /\epsilon^3))$ for DDS, by taking
$\bigO(\log n/\epsilon^2)$
MapReduce phases.
The total running time and shuffle size in each phase is $\bigO(m)$ and the reduce-key-complexity is $\bigO(\Delta)$, where $\Delta$ is the maximum degree of a vertex in the graph.
They provided an algorithm for DDS by combining the approach used for DSP with the LP formulation for DDS~\cite{Charikar2000}.

Ghaffari et al.~\cite{ghaffari2019improved} studied DSP under the Massively Parallel Computation (MPC) model, a theoretical abstraction suitable for MapReduce.
The authors provided an algorithm that w.h.p. in
$\bigO(\sqrt{\log n}\,\log \log n)$
rounds computes a
$(1+\epsilon)$-\rev{approximate solution}
for DSP.
The algorithm requires
$\tilde\bigO(n^\delta)$ memory per machine and a total memory of
$\tilde\bigO(\max\{m, n^{1+\delta}\})$ 
for an arbitrary constant
$\delta \in (0,1)$.
Epasto et al.~\cite{epasto2015dynamic} studied DSP in two dynamic graph models.
When edges can be added adversarially, the authors designed an algorithm that maintains at any point in time a
$2(1 + \epsilon)^2$-approximation
of the densest subgraph, performing
$\bigO(m \log^2 n /\epsilon^2)$
operations
and requiring
$\bigO(m+n)$ space. When edges can be added adversarially and removed uniformly at random, the authors proposed an algorithm that maintains at any point in time a
$2(1 + \epsilon)^6$-approximation
of the densest subgraph, performing
$\bigO\left(\frac{A\log A \log^2 n}{\epsilon^2} + \frac{R\log A \log^3 n}{\epsilon^4}\right)$
operations with high probability ($A$ and $R$ are the numbers of edge insertions and removals, respectively) and requiring
$\bigO\left(m+n\right)$ space.
For both algorithms, all results remain valid even in the presence of vertex insertions.
Ahmadian and Haddadan~\cite{ahmadian2021wedge} experimentally showed an improvement in the execution time by embedding this method in their framework at the cost of having a
$4(1 + \epsilon)^2$-approximation for DSP.


In the presence of both edge insertions and deletions,  Bhattacharya et al.~\cite{bhattacharya2015dynamic} designed an algorithm \rev{that provides} a $(4+\epsilon)$-approximation for DSP.
The algorithm requires $\tilde\bigO(n)$
space, \rev{and} it has an amortized time of $\tilde\bigO(1)$ for both insertion and deletion of an edge and a query time of $\tilde\bigO(1)$ for obtaining the declared approximation of the densest subgraph at any point in time.
The authors also \rev{showed} how increasing the query time to
$\tilde\bigO(n)$ yields a $(2+\epsilon)$-approximation for DSP.
When the graph is represented by an incident list, the proposed algorithm
provides a $(2+\epsilon)$-approximation for DSP
by reading $\tilde\bigO(n)$
edges, requiring
$\tilde\bigO(n)$
query time and $\tilde\bigO(n)$ space.
The authors also showed the tightness up to a poly-logarithmic factor of this running time \rev{by} providing a lower bound for the problem.
The authors also demonstrated the algorithm's applicability to the distributed streaming model defined in Cormode et al.~\cite{Cormode2010optimal},
showing that the algorithm computes a $(2+\epsilon)$-approximate solution for DSP using
$\tilde\bigO(k+n)$ bits of communications, where the space required by the coordinator is $\tilde\bigO(n)$ and the space required by each site is $\tilde\bigO(1)$.
The authors also extended the $(4+\epsilon)$-approximation algorithm for DSP to DDS, obtaining a
$(8+\epsilon)$-approximation; the extended algorithm requires $\tilde\bigO(m+n)$ space, an amortized time of $\tilde\bigO(1)$ for both insertion and deletion of an edge, and a query time of $\bigO(1)$.

McGregor et al.~\cite{mcgregor2015dynamic} \rev{provided} a single-pass algorithm that returns a $(1+\epsilon)$-approximation for DSP with high probability; their algorithm uses
$\tilde\bigO(n)$
space,
$\tilde\bigO(1)$
time for each edge insertion and deletion, and
$\bigO(\poly n)$
query time.
The space used by the algorithm matches the lower bound defined in \cite{bahmani} up to a poly-logarithmic factor for constant $\epsilon$. At the same time, the polynomial query time follows by using any exact algorithm for DSP on the subgraph generated by the algorithm.

Esfandiari et al.~\cite{esfandiari2016dynamic} also provided a single-pass algorithm that returns a $(1+\epsilon)$-approximation for DSP with high probability, 
using
$\tilde\bigO(m)$ space,
$\tilde\bigO(1)$
time for each edge insertion and deletion, and
$\bigO(\poly n)$
query time.
Their algorithm is based on sampling (and storing) edges from the input graph uniformly at random without replacement.
As in McGregor et al.~\cite{mcgregor2015dynamic}, even in this case polynomial query time follows by using any exact algorithm for DSP on the subgraph generated by the algorithm.
The authors also proved that using the greedy peeling algorithm at query time,
and using an oracle that provides direct access to a uniformly sampled edge,
the proposed algorithm gives a
$(2+\epsilon)$-approximation for DSP with high probability
running in
$\tilde\bigO(n)$ time.
The authors proved that the generality of their algorithmic framework provides a
$(1+\epsilon)$-approximation for DDS with high probability, 
using
$\tilde\bigO(n^{\frac{3}{2}})$ space,
$\tilde\bigO(1)$
time for each edge insertion and deletion, and
$\bigO(\poly n)$
query time for solving DDS exactly.

Su and Vu~\cite{su2020distributed} gave a distributed algorithm under the CONGEST~\cite{peleg2000distributed} model that w.h.p. in
$\bigO(D+(\log^4 n / \epsilon^4))$ time provides a
$(1+\epsilon)$-approximation
for DSP, where $D$ is the diameter of the graph.
Sawlani and Wang~\cite{sawlani2020dynamic}
gave a deterministic algorithm providing a
$(1+\epsilon)$-approximation for DSP,
with
$\bigO(\log^4 n / \epsilon^6)$
worst-case time per edge insertion or deletion, and
$\bigO(1)$ worst-case query time.
The \rev{authors also gave} a deterministic algorithm providing a
$(1+\epsilon)$-approximation for DDS,
with
$\bigO(\log^5 n / \epsilon^7)$
worst-case time per edge insertion or deletion, and
$\bigO(\log n / \epsilon)$ worst-case query time.
Moreover, for both DSP and DDS, at any point in time, the corresponding algorithms can output the approximate \rev{solution $S$} in 
$\bigO(|S| + \log n)$ time. 
Christiansen et al.~\cite{christiansen2022adaptive}  improved the result of Sawlani and Wang~\cite{sawlani2020dynamic}
\rev{by} giving a deterministic algorithm providing a
$(1+\epsilon)$-approximation for DSP,
with
$\bigO((\log^2 n \log \rho^*) / \epsilon^4)$
worst-case time per edge insertion or deletion,
where $\rho^*$ is the density of the densest subgraph, and
$\bigO(1)$ worst-case query time.
At any point in time, the algorithms can output the approximate \rev{solution $S$} in 
$\bigO(|S|)$ time. 
Independently from Christiansen et al.~\cite{christiansen2022adaptive}, Chekuri and Quanrud~\cite{chekuri2022dynamic} also improved the result of Sawlani and Wang~\cite{sawlani2020dynamic}
\rev{by} giving a deterministic algorithm providing a
$(1+\epsilon)$-approximation for DSP,
with
$\bigO(\log^2 n / \epsilon^4)$ amortized time and
$\bigO((\log^3 n \log\log n) / \epsilon^6)$
worst-case time per edge insertion or deletion,
and
$\bigO(1)$ worst-case query time.
At any point in time, the \rev{algorithm} can output the approximate solution $S$ in 
$\bigO(|S|)$ time. 
\rev{Building upon this work, Li and Quanrud~\cite{li2023approximate} recently proposed a fully dynamic algorithm that maintains a 
$(1+\epsilon)$-approximate 
solution for DDS in 
$\bigO((\log^3 n \log\log n)/\epsilon^6)$ 
amortized time or 
$\bigO((\log^4 n \log\log n )/\epsilon^7)$ worst-case time per edge insertion or deletion.
This is a slight improvement over Sawlani and Wang~\cite{sawlani2020dynamic}, when ignoring the $\log\log$ factors.}

Henzinger et al.~\cite{henzinger2022fine}
showed that for DSP
on graphs with a maximum degree less than or equal to seven, constant-degree graphs, expanders, and power-law graphs
there is no dynamic algorithm \rev{that} achieves both
$\bigO(n^{1/4-\epsilon})$ amortized edge update time and $\bigO(n^{1/2-\epsilon})$ amortized query time.
This conditional lower bound is weaker than the one for general graphs:  
$\bigO(n^{1/2-\epsilon})$ amortized edge update time and $\bigO(n^{1-\epsilon})$ amortized query time.

Chu et al.~\cite{chu2022hierarchical} presented a parallel algorithm that in time
$\bigO\left( n\sqrt{p} + m\alpha(n) + F\right)$
computes a $2$-approximate solution for DSP requiring $\bigO\left(n\right)$ additional space to the input storage, where $p$ is the number of threads, $F$ is the number of failures, and $\alpha(n)$ is the inverse of the Ackermann function.
The authors stated that for practical input, the dominant term is
$m\alpha(n) \leq 4m$;
consequently, the time complexity reduces to
$\bigO(m)$.

The first contribution tackling DSP on hypergraphs in a streaming scenario was by Hu~et~al.~\cite{hu2017dynamicsub}, which developed two dynamic algorithms for DSH (see Section \ref{subsec:hyper})  by extending the pioneering algorithm of~\cite{bahmani} to hypergraphs.
With only arbitrary edge insertions, the authors gave a dynamic algorithm providing a
$r(1+\epsilon)$-approximation for DSH, where $r$ is the rank of a hypergraph,
with
$\bigO\left(\poly\left(\frac{r}{\epsilon} \log n \right)\right)$ amortized time per edge insertion and $\bigO(n)$ extra space in addition to the input hypergraph.
When both arbitrary edge insertions and deletions are allowed, the authors gave a dynamic algorithm providing a
$r^2(1+\epsilon)$-approximation for DSH,
with
$\bigO\left(\poly\left(\frac{r}{\epsilon} \log n \right)\right)$ amortized time for each edge insertion and deletion and $\bigO\left(r m \poly\left(\frac{r}{\epsilon} \log n \right)\right)$ extra space in addition to the input hypergraph.

Bera et al.~\cite{bera2022dynamicsub} addressed DSH on \rev{weighted hypergraphs} in a streaming scenario \rev{and gave}
a randomized fully dynamic algorithm providing a
$(1+\epsilon)$-approximation for the problem.
Chekuri and Quanrud~\cite{chekuri2022dynamic} presented a deterministic algorithm providing a
$(1+\epsilon)$-approximation for DSH,
with
$\bigO\left(\frac{r^2 \log^2 n}{\epsilon^4}\right)$ amortized time and
$\bigO\left( \frac{r\log(n) \log(\rho^*)}{\epsilon^4} + \frac{r^2\log^3(n) \left(\log\log(n) + \log (\epsilon^{-1}) \right)}{\epsilon^6} \right)$
worst-case time per hyperedge insertion or deletion (where $\rho^*$ is the density of the densest subhypergraph),
and
$\bigO(1)$ worst-case query time.
At any point in time, the algorithm can output the approximate solution $S$ in $\bigO(|S|)$ time. 




