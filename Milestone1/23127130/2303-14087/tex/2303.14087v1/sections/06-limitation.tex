\section{Limitations}

Our work relies on projecting annotations from RGBD reconstructions in the MultiScan dataset to RGB frames.
Noise and errors in the reconstruction compound with potential annotation errors and can produce inaccurate projected 2D annotations for the openable part masks and motion parameters.
Moreover, the viewpoints from such RGBD video trajectories are biased by the path the human operators took to acquire a reconstruction and may not represent common viewpoints well.
The diversity of objects and scenes is also limited by geographic bias.
Furthermore, the sparsity of available real-world scene data with part-level motion annotations is a bottleneck for future work.
