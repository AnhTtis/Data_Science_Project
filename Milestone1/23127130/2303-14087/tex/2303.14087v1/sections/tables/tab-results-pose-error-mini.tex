\begin{table}[t]
\resizebox{\linewidth}{!}{
\begin{tabular}{@{} ll rr rr @{}}
\toprule
& & \multicolumn{2}{c}{Pose Rotation} & \multicolumn{2}{c}{Pose Translation} \\
\cmidrule(l{0pt}r{2pt}){3-4} \cmidrule(l{2pt}r{0pt}){5-6}
Dataset & Model & MedErr $\downarrow$ & Acc:5 $\uparrow$ & MedErr $\downarrow$ & Acc:0.1 $\uparrow$ \\
\midrule
\multirow{2}{*}{\ourdatacad} 
& \opdrcnnop & 4.28 & 0.58 & 0.16 & 0.28 \\
& \opdformerp &  \best{2.47} & \best{0.78} & \best{0.11} & \best{0.46}  \\
\midrule
\multirow{2}{*}{\ourdatareal} 
& \opdrcnnop & 8.33 & 0.23 & 0.19 & 0.16 \\
& \opdformerp & \best{4.96} & \best{0.51} & \best{0.14} & \best{0.29} \\
\midrule
\multirow{2}{*}{\ourdatamulti} 
& \opdrcnnop & 19.86 & 0.05 & 0.27 & 0.06 \\
& \opdformerp & \best{8.09} & \best{0.27} & \best{0.21} & \best{0.12} \\
\bottomrule
\end{tabular}
}
\caption{Object pose error on the val set for all three datasets. Rotation error is in degrees and translation error is normalized by the diagonal length of the object. For accuracy, we use thresholds of $5^\circ$ for rotation and 0.1 (of object diagonal) for translation. Averages are computed part-wise. Accuracy counts matched pairs of GT and prediction in the same way as the mAP@50 metric, with higher confidence masks picking GT first and IoU = 50 threshold.}
\label{tab:results-pose-error-mini}
\end{table}


