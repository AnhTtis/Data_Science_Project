\section{Related Work}

\mypara{2D instance segmentation.}
Instance segmentation in 2D is well-studied.
Before the popularity of vision transformers, prior work adopted region proposal-based methods~\cite{girshick2015fast,ren2015faster,he2017mask}.
\citet{carion2020end} used a transformer decoder to convert the instance segmentation task into a set prediction task with the Hungarian algorithm for a one-to-one matching loss.
MaskFormer~\cite{cheng2021per} further converted the problem into a mask classification problem to unify all 2D segmentation tasks (i.e. semantic segmentation, instance segmentation and panoptic segmentation) and achieved better results.
Recently, Mask2Former~\cite{cheng2021masked} achieved state-of-the-art results in 2D instance segmentation.
Our work builds on recent progress from instance segmentation, taking inspiration from transformer architectures that achieve state-of-the-art instance detection and segmentation performance.

\mypara{Articulated object understanding.}
With the increasing interest in embodied AI, understanding articulated objects is an important research direction.
A number of datasets of articulated objects have been recently introduced, including both synthetic \cite{xiang2020sapien,wang2019shape2motion} and scanned datasets \cite{jiang2022opd,qian2022understanding,liu2022akb,mao2022multiscan}.
These datasets have annotations of part segmentation and corresponding motion parameters.
Such data has enabled data-driven methods for predicting motion parameters from 3D meshes~\cite{hu2017learning} and points clouds~\cite{wang2019shape2motion,yan2019rpm}.
More recent work has focused on detecting articulated parts and their motion parameters from single-view point-clouds~\cite{li2020category}, images~\cite{zeng2021visual,jiang2022opd} and  videos~\cite{qian2022understanding,heppert2022category}, which are closer to real applications.
Researchers have also started to investigate how to use predicted segmentation and motion parameters to automatically create articulated objects~\cite{jiang2022ditto,collins20232}, including in scenes~\cite{hsu2023ditto}.



\mypara{Openable part detection.}
\citet{jiang2022opd} introduced the openable part detection (OPD) task to address the articulated object motion prediction problem for single-view image inputs.  In their work, they focused on images with a single main object and predicting the openable parts for that one object.
Our work generalizes the OPD task to more realistic images with multiple objects.
We also develop a part-informed transformer architecture that leverages object poses to predict more consistent and accurate part motions.
