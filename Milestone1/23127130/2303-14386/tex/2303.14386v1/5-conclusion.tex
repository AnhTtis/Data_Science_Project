%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion} 
We introduce \algname{}, a novel object detection method that achieves highly efficient inference speed while also improving zero-shot generalization compared with existing methods. The prompt-based decoding approach reduces the computational burden of object queries. The RoI-based masked attention and RoI pruning techniques allow us to efficiently leverage a large ViT-based CLIP model, enhancing detection performance through classification prediction ensembling. Comprehensive experiments show that \algname{} is $21.2$ times faster than OV-DETR while achieving comparable or higher APs on base and novel classes compared to two-stage OVD methods. %We believe that our work will inspire future work to explore the benefits of using Transformers.


%\paragraph{Ethics Statement.} 
%The focus of this paper is on open-vocabulary object detection. Our approach involves the integration of Transformer-based object detector and CLIP. We have not identified any foreseeable negative social impact associated with our work to share our findings with the scientific community. Nonetheless, we will continue to monitor and consider any potential concerns that may arise. 