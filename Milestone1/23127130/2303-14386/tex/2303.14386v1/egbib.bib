% Object Detection (General)

@inproceedings{papageorgiou1998general,
  title={A general framework for object detection},
  author={Papageorgiou, Constantine P and Oren, Michael and Poggio, Tomaso},
  booktitle={ICCV},
  pages={555--562},
  year={1998}
}

@inproceedings{he2017mask,
  title={Mask {R}-{CNN}},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={ICCV},
  year={2017}
}

@inproceedings{padilla2020survey,
  title={A survey on performance metrics for object-detection algorithms},
  author={Padilla, Rafael and Netto, Sergio L and Da Silva, Eduardo AB},
  booktitle={IWSSIP},
  pages={237--242},
  year={2020}
}

@inproceedings{redmon2016you,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{zareian2021open,
  title={Open-vocabulary object detection using captions},
  author={Zareian, Alireza and Rosa, Kevin Dela and Hu, Derek Hao and Chang, Shih-Fu},
  booktitle={CVPR},
  pages={14393--14402},
  year={2021}
}


% Object Detection (DETR)
@inproceedings{songvidt,
  title={ViDT: An Efficient and Effective Fully Transformer-based Object Detector},
  author={Song, Hwanjun and Sun, Deqing and Chun, Sanghyuk and Jampani, Varun and Han, Dongyoon and Heo, Byeongho and Kim, Wonjae and Yang, Ming-Hsuan},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={ECCV},
  year={2020}
}

@inproceedings{fang2021you,
title={You only look at one sequence: Rethinking transformer in vision through object detection},
author={Fang, Yuxin and Liao, Bencheng and Wang, Xinggang and Fang, Jiemin and Qi, Jiyang and Wu, Rui and Niu, Jianwei and Liu, Wenyu},
booktitle={NeurIPS},
year={2021}
}

@inproceedings{zhu2020deformable,
  title={Deformable {DETR}: Deformable transformers for end-to-end object detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{litransformer,
  title={A Transformer-Based Object Detector with Coarse-Fine Crossing Representations},
  author={Li, Zhishan and Nie, Ying and Han, Kai and Guo, Jianyuan and Xie, Lei and Wang, Yunhe},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{li2022exploring,
  title={Exploring plain vision transformer backbones for object detection},
  author={Li, Yanghao and Mao, Hanzi and Girshick, Ross and He, Kaiming},
  booktitle={ECCV},
  pages={280--296},
  year={2022}
}


% Open-voca
@inproceedings{zang2022open,
  title={Open-vocabulary {DERT} with conditional matching},
  author={Zang, Yuhang and Li, Wei and Zhou, Kaiyang and Huang, Chen and Loy, Chen Change},
  booktitle={ECCV},
  pages={106--122},
  year={2022}
}


@inproceedings{rasheedbridging,
  title={Bridging the Gap between Object and Image-level Representations for Open-Vocabulary Detection},
  author={Rasheed, Hanoona Abdul and Maaz, Muhammad and Khattak, Muhammd Uzair and Khan, Salman and Khan, Fahad},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={ECCV},
  year={2014},
}

@inproceedings{gupta2019lvis,
  title={{LVIS}: A Dataset for Large Vocabulary Instance Segmentation},
  author={Gupta, Agrim and Dollar, Piotr and Girshick, Ross},
  booktitle={CVPR},
  year={2019}
}

% ViT
@inproceedings{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={NeurIPS},
  year={2017}
}


@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={CVPR},
  year={2021}
}


@article{han2022survey,
  title={A survey on vision transformer},
  author={Han, Kai and Wang, Yunhe and Chen, Hanting and Chen, Xinghao and Guo, Jianyuan and Liu, Zhenhua and Tang, Yehui and Xiao, An and Xu, Chunjing and Xu, Yixing and others},
  journal={Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={1},
  year={2022}
}

@inproceedings{radford2021clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  year={2021}
}

@inproceedings{guopen2022vild,
  title={Open-vocabulary Object Detection via Vision and Language Knowledge Distillation},
  author={Gu, Xiuye and Lin, Tsung-Yi and Kuo, Weicheng and Cui, Yin},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{kuoopen2023fvlm,
  title={Open-Vocabulary Object Detection upon Frozen Vision and Language Models},
  author={Kuo, Weicheng and Cui, Yin and Gu, Xiuye and Piergiovanni, AJ and Angelova, Anelia},
  booktitle={ICLR},
  year={2023}
}

@inproceedings{zhong2022regionclip,
  title={Region{C}lip: Region-based language-image pretraining},
  author={Zhong, Yiwu and Yang, Jianwei and Zhang, Pengchuan and Li, Chunyuan and Codella, Noel and Li, Liunian Harold and Zhou, Luowei and Dai, Xiyang and Yuan, Lu and Li, Yin and others},
  booktitle={CVPR},
  pages={16793--16803},
  year={2022}
}

@inproceedings{zhou2022detic,
  title={Detecting twenty-thousand classes using image-level supervision},
  author={Zhou, Xingyi and Girdhar, Rohit and Joulin, Armand and Kr{\"a}henb{\"u}hl, Philipp and Misra, Ishan},
  booktitle={ECCV},
  pages={350--368},
  year={2022}
}

@article{minderer2022owlvit,
  title={Simple open-vocabulary object detection with vision transformers},
  author={Minderer, Matthias and Gritsenko, Alexey and Stone, Austin and Neumann, Maxim and Weissenborn, Dirk and Dosovitskiy, Alexey and Mahendran, Aravindh and Arnab, Anurag and Dehghani, Mostafa and Shen, Zhuoran and others},
  journal={ECCV},
  year={2022}
}


@inproceedings{sharma2018cc3m,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={ACL},
  pages={2556--2565},
  year={2018}
}


@article{maaz2021mvit,
  title={Multi-modal transformers excel at class-agnostic object detection},
  author={Maaz, Muhammad and Rasheed, Hanoona Bangalath and Khan, Salman Hameed and Khan, Fahad Shahbaz and Anwer, Rao Muhammad and Yang, Ming-Hsuan},
  journal={arXiv},
  year={2021}
}

@article{song2022extendable,
  title={An extendable, efficient and effective transformer-based object detector},
  author={Song, Hwanjun and Sun, Deqing and Chun, Sanghyuk and Jampani, Varun and Han, Dongyoon and Heo, Byeongho and Kim, Wonjae and Yang, Ming-Hsuan},
  journal={arXiv preprint arXiv:2204.07962},
  year={2022}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={CVPR},
  pages={248--255},
  year={2009}
}

@inproceedings{du2022detpro,
  title={Learning to prompt for open-vocabulary object detection with vision-language model},
  author={Du, Yu and Wei, Fangyun and Zhang, Zihe and Shi, Miaojing and Gao, Yue and Li, Guoqi},
  booktitle={CVPR},
  year={2022}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={ICLR},
  year={2019}
}

@article{dong2021solq,
  title={Solq: Segmenting objects by learning queries},
  author={Dong, Bin and Zeng, Fangao and Wang, Tiancai and Zhang, Xiangyu and Wei, Yichen},
  journal={NeurIPS},
  year={2021}
}

@inproceedings{lin2017focal,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={ICCV},
  pages={2980--2988},
  year={2017}
}

@inproceedings{rezatofighi2019generalized,
  title={Generalized intersection over union: A metric and a loss for bounding box regression},
  author={Rezatofighi, Hamid and Tsoi, Nathan and Gwak, JunYoung and Sadeghian, Amir and Reid, Ian and Savarese, Silvio},
  booktitle={CVPR},
  pages={658--666},
  year={2019}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={CVPR},
  year={2022}
}