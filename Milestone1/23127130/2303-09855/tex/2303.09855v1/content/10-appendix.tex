\section*{appendix}

\input{content/8-theoretical_analysis}

% \section{Product Quantization}

% \begin{figure}[hbt]
%     \centering
%     \vspace{-4mm}
%     \subfigure[\texttt{IVFPQ 64}]{
%         \includegraphics[width=0.45\linewidth]{revision experimental result/IVFPQ_64.pdf}
%        \label{fig:cost IVFPQ64}
%     }
%     \subfigure[\texttt{IVFPQ 128}]{
% 	    \includegraphics[width=0.45\linewidth]{revision experimental result/IVFPQ_128.pdf}
% 	    \label{fig:cost IVFPQ128}
%     }
%     \vspace{-4mm}
%     \caption{{\CHENG Breakdown of Running Times of} IVFPQ.}
%     % \vspace{-4mm}
%     \label{fig:cost statistics-IVF}
% \end{figure}

% \begin{figure}
%     \centering
%     \vspace{-4mm}
%     \includegraphics[width=\linewidth]{revision experimental result/QPS_linear.png}
%     \vspace{-4mm}
%     \caption{Efficiency of DCOs.}
%     \label{fig:qps linear}
% \end{figure}
{\JIANYANGREVISION
\section{Results of Tree-based and Hashing-based Methods}
\label{appendix:section tree and hashing}
\begin{figure*}[thb]
% \vspace*{-4mm}
  \centering 
  % \includesvg[width=17cm]{experimental result/time-accuracy.svg}
  % \includesvg[width=17cm]{revision experimental result/time-accuracy-hash.svg}
    \includegraphics[width=17cm]{revision experimental result/time-accuracy-hash.pdf}
  \vspace*{-4mm}
  \caption{{\JIANYANGREVISION Time-Accuracy Tradeoff (\texttt{PMLSH} and \texttt{Annoy}).}}
  \vspace*{-4mm}
  \label{figure:time-accuracy-tree-and-hashing}
\end{figure*}
For \texttt{Annoy}, following \cite{li2019approximate}, we set the number of trees $N_{tree} = 50$. 
{\JIANYANGREVISION During the \underline{index phase}, we feed the raw data vectors into the indexing algorithm of \texttt{Annoy} (note that \texttt{Annoy}, \texttt{Annoy+} and \texttt{Annoy}* have the same index structure). Then during the \underline{query phase}, for \texttt{Annoy}/\texttt{Annoy}*, we load the index and the raw data vectors into main memory, generate candidates by feeding the raw query vector into the the query algorithm of \texttt{Annoy} and re-rank the candidates with \texttt{FDScanning}/\texttt{PDScanning}. For \texttt{Annoy+}, we load the index and the transformed data vectors into main memory, generate candidates by feeding the raw query vector into the the query algorithm of \texttt{Annoy} and re-rank the candidates with \texttt{ADSampling}. }
For \texttt{PMLSH}, following \cite{zheng2020pm}, we set the dimensionality of random projection as 15, the size of internal and leaf nodes of the PM-Tree as 16. Similar to \texttt{Annoy}, during the \underline{index phase}, we build the indexes based on the raw data vectors. During the \underline{query phase}, we generate candidates by feeding the raw query vectors to the search algorithm of \texttt{PMLSH} and re-rank them with \texttt{FDScanning}, \texttt{PDScanning} and \texttt{ADSampling} based on raw vectors, raw vectors and transformed vectors respectively. 
For both methods, we vary the number of accessed candidates to control the time-accuracy tradeoff.  
{\chengr We exclude the optimization of data layout for this experiment since it is not applicable for index ensembles (e.g., tree ensembles of \texttt{Annoy}).}
% 2) according to Section~\ref{subsec:main result}, the \texttt{ADSampling} method contributes the most improvement for \texttt{IVF}, (3) as shown in Figure~\ref{figure:time-accuracy-tree-and-hashing}, \texttt{Annoy+} and \texttt{PMLSH+} have already brought consistent and significant improvement 
% and (4) \texttt{Annoy} and \texttt{PMLSH} are not the focus of our paper due to their suboptimal performance,
% {\chengr we } we exclude the optimization of data layout.
We plot the QPS-recall and QPS-average distance ratio curves {\chengr of the compared algorithms} in Figure~\ref{figure:time-accuracy-tree-and-hashing}. It shows that \texttt{AKNN+} outperforms the \texttt{AKNN}* and \texttt{AKNN} algorithms consistently and significantly. 



}