\section{Further Numerical Results}
\label{sec:furth-numer-results}

Besides the measures of accuracy and precision, we compare two further
measures in this section.
First, recall ($\RE$) measures the percentage of points with positive
label that are actually classified as positive.
It is formally given by
\begin{equation}
  \label{recall}
  \RE \define \frac{\TP}{\TP+\FN}.
\end{equation}
Note that for applications such as cancer diagnosis, it is relevant to
evaluate recall because it is more important to flag cancer rather
than to do not.
Also in cases of rare positive labels, recall is often the favored
metric.
Note that values close to 1 indicate a better classification here.

Second, we also compare the false positive rate ($\FPR$), which
measures the probability of points with negative labels being
classified as positive:
\begin{equation}
  \label{fpr}
  \FPR \define \frac{\FP}{\TN+\FP}.
\end{equation}
This quantity is important in some applications such as quality control,
where a false positive can cause more issues than a false negative.
Note that for $\FPR$, the lower the value, the better the
classification.

The main comparison in terms of recall and false positive rate is
w.r.t.\ the ``true hyperplane'', i.e., the solution of
Problem~\eqref{l2svm} on the complete data with all $N$ points and all
labels available.
The main question is how close the recall and false positive rate is
to the one of the true hyperplane.
Hence, we compute the ratios of the recall and false positive rate
according to
\begin{equation}
  \label{compartrue2}
  \widehat{\RE} \define \frac{\RE}{\RE_{\true}},
  \quad
  \widehat{\FPR} \define \frac{\FPR}{\FPR_{\true}},
\end{equation}
where $\RE_{\true}$ and $\FPR_{\true}$ are computed as
in~\eqref{recall} and~\eqref{fpr} for the true hyperplane.

As can be seen in Figure~\ref{REtru}, the SVM's relative recall is a
little bit larger than the one of the other methods. As in
Section~\ref{precisionsec}, this happens because the biased sample is
more likely to have positive labeled data and having no information about
the unlabeled data, the SVM ends up classifying points on the positive side.
\begin{figure}
  \centering
  \includegraphics[width=0.495\textwidth]{figures/REbasedontrueALL}
  \includegraphics[width=0.495\textwidth]{figures/REbasedontrueUN}
  \caption{Relative recall $\widehat{\RE}$ w.r.t.\ the true
    hyperplane; see \eqref{compartrue2}.
    Left: Comparison for all data points.
    Right: Comparison only for unlabeled data points.}
  \label{REtru}
\end{figure}

Figure~\ref{FPRtru} shows that CS$^3$VM, the IRCM, and the WIRCM have
lower $\widehat{\FPR}$ values than the original SVM.
This means that the newly proposed methods have a lower false positive
rate than the original SVM.
The fact that CS$^3$VM terminates for less instances than the
IRCM explains why the IRCM has a lower relative false positive rate
than CS$^3$VM.
Finally, since the WIRCM uses the IRCM for warm-starting, the WIRCM
also has better relative false positive rates than CS$^3$VM.
\begin{figure}
  \centering
  \includegraphics[width=0.495\textwidth]{figures/FPRbasedontrueALL}
  \includegraphics[width=0.495\textwidth]{figures/FPRbasedontrueUN}
  \caption{Relative false positive rate $\widehat{\FPR}$ w.r.t.\ the true
    hyperplane; see \eqref{compartrue2}.
    Left: Comparison for all data points.
    Right: Comparison only for unlabeled data points.}
  \label{FPRtru}
\end{figure}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "constrained-svm-preprint"
%%% End:
