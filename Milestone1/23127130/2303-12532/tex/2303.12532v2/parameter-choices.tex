\rev{\section{Choosing the Hyperparameters}}
\label{sec:sensibilty-parameters}

\rev{Each parameter of Algorithm~\ref{Second version} and~\ref{Scheme
    version} as well as in Problem~\eqref{l2svm} and~\eqref{equation2}
  can be chosen from a range. In Table~\ref{tab:ranges} we present
  plausible ranges for these parameters.}
\begin{table}
  \centering
  \caption{\rev{Plausible ranges for the hyperparameters}}
  \label{tab:ranges}
  \rev{
    \begin{tabular}{lll}
      \toprule
      Parameter & Plausible Range  & Current Choice \\
      \midrule
      $C_1$ & $\mathbb{R}_{\geq 0}$ & $1$ \\
      $C_2$ & $[0.5 C_1, 2C_1]$ & $1$ \\
      $k^1$ & $[2,m]$ & $10,20,50$ \\
      $k^+$ & $[k^1,m]$ & $50 $ \\
      $\hat{\Delta}^1$ & $[0.5, 0.9]$ & $0.8$ \\
      $\tilde{\Delta}$ & $[0.1 ,1-\hat{\Delta}^1]$ & $0.1$ \\
      $B_{\max}$ & $[1, m]$ & $0.2m,0.25m,0.35m,0.45m$ \\
      $\gamma$ & $[1.1, m/B_{\max}]$ & $1.2$ \\
      $T_{\max}$ & $[10, 100]s$& $40s$ \\
      \bottomrule
    \end{tabular}
  }
\end{table}

\rev{Clearly, $C_1 \in \mathbb{R}_{\geq 0}$ holds.
  However, the closer the value is to 1, the more equally important
  are maximizing the margin and minimizing the classification error
  for the labeled data. The range of $C_2$ is based on
  $C_1$ in order to indicate how much more important the unlabeled
  data is compared to the labeled data.
  Again, we choose $C_2 = 1$ so that both data have the
  same importance. Besides that, if $C_2$ is much bigger than $C_1$,
  our preliminary tests showed that this leads to focus on
  minimizing the classification error for the unlabeled data, which
  implies focusing on the binary variable and, hence, leads to larger
  run times.}

\rev{For choosing the other parameters, we consider the first $3$
  datasets presented in Table~\ref{table1} and varied the parameter
  choices in a preliminary numerical study.
  Based on the results, we now discuss how to choose the remaining
  parameters.
  The parameter~$k^1$ can be between $2$ and $m$ since we
  cluster $m$ unlabeled points.
  Note that, the smaller $k^1$, the less time per iteration is needed
  since we have fewer binary variables.
  However, more iterations may be needed to find the solution.
  On the other hand, the bigger $k^1$, the more time per iteration is
  required.
  We choose to start with a small value of~$k^1$ because in
  preliminary numerical tests, when the algorithm terminated, the
  number of clusters never exceeded $m/3$.
  Moreover, in our preliminary tests, if the algorithm exceeds
  $k^t=50$ for some iteration~$t$, it takes a lot of time to solve
  Problem~\eqref{equation3}.
  To decrease this time, we reduced the number of clusters,
  eliminating the ones being far from the hyperplane.
  This is the reason why we choose $k^+ = 50$.}

\rev{The parameter~$\hat{\Delta}^1$ indicates that clusters with a
  distance to the hyperplane greater than the
  $\hat{\Delta}^1$-quantile of all distances will be deactivated.
  It is between~$0.5$ and~$0.9$ because a smaller value than~$0.5$
  means removing points that are too close to the hyperplane.
  This implies that in next iterations many clusters can be
  reactivated.
  On the other hand, if it is larger than~$0.9$, it means that almost
  no clusters can be deactivated.
  We choose $0.8$ because in our preliminary numerical
  tests we noticed that with a smaller value, many clusters were
  activated again, which increased the required time per iteration.
  The range of $\tilde{\Delta}$ is justified by the fact that for
  all~$t$, the maximum value of $\hat{\Delta}^t$ is $1$.
  We chose $0.1$ because the higher the value we choose, the smaller the
  possibility to eliminate clusters becomes.
  If chosen smaller, $\hat{\Delta}^t$ and $\hat{\Delta}^{t+1}$
  would be very similar and some clusters would be deactivated and
  reactivated several times.}

\rev{Because we have $m$~unlabeled points, we can fix at most $m$
  unlabeled points, which justifies the range of $B_{\max}$ and the
  maximum value of $\gamma$.
  Since some points are not fixed on some side---they may be on the
  wrong side or it could take more than $T_{\max}$ to solve
  Problem~\eqref{equation5}---we try to fix at least more than
  \SI{10}{\percent} of $B_{\max}$ many unlabeled points.
  This is why the minimum value of $\gamma$ is 1.1.
  The maximum value of $T_{\max}$ is \SI{100}{\second} because,
  if chosen smaller, we observe that there is often not enough time to
  solve Problem~\eqref{equation5}.
  On the other hand, if it is larger, we observe that the time needed
  to solve the Algorithm~\ref{Scheme version} increases.}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "constrained-svm-preprint"
%%% End:
