\section{Conclusion}
\label{sec:conclusion}

For many classification problems, it can be costly to obtain labels for
the entire population of interest.
However, aggregate information on how many points are in each class
can be available from external sources.
For this situation, we proposed a semi-supervised SVM that can be
modeled via a big-$M$-based MIQP formulation.
We also presented a rule for updating the big-$M$ in an iterative
re-clustering method and derived further computational techniques such
as tailored dimension reduction and warm-starting to reduce the
computational cost.

In case of simple random samples, our proposed semi-supervised methods
perform as good as the classic SVM approach. However, in many
applications, the available data is coming from non-probability
samples. Hence, there is the risk of obtaining biased samples. Our
numerical study shows that our approaches have better accuracy and
precision than the original SVM formulation in this setting.

The problem of considering a cardinality constraint is
computationally challenging. Our proposed clustering approach
significantly helps to decrease the run time and to find an objective
function value that is very close to the optimal value.
Besides that, the clustering approach maintains the same accuracy and
precision as the MIQP formulation.
Moreover, using the clustering approach as a warm-start and fixing some
unlabeled points on one side of the hyperplane helps to improve the
quality of the objective function value again.
Hence, the newly proposed methods lead to a significant improvement
compared to just solving the classic MIQP formulation using a standard
solver.

In this paper, we consider only the linear SVM kernel. For future
work, the development of methods for other kernels, such as a Gaussian
kernel, can be a valuable topic.
Another possible direction of future research is to adapt our
approaches for multiclass SVMs using a one-vs.-rest strategy.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "constrained-svm-preprint"
%%% End:
