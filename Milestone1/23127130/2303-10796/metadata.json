{
    "arxiv_id": "2303.10796",
    "paper_title": "Uncertainty Driven Bottleneck Attention U-net for OAR Segmentation",
    "authors": [
        "Abdullah Nazib",
        "Riad Hassan",
        "Nosin Ibn Mahbub",
        "Zahidul Islam",
        "Clinton Fookes"
    ],
    "submission_date": "2023-03-19",
    "revised_dates": [
        "2023-06-07"
    ],
    "latest_version": 1,
    "categories": [
        "eess.IV",
        "cs.CV"
    ],
    "abstract": "Organ at risk (OAR) segmentation in computed tomography (CT) imagery is a difficult task for automated segmentation methods and can be crucial for downstream radiation treatment planning. U-net has become a de-facto standard for medical image segmentation and is frequently used as a common baseline in medical image segmentation tasks. In this paper, we develop a multiple decoder U-net architecture where a noisy auxiliary decoder is used to generate noisy segmentation. The segmentation from the main branch and the noisy segmentation from the auxiliary branch are used together to estimate the attention. Our contribution is the development of a new attention module which derives the attention from the softmax probabilities of two decoder branches. The union and intersection of two segmentation masks from two branches carry the information where both decoders agree and disagree. The softmax probabilities from regions of agreement and disagreement are the indicators of low and high uncertainty. Thus, the probabilities of those selected regions are used as attention in the bottleneck layer of the encoder and passes only through the main decoder for segmentation. For accurate contour segmentation, we also developed a CT intensity integrated regularization loss. We tested our model on two publicly available OAR challenge datasets, Segthor and LCTSC respectively. We trained 12 models on each dataset with and without the proposed attention model and regularization loss to check the effectiveness of the attention module and the regularization loss. The experiments demonstrate a clear accuracy improvement (2\\% to 5\\% Dice) on both datasets. Code for the experiments will be made available upon the acceptance for publication.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10796v1"
    ],
    "publication_venue": null
}