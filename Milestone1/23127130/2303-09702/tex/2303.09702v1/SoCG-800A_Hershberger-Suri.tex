\section{Extra Material for  Section~\ref{section:Phase-I}, Phase I
}

\subsection{Finding the Farthest Edge from each Vertex}
\label{appendix:Hershberger-Suri}

Phase I is to find the farthest edge Voronoi diagram restricted to the polygon boundary.  In this section we give the first step of Phase I:

\begin{thm}
There is a \reviewerchange{linear-time algorithm} to find the farthest edge from each vertex of a simple polygon.
\end{thm}

Hershberger and Suri~\cite{hershberger1997matrix} gave a \reviewerchange{linear-time algorithm} to find the farthest \emph{vertex} from each vertex in linear time.
We show that their algorithm extends to finding the farthest \emph{edge} from each vertex in linear time.
Hershberger and Suri build upon an algorithm called SMAWK due to Aggarwal et al.~\cite{aggarwal1987geometric} that finds row maxima in a totally monotone matrix in linear time. 
The SMAWK algorithm immediately solves the problem of finding the farthest vertex from each vertex in a convex polygon in linear time, but Hershberger and Suri need substantial new ideas to extend to general simple polgons. In order to extend Hershberger and Suri's algorithm to find the farthest edge from each vertex, we must examine their algorithm in more detail. 

We structure this section as follows:
\begin{enumerate}
\squeezelist
\item Use separators to reduce the farthest vertex/edge problem to a problem of finding all row maxima in a totally monotone matrix. 
The matrix is given implicitly---each entry in the matrix represents the distance from one vertex to a vertex/edge, and this distance is computed only when needed.
\item An overview of the SMAWK algorithm to find row maxima in a totally monotone matrix.
Together with item 1, this solves the problem of finding the farthest vertex from each vertex in a \emph{convex} polygon, because then each matrix entry (the distance between two vertices) can be computed in constant time.
\item An overview of the Hershberger-Suri algorithm that solves the problem of finding the farthest vertex from each vertex in a general simple polygon.  To do this, they show how to compute each matrix entry needed in the SMAWK algorithm in constant amortized time. 
\item The modifications required for finding the farthest \emph{edge} from each vertex.
\end{enumerate}


\paragraph*{Reducing farthest vertices/edges to row maxima in a matrix.}  We use
the notion of separators from Appendix~\ref{appendix:separators}.
Suri~\cite{suri1989} proved that there are a constant number of separators that separate every vertex from its farthest vertex.  In Lemma~\ref{lem:constant-separator-set} we extended this result to the farthest \emph{edge} from each vertex.
Thus, in either case, to find the farthest vertex/edge from each vertex it suffices to solve the following problem:  given a separator $\pi(a,b)$, find, for each vertex to the right of the separator, the farthest vertex/edge that lies  to the left of the separator.  

Consider a \defn{distance matrix} $M$ with rows indexed by the vertices to the right of the separator in counterclockwise
order and columns indexed by either the vertices or the edges to the left of the separator in counterclockwise order, and with $M(v,s)$ defined to be the geodesic distance from vertex $v$ to vertex/edge $s$.  Then we seek the maximum in each row of the matrix.  

A matrix $M$ is \defn{totally monotone} if for any $2 \times 2$ submatrix 
$\begin{bmatrix}
a & b \\
c & d
\end{bmatrix}$, 
if $b>a$ then $d > c$.


Hershberger and Suri prove that the distance matrix for farthest vertices is totally monotone.  We prove the analogous result for farthest edges.

\begin{claim}
The distance matrix $M$ for farthest edges as described above is totally monotone.
\end{claim}
\begin{proof}
Consider a $2 \times 2$ submatrix with rows indexed by vertices $u,v$ and columns indexed by edges $e,f$:
\[
\begin{blockarray}{ccc}
    & e & f \\
\begin{block}{c[cc]}
  u & a & b \\
  v & c & d \\
\end{block}
\end{blockarray}
 \]
Because the row order and column order are counterclockwise, and because $u,v$ are to the right of the separator and $e,f$ are to the left of the separator, $u,v,e,f$ occur in counterclockwise order around the polygon.
By Corollary~\ref{cor:ordering-property-paths}, if $d(u,f) > d(u,e)$ then $d(v,f) > d(v,e)$, i.e., if $b>a$ then $d>c$.
\end{proof}

Thus the problem of finding the farthest vertex/edge from each vertex is reduced in linear time to the problem of finding row maxima in an totally monotone distance matrix (where we must take into account the time required to access matrix entries).


\paragraph*{The SMAWK algorithm to find row maxima in a totally monotone matrix.}
Let $M$ be an $n \times m$ totally monotone matrix.
Break ties for the maximum value in a row by choosing the leftmost maximum. 
The positions of these row maxima progress rightward and downward---more precisely, if the maximum in row $i$ occurs in column $k$, then the maximum in row $j>i$ occurs in column $l \ge k$. 
The SMAWK algorithm~\cite{aggarwal1987geometric} finds the (leftmost) maximum in each row as follows:
\begin{enumerate}
\squeezelist
\item Delete columns (without eliminating any row maxima) to reduce to an $n \times m'$ matrix $M'$, where $m' \le n$.
This is accomplished by a routine called REDUCE that accesses $2m-n$ matrix entries. 

\item Let $M''$ consist of the even numbered rows of $M'$.  Recursively find the  row maxima in $M''$.  This gives us the row maxima for all even-numbered rows of $M'$.

\item Fill in the row maxima for the odd numbered rows of $M'$.  Observe that the column of the maximum in row number $2i+1$ occurs between the columns of the maxima in row numbers $2i$ and $2i+2$, which means that this step accesses $n + m'$ matrix entries, where the next access is below or to the right of the current one.
\end{enumerate}

Aggarwal et al.~\cite{aggarwal1987geometric} prove that the SMAWK algorithm runs in time $O(n+m)$ assuming that matrix entries can be accessed and compared in constant time.
The number of recursive calls (``phases'') is $O(\log n)$. An important property is that in step 1 and step 3 
each successive matrix entry access is to the right, or up, or down from the current one---in particular there are no left moves.
This is stated as Equation (2.3) by Hershberger and Suri~\cite{hershberger1997matrix}.


\paragraph*{The Hershberger-Suri Algorithm and Its Extension to Farthest Edges.}
As noted above, the SMAWK algorithm gives a \reviewerchange{linear-time algorithm} to find 
the farthest vertex from each vertex in a convex polygon, because in that case each entry in the distance matrix can be computed in constant time.
However, for a general simple polygon, each matrix access involves finding the distance between two vertices $v$ and $u$ on opposite sides of the separator.  
Hershberger and Suri show that this can be done in $O(1)$ amortized time per matrix access.  Their algorithm relies on the order of matrix accesses in the SMAWK algorithm as mentioned above, and on the properties of shortest paths that cross the separator $\gamma(a,b)$, as discussed in Appendix~\ref{sec:funnels-paths}.   We use the terminology and notation from Appendix~\ref{sec:funnels-paths}.
The shortest path $\pi(v,u)$ consists of edges of the funnels $Y(v)$ and $Y(u)$, with one additional tangent edge $\ell(u,v)$ in case the pair of funnels is open. 
The shortest path trees $T_a$ and $T_b$ can be preprocessed in linear time to allow constant time queries for least common ancestors, and for lengths of paths to $a$ or $b$.  Then the length of $\pi(u,v)$ can be found in constant time if the pair of funnels $Y(v),Y(u)$ is closed.
The same applies to our case of the shortest path from  vertex $v$ to edge $e$---for example, in Figure~\ref{fig:funnels-and-tangents}, the funnels $Y(v_2)$ and $Y(e)$ are closed and $d(v_2,e) = (d(a,v_2) - d(a,\gamma_a(v_2)) + (d(b,e) - d(b,\gamma_a(v_2))$.

When a pair of funnels is open the only hard part is finding their tangent edge. 
Given the tangent edge, the length of the path can be found in constant time.
For example, in Figure~\ref{fig:funnels-and-tangents}, the funnels $Y(v_1)$ and $Y(e)$ are open with tangent edge $\ell(v_1,e) = (x,y)$ of length $d_2(x,y)$ so  $d(v_1,e) = (d(b,v_1) - d(b,x)) + (d(a,e) - d(a,y)) + d_2(x,y)$.
Hershberger and Suri give a data structure to find the tangent between a pair of open funnels 
in constant amortized time
by
storing and  maintaining the 
walls of the funnels $Y(v)$ and $Y(u)$ during each phase of the algorithm as $v$ moves counterclockwise and $u$ moves in either direction.
In fact, it suffices to maintain the parts of the walls from the apex of the funnel to $\gamma$.

Binary search along the walls can be used to find the tangent edge
but this is too inefficient for a linear-time algorithm.
Therefore, a more complex data structure that modifies the shortest path trees ($T_a$ and $T_b$) at each phase is used.
Paths in the trees are broken into subpaths, and each subpath is represented by a \emph{supernode} that supports fast searching. 
Supernodes are stored as binary trees with the original polygon vertices at their leaves, and internal nodes representing the edge joining the subtrees below.
Any path of the shortest path tree in the $k$-th phase is a list of supernodes connected by superedges, such that every supernode has at most $2^k$ vertices of the original polygon.
Finally, Hershberger and Suri provide a method for obtaining the supernode representation for the trees before the $k$-th phase in time $O(k n / 2^k)$.
This takes $O(n)$ time for all the $O(\log n)$ phases and also ensures that tangents between open funnels in the $k$-th phase can be determined efficiently.
The maintenance of the supernode representation between phases is quite involved and we do not describe more details here.

The data structure permits them to find the tangent edge $\ell(v,u)$ and to update the funnels, in $O(1)$ amortized time per operation. 
Their algorithm and its  analysis depend on a lemma about the difference between two funnels. 
For two sites (vertices/edges) $s_i$ and $s_j$ on the same side of the separator $\gamma(a,b)$, the \defn{funnel-difference} is the set of edges in $Y(s_i)$ that do not occur in $Y(s_j)$. 
We observe that their result about funnel differences~\cite[Lemma 3.3]{hershberger1997matrix} extends to our situation and is crucial for the amortized analysis.

\begin{lem}
\label{lemma:funnel_difference}
The funnel difference of $s_i,s_j$ forms a path that includes the apex of $Y(s_i)$, and 
is edge-disjoint from $Y(s_k)$, for any vertex/edge $s_k$ 
that appears in the  order $s_i,s_j,s_k$ on 
the same side of the separator.
\end{lem}

In summary, the Hershberger-Suri algorithm extends in a straightforward manner to farthest edges. 
The only modifications needed are the extension to edge funnels (instead of funnels based on vertices) and the different number of separators.

