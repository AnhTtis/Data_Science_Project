\begin{abstract}
Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to confuse the model
into making a mistake.
Such examples pose a serious threat to the applicability of machine-learning-based systems, especially in life- and safety-critical domains.
To address this problem, the area of adversarial robustness investigates mechanisms behind adversarial attacks and defenses against these attacks.
This survey reviews \revadd{a particular subset of this literature} that focuses on 
\revreplace{the effects of data used by a model on the modelâ€™s adversarial robustness}
{investigating properties of training data in the context of model robustness under evasion attacks}.
\revreplace{It systematically identifies and summarizes state-of-the-art research in this area and further} 
{It first summarizes the main properties of data leading to adversarial vulnerability. 
It then discusses guidelines and techniques for improving adversarial robustness by 
enhancing the data representation and learning procedures, 
as well as techniques for estimating robustness guarantees given particular data. 
Finally, it} discusses gaps of knowledge and promising future research directions \revadd{in this area}.
\end{abstract} 
