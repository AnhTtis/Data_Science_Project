\section{Conclusion}
\label{sec:conclusion}
In this survey, we systematically collected, analyzed, and described papers that discuss how data properties affect adversarial robustness in machine learning models.
By analyzing 77 research papers from top scientific venues in Machine Learning, Computer Vision, Computational Linguistics, and Security,
we identified seven domain-agnostic data properties and one image-specific data property that are correlated with adversarial robustness. 

While several of the guidelines for constructing high-quality data that we identified
are similar to those recommended for training accurate models,
producing robust models is more sensitive to the characteristics of the data and requires more effort,
e.g., a larger number of samples, better label qualities, etc. There are also additional data properties important for building
robust models that are not extensively discussed in non-adversarial settings, e.g., concentration of measure.
In a sense, robust generalization is a stronger form of standard generalization.

We identified possible next steps towards improving the understanding of how the data affects a model's adversarial robustness.
These include
studying interactions between different properties of data,
considering the effect of additional properties that improve standard generalization on robust model generalization,
devising quantitative metrics for different aspects of the data, and
extending the studies and their empirical evaluation beyond the images domain.
We hope our survey will help researchers and ML practitioners to better understand adversarial vulnerability
and will spark further research to address the identified knowledge gaps.