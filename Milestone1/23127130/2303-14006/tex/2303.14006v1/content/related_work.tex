% \vspace{-1mm}
\section{Related Work}
% \vspace{-2mm}
Several simulators exist in our community for modeling distributed systems running general-purpose workloads~\cite{mohammad2017dist, sst, zsim}, with the classic trade-off between simulation accuracy, simulation speed and engineering effort.
Moreover, several models/simulators have been proposed to optimize communication performance in HPC platforms, such as LogGOPSim~\cite{Hoefler2010loggopsim} and SMPI~\cite{Degomme2017smpi}.
This work builds upon the observation of recent works~\cite{astrasim, Robinson2022DTS, deepflow, themis} that the compute-memory-communication characteristics of distributed training is possible to abstract and capture via a mix of analytical and simulation methods, without requiring a general-purpose simulator.
This is the first simulator, to the best of our knowledge, to enable running arbitrary DNN training execution traces over next-generation platforms with multi-dimensional (scale-up + scale-out) topologies and disaggregated memory systems.
