@book{Berg:2008:CGA:1370949,
 author = {Berg, Mark de and Cheong, Otfried and Kreveld, Marc van and Overmars, Mark},
 title = {Computational Geometry: Algorithms and Applications},
 year = {2008},
 isbn = {3540779736, 9783540779735},
 edition = {3rd ed.},
 publisher = {Springer-Verlag TELOS},
 address = {Santa Clara, CA, USA},
} 

@article{10.1371/journal.pone.0091691,
    doi = {10.1371/journal.pone.0091691},
    author = {Brassey, Charlotte A. AND Sellers, William I.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Scaling of Convex Hull Volume to Body Mass in Modern Primates, Non-Primate Mammals and Birds},
    year = {2014},
    month = {03},
    volume = {9},
    url = {https://doi.org/10.1371/journal.pone.0091691},
    pages = {1-12},
    abstract = {The volumetric method of ‘convex hulling’ has recently been put forward as a mass prediction technique for fossil vertebrates. Convex hulling involves the calculation of minimum convex hull volumes (volCH) from the complete mounted skeletons of modern museum specimens, which are subsequently regressed against body mass (Mb) to derive predictive equations for extinct species. The convex hulling technique has recently been applied to estimate body mass in giant sauropods and fossil ratites, however the biomechanical signal contained within volCH has remained unclear. Specifically, when volCH scaling departs from isometry in a group of vertebrates, how might this be interpreted? Here we derive predictive equations for primates, non-primate mammals and birds and compare the scaling behaviour of Mb to volCH between groups. We find predictive equations to be characterised by extremely high correlation coefficients (r2 = 0.97–0.99) and low mean percentage prediction error (11–20\%). Results suggest non-primate mammals scale body mass to volCH isometrically (b = 0.92, 95\%CI = 0.85–1.00, p = 0.08). Birds scale body mass to volCH with negative allometry (b = 0.81, 95\%CI = 0.70–0.91, p = 0.011) and apparent density (volCH/Mb) therefore decreases with mass (r2 = 0.36, p<0.05). In contrast, primates scale body mass to volCH with positive allometry (b = 1.07, 95\%CI = 1.01–1.12, p = 0.05) and apparent density therefore increases with size (r2 = 0.46, p = 0.025). We interpret such departures from isometry in the context of the ‘missing mass’ of soft tissues that are excluded from the convex hulling process. We conclude that the convex hulling technique can be justifiably applied to the fossil record when a large proportion of the skeleton is preserved. However we emphasise the need for future studies to quantify interspecific variation in the distribution of soft tissues such as muscle, integument and body fat.},
    number = {3}
}

@article{healthcare,
author = {Militello, Carmelo and Rundo, Leonardo and Vitabile, Salvatore and Russo, Giorgio and Pisciotta, Pietro and Marletta, Francesco and Ippolito, Massimo and D’Arrigo, Corrado and Midiri, Massimo and Gilardi, Maria},
year = {2015},
month = {09},
pages = {},
title = {Gamma Knife Treatment Planning: MR Brain Tumor Segmentation and Volume Measurement Based on Unsupervised Fuzzy C-Means Clustering},
volume = {25},
journal = {International Journal of Imaging Systems and Technology},
doi = {10.1002/ima.22139}
}

@article{hc2,
author = {Rundo, Leonardo and Stefano, Alessandro and Militello, Carmelo and Russo, Giorgio and Sabini, Maria and D'Arrigo, Corrado and Marletta, Francesco and Ippolito, Massimo and Mauri, Giancarlo and Vitabile, Salvatore and Gilardi, Maria},
year = {2017},
month = {03},
pages = {},
title = {A Fully Automatic Approach for Multimodal PET and MR Image Segmentation in Gamma Knife Treatment Planning},
volume = {144},
journal = {Computer Methods and Programs in Biomedicine},
doi = {10.1016/j.cmpb.2017.03.011}
}

@article{image,
author = {M.A, Jayaram and Fleyeh, Hasan},
year = {2016},
month = {05},
pages = {48-58},
title = {Convex Hulls in Image Processing: A Scoping Review},
volume = {2016},
journal = {American Journal of Intelligent Systems},
doi = {10.5923/j.ajis.20160602.03}
}

@article{park2021face,
  title={A Face Replacement Method Using Affine Transform of Delaunay Triangles},
  author={Park, Kyung-Nam},
  volume={22},
  number={2},
  pages={253--262},
  year={2021},
  journal = {Journal of the Optical Society of America A 35(7)}
}

@book{o1998computational,
  title={Computational geometry in C},
  author={o'Rourke, Joseph and others},
  year={1998},
  publisher={Cambridge university press}
}

@article{10.1145/321556.321564,
author = {Chand, Donald R. and Kapur, Sham S.},
title = {An Algorithm for Convex Polytopes},
year = {1970},
issue_date = {Jan. 1970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {1},
issn = {0004-5411},
url = {https://doi.org/10.1145/321556.321564},
doi = {10.1145/321556.321564},
journal = {J. ACM},
month = jan,
pages = {78–86},
numpages = {9}
}

@article{JARVIS197318,
title = {On the identification of the convex hull of a finite set of points in the plane},
journal = {Information Processing Letters},
volume = {2},
number = {1},
pages = {18-21},
year = {1973},
issn = {0020-0190},
doi = {https://doi.org/10.1016/0020-0190(73)90020-3},
url = {https://www.sciencedirect.com/science/article/pii/0020019073900203},
author = {R.A. Jarvis},
keywords = {convex hull, algorithm}
}

@article{GRAHAM1972132,
title = {An efficient algorithm for determining the convex hull of a finite planar set},
journal = {Information Processing Letters},
volume = {1},
number = {4},
pages = {132-133},
year = {1972},
issn = {0020-0190},
doi = {https://doi.org/10.1016/0020-0190(72)90045-2},
url = {https://www.sciencedirect.com/science/article/pii/0020019072900452},
author = {R.L. Graham}
}

@article{10.1145/235815.235821,
author = {Barber, C. Bradford and Dobkin, David P. and Huhdanpaa, Hannu},
title = {The Quickhull Algorithm for Convex Hulls},
year = {1996},
issue_date = {Dec. 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {4},
issn = {0098-3500},
url = {https://doi.org/10.1145/235815.235821},
doi = {10.1145/235815.235821},
abstract = {The convex hull of a set of points is the smallest convex set that contains the points. This article presents a practical convex hull algorithm that combines the two-dimensional Quickhull algorithm with the general-dimension Beneath-Beyond Algorithm. It is similar to the randomized, incremental algorithms for convex hull and delaunay triangulation. We provide empirical evidence that the algorithm runs faster when the input contains nonextreme points and that it used less memory. computational geometry algorithms have traditionally assumed that input sets are well behaved. When an algorithm is implemented with floating-point arithmetic, this assumption can lead to serous errors. We briefly describe a solution to this problem when computing the convex hull in two, three, or four dimensions. The output is a set of “thick” facets that contain all possible exact convex hulls of the input. A variation is effective in five or more dimensions.},
journal = {ACM Trans. Math. Softw.},
month = dec,
pages = {469–483},
numpages = {15},
keywords = {Delaunay triangulation, halfspace intersection, Voronoi diagram, convex hull}
}

@article{10.1145/359423.359430,
author = {Preparata, F. P. and Hong, S. J.},
title = {Convex Hulls of Finite Sets of Points in Two and Three Dimensions},
year = {1977},
issue_date = {Feb. 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/359423.359430},
doi = {10.1145/359423.359430},
abstract = {The convex hulls of sets of n points in two and three dimensions can be determined with O(n log n) operations. The presented algorithms use the “divide and conquer” technique and recursively apply a merge procedure for two nonintersecting convex hulls. Since any convex hull algorithm requires at least O(n log n) operations, the time complexity of the proposed algorithms is optimal within a multiplicative constant.},
journal = {Commun. ACM},
month = feb,
pages = {87–93},
numpages = {7},
keywords = {spatial set of points, planar set of points, convex hull, optimal algorithms, computational complexity}
}

@article{KALLAY1984197,
title = {The complexity of incremental convex hull algorithms in Rd},
journal = {Information Processing Letters},
volume = {19},
number = {4},
pages = {197},
year = {1984},
issn = {0020-0190},
doi = {https://doi.org/10.1016/0020-0190(84)90084-X},
url = {https://www.sciencedirect.com/science/article/pii/002001908490084X},
author = {Michael Kallay},
keywords = {Convex hull},
abstract = {The complexity of any incremental convex hull algorithm in Rd is shown to be Ω(n[(d+1)2]) for n points and constant d.}
}

@misc{cgal:hs-ch3-18b,
  author = {Susan Hert and Stefan Schirra},
  title = {{3D} Convex Hulls},
  publisher = {{CGAL Editorial Board}},
  edition = {{4.13}},
  booktitle = {{CGAL} User and Reference Manual},
  url = {https://doc.cgal.org/4.13/Manual/packages.html\#PkgConvexHull3Summary},
  year = 2018
}

@article{10.1145/3402819,
author = {Blelloch, Guy E. and Gu, Yan and Shun, Julian and Sun, Yihan},
title = {Parallelism in Randomized Incremental Algorithms},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {5},
issn = {0004-5411},
url = {https://doi.org/10.1145/3402819},
doi = {10.1145/3402819},
abstract = {In this article, we show that many sequential randomized incremental algorithms are in fact parallel. We consider algorithms for several problems, including Delaunay triangulation, linear programming, closest pair, smallest enclosing disk, least-element lists, and strongly connected components.We analyze the dependencies between iterations in an algorithm and show that the dependence structure is shallow with high probability or that, by violating some dependencies, the structure is shallow and the work is not increased significantly. We identify three types of algorithms based on their dependencies and present a framework for analyzing each type. Using the framework gives work-efficient polylogarithmic-depth parallel algorithms for most of the problems that we study.This article shows the first incremental Delaunay triangulation algorithm with optimal work and polylogarithmic depth. This result is important, since most implementations of parallel Delaunay triangulation use the incremental approach. Our results also improve bounds on strongly connected components and least-element lists and significantly simplify parallel algorithms for several problems.},
journal = {J. ACM},
month = {sep},
articleno = {27},
numpages = {27},
keywords = {closest pair, least-element lists, linear programming, Delaunay triangulation, smallest enclosing disk, Randomized incremental algorithms, strongly connected components}
}

@article{FERRADA2020112298,
title = {A filtering technique for fast Convex Hull construction in R2},
journal = {Journal of Computational and Applied Mathematics},
volume = {364},
pages = {112298},
year = {2020},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2019.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S0377042719302870},
author = {Héctor Ferrada and Cristóbal A. Navarro and Nancy Hitschfeld},
keywords = {Convex Hull, Filtering Technique, Priority queues},
abstract = {This work presents an optimization technique that reduces the computational cost for building the Convex Hull from a set of points. The proposed method pre-processes the input set, filtering all points inside an eight-vertex polygon in O(n) time and returns a reduced set of candidate points, ordered and distributed across four priority queues. Experimental results show that for a normal distribution of points in two-dimensional space, the filtering approach in conjunction with the Graham scan is up to 10× faster than the qhull library, and between 1.7× to 10× faster than the Convex Hull methods available in the CGAL library. Results on the worst case scenario (when all points lie in the circumference) show that a slight random radial displacement of the points make this method the fastest one. Moreover, when increasing the magnitude of this displacement, the performance of the proposed method scales at a faster rate than the other methods. In terms of memory efficiency, the proposed implementation manages to use from 3× to 6× less memory than the other methods. The reason behind this memory improvement is because the proposed method stores indices of the input arrays, avoiding duplicates of the original floating points. Furthermore, the approach extends the problem size up to n≤240 by employing 5-byte indices (instead of 8-bytes) when n>232. The optimization technique presented in this work has shown to be significantly useful in accelerating the computation of the Convex Hull, and it is not limited just to the combination with the Graham scan, but it can also be used in conjunction with other Convex Hull algorithms.}
}

@INPROCEEDINGS{5763404,  author={S. {Srungarapu} and D. P. {Reddy} and K. {Kothapalli} and P. J. {Narayanan}},  
booktitle={2011 IEEE Workshops of International Conference on Advanced Information Networking and Applications},   
title={Fast Two Dimensional Convex Hull on the GPU},
year={2011},  
volume={},  
number={},  
pages={7-12},  doi={10.1109/WAINA.2011.64}}

@article{cudachain,
author = {Mei, Gang},
year = {2016},
month = {05},
pages = {1-26},
title = {CudaChain: an alternative algorithm for finding 2D convex hulls on the GPU},
volume = {5},
journal = {SpringerPlus},
doi = {10.1186/s40064-016-2284-4}
}

@article{STEIN2012265,
title = {CudaHull: Fast parallel 3D convex hull on the GPU},
journal = {Computers \& Graphics},
volume = {36},
number = {4},
pages = {265-271},
year = {2012},
note = {Applications of Geometry Processing},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2012.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0097849312000350},
author = {Ayal Stein and Eran Geva and Jihad El-Sana},
keywords = {Convex hull, Parallel processing, GPU processing, CUDA programming},
abstract = {In this paper, we present a novel parallel algorithm for computing the convex hull of a set of points in 3D using the CUDA programming model. It is based on the QuickHull approach and starts by constructing an initial tetrahedron using four extreme points, discards the internal points, and distributes the external points to the four faces. It then proceeds iteratively. In each iteration, it refines the faces of the polyhedron, discards the internal points, and redistributes the remaining points for each face among its children faces. The refinement of a face is performed by selecting the furthest point from its associated points and generating three children triangles. In each iteration, concave edges are swapped, and concave vertices are removed to maintain convexity. The face refinement procedure is performed on the CPU, because it requires a very small fraction of the execution time (approximately 1\%), and the intensive point redistribution is performed in parallel on the GPU. Our implementation outpaced the CPU-based Qhull implementation by 30 times for 10 million points and 40 times for 20 million points.}
}

@article{mei,
author = {Qin, Jiayu and Mei, Gang and Cuomo, Salvatore and Sixu, Guo and Li, Yixuan},
year = {2019},
month = {04},
pages = {},
title = {CudaCHPre2D: A straightforward preprocessing approach for accelerating 2D convex hull computations on the GPU},
volume = {32},
journal = {Concurrency and Computation Practice and Experience},
doi = {10.1002/cpe.5229}
}

@inproceedings{10.1145/3350755.3400255,
author = {Blelloch, Guy E. and Gu, Yan and Shun, Julian and Sun, Yihan},
title = {Randomized Incremental Convex Hull is Highly Parallel},
year = {2020},
isbn = {9781450369350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350755.3400255},
doi = {10.1145/3350755.3400255},
abstract = {The randomized incremental convex hull algorithm is one of the most practical and important geometric algorithms in the literature. Due to its simplicity, and the fact that many points or facets can be added independently, it is also widely used in parallel convex hull implementations. However, to date there have been no non-trivial theoretical bounds on the parallelism available in these implementations. In this paper, we provide a strong theoretical analysis showing that the standard incremental algorithm is inherently parallel. In particular, we show that for n points in any constant dimension, the algorithm has O(log n) dependence depth with high probability. This leads to a simple work-optimal parallel algorithm with polylogarithmic span with high probability.Our key technical contribution is a new definition and analysis of the configuration dependence graph extending the traditional configuration space, which allows for asynchrony in adding configurations. To capture the "true" dependence between configurations, we define the support set of configuration c to be the set of already added configurations that it depends on. We show that for problems where the size of the support set can be bounded by a constant, the depth of the configuration dependence graph is shallow (O(log n) with high probability for input size n). In addition to convex hull, our approach also extends to several related problems, including half-space intersection and finding the intersection of a set of unit circles. We believe that the configuration dependence graph and its analysis is a general idea that could potentially be applied to more problems.},
booktitle = {Proceedings of the 32nd ACM Symposium on Parallelism in Algorithms and Architectures},
pages = {103–115},
numpages = {13},
keywords = {convex hull, configuration space, randomized incremental algorithms, parallelism},
location = {Virtual Event, USA},
series = {SPAA '20}
}

@InProceedings{10.1007/978-3-319-94776-1_14,
author="Barbay, J{\'e}r{\'e}my
and Ochoa, Carlos",
editor="Wang, Lusheng
and Zhu, Daming",
title="Synergistic Solutions for Merging and Computing Planar Convex Hulls",
booktitle="Computing and Combinatorics",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="156--167",
abstract="We describe and analyze the first adaptive algorithm for merging k convex hulls in the plane. This merging algorithm in turn yields a synergistic algorithm to compute the convex hull of a set of planar points, taking advantage both of the positions of the points and their order in the input. This synergistic algorithm asymptotically outperforms all previous solutions for computing the convex hull in the plane.",
isbn="978-3-319-94776-1"
}

@article{cudach2d,
author = {Qin, Jiayu and Mei, Gang and Cuomo, Salvatore and Sixu, Guo and Li, Yixuan},
year = {2019},
month = {04},
pages = {},
title = {CudaCHPre2D: A straightforward preprocessing approach for accelerating 2D convex hull computations on the GPU},
volume = {32},
journal = {Concurrency and Computation Practice and Experience},
doi = {10.1002/cpe.5229}
}

@article{cudach3d,
author = {Mei, Gang and Xu, Nengxiong},
year = {2015},
month = {05},
pages = {35-44},
title = {CudaPre3D: An Alternative Preprocessing Algorithm for Accelerating 3D Convex Hull Computation on the GPU},
volume = {15},
journal = {Advances in Electrical and Computer Engineering},
doi = {10.4316/AECE.2015.02005}
}

@article{alshamrani,
author = {Alshamrani, Reham and Alshehri, Fatimah and Kurdi, Heba},
year = {2020},
month = {01},
pages = {317-324},
title = {A Preprocessing Technique for Fast Convex Hull Computation},
volume = {170},
journal = {Procedia Computer Science},
doi = {10.1016/j.procs.2020.03.046}
}

@inproceedings{mei2012,
author = {Mei, Gang and Tipper, John and Xu, Nengxiong},
year = {2012},
month = {12},
title = {An Algorithm for Finding Convex Hulls of Planar Point Sets},
journal = {Proceedings of 2nd International Conference on Computer Science and Network Technology, ICCSNT 2012},
booktitle = {Proceedings of 2nd International Conference on Computer Science and Network Technology, ICCSNT 2012},
doi = {10.1109/ICCSNT.2012.6526070}
}

@book{krause1986taxicab,
  title={Taxicab geometry: An adventure in non-Euclidean geometry},
  author={Krause, Eugene F},
  year={1986},
  publisher={Courier Corporation}
}

@Inbook{Deza2009,
author="Deza, Michel Marie
and Deza, Elena",
title="Encyclopedia of Distances",
bookTitle="Encyclopedia of Distances",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--583",
isbn="978-3-642-00234-2",
doi="10.1007/978-3-642-00234-2\_1",
url="https://doi.org/10.1007/978-3-642-00234-2\_1"
}

@techreport{BlellochTR90,
	author = "Guy~E. Blelloch",
	title = "Prefix Sums and Their Applications",
	institution = "School of Computer Science, Carnegie Mellon University",
	number = "CMU-CS-90-190",
	month = nov,
	year = 1990 }

@article{navarro_hitschfeld-kahler_mateu_2014, title={A Survey on Parallel Computing and its Applications in Data-Parallel Problems Using GPU Architectures}, 
volume={15}, 
DOI={10.4208/cicp.110113.010813a}, 
number={2}, 
journal={Communications in Computational Physics}, 
publisher={Cambridge University Press}, 
author={Navarro, Crist{\'o}bal A. and Hitschfeld-Kahler, Nancy and Mateu, Luis}, year={2014}, pages={285–329}}

@misc{patagon,
    howpublished = {{\url{https://patagon.uach.cl}}},
    author = {{Patag\'on Supercomputer}},
    year = {2021}
}

@inproceedings{harris2007optimizing,
  author={Harris, Mark},
  title={Optimizing {CUDA}},
  booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  series={SC '07},
  journal={SC07: High Performance Computing With {CUDA}},
  year={2007}
}

@inproceedings{harris_2005,
 author = {Harris, Mark},
 title = {Mapping Computational Concepts to GPUs},
 booktitle = {ACM SIGGRAPH 2005 Courses},
 series = {SIGGRAPH '05},
 year = {2005},
 location = {Los Angeles, California},
 articleno = {50},
 url = {http://doi.acm.org/10.1145/1198555.1198768},
 doi = {10.1145/1198555.1198768},
 acmid = {1198768},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@ARTICLE{42122,
  author={Blelloch, G.E.},
  journal={IEEE Transactions on Computers}, 
  title={Scans as primitive parallel operations}, 
  year={1989},
  volume={38},
  number={11},
  pages={1526-1538},
  doi={10.1109/12.42122}}
  
@inproceedings{ScanTC,
author = {Dakkak, Abdul and Li, Cheng and Xiong, Jinjun and Gelado, Isaac and Hwu, Wen-mei},
title = {Accelerating Reduction and Scan Using Tensor Core Units},
year = {2019},
isbn = {9781450360791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3330345.3331057},
doi = {10.1145/3330345.3331057},
abstract = {Driven by deep learning, there has been a surge of specialized processors for matrix multiplication, referred to as Tensor Core Units (TCUs). These TCUs are capable of performing matrix multiplications on small matrices (usually 4 \texttimes{} 4 or 16 \texttimes{} 16) to accelerate HPC and deep learning workloads. Although TCUs are prevalent and promise increase in performance and/or energy efficiency, they suffer from over specialization as only matrix multiplication on small matrices is supported. In this paper we express both reduction and scan in terms of matrix multiplication operations and map them onto TCUs. To our knowledge, this paper is the first to try to broaden the class of algorithms expressible as TCU operations and is the first to show benefits of this mapping in terms of: program simplicity, efficiency, and performance. We implemented the reduction and scan algorithms using NVIDIA's V100 TCUs and achieved 89\% -- 98\% of peak memory copy bandwidth. Our results are orders of magnitude faster (up to 100 \texttimes{} for reduction and 3 \texttimes{} for scan) than state-of-the-art methods for small segment sizes (common in HPC and deep learning applications). Our implementation achieves this speedup while decreasing the power consumption by up to 22\% for reduction and 16\% for scan.},
booktitle = {Proceedings of the ACM International Conference on Supercomputing},
pages = {46–57},
numpages = {12},
location = {Phoenix, Arizona},
series = {ICS '19}
}  
  
  
@article{polylla01,
author = {Salinas-Fern\'{a}ndez, Sergio and Hitschfeld-Kahler, Nancy and Ortiz-Bernardin, Alejandro and Si, Hang},
title = {POLYLLA: Polygonal Meshing Algorithm Based on Terminal-Edge Regions},
year = {2022},
issue_date = {Oct 2022},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {38},
number = {5},
issn = {0177-0667},
url = {https://doi.org/10.1007/s00366-022-01643-4},
doi = {10.1007/s00366-022-01643-4},
abstract = {This paper presents an algorithm to generate a new kind of polygonal mesh obtained from triangulations. Each polygon is built from a terminal-edge region surrounded by edges that are not the longest-edge of any of the two triangles that share them. The algorithm is termed Polylla and is divided into three phases. The first phase consists of labeling each edge of the input triangulation according to its size; the second phase builds polygons (simple or not) from terminal-edges regions using the label system; and the third phase transforms each non simple polygon into simple ones. The final mesh contains polygons with convex and non convex shape. Since Voronoi-based meshes are currently the most used polygonal meshes, we compare some geometric properties of our meshes against constrained Voronoi meshes. Several experiments were run to compare the shape and size of polygons, the number of final mesh points and polygons. For the same input, Polylla meshes contain less polygons than Voronoi meshes and the algorithm is simpler and faster than the algorithm to generate constrained Voronoi meshes. Finally, we have validated Polylla meshes by solving the Laplace equation on an L-shaped domain using the virtual element method (VEM). We show that the numerical performance of the VEM using Polylla meshes and Voronoi meshes is similar.},
journal = {Eng. with Comput.},
month = {oct},
pages = {4545–4567},
numpages = {23},
keywords = {Terminal-edge region, Delaunay triangulations, Virtual element method, Polygonal mesh}
}

@Article{polylla02,
author={Salinas-Fern{\'a}ndez, Sergio
and Hitschfeld-Kahler, Nancy
and Ortiz-Bernardin, Alejandro
and Si, Hang},
title={POLYLLA: polygonal meshing algorithm based on terminal-edge regions},
journal={Engineering with Computers},
year={2022},
month={May},
day={03},
abstract={This paper presents an algorithm to generate a new kind of polygonal mesh obtained from triangulations. Each polygon is built from a terminal-edge region surrounded by edges that are not the longest-edge of any of the two triangles that share them. The algorithm is termed Polylla and is divided into three phases. The first phase consists of labeling each edge of the input triangulation according to its size; the second phase builds polygons (simple or not) from terminal-edges regions using the label system; and the third phase transforms each non simple polygon into simple ones. The final mesh contains polygons with convex and non convex shape. Since Voronoi-based meshes are currently the most used polygonal meshes, we compare some geometric properties of our meshes against constrained Voronoi meshes. Several experiments were run to compare the shape and size of polygons, the number of final mesh points and polygons. For the same input, Polylla meshes contain less polygons than Voronoi meshes and the algorithm is simpler and faster than the algorithm to generate constrained Voronoi meshes. Finally, we have validated Polylla meshes by solving the Laplace equation on an L-shaped domain using the virtual element method (VEM). We show that the numerical performance of the VEM using Polylla meshes and Voronoi meshes is similar.},
issn={1435-5663},
doi={10.1007/s00366-022-01643-4},
OPTurl={https://doi.org/10.1007/s00366-022-01643-4}
}

@article{NEMIRKO2021381,
title = {Machine learning algorithm based on convex hull analysis},
journal = {Procedia Computer Science},
volume = {186},
pages = {381-386},
year = {2021},
note = {14th International Symposium "Intelligent Systems},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.04.160},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921009911},
author = {A.P. Nemirko and J.H. Dulá},
keywords = {Intelligent systems, computational geometry, pattern recognition, nearest convex hull classification, linear programming, automatic medical diagnostics},
abstract = {In this paper machine learning methods for automatic classification problems using computational geometry are considered. Classes are defined with convex hulls of points sets in a multidimensional feature space. Classification algorithms based on the estimation of the proximity of the test point to convex class shells are considered. Several ways of such estimation are suggested when the test point is located both outside the convex hull and inside it. A new method for estimating proximity based on linear programming is proposed, and the corresponding nearest convex hull classifier is described. The results of experimental studies on the real medical diagnostics problem are presented. An efficiency comparison of the proposed classifier and other types of classifiers, both based on convex hull analysis and not, has shown the high efficiency of the proposed method for estimating proximity based on linear programming.}
}

@article{MEERAN1997737,
title = {Optimum path planning using convex hull and local search heuristic algorithms},
journal = {Mechatronics},
volume = {7},
number = {8},
pages = {737-756},
year = {1997},
issn = {0957-4158},
doi = {https://doi.org/10.1016/S0957-4158(97)00033-0},
url = {https://www.sciencedirect.com/science/article/pii/S0957415897000330},
author = {S. Meeran and A. Share},
abstract = {Whether in improving quality or productivity the impact of mechatronic systems such as robots in industry is unquestionable. One aspect of interest in robotics is planning the optimum path for a mobile robot or the optimum trajectory for link movements of a stationary robot in order to increase their efficiency. However, for a given set of points complete enumeration of all the possible paths to establish an optimal one is not feasible as the search space increases exponentially (explodes combinatorially) as the number of points increases. This problem, traditionally known as the “Traveling Salesman Problem” (TSP) has attracted a great deal of attention for a long time. Proven enumerative techniques such as “nearest neighbour algorithm”, “branch and bound”, “cutting planes”, and “dynamic programming” as well as approximation methods such as “tabu search”, “greedy algorithm”, “simulated annealing” and “genetic algorithm”, have had only a limited success in solving this problem. Recently “convex hull”, a minimum area and perimeter shape, has been used as an initial sub-tour along with enumerative techniques such as minimising insertion costs to solve the TSP problem. We present a system which uses heuristic rules to augment the convex hull initial sub-tour created by the Graham scan algorithm. The system is able to provide a solution in a polynomial time.}
}

@Inbook{Nearchou1994,
author="Nearchou, A. C.
and Aspragathos, N. A.",
editor="Lenar{\v{c}}i{\v{c}}, Jadran
and Ravani, Bahram",
title="A Collision-Detection Scheme Based on Convex-Hulls Concept for Generating Kinematically Feasible Robot Trajectories",
bookTitle="Advances in Robot Kinematics and Computational Geometry",
year="1994",
publisher="Springer Netherlands",
address="Dordrecht",
pages="477--484",
abstract="In this paper a technique for collision detection between a robot and a collection of obstacles is presented. The technique is based on decomposing the problem of interference into two sub-problems: Firstly, the problem of determining the arm's links too closely located to obstacles so that they are candidate to collide, and secondly the problem of checking for interference between the links in question, and the associated near by obstacles. Well known concepts in computational geometry such as convex hulls and minimum spanning circles are used in robot trajectory control moving among obstacles. The efficiency of the method is tested by numerical experiments applied on an existing path planning algorithm.",
isbn="978-94-015-8348-0",
doi="10.1007/978-94-015-8348-0_48",
url="https://doi.org/10.1007/978-94-015-8348-0_48"
}

@misc{alanhull,
  doi = {10.48550/ARXIV.2209.12310},
  
  url = {https://arxiv.org/abs/2209.12310},
  
  author = {Keith, Alan and Ferrada, Héctor and Navarro, Cristóbal A.},
  
  keywords = {Distributed, Parallel, and Cluster Computing (cs.DC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Accelerating the Convex Hull Computation with a Parallel GPU Algorithm},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@ARTICLE{9147055,
  author={Navarro, Cristóbal A. and Carrasco, Roberto and Barrientos, Ricardo J. and Riquelme, Javier A. and Vega, Raimundo},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={GPU Tensor Cores for Fast Arithmetic Reductions}, 
  year={2021},
  volume={32},
  number={1},
  pages={72-84},
  doi={10.1109/TPDS.2020.3011893}}

@misc{nvidia2020A100,
  title={{A100 Tensor Core GPU Architecture Whitepaper}},
  author={Nvidia},
  year={2020},
  url={https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/nvidia-ampere-architecture-whitepaper.pdf},
  institution={NVIDIA Corportation}
}