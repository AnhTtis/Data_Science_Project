%\documentclass[a4paper,onecolumn,11pt,unpublished]{quantumarticle}
%\pdfoutput=1
%\usepackage{lipsum}
\documentclass[
    aps,
    pra,
    longbibliography,
    % a4paper,
    superscriptaddress,
    amsmath,amssymb,amsfonts, 
    tightenlines,
    twocolumn,
    % 10pt
    ]{revtex4-1}

\usepackage{caption}
\usepackage[utf8]{inputenc}  %Input what you want e.g., é, ł, a, ü
\usepackage[T1]{fontenc}     %Output what you want e.g., é, ł, a, ü
\usepackage[english]{babel}  %Do hyphenation according to british english
%\usepackage[sc,osf]{mathpazo}\linespread{1.05}  %Palatino font
  % URL font that go well wtih palatino
%\usepackage[scaled=1.03]{inconsolata} %Monospace font
\usepackage{hyperref}  %Hyperlinks (pink, green, blue)
\usepackage{graphicx} % Package to insert external figures
\usepackage{float}
\usepackage[babel]{microtype}  %Improves text justification
\usepackage{amsmath,amssymb,amsthm,bm,amsfonts,mathrsfs,bbm} %Useful math packages
\usepackage{setspace}
\usepackage{times}
\usepackage{braket}
\usepackage[bottom]{footmisc}
\usepackage{blochsphere}
\usepackage{pgfplots}
 
\pgfplotsset{compat=1.17}
\usetikzlibrary{calc,3d,shapes, pgfplots.external, intersections}
\usepackage{algorithm}
\usepackage{physics}
% \usepackage[noend]{algpseudocode}
\usepackage[noend]{algorithmic}
\usepackage{eqparbox}
\renewcommand\algorithmiccomment[1]{%
  \hfill\#\ \eqparbox{COMMENT}{#1}%
}
\usepackage{physics}
%\usepackage{subfig}
\usepackage{tikz}
\usepackage{mathtools}
%\usepackage{mathabx}
\usetikzlibrary{arrows.meta}
\usepackage{csquotes}
\renewcommand{\qedsymbol}{\rule{0.7em}{0.7em}}
%\renewcommand{\qedsymbol}{$\blacksquare$}
\usepackage{xspace}  %Useful to add space in macros
\usepackage{pgfplots}
\usepackage{verbatim}
\usepackage{amsmath}
%\usepackage[shortlabels]{enumitem}
% \captionsetup{style=base}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newcommand{\Lagr}{\mathcal{L}}
\def\bracket#1#2{{\langle#1|#2\rangle}}
\def\expect#1{{\langle#1\rangle}}
\def\e{{\rm e}}
\def\proj{{\hat{\cal P}}}

\def\H{{\hat H}}
\def\Htot{{\bf \hat H}}
\def\Hint{{\hat H}_{\rm int}}
\def\Hbint{{\bf \hat H}_{\rm int}}
\def\L{{\hat L}}
\def\Ldag{{\hat L}^\dagger}
\def\U{{\hat U}}
\def\Udag{{\hat U}^\dagger}
\def\field{{\hat\phi}}
\def\conj{{\hat p}}
\def\P{{\hat{\vec P}}}
\def\Op{{\hat O}}


\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\newcommand\id{\leavevmode\hbox{\small1\kern-3.3pt\normalsize1}}


\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\bst}{\bs{\theta}}
\newcommand{\bsy}{\bs{y}}
\newcommand{\bsx}{\bs{x}}
\newcommand{\bsz}{\bs{0}}
\newcommand{\bse}{\bs{e}}
\newcommand{\lV}{\left\Vert}
\newcommand{\rV}{\right\Vert}
\newcommand{\cH}{{\cal H}}
\newcommand{\al}{\hat{\alpha}}
\newcommand{\be}{\hat{\beta}}
\newcommand{\tet}{\vartheta}
\newcommand{\fii}{\varphi}
\newcommand{\M}{{_{(M)}}}
\newcommand{\vt}{\widetilde{v}\, }
\newcommand{\alphas}{{\al_1, \dots\, ,\al_N}}
\newcommand{\mus}{{\mu_1, \dots\, ,\mu_N}}
\newcommand{\betas}{{\be_1 \be_2 \dots \be_N}}
\newcommand{\mbbC}{\mathbb{C}}
\newcommand{\mbbR}{\mathbb{R}}
\newcommand{\x}{{\bf x}}
\newcommand{\xp}{{\bf x'}}
\newcommand{\y}{{\bf y}}
\newcommand{\p}{{\bf p}}
\newcommand{\q}{{\bf q}}
\newcommand{\hq}{\hat{q}}
\newcommand{\hp}{\hat{p}}
\newcommand{\hrho}{\hat{\rho}}
\newcommand{\ha}{\hat{a}}
\newcommand{\had}{\hat{a}^\dagger}
\newcommand{\kk}{{\bf k}}
\newcommand{\kp}{{\bf k'}}
\newcommand{\rr}{{\bf r}}
\newcommand{\s}{{\bf s}}
\newcommand{\z}{{\bf z}}
\newcommand{\A}{{\bf \al}}
\newcommand{\sqd}{\frac{1}{\sqrt{2}}}
%\newcommand{\tr}{\mbox{Tr}}
\newtheorem{thm}{Theorem}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}{Lemma}
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{assumption}{Assumption}

\newcommand{\commentAnt}[1]{{\textcolor{brown}{Antonio: #1}}}
\newcommand{\commentFre}[1]{{\textcolor{blue}{Frederik: #1}}}
\newcommand{\je}[1]{{\textcolor{cyan}{#1}}}

\newcommand\DSD[1]{{\color{blue} \bf DSD: #1}}
\newcommand\DP[1]{{\color{red} \bf DP: #1}}

\usepackage{pdfpages}
\usepackage{pgffor}
\makeatletter
\AtBeginDocument{\let\LS@rot\@undefined}
\makeatother


\begin{document}

\title[$U(1) Tensor Networks$]{Supercomputing tensor networks for $U(1)$ symmetric quantum many-body systems}

\author{Minzhao Liu}
\affiliation{Department of Physics, The University of Chicago, Chicago, IL 60637, USA}
\affiliation{Computational Science Division, Argonne National Laboratory, Lemont, IL 60439, USA}

\author{Changhun Oh}
\affiliation{Pritzker School of Molecular Engineering, The University of Chicago, Chicago, IL 60637, USA}

\author{Junyu Liu}
\affiliation{Pritzker School of Molecular Engineering, The University of Chicago, Chicago, IL 60637, USA}
\affiliation{Department of Computer Science, The University of Chicago, Chicago, IL 60637, USA}
\affiliation{Chicago Quantum Exchange, Chicago, IL 60637, USA}
\affiliation{Kadanoff Center for Theoretical Physics, The University of Chicago, Chicago, IL 60637, USA}
\affiliation{qBraid Co., Chicago, IL 60615, USA}
\affiliation{SeQure, Chicago, IL 60615, USA}


\author{Liang Jiang}

\affiliation{Pritzker School of Molecular Engineering, The University of Chicago, Chicago, IL 60637, USA}
\affiliation{Chicago Quantum Exchange, Chicago, IL 60637, USA}

\author{Yuri Alexeev}
\affiliation{Computational Science Division, Argonne National Laboratory, Lemont, IL 60439, USA}
\affiliation{Department of Computer Science, The University of Chicago, Chicago, IL 60637, USA}
\affiliation{Chicago Quantum Exchange, Chicago, IL 60637, USA}

\maketitle

{\bf Simulation of many-body systems is extremely computationally intensive, and tensor network schemes have long been used to make these tasks more tractable via approximation. Recently, tensor network algorithms that can exploit the inherent symmetries of the underlying quantum systems have been proposed to further reduce computational complexity. One class of systems, namely those exhibiting a global $U(1)$ symmetry, is especially interesting. We provide a state-of-the-art, graphical processing unit-accelerated, and highly parallel supercomputer implementation of the tensor network algorithm that takes advantage of $U(1)$ symmetry, opening up the possibility of a wide range of quantum systems for future numerical investigations.}

\section{Introduction}

The size of the Hilbert space of a quantum many-body system is exponentially large in the system size, rendering exact state vector or density matrix simulation intractable. As a result, approximate techniques that exploit the structure of the Hilbert space are used widely where many-body simulation is needed. Tensor networks provide an efficient way of simulating large quantum systems \cite{white1992,vidal2003,verstraete2004}, and have found applications in ground state estimation \cite{Klümper1993}, simulation of open systems \cite{orus2008}, Hamiltonian simulation \cite{vidal2004}, boson sampling simulation \cite{oh2021classical,huang2019simulating,liu2023complexity}, and quantum circuit simulation in quantum machine learning \cite{liu2022embedding,liu2022exploration}, variational quantum algorithms \cite{lykov2021performance,jonathan2021fixed,lykov2022tensor}, and ansatze characterization \cite{liu2022estimating}.

An important class of quantum systems have global $U(1)$ symmetry, which arises when the system has some kind of conserved charge \cite{singh2011tensor}. Examples of such systems include the hardcore Bose Hubbard model \cite{aizenman2004bose}, the spin-$1/2$ XXZ quantum spin chain \cite{alcaraz1989}, boson sampling \cite{aaronson2011computational}, quantum walk \cite{kitagawa2010exploring,childs2010on,childs2013universal,cai2021multiparticle,schreiber2012a}, and monitored quantum circuits \cite{agrawal2022entanglement}. A model is said to be $U(1)$ symmetric if the Hamiltonian commutes with the total charge operator \cite{singh2011tensor}
\begin{equation}
    [\hat{H},\hat{N}]=0.
\end{equation}
As a result, evolution under such Hamiltonian must preserve the charge number operator. More generally, systems can preserve a global $U(1)$ symmetry if the applied unitaries preserve the global charge.

As an example, the hardcore Bose Hubbard model is $U(1)$ symmetric, whose Hamiltonian is given by
\begin{equation}
    \hat{H}_{\text{HCBH}}=\sum_{k=1}^{M}(\hat{a}^\dag_k\hat{a}_{k+1}+\hat{a}_k\hat{a}^\dag_{k+1}+\gamma \hat{n}_k \hat{n}_{k+1}-\mu \hat{n}_k),
\end{equation}
where $\hat{a}^\dag,\hat{a}$ are hardcore bosonic creation and annihilation operators, and $\hat{n}=\hat{a}^\dag\hat{a}$. Since all terms have an equal number of creation and annihilation operators, the total number of particles in the system is preserved. Moreover, the hardcore Bose Hubbard model can be mapped to the spin-$1/2$ XXZ quantum spin chain by defining
\begin{equation}
    \hat{n}=\frac{\mathbb{I}-\hat{\sigma}_z}{2},\hat{a}=\frac{\hat{\sigma}_x+i\hat{\sigma}_y}{2},
\end{equation}
which yields the Hamiltonian that preserves the total up spins:
\begin{equation}
    \hat{H}_{XXZ}=\sum_{k=1}^{M}(\hat{\sigma}_x^{(k)}\hat{\sigma}_x^{(k+1)}+\hat{\sigma}_y^{(k)}\hat{\sigma}_y^{(k+1)}+\Delta\hat{\sigma}_z^{(k)}\hat{\sigma}_z^{(k+1)}).
\end{equation}

Another example of systems with $U(1)$ symmetry is quantum walk (QW), where particle number is naturally preserved. QW is most commonly discussed in the single-particle discrete time setting, where the system has position and spin degrees of freedom. At each time step, a unitary evolution $U(\theta)=TR(\theta)$ is applied to the system, where
\begin{equation}
    T=\sum_x (\vert x+1\rangle\langle x\vert\otimes\vert\uparrow\rangle\langle\uparrow\vert+\vert x-1\rangle\langle x\vert\otimes\vert\downarrow\rangle\langle\downarrow\vert)
\end{equation}
\begin{align}
    R(\theta)=\cos{\theta}(\vert\uparrow\rangle\langle\uparrow\vert+\vert\downarrow\rangle\langle\downarrow\vert)\nonumber\\
    +\sin{\theta}(\vert\downarrow\rangle\langle\uparrow\vert-\vert\uparrow\rangle\langle\downarrow\vert).
\end{align}
Notably, the system is shown to be universal for quantum computation \cite{childs2013universal}. Further, the discrete-time evolution can be viewed as a stroboscopic view of continuous evolution under an effective Hamiltonian such that $U(\theta)=e^{-iH(\theta)\delta t}$ \cite{kitagawa2010exploring}. The system can be modified and generalized to realize numerous classes of topological phases in one and two dimensions. In the multiparticle and continuous time setting, QW has been proposed as a method for quantum sensing \cite{cai2021multiparticle}. Further, multiparticle quantum walk can be used to explore interacting bosonic and fermionic systems.

Another important particle number conserving experiment is boson sampling \cite{aaronson2011computational,spring2013boson,zhong2021phase,madsen2022quantum}, where photons are sent into an interferometer and the number of photons exiting each mode of the interferometer is counted. More precisely, the input quantum state of $N$ independent and identical modes can be written as
\begin{equation}
\vert \psi_{\text{in}}\rangle=\otimes^N_{j=1}\left(\sum_{n=0}^\infty c_n\frac{\hat{a}_j^{\dag n}}{\sqrt{n!}}\right)\vert 0\rangle,
\end{equation}
where $\hat{a}_j^{\dag}$ is the input creation operator. The action of the $M$-mode interferometer is to transform the input creation operators $\hat{a}^\dag$ into output creation operators $\hat{b}^\dag$ according to
\begin{equation}
    \hat{a}_j^\dag\rightarrow\hat{b}_j^\dag=\sum_k^M U_{j,k}\hat{a}_k^\dag,
\end{equation}
where $U$ is determined by the transmissions and phases of the beam splitters and is global Haar random when the array depth is at least $M$. Under suitable conditions and reasonable complexity-theoretic conjectures, classical simulation of boson sampling is exponentially hard \cite{aaronson2011computational}, which resulted in numerous quantum supremacy demonstrations using this scheme \cite{zhong2021phase,madsen2022quantum}. However, recent progress has shown that under high photon loss, classical approximate simulation is possible \cite{liu2023complexity,oh2021classical}.

The aforementioned many-body systems have exponentially large Hilbert spaces, but can be simulated by tensor networks in principle if the entanglement in the system doesn't grow too quickly. As a result, we discuss an important class of tensor network, the matrix product state (MPS). Consider the following wavefunction of an $M$-body quantum system, where a single particle can take on $d$ (dimension of the local Hilbert space) orthogonal physical states:
\begin{equation}
    \vert\psi\rangle=
    \sum_{i_1,\dots,i_M=0}^{d-1} c_{i_1,\dots,i_M} \vert i_1,\dots,i_M \rangle.
\end{equation}
State $\vert i_1,\dots,i_M \rangle$ represents a basis state where the $j$th particle is in the state labeled by $i_j$. The rank $M$ tensor $c_{i_1,\dots,i_M}$ with memory complexity $O(d^M)$ contains all information of the pure state.

It turns out that the quantum states for one-dimensional systems can be efficiently represented using tensor networks, especially the well-known MPS. For example, the ground states of many local Hamiltonians obey the area law of entanglement \cite{wolf2008}, where the entanglement grows with the size of the boundary of the system instead of the volume. For 1-d systems, this implies that the entanglement is constant and does not grow with the system size. Such low entanglement states are therefore a very special corner of the entire Hilbert space, and efficient simulation techniques must exploit this property.

Using the canonicalized MPS formalism, the $c_{i_1,\dots,i_M}$ probability amplitude tensor can be represented efficiently as
\begin{align}\label{MPS}
    c_{i_1,\dots,i_M} = \sum_{\alpha_0,\dots,\alpha_M=0}^{\chi-1} &\Gamma_{\alpha_0\alpha_1}^{[1]i_1}\lambda_{\alpha_1}^{[1]}\Gamma_{\alpha_1\alpha_2}^{[2]i_2}\lambda_{\alpha_2}^{[2]}\nonumber\\
    &\dots\lambda_{\alpha_{M-1}}^{[M-1]}\Gamma_{\alpha_{M-1}\alpha_M}^{[M]i_M},
\end{align}
where $\alpha_k$ is the bond index for mode $k$ and $\chi$ is the bond dimension. The memory complexity of this representation is dominated by $\Gamma$'s with $O(\chi^2)$ cost, and the total cost is linear in $M$ rather than exponential. The accuracy of the MPS representation can be controlled by tuning $\chi$. Further, it can be shown that if $\chi$ is allowed to grow exponentially with $M$, the MPS representation can be made exact.

As equation \ref{MPS} shows, each $\Gamma$ tensor is associated with the physical degree of freedom of one particle, as made evident by their associated $i$ indices, and entanglement with neighboring particles is captured by the dummy $\alpha$ indices. The $\lambda$ tensors correspond to the Schmidt coefficients if a Schmidt decomposition is performed on the wavefunction, and therefore capture entanglement. To apply a local unitary update on particle $k$ and $k+1$, the unitary matrix needs to be contracted with the wavefunction at the physical indices, leading to the resulting tensor
\begin{align}
    \Theta_{\alpha_{k-1}\alpha_{k+1}}^{j_k,j_{k+1}}=
    \sum_{i_k,i_{k+1}=0}^{d-1}\sum_{\alpha_k=0}^{\chi-1}
    &U^{j_k,j_{k+1}}_{i_k,i_{k+1}}\lambda_{\alpha_{k-1}}^{[k-1]}\Gamma_{\alpha_{k-1}\alpha_k}^{[k]i_k}\nonumber\\
    &\lambda_{\alpha_k}^{[k]}\Gamma_{\alpha_k\alpha_{k+1}}^{[k+1]i_{k+1}}\lambda_{\alpha_{k+1}}^{[k+1]}.
\end{align}

The result of this computation is a single tensor of size $d^2\chi^2$, which should be used in the new representation of the wavefunction to replace $\lambda^{[k-1]},\Gamma^{[k]i_k},\lambda^{[k]},\Gamma^{[k+1]i_{k+1}},\lambda^{[k+1]}$. However, this is no longer in the form of an MPS. To restore the MPS form, singular value decomposition (SVD) is performed on $\Theta$ to produce
\begin{equation}
 \Theta_{\alpha_{k-1}\alpha_{k+1}}^{j_k,j_{k+1}}=\sum_{\beta_k=0}^{d\chi-1}V_{(j_k,\alpha_{k-1}),\beta_k}\Tilde{\lambda}^{[k]}_{\beta_k}W_{\beta_k,(j_{k+1},\alpha_{k+1})}.
\end{equation}
By retaining only the $\chi$ largest singular values, we can identity new $\Gamma$ tensors as
\begin{align}
    \Tilde{\Gamma}_{\alpha_{k-1}\alpha_k}^{[k]i_k}&=V_{(j_k,\alpha_{k-1}),\beta_k}/\lambda_{\alpha_{k-1}}^{[k-1]}\\
    \Tilde{\Gamma}_{\alpha_k\alpha_{k+1}}^{[k+1]i_{k+1}}&=W_{\beta_k,(j_{k+1},\alpha_{k+1})}/\lambda_{\alpha_{k+1}}^{[k+1]},
\end{align}
which restores the MPS form.

%\section{MPS with $U(1)$ symmetry}\label{MPS with U(1)}

Although MPS can efficiently represent 1-d many-body systems with controlled entanglement, it does not utilize any symmetry to further reduce the computational cost. To efficiently simulate $U(1)$ symmetric systems, we need to modify the MPS formalism \cite{huang2019simulating,guo2019matrix,oh2021classical}.

We denote the total number of particles to the right of position $k$ corresponding to bond $\alpha_k$ as $c_{\alpha_k}^{[k]}$, then the probability amplitude tensor can be expressed as
\begin{align}
    c_{i_1,\dots,i_M} = \sum_{\alpha_0,\dots,\alpha_M=0}^{\chi-1} &\Gamma_{\alpha_0\alpha_1}^{[1]}\lambda_{\alpha_1}^{[1]}\Gamma_{\alpha_1\alpha_2}^{[2]}\dots
    \lambda_{\alpha_{M-1}}^{[M-1]}\Gamma_{\alpha_{M-1}\alpha_M}^{[M]}\nonumber\\
    \prod_{k=1}^{M}&\delta\left(c_{\alpha_{k-1}}^{[k-1]}-c_{\alpha_k}^{[k]}-i_k\right).
\end{align}
The $\delta$ function essentially determines the correct local particle number based on the charge value difference. Updating the wavefunction according to the unitary can be done with the following procedure. We first realize that a local two-site update does not change the charges at $k-1$ or $k+1$, and we can therefore compute the results for different resulting values of $c^{[k]}$. For each chosen value of $c^{[k]}$, $c^{[k-1]}\geq c^{[k]}$ and $c^{[k+1]}\leq c^{[k]}$. We can select a subset of bonds $\alpha_{k-1}\in\mathcal{A}_{k-1},\alpha_k\in\mathcal{A}_{k},\alpha_{k+1}\in\mathcal{A}_{k+1}$ that satisfy the conditions on the three charges. We can then obtain the $\Theta$ tensor similar to the normal MPS algorithm:
\begin{align}
    &\Theta_{\alpha_{k-1}\alpha_{k+1}}(c^{[k]})=\nonumber\\
    &\sum_{\substack{i_k,i_{k+1}=0\\j_k,j_{k+1}=0}}^{d-1}\sum_{\alpha_k\in\mathcal{A}_k}
    U_{j_k,j_{k+1}}^{i_k,i_{k+1}}\lambda_{\alpha_{k-1}}^{[k-1]}\Gamma_{\alpha_{k-1}\alpha_k}^{[k]}\lambda_{\alpha_k}^{[k]}\Gamma_{\alpha_k\alpha_{k+1}}^{[k+1]}\lambda_{\alpha_{k+1}}^{[k+1]}\nonumber\\
    &\times\delta\left(c_{\alpha_{k-1}}^{[k-1]}-c_{\alpha_k}^{[k]}-j_k\right)\delta\left(c_{\alpha_{k}}^{[k]}-c_{\alpha_{k+1}}^{[k+1]}-j_{k+1}\right)\nonumber\\
    &\times\delta\left(c_{\alpha_{k-1}}^{[k-1]}-c^{[k]}-i_k\right)\delta\left(c^{[k]}-c_{\alpha_{k+1}}^{[k+1]}-i_{k+1}\right)\label{theta},
\end{align}
where $0\leq c^{[k]}\leq N$. Once again, the $\delta$ function determines the correct local particle number from charge differences and tells us which entry of the unitary matrix to look up. Singular value decompositions are then performed on each $\Theta(c^{[k]})$, and the largest $\chi$ singular values out of all the singular values for all $\Theta(c^{[k]})$'s and their corresponding bonds are retained.

This approach considerably reduces computational complexity. First, examining the $U(1)$ symmetric MPS tells us that the $\Gamma$ tensors lost their $i$ indices corresponding to the physical degree of freedom (local particle number), reducing the memory complexity by a factor of $d$. This is instead captured by the size $\chi$ 1-d charge tensors $c$. Second, the size of the $\Theta$ matrices that we decompose with SVD is also reduced to at most $\chi\times\chi$ instead of $\chi d\times\chi d$. The fact that SVD is performed on individual $\theta$ matrices for different $c^{[k]}$ instead of a single big $\theta$ matrix also reduces the computational cost.

%Our work is structured as follows: in Section \ref{Systems with U(1)}, we begin with a brief overview of systems that exhibit $U(1)$ symmetry. We follow this with an introduction to the conventional matrix product state algorithm, which is a well-known tensor network algorithm, in Section \ref{Matrix Product State}. We then discuss how $U(1)$ symmetry is exploited to make our simulation more efficient in Section \ref{MPS with U(1)}. We follow this discussion with details of the supercomputer implementation in Section \ref{Implementation Details}. Finally, we provide numerical evidence of the efficiency of our approach in Section \ref{Results}.

%\section{Systems with $U(1)$ symmetry}\label{Systems with U(1)}



%\section{Matrix Product State}\label{Matrix Product State}



%\section{Implementation Details}\label{Implementation Details}

\section{Results}

State-of-the-art simulations using tensor networks typically employ hardware acceleration, including the use of novel hardware platforms such as graphical processing units (GPUs) \cite{nguyen2022tensor,lyakh2022exatn,lykov2021performance, lykov2022tensor}. Due to the specialized nature and the complex data movement patterns of symmetry-preserving tensor network algorithms \cite{huang2019simulating,singh2011tensor,guo2019matrix}, no highly optimized hardware acceleration is readily available. We provide an efficient GPU implementation of the $U(1)$ symmetric tensor network algorithm, achieving significant computational speed-up over the CPU-based implementation. Further, our algorithm is highly parallel and fully capable of utilizing parallel resources of supercomputing clusters.

It is hard to improve SVD as it is a well-researched and optimized routine. The naive implementation of computing $\Theta$ also requires looping over all possible values of $c^{[k-1]}$ and $c^{[k+1]}$, which introduces an additional $O(d^2)$ complexity compared to SVD. Therefore, we focus our discussion on the $\Theta$ computation subroutine and how we optimize it.

\subsection{CPU implementation}

For a given center charge $c^{[k]}$, the CPU-based implementation loops through all possible left and right charge values $c^{[k-1]}$ and $c^{[k+1]}$ and selects a subset of left and right bonds $\alpha_{k-1}$ and $\alpha_{k+1}$ that satisfy the charge requirement. Since $c^{[k]}$ is fixed for each $\Theta(c^{[k]})$ submatrix, the only term that the delta function affects given the charges is $U$ through $j_k, j_{k+1}, i_k, i_{k+1}$. Each iteration of the loop can then simply choose the correct entry of $U$, which takes care of the sum over the $i,j$ indices, and the rest of the sum is only over $\alpha_k$. After summing over $\alpha_k$, the matrix $\Theta(c^{[k]})$ is partially filled at bonds $\alpha_{k-1},\alpha_{k+1}$. Iterating over all possible left and right charges fills the entire matrix.

This nested loop implementation is very inefficient for large total particle number $d$. However, without the $U$ and $\lambda$ value lookup, this is exactly the same as matrix multiplication, which is dramatically sped up by GPUs. GPUs calculate entries of all $\alpha_{k-1}$ and $\alpha_{k+1}$ indices simultaneously in matrix multiplication, and we can use the same principle with modifications to take into account $U$ and $\lambda$ value lookup. The differences between the CPU and GPU implementations are illustrated in Fig. \ref{Theta}.

\begin{figure} [ht]
   \begin{center}
   \includegraphics[width=8cm]{Theta.pdf}
   \end{center}
   \caption{Algorithms for computing $\Theta$ matrices. (a) CPU-based implementation. A subset of bonds are selected from $\Gamma^{[k]},\Gamma^{[k+1]}$ that have the correct selected charge values $c^{[k-1]}, c^{[k+1]}$. A subset of $\Theta$ is computed. (b) GPU-based implementation. All bonds are used and the entire $\Theta$ matrix is computed at once.}
   { \label{Theta}
}
   \end{figure}

\subsection{Hierarchical GPU implementation}

If each thread computes one entry of $\Theta$, there is still much more data movement than computation per thread. In fact, memory bandwidth is a significant limiting factor in this case, and the computation gets starved by a lack of data. This issue is well addressed in optimized matrix multiplication kernels and tensor core operations, and we follow a similar approach to address this issue. For a pedagogical introduction to the hierarchical approach in the context of matrix multiplication, see the work by Kerr {\sl et. al.} \cite{kerr}

Consider an $M\times K$ matrix $A$ multiplying a $K\times N$ matrix $B$, both are stored in the \textit{global memory}, the memory \textit{every thread can access}. If each GPU thread computes one entry, the naive way is to make thread $i,j$ add $A_{i,k}B_{k,j}$ $K$ times through all $k$. In this algorithm, each thread requires $2K$ global reads, and the whole algorithm requires $2MNK$ global reads. However, the bandwidth for global memory access is low, limiting the performance.

\textit{Shared memory} is the memory that threads in a \textit{thread block} can access, and it is much faster than global memory. A block is a collection of (at most 2048) threads, and threads in a block can cooperate by sharing data through the shared memory. If a whole row/column of $A/B$ is saved in the shared memory by $M+N$ global reads, all the threads can accumulate $A_{i,k}B_{k,j}$ once by $2MN$ shared memory reads. If this is repeated $K$ times through all $k$, we would only need $K(M+N)$ global reads and $2MNK$ shared memory reads. In short, we can replace element-wise inner products with the accumulation of outer products to reduce the memory read requirement, and Fig. \ref{matmul} illustrates the differences between the two approaches. In reality, since a thread block has a limited number of threads and shared memory, we cannot fit everything in a single block and must compute the entire output matrix by sub-blocks.

\begin{figure} [ht]
   \begin{center}
   \includegraphics[width=8cm]{matmul.pdf}
   \end{center}
   \caption{Matrix multiplication with (a) inner products and (b) outer products.}
   { \label{matmul}
}
   \end{figure}

A similar approach of shifting the need for high shared memory reads to faster memory access can be achieved. We can break each block into a \textit{warp tile}, and a warp into a \textit{thread tile}. Each thread is responsible for multiple indices, a \textit{fragment} of the matrix, instead of just one element. This allows data to be stored in \textit{registers}, which are private to each thread and much faster than shared memory.

We adopt all aforementioned techniques in our GPU kernel for obtaining $\Theta(c^k)$, with the added complexity of complex number support and $U$ matrix value look-up based on charges. Software pipelining in standard matrix multiplication kernels is also implemented to hide data movement latency.

\subsection{Memory alignment in GPU implementation}

The charge data-dependent access of $U$ poses difficulties in efficient GPU parallelization. Normally, parallel threads over which computational load is distributed read and write data to memory locations in an \textit{aligned} manner. Alignment means consecutive threads read and write to consecutive memory addresses, which allows data to be sent in chunks rather than one address at a time. If we distribute the computation of each bond index of $\Theta$ over each thread, it will be completely unpredictable which address of $U$ the thread has to read since it depends on the charge of the bond, and aligned memory access is impossible.

To address this issue, we propose to sort the bonds according to their charges before GPU computation. This leads to aligned memory access as illustrated in Fig. \ref{sort} and significantly improves performance. Additionally, since thread-level tiling requires each thread to compute for multiple indices/bonds, each thread can potentially encounter multiple charge values even after sorting the bonds by charge. This rapidly increases the number of registers needed per thread, which is a limited resource. Therefore, we insert empty bonds to ensure that the charges only change in multiples of the fragment dimension, ensuring that only one value of the unitary matrix corresponding to a single charge $c$ and physical state $i$ value is stored per thread. This scheme is illustrated in Fig. \ref{alignment}.

\begin{figure} [ht]
   \begin{center}
   \includegraphics[width=8cm]{sort.pdf}
   \end{center}
   \caption{Memory access pattern (a) without sorting and (b) with sorting.}
   { \label{sort}
}
   \end{figure}

\begin{figure} [ht]
   \begin{center}
   \includegraphics[width=8cm]{alignment.pdf}
   \end{center}
   \caption{Illustration of insertion of empty bonds. (a) Worst case scenario of charge value changes within a single fragment without empty bond insertion. The thread has to store 16 values of the unitary. (b) Generic case of a fragment at a charge change boundary. Less than 16 values need to be stored, but this is not known \textit{a-priori} and 16 values of the unitary still needs to be stored. (c) With empty bond insertion, each thread only needs one unitary value.}
   { \label{alignment}
}
   \end{figure}
   
Additionally, bond indices are sorted such that $c_{\alpha_k}^{[k]}$ only increases as the bond index increases. For small $d$, this means that $c_{\alpha_k}^{[k]}$ is the same for many consecutive indices. This eliminates the need for threads to look up new $U$ elements, except at boundaries where $c_{\alpha_k}^{[k]}$ changes. This further reduces the need for memory access and reduces latency.


\subsection{High-level parallelization}
Besides the numerical parallelization of individual SVD and $\Theta$ matrix computations through the use of GPUs, additional parallelization is explicitly implemented on the algorithmic level. Further, for systems with large bond dimensions, storing the entire tensor network on a single-GPU or even a single node may become prohibitive. We distribute the storage of individual $\Gamma$ tensors to different nodes.

First, we parallelize independent two-site unitary updates. A host node identifies all parallel local unitary updates and keeps track of a list of available and busy nodes. Local unitary updates are allocated as soon as a node is available. During allocation, the compute process of the computational node requests the needed $\Gamma,\lambda,c$ tensors from the storage processes of the corresponding storage nodes. Similar communication takes place after the computation to update the stored tensors.

Second, for a single beam splitter MPO update, the overall $\Theta$ matrix is broken up into $\Theta(c^{[k]})$'s. We can compute different $\Theta(c^{[k]})$'s and perform SVD on them in parallel, then consolidate the results at the end. After the computation node receives the data needed, the data needed for each $\Theta(c^{[k]})$ is distributed to individual GPUs.

With the high-level parallelization discussed above and illustrated in Fig. \ref{parallel}, the algorithm can be easily scaled to supercomputers with multiple nodes and GPUs, especially when the system size is large. However, there are smaller systems that do not require multi-node parallelization, and we provide implementations with intermediary parallelism as well to avoid the communication overhead of the fully parallel algorithm. On the lowest level, only one GPU is considered, and no distributed memory or computation is used. On the second level, all memory is managed by a single node, and unitary updates are distributed to individual GPUs instead of nodes.

\begin{figure} [ht]
   \begin{center}
   \includegraphics[width=8cm]{parallel.pdf}
   \end{center}
   \caption{High-level parallelization. Independent unitary gate updates are distributed to different nodes. Within each unitary update, $\Theta(c^{[k]})$'s are computed and decomposed with SVD independently on different GPUs.}
   { \label{parallel}
}
   \end{figure}

\subsection{Run time reduction}\label{Results}

We evaluate the performance of our GPU supercomputing algorithm against the CPU-only implementation at the Argonne Leadership Computing Facility
(ALCF). All CPU simulations are performed with a single node of the Bebop system with a 2.10 GHz Intel Xeon E5-2695v4 32-core CPU, and GPU simulations are performed on the Polaris system. A single node of the Polaris system has 4 Nvidia A100 GPUs. Table \textrm{I} shows the simulation time in seconds of different implementations for a lossy boson sampling experiment with 12 modes, 10 input squeezed modes, bond dimension 1024 and 8192, photon loss rate 0.55, and local Hilbert space dimension 15. Increasing the bond dimension $\chi$ increases the simulation accuracy and time. Moreover, lossy boson sampling requires the density matrix instead of the state vector, and the generalized algorithm is described in detail in by Oh {\sl et. al.} \cite{oh2021classical} The consequence of the density matrix generalization is that each charge can take on $15^2=225$ values instead of only $15$, which means that the CPU-based algorithm needs to perform $225^2=50625$ iterations to fill the $\Theta$ matrix. On the other hand, our GPU algorithm computes all entries of $\Theta$ in parallel.

For the small $\chi$ experiment, we ar able to simulate using only CPUs in a reasonable amount of time for comparison. Encouragingly, the single-GPU algorithm achieves a dramatic 63-time speedup even with a single-GPU. We further test the unitary-level parallel algorithm on one node and observe a further two-fold speedup. Lastly, we use the fully parallel algorithm on 6 nodes, observing an additional 43\% increase in the computational speed. We observe that the gain in computational speed by switching from less parallelized to highly parallelized implementation is less than the increase in computational resources. Higher-level parallelism incurs significant overhead, which indicates that there is still significant room for optimization.

Fortunately, this payoff in higher parallelism is more pronounced in the setting of larger system sizes. The CPU implementation failed to complete the simulation within the maximum allowed wall time of $72$ hours. This means that our single-GPU implementation achieves at least a 125-fold speed up. The computational time is further reduced two-fold when going from the single-GPU implementation to the unitary-level parallel algorithm on one node, similar to the small bond dimension case. However, changing to the fully parallelized algorithm with 6 nodes further reduces the time more than three-fold compared to a fractional reduction in the small bond dimension case. Overall, the fully parallel implementation on six nodes is on the order of a 1000 times faster than the 32-core CPU implementation.

\begin{center}
\begin{tabular}{ |c|c|c|c|c| }
 \hline
 & CPU & single-GPU & One node & Six nodes \\ 
 \hline
$\chi=1024$ & 7966 & 126 & 60 & 42 \\
 \hline
 $\chi=8192$ & >259000 & 2066 & 1045 & 322 \\
 \hline

\end{tabular}
\captionof{table}{Simulation time in seconds.}
\end{center}

\section{Discussion}

We have shown that our GPU supercomputer algorithm dramatically speeds up $U(1)$ symmetric tensor network calculations through GPU-level and software-level parallelism. Specifically, we demonstrated greater than 125-fold speed up compared to the 32-core CPU implementation with a single-GPU, and a total speed up on the order of 1000 times when more resources are used. We believe that this tool will be especially valuable to the quantum many-body physics community due to its computational efficiency. Further, the formalism of tensor networks beyond MPS with other types of symmetry has already been developed \cite{singh2010tensor}, and adaptation of our approach to accelerating these computational tools might be possible with additional theoretical and engineering research. Lastly, with the advent of exascale supercomputing such as the Aurora supercomputer, and hardware platform independent programming models such as SYCL and oneAPI, a new era of accelerated supercomputing tensor network algorithms for quantum physics holds a tremendous amount of promise. Overall, our algorithm opens up the possibility of simulating large many-body quantum systems that are $U(1)$ symmetric, which include a wide range of interesting systems including the Bose Hubbard model, spin systems, boson sampling, and quantum walk.

\section*{Data availability}
There is not data generated from this work.

\section*{Code availability}
The code described in this work is available in the GitHub repository \url{https://github.com/sss441803/BosonSampling}.

\section*{Acknowledgment}
This research has been supported by and has used the resources of the Argonne Leadership Computing Facility, which is a U.S.~Department of Energy (DOE) Office of Science User Facility supported under Contract DE-AC02-06CH11357. Y.
~A.~acknowledges support from the U.S. Department of Energy, Office of Science, under contract DE-AC02-06CH11357 at Argonne National Laboratory and Defense Advanced Research Projects Agency (DARPA) under Contract No. HR001120C0068. L.~J.~acknowledges support from the the ARO (W911NF-23-1-0077), ARO MURI (W911NF-21-1-0325), AFOSR MURI (FA9550-19-1-0399, FA9550-21-1-0209), AFRL (FA8649-21-P-0781), DoE Q-NEXT, NSF (OMA-1936118, ERC-1941583, OMA-2137642), NTT Research, and the Packard Foundation (2020-71479). J.~L.~is supported in part by International Business Machines (IBM) Quantum through the Chicago Quantum Exchange, and the Pritzker School of Molecular Engineering at the University of Chicago through AFOSR MURI (FA9550-21-1-0209). M.~L.~acknowledges support from DOE Q-NEXT. C.~O.~acknowledges support from the the ARO (W911NF-23-1-0077), ARO MURI (W911NF-21-1-0325), AFOSR MURI (FA9550-19-1-0399, FA9550-21-1-0209), AFRL (FA8649-21-P-0781), DoE Q-NEXT, NSF (OMA-1936118, ERC-1941583, OMA-2137642), NTT Research, and the Packard Foundation (2020-71479).

\bibliography{main.bib}

\end{document}