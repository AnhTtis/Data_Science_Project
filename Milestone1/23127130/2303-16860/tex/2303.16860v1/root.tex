%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

% \documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.
% \usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{algorithmic}
\usepackage{multirow,bigdelim}
\usepackage{subfigure}
\usepackage{soul}
% \usepackage{mathtools}
\usepackage[framemethod=tikz]{mdframed}
\usepackage{todonotes}
\usepackage{balance}

\def\pink#1{{\color{pink}#1}}
\newtheorem{defa}{Definition}
\newtheorem{prom}{Problem}
\newtheorem{ex}{Example}
\newtheorem{asm}{Assumption}
\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}
\newtheorem{col}{Conclusion}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{\LARGE \bf
Physical Deep Reinforcement Learning Towards Safety Guarantee
}


\author{Hongpeng Cao$^{1}$, Yanbing Mao$^{2}$, Lui Sha$^{3}$, Marco Caccamo$^{1,4}$ % <-this % stops a space
% \thanks{*This work was not supported by any organization}% <-this % stops a space
\thanks{$^{1}$ Hongpeng Cao is with School of engineering and design, Technical University of Munich, Munich, 85748, Germany
        {\tt\small cao.hongpeng@tum.de}}%
\thanks{$^{2}$ Yanbing Mao is with Engineering Technology Division, Wayne State University, Detroit, MI 48201, USA
        {\tt\small hm9062@wayne.edu}}%
\thanks{$^{3}$ Lui Sha is with Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801, USA {\tt\small lrs@illinois.edu}}%
\thanks{$^{1, 4}$ Marco Caccamo is with School of Engineering and Design, Technical University of Munich (TUM), Munich, Germany and Munich Institute of Robotics and Machine Intelligence, Technical University of Munich (TUM), Munich, Germany. {\tt\small mcaccamo@tum.de}
}
}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Deep reinforcement learning (DRL) has achieved tremendous success in many complex decision-making tasks of autonomous systems with high-dimensional state and/or action spaces. However, the safety and stability still remain major concerns that hinder the applications of DRL to safety-critical autonomous systems. To address the concerns, we proposed the Phy-DRL: a physical deep reinforcement learning framework. The Phy-DRL is novel in two architectural designs: i) Lyapunov-like reward, and ii) residual control (i.e., integration of physics-model-based control and data-driven control). The concurrent physical reward and residual control empower the Phy-DRL the (mathematically) provable safety and stability guarantees. Through experiments on the inverted pendulum, we show that the Phy-DRL features guaranteed safety and stability and enhanced robustness, while offering remarkably accelerated training and enlarged reward.  
\end{abstract}

\input{introduction}

\input{preliminary}

\input{experiment}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\input{appendix}

\bibliographystyle{ieeetr}
\bibliography{ref}

\end{document}
