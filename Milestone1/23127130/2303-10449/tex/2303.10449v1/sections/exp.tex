\section{Experiments}\label{sec:exp}

\begin{table*}[btp!]
\renewcommand{\arraystretch}{1.}
\renewcommand{\tabcolsep}{8.pt}
\centering
\small
\caption{\textbf{Comparison between the previous SOTA methods and ours on the two SCOOD benchmarks.} We report the averaged values on 6 OOD datasets and detailed results are shown in Appendix. $\uparrow$/$\downarrow$ indicates higher/lower value is better. The best results are in \textbf{bold}.}
\label{T:Results}
\begin{tabular}{cc|ccc|cccc}
\toprule
\multirow{2}{*}{Benchmarks} 
& \multirow{2}{*}{Method} 
& \multirow{2}{*}{FPR95~$\downarrow$} 
& \multirow{2}{*}{AUROC~$\uparrow$} 
& \multirow{2}{*}{AUPR-In/Out~$\uparrow$}
& \multicolumn{4}{c}{CCR@FPR~$\uparrow$} \\ 
\cmidrule(lr){6-9}
& && && $10^{-4}$  & $10^{-3}$  & $10^{-2}$ & $10^{-1}$                      \\ \midrule
\multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}CIFAR-10\\ Benchmark\end{tabular}}
& ODIN~\cite{odin}         &  52.00 & 82.00 & 73.13~/~85.12 & 0.36 & 1.29& 	6.92    & 39.37 \\ 
& EBO~\cite{energyood}      &  50.03 &	83.83 &	77.15~/~85.11 & 0.49	& 1.93	&9.12	&46.48 \\
& OE~\cite{hendrycks18oe}  & 50.53	& 88.93	& 87.55~/~87.83	& 13.41	& 20.25	& 33.91	& 68.20 \\
& MCD~\cite{mcd}           &73.02&	83.89&	83.39~/~80.53&	5.41&	12.3&	28.02&	62.02  \\
& UDG\cite{yang2021semantically}   & 36.22 & 93.78 & 93.61~/~92.61 & 13.87  & 34.48 & 59.97 & 82.14 \\
& \textbf{Ours}     & \textbf{8.53} & \textbf{96.47} & \textbf{97.10}~/~\textbf{95.65}  &  \textbf{40.31} & \textbf{63.95} & \textbf{77.35} & \textbf{86.27}          \\ 
\midrule
\multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}CIFAR-100\\ Benchmark\end{tabular}}
& ODIN~\cite{odin}        &81.89	&77.98	&78.54~/~72.56	&1.84	&5.65	& 17.77	& 46.73 \\
& EBO~\cite{energyood}    &81.66	&79.31	&80.54~/~72.82	&2.43	&7.26	& 21.41	& 49.39 \\
& OE~\cite{hendrycks18oe} &80.06	&78.46	&80.22~/~71.83	&2.74	&8.37	& 22.18	& 46.75	\\
& MCD~\cite{mcd}          & 85.14	&74.82	&75.93~/~69.14  &1.06   & 4.60  & 16.73 & 41.83 \\
& UDG~\cite{yang2021semantically}   & 75.45 & 79.63  & 80.69~/~74.10  &  3.85  & 8.66 &  20.57 &  44.47           \\ 
& \textbf{Ours}     & \textbf{41.05} & \textbf{82.44}  & \textbf{84.37}~/~\textbf{76.47}  &  \textbf{11.70}  & \textbf{19.47} &  \textbf{34.05} &  \textbf{50.97}   \\ 
\bottomrule
\end{tabular}
% \vspace{-0.20em}
\end{table*}


\subsection{Benchmarks} We evaluate our method on the realistic SCOOD benchmarks~\cite{yang2021semantically} proposed recently. SCOOD benchmarks contain two benchmarks: CIFAR-10 benchmark and CIFAR-100 benchmark which regard CIFAR-10 and CIFAR-100~\cite{cifar} as the labeled set $D_L$, respectively. Tiny-ImageNet~\cite{tinyImageNet} mixed with ID and OOD data is utilized as extra unlabeled training set $D_U$ on SCOOD benchmarks. In test time, CIFAR-100 is used as one of the OOD datasets for CIFAR-10 benchmark while CIFAR-10 is included in the OOD set of CIFAR-100 benchmark. Additionally, five other datasets including Texture~\cite{texture}, SVHN~\cite{svhn}, Tiny-ImageNet~\cite{tinyImageNet}, LSUN~\cite{lsun} and Places365~\cite{places365} are collected to form the complete test set $T$ of the two benchmarks, which contain both ID and OOD samples. SCOOD benchmarks re-split these samples into $T^I$ and $T^O$ according to their true semantics. 


\subsection{Evaluation Metrics.} Following UDG~\cite{yang2021semantically}, we use five metrics to evaluate the performance of our method. 
\textbf{FPR@TPR95$\%$} presents the ratio of falsely identified OOD when most (\textit{i.e.}95$\%$) ID samples are correctly recognized.
\textbf{AUROC} is the area under the receiver operating characteristic curve, evaluating the OOD detection performance.
\textbf{AUPR-In/Out} calculates the area under the precision-recall curve. AUPR-In/OUT denotes ID/OOD samples as positive.
\textbf{CCR@FPR$n$} shows classification accuracy when the ratio of falsely identified OOD equals $n$, which can evaluate ID classification and OOD detection capability simultaneously.

\begin{table}[btp!]
\renewcommand{\arraystretch}{1.}
\renewcommand{\tabcolsep}{1.pt}
\small
% \setlength{\abovecaptionskip}{-0.00cm} 
\caption{\textbf{Ablation study on CIFAR-10 benchmark.} We take UDG~\cite{yang2021semantically} as baseline method. Our completed method combining ET and $L_{rep}$ is written as `Ours' for short. All experiments are tested in the T-energy score mentioned in~\cref{subsec: OOD metric} for fair comparisons. For brevity, we refer to each experiment by its index.}
\label{T:Ablation}
\centering
\begin{tabular}{c|c|cccc}
\toprule
& Strategy & FPR95~$\downarrow$ & AUROC~$\uparrow$ & AUPR-In/Out~$\uparrow$ & ACC~$\uparrow$ \\  \midrule
1: & UDG \cite{yang2021semantically}  & 21.57 & 92.44 & 91.70~/~92.12  & 92.28  \\
2: & UDG + $L_{rep}$  & 17.75 & 94.77 & 94.80~/~93.13 & 93.07\\
3: & ET     &  11.39 & 96.05 & 96.18~/~94.57 & 93.40    \\ 
4: & \textbf{Ours}  & \textbf{8.53} & \textbf{96.47} & \textbf{97.10}~/~\textbf{95.65} &  \textbf{93.71}           \\ 
\bottomrule
\end{tabular}
% \vspace{-0.3em}
\end{table}

\begin{figure}[t]
\centering
\begin{overpic}[width=0.99\linewidth]{fig/num.pdf}
 \put(50,2){\textbf{\footnotesize{Epochs}}}
  \put(2, 26){\rotatebox{90}{\footnotesize\textbf{Num}}}
\end{overpic}
% \setlength{\abovecaptionskip}{-0.5cm} 
\vspace{-6pt}
\caption{\textbf{The number of accurately assigned labels during training in EXP$\#1$ \mbox{--} $\#4$} shows that the ET has a significant improvement over IDF strategy in assigning exact labels to unlabeled ID samples, and $L_{rep}$ can further increase this advantage. EXP$\#1$ is the UDG baseline, EXP$\#2$ introduces the $L_{rep}$ into UDG, EXP$\#3$ is the proposed ET alone, and EXP$\#4$ is the complete version of our method.}
\vspace{-4pt}
\label{Fig:num}
\end{figure}

\subsection{Results on SCOOD Benchmarks} We compare the results of our proposed approach with the previous state-of-the-art (SOTA) OOD detection methods in \cref{T:Results}. OIDN~\cite{odin} and EBO~\cite{energyood} do not require extra unlabeled training data, and OE~\cite{hendrycks18oe}, MCD~\cite{mcd}, and UDG~\cite{yang2021semantically} use Tiny-ImageNet as unlabeled training data $D_U$. All experiments use ResNet-18~\cite{resnet}. We only report the average metric values on 6 OOD test datasets for each benchmark limited by space. Results show that our proposed uncertainty-aware optimal transport scheme consistently obtains the best results across all metrics, especially FPR@95 is significantly improved on both benchmarks. In particular, although MCD~\cite{mcd} introduces extra unlabeled training data and achieves satisfying results across traditional OOD benchmarks, its maximization of the entropy discrepancy between ID/OOD samples makes the model pay excessive attention to the low-level covariate shifts, which eventually leads to limited generalization in other OOD sources and failure on the SCOOD task.


\subsection{Ablation Study and Qualitative Analysis}

\textbf{Effectiveness of uncertainty-aware optimal transport scheme.}  Here we analyze the effect of each major component, including the energy-based transport (ET) mechanism and inter-cluster extension strategy $L_{rep}$ in \cref{T:Ablation}. EXP$\#1$ is the UDG~\cite{yang2021semantically} method which we use as the baseline, and then we introduce the $L_{rep}$ into UDG to carry out EXP$\#2$. To evaluate the effectiveness of the proposed ET, we replace the IDF strategy in UDG with ET and implement EXP$\#3$, and EXP$\#4$ which combines ET with the $L_{rep}$ is the complete version of our method.

From the comparison between EXP$\#2$ and EXP$\#1$, it can be seen when $L_{rep}$ is introduced in UDG and combined with IDF strategy~\cite{yang2021semantically} based on K-means clustering, the result is improved compared with the baseline. It is intuitive that an enhanced feature representation produced by $L_{rep}$ increases the ID/OOD discrepancy and facilitates clustering-based label assignment in the feature space. However, limited by the non-robust feature distance to covariate shifts and lacking the practical guidance in clustering task, simply applying $L_{rep}$ in SCOOD fails to overcome the impact of covariate shift, so the IDF strategy still has shortcomings in extracting ID semantics from the unlabeled set, as proved in \cref{Fig:num}. When we replace the IDF strategy with the ET based on the energy uncertainty and implement the Exp$\#3$, the result shows that the OOD detection ability is enhanced by a large margin, as FPR@95 gets a significant 10.18$\%$ improvement than baseline. After combining ET and $L_{rep}$, the results of EXP$\#4$ show that the performance of the model is at its best when obtaining a more discriminative uncertainty derived from a enhanced representation to promote the discrimination of inter-cluster distribution. In \cref{Fig:num} we also report the comparison among EXP$\#1$ \mbox{--} $\#4$ in the number of accurately assigned labels, we can see from where both the ET and $L_{rep}$ have brought apparent ascension in the aspect of increasing the accuracy of the label assignment. Combined with the results in \cref{T:Ablation} and \cref{Fig:num}, it is again demonstrated that more accurate semantic label assignment during training will promote the performance of the model, since the model benefits from exploring the semantic discrepancy and knowledge hidden in the unlabeled set more sufficiently.

% Additionally, a significant 6.36$\%$ increase on FPR@95 benefit from ET alone compared to EXP$\#2$ with the assistance of $L_{rep}$, which further embodies the superiority of ET. 


In summary, the performance of the model boosts mainly due to the contribution of ET, which provides effective guidance for the cluster distribution of samples based on semantics via energy metric. Then $L_{rep}$ further enlarges the advantages over baseline by providing a more discriminate energy metric between ID/OOD.


\begin{figure}[t]
\centering
% \setlength{\abovecaptionskip}{-0.03cm} 
\begin{overpic}[width=0.99\linewidth]{fig/fig5_00.pdf}
\put(10.5, 50){\footnotesize{(a) Distance vs Energy distributions of `automobile' images}}
% \put(15, 48){\footnotesize{ distributions of ‘automobile’ images from two datasets}}
  \put(15, 4){\footnotesize{(b) Distance vs Energy distributions of `bird' images}}
  % \put(23, 2){\footnotesize{distributions of ‘bird’ images from two datasets}}
\end{overpic}
\vspace{-8pt}
\caption{\textbf{The effectiveness of energy metric.} In `automobile' and `bird' classes, the energy metric still maintains better consistency with the interference of covariate shifts. CIFAR and TIN denote CIFAR-10 and Tiny-ImageNet datasets, respectively.}
\label{Fig:consistency}
% \vspace{2pt}
\end{figure}


\begin{table}[t]
\centering
\renewcommand{\arraystretch}{1.}
\renewcommand{\tabcolsep}{4.pt}
\small
% \setlength{\abovecaptionskip}{-0.01em}
    \vspace{-6pt}
    \caption{\textbf{The effectiveness of energy in ET.} V-OT and En-OT denotes the methods introducing \emph{variance} and \emph{entropy} as uncertainty like ET, respectively. The performance of our proposed ET outperforms the two methods on all metrics.}
    \label{T:OT}
    \begin{tabular}{c|cccc}
    	\toprule
    	 & FPR95~$\downarrow$ & \footnotesize{AUROC~$\uparrow$} & \footnotesize{AUPR-IN/OUT~$\uparrow$} & \footnotesize{ACC~$\uparrow$} \\
    	\midrule
    	V-OT                   & 13.46 & 96.11 & 96.70~/~95.43 & 93.15 \\
    	En-OT                 & 10.94 & 95.86 & 96.75~/~94.67 & 93.10 \\
    	\textbf{ET}             & \textbf{8.53} & \textbf{96.47} & \textbf{97.10}~/~\textbf{95.65} &  \textbf{93.71}   \\
    	\bottomrule
    \end{tabular}
    \vspace{-4pt}
\end{table} 

\textbf{The consistency and effectiveness of energy metric in ET.} 
In this work, we propose the energy-based transport (ET) mechanism to explore the semantic discrepancy and knowledge hidden in the unlabeled set more sufficiently. 
Here, we first demonstrate the robustness of the energy metric to covariate shifts on more classes. We employ a model trained only with CIFAR-10 to output the minimum Euclidean distance and energy distributions for samples belonging to the same class but from different datasets (\textit{e.g., }CIFAR-10 and Tiny-ImageNet). Except for the distributions of the `dog' images shown in the histograms of \cref{fig:motivation}, we perform the same experiment with the `automobile' and `bird' images and report the distribution difference in \cref{Fig:consistency}. In `automobile' and `bird' categories, the energy metric still better overcomes the interference of the covariate shifts and maintains the consistence of the semantic compared with feature distance. Afterward, we consider other commonly-used uncertainty metrics to replace the energy metric, including the \emph{variance} and \emph{entropy} of samples over cluster distribution, and replace the energy metric in ET with them to guide label assignment. The result in \cref{T:OT} indicates that our proposed ET outperforms both methods based on other uncertainty, confirming the effective guidance of energy in the assignment process.


\textbf{Effectiveness of extra data and classification accuracy decay.}
The comprehensive survey~\cite{yang2021generalized} indicates that extra data generally promotes the OOD detection performance of models, but the classification performance of classification-based OOD detection methods will inevitably decrease due to the interferences of OOD samples. To explore the impact of the extra training data on the performance of OOD detection and ID classification, we first evaluate the model only trained on CIFAR-10 with standard cross-entropy loss (CE loss) and then introduce Tiny-ImageNet as extra unlabeled training data and implement EXP$\#2$ \mbox{--} $\#4$. The results are reported in \cref{T:Extra Data}.

\begin{table}[t]
\centering
\renewcommand{\arraystretch}{1.}
\renewcommand{\tabcolsep}{1.pt}
    \small
    \caption{\textbf{The impact of extra training data.} EXP$\#1$ uses a model trained only on CIFAR-10 (CIFAR) with CE loss, while EXP$\#2$ \mbox{--} $\#4$  introduce Tiny-ImageNet (TIN) as extra unlabeled data and distinguish unlabeled ID/OOD samples in training. Extra training data consistently promotes the OOD detection performance but also brings a drop to classification accuracy (ACC). Our method (including both ET and $L_{rep}$, written as `Ours' for short) minimizes the degradation on ACC.}
    \label{T:Extra Data}
    \centering
    \begin{tabular}{c@{\hskip 8pt}l|@{\hskip 1pt}c@{\hskip 1pt}c@{\hskip 1pt}c@{\hskip 1pt}@{\hskip 1pt}c}
    	\toprule
    	$D$ & Strategy & \footnotesize{FPR95~$\downarrow$} & \footnotesize{AUROC~$\uparrow$} & \footnotesize{AUPR-IN/OUT~$\uparrow$} & \footnotesize{ACC~$\uparrow$} \\
    	\midrule
    	{\footnotesize{CIFAR}}     
    	& 1: CE loss  & 34.96 & 85.72 & 84.58~/~83.24 & 94.94   \\
    	\midrule
    	\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}\footnotesize{CIFAR}\\\footnotesize{+}\\\footnotesize{TIN}\end{tabular}}
    	& 2: UDG\cite{yang2021semantically}   & 21.57 & 92.44 & 91.70~/~92.12  & 92.28  \\
    	&  3: ET                     &  10.21 & 96.25 & 96.92~/~94.76 & 93.48  \\
    	& 4: \textbf{Ours}    & \textbf{8.53} & \textbf{96.47} & \textbf{97.10}~/~\textbf{95.65} &  \textbf{93.71}  \\
    	\bottomrule
    \end{tabular}
    % \vspace{-1.5pt}
\end{table}

By comparing EXP$\#2$ \mbox{--} $\#4$ and EXP$\#1$, we can see when the model is exposed to the extra unlabeled set mixed with ID and OOD and distinguishes the unlabeled ID/OOD samples during training as UDG and the ET do, the OOD detection performance will be comprehensively improved because the model keeps focusing on the semantic shifts between ID/OOD thus learning their discrepancy better. However, since unlabeled ID samples cannot be collected as fully as ideal, some of them are classified into the wrong categories, which hurts the classification performance of the model. Our method brings a more accurate label assignment derived from the practical guidance of energy score on the cluster distribution, and mitigates accuracy decay induced by extra OOD samples compared to UDG.

\textbf{Influence of OOD scores.} We notice that when replacing max softmax probability (MSP)~\cite{baseline} with T-energy as OOD score, UDG drops by about 15$\%$ on FPR@95. To exclude the possibility that our approach only gains from T-energy score, we test the performance of UDG and our approach on three kinds of OOD scores, including MSP, energy and T-energy. As shown in \cref{T:metrics}, our method outperforms the baseline no matter which OOD score is chosen. In particular, when evaluating UDG on energy and T-energy, the AUROC and AUPR both suffer a drop. However, the proposed ET explores the ID/OOD semantic discrepancy based on the energy, and in turn promotes the ability of energy score to discriminate ID/OOD by continuously optimizing label assignment, so our method obtains improved performance when being tested with energy score. Additionally, temperature scaling further widens the gap between ID and OOD, helping the model achieves the best performance on all metrics.

\begin{table}[t]
\centering
\renewcommand{\arraystretch}{1.}
\renewcommand{\tabcolsep}{3.pt}
\small
    \caption{\textbf{Influence of OOD scores.} MSP denotes max softmax probability. Our method outperforms the UDG on all OOD scores and achieves the best on the T-energy.}
    \label{T:metrics}
    \centering
    \begin{tabular}{cc|ccc}
    	\toprule
    	OOD Score & Method & \footnotesize{FPR95~$\downarrow$} & \footnotesize{AUROC~$\uparrow$} & \footnotesize{AUPR-IN/OUT~$\uparrow$} \\
    	\midrule
    	\multirow{2}{*}{MSP}        
    	& UDG\cite{yang2021semantically}                   & 36.22 & 93.78 & 92.61~/~92.94 \\
    	& Ours                 & 13.55 & 95.56 & 96.89~/~94.96\\
    	\midrule
    	\multirow{2}{*}{Energy}        
    	& UDG\cite{yang2021semantically}                   & 34.90 & 90.65 & 91.56~/~91.11 \\
    	& Ours                 & 12.86 & 96.05 & 97.04~/~95.01\\
    	\midrule
    	\multirow{2}{*}{T-Energy}        
    	& UDG\cite{yang2021semantically}                   & 21.57 & 92.44 & 91.70~/~92.12 \\
    	& Ours                 & \textbf{8.53} & \textbf{96.47} & \textbf{97.10}~/~\textbf{95.65}\\
    	\bottomrule
    \end{tabular}
    % \vspace{-0.25em}
\end{table}
