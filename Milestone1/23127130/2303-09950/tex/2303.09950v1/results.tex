%!TEX root = graphsc.tex

\section{Experiments}

We evaluate the efficacy of \ours{} on three challenging benchmarks: 4DMatch~\cite{li2022lepard} (\cref{sec:exp-4dmatch}), CAPE~\cite{ma2020learning,pons2017clothcap} (\cref{sec:exp-cape}) and DeepDeform~\cite{bozic2020deepdeform} (\cref{sec:exp-deepdeform}). Extensive ablation studies are also provided to better understand our design choices (\cref{sec:exp-ablation}). More implementation details and network settings are introduced in the appendix.

\ptitle{Metrics.}
%
Following~\cite{li2022lepard,li2022non}, we mainly evaluate $4$ metrics in the experiments:
(1) \emph{3D End Point Error} (EPE), the average errors over all warped points under the estimated and the ground-truth warp functions, (2) \emph{3D Accuracy Strict} (AccS), the fraction of points whose EPEs are below $2.5\text{cm}$ or relative errors are below $2.5\%$, (3) \emph{3D Accuracy Relaxed} (AccR), the fraction of points whose EPEs are below $5\text{cm}$ or relative errors are below $5\%$, and (4) \emph{Outlier Ratio} (OR), the fraction of points whose relative errors are above $30\%$.

\subsection{Evaluations on 4DMatch}
\label{sec:exp-4dmatch}

\ptitle{Dataset.}
%
4DMatch~\cite{li2022lepard} is a challenging synthetic benchmark for non-rigid point cloud registration, which is constructed using the animation sequences from DeformingThings4D~\cite{li20214dcomplete}. It consists of $1232$ sequences for training, $176$ for validation and $353$ for testing. The point cloud pairs in the testing sequences are divided into 4DMatch and 4DLoMatch based on a overlapping ratio threshold of $45\%$.
We use the preprocessed data from NDP~\cite{li2022non} which removes the testing pairs with nearly-rigid movements to better evaluate the performance on non-rigid scenarios.

\ptitle{Comparisons with state-of-the-art methods.}
\label{sec:exp-sota}
%
We first compare \ours{} to previous state-of-the-art non-rigid registration and scene flow estimation methods: NSFP~\cite{li2021neural}, Nerfies~\cite{park2021nerfies}, PointPWC-Net~\cite{wu2020pointpwc}, FLOT~\cite{puy2020flot}, DGFM~\cite{donati2020deep}, SyNoRiM~\cite{huang2022multiway}, and NDP~\cite{li2022non}. To evaluate the generality of our method, we adopt two recent deep correspondence extractors in the experiments, Lepard~\cite{li2022lepard} and GeoTransformer~\cite{qin2022geometric}. As shown in \cref{table:results-4dmatch}, our method outperforms the baselines by a large margin on both benchmarks, indicating the effectiveness of \ours{}.
On the two most important metrics \emph{AccS} and \emph{AccR}, our method significantly surpasses the previous best NDP by $11$ percentage points (pp) on 4DMatch and $14$ pp on 4DLoMatch.
Note that benefiting from the high-quality correspondences, our method achieves the new state-of-the-art results simply with N-ICP and achieves $10$ times acceleration than NDP ($0.2$s \vs $2$s).

\input{tables/results-4dmatch}

\input{tables/results-rejection}

\input{figures/gallery-4dmatch}

\ptitle{Comparisons with outlier rejection methods.}
\label{sec:exp-rejection}
%
We compare to one traditional outlier rejection method, VFC~\cite{ma2014robust}, and two recent learning-based methods for \emph{rigid} registration, PointCN from 3DRegNet~\cite{pais20203dregnet} and PointDSC~\cite{bai2021pointdsc}, to evaluate the efficacy of our method. We also report the precision and recall of the predicted inliers to compare the inlier classification performance. For fair comparison, we adopt similar network macro-architecture for all the models and use the same configurations in N-ICP. For PointDSC, $2048$ correspondences are randomly sampled to avoid too huge memory footprint. We show the results on two correspondence extractors (Lepard and GeoTransformer) to compare the generality of the methods. And the results using the ground-truth inliers are also reported as \emph{oracle}. As shown in \cref{table:results-rejection}, the models with outlier rejection significantly surpass the models that do not prune outliers. And our method outperforms PointCN and PointDSC by a large margin on both benchmarks and attains very close results to the oracle, demonstrating the strong effectiveness of our design.
Note that our method attains both better precision and recall, especially in low-overlap scenarios, which means it \emph{rejects more outliers while preserving more inliers}.
This guarantees more thoroughly-distributed correspondences, facilitating more accurate non-rigid registration.

\ptitle{Qualitative results.}
%
\cref{fig:gallery-4dmatch} visualizes the correspondences and the registration results of different methods. Compared with the baselines, \ours{} prunes outliers more accurately while preserves more inliers, especially in low-overlap or large-deformation scenarios. And our method performs quite well in the scenes with symmetry (see the $2^{\text{nd}}$ row) or complex geometry (see the $4^{\text{th}}$ row). As there is little interference from outliers, our method successfully recover the geometry in non-overlap regions (see the registration results enclosed by the red box).

\subsection{Generalization from 4DMatch to CAPE}
\label{sec:exp-cape}

\ptitle{Dataset.}
%
CAPE~\cite{ma2020learning,pons2017clothcap} contains the complete scans of dynamic clothed humans. It consists of $15$ human subjects and provides accurate 3D mesh registrations.
We use the data preprocessed by~\cite{huang2022multiway} where each point coud contains $8192$ points.
To better study the performance on large deformations, we first align each point cloud pair with a rigid transformation by solving a mean least square problem~\cite{besl1992method}, and ignore the pairs whose mean residuals are below $10$cm.
At last, we obtain $11288$ point cloud pairs for evaluation.

\input{tables/results-deepdeform-cape}

\ptitle{Quantitative results.}
%
We investigate the generality of our method on CAPE.
To this end, we train all the models on 4DMatch and directly evaluate the models on CAPE without fine-tuning.
The input correspondences are extracted with GeoTransformer~\cite{qin2022geometric} which is also trained 4DMatch.
As shown in \cref{table:results-deepdeform-cape}(top), \ours{} achieves significant improvements over the baseline methods. Our method surpasses the second best PointDSC by over $13$ pp on precision and AccS, $20$ pp on recall, and $11$ pp on AccR. Note that our method not only achieves better precision, but very high recall, indicating that it prunes more outliers while preserves more inliers. 
As the human pose variations in CAPE are relatively large, the baseline methods fail to effectively distinguish inlier and outlier correspondences.
Nevertheless, our method is still effective and has strong robustness thanks to the local spatial consistency.
Please refer to the appendix for more detailed qualitative results.

\subsection{Generalization from 4DMatch to DeepDeform}
\label{sec:exp-deepdeform}

\ptitle{Dataset.}
%
DeepDeform~\cite{bozic2020deepdeform} consists of real-world partial RGB-D images scanned by a RGB-D camera. It contains $400$ scenes with over $390$K RGB-D frames.
We project the depth images into point clouds and leverage the dense scene flow annotations to construct the point cloud pairs.
And we adopt the same preprocessing as in~\cref{sec:exp-cape} with a threshold of $5$cm to remove the nearly-rigid pairs.
As a result, we obtain $1011$ point cloud pairs for evaluation.

\ptitle{Quantitative results.}
%
Following~\cref{sec:exp-cape}, we train all the models on 4DMatch and directly test them on DeepDeform without fine-tuning to invesigate the generality of our method to real-world scenarios. And GeoTransformer trained 4DMatch is adopted to generate the initial correspondences.
As shown in \cref{table:results-deepdeform-cape}(bottom), PointCN achieves only marginal improvements over the model without outlier rejection. As it determines outliers based on only the coordinates of each single correspondence without considering the geometry of point clouds, its generality is unsatisfactory. PointDSC obtains considerably better results than PointCN benefiting from the global spatial consistency. However, it still lacks the capability to handle non-rigid deformations. On the contrary, our method outperforms the three baseline methods by a large margin as it leverages local rigidity to remove outliers, which better models the deformations. These results have demonstated the strong transferability and generality of our method to unseen domains.

\subsection{Ablation Studies}
\label{sec:exp-ablation}

We further conduct extensive ablation studies to provide a better understanding of the design choices in \ours{}. In the following experiments, we use GeoTransformer as the prior correspondence extractor.

\input{tables/results-ablation}

\ptitle{Node sampling.}
%
We first study the influence of the distribution of nodes. First, we vary the distance threshold $\sigma_n$ from $0.04$ to $0.32$ for node sampling. Note that we do not change the node sampling settings in N-ICP.
As shown in \cref{table:results-ablation}(a), our method attains similar performance under different $\sigma_n$, and the performance get worse if $\sigma_n$ is too small or too large. If $\sigma_n$ is too small, each local region is limited so that there could not be enough context. But if $\sigma_n$ is too large, the local spatial consistency could be broken.

Next, we replace the uniform furthest point sampling with uniform random sampling in \cref{table:results-ablation}(b), and two sampling methods achieve comparable results. The model with furthest point sampling performs slightly better as it generates more stably distributed nodes. These results prove the strong robustness of our method to the distribution of nodes.

\ptitle{Graph construction.}
%
We further study the influence of the graph structure to compute local spatial consistency. First, we build a $k$NN graph which connects each correspondence to its $k$ nearest correspondences as described in \cref{sec:local-spatial-consistency}, where $k=32$ to fit the GPU memory and the same network architecture is used for outlier rejection. From \cref{table:results-ablation}(c), our method surpasses this counterpart on all the metrics, especially in low-overlap cases. We argue that our advantage is two-fold. First, each correspondence can only be connected to limited neighbors in the $k$NN graph due to high memory usage, which fails to provide enough geometric context. Second, the learned features are predominated by the spatial areas with high densities in the $k$NN graph such that the representation ability is degraded.

Next, we vary the number of nodes $k$ where each correspondence is assigned when building the graph in \cref{table:results-ablation}(d). The results are significantly degraded when $k=1$. One the one hand, considering only one local region for each correspondence harms the robustness of the learned features to large deformation. On the other hand, the geometric context in a local region is insufficient when $k$ is too small. And the performance also gets worse with a large $k$. The distances between correspondences and nodes could be too far such that the local spatial consistency is broken in this case.