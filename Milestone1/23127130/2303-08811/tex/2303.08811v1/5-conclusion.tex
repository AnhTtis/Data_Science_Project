
\section{Conclusion}
Variability of animal behavior is likely to be driven by a number of factors that can unfold over different timescales. Thus, having ways to model behavior and discover differences in behavioral repertoires or actions at many scales could provide insights into individual differences, and help, for example, detect signatures of cognitive impairment \cite{wiltschko2020revealing}.
We make steps towards  addressing these needs by proposing a novel approach that learns representations for behavioral data at different timescales. 

Experiments on synthetic robot datasets and real-world mouse behavioral datasets show that our method can learn to encode the wide temporal spectrum of behavior representations. This makes it possible to distinguish global as well as temporally local behaviors. This separation allows us to better discover  variations at different timescales and across different agents, helping us to develop better insights. In the future, we plan to test our model on additional datasets to further study how behavior patterns are exhibited at different frequencies.

\section*{Acknowledgements}
We would like to thank Mohammad Gheshlaghi Azar and  Remi Munos for their feedback on the work. This project was supported by NIH award 1R01EB029852-01, NSF award  IIS-2039741, as well as generous gifts from the Alfred Sloan Foundation, the McKnight Foundation, and the CIFAR Azrieli Global Scholars Program. 
