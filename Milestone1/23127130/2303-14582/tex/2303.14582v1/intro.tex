\begin{abstract}
Multitask learning is widely used in practice to train a low-resource target task by augmenting it with multiple related source tasks. Yet, naively combining all the source tasks with a target task does not always improve the prediction performance for the target task due to negative transfers. Thus, a critical problem in multitask learning is identifying subsets of source tasks that would benefit the target task. This problem is computationally challenging since the number of subsets grows exponentially with the number of source tasks; efficient heuristics for subset selection does not always capture the relationship between task subsets and multitask learning performances. In this paper, we introduce an efficient procedure to address this problem via surrogate modeling. In surrogate modeling, we sample (random) subsets of source tasks and precompute their multitask learning performances; Then, we approximate the precomputed performances with a linear regression model that can also be used to predict the multitask performance of unseen task subsets. We show theoretically and empirically that fitting this model only requires sampling linearly many subsets in the number of source tasks. The fitted model provides a relevance score between each source task and the target task; We use the relevance scores to perform subset selection for multitask learning by thresholding. Through extensive experiments, we show that our approach predicts negative transfers from multiple source tasks to target tasks much more accurately than existing task affinity measures. Additionally, we demonstrate that for five weak supervision datasets, our approach consistently improves upon existing optimization methods for multi-task learning.
\end{abstract}

\section{Introduction}

Multitask learning (MTL) is an approach to combining several tasks together and learning one model for all tasks simultaneously \cite{caruana97cmu}.
The premise is that by combining the data samples of several tasks together, the dataset size of each task increases, thus improving the learning performance for every task.
However, naively using all the source tasks may worsen performance compared to single-task learning (STL) for target tasks if there exist source tasks that are unrelated to them.
This problem is commonly referred to as negative transfers in the literature but is challenging to predict for many tasks \cite{rosenstein05}.

The importance of developing a better understanding of multiple learning performance is well recognized.
In the seminal work of \citet[Chapter 3]{caruana97cmu}, heuristics for judging ``task-relatedness'' in several applications are discussed;
For instance, tasks that share many input features are more likely to be related to each other.
A classical result by \citet{ben2010theory} introduces an $\cH$-divergence notion that quantifies the distance between two label distributions and relates the bias of source domains to this notion.
MTL may perform worse than STL if the bias is too large.
In weakly-supervised learning, several programmatic labeling functions are used to annotate a corpus of unlabeled data, and each labeling function can be treated as a source task \cite{ratner2016data}.
The task labels can be highly noisy, causing negative transfer during training even though the tasks share the same input features \cite{ratner2019training}.
In multitask learning of text prediction tasks, negative transfers are observed between different categories of tasks (e.g., question answering vs. sequence labeling) and different sizes of datasets \cite{vu2020exploring}.

Motivated by the need to reduce negative transfers between different tasks, researchers have developed optimization methods for multi-task learning from various fields.
The most thorough approach to addressing these issues is to train all possible combinations of source tasks with the target task and find which subset of source tasks improves performance on the main target task.
{If there are $k$ source tasks, then this approach requires training $2^k$ MTL models. This is impractical (e.g., when $k\ge 20$).}
A more efficient solution is to train combinations of every \emph{single} source task with the target task to determine if one task helps and then merge the helpful tasks together.
This approach captures pairwise transfers, which measures first-order task affinities from one source task to another task \cite{fifty2021efficiently}.
Regarding higher-order transfers from multiple source tasks to another task, approximation techniques such as averaging the first-order affinity scores of each source task have been explored \cite{standley2020tasks}.

\begin{figure}[t!]
    \centering
    \begin{subfigure}[b]{0.99\textwidth}
        \centering
        \includegraphics[width=0.99\textwidth]{./figures/pipeline.pdf}
    \end{subfigure}
  \caption{
  \revision{Our approach involves two steps, as shown in the figure above.
  In the first step, we sample $n$ random subsets of source tasks among $k$ source tasks. Let these random subsets be denoted as $S_1, S_2, \dots, S_n$.
  For $i$ from $1$ up to $n$, we train an MTL model using the combined data of all the tasks in $S_i$ and the target task.
  We evaluate the loss of this MTL model on an evaluation set from the target task and denote the evaluation loss as $f(S_i)$.
  Then, we train a linear regression model to estimate the relevance scores {$\theta_1, \theta_2, \dots, \theta_k$}, by minimizing the mean squared error between $g_{\theta}(S_i) = \sum_{j\in S_i}\theta_j$ and $f(S_i)$, as shown on the left.
  Let the estimated scores be denoted as $\hat\theta = [\hat\theta_1, \hat\theta_2, \dots, \hat\theta_k]$.
  To predict the MTL performance of any unseen subset $S$, we compute $g_{\hat\theta}(S) = \sum_{i \in S} \hat\theta_i$.
  In the second step, we perform subset selection by choosing any task whose relevance score is below a threshold $\gamma$; We choose this selection criterion by examining the subset $S$ that minimizes $g_{\hat\theta}(S) = \sum_{j \in S} \hat\theta_j$, as shown in the right figure.}}\label{fig1}
\end{figure}

This paper designs and analyzes a scalable approach to identify negative transfers from multiple source tasks to one target task.
\revision{The key idea is to construct a surrogate model to approximate the MTL performance of a subset of source tasks combined with the target task.
Compared with prior works that measure task-relatedness based on either gradient similarity \cite{yu2020gradient} or feature space alignment of neural networks \cite{wu2020understanding,raghu2019rapid,nguyen2020leep}, our approach can be used to identify negative transfers from a set of tasks to another task.}
It also differs from existing discrepancy notions (e.g., $\cH$-divergence) between source and target domains, which are difficult to measure for deep neural networks.
Our approach builds on a recent paper that designs datamodels to predict the predictions of deep neural networks trained on a subset of training data \cite{ilyas2022datamodels}.
Unlike their work (that studies single-task learning), we evaluate surrogate models for multi-task learning with deep neural networks.

\emph{The first step of our approach} involves learning a relevance score between every source task and the target task while accounting for the presence of the other source tasks.
Let $\theta_i$ denote the relevance score of task $i$, for $i$ from $1$ to $k$, where $k$ is the total number of source tasks.
Conceptually, $\theta_i$ is analogous to the important score of a feature in random forests when hundreds of other features are available.
To estimate the relevance scores, we introduce a surrogate model $g_{\theta}(S)$, parametrized by the relevance scores $\theta$, to approximate MTL performances.
\revision{Given any subset of source tasks $S$, let $f(S)$ be a loss function that measures the performance of combining $S$ and the target task to train an MTL model and then evaluated on the target task.}
The value of $f(S)$ provides a relevance measure between $S$ and the target task. Recall that $\theta_i$ measures the relevance of task $i$ to the target task. Thus, a lower value of $\theta_i$ indicates a higher relevance of task $i$ to the target task.

\revision{We specify a linear surrogate model as $g_{\theta}(S) = \sum_{j\in S}\theta_j$ (parametrized by the relevance scores) and minimize the mean squared error between $g_{\theta}(S_i)$ and $f(S_i)$ over $n$ random subsets, for $i$ from $1$ to $n$.
In particular, we precompute the values of $f(S_1), f(S_2), \dots, f(S_n)$ by training one MTL model for each subset.
We use such a linear specification of $\theta$ because computing the performance of each subset requires training an MTL model, which is not scalable unless $n$ grows almost linearly in $k$.
In addition, we take inspiration from the recent work on datamodels \cite{ilyas2022datamodels}, which shows that a linear regression model can extrapolate the predictions of deep neural networks for subsets of training data.}
We rigorously analyze the sample complexity of our approach in Theorem \ref{thm_converge}.
After fitting $\theta$, we predict the performance of an unseen subset $S$ as $g_{\theta}(S)$ and compare it with the STL performance of the target task to determine if $S$ provides a negative transfer.

\emph{The second step of our approach} involves selecting a subset of source tasks by choosing any source task whose relevance score is below a threshold $\gamma$.
We derive this selection criterion by examining the minimum of the surrogate model $g_{\theta}(S)$ over all possible subsets $S$.
We analyze this algorithm in a setting that includes one group of source tasks closer to the target task and another group further from the target task.
The analysis reveals that for each task $i$, its relevance score $\theta_i$ is proportional to the sum of the MTL performances of all subsets that include $i$. Moreover, these performances preserve the distance gaps from the source tasks.
See Theorem \ref{thm_analysis} for the precise result.
\revision{In practice, we pick $\gamma$ via cross-validation; See Section \ref{sec:exp} for the range of $\gamma$ that we validate on in the experiments. Taken together, our approach provides an efficient pipeline to predict and optimize multitask learning performances for task subsets.
See Figure \ref{fig1} for an illustration.}






\smallskip
\textbf{Experimental Results.} We conduct extensive experiments to validate our approach in numerous data modalities and performance metrics.
We summarize a list of our results as follows:
\begin{itemize}[leftmargin=20pt,topsep=0.0pt,itemsep=7.0pt,partopsep=0pt,parsep=0pt]
    \item The runtime for constructing surrogate models until convergence scales linearly in $k$, and the predicted performances accurately fit the true MTL performances of unseen subsets, measured by Spearman's correlation (0.8 averaged among 16 evaluations). %
     Our approach achieves $4$ times higher accuracy for predicting positive vs. negative transfers than known approximation schemes, measured by the $F_1$-score.
    \item By selecting source tasks based on the predicted MTL performances and only using the selected source tasks, we observe consistent benefits over existing optimization methods.
    {We evaluate our approach on many datasets, including weak supervision, NLP, and multi-group fairness.
    In addition, we apply our approach to different MTL encoders, including BERT and multi-layer perceptrons.}
    Notably, we consider a weak supervision dataset with as many as 164 labeling functions \cite{zhang2021wrench}.
    By selecting labeling functions with our approach and then applying MTL, we obtain up to 3.6\% absolute accuracy lift compared with existing methods.
    \item We further visualize the tasks selected by our approach and find a separation between the selected tasks in terms of their labeling accuracies.
    Besides, our approach can also be used in scenarios where multiple groups of heterogeneous subpopulations are present. We are interested in the fairness and robustness of the learned model, measured as the performance of the worst-performing group. 
    We apply our MTL framework as an augmentation to expand the dataset size of the worst-performing group and show consistent empirical performance in the worst-group accuracy metric.
\end{itemize}

\smallskip
{\textbf{Summary of Contributions.} To summarize, this paper makes three contributions to studying negative transfers in multi-task learning.
First, we aim to model the higher-order relationships from a set of source tasks to another task.
We meta-learn such relationships using a linear regression method that can also predict an unseen subset's MTL performance.
Second, we design a subset selection criterion for multi-task learning, which adjusts a threshold on the relevance scores of each source task. Compared with the existing literature, our approach is much more accurate for modeling higher-order task relationships (See Figure \ref{transfer_prediction_res} in Section \ref{transfer_prediction_res} for the detailed result).
Third, we validate our approach with extensive theoretical and experimental results.}


\smallskip
\noindent\textbf{Organization.}
Section \ref{sec_approach} describes the problem setup and the surrogate modeling approach.
In Section \ref{sec_theory}, we present a subset selection algorithm for multitask learning.
We then present the experiments in Section \ref{sec:exp}.
Then, we discuss the related works in Section \ref{sec_related}.
Lastly, we summarize the paper in Section \ref{sec_conclude}.
The appendix provides complete proof of our theoretical results and omitted results from the experiments.