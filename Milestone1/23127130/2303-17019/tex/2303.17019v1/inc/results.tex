\def\secstatus{finished}

\section{Numerical results}
\label{sec:results}

Numerical experiments were performed in order to demonstrate the convergence of the
AMR-based numerical schemes and solvers, the efficiency gained by AMR with
prediction, the robustness of the solvers for practical physics regimes, and
the parallel scalability of RFP simulations.

%

\subsection{Manufactured solution results: Convergence of algorithms}
\label{sec:manufactured-results}

This section employs the manufactured solution derived in
Section~\ref{sec:solutions}  to demonstrate a convergence analysis of
the overall solver, including the numerical scheme and handling of the finite
volume discretization at hanging faces of neighboring cells with different
levels of refinement.

The manufactured solution is approximated in the domain $[0.3, 60]\times[-1, 1]$ for
$[p_\mathrm{min},p_\mathrm{max}]\times[\xi_\mathrm{min},\xi_\mathrm{max}]$.
The RFP model parameters used in~\eqref{eqn:exactCollisionMMS} are $E=0.5$,
$\alpha=0.05$; the simulation of the manufactured solution takes place in the
time interval $t=0,\ldots,10$; and the MUSCL scheme is used.  We  utilize
the 3rd-order explicit Runge--Kutta time integrator of PETSc with a constant time step
length.  The range of levels of mesh refinement, in between which our AMR
refinement criteria from Section~\ref{sec:amr-pred} are adapting the mesh
dynamically, is varying.  We prescribe the range of levels to be 3 and shift the
minimum and maximum permitted levels up by one in each simulation setup.  The
coarsest setup has refinement levels $(2,3,4)$; the next finer setup has levels
$(3,4,5)$, then $(4,5,6)$, and finally $(5,6,7)$.  Table~\ref{tab:manufactured}
lists the number of FV cells that are generated by the AMR algorithm with
prediction (see Section~\ref{sec:amr-pred}) at each refinement level.

The increasingly finer mesh resolution requires a shorter time step length that
is selected to satisfy the CFL condition; see column $\Delta t$ in
Table~\ref{tab:manufactured}.  Because of the changing time step length, we
also are adjusting the frequency of time steps at which mesh refinement is
performed; the corresponding column in Table~\ref{tab:manufactured} is called
\emph{Refine freq.}  The refinement frequency determines after how many time
steps the mesh is updated to track the dynamically changing solution.

The convergence of the numerical solution,  expressed in the relative error to
the known exact solution~\eqref{eqn:exactCollisionMMS}, is listed in the
rightmost column of Table~\ref{tab:manufactured} denoted \emph{Relative error}.
The errors decrease with each additional level of refinement by a factor of 1/2
or less.  Simultaneously the number of total cells is increasing by a factor of
$\sim$3, as opposed to a factor of 4 if the refinement was performed uniformly.

\begin{table}\centering
  \caption{Numerical results pertaining to the manufactured
    solution~\eqref{eqn:exactCollisionMMS}.
    Four simulations are shown with increasing levels of refinement, with the
    total number of dynamically adapted cells increasing by factors of $\sim$3
    and the relative error to manufactured solution decreasing by a factor of
    $\sim$1/2.}
  \label{tab:manufactured}
  \centering
  \scriptsize
  \input{inc/tab_manufactured_advdiff}
\end{table}

%

\subsection{AMR prediction results: Higher accuracy with low computational overhead}
\label{sec:pred0-vs-pred1}

This section demonstrates numerically the benefit of adding the proposed
prediction capabilities to AMR as described in Section~\ref{sec:amr-pred}.  The
benefit is that the solution function is resolved with increased accuracy with
a comparatively small increase in computational costs.
%
We focus on an experimental setup where the frequency of mesh
refinement (and coarsening) varies such that AMR is performed each 32, 16, 8,
and 4 time step iterations, where the time step length is adapted based on a
local truncation error.  For brevity, we refer to these varying frequencies of
mesh refinement as RF32, RF16, RF8, and RF4, respectively.  These refinement
frequencies are used in experiments with standard mesh refinement without
prediction and AMR with prediction. The adaptive levels for mesh refinement
range from 2 to 6, hence capturing a level contrast of 4, where a uniform mesh
of level 2 would contain 192 FV cells and each additional level subdivides a
parent cell into 4 child cells.

The RFP model parameters for this study are $E=0.5$ and $\alpha=0.1$; the time
interval of the simulation is $t=0,\ldots,4$; and the MUSCL scheme is used.

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

The AMR indicator LogDR~\eqref{eq:ldr} is a metric based on features of the numerical
solution that quantifies the smoothness of the solution with nondimensional
values.  When the solution exhibits artifacts or oscillations arising from too
coarse meshes, the metric increases to values larger than one.
Therefore, we use this metric to evaluate how well the solution is resolved by
a dynamically adapted mesh, and we compare the differences as the refinement
frequency varies and for AMR without and with prediction.

Initially, we observe how the mean of the AMR indicator  evolves in time. In
Figure~\ref{fig:pred0-vs-pred1-mean} the top graphs correspond to
standard AMR (without prediction), and the bottom graphs show AMR with
prediction.  The colors of each graph indicate different refinement
frequencies.
The top of the figure
%
shows how more frequent mesh
adaptation is resulting in a reduction of the spatial mean of the metric and
how the metric is approaching unity.  These results stand in contrast to the bottom of
%
the figure, where the AMR indicators are propagated
ahead of the solution, which results in the metric being significantly lower,
by about 10--40\%
Additionally, the curves corresponding to different refinement frequencies are
more clustered together and below unity, showing that less frequent mesh
adaptation must not result in poorer-resolved solutions as in the case without
AMR prediction.
The trend as refinement frequency increases (RF32-pred \ldots RF4-pred) is
reversed compared with the top curves (RF32 \ldots RF4), because the metric
associated with RF4-pred (pink color) is above the one for RF32-pred (green
color).  The reason  is that the prediction intervals are longer for RF32-pred and
therefore more cells of the mesh are refined along the predicted path of the
solution.

Complementary to the evolution of the mean of the metric,
Figure~\ref{fig:pred0-vs-pred1-mesh} plots the evolution of the mesh size.
This figure shows how many more mesh cells are being generated due to the
prediction of AMR indicators.  The increase in the number of cells is
$<$10\%
$\sim$20\%
RF32-pred compared with RF4-pred also support the above observations about the
mean of the metric (i.e., RF32-pred's metric is below RF4-pred).
While the discussion has been highlighting the extreme cases RF32-pred and
RF4-pred, the intermediate setups RF16-pred and RF8-pred show only moderate
increases in mesh sizes (orange and purple curves in
Figure~\ref{fig:pred0-vs-pred1-mesh}) while at the same time keeping the
metric uniformly bounded below one (orange and purple curves in
Figure~\ref{fig:pred0-vs-pred1-mean}).  This shows that a balance between mesh
size, implying computational cost, and boundedness of the metric, implying a
well-resolved solution, is possible in practice.

\begin{figure}\centering
  \includegraphics[width=0.7\columnwidth]{figs/pred0_vs_pred1/mean}
  \vspace{-0.5\baselineskip}
  \caption{Spatial mean of the AMR indicator LogDR~\eqref{eq:ldr} evolving
    in time: AMR without prediction \emph{(top)} and AMR with prediction
    \emph{(bottom)}.
    Decreasing refinement frequencies (RF32, RF16, RF8, RF4) are lowering the
    LogDR metric, whereas with prediction the metric remains at low levels for
    any refinement frequency.}
  \label{fig:pred0-vs-pred1-mean}
%
  \vskip 4ex
%
  \includegraphics[width=0.7\columnwidth]{figs/pred0_vs_pred1/mesh_size}
  \vspace{-0.5\baselineskip}
  \caption{Temporal evolution of the mesh size reported as number of FV cells.
    The \emph{top} and \emph{bottom} graphs and different \emph{colors}
    correspond to the metric shown in Figure~\ref{fig:pred0-vs-pred1-mean}.}
  \label{fig:pred0-vs-pred1-mesh}
\end{figure}

Going beyond observations of the spatial mean of the metric as it evolves in
time, we also give a sense of the distribution of the metric at time instances.
Figure~\ref{fig:pred0-vs-pred1-dist} shows the envelope of one
standard deviation about the mean for each of the experiments discussed
previously.
The bottom of the figure
%
shows how AMR with
prediction is keeping steady control of the distribution of the AMR indicators,
because the curves are staying predominantly flat.
AMR without prediction, however, shown at the top of the figure,
%
demonstrates that large values of the
metric are being created for lower frequencies of refinement (see RF32, green
color).  To reduce the spread of values, one has to refine more
frequently (see RF4, pink color), which consequently comes at an increased
computational cost (see Table~\ref{tab:pred0-vs-pred1} discussed below).

The most extreme discrepancy between AMR with and without prediction is
demonstrated in Figure~\ref{fig:pred0-vs-pred1-contrast}.  The graphs in this
figure show envelopes between the spatial mean and maximum values of the metric
as it evolves in time.  That is, these graphs are showing a contrast of the
metric between mean and maximum (note that the spatial minimum of the metric is
zero for all experiments and hence cannot be used to define a contrast).  The
differences between AMR with and without prediction are most pronounced in
these figures, with a factor of $\sim$3 difference between the
top and bottom graphs of Figure~\ref{fig:pred0-vs-pred1-contrast}.
Note that in Figure~\ref{fig:pred0-vs-pred1-contrast} the initial mesh at
$t=0$ is the same for all the cases.  Thus  a few mesh adaptation steps
are needed until a more steady state of the maximum metric is reached, and it takes longer
for RF32-pred, where AMR is performed less frequently.

\begin{figure}\centering
  \includegraphics[width=0.7\columnwidth]{figs/pred0_vs_pred1/dist}
  \vspace{-0.5\baselineskip}
  \caption{Spatial distribution of AMR indicator around the mean from
    Figure~\ref{fig:pred0-vs-pred1-mean} that is shown as an envelope of one
    standard deviation above and below the mean curve. (Note: The vertical axis
    is clipped at zero because the AMR indicator is nonnegative.)
    AMR without prediction is shown in the \emph{top} and AMR with prediction
    in the \emph{bottom} graph.}
  \label{fig:pred0-vs-pred1-dist}
\end{figure}

\begin{figure}\centering
  \includegraphics[width=0.7\columnwidth]{figs/pred0_vs_pred1/contrast}
  \vspace{-0.5\baselineskip}
  \caption{Maximum value of AMR indicator relative to the mean from
    Figure~\ref{fig:pred0-vs-pred1-mean}.
    that is shown as one standard deviation
    above and below the mean curve.
    AMR without prediction is shown in the \emph{top} and AMR with prediction
    in the \emph{bottom} graph.}
  \label{fig:pred0-vs-pred1-contrast}
\end{figure}

We summarize the preceding observations in
Table~\ref{tab:pred0-vs-pred1}.  This table lists summary statistics of the AMR
indicator by taking the time average of the spatial mean, denoted by
$\langle\text{mean}\rangle_t$, and the time averages of the standard deviation
and the maximum, denoted by $\langle\text{std}\rangle_t$ and $\langle\text{max}\rangle_t$,
respectively.  Further, the table lists a time-averaged mesh size and the
maximum mesh size over all time steps.
Complementing the earlier figures, the table presents data
about the computational costs in terms of
the time steps used until final time (these values are closely clustered), the
total number of Newton iterations across all time steps (these increase with
frequency of AMR), and the total number of GMRES iterations used (these follow
a  trend similar to the Newton iterations).
The last column of the table gives the run time of the
simulation overall, which was obtained on one node with 56 CPU cores of the
Frontera supercomputer (details in Table~\ref{tab:frontera}).
The run times show, as expected, that higher frequencies of mesh refinement
result in larger run times.
%
Additionally the run times for AMR with prediction are slightly larger than
for AMR without prediction, while AMR frequency is the same.  However,
we have demonstrated above that the accuracy of the solution is significantly
improved by AMR prediction.  The table shows that the run times are, for
instance, $\sim$15\%
RF8-pred).  This is a modest increase in computational cost but a dramatic
increase in accuracy as measured by the AMR indicator (shown in the second
column).

\begin{table}\centering
  \caption{Comparison of AMR without prediction \emph{(top four rows)} and AMR
    with prediction \emph{(bottom four rows)}.
    The table summarizes
    Figures~\ref{fig:pred0-vs-pred1-mean}--\ref{fig:pred0-vs-pred1-contrast} by
    reporting temporal averages of the AMR indicator and mesh sizes, where
    $\langle\cdot\rangle_t$ denotes a temporal average for the time interval
    $0.5<t\le4$.
    The computational cost is given in terms of iterations of Newton's method,
    the iterations of GMRES for the linearized systems of Newton, right-hand
    side (RHS) evaluations, and run time.}
  \label{tab:pred0-vs-pred1}
  \centering
  \scriptsize
  \input{inc/tab_pred0_vs_pred1}
\end{table}

We further want to illustrate the  quantitative observations with
qualitative figures of the numerical solution.
%
The effects of the different AMR settings can be observed qualitatively by
visualizing the solution and the associated mesh. This is done in Figure~\ref{fig:pred0-vs-pred1-t1.99},
where the plots visualize the solution at time $t=1.99$.
Looking at the edges of the solution's distribution, we can clearly see
artifacts for nonpredictive AMR in the left column of the figure, when the
refinement lags behind the solution.  Frequency RF32 (top left) shows the most
severe artifacts.
These artifacts can be ameliorated by faster refinement frequencies, RF32,
RF16, RF8, and RF4 (top left to bottom left, respectively).
%
On the other hand, in the right column of Figure~\ref{fig:pred0-vs-pred1-t1.99}
when AMR prediction is active, the solution's features are resolved as well as or better
than was the case for RF4 (bottom left) before.  This result holds for all
plots: RF32-pred, RF16-pred, RF8-pred, and RF4-pred (top right to bottom right,
respectively).
The additional mesh cells that AMR prediction generates are most pronounced for
RF32-pred (top right in Figure~\ref{fig:pred0-vs-pred1-t1.99}), where the
prediction window is the longest.  This illustrates the additional
computational cost that was observed before (e.g., in
Table~\ref{tab:pred0-vs-pred1}).  Reducing the prediction window to RF16-pred
or RF8-pred results in a better balance between extra generated cells and
resolving the numerical solution.

\begin{figure}\centering
  \includegraphics[width=0.98\columnwidth]{figs/pred0_vs_pred1/pred0_vs_pred1_t1.99}
  \caption{Visualization of the refinement levels of the dynamically adapted
    mesh \emph{(white lines)} at $t=1.99$, without prediction \emph{(left
    column)} vs.\ AMR with prediction \emph{(right column)}, while showing the
    numerical solution in \emph{colors}.  The four \emph{rows} of plots
    correspond, from top to bottom, to RF32, RF16, RF8, and RF4.}
  \label{fig:pred0-vs-pred1-t1.99}
\end{figure}

%

\subsection{Algorithmic robustness under different damping coefficients and electric fields}
\label{sec:robustness-results}

The first practical study focuses on the impact of two important coefficients, the damping coefficient $\alpha$, and the electric field $E$.
In this study, the Fokker--Planck collision is turned on as usual while the knock-on source is turned off.
The runs here all use the same initial condition, which is a Maxwellian with a small perturbation in the tail region.
We vary two coefficients in a range close to practice.
The AMR algorithm in this example uses a base mesh of $48\times 8$ for a domain of $[0.3, 60]\times[-1, 1]$ and a total of 7 levels of refinement.

{
\newcommand{\trimfig}[2]{\trimFig{#1}{#2}{.0}{.0}{0}{0}}
\begin{figure}[htb]
\begin{center}
\begin{tikzpicture}[scale=1]
\useasboundingbox (0,-.5) rectangle (12,2.5);
\draw(-.5,-.1) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/compare/alpha_0p1}{4.35cm}};
\draw(3.9,-.1) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/compare/alpha_0p01}{4.35cm}};
\draw(8.3,-.1) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/compare/alpha_0p001}{4.35cm}};
\draw(0,-1.2) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/compare/range_log}{12cm}};
%
%
\end{tikzpicture}
\end{center}
  \caption{Comparison of RFP solutions under different damping coefficients $\alpha$. The field is fixed as $E=0.5$, and the final time is $T=1$.
  The knock-on source is turned off. Note that the solutions are presented in the log scale and spread over more than 15 orders of magnitude.
  }
  \label{fig:compare_alpha}
\end{figure}
}


Distribution functions at $T=1$ with different damping coefficients are presented in Figure~\ref{fig:compare_alpha}.
One can see that a larger damping term leads to the initial high-energy perturbation moving close to the low-energy region (low $p$).
Meanwhile, Maxwellian bulks at the low-energy region are  similar under different $\alpha$, as expected.
Note that solutions in Figure~\ref{fig:compare_alpha} are presented in  log scale, which shows the distribution function spreads more than 15 orders of magnitude.


{
\newcommand{\trimfig}[2]{\trimFig{#1}{#2}{.0}{.0}{0}{0}}
\begin{figure}[htb]
\begin{center}
\begin{tikzpicture}[scale=1]
\useasboundingbox (0,-.5) rectangle (12,2.5);
\draw(-.5,-.1) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/compare/E_10}{4.35cm}};
\draw(3.9,-.1) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/compare/E_5}{4.35cm}};
\draw(8.3,-.1) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/compare/E_1}{4.35cm}};
\draw(0,-1.2) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/compare/range_log}{12cm}};
%
%
\end{tikzpicture}
\end{center}
  \caption{Comparison of RFP solutions under different electric fields $E$. The damping coefficient is fixed as $\alpha=0.01$, and the final time is $T=1$.
  The knock-on source is turned off. Note that the solutions are presented in  log scale and spread over more than 15 orders of magnitude.
  }
  \label{fig:compare_e}
\end{figure}
}


Distribution functions at $T=1$ with different electric fields are presented in Figure~\ref{fig:compare_e}. We find that a larger $E$ field will push the entire distribution to the high-energy region, as expected.
The expansion of the Maxwellian is found to be faster in a larger $E$ case. In practice, however, the actual distribution will be a result of the interplay of many factors such as the damping force, the electric field, and the Fokker--Planck collision.
Therefore, the distribution will not  move all the way to the high $p$ region but instead form an interesting fat tail in a moderate high $p$ region. This effect will be studied more carefully later.
In addition, we  find that AMR can capture both the Maxwellian expansion and the movement of the tail very well (not presented here).


The second focus of this example is to study the performance of the numerical algorithms under different coefficients.
Such a study for our solver is not easy because the time steps and  details of adaptive meshes change dynamically throughout the simulations.
(Here we use ESDIRK and estimate the time step  using local truncation error estimators.) In addition, when the coefficients change, the numerical difficulty of the model also changes.
To have a fair comparison, we run all the simulations with the same final time $T=1$ and average all the important algorithm quantities over the number of time steps.

\begin{table}[htb]
\caption{Comparison of RFP solver performance under different damping coefficients $\alpha$. The field is fixed as $E=2$, and the final time is $T=1$.
  \label{table:compare_alpha}}
\centering
\vskip 1ex
\footnotesize
\begin{tabular}{ccccc}
\toprule
  \thead{$\alpha$} & \thead{Averaged $\Delta t$} & \thead{Averaged DOFs} &  \thead{RHS eval./solve} & \thead{GMRES it./solve} \\
\midrule
  \num{1}{-1} & 0.00351 & 132358 & 42.85 & 4.49 \\
  \num{5}{-2} & 0.00420 & 120592 & 43.02 & 4.52 \\
  \num{2}{-2} & 0.00441 & 114166 & 43.17 & 4.67 \\
  \num{1}{-2} & 0.00457 & 111694 & 43.22 & 4.66 \\
  \num{5}{-3} & 0.00463 & 110459 & 43.02 & 4.71 \\
\bottomrule
\end{tabular}
\end{table}

We start with testing the damping coefficients. Recall that the practical range of $\alpha$ is 0.001 to 0.3. We test several $\alpha$ and present the corresponding results in Table~\ref{table:compare_alpha}.
The electric field is fixed as $E=2$, which is above the so-called avalanche threshold (see Figure 7 in~\cite{mcdevitt2018relation}).
Here we use hypre's algebraic multigrid solver (BoomerAMG) as the preconditioner for the linearized system.
We further choose hypre's parallel ILU solver as the multigrid smoother (Euclid) and use default values  in the rest hypre options.
Table~\ref{table:compare_alpha} shows that the algorithm performs  well for different $\alpha$.
We also note that as $\alpha$ increases, the averaged time step becomes smaller, and the averaged AMR degrees of freedom become larger,
which all indicate that the problem becomes harder for large $\alpha$.
Nevertheless, the  solver still performs well. %
We also present the averaged RHS evaluation per solve. The majority of those evaluations come from evaluating the Jacobian through finite difference coloring.

\begin{table}[htb]
\caption{Comparison of RFP solver performance under different electric fields $E$. The damping coefficient is fixed as $\alpha=0.1$, and the final time is $T=1$. \label{table:compare_e}}
\centering
\vskip 1ex
\footnotesize
\begin{tabular}{ccccc}
\toprule
  \thead{$E$} & \thead{Averaged $\Delta t$} & \thead{Averaged DOFs} &   \thead{RHS eval./solve} & \thead{GMRES it./solve} \\
\midrule
 2  & 0.00351 & 132358 & 42.85 & 4.49 \\
 5  & 0.00244 & 130881 & 43.02 & 4.50 \\
 10 & 0.00192 & 131288 & 43.12 & 3.96 \\
 15 & 0.00183 & 132139 & 41.82 & 3.70 \\
 20 & 0.00179 & 132657 & 41.77 & 3.51 \\
\bottomrule
\end{tabular}
\end{table}

We then consider the impact of the electric field. A reasonable region for the normalized electric field from practice would be the interval $[0, 20]$. We test several $E$ and present the corresponding results  in Table~\ref{table:compare_e}.
We find that the linear and nonlinear solvers all perform well. We also note that the averaged time steps become smaller for larger $E$, which is expected as the problem becomes  stiffer.

%

\subsection{Parallel scalability}
\label{sec:scalability-results}

This section presents the parallel scalability of the overall numerical
simulations.  Included are the AMR algorithms, the numerical scheme, the
linear solver, and the AMG-based preconditioner.  The
computations are carried out on the Frontera system,  a CPU-based
platform detailed in Section~\ref{sec:hw-sw}.

The setup of the scalability runs is challenging because during a simulation
the mesh is adaptively refined in a dynamic fashion, where the refinement and
coarsening depend on properties of the solution (see Section~\ref{sec:amr}).
Therefore, it is difficult to increase the problem size proportionally with the
number of compute cores.  Because of these difficulties we choose to present
a sequence of strong scalability results only, meaning we omit the
demonstration of weak scalability.  In order to obtain strong scalability results, the
parameters of the problem, and the problem size specifically, remain the same
for each run while the number of compute cores increases by a factor of 2.

Implicit solvers are well known to be challenging to scale strongly in parallel
despite great efforts \cite{rudi2015extreme}.  Hence, we generate a sequence of three different
problem configurations that exhibit increasing problem sizes.  Each of these
problem configurations provides a new baseline for showing strong scalability,
where the baseline core counts are increasing with larger problem sizes:
(i) problem size with 1.4 million (time-averaged) FV cells is scaled from 112 to 7,168 cores;
(ii) problem size with 2.9 million (time-averaged) FV cells is scaled from 224 to 14,336 cores; and
(iii) problem size with 4.4 million (time-averaged) FV cells is scaled from 448 to 28,672 cores.
These three different mesh sizes feature increasingly aggressive mesh adaptivity,
which is measured by the difference between finest mesh level and coarsest mesh
level of refinement;  we call this the \emph{mesh level contrast}.
The mesh level contrast for the above described problem sizes is
(i) 8 levels,
(ii) 9 levels, and
(iii) 10 levels.

In addition to these three mesh configurations, we alter the frequency
of mesh adaptation analogous to Section~\ref{sec:pred0-vs-pred1}.  As before,
the label RF32 stands for performing mesh adaptivity after every 32 time steps,
and additionally reported refinement frequencies are RF64, RF128, and RF256.
The AMR indicators are predicted, as proposed in Section~\ref{sec:amr-pred},
for all of these frequencies.

The RFP model parameters for this study are $E=5$ and $\alpha=0.1$, which
correspond to a realistic parameterization (see
Section~\ref{sec:robustness-results}). The Fokker--Planck collision is
turned on, while the knock-on source is turned off.
%
To demonstrate scalability, we prescribe 512 time
steps of the implicit second-order ESDIRK
time integrator of PETSc with a constant time step length that decreases along
with finer mesh resolutions. We use the QUICK scheme.

\begin{figure}\centering
  \includegraphics[width=0.9\columnwidth]{figs/frontera_scalability/strong_1.4E6cells}
  \vspace{-0.5\baselineskip}
  \caption{Strong scalability results on Frontera from 2 to 128 nodes, where
    the baseline problem has 1.4 million FV cells and a range of 8 levels of
    refinement; $\Delta t=10^{-5}$.}
  \label{fig:strong-scalability-1.4M}
%
  \vskip 4ex
%
  \includegraphics[width=0.9\columnwidth]{figs/frontera_scalability/strong_2.9E6cells}
  \vspace{-0.5\baselineskip}
  \caption{Strong scalability results on Frontera from 4 to 256 nodes, where
    the baseline problem has 2.9 million FV cells and a range of 9 levels of
    refinement; $\Delta t=10^{-5}$.}
  \label{fig:strong-scalability-2.9M}
%
  \vskip 4ex
%
  \includegraphics[width=0.9\columnwidth]{figs/frontera_scalability/strong_4.4E6cells}
  \vspace{-0.5\baselineskip}
  \caption{Strong scalability results on Frontera from 8 to 512 nodes, where
    the baseline problem has 4.4 million FV cells and a range of 10 levels of
    refinement; $\Delta t=10^{-6}$.}
  \label{fig:strong-scalability-4.4M}
\end{figure}

Each of the three figures shows strong scalability for one of the defined
problem configurations: Figures~\ref{fig:strong-scalability-1.4M},
\ref{fig:strong-scalability-2.9M}, and~\ref{fig:strong-scalability-4.4M}
correspond to the strong scalability results for the problem sizes
(i) 1.4 million,
(ii) 2.9 million, and
(iii) 4.4 million FV cells, respectively.
Each figure also shows four differently colored curves, which we use to
distinguish between refinement frequencies.
%
%
Every figure shows the number of cores on the horizontal axis.  Below the core
count, the average number FV cells per core is reported in parentheses, which
tells how large the portion of the distributed problem is for each core.
%
Mainly because of the reduction in problem size per core,  the
communication starts to dominate the simulation's run time, because the fewer
degrees of freedom that reside at a compute unit's local memory, the more
communication needs to be performed via MPI.
%
The vertical axis shows the speedup in run time, which is calculated as the
quotient of the baseline run time over the run time with associated core count.
The speedup depicted by the gray dashed line is the idealized perfect case when
zero communication overhead would be added to the computations.  For implicit
solvers, it is well known to be impossible to achieve.

Each of  Figures~\ref{fig:strong-scalability-1.4M},
\ref{fig:strong-scalability-2.9M}, and~\ref{fig:strong-scalability-4.4M}
shows a general trend of speedup that is unavoidable when strongly scaling an
implicit method: At first, the speedup stays close to the ideal speedup with
initial increases in cores; this is where the run time is dominated by
computations and/or communication is overlapped with computations.  Speedup
then gradually deviates from ideal and starts to flatten up to a certain
increase in cores.  After the flattening, the speedup decreases because the
time used for communication dominates compared with the time used for
computations.
Our strong scalability results follow this general trend. Specifically,
they demonstrate that the highest achievable speedup is 12.2 (green curve at
3,584 cores in Figure~\ref{fig:strong-scalability-1.4M})
The highest speedup is slightly lower in
Figure~\ref{fig:strong-scalability-2.9M} (green curve reaches speedup of 9) and
Figure~\ref{fig:strong-scalability-4.4M} (green curve reaches speedup of 8).
We show the scalability of different refinement frequencies because this work
focuses on the AMR algorithms as well as AMR-induced overheads.
The more often the mesh is refined dynamically (i.e., the lower the refinement
frequency), the wider the gap is between the case with only two refinements during
the whole simulation (green curve for RF256) and the frequencies RF128
(orange), RF64 (purple), and RF32 (pink).

This implies that in order to achieve better scalability in our solver, mesh adaptation would
need to happen less often.
Note that as discussed in Section~\ref{sec:dmbf}, the AMR algorithm based on p4est
is highly scalable. The inefficiency comes from the overhead in rebuilding various
operators when the mesh is updated.
 However, less frequent adaptation of the mesh is
detrimental for the accuracy of the solution, as demonstrated in
Section~\ref{sec:pred0-vs-pred1}.
These conflicting objectives need to be balanced, which was the main motivation
in proposing indicator prediction for AMR, which achieves control over higher
accuracies while keeping the impact on computational overheads, and hence
on scalability, at a minimum.
With the demonstrated improvements in accuracy from
Section~\ref{sec:pred0-vs-pred1} due to AMR prediction, we can expect that each
of the refinement frequencies in Figures~\ref{fig:strong-scalability-1.4M},
\ref{fig:strong-scalability-2.9M}, and~\ref{fig:strong-scalability-4.4M}
resolves the solution similarly well.  Therefore, one can choose the
frequency that is most advantageous for scalability without sacrificing
accuracy.

%

\subsection{Interaction between a Maxwellian and a runaway tail}

We next present a physics-motivated  example to demonstrate the AMR capability for resolving both  of a bulk Maxwellian and a runaway distribution tail.
Our aim is to study the algorithm performance in a practical setting, and thus we design a test that is still relatively simple.
The problem is initialized with a Maxwellian uniformly in $\xi$  under a small perturbation in the tail, which is centered around $(p, \xi) = (40, -0.9)$,
\[
f_0(p,\xi) = \frac{1}{\hat{v}_t^3 \pi^{\frac{3}{2}} } \exp\left(1-\frac{\sqrt{1+p^2}}{\hat{v}_t^2/2}\right) + 10^{-15} \exp\left(\frac{(p-40)^2}{25} \right) \exp\left(\frac{-(\xi+0.9)^2}{0.0025} \right),
\]
where the normalized thermal velocity is taken as $\hat{v}_t = 0.1$. A Neumann boundary condition is applied at the right boundary, while the left boundary uses a Dirichlet boundary condition from
the initial Maxwellian. The computational domain is $[0.3, 60]\times[-1, 1]$ as we let $p_{\min} = 3 \, \hat{v}_t$ for which the Dirichlet is still a good approximation.  We choose a numerical scheme based on the QUICK finite difference scheme and an  implicit second-order ESDIRK integrator through PETSc's TS interface.

The proposed AMR algorithm and indicators are tested using this problem.
The coarsest mesh in the AMR algorithm is chosen to be $48\times 8$, and we use a maximum of 6 more levels of refinement.
Initially, we enforce the AMR algorithm to refine around the left and bottom boundaries for better resolving the Maxwellian bulk and the large portion of the perturbation (see the top row in Figure~\ref{fig:chiu1}).
After the initial indicator is computed from the given solution, the proposed AMR indicator prediction is used to evolve those indicator values over time.
The mesh is checked and updated every 6 time steps. The averaged number of DOFs in the whole simulation is only 287,684, while the previous work~\cite{GuoMcDevittTang2017} needed several million DOFs through a structured stretched grid to have a comparable resolution.

{
\newcommand{\figWidth}{12cm}
\newcommand{\trimfig}[2]{\trimFig{#1}{#2}{.0}{.0}{0}{0}}
\begin{figure}[htb]
\begin{center}
%
\begin{tikzpicture}[scale=1]
\useasboundingbox (0.0,0) rectangle (12,11.7);  %
\draw(0,9.2) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/chiu2/full0}{\figWidth}};
\draw(0,6.9) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/chiu2/full1}{\figWidth}};
\draw(0,4.6) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/chiu2/full2}{\figWidth}};
\draw(0,2.3) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/chiu2/full3}{\figWidth}};
\draw(0,-.62) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/chiu2/full_range}{\figWidth}};
\draw(0,0) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/chiu2/full4}{\figWidth}};
%
%
%
%
\end{tikzpicture}
%
\end{center}
  \caption{Distribution functions (left), mesh and AMR levels (middle), and MPI ranks (right) over time.}
  \label{fig:chiu1}
\end{figure}
}

The numerical results are presented in Figure~\ref{fig:chiu1}. The distribution solutions along with the adaptive meshes are shown.
We note that the Maxwellian bulk and the tail perturbation are slowly merging into each other due to the interaction between the driven electric field, the relativistic Fokker-Planck collision, synchrotron radiation,
and the secondary knock-on source. Here we let the damping strength be $\alpha=0.1$ and turn on the partial screening effects. We note that our AMR algorithm captures the interesting features in the solution very well.
The finest mesh is around the region where it has a large gradient, which is either near the Maxwellian boundary layer or near the runaway tail.
It is also critical for this test that the solver be capable of resolving a large variation of the solution. The solution varies from $10^{-2}$ (the bulk Maxwellian boundary layer) to $10^{-20}$ (the runaway tail).
In order to demonstrate the large variation, the distribution function in Figure~\ref{fig:chiu1} is presented in the log scale, which shows that our adaptive solver is capable of resolving both regions.
To demonstrate the dynamic load-balancing, we include the MPI ranks  in the figure.
Note that this test is designed to be relatively simple so that 32 processors are sufficient.




{
\newcommand{\drawPlot}[4]{%
\begin{scope}[#1]
\draw(0,0) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/chiu2/int#2}{\figWidth}};
\draw(3.5,.7) node[draw,fill=white,anchor=east,xshift=2pt,yshift=0pt,scale=0.8]{\scriptsize #3};
\end{scope}
}

\newcommand{\figWidth}{4.cm}
\newcommand{\trimfig}[2]{\trimFig{#1}{#2}{.0}{.0}{0}{0}}
\newcommand{\trimfigb}[2]{\trimFig{#1}{#2}{.0}{.0}{0}{0.1}}
\begin{figure}[htb]
\begin{center}
%
\begin{tikzpicture}[scale=1]
\useasboundingbox (0.0,-.5) rectangle (12,5.4);  %
\drawPlot{xshift= -.1cm,yshift=2.2cm}{0}{$t=0$}{};
\drawPlot{xshift= 4cm,yshift=2.2cm}{1}{$t=0.269$ }{};
\drawPlot{xshift= 8.1cm,yshift=2.2cm}{2}{ $t=0.669$}{};
\drawPlot{xshift= 1.95cm,yshift=-1cm}{3}{ $t=1.769$}{};
\drawPlot{xshift= 6.05cm,yshift=-1cm}{4}{ $t=2.669$}{};
%
%
%
\end{tikzpicture}
%
\end{center}
  \caption{Runaway electron distributions in $p$ over time.}
  \label{fig:chiu_runaway}
\end{figure}
}


In addition to the distribution, we evaluate the so-called runaway electron population $R(p, t)$,
\begin{align*}
R(p, t) :=  \int_{\xi=-1}^{\xi=1} f(p,\xi, t)  v_\parallel 2\pi p^2  \, d\xi,
\end{align*}
where the parallel velocity is defined as  $v_\parallel = {p \, \xi}/{\gamma \, m_e}$.
This is a distribution in the $p$ direction to measure the runaway electron strength, which is a good indicator of the number of high-energy runaway electrons in the system.
Figure~\ref{fig:chiu_runaway} shows that initially there is a large portion of runaway electrons due to the perturbation and that they are slowly reduced and merged into the bulk.

{
\newcommand{\trimfig}[2]{\trimFig{#1}{#2}{.0}{.0}{0}{0}}
\begin{figure}[htb]
\begin{center}
\begin{tikzpicture}[scale=1]
\useasboundingbox (0,-.5) rectangle (12,3.8);
\draw(0,-.9) node[anchor=south west,xshift=-4pt,yshift=+0pt] {\trimfig{figs/chiu2/knock_on.png}{12cm}};
%
%
\end{tikzpicture}
\end{center}
  \caption{Knock-on electron source at the first checkpoint.}
  \label{fig:chiu2}
\end{figure}
}

We further present the knock-on electron source term in Figure~\ref{fig:chiu2}. We note that the knock-on source is exactly in the range of $\xi \in [-\sqrt{\gamma/(\gamma+1)}, -p/(\gamma+1)]$ as we indicated in Section~\ref{sec:knock_on}.
The mesh plot of Figure~\ref{fig:chiu2} shows that the AMR algorithm is able to capture the source term in this narrow region through adjusting the mesh on the fly.


