In this section, we elaborate the Synonymous Expressions Mining method of Sem4SAP.
Our method targets the value objects in Open-KG.
Since value object is connected by property but not relation, we detailed our method of distinguishing property from relation in subsection~\ref{021}.
The similarity calculation method is in subsection~\ref{022}.
And we introduce the synsets clustering method in subsection~\ref{023}
Illustration of methods in this section is shown in the upper of Figure~\ref{fig:my_label}





\subsection{Property Selection}
\label{021}
Since entity contains only specific semantics, while value contains more general semantics, which is expected to facilitate more aspects than entity.
Value only appears as the object in triplet \emph{$\langle$s,p,o$\rangle$}, so the mining targets at the tail of the triplet.
However, predicate is a general semantic constraint to the objects, we expect to find the predicate which has the following characteristics to better find the most descriptive values:
First, predicate should describe some general features of an entity, or to say it should be a property but not a relation.
Second, predicate should describe a categorical feature of an entity but not quantitative.
The distribution of objects has been used to distinguish whether the given predicate is a property of relation~\cite{li2021towards}.
As shown in Figure~\ref{fig:ps.png}, bigger the Shannon entropy of the object distribution is, more possible the predicate is a relation (predicate = \texttt{Address}) or quantitive property (predicate = \texttt{Birthday}), otherwise it is more likely a property (predicate = \texttt{Gender} or \texttt{Nationality}).
\begin{figure}[!t]
    \centering
    \includegraphics[width=0.85\linewidth]{property_selection.png}
    \vspace{-2mm}
    \caption{The distribution of objects connected by some predicates and the entropy of these distributions.
    }
    \label{fig:ps.png}
    \vspace{-5mm}
\end{figure}

Besides, the precision of finding categorical properties can be further improved.
We observe that the value of categorical property tends to have concentrated semantics, like the semantics of gender, which tend to concentrate on the ``male'' or ``female''.
We propose to use the Shannon entropy of the distribution to all possible word-pieces~\cite{wu2016google} (for example, all possible word-pieces to expression ``man'' are ``m'', ``a'', ``n'', ``ma'', ``an'', ``man'') as well as the entropy of the distribution to all objects to distinguish property.
And the formula for calculating the Possibility of Categorical Properties (PCP) is as follows:

\begin{equation}
    \label{equ: s_p}
    \small
    PCP(p_i) = \frac{\# c}{ent(Val(p_i)) * ent(Str(p_i))}\ \forall c\in C_{p_i}.
\end{equation}

$Val(p_i)$ and $Str(p_i)$ represent the value frequency distribution and word-pieces frequency distribution of given predicate $p_i$ respectively.
$C_{p_i}$ denote all characters in the objects connected by the given predicate $p_i$, and $\#c$ denote the number of given character $c$ in all objects of the given predicate, which is used as a penalty term in the formula.
And $ent(p_i)$ represents the Shannon Entropy of the value distribution of $p_i$.

We use Formula~\ref{equ: s_p} to get possibilities for all predicates.
Higher the $PCP(p_i)$ is, more possible $p_i$ is categorical.

\subsection{Similarity Calculation}
\label{022}

We propose to use the frequency information of every word-pieces to detect the important part of the value objects.
Then use textual features and distributed representation features of these important parts to cluster value objects into synsets.


For textual features, we count the number of occurrences of each word-piece of all value objects as the frequency.
And use the frequencies of every word-pieces as the weight of importance.
If two value objects have more high-weighted word-pieces in common, they will share a high similarity for their important part is similar.
Specifically, we use the formula of TF-IDF~\cite{ramos2003tfidf} improved with the frequency of every character to calculate the similarity of two value objects:
\begin{equation}
    \label{TF-IDF}
    TS_{\mathbb{TF-IDF}}(o_m, o_n) = \frac{f(o_m\cap o_n;O_p)}{f(o_m\cup o_n;O_p)},
\end{equation}
where $\mathbb{TF-IDF}$ denote we are using the TF-IDF method to calculate the Textual Similarity,
$O_p$ denote all the value object $o$ of property $p$, and $f(o;O)$ denote the sum of the frequencies from characters $o$ in $O$.

For distributed representation similarity, we mainly use the LM embedding as the distributed representation of the value objects.
Since LMs have limited expressive ability in representing sequences with few tokens~\cite{batista2018language}, we input all word-pieces of a value object into LMs.
The frequencies of each word-pieces of a value object are used as the weights to calculate the representation, which means the important word-piece of a value object will contribute more to the embedding of a value object.
We use cosine similarity to calculate the distributed representation similarity between two value objects, the specific formula is as follows:
\begin{equation}
    \label{LM-embedding}
    \small
    DRS_{\mathbb{M}_j}(o_m, o_n) = \frac{LM_{\mathbb{M}_j}(o_m;\Theta)\cdot LM_{\mathbb{M}_j}(o_n;\Theta)}{\parallel LM_{\mathbb{M}_j}(o_m;\Theta) \parallel\cdot \parallel LM_{\mathbb{M}_j}(o_n;\Theta) \parallel},
\end{equation}
where $LM$ denote the LM model, $\mathbb{M}_j$ denotes the different LM type, and $\Theta$ denotes the different parameters of LM.
$LM_{\mathbb{M}_j}(o_m;\Theta)$

Finally, we combine the above two formulas as follows to get the final Semantic Similarity of two value objects:
\begin{equation}
\label{o-similarity}
\small
\begin{aligned}
SS(&\langle p_i, o_m\rangle,\langle p_j, o_n\rangle)\\&=\begin{cases}0&p_i\neq p_j\\ \prod^{N_{TS}}_{i}TS_{\mathbb{S}_i}(o_m, o_n)*\prod^{N_{DRS}}_{j}DRS_{\mathbb{M}_j}(o_m,o_n)&p_i=p_j\end{cases}.
\end{aligned}
\vspace{-2mm}
\end{equation}

\subsection{Synsets Clustering}
\label{023}
A weighted complete similarity network can be formed after calculating the similarity between all value objects.
The external synonym database can be integrated by setting a new node and adjusting the edge weight in the network.
Some community detection methods can be used to cluster value objects into synsets based on the similarity network.
And in this paper, we propose to remove edges between value objects which have a low similarity between each other, and simply apply Louvain algorithm~\cite{blondel2008fast} to do the clustering.
