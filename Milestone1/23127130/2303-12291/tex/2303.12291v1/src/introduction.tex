\section{Introduction}
\begin{figure}[!htb]
    \centering
\includegraphics[width=0.5\textwidth]{figures/long_tail.jpg}
    \caption{Overview of our work: Different robust solutions incur varied impacts on noisily labeled long-tailed distributed sub-populations. We show adding \textbf{F}airness \textbf{R}egularizer (\fr) between head and tail populations encourages the classifier to achieve relatively fair performances by reducing performance gaps among sub-populations, and improves the overall learning performance.} 
    \label{fig:overview}
\end{figure}
Biased and noisy training datasets are prevalent and impose challenges for learning \cite{salakhutdinov2011learning,zhu2014capturing,liu2021importance}. The biases and noise can happen both at the sampling and label collection stages: A dataset often contains numerous sub-populations and the size of these sub-populations tends to be long-tailed distributed \cite{salakhutdinov2011learning,zhu2014capturing}, where the tail sub-populations have an exponentially scaled probability of being under-sampled. Meanwhile, a dataset tends to suffer from noisy labels if collected from unverified sources \cite{wei2021learning}. Most prior works treat either population bias or label noise in an isolated way and do not explicitly consider the coupling effects of the two. In particular, existing works on learning with noisy labels mainly focus on a homogeneous treatment of the entire population, and the underlying clean data is often balanced  \cite{natarajan2013learning,liu2015classification,patrini2017making,liu2020peer,cheng2021learningsieve}.

\begin{figure*}[!tb]
    \centering
\includegraphics[width=\textwidth]{figures/visualize.png}
    \caption{How each method improves per sub-population test accuracy w.r.t. CE loss on CIFAR-100 dataset. All methods are trained with Resnet-32. We treat the classes as a natural separation of sub-populations. For each sub-figure, the $x$-axis indicates the CE accuracy. $y$-axis denotes the performance of robust/long-tailed approaches.
    Each dot denotes the test accuracy pair $(\text{Acc}_{\text{CE}}, \text{Acc}_{\text{Method}})$ for each sub-population. The line $y=x$ stands for the case that CE performs the same as the robust treatment on a particular sub-population.
    The {\color{blue}blue} ({\color{red}red}) dot {\color{blue}above} ({\color{red}below}) the line shows the robust treatment has {\color{blue}positive} ({\color{red}negative}) effect on this sub-population compared with CE. In the sub-titles, "Balance" denotes the balanced training data (w.r.t. clean labels); "Imbalance" means the training dataset follows a long-tailed distribution where the ratio between max and min number of samples in the sub-populations is 100; "Clean": the labels of training samples are clean; "Noisy": 20\% correct labels are uniformly flipped into any other class. The test dataset is clean and balanced.}
    \label{fig:acc_com_50}
    \end{figure*}
The main inquiry of our paper is to understand and mitigate the possible heterogeneous effects of label noise when considering the imbalanced distribution of sub-populations. We start by presenting strong evidence of disparate impacts of sub-populations with a synthetic long-tailed noisy CIFAR-100 dataset \cite{krizhevsky2009learning} when using existing learning with noisy labels methods. Figure~\ref{fig:acc_com_50} illustrates the per-population (100 sub-populations in all, where we consider the class information as a natural separation of sub-populations) performance comparisons between applying the traditional Cross-Entropy (CE) loss and the recently proposed robust treatment to either noisy (i.e., Label Smoothing (LS) \cite{lukasik2020does} and PeerLoss (PL) \cite{liu2020peer}) or long-tailed data (Focal \cite{lin2017focal}, Logit-adjustment \cite{menon2021longtail}). There are three main takeaways: \emph{First}, the same robust treatment may have disparate impacts on different sub-populations, e.g., different sub-populations are improved differently by losses such as the Focal loss \cite{lin2017focal}. \emph{Second}, different robust treatments have disparate impacts on the same part of data, e.g., LS \cite{lukasik2020does} performs badly (almost 0 accuracies) on sub-populations with low CE accuracy (<50) and improves the others, while PL \cite{liu2020peer} has a reversed effect that the high CE accuracy part (>50) is likely to be degraded. \emph{Third}, the prior works fail to address the coupling effects of population imbalance and noisy labels. 

The above observations motivate us to explore how sub-population data should be treated when learning from noisily labeled long-tailed data. This work formally investigates the influence of sub-populations when learning with long-tailed and noisily labeled data. The analysis inspires us to define a fairness regularizer for this learning task. Figure~\ref{fig:overview} overviews our work. Our contributions are primarily two-fold. We quantify the influence of sub-populations using a number of metrics and discover disparate impacts of long-tailed sub-populations when label noise presents (Section \ref{sec:emp_analysis}). Following the above observation, we propose the \textbf{F}airness \textbf{R}egularizer (\fr), which encourages the learned classifier to reduce the performance gap between the head and tail sub-populations. As a result, our approach not only improves the performances of tail populations but also improves overall learning performance. Extensive experiments on the CIFAR-10, CIFAR-100, and Clothing1M datasets demonstrate the effectiveness of \fr\ when complemented with certain robust or long-tailed solutions (Section~\ref{sec:exp}). 

Contrary to most existing fairness-accuracy trade-offs observed in the literature \cite{hardt2016equality,menon2018cost,martinez2019fairness,zhao2019inherent,ustun2019fairness,islam2021can}, we show that adding this fairness regularizer alleviates disparate impacts across populations of different sizes and improves the learning from noisily labeled long-tailed data.


\subsection{Related Works}
\paragraph{Learning with Noisy Labels}  
Obtaining perfect annotations in supervised learning is a challenging task \cite{xiao2015learning,luo2020research,wei2021learning}. Due to the restrictions of human recognition, noisy annotations impose challenges to performing robust training. 
A line of popular approaches of learning with label noise firstly estimates the noise transition matrix, and then proceeds to use this knowledge to perform loss or sample correction  \cite{jiang2021information,natarajan2013learning,liu2015classification,patrini2017making,zhu2021clusterability,li2022estimating}, i.e., the surrogate loss uses the transition matrix to define unbiased estimates of the true losses \cite{scott2013classification,natarajan2013learning,scott2015rate,van2015learning,menon2015learning}. Noting that the estimation of the noise transition matrix is non-trivial \cite{zhu2021clusterability,zhu2022beyond}, another line of works aims to propose training methods without requiring knowing the noise rates, e.g., using robust loss functions \cite{kim2019nlnl,liu2020peer,wei2020optimizing,wei2022logit} training deep neural nets directly without the knowledge of noise rates \cite{han2018co,wei2020combating,wei2022mitigating,qin2022robust,cheng2023mitigating}, making use of the early stopping strategy \cite{liu2020early,xia2021robust,liu2022adaptive,liu2022robust,huang2022paddles}, or designing a pipeline which dynamically selects/corrects and trains on "clean" samples with small loss \cite{cheng2021learningsieve,xia2021instance,xia2021sample,jiang2022information,zhang2022noilin}. 
Recent works also explored the possibility of using open-set data to improve the closed-set robustness \cite{wei2021open,xia2022extended}.

\paragraph{Learning with Long-Tailed Data}
The most relevant mainstream solution of learning with long-tailed clean data is the logit/loss adjustment approaches, which modify the loss values during the training procedure, for example, adjust the loss values w.r.t. the label frequency \cite{ren2020balanced}, sample influence \cite{park2021influence}, or the distribution alignment between model prediction and a set of the balanced validation set, among many other solutions. More recently, based on the label frequencies, the logit adjustments over classic approaches \cite{menon2020long} are proposed, either through a post-hoc modification w.r.t. a trained
model or enforcement in the loss during training. Open-set data may also be used to improve complement long-tailed data \cite{wei2021open}. For interested readers, please refer to a comprehensive survey \cite{zhang2021deep}.

Existing robust approaches targeted mainly the class or sub-population level balanced training data. More recently, the literature observed several approaches to address the issue of label-noise in the long-tailed tasks, through decoupled treatments for head classes and tail ones, i.e., detecting noisy labels and performing robust solutions to the head class, meanwhile adopting a self/semi-supervised learning manner to deal with the tail classes \cite{zhong2019unequal,wei2021robust,karthik2021learning}. Beyond classes, it has been demonstrated that sub-populations with different noise rates cause disparate impacts \cite{liu2021importance,zhu2021rich} and need decoupled treatments \cite{zhu2020second,wang2020fair}, which is more crucial for long-tailed sub-populations. 

