\vspace{-1mm}
\section{Related Works on NN-based PDE solvers} \label{section_related_work}
Solving PDEs is a key aspect of scientific research, with a wealth of literature {\citep{evans2022partial}}.
Due to space limitations, a detailed discussion about the classical PDE solvers is deferred to Appendix \ref{appendix_related_work}.
In this section, we focus on the NN-based approaches as they are more related to our research.

As previously mentioned, PINN is possibly the most well-known method of this type.
PINN regards the solution to a PDE system as the root of the corresponding operators $\{\gD_i(\vg)\}_{i=1}^n$, and expresses the time and space boundary conditions as $\gB(\vg) = 0$, where $\vg$ is a candidate solution and $\gD_i$ and $\gB$ are operators acting on $\vg$.
Parameterizing $\vg= \vg_\theta$ using an NN, PINN optimizes its parameters $\theta$ by minimizing the residual $L(\theta) \defi \sum_{i=1}^n\lambda_i\|\gD_i(\vg_\theta)\|_{\gL^2(\X)}^2 + \lambda_0\|\gB(\vg_\theta)\|_{\gL^2(\X)}^2$. The hyperparameters $\lambda_i$ balance the validity of PDEs and boundary conditions under consideration and must be adjusted for optimal performance.
In contrast, \EINN\ requires no hyperparameter tuning.
PINN is versatile and can be applied to a wide range of PDEs, but its performance may not be as good as other NN-based solvers tailored for a particular class of PDEs, as it does not take into account other in-depth properties of the system, a phenomenon observed in the literature \citep{krishnapriyan2021characterizing,wang2}.
\citep{CiCP-28-2042} initiates the work of theoretically establishing the consistency of PINN by considering the {linear} elliptic and parabolic PDEs, for which they prove that a vanishing PINN loss $L(\theta)$ asymptotically implies $\vg_\theta$ recovers the true solution. A similar result is extended to the linear advection equations in \citep{shin2020error}.
Leveraging the stability of the operators $\gD_i$ (corresponding to PDEs of interest), non-asymptotic error estimations are established for linear Kolmogorov equations in \citep{de2022error}, for semi-linear and quasi-linear parabolic equations and the incompressible Euler in \citep{10.1093/imanum/drab093}, and for the NSE in \citep{deerror}. 
We highlight these non-asymptotic results are all average-in-time, meaning that even when the PINN loss is small the deviation of the candidate solution to the true solution may be significant at a particular timestamp $t \in [0, T]$. In comparison, our results are uniform-in-time, i.e. the supremum of the deviation is strictly bounded by the \EINN\ loss. Moreover, we show in Theorem \ref{NSMainEstimate}, for the NSE our error estimation holds for any $T$ uniformly, while the results in \citep{deerror} have an exponential dependence on $T$.

Recent work from \citet{zhang2022drvn} proposes the Random Deep Vortex Network (RDVN) method for solving the 2D NSE and achieves SOTA performance for this task. 
Let $\vu_t^\theta$ be an estimation of the interaction term $K\ast \rho_t$ in the SDE (\ref{eqn_MVE_particle}) and use $\rho_t^\theta$ to denote the law of the particle driven by the SDE $\ud \rmX_t = \vu_t^\theta(\rmX_t) \ud t  + \sqrt{2\nu}  \ud \rmB_t$. To train $\vu_t^\theta$, RDVN minimizes the loss $L(\theta) = \int_0^T\int_\X \|\vu_t^\theta(\vx) - K\ast \rho_t^\theta(\vx)\|^2_{\gL^2}\ud \vx \ud t$. Note that in order to simulate the SDE, one needs to discretize the time variable in loss function $L$. After training $\theta$, RDVN outputs $\rho_t^\theta$ as a solution. However, no error estimation guarantee is provided that controls the discrepancy between $\rho_t^\theta$ and $\rho_t$ using $L(\theta)$. 
% We extend RDVN to solve the MVE with the Coulomb interaction so that it be included as a baseline for that task.




\citet{shen22a} propose the concept of self-consistency for the FPE. However, unlike our work where the \EINN\ loss is derived via the stability analysis, they construct the potential $R(f)$ for the hypothesis velocity field $f$ by observing that the underlying velocity field $f^*$ is the fixed point of some velocity-consistent transformation $\gA$ and they construct $R(f)$ to be a more complicated Sobolev norm of the residual $f - \gA(f)$. In their result, they bound the Wasserstein distance between $\rho^f$ and $\rho$ by $R(f)$, which is weaker than our KL type control. The improved KL type control for the Fokker-Planck equation has also been discussed in \citep{boffi2023probability}. A very recent work \citep{li2023self} extends the self-consistency approach to compute the general Wasserstein gradient flow numerically, without providing further theoretical justification.

