\section{Adjoint Method} \label{appendix_adjoint_method}
Consider the ODE system
\begin{align*}
	\dot s(t) =&\ \psi(s(t), t, \theta) \\
	s(0) =&\ s_0,
\end{align*}
and the objective loss
\begin{equation}
	\ell(\theta) = \int_0^T g(s(t), t, \theta) \ud t.
\end{equation}
The following proposition computes the gradient of $\ell$ w.r.t. $\theta$.
We omit the parameters of the functions for succinctness. We note that all the functions in the integrands should be evaluated at the corresponding time stamp $t$, e.g. $b^\top \frac{\partial h}{\partial \theta}\ud t$ abbreviates for $b(t)^\top \frac{\partial}{\partial \theta}h(\xi(t), x(t), t, \theta)\ud t$.
\begin{proposition}
	\begin{equation}
		\frac{\ud \ell}{\ud \theta} = \int_{0}^T a^\top \frac{\partial\psi}{\partial\theta} + \frac{\partial g}{\partial\theta}\ud t.
	\end{equation}
	where $a(t)$ is solution to the following final value problems
	\begin{equation}
		\dot a^\top + a^\top \frac{\partial\psi}{\partial s} + \frac{\partial g}{\partial s} = 0, a(T) = 0, 
	\end{equation}
\end{proposition}
\begin{proof}
	Let us define the Lagrange multiplier function (or the adjoint state) $a(t)$ dual to $s(t)$.
	Moreover, let $L$ be an augmented loss function of the form
	\begin{equation}
		L = \ell - \int_0^T a^\top(\dot s - \psi) \ud t.
	\end{equation}
	Since we have $\dot s(t) = \psi(s(t), t, \theta)$ by construction, the integral term in $L$ is always null and $a$ can be freely assigned while maintaining $\ud L/\ud \theta = \ud \ell/\ud \theta$.
	Using integral by part, we have
	\begin{equation}
		\int_0^T a^\top\dot s\ \ud t = a(t)^\top s(t)\vert_0^T - \int_0^T s^\top \dot a\ \ud t.
	\end{equation}
	We obtain
	\begin{align}
		L = - a(t)^\top s(t)\vert_0^T + \int_0^T \dot a^\top s + a^\top \psi + g\ \ud t.
	\end{align}
	
	Now we compute the gradient of $L$ w.r.t. $\theta$ as
	\begin{equation*}
		\frac{\ud \ell}{\ud \theta} =  \frac{\ud L}{\ud \theta} = - a(T)^\top\frac{\ud x(T)}{\ud \theta}  + \int_0^T \dot a^\top \frac{\ud s}{\ud \theta} + a^\top \left(\frac{\partial\psi}{\partial\theta} + \frac{\partial\psi}{\partial s} \frac{\ud s}{\ud \theta} \right) \ud t
		+ \int_0^T \frac{\partial g}{\partial s} \frac{\ud s}{\ud \theta} +  \frac{\partial g}{\partial\theta}\ud t,
	\end{equation*}
	which by rearranging terms yields to
	\begin{align*}
		\frac{\ud \ell}{\ud \theta} = \frac{\ud L}{\ud \theta} = - a(T)^\top\frac{\ud x(T)}{\ud \theta} + \int_{0}^T a^\top \frac{\partial \psi}{\partial \theta} +  \frac{\partial g}{\partial \theta}\ud t
		+ \int_0^T \left(\dot a^\top + a^\top \frac{\partial \psi}{\partial s} +  \frac{\partial g}{\partial s}\right)\frac{\ud s}{\ud \theta} \ud t.
	\end{align*}
	Now by taking $a$ satisfying the \emph{final} value problems
	\begin{equation}
		\dot a^\top + a^\top \frac{\partial \psi}{\partial s} + \frac{\partial g}{\partial s} = 0, a(T) = 0, 
	\end{equation}
	we derive the result
	\begin{equation}
		\frac{\ud \ell}{\ud \theta} = \int_{0}^T a^\top \frac{\partial \psi}{\partial \theta} + \frac{\partial g}{\partial \theta}\ud t.
	\end{equation}
\subsection{Writing the Trajectory-wise Loss (\ref{eqn_trajectory_wise_loss}) in an ODE-constrained form} \label{appendix_ODE_constrained_form}
We are now ready to write $R(f_\theta; \vx_0)$ in an ODE-constrained form. Define the state $\vs(t)$, the initial condition $\vs_0$ and the transition function $\psi$ as follows: Let
\begin{equation}
	\vs(t) = \left[\vx(t), \xi(t), \{\vy_i(t)\}_{i=1}^N, \{\zeta_i(t)\}_{i=1}^N\right],
\end{equation}
with $\xi(t) = \nabla\log\rho_t^f(\vx(t))$ and $\zeta_i(t) = \nabla\log\rho_t^f(\vy_i(t))$.  Take  the initial condition 
\begin{equation}
	\vs_0 = \left[\vx_0, \xi_0, \{\vy_i(0)\}_{i=1}^N, \{\zeta_i(0)\}_{i=1}^N\right]
\end{equation}
with $\xi_0 = \nabla\log \bar \rho_0(\vx_0)$, $\zeta_i(0) = \nabla\log\bar\rho_0(\vy_i(0))$, and $\vy_i(0) \stackrel{iid}{\sim} \bar \rho_0$;
and define the function
\begin{equation}
	\psi(t, s(t); \theta) = [f_t(\vx(t); \theta),\ h_t(\vx(t), \xi(t); \theta),\ \{f_t(\vy_i(t); \theta)\}_{i=1}^N,\ \{h_t(\vy_i(t), \zeta_i(t); \theta)\}_{i=1}^N],
\end{equation}
where $h(\va, \vb; \theta) = - \nabla  \left(\udiv f_{t}(\va; \theta)\right) -   \gJ^\top_{f_{t}}(\va; \theta) \vb$ (derived from \eqref{eqn_dynamics_of_score}).
Finally, define
\begin{equation}
	g(t, \vs(t); \theta) = \|f(t, \vx(t); \theta) - \left(-\nabla V(\vx(t)) + E(t, \vs(t)) - \nu \xi(t)\right)\|^2,
\end{equation}
where the estimator $E(t, \vs)$  of the convolution term is defined as
\begin{equation}
	E(t, \vs(t)) = \begin{cases}
		\frac{1}{N} \sum_{i=1}^N K_c(\vx(t) -  \vy_i(t)) & \text{the Coulomb case}, \\
		\frac{1}{N} \sum_{i=1}^N U(\vx - \vy_i(t)) \zeta_i(t) & \text{the Biot-Savart case}.
	\end{cases}
\end{equation}
We recall the definition of $U$ in \eqref{eqn_K_as_divergence} and the definition of $K_c$ in \eqref{eqn_Coulomb_kernel_cutoff}.
\end{proof}