Attention is an intuitive and efficient technique that enables handling local and global cues.

On this basis, the first pure attention architecture, the Transformer~\cite{vaswani2017attention}, has been designed for NLP purposes. Quickly, the Computer Vision field has adapted the Transformer architecture for image classification, by designing the first visual Transformer model: the Vision Transformer (ViT)~\cite{dosovitskiy2020vit}.

However, even if Transformers naturally lead  to high performances, the raw attention mechanism is a computationally greedy and heavy technique. For this reason, several enhanced and refined derivatives of attention mechanisms have been proposed~\cite{deit,convit,cct,swin,perceiverio,jaegle2021perceiver}.

Then, rapidly, a wide variety of other tasks have been conquered by Transformer-based architectures, such as object detection~\cite{carion2020end}, image segmentation~\cite{strudel2021segmenter}, self-supervised learning~\cite{dino,he2021masked} and image generation~\cite{hudson2021generative,zhang2021styleswin}.
%
In addition, Transformer-based architectures are particularly well suited to handle multidimensional tasks.
This is because multimodal signals are easily combined through attention blocks, in particular vision and language cues~\cite{lu_vilbert_2019,ramesh_dalle_2021,clip} and spatio-temporal signals are also easily tamed, as in~\cite{bertasius2021timesformer,arnab2021vivit,jaegle2021perceiver}.

For these reasons, Transformer-based architectures enabled many fields to make tremendous progresses in the last few years.
In the future, Transformers will need to become more and more computationally efficient, e.g. to be usable on cellphones, and will play a huge role to tackle multimodal challenges and bridge together most AI fields. 