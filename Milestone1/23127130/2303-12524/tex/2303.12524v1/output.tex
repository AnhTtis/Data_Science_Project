\documentclass[10pt,conference,a4paper,twocolumn]{IEEEtran}

% Enabled blocked functionality.
\IEEEoverridecommandlockouts 

% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage[dvipsnames]{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
   
% Add a period to the end of an abbreviation unless there's one
% already, then \xspace.
\usepackage{xspace}
\makeatletter
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}

\def\eg{\emph{e.g}\onedot} \def\Eg{\emph{E.g}\onedot}
\def\ie{\emph{i.e}\onedot} \def\Ie{\emph{I.e}\onedot}
\def\cf{\emph{c.f}\onedot} \def\Cf{\emph{C.f}\onedot}
\def\etc{\emph{etc}\onedot} \def\vs{\emph{vs}\onedot}
\def\wrt{w.r.t\onedot} \def\dof{d.o.f\onedot}
\def\etal{\emph{et al}\onedot}
\makeatother

\makeatletter
\def\ps@IEEEtitlepagestyle{%
  \def\@oddfoot{\mycopyrightnotice}%
}
\def\mycopyrightnotice{%
\begin{minipage}{\textwidth}
\centering \footnotesize
Copyright~\copyright~2023 IEEE. Personal use of this material is permitted.  Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.
\end{minipage}
}
\makeatother

% Add a new command for often-used names.
\newcommand{\mname}[0]{\textit{Split-Et-Impera}}
\newcommand{\isplit}{\textsc{I-Split}\xspace}
\newcommand{\cs}{\textsc{CS}\xspace}
\newcommand{\gradcam}{Grad-CAM\xspace}

% Add a new command for each of the authors. Useful for comments at the writing stage.
\usepackage{soul}
\setulcolor{Red}
\newcommand{\mc}[1]{\textcolor{Red}{[M: #1]}}
\newcommand{\luigi}[1]{\textcolor{Blue}{[Luigi: #1]}}
\newcommand{\luca}[1]{\textcolor{OliveGreen}{[Michele: #1]}}
\newcommand{\franco}[1]{\textcolor{Purple}{[Franco: #1]}}
\newcommand{\tiziano}[1]{\textcolor{Yellow}{[Davide: #1]}}
\newcommand{\todo}[1]{\textcolor{Red}{\textbf{TODO: #1}}}


\begin{document}


% V1.
\title{
Split-Et-Impera: A Framework for the Design of Distributed Deep Learning Applications
\thanks{
This project has received funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No. 894237, and has been also partially supported by the Italian Ministry of Education, University and Research (MIUR) with the grant ``Dipartimenti di Eccellenza'' 2018-2022, and by Fondazione Cariverona with the grant ``Ricerca \& Sviluppo''.
}
}


\author{
\IEEEauthorblockN{Luigi Capogrosso, Federico Cunico, Michele Lora, Marco Cristani, Franco Fummi, Davide Quaglia}
\IEEEauthorblockA{\textit{Department of Computer Science, University of Verona, Italy}}
{\tt name.surname@univr.it}
}


\maketitle
%Add space between copyright and text.
\IEEEpubidadjcol


%%%%%%%%% ABSTRACT.
\begin{abstract}
Many recent pattern recognition applications rely on complex distributed architectures in which sensing and computational nodes interact together through a communication network. Deep neural networks (DNNs) play an important role in this scenario, furnishing powerful decision mechanisms, at the price of a high computational effort. Consequently, powerful state-of-the-art DNNs are frequently split over various computational nodes, \eg{}, a first part stays on an embedded device and the rest on a server. Deciding where to split a DNN is a challenge in itself, making the design of deep learning applications even more complicated. Therefore, we propose \mname{}, a novel and practical framework that \textit{i)} determines the set of the best-split points of a neural network based on deep network interpretability principles without performing a tedious try-and-test approach, \textit{ii)} performs a communication-aware simulation for the rapid evaluation of different neural network rearrangements, and \textit{iii)} suggests the best match between the quality of service requirements of the application and the performance in terms of accuracy and latency time. % Experiments validate the proposed framework, and a software prototype has been made available at \url{https://github.com/luigicapogrosso/split_et_impera}.
\end{abstract}


%%%%%%%%% KEYWORDS.
\begin{IEEEkeywords}
Deep Neural Networks, Split Computing, System-Level Design, Communication Networks, Simulation
\end{IEEEkeywords}


%%%%%%%%% BODY TEXT.
\input{src/1_introduction-v3}
\input{src/2_related-v3}
\input{src/3_method-v3}
\input{src/5_experiments-v3}
\input{src/6_conclusions}


% \section*{Acknowledgements}
% The work has been partially supported by the Italian Ministry of Education, University and Research (MIUR) with the grant ``Dipartimenti di Eccellenza'' 2018-2022
% and by Fondazione Cariverona with the grant ``Ricerca \& Sviluppo''.
% This project has received funding from the European Union’s Horizon 2020 research and innovation
% programme under the Marie Sklodowska-Curie grant agreement No 894237.


%%%%%%%%% BIBLIOGRAPHY.
\bibliographystyle{IEEEtran}
\bibliography{bibi}


\end{document}
