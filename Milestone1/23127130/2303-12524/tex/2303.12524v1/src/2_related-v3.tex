\section{Related Work}
\label{sec:related}

This section provides a concise overview of the main architectural typologies used for distributed deep-learning applications. Then, we introduce the state-of-the-art on simulation for distributed DNN architectures.
%More complex solutions can be designed, as it is described in~\cite{Saini2022}. 


%It is worth noting that all frameworks are characterized by the presence of a communication network that organizes information in a sequence of messages according to a predefined protocol and transmits packets onto an actual channel as a sequence of bits between intermediate systems such as switches and routers. Protocols and relaying procedures introduce latency in the information flow and packets may drop due to unrecoverable bit errors or congestion. In \mname{}, we developed the network simulation by using the SCNSL~\cite{fummi2008systemc} library, introducing parameters such as \emph{communication protocol}, \emph{interface speed} \etc{}, (in Sec.\ref{sec:simulator} the details).


%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Distributed deep learning architectures}
We focus on architectures operating through a DNN model $M(\cdot{})$, whose task is to produce the inference output $y$ from an input $x$. %In the literature, can be identified three types of architectures used for distributed deep learning applications, \ie{}, \textit{LC}, \textit{RC}, and \textit{SC}.
Three types of architectures used for distributed deep learning applications can be identified in the literature, \ie{}, \textit{LC}, \textit{RC}, and \textit{SC}.

%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph*{Local computing}
under this policy, the entire computation is performed on the sensing devices, \eg{}, mobile phones, cameras equipped with micro-controller, \etc{} Therefore, the function $M(x)$ is entirely executed by the edge device.

This approach is well-suited for applications characterized by a high data transfer rate, such as automated video analysis~\cite{laureshyn2010application}. It provides low latency since the computing element is very close to the sensor. On the other hand, it does not fit with DNN-based architectures requiring powerful hardware. Usually, simpler DNN models $\bar{M}(x)$ that use specific architectures (\eg{}, depth-wise separable convolutions) are used to build lightweight networks, such as MobileNet~\cite{sandler2018mobilenetv2}. 

%Besides designing lightweight neural models, in the last few years, great progress has been made in the area of DNN compression. Compression techniques, such as network pruning~\cite{reed1993pruning}, quantization~\cite{gholami2021survey}, and knowledge distillation~\cite{gou2021knowledge} achieve a more efficient representation of one or more layers of the neural network, with a possible quality degradation~\cite{menghani2021efficient}.


%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph*{Remote computing}
the input $x$ is transferred through the communication network and then is processed at the remote system through the function $M(x)$.

This architecture preserves full accuracy considering the higher power budget of the remote system, but leads to high latency and consuming bandwidth due to the input transfer~\cite{kim2009cloud}.


%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph*{Split computing}
The SC paradigm divides the DNN model into a head, executed by the sensing device, and a tail executed by the remote system. It combines the advantages of both LC and RC thanks to the lower latency and, more importantly, drastically reduces the required transmission bandwidth by compressing the input to be sent $x$ through the use of an autoencoder~\cite{matsubara2021split}. We define the encoder and decoder models as $z_{l}=F(x)$ and $\bar{x}=G(z_{l})$, which are executed at the edge, and remotely, respectively. The distance $d(x,\bar{x})$ defines the performance of the encoding-decoding process.

%In general, once a given split configuration has been decided, one has to retrain the whole distributed framework, and redo the testing step on the validation data partition. So far, no precise indications (grounded on a solid theory) have been published, resulting in a test and trial routine which takes days. 

In this paper, we consider the theory of~\cite{cunico2022split} (\isplit{}) as a way to suggest which split configuration has to be preferred while avoiding an exhaustive model search. Specifically, our method is closely related to \isplit{} but has three major differences: \textit{i)} we have different motivations, \ie{}, our work is motivated by the proposal of a novel framework that can take into account aspects such as computation time, transmission topology, and protocol, that in \isplit{} are not presented. \textit{ii)} The \isplit{} approach is limited to working on images. Meanwhile, our method generalizes it to be used with any type of signal. \textit{iii)} Our framework performs a communication-aware simulation greatly reducing the time required for the evaluation of SC applications.


%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Simulators for distributed DNN architectures}
A mobile computing system, based on several advanced partition schemes (\eg{}, BODP, MSCC), to enable parallel computation of DNN on mobile platforms is presented in~\cite{mao2017modnn}.

In~\cite{zhao2018deepthings}, is presented a framework for adaptively distributed execution of CNN-based inference. The focus is on the early layers, which largely contribute to the overall latency.

In~\cite{huang2019deepar}, the authors proposed a framework focused on a layer-level partitioning strategy to further improve the overall inference performance in an edge computing scenario.

In~\cite{alwasel2021iotsim}, the authors presented a simulation framework for analyzing and validating osmotic computing. Osmotic computing provides a model for the deployment of IoT in the integrated edge-cloud environment.

None of these simulators is considering all four elements which give a reliable blueprint of the final system (computation time, transmission topology, protocol, and accuracy). Therefore, to the best of our knowledge, we are the first in this respect. Most importantly, we are the first in providing suggested configurations. When using \mname{}, the engineer will just need to select the type of network to be used and its initial parameters (\ie{}, the model has to be trained). Then, the simulator can focus on a few selected alternatives to evaluate, avoiding exhaustive model state searches.
