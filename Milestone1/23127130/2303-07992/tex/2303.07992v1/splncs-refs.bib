@article{bang2023multitask,
  title={A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity},
  author={Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and others},
  journal={arXiv e-prints},
  pages={arXiv--2302},
  year={2023}
}

@article{zhong2023can,
  title={Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT},
  author={Zhong, Qihuang and Ding, Liang and Liu, Juhua and Du, Bo and Tao, Dacheng},
  journal={arXiv e-prints},
  pages={arXiv--2302},
  year={2023}
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}

@article{pramanik2021uniqorn,
  title={UNIQORN: Unified Question Answering over RDF Knowledge Graphs and Natural Language Text},
  author={Pramanik, Soumajit and Alabi, Jesujoba and Saha Roy, Rishiraj and Weikum, Gerhard},
  journal={arXiv e-prints},
  pages={arXiv--2108},
  year={2021}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{kocon2023chatgpt,
  title={ChatGPT: Jack of all trades, master of none},
  author={Koco{\'n}, Jan and Cichecki, Igor and Kaszyca, Oliwier and Kochanek, Mateusz and Szyd{\l}o, Dominika and Baran, Joanna and Bielaniewicz, Julita and Gruza, Marcin and Janz, Arkadiusz and Kanclerz, Kamil and others},
  journal={arXiv e-prints},
  pages={arXiv--2302},
  year={2023}
}

@article{chen2023robust,
  title={How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks},
  author={Chen, Xuanting and Ye, Junjie and Zu, Can and Xu, Nuo and Zheng, Rui and Peng, Minlong and Zhou, Jie and Gui, Tao and Zhang, Qi and Huang, Xuanjing},
  journal={arXiv e-prints},
  pages={arXiv--2303},
  year={2023}
}

@article{zhuo2023exploring,
  title={Exploring AI Ethics of ChatGPT: A Diagnostic Analysis},
  author={Zhuo, Terry Yue and Huang, Yujin and Chen, Chunyang and Xing, Zhenchang},
  journal={arXiv e-prints},
  pages={arXiv--2301},
  year={2023}
}

@article{huang2023chatgpt,
  title={Is ChatGPT better than Human Annotators? Potential and Limitations of ChatGPT in Explaining Implicit Hate Speech},
  author={Huang, Fan and Kwak, Haewoon and An, Jisun},
  journal={arXiv e-prints},
  pages={arXiv--2302},
  year={2023}
}

@article{wang2023can,
  title={Can ChatGPT Write a Good Boolean Query for Systematic Review Literature Search?},
  author={Wang, Shuai and Scells, Harrisen and Koopman, Bevan and Zuccon, Guido},
  journal={arXiv e-prints},
  pages={arXiv--2302},
  year={2023}
}

@article{longpre2021mkqa,
  title={MKQA: A linguistically diverse benchmark for multilingual open domain question answering},
  author={Longpre, Shayne and Lu, Yi and Daiber, Joachim},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={1389--1406},
  year={2021},
  publisher={MIT Press}
}

@article{wang2023cross,
  title={Cross-Lingual Summarization via ChatGPT},
  author={Wang, Jiaan and Liang, Yunlong and Meng, Fandong and Li, Zhixu and Qu, Jianfeng and Zhou, Jie},
  journal={arXiv e-prints},
  pages={arXiv--2302},
  year={2023}
}

@article{qin2023chatgpt,
  title={Is ChatGPT a General-Purpose Natural Language Processing Task Solver?},
  author={Qin, Chengwei and Zhang, Aston and Zhang, Zhuosheng and Chen, Jiaao and Yasunaga, Michihiro and Yang, Diyi},
  journal={arXiv e-prints},
  pages={arXiv--2302},
  year={2023}
}

@article{liang2022holistic,
  title={Holistic Evaluation of Language Models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={arXiv e-prints},
  pages={arXiv--2211},
  year={2022}
}

@article{jiang2020can,
  title={How Can We Know What Language Models Know?},
  author={Jiang, Zhengbao and Xu, Frank F and Araki, Jun and Neubig, Graham},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={423--438},
  year={2020}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{Rae2021scaling,
  title={Scaling Language Models: Methods, Analysis \& Insights from Training Gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv e-prints},
  pages={arXiv--2112},
  year={2021}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{segura2016survey,
  title={A survey on metamorphic testing},
  author={Segura, Sergio and Fraser, Gordon and Sanchez, Ana B and Ruiz-Cort{\'e}s, Antonio},
  journal={IEEE Transactions on software engineering},
  volume={42},
  number={9},
  pages={805--824},
  year={2016},
  publisher={IEEE}
}

@article{chowdhery2022palm,
  title={PaLM: Scaling Language Modeling with Pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv e-prints},
  pages={arXiv--2204},
  year={2022}
}

@article{srivastava2022beyond,
  title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={arXiv e-prints},
  pages={arXiv--2206},
  year={2022}
}

@article{gao2021framework,
  title={A framework for few-shot language model evaluation},
  author={Gao, Leo and Tow, Jonathan and Biderman, Stella and Black, Sid and DiPofi, Anthony and Foster, Charles and Golding, Laurence and Hsu, Jeffrey and McDonell, Kyle and Muennighoff, Niklas and others},
  journal={Version v0. 0.1. Sept},
  year={2021}
}

@article{belinkov2019analysis,
  title={Analysis methods in neural language processing: A survey},
  author={Belinkov, Yonatan and Glass, James},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={49--72},
  year={2019},
  publisher={MIT Press}
}

@article{fu2022does,
  title={How does gpt obtain its ability? tracing emergent abilities of language models to their sources},
  author={Fu, Yao and Peng, Hao and Khot, Tushar},
  journal={Yao Fuâ€™s Notion},
  year={2022}
}

@article{omar2023chatgpt,
  title={ChatGPT versus Traditional Question Answering for Knowledge Graphs: Current Status and Future Directions Towards Knowledge Graph Chatbots},
  author={Omar, Reham and Mangukiya, Omij and Kalnis, Panos and Mansour, Essam},
  journal={arXiv e-prints},
  pages={arXiv--2302},
  year={2023}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={arXiv e-prints},
  pages={arXiv--2203},
  year={2022}
}

@article{frieder2023mathematical,
  title={Mathematical Capabilities of ChatGPT},
  author={Frieder, Simon and Pinchetti, Luca and Griffiths, Ryan-Rhys and Salvatori, Tommaso and Lukasiewicz, Thomas and Petersen, Philipp Christian and Chevalier, Alexis and Berner, Julius},
  journal={arXiv e-prints},
  pages={arXiv--2301},
  year={2023}
}

@article{ngomo20189th,
  title={9th challenge on question answering over linked data (QALD-9)},
  author={Ngomo, Ngonga},
  journal={language},
  volume={7},
  number={1},
  pages={58--64},
  year={2018}
}

%------------------------------------------------------------------------------------

@inproceedings{ribeiro2020beyond,
  title={Beyond Accuracy: Behavioral Testing of NLP Models with CheckList},
  author={Ribeiro, Marco Tulio and Wu, Tongshuang and Guestrin, Carlos and Singh, Sameer},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={4902--4912},
  year={2020}
}

@inproceedings{petroni2019language,
  title={Language Models as Knowledge Bases?},
  author={Petroni, Fabio and Rockt{\"a}schel, Tim and Riedel, Sebastian and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={2463--2473},
  year={2019}
}

@inproceedings{he2021stem,
  title={The Stem Cell Hypothesis: Dilemma behind Multi-Task Learning with Transformer Encoders},
  author={He, Han and Choi, Jinho D},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={5555--5577},
  year={2021}
}

@inproceedings{weichain,
  title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed H and Le, Quoc V and Zhou, Denny and others},
  booktitle={Advances in Neural Information Processing Systems}
}

@inproceedings{kenton2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of NAACL-HLT},
  pages={4171--4186},
  year={2019}
}

@inproceedings{reynolds2021prompt,
  title={Prompt programming for large language models: Beyond the few-shot paradigm},
  author={Reynolds, Laria and McDonell, Kyle},
  booktitle={Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--7},
  year={2021}
}

@inproceedings{qin2021learning,
  title={Learning How to Ask: Querying LMs with Mixtures of Soft Prompts},
  author={Qin, Guanghui and Eisner, Jason},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)},
  year={2021}
}

@inproceedings{wang2019superglue,
  title={SuperGLUE: a stickier benchmark for general-purpose language understanding systems},
  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  booktitle={Proceedings of the 33rd International Conference on Neural Information Processing Systems},
  pages={3266--3280},
  year={2019}
}

@inproceedings{rychalska2019models,
  title={Models in the wild: On corruption robustness of neural nlp systems},
  author={Rychalska, Barbara and Basaj, Dominika and Gosiewska, Alicja and Biecek, Przemys{\l}aw},
  booktitle={Neural Information Processing: 26th International Conference, ICONIP 2019, Sydney, NSW, Australia, December 12--15, 2019, Proceedings, Part III 26},
  pages={235--247},
  year={2019},
  organization={Springer}
}

@inproceedings{wu2019errudite,
  title={Errudite: Scalable, reproducible, and testable error analysis},
  author={Wu, Tongshuang and Ribeiro, Marco Tulio and Heer, Jeffrey and Weld, Daniel S},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={747--763},
  year={2019}
}

@inproceedings{purkayastha2022deep,
  title={A Deep Neural Approach to KGQA via SPARQL Silhouette Generation},
  author={Purkayastha, Sukannya and Dana, Saswati and Garg, Dinesh and Khandelwal, Dinesh and Bhargav, GP Shrivatsa},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2022},
  organization={IEEE}
}

@inproceedings{nie2022graphq,
  title={GraphQ IR: Unifying the Semantic Parsing of Graph Query Languages with One Intermediate Representation},
  author={Nie, Lunyiu and Cao, Shulin and Shi, Jiaxin and Sun, Jiuding and Tian, Qi and Hou, Lei and Li, Juanzi and Zhai, Jidong},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={5848--5865},
  year={2022}
}

@inproceedings{perevalov2022knowledge,
  title={Knowledge Graph Question Answering Leaderboard: A Community Resource to Prevent a Replication Crisis},
  author={Perevalov, Aleksandr and Yan, Xi and Kovriguina, Liubov and Jiang, Longquan and Both, Andreas and Usbeck, Ricardo},
  booktitle={Proceedings of the Thirteenth Language Resources and Evaluation Conference},
  pages={2998--3007},
  year={2022}
}

@inproceedings{ye2022rng,
  title={RNG-KBQA: Generation Augmented Iterative Ranking for Knowledge Base Question Answering},
  author={Ye, Xi and Yavuz, Semih and Hashimoto, Kazuma and Zhou, Yingbo and Xiong, Caiming},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={6032--6043},
  year={2022}
}

@inproceedings{hu2022logical,
  title={Logical form generation via multi-task learning for complex question answering over knowledge bases},
  author={Hu, Xixin and Wu, Xuan and Shu, Yiheng and Qu, Yuzhong},
  booktitle={Proceedings of the 29th International Conference on Computational Linguistics},
  pages={1687--1696},
  year={2022}
}

@inproceedings{dubey2019lc,
  title={LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and DBpedia},
  author={Dubey, Mohnish and Banerjee, Debayan and Abdelkawi, Abdelrahman and Lehmann, Jens},
  booktitle={The Semantic Web--ISWC 2019: 18th International Semantic Web Conference, Auckland, New Zealand, October 26--30, 2019, Proceedings, Part II},
  pages={69--78},
  year={2019}
}

@inproceedings{cao2022kqa,
  title={KQA pro: A dataset with explicit compositional programs for complex question answering over knowledge base},
  author={Cao, Shulin and Shi, Jiaxin and Pan, Liangming and Nie, Lunyiu and Xiang, Yutong and Hou, Lei and Li, Juanzi and He, Bin and Zhang, Hanwang},
  booktitle={PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1:(LONG PAPERS)},
  pages={6101--6119},
  year={2022},
  organization={ASSOC COMPUTATIONAL LINGUISTICS-ACL}
}

@inproceedings{yih2016value,
  title={The value of semantic parse labeling for knowledge base question answering},
  author={Yih, Wen-tau and Richardson, Matthew and Meek, Christopher and Chang, Ming-Wei and Suh, Jina},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={201--206},
  year={2016}
}

@inproceedings{talmor2018web,
  title={The Web as a Knowledge-Base for Answering Complex Questions},
  author={Talmor, Alon and Berant, Jonathan},
  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
  pages={641--651},
  year={2018}
}

@inproceedings{su2016generating,
  title={On generating characteristic-rich question sets for qa evaluation},
  author={Su, Yu and Sun, Huan and Sadler, Brian and Srivatsa, Mudhakar and G{\"u}r, Izzeddin and Yan, Zenghui and Yan, Xifeng},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  pages={562--572},
  year={2016}
}

@inproceedings{gu2021beyond,
  title={Beyond iid: three levels of generalization for question answering on knowledge bases},
  author={Gu, Yu and Kase, Sue and Vanni, Michelle and Sadler, Brian and Liang, Percy and Yan, Xifeng and Su, Yu},
  booktitle={Proceedings of the Web Conference 2021},
  pages={3477--3488},
  year={2021}
}

@inproceedings{berant2013semantic,
  title={Semantic parsing on freebase from question-answer pairs},
  author={Berant, Jonathan and Chou, Andrew and Frostig, Roy and Liang, Percy},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1533--1544},
  year={2013}
}

