\section{Related Work} 

\label{sec:related}

\paragraph{Visual Prompting Tuning.} Prompting is initially proposed in NLP~\cite{brown2020language,liu2021pre}.~\cite{brown2020language} demonstrates strong generalization to downstream transfer learning
tasks even in the few-shot or zero-shot settings with manually chosen
prompts in GPT-3. Recently, prompting~\cite{sandler2022fine,vpt} has been adapted to vision tasks.~\cite{sandler2022fine} proposes memory tokens which is a set of learnable embedding vectors for each transformer layer. VPT~\cite{vpt} proposes similar ideas and investigates the generality and feasibility of visual prompting
via extensive experiments spanning multiple kinds of recognition tasks across multiple domains and backbone architectures. Unlike VPT, whose main focus is on recognition tasks, our work aims at exploring optimal visual content for low-level structure segmentation. 

\paragraph{Forgery Detection.} The goal of forgery detection is to detect pixels that are manually manipulated, such as pixels that are removed, replaced, or edited. Early approaches~\cite{mahdian2009using,lyu2014exposing,fridrich2012rich, cun2018image} detect region splicing through inconsistencies in local noise levels, based on the fact that images of different origins might contain different noise characteristics introduced by the sensors or post-processing steps. Other clues are found to be helpful, such as SIFT~\cite{huang2008detection}, JPEG compression artifacts~\cite{luo2010jpeg} and re-sampling artifacts~\cite{feng2012normalized,popescu2005exposing}. Recently, approaches have moved towards end-to-end deep learning methods for solving specific forensics tasks using labeled training data~\cite{islam2020doa,wu2017deep,zhong2019end,salloum2018image,hu2020span}. Salloum 
\etal~\cite{salloum2018image} learn to detect splicing by training a fully convolutional network on labeled training data.~\cite{wu2017deep,zhong2019end,wu2019mantra,hu2020span,psccnet} propose improved architectures. Islam \etal~\cite{islam2020doa} incorporate Generative Adversarial Network (GAN) to detect copy-move forgeries. Huh \etal~\cite{huh2018fighting} propose to take photographic metadata as a free and plentiful supervisory signal for learning self-consistency and apply the trained model to detect splices. Recently, TransForensic~\cite{hao2021transforensics} leverages vision transformers~\cite{dosovitskiy2020image} to tackle the problem. High-frequency components still served as useful prior in this field. RGB-N~\cite{zhou2018learning} designs an additional noise stream. ObjectFormer~\cite{wang2022objectformer} extracts high-frequency features as complementary signals to visual content. But unlike ObjectFormer, our main focus is to leverage high-frequency components as a prompting design to efficiently and effectively adapt to different low-level segmentation tasks.


\paragraph{Defocus Blur Detection.} Given an image, defocus blur detection aims at separating in-focus and out-of-focus regions, which could be potentially useful for auto-refocus~\cite{bae2007defocus}, salient object detection~\cite{jiang2013salient} and image retargeting~\cite{karaali2016image}. Traditional approaches mainly focus on designing hand-crafted features based on gradient~\cite{shi2014discriminative,yi2016lbp,golestaneh2017hifst} or edge~\cite{karaali2017edge,shi2015just}. In the deep era, most methods delve into CNN architectures~\cite{park2017unified,zhao2019btbnet,tang2019defusionnet,zhao2019cenet}.~\cite{park2017unified} proposes the first CNN-based method using both hand-crafted and deep features. BTBNet~\cite{zhao2019btbnet} develops a fully convolutional network to integrate low-level clues and high-level semantic information. DeFusionNet~\cite{tang2019defusionnet} recurrently fuses and refines multi-scale deep features for defocus blur detection. CENet~\cite{zhao2019cenet} learns multiple smaller defocus blur detectors and ensembles them to enhance diversity.~\cite{cun2020defocus} further employs the depth information as additional supervision and proposes a joint learning framework inspired by knowledge distillation.~\cite{zhao2021defocus} explores deep ensemble networks for defocus blur detection.~\cite{zhao2021self} proposes to learn generator to generate mask in an adversarial manner.

\paragraph{Shadow Detection.} Shadows occur frequently in natural scenes, and have hints for scene geometry~\cite{okabe2009attached}, light conditions~\cite{okabe2009attached} and camera location ~\cite{junejo2008estimating} and lead to challenging cases in many vision tasks including image segmentation~\cite{ecins2014shadow} and object tracking~\cite{cucchiara2003detecting,nadimi2004physical}.
Early attempts explore illumination ~\cite{finlayson2005removal,finlayson2009entropy} and hand-crafted features~\cite{huang2011characterizes,lalonde2010detecting,zhu2010learning}. In the deep era, some methods mainly focus on the design of CNN architectures~\cite{zhu2018bidirectional,cun2020towards} or involving the attention modules~(\emph{e.g.}, the direction-aware attention~\cite{hu2018direction}, distraction-aware module~\cite{zheng2019distraction}). Recent works~\cite{le2018a+,zhu2021mitigating} utilize the lighting as additional prior, for example, ADNet~\cite{le2018a+} generates the adversarial training samples for better detection and FDRNet~\cite{zhu2021mitigating} arguments the training samples by additionally adjusted brightness. MTMT~\cite{mtmt} leverages the mean teacher model to explore unlabeled data for semi-supervised shadow detection.

\paragraph{Camouflaged Object Detection.} 
Detecting camouflaged objects is a challenging task as foreground objects are often with visual similar patterns to the background. Early works distinguish the foreground and background through low-level clues such as texture~\cite{sengottuvelan2008performance,feng2013camouflage}, brightness~\cite{pike2018quantifying}, and color~\cite{hou2011detection}. Recently, deep learning-based methods~\cite{fan2020camouflaged,mei2021camouflaged,li2021uncertainty,lv2021simultaneously,jiaying2022frequency} show their strong ability in detecting complex camouflage objects. Le \etal~\cite{le2019anabranch} propose the first end-to-end network for camouflaged object detection, which is composed of a classification branch and a segmentation branch. Fan \etal~\cite{fan2020camouflaged} develops a search-identification network and the largest camouflaged object detection dataset. PFNet~\cite{mei2021camouflaged} is a bio-inspired framework that mimics the process of positioning and identification in predation. FBNet~\cite{jiaying2022frequency} suggests disentangling frequency modeling and enhancing the important frequency component.