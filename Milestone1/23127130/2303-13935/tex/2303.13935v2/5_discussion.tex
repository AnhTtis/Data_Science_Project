% !TEX root = root.tex

\section{Conclusions and Future Work}
\label{sec:5_discussion}
Our work unifies the SF-GPI and value composition to the continuous concurrent composition framework and allows the reconstruction of true policy from a set of primitives. The proposed method was extended to composition in the action space. In the Pointmass and Pointer environments, we demonstrate that our multi-task agents can approximate the true policy in real time and transfer the skills to solve unseen tasks while the single-task performance is competitive with SAC.
Our framework incorporates well with the reward-shaping techniques \cite{ng1999policy} and provides fine control over each sub-tasks via primitives. 
In addition, the task-agnostic property should benefit the autotelic agent \cite{colas2022autotelic} who can set goals and curriculum for themselves \cite{narvekar2020curriculum}. 
%However, the primary concern at this stage is whether the proposed approach can scale to higher dimensional problems. 
%Additionally, two important topics are left as future works. First, look for the corresponding value composition for DAC. A good starting point might be thinking of the MSF composition with weights evaluated by GPE. 
%Second, the optimality of each composition method. One might start with bounding the loss incurred by the policy and value composition. 