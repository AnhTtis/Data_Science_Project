% !TEX root = root.tex

\section{Related work}
\label{sec:2_related}

The compositionality in continuous control was first exploited by linearly-solvable Markov Decision Processes (LMDPs) \cite{todorov2006linearly}. It can be shown that composing the optimal value function of LMDPs results in the optimal value function in the composite task \cite{todorov2009compositionality}. However, LMDPs were restricted to known dynamics. 

The compositional agents in our framework instead build upon the two transfer learning frameworks: VC and SF-GPI. 
The \textbf{VC}-based methods often exploit the property that the optimal value function of conjunction tasks can be well approximated by the average of the constituent value functions \cite{haarnoja2018composable, hunt2019composing}. Interestingly, boolean 
operators can further expand the valid compositions in the discrete setting and 
achieve a super-exponential amount of task transfer \cite{van2019composing,nangue2020boolean}. However, none of these 
approaches consider concurrent composition scenarios. 

On the other hand, \textbf{SF-GPI} \cite{barreto2020fast} applies successor 
features \cite{dayan1993improving} to estimate a set of Q-functions in the new task. Maximizing these Q-functions results in policy improvement. The results in \cite{barreto2020fast} indicate that simultaneously training several primitives can significantly improve the sample efficiency for solving a new task with collective knowledge. Our work can be seen as an extension to SF-GPI by bringing valid operations from VC to successor feature-enabled concurrent learning. 
 
