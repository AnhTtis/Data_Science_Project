% !TEX root = root.tex

\section{Conclusions and Future Work}
\label{sec:5_discussion}
Our work unifies the SF-GPI and value composition to the continuous concurrent composition framework and allows reconstructing task policy from a set of primitives. The proposed method was extended to composition at the action component level. We demonstrate in the Pointmass environment that our multi-task agents can reconstruct the task policy from a set of primitives in real time and transfer the skills to solve unseen tasks while the single-task performance is competitive with SAC.
This flexible framework incorporates well with the reward-shaping techniques, such as entropy regularization, curiosity\cite{pmlr-v70-pathak17a}, etc. In addition, the task-agnostic property should benefit the autotelic framework \cite{colas2022autotelic} where agents can set goals and curriculum for themselves \cite{narvekar2020curriculum}. 

However, the primary concern at this stage is whether the proposed approach can scale to higher dimensional problems. Additionally, two important topics are left as future works. First, look for the corresponding value composition for DAC. A good starting point might be thinking of the MSF composition with weights evaluated by GPE. 
Second, the optimality of each composition method. One might start with bounding the loss incurred by the policy and value composition. 