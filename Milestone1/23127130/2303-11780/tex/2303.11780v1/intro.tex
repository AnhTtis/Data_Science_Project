\section{Introduction}
\label{sec:intro}
% Recommender systems (RSs) have become one of the leading solutions to the information overload problem on the Web today. Many online platforms, such as shopping sites, video platforms, and social networks, employ recommender systems to help users explore their potential interests and enhance their experience. Sequential recommenders, among various types of RS, are widely deployed to predict the items that users will interact with in the future based on historical behavior sequences.

Recommender systems (RSs) are increasingly popular in addressing the information overload problem on the Web, especially on platforms such as shopping sites, video platforms, and social networks. These systems help users discover items of interest and enhance their user experience. Among the different types of RSs, sequential recommenders are commonly used to predict future item interactions based on historical behavior sequences~\cite{fang2020deep}.

In the past few years, numerous neural network-based methods have been proposed by researchers to effectively model user interest transitions on item sequences. Examples of such methods include using RNNs~\cite{gru4rec, gru4rec2} or attention-based models~\cite{sasrec, bert4rec} to capture users' evolving interests over time, as reflected by their historical item sequences. However, these methods heavily rely on sufficient interaction data and semantically-rich sequences, making them inadequate for addressing issues such as sparsity~\cite{li2020time}, short sequences~\cite{insert}, and noise~\cite{zhang2021causerec} in recommendation.

% In recent years, researchers have proposed many effective neural network-based methods to model the transitions of user interest on item sequences. For example, some researchers use RNN~\cite{gru4rec, gru4rec2} or attention-based~\cite{sasrec, bert4rec} models to model users' evolving interests as reflected by time-aware historical item sequences. In addition, more researchers devise to transform sequences into meaningful graphs and design GNN-based models~\cite{gcsan,srgnn,surge,mtd} to better model the global user interests in the sequence to aid in the prediction of the next item. However, these methods highly depend on dense interaction data and semantically-rich sequences, thus fail to handle sparsity~\cite{li2020time}, short sequence~\cite{insert} and noise~\cite{zhang2021causerec} issues.

% what are the techniques of existing SSL methods

As self-supervised learning (SSL) has proven to be effective in the field of recommender systems~\cite{sgl, kgcl, mhcn, lightgcl}, researchers have sought to leverage this paradigm by introducing contrastive learning tasks into sequential recommendation models~\cite{cl4srec, s3rec, duorec, iclrec}. To incorporate supplementary SSL signals,~\cite{cl4srec,s3rec} utilize various data augmentations on sequences or item features to enforce agreement between the augmented views for embedding contrasting. Other methods~\cite{iclrec, duorec} apply contrastive learning by identifying semantically positive pairs for sequences or items for recommendation.

% As self-supervised learning has shown its effectiveness in recommender systems~\cite{kgcl, sgl, mhcn}, researchers attempt to introduce the contrastive learning task into sequential recommendation models~\cite{cl4srec, s3rec, duorec, iclrec}. To tackle the challenges of data sparsity and short sequence issues, some methods~\cite{cl4srec, iclrec, s3rec} adopt stochastic data augmentations on sequences or item features and force the agreement between the raw view and the augmented view. Some other methods~\cite{iclrec, duorec} perform contrastive learning by finding semantically positive pairs for a sequence or an item. For example, DuoRec~\cite{duorec} takes two sequences as positive pairs if they ends at the same item (Figure~\ref{fig:intro_case}).

Although these methods have shown significant improvements in recommendation performance, we believe that existing methods across various research lines have not adequately addressed the inherent popularity bias in data augmentation. To illustrate this issue, we present a case study using data from the Reddit dataset in Figure~\ref{fig:intro_case}. The figure depicts a user, $U_{860}$, who subscribes to a series of niche basketball topics (shown in blue) and also subscribes to the popular topic ``nba'' (shown in red). Another user, $U_{14463}$, subscribes to a range of popular topics observed from his interaction behaviors, with the ``nba'' topic also included. The first user subscribes to ``nba'' due to their genuine interest in basketball sports, while the second user has shown a preference for popular topics in general. For instance, In DuoRec, these two user sequences are wrongly viewed as positive pairs, regardless of the dominance of the user' behaviors, \eg interest or conformity. This, in turn, leads to inaccurate data augmentation for misleading user preference learning.

Moreover, we note that the predictions for $U_{860}$ generated by our proposed \model\ and the state-of-the-art self-supervised sequential models are dissimilar. Our \model\ proves to be effective in capturing the user's interests, enabling accurate ranking of the ground-truth as the top-ranked result. However, the other two models (\ie, DuoRec, CL4SRec) are susceptible to the influence of popularity bias and produce inaccurate recommendations. Therefore, effectively capturing both the interest and conformity components of user intent and modeling them in a disentangled manner, is crucial to enhancing the performance of sequential recommendation against the prevalent popularity bias in data augmentation.

% Drawbacks of their methods
% While these methods significantly enhance the recommendation performance, we argue that existing methods in different research lines pay less attention to the inherent popularity bias in the data augmentation. 

% We present a motivating case from Reddit dataset in Figure~\ref{fig:intro_case} to address the problem. The user $U_{860}$ subscribed a series niche (\textit{in blue}) topics about basketball and ended up subscribing the popular (\textit{in red}) topic "nba". Another user $U_{14463}$ subscribed a variety of popular topics in her behavior sequence; the last item is also "nba". 

% Obviously, the first user subscribed "nba" because of his real interest in basketball sports. The second user, however, favors many popular topics. 

% In DuoRec, these two user sequences are wrongly viewed as positive pairs, regardless of the dominance of the user' behaviors, \ie interest or conformity. 

% Further, we can observe that predictions for $U_{860}$ made by our proposed \model~and SOTA self-supervised sequential models are significantly different. 

% \model~accurately captures the user interests and ranks the ground-truth as top1. The other two models, however, are affected by popularity bias and fail to make correct rankings. 

% Hence, comprehensively capturing the interest and conformity parts of user intent and modeling them in a disentangled way is key to improving the performance of sequential recommenders against the pervasive popularity bias in the training data.

% To this end, to tackle the challenge, we propose a \textbf{C}ontrastive \textbf{L}earning with \textbf{I}nterest and \textbf{C}onformity \textbf{D}isentanglement (\model) framework for sequential recommendation.

This work proposes \model, a Debiased Contrastive learning framework for sequential Recommendation, to address the limitations mentioned above. Specifically, \model\ integrates contrastive learning with conformity and interest disentanglement to learn augmented representations that are aware of popularity bias. This new paradigm distills informative self-supervision signals for effective augmentation. By integrating relation learning from both sequential and collaborative views, our contrastive learning is conducted across view-specific representations, which can reflect both intra-sequence transitional patterns and inter-sequence global user dependency. Our proposed \model\ disentangles user conformity from noisy item interactions using a multi-channel conformity weighting network, which is based on three semantic channels. The aim of this new approach is to address the issue of bias in the contrastive learning paradigm in recommender systems.

% In light of the above limitations, this work proposes a \textbf{D}ebiased \textbf{C}ontrastive learning framework for sequential \textbf{Rec}ommendation (\model). To be specific, to distill the informative self-supervision signals for effective augmentation, we relate contrastive learning with the conformity and interest disentanglement to learn augmented representations with the awareness of popularity bias. By integrating the relation learning from both sequential and collaborative views, our contrastive learning is conducted across view-specific representations to be reflective of intra-sequence transitional patterns and inter-sequence global user semantics. In our \model, user conformity is disentangled from noisy item interactions through our designed multi-channel conformity weighting network based on three semantic channels to tackle the popularity bias.

In summary, our work makes the following contributions:

\begin{itemize}[leftmargin=*]

\item We highlight the significance of addressing the popularity bias problem in sparse and noisy user sequence data by extracting self-supervision signals in an adaptable way that disentangles user conformity and actual interest for recommendation.

\item We propose a novel recommendation model, called \model, which addresses the issue of popularity bias in user sequence data through a multi-channel conformity weighting network. Furthermore, our model adapts the strength of contrastive regularization to effectively augment the training data.

\item We demonstrate the effectiveness of our proposed method on several real-world datasets, where our method consistently outperforms state-of-the-art sequential recommendation methods while mitigating the effects of popularity bias.


\end{itemize}

% To summarize, our main contributions are as follows:
% \begin{itemize}[leftmargin=*]
%     \item We emphasize the importance of tackling the popularity bias issue from sparse and noisy user sequence data by distilling self-supervision signals in an adaptive manner of disentangling conformity and real interest of the user.
    
%     \item We propose a new recommender system \model\ that automatically determines the strength of contrastive regularization as effective augmentation, with our disentangled conformity.

%     \item Extensive experiments on real-world datasets justify the effectiveness of \model\ by competing with various baselines. In-depth analyses also demonstrate the rationality of \model~design.
    
%     % \item We perform extensive experiments in various research lines on four real-world datasets to verify the superiority of the proposed \model~compared with state-of-the-art baselines. Especially, the results demonstrate that \model~is strong in tackling data sparsity and popularity bias problems.
% \end{itemize}

\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{material/intro_case.pdf}
\vspace{-0.25in}
\caption{A motivating case from the Reddit data illustrates how the lack of attention to popularity bias and user conformity can lead to suboptimal recommendation performance.}
\label{fig:intro_case}
\vspace{-0.22in}
\end{figure}