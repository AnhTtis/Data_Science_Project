\begin{figure*}[htbp]
\centering
    \includegraphics[width=0.9\linewidth]{Figure/pipeline/Pipeline_revise.pdf}
\vspace{-0.5em}
\caption{The framework of our approach. We project a sampled pixel on the input image $\imageGT$ to 3D to get the sampled 3D points $\textbf{p}(t)$ on a ray. Next, the SDF-Net, Validity-Net, and Color-Net take $\textbf{p}(t)$ as the input to predict the signed distance $f(\textbf{p}(t))$, validity probability $\vldty(\textbf{p}(t))$, and the RGB $\clr(\textbf{p}(t))$, respectively. Then our \modelName~ renderer generates the color $\imagePred$ and the mask $\maskPred$ for \netName~ optimization.
In the mesh exportation (testing) stage, we update the SDF by assigning the low-validity points with a nan value, thus preventing the decision boundary from forming at those regions. Finally, we export arbitrary surfaces from the updated SDF with the Marching Cubes Algorithm.
}
\vspace{-0.5em}
\label{fig:pipeline}
\end{figure*}
%\brandon{This figure needs revision in terms of font, size, color, etc. It is ugly now.}
%\weikai{Current version of this figure is too mathematics heavy. The goal of this figure is to demonstrate the high-level idea. There, simply put $f(t)$ instead of $f(0),...,f(t),...$ (this applies to all scenarios). Try to use more figures for illustration (e.g. intermediate results, final results etc.) instead of texts. Show corresponding results in the pipeline as well. }