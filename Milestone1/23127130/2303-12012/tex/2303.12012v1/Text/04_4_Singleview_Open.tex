\input{Figure/comparison_singleview_reconstruction/comparison_singleview_reconstruction}
\vspace{-0.5em}
\subsection{Single View Reconstruction on Open Surfaces}
\vspace{-0.5em}
% We investigate if our method is applicable to arbitrary 3D shape reconstruction from single-view images. 
We construct an autoencoder, which accepts a single image as the input, and exports the 3D mesh as the output. For this experiment, we compare our approach against the state-of-the-art single-view reconstruction method: DVR~\cite{dvr} and the volume rendering based method: NeuS~\cite{wang2021neus}.

% We use the dress subset from \textit{Deep Fashion 3D Dataset}~\cite{zhu2020deep} for this experiment. We randomly select $116$ meshes and $28$ meshes as the training and testing sets, respectively. We render $648$ RGB images and the corresponding masks of resolution $256\times256$ per object as the supervision.
% We randomly sample the viewpoint on the unit-sphere to get diverse supervision data.

The qualitative results is shown in Fig~\ref{fig:comparison_singleview_reconstruction}.
% , and the quantitative results in reported in Table~\ref{}.
Our method is able to infer accurate 3D shape representations from single-view images when only using 2D multi-view images and object masks as supervision.
Qualitatively, in contrast to the DVR~\cite{dvr} and NeuS~\cite{wang2021neus} autoencoder, our method is able to reconstruct open surfaces.
Quantitatively, our method achieves CD = $0.0771$, which outperforms NeuS (CD = $0.0778$) and DVR (CD = $0.0789$) averaged on all the 25 objects from the test set.
% Our results rivals the quality of the conventional multi-view reconstruction approach.
