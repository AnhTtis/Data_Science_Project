\subsection{Experiment Setup}

\paragraph{Tasks and Datasets.}
We validate \modelName~using three types of experiments. 
We first conduct multi-view reconstruction for real-world watertight objects to ensure that \modelName~achieves comparable reconstruction quality on watertight surfaces. We conduct this experiment on 10 scenes from the \textit{DTU Dataset}~\cite{dtu}. Each scene contains $49$ or $64$ RGB images and masks with a resolution of $1600\times 1200$.
Second, we reconstruct open surfaces from multi-view images. We run this experiment on eight categories from the \DFD~\cite{zhu2020deep} and five categories from the \MGN~\cite{bhatnagar2019mgn}, which contain clothes with a wide variety of materials, appearance, and geometry, including challenging cases for reconstruction algorithms, such as camisoles.
Finally, we construct an autoencoder, which takes a single image as the input and provides validation on the challenging task of single-view reconstruction on open surfaces. We conduct this experiment on the \textit{dress} category from the \DFD~\cite{zhu2020deep}. We randomly select 116 objects as the training set and 25 objects as the test set.
All experiments are compared with the SOTA methods for better verification.
{To avoid thin closed reconstructions during the training process, we employ a smaller learning rate for the SDF-Net and a larger learning rate for the Validity-Net.}
Please refer to the implementation of \netName{} in the supplementary.
\vspace{-3mm}

\input{Figure/comparison_open_d3d/comparison_open_d3d_v2}
\vspace{-0.5em}


% \paragraph{Implementation of \netName.} 
% We implement \netName~as follows.
% \textbf{SDF-Net}: We borrowed the implementation of the SDF network in DeepSDF~\cite{deepsdf}, which consists of 8 layers
% with hidden layers of width 512, and a single skip connection from the input to the middle layer. We initialize the parameters of the MLP with geometric initialization~\cite{igr}.
% \noindent\textbf{Color-Net}: We borrowed the implementation of the renderer MLP in IDR~\cite{yariv2020idr}, which consists of 4 layers, with hidden layers of
% width $512$. We apply positional encoding~\cite{mildenhall2020nerf} to improve the learning of high-frequencies.
% \noindent \textbf{Validity-Net}: The MLP consists of 8 layers with Xavier initialization. We used the \textit{ReLU} activation between hidden layers and \textit{Sigmoid} for the output.
% \weikai{Move this paragraph to supplemental.}

\vspace{-0.5mm}


\paragraph{Implementation details.}
For the reconstruction experiments on open surfaces, we render the  ground truth point clouds from \DFD~\cite{zhu2020deep} with Pytorch3D~\cite{ravi2020pytorch3d} at a resolution of $256^2$. To get diverse supervision data, we uniformly sample 648 and 64 viewpoints on the unit sphere for \DFD~and \MGN~(MGN), respectively.
For the single view reconstruction experiment, we uniformly sample 64 viewpoints on the unit sphere as the camera positions.
We use an ResNet-18~\cite{He_2016_CVPR} encoder to predict a latent code $\textbf{z}$ describing the surface's geometry and color. We then use the concatenation of $\{\textbf{z}, \pt\}$ as the input to \netName~(decoder) to evaluate the SDF, validity, and color at the query positions. We optimize the autoencoder by comparing the 2D rendering and the ground truth image. 
In the evaluation stage, we accept a single image as the input and directly export the evaluated SDF and validity as 3D mesh.

\vspace{-1em}
\paragraph{Evaluations.} For multiview reconstruction on watertight surfaces, we measure the Chamfer Distance (CD) with \textit{DTU MVS 2014 evaluation toolkit}~\cite{dtu}. For the reconstruction experiments on open surfaces, we measure the CD with the \textit{PCU} Library~\cite{point-cloud-utils}. For all the experiments, we evaluate the result meshes at resolution $512^3$. 