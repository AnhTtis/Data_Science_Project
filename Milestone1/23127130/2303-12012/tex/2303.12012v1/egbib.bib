@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@article{chen2022ndc,
  title={Neural Dual Contouring}, 
  author={Zhiqin Chen and Andrea Tagliasacchi and Thomas Funkhouser and Hao Zhang},
  journal={ACM Transactions on Graphics (Special Issue of SIGGRAPH)},
  volume = {41},
  number = {4},
  year={2022}
}

@inproceedings{oechsle2021unisurf,
  title={Unisurf: Unifying neural implicit surfaces and radiance fields for multi-view reconstruction},
  author={Oechsle, Michael and Peng, Songyou and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5589--5599},
  year={2021}
}

@article{wang2021neus,
    title={NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction}, 
    author={Peng Wang and Lingjie Liu and Yuan Liu and Christian Theobalt and Taku Komura and Wenping Wang},
    journal={NeurIPS},
    year={2021}
}

@inproceedings{zhu2020deep, 
    title={Deep Fashion3D: A Dataset and Benchmark for 3D Garment Reconstruction from Single Images}, 
    booktitle={Computer Vision -- ECCV 2020},
    author={Heming, Zhu and Yu, Cao and Hang, Jin and Weikai, Chen and Dong, Du and Zhangye, Wang and Shuguang, Cui and Xiaoguang,Han},
    year={2020},
    publisher={Springer International Publishing},
    pages={512--530},
    isbn={978-3-030-58452-8}
}

@article{chen_2022_3psdf,
  title={3PSDF: Three-Pole Signed Distance Function for Learning Surfaces with Arbitrary Topologies},
  author={Chen, Weikai and Lin, Cheng and Li, Weiyang and Yang, Bo},
  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  month={June},
  year={2022}
}

@inproceedings{niemeyer2020differentiable,
  title={Differentiable volumetric rendering: Learning implicit 3d representations without 3d supervision},
  author={Niemeyer, Michael and Mescheder, Lars and Oechsle, Michael and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3504--3515},
  year={2020}
}

@article{yariv2020idr,
  title={Multiview neural surface reconstruction by disentangling geometry and appearance},
  author={Yariv, Lior and Kasten, Yoni and Moran, Dror and Galun, Meirav and Atzmon, Matan and Ronen, Basri and Lipman, Yaron},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2492--2502},
  year={2020}
}

@article{gropp2020implicit,
  title={Implicit geometric regularization for learning shapes},
  author={Gropp, Amos and Yariv, Lior and Haim, Niv and Atzmon, Matan and Lipman, Yaron},
  journal={arXiv preprint arXiv:2002.10099},
  year={2020}
}

@inproceedings{dvr,
    title = {Differentiable Volumetric Rendering: Learning Implicit 3D Representations without 3D Supervision},
    author = {Niemeyer, Michael and Mescheder, Lars and Oechsle, Michael and Geiger, Andreas},
    booktitle = {Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
    year = {2020}
}

@inproceedings{mildenhall2020nerf,
  title={Nerf: Representing scenes as neural radiance fields for view synthesis},
  author={Mildenhall, Ben and Srinivasan, Pratul P and Tancik, Matthew and Barron, Jonathan T and Ramamoorthi, Ravi and Ng, Ren},
  booktitle={European conference on computer vision},
  pages={405--421},
  year={2020},
  organization={Springer}
}

@inproceedings{chen2019learning,
 author = {Chen, Wenzheng and Ling, Huan and Gao, Jun and Smith, Edward and Lehtinen, Jaakko and Jacobson, Alec and Fidler, Sanja},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning to Predict 3D Objects with an Interpolation-based Differentiable Renderer},
 url = {https://proceedings.neurips.cc/paper/2019/file/f5ac21cd0ef1b88e9848571aeb53551a-Paper.pdf},
 volume = {32},
 year = {2019}
}

@inproceedings{bhatnagar2019mgn,
    title = {Multi-Garment Net: Learning to Dress 3D People from Images},
    author = {Bhatnagar, Bharat Lal and Tiwari, Garvita and Theobalt, Christian and Pons-Moll, Gerard},
    booktitle = {{IEEE} International Conference on Computer Vision ({ICCV})},
    month = {oct},
    organization = {{IEEE}},
    year = {2019},
}

@inproceedings{occnet,
    title = {Occupancy Networks: Learning 3D Reconstruction in Function Space},
    author = {Mescheder, Lars and Oechsle, Michael and Niemeyer, Michael and Nowozin, Sebastian and Geiger, Andreas},
    booktitle = {Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
    year = {2019}
}

@article{liu2019softras,
  title={Soft Rasterizer: A Differentiable Renderer for Image-based 3D Reasoning},
  author={Liu, Shichen and Li, Tianye and Chen, Weikai and Li, Hao},
  journal={The IEEE International Conference on Computer Vision (ICCV)},
  month = {Oct},
  year={2019}
}

@inproceedings{sdf0,
  title={Learning implicit fields for generative shape modeling},
  author={Chen, Zhiqin and Zhang, Hao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5939--5948},
  year={2019}
}

@inproceedings{Occupancy_Networks,
  title = {Occupancy Networks: Learning 3D Reconstruction in Function Space},
  author = {Mescheder, Lars and Oechsle, Michael and Niemeyer, Michael and Nowozin, Sebastian and Geiger, Andreas},
  booktitle = {Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
  year = {2019},
  doi = {}
}

@inproceedings{genova2018unsupervised,
  title={Unsupervised training for 3d morphable model regression},
  author={Genova, Kyle and Cole, Forrester and Maschinot, Aaron and Sarna, Aaron and Vlasic, Daniel and Freeman, William T},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8377--8386},
  year={2018}
}

@inproceedings{kato2018neural,
  title={Neural 3d mesh renderer},
  author={Kato, Hiroharu and Ushiku, Yoshitaka and Harada, Tatsuya},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3907--3916},
  year={2018}
}

@InProceedings{kundu20183drcnn,
    author = {Kundu, Abhijit and Li, Yin and Rehg, James M.},
    title = {3D-RCNN: Instance-Level 3D Object Reconstruction via Render-and-Compare},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2018}
}

@InProceedings{Paschalidou_2018_CVPR,
   author = {Paschalidou, Despoina and Ulusoy, Osman and Schmitt, Carolin and Van Gool, Luc and Geiger, Andreas},
   title = {RayNet: Learning Volumetric 3D Reconstruction With Ray Potentials},
   booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   month = {June},
   year = {2018}
   }

@inproceedings{tatarchenko2017octree,
  title={Octree generating networks: Efficient convolutional architectures for high-resolution 3d outputs},
  author={Tatarchenko, Maxim and Dosovitskiy, Alexey and Brox, Thomas},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2088--2096},
  year={2017}
}

@InProceedings{opendr,
author="Loper, Matthew M.
and Black, Michael J.",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="OpenDR: An Approximate Differentiable Renderer",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="154--169",
abstract="Inverse graphics attempts to take sensor data and infer 3D geometry, illumination, materials, and motions such that a graphics renderer could realistically reproduce the observed scene. Renderers, however, are designed to solve the forward process of image synthesis. To go in the other direction, we propose an approximate differentiable renderer (DR) that explicitly models the relationship between changes in model parameters and image observations. We describe a publicly available OpenDR framework that makes it easy to express a forward graphics model and then automatically obtain derivatives with respect to the model parameters and to optimize over them. Built on a new auto-differentiation package and OpenGL, OpenDR provides a local optimization method that can be incorporated into probabilistic programming frameworks. We demonstrate the power and simplicity of programming with OpenDR by using it to solve the problem of estimating human body shape from Kinect depth and RGB data.",
isbn="978-3-319-10584-0"
}

@incollection{igr,
 author = {Gropp, Amos and Yariv, Lior and Haim, Niv and Atzmon, Matan and Lipman, Yaron},
 booktitle = {Proceedings of Machine Learning and Systems 2020},
 pages = {3569--3579},
 title = {Implicit Geometric Regularization for Learning Shapes},
 year = {2020}
}

@INPROCEEDINGS{dtu,
 author={Jensen, Rasmus and Dahl, Anders and Vogiatzis, George and Tola, Engil and Aanæs, Henrik},
 booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition},
 title={Large Scale Multi-view Stereopsis Evaluation},
 year={2014},
 volume={},
 number={},
 pages={406-413},
 doi={10.1109/CVPR.2014.59}
}

@InProceedings{deepsdf,
author = {Park, Jeong Joon and Florence, Peter and Straub, Julian and Newcombe, Richard and Lovegrove, Steven},
title = {DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}

@INPROCEEDINGS{michalkiewicz2019implicit,  author={Michalkiewicz, Mateusz and Pontes, Jhony Kaesemodel and Jack, Dominic and Baktashmotlagh, Mahsa and Eriksson, Anders},  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)},   title={Implicit Surface Representations As Layers in Neural Networks},   year={2019},  volume={},  number={},  pages={4742-4751},  doi={10.1109/ICCV.2019.00484}}

@InProceedings{Atzmon_2020_CVPR,
	author = {Atzmon, Matan and Lipman, Yaron},
	title = {SAL: Sign Agnostic Learning of Shapes From Raw Data},
	booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2020}
	}
	
@inproceedings{chibane2020ndf,
    title = {Neural Unsigned Distance Fields for Implicit Function Learning},
    author = {Chibane, Julian and Mir, Aymen and Pons-Moll, Gerard},
    booktitle = {Advances in Neural Information Processing Systems ({NeurIPS})},
    month = {December},
    year = {2020},
}

@inproceedings{jiang2020sdfdiff,
    author = {Jiang, Yue and Ji, Dantong and Han, Zhizhong and Zwicker, Matthias},
    title = {SDFDiff: Differentiable Rendering of Signed Distance Fields for 3D Shape Optimization},
    booktitle = {The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2020} 
}

@InProceedings{dist,
author = {Liu, Shaohui and Zhang, Yinda and Peng, Songyou and Shi, Boxin and Pollefeys, Marc and Cui, Zhaopeng},
title = {DIST: Rendering Deep Implicit Signed Distance Function With Differentiable Sphere Tracing},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@article{liu2019learning,
  title={Learning to infer implicit surfaces without 3d supervision},
  author={Liu, Shichen and Saito, Shunsuke and Chen, Weikai and Li, Hao},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{pifuSHNMKL19,
  title={PIFu: Pixel-Aligned Implicit Function for 
High-Resolution Clothed Human Digitization},
  author = {Shunsuke Saito and
  and Zeng Huang
  and Ryota Natsume
  and Shigeo Morishima
  and Angjoo Kanazawa
  and Hao Li
  },
  journal={arXiv preprint arXiv:1905.05172},
  year={2019}
}
@inproceedings{disn,
 author = {Xu, Qiangeng and Wang, Weiyue and Ceylan, Duygu and Mech, Radomir and Neumann, Ulrich},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {DISN: Deep Implicit Surface Network for High-quality Single-view 3D Reconstruction},
 url = {https://proceedings.neurips.cc/paper/2019/file/39059724f73a9969845dfe4146c5660e-Paper.pdf},
 volume = {32},
 year = {2019}
}


@inproceedings{NEURIPS2019_f5ac21cd,
 author = {Chen, Wenzheng and Ling, Huan and Gao, Jun and Smith, Edward and Lehtinen, Jaakko and Jacobson, Alec and Fidler, Sanja},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning to Predict 3D Objects with an Interpolation-based Differentiable Renderer},
 url = {https://proceedings.neurips.cc/paper/2019/file/f5ac21cd0ef1b88e9848571aeb53551a-Paper.pdf},
 volume = {32},
 year = {2019}
}

@INPROCEEDINGS{softras,
 author={Liu, Shichen and Chen, Weikai and Li, Tianye and Li, Hao},  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
 title={Soft Rasterizer: A Differentiable Renderer for Image-Based 3D Reasoning},
 year={2019},
 volume={},
 number={},
 pages={7707-7716},
 doi={10.1109/ICCV.2019.00780}
}

@INPROCEEDINGS{8578972,  
 author={Genova, Kyle and Cole, Forrester and Maschinot, Aaron and Sarna, Aaron and Vlasic, Daniel and Freeman, William T.},  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
 title={Unsupervised Training for 3D Morphable Model Regression},   year={2018},
 volume={},
 number={},
 pages={8377-8386},
 doi={10.1109/CVPR.2018.00874}
}

@techreport{shapenet2015,
  title       = {{ShapeNet: An Information-Rich 3D Model Repository}},
  author      = {Chang, Angel X. and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and Xiao, Jianxiong and Yi, Li and Yu, Fisher},
  number      = {arXiv:1512.03012 [cs.GR]},
  institution = {Stanford University --- Princeton University --- Toyota Technological Institute at Chicago},
  year        = {2015}
}

@INPROCEEDINGS{voxnet,
  author={Maturana, Daniel and Scherer, Sebastian},
  booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={VoxNet: A 3D Convolutional Neural Network for real-time object recognition}, 
  year={2015},
  volume={},
  number={},
  pages={922-928},
  doi={10.1109/IROS.2015.7353481}}

@INPROCEEDINGS{7410471,
 author={Su, Hang and Maji, Subhransu and Kalogerakis, Evangelos and Learned-Miller, Erik},  
 booktitle={2015 IEEE International Conference on Computer Vision (ICCV)},   
 title={Multi-view Convolutional Neural Networks for 3D Shape Recognition},   
 year={2015},  
 volume={},  
 number={},  
 pages={945-953},  
 doi={10.1109/ICCV.2015.114}
}

@InProceedings{3dr2n2,
author="Choy, Christopher B.
and Xu, Danfei
and Gwak, JunYoung
and Chen, Kevin
and Savarese, Silvio",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="628--644",
abstract="Inspired by the recent success of methods that employ shape priors to achieve robust 3D reconstructions, we propose a novel recurrent neural network architecture that we call the 3D Recurrent Reconstruction Neural Network (3D-R2N2). The network learns a mapping from images of objects to their underlying 3D shapes from a large collection of synthetic data [13]. Our network takes in one or more images of an object instance from arbitrary viewpoints and outputs a reconstruction of the object in the form of a 3D occupancy grid. Unlike most of the previous works, our network does not require any image annotations or object class labels for training or testing. Our extensive experimental analysis shows that our reconstruction framework (i) outperforms the state-of-the-art methods for single view reconstruction, and (ii) enables the 3D reconstruction of objects in situations when traditional SFM/SLAM methods fail (because of lack of texture and/or wide baseline).",
isbn="978-3-319-46484-8"
}

@INPROCEEDINGS{8099747,  
 author={Fan, Haoqiang and Su, Hao and Guibas, Leonidas},  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   
 title={A Point Set Generation Network for 3D Object Reconstruction from a Single Image},   
 year={2017},  
 volume={},  
 number={},  
 pages={2463-2471},  
 doi={10.1109/CVPR.2017.264}
}

@inproceedings{mandikal20183dlmnet,
 author = {Mandikal, Priyanka and Navaneet, K L and Agarwal, Mayank and Babu, R Venkatesh},
 booktitle = {Proceedings of the British Machine Vision Conference ({BMVC})},
 title = {{3D-LMNet}: Latent Embedding Matching for Accurate and Diverse 3D Point Cloud Reconstruction from a Single Image},
 year = {2018}
}

@inproceedings{lin2018learning,
  title={Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction},
  author={Lin, Chen-Hsuan and Kong, Chen and Lucey, Simon},
  booktitle={AAAI Conference on Artificial Intelligence ({AAAI})},
  year={2018}
}

@INPROCEEDINGS{FoldingNet,  
 author={Yang, Yaoqing and Feng, Chen and Shen, Yiru and Tian, Dong},  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},   
 title={FoldingNet: Point Cloud Auto-Encoder via Deep Grid Deformation},   
 year={2018},  
 volume={},  
 number={},  
 pages={206-215},  
 doi={10.1109/CVPR.2018.00029}
}

@misc{achlioptas2018learning,
 title={Learning Representations and Generative Models for 3D Point Clouds},
 author={Panos Achlioptas and Olga Diamanti and Ioannis Mitliagkas and Leonidas Guibas},
 year={2018},
 url={https://openreview.net/forum?id=BJInEZsTb},
}

@ARTICLE{pixel2mesh,  
 author={Wang, Nanyang and Zhang, Yinda and Li, Zhuwen and Fu, Yanwei and Yu, Hang and Liu, Wei and Xue, Xiangyang and Jiang, Yu-Gang},  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},   
 title={Pixel2Mesh: 3D Mesh Model Generation via Image Guided Deformation},   
 year={2021},  
 volume={43},  
 number={10},  
 pages={3600-3613},  
 doi={10.1109/TPAMI.2020.2984232}
}
 
@inproceedings{atlasnet,
  title={{AtlasNet: A Papier-M\^ach\'e Approach to Learning 3D Surface Generation}},
  author={Groueix, Thibault and Fisher, Matthew and Kim, Vladimir G. and Russell, Bryan and Aubry, Mathieu},
  booktitle={Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@inProceedings{pixel2mesh++,
  title={Pixel2Mesh++: Multi-View 3D Mesh Generation via Deformation},
  author={Chao Wen and Yinda Zhang and Zhuwen Li and Yanwei Fu},
  booktitle={ICCV},
  year={2019}
}

@InProceedings{Venkatesh_2021_ICCV,
    author    = {Venkatesh, Rahul and Karmali, Tejan and Sharma, Sarthak and Ghosh, Aurobrata and Babu, R. Venkatesh and Jeni, L\'aszl\'o A. and Singh, Maneesh},
    title     = {Deep Implicit Surface Point Prediction Networks},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {12653-12662}
}

@article{venkatesh2020dude,
  title={Dude: Deep unsigned distance embeddings for hi-fidelity representation of complex 3d surfaces},
  author={Venkatesh, Rahul and Sharma, Sarthak and Ghosh, Aurobrata and Jeni, Laszlo and Singh, Maneesh},
  journal={arXiv preprint arXiv:2011.02570},
  year={2020}
}

@ARTICLE{BPA,
  author={Bernardini, F. and Mittleman, J. and Rushmeier, H. and Silva, C. and Taubin, G.},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  title={The ball-pivoting algorithm for surface reconstruction},
  year={1999},
  volume={5},
  number={4},
  pages={349-359},
  doi={10.1109/2945.817351}
}

@inproceedings{guillard2021meshudf,
  author = {Guillard, Benoit and Stella, Federico and Fua, Pascal},
  title = {MeshUDF: Fast and Differentiable Meshing of Unsigned Distance Field Networks},
  booktitle = {European Conference on Computer Vision},
  year = {2022}
}

@article{10.1145/37402.37422,
author = {Lorensen, William E. and Cline, Harvey E.},
title = {Marching Cubes: A High Resolution 3D Surface Construction Algorithm},
year = {1987},
issue_date = {July 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {4},
issn = {0097-8930},
url = {https://doi.org/10.1145/37402.37422},
doi = {10.1145/37402.37422},
abstract = {We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer approach to generate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of the original data, normalize it, and use it as a basis for shading the models. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 3D data. Results from computed tomography (CT), magnetic resonance (MR), and single-photon emission computed tomography (SPECT) illustrate the quality and functionality of marching cubes. We also discuss improvements that decrease processing time and add solid modeling capabilities.},
journal = {SIGGRAPH Comput. Graph.},
month = {aug},
pages = {163–169},
numpages = {7}
}

@inproceedings{marching_cubes,
author = {Lorensen, William E. and Cline, Harvey E.},
title = {Marching Cubes: A High Resolution 3D Surface Construction Algorithm},
year = {1987},
isbn = {0897912276},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/37401.37422},
doi = {10.1145/37401.37422},
abstract = {We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer approach to generate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of the original data, normalize it, and use it as a basis for shading the models. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 3D data. Results from computed tomography (CT), magnetic resonance (MR), and single-photon emission computed tomography (SPECT) illustrate the quality and functionality of marching cubes. We also discuss improvements that decrease processing time and add solid modeling capabilities.},
booktitle = {Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques},
pages = {163–169},
numpages = {7},
series = {SIGGRAPH '87}
}

@inproceedings{schoenberger2016sfm,
    author={Sch\"{o}nberger, Johannes Lutz and Frahm, Jan-Michael},
    title={Structure-from-Motion Revisited},
    booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2016},
}

@inproceedings{schoenberger2016mvs,
    author={Sch\"{o}nberger, Johannes Lutz and Zheng, Enliang and Pollefeys, Marc and Frahm, Jan-Michael},
    title={Pixelwise View Selection for Unstructured Multi-View Stereo},
    booktitle={European Conference on Computer Vision (ECCV)},
    year={2016},
}

@InProceedings{colmap,
author="Sch{\"o}nberger, Johannes L.
and Zheng, Enliang
and Frahm, Jan-Michael
and Pollefeys, Marc",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="Pixelwise View Selection for Unstructured Multi-View Stereo",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="501--518",
abstract="This work presents a Multi-View Stereo system for robust and efficient dense modeling from unstructured image collections. Our core contributions are the joint estimation of depth and normal information, pixelwise view selection using photometric and geometric priors, and a multi-view geometric consistency term for the simultaneous refinement and image-based depth and normal fusion. Experiments on benchmarks and large-scale Internet photo collections demonstrate state-of-the-art performance in terms of accuracy, completeness, and efficiency.",
isbn="978-3-319-46487-9"
}

@InProceedings{He_2016_CVPR,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {Deep Residual Learning for Image Recognition},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@article{ravi2020pytorch3d,
    author = {Nikhila Ravi and Jeremy Reizenstein and David Novotny and Taylor Gordon
                  and Wan-Yen Lo and Justin Johnson and Georgia Gkioxari},
    title = {Accelerating 3D Deep Learning with PyTorch3D},
    journal = {arXiv:2007.08501},
    year = {2020},
}

@InProceedings{Ye_2022_CVPR,
    author    = {Ye, Jianglong and Chen, Yuntao and Wang, Naiyan and Wang, Xiaolong},
    title     = {GIFS: Neural Implicit Function for General Shape Representation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {12829-12839}
}

@misc{point-cloud-utils,
  title = {Point Cloud Utils},
  author = {Francis Williams},
  note = {https://www.github.com/fwilliams/point-cloud-utils},
  year = {2022}
}

@article{wang2022hfneus,
  title={HF-NeuS: Improved Surface Reconstruction Using High-Frequency Details},
  author={Wang, Yiqun and Skorokhodov, Ivan and Wonka, Peter},
  journal={arXiv preprint arXiv:2206.07850},
  year={2022}
}

@ARTICLE{li2022voxsurf,
  author={Li, Hai and Yang, Xingrui and Zhai, Hongjia and Liu, Yuqian and Bao, Hujun and Zhang, Guofeng},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Vox-Surf: Voxel-Based Implicit Surface Representation}, 
  year={2022},
  volume={},
  number={},
  pages={1-12},
  doi={10.1109/TVCG.2022.3225844}}

@inproceedings{yariv2021volume,
  title={Volume rendering of neural implicit surfaces},
  author={Yariv, Lior and Gu, Jiatao and Kasten, Yoni and Lipman, Yaron},
  booktitle={Thirty-Fifth Conference on Neural Information Processing Systems},
  year={2021}
}

@InProceedings{long2023neuraludf,
  title={NeuralUDF: Learning Unsigned Distance Fields for Multi-view Reconstruction of Surfaces with Arbitrary Topologies},
  author={Long, Xiaoxiao and Lin, Cheng and Liu, Lingjie and Liu, Yuan and Wang, Peng and Theobalt, Christian and Komura, Taku and Wang, Wenping},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@InProceedings{liu2023neudf,
  title={NeUDF: Leaning Neural Unsigned Distance Fields with Volume Rendering},
  author={Liu, Yu-Tao and Wang, Li and Yang, Jie and Chen, Weikai and Meng, Xiaoxu and Yang, Bo and Gao, Lin},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}