% CVPR 2022 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

% \documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
% \usepackage[review]{cvpr}      % To produce the REVIEW version
\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{url}            % simple URL typesetting
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}       % professional-quality tables
\usepackage{float}
\usepackage{graphicx}
\usepackage{microtype}      % microtypography
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{xcolor}         % colors
\usepackage{mathrsfs}
\usepackage{empheq}
\usepackage{array,multirow}
% \usepackage[accsupp]{axessibility}  % Improves PDF readability for those with disabilities.

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}

\makeatletter
\@namedef{ver@everyshi.sty}{}
\makeatother
\usepackage{tikz}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{2230} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}


\input{Utils/packages}
\input{Utils/macros}
\input{Utils/symbols}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{\modelName{}: Learning Neural Implicit Surfaces with Arbitrary Topologies\\ from Multi-view Images}
\author{Xiaoxu Meng~~~~~~~~Weikai Chen~~~~~~~~Bo Yang\\
Digital Content Technology Center, Tencent Games\\
{\tt\small \{xiaoxumeng,weikaichen,brandonyang\}@global.tencent.com}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
% \and
% Second Author\\
% Institution2\\
% First line of institution2 address\\
% {\tt\small secondauthor@i2.org}
}

% We show three groups of shape reconstruction results generated by NDF [10] (in cyan) and our proposed 3PSDF (in gold)
% respectively. Our method is able to faithfully reconstruct high-fidelity, intricate geometric details including both the closed and open
% surfaces, while NDF suffers from the meshing problems. Each NDF result is reconstructed from a dense point cloud containing 1 million
% points while ours are reconstructed using an equivalent resolution.

\twocolumn[{%
    \renewcommand\twocolumn[1][]{#1}%
    \maketitle
    \begin{center}
    \centering
    \captionsetup{type=figure}
    \includegraphics[width=0.95\textwidth]{Figure/teaser/teaser.pdf}
    \captionof{figure}{
    We show three groups of surface reconstruction from multi-view images. The front and back faces are rendered in blue and yellow respectively. Our method (left) is able to  reconstruct high-fidelity and intricate surfaces of arbitrary topologies, including those non-watertight structures, e.g. the thin single-layer shoulder strap of the top (middle). In comparison, the state-of-the-art NeuS~\cite{wang2021neus} method (right) can only generate watertight surfaces, resulting in thick, double-layer geometries.
    }
    \end{center}%
}]

\input{Text/99_Commands}

\input{Text/00_Abstract}
\input{Text/01_Introduction}
\input{Text/02_RelatedWork}
\input{Text/03_Method}
\input{Text/04_Experiments}
\input{Text/06_Discussion}
\input{Text/07_Conclusion}

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
