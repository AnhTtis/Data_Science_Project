\section{Appendix}


In the Appendix, we elaborate on the following aspects that are not presented in the submission due to space limit: 
\begin{itemize}[leftmargin=*]
    \item \textbf{Source Code and Training Logs:} The code for our implementation on the VDD and 5-datasets benchmarks is available in the directory {\tt artihippo}. Due to size limit, we are not able to upload the pretrained checkpoints. We provide the anonymized training logs of the experiments on the VDD benchmark and the 5-datasets benchmarks in {\tt artihippo/artifacts}. The pretrained checkpoints will be released after the reviewing process.
    \item \textbf{Section \ref{sec:more-identifying-artihippo}: Identifying ArtiHippo in Transformers}: We provide the analysis which leads us to identify the final linear projection layer from the Multi-Head Self-Attention block as the ArtiHippo.
    \item \textbf{Section \ref{sec:ablations}: Ablation Studies}: 
    \begin{itemize}
        \item \textbf{Section \ref{sec:hybrid-adapter}}: We describe the proposed hybrid adapter and an ablation study to verify its effect.
        \item \textbf{Section \ref{sec:artihippo-components}}: We perform ablation experiments on the feasibility of other components of the Vision Transformer, and verify our hypothesis of selecting the final linear projection layer of the MHSA block as the ArtiHippo (Section 3.1 in the main text).
        \item \textbf{Section \ref{sec:exp-expl-sampling}}: Through ablation experiments, we show that the proposed exploration-exploitaiton sampling strategy obtains higher average accuracy and model efficiency, and requires less training epochs for the supernet.
        \item \textbf{Section \ref{sec:param-growth-over-time}}
    \end{itemize}
    \item \textbf{Section \ref{sec:comparison-additional}: Comparison with Additional Methods}: We compare with Elastic Weight Consolidation (EWC, \cite{kirkpatrick-overcoming}), L2 Parameter Regularization \citep{smith2023closer}, and Experience Replay \citep{icarl} for completeness.
    \item \textbf{Section \ref{sec:modification-for-vits}: Modifying dynamic model based methods for vision transformers}: We provide details of our modifications to Supermasks in Superposition (SupSup, \citep{supsup}), Efficient Feature Transformations (EFT, \citep{eft}), and Lightweight Learner (LL, \citep{ll}) for Vision Transformers.
    \item \textbf{Section \ref{sec:task-inc-l2p-sprompt}: Implementation details for S-Prompts and Learn to Prompt}: We describe our implementation of L2P$^\dagger$ and S-Prompts$^\dagger$ used for comparisons, show the results of ablation studies for the number of prompts used in S-Prompts \citep{s-prompts}, and describe how we calculate the number of prompts used in L2P$^\dagger$.
    \item \textbf{Section \ref{sec:dataset-details}: Details of the two benchmarks}: the Visual Domain Decathlon (VDD)~\citep{vdd} benchmark (Section~\ref{sec:vdd}) and the 5-Datasets~\citep{adversarial-continual-learning} benchmark (Section~\ref{sec:5datasets}).
    \item \textbf{Section \ref{sec:base-vit-model}: The Base Model and Its Training Details}: the Vision Transformer (ViT) model specification (ViT-B/8) used in our experiments on the VDD and 5-Dataset benchmarks, and training details on the ImageNet (Section~\ref{sec:imagenet-training}). 
    \item \textbf{Section \ref{sec:background}: Background:} To be self-contained, we give a brief introduction to the learn-to-grow method~\citep{learn-to-grow} in Section~\ref{sec:learn-to-grow-review} and the single-path one-shot (SPOS) neural architecture search (NAS) algorithm~\citep{spos} in Section~\ref{sec:spos}.
    \item \textbf{Section \ref{sec:training-details}: Settings and Hyperparameters in the Proposed Lifelong Learning:} We provide the hyperparameters used for training on the VDD and 5-dataset benchmarks.
    \item \textbf{Section \ref{sec:other-architectures}: Learned architecture with pure exploration and different task order}: We show that with a different task order, the proposed method can still learn to exploit inter-task similarities. We also show that pure exploration cannot effectively exploit task similairties by comparing the learned architecture with the architecture learned using the exploration-exploitation strategy.
     
\end{itemize}