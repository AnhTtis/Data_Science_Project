\section{Related Work and Our Contributions} \vspace{-2mm}
\textit{Experience Replay Based approaches} aim to retain some exemplars from the previous tasks and replay them to the model along with the data from the current task~\citep{gradient-based-sample-selection,mir,large-scale-er,rainbow-memory,hindsight,agem,continual-prototype-evolution,remind,gem,gdumb,icarl,tiny-replay,hayes-icra,dark-experience-replay,large-scale-inc-learning,fast-and-slow,contrastive-continual-learning}. Instead of storing raw exemplars, \textit{Generative replay methods}~\citep{generative-replay,gan-memory} learn the generative process for the data of a task, and replay exemplars sampled from that process along with the data from the current task. For exemplar-free continual learning, \textit{Regularization Based approaches} explicitly control the plasticity of the model by preventing the parameters of the model from deviating too far from their stable values learned on the previous tasks when learning the current task~\citep{what-not-to-forget,selfless-sequential-learning,podnet,variational-continual-learning,kirkpatrick-overcoming,lwf,synaptic-intelligence,progress-and-compress}. Both these approaches aim to balance the stability and plasticity of a fixed-capacity model.

\textit{Dynamic Models} aim to use different parameters per task to avoid use of stored exemplars. Dynamically Expandable Network~\citep{dynamic-expandable-nets} adds neurons to a network based on learned sparsity constraints and heuristic loss thresholds. PathNet~\citep{pathnet} finds task-specific submodules from a dense network, and only trains submodules not used by other tasks. Progressive Neural Networks~\citep{pnn} learn a new network per task and adds lateral connections to the previous tasks' networks.~\citep{vdd} learns residual adapters which are added between the convolutional and batch normalization layers. \citep{network-of-experts} learns an expert network per task by transferring the expert network from the most related previous task. The L2G~\citep{learn-to-grow} uses Differentiable Architecture Search (DARTS~\citep{darts}) to determine if a layer can be reused, adapted, or renewed (3 fundamental skills: {\tt reuse}, {\tt adapt}, {\tt new}) for a task. Our approach is most closely related to Learn to Grow~\citep{learn-to-grow} which can also be interpreted as a Mixture of Experts framework. \citet{task-driven-priors} use task priors derived from a task similarity measure and use those to train a stochastic network and retain some layers of the most similar task, and retrain other layers. \citep{wang-task-difficulty-aware} use a task difficulty metric and threshold hyperparameters to either impose regularization constraints on the previous network, to use the same architecture as the previous tasks, or learn an entirely new architecture and parameters using NAS. Although similar to our method, they rely on (fixed) manually chosen threshold, whereas our method does not have any such heuristics. Dynamic models have also been explored for efficient transfer learning~\citep{nettailor,spottune,piggyback}.

Recently, there has been increasing interest in lifelong learning using Vision Transformers~\citep{learning-to-prompt,dualprompt,meta-attention,pool-of-adapters,dytox,towards-exemplar-free-continual-learning-vits,improving-vits,continual-obj-det-kd,memory-transformer,s-prompts}. \textit{Prompt Based approaches} learn external parameters appended to the data tokens that encode task-specific information useful for classification~\citep{learning-to-prompt,s-prompts,dytox}. Learning to Prompt (L2P)~\citep{learning-to-prompt} learns a pool of prompts and uses a key-value based retrieval to retrieve the correct set of prompts at test time. DualPrompt~\citep{dualprompt} learns generic and task-specific prompts and extends Learning to Prompt.~\citep{meta-attention} uses a ViT pretrained on ImageNet and learns binary masks to enable/disable parameters of the Feedforward Network (FFN), and the attention between image tokens for downstream tasks.

\textbf{Our Contributions} 
We make four main contributions to the field of lifelong learning with ViTs. (i) We propose and identify ArtiHippo in ViTs, i.e., the final projection layers of the multi-head self-attention blocks in a ViT.
We also present a new usage for the class-token in ViTs as the memory growing guidance. (ii) We present a hierarchical task-similarity-oriented exploration-exploitation-sampling-based NAS method for learning to grow ArtiHippo continually with respect to four basic growing operations: {\tt Skip}, {\tt Reuse}, {\tt Adapt}, and {\tt New} to overcome catstrophic forgetting. (iii) We are the first, to the best of our knowledge, to evaluate lifelong learning with ViTs on the large-scale, diverse and imbalanced VDD benchmark~\citep{vdd} with strong empirical performance obtained. We also materialize several state-of-the-art lifelong learning methods that were developed for ConvNets with ViTs on VDD for a comprehensive study.   
(iv) We show that our method is complementary to prompting-based approaches, and combining the two leads to  higher performance.