    



\newpage
\section{Ablation Studies}
\label{sec:ablations} 

\begin{table} [h] %
    \centering
    \caption{Results of ablation study on other components of the ViT used for realizing the CHEEM. The results have been averaged over 3 different seeds.
    }
    \resizebox{\textwidth}{!}{
    \begin{tabular}{l|c|ccccccccc|c|c}
        \toprule
            Component &  ImNet &  C100 &    SVHN &   UCF &  OGlt &  GTSR &  DPed &  Flwr &  Airc. &   DTD &  Avg. Accuracy & Avg. Param. Inc./task (M) \\
        \midrule           
             Projection & $  82.65 $ &    $  90.54 $ &$  96.12 $ &  $  75.53 $ &    $  83.81 $ & $  99.93 $ &         $  99.88 $ &       $  91.21 $ &    $  55.59 $ &$  59.18 $ &   $  83.44 \pm 0.50 $ & $1.06 \pm 0.04$\\ \midrule
           
            Query & $  82.65 $ &    $  89.66 $ &$  93.74 $ &  $  71.53 $ &    $  82.02 $ & $  99.87 $ &         $  99.89 $ &       $  90.03 $ &    $  49.57 $ &$  59.40 $ &   $  81.84 \pm 0.32 $ & $2.38 \pm 0.12$ \\ 
            Key & $  82.65 $ &    $  89.29 $ &$  94.77 $ &  $  72.25 $ &    $  81.86 $ & $  99.86 $ &         $  99.90 $ &       $  88.86 $ &    $  51.72 $ &$  60.46 $ &   $  82.16 \pm 0.17 $ & $2.41 \pm 0.03$ \\ 
             Value & $  82.65 $ &    $  84.94 $ &$  95.90 $ &  $  75.85 $ &    $  84.68 $ & $  99.89 $ &         $  99.89 $ &       $  86.54 $ &    $  48.83 $ &$  55.37 $ &   $  81.46 \pm 0.25 $ & $1.70 \pm 0.11$ \\ \hline 
            FFN & $  82.65 $ &    $  91.05 $ &$  96.08 $ &  $  76.96 $ &    $  85.22 $ & $  99.94 $ &         $  99.94 $ &       $  93.79 $ &    $  56.74 $ &$  59.61 $ &   $  84.20 \pm 0.28$ & $2.31 \pm 0.28$ \\  
        \bottomrule
    \end{tabular}}
    \label{tab:vdd-component-ablation} %
\end{table}

\subsection{CHEEM Placed at Other ViT Components}
\label{sec:CHEEM-components}

Table \ref{tab:vdd-component-ablation} shows the performance comparisons with other four different components in the ViT (the Query/Key/Value linear projection layer and the FFN block) used in realizing the proposed CHEEM. The Query/Key/Value component as the CHEEM does not perform as well as the Projection component. The FFN block as the CHEEM performs only slightly better than the Projection layer, but at the expense of a much larger parameter cost. This reinforces our identification above.


\subsection{Implementation Details of the {\tt Adapt} Operation}
\label{sec:hybrid-adapter}
\paragraph{How to {\tt Adapt} in a sustainable way?} The proposed {\tt Adapt} operation will effectively increase the depth of the network in a plain way. In the worst case, if too many tasks use {\tt Adapt} on top of each other, we will end up stacking too many MLP layers together. This may lead to unstable training due to gradient vanishing. Shortcut connections~\cite{resnet} have been shown to alleviate the gradient vanishing and exploding  problems, making it possible to train deeper networks. We introduce the shortcut connection in adding a MLP {\tt Adapt} operation. We test two different implementations: with shortchut in all the three components (supernet training, target network selection and target network finetuing)  versus with shortcut only in target network finetuning  (i.e., without shortcut in the NAS including both supernet training and target network selection).


\begin{table} [h]
    \centering
    \caption{Results of the ablation study on the implementation of the {\tt Adapt} operation: with (w/) vs without (w/o) shortcut connection for the MLP {\tt Adapt} layer in NAS. The first two rows are for the sequential and continual paradigm and the last two rows for the task-to-task (T2T) transfer based paradigm.}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{l|c|ccccccccc|c|c|c}
        \toprule
            Shortcut in &  \multirow{2}{*}{ImNet} &  \multirow{2}{*}{C100} &    \multirow{2}{*}{SVHN} &   \multirow{2}{*}{UCF} &  \multirow{2}{*}{OGlt} &  \multirow{2}{*}{GTSR} &  \multirow{2}{*}{DPed} &  \multirow{2}{*}{Flwr} &  \multirow{2}{*}{Airc.} &   \multirow{2}{*}{DTD} &  Avg. & Avg. Param. & Avg. FLOPs \\
            NAS & \multicolumn{10}{c|}{} & Accuracy & $\uparrow$/task (M) & $\uparrow$/task (G) \\
        \midrule           
             w/o & $  82.65 $ &    $  90.54 $ &$  96.12 $ &  $  75.53 $ &    $  83.81 $ & $  99.93 $ &         $  99.88 $ &       $  91.21 $ &    $  55.59 $ &$  59.18 $ &   $  83.44 \pm 0.50 $ & $1.06 \pm 0.04$ & $0.17 \pm 0.01$\\ 
             w/ & $  82.65 $ &    $  91.18 $ &$  96.18 $ &  $  82.34 $ &    $  86.03 $ & $  99.91 $ &         $  99.95 $ &       $  91.60 $ &    $  58.90 $ &$  58.56 $ &   $  84.73 \pm 0.19 $ & $2.01 \pm 0.18$ & $0.49 \pm 0.13$ \\ \hline
             w/o (T2T) & $82.65$ & $90.93$ & ${95.96}$ & ${80.74}$ & ${83.25}$ & ${99.94}$ & $99.96$ & $94.12$ & ${58.90}$ & $60.05$ & ${84.65} \pm {0.33}$ & $2.61 \pm 0.15$ & $-0.19 \pm 0.09$ \\
             w/ (T2T) & $82.65$ & $91.24$ & ${99.25}$ & ${84.14}$ & ${85.99}$ & ${99.97}$ & $99.95$ & $94.64$ & ${60.34}$ & $61.63$ & ${85.68} \pm {0.16}$ & $3.23 \pm 0.12$ & $0.01 \pm 0.02$ \\
        \bottomrule
    \end{tabular}}
    \label{tab:vdd-shortcut-ablation} %
\end{table}
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{0.99\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/structure-ee-100-4242.pdf}
        \caption{An example of CHEEM learned \textbf{without} the shortcut for the MLP {\tt Adapt} layer in NAS (the same one as the 2nd row in Fig.~\ref{fig:vdd_arch_seq1_hee}).}
    \end{subfigure}\vspace{1em}
    ~    
    \begin{subfigure}[t]{0.99\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/res-structure-ee-100-4242.pdf}
        \caption{An example of CHEEM learned \textbf{with} the shortcut for the MLP {\tt Adapt} layer in NAS. More {\tt Adapt} on top of {\tt Adapt} operations are learned. }
    \end{subfigure}\vspace{1em}
    \caption{Comparisons between CHEEM learned by two different implementations of the MLP {\tt Adapt} operation under the sequential and continual learning paradigm. \colorbox{skip}{S}, \colorbox{reuse}{R}, \colorbox{adapt}{A} and \colorbox{new}{N} represent {\tt Skip}, {\tt Reuse}, {\tt Adapt} and {\tt New} respectively. 
    }
    \label{fig:residual-adapter-comparison} 
\end{figure}

Table \ref{tab:vdd-shortcut-ablation} shows the performance comparisons on the VDD Benchmark under the continual learning paradigm. In terms of sequentially introduced complexities, a more compact model is learned without the shortcut in the {\tt Adapt} during NAS (supernet training and target network selection) as evidenced by the number of additional parameters and the increase in FLOPs. Using the shortcut in both supernet training and target network selection results in twice the parameter increase, and almost 4$\times$ increase in FLOPs. 
Fig. \ref{fig:residual-adapter-comparison} and Fig.~\ref{fig:residual-adapter-comparison-t2t} show comparisons of the learned CHEEM by the two implementation methods under the two paradigms respectively.

\textbf{Remarks.} We have two remarks as follows. 
\begin{itemize} [leftmargin=*]
    \item We use the more parameter-efficient implementation (i.e., w/o shortcut for the {\tt Adapt} in NAS) in the main paper for both the continual learning and the task-to-task transfer learning paradigms, even though the counterparts have better performance. %
    \item We note that although the T2T paradigm results in larger parameter increase per task, its computational costs are relatively lower due to either more {\tt Skip} operations learned and/or the fact that there is no {\tt Adapt}-on-{\tt Adapt} operations since it is task-to-task transfer based learning.  
\end{itemize}



\begin{figure}[t]
    \centering
    \begin{subfigure}[t]{0.99\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/structure-42-t2t-ee-50-v2.pdf}
        \caption{An example of CHEEM learned \textbf{without} the shortcut for the MLP {\tt Adapt} layer in NAS.}
    \end{subfigure}\vspace{1em}
    ~
    \vspace{1em}
    \begin{subfigure}[t]{0.99\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/res-attn_proj-ee-w-t2t-50-42.pdf}
        \caption{An example of CHEEM learned \textbf{with} the shortcut for the MLP {\tt Adapt} layer in NAS. More {\tt Adapt} operations are learned. }
    \end{subfigure}
    \caption{Comparisons between CHEEM learned by two different implementations of the {\tt Adapt} operation under the task-to-task (T2T) transfer based lifelong learning setting. Here all the 9 tasks are transferred from the base Tsk1\_ImNet model, so we omit the arrows linking the blocks for clarity.  \colorbox{skip}{S}, \colorbox{reuse}{R}, \colorbox{adapt}{A} and \colorbox{new}{N} represent {\tt Skip}, {\tt Reuse}, {\tt Adapt} and {\tt New} respectively. 
    }
    \label{fig:residual-adapter-comparison-t2t} 
\end{figure}
\FloatBarrier

\newpage

\subsection{Effects of Task Orders}\label{sec:task_orders}
We investigate the effects of task orders of the 9 tasks in the VDD benchmark. We test four more task sequences in addition to the one presented in the main paper. Overall, The CHEEM learned by our proposed HEE-based NAS achieve similar performance across different task orders, and consistently significantly outperform those learned by the vanilla PE-based NAS.  

Table~\ref{tab:vdd-sequence-ablation} reports the performance. Fig.~\ref{fig:vdd_arch_seq2_hee}, Fig.~\ref{fig:vdd_arch_seq3_hee}, Fig.~\ref{fig:vdd_arch_seq4_hee} and Fig.~\ref{fig:vdd_arch_seq5_hee} show the learned CHEEM using our proposed HEE-based NAS.

\begin{table} [h!]
    \centering
    \caption{Results of ablation study on CHEEM learning with four different task orders using both our proposed HEE-based NAS and the vanilla PE-based NAS. 
    The results have been averaged over 3 different seeds.
    }
    \resizebox{\textwidth}{!}{
    \begin{tabular}{l|c|ccccccccc|c|c}
        \toprule
            \rowcolor{gray!30} NAS &  ImNet &  OGlt &  UCF &  Airc. &  Flwr &  SVHN &   DTD &  GTSR &  DPed &  C100 &  Avg. Accuracy & Avg. Param. Inc./task (M) \\
        \midrule           
             HEE & $ 82.65 $&    $ 84.32 $&  $ 75.27 $&    $ 54.32 $&       $ 90.29 $&$ 95.83 $&$ 57.89 $& $ 99.92 $&         $ 99.72 $&    $ 89.96 $& $83.02 \pm 0.31$ & $1.25 \pm 0.15$ \\ \midrule
           
            PE & $ 82.65 $&    $ 77.41 $&  $ 70.12 $&    $ 39.40 $&       $ 64.35 $&$ 94.12 $&$ 37.02 $& $ 99.83 $&         $ 99.41 $&    $ 70.78 $& $73.51 \pm 0.80$ & $2.86 \pm 0.14$  \\ 
        \bottomrule
        \toprule
            \rowcolor{gray!30} NAS &  ImNet &  DPed &  SVHN &   DTD &  Airc. &  OGlt &  C100 &  GTSR &  Flwr &  UCF &  Avg. Accuracy & Avg. Param. Inc./task (M) \\
        \midrule           
             HEE & $ 82.66 $&         $ 99.94 $&$ 95.83 $&$ 58.56 $&    $ 42.43 $&    $ 83.55 $&    $ 89.98 $& $ 99.95 $&       $ 91.99 $&  $ 75.67 $& $82.06 \pm 1.28$ & $1.42 \pm 0.05$  \\ \midrule
           
            PE & $ 82.66 $&         $ 99.65 $&$ 95.04 $&$ 45.66 $&    $ 35.87 $&    $ 77.62 $&    $ 71.51 $& $ 99.85 $&       $ 66.11 $&  $ 63.99 $& $73.79 \pm 0.50$ & $2.85 \pm 0.12$  \\ 
        \bottomrule
        \toprule
            \rowcolor{gray!30} NAS &  ImNet &  UCF &  C100 &  OGlt &  GTSR &   DTD &  Flwr &  SVHN &  DPed &  Airc. &  Avg. Accuracy & Avg. Param. Inc./task (M) \\
        \midrule           
             HEE & $ 82.66 $&  $ 79.73 $&    $ 90.75 $&    $ 84.93 $& $ 99.90 $&$ 58.14 $&       $ 91.27 $&$ 96.05 $&         $ 99.89 $&    $ 54.06 $& $83.74 \pm 0.51$ & $1.37 \pm 0.05$  \\ \midrule
           
            PE & $ 82.66 $&  $ 74.49 $&    $ 74.17 $&    $ 78.76 $& $ 99.91 $&$ 41.01 $&       $ 70.49 $&$ 94.15 $&         $ 99.25 $&    $ 37.77 $& $75.27 \pm 2.41$ & $2.75 \pm 0.16$  \\ 
        \bottomrule
        \toprule
            \rowcolor{gray!30} NAS &  ImNet &  Flwr &  UCF &  OGlt &  GTSR &  DPed &  C100 &  Airc. &   DTD &  SVHN &  Avg. Accuracy & Avg. Param. Inc./task (M) \\
        \midrule           
             HEE & $ 82.66 $&       $ 87.52 $&  $ 77.17 $&    $ 84.20 $& $ 99.92 $&         $ 99.80 $&    $ 90.30 $&    $ 54.49 $&$ 56.83 $&$ 96.03 $&   $82.89 \pm 0.58$ & $1.41 \pm 0.09$ \\ \midrule
           
            PE & $ 82.66 $&       $ 72.75 $&  $ 76.31 $&    $ 78.47 $& $ 99.89 $&         $ 99.42 $&    $ 70.09 $&    $ 34.95 $&$ 39.89 $&$ 93.72 $& $74.81 \pm 1.40 $ & $2.70 \pm 0.11$ \\ 
        \bottomrule
    \end{tabular}}
    \label{tab:vdd-sequence-ablation} 
\end{table}

\newpage

\begin{figure}[!ht]
    \centering
    \begin{subfigure}[t]{0.99\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/vdd-order-2.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{1.0\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/structures/attn_proj-ee-seq2-100-4242.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{1.0\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/structures/attn_proj-ee-seq2-100-42.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{1.0\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/structures/attn_proj-ee-seq2-100-424242.pdf}
    \end{subfigure}
    \caption{Examples of the task-synergy memory (CHEEM) learned on the VDD benchmark~\cite{vdd} with the task sequence shown in the top \textbf{using our proposed HEE-based NAS} and three different random seeds. The overall performance is reported in Table~\ref{tab:vdd-sequence-ablation}. \colorbox{skip}{S}, \colorbox{reuse}{R}, \colorbox{adapt}{A} and \colorbox{new}{N} represent {\tt Skip}, {\tt Reuse}, {\tt Adapt} and {\tt New} respectively. The last two columns show the number of new task-specific parameters and added FLOPs respectively, in comparison with the first task, ImNet model. Overall, the learned task synergies make intutive sense and remain relatively stable across different random seeds. }
    \label{fig:vdd_arch_seq2_hee} 
\end{figure}

\newpage

\begin{figure}[!ht]
    \centering
    \begin{subfigure}[t]{0.99\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/vdd-order-3.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{1.0\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/structures/attn_proj-ee-seq3-100-4242.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{1.0\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/structures/attn_proj-ee-seq3-100-42.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{1.0\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/structures/attn_proj-ee-seq3-100-424242.pdf}
    \end{subfigure}
    \caption{Examples of the task-synergy memory (CHEEM) learned on the VDD benchmark~\cite{vdd} with the task sequence shown in the top \textbf{using our proposed HEE-based NAS} and three different random seeds. The overall performance is reported in Table~\ref{tab:vdd-sequence-ablation}. \colorbox{skip}{S}, \colorbox{reuse}{R}, \colorbox{adapt}{A} and \colorbox{new}{N} represent {\tt Skip}, {\tt Reuse}, {\tt Adapt} and {\tt New} respectively. The last two columns show the number of new task-specific parameters and added FLOPs respectively, in comparison with the first task, ImNet model. Overall, the learned task synergies make intutive sense and remain relatively stable across different random seeds. }
    \label{fig:vdd_arch_seq3_hee} 
\end{figure}

\newpage

\begin{figure}[!ht]
    \centering
    \begin{subfigure}[t]{0.99\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/vdd-order-4.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{1.0\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/structures/attn_proj-ee-seq4-100-4242.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{1.0\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/structures/attn_proj-ee-seq4-100-42.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{1.0\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/structures/attn_proj-ee-seq4-100-424242.pdf}
    \end{subfigure}
    \caption{Examples of the task-synergy memory (CHEEM) learned on the VDD benchmark~\cite{vdd} with the task sequence shown in the top \textbf{using our proposed HEE-based NAS} and three different random seeds. The overall performance is reported in Table~\ref{tab:vdd-sequence-ablation}. \colorbox{skip}{S}, \colorbox{reuse}{R}, \colorbox{adapt}{A} and \colorbox{new}{N} represent {\tt Skip}, {\tt Reuse}, {\tt Adapt} and {\tt New} respectively. The last two columns show the number of new task-specific parameters and added FLOPs respectively, in comparison with the first task, ImNet model. Overall, the learned task synergies make intutive sense and remain relatively stable across different random seeds. }
    \label{fig:vdd_arch_seq4_hee} 
\end{figure}

\newpage

\begin{figure}[!ht]
    \centering
    \begin{subfigure}[t]{0.99\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/vdd-order-5.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{1.0\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/structures/attn_proj-ee-seq5-100-4242.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{1.0\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/structures/attn_proj-ee-seq5-100-42.pdf}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{1.0\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/structures/attn_proj-ee-seq5-100-424242.pdf}
    \end{subfigure}
    \caption{Examples of the task-synergy memory (CHEEM) learned on the VDD benchmark~\cite{vdd} with the task sequence shown in the top \textbf{using our proposed HEE-based NAS} and three different random seeds. The overall performance is reported in Table~\ref{tab:vdd-sequence-ablation}. \colorbox{skip}{S}, \colorbox{reuse}{R}, \colorbox{adapt}{A} and \colorbox{new}{N} represent {\tt Skip}, {\tt Reuse}, {\tt Adapt} and {\tt New} respectively. The last two columns show the number of new task-specific parameters and added FLOPs respectively, in comparison with the first task, ImNet model. Overall, the learned task synergies make intutive sense and remain relatively stable across different random seeds. }
    \label{fig:vdd_arch_seq5_hee} 
\end{figure}

\newpage


