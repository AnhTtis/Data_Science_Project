\section{Dataset Details}
\label{sec:dataset-details}
\begin{figure} [h]
\begin{minipage}{0.52\linewidth}
    \includegraphics[width=\textwidth]{figures/vdd-samples.pdf}
    \captionof{figure}{Example images from the VDD benchmark~\cite{vdd}. Each task has a significantly different domain than others, making VDD a challenging benchmark for lifelong learning.}
    \label{fig:vdd-examples}
\end{minipage}
\hfill
\begin{minipage}{0.45\linewidth}
    \centering
    \captionof{table}{The number of samples in training, validation and testing sets per task used in our experiments on the VDD benchmark~\cite{vdd}.}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|c|c|c|c}
  \toprule
  Task & Train & Validation & Test & \#Categories \\
  \midrule
  ImageNet12 & 1108951 & 123216 & 49000 & 1000 \\
  CIFAR100 & 36000 & 4000 & 10000 & 10 \\
  SVHN & 42496 & 4721 & 26040 & 10\\
  UCF & 6827 & 758 & 1952 & 101 \\
  Omniglot & 16068 & 1785 & 6492 & 1623 \\
  GTSR & 28231 & 3136 & 7842 & 43 \\
  DPed & 21168 & 2352 & 5880 & 2 \\
  VGG-Flowers & 918 & 102 & 1020 & 102 \\
  Aircraft & 3001 & 333 & 3333 & 100 \\
  DTD & 1692 & 188 & 1880 & 47 \\
  \bottomrule
\end{tabular}}
    \label{tab:vdd-num-samples}
\end{minipage}
\end{figure}
\subsection{The VDD Benchmark}\label{sec:vdd}
It consists of 10 tasks: ImageNet-1k~\cite{imagenet}, CIFAR100~\cite{cifar}, SVHN~\cite{svhn}, UCF101 Dynamic Images (UCF)~\cite{ucf1,ucf2}, Omniglot~\cite{omniglot}, German Traffic Signs (GTSR)~\cite{gtsrb}, Daimler Pedestrian Classification (DPed)~\cite{daimlerpedcls},  VGG Flowers~\cite{vgg-flowers}, FGVC-Aircraft~\cite{aircraft},    and Describable Textures (DTD)~\cite{dtd}. All the images in the VDD benchmark have been scaled such that the shorter side is 72 pixels. Table~\ref{tab:vdd-num-samples} shows the number of samples in each task. Fig.~\ref{fig:vdd-examples} shows examples of images from each task of the VDD benchmark.
In our experiments, we use 10\% of {\tt the official training data} from each of the tasks for validation (e.g., used in the target network selection in Section 3.2.3 in main text), and report the accuracy on {\tt the official validation set} due to the unavailability of the ground-truth labels for the {\tt official test data}. In Table~\ref{tab:vdd-num-samples}, the \texttt{train, validation} and \texttt{test} splits are thus referred to 90\% of the official training data, 10\% of the official training data, and the entire official validation data respectively. When finetuning the learned architecture (i.e., the searched target network) for each task, we use {\tt the entire  official training data} to train and report results on {\tt the official validation set}.%




\begin{figure} [h]
\begin{minipage}{0.53\linewidth}
    \includegraphics[width=\textwidth]{figures/5-datasets-samples.pdf}
    \captionof{figure}{Example images from the 5-Datasets benchmark~\cite{adversarial-continual-learning}.}
    \label{fig:5-dataset-examples}
\end{minipage}
\hfill
\begin{minipage}{0.4\linewidth}
    \centering
    \captionof{table}{Number of samples in training, validation, and test sets per task in the 5-Datasets benchmark~\cite{adversarial-continual-learning}.
    }
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|c|c|c}
    \toprule
         Task & Train & Validation & Test  \\
         \midrule
         MNIST & 51000 & 9000 & 10000 \\
         not-MNIST & 12733 & 2247 & 3744 \\
         SVHN & 62269 & 10988 & 26032 \\
         CIFAR10 & 42500 & 7500 & 10000 \\
         Fashion MNIST & 51000 & 9000 & 10000 \\
    \bottomrule
    \end{tabular}}
    \label{tab:5-dataset-num-samples}
\end{minipage}
\end{figure}

\subsection{The 5-Datasets Benchmark}\label{sec:5datasets}
It consists of 5 tasks: CIFAR10~\cite{cifar}, MNIST~\cite{mnist}, Fashion-MNIST~\cite{fashion-mnist}, not-MNIST~\cite{notmnist}, and SVHN~\cite{svhn}, all having 10 categories. MNIST, Fashion-MNIST, and not-MNIST have a resolution of $28\times28$, and CIFAR10 and SVHN have a resolution of $32\times32$. We upsample the images to $72\times72$ to match the resolution of the ImageNet images on which the backbone ViT model is trained. Table~\ref{tab:5-dataset-num-samples} shows the data statistics. Fig.~\ref{fig:5-dataset-examples} shows examples of images from each task. To be consistent with the settings used on the VDD benchmark, we use 15\% of \texttt{the training data} for validation and report the results on \texttt{the official test data}, except for not-MNIST for which an official test split is not available. So, for the not-MNIST dataset, we use the small version of that dataset, with which we construct the test set by randomly sampling 20\% of the samples. From the remaining 80\%, we use 15\% for validation, and the rest as the training set.

