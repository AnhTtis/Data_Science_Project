@article{Dempster2022Maximum,
 abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
 author = {A. P. Dempster and N. M. Laird and D. B. Rubin},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {1},
 pages = {1--22},
 title = {Maximum Likelihood from Incomplete Data via the {EM} Algorithm},
 volume = {39},
 year = {1977}
}

@article{Richard2022Mixture,
 abstract = {The problem of estimating the parameters which determine a mixture density has been the subject of a large, diverse body of literature spanning nearly ninety years. During the last two decades, the method of maximum likelihood has become the most widely followed approach to this problem, thanks primarily to the advent of high speed electronic computers. Here, we first offer a brief survey of the literature directed toward this problem and review maximum-likelihood estimation for it. We then turn to the subject of ultimate interest, which is a particular iterative procedure for numerically approximating maximum-likelihood estimates for mixture density problems. This procedure, known as the EM algorithm, is a specialization to the mixture density context of a general algorithm of the same name used to approximate maximum-likelihood estimates for incomplete data problems. We discuss the formulation and theoretical and practical properties of the EM algorithm for mixture densities, focussing in particular on mixtures of densities from exponential families.},
 author = {Richard A. Redner and Homer F. Walker},
 journal = {SIAM Review},
 number = {2},
 pages = {195--239},
 publisher = {Society for Industrial and Applied Mathematics},
 title = {Mixture Densities, Maximum Likelihood and the {EM} Algorithm},
 volume = {26},
 year = {1984}
}

@article{yi2020shrinking,
  title={Shrinking the Covariance Matrix using Convex Penalties on the Matrix-Log Transformation},
  author={Yi, Mengxi and Tyler, David E},
  journal= {Journal of Computational and Graphical Statistics},
  number= 2,
  volume = 30,
  pages={442--451},
  year={2020},
  publisher={Taylor \& Francis}
}
@INPROCEEDINGS{Guorong2001EM,
  author={Guorong Xuan and Wei Zhang and Peiqi Chai},
  booktitle={Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205)}, 
  title={{EM} algorithms of {G}aussian mixture model and hidden {M}arkov model}, 
  year={2001},
  volume={1},
  number={},
  pages={145-148 vol.1}
  }

@incollection{Ingrassia2012Studies,
  title={An {EM} algorithm for the student-t cluster-weighted modeling},
  author={Ingrassia, Salvatore and Minotti, Simona C and Incarbone, Giuseppe},
  booktitle={Challenges at the Interface of Data Analysis, Computer Science, and Optimization},
  pages={13--21},
  year={2012},
  publisher={Springer}
}


@article{Teimour2021EM,
author = {Mahdi Teimouri},
title = {{EM} algorithm for mixture of skew-normal distributions fitted to grouped data},
journal = {Journal of Applied Statistics},
volume = {48},
number = {7},
pages = {1154-1179},
year  = {2021}
}
@inproceedings{houdouin2022robust,
  title={Robust classification with flexible discriminant analysis in heterogeneous data},
  author={Houdouin, Pierre and Wang, Andrew and Jonckheere, Matthieu and Pascal, Fr{\'e}d{\'e}ric},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5717--5721},
  year={2022},
  organization={IEEE}
}
@article{roizman2019flexible,
  title={A flexible {EM}-like clustering algorithm for noisy data},
  author={Roizman, Violeta and Jonckheere, Matthieu and Pascal, Fr{\'e}d{\'e}ric},
  journal={arXiv preprint arXiv:1907.01660},
  year={2019}
}
@misc{Yi2015Regularized,
  doi = {10.48550/ARXIV.1511.08551},
  url = {https://arxiv.org/abs/1511.08551},
  author = {Yi, Xinyang and Caramanis, Constantine},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Regularized EM Algorithms: A Unified Framework and Statistical Guarantees},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Cai2017CHIME,
author = {Cai, T and Ma, Jing and Zhang, Linjun},
year = {2019},
volume = {47}, 
number = {3},
 pages={1234--1267},
title = {{CHIME}: Clustering of high-dimensional Gaussian mixtures with {EM} algorithm and its optimality},
journal = {Annals of Statistics}
}

@article{Ying2014Regularized,
	year = 2014,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {62},
	number = {19},
	pages = {5143--5156},
	author = {Ying Sun and Prabhu Babu and Daniel P. Palomar},
	title = {Regularized {T}yler{\textquotesingle}s Scatter Estimator: Existence, Uniqueness, and Algorithms},
	journal = {{IEEE} Transactions on Signal Processing}
}

@article{Ledoit2004A,
  title={A well-conditioned estimator for large-dimensional covariance matrices},
  author={Ledoit, Olivier and Wolf, Michael},
  journal={Journal of multivariate analysis},
  volume={88},
  number={2},
  pages={365--411},
  year={2004},
  publisher={Elsevier}
}

@ARTICLE{Ollila2019Optimal,
  author={Ollila, Esa and Raninen, Elias},
  journal={IEEE Transactions on Signal Processing}, 
  title={Optimal Shrinkage Covariance Matrix Estimation Under Random Sampling From Elliptical Distributions}, 
  year={2019},
  volume={67},
  number={10},
  pages={2707-2719}
  }
  
  @article{ollila2021shrinking,
  title={Shrinking the eigenvalues of {M}-estimators of covariance matrix},
  author={Ollila, Esa and Palomar, Daniel P. and Pascal, Fr{\'e}d{\'e}ric},
  journal={{IEEE} Transactions on Signal Processing},
  volume = {69},
  pages = {256--269},
  year = {2021}
}
@article{pascal2014generalized,
  title={Generalized robust shrinkage estimator and its application to {STAP} detection problem},
  author={Pascal, Fr{\'e}d{\'e}ric and Chitour, Yacine and Quek, Yihui},
  journal= {{IEEE} Transactions on Signal Processing},
  volume={62},
  number={21},
  pages={5640--5651},
  year={2014},
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@misc{McDaid2011Normalized,
  doi = {10.48550/ARXIV.1110.2515},
  url = {https://arxiv.org/abs/1110.2515},
  author = {McDaid, Aaron F. and Greene, Derek and Hurley, Neil},
  keywords = {Physics and Society (physics.soc-ph), Social and Information Networks (cs.SI), Data Analysis, Statistics and Probability (physics.data-an), FOS: Physical sciences, FOS: Physical sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Normalized Mutual Information to evaluate overlapping community finding algorithms},
  publisher = {arXiv},
  year = {2011},
  copyright = {Creative Commons Attribution 3.0 Unported}
}
