\section{Conclusion}
\label{conclusion}
We have presented RICO, a novel approach for compositional reconstruction in indoor scenes. 
Our key motivation is to regularize the unobservable regions for the objects with partial observations in indoor scenes. 
We exploit the geometry smoothness for the occluded background, and then adopt the improved background as the prior to regularize the objects' geometry. Our experimental results prove that our method achieves compositional reconstruction with fewer artifacts and watertight object geometry, which further facilitates applicable applications like object manipulation.

\boldparagraph{Future work} 
% Currently, each object's pose is baked with its geometry. We identify learning the shape and pose separately as potential direction for more flexible applications.
Currently, each object's pose is baked with its geometry. An interesting future direction would be represent each object in scene as the combination of its own canonical coordinates and the pose, \ie the rotated 3D bounding box in the world coordinate. With these disentangled representations, we can cast more regularizations from the shape and box perspectives, and the disentanglement also allows more flexible downstream applications.
Another interesting direction would be developing more semantic-based prior knowledge for systemic regularization. Now the geometry motivated regularizations are lack of the understanding of the actual shape of each object. With the general knowledge emerged in recent large vision-language model, like StableDiffusion, it's interesting to distill its knowledge in our compositional reconstruction task. The learnt semantic knowledge can provide a holistic understanding of each object and provide a more comprehensive regularization.

\boldparagraph{Acknowledgements} We thank Kechun Xu and Huaijin Pi for detailed feedback on the paper. We thank all authors and reviewers for the contributions. This work is in part supported by a Grant from the National Natural Science Foundation of China~(No.U21A20484), the NSFC under grant U21B2004, 62202418, and the Zhejiang University Education Foundation Qizhen Scholar Foundation.