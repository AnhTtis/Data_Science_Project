@article{campa2009,
title = {Statistical mechanics and dynamics of solvable models with long-range interactions},
journal = {Physics Reports},
volume = {480},
number = {3},
pages = {57-159},
year = {2009},
issn = {0370-1573},
doi = {https://doi.org/10.1016/j.physrep.2009.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0370157309001586},
author = {Alessandro Campa and Thierry Dauxois and Stefano Ruffo},
keywords = {Long-range interactions, Ensemble inequivalence, Negative specific heat, Ergodicity breaking, Vlasov equation, Quasi-stationary states},
abstract = {For systems with long-range interactions, the two-body potential decays at large distances as V(r)∼1/rα, with α≤d, where d is the space dimension. Examples are: gravitational systems, two-dimensional hydrodynamics, two-dimensional elasticity, charged and dipolar systems. Although such systems can be made extensive, they are intrinsically non additive: the sum of the energies of macroscopic subsystems is not equal to the energy of the whole system. Moreover, the space of accessible macroscopic thermodynamic parameters might be non convex. The violation of these two basic properties of the thermodynamics of short-range systems is at the origin of ensemble inequivalence. In turn, this inequivalence implies that specific heat can be negative in the microcanonical ensemble, and temperature jumps can appear at microcanonical first order phase transitions. The lack of convexity allows us to easily spot regions of parameter space where ergodicity may be broken. Historically, negative specific heat had been found for gravitational systems and was thought to be a specific property of a system for which the existence of standard equilibrium statistical mechanics itself was doubted. Realizing that such properties may be present for a wider class of systems has renewed the interest in long-range interactions. Here, we present a comprehensive review of the recent advances on the statistical mechanics and out-of-equilibrium dynamics of solvable systems with long-range interactions. The core of the review consists in the detailed presentation of the concept of ensemble inequivalence, as exemplified by the exact solution, in the microcanonical and canonical ensembles, of mean-field type models. Remarkably, the entropy of all these models can be obtained using the method of large deviations. Long-range interacting systems display an extremely slow relaxation towards thermodynamic equilibrium and, what is more striking, the convergence towards quasi-stationary states. The understanding of such unusual relaxation process is obtained by the introduction of an appropriate kinetic theory based on the Vlasov equation. A statistical approach, founded on a variational principle introduced by Lynden-Bell, is shown to explain qualitatively and quantitatively some features of quasi-stationary states. Generalizations to models with both short and long-range interactions, and to models with weakly decaying interactions, show the robustness of the effects obtained for mean-field models.}
}

@article{kohnke2020,
author = {Kohnke, Bartosz and Kutzner, Carsten and Grubmüller, Helmut},
title = {A GPU-Accelerated Fast Multipole Method for GROMACS: Performance and Accuracy},
journal = {Journal of Chemical Theory and Computation},
volume = {16},
number = {11},
pages = {6938-6949},
year = {2020},
doi = {10.1021/acs.jctc.0c00744},
    note ={PMID: 33084336},

URL = { 
        https://doi.org/10.1021/acs.jctc.0c00744
    
},
eprint = { 
        https://doi.org/10.1021/acs.jctc.0c00744
    
}

}

@article{yildirim2015,
author = {Yildirim, Handan and Matos, Jeronimo and Kara, Abdelkader},
title = {Role of Long-Range Interactions for the Structure and Energetics of Olympicene Radical Adsorbed on Au(111) and Pt(111) Surfaces},
journal = {The Journal of Physical Chemistry C},
volume = {119},
number = {45},
pages = {25408-25419},
year = {2015},
doi = {10.1021/acs.jpcc.5b08191},

URL = { 
        https://doi.org/10.1021/acs.jpcc.5b08191
    
},
eprint = { 
        https://doi.org/10.1021/acs.jpcc.5b08191
    
}

}

@book{tuckerman2010,
  title={Statistical Mechanics: Theory and Molecular Simulation},
  author={Tuckerman, M.},
  isbn={9780191523465},
  lccn={2010278327},
  series={Oxford Graduate Texts},
  url={https://books.google.de/books?id=Lo3Jqc0pgrcC},
  year={2010},
  publisher={OUP Oxford}
}

@article{arnold2013,
  title = {Comparison of scalable fast methods for long-range interactions},
  author = {Arnold, Axel and Fahrenberger, Florian and Holm, Christian and Lenz, Olaf and Bolten, Matthias and Dachsel, Holger and Halver, Rene and Kabadshow, Ivo and G\"ahler, Franz and Heber, Frederik and Iseringhausen, Julian and Hofmann, Michael and Pippig, Michael and Potts, Daniel and Sutmann, Godehard},
  journal = {Phys. Rev. E},
  volume = {88},
  issue = {6},
  pages = {063308},
  numpages = {22},
  year = {2013},
  month = {Dec},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.88.063308},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.88.063308}
}

@article{toukmaji1996,
title = {Ewald summation techniques in perspective: a survey},
journal = {Computer Physics Communications},
volume = {95},
number = {2},
pages = {73-92},
year = {1996},
issn = {0010-4655},
doi = {https://doi.org/10.1016/0010-4655(96)00016-1},
url = {https://www.sciencedirect.com/science/article/pii/0010465596000161},
author = {Abdulnour Y. Toukmaji and John A. Board},
keywords = {Ewald summation, Fast multipole algorithm, Particle-mesh algorithms, Periodic boundary conditions, Molecular dynamics, Algorithms},
abstract = {The simulation of large macromolecular systems has been and remains a challenging problem. There is a general presumption that simulations carried in periodic boundary conditions (PBC) are often the most appropriate to suppress boundary effects. To this end, Ewald summation has been employed to handle long ranged interactions in PBC. There has been a great deal of research targeted at improving the efficiency of Ewald summation, an O(N2) algorithm in its traditional formulation, where N is the number of particles in the system. This paper reviews Ewald summation techniques by surveying conventional as well as state of the art efficient methods. Conventional methods, such as tabulation and approximation, are first re-examined along with an O(N32) method. Fourier-based approaches which have reduced the complexity to O(N log(N)) are presented. Multipole expansion techniques, suggested as an alternative to Ewald sums, are reviewed and compared to Fourier methods. The computational efficiency of these new methods facilitates longer, larger and more realistic simulations.}
}

@article{harvey2009,
author = {Harvey, M. J. and De Fabritiis, G.},
title = {An Implementation of the Smooth Particle Mesh Ewald Method on GPU Hardware},
journal = {Journal of Chemical Theory and Computation},
volume = {5},
number = {9},
pages = {2371-2377},
year = {2009},
doi = {10.1021/ct900275y},
    note ={PMID: 26616618},

URL = { 
        https://doi.org/10.1021/ct900275y
    
},
eprint = { 
        https://doi.org/10.1021/ct900275y
    
}

}

@ARTICLE{rockmore2000,

  author={Rockmore, D.N.},

  journal={Computing in Science   Engineering}, 

  title={The FFT: an algorithm the whole family can use}, 

  year={2000},

  volume={2},

  number={1},

  pages={60-64},

  doi={10.1109/5992.814659}}

@ARTICLE{frigo2005,

  author={Frigo, M. and Johnson, S.G.},

  journal={Proceedings of the IEEE}, 

  title={The Design and Implementation of FFTW3}, 

  year={2005},

  volume={93},

  number={2},

  pages={216-231},

  doi={10.1109/JPROC.2004.840301}}

@article{jung2016,
title = {Parallel implementation of 3D FFT with volumetric decomposition schemes for efficient molecular dynamics simulations},
journal = {Computer Physics Communications},
volume = {200},
pages = {57-65},
year = {2016},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2015.10.024},
url = {https://www.sciencedirect.com/science/article/pii/S0010465515004063},
author = {Jaewoon Jung and Chigusa Kobayashi and Toshiyuki Imamura and Yuji Sugita},
keywords = {Fast Fourier Transform (FFT), Volumetric decomposition, Molecular dynamics (MD) simulation, Particle mesh Ewald (PME) calculation, Midpoint cell method, Hybrid (MPI+OpenMP) parallelization},
abstract = {Three-dimensional Fast Fourier Transform (3D FFT) plays an important role in a wide variety of computer simulations and data analyses, including molecular dynamics (MD) simulations. In this study, we develop hybrid (MPI+OpenMP) parallelization schemes of 3D FFT based on two new volumetric decompositions, mainly for the particle mesh Ewald (PME) calculation in MD simulations. In one scheme, (1d_Alltoall), five all-to-all communications in one dimension are carried out, and in the other, (2d_Alltoall), one two-dimensional all-to-all communication is combined with two all-to-all communications in one dimension. 2d_Alltoall is similar to the conventional volumetric decomposition scheme. We performed benchmark tests of 3D FFT for the systems with different grid sizes using a large number of processors on the K computer in RIKEN AICS. The two schemes show comparable performances, and are better than existing 3D FFTs. The performances of 1d_Alltoall and 2d_Alltoall depend on the supercomputer network system and number of processors in each dimension. There is enough leeway for users to optimize performance for their conditions. In the PME method, short-range real-space interactions as well as long-range reciprocal-space interactions are calculated. Our volumetric decomposition schemes are particularly useful when used in conjunction with the recently developed midpoint cell method for short-range interactions, due to the same decompositions of real and reciprocal spaces. The 1d_Alltoall scheme of 3D FFT takes 4.7 ms to simulate one MD cycle for a virus system containing more than 1 million atoms using 32,768 cores on the K computer.}
}

@article{kolda2009,
author = {Kolda, Tamara and Bader, Brett},
year = {2009},
month = {08},
pages = {455-500},
title = {Tensor Decompositions and Applications},
volume = {51},
journal = {SIAM Review},
doi = {10.1137/07070111X}
}

@article{sedukhin2015,
author = {Sedukhin, Stanislav and Sakai, T. and Nakasato, Naohito},
year = {2015},
month = {01},
pages = {193-200},
title = {3D discrete transforms with cubical data decomposition on the IBM Blue Gene/Q},
journal = {Proceedings of the 30th International Conference on Computers and Their Applications, CATA 2015}
}

@InProceedings{ayala2021,
author="Ayala, Alan
and Tomov, Stanimire
and Stoyanov, Miroslav
and Dongarra, Jack",
editor="Malyshkin, Victor",
title="Scalability Issues in FFT Computation",
booktitle="Parallel Computing Technologies",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="279--287",
abstract="The fast Fourier transform (FFT), is one the most important tools in mathematics, and it is widely required by several applications of science and engineering. State-of-the-art parallel implementations of the FFT algorithm, based on Cooley-Tukey developments, are known to be communication-bound, which causes critical issues when scaling the computational and architectural capabilities. In this paper, we study the main performance bottleneck of FFT computations on hybrid CPU and GPU systems at large-scale. We provide numerical simulations and potential acceleration techniques that can be easily integrated into FFT distributed libraries. We present different experiments on performance scalability and runtime analysis on the world's most powerful supercomputers today: Summit, using up to 6,144 NVIDIA V100 GPUs, and Fugaku, using more than one million Fujitsu A64FX cores.",
isbn="978-3-030-86359-3"
}

@INPROCEEDINGS{gupta1993,

  author={Gupta, Anshul and Kumar, Vipin},

  booktitle={1993 International Conference on Parallel Processing - ICPP'93}, 

  title={Scalability of Parallel Algorithms for Matrix Multiplication}, 

  year={1993},

  volume={3},

  number={},

  pages={115-123},

  doi={10.1109/ICPP.1993.160}}

@misc{kloeffel2020,
  doi = {10.48550/ARXIV.2003.08477},
  
  url = {https://arxiv.org/abs/2003.08477},
  
  author = {Klöffel, Tobias and Mathias, Gerald and Meyer, Bernd},
  
  keywords = {Computational Physics (physics.comp-ph), Performance (cs.PF), Chemical Physics (physics.chem-ph), FOS: Physical sciences, FOS: Physical sciences, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Integrating State of the Art Compute, Communication, and Autotuning Strategies to Multiply the Performance of the Application Programm CPMD for Ab Initio Molecular Dynamics Simulations},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{lippert1997,
  title={FFT for the APE Parallel Computer},
  author={Lippert, Thomas and Schilling, Klaus and Trentmann, Sven and Toschi, Federico and Tripiccione, Raffaele},
  journal={International Journal of Modern Physics C},
  volume={8},
  number={06},
  pages={1317--1334},
  year={1997},
  publisher={World Scientific}
}

@inproceedings{pekurovsky2011,
author = {Pekurovsky, Dmitry},
title = {Ultrascalable Fourier Transfroms in Three Dimensions},
year = {2011},
isbn = {9781450308885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2016741.2016751},
doi = {10.1145/2016741.2016751},
abstract = {Fourier and related types of transforms are widely used in scientific community. Three-dimensional Fast Fourier Transforms (3D FFT), for example, are used in many areas such as DNS turbulence, astrophysics, material science, chemistry, oceanography and X-ray crystallography. In many cases this is a very compute-intensive operation. Lately there has been a need for implementations of scalable 3D FFT and related algorithms on Petascale parallel machines [1-8]. Most existing implementations of 3D FFT use one-dimensional task decomposition, and therefore are subject to scaling limitation when the number of cores reaches domain size. P3DFFT library overcomes this limitation. It is an open-source, easy-to-use software package [9] providing general solution for 3D FFT based on two-dimensional decomposition. In this way it is different from majority of other libraries such as FFTW, PESSL, MKL and ACML. P3DFFT is written in Fortran90 and MPI, with C interface available. It uses FFTW as an underlying library for FFT computation in one dimension. P3DFFT has been demonstrated to scale quite well up to tens of thousands cores on several platforms, including Kraken at NICS/ORNL. Theoretically it is scalable up to N-squared cores, provided suitable hardware support, where N is the domain size. In practice all-to-all communication inherent in the algorithm is often the performance bottleneck at large core counts. This type of communication stresses bisection bandwidth of the interconnect and is a challenging operation for most High Performance Computing (HPC) systems. (In fact one of the three NSF Track 1 system application procurement requirements involves 3D FFT as a crucial software component.) As a consequence, communication time is typically a high fraction of overall time for the algorithm (80% is not uncommon). In spite of this, P3DFFT scales quite well since with the increase of core counts the volume of data to be exchanged decreases proportionately. A test benchmark P3DFFT program has shown about 50% efficiency in strong scaling from 4k to 64k cores on Cray XT5 (see Figure 1). This is consistent with the expectation of a power law scaling of an all-to-all exchange on a 3D torus (where bisection bandwidth scales as P2/3). Some performance tuning is recommended to get the maximum benefit, and it is carried out by simply varying the aspect ratio of the two-dimensional processor grid. More details will be included in presentation.},
booktitle = {Proceedings of the 2011 TeraGrid Conference: Extreme Digital Discovery},
articleno = {9},
numpages = {2},
keywords = {numerical libraries, two-dimensional decomposition, parallel performance, community applications, scalability, high performance computing (HPC), open source software, petascale},
location = {Salt Lake City, Utah},
series = {TG '11}
}

@phdthesis{cannon1969,
author = {Cannon, Lynn Elliot},
title = {A Cellular Computer to Implement the Kalman Filter Algorithm},
year = {1969},
publisher = {Montana State University},
address = {USA},
note = {AAI7010025}
}

@INPROCEEDINGS{quintin2013,

  author={Quintin, Jean-Noël and Hasanov, Khalid and Lastovetsky, Alexey},

  booktitle={2013 42nd International Conference on Parallel Processing}, 

  title={Hierarchical Parallel Matrix Multiplication on Large-Scale Distributed Memory Platforms}, 

  year={2013},

  volume={},

  number={},

  pages={754-762},

  doi={10.1109/ICPP.2013.89}}

@misc{s3dft,
  title = {S3DFT: Scalable 3D-DFT},
  author = {Nitin Malapally},
  howpublished = {Available on \url{https://gitlab.com/anxiousprogrammer/s3dft}},
  year = {2021},
  note = {Last accessed: 08.11.2022},
}

@article{alvarez2021,
author = {Alvarez, Damian},
year = {2021},
month = {10},
pages = {},
title = {{JUWELS} {C}luster and {B}ooster: {E}xascale {P}athfinder with {M}odular {S}upercomputing {A}rchitecture at {J}uelich {S}upercomputing {C}entre},
volume = {7},
journal = {Journal of large-scale research facilities JLSRF},
doi = {10.17815/jlsrf-7-183}
}

@manual{intel2022,
  title        = {Intel(R) Advisor User Guide},
  organization = {Intel Corporation},
  edition      = {2022.3},
  year         = {2022},
  note         = {Available at \url{https://www.intel.com/content/www/us/en/develop/documentation/advisor-user-guide/top.html}},
}

@misc{intel2021,
  title = {Where Can I Find Information about FLOPS Per Cycle for Intel(R) Processors?},
  author = {Intel Corporation},
  howpublished = {\url{https://www.intel.com/content/www/us/en/support/articles/000057415/processors.html}},
  year = {2021},
  note = {Last accessed: 08.11.2022},
}

@manual{intel2020,
  title        = {Intel(R) Xeon(R) Processor Scalable Family Specification Update},
  organization = {Intel Corporation},
  edition      = {017},
  month        = {October},
  year         = {2020},
  note         = {Available at \url{https://www.intel.com/content/dam/www/public/us/en/documents/specification-updates/xeon-scalable-spec-update.pdf}},
}

@book{hager2010,
author = {Hager, Georg and Wellein, Gerhard},
year = {2010},
month = {07},
pages = {},
title = {Introduction to High Peformance Computing for Scientists and Engineers},
isbn = {978-1439811924},
journal = {Introduction to High Performance Computing for Scientists and Engineers},
doi = {10.1201/EBK1439811924}
}

@misc{tixl,
  title = {TiXL: Timed eXperiments in a Loop},
  author = {Nitin Malapally},
  howpublished = {Available on \url{https://gitlab.com/anxiousprogrammer/tixl}},
  year = {2021},
  note = {Last accessed: 08.11.2022},
}

@manual{fftw3_manual,
  title        = {FFTW},
  author       = {Frigo, Matteo and Johnson, G. Steven},
  organization = {Massachusetts Institute of Technology},
  month        = {December},
  year         = {2020},
  note         = {Available at \url{http://www.fftw.org/fftw3.pdf}},
}
