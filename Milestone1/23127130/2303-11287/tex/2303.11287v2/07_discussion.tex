
\section{Discussion}

% \section{Limitations}
While our method improves hologram quality for simultaneous illumination and is compatible with VR/AR displays, it does have limitations.  First, our method is not equally effective for all images.  Natural images with high levels of texture work best, as they have similarly structured color channels and contain high frequency color information that is perceptually suppressible by our loss function. 
Images with large flat areas may exhibit noticeable artifacts due to the more difficult task of determining an SLM pattern that produces 3 largely unique holograms \revised{(see Supplement Fig. S4)}.  

SLMs with large phase range can be slower than their short phase range counterparts. Although our SLM has $7.4\pi$ phase range in blue, we show in the Supplement that we can achieve reasonable quality with only a $4\pi$ range, opening the possibility for simultaneous color with a wider variety of SLMs.

Calculating a single SLM pattern for a 2D image using an Nvidia A6000 takes minutes with our method, inhibiting real-time displays. Neural nets can generate SLM patterns in real-time while retaining quality, suggesting a potential future solution for simultaneous color holography~\cite{shi2021towards, eybposh2020high, yang2022diffraction}.

\label{sec:limits}

% Finally, many recent works have shown active camera-in-the-loop (CiTL) can dramatically increase hologram quality.  While this is true, using active CiTL for a user display is not feasible.  As the argument for simultaneous color is to make color holographic displays possible for VR and AR, we have chosen to not focus on active CiTL in this work.  Active CiTL does provide proof-of-existence of experimental image quality and our method is compatible with it.  Results using active CiTL can be found in the supplement. 
% \paragraph{Conclusion}
% In conclusion, this work presents a comprehensive framework for the generation of color holograms using simultaneous RGB illumination with a simple and compact optical setup. The framework utilizes a camera-calibrated and differentiable forward model, which reduces model mismatch and enables the use of custom loss functions. A perceptual loss function is employed to address the over-determined problem of simultaneous color holography, resulting in higher quality results. All findings were validated through experimental testing, bringing us closer to achieving the goal of creating holographic near-eye displays.

In summary, we developed a framework for high-quality color holograms using simultaneous RGB illumination in a compact setup, featuring a camera-calibrated, differentiable model and custom loss functions. %Our perceptual loss function effectively addresses the difficult challenges of simultaneous color holography, proven by successful 2D and 3D experiments, advancing us towards holographic near-eye displays.
