\begin{figure*}
    \centering
    \includegraphics[clip, trim = 0in 8.5in 0in 0in, width=\textwidth]{figures/ForwardModel.pdf}
    \caption{\textbf{Hologram optimization framework.}
    This figure illustrates the three key components of the simultaneous color optimization framework: an SLM model, a propagation model, and a perceptual loss function. The SLM model maps voltage values to a complex field using a learned cross-talk kernel and a linear lookup table. The complex wavefront from the SLM is then propagated to the sensor plane using a modified version of the model proposed by \citet{Gopakumar2021UnfilteredDisplays}, which separates the zeroth and first diffraction orders and combines them through a U-Net. The output is then fed into the perceptual loss function, and gradients are calculated using Pytorch's autograd implementation. The SLM voltages are then updated using these gradients. Rubik's cube source image by Iwan Gabovitch (CC BY 2.0).}  
    \label{fig:ForwardModel}
\end{figure*}

\section{Related Works}
\label{RelatedWorks}

\paragraph{Field Sequential Color}
The vast majority of color holographic displays use field sequential color in which the SLM is sequentially illuminated by red, green, and blue sources while the SLM pattern is updated accordingly \cite{maimone2017holographic, jang2018holographic, Chakravarthula2019WirtingerDisplays, Chakravarthula2020LearnedDisplays, chakravarthula2022pupil,  Peng2020NeuralTraining, Peng2021Speckle-freeCalibration,Choi2021NeuralDisplays, choi2021optimizing, shi2021towards, yang2022diffraction, li2016holographic}. Field sequential color is effective at producing full color holograms but reduces framerate by a factor of $3\times$. This is a challenge for LCoS SLMs where framerate is severely limited by the LC response time \cite{zhang2014fundamentals}. Although, SLMs based on MEMS technology can run at high framerates in the kilohertz range \cite{MEMS}, so far these modulators are maximum 4-bit displays, with most being binary \cite{Choi2022Time-multiplexedModulators, kim2022accommodative, lee2022high}. Even with high framerate modulators, it may be worthwhile to maintain the full temporal bandwidth, since the extra bandwidth can be used to address other holography limitations. For example, speckle can be reduced through temporal averaging \cite{Choi2022Time-multiplexedModulators, kim2022accommodative, lee2022high}, and limited etendue can be mitigated through pupil scanning \cite{jang2018holographic, kim2022holographic}.

\paragraph{Spatial Multiplexing} An alternate approach is spatial multiplexing, which maintains the native SLM framerate by using different regions of the SLM for each color. Most prior works in this area use three separate SLMs and an array of optics to combine the wavefronts~\cite{Yaras2009Real-timeIllumination, Shiraki2009SimplifiedLinks, Nakayama2010Real-timePanels}. 
Although this method produces high quality holograms, the resulting systems are  bulky, expensive, and require precise alignment, making them poorly suited for near-eye displays. Spatial multiplexing can also be implemented with a single SLM split into sub-regions~\cite{Makowski2011SimpleColor, Makowski2009ExperimentalDisplay}; while less expensive, this approach still requires bulky combining optics and sacrifices space-bandwidth product (SBP), also known as etendue. Etendue is already a limiting factor in holographic displays \cite{kuo2020high}, and further reduction is undesirable as it limits the range of viewing angles or display field-of-view.

\paragraph{Frequency Multiplexing} Rather than split the physical extent of the SLM into regions, frequency multiplexing assigns each color a different region in the frequency domain, and the colors are separated with a physical color filter at the Fourier plane of a 4$f$ system \cite{Makowski2010ColorHolograms, Lin17, Lin19}. A variation on this idea uses different angles of illumination for each color so that the physical filter in Fourier space is not color-specific \cite{Xue:14}. Frequency multiplexing can also be implemented with white light illumination, which reduces speckle noise at the cost of resolution \cite{Kozacki16, yang2019full}. However, all of these techniques involve filtering in Fourier space, which sacrifices system etendue and requires a bulky 4$f$ system.

\paragraph{Depth Division and Bit Division for Simultaneous Color} The prior methods most closely related to our work also use simultaneous RGB illumination over the SLM, maintain the full SLM etendue, and don't require a bulky 4$f$ system \cite{Pi2022ReviewDisplay}. We refer to the first method as \textit{depth division multiplexing} which takes advantage of the ambiguity between color and propagation distance (explained in detail in Sec. \ref{sec:color-depth-ambiguity}) and assigns each color a different depth~\cite{Makowski2008ColorfulHologram, Makowski2010ColorHolograms}. After optimizing with a single color for the correct multiplane image, the authors show they can form a full color 2D hologram when illuminating in RGB. However,  this approach does not account for wavelength dependence of the SLM response, and since it explicitly defines content at multiple planes, it translates poorly to 3D.

Another similar approach is \textit{bit division multiplexing}, which takes advantage of the extended phase range of LCoS SLMs \cite{Jesacher2014ColourRange}. The authors calibrate an SLM lookup-table consisting of phase-value triplets (for RGB) as a function of digital SLM input, and they note that SLMs with extended phase range (up to $10\pi$) can create substantial diversity in the calibrated phase triplets. After pre-optimizing a phase pattern for each color separately, the lookup-table is used on a per-pixel basis to find the digital input that best matches the desired phase for all colors. In our approach, we also use an extended SLM phase range for the same reason, but rather than using a two-step process, we directly optimize the output hologram. This flexible framework also allows us to incorporate a perceptual loss function to further improve perceived image quality.

\paragraph{Algorithms for Hologram Generation}
Our work builds on a body of literature applying iterative optimization algorithms to holographic displays. Perhaps most popular is the Gerchberg-Saxton (GS) method \cite{gerchberg1972practical}, which is effective and easy to implement, but does not have an explicitly defined loss function, making it challenging to adapt to specific applications. \citet{zhang20173d} and \citet{Chakravarthula2019WirtingerDisplays} were the first to explicitly formulate the hologram generation problem in an optimization framework. This framework has been very powerful, enabling custom loss functions \cite{Choi2022Time-multiplexedModulators} and flexible adaptation to new optical configurations \cite{choi2021optimizing, Gopakumar2021UnfilteredDisplays}. In particular, perceptual loss functions can improve the perceived image by taking aspects of human vision into account, such as human visual acuity \cite{kuo2020high}, foveated vision \cite{walton2022metameric}, and sensitivity to spatial frequencies during accommodation \cite{kim2022accommodative}. Like these prior works, we use an optimization-based framework which we adapt to account for the wavelength-dependence of the SLM; this also enables our  new perceptual loss function for color, which is based on visual acuity difference between chrominance and luminance channels.


\paragraph{Camera-Calibration of Holographic Displays}
When the model used for hologram generation does not match the physical system, deviations cause artifacts in the experimental holograms. Recently, several papers have addressed this issue using measurements from a camera in the system for calibration.  \citet{Peng2020NeuralTraining} proposed using feedback from the camera to update the SLM pattern for a particular image; although a single image can be improved, it does not extend to new content.
A more flexible approach uses pairs of SLM patterns and camera captures to estimate the learnable parameters in a model, which is then used for offline hologram generation. Learnable parameters can be physically-based \cite{Peng2020NeuralTraining, kavakli2022learned, Chakrabarti2016LearningBack-propagation}, black box CNNs \cite{Choi2021NeuralDisplays}, or a combination of both \cite{Choi2022Time-multiplexedModulators}. The choice of learnable parameters effects the ability of the model to match the physical system; we introduce a new parameter for modeling SLM cross talk and tailor the CNN architecture for higher diffraction orders from the SLM.  