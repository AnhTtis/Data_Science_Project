The impact of the COVID-19 pandemic has brought the importance of reliable supply chains to everyone's attention. Empty supermarket aisles and medication shortages have shown the general public the fragility of modern supply chains. From a consumer's perspective, it is vital that supply chains are robust enough to handle unexpected changes in demand, supplier issues, and transport disruptions, making it essential for supply chain optimization to address these concerns. 
Supply chains are a central topic within operations research and are typically broken down into Supply Chain Design (SCD), Supply Chain Planning (SCP), and Supply Chain Execution (SCE)~\citep{wenzel2019literature}. 
SCD describes the process of planning the locations, capacity and general demand policy of a supply chain, while SCP describes the medium-term strategy, such as production cycles and logistics. 
Finally, SCE deals with the supply chain management and its control. From this it is clear that the robustness of a supply chain may be influenced at different moments in its life cycle. The focus of this work lies on inventory optimization, a subpart of SCE, using dynamic yet interpretable policies. 

Since early seminal works by~\citet{harris1913many}, inventory optimization has been a focus of operations research. It is now widely used in enterprise resource-planning systems that help operate most manufacturing and distribution companies. Traditionally, inventory optimization methods aim to construct a \emph{static} policy, based on minimum inventory levels and reorder quantities. On the one hand, these static policies can easily be implemented in a fixed process and, on the other hand, are easy to interpret and communicate to supply chain stakeholders. However, these methods rely on assumptions such as linearity of costs or expected demand distribution~\citep{snyder2019fundamentals, mula2010mathematical} and cannot easily be adjusted to changes in a dynamic environment -- not to mention drastic short-term disruptions such as those caused by the \textsc{Covid}-19 pandemic. As a consequence, static policies are often suboptimal with respect to cost and efficiency.

With the advent of modern computational methods, the focus has since shifted to construct more complex policies. These can be based on simulation tools, like the static {OTD-Net}~\citep{odtnet} simulator, Monte-Carlo-based discrete event simulators such as {SimPy}~\citep{simpy}, or optimal control techniques. Within the latter category, Reinforcement Learning (RL) can be used to find \emph{dynamic} policies that do not require assumptions about the environment. Paired with a broad range of simulatable dynamic supply chain scenarios, these policies can be made resilient against disruptions of the supply chains, or can be used in conjunction with continual learning to dynamically react to new set points of the supply chains. However, state-of-the-art RL methods rely on Neural Networks (NNs) to represent policies making their interpretation difficult. 

To overcome these limitations, we propose an \emph{interpretable} RL approach based on Neural Additive Models (NAMs)~\citep{agarwal2021neural}. Using a NAM to represent the agent's policy, we can leverage its interpretability to gain insights into the learned features of the policy, closing the gap towards static and interpretable approaches. At the same time, their functional form is highly flexible to be on par with other deep learning-based RL approaches when learning environment-agnostic dynamic policies. 

To the best of our knowledge, this paper provides the first application of full end-to-end \textit{interpretable} neural policies to solve challenging, dynamic optimization problems in an Inventory Optimization benchmark. Thus, our approach explicitly contributes to one of the grand challenges of interpretable machine learning set out by~\citet{rudin2022interpretable}.




