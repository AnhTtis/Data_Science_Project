% Template for ICME 2022 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP/ICME LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{booktabs}

\usepackage{framed,multirow}
\usepackage{latexsym}
\usepackage{verbatim}
\usepackage{color}
\usepackage{subfigure}

\let\OLDthebibliography\thebibliography
\renewcommand\thebibliography[1]{
  \OLDthebibliography{#1}
  \setlength{\parskip}{0pt}
  \setlength{\itemsep}{0pt plus 0.3ex}
}

\pagestyle{empty}


\begin{document}\sloppy

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}


% Title.
% ------
\title{Uncertainty-aware U-Net for Medical Landmark Detection}
%
% Single address.
% ---------------
%\name{Anonymous ICME submission}
\name{Ziyang Ye, Haiyang Yu, and Bin Li}
%Address and e-mail should NOT be added in the submission paper. They should be present only in the camera ready paper. 
\address{\{yezy20, hyyu20, libin\}@fudan.edu.cn\\
Shanghai Key Laboratory of Intelligent Information Processing\\
School of Computer Science, Fudan University}


\maketitle


%
\begin{abstract}
Heatmap-based methods play an important role in anatomical landmark detection. However, most current heatmap-based methods assume that the distributions of all landmarks are the same and the distribution of each landmark is isotropic, which may not be in line with reality. For example, the landmark on the jaw is more likely to be located along the edge and less likely to be located inside or outside the jaw. Manually annotating tends to follow similar rules, resulting in an anisotropic distribution for annotated landmarks, which represents the uncertainty in the annotation. To estimate the uncertainty, we propose a module named Pyramid Covariance Predictor to predict the covariance matrices of the target Gaussian distributions, which determine the distributions of landmarks and represent the uncertainty of landmark annotation. Specifically, the Pyramid Covariance Predictor utilizes the pyramid features extracted by the encoder of the backbone U-Net and predicts the Cholesky decomposition of the covariance matrix of the landmark location distribution. Experimental results show that the proposed Pyramid Covariance Predictor can accurately predict the distributions and improve the performance of anatomical landmark detection.
\end{abstract}

%
\begin{keywords}
uncertainty estimation, anatomical landmark detection, heatmap regression
\end{keywords}
%

\section{Introduction}
\label{sec:Introduction}

Anatomical landmark detection plays an important role in medical image analysis. Due to the advantage of likelihood modeling, researchers often utilize a heatmap to obtain the location of landmarks rather than directly regressing their coordinates \cite{kumar2020luvli}. The heatmap is a probability distribution of landmark location, and as a common practice, researchers usually use a Gaussian likelihood to estimate the distribution. 

% 再解释一下

However, most current heatmap-based methods need predetermined heatmaps with fixed Gaussian kernels as prior knowledge, and this potentially introduces two assumptions into their approaches: 1) The distributions of all landmarks are the same. 2) The distribution of each landmark is isotropic. These hypotheses may not be consistent with reality. Firstly, since there may be differences in the difficulty of locating various landmarks, the distributions of landmarks may be different from each other. For landmarks that are easy to locate, such as those on clear edges, the variances of their distributions may be smaller, and vice versa. Secondly, for a single landmark, its distribution in different directions may also vary. For landmarks that lie on edges, their distributions may be more likely to be along the edge, thus introducing anisotropy \cite{payer2020uncertainty}. Fig.~\ref{fig:fig0} shows an example.

%\begin{figure}[!t]
%\centering
%\includegraphics[height=4cm]{fig10.png}
%\caption{The left image shows the Gaussian distribution of one landmark used in most methods. However, the landmark is more likely to be located along the jaw and less likely to be located out in space or within the jaw, so the distribution illustrated in the right image may be more representative.}
%\label{fig:fig0}
%\end{figure}

\begin{figure}[!t]
\centering
 \subfigure[]{\includegraphics[width=3cm]{fig10a.png}}
 \subfigure[]{\includegraphics[width=3cm]{fig10b.png}}
\caption{The left image shows the Gaussian distribution of one landmark used in most methods. However, the landmark is more likely to be located along the jaw and less likely to be located out in space or within the jaw, so the distribution illustrated in the right image is likely to be more representative.}
\label{fig:fig0}
\end{figure}

% Since the structure of human bodies is complex with various substances, it is difficult to annotate the anatomical landmarks with perfect accuracy.
The aforementioned phenomenon shows the \textit{aleatoric} uncertainty of landmark detection. \textit{Aleatoric} uncertainty represents the noise inherent in the observations and is mainly caused by annotation ambiguities. It is difficult for humans to annotate anatomical landmarks with perfect accuracy. When annotating the same image several times, annotators may give different annotations, and the possibility can be described as a distribution. As mentioned before, different landmarks may have different distributions which are possibly anisotropic. However, previous methods simply utilize a fixed Gaussian kernel to get the heatmap, thus failing to model real distributions of landmarks. Specifically, these methods use a predetermined heatmap with the same variance and optimize the model by minimizing the loss between the predicted heatmap and the predetermined heatmap. Such predetermined heatmaps are not representative enough of the real annotation distributions, which may limit the performance of heatmap-based methods.

% 分布对比图，边缘分布可视化（加experiment中）

% Uncertainty can be divided into two major types \cite{kendall2017uncertainties}: \textit{epistemic} uncertainty is related to model parameters, capturing the lack of knowledge about the model when generating the collected data, and \textit{aleatoric} uncertainty shows the noise inherent in the observations, which can not be reduced even if more data is provided. We focus on the \textit{aleatoric} uncertainty of landmark detection methods since it tends to be ignored by past methods. \textit{Aleatoric} uncertainty of landmark detection is mainly caused by annotation ambiguities. Since the structure of human bodies is complex with various substances, it is difficult to annotate the anatomical landmarks with perfect accuracy. Therefore, the \textit{aleatoric} uncertainty generally exists, representing not only an inter-observer variability between different human annotators but also an intra-observer variability between different images.

% \textit{Aleatoric} uncertainty can be obtained by annotating the same image several times, but generally, each image has only one ground-truth label for each landmark in the existing public datasets. There are also difficulties in collecting a multi-labeled dataset since multiple manual annotations for one landmark in one image are sometimes time-consuming, especially in the medical field. Hence, we need to estimate the uncertainty from the single-labeled images. Fortunately, estimating uncertainty distribution from one ground-truth annotation is not impossible since a heatmap-based landmark detection framework can also be used to model the uncertainty \cite{payer2020uncertainty}.

% 我们的uncertainty和Aleatoric uncertainty关系，怎么对应
% 模型预测的热力图的分布应该符合人工标注关键点的uncertainty
% 如果按照各向同性（之前统一的高斯核）的部分的话，那人为标注的误差会给模型带来负面影响   模型构建的热力图的分布和人工标注的分布存在较大的差异

% the \textit{aleatoric} uncertainty of each landmark
% representing the real distribution of annotation. Our parametric model is based on U-Net \cite{ronneberger2015u}, which is widely used and has proven its effectiveness in heatmap-based landmark detection methods.

To this end, we propose a U-Net-based method to jointly predict the landmarks and their probability distributions. We use a Gaussian distribution to describe the possibility, and let the ground-truth landmark coordinate be the mean of the distribution. To predict the covariance matrix of the target distribution, we develop a Pyramid Covariance Predictor branch (shown in Fig.~\ref{fig:fig1}). Considering differences between low-level and high-level features, the branch processes the two kinds of features separately and fuses them to predict the covariance matrix. The experimental results show that the proposed Pyramid Covariance Predictor can indeed estimate the uncertainty of landmarks and improve the performance of anatomical landmark detection. Our contributions are as follows:

\begin{enumerate}
    \item We propose a method for uncertainty-aware landmark detection that jointly predicts the landmark and the covariance matrix of the target distribution.
    \item We design a module called Pyramid Covariance Predictor to discover the covariance matrix of the heatmap distribution. Visualizations demonstrate that the uncertainty our method estimates is more reasonable than that used in other methods.
    \item The experimental results show that our method achieves overall better performance compared with other methods.
\end{enumerate}

\section{Related Work}
\label{sec:Related Work}

\subsection{Medical Landmark Detection}

Early methods for medical landmark detection were based on a simple classifier, such as Random Forest \cite{ibragimov2015computerized, lindner2015fully}. Recently, deep-learning-based methods \cite{noothout2020deep,zhong2019attention,chen2019cephalometric} have been proven to be effective in medical landmark detection. Existing methods can be classified into three categories \cite{li2020structured}: 1) the coordinate-based approach \cite{noothout2020deep} that directly predicts the location of the landmarks by regression, 2) the graph-based approach \cite{li2020structured} that uses a graph to represent the structure of the landmarks, and 3) the heatmap-based approach.

Heatmap-based methods are the most common. These methods try to obtain the likelihood heatmap for each landmark and use this heatmap (sometimes with offset maps) to predict the locations of landmarks. For instance, in \cite{zhong2019attention}, a two-stage U-Net framework with attention mechanism and heatmap regression is developed to detect landmarks. In \cite{chen2019cephalometric}, an attentive feature pyramid fusion module is proposed to shape enhanced fusion features to improve accuracy. These methods generate the ground-truth heatmap using a symmetric Gaussian distribution with a fixed Gaussian kernel and optimize the model by minimizing the distance between predicted heatmaps and target heatmaps.

\subsection{Uncertainty Estimation}

There are two types of methods in uncertainty estimation: sampling-based and sampling-free. Sampling-based methods \cite{shridhar2019comprehensive,gal2016dropout,ayhan2018test} utilize the existing models and estimate the uncertainty by multiple evaluations. Popular methods, such as Bayesian neural networks \cite{shridhar2019comprehensive} and Monte Carlo dropout \cite{gal2016dropout}, all rely on several predictions by an ensemble of multiple networks or a dropout layer. Running the model on different augmentations\cite{ayhan2018test} is also an effective way.

%Except for sampling multiple models, data augmentation \cite{ayhan2018test} is also utilized in uncertainty estimation. By running the model on different augmentations, one can also obtain the distribution.

Sampling-free methods are modified from previous architectures to compute uncertainty using a single network and the same dataset. For example, in \cite{ovadia2019can}, the authors introduced stochastic variational inference and temperature scaling into the model to evaluate uncertainty. In \cite{sensoy2018evidential}, the uncertainty is estimated by fitting a Dirichlet distribution. In other fields, researchers have also tried to introduce uncertainty into their methods to improve performance, such as face alignment \cite{chen2019face} and body pose estimation \cite{gundavarapu2019structured}.

\begin{figure}[!t]
\centering
\includegraphics[height=5.5cm]{fig11.png}
\caption{Overview of our method. We add a branch to the U-Net architecture and fuse the low-level and high-level features separately. The low-level features are extracted by the first two layers of the encoder, and the high-level features are the output of remaining three layers.}
\label{fig:fig1}
\end{figure}

\section{Methods}
\label{sec:Method}

As shown in Fig.~\ref{fig:fig1}, we use a U-Net architecture as the heatmap predictor to obtain the heatmaps of landmarks. In this paper, we introduce a new branch, called Pyramid Covariance Predictor, to calculate the covariance matrix of the target distribution and estimate the annotating uncertainty. The details of our method are illustrated as follows.

\subsection{Heatmap Predictor}\label{section:HP}

% Although current methods in landmark detection achieve better performance through more complicated architectures, such as stacked or cascaded models, U-Net still shows its effectiveness with a relatively simple structure \cite{mccouat2022contour}. \textbf{Using U-Net to predict the heatmap is also a common method, so we adopt the standard U-Net as the heatmap predictor similarly.} 

We adopt the standard U-Net as the heatmap predictor due to its effectiveness and relatively simple structure. The standard U-Net architecture consists of an encoder and a decoder, where the encoder extracts the multi-scale features of input images and the decoder takes them as input to predict the heatmap. In our method, a VGG19 network \cite{simonyan2014very} pretrained on ImageNet Dataset \cite{krizhevsky2012imagenet} is adopted as the encoder. The decoder consists of consecutive modules. Each module contains an upsampling layer and a multi-scale feature discovery (MSFD) block (note that we omit the upsampling layer in Fig.~\ref{fig:fig1}). The upsampling layer upsamples the output from the last module using bilinear interpolation and combines the upsampled features with the image features from skip connections. The structure of the MSFD block is similar to the context-aware pyramid feature extraction (CPFE) module \cite{zhao2019pyramid}, which aims to fuse the combined features by the following two steps (as shown in Fig.~\ref{fig:fig2}): 1) extract multi-scale features by multiple atrous convolution layers with different dilation rates, and 2) concatenate them and reduce the channel. 

Finally, for $ N $ landmarks, the heatmap predictor outputs the heatmap $ \boldsymbol{\hat{H_i}} $, corresponding to the $i$-th landmark. For further processing, we calculate the predicted coordinate $ \boldsymbol{\hat{x}_i} $ from the heatmap. To utilize information from the whole heatmap and keep the gradient propagation, we use a weighted spatial mean to obtain $\boldsymbol{\hat{x}_i} $:

\begin{align}
 \label{eq:WSM}
 \boldsymbol{\hat{x}_i} = \frac{\Sigma_{\boldsymbol{x}}\delta\left(\boldsymbol{\hat{H_i}}\left(\boldsymbol{x}\right)\right)\boldsymbol{x}}{\Sigma_{\boldsymbol{x}}\delta\left(\boldsymbol{\hat{H_i}}\left(\boldsymbol{x}\right)\right)}
\end{align}
where $ \boldsymbol{\hat{H_i}}\left(\boldsymbol{x}\right) $ is the value at position $ \boldsymbol{x} $ in $ \boldsymbol{\hat{H_i}} $, $ \delta\left(\cdot\right) $ is the activation function.

% heatmap获得坐标

\begin{figure}[!t]
\centering
\includegraphics[height=3cm]{fig12.png}
\caption{The structure of the MSFD block consists of three convolution layers, with the concatenated feature as input. The outputs are then concatenated and processed by a $1 \times 1$ convolution to reduce the channel.}
\label{fig:fig2}
\end{figure}

% 加入SDR

\setlength{\tabcolsep}{3pt}
\begin{table*}[t]
\begin{center}
\caption{Comparison with other SOTA methods on IEEE ISBI Challenge 2015 Dataset.}
\label{table:table1}
\setlength{\tabcolsep}{2mm}{
\begin{tabular}{@{}ccccccccccc@{}}
\toprule

\multirow{3}{*}{Model} & \multicolumn{5}{c}{Validation Set} & \multicolumn{5}{c}{Test Set}  \\ \cmidrule(l){2-6} \cmidrule(l){7-11} & \multirow{2}{*}{MRE} & \multicolumn{4}{c}{SDR} & \multirow{2}{*}{MRE} & \multicolumn{4}{c}{SDR} \\ & & 2mm & 2.5mm & 3mm & 4mm & & 2mm & 2.5mm & 3mm & 4mm \\ \cmidrule(l){1-11}

Ibragimov \textit{et al.} \cite{ibragimov2015computerized} & 1.84 & 71.70 & 77.40 & 81.90  & 88.00 & - & 62.74 & 70.47 & 76.53 & 85.11 \\
Lindner \textit{et al.} \cite{lindner2015fully} & 1.67 & 74.95 & 80.28 & 84.56 & 89.68 & - & 66.11 & 72.00 & 77.63 & 87.42 \\
Arik \textit{et al.} \cite{arik2017fully} & - & 75.37 & 80.91 & 84.32 & 88.25 & - & 67.68 & 74.16 & 79.11 & 84.63 \\
Qian \textit{et al.} \cite{qian2019cephanet} & - & 82.50 & 86.20 & 89.30 & 90.60 & - & 72.40 & 76.15 & 79.65 & 85.90 \\
Chen \textit{et al.} \cite{chen2019cephalometric} & 1.17 & \textbf{86.67} & \textbf{92.67} & 95.54 & 98.53 & \textbf{1.48} & \textbf{75.05} & \textbf{82.84} & 88.53 & 95.05 \\
%Oh et al\cite{oh2020deep} & 1.18 & 86.20 & 91.20 & 94.40 & 97.70 & \textbf{1.45} & 75.89 & 83.36 & 89.26 & \textbf{95.73} \\
Lin \textit{et al.} \cite{lin2021structure} & 1.23 & 85.01 & 91.57 & 94.52 & 97.68 & 1.65 & 72.00 & 81.63 & 87.84 & 94.05 \\
%Li et al \citep{li2020structured} & \textbf{1.04} & \textbf{88.49} & 93.12 & 95.72 & 98.42 & \textbf{1.43} & 76.57 & 83.68 & 88.21 & 94.31 \\
Ours & \textbf{1.16} & 86.25 & 92.18 & \textbf{95.72} & \textbf{98.59} & \textbf{1.48} & 74.26 & 82.11 & \textbf{88.57} & \textbf{95.21} \\ \bottomrule
\end{tabular}}
\end{center}
\end{table*}
\setlength{\tabcolsep}{1.4pt}

\subsection{Pyramid Covariance Predictor}\label{section:CP}
% 点一下功能，呼应
The proposed Pyramid Covariance Predictor utilizes the pyramid features extracted by U-Net to predict the covariance matrix, which determines the distribution of the landmark location. For the multivariate location distribution, there are two approaches to building the target heatmap: Gaussian and Laplacian. Following \cite{payer2020uncertainty}, we typically choose the Gaussian function to represent the distributions of landmarks.

In previous works \cite{zhong2019attention,payer2016regressing}, the target heatmap $ \boldsymbol{H_i} $ of the $i$-th landmark can be described by an isotropic two-dimensional Gaussian function:

\begin{align}
 \label{eq:GF}
 \boldsymbol{H_i}\left(\boldsymbol{x};\sigma_i\right) = \frac{\gamma}{2\pi\sigma_i^2}\exp\left(-\frac{\|\boldsymbol{x} - \boldsymbol{x_i}\|^2_2}{2\sigma_i^2}\right)
\end{align}
where $ \boldsymbol{x_i} $ represents the location of the $i$-th landmark, $ \sigma_i $ is the standard deviation of the Gaussian distribution, and $ \gamma $ is a scaling factor that makes the function numerically stable. The mean of the distribution is set to the ground-truth landmark coordinate $ \boldsymbol{x_i} $ during training.

%However, isotropic Gaussian functions may be too simple to represent the real distribution. An isotropic Gaussian distribution for the landmark indicates that there is the same possibility of the same prediction error in all directions. This assumption may be realistic when the landmark is placed inside, where the surrounding pixels have similar colors. However, for those landmarks that lie on edges, an isotropic Gaussian heatmap may provide unrealistic information. Since the colors of the pixels near the edge change significantly, the landmark may be highly likely to be located along the edge rather than off the edge. Therefore, isotropic Gaussian functions are not representative enough to show the uncertainty of the location of landmarks. To better model the probability distribution, we use an anisotropic Gaussian function to estimate the uncertainty:

However, as aforementioned, isotropic Gaussian functions may be too simple to accurately represent the real distributions of landmarks. To better model the probability distributions, we use an anisotropic Gaussian function to estimate the uncertainty:

\begin{align}
 \label{eq:AGF}
 \boldsymbol{H_i}\left(\boldsymbol{x};\boldsymbol{\Sigma_i}\right) = \frac{\gamma \cdot exp\left(-\frac{1}{2}\left(\boldsymbol{x} - \boldsymbol{x_i}\right)^T\boldsymbol{\Sigma_i}^{-1}\left(\boldsymbol{x} - \boldsymbol{x_i}\right)\right)}{2\pi\sqrt{\left|\boldsymbol{\Sigma_i}\right|}}
\end{align}
Different from Eq.~\ref{eq:GF}, we use a full two-dimensional covariance matrix $ \boldsymbol{\Sigma_i} $ rather than a single value $ \sigma_i $ to represent the heatmap, thus introducing anisotropy into the distribution.

\begin{comment}

However, since the covariance matrix is a positive semi-definite matrix, its determinant is non-negative:

\begin{align}
 \label{eq:DET}
 det\left(\boldsymbol{\Sigma_i}\right) = cov\left(\boldsymbol{x}, \boldsymbol{x}\right)cov\left(\boldsymbol{y}, \boldsymbol{y}\right) - cov\left(\boldsymbol{x}, \boldsymbol{y}\right)^2 \geq 0
\end{align}

Note that $ det\left(\boldsymbol{\Sigma_i}\right) = 0 $ if and only if the correlation coefficient of $ \boldsymbol{X} $ and $ \boldsymbol{Y} $ equals 1 or -1, which is nearly impossible in the reality. Therefore, we hypothesize that the target covariance matrix is a positive definite matrix, which can simplify the following steps.

Eq.~\ref{eq:DET} shows that there is a relationship among elements of the covariance matrix. If we directly predict the elements of the matrix by regression, the outputs may be illegal since all the outputs of the fully connected layer are independent of each other. To solve this problem, we try to capture the degrees of freedom of the covariance matrix. Predicting its Cholesky decomposition is a simple but effective way \cite{kumar2020luvli}. Cholesky decomposition is a useful method in numerical solutions, such as Monte Carlo simulations. It decomposes a Hermitian, positive-definite matrix into the product of a lower-triangular matrix and its conjugate transpose. In our method, the target covariance matrix can be decomposed as:

\end{comment}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We follow \cite{kumar2020luvli} to predict the Cholesky decomposition of the covariance matrix in case of the illegal covariance matrix from direct regression. Details are further demonstrated in the Appendix. According to Cholesky Factorization Theorem \cite{schabauer2010toward}, the target covariance matrix can be decomposed as:

%\textbf{To obtain the covariance matrix, we choose to predict its Cholesky decomposition\cite{kumar2020luvli}. The target covariance matrix can be decomposed as:}

\begin{align}
 \label{eq:CD}
 \boldsymbol{\Sigma_i} = \boldsymbol{C_i}\boldsymbol{C_i}^T
\end{align}
%where $ \boldsymbol{C_i} $ has the form of $ \begin{bmatrix} a_i & 0 \\ b_i & c_i \end{bmatrix} $. It is proved that the Cholesky decomposition of a matrix always exists and is unique. Since $ a_i $, $ b_i $, and $ c_i $ are independent of each other, and they can determine a covariance matrix, we can predict these values by regression.
where $ \boldsymbol{C_i} $ has the form of $ \begin{bmatrix} a_i & 0 \\ b_i & c_i \end{bmatrix} $. 

%这一段的描述不是很清楚 感觉有点乱
In our work, we calculate $ a_i $, $ b_i $, and $ c_i $ by utilizing the multi-scale features extracted by the encoder of U-Net architecture. The multi-scale features can be divided into two categories: low-level features and high-level features \cite{zhao2019pyramid}. Low-level features represent features that show the pattern of the image, such as color, texture, and edges, while high-level features contain more semantic information. Due to the difference between low-level features and high-level features, we process the two types of features separately. Following \cite{zhao2019pyramid}, we choose the features of the first two layers of the encoder as low-level features and choose the features of the remaining three layers as high-level features. For both low-level features and high-level features, we first apply average pooling to generate feature maps with the same resolution. Then, we concatenate them separately into two larger pyramid features. We fuse both features using the self-attention mechanism \cite{vaswani2017attention} since it has shown excellent ability in capturing long-range dependency. The self-attention mechanism is a Query-Key-Value architecture. It computes the scaled dot product of Query and Key and uses the result as a weight on Value. Formally, given an input feature $ X $, to compute its self-attention results, we first embed $ X $ to three different matrices $ \boldsymbol{Q} $, $ \boldsymbol{K} $, $ \boldsymbol{V} $, representing Query, Key, and Value:

\begin{align}
 \boldsymbol{Q} = \boldsymbol{XW_Q}, \quad\boldsymbol{K} = \boldsymbol{XW_K}, \quad\boldsymbol{V} = \boldsymbol{XW_V}
\end{align}
Then the self-attention results can be computed by:

\begin{align}\label{formula:sa}
 \boldsymbol{S} = \sigma\left(\frac{\boldsymbol{QK}^T}{\sqrt{d}}\right)\boldsymbol{V}
\end{align}
where $ d $ is the dimension of $\boldsymbol{K}$, $ \sigma $ is the softmax function.

Finally, we concatenate the output features and predict the Cholesky decomposition through a fully connected layer. Thus, the covariance matrix can be computed using its Cholesky decomposition (shown in Eq. \ref{eq:CD}).

\subsection{Loss Function}\label{section:LF}

The loss function of our method, similar to the negative log-likelihood of the anisotropic Gaussian function, can be expressed as follows:

\begin{align}\label{formula:loss}
 L = \left(\boldsymbol{\hat{x}_i} - \boldsymbol{x_i}\right)^T\boldsymbol{\hat{\Sigma}}_i^{-1}\left(\boldsymbol{\hat{x}_i} - \boldsymbol{x_i}\right) + \alpha log\left|\boldsymbol{\hat{\Sigma}_i}\right|
\end{align}
where $ \boldsymbol{\hat{x}_i} $ and $ \boldsymbol{x_i} $ are the predicted and ground truth locations of the $ i $-th landmark, respectively. $ \boldsymbol{\hat{\Sigma}_i} $ is the predicted covariance matrix.

The first term in Eq.~\ref{formula:loss}  is the squared Mahalanobis distance between the predicted landmark and the ground truth. The second term in Eq.~\ref{formula:loss} is a regularization to prevent the distribution from becoming excessively flattened. $ \alpha $ is a hyperparameter to adjust the weight of the regularization term. In our experiment, we empirically set it to 0.1. 
% 为啥要二分之一
% 权重

\setlength{\tabcolsep}{3pt}
\begin{table*}[t]
\begin{center}
\caption{Results of ablation experiments.}
\label{table:table2}
\begin{tabular}{@{}ccccccccccc@{}}
\toprule
\multirow{3}{*}{Model} & \multicolumn{5}{c}{Validation Set} & \multicolumn{5}{c}{Test Set}  \\ \cmidrule(l){2-6} \cmidrule(l){7-11} & \multirow{2}{*}{MRE} & \multicolumn{4}{c}{SDR} & \multirow{2}{*}{MRE} & \multicolumn{4}{c}{SDR} \\ & & 2mm & 2.5mm & 3mm & 4mm & & 2mm & 2.5mm & 3mm & 4mm \\ \cmidrule(l){1-11}
U-Net & 1.24 & 84.84 & 90.52 & 93.75 & 97.40 & 1.61 & 71.89 & 80.63 & 86.36 & 93.68 \\
Exp-U-Net & 1.23 & 84.59 & 91.64 & 94.87 & 98.28 & \textbf{1.48} & \textbf{75.05} & \textbf{82.84} & \textbf{88.68} & 94.42 \\
Ours & \textbf{1.16} & \textbf{86.25} & \textbf{92.18} & \textbf{95.72} & \textbf{98.59} & \textbf{1.48} & 74.26 & 82.11 & 88.57 & \textbf{95.21} \\ \bottomrule
\end{tabular}
\end{center}
\end{table*}
\setlength{\tabcolsep}{1.4pt}

\begin{figure}[!t]
\centering
\includegraphics[height=7cm]{bigger_fig4.png}
\caption{The result samples of our method. The images in the first row are from the validation set, and the others are from the test set. The indigo and yellow points represent the ground truth landmarks and predicted landmarks, respectively. The red numbers indicate the indices of landmarks.}
% 颜色太接近了  可以搞一个放大的那种，加序号
\label{fig:fig3}
\end{figure}

\section{Experiments}
\label{sec:Experiments}

\subsection{Experimental Setting}\label{section:ES}

\textbf{Datasets.} We conduct experiments on IEEE ISBI Challenge 2015 Dataset \cite{wang2016benchmark}, which is widely used in cephalometric landmark detection tasks. It contains 400 cephalometric radiograph samples with a size of $ 1935 \times 2400 $, each labeled with 19 landmarks by two doctors. We choose the average of two annotations as the ground truth. Following previous methods \cite{chen2019cephalometric,oh2020deep}, we set the sizes of the training set, validation set, and test set to 150, 150, and 100, respectively. The result samples are illustrated in Fig.\ref{fig:fig3}. 

\noindent\textbf{Evaluation.} We use two metrics to evaluate the performance: Mean Radial Error (MRE) and Successful Detection Rate (SDR) in different radii (2mm, 2.5mm, 3mm, and 4mm). These standards are computed as follows:

\begin{gather}
 \text{MRE} = \frac{\sum_{i=1}^{n}\sqrt{\Delta x_i^2 + \Delta y_i^2}}{n} \\
 \text{SDR} = \frac{N_{acc}}{N_{all}} \times 100\%
 % n换个大写字母
\end{gather}
where $ \Delta x_i $ and $ \Delta y_i $ are the absolute differences between the $i$-th ground truth landmark and the corresponding predicted landmark in the x and y axis, respectively. $ N_{acc} $ is the number of successful detections and $ N_{all} $ is the number of detections. A successful detection is defined as the real distance between the two landmarks being lower than the precision radius.

\noindent {\bf Implementation Details.}  For a fair comparison, we resize the cephalometric radiographs to $ 800 \times 640 $ and normalize them for further training. We use PyTorch to build our framework and use Adam \cite{kingma2014adam} as our optimizer. The learning rate is set to 3e-4, and the weight decay is 1e-4.

\subsection{Comparison with Other Methods}\label{section:CWOM}

We select six representative landmark detection methods for comparison. The experimental results shown in Tab. \ref{table:table1} demonstrate that our method achieves better performance on MRE and outperforms existing SOTA methods on SDR in 3mm and 4mm radii. For localization evaluated by SDR in 2mm and 2.5mm radii, our method also achieves comparable results with the SOTA method \cite{chen2019cephalometric}. 

The results show that our method has an overall better result, but compared with Chen \textit{et al.} \cite{chen2019cephalometric}, our method is slightly less effective in terms of more accurate predictions. The method in \cite{chen2019cephalometric} uses not only a heatmap but also two offset maps to predict the landmarks. In their approach, the heatmap only provides a rough prediction, and the offset maps are utilized to precisely locate the position. However, due to the proposed Pyramid Covariance Predictor, our method can improve the performance of the heatmap and achieve comparable results using only heatmaps. Additionally, our method has a better result in larger precision radii. More comparison experiments are shown in the Appendix.
% \textbf{It indicates that our method can make the relatively poor predictions more precise and thus has an overall better result on MRE.}

\subsection{Ablation Studies}\label{section:AS}

In this section, we conduct ablation studies on the Pyramid Covariance Predictor and use the classic U-Net framework as the baseline model. To demonstrate the effectiveness of the proposed Pyramid Covariance Predictor, we also compare our model with the traditional U-Net framework with similar computation and parameter levels (Exp-U-Net). Exp-U-Net is constructed by adding convolution layers.

The experimental results are shown in Tab.~\ref{table:table2}. Our method outperforms the compared methods in all metrics on the validation set. For the test set, our method also achieves better results in MRE and SDR on 4mm radius. Although Exp-U-Net has better performance on the test set in other precision radii, the performance gap between our method and Exp-U-Net gradually narrows with an increase in the precision radius. These results also show that our method can perform better in larger precision radii.

\begin{figure}[!t]
\centering
\includegraphics[height=7cm]{more_fig5.png}
\caption{A comparison between our predicted Gaussian distributions (the lower three images) and the predetermined Gaussian distributions generated by Chen \textit{et al.} \cite{chen2019cephalometric} (the upper three images) is shown. Cyan points represent the landmarks, and yellow ellipses indicate the distribution of each landmark.}
\label{fig:fig4}
\end{figure}

\subsection{Uncertainty Estimation}\label{section:UE}

In our work, we also predict the covariance matrix and obtain the distribution for each landmark. The distributions we predict differ from the predetermined distributions used in most of the current heatmap-based methods, as illustrated in Fig.~\ref{fig:fig4}. We also measure the uncertainty of the predicted landmarks and compare it with the predicted uncertainty; the details are discussed in the Appendix.

The predicted distributions of our method are intuitively in line with the annotation uncertainty. For each ellipse in the right image of Fig.~\ref{fig:fig4}, the direction of the major axis conforms to the direction of the edge to a certain degree. Therefore, the possibility along the normal direction decreases more rapidly than that along the edge, which is in accordance with our cognition. The results show that a heatmap-based landmark detection framework can also be used to model the uncertainty.

In addition, some neighbor ellipses overlap in the left image of Fig.~\ref{fig:fig4}, especially in the areas where landmarks are relatively densely distributed. This indicates that those pixels in the overlapping area may be detected as multiple landmarks with similar probability, which may confuse the model. However, in the generated distributions of our method, each distribution area can be well separated, which further demonstrates the effectiveness of our method.

\section{Conclusion}
\label{sec:Conclusion}

In this paper, we propose the Pyramid Covariance Predictor to discover the \textit{aleatoric} uncertainty of each landmark. The Pyramid Covariance Predictor makes use of multi-scale features and predicts the covariance matrix of the anisotropic Gaussian distribution to better represent the distributions of landmarks. Experimental results show that our method can estimate the uncertainty to some degree and achieve overall better results than other compared methods in cephalometric landmark detection.

% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------

\bibliographystyle{IEEEbib}
\bibliography{icme2023template}

\input{supple}

\end{document}
