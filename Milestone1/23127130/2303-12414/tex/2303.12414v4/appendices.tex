\begingroup
\let\clearpage\relax 
% \onecolumn %%% For
\onecolumn

\appendices 
\setcounter{lemma}{0}
\setcounter{proposition}{0}
\setcounter{theorem}{0}
\setcounter{definition}{0}
\setcounter{assumption}{0}
\section{Preliminaries and Notations used in the Proofs}\label{app:notations}
In the following Appendices, in order to increase the tractability of the the expressions inside the proofs, we introduce the  the following scaled parameters: (i) strong convexity denoted by $\tilde{\mu}$, normalized gradient diversity by $\tilde{\delta}$, step size by $\tilde{\eta_t}$, SGD variance $\tilde{\sigma}$, and consensus error inside the clusters $\tilde{\epsilon}_c^{(t)}$ and across the network $\tilde{\epsilon}^{(t)}$ inside the cluster as follows:
\begin{itemize}[leftmargin=5mm]
\item  \textbf{Strong convexity}:
 $F$ is $\mu$-strongly convex, i.e.,
\begin{align} 
    F(\mathbf w_1) \geq  F(\mathbf w_2)&+\nabla F(\mathbf w_2)^\top(\mathbf w_1-\mathbf w_2)+\frac{\tilde{\mu}\beta}{2}\Big\Vert\mathbf w_1-\mathbf w_2\Big\Vert^2,~\forall { \mathbf w_1,\mathbf w_2},
\end{align}
where as compared to~Assumption~\ref{Assump:SmoothStrong}, we considered $\tilde{\mu}=\mu/\beta\in(0,1)$.
\item \textbf{Gradient diversity}: The gradient diversity across the device clusters $c$ is measured via two non-negative constants $\delta,\zeta$ that satisfy 
\begin{align} 
    \Vert\nabla\hat F_c(\mathbf w)-\nabla F(\mathbf w)\Vert
    \leq \sqrt{\beta}\tilde{\delta}+ 2\omega\beta \Vert\mathbf w-\mathbf w^*\Vert,~\forall c, \mathbf w,
\end{align}
where as compared to Assumption~\ref{gradDiv}, we presumed $\tilde{\delta}=\delta/\sqrt{\beta}$ and $\omega=\zeta/(2\beta)\in [0,1]$.

\item \textbf{Step size}: The local updates to compute \textit{intermediate updated local model} at the devices is expressed as follows:
\begin{align} 
    {\widetilde{\mathbf{w}}}_i^{(t)} = 
           \mathbf w_i^{(t-1)}-\frac{\tilde{\eta}_{t-1}}{\beta} \widehat{\mathbf g}_{i}^{(t-1)},~t\in\mathcal T_k,
\end{align}
where we used the scaled in the step size, i.e., ${\tilde{\eta}_{t-1}}=\eta_{t-1}{\beta}$. Also, when we consider decreasing step size, we consider scaled parameter $\tilde{\gamma}$ in the step size as follows: $\frac{\gamma}{t+\alpha}=\frac{\tilde{\gamma}/\beta}{t+\alpha}$ indicating that $\tilde{\gamma}=\gamma\beta$.

\item \textbf{Variance of the noise of the estimated gradient through SGD}:
The variance on the SGD noise is bounded as:
\begin{align}
    \mathbb{E}[\Vert{\mathbf n}_{j}^{(t)}\Vert^2]\leq \beta\tilde{\sigma}^2, \forall j,t,
\end{align}
where we consider scaled SGD noise as: $\tilde{\sigma}^2=\sigma^2/\beta$.

\item \textbf{Average of the consensus error inside cluster $c$ and across the network}: $\epsilon_c^{(t)}$ is an upper bound on the average of the consensus error inside cluster $c$ for time $t$, i.e.,
    \begin{align}
        \frac{1}{s_c}\sum\limits_{i\in \mathcal S_c}\Vert \mathbf{e}_i^{(t)}\Vert^2 \leq (\tilde{\epsilon}_c^{(t)})^2/\beta,
    \end{align}
    where we use the scaled consensus error $(\tilde{\epsilon}_c^{(t)})^2=\beta(\epsilon_c^{(t)})^2$.
    % When the consensus is assumed to be decreasing over time, we use the scaled coefficient $\tilde{\phi}_c$, where ... ....
    % $(\epsilon_c^{(t)})^2=(\tilde{\epsilon}_c^{(t)})^2/\beta=\eta_t^2\phi_c^2=\tilde{\eta}_t^2\tilde{\phi_c}^2/\beta$, which indicates that $\phi_c^2=\tilde{\phi_c}^2/\beta$. 
    Also, in the proofs we use the notation $\epsilon$ to denote the average consensus error across the network defined as $(\epsilon^{(t)})^2=\sum_{c=1}^N\varrho_c(\epsilon_c^{(t)})^2$. When the consensus is assumed to be decreasing over time we use the scaled coefficient $\tilde{\phi}^2=\phi^2/\beta$, resulting in  $(\epsilon^{(t)})^2=\eta_t^2\tilde{\phi}^2\beta $.
    % \begin{align}
    %  \sum_{c=1}^N\varrho_c\phi_c^2=\phi^2,
    % \end{align}
    % where $\phi^2=\tilde{\phi}^2/\beta$.
\end{itemize}

\section{Proof of Proposition \ref{Local_disperse}} \label{app:Local_disperse}
% \iffalse
% \addFL{
% \begin{proposition} 
%         Under Assumption \ref{beta}, if $\eta_t=\frac{\gamma}{t+\alpha}$, $\epsilon_c^{(t)}=\eta_t\phi_c,\forall c$,
%     $\forall t \in \mathcal T_k$,$\alpha\geq \max\{2/\vartheta^2,3\}$,
%     $2/\mu\leq\gamma\leq\vartheta/\beta\alpha$ and $C=3$, where $\sum_d\varrho_d\phi_d\leq\phi$
%     % \nm{you need to remember this condition when you use this proposition!}
%     , the following upper bound on the local model dispersion of the devices holds:
%         \begin{align*}
%             &A^{(t)}\leq
%             24C^2\eta_{t}^2[1+\eta_{0}(2\beta\omega-\mu/2)]^2
%             \frac{(t_{k-1}+\alpha-1)^2}{\mu\gamma^2} [F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]\\&
%             +12C^2\eta_{t}^2[1+\eta_{0}(2\beta\omega-\mu/2)]^2\tau_k^2(\beta\phi\eta_{t_{k-1}}+\sigma)^2
%             +3C^2\eta_{t}^2(2\beta\phi\eta_{0}+\sqrt{2}\sigma+2\delta)^2
%             +\phi^2\eta_{t}^2.
%         \end{align*}
% \end{proposition}
% }
% \begin{proof}
% {\color{red}
% Note that 
%     \begin{align}
%         \Vert\mathbf w_i^{(t)}-\bar{\mathbf w}^{(t)}\Vert_2^2
%         =
%         \Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert_2^2
%         +\Vert \mathbf e_i^{{(t)}}\Vert^2
%         +2[\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}]^\top \mathbf e_i^{{(t)}}.
%     \end{align} 
%     Then, using Definition \ref{paraDiv} and the fact that
%     $\frac{1}{s_c^{(k)}}\sum\limits_{i\in \mathcal S_c^{(k)}}\mathbf e_i^{{(t)}}=\bf 0$, it follows that 
%     \begin{align}
%         \frac{1}{s_c^{(k)}}\sum\limits_{i\in \mathcal S_c^{(k)}}\Vert\mathbf w_i^{(t)}-\bar{\mathbf w}^{(t)}\Vert_2^2
% \leq
%         \Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert_2^2
%         +(\epsilon_c^{(t)})^2.
%     \end{align} 
% Taking the weighted average across cluster and the expectation, we then obtain
% \begin{align}
%       A^{(t)}\leq
%         \mathbb E\left[\sum_c\varrho_c\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert_2^2\right]
%         +\phi^2\eta_t^2.
%     \end{align} 
% To further bound the right hand side,
% we first determine an upper bound to $\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert$. We have
%     \begin{align}\label{eq:initdifCO}
%         &\bar{\mathbf w}_c^{(t+1)}-\mathbf w^* = \bar{\mathbf w}_c^{(t)}-\mathbf w^*-\eta_{t} \nabla F(\bar{\mathbf w}_c^{(t)})
%         \nonumber \\&
%         -\eta_{t} \frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}} [\nabla F_j(\mathbf w_j^{(t)})-\nabla F_j(\bar{\mathbf w}_c^{(t)})]
%         -\eta_{t} \frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}} \mathbf n_j^{(t)}.
%     \end{align}
%     Taking the norm and applying the triangle inequality, we obtain
%     \begin{align}\label{eq:initdifCO}
%         &\Vert\bar{\mathbf w}_c^{(t+1)}-\mathbf w^*\Vert \leq
%         \Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*-\eta_{t} \nabla F(\bar{\mathbf w}_c^{(t)})\Vert
%         \nonumber \\&
%         +\eta_{t} \frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}} \Vert\nabla F_j(\mathbf w_j^{(t)})-\nabla F_j(\bar{\mathbf w}_c^{(t)})\Vert
%         +\eta_{t}\Vert \frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}} \mathbf n_j^{(t)}\Vert.
%     \end{align}
%     To bound the terms on the right hand side above, we first use the $\mu$-strong convexity and $\beta$-smoothness of $F(\cdot)$, when $\eta_t\leq\frac{\vartheta}{\beta}$, to get
%     \begin{align} \label{eq:strCVX_use}
%         &\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*-\eta_t \nabla F(\bar{\mathbf w}_c^{(t)})\Vert
%         \nonumber \\&
%         = 
%         \sqrt{\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert^2+\eta_t^2\Vert\nabla F(\bar{\mathbf w}_c^{(t)})\Vert^2-2\eta_t(\bar{\mathbf w}_c^{(t)}-\mathbf w^*)^\top\nabla F(\bar{\mathbf w}_c^{(t)})}
%         \nonumber \\&
%         \overset{(a)}{\leq} 
%         \sqrt{(1-2\eta_t\mu)\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert^2+\eta_t^2\Vert\nabla F(\bar{\mathbf w}_c^{(t)})\Vert^2}
%         \nonumber \\&
%         \overset{(b)}{\leq}
%         \sqrt{(1-2\eta_t\mu+\eta_t^2\beta^2)}\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert
%         \nonumber \\&
%         \overset{(c)}{\leq} 
%         \sqrt{1-\eta_t\mu}\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert
%         \nonumber \\&
%         \overset{(d)}{\leq}
%         (1-\frac{\eta_t\mu}{2})\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert,
%     \end{align}
%     where $(a)$ results from the property of a strongly convex function, i.e., $(\bar{\mathbf w}_c^{(t)}-\mathbf w^*)^\top\nabla F(\bar{\mathbf w}_c^{(t)})\geq\mu\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert^2$, $(b)$ comes from the property of smooth functions, i.e., $\Vert\nabla F(\bar{\mathbf w}_c^{(t)})\Vert^2\leq\beta^2\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert^2$, $(c)$ comes from the fact that $\eta_t\leq\vartheta/\beta$ and $(d)$ comes from the fact that $1-\eta_t\mu\leq(1-\frac{\eta_t\mu}{2})^2$.
%     % \nm{you need to explain these steps..why have my comments be neglected? (see my "commented" comment below)}
%     % \nm{you need to explain the steps... add "(a)", "(b)"... on top of the "$\leq$" and then explain: "in step (a), we apply...." and so on }
%     % \nm{you might not need to do the last inequality.. in fact, it was used only in the previous formulation to simplify the eigenvalue decomposition..use the previous inequality insted, which allows you to relax the condition $\eta\leq\vartheta/\beta$}
%     % \nm{before putting everything together, I would do this:}
%     Also, using $\beta$-smoothness, we have 
%     \begin{align} \label{eq:beta_use}
%         \Vert\nabla F_j(\mathbf w_j^{(t)})-\nabla F_j(\bar{\mathbf w}_d^{(t)})\Vert
%         \leq
%         \beta\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\Vert\mathbf w_j^{(t)}-\bar{\mathbf w}_d^{(t)}\Vert.
%     \end{align}
%         Moreover, using Definition \ref{paraDiv}, we get
%     \begin{align} 
%         \frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\Vert\mathbf w_j^{(t)}-\bar{\mathbf w}_d^{(t)}\Vert
%         &=
%         \frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\Vert\mathbf e_j^{(t)}\Vert
%         \nonumber \\&\leq
%         \sqrt{\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\Vert\mathbf e_j^{(t)}\Vert^2}
%         \leq\epsilon_d^{(t)},
%     \end{align}
% so that
%     \begin{align} \label{eq:epsilon_use}
%         \frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\Vert\nabla F_j(\mathbf w_j^{(t)})-\nabla F_j(\bar{\mathbf w}_d^{(t)})\Vert
%         \leq
%         \beta\epsilon_d^{(t)}.
%     \end{align}
%     Hence, we can further upper bound \eqref{eq:initdifCO} as
%     \begin{align}
%         &\Vert\bar{\mathbf w}_c^{(t+1)}-\mathbf w^*\Vert \leq
% (1-\frac{\eta_t\mu}{2})\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert
%         \nonumber \\&
%         +\eta_{t}\beta\epsilon_c^{(t)}
%         +\eta_{t}\Vert \frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}} \mathbf n_j^{(t)}\Vert.
%     \end{align}
%   Taking the weighted average $\sum\limits_{d=1}^N\varrho_{d}$ on both sides of the above inequality, and using the fact that $\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\epsilon_d^{(t)}\leq $, yields
%     \begin{align}\label{eq:normCOS}
%         &\sum\limits_{d=1}^N\varrho_{d}\Vert\bar{\mathbf w}_d^{(t+1)}-\mathbf w^*\Vert \leq (1-\frac{\eta_{t}\mu}{2})\sum\limits_{d=1}^N\varrho_{d}\Vert\bar{\mathbf w}_d^{(t)}-\mathbf w^*\Vert
%         \nonumber \\&
%         +\eta_{t} \sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}} \Vert\mathbf n_j^{(t)}\Vert
%         +\eta_{t}\beta \epsilon^{(t)}.
%     \end{align}
%     Taking the expectation on both sides and 
%     using Fact~\ref{fact:1} (see Appendix \ref{app:fact1}), we finally obtain
%     \begin{align} \label{141}
%         &\sqrt{\mathbb E[\Vert\bar{\mathbf w}_c^{(t+1)}-\mathbf w^*\Vert^2]} 
%         \leq
%         (1-\frac{\eta_{t}\mu}{2})\sqrt{\mathbb E[\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert^2]}
%         % \nonumber \\&
%         +\eta_{t}(\beta\epsilon_c^{(t)}+\sigma).
%     \end{align}
% and
%     \begin{align} \label{142}
%          \sqrt{\mathbb E(\sum\limits_{d=1}^N\varrho_{d}[\Vert\bar{\mathbf w}_d^{(t+1)}-\mathbf w^*\Vert)^2]} 
%       & \leq
%         (1-\frac{\eta_{t}\mu}{2})\sqrt{\mathbb E[(\sum\limits_{d=1}^N\varrho_{d}\Vert\bar{\mathbf w}_d^{(t)}-\mathbf w^*\Vert)^2]}
%         +\eta_{t}(\beta\epsilon^{(t)}+\sigma),
%     \end{align}
%     where in both cases we used the independence of gradient noise across agents, and $\mathbb E[\Vert\mathbf n_j^{(t)}\Vert^2]\leq \sigma^2$.
% Let $x_c^{(t)}=\sqrt{\mathbb E[\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert^2]}$. Using the fact that $\eta_t=\frac{\gamma}{t+\alpha}$ and $\epsilon_c^{(t)}=\phi_c\eta_t$, we obtain
%     \begin{align} \label{x_t}
%         &[t+\alpha]x_c^{(t+1)}
%         % \nonumber \\&
%         \leq\left[\frac{t+\alpha-\gamma\mu/2}{t+\alpha-1}\right][t+\alpha-1]x_c^{(t)}+\gamma(\beta\phi_c\eta_t+\sigma)
%         \nonumber \\&
%          \leq[t+\alpha-1]x_c^{(t)}
%         \max_{u\geq 1}\left[\frac{u+\alpha-\gamma\mu/2}{u+\alpha-1}\right]+\gamma(\phi_c\vartheta+\sigma)
%         \nonumber \\&
%         \leq 
%         [t+\alpha-1]x_c^{(t)}+\gamma(\phi_c\vartheta+\sigma),
%         % \leq\alpha x(0)+\sum\limits_{i=1}^{k}\tau_i\gamma(\beta\epsilon_c(t_{i-1})+\sigma)
%     \end{align}
%     where in the second step we used the fact that
%     $\gamma\mu/2\geq 1$ and $\eta_t\leq\eta_0\leq \gamma/\alpha\leq \vartheta/\beta$, and by induction
%     \begin{align} \label{x_t}
%         &[t+\alpha-1]x_c^{(t)}
%         \leq 
%         [t_{k-1}+\alpha-1]x_c^{(t_{k-1})}+(t-t_{k-1})\gamma(\phi_c\vartheta+\sigma),
%         % \leq\alpha x(0)+\sum\limits_{i=1}^{k}\tau_i\gamma(\beta\epsilon_c(t_{i-1})+\sigma)
%     \end{align}
%     % \addFL{
%     % Since synchronization do not affect $x_c^{(t)}$, we have
%     % \begin{align} 
%     %     &[t+\alpha-1]x_c^{(t)}
%     %     \leq 
%     %     [\alpha-1]x_c^{(0)}+t\gamma(\phi_c\vartheta+\sigma),
%     %     \leq\alpha x_c^{(0)}+\sum\limits_{i=1}^{k}\tau_i\gamma(\beta\epsilon_c(t_{i-1})+\sigma)
%     % \end{align}
%     % }
% which implies
%     \begin{align}\label{eq:xt}
%         &
%         x_c^{(t)}
%         \leq 
%         \frac{t_{k-1}+\alpha-1}{t+\alpha-1}
%         \sqrt{\mathbb E[\Vert\hat{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert^2]}
%         +\tau_k\eta_{t-1}(\phi_c\vartheta+\sigma),
%     \end{align}
%     where we used the fact that $t=t-t_{k-1}\leq \tau_k$ and  $\bar{\mathbf w}_c^{(t_{k-1})}=\hat{\mathbf w}^{(t_{k-1})},\forall c$ right after synchronization.
%         Similarly, considering~\eqref{142}, letting $y^{(t)}=\sqrt{\mathbb E[(\sum\limits_{d=1}^N\varrho_{d}\Vert\bar{\mathbf w}_d^{(t)}-\mathbf w^*\Vert)^2]}$, we get
%     \begin{align} \label{y_t}
%         &[t+\alpha]y^{(t+1)}
%         % \nonumber \\&
%         \leq\left[\frac{t+\alpha-\gamma\mu/2}{t+\alpha-1}\right][t+\alpha-1]y^{(t)}+\gamma(\beta\phi\eta_t+\sigma)
%         \nonumber \\&
%          \leq[t+\alpha-1]y^{(t)}
%         \max_{u\geq 1}\left[\frac{u+\alpha-\gamma\mu/2}{u+\alpha-1}\right]+\gamma(\phi\vartheta+\sigma)
%         \nonumber \\&
%         \leq 
%         [t+\alpha-1]y^{(t)}+\gamma(\phi\vartheta+\sigma),
%     \end{align}
%     and by induction
%     \begin{align} \label{y_t}
%         &[t+\alpha-1]y^{(t)}
%         \leq 
%         [t_{k-1}+\alpha-1]y^{(t_{k-1})}+(t-t_{k-1})\gamma(\phi\vartheta+\sigma),
%     \end{align}
%  which implies
% \begin{align} \label{eq:y_t}
%         &
%         y^{(t)}
%         \leq 
%         \frac{t_{k-1}+\alpha-1}{t+\alpha-1}
%         \sqrt{\mathbb E[\Vert\hat{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert^2]}
% +\tau_k\eta_{t-1}(\phi\vartheta+\sigma),
%     \end{align}
%         where we used the fact that $t=t-t_{k-1}\leq \tau_k$ and $\bar{\mathbf w}_c^{(t_{k-1})}=\hat{\mathbf w}^{(t_{k-1})},\forall c$ right after synchronization.
% }
% We now bound the difference between the average of local parameters at an arbitrary cluster $c$ and the global average of parameters as follows:
%     \begin{align} 
%         &\bar{\mathbf w}_c^{(t+1)}-\bar{\mathbf w}^{(t+1)}=\Big[\bar{\mathbf w}_c^{(t)}-\mathbf w^*-\eta_{t}\nabla F(\bar{\mathbf w}_c^{(t)})\Big]
%         -\sum\limits_{d=1}^N\varrho_{d}\Big[\bar{\mathbf w}_d^{(t)}-\mathbf w^*-\eta_{t}\nabla F(\bar{\mathbf w}_d^{(t)})\Big]
%         \nonumber \\&
%         +\eta_{t}[\nabla F(\bar{\mathbf w}_c^{(t)})-\nabla\hat F_c(\bar{\mathbf w}_c^{(t)})]
%         -\eta_{t}\sum\limits_{d=1}^N\varrho_{d}[\nabla F(\bar{\mathbf w}_d^{(t)})-\nabla\hat F_d(\bar{\mathbf w}_d^{(t)})]
%         \nonumber \\&
%         -\eta_{t}\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\mathbf n_j^{(t)}
%         +\eta_{t}\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\mathbf n_j^{(t)}
%         -\eta_{t}\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\Big[\nabla F_j(\mathbf w_j ^{(t)})-\nabla F_j(\bar{\mathbf w}_c ^{(t)})\Big]\nonumber \\&
%         +\eta_{t}\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\Big[\nabla F_j(\mathbf w_j ^{(t)})-\nabla F_j(\bar{\mathbf w}_d^{(t)})\Big].
%     \end{align}  
%     % \nm{\text{sum over d! please check also next eqs, there are similar errors}}
%     By applying the triangular inequality on both hand sides of the above equation, we obtain 
%     % \nm{be consistent with notation! $g-\nabla=n$!}
%     \begin{align} \label{w_c-w:2}
%         &\Vert\bar{\mathbf w}_c^{(t+1)}-\bar{\mathbf w}^{(t+1)}\Vert
%         \nonumber \\&
%         \leq 
%         \Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*-\eta_{t}\nabla F(\bar{\mathbf w}_c^{(t)})\Vert
%         +\sum\limits_{d=1}^N\varrho_{d}\Vert\bar{\mathbf w}_d^{(t)}-\mathbf w^*-\eta_{t}\nabla F(\bar{\mathbf w}_d^{(t)})\Vert
%         \nonumber \\&
%         +\eta_{t}\Vert\nabla F(\bar{\mathbf w}_c^{(t)})-\nabla\hat F_c(\bar{\mathbf w}_c^{(t)})\Vert
%         +\eta_{t}\sum\limits_{d=1}^N\varrho_{d}\Vert\nabla F(\bar{\mathbf w}_d^{(t)})-\nabla\hat F_d(\bar{\mathbf w}_d^{(t)})\Vert
%         \nonumber \\&
%         +\eta_{t}\left\Vert\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\mathbf n_j^{(t)}-\sum\limits_{c=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\mathbf n_j^{(t)}\right\Vert
%         +\eta_{t}\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\Vert\nabla F_j(\mathbf w_j^{(t)})-\nabla F_j(\bar{\mathbf w}_c^{(t)})\Vert
%                 \nonumber \\&
%         +\eta_{t}\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\Vert\nabla F_j(\mathbf w_j^{(t)})-\nabla F_j(\bar{\mathbf w}_d^{(t)})\Vert.
%     \end{align}   
% Using Definition \ref{gradDiv}, we have
% \begin{align}\label{eq:GradDivSlack}
% \Vert\nabla F(\bar{\mathbf w}_c^{(t)})-\nabla\hat F_c(\bar{\mathbf w}_c^{(t)})\Vert
% \leq
% \delta+2\beta\omega
% \Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert.
% \end{align}
%     Using this inequality along with \eqref{eq:beta_use} and \eqref{eq:epsilon_use}, we further bound \eqref{w_c-w:2} as 
%     \begin{align}\label{eq:midnorm}
%         &\Vert\bar{\mathbf w}_c^{(t+1)}-\bar{\mathbf w}^{(t+1)}\Vert
%         \leq 
%         (1-\frac{\eta_{t}\mu}{2})\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert
%         % \nonumber \\&
%         +(1-\frac{\eta_{t}\mu}{2})\sum\limits_{d=1}^N\varrho_d\Vert\bar{\mathbf w}_d^{(t)}-\mathbf w^*\Vert
%         \nonumber \\&
%         +\eta_{t}\Big[\delta+2\beta\omega\Vert\bar{\mathbf w}_c^{(t)}- \mathbf w^*\Vert\Big]
%         +\eta_{t}\sum\limits_{d=1}^N\varrho_{d}\Big[\delta+2\beta\omega\Vert\bar{\mathbf w}_d^{(t)}- \mathbf w^*\Vert\Big]
%         \nonumber \\&
%         +\eta_{t}\left\Vert\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\mathbf n_j^{(t)}
%         -\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\mathbf n_j^{(t)}\right\Vert
%         +\eta_{t}^2\beta(\phi_c+\phi),
%     \end{align}
%     Using Fact~\ref{fact:1} (see Appendix \ref{app:fact1}) combined with~\eqref{eq:midnorm}, we get
%     % \nm{please explain the steps!}
%     \begin{align} \label{goal}
%         &\sqrt{\mathbb E[\Vert\bar{\mathbf w}_c^{(t+1)}-\bar{\mathbf w}^{(t+1)}\Vert^2]}
%         \leq
%         [1+\eta_{t}(2\beta\omega-\mu/2)](x_c^{(t)}+y^{(t)})
%         \nonumber \\&
%         +\eta_{t}(\phi\vartheta+\phi_c\vartheta+\sqrt{2}\sigma+2\delta),
%     \end{align}
%     where to obtain~\eqref{goal} we used the facts that
%     $\sum\limits_{d=1}^N\varrho_{d}\epsilon_d^{(t)}\leq \epsilon^{(t)}$, and
%     \begin{align}\label{eq:nextGoal}
%           &\mathbb E\Big(\Vert\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\mathbf n_j^{(t)}-\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\mathbf n_j^{(t)}\Vert\Big)^2
%           \nonumber \\&
%           =(1-\varrho_{c})^2\frac{1}{s_{c}^2}\sum\limits_{j\in\mathcal S_{c}}\mathbb E[\Vert\mathbf n_j^{(t)}\Vert^2]+\sum\limits_{d\neq c}\varrho_{d}^2\frac{1}{s_{d}^2}\sum\limits_{j\in\mathcal S_{d}}\mathbb E[\Vert \mathbf n_j^{(t)}\Vert^2]
%           \leq 2\sigma^2.
%     \end{align} 
%   In~\eqref{eq:nextGoal} we used the facts that $\mathbb E[\mathbf n_i^{{(t)}}]=0$,  $\mathbb E[\Vert\mathbf n_i^{{(t)}}\Vert^2]\leq\sigma^2$, and
%     $\sum\limits_{d\neq c}\varrho_{d}^2\frac{1}{s_{d}^2}
%     \leq\sum\limits_{d\neq c}\varrho_{d}^2\leq\sum\limits_{d\neq c}\varrho_{d}\leq 1$.

% \add{We use the bounds on $x_c^{(t)}$ and $y^{(t)}$ given by~\eqref{eq:xt} and~\eqref{eq:y_t} to further bound
% \begin{align}
%         &\sqrt{\mathbb E[\Vert\bar{\mathbf w}_c^{(t+1)}-\bar{\mathbf w}^{(t+1)}\Vert^2]}
%         \leq
%         2[1+\eta_{t}(2\beta\omega-\mu/2)]
% \frac{t_{k-1}+\alpha-1}{\gamma}\eta_{t-1}\Vert\hat{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert\\&
% +\eta_{t-1}\tau_k[1+\eta_{t}(2\beta\omega-\mu/2)]((\phi+\phi_c)\vartheta+2\sigma)
%         \nonumber \\&
%         +\eta_{t}(\phi\vartheta+\phi_c\vartheta+\sqrt{2}\sigma+2\delta),
%     \end{align}
%      Taking the square of both sides and applying Cauchy–Schwarz inequality $(\sum_{i=1}^{j} a_i)^2\leq j \sum_{i=1}^{j} (a_i)^2$, we obtain
%      \begin{align}
%         &\mathbb E[\Vert\bar{\mathbf w}_c^{(t+1)}-\bar{\mathbf w}^{(t+1)}\Vert^2]
%         \leq
%         12[1+\eta_{t}(2\beta\omega-\mu/2)]^2
% \frac{(t_{k-1}+\alpha-1)^2}{\gamma^2}\eta_{t-1}^2\Vert\hat{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert^2\\&
% +3[1+\eta_{t}(2\beta\omega-\mu/2)]^2\tau_k^2\eta_{t-1}^2(\beta(\phi+\phi_c)\eta_{t_{k-1}}+2\sigma)^2
%         \nonumber \\&
%         +3\eta_{t}^2(\beta\phi\eta_t+\beta\phi_c\eta_t+\sqrt{2}\sigma+2\delta)^2,
%     \end{align}
%         Taking the weighted average $\sum\limits_{d=1}^N\varrho_{d}$
%         and using the bound
%         $\Vert\hat{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert\leq 2/\mu [F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]$ (from strong convexity)
%         we obtain
%          \begin{align}
%         &\mathbb E[\sum\limits_{d=1}^N\varrho_{d}\Vert\bar{\mathbf w}_d^{(t+1)}-\bar{\mathbf w}^{(t+1)}\Vert^2]
%         \leq
%         24[1+\eta_{t}(2\beta\omega-\mu/2)]^2
% \frac{(t_{k-1}+\alpha-1)^2}{\mu\gamma^2}\eta_{t-1}^2 [F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]\\&
% +12[1+\eta_{t}(2\beta\omega-\mu/2)]^2\tau_k^2\eta_{t-1}^2(\beta\phi\eta_{t_{k-1}}+\sigma)^2
%         \nonumber \\&
%         +3\eta_{t}^2(2\beta\phi\eta_t+\sqrt{2}\sigma+2\delta)^2,
%     \end{align}
%     Finally, using  
%     \begin{align}
%         \Vert\mathbf w_i^{(t)}-\bar{\mathbf w}^{(t)}\Vert_2^2
%         =
%         \Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert_2^2
%         +\Vert \mathbf e_i^{{(t)}}\Vert^2
%         +2[\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}]^\top \mathbf e_i^{{(t)}},
%     \end{align} we obtain the bound in the statement, which completes the proof.
%     \begin{align}
%     &   A^{(t)}\leq
%         24[1+\eta_{t-1}(2\beta\omega-\mu/2)]^2
% \frac{(t_{k-1}+\alpha-1)^2}{\mu\gamma^2}\eta_{t-2}^2 [F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]\\&
% +12[1+\eta_{t-1}(2\beta\omega-\mu/2)]^2\tau_k^2\eta_{t-2}^2(\beta\phi\eta_{t_{k-1}}+\sigma)^2
%         +3\eta_{t-1}^2(2\beta\phi\eta_{t-1}+\sqrt{2}\sigma+2\delta)^2
%         +\phi^2\eta_t^2
%         \nonumber \\&
%         \overset{(a)}{\leq}
%         24[1+\eta_{0}(2\beta\omega-\mu/2)]^2
% \frac{(t_{k-1}+\alpha-1)^2}{\mu\gamma^2}\eta_{t-2}^2 [F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]\\&
% +12[1+\eta_{0}(2\beta\omega-\mu/2)]^2\tau_k^2\eta_{t-2}^2(\beta\phi\eta_{t_{k-1}}+\sigma)^2
%         +3\eta_{t-2}^2(2\beta\phi\eta_{0}+\sqrt{2}\sigma+2\delta)^2
%         +\phi^2\eta_{t}^2
%         \nonumber \\&
%         \overset{(b)}{\leq}
%         24C^2\eta_{t}^2[1+\eta_{0}(2\beta\omega-\mu/2)]^2
% \frac{(t_{k-1}+\alpha-1)^2}{\mu\gamma^2} [F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]\\&
% +12C^2\eta_{t}^2[1+\eta_{0}(2\beta\omega-\mu/2)]^2\tau_k^2(\beta\phi\eta_{t_{k-1}}+\sigma)^2
%         +3C^2\eta_{t}^2(2\beta\phi\eta_{0}+\sqrt{2}\sigma+2\delta)^2
%         +\phi^2\eta_{t}^2,
%     \end{align}
%     where $(a)$ results from the fact that $\frac{\eta_t}{\eta_{t-1}}\leq1$ and $(b)$ results from the fact that $\eta_{t-1}\leq C\eta_t$, where $C=3$.
% }
% \fi
% \iffalse
%     \begin{align} 
%         &\sqrt{\mathbb E[\Vert\bar{\mathbf w}_c^{(t+1)}-\bar{\mathbf w}^{(t+1)}\Vert^2]}
%         \leq
%         2\eta_{t-1}(t_{k-1}+\alpha)[1+\eta_{t}(2\beta\omega-\mu/2)]/\gamma\mathbb E\Vert\hat{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert
%         \nonumber \\&
%         +\eta_{t-1}[1+\eta_{t}(2\beta\omega-\mu/2)]\left[\tau_k(\beta[\epsilon^{(t_{k-1})}+\epsilon_c^{(t_{k-1})}]+2\sigma)\right]
%         \nonumber \\&
%         +\eta_{t}(\beta\epsilon^{(t)}+\beta\epsilon_c^{(t)}+\sqrt{2}\sigma+2\delta)
%         \nonumber \\&
%         \leq
%         2\eta_{t-1}(t_{k-1}+\alpha)[1+\eta_{t}(2\beta\omega-\mu/2)]/\gamma\mathbb E\Vert\hat{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert
%         \nonumber \\&
%         +\eta_{t-1}[1+\eta_{t}(2\beta\omega-\mu/2)]\left[\tau_k(\beta[\epsilon^{(t_{k-1})}+\epsilon_c^{(t_{k-1})}]+2\sigma)\right]
%         \nonumber \\&
%         +\eta_{t}(\beta\epsilon^{(t_{k-1})}+\beta\epsilon_c^{(t_{k-1})}+\sqrt{2}\sigma+2\delta)
%     \end{align}

%  Taking the square from both hand sides and applying the Cauchy–Schwarz inequality (i.e., $(\sum_{i=1}^{j} a_i)^2\leq j \sum_{i=1}^{j} (a_i)^2$) successively\nm{why successifely? Do in one shot} we get:
%     \begin{align}
%         &\mathbb E[\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2]
%         \leq
%         8\eta_{t-1}^2(t_{k-1}+\alpha)^2[1+\eta_{t}(2\beta\omega-\mu/2)]^2/\gamma^2\mathbb E\Vert\hat{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert^2
%         \nonumber \\&
%         +2\bigg[\eta_{t-1}[1+\eta_{t}(2\beta\omega-\mu/2)]\left[\tau_k(\beta[\epsilon^{(t_{k-1})}+\epsilon_c^{(t_{k-1})}]+2\sigma)\right]
%         \nonumber \\&
%         +\eta_{t}(\beta\epsilon^{(t_{k-1})}+\beta\epsilon_c^{(t_{k-1})}+\sqrt{2}\sigma+2\delta)\bigg]^2
%         \nonumber \\&
%         \leq
%         8\eta_{t-1}^2(t_{k-1}+\alpha)^2[1+\eta_{t}(2\beta\omega-\mu/2)]^2/\gamma^2\mathbb E\Vert\hat{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert^2
%         \nonumber \\&
%         +4\eta_{t-1}^2[1+\eta_{t}(2\beta\omega-\mu/2)]^2\left[\tau_k(\beta[\epsilon^{(t_{k-1})}+\epsilon_c^{(t_{k-1})}]+2\sigma)\right]^2
%         \nonumber \\&
%         +4\eta_{t}^2(\beta\epsilon^{(t_{k-1})}+\beta\epsilon_c^{(t_{k-1})}+\sqrt{2}\sigma+2\delta)^2
%         \nonumber \\&
%         \leq
%         8\eta_{t-1}^2(t_{k-1}+\alpha)^2[1+\eta_{t}(2\beta\omega-\mu/2)]^2/\gamma^2\mathbb E\Vert\hat{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert^2
%         \nonumber \\&
%         +12\eta_{t-1}^2[1+\eta_{t}(2\beta\omega-\mu/2)]^2 \left[\tau_k^2(\beta^2[(\epsilon^{(t_{k-1})})^2+(\epsilon_c^{(t_{k-1})})^2]+4\sigma^2)\right]
%         \nonumber \\&
%         +16\eta_{t}^2(\beta^2(\epsilon^{(t_{k-1})})^2+\beta^2(\epsilon_c^{(t_{k-1})})^2+2\sigma^2+\delta^2).
%     \end{align}
%   Taking the weighted average $\sum\limits_{d=1}^N\varrho_{d}$ from both hand sides of the above inequality gives us
%     \begin{align}
%         &\sum\limits_{c=1}^N\varrho_{c}\mathbb E[\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2]
%         \leq
%         8\eta_{t-1}^2(t_{k-1}+\alpha)^2[1+\eta_{t}(2\beta\omega-\mu/2)]^2/\gamma^2\mathbb E\Vert\hat{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert^2
%         \nonumber \\&
%         +24\eta_{t-1}^2[1+\eta_{t}(2\beta\omega-\mu/2)]^2 \left[\tau_k^2(\beta^2(\epsilon^{(t_{k-1})})^2+2\sigma^2)\right]
%         % \nonumber \\&
%         +16\eta_{t}^2(2\beta^2(\epsilon^{(t_{k-1})})^2+2\sigma^2+\delta^2)
%         \nonumber \\&
%         \overset{(a)}\leq
%         16\eta_{t-1}^2(t_{k-1}+\alpha)^2[1+\eta_{t}(2\beta\omega-\mu/2)]^2/(\mu\gamma^2)\mathbb E[F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]
%         \nonumber \\&
%         +24\eta_{t-1}^2[1+\eta_{t}(2\beta\omega-\mu/2)]^2 \left[\tau_k^2(\beta^2(\epsilon^{(t_{k-1})})^2+2\sigma^2)\right]
%         % \nonumber \\&
%         +16\eta_{t}^2(2\beta^2(\epsilon^{(t_{k-1})})^2+2\sigma^2+\delta^2).
%     \end{align}
%     % We take the unconditional expectation from both hand sides of the above inequality to get
%     % \begin{align}
%     %     &\sum\limits_{c=1}^N\varrho_{c}\mathbb E[\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2]
%     %     \leq
%     %     32(t_{k-1}+\alpha)^2\eta_t^2/\gamma^2[1+\eta_{t-1}(\zeta-\mu/2)]^2\mathbb E\Vert\hat{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert^2
%     %     \nonumber \\&
%     %     +\eta_{t}^2\left[16\beta^2\epsilon^2^{(t_{k-1})}+16\sigma^2+32\delta^2+\tau_k^2\Big(16\beta^2\epsilon^2^{(t_{k-1})}+8\sigma^2\Big)\right]
%     %     \nonumber \\&
%     %     \overset{(a)}\leq
%     %     32(t_{k-1}+\alpha)^2\eta_t^2/(\mu\gamma^2)[1+\eta_{t-1}(\zeta-\mu/2)]^2\mathbb E[F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]
%     %     \nonumber \\&
%     %     +\eta_{t}^2\left[16\beta^2\epsilon^2^{(t_{k-1})}+16\sigma^2+32\delta^2+\tau_k^2\Big(16\beta^2\epsilon^2^{(t_{k-1})}+8\sigma^2\Big)\right],
%     % \end{align} 
%     where $(a)$ results from $\mu$-strongly convexity of $F(\cdot)$.
    
%     Finally, Since 
%     \begin{align}
%         \Vert\mathbf w_i^{(t)}-\bar{\mathbf w}^{(t)}\Vert_2^2
%         =
%         \Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert_2^2
%         +\Vert \mathbf e_i^{{(t)}}\Vert^2
%         +2[\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}]^\top \mathbf e_i^{{(t)}}
%     \end{align} 
%     we have
%     \begin{align}
%         &\mathbb E\left[\sum\limits_{c=1}^N\varrho_{c}\frac{1}{s_c^{(k)}}\sum\limits_{i\in\mathcal{S}_c^{(k)}}\Big\Vert\bar{\mathbf w}^{(t)}-\mathbf w_i^{(t)}\Big\Vert^2\right]
%         \nonumber \\&
%         \leq 
%         16\eta_{t-1}^2(t_{k-1}+\alpha)^2[1+\eta_{t}(2\beta\omega-\mu/2)]^2/(\mu\gamma^2)\mathbb E[F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]
%         \nonumber \\&
%         +24\eta_{t-1}^2[1+\eta_{t}(2\beta\omega-\mu/2)]^2 \left[\tau_k^2(\beta^2(\epsilon^{(t_{k-1})})^2+2\sigma^2)\right]
%         % \nonumber \\&
%         +16\eta_{t}^2(2\beta^2(\epsilon^{(t)})^2+2\sigma^2+\delta^2)+(\epsilon^{(t)})^2
%         \nonumber \\&
%         \overset{(a)}{\leq} 
%         16\eta_{t-1}(t_{k-1}+\alpha)[1+\eta_{t}(2\beta\omega-\mu/2)]^2/(\mu\gamma^2)\mathbb E[F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]
%         \nonumber \\&
%         +24\eta_{t-1}^2[1+\eta_{t}(2\beta\omega-\mu/2)]^2 \left[\tau_k^2(\beta^2(\epsilon^{(t_{k-1})})^2+2\sigma^2)\right]
%         % \nonumber \\&
%         +16\eta_{t}^2(2\beta^2(\epsilon^{(t_{k-1})})^2+2\sigma^2+\delta^2)+(\epsilon^{(t)})^2,
%     \end{align}
%     where $\epsilon{(t_{i-1})},~\forall i$ can be bounded by $\eta_0\phi$. Note that $(a)$ results from the fact that $(t_{k-1}+\alpha)\eta_{t-1}\leq 1$.  This concludes the proof.
%     \fi
    % If we have a step size $\eta_k$ that only changes with respect to $k$, then we can rewrite \eqref{goal}, \eqref{141} and \eqref{142} as
    % \begin{align} 
    %     &\sqrt{\mathbb E[\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2]}
    %     \leq
    %     [1+\eta_k(\zeta-\mu/2)]\sqrt{\mathbb E[\Vert\bar{\mathbf w}_c^{(t-1)}-\mathbf w^*\Vert^2]}
    %     \nonumber \\&
    %     +[1+\eta_k(\zeta-\mu/2)]\sqrt{\mathbb E[(\sum\limits_{c=1}^N\varrho_{c}\Vert\bar{\mathbf w}_c^{(t-1)}-\mathbf w^*\Vert)^2]}
    %     \nonumber \\&
    %     +\eta_k(\beta\epsilon(k)+\beta\epsilon_c(k)+\sqrt{2}\sigma)+2\eta_k\delta.
    % \end{align},
    % \begin{align} 
    %     &\sqrt{\mathbb E[\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert^2]} 
    %     \leq
    %     (1-\frac{\eta_k\mu}{2})\sqrt{\mathbb E[\Vert\bar{\mathbf w}_c^{(t-1)}-\mathbf w^*\Vert^2]}
    %     % \nonumber \\&
    %     +\eta_k(\beta\epsilon_c(k)+\sigma).
    % \end{align}
    % and 
    % \begin{align} 
    %     &\sqrt{(\sum\limits_{c=1}^N\varrho_{c}\mathbb E[\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert)^2]} 
    %     \leq
    %     (1-\frac{\eta_k\mu}{2})\sqrt{\mathbb E[(\sum\limits_{c=1}^N\varrho_{c}\Vert\bar{\mathbf w}_c^{(t-1)}-\mathbf w^*\Vert)^2]}
    %     % \nonumber \\&
    %     +\eta_k(\beta\epsilon(k)+\sigma).
    % \end{align}
    % Combining \eqref{goal}, \eqref{141} and \eqref{142}, we obtain
    % \begin{align}
    %     &\sqrt{\mathbb E[\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2]}
    %     \leq
    % \end{align}
% \end{proof}

% \begin{proposition} \label{Local_disperse}
%     Under Assumption \ref{beta}, if $\eta_0=\frac{\gamma}{t+\alpha}$, $\epsilon^{(t)}$ is non-increasing with respect to $t\in \mathcal T_k$, i.e., $\epsilon^{(t+1)}/\epsilon^{(t)} \leq 1$,
%     $\frac{1}{2\beta}\leq\gamma\leq\vartheta/\beta\alpha$ and $C=\frac{\beta\tau(\tau+\alpha)}{\alpha}$, where $\tau\triangleq \max\{\tau_1,\cdots,\tau_{k}\}$, the following upper bound on the local model dispersion of the devices holds:
%         \begin{align}
%             &A^{(t)}\leq
%             16\omega^2/\mu[\Sigma_{+,t}]^2[F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]+[\Sigma_{+,t}]^2[150/4\sigma^2/\beta^2+150/4(\epsilon^{(0)})^2+6\delta^2/\beta^2]+(\epsilon^{(t)})^2,
%         \end{align}
%         where 
%         \begin{align}
%             &[\Sigma_{+,t}]=\sum\limits_{\ell=t_{k-1}}^{t-1}\left[\prod_{j=t_{k-1}}^{\ell-1}(1+\eta_j\beta\lambda_+)\right]\beta\eta_\ell\left[\prod_{j=\ell+1}^{t-1}(1+\eta_j\beta)\right]
%             \nonumber \\&
%             \leq 
%             \gamma\beta\frac{t-t_{k-1}}{t_{k-1}-1+\alpha+\gamma\beta\lambda_+}\left(1+\frac{t-t_{k-1}}{t_{k-1}-1+\alpha}\right)^{\gamma\beta\lambda_+}
%             \nonumber \\&
%             \leq 
%             \gamma\beta\frac{t-t_{k-1}}{t_{k-1}+\alpha}\left(1+\frac{t-t_{k-1}}{\alpha-1}\right)^{\gamma\beta\lambda_+}
%             \nonumber \\&
%             \leq
%             \eta_t C\left(1+\frac{\tau}{\alpha-1}\right)^{3\gamma\beta}. 
%         \end{align}
% \end{proposition}
% or 
\begin{proposition} \label{Local_disperse}
    Under Assumptions \ref{beta} and~\ref{assump:SGD_noise}, if $\eta_t=\frac{\gamma}{t+\alpha}$, $\epsilon^{(t)}$ is non-increasing with respect to $t\in \mathcal T_k$, i.e., $\epsilon^{(t+1)}/\epsilon^{(t)} \leq 1$ and $\alpha\geq\max\{\beta\gamma[\frac{\mu}{4\beta}-1+\sqrt{(1+\frac{\mu}{4\beta})^2+2\omega}],\frac{\beta^2\gamma}{\mu}\}$, using {\tt TT-HF} for ML model training, the following upper bound on the expected model dispersion across the clusters holds:
        \begin{align}
            &A^{(t)}\leq
             \frac{16\omega^2}{\mu}[\Sigma_{+,t}]^2 [F(\bar{\mathbf w}(t_{k-1}))-F(\mathbf w^*)]
            +25[\Sigma_{+,t}]^2
            \left[\frac{\sigma^2}{\beta^2}+\frac{\delta^2}{\beta^2}+(\epsilon^{(0)})^2\right], ~~t\in\mathcal{T}_k,
        \end{align}
        where 
        \begin{align}
            &[\Sigma_{+,t}]^2=\left[\sum\limits_{\ell=t_{k-1}}^{t-1}\left(\prod_{j=t_{k-1}}^{\ell-1}(1+\eta_j\beta\lambda_+)\right)\beta\eta_\ell\left(\prod_{j=\ell+1}^{t-1}(1+\eta_j\beta)\right)\right]^2,
        \end{align}
    and
    % \nm{please dont use the symbol $\vartheta$. Replace it with $\mu/\beta$ or normalize $\mu$, so that $\mu\beta$ is the strong convexity param}
    \begin{equation}
        \lambda_+=1-\frac{\mu}{4\beta}+\sqrt{(1+\frac{\mu}{4\beta})^2+2\omega}.
    \end{equation}
\end{proposition}
% \addFL{
% \textbf{Condition for} $\Sigma_{-,t}\geq0$: from the following expression  
% % \begin{align}
% %     \Sigma_{\{+,-,0\},t}=\sum\limits_{\ell=t_{k-1}}^{t-1}\left(\prod_{j=t_{k-1}}^{\ell-1}(1+\eta_j\beta\lambda_{\{+,-,0\}})\right)\beta\eta_\ell\left(\prod_{j=\ell+1}^{t-1}(1+\eta_j\beta)\right),
% % \end{align}
% \begin{align}
%     \Sigma_{-,t}=\sum\limits_{\ell=t_{k-1}}^{t-1}\left(\prod_{j=t_{k-1}}^{\ell-1}(1+\eta_j\beta\lambda_{-})\right)\beta\eta_\ell\left(\prod_{j=\ell+1}^{t-1}(1+\eta_j\beta)\right),
% \end{align}
% where $\lambda_{\pm}=1-\frac{\vartheta}{4}\pm\sqrt{(1+\frac{\vartheta}{4})^2+2\omega}$ and $\lambda_{-}=-\frac{\vartheta+2\omega}{\lambda_+}<0$.
% We can observe that the condition for $\Sigma_{-,t}\geq0$ is $$1+\eta_t\beta\lambda_{-}\geq0,~\forall t \in \mathcal T_k,$$ 
% which can be satisfied when
% $$
% 1+\frac{\gamma\beta\lambda_-}{\alpha}\geq0,
% $$
% or equivalently 
% $$
% \gamma\leq-\frac{\alpha}{\beta\lambda_-}.
% $$
% Since $2\leq\lambda_+\leq3$ and $0\leq\omega\leq1$, we have
% $$
% -\frac{\vartheta+2}{2}\leq-\frac{\vartheta+2\omega}{2}\leq\lambda_-\leq-\frac{\vartheta+2\omega}{3}\leq-\frac{\vartheta}{3}.
% $$
% Then the condition on gamma to satisfy all possible values of $\lambda_-$ to make $\Sigma_{-,t}\geq0$ is
% $$
% \gamma\leq\frac{2\alpha}{\beta(\vartheta+2)}.
% $$
% }
\begin{proof}
% \addFL{

We break down the proof into 3 parts: in Part I we find the relationship between $\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert$ and $\sum\limits_{c=1}^N\varrho_{c}\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert$, which turns out to form a coupled dynamic system, which is solved in Part II. Finally, Part III draws the connection between $A^{(t)}$ and the solution of the coupled dynamic system and obtains the upper bound on $A^{(t)}$.

\textbf{(Part I) Finding the relationship between $\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert$ and $\sum\limits_{c=1}^N\varrho_{c}\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert$}:
Using the definition of $\bar{\mathbf w}^{(t+1)}$ given in Definition~\ref{modDisp}, and the notations introduced in Appendix~\ref{app:notations}, we have:  
\begin{equation}
    \bar{\mathbf w}^{(t+1)}= \bar{\mathbf w}^{(t)}-\frac{\tilde{\eta_t}}{\beta}\sum\limits_{c=1}^N\varrho_{c}\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}} \widehat{\mathbf g}_{j,t},~t\in\mathcal{T}_k.
\end{equation}
Adding and subtracting terms in the above equality gives us:
\begin{align} 
        \bar{\mathbf w}^{(t+1)}-\mathbf w^* =&~ \bar{\mathbf w}^{(t)}-\mathbf w^*-\frac{\tilde{\eta_t}}{\beta} \nabla F(\bar{\mathbf w}^{(t)})
        \nonumber \\&
        -\frac{\tilde{\eta_t}}{\beta}\sum\limits_{c=1}^N\varrho_{c}\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}} [\widehat{\mathbf g}_{j,t}-\nabla F_j(\mathbf w_j^{(t)})]
        \nonumber \\&
        -\frac{\tilde{\eta_t}}{\beta} \sum\limits_{c=1}^N\varrho_{c}\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}} [\nabla F_j(\mathbf w_j^{(t)})-\nabla F_j(\bar{\mathbf w}_c^{(t)})]
        \nonumber \\&
        -\frac{\tilde{\eta_t}}{\beta} \sum\limits_{c=1}^N\varrho_{c} [\nabla F_c(\bar{\mathbf w}_c^{(t)})-\nabla F_c(\bar{\mathbf w}^{(t)})].
    \end{align}
    Taking the norm-2 from the both hand sides of the above equality and applying the triangle inequality yields:
    \begin{align} \label{29}
        \Vert\bar{\mathbf w}^{(t+1)}-\mathbf w^*\Vert \leq& \Vert\bar{\mathbf w}^{(t)}-\mathbf w^*-\frac{\tilde{\eta_t}}{\beta} \nabla F(\bar{\mathbf w}^{(t)})\Vert
        +\frac{\tilde{\eta_t}}{\beta} \sum\limits_{c=1}^N\varrho_{c}\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}} \Vert\mathbf n_{j}^{(t)}\Vert
        \nonumber \\&
        +\frac{\tilde{\eta_t}}{\beta} \sum\limits_{c=1}^N\varrho_{c}\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}} \Vert\nabla F_j(\mathbf w_j^{(t)})-\nabla F_j(\bar{\mathbf w}_c^{(t)})\Vert
        \nonumber \\&
        +\frac{\tilde{\eta_t}}{\beta} \sum\limits_{c=1}^N\varrho_{c} \Vert\nabla F_c(\bar{\mathbf w}_c^{(t)})-\nabla F_c(\bar{\mathbf w}^{(t)})\Vert.
    \end{align}
 To bound the terms on the right hand side above, we first use the $\mu$-strong convexity and $\beta$-smoothness of $F(\cdot)$, when $\eta_t\leq\frac{\mu}{\beta^2}$, to get 
    \begin{align} \label{eq:stx}
        &\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*-\frac{\tilde{\eta_t}}{\beta} \nabla F(\bar{\mathbf w}^{(t)})\Vert
        \nonumber \\&
        =
        \sqrt{\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert^2+(\frac{\tilde{\eta_t}}{\beta})^2\Vert\nabla F(\bar{\mathbf w}^{(t)})\Vert^2-\frac{2\tilde{\eta_t}}{\beta}(\bar{\mathbf w}^{(t)}-\mathbf w^*)^\top\nabla F(\bar{\mathbf w}^{(t)})}
        \nonumber \\&
        \overset{(a)}{\leq} 
        \sqrt{(1-2\tilde{\eta}_t\tilde{\mu})\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert^2+(\frac{\tilde{\eta_t}}{\beta})^2\Vert\nabla F(\bar{\mathbf w}^{(t)})\Vert^2}
        \nonumber \\&
        \overset{(b)}{\leq}
        \sqrt{1-2\tilde{\eta}_t\tilde{\mu}+\tilde{\eta}_t^2}\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert
        \overset{(c)}{\leq} 
        (1-\frac{\tilde{\eta}_t\tilde{\mu}}{2})\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert,
    \end{align}
    where $(a)$ results from the property of a strongly convex function, i.e., $(\bar{\mathbf w}^{(t)}-\mathbf w^*)^\top\nabla F(\bar{\mathbf w}^{(t)})\geq\tilde{\mu}\beta\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert^2$, $(b)$ comes from the property of smooth functions, i.e., $\Vert\nabla F(\bar{\mathbf w}^{(t)})\Vert^2\leq\beta^2\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert^2$ and the last step $(c)$ follows from the fact that $\tilde{\eta}_t\leq \tilde{\eta}_0$ and assuming $ \tilde{\eta}_0\leq\tilde{\mu}$, implying $\alpha\geq  \tilde{\gamma}/\tilde{\mu}$.
    Also, considering the other terms on the right hand side of~\eqref{29}, using $\beta$-smoothness, we have 
    \begin{align} \label{eq:beta_use}
        \Vert\nabla F_j(\mathbf w_j^{(t)})-\nabla F_j(\bar{\mathbf w}_c^{(t)})\Vert
        \leq
        \beta\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\Vert\mathbf w_j^{(t)}-\bar{\mathbf w}_c^{(t)}\Vert.
    \end{align}
    Moreover, using Definition \ref{paraDiv}, we get
    \begin{align} \label{eq:e_c}
        \frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\Vert\mathbf w_j^{(t)}-\bar{\mathbf w}_c^{(t)}\Vert
        &=
        \frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\Vert\mathbf e_j^{(t)}\Vert
        \nonumber \\&\leq
        \sqrt{\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\Vert\mathbf e_j^{(t)}\Vert^2}
        \leq\tilde{\epsilon}_c^{(t)}/\sqrt{\beta}.
    \end{align}
Combining \eqref{eq:beta_use} and \eqref{eq:e_c} gives us:
    \begin{align} \label{eq:epsilon_use}
        \frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\Vert\nabla F_j(\mathbf w_j^{(t)})-\nabla F_j(\bar{\mathbf w}_c^{(t)})\Vert
        \leq
        \sqrt{\beta}\tilde{\epsilon}_c^{(t)}.
    \end{align}
    Replacing the result of~\eqref{eq:stx} and~\eqref{eq:epsilon_use} in~\eqref{29} yields:
    \begin{align}
        \Vert\bar{\mathbf w}^{(t+1)}-\mathbf w^*\Vert \leq& 
         (1-\frac{\tilde{\eta}_t\tilde{\mu}}{2})
\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert
        +\frac{\tilde{\eta}_t}{\beta} \sum\limits_{c=1}^N\varrho_{c}\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}} \Vert\mathbf n_{j}^{(t)}\Vert
        \nonumber \\&
        +\frac{\tilde{\eta}_t}{\sqrt{\beta}}\sum\limits_{c=1}^N\varrho_{c}\tilde{\epsilon}_{c}^{(t)}
        +\tilde{\eta}_t \sum\limits_{c=1}^N\varrho_{c} \Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert.
    \end{align}
Multiplying the both hand sides of the above inequality by $\sqrt{\beta}$ followed by taking square and expectation, we get
\begin{align}
        \mathbb E\left[\sqrt{\beta}\Vert\bar{\mathbf w}^{(t+1)}-\mathbf w^*\Vert\right]^2 \leq& 
         \mathbb E\bigg[\sqrt{\beta}(1-\frac{\tilde{\eta}_t\tilde{\mu}}{2})
\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert
        +\frac{\tilde{\eta}_t}{\sqrt{\beta}} \sum\limits_{c=1}^N\varrho_{c}\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}} \Vert\mathbf n_{j}^{(t)}\Vert
        \nonumber \\&
        +{\tilde{\eta}_t}\sum\limits_{c=1}^N\varrho_{c}\tilde{\epsilon}_{c}^{(t)}
        +\tilde{\eta}_t \sqrt{\beta} \sum\limits_{c=1}^N\varrho_{c}  \Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert\bigg]^2.
    \end{align}
Taking the square roots from the both hand sides and using Fact \ref{fact:1} (See Appendix \ref{app:fact1}) yields:
\begin{align} \label{eq:fact_x2}
       \sqrt{\beta\mathbb E[\Vert\bar{\mathbf w}^{(t+1)}-\mathbf w^*\Vert^2]} 
       \leq& 
         (1-\frac{\tilde{\eta}_t\tilde{\mu}}{2})
\sqrt{\beta\mathbb E[\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert^2]}
        +{\tilde{\eta}_t} \tilde{\sigma}
        \nonumber \\&
        +{\tilde{\eta}_t}\sum\limits_{c=1}^N\varrho_{c}\tilde{\epsilon}_{c}^{(t)}
        +\tilde{\eta}_t \sqrt{\beta \Big(\sum\limits_{c=1}^N\varrho_{c} \mathbb E\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert\Big)^2}.
    \end{align}
    We compact~\eqref{eq:fact_x2} and represent it via the following relationship:
\begin{align} \label{eq:x2_x1}
        &x_2^{(t+1)} \leq \begin{bmatrix} \tilde{\eta}_t & 1-\frac{\tilde{\eta}_t\tilde{\mu}}{2}\end{bmatrix}\mathbf x^{(t)}+\tilde{\eta}_t\left(\tilde{\sigma}+\sum\limits_{c=1}^N\varrho_{c}\tilde{\epsilon}_{c}^{(t)}\right),
    \end{align}
     where $\mathbf x^{(t)}=\begin{bmatrix} x_1^{(t)} & x_2^{(t)}\end{bmatrix}^\top$, 
         $x_1^{(t)}=\sqrt{\beta\mathbb E[(\sum\limits_{c=1}^N\varrho_{c}\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert)^2]}$, and $x_2^{(t)}=\sqrt{\beta\mathbb E[\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert^2]}$.


The relationship in~\eqref{eq:x2_x1} reveals the dependency of $x_2^{(t+1)}$ on $x_2^{(t)}$ and $x_1^{(t)}$. 
    To bound $x^{(t)}_1$, we first use the fact that $\bar{\mathbf w}_c^{(t+1)}$ can be written as follows:
    \begin{align} \label{eq:w_c}
        &\bar{\mathbf w}_c^{(t+1)}=\bar{\mathbf w}_c^{(t)}
        -\frac{\tilde{\eta}_t}{\beta}\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\nabla F_j(\mathbf w_j^{(t)})
        -\frac{\tilde{\eta}_t}{\beta}\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\mathbf n_j^{(t)}.
    \end{align}
    Similarly, $\bar{\mathbf w}^{(t+1)}$ can be written as:
    \begin{align} \label{eq:w-}
        &\bar{\mathbf w}^{(t+1)}=
        \bar{\mathbf w}^{(t)}
        -\frac{\tilde{\eta}_t}{\beta}\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\nabla F_j(\mathbf w_j^{(t)})
        -\frac{\tilde{\eta}_t}{\beta}\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\mathbf n_j^{(t)}.
    \end{align}
    Combining~\eqref{eq:w_c} and~\eqref{eq:w-} and performing some algebraic manipulations yields:
    \begin{align} 
        &\bar{\mathbf w}_c^{(t+1)}-\bar{\mathbf w}^{(t+1)}=\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}
        -\frac{\tilde{\eta}_t}{\beta}\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\mathbf n_{j}^{(t)}
        +\frac{\tilde{\eta}_t}{\beta}\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\mathbf n_{j}^{(t)}
        \nonumber \\&
        -\frac{\tilde{\eta}_t}{\beta}\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\Big[\nabla F_j(\bar{\mathbf w}_j ^{(t)})-\nabla F_j(\bar{\mathbf w}_c ^{(t)})\Big]
        +\frac{\tilde{\eta}_t}{\beta}\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\Big[\nabla F_j(\bar{\mathbf w}_j ^{(t)})-\nabla F_j(\bar{\mathbf w}_d^{(t)})\Big]
        \nonumber \\&
        -\frac{\tilde{\eta}_t}{\beta}\Big[\nabla\hat F_c(\bar{\mathbf w}_c^{(t)})-\nabla\hat F_c(\bar{\mathbf w}^{(t)})\Big]
        +\frac{\tilde{\eta}_t}{\beta}\sum\limits_{d=1}^N\varrho_{d}\Big[\nabla\hat F_d(\bar{\mathbf w}_d^{(t)})-\nabla\hat F_d(\bar{\mathbf w}^{(t)})\Big]
       \nonumber \\&
        -\frac{\tilde{\eta}_t}{\beta}\Big[\nabla\hat F_c(\bar{\mathbf w}^{(t)})-\nabla F(\bar{\mathbf w}^{(t)})\Big].
    \end{align}   
    Taking the norm-2 of the both hand sides of the above equality and applying the triangle inequality gives us
    \begin{align} \label{eq:tri_wc}
        &\Vert\bar{\mathbf w}_c^{(t+1)}-\bar{\mathbf w}^{(t+1)}\Vert\leq
        \Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert
        +\frac{\tilde{\eta}_t}{\beta}\Vert\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\mathbf n_{j}^{(t)}\Vert
        +\frac{\tilde{\eta}_t}{\beta}\Vert\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\mathbf n_{j}^{(t)}\Vert
        \nonumber \\&
        +\frac{\tilde{\eta}_t}{\beta}\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\Vert\nabla F_j(\bar{\mathbf w}_j ^{(t)})-\nabla F_j(\bar{\mathbf w}_c ^{(t)})\Vert
        +\frac{\tilde{\eta}_t}{\beta}\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\Vert\nabla F_j(\bar{\mathbf w}_j ^{(t)})-\nabla F_j(\bar{\mathbf w}_d^{(t)})\Vert
        \nonumber \\&
        +\frac{\tilde{\eta}_t}{\beta}\Vert\nabla\hat F_c(\bar{\mathbf w}_c^{(t)})-\nabla\hat F_c(\bar{\mathbf w}^{(t)})\Vert
        +\frac{\tilde{\eta}_t}{\beta}\sum\limits_{d=1}^N\varrho_{d}\Vert\nabla\hat F_d(\bar{\mathbf w}_d^{(t)})-\nabla\hat F_d(\bar{\mathbf w}^{(t)})\Vert
        \nonumber \\&
        +\frac{\tilde{\eta}_t}{\beta}\Vert\nabla\hat F_c(\bar{\mathbf w}^{(t)})-\nabla F(\bar{\mathbf w}^{(t)})\Vert.
    \end{align}   
    Using $\beta$-smoothness of $F_j(\cdot)$, $\forall j$, and $\hat F_c(\cdot)$, $\forall c$, Definition \ref{gradDiv} and Definition \ref{paraDiv}, we further bound the right hand side of~\eqref{eq:tri_wc} to get
\begin{align} \label{eq:tri_wc2}
        &\Vert\bar{\mathbf w}_c^{(t+1)}-\bar{\mathbf w}^{(t+1)}\Vert\leq
        (1+\tilde{\eta}_t)\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert
        +2\omega\tilde{\eta}_t\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert
                +\tilde{\eta}_t\sum\limits_{d=1}^N\varrho_{d}\Vert\bar{\mathbf w}_d^{(t)}-\bar{\mathbf w}^{(t)}\Vert
        \nonumber \\&
        +\frac{\tilde{\eta}_t}{\beta}\Vert\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\mathbf n_{j}^{(t)}\Vert
        +\frac{\tilde{\eta}_t}{\beta}\Vert\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\mathbf n_{j}^{(t)}\Vert
        \nonumber \\&
        +\tilde{\eta}_t\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}
        \Vert\bar{\mathbf w}_j ^{(t)}-\bar{\mathbf w}_c ^{(t)}\Vert
        +\tilde{\eta}_t\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}
        \Vert\bar{\mathbf w}_j ^{(t)}-\bar{\mathbf w}_d^{(t)}\Vert
        +\frac{\tilde{\eta}_t}{\sqrt{\beta}}\tilde{\delta}.
    \end{align}   
    Using~\eqref{eq:e_c} we have $\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}
        \Vert\bar{\mathbf w}_j ^{(t)}-\bar{\mathbf w}_d^{(t)}\Vert\leq\frac{\tilde{\epsilon}_{d}^{(t)}}{\sqrt{\beta}}$, and thus~\eqref{eq:tri_wc2} can be written as
        \begin{align} \label{eq:wc_w}
        &\Vert\bar{\mathbf w}_c^{(t+1)}-\bar{\mathbf w}^{(t+1)}\Vert\leq
        (1+\tilde{\eta}_t)\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert
        +2\omega\tilde{\eta}_t\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert
                +\tilde{\eta}_t\sum\limits_{d=1}^N\varrho_{d}\Vert\bar{\mathbf w}_d^{(t)}-\bar{\mathbf w}^{(t)}\Vert
        \nonumber \\&
        +\frac{\tilde{\eta}_t}{\beta}\Vert\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\mathbf n_{j}^{(t)}\Vert
        +\frac{\tilde{\eta}_t}{\beta}\Vert\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\mathbf n_{j}^{(t)}\Vert
        +\frac{\tilde{\eta}_t}{\sqrt{\beta}}\left(\tilde{\epsilon}_{c}^{(t)}+\sum\limits_{d=1}^N\varrho_{d}\tilde{\epsilon}_{d}^{(t)}+\tilde{\delta}\right).
    \end{align} 
  Taking the weighted sum $\sum\limits_{c=1}^N\varrho_c$ from the both hand sides of the above inequality gives us
    \begin{align} 
        &\sum\limits_{c=1}^N\varrho_c\Vert\bar{\mathbf w}_c^{(t+1)}-\bar{\mathbf w}^{(t+1)}\Vert\leq
        (1+2\tilde{\eta}_t)\sum\limits_{c=1}^N\varrho_c\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert
        +2\omega\tilde{\eta}_t\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert
        \nonumber \\&
        +\frac{\tilde{\eta}_t}{\beta}\sum\limits_{c=1}^N\varrho_c\Vert\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\mathbf n_{j}^{(t)}\Vert
        +\frac{\tilde{\eta}_t}{\beta}\Vert\sum\limits_{d=1}^N\varrho_{d}\frac{1}{s_{d}}\sum\limits_{j\in\mathcal S_{d}}\mathbf n_{j}^{(t)}\Vert
        +\frac{\tilde{\eta}_t}{\sqrt{\beta}}\left(2\sum\limits_{d=1}^N\varrho_{d}\tilde{\epsilon}_{d}^{(t)}+\tilde{\delta}\right).
    \end{align}  
    
    Multiplying the both hand side of the above inequality by $\sqrt{\beta}$, followed by taking square and expectation, using a similar procedure used to obtain~\eqref{eq:fact_x2}, we get the bound on $x_1^{(t+1)}$ as follows:
     \begin{align} \label{eq:fact_x1}
        &
x_1^{(t+1)}\leq
\begin{bmatrix} 1+2\tilde{\eta}_t & 2\omega\tilde{\eta}_t\end{bmatrix}\mathbf x^{(t)}
        +\tilde{\eta}_t\left(2\sum\limits_{d=1}^N\varrho_{d}\tilde{\epsilon}_{d}^{(t)}+\tilde{\delta}+2\tilde{\sigma}\right).
    \end{align}  


\textbf{(Part II) Solving the coupled dynamic system:}
To bound $\mathbf x^{(t)}$, we need to bound $x_1^{(t)}$ and $x_2^{(t)}$, where $x_2^{(t)}$ is given by~\eqref{eq:x2_x1}, which is dependent on $\mathbf x^{(t-1)}$. Also, $x_1^{(t)}$ is given in~\eqref{eq:fact_x1} which is dependent on  $\mathbf x^{(t-1)}$. This leads to a \textit{coupled dynamic system} where $\mathbf x^{(t)}$ can be expressed in a compact form as follows:
    \begin{align} \label{69}
        \mathbf x^{(t+1)}
        &\leq 
        [\mathbf I+\tilde{\eta}_t\mathbf B]\mathbf  x^{(t)}
        +\tilde{\eta}_t\mathbf z, 
    \end{align}
    where $\mathbf  x^{(t_{k-1})}=\mathbf e_2\sqrt{\beta}\Vert\bar{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert$,
    $
\mathbf z= \begin{bmatrix} 2 & 1\end{bmatrix}^\top[\tilde{\sigma}+\sum\limits_{d=1}^N\varrho_{d}\tilde{\epsilon}_{d}^{(0)}]
        +\mathbf e_1\tilde{\delta}
    $
    ,    
    $\mathbf B=\begin{bmatrix} 2 & 2\omega
    \\ 1 & -\tilde{\mu}/2\end{bmatrix}$, $\mathbf e_1=\begin{bmatrix}1\\0\end{bmatrix}$ and $\mathbf e_2=\begin{bmatrix}0\\1\end{bmatrix}$.
    We aim to characterize an upper bound on $\mathbf x^{(t)}$ denoted by $\bar{\mathbf x}^{(t)}$, where 
     \begin{align} \label{69}
 \bar{\mathbf x}^{(t+1)}
= 
        [\mathbf I+\tilde{\eta}_t\mathbf B]\bar{\mathbf x}^{(t)}
        +\tilde{\eta}_t\mathbf z.
    \end{align}
 To solve the coupled dynamic, we use the eigen-decomposition on $\mathbf B$:
    $\mathbf B=\mathbf U\mathbf D\mathbf U^{-1}$, where
    $$\mathbf D=\begin{bmatrix} \lambda_+ & 0
    \\ 0 & \lambda_-\end{bmatrix},\ 
    \mathbf U=\begin{bmatrix} \omega & \omega
    \\ \frac{\lambda_+}{2}-1 & \frac{\lambda_-}{2}-1\end{bmatrix},\ 
\mathbf U^{-1}=\frac{1}{
    \omega\sqrt{(1+\tilde{\mu}/4)^2+2\omega}
    }\begin{bmatrix} 1-\frac{\lambda_-}{2} & \omega
    \\ \frac{\lambda_+}{2}-1 &-\omega\end{bmatrix}$$
        and the eigenvalues in $\mathbf D$ are given by
        \begin{align} \label{eq:lambda+}
            \lambda_+ =1-\tilde{\mu}/4+\sqrt{(1+\tilde{\mu}/4)^2+2\omega}>0
        \end{align}
    and 
    \begin{align} \label{eq:lambda-}
        \lambda_-=
        1-\tilde{\mu}/4-\sqrt{(1+\tilde{\mu}/4)^2+2\omega}
        =
        -\frac{\tilde{\mu}+2\omega}{\lambda_+}<0
    \end{align}
    
    To further compact the relationship in~\eqref{69}, we introduce a variable $\mathbf f^{(t)}$, where $\mathbf f^{(t)}=\mathbf U^{-1}\bar{\mathbf x}^{(t)}+\mathbf U^{-1}\mathbf B^{-1}\mathbf z$, satisfying the following recursive expression:
    % Then, letting $\mathbf f_t=\mathbf U^{-1}\bar{\mathbf x}^{(t)}+\mathbf U^{-1}\mathbf B^{-1}\mathbf z$
    % we obtain
    \begin{align} 
        \mathbf f^{(t+1)}
        &= 
         [\mathbf I+\tilde{\eta}_t\mathbf D]\mathbf f^{(t)}.
    \end{align}
  Recursive expansion of the right hand side of the above equality yields: 
    \begin{align} 
        \mathbf f^{(t)}
        &= 
         \prod_{\ell=t_{k-1}}^{t-1}[\mathbf I+\tilde{\eta}_\ell\mathbf D]\mathbf f^{(t_{k-1})}.
    \end{align}
    Using the fact that
    $\bar{\mathbf x}^{(t)}=\mathbf U\mathbf f^{(t)}-\mathbf B^{-1}\mathbf z$,
    we obtain the following expression for $\bar{\mathbf x}^{(t)}$:
    \begin{align} 
    \bar{\mathbf x}^{(t)}=
\mathbf U\prod_{\ell=t_{k-1}}^{t-1}(\mathbf I+\tilde{\eta}_\ell\mathbf D)
         \mathbf U^{-1}\mathbf e_2\Vert\bar{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert
+\mathbf U\left[\prod_{\ell=t_{k-1}}^{t-1}(\mathbf I+\tilde{\eta}_\ell\mathbf D)-\mathbf I\right]
         \mathbf U^{-1}\mathbf B^{-1}\mathbf z.
    \end{align}
    \textbf{(Part III) Finding the connection between $A^{(t)}$ and ${\mathbf x}^{(t)}$ and the expression for $A^{(t)}$}:
To bound the model dispersion across the clusters, we revisit~\eqref{eq:wc_w}, where we multiply its both hand side by $\sqrt{\beta}$, followed by taking square and expectation and follow a similar procedure used to obtain~\eqref{eq:fact_x2} to get:
%  Bounding the left hand side of~\eqref{eq:expanded} requires bounding $y^{(t)}$ appearing on the right hand side. To bound $y^{(t)}$ 
% Considering the definition of $A^(t)$ that we aimed to bound, we first use ..and 
% Multiplying the both hand side of the above inequality by $\sqrt{\beta}$, followed by taking square and expectation, using a similar procedure used to obtain~\eqref{eq:fact_x2}, we get:
    \begin{align} \label{eq:recurse}
        \sqrt{\beta\mathbb E[\Vert\bar{\mathbf w}_c^{(t+1)}-\bar{\mathbf w}^{(t+1)}\Vert^2]}
        \leq&
        (1+\tilde{\eta}_t)\sqrt{\beta\mathbb E[\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2]}
        +\tilde{\eta}_t y^{(t)}
        % \nonumber \\&
        +\tilde{\eta}_t[\tilde{\epsilon}_{c}^{(t)}+\sum\limits_{d=1}^N\varrho_{d}\tilde{\epsilon}_{d}^{(t)}+\tilde{\delta}+2\tilde{\sigma}],
    \end{align}  
    where $y^{(t)}=\begin{bmatrix} 1 & 2\omega\end{bmatrix}\mathbf x^{(t)}$. Recursive expansion of~\eqref{eq:recurse} yields: 
    \begin{align} \label{eq:expanded}
        &
\sqrt{\beta\mathbb E[\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2]}
        \leq
        \sum_{\ell=t_{k-1}}^{t-1}\tilde{\eta}_\ell\prod_{j=\ell+1}^{t-1}(1+\tilde{\eta}_j)
        y^{(\ell)}
        % \nonumber \\&
        +\sum_{\ell=t_{k-1}}^{t-1}\tilde{\eta}_\ell\prod_{j=\ell+1}^{t-1}(1+\tilde{\eta}_j)
        [\tilde{\epsilon}_{c}^{(0)}+\sum\limits_{d=1}^N\varrho_{d}\tilde{\epsilon}_{d}^{(0)}+\tilde{\delta}+2\tilde{\sigma}].
    \end{align}    
The expression in~\eqref{eq:expanded} reveals the dependency of the difference between the model in one cluster $c$ and the global average of models, i.e., the left hand side, on $y^{(t)}$ which by itself depends on $\mathbf x^{(t)}$. Considering the fact that $A^{(t)}\triangleq\mathbb E\left[\sum\limits_{c=1}^N\varrho_{c}\big\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\big\Vert^2\right]$, the aforementioned dependency implies the dependency of $A^{(t)}$ on $\mathbf x^{(t)}$. 


So, the key to obtain $A^{(t)}$ is to bound $y^{(t)}$, which can be expressed as follows:
% \triangleq \bar y^{(t)}
\begin{align} \label{eq:yt}
    y^{(t)}&=\begin{bmatrix} 1 & 2\omega\end{bmatrix}\mathbf x^{(t)}\leq \begin{bmatrix} 1 & 2\omega\end{bmatrix}\bar{\mathbf x}^{(t)}
   \nonumber\\&=
  [g_1\Pi_{+,t}+g_2\Pi_{-,t}]\sqrt{\beta}\Vert\bar{\mathbf w}(t_{k-1})-\mathbf w^*\Vert
  \nonumber \\&
+[g_3(\Pi_{+,t}-\Pi_{0,t})+g_4(\Pi_{-,t}-\Pi_{0,t})]
[\tilde{\sigma}+\sum\limits_{d=1}^N\varrho_{d}\tilde{\epsilon}_{d}^{(0)}] \nonumber\\&
+[g_5(\Pi_{+,t}-\Pi_{0,t})+g_6(\Pi_{-,t}-\Pi_{0,t})]\tilde{\delta},
    \end{align}
    where we define
    $
    \Pi_{\{+,-,0\},t}=\prod_{\ell=t_{k-1}}^{t-1}[1+\tilde{\eta}_\ell\lambda_{\{+,-,0\}}],\ 
    $ with $\lambda_+$ given by~\eqref{eq:lambda+} and $\lambda_-$ given by~\eqref{eq:lambda-} and $\lambda_0=0$. Also, the constants $g_1$, $g_2$, $g_3$, $g_4$, $g_5$, and $g_6$ are given by:
    $$
        g_1\triangleq
        \begin{bmatrix} 1 & 2\omega\end{bmatrix}\mathbf U\mathbf e_1\mathbf e_1^\top\mathbf U^{-1}\mathbf e_2
        =
        \omega
        \left[1-\frac{\tilde{\mu}/4}{\sqrt{(1+\tilde{\mu}/4)^2+2\omega}}\right]>0,
    $$
    $$
g_2\triangleq
    \begin{bmatrix} 1 & 2\omega\end{bmatrix}\mathbf U\mathbf e_2\mathbf e_2^\top\mathbf U^{-1}\mathbf e_2
    =
    \omega\left[1+\frac{\tilde{\mu}/4}{\sqrt{(1+\tilde{\mu}/4)^2+2\omega}}\right]
    =g_2=2\omega-g_1>0,
    $$
    $$
g_3\triangleq
    \begin{bmatrix} 1 & 2\omega\end{bmatrix}\mathbf U\mathbf e_1\mathbf e_1^\top\mathbf U^{-1}\mathbf B^{-1}[2,1]^\top
    =
\frac{1}{2}+\frac{1+\tilde{\mu}/4+2\omega}{2\sqrt{(1+\tilde{\mu}/4)^2+2\omega}}
    =g_3>1,
$$
$$
g_4\triangleq
    \begin{bmatrix} 1 & 2\omega\end{bmatrix}\mathbf U\mathbf e_2\mathbf e_2^\top\mathbf U^{-1}\mathbf B^{-1}[2,1]^\top
=
\frac{1}{2}-\frac{1+\tilde{\mu}/4+2\omega}{2\sqrt{(1+\tilde{\mu}/4)^2+2\omega}},
$$$$
=
-\omega\frac{1+2\omega+\tilde{\mu}/2}{\sqrt{(1+\tilde{\mu}/4)^2+2\omega}}
\frac{1}{\sqrt{(1+\tilde{\mu}/4)^2+2\omega}+[1+\tilde{\mu}/4+2\omega]}
=1- g_3<0,
$$

$$
g_5
\triangleq
    \begin{bmatrix} 1 & 2\omega\end{bmatrix}\mathbf U\mathbf e_1\mathbf e_1^\top\mathbf U^{-1}\mathbf B^{-1}\mathbf e_1
=
\frac{1}{[\tilde{\mu}+2\omega]\sqrt{(1+\tilde{\mu}/4)^2+2\omega}}
$$
$$
\cdot\frac{
\frac{\tilde{\mu}}{2}(1+\tilde{\mu}/4)^2
+\omega[1+\frac{5\tilde{\mu}}{4}+\tilde{\mu}^2/8]
+2\omega^2
+\sqrt{(1+\tilde{\mu}/4)^2+2\omega}[\frac{\tilde{\mu}}{2}(1+\tilde{\mu}/4)+\omega[1+\tilde{\mu}/2]]
}{1+\tilde{\mu}/4+\sqrt{(1+\tilde{\mu}/4)^2+2\omega}}
>0,
$$

$$
g_6\triangleq
\begin{bmatrix} 1 & 2\omega\end{bmatrix}\mathbf U\mathbf e_2\mathbf e_2^\top\mathbf U^{-1}\mathbf B^{-1}\mathbf e_1
$$$$
=
\frac{\omega}{[\tilde{\mu}+2\omega]\sqrt{(1+\tilde{\mu}/4)^2+2\omega}}
\frac{1+\frac{3\tilde{\mu}}{4}+2\omega+\sqrt{(1+\tilde{\mu}/4)^2+2\omega}}{1+\tilde{\mu}/4+\sqrt{(1+\tilde{\mu}/4)^2+2\omega}}
 =
\frac{\tilde{\mu}/2+2\omega}{\tilde{\mu}+2\omega}-g_5>0.
$$
% \nm{these coeff can later be bounded to simplify}

Revisiting~\eqref{eq:recurse} with the result of~\eqref{eq:yt} gives us:
\begin{align} \label{eq:mid_goal}
        &
        \sqrt{\beta\mathbb E[\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2]}
        \leq
2\omega\frac{g_1\Sigma_{+,t}+g_2\Sigma_{-,t}}{g_1+g_2}\sqrt{\beta}\Vert\bar{\mathbf w}(t_{k-1})-\mathbf w^*\Vert
         \nonumber\\&
+[\Sigma_{+,t}+(g_3-1)(\Sigma_{+,t}-\Sigma_{-,t})]
[\tilde{\sigma}+\sum\limits_{d=1}^N\varrho_{d}\tilde{\epsilon}_{d}^{(0)}]
\nonumber\\&
+\frac{\tilde{\mu}/2}{\tilde{\mu}+2\omega}[\frac{g_5}{g_5+g_6}\Sigma_{+,t}+\frac{g_6}{g_5+g_6}\Sigma_{-,t}+\Sigma_{0,t}]\tilde{\delta}
+\Sigma_{0,t}[\tilde{\epsilon}_{c}^{(0)}+\tilde{\sigma}],
    \end{align}
    where we used the facts that $g_3+g_4=1$, $g_5+g_6=\frac{\tilde{\mu}/2+2\omega}{\tilde{\mu}+2\omega}$,
    $g_1+g_2=2\omega$,  and $g_3>1$, and defined  $\Sigma_{+,t}$, $\Sigma_{-,t}$, and $\Sigma_{0,t}$ as follows:
    $$
 \Sigma_{\{+,-,0\},t}
 =\sum_{\ell=t_{k-1}}^{t-1}\tilde{\eta}_\ell\prod_{j=\ell+1}^{t-1}(1+\tilde{\eta}_j)\Pi_{\{+,-,0\},\ell}
  =\sum_{\ell=t_{k-1}}^{t-1}
  \left[\prod_{j=t_{k-1}}^{\ell-1}(1+\tilde{\eta}_j\lambda_{\{+,-,0\}})\right]
  \tilde{\eta}_\ell
  \left[\prod_{j=\ell+1}^{t-1}(1+\tilde{\eta}_j)\right].
    $$
    
    
    We now demonstrate that: (i)
    $\Sigma_{-,t}\leq \Sigma_{+,t}$, (ii)
    $\Sigma_{0,t}\leq \Sigma_{+,t}$, and (iii)
    $\Sigma_{-,t}\geq 0$.

To prove $\Sigma_{-,t}\leq \Sigma_{+,t}$, we upper bound  $\Sigma_{-,t}$ as follows:
\begin{align}
 \Sigma_{-,t}
 &\leq\sum_{\ell=t_{k-1}}^{t-1}
  \left[\prod_{j=t_{k-1}}^{\ell-1}|1+\tilde{\eta}_j \lambda_{-}|\right]
  \tilde{\eta}_\ell
  \left[\prod_{j=\ell+1}^{t-1}(1+\tilde{\eta}_j)\right]
\nonumber\\&
   \leq\sum_{\ell=t_{k-1}}^{t-1}
  \left[\prod_{j=t_{k-1}}^{\ell-1}(1+\tilde{\eta}_j \lambda_{+})\right]
  \tilde{\eta}_\ell
  \left[\prod_{j=\ell+1}^{t-1}(1+\tilde{\eta}_j)\right]=\Sigma_{+,t}.
    \end{align}
    Similarly it can be shown that $\Sigma_{0,t}\leq \Sigma_{+,t}$ since $\lambda_+>1$.
    
    
    To prove $\Sigma_{-,t}\geq 0$, it is sufficient to impose the condition
    $(1+\tilde{\eta}_j \lambda_-)\geq 0,\forall j$, i.e.
    $(1+\tilde{\eta}_0 \lambda_-)\geq 0$, which implies
    $
    \alpha\geq\tilde{\gamma}[\tilde{\mu}/4-1+\sqrt{(1+\tilde{\mu}/4)^2+2\omega}].
    $
    % \nm{otherwise, we can use the a different inequality:
    % $\Sigma_{-,t}\geq 2\Sigma_{0,t}-\Sigma_{+,t}$ (TBP)}
    
   Considering~\eqref{eq:mid_goal} with the above mentioned properties for $\Sigma_{-,t}$, $\Sigma_{+,t}$, and $\Sigma_{0,t}$, we get:
    \begin{align} \label{eq:midgoal2}
        \sqrt{\beta\mathbb E[\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2]}
        \leq&
2\omega\Sigma_{+,t}\sqrt{\beta}\Vert\bar{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert
        % \nonumber  \\&
+g_3\Sigma_{+,t}
[\tilde{\sigma}+\sum\limits_{d=1}^N\varrho_{d}\tilde{\epsilon}_{d}^{(0)}]
%  \nonumber \\&
+\frac{\tilde{\mu}}{\tilde{\mu}+2\omega}\Sigma_{+,t}\tilde{\delta}
+\Sigma_{+,t}[\tilde{\sigma}+\tilde{\epsilon}_{c}^{(0)}].
    \end{align}
    Moreover, since $\frac{\tilde{\mu}}{\tilde{\mu}+2\omega}\leq 1$,
    $\sum\limits_{d=1}^N\varrho_{d}\tilde{\epsilon}_{d}^{(0)}= \tilde{\epsilon}^{(0)}$ and
        $
g_3\leq\frac{1+\sqrt{3}}{2}
$
(since $g_3$ is increasing with respect to $\omega$ and decreasing with respect to $\tilde{\mu}$), from~\eqref{eq:midgoal2} we obtain
 \begin{align} 
        \sqrt{\beta\mathbb E[\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2]}
        \leq &
2\omega\Sigma_{+,t}\sqrt{\beta}\Vert\bar{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert
        %  \nonumber \\&
+\Sigma_{+,t}
\left[\frac{3+\sqrt{3}}{2}\tilde{\sigma}+\frac{1+\sqrt{3}}{2}\tilde{\epsilon}^{(0)}+\tilde{\epsilon}_{c}^{(0)}+\tilde{\delta}\right].
    \end{align}
    Taking the square of the both hand sides followed by taking the weighted sum $\sum_{c=1}^N\varrho_c$, we get:
    \begin{align} \label{eq:Amid}
        &
 \beta A^{(t)}=\beta\mathbb E\left[\sum_{c=1}^N\varrho_c\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2\right]
        \leq
8\omega^2[\Sigma_{+,t}]^2\beta\Vert\bar{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert^2
\nonumber \\&
+2[\Sigma_{+,t}]^2\sum_{c=1}^N\varrho_c
\left[\frac{3+\sqrt{3}}{2}\tilde{\sigma}+\frac{1+\sqrt{3}}{2}\tilde{\epsilon}^{(0)}+\tilde{\epsilon}_{c}^{(0)}+\tilde{\delta}\right]^2
\nonumber \\&
\leq
8\omega^2[\Sigma_{+,t}]^2\beta\Vert\bar{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert^2
+2[\Sigma_{+,t}]^2
\left[\frac{3+\sqrt{3}}{2}\tilde{\sigma}+\frac{3+\sqrt{3}}{2}\tilde{\epsilon}^{(0)}+\tilde{\delta}
\right]^2
\nonumber \\&
\leq
8\omega^2[\Sigma_{+,t}]^2\beta\Vert\bar{\mathbf w}^{(t_{k-1})}-\mathbf w^*\Vert^2
+25[\Sigma_{+,t}]^2
\left[\tilde{\sigma}^2+\tilde{\delta}^2+(\tilde{\epsilon}^{(0)})^2\right].
    \end{align}
    Using the strong convexity of $F(.)$, we have
    $\Vert\bar{\mathbf w}(t_{k-1})-\mathbf w^*\Vert^2
    \leq \frac{2}{\tilde{\mu}\beta}
    [F(\bar{\mathbf w}(t_{k-1}))-F(\mathbf w^*)]
    $, using which in~\eqref{eq:Amid} yields:
    \begin{align} 
    &\beta A^{(t)}
    \leq
    \frac{16\omega^2}{\tilde{\mu}}[\Sigma_{+,t}]^2 [F(\bar{\mathbf w}(t_{k-1}))-F(\mathbf w^*)]
    +25[\Sigma_{+,t}]^2
    \left[\tilde{\sigma}^2+(\tilde{\epsilon}^{(0)})^2+\tilde{\delta}^2\right]
    \nonumber \\&
    = 
    \frac{16\omega^2\beta}{\mu}[\Sigma_{+,t}]^2 [F(\bar{\mathbf w}(t_{k-1}))-F(\mathbf w^*)]
    +25[\Sigma_{+,t}]^2
    \left[\frac{\sigma^2}{\beta}+\frac{\delta^2}{\beta}+\beta(\epsilon^{(0)})^2\right].
    \end{align}
   This concludes the proofs.
    
\end{proof}

\section{Proof of Theorem \ref{co1}} \label{app:thm1}
% \begin{corollary} \label{co1}
% Let $\bar{\mathbf w}^{(t)}
%         =\sum\limits_{c=1}^{N}\varrho_c^{(k)}\bar{\mathbf w}_c^{(t)}$ denote the global average of the local models, $\forall t$.
%         Under Assumption \ref{beta}, if $\eta_t=\frac{\gamma}{t+\alpha}\leq\vartheta/\beta$, $\epsilon_c^{(t)}=\eta_t\phi_c$, where $\sum_d\varrho_d\phi_d\leq\phi$ for some $\phi>0$, $\forall t$ and $\alpha\geq \max\{2/\vartheta^2,3\}$ and
%     $2/\mu\leq\gamma\leq\vartheta\alpha/\beta$, then the one-step behavior of $\bar{\mathbf w}^{(t)}$ under  {\tt TT-HF} for $t\in \mathcal{T}_k$ can be described as follows:
% % https://www.overleaf.com/project/5f7c9b5ce460a000011dc1e1
% \begin{align*} 
%       &\mathbb E\left[F(\hat{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
%         \leq 
%         (1-\mu\eta_{t})\mathbb E\left[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)\right]
%         % +\beta\eta_{t}^2\phi^2
%         \nonumber \\&
%         +\eta_{t}^2\beta^2
%         \bigg[ 
%          12C^2(t_{k-1}+\alpha-1)[1+\eta_{0}(2\beta\omega-\mu/2)]^2/(\mu\gamma^2) [F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]\\&
%         +6C^2\eta_0[1+\eta_{0}(2\beta\omega-\mu/2)]^2\tau_k^2(\beta\vartheta+\sigma)^2
%         +3C^2\eta_{0}(\sqrt{2}\beta\phi\eta_{0}+\sigma+\sqrt{2}\delta)^2
%         +\phi^2(\frac{1}{2\beta}+\eta_{0}/2)+\frac{\sigma^2}{2\beta}
%         \bigg].
% \end{align*}
% \end{corollary}

\begin{theorem} \label{co1}
        Under Assumptions \ref{beta},~\ref{assump:cons}, and~\ref{assump:SGD_noise}, upon using {\tt TT-HF} for ML model training, if $\eta_t \leq 1/\beta$, $\forall t$, the one-step behavior of $\hat{\mathbf w}^{(t)}$ can be described as follows:
% https://www.overleaf.com/project/5f7c9b5ce460a000011dc1e1
\begin{align*} 
       \mathbb E\left[F(\hat{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
        \leq&
        (1-\mu\eta_{t})\mathbb E[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)]
        \nonumber \\&
        +\frac{\eta_{t}\beta^2}{2}A^{(t)}
        +\frac{1}{2}[\eta_{t}\beta^2(\epsilon^{(t)})^2+\eta_{t}^2\beta\sigma^2+\beta(\epsilon^{(t+1)})^2], ~t\in\mathcal{T}_k,
\end{align*}
where
\begin{align}
     A^{(t)}\triangleq\mathbb E\left[\sum\limits_{c=1}^N\varrho_{c}\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert_2^2\right].
\end{align}
\end{theorem}

\begin{proof}
% \add{(we omit the dependence on $k$ for conciseness)}.
% We define 
% the average of the local models for an arbitrary cluster $c$ as
% \nm{drop the dependence on k..}
% \begin{align}
%     \bar{\mathbf w}_c^{(t)}=\frac{1}{s_c^{(k)}}
%     \sum\limits_{j\in\mathcal{S}_c^{(k)}}\mathbf w_j^{(t)}.
% \end{align}
% and also define global average of the local models as
% \begin{align}
%     \bar{\mathbf w}^{(t)}&
%         =\sum_c\varrho_c^{(k)}\bar{\mathbf w}_c^{(t)}.
% \end{align}
Considering $t \in \mathcal T_k$, using \eqref{8}, \eqref{eq14}, the definition of $\bar{\mathbf{w}}$ given in Definition~\ref{modDisp}, and the fact that $\sum\limits_{i\in\mathcal{S}_c} \mathbf e_{i}^{{(t)}}=0$, $\forall t$, under Assumption~\ref{assump:cons},
the global average of the local models follows the following dynamics:
% \nm{define ${\mathbf n}_{j,t}=\widehat{\mathbf g}^{(t)}_{j}-\nabla F_j(\mathbf w_j^{(t)})$ (or something else) from the beginning so that you keep the math more concise}
\begin{align}\label{eq:GlobDyn1}
    \bar{\mathbf w}^{(t+1)}=
    \bar{\mathbf w}^{(t)}
    -\frac{\tilde{\eta}_{t}}{\beta}\sum\limits_{c=1}^N \varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c} 
    \nabla F_j(\mathbf w_j^{(t)})
              -\frac{\tilde{\eta}_{t}}{\beta}\sum\limits_{c=1}^N \varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c} 
             \mathbf n_j^{{(t)}},
\end{align} where ${\mathbf n}_{j}^{{(t)}}=\widehat{\mathbf g}^{(t)}_{j}-\nabla F_j(\mathbf w_j^{(t)})$.
On the other hand, the $\beta$-smoothness of the global function $F$ implies
\begin{align} 
    F(\bar{\mathbf w}^{(t+1)}) \leq  F(\bar{\mathbf w}^{(t)})&+\nabla F(\bar{\mathbf w}^{(t)})^\top(\bar{\mathbf w}^{(t+1)}-\bar{\mathbf w}^{(t)})+\frac{\beta}{2}\Big\Vert \bar{\mathbf w}^{(t+1)}-\bar{\mathbf w}^{(t)}\Big\Vert^2.
\end{align}
Replacing the result of~\eqref{eq:GlobDyn1} in the above inequality, taking the conditional expectation (conditioned on the knowledge of $\bar{\mathbf w}^{(t)}$) of the both hand sides, and using the fact that $\mathbb E_t[{\mathbf n}^{(t)}_{j}]=\bf 0$ yields:
\begin{align}
    &\mathbb E_{t}\left[F(\bar{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
    \leq F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*)
    -\frac{\tilde{\eta}_{t}}{\beta}\nabla F(\bar{\mathbf w}^{(t)})^\top \sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c}\nabla F_j(\mathbf w_j^{(t)})
    \nonumber \\&
    +\frac{\tilde{\eta}_{t}^2}{2\beta}\Big
    \Vert\sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c} \nabla F_j(\mathbf w_j^{(t)})
    \Big\Vert^2
    + \frac{\tilde{\eta}_{t}^2}{2\beta}\mathbb E_t\left[
    \Big
    \Vert\sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c}\mathbf n_j^{{(t)}}\Big\Vert^2
    \right].
\end{align}
% \add{where we used the fact that $\mathbb E_t[\widehat{\mathbf g}^{(t)}_{j}]=\nabla F_j(\mathbf w_j^{(t)})$}
% \nm{in the last step you used the fact that SGD is unbiased.. please explain}
Since $\mathbb E_t[\Vert\mathbf n_i^{{(t)}}\Vert_2^2]\leq \beta\tilde{\sigma}^2$, $\forall i$, we get
\begin{align}\label{eq:aveGlob1}
    \mathbb E_{t}\left[F(\bar{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
        \leq& F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*)
        \nonumber \\&
        -\frac{\tilde{\eta}_{t}}{\beta}\nabla F(\bar{\mathbf w}^{(t)})^\top \sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c}\nabla F_j(\mathbf w_j^{(t)})
        \nonumber \\&
        +\frac{\tilde{\eta}_{t}^2}{2\beta}\Big
        \Vert\sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c} \nabla F_j(\mathbf w_j^{(t)})
        \Big\Vert^2
        +\frac{\tilde{\eta}_{t}^2\tilde{\sigma}^2}{2}.
\end{align}
Using Lemma \ref{lem1} (see Appendix \ref{app:PL-bound}), we further bound~\eqref{eq:aveGlob1} as follows:
\begin{align} \label{eq:E_t}
    &\mathbb E_{t}\left[F(\bar{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
    \leq
        (1-\tilde{\mu}\tilde{\eta}_{t})(F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*))
        \nonumber \\& 
       -\frac{\tilde{\eta}_{t}}{2\beta}(1-\tilde{\eta}_{t})\Big\Vert\sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c} \nabla F_j(\mathbf w_j^{(t)})\Big\Vert^2
       +\frac{\tilde{\eta}_{t}^2\tilde{\sigma}^2}{2}
        +\frac{\tilde{\eta}_{t}\beta}{2}\sum\limits_{c=1}^N\varrho_c \frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c}\Big\Vert\bar{\mathbf w}^{(t)}-\mathbf w_j^{(t)}\Big\Vert^2
    \nonumber \\&
    \leq
        (1-\tilde{\mu}\tilde{\eta}_{t})(F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*))
        +\frac{\tilde{\eta}_{t}\beta}{2}\sum\limits_{c=1}^N\varrho_c \frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c}\Big\Vert\bar{\mathbf w}^{(t)}-\mathbf w_j^{(t)}\Big\Vert^2+\frac{\tilde{\eta}_{t}^2\tilde{\sigma}^2}{2},
\end{align}
where the last step follows from $\tilde{\eta}_t\leq 1$. 
To further bound the terms on the right hand side of~\eqref{eq:E_t}, we use the fact that
\begin{align}
        \Vert\mathbf w_i^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2
        =
        \Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2
        +\Vert \mathbf e_i^{{(t)}}\Vert^2
        +2[\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}]^\top \mathbf e_i^{{(t)}},
    \end{align} 
    % where $\mathbf e_i^{{(t_{k-1})}}=\mathbf 0$.
    which results in
    \begin{align} \label{eq:wi_w}
        \frac{1}{s_c}\sum\limits_{i\in \mathcal S_c}\Vert\mathbf w_i^{(t)}-\bar{\mathbf w}^{(t)}\Vert_2^2
        \leq
        \Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert_2^2
        +\frac{(\tilde{\epsilon}_{c}^{(t)})^2}{\beta}.
    \end{align} 
    Replacing \eqref{eq:wi_w} in \eqref{eq:E_t}  and taking the unconditional expectation from the both hand sides of the resulting expression gives us
    \begin{align} \label{eq:ld}
        &\mathbb E\left[F(\bar{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
        \leq
        (1-\tilde{\mu}\tilde{\eta}_{t})\mathbb E[F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*)]
        \nonumber \\&
        +\frac{\tilde{\eta}_{t}\beta}{2}\sum\limits_{c=1}^N\varrho_c \left(\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert_2^2
        +\frac{(\tilde{\epsilon}_{c}^{(t)})^2}{\beta}\right)+\frac{\tilde{\eta}_{t}^2\tilde{\sigma}^2}{2}
        \nonumber \\&
        =
        (1-\tilde{\mu}\tilde{\eta}_{t})\mathbb E[F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*)]
        +\frac{\tilde{\eta}_{t}\beta}{2}A^{(t)}
        +\frac{1}{2}[\tilde{\eta}_{t}(\tilde{\epsilon}^{(t)})^2+\tilde{\eta}_{t}^2\tilde{\sigma}^2],
    \end{align}
where  
\begin{align}
    A^{(t)}\triangleq\mathbb E\left[\sum\limits_{c=1}^N\varrho_c \Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2\right].
\end{align}
% denotes the \emph{cluster model dispersion}, quantifying how much the average of local models in each cluster deviate from the global average of the  local models.
% \frank{Definition slightly changed here:cluster model dispersion.}
% Using the result of Proposition \ref{Local_disperse} (see Appendix \ref{app:Local_disperse}) to bound the cluster model dispersion, in~\eqref{eq:ld} we get
% \begin{align} \label{eq:wbar-update}
%         &\mathbb E\left[F(\bar{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
%         \leq (1-\mu\eta_{t})\mathbb E\left[(F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*))\right] 
%         \nonumber \\&
%         +\frac{\eta_t\beta^2}{2}
%         \bigg[ 
%         \frac{16\omega^2\eta_t C_k}{\mu}\left(1+\frac{\tau_k}{\alpha-1}\right)^{6\gamma\beta}[F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]
%         \nonumber \\&
%         +\eta_t C_k\left(1+\frac{\tau_k}{\alpha-1}\right)^{6\gamma\beta}[\frac{150\sigma^2}{4\beta^2}+\frac{150(\epsilon^{(0)})^2}{4}+\frac{6\delta^2}{\beta^2}]+(\epsilon^{(t)})^2
%         \bigg]
%         +\frac{\eta_t^2 \beta\sigma^2}{2}
%         \nonumber \\&
%         \overset{(a)}{\leq} 
%         (1-\mu\eta_{t})\mathbb E\left[(F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*))\right] 
%         \nonumber \\&
%         +\frac{\eta_t\beta^2}{2}
%         \bigg[ 
%         \frac{16\omega^2\eta_t C_k}{\mu}\left(1+\frac{\tau_k}{\alpha-1}\right)^{6\gamma\beta}[F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]
%         \nonumber \\&
%         +\eta_t C_k\left(1+\frac{\tau_k}{\alpha-1}\right)^{6\gamma\beta}[\frac{150\sigma^2}{4\beta^2}+\frac{150(\eta_0\phi)^2}{4}+\frac{6\delta^2}{\beta^2}]+\eta_t^2\phi^2
%         \bigg]
%         +\frac{\eta_t^2 \beta\sigma^2}{2}
%         \nonumber \\&
%         \overset{(b)}{\leq}
%          (1-\mu\eta_{t})\mathbb E\left[(F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*))\right] 
%         \nonumber \\&
%         +\eta_{t}^2\beta^2
%         \bigg[ 
%         \frac{8\omega^2 C_k}{\mu}\left(1+\frac{\tau_k}{\alpha-1}\right)^{6\gamma\beta}[F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]
%         \nonumber \\&
%         +C_k\left(1+\frac{\tau_k}{\alpha-1}\right)^{6\gamma\beta}[\frac{150\sigma^2}{8\beta^2}+\frac{150(\eta_0\phi)^2}{8}+\frac{3\delta^2}{\beta^2}]
%         +\frac{\phi^2\eta_{0}}{2}+\frac{\sigma^2}{2\beta}
%         \bigg],
% \end{align} where in $(a)$ we use the fact that $\epsilon^{(t)}=\eta_t\phi$ and in $(b)$ we used the fact that $\eta_t\leq \eta_{t-1}\leq\eta_0$, $\forall t\in\mathcal T_k$.

By $\beta$-smoothness of $F(\cdot)$, we have
\begin{align} \label{eq:39}
    &F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*) 
    \leq F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*)
    +\nabla F(\bar{\mathbf w}^{(t)})^\top\Big(\hat{\mathbf w}^{(t)}-\bar{\mathbf w}^{(t)}\Big)+\frac{\beta}{2}\Vert\hat{\mathbf w}^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2
    \nonumber \\&
    \leq F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*)+\nabla F(\bar{\mathbf w}^{(t)})^\top\sum\limits_{c=1}^N\varrho_c \mathbf e_{s_c}^{{(t)}}
    +\frac{\beta}{2}\sum\limits_{c=1}^N\varrho_c\Vert \mathbf e_{s_c}^{{(t)}}\Vert^2.
\end{align}
Taking the expectation with respect to the device sampling from both hand sides of \eqref{eq:39}, since the sampling is conducted uniformly at random, we obtain
\begin{align} 
    \mathbb E_t\left[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)\right]  
    \leq& F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*)+\nabla F(\bar{\mathbf w}^{(t)})^\top\sum\limits_{c=1}^N\varrho_c \underbrace{\mathbb    E_t\left[\mathbf e_{s_c}^{{(t)}}\right]}_{=0}
    \nonumber \\&+\frac{\beta}{2}\sum\limits_{c=1}^N\varrho_c\mathbb E_t\left[\Vert \mathbf e_{s_c}^{{(t)}}\Vert^2\right].
\end{align}
Taking the total expectation from both hand sides of the above inequality yields:
\begin{align} \label{eq:hat-bar}
    &\mathbb E\left[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)\right]  
    \leq \mathbb E\left[F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*)\right]
    +\frac{(\tilde{\epsilon}^{(t)})^2}{2}.
\end{align}
Replace \eqref{eq:ld} into \eqref{eq:hat-bar}, we have
\begin{align} \label{eq:-}
    \mathbb E\left[F(\hat{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
        \leq&
        (1-\tilde{\mu}\tilde{\eta}_{t})\mathbb E[F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*)]+\frac{\tilde{\eta}_{t}\beta}{2}A^{(t)}
        \nonumber \\&
        +\frac{1}{2}[\tilde{\eta}_{t}(\tilde{\epsilon}^{(t)})^2+\tilde{\eta}_{t}^2\tilde{\sigma}^2+(\tilde{\epsilon}^{(t+1)})^2].
\end{align}
On the other hands, using the strong convexity of $F(\cdot)$, we have
\begin{align} \label{eq:^}
    &F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*) 
    \geq F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*)
    +\nabla F(\bar{\mathbf w}^{(t)})^\top\Big(\hat{\mathbf w}^{(t)}-\bar{\mathbf w}^{(t)}\Big)+\frac{\mu}{2}\Vert\hat{\mathbf w}^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2
    \nonumber \\&
    \geq F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*)+\nabla F(\bar{\mathbf w}^{(t)})^\top\sum\limits_{c=1}^N\varrho_c \mathbf e_{s_c}^{{(t)}}.
    % \\&
    % \add{
    % \leq F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)
    % -\nabla F(\bar{\mathbf w}^{(t)})^\top\sum\limits_{c=1}^N\varrho_c \mathbf e_{s_c}^{{(t)}}
    % +\Vert\nabla F(\hat{\mathbf w}^{(t)})-\nabla F(\bar{\mathbf w}^{(t)})\Vert\Vert\sum\limits_{c=1}^N\varrho_c \mathbf e_{s_c}^{{(t)}}\Vert
    % +\frac{\beta}{2}\sum\limits_{c=1}^N\varrho_c\Vert \mathbf e_{s_c}^{{(t)}}\Vert^2
    % }
    %     \\&
    % \add{
    % \leq F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)
    % -\nabla F(\bar{\mathbf w}^{(t)})^\top\sum\limits_{c=1}^N\varrho_c \mathbf e_{s_c}^{{(t)}}
    % +\beta\Vert\sum\limits_{c=1}^N\varrho_c \mathbf e_{s_c}^{{(t)}}\Vert^2
    % +\frac{\beta}{2}\sum\limits_{c=1}^N\varrho_c\Vert \mathbf e_{s_c}^{{(t)}}\Vert^2
    % }
    %         \\&
    % \add{
    % \leq F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)
    % -\nabla F(\bar{\mathbf w}^{(t)})^\top\sum\limits_{c=1}^N\varrho_c \mathbf e_{s_c}^{{(t)}}
    % +\frac{3\beta}{2}\sum\limits_{c=1}^N\varrho_c\Vert \mathbf e_{s_c}^{{(t)}}\Vert^2
    % }
\end{align}
Taking the expectation with respect to the device sampling from the both hand sides of \eqref{eq:^}, since the sampling is conducted uniformly at random, we obtain
\begin{align} 
    &\mathbb E_t\left[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)\right]  
    % \nonumber \\&
    \geq 
    F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*)
    +\nabla F(\bar{\mathbf w}^{(t)})^\top\sum\limits_{c=1}^N\varrho_c \underbrace{\mathbb    E_t\left[\mathbf e_{s_c}^{{(t)}}\right]}_{=0}.
\end{align}
Taking the total expectation from both hand sides of the above inequality yields:
\begin{align} \label{eq:bar-hat}
    &\mathbb E\left[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)\right]  
    \geq \mathbb E\left[F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*)\right].
\end{align}
Finally, replacing \eqref{eq:bar-hat} into \eqref{eq:-}, we obtain
\begin{align}
    &\mathbb E\left[F(\hat{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
        \leq
        (1-\tilde{\mu}\tilde{\eta}_{t})\mathbb E[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)]
        \nonumber \\&
        +\frac{\tilde{\eta}_{t}\beta}{2}A^{(t)}
        +\frac{1}{2}[\tilde{\eta}_{t}(\tilde{\epsilon}^{(t)})^2+\tilde{\eta}_{t}^2\tilde{\sigma}^2+(\tilde{\epsilon}^{(t+1)})^2]
        \nonumber
        \nonumber \\&
        =
        (1-\mu\eta_{t})\mathbb E[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)]
        +\frac{\eta_{t}\beta^2}{2}A^{(t)}
        +\frac{1}{2}[\eta_{t}\beta^2(\epsilon^{(t)})^2+\eta_{t}^2\beta\sigma^2+\beta(\epsilon^{(t+1)})^2].
        % \nonumber \\&
        % \overset{(a)}{\leq}
        % (1-\tilde{\mu}\tilde{\eta}_{t})\mathbb E[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)]
        % +\frac{\tilde{\eta}_{t}\beta}{2}A^{(t)}
        % +\frac{1}{2}[\tilde{\eta}_{t}^3\tilde{\phi}^2+\tilde{\eta}_{t}^2\tilde{\sigma}^2+\tilde{\eta}_{t+1}^2\tilde{\phi}^2]
        % \nonumber \\&
        % =
        % (1-\mu\eta_{t})\mathbb E[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)]
        % +\frac{\eta_{t}\beta^2}{2}A^{(t)}
        % % \nonumber \\&
        % +\frac{1}{2}[\eta_{t}^3\phi^2\beta^2+\eta_{t}^2\beta\sigma^2+\eta_{t+1}^2\phi^2\beta],
\end{align}
% where $(a)$ comes from the fact that $\tilde{\epsilon}^{(t)}=\tilde{\eta}_t\tilde{\phi}$.
% $\tilde{\epsilon}^{(t)}=\tilde{\eta}_t\phi=\eta_t\phi\beta$. 
This concludes the proof.

% \begin{align}
%     &\mathbb E\left[F(\hat{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
%         \leq 
%         (1-\mu\eta_{t})\mathbb E\left[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)\right]
%          + \frac{\beta}{2}\eta_{t+1}^2\phi^2
%         \nonumber \\&
%         +\eta_{t}^2\beta^2
%         \bigg[ 
%         \frac{8\omega^2 C_k}{\mu}\left(1+\frac{\tau_k}{\alpha-1}\right)^{6\gamma\beta}[F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]
%         \nonumber \\&
%         +C_k\left(1+\frac{\tau_k}{\alpha-1}\right)^{6\gamma\beta}[\frac{150\sigma^2}{8\beta^2}+\frac{150(\eta_0\phi)^2}{8}+\frac{3\delta^2}{\beta^2}]
%         +\frac{\phi^2\eta_{0}}{2}+\frac{\sigma^2}{2\beta}
%         \bigg]
%         \nonumber \\&
%         \overset{(a)}{\leq}
%         (1-\mu\eta_{t})\mathbb E\left[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)\right]
%         \nonumber \\&
%         +\eta_{t}^2\beta^2
%         \bigg[ 
%         \frac{8\omega^2 C_k}{\mu}\left(1+\frac{\tau_k}{\alpha-1}\right)^{6\gamma\beta}[F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]
%         \nonumber \\&
%         +C_k\left(1+\frac{\tau_k}{\alpha-1}\right)^{6\gamma\beta}[\frac{150\sigma^2}{8\beta^2}+\frac{150(\eta_0\phi)^2}{8}+\frac{3\delta^2}{\beta^2}]
%         +\phi^2(\frac{\eta_{0}}{2}+\frac{1}{2\beta})+\frac{\sigma^2}{2\beta}
%         \bigg],
%         % \nonumber \\&
%         % \overset{(b)}{\leq}
%         % (1-\mu\eta_{t})\mathbb E\left[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)\right]
%         % % +\beta\eta_{t}^2\phi^2
%         % \nonumber \\&
%         % +\eta_{t}^2\beta^2
%         % \bigg[ 
%         %  12C^2(t_{k-1}+\alpha-1)[1+\eta_{0}(2\beta\omega-\mu/2)]^2/(\mu\gamma^2) [F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]\\&
%         % +6C^2\eta_0[1+\eta_{0}(2\beta\omega-\mu/2)]^2\tau_k^2(\beta\vartheta+\sigma)^2
%         % +3C^2\eta_{0}(\sqrt{2}\beta\phi\eta_{0}+\sigma+\sqrt{2}\delta)^2
%         % +\phi^2(\frac{1}{2\beta}+\eta_{0}/2)+\frac{\sigma^2}{2\beta}
%         % \bigg],
% \end{align}
% where $(a)$ comes from the fact that $\eta_{t+1}/\eta_t\leq1,~\forall t$.
\end{proof}

\iffalse
{\color{blue}
\section{Proof of Theorem \ref{thm:subLin}} \label{app:subLin}
% \addFL{
\begin{theorem} \label{thm:subLin}
Define $A=8\eta_{0}((2\vartheta^2+1/16)\phi^2+2\sigma^2+\delta^2)+\frac{\sigma^2}{2\beta}$, $B=12\eta_{0}[1+\eta_{0}(2\beta\omega-\mu/2)]^2[\vartheta^2\phi^2+2\sigma^2]$, and $\tau\triangleq \max\{\tau_1,\cdots,\tau_{k} \}$, $\forall k$. Also, let $\gamma>[3+8\big(1/\vartheta+(2\omega-\vartheta/2)\big)^2]/\mu$ and $\alpha\geq\max\{\beta\gamma/\vartheta,\beta\mu/2,3\}$. Then, using {\tt TT-HF} for ML model training under Assumption \ref{beta}, by choosing $\eta_t=\frac{\gamma}{t+\alpha}$, $\epsilon^{(t)}=\eta_t\phi$, $\forall t$, we have: 
    % Using {\tt TT-HF} for ML model training, under Assumption \ref{beta}, if we set the step size as $\eta_t=\frac{\gamma}{t+\alpha}$, $\forall t$, and assuming that $\epsilon(t)=\eta_t\phi$, $\forall t$,
    % we have
    \begin{align} \label{eq:thm2_result-1}
        &\mathbb E\left[F(\hat{\mathbf w}^{(t_k)})-F(\mathbf w^*)\right]  
        \leq \frac{\nu}{t+\alpha},~\forall k = 1,\cdots,K,
    \end{align}
    where $\nu=\max\{\alpha[F(\hat{\mathbf w}^{(0)})-F(\mathbf w^*)],\frac{\gamma^2\beta^2 (A+12\eta_{0}[1+\eta_{0}(2\beta\omega-\mu/2)]^2\phi^2/(3\gamma\beta)+\tau^2 B)}{\mu\gamma-[3+8(1/\vartheta+(2\omega-\vartheta/2))^2]}\}$.
    
    % under either of the following two cases:

    % \textbf{Case 1:} For a given value of $\tau\triangleq \max\{\tau_1,\cdots,\tau_{k} \}\geq1$, choosing 
    %     \begin{align} \label{eq:thm2_case1}
    %         \tilde{\Gamma} \geq \gamma^2\beta^2 (A+\tau^2 B)/\Big[\gamma-2[1/\mu+8\big(\beta+\kappa(\zeta-\mu/2)\big)^2/\mu^2]\Big] + \kappa\gamma\phi^2/2,
    %     \end{align}
        
    % \textbf{Case 2:} For a given value of $\tilde{\Gamma}\geq\gamma^2\beta^2(A+B)/\Big[\gamma-2[1/\mu+8\big(\beta+\kappa(\zeta-\mu/2)\big)^2/\mu^2]\Big]+\kappa\gamma\phi^2/2$, choosing 
    %     \begin{align} \label{eq:thm2_case2}
    %          1 \leq \tau \leq \sqrt{\Big[\gamma-2[1/\mu+8\big(\beta+\kappa(\zeta-\mu/2)\big)^2/\mu^2]\Big]\Big[\tilde{\Gamma}-\kappa\gamma\phi^2/2\Big]/(\gamma^2\beta^2 B)-A/B}.
    %     \end{align} 
\end{theorem}
\begin{proof}
    We first prove that 
    \begin{equation}\label{eq:firstpartTh2}
        \mathbb E\left[(F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*))\right]\leq\frac{\nu}{t+\alpha}+\frac{(k-1)\beta\phi^2}{2}\eta_{t}^2,~\forall t\in\mathcal T_k ... \frac{\beta \phi^2}{2}\sum_{k'=1}^{k-1}\eta^2_{t_{k'}}
    \end{equation}
    where $\nu\geq\max\{\alpha[F(\bar{\mathbf w}^{(0)})-F(\mathbf w^*)],\tilde{\nu}\}$ with $\tilde{\nu} \geq
    \gamma^2\beta^2 (A+\tau^2 B)/\Big[\mu\gamma-[3+8(1/\vartheta+(2\omega-\vartheta/2))^2]\Big]$.
    We carry out the proof by induction.  It can be seen that $\mathbb E\left[(F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*))\right]\leq\frac{\nu}{t+\alpha}$ trivially holds for $t=0$ from the definition of $\nu$. 
     By $\beta$-smoothness of $F(\cdot)$, we have
\begin{align} \label{39}
    &\mathbb E\left[F(\hat{\mathbf w}^{(t_k)})-F(\mathbf w^*)\right]  
    \leq \mathbb E\left[F(\widetilde{\bar{\mathbf w}^{(t_k)}})-F(\mathbf w^*)\right]
    \nonumber \\&
    +\mathbb E\left[\nabla F(\widetilde{\bar{\mathbf w}^{(t_k)}})^\top\Big(\hat{\mathbf w}^{(t_k)}-\widetilde{\bar{\mathbf w}^{(t_k)}}\Big)\right]+\frac{\beta}{2}\mathbb E\left[\Vert\hat{\mathbf w}^{(t_k)}-\widetilde{\bar{\mathbf w}^{(t_k)}}\Vert^2\right]
    \nonumber \\&
    \leq \mathbb E\left[F(\widetilde{\bar{\mathbf w}^{(t_k)}})-F(\mathbf w^*)\right]+\mathbb E\left[\nabla F(\widetilde{\bar{\mathbf w}^{(t_k)}})\right]^\top\sum\limits_{c=1}^N\varrho_c^{(k)} \mathbb E\left[e_{s_c^{(k)}}^{{(t_k)}}\right]
    +\frac{\beta}{2}\sum\limits_{c=1}^N\varrho_c^{(k)}\mathbb E\left[\Vert e_{s_c^{(k)}}^{{(t_k)}}\Vert^2\right]
    \nonumber \\&
    \leq \mathbb E\left[F(\widetilde{\bar{\mathbf w}^{(t_k)}})-F(\mathbf w^*)\right]
    +\frac{\beta}{2}(\epsilon^{(t_k)})^2
    % \nonumber \\&
    \overset{(a)}{\leq}
    \frac{\nu}{t_{k}+\alpha}+\frac{(k-1)\beta\phi^2}{2}\eta_{t_k}^2
    +\frac{\beta}{2}\eta_{t_k}^2\phi^2
    \nonumber \\&
    \leq
    \frac{\nu}{t_{k}+\alpha}+\frac{k\beta\phi^2}{2}\eta_{t_k}^2
    .
\end{align}
    Assuming that the result holds for all iterations before $t$, we show that the results also holds for iteration $t+1$.
    Using the result of Theorem \ref{co1}, we get   
    % \nm{dont you need to assume $t\in \mathcal{T}_k$ to apply Thm1?}
    % \nm{also, you cannot use the induction HP to bound $\mathbb E[F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]$ since HP holds for $\bar w$ only}
    % Consider case $t\in\mathcal T_1$, we 
    \begin{align}\label{eq:BigTh2}
        &\mathbb E\left[F(\bar{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
        \leq 
         (1-\mu\eta_{t})\mathbb E\left[(F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*))\right] 
        \nonumber \\&
        +\eta_{t-2}^2\beta^2
        \bigg[ 
         12(t_{k-1}+\alpha-1)[1+\eta_{0}(2\beta\omega-\mu/2)]^2/\mu\gamma^2 [F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]\\&
        +6\eta_0[1+\eta_{0}(2\beta\omega-\mu/2)]^2\tau_k^2(\beta\vartheta+\sigma)^2
        +3\eta_{0}(\sqrt{2}\beta\phi\eta_{0}+\sigma+\sqrt{2}\delta)^2
        +\phi^2\eta_{0}/2+\frac{\sigma^2}{2\beta}
        \bigg]
        \nonumber \\&
        \overset{(a)}{\leq}
         (1-\mu\eta_{t})\Big[\frac{\nu+k\beta\gamma\eta_{t}\phi^2/2}{t+\alpha}\Big]
        \nonumber \\&
        +\eta_{t-2}^2\beta^2
        \bigg[ 
         12(t_{k-1}+\alpha-1)[1+\eta_{0}(2\beta\omega-\mu/2)]^2/\mu\gamma^2 \Big[\frac{\nu+k\beta\gamma\eta_{t_{k-1}}\phi^2/2}{t_{k-1}+\alpha}\Big]\\&
        +6\eta_0[1+\eta_{0}(2\beta\omega-\mu/2)]^2\tau_k^2(\beta\vartheta+\sigma)^2
        +3\eta_{0}(\sqrt{2}\beta\phi\eta_{0}+\sigma+\sqrt{2}\delta)^2
        +\phi^2\eta_{0}/2+\frac{\sigma^2}{2\beta}
        \bigg]
        \nonumber \\&
        \overset{(b)}{\leq}
        \frac{t+\alpha-\mu\gamma}{(t+\alpha)^2}[\nu+k\beta\gamma\eta_{t}\phi^2/2]
        \nonumber \\&
        +\frac{\gamma^2\beta^2}{(t+\alpha-2)^2}
        \bigg[ 
         12[1+\eta_{0}(2\beta\omega-\mu/2)]^2/\mu\gamma^2 \Big[\nu+k\beta\gamma\eta_{t_{k-1}}\phi^2/2\Big]\\&
        +6\eta_0[1+\eta_{0}(2\beta\omega-\mu/2)]^2\tau_k^2(\beta\vartheta+\sigma)^2
        +3\eta_{0}(\sqrt{2}\beta\phi\eta_{0}+\sigma+\sqrt{2}\delta)^2
        +\phi^2\eta_{0}/2+\frac{\sigma^2}{2\beta}
        \bigg]
        \nonumber \\&
        \overset{(c)}{\leq}
        \frac{t+\alpha-5}{(t+\alpha-2)^2}[\nu+k\beta\gamma\eta_{t}\phi^2/2]-\frac{\mu\gamma-\Big[5+12[\beta+\vartheta(2\beta\omega-\mu/2)]^2/\mu\Big]}{(t+\alpha-2)^2}[\nu+k\beta\gamma\eta_{t_{k-1}}\phi^2/2]
        \nonumber \\&
        +\frac{\gamma^2\beta^2}{(t+\alpha-2)^2}
        \bigg[
        6\eta_0[1+\eta_{0}(2\beta\omega-\mu/2)]^2\tau_k^2(\beta\vartheta+\sigma)^2
        +3\eta_{0}(\sqrt{2}\beta\phi\eta_{0}+\sigma+\sqrt{2}\delta)^2
        +\phi^2\eta_{0}/2+\frac{\sigma^2}{2\beta}
        \bigg]
        \nonumber \\&
        \leq
        \frac{t+\alpha-5}{(t+\alpha-2)^2}[\nu+k\beta\gamma\eta_{t}\phi^2/2]\underbrace{-\underbrace{\frac{\mu\gamma-\Big[5+12[1/\vartheta+(2\omega-\vartheta/2)]^2\Big]}{(t+\alpha-2)^2}}_{(i)}[\nu+k\beta\gamma\eta_{t_{k-1}}\phi^2/2]
        % \nonumber \\&
        +\frac{\gamma^2\beta^2 (A+\tau_k^2B)}{(t+\alpha-2)^2}}_{(ii)}.
    \end{align}
    In~\eqref{eq:BigTh2}, $(a)$ is obtained based on the induction hypothesis and the fact that $\hat{\mathbf w}^{(t_{0})}=\bar{\mathbf w}^{(t_{0})}$, $(b)$ is due to the fact that $\eta_t=\frac{\gamma}{t+\alpha}$, and $(c)$ is obtained assuming $\eta_t\leq\vartheta/\beta$. We also assume that $\alpha\geq 3$ to make the first term in the right hand side of the last inequality positive, $\forall t\geq 0$.\nm{and why do you care in making that positive?}
    
    To make term (i) in~\eqref{eq:BigTh2} positive, we obtain the following range for $\gamma$:
     \begin{align} \label{eq:range_gam}
        \gamma > [3+8\big(1/\vartheta+(2\omega-\vartheta/2)\big)^2]/\mu.
    \end{align}
      To satisfy the initial condition on the step size $\eta_0\leq\min\{\vartheta/\beta,2/\mu\}$, the range of $\alpha$ is subsequently given by
    \begin{align} \label{eq:range_alpha}
        \alpha \geq \max\{\beta\gamma/\vartheta,\beta\mu/2,3\}.
    \end{align}
    Using~\eqref{eq:BigTh2} and performing some algebraic manipulations, it can be verified that the following inequality holds
    \begin{align} \label{sub_t+1}
        &\mathbb E\left[F(\bar{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
        \leq
        \frac{t+\alpha-3}{(t+\alpha-1)^2}\tilde{\nu}
        \overset{(a)}{\leq}
        \frac{\tilde{\nu}}{t+\alpha+1}
        \leq
        \frac{\nu}{t+\alpha+1}
    \end{align}
    under either of the two cases below. Note that $(a)$ results from the fact that $(t+\alpha-1)^2>(t+\alpha+1)(t+\alpha-3)$.
    
    % \nm{arent these tow cases equivalent? Dont have both, it is quite confusing..}
    % \textbf{Case 1:}  
    For a given value of $\tau_1\geq1$, choosing 
    \begin{align} \label{eq:nu_first}
        \tilde{\nu} \geq \gamma^2\beta^2 (A+\tau_1^2 B)/\Big[\mu\gamma-[3+8(1/\vartheta+(2\omega-\vartheta/2))^2]\Big].
    \end{align}
    
    \iffalse
    \textbf{Case 2:} For a given value of $\tilde{\nu}\geq\gamma^2\beta^2(A+B)/\Big[\mu\gamma-[3+8(1/\vartheta+(2\omega-\vartheta/2))^2]\Big]$, choosing 
    \begin{align}
         1 \leq \tau \leq \sqrt{\Big[\mu\gamma-[3+8(1/\vartheta+(2\omega-\vartheta/2))^2]\Big]\tilde{\nu}/(\gamma^2\beta^2 B)-A/B}.
    \end{align} 
    \fi
    % For
    % \begin{align} \label{eq:range_gam}
    %     \gamma > 2[1/\mu+8\big(\beta+\vartheta(\zeta-\mu/2)\big)^2/\mu^2],
    % \end{align}
%     if we are given some value of $\tau_k\geq1$, then by choosing 
%     \begin{align}
%         \tilde{\nu} \geq \gamma^2\beta^2 (A+\tau_k^2 B)/\Big[\gamma-2[1/\mu+8\big(\beta+\vartheta(\zeta-\mu/2)\big)^2/\mu^2]\Big],
%     \end{align}
%     we show that 
%     \begin{align} \label{sub_t+1}
%         &\mathbb E\left[F(\bar{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
%         \leq
%         \frac{t+\alpha-1}{(t+\alpha)^2}\nu
%         \leq
%         \frac{\tilde{\nu}}{t+\alpha+1}
%         \leq
%         \frac{\nu}{t+\alpha+1}
%     \end{align}
%     holds. \\
%     Or equivalently, if we are given some $$\tilde{\nu}\geq\gamma^2\beta^2(A+B)/\Big[\gamma-2[1/\mu+8\big(\beta+\vartheta(\zeta-\mu/2)\big)^2/\mu^2]\Big],$$ 
%     then by choosing 
%     \begin{align}
%          1 \leq \tau_k \leq \sqrt{\Big[\gamma-2[1/\mu+8\big(\beta+\vartheta(\zeta-\mu/2)\big)^2/\mu^2]\Big]\tilde{\nu}/(\gamma^2\beta^2 B)-A/B},
%     \end{align} 
%   we show that \eqref{sub_t+1} holds. \\
  This completes the proof of~\eqref{eq:firstpartTh2}.
    % which then results in
    % \begin{align} \label{wbar_pfd}
    %     &\mathbb E\left[F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*)\right]
    %     \leq
    %     \frac{\nu}{t+\alpha},~\forall t=0,1,\dots,T.
    % \end{align}
    Now, after showing that \eqref{eq:firstpartTh2} holds for $t\in\mathcal T_1$, we aim to prove that
    \begin{align} \label{eq:secondpartTh2}
        \mathbb E\left[F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*)\right]\leq\frac{\nu}{t+\alpha}, \forall t\in\mathcal T_k,
    \end{align}
    % where the value of $\Gamma$ is specified in the Theorem's statement. This result trivially holds for $t=0$. For $t\geq 1$, we conduct the proof using the result of~\eqref{eq:firstpartTh2}.
    
\nm{the above result is in contradiction with eq 95 that you try to prove! Hence, 95 is wrong! Did you try follow my suggestion?}
% \nm{why are you takin the gradient out of the expectation above?}
where $\widetilde{\bar{\mathbf w}^{(t_k)}}$ is defined as the global average of local models at $t_{k}$ before synchronization, $(a)$ is obtained from~\eqref{eq:firstpartTh2} and $(b)$ is obtained due to the fact that $\eta_t=\frac{\gamma}{t+\alpha}\leq\vartheta/\beta$. Again, we assume $\mathbb E\left[(F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*))\right]\leq\frac{\nu}{t+\alpha},~\forall t\in\mathcal T_k$ by induction hypothesis, replacing \eqref{39} into Theorem \ref{co1}, we have
\begin{align}\label{eq:BigTh2-k}
        &\mathbb E\left[F(\bar{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
        \leq 
         (1-\mu\eta_{t})\mathbb E\left[(F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*))\right] 
        \nonumber \\&
        +\eta_{t-1}^2\beta^2
        \bigg[ 
        8(t_{k-1}+\alpha)[1+\eta_{0}(2\beta\omega-\mu/2)]^2/(\mu\gamma^2)\mathbb E[F(\hat{\mathbf w}^{(t_{0})})-F(\mathbf w^*)]
        \nonumber \\&
        +12\eta_{0}[1+\eta_{0}(2\beta\omega-\mu/2)]^2 \left[\tau_k^2(\vartheta^2\phi^2+2\sigma^2)\right]
        +8\eta_{0}[(2\vartheta^2+1/16)\phi^2+2\sigma^2+\delta^2]+\frac{\sigma^2}{2\beta}
        \bigg]
        \nonumber \\&
        \overset{(a)}{\leq}
        (1-\mu\eta_{t})\frac{\nu}{t+\alpha}
        % \nonumber \\&
        +\eta_{t-1}^2\beta^2
        \bigg[ 
        8[1+\eta_{0}(2\beta\omega-\mu/2)]^2/(\mu\gamma^2)(\nu+\gamma\vartheta\phi^2/2)
        \nonumber \\&
        +12\eta_{0}[1+\eta_{0}(2\beta\omega-\mu/2)]^2 \left[\tau_k^2(\vartheta^2\phi^2+2\sigma^2)\right]
        % \nonumber \\&
        +8\eta_{0}[((2\vartheta^2+1/16))\phi^2+2\sigma^2+\delta^2]+\frac{\sigma^2}{2\beta}
        \bigg]
        \nonumber \\&
        \overset{(b)}{\leq}
        \frac{t+\alpha-\mu\gamma}{(t+\alpha)^2}\nu
        % \nonumber \\&
        +\frac{\gamma^2\beta^2}{(t+\alpha-1)^2}
        \bigg[ 
        8[1+\eta_{0}(2\beta\omega-\mu/2)]^2/(\mu\gamma^2)\nu
        \nonumber \\&
        +12\eta_{0}[1+\eta_{0}(2\beta\omega-\mu/2)]^2 \left[\tau_k^2(\vartheta^2\phi^2+2\sigma^2)+\phi^2/(3\gamma\beta)\right]
        +8\eta_{0}[((2\vartheta^2+1/16))\phi^2+2\sigma^2+\delta^2]+\frac{\sigma^2}{2\beta}
        \bigg]
        \nonumber \\&
        \overset{(c)}{\leq}
        \frac{t+\alpha-3}{(t+\alpha-1)^2}\nu-\frac{\mu\gamma-\Big[3+8[\beta+\vartheta(2\beta\omega-\mu/2)]^2/\mu\Big]}{(t+\alpha-1)^2}\nu
        \nonumber \\&
        +\frac{\gamma^2\beta^2}{(t+\alpha-1)^2}
        \bigg[12\eta_{0}[1+\eta_{0}(2\beta\omega-\mu/2)]^2 \left[\tau_k^2(\vartheta^2\phi^2+2\sigma^2)+\phi^2/(3\gamma\beta)\right]
        \nonumber \\&
        +8\eta_{0}((2\vartheta^2+1/16)\phi^2+2\sigma^2+\delta^2)+\frac{\sigma^2}{2\beta}
        \bigg]
        \nonumber \\&
        \leq
        \frac{t+\alpha-3}{(t+\alpha-1)^2}\nu-\frac{\mu\gamma-\Big[3+8[1/\vartheta+(2\omega-\vartheta/2)]^2\Big]}{(t+\alpha-1)^2}\nu
        % \nonumber \\&
        +\frac{\gamma^2\beta^2 (A'+\tau_k^2B)}{(t+\alpha-1)^2},
    \end{align}
    where $A'=12\eta_{0}[1+\eta_{0}(2\beta\omega-\mu/2)]^2\phi^2/(3\gamma\beta)+A$. In~\eqref{eq:BigTh2}, $(a)$ is obtained based on the induction hypothesis and the fact that $\hat{\mathbf w}^{(t_{0})}=\bar{\mathbf w}^{(t_{0})}$, $(b)$ is due to the fact that $\eta_t=\frac{\gamma}{t+\alpha}$, and $(c)$ is obtained assuming $\eta_t\leq\vartheta/\beta$.
    Since $\gamma > [3+8\big(1/\vartheta+(2\omega-\vartheta/2)\big)^2]/\mu$ and $\alpha \geq \max\{\beta\gamma/\vartheta,\beta\mu/2,3\}$, it can be verified that the following inequality holds \eqref{sub_t+1} holds by choosing 
    \begin{align} \label{eq:nu_final}
        \tilde{\nu} \geq \gamma^2\beta^2 (A'+\tau^2 B)/\Big[\mu\gamma-[3+8(1/\vartheta+(2\omega-\vartheta/2))^2]\Big],
    \end{align} 
    where $\tau\triangleq \max\{\tau_1,\cdots,\tau_{k} \}$, $\forall k$.
    Since $A'>A$, choosing the value of $\tilde{\nu}$ based on \eqref{eq:nu_final}, we see that \eqref{eq:nu_first} can be directly satisfied, which leads to \eqref{eq:secondpartTh2}.
    
    Finally, since $\mathbb E\left[F(\hat{\mathbf w}^{(t_k)})-F(\mathbf w^*)\right]  =\mathbb E\left[F(\bar{\mathbf w}^{(t_k)})-F(\mathbf w^*)\right],~\forall k=1,\cdots,K$, based on the result of \eqref{eq:secondpartTh2}, we show that
    \begin{align}
        &\mathbb E\left[F(\hat{\mathbf w}^{(t_k)})-F(\mathbf w^*)\right]   
        \leq \frac{\nu}{t+\alpha},~\forall k = 1,\cdots,K
    \end{align}
   and conclude the proof.  
\end{proof}
}
\fi

% \frank{Theorem 2: under construction}
\section{Proof of Theorem \ref{thm:subLin}} \label{app:subLin}
% \addFL{
% \frank{Statement of the Theorem 2 needs modified:}
\begin{theorem} \label{thm:subLin}
Define $Z_1\triangleq \frac{32\beta^2\gamma}{\mu}(\tau-1)\left(1+\frac{\tau}{\alpha-1}\right)^{2}\left(1+\frac{\tau-1}{\alpha-1}\right)^{6\beta\gamma}$, $ Z_2\triangleq
    \frac{1}{2}[\frac{\sigma^2}{\beta}+\frac{2\phi^2}{\beta}]
    +50\beta\gamma(\tau-1)\left(1+\frac{\tau-2}{\alpha+1}\right)
    \left(1+\frac{\tau-1}{\alpha-1}\right)^{6\beta\gamma}\left[\frac{\sigma^2}{\beta}+\frac{\phi^2}{\beta}+\frac{\delta^2}{\beta}\right]$. Also, assume $\gamma>1/\mu$, $\alpha\geq\max\{\beta\gamma[\frac{\vartheta}{4}-1+\sqrt{(1+\frac{\vartheta}{4})^2+2\omega}],\frac{\beta^2\gamma}{\mu}\}$ and $\omega< \frac{1}{\beta\gamma}\sqrt{\alpha\frac{\mu\gamma-1+\frac{1}{1+\alpha}}{Z_1}}\triangleq \omega_{\max}$. Upon using {\tt TT-HF} for ML model training under Assumptions \ref{beta},~\ref{assump:cons}, and~\ref{assump:SGD_noise}, if $\eta_t=\frac{\gamma}{t+\alpha}$ and $\epsilon^{(t)}=\eta_t\phi$, $\forall t$, we have: 
    % Using {\tt TT-HF} for ML model training, under Assumption \ref{beta}, if we set the step size as $\eta_t=\frac{\gamma}{t+\alpha}$, $\forall t$, and assuming that $\epsilon(t)=\eta_t\phi$, $\forall t$,
    % we have
    \begin{align} \label{eq:thm2_result-1-A}
        &\mathbb E\left[(F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*))\right]\leq\frac{\nu}{t+\alpha}, ~~\forall t,
    \end{align}
    where $\nu \triangleq Z_2 \max \left\{\frac{\beta^2\gamma^2}{\mu\gamma-1},
\frac{\alpha}{Z_1\left(\omega_{\max}^2-\omega^2\right)},\frac{\alpha}{Z_2}\left[F(\hat{\mathbf w}^{(0)})-F(\mathbf w^*)\right]\right\}$.
\end{theorem}
\begin{proof}



We carry out the proof by induction. We start by considering the first global aggregation, i.e., $k=1$. Note that the condition in~\eqref{eq:thm2_result-1-A} trivially holds at the beginning of this global aggregation $t=t_0=0$ since $
\nu\geq\alpha\left[F(\hat{\mathbf w}^{(0)})-F(\mathbf w^*)\right]$.
    Now, assume that
    \begin{align} \label{eq:thm2_result-1}
        &\mathbb E\left[F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)\right]  
        \leq \frac{\nu}{t_{k-1}+\alpha}
    \end{align}
for some $k\geq 1$. We prove that this implies 
\begin{align} \label{eq:thm2_result-1}
        &\mathbb E\left[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)\right]  
        \leq \frac{\nu}{t+\alpha},\ \forall t\in \mathcal{T}_k,
    \end{align}
    and as a result $\mathbb E\left[F(\hat{\mathbf w}^{(t_{k})})-F(\mathbf w^*)\right]  
        \leq \frac{\nu}{t_{k}+\alpha}$.
    % so that the theorem follows by induction over $k$.
    To prove~\eqref{eq:thm2_result-1}, we use induction over $t\in \{t_{k-1}+1,\dots,t_k\}$.
    Clearly, the condition holds for $t=t_{k-1}$ from the induction hypothesis.
    Now, we assume that it also holds for some $t\in \{t_{k-1},\dots,t_k-1\}$, and aim to show that it holds at $t+1$.
    
    From the result of Theorem~\ref{co1}, considering $\tilde{\epsilon}^{(t)}=\tilde{\eta}_t\tilde{\phi}$, we get
    \begin{align} \label{eq:thm1_temp}
        &\mathbb E\left[F(\hat{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
        \leq
        (1-\tilde{\mu}\tilde{\eta}_{t})\frac{\nu}{t+\alpha}
        +\frac{\tilde{\eta}_{t}\beta}{2}A^{(t)}
        +\frac{1}{2}[\tilde{\eta}_{t}^3\tilde{\phi}^2+\tilde{\eta}_{t}^2\tilde{\sigma}^2+\tilde{\eta}_{t+1}^2\tilde{\phi}^2].
    \end{align}
Using the induction hypothesis and the bound on $A^{(t)}$, we can further upper bound~\eqref{eq:thm1_temp} as
\begin{align} \label{eq:induction_main}
    &\mathbb E\left[F(\hat{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
    \leq
    \left(1-\tilde{\mu}\tilde{\eta}_{t}\right)\frac{\nu}{t+\alpha}
    +\frac{8\tilde{\eta}_t\omega^2}{\tilde{\mu}}[\Sigma_{+,t}]^2\frac{\nu}{t_{k-1}+\alpha}
    \nonumber \\&+\frac{25}{2}\tilde{\eta}_t[\Sigma_{+,t}]^2
    \left[\tilde{\sigma}^2+(\tilde{\epsilon}^{(0)})^2+\tilde{\delta}^2\right]   
    +\frac{1}{2}[\tilde{\eta}_{t}^3\tilde{\phi}^2+\tilde{\eta}_{t}^2\tilde{\sigma}^2+\tilde{\eta}_{t+1}^2\tilde{\phi}^2].
\end{align}
Since $\tilde{\eta}_{t+1}\leq \tilde{\eta}_t$, $\tilde{\eta}_t\leq \tilde{\eta}_0\leq\tilde{\mu}\leq 1$ and $\tilde{\epsilon}^{(0)}=\tilde{\eta}_0\tilde{\phi}\leq\tilde{\phi}$, we further upper bound~\eqref{eq:induction_main} as
\begin{align} \label{eq:thm1_Sig}
    &\mathbb E\left[F(\hat{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
    \leq
    \left(1-\tilde{\mu}\tilde{\eta}_{t}\right)\frac{\nu}{t+\alpha}
    +\frac{8\tilde{\eta}_t\omega^2}{\tilde{\mu}}\underbrace{[\Sigma_{+,t}]^2}_{(a)}\frac{\nu}{t_{k-1}+\alpha}
    \nonumber \\&
    +\frac{25}{2}\tilde{\eta}_t\underbrace{[\Sigma_{+,t}]^2}_{(b)}
\left[\tilde{\sigma}^2+\tilde{\phi}^2+\tilde{\delta}^2\right]    
    + \frac{\tilde{\eta}_t^2}{2}[\tilde{\sigma}^2+2\tilde{\phi}^2].
\end{align}
To get a tight upper bound for~\eqref{eq:thm1_Sig}, we bound the two instances of $[\Sigma_{+,t}]^2$ appearing in $(a)$ and $(b)$ differently. In particular, for $(a)$, we first use the fact that
\begin{align*}
    \lambda_+ =1-\tilde{\mu}/4+\sqrt{(1+\tilde{\mu}/4)^2+2\omega}\in[2,1+\sqrt{3}],
\end{align*}
which implies that
\begin{align}
    \Sigma_{+,t}
  =&\sum_{\ell=t_{k-1}}^{t-1}
  \left[\prod_{j=t_{k-1}}^{\ell-1}(1+\tilde{\eta}_j\lambda_{+})\right]
  \eta_\ell
  \left[\prod_{j=\ell+1}^{t-1}(1+\tilde{\eta}_j)\right]
  \nonumber \\&\leq
  \sum_{\ell=t_{k-1}}^{t-1}
  \left[\prod_{j=t_{k-1}}^{\ell-1}(1+\tilde{\eta}_j\lambda_{+})\right]
  \eta_\ell
  \left[\prod_{j=\ell+1}^{t-1}(1+\tilde{\eta}_j\lambda_{+})\right]
  \nonumber \\&
  \leq
  \left[\prod_{j=t_{k-1}}^{t-1}(1+\tilde{\eta}_j\lambda_{+})\right]
\sum_{\ell=t_{k-1}}^{t-1}\frac{\tilde{\eta}_\ell}{1+\tilde{\eta}_\ell\lambda_{+}}.
\end{align}
Also, with the choice of step size $\tilde{\eta}_\ell=\frac{\tilde{\gamma}}{\ell+\alpha}$, we get
\begin{align} \label{eq:Sigma_1}
  \Sigma_{+,t}
  \leq
  \tilde{\gamma}\underbrace{\left[\prod_{j=t_{k-1}}^{t-1}\left(1+\frac{\tilde{\gamma}\lambda_+}{j+\alpha}\right)\right]}_{(i)}
  \underbrace{\sum_{\ell=t_{k-1}}^{t-1}\frac{1}{\ell+\alpha+\tilde{\gamma}\lambda_+}}_{(ii)}.
\end{align}
To bound $(ii)$, since $\frac{1}{\ell+\alpha+\tilde{\gamma}\lambda_+}$ is a decreasing function with respect to $\ell$, we have
\begin{align}
    \sum_{\ell=t_{k-1}}^{t-1}\frac{1}{\ell+\alpha+\tilde{\gamma}\lambda_+}
    \leq
    \int_{t_{k-1}-1}^{t-1}\frac{1}{\ell+\alpha+\tilde{\gamma}\lambda_+}\mathrm d\ell
    =
    \ln\left(1+\frac{t-t_{k-1}}{t_{k-1}-1+\alpha+\tilde{\gamma}\lambda_+}\right),
\end{align}
where we used the fact that $\alpha>1-\tilde{\gamma}\lambda_+$ (implied by $\alpha>1$).

To bound $(i)$, we first rewrite it as follows: 
    \begin{align} \label{eq:(i)}
        \prod_{j=t_{k-1}}^{t-1}\left(1+\frac{\tilde{\gamma}\lambda_+}{j+\alpha}\right)
        =
        e^{\sum_{j=t_{k-1}}^{t-1}\ln\big(1+\frac{\tilde{\gamma}\lambda_+}{j+\alpha}\big)}
    \end{align}
To bound~\eqref{eq:(i)}, we use the fact that $\ln(1+\frac{\tilde{\gamma}\lambda_+}{j+\alpha})$ is a decreasing function with respect to $j$, and $\alpha >1$, to get
\begin{align} \label{eq:ln(i)}
    &\sum_{j=t_{k-1}}^{t-1}\ln(1+\frac{\tilde{\gamma}\lambda_+}{j+\alpha})
    \leq
    \int_{t_{k-1}-1}^{t-1}\ln(1+\frac{\tilde{\gamma}\lambda_+}{j+\alpha})\mathrm dj
    \nonumber \\&
    \leq
    \tilde{\gamma}\lambda_+\int_{t_{k-1}-1}^{t-1}\frac{1}{j+\alpha}\mathrm dj
    =
    \tilde{\gamma} \lambda_+\ln\left(1+\frac{t-t_{k-1}}{t_{k-1}-1+\alpha}\right).
\end{align}
Considering ~\eqref{eq:(i)} and~\eqref{eq:ln(i)} together, we  bound $(i)$ as follows:
    \begin{align}
        \prod_{j=t_{k-1}}^{t-1}\left(1+\frac{\tilde{\gamma}\lambda_+}{j+\alpha}\right)
        \leq
        \left(1+\frac{t-t_{k-1}}{t_{k-1}-1+\alpha}\right)^{\tilde{\gamma} \lambda_+}.
    \end{align}
    
    
    Using the results obtained for bounding $(i)$ and $(ii)$ back in~\eqref{eq:Sigma_1}, we get:
    \begin{align} \label{eq:Sigma1_bound}
        \Sigma_{+,t}
        \leq
        \tilde{\gamma}\ln\left(1+\frac{t-t_{k-1}}{t_{k-1}-1+\alpha+\tilde{\gamma}\lambda_+}\right)
        \left(1+\frac{t-t_{k-1}}{t_{k-1}-1+\alpha}\right)^{\tilde{\gamma} \lambda_+}.
    \end{align}
    Since $\ln(1+x)\leq\ln(1+x+2\sqrt{x})=\ln((1+\sqrt{x})^2)=2\ln(1+\sqrt{x})\leq 2\sqrt{x}$ for $x\geq 0$,
    we can further bound~\eqref{eq:Sigma1_bound} as follows:
    \begin{align} \label{eq:Sig}
        &\Sigma_{+,t}
        \leq
        2\tilde{\gamma}\sqrt{\frac{t-t_{k-1}}{t_{k-1}-1+\alpha+\tilde{\gamma}\lambda_+}}
        \left(1+\frac{t-t_{k-1}}{t_{k-1}+\alpha-1}\right)^{\tilde{\gamma}\lambda_+}
        \nonumber \\&
        \leq
        2\tilde{\gamma}\sqrt{\frac{t-t_{k-1}}{t_{k-1}+\alpha+1}}
        \left(1+\frac{t-t_{k-1}}{t_{k-1}+\alpha-1}\right)^{3\tilde{\gamma}},
    \end{align}
    where in the last inequality we used
     $2\leq\lambda_+ < 3$ and $\tilde{\gamma}\geq \frac{\tilde{\mu}}{\beta}\tilde{\gamma} >1$.
Taking the square from the both hand sides of~\eqref{eq:Sig} followed by multiplying the both hand sides with $\frac{[t+\alpha]^2}{\tilde{\mu}\tilde{\gamma}[t_{k-1}+\alpha]}$ gives us:
    \begin{align} \label{eq:sig_sqaured}
        &[{\Sigma}_{+,t}]^2\frac{[t+\alpha]^2}{\tilde{\mu}\tilde{\gamma}[t_{k-1}+\alpha]}
        \leq
        \frac{4\tilde{\gamma}}{\tilde{\mu}}\frac{[t-t_{k-1}][t+\alpha]^2}{[t_{k-1}+\alpha+1][t_{k-1}+\alpha]}
        \left(1+\frac{t-t_{k-1}}{t_{k-1}+\alpha-1}\right)^{6\tilde{\gamma}}
        \nonumber \\&
        \leq
        \frac{4\tilde{\gamma}}{\tilde{\mu}}\frac{[t-t_{k-1}][t+\alpha]^2}{[t_{k-1}+\alpha-1]^2}
        \frac{[t_{k-1}+\alpha-1]^2}{[t_{k-1}+\alpha+1][t_{k-1}+\alpha]}
        \left(1+\frac{\tau-1}{t_{k-1}+\alpha-1}\right)^{-2}
        \left(1+\frac{\tau-1}{t_{k-1}+\alpha-1}\right)^{6\tilde{\gamma}+2}
        \nonumber \\&
        \overset{(a)}{\leq}
        \frac{4\tilde{\gamma}}{\tilde{\mu}}\frac{[\tau-1][t_{k-1}+\tau-1+\alpha]^2}{[t_{k-1}+\alpha-1]^2}
        \left(\frac{t_{k-1}+\alpha+\tau-2}{t_{k-1}+\alpha-1}\right)^{-2}
        \frac{[t_{k-1}+\alpha-1]^2}{[t_{k-1}+\alpha+1][t_{k-1}+\alpha]}
        \left(1+\frac{\tau-1}{t_{k-1}+\alpha-1}\right)^{6\tilde{\gamma}+2}
        \nonumber \\&
        \leq
        \frac{4\tilde{\gamma}}{\tilde{\mu}}(\tau-1)\left(1+\frac{1}{\tau+t_{k-1}+\alpha-2}\right)^2
        \frac{[t_{k-1}+\alpha-1]^2}{[t_{k-1}+\alpha+1][t_{k-1}+\alpha]}
        \left(1+\frac{\tau-1}{t_{k-1}+\alpha-1}\right)^{6\tilde{\gamma}+2}\hspace{-6mm},\hspace{-1mm}
    \end{align}
    where $(a)$ comes from the fact that $t\leq t_{k-1}+\tau_k-1\leq t_{k-1}+\tau-1$. To bound~\eqref{eq:sig_sqaured}, we use the facts that
    \begin{align}
        1+\frac{1}{\tau+t_{k-1}+\alpha-2}
        \leq
        1+\frac{1}{\tau+\alpha-2},\ 1+\frac{\tau-1}{t_{k-1}+\alpha-1}\leq 1+\frac{\tau-1}{\alpha-1},
    \end{align}
    and
    \begin{align}
        \frac{[t_{k-1}+\alpha-1]^2}{[t_{k-1}+\alpha+1][t_{k-1}+\alpha]}\leq 1,
    \end{align}
    which yield
    \begin{align}
        [{\Sigma}_{+,t}]^2\frac{[t+\alpha]^2}{\tilde{\mu}\tilde{\gamma}[t_{k-1}+\alpha]}
        \leq
        \frac{4\tilde{\gamma}}{\tilde{\mu}}(\tau-1)\left(1+\frac{\tau}{\alpha-1}\right)^{2}
        \left(1+\frac{\tau-1}{\alpha-1}\right)^{6\tilde{\gamma}}.
    \end{align}
    Consequently, we have
    \begin{align} \label{eq:Sigma_1st}
        [{\Sigma}_{+,t}]^2
        \leq
        4(\tau-1)\left(1+\frac{\tau}{\alpha-1}\right)^{2}
        \left(1+\frac{\tau-1}{\alpha-1}\right)^{6\tilde{\gamma}}
        \tilde{\eta}_t^2[t_{k-1}+\alpha].
    \end{align}
    
On the other hand, we bound the second instance of $[{\Sigma}_{+,t}]^2$, i.e., $(b)$ in~\eqref{eq:thm1_Sig}, as follows:
\begin{align}
    [t+\alpha] [\Sigma_{+,t}]^2
    &\leq
    4\tilde{\gamma}^2\frac{[t-t_{k-1}][t+\alpha]}{t_{k-1}+\alpha+1}
    \left(1+\frac{t-t_{k-1}}{t_{k-1}+\alpha-1}\right)^{6\tilde{\gamma}}
    \nonumber \\&
    \leq
    4\tilde{\gamma}^2(\tau-1)\left(1+\frac{\tau-2}{t_{k-1}+\alpha+1}\right)
    \left(1+\frac{\tau-1}{t_{k-1}+\alpha-1}\right)^{6\tilde{\gamma}}
    \nonumber \\&
    \leq
    4\tilde{\gamma}^2(\tau-1)\left(1+\frac{\tau-2}{\alpha+1}\right)
    \left(1+\frac{\tau-1}{\alpha-1}\right)^{6\tilde{\gamma}},
\end{align}
which implies
\begin{align} \label{eq:Sigma_2nd}
    [\Sigma_{+,t}]^2
    \leq
    4\tilde{\gamma}(\tau-1)\left(1+\frac{\tau-2}{\alpha+1}\right)
    \left(1+\frac{\tau-1}{\alpha-1}\right)^{6\tilde{\gamma}}\tilde{\eta}_t.
\end{align}
Replacing~\eqref{eq:Sigma_1st} and~\eqref{eq:Sigma_2nd} into \eqref{eq:thm1_Sig}, we get
\begin{align} \label{eq:induce_form}
    \mathbb E[F(\hat{\mathbf w}^{(t+1)})-F(\mathbf w^*)]
    \leq
    \left(1-\tilde{\mu}\tilde{\eta}_t+Z_1\omega^2\tilde{\eta}_t^2 \right)\frac{\nu}{t+\alpha}
    +\tilde{\eta}_t^2Z_2,
\end{align}
where we have defined
\begin{align}
    Z_1\triangleq \frac{32\tilde{\gamma}}{\tilde{\mu}}(\tau-1)\left(1+\frac{\tau}{\alpha-1}\right)^{2}
    \left(1+\frac{\tau-1}{\alpha-1}\right)^{6\tilde{\gamma}},
\end{align}
and
\begin{align}
    Z_2\triangleq
    \frac{1}{2}[\tilde{\sigma}^2+2\tilde{\phi}^2]
    +50\tilde{\gamma}(\tau-1)\left(1+\frac{\tau-2}{\alpha+1}\right)
    \left(1+\frac{\tau-1}{\alpha-1}\right)^{6\tilde{\gamma}}\left[\tilde{\sigma}^2+\tilde{\phi}^2+\tilde{\delta}^2\right].  
\end{align}

Now, from~\eqref{eq:induce_form}, to complete the induction, we aim to show that 
\begin{align}\label{eq:lastBeforeInd}
    \mathbb E[F(\hat{\mathbf w}^{(t+1)})-F(\mathbf w^*)]
    \leq
    \left(1-\tilde{\mu}\tilde{\eta}_t+Z_1\omega^2\tilde{\eta}_t^2 \right)\frac{\nu}{t+\alpha}
    +\tilde{\eta}_t^2Z_2
    \leq
    \frac{\nu}{t+1+\alpha}.
\end{align}
We transform the condition in~\eqref{eq:lastBeforeInd} through the set of following algebraic steps to an inequality condition on a convex function:
\begin{align}\label{eq:longtrasform}
    &
     \left(-\frac{\tilde{\mu}}{\tilde{\eta}_t^2}+\frac{Z_1\omega^2}{\tilde{\eta}_t} \right)\frac{\nu}{t+\alpha}
    +\frac{Z_2}{\tilde{\eta_t}}
    +\frac{\nu}{t+\alpha}\frac{1}{\tilde{\eta_t}^3}
    \leq\frac{\nu}{t+1+\alpha}\frac{1}{\tilde{\eta_t}^3}
    \nonumber \\&
    \Rightarrow
     \left(-\frac{\tilde{\mu}}{\tilde{\eta}_t}+Z_1\omega^2 \right)\frac{\nu}{t+\alpha}\frac{1}{\tilde{\eta}_t}
    +\frac{Z_2}{\tilde{\eta_t}}
    +\left(\frac{\nu}{t+\alpha}-\frac{\nu}{t+1+\alpha}\right)\frac{1}{\tilde{\eta_t}^3}
    \leq0
    \nonumber \\&
    \Rightarrow
     \left(-\frac{\tilde{\mu}}{\tilde{\eta}_t}+Z_1\omega^2 \right)\frac{\nu}{\tilde{\gamma}}
    +\frac{Z_2}{\tilde{\eta_t}}
    +\left(\frac{\nu}{t+\alpha}-\frac{\nu}{t+1+\alpha}\right)\frac{(t+\alpha)^3}{\tilde{\gamma}^3}
    \leq0
    \nonumber \\&
    \Rightarrow
     \left(-\frac{\tilde{\mu}}{\tilde{\eta}_t}+Z_1\omega^2 \right)\frac{\nu}{\tilde{\gamma}}
    +\frac{Z_2}{\tilde{\eta_t}}
    +\frac{\nu}{(t+\alpha)(t+\alpha+1)}\frac{(t+\alpha)^3}{\tilde{\gamma}^3}
    \leq0
    \nonumber \\&
    \Rightarrow
     \left(-\frac{\tilde{\mu}}{\tilde{\eta}_t}+Z_1\omega^2 \right)\frac{\nu}{\tilde{\gamma}}
    +\frac{Z_2}{\tilde{\eta_t}}
    +\frac{\nu}{t+\alpha+1}\frac{(t+\alpha)^2}{\tilde{\gamma}^3}
    \leq0
    \nonumber \\&
    \Rightarrow
      \tilde{\gamma}^2\left(-\frac{\tilde{\mu}}{\tilde{\eta}_t}+Z_1\omega^2 \right)\nu
    +\frac{Z_2}{\tilde{\eta_t}} \tilde{\gamma}^3
    +\frac{(t+\alpha)^2}{t+\alpha+1}\nu
    \leq0
    \nonumber \\&
    \Rightarrow
      \tilde{\gamma}^2\left(-\frac{\tilde{\mu}}{\tilde{\eta}_t}+Z_1\omega^2 \right)\nu
    +\frac{Z_2}{\tilde{\eta_t}} \tilde{\gamma}^3
    +\left(\frac{(t+\alpha+1)(t+\alpha-1)}{t+\alpha+1}\nu+\frac{\nu}{t+\alpha+1}\right)
    \leq 0,
\end{align}
where the last condition in~\eqref{eq:longtrasform} can be written as:
\begin{align}\label{eq:finTransform}
    \tilde{\gamma}^2\left(-\frac{\tilde{\mu}}{\tilde{\eta}_t}+Z_1\omega^2\right)\nu
    +\frac{Z_2}{\tilde{\eta}_t}\tilde{\gamma}^3
    +\nu[t+\alpha-1]
    +\frac{\nu}{t+1+\alpha}
    \leq 0.
\end{align}
Since the above condition needs to be satisfied $\forall t\geq 0$ and the expression on the left hand  side of the inequality is a convex function with respect to $t$  ($1/\eta_t$ is linear in $t$ and $\frac{1}{t+1+\alpha}$ is convex),
 it is sufficient to satisfy this condition for $t\to\infty $ and $t=0$. To obtain these limits, we first express~\eqref{eq:finTransform} as follows:
 \begin{align}\label{eq:fin2}
    \tilde{\gamma}^2\left(-\frac{\tilde{\mu}}{\tilde{\gamma}}(t+\alpha)+Z_1\omega^2 \right)\nu
    +Z_2 \tilde{\gamma}^2(t+\alpha)
    +\nu[t+\alpha-1]
    +\frac{\nu}{t+1+\alpha}
    \leq 0.
 \end{align}
 Upon $t\to\infty$ considering the dominant terms yields
 \begin{align}\label{eq:condinf}
     &-\tilde{\gamma}\tilde{\mu}\nu t
    +Z_2 \tilde{\gamma}^2t
    +\nu t
    \leq0
    \nonumber \\&
    \Rightarrow
    \left[1-\tilde{\gamma}\tilde{\mu}\right]\nu t
    +Z_2 \tilde{\gamma}^2 t
    \leq 0.
 \end{align}
To satisfy~\eqref{eq:condinf}, the necessary condition is given by:
\begin{equation}
    \tilde{\mu}\tilde{\gamma}-1>0,
\end{equation}
 \begin{align} \label{eq:nu1}
     \nu \geq \frac{\tilde{\gamma}^2Z_2}{\tilde{\mu}\tilde{\gamma}-1}.
 \end{align}
 Also, upon $t\rightarrow 0$, from~\eqref{eq:fin2} we have
 \begin{align}
    &\left(-\tilde{\mu}\tilde{\gamma}\alpha+Z_1\omega^2\tilde{\gamma}^2 \right)\nu
    +Z_2 \tilde{\gamma}^2\alpha
    +\nu[\alpha-1]
    +\frac{\nu}{1+\alpha}\leq0
    \nonumber \\&
    \Rightarrow
    \nu\left(\alpha(\tilde{\mu}\tilde{\gamma}-1)+\frac{\alpha}{1+\alpha}-Z_1\omega^2\tilde{\gamma}^2\right)
    \geq
  \tilde{\gamma}^2 Z_2\alpha,
 \end{align}
which implies the following conditions
\begin{align} \label{eq:omega_cond}
    \omega
    <
    \frac{1}{\tilde{\gamma}}\sqrt{\alpha\frac{\tilde{\mu}\tilde{\gamma}-1+\frac{1}{1+\alpha}}{Z_1}},
\end{align}
% \nm{note that we can make this arbitrarily large by making $\alpha$ large for ANY tau.. in fact, $Z_1\to 32\gamma/\mu(\tau-1)$ for $\alpha\to\infty$}
and
\begin{align} \label{eq:nu2}
    \nu\geq\frac{Z_2\alpha}{Z_1\left(\omega_{\max}^2-\omega^2\right)}.
\end{align}
Combining~\eqref{eq:nu1} and~\eqref{eq:nu2}, when $\omega$ satisfies~\eqref{eq:omega_cond}
and
\begin{align}
    \nu \geq Z_2\max\{\frac{\beta^2\gamma^2}{\mu\gamma-1},
    \frac{\alpha}{Z_1\left(\omega_{\max}^2-\omega^2\right)}\},
\end{align}
completes the induction and thus the proof.

\end{proof}

% \begin{proof}
%     By induction, we first prove that 
%     \begin{equation}\label{eq:firstpartTh2}
%         \mathbb E\left[(F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*))\right]\leq\frac{\nu}{t+\alpha},~\forall t\in\mathcal T_1.
%     \end{equation}
%     Let $\nu\geq\alpha[F(\hat{\mathbf w}^{(0)})-F(\mathbf w^*)]$, the condition $\mathbb E\left[(F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*))\right]\leq\frac{\nu}{t+\alpha}$ for $t=0$ trivially holds. 
%     Assuming that this holds for all iterations before $t\in\mathcal T_1$, we aim to show that the results also holds for iteration $t+1\in\mathcal T_1$.
%     Using the result of Theorem \ref{co1}, for $t\in\mathcal T_1$, we get   
%     \begin{align}\label{eq:BigTh2}
%         &\mathbb E\left[F(\hat{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
%         \leq 
%         (1-\mu\eta_{t})\mathbb E\left[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)\right]
%         \nonumber \\&
%         +\eta_{t}^2\beta^2
%         \bigg[ 
%         \frac{8\omega^2 C}{\mu}\left(1+\frac{\tau}{\alpha-1}\right)^{6\gamma\beta}[F(\hat{\mathbf w}^{(0)})-F(\mathbf w^*)]
%         \nonumber \\&
%         +C\left(1+\frac{\tau}{\alpha-1}\right)^{6\gamma\beta}[\frac{150\sigma^2}{8\beta^2}+\frac{150(\eta_0\phi)^2}{8}+\frac{3\delta^2}{\beta^2}]
%         +\phi^2(\frac{\eta_{0}}{2}+\frac{1}{2\beta})+\frac{\sigma^2}{2\beta}
%         \bigg]
%         \nonumber \\&
%         \overset{(a)}{\leq}
%         (1-\mu\eta_{t})\frac{\nu}{t+\alpha}
%         % \nonumber \\&
%         +\eta_{t}^2\beta^2
%         \bigg[ 
%         \frac{8\omega^2 C}{\mu\alpha}\left(1+\frac{\tau}{\alpha-1}\right)^{6\gamma\beta}\nu
%         \nonumber \\&
%         +C\left(1+\frac{\tau}{\alpha-1}\right)^{6\gamma\beta}[\frac{150\sigma^2}{8\beta^2}+\frac{150(\eta_0\phi)^2}{8}+\frac{3\delta^2}{\beta^2}]
%         +\phi^2(\frac{\eta_{0}}{2}+\frac{1}{2\beta})+\frac{\sigma^2}{2\beta}
%         \bigg]
%         \nonumber \\&
%         \overset{(b)}{\leq}
%         \frac{t+\alpha-\mu\gamma}{(t+\alpha)^2}\nu
%         % \nonumber \\&
%         +\frac{\gamma^2\beta^2}{(t+\alpha)^2}
%         \bigg[ 
%         \frac{8\omega^2 C}{\mu\alpha}\left(1+\frac{\tau}{\alpha-1}\right)^{6\gamma\beta}\nu
%         \nonumber \\&
%         +C\left(1+\frac{\tau}{\alpha-1}\right)^{6\gamma\beta}[\frac{150\sigma^2}{8\beta^2}+\frac{150(\eta_0\phi)^2}{8}+\frac{3\delta^2}{\beta^2}]
%         +\phi^2(\frac{\eta_{0}}{2}+\frac{1}{2\beta})+\frac{\sigma^2}{2\beta}
%         \bigg]
%         \nonumber \\&
%         \overset{(c)}{\leq}
%         \frac{t+\alpha-1}{(t+\alpha)^2}\nu-\frac{\mu\gamma-\Big[1+\frac{8\gamma^2\beta^2\omega^2 C}{\mu\alpha}\left(1+\frac{\tau}{\alpha-1}\right)^{6\gamma\beta}\Big]}{(t+\alpha)^2}\nu
%         \nonumber \\&
%         +\frac{\gamma^2\beta^2}{(t+\alpha)^2}
%         \bigg[ 
%         C\left(1+\frac{\tau}{\alpha-1}\right)^{6\gamma\beta}[\frac{150\sigma^2}{8\beta^2}+\frac{150(\eta_0\phi)^2}{8}+\frac{3\delta^2}{\beta^2}]
%         +\phi^2(\frac{\eta_{0}}{2}+\frac{1}{2\beta})+\frac{\sigma^2}{2\beta}
%         \bigg]
%         \nonumber \\&
%         \leq
%         \frac{t+\alpha-1}{(t+\alpha)^2}\nu\underbrace{-\underbrace{\frac{\mu\gamma-\Big[1+\frac{8\gamma^2\beta^2\omega^2 C}{\mu\alpha}\left(1+\frac{\tau}{\alpha-1}\right)^{6\gamma\beta}\Big]}{(t+\alpha)^2}}_{(i)}\nu
%         % \nonumber \\&
%         +\frac{\gamma^2\beta^2 B}{(t+\alpha)^2}}_{(ii)}.
%     \end{align}
%     In~\eqref{eq:BigTh2}, $(a)$ is obtained based on the induction hypothesis, $(b)$ is due to the fact that $\eta_t=\frac{\gamma}{t+\alpha}$, and $(c)$ is obtained assuming $\eta_{t+1}\leq\eta_t\leq\vartheta/\beta$. 
    
%     To make term (i) in~\eqref{eq:BigTh2} positive, we obtain for $\gamma>\frac{1}{\mu}$, the following range for $\omega$:
%      \begin{align} \label{eq:range_gam}
%         \mu\gamma-\Big[1+\frac{8\gamma^2\beta^2 \omega^2 C}{\mu\alpha}(1+\frac{\tau}{\alpha-1})^{6\gamma\beta}\Big]>0,
%     \end{align}
%     or equivalently
%     \begin{align}
%         \omega\leq\sqrt{\frac{(\mu\gamma-1)\mu\alpha}{8\gamma^2\beta^2 C(1+\frac{\tau}{\alpha-1})^{6\gamma\beta}}}.
%     \end{align}
%     %   To satisfy the initial condition on the step size $\eta_0\leq\min\{\vartheta/\beta,2/\mu\}$, the range of $\alpha$ is subsequently given by
%     % \begin{align} \label{eq:range_alpha}
%     %     \alpha \geq \max\{\beta\gamma/\vartheta,\beta\mu/2,3\}.
%     % \end{align}
%     Assuming term (ii) in~\eqref{eq:BigTh2} is negative, it can be verified that the following inequality holds
%     \begin{align} \label{sub_t+1}
%         &\mathbb E\left[F(\hat{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
%         \leq
%         \frac{t+\alpha-1}{(t+\alpha)^2}\nu
%         \overset{(a)}{\leq}
%         \frac{\nu}{t+\alpha+1}
%     \end{align}
%     Note that $(a)$ results from the fact that $t+\alpha-1\geq0$ and $(t+\alpha)^2>(t+\alpha+1)(t+\alpha-1)$. 
%     To make term (ii) in~\eqref{eq:BigTh2} negative, the following range for $\nu$ is obtained:
%     \begin{align} \label{eq:nu_first}
%         \nu \geq \frac{\gamma^2\beta^2 B}{\mu\gamma-[1+\frac{8\gamma^2\beta^2 \omega^2 C}{\mu\alpha}(1+\frac{\tau}{\alpha-1})^{6\gamma\beta}]}.
%     \end{align}
%     Since the value of $\mathbb E\left[F(\hat{\mathbf w}^{(t_{k})}-F(\mathbf w^*)\right]$ does not change after synchronization, \eqref{sub_t+1} implies that $\mathbb E\left[F(\hat{\mathbf w}^{(t_{1})})-F(\mathbf w^*)\right]\leq\frac{\nu}{t_{1}+\alpha}$. Applying this result to Theorem \ref{co1}, we can sequentially prove by induction that when $\gamma$ is in the range of \eqref{eq:range_gam} and $\nu$ satisfies \eqref{eq:nu_first},
%     the following relationship
%     \begin{equation} \label{eq:nu_k}
%         \mathbb E\left[(F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*))\right]\leq\frac{\nu}{t+\alpha},~\forall t\in\mathcal T_k
%     \end{equation} holds for all $k=1,\cdots,K$, which is equivalent to 
    
%     % Finally, from \eqref{eq:nu_k}, if we choose some value of $\nu$ such that 
%     % \begin{align}
%     %     \nu \geq \gamma^2\beta^2 (A+\tau^2 B)/\Big[\mu\gamma-[1+12C^2(1/\vartheta+(2\omega-\vartheta/2))^2]\Big].
%     % \end{align}
%     % where $\tau\triangleq \max\{\tau_1,\cdots,\tau_{k} \}$, $\forall k$, we can prove that
%     \begin{equation}
%         \mathbb E\left[(F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*))\right]\leq\frac{\nu}{t+\alpha},~\forall t.
%     \end{equation}
%   This completes the proof.
% \end{proof}


% {\color{red}
% From Theorem \ref{co1}:
% \begin{align*} 
%       &\mathbb E\left[F(\hat{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
%         \leq 
%         (1-\mu\eta_{t})\mathbb E\left[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)\right]
%         % +\beta\eta_{t}^2\phi^2
%         \nonumber \\&
%         +\eta_{t}^2\beta^2
%         \bigg[ 
%          12C^2(t_{k-1}+\alpha-1)[1+\eta_{0}(2\beta\omega-\mu/2)]^2/(\mu\gamma^2) [F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]\\&
%         +6C^2\eta_0[1+\eta_{0}(2\beta\omega-\mu/2)]^2\tau_k^2(\beta\vartheta+\sigma)^2
%         +3C^2\eta_{0}(\sqrt{2}\beta\phi\eta_{0}+\sigma+\sqrt{2}\delta)^2
%         +\phi^2(\frac{1}{2\beta}+\eta_{0}/2)+\frac{\sigma^2}{2\beta}
%         \bigg].
% \end{align*}
% Note that $C=\frac{\alpha}{\alpha-2}$ and $\alpha\geq3$. Let $a/\beta=12C^2[1+\eta_{0}(2\beta\omega-\mu/2)]^2/\mu$ and $b=6C^2\eta_0[1+\eta_{0}(2\beta\omega-\mu/2)]^2\tau_1^2(\beta\vartheta+\sigma)^2+3C^2\eta_{0}(\sqrt{2}\beta\phi\eta_{0}+\sigma+\sqrt{2}\delta)^2+\phi^2(\frac{1}{2\beta}+\eta_{0}/2)+\frac{\sigma^2}{2\beta}\bigg]$, 
% when $k=1$ and $t=1$, we have
% \begin{align}
%     &\mathbb E\left[F(\hat{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
%     \nonumber \\&
%         \leq 
%         (1-\mu\eta_{t})\mathbb E\left[F(\hat{\mathbf w}^{(t)})-F(\mathbf w^*)\right]
%         +\eta_{t}^2\beta^2
%         [ a(\alpha-1)/(\beta\gamma^2) [F(\hat{\mathbf w}^{(0)})-F(\mathbf w^*)]+b].
% \end{align}
% By induction, we want to show that 
% \begin{align}
%         &(1-\mu\eta_{1})\frac{\nu}{1+\alpha}
%         +\eta_{1}^2\beta^2
%         \bigg[ 
%          \frac{a}{\beta\gamma^2} \nu+b
%         \bigg]
%         \leq \frac{\nu}{2+\alpha}
%         \nonumber \\&
%         \Rightarrow 
%         (1-\frac{\mu\gamma}{1+\alpha})\frac{\nu}{1+\alpha}
%         +\frac{\gamma^2\beta^2}{(1+\alpha)^2}
%         \bigg[ 
%         a\nu/(\beta\gamma^2)+b
%         \bigg]
%         \leq \frac{\nu}{2+\alpha}
%         \nonumber \\&
%         \Rightarrow 
%         \frac{\alpha}{(1+\alpha)^2}\nu
%         \underbrace{-\underbrace{\frac{\mu\gamma-\Big[1+\beta a\Big]}{(1+\alpha)^2}\nu}_{(a)} 
%         +\frac{\gamma^2\beta^2}{(1+\alpha)^2}b}_{(b)}
%         \leq \frac{\nu}{2+\alpha}
% \end{align}
% To make $(a)$ positive, we need $\gamma>[1+\beta a]/\mu$ and to make $(b)$ non-positive, we further need $\nu\geq \gamma^2\beta^2b/\Big[\mu\gamma-[1+\beta a]\Big]$, then we can show that 
% \begin{align}
%     \frac{\alpha}{(1+\alpha)^2}\nu
%     \leq \frac{\alpha}{\alpha(\alpha+2)}
%         \leq \frac{\nu}{2+\alpha},
% \end{align} since $(1+\alpha)^2\geq \alpha(\alpha+2)$.
% }
\iffalse
\nm{New proof of Thm 2}
{\color{red}
\section{Proof of Theorem \ref{thm:subLin}} \label{app:subLin}
\begin{theorem} \label{thm:subLin}
Define $A=3\eta_{0}(\sqrt{2}\beta\phi\eta_{0}+\sigma+\sqrt{2}\delta)^2
+\phi^2\eta_{0}/2+\frac{\sigma^2}{2\beta}$, $B= 6\eta_0[1+\eta_{0}(2\beta\omega-\mu/2)]^2(\beta\vartheta+\sigma)^2$. 
% and $\tau\triangleq \max\{\tau_1,\cdots,\tau_{k} \}$, $\forall k$
Also, let $\gamma>[5+12\big(1/\vartheta+(2\omega-\vartheta/2)\big)^2]/\mu$, $\alpha\geq\max\{\beta\gamma/\vartheta,5\}$, and
    $2/\mu\leq\gamma\leq\vartheta/\beta\alpha$. Then, using {\tt TT-HF} for ML model training under Assumption \ref{beta}, by choosing $\eta_t=\frac{\gamma}{t+\alpha}$, $\epsilon_c(t)=\eta_t\phi_c$,  where $\sum_d\varrho_d\phi_d\leq\phi$ for some $\phi>0$, $\forall t$, we have: 
    \begin{align} \label{eq:thm2_result-1}
        &\mathbb E\left[F(\hat{\mathbf w}^{(t_k)})-F(\mathbf w^*)\right]  
        \leq \frac{\nu}{zt_k+\alpha},~\forall k = 0,\cdots,K,
    \end{align}
    \nm{conditions to be determined in the proof; to start with, $z>0$, $\nu>0$, $\alpha>0$. Conditions required:}
    \begin{equation}\label{eq:nuNewTh2}
        \nu\geq \left(\alpha\left[F(\hat{\mathbf w}^{(0)})-F(\mathbf w^*)\right],  \right)
    \end{equation}
\end{theorem}
\begin{proof}
We carry out the proof by induction.
First, note that the condition in~\eqref{eq:thm2_result-1} holds at $k=0$ since $t_0=0$ and $
\nu\geq\alpha\left[F(\hat{\mathbf w}^{(0)})-F(\mathbf w^*)\right]$.
    Now, assume the condition holds for $k\geq 1$. We prove that the condition in~\eqref{eq:thm2_result-1} also holds for $k+1$. Consider the $k$th synchronization period $t\in\mathcal T_k$, we first prove by induction over $t$ that
    \begin{equation}\label{eq:firstpartTh2}
        \mathbb E\left[(F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*))\right]\leq\frac{t_{k-1}+\alpha}{zt_{k-1}+\alpha}\frac{\nu}{t+\alpha},~\forall t\in\mathcal T_k,
    \end{equation}
    where $\nu$ is given by~\eqref{eq:nuNewTh2}.
    First, note that this condition is satisfied for $t=t_{k-1}$ from the induction hypothesis, since
    $\bar{\mathbf w}^{(t_{k-1})}=\hat{\mathbf w}^{(t_{k-1})}$ after global synchronization.
    Now, assume that the condition holds for some $t$, where $t_{k-1}\leq t<t_{k}$. We show that it implies the condition holds for $t+1$ as well.
    Using the result of Theorem \ref{co1}, we obtain
    \begin{align}\label{eq:BigTh2}
        &\mathbb E\left[F(\bar{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
        \leq 
         (1-\mu\eta_{t})\mathbb E\left[(F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*))\right] 
        \nonumber \\&
        +\eta_{t-2}^2\beta^2
        \bigg[ 
         12(t_{k-1}+\alpha-1)[1+\eta_{0}(2\beta\omega-\mu/2)]^2/\mu\gamma^2 [F(\hat{\mathbf w}^{(t_{k-1})})-F(\mathbf w^*)]\\&
        +6\eta_0[1+\eta_{0}(2\beta\omega-\mu/2)]^2\tau_k^2(\beta\vartheta+\sigma)^2
        +3\eta_{0}(\sqrt{2}\beta\phi\eta_{0}+\sigma+\sqrt{2}\delta)^2
        +\phi^2\eta_{0}/2+\frac{\sigma^2}{2\beta}
        \bigg]
        \nonumber \\&
        \overset{(a)}{\leq}
         (1-\mu\eta_{t})\frac{t_{k-1}+\alpha}{zt_{k-1}+\alpha}\frac{\nu}{t+\alpha}
        \nonumber \\&
        +\eta_{t-2}^2\beta^2
        \bigg[ 
         12[1+\eta_{0}(2\beta\omega-\mu/2)]^2/\mu\gamma^2 \frac{t_{k-1}+\alpha}{zt_{k-1}+\alpha}\nu\\&
        +6\eta_0[1+\eta_{0}(2\beta\omega-\mu/2)]^2\tau_k^2(\beta\vartheta+\sigma)^2
        +3\eta_{0}(\sqrt{2}\beta\phi\eta_{0}+\sigma+\sqrt{2}\delta)^2
        +\phi^2\eta_{0}/2+\frac{\sigma^2}{2\beta}
        \bigg]
        \nonumber \\&
        \overset{(b)}{\leq}
        \frac{t+\alpha-\mu\gamma}{(t+\alpha)^2}\frac{t_{k-1}+\alpha}{zt_{k-1}+\alpha}\nu
        % \nonumber \\&
        +\frac{\gamma^2\beta^2}{(t+\alpha-2)^2}
        \bigg[ 
         12[1+\eta_{0}(2\beta\omega-\mu/2)]^2/\mu\gamma^2 \frac{t_{k-1}+\alpha}{zt_{k-1}+\alpha}\nu\\&
        +6\eta_0[1+\eta_{0}(2\beta\omega-\mu/2)]^2\tau_k^2(\beta\vartheta+\sigma)^2
        +3\eta_{0}(\sqrt{2}\beta\phi\eta_{0}+\sigma+\sqrt{2}\delta)^2
        +\phi^2\eta_{0}/2+\frac{\sigma^2}{2\beta}
        \bigg]
        \nonumber \\&
        \overset{(c)}{\leq}
        \frac{t+\alpha-5}{(t+\alpha-2)^2}\frac{t_{k-1}+\alpha}{zt_{k-1}+\alpha}\nu-\frac{\mu\gamma-\Big[5+12[\beta+\vartheta(2\beta\omega-\mu/2)]^2/\mu\Big]}{(t+\alpha-2)^2}\frac{t_{k-1}+\alpha}{zt_{k-1}+\alpha}\nu
        \nonumber \\&
        +\frac{\gamma^2\beta^2}{(t+\alpha-2)^2}
        \bigg[
        6\eta_0[1+\eta_{0}(2\beta\omega-\mu/2)]^2\tau_k^2(\beta\vartheta+\sigma)^2
        +3\eta_{0}(\sqrt{2}\beta\phi\eta_{0}+\sigma+\sqrt{2}\delta)^2
        +\phi^2\eta_{0}/2+\frac{\sigma^2}{2\beta}
        \bigg]
        \nonumber \\&
        \leq
        \frac{t+\alpha-5}{(t+\alpha-2)^2}\frac{t_{k-1}+\alpha}{zt_{k-1}+\alpha}\nu\underbrace{-\underbrace{\frac{\mu\gamma-\Big[5+12[1/\vartheta+(2\omega-\vartheta/2)]^2\Big]}{(t+\alpha-2)^2}}_{(i)}\frac{t_{k-1}+\alpha}{zt_{k-1}+\alpha}\nu
        % \nonumber \\&
        +\frac{\gamma^2\beta^2 (A+\tau_k^2B)}{(t+\alpha-2)^2}}_{(ii)}.
    \end{align}
    In~\eqref{eq:BigTh2}, $(a)$ is obtained based on the induction hypothesis and the fact that $\hat{\mathbf w}^{(t_{k-1})}=\bar{\mathbf w}^{(t_{k-1})}$, $(b)$ is due to the fact that $\eta_t=\frac{\gamma}{t+\alpha}$, and $(c)$ is obtained assuming $\eta_0\leq\vartheta/\beta$. 
    
    To make term (i) in~\eqref{eq:BigTh2} positive, we obtain the following range for $\gamma$:
     \begin{align} \label{eq:range_gam}
        \gamma > [5+12\big(1/\vartheta+(2\omega-\vartheta/2)\big)^2]/\mu.
    \end{align}
      To satisfy the initial condition on the step size $\eta_0\leq\vartheta/\beta$, the range of $\alpha$ is subsequently given by
    \begin{align} \label{eq:range_alpha}
        \alpha \geq \beta\gamma/\vartheta.
    \end{align}
     Assuming term (ii) in~\eqref{eq:BigTh2} is negative, it can be verified that the following inequality holds
    \begin{align} \label{sub_t+1}
        &\mathbb E\left[F(\bar{\mathbf w}^{(t+1)})-F(\mathbf w^*)\right]
        \leq
        \frac{t+\alpha-5}{(t+\alpha-2)^2}\frac{t_{k-1}+\alpha}{zt_{k-1}+\alpha}\nu
        \overset{(a)}{\leq}
        \frac{1}{t+\alpha+1}\frac{t_{k-1}+\alpha}{zt_{k-1}+\alpha}\nu.
    \end{align}
    Note that $(a)$ results from the fact that $(t+\alpha-2)^2>(t+\alpha+1)(t+\alpha-5)$, and assuming that $\alpha\geq 5$.
    % \nm{arent these tow cases equivalent? Dont have both, it is quite confusing..}
    % \textbf{Case 1:}  
    To make term (ii) in~\eqref{eq:BigTh2} positive, the following range for $\nu$ is obtained:
    \begin{align} \label{eq:nu_first}
        \nu \geq \frac{\gamma^2\beta^2 (A+\tau^2 B)\frac{zt_{k-1}+\alpha}{t_{k-1}+\alpha}}{\mu\gamma-[5+12(1/\vartheta+(2\omega-\vartheta/2))^2]},
    \end{align}
    where $\tau\triangleq \max\{\tau_1,\cdots,\tau_{k} \}$, $\forall k$. This completes the proof of~\eqref{eq:firstpartTh2}.
  
    Let $\widetilde{\bar{\mathbf w}^{(t_k)}}$ denote the global average of local models at $t_{k}$ before synchronization. By $\beta$-smoothness of $F(\cdot)$, we have
\begin{align} \label{39}
    &F(\hat{\mathbf w}^{(t_k)})-F(\mathbf w^*) 
    \leq F(\widetilde{\bar{\mathbf w}^{(t_k)}})-F(\mathbf w^*)
    +\nabla F(\widetilde{\bar{\mathbf w}^{(t_k)}})^\top\Big(\hat{\mathbf w}^{(t_k)}-\widetilde{\bar{\mathbf w}^{(t_k)}}\Big)+\frac{\beta}{2}\Vert\hat{\mathbf w}^{(t_k)}-\widetilde{\bar{\mathbf w}^{(t_k)}}\Vert^2
    \nonumber \\&
    \leq F(\widetilde{\bar{\mathbf w}^{(t_k)}})-F(\mathbf w^*)+\nabla F(\widetilde{\bar{\mathbf w}^{(t_k)}})^\top\sum\limits_{c=1}^N\varrho_c^{(k)} e_{s_c^{(k)}}^{{(t_k)}}
    +\frac{\beta}{2}\sum\limits_{c=1}^N\varrho_c^{(k)}\Vert e_{s_c^{(k)}}^{{(t_k)}}\Vert^2.
\end{align}
Taking the expectation with respect to the device sampling from both hand sides of \eqref{39}, since the sampling is conducted uniformly at random, we obtain
\begin{align} 
    &\mathbb E_t\left[F(\hat{\mathbf w}^{(t_k)})-F(\mathbf w^*)\right]  
    \nonumber \\&
    \leq F(\widetilde{\bar{\mathbf w}^{(t_k)}})-F(\mathbf w^*)+\nabla F(\widetilde{\bar{\mathbf w}^{(t_k)}})^\top\sum\limits_{c=1}^N\varrho_c^{(k)} \underbrace{\mathbb    E_t\left[e_{s_c^{(k)}}^{{(t_k)}}\right]}_{=0}
    +\frac{\beta}{2}\sum\limits_{c=1}^N\varrho_c^{(k)}\mathbb E_t\left[\Vert e_{s_c^{(k)}}^{{(t_k)}}\Vert^2\right].
\end{align}
Taking the total expectation from both hand sides of the above inequality yields:
\begin{align} 
    &\mathbb E\left[F(\hat{\mathbf w}^{(t_k)})-F(\mathbf w^*)\right]  
    \leq \mathbb E\left[F(\widetilde{\bar{\mathbf w}^{(t_k)}})-F(\mathbf w^*)\right]
    +\frac{\beta}{2}\eta_{t_k}^2\phi^2,
\end{align}
and thus
\begin{align} \label{eq:sync_condition}
   \hspace{-6mm}\mathbb E\left[F(\hat{\mathbf w}^{(t_k)})-F(\mathbf w^*)\right]   \leq \frac{t_{k-1}+\alpha}{zt_{k-1}+\alpha}\frac{\nu}{t_k+\alpha}
    +\frac{\beta}{2}\eta_{t_k}^2\phi^2
    % \overset{(a)}{\leq}
    % \frac{\nu}{z(\tau_k+\alpha)}
    % +\frac{\beta}{2}\eta_{t_k}^2\phi^2
    \overset{(b)}{\leq} \frac{\nu}{z t_k+\alpha}
    ,\hspace{-4mm}
\end{align}
where in $(a)$ we used the fact that $\frac{t_{k-1}+\alpha}{zt_{k-1}+\alpha}$ is an increasing function with respect to $t_{k-1}$, when $z> 1$, and thus $\max\limits_{t_{k-1}\in \mathbb Z^+}\left[\frac{t_{k-1}+\alpha}{zt_{k-1}+\alpha}\right] \leq {1/z}$.
To obtain $(b)$, we assumed
\begin{equation}
    \nu\alpha[1-z]
+\frac{\beta\gamma^2\phi^2}{2\alpha^2}[z \tau_k+\alpha]z[\tau_k+\alpha]
    \leq0
\end{equation}
or equivalently wrt $\nu$:
\begin{align}
    \nu \geq \frac{\beta\gamma^2\phi^2}{2\alpha^3(z-1)}[z \tau_k+\alpha]z[\tau_k+\alpha]
\end{align}

% $\frac{2}{\beta\gamma^2\phi^2}\nu\alpha(1-z) \leq - 1$, which implies $\nu \geq \frac{\beta\gamma^2\phi^2}{2\alpha(z-1)}$, [this will not impose an extra condtiion when $z\geq 3/2$. 


% or equivalently wrt $z$:
% \begin{equation}
%     \nu\alpha[1-z]
% +\frac{\beta\gamma^2\phi^2}{2\alpha^2}[z^2\tau_k^2(1+\alpha)+\alpha z\tau_k+\alpha^2 z]
%     \leq0
% \end{equation}

% $(a)$ is obtained from~\eqref{eq:firstpartTh2} and $(b)$ is obtained due to the fact that $\eta_t=\frac{\gamma}{t+\alpha}\leq\vartheta/\beta$. 
    
    Finally, since $\mathbb E\left[F(\hat{\mathbf w}^{(t_k)})-F(\mathbf w^*)\right]  =\mathbb E\left[F(\bar{\mathbf w}^{(t_k)})-F(\mathbf w^*)\right],~\forall k=1,\cdots,K$, based on the result of \eqref{eq:firstpartTh2}, we show that
    \begin{align}
        &\mathbb E\left[F(\hat{\mathbf w}^{(t_k)})-F(\mathbf w^*)\right]  
        \leq \frac{\nu}{zt_k+\alpha},~\forall k = 0,\cdots,K
    \end{align}
   and conclude the proof.  
   \addFL{
   or equivalently wrt $\tau$:
\begin{equation}
    \nu\alpha[1-z]
+\frac{\beta\gamma^2\phi^2}{2\alpha^2}[z(z\tau_k^2+\alpha(1+z)\tau_k+\alpha^2)]
    \leq0
\end{equation}
this implies $a=\frac{\beta\gamma^2\phi^2z^2}{2\alpha^2}$, $b=\frac{\beta\gamma^2\phi^2\alpha(1+z)}{2\alpha^2}$, $c=\frac{\beta\gamma^2\phi^2}{2\alpha^2}\alpha^2+\nu\alpha[1-z]$
\begin{align}
    & \frac{-\alpha(1+z)- \sqrt{\alpha^2(1+z)^2-4z^2[\alpha^2+\frac{2\alpha^2}{\beta\gamma^2\phi^2}\nu\alpha(1-z)}]}{2z^2} \leq \tau_k \nonumber \\ &\leq \frac{-\alpha(1+z)+ \sqrt{\alpha^2(1+z)^2-4z^2[\alpha^2+\frac{2\alpha^2}{\beta\gamma^2\phi^2}\nu\alpha(1-z)}]}{2z^2}
\end{align}
where the lower-bound is negative for $z> 1$, which implies: 
\begin{equation} \label{eq:cond_tau}
    1 \leq \tau_k \leq \frac{-\alpha(1+z)+ \sqrt{\alpha^2(1+z)^2+4z^2[\alpha^2+\frac{2\alpha^2}{\beta\gamma^2\phi^2}\nu\alpha(z-1)}]}{2z^2}.
\end{equation}
From \eqref{eq:nu_first}, we obtain the necessary condition on 
\begin{align} \label{eq:nu_nec}
    \nu \geq \frac{\gamma^2\beta^2\phi^2 z}{\mu\gamma}.
\end{align}
Note that $z>1$ and $z$ satisfying the following condition:
\begin{align} \label{eq:tau_nec}
     1 \leq \frac{-\alpha(1+z)+ \sqrt{\alpha^2(1+z)^2+4z^2[\alpha^2+\frac{2\alpha^2}{\beta\gamma^2\phi^2}\frac{\gamma^2\beta^2\phi^2 z}{\mu\gamma}\alpha(z-1)}]}{2z^2}.
\end{align}
From \eqref{eq:cond_tau}, we see that larger $z$ provides larger upper bound on $\tau_k$. However, from~\eqref{eq:nu_first}, larger $z$ requires larger $\nu$, to be continued....] ensures the feasibility of \eqref{eq:sync_condition} via ensuring that the term in the right hand side of \eqref{eq:cond_tau} is strictly positive when we replace the lower bound of $\nu$ with \eqref{eq:nu_nec}.
}
\end{proof}
}
%%%%%%%%%%%%%%%%%%%%%
\iffalse
\begin{theorem}
    Under Assumption \ref{beta} and Algorithm \ref{GT}, for $\eta_k\leq\kappa/\beta$, when 
    \begin{align*}
        &\frac{\eta_k\beta^2}{2}\left[\frac{(1+\mu\eta_k)^{\tau_k}\lambda_1^{2\tau_k}-1}{(1-\mu\eta_k)\lambda_1^2-1}-\frac{1-(1-\mu\eta_k)^{\tau_k}}{\mu\eta_k}\right]\{153/16\epsilon^2(k)+81/16\frac{\sigma^2}{\beta^2}+\frac{\delta^2}{\beta^2}\}
        \nonumber \\&
        +\frac{1-(1-\mu\eta_k)^{\tau_k}}{2}\kappa[\eta_k\sigma^2+\beta\epsilon^2(k)]
        +\frac{\beta}{2}\epsilon^2(k)
        \nonumber \\&
        \leq \frac{\mu}{2\beta^2}\left(1-\vartheta-\Big((1-\mu\eta_k)^{\tau_k}+16\eta_k\omega^2\beta/\kappa\left[\frac{(1-\mu\eta_k)^{\tau_k}\lambda_1^{2\tau_k}-1}{(1-\mu\eta_k)\lambda_1^2-1}-\frac{1-(1-\mu\eta_k)^{\tau_k}}{\mu\eta_k}\right]\Big)\right)\Vert\nabla F(\hat{\mathbf w}(k))\Vert^2,
    \end{align*}
    where $0<\vartheta\leq 1-\Big((1-\mu\eta_k)^{\tau_k}+16\eta_k\omega^2\beta/\kappa\left[\frac{(1-\mu\eta_k)^{\tau_k}\lambda_1^{2\tau_k}-1}{(1-\mu\eta_k)\lambda_1^2-1}-\frac{1-(1-\mu\eta_k)^{\tau_k}}{\mu\eta_k}\right]\Big)$ holds, we have
    \begin{align*}
        &\mathbb E\left[F(\hat{\mathbf w}(t_k))-F(\mathbf w^*)\right] 
        \leq  
        \left(1-\vartheta\right)[ F(\hat{\mathbf w}(t_{k-1}))-F(\mathbf w^*)] 
    \end{align*}
\end{theorem}
\begin{proof}
    From \eqref{32}, we have
    \begin{align}
        &\mathbb E\left[F(\hat{\mathbf w}(t_k))-F(\mathbf w^*)\right] 
        \nonumber \\&
        \leq  
        \left((1-\mu\eta_k)^{\tau_k}+16\eta_k\omega^2\beta/\kappa\left[\frac{(1-\mu\eta_k)^{\tau_k}\lambda_1^{2\tau_k}-1}{(1-\mu\eta_k)\lambda_1^2-1}-\frac{1-(1-\mu\eta_k)^{\tau_k}}{\mu\eta_k}\right]\right)[ F(\hat{\mathbf w}(t_{k-1}))-F(\mathbf w^*)] 
        \nonumber \\&
        + \frac{\eta_k\beta^2}{2}\left[\frac{(1+\mu\eta_k)^{\tau_k}\lambda_1^{2\tau_k}-1}{(1-\mu\eta_k)\lambda_1^2-1}-\frac{1-(1-\mu\eta_k)^{\tau_k}}{\mu\eta_k}\right]\{153/16\epsilon^2(k)+81/16\frac{\sigma^2}{\beta^2}+\frac{\delta^2}{\beta^2}\}
        \nonumber \\&
        +\frac{1-(1-\mu\eta_k)^{\tau_k}}{2}\kappa[\eta_k\sigma^2+\beta\epsilon^2(k)]
        +\frac{\beta}{2}\epsilon^2(k).
    \end{align}
    If the following condition holds for all $k$
    \begin{align*}
        &\frac{\eta_k\beta^2}{2}\left[\frac{(1+\mu\eta_k)^{\tau_k}\lambda_1^{2\tau_k}-1}{(1-\mu\eta_k)\lambda_1^2-1}-\frac{1-(1-\mu\eta_k)^{\tau_k}}{\mu\eta_k}\right]\{153/16\epsilon^2(k)+81/16\frac{\sigma^2}{\beta^2}+\frac{\delta^2}{\beta^2}\}
        \nonumber \\&
        +\frac{1-(1-\mu\eta_k)^{\tau_k}}{2}\kappa[\eta_k\sigma^2+\beta\epsilon^2(k)]
        +\frac{\beta}{2}\epsilon^2(k)
        \nonumber \\&
        \leq \frac{\mu}{2\beta^2}\left(1-\vartheta-\Big((1-\mu\eta_k)^{\tau_k}+16\eta_k\omega^2\beta/\kappa\left[\frac{(1-\mu\eta_k)^{\tau_k}\lambda_1^{2\tau_k}-1}{(1-\mu\eta_k)\lambda_1^2-1}-\frac{1-(1-\mu\eta_k)^{\tau_k}}{\mu\eta_k}\right]\Big)\right)\Vert\nabla F(\hat{\mathbf w}(k))\Vert^2,
    \end{align*}
    where $0<\vartheta\leq 1-\Big((1-\mu\eta_k)^{\tau_k}+16\eta_k\omega^2\beta/\kappa\left[\frac{(1-\mu\eta_k)^{\tau_k}\lambda_1^{2\tau_k}-1}{(1-\mu\eta_k)\lambda_1^2-1}-\frac{1-(1-\mu\eta_k)^{\tau_k}}{\mu\eta_k}\right]\Big)$, then the following relationship
    \begin{align}
        &\mathbb E\left[F(\hat{\mathbf w}(t_k))-F(\mathbf w^*)\right] 
        % \nonumber \\&
        \leq  
        \left(1-\vartheta\right)[ F(\hat{\mathbf w}(t_{k-1}))-F(\mathbf w^*)] 
    \end{align}
    holds.
    % In this proof, we first find the condition such that $\mathbb E\left[F(\bar{\mathbf w}(t))-F(\mathbf w^*)\right]\leq(1-\vartheta)\mathbb E\left[F(\bar{\mathbf w}(t-1))-F(\mathbf w^*)\right]$ hold for $t=1,2,\dots,T$. Finally, we prove the result for this Proposition. \\
    % From \eqref{26} and \eqref{39}, we have   
    % \begin{align} \label{wbar2}
    %     &\mathbb E\left[F(\bar{\mathbf w}(t+1))-F(\mathbf w^*)\right]
    %     \nonumber \\&
    %     \leq 
    %     (1-\mu\eta_t)\mathbb E\left[F(\bar{\mathbf w}(t))-F(\mathbf w^*)\right]
    %     +
    %     16\omega^2\beta\eta_t/\kappa[\lambda_1^{2(t-t_{k-1})}-1][F(\bar{\mathbf w}(t_{k-1}))-F(\mathbf w^*)+\frac{\beta}{2}\epsilon^2(k)]
    %     \nonumber \\&
    %     +\frac{\eta_t\beta^2}{2}
    %     [\lambda_1^{2(t-t_{k-1})}-1]\{153/16\epsilon^2(k)+81/16\frac{\sigma^2}{\beta^2}+\frac{\delta^2}{\beta^2}\}
    %     +\frac{\eta_t\beta}{2}[\eta_t\sigma^2+\beta\epsilon^2(k)].
    % \end{align}
    % If for all $k$
    % \begin{align*}
    %     &16\omega^2\beta\eta_t/\kappa[\lambda_1^{2(t-t_{k-1})}-1][F(\bar{\mathbf w}(t_{k-1}))-F(\mathbf w^*)+\frac{\beta}{2}\epsilon^2(k)]
    %     \nonumber \\&
    %     +\frac{\eta_t\beta^2}{2}
    %     [\lambda_1^{2(t-t_{k-1})}-1]\{153/16\epsilon^2(k)+81/16\frac{\sigma^2}{\beta^2}+\frac{\delta^2}{\beta^2}\}
    %     +\frac{\eta_t\beta}{2}[\eta_t\sigma^2+\beta\epsilon^2(k)]
    %     \nonumber \\&
    %     \leq \frac{\mu}{2\beta^2}(\mu\eta_k-\vartheta)\Vert\nabla F(\bar{\mathbf w}(t))\Vert^2,
    % \end{align*}
    % holds for all $k$,
    % then we show that, for $t=1,2,\dots,T$, we have
    % \begin{align}
    %     \mathbb E\left[F(\bar{\mathbf w}(t))-F(\mathbf w^*)\right]\leq(1-\vartheta)\mathbb E\left[F(\bar{\mathbf w}(t-1))-F(\mathbf w^*)\right].
    % \end{align}
\end{proof}
\fi
% \add{
% Or we can also upper bound \eqref{26} as 
% \begin{align} 
%         &\mathbb E\left[F(\bar{\mathbf w}(t+1))-F(\mathbf w^*)\right]
%         \leq 
%         (1-\mu\eta_k)\mathbb E\left[(F(\bar{\mathbf w}(t))-F(\mathbf w^*))\right]
%         +2\cdot16^{\tau_k}\frac{\eta_k\beta^2\omega^2}{\mu}[F(\hat{\mathbf w}(t_{k-1}))-F(\mathbf w^*)]
%         \nonumber \\&
%         +\frac{\eta_k\beta^2}{2}\bigg[ 
%         \frac{16^{\tau_k}}{4}\phi \big(\eta_k\sigma^2+2\eta_k^2[\delta+2\sigma+2\beta\sum\limits_{c=1}^N\varrho_{c}\epsilon_c(k)]^2\big)
%         +\sum\limits_{c=1}^N\varrho_{c}\epsilon_c^2(k)\bigg]
%         +\frac{\eta_k^2 \beta\sigma^2}{2}
% \end{align}
% By applying \eqref{26} recursively, we have
% \begin{align} 
%     &\mathbb E\left[F(\bar{\mathbf w}(t_k))-F(\mathbf w^*)\right] 
%     \nonumber \\&
%     \leq  
%     \left((1-\mu\eta_k)^{\tau_k}+\frac{1-(1-\mu\eta_k)^{\tau_k}}{\mu^2}\cdot2\cdot16^{\tau_k}\beta^2\omega^2\right)[ F(\hat{\mathbf w}(t_{k-1}))-F(\mathbf w^*)] 
%     \nonumber \\&
%     +\frac{1-(1-\mu\eta_k)^{\tau_k}}{2\mu}\beta\Big(\frac{16^{\tau_k}}{4}\phi\beta \big(\eta_k\sigma^2+2\eta_k^2[\delta+2\sigma+2\beta\sum\limits_{c=1}^N\varrho_{c}\epsilon_c(k)]^2\big)+\beta\sum\limits_{c=1}^N\varrho_{c}\epsilon_c(k)^2+\eta_k\sigma^2\Big).
% \end{align}
% }


\iffalse
\addFL{
\begin{proposition} \label{converge}
    Under Assumption \ref{beta}, Definition \ref{gradDiv} and Algorithm \ref{GT}, for $\eta_k\leq\frac{1}{\beta}$ and $t\in\mathcal T_k$, suppose the following condition is satisfied, 
    \begin{align} \label{condition}
        &\frac{\eta_k\beta^2}{2}\bigg[\frac{1-(1-\mu\eta_k)^{\tau_k}}{\mu\eta_k}\Big[(\frac{1+\beta\eta_k}{\beta\eta_k})\sum\limits_{c=1}^N\varrho_{c}\epsilon_c(k)+\frac{\eta_k\sigma^2}{\beta}\Big]
        \nonumber \\&
        + 8\psi(\eta_k^2[\delta+2\sigma+2\beta\sum\limits_{c=1}^N\varrho_{c}\epsilon_c(k)]^2+\eta_k\sigma^2)
        \left(\frac{1}{\eta_k^2\beta^2(3+\sqrt{1+4\omega})^2}\frac{1-[\frac{(\eta_k\beta(3+\sqrt{1+4\omega})+2)^2}{4(1-\mu\eta_k)}]^{\tau_k}}{1-[\frac{(\eta_k\beta(3+\sqrt{1+4\omega})+2)^2}{4(1-\mu\eta_k)}]}\right)\bigg]
        \nonumber \\&
        \leq \frac{\mu}{2\beta^2}\left[1-\lambda_k-\left((1-\mu\eta_k)^{\tau_k}+\frac{\eta_k\psi\beta^2\omega^2}{4\mu(1+4\omega)(1-\mu\eta_k)}\frac{1-[\frac{(\eta_k\beta(3+\sqrt{1+4\omega})+2)^2}{4(1-\mu\eta_k)}]^{\tau_k}}{1-[\frac{(\eta_k\beta(3+\sqrt{1+4\omega})+2)^2}{4(1-\mu\eta_k)}]}\right)\right]\big\Vert\nabla F(\hat{\mathbf w}(t_{k-1}))\big\Vert^2
    \end{align}
    Algorithm \ref{GT} is guaranteed to converge to the optimum:
    \begin{align*}
        &\mathbb E[F(\hat{\mathbf w}(t_{k}))-F(\mathbf w^*)]
        \leq (1-\lambda_k)[F(\hat{\mathbf w}(t_{k-1}))-F(\mathbf w^*)]
    \end{align*}
    for $0<\lambda_k\leq 1-\left((1-\mu\eta_k)^{\tau_k}+\frac{\eta_k\psi\beta^2\omega^2}{4\mu(1+4\omega)(1-\mu\eta_k)}\frac{1-[\frac{(\eta_k\beta(3+\sqrt{1+4\omega})+2)^2}{4(1-\mu\eta_k)}]^{\tau_k}}{1-[\frac{(\eta_k\beta(3+\sqrt{1+4\omega})+2)^2}{4(1-\mu\eta_k)}]}\right)$.
\end{proposition}
% \begin{align}
%     E[F^k-F^*] \leq \Pi_{k=0}^{K} (1-\lambda_k) [Ft_0 -f^*]
%     \rightarrow linear\\ convergence--> E[F^k-is F^*] \leq \theta^k [Ft_0 -f^*]\\
%     --->\theta=\max_{k} (1-\lambda_k)
% \end{align}
\begin{proof}
    By $\beta$-smoothness and $\mu$-strong convexity of $F(\cdot)$, we have
    \begin{align} \label{145}
        \big\Vert \nabla F(\hat{\mathbf w}(t_{k-1}))\big\Vert^2
        \leq\frac{2\beta^2}{\mu}[F(\hat{\mathbf w}(t_{k-1}))- F(\mathbf w^*)].
    \end{align}
    Combining \eqref{145} with \eqref{condition}, we have
    \begin{align}
         &\frac{\eta_k\beta^2}{2}\bigg[\frac{1-(1-\mu\eta_k)^{\tau_k}}{\mu\eta_k}\Big[(\frac{1+\beta\eta_k}{\beta\eta_k})\sum\limits_{c=1}^N\varrho_{c}\epsilon_c(k)+\frac{\eta_k\sigma^2}{\beta}\Big]
        \nonumber \\&
        + 8\psi(\eta_k^2[\delta+2\sigma+2\beta\sum\limits_{c=1}^N\varrho_{c}\epsilon_c(k)]^2+\eta_k\sigma^2)
        \left(\frac{1}{\eta_k^2\beta^2(3+\sqrt{1+4\omega})^2}\frac{1-[\frac{(\eta_k\beta(3+\sqrt{1+4\omega})+2)^2}{4(1-\mu\eta_k)}]^{\tau_k}}{1-[\frac{(\eta_k\beta(3+\sqrt{1+4\omega})+2)^2}{4(1-\mu\eta_k)}]}\right)\bigg]
        \nonumber \\&
        \leq \left[1-\lambda_k-\left((1-\mu\eta_k)^{\tau_k}+\frac{\eta_k\psi\beta^2\omega^2}{4\mu(1+4\omega)(1-\mu\eta_k)}\frac{1-[\frac{(\eta_k\beta(3+\sqrt{1+4\omega})+2)^2}{4(1-\mu\eta_k)}]^{\tau_k}}{1-[\frac{(\eta_k\beta(3+\sqrt{1+4\omega})+2)^2}{4(1-\mu\eta_k)}]}\right)\right][F(\hat{\mathbf w}(t_{k-1}))- F(\mathbf w^*)],
    \end{align}
    such that the main result in Theorem \ref{co1} becomes
    \begin{align}
        &\mathbb E\left[F(\hat{\mathbf w}(t_k))-F(\mathbf w^*)\right] 
    \nonumber \\&
    \leq  
    \left((1-\mu\eta_k)^{\tau_k}+\frac{\eta_k\psi\beta^2\omega^2}{4\mu(1+4\omega)(1-\mu\eta_k)}\frac{1-[\frac{(\eta_k\beta(3+\sqrt{1+4\omega})+2)^2}{4(1-\mu\eta_k)}]^{\tau_k}}{1-[\frac{(\eta_k\beta(3+\sqrt{1+4\omega})+2)^2}{4(1-\mu\eta_k)}]}\right)[ F(\hat{\mathbf w}(t_{k-1}))-F(\mathbf w^*)] 
    \nonumber \\&
    \left[1-\lambda_k-\left((1-\mu\eta_k)^{\tau_k}+\frac{\eta_k\psi\beta^2\omega^2}{4\mu(1+4\omega)(1-\mu\eta_k)}\frac{1-[\frac{(\eta_k\beta(3+\sqrt{1+4\omega})+2)^2}{4(1-\mu\eta_k)}]^{\tau_k}}{1-[\frac{(\eta_k\beta(3+\sqrt{1+4\omega})+2)^2}{4(1-\mu\eta_k)}]}\right)\right][F(\hat{\mathbf w}(t_{k-1}))- F(\mathbf w^*)].
    \nonumber \\&
    = (1-\lambda_k)\Big(F(\hat{\mathbf w}(t_{k-1}))-F(\mathbf w^*)\Big).
    \end{align}
\end{proof}
}
\fi
% \subsection{Detail proof of Theorem \ref{co1}}

% % \nm{please use $\mathbf w_{c,i}(t)$ for node i in cluster c,
% % $F_{c,i}$ for local function
% % $F_c$ for cluster function
% % $F$ for global fiunction; otherwise your notation is confusing}

% \begin{proof}
% Using $\beta$-smoothness of $F(\cdot)$, we have
%     \begin{align} \label{12}
%         F(\mathbf v)-F(\mathbf m)\leq \nabla F(\mathbf m)^\top(\mathbf v-\mathbf m)+\frac{\beta}{2}\Big\Vert\mathbf v-\mathbf m\Big\Vert^2.
%     \end{align}
%     Consider $t \in \mathcal T_k$, let $\mathbf v = \mathbf w(t+1)$ and $\mathbf m = \mathbf w(t)$, from \eqref{8}, \eqref{eq14} and \eqref{15} we have
%     \begin{align*}
%     \mathbf w(t) &= 
%           \sum\limits_{c=1}^N \varrho_c^{(k)} \frac{1}{s_c^{(k)}} \sum\limits_{i\in\mathcal{S}_c^{(k)}}\mathbf w_{i}(t)
%           \nonumber\\&
%           =\sum\limits_{c=1}^N \varrho_c^{(k)} \frac{1}{s_c^{(k)}} \sum\limits_{i\in\mathcal{S}_c^{(k)}}\big(\overline{\mathbf w_{c}}(t)+s_c^{(k)} e_{i}^{(\Gamma_c(t))}\big)
%     \end{align*}
%     Since $\sum\limits_{c=1}^N \varrho_c^{(k)} \frac{1}{s_c^{(k)}} \sum\limits_{i\in\mathcal{S}_c^{(k)}}s_c^{(k)} e_{i}^{(\Gamma_c(t))}=0$ for all $t$, $\mathbf w(t)$ can be written as
%     \nm{no need for all these steps: replace with}
%     \add{Consider $t \in \mathcal T_k$, let $\mathbf v = \mathbf w(t+1)$ and $\mathbf m = \mathbf w(t)$, from \eqref{8}, \eqref{eq14} and \eqref{15}
%     and using the fact that $\sum\limits_{i\in\mathcal{S}_c^{(k)}} e_{i}^{(\Gamma_c(t))}=0$ we have
%     \begin{align*}
%     \mathbf w(t) &= \mathbf w(t-1)
%           -\eta_k\sum\limits_{c=1}^N \varrho_c^{(k)}\frac{1}{s_c^{(k)}}\sum\limits_{i\in\mathcal{S}_c^{(k)}} \nabla F_i(\mathbf w_i(t-1))
%     \end{align*}}
%     \begin{align*}
%     \mathbf w(t) &= 
%           \sum\limits_{c=1}^N \varrho_c^{(k)} \frac{1}{s_c^{(k)}} \sum\limits_{i\in\mathcal{S}_c^{(k)}}\overline{\mathbf w_{c}}(t)
%           \nonumber\\&
%           =\sum\limits_{c=1}^N \varrho_c^{(k)} \frac{1}{s_c^{(k)}} \sum\limits_{i\in\mathcal{S}_c^{(k)}}\big(\frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}} \left[\mathbf w_j(t-1)-\eta_k\nabla F_j(\mathbf w_j(t-1))\right]\big)
%           \nonumber\\&
%           =\sum\limits_{c=1}^N \varrho_c^{(k)} \frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}} \mathbf w_j(t-1)
%           \nonumber\\&
%           -\eta_k\sum\limits_{c=1}^N \varrho_c^{(k)}\frac{1}{s_c^{(k)}}\sum\limits_{i\in\mathcal{S}_c^{(k)}} \nabla F_i(\mathbf w_i(t-1))
%           \nonumber\\&
%           =\sum\limits_{c=1}^N \varrho_c^{(k)} \frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}} \Big(\bar{\mathbf w}_c(t-1)+s_c^{(k)} e_{j}^{(\Gamma_c(t-1))}\Big)
%           \nonumber\\&
%           -\eta_k\sum\limits_{c=1}^N \varrho_c^{(k)}\frac{1}{s_c^{(k)}}\sum\limits_{i\in\mathcal{S}_c^{(k)}} \nabla F_i(\mathbf w_i(t-1))
%           \nonumber\\&
%           =\sum\limits_{c=1}^N \varrho_c^{(k)} \frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}} \bar{\mathbf w}_c(t-1)
%           -\eta_k\sum\limits_{c=1}^N \varrho_c^{(k)}\frac{1}{s_c^{(k)}}\sum\limits_{i\in\mathcal{S}_c^{(k)}} \nabla F_i(\mathbf w_i(t-1))
%           \nonumber\\&
%           =\sum\limits_{c=1}^N \varrho_c^{(k)} \frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}} \Big(\mathbf w_j(t-1)-s_c^{(k)} e_{j}^{(\Gamma_c(t-1))}\Big)
%           \nonumber\\&
%           -\eta_k\sum\limits_{c=1}^N \varrho_c^{(k)}\frac{1}{s_c^{(k)}}\sum\limits_{i\in\mathcal{S}_c^{(k)}} \nabla F_i(\mathbf w_i(t-1))
%           \nonumber\\&
%           = \mathbf w(t-1)
%           -\eta_k\sum\limits_{c=1}^N \varrho_c^{(k)}\frac{1}{s_c^{(k)}}\sum\limits_{i\in\mathcal{S}_c^{(k)}} \nabla F_i(\mathbf w_i(t-1))
%     \end{align*}
%     and thus
%     \begin{align} \label{13}
%         &F(\mathbf w(t+1))-F(\mathbf w(t))
%         \\&
%         \leq -\eta_k\nabla F(\mathbf w(t))^\top \sum\limits_{c=1}^N\varrho_c^{(k)}\frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}} \nabla F_j(\mathbf w_j(t))
%         \\& \label{60}
%         +\frac{\eta_k^2 \beta}{2}\Big\Vert\sum\limits_{c=1}^N\varrho_c^{(k)}\frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}} \nabla F_j(\mathbf w_j(t))\Big\Vert^2.
%     \end{align}
%     %%%%%%%%%%%%%%%%%
%     By bounding the first term of \eqref{13} with Lemma \ref{lem1} \add{and \eqref{60} with lemma \ref{lem2}}, we obtain
%     \nm{remove this one!}
%     \begin{align}
%         &F(\mathbf w(t+1))-F(\mathbf w(t))
%         \leq -\mu\eta_k(F(\mathbf w(t))-F(\mathbf w^*))
%         \\&
%         +\frac{\eta_k}{2}(\eta_k\beta-1)\Big\Vert\sum\limits_{c=1}^N\varrho_c^{(k)}\frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}} \nabla F_j(\mathbf w_j(t))\Big\Vert^2
%         \\&
%         +\frac{\eta_k}{2}\beta^2\sum\limits_{c=1}^N\varrho_c^{(k)} \frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}}\Big\Vert\mathbf w(t)-\mathbf w_i(t)\Big\Vert^2.
%     \end{align}
%     By bounding \eqref{60} with lemma \ref{lem2}, we obtain
%     \begin{align} \label{46}
%         &F(\mathbf w(t+1))-F(\mathbf w(t))
%         \leq -\mu\eta_k(F(\mathbf w(t))-F(\mathbf w^*))
%         \\&
%         +\frac{\eta_k}{2}(\eta_k\beta-1)\Big\Vert\sum\limits_{c=1}^N\varrho_c^{(k)}\frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}} \nabla F_j(\mathbf w_j(t))\Big\Vert^2
%         \\&
%         +\frac{\eta_k}{2}\beta^2\eta_k^2\tau_k\sum\limits_{l=t_{k-1}}^{t-1}\sum\limits_{c=1}^N\varrho_{c}\frac{1}{s_c^{(k)}}\sum\limits_{i\in\mathcal{S}_c^{(k)}}
%         \\&
%         \Big\Vert\frac{1}{s_{c}}\sum\limits_{j\in\mathcal S_{c}}\nabla F_j(\mathbf w_j(l)) 
%         -s_c^{(k)} e_{i}^{(l+1)}\Big\Vert^2.
%     \end{align}
%     Since $\Vert\mathbf a+\mathbf b\Vert^2\leq 2(\Vert\mathbf a\Vert^2+\Vert\mathbf b\Vert^2)$, \eqref{46} can be bounded as
%     \begin{align} \label{47}
%         &F(\mathbf w(t+1))-F(\mathbf w(t))
%         \leq -\mu\eta_k(F(\mathbf w(t))-F(\mathbf w^*))
%         \\&
%         +\frac{\eta_k}{2}(\eta_k\beta-1)\Big\Vert\sum\limits_{c=1}^N\varrho_c^{(k)}\frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}} \nabla F_j(\mathbf w_j(t))\Big\Vert^2
%         \\&
%         +\eta_k\beta^2\eta_k^2\tau_k\sum\limits_{l=t_{k-1}}^{t-1}\sum\limits_{c=1}^N\varrho_{c}\Big\Vert\frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}}\nabla F_j(\mathbf w_j(l))\Big\Vert^2
%         \\&
%         +\eta_k\beta^2\eta_k^2\tau_k\sum\limits_{l=t_{k-1}}^{t-1}\sum\limits_{c=1}^N\varrho_{c} s_c^{(k)}\sum\limits_{i\in\mathcal{S}_c^{(k)}}\Big\Vert e_i^{(\Gamma_c(l+1))}\Big\Vert^2.
%     \end{align}
%     \eqref{47} is equivalent to 
%     \begin{align} \label{73}
%         &F(\mathbf w(t+1))-F(\mathbf w^*)
%         \leq (1-\mu\eta_k)(F(\mathbf w(t))-F(\mathbf w^*)) 
%         \nonumber \\&
%         +\frac{\eta_k}{2}(\eta_k\beta-1)\Big\Vert\sum\limits_{c=1}^N\varrho_c^{(k)}\frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}} \nabla F_j(\mathbf w_j(t))\Big\Vert^2
%         \\&
%         +\eta_k\beta^2\eta_k^2\tau_k\sum\limits_{l=t_{k-1}}^{t-1}\sum\limits_{c=1}^N\varrho_{c}\Big\Vert\frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}}\nabla F_j(\mathbf w_j(l))\Big\Vert^2
%         \\&
%         +\eta_k\beta^2\tau_k\sum\limits_{l=t_{k-1}}^{t-1}\sum\limits_{c=1}^N\varrho_{c} s_c^{(k)}\sum\limits_{i\in\mathcal{S}_c^{(k)}}\Big\Vert E_i^{(\Gamma_c(l+1))}\Big\Vert^2.
%     \end{align}
    
%     Based on assumption \ref{gradDiv}, \eqref{73} can be bounded as
%     \begin{align} \label{74}
%         &F(\mathbf w(t+1))-F(\mathbf w^*)
%         \leq (1-\mu\eta_k)(F(\mathbf w(t))-F(\mathbf w^*)) 
%         \nonumber \\&
%         +\frac{\eta_k}{2}(\eta_k\beta-1)\Big\Vert\sum\limits_{c=1}^N\varrho_c^{(k)}\frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}} \nabla F_j(\mathbf w_j(t))\Big\Vert^2
%         \\&
%         +\eta_k\beta^2\eta_k^2\delta\tau_k\sum\limits_{l=t_{k-1}}^{t-1}\Big\Vert\sum\limits_{c=1}^N\varrho_{c}\frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}}\nabla F_j(\mathbf w_j(l))\Big\Vert^2
%         \\&
%         +\eta_k\beta^2\tau_k\sum\limits_{l=t_{k-1}}^{t-1}\sum\limits_{c=1}^N\varrho_{c} s_c^{(k)}\sum\limits_{i\in\mathcal{S}_c^{(k)}}\Big\Vert E_i^{(\Gamma_c(l+1))}\Big\Vert^2.
%     \end{align}
   
%     Since $\Big\Vert G_{i}^{(\Gamma_c(t))} \Big\Vert^2 \leq \lambda_c^{2\Gamma_c(t)}s_c^{(k)}^2\epsilon_c^2(t) m^2$, \eqref{74} can bounded as
%     \begin{align} \label{96}
%         &F(\mathbf w(t+1))-F(\mathbf w^*)
%         \leq (1-\mu\eta_k)(F(\mathbf w(t))-F(\mathbf w^*)) 
%         \nonumber \\&
%         +\frac{\eta_k}{2}(\eta_k\beta-1)\Big\Vert\sum\limits_{c=1}^N\varrho_c^{(k)}\frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}} \nabla F_j(\mathbf w_j(t))\Big\Vert^2
%         \\&
%         +\eta_k\beta^2\eta_k^2\delta\tau_k\sum\limits_{l=t_{k-1}}^{t-1}\Big\Vert\sum\limits_{c=1}^N\varrho_{c}\frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}}\nabla F_j(\mathbf w_j(l))\Big\Vert^2
%         \\&
%         +\eta_k\beta^2\tau_k\sum\limits_{l=t_{k-1}}^{t-1}\sum\limits_{c=1}^N\varrho_{c} \lambda_c^{2\Gamma_c(l+1)}s_c^{(k)}^4\epsilon_c^2(l+1) m^2.
%     \end{align}
%     Since consensus is performed at $t\in\mathcal H_k$, the error in \eqref{96} can be written as as the sum of two components: error with zero rounds of consensus at $t\in\mathcal T_k \setminus\mathcal H_k$ and error with $\Gamma_c(t)$ rounds of consensus at $t\in\mathcal H_k$.
%     Let $\epsilon_c(k)\leq\varepsilon_c(k)$ for all $t\in\mathcal T_k$, if the number of consensus rounds for cluster $c$ at $t\in\mathcal H_k$ satisfies
%     \begin{align*} 
%         \begin{cases}
%             \Gamma_c(k)\geq\frac{\log(\sigma_c^{(k)})-2\log(s_c^{(k)}^2\varepsilon_c(k))}{2\log(\lambda_c)} ,& \sigma_c^{(k)} \leq s_c^{(k)}^4\varepsilon_c^2(k), \forall c, k,  \\
%             \Gamma_c(k)\geq 0 ,& \text{otherwise}
%         \end{cases},
%     \end{align*}
%     \eqref{96} can be upper bounded as
%     \begin{align} \label{97}
%         &F(\mathbf w(t+1))-F(\mathbf w^*)
%         \leq (1-\mu\eta_k)(F(\mathbf w(t))-F(\mathbf w^*)) 
%         \nonumber \\&
%         +\frac{\eta_k}{2}(\eta_k\beta-1)\Big\Vert\sum\limits_{c=1}^N\varrho_c^{(k)}\frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}} \nabla F_j(\mathbf w_j(t))\Big\Vert^2
%         \\&
%         +\eta_k\beta^2\eta_k^2\delta\tau_k\sum\limits_{l=t_{k-1}}^{t-1}\Big\Vert\sum\limits_{c=1}^N\varrho_{c}\frac{1}{s_c^{(k)}}\sum\limits_{j\in\mathcal{S}_c^{(k)}}\nabla F_j(\mathbf w_j(l))\Big\Vert^2
%         \\&
%         +\eta_k\beta^2\tau_k m^2 h_k\sum\limits_{c=1}^N\varrho_{c} \sigma_c^{(k)}
%         \\&
%         +\eta_k\beta^2\tau_k m^2 (\tau_k-h_k)\sum\limits_{c=1}^N\varrho_{c} s_c^{(k)}^4\varepsilon_c^2(k).
%     \end{align}
    
% Finally, by Lemma \ref{lem3}, we obtain the update relationship as 
%     \begin{align}
%         &F(\mathbf w(t_{k}))-F(\mathbf w^*) \label{140}
%         \leq 
%         (1-\mu\eta_{k})^{\tau_{k}} \Big(\mathbf w(t_{k-1})-F(\mathbf w^*)\Big)
%         \nonumber \\& 
%         +\frac{1-(1-\mu\eta_k)^{\tau_k}}{\mu\eta_k}\eta_k\beta^2\tau_k m^2 h_k\sum\limits_{c=1}^N\varrho_{c} \sigma_c^{(k)}
%         \nonumber \\&
%         +\frac{1-(1-\mu\eta_k)^{\tau_k}}{\mu\eta_k}\eta_k\beta^2\tau_k m^2
%         (\tau_k-h_k)\sum\limits_{c=1}^N\varrho_{c} s_c^{(k)}^4\varepsilon_c^2(k).
%     \end{align}
%     With this relationship, we can recursively obtain
%     \begin{align}
%         &F(\mathbf w(t_{k}))-F(\mathbf w^*)
%         \leq\prod_{n=1}^k(1-\mu\eta_n)^{\tau_n} \Big(F(\mathbf w(0))-F(\mathbf w^*)\Big)
%         \nonumber \\&
%         +\sum\limits_{n=0}^{k-1}\frac{1-(1-\mu\eta_n)^{\tau_n}}{\mu\eta_n}\eta_n\beta^2\tau_n m^2 h_n\sum\limits_{c=1}^N\varrho_{c} \sigma_c^{(n)}
%         \nonumber \\&
%         +\sum\limits_{n=0}^{k-1}\frac{1-(1-\mu\eta_n)^{\tau_n}}{\mu\eta_n}\eta_n\beta^2\tau_n m^2
%         (\tau_n-h_n)\sum\limits_{c=1}^N\varrho_{c} s_c^{(k)}^4\varepsilon_c^2(n).
%     \end{align}
% \end{proof}

% \subsection{Proof of Proposition \ref{genLin}}

% \begin{proposition} \label{genLin}
%     Under Assumption \ref{beta}, \ref{PL}, \ref{gradDiv} and Algorithm \ref{GT}, suppose the number of consensus rounds at different clusters of the network satisfying
%     $$
%     \Gamma_c(k)\geq
%     \left[\frac{\log(\sigma_c^{(k)})-2\log(s_c^{(k)}^2\varepsilon_c(k))}{2\log(\lambda_c)}\right]^+
%     $$
%     such that $\sigma_c^{(k)}$ satisfies the following inequalities 
%     \begin{equation} \label{cond2}
%         \begin{aligned}
%             \begin{cases}
%                 \lim_{k\rightarrow\infty}B_{k+1}/B_k\leq 1, \\
%                 \eta_k\leq\frac{1}{\beta+\frac{2\beta^2\delta(\mathbf w)\tau_k}{\eta_k(1-\mu\eta_k)^{\tau_k-1}}\big[1-(1-\mu\eta_k)^{\tau_k-1}\big]},
%             \end{cases},
%         \end{aligned}
%     \end{equation}
%     where $B_k = \frac{1-(1-\mu\eta_k)^{\tau_k}}{\mu}\beta^2\tau_k m^2 \Big(h_k\sum\limits_{c=1}^N\varrho_{c} \sigma_c^{(k)}+(\tau_k-h_k)\sum\limits_{c=1}^N\varrho_{c} s_c^{(k)}^4\varepsilon_c^2(k)\Big)$. 
%     Then Algorithm \ref{GT} is guaranteed to converge:
%     \begin{align*}
%         &F(\mathbf w(t_{k}))-F(\mathbf w^*)
%         \\&
%         \leq\prod_{n=1}^k(1-\mu\eta_n)^{\tau_n} \Big(F(\mathbf w(0))-F(\mathbf w^*)\Big)+\mathcal O(C_k),
%     \end{align*}
%     where $C_k=\max\{B_k,\Big((1-\mu\eta_k)^{\tau_k}+\xi\Big)^{t_k}\}$ for any $\xi>0$.

% \end{proposition}

% \begin{proof}
%     Let $\upsilon=(1-\mu\eta)^{\tau_k}$
%     % \begin{align}
%     %     &B_k=\frac{m^2}{\eta_k}\sum\limits_{c=1}^N \varrho_c^{(k)}\Big(\sum\limits_{t \in \mathcal H_k}(1-\mu\eta_k)^{(k+1)\tau_k-t}\sigma_c^{(t)}
%     %     \\&
%     %     +s_c^{(k)}^2\sum\limits_{t \in \mathcal T_k \setminus\mathcal H_k}(1-\mu\eta_k)^{(k+1)\tau_k-t}\epsilon_c^2(t)\Big),
%     % \end{align}
%     \eqref{31} becomes
%     \begin{align}
%         &F(\mathbf w(t_{k}))-F(\mathbf w^*)
%         \\&
%         \leq(1-\mu\eta_k)^{\tau_k} \Big(F(\mathbf w(t_{k-1}))-F(\mathbf w^*)\Big)
%         +B_k.
%     \end{align}
%     Recursively, we obtain  
%      \begin{align*}
%         &F(\mathbf w(t_{k}))-F(\mathbf w^*)
%         \\&
%         \leq (1-\mu\eta_k)^{\tau_k}\Big(F(\mathbf w(t_{k-1}))-F(\mathbf w^*)\Big)+\mathcal O(\zeta_k),
%     \end{align*}
%     where $\zeta_k=\sum_{n=0}^{k-1} \upsilon^{k-n-1}B_n$ such that $\zeta_{k+1}=B_k+\upsilon\zeta_k$.
%     Based on $\lim_{k\rightarrow\infty}B_{k+1}/B_k\leq 1$ and the definition of $C_k$ that $\lim_{k\rightarrow\infty}C_{k+1}/C_k\geq \upsilon+\pi$. Therefore, there exist some $N$ such that $C_{k+1}/C_k-\upsilon\geq\epsilon/2$ for all $k\geq N$. Since $\zeta_k$ are finite and $\pi>0$, we can always choose $\phi$ such that
%     \begin{align*}
%         \begin{cases}
%             \zeta_k \leq \phi C_k,\ \forall k\leq N,\\
%             \phi\pi/2\geq 1,
%         \end{cases}
%     \end{align*}
%     Assume this holds for some arbitrary $k\geq N$, we have
%     \begin{align}
%         &\zeta_{k+1}=B_k+\upsilon\zeta_k\leq C_k+\upsilon\pi C_k
%         \leq \pi(\phi/2)C_k+\upsilon\pi C_k
%         \\&
%         \leq\pi(C_{k+1}/C_k-\upsilon)C_k+\upsilon\pi C_k=\pi C_{k+1}.
%     \end{align}
%     Therefore, $\zeta_k=\mathcal O(C_k)$ for all $k$.
% \end{proof}

% \subsection{Proof of Proposition \ref{strLin}}

% \begin{proposition} \label{strLin}
%     Under Assumption \ref{beta}, \ref{PL} and \ref{gradDiv}, suppose the number of consensus rounds at different clusters of the network satisfies
%     $$
%     \Gamma_c(k)\geq
%     \left[\frac{\log(\sigma_c^{(k)})-2\log(s_c^{(k)}^2\varepsilon_c(k))}{2\log(\lambda_c)}\right]^+
%     $$
%     where $\sigma_c^{(k)}$, $\tau_k$ and $\eta_k$ are determined to satisfy the following inequalities   
%     \begin{align} \label{cond3}
%             \begin{cases} \label{35}
%             h_k\sum\limits_{c=1}^N\varrho_{c} \sigma_c^{(k)}+(\tau_k-h_k)\sum\limits_{c=1}^N\varrho_{c} s_c^{(k)}^4\varepsilon_c^2(k)
%             \\
%             \leq\frac{\mu^2(\gamma_k-\lambda_k)}{2\beta^4 m^2 \tau_k\left[1-(1-\mu\eta_k)^{\tau_k}\right]}\Big\Vert\nabla F(\mathbf w(t_{k-1}))\Big\Vert^2, \\
%             \eta_k\leq\frac{1}{\beta+\frac{2\beta^2\delta(\mathbf w)\tau_k}{\eta_k(1-\mu\eta_k)^{\tau_k-1}}\big[1-(1-\mu\eta_k)^{\tau_k-1}\big]},
%             \end{cases}.
%     \end{align}
%     Then Algorithm \ref{GT} is guaranteed to achieve linear convergence:
%     \begin{align*}
%         &F(\mathbf w(t_{k}))-F(\mathbf w^*)
%         \leq (1-\lambda_k)\Big(F(\mathbf w(t_{k-1}))-F(\mathbf w^*)\Big)
%     \end{align*}
%     for $0\leq\lambda_k\leq1-(1-\mu\eta_k)^{\tau_k}$.
% \end{proposition}

% \begin{proof}   
%     Let $\gamma_k=1-(1-\mu\eta_k)^{\tau_k}$, from \eqref{35}, we have
%     \begin{align} \label{36}
%         &h_k\sum\limits_{c=1}^N\varrho_{c} \sigma_c^{(k)}+(\tau_k-h_k)\sum\limits_{c=1}^N\varrho_{c} s_c^{(k)}^4\varepsilon_c^2(k)
%         \nonumber \\&
%         \leq\frac{\mu^2(\gamma_k-\lambda_k)}{2\beta^4 m^2 \tau_k\left[1-(1-\mu\eta_k)^{\tau_k}\right]}\Big\Vert\nabla F(\mathbf w(t_{k-1}))\Big\Vert^2.
%     \end{align}

%     By $\beta$-smoothness and $\mu$-strong convexity of $F(\cdot)$, we have
%     \begin{align} \label{145}
%         \Big\Vert \nabla F(\mathbf w(t_{k-1}))\Big\Vert^2
%         \leq\frac{2\beta^2}{\mu}\Big(F(\mathbf w(t_{k-1}))- F(\mathbf w^*)\Big)
%     \end{align}
%     Combining \eqref{31}, \eqref{35} and \eqref{36}, we have
%     \begin{align}
%         &F(\mathbf w(t_{k}))-F(\mathbf w^*)
%         % \leq(1-\gamma_k) \Big(F(\mathbf w(t_{k-1}))-F(\mathbf w^*)\Big)
%         % \\&
%         % + (\gamma_k-\lambda_k)\big(F(\mathbf w(t_{k-1}))- F(\mathbf w^*)\big)
%         % \\&
%         \leq (1-\lambda_k)\Big(F(\mathbf w(t_{k-1}))-F(\mathbf w^*)\Big)
%     \end{align}
% \end{proof}
% {\color{blue}
\fi

\section{Proof of Lemma \ref{lem:consensus-error}} \label{app:consensus-error}

\begin{lemma} \label{lem:consensus-error}
If the consensus matrix $\mathbf{V}_{{c}}$ satisfies Assumption~\ref{assump:cons}, then after performing $\Gamma^{(t)}_{{c}}$ rounds of consensus in cluster $\mathcal{S}_c$, the consensus error $\mathbf e_i^{(t)}$ is upper-bounded as:
\begin{equation}
   \Vert \mathbf e_i^{(t)} \Vert \leq \left(\lambda_{{c}}\right)^{\Gamma^{(t)}_{{c}}} s_c{\Upsilon^{(t)}_{{c}}} M,~ \forall i\in \mathcal{S}_c,
\end{equation}
where each $\lambda_{{c}}$ is a constant such that $1 > \lambda_{{c}} \geq \rho \left(\mathbf{V}_{{c}}-\frac{\textbf{1} \textbf{1}^\top}{s_c} \right)$.
\end{lemma} 
\begin{proof}
    Let $[\cdot]_q$ denote the $q$-th column of the matrix, the evolution of the devices' parameters can be described by~\eqref{eq:consensus} as:
  \begin{equation}
      \left[\mathbf{W}^{(t)}_{{c}}\right]_q= \left(\mathbf{V}_{{c}}\right)^{\Gamma^{(t)}_{{c}}} \left[\widetilde{\mathbf{W}}^{(t)}_{{c}}\right]_q, ~t\in\mathcal T_k,
  \end{equation}
  where 
  \begin{align}
      \left[\mathbf{W}^{(t)}_{{c}}\right]_q=\left[(\mathbf{w}^{(t)}_{{c_1}})_q,(\mathbf{w}^{(t)}_{{c_2}})_q,\dots,(\mathbf{w}^{(t)}_{{s_c}})_q\right]^\top
  \end{align}
  and 
  \begin{align}
      \left[\widetilde{\mathbf{W}}^{(t)}_{{c}}\right]_q=\left[(\tilde{\mathbf{w}}^{(t)}_{{c_1}})_q,(\tilde{\mathbf{w}}^{(t)}_{{c_2}})_q,\dots,(\tilde{\mathbf{w}}^{(t)}_{{s_c}})_q\right]^\top
  \end{align}
  with $(\cdot)_q$ denote the $q$-th element of the vector. 
  
  Let matrix $\overline{\mathbf{W}}^{(t)}_{{c}}$ denote the average of the vector of parameters in cluster $c$. The $q$-th column of this matrix can be represented as:
  \begin{align}
      \left[\overline{\mathbf{W}}^{(t)}_{{c}}\right]_q=\frac{\mathbf 1_{s_c} \mathbf 1_{s_c}^\top\left[\widetilde{\mathbf{W}}^{(t)}_{{c}}\right]_q}{s_c},~\forall q.
  \end{align}
  We then define the vector $\mathbf r$ as 
  \begin{align} \label{eq:r-definition}
      \mathbf r= \left[\widetilde{\mathbf{W}}^{(t)}_{{c}}\right]_q-\left[\overline{\mathbf{W}}^{(t)}_{{c}}\right]_q,
  \end{align}
  where $\langle\mathbf 1_{s_c},\mathbf r\rangle=0$. According to Assumption \ref{assump:cons}, for $i\in\mathcal S_c$, we can bound $q$-th element of the consensus error $\Vert\mathbf e_{i}^{(t)}\Vert$ as follows:
  \begin{align} \label{eq:consensus-bound}
      &\Vert(\mathbf e_{i}^{(t)})_q\Vert\leq\left\Vert\left[\widetilde{\mathbf{W}}^{(t)}_{{c}}\right]_q-\left[\overline{\mathbf{W}}^{(t)}_{{c}}\right]_q\right\Vert
      =\left\Vert\left(\mathbf{V}_{{c}}\right)^{\Gamma^{(t)}_{{c}}} \left[\widetilde{\mathbf{W}}^{(t)}_{{c}}\right]_q-\left[\overline{\mathbf{W}}^{(t)}_{{c}}\right]_q\right\Vert
      \nonumber \\&
      =\left\Vert\left(\mathbf{V}_{{c}}\right)^{\Gamma^{(t)}_{{c}}} \Big(\left[\overline{\mathbf{W}}^{(t)}_{{c}}\right]_q+\mathbf r\Big)-\left[\overline{\mathbf{W}}^{(t)}_{{c}}\right]_q\right\Vert
      =\left\Vert\left(\mathbf{V}_{{c}}\right)^{\Gamma^{(t)}_{{c}}} \mathbf r\right\Vert
      \nonumber \\&
      =
      \left\Vert\bigg(\left(\mathbf{V}_{{c}}\right)^{\Gamma^{(t)}_{{c}}}-\frac{\mathbf 1_{s_c} \mathbf 1_{s_c}^\top}{s_c}\bigg) \mathbf r\right\Vert
      \overset{(a)}{=}
      \left\Vert\bigg(\mathbf{V}_{{c}}-\frac{\mathbf 1_{s_c} \mathbf 1_{s_c}^\top}{s_c}\bigg)^{\Gamma^{(t)}_{{c}}} \mathbf r\right\Vert
      \nonumber \\&
      \leq 
      \left\Vert\bigg(\mathbf{V}_{{c}}-\frac{\mathbf 1_{s_c} \mathbf 1_{s_c}^\top}{s_c}\bigg)^{\Gamma^{(t)}_{{c}}}\right\Vert\Vert\mathbf r\Vert
      \leq 
      \left\Vert\bigg(\mathbf{V}_{{c}}-\frac{\mathbf 1_{s_c} \mathbf 1_{s_c}^\top}{s_c}\bigg)\right\Vert^{\Gamma^{(t)}_{{c}}}\Vert\mathbf r\Vert
      \leq
      (\lambda_{{c}})^{\Gamma^{(t)}_{{c}}} \Vert\mathbf r\Vert,
  \end{align}
  where $(a)$ results from Assumption \ref{assump:cons}. To further bound $\Vert\mathbf r\Vert$, we first apply \eqref{eq:r-definition} and Definition \ref{def:clustDiv} obtain the following bound:
  \begin{align} \label{eq:ri-bound}
      &\Vert(\mathbf r)_z\Vert
      =\left\Vert(\widetilde{\mathbf{w}}^{(t)}_{{i}})_{z}-\frac{\Big(\sum\limits_{j\in\mathcal S_c}\widetilde{\mathbf{w}}^{(t)}_{{j}}\Big)_z}{s_c}\right\Vert
      =
      \frac{1}{s_c}\left\Vert s_c(\widetilde{\mathbf{w}}^{(t)}_{{i}})_{z}-\Big(\sum\limits_{j\in\mathcal S_c}\widetilde{\mathbf{w}}^{(t)}_{{j}}\Big)_z\right\Vert
      \nonumber \\&
      \leq
       \frac{1}{s_c}\left\Vert \Big(\widetilde{\mathbf{w}}^{(t)}_{{i}}-\sum\limits_{j\in\mathcal S_c}\widetilde{\mathbf{w}}^{(t)}_{{j}}\Big)_z\right\Vert
       \leq
       \frac{s_c-1}{s_c}\Upsilon^{(t)}_{{c}},~ i\in\mathcal S_c.
  \end{align}
  Then we use the result from \eqref{eq:ri-bound} to bound $\Vert\mathbf r\Vert$ as follows:
  \begin{align} \label{eq:r_bound}
      \Vert\mathbf r\Vert\leq (s_c-1)\Upsilon^{(t)}_{{c}}\leq s_c\Upsilon^{(t)}_{{c}}.
  \end{align}
  Finally, we upper bound the consensus error based on \eqref{eq:consensus-bound} using the result of $\eqref{eq:r_bound}$ as:
  \begin{align}
      &\Vert\mathbf e_{i}^{(t)}\Vert
      \leq \sum\limits_{q=1}^{M} \Vert(\mathbf e_{i}^{(t)})_q\Vert
      \leq(\lambda_{{c}})^{\Gamma^{(t)}_{{c}}}s_c\Upsilon^{(t)}_{{c}}M.
  \end{align}
\end{proof}
% }
\section{Proof of Lemma \ref{lem1}} \label{app:PL-bound}
 
\begin{lemma} \label{lem1}
Under Assumption \ref{beta}, we have
%\nm{$\eta_t$ not $\eta_k$!}
    \begin{align*}
        &-\frac{\tilde{\eta}_{t}}{\beta}\nabla F(\bar{\mathbf w}^{(t)})^\top \sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c} \nabla F_j(\mathbf w_j^{(t)})
        \leq
        -\tilde{\mu}\tilde{\eta}_{t}(F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*))
        \nonumber \\&
        -\frac{\tilde{\eta}_{t}}{2\beta}\Big\Vert\sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c} \nabla F_j(\mathbf w_j^{(t)})\Big\Vert^2
        +\frac{\tilde{\eta}_{t}\beta}{2}\sum\limits_{c=1}^N\varrho_c \frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c}\Big\Vert\bar{\mathbf w}^{(t)}-\mathbf w_j^{(t)}\Big\Vert^2.
    \end{align*}
\end{lemma}

\begin{proof}  Since $-2 \mathbf a^\top \mathbf b = -\Vert \mathbf a\Vert^2-\Vert \mathbf b \Vert^2 + \Vert \mathbf a- \mathbf b\Vert^2$ holds for any two vectors $\mathbf a$ and $\mathbf b$ with real elements, we have
    \begin{align} \label{14}
        &-\frac{\tilde{\eta}_{t}}{\beta}\nabla F(\bar{\mathbf w}^{(t)})^\top
        \sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c} \nabla F_j(\mathbf w_j^{(t)})
        \nonumber \\&
        =\frac{\tilde{\eta}_{t}}{2\beta}\bigg[-\Big\Vert\nabla F(\bar{\mathbf w}^{(t)})\Big\Vert^2
        -\Big\Vert\sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c} \nabla F_j(\mathbf w_j^{(t)})\Big\Vert^2
        \nonumber \\&
        +\Big\Vert\nabla F(\bar{\mathbf w}^{(t)})-\sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c} \nabla F_j(\mathbf w_j^{(t)})\Big\Vert^2\bigg].
    \end{align}
    Since $\Vert\cdot\Vert^2$ is a convex function, using Jenson's inequality, we get: $\Vert \sum_{i=1}^j {c_j} \mathbf a_j  \Vert^2 \leq \sum_{i=1}^j {c_j} \Vert  \mathbf a_j  \Vert^2 $, where $\sum_{i=1}^j {c_j} =1$. Using this fact in~\eqref{14} yields
    \begin{align} \label{20}
        &-\frac{\tilde{\eta}_{t}}{\beta}\nabla F(\bar{\mathbf w}^{(t)})^\top \sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c} \nabla F_j(\mathbf w_j^{(t)})
        \nonumber \\&
        \leq\frac{\tilde{\eta}_{t}}{2\beta}\bigg[-\Big\Vert\nabla F(\bar{\mathbf w}^{(t)})\Big\Vert^2
        -\Big\Vert\sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c} \nabla F_j(\mathbf w_j^{(t)})\Big\Vert^2
        \nonumber \\&
        +\sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c}\Big\Vert\nabla F_j(\bar{\mathbf w}^{(t)})-\nabla F_j(\mathbf w_j^{(t)})\Big\Vert^2\bigg].
    \end{align}
    
   Using $\mu$-strong convexity of $F(.)$, we get: $\Big\Vert\nabla F(\bar{\mathbf w}^{(t)})\Big\Vert^2 \geq 2\tilde{\mu}\beta (F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*))$. Also, using $\beta$-smoothness of $F_j(\cdot)$ we get $\Big\Vert\nabla F_j(\bar{\mathbf w}^{(t)})-\nabla F_j(\mathbf w_j^{(t)})\Big\Vert^2 \leq \beta^2 \Vert\bar{\mathbf w}^{(t)}-\mathbf w_j^{(t)}\Big\Vert^2$, $\forall j$. Using these facts in~\eqref{20} yields:
    \begin{align}
        &-\frac{\tilde{\eta}_{t}}{\beta}\nabla F(\bar{\mathbf w}^{(t)})^\top \sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c} \nabla F_j(\mathbf w_j^{(t)})
        \leq
        -\tilde{\mu}\tilde{\eta}_{t}(F(\bar{\mathbf w}^{(t)})-F(\mathbf w^*))
        \nonumber \\&
        -\frac{\tilde{\eta}_{t}}{2\beta}\Big\Vert\sum\limits_{c=1}^N\varrho_c\frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c} \nabla F_j(\mathbf w_j^{(t)})\Big\Vert^2
        +\frac{\tilde{\eta}_{t}\beta}{2}\sum\limits_{c=1}^N\varrho_c \frac{1}{s_c}\sum\limits_{j\in\mathcal{S}_c}\Big\Vert\bar{\mathbf w}^{(t)}-\mathbf w_j^{(t)}\Big\Vert^2,
    \end{align}
    which concludes the proof.
\end{proof}

\section{Proof of Fact \ref{fact:1}} \label{app:fact1}
\begin{fact}\label{fact:1} For an arbitrary set of $n$ random variables $x_1,\cdots,x_n$, we have: 
 \begin{equation}
     \sqrt{\mathbb E\left[\left(\sum\limits_{i=1}^{n} x_i\right)^2\right]}\leq \sum\limits_{i=1}^{n} \sqrt{\mathbb E[x_i^2]}.
 \end{equation}
\end{fact}
\begin{proof} The proof can be carried out through the following set of algebraic manipulations:
    % Using the following result of Cauchy-Schwarz Inequality
    % \begin{align}
    %     \mathbb E[XY] \leq \sqrt{\mathbb E[X^2]\mathbb E[ Y^2]},
    % \end{align}
    % we obtain
    \begin{align}
        &\sqrt{\mathbb E\left[\left(\sum\limits_{i=1}^{n} x_i\right)^2\right]}
        =
        \sqrt{\sum\limits_{i=1}^{n} \mathbb E[x_i^2] +\sum\limits_{i=1}^{n}\sum\limits_{j=1,j\neq i}^{n}\mathbb E [x_i x_j]}
        \nonumber \\&
        \overset{(a)}{\leq}
        \sqrt{\sum\limits_{i=1}^{n} \mathbb E[x_i^2] +\sum\limits_{i=1}^{n}\sum\limits_{j=1,j\neq i}^{n}\sqrt{\mathbb E [x_i^2] \mathbb E[x_j^2]]}}
        % \nonumber \\&
        =\sqrt{\Big(\sum\limits_{i=1}^{n} \sqrt{\mathbb E[x_i^2]}\Big)^2}
        =
        \sum\limits_{i=1}^{n} \sqrt{\mathbb E[x_i^2]},
    \end{align}
    where $(a)$ is due to the fact that $\mathbb E[XY] \leq \sqrt{\mathbb E[X^2]\mathbb E[ Y^2]}$ resulted from Cauchy-Schwarz inequality.
\end{proof}
% \begin{proof}
%     \begin{align}
%         &\sqrt{\mathbb E[X+Y]^2}=\sqrt{\mathbb E[X^2+2XY+Y^2]}
%         =\sqrt{\mathbb E[X^2]+2\mathbb E[XY]+\mathbb[Y^2]]}
%         \nonumber \\&
%         \leq
%         \sqrt{\mathbb E[X^2]+\mathbb[Y^2]]+2\sqrt{\mathbb E [X^2] \mathbb E[Y^2]]}}
%         =\sqrt{\mathbb E[X^2]}+\sqrt{\mathbb E[Y^2]}.
%     \end{align}
% \end{proof}






\newpage

\section{Additional Experimental Results}
\label{app:experiments}

This section presents the plots from complimentary experiments mentioned in Sec.~\ref{sec:experiments}. We use an additional dataset, Fashion-MNIST (FMNIST), and fully connected neural networks (FCN) for these additional experiments. FMNIST (\url{https://github.com/zalandoresearch/fashion-mnist}) is a dataset of clothing articles consisting of a training set of 60,000 samples and a test set of 10,000 samples. Each sample is a 28x28 grayscale image, associated with a label from 10 classes.

In the following, we explain the relationship between the figures presented in this appendix and the results presented in the main text. Overall, we find that the results are qualitatively similar to what was observed for the SVM and MNIST cases:
\begin{itemize}
    \item Fig.~\ref{fig:mnist_poc_1_all} from main text is repeated in Fig.~\ref{fig:fmnist_poc_1_all} for FMNIST dataset using SVM, Fig.~\ref{fig:mnist_nn_poc_1_all} for MNIST dataset using FCN, and Fig.~\ref{fig:fmnist_nn_poc_1_all} for FMNIST dataset using FCN.
    
    \item Fig.~\ref{fig:mnist_poc_2_all} from main text is repeated in Fig.~\ref{fig:fmnist_poc_2_all} for FMNIST dataset using SVM, Fig.~\ref{fig:mnist_nn_poc_2_all} for MNIST dataset using FCN, and Fig.~\ref{fig:fmnist_nn_poc_2_all} for FMNIST dataset using FCN.
    
    \item Fig.~\ref{fig:poc_3_iid_1_gamma_1_lut_50} from main text is repeated in Fig.~\ref{fig:fmnist_poc_3_iid_1_gamma_1_lut_50} for FMNIST dataset using SVM, Fig.~\ref{fig:mnist_nn_poc_3_iid_1_gamma_1_lut_50} for MNIST dataset using FCN, and Fig.~\ref{fig:fmnist_nn_poc_3_iid_1_gamma_1_lut_50} for FMNIST dataset using FCN.
    
    \item Fig.~\ref{fig:resource_bar_0} from main text is repeated in Fig.~\ref{fig:fmnist_resource_bar_0} for FMNIST dataset using SVM, Fig.~\ref{fig:mnist_nn_resource_bar_0} for MNIST dataset using FCN, and Fig.~\ref{fig:fmnist_nn_resource_bar_0} for FMNIST dataset using FCN.
    
    \item Fig.~\ref{fig:behaviour_of_tau} from main text is repeated in Fig.~\ref{fig:fmnist_behaviour_of_tau} for FMNIST dataset using SVM.
\end{itemize}
Since FCN has a non-convex loss function, Algorithm~\ref{GT} is not directly applicable for the experiments in Fig.~\ref{fig:mnist_nn_resource_bar_0}\&\ref{fig:fmnist_nn_resource_bar_0}. As a result, in these cases, we skip the control steps in line 24-25. We instead use a fixed step size, using a constant $\phi$ value to calculate the $\Gamma$'s using \eqref{eq:consensusNum}. We are still able to obtain comparable reductions in total cost compared with the federated learning baselines.

\begin{figure}[t]
\includegraphics[width=1.0\columnwidth]{fmnist_125/poc_1_all.eps}
\centering
\caption{Performance comparison between {\tt TT-HF} and baseline methods when varying the number of D2D consensus rounds ($\Gamma$). Under the same period of local model training ($\tau$), increasing $\Gamma$ results in a considerable improvement in the model accuracy/loss over time as compared to the current art~\cite{wang2019adaptive,Li} when data is non-i.i.d. (FMNIST, SVM)}
\label{fig:fmnist_poc_1_all}
\vspace{-5mm}
\end{figure} 

\begin{figure}[t]
\includegraphics[width=1.0\columnwidth]{fmnist_125/poc_2_all.eps}
\centering
\caption{Performance comparison between {\tt TT-HF} and baseline methods when varying the local model training interval ($\tau$) and the number of D2D consensus rounds ($\Gamma$). With a larger $\tau$, {\tt TT-HF} can still outperform the baseline federated learning~\cite{wang2019adaptive,Li} if $\Gamma$ is increased, i.e., local D2D communications can be used to offset the frequency of global aggregations. (FMNIST, SVM)}
\label{fig:fmnist_poc_2_all}
\vspace{-5mm}
\end{figure}

\begin{figure}[t]
\includegraphics[width=1.0\columnwidth]{fmnist_125/poc_3_iid_1_gamma_1_lut_50.eps}
\centering
\caption{Performance of {\tt TT-HF} in the extreme non-i.i.d. case for the setting in Fig.~\ref{fig:mnist_poc_2_all} when $\Gamma$ is small and the local model training interval length is increased substantially. {\tt TT-HF} exhibits poor convergence behavior when $\tau$ exceeds a certain value, due to model dispersion. (FMNIST, SVM)}
\label{fig:fmnist_poc_3_iid_1_gamma_1_lut_50}
\vspace{-5mm}
\end{figure}

\begin{figure}[t]
\hspace{-3mm}
\includegraphics[width=0.99\columnwidth]{fmnist_125/resource_bar_0.01_0.15.eps}
\centering
\caption{Comparing total (a) cost, (b) power, and (c) delay metrics from the optimization objective in $(\bm{\mathcal{P}})$ achieved by {\tt TT-HF} versus baselines upon reaching $75\%$ of peak accuracy, for different configurations of delay and energy consumption. {\tt TT-HF} obtains a significantly lower total cost in (a). (b) and (c) demonstrate the region under which {\tt TT-HF} attains energy savings and delay gains. (FMNIST, SVM)}
\label{fig:fmnist_resource_bar_0}
\vspace{-5mm}
\end{figure}

\begin{figure}[t]
\vspace{4mm}
\hspace{-2.5mm}
\includegraphics[width=1\columnwidth]{fmnist_125/behaviour_of_tau.eps}
\centering
\caption{Value of the second local model training interval obtained through $(\bm{\mathcal{P}})$ for different configurations of weighing coefficients $c_1, c_2, c_3$ (default $c_1 = 10^{-3}, c_2=10^2, c_3=10^4$). Higher weight on energy and delay (larger $c_1$ and $c_2$) prolongs the local training period, while higher weight on the global model loss (larger $c_3$) decreases the length, resulting in more rapid global aggregations. (FMNIST, SVM)
}
\label{fig:fmnist_behaviour_of_tau}
\vspace{-5mm}
\end{figure}

\begin{figure}[t]
\includegraphics[width=1.0\columnwidth]{mnist_nn/poc_1_all.eps}
\centering
\caption{Performance comparison between {\tt TT-HF} and baseline methods when varying the number of D2D consensus rounds ($\Gamma$). Under the same period of local model training ($\tau$), increasing $\Gamma$ results in a considerable improvement in the model accuracy/loss over time as compared to the current art~\cite{wang2019adaptive,Li} when data is non-i.i.d. (MNIST, Neural Network)}
\label{fig:mnist_nn_poc_1_all}
\vspace{-5mm}
\end{figure} 

\begin{figure}[t]
\includegraphics[width=1.0\columnwidth]{mnist_nn/poc_2_all.eps}
\centering
\caption{Performance comparison between {\tt TT-HF} and baseline methods when varying the local model training interval ($\tau$) and the number of D2D consensus rounds ($\Gamma$). With a larger $\tau$, {\tt TT-HF} can still outperform the baseline federated learning~\cite{wang2019adaptive,Li} if $\Gamma$ is increased, i.e., local D2D communications can be used to offset the frequency of global aggregations. (MNIST, Neural Network)}
\label{fig:mnist_nn_poc_2_all}
\vspace{-5mm}
\end{figure}

\begin{figure}[t]
\includegraphics[width=1.0\columnwidth]{mnist_nn/poc_3_iid_1_gamma_1_lut_50.eps}
\centering
\caption{Performance of {\tt TT-HF} in the extreme non-i.i.d. case for the setting in Fig.~\ref{fig:mnist_poc_2_all} when $\Gamma$ is small and the local model training interval length is increased substantially. {\tt TT-HF} exhibits poor convergence behavior when $\tau$ exceeds a certain value, due to model dispersion. (MNIST, Neural Network)}
\label{fig:mnist_nn_poc_3_iid_1_gamma_1_lut_50}
\vspace{-5mm}
\end{figure}

\begin{figure}[t]
\hspace{-3mm}
\includegraphics[width=0.99\columnwidth]{mnist_nn/resource_bar_0.01_0.15.eps}
\centering
\caption{Comparing total (a) cost, (b) power, and (c) delay metrics from the optimization objective in $(\bm{\mathcal{P}})$ achieved by {\tt TT-HF} versus baselines upon reaching $75\%$ of peak accuracy, for different configurations of delay and energy consumption. {\tt TT-HF} obtains a significantly lower total cost in (a). (b) and (c) demonstrate the region under which {\tt TT-HF} attains energy savings and delay gains. (FMNIST, SVM)}
\label{fig:mnist_nn_resource_bar_0}
\vspace{-5mm}
\end{figure}


\begin{figure}[t]
\includegraphics[width=1.0\columnwidth]{fmnist_nn/poc_1_all.eps}
\centering
\caption{Performance comparison between {\tt TT-HF} and baseline methods when varying the number of D2D consensus rounds ($\Gamma$). Under the same period of local model training ($\tau$), increasing $\Gamma$ results in a considerable improvement in the model accuracy/loss over time as compared to the current art~\cite{wang2019adaptive,Li} when data is non-i.i.d. (FMNIST, Neural Network)}
\label{fig:fmnist_nn_poc_1_all}
\vspace{-5mm}
\end{figure} 

\begin{figure}[t]
\includegraphics[width=1.0\columnwidth]{fmnist_nn/poc_2_all.eps}
\centering
\caption{Performance comparison between {\tt TT-HF} and baseline methods when varying the local model training interval ($\tau$) and the number of D2D consensus rounds ($\Gamma$). With a larger $\tau$, {\tt TT-HF} can still outperform the baseline federated learning~\cite{wang2019adaptive,Li} if $\Gamma$ is increased, i.e., local D2D communications can be used to offset the frequency of global aggregations. (FMNIST, Neural Network)}
\label{fig:fmnist_nn_poc_2_all}
\vspace{-5mm}
\end{figure}

\begin{figure}[t]
\includegraphics[width=1.0\columnwidth]{fmnist_nn/poc_3_iid_1_gamma_1_lut_50.eps}
\centering
\caption{Performance of {\tt TT-HF} in the extreme non-i.i.d. case for the setting in Fig.~\ref{fig:mnist_poc_2_all} when $\Gamma$ is small and the local model training interval length is increased substantially. {\tt TT-HF} exhibits poor convergence behavior when $\tau$ exceeds a certain value, due to model dispersion. (FMNIST, Neural Network)}
\label{fig:fmnist_nn_poc_3_iid_1_gamma_1_lut_50}
\vspace{-5mm}
\end{figure}

\begin{figure}[t]
\hspace{-3mm}
\includegraphics[width=0.99\columnwidth]{fmnist_nn/resource_bar_0.01_0.15.eps}
\centering
\caption{Comparing total (a) cost, (b) power, and (c) delay metrics from the optimization objective in $(\bm{\mathcal{P}})$ achieved by {\tt TT-HF} versus baselines upon reaching $75\%$ of peak accuracy, for different configurations of delay and energy consumption. {\tt TT-HF} obtains a significantly lower total cost in (a). (b) and (c) demonstrate the region under which {\tt TT-HF} attains energy savings and delay gains. (FMNIST, Neural Network)}
\label{fig:fmnist_nn_resource_bar_0}
\vspace{-5mm}
\end{figure}


\endgroup