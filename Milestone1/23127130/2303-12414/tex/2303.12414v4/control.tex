
\section{Adaptive Control Algorithm for {\tt DFL}}\label{Sec:controlAlg}
\noindent In this section, we develop a control algorithm based on Theorem~\ref{thm:subLin_m} for tuning the controllable parameters in {\tt DFL}, while guaranteeing the sublinear convergence of the model. In {\tt DFL}, there are four sets of controllable parameters: (i) local model training intervals $\{\tau_k\}$, (ii) the combiner weight $\{\alpha_k\}$, (iii) the gradient descent step size $\{\eta_k\}$, and (iv) the instances of local aggregations $\{\mathcal T^\mathsf{L}_{k,c}\}$. The decisions on (i), (ii), (iii) and (iv) are made by the main server at $t=t_{k+1}-\Delta_k^{\mathsf{D}},~\forall k$ during global aggregation. 
% while the decision on (iv) is made at the edge server at the instance of local aggregations. These decisions are deployed at the system at $t=t_{k+1},~\forall k$.
% \nm{isnt the edge server responsible for the decisions on local agg??}
% whereas for (iv) the decision of the first instance (i.e., the time of first local aggregation) is determined by the main server at $t=t_k-\Delta_k^{\mathsf{D}},~\forall k$ while the rest (i.e., the time of the remaining local aggregations) are determined by the edge server at the instances when the local models are sent from the edge devices to the edge server to perform local aggregations (e.g., the time of the second local aggregation is obtained when the edge server conducts the first local aggregation).

To tune these parameters, we develop a control algorithm consisting of the following two parts. \textit{Part I:}  an adaptive technique (Sec.~\ref{subsec:learniParam}) to determine the step-size (i.e., $\eta_{max}$ and $\gamma$ in $\eta_k$ defined in Theorem~\ref{thm:subLin_m}) considering the conditions imposed by Theorem~\ref{thm:subLin_m}. \textit{Part II:} an optimization scheme (Sec.~\ref{subsec:learnduration}) to tune $\tau_k$ and $\alpha_k$ accounting for the tradeoff between the ML model performance and network resource consumption. 
% \textit{Part III:} an estimation procedure to estimate dataset and model-related parameters ($\beta, \mu, \zeta, \delta, \zeta_c, \delta_c, \sigma$, $\omega$, and $\omega_c$) used in Parts I and II (Sec.~\ref{subsub:estparam}). 
In Sec.~\ref{ssec:control}, we provide the pseudocode summarizing how Parts I and II are integrated.
% In this section, we develop a control algorithm (Sec.~\ref{ssec:control}) based on Theorem~\ref{thm:subLin} for tuning (i), (ii) at the main server at the beginning of each global aggregation, and (iii) at each device cluster in a decentralized manner. To do so, we propose an approach for determining the learning-related parameters (Sec.~\ref{subsec:learniParam}), a resource-performance tradeoff optimization for $\tau_k$ and $\Gamma_c$ (Sec.~\ref{subsec:learnduration}), and estimation procedures for dataset-related parameters (Sec.~\ref{subsec:cont}).  
  

\subsection{Step Size Parameters ($\eta_{max}$, $\gamma$)}\label{subsec:learniParam}
We first tune the step size parameters ($\eta_{max}$, $\gamma$). This is done for a given set of model-related parameters ($\beta, \mu, \zeta, \delta, \zeta_c, \delta_c, \sigma$, $\omega$ and $\omega_c$), which can be estimated by the server (e.g., see Sec. IV-C of~\cite{lin2021timescale}). 
% We assume that the latency-sensitivity of the learning application specifies a tolerable amount of time that {\tt DFL} can wait between consecutive global aggregations, i.e., the value of $\tau$. 
Given the fact that larger feasible values of $\eta_{max}$ result in larger values of step size and thus faster convergence, given the conditions mentioned in the statement of Theorem~\ref{thm:subLin_m}, we first determine the largest value for $\eta_{max}$ such that $\eta_{max}<\min\left\{\frac{2}{\beta+\mu},\frac{(\tau-\Delta)\mu}{\beta^2[(1+\lambda_+)^{\tau}-1-\tau\lambda_+]}\right\}$, where $\lambda_+$ is defined in Theorem~\ref{thm:subLin_m}. Afterward, 
% given the fact that smaller values of $\Lambda$ result in a larger value of step size and thus faster convergence, 
we arbitrarily choose the value of $\gamma$ such that $\gamma<\min\left\{1-(1-\mu\eta_{\mathrm{max}})^{2(\tau-\Delta)},C_3\eta_{\mathrm{max}}\beta\right\}$.
% \begin{align} \label{eq:gammaCond}
%        \hspace{-3mm} 
%             \gamma<\min\left\{1-(1-\mu\eta_{\mathrm{max}})^{2(\tau-\Delta)},C_3\eta_{\mathrm{max}}\beta\right\}. 
%         \hspace{-4mm}
%     \end{align} 

% The step size-related parameters will be re-computed at the server at each global aggregation using the most recent estimates of dataset and model-related parameters and used in the subsequent local model training interval.

We next introduce the optimization formulation to determine the length of local model training interval $\tau_k$ and the combiner weight $\alpha_k$ for each local model training interval. 

%With the learning-related parameters in hand, we then determine the period of local model training in the following.

% $
% \frac{\phi^2}{\beta}
% $
% $ Z_2\triangleq
%     \frac{1}{2}[\frac{\sigma^2}{\beta}+\frac{2\phi^2}{\beta}]
%     +50\beta\gamma(\tau-1)\left(1+\frac{\tau-2}{\alpha+1}\right)
%     \left(1+\frac{\tau-1}{\alpha-1}\right)^{6\beta\gamma}\left[\frac{\sigma^2}{\beta}+\frac{\phi^2}{\beta}+\frac{\delta^2}{\beta}\right]$
% and allows the value of $\tau_k$ 
%     \begin{align} \label{60}
%         1 \leq \tau_k \leq \sqrt{\Big[\mu\gamma-[3+8(1/\vartheta+(2\omega-\vartheta/2))^2]\Big]\Big[\tilde{\Gamma}-\vartheta\gamma\phi^2/2\Big]/(\gamma^2\beta^2 B)-A/B}
%     \end{align}
% to resides within a desirable range. 
% Note that satisfying \eqref{47} is equivalent to satisfy the second condition for $\nu$ in Theorem \ref{thm:subLin}.

% want to find some $\tau$ and $\phi$ such that the objective in (48) can be minimized while satisfying the second term in the lower bound of $\Gamma$ as follows:
% \begin{align}
%      &\Gamma\geq \frac{\gamma^2\beta}{2}[Q_k A+B]/[\mu\gamma-(1+16\omega^2\beta^2\gamma^2 Q_k/\kappa)]+\beta\phi\gamma/2
% \end{align}
% can be satisfied.
% which forces $\phi,\tau$ to have an upper bound. Now, intuitively, larger gamma always helps with reducing the consensus rounds, so we choose to select the largest $\Gamma$. Note that $\Gamma$ is a function of $\tau$ and $\phi$. In general, larger $\phi$ makes $\Gamma$ larger and so does larger $\tau$.
% $A=(16\omega^2/\kappa+153/16)\beta\phi+81/16\sigma^2+\delta^2$, $B=\sigma^2+\beta\phi$

% \begin{align}
%     \frac{\gamma^2\beta}{2}[97/4\sigma^2+\delta^2]/
%     \{[\mu\gamma-(1+16\omega^2\beta^2\gamma^2 Q_k/\kappa)]F(\hat{ \mathbf{w}}(0)\}\geq\alpha\geq\max\{\beta\gamma/\kappa, \beta\gamma\big[1-\kappa/4+\sqrt{(1+\kappa/4)^2+2\omega}\big]\}
% \end{align}
% \addFL{
% Or equivalently, for the given value of $\Gamma$, we want to find the maximum value of $\tau$ based on a given value of $\phi$.
%     $$
%     [(\mu\gamma-1)(\Gamma-\beta\phi\gamma/2)-B]/[\frac{\gamma^2\beta}{2}A+\frac{16\omega^2\beta^2\gamma^2(\Gamma-\beta\phi\gamma/2)}{\kappa}]>4,
%     $$
%     we obtain the range of $\tau$ as  
%     \begin{align}
%         \tau \leq \log_4\left\{[(\mu\gamma-1)(\Gamma-\beta\phi\gamma/2)-B]/[\frac{\gamma^2\beta}{2}A+\frac{16\omega^2\beta^2\gamma^2(\Gamma-\beta\phi\gamma/2)}{\kappa}]\right\}.
%     \end{align}
% }

% we keep changing $\phi$ in the interval obtained from \eqref{47} and \eqref{60} (for example, we can use line search with a certain quantization step) and 
% we compute the optimization of \eqref{eq:obj} with convex optimization techniques to obtain the corresponding value of $\tau_k$ for each round of global aggregation. 
% This will give us multiple pairs of $\tau_1$ and $\phi$. We choose the pair of $\tau_1,\phi$ that gives us the best result with respect to the objective and fix this value of $\phi$ for the rest of the training.

% Note that the dynamics of $\Upsilon_c^{(t)}$ with respect to different values of $\tau_k$ given some fixed value of $\phi$ will be obtained in the estimation phase.
 
\subsection{Length of Local Training Interval $\{\tau_k\}$ and Value of Combiner Weight $\{\alpha_k\}$}\label{subsec:learnduration}

Considering the convergence goal of {\tt DFL} (i.e., sublinear convergence with low resource consumption across edge devices), we formulate an optimization problem $\bm{\mathcal{P}}$ solved by the main server at each instance of global aggregation at $t=t_{k}-\Delta_{k-1}^{\mathsf{D}},~\forall k$ to tune $\tau_k$ and $\alpha_k$ for the subsequent local model training intervals $\mathcal{T}_k,~\forall k$. The objective function of $\bm{\mathcal{P}}$ accounts for the joint impact of three metrics: $(a)$ energy consumption of local and global model aggregation, $(b)$ communication delay of local and global aggregation, and $(c)$ the performance of global deployed model captured by the optimality gap in Theorem~\ref{thm:subLin_m}. 
% In this paper, we assume that the latency-sensitivity of the learning application in {\tt DFL} specifies a tolerable length on the local model training interval $\tau_k$ denoted as $\tau_{\textrm{max}}$, providing the formulation as follows:
% To capture this, we formulate an optimization problem $(\bm{\mathcal{P}})$ solved by the main server at the beginning of each global aggregation period $\mathcal{T}_k$, i.e., when $t=t_{k-1}$:

% \footnote{$\sum\limits_{j\in\mathcal S_c}\rho_{j,c}\mathbb E_{t_{k-1}}[\Vert \mathbf e_j^{(t)} \Vert] 
%       \leq \sum\limits_{j\in\mathcal S_c}\rho_{j,c}\mathbb E_{t_{k-1}}\Vert\mathbf e_{j}^{(t_{k-1})}\Vert\prod\limits_{u=t_{k-1}}^{t-1}(1+2\eta_{u}\beta)
%     +\sum\limits_{u=t_{k-1}}^{t-1}\eta_{u}\Big(\frac{2\omega_c\beta}{\mu}\mathbb E_{t_{k-1}}\Vert\nabla F(\bar{\mathbf w}_c^{(u)})\Vert
%     +(2\sigma+\delta_c)\Big)\prod\limits_{m=n+1}^{t-1}(1+2\eta_{m}\beta)$}
% \nm{I dont understand, what is $\Gamma_{\{c,k\}}$ for? Is it capturing the time slots that trigger local aggregation? If that is the case, shuoldnt Ak be defined as 
% $\mathcal{A}_{k} = \{t\in\mathcal T_k:  X_t> \eta_t \phi \}$
% ins tead of 
% $\mathcal{A}_{k} = \{t\in\mathcal T_k:  X_t\leq  \eta_t \phi \}$??
% }
\begin{align*} 
    &(\bm{\mathcal{P}}): ~~\min_{\tau,\alpha}  c_1\underbrace{(\frac{T-t_{k}}{\tau})\Big(E_{\textrm{GlobAgg}}+\sum\limits_{c=1}^N \vert\mathcal{A}_{\{c,k\}}\vert E_{c,\textrm{LocalAgg}}\Big)}_{(a)}+
    \nonumber \\&
    c_2\underbrace{(\frac{T-t_{k}}{\tau})\Big(\Delta_{\textrm{GlobAgg}}+\sum\limits_{c=1}^N\vert\mathcal{A}_{\{c,k\}}\vert\Delta_{c,\textrm{LocAgg}}\Big)}_{(b)}
    + c_3\underbrace{\nu(\tau,\alpha)}_{(c)}
\end{align*}  
%  network prop delay, trans delay, queiuing and processing delay, describe (44) when range of tau is empty 
\vspace{-0.3in}  
    \begin{align} 
    & \textrm{s.t.}\nonumber \\ 
    % & \;\;\; 1 \leq \Delta_k, \Delta_k\in\mathbb{Z}^+, \\
   & \;\;\; \Delta \leq \tau \leq \min{\{\tau_\textrm{max}, T-t_{k}\}}, \tau_k\in\mathbb{Z}^+, \label{eq:tauMax}\\   
   & \;\;\; \alpha<\frac{1}{\frac{C_2\eta_{\max}^2}{\eta_{\max}\beta C_3-\gamma}
         2\omega C_2(1+\gamma)
        +(1+\gamma)(1+\lambda_+)^{\tau}}, \label{eq:bound_alpha}
 %   & \;\;\; \nu(\tau_k,\alpha_k) \geq \nu^{\mathsf{min}},  
 % \label{eq:bound_min}\\
 %   & \;\;\; \nu^{\mathsf{min}} = \max\hspace{.51mm} \left\{\frac{Y_3\beta^2\gamma^2(\Lambda-\Delta)}{(\Lambda-\Delta)(Y_1\gamma-(\Delta+1))-Y_2{\gamma}^2\beta^2},\frac{\Lambda\Vert\nabla F(\widehat{\mathbf w}^{(0)})\Vert^2}{2\mu}\right\}, \label{eq:eps_min}
%   & \;\;\; 1 \leq \Delta \leq \tau, \Delta\in\mathbb{Z}^+, \label{eq:delta}\\ 
%   & \;\;\; \Delta_{\textrm{GlobAgg}} = \max_{n_i\in\mathcal{N}} M\times Q/R_{\{c,n_i\}}, \label{eq:globDelay}\\
%   & \;\;\; \Delta_{c,\textrm{LocalAgg}} = \max_{j\in\mathcal{S}_c} M\times Q/R_{\{n_c,j\}}, \label{eq:locDelay}\\
%   & \;\;\; E_{\textrm{GlobAgg}} = \sum\limits_{i=1}^Np_{\{c,n_i\}} M\times Q/R_{\{c,n_i\}}, \label{eq:globEng}\\
%   & \;\;\; E_{c,\textrm{LocalAgg}} = \sum\limits_{j=1}^{s_c}\ p_{\{n_c,j\}} M\times Q/R_{\{n_c,j\}}, \label{eq:locEng}\\
%   & \;\;\; \mathcal{A}_{\{c,k\}} = \{t\in\mathcal T_k:  (\epsilon_c^{(t)})^2> \eta_t \phi \},  \label{eq:consensusNum} \\
\end{align}
% \nm{doesnt make sense that X depebnds ob the expected terms. You need to use upper bounds for them}
where $E_{\textrm{c,LocalAgg}}= \sum_{j\in \mathcal{S}_c} M\times Q\times p_{j}/R_j^{(t)}$ is the energy consumption of conducting local model aggregation at edge server $n_c$, where $M$ denotes the size of the model (i.e., number of model parameters), $Q$ denotes the number of bits used to represent each model parameter, which is dependent on the quantization level, $p_{j}$ denotes the transmit power of device $j\in\mathcal S_c$,  and $R_j^{(t)}=W\log_2 \left(1+ \frac{p_j \vert {h}^{(t)}_{j}\vert^2}{N_0W} \right)$ is the transmission rate between device $j\in\mathcal S_c$ and its associated edge server $n_c$ at time $t$. The noise power is $N_0 W$, with $N_0$ as the white noise power spectral density, $W$ as the bandwidth, and ${h}^{(t)}_{j}$ as the channel coefficient.
% \footnote{Although the exact data rates between the devices and the server may not be known in advance due to unknown channel conditions, we can use expected data rates given the channel condition statistics (see Sec.~\ref{sec:experiments}).} 
$E_{\textrm{GlobAgg}}=\sum_{n_c \in\mathcal{N}} M\times Q \times \bar{p}_{n_c}/\bar{R}_{n_c}^{(t)}$ is the energy consumption for edge-to-main server communications, where $\bar{p}_{n_c}$ and $\bar{R}_{n_c}^{(t)}$ denote the transmit power of edge server $n_c$ and the transmission rate between the edge server $n_c\in\mathcal N,~\forall c$ and the main server, respectively. Furthermore, $\Delta_{\textrm{c,LocalAgg}}=\max_{j\in\mathcal{S}_c} \{ M\times Q/R_{j}^{(t)}\}$ is the communication delay of performing local aggregation via device $j\in\mathcal S_c$.\footnote{The device-to-edge server communications are assumed to occur in parallel, using multiple access techniques such as FDMA.}
% The edge server waits for the reception of ML models from all its associated devices before performing a local aggregation.}  
$\Delta_{\textrm{GlobAgg}}=\max_{i\in\mathcal I}\{\Delta_k / R(\xi_i^{(t)})\}$ is the device-to-main server communication delay, where $\Delta_k$ denotes the round-trip delay measured in terms of the number of conducted SGDs and $R(\xi_i^{(t)})$ denotes the processing rate (the number of SGDs conducted at each time instance measured in seconds) at edge device $i$. 

In $\bm{\mathcal{P}}$, $\vert\mathcal{A}_{\{c,k\}}\vert$ is the number of local aggregations performed by devices $i\in\mathcal S_c$ within a period of local model training interval, which we obtain as $\mathcal{A}_{\{c,k\}} = \{t\in\mathcal T_k:  \sum\limits_{c=1}^N\varrho_c(1-\Theta_c^{(t)})(2\delta_c^2+4\omega_c^2\beta^2\Vert\bar{\mathbf v}_c^{(t)}-\mathbf w^*\Vert^2)>\phi^2 \}$ (see Assumption~\ref{assump:sub_err}). To obtain $\mathcal{A}_{\{c,k\}}$ we thus need to control $\Vert\bar{\mathbf v}_c^{(t)}-\mathbf w^*\Vert^2$, to monitor the value of which, we first approximate it as $\Vert\bar{\mathbf v}_c^{(t)}-\mathbf w^*\Vert^2\approx\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert^2$. Then, during each local aggregation, the edge server estimates the upper bound on $\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert^2$ using strong convexity of $F(\cdot)$ (i.e., $\Vert\nabla F(\bar{\mathbf w}_c^{(t)})\Vert^2 \geq \mu^2\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert^2$). 
% The decision variables for the $k$-th local model training interval in $(\bm{\mathcal{P}})$ are obtained using the estimated values of $\Vert\nabla F(\bar{\mathbf w}_c^{(t)})\Vert^2,~\forall t\in\mathcal{T}^\mathsf{L}_{k-1,c}$ from the previous interval.
Finally, $\nu(\tau,\alpha)=2Y_1^2 \eta_K+2Y_3^2\eta_K^2$ denotes the optimality gap upper bound derived in Theorem~\ref{thm:subLin_m} at time $t_K=T$. To compute $Y_3$, we first approximate $e_3^{(0)}\approx\mathbb \Vert\bar{\mathbf w}^{(0)}-\mathbf w^*\Vert$, and then estimate its using its upper bound $\left\Vert\nabla F(\bar{\mathbf w}^{(0)})\right\Vert \geq \mu\Vert\bar{\mathbf w}^{(0)}-\mathbf w^*\Vert$.
% Also, constraint~\eqref{eq:bound_min} guarantee a feasible value for the optimality gap.
% is the sum of the upper bounds on $e_1^{(T)}$, $e_2^{(T)}$ and $e_3^{(T)}$ after expanding the recurrence relationship from the nth term to the $K$-th term. Note that the bound in Theorem~\ref{thm:subLin_m} is not applied in the optimization since 

\textbf{Constraints.}
% The objective function of $\bm{\mathcal{P}}$ captures a tradeoff between $(a)$ energy consumption, $(b)$ communication delay, and $(c)$ the expected ML model performance, with $c_1$, $c_2$, $c_3\geq 0$ weighting coefficients. 
% In $(a)$, we account for the total amount of transmission power to perform local and global aggregation;
% in $(b)$, we consider the transmission delay for conducting local aggregation $\Delta_{c,\textrm{LocalAgg}}$, whereas we consider the propagation delay in the edge-to-cloud link for performing global aggregation $\Delta_{\textrm{GlobAgg}}$.
% Note that the reason to neglect the transmission delay for performing global aggregations is due to the fact that, in the system model, we assume device-to-edge links have much shorter range than the edge-to-cloud links such that the propagation delay becomes a dominant portion of the communication delay. Therefore, we neglect the transmission delay in device-to-edge links for global aggregations in the objective function.
% Term $(c)$ is the upper bound of the expected optimality gap derived in Theorem~\ref{thm:subLin_m}. 
% A smaller value of $(c)$ corresponds to a smaller optimality gap, implying a better ML performance. 
% Note that the optimization formulation $(\bm{\mathcal{P}})$ is solved at $t=t_k-\Delta_{k-1}^{\mathsf{D}}$ at the main server, which
% obtains the values of $\tau$ and $\alpha$ assuming that these values will be used for the rest of the training period (i.e., $\tau_{k'}=\tau$ and $\alpha_{k'}=\alpha,~\forall k'\geq k$ given the current edge-to-cloud communication delay $\Delta = \Delta_k$).
% accounts for the assumptions imposed in the convergence analysis by having a fixed value of $\tau=\tau_k$ and $\alpha=\alpha_k,~\forall k$ via optimizing the performance metrics over the remaining model training time based on a given edge-to-cloud communication delay $\Delta = \Delta_k,~\forall k$. Upon doing so, the formulation inherently assumes that the optimization variables $\tau_k$ and $\alpha_k$ along with the delay $\Delta_k$ are fixed over the remaining period from $t_{k-1}$ to $T$.
The constraint in~\eqref{eq:tauMax} guarantees that the value of $\tau_k$ is larger than the edge-to-main server communication delay, matching our assumption in Sec.~\ref{subsec:syst3}.
Constraint~\eqref{eq:bound_alpha} is a condition on $\alpha$ described in Theorem~\ref{thm:subLin_m} and ensures that the value of $\alpha$ lies within a range to guarantee the sublinear convergence of the global deployed model.
% via using the Polyak-Lojasiewicz (PL) inequality $\left\Vert\nabla F(\widehat{\mathbf w}^{(t)})\right\Vert^2 \geq 2\mu [F(\widehat{\mathbf w}^{(t)})-F(\mathbf w^*)]$.
% Also, constraint~\eqref{eq:bound_min} guarantee a feasible value for the optimality gap.

\textbf{Solution.} Formulation $\bm{\mathcal{P}}$ is a non-convex  mixed-integer programming problem. Due to the complex nature of the problem, we solve it via exhaustive search, performing line search over the integer values of $\tau$ in the range given in~\eqref{eq:tauMax} and obtain the optimum of $\alpha\in(0,1]$ corresponding to each value of $\tau$. Note that, given a value of $\tau$,  $\bm{\mathcal{P}}$  is still non-convex with respect to  $\alpha$. Therefore, we discretize the search space of $\alpha$ and perform a line search over the discretized search space of $\alpha$ for each $\tau$. Based on this approach, the search space of $\bm{\mathcal{P}}$ remains to be small due to the limited ranges/choices of $\tau$ and $\alpha$ (i.e., the time complexity of performing line search over $\tau$ is $\mathcal O(T-t_{k}-\Delta_{k-1})$ and the time complexity of performing line search over $\alpha$ is $\mathcal O( 1/S_{\alpha})$, where $S_{\alpha}$ is the discretization step used to discretize  $(0,1]$ interval, resulting in a time complexity of $\mathcal O((T-t_{k}-\Delta_{k-1})\times1/S_{\alpha})$). Thus, we are able to  solve the problem via a reasonable precision (e.g., $S_{\alpha}=0.01$) in a short duration of time (e.g., less than $3$ seconds on a laptop with Intel(R) Xeon(R) Gold 6242 CPU @ 2.80GHz).
\subsection{{\tt DFL} Control Algorithm}
\label{ssec:control}
The procedure of the {\tt DFL} control algorithm is outlined in Algorithm~\ref{GT}, which integrates the procedures described in Sec.~\ref{subsec:learniParam} and~\ref{subsec:learnduration}. 
% \clearpage

\begin{algorithm}[H]
{\scriptsize 
\SetAlgoLined
\caption{{\tt DFL} with adaptive control parameters.} \label{GT}
% \KwResult{Write here the result }
\KwIn{Desirable subnet deviation error coefficient $\phi$, length of model training $T$} 
\KwOut{Global model $\bar{\mathbf w}^{(T)}$}
% // Start of initialization by the main server\\
 Initialize $\bar{\mathbf w}^{(0)}$ and broadcast it among the edge devices through the edge server.\\
 Initialize estimates of $\zeta \ll 2\beta,\delta,\sigma$.\\
 Initialize $\eta_{max}<\min\left\{\frac{2}{\beta+\mu},\frac{(\tau-\Delta)\mu}{\beta^2[(1+\lambda_+)^{\tau}-1-\tau\lambda_+]}\right\}$ and $\gamma$ for the step size $\eta_k=\frac{\eta_{max}}{1+\gamma k}$ according to Sec.~\ref{subsec:learniParam}.\\ 
%  and $\Lambda, \gamma,\xi, T$ satisfy~\eqref{46}.\\
%  Obtain $\phi^{\mathsf{max}}$ from~\eqref{47}.\\
 % Initialize $\tau_0$ randomly, where $\tau_0\leq T-t_{k-1}.~\forall k$.\\
%  \textbf{Initialization by the server:} 
Initialize $t=0, ~k=0,~ t_0=0, ~t_1=\tau_0$, with $\tau_0$ chosen randomly, such that $\tau_0\leq T-t_{k},~\forall k$.\\ 
% // End of initialization by the main server\\
 \While{$t\leq T$}{
     \While{$t\leq t_{k+1}$}{
        \For( // Operation at the subnets){$c=1:N$}
        {
         Each device $i\in\mathcal{S}_c$ performs a local SGD update based on~\eqref{eq:SGD} and~\eqref{8} using $\mathbf w_i^{(t-1)}$ to obtain~$\widetilde{\mathbf{w}}_i^{(t)}$.\\
        %  with:\\
        %   $\widetilde{\mathbf w}_i^{(t)} = 
        %   \mathbf w_i^{(t-1)}-\eta_{t-1} \widehat{\mathbf g}_{i}^{(t-1)}$\; 
        % Devices estimate the value of $\Upsilon^{(t)}_c$ using~\eqref{eq:Ups_est} with distributed message passing.\\
        \uIf{$t\in\mathcal T^\mathsf{L}_{k,c}$}{
        Devices inside the subnet conduct local model aggregation using~\eqref{eq:local_agg} to obtain the updated local model $\mathbf w_i^{(t)}$.
        }
        \uElseIf{$t=t_{k+1}$}{
        Devices inside each subnet perform global synchronization using~\eqref{eq:aggr_alpha}.
        }
        \Else{
        Each device $i\in\mathcal{S}_c$ obtains its updated local model as $\mathbf{w}_i^{(t)} = \widetilde{\mathbf{w}}_i^{(t)}$
        }
      }
      \uIf( // Operation at the edge server){$t=t_{k+1}-\Delta_k$}{
      % // Operation at the edge server\\
    %   Each edge server $n_c$ estimates the local SGD noise 
    %   as described in Sec.~\ref{subsub:estparam}.\\
      Each edge server $n_c$ sends $\mathbf w_{i}^{(t_{k+1}-\Delta_k)}$, $\widehat{\mathbf g}_{i}^{(t_{k+1}-\Delta_k)},~\forall i\in\mathcal S_c$ to the main server.\\
    %   and the estimated local SGD noise to the main server. \\
    %  Solve Problem $(\bm{\mathcal{P}})$ to obtain $\tau_{k+1}$, and set $t_{k+1}=t+\tau_{k+1}$\\
    %  Compute $\Xi^{(k)}$ using~\eqref{eq:Xi_est} and set $\mu=\min\{ \}_{k'=1}^{k}$, and $\beta=\max\{ \}_{k'=1}^{k}$
       }
    \ElseIf( // Operation at the main server){$t=t_{k+1}-\Delta_k^{\mathsf{D}}$}{
    % // Operation at the main server\\
    %   Estimate $\delta$\;
      Compute $\bar{\mathbf w}^{(t_{k+1}-\Delta_k)}$ according to~\eqref{15}, $\hat{\beta}_k$, $\hat{\mu}_k$, $\hat{\sigma}_k$.\\ 
      % using \eqref{15},~\eqref{eq:est_beta},~\eqref{eq:est_mu} and~\eqref{eq:est_sigma}.\\
      % Compute $\hat{\beta}_k$ using~\eqref{eq:est_beta}.\\ 
      % Compute $\hat{\mu}_k$ using~\eqref{eq:est_mu}.\\
      % Compute $\hat{\Psi}_k$ using~\eqref{eq:est_psi}.\\
      Set $\hat{\zeta}_k\ll 2\hat{\beta}_k$ and $\hat{\zeta}_{c,k}\ll 2\hat{\beta}_k$, then compute $\hat{\delta}_k$ and $\hat{\delta}_{c,k}$ using the method in~\cite{lin2021timescale}. \\ 
      % via~\eqref{eq:grad_div_est} and~\eqref{eq:est_delta_c}. \\
      % Set $\hat{\zeta}_{c,k}\ll 2\hat{\beta}_k$, and compute $\hat{\delta}_{c,k}$ via~\eqref{eq:est_delta_c}. \\
      % Compute $\hat{\sigma}_k$ using~\eqref{eq:est_sigma} 
      Characterize $\eta_{max}$ and $\gamma$ for the step size $\eta_k=\frac{\eta_{max}}{1+\gamma k}$ according to Sec.~\ref{subsec:learniParam}.\\
    %  Compute the value of $\alpha$ by (to be determined)\\
     Compute the instances of local aggregation for each cluster $c$ using Sec.~\ref{subsec:learnduration}.\\
     Solve the optimization~$\bm{\mathcal{P}}$ to obtain $\tau_{k+1}$ and $\alpha_{k+1}$.\\
     Broadcast (i) $\bar{\mathbf w}^{(t_{k+1}-\Delta_k)}$, (ii) $\alpha_{k+1}$ and (iii) $\eta_k$ among the devices.
    }
     $t\gets t+1$
 }
 $k\gets k+1$ and $t_{k+1}\gets t_k+\tau_k$\\
}
}
\end{algorithm}

\iffalse
\textbf{Obtaining Tractable Solutions.}
Let the subnet deviation error coefficient $\phi$ be a desirable value chosen based on the learning application and consider the expression for $\nu$ in Theorem~\ref{thm:subLin}, the instances of local aggregations are obtained based on the condition $(\epsilon^{(t)})^2=\eta_t\phi$ imposed in Theorem~\ref{thm:subLin} along with applying the bound on $(\epsilon^{(t)})^2$ derived in Proposition~\ref{prop:clust_div_mn}. Note that the expression for $(\epsilon^{(t)})^2$ depends upon $\mathbb E\Vert\bar{\mathbf w}_c^{(t-t')}-\mathbf w^*\Vert$, where $t-t'$ is the instance of conducting local aggregation. Although the value of the optimum $\mathbf w^*$ is unknown, each edge server can still apply Proposition~\ref{prop:clust_div_mn} to determine the time instances and total number of local aggregation in a local model training interval via replacing the estimation of $\mathbb E\Vert\bar{\mathbf w}_c^{(t-t')}-\mathbf w^*\Vert$ in the expression of $(\epsilon^{(t)})^2$ with $\mathbb E\big\Vert\nabla F(\bar{\mathbf w}_c^{(t-t')})\big\Vert/\mu$, which is an upper bound of $\mathbb E\Vert\bar{\mathbf w}_c^{(t-t')}-\mathbf w^*\Vert$ that can be obtained via applying the property of strong convexity on $F(\cdot)$, i.e., $\big\Vert\nabla F(\bar{\mathbf w}_c^{(t)})\big\Vert \geq \mu \Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert$. Note that the decision for determining the first instance of local aggregation is conducted 
during global aggregation, whereas the decision of the following instance of local aggregations is performed at its precedent local aggregations. Therefore, we will use the value of $\mathbb E\Vert\bar{\mathbf w}_c^{(t_k-\Delta_k)}-\mathbf w^*\Vert$ as the estimate for $\mathbb E\big\Vert\nabla F(\bar{\mathbf w}_c^{(t-t')})\big\Vert/\mu$ to determine the first instance of local aggregation in $\mathcal T_k$ and $\mathbb E\big\Vert\nabla F(\bar{\mathbf w}_c^{(t-t')})\big\Vert/\mu$ as the estimate of $\mathbb E\Vert\bar{\mathbf w}_c^{(t-t')}-\mathbf w^*\Vert$ to determine the rest local aggregation instances.
\fi

 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \addFL{Finally, we are going to describe Part C}
% In this section, we describe the design of the two-phase adaptive control algorithm {\tt DFL} based on the results obtained from Theorem \ref{thm:subLin} in Section III. In phase I, we design an parameter estimation scheme to estimate the value for defining the characteristics of the loss function (i.e. $\beta,\mu$), gradient diversity (i.e. $\delta,\zeta$) and upper bound on the variance of the estimated gradient used in SGD (i.e. $\sigma$). 
% the convergence parameters (i.e. $\Gamma,\gamma$) and the initial value on the length of the 1-st \emph{local model training interval} (i.e. $\tau_1$).
% In phase II, we develop an adaptive control scheme for {\tt DFL} that adaptively tunes the step size, length of the local model training interval and the number of D2D rounds through time using the parameters estimated in the first phase.

% According to \eqref{cond1}, \eqref{cond2} and \eqref{cond3}, the tuning of learning parameters requires the knowledge on the upper bound of (A.) parameter divergence $\Upsilon_c(k)$ to satisfy the condition provided by Proposition \ref{genLin} and \ref{strLin}. Therefore, we first derive an adaptive estimation for the divergence of parameters in a distributed manner for every local iteration $t$. 


% \begin{algorithm}
% \small
% \SetAlgoLined
% \caption{Two Timescale Hybrid Federated Learning ({\tt \DFL})-Phase I} \label{GT}
% % \KwResult{Write here the result }
% \KwIn{$K$} 
% \KwOut{Global model $\hat{\mathbf w}(t_K)$}
%  \textbf{Initialization operated by the server:} (i) Initialize the local model as $\mathbf w_i(0)=\hat{\mathbf w}(0),\  \forall i$, (ii) Set the step size as \add{$\eta_t=\frac{\gamma}{t+\alpha}$}, where $\alpha=\max\{\beta\gamma/\kappa, \beta\gamma\big[1-\kappa/4+\sqrt{(1+\kappa/4)^2+2\omega}\big]\}$\;
%  \For{$k=1:K$}{
%      \For{$t=t_{k-1}+1:t_k$}{
%       \uIf{$t=t_k$}{
%       Estimate $\hat{\beta}\leftarrow\sum_{c=1}^N \varrho_c^{(k)}\hat{\beta}_i$\;
%       Estimate $\hat{\mu}\leftarrow\sum_{c=1}^N \varrho_c^{(k)}\hat{\mu}_i$\;
%       Estimate $\delta,\zeta\leftarrow\Vert\nabla F(\hat{\mathbf w}(t_k))-\nabla F_i(\hat{\mathbf w}(t_k))\Vert$\;
%     %   Estimate parameter for the variance of SGD $\sigma$\;
%       Compute $\hat{\mathbf w}(t)$ with \eqref{15} at the server\;
%       Synchronize local models with the global model $\mathbf w_i(t)=\hat{\mathbf w}(t),~\forall i$ //Global Synchronization\;
%         % \uIf{$\tau_{k+1}>\log_4\left\{(\mu\gamma-1)\kappa/(16\omega^2\beta^2\gamma^2)\right\}$} 
%         % {
%         % $\tau_{k+1} = \tau_{k+1}/2$ // The initial choice of $\tau_{k+1}$ could not be satisfied\;
%         % }
%         % \Else{
%         % Tune the number of D2D consensus such that \\
%         % $\tau_k \leq \log_4\left\{[(\mu\gamma-1)\nu-B]/[\gamma^2\beta A/2 +16\omega^2\beta^2\gamma^2(\Gamma-\phi^2\gamma/2)/\kappa]\right\}$ is satisfied\;
%         % }
%           }
%     \Else{
%       For each edge device $i$ in parallel, perform local update with\\
%       $\mathbf w_i(t+1) =  
%           \mathbf w_j(t)-\eta_t\nabla F_j(\mathbf w_j(t))$\;
%           \uIf{$\hat{\mu}_i>(\nabla F_i(\mathbf w _i(t))-\nabla F_i(\hat{\mathbf w}(t_{k-1})))^\top(\mathbf w _i(t)-\hat{\mathbf w}(t_{k-1}))/\Vert\mathbf w _i(t)-\hat{\mathbf w}(t_{k-1})\Vert^2$}
%           {Estimate $\hat{\mu}_i\leftarrow(\nabla F_i(\mathbf w _i(t))-\nabla F_i(\hat{\mathbf w}(t_{k-1})))^\top(\mathbf w _i(t)-\hat{\mathbf w}(t_{k-1}))/\Vert\mathbf w _i(t)-\hat{\mathbf w}(t_{k-1})\Vert^2$\;
%           }
%           \uIf{$\hat{\beta}_i<\Vert\nabla F_i(\mathbf w _i(t))-\nabla F_i(\hat{\mathbf w}(t_{k-1}))\Vert/\Vert\mathbf w _i(t)-\hat{\mathbf w}(t_{k-1})\Vert$}
%           {
%           Estimate $\hat{\beta}_i\leftarrow\Vert\nabla F_i(\mathbf w _i(t))-\nabla F_i(\hat{\mathbf w}(t_{k-1}))\Vert/\Vert\mathbf w _i(t)-\hat{\mathbf w}(t_{k-1})\Vert$\;
%           }
%           \uIf{$\hat{\tilde{\beta}}_i<\Vert\nabla \hat{f}(\mathbf x_{i,b};\mathbf w_i(t))-\nabla \hat{f}(\mathbf x_{i,b'};\mathbf w_i(t))\Vert/\Vert\mathbf x_{i,b}-\mathbf x_{i,b'}\Vert$}
%           {
%           Estimate $\hat{\tilde{\beta}}_i\leftarrow\Vert\nabla F_i(\mathbf w _i(t))-\nabla F_i(\hat{\mathbf w}(t_{k-1}))\Vert/\Vert\mathbf w _i(t)-\hat{\mathbf w}(t_{k-1})\Vert$\;
%           }
%       }
%      }
%  }
%  Estimate $\hat{\sigma}_i^2 
% \leftarrow
% \Big(1-\frac{\vert\xi_i^{(t)}\vert}{D_i}\Big)\frac{\tilde{\beta}^2}{D_i}
% \frac{\sum_{b=1}^{D_i}\sum_{b'=1}^{D_i}\Vert b-b'\Vert^2}
% {\vert\xi_i^{(t)}\vert(D_i-1)}$\;
% \end{algorithm}

\iffalse
\subsection{Data and Model-Related Parameters ($\beta, \mu, \delta, \zeta, \delta_c, \zeta_c, \sigma^2$)} \label{subsub:estparam}
% In Phase I, we perform several rounds of the standard federated averaging {\tt FedAvg} \cite{McMahan} and estimate the parameters throughout the training process. {\tt FedAvg} generally consist of three steps repeated in sequence: (i) several iterations of parallel, local model training at each device using their own local datasets, (ii) aggregation of the local models at an edge server into a single, global model, and (iii) synchronization of the local models at each device with this global model. During the training process, we continuing to estimate $\beta,\mu,\delta,\zeta$ and $\sigma$ with the local and global models. After several rounds of training, we obtain the estimated value of all the parameters, and use them for the scheme in Phase II. The estimation scheme for each of the parameters is demonstrated as follows. In the following, we use the same notations for the system model of {\tt \DFL} as described in Section II:

We next aim to estimate the values of parameters used to describe the loss function (i.e. $\beta,\mu$), gradient diversity (i.e. $\delta,\zeta$, $\delta_c$, $\zeta_c$), and the variance of the stochastic gradients used during SGD iterations (i.e. $\sigma^2$). These parameters are estimated  at the main server based on the ML parameters of the devices transmitted at each $t=t_{k+1}-\Delta_k,~\forall k$.
% at each $t=t_k-\Delta_k^{\mathsf{D}},~\forall k$ of each global aggregation with parameters estimations obtained from

%We first overview the estimation method of the ML parameters and the divergence of local models inside the clusters, using which we develop our control algorithm for {\tt \DFL} that dynamically tunes the number of D2D communication rounds and obtains the length of interval of local model training.
\subsubsection{Estimation of $\mu$}
The main server estimates the value of $\mu$ according  to the strong convex property of $F(\cdot)$ given in~\eqref{eq:11_mu}, which can be equivalently expressed as 
$
\exists \mu>0: \Big\Vert \nabla F(\mathbf w_1)-\nabla F(\mathbf w_2)\Big\Vert \geq \mu\Big\Vert \mathbf w_1-\mathbf w_2 \Big\Vert,~\forall \mathbf w_1, \mathbf w_2.
$
To this end, 
the main server uses the received local models and gradients  to acquire the estimate of $\mu$ denoted by $\hat{\mu}_k$ as follows: 
{\small\begin{align} \label{eq:est_mu}
    \hat{\mu}_k = \min_{i,j\in\mathcal I}\left\{\big\Vert\sum_{c=1}^N\varrho_c\sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)}-\sum_{c=1}^N\varrho_c\sum_{j\in\mathcal S_c}\rho_{j,c}\widehat{\mathbf g}_{j}^{(t_{k}-\Delta_k)}\big\Vert/\Vert\mathbf w_i^{(t_{k}-\Delta_k)}-\mathbf w_j^{(t_{k}-\Delta_k)}\Vert\right\}.
\end{align}}


% as the candidates for $\hat{\mu_i}$ at every edge device $i$. The smallest value of candidates estimated at every edge device $i$ throughout the entire training process will be chosen as $\hat{\mu_i}$. Then, we compute $\hat{\mu}\leftarrow\sum_{c=1}^N \varrho_c^{(k)}\hat{\mu}_i$ as the estimate for $\mu$. 

\subsubsection{Estimation of $\beta$}
The main server estimates the value of $\beta$ using the $\beta$-smoothness property of $F_i(\cdot)$ expressed in Assumption \ref{beta} via~\eqref{eq:11_beta}. To this end, the main server uses the received local models and gradients to estimate $\beta$ as follows: 
 \begin{align} \label{eq:est_beta}
     \hat{\beta}_k = \max_{i,j\in\mathcal I}\left\{ \Vert\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)}-\widehat{\mathbf g}_{j}^{(t_{k}-\Delta_k)}\big\Vert/\Vert\mathbf w_i^{(t_{k}-\Delta_k)}-\mathbf w_j^{(t_{k}-\Delta_k)}\Vert\right\}.
 \end{align}
 
%  \subsubsection{Estimation of $\Psi$} To estimate the value of $\Psi$, denoted by $\hat{\Psi}_k$, we first upper bound the optimality gap of the ML model with 
% $\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert \leq \Vert\nabla F(\bar{\mathbf w}^{(t)})\Vert$ and apply it into the result in Proposition~\ref{prop:clust_div_mn} to get
% \begin{align}
%      &\mathbb E\left[\sum\limits_{c=1}^N\varrho_{c}\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2\right] + \mathbb E[\Vert\bar{\mathbf w}^{(t)}-\mathbf w^*\Vert^2] 
%      \nonumber \\&
%      \leq  
%      \mathbb E\left[\sum\limits_{c=1}^N\varrho_{c}\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2\right] + \mathbb E[\Vert\nabla F(\bar{\mathbf w}^{(t)})\Vert^2] \approx \Psi.  
% \end{align}
%     By using $\sum_{n_c\in\mathcal N}\varrho_c\Vert\bar{\mathbf w}_c^{(t_k-\Delta_k)}-\bar{\mathbf w}^{(t_k-\Delta_k)}\Vert^2$ and $\Big\Vert\sum_{n_c\in\mathcal{N}}\varrho_c\sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)}\Big\Vert$ as the estimate for $\mathbb E\Big[\sum_{n_c\in\mathcal N}\varrho_c\Vert\bar{\mathbf w}_c^{(t)}-\bar{\mathbf w}^{(t)}\Vert^2\Big]$ and $\mathbb E[\Vert\nabla F(\bar{\mathbf w}^{(t)})\Vert^2]$, respectively, the main server estimates the value of $\Psi$ as follows:
% \begin{align} \label{eq:est_psi}
%     \hat{\Psi}_k = \max_{k'\in\{1,\cdots,k\}}\Big\{\sum_{n_c\in\mathcal N}\varrho_c\Vert\bar{\mathbf w}_c^{(t_k-\Delta_k)}-\bar{\mathbf w}^{(t_k-\Delta_k)}\Vert^2+\Big\Vert\sum_{n_c\in\mathcal{N}}\varrho_c\sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)}\Big\Vert^2\Big\}.
% \end{align}

%  $\Vert\nabla F_i(\mathbf w _i(t))-\nabla F_i(\hat{\mathbf w}(t_{k-1}))\Vert/\Vert\mathbf w _i(t)-\hat{\mathbf w}(t_{k-1})\Vert,~t\in\mathcal{T}_k$ as the candidates for $\hat{\mu_i}$ at every edge device $i$. The largest value of candidates estimated at every edge device $i$ throughout the entire training process will be chosen as $\hat{\beta}_i$. Then, we compute $\hat{\beta}\leftarrow\sum_{c=1}^N \varrho_c\hat{\beta}_i$ as the estimate for $\beta$.
\subsubsection{Estimation of $\delta,\zeta$}
To estimate the values of $\delta,\zeta$, we first upper bound the gradient diversity in Definition \ref{gradDiv} as 
\begin{align} \label{eq:grad_div_est}
    \Vert\nabla\bar F_c(\mathbf w)-\nabla F(\mathbf w)\Vert
    \leq \delta+ \zeta \Vert\mathbf w-\mathbf w^*\Vert 
    \leq \delta+ \zeta/\mu \Vert\nabla F(\mathbf w)\Vert,~\forall c, \mathbf w
\end{align}
via applying the strongly convex property of $F(\cdot)$, i.e., $\big\Vert\nabla F(\mathbf w)\big\Vert \geq \mu \Vert\mathbf w-\mathbf w^*\Vert$. Based on~\eqref{eq:grad_div_est}, to obtain the estimates of $\delta$ and $\zeta$ denoted by $\hat{\delta}_k$ and $\hat{\zeta}_k$, we first select an arbitrary value of $\hat{\zeta}_k$ such that $\hat{\zeta}_k\ll 2\hat{\beta}_k$ and obtain $\hat{\delta}_k$ via computing an estimate for $\Vert\nabla\bar F_c(\mathbf w)-\nabla F(\mathbf w)\Vert$ and $\Vert\nabla F(\mathbf w)\Vert$, which can be obtained using the received local gradients (i.e., $\Big\Vert\sum_{n_c\in\mathcal{N}}\varrho_c\sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)} - \sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)}\Big\Vert$ and $\Big\Vert\sum_{n_c\in\mathcal{N}}\varrho_c\sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)}\Big\Vert$) as follows: 
\begin{align}
    \hat{\delta}_k = 
    \left[\max_{n_c\in\mathcal{N}}\left\{\Big\Vert\sum_{n_c\in\mathcal{N}}\varrho_c\sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)} - \sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)}\Big\Vert - \hat{\zeta}_k/\hat{\mu}_k\Big\Vert\sum_{n_c\in\mathcal{N}}\varrho_c\sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)}\Big\Vert\right\}\right]^+,
\end{align}
where notation $[A]^+\triangleq \max\{A,0\}$, $A\in \mathbb{R}$.
% where we use $\Big\Vert\sum_{c=1}^N\varrho_c\sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)} - \sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)}\Big\Vert$ and $\Big\Vert\sum_{c=1}^N\varrho_c\sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)}\Big\Vert$ as the estimates for $\Vert\nabla\bar F_c(\mathbf w)-\nabla F(\mathbf w)\Vert$ and $\Vert\nabla F(\mathbf w)\Vert$ respectively.

\subsubsection{Estimation of $\delta_c,\zeta_c$}
Similarly, to estimate the values of $\delta_c,\zeta_c$ denoted by $\hat{\delta}_{c,k}$ and $\hat{\zeta}_{c,k}$, we first upper bound the gradient diversity in Definition \ref{gradDiv_c} as 
\begin{align} 
    \left\Vert\nabla F_i(\mathbf w)-\nabla\bar F_c(\mathbf w)\right\Vert
    \leq \delta_c+\zeta_c\Vert\mathbf w-\mathbf w^*\Vert
    \leq \delta_c+\zeta_c/\mu \Vert\nabla F(\mathbf w)\Vert,~\forall i\in\mathcal{S}_c,  ~\forall c, \mathbf w.
\end{align}
% via applying the strongly convex property of $F(\cdot)$, i.e., $\big\Vert\nabla F(\mathbf w)\big\Vert \geq \mu \Vert\mathbf w-\mathbf w^*\Vert$. 
By choosing the value of $\hat{\zeta}_{c,k}$ such that $\hat{\zeta}_{c,k}\ll2\beta$ along with using $\Big\Vert\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)} - \sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)}\Big\Vert$ and $\Big\Vert\sum_{n_c\in\mathcal{N}}\varrho_c\sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)}\Big\Vert$ as the estimates for $\Vert\nabla F_i(\mathbf w)-\nabla\bar F_c(\mathbf w)\Vert$ and $\Vert\nabla F(\mathbf w)\Vert$ respectively, we can estimate the value of $\delta$ as follows:
\begin{equation} \label{eq:est_delta_c}
    \hat{\delta}_{c,k} = 
    \left[\max_{i\in\mathcal{S}_c}\left\{\Big\Vert\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)} - \sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)}\Big\Vert-\hat{\zeta}_{c,k}/\hat{\mu}_k\Big\Vert\sum_{n_c\in\mathcal{N}}\varrho_c\sum_{i\in\mathcal S_c}\rho_{i,c}\widehat{\mathbf g}_{i}^{(t_{k}-\Delta_k)}\Big\Vert\right\}\right]^+,
\end{equation}
where $\hat{\delta}_{c,k}$ is the estimated value for $\delta_c$.

\subsubsection{Estimation of $\sigma^2$}
% From Assumption~\ref{assump:SGD_noise}, a simple way of obtaining the value of $\sigma^2$ would be comparing the gradients from sampled devices with their full-batch counterparts. But this might be impractical if the local datasets $\mathcal{D}_i$ are large. Thus, we propose an approach where $\sigma^2$ is computed at each device through two independent mini-batches of data. Recall $|\xi_i|$ denotes the mini-batch size used at node $i$ during the model training.
At each instance of global aggregation, the edge servers collects the local gradients at $t=t_{k}-\Delta_k$. Since $\hat{\mathbf  g}_i^{(t_k-\Delta_k)}= \nabla F_i(\mathbf w^{(t_k-\Delta_k)})+\mathbf n_i^{(t_k-\Delta_k)}$, $\hat{\mathbf g}_j^{(t_k-\Delta_k)}= \nabla F_j(\mathbf w^{(t_k-\Delta_k)}) +\mathbf n_j^{(t_k-\Delta_k)},~\forall i\neq j$, we use the fact that $\mathbf n_i^{(t_k-\Delta_k)}$ and $\mathbf n_j^{(t_k-\Delta_k)}$ are independent random variables with $\mathbb E_t[\mathbf n_i^{(t_k-\Delta_k)}]=\mathbb E_t[\mathbf n_j^{(t_k-\Delta_k)}]\leq\sigma^2$, and thus $\mathbb E_t\Vert \hat{\mathbf  g}_i^{(t_k-\Delta_k)}-\hat{\mathbf  g}_j^{(t_k-\Delta_k)} \Vert^2 = \mathbb E_t\Vert \mathbf n_i^{(t_k-\Delta_k)} - \mathbf n_j^{(t_k-\Delta_k)} \Vert^2 \leq  2\sigma^2,~\forall i\neq j$. The estimation of $\sigma^2$ denoted by $\hat{\sigma}^2_k$ can then be obtained as follows:
\begin{align} \label{eq:est_sigma}
    \hat{\sigma}^2_k = \max_{i,j\in\mathcal I}\big\{\Vert\hat{\mathbf  g}_i^{(t_k-\Delta_k)}-\hat{\mathbf  g}_j^{(t_k-\Delta_k)}\Vert^2/2\big\}.
\end{align}
\fi


\iffalse
\textbf{Estimation of $\delta,\zeta,\sigma^2$:}\label{subsub:estparam} 
These parameters can be estimated by the main server during model training. The server can estimate $\delta$ and $\zeta$ at each global aggregation by receiving the latest gradients from SGD at the sampled devices. $\sigma^2$ can first estimated locally at the sampled devices, and then decided at the main server.



% where the main server broadcasts a few test global parameters $\mathbf{w}^{(1)},\cdots,\mathbf{w}^{(n)}$ and receives the corresponding local gradient from the nodes. 
 
% \begin{align}
%         \exists \beta>0: \Big\Vert \nabla F_i(\mathbf w_1)-\nabla F_i(\mathbf w_2)\Big\Vert \leq & \beta\Big\Vert \mathbf w_1-\mathbf w_2 \Big\Vert,~\forall i, \mathbf w_1, \mathbf w_2.
% \end{align}
%     where $\mathbf x_{i,b}\in\mathcal{D}_i,~\forall i,b$.
% During the training phase of {\tt FedAvg}, we collect the global model at the beginning of each \emph{local model training interval} at $t_{k-1}$, and 
% continually calculate 




% The 
% estimation of $\beta$ and $\mu$ can be conducted at via computing
% \begin{equation} \label{eq:Xi_est}
%   \hspace{-3mm} \begin{aligned}
%         &\Xi{(k',k'')}
%       = \frac{\left\Vert\sum\limits_{i=1}^I \varrho_i\widehat{\mathbf g}_{i}^{(k')}-\sum\limits_{i=1}^I \varrho_i\widehat{\mathbf g}_{i}^{({k''})}\right\Vert}{\left\Vert{\mathbf w}^{({k'})}-{\mathbf w}^{({k''})}\right\Vert}, 1\leq  k'\neq k''\leq n,
%     \end{aligned} \hspace{-3mm} 
% \end{equation}
% and saving the maximum values among $\Xi{(.,.)}$-s as a candidate for $\beta$ and the minimum value among $\Xi{(.,.)}$-s as a candidate for $\mu$. In~\eqref{eq:Xi_est}, $\widehat{\mathbf g}_{i}^{(k')}$ and $\widehat{\mathbf g}_{i}^{(k'')}$ denote the local SGD at the node computed based on $\mathbf w^{(k')}$ and $\mathbf w^{(k'')}$, respectively.


% as the candidates for $\hat{\mu_i}$ at every edge device $i$. The largest value of candidates estimated at every edge device $i$ throughout the entire training process will be chosen as $\hat{\beta}_i$. Then, we compute $\hat{\beta}\leftarrow\sum_{c=1}^N \varrho_c^{(k)}\hat{\beta}_i$ as the estimate for $\beta$.
% The same procedure can be used to estimate the internal value of $mu$. These values can then be sent to the server to estimate $\beta$ and $\mu$ via averaging. 
% We estimate the value of $\mu$ by the monoticity property of strongly convex of $F_i(\cdot)$ expressed as 
% \begin{align}
%     \exists \mu>0: \mu\leq\big(\nabla F_i(\mathbf w_1)-\nabla F_i(\mathbf w_2)\big)^\top\big(\mathbf w_1-\mathbf w_2\big)/\Vert\mathbf w _1-\mathbf w_2\Vert^2,~\forall \mathbf w_1, \mathbf w_2.
% \end{align}
% During the training phase of {\tt FedAvg}, we collect the global model at the beginning of each \emph{local model training interval} at $t_{k-1}$, and continually calculate $[\nabla F_i(\mathbf w _i(t))-\nabla F_i(\hat{\mathbf w}(t_{k-1}))]^\top[\mathbf w _i(t)-\hat{\mathbf w}(t_{k-1})]/\Vert\mathbf w _i(t)-\hat{\mathbf w}(t_{k-1})\Vert^2,~t\in\mathcal{T}_k$ as the candidates for $\hat{\mu_i}$ at every edge device $i$. The smallest value of candidates estimated at every edge device $i$ throughout the entire training process will be chosen as $\hat{\mu_i}$. Then, we compute $\hat{\mu}\leftarrow\sum_{c=1}^N \varrho_c^{(k)}\hat{\mu}_i$ as the estimate for $\mu$.

Specifically, to estimate $\delta,\zeta$, since the value of $\mathbf w^*$ is not known, we upper bound the gradient diversity Definition \ref{gradDiv} by introducing a new parameter $\delta'$:
\begin{align} \label{eq:estGradDiv}
  \hspace{-3mm}  \Vert\nabla\hat F_c(\mathbf w)-\nabla F(\mathbf w)\Vert \leq \delta+ \zeta \Vert\mathbf w-\mathbf w^*\Vert \leq  \delta' + \zeta \Vert\mathbf w\Vert,  \hspace{-3mm} 
\end{align}
\nm{Instead of centering it around 0 shouldnt it be better it to center it around the global aggregation parameter? Since the latter converges to Wstar?}
where $\delta'$ satisfies $\delta'\geq \delta+\zeta\Vert\mathbf w^*\Vert$\nm{how do you satrisfy this if you dont know wstar??  You said two lines ago that you used delta prime to overcome the fact that you dont know wstar, but you still need wster here.  }. Thus, a value of $\zeta\ll 2\beta$\nm{how do you set this??} is set, and then the value of $\delta'$ is estimated using~\eqref{eq:estGradDiv}\nm{I dont undestand, how do you estimate delta' using 53 without knowing wstar?}, where the server uses the SGD gradients $\widehat{\mathbf g}_{n_c}^{(t_k)}$ from the sampled devices $n_c$ at the instance of each global aggregation $k$, and chooses the smallest $\delta'$ such that $\Vert\nabla\hat F_c(\hat{\mathbf w}^{(t_k)})-\nabla F(\hat{\mathbf w}^{(t_k)})\Vert \approx \Vert \widehat{\mathbf g}_{n_c}^{(t_k)}-\sum_{c'=1}^N \varrho_{c'}\widehat{\mathbf g}_{n_{c'}}^{(t_k)}\Vert\leq \delta'+\zeta \Vert \hat{\mathbf w}^{(t_k)}\Vert$ $\forall c$.
% instead of their full-batch counterparts

% for each instance of $k'\in\{ 1,\cdots,n\}$ the maximum among which is chosen as the final value of $\delta'$.  Given $\Vert \mathbf w^{(k')}\Vert$, the server uses the SGD values instead of full-batch counterparts: $\Vert\nabla\hat F_c(\mathbf w^{(k')})-\nabla F(\mathbf w^{(k')})\Vert \approx \Vert \widehat{\mathbf g}_{i}^{(k')}-\sum_{j=1}^I \varrho_j\widehat{\mathbf g}_{j}^{(k')}\Vert\leq \delta'+\Vert \mathbf w^{(k')}\Vert$.

% To estimate the value of SGD variance $\sigma^2$, since the estimation of full-batch gradient might be impractical due to large number of local data points, each node $i$ estimates its local SGD noise at the end of each local model training round $k$ as $\sigma^2_i=\Vert\widehat{\mathbf g}_{j}^{(t_k)}-\widetilde{\nabla F}_j(\mathbf w_{j}^{(t_k)})\Vert^2$, where $\widehat{\mathbf g}_{j}^{(t_k)}$ is the latest SGD computed at the node and $\widetilde{\nabla F}_j(\mathbf w_{j}^{(t_k)})$ is a more accurate estimation of the full-batch gradient obtained via sampling a larger number of data points as compared to the mini-batch size. These scalars are then transferred to the main server, which chooses $\sigma^2=\max\{\sigma^2_1,\cdots,\sigma^2_I\}$.

From Assumption~\ref{assump:SGD_noise}, a simple way of obtaining the value of $\sigma^2$ would be comparing the gradients from sampled devices with their full-batch counterparts. But this might be impractical if the local datasets $\mathcal{D}_i$ are large. Thus, we propose an approach where $\sigma^2$ is computed at each device through two independent mini-batches of data. Recall $|\xi_i|$ denotes the mini-batch size used at node $i$ during the model training. 
At each instance of global aggregation, the sampled devices each select two mini-batches of size $|\xi_i|$ and compute two SGD realizations $\mathbf g_1$, $\mathbf g_2$ from which $\widehat{\mathbf g}_{i}^{(t_k)} = (\mathbf g_1 + \mathbf g_2) /2$. Since $\mathbf  g_1= \nabla F_i(\mathbf w^{(t_k)})+\mathbf n_1$, $\mathbf g_2= \nabla F_i(\mathbf w^{(t_k)}) +\mathbf n_2$, we use the fact that $\mathbf n_1$ and $\mathbf n_2$ are independent random variables with the same upper bound on variance $\sigma^2$, and thus $\Vert \mathbf  g_1-\mathbf  g_2 \Vert^2 = \Vert \mathbf n_1-\mathbf n_2 \Vert^2 \leq  2\sigma^2$, from which $\sigma^2$ can be approximated locally. These scalars are then transferred to the main server, where the server chooses the maximum reported $\sigma^2$ from the sampled devices.
\fi
% \subsubsection{Estimation of $\Upsilon^{(t)}_c$}
% Based on~\eqref{eq:Updef}, we propose the following approximation to estimate the value of $\Upsilon^{(t)}_c$:
% % By Definition \ref{paraDiv} and given the conditions in XXX, since the server needs to determine the learning parameters at the beginning of global aggregation, we are interesting in approximating the prediction of $\epsilon_c(k)$ for $t\in\mathcal T_k$ by $\epsilon_c(k)$ at the beginning of the global aggregation $k$. Therefore, $\epsilon_c(k)$ is approximated as
% % \begin{align*}
% %     \epsilon_c(k) &\geq \Vert\mathbf w_i(t)-\mathbf w_j(t)\Vert
% %     \\&
% %     \geq \vert\Vert\mathbf w_i(t)\Vert-\Vert\mathbf w_j(t)\Vert\vert, ~\forall i, j\in\mathcal{S}_c^{(k)}, ~\forall t\in\mathcal T_k
% % \end{align*}
%     \begin{align} \label{eq:Ups_est}
%          \Upsilon^{(t)}_c&\approx \max_{i, j\in\mathcal{S}_c,1\leq z\leq M}\{\vert[\mathbf w_i(t)]_z-[\mathbf w_j(t)]_z\vert\} 
%     \nonumber \\ &\approx \underbrace{\max_{i\in\mathcal{S}_c} \Vert  \mathbf w_i(t)\Vert_{\infty}}_{(a)}- \underbrace{\min_{j\in\mathcal{S}_c} \Vert  \mathbf w_j(t)\Vert_{\infty}}_{(b)},~ i\neq j, 
%     % \leq \max_{i, j\in\mathcal{S}^{(k)}_c,1\leq z\leq M}\{\vert[\mathbf w_i(t)]_z\vert+\vert[\mathbf w_j(t)]_z\vert\}
%     % \nonumber \\& \leq 2\underbrace{\max_{i, j\in\mathcal{S}^{(k)}_c,1\leq z\leq M}\{\vert[\mathbf w_i(t)]_z\vert\}}_{(a)},~\forall t\in \tau_k,
%     \end{align}
% % \begin{align}
% %     \Upsilon_c(k) &\approx \max_{i, j\in\mathcal{S}_c.}\{\Vert\mathbf w_i(t)\Vert-\Vert\mathbf w_j(t)\Vert\}
% %     \\& \label{epsProx}
% %     =\underbrace{\max_{i\in\mathcal{S}_c}\Vert\mathbf w_i(t)\Vert}_{(a)}-\underbrace{\min_{j\in\mathcal{S}_c}\Vert\mathbf w_j(t)\Vert}_{(b)}, ~\forall t\in\mathcal T_k,
% % \end{align}
% where we have used the lower bound $\Vert\mathbf a - \mathbf b \Vert_{\infty} \geq \Vert\mathbf a\Vert_{\infty}-\Vert\mathbf b\Vert_{\infty}$ for vectors $\mathbf a$ and $\mathbf b$, which we experimentally observe gives a better approximation of $\Upsilon^{(t)}_c$. In~\eqref{eq:Ups_est}, $(a)$ and $(b)$ can be both obtained in a distributed manner through scalar message passing, where each device $i\in\mathcal{S}_c$ computes $\max_{1\leq z\leq M}\{\vert[\mathbf w_i(t)]_z\vert\}$ and $\min_{1\leq z\leq M}\{\vert[\mathbf w_i(t)]_z\vert\}$ and shares it with its neighbors $j \in \mathcal{N}_i$. The devices update their $\max$ and $\min$ accordingly, share these updated values, and the process continues. After the rounds of message passing has exceeded the diameter of the graph, each node has the value of $(a)$ and $(b)$, and thus the estimate of $\Upsilon^{(t)}_c$. The server can obtain these values for $t \in \mathcal{T}_k$ from the node $n_c$ it samples for cluster $c$ at $t = t_k$. %The aforementioned estimated parameters are used in our control algorithm that adaptively tunes the number of D2D communication rounds inside the clusters in a distributed manner and obtains the length of local model training intervals.
  




% The values of $\tau_{\textrm{max}}$, $\phi$ and $T$ are provided as inputs.
% }
% First, estimates of different parameters are initialized, the value of $\phi$ is determined, and the first period of model training is set (lines 2-6). Then, during the local model training intervals, in each timestep, the devices (i) compute the SGD updates, (ii) estimate the cluster model divergence, (iii) determine the instants and number of local aggregations, and (iv) conduct the consensus process with their neighboring nodes (lines 12-16).

% At global aggregation instances, the sampled devices compute their estimated local SGD noise, and transmit it along with their model parameter vector, gradient vector, and estimates of cluster parameter divergence over the previous global aggregation round to the server (lines 20-21). Then, the main server (i) updates the global model, (ii) estimates $\zeta,\delta',\sigma$ for the step size, (iii) estimates the linear model coefficients used in~\eqref{eq:Up_dyn}, (iv) obtains the optimal length $\tau_{k+1}$ of the next local model training interval, and (v) broadcasts the updated global model, step size coefficients, local model training interval, and consensus coefficient, along with the indices of the sampled devices for the next global aggregation (line 23-29).

% \nm{Where are the numerical results?}





% To obtain (a) and (b) for each cluster, each device in the cluster computes $\Vert\mathbf w_i(t_k)\Vert$ and share it with its neighbors iteratively. During 
% each iteration, each device memorizes both the (i) maximum and (ii) minimum values among the exchanged values of $\Vert\mathbf w_i(t_k)\Vert$ such that the approximation of $\epsilon_c(k)$ can be estimated.

\iffalse
\begin{corollary} \label{SPEgenLin}
    Consider the case that each device performs rounds of distributed average consensus after each local gradient update, under Assumption \ref{beta}, \ref{PL}, Definition \ref{gradDiv} and Algorithm \ref{GT}, if the number of consensus rounds at different clusters of the network satisfies 
    $$
    \Gamma_c(k)\geq
    \left[\frac{\log(\sigma_c^{(k)})-2\log(s_c^{(k)}^2\varepsilon_c(k))}{2\log(\lambda_c)}\right]^+
    $$
    such that $\sigma_c^{(k)}$ satisfies the following inequalities 
    \begin{equation} \label{cond2}
        \begin{aligned}
            \begin{cases}
                \lim_{k\rightarrow\infty}B_{k+1}/B_k\leq 1, \\
                \eta_k\leq\frac{1}{\beta+\frac{2\beta^2\delta(\mathbf w)\tau_k}{\eta_k(1-\mu\eta_k)^{\tau_k-1}}\big[1-(1-\mu\eta_k)^{\tau_k-1}\big]},
            \end{cases},
        \end{aligned}
    \end{equation}
    \nm{which $\mathbf w$?}
    where $B_k = \frac{1-(1-\mu\eta_k)^{\tau_k}}{\mu}\beta^2\tau_k m^2 h_k\sum\limits_{c=1}^N\varrho_{c} \sigma_c^{(k)}$. 
    Then Algorithm \ref{GT} is guaranteed to converge:
    \begin{align*}
        &F(\mathbf w(t_{k}))-F(\mathbf w^*)
        \\&
        \leq\prod_{n=1}^k(1-\mu\eta_n)^{\tau_n} \Big(F(\mathbf w(0))-F(\mathbf w^*)\Big)+\mathcal O(C_k),
    \end{align*}
    where $C_k=\max\{B_k,\Big((1-\mu\eta_k)^{\tau_k}+\xi\Big)^{t_k}\}$ for any $\xi>0$.
\end{corollary}

For the case that each device performs rounds of distributed average consensus after each local gradient update, corollary \ref{SPEgenLin} 
provides a guideline for designing the number of consensus rounds $\Gamma_c(k)$ at different network clusters over each global aggregation $k$, the number of local updates in the $k$-th global aggregation $\tau_k$ and the step size $\eta_k$ to guarantee weak linear convergence.

The condition to guarantee convergence is more relaxed compared to the condition for the case in proposition \ref{genLin} that consensus are performed after several rounds of local gradient updates since $\sigma_c^{(k)}$ is always upper bounded by $s_c^{(k)}^2\epsilon_c^2(t)$.
It shows that by performing less number of local gradient updates between consensus, the system obtains better performance, which coincides with the result in our simulation.

\begin{corollary} \label{SPEstr}
    Consider the case that each device performs rounds of distributed average consensus after each local gradient update, under Assumption \ref{beta}, \ref{PL} and Definition \ref{gradDiv}, if the number of consensus rounds at different clusters of the network are chosen to satisfy
    $$
    \Gamma_c(k)\geq
    \left[\frac{\log(\sigma_c^{(k)})-2\log(s_c^{(k)}^2\varepsilon_c(k))}{2\log(\lambda_c)}\right]^+
    $$
    where $\sigma_c^{(k)}$, $\tau_k$ and $\eta_k$ are determined to satisfy the following inequalities   
    \begin{align} \label{cond3}
            \begin{cases} \label{35}
            h_k\sum\limits_{c=1}^N\varrho_{c} \sigma_c^{(k)}
            \leq\frac{\mu^2(\gamma_k-\lambda_k)}{2\beta^4 m^2 \tau_k\left[1-(1-\mu\eta_k)^{\tau_k}\right]}\Big\Vert\nabla F(\mathbf w(t_{k-1}))\Big\Vert^2, \\
            \eta_k\leq\frac{1}{\beta+\frac{2\beta^2\delta(\mathbf w)\tau_k}{\eta_k(1-\mu\eta_k)^{\tau_k-1}}\big[1-(1-\mu\eta_k)^{\tau_k-1}\big]},
            \end{cases}.
    \end{align}
    \nm{what is gamma and is lambdak$<$gamma?}
    Then Algorithm \ref{GT} is guaranteed to achieve linear convergence:
    \begin{align*}
        &F(\mathbf w(t_{k}))-F(\mathbf w^*)
        \leq (1-\lambda_k)\Big(F(\mathbf w(t_{k-1}))-F(\mathbf w^*)\Big)
    \end{align*}
    for $0\leq\lambda_k\leq1-(1-\mu\eta_k)^{\tau_k}$.
\end{corollary}
\nm{how do you choose tau? Why not choosing it to be constant over k?
}
Similar to corollary \ref{SPEgenLin}, consider the case that each device performs rounds of distributed average consensus after each local gradient update, corollary \ref{SPEstr} 
provides a guideline for designing the number of consensus rounds $\Gamma_c(k)$ at different network clusters over each global aggregation $k$, the number of local updates in the $k$-th global aggregation $\tau_k$ and the step size $\eta_k$ to guarantee strong linear convergence with a rate $\lambda$ upper bounded by $1-(1-\mu\eta_k)^{\tau_k}$. 

The condition to guarantee convergence is more relaxed compared to the condition for the case in proposition \ref{strLin} that consensus are performed after several rounds of local gradient updates\\
since $\sigma_c^{(k)}$ is always upper bounded by $s_c^{(k)}^2\epsilon_c^2(t)$\\
It shows that by performing less number of local gradient updates between consensus, the system obtains better performance, which coincides with the result in our simulation.

\begin{corollary} \label{inf}
    Consider the case that each device performs infinite rounds of distributed average consensus after each local gradient update, under Assumption \ref{beta}, \ref{PL} and Definition \ref{gradDiv}, Algorithm \ref{GT} is always guaranteed to achieve linear convergence when $\eta_k\leq\frac{1}{\beta+\frac{2\beta^2\delta(\mathbf w)\tau_k}{\eta_k(1-\mu\eta_k)^{\tau_k-1}}\big[1-(1-\mu\eta_k)^{\tau_k-1}\big]}$:
    \begin{align*}
        &F(\mathbf w(t_{k}))-F(\mathbf w^*)
        \leq (1-\mu\eta_k)^{\tau_k}\Big(F(\mathbf w(t_{k-1}))-F(\mathbf w^*)\Big).
    \end{align*}
\end{corollary} 

Corollary \ref{inf} asserts that each device performs consensus after local gradient update,
if each device performs infinite rounds of consensus within their cluster and the step size is properly chosen to satisfy $\eta_k\leq\frac{1}{\beta+\frac{2\beta^2\delta\tau_k}{\mu(1-\mu\eta_k)^{\tau_k-1}}}$,\nm{since both sides of the eq depend on eta, when is it satisfied? (it is for eta=0), hence there exists a  range $[0,\eta_{th}]$, where $\eta_{th}$ is a function of beta delta tau, mu, for which it is satisfied} linear convergence is always guaranteed.  

For each local model $i$, instead being updated based on its own data, it is equivalent to be updated based upon the entire dataset from the cluster it belongs to.

\section{Real-time adaptive {\tt \DFL} algorithm} \label{sec:control}
In this section, we develop a real-time adaptive {\tt \DFL} algorithm to tune the learning parameters on the step size, time span between consecutive global aggregation and the number of consensus based on the result of convergence analysis in section \ref{sec:convAnalysis}.

In Propositions \ref{genLin} and \ref{strLin}, policies to guarantee linear convergence are provided. Proposition \ref{genLin} provides condition in \eqref{cond1} and \eqref{cond2} on the learning parameters $\eta_k$, $\tau_k$ and $\Gamma_c(k)$ to guarantee a general linear convergence to the optimal whereas Proposition \ref{strLin} provides a stricter condition \eqref{cond1} and \eqref{cond3} on these learning parameters to guarantee strong linear convergence to the optimal with convergence rate $\lambda\leq1-(1-\mu\eta_k)^{\tau_k}$.

To realize the policies provided in Propositions 1 and 2, we design a real-time adaptive algorithm to tune the learning parameters in practice. It is assumed that the sever
has an estimate about the topology of each cluster, and thus the upper-bound of the
spectral radius $\lambda_c$ at each global iteration.

According to \eqref{cond1}, \eqref{cond2} and \eqref{cond3}, the tuning of learning parameters requires the knowledge on the upper bound of (A.) parameter divergence $\epsilon_c(k)$ to satisfy the condition provided by Proposition \ref{genLin} and \ref{strLin}. In addition, Proposition \ref{strLin} further requires information of the (B.) global gradient $\Vert\nabla F(\mathbf w(t_{k-1}))\Vert$. Therefore, we first derive an adaptive estimation for the divergence of parameters in a distributed manner for every local iteration $t$. Then, we focus on the approach to approximate the global gradient $\Vert\nabla F(\mathbf w(t_{k-1}))\Vert$ at each global iteration $k$. 

\subsection{Estimation of parameter divergence} 
By Definition \ref{paraDiv} and given the conditions in \eqref{cond1} and \eqref{cond2}, since the server needs to determine the learning parameters at the beginning of global aggregation, we are interesting in approximating the prediction of $\epsilon_c(k)$ for $t\in\mathcal T_k$ by $\epsilon_c(k)$ at the beginning of the global aggregation $k$. Therefore, $\epsilon_c(k)$ is approximated as
% \begin{align*}
%     \epsilon_c(k) &\geq \Vert\mathbf w_i(t)-\mathbf w_j(t)\Vert
%     \\&
%     \geq \vert\Vert\mathbf w_i(t)\Vert-\Vert\mathbf w_j(t)\Vert\vert, ~\forall i, j\in\mathcal{S}_c^{(k)}, ~\forall t\in\mathcal T_k
% \end{align*}

\begin{align}
    \epsilon_c(k) &\approx \max_{i, j\in\mathcal{S}_c^{(k)}.}\{\Vert\mathbf w_i(t_k)\Vert-\Vert\mathbf w_j(t_k)\Vert\}
    \\& \label{epsProx}
    =\underbrace{\max_{i\in\mathcal{S}_c^{(k)}}\Vert\mathbf w_i(t_k)\Vert}_{(a)}-\underbrace{\min_{j\in\mathcal{S}_c^{(k)}}\Vert\mathbf w_j(t_k)\Vert}_{(b)}, ~\forall t\in\mathcal T_k,
\end{align}

To obtain (a) and (b) for each cluster, each device in the cluster computes $\Vert\mathbf w_i(t_k)\Vert$ and share it with its neighbors iteratively. During 
each iteration, each device memorizes both the (i) maximum and (ii) minimum values among the exchanged values of $\Vert\mathbf w_i(t_k)\Vert$ such that the approximation of $\epsilon_c(k)$ can be estimated.
\fi
% \subsection{Approximation of global gradient}
% In this section, we propose a two-step method to approximate $\Vert\nabla F(\mathbf w(t_{k-1}))\Vert$. By \eqref{15}, we first approximate $\nabla F(\mathbf w(t_{k-2}))$ as 
% $\nabla \widehat{F}(\mathbf w(t_{k-2}))=\mathbf w(t_{k-2})-\mathbf w(t_{k-1})/\eta_{k-2}$.\nm{why?}
% Since $F(\cdot)$ is strongly convex, the value $\Vert\nabla F(\mathbf w(t_{k}))\Vert$ is expected to decrease over $k$. Thus, $\Vert\nabla F(\mathbf w(t_{k-1}))\Vert$ can be further approximated by $\Vert\nabla \widehat{F}(\mathbf w(t_{k-1}))\Vert=\alpha\Vert\nabla F(\mathbf w(t_{k-2}))\Vert$, where $0\leq\alpha\leq 1$. The two-step approximation can be summarized as
% \begin{align} \label{gradProx}
%     \Vert\nabla \widehat{F}(\mathbf w(t_{k-1}))\Vert=\alpha\big(\mathbf w(t_{k-2})-\mathbf w(t_{k-1})\big)/\eta_{k-2}.
% \end{align}
% \nm{norm of RHS?}

% bibtex


% \section{Possible Optimization Formulations}
% 1) Optimization formulation:
% In the first proposed formulation, we aim to optimize the next interval for the local training period at each global aggregation with a look-ahead method. In particular, we try to minimize the total cost consisting of communication energy and delay starting from the beginning of k-th global aggregation (i,e., $t=t_{k-1}$) all the way to the end (i.e., $t=T$) to determine the value of local training period for the current global aggregation period (i.e., $\tau_{k}$). We assume that the value of $\tau_{k}$ is also going to be used for the rest of the training period, i.e., $\tau_{k}=\tau_{k+1}=....$. The intuition behind this is that we want to find the best choice of $\tau_{k}$ that minimizes the overall cost for the remaining training process as the decision for $\tau_{k}$. 

% We propose the following optimization  problem:
% \begin{align}
%   &\hspace{-3mm}\min_{\tau_k,\phi}  c_1 \times \left(\left[\sum_{t=t_{k-1}}^{T}\sum_{c=1}^{N}\theta_{c}(t)*E_{\textrm{D2D}} \right]+ K*E_{\textrm{Glob}} \right) + c_2\times \left(\left[\sum_{t=t_{k-1}}^{T}\sum_{c=1}^{N}\theta_{c}(t)*\Delta_{\textrm{D2D}}\right]+K*\Delta_{\textrm{Glob}}\right) \label{obj}
%   \hspace{-3mm} \\
%   & \textrm{s.t.}\nonumber \\
%   & \theta_c^{(t)}\geq\max\Big\{\log\Big(\eta_t\phi/(s_c\Upsilon_c^{(t)})\Big)/\log\Big(\lambda_c^{(t_{k-1})}\Big),0\Big\},~t_{k-1}\leq t\leq T \\
% %   &0<\tau_k<\log_4\frac{(\mu\gamma-1)\kappa}{16\omega^2\beta^2\gamma^2} \\
% %   &(T+\alpha) \xi>\Gamma\geq \alpha [F(\hat{\mathbf w}(0))] \\
% %   &[(\mu\gamma-1)(\Gamma-\beta\phi\gamma/2)-B]/[\frac{\gamma^2\beta}{2}A+\frac{16\omega^2\beta^2\gamma^2(\Gamma-\beta\phi\gamma/2)}{\kappa}]>4 \\
%   &1 \leq \tau_k \leq \sqrt{\Big[\mu\gamma-[3+8(1/\vartheta+(2\omega-\vartheta/2))^2]\Big]\Big[\tilde{\Gamma}-\vartheta\gamma\phi^2/2\Big]/(\gamma^2\beta^2 B)-A/B} \\
% %   &T\zeta/[F(\hat{\mathbf w}(0))-\xi]>\alpha\geq\max\{\beta\gamma/\kappa, \beta\gamma\big[1-\kappa/4+\sqrt{(1+\kappa/4)^2+2\omega}\big]\} \\
% %   &\Upsilon_c^{(t_k)} = 0\\
% %   &\Upsilon_c^{(k)} \leq d(\tau)\Upsilon_c^{(k-1)} \\
%     &K=\floor{\frac{T-t_{k-1}}{\tau_k}} \\
%     & \Upsilon_c^{(t_{k'-1})}=0, k'=k,\cdots,K,~ \forall c \\
%     & \Upsilon_c^{(t)} = 1_{\{\theta^{(t)}_c =0\}} (\hat{\chi}_c^{(k')}\Upsilon_c^{(t-1)}+\bar{\chi}_c^{(k')})+ (1-1_{\{\theta^{(t)}_c =0\}}) (\tilde{\chi}_c^{(k')}), t\in \bigcup_{k'=k}^{K} \overline{\mathcal{T}_{k'}}, ~\forall c\\
%   &\hat{\chi}_c^{(k')}=\hat{R}_c \hat{\chi}_c^{(k'-1)},~k'=k,\cdots,K, ~\forall c,\\
%   & \bar{\chi}_c^{(k')} = \bar{R}_c \bar{\chi}_c^{(k'-1)},~k'=k,\cdots,K, ~\forall c\\
%   &\tilde{\chi}_c^{(k')} = \tilde{R}_c \tilde{\chi}_c^{(k'-1)},~k'=k,\cdots,K, ~\forall c\\
%   &\overline{\mathcal{T}_k'}=\mathcal{T}_k'\setminus \{t_{k'-1}\},~k'=k,\cdots,K.
%     % & \Upsilon_c^{(t_{k'}+1)} = c''(k')\Upsilon_c^{(t_{k'-1}+1)}, k'=k-1,\cdots,K  \\
%     % & c(t)=c'(t)=0, t=t_{k'},~k' = 1,\cdots,K
% \end{align}



% \textbf{Successive Estimation of Divergence of Parameters ($\Upsilon$)}: rate of increase inside a global aggregation, periodic behavior, rate of decrease in increase in rate between two global aggregation... 
% Clearly reveal how this is a function of tau!!!!

% 1.3 , 5..
% 1.2 , 6..
% 1.2 * ... , 6

% 1.2/1.3



% We can see that the above optimization problem is highly non-convex. Thus, we propose to estimate and set a few of the parameters such as $\phi,\Gamma,\alpha,\gamma$ during a first global aggregation and keep tuning the $\tau_k$ for the rest of global aggregations. Note that even fixing all the parameters except $\tau_k$ does not result in a unique $\tau_k$ since the value of $\Upsilon_c^{(t)}$ keeps changing over time and we need to keep tracking and estimating it, which changes the value of $\tau_k$ since it affects the number of D2D rounds $\theta_c^{(t)}$.

\iffalse
Formulation 2: In this formulation, the designer also wants to minimize the convergence bound at a given time instance $T$.
\begin{align}
    &\min_{\tau,\phi}  
    c_0 \xi
    +c_1 \times \left(\sum_{t=t_{k-1}}^{T}\theta_{c}(t)*E_{\textrm{D2D}} + K*E_{\textrm{Glob}} \right) 
    +c_2\times \left(\sum_{t=t_{k-1}}^{T}\theta_{c}(t)*\Delta_{\textrm{D2D}}+K*\Delta_{\textrm{Glob}}\right)
    \\
   & \textrm{s.t.}\\
   & \frac{\Gamma}{T+\alpha}\leq\xi \\
   & \theta_c^{(t)}\geq\max\Big\{\log\Big(\eta_t\phi/(s_c\Upsilon_c^{(t)})\Big)/\log\Big(\lambda_c^{(t_{k-1})}\Big),0\Big\} \\
   &0<\tau_k<\log_4\frac{(\mu\gamma-1)\kappa}{16\omega^2\beta^2\gamma^2} \\
   &(T+\alpha) \xi>\Gamma\geq \alpha [F(\hat{\mathbf w}(0))] \\
   &[(\mu\gamma-1)(\Gamma-\beta\phi\gamma/2)-B]/[\frac{\gamma^2\beta}{2}A+\frac{16\omega^2\beta^2\gamma^2(\Gamma-\beta\phi\gamma/2)}{\kappa}]>4 \\
   &\tau_k \leq \log_4\left\{[(\mu\gamma-1)(\Gamma-\beta\phi\gamma/2)-B]/[\frac{\gamma^2\beta}{2}A+\frac{16\omega^2\beta^2\gamma^2(\Gamma-\beta\phi\gamma/2)}{\kappa}]\right\} \\
   &T\zeta/[F(\hat{\mathbf w}(0))-\xi]>\alpha\geq\max\{\beta\gamma/\kappa, \beta\gamma\big[1-\kappa/4+\sqrt{(1+\kappa/4)^2+2\omega}\big]\} \\
%   &\Upsilon_c^{(t_k)} = 0\\
%   & \Upsilon_c^{(t)} \leq c\Upsilon_c^{(t-1)}+c',~~t\in \mathcal{T}_k\\
%   &\Upsilon_c^{(k)} \leq d(\tau)\Upsilon_c^{(k-1)} \\
    &K=\floor{\frac{T-t_{k-1}}{\tau}}
    \\
    &t_{k-1}\leq t\leq T
\end{align}
In this formulation, the value of $\xi$ is also one of the optimization variables. Based on the solving technique discussed above, since we have different values of $\tau_k$ for different rounds of global aggregations, we need to recompute the optimization process with different values of $\xi$ and find the corresponding optimal choice of $\tau_k$ repeatedly for every aggregation rounds. However, different decisions on the value of $\xi$ in different global aggregation round correspondingly results in different range for the options of $\alpha$ and $\Gamma$ (can be observed from \eqref{45} and \eqref{46}). And since $\eta_t=\frac{\gamma}{t+\alpha}$ depends on the value of $\alpha$, the step size would vibrate up and down across aggregations (instead of steadily decreasing linearly). Another approach is to fix all the variables as described above for a fixed $\xi$ and keep changing the $\xi$ via a line search to obtain the best combination of $(\xi,\tau_1,\phi)$ and then we fix everything except $\tau_k$ and keep recomputing it through the algorithm. 
\fi

% for the case when $\alpha>\frac{\gamma^2\beta}{2}[Q_k A+B]/\{[\mu\gamma-(1+16\omega^2\beta^2\gamma^2 Q_k/\kappa)]F(\hat{ \mathbf{w}}(0)\}$, $\Gamma$ depends on the value of $\phi$, whereas for the case when $\alpha\leq\frac{\gamma^2\beta}{2}[Q_k A+B]/\{[\mu\gamma-(1+16\omega^2\beta^2\gamma^2 Q_k/\kappa)]F(\hat{ \mathbf{w}}(0)\}$, $\Gamma$ depends both on the value of $\phi$ and $\tau$. 









