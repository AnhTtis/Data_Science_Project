% \nm{Where is the abstract?}

% \nm{I downloaded the latex to work offline on it and add my comments, but there are several compilation errors. Please fix the errors!}

\section{Introduction}\label{sec:intro}
\noindent
% \nm{this paragraph is too long and shuold be shortened.
% You are quite repetitive..}

Machine Learning (ML) has become a popular tool for carrying out a variety of practical applications in   computer vision, speech recognition, natural language processing, and robotic control~\cite{wu2017squeezedet,AI_jordan,goldberg2017neural}. Conventionally, ML model training for these applications is conducted in a centralized manner, where
data from different sources is collected and processed in a single server/datacenter.
Nevertheless, in many applications, data used for model training is generated/gathered at the modern Internet-of-Things (IoT) devices located at the edge of the network (e.g., autonomous vehicles, mobile phones, and wearable devices)~\cite{CVN}, which makes centralized model training impractical. In fact, transferring the massive amount of data collected from the IoT devices to a central location imposes high latency and power/resource consumption~\cite{Chiang}, which is not desired especially in real-time applications~\cite{wu2017squeezedet,hard2018federated}. 
Also, privacy concerns related to transmitting private data across the network have progressively advocated for storing data locally and shifting the ML model training computation to the network edge where the data gets collected. This has led to an emerging area of distributed ML over the network edge, which exploits the distributed computing power of IoT devices to realize an intelligent edge/fog~\cite{hosseinalipour2020federated,park2019wireless}.

% This explosive growth of Internet-of-Things (IoT) devices has brought in a new era in edge computing, providing a greater distribution of computing power.


% In addition, coupled with privacy concerns over transmitting private information across the network, it has become progressively attractive to store data locally and shift model training computation to the edge. 

% Moreover, due to the excessive growth of data on each device, addressing the costs of bandwidth for data traveling long distances from edge to a remote server has become critical to enabling real-time applications~\cite{Chiang}, including object detection and next word prediction on autonomous vehicles and smartphones~\cite{wu2017squeezedet,hard2018federated}.




% This explosive growth of Internet-of-Things (IoT) devices has brought in a new era in edge computing, providing a greater distribution of computing power.

% In addition, coupled with privacy concerns over transmitting private information across the network, it has become progressively attractive to store data locally and shift model training computation to the edge. Moreover, due to the excessive growth of data on each device, addressing the costs of bandwidth for data traveling long distances from edge to a remote server has become critical to enabling real-time applications~\cite{Chiang}, including object detection and next word prediction on autonomous vehicles and smartphones~\cite{wu2017squeezedet,hard2018federated}. 



% Consequently, this trend results in a paradigm shift from the conventional ML training approach to distributed ML training. Multiple edge devices collaboratively train a shared model locally by exchanging information across the network.


Federated learning (FL)~\cite{mcmahan2017communication}, a popular distributed ML framework, trains an ML model via engaging edge devices in collaborative model training while keeping their data locally.
% as depicted in Fig.~\ref{fig:simpleFL}.
% to train an ML model collaboratively while keeping the training data locally without transmitting them to a centralized location.
It does so by executing three steps repeatedly: (i) \textit{local model training} at each edge device using its local dataset, (ii) \textit{aggregation of the local models} to a global model, and (iii) \textit{synchronization of the local models} with the newly obtained global model.
% , 
% during which each edge device updates the local model with the global one. 
Upon being implemented over a real-world network edge, FL will face many challenges and design problems given the heterogeneities existing at the wireless edge \cite{lim2020federated,hosseinalipour2020federated}. (i) \textit{Extreme Data Heterogeneity:}
the local datasets of the devices may exhibit significant heterogeneity, making them non-independent and identically distributed (non-i.i.d.), causing the locally trained models in each edge device to be significantly biased towards the local dataset~\cite{hosseinalipour2020federated}. 
(ii) \textit{Delay of Model Aggregations:} Variable distances and quality of communications between the edge devices and the point of aggregation (e.g., a cloud server) may result in considerable model aggregation and synchronization delays, making naive synchronization of the received global model with the local model impractical~\cite{frank2020delay}. 
(iii) \textit{Hierarchical Architecture of Network Edge:} Large-scale edge networks do not admit the conventional FL network architecture.
% in Fig.~\ref{fig:simpleFL}. 
In particular, edge devices are often not directly connected to a cloud server, instead, they are connected to the edge servers, which facilitate the communication to the cloud server~\cite{wang2021HFL}.
% federated learning, aims to enable large-scale model training by massive devices at the edge without exposing their local datasets to a third-party device. However, performing model training via the traditional cloud-based network architecture suffers from the communication bottleneck in the core network when implemented at scale~\cite{wang2021HFL}.
In this paper, we are motivated to address the above three challenges. In particular, we consider model training under a
% \nm{are you defining a new metric, or extending an existing one? Based on your Def 1 and Def 2, I think you are extending it} 
metric of data heterogeneity extended from the current art, which can capture extreme cases of data diversity across the devices. Also, we explicitly account for the delay in model aggregation and introduce a linear local-global model combining scheme. This scheme retains essential elements of both the outdated global model and the current local model, thereby improving the overall learning efficiency. Our methodology can augment existing studies by incorporating our strategy with those already established. Finally, we consider model training over a realistic hierarchical network edge architecture.


\textbf{Outline and Summary of Contributions}\label{subsec:contrib}:\\
Our contributions in this work can be summarized as follows:
\begin{itemize}[leftmargin=5mm]
\item We propose \textit{delay-aware federated learning} ({\tt DFL}), a novel methodology for improving distributed ML model training efficiency by accounting for the round-trip delay between edge and cloud. 
% (Sec. \ref{sec:tthf}). 
{\tt DFL} accounts for the effects of delays by introducing a local-global model combiner scheme during global synchronization, which conserve vital aspects of both the stale global model and the current local model, thereby enhancing overall learning efficiency.

\item  We theoretically investigate the convergence behavior of {\tt DFL} under a generalized data heterogeneity metric. Our convergence analysis introduces new techniques, such as coupled dynamic systems, to the current art in hierarchical FL~\cite{Feng2022HFL,Lim2021HFL,Xu2022HFL,Luo2020HFEL,wang2021HFL,Mhaisen2022HFL}. We obtain a set of conditions to achieve the sub-linear convergence rate of $\mathcal{O}(1/k)$ while mitigating the communication delay, which resembles the convergence rate of stochastic gradient descent in centralized model training without delay.

\item Leveraging the convergence characteristics, we introduce an adaptive control algorithm for {\tt DFL}, which targets a joint optimization of communication energy, latency, and ML performance while preserving a sub-linear convergence rate. This involves solving a non-convex integer programming problem, adapting (i) the global aggregation interval with the cloud, (ii) the local aggregation interval with the edge servers, (iii) the learning rate, and (iv) the combiner weight over time.

\item Our numerical evaluations demonstrate the effectiveness of {\tt DFL} in terms of convergence speed and resource consumption under various network settings, under both convex and non-convex loss functions. We observe that {\tt DFL} achieves (i) faster convergence of the global model, (ii) reduced resource consumption, and (iii) improved robustness against communication delays compared to existing FL algorithms.
%The combination of device-to-device and device-to-server communications aims to minimize network costs while maximizing trained global model accuracy and convergence speed.

%Based on an organization of edge devices into local clusters, {\tt TT-HF} augments organizes edge devices into clusters and orchestrates the edge devices by partitioning them into multiple clusters in each of which cooperative D2D communications can be performed. Subsequently, we introduce a \textit{hybrid} learning paradigm where the model training consists of both device-server (inter-cluster) and cooperative D2D (intra-cluster) communications.  Also, we constitute a \textit{two timescale} learning paradigm that relies on successive SGD interactions complemented by aperiodic consensus formation among the devices via heterogeneous number of D2D communications  in conjunction with aperiodic global aggregations.

% We theoretically derive the convergence behavior of {\tt DFL} on the decrease \nm{?? (sentence makes no sense)} optimality gap between the global model loss and optimal loss achieved at each round in the presence of non-i.i.d data distributions across different edge devices.

% Through techniques including coupled dynamic systems with a general\nm{what do you mean by general?} definition of gradient diversity (Sec. \ref{sec:convAnalysis}), our bounds quantify \nm{THE please use articles properly} dependence of model performance on properties of the loss function, the weighting used in synchronization, and the communication delay. In doing so, we obtain a set of conditions to achieve a sublinear convergence rate of $\mathcal{O}(1/t)$ while mitigating network resource utilization.
% \nm{are you sure you are "minimizing"? Can you demonstrate that your allocation achieves MINiMum cost? IF not, you need to sue a different word. mitigating? reducing?}

%and obtain an upper bound on its conv under a new general assumption on gradient diversity that accommodates for extreme heterogeneity among the local datasets. Our convergence bound relates topology structure inside different clusters, gradient diversity, number of D2D communications, and interval of consecutive  local and global aggregations to the convergence behavior of {\tt TT-HF}. We then obtain the condition under which the {\tt TT-HF} converges with the rate of $\mathcal{O}(1/t)$. 

% (Sec. \ref{Sec:controlAlg}). 
% This control algorithm obtains the $\mathcal{O}(1/t)$ convergence rate by including our derived conditions. 
% \hl{as constraints in the optimization.}\nm{too much d etails I dont think the reader can follow}

%\item Using our convergence relationships, we develop an adaptive control algorithm for {\tt TT-HF} that obtain a set of requirements on parameters of the consensus process (D2D rounds per local update instance), local learning algorithm (gradient step size), and global coordination (interval between model aggregations) to guarantee certain convergence behaviors. We then use these conditions to develop an online control algorithm for {\tt TT-HF} that tunes these parameters during the learning period (Sec. \ref{Sec:controlAlg}).

%\item Through studying the convergence characteristic, we obtain a set of new general policies on the required number of D2D rounds at each instance of local aggregation, the choice of step-size, and the interval of local training to guarantee certain convergence behavior. We subsequently utilize our theoretical findings to develop an online control algorithm to tune these design parameters during the learning period in real-time.

% We also show the delay-robustness of {\tt DFL} relative to existing FL algorithms, i.e., that performance is much more stable for variations in delay.

% \item Our subsequent experiments on popular learning tasks (Sec. \ref{sec:experiments}) verify that {\tt DFL} outperforms federated learning substantially in terms of resource consumption and/or training time over D2D-enabled wireless devices. They also confirm that the control algorithm is able to address resource limitations and data heterogeneity across devices by adapting the local and global aggregation periods.
\end{itemize}

For brevity, proofs are provided as sketches with full versions in our technical report~\cite{lin2023delay}.

% Second Delya:


% Third Hierarchy:



% the variety of edge devices may exhibit significant heterogeneity in computational resources, affecting the amount of sampled data each can process \cite{tu2020network}

% While providing a promising solution to real-time application in ML model training~\cite{lim2020federated,bennis2020edge},

% federated learning framework poses several challenges: the variety of edge devices may exhibit significant heterogeneity in computational resources, affecting the amount of sampled data each can process \cite{tu2020network}. Additionally, channel conditions of communication links between the server and each device may exhibit tremendous variance based on proximities and environmental conditions between the edge devices and the server. This may result in significant delay or energy consumption for some devices when transmitting models up to the server~\cite{frank2020delay,yang2019energy}. 

% Therefore, several research efforts have been conducted in recent years to address the aforementioned challenges. In this paper, we consider model performance regarding the effect of communication delays between the edge and server performing the aggregations, as advocated in our previous works~\cite{frank2020delay,david2022delay}. Extending from our previous works, this work migrates from the ``star'' topology of conventional federated learning in Fig.~\ref{fig:simpleFL} to a more complex hierarchical structure in which edge devices are grouped into multiple clusters, each connected to an edge server performing local aggregations using local models computed by the devices in the same group. Each edge server is then connected to a cloud server, performing global aggregation across the models uploaded by the edge serves. During the local update process in federated learning, edge servers occasionally perform local aggregation across their associated edge devices by requesting the devices in the corresponding coordinated cluster to send their local model parameters. This architecture is commonly promoted in large-scale networks, where each edge device is clustered according to their locations to the base station based on an acceptable proximity~\cite{liu2020client,hierar2020abad,Yang2021hierar}. In reality, the delay between the cloud and edge servers can be prohibitively large, usually from hundreds of milliseconds to several seconds depending on the network bandwidth~\cite{Lin}.
% % \nm{how large? Can you back it up with some reference?}. 
% Thus, our proposed algorithm, Delay-aware Federated Learning ({\tt DFL}), quantifies the impact of such delays and optimizes model performance along with resource consumption in their presence under a hierarchical network architecture. 
% \nm{can you at high level outline the results and contributions?} 

%keyboard next word prediction in cellular phones~\cite{hard2018federated} and object detection for autonomous vehicles~\cite{wu2017squeezedet}, the data required to train the ML model is generated at the edge devices, e.g., cellular phones and smart cars, using the plethora of their mounted sensing devices and interactions with the users. In these applications, transferring of the raw data to a central location may not be feasible/practical due to the following reasons: (i) the size of the dataset can become prohibitively large upon data acquisition from a large number of users, which is cumbersome to store in a central location; (ii) transferring of the raw data from the end users to a central server can be extremely time and power consuming; (iii) the end devices may not be willing to share their gathered data due to privacy concerns. 

\iffalse
\subsection{Federated Learning at the Wireless Edge}
Federated learning has emerged as a popular distributed ML technique for addressing these bandwidth and privacy challenges~\cite{mcmahan2017communication,konevcny2016federated,yang2019federated}. A schematic of its conventional architecture is given in Fig.~\ref{fig:simpleFL}. In each iteration, each device trains a local model based on its own dataset, often using (stochastic) gradient descent. The devices then upload their local models to the server, which aggregates them into a global model, often using a weighted average, and synchronizes the devices with this new model to initiate the next round of local training. 
 
Although widespread deployment of federated learning is desired~\cite{lim2020federated,bennis2020edge}, its conventional architecture in Fig.~\ref{fig:simpleFL} poses challenges for the wireless edge. The devices comprising the Internet of Things (IoT) can exhibit significant heterogeneity in their computational resources (e.g., a high-powered drone compared to a low-powered smartphone), which can affect the number of samples each can process \cite{tu2020network}. Additionally, the devices may exhibit varying proximities to the server (e.g., varying distances from smartphones to the base station in a cell), which can cause significant energy consumption from some devices in transmitting models upstream \cite{yang2019energy}.    

%Federated learning conducts model training via exchanging the model parameters of the devices and eliminates the need to exchange the devices' raw data. In particular, 
%it distributes the model training across the edge devices where each device trains a local model often using a gradient descent-based method. The models of the devices are then aggregated by a main server, which computes the weighted average of the devices' parameters and updates the devices with the new global model, based on which the devices initiate the next rounds of local training.  Although federated learning is predicted to be implemented over large-scale wireless networks~\cite{lim2020federated}, its conventional learning architecture does not fully match with the reality of wireless edge. In particular,  (i) sequential uplink transmissions are very energy consuming for resource constrained wireless devices (e.g., energy limited sensors, cellular phones, and drones); (ii) sequential transmission of model parameters from a large number of devices requires prohibitive bandwidth and may incur low quality-of-service (QoS) for the other users, (iii) the devices may posses extremely heterogeneous datasets (i.e., non-i.i.d datasets), which further hinders the convergence performance upon carrying out arbitrary local training at the devices.

%(i) sequential uplink transmissions are very energy consuming for resource constrained wireless devices (e.g., energy limited sensors, cellular phones, and drones); (ii) sequential transmission of model parameters from a large number of devices requires prohibitive bandwidth and may incur low quality-of-service (QoS) for the other users, (iii) the devices may posses extremely heterogeneous datasets (i.e., non-i.i.d datasets), which further hinders the convergence performance upon carrying out arbitrary local training at the devices.

One technique that has been developed to address the variation in communication requirements across wireless devices in federated learning is decreasing the frequency of global aggregations~\cite{wang2019adaptive,tu2020network}. By increasing the length of the local update period, devices can also perform more gradient iterations to further refine their local models between aggregations, while decreasing the frequency of uplink and downlink transmissions. However, the local datasets may exhibit significant heterogeneity in their statistical distributions~\cite{hosseinalipour2020federated}. In this case, longer local update periods will result in device models that are significantly biased towards local datasets. This can in turn degrade the convergence speed of the global model and the resulting trained model accuracy~\cite{wang2019adaptive}. In such settings, methods are needed to mitigate divergence across the local models.

%Moreover, the local datasets may exhibit significant heterogeneity in their statistical distributions (i.e., varying degrees of non-i.i.d.), which can cause considerable divergence between local models and hinder convergence of the global model \cite{hosseinalipour2020federated}.
%One of the main techniques to implement federated learning in such environments is reducing the number of global aggregations during the period of learning via conducting multiple local gradient descent rounds at the edge devices between two consecutive global aggregations~\cite{wang2019adaptive,tu2020network}. However, upon having extreme non-i.i.d datasets, this method does not perform well since it results in model bias toward the local datasets, which is boosted by increasing the number of local descent updates that can severely affect the performance of the model training~\cite{wang2019adaptive}.

Motivated by this, we study the problem of \textit{resource-efficient federated learning across heterogeneous local datasets at the wireless edge}. A key technology that we incorporate into our approach is device-to-device (D2D) communications among edge devices, which is a localized version of peer-to-peer (P2P) among direct physical connections. D2D is being enabled today in fog computing and IoT systems through 5G wireless~\cite{chen2020wireless}; it is expected that 50\% of all network connections will be machine-to-machine by 2023~\cite{hosseinalipour2020federated}. Through D2D, we can design a coordination mechanism to mitigate model divergence via low-power communications among nearby devices. Specifically, during the local update interval in federated learning, devices can occasionally share their model parameters with others in their neighborhood to form a distributed consensus among each cluster of edge devices. Then, at the end of each local training interval, assuming that each device's model now reflects the consensus of its cluster, the main server can randomly sample just one device from each cluster for the global aggregation. We call our approach \textit{two timescale hybrid federated learning} ({\tt TT-HF}), since it (i) involves a hybrid between device-to-device and device-to-server communications, and (ii) incorporates two timescales for model training: iterations of gradient descent at individual devices, and rounds of cooperative D2D communications within clusters.

{\tt TT-HF} migrates from the ``star'' topology of conventional federated learning in Fig.~\ref{fig:simpleFL} to a more complex structure that includes local topologies between edge devices, as has been advocated in the new ``fog learning'' paradigm~\cite{hosseinalipour2020federated}. In doing so, we must carefully consider the relationships between device-level gradient updates, cluster-level consensus formation, and network-level global aggregations. We quantify these relationships in this work, and use them to tune the lengths of each local update and consensus period. As we will see, the result is a version of federated learning which optimizes the global model convergence characteristics while minimizing the uplink communication requirement in the system.

\fi

% \begin{figure}[t]
% \includegraphics[width=.8\textwidth]{SimpFL_star.pdf}
% \centering
% \caption{Conventional federated learning. In each training round, devices perform local model updates based on local datasets, followed by an aggregation at the main server to compute the global model, which is broadcast to the devices for the next round of local updates.\nm{fontsize in the figure is too small difficult to read... I would show only two clusters instead of 3 and spread it out more vertically}}
% \label{fig:simpleFL}
% \vspace{-5mm}
% \end{figure}

%{\tt TT-HF} migrates from the conventional learning architecture of federated learning depicted in~\ref{fig:simpleFL} and forms a complex learning architecture that is (i) \textit{two timescale}, i.e., heterogeneous number of D2D communications rounds are carried out aperiodically at different clusters in conjunction with aperiodic global aggregations, and (ii) \textit{hybrid}, i.e., the model training consists of both device-server (inter-cluster) and cooperative D2D (intra-cluster) communications.
%{\tt TT-HF} aims to address the aforementioned three challenges of federated learning over wireless edge by (i) reducing the number of uplink transmissions during the model training interval via conducting low-power D2D communications during the period of local updates, (ii) reducing the bandwidth consumption via engaging only one device from each cluster, i.e., cluster-heads, in each instant of global aggregation,\footnote{Note that D2D communications can be performed in out-band mode~\cite{kar2018overview}, which does not occupy the licensed spectrum.} (iii) taking into account for the extreme heterogeneity of data at the wireless edge via imposing a new general definition on the gradient diversity. 

%We recently introduced fog learning (FogL) to conduct model training over large-scale fog/edge networks~\cite{hosseinalipour2020federated}, which incorporates device-to-device (D2D) communications to the learning architecture.
%In this work, we exploit the paradigm of FogL to propose a novel learning platform, called \textit{two timescale hybrid federated learning} ({\tt TT-HF}), where the edge devices are partitioned into multiple clusters inside each of which cooperative D2D communications are enabled.
%In ({\tt TT-HF}), during the local training interval, the edge devices in each cluster perform multiple rounds of local stochastic gradient descent (SGD) updates in between which they aperiodically engage in D2D communications to form consensus on their model parameters to suppress local models biasedness.
%After the local training interval, the main server randomly selects one device from each cluster and requests uplink transmission of model parameters which is then used to carry out the global aggregation followed by broadcasting of the new global model that initiates the next round of local updates.
%{\tt TT-HF} migrates from the conventional learning architecture of federated learning depicted in~\ref{fig:simpleFL} and forms a complex learning architecture that is (i) \textit{two timescale}, i.e., heterogeneous number of D2D communications rounds are carried out aperiodically at different clusters in conjunction with aperiodic global aggregations, and (ii) \textit{hybrid}, i.e., the model training consists of both device-server (inter-cluster) and cooperative D2D (intra-cluster) communications.
%{\tt TT-HF} aims to address the aforementioned three challenges of federated learning over wireless edge by (i) reducing the number of uplink transmissions during the model training interval via conducting low-power D2D communications during the period of local updates, (ii) reducing the bandwidth consumption via engaging only one device from each cluster, i.e., cluster-heads, in each instant of global aggregation,\footnote{Note that D2D communications can be performed in out-band mode~\cite{kar2018overview}, which does not occupy the licensed spectrum.} (iii) taking into account for the extreme heterogeneity of data at the wireless edge via imposing a new general definition on the gradient diversity. 


\section{Related Work}\label{sec:RW}
We categorize the related work to this study with respect to the three aforementioned challenges of FL. For a comprehensive survey of works on FL, we refer the interested reader to~\cite{Kairouz}.

\textbf{Non-i.i.d. Data Across the Devices.}
Non-i.i.d data across the devices has been shown to significantly reduce the performance of FL due to local model bias \cite{McMahan}. To counteract this effect, \cite{wang2019adaptive,Sun2021adaptive} tunes the frequency of global model aggregations, \cite{tu2020network,wang2021device} conduct data transfer across the devices to reduce the heterogeneity of data, and~\cite{8737464,chen2020joint,yang2020energy} conduct efficient resource allocation under non-i.i.d. data. However, most of these works rely on a simple modeling of non-i.i.d. data across the devices which cannot be generalized to real-world settings.
Recently, we introduced a new metric of data heterogeneity in \cite{lin2021timescale} that extends the current art and is able to capture extreme non-i.i.d. data across the devices. However, in \cite{lin2021timescale}, this metric is exploited in a completely different framework, where devices conduct local device-to-device (D2D) communications for model consensus, as compared to this works. In this work, we aim to conduct convergence analysis of model training under this general data heterogeneity metric, while taking into account for communication delay and hierarchical network architecture.

% Variable wireless connections in edge networks can result in unreliable communication, which operates at lower rates and thus cause communication delays that can impact distributed ML techniques. 


\textbf{Model Training under Delay Considerations.} Upstream/downstream communication between the edge and server can
% be very extremely expensive considering the 
often lead to non-negligible transmission delays in FL. 
% One major technique that has been developed to address this issue in federated learning is decreasing the frequency of local model updates in between global aggregations~\cite{wang2019adaptive,tu2020network}. The paper \cite{McMahan} proposed reducing the frequency of communication in federated learning by performing global updates after multiple iterations of local updates, i.e., decreasing the total number of rounds. In addition, the paper \cite{K2} proposed combining random sparsification with probabilistic quantization on model updates to further reduce the number of upstream and downstream communication rounds required. However, by increasing the length of the period of local model updates, the local datasets may exhibit significant heterogeneity in their statistical distributions causing the local models in each edge device to be significantly biased towards their own local datasets~\cite{hosseinalipour2020federated}. This can in turn result in significant degradation of accuracy performance of the global model along with the convergence speed~\cite{wang2019adaptive}. On the other hand, significant communication bandwidth for model/gradient exchange is required for distributed training in large-scale networks, limiting the scalability of multi-device training at the edge and requiring expensive high-bandwidth network infrastructure. Consequently, other efforts have proposed compression techniques to reduce the communication required between the edge devices and the server. In particular, some proposed compression methods, i.e., cutting the gradient
% size via gradient compression, to reduce the bandwidth required in each transmission~\cite{Lin,K3,Horvath}. Furthermore, the papers \cite{Tu} and \cite{lin2021timescale} proposed a network-aware federated learning architecture that trades off communication demand with model convergence.
% \nm{most of the works you mention above are not quite relevant to what you are doing. You should instead stress the fact that these works do not consider hte impact of delay which maydegrade the performance of these algos..}
% Different from these prior works, rather than minimizing communication costs or frequency of federated learning\nm{are you saying that your scheme does not reduce communication cost? After you have been saying in the intro that comm cost is one of the biggest hurdles of FL..
% if I am a reviewer and I read this sentence, I would be concerned to read this..
% }, we focus on the impact of delays on the performance of the trained global model, i.e., convergence rate and accuracy, and develop an adaptive algorithm to address them. \nm{why are state of art schemes not adequately addressing this issue? Your literature review does not address this question}
Delay of model training in FL has been modeled and considered in several recent works \cite{8737464,PSL2022federated,Shi2021latency,sam2022latency,Zhao2022layency,Gao2021latency}. These works model the delay with respect to the channel conditions between the devices and the server and the devices' local computation power. The delay is often aimed to be minimized in these works to have the fastest model training scheme. However, none of these works aim to \textit{mitigate} the impact of delay via intelligent synchronization of the received global model and the local model at the devices. In this work, we study this under-explored topic via proposing a linear local-global model combiner.



\textbf{Hierarchical Federated Learning.}
% The combination of AI and edge computing has given rise to edge intelligence, leveraging the capabilities of end devices to process data~\cite{Lim2022EI}. One of the promising solutions, 
% federated learning\nm{you have been talking about FL until now, you make it seem like you are talking about something new..}, aims to enable large-scale model training by massive devices at the edge without exposing their local datasets to a third-party device. However, performing model training via the traditional cloud-based network architecture suffers from the communication bottleneck in the core network when implemented at scale~\cite{wang2021HFL}. 
% As a result,  
Several studies have aimed to propose new system architectures to improve the scalability of ML model training in FL~\cite{liu2020client,Lim2022EI,wang2021HFL,lin2021timescale,Zhao2020HFL}. Specifically, hierarchical federated learning has been proposed as a realistic system model, which allows edge devices to first transmit their local model parameters to edge servers for intermediate aggregation before edge servers conduct global aggregation through a cloud server, which reduces the frequency of performing resource intensive global aggregations~\cite{Feng2022HFL,Lim2021HFL,Xu2022HFL,Luo2020HFEL,wang2021HFL,Mhaisen2022HFL}. This architecture has been investigated through the lens of resource allocation \cite{Xu2022HFL,Feng2022HFL}, and edge association~\cite{Luo2020HFEL,wang2021HFL,Lim2021HFL,Mhaisen2022HFL}. Although these works provide valuable design insights, they mostly consider a simplistic data heterogeneity metric and do not take into account for smart local synchronization of the local models with the global model. Subsequently,
as compared to these works, we introduce a new ML convergence analysis scheme that takes into account for a generalized data heterogeneity metric under a new linear local-global model combiner scheme. Drawing from the convergence properties, we devise a control algorithm for {\tt DFL}, which incorporates strategies aimed at mitigating energy consumption and communication latency.
% \nm{I think you need to talk about your control scheme as well that aims at optimizing resource utilization..}

% Our work considers a large-scale hierarchical federated learning system, accounting for the non-negligible delays between the edge devices and the cloud, and formulate a joint problem of edge aggregation interval and global aggregation interval control to minimize the global training loss as well as resource consumption. 



% The paper \cite{Xu2022HFL} formulated a joint problem of edge aggregation interval control and resource allocation to minimize the weighted sum of training loss and training latency for a hierarchical federated learning framework. Specifically, given the resource allocation strategy, a relaxation and rounding method is proposed to optimize the edge aggregation interval. Some develop edge association schemes for hierarchical federated learning taking into account resource consumption by formulating a joint resource allocation and edge association problem to achieve global cost minimization~\cite{Luo2020HFEL,wang2021HFL,Lim2021HFL}. 

% The paper \cite{Mhaisen2022HFL} optimized the edge association problem based on statistical properties and network topology to accord edge-level data distributions across edge devices and enhance the learning performance. The paper \cite{Feng2022HFL} redesigned the access mechanism, local update rule, and model aggregation scheme for a hierarchical learning framework to account for the impact of user mobility on the learning performance. The paper \cite{Luo2020HFEL} introduced a hierarchical federated edge learning framework with partial model aggregation migrated to edge servers from the cloud. They formulated a joint computation and communication resource allocation and edge association problem via resource scheduling for edge devices to achieve global cost minimization. Other studies proposed a server-less hierarchical federated learning framework to reduce the reliance on a central controller and the risk of a single point of failure~\cite{Ng2021HFL,Lim2021HFL}. The paper \cite{Lim2021HFL} considers a two-level resource allocation and incentive mechanism design problem applying the evolutionary game theory to model the dynamics of the cluster selection process. In addition, the paper \cite{Ng2021HFL} proposed a reputation-aware scheme under a two-layer network architecture, taking into account the incentive design for edge devices marginal contributions by rewarding their marginal contribution to the cluster.
% \nm{What are the weaknesses of these works that you aim to address? You need to identify these, otherwise it is not clear how you work improves over the state of art..}


\iffalse
A multitude of works on federated learning has emerged in the past few years. Most existing literature has studied optimizations/enhancements over the classic structure depicted in Fig.~\ref{fig:simpleFL}. Popular topics of investigation have included addressing communication and computation constraints of wireless devices~\cite{8737464,chen2019joint,yang2019energy,yang2020federated}, supporting multi-task learning~\cite{smith2017federated,corinzia2019variational,9006060}, and personalized model training~\cite{jiang2019improving,fallah2020personalized}. We refer the reader to e.g.,~\cite{rahman2020survey,li2020federated} for comprehensive surveys of the federated learning literature; in this section, we will focus on those addressing resource efficiency, statistical data heterogeneity, and cooperative learning as we do in this paper.


%we refer the reader to \cite{rahman2020survey} for a comprehensive survey. Most existing literature in this area has studied optimizations of federated learning over its classic structure depicted in Fig.~\ref{fig:simpleFL}. In particular, the consideration of computation and communication constraints of devices over wireless networks is an active area of research~\cite{8737464,chen2019joint,yang2019energy,yang2020federated}.
%Also, federated learning has been studied in other contexts, such as multi-task learning and personalized model training~\cite{smith2017federated,corinzia2019variational,9006060,jiang2019improving,fallah2020personalized}, where individual models are tailored for different users. We refer the reader to~\cite{li2020federated} and references therein for other research directions and interesting problems investigated.

In terms of wireless communication efficiency, several works have investigated the impact of performing multiple rounds of local gradient updates in-between consecutive global aggregations~\cite{haddadpour2019convergence,wang2019adaptive}, including optimizing the aggregation period according to a total resource budget~\cite{wang2019adaptive}. To further reduce the demand for global aggregations,~\cite{liu2020client} proposed a hierarchical system model for federated learning where edge servers are utilized for partial global aggregations. Regarding device processing efficiency,~\cite{tu2020network} showed that data offloading in D2D-enabled wireless networks can reduce resource utilization while preserving model accuracy. Model quantization~\cite{amiri2020federated} and sparsification~\cite{sattler2019robust} techniques have also been proposed.

% Conducting multiple local descents is mostly advocated in terms of energy efficiency since it can reduce the number of global aggregations in a certain period that are more energy consuming.
%However, these approaches are prone to the existence of nodes with non-i.i.d datasets, where multiple local descent updates may lead to the model biasedness toward the local datasets, which in turn could lead to severe deterioration of the convergence speed of the model training~\cite{wang2019adaptive}.

Other works have considered improving model training in the presence of heterogeneous data among the devices. Many of these techniques have involved raw data sharing over the network, e.g.,~\cite{9149323,wang2021device,zhao2018federated}. In~\cite{9149323}, the authors propose uploading portions of the local datasets to the server, which is then used to augment global model training. The work in~\cite{zhao2018federated} can be seen as an additional step, where the server shares a portion of its aggregated data among the devices to make their local data distributions less heterogeneous.~\cite{wang2021device} also attempts to promote homogeneity among local datasets, but instead through  D2D data offloading optimization. Raw data sharing, however, may suffer from privacy concerns or bandwidth limitations.

Different from these works, we propose a methodology that addresses the communication efficiency and data heterogeneity challenges simultaneously. To do this, we introduce distributed cooperative learning among devices into the local update process -- as has been advocated recently~\cite{hosseinalipour2020federated,chen2020wireless} -- resulting in a novel system architecture with P2P-augmented learning. In this regard, the most relevant existing work is~\cite{hosseinalipour2020multi}, which also studies cluster-based consensus formation between global aggregations. Different from~\cite{hosseinalipour2020multi}, we consider the case where (i) devices may conduct multiple (stochastic) gradient iterations between global aggregations, (ii) the global aggregations are aperiodic, and (iii) consensus formation among the devices may occur aperiodically during each global aggregation. Doing so leads to a more complex system model, which we analyze to provide improvements to resource efficiency and model convergence. There is also an emerging set of works on fully decentralized (server-less) federated learning~\cite{9154332,8950073,hu2019decentralized,lalitha2019peer}: our work can be seen as an intermediate between the star topology and fully distributed approaches when a server is available.

Finally, note that there is a well-developed literature on consensus-based optimization, e.g.,~\cite{yuan2011distributed,shi2014linear}. Our work employs the distributed average consensus technique~\cite{xiao2004fast} and contributes new results on distributed ML to this literature.
\fi

% \nm{the submitted paper needs to be self-standing. Since I don't think you will include the appendices, you need to refer to the extended version on arxiv.}