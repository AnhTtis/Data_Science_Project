\begingroup
\let\clearpage\relax 
% \onecolumn %%% For
\onecolumn

\appendices 
\setcounter{lemma}{0}
\setcounter{proposition}{0}
\setcounter{theorem}{0}
\setcounter{definition}{0}
\setcounter{assumption}{0}

\section*{Introduction to Notations and Preliminaries used in the Proofs}\label{app:notations}
\noindent The subnet noise-free variable before global synchronization is introduced as follows:
\begin{equation}\label{eq:v_c}
    \bar{\mathbf v}_c^{(t+1)}= \bar{\mathbf v}_c^{(t)}-\eta_{k}\nabla \bar{F}_c(\bar{\mathbf v}_c^{(t)}),~\forall t\in\mathcal{T}_k\setminus{\{t_k\}},
\end{equation}
% \nm{what about global sync??} 
with the subnet noise-free variable at global synchronization is defined as 
\begin{align}
    \bar{\mathbf v}_c^{(t_{k+1})}
    =& (1-\alpha)\bar{\mathbf v}^{(t_{k+1}-\Delta)}
    +\alpha\widetilde{\mathbf v}_c^{(t_{k+1})},
\end{align}
where $\widetilde{\mathbf v}_c^{(t_{k+1})}$ is the noise-free variable right before global synchronization, as opposed to $\mathbf v_c^{(t_{k+1})}$ defined right after global synchronization. Similarly, the global noise-free variable is defined as  
\begin{equation}
    \bar{\mathbf v}^{(t+1)}=\sum\limits_{d=1}^N\varrho_{d}\bar{\mathbf v}_d^{(t+1)}~~\forall t\in\mathcal{T}_k.
\end{equation}
% \nm{please move def of e1 e2 e3 here}
The following noise terms used in the appendices are defined as follows:
\begin{align}
 &\label{eq:def_e1}   e_1^{(t)}\triangleq\Big(\mathbb E\Big[\sum\limits_{c=1}^N\varrho_c\sum\limits_{j\in\mathcal S_c}\rho_{j,c}\Vert\mathbf w_i^{(t)} - \bar{\mathbf v}_c^{(t)}\Vert^2\Big]\Big)^{1/2},\\
&\label{eq:def_e2}       e_2^{(t)} \triangleq\sum\limits_{c=1}^N\varrho_{c}\Vert\bar{\mathbf v}_c^{(t)}-\bar{\mathbf v}^{(t)}\Vert,
\\
&\label{eq:def_e3}
        e_3^{(t)}\triangleq\Vert\bar{\mathbf v}^{(t)}-\mathbf w^*\Vert.
    \end{align}
\section{Proof of Theorem~\ref{thm:subLin}} \label{app:subLin} 
% \nm{MAIN PROOF}
\begin{theorem} \label{thm:subLin}
% \nm{I think you need to define all the quantities here as well...it is difficult to read when you are pointing to equations that appear somewhere else..}
    Under Assumptions \ref{beta},~\ref{assump:SGD_noise} and~\ref{assump:sub_err}, if $\eta_{k}=\frac{\eta_{\mathrm{max}}}{1+\gamma k},~\forall k$ and $\vert\mathcal T_k\vert\leq\tau,~\forall k$, using {\tt DFL} for ML model training, the distance between the global model and the optimum at global synchronization can be bounded as 
    \begin{align}
        \mathbb E[\Vert\bar{\mathbf w}^{(t_k)}-\mathbf w^*\Vert^2]
        \leq 2Y_1^2 \eta_k+2Y_3^2\eta_k^2,
    \end{align}
    % \nm{??? Isnt it $\mathbb E[\Vert\bar{\mathbf w}^{(t_k)}-\mathbf w^*\Vert^2]\leq (e1+e3)^2\leq 2e1^2+2e3^2\leq 2Y_1^2 \eta_k+2Y_3^2\eta_k^2$? I think you need to keep them separate since they show a stronger result: the impact of delta decays faster with k.}
    where 
    $\eta_{\mathrm{max}}<\min\left\{\frac{2}{\beta+\mu},\frac{(\tau-\Delta)\mu}{\beta^2[(1+\lambda_+)^{\tau}-1-\tau\lambda_+]}\right\}$, $\gamma<\min\left\{1-(1-\mu\eta_{\mathrm{max}})^{2(\tau-\Delta)},C_3\eta_{\mathrm{max}}\beta\right\}$,
    \begin{align}
        \alpha<\alpha^* \triangleq \frac{1}{\frac{C_2\eta_{\max}^2}{\eta_{\max}\beta C_3-\gamma}
         2\omega C_2(1+\gamma)
        +(1+\gamma)(1+\lambda_+)^{\tau}},
    \end{align}
    \begin{align}\label{eq:Y1}
        Y_1 \triangleq\sqrt{\frac{(\tau-(1-\alpha)\Delta)(\sigma^2+\phi^2)\eta_{\mathrm{max}}}{C_1-\gamma}},
    \end{align}
    \begin{align}\label{eq:Y2}
    Y_2\triangleq\max\left\{
    \frac{\eta_{\mathrm{max}}^2\alpha 2\omega C_2(1+\gamma)
    e_3^{(0)}
    +\alpha K_1\delta(1+\gamma)
    }{1-\alpha(1+\gamma)(1+\lambda_+)^{\tau}},
    \frac{\frac{ K_1\delta}{\eta_{\mathrm{max}} 2\omega C_2}
    +\frac{K_2\delta}{\beta C_3-\gamma}
    }{
    \frac{[1-\alpha(1+\gamma)(1+\lambda_+)^{\tau}]}{\eta_{\mathrm{max}}\alpha 2\omega C_2(1+\gamma)}
    -\frac{C_2}{\beta C_3-\gamma}
    }\right\},
\end{align}
    % \begin{align}
    %     Y_2 \triangleq\frac{\eta_{\mathrm{max}}K_1\nm{K1(alpha??)}Y_3(1+\gamma)+K_2\delta(1+\gamma)}{1-\alpha(1+\gamma)(1+\lambda_+)^{\tau}},
    % \end{align}
    \begin{align}\label{eq:Y3}
        Y_3 \triangleq \max\left\{\eta_{\mathrm{max}}e_3^{(0)},
        \frac{[C_2Y_2+K_2\delta]\eta_{\max}}{\eta_{\max}\beta C_3-\gamma}\right\}.
    \end{align}
    with $K_1=\frac{\mu}{-\beta\lambda_+\lambda_-}[(1+\lambda_+)^{\tau}-1]$, $K_2=\frac{\beta}{\sqrt{1+8\omega}}\sum_{\ell=0}^{\tau-2}\Big(\begin{array}{c}\tau\\\ell+2\end{array}\Big)[\lambda_+^{\ell+1}-\lambda_-^{\ell+1}]$, $C_1=1-((1-\alpha)(1-\mu\eta_{\mathrm{max}})^{2(\tau-\Delta)}+\alpha(1-\mu\eta_{\mathrm{max}})^{2\tau})$, $C_2=\frac{2\beta}{\sqrt{8\omega+1}}[(1+\lambda_+)^{\tau}-1]$, $C_3=(\tau-\Delta)\mu/\beta 
        - \eta_{\mathrm{max}}\beta[(1+\lambda_+)^{\tau}-1-\tau\lambda_+]$ and $\lambda_{\pm} =\frac{1}{2}-\frac{\mu}{\beta}\pm\frac{\sqrt{8\omega+1}}{2}$.
    % \nm{you need to tell where these vars are defined.}
    % \nm{since K1 and K2 are prop to alphha redefine $K_1\gets K_1(1)$, so that $K_1(\alpha)$ becomes $K_1\alpha$. Same for K2.}
\end{theorem}
\begin{proof}
Note that
\begin{align} 
    &\sqrt{\mathbb E[\Vert\bar{\mathbf w}^{(t_{k})}-\mathbf w^*\Vert^2]} 
    =\sqrt{\mathbb E[\Vert\bar{\mathbf w}^{(t_{k})}-\bar{\mathbf v}^{(t_{k})}+\bar{\mathbf v}^{(t_{k})}-\mathbf w^*\Vert^2]} 
    \\&
    \leq
    \sqrt{\mathbb E[\Vert\bar{\mathbf w}^{(t_{k})}-\bar{\mathbf v}^{(t_{k})}\Vert]}+\Vert\bar{\mathbf v}^{(t_{k})}-\mathbf w^*\Vert
    \\&
    =
    \sqrt{\mathbb E[\Vert\sum\limits_{c=1}^N\varrho_c\sum_{j\in\mathcal S_c}\rho_{j,c}({\mathbf w}_j^{(t_{k})}-\bar{\mathbf v}_c^{(t_{k})})\Vert^2]}+\Vert\bar{\mathbf v}^{(t_{k})}-\mathbf w^*\Vert
    \\&
    \leq
    \sqrt{\sum\limits_{c=1}^N\varrho_c\sum_{j\in\mathcal S_c}\rho_{j,c}\mathbb E[\Vert{\mathbf w}_j^{(t_{k})}-\bar{\mathbf v}_c^{(t_{k})}\Vert^2]}+\Vert\bar{\mathbf v}^{(t_{k})}-\mathbf w^*\Vert
    = e_1^{(t_k)}+e_3^{(t_k)},
\end{align}
and therefore
\begin{align}\label{eq:final}
     \mathbb E[\Vert\bar{\mathbf w}^{(t_k)}-\mathbf w^*\Vert^2]\leq (e_1^{(t_k)}+e_3^{(t_k)})^2\leq 2(e_1^{(t_k)})^2+2(e_3^{(t_k)})^2.
\end{align}
We now show by induction that $e_1^{(t_k)}\leq Y_1\sqrt{\eta_k}$, $e_2^{(t_k)}\leq Y_2\eta_k$ and $e_3^{(t_k)}\leq Y_3\eta_k$ with $Y_1$, $Y_2$
and $Y_3$ defined in~\eqref{eq:Y1},~\eqref{eq:Y2} and~\eqref{eq:Y3}. The conditions trivially holds at the beginning of training at $k=0$ since $Y_1\geq0$, $Y_2\geq0$ and $Y_3\geq\eta_{\mathrm{max}}e_3^{(0)}$.
% \nm{note that e2 and e3 are of order eta...Can be seen in the constatn stepsize case, asyntotuic regime}
% \nm{/init condyion here
Now, assume $e_1^{(t_k)}\leq Y_1\sqrt{\eta_k}$, $e_2^{(t_k)}\leq Y_2\eta_k$ and $e_3^{(t_k)}\leq Y_3\eta_k$ for a certain $k\geq0$. We prove the condition holds for $k+1$ as well. 

To show $e_1^{(t_{k+1})}\leq\sqrt{\eta_{k+1}}Y_1$, we use~\eqref{eq:e1_main} of Proposition~\ref{lem:main_gap} and the induction hypothesis ($e_1^{(t_{k})}\leq\sqrt{\eta_{k}}Y_1$), yielding the sufficient condition
% For $e_1^{(t_k)}$, from~\eqref{eq:e1_main} of Proposition~\ref{lem:main_gap}, we aim to show that $(e_1^{(t_{k+1})})^2-\eta_{k+1}Y_1^2\leq 0$. Applying the induction condition into \eqref{eq:e1_main}, it is sufficient 
 \begin{align} 
&\left(1-\eta_k/\eta_{\mathrm{max}}C_1\right)\eta_{k}Y_1^2
    % \nonumber \\&
    +\eta_{k}^2(\tau-(1-\alpha)\Delta)(\sigma^2+\phi^2)
    -\eta_{k+1}Y_1^2\leq 0.
\end{align}
% \nm{you have already applyied the ind hp to get the above!}
% \hl{Applying the induction hypothesis} and 
% \nm{sentence sounds weird.. please rephrase, I would just do:}
% \sst{Transforming the condition above through the set of following algebraic steps:}
% \nm{a bit confusing and not systematic.. are you replacing the values of etak?? Then do that for ALL etak! I would say :}
Using the expression of $\eta_k=\frac{\eta_{\mathrm{max}}}{1+\gamma k}$, the above condition is equivalent to
$$
     -[C_1-\gamma]Y_1^2
    % \\&
    +\eta_{\mathrm{max}}(\tau-(1-\alpha)\Delta)(\sigma^2+\phi^2)
    -\gamma Y_1^2\frac{\gamma}{1+\gamma (k+1)}
    \leq 0.
$$
To satisfy the condition for all $k\geq 0$, the above condition is equivalent to
$$
\eta_{\mathrm{max}}(\tau-(1-\alpha)\Delta)(\sigma^2+\phi^2)
\leq 
[C_1-\gamma]Y_1^2,
$$
which is indeed verified since 
% \sst{$\gamma<1-((1-\alpha)(1-\mu\eta_{\mathrm{max}})^{2(\tau-\Delta)}+\alpha(1-\mu\eta_{\mathrm{max}})^{2\tau})\leq1-(1-\mu\eta_{\mathrm{max}})^{2(\tau-\Delta)}$}
% \nm{
$\gamma<1-(1-\mu\eta_{\mathrm{max}})^{2(\tau-\Delta)}\leq C_1$
% }
 and $Y_1^2=\frac{(\tau-(1-\alpha)\Delta)(\sigma^2+\phi^2)\eta_{\mathrm{max}}}{C_1-\gamma}.$
This completes the induction for $e_1^{(t_k)}$, showing that $(e_1^{(t_k)})^2\leq\eta_{k}Y_1^2,~\forall k$. 

% \nm{please use a similar approach for e2 as I did for e1.. Dont overcomplicate things: replace the value of etak, organize the terms properly, and then bound properly (worst case over k)}
To show $e_2^{(t_{k+1})}\leq\eta_{k+1}Y_2$, we use~\eqref{eq:x1_syn_inter2} of Proposition~\ref{lem:main_gap} and the induction hypothesis ($e_2^{(t_{k})}\leq\eta_{k}Y_2$), yielding the sufficient condition
 \begin{align} 
&\alpha(1+\lambda_+)^{\tau}\eta_k Y_2
    +\alpha 2\omega C_2\eta_k^2 Y_3
    % \nonumber\\& 
    +\alpha K_1\eta_k\delta
    -\eta_{k+1}Y_2\leq 0,
\end{align} 
Using the expression of $\eta_k=\frac{\eta_{\mathrm{max}}}{1+\gamma k}$, the above condition can be written as:
% \nm{Reorganize as
\begin{align}\label{eq:e2_finTransform}
    & \frac{\alpha(1+\lambda_+)^{\tau} Y_2}{\eta_{\mathrm{max}}}
    +\alpha 2\omega C_2Y_3
    +\frac{\alpha K_1\delta}{\eta_{\mathrm{max}}}
    - \frac{Y_2}{\eta_{\mathrm{max}}(1+\gamma)}
    - \frac{Y_2\gamma^2 k}{\eta_{\mathrm{max}}(1+\gamma(k+1))(1+\gamma)}
    - \frac{\alpha 2\omega C_2Y_3\gamma k}{1+\gamma k}
    \leq 0,
\end{align}
% which makes it immediately clear that $k=0$ is the worst case
% }
To satisfy the condition for all $k\geq 0$, the above condition is equivalent to
 \begin{align}\label{eq:e2_cond2}
    & \frac{[1-\alpha(1+\gamma)(1+\lambda_+)^{\tau}]Y_2-\alpha K_1\delta(1+\gamma)}{\eta_{\mathrm{max}}}
    -\alpha 2\omega C_2Y_3(1+\gamma)
    \geq 0.
 \end{align}
% which can be verified since $\alpha<\alpha*\leq\frac{1}{(1+\gamma)(1+\lambda_+)^{\tau}}$ and $Y_2\geq\frac{\alpha (\eta_{\mathrm{max}}2\omega C_2Y_3+K_1\delta)}{1/(1+\gamma)-\alpha(1+\lambda_+)^{\tau}}$. 

To show $e_3^{(t_{k+1})}\leq\eta_{k+1}Y_3$, we use~\eqref{eq:e3_sync} of Proposition~\ref{lem:main_gap} and the induction hypothesis ($e_3^{(t_{k})}\leq\eta_{k}Y_3$), yielding the sufficient condition
\begin{align}
    (1-\eta_k\beta C_3)Y_3\eta_k
      % \nonumber \\&
    +[C_2Y_2+K_2\delta] \eta_k^2
    - Y_3\eta_{k+1}\leq 0.
\end{align}
Using the expression of $\eta_k=\frac{\eta_{\mathrm{max}}}{1+\gamma k}$, the above condition can be written as:
\begin{align}
Y_3[\gamma -\eta_{\max}\beta C_3]
      % \nonumber \\&
    +[C_2Y_2+K_2\delta]\eta_{\max}
    % \nonumber\\&
    % +[g_{5}(\Pi_{+,t}-1)+g_{6}(\Pi_{-,t}-1)]
    % [\sigma/\beta+\sum\limits_{d=1}^N\varrho_{d}\epsilon_{d}^{(0)}] \nonumber\\&
 -Y_3\gamma^2(1+\gamma k+\gamma)\leq 0.
\end{align}
To satisfy the condition for all $k\geq 0$, the above condition is equivalent to
\begin{align} \label{eq:cond_Y3}
    Y_3[\gamma -\eta_{\max}\beta C_3]
    +[C_2Y_2+K_2\delta]\eta_{\max}
    \leq 0.
\end{align}
 To show $e_2^{(t_k)}\leq\eta_{k+1}Y_2$ and $e_3^{(t_k)}\leq\eta_{k+1}Y_3$, the conditions $e_3^{(t_k)}\geq \eta_{\mathrm{max}}e_3^{(0)}$,~\eqref{eq:e2_cond2} and~\eqref{eq:cond_Y3} need to be satisfied simultaneously. To satisfy this, we need $\gamma<C_3\eta_{\mathrm{max}}\beta$ and
 \begin{align}
     Y_3\geq \eta_{\mathrm{max}}e_3^{(0)},
 \end{align}
 \begin{align}
     Y_3\leq
    \frac{[1-\alpha(1+\gamma)(1+\lambda_+)^{\tau}]Y_2-\alpha K_1\delta(1+\gamma)}{\eta_{\mathrm{max}}\alpha 2\omega C_2(1+\gamma)},
 \end{align}
 and
 \begin{align}
     Y_3\geq\frac{[C_2Y_2+K_2\delta]\eta_{\max}}{\eta_{\max}\beta C_3-\gamma}.
 \end{align}
 Using the definition of $Y_3$ in~\eqref{eq:Y3}, the conditions above become equivalent to 
 \begin{align}
     Y_3\leq
    \frac{[1-\alpha(1+\gamma)(1+\lambda_+)^{\tau}]Y_2-\alpha K_1\delta(1+\gamma)}{\eta_{\mathrm{max}}\alpha 2\omega C_2(1+\gamma)},
 \end{align}
 yielding the sufficient conditions
 \begin{align}
     \eta_{\mathrm{max}}e_3^{(0)}\leq
    \frac{[1-\alpha(1+\gamma)(1+\lambda_+)^{\tau}]Y_2-\alpha K_1\delta(1+\gamma)}{\eta_{\mathrm{max}}\alpha 2\omega C_2(1+\gamma)},
 \end{align}
 and 
 \begin{align}
     \frac{[C_2Y_2+K_2\delta]\eta_{\max}}{\eta_{\max}\beta C_3-\gamma}\leq
    \frac{[1-\alpha(1+\gamma)(1+\lambda_+)^{\tau}]Y_2-\alpha K_1\delta(1+\gamma)}{\eta_{\mathrm{max}}\alpha 2\omega C_2(1+\gamma)},
 \end{align}
which can be verified since $\alpha<\alpha^*$ together with the definition of $Y_2$ given in~\eqref{eq:Y2}.
This completes the induction showing that $e_2^{(t_k)}\leq\eta_{k+1}Y_2$ and $e_3^{(t_k)}\leq\eta_{k+1}Y_3$. Finally, applying the result of induction for $e_1^{(t_k)}, e_2^{(t_k)}$ and $e_3^{(t_k)}$ into~\eqref{eq:final} completes the proof.
\end{proof}

\pagebreak
\section{Proof of Proposition~\ref{lem:main_gap}} \label{app:main_gap} 
% \nm{this is also an auxiliary result and should be moved after Thm1}
\begin{proposition} \label{lem:main_gap}
    Under Assumptions \ref{beta},~\ref{assump:SGD_noise} and~\ref{assump:sub_err}, if $\eta_{k}=\frac{\eta_{\mathrm{max}}}{1+\gamma k}$, where $\eta_{\mathrm{max}}<\min\left\{\frac{2}{\beta+\mu},\frac{(\tau-\Delta)\mu}{\beta^2[(1+\lambda_+)^{\tau}-1-\tau\lambda_+]}\right\}$, using {\tt DFL} for ML model training, $(e_1^{(t_{k+1})})^2$, $e_2^{(t_{k+1})}$ and $e_3^{(t_{k+1})}$ across global synchronizations can be bounded as 
\begin{align} \label{eq:e1_main}
    (e_1^{(t_{k+1})})^2
    \leq&
    \left(1-\eta_k/\eta_{\mathrm{max}}C_1\right)(e_1^{(t_k)})^2
    % \nonumber \\&
    +\eta_{k}^2 (\tau-(1-\alpha)\Delta)(\sigma^2+\phi^2),
    % \nm{ERROR, SEE\ BELOW}
\end{align} 
\begin{align} \label{eq:x1_syn_inter2}
    e_2^{(t_{k+1})}&\leq 
    % \nonumber \\&
    \alpha(1+\lambda_+)^{\tau}e_2^{(t_k)}
    +\eta_k\alpha 2\omega C_2e_3^{(t_k)}
    % \nonumber\\& 
    +\eta_k\alpha K_1\delta,
\end{align}
\begin{align} \label{eq:e3_sync}
     &  e_3^{(t_{k+1})}\leq
    (1-\eta_k\beta C_3) e_3^{(t_k)}
    +C_2 \eta_ke_2^{(t_k)}
    +\eta_k^2 K_2\delta,
\end{align}
 where 
 \begin{align}\label{eq:K1}
     C_1 \triangleq 1-((1-\alpha)(1-\mu\eta_{\mathrm{max}})^{2(\tau-\Delta)}+\alpha(1-\mu\eta_{\mathrm{max}})^{2\tau}),
 \end{align}
  \begin{align}\label{eq:C2}
     C_2\triangleq\frac{2\beta}{\sqrt{8\omega+1}}[(1+\lambda_+)^{\tau}-1],
 \end{align}
 \begin{align}\label{eq:C1}
     &C_3 \triangleq (\tau-\Delta)\mu/\beta 
        - \eta_{\mathrm{max}}\beta[(1+\lambda_+)^{\tau}-1-\tau\lambda_+],
 \end{align}
 \begin{align}\label{eq:K2}
     K_1 \triangleq \frac{\mu}{-\beta\lambda_+\lambda_-}[(1+\lambda_+)^{\tau}-1],
 \end{align}
 \begin{align}\label{eq:C3}
     K_2\triangleq \frac{\beta}{\sqrt{1+8\omega}}\sum_{\ell=0}^{\tau-2}\left(\begin{array}{c}\tau\\\ell+2\end{array}\right)[\lambda_+^{\ell+1}-\lambda_-^{\ell+1}],
 \end{align}
 with $\lambda_\pm$ defined in~\eqref{eq:eign+-} of Lemma~\ref{lem:main}.
\end{proposition}
\begin{proof}
% \nm{follow the order: e1, e2 finally e3}
We prove this result by further upper bounding $e_1^{(t_{k+1})}$ in Lemma~\ref{lem:main}. Therein, we found that
\begin{align} \label{eq:e1_lem2}
        &(e_1^{(t_{k+1})})^2
        \leq [(1-\alpha)(1-\mu\eta_{k})^{2(\tau-\Delta)}+\alpha(1-\mu\eta_{k})^{2\tau}](e_1^{(t_k)})^2
        % \nonumber \\&
        +\eta_{k}^2(\tau-(1-\alpha)\Delta)(\sigma^2+\phi^2).
    \end{align} 
To bound $(e_1^{(t_{k+1})})^2$ in~\eqref{eq:e1_lem2}, we
 use the fact that $[(1-\alpha)(1-\mu\eta_{k})^{2(\tau-\Delta)}+\alpha(1-\mu\eta_{k})^{2\tau}]$ is a convex function of $\eta_k\in[0,\eta_{\mathrm{max}}]$ (in fact, $\mu\eta_{\mathrm{max}}\leq 1$ since $\eta_{\mathrm{max}}\leq\frac{2}{\beta+\mu}$), hence
% \nm{This is only true if $\mu\epsilon\leq 1$ iff $\tau\geq (1-\alpha)\Delta$, see above}
\begin{align} \label{eq:cvx_eta}
    &(1-\alpha)(1-\mu\eta_{k})^{2(\tau-\Delta)}+\alpha(1-\mu\eta_{k})^{2\tau}
    % \nonumber \\&
    \leq
    1-\eta_k/\eta_{\mathrm{max}}C_1.
\end{align}
 Applying the result from~\eqref{eq:cvx_eta} into~\eqref{eq:e1_lem2}, gives us the result in~\eqref{eq:e1_main}.
Similarly for $e_2^{(t_{k+1})}$, we found
  \begin{align} 
    e_2^{(t_{k+1})}&\leq 
    \alpha\Pi_{+,t_{k+1}}e_2^{(t_k)}
    +\alpha\frac{4\omega}{\sqrt{8\omega+1}}[\Pi_{+,t_{k+1}}-1]e_3^{(t_k)}
    % \nonumber \\&
    % \nonumber\\& 
+\alpha\frac{\mu}{-\beta^2\lambda_+\lambda_-}(\Pi_{+,t_{k+1}}-1)\delta,
    \end{align}
    where $\Pi_{\{+,-\},t}=[1+\eta_{k}\beta\lambda_{\{+,-\}}]^{t-t_{k}}$.
    % \nm{above, first shoe the e2 term and then the e3, to be consistent and easier to follow}
    Using convexity of $\Pi_{+,t_{k+1}}$ in $\eta_k\beta\in[0,1]$, we bound it as $\Pi_{+,t_{k+1}}\leq1+ \eta_k\beta [(1+\lambda_+)^{\tau}-1]$. Applying it into the above inequality yields
    % \nm{But: if you are bounding $\eta_k\beta\leq 1$, why not simply use convexity wrt $\eta_{k}\beta\in(0,1)$ yielding
    % $(1+\eta_{k}\beta\lambda_+)^{\tau}\leq 1+\eta_{k}\beta[(1+\lambda_+)^{\tau}-1]$?? This is actually tighter since $\beta\leq 1/\eta_{\max}$. 
    % gives\nm{grammar}
    \begin{align}
    e_2^{(t_{k+1})}&\leq 
    \alpha(1+\lambda_+)^{\tau}e_2^{(t_k)}
    +\eta_{k}\alpha 2\omega C_2e_3^{(t_k)}
    % \nonumber \\&
    % \nonumber\\& 
    +\eta_{k}\alpha K_1\delta.
    \end{align}
    Finally, we found in~\eqref{eq:wc-w*_sync1} of Lemma~\ref{lem:main} that
    \begin{align} \label{eq:e3_init}
         &e_3^{(t_{k+1})}\leq
        \Psi_1(\eta_k) e_3^{(t_k)}
          \nonumber \\&
        +\underbrace{2g_{3}[(1-\alpha)\Pi_{+,t_{k+1}-\Delta}+\alpha\Pi_{+,t_{k+1}}-1]}_{(a)}e_2^{(t_k)}
        \nonumber\\&
        % +[g_{5}(\Pi_{+,t}-1)+g_{6}(\Pi_{-,t}-1)]
        % [\sigma/\beta+\sum\limits_{d=1}^N\varrho_{d}\epsilon_{d}^{(0)}] \nonumber\\&
        +\underbrace{\left[(1-\alpha)[g_{5}(\Pi_{+,t_{k+1}-\Delta}-1)+g_{6}(\Pi_{-,t_{k+1}-\Delta}-1)]
        +\alpha[g_{5}(\Pi_{+,t_{k+1}}-1)+g_{6}(\Pi_{-,t_{k+1}}-1)]\right]}_{(b)}\delta/\beta,
    \end{align}
    where $\Psi_1(\eta_k)$, $g_3$, $g_5$ and $g_6$ is defined in~\eqref{eq:Psi_1},~\eqref{eq:g3},~\eqref{eq:g5} and~\eqref{eq:g6} of Lemma~\ref{lem:main}. We bound $\Psi_1(\eta_k)$ as follows.
    Applying the binomial expansion, we have
    \begin{align} \label{eq:phi_bi}
        &\frac{g_{1}\Pi_{+,t_{k}+\ell}+g_{2}\Pi_{-,t_{k}+\ell}-1}{\eta_k\beta}
        \nonumber \\&
        =-\ell\mu/\beta+\eta_k\beta\sum\limits_{r=2}^\ell\frac{\ell!}{r!(\ell-r)!}(\eta_k\beta)^{r-2}
        \left[\frac{1}{2}(1-\frac{1}{\sqrt{8\omega+1}})\lambda_+^r+\frac{1}{2}(1+\frac{1}{\sqrt{8\omega+1}})\lambda_-^r\right].
    \end{align}
    Since $\lambda_-\leq\lambda_+$, $\eta_k\leq\eta_{\mathrm{max}}$
    % \nm{??? etamax?? PLEASE check that you are not using old variables} 
    and $\eta_k\beta\leq1$, we can further upper bound~\eqref{eq:phi_bi} with
    \begin{align}
        &\frac{g_{1}\Pi_{+,t_{k}+\ell}+g_{2}\Pi_{-,t_{k}+\ell}-1}{\eta_k\beta}
        \leq -\ell\mu/\beta +\eta_k\beta\sum\limits_{r=2}^\ell\frac{\ell!}{r!(\ell-r)!}(\eta_k\beta)^{r-2}\lambda_+^r
        \nonumber \\&
        \leq -\ell\mu/\beta +\eta_{\mathrm{max}}\beta\sum\limits_{r=2}^\ell\frac{\ell!}{r!(\ell-r)!}\lambda_+^r
        \nonumber \\&
        \overset{(a)}{=} -\ell\mu/\beta +\eta_{\mathrm{max}}\beta[(1+\lambda_+)^\ell-1-\ell\lambda_+],
    \end{align}
    where $(a)$ comes from applying the binomial theorem.
    Note that $(1+\lambda_+)^\ell-1-\ell\lambda_+\geq0,~\forall \ell\geq0$. 
    Combining this result into~\eqref{eq:Psi_1} of Lemma~\ref{lem:main}, it follows that 
    \begin{align}
        &\frac{\Psi_1(\eta_k)-1}{\eta_k\beta}
        \leq 
        -(\tau-(1-\alpha)\Delta)\mu/\beta 
        \nonumber \\&
        + \eta_{\mathrm{max}}\beta[(1-\alpha)(1+\lambda_+)^{\tau-\Delta}+\alpha(1+\lambda_+)^{\tau}-1-(\tau-(1-\alpha)\Delta)\lambda_+]
        \nonumber \\&
        \leq 
        -(\tau-\Delta)\mu/\beta 
        + \eta_{\mathrm{max}}\beta[(1+\lambda_+)^{\tau}-1-\tau\lambda_+]
        \triangleq -C_3,
    \end{align}
    where in the last inequality comes from $\tau-(1-\alpha)\Delta\geq\tau-\Delta$ and $(1-\alpha)(1+\lambda_+)^{\tau-\Delta}+\alpha(1+\lambda_+)^{\tau}-1-(\tau-(1-\alpha)\Delta)\lambda_+\leq(1+\lambda_+)^{\tau}-1-\tau\lambda_+$.
    Therefore, under $\eta_{\mathrm{max}}<\frac{(\tau-\Delta)\mu}{\beta^2[(1+\lambda_+)^{\tau}-1-\tau\lambda_+]}$, we have $C_3>0$ and
    \begin{align}
        \Psi_1(\eta_k)\leq 1-\eta_k\beta C_3<1. 
    \end{align}
    Next, we bound $(a)$ in~\eqref{eq:e3_init}.
    Convexity of $\Pi_{+,t}-1$ with respect to $\eta_k\beta$ and $\eta_{\mathrm{max}}\beta\leq1$ implies that
    \begin{align}
        &2g_3[(1-\alpha)\Pi_{+,t_{k+1}-\Delta}+\alpha\Pi_{+,t_{k+1}}-1]
        \nonumber \\&
        \leq
        \eta_{k} \frac{2\beta}{\sqrt{8\omega+1}}[(1-\alpha)(1+\lambda_+)^{\tau-\Delta}+\alpha(1+\lambda_+)^{\tau}-1]
        \leq 
        \eta_k C_2,
    \end{align}
    where $g_3$ is defined in~\eqref{eq:g3} of Lemma~\ref{lem:main},
    with $$C_2= \frac{2\beta}{\sqrt{8\omega+1}}[(1+\lambda_+)^{\tau}-1].$$
Finally, we bound $(b)$ in~\eqref{eq:e3_init}, using the binomial expansion and the expressions of $g_5$ and $g_6$ 
% \nm{need more steps. First show the binomial expansion with =, then bound}
    $$
    g_{5}(\Pi_{+,t}-1)+g_{6}(\Pi_{-,t}-1)
    =(\eta_k\beta)^2\frac{1}{\sqrt{1+8\omega}}\sum_{\ell=0}^{t-t_k-2}\left(\begin{array}{c}t-t_k\\\ell+2\end{array}\right)(\eta_k\beta)^{\ell}[\lambda_+^{\ell+1}-\lambda_-^{\ell+1}]
    \leq \eta_k^2\beta K_2.
    $$
Using these bounds in~\eqref{eq:e3_init} yield the final result in~\eqref{eq:e3_sync}.
\end{proof} 
\pagebreak


\section{Lemmas and Auxiliary Results}\label{app:lemmas}
To improve the tractability of the proofs, we provide a set of lemmas in the following, which will be used to obtain the main results of the paper.

\begin{lemma} \label{lem:An_oneSTP}
For $t\in\mathcal T_k$ before performing global synchronization, under Assumptions \ref{beta},~\ref{assump:SGD_noise} and~\ref{assump:sub_err}, if $\eta_{k}\leq\frac{2}{\mu+\beta},~\forall k$, using {\tt DFL} for ML model training, in $t\in\mathcal T_k$, the one-step behaviors of $(e_1^{(t+1)})^2$, $e_2^{(t+1)}$ and $e_3^{(t+1)}$ are presented as follows:
% \nm{move to very beginning of App}
\begin{align} \label{eq:e1_oneSTP}
    &(e_1^{(t+1)})^2
    \leq
    (1-\mu\eta_{k})^2(e_1^{(t)})^2
    +\eta_{k}^2(\sigma^2+\phi^2),
    \\\label{eq:e2_oneSTP}
    &e_2^{(t+1)}\leq
    (1+\eta_{k}(\beta-\mu))e_2^{(t)} 
    +2\omega\eta_{k}\beta e_3^{(t)}
    +\eta_{k}\delta,
\\ \label{eq:e3_oneSTP}
&   e_3^{(t+1)} \leq
     (1-\eta_{k}\mu)e_3^{(t)} 
    +\eta_{k}\beta e_2^{(t)}.
\end{align} 
%\nm{assumption on control algo (phi) missing. state as an Assumption in the main text and recall it here}
\end{lemma}

\begin{proof}
To bound $e_1^{(t)}$, we first use the definition of $\mathbf w_i^{(t+1)},~\forall i \in\mathcal S_c$ in \eqref{eq:w_i-gen} and $\mathbf v_c^{(t+1)}$ in \eqref{eq:v_c} to get, 
\begin{align} \label{eq:e_tmp1}
    &\mathbf w_i^{(t+1)} - \bar{\mathbf v}_c^{(t+1)}
    =(1-\Theta_c^{(t)})(\mathbf w_i^{(t)}-\eta_{k} \nabla F_i({\mathbf w}_i^{(t)})-\bar{\mathbf v}_c^{(t)}+\eta_{k} \nabla\bar F_c(\bar{\mathbf v}_c^{(t)}))
    \nonumber \\&
    +\Theta_c^{(t)}(\bar{\mathbf w}_c^{(t)}-\eta_{k}\sum\limits_{j\in\mathcal S_{c}}\rho_{j,c}\nabla F_j({\mathbf w}_j ^{(t)})-\bar{\mathbf v}_c^{(t)}+\eta_{k} \nabla\bar F_c(\bar{\mathbf v}_c^{(t)}))
    \nonumber \\&
    -\eta_{k}(1-\Theta_c^{(t)})\mathbf n_{i}^{(t)}-\eta_{k}\Theta_c^{(t)}\sum\limits_{j\in\mathcal S_c}\rho_{j,c}\mathbf n_{j}^{(t)}.
\end{align}
Then,
\begin{align}\label{eq:A_new}
    &(e_1^{(t+1)})^2\triangleq\mathbb E\Big[\sum\limits_{c=1}^N\varrho_c\sum\limits_{j\in\mathcal S_c}\rho_{j,c}\Vert\mathbf w_j^{(t+1)} - \bar{\mathbf v}_c^{(t+1)}\Vert^2\Big]
    \nonumber \\&
    \leq
    \mathbb E\Big[\sum\limits_{c=1}^N\varrho_c(1-\Theta_c^{(t)})\sum\limits_{j\in\mathcal S_c}\rho_{j,c}\Vert\mathbf w_j^{(t)}-\eta_{k} \nabla F_j({\mathbf w}_j^{(t)})-\bar{\mathbf v}_c^{(t)}+\eta_{k} \nabla\bar F_c(\bar{\mathbf v}_c^{(t)})\Vert^2\Big]
    % \nm{mismatch between i and j indece!!!}
    \nonumber \\&
    +\mathbb E\Big[\sum\limits_{c=1}^N\varrho_c\Theta_c^{(t)}\Vert\bar{\mathbf w}_c^{(t)}-\eta_{k}\sum\limits_{j\in\mathcal S_{c}}\rho_{j,c}\nabla F_j({\mathbf w}_j ^{(t)})-\bar{\mathbf v}_c^{(t)}+\eta_{k} \nabla\bar F_c(\bar{\mathbf v}_c^{(t)})\Vert^2\Big]+\eta_{k}^2\sigma^2
        \nonumber \\&
    \leq
    \mathbb E\Big[\sum\limits_{c=1}^N\varrho_c(1-\Theta_c^{(t)})\sum\limits_{j\in\mathcal S_c}\rho_{j,c}\Vert\mathbf w_j^{(t)}-\bar{\mathbf v}_c^{(t)}-\eta_{k} (\nabla F_j({\mathbf w}_j^{(t)})- \nabla\bar F_c(\bar{\mathbf v}_c^{(t)}))\Vert^2\Big]
    \nonumber \\&
    +\mathbb E\Big[\sum\limits_{c=1}^N\varrho_c\Theta_c^{(t)}
    \sum\limits_{j\in\mathcal S_{c}}\rho_{j,c}
    \Vert\mathbf w_j^{(t)}-\eta_{k}\nabla F_j({\mathbf w}_j ^{(t)})-\bar{\mathbf v}_c^{(t)}+\eta_{k} \nabla F_j(\bar{\mathbf v}_c^{(t)})\Vert^2\Big]+\eta_{k}^2\sigma^2,
\end{align}
where the last step
follows from
$\sum\limits_{j\in\mathcal S_c}\rho_{j,c}
 F_j(\bar{\mathbf v}_c^{(t)})
=
\bar F_c(\bar{\mathbf v}_c^{(t)}),
$
$\sum\limits_{j\in\mathcal S_c}\rho_{j,c}
{\mathbf w}_j^{(t)}
=\bar{\mathbf w}_c^{(t)}
$
and convexity of $\Vert\cdot\Vert^2$. Using again the fact that
$\sum\limits_{j\in\mathcal S_c}\rho_{j,c}
 F_j(\bar{\mathbf v}_c^{(t)})
=
\bar F_c(\bar{\mathbf v}_c^{(t)}),
$
we further bound
\begin{align}
    &\sum\limits_{j\in\mathcal S_c}\rho_{j,c}\Vert\mathbf w_j^{(t)}-\bar{\mathbf v}_c^{(t)}-\eta_{k} (\nabla F_j({\mathbf w}_j^{(t)})- \nabla\bar F_c(\bar{\mathbf v}_c^{(t)}))\Vert^2
    % \nm{mismatch between i and j indece!!!}
    \nonumber \\&
    =
\sum\limits_{j\in\mathcal S_c}\rho_{j,c}\Vert\mathbf w_j^{(t)}-\bar{\mathbf v}_c^{(t)}-\eta_{k}(\nabla F_j({\mathbf w}_j^{(t)})-\nabla F_j(\bar{\mathbf v}_c^{(t)})) -\eta_{k}\left(\nabla F_j(\bar{\mathbf v}_c^{(t)})- \nabla\bar F_c(\bar{\mathbf v}_c^{(t)})\right)\Vert^2
    \nonumber \\&
    \leq
\sum\limits_{j\in\mathcal S_c}\rho_{j,c}\Vert\mathbf w_j^{(t)}-\bar{\mathbf v}_c^{(t)}-\eta_{k} (\nabla F_j({\mathbf w}_j^{(t)})-\eta_{k} \nabla F_j(\bar{\mathbf v}_c^{(t)}))\Vert^2
    +\eta_{k}^2\sum\limits_{j\in\mathcal S_c}\rho_{j,c}\Vert\nabla F_j(\bar{\mathbf v}_c^{(t)})- \nabla\bar F_c(\bar{\mathbf v}_c^{(t)})\Vert^2.
    \nonumber
\end{align}
Furthermore, 
$\Vert\nabla F_j(\bar{\mathbf v}_c^{(t)})- \nabla\bar F_c(\bar{\mathbf v}_c^{(t)})\Vert^2
\leq
(\delta_c+2\omega_c\beta\Vert\bar{\mathbf v}_c^{(t)}-\mathbf w^*\Vert)^2
\leq
2\delta_c^2+4\omega_c\beta\Vert\bar{\mathbf v}_c^{(t)}-\mathbf w^*\Vert^2
$ (Definition~\ref{gradDiv_c}).
Combining these bounds together into~\eqref{eq:A_new} and using Fact~\ref{fact:3} yields
\begin{align}\label{eq:A_new}
    &(e_1^{(t+1)})^2
    \leq
    (1-\mu\eta_k)^2\mathbb E\Big[\sum\limits_{c=1}^N\varrho_c
    \sum\limits_{j\in\mathcal S_{c}}\rho_{j,c}
    \Vert\bar{\mathbf w}_j^{(t)}-\bar{\mathbf v}_c^{(t)}\Vert^2\Big]
    \nonumber \\&
    +\eta_{k}^2
    \sum\limits_{c=1}^N\varrho_c(1-\Theta_c^{(t)})(2\delta_c^2+4\omega_c^2\beta^2\Vert\bar{\mathbf v}_c^{(t)}-\mathbf w^*\Vert^2)
    +\eta_{k}^2\sigma^2.
\end{align}
Assuming that $\Theta_c^{(t)}$ is chosen such that $\sum\limits_{c=1}^N\varrho_c(1-\Theta_c^{(t)})(2\delta_c^2+4\omega_c^2\beta^2\Vert\bar{\mathbf v}_c^{(t)}-\mathbf w^*\Vert^2)\leq\phi^2$, (this will be part of the control algorithm, see Assumption~\ref{assump:sub_err}) we can further upper bound~\eqref{eq:A_new} and obtain the result in~\eqref{eq:e1_oneSTP}.
% \nm{sentence does not make greammatical sense: Assuming... yielding....}

% \nm{changed the order: e2 first and finally e3}
Next, we  bound $e_2$.
Using~\eqref{eq:v_c} we find that
    \begin{align} \label{eq:w-_3}
        &\bar{\mathbf v}^{(t+1)}=
        \bar{\mathbf v}^{(t)}
        -\eta_{k}\sum\limits_{d=1}^N\varrho_{d}\nabla \bar{F}_d(\bar{\mathbf v}_d^{(t)}).
    \end{align}
It then follows, after algebraic manipulations,
    \begin{align} 
        &\bar{\mathbf v}_c^{(t+1)}-\bar{\mathbf v}^{(t+1)}=\bar{\mathbf v}_c^{(t)}-\bar{\mathbf v}^{(t)}
        -\eta_{k}\Big(\nabla\bar F_c(\bar{\mathbf v}_c^{(t)})-\nabla\bar F_c(\bar{\mathbf v}^{(t)})\Big)
        % \nonumber\\&
        % -\eta_t\sum\limits_{j\in\mathcal S_{c}}\rho_{j,c}\mathbf n_{j}^{(t)}
        % +\eta_t\sum\limits_{d=1}^N\varrho_{d}\sum\limits_{j\in\mathcal S_{d}}\rho_{j,d}\mathbf n_{j}^{(t)}
        % \nonumber \\&
        % -\eta_t\sum\limits_{j\in\mathcal S_{c}}\rho_{j,c}\Big(\nabla F_j(\mathbf w_j ^{(t)})-\nabla F_j(\bar{\mathbf w}_c ^{(t)})\Big)
        % +\eta_t\sum\limits_{d=1}^N\varrho_{d}\sum\limits_{j\in\mathcal S_{d}}\rho_{j,d}\Big(\nabla F_j(\mathbf w_j ^{(t)})-\nabla F_j(\bar{\mathbf w}_d^{(t)})\Big)
        \nonumber \\&
        +\eta_{k}\sum\limits_{d=1}^N\varrho_{d}\Big(\nabla\bar F_d(\bar{\mathbf v}_d^{(t)})-\nabla\bar F_d(\bar{\mathbf v}^{(t)})\Big)
    %   \nonumber \\&
        -\eta_{k}\Big(\nabla\bar F_c(\bar{\mathbf v}^{(t)})-\nabla F(\bar{\mathbf v}^{(t)})\Big).
    \end{align}   
    Taking the norm-2 of both hand sides of the above equality and applying the triangle inequality results in
    \begin{align} \label{eq:tri_wc}
        &\Vert\bar{\mathbf v}_c^{(t+1)}-\bar{\mathbf v}^{(t+1)}\Vert\leq
        \left\Vert\bar{\mathbf v}_c^{(t)}-\bar{\mathbf v}^{(t)} -\eta_{k}[\nabla\bar F_c(\bar{\mathbf v}_c^{(t)})-\nabla\bar F_c(\bar{\mathbf v}^{(t)})]\right\Vert
        \nonumber \\&
        +\eta_{k}\sum\limits_{d=1}^N\varrho_{d}\Vert\nabla\bar F_d(\bar{\mathbf v}_d^{(t)})-\nabla\bar F_d(\bar{\mathbf v}^{(t)}))\Vert
        % \nonumber \\&
        +\eta_{k}\Vert\nabla\bar F_c(\bar{\mathbf v}^{(t)})-\nabla F(\bar{\mathbf v}^{(t)})\Vert.
    \end{align}   
    Using $\beta$-smoothness of $F_i(\cdot),\forall i$ (hence of $\bar F_d(\cdot)$), Definition \ref{gradDiv}, Fact~\ref{fact:3}, and adding over $\sum_c\rho_c$,
     we further bound the right hand side of~\eqref{eq:tri_wc} as
\begin{align} \label{eq:tri_wc2_3}
    &e_2^{(t+1)}\triangleq\sum\limits_{c=1}^N\varrho_{c}\Vert\bar{\mathbf v}_c^{(t+1)}-\bar{\mathbf v}^{(t+1)}\Vert\leq
    (1+\eta_{k}(\beta-\mu))\sum\limits_{c=1}^N\varrho_{c}\Vert\bar{\mathbf v}_c^{(t)}-\bar{\mathbf v}^{(t)}\Vert
    +2\omega\eta_{k}\beta\Vert\bar{\mathbf v}^{(t)}-\mathbf w^*\Vert
    +\eta_{k}\delta,
\end{align}   
which proves~\eqref{eq:e1_oneSTP}.
% \nm{wrong ref.. pleases check all refs}.
% \textbf{Finding the relationship between $\Vert\bar{\mathbf w}_c^{(t)}-\mathbf w^*\Vert$ and $\sum\limits_{j\in\mathcal S_c}\rho_{j,c}\Vert\mathbf w_j^{(t)}-\bar{\mathbf w}_c^{(t)}\Vert$}:
Finally, we  bound $e_3$. From \eqref{eq:w-_3}, we get 
% \nm{change sum c to sum d for consistency}
\begin{align} 
        &\bar{\mathbf v}^{(t+1)}-\mathbf w^* =~ \bar{\mathbf v}^{(t)}-\mathbf w^*-\eta_{k} \nabla F(\bar{\mathbf v}^{(t)})
        -\eta_{k} \sum\limits_{c=1}^N\varrho_{d} [\nabla \bar F_d(\bar{\mathbf v}_d^{(t)})-\nabla \bar F_d(\bar{\mathbf v}^{(t)})].
    \end{align}
    Taking the norm of both hand sides of the above equality and applying the triangle inequality gives us
    \begin{align} \label{29_3}
        &\Vert\bar{\mathbf v}^{(t+1)}-\mathbf w^*\Vert \leq \Vert\bar{\mathbf v}^{(t)}-\mathbf w^*-\eta_{k} \nabla F(\bar{\mathbf v}^{(t)})\Vert
        % +\eta_t \sum\limits_{c=1}^N\varrho_{c}\sum\limits_{j\in\mathcal S_{c}}\rho_{j,c} \Vert\mathbf n_{j}^{(t)}\Vert
        % \nonumber \\&
        % +\eta_t \sum\limits_{c=1}^N\varrho_{c}\sum\limits_{j\in\mathcal S_{c}}\rho_{j,c} \Vert\nabla F_j(\mathbf w_j^{(t)})-\nabla F_j(\bar{\mathbf w}_c^{(t)})\Vert
        % \nonumber \\&
        +\eta_{k} \sum\limits_{d=1}^N\varrho_{d} \Vert\nabla \bar F_d(\bar{\mathbf v}_d^{(t)})-\nabla \bar F_d(\bar{\mathbf v}^{(t)})\Vert.
    \end{align}
    Using $\beta$-smoothness of $F_i(\cdot)$ (hence of $\bar F_c(\cdot)$) and Fact~\ref{fact:3}, we further bound
    \begin{align}
        e_3^{(t+1)}\triangleq\Vert\bar{\mathbf v}^{(t+1)}-\mathbf w^*\Vert \leq& 
         (1-\eta_{k}\mu)
        \Vert\bar{\mathbf v}^{(t)}-\mathbf w^*\Vert
        +\eta_{k}\beta \sum\limits_{d=1}^N\varrho_{d} \Vert\bar{\mathbf v}_d^{(t)}-\bar{\mathbf v}^{(t)}\Vert,
    \end{align}
    yielding~\eqref{eq:e3_oneSTP}.
\end{proof}

% \section{Proof of Proposition~\ref{Local_disperse}} \label{app:Local_disperse}
\begin{lemma} \label{lem:main}
    Under Assumptions \ref{beta},~\ref{assump:SGD_noise} and~\ref{assump:sub_err}, if $\eta_{k}\leq\frac{2}{\beta+\mu},~\forall k$, using {\tt DFL} for ML model training, $e_1^{t_{k+1}}$, $e_2^{t_{k+1}}$ and $e_3^{(t_{k+1})}$ across global synchronization periods can be bounded as 
    % \nm{assumption on control algo (phi) missing. state as an Assumption in the main text and recall it here}
    % \nm{Use e2 and e3!}
 \begin{align} \label{eq:e1_orig}
    &(e_1^{t_{k+1}})^2
    \leq [(1-\alpha)(1-\mu\eta_{k})^{2(\tau-\Delta)}+\alpha(1-\mu\eta_{k})^{2\tau}](e_1^{(t_k)})^2
    % \nonumber\\&
    +[\tau-(1-\alpha)\Delta]\eta_{k}^2(\sigma^2+\phi^2),
\end{align} 
\begin{align} \label{eq:x1_syn_inter1}
    e_2^{(t_{k+1})}&\leq 
    \alpha\Pi_{+,t_{k+1}}e_2^{(t_k)}
    +\alpha\frac{4\omega}{\sqrt{8\omega+1}}[\Pi_{+,t_{k+1}}-1]e_3^{(t_k)}
    % \nonumber \\&
    % \nonumber\\& 
    +\alpha\frac{\mu}{-\beta^2\lambda_+\lambda_-}[\Pi_{+,t_{k+1}}-1]\delta,
\end{align}
% \nm{e3 is wrong. This is not what you are using later on... we need a tighter bound with Pi+ and Pi-}
\begin{align} \label{eq:wc-w*_sync1}
    &e_3^{(t_{k+1})}\leq
    \Psi_1(\eta_k) e_3^{(t_k)}
      % \nonumber \\&
    +2g_{3}[(1-\alpha)\Pi_{+,t_{k+1}-\Delta}+\alpha\Pi_{+,t_{k+1}}-1]e_2^{(t_k)}
    \nonumber\\&
    % +[g_{5}(\Pi_{+,t}-1)+g_{6}(\Pi_{-,t}-1)]
    % [\sigma/\beta+\sum\limits_{d=1}^N\varrho_{d}\epsilon_{d}^{(0)}] \nonumber\\&
    +\left[(1-\alpha)[g_{5}(\Pi_{+,t_{k+1}-\Delta}-1)+g_{6}(\Pi_{-,t_{k+1}-\Delta}-1)] 
    +\alpha[g_{5}(\Pi_{+,t_{k+1}}-1)+g_{6}(\Pi_{-,t_{k+1}}-1)]\right]\delta/\beta.
\end{align}
where 
\begin{align}\label{eq:Psi_1}
    \Psi_1(\eta_k)\triangleq (1-\alpha)[g_{1}\Pi_{+,t_{k+1}-\Delta}+g_{2}\Pi_{-,t_{k+1}-\Delta}]
    + \alpha[g_{1}\Pi_{+,t_{k+1}}+g_{2}\Pi_{-,t_{k+1}}]
\end{align}
and
\begin{align}\label{eq:eign+-}
    \lambda_{\pm} =\frac{1}{2}-\frac{\mu}{\beta}\pm\frac{\sqrt{8\omega+1}}{2},
\end{align}
with $\lambda_+>0$, $\lambda_-<0$, $\Pi_{\{+,-\},t}=[1+\eta_{k}\beta\lambda_{\{+,-\}}]^{t-t_{k}}$ and $g_1$, $g_2$, $g_3$, $g_5$, $g_6$ defined in~\eqref{eq:g1},~\eqref{eq:g2},~\eqref{eq:g3},~\eqref{eq:g5},~\eqref{eq:g6}.
% $\lambda_+ =\frac{1}{2}-\frac{\mu}{\beta}+\frac{\sqrt{8\omega+1}}{2}>0$ and $\lambda_-= \frac{1}{2}-\frac{\mu}{\beta}-\frac{\sqrt{8\omega+1}}{2}<0$.
\end{lemma}

\begin{proof}
% \addFL{
% \nm{follow the order, start with e1. first}
\subsection{Obtaining the upper bound of $e_1^{(t_{k+1})}$ at global synchronization} 
Using the one-step dynamics in~\eqref{eq:e1_oneSTP}, Lemma~\ref{lem:An_oneSTP}, we find before global synchronization
\begin{align}
\label{e1beforesync}
    &(e_1^{(t)})^2
    \leq
    (1-\mu\eta_{k})^{2(t-t_k)}(e_1^{(t_k)})^2
    +\sum_{\ell=0}^{t-t_k-1}(1-\mu\eta_{k})^{2\ell}\eta_{k}^2(\sigma^2+\phi^2)
    \nonumber \\&
    \leq
    (1-\mu\eta_{k})^{2(t-t_k)}(e_1^{(t_k)})^2
    +(t-t_k)\eta_{k}^2(\sigma^2+\phi^2).
\end{align}
         Next, we obtain the behavior of $e_1^{(t)}$ at global synchronization by using the definition of $\mathbf w_i^{(t)}$, $\bar{\mathbf v}_c^{(t)}$ and the global synchronization scheme in~\eqref{eq:aggr_alpha} as follows:
\begin{align}
    &\mathbf w_i^{(t_{k+1})}-\bar{\mathbf v}_c^{(t_{k+1})}
    = (1-\alpha)\sum\limits_{d=1}^N\varrho_d\sum_{j\in\mathcal S_d}\rho_{j,d}({\mathbf w}_j^{(t_{k+1}-\Delta)}-\bar{\mathbf v}_d^{(t_{k+1}-\Delta)})
    +\alpha\left(\widetilde{\mathbf w}_i^{(t_{k+1})}-\widetilde{\mathbf v}_c^{(t_{k+1})}\right), 
\end{align}
where $\widetilde{\mathbf w}_i^{(t_{k+1})}$ and $\widetilde{\mathbf v}_c^{(t_{k+1})}$ are the local model and subnet noise-free variables right before global synchronization, as opposed to $\mathbf w_i^{(t_{k+1})}$ and $\mathbf v_c^{(t_{k+1})}$ defined right after global synchronization.
  Taking the squared norm on both hand sides of the above equality and applying Jensen's inequality (convexity of $\Vert\cdot\Vert^2$) yields
\begin{align} 
    &\Vert\mathbf w_i^{(t_{k+1})}-\bar{\mathbf v}_c^{(t_{k+1})}\Vert^2
    \leq (1-\alpha)\sum\limits_{d=1}^N\varrho_d\sum_{j\in\mathcal S_d}\rho_{j,d}\Vert{\mathbf w}_j^{(t_{k+1}-\Delta)}-\bar{\mathbf v}_d^{(t_{k+1}-\Delta)}\Vert^2
    +\alpha\Vert\widetilde{\mathbf w}_i^{(t_{k+1})}-\widetilde{\mathbf v}_c^{(t_{k+1})}\Vert^2.
\end{align} 
% \nm{please fix c index. Used d}
Therefore, 
\begin{align} \label{eq:e1_sy}
    &(e_1^{(t_{k+1})})^2=\sum\limits_{c=1}^N\varrho_c\sum_{i\in\mathcal S_c}\rho_{i,c}\Vert\mathbf w_i^{(t_{k+1})}-\bar{\mathbf v}_c^{(t_{k+1})}\Vert^2
        \nonumber \\&
    \leq (1-\alpha)\sum\limits_{c=1}^N\varrho_c\sum_{j\in\mathcal S_c}\rho_{j,c}\Vert{\mathbf w}_j^{(t_{k+1}-\Delta)}-\bar{\mathbf v}_c^{(t_{k+1}-\Delta)}\Vert^2
    +\alpha\sum\limits_{c=1}^N\varrho_c\sum_{j\in\mathcal S_c}\rho_{j,c}\left\Vert\widetilde{\mathbf w}_j^{(t_{k+1})}-\widetilde{\mathbf v}_c^{(t_{k+1})}\right\Vert^2.
\end{align} 
Note that the terms above are upper bounded by \eqref{e1beforesync} before global synchronization, hence they can be bounded as
$$
\sum\limits_{c=1}^N\varrho_c\sum_{j\in\mathcal S_c}\rho_{j,c}\Vert{\mathbf w}_j^{(t_{k+1}-\Delta)}-\bar{\mathbf v}_c^{(t_{k+1}-\Delta)}\Vert^2
    \leq
    (1-\mu\eta_{k})^{2(\tau-\Delta)}(e_1^{(t_k)})^2+[\tau-\Delta]\eta_{k}^2(\sigma^2+\phi^2),
$$
$$
 \sum\limits_{c=1}^N\varrho_c\sum_{j\in\mathcal S_c}\rho_{j,c}\left\Vert\widetilde{\mathbf w}_j^{(t_{k+1})}-\widetilde{\mathbf v}_c^{(t_{k+1})}\right\Vert^2
    \leq
    (1-\mu\eta_{k})^{2\tau}(e_1^{(t_k)})^2
    +\tau\eta_{k}^2(\sigma^2+\phi^2).
$$
Using these bounds in~\eqref{eq:e1_sy} yields~\eqref{eq:e1_orig}. 

\subsection{Solving the coupled dynamics between $e_2$ and $e_3$} 

Let $\mathbf x^{(t)}=
     \begin{bmatrix}
         e_2^{(t)} & e_3^{(t)}
     \end{bmatrix}^\top$, with $e_2$ and $e_3$ defined in~\eqref{eq:def_e2} and~\eqref{eq:def_e3}. Using the one-step dynamics found in Lemma~\ref{lem:main} for $t\in\mathcal T_k$, we find (here, the vector inequality is entry-wise)
    \begin{align} \label{69}
        \mathbf x^{(t+1)}
        &\leq  
        [\mathbf I+\eta_{k}\beta\mathbf B]\mathbf  x^{(t)}
        +\eta_{k}\beta\mathbf z, 
    \end{align}
    where
    $
\mathbf z=  
\mathbf e_1\delta/\beta
    $
    ,    
    $\mathbf B=\begin{bmatrix} 1-\frac{\mu}{\beta} & 2\omega
    \\ 1 & -\frac{\mu}{\beta}\end{bmatrix}$, $\mathbf e_1=[1,0]^\top$. We also define  $\mathbf e_2=[0,1]^\top$.
    We aim to derive an upper bound on $\mathbf x^{(t)}$ denoted by $\mathbf x^{(t)}\leq\bar{\mathbf x}^{(t)}$. Using the above inequality, such upper bound is given by the recursion
     \begin{align} \label{69_3}
 \bar{\mathbf x}^{(t+1)}
=  
        [\mathbf I+\eta_{k}\beta\mathbf B]\bar{\mathbf x}^{(t)}
        +\eta_{k}\beta\mathbf z, \ \forall t\in\mathcal T_k,
    \end{align}
 initialized as $\bar{\mathbf x}^{(t_k)}={\mathbf x}^{(t_k)}$.
 To solve the coupled dynamic, we first apply eigen-decomposition on $\mathbf B$ yielding
    $\mathbf B=\mathbf U\mathbf D\mathbf U^{-1}$, where
    $$\mathbf D=\begin{bmatrix} \lambda_+ & 0
    \\ 0 & \lambda_-\end{bmatrix},\ 
    \mathbf U=\begin{bmatrix} \frac{1}{2}(1+\sqrt{8\omega+1}) & -\frac{1}{2}(\sqrt{8\omega+1}-1)
    \\ 1 & 1\end{bmatrix},\ 
\mathbf U^{-1}=\frac{1}{
    \sqrt{8\omega+1}
    }\begin{bmatrix} 1 & \frac{1}{2}(\sqrt{8\omega+1}-1)
    \\ -1 &\frac{1}{2}(\sqrt{8\omega+1}+1)\end{bmatrix}$$
with eigenvalues given by~\eqref{eq:eign+-}.
Using this decomposition in~\eqref{69_3} yields by induction
    \begin{align} 
    \bar{\mathbf x}^{(t)}=
\mathbf U(\mathbf I+\eta_{k}\beta\mathbf D)^{t-t_{k}}
         \mathbf U^{-1}{\mathbf x}^{(t_k)}
+\mathbf U\left[(\mathbf I+\eta_{k}\beta\mathbf D)^{t-t_{k}}-\mathbf I\right]
         \mathbf D^{-1}\mathbf U^{-1}\mathbf z.
    \end{align}
    % \textbf{(Part III) Finding the connection between the bound on ${\mathbf x}^{(t)}$ and the expressions for $A^{(t)}$ and $B^{(t)}$}:
Therefore,
% \triangleq \bar y^{(t)}
\begin{align} \label{eq:x2_dyn}
    e_2^{(t)}&=\mathbf e_1^\top\mathbf x^{(t)}\leq 
    \mathbf e_1^\top\bar{\mathbf x}^{(t)}
   \nonumber\\&=
  [m_{1}\Pi_{+,t}+m_{2}\Pi_{-,t}]e_3^{(t_k)}
  \nonumber \\&
+[m_{3}\Pi_{+,t}+m_{4}\Pi_{-,t}]e_2^{(t_k)}
\nonumber\\&
% +[m_{5}(\Pi_{+,t}-1)+m_{6}(\Pi_{-,t}-1)]
% [\sigma/\beta+\sum\limits_{d=1}^N\varrho_{d}\epsilon_{d}^{(0)}] \nonumber\\&
+[m_{5}(\Pi_{+,t}-1)+m_{6}(\Pi_{-,t}-1)]\delta/\beta, 
    \end{align}
    where we have defined $\Pi_{\{+,-\},t}=[1+\eta_{k}\beta\lambda_{\{+,-\}}]^{t-t_{k}}$ and constants $m_{1}$-$m_{8}$ as  
        % \nm{please align left}
    \begin{flalign}
        m_{1}\triangleq
        &[\mathbf U]_{1,1}[\mathbf U^{-1}]_{1,2}
        =
        \frac{2\omega}{\sqrt{8\omega+1}},&
    \end{flalign}
    % \nm{use $[\mathbf A]_{i,j}$ instead of $\mathbf e_i^\top\mathbf A\mathbf e_j$...}
    \begin{flalign}
        m_{2}\triangleq
        &[\mathbf U]_{1,2}[\mathbf U^{-1}]_{2,2}
        =
        -m_1, &
    \end{flalign}
    \begin{flalign}
        m_{3}\triangleq
         &[\mathbf U]_{1,1}[\mathbf U^{-1}]_{1,1}
         =\frac{\sqrt{8\omega+1}+1}{2\sqrt{8\omega+1}}, &
    \end{flalign}
    \begin{flalign}
        m_{4}\triangleq
        &[\mathbf U]_{1,2}[\mathbf U^{-1}]_{2,1}
        =1-m_3\geq 0, &
    \end{flalign}
\begin{flalign}
    m_{5}
    \triangleq
    &[\mathbf U]_{1,1}[\mathbf D^{-1}\mathbf U^{-1}]_{1,1}
    =
    \frac{\mu(\sqrt{8\omega+1}+1)+4\omega\beta}{-2\beta\lambda_+\lambda_-\sqrt{8\omega+1}}=\frac{\sqrt{8\omega+1}+1}{2\sqrt{8\omega+1}\lambda_+}\geq 0,&
\end{flalign}
\begin{flalign}
    m_{6}\triangleq
    &[\mathbf U]_{1,2}[\mathbf D^{-1}\mathbf U^{-1}]_{2,1}
    =
    \frac{\mu(\sqrt{8\omega+1}-1)-4\omega\beta}{-2\beta\lambda_+\lambda_-\sqrt{8\omega+1}}
    =\frac{\sqrt{8\omega+1}-1}{-2\sqrt{8\omega+1}\lambda_-}\leq 0.&
\end{flalign}
Since $\Pi_{-,t}\leq\Pi_{+,t}$, $\Pi_{+,t}-\Pi_{-,t}\leq 2[\Pi_{+,t}-1]$, 
% \nm{can be proved using binomial expansion}
 $m_3+m_4=1$ and $\Pi_{-,t}-1\geq-(\Pi_{+,t}-1)$, we can further upper bound
 % \nm{unless I did something wrong m6 is negative! therefore cannot use $\Pi_{-,t}-1\leq0$.
 % Use $1-\Pi_{-,t}\leq \Pi_{+,t}-1$ instead.
 % }
\begin{align} \label{eq:E_1}
    e_2^{(t)}&\leq 
    \frac{4\omega}{\sqrt{8\omega+1}}[\Pi_{+,t}-1]e_3^{(t_k)}
    % \nonumber \\&
    +\Pi_{+,t}e_2^{(t_k)}
    % \nonumber\\& 
    +\frac{\mu}{-\beta^2\lambda_+\lambda_-}(\Pi_{+,t}-1)\delta
    . 
    \end{align}
% Revisit~\eqref{eq:x2_dyn}, we get
% coupled dynamics of x1 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Similarly, from the expression of $\bar{\mathbf x}^{(t)}$ above, we find
% \triangleq \bar y^{(t)}
\begin{align} \label{eq:x2_dyn}
    e_3^{(t)}&=\mathbf e_2^\top\mathbf x^{(t)}\leq 
    \mathbf e_2^\top\bar{\mathbf x}^{(t)}
   \nonumber\\&=
  [g_{1}\Pi_{+,t}+g_{2}\Pi_{-,t}]e_3^{(t_k)}
  \nonumber \\&
+[g_{3}\Pi_{+,t}+g_{4}\Pi_{-,t}]e_2^{(t_k)}
\nonumber\\&
% +[g_{5}(\Pi_{+,t}-1)+g_{6}(\Pi_{-,t}-1)]
% [\sigma/\beta+\sum\limits_{d=1}^N\varrho_{d}\epsilon_{d}^{(0)}] \nonumber\\&
+[g_{5}(\Pi_{+,t}-1)+g_{6}(\Pi_{-,t}-1)]\delta/\beta, 
    \end{align}
    where we have defined $g_{1}$-$g_{8}$ as
    % \nm{use $[]_{i,j}$}
    % \nm{please align left}
    \begin{flalign}\label{eq:g1}
        g_{1}\triangleq
        &[\mathbf U]_{2,1}[\mathbf U^{-1}]_{1,2}
        =
        \frac{1}{2}(1-\frac{1}{\sqrt{8\omega+1}})\geq 0,&
    \end{flalign}
    \begin{flalign}\label{eq:g2}
        g_{2}\triangleq
        &[\mathbf U]_{2,2}[\mathbf U^{-1}]_{2,2}
        =
        \frac{1}{2}(1+\frac{1}{\sqrt{8\omega+1}})=1-g_1\geq 0,&
    \end{flalign}
    \begin{flalign}\label{eq:g3}
        g_{3}\triangleq
        &[\mathbf U]_{2,1}[\mathbf U^{-1}]_{1,1}
         =\frac{1}{\sqrt{8\omega+1}}\in [1/3,1],&
    \end{flalign}
    \begin{flalign}
        g_{4}\triangleq
        &[\mathbf U]_{2,2}[\mathbf U^{-1}]_{2,1}
        =-g_3,&
    \end{flalign}
    \begin{flalign}\label{eq:g5}
        g_{5}
        \triangleq
        &[\mathbf U]_{2,1}[\mathbf D^{-1}\mathbf U^{-1}]_{1,1}
        =
        \frac{1}{\lambda_+\sqrt{1+8\omega}}\geq 0,&
    \end{flalign}
    \begin{flalign}\label{eq:g6}
        g_{6}\triangleq
        &[\mathbf U]_{2,2}[\mathbf D^{-1}\mathbf U^{-1}]_{2,1}
        =
        \frac{1}{-\lambda_-\sqrt{1+8\omega}}\geq0.&
    \end{flalign}
Since $\Pi_{+,t}-\Pi_{-,t}\leq 2[\Pi_{+,t}-1]$ and $g_4=-g_3$, we can further upper bound $e_3$ as
\begin{align} \label{eq:E_2}
    &e_3^{(t)}\leq
     [g_{1}\Pi_{+,t}+g_{2}\Pi_{-,t}]e_3^{(t_k)}
      \nonumber \\&
    +2g_3[\Pi_{+,t}-1]e_2^{(t_k)}
    \nonumber\\&
    % +[g_{5}(\Pi_{+,t}-1)+g_{6}(\Pi_{-,t}-1)]
    % [\sigma/\beta+\sum\limits_{d=1}^N\varrho_{d}\epsilon_{d}^{(0)}] \nonumber\\&
    +[g_{5}(\Pi_{+,t}-1)+g_{6}(\Pi_{-,t}-1)]\delta/\beta.
\end{align}
Next, we use these results to bound $e_2$ and $e_3$ at global synchronization.
% \nm{seems good enough for our purpose}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Obtaining the upper bound of $e_2^{(t_{k+1})}$ at global synchronization.} 
% \nm{I dont know why you were doing that, so I cut it. You already have the results of solving the induction, why are you doing an additional step??}
To obtain the behavior of $\bar{\mathbf v}_c^{(t_{k+1})}-\bar{\mathbf v}^{(t_{k+1})}$ after global synchronization, we use the definition of $\bar{\mathbf v}_c^{(t)}$, $\bar{\mathbf v}^{(t)}$ and the global synchronization scheme in~\eqref{eq:aggr_alpha}, we have  
% \nm{please use constant alpha} 
\begin{align}
    \bar{\mathbf v}_c^{(t_{k+1})}-\bar{\mathbf v}^{(t_{k+1})}
    =& (1-\alpha)(\bar{\mathbf v}^{(t_{k+1}-\Delta)}-\bar{\mathbf v}^{(t_{k+1}-\Delta)})
    +\alpha\left(\widetilde{\mathbf v}_c^{(t_{k+1})}-\widetilde{\mathbf v}^{(t_{k+1})}\right)
    \nonumber \\
    =&
    \alpha\left(\widetilde{\mathbf v}_c^{(t_{k+1})}-\widetilde{\mathbf v}^{(t_{k+1})}\right),
    % \nm{fix\ conflict\ of indeces.. use\ d\ instead\ of\ c}
\end{align}
where $\widetilde{\mathbf v}^{(t_{k+1})}$ is the global noise-free variable right before global synchronization, as opposed to $\mathbf v^{(t_{k+1})}$ defined right after global synchronization.
Taking the norm of both hand sides of the above equality and adding over $\sum_c\rho_c$ yields
\begin{align} \label{eq:wc-w*_sync2}
        &e_2^{(t_{k+1})}=\sum_c\rho_c\Vert\bar{\mathbf v}_c^{(t_{k+1})}-\bar{\mathbf v}^{(t_{k+1})}\Vert
        = \alpha\sum_c\rho_c\left\Vert\widetilde{\mathbf v}_c^{(t_{k+1})}-
        \widetilde{\mathbf v}^{(t_{k+1})}\right\Vert.
\end{align} 
Note that, since $\widetilde{\mathbf v}_c^{(t_{k+1})}$ represents the noise-free variable right before the global synchronization, the right hand side above can be bounded
via \eqref{eq:E_1}, yielding the final result \eqref{eq:x1_syn_inter1}.
\subsection{Obtaining upper bound of $e_3^{(t_{k+1})}$ at global synchronization.}
% \nm{I dont know why you were doing that, so I cut it. You already have the results of solving the induction, why are you doing an additional step??}
To obtain the behavior of $\bar{\mathbf v}^{(t_{k+1})}-\mathbf w^*$ after global synchronization,  we use the definition of $\bar{\mathbf v}^{(t)}$ and the global synchronization scheme in~\eqref{eq:aggr_alpha}, we have  
\begin{align}
    & \bar{\mathbf v}^{(t_{k+1})}-\mathbf w^*
        = (1-\alpha)[\bar{\mathbf v}^{(t_{k+1}-\Delta)}-\mathbf w^*]
        +\alpha\left[\widetilde{\mathbf v}^{(t_{k+1})}-\mathbf w^*\right].
\end{align} 
Note that $\widetilde{\mathbf v}^{(t)}$ is equivalent to $\bar{\mathbf v}^{(t)}$ before conducting global synchronization. Taking the norm of both hand sides of the above equality and applying the triangle inequality
gives us
\begin{align} \label{eq:wc-w*_sync_tmp}
        &e_3^{(t_{k+1})}= \Vert\bar{\mathbf v}^{(t_{k+1})}-\mathbf w^*\Vert
        \leq (1-\alpha)\Vert\bar{\mathbf v}^{(t_{k+1}-\Delta)}-\mathbf w^*\Vert
        +\alpha\Vert\widetilde{\mathbf v}^{(t_{k+1})}-\mathbf w^*\Vert.
\end{align} 
We further upper bound the right hand using~\eqref{eq:E_2} to obtain the result in\eqref{eq:wc-w*_sync1}.
\end{proof}


\begin{fact}\label{fact:1} 
Consider $n$ random real-valued vectors $\mathbf x_1,\cdots,\mathbf x_n\in\mathbb R^m$, the following inequality holds: 
 \begin{equation}
     \sqrt{\mathbb E\left[\Big\Vert\sum\limits_{i=1}^{n} \mathbf x_i\Big\Vert^2\right]}\leq \sum\limits_{i=1}^{n} \sqrt{\mathbb E[\Vert\mathbf x_i\Vert^2]}.
 \end{equation}
\end{fact}
\begin{proof} Note that
    % Using the following result of Cauchy-Schwarz Inequality
    % \begin{align}
    %     \mathbb E[XY] \leq \sqrt{\mathbb E[X^2]\mathbb E[ Y^2]},
    % \end{align}
    % we obtain
    \begin{align}
        &\sqrt{\mathbb E\left[\Big\Vert\sum\limits_{i=1}^{n}\mathbf x_i\Big\Vert^2\right]}
        =
        \sqrt{\sum\limits_{i,j=1}^{n}\mathbb E [\mathbf x_i^\top\mathbf x_j]}
        \overset{(a)}{\leq}
\sum\limits_{i,j=1}^{n}\sqrt{\mathbb E [\Vert\mathbf x_i\Vert^2] \mathbb E[\Vert\mathbf x_j\Vert^2]]}
        % \nonumber \\&
        =
        \sum\limits_{i=1}^{n} \sqrt{\mathbb E[\Vert\mathbf x_i\Vert^2]},
    \end{align}
    where $(a)$ follows from Holder's inequality, $\mathbb E[|XY|] \leq \sqrt{\mathbb E[|X|^2]\mathbb E[ |Y|^2]}$.
\end{proof}


\begin{fact}\label{fact:3} Let $f(\cdot)$ be $\mu$-strong convex and $\beta$-smooth and $\eta\leq\frac{2}{\beta+\mu}$, the following inequality holds
\begin{align}
    \left\Vert\mathbf w_1-\mathbf w_2 -\eta(\nabla f(\mathbf w_1)-\nabla f(\mathbf w_2))\right\Vert
    \leq (1-\mu\eta)\left\Vert\mathbf w_1-\mathbf w_2\right\Vert,\ \forall \mathbf w_1,\mathbf w_2\in\mathbb R^M.
\end{align}    
\end{fact}
\begin{proof}
    \begin{align} \label{eq:stx_3}
        &\left\Vert\mathbf w_1-\mathbf w_2 -\eta(\nabla f(\mathbf w_1)-\nabla f(\mathbf w_2))\right\Vert
        \nonumber \\&
        =
        \sqrt{\Vert\mathbf w_1-\mathbf w_2\Vert^2+\eta^2\Vert\nabla f(\mathbf w_1)-\nabla f(\mathbf w_2)\Vert^2-2\eta(\mathbf w_1-\mathbf w_2)^\top(\nabla f(\mathbf w_1)-\nabla f(\mathbf w_2))}
        \nonumber \\&
        \overset{(a)}{\leq} 
        \sqrt{\left(1-\eta\frac{2\mu\beta}{\mu+\beta}\right)\Vert\mathbf w_1-\mathbf w_2\Vert^2-\eta\left(\frac{2}{\mu+\beta}-\eta\right)\Vert\nabla f(\mathbf w_1)-\nabla f(\mathbf w_2)\Vert^2}
        \nonumber \\&
        \overset{(b)}{\leq}
%        \sqrt{\left(1-2\mu\eta+\mu^2\eta^2\right)\Vert\mathbf w_1-\mathbf w_2\Vert^2}        \leq 
        (1-\eta\mu)\Vert\mathbf w_1-\mathbf w_2\Vert,
    \end{align}
    where $(a)$ comes from~\cite[Theorem 2.1.12]{Nesterov}, i.e., $(\mathbf w_1-\mathbf w_2)^\top(\nabla f(\mathbf w_1)-\nabla f(\mathbf w_2))\geq\frac{\mu\beta}{\mu+\beta}\Vert\mathbf w_1-\mathbf w_2\Vert^2+\frac{1}{\mu+\beta}\Vert\nabla f(\mathbf w_1)-\nabla f(\mathbf w_2)\Vert^2$ and $(b)$ results from
    $\Vert\nabla f(\mathbf w_1)-\nabla f(\mathbf w_2)\Vert\geq \mu\Vert\mathbf w_1-\mathbf w_2\Vert$ (strong convexity)
 and $\eta\leq \frac{2}{\mu+\beta}$.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagebreak
