\appendix
\numberwithin{equation}{section}
\numberwithin{figure}{section}
\numberwithin{table}{section}
\section*{Appendix}
We offer supplementary materials in this document. Specifically, we provide the detailed algorithm of \ours in Section \ref{sec_append:algo}. In Section \ref{sec_append:details}, we present implementation details including model architectures, optimization, implementations of baseline methods, and the range of hyperparameters used. In addition, we report some additional results for a naive debiasing scenario in Section \ref{sec_append:naive_debiasing} and other various settings in Section \ref{sec_append:additional_results}. Finally, we discuss the results of our study for the backward transfer on Split ImageNet-100 in Section \ref{sec_append:discussion}.
\section{\ours sampling algorithm}
\label{sec_append:algo}
\begin{algorithm}
    \caption{\methodnamefull}
    \label{alg:ours}
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \SetKwInOut{Init}{Init}
    \Init{Memory $\mathcal{M}=\{\{\}, \dots, \}$ with capacity $K$, Labels $\mathcal{L}=\{\}$, Count $C=\{0,\dots\}$ 
    }
    \Input{a data sample $(x_i, a_i, y_i)$, task id $t$}
    
    \Output{$\mathcal{M}$}
    % $N_{y} \gets N_{y} + |\mathcal{Y}_{t}|$\;
    % $\mathcal{Y} \gets \mathcal{M}_{t-1}.\mathcal{Y} \cup \mathcal{Y}_{t}$\;
    $k \gets \frac{K}{|\mathcal{L}| \times |\mathcal{A}|}$\;
    \If{$C\big[(a_i, y_i, t)\big] < k$}{
    \eIf{$\Sigma_{a\in\mathcal{A}, (y,t)\in\mathcal{L}} C\big[(a,y,t)\big] < K$}{
        $\mathcal{M}\big[(a_i, y_i, t)\big] = \mathcal{M}\big[(a_i, y_i, t)\big] \cup (x_i, a_i, y_i, t)$\;
    } 
    {
        $(a_j, y_j, t_j)$ = $\operatorname{argmax}_{(a, y, t)} C\big[(a,y,t)\big] $\;
        $\mathcal{M}\big[(a_j, y_j, t_j)\big].\operatorname{pop}()$\;
        $\mathcal{M}\big[(a_i, y_i, t)\big] = \mathcal{M}\big[(a_i, y_i, t)\big] \cup (x_i, a_i, y_i, t)$\;
        $C[(a_j, y_j, t_j)] = C[(a_j, y_j, t_j)] - 1$ \;
    }
    \If{$C\big[(a_i, y_i, t)\big]==0$}{
        $\mathcal{L} = \mathcal{L} \cup (y_i, t)$\;
    }
        $C\big[(a_i, y_i, t)\big] = C\big[(a_i, y_i, t)\big] + 1$\;
    }
\end{algorithm}
\section{More implementation details}
\label{sec_append:details}
\subsection{Model architectures and optimization}
For all datasets, we used the AdamW optimizer \cite{adamw} with the following hyperparameters: learning rate of 0.001, weight decay of 0.01, $\beta_1$ of 0.9 , $\beta_2$ of 0.999, and $\epsilon$ of $10^{-8}$. 
For Split CIFAR-100S, we trained ResNet-56 \cite{resnet} from scratch for 70 epochs using a batch size of 256. 
For CelebA and Split ImageNet-100, we trained ResNet-18 from scratch for 50 and 70 epochs, respectively, using a batch size of 128. We incorporated the cosine annealing learning rate decay, with the maximum number of iterations set to the same as the number of training epochs.

\subsection{Implementations of continual learning methods}
In the original Elastic Weight Consolidation (EWC) algorithm \cite{ewc}, the snapshot of a CL model should be stored whenever the model is updated from a new task. This stored model is then used to calculate the importance scores of model parameters in the new task. Namely, the algorithm requires a linearly growing amount of memory to store a sequence of models, which is space-inefficient. To address this issue, we implemented online EWC, proposed in \cite{schwarz2018progress}, which averages the importance scores in an online manner without storing a set of models. 

For Learning Without Forgetting (LWF) \cite{li2017learning}, we used an average of the distillation losses for each head to balance between the cross entropy loss and the distillation losses.

For Experience Replay (ER) \cite{er}, incremental classifier and representation learning (iCaRL) \cite{rebuffi2017icarl} and Packnet \cite{mallya2018packnet}, we implemented the same as their original versions. For ER, we employed the Reservoir sampling \cite{reservoir}  as a strategy for updating the exemplar memory.  

\subsection{Hyperparameters for each result}
In our experiments, we evaluated CL methods several times by varying their hyperparameters based on the sets of candidates. The  candidates are uniformly distributed on a logarithmic scale within a given range. For all figures presented in Section 4 and 5, we then plotted results for some of those hyperparameter candidates. We note that we omitted some overlapped results in Section 4 to enhance visibility. For the table results in Section 6, we tuned the hyperparameters for regularization based methods and Group DRO using the same candidates. We included Table \ref{table:hyperparams} to provide full ranges of hyperparameters tested. 
We note that the memory size specified in Table \ref{table:hyperparams} represents the fraction of the number of training images included in one of all tasks except the last one. 
\begin{table}[t]
    % \vskip -0.5in
    \caption{\small \textbf{Hyperparameter search ranges.}}
    \label{table:hyperparams}
    \centering
    \small
    \begin{tabular}{ccc}
    \toprule
        Method & Hyperparameter & Search range \\ \midrule
        EWC \cite{ewc} & Regularization strength $\lambda$ &[$10^0, 10^9$] \\\midrule
        LWF \cite{li2017learning} & Regularization strength $\lambda$ &[$10^{-2}, 3\times10^{2}$] \\\midrule
        ER \cite{er} & Memory size & [$10^{-3}, 10^{0}$] \\ \midrule
        iCaRL \cite{rebuffi2017icarl} & Memory size & [$10^{-3}, 10^{0}$]  \\ \midrule
        PackNet \cite{mallya2018packnet}  & Pruning ratio $r$ & [$10^{-1}, 8\times10^{-1}$] \\ \midrule
        Group DRO \cite{groupdro}  & Learning rate of $q$ &  [$10^{-8}, 10^2$] \\ 
        \bottomrule
    \end{tabular}
\end{table}
\subsection{Datasets}
\noindent\textbf{Split CIFAR-100S}. In the training dataset of each task, the first five classes are skewed toward the color group and the latter skewed toward the grayscale group, given the skew ratio. For the test dataset of each task, we have pairs of the same images; ones in color, and ones in grayscale. Fig \ref{fig:split_cifar100s_samples} illustrates some training and test samples in Split CIFAR-100S.

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.4\linewidth}
        \includegraphics[width=0.9\linewidth]{figures/cifar100_sample_train.pdf}
        \caption{Training samples}
        \label{fig:split_cifar100s_train}
    \end{subfigure}
    % \hspace{1cm}
    \begin{subfigure}[t]{0.4\linewidth}
        \includegraphics[width=0.9\linewidth]{figures/cifar100_sample_test.pdf}
        \caption{Test samples}
        \label{fig:split_cifar_100s_test}
    \end{subfigure}
    \caption{\small {\bf Samples in a certain task with bias level of 2 in Split CIFAR-100S.} Each row represents a specific class within the task. The top three rows represent classes biased toward the grayscale samples, while the bottom three rows contain classes biased toward the color samples. The test dataset includes pairs of images, where each pair contains one grayscale and one color version of the same image.}
    \label{fig:split_cifar100s_samples}
\end{figure*}

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.4\linewidth}
        \includegraphics[width=0.9\linewidth]{figures/Imagenet_samples_without_carton.pdf}
        \caption{Without ``Carton'' class}
        \label{fig:split_imagenet_train_wo_carton}
    \end{subfigure}
    % \hspace{1cm}
    \begin{subfigure}[t]{0.4\linewidth}
        \includegraphics[width=0.9\linewidth]{figures/Imagenet_samples_with_carton.pdf}
        \caption{With ``Carton'' class}
        \label{fig:split_imagenet_train_w_carton}
    \end{subfigure}
    \caption{\small \textbf{Training samples in Split ImageNet-100}. Two plots show training samples in a certain task with different bias levels, \ie, 0 \& 6. Each row represents a specific class within the task. The last row of the right plot is the carton class.}
    \label{fig:split_imagenet_train_samples}
\end{figure*}

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.4\linewidth}
        \includegraphics[width=0.9\linewidth]{figures/Imagenet_test_samples_without_water.pdf}
        \caption{Test samples in a task without watermark}
        \label{fig:split_imagenet_test_wo_water}
    \end{subfigure}
    % \hspace{1cm}
    \begin{subfigure}[t]{0.4\linewidth}
        \includegraphics[width=0.9\linewidth]{figures/Imagenet_test_samples_with_water.pdf}
        \caption{Test samples in a task with watermark}
        \label{fig:split_imagenet_test_w_water}
    \end{subfigure}
    \caption{\small \textbf{Test samples in Split ImageNet-100}. Both sides of samples are used to compute BMR.}
    \label{fig:split_imagenet_test_samples}
\end{figure*}

\noindent\textbf{CelebA}. Domain-IL typically assumes the input distributions vary as the number of tasks increases. To reflect this assumption in CL scenarios, we divided the CelebA dataset into several tasks based on some selected attributes and each task thereby has different facial features. For instance, the two tasks in CelebA$^2$ are defined by whether face images are ``smiling'' or not. Similarly, we utilize three attributes, ``Black Hair'', ``Oval Face'', and ``Mouth slightly open'' for CelebA$^8$. By dividing the data in this way, CL scenarios based on CelebA$^2$ or CelebA$^8$ mimic the distribution shift occurring in real-world applications.

\noindent\textbf{Split ImageNet-100}. To study the impact of the watermark bias in CL scenarios, we replace a randomly selected class with the ``Carton'' class in a certain task. To calculate BMR for the watermark bias, we make watermarked versions of each sample in the original test dataset by the style transfer used in \cite{li2022whac}. Examples of training and test samples of Split ImageNet-100 are illustrated in Fig \ref{fig:split_imagenet_train_samples} and \ref{fig:split_imagenet_test_samples}.

\section{Naive debiasing in CL scenarios}
\label{sec_append:naive_debiasing}
Here, we assume a scenario in which the bias of a model is detected after learning $T_1$ (stage 1) and $T_2$ (stage 2) continually. After that, the model is re-trained using existing debiasing techniques to obtain a debiased model (stage 3). For debiasing, we employ an existing debiasing technique, Group DRO, \cite{groupdro} which minimizes the worst-case group loss.
For this scenario, we set the bias level of $T_1$ and $T_2$ as 0 and 6 respectively. Figure
\ref{fig:naive_debiasing_gdro} show the accuracy and BMR of $T_2$ (left) and $T_1$ (right) at each stage for each baseline. We plotted the results of each baseline with hyperparameters achieving the highest average accuracy of the two tasks.
In the right plot, we observe that some points shift to the bottom left as progressing from stage 1 to stage 2, \ie, forgetting of $T_1$.
% It means that as the stability gets less focus, the bias obtained from T2 is more transferred to T1, i.e., the backward transfer of bias. 
From results of the stage 3 in the left plot, we show that BMR of $T_2$ can be reduced by Group DRO and MFD.
% with similar accuracy. 
However, we also identify that the accuracy of $T_1$ significantly drops. Thus, when debiasing after learning each task as we argued in Section \ref{sec:two_task_studies}, one should consider forgetting issue of the learned tasks at the same time, \ie, it is necessary to develop a novel debiasing method considering the stability for CL.
% As shown in \cref{fig:naive_debiasing}, 

\begin{figure}
    \centering
    \includegraphics[width=0.6\linewidth]{figures/two_task_cl_debiased_pareto_gdro.pdf}
    \caption{\small \textbf{Naive debiasing with Group DRO on Split CIFAR-100S.} The accuracy and BMR of $T_1$ and $T_2$ are shown for each stage.}
    \label{fig:naive_debiasing_gdro}
\end{figure}

% \begin{figure}
%     \centering
%     \includegraphics[width=0.6\linewidth]{figures/two_task_cl_debiased_pareto_mfd.pdf}
%     \caption{\small \textbf{Naive debiasing with MFD on Split CIFAR-100S.} The accuracy and BMR of $T_1$ and $T_2$ are shown for each stage.}
%     \label{fig:naive_debiasing_mfd}
% \end{figure}


\section{Additional experimental results}
\label{sec_append:additional_results}
% \subsection{Further analyses for CL with two-tasks}
\subsection{Forward and backward transfers of bias for CL with two tasks}
Figure \ref{fig:two_forward_more_levels} displays the forward transfer of the color bias for two task-CLs on Split CIFAR-100S. In each plot in the figure, the bias levels of $T_2$ are fixed to 2 or 4, respectively, and BMR of $T_1$ is reported for each CL method and hyperparameter. It is apparent from the figure that the difference in BMR between colored and uncolored points becomes more pronounced with the bias transfer, as compared to results obtained when the bias level of $T_2$ is fixed to 0. This would be because previously learned biases of a CL model tend to facilitate learning of the dataset bias of the current task more. 

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.4\linewidth}
        \includegraphics[width=0.9\linewidth]{figures/two_cifar_forward_level2.pdf}
        \caption{Bias level of $T_2$ : 2}
        \label{fig:two_forward_cifar_level2}
    \end{subfigure}
    \begin{subfigure}[t]{0.4\linewidth}
        \includegraphics[width=0.9\linewidth]{figures/two_cifar_forward_level4.pdf}
        \caption{Bias level of $T_2$ : 4}
        \label{fig:two_forward_cifar_level4}
    \end{subfigure}
    \caption{\small{\bf Forward transfer of bias in two tasks-continual learning on Split CIFAR-100S}. }
    \label{fig:two_forward_more_levels}
\end{figure*}


Similarly, in Figure \ref{fig:two_backward_more_levels}, we present the outcomes of two-task experiments for analysis of the backward transfer of bias. As in Figure \ref{fig:two_backward_more_levels}, the results show that if $T_1$ already contains a dataset bias, the effect of the backward transfer of the bias from $T_2$ is more pronounced. 

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.4\linewidth}
        \includegraphics[width=0.9\linewidth]{figures/two_cifar_backward_level2.pdf}
        \caption{Bias level of $T_1$ : 2}
        \label{fig:two_backward_cifar_level2}
    \end{subfigure}
    \begin{subfigure}[t]{0.4\linewidth}
        \includegraphics[width=0.9\linewidth]{figures/two_cifar_backward_level4.pdf}
        \caption{Bias level of $T_1$ : 4}
        \label{fig:two_backward_cifar_level4}
    \end{subfigure}
    \caption{\small{\bf Backward transfer of bias in two tasks-continual learning on Split CIFAR-100S}.}
    \label{fig:two_backward_more_levels}
\end{figure*}

\subsection{Feature representation analysis for backward transfer of bias}
We exhibit the results of CKA analysis for the backward transfer on Split CIFAR-100S. From Figure \ref{fig:cka_backward}, we observe a clear trend indicating the CKA value decreases as the regularization strength decreases and the bias level of $T_2$ increases. This again suggests that when a CL method focuses on learning a biased current task, \ie, plasticity, the backward transfer of bias by a CL method becomes more obvious. 
\begin{figure}
    \centering
    \includegraphics[width=0.4\linewidth]{figures/cka_backward.pdf}
    \caption{\small {\bf CKA on Split CIFAR-100S.} The CKA values between color images and grayscale images in $T_1$ are shown. Each value is calculated after learning $T_2$ by EWC.}
    \label{fig:cka_backward}
\end{figure}

\subsection{Experimental results for accuracy with a longer sequence of tasks}
Figure \ref{fig:long_cifar_acc} and \ref{fig:accumul_acc} show accuracies corresponding to each of the results in Figure 5 and 6 in the manuscript. The figures demonstrate that the accuracies in the same intervals are roughly the same, so we conclude that the gaps of BMR shown in Figure 5 and 6 are due to the bias transfers, not the accuracy gaps.
\begin{figure}
    \centering
    \begin{subfigure}{0.45\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{figures/long_cifar_forward_acc.pdf}    
        % \caption{Forward transfer of bias}
    \end{subfigure}
    \begin{subfigure}{0.45\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{figures/long_cifar_backward_acc.pdf}    
        % \caption{d}
    \end{subfigure}    
    \caption{\small {\bf Accuracy in longer sequences of Split CIFAR-100S.} The experimental settings in two plots are the same as in Figure 5(a) and 5(b), respectively.}
    \label{fig:long_cifar_acc}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.4\linewidth]{figures/accumul_forward_cifar_acc.pdf}
    \caption{\small{\bf Accuracy of $T_5$ depending on the number of biased tasks.} The experimental settings are the same as in Figure 6.}
    \label{fig:accumul_acc}
\end{figure}

\begin{table}[]
\centering
\caption{\small\textbf{Mis-classified ratio of $T_2$ test data when watermark is added either after learning ``carton'' in $T_1$ or not.} We reported the results with memory capacity which is 100\% of $T_1$ data to consider the stability.}
\resizebox{0.5\linewidth}{!}{
\begin{tabular}{ccc}
\toprule
\multirow{2}{*}{Prediction} & \multicolumn{2}{c}{Mis-classified ratio (\%)}              \\ 
                             & \multicolumn{1}{c}{$T_1$ with ``carton''} & $T_1$ without ``carton'' \\ \midrule
Old class                  & \multicolumn{1}{c}{4.52}             & 7.78                \\ 
New class                  & \multicolumn{1}{c}{7.74}             & 6                \\ 
``Carton'' class (old)            & \multicolumn{1}{c}{4.02}             & -                   \\ \midrule 
Total (BMR)             &      16.28   &    13.78           \\ \bottomrule
\end{tabular}
}
\label{tab:forward_image_mis}
\end{table}

\begin{table}[]
\centering
\caption{\small \textbf{Mis-classified ratio of $T_1$ test data when watermark is added either after learning ``carton'' in $T_2$ or not.} We reported the results with memory capacity which is 10\% of $T_1$ data to consider the plasticity.}
\resizebox{0.5\linewidth}{!}{
\begin{tabular}{ccc}
\toprule
\multirow{2}{*}{Prediction} & \multicolumn{2}{c}{Mis-classified ratio (\%)}              \\ 
                             & \multicolumn{1}{c}{$T_2$ with ``carton''} & $T_2$ without ``carton'' \\ \midrule
Old class                  & \multicolumn{1}{c}{2.06}             & 1.38              \\ 
New class                  & \multicolumn{1}{c}{21.61}            & 28.06               \\ 
``Carton'' class (new)            & \multicolumn{1}{c}{5.69}            & -                   \\ \midrule 
Total (BMR)             &    29.36     &  29.44            \\ \bottomrule
\end{tabular}
}
\label{tab:backward_image_mis}
\end{table}

\section{Discussions about results for backward transfer on Split ImageNet-100}
\label{sec_append:discussion}
In this section, we analyze the predictions of a models in order to investigate why the backward transfer is not observed in Class-IL scenarios with two-tasks on Split ImageNet-100. 
% to investigate the effect of the old-new bias of Class-IL on the backward transfer of bias. 
Table \ref{tab:forward_image_mis} (resp. Table \ref{tab:backward_image_mis}) represents the CL scenarios for the forward (resp. backward) transfer of bias,  which evaluates the bias for $T_2$ (resp. $T_1$) by varying the bias level of $T_1$ (resp. $T_2$), \ie, whether the ``carton'' class is contained in the task or not. We employ ER in our experiments and set the memory size as 1 in Table \ref{tab:forward_image_mis} or 0.1 in Table \ref{tab:backward_image_mis}, to make forward and backward transfer of bias significantly occurs by focusing more on stability or stability, respectively. 
% to store 100\% of $T_1$ data for Table \ref{tab:forward_image_mis} and 10\% of $T_1$ data for Table \ref{tab:backward_image_mis} to consider the model highly focusing on the stability and the plasticity respectively. 
% In the tables, we report BMR for each scenario and 
To analyze BMR values in more detail, we divided the cases of misclassification  of bias-conflicted samples into three categories; a CL model falsely predicts for 1) one of the old classes (except the carton), 2) one of the new classes (except the carton), and 3) the ``carton'' class. 

The following are our observations from the tables.
First, we observe that BMRs of $T_1$ in Table \ref{tab:backward_image_mis} show almost no difference regardless of whether a CL model learns the ``carton'' class under high plasticity, while BMR of $T_2$ increases in Table \ref{tab:forward_image_mis} when $T_1$ contains the ``carton'' class. Namely, in terms of BMR, it looks like the backward transfer of the watermark bias does not occur. However, when we look at the categorized results, we can derive different trends, \ie, the backward transfer still occurs. In Table \ref{tab:backward_image_mis}, when $T_2$ contains the ``carton'' class, some samples with the watermark are misclassified into the ``carton'' class, \ie, the CL model possesses watermark bias in $T_1$ due to backward transfer. We then argue that the main cause of similar BMRs in Table \ref{tab:backward_image_mis} would be the \textit{old-new bias}, an inherent issue of Class-IL, which indicates biased predictions towards new classes. Indeed, when the watermark is injected into samples in $T_1$ which belongs to old classes, we see a disproportionately high ratio of incorrectly predicted samples for the new classes in Table \ref{tab:backward_image_mis}. On the other hand, we observe that the ratios for old and new classes are relatively similar in Table \ref{tab:forward_image_mis}, since the watermark bias is injected to samples in $T_2$ which belongs to new classes. Thus, we can infer that the old-new bias can make the model predictions for samples in $T_1$ vulnerable to watermark bias and easily shift to new classes in $T_2$, even if the model did not explicitly learn the ``carton'' class. This explains high misclassified ratios for new class regardless of the dataset bias of $T_2$ and similar BMRs in Table \ref{tab:backward_image_mis} although the backward transfer of bias occurs. 
% In addition, we calculated the CKAs from the two models in \cref{tab:backward_image_mis} and find out that a model learning $T_2$ with the ``carton'' class has lower CKA by 0.12, which can be used in another evidence for the backward transfer.


% In Table \ref{tab:forward_image_mis} and \ref{tab:backward_image_mis}, we computed mis-classified ratio of correctly predicted samples when the watermark is added. 
% To investigate how the mis-classifications are made, we divide them into three cases according to the predictions.
% In Table \ref{tab:forward_image_mis}, we report the results when the memory stored the whole $T_1$ training data, \ie, high stability, when learning ``carton'' class in $T_1$ or not. We clearly observe that adding watermark leads more images of $T_2$ to be mis-classified as ``carton'' after learning ``carton'' in $T_1$, \ie, the forward transfer of bias, while the total ratios of old and new classes are similar.
% In Table \ref{tab:backward_image_mis}, we report the results when the memory stored 10\% of $T_1$ training data, \ie, high plasticity, when learning ``carton'' class in $T_2$ or not. In this case, we again observe that some images of $T_1$ are mis-classified as ``carton'' after learning ``carton'' in $T_2$. However, even when not learning ``carton'', the model predicted the old task samples to another new class and this made BMR of two different models be almost the same. We believe this is because the model is vulnerable to a random perturbation of an image and tends to predict the samples to the recently learned classes when the old task samples was not considered enough while learning a new task, \ie, old-new bias of Class-IL.
% A model in Class-IL tends to suffer from a phenomenon which is to predict samples from old classes to the one of the recently learned classes when the old samples are not considered enough while learning a new task. 

% To interpret the phenomenon, we counted predictions of the model for the test data of two tasks $T_1$ and $T_2$ after learning $T_2$ in Table \ref{tab:backward_image_oldnew}. As shown in the table, the model predicted most of samples from old classes to the new classes in both cases when learning ``carton'' and not. Furthermore, when the watermark is added, more old samples are predicted to the new classes, which shows the vulnerability of a model to the perturbation. Similar trend is observed in Table \ref{tab:forward_image_oldnew} when the memory capacity is large. In the meantime, the table also shows that few samples are predicted to old classes when the watermark is added, and it increased slightly more in the case when learning ``carton'' in $T_1$ which represents, due to the old-new bias, robust predictions could be made to the new task samples more easily.
% more new class samples are predicted to old classes when learning 'carton' in $T_1$ than when not learning 'carton' which represents 
% Table \ref{tab:forward_image_oldnew} and \ref{tab:backward_image_oldnew} show predictions of models for the test data of two tasks $T_1$ and $T_2$ after learning $T_2$ with 100\%  and 10\% of $T_1$ training data, respectively. Settings of those two tables are correspond to table \ref{tab:forward_image_mis} and \ref{tab:backward_image_mis} respectively.

% , we investigated the predictions of models for the test data of $T_1$ and $T_2$ after learning $T_2$ when we stored 100\% and 10\% of $T_1$ training data respectively. 
% In those tables, we observe that the model predicted original samples from old classes to new classes more when the less memory capacity is used. 
% Moreover, adding watermark on the test samples, let the model 




% Please add the following required packages to your document preamble:
% \usepackage{multirow}


% Please add the following required packages to your document preamble:
% \usepackage{multirow}


% Please add the following required packages to your document preamble:
% \usepackage{multirow}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}



% \begin{table}[t]
% \centering
% \caption{\small \textbf{Model predictions in the scenario to study the forward transfer of bias.} We reported the results with memory capacity which is the same as the number of $T_1$ data to consider the stability.}
% \resizebox{0.7\linewidth}{!}{
% \begin{tabular}{cccccc}
% \toprule
% \multirow{2}{*}{Label}      & \multirow{2}{*}{Prediction} & \multicolumn{2}{c}{$T_1$ with ``carton''}           & \multicolumn{2}{c}{$T_1$ without ``carton''}        \\ 
%                              &                              & \multicolumn{1}{c}{Original} & Watermark-added & \multicolumn{1}{c}{Original} & Watermark-added \\ \midrule
% \multirow{2}{*}{Old class} & Old class                  & \multicolumn{1}{c}{443}      & 410             & \multicolumn{1}{c}{446}      & 410             \\ 
%                              & New class                  & \multicolumn{1}{c}{57}       & 90              & \multicolumn{1}{c}{54}       & 90              \\ \midrule
% \multirow{2}{*}{New class} & Old class                  & \multicolumn{1}{c}{56}       & 79              & \multicolumn{1}{c}{56}       & 75              \\ 
%                              & New class                  & \multicolumn{1}{c}{444}      & 421             & \multicolumn{1}{c}{444}      & 425           \\ \bottomrule
% \end{tabular}
% }
% \label{tab:forward_image_oldnew}
% \end{table}
% \begin{table}[]
% \centering
% \caption{\small \textbf{Model predictions in the scenario to study the backward transfer of bias.} We reported the results with memory capacity which is 10\% of $T_1$ data to less consider the stability.}
% \resizebox{0.7\linewidth}{!}{
% \begin{tabular}{cccccc}
% \toprule
% \multirow{2}{*}{Label}      & \multirow{2}{*}{Prediction} & \multicolumn{2}{c}{$T_2$ with ``carton''}           & \multicolumn{2}{c}{$T_2$ without ``carton''}        \\ 
%                              &                              & \multicolumn{1}{c}{Original} & Watermark-added & \multicolumn{1}{c}{Original} & Watermark-added \\ \midrule
% \multirow{2}{*}{Old class} & Old class                  & \multicolumn{1}{c}{294}      & 208             & \multicolumn{1}{c}{280}      & 196             \\  
%                              & New class                  & \multicolumn{1}{c}{206}      & 292             & \multicolumn{1}{c}{220}      & 304             \\ \midrule
% \multirow{2}{*}{New class} & Old class                  & \multicolumn{1}{c}{6}        & 5               & \multicolumn{1}{c}{7}        & 8               \\
%                              & New class                  & \multicolumn{1}{c}{494}      & 495             & \multicolumn{1}{c}{493}      & 492             \\ \bottomrule
% \end{tabular}
% }
% \label{tab:backward_image_oldnew}
% \end{table}
