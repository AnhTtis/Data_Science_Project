\section{Related works}
\label{sec:relwork}

\noindent\textbf{Continual learning (CL)}.
Assuming that tasks are clearly separated, CL scenarios are typically categorized into three categories: task-incremental learning (Task-IL), domain-incremental learning (Domain-IL), and class-incremental learning (Class-IL) \cite{van2019three}. The Task-IL and Class-IL assume each task has a disjoint set of labels and the task identity is provided during training. The main difference between the two is whether the task identity is used (Task-IL) at test time or not (Class-IL). Task-IL adopts the structure of a multi-headed network with a classification head for each task since it uses the task identity at the test time. In contrast, Class-IL uses a single-headed network due to the lack of task identity at the test time. In Domain-IL, the class set of the tasks always remains the same, but only the input distributions vary as the number of tasks increases.  
% Our analysis includes all types of scenarios by using one of the three datasets for each scenario.

Recent CL methods can also be classified into three categories based on how they prevent forgetting of the previously learned tasks \cite{de2021continual}: rehearsal based, regularization based, and parameter isolation based methods. Regularization based methods add regularization terms for penalizing deviation from past models and balance the stability-plasticity trade-off by controlling the regularization hyperparameter \cite{ewc, li2017learning, agscl, titsias2020functional}. Rehearsal based methods store some data points from past tasks in a small exemplar memory and replay them while learning the current task \cite{er, gem, agem, tiwari2022gcr}. Parameter isolation based methods \cite{rusu2016progressive, mallya2018packnet, mallya2018piggyback, hung2019compacting, ye2021lifelong} allocate model parameters separately for each task by masking out previous task parameters and updating only remained parameters for learning a new task. Note that parameter isolation based methods can be applied to only Task-IL settings since they require task identity during inference to separate parameters for each task.
% We analyzed some representative methods from each category.

While many state-of-the-art CL methods in each category have been actively developed, many of them were limited for direct application to real-world deployment scenarios. 
% most of them are far from being practical for real-world deployment scenarios. 
For instance, most existing CL methods focus on learning well-balanced tasks with reliable labels. To that end, some considered more practical settings; \textit{e.g., } CL scenarios with imbalanced data \cite{kim2020imbalanced}, noisy labels \cite{kim2021continual, bang2022online}, and dataset bias \cite{lesort2022continual}. While \cite{lesort2022continual} shares a somewhat similar motivation as ours, their overall experimental setup was not sufficiently fine-grained to fully support their own findings. 


% For better practicality, some researchers have studied more practical scenarios with imbalanced data \cite{kim2020imbalanced} or noisy labels \cite{kim2021continual, bang2022online}. Similar to our work, Lesort \cite{lesort2022continual} investigated how dataset bias of each task affect CL scenarios. While they study the relationship between spurious correlations and continual learning, their overall experiment setup may not be sufficiently fine-grained to fully support their own findings. 
% In contrast, we conducted more systematic experiments to show how standard CL methods propagate bias of tasks to previous or new tasks. 

\noindent\textbf{Spurious correlations and debiased learning}.  
% The machine learning community has attempted to comprehending the issue of how models can rely on spurious correlations, and as a result, a variety of studies have emerged under different names, including dataset bias, learning under covariate shift, shortcut learning, and anti-causal learning.
% Numerous works in the machine learning communities has been attempting to develop a formal understanding of model bias under different names, such as shortcut learning \cite{geirhos2020shortcut}, learning under covariate shift \cite{bickel2009discriminative}, dataset bias \cite{torralba2011unbiased, wang2019balanced} and anti-causal learning \cite{liu2022contextual}. 
 Machine learning community has attempted to comprehend issues of spurious correlations, and as a result, there have been a variety of studies that aim to identify and mitigate various forms of real-world spurious correlations. For instance, in vision tasks, neural networks may rely on background \cite{groupdro, geirhos2020shortcut}, texture \cite{geirhos2018}, or semantically irrelevant features of objects \cite{liu2022contextual} in the image. In addition, numerous approaches to address these issues have been proposed. 
Early approaches utilize known group labels that indicate the misleadingly correlated attributes, such as background or gender \cite{groupdro, mfd}. As an example, Sagawa et al. \cite{groupdro} developed Group DRO which minimizes the worst-case group loss in the training data by using some prior knowledge of spurious correlations. Since annotating group labels is costly, more recent works have developed more practical methods that need only bias type \cite{bahng2020learning}, partially annotated group labels \cite{liu2021just, jung2022learning}, or no group labels  \cite{learningfromfailure}. Nonetheless, they have not been considered spurious correlations in continual learning.
