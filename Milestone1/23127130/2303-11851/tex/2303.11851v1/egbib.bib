
@INPROCEEDINGS{Chebrolu2019robotlocal,
  author={Chebrolu, Nived and Lottes, Philipp and Läbe, Thomas and Stachniss, Cyrill},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)}, 
  title={Robot Localization Based on Aerial Images for Precision Agriculture Tasks in Crop Fields}, 
  year={2019},
  volume={},
  number={},
  pages={1787-1793},
  doi={10.1109/ICRA.2019.8794030}}

@article{Merkle2017Sardata, title={Exploiting Deep Matching and SAR Data for the Geo-Localization Accuracy Improvement of Optical Satellite Images}, volume={9}, ISSN={2072-4292}, url={http://dx.doi.org/10.3390/rs9060586}, DOI={10.3390/rs9060586}, number={6}, journal={Remote Sensing}, publisher={MDPI AG}, author={Merkle, Nina and Luo, Wenjie and Auer, Stefan and Müller, Rupert and Urtasun, Raquel}, year={2017}, month={Jun}, pages={586} }


@INPROCEEDINGS{Agarwal2009Rome,
  author={Agarwal, Sameer and Snavely, Noah and Simon, Ian and Seitz, Steven M. and Szeliski, Richard},
  booktitle={2009 IEEE 12th International Conference on Computer Vision}, 
  title={Building Rome in a day}, 
  year={2009},
  volume={},
  number={},
  pages={72-79},
  doi={10.1109/ICCV.2009.5459148}}

@article{Guidi2017Milan, title={Accurate Reconstruction of the Roman Circus in Milan by Georeferencing Heterogeneous Data Sources with GIS}, volume={7}, ISSN={2076-3263}, url={http://dx.doi.org/10.3390/geosciences7030091}, DOI={10.3390/geosciences7030091}, number={3}, journal={Geosciences}, publisher={MDPI AG}, author={Guidi, Gabriele and Gonizzi Barsanti, Sara and Micoli, Laura and Malik, Umair}, year={2017}, month={Sep}, pages={91} }

@article{Kounavis2012artourism,
author = {Chris D. Kounavis and Anna E. Kasimati and Efpraxia D. Zamani},
title ={Enhancing the Tourism Experience through Mobile Augmented Reality: Challenges and Prospects},
journal = {International Journal of Engineering Business Management},
volume = {4},
number = {},
pages = {10},
year = {2012},
doi = {10.5772/51644},
URL = { 
        https://doi.org/10.5772/51644 
},
eprint = { 
        https://doi.org/10.5772/51644 
}
,
    abstract = { This paper discusses the use of Augmented Reality (AR) applications for the needs of tourism. It describes the technology's evolution from pilot applications into commercial mobile applications. We address the technical aspects of mobile AR application development, emphasizing the technologies that render the delivery of augmented reality content possible and experientially superior. We examine the state of the art, providing an analysis concerning the development and the objectives of each application. Acknowledging the various technological limitations hindering AR's substantial end-user adoption, the paper proposes a model for developing AR mobile applications for the field of tourism, aiming to release AR's full potential within the field. }
}


@INPROCEEDINGS{cozman1995sextant,
  author={Cozman, F. and Krotkov, E.},
  booktitle={Proceedings of 1995 IEEE International Conference on Robotics and Automation}, 
  title={Robot localization using a computer vision sextant}, 
  year={1995},
  volume={1},
  number={},
  pages={106-111 vol.1},
  doi={10.1109/ROBOT.1995.525271}}

@article{lalonde2010sky,
author = {Lalonde, Jean-François and Narasimhan, Srinivasa and Efros, Alexei},
year = {2010},
month = {05},
pages = {24-51},
title = {What Do the Sun and the Sky Tell Us About the Camera?},
volume = {88},
journal = {International Journal of Computer Vision},
doi = {10.1007/s11263-009-0291-4}
}

@article{Imran2010gps,
title = {GPS coordinates estimation and camera calibration from solar shadows},
journal = {Computer Vision and Image Understanding},
volume = {114},
number = {9},
pages = {991-1003},
year = {2010},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2010.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S1077314210001347},
author = {Imran N. Junejo and Hassan Foroosh},
keywords = {Camera calibration, Camera geo-location, Computer vision},
abstract = {In this paper, we discuss the issue of camera parameter estimation (intrinsic and extrinsic parameters), along with estimation of the geo-location of the camera by using only the shadow trajectories. By observing stationary objects over a period of time, it is shown that only six points on the trajectories formed by tracking the shadows of the objects are sufficient to estimate the horizon line of the ground plane. This line is used along with the extracted vertical vanishing point to calibrate the stationary camera. The method requires as few as two shadow casting objects in the scene and a set of six or more points on the shadow trajectories of these objects. Once camera intrinsic parameters are recovered, we present a novel application where one can accurately determine the geo-location of the camera up to a longitude ambiguity using only three points from these shadow trajectories without using any GPS or other special instruments. We consider possible cases where this ambiguity can also be removed if additional information is available. Our method does not require any knowledge of the date or the time when the images are taken, and recovers the date of acquisition directly from the images. We demonstrate the accuracy of our technique for both steps of calibration and geo-temporal localization using synthetic and real data.}
}


@INPROCEEDINGS{Jacobs2008,
  author={Jacobs, Nathan and Roman, Nathaniel and Pless, Robert},
  booktitle={2008 IEEE Workshop on Applications of Computer Vision}, 
  title={Toward Fully Automatic Geo-Location and Geo-Orientation of Static Outdoor Cameras}, 
  year={2008},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/WACV.2008.4544040}}

@INPROCEEDINGS{Jacobs2011,

  author={Jacobs, Nathan and Miskell, Kylia and Pless, Robert},
  booktitle={2011 IEEE Workshop on Applications of Computer Vision (WACV)}, 
  title={Webcam geo-localization using aggregate light levels}, 
  year={2011},
  volume={},
  number={},
  pages={132-138},
  doi={10.1109/WACV.2011.5711494}}


@inproceedings{arandjelovic2016netvlad,
  title={NetVLAD: CNN architecture for weakly supervised place recognition},
  author={Arandjelovic, Relja and Gronat, Petr and Torii, Akihiko and Pajdla, Tomas and Sivic, Josef},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5297--5307},
  year={2016}
}

@INPROCEEDINGS{Lin2015,
  author={Lin, Tsung-Yi and Yin Cui and Belongie, Serge and Hays, James},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Learning deep representations for ground-to-aerial geolocalization}, 
  year={2015},
  volume={},
  number={},
  pages={5007-5015},
  doi={10.1109/CVPR.2015.7299135}}

@inproceedings{liu2019lending,
  title={Lending orientation to neural networks for cross-view geo-localization},
  author={Liu, Liu and Li, Hongdong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5624--5633},
  year={2019}
}


@InProceedings{Workman_2015_CVPR_Workshops,
author = {Workman, Scott and Jacobs, Nathan},
title = {On the Location Dependence of Convolutional Neural Network Features},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2015}
} 

@INPROCEEDINGS{workmann2015cvusa,
  author={Workman, Scott and Souvenir, Richard and Jacobs, Nathan},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Wide-Area Image Geolocalization with Aerial Reference Imagery}, 
  year={2015},
  volume={},
  number={},
  pages={3961-3969},
  doi={10.1109/ICCV.2015.451}}

  @inproceedings{zheng2020university,
  title={University-1652: A multi-view multi-source benchmark for drone-based geo-localization},
  author={Zheng, Zhedong and Wei, Yunchao and Yang, Yi},
  booktitle={Proceedings of the 28th ACM international conference on Multimedia},
  pages={1395--1403},
  year={2020}
}

@inproceedings{weyand2020google,
  title={Google landmarks dataset v2-a large-scale benchmark for instance-level recognition and retrieval},
  author={Weyand, Tobias and Araujo, Andre and Cao, Bingyi and Sim, Jack},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2575--2584},
  year={2020}
}

@inproceedings{brosh2019accurate,
  title={Accurate visual localization for automotive applications},
  author={Brosh, Eli and Friedmann, Matan and Kadar, Ilan and Yitzhak Lavy, Lev and Levi, Elad and Rippa, Shmuel and Lempert, Yair and Fernandez-Ruiz, Bruno and Herzig, Roei and Darrell, Trevor},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={0--0},
  year={2019}
}

@inproceedings{zhu2021vigor,
  title={Vigor: Cross-view image geo-localization beyond one-to-one retrieval},
  author={Zhu, Sijie and Yang, Taojiannan and Chen, Chen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3640--3649},
  year={2021}
}

@INPROCEEDINGS{hu2018cvm,
  author={Hu, Sixing and Feng, Mengdan and Nguyen, Rang M. H. and Lee, Gim Hee},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={CVM-Net: Cross-View Matching Network for Image-Based Ground-to-Aerial Geo-Localization}, 
  year={2018},
  volume={},
  number={},
  pages={7258-7267},
  doi={10.1109/CVPR.2018.00758}}

@inbook{shi2019safa,
author = {Shi, Yujiao and Liu, Liu and Yu, Xin and Li, Hongdong},
title = {Spatial-Aware Feature Aggregation for Cross-View Image Based Geo-Localization},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Recent works show that it is possible to train a deep network to determine the geographic location of a ground-level image (e.g., a Google street-view panorama) by matching it against a satellite map covering the wide geographic area of interest. Conventional deep networks, which often cast the problem as a metric embedding task, however, suffer from poor performance in terms of low recall rates. One of the key reasons is the vast differences between the two view modalities, i.e., ground view versus aerial/satellite view. They not only exhibit very different visual appearances, but also have distinctive geometric geometric configurations. Existing deep methods overlook those appearance and geometric differences, and instead use a bruteforce training procedure, leading to inferior performance. In this paper, we develop a new deep network to explicitly address these inherent differences between ground and aerial views. We observe that pixels lying on the same azimuth direction in an aerial image approximately correspond to a vertical image column in the ground view image. Thus, we propose a two-step approach to exploit this prior. The first step is to apply a regular polar transform to warp an aerial image such that its domain is closer to that of a ground-view panorama. Note that polar transform as a pure geometric transformation is agnostic to scene content, hence cannot bring the two domains into full alignment. Then, we add a subsequent spatial-attention mechanism which brings corresponding deep features closer in the embedding space. To improve the robustness of feature representation, we introduce a feature aggregation strategy via learning multiple spatial embeddings. By the above two-step approach, we achieve more discriminative deep representations, facilitating cross-view Geo-localization more accurate. Our experiments on standard benchmark datasets show significant performance boosting, achieving more than doubled recall rate compared with the previous state of the art. Remarkably, the recall rate@top-1 improves from 22.5\% in [4] (or 40.7\% in [10]) to 89.8\% on CVUSA benchmark, and from 20.1\% [4] to 81.0\% on the new CVACT dataset.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {905},
numpages = {11}
}

@INPROCEEDINGS{cai2019SiamFCANet,
  author={Cai, Sudong and Guo, Yulan and Khan, Salman and Hu, Jiwei and Wen, Gongjian},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Ground-to-Aerial Image Geo-Localization With a Hard Exemplar Reweighting Triplet Loss}, 
  year={2019},
  volume={},
  number={},
  pages={8390-8399},
  doi={10.1109/ICCV.2019.00848}}

@inproceedings{shi2020optimal,
  title={Optimal feature transport for cross-view image geo-localization},
  author={Shi, Yujiao and Yu, Xin and Liu, Liu and Zhang, Tong and Li, Hongdong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={07},
  pages={11990--11997},
  year={2020}
}

@article{Wang2022LearningCG,
  title={Learning Cross-view Geo-localization Embeddings via Dynamic Weighted Decorrelation Regularization},
  author={Ting Wang and Zhedong Zheng and Zunjie Zhu and Yu-Fei Gao and Yi Yang and Chenggang Yan},
  journal={ArXiv},
  year={2022},
  volume={abs/2211.05296}
}

@article{wang2021each,
  title={Each part matters: Local patterns facilitate cross-view geo-localization},
  author={Wang, Tingyu and Zheng, Zhedong and Yan, Chenggang and Zhang, Jiyong and Sun, Yaoqi and Zheng, Bolun and Yang, Yi},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={32},
  number={2},
  pages={867--879},
  year={2021},
  publisher={IEEE}
}

@inproceedings{shi2020looking,
  title={Where am i looking at? joint location and orientation estimation by cross-view matching},
  author={Shi, Yujiao and Yu, Xin and Campbell, Dylan and Li, Hongdong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4064--4072},
  year={2020}
}

@inproceedings{yang2021l2ltr,
 author = {Yang, Hongji and Lu, Xiufan and Zhu, Yingying},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {29009--29020},
 publisher = {Curran Associates, Inc.},
 title = {Cross-view Geo-localization with Layer-to-Layer Transformer},
 url = {https://proceedings.neurips.cc/paper/2021/file/f31b20466ae89669f9741e047487eb37-Paper.pdf},
 volume = {34},
 year = {2021}
}

@article{zhao2022mutual,
  title={Mutual Generative Transformer Learning for Cross-view Geo-localization},
  author={Zhao, Jianwei and Zhai, Qiang and Huang, Rui and Cheng, Hong},
  journal={arXiv preprint arXiv:2203.09135},
  year={2022}
}

@inproceedings{zhu2022transgeo,
  title={Transgeo: Transformer is all you need for cross-view image geo-localization},
  author={Zhu, Sijie and Shah, Mubarak and Chen, Chen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1162--1171},
  year={2022}
}

@INPROCEEDINGS{chopra2005simiaritymetric,
  author={Chopra, S. and Hadsell, R. and LeCun, Y.},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)}, 
  title={Learning a similarity metric discriminatively, with application to face verification}, 
  year={2005},
  volume={1},
  number={},
  pages={539-546 vol. 1},
  doi={10.1109/CVPR.2005.202}}

@INPROCEEDINGS{taigman2014deepface,
  author={Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={DeepFace: Closing the Gap to Human-Level Performance in Face Verification}, 
  year={2014},
  volume={},
  number={},
  pages={1701-1708},
  doi={10.1109/CVPR.2014.220}}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9729--9738},
  year={2020}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@inproceedings{zhai2017predicting,
  title={Predicting ground-level scene layout from aerial imagery},
  author={Zhai, Menghua and Bessinger, Zachary and Workman, Scott and Jacobs, Nathan},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={867--875},
  year={2017}
}

@inproceedings{vo2016localizing,
  title={Localizing and orienting street views using overhead imagery},
  author={Vo, Nam N and Hays, James},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part I 14},
  pages={494--509},
  year={2016},
  organization={Springer}
}

@InProceedings{Hu_2018_CVPR,
author = {Hu, Sixing and Feng, Mengdan and Nguyen, Rang M. H. and Lee, Gim Hee},
title = {CVM-Net: Cross-View Matching Network for Image-Based Ground-to-Aerial Geo-Localization},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
} 

@inproceedings{hu2022beyondgeolocal,
author = {Hu, Wenmiao and Zhang, Yichen and Liang, Yuxuan and Yin, Yifang and Georgescu, Andrei and Tran, An and Kruppa, Hannes and Ng, See-Kiong and Zimmermann, Roger},
title = {Beyond Geo-Localization: Fine-Grained Orientation of Street-View Images by Cross-View Matching with Satellite Imagery},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3548102},
doi = {10.1145/3503161.3548102},
abstract = {Street-view imagery provides us with novel experiences to explore different places remotely. Carefully calibrated street-view images (e.g., Google Street View) can be used for different downstream tasks, e.g., navigation, map features extraction. As personal high-quality cameras have become much more affordable and portable, an enormous amount of crowdsourced street-view images are uploaded to the internet, but commonly with missing or noisy sensor information. To prepare this hidden treasure for "ready-to-use" status, determining missing location information and camera orientation angles are two equally important tasks. Recent methods have achieved high performance on geo-localization of street-view images by cross-view matching with a pool of geo-referenced satellite imagery. However, most of the existing works focus more on geo-localization than estimating the image orientation. In this work, we re-state the importance of finding fine-grained orientation for street-view images, formally define the problem and provide a set of evaluation metrics to assess the quality of the orientation estimation. We propose two methods to improve the granularity of the orientation estimation, achieving 82.4\% and 72.3\% accuracy for images with estimated angle errors below 2 degrees for CVUSA and CVACT datasets, corresponding to 34.9\% and 28.2\% absolute improvement compared to previous works. Integrating fine-grained orientation estimation in training also improves the performance on geo-localization, giving top 1 recall 95.5\%/85.5\% and 86.8\%/80.4\% for orientation known/unknown tests on the two datasets.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {6155–6164},
numpages = {10},
keywords = {satellite imagery, geo-localization, street-view imagery, cross-view matching, camera orientation estimation},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inproceedings{woo2018cbam,
  title={Cbam: Convolutional block attention module},
  author={Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}

@article{goodfellow2020generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@inproceedings{toker2021coming,
  title={Coming down to earth: Satellite-to-street view synthesis for geo-localization},
  author={Toker, Aysim and Zhou, Qunjie and Maximov, Maxim and Leal-Taix{\'e}, Laura},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6488--6497},
  year={2021}
}

@ARTICLE{lu2022iterative,
  author={Lu, Xiufan and Luo, Siqi and Zhu, Yingying},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={It’s Okay to Be Wrong: Cross-View Geo-Localization With Step-Adaptive Iterative Refinement}, 
  year={2022},
  volume={60},
  number={},
  pages={1-13},
  doi={10.1109/TGRS.2022.3210195}}

  @inproceedings{kwon2021asam,
  title={Asam: Adaptive sharpness-aware minimization for scale-invariant learning of deep neural networks},
  author={Kwon, Jungmin and Kim, Jeongseop and Park, Hyunseo and Choi, In Kwon},
  booktitle={International Conference on Machine Learning},
  pages={5905--5914},
  year={2021},
  organization={PMLR}
}

@article{zhang2022cross,
  title={Cross-view Geo-localization via Learning Disentangled Geometric Layout Correspondence},
  author={Zhang, Xiaohan and Li, Xingyu and Sultani, Waqas and Zhou, Yi and Wshah, Safwan},
  journal={arXiv preprint arXiv:2212.04074},
  year={2022}
}

@article{tolstikhin2021mlp,
  title={Mlp-mixer: An all-mlp architecture for vision},
  author={Tolstikhin, Ilya O and Houlsby, Neil and Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Unterthiner, Thomas and Yung, Jessica and Steiner, Andreas and Keysers, Daniel and Uszkoreit, Jakob and others},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={24261--24272},
  year={2021}
}

@article{zhu2023simple,
  title={Simple, Effective and General: A New Backbone for Cross-view Image Geo-localization},
  author={Zhu, Yingying and Yang, Hongji and Lu, Yuxin and Huang, Qiang},
  journal={arXiv preprint arXiv:2302.01572},
  year={2023}
}

@article{foret2020sharpness,
  title={Sharpness-aware minimization for efficiently improving generalization},
  author={Foret, Pierre and Kleiner, Ariel and Mobahi, Hossein and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:2010.01412},
  year={2020}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{schroff2015facenet,
  title={Facenet: A unified embedding for face recognition and clustering},
  author={Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={815--823},
  year={2015}
}

@inproceedings{habel2022clipreid,
author = {Habel, Konrad and Deuser, Fabian and Oswald, Norbert},
title = {CLIP-ReIdent: Contrastive Training for Player Re-Identification},
year = {2022},
isbn = {9781450394888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3552437.3555698},
doi = {10.1145/3552437.3555698},
abstract = {Sports analytics benefits from recent advances in machine learning providing a competitive advantage for teams or individuals. One important task in this context is the performance measurement of individual players to provide reports and log files for subsequent analysis. During sport events like basketball, this involves the re-identification of players during a match either from multiple camera viewpoints or from a single camera viewpoint at different times. In this work, we investigate whether it is possible to transfer the out-standing zero-shot performance of pre-trained CLIP models to the domain of player re-identification. For this purpose we reformulate the contrastive language-to-image pre-training approach from CLIP to a contrastive image-to-image training approach using the InfoNCE loss as training objective. Unlike previous work, our approach is entirely class-agnostic and benefits from large-scale pre-training. With a fine-tuned CLIP ViT-L/14 model we achieve 98.44\% mAP on the MMSports 2022 Player Re-Identification challenge. Furthermore we show that the CLIP Vision Transformers have already strong OCR capabilities to identify useful player features like shirt numbers in a zero-shot manner without any fine-tuning on the dataset. By applying the Score-CAM algorithm we visualise the most important image regions that our fine-tuned model identifies when calculating the similarity score between two images of a player.},
booktitle = {Proceedings of the 5th International ACM Workshop on Multimedia Content Analysis in Sports},
pages = {129–135},
numpages = {7},
keywords = {deep learning, computer vision, basketball, transfer learning, person re-identification},
location = {Lisboa, Portugal},
series = {MMSports '22}
}

@inproceedings{liu2022convnet,
  title={A convnet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11976--11986},
  year={2022}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{wu2017sampling,
  title={Sampling matters in deep embedding learning},
  author={Wu, Chao-Yuan and Manmatha, R and Smola, Alexander J and Krahenbuhl, Philipp},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2840--2848},
  year={2017}
}

@article{zhu2023uavworth, title={UAV’s Status Is Worth Considering: A Fusion Representations Matching Method for Geo-Localization}, volume={23}, ISSN={1424-8220}, url={http://dx.doi.org/10.3390/s23020720}, DOI={10.3390/s23020720}, number={2}, journal={Sensors}, publisher={MDPI AG}, author={Zhu, Runzhe and Yang, Mingze and Yin, Ling and Wu, Fei and Yang, Yuncheng}, year={2023}, month={Jan}, pages={720} }

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}
