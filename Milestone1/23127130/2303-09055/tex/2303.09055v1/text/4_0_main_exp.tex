\section{Experimental Results}
In this section, we show that our proposed method, TemporalMaxer, demonstrates the outstanding results achieved across a variety of challenging datasets, namely THUMOS \cite{idrees2017thumos}, EPIC-Kitchens 100 \cite{damen2020rescaling}, MultiTHUMOS \cite{yeung2018every}, and MUSES \cite{liu2021multi}. These datasets are recognized as standard benchmarks in the Temporal Action Localization task. Our approach surpasses the state-of-the-art baseline, ActionFormer \cite{zhang2022actionformer}, in each dataset, showcasing its superior performance compared to other works.

\textbf{Evaluation Metric}. We employ a widely-used evaluation metric for TAL known as the mean average precision (mAP) calculated at various temporal intersections over union (tIoU). tIoU is the intersection over union between two temporal windows, i.e., the 1D Jaccard index. We report the mAP scores for all action categories based on the given tIoU thresholds, and further report an averaged mAP value across all tIoU thresholds.

% \textbf{Training Details}. Our experimental setup followed exactly the same with strong baseline ActionFormer \cite{zhang2022actionformer}. The length of input features is fixed to 2304 during training. It results in each input sequence representing roughly 5 minutes on THUMOS14 and around 20 minutes on EPIC-Kitchens 100 \cite{damen2020rescaling}. The input features are then cropped randomly into a sequence of contiguous clips before feeding the feature to the model. Furthermore, Model EMA \cite{huang2017snapshot} and gradient clipping are utilized to stabilize the training as in \cite{zhang2022actionformer}.
\textbf{Training Details}. To ensure a fair and unbiased comparison, we employed the experimental setup of the robust baseline model, ActionFormer \cite{zhang2022actionformer}. This setup included various components such as decoder design $d$, non-maximum suppression (NMS) hyper-parameters in the post-processing stage, data augmentation, learning rate, feature extraction, and the number of feature pyramid level $L$. The sole variation in our study was the substitution of the Transformer block in ActionFormer with the Max Pooling block. All experiments are conducted with a kernel size of 3 for all TCM blocks. The subsequent ablation  will thorough analysis of the effects of varying kernel sizes. During training, the input feature length is kept constant at 2304, corresponding to approximately 5 minutes of video on both THUMOS14 and MultiTHUMOS datasets, roughly 20 minutes on the EPIC-Kitchens 100 dataset, and approximately 45 minutes on MUSES. Additionally, Model EMA \cite{huang2017snapshot} and gradient clipping techniques are employed, consistent with those used in \cite{zhang2022actionformer}, to promote training stability.

\subsection{Results on THUMOS14}
\input{text/4_1_exp_sota_thumos}

\subsection{Results on EPIC-Kitchens 100}
\input{text/4_2_exp_sota_epic}

\subsection{Results on MUSES}
\input{text/4_3_exp_sota_muses}


\subsection{Results on MultiTHUMOS}
\input{text/4_4_exp_sota_multithumos}

\subsection{Ablation Study}
\input{text/4_5_exp_ablation_study}
% Illustrate self-similarity samples on the MUSES and THUMOS14 datasets to demonstrate that Temporalmaxer works well in any case.
