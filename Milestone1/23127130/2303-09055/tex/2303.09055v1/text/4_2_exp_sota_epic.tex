\textbf{Dataset}. The EPIC-Kitchens 100 dataset \cite{damen2020rescaling} is a comprehensive collection of egocentric action videos, featuring 100 hours of footage from 700 sessions that document cooking activities in a variety of kitchens. Additionally, EPIC-Kitchens 100 is three times larger in terms of total video hours and more than ten times larger in terms of action instances (averaging 128 per video) when compared to THUMOS14. These videos are recorded from a first-person perspective, resulting in significant camera motion, and represent a novel challenge for TAL research.

\textbf{Feature Extraction}. Following previous work \cite{zhang2022actionformer, lin2019bmn, xu2020g}, we extract the videos feature using SlowFast network \cite{feichtenhofer2019slowfast} pre-trained on EPICKitchens \cite{damen2020rescaling}. We utilized a 32-frame input sequence with a stride of 16 to generate a set of 2304-D features. These features were then fed as input to our model.

\textbf{Result}. Tab. \ref{table:sota_epic} shows our results. TemporalMaxer demonstrates notable performance on the EPIC-Kitchens 100 dataset, achieving an average mAP of 24.5\% and 22.8\% for verb and noun, respectively. The superiority of our approach is further confirmed by a large margin over a strong and robust baseline, ActionFormer \cite{zhang2022actionformer}, with an average improvement of 1.0\% mAP for verb and 0.9\% mAP for noun. Again, TemporalMaxer outperforms other methods that utilize long-term TCM including self-attention \cite{zhang2022actionformer} or Graph \cite{xu2020g}. These results provide empirical evidence of the effectiveness of the simplest backbone in advancing the state-of-the-art on this challenging task.

\begin{table*}[]
\centering
\resizebox{.6\textwidth}{!}{%
\begin{tabular}{cccccccc}
\hline
\multirow{2}{*}{Task} & \multirow{2}{*}{Method}                                    & \multicolumn{6}{c}{tIoU}                                                                      \\ \cline{3-8}
                      &                                                            & 0.1           & 0.2           & 0.3           & 0.4           & 0.5           & Avg           \\ \hline
\multirow{4}{*}{Verb} & BMN \cite{lin2019bmn, damen2020rescaling} & 10.8          & 9.8           & 8.4           & 7.1           & 5.6           & 8.4           \\
                      & G-TAD \cite{xu2020g}                      & 12.1          & 11.0          & 9.4           & 8.1           & 6.5           & 9.4           \\
                      & ActionFormer \cite{zhang2022actionformer} & 26.6          & 25.4          & 24.2          & 22.3          & 19.1          & 23.5          \\
                      & Our (TemporalMaxer)                                        & \textbf{27.8} & \textbf{26.6} & \textbf{25.3} & \textbf{23.1} & \textbf{19.9} & \textbf{24.5} \\ \cline{2-8}
\multirow{4}{*}{Noun} & BMN \cite{lin2019bmn, damen2020rescaling} & 10.3          & 8.3           & 6.2           & 4.5           & 3.4           & 6.5           \\
                      & G-TAD \cite{xu2020g}                      & 11.0          & 10.0          & 8.6           & 7.0           & 5.4           & 8.4           \\
                      & ActionFormer \cite{zhang2022actionformer} & 25.2          & 24.1          & 22.7          & 20.5          & 17.0          & 21.9          \\
                      & Our (TemporalMaxer)                                        & \textbf{26.3} & \textbf{25.2} & \textbf{23.5} & \textbf{21.3} & \textbf{17.6} & \textbf{22.8} \\ \hline
\end{tabular}
}
\caption{The performance of our proposed method on the EPIC-Kitchens 100 dataset \cite{damen2020rescaling} is evaluated using various tIoU thresholds. The average mAP is reported over a range of tIoU thresholds [0.1:0.5:0.1]. The top-performing methods are highlighted in bold. Our proposed method outperforms the other methods significantly.}
\label{table:sota_epic}
\end{table*}
