\section{Related Work}
\label{sec:relatedwork}

\boldparagraph{Lane detection.}
% \boldparagraph{Lane detection.} 
Lane detection only considers predicting and evaluating the lane divider lines without spatial relation (merging and fork). 
Since most lane detection datasets only provide front-view images, previous lane detection methods~\cite{tabelini2021keep,wang2022keypoint,garnett20193d,lstr,guo2020gen,liu2022learning} were stuck in predicting lines with a small curvature in a limited horizontal FOV. BezierLaneNet~\cite{feng2022rethinking} uses a fully convolutional network to predict Bezier lanes defined with 4 Bezier control points. PersFormer~\cite{chen2022persformer} 
% proposes an end-to-end monocular 3D lane detector with  Transformer-based spatial feature transformation module, predicting 2D/3D lanes. 
proposes a Transformer-based architecture for spatial transformation and unifies 2D and 3D lane detection. 

\boldparagraph{Online HD map construction.}
% \boldparagraph{Online HD map construction.}
Online HD map construction can be seen as an advanced setting of lane detection, consisting of  lines and polygons with various semantics in the local 360$^\circ$ FOV  perception range of ego-vehicle.
% based on vehicle-mounted sensors.
With advanced 2D-to-BEV modules~\cite{Ma2022VisionCentricBP}, previous online HD map construction methods cast it into semantic segmentation task on the transformed BEV features~\cite{polarbev,cvt,bevformer,liu2022bevfusion,liu2022petrv2,lu2022ego3rt}. Building vectorized semantic HD map online achieves increasing interests nowadays~\cite{hdmapnet,maptr,vectormapnet,instagram,bemapnet,pivotnet}, HDMapNet~\cite{hdmapnet} follows a segmentation-then-vectorization paradigm.
% which predicts instance, direction, and class on each pixel of BEV features and then post-processes them on dense pixels.
To achieve end-to-end learning~\cite{detr,deformdetr,yolos}, VectorMapNet~\cite{vectormapnet} 
% first predicts coarse boxes and then utilizes an autoregressive network to predict point by point for each map element based on the coarse intermediate boxes. 
adopts a  two-stage pipeline for vectorized HD map learning.
MapTR~\cite{maptr} proposes a unified permutation-equivalent modeling to exploit the undirected nature of semantic HD map and designs a parallel end-to-end framework. BeMapNet~\cite{bemapnet} and PivotNet~\cite{pivotnet} propose  Bezier-based representation and pivot-based representation for modeling map geometry. While the above works focus on map elements without physical directions and lane graph topology, we aim to fill the gap in this work.
% to predict all the semantic map elements in one shot at real-time speed and state-of-the-art accuracy.

\boldparagraph{Road graph construction.}
% \boldparagraph{Road graph construction.} 
There is a long history of extracting the road graph from remote sensor data (\eg, aerial imagery and satellite imagery). 
Many works~\cite{Mattyus_2017_ICCV, zhou2018d, batra2019improved,He2020Sat2GraphRG,buslaev2018fully}
frame the road graph as a pixel-wise segmentation problem  
and utilizes morphological post-processing methods to extract the road graph. RoadTracer~\cite{bastani2018roadtracer} uses an iterative search process to extract graph topology step by step. Some works~\cite{chu2019neural,Tan_2020_CVPR,xu2021icurb,li2019topological,mi2021hdmapgen} follow this sequential generation paradigm. Different from the above works, we focus on the online, ego-centric setting with vehicle-mounted sensors to produce more fine-grained lane-level graph.


\boldparagraph{Lane graph construction.}
% \boldparagraph{Lane graph construction.} 
The lane graph is traditionally constructed with an offline pipeline~\cite{centerlinedet,laneextract, buchner2023learning}. \cite{laneextract} proposes a multi-step training pipeline to construct the lane graph of aerial images based on pixel-wise modeling. \cite{buchner2023learning} proposes a bottom-up approach to aggregate multiple local aerial lane graphs into a globally consistent graph. CenterlineDet~\cite{centerlinedet} proposes a DETR-like decision-making transformer network to iteratively update the global lane graph with vehicle-mounted sensors.
Recently, STSU~\cite{stsu} shifts the offline lane graph construction to the online, ego-centric setting with vehicle-mounted sensors. It models the lane graph as a set of disjoint pieces split by junction points and a set of connections among those pieces. 
% A DETR-like Transformer decoder is proposed to detect those Beizer lane pieces, and a successive MLP head is used to predict inter-piece connectivity.  
Based on STSU, recent works~\cite{can2022topology,toponet,wu2024topomlp} advance this piece-wise setting and push forward the performance.  Different from the above graph modelings, we regard the path as the primitive of the lane graph, and model the lane graph in a novel path-wise manner.

% % first trains a segmentation model to extract lanes at non-intersection areas, then it enumerates the pairs among those disjoint lanes and validates the connectivity with a trained turning lane validation model. An extra turning lane segmentation model is trained to complete the lane graph. 

% Recently, STSU~\cite{stsu} focuses on online lane graph construction with the vehicle-mounted monocular front camera, modeling the lane graph as a set of disjoint pieces split by junction points and a set of connections among those pieces. Based on STSU, \cite{can2022topology} designs a network and utilizes minimal circle extracted by time-consuming offline processing to further supervise the network to produce lane graph in a limited-FOV perception range.


% Different from the above works, we focus on building the lane graph under the challenging online setting~\cite{hdmapnet,maptr,vectormapnet}, \ie, broad  360$^\circ$ FOV perception based on vehicle-mounted sensors, facing diverse traffic conditions and topology. 
% Different from previous modeling, we regard the path as the primitive of the lane graph, and model the lane graph in a novel path-wise manner. 
