\documentclass[review]{elsarticle}
\begin{document}
	
\begin{itemize}
	\item We propose a novel CNN-Transformer model for slot-filling and intent-detection, achieving state-of-the-art for slot-filling task.
	\item We introduce the aligned Transformer decoder for sequence tagging problems.
	\item The window size of 1 in Convolutional networks should be used to preserve the one-to-one relationship of input tokens to output tags.
	\item Convolutional layer can be used to put an emphasis on the importance of adjacent tokens in the meaning of a word.
	\item Additional encoding after a pre-trained language model entails small computational cost but can be beneficial.

\end{itemize}
\end{document}