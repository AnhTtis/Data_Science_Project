\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{img/bit_da_framework.pdf}
    \caption{PICO++. A student-teacher framework, where the teacher is updated using EMA. The teacher then is used as a target data pseudo-labeler for both supervised contrastive and cross-entropy losses. Details are in Appendix \ref{sec:app_pico}. \vspace{-10pt}}
    \label{fig:pico++}
\end{figure}

\noindent\textbf{Overview:} PICO++ is a variant of  SePiCo \cite{xie2023sepico}. The method composes a student-teacher architecture with learning signals from  semi-supervised contrastive and semi-supervised cross-entropy losses.  The student updates the teacher with EMA, while the teacher provides pseudo-labels for the student network to learn from target data. The samples are constrasted against class prototypes, which are computed from teacher representations. Different from other solutions, the contrastive loss provides explicit source-target domain alignment. Similar to other winning solutions,  PICO++ is built on top of the very strong DAFormer\cite{hoyer2022daformer} architecture. The EMA update provides an implicit ensembling, which has been  shown to improve domain generalization performance \cite{}. 
\newline
\newline
\noindent\textbf{Results: }Source-only and domain adaptation results of PICO++ are reported in Table \ref{tab:baseline_results_new}. PICO++ achieves substantial performance gains compared to the source-only method. 
In Tables \ref{table:zerov2_class_val} and \ref{table:zerov2_class_test} , results are broken into different types of waste. The gain is much greater for classes like rigid plastic and metal, implying that PICO++ has more potential in recognizing classes featuring a relatively regular shape. Nonetheless, a consistent improvement could be observed from all valid classes, showing the effectiveness of PICO++.
\newline
\begin{table*}[h]
    \centering
    \resizebox{\textwidth}{!}{
        \begin{tabular}{ l | c c c c c | c }
            \toprule[1.2pt]
            Method & \rotatebox{0}{background} & \rotatebox{0}{rigid plastic} & \rotatebox{0}{cardboard} & \rotatebox{0}{metal} & \rotatebox{0}{soft plastic} & mIoU \\
            \midrule
            Source-only & 86.87 & 20.11 & 58.32 & 15.7 & 49.36 & 46.07 \\
            PICO++ & 86.10 & 42.77 & 58.79 & 32.13 & 52.33 & 54.43 \\
            \bottomrule[1.2pt]
        \end{tabular}
    }
    \caption{mIoU on ZeroWaste $\rightarrow$ ZeroWasteV2 \textbf{validation} set.}
    \label{table:zerov2_class_val}
\end{table*}

\begin{table*}[t]
    \centering
    \resizebox{\textwidth}{!}{
        \begin{tabular}{ l | c c c c c | c }
            \toprule[1.2pt]
            Method & \rotatebox{0}{background} & \rotatebox{0}{rigid plastic} & \rotatebox{0}{cardboard} & \rotatebox{0}{metal} & \rotatebox{0}{soft plastic} & mIoU \\
            \midrule
            Source-only & 91.80 & 25.03 & 61.60 & 15.51 & 42.15 & 47.22 \\
            PICO++ & 91.36 & 44.35 & 61.71 & 31.24 & 43.25 & 54.38 \\
            \bottomrule[1.2pt]
        \end{tabular}
    }
    \caption{mIoU on ZeroWaste $\rightarrow$ ZeroWasteV2 \textbf{test} set.}
    \label{table:zerov2_class_test}
\end{table*}
% This section should contain the source-only and domain adaptation results of your team's method on ZeroWaste V2 validation and test sets, including the class-wise results. Optionally, you can include the ablation study results if your method proposes multiple modifications to the baseline. Please elaborate here why you think certain modifications improved segmentation quality.

%\noindent\textbf{Student and Teacher Network Architectures:} The student and teacher networks are identical in architecture; they are built on top of the very strong DAFormer architecture, which is also used as a baseline for the challenge.Additionally, an extra projection head is added to reduce dimensionality (512$\rightarrow$256) for both the student and teacher. During training, the student is updated with loss gradients while the teacher is update with an exponential moving average (EMA)~\citep{} of student iterates. 
%\newline
%\noindent\textbf{Cross-Entropy Losses:} There are two cross-entropy losses used to update the student network. The first is a standard cross entropy loss applied on (augmented) source samples, denoted as $\mathcal{L}_{ce}^s$. Then, augmented target samples are pseudo-labeled using the teacher network, and then mixed with a source sample, creating mixed image $I_m^a$. The target pseudo-label is also mixed with the source label, creating mixed label $Y_m$. Another cross-entropy loss is applied to the student with the resulting mixed image-label pair $\mathcal{L}_{ce}^m(I_m^a, Y_m)$. The ratio of mixed image predictions whose confidence exceed $\beta$, which is called $\lambda_\beta$, reweights the $\mathcal{L}_{ce}^m$. The final loss on mixed images is $\mathcal{L}_{ssl}^m = \lambda_\beta\mathcal{L}_{ce}^m$. This method follows the DACS~\citep{tranheden2021dacs} methodology and allows for self-training using unlabelled target data. 
%\newline
%\noindent\textbf{Contrastive Losses:} In addition to the cross-entropy losses, a semi-supervised contrastive loss is used following SePiCo \cite{}. First, the training is warm-started using cross-entropy losses for $T_w = 3000$ iterations. Then, using the source data, per-label gaussians are fit to teacher projection-head features. These per-label gaussians are used to create proto-types to contrast the student features against. For a single sample of class $i$, the contrastive loss is formulated as 
%    \begin{align}
 %       \mathcal{L}_{cl}^{q_i} = -\log\left[\frac{exp(\frac{q_i^\top \mu_i}{\tau} + \frac{q_i^\top \Sigma_i q_i}{2\tau^2})}{exp(\frac{q_i^\top \mu_i}{\tau} + \frac{q_i^\top \Sigma_i q_i}{2\tau^2}) + \sum_{k=1, k\neq i}^{C}exp(\frac{q_i^\top \mu_k}{\tau} + \frac{q_i^\top \Sigma_k q_i}{2\tau^2})}\right] + \frac{q_i^\top\Sigma_iq_i}{2\tau^2}\,,
  %  \end{align}%
%where $q_i$ represents a query feature $q$ of $i^{th}$ class, and $C$ is the class number, $\tau$ denotes the smoothing factor common in contrastive learning. $\mu_i$ and $\Sigma_i$ are the mean and covariance of the distribution within the prototype from $i^{th}$ class. For source samples, ground truth class labels. For target samples, pseudo-labels are used. This contrastive loss ensures cross-domain feature alignment. For the derivation of this loss, please see the SePiCo paper, section 3.3.2.. Finally the regularization term is formulated as:

%    \begin{align}
%        \mathcal{L}_{reg}^{\bar{q}} = \frac{1}{C\log C} \sum_{k=1}^{C} \log\frac{e^{\bar{q}^{\top} \mu_k/\tau}}{\sum_{l=1}^{K} e^{\bar{q}^\top \mu_l/\tau}}\,,
%    \end{align}%
%where $\bar{q}$ is the average of all features for either source or target domain. This prevents collapse of unsupervised samples. 
%\newline
%\noindent\textbf{Overall loss and Results:} Overall, PICO++ trained with the following objective:

%    \begin{align}
%        \mathcal{L} = \mathcal{L}_{ce}^s + \mathcal{L}_{ssl}^m + \lambda_{cl}\mathcal{L}_{cl} + \lambda_{reg}\mathcal{L}_{reg}
%    \end{align}%
%where $\lambda_{cl}$ and $\lambda_{reg}$ are constant weights.

%As seen in Table 1, this methodology substantially improves over the source-only baseline. 
