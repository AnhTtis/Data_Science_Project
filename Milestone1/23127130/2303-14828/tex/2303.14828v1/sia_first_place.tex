 The first place solution, \texttt{SIA\_Adapt}, uses DAFormer (the baseline method) as the first step. There were two notable variations to DAFormer used by SIA\_Adapt. First, the team found rare class sampling, which was used in training DAFormer, to be unhelpful for performance, and so they dropped it. Second, and more importantly, instead of an Imagenet-1K pre-trained transformer backbone, an Imagenet-22K pretrained ConvNeXt-L~\citep{liu2022convnet} backbone was used. This allowed the method to use a strong feature representation to build on top of and even without any target data at training time, perform at an impressive 56.4\% mIoU on the target (ZeroWaste v2) test set. As another comparison, when the method was initialized with an Imagenet-1K pre-trained ConvNeXt-L backbone, it achieved 57.29\% mIoU on the target test set, compared to the 59.66\% mIoU (See Table~\ref{tab:baseline_results_new}) achieved with an Imagenet-22K initialization, thus isolating the effect that pre-training had on SIA\_Adapt's performance. To better decouple the effects of the backbone architecture and pre-training, we conducted a study with the DAFormer baseline (See Appendix~\ref{sec:backbone-ablation}).

With a trained DAFormer (including the modifications as described above), the method proceeds by pseudo-labeling the target and further self-training three different copies of this initial trained DAFormer, each using a different data-augmentation method (See Figure~\ref{figure:sia_adapt}). Finally, these three networks are combined in a model soup~\citep{wortsman2022model}, i.e., their weights are averaged, to obtain the final model. 

\begin{figure*}[!t] \vspace{-20pt}
  \centering
  \includegraphics[width=\linewidth]{img/sia_adapt.pdf}
  \caption{
  \vspace{-3mm}
  Overview of \texttt{SIA\_Adapt}, the first place solution for VisDA-2022. The method uses a strong backbone initialization in the form of an Imagenet-22K pre-trained ConvNeXt-L and pseudolabeling. Also key to the method are self-training using different augmentations and using the resulting models together in a model soup. 
  \vspace{-5mm}
  }
  \label{figure:sia_adapt}
\end{figure*}