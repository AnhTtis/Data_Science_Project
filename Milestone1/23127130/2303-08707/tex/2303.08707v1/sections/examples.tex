\section{Numerical Example}\label{sec_examples}
In \cite[Sec.~VII.B]{DePersis22}, a stabilizing controller for SISO flat systems was designed from data by solving a semi-definite program. The resulting controller is a weighted sum of a set of basis functions which contain the synthetic input $v$ in their span. If $v$ was not contained in their span, then a locally stabilizing controller can potentially be designed, provided that the basis functions result in a sufficiently good local approximation of $v$ (cf. \cite[Cor. 2 and Sec.~III.B]{DePersis22}). In both cases, persistence of excitation of the basis functions of order one is a necessary and sufficient condition for the feasibility of a convex program that is solved to obtain the control gains (cf. \cite[Cor. 2, Thm. 2, and Thm. 5]{DePersis22}).

Consider the following SISO flat system
\begin{equation}
	\begin{aligned}
		x_{1,k+1} &= x_{2,k},\\
		x_{2,k+1} &= -\sin(x_{1,k}) + x_{1,k}x_{2,k}^2 - x_{1,k}^3x_{2,k} + u_k,
		%		2\sin(x_{1,k}) + 0.5x_{1,k}x_{2,k}^2 + u_k,
	\end{aligned}\label{eqn_ex_NLsys}
\end{equation}
%Notice that the system is in the normal form \eqref{BINF}, i.e., $\xi_k=x_k$ and that $v_k=x_{2,k+1}$. 
with the output being $y_k=x_{1,k}$. In this example, we compare the performance of three stabilizing controllers: (i) An exact linearizing and stabilizing controller designed using a set of basis functions that include $v$ in their span (based on model knowledge), and two locally stabilizing controllers (ii and iii) designed using the following choice of basis functions which do not contain $v$ in their span (and can hence be applied without model knowledge)
\begin{equation}
	\Phi(\xi_k,u_k) = \begin{bmatrix}
		u_k & \xi_k^\top & (\xi_k^2)^\top & (\xi_k^3)^\top
	\end{bmatrix}^{\hspace{-0.5mm}\top}.\label{eqn_ex_basisfunctions}
\end{equation}
For controllers (i) and (ii), PE is enforced by sampling the input randomly from a uniform distribution, then the collected data is used to design the controllers as described in \cite[Cor. 2]{DePersis22} and \cite[Cor. 2 and Thm. 5]{DePersis22}, respectively. For the last controller, PE is enforced \textit{a priori} using the results of Theorem~\ref{thm_aprioriFL}. Although the choice of the basis functions in \eqref{eqn_ex_basisfunctions} is different\footnote{The method described in \cite[Cor. 2]{DePersis22} requires that the unknown map \eqref{eqn_expressionforv} is linear in $u$, which is why we use the basis functions \eqref{eqn_ex_basisfunctions}.} from that in \eqref{eqn_specificchoice}, one can easily see from the proof of Theorem \ref{thm_aprioriFL} that using inputs of the form \eqref{eqn_PEinputSISOflat} also guarantees collective PE of \eqref{eqn_ex_basisfunctions}. For controller (iii), we used a straightforward extension of the design procedure in \cite{DePersis22} such that collected data from multiple experiments (i.e., collective persistence of excitation) can be used.
%Based on the collected data, we used a straightforward extension of the design procedure in \cite{DePersis22} to multiple experiments.

Notice that Theorem~\ref{thm_aprioriFL} requires $\sum_{j=1}^{t} N_j=9$ data points, where $t=3$ as in \eqref{eqn_ex_basisfunctions}. Since the system is unstable, the input data for controllers (i) and (ii) (also of length $N=9$) had to be sampled from a small neighborhood around the origin, namely from the uniform distribution $U(-0.5,0.5)$, whereas using multiple experiments as in Theorem~\ref{thm_aprioriFL} allowed us to use inputs with larger magnitudes (sampled from $U(-1,1)$). In \cite{vanWaarde20}, a similar observation was made for linear systems. As a result, a larger quantitative level of PE was attained. Table~\ref{table_comparison} shows the average minimum singular value (denoted $\sigma_{\textup{min}}$) of the data matrices over 100 experiments.

The performance of the closed-loop system (over $T=20$ time instants) was compared for each of the three controllers starting from the same initial conditions (randomly sampled from $U(-1,1)\times U(-1,1)$). Table~\ref{table_comparison} shows the average cumulative stabilization errors (defined as $\sum_{k=0}^{T-1}\frac{1}{T}|x_{i,k}|$, for $i=1,2$) for all three controllers over 100 experiments. It is observed that controller~(i) is the best performing one, which is expected because it enforces exact nonlinearity cancellation. Controller (iii) is shown to outperform controller (ii), although the same set of basis functions \eqref{eqn_ex_basisfunctions} was used. This can be attributed to the fact that larger levels of PE were attained using multiple experiments. Finally, Table~\ref{table_comparison} excludes 9 (respectively 4) closed-loop experiments that were unstable for controllers (ii) and (iii). This may suggest that the region of attraction of controller (iii) is larger compared to (ii).
\begin{table}[!t]
	\caption{Average level of PE and cumulative stabilization error for all three control schemes.}
	\vspace{-1.5em}
	\begin{center}
		\begin{tabular}{|l|l|l|l|}
			\hline
			Compared value & Controller (i) & Controller (ii) & Controller (iii) \\ \hline
			$\sigma_{\textup{min}}$
			& 0.0050 & 0.0050 & 0.0264 \\ \hline
			$\sum_{i=0}^{T-1}\frac{1}{T}|x_{1,i}|$ 
			& 0.0469 & 0.0657 & 0.0569 \\ \hline
			$\sum_{i=0}^{T-1}\frac{1}{T}|x_{2,i}|$ 
			& 0.0269 & 0.0458 & 0.0370 \\ \hline
		\end{tabular}
	\vspace{-2.5em}
	\label{table_comparison}
	\end{center}
\end{table}