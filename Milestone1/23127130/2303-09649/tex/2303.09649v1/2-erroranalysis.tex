Now we will examine the error introduced by zeroth order mapping, which is used by existing neuron mapping methods. First, note that under affine transformations, zeroth order mapping of piecewise linear curves introduce no error, so these results are most applicable under non-affine transformations. The following results require that the curve $c$ be parameterized by arc length. However, all continuously differentiable regular curves can be reparameterized by arc length \cite{younes2010shapes}. We use $\vert \cdot \vert$ to denote the Euclidean norm for elements of $\mathbb{R}^d$, and the spectral norm for matrices.

\begin{proposition}
\textbf{[Zeroth Order Mapping Error Bound 1]} Say $\phi: \mathbb{R}^3 \rightarrow \mathbb{R}^3$ is a $C^1$ diffeomorphism and $c: [0,L] \rightarrow \mathbb{R}^3$ is a continuous, piecewise $C^1$ curve parameterized by arc length with knots $\{t_i: t_1=0, t_n=L, t_{i-1} < t_i\}_{i=1}^n$. For the transformed curve $f=\phi \circ c$, the zeroth order mapping defines a first order spline $g$ which satisfies:

\begin{align}
    \max_{t \in [0,L]} \vert f(t)-g(t)\vert &\leq \delta \sqrt{3} \max_{t \in [0,L]} \vert D\phi \circ c(t) \vert \label{eq:error}
\end{align}

\noindent
where $\delta \triangleq \max_{2 \leq i\leq n} \vert t_i-t_{i-1}\vert$, and $D\phi \circ c(t)$ is the Jacobian of $\phi$ evaluated at $c(t)$.
\end{proposition}

The proof of the proposition is an adaptation of a spline approximation theorem in \cite{kincaid2009numerical}. In practice, the neuronal curves that are being mapped ($c\rightarrow \phi \circ c$) are often piecewise linear curves themselves. So, we present another bound in this setting, and when $\phi$ is close to the identity transformation.

\begin{proposition}
\textbf{[Zeroth Order Mapping Error Bound 2]} Say $\phi: \mathbb{R}^3 \rightarrow \mathbb{R}^3$ is a $C^1$ diffeomorphism and $c: [0,L] \rightarrow \mathbb{R}^3$ is a continuous, piecewise linear curve parameterized by arc length with knots $\{t_i: t_1=0, t_n=L, t_{i-1} < t_i\}_{i=1}^n$. For the transformed curve $f=\phi \circ c$, the zeroth order mapping defines a first order spline $g$ which satisfies:

\begin{align}
    \max_{t \in [0,L]} \vert f(t)-g(t)\vert &\leq \max_{i \in \{0,...,n\}, t \in [t_{i-1}, t_i]} \frac{1}{2} \left( \vert D\phi \circ c(t) - I \vert \vert t_i-t_{i-1} \vert + \vert \epsilon_i - \epsilon_{i-1}\vert \right) \label{eq:error2}
\end{align}

\noindent
where $\epsilon_i\triangleq c(t_i)-\phi(c(t_i))$ and $D\phi \circ c(t)$ is the Jacobian of $\phi$ evaluated at $c(t)$.
\end{proposition}

In summary, we have presented two bounds on the maximum deviation of the true transformed curve from the approximation obtained by zeroth order mapping. Eq. \ref{eq:error} applies to all piecewise differentiable curves but involves $\vert D\phi \vert$ which does not vanish even if $\phi$ is the identity map (in which case zeroth order mapping has zero error for piecewise linear curves). Eq. \ref{eq:error2} only applies to piecewise linear $c$, but goes to zero as $\phi$ approaches the identity map. Both bounds depend on the spectral norm of $D\phi$, and arc lengths of the original curve segments. We note that $\log \vert D\phi\vert$ is the finite time Lyapunov exponent, a well-known quantity in field dynamics which characterizes the amount of stretching in a differentiable flow. 

It is worth noting that Eq. \ref{eq:error} and \ref{eq:error2} apply to $\max_{t \in [0,L]} \vert f(t)-g(t)\vert$, which is not parameterization invariant, and therefore not a strictly geometric quantity. However we note that this quantity is an upper bound of the Frechet distance, which is parameterization invariant. 


In this paper we demonstrate first order mapping in an effort to mitigate this mapping error. Such a method has the advantage of having superior error convergence at the knots as a consequence of Taylor's theorem. Further, we present a set of error bounds that helps clarify the advantage of first order mapping.

\begin{proposition}
\textbf{[Comparable Bounds for Zeroth and First Order Mapping]} Say $\phi: \mathbb{R}^3 \rightarrow \mathbb{R}^3$ is a $C^4$ diffeomorphism and $c: [a,b] \rightarrow \mathbb{R}^3$ is a continuous, piecewise $C^4$ curve parameterized with knots $\{t_i: t_1=a, t_n=b, t_{i-1} < t_i\}_{i=1}^n$. For the transformed curve $f=\phi \circ c$ defined by coordinate functions $f=(f^0,f^1,f^2)^T$, the zeroth order mapping defines a first order spline $g_0$ which satisfies:

\begin{align}
    \max_{t \in [a,b]} \vert f(t)-g_0(t)\vert &\leq \frac{\sqrt{3}}{4} \max_{t \in [a,b], j \in \{0,1,2\}} \vert \partial^{(4)}_t f^j(t)\vert \left(\frac{\delta}{2}\right)^4 + \nonumber \\
    &\frac{\sqrt{3}}{2} \left(\frac{\delta}{2}\right)^2 \max_{i \in \{1...n\}, j \in \{0,1,2\}} \vert \partial^{(3)}_t f^j(t_i)\vert \left(\frac{\delta}{2}\right) + \nonumber \\
    & \frac{\sqrt{3}}{2} \left(\frac{\delta}{2}\right)^2 \max_{i \in \{1...n\}, j \in \{0,1,2\}} \vert \partial^{(2)}_t f^j(t_i)\vert \label{eq:compare0}
\end{align}

\noindent 
where $\delta\triangleq \max_{2 \leq i\leq n} \vert t_i-t_{i-1}\vert$ and $\partial^{(k)}_t f^j(t)$ is the $k$'th derivative of $f^j$ evaluated at $t$. Also, the first order mapping defines a third order spline $g_1$, which satisfies

\begin{align}
    \max_{t \in [a,b]} \vert f(t)-g_1(t)\vert &\leq \frac{\sqrt{3}}{4!} \max_{t \in [a,b], j\in \{0,1,2\}} \vert \partial^{(4)}_t f^j(t)\vert \left(\frac{\delta}{2}\right)^4 \label{eq:compare1}
\end{align}

\noindent

and we note that the bound in \ref{eq:compare1} is tighter than the bound in \ref{eq:compare0}.
Further, there exists a transformed curve $f$ and a set of knots $\{t_i\}_{i=1}^n$ that achieves both bounds exactly.

\end{proposition}

Thus, we present related error bounds on both zeroth and first order mapping methods, both of which are achieved for some curve. The error bound for first order mapping is smaller than that for zeroth order mapping, though for any given curve, either method may produce smaller error than the other. Proofs for the propositions are in the supplement.

% which states that for a function $f:\mathbb{R} \rightarrow \mathbb{R}$ that is $k$ times differentiable at $x=a$:

% \begin{align*}
%     f(x) - \sum_{j=1}^k \frac{f^{(j)}(a)}{j!} (x-a)^j=o((x-a)^k)
% \end{align*}

% i.e. the $k$-th order Taylor approximation converges to $0$ at order $k$. This bound is known to be tight and therefore the error of the first order mapping has superior convergence at the knots.