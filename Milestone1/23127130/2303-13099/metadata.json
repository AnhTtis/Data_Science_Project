{
    "arxiv_id": "2303.13099",
    "paper_title": "Multi-View Zero-Shot Open Intent Induction from Dialogues: Multi Domain Batch and Proxy Gradient Transfer",
    "authors": [
        "Hyukhun Koh",
        "Haesung Pyun",
        "Nakyeong Yang",
        "Kyomin Jung"
    ],
    "submission_date": "2023-03-23",
    "revised_dates": [
        "2023-04-25"
    ],
    "latest_version": 2,
    "categories": [
        "cs.CL",
        "cs.AI"
    ],
    "abstract": "In Task Oriented Dialogue (TOD) system, detecting and inducing new intents are two main challenges to apply the system in the real world. In this paper, we suggest the semantic multi-view model to resolve these two challenges: (1) SBERT for General Embedding (GE), (2) Multi Domain Batch (MDB) for dialogue domain knowledge, and (3) Proxy Gradient Transfer (PGT) for cluster-specialized semantic. MDB feeds diverse dialogue datasets to the model at once to tackle the multi-domain problem by learning the multiple domain knowledge. We introduce a novel method PGT, which employs the Siamese network to fine-tune the model with a clustering method directly.Our model can learn how to cluster dialogue utterances by using PGT. Experimental results demonstrate that our multi-view model with MDB and PGT significantly improves the Open Intent Induction performance compared to baseline systems.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13099v1",
        "http://arxiv.org/pdf/2303.13099v2"
    ],
    "publication_venue": "8 pages, 3 figures, DSTC 2023 workshop"
}