
@article{cscw2021-qbd.pdf,
author = {Jiang, Jialun Aaron and Wade, Kandrea and Fiesler, Casey and Brubaker, Jed R.},
title = {Supporting Serendipity: Opportunities and Challenges for Human-AI Collaboration in Qualitative Analysis},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW1},
doi = {10.1145/3449168},
abstract = {Qualitative inductive methods are widely used in CSCW and HCI research for their ability to generatively discover deep and contextualized insights, but these inherently manual and human-resource-intensive processes are often infeasible for analyzing large corpora. Researchers have been increasingly interested in ways to apply qualitative methods to "big" data problems, hoping to achieve more generalizable results from larger amounts of data while preserving the depth and richness of qualitative methods. In this paper, we describe a study of qualitative researchers' work practices and their challenges, with an eye towards whether this is an appropriate domain for human-AI collaboration and what successful collaborations might entail. Our findings characterize participants' diverse methodological practices and nuanced collaboration dynamics, and identify areas where they might benefit from AI-based tools. While participants highlight the messiness and uncertainty of qualitative inductive analysis, they still want full agency over the process and believe that AI should not interfere. Our study provides a deep investigation of task delegability in human-AI collaboration in the context of qualitative analysis, and offers directions for the design of AI assistance that honor serendipity, human agency, and ambiguity.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {94},
numpages = {23},
keywords = {ai, interview, human-ai collaboration, qualitative research}
}


@misc{Marcus.pdf,
title="AI's Jurassic Park moment",
url={https://garymarcus.substack.com/p/ais-jurassic-park-moment},
year={2022},
author={Gary Marcus},
day={10},
month={Dec},
}


@misc{Dawn_of_Artificial_Imagination,
title={The Dawn of Artificial Imagination},
author={Matteo Wong},
year={2022},
day={14},
month={Dec},
url={https://www.theatlantic.com/technology/archive/2022/12/generative-ai-technology-human-creativity-imagination/672460/},
}


@misc{The_Future_of_Employment.pdf,
author={Carl Benedikt Frey and Michael Osborne},
title={The Future of Employment: How susceptible are jobs to computerisation?},
journal={},
volume={},
number={},
year={2013},
publisher={University of Oxford},
}


@article{McDonald_Reliability_CSCW19.pdf,
author = {McDonald, Nora and Schoenebeck, Sarita and Forte, Andrea},
title = {Reliability and Inter-Rater Reliability in Qualitative Research: Norms and Guidelines for CSCW and HCI Practice},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {CSCW},
doi = {10.1145/3359174},
abstract = {What does reliability mean for building a grounded theory? What about when writing an auto-ethnography? When is it appropriate to use measures like inter-rater reliability (IRR)? Reliability is a familiar concept in traditional scientific practice, but how, and even whether to establish reliability in qualitative research is an oft-debated question. For researchers in highly interdisciplinary fields like computer-supported cooperative work (CSCW) and human-computer interaction (HCI), the question is particularly complex as collaborators bring diverse epistemologies and training to their research. In this article, we use two approaches to understand reliability in qualitative research. We first investigate and describe local norms in the CSCW and HCI literature, then we combine examples from these findings with guidelines from methods literature to help researchers answer questions like: "should I calculate IRR?" Drawing on a meta-analysis of a representative sample of CSCW and HCI papers from 2016-2018, we find that authors use a variety of approaches to communicate reliability; notably, IRR is rare, occurring in around 1/9 of qualitative papers. We reflect on current practices and propose guidelines for reporting on reliability in qualitative research using IRR as a central example of a form of agreement. The guidelines are designed to generate discussion and orient new CSCW and HCI scholars and reviewers to reliability in qualitative research.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {72},
numpages = {23},
keywords = {content analysis, qualitative methods, interviews, inter-rater reliability, IRR}
}


@article{nurses,
title={Fastest Growing Occupations},
author={{U.S. Bureau of Labor Statistics}},
url={https://www.bls.gov/ooh/fastest-growing.htm},
year={2022},
}


@article{braun2006.pdf,
author = { Virginia   Braun  and  Victoria   Clarke },
title = {Using thematic analysis in psychology},
journal = {Qualitative Research in Psychology},
volume = {3},
number = {2},
pages = {77-101},
year  = {2006},
publisher = {Routledge},
doi = {10.1191/1478088706qp063oa},
URL = { https://www.tandfonline.com/doi/abs/10.1191/1478088706qp063oa
},
}


@Inbook{braun2019.pdf,
author="Braun, Virginia
and Clarke, Victoria
and Hayfield, Nikki
and Terry, Gareth",
editor="Liamputtong, Pranee",
title="Thematic Analysis",
bookTitle="Handbook of Research Methods in Health Social Sciences",
year="2019",
publisher="Springer Singapore",
address="Singapore",
pages="843--860",
abstract="This chapter maps the terrain of thematic analysis (TA), a method for capturing patterns (``themes'') across qualitative datasets. We identify key concepts and different orientations and practices, illustrating why TA is often better understood as an umbrella term, used for sometimes quite different approaches, than a single qualitative analytic approach. Under the umbrella, three broad approaches can be identified: a ``coding reliability'' approach, a ``codebook'' approach, and a ``reflexive'' approach. These are often characterized by distinctive -- sometimes radically different -- conceptualizations of what a theme is, as well as methods for theme identification and development, and indeed coding. We then provide practical guidance on completing TA within our popular (reflexive) approach to TA, discussing each phase of the six-phase approach we have developed in relation to a project on men, rehabilitation, and embodiment. We conclude with a discussion of key concerns related to ensuring the TA you do -- within whatever approach -- is of the highest quality.",
isbn="978-981-10-5251-4",
doi="10.1007/978-981-10-5251-4_103",
}



@inproceedings{Local_Standards,
author = {Caine, Kelly},
title = {Local Standards for Sample Size at CHI},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/2858036.2858498},
abstract = {We describe the primary ways researchers can determine the size of a sample of research participants, present the benefits and drawbacks of each of those methods, and focus on improving one method that could be useful to the CHI community: local standards. To determine local standards for sample size within the CHI community, we conducted an analysis of all manuscripts published at CHI2014. We find that sample size for manuscripts published at CHI ranges from 1 -- 916,000 and the most common sample size is 12. We also find that sample size differs based on factors such as study setting and type of methodology employed. The outcome of this paper is an overview of the various ways sample size may be determined and an analysis of local standards for sample size within the CHI community. These contributions may be useful to researchers planning studies and reviewers evaluating the validity of results.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {981–992},
numpages = {12},
keywords = {sample size, methodology, N, number of participants, evaluation, research methods, meta-HCI},
series = {CHI '16}
}
location = {San Jose, California, USA},



@article{deterding2018.pdf,
author = {Nicole M. Deterding and Mary C. Waters},
title ={Flexible Coding of In-depth Interviews: A Twenty-first-century Approach},
journal = {Sociological Methods \& Research},
volume = {50},
number = {2},
pages = {708-739},
year = {2021},
doi = {10.1177/0049124118799377},
    abstract = { Qualitative coding procedures emanating from grounded theory were limited by technologies of the 1960s: colored pens, scissors, and index cards. Today, electronic documents can be flexibly stored, retrieved, and cross-referenced using qualitative data analysis (QDA) software. We argue the oft-cited grounded theory framework poorly fits many features of contemporary sociological interview studies, including large samples, coding by teams, and mixed-method analysis. The grounded theory approach also hampers transparency and does not facilitate reanalysis or secondary analysis of interview data. We begin by summarizing grounded theory’s assumptions about coding and analysis. We then analyze published articles from American Sociological Association flagship journals, demonstrating that current conventions for semistructured interview studies depart from the grounded theory framework. Based on experience analyzing interview data, we suggest steps in data organization and analysis to better utilize QDA technology. Our goal is to support rigorous, transparent, and flexible analysis of in-depth interview data. We end by discussing strengths and limitations of our twenty-first-century approach. }
}


@misc{chatgpt-blog,
url={https://openai.com/blog/chatgpt/},
title={ChatGPT: Optimizing Language Models for Dialogue},
year={2022},
author={{OpenAI}},
}


@article{pmed.0020124.pdf,
    doi = {10.1371/journal.pmed.0020124},
    author = {Ioannidis, John P. A.},
    journal = {PLOS Medicine},
    publisher = {Public Library of Science},
    title = {Why Most Published Research Findings Are False},
    year = {2005},
    month = {08},
    volume = {2},
    pages = {null},
    abstract = {Summary There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
    number = {8},
}

@article{roberta-base-openai-detector,
  title={Release strategies and the social impacts of language models},
  author={Solaiman, Irene and Brundage, Miles and Clark, Jack and Askell, Amanda and Herbert-Voss, Ariel and Wu, Jeff and Radford, Alec and Krueger, Gretchen and Kim, Jong Wook and Kreps, Sarah and others},
  journal={arXiv preprint arXiv:1908.09203},
  year={2019}
}


@misc{icml,
title={Clarification on Large Language Model Policy LLM},
year={2023},
author={
    Barbara Engelhardt and
    Emma Brunskill and
    Kyunghyun Cho
},
url={https://icml.cc/Conferences/2023/llm-policy},
}
author={{ICML Program Chairs}},



@misc{stackoverflowBAN,
title={Temporary policy: ChatGPT is banned},
author={Stackoverflow.com},
year={2022},
url={https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned},
}

@book{dilemma,
title={The Innovator’s Dilemma. When New Technologies Cause Great Firms to Fail  },
autor={Christensen, Clayton M. },
publisher={Harvard Business School Press},
year={1997},
address={Boston, MA},
}

@misc{moore,
title={Moore's Law for Everything},
url={https://moores.samaltman.com/},
year={2021},
author={Sam Altman},
}



@book{Glaser_1967.pdf,
title={The Discovery of Grounded Theory: Strategies for Qualitative Research},
author={Glaser, Barney G. and Strauss, Anselm L.},
publisher={Aldine Publishing Company},
address={Chicago},
year={1967},
}


@book{Superintelligence,
title={Superintelligence. Paths, Dangers, Strategies.},
author={Nick Bostrom},
year={2014},
publisher={Oxford University Press},
}


@misc{StackOverflow,
title={Use of ChatGPT generated text for content on Stack Overflow is temporarily banned},
author={{StackOverflow}},
year={2022},
}


@misc{atlantic-essay,
title={The End of High-School English},
author={Daniel Herman},
publisher={{The Atlantic}},
url={https://www.theatlantic.com/technology/archive/2022/12/openai-chatgpt-writing-high-school-english-essay/672412/},
year={2022},
}

@misc{dead,
title={The College Essay Is Dead},
url={https://12ft.io/proxy?ref=&q=https://www.theatlantic.com/technology/archive/2022/12/chatgpt-ai-writing-college-student-essays/672371/},
year={2022},
author={Stephen Marche},
}

@misc{Google,
title={A New Chat Bot Is a ‘Code Red’ for Google’s Search Business},
author={Nico Grant and Cade Metz},
publisher={The New York Times},
year={2022},
url={https://www.nytimes.com/2022/12/21/technology/ai-chatgpt-google-search.html},
}



@misc{money,
title={Money Will Kill ChatGPT’s Magic},
author={David Karpf},
url={https://www.theatlantic.com/technology/archive/2022/12/chatgpt-ai-chatbots-openai-cost-regulations/672539/},
publisher={The Atlantic},
year={2022},
}

@report{RAND_PE198.pdf,
title={The Russian ``Firehose of Falsehood'' Propaganda Model},
author={Christopher Paul and Miriam Matthews},
year={2016},
publisher={Rand Corporation},
url={https://www.rand.org/pubs/perspectives/PE198.html},
}



@misc{2206.13353.pdf,
  doi = {10.48550/ARXIV.2206.13353},
  author = {Carlsmith, Joseph},
  keywords = {Computers and Society (cs.CY), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Is Power-Seeking AI an Existential Risk?},
  publisher = {arXiv},
  year = {2022},
}
  copyright = {arXiv.org perpetual, non-exclusive license}


@misc{existential-risk,
url={https://www.lesswrong.com/posts/TeSTeAwrnGtf9jwfR/power-seeking-ai-and-existential-risk},
author={Antonio Franca},
year={2022},
}

@book{posttruth,
title={Post-Truth},
author={Lee C. McIntyre},
year={2018},
publisher={MIT Press},
address={Cambridge, MA},
}


@misc{2212.07476.pdf,
  doi = {10.48550/ARXIV.2212.07476},
  author = {Deckers, Niklas and Fröbe, Maik and Kiesel, Johannes and Pandolfo, Gianluca and Schröder, Christopher and Stein, Benno and Potthast, Martin},
  keywords = {Information Retrieval (cs.IR), Computation and Language (cs.CL), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {The Infinite Index: Information Retrieval on Generative Text-To-Image Models},
  publisher = {arXiv},
  year = {2022},
}
  copyright = {arXiv.org perpetual, non-exclusive license}


@misc{2201.11903.pdf,
  doi = {10.48550/ARXIV.2201.11903},
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Chain of Thought Prompting Elicits Reasoning in Large Language Models},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{gptindex,
title={GPT Index},
url={https://github.com/jerryjliu/gpt_index},
author={Jerry Liu},
year={2022},
}


@misc{jukebox,
  doi = {10.48550/ARXIV.2005.00341},
  author = {Dhariwal, Prafulla and Jun, Heewoo and Payne, Christine and Kim, Jong Wook and Radford, Alec and Sutskever, Ilya},
  keywords = {Audio and Speech Processing (eess.AS), Machine Learning (cs.LG), Sound (cs.SD), Machine Learning (stat.ML), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Jukebox: A Generative Model for Music},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{soundraw,
title={Soundraw.io},
author={Soundraw},
url={https://soundraw.io},
year={2022},
}

@mis{musenet,
title={MuseNet},
url={https://openai.com/blog/musenet/},
year={2019},
author={OpenAI},
}

@misc{harmonai,
title={Harmonai.org},
author={Harmonai},
year={2022},
url={https://www.harmonai.org/},
}

@misc{Midjourney,
title={Midjourney.com},
author={Midjourney},
year={2022},
url={},
}

@misc{stablediffusion,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2021},
      eprint={2112.10752},
      archivePrefix={arXiv},
}
      primaryClass={cs.CV}


@inproceedings{creativity,
  author = {Oppenlaender, Jonas},
  title = {The Creativity of Text-to-Image Generation},
  year = {2022},
  isbn = {9781450399555},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3569219.3569352},
  booktitle = {25th International Academic Mindtrek Conference},
  pages = {192–202},
  numpages = {11},
  series = {Academic Mindtrek 2022},
  doi = {10.1145/3569219.3569352},
}
  location = {Tampere, Finland},


@misc{prompt-engineering,
  author = {Jonas Oppenlaender},
  title = {A Taxonomy of Prompt Modifiers for Text-To-Image Generation},
  year = {2022},
  publisher = {arXiv},
  numpages = {15},
  doi = {10.48550/ARXIV.2204.13988},
}
  note = {arXiv},



@InProceedings{978-3-030-16667-0_3.pdf,
author="McCormack, Jon
and Gifford, Toby
and Hutchings, Patrick",
editor="Ek{\'a}rt, Anik{\'o}
and Liapis, Antonios
and Castro Pena, Mar{\'i}a Luz",
title="Autonomy, Authenticity, Authorship and Intention in Computer Generated Art",
booktitle="Computational Intelligence in Music, Sound, Art and Design",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="35--50",
abstract="This paper examines five key questions surrounding computer generated art. Driven by the recent public auction of a work of ``AI Art'' we selectively summarise many decades of research and commentary around topics of autonomy, authenticity, authorship and intention in computer generated art, and use this research to answer contemporary questions often asked about art made by computers that concern these topics. We additionally reflect on whether current techniques in deep learning and Generative Adversarial Networks significantly change the answers provided by many decades of prior research.",
isbn="978-3-030-16667-0"
}




@inproceedings{3334480.3382892.pdf,
author = {Ragot, Martin and Martin, Nicolas and Cojean, Salom\'{e}},
title = {AI-Generated vs. Human Artworks. A Perception Bias Towards Artificial Intelligence?},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3334480.3382892},
abstract = {Via generative adversarial networks (GANs), artificial intelligence (AI) has influenced many areas, especially the artistic field, as symbol of a human task. In human-computer interaction (HCI) studies, perception biases against AI, machines, or computers are generally cited. However, experimental evidence is still lacking. This paper presents a wide-scale experiment in which 565 participants are asked to evaluate paintings (which were created by humans or AI) on four dimensions: liking, perceived beauty, novelty, and meaning. A priming effect is evaluated using two between-subject conditions: Artworks presented as created by an AI, and artworks presented as created by a human artist. Finally, the paintings perceived as being drawn by human are evaluated significantly more highly than those perceived as being made by AI. Thus, using such a methodology and sample in an unprecedented way, the results show a negative bias of perception towards AI and a preference bias towards human systems.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {AI, GAN, computational creativity, artificial intelligence, can, authorship, painting, arts, bias},
series = {CHI EA '20}
}
location = {Honolulu, HI, USA},


@misc{HYPECYCLE,
author={Fenn, Jackie and Linden, Alexander},
year={2003},
title={Understanding Gartner's Hype Cycles},
howpublished={Strategic Analysis Report R-20-1971},
publisher={Gartner},
url={https://www.gartner.com/en/documents/396330/understanding-gartner-s-hype-cycles},
}

@article{PIIS2589004220307070.pdf,
title={Who Gets Credit for AI-Generated Art?},
author={Ziv Epstein and
Sydney Levine and
David G. Rand and
Iyad Rahwan},
year={2020},
journal={iScience},
volume={23},
doi={10.1016/j.isci.2020.101515},
}

@article{ncw_89.pdf,
  doi = {10.48550/ARXIV.2112.03111},
  author = {Rostamzadeh, Negar and Denton, Emily and Petrini, Linda},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Computers and Society (cs.CY), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Ethics and Creativity in Computer Vision},
  publisher = {arXiv},
  year = {2021},
}



@article{AIartworkvsHumanartwork.pdf,
author = {Hong, Joo-Wha and Curran, Nathaniel Ming},
title = {Artificial Intelligence, Artists, and Art: Attitudes Toward Artwork Produced by Humans vs. Artificial Intelligence},
year = {2019},
issue_date = {April 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2s},
issn = {1551-6857},
doi = {10.1145/3326337},
abstract = {This study examines how people perceive artwork created by artificial intelligence (AI) and how presumed knowledge of an artist's identity (Human vs. AI) affects individuals’ evaluation of art. Drawing on Schema theory and theory of Computers Are Social Actors (CASA), this study used a survey-experiment that controlled for the identity of the artist (AI vs. Human) and presented participants with two types of artworks (AI-created vs. Human-created). After seeing images of six artworks created by either AI or human artists, participants (n = 288) were asked to evaluate the artistic value using a validated scale commonly employed among art professionals. The study found that human-created artworks and AI-created artworks were not judged to be equivalent in their artistic value. Additionally, knowing that a piece of art was created by AI did not, in general, influence participants’ evaluation of art pieces’ artistic value. However, having a schema that AI cannot make art significantly influenced evaluation. Implications of the findings for application and theory are discussed.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = {jul},
articleno = {58},
numpages = {16},
keywords = {human-machine communication, human-computer interaction, schema theory, Artificial intelligence, creativity, CASA, art}
}


@article{EDT,
title = {Incorporating trust-in-technology into Expectation Disconfirmation Theory},
journal = {The Journal of Strategic Information Systems},
volume = {23},
number = {2},
pages = {128-145},
year = {2014},
issn = {0963-8687},
doi = {10.1016/j.jsis.2013.09.001},
author = {Nancy Lankton and D. Harrison McKnight and Jason Bennett Thatcher},
keywords = {Expectation Disconfirmation Theory, Trust, Technology trust, IT continuance},
abstract = {Continued use of strategic information systems is not always a given. This study proposes that users’ trust in the system may influence their satisfaction and continuance intention. While trust has been found to have strategic implications for understanding consumers’ technology usage, relatively little research has examined how trust’s influence operates over time. To gain insight into trust’s influence on strategic system usage over time and to explain how trust relates to satisfaction and continuance intention, we integrate trust-related constructs with the Complete Expectation Disconfirmation Theory (EDT) Model. Our results demonstrate that trust plays a central role in the EDT process and that the EDT process helps explain trust’s role more completely. The study shows that technology trusting expectations influence trusting intention through performance, disconfirmation, and satisfaction. We also show that technology trusting intention adds predictive power to EDT’s satisfaction construct as together they predict usage continuance intention. For research, our results provide a strong combined EDT and trust theory base for future studies that examine expectation management and system development projects. For practice, our study informs systems implementation strategies for technologies that have fewer human-like characteristics and more technology-like characteristics. Our findings underscore that managers need to adopt an EDT process-based view when seeking to build trust, satisfaction, and continuance intention in strategically important information systems.}
}


@misc{dalle2,
  doi = {10.48550/ARXIV.2204.06125},
  author = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Hierarchical Text-Conditional Image Generation with CLIP Latents},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{galactica.pdf,
  doi = {10.48550/ARXIV.2211.09085},
  author = {Taylor, Ross and Kardas, Marcin and Cucurull, Guillem and Scialom, Thomas and Hartshorn, Anthony and Saravia, Elvis and Poulton, Andrew and Kerkez, Viktor and Stojnic, Robert},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Galactica: A Large Language Model for Science},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}


@report{RAND_RR2237.pdf,
title={Russian Social   Media Inﬂuence. Understanding Russian Propaganda  in Eastern Europe},
author={Todd C. Helmus and Elizabeth Bodine-Baron and Andrew Radin and  
Madeline Magnuson and Joshua Mendelsohn and William Marcellino and 
Andriy Bega and Zev Winkelman},
publisher={Rand Corporation},
year={2018},
}


@misc{metafail,
url={https://www.technologyreview.com/2022/11/18/1063487/meta-large-language-model-ai-only-survived-three-days-gpt-3-science/},
author={Heaven, Will Douglas},
year={2022},
title={Why Meta's latest large language model survived only three days online},
}



@article{Lewandowsky.2017.JARMAC.pdf,
title = {Beyond Misinformation: Understanding and Coping with the ``Post-Truth'' Era},
journal = {Journal of Applied Research in Memory and Cognition},
volume = {6},
number = {4},
pages = {353-369},
year = {2017},
issn = {2211-3681},
doi = {10.1016/j.jarmac.2017.07.008},
author = {Stephan Lewandowsky and Ullrich K.H. Ecker and John Cook},
keywords = {Misinformation, Fake news, Post-truth politics, Demagoguery},
abstract = {The terms “post-truth” and “fake news” have become increasingly prevalent in public discourse over the last year. This article explores the growing abundance of misinformation, how it influences people, and how to counter it. We examine the ways in which misinformation can have an adverse impact on society. We summarize how people respond to corrections of misinformation, and what kinds of corrections are most effective. We argue that to be effective, scientific research into misinformation must be considered within a larger political, technological, and societal context. The post-truth world emerged as a result of societal mega-trends such as a decline in social capital, growing economic inequality, increased polarization, declining trust in science, and an increasingly fractionated media landscape. We suggest that responses to this malaise must involve technological solutions incorporating psychological principles, an interdisciplinary approach that we describe as “technocognition.” We outline a number of recommendations to counter misinformation in a post-truth world.}
}


@book{Charmaz,
title={Constructing Grounded Theory },
year={2006},
author={Kathy Charmaz},
publisher={SAGE Publications Ltd.},
address={},
}


@report{automation.pdf,
title={The Risk of Automation for Jobs in OECD Countries: A Comparative
Analysis},
author={Arntz, M. and T. Gregory and U. Zierahn},
year={2016},
doi={10.1787/5jlz9h56dvq7-en},
howpublished={OECD Social, Employment and Migration Working Papers, No. 189},
numpages={34},
publisher={OECD Publishing},
address={Paris, France},
}



@inproceedings{ICCC_2021_paper_50.pdf,
title={Generative Search Engines: Initial Experiments},
author={Simon Colton and Amy Smith and Sebastian Berns and Ryan Murdock and Michael Cook},
year={2021},
booktitle={Proceedings of the 12th International
Conference on Computational Creativity},
series={ICCC ’21},
pages={237--246},
}


@misc{2205.09911.pdf,
  doi = {10.48550/ARXIV.2205.09911},
  author = {Narayan, Avanika and Chami, Ines and Orr, Laurel and Arora, Simran and Ré, Christopher},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Databases (cs.DB), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Can Foundation Models Wrangle Your Data?},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Zero v1.0 Universal}
}





@article{Grand_Challenges,
author = {Ozlem Ozmen Garibay and Brent Winslow and Salvatore Andolina and Margherita Antona and Anja Bodenschatz and Constantinos Coursaris and Gregory Falco and Stephen M. Fiore and Ivan Garibay and Keri Grieman and John C. Havens and Marina Jirotka and Hernisa Kacorri and Waldemar Karwowski and Joe Kider and Joseph Konstan and Sean Koon and Monica Lopez-Gonzalez and Iliana Maifeld-Carucci and Sean McGregor and Gavriel Salvendy and Ben Shneiderman and Constantine Stephanidis and Christina Strobel and Carolyn Ten Holter and Wei Xu},
title = {Six Human-Centered Artificial Intelligence Grand Challenges},
journal = {International Journal of Human–Computer Interaction},
volume = {39},
number = {3},
pages = {391-437},
year  = {2023},
publisher = {Taylor & Francis},
doi = {10.1080/10447318.2022.2153320},
}


@book{arieti,
    title={Creativity: The Magic Synthesis},
    author={Arieti, Silvano},
    year={1976},
    publisher={Basic Books},
    address={New York, NY},
}

@report{PI_2018.12.10_future-of-ai_FINAL1.pdf,
    author={Janna Anderson and Lee Rainie and Alex Luchsinger},
    title={Artiﬁcial Intelligence and the Future of Humans},
    year={2018},
    publisher={Pew Research Center},
}


