%%
%% This is file `sample-manuscript.tex',
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
\documentclass[manuscript,screen,authorversion]{acmart}% anonymous

\newcommand{\todo}[1]{{\leavevmode\color{black}#1}}
\newcommand{\ok}[1]{{\leavevmode\color{black}#1}}
\newcommand{\chatgpt}[1]{{\leavevmode\color{black}#1}}

% remove acm reference format
\settopmatter{printacmref=false}

\usepackage{numprint}
\nprounddigits{5}
\npdecimalsign{.}
\npthousandsep{}
\npfourdigitnosep

\usepackage{caption}
\usepackage{subcaption}
% \usepackage{framed}

\setcopyright{rightsretained}
\copyrightyear{2023}
\acmYear{2023}
\acmDOI{}% XXXXXXX.XXXXXXX
\acmConference[
Generative AI and HCI, CHI '23 Workshop]{GenAI Workshop 2023}{April 28}{2023}

%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
% \acmPrice{15.00}
% \acmISBN{978-1-4503-XXXX-X/18/06}

%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%\citestyle{acmauthoryear}


\begin{document}



% We did an online survey study on text-to-image generation. The questions included
% - people's understanding of text-to-image generation
% - application areas of text-to-image generation
% - current and future professional importance of the emerging technology to participants
% - the personal and societal dangers and risks of text-to-image generation
% - other questions related to ethics, copyright, and ownership of synthetic media
% Please give a some ideas for the title of this paper.

% \chatgpt{
%     "Text-to-Image Generation: Understanding, Applications, and Implications"
%     "Exploring the Landscape of Text-to-Image Generation"
%     "A Comprehensive Study on Text-to-Image Generation and its Ethical Considerations"
%     "Text-to-Image Generation: Perceptions and Realities"
%     "Balancing the Benefits and Risks of Text-to-Image Generation"
%     "Text-to-Image Generation: A Critical Analysis of Its Uses and Consequences"
%     "The Future of Text-to-Image Generation: Insights from a Survey Study"
%     "Navigating the Ethics and Risks of Text-to-Image Generation"
%     "Exploring the Opportunities and Challenges of Text-to-Image Generation".

    % "Text-to-Image Generation in the Digital Age"
    % "From Text to Image: Understanding the Possibilities and Limits"
    % "The Power and Perils of Text-to-Image Generation"
    % "Exploring the Impact of Text-to-Image Generation on Society"
    % "Navigating the Ethics of Text-to-Image Generation"
    % "Text-to-Image Generation: Opportunities and Challenges"
    % "Synthetic Images: A Study on Text-to-Image Generation"
    % "The Human Side of Text-to-Image Generation"
    % "Text-to-Image Generation: Transforming Communication and Creativity".

% }

\title{\chatgpt{%
Text-to-Image Generation: Perceptions and Realities}}%
% Text-to-Image Generation: A Critical Analysis of Its Uses and Consequences
% Navigating the Ethics and Risks of Text-to-Image Generation

\author{Jonas Oppenlaender}
% \authornote{This submission to the GenAI workshop at CHI '23 was not written with AI. However, it will be copy-edited with ChatGPT before camera-ready (provided that ChatGPT is still available by then).}
\email{jonas.x1.oppenlander@jyu.fi}
% \orcid{1234-5678-9012}
% \authornotemark[1]
\affiliation{%
  \institution{University of Jyv\"askyl\"a}
  \city{Jyv\"askyl\"a}
  \country{Finland}
  \postcode{40014}
}

% \author{ChatGPT}
% % % \authornotemark[1]
% \affiliation{%
%   \institution{OpenAI}
% % %   \streetaddress{P.O. Box 1212}
%   \city{San Francisco}
%   \state{CA}
%   \country{United States}
% }

\author{Aku Visuri}
\email{aku.visuri@oulu.fi}
\affiliation{%
  \institution{University of Oulu}
  \city{Oulu}
  \country{Finland}
  \postcode{90570}
}

\author{Ville Paananen}
\email{ville.paananen@oulu.fi}
\affiliation{%
  \institution{University of Oulu}
  \city{Oulu}
  \country{Finland}
  \postcode{90570}
}

\author{Rhema Linder}
\email{rlinder@utk.edu}
\affiliation{%
  \institution{University of Tennessee}
  \city{Knoxville}
  \country{United States}
  \postcode{37996}
}

\author{Johanna Silvennoinen}
\email{johanna.silvennoinen@jyu.fi}
\affiliation{%
  \institution{University of Jyv\"askyl\"a}
  \city{Jyv\"askyl\"a}
  \country{Finland}
  \postcode{40014}
}

%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Oppenlaender et al.}


\begin{abstract}%
Generative AI is an emerging technology that will have a profound impact on society and individuals.
    Only a decade ago, it was thought that creative work would be among the last to be automated -- yet today, we see AI encroaching on creative domains. % that were previously considered as being `safe' from AI automation.
In this paper, we present the key findings of a survey study on people's perceptions of text-to-image generation.
We touch on participants' technical understanding of the emerging technology, their ideas for potential application areas, as well as concerns, risks, and dangers of text-to-image generation to society and the individual.
% We find while participants were aware of the risks and dangers of the technology.
% 1) only few participants thought there was a risk to them personally
% 2) those who had tried the technology rated the future importance of the technology lower than those who had not tried it.
\chatgpt{The study found that participants were aware of the risks and dangers associated with the technology, % \todo{to practitioners in the creative industry},
but only few participants considered the technology to be a risk to themselves. Additionally, those who had tried the technology rated its future importance lower than those who had not.}
\end{abstract}%

% http://dl.acm.org/ccs.cfm
% \begin{CCSXML}
% <ccs2012>
%   <concept>
%       <concept_id>10010147.10010178.10010179.10010182</concept_id>
%       <concept_desc>Computing methodologies~Natural language generation</concept_desc>
%       <concept_significance>500</concept_significance>
%       </concept>
% %   <concept>
% %       <concept_id>10010147.10010178.10010216.10010218</concept_id>
% %       <concept_desc>Computing methodologies~Theory of mind</concept_desc>
% %       <concept_significance>100</concept_significance>
% %       </concept>
%  </ccs2012>
% \end{CCSXML}
% \ccsdesc[500]{Computing methodologies~Natural language generation}
% \ccsdesc[100]{Computing methodologies~Theory of mind}

\keywords{text-to-image, generative AI, generative deep learning, AI co-creation, computational creativity}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% ====================
\section{Introduction}%
% ====================
%
% Generative artificial intelligence (GenAI) has made significant progress in recent years. Text-to-image generation has reached a level of sophistication where the outputs produced are often indistinguishable from those produced by humans. This has led to the potential for significant impact in a variety of fields.
% In particular the creative domain is set to be affected by GenAI.
% Only a decade ago, the going opinion was that knowledge work and creative work were the last ones to be automated \cite{x}.
% Today, we see the opposite come true.

%%% Please rewrite this text so that it sounds more scientific:
\chatgpt{Recent advancements in generative artificial intelligence (GenAI) have yielded significant progress in various domains. %, particularly in text-to-image generation.
This has the potential to greatly impact a wide range of industries, particularly in the creative domain.
}%
%
% We investigated how people perceive the emerging technology of text-to-image generation.
% Our survey-based inquiry included both participants with no experience with text-to-image generation, and participants with self-rated experience.
% In this paper, we report some of the findings.
% However, we want to particularly report our experiences with this investigation, in particular the challenges that we faced.
%
%
\chatgpt{%
Only a decade ago, the general consensus was that knowledge and creative work would be among the last to be automated \cite{The_Future_of_Employment.pdf,automation.pdf}. However, current developments in GenAI have} % proven this notion to be false.
turned this prediction on its head.
Progress in generative AI has exploded in recent years and we increasingly see GenAI being applied in creative domains, such as arts and research.
One particularly popular domain is text-to-image generation,
as evident in generative systems that can synthesize images from text prompts, such as Midjourney \cite{Midjourney}, Stable Diffusion \cite{stablediffusion}, and DALL-E 2 \cite{dalle2}.
Outputs from state-of-the-art diffusion models are often indistinguishable from those generated by humans \cite{creativity,prompt-engineering}.
% Midjourney is now the largest Discord community, and applications of generative AI are more and more
    % Systems for music can generation produce songs, including coherent lyrics \cite{jukebox,soundraw,harmonai,musenet}.
    % In academia, Galactica \cite{galactica.pdf} by Meta (formerly Facebook) promised % (and ultimately failed)
    % to produce research papers with citations \cite{metafail}.
% It seems almost magical \cite{money}, akin to what Arieti called the ``magic synthesis'' (as a synonym for creativity) \cite{arieti}.
% \chatgpt{Generative AI can appear almost magical, reminiscent of Arieti's concept of ``magic synthesis,'' which he used as a synonym for creativity \cite{arieti}.}
Some call this development ``AI's Jurassic Park moment'' \cite{Marcus.pdf} -- an adapt-or-die moment that could potentially result in massive job loss across many sectors.
However, many people are still oblivious to the generative powers of state-of-the-art systems.


%%% Please rewrite this text so that it sounds more scientific, but avoid jargon:
In October 2022, we conducted a survey study on the 
\chatgpt{%
perception of the text-to-image generation technology among different groups of individuals, including artists as well as people with no prior experience and those who self-reported having experience with the technology.}
The survey focused on people's understanding of the emerging technology, its potential uses, and the dangers of the technology for the individual and society.
We present the key findings of the survey in this paper.

% \todo{
% We close with a self-reflective account of two challenges that we experienced in this survey study.
% }

% Text-to-image generation is an emerging technology, and as such, only few people had tried it at the time of conducting the study.
% % \chatgpt{we also discuss the challenges encountered during the course of the investigation and the methods implemented to overcome them.}
% Our main contribution is a self-reflective account of our own experience with this study.
% We discuss how some participants starkly misjudged their own experience with the technology.}
% \todo{
% Implications for future data collection efforts
% }




% % % ====================
\section{Related Work}
% % % ====================
% \todo{some related work on perception of dangers of text-to-image generation}


% \citeauthor{978-3-030-16667-0_3.pdf}: Autonomy, Authenticity, Authorship and Intention in Computer Generated Art
% \cite{978-3-030-16667-0_3.pdf}

% \citeauthor{AIartworkvsHumanartwork.pdf}: Artificial Intelligence Art: Attitudes and Perceptions Toward Human Versus Artificial Intelligence Artworks
% \cite{AIartworkvsHumanartwork.pdf}

% \citeauthor{3334480.3382892.pdf}: Al-generated vs. Human Artworks. A Perception Bias Towards Artificial Intelligence?
% \cite{3334480.3382892.pdf}

% \citeauthor{ncw_89.pdf}: Ethics and Creativity in Computer Vision
% \cite{ncw_89.pdf}

% \citeauthor{PIIS2589004220307070.pdf}:
% who should be credited for AI-generated art; tool versus agent
% \cite{PIIS2589004220307070.pdf}


\chatgpt{%
Related research has explored various aspects of artificial intelligence and its use in visual art.
These studies have focused on understanding the perception and attitudes towards art generated by AI \cite{AIartworkvsHumanartwork.pdf}, authorship, agency, and intention in AI-generated art \cite{978-3-030-16667-0_3.pdf}, and the potential bias towards such art \cite{3334480.3382892.pdf}.
Additionally, \citeauthor{ncw_89.pdf} discussed the ethical implications of AI in the creative application of computer vision % creation of art
\cite{ncw_89.pdf} and
\citeauthor{PIIS2589004220307070.pdf} discussed the question of who should be credited for AI-generated works \cite{PIIS2589004220307070.pdf}.
% These studies provide valuable insights into the complex and evolving relationship between AI and art.
Our paper provides a novel empirical perspective on this related work.
}%



% % ====================
\section{Method}%
% % ====================

In autumn of 2022, we invited visitors to complete an online survey at the Researchers Night, a local annual event in which researchers present their research to the public.
The questionnaire consisted of 26 questions, including three open-ended items.
Participation was incentivized with a raffle for three Amazon vouchers, each worth 30 EUR.

We qualitatively analyzed the responses to the three open-ended survey items using in vivo coding \cite{Charmaz}. The first author read and then iteratively coded all responses.
Multiple codes were assigned, if needed, and iteratively improved by % frequently
visualizing the codes in histogram charts.
Due to the manageable amount of data and straight-forward answers, the coding did not require multiple raters and an analysis of inter-rater reliability \cite{McDonald_Reliability_CSCW19.pdf}.


% % ====================
\section{Participants}%
% % ====================

\begin{comment}
In total, 35 participants completed the online survey.
Participants were aged between 19 to 50 ($M=33.66$ years, $SD=9.27$ years)
and had a diverse educational backgrounds,
%
\chatgpt{%
with the most common being
computer science, literature, and information systems.
Other represented fields included psychology, healthcare, economics, mathematics, physics, and various arts and humanities disciplines.
The highest level of degree held by the participants was a Bachelor's degree (14 participants), followed by Master of Science (10 participants) and Master of Arts (4 participants). Three participants held a doctoral degree and one participant held no academic degree.
}
The sample included 24 enrolled students.


Twelve participants (34.3\%) responded they had used text-to-image generation before.
We aimed to measured the experience of these participants in three ways.
First, participants were asked which systems they had used (from a list of systems).
    DALL-E Mini/Craiyon was most popular among these participants ($n=7$), followed by DALL-E 2 ($n=5$), Dream/Wombo ($n=3$), and Stable Diffusion ($n=2$).
    One participant each had used Midjourney, Disco Diffusion, and Art Breeder.
Second, participants were asked how often they use text-to-image generation.
    Interestingly, all twelve participants replied they had ``rarely'' used text-to-image generation (on a scale from ``Never'' to ``Multiple Times a Day'').
Last, we asked participants to estimate how many prompts for text-to-image generation they had written.
    Participants had written on average an estimated 20 prompts ($SD\approx22$ prompts, $Max=80$ prompts).
All participants can therefore be considered being inexperienced with the technology.
Participants who had tried the technology were, on average, significantly younger than those who had not tried the technology
($p=0.021$).

We asked participants whether they considered themselves as being artists.
Ten participants responded positively to this question.
All ten participants had created watercolor, acrylic or oil paintings. Other art created by participants included digital paintings, drawings, and writing. Less common art forms included clothing, music, handicrafts, and food art. % (cakes).%
%
% Mean age of artists: 32.3
% Mean age of non-artists: 34.2
% p = 0.591
\end{comment}


%%% Below is a text from a scientific article. Please shorten this text. Use scientific language, but avoid jargon.
\chatgpt{%
35 participants (P1--P35, aged 19 to 50, $M=33.7$ years, $SD=9.3$ years) completed the online survey. 
%Their ages ranged from 19 to 50 with an average age of 33.7 years. 
Participants had diverse educational backgrounds, the most common being computer science, literature, and information systems. Fourteen participants held a Bachelor's degree, 10 held a Master of Science, 4 held a Master of Arts, 3 held a doctoral degree, and one held no academic degree. Twenty-four participants were students.
A third (34.3\%) of the participants had used text-to-image generation before. The most popular system used was DALL-E Mini/Craiyon (used by 7 participants), followed by DALL-E 2 (5 participants), Dream/Wombo (3 participants), and Stable Diffusion (2 participants). Participants estimated they had written an average of 20 prompts ($Max=80$, $SD=22$).
Participants were, therefore, inexperienced with the emerging technology. Participants who had tried text-to-image generation were younger than those who had not tried the technology ($p<0.05$). Ten participants considered themselves artists and had created paintings, digital art, drawings, writing, and other forms of art.%
}%
%
%
%
% ====================
\section{Key Findings}%
% ====================
%
%
% % ====================
\subsection{Understanding of Text-to-image Generation and Application Areas of the Emerging Technology}%
% % ====================
%
% Overall, participants had a limited understanding of how the technology works % , with most of them relating it to image retrieval and combining existing images.
Most participants did not have a strong understanding of how text-to-image generation works.
In their description of the technology, all but four participants did not distinguish between training and inference (i.e., image generation).
Participants most often related the technology to image retrieval, followed by combining or mixing existing images (see \autoref{fig:working}).
%
% Creative areas were the most popular potential application areas for the technology.
Creative areas dominated when it comes to participants' thoughts about potential application areas for text-to-image generation (see \autoref{fig:application}).
Participants thought the technology was % perfectly
suited for creating artworks, illustrations, and other visual media.
These could be applied in brainstorming or product development, but also marketing and design.
The entertainment industry was also seen as an application area, for instance to make animations and games.
The technology would also make a fun pass-time, according to participants.
%
Less common, but still interesting, application areas included therapy, education, journalism, and criminology \textit{``to reconstruct crime scenes''} (P33).

% therapy:
    % The potential of these systems is infinite. They could be used in schools to aid teaching, in therapy, to speed up design processes such as games, etc.(P31)

% education:
%     They could also be used probably in education, as pictures are many cases more effective way to describe things that words. (P24)
%     They could be used in schools to aid teaching (P31)
%     They can be used as educational tools too, inspiring kids, giving ideas. (P1)
    
%     cheaper AI based art is ultimately limited in its aesthetics. If e.g. school book visualizations are in the future bade like this, then it might lead to issues with visual literacy. (P)

% journalism:
%     The systems are capable of creating very specific images quickly, that you might not find in any stock photo website etc. This can be useful in many cases. I have already that these systems have been used to create images for news articles. I think that other possible applications can probably be found in similar fields to journalism that probably value quick receiving of images. (P16)
    
% criminology:
%         One participant 
%         ``In some cases the technology can be used to reconstruct e.g. crime scenes.'' (P33)



\begin{figure}[!htb]
\centering
\begin{subfigure}[b]{0.49\textwidth}
  \centering
  \includegraphics[width=.8\textwidth]{figures/working.png}
  \caption{Participants' understanding of text-to-image generation.}
  \label{fig:working}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.49\textwidth}
  \centering
  \includegraphics[width=.8\textwidth]{figures/application-area.png}
  \caption{Participants' thoughts on potential application areas.}
 \label{fig:application}
\end{subfigure}%
  % \caption{Participants' understanding of text-to-image generation (left) and thoughts on potential application areas of text-to-image generation (right).}%
  % \Description{A woman and a girl in white dresses sit in an open car.}%
\\
% \end{figure}
% \begin{figure}[!htb]%
% \centering%
% \vspace{.5\baselineskip}
\begin{subfigure}[b]{0.49\textwidth}%
     \centering
     \includegraphics[width=.82\textwidth]{figures/importance-experience.png}
     % \caption{}
     % \label{fig:importance:a}
     \\
     \includegraphics[width=.77\textwidth]{figures/importance-artist.png}
     \caption{Current and future professional importance of image generation for participants who did and did not try text-to-image generation before (top) and self-identified artists and non-artists (bottom), from 1 -- Not At All Important to 7 -- Extremely Important.}
     \label{fig:importance}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.49\textwidth}
     \centering
    \includegraphics[width=.85\textwidth]{figures/danger-highlevel.png}%
    \caption{Participants' concerns about text-to-image generation.}%
     \label{fig:dangers}%
\end{subfigure}
\caption{%
\chatgpt{%
Key results of the study on participants' perceptions of text-to-image generation, including their understanding of the technology, potential applications, perceived importance in their profession, and concerns.%
% The subfigures showcase the participants' views on these various aspects, including differences in importance between those who have tried the technology and those who have not, as well as between self-identified artists and non-artists.
}%
}%
\Description{Key results of the study on participants' perceptions of text-to-image generation, including their understanding of the technology, potential applications, perceived importance in their profession, and concerns.}%
\label{fig:importancedangers}%
\end{figure}%



% % ====================
\subsection{Criticisms and Concerns about Text-to-image Generation}%
% % ====================

\subsubsection{Professional importance of text-to-image generation}
% To get a feeling about the importance of text-to-image generation for participants, we asked participants to rate the importance of this technology for their current and future professional career.
Most participants responded that text-to-image generation is currently not important for their profession, but will play an increasingly important role in the future (see \autoref{fig:importance}).
Interestingly, those who had tried image generation before found text-to-image generation not as important for their professional future, as opposed to those who had not tried it before. This difference was significant ($p<0.05$) and not found among self-declared artists.





\subsubsection{Concerns about the emerging technology}
The majority of participants did not think that text-to-image poses a personal danger to themselves. But participants voiced many concerns about the effect of this emerging technology on society (see \autoref{fig:dangers}).
%
%
%%% fake news / misinformation -------------------------
The use of AI-generated imagery for opinion manipulation, fake news, and ``deep fakes'' was leading cause for concern.
Many participants warned that synthetic images could be spread naively (misinformation) or for malicious purposes (disinformation).
% \todo{more quotes?}
%
%
%%% job loss -------------------------
Another concern was unemployment due to increases in productivity.
   Participants mentioned that generative AI is cheaper and faster, and this could lead companies to not commission works from humans. % of human designers and artists.
Artists and designers were said to be particularly affected.
    % P1: \textit{``If I were an artist, I'd be worried that might put me out of business.''}
% Participants voiced concerns that the technology could lead to unemployment of artists and designers. %  if companies stop hiring or commissioning works in favor of ``artists and designers who can use good search words to make an AI generated image'' (P7).
%%% copyright -------------------------
Related to the potential loss of jobs, many participants noted that text-to-image generation operates in a legal gray zone with copyright infringement being one major concern.
    P15, for instance, mentioned that some \textit{``people have directly used the artists name in the prompt to get an image to resemble the artists work as much as possible [without consent].''}
As potential long-term effect, some participants mentioned there could be a loss of appreciation for artists and their work. % (e.g. P16)
The synthetic images could \textit{``lessen the importance of the creator and the creative act''} (P4).
Artists, \textit{``who already suffer from poor income and low appreciation''} (P22), would be particularly vulnerable.
% \todo{more quotes?}

%%% effect on culture and individuals -------------------------
Some participants mentioned the potential effects of text-to-image generation on individuals and culture.
For the individual, the effects could include harm, such as depression and % other illnesses
other illnesses related to mental health.
The AI could be used to produce offensive, abusive, and inappropriate images that are \textit{``not sensitive to people beliefs''} (P3).
The harm could be accidental, such as the negative effects of accidental fame and leakage of private information, but also intentionally abusive, such as cyberbulllying. % (P22, P30).
% \todo{more quotes?}
As for society, several participants thought there could be a \textit{``decline in human creativity''} (P2, P23, P27).
    The technology \textit{``could curtain artist imagination, when an AI can create art better than humans''} (P3).
However, the AI was thought to be \textit{``ultimately limited in its aesthetics''} (P20). This low diversity in synthetic imagery could contribute to \textit{``narrow the viewpoint of the world''} if \textit{``a lot of images start to look the same''} (P15). % and
%%% bias -------------------------
Synthetic images could lead to a \textit{``biased and one-sided visual culture''} (P23).
% because of lack of diversity and the AI's ignorance of ethical sensitive
As P20 noted, generative AI \textit{``has a great danger of enforcing certain values''} by showing ``mainly white European bodies with certain aesthetics.''
    % ``AI images can also have a narrow viewpoint of the world and people. A lot of images start to look the same and a lot of people generated by AI resemble each other a lot. You don't see as many different faces and body types as you see in photography or art.'' (P15)
(P15).
The low diversity in synthetic imagery was seen to have a potentially negative impact on visual literacy if \textit{``school book visualizations are [made] in the future with AI''} (P20).
    % \textit{``AI based art is ultimately limited in its aesthetics. If e.g. school book visualizations are in the future bade like this, then it might lead to issues with visual literacy''} (P20).
As P26 put it, text-to-image generation is \textit{``a movement away from the things that make us human, e.g, human emotions being reflected in human-made art. The knock-on effects of unemployment, depression, cause by this lack of connection with human values and needs to create and be creative''} (P26).%
%
%
%
\begin{figure}[!htb]%
\centering%
% \vspace{.5\baselineskip}
\begin{subfigure}[b]{0.56\textwidth}%
     \centering%
     \includegraphics[width=.85\textwidth]{figures/ethicality.png}
     \caption{Rating of the ethicality of submitting a text-to-image artwork to an art fair on a Likert scale from 1 -- Not Ethical At All to 7 -- Highly Ethical.}
     \label{fig:disclosure}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.40\textwidth}
     \centering
     \includegraphics[width=.7\textwidth]{figures/copyright_versus_creator.png}
     \caption{Participants responses to the multiple-choice questions of ``who is the copyright holder and the creator?''}
     \label{fig:copyright_creator}
\end{subfigure}
\caption{Participants thoughts on the ethicality of labeling AI-created images (left) and copyright and creatorship (right).}
\Description{A woman and a girl in white dresses sit in an open car.}%
\end{figure}%
%
%
\subsubsection{Ethicality of disclosing AI generation.}%
% Forcing disclosure:
% yes: 19
% not sure: 10
% no: 6
About half of the participants ($n=19$; 54.3\%) were of the opinion that it should be disclosed when something was created with AI.
Ten participants had no strong opinion about this, and six participants (16.7\%) thought that AI-generated % synthetic
images do not need to be labeled as such.
However, when presented with the scenario of a person submitting a digital artwork to an art contest, participants thought that it was unethical to submit without disclosing that the image was created with AI (see \autoref{fig:disclosure}).
Not labeling a submission as created by AI was seen as equally unethical as submitting an artwork created from somebody else's prompt.


% ====================
\section{Discussion and Conclusion}%
% ====================

\chatgpt{%
Our survey study aimed to understand people's perceptions of text-to-image generation technology.
While participants did not see immediate harm for themselves, they had varied opinions on the implications of the technology for society.
% We found that participants were aware of the potential dangers and risks associated with the technology,
}%
It seems that when it comes to pinpointing the risks and dangers of text-to-image generation as an emerging technology, it was easier for participants to enumerate the potential problems of other people
    % (such as artists)
    as compared to self-reflectively analyzing the impact of 
    % introspective
    the technology on their own life.
% Our survey study revealed that many participants were aware of the dangers and risks of generative AI.
% Participants voiced specific concerns, such as bias inherent in generative AI, the potential loss of human values and creativity, and the potential abuse of generative AI for deep fakes, propaganda, and disinformation.
\chatgpt{%
% but only few participants considered it to be a personal risk to themselves.
% but most participants did not think that they were personally affected.
% most participants did not think that they were personally affected, but acknowledged that generative AI would play an increasingly important role in their professional life in the future.
Interestingly, participants who had tried the technology rated its future importance lower compared to those who had not tried it.
    This observation conforms with the general hype cycle of technology in which expectations of an emerging technology undergo a trough of disillusionment before the technology's potential is realized \cite{HYPECYCLE}.
% Concerns were raised about the professional importance of text-to-image generation and potential impacts on employment and privacy.
Our findings suggest that while there is some awareness of the emerging technology, more education and awareness is needed to help people understand the capabilities and potential implications of text-to-image generation and generative AI.
}%



% Interestingly, participants who had tried the technology thought less of it.
% Prior research has shown that people tend to overestimate the effect of technology in the short-run and underestimate it in the long run.
% Perhaps an inverse of Amara's law: participants tended to underestimate the short-term effects of generative AI for their individual work life and overestimated future effects.
% The expectation disinformation theory (EDT) model \cite{EDT} may also explain this observation.
%     The EDT model contrasts expectations (pre-exposure) with perceived performance (post-exposure).
    % "Postexposure can disconfirm technology expectations, which leads to usage satisfaction and continued use."
%%% The following text explains what the expectation disinformation theory is. Please rewrite the text for an academic article:
% \chatgpt{
%     The Expectation Disinformation Theory (EDT) may also offer an explanation for this phenomenon. This theory is founded on the comparison between pre-exposure expectations and post-exposure perceptions of performance of a technology.
%     % If post-exposure experience disconfirms the expectations that were previously held, it can result in heightened usage satisfaction and a likelihood of continued usage.
% }

% This poses challenges for researchers and carry implications for survey studies. For instance, one should carefully think phrasing survey questions


% Based on our experience with this study and a post-mortem analysis of the study, we reflect on two lessons learned:%
% \begin{itemize}%
% \item  \textit{Measuring participants' experience with the emerging technology:}
%     Originally, we had set out to compare experienced with non-experienced users of text-to-image generation.
%     This objective fell short, as we found that most participants had very little experience with text-to-image generation.
%     Asking ``have you used this technology before'' is not a way to measure experience with the technology.
%     Other measurements should be used, such as ...
% \item \textit{The dangers of the emerging technology:}
%     People did not see personal dangers, but had concerns for society.
%     Another interesting result of our study is that the majority of respondents did not see any personal dangers of the technology.
%     Participants had, however, varied opinions on the implications of the technology for society.
%     It is easier to find come up with effects on society than personal issues.
%     Implications for phrasing survey questions
% \end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{table}
%   \caption{Frequency of Special Characters}
%   \label{tab:freq}
%   \begin{tabular}{ccl}
%     \toprule
%     Non-English or Math&Frequency&Comments\\
%     \midrule
%     \O & 1 in 1,000& For Swedish names\\
%     $\pi$ & 1 in 5& Common in math\\
%     \$ & 4 in 5 & Used in business\\
%     $\Psi^2_1$ & 1 in 40,000& Unexplained usage\\
%   \bottomrule
% \end{tabular}
% \end{table}

% \begin{table*}
%   \caption{Some Typical Commands}
%   \label{tab:commands}
%   \begin{tabular}{ccl}
%     \toprule
%     Command &A Number & Comments\\
%     \midrule
%     \texttt{{\char'134}author} & 100& Author \\
%     \texttt{{\char'134}table}& 300 & For tables\\
%     \texttt{{\char'134}table*}& 400& For wider tables\\
%     \bottomrule
%   \end{tabular}
% \end{table*}


% \begin{figure}[h]
%   \centering
%   \includegraphics[width=\linewidth]{sample-franklin}
%   \caption{1907 Franklin Model D roadster. Photograph by Harris \&
%     Ewing, Inc. [Public domain], via Wikimedia
%     Commons. (\url{https://goo.gl/VLCRBB}).}
%   \Description{A woman and a girl in white dresses sit in an open car.}
% \end{figure}

%   \begin{teaserfigure}
%     \includegraphics[width=\textwidth]{sampleteaser}
%     \caption{figure caption}
%     \Description{figure description}
%   \end{teaserfigure}


%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
% \begin{acks}
% To Robert, for the bagels and explaining CMYK and color spaces.
% \end{acks}

%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{paper}


%%
%% If your work has an appendix, this is the place to put it.
% \appendix

\end{document}
\endinput
%%
%% End of file `sample-manuscript.tex'.
