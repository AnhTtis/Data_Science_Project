\section{Tried-and-Tested Workflows}
\label{apx:Workflow}
%
In this appendix, we describe 12 workflows for assessing the 12 criteria, respectively, outlined in the main body of the paper. In November 2021, we began to abstract our experience in designing glyphs into a set of criteria for analyzing the trade-offs among different criteria. We drew our experience from the previous practice in designing glyphs for different applications (including those reported in \cite{botchen2008action,Maguire:2012:TVCG,Legg:2012:CGF,Borgo:2013:STAR,Duffy:2015:TVCG,chung2015glyph,Chung:2016:CGF,legg2016glyph}) as well as our recent experience of designing glyphs for gait analysis and music analysis in undergraduate and doctoral projects. The workflows reported here reflect our experience of using the 12 criteria in comparing different glyphs designs since December 2022 when the first version of the 12 criteria was completed (archived as arXiv:2303.08554 in March 2023).  
We believe that the proposed criteria and the accompanying workflows will be evaluated and improved by the VIS community after the work has been tested, critiqued, and adopted or adapted by VIS practitioners. This will take some time (e.g., the first paper that reported the adoption of the nested model was published four years after the paper on the nested model). We hope that at some stage, a set of recommended workflows will emerge in the VIS community.

\reviseTVCG{``Multi-criteria decision analysis'' is a standard term for a methodology in social sciences. The term ``decision'' can be interpreted in many ways relevant to glyph designs, e.g.,
\begin{itemize}
    \item \textbf{Selective decision} --- Given $N$ design options at an intermediate design stage, the designer selects $K < N$ designs to be put forward to the next meetings with domain experts. Based on our experience of meeting domain experts for discussing design options, discussing 4 $\sim$ 8 design options seems to be relatively effective. Domain experts often prefer to make comments such as ``I like this better than that.'' Having too many design options may overwhelm the domain experts, especially with many similarly-looking designs, while having too few may hinder domain experts' ability to compare and often leads to a hesitant positive answer ``it seems OK''.
    %
    \item \textbf{Judgment decision} --- Given a new design proposed by one or a few designers, the designers themselves apply the scheme to the design to identify strengths and weaknesses of the design. Cognitively, the score sheets used for the MCDA enable external memorization for the judgment on different design criteria, where externalized information facilitates more effective communication among different designers.
    %
    \item \textbf{Initial Judgment decision} --- At an early design stage, we also found that comparing each proposed design with a baseline design (e.g., $n$ variables are encoded as $n$ bars around a circle) quickly using the 12 criteria is also highly effective for filtering out designs that overly in favor of some criteria but have major issues with other criteria. A few undergraduate students working on glyph-based visualization as their final year projects used this approach to learn and appreciate different design criteria.
\end{itemize}}

\reviseTVCG{It is possible that after the MCDA scheme has been deployed, many VIS designers may use the MCDA scheme to make other types of decisions.}

\reviseTVCG{In many design processes, there may be more than one designer or more than one assessor. As described in Section \ref{sec:Evaluation}, we have experienced two mechanisms for deriving the final scores for a design option when there are multiple assessors. It is possible that after the MCDA scheme has been deployed, many VIS designers may report their experience of using these two mechanisms and propose new mechanisms.}

In the next 12 subsections, we outline 12 workflows for the 12 criteria respectively. Following these, we summarize our general observations about these workflows in the final subsection. In these subsections, we refer to the person who assesses different glyph designs as a ``rater''. A rater may be the designer who wishes to compare a set of provisional designs to filter out a small set for further discussions with the potential users, or be a relatively independent VIS specialist for assessing different designs produced by others (e.g., in a training course).

Before diving into the details of each criterion, we have a few general recommendations:
%
\begin{enumerate}
    \item[R1.] It is important to read the definition of each criterion in Section \ref{sec:Scheme} carefully, rather than relying on a personal interpretation of the name of the criterion. As discussed in Appendix \ref{apx:Orthogonality}, there may not always be appropriate words in the dictionary to convey the definitions of the criteria in an orthogonal manner.
    %
    \item[R2.] When considering a glyph design, a rater should ideally see a few variable settings for the same design. For example, if a glyph encodes two data variables $d_1$ and $d_2$ where $d_1 \in \{1, 2, 3, 4, 5\}$  and $d_2 \in \{a, b, c, d\}$. The rater may observe a few instances, such as five glyphs for $(1, a)$, $(1, d)$, $(5, a)$, $(5, d)$, and $(3, b)$.
    %
    \item[R3.] When there are a number of data variables and each variable has a number of valid values, there will be too many instances for a rater to observe. One important practice is for the rater to imagine what a glyph may look like in other variable settings that are not available to view. This is mostly a practice issue rather than a skill issue. Many visualization researchers and practitioners are often in a situation where one is given some data, and is asked to produce a visualization for the given data. On the other hand, when one is designing a system for handling dynamic data, one has to imagine different scenarios of the data that has not yet become available. When we design and evaluate glyphs, we must get into the habit of anticipating different scenarios, i.e., different variable settings.
\end{enumerate}

% Here we give a suggested procedure that a novice rater may follow to make evaluations on the twelve criteria. Following this procedure will allow the evaluation to meet a fair quality. For more experienced raters, reasonable simplification may applied to some part of the standard procedure as long as it doesn't compromise the quality of the evaluation.

% ---------------------
\subsection{Typedness}
\label{apx:Typedness}
%
In the process for designing a glyph to encode a small number of data variables, a rater may wish to assess each design directly using a Type D score directly. However, when the number increases, the rater could easily overlook some variables. By listing and scoring all variables to produce Type A scores first, e.g., using a spreadsheet, the explicit scoring sheet serves as a form of external memorization, which also happens to be a merit of visualization. The basic steps are:

\begin{enumerate}
    \item[1.] Identify $n$ data variables to be encoded, together with the visual identities of these variables. For the time being, we consider the identities as the valid values of a single nominal variable. Later, we will discuss these identities further.
    \item[2.] For each data variable, determine its type (i.e., nominal, ordinal, ratio, or interval).
    \item[3.] For each data variable, determine the KOPs (Bertin's kinds of perception) required by the variable, resulting in applicable KOPs (AKOPs).
    \item[4.] For each data variable, check if the visual encoding is appropriate, and assign a score based on the five levels defined in Section \ref{sec:Typedness}.
    \item[...] Repeat steps 2$\sim$4 for all $n+1$ variables.
    \item[fin.] Derive a type D score by calculating the average of the $n+1$ Type A scores. Here ``fin.'' is short for ``finally'', and it is also used in the other workflows in this appendix.
\end{enumerate}

Table \ref{tab:BertinKOP} lists Bertin's four kinds of perception (KOP) and their applicability to four types of variables \cite{bertin1983semiology}. 

\begin{table}[th]
    \centering
    %\small
    \caption{Bertin's four kinds of perception (KOP).}
    \begin{tabular}{ccccc}
        \textbf{KOP} & \textbf{Nominal} & \textbf{Ordinal}
        & \textbf{Interval} & \textbf{Ratio}\\
        \hline
        Associative  & required  & required & required & required \\
        Selective    & required  & required & required & required \\
        Ordered      & not req. & required & required & required \\
        Quantitative & not req. & not req. & required & required \\
        \hline
    \end{tabular}
    \label{tab:BertinKOP}
\end{table}

In many existing research papers on glyphs, the authors often focused the discussions on the variables of the data concerned, while the identities of these variables are commonly not discussed as a variable although they are always encoded one way or another. For example, in Design A by Maguire et al. \cite{Maguire:2012:TVCG} in Table \ref{tab:CaseStudy1}, the data variables S0, S6, S2 and S5 are identifiable by the locations of their visual channels as well as other visual variations, e.g., the outside shape for S0, filling color and shape for S6, the circular line type (always grey) for S2, and inside shape (always orange) for S2. 

Theoretically, given $n$ data variables, we can treat these identities as the $n$ valid values of a single nominal variable, which is encoded using multiple visual channels. We can thus assess it as a single variable. Alternatively we can break it down to $n$ identity variables and each identity variable is a binary variable, representing whether the corresponding data variable is visually distinguishable from others. Note that one should not confuse that the identity variable for a data variable with the associative and selective KOPs for the data variable. As shown in Table \ref{tab:BertinRating}, Bertin proposed to assess the KOPs of a variable (i.e., its visual encoding) independently from other variables. The assessment of an identity variable or variables has to consider the identity encoding for all $n$ data variables.  

% ---------------------
\subsection{Discernability}
\label{apx:Discernability}
%
Similar to the Typedness criterion, we recommend to assess each variable individually and then take the average of the obtained Type A scores to produce a Type D score.

It is important to stress that the goal of encoding a numerical variable is not for us to read the number from the visual encoding. As already evidenced in empirical studies (e.g., Kanjanabose et al. 2015, 10.1111/cgf.12638), for such a goal, data tables usually allow humans to perform their tasks more accurately and quickly than visual objects that encode numbers. As the visual objects in a glyph are much smaller than those in most visualization plots, over-focusing on the goal of reading numbers can only be a distraction from the real uses of glyphs.

Previous work on glyph-based visualization typically features applications where many glyphs are displayed in the same visualization (e.g., \cite{Legg:2012:CGF,Maguire:2012:TVCG,Duffy:2015:TVCG,chung2015glyph,legg2016glyph}), and the visualization tasks concerned include observing temporal changes in a group of glyphs, comparing different glyphs, identifying clusters and anomalies, and so on. Of course, to perform these tasks, one needs to be able to discern encoded values in each variable at a certain resolution. A glyph design ideally could achieve an optimal trade-off among (i) keeping its size reasonably small, (ii) enabling high discernability, and (iii) enabling the efficient performance of the tasks to be supported by glyph-based visualization. This trade-off is often characterized by the balance between a design with a large glyph and a design allowing many glyphs to be displayed simultaneously. Such trade-offs are encapsulated by the information-theoretical analysis of the cost-benefit of visualization (Chen and Golan 2016, 10.1109/TVCG.2015.2513410).

One important step in assessing the discernability of a variable is to determine the data values or data ranges that need to be discernable. For example,
%
\begin{itemize}
    \item \emph{Nominal and ordinal variables} -- If such a variable has $n$ valid values, must all $n$ values be discernable? When $n$ is a relatively large number (e.g., $n > 8$), would grouping be helpful or problematic for tasks such as observing temporal patterns or identifying anomalies?
    \vspace{-1mm}
    \item \emph{Interval and ratio variables} -- Such a variable usually has a large number of valid values within the range, or even an infinite number of values theoretically. Almost all visualization representations have to deal with the discernability issues, e.g., in a heat-map, is a pixel color distinguishable from another; in a line plot, is a point on a time series discernable from another point a few seconds later. In glyph-based visualization, typically the valid values are divided into $k$ sub-ranges, with different critical values falling into different sub-ranges. Even when continuous visual mapping is used (e.g., continuous line length or color-mapping), one needs to determine what level of perceptual discernability is required.  
\end{itemize}

When a data variable is encoded using multiple visual channels, the scoring focuses on the most discernable visual channel. For example, imagine that one needs to encode a real variable describing music volume. One decides that six levels are sufficient in a glyph design. One may encode six levels as five stacked color strips, i.e., no strip for 0, 1 strip for level 1, etc. The visual channels used include size of the colored area, aspect ratio of the colored area, location of the top strip, and strip counting. Among these visual channels, strip counting is most reliable in terms of discernability.

The main steps for assessing discernability are therefore as follows:

\begin{enumerate}
    \item[1.] Identify $n$ data variables to be encoded, together with the visual identities of these variables.
    \item[2.] For each data variable, determine its $k$ values (or $k$ groups of its values) that must be discernable. 
    \item[3.] For each data variable, compare all $k(k-1)/2$ pairs of values (or groups, ranges) to see if they can be differentiated at ease, and assign a score based on the five levels defined in Section \ref{sec:Discernability}.
    \item[...] Repeat steps 2$\sim$3 for all $n+1$ variables.
    \item[fin.] Derive a type D score by calculating the average of the $n+1$ Type A scores.
\end{enumerate}

% Ideally, to perform the evaluation of discernability, the visual instances of all possible pairs of values amongst the value ranges of the variable shall be examined. However, the emphasis of the operation varies slightly with the variable type.
% \begin{itemize}
%    \item \emph{Nominal variables} -- Examine all pairs of values to observe any difficulty in differentiating the instances.%
    % \vspace{-1mm}
%    \item \emph{Ordinal variables} -- Ideally, examine all pairs of values to observe differentiation obstacles. For this type of variables, the differentiation obstacles often happen between neighbouring values.
    % \vspace{-1mm}
%    \item \emph{Interval and ratio variables} -- For any value, find out the minimum discernable difference and potentially a minimum easily-discernable difference. the ranges of values that can be perceptually differentiable and differentiable at ease then can be found.
% \end{itemize}
% For interval and ratio variables, there is often a large number of value instances in the possible value range. In such situations, pairwise differentiability examination may be impractical. Thus, an alternative estimation method is suggested. After all value pairs with differentiation obstacles are found, give a score follow the instructions.

% ---------------------
\subsection{Intuitiveness}
\label{apx:Intuitiveness}
%
When we were formulating the MCDA scheme, we had extensive discussions on three related criteria, Intuitiveness, Learnability, and Memorability. Some aspects, such as the total number of data variables, which affect Learnability and Memorability, should ideally be assessed ``globally'' for the whole glyph. Some aspects, such as domain-specific convention for visual mapping (e.g., mapping music volume to height), should ideally be assessed ``locally'' for individual variables. Some aspects, such as visual metaphors, may need to be assessed both ``locally'' (e.g., the metaphoric visual encoding for a data variable) and ``globally'' (e.g., a metaphoric layout). If the ``local'' and ``global'' were mixed into the same criterion, it would be challenging to disentangle different aspects. On balance, we found that separating ``local'' and ``global'' assessment helps structure these aspects into different criteria, so the rater can be more focused in assessing each criterion. The main steps for assessing Intuitiveness are as follows:

\begin{enumerate}
    \item[1.] Identify $n$ data variables to be encoded, together with the visual identities of these variables.
    \item[2.] For each data variable, list the domain-specific conventions for encoding this variable.
    \item[3.] Determine if the proposed visual encoding features an additional visual metaphor. 
    \item[4.] For each data variable, consider the quality of the visual encoding in terms of domain-specific conventions (if any) and visual metaphor (if any), and assign a score based on the five levels defined in Section \ref{sec:Intuitiveness}.
    \item[...] Repeat steps 2$\sim$4 for all $n+1$ variables.
    \item[fin.] Derive a type D score by calculating the average of the $n+1$ Type A scores.
\end{enumerate}

\reviseTVCG{Consider the example in Fig. \ref{fig:Intuitiveness}, which was one of seven variables in the application reported by Maguire et al. \cite{Maguire:2012:TVCG}. It is variable $S5$, and it has seven categorical values, namely
(C1) input molecular part,
(C2) input cellular component,
(C3) input cell,
(C4) input tissue,
(C5) input organ,
(C6) input organism,
(C7) input population.
In the application concerned, these are seven levels of granularity associated with material entities in a biological workflow. The domain experts need to inspect many workflows routinely and there were tens of thousands of workflows in a data repository managed by these domain experts when the paper \cite{Maguire:2012:TVCG} was written. The designs in Fig. \ref{fig:Intuitiveness} and some other designs in \cite{Maguire:2012:TVCG} were all considered by Maguire et al., and many more designs were drawn on whiteboards at that time.
The scores in Fig. \ref{fig:Intuitiveness} were given by the authors of this work after one co-author recalled the discussions by  Maguire et al. when their work was carried out.}

\reviseTVCG{The domain-specific convention (DC) was considered as the seven levels, i.e., 1, 2, $\ldots$, 7. There was no standard visual representation for these seven levels, and photo-realistic images or fairly realistic sketches were often used as illustrations. As the first three rows all have the numbers 1, 2, $\ldots$, 7 encoded, they are labeled with cnDC (consistent with the DC), while the bottom three rows are labeled with inDC (inconsistent with the DC). The 2nd and 5th rows do not have any additional visual metaphor (AM), and we labeled them as noAM.}

\reviseTVCG{The 1st and 4th rows were considered by domain-expert co-authors of \cite{Maguire:2012:TVCG} as appropriate, and we labeled them as apAM. There were many versions of these, abstracted from some photo-realistic images or fairly realistic sketches used for illustrations. The design in the 5th row was first obtained, and the design in the 1st row was then derived by ``injecting'' numbers into the shapes in the 5th row.}

\reviseTVCG{The 3rd row attempted to create a visual metaphor from the numbers. It was considered too difficult to perceive the visual metaphors. Hence we labeled it inAM. Some visual metaphors (e.g., the smiley face and the cloud) in the 6th row were considered as inappropriate. The small and large circles were also considered to be metaphorically too close to each other. We thus labeled the design option as inAM. Note that the label inAM is assigned to a variable, rather than an individual categorical value. If one categorical value is encoded inappropriately, the encoding of the whole variable is considered as inAM.   
}

One reviewer of this paper drew our attention to a broad discussion on the assessment of intuitiveness (e.g., \cite{Naumann:2007:book,Reinhardt:2024:IJHCF}). We hope that future research in this broad context will help improve the intuitiveness assessment in the relatively small context of glyph design.  

% ---------------------
\subsection{Invariance: Geometry}
\label{apx:Geometry}
%
As discussed in Section \ref{sec:Geometry}, we recommend to evaluate this criterion with a Type D score directly as it is more efficient and effective to scale a glyph design as a whole object. Likely different raters will work out their own ways to scale a glyph being assessed. In the future, a software tool for glyph design will likely be equipped with scaling functions for evaluating geometrical invariance. With the current software provision, a glyph designer may draw glyphs by programming or using a drawing tool, such as Adobe Illustrator, Microsoft PowerPoint, or Apple Keynote. When glyphs are created by writing programs, the designer can easily draw glyphs with different scaling factors. When glyphs are created using drawing tools, one can also scale them using such tools. Using Microsoft PowerPoint as an example, after drawing a glyph, one may scale it with the following steps:

\begin{enumerate}
    \item[1.] Group all graphical elements together to form a single object.
    \item[2.] Copy the single object into the clipboard, and paste it as a picture (e.g., Enhanced Metafile or PNG). Make five ``picture'' copies in the same format. 
    \item[3.] Open the ``Drawing'' panel and the ``Size'' sub-panel, and make sure that ``Lock aspect ratio'' is on.
    \item[4a] If the glyph design is a circular design, change the widths of the five pictures to 4.37cm, 3.49cm, 2.62cm, 1.75cm, and 0.87cm respectively. One should see five glyphs of different sizes similar to the middle row of Fig. \ref{fig:Invariance}. See Section \ref{sec:Geometry} for the definitions of these values.
    \item[4b] If the glyph design is a rectangular design, determine if the width or height will be used to control the scaling. One normally selects whichever is shorter. Assuming the width is selected, change the widths of the five pictures to 3.09cm, 2.47cm, 1.85cm, 1.23cm, and 0.62cm respectively. One should see five glyphs of different sizes similar to the bottom row of Fig. \ref{fig:Invariance}. See Section \ref{sec:Geometry} for the definitions of these values.
    \item[5.] Align the five resized glyphs on the same slide.
    \item[6.] Draw a square of 4cm$\times$4cm (digilally) on the same slide, and zoom-in or out the slide to ensure that the square measures 4cm$\times$4cm (physically) on the monitor.
    \item[7.] Adjust the viewing distance from the eyes to the monitor to be 50cm.
    \item[fin.] Observe the glyphs carefully and assign a score based on the five levels defined in Section \ref{sec:Geometry}.
\end{enumerate}

% ---------------------
\subsection{Invariance: Colorimetry}
\label{apx:Colorimetry}
%
Most imaging processing tools and some drawing tools provide facilities to adjust the brightness and contrast of an image. However, they do not necessarily using the same formula. Hence there will be some inconsistency when different raters are using different tools. Even if all raters were using the same tool, the perceptual judgment among different people would not be consistent. Different monitors may also affect the perception. Ideally, there would be glyph design tools equipped with the same formula for adjusting the brightness and contrast of a glyph, and for assessing the levels of the chromatic and achromatic invariance algorithmically based on appropriate computer monitor data and human perception data collected from extensive empirical studies. It will likely take years or decades to achieve this. Until then, raters can make use of existing tools to evaluate this criterion. For example, one may use Microsoft PowerPoint by following a sequence of steps similar to those in Appendix \ref{apx:Geometry}.

\begin{enumerate}
    \item[1.] Group all graphical elements together to form a single object.
    \item[2.] Copy the single object into the clipboard, and paste it as a picture (e.g., Enhanced Metafile or PNG). Make 20 ``picture'' copies in the same format, and organize them into a $4 \times 5$ grid, i.e., four rows by five columns. 
    \item[3.] Open the ``Drawing'' panel and the ``Picture'' sub-panel.
    \item[4.] For the first column of glyph pictures, make no changes. For the second column of four glyphs, change the brightness ($B$) and contrast ($C$) as:
    \begin{itemize}
        \item $[B+10\% B,\; C+10\% C]$,
        \item $[B+10\% B,\; C-10\% C]$,
        \item $[B-10\% B,\; C+10\% C]$,
        \item $[B-10\% B,\; C-10\% C]$ 
    \end{itemize}
    For the third column, perform similar adjustment by replacing the previous $10\%$ with $20\%$. For the fourth column, perform similar adjustment by replacing the previous $20\%$ with $30\%$. For the fifth column, perform similar adjustment by replacing the previous $30\%$ with $40\%$.     
    \item[fin.] Compare the first column with each of the other four columns and assign a score based on the five levels defined in Section \ref{sec:Colorimetry}.
\end{enumerate}

% ---------------------
\subsection{Composition: Separability}
\label{apx:Separability}
%
As discussed in Section \ref{sec:Separability}, obtaining $n(n-1)$ pairwise Type B scores $s_\text{int}(\lambda_i, \lambda_j)$ would be time-consuming. Note that we consider that $(\lambda_i, \lambda_j)$ is a directional pair, as it is common that $s_\text{int}(\lambda_i, \lambda_j) \neq s_\text{int}(\lambda_j, \lambda_i)$. It is therefore more cost-effective to estimate Type C scores or a Type D score. Let us first describe how to estimate Type C scores $S_\text{int}(\lambda_i)$ that is defined by a $\max()$ formula, and we follow this by describing the methods for estimating $\max_\text{int}$ and $\text{avg}_\text{int}$, which determine a Type D score.

$\blacktriangleright$ Estimating $S_\text{int}(\lambda_i)$ --- Given $n$ visual channels in a glyph, $\lambda_1, \lambda_2, \ldots, \lambda_n$, $\max_\text{int}(\lambda_i)$ defines the maximal level of interference $\lambda_i$ that could receive from other visual channels. As $s_\text{int}(\lambda_i, \lambda_j)$ may take one of four possible values 1 (major), 0.1 (medium), 0.01 (minor), and 0 (none), $S_\text{int}(\lambda_i)$ can only take one of these four values. Hence to estimate $S_\text{int}(\lambda_i)$, the rater needs to identify a visual channel $\lambda_j$ ($j \neq i$) that may give most undesirable interference to $\lambda_i$. The rater needs to focus only on the worst case scenario, which is cognitively less demanding than, e.g., taking the average of all Type B scores for $s_\text{int}(\lambda_i, \lambda_j), j \neq i \land j = 1, 2, \ldots, n$.

$\blacktriangleright$ Estimating $\max_\text{int}$ --- For the whole glyph, the score $\max_\text{int}$ is also defined by a $\max()$ formula. Hence the rater only needs to consider the worst case scenario among $S_\text{int}(\lambda_1), S_\text{int}(\lambda_2), \ldots, S_\text{int}(\lambda_n)$. Hence obtaining $\max_\text{int}$ is not cognitively demanding. 

$\blacktriangleright$ Estimating $\text{avg}_\text{int}$ --- In Section \ref{sec:Separability}, $\text{avg}_\text{int}$ is defined with an average formula, which seems to be cognitively demanding to estimate if one were to use mental calculation. However, because Type C scores have only four levels, i.e., 1 (major), 0.1 (medium), 0.01 (minor), and 0 (none), we can use counting primarily to estimate $\text{avg}_\text{int}$ as shown in Algorithm \ref{alg:Separability}. This is not a complex algorithm because lines 1-8 are very similar to lines 10-17. There are only three pathways for running the algorithm, (i) lines 1-8, (i) lines 1, 2, 9-17, and (ii) lines 1, 2, 9-11, 18-20. Hence it is possible to run through this counting process in one's mind.

\begin{algorithm}[t]
  Count the number of 1's among $S_\text{int}(\lambda_1), S_\text{int}(\lambda_2), \ldots, S_\text{int}(\lambda_n)$, which is denoted as $K_a$\;
  \eIf{$K_a > 0$}{
    $T := K_a$\;
    Count the number of 0.1's among $S_\text{int}(\lambda_1), S_\text{int}(\lambda_2),$ $\ldots, S_\text{int}(\lambda_n)$, which is denoted as $K_b$\;
    \uIf{$K_b \in [5, 14]$}{
      $T := T + 1$\;
    } \uElseIf{$K_b \in [15, 24]$}{
      $T := T + 2$\;
    }
    \tcp{\small add more \textbf{else if} when there are 25+ channels}
  } {
  Count the number of 0.1's among $S_\text{int}(\lambda_1), S_\text{int}(\lambda_2),$ $\ldots, S_\text{int}(\lambda_n)$, which is denoted as $K_b$\;
  \eIf{$K_b > 0$}{
    $T := 0.1 K_b$\;
    Count the number of 0.01's among $S_\text{int}(\lambda_1), S_\text{int}(\lambda_2),$ $\ldots, S_\text{int}(\lambda_n)$, which is denoted as $K_c$\;
    \uIf{$K_c \in [5, 14]$}{
      $T := T + 0.1$\;
    } \uElseIf{$K_c \in [15, 24]$}{
      $T := T + 0.2$\;
    }
    \tcp{\small add more \textbf{else if} when there are 25+ channels}
  } {
    Count the number of 0.01's among $S_\text{int}(\lambda_1), S_\text{int}(\lambda_2),$ $\ldots, S_\text{int}(\lambda_n)$, which is denoted as $K_c$\;
    $T := 0.01 K_c$\;
    }
  }
  $\text{avg}_\text{int} := T / n$\;
\caption{Mental steps for estimating $\text{avg}_\text{int}$}
\label{alg:Separability}
\end{algorithm}

We describe below the steps for estimating and writing down Type C scores first, then estimating $\max_\text{int}$ and $\text{avg}_\text{int}$, and finally working out the Type D score.

\begin{enumerate}
    \item[1.] Select one visual channel $\lambda_i\; (i = 1, 2, \ldots, n)$ for assessment.
    \item[2.] Examine if $\lambda_i$ may potentially receive interference from any of the other channels. Estimate and write down $S_\text{int}(\lambda_i)$ as described earlier.
    \item[...] Repeat steps 1$\sim$2 for all $n$ variables.
    \item[fin.] Estimate $\max_\text{int}$ and $\text{avg}_\text{int}$ as described earlier. Assign a score based on the five levels defined in Section \ref{sec:Separability}.
\end{enumerate}

For an experience rater, because $\max_\text{int}$ and $\text{avg}_\text{int}$ can be estimated mentally, the rater can assign a Type D score directly. 

% \begin{enumerate}
%    \item[1.] Make a glyph object in the standard size with the variable values adjustable.
%    \item[2.] For the visual encoding of each variable, adjust the values of other variables within their possible value ranges and observe all possible interference that can be imposed on the current data channel.
%    \item[3.] Follow the formula given in the paper to calculate the overall scores.
% \end{enumerate}

% ---------------------
\subsection{Composition: Comparability}
\label{apx:Comparability}
%
Although Type B and Type C scores may seem applicable to this criterion, it is not as complex as it appears, because we only need to consider those pairs of data variables that need to be compared within a glyph. Given $n$ data variables, we can divide them into $k$ groups, each with $n_i\; (i=1,2,\ldots,k)$ number of variables. Therefore, $n_1 \geq 0$, $n_i > 0\; (i=2, \ldots, k)$, and $ n = n_1 + n_2 + \ldots + n_k$. Here the first group is designated as the non-comparable group, i.e., there is no requirement to compare the $n_1$ data variables in the first group. In many applications, $k$ is usually a small number. When $k = 1$, there is no need to compare any of the $n$ data variables. In this case, we do not assign any Type D score to this criterion, which will not contribute to the overall weighted average.

When $k > 1$, one needs examine $M$ pairwise relationships, where
\[
    M = \frac{n_2 (n_2 - 1) }{2} + \frac{n_3 (n_3 - 1) }{2} + \ldots + \frac{n_k (n_k - 1) }{2}
\]
\noindent As $k$ is usually a small number, the actual situations are not as complex as the impression given by the formula. The following two scenarios are relatively common.
%
\begin{itemize}
    \item[a.] Most data variables in a glyph need to be compared, e.g., a glyph encodes the average incomes of $n_2$ social groups. Most glyph designers are expected to notice the need to compare these $n_2$ variables, and likely they would have used the same type of visual channels to encode these variables. The rater's role is to check for outliers.
    \item[b.] There are a few small groups of data variables that need to be compared, e.g., in Duffy et al. \cite{Duffy:2015:TVCG}, there are two such groups, with two and three data variables respectively. Therefore $k=3, n=20, n_1 = 15, n_2 = 2, n_3 = 3$. The rater would need to assess $M=4$ pairwise relationships. This is not a big number.
\end{itemize}

We will describe the workflow below as if we use Type B scores. In practice, with the above common scenarios (a) and (b), the rater can easily obtain a Type D score directly.   

\begin{enumerate}
    \item[1.] Identify all $M$ pairs of comparable relationships that need to be assessed.
    \item[2.] For each pairwise relationship, determine if there is a \emph{Major}, \emph{Medium}, and \emph{Minor} obstacle to hinder the comparability.
    \item[...] Repeat step 2 for all $M$ pairs.
    \item[fin.] Transform the $M$ assessment to a score based on the five levels defined in Section \ref{sec:Comparability}.
\end{enumerate}

% \begin{enumerate}
%    \item[1.] Make a glyph object in the standard size with the variable values adjustable.
%    \item[2.] Identify all data channels in which comparison will be required.
%    \item[3.] Examine each pair of comparing data channels and evaluate the obstacle level in their value comparison.
%    \item[4.] Integrate the results from all comparing channel pairs and find the comparibility level that best describes.
% \end{enumerate}

% ---------------------
\subsection{Attention: Importance}
\label{apx:Importance}
%
The mathematical definition for this criterion in Section \ref{sec:Importance} is for ensuring long-term consistency of the definition itself. In the short-term, the community is still waiting for more empirical studies that can inform us about the amount of attention that different visual channels may attract. As shown in Appendix \ref{apx:Typedness}, many visual channels have not yet been adequately studied.

Nevertheless, we can conduct the assessment at a ``lower resolution'' relatively easily. If we consider only two levels of importance and two levels of attention, we can place $n$ data variables into $2 \times 2$ boxes:
%
\begin{center}
\begin{tabular}{|c|c|c|}
    \hline
    & \textbf{1. less important} & \textbf{2. more important} \\
    \hline
    \textbf{1. less preattentive} & $n_{1,1}$ variables & $n_{1,2}$ variables \\
    \hline
    \textbf{2. more preattentive} & $n_{2,1}$ variables & $n_{2,2}$ variables \\
    \hline
\end{tabular}
\end{center}

\noindent Let $n_{1,1}$, $n_{1,2}$, $n_{2,1}$, $n_{2,2}$ be the numbers of data variables in these four boxes. We assign $\iota = 1$ to the ``less important'' category and $\iota = 2$ to the ``more important'' category. Similarly, we assign $\alpha = 1$ to the ``less preattentive'' category and $\alpha = 2$ to the ``more preattentive'' category.   We can actually compute the Pearson correlation index as:

\begin{align*}
    \overline{\iota} &= \frac{n_{1,1} + n_{2,1} + 2 n_{1,2} + 2 n_{2,2}}{n}\\
    \overline{\alpha} &= \frac{n_{1,1} + n_{1,2} + 2 n_{2,1} + 2 n_{2,2}}{n}\\
    %
    A &= n_{1,1}(1-\overline{\iota})(1-\overline{\alpha}) +
    n_{1,2}(2-\overline{\iota})(1-\overline{\alpha})\\
    &+ n_{2,1}(1-\overline{\iota})(2-\overline{\alpha}) +
    n_{2,2}(2-\overline{\iota})(2-\overline{\alpha})\\
    B_\iota &= (n_{1,1} + n_{2,1})(1-\overline{\iota})^2 +
         (n_{1,2} + n_{2,2})(2-\overline{\iota})^2\\
    B_\alpha &= (n_{1,1} + n_{1,2})(1-\overline{\alpha})^2 +
         (n_{2,1} + n_{2,2})(2-\overline{\alpha})^2\\
    %
    C &= \frac{A}{\sqrt{B_\iota B_\alpha}}
\end{align*}

A rater can simply make a standard spreadsheet for calculating $C$ with four input values $n_{1,1}$, $n_{1,2}$, $n_{2,1}$, $n_{2,2}$. Similar, if a rater wishes to use three levels for both importance and attention, the above procedure can be adapted for $3 \times 3$ boxes and a sightly different spreadsheet for calculating $C$. The following steps describe a procedures for generalized $k \times k$ boxes. 


\begin{enumerate}
    \item[1.] Place each data variable into one of the $k \times k$ boxes.
    \item[2.] Count the number of data variables in each box.
    \item[3.] Use a spreadsheet to determine the correlation index $C$.
    \item[fin.] Map the value of $C$ to one of the five levels defined in Section \ref{sec:Importance}.
\end{enumerate}

% ---------------------
\subsection{Attention: Balance}
\label{apx:Balance}
%
To assess this criterion, a rater needs to explore all data variables and all possible values that each variable may take, considering the attention that the variable may attract through its visual channel(s). When a data variable is encoded using multiple visual channels, focus on the most preattentive visual channel and the combined preattentive quality, rather than the visual channel with the weakest preattentive quality. As the rater may be presented with a limited number of glyph instances, the rater needs to imagine the preattentive quality of those glyphs that encode other values but are not presented. As long as a data variable can take a certain value, with which the data variable attracts an inadequate amount of attention, the rater should consider that this is a case of weak attention. In other words, the rater should consider the worst case scenario (rather than the average case) for a variable. The steps for assessing this criterion are relatively straightforward. 

% The rater could explore the possibility of weak attention by varying the value of every variable over its entire value range while observing if some channels draw the users' attention weakly or perhaps some visual instances in the channel drive particularly low attention while others don't. If only some visual instances attract weak attention, the rater may consider the severity level based on how many weak attention-attracting instances there are and potentially how much impact the weak attention may lead to.

\begin{enumerate}
    \item[1.] Scan every data variable to see if it receives weak attention, i.e., it cannot attract an inadequate amount of attention.
    \item[2.] Count the number of such data variables.
    \item[fin.] Map the counted number to one of the five levels defined in Section \ref{sec:Balance}.
\end{enumerate}

% ---------------------
\subsection{Searchability}
\label{apx:Searchability}
%
As discussed in Section \ref{sec:Searchability} and Appendix \ref{apx:Orthogonality}, this criterion cannot be replaced by or included in other criteria easily, though its name seems to suggest some overlapping. Nevertheless, its definition separates this criteron from others. As defined in Section \ref{sec:Searchability}, the searchability criterion \emph{assesses the desirable property that the visual channel(s) for each data variable can be recognized easily among others after a viewer has learned and remembered the encoding scheme.} 

The notion of cognitive load is well-known in the fields of visualization and psychology, and is critical to understand how visualization works and how to optimize a visual design. However, the measurement of cognitive load has not reached the level that we can easily quantify the cognitive load of an action or task in a visualization process. Likely it will take decades to improve the current situation, possibly through conducting a huge number of empirical studies to collect data and/or developing more efficient and effective techniques for measuring cognitive load.

Nevertheless, the scheme requires a rater to estimate cognitive load but at only three levels, \emph{low}, \emph{medium}, and \emph{high}, as defined in Section \ref{sec:Searchability}. A rater can become used to the practice of estimating cognitive load at these three levels. Equipped with the skill for estimating cognitive load, a rater can produce a Type D score with the following steps. 

\begin{enumerate}
    \item[1.] Scan every data variable to see if searching it will likely demand a \emph{low}, \emph{medium}, or \emph{high} amount of cognitive load.
    \item[2.] Count the numbers of such data variables in the categories of \emph{low}, \emph{medium}, and \emph{high} respectively.
    \item[fin.] Map the counted numbers to one of the five levels defined in Section \ref{sec:Searchability}.
\end{enumerate}

% Prior to the evaluation, the users are expected to be equipped with the knowledge of the semantic backgrounds and semantic encoding. If a rater lacks this knowledge, written instruction containing information on all semantic backgrounds and semantic encoding should be available to be looked up. While rating, the rater should not consider the effort of looking up information in such material. the rating contains three steps:

% \begin{enumerate}
%    \item[1.] Evaluate the cognitive load the users experience in the search of individual channels.
%    \item[2.] If there is any visual search bringing a high cognitive load, depending on the number of such data channels, give a score of 1 or 2.
%    \item[3.] If there is no visual search bringing a high cognitive load but any giving medium load, depending on the number of such data channels, give a score of 3 or 4.
% \end{enumerate}

% ---------------------
\subsection{Learnability}
\label{apx:Learnability}
%
An experienced rater will likely be able to anticipate the time required to learn a glyph design. Alternatively, a rater or designer can organize meetings with potential users to observe how quickly potential users can grasp the visual encoding scheme and how easily they may be confused by the semantic meanings of the visual encoding. As it is common for glyph designers to hold meetings with potential users for requirement analysis and evaluation, assessing learnability can be part of such meetings.

For an independent rater who may not have the access to the potential users, the rater can gather learnability information from the glyph designer, while using the rater's own knowledge and experience to estimate the learning time. Hopefully, there will be more empirical studies in the future to provide more data about the time required to learn different glyph designs in different contexts.

The rater needs to estimate the following values:
%
\begin{itemize}
    \item The \emph{learning time} required in the ``self-learning'' mode.
    \item The \emph{learning time} required in the ``self-learning + Q\&A'' mode, i.e., the potential users will likely need to hold a Q\&A session with the designer or someone who has already learned the encoding scheme of a glyph design.
    \item The \emph{learning time} required in the ``tutorial'' mode.
    \item The effort required for \emph{repeated learning}, in terms of four levels
    (i.e., effortless, minor effort, noticeable effort, and serious effort).
\end{itemize}

In summary, the rater can determine a Type D score by using the following steps:

\begin{enumerate}
    \item[1.] If the rater has the opportunity to meet potential users, observe the learnability of a glyph design in the meetings. Otherwise, gather the learnability information from the glyph designer who is expected to have the opportunity to meet potential users.
    \item[2.] Estimate how long it will take to learn the encoding scheme for all data variables in a glyph design in three learning modes (i.e., self learning, self-learning + Q\&A, and tutorial).
    \item[3.] Estimate the effort required for repeated learning in terms of four levels (i.e., effortless, minor effort, noticeable effort, and serious effort).
    \item[fin.] Map the three time values for different learning modes and the effort level for repeated learning to one of the five levels defined in Section \ref{sec:Learnability}.
\end{enumerate}

%The rating of learnability is relatively straightforward and can be performed easily following the instructions in the paper. The raters should first examine the degree of self-explanatoriness of all semantic encoding to distinguish between scores 5, 4, or below 4. If it is deemed below 4, the users evaluate the complexity of the information to be learned to decide whether a score of 1, 2, or 3 best fits the condition.

% ---------------------
\subsection{Memorability}
\label{apx:Memorability}
%
Similar to learnability, an experience rater will likely be able to predict whether potential users can still remember a glyph design or part of a glyph design after 1 hour and 24 hours respectively. Of course, it is not absolutely necessary to define memorability based on the 1-hour and 24-hour interval. Nevertheless, it would be confusing and time consuming to consider many different intervals for evaluating this criterion.

A glyph designer or a rater can also use meetings to observe the memorability of a glyph design. For example, during a meeting, one may note down how often some participants would say ``I forgot what the black squire is for,'' or ask ``could you remind me what the middle line is?''. At the beginning of the subsequent meetings, a designer can also ask participants to recall the associations between data variables and visual channels.  

Similar to the evaluation of learnability, for an independent rater who may not have the access to the potential users, the rater can gather memorability information from the glyph designer, while using the rater's own knowledge and experience to estimate the level of easiness and difficulty in remembering a glyph design. Hopefully, there will be more empirical studies in the future to provide more data about the memorability of different glyph designs in different contexts.

In summary, the rater can determine a Type D score by using the following steps:

\begin{enumerate}
    \item[1.] If the rater has the opportunity to meet potential users, observe the memorability of a glyph design using the meetings. Otherwise, gather the memorability information from the glyph designer who is expected to have the opportunity to meet potential users.
    \item[2.] Scan all data variables in the glyph design, and estimate whether potential users can still remember, after 1 hour and 24 hours respectively, (i) the associations between the data variables and their visual channels and (ii) the encoding scheme of each visual channel in the glyph design, based on the information gathered, in conjunction with the rater's own analysis of the glyph design and knowledge and experience about glyph memorability in general.
    \item[3.] Work out the percentage of the data variables, whose visual encoding can still be remembered after 1 hour and after 24 hours.
    \item[fin.] Map the two percentage values to one of the five levels defined in Section \ref{sec:Memorability}.
\end{enumerate}


% The standard operation of memorability rating requires make evaluation at two timepoints. One hour after learning, a user should examine how much review he/she requires to be fully able to use the glyph design. Twenty-four hours afterwards, the user makes the evaluation again. Following the description in the paper, the final score should be the one that is closest to the conditions at the two timepoints.




