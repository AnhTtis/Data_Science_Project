
\section*{}
The paper, which is entitled ``Multi-Criteria Decision Analysis for Aiding Glyph Design'', is accompanied by three appendices (in this document) and three further documents in the supplementary materials:
%
\begin{itemize}
    \item Appendix \ref{apx:FrameworkDesign} --- Providing an analysis of different categorization schemes in the literature and discussing why the proposed categorization scheme is suitable for the methodology of multi-criteria decision analysis. \reviseTVCG{It also includes discussions on the strategies for defining the five levels of each criterion.} 
    \item Appendix \ref{apx:Bertin} --- Providing the background information about the term ``Typedness'' and Bertin's criteria.
    \item Appendix \ref{apx:Workflow} --- Providing 12 detailed workflows, one for each criterion defined in Section \ref{sec:Scheme}.
    % \item PDF File (ParodyDesigns.pdf) --- Providing detailed documentation about the parody designs used in the evaluation (as reported in Section \ref{sec:Evaluation}).
    \item PDF File (ParodiesJointsDesigns.pdf) --- Providing detailed documentation about the parody designs and the glyph designs for a biomechanical application, which were reported in Section \ref{sec:Evaluation}.
    \item Spreadsheet File (GlyphRating\_ScoreSheets.xlsx) --- Providing multiple score sheets, each of which was used to score one of the designs in Section \ref{sec:Evaluation}. The spreadsheet file can also be used as a template for future applications of the MCDA scheme.  
\end{itemize}

% ====================
\section{The Process for Formulating the Framework}
\label{apx:FrameworkDesign}

\begin{figure*}[h]
    \centering
    \includegraphics[width=\linewidth]{Figures/Categories.pdf}
    \caption{Left: The criteria proposed by Bertin \cite{Bertin:2011:book}, Maguire et al. \cite{Maguire:2012:TVCG}, Borgo et al. \cite{Borgo:2013:STAR}, and Chung et al. \cite{chung2015glyph}. Right: the connections among these criteria. Each connection line indicates partial overlapping between the two connected criteria.} 
    \label{fig:Criteria}
\end{figure*}

The members of the author team have different amounts of experience in glyph-based visualization, varying from working on glyph designs for about two years to co-authorship of some 20 papers involving glyph-related work, including three papers on the criteria for glyph designs (i.e., \cite{Maguire:2012:TVCG,Borgo:2013:STAR,chung2015glyph}, which are considered extensively in this work). During the processes of designing glyph-based visualization for a medical application, the team recognized that the design criteria in the literature (e.g., \cite{Bertin:2011:book,Maguire:2012:TVCG,Borgo:2013:STAR,chung2015glyph}) are not easy to use, because:
%
\begin{enumerate}
    \item Different sets of criteria are overlapping in some aspects but distinctive in other aspects. Fig. \ref{fig:Criteria} illustrates the overlapping and distinctive aspects. From the figure, we can also have a sense that combining these four sets is a not a trivial undertaking.
    %
    \item Some criteria are defined with phrases ``should ideally'', ``may minimize'', and ``as much as possible'', reflecting the challenges for glyph designs to meet all criteria.
    %
    \item On the one hand, one may wish to have a small set of criteria. However, each criterion would include several sub-criteria, making the combined criterion difficult to assess. One may also wish to have a set of highly-independent (often referred to as orthogonal) criteria, avoiding the same aspect being assessed multiple time. In general, narrowly-defined criteria are more likely to be independent of one another. However, the more narrowly-defined criteria are, the higher the number of criteria will be.  
    %
    % $~$\hspace{5mm} One may compare this desire to setting examination papers. It is usually not trivial to determine what is the optimal number of examination papers and whether the questions in examination papers are orthogonal enough.
\end{enumerate}

The author team recognized the need to identify a set of criteria, each of which can be assessed with multi-level scores that transform semantic definitions of quality or desirability to numerical values. The operations research method ``multi-criteria decision analysis (MCDA)'' became the focus of this work, which commenced in October 2021. %\textcolor{red}{Hong-Po: Please check.}

From Fig. \ref{fig:Criteria}, we can imagine many different options for combining these criteria, not mentioning further options which would be introduced in a combinatory fashion if one added new criteria or split some existing criteria. While Bertin's four levels of organization ($\equiv, \neq, \text{O}, \text{Q}$) \cite{Bertin:2011:book} may be translated into levels of quality or desirability, they cannot be applied to most (if not all) other criteria in Fig. \ref{fig:Criteria}, which were not accompanied by any level-definitions. When each criterion is enriched by defining such levels, there will be many different options for defining such levels. When an MCDA scheme is proposed for a set of criteria, there will be many options for assigning weighting values. The design space for such a framework is thus huge. Because the space is not a mathematically-defined space, one cannot utilize techniques such as mathematical optimization or machine learning to explore such a space.

Therefore, like almost all MCDA schemes in the literature, it will be a community effort to improve earlier schemes gradually. For this reason, we consider the criteria proposed by Bertin, Maguire et al., Borgo et al., and Chung et al. positively and highly valuable, rather than negatively as schemes that might not be optimized, since optimization is simply too challenging to obtain or ascertain.         

% In some ways, formulating an optimal set of criteria for assessing glyph designs is challenging as determining an optimal set of courses to teach or an optimal set of examination questions to write. One group of academia of a subject has to make the first step.     

Since January 2022, the author team (including one member who devoted almost 100\% of research time on proposing this MCDA scheme) conducted a number of research activities, including:
%
\begin{itemize}
    \item Studying the literature on glyph-based visualization, aspects of perception and cognition, and MDCA methodology and applications. This was summarized in Section \ref{sec:RelatedWork}.
    \item Analysing the merits and potential shortcomings of each existing set of criteria, i.e., the Bs, Ms, Cs, and Rs in Fig. \ref{fig:Criteria} in the context of a premise that we were to transform the set to an MDCA scheme. We will describe these merits and shortcomings briefly in the four subsections below.
    \item Proposing a number of possible schemes and comparing their relative merits through both conceptual analysis and practice-based evaluation (i.e., by using each proposed scheme to score some glyph designs in the literature and their parody designs as well as our own designs for a set of biomechanical measures). We identified the best scheme among various other schemes considered including those based on the four existing sets of criteria. Because of the page limit, the conceptual analysis was concisely reported for each criterion individually in Section \ref{sec:Scheme}. The practice-based evaluation was selectively reported in Section \ref{sec:Evaluation}.
\end{itemize}

In Sections \ref{sec:BertinSet}$\sim$\ref{sec:BorgoSet}, we report our analysis of the merits and potential shortcomings of the four existing sets of criteria in the context of a premise that we were to transform the set to an MDCA scheme. This is not to be confused with an analysis of their relative merits in a broader context or in other contexts. In general, we do not make orthogonality among criteria an essential requirement since this not easily achievable. The difficulty is likely due to the fact that many different criteria share the same underlying perceptual and cognitive factors, or their underlying factors are intertwined. Therefore, we will point out such overlapping not as a criticism but as a potential angle for reducing overlapping through more precise definitions or reorganization of the grouping of criteria.

The discussions on the existing sets of criteria are followed by Section \ref{sec:BuildOn} where we summarize the major attributes in the existing sets that were adopted in our MCDA scheme described in Section \ref{sec:Scheme}.  

% ----------
\subsection{The Four Criteria by Bertin}
\label{sec:BertinSet}
%
Bertin's four criteria are much better known in comparison to the other three sets of criteria. They are also accompanied by four levels of organization, i.e., selective ($\equiv$), associative ($\neq$), ordered (O) and quantitative (Q). \reviseTVCG{These can be translated to four different criteria in an MCDA scheme. When considering a visual channel against one of the four criteria, Bertin used binary assessment, i.e., yes or no (see also Appendix \ref{apx:Bertin})}. 

One may also recognize that there is some correlation between \emph{B1. Associative Perception} and \emph{B2. Selective Perception}, because of which, many have found it hard to distinguish between these two criteria. Meanwhile \emph{B3. Ordered Perception} and \emph{B4. Quantitative Perception} have some overlapping since a visual channel that is quantitative is also ordered.
However, Bertin made a serious effort to provide precise definitions of each criteria, which alleviated the confusion between overlapping criteria. 

On the other hand, as shown in Fig. \ref{fig:Criteria}, Bertin's four criteria may give a reasonable coverage of different aspects of an individual visual channel, but they do not cover some desirable qualities in terms of the interaction between different visual channels, such as \emph{C4. Searchability} and \emph{C7 Attention Balance} \cite{chung2015glyph}, and \emph{R8 Simplicity and Symmetry} and \emph{R9. Orthogonality and Normalization} \cite{Borgo:2013:STAR}.

% ----------
\subsection{The Four Extra Criteria by Maguire et al.}
\label{sec:MaguireSet}
%
Maguire et al. \cite{Maguire:2012:TVCG} recognized the specific focus of \emph{B1}$\sim$\emph{B4} on visual channels individually, and proposed four additional criteria for evaluating desirable qualities in terms of the interaction among different visual channels. Among these, assessing \emph{M1. Channel Composition}, \emph{M2. Pop-out Effects}, and \emph{M3. Visual Hierarchy} involves the consideration of at least two visual channels, while \emph{M4. Convention \& Metaphor} may be applied to a visual channel individually or a whole glyph holistically.

Maguire et al. proposed \emph{M1}, \emph{M2}, and \emph{M3} according to some experimental findings and theoretical discourse in psychology, while proposing \emph{M4} based on their own experience of graphic design. Later Borgo et al. underpinned \emph{M4} with evidence from VIS literature and related it to memorability of a glyph design.  

On the other hand, the criteria proposed by Maguire et al. do not adequately cover the desirable quality for each visual channel to encode a sufficient number of data values, which is referred to as \emph{C3. Channel Capacity} by Chung et al. \cite{chung2015glyph}. Despite this lack, \emph{M1} captures an aspect of \emph{C3} as integration of visual channels may reduce their channel capacities. While \emph{M1} considers potential negative impact because of integrated composition, Maguire et al. did not consider the need for an effective composition in some glyph designs to facilitate comparative observation of different visual channels.     
Although Maguire et al. used redundant mapping in their glyph design, they did not propose a criterion to convey \emph{R5. Redundant mapping of variables} as done by Bogor et al. \cite{Borgo:2013:STAR}. Maguire et al. also conducted scalability tests, but did not include scalability as a criterion.    

% ----------
\subsection{The Eight Criteria by Chung et al.}
\label{sec:ChungSet}
%
The reason that we discuss the eight criteria by Chung et al. \cite{chung2015glyph} before the fourteen criteria by Borgo et al.  \cite{Borgo:2013:STAR} is because the latter discussed the work by the former, though Chung et al. \cite{chung2015glyph} was published later.

Chung et al. combined Bertin's four criteria into a single criterion \emph{C1.
Typedness}, and introduced \emph{C3. Channel Capacity} as a new criterion.
Chung et al. used the terms ``$\square$-ability'' for four of their eight criteria, suggesting a possible intention to assess such criteria using a rating scale, such as a Likert-type scale.
For example, \emph{C4. Separability} is a rateable criterion corresponding to Maguire et al.'s \emph{M1}. \emph{C6. Learnability} is a rateable criterion corresponding to Maguire et al.'s \emph{M4}. Chung et al. recognized the pros and cons of pop-out effects (\emph{M2}) and visual hierarchy (\emph{M3}) and replaced them with \emph{C5. Searchability} and \emph{C7. Attention Balance}.

The criterion \emph{C2. Visual Orderability}, which is strongly related to their research on the topic \cite{Chung:2016:CGF}, overlaps with Bertin's \emph{B3} and \emph{B4}. The definition of \emph{C6. Learnability} includes both learning and remembering, but memorability is not obvious in the term learnability. Chung et al. did not include either scalability or comparability as a criterion.

For this work, we did not include the consideration of \emph{C8. Focus and Context} as this was for assessing glyphs to be used in interactive visualization. 

% ----------
\subsection{The Fourteen Criteria by Borgo et al.}
\label{sec:BorgoSet}
%
Borgo et al. \cite{Borgo:2013:STAR} conducted a comprehensive survey on a broad range of topics in glyph-based visualization, including the theoretic foundations, design guidelines, techniques, and applications. They summarized a set of fourteen criteria as design guidelines. Here we focus on eight of them as the other six are for 3D glyph design, using glyphs in other visual representations (e.g., volume rendering), and glyph placement and occlusion when multiple glyphs are used in a visualization (e.g., on a geographical map). 

As shown in Fig. \ref{fig:Criteria}, the eight criteria proposed by Borgo et al., i.e., \emph{R1}, \emph{R2}, \emph{R4}, \emph{R5}, \emph{R6}, \emph{R8}, \emph{R9}, and \emph{R10}, are somehow related to the criteria proposed by Maguire et al. \cite{Maguire:2012:TVCG} and Chung et al. \cite{chung2015glyph}. For example, \emph{R4. Perceptually-uniform glyph properties} and \emph{R5. Redundant mapping of variables} are two approaches for improving \emph{C3. Channel Capacity}. \emph{R10. Intuitive mapping based on semantics} and \emph{R1. Task-based choice of visualization space} are related directly to \emph{C6} while broadening \emph{M4}. Criterion \emph{R6. Importance-based mapping} is related to \emph{C5} and \emph{C7} as well as \emph{M2} and \emph{M3}.

 Borgo et al. introduced the criterion \emph{R5. Redundant mapping of variables}, acknowledging the potential positive impact of using multiple visual channels to encode a data variable.

Unlike Maguire et al. and Chung et al., Borgo et al. did not include Bertin's four criteria in their categorization, nor were the criteria scalability and comparability considered. Because they defined their categorization as a set of design guidelines, some guidelines are stated in a way ``to try to do if one can'', which is not quite the same as criteria to be assessed. 

% ----------
\subsection{Building on the Existing Sets of Criteria}
\label{sec:BuildOn}
%
The development of the four sets of criteria by Bertin, Maguire et al., Chung et al., and Borgo et al. reflects a research-based process for improving our scientific understanding about glyph-based visualization as well as practical methods for evaluating glyph designs. While we anticipate that this research-based process will continue for years and decades, it is important for us to continue this process, building on the existing contributions, and making further improvement. Here we summarize the main attributes that we can adopt or adapt in formulating an MCDA scheme.
%
\begin{itemize}
    \item \textbf{Rateable Criteria} --- Bertin's criteria are rateable (see Appendix \ref{apx:Bertin}). Chung et al. used terms ``$\square$-ability'', which suggest the potential for defining rateable criteria.
    %
    \item \textbf{Channel-focused vs. Glyph-focused} --- From Fig. \ref{fig:Criteria}, we can observe that some criteria focus on the desired qualities of individual visual channels, and some focus on the whole glyph or the interaction among visual channels. This difference entails assessment at different levels of detail. Some criteria can be used to assess both channel-focused and glyph-focused qualities.
    %
    \item \textbf{Major Clusters of Criteria} --- From Fig. \ref{fig:Criteria}, we can observe the major clusters of criteria connected by lines colored differently. These include: (i) Bertin's criteria (two shades of green), (ii) channel capacity (purple), (iii) channel intuitiveness (pink), (iv) composition and separability (two shades of orange), (v) attention and searchability (two shades of blue), and (vi) glyph intuitiveness (red).
    %
    \item \textbf{Missing Criteria} --- The missing criteria identified in the above sections, i.e., scalability and comparability, should be included in the new scheme.
    %
    \item \textbf{Two Sides of the Same Coin} --- Chung et al. considered the positive and negative impact of varying attention in terms of \emph{C5} and \emph{C7}. One may consider the two sides of varying composition in terms of interference (\emph{M1}) and comparability.
    %
    \item \textbf{Sub-criteria} --- Some differences among different sets of criteria in Fig. \ref{fig:Criteria} reflect the desire to assess sub-criteria separately. There is a trade-off between assessing a criterion holistically and assessing its sub-criteria individually.
    %
    \item \textbf{One-to-many Mapping} --- Borgo et al. introduced the potential use of multiple visual channels to encode an important data variable as a guideline, while Maguire et al. demonstrated the merits of such one-to-many encoding. In fact, one-to-many encoding is more common than one expects and often cannot be avoided. For example, a circular arc naturally has at least several visual channels: arc length, arc angle, starting and terminating angles in relation to 0 degrees. When a data value is encoded using an arc, one can perceive this value using both arc length and arc angle. Varying the height of a triangle causes changes to several visual channels including height, area, shape, and angles. Hence this raises a question: shall we assess each visual channel individually or assess all visual channels used to encode a data variable? 
\end{itemize}

Building on these attributes, the author team proposed a number of MCDA schemes. After some lengthy comparative analysis, these different MCDA schemes evolved to become the MCDA scheme described in Section \ref{sec:Scheme}.

\reviseTVCG{As briefly discussed at the beginning of Appendix \ref{apx:FrameworkDesign}, when an MCDA scheme is proposed for a set of criteria, there will be many options for assigning
weighting values. The design space for such a framework is thus huge. Because the space is not a mathematically-defined space, one cannot utilize techniques such as mathematical optimization to explore such a space. After the scheme have been used in tens and hundreds of design processes, the designers in the VIS community may share their experience and some colleagues may bring such experience together into coherent evaluation documents, which may lead to further improvement of the scheme, different weight distribution, or proposals of new schemes.}

\reviseTVCG{The current scheme is accompanied by a simple weight distribution. Criteria 1, 2, and 3 are Type A criteria (assessed through examining data variables individually). All of them are assigned a weight of 1 at the Type D level. Criteria 4 $\sim$ 12 are all Type D criteria and are assigned a weight of 0.5 at the Type D level. We can also observe that many criteria are in pairs (e.g., criteria [4, 5], [6, 7], [8, 9], and [11, 12], and this provides another justification for a 0.5 weight for each of these criteria. Meanwhile, we consider, qualitatively, that the impact level of criterion 10 is similar to those of criteria $4 \sim 9, 11 \sim 12$, while Criteria 1, 2, and 3 may have more critical impact than these criteria. This provides another justification for the difference between the 1.0 and 0.5 weights.}

\reviseTVCG{At the moment, there is no definite reason to make small adjustment of the weights (e.g., 0.4 instead of 0.5) for any criterion. We also do not recommend for designers to change the weight distribution in different design processes. In general, it is easy for the designers to interpret the scores in the context of different applications. When a design option received a low score for a criterion, it alerts the designer to have a close look and make attempts to improve it. When a criterion is adjusted to a lower weight in an assessment process, it would invite designers to ignore the criterion.}

% ----------
\subsection{Orthogonal Names vs. Orthogonal Definitions}
\label{apx:Orthogonality}
%
We found that some conceptual overlapping is unavoidable, largely due to the broad interpretation of many words and the interrelated cognitive processes underpinning these concepts. It would be great if future research could propose a set of orthogonal names for different criteria.
Even if this were possible, it would take some time before the new names and definitions were to emerge and be used consistently in the literature. One may compare this desire to setting examination papers. It is usually not trivial to determine what is the optimal number of questions and whether the questions are orthogonal enough.

As an example of unavoidable overlap shown in Fig. \ref{fig:Criteria}, the concept of ``searchability'' (C5) in \cite{Chung:2016:CGF} is connected to several other concepts in \cite{Maguire:2012:TVCG,Borgo:2013:STAR,Chung:2016:CGF}. In general, a visual channel for encoding a data variable is expected to be distinguishable from the background and neighboring visual objects, though it may suffer from various shortcomings, e.g., being too small (Section \ref{sec:Geometry}), not having enough contrast with the background (Section \ref{sec:Colorimetry}), too much interference from the neighboring objects (Section \ref{sec:Separability}), lack of preattentiveness (Section \ref{sec:Balance}), etc. While any of these shortcomings can affect searchability, a visual channel, which does not suffer from these shortcomings, can still be difficult to search.

As discussed in Section \ref{sec:Searchability}, the searchability criterion cannot be replaced by or included in other criteria easily. At least, we have not found a suitable semantic definitions for other criteria in order for any of them to include all aspects of searchability. Meanwhile, if we were to combine all these criteria into a single criterion, it would be too complex to evaluate and too fluid to score consistently.

We should not see such semantic intricacy as a demerit of this proposed scheme but rather as a starting point for discussion by the community of the most appropriate and unambiguous terminology to use. Other alternative schemes may emerge in the future and they may be considered to be better by the community. Through the evolution of a language, a word can have several semantic meanings, and many words can have partially overlapping meanings. While we strive to optimize the boundary and minimize the overlapping among criteria, we are also constrained by the available words used to label these criteria. Hence in this work, we have made every effort to define each criterion precisely (see Section \ref{sec:Scheme}), to minimize the overlapping, and to find the most suitable word(s) to describe each criterion. Because of the constraints of the available words, having a set of orthogonal names for different criteria may not be possible. Meanwhile, the definitions of the criteria in Section \ref{sec:Scheme} are reasonably orthogonal.

% ----------
\subsection{\reviseTVCG{Strategies for Defining the Five Levels of Each Criterion}}
\label{apx:Orthogonality}

\reviseTVCG{In the literature, Bertin \cite{Bertin:2011:book} assessed his criteria with two quality levels, i.e., ``yes'' or ``no''. Maguire et al. \cite{Maguire:2012:TVCG} used 5-level assessment for two criteria and 3-level assessment for one criterion, in addition to binary assessment for Bertin's criteria. They did not intend to combine these assessment scores numerically. Chung et al. \cite{Chung:2016:CGF} and Borgo et al. \cite{Borgo:2013:STAR} did not define assessment levels for their criteria. Nevertheless, they must have had at least two levels in mind, i.e., meeting or failing a criterion.}

\reviseTVCG{In general, most MCDA schemes in the literature used a 5-level or 10-level scoring system that is applied to all criteria in the same scheme consistently. While all VIS researchers and practitioners have been dealing with multiple design criteria in their work, using a MCDA scheme is not common. We thus propose to introduce a 5-level scoring system, which is a major step forward considering what is in the VIS literature. The VIS community is also familiar with 5-level scoring as major VIS conferences all use a 5-level scoring system for reviewing papers. Meanwhile, it may be premature to introduce a 10-level scoring system because the more levels an MCDA scheme has, the more precise specification is required. One can relate such a challenge to marking an essay with a marking scheme that has two levels (pass, fail), three levels (distinction, pass, fail), five levels (A, B, C, D, E), 11 levels (0 $\sim$ 10), or 101 levels (0 $\sim$ 100). The number of levels usually correlates with the level of preciseness requirement for a marking scheme and the level of difficulty in specifying such requirement.}

\reviseTVCG{We adopted a few relatively obvious approaches to the specification of the five levels:
\begin{itemize}
    \item A higher value is considered to be better. Hence 5 is the best and 1 is the worst.
    %
    \item Level 3 is considered to be easily attainable by a relatively experienced VIS designer in most situations. There can be some exceptional circumstances, which will be discussed later in this Section.
    %
    \item Level 4 is defined as the inbetweening point between Levels 3 and 5, and Level 2 is defined as the inbetweening point between Levels 1 and 3.
\end{itemize}
}

\reviseTVCG{We also adopted a few strategies that we consider to be realistic and sensible based on the current state of the art in terms of the theoretical understanding and available empirical data in the field of visualization. These include:}

\vspace{2mm}\noindent
\reviseTVCG{%
\textbf{Assuming that VIS knowledge is necessary.} Each scoring decision is expected to be made by a relatively experienced VIS designer, rather than a person with limited VIS design knowledge or a computer. Using such human knowledge should be considered as a positive aspect of the proposed MCDA scheme, rather than dismissing it as subjective or biased. In comparison with a design process without any scoring mechanism and specification of levels, the proposed MCDA scheme is less subjective and less biased. Meanwhile, our theoretical understanding about VIS designs is not ready for hand-crafting an algorithm to score each glyph design option, while there is not enough human-scoring data to train a machine-learning model to do so either. In the real-world, there are many MCDA schemes (e.g., building health-safety assessment, candidate selection assessment, and essay marking) for which expert knowledge has always been considered necessary in determining scores.}

\vspace{2mm}\noindent
\reviseTVCG{%
\textbf{Focusing on one or two key indicators to assess individual criterion.} When we have a \textbf{close} look at each criterion, it is not difficult for most of us to notice that its assessment could potentially involve the consideration of several factors. In other words, one could specify another MCDA scheme for assessing each criterion. This could go further into nested MCDA iterations in a hairsplitting manner.}

\reviseTVCG{\emph{Note: Such nested iterations are about breaking one criterion into multiple sub-criteria, and then breaking down each sub-criterion into multiple sub-sub-criteria. They are not the same as Type A, Type B, and Type C iterations as discussed in Section \ref{sec:Overview} as the latter break down the assessment of a whole glyph (Type D) into that of the encoding of individual variables (Type A) or their comparison (Type B and Type C).}}

\reviseTVCG{
It would cost so much time to complete a full round of assessment. We therefore focus the assessment of each criterion on one or two key indicators. This is somehow similar to setting examination questions for a course (e.g., calculus). At the high-level, the lecturer may set $N$ questions to cover $N$ topics of the taught courses (e.g., $N=10$, 10 marks each). Likely, most lecturers will try to ensure a good coverage (cf. the 12 criteria of the proposed MCDA scheme). At the level of each individual topic, the lecturer may focus on one aspect with one example (e.g., Q: $\int_0^\infty \frac{1}{a^2 + x^2}dx$, A: $\frac{\pi}{2a}, a \neq 0$). Based on the lecturer's experience, the assessment of $\int_0^\infty$ correlates with similar aspects (e.g., $\int_0^1$, $\int_{-\infty}^{\infty}$, etc.) The lecturer thus treats $\int_0^\infty$ as a key indicator. Meanwhile, there can be numerous examples of $f(x)$, and the lecturer can only select one or a few. This is also similar to the scenario that only a small number of examples and case studies could be provided in any paper.}

\reviseTVCG{
For example, there are many different types of color degeneration. The testing defined in Section \ref{sec:Colorimetry} involves two aspects, \emph{contrast} and \emph{brightness}. Many other aspects are not assessed directly, e.g., missing one of the RGB channels (a common error during overhead projection), different gamma settings of computer screens, and different environmental lighting conditions. Nevertheless, we can all appreciate some correlation between the two tested aspects and those not tested explicitly.}

\reviseTVCG{
While we focus on one or two key indicators for most criteria, the only exception is the first criterion, Typedness, which is assessed with four key indicators, i.e., Bertinâ€™s
four kinds of perception (KOP), namely, associative, selective, ordered, and quantitative perception. This is partly because we do not wish to split Bertin's KOPs into different sub-criteria or select 1 $\sim$ 3 out of the four KOPs. Partly, and perhaps as a more significant reason, we anticipate most (if not all) VIS designers are familiar with Bertin's KOPs for the six visual channels in Table \ref{tab:BertinRating}, and they can make judgment about the typedness of these six visual channels quickly. In the worst-case scenario, having a quick glance at Table \ref{tab:BertinRating} does not take much time. As a glyph designer may potentially use many other visual channels, we also provide Table \ref{tab:ChannelRating} as provisional judgment decisions, which will need to be finalized by many empirical studies in the future. These two tables are further discussed in Appendix \ref{apx:Bertin}.}

\vspace{2mm}\noindent
\reviseTVCG{%
\textbf{Having one recommended solution is better than having none or waiting for reaching an agreement within the VIS community.} While most in the VIS community may agree the aforementioned approach to focus on one or two key indicators, it may not be easy to reach an agreement on choosing which key indicator for every criterion. In some cases, there are many options and we might have to wait for many years to reach an agreement. For example, for varying the contrast and brightness of an glyph image, there are many formulae in the literature in addition to the one given in Section \ref{sec:Colorimetry}. One may argue to use a non-linear formula or a local adjustment algorithm and start a new discussion about which non-linear formula or local algorithm. Even for the given linear formula, there can be many minor variations, such as replacing 259 with another number $> 255$ (avoiding division by 0) or replacing 128 with a ``better-defined'' middle gray. We decided to use 259 as there was a reasonable rationale in an online discussion \cite{Loch:2021:web}. We decided to use the more ``straightforward'' and ``obvious'' definition of middle gray, $128 \approx 255 \div 2$, because we consider that it is beyond the scope of this paper to debate about using which ``sophisticated'' definitions (e.g., ``18\% reflectance in visible light'' or the middle grey in CIEXYZ, CIELUV, CIELAB, or HSLuv color spaces).   
}

\reviseTVCG{%
We anticipate that discussions about selecting different key indicators for each criterion or different measuring formulae for each key indicator will continue as part of the VIS research. Such discussions should be encouraged and can be carried out through future research publications.   
}

\vspace{2mm}\noindent
\reviseTVCG{%
\textbf{Making level specification independent of the number of data variables.}
Most glyph designs in the VIS literature involve 10 or fewer data variables. Occasionally, there are more than 10 data variables (e.g., 20 in Duffy et al. \cite{Duffy:2015:TVCG}). The more data variables that a glyph has to encode, the more challenging for a design to be scored high against all criteria. We consider this is a norm. We do not wish for the MCDA scores to be used as an \emph{absolute} comparison across designs in different applications (specially in paper review processes). Consider two glyph designs X and Y. X involves many data variables as required in an application context, while Y involves only a few data variables. When X is scored lower than Y using the MCDA scheme, we should not consider that X is the worse design.}

\reviseTVCG{
Several criteria can easily be affected by the number of data variables. For example, the more data variables, the more difficult to achieve (i) high separability, (ii) good attention balance, (iii) high searchability, (iv) high learnability, and (v) high memorability. Some criteria may be indirectly affected. For example, discernability is recommended to be assessed for each data variable individually (i.e., Type A, direct assessment). However, with many data variables to be encoded, a designer may have to use smaller data objects or less powerful visual channels for some data variables. Nevertheless, when one obtains a Type D score through aggregation, the lower scores for some individual data variables may not impact on the Type D score noticeably.}

\reviseTVCG{
It may be helpful to note that the five levels of discernability are defined using percentage estimation across $n$ pairs of values (ranges). This is very different from across $n$ data variables. The latter would mean dependence on the number of data variables. In information theory, it is easy to distinguish the meanings of variable and value. Variables are alphabets and values are letters in an alphabet. Hence, using percentage estimation across $n$ pairs of values (ranges) does not contradict with this particular strategy.}

\reviseTVCG{
Some may wonder why not using absolute values, such as $\geq 40$ pairs, $40 \sim 39$ pairs, $20 \sim 29$, $10 \sim 19$ pairs, and $< 10$ pairs. The main reasons are:
\begin{itemize}
    \item The percentage-based specification is easy to define, learn, and memorize, while the counting-based specification has to consider the actual number $n$ (e.g., when $k = 5, n = 10$). For $k$ key values (ranges) in a data variable, there are $n = k(k-1)/2$ pairwise comparisons.
    %
    \item When $n$ is a big number, it is quicker to estimate percentage than counting.
    %
    \item Based on the authors' experience, it is common to over-specify the number $k$ for the key values (ranges) in each data variable during requirements analysis, as visualization is still commonly perceived as a tool for retrieving data, despite some empirical studies showing that for data retrieving tasks, visualization normally does not have any advantage over data tables \cite{Kanjanabose:2015:CGF}. Since visual channels in a glyph have very limited bandwidth, glyphs are in general worse than other forms of visualization for data retrieving tasks. We anticipate that this misconception will take many years to be adjusted, especially among non-VIS domain experts. Using percentage alleviates the problems caused by over-specification of the number $k$.     
\end{itemize}  
}

