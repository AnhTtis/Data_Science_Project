

\begin{table*}[htbp!]
    \centering
    \caption{Summary of model architectures for experiments for the QM9 and Alchemy datasets. These models incorporate a global mean pool layer since predictions are at the graph level, rather than at the node level as in all other datasets.
    }
    
\scalebox{0.83}{
    \begin{tabular}{lcc ccc}
    \toprule 
&  & &\multicolumn{3}{c}{Model}
    \\ \midrule
          &
& &
         \textbf{MLP} &  
         \textbf{GCN} & 
         \textbf{GCN-dDGM}
         \\ \midrule

         
         
         No. Layer parameters & BatchNorm & Activation & \multicolumn{3}{c}{Layer type}
         \\\midrule
          &  & & N/A & N/A & dDGM
          \\\hdashline
         (No. features, 20) & Yes (GraphNorm) & SiLU & Linear & Graph Conv & Graph Conv
          \\
          (20, 20) & Yes (GraphNorm) & SiLU & Linear & Graph Conv & Graph Conv
          \\ \hdashline
            &  & & \multicolumn{3}{c}{Global Mean Pool}
          \\ \hdashline
          
          (20, 20) & No & SiLU & Linear &  Linear & Linear
          \\ 
          (20, 20) & No & SiLU & Linear &  Linear & Linear
          \\ 
          (20, No. prediction targets) & No & - & Linear &  Linear & Linear
          \\ 
         \bottomrule
         
    \end{tabular}}
    
    \label{tab:Summary of model inductive learning}
\end{table*}