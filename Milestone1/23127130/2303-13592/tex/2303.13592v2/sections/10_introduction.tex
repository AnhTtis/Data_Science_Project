\section{Introduction}
Code-mixing is the linguistic practice of alternating between two or more languages in an utterance or conversation~\citep{poplack1978syntactic}. It allows individuals to express culturally-specific ideas, connect with or differentiate from other interlocutors, and reify their identities~\citep{bhatia2004,grosjean1982,toribio2006,chen1996code}. Despite its prevalence across many parts of the world, computational research into the area has only picked up steam recently~\cite{winata2022decades}. The growing visibility of code-mixing in the global media landscape, the proliferation of data-hungry machine-learning methods, and calls for natural language processing (NLP) research to devote more attention to multilingualism and low-resource languages collectively contribute to this emerging interest~\cite{aziz2019types,barman2014code,https://doi.org/10.48550/arxiv.2207.04672}.

\begin{figure}[t]
\centering
\includegraphics[width=0.8\columnwidth]{assets/alt-world.pdf}
\caption{\label{fig:SEA} Depiction of SEA regions, which consist of a total of 11 countries. We prompt LLMs to generate code-mixed data of languages used in six South East Asian countries (colored in dark blue): Brunei, Indonesia, Malaysia, Philippines, Singapore, and Vietnam.}
\end{figure}

That said, acquiring high-quality and low-cost code-mixed data presents itself as a challenge to NLP researchers in this field. For one, code-mixing is observed more frequently in colloquial settings and spoken communication, which makes procuring and curating extensive datasets logistically demanding and costly~\citep{chan2009automatic,winata2021multilingual}. Moreover, despite code-mixing's prevalence across social media or digital messaging platforms, consolidating such data may be curtailed by legal guardrails and scalability issues.

Recognizing these challenges, this article explores the feasibility of using Large Language Models (LLMs) to ameliorate data scarcity in code-mixing research. Known for their generative capabilities, we test whether multilingual LLMs can be prompted to create code-mixed data, and if so, to what degree. Using a code-mixing scale of 0 to 3 (0-no code-mixing; 1-loanword usage; 2-topic-related entities; 3-beyond entities), we compare performance across different models on different languages and assess whether these outputs are of a quality decent enough for research deployment. 

To do this, we hone in on languages in South East Asia (SEA). Home to more than 680 million people and over 1200 languages, code-mixing is particularly prevalent in this region due to their extended histories of language and cultural cross-fertilization (Figure~\ref{fig:SEA})~\cite{goddard2005languages,bautista2006southeast,reid-etal-2022-m2d2}. Marked by its distinctive multiracial and multilingual composition today, SEA exhibits unparalleled linguistic diversity and presents an opportunity to further research on multiple under-explored languages and practices\footnote{Major languages in SEA countries belong to different language families such as Indo-European, Thai, Austronesian, Sino-Tibetan, Dravidian, and Austro-Asiatic. Furthermore, there are at least thousands of major and minor SEA languages.}~\cite{migliazza1996mainland,goddard2005languages, joshi-etal-2020-state, aji-etal-2022-one,cahyawijaya2023nusacrowd}. 
Despite so, multilingual NLP research has devoted scant attention to examining code-mixing in this region, and publicly available code-mixed datasets relevant to its communities remain limited \cite{lyu2010seame,winata2022decades}. 

%One explanation for this is that code-mixing is observed more often in colloquial settings and speech-based communication, leading to challenges in collecting extensive datasets that can be used for language processing research. While it remains critical to better understand code-mixing computationally to allow better downstream performance in real-world contexts involving diverse ethnic, cultural, and linguistic expressions~\citep{sitaram2019survey,lovenia-etal-2022-ascend,hershcovich-etal-2022-challenges}, there is a limited number of publicly available code-mixed datasets representative of the SEA communities \cite{lyu2010seame,winata2022decades}.
% and even these public datasets have largely focused on more extremely high-resource languages like English and Mandarin~\citep{lyu2010seame}. 

%Our focus on SEA presents an opportunity to contribute to a region with diverse under-studied and under-resourced languages \cite{joshi-etal-2020-state,aji-etal-2022-one}. 

In this effort, we prompt LLMs such as ChatGPT, InstructGPT (davinci-002 and davinci-003) \cite{ouyang2022rlhf}, BLOOMZ \cite{muennighoff2022bloomz}, and Flan-T5-XXL \cite{chung2022flant5} to automatically generate code-mixed text that bilingually mixes English with either \textbf{Malay, Indonesian, Chinese, Tagalog, or Vietnamese}. All of these five SEA languages (alongside English) are used across six SEA countries, namely Singapore, Malaysia, Brunei, Philippines, Indonesia, and Vietnam. Furthermore, they belong to different language families---Indo-European, Austronesian, Sino-Tibetan, and Austro-Asiatic. An example of such a prompt is: "Write an English and Tagalog code-mixed sentence about Artificial Intelligence." In addition, we prompt these LLMs to generate texts in \textbf{Singlish} (a portmanteau of Singapore and English), a creole language that borrows from multiple languages. An example of a prompt involving Singlish looks like this: "Imitate the speaking style of a person who can speak Singlish in one sentence about family." We then ask native speakers to annotate the level of code-mixing in these generated outputs. We provide the complete set of prompts and code-mixed responses here: \url{https://github.com/Southeast-Asia-NLP/LLM-Code-Mixing}.

To the best of our knowledge, this marks the first attempt at studying the generation of synthetic code-mixed data through prompting LLMs in a zero-shot fashion without any monolingual reference texts or explicit linguistic constraints \citep{tarunesh-etal-2021-machine,rizvi-etal-2021-gcm,mondal-etal-2022-cocoa}. We discover that---for certain prompts---ChatGPT is able to follow instructions and generate syntactically sound code-mixed texts for the five SEA languages aforementioned up to 68\% success rate. For Singlish, ChatGPT and InstructGPT (davinci-003)'s performances are particularly noteworthy, clocking at 96\% across all prompts. In comparison, models such as BLOOMZ and Flan-T5-XXL are unable to produce code-mixed texts altogether (despite being advertised as multilingual). This leads us to conclude that code-mixing, at least as of today, is not considered an essential component of many multilingual LLMs. Moreover, the opaque creation of models like ChatGPT makes it difficult to ascertain the mechanisms that enable code-mixing generation.

Meanwhile, despite ChatGPT and InstructGPT's relative success in terms of performance, the code-mixing capabilities of these models are dampened by word choice errors that lead to semantic inaccuracies. In other words, while the grammatical arrangement of words in the output sentences may be correct, further scrutiny reveals misuses of words or concepts that ultimately diminish the fluency of these utterances. 
Furthermore, while ChatGPT can explain how the sentences are code-mixed, the explanations may be inaccurate. 
Thus, relying on LLMs to generate synthetic code-mixed data without extensive human supervision is discouraged. By highlighting the limited promises of LLMs in a specific form of low-resource data generation, we hope that NLP researchers think more critically 
about using such systems to produce synthetic data. 

%With little transparency into the training data supporting models such as ChatGPT and InstructGPT, it is difficult to ascertain the consistency of their code-mixing capabilities. Even for languages where, we recommend researchers to rely on human annotation 

%It is unknown which languages and what kind of data both ChatGPT and InstructGPT may have been exposed to, making it difficult to determine the source for their ability to generate code-mixed data.



% \begin{itemize}
%     \item How natural is ChatGPT on generating Code-mixed sentences?
%     \item How is the generation diversity over different language pairs? Are they culturally related with the languages?
%     \item Is there any common code-mixing pattern that we can observe from ChatGPT? Does it cover all the possible code-mixed sentences in these languages?
% \end{itemize}


%%% DESCRIBE FINDINGS HERE


% Despite the prevalence of code-mixing, multilingual natural language processing research has traditionally avoided studying code-mixed text. Among the reasons for this is that code-mixing is observed more often in spoken than written form, leading to an absence of extensive data sets that can be used for language processing research~\citep{winata2021multilingual}. Text that utilizes multiple languages instead of consistently utilizing a single language can be labelled as 'contaminated' and discarded. Moreover, the linguistic structure of a code-mixed utterance is distinct from that of its component languages as it combines the grammatical structure of each language. Modelling the dynamics of a code-mixed utterance is thus not necessarily equivalent to modelling the dynamics of each language, making it even more difficult for current models to process the data. Furthermore, code-mixed text presents challenges in machine translation or masked-language-modeling. Understanding code-mixing allows better downstream performance in real-world data involving demographics of diverse culture, ethnicity, and language that code-mix~\citep{sitaram2019survey,hershcovich-etal-2022-challenges,winata2022decades}.

% As large language models demonstrate broad zero-shot performance across a wide range of tasks, their mastery of multiple languages is increasingly tested. Typically, tasks such as machine translation or multilingual summarization are used, all of which expect monolingual output. Evaluation of code-mixed tasks remains understudied.