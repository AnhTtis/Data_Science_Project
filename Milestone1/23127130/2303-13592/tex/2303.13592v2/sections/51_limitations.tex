\section{Limitations}
\subsection{Sample Size}
Our observations were limited to 180 prompts across five topics and six SEA languages. With the recent release of ChatGPT API, our immediate next step is to automatically generate more code-mixed samples and present a more robust and generalizable conclusion about ChatGPT's ability to generate synthetic code-mixed data.

\subsection{Language Models}
Our work only covers instruction-tuned language models. In future work, we will include a comparison between multilingual models that are not finetuned with instructions---for example, GPT3 (davinci) \cite{brown2020gpt3} and BLOOM \cite{scao2022bloom}---to explore the effects of instruction tuning in generating code-mixed data.

\subsection{Evaluation} 
While we annotated the degree of code-mixedness and checked for semantic or fluency issues, we were unable to systematically compare LLM-generated outputs against human-generated code-mixed data. In future efforts, the involvement of native speakers in such tasks is key in ensuring adequate fluency and naturalness levels. We can also further analyze the data with automated metrics such as CMI and M-/I-index, which requires human efforts in annotating each word token with the most accurate language labels.

\subsection{Prompt Templates}
Our study only uses prompt templates written in English to prompt language models in a zero-shot manner. In future follow-ups, we will (1) use code-mixed prompt templates such as "Generate an English-Bahasa sentence" instead of "Generate an English-Malay sentence" and (2) investigate LLMs' capability in generating code-mixed data with in-context few-shot examples. 

\subsection{Languages}
Our study focuses on generating code-mixed data for English-SEA language pairs. For future studies, we plan to investigate generating code-mixed data for non-English language pairs, such as Malay-Chinese and Indonesian-Javanese, and more SEA languages, such as Thai and Burmese. 