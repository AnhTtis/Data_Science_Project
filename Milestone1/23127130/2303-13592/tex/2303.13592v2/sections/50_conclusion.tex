\section{Conclusion}
We demonstrate that ChatGPT and InstructGPT outperform other multilingual LLMs when prompted to generate code-mixed texts for South East Asian languages and that their performances are particularly noteworthy for Singlish. We also discover that publicly available multilingual LLMs such as BLOOMZ and Flan-T5-XXL are incapable of generating code-mixed data through zero-shot prompting. Nonetheless, we discover issues with accurateness, reliability, and fluency for code-mixed data generated by models such as ChatGPT. Therefore, we caution against using LLM-generated synthetic code-mixed data without the involvement of native speakers for annotating and editing.