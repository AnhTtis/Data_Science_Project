\begin{abstract}
While code-mixing is a common linguistic practice in many parts of the world, collecting high-quality and low-cost code-mixed data remains a challenge for natural language processing (NLP) research. The proliferation of Large Language Models (LLMs) in recent times compels one to ask: can these systems be used for data generation? In this article, we explore prompting multilingual LLMs in a zero-shot manner to create code-mixed data for five languages in South East Asia (SEA)---Indonesian, Malay, Chinese, Tagalog, Vietnamese, as well as the creole language Singlish.
We find that ChatGPT shows the most potential, capable of producing code-mixed text 68\% of the time when the term "code-mixing" is explicitly defined. Moreover, both ChatGPT's and InstructGPT's (davinci-003) performances in generating Singlish texts are noteworthy, averaging a 96\% success rate across a variety of prompts. Their code-mixing proficiency, however, is dampened by word choice errors that lead to semantic inaccuracies. Other multilingual models such as BLOOMZ and Flan-T5-XXL are unable to produce code-mixed texts altogether. By highlighting the limited promises of LLMs in a specific form of low-resource data generation, we call for a measured approach when applying similar techniques to other data-scarce NLP contexts.






% We also provide qualitative analysis for scenarios where ChatGPT fails to follow the prompts and highlight its unreliability in reasoning about how the text is code-mixed. \todo{(first draft of the abstract.)}
\end{abstract}