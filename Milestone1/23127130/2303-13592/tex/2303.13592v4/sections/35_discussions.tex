\section{Implications for LLMs and Ways Forward}

In this section, we walk through various implications of our work for understanding the deployment of LLMs for synthetic data generation in low-resource settings, multilinguality in LLMs, importance of code-mixing ability in generative LLMs, and research transparency.

\paragraph{Deploying LLMs for Low-Resourced Data Generation} By putting LLMs' generative capabilities to the test, we ask in this work if they can generate high-quality and low-cost code-mixed texts for researchers working on a topic plagued by limited data availability. While we conclude that ChatGPT has shown relative success in generating code-mixed texts for some SEA languages, we advise researchers to exercise heavy caution when using this data generation technique. Even for Singlish, which outperforms the other languages examined, we find that syntactically-sound responses may contain semantic inaccuracies that are difficult for non-native speakers to detect. Furthermore, its explanations may be misleading. Due to the lack of reliability, we strongly suggest researchers to implement extensive human checks with native speakers if they wish to pursue this method of data generation.

\paragraph{Multilingual $\neq$ Code-Mix Compatible} Our results with BLOOMZ and Flan-T5-XXL show that the ability to code-mix is not acquired by LLMs after pretraining and/or finetuning with multilingual data \cite{lauren2022roots,muennighoff2022bloomz,chung2022flant5}. In other words, for most NLP models, multilinguality simply means that the same system can process tasks and generate outputs in multiple languages, but not necessarily in the same sentence. %In other words, many existing models are not able to code-mix like how many multilingual speakers would. In comparison to multilingual speakers, who rely on both monolingual and code-mixed speech, multilingual models then are lagging behind.
By highlighting this limitation, we echo previous research motivating the inclusion of code-mixing abilities in NLP models. % By highlighting this limitation, we compel researchers to consider code-mixing as a core feature of many people's multilingual repertoire across the world. Building LLMs that include code-mixing not only allows NLP researchers to more accurately capture the dynamic elements of many languages, 
Doing so requires NLP models to capture the dynamics of combining languages that have different degrees of typological affinities, as well as pragmatic and contextual features such as tone, formality, and other cultural nuances~\cite{winata2020crossaccent,lai-nissim-2022-multi,kabra2023multilingual}. %it also improve one's understanding 
%of tone, formality, and other cultural aspects embedded in conversations. Finally, we hope that by conceiving multilinguality to go beyond language inclusion and encompass language-\textit{mixing}, we can develop representative and equitable LLMs that cater to the needs of marginalized linguistic communities across the world. To this end, we recommend researchers to include more code-mixed data in model pretraining and explicitly train the general-purpose LLMs to handle code-mixing.

\paragraph{Towards More Inclusive Language Technology} 
Recognizing that generative LLMs are the primary driving force behind the advancement of AI conversational agents and speech technology \cite{thoppilan2022lamda,bloomchat,pratap2023scaling}, we emphasize the significance of incorporating code-mixed output recognition and generation capabilities in LLMs in order to enhance the inclusivity and humaneness of language technology. By enabling conversational agents to reflect the language-mixing patterns of the users, people can communicate in ways that are more comfortable and authentic to their linguistic identities. In fact, a recent study by \citet{bawa2020multilingual} has shown that multilingual users strongly prefer chatbots that can code-mix. Removing the need for people to adjust their speech patterns to become legible to machines would not only mitigate the effects of linguistics profiling \cite{baugh2005linguistic,dingemanse-liesenfeld-2022-text} and hegemonic, Western-centric technological designs, but also enable users to develop more trust with language technology through naturalistic dialogue interactions.

% Voice assistants supported by code-mixing-friendly automatic speech recognition (ASR) systems~\cite{winata2020meta,winata2020crossaccent} could help people communicate in ways that are potentially more naturalistic and authentic to their linguistic identities.


% \paragraph{Beyond Written Code-Mixing} 
% As the LLM landscape continues to broaden, we anticipate that emerging models will likely be increasingly multimodal. Text-based LLMs that serve as conversational agents will likely start to include speech or visual units (e.g., GPT-4). Owing to the prevalence of code-mixing in vocal speech, including the ability to recognize and generate code-mixed outputs in LLMs will make the technology more inclusive and humane \cite{dingemanse-liesenfeld-2022-text}. For instance, voice assistants supported by code-mixing-friendly automatic speech recognition (ASR) systems~\cite{winata2020meta,winata2020crossaccent} could help people communicate in ways that are potentially more naturalistic and authentic to their linguistic identities. Removing the need for people to adjust their speech patterns to become legible to machines could further mitigate the effects of linguistics profiling \cite{baugh2005linguistic,dingemanse-liesenfeld-2022-text} and hegemonic, Western-centric technological designs.

\paragraph{Research Transparency} Aside from showing that ChatGPT and InstructGPT \textit{can} code-mix, we cannot confidently identify \textit{how} the models do so due to the lack of transparency in how these systems are developed. Without a window into training data and engineering processes that went into models like ChatGPT, we can only speculate that their training data includes a substantial amount of code-mixed texts.
%they were not only fed multilingual texts but were also explicitly trained to handle code-mixing. 
To help facilitate greater levels of transparency and accountability, we urge forthcoming LLMs 
%that have code-mixing capabilities 
to be more open about how the models were developed and to document accurately and comprehensively the training data used.

%\paragraph{Future research}
%Although we see code-mixed data collected from native speakers as the 'gold standard', we recognize that time and resource-constrained researchers may use LLMs like ChatGPT for data generation. Since our work demonstrates that LLMs are sensitive to potential biases in prompts and may generate sentences that suffer from semantic inaccuracies, it is crucial to design a filtering mechanism (such as human annotators) to control the quality of the synthetic data. \todo {we need more stuff here}

% Nudge OpenAI to be open. - suggests data include CM data.

% Non-transparency has been actively studied - inability to do something well. We are looking for ability to do something. 

% Ethics consideration generation - abusive languages / cultural respectful - people more likely to believe texts come from people. 

% Publicly available MLM bad because they are not finetuned on these CM tasks where ChatGPT is probably exposed to. \url{https://twitter.com/ShayneRedford/status/1630252835404218371?s=20}