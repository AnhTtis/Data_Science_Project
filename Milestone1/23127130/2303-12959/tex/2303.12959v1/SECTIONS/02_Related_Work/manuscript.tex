\vspace{-0.5em}
\section{Related Work}
\vspace{-0.5em}
\noindent \textbf{Disentanglement Learning.} 
Disentanglement learning aims at learning
generative factors existing in the dataset, that is, disentangled representation learning.
Though the definition of disentanglement is still an open topic~\citep{Kumar2018DIPVAE,Do.2020,abdi2019preliminary,iclr/DuanMSWBLH20/UDR,mo2023representation}, it is widely accepted that the redundancy between latent variables diminishes disentanglement.
Penalizing the Total Correlation (TC)~\citep{Watanabe.1960} is an important direction in disentanglement learning, and many SOTA methods are based on it~\citep{Chen2018betatcvae,Kim2018factorvae,esmaeili2019structured,Kumar2018DIPVAE,Wei_2021_ICCV}.
PM algorithm promotes factorial codes but only works for binary codes~\citep{Schmidhuber.1992};
Though ICA~\citep{comon1994independent} and PCA~\citep{wold1987principal} ensure independence theoretically, they extract linear representations.
Until recently, deep learning has made it workable.
FactorVAE~\citep{Kim2018factorvae} applies an adversarial training method to approximate and penalize the TC term.
\btcvae{}~\citep{Chen2018betatcvae} decomposed the KL term into three parts: mutual information (MI), total correlation (TC), and dimensional-wise KL (DWKL).
However, these methods rely on the estimation of TC, which is extremely hard for high-dimensional spaces.



\noindent\textbf{Information Bottleneck.} 
Information bottleneck theory~\citep{Tishby.1999,Shannon.1948} plays a vital role in interpreting neural networks.
Some methods encourage disentanglement by increasing the information bottleneck while training~\citep{JeongS19a,Burgess.2018,shao2022rethinking,Dupont.2018,DBLP:journals/ml/WuDEFT22}.
These methods vary in the way of expanding the IB.
CascadeVAE~\citep{JeongS19a} sequentially relieves one latent variable at one stage to increase the IB.
DynamicVAE~\citep{shao2022rethinking} designs a non-linear PI controller for manipulating $\beta$ to control IB steadily increasing.
DEFT~\citep{DBLP:journals/ml/WuDEFT22} applies a multi-stage training strategy with separated encoders to extract one factor at one stage according to its information freezing point (IFP).
However, the above incremental models, increasing the IB while training, suffer from the information diffusion (ID) problem ~\citep{DBLP:journals/ml/WuDEFT22} that the disentangled representation may diffuse the learned information into other variables.
This work presents a novel framework with a decremental information bottleneck to solve the ID problem.

\noindent\textbf{Hierarchical Latent Variables.} 
Normalizing Flow~\citep{rezende2015variational,kingma2016improved} also uses hierarchical latent layers to generate an arbitrary distribution. 
Unlike Normalizing Flow, each layer aims to encourage disentanglement or reconstruction.
Besides, Normalizing Flow gradually increases the complexity of the output distribution after entering a new layer.
In contrast, our model reduces the complexity layer by layer.
\fix{R2Q6}{LadderVAE~\citep{Snderby2016LadderVAE} also applies hierarchical latent variables in the encoder, but it using a symmetry structure decodes these latent variables in hierarchy.
Therefore, the information among the $i$-th layer will increase comparing to the last layer.
}