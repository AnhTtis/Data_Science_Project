% \vspace{-0.5em}
\section{Related Work}

\paragraph{Disentanglement Learning.} 
Disentanglement learning aims to learn generative factors existing in the dataset~\cite{Bengio.2013}.
Although the formal definition of disentanglement is still an open topic, it is widely accepted that the redundancy between latent variables diminishes disentanglement~\citep{Do.2020}.
Penalizing the Total Correlation (TC)~\citep{Watanabe.1960} is an important direction in disentanglement learning, and many state-of-the-art (SOTA) methods are based on it~\citep{Chen2018betatcvae}.
Predictability Minimization (PM) algorithm ~\citep{Schmidhuber.1992} promotes factorial codes but only works for binary codes;
Though ICA~\citep{comon1994independent} and PCA~\citep{wold1987principal} ensure independence theoretically, they extract linear representations.
Recently, deep learning has made this more feasible. 
FactorVAE~\citep{Kim2018factorvae} applies an adversarial training method to approximate and penalize the TC term.
\btcvae{}~\citep{Chen2018betatcvae} decomposed the KL term into three parts: mutual information (MI), total correlation (TC), and dimensional-wise KL (DWKL).
They achieve good performance by optimizing the TC term and avoiding penalizing the MI term.
However, the TC-based methods introduce a strong assumption that generative factors are independent, which is impractical for real-world problems.

\paragraph{Information Bottleneck.} 
Information bottleneck theory~\citep{Tishby.1999,Shannon.1948} plays a vital role in interpreting neural networks.
Some methods encourage disentanglement by increasing the IB during training~\citep{Burgess.2018}.
These methods differ in the way they expand the IB. 
CascadeVAE~\citep{JeongS19a} sequentially relieves one latent variable at each stage to increase the IB.
DynamicVAE~\citep{shao2022rethinking} designs a non-linear PI controller for manipulating $\beta$ to control the steadily increasing IB.
DEFT~\citep{DBLP:journals/ml/WuDEFT22} applies a multi-stage training strategy with separated encoders to extract factors separately at different stages.
However, the above incremental models, which increase the IB during training, suffer from the information diffusion (ID) problem~\citep{DBLP:journals/ml/WuDEFT22}, as the disentangled representation may diffuse the learned information into other variables when expanding the IB.

\paragraph{Hierarchical Latent spaces.} 
Normalizing Flow~\citep{rezende2015variational,kingma2016improved} uses hierarchical latent spaces to generate an arbitrary distribution. Unlike Normalizing Flow, each space in our model aims to encourage disentanglement or reconstruction. Additionally, Normalizing Flow gradually increases the complexity of the output distribution after entering a new space. In contrast, our model reduces the complexity space by space.
