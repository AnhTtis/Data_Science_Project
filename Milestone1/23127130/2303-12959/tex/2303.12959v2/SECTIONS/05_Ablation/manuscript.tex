\subsection{Experimental Analysis}
\label{sec:ablation}

In this section, we conduct ablation studies to evaluate the benefits of the proposed Hierarchical Latent Spaces (HiS) and Disentanglement-invariant Transformation (DiT). We also explore the effect of these spaces on the balance between disentanglement and reconstruction.

\input{tabs/ab_component}

% \noindent\textbf{HiS \& DiT.}\quad
\paragraph{HiS \& DiT.}
To demonstrate the effectiveness of the proposed Hierarchy Latent Spaces (HiS) and Disentanglement-invariant Transformation (DiT), we performed ablation experiments on the following scenarios:
1) HiS and DiT are removed, which equals to $\beta$-VAE;
2) HiS is replaced with multiple symmetric encoders instead of the hierarchy encoder, where latent spaces are independent;
3) DiT is replaced with Linear Transformation ($\tau_i(\vect{z_{i+1}}|\vect{z_{i}})=\vect{w} \vect{z_{i}})$, where $\vect{w}$ is an arbitrary matrix.
4) The proposed model DeVAE.
Unlike previous experiments, we compared these models on the dSprites dataset using three spaces ($\{\beta_i\} = [1,10,40]$) to show how DiT affects the connection between spaces.
Table~\ref{tab:ab_component} shows the MIG and reconstruction for each space. 
From the results, we can see that MS and HiS without DiT improve disentanglement slightly. Adding DiT can make sure all latent spaces have same disentanglement. 
DeVAE achieves the best balance through sharing disentanglement at the third space and learning reconstruction at the first space. Thus, the key to DeVAE lies in connecting HiS through DiT.


\input{figs/recon_mig}
\paragraph{Pressure on Space.}
We argue that the primary role of the first space is to optimize reconstruction and the second space is to optimize disentanglement.
We investigated DeVAE with two latent spaces and applied the following rules to increase beta: 
1) Beta\_x: both spaces apply the same $\beta$, which equals to $\beta$-VAE.
2) Beta\_1-x: only change the pressure of the second space.
3) Beta\_x-40: only change the pressure of the first space.
Figure~\ref{fig:recon_mig} demonstrates the MIG and reconstruction by increasing beta. Each point denotes one experiment with corresponding beta.
One can see that the DeVAE has few reconstruction drop to get a high MIG score.
$\beta_0$ and $\beta_1$ have strong positive correlations with reconstruction error and MIG score respectively, meanwhile, the relationships to MIG and reconstruction are weaker.
Therefore, $\beta_0$ controls reconstruction and $\beta_1$ promotes disentanglement. 

% One can see that the disentanglement and reconstruction error increase over increasing beta for Beta\_x. Increasing the pressure of the second space promotes disentanglement. Reducing the pressure of the first space encourages reconstruction.
% In conclusion, our model optimizes disentanglement in the second space and shares it with the first space through DiT. Meanwhile, the first space focuses on reconstruction to achieve a good balance between the two goals.


\input{tabs/ablation.tex}
% \paragraph{Increasing spaces.}
% \noindent\textbf{Increasing spaces.}\quad
\paragraph{Increasing Spaces.}
The number of spaces is a crucial hyperparameter in our framework. Although the setting $K=2$ achieves remarkable performance, increasing the number of spaces may provide more opportunities to find an optimal solution. However, more spaces require additional computational resources and make it more challenging to optimize the neural network.
In Table~\ref{tab:betas}, we compared tree settings: $\{\beta_i\} =[1,10,20,40,80]$, $\{\beta_i\} =[1,10,40]$, $\{\beta_i\} =[1,10]$.
Fortunately, redundant betas slightly reduce the performance, which means we can create redundant latent spaces spanning a wide range of $\beta$ values to obtain a good model without tuning the hyperparameter extensively.


% \paragraph[]{Effect of Scale $s$.}
% Increasing $s$ will add the weights of higher beta, encouraging disentanglement more than reconstruction fidelity.
% It is a crucial hyperparameter to balance the objectives of latent spaces.
% Note that our model equals the vanilla VAE when $s=0$.
% In Table~\ref{tab:scale}, we compared the effects of choosing $s$ and reported the mean$\pm$std scores of MIG~\citep{Chen2018betatcvae} and reconstruction.
% For most cases, $s=1$ is a good choice.

% \input{figs/betas.tex}
