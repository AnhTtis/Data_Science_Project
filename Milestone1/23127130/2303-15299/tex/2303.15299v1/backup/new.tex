\documentclass[letterpaper, 12pt, journal, twoside]{support/IEEEtran}
\usepackage[fleqn]{amsmath}
\usepackage{times}
\usepackage[pdftex]{graphicx}
\usepackage{subfigure}
\usepackage{amsmath,amssymb,amsopn,amstext,amsfonts}
\usepackage{cancel}
\usepackage[noadjust]{cite}
\usepackage{soul}
\usepackage{caption}
\captionsetup{font={small}}

\captionsetup[figure]{labelfont={},textfont={}}


\usepackage{balance}
\usepackage{color}
\usepackage{mathtools}
% \usepackage{algorithm}
% \usepackage{algorithmic}
\usepackage{bm}
%\newtheorem{theorem}{Theorem}
\usepackage{diagbox}
\usepackage{float}
\usepackage{epstopdf}
\usepackage{url}
\usepackage{multirow}
\usepackage{tikz}
\usepackage{subeqnarray}
\usepackage{cases}
\usepackage{booktabs}
\usepackage[linkcolor=black,citecolor=black,urlcolor=black,colorlinks=true]{hyperref}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\newtheorem{myTheo}{Theorem}
%\newtheorem{thm}{Theorem}[section] %如果不采用章节号做前缀，则不用[section]
\newtheorem{myDef}{Definition} %这句定义使得defn环境和thm共享编号
\newtheorem{lemma}{Lemma} %这句定义使得lem环境和thm共享编号
\newtheorem{myCollo}{Corollary}
\newtheorem{remark}{Remark}
%\newtheorem{lemma}{Lemma}
\newtheorem{myPro}{Proposition}
\newtheorem{assumption}{Assumption}
\newtheorem{example}{Example}
\soulregister\cite7
\soulregister\citep7
\soulregister\citet7
\soulregister\ref7
\soulregister\it7
\soulregister\pageref7

\bibliographystyle{support/IEEEtran}

\newcommand\px{\mathrel{/\mkern-5mu/}}  %平行
\newcommand{\ann}[1]{%
    \begin{tikzpicture}[remember picture, baseline=-0.75ex]%
        \node[coordinate] (inText) {};%
    \end{tikzpicture}%
    \marginpar{%
        \renewcommand{\baselinestretch}{1.0}%
        \begin{tikzpicture}[remember picture]%
            \definecolor{orange}{rgb}{1,0.5,0}%
            \draw node[fill=red!20,rounded corners,text width=\marginparwidth] (inNote){\footnotesize#1};%
    \end{tikzpicture}%
    }%
    \begin{tikzpicture}[remember picture, overlay]%
        \draw[draw = orange, thick]
            ([yshift=-0.2cm] inText)
                -| ([xshift=-0.2cm] inNote.west)
                -| (inNote.west);%
    \end{tikzpicture}%
}%

\graphicspath{{figures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg,.eps}
\IEEEoverridecommandlockouts
%\overrideIEEEmargins

\title{\LARGE \bf Learn-Estimation-Control via a Digitial Twin: A Resilient Formation Tracking control of Heterogeneous MAS against Composite Attacks}

%\title{Distributed Optimization in Prescribed-Time: Theory and Experiment}%
\author{
  \vskip 1em
  { 
  Xin Gong, \emph{Graduate Student Member, IEEE}, 
	Yukang Cui, \emph{Member, IEEE},
  Yiwen Liang
  }

  \thanks{
    This work was partially supported by the National Natural Science Foundation of China under Grant 61903258, 61973156, 61603180, Qatar National Research Fund NPRP12C-0814-190012. %(\emph{Corresponding author: Yukang Cui.}) %the National Natural Science Foundation of China under Grant 61903258

X. Gong is with the Department of Mechanical Engineering, The University of Hong Kong, Pokfulam Road, Hong Kong (e-mail: {\tt\small gongxin@connect.hku.hk}).


Y. Cui and T. Wang are with the College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen, 518060, China (e-mail: {\tt\small cuiyukang,szuwtn@gmail.com}).


  
%J. He is with the Department of Mechanical Engineering, The University of Hong Kong, Pokfulam Road, Hong Kong (e-mail: {\tt\small esmehe@connect.hku.hk}). 

%X. Gong is with the Department of Mechanical Engineering, The University of Hong Kong, Pokfulam Road, Hong Kong, and also with the College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen 518060, China. (e-mail: {\tt\small gongxin@connect.hku.hk}).
%China, and also
%with the Department of Mechanical Engineering, University of Hong Kong,
%Hong Kong
    
  }
%\thanks{$^{*}$ means the corresponding author.}
}

%\maketitle
%\author{}%\vspace{-0.0cm}
%%\thanks{This work was partially supported by.}% <-this % stops a space
%\thanks{$^{*}$These authors contribute equally and share the first authorship.}
%\thanks{$^{1}$Author is with the Group Robotics with Intelligent Planning (GRIP) Lab, Department of Mechanical Engineering, University of Hong Kong, Hong Kong,
%   {\tt\small gongxin@connect.hku.hk}}
%\thanks{Digital Object Identifier (DOI): see the top of this page.}
%\vspace{-0.5cm}}

% The note headers
%\markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2015}%
%{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for IEEE Journals}
\markboth{IEEE Transactions on ...}{GONG \MakeLowercase{\textit{et al.}}: Distributed Prescribed-time Consensus Observer on Directed Graphs}%{He \MakeLowercase{\textit{et al.}}: Resilient Path Planning of UAVs against Covert Attacks on UWB Sensors}











\begin{document}

in the design of distributed finite-time observer, which achieved the distributed fixed-time estimation w.r.t. the leader state on both undirected graphs \cite{zuo2017fixed2,zuo2019distributed} and directed ones \cite{zuo2019distributed}. As pointed in \cite{zuo2019distributed}, the proof based on the symmetry of Laplacian matrices is not applicable for directed topologies. Thus, it is not trivial to study the distributed finite-time observer on directed graphs. Notice that the fixed-time zero-error convergence is only guaranteed on undirected topologies \cite[Theorem 1]{zuo2019distributed}, while only fixed-time attractiveness of an error domain is proven in  \cite[Theorem 2]{zuo2019distributed}. Thus, it remains a big challenge to design a distributed finite-time zero-error observer on general directed topologies. Moreover, the needed time interval to achieve distributed observation in the above works \cite{fu2017finite,fu2016fixed,zuo2017fixed2,zuo2019distributed} depends on the settings of initial conditions and the network algebraic connectivity \cite{wu2005algebraic}, which put barriers in the way of their applications.







Two inevitable yet challenging difficulties arise when designing distributed finite-time observers for MAS:

\begin{enumerate}
  \item How can all followers obtain finite-time zero-error convergence since the actual states of each pinned leader are only available to only a portion of followers, especially on a directed topology?
  \item How to regulate the consensus observation time arbitrarily despite the influences of the initial states of the MAS and network algebraic connectivity, particularly for high-order MAS on large directed networks?
\end{enumerate}




Fortunately, recently proposed prescribed-time protocols in \cite{wang2018prescribed, gong2020distributed2} shed light on the solution of the above two issues. Motivated by \cite{wang2018prescribed, gong2020distributed2}, we formulate a kind of DPTO for each follower, featured by a new hybrid constant and time-varying scaling function. This design is fundamentally different from the previous distributed finite-time observer in \cite{fu2017finite,fu2016fixed,zuo2017fixed2,zuo2019distributed} based fractional power feedback, which has the following main contributions and characteristics:


\begin{enumerate}
\item  A new kind of cascaded DPTO, based on a \textbf{hybrid constant and time-varying feedback}, is developed for the agents on directed graphs, which achieves the distributed accurate estimation on each order of leader state in a cascaded manner. 
\item \textbf{Zero-error convergence on time-invariant/varying directed graphs}: In contrast to the previous work \cite{zuo2019distributed} which only guarantees finite-time attractiveness of a fixed error bound, we manage to regulate the observation error on directed graphs into zero in a finite-time sense. It is further found that the feasibility of this DPTO can be extended to some time-varying directed graphs.
%The difficulties caused by the asymmetrical Laplacian matrix under the circumstance of single-way directed communication topology are circumvented in the frameworks of distributed prescribed-time fault-tolerant control.
\item \textbf{Prescribed-time convergence}: This DPTO could achieve distributed zero-error estimation in a predefined-time manner, whose needed time interval is independent of the initial states of all agents and network algebraic connectivity. Thus, the observer design procedure is much more easily-grasped for the new users than that in \cite[Theorem 2]{zuo2019distributed}.
\end{enumerate}




\noindent\textbf{Notations:}
In this brief, $\boldsymbol{1}_m$ (or $\boldsymbol{0}_m$) denotes a column vector of size $m$ filled with $1$ (respectively, 0). Denote the index set of sequential integers as $\textbf{I}[m,n]=\{m,m+1,\ldots~,n\}$ where $m<n$ are two natural numbers. Define the set of real numbers, positive real numbers and nonnegative real numbers as $\mathbb{R}$, $\mathbb{R}_{>0}$ and $\mathbb{R}_{\geq 0}$, respectively. ${\rm diag}({b})$ means a diagonal matrix whose diagonal elements equal to a given vector ${b}$.
For a given symmetric matrix $A\in \mathbb{R}^{n\times n}$, its spectrum can be sorted as: $\lambda_1(A)\leq\lambda_2(A) \leq\ldots \leq\lambda_n(A)$.





\label{introduction}
\section{Introduction}
\IEEEPARstart{T}{he} last decade has witnessed substantial progresses contributed by various industries (see \cite{ xu2020distributed, liang2016leader, hua2017distributed, de2014controlling} and references therein) on distributed coordination of multi-agent systems (MAS). 
In this brief, we consider the leader-following scenarios \cite{liang2016leader} rather than leaderless ones \cite{hua2017distributed}, where only a small portion of followers is  pinned (directly connected) to the leader. As pointed out in \cite{de2014controlling}, the formation error (consensus error) suffers from biased measuring noise among robots. Moreover, the actuation faults may also propagate among the MAS networks, which pose a non-negligible threat to the collective control of MAS. An alternative and easily realized method to overcome the above harmful measuring noise and fault propagation is introducing a distributed observer for each agent and reassigning the control input according to the estimated information. Similar to the distributed consensus observer defined in \cite{zuo2019distributed}, herein, we intend to design a kind of distributed prescribed-time observers (DPTO), which could reconstruct the leader state for all followers, especially these unpinned ones. Notice that the above distributed observers are different from the traditional Luenberger observers \cite{9311845} focusing on reconstruction on the unmeasured states. Also, this kind of distributed observers \cite{de2014controlling,fu2017finite,fu2016fixed,zuo2017fixed2,zuo2019distributed} could eradicate the notorious communication loop problem \cite{khoo2014multi} encountered in traditional convey communication mechanism.
One of the key properties of a superior distributed observer is to achieve distributed estimation quickly with little constraint on the communication topologies and high accuracy. Unlike the distributed observer in \cite{de2014controlling} which only owns asymptotical convergence, Fu \emph{et. al.} first proposed a kind of distributed fixed-time observer for first-order \cite{fu2017finite} and second-order MAS \cite{fu2016fixed}, respectively. However, the above two works employ two fractional power feedback terms, that is, $\frac{p}{q}$ and  $2-\frac{p}{q}$ with $q>p>0$, which are too cumbersome to extend to high-order dynamics. Zuo \emph{et. al.} further employed single fractional power feedback ($\gamma>1$) in the design of distributed finite-time observer, which achieved the distributed fixed-time estimation w.r.t. the leader state on both undirected graphs \cite{zuo2017fixed2,zuo2019distributed} and directed ones \cite{zuo2019distributed}. As pointed in \cite{zuo2019distributed}, the proof based on the symmetry of Laplacian matrices is not applicable for directed topologies. Thus, it is not trivial to study the distributed finite-time observer on directed graphs. Notice that the fixed-time zero-error convergence is only guaranteed on undirected topologies \cite[Theorem 1]{zuo2019distributed}, while only fixed-time attractiveness of an error domain is proven in  \cite[Theorem 2]{zuo2019distributed}. Thus, it remains a big challenge to design a distributed finite-time zero-error observer on general directed topologies. Moreover, the needed time interval to achieve distributed observation in the above works \cite{fu2017finite,fu2016fixed,zuo2017fixed2,zuo2019distributed} depends on the settings of initial conditions and the network algebraic connectivity \cite{wu2005algebraic}, which put barriers in the way of their applications.







Two inevitable yet challenging difficulties arise when designing distributed finite-time observers for MAS:

\begin{enumerate}
  \item How can all followers obtain finite-time zero-error convergence since the actual states of each pinned leader are only available to only a portion of followers, especially on a directed topology?
  \item How to regulate the consensus observation time arbitrarily despite the influences of the initial states of the MAS and network algebraic connectivity, particularly for high-order MAS on large directed networks?
\end{enumerate}




Fortunately, recently proposed prescribed-time protocols in \cite{wang2018prescribed, gong2020distributed2} shed light on the solution of the above two issues. Motivated by \cite{wang2018prescribed, gong2020distributed2}, we formulate a kind of DPTO for each follower, featured by a new hybrid constant and time-varying scaling function. This design is fundamentally different from the previous distributed finite-time observer in \cite{fu2017finite,fu2016fixed,zuo2017fixed2,zuo2019distributed} based fractional power feedback, which has the following main contributions and characteristics:


\begin{enumerate}
\item  A new kind of cascaded DPTO, based on a \textbf{hybrid constant and time-varying feedback}, is developed for the agents on directed graphs, which achieves the distributed accurate estimation on each order of leader state in a cascaded manner. 
\item \textbf{Zero-error convergence on time-invariant/varying directed graphs}: In contrast to the previous work \cite{zuo2019distributed} which only guarantees finite-time attractiveness of a fixed error bound, we manage to regulate the observation error on directed graphs into zero in a finite-time sense. It is further found that the feasibility of this DPTO can be extended to some time-varying directed graphs.
%The difficulties caused by the asymmetrical Laplacian matrix under the circumstance of single-way directed communication topology are circumvented in the frameworks of distributed prescribed-time fault-tolerant control.
\item \textbf{Prescribed-time convergence}: This DPTO could achieve distributed zero-error estimation in a predefined-time manner, whose needed time interval is independent of the initial states of all agents and network algebraic connectivity. Thus, the observer design procedure is much more easily-grasped for the new users than that in \cite[Theorem 2]{zuo2019distributed}.
\end{enumerate}




\noindent\textbf{Notations:}
In this brief, $\boldsymbol{1}_m$ (or $\boldsymbol{0}_m$) denotes a column vector of size $m$ filled with $1$ (respectively, 0). Denote the index set of sequential integers as $\textbf{I}[m,n]=\{m,m+1,\ldots~,n\}$ where $m<n$ are two natural numbers. Define the set of real numbers, positive real numbers and nonnegative real numbers as $\mathbb{R}$, $\mathbb{R}_{>0}$ and $\mathbb{R}_{\geq 0}$, respectively. ${\rm diag}({b})$ means a diagonal matrix whose diagonal elements equal to a given vector ${b}$.
For a given symmetric matrix $A\in \mathbb{R}^{n\times n}$, its spectrum can be sorted as: $\lambda_1(A)\leq\lambda_2(A) \leq\ldots \leq\lambda_n(A)$.AAAAAA
{\color{blue}
\subsection{Graph Theory}
In this article, N follower agents and a leader agent are considered.
 Define a digraph $\mathcal{G } =(\mathcal{V}, \mathcal{E}, \boldsymbol{A} )$, where $\mathcal{V}=\{ 1, 2, \ldots~ , N \}$ indicates the vertex set, $\mathcal{E} \subset \mathcal{V} \times \mathcal{V}$  the edge set, $\boldsymbol{A}=[a_{ij}] \in \mathbb{R}^{N\times N} $  the associated adjacency matrix.For $i,\ j \in \mathcal{V}$, $a_{ij}= 1$ if only if $(i,\ j)\in \mathcal{E}$ and otherwise,$a_{ij}= 0$.The in-degree of $v_i$ is defined as $d_i =  \sum_{j \in \mathcal{N}_{i}} a_{ij}  $. Let 
 $L=D-A$, where $D=diag\{d_1, d_2, \ldots~, d_N \}\in \mathbb{R}^{N\times N}$.A path from $i$ to $i$ is a sequence of edges in the form \{($i$,$m$), ($m$,$n$), \ldots~, ($k$,$j$) \}. If there exists a path between any vertexes $j$ to $i$,  then the undirected graph $\mathcal{G}$ is called connected.  Define $\mathcal{H}=\mathcal{L}+ \mathcal{M}$ , where $\mathcal{M}=diag\{a_{10}, a_{20}, \ldots~, a_{N0} \}$ with $a_{i0}=1$ representing that agent $i$ can receive a signal from the exosystem and $a_{i0}=0$ otherwise.
\subsection{Some Useful Definitions and Lemmas}
\begin{lemma}
Consider a Lyapunov function $V(t)$ , if there exist positive constants $a$ and $b$ such that (i) $\dot{V}(t)<bV(t) \ for \ t \in \ S_A $; (ii)$\dot{V}(t)<-aV(t) \ for \ t \in \ S_N$ , then following inequality holds:
\begin{equation*}
V(t)\leq e^{{b|S_A 0,t)|}-{a|S_N(0, t)|}}
\end{equation*}
\end{lemma}
\begin{lemma}
If $c$ and $d$ are nonnegative real numbers, and $p$ and $q$ are positive real numbers
such that $\frac{1}{p}+\frac{1}{q}=1$, then 
\begin{equation*}
cd\leq \frac{c^p}{p}+ \frac{d^q}{q}
\end{equation*}
\end{lemma}

 \begin{lemma}
The algebraic multiplicity of the eigenvalue $\lambda_0=0$ of the Laplacian matrix $L_0$ that belongs to the graph $\mathcal{G_0}$ is one if $\mathcal{G_0}$ contains a directed spanning tree.Furthermore, the other eigenvalues have positive real parts and the right and left eigenvectors associated with $\lambda_0=0$ are denoted by  $\boldsymbol{1}_N$ and 
$r_0 =[r_0,\ldots~,r_N]^{\mathrm{T}} \in \mathbb{R}^n$,  respectively,
where $\sum_{j=1}^{N}r_j=1$ with scalar $r_j$

\end{lemma}

\begin{myDef}\label{def41}
Persistent excitation condition. A bounded continuous function x0(t) is called persistent excitation if there exist positive constants $T$ , $t_0$ and such that the condition
\begin{equation*} 
\frac{1}{T}\int_{t}^{t+T}\ x_0(\tau)d\tau \ge \epsilon \boldsymbol{I}_q 
\end{equation*}
holds for all $t \ge {t_0}$


\end{myDef}

\subsection{System Description}
Consider the leader given by
\begin{equation*}
\dot x_0(t)=A_0x_0(t)
\end{equation*}
where $x_0(t)\in \mathbb{R}^{N\times N}$ is the state of the leader and A0 is an
unknown matrix.
The dynamic of each follower agent is given by

where $y_i(t)\in \mathbb{R}^q$ ,$x_i(t)\in \mathbb{R}^{n_i}$ and $u_i(t)\in \mathbb{R}^{m_i}$ represent the system output, system state and control input, respectively.$A_i$, $B_i$ ,$C_i$ are constant matrices.
By using the estimator state , the adaptive fault-tolerant resilient controller is designed as follows:
\begin{equation*}
u_i(t)=\hat{K}_i(\widetilde{t})\overline{x}_i(\widetilde{t})+\hat{U}_i(\widetilde{t})\overline{x}_{oi}(\widetilde{t})
\end{equation*}
where 
\begin{equation*}
\widetilde{t}=
\begin{cases}
t,t\in \Theta[t_0,t)\\
\delta_{2i+1} ,t\in [\delta_{2i+1},\delta_{2i+2})
\end{cases}
\end{equation*}
\begin{myTheo}\label{Plemma800}
Consider MASs (1) and (2) satisfying Assumptions 1–4. If the conditions in Theorem 1 are satisfied, then the fault-tolerant resilient consensus problem can be solved by using the adaptive fault-tolerant resilient controller (25) with the adaptive laws  and the learning-based estimator .
\end{myTheo}
 \textbf{Proof.} 
 \begin{equation*}
 \dot{\overline{x}}=\dot{x_i}-X_i\dot{x_{oi}}
 \end{equation*}
It can be calculated as
\begin{equation*}
\dot{\overline{x}}=\overline{A}_i\overline{x}_i+B_i\Lambda_i(\widetilde{K}_i\overline{x}_i+\widetilde{U}_ix_{oi})+\mathbb{Y}_i
\end{equation*}
Considering the Lyapunov function
 \begin{equation*}
V_2=\sum_{i=1}^N(\overline{x}^T_iP_i\overline{x}_i+\sum_{j=1}^{m_i}\Lambda_{ij}(\widetilde{K}_{ij} (\delta_{2i+1}) \Gamma^{-1}_{1ij}\widetilde{K}^T_{ij}(\delta_{2i+1})+\widetilde{U}_{ij}(\delta_{2i+1})\Gamma^{-1}_{2ij}\widetilde{U}^T_{ij}(\delta_{2i+1})))
\end{equation*}
where $\widetilde{K}_{ij}(\delta_{2i+1})=\hat{K}_{ij} (\delta_{2i+1})-K_{ij} (\delta_{2i+1})$ and $\widetilde{U}_{ij}(\delta_{2i+1})=\hat{U}_{ij}(\delta_{2i+1})-U_{ij}(\delta_{2i+1})$.The derivative of $V_2$  can be calculated as
\begin{equation*}
\begin{split}
\dot{V_2}=\sum_{i=1}^N\overline{x}^T_i(P_i A_i+A^T_i P_i+P_iB_i\Lambda_i K_i+K^T_i\Lambda_i B^T_iP_i)\overline{x}_i+\\ 2\sum_{i=1}^N(\overline{x}^T_i P_i \mathbb{Y}_i(\delta_{2i+1})+\sum_{j=1}^{m_i}\Lambda_{ij}\overline{x}^T_i P_i B_{ij}(\widetilde{K}_{ij}\overline{x}_i+\widetilde{U}_{ij}x_{oi}))+ \\ 2\sum_{j=1}^{m_i}\Lambda_{ij}(\dot{\widetilde{K}}_{ij}\Gamma^{-1}_{1ij}\widetilde{K}^T_{ij}+\dot{\widetilde{U}}_{ij}\Gamma^{-1}_{2ij}\widetilde{U}^T_{ij}))
\end{split}
\end{equation*}
By using Lemma 1 , we can obtain that
\begin{equation*}
P_i A_i+A^T_i P_i B_i \Lambda_i K_i+K^T_i \Lambda_i B^T_i P_i \leq -Q_i-\frac{1}{v_i}I
\end{equation*}
Using the Young’s inequality yields
\begin{equation*}
2\overline{x}^T_i P_i \mathbb{Y}_i \leq \frac{1}{v_i} \overline{x}^T_i \overline{x}_i+v_i\mathbb{Y}^T_i P^2_i\mathbb{Y}_i
\end{equation*}
We conclude that
\begin{equation*}
\sum_{j=1}^{m_i}(\Lambda_{ij}\overline{x}^T_i P_i B_{ij}\widetilde{K}_{ij}\overline{x}_i+\Lambda_{ij}\dot{\widetilde{K}}_{ij}\Gamma^{-1}_{1ij}\widetilde{K}^T_{ij})=0
\end{equation*}
 We have
\begin{equation*}
\sum_{j=1}^{m_i}(\Lambda_{ij}\overline{x}^T_i P_i B_{ij}\widetilde{U}_{ij}\overline{x}_i+\Lambda_{ij}\dot{\widetilde{U}}_{ij}\Gamma^{-1}_{1ij}\widetilde{U}^T_{ij})=0
\end{equation*}
We obtain 
\begin{equation*}
\dot{V}_2 \leq -\sum_{j=1}^N \overline{x}^T_i Q_i \overline{x}_i+\sum_{j=1}^N v_i \mathbb{Y}^T_i P_i \mathbb{Y}_i
\end{equation*}
Invoking Theorem 1, we conclude that there exist $\underline{\epsilon}$
 and $\overline{\epsilon}$ such that $\sum_{j=1}^N v_i \mathbb{Y}^T_i P_i \mathbb{Y}_i \leq \overline{\epsilon} e^{-\underline{\epsilon}t}$.Thus
\begin{equation*} 
 \dot{V}_2 \leq -\eta \sum_{j=1}^N {\Vert x \Vert}^2+\overline{\epsilon} e^{-\underline{\epsilon}t}
\end{equation*}
where $\eta=min_{i=1,2,\dots,N} \lambda_{min} (Q_i)$.Beside, we have 
\begin{equation*} 
V_2(t)-V_2(\overline{T})+\eta \sum_{j=1}^N \int_{\overline{T}}^{t} 
\Vert \overline{x}_i \Vert^2 d\tau \leq \frac{\overline{\epsilon}}{\underline{\epsilon}}(1-e^{-\underline{\epsilon}(t-\overline{T})})
\end{equation*} 
Thus
\begin{equation*} 
 \sum_{j=1}^N {\Vert x \Vert}^2+\sum_{j=1}^N\int_{\overline{T}}^{t} \Vert \overline{x}_i \Vert^2 d\tau \leq  \overline{B}
\end{equation*} 
where $\overline{B}=\frac{1}{\eta}(V_2(0)+\frac{\overline{\epsilon}}{\underline{\epsilon}}(1-e^{-\underline{\epsilon}(t-\overline{T})}))$.By using the $Bellman–Gronwall$ Lemma,it has
\begin{equation*} 
 \sum_{j=1}^N {\Vert x \Vert}^2 \leq -\sqrt{\overline{B}}e^{-(t-\overline{T})}
\end{equation*} 
By using these results,we have
\begin{equation*} 
{\lim_{x\to \infty}}\overline{x}_i(t)=0
\end{equation*} 
Invoking Theorem , it has
\begin{equation*} 
{\lim_{x\to \infty}}(y_i(t)-x_0(t))={\lim_{x\to \infty}}C_i(x_i-X_ix_0)={\lim_{x\to \infty}} C_i \overline{x}_i(t)
\end{equation*} 
Thus,we can conclude that
\begin{equation*} 
{\lim_{x\to \infty}}(y_i(t)-x_0(t))=0
\end{equation*} 
\begin{myTheo}\label{Plemma800}
Consider the MASs (1)–(2) under DoS attacks,
which satisfy Assumption 1. If the conditions in Lemma 7 are
satisfied and there exist scalars $\alpha>0$ ,$\beta>0$ and $\chi>0$ and a matrix $P>0$ such that the conditions i)$PA_0+A_0^T P-\beta P<0$;ii)$PA_0+A_0^T P-2(\chi/N^2)P+\alpha P<0$;iii)$\alpha+\beta<\alpha \tau_{G}$hold, then it can be guaranteed that the estimation error $x_{0i}(t)-x_0(t)$exponentially converges to zero in the presence of DoS attacks.
\end{myTheo}
\textbf{Proof.} 
Now, we consider the Lyapunov function $V(t)=\widetilde{z}^T(I\otimes P)\widetilde{z}$.Along with (17), we have
\begin{equation*}
\dot{\widetilde{z}}=(I\otimes A_0)\widetilde{z}-\chi (\mathcal{H}\otimes I)\widetilde{z}
\end{equation*} 
\begin{equation*}
\dot{V}(t)=2\widetilde{z}^T(I\otimes PA_0)\widetilde{z}-2\chi \widetilde{z}^T(\mathcal{H}(t)\otimes P)\widetilde{z}
\end{equation*} 
Due to the effect of DoS attacks, the dynamic of the system
will be switched among different models. Thus, we consider
the following situations.
1)For any $t \in S_N(0,\infty)$, there exists an interval $[\delta_{2i},\delta_{2i+1})$ such that $t \in [\delta_{2i},\delta_{2i+1})$. In this situation, we have
\begin{equation*}
\dot{V}(t)=\widetilde{z}^T(I\otimes (PA_0+A_0^T P))\widetilde{z}-2\chi \widetilde{z}^T(\mathcal{H}\otimes P)\widetilde{z}
\end{equation*}
Then, combining the second statement of this theorem
and the inequality (19) yield
\begin{equation*}
\dot{V}(t) \leq - \alpha V(t)
\end{equation*}
which implies that
\begin{equation*}
V(t) \leq e^{-\alpha(t-\delta_{2i}V(\delta_{2i})}
\end{equation*}
2)For any $t \in S_A(0,\infty)$, there exists an interval $[\delta_{2i+1},\delta_{2i+2})$ such that $t \in [\delta_{2i+1},\delta_{2i+2})$.In this situation, we get 
\begin{equation*}
\dot{V}(t) \leq \widetilde{z}^T(I\otimes (PA_0+A_0^T P))\widetilde{z}
\end{equation*}
Invoking the first statement of this theorem and the
inequality (22), we obtain that
\begin{equation*}
V(t) \leq e^{\beta(t-\delta_{2i+1}V(\delta_{2i+1})}
\end{equation*}
We now conclude from (21), (23), ii) in Assumption 1 and
Lemma 3 that
\begin{equation*}
V(t) \leq e^{-\alpha|S_N(\overline{T},t)|}e^{\beta|S_A(\overline{T},t)|}V(\overline{T}) \leq \mathcal{A}e^{-\overline{\alpha}}
\end{equation*}
where $\mathcal{A}=V(\overline{T})e^{\overline{\alpha} \overline{T}}e^{(\beta+\alpha)\xi_{G}}$ and $\overline{\alpha}=\alpha-(\alpha+\beta)/\tau_{G})$.From
the third statement of this theorem, it can be noted that $\overline{\alpha}> 0$.From (24), we can conclude that $\lim_{x\to \infty} \widetilde{z} (t) = 0$. The proof is completed.


Consider the system with the following form:
\begin{equation*}
x_{k+1}=f(x_k)+Bu_k+Cw_k
\end{equation*}
where $x_k \in \mathcal{R}^{n_x}$  and $u_k \in \mathcal{R}^{n_u} $ are the system state and the actuator input, respectively. 
\begin{equation*}
e_k=x_k-x_{k^{e}_s}
\end{equation*}
Considering the vulnerability of the network, the transmitted information may be subject to DoS attacks, and the attacked one is modeled by
\begin{equation*}
\vec{x_{k^{e}_s}}=\alpha_{k^{e}_s}x_{k^{e}_s}
\end{equation*}
let $F(x_k)=f(x_k)-Ax_k$,the system  can be rewritten as:
\begin{equation*}
x_{k+1}=Ax_k+F(x_k)+Bu_k+Cw_k
\end{equation*}
any continuous function $f(x)$ can be approximated closely on a compact set by using an $N N$ with appropriate weights and activation functions, where the norm of weight matrices and the approximation error are
all bounded
\begin{assumption}
 The unknown continuous function $f(x_k)$ on a compact set $\omega \in \mathcal{R}^{n_x} $ can be described by a N N, that is,
\end{assumption}
\begin{equation*}
f(x_k)=W^T_f \Phi(x_k)+\theta_f(x_k)
\end{equation*}
where the weight matrix $W_f$   satisfies $||W_f|| \leq w_{fM}$
Then, the above system (8) can be represented
\begin{equation*}
x_{k+1}=Ax_k+W^T_f \Phi(x_k)+\theta_f(x_k)+Bu_k+Cw_k
\end{equation*}
In this article, the following NN-based observer is proposed to identify the unknown nonlinear function:
\begin{equation*}
\hat{x_{k+1}}=
\begin{cases}
A\hat{x_k}+\hat{W^T_f}\Phi(x_k)+\theta_f(x_k)+Bu_k+L(x_{k^{e}_s}-\hat{x_k})  ,\alpha_{k^{e}_s}=1, k \in [k^{e}_s,k^{e}_{s+1}),  \\
A\hat{x_k}+\hat{W^T_f}\Phi(x_k)+\theta_f(x_k)+Bu_k ,otherwise,
\end{cases}
\end{equation*}
where $\hat{W^T_f}$ is the estimated value of the target N N weight $W_f$,$\hat{x}_k$ is the reconstructed system state vector and L 
is the observer gain selected by the designer, respectively.
Now, defining $ \widetilde{x}_k=x_k-\hat{x}_k$ and $\widetilde{W}_{f,k}=W_{f,k}-\hat{W}_{f,k}$,we have the following state estimation error:
\begin{equation*}
\widetilde{x}_{k+1}=
\begin{cases}
A^L\widetilde{x}_k+\widetilde{W}^T_{f,k}\Phi(\hat{x_k})+Le_k+\xi_k,\alpha_{k^{e}_s}=1, k \in [k^{e}_s,k^{e}_{s+1}),  \\
A\widetilde{x}_k+\widetilde{W}^T_{f,k}\Phi(\hat{x_k})+\xi_k ,otherwise,
\end{cases}
\end{equation*}
where 
\begin{equation*}
A^L=A-L,\xi_k=W^T_f(\phi_f({x}_k)-\phi_f({\hat{x}}_k))+\theta_f(x_k)+Cw_k
\end{equation*}
Obviously, $\xi_k$ has an upper bound of known positive constant $\xi_M$ that is, $||\xi_k|| \leq \xi_M$

\begin{equation*}
\begin{cases}
\dot{x}_i(t)=Ax_i+Bu_i+Cf(x_i(t)) \\
y_i(t)=D x_i(t)
\end{cases}
\end{equation*}
we will construct the observer to estimate the agents’
states
\begin{equation*}
\dot{\hat{x}}_i(t)=A \hat{x}_i(t)+Bu_i(t)+Cf(\hat{x}_i(t))+\eta_i(t)
\end{equation*}
\begin{equation*}
u_i(t)=
\begin{cases}
K_1\sum_{j \in N_i} \alpha_{i j}(\hat{x}_j(t)-\hat{x}_i(t))+d_i(x_o(t)-\hat{x}_i(t)) ,t \in \Theta[t_o,t ) \\
K_2\sum_{j \in N_i} \alpha_{i j}(\hat{x}_j(t_{2k-1})-\hat{x}_i(t_{2k-1}))+d_i(x_o(t_{2k-1})-\hat{x}_i(t_{2k-1})) ,t \in \Gamma[t_o,t ) \\
\end{cases}
\end{equation*}
where
\begin{equation*}
\eta_i(t)=
\begin{cases}
L_1\sum_{j \in N_i} \alpha_{i j}(\widetilde{y}_j(t)-\widetilde{y}_i(t))+d_i(y_o(t)-\widetilde{y}_i(t)) ,t \in \Theta(t_o,t ) \\
L_2\sum_{j \in N_i} \alpha_{i j}(\widetilde{y}_j(t_{2k-1})-\widetilde{y}_i(t_{2k-1}))+d_i(y_o(t_{2k-1})-\widetilde{y}_i(t_{2k-1})) ,t \in \Theta(t_o,t ) \\
\end{cases}
\end{equation*}
where
\begin{equation*}
\widetilde{y}_i(t))=y_i(t)-D \hat{x}_i(t)
\end{equation*}
Let
\begin{equation*}
e_i(t)=x_i(t)-x_o(t)
\end{equation*}
\begin{equation*}
\hat{e}_i(t)=x_i(t)-\hat{x}_i (t)
\end{equation*}
when $t \in \Theta(t_o,t)$
\begin{equation*}
\dot{e}_i(t)=\dot{x}_i(t)-\dot{x}_o (t) = Ax_i(t)+BK_1\sum_{j \in N_i} \alpha_{i j}(\hat{x}_j(t)-\hat{x}_i(t))+d_i(x_o(t)-\hat{x}_i(t))+C(f(x_i(t))-f(x_o (t))
\end{equation*}
when $i=1$
\begin{equation*}
\begin{aligned}
\sum_{j \in N_i} \alpha_{i j}(\hat{x}_j(t)-\hat{x}_i(t))+d_i(x_o(t)-\hat{x}_i(t)) &=&  
 \alpha_{11}(\hat{x}_1-\hat{x}_1)+\alpha_{22}(\hat{x}_2-\hat{x}_1)+\dot{...}+\alpha_{1N}(\hat{x}_N-\hat{x}_1)+d_1(x_o-\dot{x}_1) \\
&=& -\hat{x}_1(\alpha_{11}+\alpha_{12}+\dot{...}+\alpha_{1N}+d_1)+\hat{x}_2 \alpha_{12}+\dot{...}+\hat{x}_N \alpha_{1N}+d_1x_o                                          
\end{aligned}
\end{equation*}
so that
\begin{equation*}
\dot{e}(t)= (I\otimes A)e(t)+(I\otimes C)F(e(t))+(H \otimes BK_1)(\hat{e}(t)-e(t))
\end{equation*}
when $t \in \Gamma(t_o,t)$
\begin{equation*}
\dot{\hat{e}}_i (t)=\dot{x}_i(t)-\dot{\hat{x}}_i(t)=A\hat{x}_i(t)+C(f(x_i(t))-f(\hat{x}_i(t)))-L_1\sum_{j \in N_i} \alpha_{i j}(\widetilde{y}_j(t)-\widetilde{y}_i(t))+d_i(y_o(t)-\widetilde{y}_i(t))
\end{equation*}
when $i=1$
\begin{equation*}
\begin{aligned}
\sum_{j \in N_i} \alpha_{i j}(\widetilde{y}_j(t)-\widetilde{y}_i(t))+d_i(y_o(t)-\widetilde{y}_i(t))  &=& \alpha_{1 1} (\widetilde{y}_1-\widetilde{y}_1)+\alpha_{1 2} (\widetilde{y}_2-\widetilde{y}_1)+\dot{...}+\alpha_{1 N} (\widetilde{y}_N-\widetilde{y}_1)+d_1(y_o-\widetilde{y}_1) \\
&=& -\widetilde{y}_1(\alpha_{1 2}+\dot{...}+\alpha_{1 N}+d_1)+\widetilde{y}_2\alpha_{1 2}+\widetilde{y}_3\alpha_{13}+\dot{...}+\widetilde{y}_N\alpha_{1 N}+d_1y_o   \\
&=& -(D x_1-D \hat{x}_1)(\alpha_{1 2}+\dot{...}+\alpha_{1 N}+d_1)+(D x_2-D \hat{x}_2)\alpha_{1 2}+\dot{...} \\
&+&
(D x_N-D \hat{x}_N)\alpha_{1 N}+d_1y_o \\
&=&  -D\hat{e}_1(\alpha_{1 2}+\dot{...}+\alpha_{1 N}+d_1)+D\hat{e}_2\alpha_{1 2}+\dot{...}+D\hat{e}_N\alpha_{1 N}+d_1y_o
\end{aligned}
\end{equation*}
so that 
\begin{equation*}
\dot{\hat{e}}(t)=(I \otimes A)\hat{e}(t)+(I \otimes C)F(\hat{e}(t))+(H \otimes L_1 D)\hat{e}(t)-(I \otimes L_1 \mathcal{D})Y(t)
\end{equation*}

The exogenous signal v(t) cannot be manipulated
at any time.





%%对leader的估计
\subsection{Design of resilient observer}
Each follower shall first estimate the leader.
So as to work in a secure way, this part develops a resilient
observer based on RCP-$f$ . The designed observer is proved to be effective in the sense that the estimation error of any benign node vanishes despite the misbehaviors. By using measurement output $y(t)$ to get the state estimate
$\hat{v}$ based on the following  observer:
\begin{equation}
\dot{\hat{v}}_i(t)=S \hat{v}(t)+L(y(t)-\hat{y}(t)),
\end{equation}
where $\hat{v}(t)$ is designed to estimate the leader state $v(t)$. Define $\widetilde{v}(t)= v(t)-\hat{v}(t)$, then
\begin{equation}
\begin{split}
\dot{\widetilde{v}}(t)&=S v(t)-S \hat{v}(t)-L(y(t)-\hat{y}(t))\\
&=(S-LR)\widetilde{v}(t)
\end{split}
\end{equation}


We have the result as follows:
\begin{myTheo}\label{Plemma800}
Consider the heterogeneous MASs (3) and (4). Suppose that Assumption 2 holds, the network $\mathcal{G } =(\mathcal{V},\mathcal{E})$ is under $f$-local attack and is strongly $(3f+1)$-robust w.r.t. $\mathcal{X}$. With the - resilient observer(10), the estimation error $\widetilde{v}(t)$ exponentially converges to 0 for any $i \in \mathcal{R}$, regardless of the network misbehaviors.
\end{myTheo}\label{Plemma800}
\textbf{Proof.} 
We consider the following Lyapunov function:
\begin{equation}
\begin{split}
V_1 = \widetilde{v}^T P \widetilde{v}.
\end{split}
\end{equation}
The derivative of $V_1$ is
\begin{equation}
\begin{split}
\dot{V}_1&=2\widetilde{v}^T P \dot{\widetilde{v}}\\
&=2\widetilde{v}^T P(S-LR)\widetilde{v}\\
&=\widetilde{v}^T(P(S-LR)+(S-LR)^T P)\widetilde{v}\\
&=\widetilde{v}^T(P\overline{S}+\overline{S}^T P)\widetilde{v},
\end{split}
\end{equation}
where $L$ is chosen such that $\overline{S}=(S-LR)$ is Hurwitz. Since $\overline{S}$ is Hurwitz, we can find that $P\overline{S}+\overline{S}^T P = -Q$ with $Q$  being a positive definite matrix.
\begin{equation}
\begin{split}
\dot{V}_1 \leq -\widetilde{v}^T Q \widetilde{v}.
\end{split}
\end{equation}
 As a result, (14) can be rewritten as
 \begin{equation}
 V(t)-V(0) \leq - \chi \int_0^t \Vert{\widetilde{v}(s) \Vert}^2 ds,
 \end{equation}
 where $\chi$ is the minimum eigenvalue of all the matrix $Q$. Thus, 
\begin{equation}
  \Vert{\widetilde{v}(t)\Vert}^2 \leq -\int_0^t \Vert{\widetilde{v}(s) \Vert}^2 ds + \mathcal{C},
\end{equation}
where $\mathcal{C} = \frac{1}{\chi} V(0)$. Using Bellman–Gronwall Lemma, (16) can be rewritten as
\begin{equation}
\widetilde{v}(t)^T \widetilde{v}(t) \leq - \sqrt{C}e^{-t},
\end{equation}
 which implies that $\sum_{t \rightarrow \infty} \widetilde{v}(t) = 0$. The proof is followed.
\end{document}

\color{black}
\subsection{Some Useful Definitions and Lemmas}






%\begin{myDef}\label{def41}
%{\color{blue}
\begin{myDef}\label{def41}
Consider the system in the form of
\begin{equation}\label{EQ1}
\begin{cases}
\dot{x}=f(x,t),\\
x(0)=x_0,
\end{cases}
\end{equation}
where $x\in \mathbb{R}^n$ and $f\colon \mathbb{R}^{n}\times \mathbb{R}_{>0}\mapsto \mathbb{R}^{n}$ is a given nonlinear function. The solutions of (\ref{EQ1}) can be understood from the viewpoint of Flippov \cite{filippov2013differential} if $f(x,t)$ is discontinuous. Suppose that the equilibrium point of (\ref{EQ1}) is the origin. The origin is said to be \textbf{globally prescribed-time stable}, if it is globally asymptotical stable and any solution $x(t)$ arrives at the origin no later than a prescribed time instant, that is, $x(t)\equiv 0$, $\forall t\geq T$, where $T$ denotes a prescribed time interval.
$\hfill \hfill \square $
%\begin{enumerate}[{\rm 1)},itemsep= 0 pt, topsep =1ex, itemindent=-0em, listparindent = 0 pt]
%\item The origin of system (\ref{EQ1}) is said to be \emph{globally prescribed-time stable}, if it is globally asymptotically stable and any solution $x(t)$ reaches the origin no later than a prescribed time instant, that is, $x(t)=0$, $\forall t\geq T$, where $T$ denotes a prescribed time interval;
%\item The set $\mathcal{S}$ is said to be \emph{globally prescribed-time attractive}, if  any solution $x(t)$ reaches $\mathcal{S}$ no later than a prescribed time instant and remains there, that is, $x(t)\in \mathcal{S}$, $\forall t\geq T$, where $T$ denotes a prescribed time interval.
%\end{enumerate}
\end{myDef}

The following Lemma provides a key judgment criterion for the globally prescribed-time stability in Definition \ref{def41}:%}



\begin{lemma}[{\cite[Lemma 1]{wang2018prescribed}}]\label{Plemma001}
For a scalar function $V:\mathbb{R}^n \times \mathbb{R}_{>0} \mapsto \mathbb{R}_{\geq0}$, if there exists a positive scalar $c$ such that
 \begin{equation*}
\dot{V}(x,\ t)=-\left(c+2\frac{\dot{\varsigma} (t_0,T)}{{\varsigma (t_0,T)}}\right){V}(x,\ t)
,\ t\in [t_0,\ t_0+\infty),
\end{equation*}
with
  \begin{equation*}
 {\varsigma (t_0,T)}=
\begin{cases}
  (\frac{T}{t_0+T-t})^{h}, & \mbox{if }  t\in [t_0,\ t_0+T), \\
  1, & \mbox{otherwise},
\end{cases}
\end{equation*}
and
 \begin{equation*}\label{roudot}
 \dot{\varsigma} (t_0,\ T)=
\begin{cases}
 \frac{h}{T} \varsigma(t_0+T)^{1+\frac{1}{h}}, & \mbox{if }  t\in [t_0,\ t_0+T), \\
  0, & \mbox{otherwise},
\end{cases}
\end{equation*}
where $t_0$ is the start time point, $T$ denotes the duration of the time-varying period of $\varsigma (t_0,T)$, and $h$ is a scalar bigger than 2. Then, we can conclude
$\lim_{t\rightarrow (t_0+T)^{-}} V(x,\ t)=0$ and $V(x,\ t)\equiv0,\ t\in [t_0+T,\ \infty)$,
which shows $V(t)$ is globally prescribed-time stable with needed time interval $T$. 
% Furthermore, we have
%  \begin{equation}\label{Vrealm}
% V(t)\leq {\varsigma (t_0,T)}^{-2}\exp(-c(t-t_0))V(t_0),~t\in [t_0,\ t_0+\infty).
% \end{equation}
\end{lemma}










\subsection{Problem Formulation}



In this brief, we consider a MAS with one leader and $N$ followers on directed graphs $\mathcal{G}$, which can be denoted as agent $0$ and agents $1\sim N$, respectively.
Consider the same dynamics of the non-autonomous leader as described in \cite{zuo2019distributed}:
\begin{equation}\label{condition_variate}
  \dot{x}_{0,1}=x_{0,2},\ \dot{x}_{0,2}=x_{0,3},\ \ldots,\ \dot{x}_{0,n}=f_0(x_0,t),
\end{equation}
where $x_0 =[x_{0,1},x_{0,2},\ldots~,x_{0,n}]^{\mathrm{T}} \in \mathbb{R}^n$ and $f_0(x_0,t)\in \mathbb{R}$ denote the state vector and the input of the leader, respectively.

\begin{assumption} \label{assumption035}
  $f_0(x_0,t)$ is continuous w.r.t. t, which satisfies ${{\|f_0(x_0,t)\|}_{\infty}} \leq \bar{f}_0$, where $\bar{f}_0$ is a positive scalar denoting the upper bound of the leader input.
\end{assumption}



Let $\hat{x}^i_{0,k}$, for all $i\in \textbf{I}[1,N]$ and $k\in \textbf{I}[1,n]$, denote as the $i$th follower's estimation of the $k$th state of the leader.
Based on the above settings, the design problem of the DPTO is summarized as follows:

\vspace{0.2cm}

\noindent \textbf{Problem DPTOHD} (Distributed Prescribed-Time Observer for multi-agent systems with
High-order integrator dynamics and Directed topologies) : For any initial bounded estimations, design a distributed observer $\hat{x}^i_{0,k}$, $k\in \textbf{I}[1,n]$, such that all followers on the digraph achieve distributed zero-error estimation after a predefined time interval $T_{obs}$ w.r.t. the high-order integrator leader (\ref{condition_variate}), that is,
% \begin{equation}
%   1
% \end{equation}
\begin{equation*}%\label{PTfocusall}
\begin{cases}
\lim_{t\rightarrow  t^{*}}\hat{x}^i_{0}= x_0,\\
\hat{x}^i_{0}(t)= x_0(t), \forall t\geq t^{*},
\end{cases}
\end{equation*}
where $t^{*}=t_0+T_{obs}$ with $t_0$ denoting the initial time instant and $\hat{x}^i_{0}=[\hat{x}^i_{0,1},\ldots~,\hat{x}^i_{0,n}]^{\mathrm{T}}$.
$\hfill \hfill \square $
\vspace{0.2cm}




\section{Main Results}

To solve \textbf{Problem DPTOHD}, a kind of DPTO on time-invariant/varying digraphs is proposed in this section. 

\subsection{Time-invariant Topology Cases}







In this subsection, we consider the time-invariant directed topologies satisfying the following assumptions:

\begin{assumption} \label{assumption040}
  The graph $\mathcal{G}$ contains a spanning tree rooted by the leader, that is, agent 0.
\end{assumption}

Based on Assumption \ref{assumption040}, the Laplacian matrix corresponding to $\mathcal{G }$ can be divided into four blocks:
\begin{equation*}
L=
  \left[
  \begin{array}{c|c}
0&0_{1\times N}\\ \hline
-\boldsymbol{B} &L_0 \\
  \end{array}
  \right]\in \mathbb{R}^{(N+1)\times (N+1)},
\end{equation*}
where $L_0\in \mathbb{R}^{N\times N}$ denotes the communication topology among followers; $\boldsymbol{B}=(b_{1},\ldots~, b_{N})^{\mathrm{T}}\in \mathbb{R}_{\geq 0}^{N\times 1}$ represents the pinned vector, with $b_i=1,\ i\in {\textbf{I}[1,N]}$, if the $i$th follower connects directly to the leader, otherwise, $b_i=0$. 
Furthermore, $L_0$ owns the following property:
\begin{lemma}[{\cite[Lemma 3]{gong2020distributed2}}]\label{Plemma74}
  Under Assumption \ref{assumption040}, the matrix $L_0$ is invertible.
  Define that $P:={\rm diag(\rho)}$ where $\rho=(L_0^{\mathrm{T}})^{-1}\boldsymbol{1}_N = [\rho_1,\ldots,\rho_N]^{\mathrm{T}}$, then we have
  \begin{equation*}
    M(L_0) = \frac{1}{2}(PL_0+L_0^{\mathrm{T}}P) > 0.
  \end{equation*}
\end{lemma}
\begin{figure}[!]
  %\begin{minipage}[t]{1\linewidth}
  \centering
  \includegraphics[width=0.5\textwidth]{pic/P4.pdf}
  \caption{Timeflow graph of the cascaded DPTO}
  \label{fig:figure0}
\end{figure}
  %\vspace{-1.8cm}

Define $\tilde{x}^i_{0,k}=\hat{x}^i_{0,k}-{x}_{0,k}$, $k\in \textbf{I}(1,n)$, as the global state estimation error of the $i$th follower on the leader's $k$th state. Moreover, let $\psi^i_{k}=b_i(\hat{x}^i_{0,k}-x_{0,k})+\sum_{j \in \mathcal{N}_{i}}a_{ij}(\hat{x}^i_{0,k}-\hat{x}^j_{0,k})$ denote the local state estimation error of the $i$th follower on the leader's $k$th state. The DPTO for the $i$th follower, $i\in\textbf{I}[1,N]$, can be designed as
%Revised version:

where $T^k_{obs}\in \mathbb{R}_{> 0}$, $\forall k \in\textbf{I}[1,n]$, satisfy $T_{obs}=\sum_{k=1}^{n}T^k_{obs}$ and thus $t_{n-k}=t_0+\sum_{j=k+1}^{n}T^j_{obs}$, $\forall k\in \textbf{I}[0,n-1]$. To be more specific, the timeflow graph of the DPTO (\ref{DPTO}) is depicted in Fig. \ref{fig:figure0}, which shows that the cascaded estimation process on each leader state in an inverted order.


%
\begin{myTheo}\label{Plemma800}
Consider the leader with high-order dynamics (\ref{condition_variate}), if Assumptions \ref{assumption035} and \ref{assumption040} hold, then {\textbf{Problem DPTOHD}} can be solved via the DPTO (\ref{DPTO}) satisfying
%can ensure the estimation errors of all followers w.r.t. the leader converge into zero in a prescribed time interval $T_{obs}$.
\end{myTheo}

\textbf{Proof.} First, define that $\psi_k:=[\psi^1_k,\ldots~,\psi^N_k]^{\mathrm{T}}$ and $\tilde{x}_{0,k}:=[\tilde{x}^1_{0,k},\ldots~,\tilde{x}^N_{0,k}]^{\mathrm{T}}$, $\forall k\in  \textbf{I}[1,n]$. Then we have $\psi_k=L_0\tilde{x}_{0,k}$ and $\psi_k=\boldsymbol{0}_{N} \Leftrightarrow \tilde{x}_{0,k}=\boldsymbol{0}_{N}$ since $L_0$ is nonsingular. Thus, the effectiveness of the DPTO can be ensured via proving the proposition that $\psi_k$, $\forall k\in  \textbf{I}[1,n]$, converges into zero. Theorem \ref{Plemma800} is proven step by step via \emph{Mathematical Induction}:

\textbf{Step 1:}
Consider the second equation in (\ref{DPTO}), define that
\begin{equation*}
u^{i}_{0,n}=\dot{\hat{x}}^i_{0,n}=u^{i,a}_{0,n}+u^{i,b}_{0,n},~i\in\textbf{I}[1,N],
\end{equation*}
where
\begin{equation*}
\begin{cases}
u^{i,a}_{0,n}=-\left(\alpha+\beta\frac{\dot{\varsigma}(t_0, T^n_{obs})}{\varsigma(t_0, T^n_{obs})}\right)\psi^i_{n},\\
u^{i,b}_{0,n}=-\sigma{\rm sign}(\psi^i_{n}).\\
\end{cases}
\end{equation*}
The time derivative of $\psi_{n}^i$ equals to
\begin{equation}\label{phi5}
\dot{\psi}_n^i=\sum_{j \in \mathcal{N}_{i}}a_{ij}(u^{i}_{0,n}-u^{j}_{0,n})+b_{i}(u^{i}_{0,n}-f_0).
\end{equation}
Consider the following Lyapunov function candidate:
\begin{equation*}
V_n=  \frac{1}{2}\psi_{n}^{\mathrm{T}}P\psi_{n}=\frac{1}{2}\sum_{i=1}^{N}\rho_i( |{\psi}_n^i|^2),
\end{equation*}
where $\psi_{n}:=[\psi^1_{n},\ldots~,\psi^N_{n}]^{\mathrm{T}}$, $P$ and $\rho$ are defined in Lemma \ref{Plemma74}. Notice that $V_n$ is well-defined due to the positive definiteness of $P$. It can be computed via (\ref{phi5}) that
\begin{eqnarray}\label{9eq}
\dot{V}_n
% =&\sum_{i=1}^{N}\rho_i {\psi}_n^i\left(\sum_{j \in \mathcal{N}_{i}}a_{ij}(u^{i}_{0,n}-u^{j}_{0,n})+b_{i}(u^{i}_{0,n}-f_0)\right)\nonumber\\
=&\sum\limits _{i=1}^{N}\rho_i {\psi}_n^i\left(\sum_{j \in \mathcal{N}_{i}}a_{ij}(u^{i,a}_{0,n}-u^{j,a}_{0,n})+b_{i}(u^{i,a}_{0,n})\right)+\nonumber\\
&\underbrace{\sum_{i=1}^{N}\rho_i {\psi}_n^i\sum_{j \in \mathcal{N}_{i}}[a_{ij}(u^{i,b}_{0,n}-u^{j,b}_{0,n})+b_{i}(u^{i,b}_{0,n}-f_0)]}_{\dot{V}^{b}_{n}}
\end{eqnarray}
%By recalling the fact that $u^*_{ib}-u^*_{jb}\leq -\sigma{\rm sign}({\psi}_v^i)+\sigma$ and $u^*_{ib}-f_0\leq -\sigma{\rm sign}({\psi}_v^i)+\sigma$, we come to a conclusion that
%\begin{equation}\label{10eq}
%  \dot{V}_{1b}\leq0
%\end{equation}
%\begin{remark}
The proposition under Condition (\ref{DPTOparam1c}) that
\begin{equation}\label{10eq}
  \dot{V}^{b}_{n}\leq0,
\end{equation}
 can be verified via the following analysis:
\begin{enumerate}
\item When ${\psi}_n^i<0$, we obtain that $u^{i,b}_{0,n}=\sigma$, $u^{j,b}_{0,n}\leq\sigma$, $f_0\leq\bar{f}_0\leq\sigma$, and thus $u^{i,b}_{0,n}-u^{j,b}_{0,n}\geq 0$, $u^{i,b}_{0,n}-f_0\geq 0$. Consequently, one can easily obtain that $\dot{V}^{b}_{n}\leq0$;
\item When ${\psi}_n^i=0$, we have $\dot{V}^{b}_{n}=0$;
\item When ${\psi}_n^i>0$, we obtain that $u^{i,b}_{0,n}=-\sigma$, $-u^{j,b}_{0,n}\leq\sigma$, $-f_0\leq\bar{f}_0\leq\sigma$, and thus $u^{i,b}_{0,n}-u^{j,b}_{0,n}\leq 0$, $u^{i,b}_{0,n}-f_0\leq 0$. To this end, it follows that $\dot{V}^{b}_{n}\leq0$.%$\hfill \hfill \square $
\end{enumerate}
%\end{remark}
It can be obtained from (\ref{9eq}), (\ref{10eq}) and Lemma \ref{Plemma74} that
\begin{align}\label{11eq}
\dot{V}_n
\leq&\sum_{i=1}^{N}\rho_i( {\psi}_n^i)\sum_{j \in \mathcal{N}_{i}}a_{ij}(u^{i,a}_{0,n}-u^{j,a}_{0,n})+b_{i}(u^{i,a}_{0,n})\nonumber\\
% =&-\left(\alpha+\beta\frac{\dot{\varsigma}(t_0, T^n_{obs})}{\varsigma(t_0, T^n_{obs})}\right) {\psi}_n^{\mathrm{T}}PL_0 {\psi}_n \nonumber\\
%=&-\left(\alpha+\beta\frac{\dot{\varsigma}(t_0, T^n_{obs})}{\varsigma(t_0, T^n_{obs})}\right) {\psi}_v^{\mathrm{T}}M(L_0){\psi}_v \nonumber\\
=&-\left(\alpha+\beta\frac{\dot{\varsigma}(t_0, T^n_{obs})}{\varsigma(t_0, T^n_{obs})}\right) {\psi}_n^{\mathrm{T}}PL_0{\psi}_n \nonumber\\
\leq&-2\left(\alpha+\beta\frac{\dot{\varsigma}(t_0, T^n_{obs})}{\varsigma(t_0, T^n_{obs})}\right) \frac{\lambda_1(M(L_0))}{{\max}\{\rho\}}{V}_n(t).\nonumber
\end{align}
By recalling Condition (\ref{DPTOparam1b}), it follows that
\begin{equation*}
 \dot{V}_n(t)
\leq -2\alpha\frac{\lambda_1(M(L_0))}{{\max}\{\rho\}}{V}_n(t)-2\frac{\dot{\varsigma}(t_0, T_{obs}^n)}{\varsigma(t_0, T_{obs}^n)}{V}_n(t).
\end{equation*}
By recalling Lemma  \ref{Plemma001}, we learn that ${V}_n(t)\equiv 0$ and thus $\psi_n\equiv \boldsymbol{0}_{N}$ over $[t_0+ T_{obs}^n,\infty)$.
% Herein, the DPTO can ensure that the velocity estimation errors of all followers w.r.t. the leader converge into zero in a prescribed time interval $T_{obs}^n$.

\textbf{Step 2:} Suppose that $V_{k+1}=  \frac{1}{2}\psi_{k+1}^{\mathrm{T}}P\psi_{k+1}=\frac{1}{2}\sum_{i=1}^{N}\rho_i( |{\psi}_{k+1}^i|^2)$, $k=n-1,~n-2,\ldots~,1,$ can be globally prescribed-time stabilized no later than $t_{n-k}$, that is, 
\begin{equation}\label{Inferk}
\psi_{k+1}=\boldsymbol{0}_{N}, ~\forall t\geq t_{n-k}.
\end{equation}
It can be easily verified that the first $V_{k+1}$ term, that is, $V_n$ satisfies (\ref{Inferk}) according to the analysis of Step 1.

\textbf{Step 3:} Selecting the Lyapunov function as $V_k=  \frac{1}{2}\psi_k^{\mathrm{T}}P\psi_k=\frac{1}{2}\sum_{i=1}^{N}\rho_i( |{\psi}_k^i|^2)$, we compute that
%\begin{align*}%\label{9eq1}
  \begin{eqnarray*}
\dot{V}_k
=&\sum_{i=1}^{N}\rho_i {\psi}_k^i\left(\sum_{j \in \mathcal{N}_{i}}a_{ij}(u^{i,a}_{0,k}-u^{j,a}_{0,k})+b_{i}(u^{i,a}_{0,k})\right)+\nonumber\\
&\underbrace{\sum_{i=1}^{N}\rho_i {\psi}_k^i \sum_{j \in \mathcal{N}_{i}}[a_{ij}(u^{i,b}_{0,k}-u^{*}_{jb,k})+b_{i}(u^{i,b}_{0,k}-x_{0,k})]}_{\dot{V}^{b}_{k}}
\end{eqnarray*}
%\end{align*}
where
\begin{equation*}
\begin{cases}
u^{i,a}_{0,k}=-\left(\alpha+\beta\frac{\dot{\varsigma}(t_{n-k}, T^k_{obs})}{\varsigma(t_{n-k}, T^k_{obs})}\right)\psi^i_{k},\\
u^{i,b}_{0,k}=\hat{x}^i_{0,k+1}.\\
\end{cases}
\end{equation*}
It should be noted that equation (\ref{Inferk}) holds, which leads to ${\dot{V}^{b}_{k}}=0$, $\forall t\geq t_{n-k}$. Thus, we have
\begin{align}\label{10eq1}
\dot{V}_k(t)
% =&\sum_{i=1}^{N}\rho_i {\psi}_k^i\times\left(\sum_{j \in \mathcal{N}_{i}}a_{ij}(u^{i,a}_{0,k}-u^{j,a}_{0,k})+b_{i}(u^{i,a}_{0,k})\right)\nonumber\\
\leq&-2\left(\alpha+\beta\frac{\dot{\varsigma}(t_{n-k}, T^k_{obs})}{\varsigma(t_{n-k}, T^k_{obs})}\right) \frac{\lambda_1(M(L_0))}{{\max}\{\rho\}}{V}_k(t),\nonumber
\end{align}
$\forall t\geq t_{n-k}$. Following the similar procedure as Step 1, we could obtain that ${V}_k\equiv0$ and thus $\psi_k= \tilde{x}_{0,k}\equiv\boldsymbol{0}_{N}$, $\forall t\geq t_{n+1-k}$. Thus, the DPTO (\ref{DPTO}) can reconstruct the $k$th leader state no latter than a prescribed time instant $t_{n+1-k}$, as long as the $(k+1)$th leader state can be accurately estimated within $t_{n-k}$, $\forall k\in \textbf{I}(1,n-1)$.
%$\tilde{x}^i_{0,q}$

Based on the above analysis, we obtain $\tilde{x}_{0,k}=\boldsymbol{0}_{N}$, $\forall t\geq t_0+T_{obs}$ and $k\in \textbf{I}(1,n)$. Therefore, Theorem \ref{Plemma800} is proved.
$\hfill \hfill \blacksquare $
\vspace{0.001cm}
\begin{remark}
  For simplicity, herein we investigate the design of DPTO w.r.t. the leader with high-order integrator dynamics (\ref{condition_variate}). Actually, this DPTO could be extended to the leader with certain high-order strict-feedback dynamics in a canonical form \cite{zhang2015leader, holloway2019prescribed}, whose estimation process can also be implemented in a cascaded manner.
  $\hfill \hfill \square $
\end{remark}















































\subsection{Time-varying Topology Cases}
\begin{figure}[htbp]
  \centering
  \subfigure[Digraph 1]{
  \begin{minipage}[t]{0.225\textwidth}
  \centering
  \includegraphics[width=0.85\textwidth]{pic/4Ag.pdf}
  \label{fig:figure1:1}
  %\caption{fig1}
  \end{minipage}%
  }%
  %\hspace{-0.2in}
  \subfigure[Digraph 2]{
  \begin{minipage}[t]{0.225\textwidth}
  \centering
  \includegraphics[width=0.85\textwidth]{pic/4Bg.pdf}
  \label{fig:figure1:2}
  %\caption{fig2}
  \end{minipage}%
  }
  \centering
  \caption{Time-varying directed communication topology among all agents: The periodically switching sequence is that the initial topology is digraph 1 and the switching occurs every $0.1$ s.}
  \label{fig:figure1}
  \end{figure}
Let $\mathcal{G}_{\sigma(t)}$ denote a time-varying digraph switching among $p$ kinds of possible directed topologies, where $\sigma(t)\in\textbf{I}[1,p]$ denotes the index associated with the directed topology at the time instant $t$. Denote the sub-Laplacian matrix of $\mathcal{G}_{\sigma(t)}$ as $L_{\sigma(t)}$, which is a counterpart of $L_0$ associated with $\mathcal{G}$. The protocol (\ref{DPTO}) could also be extended to some time-varying digraphs satisfying the following assumption:% \cite{liu2019leader}

\begin{assumption} \label{assumption0402}
  The graph $\mathcal{G}_{\sigma(t)}$ contains a spanning tree rooted by the leader all the time. Furthermore, there exists a diagonal matrix $H:={\rm diag}(\eta)>0$ with $\eta=[\eta_1,\ldots~,\eta_N]^{\mathrm{T}}$ such that $M(L_j):=\frac{1}{2}(HL_j+L_j^{\mathrm{T}}H) > 0$, $\forall j\in\emph{\textbf{I}}[1,p]$.
\end{assumption}

\begin{remark}
Notice that Assumption \ref{assumption040} is a special case of Assumption \ref{assumption0402}. Actually, the constraint brought by Assumption \ref{assumption0402} is not too strict since it is feasible to obtain a diagonal matrix $H$ in many time-varying directed topology cases. One such example can be found in our simulation part in Section \ref{SecSm}.$\hfill \hfill \square $
\end{remark}

By replacing $\psi^i_{k}$ in (\ref{DPTO}) with $\psi^{i,{\sigma(t)}}_{k}=b_i^{\sigma(t)}(\hat{x}^i_{0,k}-x_{0,k})+\sum_{j=1}^Na_{ij}^{\sigma(t)}(\hat{x}^i_{0,k}-\hat{x}^j_{0,k})$, we have the following corollary:

\begin{myCollo}\label{Theo3}
  Consider the leader with dynamics (\ref{condition_variate}), if Assumptions \ref{assumption035} and \ref{assumption0402} hold, then the DPTO (\ref{DPTO}) satisfying
\begin{equation}\label{DPTOparam2}
  \begin{cases}
    \alpha >0,\\
    \beta\geq \frac{\max_{i\in {\textbf{I}}[1,N]}\{\eta_i\}}{\min_{j\in {\textbf{I}}[1,p]}\lambda_1(M(L_j))},\\
    \sigma \geq \bar{f}_0.
  \end{cases}
  \end{equation}
  can ensure the estimation error of each follower w.r.t. the leader converges into zero in a prescribed time interval $T_{obs}$.
\end{myCollo}

\textbf{Proof.}
The proving process is similar to Theorem \ref{Plemma800} and hence omitted here.
$\hfill \hfill \blacksquare $
\vspace{0.1cm}
%\vspace{0.2cm}

\begin{figure*}[htbp]
  \centering
  \subfigure[Estimation w.r.t. the acceleration of L0]{
  \begin{minipage}[t]{0.32\textwidth}
  \centering
  \includegraphics[width=0.85\textwidth]{pic/est0a.eps}
  \label{fig:figure2:1}
  %\caption{fig1}
  \end{minipage}%
  }%
  %\hspace{-0.2in}
  \subfigure[Estimation w.r.t. the velocity of L0]{
  \begin{minipage}[t]{0.32\textwidth}
  \centering
  \includegraphics[width=0.85\textwidth]{pic/est0v.eps}
  \label{fig:figure2:2}
  %\caption{fig2}
  \end{minipage}%
  }%
  %\subfigure[Estimation performance w.r.t. the displacement of leader0]{
  %\begin{minipage}[t]{0.475\textwidth}
  %\centering
  %\includegraphics[width=0.85\textwidth]{pic/est0p.eps}
  %\label{fig:figure2:3}
  %%\caption{fig1}
  %\end{minipage}%
  %}%
  %\subfigure[Estimation performance w.r.t. the velocity of L1]{
  %\begin{minipage}[t]{0.475\textwidth}
  %\centering
  %\includegraphics[width=0.85\textwidth]{pic/est1v.eps}
  %\label{fig:figure2:4}
  %%\caption{fig2}
  %\end{minipage}
  %}%
  %\hspace{-0.2in}
  \subfigure[Estimation w.r.t. the displacement of L0]{
  \begin{minipage}[t]{0.32\textwidth}
  \centering
  \includegraphics[width=0.85\textwidth]{pic/est0p.eps}
  \label{fig:figure2:3}
  %\caption{fig2}
  \end{minipage}
  }%
  \centering
  \caption{Performance of the DPTO: the shadow areas denote time intervals using time-varying gains.}
  \label{fig:figure2}
  \end{figure*}
  

\begin{remark}%
  The main merits of the DPTO (\ref{DPTO}) are:
   \begin{enumerate}
    \item One of recent distinguished distributed finite-time observers on digraphs is summarized in \cite[Theorem 2]{zuo2019distributed}, which achieved distributed estimation w.r.t. the leader in finite-time cooperatively ultimately uniformly boundedness sense. The needed time interval to achieve uniform bounded estimation error depended directly on the generalized network algebraic connectivity \cite{wu2005algebraic} of digraphs, which varies as the network topology alters. Compared with the distributed finite-time observer in a recently distinguished work \cite[Theorem 2]{zuo2019distributed}, our DPTO on directed graphs possesses the following two highlights: a) zero-error convergence rather than uniformly bounded convergence; b) prescribed-time convergence rather than just finite-time convergence. Also, the parameter design principle in Theorem \ref{Plemma800} is much simpler than that in \cite[Theorem 2]{zuo2019distributed}. These user-friendly merits bring great convergence to the users of the DPTO. 
\item Compared with our previous DPTO in \cite[Eq. 34]{9311845}, this new DPTO can achieve prescribed-time performance without using the real-time control input of the leader, which facilitates the actual applications of DPTO since the control input is generally not available for the pinned followers \cite[Definition 1]{9311845}. Herein, only the assumption on the upper boundedness of the leader input is needed, which is quite reasonable and general since all force-driven robots in real applications are actuation bounded.
\item This work first considers extending the topologies of distributed finite-time consensus observers from time-invariant digraphs to time-varying ones. Besides, the obtained parameter design principle (\ref{DPTOparam2}) in Corollary \ref{Theo3} is also quite simple and clear to be deployed, as the one (\ref{DPTOparam1}) in Theorem \ref{Plemma800}.
  $\hfill \hfill \square $
  %eradicate the notorious communication loop problem \cite{khoo2014multi} encountered in traditional convey communication mechanism.
\end{enumerate}
\end{remark}



% Assumption 5.1: For any p ∈ P, every node i = 1,...,N is reachable from node 0 in the digraph G¯p and there exists a positive definite
% diagonal matrix D = diag(d1,...,dN ) such that DHp + HT
% p D is
% positive definite.






\section{Numerical Simulation}\label{SecSm}

% \begin{figure}[!htbp]
% %\begin{minipage}[t]{1\linewidth}
% \centering
% \includegraphics[width=0.6\textwidth]{4Ag.pdf}
% \caption{Time-varying directed communication topology among all agents}
% \label{fig:figure1}
% \end{figure}



%{\color{blue}
%\begin{figure}[htbp]
%\centering
%\subfigure[Performance of observer w.r.t. the leader]{
%\begin{minipage}[t]{0.475\textwidth}
%\centering
%\includegraphics[width=0.85\textwidth]{pic/pobs.eps}
%%\caption{fig1}
%\end{minipage}\label{fig:figure2:1}
%}
%%\hspace{-0.1in}
%\subfigure[Performance of observer w.r.t. the first leader]{
%\begin{minipage}[t]{0.475\textwidth}
%\centering
%\includegraphics[width=0.85\textwidth]{pic/vobs.eps}
%%\caption{fig2}
%\end{minipage}\label{fig:figure2:2}
%}\\%
%\centering
%\caption{Performance of two observers}
%\label{fig:figure2}
%\end{figure}









Consider a triple-integrator MAS, where agent $0$ represents the leader, while agents $1\sim 3$ stand for the three followers. Their communication topology is shown in Fig. \ref{fig:figure1}, which satisfies Assumption \ref{assumption0402} together with the selection of $H={\rm diag}([3,~5,~4]^{\mathrm{T}})$. 
The Laplace matrices are
\begin{equation*}
L_1
=
 \left[
  \begin{array}{ccc}
 2 &  0  & -1  \\
-1 &  1  & 0   \\
 0 &  -1  & 1  \\ 
  \end{array}
  \right],~L_2
  =
   \left[
    \begin{array}{ccc}
   1 &  0  & 0  \\
  -1 &  1  & 0   \\
   -1 & 0  & 1  \\ 
    \end{array}
    \right].
\end{equation*}
%0& 0 &  0  & 0 & 1 & 0 & -1 \\
% 0& 0 &  0  & 0 & -1 & 1 & 0 \\
% 0& 0 &  0  & 0 & 0 & -1 & 1\\
 %The formation pattern of the three leaders is defined as
%\begin{equation*}\label{leaderformpattern}
%\varpi_i=[0.5\cos((i-4)\pi/3),0.5\sin((i-4)\pi/3)]^{\mathrm{T}},\ i\in \textbf{I}[1,n].
%\end{equation*}
%v00-1/2*sin(t/2); v00-1/2*sin(t/2);-1/4*cos(t/2);-1/4*cos(t/2)
Let $t_0=0$ s. 
The dynamic of the leader is $\dot{x}_{0,1}=x_{0,2}$, $\dot{x}_{0,2}=x_{0,3}$, and $\dot{x}_{0,3}=\frac{1}{8}\sin(\frac{t}{2}) $. Thus, $\bar{f}_0$ can be chosen as $\frac{1}{8}$. The following design parameters are applied in the simulation: $T_{obs}=0.6$ s, $T_{obs}^1=T_{obs}^2=T_{obs}^3=\frac{T_{obs}}{3}=0.2$ s and $h=2.01>2$.
By recalling Corollary \ref{Theo3}, we choose the parameters of the DPTO in (\ref{DPTO}) as: $\alpha=1.05$, $\beta=5.692$ and $\sigma=0.125$. The performance of this observer is shown in Fig. \ref{fig:figure2}. As shown in Fig. \ref{fig:figure2:1}, the global acceleration estimation error of this observer will remain zero after the predefined time point $t_0+T^3_{obs}=0.2$ s. Similarly, the global velocity and displacement estimation errors of this observer will remain zero after the predefined time point $t_0+T^3_{obs}+T^2_{obs}=0.4$ s and $t_0+T_{obs}=0.6$ s, respectively, as shown in Fig. \ref{fig:figure2:2} and Fig. \ref{fig:figure2:3}.


\section{Conclusion}
We investigate the distributed prescribed-time consensus observer for multi-agent systems with
high-order integrator dynamics and directed topologies in this brief.  To our best knowledge, the DPTO on time-invariant/varying digraphs with prescribed-time zero-error convergence has been formulated for the first time, which could achieve distributed estimation w.r.t. the leader state within an arbitrary time interval predefined by the users. An illustrative simulation example has been conducted, which confirms the prescribed-time performance of the above DPTO. Future works will consider using this prescribed-time observer to deal with distributed fault-tolerant control problems \cite{hua2017distributed, xu2020distributed}. %\cite{3xiao2021distributed} 

\section*{Appendix}


\begin{algorithm}[!]
  %\floatname{algorithm}{Procedure*}
  %\floatname{algorithm 1}{Algorithm PDO}
  \caption{{\color{blue}Prescribed-time Algorithm for Distributed Optimization: A Fractional-step Implementation}} %算法的名字
  \raggedright {\bf Input:} %算法的输入， \hspace*{0.02in}用来控制位置，同时利用 \\ 进行换行The eigenvalues
  Three predefined time intervals: $T_i$, $i=1, 2, 3$. The number of agents: $N$. $\lambda_2(L)$ and the upper bound of $\|g_i-g_j\|$: $\xi$.\\
  \raggedright {\bf Output:} %算法的结果输出
  The minimizer $ x^*$ of the global objective function.
  %\caption{Euclid's algorithm}\label{euclid}
  \begin{algorithmic}[1]
  % \Procedure{Euclid}{$a,b$}%\Comment{The gcd of $a$ and $b$}
  %  \State $r \gets a \bmod b$
  %  \While{$r \neq 0$}%\Comment{We have the answer if $r$ is $0$}
  %   \State $a \gets b$
  %   \State $b \gets r$
  %   \State $r \gets a \bmod b$
  %  \EndWhile\label{euclidendwhile}
  %  \State \textbf{return} $b$%\Comment{The gcd is $b$}
  % \EndProcedure
  \State For the MAS in (\ref{SIsystem}), initialize $\delta_i(t_0)=\boldsymbol{0}_{r^2+r}$ and parameters $c_i$, $i=0\sim 4$, and $k_i$, $i=1, 3$ such that (\ref{th4param}) holds.
  \While{$t<t_0+T_1$}
  \State Simulate (\ref{esterr}) using the adaptive law (\ref{deltaupdate4}).
  % \State Simulate (\ref{SIsystem}) using the control law (\ref{th4u}) and (\ref{where1}), that is, $u_i=\hat{u}_i+\bar{u}_i$ with $\bar{u}_i=c_3\sum_{j \in \mathscr{N}_i} (x_j-x_i)$.
  %\END
  \EndWhile       %算法的返回值
  \State \hspace*{-0.05in} \textbf{endwhile}\algorithmiccomment{{\color{blue}Then estimation error remains at zero}}
  \While{$t<t_0+T_1+T_2$}
  \State Simulate (\ref{esterr}) using the adaptive law (\ref{deltaupdate4}).
  \State Simulate (\ref{SIsystem}) using the control law (\ref{th4u}) and (\ref{where1}).
  \EndWhile       %算法的返回值
  \State \hspace*{-0.05in} \textbf{endwhile}\algorithmiccomment{{\color{blue}Then consensus error remains at zero}}
  \While{$t<t_0+T_1+T_2+T_3$}
  \State Simulate (\ref{esterr}) using the adaptive law (\ref{deltaupdate4}).
  \State Go on simulating (\ref{SIsystem}) using the control law (\ref{th4u}) and (\ref{where1}), that is, $u_i=u^*$ in the form of (\ref{th1u}).
  \EndWhile      %算法的返回值
  \State \hspace*{-0.05in} \textbf{endwhile}\algorithmiccomment{{\color{blue}Then optimization error remains at zero}}\\
  \Return The minimizer of global objective function $ x^*=x(t)$, $\forall t\geq t_0+\sum_{i=1}^3T_i$.
  \end{algorithmic}
  \end{algorithm}

\begin{table}[!t]\small\label{table1}
  \renewcommand{\arraystretch}{1.3}         % 1.3表示单个框宽度
  \caption{{Optimal time horizon and associated deviation.}}
  \label{table_example}
  \centering
  \begin{tabular}{cccc}
      \toprule
      \toprule
      % Network index & & &$\beta(0)$  &   &  &  &  &$\delta(0)$ &  & \\    % \bfseries表示加粗
      % \hline                          % \hline横线框
      \multirow{3}*{Defense in SBS} &
      $\epsilon$ & $T^*(s)$ & $ \left\|p_n(T^*) - p^F_{n}\right\|(m)$\\
      \cline{2-4}
      %\multirow{2}*{Network 1} &
      &0.03 & \textbf{4.51} & 1.0705 \\
      &0.3   &5.65 &\textbf{0.5032} \\
      \toprule
      \multirow{3}*{Defense in DBS} &
      $\epsilon$ & $T^*(s)$ & $ \left\|p_n(T^*) - p^F_{n}\right\|(m)$\\
      \cline{2-4}
       &0.03 &\textbf{4.30} &0.4409 \\
       &0.3 &5.49 &\textbf{0.2113} \\
      \bottomrule
      \bottomrule
  \end{tabular}
\end{table}
\end{document}


\section{Introduction}
\IEEEPARstart{T}{he} last decade has witnessed substantial progresses contributed by various industries (see \cite{ xu2020distributed, liang2016leader, hua2017distributed, de2014controlling} and references therein) on distributed coordination of multi-agent systems (MAS). 
In this brief, we consider the leader-following scenarios \cite{liang2016leader} rather than leaderless ones \cite{hua2017distributed}, where only a small portion of followers is  pinned (directly connected) to the leader. As pointed out in \cite{de2014controlling}, the formation error (consensus error) suffers from biased measuring noise among robots. Moreover, the actuation faults may also propagate among the MAS networks, which pose a non-negligible threat to the collective control of MAS. An alternative and easily realized method to overcome the above harmful measuring noise and fault propagation is introducing a distributed observer for each agent and reassigning the control input according to the estimated information. Similar to the distributed consensus observer defined in \cite{zuo2019distributed}, herein, we intend to design a kind of distributed prescribed-time observers (DPTO), which could reconstruct the leader state for all followers, especially these unpinned ones. Notice that the above distributed observers are different from the traditional Luenberger observers \cite{9311845} focusing on reconstruction on the unmeasured states. Also, this kind of distributed observers \cite{de2014controlling,fu2017finite,fu2016fixed,zuo2017fixed2,zuo2019distributed} could eradicate the notorious communication loop problem \cite{khoo2014multi} encountered in traditional convey communication mechanism.




One of the key properties of a superior distributed observer is to achieve distributed estimation quickly with little constraint on the communication topologies and high accuracy. Unlike the distributed observer in \cite{de2014controlling} which only owns asymptotical convergence, Fu \emph{et. al.} first proposed a kind of distributed fixed-time observer for first-order \cite{fu2017finite} and second-order MAS \cite{fu2016fixed}, respectively. However, the above two works employ two fractional power feedback terms, that is, $\frac{p}{q}$ and  $2-\frac{p}{q}$ with $q>p>0$, which are too cumbersome to extend to high-order dynamics. Zuo \emph{et. al.} further employed single fractional power feedback ($\gamma>1$) in the design of distributed finite-time observer, which achieved the distributed fixed-time estimation w.r.t. the leader state on both undirected graphs \cite{zuo2017fixed2,zuo2019distributed} and directed ones \cite{zuo2019distributed}. As pointed in \cite{zuo2019distributed}, the proof based on the symmetry of Laplacian matrices is not applicable for directed topologies. Thus, it is not trivial to study the distributed finite-time observer on directed graphs. Notice that the fixed-time zero-error convergence is only guaranteed on undirected topologies \cite[Theorem 1]{zuo2019distributed}, while only fixed-time attractiveness of an error domain is proven in  \cite[Theorem 2]{zuo2019distributed}. Thus, it remains a big challenge to design a distributed finite-time zero-error observer on general directed topologies. Moreover, the needed time interval to achieve distributed observation in the above works \cite{fu2017finite,fu2016fixed,zuo2017fixed2,zuo2019distributed} depends on the settings of initial conditions and the network algebraic connectivity \cite{wu2005algebraic}, which put barriers in the way of their applications.







Two inevitable yet challenging difficulties arise when designing distributed finite-time observers for MAS:

\begin{enumerate}
  \item How can all followers obtain finite-time zero-error convergence since the actual states of each pinned leader are only available to only a portion of followers, especially on a directed topology?
  \item How to regulate the consensus observation time arbitrarily despite the influences of the initial states of the MAS and network algebraic connectivity, particularly for high-order MAS on large directed networks?
\end{enumerate}




Fortunately, recently proposed prescribed-time protocols in \cite{wang2018prescribed, gong2020distributed2} shed light on the solution of the above two issues. Motivated by \cite{wang2018prescribed, gong2020distributed2}, we formulate a kind of DPTO for each follower, featured by a new hybrid constant and time-varying scaling function. This design is fundamentally different from the previous distributed finite-time observer in \cite{fu2017finite,fu2016fixed,zuo2017fixed2,zuo2019distributed} based fractional power feedback, which has the following main contributions and characteristics:


\begin{enumerate}
\item  A new kind of cascaded DPTO, based on a \textbf{hybrid constant and time-varying feedback}, is developed for the agents on directed graphs, which achieves the distributed accurate estimation on each order of leader state in a cascaded manner. 
\item \textbf{Zero-error convergence on time-invariant/varying directed graphs}: In contrast to the previous work \cite{zuo2019distributed} which only guarantees finite-time attractiveness of a fixed error bound, we manage to regulate the observation error on directed graphs into zero in a finite-time sense. It is further found that the feasibility of this DPTO can be extended to some time-varying directed graphs.
%The difficulties caused by the asymmetrical Laplacian matrix under the circumstance of single-way directed communication topology are circumvented in the frameworks of distributed prescribed-time fault-tolerant control.
\item \textbf{Prescribed-time convergence}: This DPTO could achieve distributed zero-error estimation in a predefined-time manner, whose needed time interval is independent of the initial states of all agents and network algebraic connectivity. Thus, the observer design procedure is much more easily-grasped for the new users than that in \cite[Theorem 2]{zuo2019distributed}.
\end{enumerate}




\noindent\textbf{Notations:}
In this brief, $\boldsymbol{1}_m$ (or $\boldsymbol{0}_m$) denotes a column vector of size $m$ filled with $1$ (respectively, 0). Denote the index set of sequential integers as $\textbf{I}[m,n]=\{m,m+1,\ldots~,n\}$ where $m<n$ are two natural numbers. Define the set of real numbers, positive real numbers and nonnegative real numbers as $\mathbb{R}$, $\mathbb{R}_{>0}$ and $\mathbb{R}_{\geq 0}$, respectively. ${\rm diag}({b})$ means a diagonal matrix whose diagonal elements equal to a given vector ${b}$.
For a given symmetric matrix $A\in \mathbb{R}^{n\times n}$, its spectrum can be sorted as: $\lambda_1(A)\leq\lambda_2(A) \leq\ldots \leq\lambda_n(A)$.%; moreover, $A>0$ means that $\lambda_1(A)>0$.
%For a time-varying function $x(t): \mathbb{R}_{\geq 0 }\mapsto \mathbb{R}$, denote that $\sup_{t\in [t_0, t_1]} x(t) $ and $\inf_{t\in [t_0, t_1]} x(t)$ as the upper bound and lower bound of $x(t)$ over the time interval $[t_0, t_1]$, respectively. Moreover, denote that $\|x(t)\|_{[t_0, t_1]} =\sup_{t\in [t_0, t_1]} \|x(t)\| $. Define that $L_{\infty}:=\{x(t)|x(t): \mathbb{R}_{\geq 0 }\mapsto \mathbb{R}^n,\ \|x(t)\|_{[t_0, t_1]}<\infty\}$. In the following sections, $x(t) \in L_{\infty}$, $t\in [t_0, t_1]$, represents that the variable $x$ is uniformly bounded over $[t_0, t_1]$.   %$A\succeq 0$ (or $A\succ 0$) denotes that $A$ is a nonnegative matrix (positive matrix, respectively), which means all elements of $A$ are nonnegative (positive, respectively).
 %${\rm span}(x)$ denotes the span vector of a given vector $x=[p_1, p_2,\ldots~, p_n]^{\mathrm{T}}\in \mathbb{R}^n$.

\label{introduction}


\section{Preliminaries}\label{section2}

%\subsection{Notations}





\subsection{Graph Theory}
We employ a directed graph (`digraph' for short) to denote the communication topology of the MAS.
For the MAS, a digraph $\mathcal{G } =(\mathcal{V}, \mathcal{E}, \boldsymbol{A} )$ is a ternary,  which consists of a node set $\mathcal{V}=\{ 1, 2, \ldots~ , N \}$; an edge set $\mathcal{E} \subset \mathcal{V} \times \mathcal{V}=\{(v_j,\ v_i)\mid\ v_i,\ v_j \in \mathcal{V}\}$ such that $(v_j,\ v_i)$ is a directed edge from $v_j$ to $v_i$; and an adjacency matrix $\boldsymbol{A}=[a_{ij}] \in \mathbb{R}^{N\times N} $ is a weight matrix such that $a_{ij}\neq 0\Leftrightarrow (v_j,\ v_i) \in \mathcal{E}$ and $a_{ij}= 0$, otherwise.  
%Each node on $\mathcal{G }$ can be uniquely labeled by an integer $i$ belonging to a finite index set $\mathcal{I}=\{1, 2,  \ldots ~ , n \}$.
%Assume the signed digraph $\mathcal{G }$ is digon sign-symmetric, that is, $a_{ij}a_{ji}\geq 0,\ \forall i,\ j\in  \mathcal{I}$.
The neighbor set of node $v_i$ is defined by $\mathcal{N}_{i}=\{v_{j}\in \mathcal{V}\mid (v_j,\ v_i)\in \mathcal{E} \}$.
%An adjacency matrix $A=[a_{ij}]$ of graph $\mathcal{G}$ with order $n$ is defined as $a_{ij}=1$ if $ (v_i,v_j)\in \mathcal{E}$, but $0$ otherwise.
The Laplacian matrix ${L}\in \mathbb{R}^{n\times n}$ of graph $\mathcal{G}$ with order $N$ is defined as ${[L]}_{ii}=  \sum_{j \in \mathcal{N}_{i}} a_{ij}  $ and  ${[L]}_{ij}= -a_{ij} $ for any $i\neq j$.
A directed path of length $m$ from node $v_{s_0}$ to $v_{s_m}$ is an ordered sequence of distinct nodes $\{v_{s_0}, v_{s_1}, \ldots~ , v_{s_m}   \}$ where $(v_{s_i}, v_{s_{i+1}} ) \in \mathcal{E}$, $ \forall i\in \textbf{I}[0,m-1]$.
A digraph $\mathcal{G}$ has a directed spanning tree if and only if there exists at least one node $v_{i}$ owning a directed path to any other node $v_{j}$ on $\mathcal{G}$.
% Two nodes $v_{i}$ and $v_{j}$ on a digraph $\mathcal{G}$ are \emph{path equivalent} if there exists a directed path from $v_i$ to $v_j$ and another return path from $v_j$ to $v_i$. The node set $\mathcal{V}$ can be partitioned into a unique series of disjoint node subsets consisting of path equivalent nodes, that is, \emph{strongly connected components} of $\mathcal{G }$. A digraph is called \emph{strongly connected} if and only if all nodes belong to one strongly connected component.
To solve the problem induced by the asymmetrical Laplacian matrix ${L}$ under general directed topology, a mirror matrix ${M}$ \cite{gong2020distributed2} corresponding to ${L}$ is established as $
{M}(L)=[{\rm diag}({\rho})L+L^{\mathrm{T}}{\rm diag}({\rho})]/2$,
where $\rho=[\rho_1, \rho_2, \ldots~,\rho_N]^{\mathrm{T}}=(L^{\mathrm{T}})^{-1}\boldsymbol{1}_N$.




We then show that by having a small number of trusted nodes, networks exhibit improved robustness that otherwise could be achieved only by adding extra edges.

Given a graph $\mathcal{G } =(\mathcal{V},\mathcal{E})$, let $\mathcal{T} \subseteq  \mathcal{V}$ be a set of trusted nodes. A path consisting of only trusted nodes is referred to as the $trusted \ path$. Next, we compute and relate connectivity with trusted nodes to the traditional notion of connectivity. Let $\mathcal{G }'(\mathcal{V}, \mathcal{E}')$ be a graph
obtained from $\mathcal{G }(\mathcal{V}, \mathcal{E})$as follows: for every nonadjacent pair of nodes $u$ and $v$ in $\mathcal{G }$, if there exists a trusted node that is adjacent
to both $u$ and $v$, or if there is a trusted path connecting $u$ and $v$, then add an edge $u v$ in $\mathcal{G }'$. 
\begin{lemma}
Let $\mathcal{G } =(\mathcal{V},\mathcal{E})$ be an $r$-robust  graph with a set of trusted nodes. Let $\mathcal{U}$ be a graph obtained from  $\mathcal{G}$ by replacing each trusted node $\tau \in \mathcal{T}$ with a clique of $r$ nodes, such that if a node $u$ is adjacent in $\mathcal{G}$ to a trusted node $\tau \in \mathcal{T}$, then in $\mathcal{U}$, $u$ is adjacent to all the nodes in the clique corresponding to the trusted node $\tau$ . Then, $\mathcal{U}$ is $r$-robust.
\end{lemma}

The above-mentioned lemma provides a way of
replacing a trusted node with a certain number of nontrusted
nodes while preserving the robustness property of the network. 

Let $\mathcal{N}_t$ denotes the neighbors of trusted nodes or trusted nodes constituting trusted paths. According to the definition of trusted nodes, there exists at least $(3f+1)$ neighbors outside $\mathcal{Y}_R$  if $|\mathcal{N}_t \cap \mathcal{X}_R|+|\mathcal{T} \cap \mathcal{X}_R| \geq (3f+1)$ and $ \mathcal{Y}_R \subseteq (\mathcal{N}_t \cap \mathcal{T})$. Then $\mathcal{G}' =(\mathcal{V}, \mathcal{E}')$ is strongly $(3f+1)$-robust w.r.t. $\mathcal{X}$.



\subsection{Trusted Node}
By increasing the number of edges between nodes, the connectivity of the network will be enhanced. However, if we add some nodes such that they cannot be attacked, then the overall node connectivity can be improved similarly. Such nodes are called trust nodes. 
In practice, these components can be made more flexible and secure through complex security mechanisms to resist physical attacks, so as to realize trust. 

\begin{figure}
  \centering
  \includegraphics[height=6cm, width=14cm]{b.PNG}
  \caption{$\mathcal{G}$ with the trusted node $a$ and $\mathcal{H}$}\label{image2}
\end{figure}

Let $\mathcal{H}=(\mathcal{V}',\mathcal{E})$ be a graph obtained from $\mathcal{G}=(\mathcal{V},\mathcal{E})$ as follows:
if there exists a trusted node $\tau \in \mathcal{T}$ that is adjacent
to some nodes and the signal flows from one node to the trust node and then to another node, then add an edge between them in $\mathcal{H}$. An example is shown in Figure.$\ref{image2}$, where $a$ is the trusted nodes in $\mathcal{G}$. Since node $a$ is a trusted node, the neighbors of node $a$ are  adjacent in $\mathcal{H}$. 

\begin{myTheo}
Let $\mathcal{G}=(\mathcal{V},\mathcal{E})$ be a graph with a trusted node $\tau \in \mathcal{V}_y$. The node $\tau$ is adjacent to $r$ nodes in $\mathcal{V}_x$ and all nodes in $\mathcal{V}_y$. Then the graph $\mathcal{H}$ obtained from $\mathcal{V}$ is strongly $r$-robust w.r.t. nodes in $\mathcal{V}_x$. 
\end{myTheo}

\textbf{Proof.} 
Two cases that are discussed as follows:

\textbf{Case 1:} The node $i \in \mathcal{T}$. It is obvious node $\tau$ has $r$ in-neighbors in the set $\mathcal{V}_x$.

\textbf{Case 1:} The node $i \in \mathcal{V}_y \backslash \mathcal{T}$. According to the definition of trusted node, there exists at least $r$ neighbors outside $\mathcal{V}_y$. Thus 
$r$ in-neighbors in the set $\mathcal{V}_x$ are adjacent to all nodes in the set $\mathcal{V}_y$.

The proof is completed by above two cases.



Since $\mathcal{G } =(\mathcal{V}, \mathcal{E})$  is strongly $(2f+1)$-robust w.r.t. $\mathcal{V}_p$, there exists $S_1 \subset \mathcal{V}_{np}$, such that for any $i \in S_1$, $|\mathcal{N}_i \backslash  \mathcal{V}_{np}| \leq (2f+1)$. As $f$-local attack, we can obtain 
$|\mathcal{N}_i \cap  \mathcal{B}| \leq f$ and $|\mathcal{N}_i \cap  \mathcal{V}_p| \geq f+1$. According to W-MSR, agent $i$ removes at most $2f$ values. We consider the worst case where only one agent $o$ is retained in the set $\Omega_i(t)$. If the agent $o$ is the normal target agent, the agent $o$ can be reached from the leader. So we mainly consider the case that agent $o$ is a Byzantine agent. 

If agent $o$ is the Byzantine agent, we can find a pair of normal agents $p, q \in \mathcal{R}$ such that $z_o(t) \in [z_p(t), z_q(t)]$. From the lemma 3, we similarly select $\bar{a}_{io}(t) = \gamma \bar{a}_{ip}(t) + (1-\gamma) \bar{a}_{iq}(t)$. Byzantine node can be regarded as a combination of two normal nodes. Since ${\rm min}\{{\rm max}\{\gamma\}, {\rm max}\{1-\gamma\}\}=0.5$, we can obtain
there exists a secure directed path from leader to any follower, whose  weight is larger than 0.5$\alpha$.

Let us define $V_{np}^1=V_{np} \backslash S_1 \subset V \backslash V_p$. Since $\mathcal{G }$ is strongly $(2f+1)$-robust w.r.t. $\mathcal{V}_p$, we can find a nonempty set $S_2 \subset V_{np}^1$. There exists at least $2f+1$
in-neighbors outside $ V_{np}^1$. Since $|N_j \backslash V_{np}^1| \geq 2f+1$, for $j \in S_2$, there exists a normal agent $i \in {V}_{pR} \cup S_1$, whose value will be kept by agent $j$. From lemma 4, agent $j$ can be reached by leader with length no more than 2 in the graph $\mathcal{G}_{0.5\alpha}(\bar{\Phi}(t))$.

Similarly, we also can define $V_{np}^{\tau}=V_{np}^{\tau-1} \backslash S_{\tau}$. By repeating the above procedures, agent $k$ , for $k\in S_{\tau +1}$, can be reached via a secure directed path to it with length no more than $\tau +1$.


