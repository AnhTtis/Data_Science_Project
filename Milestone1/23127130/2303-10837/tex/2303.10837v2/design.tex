\section{FedML-HE System Design}
\label{sec:system}


% \carlee{This seems a bit generic. Does the server package go the server and the client package to the clients? Where does the key go and who generates it? What runs at the edge device--encryption module, training module, decryption module? This figure also doesn't illustrate automated scaling (does that mean new clients can be added automatically during the training?)}

In this section, we first provide the overview of FedML-HE system in \tsref{sec:system_overview}, define the threat model in \tsref{sec:threat_model}, describe the algorithmic design of FedML-HE in \tsref{sec:algo}, propose our efficient optimization method \textbf{Selective Parameter Encryption} after pinpointing the overhead bottleneck in \tsref{sec:opt}, and explain how we integrate homomorphic encryption in federated learning from a software framework perspective in \tsref{sec:he_fedml}. 

\subsection{System Overview}
\label{sec:system_overview}

As shown in Figure~\ref{fig:mlops-flow}, our efficient HE-based federated training process at a high level goes through three major stages: \textit{(1)} Encryption key agreement: the clients either use threshold HE key agreement protocol or trusted key authority to generate HE keys; \textit{(2)} Encryption mask calculation: the clients and the server apply \textbf{Selective Parameter Encryption} method using homomorphic encryption to agree on a selective encryption mask; \textit{(3)} Encrypted federated learning: the clients selectively encrypt local model updates using the homomorphic encryption key and the encryption mask for efficient privacy-preserving training. %Detailed steps can be found in Algorithm~\ref{alg:fedml-fhe}.



\subsection{Threat Model}
\label{sec:threat_model}
% \shanshan{I modified this subsection. is the new threat model correct? i commented the old version. If the new description is wrong, please revert to the original version. }We define two types of adversaries: an honest-but-curious (HBC) adversary (or a passive adversary), and an active adversary. 
% The honest-but-curious adversary can be the adversarial FL server or an external attacker (or eavesdropper). They would not disrupt or modify the FL training process but are always curious to learn sensitive information, such as the clients' training data, as much  as possible.
% On the other hand, being curious about sensitive local training data as well, the active adversary can further actively corrupt the aggregation server or any subset of local clients. Loosely speaking, under such an adversary,  only the private information in local models from the corrupted clients will be learned when the active adversary corrupts a subset of clients; no private information from local models nor global models will be learned by the active adversary when it corrupts the aggregation server.

% In this paper, we consider a single-key homomorphic encryption setup, which is sufficient to prevent the HBC adversary and the simple cases of the active adversary, where the active adversary corrupts either the FL aggregation server or a subset of clients. As for the complex case of the active adversary where both the aggregation server and a number of clients are corrupted, the default setup where the private key is shared with all clients (also with corrupted clients) will allow the adversary to decrypt local models from benign clients by combining encrypted local models received by the corrupted server and the private key received by any corrupted client. This issue can be mitigated by adopting the threshold or multi-key variant of HE where decryption must be collaboratively performed by a certain number of clients~\cite{aloufi2021computing, ma2022privacy, du2023efficient}. Since the multi-party homomorphic encryption issue is not the focus of this work, we defer the details on threshold homomorphic encryption federated learning setup and microbenchmarks to the appendix.

We define a semi-honest adversary $\mathcal{A}$ that can corrupt the aggregation server or any subset of local clients. $\mathcal{A}$ follows the protocol but tries to learn as much information as possible. Loosely speaking, under such an adversary, the security definition requires that only the private information in local models from the corrupted clients will be learned when $\mathcal{A}$ corrupts a subset of clients; no private information from local models nor global models will be learned by $\mathcal{A}$ when $\mathcal{A}$ corrupts the aggregation server.

When $\mathcal{A}$ corrupts both the aggregation server and a number of clients, the default setup where the private key is shared with all clients (also with corrupted clients) will allow $\mathcal{A}$ to decrypt local models from benign clients (by combining encrypted local models received by the corrupted server and the private key received by any corrupted client). This issue can be mitigated by adopting the threshold or multi-key variant of HE where decryption must be collaboratively performed by a certain number of clients~\cite{aloufi2021computing, ma2022privacy, du2023efficient}. Since the multi-party homomorphic encryption issue is not the focus of this work, in the rest of the paper we default to a single-key homomorphic encryption setup, but details on threshold homomorphic encryption federated learning setup and microbenchmarks are provided in the appendix.

%\carlee{Need to have a section here describing how the training works with a pipeline diagram}

\subsection{Algorithm for HE-Based Federated Aggregation}
\label{sec:algo}

%\carlee{I think this should go into Section 3, or at least, before the encryption mask discussion. Otherwise there is no context for what happens to the masked parameters}

\noindent Privacy-preserving federated learning systems utilize homomorphic encryption to enable the aggregation server to combine local model parameters without viewing them in their unencrypted form by designing homomorphic encrypted aggregation functions. We primarily focus on FedAvg~\cite{mcmahan2017communication}, which has been proved as still one of the most robust federated aggregation strategies while maintaining computational simplicity~\cite{wang2022unreasonable}. 


%       \begin{algorithm}[H]
% \SetKwFor{ForPar}{for}{do in parallel}{end forpar}
%     \caption{HE-Based Federated Aggregation}
%     \label{alg:fedml-fhe}
%     %\weizhao{@Yuhang, can you fix the algo format here?}
% /*Key authority server generates a key pair $(pk, sk)$ and the crypto context then distributes it to clients and server. (except server does not get $sk$); */%\yuhang{Weizhao: Add multi-key pseudo code?}
% \raggedright %yuhang: done

% \For{$t = 1, 2, \dots, T$}{
%     \ForPar{each client $i \in [N]$}{
%         \If{$t > 1$}{
%             Receive $[\![\mathbf{W}_\text{glob}]\!]$ from $\mathcal{S}$;\\
%             $\mathbf{W}_i \gets Dec(sk, [\![\mathbf{W}_\text{glob}]\!])$;\\
%         }
%         $\mathbf{W}_i \gets Train(\mathbf{W}_i, \mathcal{D}_i)$;\\
%         $[\![\mathbf{W}_i]\!] \gets Enc(pk, \mathbf{W}_i)$;\\
%         Send $[\![\mathbf{W}_i]\!]$ to server $\mathcal{S}$;\\
%     }
%     \tcp{Server Aggregation}
%     $[\![\mathbf{W}_\text{glob}]\!] \gets \sum_{i=1}^N \alpha_i [\![\mathbf{W}_i]\!]$;\\
% }
% \end{algorithm}
Our HE-based secure aggregation algorithm, as illustrated in Algorithm~\ref{alg:fedml-fhe}, can be summarized as: given an aggregation server and $N$ clients, each client $i\in [N]$ owns a local dataset $\mathcal{D}_i$ and initializes a local model $\mathbf{W}_i$ with the aggregation weighing factor $\alpha_i$; the key authority or the distributed threshold key agreement protocol generates a key pair $(pk, sk)$ and the crypto context, then distributes it to clients and server (except the server only gets the crypto context which is public configuration). The clients and the server then collectively calculate the encryption mask $\mathbf{M}$ for \textbf{ Selective Parameter Encryption} also using homomorphic encryption.
%\carlee{does $pk$ get sent to both clients and server?}\weizhao{Good catch! Server does not need $pk$ in this case actually, if any more functions needed, it can always use plaintext [operator] ciphertext. Fixed} 
At every communication round $t \in [T]$, the server performs the aggregation 
$$[\mathbf{W}_{\text {glob}}] =\sum_{i=1}^N \alpha_i [\![\mathbf{M} \odot \mathbf{W}_i]\!] + \sum_{i=1}^N \alpha_i ((\mathbf{1}-\mathbf{M})\odot \mathbf{W}_i),$$ 
where $[\mathbf{W}_{\text {glob}}]$ is the partially-encrypted global model, $\mathbf{W}_i$ is the $i$-th plaintext local model where $[\![]\!]$ indicates the portion of the model that is fully encrypted, $\alpha_i$ is the aggregation weight for client $i$, and $\mathbf{M}$ is the model encryption mask.
%\carlee{does $\alpha_i$ come from FedAvg? Or is it part of the HE scheme?}\yuhang{change to aggregation weight} 


Note that the aggregation weights can be either encrypted or in plaintext depending on whether the aggregation server is trustworthy enough to obtain that information. In our system, we set the aggregation weights to be plaintext by default. We only need one multiplicative depth %\carlee{what does ``depth'' mean? Would you have deeper HE multiplication if the weighting factors were also encrypted?} \weizhao{the depth means the max number of multiplications of a chain of operators within a function, for example, a x b x c is 2. So in our case, a weighted mean function is always 1 no matter the factor numbers are encrypted or not}
of HE multiplication in our algorithm for weighting, which is preferred to reduce HE multiplication operations. Our system can also be easily extended to support more FL aggregation functions with HE by encrypting and computing the new parameters in these algorithms (e.g. FedProx~\cite{li2020federated}). Additionally, in Algorithm~\ref{alg:fedml-fhe}, optional local differential privacy noise can be easily added after local models are trained if there is an extra desire for differential privacy. 

\begin{algorithm}[ht!]
\SetKwFor{ForPar}{for}{do in parallel}{end forpar}
    \caption{HE-Based Federated Aggregation}
    \label{alg:fedml-fhe}
    %\weizhao{@Yuhang, can you fix the algo format here?}
    \begin{itemize}[itemsep=0em]
        %\item $\mathcal{S}$: aggregation server $|$ $N$: clients;
        %\item $\mathcal{D}_i$: a local dataset owned by Client $i\in [N]$;
        \item $[\![\mathbf{W}]\!]$: the fully encrypted model $|$ $[\mathbf{W}]$: the partially encrypted model;
        %\item $\alpha_i$: the aggregation weighing factor;
        \item $p$: the ratio of parameters for selective encryption;
        %\item $T$: the number of communication rounds;
        \item $b$: (optional) differential privacy parameter.
    \end{itemize}
\tcp{Key Authority Generate Key}
$(pk, sk) \gets HE.KeyGen(\lambda)$;

\tcp{Local Sensitivity Map Calculation}
\ForPar{each client $i \in [N]$}{
    $\mathbf{W}_i \gets Init(\mathbf{W})$;

    $\mathbf{S}_i \gets Sensitivity(\mathbf{W}, \mathcal{D}_i)$;
    
    $[\![\mathbf{S}_i]\!] \gets Enc(pk, \mathbf{S}_i)$;
    
    Send $[\![\mathbf{S}_i]\!]$ to server;
}
\tcp{Server Encryption Mask Aggregation}
$[\![\mathbf{M}]\!] \gets Select(\sum_{i=1}^N \alpha_i [\![\mathbf{S}_i]\!], p$);

\tcp{Training}
\raggedright %yuhang: done
\For{$t = 1, 2, \dots, T$}{
    \ForPar{each client $i \in [N]$}{
        \If{$t = 1$}{
             Receive $[\![\mathbf{M}]\!]$ from server;\\
            $\mathbf{M} \gets HE.Dec(sk,  [\![\mathbf{M}]\!])$;\\
        }
        \If{$t > 1$}{
            Receive $[\mathbf{W}_\text{glob}]$ from server;\\
            $\mathbf{W}_i \gets HE.Dec(sk, \mathbf{M} \odot [\mathbf{W}_\text{glob}]) + (\mathbf{1}-\mathbf{M})\odot [\mathbf{W}_\text{glob}]$;\\
        }
        $\mathbf{W}_i \gets Train(\mathbf{W}_i, \mathcal{D}_i)$;\\
        \tcp{Additional Differential Privacy}
        \If{Add DP}{
        $\mathbf{W}_i \gets \mathbf{W}_i + Noise(b)$;
        }
        $[\mathbf{W}_i] \gets HE.Enc(pk, \mathbf{M} \odot \mathbf{W}_i) + (\mathbf{1}-\mathbf{M})\odot \mathbf{W}_i$;\\
        Send $[\mathbf{W}_i]$ to server $\mathcal{S}$;\\
    }
    \tcp{Server Model Aggregation}
    $[\mathbf{W}_{\text {glob}}] \gets \sum_{i=1}^N \alpha_i [\![\mathbf{M} \odot \mathbf{W}_i]\!] + \sum_{i=1}^N \alpha_i ((\mathbf{1}-\mathbf{M})\odot \mathbf{W}_i)$;\\
}
\end{algorithm}

We will explain in detail how the encryption mask $\mathbf{M}$ is formalized in \tsref{sec:opt}.
% \begin{wrapfigure}{L}{0.5\textwidth}
% \begin{minipage}{0.5\textwidth}
% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.5\textwidth]{figs/dls-new.pdf}
%     \caption{Framework Structure: our framework consists of a three-layer structure including Crypto Foundation to support basic HE building blocks, ML Bridge to connect crypto tools with ML functions, and FL Orchestration to coordinate different parties during a task.}
%     \label{fig:design}
% \end{figure}
% \end{minipage}
% \end{wrapfigure}



% \begin{wrapfigure}{r}{0.5\textwidth}
%   \begin{center}
%     \includegraphics[width=0.48\textwidth]{figs/dls-new.pdf}
%   \end{center}
%   \caption{Birds}
% \end{wrapfigure}

% \begin{figure}[htbp]
%   \centering

%   \begin{subfigure}[t]{0.48\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{figs/dls.pdf}
%     \caption{Framework Structure: our framework consists of a three-layer structure including Crypto Foundation to support basic HE building blocks, ML Bridge to connect crypto tools with ML functions, and FL Orchestration to coordinate different parties during a task.}
%     \label{fig:design}
%   \end{subfigure}
%   \hfill
%   \begin{subfigure}[t]{0.5\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{figs/opt-scheme.pdf}
%     \caption{A Universal Overhead Optimization Scheme: Parameter Efficiency x Parameter Selection. Reducing the number of model parameters and selectively encrypting them significantly reduces FedML-HE's overhead while preserving privacy.}
%     \label{fig:opt_scheme}
%     \end{subfigure}
%     \caption{Framework Overview}
% \end{figure}



 %\carlee{does this change for other types of aggregation?} \weizhao{yes, it depends on the multiplicative depth of the aggregation function, i.e., how many mult operations in the function}





%yuhang: go on kk

% \begin{figure}
% \includegraphics[width=0.47\textwidth]{figs/model_comm.pdf}
% \caption{(w/o Optimization) Communicational Overhead For Models of Different Sizes: FedML-HE vs. Nvidia FLARE vs. Plaintext Aggregation}
% \label{fig:comm}
% \end{figure}


%and Figure~\ref{fig:comm}. Empirically, it typically has $10\times$ more computation overhead and $15\times$ more communication overhead than the plaintext FL.
%\yuhang{The computation cost and the communication cost (file size) are $O(n)$, both grows linearly with the model size $n$.} 
%\carlee{is there existing theoretical analysis on HE overheads to support this observation? E.g., big-O runtime bounds?}
% \yuhang{Weizhao: Add that Multi-key Table}

\input{opt}

\subsection{Software Framework: Homomorphic Encryption In Federated Learning}
\label{sec:he_fedml}
\noindent In this part, we will illustrate how we design our HE-based aggregation from a software framework perspective. 
% \carlee{talk a bit more about why you used a layered design and how this facilitates integration.}
\begin{figure}[ht!]
  \centering
 \includegraphics[width=0.48\textwidth]{figs/dls-new.pdf}
  \caption{Framework Structure: our framework consists of a three-layer structure including Crypto Foundation to support basic HE building blocks, ML Bridge to connect crypto tools with ML functions, and FL Orchestration to coordinate different parties during a task. }
    \label{fig:design}
\end{figure}

Figure~\ref{fig:design} provides a high-level design of our framework, which consists of three major layers: 
%\carlee{where is each of these modules located? At each client?}
\begin{itemize}[noitemsep,topsep=0pt]
    \item \textbf{Crypto Foundation.} The foundation layer is where Python wrappers are built to realize HE functions including key generation, encryption/decryption, secure aggregation, and ciphertext serialization using open-sourced HE libraries;
    \item \textbf{ML Bridge.} The bridging layer connects the FL system orchestration and cryptographic functions. Specifically, we have ML processing APIs to process inputs to HE functions from local training processes and outputs vice versa. Additionally, we realize the optimization module here to mitigate the HE overheads;
    \item \textbf{FL Orchestration.} The FL system layer is where the key authority server manages the key distribution and the (server/client) managers and task executors orchestrate participants.
\end{itemize}
Our layered design makes the HE crypto foundation and the optimization module \textit{semi-independent}, allowing different HE libraries to be easily switched into FedML-HE and further FL optimization techniques to be easily added to the system.