\section{Preliminaries And Related Work}
\subsection{Federated Learning}
Federated learning is first proposed in~\cite{mcmahan2017communication}, which builds distributed machine learning models while keeping personal data on clients. Instead of uploading data to the server for centralized training, clients process their local data and share updated local models with the server. Model parameters from a large population of clients are aggregated by the server and combined to create an improved global model. 

The FedAvg~\cite{mcmahan2017communication} is commonly used on the server to combine client updates and produce a new global model. At each round, a global model $\mathbf{W}_\text {glob}$ is sent to $N$ client devices.
Each client $i$ performs gradient descent on its local data with $E$ local iterations to update the model $\mathbf{W}_i$.
%For a client learning rate $\eta$, the local client update of 1 local epoch, $w_k$, is given by
%\begin{equation}
%   w_k\leftarrow w_k - \eta g_k.
%\end{equation}
The server then does a weighted aggregation of the local models to obtain a new global model, $\mathbf{W}_{\text {glob}}=\sum_{i=1}^N \alpha_i \mathbf{W}_i,$ where $\alpha_i$ is the weighting factor for client $i$.
%the number of local data points in

Typically, the aggregation runs using plaintext model parameters through a central server  (in some cases, via a decentralized protocol), giving the server visibility of each local client's model in plaintext.

\subsection{Homomorphic Encryption}
\input{fhe.tex}
 Homomorphic Encryption is a cryptographic primitive that allows computation to be performed on encrypted data without revealing the underlying plaintext. It usually serves as a foundation for privacy-preserving outsourcing computing models. HE has generally four algorithms (\textit{KeyGen}, \textit{Enc}, \textit{Eval}, \textit{Dec}) as defined in Figure~\ref{fig:fhe}. The fundamental concept is to encrypt data prior to computation, perform the computation on the encrypted data without decryption, and then decrypt the resulting ciphertext to obtain the final plaintext.

Since FL model parameters are usually not integers, our method is built on the Cheon-Kim-Kim-Song (CKKS) scheme~\cite{cheon2017homomorphic}, a (leveled) HE variant that can work with approximate numbers.

\subsection{Previous Work}
\noindent\textbf{Existing Privacy Attacks On FL}
Threats and attacks on privacy in the domain of Federated Learning have been studied in recent years~\cite{mothukuri2021survey}. General FL privacy attacks can be categorized into two types: inference attacks~\cite{nasr2019comprehensive, wang2019beyond, truex2019demystifying} and data leakage/reconstruction~\cite{criswell2014kcofi,bhowmick2018protection, hitaj2017deep}. Attacks are usually carried out on the models to retrieve certain properties of data providers or even reconstruct the data in the training datasets. With direct access to more fine-grained local models trained on a smaller dataset~\cite{wang2019beyond}, the adversary can have a higher chance of a successful attack.  Moreover, further attacks can be performed using GAN-based attacks to even fully recover the original data~\cite{hitaj2017deep}. The majority of the privacy attacks can be traced back to the direct exposure of plaintext accesses to local models to other parties (usually the aggregation server) within the system.

\noindent\textbf{Existing Non-HE Defense Mechanism}
Compared to other existing solutions providing privacy protection in FL, HE is non-interactive and dropout-resilient (vs. general Multi-Party Computation protocols~\cite{bonawitz2017practical, so2022lightsecagg}); it introduces negligible model performance degradation (vs. noise-based Differential Privacy solutions~\cite{truex2019hybrid,byrd2020differentially}).

\noindent\textbf{Existing HE-based FL Work}
Existing HE-based FL work either apply restricted HE schemes (e.g. additive scheme Paillier)~\cite{zhang2020batchcrypt,fang2021privacy, jiang2021flashe} without extensibility to further FL aggregation functions as well as sufficient performance and security guarantee (due to Paillier) or provide a generic HE implementation on FL aggregation~\cite{roth2022nvidia,ibmfl, jiang2021flashe, du2023efficient, ma2022privacy}. However, previous work still leaves the HE overhead increase issue as an open question. In our work, we propose a universal optimization scheme to largely reduce the overhead while providing promised privacy guarantees in a both systematic and algorithmic fashion, which makes HE-based FL viable in practical deployments.
