\begin{proof}
    We denote by $U(\theta) \subseteq [K]$ the support of $\theta$ and  $C = \bigcap_{\theta \in \Theta} U(\theta)$. We consider $N$ environments $\{\mu_{\theta}\}_{\theta \in \Theta}$ such that for $\mu_{\theta}$ and arm $j$, $\mu_{\theta}(j) = \frac{1}{2} - \Delta\mathbb{I}\{j \in U(\theta) \backslash C\}$, where $0 < \Delta < \frac{1}{2}$ is to be tuned later. Let $\mu_0$ be an environment such that $\mu_0(j) = \frac{1}{2}$ for any arm $j$. Note that $\theta$ is the optimal policy in $\mu_{\theta}$, and for $\theta' \in \Theta \backslash \{\theta\}$, we have that:
    \begin{equation*}
        \sum_{j=1}^K (\theta'(j) - \theta(j)) \mu(j) = \Delta \sum_{j\in U(\theta) \backslash C} \left(\frac{1}{M} - 0\right) = \Delta \frac{M-V}{M}.
    \end{equation*}
    And thus, 
    \begin{align*}
        R_T(\mu_\theta) &= \Delta \frac{M-V}{M} (T - N_{\mu_\theta}(\theta; T)) \\
        &\geq \Delta \frac{M-V}{M} \bigg(T - N_{\mu_0}(\theta; T) - T \sqrt{\frac{1}{2}D(P_{\mu_0},P_{\mu_\theta})}\bigg),
    \end{align*}
    where the inequality follows from the fact that\footnote{See Exercise 14.4 in \cite{lattimore2020bandit} for a general version of this inequality.} $N_{\mu_\theta}(\theta; T) - N_{\mu_0}(\theta; T) \leq T \tv(P_{\mu_0},P_{\mu_\theta})$ and by Pinsker's inequality. Starting from Lemma \ref{low:kl-decomp}, we have that:
    \begin{align*}
         D(P_{\mu_0}, P_{\mu_\theta}) &= \sum_{\theta' \in \Theta} N_{\mu_0}(\theta'; T) \sum_{j=1}^K \theta'(j) d(\mu_0(j),\mu_\theta(j)) \\
         &= N_{\mu_0}(\theta; T) \sum_{j\in U(\theta) \backslash C} \frac{1}{M} d\left(\frac{1}{2},\frac{1}{2}-\Delta\right)\\
         &= \frac{M-V}{M} N_{\mu_0}(\theta; T) \left(-\frac{1}{2} \log(1-4\Delta^2)\right)\\
         &\leq \frac{M-V}{M} N_{\mu_0}(\theta; T) c \Delta^2, 
    \end{align*}
    where the second equality holds since the only arms whose means have changed between the two environments lie exclusively in the support of $\theta$,
    and the inequality holds for $\Delta \leq \frac{1}{4}$ with $c = 8\log{\frac{4}{3}}$. Hence:
    \begin{align*}
        \sup_{\mu} R_T(\mu) &\geq \frac{1}{N}\sum_{\theta \in \Theta} R_T(\mu_\theta)\\
        &\geq \Delta \frac{M-V}{M} \bigg(T - \frac{T}{N} - T \sqrt{\frac{1}{2}\frac{M-V}{M} \frac{T}{N} c \Delta^2}\bigg)\\
        &\geq \Delta \frac{M-V}{M} T \bigg(\frac{1}{2} - \Delta \sqrt{\frac{1}{2}\frac{M-V}{M} \frac{T}{N} c}\bigg),
    \end{align*}
    where the second inequality holds by the concavity of the square root, and the third since $N\geq2$. The theorem then follows by setting $\Delta = \frac{1}{4} \sqrt{\frac{2MN}{c(M-V)T}}$ and verifying that the condition on $T$ ensures that $\Delta \leq \frac{1}{4}$.
\end{proof}