\begin{proof}
    Noting  that $\hat{\ell}_t$ is unbiased given $x_t$, we get that
    $
         R_T 
        = \E \sum\nolimits_t \langle x_t - \theta^*, \hat{\ell}_t \rangle.
    $
    This expression is the regret of OMD on the estimated losses with a decision set $\text{co}(\Theta)$ and the negative entropy function $\psi(x) = \sum_{j} x(j) \log x(j)$ as the regularizer. Using Lemma 6.14 in \cite{orabona},\footnote{See also, still in \cite{orabona}, the discussion leading up to Theorem 10.2 concerning the negative entropy regularizer.} we get that:     
    \begin{equation} \label{cvxhull-omd}
        R_T \leq \frac{D(\theta^*, \tau^*)}{\eta} + \frac{\eta}{2} \E \sum\nolimits_t\sum\nolimits_j x_t(j) \hat{\ell}^2_t(j),
    \end{equation}
    Similar to the last step of the proof of Theorem \ref{upper:alt-losses:thm}, we can show that
    $\E \sum_{j} x_t(j) \hat{\ell}^2_t(j) \leq K$. 
    The proof concludes by bounding $D(\theta^*, \tau^*)$ with $D^*(\Theta)$ and plugging in the value of $\eta$.
\end{proof}


    %\begin{equation*} %\label{cvxhull-omd}
    %    R_T \leq \frac{D(\theta^*, \tau)}{\eta} + \frac{\eta}{2} \E \sum_{t=1}^T\sum_{j=1}^K z_t(j) \hat{\ell}^2_t(j),
    %\end{equation*}
    %where $z_t$ lies on the line segment between $x_t$ and $\tilde{x}_{t+1} = \argmin_{x \in \text{dom}(\psi)} \eta \langle x, \hat{\ell}_t \rangle + D(x, x_t)$. It can be shown that $\tilde{x}_{t+1}(j) = x_t(j) \exp(-\eta \hat{\ell}_t(j))$, and since $\hat{\ell}_t(j)$ is non-negative, we get that $\tilde{x}_{t+1}(j) \leq x_t(j)$, and thus $\E \sum_{j=1}^K z_t(j) \hat{\ell}^2_t(j) \leq \E \sum_{j=1}^K x_t(j) \hat{\ell}^2_t(j) \leq K$, where the last inequality follows from the definition of $\hat{\ell}_t(j)$ and the fact that $\ell_t(j)\leq 1$. 