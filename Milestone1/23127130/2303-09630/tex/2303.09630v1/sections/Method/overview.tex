In this section, we detail our nonlinear model reduction method based on the hyper-reduced decoder. 

The first step in our proposed method is the selection of the indices of the sample mesh and the construction of the stencil mesh. This step is described in Section \ref{subsec:stencil_mesh}. In Section \ref{subsec:AE} we describe how once a set of stencil mesh indices is fixed we can train a reduced decoder $\hat{g}$ using high-fidelity solutions of \eqref{eq:FOM} restricted on the stencil mesh. The reduced decoder $\hat{g}$ can then be used in the reduced order model \eqref{eq:hyperODeltaE} to estimate the restriction of the FOM states $\vy$ on the stencil mesh (as in \eqref{eq:ghat}). In Section \ref{subsec:gappyPOD} we then recall the Gappy-POD method and how it can be used to efficiently recover ${\vy}$ from $\hat{\vy}$.

In this section, we will assume that \eqref{eq:FOM} has been solved for $n_\text{train}$ number of parameters $\mu \in \R^{N_\mu}$ and for $N_t$ number of time steps. The high-fidelity solutions have then been collected in a snapshots matrix
\[
	\mY_{\text{train}} = \big[ \vy^0_{\mu_1}, \dots, \vy^{N_t}_{\mu_1}, \dots,  \vy^{0}_{\mu_{n_\text{train}}}  , \dots,  \vy^{N_t}_{n_\text{train}}\big] \in \R^{N \times n_\text{train}\,(N_t + 1)}.
\]
We will denote by $\mPhi \in R^{N \times n_\text{train}\,(N_t + 1)}$ the orthogonal (POD) matrix obtained the Singular Value Decomposition (SVD) of the snapshot matrix $\mY_{text{train}}$. We also use $\mathcal{Y}_\text{train}$ to denote the set of  high-fidelity solutions $\mathcal{Y}_\text{train} = \{ \vy^0_{\mu_1}, \dots,  \vy^{N_t}_{\mu_1}, \dots,  \vy^{0}_{\mu_{n_\text{train}}}  , \dots,  \vy^{N_t}_{n_\text{train}}\}$
