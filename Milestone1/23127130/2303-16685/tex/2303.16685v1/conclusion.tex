\section{Conclusions and Future Work}\label{conclusion}
%The use of reinforcement learning (RL) for load balancing has gain increasingly more attention in recent years. 
% Efficient load balancing can help to improve the quality of experience for network systems.
Reinforcement learning (RL) for load balancing has gained increasingly more attention in recent years. Although RL can achieve impressive performance, its generalization to diverse and unseen traffic patterns is a challenging problem. In this work, we have proposed a policy reuse framework that allows the selection of suitable pre-trained RL policies for unseen traffic scenarios. We construct a policy bank that contains pre-train RL policies trained on a diverse set of traffic scenarios. When facing a new traffic scenario, we use a policy selector to find the policy whose scenario it trained on is the most similar to this new scenario. Our results demonstrate the effectiveness of our solution against rule-based and adaptive rule-based methods. Our future work includes policy selection on a shorter time frame and policy ensemble.