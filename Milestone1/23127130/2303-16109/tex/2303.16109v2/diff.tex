%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%DIF LATEXDIFF DIFFERENCE FILE
%DIF DEL D:\OneDrive\OneDrive\PHD\4. Chapter Two\RAL Revision\latexdiff\old\root.tex   Thu Jun 15 21:19:47 2023
%DIF ADD D:\OneDrive\OneDrive\PHD\4. Chapter Two\RAL Revision\latexdiff\new\root.tex   Wed Jun 21 17:04:41 2023
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts % This command is only needed if 
\RequirePackage[normalem]{ulem}
\providecommand{\DIFdel}[1]{{\color{red}\sout{#1}}} % Don't show deleted text
\providecommand{\DIFadd}[1]{{\color{blue}\uline{#1}}}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}                      
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{lmodern}
\usepackage{mathtools}
%\usepackage[shortlabels]{enumitem}
\usepackage{url}
\def\UrlBreaks{\do\/\do-}
\usepackage{breakurl}
\usepackage[breaklinks]{hyperref}
\usepackage{multirow}
\usepackage{booktabs}
%DIF 22a22-26
\usepackage{xcolor} %DIF > 
\usepackage{tabularray} %DIF > 
\usepackage{rotating} %DIF > 
\usepackage{tabularray} %DIF > 
\usepackage{makecell} %DIF > 
\usepackage{graphics}
%DIF -------
%\usepackage{unicode-math}
\DeclareMathOperator*{\argmin}{arg\,min}
%DIF 24a29-30
\newcommand{\Hquad}{\hspace{0.5em}}  %DIF > 
 %DIF > 
%DIF -------
\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{\LARGE \bf
Multimodal Manoeuvre and Trajectory Prediction for \DIFdelbegin \DIFdel{Autonomous Vehicles }\DIFdelend \DIFaddbegin \DIFadd{Automated Driving on Highways }\DIFaddend Using Transformer Networks
}


\author{Sajjad Mozaffari, \DIFaddbegin \DIFadd{Mreza Alipour Sormoli, }\DIFaddend Konstantinos Koufos, and Mehrdad Dianati% <-this % stops a space
\thanks{This work was part of the Hi-Drive project. The project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No. 101006664.}% <-this % stops a space
\thanks{All authors are with WMG,
        University of Warwick, Coventry, U.K.
        {\tt\small Email: \href{mailto:sajjad.mozaffari@warwick.ac.uk}{sajjad.mozaffari@warwick.ac.uk} }}%
}
%DIF PREAMBLE EXTENSION ADDED BY LATEXDIFF
%DIF CTRADITIONAL PREAMBLE %DIF PREAMBLE
\RequirePackage{color}\definecolor{RED}{rgb}{1,0,0}\definecolor{BLUE}{rgb}{0,0,1} %DIF PREAMBLE
\RequirePackage[stable]{footmisc} %DIF PREAMBLE
\DeclareOldFontCommand{\sf}{\normalfont\sffamily}{\mathsf} %DIF PREAMBLE
\providecommand{\DIFaddtex}[1]{{\protect\color{blue} \sf #1}} %DIF PREAMBLE
\providecommand{\DIFdeltex}[1]{{\protect\color{red} [..\footnote{removed: #1} ]}} %DIF PREAMBLE
%DIF SAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddbegin}{} %DIF PREAMBLE
\providecommand{\DIFaddend}{} %DIF PREAMBLE
\providecommand{\DIFdelbegin}{} %DIF PREAMBLE
\providecommand{\DIFdelend}{} %DIF PREAMBLE
\providecommand{\DIFmodbegin}{} %DIF PREAMBLE
\providecommand{\DIFmodend}{} %DIF PREAMBLE
%DIF FLOATSAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddFL}[1]{\DIFadd{#1}} %DIF PREAMBLE
\providecommand{\DIFdelFL}[1]{\DIFdel{#1}} %DIF PREAMBLE
\providecommand{\DIFaddbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFaddendFL}{} %DIF PREAMBLE
\providecommand{\DIFdelbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFdelendFL}{} %DIF PREAMBLE
%DIF HYPERREF PREAMBLE %DIF PREAMBLE
\providecommand{\DIFadd}[1]{\texorpdfstring{\DIFaddtex{#1}}{#1}} %DIF PREAMBLE
\providecommand{\DIFdel}[1]{\texorpdfstring{\DIFdeltex{#1}}{}} %DIF PREAMBLE
%DIF COLORLISTINGS PREAMBLE %DIF PREAMBLE
\RequirePackage{listings} %DIF PREAMBLE
\RequirePackage{color} %DIF PREAMBLE
\lstdefinelanguage{DIFcode}{ %DIF PREAMBLE
%DIF DIFCODE_CTRADITIONAL %DIF PREAMBLE
  moredelim=[il][\color{red}\scriptsize]{\%DIF\ <\ }, %DIF PREAMBLE
  moredelim=[il][\color{blue}\sffamily]{\%DIF\ >\ } %DIF PREAMBLE
} %DIF PREAMBLE
\lstdefinestyle{DIFverbatimstyle}{ %DIF PREAMBLE
	language=DIFcode, %DIF PREAMBLE
	basicstyle=\ttfamily, %DIF PREAMBLE
	columns=fullflexible, %DIF PREAMBLE
	keepspaces=true %DIF PREAMBLE
} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim}{\lstset{style=DIFverbatimstyle}}{} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim*}{\lstset{style=DIFverbatimstyle,showspaces=true}}{} %DIF PREAMBLE
%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF

\begin{document}



\maketitle
\DIFdelbegin %DIFDELCMD < \thispagestyle{empty}
%DIFDELCMD < \pagestyle{empty}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \thispagestyle{plain}
\pagestyle{plain}
\DIFaddend 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}

Predicting the behaviour (i.e.\DIFaddbegin \DIFadd{, }\DIFaddend manoeuvre/trajectory) of other road users, including vehicles, is critical for the safe and efficient operation of autonomous vehicles (AVs), a.k.a.\DIFaddbegin \DIFadd{, }\DIFaddend automated driving systems (ADSs). Due to the uncertain future behaviour of vehicles, multiple future behaviour modes are often plausible for a vehicle in a given driving scene. Therefore, multimodal prediction can provide richer information than single-mode prediction\DIFaddbegin \DIFadd{, }\DIFaddend enabling AVs to perform a better risk assessment. To this end, we propose a novel multimodal prediction framework that can predict multiple plausible behaviour modes and their likelihoods. The proposed framework includes a bespoke problem formulation for manoeuvre prediction, a novel transformer-based prediction model, and a tailored training method for multimodal manoeuvre and trajectory prediction. The performance of the framework is evaluated using \DIFdelbegin \DIFdel{two public benchmark }\DIFdelend \DIFaddbegin \DIFadd{three public }\DIFaddend highway driving datasets, namely NGSIM\DIFdelbegin \DIFdel{and highD}\DIFdelend \DIFaddbegin \DIFadd{, highD, and exiD}\DIFaddend . The results show that \DIFdelbegin \DIFdel{the proposed }\DIFdelend \DIFaddbegin \DIFadd{our }\DIFaddend framework outperforms the state-of-the-art multimodal methods in \DIFdelbegin \DIFdel{the literature in }\DIFdelend terms of prediction error and is capable of predicting plausible manoeuvre and trajectory modes.

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Introduction}
%1. Importance of the problem
% major challenge of multimodal prediction

Predicting the behaviour of other road users, including vehicles, is crucial for safe and informed decision-making in automated/autonomous vehicles (AVs). A vehicle's future behaviour is inherently multimodal and nondeterministic due to multiple degrees of freedom in a typical driving scenario and the inherent lack of knowledge about the intentions and reactions of other road users. An AV shall consider all plausible future behaviour modes (hereinafter referred to as modes)  of the \DIFdelbegin \DIFdel{surrounding }\DIFdelend \DIFaddbegin \DIFadd{nearby }\DIFaddend vehicles to effectively assess and manage the risks and enhance driving safety and efficiency. To this end, several multimodal prediction approaches have been proposed in the literature.

A category of \DIFdelbegin \DIFdel{existing }\DIFdelend multimodal approaches in the literature predicts multiple plausible modes, each represented by a single manoeuvre type and its corresponding trajectory~\cite{Deo_2018, Mersch2021, Chen2022}. Such an approach does not provide a comprehensive picture of the future \DIFdelbegin \DIFdel{behaviour mode }\DIFdelend \DIFaddbegin \DIFadd{modes }\DIFaddend of a vehicle since a single manoeuvre type can have multiple behaviour realisations depending on the driving styles and interactions with other vehicles. For example, aggressive drivers execute a left lane change \DIFdelbegin \DIFdel{manoeuvre }\DIFdelend differently from conservative drivers in terms of the start time and duration of the manoeuvre. In addition, the future behaviour of a vehicle within a prediction horizon can include a sequence of more than one manoeuvre type.

Another category of existing studies predicts multiple \DIFdelbegin \DIFdel{behaviour }\DIFdelend modes, each represented by a trajectory\DIFaddbegin \DIFadd{, without predicting the manoeuvre of vehicles}\DIFaddend . There are \DIFdelbegin \DIFdel{two approaches in this category, }\DIFdelend generative and discriminative  \DIFaddbegin \DIFadd{approaches under this category}\DIFaddend . Generative approaches rely on estimating the probability \DIFdelbegin \DIFdel{density }\DIFdelend \DIFaddbegin \DIFadd{distribution }\DIFaddend function (PDF) of the trajectory using generative models such as  Conditional Variational Auto Encoders (CVAEs) 
 in ~\cite{Salzmann2020, Lee2017} or Generative Adversarial Networks (GANs) in ~\cite{Zhao2019, Gupta2018}. They then sample the PDF to generate multiple trajectories. However, these approaches often require many samples to cover all plausible \DIFdelbegin \DIFdel{future }\DIFdelend modes, especially those with lower probabilities, which is not ideal from a planning perspective. On the contrary, discriminative approaches assume a predetermined number of modes and predict one trajectory for each mode along with its likelihood~\cite{Liu2021, Huang2022}. The training of these approaches relies on designing a mode selection method \DIFdelbegin \DIFdel{with the aim of assigning }\DIFdelend \DIFaddbegin \DIFadd{to assign }\DIFaddend each ground truth \DIFdelbegin \DIFdel{behaviour }\DIFdelend mode to one of the \DIFdelbegin \DIFdel{fixed-number trajectory outputs of the model}\DIFdelend \DIFaddbegin \DIFadd{prediction modes}\DIFaddend . Poor mode selection methods can lead to convergence problems such as mode collapsing~\cite{Liu2021, Zhang2021} or implausible modes~\cite{Rhinehart2018, Greer2021}. In the former, multiple predicted trajectories converge to a single plausible mode in the driving scene, whereas in the latter, some predicted trajectories do not conform to traffic or scene context, such as off-road \DIFaddbegin \DIFadd{or invalid collision }\DIFaddend predictions.
% due to receiving much fewer training updates compared to other modes.

To address the aforementioned limitations, we propose a novel Multimodal Manoeuvre and Trajectory Prediction (MMnTP) framework. Firstly, we \DIFdelbegin \DIFdel{propose a bespoke }\DIFdelend \DIFaddbegin \DIFadd{provide a new }\DIFaddend formulation of manoeuvre prediction based on a vector representation of manoeuvres\DIFdelbegin \DIFdel{. This representation }\DIFdelend \DIFaddbegin \DIFadd{, which }\DIFaddend includes a sequence of manoeuvre types and transition times \DIFdelbegin \DIFdel{between those }\DIFdelend during the prediction window. To increase the plausibility of the predictions, constraints are introduced on the manoeuvre types and the number of allowed manoeuvre changes within the prediction horizon. We then propose a multimodal discriminative manoeuvre prediction model using this new formulation. The \DIFdelbegin \DIFdel{framework also }\DIFdelend \DIFaddbegin \DIFadd{proposed framework }\DIFaddend employs state-of-the-art transformer neural networks~\cite{Vaswani2017} augmented by manoeuvre-specific heads to predict multiple trajectories conditioned on the predicted manoeuvre vectors. To train the model, a novel multimodal manoeuvre prediction loss function and a mode selection method are proposed based on the predicted types and timings of manoeuvres. \DIFdelbegin \DIFdel{The proposed }\DIFdelend \DIFaddbegin \DIFadd{Our }\DIFaddend framework is evaluated in highway driving scenarios using \DIFdelbegin \DIFdel{two }\DIFdelend \DIFaddbegin \DIFadd{three }\DIFaddend public trajectory datasets, namely NGSIM~\cite{ngsim}\DIFdelbegin \DIFdel{and }\DIFdelend \DIFaddbegin \DIFadd{, }\DIFaddend highD~\cite{highD}\DIFaddbegin \DIFadd{, and exiD~\cite{exiDdataset}}\DIFaddend . Our contributions can be summarised as follows:
\begin{itemize}
    \item A \DIFdelbegin \DIFdel{bespoke }\DIFdelend \DIFaddbegin \DIFadd{new }\DIFaddend formulation of manoeuvre prediction, which allows estimating a sequence of manoeuvre types and transition times between them.
    \item A novel transformer-based model to predict multimodal manoeuvres and their corresponding trajectories. 
    \item A tailored multimodal training method using a new multimodal manoeuvre loss function and mode selection method.
    \item Comprehensive and comparative performance evaluation of \DIFdelbegin \DIFdel{the proposed framework }\DIFdelend \DIFaddbegin \DIFadd{MMnTP }\DIFaddend using well-known benchmark datasets and state-of-the-art multimodal models.
\end{itemize}
%The rest of this paper is organised as follows. Section~\ref{sec:relworks} reviews recent multimodal prediction approaches. Section~\ref{sec:method} introduces the proposed framework. Section~\ref{sec:eval} presents the performance evaluation. Finally, some concluding remarks are given in Section~\ref{sec:conc}.


\section{Related Works}\label{sec:relworks}
Anticipating the future behaviour of other vehicles has been one of the main focuses of research in intelligent vehicles for the last few decades. Early works, reviewed in~\cite{survey_motion_risk}, use physics-based kinematic models \DIFdelbegin \DIFdel{~\cite{Lytrivis2008, Barth2008, Kaempchen2004} }\DIFdelend to predict the short-term future motion. In recent years, learning-based methods, reviewed in~\cite{mozaffari2022Survey, Liu2021s}, have become popular due to their increased prediction accuracy and extended prediction horizon (i.e., more than 3 seconds). In this section, we specifically review two subsets of recent learning-based methods that correlate with our proposed approach.
\subsection{Manoeuvre-based Multimodal prediction}
These methods rely on early recognition of the manoeuvre intention of vehicles as prior knowledge for trajectory prediction. \DIFdelbegin \DIFdel{N. Deo and M.M Trivedi}\DIFdelend \DIFaddbegin \DIFadd{The authors in}\DIFaddend ~\cite{Deo_2018, Deo20118iv} proposed encoder-decoder neural networks for manoeuvre-based multimodal trajectory prediction. In both papers, \DIFdelbegin \DIFdel{a manoeuvre set is defined by combining three lateraland two longitudinal manoeuvre types in }\DIFdelend \DIFaddbegin \DIFadd{the prediction modes include six lateral/longitudinal manoeuvres for }\DIFaddend highway driving scenarios. The decoder network estimates the probability of each \DIFdelbegin \DIFdel{manoeuvre type }\DIFdelend \DIFaddbegin \DIFadd{mode }\DIFaddend and predicts one trajectory per \DIFdelbegin \DIFdel{manoeuvre type}\DIFdelend \DIFaddbegin \DIFadd{mode}\DIFaddend . In~\cite{Chen2022}, a three-layer hierarchical network consisting of Long Short-Term Memory (LSTM) and attention mechanism is used to encode the vehicles' motion, \DIFaddbegin \DIFadd{and }\DIFaddend their social interaction with other vehicles\DIFdelbegin \DIFdel{at each time step, and the temporal dependencies in their social interaction}\DIFdelend . Then, a decoding mechanism similar to that in~\cite{Deo20118iv} is used to predict manoeuvre-based trajectories. In~\cite{Messaoud2021} an attention-pooling architecture with specialised heads per manoeuvre type is introduced. \DIFdelbegin \DIFdel{Mostly similar to }\DIFdelend \DIFaddbegin \DIFadd{In~\cite{galceran2017multipolicy} the distributions over multiple future policies (i.e., manoeuvre types) of nearby vehicles are estimated, and then the policies are sampled to plan for the Ego vehicle accordingly. Similar to }\DIFaddend our paper, Mersch~\textit{et al.}~\cite{Mersch2021} \DIFdelbegin \DIFdel{predict }\DIFdelend \DIFaddbegin \DIFadd{predicted }\DIFaddend the sequence of manoeuvre types of vehicles at \DIFdelbegin \DIFdel{time steps equal to one second. The predicted manoeuvre vector is augmented with the learnt features to }\DIFdelend \DIFaddbegin \DIFadd{one-second time steps as an auxiliary feature to }\DIFaddend predict a single \DIFdelbegin \DIFdel{modal trajectory . Given three manoeuvre types such as right lane change, left lane change and lane keeping and a prediction horizon of 5 seconds, their model can output $3^5=243$ different manoeuvre sequences. However, most of these sequences are not feasible }\DIFdelend \DIFaddbegin \DIFadd{trajectory output. Their model can generate numerous manoeuvre sequences, but most of them are unrealistic }\DIFaddend in real-world driving \DIFdelbegin \DIFdel{since drivers do not tend to change their manoeuvresregularly}\DIFdelend \DIFaddbegin \DIFadd{as drivers don't frequently change manoeuvres}\DIFaddend . We address this problem by limiting the number of manoeuvre changes in \DIFdelbegin \DIFdel{a manoeuvre vector prediction. In addition, we introduced a multimodal }\DIFdelend \DIFaddbegin \DIFadd{our predictions. Additionally, we introduce a multimodal framework for }\DIFaddend manoeuvre and trajectory prediction\DIFdelbegin \DIFdel{framework}\DIFdelend , in contrast to \DIFdelbegin \DIFdel{the single modal modeldeveloped in~\cite{Mersch2021}}\DIFdelend \DIFaddbegin \DIFadd{Mersh et al.'s single-modal model}\DIFaddend .

\subsection{Dynamic Multimodal Prediction}
In these methods, multiple trajectories are predicted without using pre-defined manoeuvre types. Such studies broadly fall into the two following sub-categories:

\subsubsection{Generative Models} They \DIFdelbegin \DIFdel{attempt to }\DIFdelend estimate the multimodal probability distribution of future trajectories conditioned on past observation. \DIFdelbegin \DIFdel{In such models , }\DIFdelend \DIFaddbegin \DIFadd{These models rely on sampling to generate }\DIFaddend multiple future trajectories\DIFdelbegin \DIFdel{are generated by sampling the estimated distribution multiple times}\DIFdelend . In~\cite{Zyner2020, Mercat2020} mixture density model is \DIFdelbegin \DIFdel{used }\DIFdelend \DIFaddbegin \DIFadd{applied }\DIFaddend on top of a Recurrent Neural Network (RNN) to model the multimodal \DIFdelbegin \DIFdel{trajectory }\DIFdelend distribution. Conditional Variational Auto Encoders (CVAEs) are commonly used to explicitly encode \DIFdelbegin \DIFdel{multimodal future trajectory }\DIFdelend \DIFaddbegin \DIFadd{the aforementioned }\DIFaddend distribution~\cite{Lee2017, Zhao2019, Salzmann2020, Cui2021, Yuan2021}. \DIFdelbegin \DIFdel{Several }\DIFdelend \DIFaddbegin \DIFadd{However, several }\DIFaddend studies use Generative Adversarial Networks (GAN) to implicitly model the multimodality~\cite{Gupta_2018_CVPR, Sadeghian_2019_CVPR, Vinet2019}. In general, generative methods require a very large number of samples to cover all prediction modes, especially the ones with low probability that are not necessarily unimportant. In addition, such models do not provide a likelihood value for each predicted \DIFdelbegin \DIFdel{trajectory }\DIFdelend mode, which is necessary for risk assessment in AVs. 

\subsubsection{Discriminative Models} They directly regress multiple future trajectories and their probabilities. In~\cite{Cui2019} a convolutional neural network is applied on a rasterised bird-eye view representation of the driving environment to predict multiple futures. During training, a mode selection method is defined to select the matching mode to the ground truth \DIFaddbegin \DIFadd{for each data sample}\DIFaddend . The winning mode receives the weight updates through gradient descent optimisation\DIFdelbegin \DIFdel{for each data sample}\DIFdelend . The authors argue that modelling the multimodal behaviour highly depends on the ability of the mode selection method to distinguish between different \DIFdelbegin \DIFdel{behaviour }\DIFdelend modes in a driving scenario. Several studies~\cite{Zhang2021, Kim2021, Messaoud2021, Huang2022, Liu2021, Zhang2021} adopt similar training strategies while attempting to increase compliance with the driving environment and diversity of the predictions. In~\cite{Zhang2021} a scoring and selection layer is introduced to rank the modes and reject the near-duplicates. Kim~\textit{et al.}~\cite{Kim2021} propose a lane-aware feature extraction to predict trajectories in compliance with \DIFdelbegin \DIFdel{the surrounding environment}\DIFdelend \DIFaddbegin \DIFadd{lanes}\DIFaddend . To increase the diversity of models, Haung et al.~\cite{Huang2022} use transformers with multimodal attention heads where each \DIFdelbegin \DIFdel{trajectory }\DIFdelend mode is assigned to a group of attention heads. Liu et al~\cite{Liu2021} \DIFdelbegin \DIFdel{use stacked transformers to predict multiple trajectory modes. The authors }\DIFdelend propose a region-based training algorithm \DIFdelbegin \DIFdel{by assigning groups of prediction modes to }\DIFdelend \DIFaddbegin \DIFadd{for stacked transformers to improve diversity. They group prediction modes based on }\DIFaddend plausible driving regions\DIFdelbegin \DIFdel{to improve the diversity of predictions}\DIFdelend . In~\cite{Zhang2021} a set-based neural network architecture is used to predict \DIFdelbegin \DIFdel{map-adaptive trajectory modes }\DIFdelend \DIFaddbegin \DIFadd{trajectories }\DIFaddend from a set of \DIFdelbegin \DIFdel{proposals based on map-adaptive goals}\DIFdelend \DIFaddbegin \DIFadd{map adaptive proposals}\DIFaddend . In this paper, we use a dynamic discriminative multimodal prediction approach\DIFdelbegin \DIFdel{, while }\DIFdelend \DIFaddbegin \DIFadd{. However, }\DIFaddend unlike existing studies\DIFaddbegin \DIFadd{, }\DIFaddend multiple future modes are predicted in manoeuvre space, enabled by vector representation of manoeuvres. Also, a mode selection method is introduced to differentiate between future modes based on the predicted manoeuvre vectors.








\section{Proposed Framework}\label{sec:method}
This section describes the proposed \textbf{M}ultimodal \textbf{M}anoeuvre \textbf{a}nd \textbf{T}rajectory \textbf{P}rediction (\textbf{MMnTP}) framework. First, we define the \DIFdelbegin \DIFdel{bespoke }\DIFdelend multimodal manoeuvre and trajectory prediction problem and notations in Section~\ref{sec:prob}.
We then describe the \DIFdelbegin \DIFdel{proposed }\DIFdelend transformer-based prediction model and its main components in Section~\ref{sec:model}. Finally, the \DIFdelbegin \DIFdel{tailored }\DIFdelend training process is explained in Section~\ref{sec:train}.



\subsection{Problem Definition}\label{sec:prob}
We define the problem of multimodal manoeuvre and trajectory prediction as the estimation of multiple \DIFdelbegin \DIFdel{plausible }\DIFdelend future modes, each \DIFdelbegin \DIFdel{with }\DIFdelend \DIFaddbegin \DIFadd{represented by }\DIFaddend a sequence of manoeuvre types which we call a manoeuvre vector $\hat{M}_i$, a corresponding trajectory $\hat{Y}_i$ and a probability of occurrence $p_i$, where $i\in\{1,.., N\}$ and $N$ is the number of prediction modes. The prediction is carried out for \DIFdelbegin \DIFdel{the }\DIFdelend $T_{pred}$ \DIFdelbegin \DIFdel{time steps in future }\DIFdelend \DIFaddbegin \DIFadd{future time steps }\DIFaddend based on the observation $O$ of a target vehicle \DIFaddbegin \DIFadd{(TV) }\DIFaddend and its surrounding \DIFaddbegin \DIFadd{vehicles (SVs) }\DIFaddend during the past $T_{obs}$ time steps. The predicted manoeuvre vector of mode $i$ \DIFdelbegin \DIFdel{, }\DIFdelend is defined as $\hat{M}_i=\{\hat{m}_{i,t}\}_{t=1}^{T_{pred}}$, and its corresponding trajectory is defined as $\hat{Y}_i=\{\hat{y}_{i,t}\}_{t=1}^{T_{pred}}$\DIFdelbegin \DIFdel{. At the time step $t$, the }\DIFdelend \DIFaddbegin \DIFadd{, where $\hat{y}_{i,t} =(\hat{y}^{long}_{i,t},\hat{y}^{lat}_{i,t})$ is the predicted x-y location (in meters) of mode }\DIFaddend $i$ \DIFdelbegin \DIFdel{-th }\DIFdelend \DIFaddbegin \DIFadd{at time-step $t$. The }\DIFaddend predicted manoeuvre type, $\hat{m}_{i,t}$, is the intention of the \DIFdelbegin \DIFdel{target vehicle }\DIFdelend \DIFaddbegin \DIFadd{TV }\DIFaddend when moving from \DIFdelbegin \DIFdel{x-y }\DIFdelend location $\hat{y}_{i,t-1}$ to $\hat{y}_{i,t}$. \DIFdelbegin \DIFdel{Manoeuvre }\DIFdelend \DIFaddbegin \DIFadd{Similarly, $M=\{m_t\}_{t=1}^{T_{pred}}$ and $Y=\{y_t\}_{t=1}^{T_{pred}}$ denote the ground-truth future manoeuvre vector and trajectory, respectively. All manoeuvre }\DIFaddend types belong to a countable pre-defined manoeuvre set $\bar{M}$. In \DIFdelbegin \DIFdel{the highway drivingscenario}\DIFdelend \DIFaddbegin \DIFadd{highway driving}\DIFaddend , three manoeuvre types are defined as Lane Keeping (LK), Right Lane Change (RLC), and Left Lane \DIFdelbegin \DIFdel{Change }\DIFdelend \DIFaddbegin \DIFadd{Changes }\DIFaddend (LLC).

\DIFdelbegin %DIFDELCMD < \begin{figure}[!t] %%%
%DIF <  TODO fix notation of t_{c,i}
%DIFDELCMD < \centering
%DIFDELCMD < \includegraphics[width=3.4in]{Figures/manoeuvre_fig.pdf}
%DIFDELCMD < %%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
\DIFdelFL{An example of manoeuvre vector representation. The following terminology is used in the exemplar input/output data. EV: Ego Vehicle, TV: Target Vehicle, SV: Surrounding Vehicle.}}
%DIFAUXCMD
%DIFDELCMD < \label{man_fig}
%DIFDELCMD < \end{figure}
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend We assume that vehicles do not change their manoeuvre \DIFdelbegin \DIFdel{intentions with periods }\DIFdelend \DIFaddbegin \DIFadd{in }\DIFaddend less than $T_{change}$ time steps. Therefore the prediction \DIFdelbegin \DIFdel{of }\DIFdelend \DIFaddbegin \DIFadd{horizon, }\DIFaddend $T_{pred}$\DIFdelbegin \DIFdel{time steps ahead }\DIFdelend \DIFaddbegin \DIFadd{, }\DIFaddend can be divided into $C=\lceil \frac{T_{pred}}{T_{change}}\rceil$ change periods. \DIFdelbegin \DIFdel{Hence, a manoeuvre vector can be }\DIFdelend \DIFaddbegin \DIFadd{A manoeuvre vector is }\DIFaddend written as $M \equiv \{U, V\}$, where  $U = \{u_i\}_{i=0}^{C}$ and $V = \{v_i\}_{i=1}^{C}$ are the manoeuvre type and manoeuvre transition time vectors, respectively. Precisely, $u_i \in \bar M$ is the manoeuvre type at the beginning of \DIFaddbegin \DIFadd{the }\DIFaddend $(i+1)$-th change period and $v_i \in [0,1]$ is the \DIFdelbegin \DIFdel{normalised }\DIFdelend transition time from  \DIFdelbegin \DIFdel{manoeuvre }\DIFdelend type $u_{i-1}$ to $u_i$\DIFdelbegin \DIFdel{within the $i$-th change period }\DIFdelend \DIFaddbegin \DIFadd{. The transition times are determined by measuring the duration from the beginning of each manoeuvre change period and then normalizing them to the duration of the change period}\DIFaddend . If $u_{i-1}=u_i$, the transition time\DIFaddbegin \DIFadd{, $v_i$, }\DIFaddend will be ignored (its value is set to $-1$).  Fig.~\ref{man_fig} demonstrates an example of a \DIFdelbegin \DIFdel{manoeuvre vector and its corresponding trajectory.
%DIF <  The manoeuvre vector can be automatically extracted from a ground-truth trajectory.
}%DIFDELCMD < \begin{figure*}[!t] %%%
\DIFdelendFL \DIFaddbeginFL \DIFaddFL{vehicle trajectory and its respective manoeuvre vector.
}\begin{figure}[!t] \DIFaddendFL % TODO fix notation of t_{c,i}
\centering
\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=6.8in]{Figures/model_fig.pdf}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=\linewidth]{Figures/manoeuvre_fig.pdf}
\DIFaddendFL \caption{An \DIFdelbeginFL \DIFdelFL{overview }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{example }\DIFaddendFL of \DIFaddbeginFL \DIFaddFL{a manoeuvre vector with three change periods: $\{C_1, C_2, C_3\}$. The following terminology is used throughout }\DIFaddendFL the \DIFdelbeginFL \DIFdelFL{proposed prediction model}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{paper}\DIFaddendFL . \DIFaddbeginFL \DIFaddFL{EV: Ego Vehicle, TV: Target Vehicle, SV: Surrounding Vehicle.}\DIFaddendFL }
\DIFdelbeginFL %DIFDELCMD < \label{model_fig}
%DIFDELCMD < \end{figure*}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \label{man_fig}
\end{figure}
\DIFaddend 

%DIF >  The manoeuvre vector can be automatically extracted from a ground-truth trajectory.
 \DIFaddbegin 


\DIFaddend \subsection{Prediction Model}\label{sec:model}
The prediction model includes three main components. First, a transformer encoder extracts latent features from a sequence of interaction-aware inputs (Section~\ref{sec:feature}). Then, a multimodal manoeuvre generator estimates multiple manoeuvre vectors and their likelihoods (Section~\ref{sec:man}). Finally, a \DIFdelbegin \DIFdel{transformer decoder with manoeuvre-specific heads }\DIFdelend \DIFaddbegin \DIFadd{trajectory predictor }\DIFaddend uses the learnt features and estimated manoeuvre vectors to predict their associated trajectory (Section~\ref{sec:traj}). Fig.~\ref{model_fig} illustrates the architecture of the \DIFdelbegin \DIFdel{prediction model}\DIFdelend \DIFaddbegin \DIFadd{MMnTP}\DIFaddend .


\subsubsection{Feature Learning}\label{sec:feature}
The input data to the prediction model is the track history of the \DIFdelbegin \DIFdel{target vehicle and its surrounding vehicles }\DIFdelend \DIFaddbegin \DIFadd{TV and its SVs, }\DIFaddend and the position of lane markings during an observation window of $T_{obs}$ time steps. We consider eight \DIFdelbegin \DIFdel{surrounding vehicles }\DIFdelend \DIFaddbegin \DIFadd{SVs }\DIFaddend including the preceding and following vehicles and the three closest vehicles in each of the adjacent lanes. In~\cite{Wirthmuller2021}\DIFaddbegin \DIFadd{, }\DIFaddend a systematic study has been performed to identify the most relevant features for behaviour prediction in highway driving scenarios, which are also validated by our empirical studies in~\cite{mozaffari2022}. The same set of features is used in this study. These features describe the motion of the \DIFdelbegin \DIFdel{target vehicle }\DIFdelend \DIFaddbegin \DIFadd{TV }\DIFaddend (e.g., its lateral acceleration), its interaction with \DIFdelbegin \DIFdel{surrounding vehicles }\DIFdelend \DIFaddbegin \DIFadd{SVs }\DIFaddend (e.g., the relative longitudinal velocity of the \DIFdelbegin \DIFdel{target vehicle }\DIFdelend \DIFaddbegin \DIFadd{TV }\DIFaddend with respect to the following vehicle), and the driving environment (e.g., the existence of right/left lanes).

A transformer encoder model \DIFdelbegin \DIFdel{, }\DIFdelend introduced in~\cite{Vaswani2017}, is used to encode the input feature sequence. Within the encoder model, the input features are embedded into vectors of $512$ \DIFdelbegin \DIFdel{dimension}\DIFdelend \DIFaddbegin \DIFadd{dimensions}\DIFaddend . Then, a sinusoidal positional encoding (proposed in~\cite{Vaswani2017}) is added to the embedded input to specify the order of each input in the sequence.  Finally, eight heads of self-attention are applied to the embedded data, followed by a normalisation layer and a linear layer of size $128$.
\DIFdelbegin \DIFdel{Our empirical study shows that a single transformer encoder layer has the best performance in our evaluation of highway driving datasets.
}\DIFdelend 

\subsubsection{Manoeuvre Prediction} \label{sec:man}
The multimodal manoeuvre generator takes as input the hidden representation learnt by the encoder and predicts $N$ manoeuvre vectors and their probabilities. The \DIFdelbegin \DIFdel{multimodal manoeuvre generator }\DIFdelend model is a two-layer fully-connected neural network with $256$ hidden neurons and ReLU activation function. The output layer contains $N$ neurons for the estimation of mode probabilities, $N\times (C+1)\times3$ neurons for the classification of manoeuvre types, and \DIFdelbegin \DIFdel{$N$ }\DIFdelend \DIFaddbegin \DIFadd{$N\times C$ }\DIFaddend neurons for the regression of manoeuvre change times. \DIFaddbegin \DIFadd{Note that $N$ is the number of prediction modes and $C$ is the number of change periods, as explained in Section~\ref{sec:prob}. 
}\begin{figure*}[!t]
\centering
\includegraphics[width=\textwidth]{Figures/model_fig2.pdf}
\caption{\DIFaddFL{An overview of the MMnTP prediction model.}}
\label{model_fig}
\end{figure*}
\DIFaddend 

\subsubsection{Trajectory Prediction} \label{sec:traj}
The trajectory prediction component includes a transformer decoder network, introduced in~\cite{Vaswani2017}, and manoeuvre-specific heads. Similar to the transformer encoder, the decoder network includes embedding, positional encoding, multi-head self-attention, normalisation layers, and linear layers. In addition, the decoder network benefits from a multi-head cross-attention mechanism to find relevancy between the decoder output and the encoded latent representation. We refer interested readers to~\cite{Vaswani2017} for more details about the transformers. Similar to the encoder network, we use \DIFdelbegin \DIFdel{a single-layer transformer decoder with }\DIFdelend an embedded size of $512$, eight attention heads, and a linear layer of size $128$ \DIFaddbegin \DIFadd{in the transformer decoder}\DIFaddend .

The output of the transformer decoder is fed to manoeuvre-specific heads to \DIFdelbegin \DIFdel{generate trajectories per }\DIFdelend \DIFaddbegin \DIFadd{predict each coordinate of a trajectory based on the estimated }\DIFaddend manoeuvre type. For the application of the framework in highway driving scenarios, three heads are considered corresponding to RLC, LK, and LLC manoeuvre types. 
Each head \DIFdelbegin \DIFdel{acts as an expert in trajectory prediction for a manoeuvre type. The future trajectory is selected from manoeuvre heads based on the predicted manoeuvre types within the manoeuvre vector (note the input from the manoeuvre prediction block to the selector in the trajectory prediction block in Fig.~\ref{model_fig}). Each head is }\DIFdelend \DIFaddbegin \DIFadd{is }\DIFaddend a linear layer and outputs the parameters of a bi-variate Gaussian distribution (i.e., the x-y means, variances, and correlation coefficient) \DIFdelbegin \DIFdel{at }\DIFdelend \DIFaddbegin \DIFadd{for }\DIFaddend each prediction time step. \DIFdelbegin \DIFdel{Note that during inferencethe }\DIFdelend \DIFaddbegin \DIFadd{During inference, the future trajectory is predicted using the heads that correspond to the sequence of manoeuvre types within the predicted manoeuvre vector. The }\DIFaddend mean values of the estimated Gaussian distributions are \DIFdelbegin \DIFdel{outputted }\DIFdelend \DIFaddbegin \DIFadd{reported }\DIFaddend as the predicted \DIFaddbegin \DIFadd{coordinates of a }\DIFaddend trajectory.

%DIF > \begin{equation}
%DIF >     \Omega_{r,t} = \{\mu_{r,t}, \Sigma_{r,t}\},
%DIF > \end{equation}
%DIF > where $1\leq r\leq3$ corresponds to one of three pre-defined manoeuvre types, $\mu$ is the x-y mean and $\Sigma$ is the covariance matrix. 
\DIFaddbegin 

\DIFaddend \subsection{Training Process} \label{sec:train}
We use end-to-end learning to predict multiple manoeuvre vectors, their corresponding trajectories and \DIFdelbegin \DIFdel{their likelihood }\DIFdelend \DIFaddbegin \DIFadd{likelihoods }\DIFaddend from a sequence of input features. The \DIFdelbegin \DIFdel{overall }\DIFdelend training loss $L$ consists of a trajectory prediction part $L^{traj}$ and a multimodal manoeuvre prediction part $L^{man}$.
\DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \begin{equation}
    L = L^{traj} + L^{man}.
\end{equation}

The \DIFdelbegin \DIFdel{trajectory prediction loss }\DIFdelend \DIFaddbegin \DIFadd{term $L^{traj}$ }\DIFaddend aims to minimise the negative log-likelihood \DIFaddbegin \DIFadd{(NLL) }\DIFaddend of the estimated bi-variate Gaussian \DIFdelbegin \DIFdel{distribution calculated at the x-y location of the }\DIFdelend \DIFaddbegin \DIFadd{distributions evaluated at each time step of the future }\DIFaddend ground truth trajectory \DIFdelbegin \DIFdel{for each time step}\DIFdelend \DIFaddbegin \DIFadd{$Y=\{y_t\}_{t=1}^{T_{pred}}$}\DIFaddend . We use the teacher-forcing technique in optimising the \DIFdelbegin \DIFdel{prediction }\DIFdelend model's parameters~\cite{Williams1989}. Therefore, \DIFdelbegin \DIFdel{to predict the x-y location }\DIFdelend \DIFaddbegin \DIFadd{for prediction }\DIFaddend at time step \DIFdelbegin \DIFdel{$t+1$, $\hat{y}_{t+1}$, }\DIFdelend \DIFaddbegin \DIFadd{$t$, }\DIFaddend the ground truth manoeuvre vector \DIFdelbegin \DIFdel{$M_{0:t}$ }\DIFdelend \DIFaddbegin \DIFadd{$M_{1:t}=\{m_j\}_{j=1}^t$ }\DIFaddend and the ground truth trajectory \DIFdelbegin \DIFdel{$Y_{0:t}$ }\DIFdelend \DIFaddbegin \DIFadd{$Y_{1:t-1}=\{y_j\}_{j=1}^{t-1}$ }\DIFaddend at previous time steps are used. Thus, the trajectory prediction loss \DIFdelbegin \DIFdel{for each data sample }\DIFdelend can be written as:
\begin{equation}
\DIFdelbegin %DIFDELCMD < \begin{aligned}
%DIFDELCMD <     &L^{traj}=\\
%DIFDELCMD <     &-log\Bigl(f_{\hat Y}(y_{1}|m_{1}, O)\prod_{t=1}^{T_{pred}} f_{\hat Y}(y_{t+1}|M_{0:t},Y_{0:t}, O)\Bigl),
%DIFDELCMD < \end{aligned}%%%
\DIFdelend \DIFaddbegin \begin{aligned}
    % &L^{traj}=\\
    &-\log\Bigl(f_{\hat Y}(y_{1}|m_{1}, O, \hat{\Omega}_1)\prod_{t=2}^{T_{pred}} f_{\hat Y}(y_{t}|M_{1:{t}},Y_{1:{t-1}}, O, \hat{\Omega}_t)\Bigl),
%L^{traj}= &-\log\left(\prod_{t=1}^{T_{pred}} f_{\hat Y}(y_{t}|\{m_j\}_{j=0}^t,\{y_j\}_{j=0}^{t-1}, O)\right),
\end{aligned}\DIFaddend 
\end{equation}
where $f_{\hat Y}$ is \DIFdelbegin \DIFdel{the estimated }\DIFdelend \DIFaddbegin \DIFadd{a }\DIFaddend bivariate Gaussian distribution \DIFdelbegin \DIFdel{of future trajectory}\DIFdelend \DIFaddbegin \DIFadd{parameterised by $\hat{\Omega}_t$ at time-step t}\DIFaddend .

Inspired by the Multiple Trajectory Prediction loss (MTP)\DIFdelbegin \DIFdel{introduced in}\DIFdelend ~\cite{Cui2019}, we propose a Multiple Manoeuvre Prediction (MMP) loss in \DIFaddbegin \DIFadd{the }\DIFaddend manoeuvre space. \DIFdelbegin \DIFdel{A }\DIFdelend \DIFaddbegin \DIFadd{Specifically, a }\DIFaddend novel mode selection method is defined \DIFdelbegin \DIFdel{to find the matching predicted mode to the ground truth}\DIFdelend \DIFaddbegin \DIFadd{as follows}\DIFaddend :
\begin{equation}
    n^* =  \underset{n\in \{1,...,N\}}{\argmin} L^{\hat{U}}_n,
\end{equation}
where $L^{\hat{U}}_n$ is \DIFdelbegin \DIFdel{a negative log-likelihood }\DIFdelend \DIFaddbegin \DIFadd{the NLL }\DIFaddend loss for the classification of manoeuvre types \DIFdelbegin \DIFdel{of }\DIFdelend \DIFaddbegin \DIFadd{in }\DIFaddend mode $n$ \DIFdelbegin \DIFdel{:
}\DIFdelend \DIFaddbegin \DIFadd{that can be read as:
}\DIFaddend \begin{equation}
    L^{\hat{U}}_{n} = -\log \DIFdelbegin \DIFdel{p_{\hat U_n}.
}\DIFdelend \DIFaddbegin \DIFadd{\prod}\limits\DIFadd{_{c=0}^{C} q_{n,c}, 
}\DIFaddend \end{equation}
\DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{where $q_{n,c}$ is the estimated probability of ground truth manoeuvre type $u_c$ for mode $n$. }\DIFaddend Once the winning mode $n^*$ is identified, the manoeuvre loss can be calculated as:
\begin{equation}
    L^{man} = L^{p} +  L^{\hat{U}}_{n^*} +  L^{\hat{V}}_{n^*},
\end{equation}
where \DIFdelbegin \DIFdel{:
}\begin{displaymath}\DIFdel{\label{eq:man_losses}
\begin{aligned}
    & L^{p} = -\log p_{n^*}\\
    & L^{\hat{V}}_{n} = \lVert V-\hat V_n\lVert_2.
\end{aligned}
}\end{displaymath}%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{The loss function $L^{p}$ is the negative log-likelihood of the selected mode , and $L^{\hat{V}}_{n}$ }\DIFdelend \DIFaddbegin \DIFadd{$L^{p} = -\log p_{n^*}$ is the NLL of the estimated probability of the winning mode and $L^{\hat{V}}_{n^*}$ }\DIFaddend is the Euclidean norm between the \DIFdelbegin \DIFdel{predicted }\DIFdelend \DIFaddbegin \DIFadd{estimated }\DIFaddend manoeuvre change timings and their ground truth values \DIFdelbegin \DIFdel{.
}\DIFdelend \DIFaddbegin \DIFadd{for the winning mode that can be read as:
}\begin{equation}\DIFadd{\label{eq:man_losses}
\begin{aligned}
    %& L^{p} = -\log p_{n^*}\\
    & L^{\hat{V}}_{n^*} = \lVert V-\hat V_{n^*}\lVert_2. 
\end{aligned}
}\end{equation}
\DIFaddend 

\section{Performance Evaluation}~\label{sec:eval}
In this section, we evaluate the performance of the \DIFdelbegin \DIFdel{proposed }\DIFdelend \DIFaddbegin \DIFadd{MMnTP }\DIFaddend framework in highway driving scenarios. \DIFdelbegin \DIFdel{we }\DIFdelend \DIFaddbegin \DIFadd{We }\DIFaddend first explain the selected datasets\DIFaddbegin \DIFadd{, the data preprocessing steps, }\DIFaddend and the evaluation metrics, followed by the implementation details. Then, we compare the performance of the framework with state-of-the-art \DIFdelbegin \DIFdel{prediction methods}\DIFdelend \DIFaddbegin \DIFadd{models}\DIFaddend . We also provide \DIFdelbegin \DIFdel{an ablation study to compare the proposed transformer-based prediction model with and without the multimodal manoeuvre and trajectory prediction both quantitatively and qualitatively}\DIFdelend \DIFaddbegin \DIFadd{two ablation studies to analyse the impact of the number of prediction modes and the proposed training process in our framework. Finally, we provide the results of a contingency motion planner using MMnTP prediction data}\DIFaddend .

\subsection{Dataset \DIFaddbegin \DIFadd{and Data Preprocess}\DIFaddend }% pr data prepration
We consider \DIFdelbegin \DIFdel{two widely used }\DIFdelend \DIFaddbegin \DIFadd{three real-world }\DIFaddend trajectory datasets for \DIFdelbegin \DIFdel{our real-world }\DIFdelend \DIFaddbegin \DIFadd{the }\DIFaddend highway driving scenario evaluation, namely \DIFaddbegin \DIFadd{NGSIM~\cite{ngsim}, }\DIFaddend highD~\cite{highD}\DIFdelbegin \DIFdel{and NGSIM~\cite{ngsim}. The }\DIFdelend \DIFaddbegin \DIFadd{, and exiD~\cite{exiDdataset}. The NGSIM dataset includes two different highways in the US with $5$- to $6$- lanes and mild, moderate, and congested traffic conditions. The }\DIFaddend highD dataset contains \DIFdelbegin \DIFdel{$110,000$ vehicle trajectories in six different locations in Germany. The dataset includes }\DIFdelend different traffic states (e.g., traffic jams) in $2$- to $3$-lane highways \DIFdelbegin \DIFdel{. The highD dataset has been originally recorded at 25 FPS, which we downsample to 5 FPS in our application. The NGSIM dataset includes $9,206$ vehicle trajectories on two different highways in the US. NGSIM dataset is recorded in $5$- to $6$- lane highways with mild, moderate, and congested traffic conditions}\DIFdelend \DIFaddbegin \DIFadd{in six different locations. NGSIM and highD are the benchmark highway trajectory datasets used in many studies~\cite{Tang2019, Gupta_2018_CVPR, Chen2022}}\DIFaddend . We create training, validation, and test sets for each dataset with \DIFdelbegin \DIFdel{ratio }\DIFdelend \DIFaddbegin \DIFadd{ratios }\DIFaddend of $70\%$, $10\%$, and $20\%$, following the experiment protocol of~\cite{Tang2019}. \DIFaddbegin \DIFadd{The exiD is a new highly interactive dataset containing challenging merging and exiting highway scenarios and is not exploited in multimodal prediction studies yet. We follow the experiment protocol from~\cite{mozaffari2023trajectory} to prepare the train, validation and test set and preprocess the exiD dataset. To this end, we use single-lane merging scenarios from four locations of the exiD dataset and convert their trajectories and lane markings from Cartesian to Frenet coordinates.
}\DIFaddend 

%\DIFdelbegin \subsection{\DIFdel{Evaluation Metrics}}
%DIFAUXCMD
%\addtocounter{subsection}{-1}%DIFAUXCMD
\DIFdel{We report minRMSE-K (the lower the better) for the }\DIFdelend \DIFaddbegin \DIFadd{Each trajectory in the datasets is automatically labelled with a manoeuvre vector of the same length. If a trajectory crosses a right/left lane marking it is labelled as RLC/LLC for all timesteps before and after crossing until its lateral speed comes to zero. All other timesteps are labelled as lane-keeping.
}

\subsection{Evaluation Metrics}
\DIFadd{\textbf{minRMSE-K} is commonly reported in }\DIFaddend multimodal trajectory prediction \DIFdelbegin \DIFdel{problem over 5 seconds prediction horizon, similar to~\cite{Tang2019}. MinRMSE-K }\DIFdelend \DIFaddbegin \DIFadd{studies~\cite{Gupta2018, Tang2019, Mercat2020}. It }\DIFaddend is defined as the minimum Root Mean Squared Error (RMSE) among the $K$ \DIFdelbegin \DIFdel{prediction modes }\DIFdelend \DIFaddbegin \DIFadd{selected trajectories for evaluation. In a  model with $N$ prediction modes, $K\leq N$ are the trajectories corresponding to modes }\DIFaddend with the highest \DIFdelbegin \DIFdel{probability.
RMSE and its equivalent for multimodal prediction (i.e., minRMSE-K) have been widely used in the trajectory prediction literature. However, we also report the average Negative Log Likelihood (NLL , the higher }\DIFdelend \DIFaddbegin \DIFadd{probabilities.
}

\DIFadd{\textbf{meanNLL} is the weighted average NLL (the lower }\DIFaddend the better) \DIFdelbegin \DIFdel{of estimated trajectory distribution across }\DIFdelend \DIFaddbegin \DIFadd{among }\DIFaddend all prediction modes. The \DIFdelbegin \DIFdel{average NLL is used to to }\DIFdelend \DIFaddbegin \DIFadd{log-likelihood is associated with the probability of observing ground truth trajectory samples given the estimated distribution function. The meanNLL is used to }\DIFaddend compare multimodal with single modal models (see section~\DIFdelbegin \DIFdel{\ref{sec:ablation}). 
This is because distance-based metrics such as RMSE are skewed in favour of single modal predictions that converge to the average of modes, while such predictions do not necessarily have high quality. To }\DIFdelend \DIFaddbegin \DIFadd{\ref{sec:ablation1}). 
}

\DIFadd{\textbf{CollisionRate, OffroadRate} are the ratios of collisions with SVs and off-road predictions respectively averaged over all predicted modes (the lower the better). A predicted trajectory is considered as a collision or an off-road if at any time-step it overlaps with the bounding box of other vehicles or its centre crosses road borders, respectively. These metrics indicate the feasibility of prediction in terms of future interaction with other vehicles and compliance to map data~\cite{Greer2021}, respectively. 
}

\DIFadd{$\mathbf{\text{\textbf{div}}_K}$ is introduced in this paper as an indicator for the diversity of prediction modes. It is the ratio of pairwise non-overlapping prediction for $K$ prediction modes with the highest probability:
}\begin{equation}
        {\DIFadd{\text{div}}}\DIFadd{_K = 1-\dfrac{1}{K(K-1)} \sum\limits_{i=1}^{K} \sum\limits_{j=1,j\neq i}^{K} 
     }{\DIFadd{\text{overlap}}}\DIFadd{(i,j)),
}\end{equation}
\DIFadd{where
}\begin{equation}
\DIFadd{\text{overlap}(i,j)=
\begin{cases}
    1, & \makecell{\lvert\hat{y}^{lat}_{i, T_{pred}}-\hat{y}^{lat}_{j, T_{pred}}\rvert<2~{\text{m}} \,\,\text{and} \\
    \lvert\hat{y}^{long}_{i, T_{pred}}-\hat{y}^{long}_{j, T_{pred}}\rvert<5~{\text{m}}}\\
    0,              & \text{otherwise},
\end{cases}.
}\end{equation} 

\DIFadd{\textbf{maxACC-K} is used to }\DIFaddend evaluate the performance of \DIFaddbegin \DIFadd{the }\DIFaddend multimodal manoeuvre prediction \DIFdelbegin \DIFdel{, maxACC-K (i.e., }\DIFdelend \DIFaddbegin \DIFadd{model and is defined as the }\DIFaddend maximum accuracy among \DIFaddbegin \DIFadd{the }\DIFaddend $K$ \DIFdelbegin \DIFdel{prediction with highest probabilities, }\DIFdelend \DIFaddbegin \DIFadd{manoeuvre prediction vectors with the highest probabilities (}\DIFaddend the higher the better)\DIFdelbegin \DIFdel{is reported.
MaxACC-K is the equivalent multimodal variant of the accuracy metric which is widely used for single modal manoeuvre prediction.
}\DIFdelend \DIFaddbegin \DIFadd{.
}\iffalse
\begin{figure}[t] %DIF >  TODO fix notation of t_{c,i}
\centering
\includegraphics[width=\linewidth]{Figures/qual_result3.pdf}
\caption{\DIFaddFL{Comparing performance of single modal and multimodal variant of our framework in two example scenarios (a and b). Both scenarios are from the validation set of the highD dataset. This figure demonstrates the 3 modes with the highest probabilities out of 6 predicted modes, ranked from 1 to 3. Target vehicles and SVs and their sizes are represented with dark blue and grey bounding boxes, respectively. Note that higher lateral resolution is used for demonstration purposes.}}
\label{qual_fig}
\end{figure}
\fi
\DIFaddend 

\subsection{Implementation Details}
The prediction model is trained independently on the balanced training set of each dataset\DIFdelbegin \DIFdel{for $300$ epochs. The model is trained using Adam optimiser~\cite{kingma2014adam}, $10$ epochs of linear learning rate warm-up, a final learning rate of $0.001$, and batch size of $32$}\DIFdelend . Similar to~\cite{Tang2019}, we use \DIFdelbegin \DIFdel{3 }\DIFdelend \DIFaddbegin \DIFadd{three }\DIFaddend seconds of observation \DIFdelbegin \DIFdel{for the prediction of the next 5 }\DIFdelend \DIFaddbegin \DIFadd{to predict the next five }\DIFaddend seconds. We \DIFdelbegin \DIFdel{consider $N=6$ manoeuvre/trajectory modes and a duration of }\DIFdelend \DIFaddbegin \DIFadd{use five frames per second (FPS) for both observation and prediction windows. We consider }\DIFaddend 2.5 seconds for each manoeuvre intention change period ($C=2$). \DIFdelbegin \DIFdel{The experiments are implemented in PyTorch library~\cite{paszke2017automatic} and are carried out on a single GeForce RTX 2080 Ti GPU. The source code of this study is available at }\href{https://github.com/SajjadMzf/TrajPred}{\DIFdel{https://github.com/SajjadMzf/TrajPred}}%DIFAUXCMD
\DIFdel{.
}%DIFDELCMD < 
%DIFDELCMD < %%%
%\subsection{\DIFdel{Comparison with Baseline Models}}
%DIFAUXCMD
%\addtocounter{subsection}{-1}%DIFAUXCMD
\DIFdel{Tables~\ref{tab:comparative_ngsim} and Table~\ref{tab:comp_highd} compare the performance of the MMnTP framework and state-of-the-art multimodal trajectory prediction approaches evaluated on }\DIFdelend \DIFaddbegin \DIFadd{We use a single layer of transformer encoder-decoder for our evaluations with }\DIFaddend NGSIM and highD datasets, \DIFdelbegin \DIFdel{respectively. The baseline models are selected from state-of-the-art multimodal prediction models that report minRMSE-K on either NGSIM or highD dataset at least for one value of $K$. These models include manoeuvre-based multimodal approaches like CS-LSTM~\cite{Deo_2018} and STDAN~\cite{Chen2022}, dynamic discriminative multimodal approaches like SAMMP~\cite{Mercat2020}, and generative multimodal approaches like S-GAN~\cite{Gupta2018}, MFP~\cite{Tang2019}, and MATF-GAN~\cite{Zhao2019}. We report minRMSE-K of our framework for different values of $K$ from $1$ to $6$ to match the evaluation metric reported in baseline studies. The results show that our framework outperforms baseline models for all values of $K$. 
The prediction performance of our framework constantly improves by considering more modes, which demonstrates the diversity of prediction modes. On the contrary, minRMSE-K does not noticeably decrease by increasing the number of considered modes, $K$, in generative models (such as MFP, S-GAN, and MATF-GAN), indicating low diversity of sampled trajectories in such approaches.
In general, prediction models, including ours, has lower performance on NGSIM compared to highD, which can be linked to around 10 times smaller dataset size and higher annotation errors of NGSIM dataset~\cite{ngsim_critic}.
%DIF <  Table here
}\DIFdelend \DIFaddbegin \DIFadd{and two layers for evaluations with the exiD. This is because the exiD dataset has more challenging vehicle interactions. Interested readers are referred to the paper's GitHub page available at }\href{https://github.com/SajjadMzf/TrajPred}{\DIFadd{https://github.com/SajjadMzf/TrajPred}} \DIFadd{for further information regarding re-implementing the framework.
}\DIFaddend 

\DIFdelbegin %DIFDELCMD < \begin{figure*}[!t] %%%
%DIF <  TODO fix notation of t_{c,i}
\DIFdelendFL \DIFaddbeginFL \begin{table}
\DIFaddendFL \centering
\DIFdelbeginFL %DIFDELCMD < \includegraphics[width=6in]{Figures/qual_result.pdf}
%DIFDELCMD < %%%
\DIFdelendFL \caption{\DIFdelbeginFL \DIFdelFL{Comparing performance of single modal and multimodal variant of the proposed framework }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{Comparision with baselines }\DIFaddendFL in \DIFdelbeginFL \DIFdelFL{two example scenarios (a and b). Both scenarios are from the validation set }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{terms }\DIFaddendFL of  \DIFdelbeginFL \DIFdelFL{the highD dataset. This figure demonstrates the 3 modes with highest probabilities out }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{MinRMSE-K at different values }\DIFaddendFL of \DIFdelbeginFL \DIFdelFL{6 predicted modes, ranked from 1 to 3.}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{$K$ and prediction horizons}\DIFaddendFL }
\DIFdelbeginFL %DIFDELCMD < \label{qual_fig}
%DIFDELCMD < \end{figure*}
%DIFDELCMD < 

%DIFDELCMD < \begin{table}[]
%DIFDELCMD < \centering
%DIFDELCMD < %%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
\DIFdelFL{Comparision of MinRMSE-K At Different Prediction Horizons Evaluated on NGSIM dataset}}
%DIFAUXCMD
%DIFDELCMD < \label{tab:comparative_ngsim}
%DIFDELCMD < \begin{tabular}{@{}ccccccc@{}}
%DIFDELCMD < \toprule
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \label{tab:comparative}
\resizebox{\columnwidth}{!}{%
\begin{tblr}{
  row{1-25} = {c},
  cell{2}{1} = {r=13}{},
  cell{16}{1} = {r=6}{},
  cell{22}{1} = {r=3}{},
  cell{2}{2} = {r=6}{},
  cell{8}{2} = {r=4}{},
  cell{12}{2} = {r=2}{},
  cell{14}{2} = {r=2}{},
  cell{16}{2} = {r=4}{},
  cell{20}{2} = {r=2}{},
  cell{22}{2} = {r=2}{},
  hline{1,25} = {-}{0.08em},
  hline{16,22} = {-}{0.03em},
  hline{2} = {-}{},
  hline{8,12,14,20,24} = {2-8}{0.03em},
}
 & \DIFaddendFL K & Model     & 1 s           & 2 s           & 3 s           & 4 s           & 5 s           \\
\DIFdelbeginFL %DIFDELCMD < \midrule
%DIFDELCMD < \multirow{5}{*}{1} %%%
\DIFdelendFL \DIFaddbeginFL \begin{sideways}\DIFaddFL{NGSIM}\end{sideways}   \DIFaddendFL & \DIFdelbeginFL \DIFdelFL{~\cite{Mersch2021}       }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{1 }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{0.53          }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{CV          }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{1.17          }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0.73          }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{1.93          }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{1.78          }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{2.88          }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{3.13          }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{4.37          }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{4.78          }& \DIFaddFL{6.68          }\DIFaddendFL \\
        \DIFdelbeginFL %DIFDELCMD < \cmidrule%%%
\DIFdelFL{(l)}%DIFDELCMD < {%%%
\DIFdelFL{2-7}%DIFDELCMD < } 
%DIFDELCMD <                    %%%
\DIFdelendFL &   \DIFaddbeginFL & \DIFaddendFL CS-LSTM~\cite{Deo_2018}  & 0.58          & 1.26          & 2.07          & 3.09          & 3.98          \\
        &   \DIFaddbeginFL & \DIFaddendFL SAMMP~\cite{Mercat2020}    & 0.51          & 1.13          & 1.88          & 2.81          & 3.67          \\
        &   \DIFaddbeginFL & \DIFaddendFL STDAN~\cite{Chen2022}     & 0.42          & 1.01          & 1.69          & 2.56          & 4.05          \\
        &  \DIFaddbeginFL & \DIFaddFL{MFP~\cite{Tang2019}      }& \DIFaddFL{0.54          }& \DIFaddFL{1.16          }& \DIFaddFL{1.9           }& \DIFaddFL{2.78          }& \DIFaddFL{3.83          }\\
        &   & \DIFaddendFL MMnTP     & \textbf{0.36} & \textbf{0.96} & \textbf{1.69} & \textbf{2.56} & \textbf{3.55} \\
        \DIFdelbeginFL %DIFDELCMD < \midrule
%DIFDELCMD < \multirow{3}{*}{3} %%%
\DIFdelendFL & \DIFdelbeginFL \DIFdelFL{MATF-GAN}\DIFdelendFL \DIFaddbeginFL \DIFaddFL{3 }& \DIFaddFL{MATF}\DIFaddendFL ~\cite{Zhao2019} & 0.66          & 1.34          & 2.08          & 2.97          & 4.13          \\
        &   \DIFaddbeginFL & \DIFaddendFL S-GAN~\cite{Gupta2018}    & 0.57          & 1.32          & 2.22          & 3.26          & 4.4           \\
        &  \DIFaddbeginFL & \DIFaddFL{MFP~\cite{Tang2019}      }& \DIFaddFL{0.54          }& \DIFaddFL{1.17          }& \DIFaddFL{1.91           }& \DIFaddFL{2.78          }& \DIFaddFL{3.83          }\\

        &   & \DIFaddendFL MMnTP     & \textbf{0.26} & \textbf{0.67} & \textbf{1.15} & \textbf{1.73} & \textbf{2.4}  \\
        \DIFdelbeginFL %DIFDELCMD < \midrule
%DIFDELCMD < \multirow{2}{*}{5} %%%
\DIFdelendFL & \DIFaddbeginFL \DIFaddFL{5 }& \DIFaddendFL MFP~\cite{Tang2019}      & \DIFdelbeginFL \DIFdelFL{0.54          }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0.55          }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{1.16          }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{1.18          }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{1.9           }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{1.92           }\DIFaddendFL & 2.78          & \DIFdelbeginFL \DIFdelFL{3.83          }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{3.80          }\DIFaddendFL \\
        &   \DIFaddbeginFL & \DIFaddendFL MMnTP     & \textbf{0.23} & \textbf{0.58} & \textbf{1}    & \textbf{1.49} & \textbf{2.06} \\
        \DIFdelbeginFL %DIFDELCMD < \midrule
%DIFDELCMD < \multirow{2}{*}{6} %%%
\DIFdelendFL & \DIFaddbeginFL \DIFaddFL{6 }& \DIFaddendFL SAMMP~\cite{Mercat2020}     & 0.31          & 0.71          & 1.20          & 1.80          & 2.55          \\
        &   \DIFaddbeginFL & \DIFaddendFL MMnTP     & \textbf{0.22} & \textbf{0.56} & \textbf{0.95} & \textbf{1.42} & \textbf{1.96} \\
\DIFdelbeginFL %DIFDELCMD < \bottomrule
%DIFDELCMD < \end{tabular}
%DIFDELCMD < \end{table}
%DIFDELCMD < 

%DIFDELCMD < \begin{table}[]
%DIFDELCMD < \centering
%DIFDELCMD < %%%
%DIFDELCMD < \caption{%
{%DIFAUXCMD
\DIFdelFL{Comparision of MinRMSE-K At Different Prediction Horizons Evaluated on highD Dataset}}
%DIFAUXCMD
%DIFDELCMD < \label{tab:comp_highd}
%DIFDELCMD < \begin{tabular}{ccccccc}
%DIFDELCMD < \hline
%DIFDELCMD < %%%
\DIFdelFL{K                  }\DIFdelendFL \DIFaddbeginFL \begin{sideways}\DIFaddFL{highD}\end{sideways}\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{Model                   }%DIFDELCMD < & %%%
\DIFdelendFL 1 \DIFdelbeginFL \DIFdelFL{s           }\DIFdelendFL & \DIFdelbeginFL \DIFdelFL{2 s           }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{CV          }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{3 s           }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{\textbf{0.09}          }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{4 s           }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0.32          }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{5 s           }%DIFDELCMD < \\ \hline
%DIFDELCMD < \multirow{4}{*}{1} %%%
\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0.67          }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{~\cite{Mersch2021}      }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{1.14          }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{0.1           }%DIFDELCMD < & %%%
\DIFdelFL{0.21          }%DIFDELCMD < & %%%
\DIFdelFL{0.41          }%DIFDELCMD < & %%%
\DIFdelFL{0.78          }%DIFDELCMD < & %%%
\DIFdelFL{1.34          }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{1.73          }\DIFaddendFL \\
        \DIFdelbeginFL %DIFDELCMD < \cline{2-7} 
%DIFDELCMD <                    %%%
\DIFdelendFL &   \DIFaddbeginFL & \DIFaddendFL CS-LSTM~\cite{Deo_2018} & 0.19          & 0.57          & 1.16          & 1.96          & 2.96          \\
        &   \DIFaddbeginFL & \DIFaddendFL STDAN~\cite{Chen2022}   & 0.19          & \DIFdelbeginFL \DIFdelFL{0.27          }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{\textbf{0.27}          }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{0.48          }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{\textbf{0.48}          }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{0.91          }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{\textbf{0.91}          }\DIFaddendFL & 1.66          \\
        &   \DIFaddbeginFL & \DIFaddendFL MMnTP                   & \DIFdelbeginFL \DIFdelFL{\textbf{0.19} }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0.19 }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{\textbf{0.38} }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0.38 }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{\textbf{0.62} }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0.62 }\DIFaddendFL & \DIFdelbeginFL \DIFdelFL{\textbf{0.95} }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{0.95 }\DIFaddendFL & \textbf{1.39} \\
        \DIFdelbeginFL %DIFDELCMD < \hline
%DIFDELCMD < \multirow{2}{*}{3} %%%
\DIFdelendFL & \DIFaddbeginFL \DIFaddFL{3 }& \DIFaddendFL S-GAN~\cite{Gupta2018}  & 0.3           & 0.78          & 1.46          & 2.34          & 3.41          \\
        &   \DIFaddbeginFL & \DIFaddendFL MMnTP                   & \textbf{0.1}  & \textbf{0.2}  & \textbf{0.34} & \textbf{0.57} & \textbf{0.87} \\
\DIFdelbeginFL %DIFDELCMD < \hline
%DIFDELCMD < \end{tabular}
%DIFDELCMD < %%%
\DIFdelendFL \DIFaddbeginFL \begin{sideways}\DIFaddFL{exiD}\end{sideways}& \DIFaddFL{1 }& \DIFaddFL{CV          }& \DIFaddFL{\textbf{0.25}          }& \DIFaddFL{0.63          }& \DIFaddFL{1.19          }& \DIFaddFL{1.92          }& \DIFaddFL{2.82          }\\
        &   & \DIFaddFL{MMnTP          }& \DIFaddFL{0.26          }& \DIFaddFL{\textbf{0.57}          }& \DIFaddFL{\textbf{0.98}          }& \DIFaddFL{\textbf{1.50}          }& \DIFaddFL{\textbf{2.11}          }\\
        & \DIFaddFL{3 }& \DIFaddFL{MMnTP          }& \DIFaddFL{\textbf{0.17}          }& \DIFaddFL{\textbf{0.39}          }& \DIFaddFL{\textbf{0.69}          }& \DIFaddFL{\textbf{1.07}          }& \DIFaddFL{\textbf{1.52}          }\\

\end{tblr}}
\vspace{-20 pt}
\DIFaddendFL \end{table}
\DIFaddbegin \subsection{\DIFadd{Comparison with Baseline Models}}
\DIFadd{Table~\ref{tab:comparative} reports the performance of the MMnTP framework with six modes ($N=6$), Constant Velocity (CV) predictor, and state-of-the-art multimodal trajectory prediction approaches evaluated on NGSIM, highD, and exiD datasets. The multimodal prediction models are those from the literature that report minRMSE-K on any highway trajectory datasets at least for one value of $K$ in five seconds prediction horizon. These models include manoeuvre-based multimodal approaches like CS-LSTM~\cite{Deo_2018} and STDAN~\cite{Chen2022}, dynamic discriminative multimodal approaches like SAMMP~\cite{Mercat2020}, and generative multimodal approaches like S-GAN~\cite{Gupta2018}, MFP~\cite{Tang2019}, and MATF~\cite{Zhao2019}. To the best of our knowledge, there is no existing multimodal trajectory prediction study on the exiD dataset. We report minRMSE-K of our framework for different values of $K$ from $1$ to $6$. 
}\DIFaddend 



\DIFaddbegin \DIFadd{The results show that our framework outperforms baseline and CV models for all values of $K$ in the five-second prediction horizon. The prediction performance of our framework strictly increases by considering more modes in the evaluation (i.e., increasing $K$). This means that the new modes considered for evaluation add a diversity that lowers the prediction error (i.e., effective diversity). Such diversity is not observed in generative models such as MFP, which has roughly the same minRMSE-K errors for all values of $K$. The CV prediction has a relatively low short-term prediction error, while it is substantially outperformed in the five-second prediction horizon by most learning-based methods. All prediction models, including ours, have lower performance on NGSIM as compared to highD and exiD, which can be linked to high annotation errors of the NGSIM dataset~\cite{ngsim_critic}. 
}




\DIFaddend \begin{table}[]
\centering
\caption{Percentage of \DIFdelbeginFL \DIFdelFL{Minimum Accuracy }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{maximum accuracy }\DIFaddendFL of \DIFdelbeginFL \DIFdelFL{Manoeuvre Intention Prediction }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{manoeuvre intention prediction }\DIFaddendFL among K \DIFdelbeginFL \DIFdelFL{Highest Probable Modes }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{high probable modes }\DIFaddendFL (MaxACC-K) \DIFdelbeginFL \DIFdelFL{Evaluated }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{evaluated }\DIFaddendFL on balanced NGSIM and highD}
\label{tab:man_perf}
\begin{tabular}{@{}lllllll@{}}
\toprule
Dataset & k=1   & k=2   & k=3   & k=4   & k=5   & k=6   \\ \midrule
NGSIM   & 64.6  & 81.2  & 86.01 & 88.04 & 89.86 & 90.48 \\
highD   & 82.04 & 93.26 & 94.89 & 95.81 & 95.97 & 96.03 \\
\DIFaddbeginFL \DIFaddFL{exiD   }& \DIFaddFL{79.91 }& \DIFaddFL{89.54 }& \DIFaddFL{93.51 }& \DIFaddFL{95.08 }& \DIFaddFL{95.70 }& \DIFaddFL{95.98 }\\
\DIFaddendFL \bottomrule
\end{tabular}
\end{table}





\begin{table}[]
\centering
\caption{Ablation \DIFdelbeginFL \DIFdelFL{Study }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{study }\DIFaddendFL on impact of number of modes(N) in \DIFdelbeginFL \DIFdelFL{proposed framework }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{the MMnTP model }\DIFaddendFL on prediction performance}
\label{tab:abb}
\begin{tabular}{@{}lllllll@{}}
\toprule
Metric                     & N & \multicolumn{1}{c}{1 s} & \multicolumn{1}{c}{2 s} & \multicolumn{1}{c}{3 s} & \multicolumn{1}{c}{4 s} & \multicolumn{1}{c}{5 s} \\ \midrule
\multirow{3}{*}{MinRMSE-1} & 1 & \textbf{0.19}           & \textbf{0.36}           & \textbf{0.56}           & \textbf{0.82}           & \textbf{1.19}           \\
                           & 3 & 0.19                    & 0.38                    & 0.62                    & 0.95                    & 1.37                    \\
                           & 6 & 0.21                    & 0.41                    & 0.67                    & 1.01                    & 1.46                    \\ \midrule
\multirow{2}{*}{MinRMSE-3} & 3 & \textbf{0.1}            & \textbf{0.21}           & \textbf{0.36}           & \textbf{0.58}           & \textbf{0.88}           \\
                           & 6 & 0.11                    & 0.21                    & 0.37                    & 0.6                     & 0.91                    \\ \midrule
MinRMSE-6                  & 6 & \textbf{0.07}           & \textbf{0.15}           & \textbf{0.28}           & \textbf{0.46}           & \textbf{0.72}           \\ \midrule
\DIFdelbeginFL %DIFDELCMD < \multirow{3}{*}{NLL}      %%%
\DIFdelendFL \DIFaddbeginFL \multirow{3}{*}{meanNLL}      \DIFaddendFL & 1 & \textbf{-5.08}          & \textbf{-4.77}          & -3.79                   & -2.06                   & 0.05                    \\
                           & 3 & -4.99                   & -4.55                   & -3.65                   & -2.38                   & -1.04                   \\
                           & 6 & -5.04                   & -4.63                   & \textbf{-3.79}          & \textbf{-2.67}          & \textbf{-1.49}          \\ \bottomrule
\end{tabular}
\end{table}





\subsection{Manoeuvre Prediction Performance} %DIF > TODO: add new results and discussion
Table~\ref{tab:man_perf} demonstrates the manoeuvre prediction performance of the \DIFdelbegin \DIFdel{proposed framework }\DIFdelend \DIFaddbegin \DIFadd{MMnTP }\DIFaddend reported on NGSIM\DIFdelbegin \DIFdel{and highD}\DIFdelend \DIFaddbegin \DIFadd{, highD, and exiD }\DIFaddend test sets. The table reports \DIFdelbegin \DIFdel{max accuracy among }\DIFdelend \DIFaddbegin \DIFadd{MaxACC-K for }\DIFaddend $K = {1,2,...,6}$ modes. Particularly for this experiment, we balance the test sets in terms of the type of manoeuvres, since accuracy metrics can provide misleading results on unbalanced datasets. The results show that for \DIFdelbegin \DIFdel{the maximum number of modes the }\DIFdelend \DIFaddbegin \DIFadd{$K=6$ the }\DIFaddend model achieves an accuracy of more than $90\%$, while with $K=1$ it achieves around $64\%$ on NGSIM\DIFdelbegin \DIFdel{and }\DIFdelend \DIFaddbegin \DIFadd{, }\DIFaddend $82\%$ on highD \DIFaddbegin \DIFadd{and $79\%$ on exiD}\DIFaddend . We speculate that the lower performance on NGSIM could be related to inaccuracies in manoeuvre labels on this dataset caused by tracking errors \DIFdelbegin \DIFdel{. The Lower performance on manoeuvre prediction in the NGSIM dataset, compared to highD, can also cascade }\DIFdelend \DIFaddbegin \DIFadd{which also cascades }\DIFaddend to lower trajectory prediction performance on this dataset\DIFdelbegin \DIFdel{reported in Table~\ref{tab:comparative_ngsim}}\DIFdelend .

\DIFaddbegin \begin{figure}[t!]
\centering
\includegraphics[width=.9\linewidth]{Figures/mm_qual.pdf}
\caption{\DIFaddFL{Contingency motion planning for MMnTP's multimodal prediction in three different merging scenarios extracted from the exiD dataset. Trajectory predictions and plans are depicted with dashed and continues lines of matching colours, respectively.}}
\label{fig: contingencyPlanning}
\centering
\end{figure}

\DIFaddend \subsection{\DIFdelbegin \DIFdel{Ablation }\DIFdelend \DIFaddbegin \DIFadd{Ab. }\DIFaddend Study \DIFaddbegin \DIFadd{1: Impact of Number of Prediction Modes}\DIFaddend }\DIFdelbegin %DIFDELCMD < \label{sec:ablation}
%DIFDELCMD < %%%
\DIFdel{In this subsection, we }\DIFdelend \DIFaddbegin \label{sec:ablation1}
\DIFadd{We }\DIFaddend investigate the impact of $N$, the number of \DIFdelbegin \DIFdel{predicted }\DIFdelend \DIFaddbegin \DIFadd{prediction }\DIFaddend modes on the performance of trajectory prediction \DIFdelbegin \DIFdel{in }\DIFdelend \DIFaddbegin \DIFadd{of }\DIFaddend our framework. We consider \DIFdelbegin \DIFdel{three values for the number of modes }\DIFdelend $N={1,3,6}$, where $N=1$ is the single modal variant (e.g\DIFaddbegin \DIFadd{.}\DIFaddend , transformer encoder decoder only). Table~\ref{tab:abb} shows the results \DIFdelbegin \DIFdel{of ablation }\DIFdelend using minRMSE-K and \DIFdelbegin \DIFdel{NLL }\DIFdelend \DIFaddbegin \DIFadd{meanNLL }\DIFaddend metrics on the validation set of the highD dataset. The results indicate that for minRMSE-1 the single modal variant \DIFdelbegin \DIFdel{of the proposed framework }\DIFdelend achieves the lowest error. We speculate \DIFdelbegin \DIFdel{that }\DIFdelend this is because single modal approaches are prone to converging to averages of modes which can yield lower RMSE scores. Nonetheless, among all minRMSE-K metrics, the model with 6 modes achieves the best performance. In addition, the multimodal variant with 6 modes achieves the lowest \DIFdelbegin \DIFdel{NLL }\DIFdelend \DIFaddbegin \DIFadd{meanNLL }\DIFaddend in long-term predictions (i.e., 3 to 5-second prediction horizon)\DIFdelbegin \DIFdel{, which indicates that the predicted multimodal distribution fits better to the ground truth data.}\DIFdelend \DIFaddbegin \DIFadd{.
}\DIFaddend 

\DIFaddbegin \begin{table} 
\centering
\caption{\DIFaddFL{Ablation study on the impact of proposed training process on accuracy, plausibility, and diversity of predictions}}
\resizebox{\columnwidth}{!}{
\begin{tblr}{
  cells = {c},
  hline{1,4} = {-}{0.08em},
  hline{2} = {-}{},
}
\makecell{Training Method} & \begin{sideways}minRMSE-1\end{sideways} & \begin{sideways}minRMSE-2\end{sideways} & \begin{sideways}minRMSE-3\end{sideways} & \begin{sideways}$\text{div}_2$\end{sideways} & \begin{sideways}$\text{div}_3$\end{sideways} & \begin{sideways}\makecell{CollisionRate \\ (\%)}\end{sideways}  & 
\begin{sideways}\makecell{OffroadRate\\(\%)}\end{sideways}  \\
\makecell{MMnTP+MTP}                                                                 & \textbf{1.98}                                    & \textbf{1.62}                                    & 1.62                                    & 0.08                                  & \textbf{0.69}                                  & 9.63                                 & 26.83                                  \\
 \makecell{MMnTP+MMP (ours)}                                                                          & 2.11                                    & 1.71                                    & \textbf{1.52}                                    & \textbf{0.31}                                  & 0.27                                  & \textbf{2.46}                                & \textbf{0.06}                                                                   
\end{tblr}}
\label{tab:abb2}
\end{table}


\subsection{\DIFadd{Ab. Study 2: Impact of Training Process}}\label{sec:ablation2}
\DIFadd{We investigate the impact of the proposed training strategy and the MMP loss function on the performance of our framework. To this end, we train and evaluate a modified version of MMnTP with an alternative well-known training strategy for multimodal trajectory prediction known as MTP loss function~\cite{Cui2019, Liu2021}. The MMnTP+MTP is considered a dynamic multimodal prediction model where the trajectory prediction is not conditioned on estimated manoeuvre. We use the same hyperparameters and trajectory loss function for MMnTP+MTP as in the original framework (i.e., MMnTP+MMP).
The mode selection algorithm for MMnTP+MTP is defined as:
}\begin{equation}
    \DIFadd{n^* =  \underset{n\in \{1,...,N\}}{\argmin}  \lVert\hat{y}_{n, T_{pred}}-y_{T_{pred}}\rVert_1,
}\end{equation}
\DIFadd{where $\hat{y}_{n,T_{pred}}$ is the predicted x-y coordinates of mode $n$ at the end of the prediction horizon and $y_{T_{pred}}$ is the corresponding ground-truth value.
}


\DIFadd{We train and evaluate both versions of MMnTP with $N=3$ on the exiD dataset. Table~\ref{tab:abb2} compares the performance of these approaches in terms of prediction accuracy (i.e., minRMSE-K), diversity (i.e., $\text{div}_K$), and plausibility (i.e., CollisionRate and OffroadRate). The results show that the proposed MMnTP+MMP achieves relatively the same accuracy, but much lower collision and offroad predictions, compared to MMnTP+MTP.  Also, note that the high diversity in MMnTP+MTP with three modes (i.e., ${\text{div}}_3$) does not effectively contribute to prediction accuracy because minRMSE-2 and minRMSE-3 are the same for this method.
}

\iffalse
\DIFaddend \subsection{Qualitative \DIFaddbegin \DIFadd{Prediction }\DIFaddend Results}
In this section, we compare the performance of single modal and multimodal ($N=6$) variants of the prediction models in \DIFdelbegin \DIFdel{two different driving scenarios}\DIFdelend \DIFaddbegin \DIFadd{an example driving scenario}\DIFaddend , as illustrated in Fig.~\ref{qual_fig}. In \DIFdelbegin \DIFdel{scenario a, the target vehicle }\DIFdelend \DIFaddbegin \DIFadd{this scenario, the TV }\DIFaddend (dark blue rectangle) is going to start a left lane change manoeuvre in 1.2 seconds. The single modal model (Fig.~\ref{qual_fig}.a.1) predicts a lane keeping trajectory for the \DIFdelbegin \DIFdel{target vehicle}\DIFdelend \DIFaddbegin \DIFadd{TV}\DIFaddend . The multimodal model (Fig.~\ref{qual_fig}.a.2) also assigns the highest probability percentage to the mode associated with lane keeping during the next 5 seconds. However, the second highest probability mode, with $17\%$ probability percentage, correctly predicts the manoeuvre vector of the \DIFdelbegin \DIFdel{target vehicle}\DIFdelend \DIFaddbegin \DIFadd{TV}\DIFaddend . The corresponding trajectory \DIFdelbegin \DIFdel{of this mode, with orange colour, }\DIFdelend \DIFaddbegin \DIFadd{(orange colour) }\DIFaddend also relatively matches the ground truth. \DIFdelbegin \DIFdel{This example illustrates that multimodal prediction can be beneficial (e.g.,  for risk assessment) as compared to single modal prediction. In scenario b, the target vehicle has already started a right lane change manoeuvre, while the single modal model predicts a lane keeping trajectory. The first mode of the multimodal model with $22\%$ probability percentage correctly predicts the manoeuvre intention, while the trajectory prediction has some inaccuracies. The results in both scenarios }\DIFdelend \DIFaddbegin \DIFadd{The results }\DIFaddend show the diversity and plausibility of predicted manoeuvre vectors and their corresponding trajectories. Readers are referred to the video uploaded in~\cite{vid} for \DIFdelbegin \DIFdel{prediction results in other time steps of both scenarios }\DIFdelend \DIFaddbegin \DIFadd{more qualitative prediction results}\DIFaddend .
\DIFaddbegin \fi
\DIFaddend 

\DIFaddbegin \subsection{\DIFadd{Prediction-based Planning Results}}
\DIFadd{To assess the impact of the MMnTP on a downstream motion planner, we feed its trajectory predictions to a Model Predictive Control (MPC). We adopt the same planning cost function and parameters as in~\cite{mozaffari2023trajectory}. Similar to~\cite{chen2022scept, cui2021lookout}, we design a contingency planner using multimodal predictions, where $N$ trajectories are planned for the EV based on each of the $N$ predicted modes for a selected TV. Fig.~\ref{fig: contingencyPlanning} illustrates the MMnTP-based trajectory predictions and the corresponding EV's planned motion for three merging scenarios extracted from the exiD dataset. The closest left-following vehicle to the EV is selected as the TV. The results show that MMnTP's diverse and plausible predictions result in various merging plans for the EV.
}


\DIFaddend \section{Conclusion}~\label{sec:conc}
\DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{We }\DIFdelend \DIFaddbegin \DIFadd{In this paper, we }\DIFaddend proposed a novel transformer-based multimodal manoeuvre and trajectory prediction \DIFaddbegin \DIFadd{(MMnTP) }\DIFaddend framework using a new formulation of manoeuvre prediction. The performance evaluation on \DIFdelbegin \DIFdel{NGSIM and highD indicates that our framework outperforms existing multimodal prediction methods in terms of prediction distance error. Also, the ablation and qualitative studies reveal that allowing a higher number of prediction modes reduces the chance of missing the prediction of a potentially significant future behaviour of surrounding vehicles}\DIFdelend \DIFaddbegin \DIFadd{highway driving scenarios indicates that the diverse prediction modes of MMnTP can enhance prediction accuracy as compared to state-of-the-art models. The results show that the multimodal manoeuvre training strategy plays a key role in enhancing the plausibility of predictions. Furthermore, we show that MMnTP can be effectively integrated with a contingency motion planner}\DIFaddend . In future studies, \DIFdelbegin \DIFdel{we will integrate our framework with a motion planning algorithm to directly evaluate the impact of multimodal trajectory predictions of surrounding vehicleson the decision-making of AVs.
}\DIFdelend \DIFaddbegin \DIFadd{it is important to extend the current framework to incorporate multi-agent prediction, enabling the prediction of multiple futures for a group of nearby vehicles.
}


%DIF > The key takeaway is that the diverse and plausible prediction modes of the MMnTP enhance the accuracy and diversity of the predicted trajectories which in turn can affect the effectiveness and variety of contingency plans for motion planning. 
%DIF > The performance evaluation on NGSIM, highD and exiD indicates that our framework outperforms existing multimodal prediction methods in terms of prediction distance error. Also, the ablation and qualitative studies reveal that the diverse and plausible prediction modes of the MMnTP contribute to varied contingency plans for an EV. 

\DIFaddend %\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.






\bibliographystyle{IEEEtran}

\bibliography{references}



\end{document}
