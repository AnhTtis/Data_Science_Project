%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}                                                   
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{lmodern}
\usepackage{mathtools}
%\usepackage[shortlabels]{enumitem}
\usepackage{url}
\def\UrlBreaks{\do\/\do-}
\usepackage{breakurl}
\usepackage[breaklinks]{hyperref}
\usepackage{multirow}
\usepackage{booktabs}
%\usepackage{unicode-math}
\DeclareMathOperator*{\argmin}{arg\,min}
\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{\LARGE \bf
Multimodal Manoeuvre and Trajectory Prediction for Autonomous Vehicles Using Transformer Networks
}


\author{Sajjad Mozaffari, Konstantinos Koufos, and Mehrdad Dianati% <-this % stops a space
\thanks{This work was part of the Hi-Drive project. The project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No. 101006664.}% <-this % stops a space
\thanks{All authors are with WMG,
        University of Warwick, Coventry, U.K.
        {\tt\small Email: \href{mailto:sajjad.mozaffari@warwick.ac.uk}{sajjad.mozaffari@warwick.ac.uk} }}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}

Predicting the behaviour (i.e. manoeuvre/trajectory) of other road users, including vehicles, is critical for the safe and efficient operation of autonomous vehicles (AVs), a.k.a. automated driving systems (ADSs). Due to the uncertain future behaviour of vehicles, multiple future behaviour modes are often plausible for a vehicle in a given driving scene. Therefore, multimodal prediction can provide richer information than single-mode prediction enabling AVs to perform a better risk assessment. To this end, we propose a novel multimodal prediction framework that can predict multiple plausible behaviour modes and their likelihoods. The proposed framework includes a bespoke problem formulation for manoeuvre prediction, a novel transformer-based prediction model, and a tailored training method for multimodal manoeuvre and trajectory prediction. The performance of the framework is evaluated using two public benchmark highway driving datasets, namely NGSIM and highD. The results show that the proposed framework outperforms the state-of-the-art multimodal methods in the literature in terms of prediction error and is capable of predicting plausible manoeuvre and trajectory modes.

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Introduction}
%1. Importance of the problem
% major challenge of multimodal prediction

Predicting the behaviour of other road users, including vehicles, is crucial for safe and informed decision-making in automated/autonomous vehicles (AVs). A vehicle's future behaviour is inherently multimodal and nondeterministic due to multiple degrees of freedom in a typical driving scenario and the inherent lack of knowledge about the intentions and reactions of other road users. An AV shall consider all plausible future behaviour modes (hereinafter referred to as modes)  of the surrounding vehicles to effectively assess and manage the risks and enhance driving safety and efficiency. To this end, several multimodal prediction approaches have been proposed in the literature.

A category of existing multimodal approaches in the literature predicts multiple plausible modes, each represented by a single manoeuvre type and its corresponding trajectory ~\cite{Deo_2018, Mersch2021, Chen2022}. Such an approach does not provide a comprehensive picture of the future behaviour mode of a vehicle since a single manoeuvre type can have multiple behaviour realisations depending on the driving styles and interactions with other vehicles. For example, aggressive drivers execute a left lane change manoeuvre differently from conservative drivers in terms of the start time and duration of the manoeuvre. In addition, the future behaviour of a vehicle within a prediction horizon can include a sequence of more than one manoeuvre type.

Another category of existing studies predicts multiple behaviour modes, each represented by a trajectory. There are two approaches in this category, generative and discriminative. Generative approaches rely on estimating the probability density function (PDF) of the trajectory using generative models such as  Conditional Variational Auto Encoders (CVAEs) 
 in ~\cite{Salzmann2020, Lee2017} or Generative Adversarial Networks (GANs) in ~\cite{Zhao2019, Gupta2018}. They then sample the PDF to generate multiple trajectories. However, these approaches often require many samples to cover all plausible future modes, especially those with lower probabilities, which is not ideal from a planning perspective. On the contrary, discriminative approaches assume a predetermined number of modes and predict one trajectory for each mode along with its likelihood~\cite{Liu2021, Huang2022}. The training of these approaches relies on designing a mode selection method with the aim of assigning each ground truth behaviour mode to one of the fixed-number trajectory outputs of the model. Poor mode selection methods can lead to convergence problems such as mode collapsing~\cite{Liu2021, Zhang2021} or implausible modes~\cite{Rhinehart2018, Greer2021}. In the former, multiple predicted trajectories converge to a single plausible mode in the driving scene, whereas in the latter, some predicted trajectories do not conform to traffic or scene context, such as off-road predictions.
% due to receiving much fewer training updates compared to other modes.

To address the aforementioned limitations, we propose a novel Multimodal Manoeuvre and Trajectory Prediction (MMnTP) framework. Firstly, we propose a bespoke formulation of manoeuvre prediction based on a vector representation of manoeuvres. This representation includes a sequence of manoeuvre types and transition times between those during the prediction window. To increase the plausibility of the predictions, constraints are introduced on the manoeuvre types and the number of allowed manoeuvre changes within the prediction horizon. We then propose a multimodal discriminative manoeuvre prediction model using this new formulation. The framework also employs state-of-the-art transformer neural networks~\cite{Vaswani2017} augmented by manoeuvre-specific heads to predict multiple trajectories conditioned on the predicted manoeuvre vectors. To train the model, a novel multimodal manoeuvre prediction loss function and a mode selection method are proposed based on the predicted types and timings of manoeuvres.   The proposed framework is evaluated in highway driving scenarios using two public trajectory datasets, namely NGSIM~\cite{ngsim} and highD~\cite{highD}. Our contributions can be summarised as follows:
\begin{itemize}
    \item A bespoke formulation of manoeuvre prediction, which allows estimating a sequence of manoeuvre types and transition times between them.
    \item A novel transformer-based model to predict multimodal manoeuvres and their corresponding trajectories. 
    \item A tailored multimodal training method using a new multimodal manoeuvre loss function and mode selection method.
    \item Comprehensive and comparative performance evaluation of the proposed framework using well-known benchmark datasets and state-of-the-art multimodal models.
\end{itemize}
%The rest of this paper is organised as follows. Section~\ref{sec:relworks} reviews recent multimodal prediction approaches. Section~\ref{sec:method} introduces the proposed framework. Section~\ref{sec:eval} presents the performance evaluation. Finally, some concluding remarks are given in Section~\ref{sec:conc}.


\section{Related Works}\label{sec:relworks}
Anticipating the future behaviour of other vehicles has been one of the main focuses of research in intelligent vehicles for the last few decades. Early works, reviewed in~\cite{survey_motion_risk}, use physics-based kinematic models~\cite{Lytrivis2008, Barth2008, Kaempchen2004} to predict the short-term future motion. In recent years, learning-based methods, reviewed in~\cite{mozaffari2022Survey, Liu2021s}, have become popular due to their increased prediction accuracy and extended prediction horizon (i.e., more than 3 seconds). In this section, we specifically review two subsets of recent learning-based methods that correlate with our proposed approach.
\subsection{Manoeuvre-based Multimodal prediction}
These methods rely on early recognition of the manoeuvre intention of vehicles as prior knowledge for trajectory prediction. N. Deo and M.M Trivedi~\cite{Deo_2018, Deo20118iv} proposed encoder-decoder neural networks for manoeuvre-based multimodal trajectory prediction. In both papers, a manoeuvre set is defined by combining three lateral and two longitudinal manoeuvre types in highway driving scenarios. The decoder network estimates the probability of each manoeuvre type and predicts one trajectory per manoeuvre type. In~\cite{Chen2022}, a three-layer hierarchical network consisting of Long Short-Term Memory (LSTM) and attention mechanism is used to encode the vehicles' motion, their social interaction with other vehicles at each time step, and the temporal dependencies in their social interaction. Then, a decoding mechanism similar to that in~\cite{Deo20118iv} is used to predict manoeuvre-based trajectories. In~\cite{Messaoud2021} an attention-pooling architecture with specialised heads per manoeuvre type is introduced. Mostly similar to our paper, Mersch~\textit{et al.}~\cite{Mersch2021} predict the sequence of manoeuvre types of vehicles at time steps equal to one second. The predicted manoeuvre vector is augmented with the learnt features to predict a single modal trajectory. Given three manoeuvre types such as right lane change, left lane change and lane keeping and a prediction horizon of 5 seconds, their model can output $3^5=243$ different manoeuvre sequences. However, most of these sequences are not feasible in real-world driving since drivers do not tend to change their manoeuvres regularly. We address this problem by limiting the number of manoeuvre changes in a manoeuvre vector prediction. In addition, we introduced a multimodal manoeuvre and trajectory prediction framework, in contrast to the single modal model developed in~\cite{Mersch2021}.

\subsection{Dynamic Multimodal Prediction}
In these methods, multiple trajectories are predicted without using pre-defined manoeuvre types. Such studies broadly fall into the two following sub-categories:

\subsubsection{Generative Models} They attempt to estimate the multimodal probability distribution of future trajectories conditioned on past observation. In such models, multiple future trajectories are generated by sampling the estimated distribution multiple times. In~\cite{Zyner2020, Mercat2020} mixture density model is used on top of a Recurrent Neural Network (RNN) to model the multimodal trajectory distribution. Conditional Variational Auto Encoders (CVAEs) are commonly used to explicitly encode multimodal future trajectory distribution~\cite{Lee2017, Zhao2019, Salzmann2020, Cui2021, Yuan2021}. Several studies use Generative Adversarial Networks (GAN) to implicitly model the multimodality~\cite{Gupta_2018_CVPR, Sadeghian_2019_CVPR, Vinet2019}. In general, generative methods require a very large number of samples to cover all prediction modes, especially the ones with low probability that are not necessarily unimportant. In addition, such models do not provide a likelihood value for each predicted trajectory mode, which is necessary for risk assessment in AVs. 

\subsubsection{Discriminative Models} They directly regress multiple future trajectories and their probabilities. In~\cite{Cui2019} a convolutional neural network is applied on a rasterised bird-eye view representation of the driving environment to predict multiple futures. During training, a mode selection method is defined to select the matching mode to the ground truth. The winning mode receives the weight updates through gradient descent optimisation for each data sample. The authors argue that modelling the multimodal behaviour highly depends on the ability of the mode selection method to distinguish between different behaviour modes in a driving scenario. Several studies~\cite{Zhang2021, Kim2021, Messaoud2021, Huang2022, Liu2021, Zhang2021} adopt similar training strategies while attempting to increase compliance with the driving environment and diversity of the predictions. In~\cite{Zhang2021} a scoring and selection layer is introduced to rank the modes and reject the near-duplicates. Kim~\textit{et al.}~\cite{Kim2021} propose a lane-aware feature extraction to predict trajectories in compliance with the surrounding environment. To increase the diversity of models, Haung et al.~\cite{Huang2022} use transformers with multimodal attention heads where each trajectory mode is assigned to a group of attention heads. Liu et al~\cite{Liu2021} use stacked transformers to predict multiple trajectory modes. The authors propose a region-based training algorithm by assigning groups of prediction modes to plausible driving regions to improve the diversity of predictions. In~\cite{Zhang2021} a set-based neural network architecture is used to predict map-adaptive trajectory modes from a set of proposals based on map-adaptive goals. In this paper, we use a dynamic discriminative multimodal prediction approach, while unlike existing studies multiple future modes are predicted in manoeuvre space, enabled by vector representation of manoeuvres. Also, a mode selection method is introduced to differentiate between future modes based on the predicted manoeuvre vectors.








\section{Proposed Framework}\label{sec:method}
This section describes the proposed \textbf{M}ultimodal \textbf{M}anoeuvre \textbf{a}nd \textbf{T}rajectory \textbf{P}rediction (\textbf{MMnTP}) framework. First, we define the bespoke multimodal manoeuvre and trajectory prediction problem and notations in Section~\ref{sec:prob}.
We then describe the proposed transformer-based prediction model and its main components in Section~\ref{sec:model}. Finally, the tailored training process is explained in Section~\ref{sec:train}.



\subsection{Problem Definition}\label{sec:prob}
We define the problem of multimodal manoeuvre and trajectory prediction as the estimation of multiple plausible future modes, each with a sequence of manoeuvre types which we call a manoeuvre vector $\hat{M}_i$, a corresponding trajectory $\hat{Y}_i$ and a probability of occurrence $p_i$, where $i\in\{1,.., N\}$ and $N$ is the number of prediction modes. The prediction is carried out for the $T_{pred}$ time steps in future based on the observation $O$ of a target vehicle and its surrounding during the past $T_{obs}$ time steps. The predicted manoeuvre vector of mode $i$, is defined as $\hat{M}_i=\{\hat{m}_{i,t}\}_{t=1}^{T_{pred}}$, and its corresponding trajectory is defined as $\hat{Y}_i=\{\hat{y}_{i,t}\}_{t=1}^{T_{pred}}$. At the time step $t$, the $i$-th predicted manoeuvre type, $\hat{m}_{i,t}$, is the intention of the target vehicle when moving from x-y location $\hat{y}_{i,t-1}$ to $\hat{y}_{i,t}$. Manoeuvre types belong to a countable pre-defined manoeuvre set $\bar{M}$. In the highway driving scenario, three manoeuvre types are defined as Lane Keeping (LK), Right Lane Change (RLC), and Left Lane Change (LLC). 

\begin{figure}[!t] % TODO fix notation of t_{c,i}
\centering
\includegraphics[width=3.4in]{Figures/manoeuvre_fig.pdf}
\caption{An example of manoeuvre vector representation. The following terminology is used in the exemplar input/output data. EV: Ego Vehicle, TV: Target Vehicle, SV: Surrounding Vehicle.}
\label{man_fig}
\end{figure}

We assume that vehicles do not change their manoeuvre intentions with periods less than $T_{change}$ time steps. Therefore the prediction of $T_{pred}$ time steps ahead can be divided into $C=\lceil \frac{T_{pred}}{T_{change}}\rceil$ change periods. Hence, a manoeuvre vector can be written as $M \equiv \{U, V\}$, where  $U = \{u_i\}_{i=0}^{C}$ and $V = \{v_i\}_{i=1}^{C}$ are the manoeuvre type and manoeuvre transition time vectors, respectively. Precisely, $u_i \in \bar M$ is the manoeuvre type at the beginning of $(i+1)$-th change period and $v_i \in [0,1]$ is the normalised transition time from manoeuvre type $u_{i-1}$ to $u_i$ within the $i$-th change period. If $u_{i-1}=u_i$, the transition time will be ignored (its value is set to $-1$).  Fig.~\ref{man_fig} demonstrates an example of a manoeuvre vector and its corresponding trajectory.
% The manoeuvre vector can be automatically extracted from a ground-truth trajectory.
\begin{figure*}[!t] % TODO fix notation of t_{c,i}
\centering
\includegraphics[width=6.8in]{Figures/model_fig.pdf}
\caption{An overview of the proposed prediction model.}
\label{model_fig}
\end{figure*}

\subsection{Prediction Model}\label{sec:model}
The prediction model includes three main components. First, a transformer encoder extracts latent features from a sequence of interaction-aware inputs (Section~\ref{sec:feature}). Then, a multimodal manoeuvre generator estimates multiple manoeuvre vectors and their likelihoods (Section~\ref{sec:man}). Finally, a transformer decoder with manoeuvre-specific heads uses the learnt features and estimated manoeuvre vectors to predict their associated trajectory (Section~\ref{sec:traj}). Fig.~\ref{model_fig} illustrates the architecture of the prediction model.


\subsubsection{Feature Learning}\label{sec:feature}
The input data to the prediction model is the track history of the target vehicle and its surrounding vehicles and the position of lane markings during an observation window of $T_{obs}$ time steps. We consider eight surrounding vehicles including the preceding and following vehicles and the three closest vehicles in each of the adjacent lanes. In~\cite{Wirthmuller2021} a systematic study has been performed to identify the most relevant features for behaviour prediction in highway driving scenarios, which are also validated by our empirical studies in~\cite{mozaffari2022}. The same set of features is used in this study. These features describe the motion of the target vehicle (e.g., its lateral acceleration), its interaction with surrounding vehicles (e.g., the relative longitudinal velocity of the target vehicle with respect to the following vehicle), and the driving environment (e.g., the existence of right/left lanes).

A transformer encoder model, introduced in~\cite{Vaswani2017}, is used to encode the input feature sequence. Within the encoder model, the input features are embedded into vectors of $512$ dimension. Then, a sinusoidal positional encoding (proposed in~\cite{Vaswani2017}) is added to the embedded input to specify the order of each input in the sequence.  Finally, eight heads of self-attention are applied to the embedded data, followed by a normalisation layer and a linear layer of size $128$. Our empirical study shows that a single transformer encoder layer has the best performance in our evaluation of highway driving datasets.

\subsubsection{Manoeuvre Prediction} \label{sec:man}
The multimodal manoeuvre generator takes as input the hidden representation learnt by the encoder and predicts $N$ manoeuvre vectors and their probabilities. The multimodal manoeuvre generator model is a two-layer fully-connected neural network with $256$ hidden neurons and ReLU activation function. The output layer contains $N$ neurons for the estimation of mode probabilities, $N\times (C+1)\times3$ neurons for the classification of manoeuvre types, and $N$ neurons for the regression of manoeuvre change times. 




\subsubsection{Trajectory Prediction} \label{sec:traj}
The trajectory prediction component includes a transformer decoder network, introduced in~\cite{Vaswani2017}, and manoeuvre-specific heads. Similar to the transformer encoder, the decoder network includes embedding, positional encoding, multi-head self-attention, normalisation layers, and linear layers. In addition, the decoder network benefits from a multi-head cross-attention mechanism to find relevancy between the decoder output and the encoded latent representation. We refer interested readers to~\cite{Vaswani2017} for more details about the transformers. Similar to the encoder network, we use a single-layer transformer decoder with an embedded size of $512$, eight attention heads, and a linear layer of size $128$.

The output of the transformer decoder is fed to manoeuvre-specific heads to generate trajectories per manoeuvre type. For the application of the framework in highway driving scenarios, three heads are considered corresponding to RLC, LK, and LLC manoeuvre types. Each head acts as an expert in trajectory prediction for a manoeuvre type. The future trajectory is selected from manoeuvre heads based on the predicted manoeuvre types within the manoeuvre vector (note the input from the manoeuvre prediction block to the selector in the trajectory prediction block in Fig.~\ref{model_fig}). Each head is a linear layer and outputs the parameters of a bi-variate Gaussian distribution (i.e., the x-y means, variances, and correlation coefficient) at each prediction time step. Note that during inference the mean values of the estimated Gaussian distributions are outputted as the predicted trajectory.

\subsection{Training Process} \label{sec:train}
We use end-to-end learning to predict multiple manoeuvre vectors, their corresponding trajectories and their likelihood from a sequence of input features. The overall training loss $L$ consists of a trajectory prediction part $L^{traj}$ and a multimodal manoeuvre prediction part $L^{man}$.

\begin{equation}
    L = L^{traj} + L^{man}.
\end{equation}

The trajectory prediction loss aims to minimise the negative log-likelihood of the estimated bi-variate Gaussian distribution calculated at the x-y location of the ground truth trajectory for each time step. We use the teacher-forcing technique in optimising the prediction model's parameters~\cite{Williams1989}. Therefore, to predict the x-y location at time step $t+1$, $\hat{y}_{t+1}$, the ground truth manoeuvre vector $M_{0:t}$ and the ground truth trajectory $Y_{0:t}$ at previous time steps are used. Thus, the trajectory prediction loss for each data sample can be written as: 
\begin{equation}
\begin{aligned}
    &L^{traj}=\\
    &-log\Bigl(f_{\hat Y}(y_{1}|m_{1}, O)\prod_{t=1}^{T_{pred}} f_{\hat Y}(y_{t+1}|M_{0:t},Y_{0:t}, O)\Bigl),
\end{aligned}
\end{equation}
where $f_{\hat Y}$ is the estimated bivariate Gaussian distribution of future trajectory.

Inspired by the Multiple Trajectory Prediction loss (MTP) introduced in~\cite{Cui2019}, we propose a Multiple Manoeuvre Prediction (MMP) loss in manoeuvre space. A novel mode selection method is defined to find the matching predicted mode to the ground truth:
\begin{equation}
    n^* =  \underset{n\in \{1,...,N\}}{\argmin} L^{\hat{U}}_n,
\end{equation}
where $L^{\hat{U}}_n$ is a negative log-likelihood loss for the classification of manoeuvre types of mode $n$:
\begin{equation}
    L^{\hat{U}}_{n} = -\log p_{\hat U_n}.
\end{equation}

Once the winning mode $n^*$ is identified, the manoeuvre loss can be calculated as:
\begin{equation}
    L^{man} = L^{p} +  L^{\hat{U}}_{n^*} +  L^{\hat{V}}_{n^*},
\end{equation}
where:
\begin{equation}\label{eq:man_losses}
\begin{aligned}
    & L^{p} = -\log p_{n^*}\\
    & L^{\hat{V}}_{n} = \lVert V-\hat V_n\lVert_2.
\end{aligned}
\end{equation}

The loss function $L^{p}$ is the negative log-likelihood of the selected mode, and $L^{\hat{V}}_{n}$ is the Euclidean norm between the predicted manoeuvre change timings and their ground truth values.

\section{Performance Evaluation}~\label{sec:eval}
In this section, we evaluate the performance of the proposed framework in highway driving scenarios. we first explain the selected datasets and the evaluation metrics, followed by the implementation details. Then, we compare the performance of the framework with state-of-the-art prediction methods. We also provide an ablation study to compare the proposed transformer-based prediction model with and without the multimodal manoeuvre and trajectory prediction both quantitatively and qualitatively.

\subsection{Dataset}% pr data prepration
We consider two widely used trajectory datasets for our real-world highway driving scenario evaluation, namely highD~\cite{highD} and NGSIM~\cite{ngsim}. The highD dataset contains $110,000$ vehicle trajectories in six different locations in Germany. The dataset includes different traffic states (e.g., traffic jams) in $2$- to $3$-lane highways. The highD dataset has been originally recorded at 25 FPS, which we downsample to 5 FPS in our application. The NGSIM dataset includes $9,206$ vehicle trajectories on two different highways in the US. NGSIM dataset is recorded in $5$- to $6$- lane highways with mild, moderate, and congested traffic conditions. We create training, validation, and test sets for each dataset with ratio of $70\%$, $10\%$, and $20\%$, following the experiment protocol of~\cite{Tang2019}.

\subsection{Evaluation Metrics}
We report minRMSE-K (the lower the better) for the multimodal trajectory prediction problem over 5 seconds prediction horizon, similar to~\cite{Tang2019}. MinRMSE-K is defined as the minimum Root Mean Squared Error (RMSE) among the $K$ prediction modes with the highest probability. RMSE and its equivalent for multimodal prediction (i.e., minRMSE-K) have been widely used in the trajectory prediction literature. However, we also report the average Negative Log Likelihood (NLL, the higher the better) of estimated trajectory distribution across all prediction modes. The average NLL is used to to compare multimodal with single modal models (see section~\ref{sec:ablation}). This is because distance-based metrics such as RMSE are skewed in favour of single modal predictions that converge to the average of modes, while such predictions do not necessarily have high quality. To evaluate the performance of multimodal manoeuvre prediction, maxACC-K (i.e., maximum accuracy among $K$ prediction with highest probabilities, the higher the better) is reported. MaxACC-K is the equivalent multimodal variant of the accuracy metric which is widely used for single modal manoeuvre prediction.

\subsection{Implementation Details}
The prediction model is trained independently on the balanced training set of each dataset for $300$ epochs.  The model is trained using Adam optimiser~\cite{kingma2014adam}, $10$ epochs of linear learning rate warm-up, a final learning rate of $0.001$, and batch size of $32$. Similar to~\cite{Tang2019}, we use 3 seconds of observation for the prediction of the next 5 seconds. We consider $N=6$ manoeuvre/trajectory modes and a duration of 2.5 seconds for each manoeuvre intention change period($C=2$). The experiments are implemented in PyTorch library~\cite{paszke2017automatic} and are carried out on a single GeForce RTX 2080 Ti GPU. The source code of this study is available at \href{https://github.com/SajjadMzf/TrajPred}{https://github.com/SajjadMzf/TrajPred} .

\subsection{Comparison with Baseline Models}
Tables~\ref{tab:comparative_ngsim} and Table~\ref{tab:comp_highd} compare the performance of the MMnTP framework and state-of-the-art multimodal trajectory prediction approaches evaluated on NGSIM and highD datasets, respectively. The baseline models are selected from state-of-the-art multimodal prediction models that report minRMSE-K on either NGSIM or highD dataset at least for one value of $K$. These models include manoeuvre-based multimodal approaches like CS-LSTM~\cite{Deo_2018} and STDAN~\cite{Chen2022}, dynamic discriminative multimodal approaches like SAMMP~\cite{Mercat2020}, and generative multimodal approaches like S-GAN~\cite{Gupta2018}, MFP~\cite{Tang2019}, and MATF-GAN~\cite{Zhao2019}. We report minRMSE-K of our framework for different values of $K$ from $1$ to $6$ to match the evaluation metric reported in baseline studies. The results show that our framework outperforms baseline models for all values of $K$. 
The prediction performance of our framework constantly improves by considering more modes, which demonstrates the diversity of prediction modes. On the contrary, minRMSE-K does not noticeably decrease by increasing the number of considered modes, $K$, in generative models (such as MFP, S-GAN, and MATF-GAN), indicating low diversity of sampled trajectories in such approaches. In general, prediction models, including ours, has lower performance on NGSIM compared to highD, which can be linked to around 10 times smaller dataset size and higher annotation errors of NGSIM dataset~\cite{ngsim_critic}.
% Table here


\begin{figure*}[!t] % TODO fix notation of t_{c,i}
\centering
\includegraphics[width=6in]{Figures/qual_result.pdf}
\caption{Comparing performance of single modal and multimodal variant of the proposed framework in two example scenarios (a and b). Both scenarios are from the validation set of the highD dataset. This figure demonstrates the 3 modes with highest probabilities out of 6 predicted modes, ranked from 1 to 3.}
\label{qual_fig}
\end{figure*}





\begin{table}[]
\centering
\caption{Comparision of MinRMSE-K At Different Prediction Horizons Evaluated on NGSIM dataset}
\label{tab:comparative_ngsim}
\begin{tabular}{@{}ccccccc@{}}
\toprule
K                  & Model                    & 1 s           & 2 s           & 3 s           & 4 s           & 5 s           \\ \midrule
\multirow{5}{*}{1} & ~\cite{Mersch2021}       & 0.53          & 1.17          & 1.93          & 2.88          & 4.37          \\ \cmidrule(l){2-7} 
                   & CS-LSTM~\cite{Deo_2018}  & 0.58          & 1.26          & 2.07          & 3.09          & 3.98          \\
                   & SAMMP~\cite{Mercat2020}  & 0.51          & 1.13          & 1.88          & 2.81          & 3.67          \\
                   & STDAN~\cite{Chen2022}    & 0.42          & 1.01          & 1.69          & 2.56          & 4.05          \\
                   & MMnTP                    & \textbf{0.36} & \textbf{0.96} & \textbf{1.69} & \textbf{2.56} & \textbf{3.55} \\ \midrule
\multirow{3}{*}{3} & MATF-GAN~\cite{Zhao2019} & 0.66          & 1.34          & 2.08          & 2.97          & 4.13          \\
                   & S-GAN~\cite{Gupta2018}   & 0.57          & 1.32          & 2.22          & 3.26          & 4.4           \\
                   & MMnTP                    & \textbf{0.26} & \textbf{0.67} & \textbf{1.15} & \textbf{1.73} & \textbf{2.4}  \\ \midrule
\multirow{2}{*}{5} & MFP~\cite{Tang2019}      & 0.54          & 1.16          & 1.9           & 2.78          & 3.83          \\
                   & MMnTP                    & \textbf{0.23} & \textbf{0.58} & \textbf{1}    & \textbf{1.49} & \textbf{2.06} \\ \midrule
\multirow{2}{*}{6} & SAMMP~\cite{Mercat2020}  & 0.31          & 0.71          & 1.20          & 1.80          & 2.55          \\
                   & MMnTP                    & \textbf{0.22} & \textbf{0.56} & \textbf{0.95} & \textbf{1.42} & \textbf{1.96} \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[]
\centering
\caption{Comparision of MinRMSE-K At Different Prediction Horizons Evaluated on highD Dataset}
\label{tab:comp_highd}
\begin{tabular}{ccccccc}
\hline
K                  & Model                   & 1 s           & 2 s           & 3 s           & 4 s           & 5 s           \\ \hline
\multirow{4}{*}{1} & ~\cite{Mersch2021}      & 0.1           & 0.21          & 0.41          & 0.78          & 1.34          \\ \cline{2-7} 
                   & CS-LSTM~\cite{Deo_2018} & 0.19          & 0.57          & 1.16          & 1.96          & 2.96          \\
                   & STDAN~\cite{Chen2022}   & 0.19          & 0.27          & 0.48          & 0.91          & 1.66          \\
                   & MMnTP                   & \textbf{0.19} & \textbf{0.38} & \textbf{0.62} & \textbf{0.95} & \textbf{1.39} \\ \hline
\multirow{2}{*}{3} & S-GAN~\cite{Gupta2018}  & 0.3           & 0.78          & 1.46          & 2.34          & 3.41          \\
                   & MMnTP                   & \textbf{0.1}  & \textbf{0.2}  & \textbf{0.34} & \textbf{0.57} & \textbf{0.87} \\ \hline
\end{tabular}
\end{table}



\begin{table}[]
\centering
\caption{Percentage of Minimum Accuracy of Manoeuvre Intention Prediction among K Highest Probable Modes (MaxACC-K) Evaluated on balanced NGSIM and highD}
\label{tab:man_perf}
\begin{tabular}{@{}lllllll@{}}
\toprule
Dataset & k=1   & k=2   & k=3   & k=4   & k=5   & k=6   \\ \midrule
NGSIM   & 64.6  & 81.2  & 86.01 & 88.04 & 89.86 & 90.48 \\
highD   & 82.04 & 93.26 & 94.89 & 95.81 & 95.97 & 96.03 \\ \bottomrule
\end{tabular}
\end{table}





\begin{table}[]
\centering
\caption{Ablation Study on impact of number of modes(N) in proposed framework on prediction performance}
\label{tab:abb}
\begin{tabular}{@{}lllllll@{}}
\toprule
Metric                     & N & \multicolumn{1}{c}{1 s} & \multicolumn{1}{c}{2 s} & \multicolumn{1}{c}{3 s} & \multicolumn{1}{c}{4 s} & \multicolumn{1}{c}{5 s} \\ \midrule
\multirow{3}{*}{MinRMSE-1} & 1 & \textbf{0.19}           & \textbf{0.36}           & \textbf{0.56}           & \textbf{0.82}           & \textbf{1.19}           \\
                           & 3 & 0.19                    & 0.38                    & 0.62                    & 0.95                    & 1.37                    \\
                           & 6 & 0.21                    & 0.41                    & 0.67                    & 1.01                    & 1.46                    \\ \midrule
\multirow{2}{*}{MinRMSE-3} & 3 & \textbf{0.1}            & \textbf{0.21}           & \textbf{0.36}           & \textbf{0.58}           & \textbf{0.88}           \\
                           & 6 & 0.11                    & 0.21                    & 0.37                    & 0.6                     & 0.91                    \\ \midrule
MinRMSE-6                  & 6 & \textbf{0.07}           & \textbf{0.15}           & \textbf{0.28}           & \textbf{0.46}           & \textbf{0.72}           \\ \midrule
\multirow{3}{*}{NLL}      & 1 & \textbf{-5.08}          & \textbf{-4.77}          & -3.79                   & -2.06                   & 0.05                    \\
                           & 3 & -4.99                   & -4.55                   & -3.65                   & -2.38                   & -1.04                   \\
                           & 6 & -5.04                   & -4.63                   & \textbf{-3.79}          & \textbf{-2.67}          & \textbf{-1.49}          \\ \bottomrule
\end{tabular}
\end{table}





\subsection{Manoeuvre Prediction Performance}
Table~\ref{tab:man_perf} demonstrates the manoeuvre prediction performance of the proposed framework reported on NGSIM and highD test sets. The table reports max accuracy among $K = {1,2,...,6}$ modes. Particularly for this experiment, we balance the test sets in terms of the type of manoeuvres, since accuracy metrics can provide misleading results on unbalanced datasets. The results show that for the maximum number of modes the model achieves an accuracy of more than $90\%$, while with $K=1$ it achieves around $64\%$ on NGSIM and $82\%$ on highD. We speculate that the lower performance on NGSIM could be related to inaccuracies in manoeuvre labels on this dataset caused by tracking errors. The Lower performance on manoeuvre prediction in the NGSIM dataset, compared to highD, can also cascade to lower trajectory prediction performance on this dataset reported in Table~\ref{tab:comparative_ngsim}. 


\subsection{Ablation Study}\label{sec:ablation}
In this subsection, we investigate the impact of $N$, the number of predicted modes on the performance of trajectory prediction in our framework. We consider three values for the number of modes $N={1,3,6}$, where $N=1$ is the single modal variant (e.g, transformer encoder decoder only). Table~\ref{tab:abb} shows the results of ablation using minRMSE-K and NLL metrics on the validation set of the highD dataset. The results indicate that for minRMSE-1 the single modal variant of the proposed framework achieves the lowest error. We speculate that this is because single modal approaches are prone to converging to averages of modes which can yield lower RMSE scores. Nonetheless, among all minRMSE-K metrics, the model with 6 modes achieves the best performance. In addition, the multimodal variant with 6 modes achieves the lowest NLL in long-term predictions (i.e., 3 to 5-second prediction horizon), which indicates that the predicted multimodal distribution fits better to the ground truth data.

\subsection{Qualitative Results}
In this section, we compare the performance of single modal and multimodal ($N=6$) variants of the prediction models in two different driving scenarios, as illustrated in Fig.~\ref{qual_fig}. In scenario a, the target vehicle (dark blue rectangle) is going to start a left lane change manoeuvre in 1.2 seconds. The single modal model (Fig.~\ref{qual_fig}.a.1) predicts a lane keeping trajectory for the target vehicle. The multimodal model (Fig.~\ref{qual_fig}.a.2) also assigns the highest probability percentage to the mode associated with lane keeping during the next 5 seconds. However, the second highest probability mode, with $17\%$ probability percentage, correctly predicts the manoeuvre vector of the target vehicle. The corresponding trajectory of this mode, with orange colour, also relatively matches the ground truth. This example illustrates that multimodal prediction can be beneficial (e.g.,  for risk assessment) as compared to single modal prediction. In scenario b, the target vehicle has already started a right lane change manoeuvre, while the single modal model predicts a lane keeping trajectory. The first mode of the multimodal model with $22\%$ probability percentage correctly predicts the manoeuvre intention, while the trajectory prediction has some inaccuracies. The results in both scenarios show the diversity and plausibility of predicted manoeuvre vectors and their corresponding trajectories. Readers are referred to the video uploaded in~\cite{vid} for prediction results in other time steps of both scenarios.

\section{Conclusion}~\label{sec:conc}

We proposed a novel transformer-based multimodal manoeuvre and trajectory prediction framework using a new formulation of manoeuvre prediction. The performance evaluation on NGSIM and highD indicates that our framework outperforms existing multimodal prediction methods in terms of prediction distance error. Also, the ablation and qualitative studies reveal that allowing a higher number of prediction modes reduces the chance of missing the prediction of a potentially significant future behaviour of surrounding vehicles. In future studies, we will integrate our framework with a motion planning algorithm to directly evaluate the impact of multimodal trajectory predictions of surrounding vehicles on the decision-making of AVs.
%\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.






\bibliographystyle{IEEEtran}

\bibliography{root}



\end{document}
