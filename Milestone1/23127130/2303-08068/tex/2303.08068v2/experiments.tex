\section{Experiments}
We evaluated the effectiveness of the proposed style feature extraction method using four datasets.
We analyzed the validity of the proposed method using MNIST~\cite{MNIST}, an original Google Fonts-based dataset (hereinafter, Google Fonts dataset) because they are simple, small, and easy to handle.
In addition, we assessed the performance on practical, real-world natural images using Imagenette~\cite{imagenette}, and DAISO-100~\cite{katoh2021dataset}.

Although several CL methods are available, we mainly employed MoCo v2~\cite{chen2020mocov2}, which is relatively lightweight and stable.
In the experiments using MNIST and the Google Fonts dataset, we evaluated the combination of the proposed method and the different CL methods.

\subsection{Datasets}
\subsubsection{MNIST-Like Datasets}
We confirmed that the proposed method works as intended using MNIST~\cite{MNIST} and the Google Fonts dataset.
MNIST is a handwritten digits image dataset that has various handwriting styles.
For additional evaluation, we composed the Google Fonts dataset, which is based on Google Fonts~\cite{googlefonts}.
Font faces can be considered as styles, and therefore, the Google Fonts dataset is expected to contain more style variations than that in MNIST.
The Google Fonts dataset consists of images of digits, Latin alphabets, and Japanese hiragana.
We obtained 1,244 font families by selecting fonts that contain these characters by creating images with each character for each font.
Each font family may contain different font weights.
We obtained 280,694 training samples and 31,189 testing samples.
Each image is $32\times 32$ pixels in grayscale.
Some examples from the Google Fonts dataset are shown in \cref{fig:google_fonts_example}.

For experiments using MNIST, we trained the CL model using EMNIST ByClass~\cite{emnist}, which is an extension of MNIST.
This is because CL works better with larger datasets~\cite{SimCLR}.
We trained the CVAE using MNIST and evaluated the overall proposed method also using MNIST.
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{fig/google_fonts_examples.pdf}
    \caption{Example images from the Google Fonts dataset.}
    \label{fig:google_fonts_example}
\end{figure}

We evaluated the proposed method from five viewpoints using the two datasets.
First, we confirmed that the CL method extracts feature vectors independent of data augmentation, and the CVAE successfully extracts features corresponding to the augmentation by observing the decoder outputs corresponding to the data augmented inputs.
Second, we assessed the relationship between the feature vectors of the CVAE and the styles by generating samples using the decoder with some fixed $z_\text{content}$ and interpolated $z_\text{style}$.
Third, we evaluated the variations in style features through style transfer experiments.
Fourth, we observed the neighbors of the test data mapped by the encoder (i.e., the test data in the space of $z_\text{style}$) to evaluate the style features without passing them to the decoder.
Finally, we compared the effects of using CL methods besides MoCo v2 in combination with the proposed method.

We used almost the same hyperparameters for MNIST and the Google Fonts dataset.
The backbone networks of the CL ($f_\psi$) and the encoder ($E_\phi$) were ResNet-18~\cite{He2016}.
While training the CL and the CVAE, data augmentation that consists of random perspective transformation, random cropping, random blurring, and random perturbation of brightness and contrast, was applied.
We used the Adam optimizer~\cite{Adam} for training.
Other hyperparameters are listed in \cref{tab:hparams}.
\begin{table*}[t]
    \centering
    \caption{Hyperparameters in the experiments.}
    \label{tab:hparams}
    \begin{tabular}{lccccc}
        \toprule
        Dataset      & Architecture of $E_\theta, f_\psi$ & Dataset for CL & $\lambda_\text{KL}$ & $\lambda_\text{MINE}$ & $\text{dim}(z_\text{style})$ \\\midrule
        MNIST        & ResNet-18 & EMNIST~\cite{emnist} ByClass & $0.1$ & $10^{-2}$ & 32\\
        Google Fonts & ResNet-18 & Google Fonts                 & $0.1$ & $10^{-3}$ & 32\\
        Imagenette   & ResNet-50 & ImageNet~\cite{ILSVRC15}     & $1$   & $10^{-2}$ & 128\\
        DAISO-100    & ResNet-50 & ImageNet~\cite{ILSVRC15}     & $1$   & $10^{-3}$ & 128\\\bottomrule
    \end{tabular}
\end{table*}

\subsubsection{Real-World Natural Image Datasets}
We conducted additional experiments using two natural image datasets, Imagenette~\cite{imagenette} and DAISO-100~\cite{katoh2021dataset}, to evaluate the expandability of the proposed method.
Imagenette is a lightweight subset of ImageNet~\cite{ILSVRC15} and contains 10 classes of the original ImageNet.
DAISO-100 is an image dataset consisting of photos of 100 miscellaneous goods in various scenarios.
In DAISO-100, three style-like conditions are explicitly labeled; these conditions are lighting, decoration by sticker, and camera angles.
We used ImageNet for training the CL model in the experiments using the natural image datasets.

We performed evaluations using style transfer and neighbor analysis because the proposed method does not aim to generate images.
The generated images were not sufficiently clear to be evaluated.
Style transfer experiments actually require image generation; however, we could examine changes in generated images when the styles were transferred.
We can evaluate the style features without generating images using neighbor analysis.

For the CL model ($f_\psi$) and encoder ($E_\phi$), we used ResNet-50~\cite{He2016}.
We initialized the CL model by pretrained weights, which are available publicly~\cite{chen2020mocov2}.
While training the CL model and CVAE, data augmentation used in MoCo v2~\cite{chen2020mocov2} was applied.
We used the Adam optimizer~\cite{Adam} for the training.
Other hyperparameters are summarized in \cref{tab:hparams}.

\subsection{Capturing Isolated Data Augmentation Features}
\label{sec:da_removal_mnist}
We conducted simple sanity check experiments.
For CL methods that learn features independent of data augmentation, we comfirmed that the CVAE successfully captured the information corresponding to data augmentation.

\Cref{fig:da_removal} shows the results.
In the figure, two types of reconstruction are shown: normal reconstruction using both $z_\text{content}$ and $z_\text{style}$ (the third row of \cref{fig:da_removal}) and data augmentation-independent reconstruction using only $z_\text{content}$ (the bottom row of \cref{fig:da_removal}).
Although normal reconstructions were similar to the input, the data augmentation-independent reconstructions looked similar to the input without augmentation effects.
These results illustrate that the CL model isolated data augmentation features and the CVAE captured them.
Interestingly, for the Google Fonts dataset, the reconstructions with $z_\text{style}=\mathbf{0}$ were not similar to the input data before the data augmentation; they seemed to be average style versions of the data-augmented input data.
\begin{figure*}[t]
    \centering
    \begin{minipage}{\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[height=3cm]{fig/da_removal_mnist.pdf}};
            \node[anchor=north east, yshift=-0.3cm] at (pic.north west) {Input $x$};
            \node[anchor=north east, yshift=-1cm] at (pic.north west) {Data augmented input};
            \node[anchor=north east, yshift=-1.7cm] at (pic.north west) {Reconstruction $D_\theta(z_\text{style}, z_\text{content})$};
            \node[anchor=north east, yshift=-2.5cm] at (pic.north west) {Style-free reconstruction $D_\theta(\mathbf{0}, z_\text{content})$};
        \end{tikzpicture}
        \subcaption{MNIST}\label{fig:da_removal_mnist}
    \end{minipage}
    \vspace{0.2cm}

    \begin{minipage}{\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[height=3cm]{fig/da_removal_font.pdf}};
            \node[anchor=north east, yshift=-0.3cm] at (pic.north west) {Input $x$};
            \node[anchor=north east, yshift=-1cm] at (pic.north west) {Data augmented input};
            \node[anchor=north east, yshift=-1.7cm] at (pic.north west) {Reconstruction $D_\theta(z_\text{style}, z_\text{content})$};
            \node[anchor=north east, yshift=-2.5cm] at (pic.north west) {Style-free reconstruction $D_\theta(\mathbf{0}, z_\text{content})$};
        \end{tikzpicture}
        \subcaption{Google Fonts}\label{fig:da_removal_font}
    \end{minipage}
    \caption{%
    Examples of isolating and capturing data augmentation features.
    From top to bottom: original images, images after data augmentation, reconstructed images $D_\theta(z_\text{style}, z_\text{content})$, and images reconstructed without style features $D_\theta(\mathbf{0}, z_\text{content})$.
    }
    \label{fig:da_removal}
\end{figure*}

\subsection{Conditional Generation}
\label{sec:interp_mnist}
Conditional generation experiments confirmed that the learned feature of the CVAE corresponded to the style feature.
We observed the decoder outputs with fixed $z_\text{content}$ and interpolated $z_\text{style}$.
The CL features $z_\text{content}$ were outputs of the CL model of the test data.
The CVAE features $z_\text{style}$ were generated along random line segments that cross the origin.

\Cref{fig:interp} shows the conditional generation results.
For both datasets, the styles changed by changing $z_\text{style}$ without altering the contents.
When $z_\text{style}$ was near the origin, the outputs were in average styles, and only styles shifted gradually as $z_\text{style}$ moved away from the origin.
In addition, changes in styles were consistent across different $z_\text{content}$.
\begin{figure*}[t]
    \centering
    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[width=0.85\linewidth]{fig/interp_mnist.pdf}};
            \node[anchor=south east, xshift=1cm] at (pic.north west) {$z_\text{content}$};
            \node[anchor=north west, xshift=-0.8cm] at (pic.south east) {$z_\text{style}$};
            % \node[anchor=north] at (pic.south) {$\mathbf{0}$};
            \draw[-latex](pic.south west) -- (pic.north west);
            \draw[-latex](pic.south west) -- (pic.south east);
        \end{tikzpicture}
        \subcaption{MNIST}\label{fig:interp_mnist}
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[width=0.85\linewidth]{fig/interp_font.pdf}};
            \node[anchor=south east, xshift=1cm] at (pic.north west) {$z_\text{content}$};
            \node[anchor=north west, xshift=-0.8cm] at (pic.south east) {$z_\text{style}$};
            % \node[anchor=north] at (pic.south) {$\mathbf{0}$};
            \draw[-latex](pic.south west) -- (pic.north west);
            \draw[-latex](pic.south west) -- (pic.south east);
        \end{tikzpicture}
        \subcaption{Google Fonts}\label{fig:interp_font}
    \end{minipage}
    \caption{%
    Examples of conditional generation.
    Each row corresponds to different $z_\text{content}$ from some test data.
    Each column corresponds to interpolated $z_\text{style} (0 \leq \|z_\text{style}\| \leq 3)$ along a randomly chosen unit vector.
    The images of the center column with the red frame are generated without the style features (i.e., $z_\text{style}=\mathbf{0}$).
    }
    \label{fig:interp}
\end{figure*}

\subsection{Style Transfer}
\label{sec:style_transfer_mnist}
Style-transfer experiments were performed to evaluate the variation of the learned style features.
Using the CL model, we extracted the $z_\text{content}$ of the test data.
Then, we combined them with the $z_\text{style}$ of different test data and put them into the decoder to generate style-transferred images.

The results of the style-transfer experiments are presented in \cref{fig:style_transfer}.
They illustrate that the styles were successfully transferred using the proposed style feature extractor.
For MNIST, styles such as the slant, size, and thickness were transferred.
For the Google Fonts dataset, mainly the bounding boxes (i.e., the size and the placement) of the characters were transferred as the styles.
This result indicated that the proposed method did not always learn the font faces as styles.
\begin{figure*}[t]
    \centering
    \begin{minipage}[b]{0.45\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[height=6cm]{fig/style_transfer_mnist_results.pdf}};
            \node[anchor=east] (src) at (pic.west) {\includegraphics[height=6cm]{fig/style_transfer_mnist_src.pdf}};
            \node[anchor=south] (dst) at (pic.north) {\includegraphics[width=6.6cm]{fig/style_transfer_mnist_dst.pdf}};
            \node[anchor=west, font=\footnotesize, xshift=0.08cm] at (dst.west) {self};
            \node[rotate=90, text=sxfer-red, anchor=south] at (src.west){Content source};
            \node[text=sxfer-blue, anchor=south] at (dst.north){Style destination};
        \end{tikzpicture}
        \subcaption{MNIST}\label{fig:style_transfer_mnist}
    \end{minipage}%
    \begin{minipage}[b]{0.55\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[height=6cm]{fig/style_transfer_font_results.pdf}};
            \node[anchor=east] (src) at (pic.west) {\includegraphics[height=6cm]{fig/style_transfer_font_src.pdf}};
            \node[anchor=south] (dst) at (pic.north) {\includegraphics[width=8.4cm]{fig/style_transfer_font_dst.pdf}};
            \node[anchor=west, font=\footnotesize, xshift=0.08cm] at (dst.west) {self};
            % \node[rotate=90, text=sxfer-red, anchor=south] at (src.west){Content source};
            % \node[text=sxfer-blue, anchor=south] at (dst.north){Style destination};
        \end{tikzpicture}
        \subcaption{Google Fonts}\label{fig:style_transfer_font}
    \end{minipage}
    \vspace{0.2cm}

    \begin{minipage}[b]{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[height=4cm]{fig/style_transfer_imagenette_results.pdf}};
            \node[anchor=east] (src) at (pic.west) {\includegraphics[height=4cm]{fig/style_transfer_imagenette_src.pdf}};
            \node[anchor=south] (dst) at (pic.north) {\includegraphics[width=7.2cm]{fig/style_transfer_imagenette_dst.pdf}};
            \node[anchor=west, font=\footnotesize, xshift=0.2cm] at (dst.west) {self};
        \end{tikzpicture}
        \subcaption{Imagenette}\label{fig:style_transfer_imagenette}
    \end{minipage}%
    \begin{minipage}[b]{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[height=4cm]{fig/style_transfer_daiso100_results.pdf}};
            \node[anchor=east] (src) at (pic.west) {\includegraphics[height=4cm]{fig/style_transfer_daiso100_src.pdf}};
            \node[anchor=south] (dst) at (pic.north) {\includegraphics[width=7.2cm]{fig/style_transfer_daiso100_dst.pdf}};
            \node[anchor=west, font=\footnotesize, xshift=0.2cm] at (dst.west) {self};
        \end{tikzpicture}
        \subcaption{DAISO-100}\label{fig:style_transfer_daiso100}
    \end{minipage}
    \caption{%
    Examples of style transfer.
    The red framed images represent the original images and the blue framed images represent the style destination images.
    Each white framed image is generated using the style-independent feature $z_\text{content}$ from the red framed image and the style feature $z_\text{style}$ from the blue framed image.
    }
    \label{fig:style_transfer}
\end{figure*}

\cref{fig:style_transfer_imagenette} shows the results on Imagenette.
The generated images were not clear; however, styles such as brightness and object shapes were transferred.
The results on DAISO-100 are shown in \cref{fig:style_transfer_daiso100}.
The generated images were slightly clearer than those of Imagenette, and the direction of the background conveyor belt was transferred as styles.

\subsection{Neighbor Analysis}
\label{sec:nn_mnist}
Although we evaluated the outputs of the decoder in the previous three experiments, we also attempted to directly observe the style features by analyzing neighbors.
We mapped all test data to the style feature space using the encoder, and we observed the neighbors of some of the test data in terms of $z_\text{style}$.
Besides, we observed the neighbors in terms of $z_\text{content}$ to confirm the style independence of the CL features.

We illustrate the neighbors of some example test data in \cref{fig:nn}.
The neighbors had similar styles in the style feature spaces shown in \cref{fig:nn_vae_mnist,fig:nn_vae_font}.
However, for MNIST, the neighbors tended to simply be similar data.
For the Google Fonts dataset, the neighbors had different characters with similar bounding boxes.
Changes in bounding boxes were observed as the styles in the style-transfer experiments.
In style-independent feature spaces, the neighbors had almost the same content in different styles, as shown in \cref{fig:nn_cl_mnist,fig:nn_cl_font}.
This result agrees with the characteristics of the CL; the CL models extract data augmentation-independent features and are suitable for classification~\cite{SimCLR,MoCo,SimSiam}.
\begin{figure*}[t]
    \centering
    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0){\includegraphics[height=4.5cm]{fig/nn_vae_mnist_neighbors.pdf}};
            \node[anchor=east] (anchors) at (pic.west){\includegraphics[height=4.5cm]{fig/nn_vae_mnist_anchors.pdf}};
            \node[anchor=south, text=sxfer-red, font=\small] at (anchors.north) {Anchor};
            \node[anchor=south, font=\small, text depth=0cm] at (pic.north) {Neighbor data (w.r.t.~$z_\text{style}$)};
            \draw[-latex] (pic.south west) -- (pic.south east);
            \node[anchor=north east, font=\small] at (pic.south east) {Distance from anchors};
        \end{tikzpicture}
        \subcaption{MNIST, $z_\text{style}$}\label{fig:nn_vae_mnist}
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0){\includegraphics[height=4.5cm]{fig/nn_cl_mnist_neighbors.pdf}};
            \node[anchor=east] (anchors) at (pic.west){\includegraphics[height=4.5cm]{fig/nn_cl_mnist_anchors.pdf}};
            \node[anchor=south, text=sxfer-red, font=\small] at (anchors.north) {Anchor};
            \node[anchor=south, font=\small, text depth=0cm] at (pic.north) {Neighbor data (w.r.t.~$z_\text{content}$)};
            \draw[-latex] (pic.south west) -- (pic.south east);
            \node[anchor=north east, font=\small] at (pic.south east) {Distance from anchors};
        \end{tikzpicture}
        \subcaption{MNIST, $z_\text{content}$}\label{fig:nn_cl_mnist}
    \end{minipage}
    \vspace{0.2cm}

    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0){\includegraphics[height=4.5cm]{fig/nn_vae_font_neighbors.pdf}};
            \node[anchor=east] (anchors) at (pic.west){\includegraphics[height=4.5cm]{fig/nn_vae_font_anchors.pdf}};
        \end{tikzpicture}
        \subcaption{Google Fonts, $z_\text{style}$}\label{fig:nn_vae_font}
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0){\includegraphics[height=4.5cm]{fig/nn_cl_font_neighbors.pdf}};
            \node[anchor=east] (anchors) at (pic.west){\includegraphics[height=4.5cm]{fig/nn_cl_font_anchors.pdf}};
        \end{tikzpicture}
        \subcaption{Google Fonts, $z_\text{content}$}\label{fig:nn_cl_font}
    \end{minipage}
    \vspace{0.2cm}

    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0){\includegraphics[height=3.8cm]{fig/nn_vae_imagenette_neighbors.pdf}};
            \node[anchor=east] (anchors) at (pic.west){\includegraphics[height=3.8cm]{fig/nn_vae_imagenette_anchors.pdf}};
        \end{tikzpicture}
        \subcaption{Imagenette, $z_\text{style}$}\label{fig:nn_vae_imagenette}
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0){\includegraphics[height=3.8cm]{fig/nn_cl_imagenette_neighbors.pdf}};
            \node[anchor=east] (anchors) at (pic.west){\includegraphics[height=3.8cm]{fig/nn_cl_imagenette_anchors.pdf}};
        \end{tikzpicture}
        \subcaption{Imagenette, $z_\text{content}$}\label{fig:nn_cl_imagenette}
    \end{minipage}
    \vspace{0.2cm}

    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0){\includegraphics[height=3.8cm]{fig/nn_vae_daiso100_neighbors.pdf}};
            \node[anchor=east] (anchors) at (pic.west){\includegraphics[height=3.8cm]{fig/nn_vae_daiso100_anchors.pdf}};
        \end{tikzpicture}
        \subcaption{DAISO-100, $z_\text{style}$}\label{fig:nn_vae_daiso100}
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0){\includegraphics[height=3.8cm]{fig/nn_cl_daiso100_neighbors.pdf}};
            \node[anchor=east] (anchors) at (pic.west){\includegraphics[height=3.8cm]{fig/nn_cl_daiso100_anchors.pdf}};
        \end{tikzpicture}
        \subcaption{DAISO-100, $z_\text{content}$}\label{fig:nn_cl_daiso100}
    \end{minipage}
    \caption{%
    Visualization of the neighbors in terms of $z_\text{style}$ and $z_\text{content}$.
    The leftmost red framed data are anchors, and their neighbors are listed in order of distance.
    }
    \label{fig:nn}
\end{figure*}

\cref{fig:nn_vae_imagenette,fig:nn_cl_imagenette} show the results on Imagenette.
\cref{fig:nn_vae_imagenette} is difficult to interpret; however, \cref{fig:nn_cl_imagenette} illustrates that CL mapped images with the same object to similar vectors.
\cref{fig:nn_vae_daiso100,fig:nn_cl_daiso100} show the results on DAISO-100.
For CL model, the results were similar to those of Imagenette; the neighbors were almost the same object in various styles.
\cref{fig:nn_vae_daiso100} shows that the CVAE extracted similar features corresponding to the styles.
Specifically, we can see that the neighbors were with different objects and similar backgrounds.

\subsection{Combination with various CL Methods}
Although we evaluated the proposed method combined with MoCo v2~\cite{chen2020mocov2}, we also examined the combinations with other CL methods.
We used SimCLR~\cite{SimCLR}, SimSiam~\cite{SimSiam}, and VICReg~\cite{VICReg}.
SimCLR is a classical CL method on which MoCo~\cite{MoCo,chen2020mocov2} is based.
SimSiam and VICReg are noncontrastive CL methods, and they do not use negative samples while learning.
As a reference, we tested a supervised variant of the proposed method.
The one-hot encoded class labels are used instead of the CL feature vectors.
We compared the effects of the different CL methods using the same experiments described in \cref{sec:da_removal_mnist,sec:interp_mnist}.

The hyperparameters of the CL methods were set to their defaults described in the original papers.
For training CVAE, we used the same hyperparameters as that in the MoCo v2 version except for the combination of SimSiam and MNIST.
In the experiment with this combination, we changed the weight of the MI $\lambda_\text{MINE}$ to $0.1$ because the styles were not extracted well with the original setting.

\cref{fig:da_removal_variations} shows the results of data augmentation isolation.
Data augmentation features were isolated by the CL methods, and the CVAE captured them, regardless of the selected CL method.
The reconstruction images without styles were blurry in the experiment using SimSiam with MNIST (bottom row of \cref{fig:da_removal_mnist_simsiam}).
This indicates that style extraction performance depends on how the CL method is trained.
Besides, when class labels are given instead of the CL feature, the reconstruction images without styles looked similar to the average of the class (bottom row of \cref{fig:da_removal_mnist_supervised,fig:da_removal_font_supervised}).
These results show that the proposed method successfully captured features that the condition of the CVAE (i.e., style-independent CL feature $z_\text{content}$ or the class label) do not contain.
\begin{figure*}
    \centering
    \begin{minipage}{\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[height=3cm]{fig/da_removal_mnist.pdf}};
            \node[anchor=north east, yshift=-0.3cm] at (pic.north west) {Input $x$};
            \node[anchor=north east, yshift=-1cm] at (pic.north west) {Data augmented input};
            \node[anchor=north east, yshift=-1.7cm] at (pic.north west) {Reconstruction $D_\theta(z_\text{style}, z_\text{content})$};
            \node[anchor=north east, yshift=-2.5cm] at (pic.north west) {Style-free reconstruction $D_\theta(\mathbf{0}, z_\text{content})$};
        \end{tikzpicture}
        \subcaption{MNIST, MoCo v2 (from \cref{fig:da_removal_mnist})}
    \end{minipage}
    \vspace{0.2cm}

    \begin{minipage}{0.5\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{fig/da_removal_mnist_simclr.pdf}
        \subcaption{MNIST, SimCLR~\cite{SimCLR}}\label{fig:da_removal_mnist_simclr}
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{fig/da_removal_mnist_simsiam.pdf}
        \subcaption{MNIST, SimSiam~\cite{SimSiam}}\label{fig:da_removal_mnist_simsiam}
    \end{minipage}%
    \vspace{0.2cm}

    \begin{minipage}{0.5\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{fig/da_removal_mnist_simclr.pdf}
        \subcaption{MNIST, VICReg~\cite{VICReg}}\label{fig:da_removal_mnist_vicreg}
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{fig/da_removal_mnist_supervised.pdf}
        \subcaption{MNIST, supervised (reference)}\label{fig:da_removal_mnist_supervised}
    \end{minipage}%
    \vspace{0.2cm}

    \begin{minipage}{\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[height=3cm]{fig/da_removal_font.pdf}};
            \node[anchor=north east, yshift=-0.3cm] at (pic.north west) {Input $x$};
            \node[anchor=north east, yshift=-1cm] at (pic.north west) {Data augmented input};
            \node[anchor=north east, yshift=-1.7cm] at (pic.north west) {Reconstruction $D_\theta(z_\text{style}, z_\text{content})$};
            \node[anchor=north east, yshift=-2.5cm] at (pic.north west) {Style-free reconstruction $D_\theta(\mathbf{0}, z_\text{content})$};
        \end{tikzpicture}
        \subcaption{Google Fonts, MoCo v2 (from \cref{fig:da_removal_font})}
    \end{minipage}
    \vspace{0.2cm}

    \begin{minipage}{0.5\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{fig/da_removal_font_simclr.pdf}
        \subcaption{Google Fonts, SimCLR~\cite{SimCLR}}\label{fig:da_removal_font_simclr}
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{fig/da_removal_font_simsiam.pdf}
        \subcaption{Google Fonts, SimSiam~\cite{SimSiam}}\label{fig:da_removal_font_simsiam}
    \end{minipage}%
    \vspace{0.3cm}

    \begin{minipage}{0.5\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{fig/da_removal_font_simclr.pdf}
        \subcaption{Google Fonts, VICReg~\cite{VICReg}}\label{fig:da_removal_font_vicreg}
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{fig/da_removal_font_supervised.pdf}
        \subcaption{Google Fonts, supervised (reference)}\label{fig:da_removal_font_supervised}
    \end{minipage}%
    \caption{%
    Examples of isolating and capturing data augmentation features when the proposed method is combined with different CL methods.
    From top to bottom: original images, images after data augmentation, reconstructed images $D_\theta(z_\text{style}, z_\text{content})$, and images reconstructed without style features $D_\theta(\mathbf{0}, z_\text{content})$.
    }
    \label{fig:da_removal_variations}
\end{figure*}

The results of conditional generation are shown in \cref{fig:interp_variations}.
Note that the learned feature spaces of the CVAE are different in every experiment, and therefore, the changes in styles were not the same across the experiments.
\cref{fig:interp_variations} illustrates that the CVAE can extract style features with any CL method successfully.
The supervised variant on the Google Font dataset (\cref{fig:interp_mnist_supervised,fig:interp_font_supervised}) generated more variation in styles by $z_\text{style}$.
Specifically, the changes in the font faces were captured as shown in \cref{fig:interp_font_supervised}.
\begin{figure*}
    \centering
    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[width=0.8\linewidth]{fig/interp_mnist_simclr.pdf}};
            \node[anchor=south east, xshift=1cm] at (pic.north west) {$z_\text{content}$};
            \node[anchor=north west, xshift=-0.8cm] at (pic.south east) {$z_\text{style}$};
            % \node[anchor=north] at (pic.south) {$\mathbf{0}$};
            \draw[-latex](pic.south west) -- (pic.north west);
            \draw[-latex](pic.south west) -- (pic.south east);
        \end{tikzpicture}
        \subcaption{MNIST, SimCLR~\cite{SimCLR}}\label{fig:interp_mnist_simclr}
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[width=0.8\linewidth]{fig/interp_mnist_simsiam.pdf}};
            \node[anchor=south east, xshift=1cm] at (pic.north west) {$z_\text{content}$};
            \node[anchor=north west, xshift=-0.8cm] at (pic.south east) {$z_\text{style}$};
            % \node[anchor=north] at (pic.south) {$\mathbf{0}$};
            \draw[-latex](pic.south west) -- (pic.north west);
            \draw[-latex](pic.south west) -- (pic.south east);
        \end{tikzpicture}
        \subcaption{MNIST, SimSiam~\cite{SimSiam}}\label{fig:interp_mnist_simsiam}
    \end{minipage}%
    \vspace{0.2cm}

    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[width=0.8\linewidth]{fig/interp_mnist_vicreg.pdf}};
            % \node[anchor=south east, xshift=1cm] at (pic.north west) {$z_\text{content}$};
            % \node[anchor=north west, xshift=-0.8cm] at (pic.south east) {$z_\text{style}$};
            % \node[anchor=north] at (pic.south) {$\mathbf{0}$};
            \draw[-latex](pic.south west) -- (pic.north west);
            \draw[-latex](pic.south west) -- (pic.south east);
        \end{tikzpicture}
        \subcaption{MNIST, VICReg~\cite{VICReg}}\label{fig:interp_mnist_vicreg}
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[width=0.8\linewidth]{fig/interp_mnist_supervised.pdf}};
            \node[anchor=south east, xshift=1cm] at (pic.north west) {$z_\text{content}$};
            \node[anchor=north west, xshift=-0.8cm] at (pic.south east) {$z_\text{style}$};
            % \node[anchor=north] at (pic.south) {$\mathbf{0}$};
            \draw[-latex](pic.south west) -- (pic.north west);
            \draw[-latex](pic.south west) -- (pic.south east);
        \end{tikzpicture}
        \subcaption{MNIST, supervised (reference)}\label{fig:interp_mnist_supervised}
    \end{minipage}%
    \vspace{0.2cm}

    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[width=0.8\linewidth]{fig/interp_font_simclr.pdf}};
            \node[anchor=south east, xshift=1cm] at (pic.north west) {$z_\text{content}$};
            \node[anchor=north west, xshift=-0.8cm] at (pic.south east) {$z_\text{style}$};
            % \node[anchor=north] at (pic.south) {$\mathbf{0}$};
            \draw[-latex](pic.south west) -- (pic.north west);
            \draw[-latex](pic.south west) -- (pic.south east);
        \end{tikzpicture}
        \subcaption{Google Fonts, SimCLR~\cite{SimCLR}}\label{fig:interp_font_simclr}
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[width=0.8\linewidth]{fig/interp_font_simsiam.pdf}};
            \node[anchor=south east, xshift=1cm] at (pic.north west) {$z_\text{content}$};
            \node[anchor=north west, xshift=-0.8cm] at (pic.south east) {$z_\text{style}$};
            % \node[anchor=north] at (pic.south) {$\mathbf{0}$};
            \draw[-latex](pic.south west) -- (pic.north west);
            \draw[-latex](pic.south west) -- (pic.south east);
        \end{tikzpicture}
        \subcaption{Google Fonts, SimSiam~\cite{SimSiam}}\label{fig:interp_font_simsiam}
    \end{minipage}%
    \vspace{0.2cm}

    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[width=0.8\linewidth]{fig/interp_font_vicreg.pdf}};
            \node[anchor=south east, xshift=1cm] at (pic.north west) {$z_\text{content}$};
            \node[anchor=north west, xshift=-0.8cm] at (pic.south east) {$z_\text{style}$};
            % \node[anchor=north] at (pic.south) {$\mathbf{0}$};
            \draw[-latex](pic.south west) -- (pic.north west);
            \draw[-latex](pic.south west) -- (pic.south east);
        \end{tikzpicture}
        \subcaption{Google Fonts, VICReg~\cite{VICReg}}\label{fig:interp_font_vicreg}
    \end{minipage}%
    \begin{minipage}{0.5\linewidth}
        \centering
        \begin{tikzpicture}
            \node (pic) at (0, 0) {\includegraphics[width=0.8\linewidth]{fig/interp_font_supervised.pdf}};
            \node[anchor=south east, xshift=1cm] at (pic.north west) {$z_\text{content}$};
            \node[anchor=north west, xshift=-0.8cm] at (pic.south east) {$z_\text{style}$};
            % \node[anchor=north] at (pic.south) {$\mathbf{0}$};
            \draw[-latex](pic.south west) -- (pic.north west);
            \draw[-latex](pic.south west) -- (pic.south east);
        \end{tikzpicture}
        \subcaption{Google Fonts, supervised (reference)}\label{fig:interp_font_supervised}
    \end{minipage}%
    \caption{%
    Examples of conditional generation when the proposed method is combined with different CL methods.
    Each row corresponds to different $z_\text{content}$ from some test data.
    Each columns corresponds to interpolated $z_\text{style} (0 \leq \|z_\text{style}\| \leq 3)$ along a randomly chosen unit vector.
    The images of the center column with the red frame are generated without the style features (i.e., $z_\text{style}=\mathbf{0}$).
    }
    \label{fig:interp_variations}
\end{figure*}
