% !TEX root = ../main.tex
\section{Introduction}\label{sec:intro}


\paragraph{Molecular Descriptors and Topological Indices} In computational chemistry, a molecular descriptor is simply a function that maps graphs modeling molecules to numbers. An important family of molecular descriptors are the topological indices, i.e.~numerical graph invariants that characterize the topology of graphs associated with molecules~\cite{trinajstic2018chemical}. They have been studied for more than a century and hundreds of them are available and used in the literature~\cite{todeschini2008handbook}. These indices play a vital role in computational chemistry as they are used as molecular descriptors for QSAR (Quantitative Structure-Activity Relationship) and QSPR (Quantitative Structure-Property Relationship) \cite{yousefinejad2015chemometrics,dearden2017use}. In other words, the topology and geometrical properties of hydrogen-suppressed graphs of molecules can be used to describe their physical and chemical properties \cite{bonchev2018chemical}. This in turn helps in predicting the biological activity, toxicity, and other properties of molecules. Topological indices provide a single numerical value that can describe otherwise complicated and intricate topological and geometrical properties of molecules. Due to their efficacy in capturing molecular properties, topological indices are often used for drug design, toxicity detection, and many other applications in computational chemistry~\cite{nantasenamat2010advances,ghasemi2018neural}.

\paragraph{Connectivity and Distance-based Indices} The many topological indices that have been proposed and studied in the literature~\cite{todeschini2008handbook} can be broadly classified in two categories: connectivity-based and distance-based \cite{trinajstic2018chemical, todeschini2008handbook, leszczynski2012handbook, xue2000molecular}. The former are based on the adjacency relationships among the vertices of the graph, while the latter use the distances. Some well-known connectivity-based indices are the so-called ``Zagreb group'' indices~\cite{nikolic2003zagreb}, the Randi{\'c} index~\cite{randic2001connectivity} and the Hosoya index~\cite{hosoya1971topological}. On the other hand, classical distance-based indices include the Wiener index~\cite{nikolic1995wiener}, the Balaban index~\cite{balaban2000historical} and information-theoretic indices~\cite{basak2000information}.

\paragraph{Treewidth~\cite{robertson1984graph}}
Treewidth is a well-studied parameter for graphs~\cite{cygan2015parameterized}. Informally, it is a measure of tree-likeness of a graph~\cite{bodlaender1993tourist}. Trees and forests have a treewidth of $1$ and graphs with treewidth $k$ can be decomposed into small parts, called ``bags'', of size at most $k+1$ which are in turn connected to each other in a tree-like manner. Many NP-hard graph problems are known to have efficient solutions when restricted to graphs with bounded treewidth~\cite{DBLP:conf/icalp/Bodlaender88}. See Section~\ref{sec:prelim} for a formal definition.

%In this work we show that more than $99.9 \%$ molecules in the enitre PubChem database have treewidht less than $5$, less than $100$ molecules have treewidth greater than $20$, in the enitre database of more than $100$ million compounds. For more detailed statistics for the entire database refer to Section \ref{sec:Experiments}. Therefore, supporting our argument of developing parameterized algorithms for bounded treewidth and pathwidth for the above mentioned problems.


\paragraph{Our Focus} Given their significance in computational chemistry and biology, computing chemical descriptors is a natural algorithmic problem. Some of these indices are computable in polynomial time. Unfortunately, for many other well-studied studied topological indices, such as the ones below, the corresponding counting problems are known to be $\# P$-complete~\cite{valiant1979complexity}, leading to best-known algorithms that can only scale to molecules with a tiny number of atoms. In this work, we focus on developing fixed-parameter tractable (FPT) algorithms using treewidth as the parameter. This is motivated by the observation that real-world molecules are sparse, due to the limited valency of atoms, and often have a tree-like appearance. Thus, we guess that they should have small treewidth. In particular, we focus on computing the following:
\begin{compactitem}
	\item \textbf{Counting Kekulé Structures:}  A Kekulé structure of a molecule is essentially a perfect matching of the underlying graph. Therefore, counting Kekulé structures is equivalent to finding the total number of perfect matchings of the underlying graph~\cite{trinajstic2018chemical}.
	\item \textbf{Hosoya Index:} The Hosoya index, also known as the Z index, of a graph is the total number of matchings of the graph~\cite{hosoya1971topological}. 
	\item \textbf{Merrifield–Simmons Index:} The Merrifield–Simmons index of a graph is the total number of independent sets of the graph~\cite{merrifield1980structures}.
	\item \textbf{Graph Entropy:} Graph Entropy is defined based on the number of matchings and independent sets of every possible size in a given graph~\cite{cao2017network}. Specifically, for a graph $G$ with $n$ vertices and $m$ edges, we have
	\begin{equation} \textstyle \label{eq:entropy}
	I_v(G) := - \sum_{k=0}^n \frac{i_k(G)}{i(G)} \cdot \log \frac{i_k(G)}{i(G)}
	~~~\text{ and }~~~
	I_e(G) := -\sum_{k=0}^m \frac{i'_k(G)}{i'(G)} \cdot \log \frac{i'_k(G)}{i'(G)}.
\end{equation}
	Here, $I_v(G)$ is the \emph{graph entropy based on independent sets}, $i_k(G)$ is the number of independent sets of size $k$ in the graph $G$ and $i(G)$ is the total number of independent sets, i.e.~$i(G) = \sum_{k=0}^n i_k(G).$ Similarly, $I_e(G)$ is the \emph{graph entropy based on matchings} and $i'_k(G)$ is the number of matchings with $k$ edges in $G$ with $i'(G) := \sum_{k=0}^m i'_k(G)$~\cite{wan2018computing}.
\end{compactitem}


It is well-known that the first three problems above are $\# P$-complete~\cite{valiant1979complexity,jerrum1987two,dyer2000markov}. Currently, the existing non-parameterized approaches take exponential time in the worst case and do not scale up for molecules with a large number of atoms and bonds. There are known FPT algorithms parameterized by the treewidth~\cite{wan2018computing} in the literature. However, we show that one can improve these algorithms significantly, as well.

%\paragraph*{Parameterized Algorithms}
%Parameterized algorithms are a class of algorithms designed to handle computational problems that are otherwise considered computationally intractable \cite{cygan2015parameterized,downey2012parameterized}.These algorithms take an additional parameter $k$ along with the usual input size $n$. The goal in developing these algorithms is to provide a solution that runs in time $f(k) \cdot \poly(n)$, where $f(k)$ is a function of the parameter $k$ and $\poly(n)$ is a polynomial in the size of the input $n$. A problem that can be solved with this time complexity—having polynomial dependence on the input size and non-polynomial dependence on the parameter—is called fixed-parameter tractable (FPT). This provides an efficient way to deal with problems in applications where the input size is large and the parameter is known to be bounded and small. In contrast, naive algorithms, which have non-polynomial dependence on the input size, would not scale up and would be impractical to use.



\paragraph{Our Contribution} On the theoretical side, we present several algorithms for the aforementioned classical problems in computational chemistry. Our algorithms are fixed-parameter tractable (FPT) and run in polynomial time for graphs with bounded treewidth. They are simple and follow the paradigm of dynamic programming over tree decompositions. Moreover, they significantly improve the previous asymptotic runtime for combinatorial solutions to these problems as summarized in Table~\ref{tab:runtime}.
%\footnote{In \cite{wan2018computing}, only the time complexity for computing matchings of all sizes and independent sets of all sizes is given, whereas the time complexity reported in the table follows from a simple extension of their ideas.}.
On the practical side, we provide extensive experimental results over more than 113 million real-world molecules from the PubChem database~\cite{kim2023pubchem}. Our experiments demonstrate that more than $99.9\%$ of molecules in the PubChem database have a treewidth of $5$ or smaller.  Thus, our algorithms are directly applicable to them. 
% To the best of our knowledge, this is the first work advocating for the use of parameterized algorithms in computational chemistry and the discovery that most molecules have bounded treewidth is novel. 
Based on our results, we believe developing parameterized algorithms and specifically using treewidth as the parameter, should be adopted as the default strategy when dealing with graph problems in computational chemistry. Finally, we also experimentally compare the runtime of our algorithms with previous methods in the literature, over the entire PubChem database, showing that the theoretical advances lead to significant runtime improvements in practice, as well.

\paragraph{Related Parameterized Results} Counting all matchings or independent sets of a given graph is a problem expressible in the monadic second-order logic and thus FPT with respect to treewidth, based on Courcelle's well-known theorem~\cite{courcelle2001fixed}. However, algorithms obtained by Courcelle's theorem are not practical and this approach is also not applicable to counting matchings/independent sets of a desired size. The work~\cite{wan2018computing} provides parameterized algorithms to find the number of independent sets or matchings of any desired size using treewidth as the parameter. This can directly be applied to our setting. In comparison to~\cite{wan2018computing}, our approach is more efficient by an almost-linear factor for graph entropies and a quadratic factor for the indices. We also improve the runtime's dependence on treewidth. See Table~\ref{tab:runtime}. Our algorithms are not asymptotically optimal with respect to the parameter. Specifically, the runtime's dependence on treewidth can be further improved using techniques that employ fast subset convolution~\cite{DBLP:journals/corr/abs-1806-01667}. However, there are two downsides to this: (i)~some convolution-based algorithms produce incorrect results in practice due to floating-point precision errors, and (ii)~the runtime dependence on $n$ increases by a logarithmic factor. The former issue is of course unacceptable in our setting, thus we design purely combinatorial algorithms that avoid floating-point computations. As for the latter issue, we will see in Section~\ref{sec:Experiments} that 99.9\% of molecules have a treewidth of less than $5.$ Thus, the primary goal is to reduce the runtime's dependence on $n,$ rather than $\twi.$

\begin{table}[H]
	\centering
	\small 
	\begin{tabular}{llccc}
	\toprule
	  \textbf{Counting Problem} & \textbf{WTZL~\cite{wan2018computing}} & \textbf{Our Algorithm} \\
	\midrule
	Kekulé  & $\bigO(n^3 \cdot \textup{poly}(\twi) \cdot 4^{\twi})$ & $\bigO(n\cdot \textup{poly}(\twi)\cdot3^{\twi})$ \\
	Hosoya & $\bigO(n^3 \cdot \textup{poly}(\twi) \cdot 4^{\twi})$ & $\bigO(n\cdot \textup{poly}(\twi)\cdot3^{\twi})$ \\
	Merrifield--Simmons &  $\bigO(n^3 \cdot \textup{poly}(\twi) \cdot 2^{\twi})$ & $\bigO(n\cdot \textup{poly}(\twi)\cdot2^{\twi})$ \\
	Matchings (all sizes) &  $\bigO(n^3 \cdot \twi \cdot 4^\twi)$ & $\bigO(n^2 \cdot \log n  \cdot \poly(\twi)\cdot3^{\twi})$ \\
	Independent Sets (all sizes) &  $\bigO(n^3 \cdot \twi \cdot 2^\twi)$ & $\bigO(n^2 \cdot \log n  \cdot \poly(\twi)\cdot2^{\twi})$ \\
	\bottomrule
	\end{tabular}
	\caption{Runtime comparison of our algorithms and those of~\cite{wan2018computing}. Here, $n$ is the number of vertices, $m$ is the number of edges, and $\twi$ is the treewidth of the graph.}
	\label{tab:runtime}
\end{table}
% \todo{Add a footnote that Kekule, Hosoya, Merrifield--Simmons are mentioned in int WTZL work but complexities are gievn only for all matchings computing}
	


%\paragraph*{Structure of the paper}
%The paper is divided into three main sections. We begin with basic notations and preliminaries in Section \ref{sec:prelim}. Our main algorithms and theoretical results are presented in Section \ref{sec:algos}. Finally in Section \ref{sec:Experiments}, we provide all the experimental results, statistics, and implementation details. Additionally, for the sake of completeness, we provide all the proofs in the appendix.