% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
%\usepackage[review]{EMNLP2022}
%\usepackage[review]{EACL2023}
\usepackage{EMNLP2023}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

\usepackage{xcolor}
\newcommand\todo[1]{\textcolor{red}{#1}}
\usepackage{hyperref} % added for URL hyperlink

% Importing packages
\usepackage{booktabs} % for table
\usepackage{makecell} % for table
\usepackage{xcolor} % for color
\usepackage{graphicx} % for images
\graphicspath{ {images/} }
\usepackage{comment}


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.


%Generating negation and role reversal data via in-context learning
% Extended Datasets Tell a Different Story
\title{Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning}
%\title{Extending Psycholinguistic Datasets Via In-Context Learning: Larger Probes Tell a Different Story}
% Scaling up psycholinguistic probing: the benefits of larger datasets


% \title{Can large language models really do everything? The benefits of extended psycholinguistic datasets}
% \title{Scaling up psycholinguistic probing: the benefits of larger datasets}
% \title{When data size matters: extending psycholinguistic datasets to study negation and role reversal}
% \title{When data size matters: extending psycholinguistic datasets via in-context learning}
% \title{Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-context Learning}
% \title{When size matters: extending psycholinguistic datasets via in-context learning}
% \title{Negation and role reversal: large-scale psycholinguistic probing of language models}
% \title{Extending Psycholinguistic Datasets Via In-Context Learning}
%\title{1500 Samples Are Better Than 44: Extending Psycholinguistic Datasets Via In-Context Learning}
%\title{Can Generate, But Not Understand: \\Extending Psycholinguistic Datasets Via In-Context Learning}
%\title{Can Generate, But Not Necessarily  Understand: \\Extending Psycholinguistic Datasets Via In-Context Learning}
%\title{Extending Psycholinguistic Datasets Via In-Context Learning}
%\title{(WIP title) Extending Psycholinguistic Datasets using template and GPT3}
%\title{(WIP title) GPT doesn't understand it, but it can generate it}
% \title{(WIP title) Negation, roles and other things LMs can't do.\\Now more of them.}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

%\author{Namrata Shivagunde \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  \texttt{nshivagu@cs.uml.edu} \\\And
%  Second Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  \texttt{email@domain} \\
%   Second Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  \texttt{email@domain} \\}

\author{
Namrata Shivagunde, Vladislav Lialin, and Anna Rumshisky\\
Department of Computer Science\\
University of Massachusetts Lowell\\
\texttt{\{nshivagu,vlialin,arum\}@cs.uml.edu}\\
}

\begin{document}
\maketitle
\begin{abstract}

% Older version:
% As the community invests considerable effort into creating, training, and deploying large language models (LMs), it is important to understand the datasets and tasks to which LMs might not be well-suited. The datasets NEG-136-SIMP and ROLE-88 used for Psycholinguistic diagnostics tests in  \cite{ettinger2020bert} are drawn from human experiments and found to be a very useful in understanding how well language model perform on negation and role reversal tasks. However, these are very small datasets and as small datasets do not have enough statistical power to be useful for model comparison (Card et al., 2020), we introduce large extensions to the existing datasets. For negation, we used a template following original source of dataset and increased from 18 to 770 sentence pairs. For role reversal, we used GPT3 with few-shot prompting and human verification to increase from 44 sentence pair to 750. We evaluated 22 models on these datasets following \cite{Lialin2022LifeAB} including GPT3 and we observed that GPT3 can generate ROLE-1500 but its prediction accuracy was not the best among all models. We also found that the performance of all the models dips 20-54\% on extended datasets and sensitivity to negation increased upto 4-36\% for most of it.

% Probing is one such method that allows us to evaluate specific capabilities of pre-trained models without the need for training data.

% New version:
% As the community invests considerable effort into creating, training, and deploying large language models (LMs), it is important to understand the datasets and tasks to which LMs might not be well-suited. One promising approach to this task are probing datasets that test specific model abilities, such as the ability to understand negation. However, frequently, these datasets are small and this limits their statistical power, thus, the utility in comparing different models. In this work, we introduce new datasets for negation and role reversal inspired by psycholinguistic studies. We dramatically extend NEG-136 and ROLE-88 datasets using rule-based generation and GPT3 increasing their size from 18 and 44 examples to 770 and 750 correspondingly. We evaluate 22 models on these datasets including GPT3 and show that the performance of all the models dips 20-54\% compared to the original, smaller datasets. Finally, we observe that while GPT3 has generated all the examples in ROLE-1500 its top-5 accuracy is only 24.5\%. More than that, RoBERTa and ALBERT outperform GPT3 on this dataset. Our experiments also show unexpected levels of negation sensitivity in models like RoBERTa and T5 demonstrating that previous findings might have been skewed due to smaller test sets.

% Version 3 (shorter):
%As the community invests considerable effort into creating, training, and deploying large language models, it is important to understand their capabilities and limitations. 
%the datasets and tasks to which language models might not be well-suited. 
%One common technique for this problem is probing, which tests specific model abilities using targeted datasets.%

% Probing is a technique often used to test specific capabilities of large language models using targeted datasets.
Language model probing is often used to test specific capabilities of models.
However, conclusions from such studies may be limited when the probing benchmarks are small and lack statistical power. In this work, we introduce new, larger datasets for negation (NEG-1500-SIMP) and role reversal (ROLE-1500) inspired by psycholinguistic studies. We dramatically extend existing NEG-136 and ROLE-88 benchmarks using GPT3, increasing their size from 18 and 44 sentence pairs to 750 each. 
%Our study also includes 
We also create 
another version of extended negation dataset (NEG-1500-SIMP-TEMP), created using template-based generation. It consists of 770 sentence pairs. We evaluate 22 models on the extended datasets,
seeing model performance dip 
%and show that the performance of all the models dips 
20-57\% compared to the original smaller benchmarks. 
%Our experiments show 
We observe 
high levels of negation sensitivity in models like BERT and ALBERT demonstrating that previous findings might have been skewed due to smaller test sets. Finally, we observe that while GPT3 has generated all the examples in ROLE-1500 is only able to solve 24.6\% of them during probing. 
%
The datasets and code are available on \href{https://github.com/text-machine-lab/extending_psycholinguistic_dataset}{Github}\footnote{ \href{https://github.com/text-machine-lab/extending_psycholinguistic_dataset}{https://github.com/text-machine-lab/extending\_psycholinguistic\_dataset}}.

\end{abstract}

\section{Introduction}
Understanding the limitations of large language models (LLMs) becomes ever more important with their accelerated adoption and application to real-life tasks. After the original discovery that large LMs %language models (LMs) 
could perform simple NLP tasks without additional training
%any task-specific training data 
\cite{radford2019language}, the use of these models has rapidly grown, as have their capabilities \cite{brown2020language_gpt3,Sanh2021MultitaskPT,Chowdhery2022PaLMSL_PALM}.
As the community invests considerable effort into creating, training, and deploying these models \cite{Zhang2022OPTOP_OPT,gptneo}, it is important to understand the types of data and tasks they might not be well-suited.

The field of analysis of pre-trained models 
%although still relatively young, 
has grown rapidly in recent years
\cite{Zagoury2021WhatsTB,Liu2021ProbingAT,Lialin2022LifeAB,Srivastava2022BeyondTI,aroger2020}.
%\cite{tenney2019bert_rediscovers,mccoy-etal-2019-right,talmor2019olmpics,Goldberg2019AssessingBS,ettinger2020bert,Kassner2020ArePL,Zagoury2021WhatsTB,Liu2021ProbingAT,Lialin2022LifeAB,Srivastava2022BeyondTI}.
Methods such as attention pattern analysis \cite{kovaleva2019revealing,kobayashi2020attention}, linear probing \cite{tenney2019bert_rediscovers}, and zero-shot
% a.k.a. behavioral 
probing \cite{belinkov-etal-2020-interpretability,talmor2019olmpics,ettinger2020bert,Lialin2022LifeAB} allow us to evaluate specific capabilities of pre-trained models. Zero-shot methods give us arguably the most clear picture, as they directly probe what the model learned through the upstream task and allow the researcher to target very specific skills such as understanding of negation or role. %the ability to object comparison.

However, even though these methods do not require training data, producing a good dataset for zero-shot evaluation of these language models is not an easy task. We want these datasets to be clean, diverse and to have enough statistical power to be useful for model comparison \cite{card-etal-2020-little_power}.
%
% First, we want it to be as clean as possible with close-to-zero mislabelled examples. Second, it should be large, as small datasets do not have enough statistical power to be useful for model comparison \cite{card-etal-2020-little_power}. And third, these datasets should be diverse and reflect the distribution of real-life texts.
%
Many existing probing datasets struggle with at least one of these requirements.

% Negation and role reversal datasets from \citet{ettinger2020bert} suffer from their limited size.
Psycholinguistic datasets used in a study by \citet{ettinger2020bert} have been particularly interesting in that they enabled a comparison between model behavior and human response, including both N400 effects and well-reasoned cloze judgments by human speakers. 
%
Despite being used in multiple studies since   \cite{Lialin2022LifeAB,aroger2020,Yian2020ett}, these datasets are quite small, ranging in size from 18 sentence pairs in negation (NEG-136-SIMP) to a maximum of 44 sentence pairs in the role-reversal dataset (ROLE-88).

%\citet{ettinger2020bert} tests BERT \cite{devlin2018bert} capabilities on extremely small datasets with the largest having 60 examples and the smallest just 18.

% \citet{talmor2019olmpics} and \citet{Kassner2020ArePL} extensively use template-based generation. {Why this is a problem?} 

In our %the present 
work, the NEG-136-SIMP and ROLE-88 datasets are dramatically extended. For each of them, we follow the original dataset collection method \cite{fischler1983brain,chow2016bag}, with the exception of N400 amplitude (requires electroencephalography) and cloze probability studies on humans \cite{Federmeier1999ARB}. To explore different approaches to data extension, we extended negation dataset using two methods 1) a template-based %method, 
and 2) using GPT3\footnote{We use \texttt{text-davinci-002} version of GPT3} %including evaluation and dataset generation} 
with human-in-the-loop. For ROLE, we only used GPT3 to extend the dataset, as no additional role categories were available in original source paper for this data \cite{chow2016bag}.
% OpenAI API.

%commented to make up for the page limit
%Our methods allow us to easily increase the sizes of ROLE-88, NEG-136 to 1500 sentences each. 17 fold and 11 fold respectively.

% For template-based generation, we use the original source of categories and subcategories from \citet{Battig1969CategoryNO} and generate data points using a template, increasing the dataset size from 18 to 770 sentence pairs (1540 sentences). To extend negation data via GPT3, we utilize
% the GPT3-davinci 175B API with
% few-shot prompting and human verification to produce 750 sentence pairs (1500 sentences).
% ROLE-88 is extended in a similar way from 88 to 750 sentence pairs.
% To extend ROLE-88, we use GPT3 API in a similar manner to generate 750 new sentence pairs.
% We extend ROLE-88 

%\todo{A note that GPT3 generation allows us to produce arguably more diverse examples than mechanical turkers. But how to phrase this?}

% \todo{finish this}.

To understand how well language models perform on these extended datasets, we evaluated 22 models, including GPT3,
% newly extended datasets by
following the methodology from \citet{Lialin2022LifeAB}. Compared to the original test sets, we see a significant drop (up to 57\%) in accuracy for both Role and Negation tasks. At the same time
% , all models except ALBERT-v2-base, T5-large, and GPT2-base,
most models show higher sensitivity to negation compared to the original dataset. Finally, while GPT3 has \textbf{generated all of the examples} in ROLE-1500, it is only able to predict the correct answer in \textbf{24.6\% cases} (top-5 accuracy).
% ALBERT-v1-xxlarge and ALBERT-v2-xxlarge surpass GPT3 by 3.9\% and 4.6\%, respectively.
ALBERT-v2-xxlarge surpasses GPT3 by 4.6\%.

%ALBERT-xxlarge both version surpasses GPT3 by around 4\%

% \begin{enumerate}
%     \item 
% \end{enumerate}

% In this work, we demonstrate that large language models are capable of generating training examples for ROLE-88 \cite{chow2016AM} dataset. \citet{ettinger2020bert} and \cite{Lialin2022LifeAB} demonstrated that this dataset is extremely chllenging for currently existing models, even at large scale. In this paper we show that the largest GPT3 (175B, davinchi-v2) \cite{brown2020language_gpt3} is only capable of solving it in THISMANY cases, however, it can produce valid training examples in THISMANY cases. More that that, we show that training on unfiltered generated examples can make the model solve these tasks with a high accuracy.

\section{Related Work}
Recent research has shown that LLMs are capable of generating labeled data \cite{Anaby2020,Papanikolaou2020,kumar2020,Meng2020,Biswesh2020,Yiben2020,li2022systematicity,wu2022generating}.
Most previous studies used GPT or GPT2 for dataset extension \cite{datagenSchick2010,Gao2022gpt2,Whitfield2021,Anaby2020}.
%\citet{datagenSchick2010} and \citet{Gao2022gpt2} used GPT2-XL; \citet{Whitfield2021} and \citet{Anaby2019} used GPT to generate data points
%
\citet{Smith2022} attempted to generate labels for the unlabelled dataset using GPT3. In our work, we generate the entire dataset, rather than just the labels. \citet{Bonifacio2022gpt3} used GPT3 to generate questions,  sampling from 100k documents to create the prompts. 
%In contrast, in the present work, existing datasets are too small to sample from. 
\citet{Han2021gpt3translation} and  \citet{Liu2022gpt3nli} prompted GPT3 to generate synthetic translation and NLI datasets, respectively. 



\citet{Lialin2022LifeAB} and \citet{ettinger2020bert} evaluated language models on smaller datasets for negation and role reversal. We extend these datasets to around 1500 data points and evaluate 22 models, including GPT3. To our knowledge, our work is the first to extend psycholinguistic datasets 
%sing GPT3 
and use it to evaluate an extended set of models. 

%\todo{\paragraph{Large language models} write this section}

%\todo{\paragraph{Prompting}write this section}

%\todo{\paragraph{Probing tasks} Some stuff about probing and then we'll have another paragraph that says that we're different from all the people. Should also cite the "step-by-step paper here". This work shows that probing tasks can miss some capabilities of pre-trained models. More that that, we show that a large generative model can produce valid training examples that that tuning the model on them can make it solve this task with a high accuracy.}


\section{Data generation}
\subsection{Negation Dataset: NEG-1500-SIMP}
% What does original data look like?
The existing negation dataset NEG-136-SIMP from \citet{ettinger2020bert} consists of 18 sentence pairs. 
%The existing negation dataset from \citet{ettinger2020bert} is called NEG-136-SIMP consisting of 18 pairs of sentences.
Each pair is made of one affirmative and one negated sentence e.g. the sentences ``A robin is a bird'' (affirmative) and ``A robin is not a tree'' (negated) form a pair. % How do we generate new samples? state the rules
We extend this dataset using two methods: template-based and generation-based. By employing both methods, we could gauge the potential strengths and limitations inherent to each method, which we discuss in Section \ref{results}. We create 770 sentence pairs with the template-based method and generate 750 pairs using GPT3. We refer to these datasets as NEG-1500-SIMP-TEMP and NEG-1500-SIMP-GEN, respectively.

%\vspace{-3.5pt}
\paragraph{NEG-1500-SIMP-TEMP} Each pair in the original dataset follows a template. For affirmative sentences, the template is ``\emph{A/An \{subject\} is a/an \{object\}}''. %For negated sentences, 
Its negated version is ``\emph{A/An \{subject\} is not a/an \{another object\}}''. \citet{Battig1969CategoryNO} and \citet{fischler1983brain} 
%also provide
%provide these templates along with 
provide a template and a list of objects (e.g., robin, 
%lily, 
pine) and the corresponding categories (e.g., bird, 
%flower, 
tree) which are used to generate samples %can be used to generate from these templates.
\footnote{\citet{fischler1983brain} refers to these as ``subjects'' and ''objects'', respectively.}.
For instance, the category, ``bird'' in the example, ``A robin is a bird'' is replaced with another category (``tree'') to generate the negated example ``A robin is not a tree''.
%For example, in the sentence pair, ``A robin is a bird'' and ``A robin is not a tree'', ``robin'' is classified as a `` bird'', which changes to another, different category (``tree'') in the negated example.
%sentence however in the negation, the object changes to a different category ``tree''.

% Different methods we tried?
We experimented with using WordNet to generate from this template, but found that it required a careful curation of hypernym hierarchies. Since our goal was to reduce human effort and cost, we decided against it. We used a template from \citet{fischler1983brain} along with the categories and subcategories listed in \citet{Battig1969CategoryNO} to create 770 sentence pairs. Similar to \citet{ettinger2020bert}, we did not use multi-word category names.

%\vspace{-3.5pt}
\paragraph{NEG-1500-SIMP-GEN}
We use human-in-the-loop and few-shot prompted GPT3-text-davinci-002 with default parameters, to generate 750 pairs (1500 sentences). Each GPT3 prompt consists of an instruction and four randomly selected in-context examples. The cost of generating the dataset is around \$30. An example of the prompt is shown in the appendix~\ref{gpt3-prompt}. After generating samples from GPT3, the dataset was manually cleaned to filter out poorly generated examples. Details about manual filtering in mentioned in Appendix ~\ref{manual-cleaning-neg1500simp}.


%\footnote{Temperature set to 1, maximum tokens 150 and Top P set to 1. We tuned hyperparameters by manually evaluating the output and selecting values that were more likely to produce the desired results based on the specifications in the original NEG and ROLE dataset papers. }. 

%Another way we tried extending negation dataset was by using 
%We generated 1500 sentences (750 pairs) using GPT3 OpenAI API. We prompted GPT3 da-vinci model with an instruction and four in-context examples. The temperature was set to 1 and maximum tokens to 150. The four in-context pairs were chosen randomly from the original dataset NEG-136-SIMP. Example prompts are given in Appendix~\ref{gpt3-prompt}. The generation process was followed by manual cleaning to filter out poorly generated examples. The details on manual filtering are given in Appendix ~\ref{manual-cleaning-neg1500simp}.

%We generated 750 pairs (1500 samples) and call this dataset NEG-1500-SIMP-GEN. 
%An example of the prompt is given in Appendix~\ref{gpt3-prompt}.

% manual cleaning

%As NEG-1500-SIMP-TEMP was generated using a pre-defined template, it didn't require data cleaning however GPT3 generated samples had many mistakes and were manually filtered. 


% data analysis
% Appendix~\ref{toptarget} shows top 20 categories in the new negation datasets. NEG-1500-SIMP-GEN has almost three times more examples in the ``animal'' category than ``tree'' or ``drink''. The distribution is more skewed compared to the template-based dataset. All the categories from the original dataset NEG-136-SIMP are represented in the top 20 (by frequency) categories in NEG-1500-SIMP-GEN (except ``insect'').  However, only four out of nine categories from the original data are present in the top 20 most frequent categories in the template-generated NEG-1500-SIMP-TEMP.

We analyzed the word distribution for the extended datasets and found that for NEG-1500-SIMP-GEN, few categories are more frequent than others, for example, the highest frequent category ``animal'' has three times more examples than the lowest frequent category ``tree''. This difference is 1.5 times in NEG-1500-SIMP-TEMP. Appendix~\ref{toptarget} show the top 20 categories for all datasets.

\subsection{Role-reversal Dataset: ROLE-1500}

% what was the original dataset?
The original ROLE-88 dataset \cite{ettinger2020bert,chow2016bag} is a role reversal dataset consisting 88 sentences (44 sentence pairs). Here is an example of a sentence pair:  \emph{``The librarian documented which journalist the celebrities had avoided.''
``The librarian documented which celebrities the journalist had interviewed''}. The first sentence has two words representing roles (here: journalist, celebrities), which are reversed in the second sentence. The target verb (the last verb in the sentence) is always preceded by the auxiliary ``had''. This dataset was created to observe the effect of role reversal on the target verb. We notice that all of the role words represent human roles (chef, worker, etc.) or animals (whale, dog, etc.). There were some pairs where the role reversal didn't change the target word, but they were semantically correct. % e.g. hired/hired

% methods we tried?
%We couldn't use WordNET for this task as the rules were not as simple as negation dataset, therefore 

% We use method same as NEG-1500-SIMP to generate ROLE-1500 but with temperature 0.64. 

%We use human-in-the-loop and few-shot prompted GPT3 with the above principles to generate 750 pairs (1500 sentences), to approximately 18 times the size of the original dataset. The cost of generating this dataset, which we will refer to as ROLE-1500, is \$25. Each GPT3 prompt consists of an instruction and four randomly selected in-context examples. We used GPT3-davinci with temperature 0.64, maximum tokens 100 and Top P set to 1. An example of the prompt is shown in the appendix~\ref{gpt3-prompt}. After generating samples from GPT3, the dataset was manually cleaned. Details about manual filtering in mentioned in Appendix ~\ref{manual-cleaning-role1500}.

% changes
To extend ROLE dataset, we used the same method as NEG-1500-SIMP-GEN and generated %750 pairs 
1500 sentences with temperature set to 0.64 \footnote{We set Hyperparameters by manually evaluating the output and selecting values that produced samples close to the specifications mentioned in the original dataset papers.}. We call this new dataset as ROLE-1500 and cost of generating it is \$25. %The cost of generating this dataset, which we will refer to as ROLE-1500, is \$25.
After generating samples from GPT3, the dataset was manually cleaned. An example of the prompt, details on data filtering and word distribution for ROLE-1500 is provided in the Appendix ~\ref{gpt3-prompt}, ~\ref{manual-cleaning-role1500}, and ~\ref{toptarget} respectively.  Word distribution analysis in ROLE-1500 revealed a three-fold difference between the highest and lowest frequency categories, similar to the findings in NEG-1500-SIMP-GEN.


%An example of the prompt, is shown in the appendix~\ref{gpt3-prompt}. After generating samples from GPT3, the dataset was manually cleaned. Details about manual filtering in mentioned in Appendix ~\ref{manual-cleaning-role1500}. Word distribution analysis in ROLE-1500 revealed a three-fold difference between the highest and lowest frequency categories, similar to the findings in NEG-1500-SIMP-GEN.

%Appendix ~\ref{toptarget} shows top 20 target verbs in ROLE-88 and ROLE-1500. Except four, all of the top 20 verbs are common in both datasets.

\section{Evaluation on Extended Datasets}
% what are we doing here?
Following methodology from \citet{Lialin2022LifeAB}, we evaluated 22 models on the newly created negation and role reversal data (Figure \ref{tab:accuracy-top5}).
% The models include different sizes of BERT, RoBERTa, ALBERT, DistilBERT, T5, GPT2, and GPT3 \cite{devlin2018bert,liu2019roberta,sanh2019distilbert,lan2019albert,raffel2019exploring,radford2019language,brown2020language_gpt3} in a zero-shot setting. 
% explain lialin 2022 method
Both negation and role reversal tasks were first converted into a masked language modeling task, where
% target word (
the category (the final verb) was replaced with a mask token.
% ,\footnote{``[MASK]'' for BERT, DistilBERT and ALBERT, ``<mask> .'' for for RoBERTa, and ``<extra\_id\_0>'' for T5.} and  
%For BERT, DistilBERT and ALBERT, the target word (the category or the final verb) was replaced with a mask ``[MASK]''. For RoBERTa and T5, it was replaced with ``<mask> .'' and ``<extra\_id\_0>'', respectively. 
% the model had to predict the masked word.
For GPT2 and GPT3, the task was converted into a causal language modeling task, where the target was removed, and the model had to predict the target word. The responses of the models were evaluated against the true target.

% gpt3
For GPT3, we also performed zero-shot evaluation with two prompts: with and without instructions pre-pended to the input sentence (see Appendix ~\ref{gpt3-prompt}). We used the GPT3-text-davinci-002 model via OpenAI API with the default parameters with max\_tokens as 1. GPT3 response was evaluated against gold label.

%--------------------TABLE START-----------------------
\begingroup
\begin{table*}
\centering
\footnotesize
%\setlength{\tabcolsep}{-1 pt}
\addtolength{\tabcolsep}{-2.5pt} % reduce space by -4pt
\begin{tabular}{ l | c c c | c c c | c c}
\toprule
& \thead{ROLE-88} & \thead{NEG-136\\SIMP(Aff)} & \thead{NEG-136\\Sensitivity} & \thead{ROLE-\\1500} & \thead{NEG-1500\\SIMP\\TEMP(Aff)}  & \thead{NEG-1500\\SIMP\\GEN(Aff)} & \thead{NEG-1500\\SIMP-TEMP\\ Sensitivity} & \thead{NEG-1500\\SIMP-GEN\\ Sensitivity} \\
\midrule
        $\mathrm{BERT}_\mathrm{base}$  & 27.3 & \bf{100.0} & 16.7 & 20.3 & 58.4 & 55.3 & 53.5 & 35.9\\ 
        $\mathrm{BERT}_\mathrm{large}$ & 37.5 & \bf{100.0} & 33.3 & 21.5 & 65.1 & 53.8 & 53.5 & 40.3 \\
        $\mathrm{RoBERTa}_\mathrm{base}$  & 46.6 & 94.4 & 66.7 & 23.0  & 62.1 & 44.0 & 64.4 & 71.5 \\
        $\mathrm{RoBERTa}_\mathrm{large}$ & \bf{55.7} & 94.4 & 50.0 & 26.1 & 63.4 & 53.7 & 64.5 & 69.5 \\ 
        $\mathrm{DistilBERT}_\mathrm{base}$  & 28.4 & 94.4 &27.8 & 19.3 & 57.3 & 52.8 & 44.7 & 41.5 \\
        % $\mathrm{AlBERTv1}_\mathrm{base}$ & 17.1 & 72.2 &22.2 & 10.4 & 37.1 & 36.4 & 40.0 & 35.6 \\
        % %$\mathrm{AlBERTv1}_\mathrm{large}$  & 26.1 & 83.3 & 22.2 & 17.4 & 48.4 & 42.4 & 38.6 & 32.9 \\
        % $\mathrm{AlBERTv1}_\mathrm{xlarge}$  & 34.1 & 55.5 & 55.6 & 19.5 & 22.3 & 26.0 & 77.0 & 62.5 \\
        % $\mathrm{AlBERTv1}_\mathrm{xxlarge}$  &  53.4 & 72.2 & 55.6 & 28.5 & 38.7 & 39.3 & 59.9 & 61.7\\
        $\mathrm{AlBERTv2}_\mathrm{base}$  & 26.1 & 33.3 & 38.9 & 15.3 & 10.0 & 11.7 & 37.3 & 35.9\\
        %$\mathrm{AlBERTv2}_\mathrm{large}$  & 29.5 & 83.3 & 22.2 & 18.8 & 36.6 & 36.2 & 31.7 & 33.1 \\
        $\mathrm{AlBERTv2}_\mathrm{xlarge}$ & 37.5 & 94.4 & 27.8 & 21.1 & 40.4 & 47.8 & 52.7 & 51.1 \\
        $\mathrm{AlBERTv2}_\mathrm{xxlarge}$ &  50.0 & \bf{100.0} & 44.4 & \bf{29.0} & 42.9 & 45.3 & 55.7 & 61.5 \\
        %$\mathrm{T5}_\mathrm{small}$  & 9.1 & 44.4 & 0.0 & 5.8 & 33.6 & 25.3 & 16.8 & 19.6 \\
        %$\mathrm{T5}_\mathrm{base}$ & 27.3 & 88.9 & 27.8 & 14.8 & 58.2 & 45.1 & 46.5 & 33.5\\
        $\mathrm{T5}_\mathrm{large}$  & 36.4 & 94.4 & 50.0 & 18.2 & 60.4 & 49.8 & 44.0 & 0.0\\
        $\mathrm{T5}_\mathrm{xl}$ &   44.3 & 83.3 & 66.7 & 21.5 & 60.9 &  60.9 &  68.2 & 70.0 \\
        $\mathrm{GPT2}_\mathrm{base}$  &  0.0 & 0.0 & 66.7 & 11.2 & 48.3 & 37.7 & 60.4 & 56.4\\
        %$\mathrm{GPT2}_\mathrm{medium}$ & 0.0 & 0.0 & 50.0 & 16.4 & 61.4 & 46.9 & 53.1 & 60.7\\
        %$\mathrm{GPT2}_\mathrm{large}$  & 0.0 & 0.0 & 38.9 & 16.8 & 61.7 & 51.7 & 57.9 & 69.2 \\
        $\mathrm{GPT2}_\mathrm{xl}$ & 0.0 & 0.0 & 44.4 & 18.8 & 63.6 & 52.8 & 59.0 & 71.9 \\
        $\mathrm{GPT3}$ & 44.4 & 94.4 & \bf{100.0} & 24.6 & \bf{65.9} & \bf{63.3} & \bf{100.0} & \bf{100.0} \\
        $\mathrm{GPT3}_\mathrm{prompt}$ & 38.6 & 72.2 & \bf{100.0} & 24.4 & 55.9 & 55.2 & \bf{100.0} & \bf{100.0}\\
        \bottomrule
\end{tabular}
\caption{Zero-shot top-5 word prediction accuracy and sensitivity (top-5 over the whole vocabulary).
%Top-5 is selected over the whole vocabulary. 
ROLE-88 and NEG-136 are from \citet{Lialin2022LifeAB}. ROLE-1500 and NEG-1500 are the new datasets. The best result for each task is in bold. ``SIMP'' stands for simple, ``prompt'' stands for prompting(adding instruction). The negation task is evaluated in the affirmative form (\textit{Aff}).  Sensitivity is the percentage of sentence pairs for which the top-1 prediction changed. See Appendix \ref{full-results-section} for accuracy and sensitivity of all models on extended datasets.
}
\label{tab:accuracy-top5}
\end{table*}
\endgroup
%--------------------TABLE END-----------------------

Our evaluation metric is the top-5 prediction accuracy, following \citet{ettinger2020bert}. It is the percentage of the model responses where the gold label is among the top five predictions from the model. Table \ref{tab:accuracy-top5} shows the results for the original and extended datasets. 
% commented this for page limit %(ROLE-88, NEG-136-SIMP) and the extended datasets (ROLE-1500, NEG-1500-SIMP-TEMP, NEG-1500-SIMP-GEN).
We also included top 1, 10, and 20 accuracies in Appendix ~\ref{top20accuracy}. 
For the negation dataset, we used model sensitivity as an additional metric. Since we didn't have N400 amplitude and cloze probability for the extended datasets, we defined sensitivity as the percentage of sentence pairs for which the top-1 prediction changed, when ``not'' was added. Table \ref{tab:accuracy-top5} shows the sensitivity result. %gives sensitivity for the original and extended negation datasets. 
Results for all models are shown in Appendix \ref{full-results-section}. We could not compute ROLE-1500 sensitivity, as in some sentence pairs the target word was the same.

To assess the reliability of the new datasets, we employed the methodology proposed by \citet{card-etal-2020-little_power} to evaluate the statistical power of the datasets. Specifically, we used  McNemar's test to assess the top two models on each dataset.  For the ROLE dataset, our primary criterion was accuracy, while for the NEG dataset, we used the accuracy on affirmative examples (as in \citet{ettinger2020bert}). Additionally, we conducted a permutation test to check the statistical significance of the differences for extended datasets. The results are discussed in Section \ref{results}.
%The p-values for the top 2 models (referenced in Table 1) are discussion in the section \ref{results}.}

We validated our new datasets through human evaluation. For this, we randomly selected 100 samples from each of the extended datasets. Each of these sentences was presented to two annotators, who were asked to complete the sentences with a one-word response. The completion was compared against target labels. This is a method analogous to the cloze test used traditionally to gauge human language comprehension. We used Cohen's kappa to compute inter-annotator agreement.
% \cite{ettinger2020bert}.}

%\todo{I think it would be a good idea to compute the power of our datasets following \cite{card-etal-2020-little_power}}
%\todo{Copy the tables from Notion}
\section{Results}
\label{results}


%\vspace{-3.5pt}
\paragraph{Models performance dropped substantially on extended datasets.}
Model performance\footnote{Difference in the model performance is mentioned as the difference in percentage points. For example,  if model A scores 40\% and model B scores 20\%, model B is worse by 20 percentage point and not by 50\%.} dropped by 40-50\% on negation (affirmative-only) and by 20-30\% on role reversal for all models except GPT2. Even top-20 prediction accuracy couldn't reach the performance shown for the original datasets. For NEG-1500-SIMP-TEMP, BERT\footnote{When we mention a model without specifying its size, we refer to the average percentage change for different sizes within that model family used in our experiments. For example, BERT performance will include BERT-base and BERT-large accuracies.}, RoBERTa, DistilBERT and T5 accuracy decreased ~30\% each, while ALBERT-xxlarge-v2 had the biggest drop of 57\%. Compared to NEG-1500-SIMP-TEMP, NEG-1500-SIMP-GEN shows 5-10\% more (absolute) drop in the performance. In ROLE-1500, the performance of BERT, DistilBERT and T5 decreased by about 5-15\% each. RoBERTa and ALBERT showed the highest drop of 23-29\% on this task. Increasing dataset size had a larger effect on model accuracy for negation %(especially NEG-1500-SIMP-GEN), 
than for the role-reversal task.
The models that performed best on the small datasets did not remain in the lead on the extended. For example, in ROLE, RoBERTa-large was the best model on the original dataset, but ALBERT-v2-xxlarge surpassed it on the extended one. For negation, BERT and ALBERT were best originally, but GPT3 surpassed them when the datasets became larger. % (both for template-based and generated data).

\paragraph{GPT3 cannot solve, but can generate such examples.}
While GPT3 is unable to reliably solve these tasks, it is perfectly capable of picking up the pattern and generating valid examples. ROLE-1500 was generated by GPT3, and yet, RoBERTa-large, and %ALBERT-xxlarge-v1 and v2 
ALBERT-xxlarge perform better on it than GPT3. There is a gap of around 4.5\% between the best model and GPT3. Adding instructions to the prompt, didn't change the performance on ROLE-1500, but decreased the accuracy by 8-10\% on negation. Sensitivity to negation remains the same for GPT3 with and without instruction prompts.

\paragraph{GPT3 responses contain variety of mistakes.}
%As mentioned above, approximately 2/3 of the generated ROLE data had to be manually filtered out.
%To extend the ROLE dataset to 1500 sentences, we generated almost 4700 sentences and cleaned them manually. Due to the high rate of duplication, data generation was stopped after 750 pairs. 
%During this process, we observed that 14.3\% of responses were without a pair or were simple sentences. 
Approximately 2/3 of the generated ROLE data was manually filtered out. 14.3\% of responses were single sentences without a pair. %For example, the model generated \emph{``the athlete reported which coach the player had injured,''} but not its pair \emph{``the athlete reported which player the coach had trained''}. 
7.4\% responses were semantically incorrect. 
%Such responses were either removed or edited to match the format. 
Similar kind of errors were filtered out in the negation data as well. GPT3 also generated duplicate entries. 62.5\% of negation data generated with GPT3 were duplicate samples, compared to 32.5\% for the role reversal dataset.

\paragraph{GPT3 generates more diverse examples than the template-based method.}
While GPT-3 provided a 
%dynamic 
way to generate diverse samples, the template-based method ensured consistency and alignment with the original dataset. Our result shows that GPT-3 generated samples offered a variety with 63 unique target labels whereas the template-based method provided controlled variability based on predefined structures with 23 unique target labels. 11 of these target labels are common between both the datasets. The models exhibit similar performance when evaluated on datasets produced by both template as well as model based methods.


\paragraph{Models are more sensitive to negation for extended dataset.}  All models except ALBERT-v2-base, T5-large, and GPT2-base show higher sensitivity to negation on both extended negation datasets compared to the original one. For NEG-1500-SIMP-TEMP, %(template-based dataset) 
the sensitivity for BERT and ALBERT-xl %(v1 and v2)
increased by 36.8\% and 21-25\%, respectively. For RoBERTa-base, T5-large and GPT2, sensitivity to negation dropped by 2.3-6\%. The sensitivity to negation on NEG-1500-SIMP-GEN either increased or remained the same compared to original data for all models, except ALBERT-v2-base, T5-large and GPT2-base. For BERT and RoBERTa the sensitivity increased by almost 20\%. Results demonstrate high levels of negation sensitivity in models like BERT and ALBERT, suggesting that previous findings might have been skewed due to smaller test sets. 

\paragraph{Change in model performance on extended datasets depends on its architecture and size.}
Encoder-only models had the highest performance drop of ~15\% for ROLE-1500 and ~40\% for NEG-1500 (average of template-based and generated negation dataset). In comparison, the seq-to-seq models accuracy decreased by 14\% in ROLE-1500 and 29\% in NEG-1500, while decoder-only models show a gain of ~5\% in ROLE-1500 and ~27\% in NEG-1500. Encoder-only models also demonstrate the highest increase in negative sensitivity, with a gain of 13\% , while seq-to-seq and decoder-only models gains only 1.2\% and 7.4\% respectively. When analyzed across model size, we found models of size around 60M show the highest drop of around 35\% in NEG-1500, while models of size close to 300M experience the highest decrease of 14.6\% in the ROLE dataset. The ~300M size models exhibit the highest gain of 44\% in negativity sensitivity (see tables in Appendix \ref{analysis-model-type}).

\paragraph{New extended datasets are more reliable than original small datasets.}
The power analysis using McNemar's test reveals very low power for original datasets. ROLE-88 has a power of %0.255 
0.26 whereas NEG-136's power is 
%0.014
0.01. For the extended dataset ROLE-1500, the power to differentiate between the top two accuracy models significantly improved to 
%0.721
0.72, and for GPT3-generated NEG-1500-SIMP, the power reached a full 
%1.000
1.00 in distinguishing top models. However, for the template-generated NEG-1500-SIMP, the power remained low: 
%0.043 
0.04 for the top two models and 
%0.230 
0.23 for the top 1 versus top 3. From these results, it is evident that ROLE-1500 and NEG-1500-SIMP-GEN are dramatically more reliable datasets. Specifically, they can distinguish between small effects of approximately 0.03 for ROLE and about 0.15 for NEG-1500-SIMP-GEN (minimum detectable effect, MDE).
%Note that 0.15 is the smallest difference we could find in the real data, with a simulated power for a 0.03 difference in ROLE being 0.933.}

% \textcolor{blue}{The p-values for the top 2 models (referenced in Table 1) for ROLE-1500 is 0.0124 and for NEG-1500-SIMP-TEMP and NEG-1500-SIMP-GEN, it is 0.2206 and 0.0002 respectively. It shows that there is a statistically significant difference between the models on ROLE-1500 and NEG-1500-SIMP-GEN at the 0.05 significance level. In contrast, the template-generated dataset does not distinguish between the top 2 models.}

The permutation test shows a statistically significant difference between the accuracies of the top-2 models for ROLE-1500 and NEG-1500-SIMP-GEN at a 0.05 significance level. P-values are 0.01 and 0.0002 respectively. In contrast, template generated dataset (NEG-1500-SIMP-TEMP) does not show statistically significant accuracies and fails the test with a p-value of 0.22.


%We also did manual evaluation of ALBERT-xxlarge-v2 predictions, the model with the highest performance drop. We noticed that in NEG-1500, it accurately predicted simple categories like ``animals'',``trees'' but struggled with complex categories such as ``devices'', "minerals". In the ROLE dataset, it correctly predicted for roles like ``journalist-athlete'', ``writer-critic'' but struggled with roles like ``zookeeper-animal'', ``clown-birthday boy''.

\paragraph{Human performance surpasses all model performance.}
From human cloze test on ROLE-1500 and NEG-1500-SIMP(TEMP and GEN), we observed that human performance consistently exceeded model performance across all datasets. Specifically, for NEG-1500-SIMP-TEMP, human evaluation resulted in a top-1 accuracy of 58.5\%, whereas the top-performing model, T5-xl, achieved about 40\%.
In the case of NEG-1500-SIMP-GEN, the human evaluation yielded an accuracy of 45.5\%, 5.8\% higher than the leading model, T5-xl. For ROLE, human performance (10\%) is better than all of the model performances except ALBERT-xxlarge (v1 and v2). Human evaluation results are included in Tables \ref{fig:neg-1500-simp-temp}, \ref{tab:neg_accuracy_top20} and \ref{tab:role_accuracy_top20}. Inter-annotator agreement for ROLE-1500 is 0.07, whereas for NEG-1500-SIMP-TEMP and NEG-1500-SIMP-GEN, it is 0.50 and 0.45 respectively.
%We appreciate the additional external validation offered by N400 human performance. It's worth noting that the authors of the original datasets relied on data from established psycholinguistic studies rather than replicating these complex and resource-intensive experiments. Given that both cloze and N400 human results are available for the original data, it's reasonable to infer a level of generalizability to the extended datasets. The underlying linguistic phenomena and structures being probed remain consistent, thus lending credence to the notion that human performance metrics on the original data would, in all likelihood, be comparable if reproduced on the new data.
%We believe our cloze test results offer some evidence for the external validity of our extended datasets in capturing non-expert linguistic behavior. We will conduct similar human evaluations for the ROLE datasets in the finalized version of our paper. We hope this allays your concerns about the external validation of our datasets.}

\section{Conclusion}
We provide a new resource that dramatically extends existing probing data for negation and role reversal. The psycholinguistic datasets NEG-136-SIMP and ROLE-88 are extended to more reliable and large datasets, each with 1500 data points. We evaluate 22 models using the new data, observing that the absolute accuracy drops for most models on both tasks. However, most models do show an increased sensitivity to negation. Strikingly, as seen in the role reversal task, we show that GPT3 may be capable of generating the data for a task while failing to show top performance on it.


%extending the role dataset, fails to perform best on it. 

\section*{Limitations}
The current work has several limitations. The study did not include N400 amplitude. Another limitation is the smaller size of the original datasets. As we had a limited number of in-context samples that were drawn from original datasets, there was a limitation on the number of new data points we could generate. Additionally, the cost of generating samples with GPT3 was another limiting factor. Lastly, the frequency distribution of the categories in the new datasets is not balanced, which may introduce some bias in model evaluation. This imbalance exists in the original datasets too. 

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% OLD LIMITATION OCT 2023 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \textcolor{red}{The current work has several limitations. Firstly, the study did not include the N400 amplitude and the cloze probability to generate samples and was more based on a large language model picking up the pattern and generating samples. Another limitation is the constraint on the number of samples generated using the model-based method. We observed that the fewer samples we have, the more duplication we get in GPT3 responses which caps on how many datapoints we can generate with a limited number of original samples used via in-context learning. %Additionally, generating samples with GPT3 is expensive. 
% Additionally, the cost of generating samples with GPT3 was a limiting factor on the amount of examples generated for the new datasets.
% We also observe that there is an imbalance between the most represented and least represented categories in the extended datasets, which may introduce some biases in model evaluation. This imbalance is present in the original datasets too.}

%%%%%%%%%% OLD LIMITATION SECTION %%%%%%%%%%
%The current method did not include the N400 amplitude and the cloze probability to generate samples and was more based on a large language model picking up the pattern and generating samples. The other limitation was the diversity of datapoints generated using existing small dataset. We observed that there is a cap on how many datapoints we can generate with a limited number of original samples used via in-context learning. The fewer samples we have the more duplication we get in GPT3 responses. We also need to be careful in generating samples, as GPT3 responses can be expensive, especially when using more in-context examples.


% Therefore to extend the dataset further, we will need more GPT3 open AI credits and more in-context examples. 


% EMNLP 2022 requires all submissions to have a section titled ``Limitations'', for discussing the limitations of the paper as a complement to the discussion of strengths in the main text. This section should occur after the conclusion, but before the references. It will not count towards the page limit.  The discussion of limitations is mandatory. Papers without a limitation section will be desk-rejected without review. ARR-reviewed papers that did not include ``Limitations'' section in their prior submission, should submit a PDF with such a section together with their EMNLP 2022 submission.While we are open to different types of limitations, just mentioning that a set of results have been shown for English only probably does not reflect what we expect. Mentioning that the method works mostly for languages with limited morphology, like English, is a much better alternative. In addition, limitations such as low scalability to long text, the requirement of large GPU resources, or other things that inspire crucial further investigation are welcome.

\section*{Ethics Statement}
Using large closed-source language models to generate evaluation data, while highly effective, should be approached with caution.
First, neural networks of hundreds of billions of parameters are computationally expensive to infer and potential carbon dioxide emissions should be taken into consideration.
Second, while API access to such models allows to avoid many technical challenges, especially having enough resources to inference large models, it comes with limitations.
For example, GPT3 can only return the logprops of at most five top tokens over the vocabulary. Also, the API provides no control over the random seed used for sampling reducing the potential reprehensibility of the research.
Finally, without the direct access to the model weights, there is no guarantee that this version of the model will be always accessible to researchers in the future and won't be restricted, modified, deleted, or lost.

%Scientific work published at EMNLP 2022 must comply with the \href{https://www.aclweb.org/portal/content/acl-code-ethics}{ACL Ethics Policy}. We encourage all authors to include an explicit ethics statement on the broader impact of the work, or other ethical considerations after the conclusion but before the references. The ethics statement will not count toward the page limit (8 pages for long, 4 pages for short papers).

\section*{Acknowledgment}
This project is funded in part by an NSF CAREER award to Anna Rumshisky (IIS-1652742). We would like to express our gratitude to Vijeta Deshpande and Sherin Muckatira for participating in human evaluation.

% Entries for the entire Anthology, followed by custom entries
\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}

\clearpage
\appendix
 \section{GPT3 prompt}
 \label{gpt3-prompt}
 \subsection{ROLE-1500 generation prompt}
An example prompt for generating ROLE-1500 dataset is given below.
The roles are colored orange and blue, whereas the target word is highlighted in green:

% \todo{figure out how to make it look good}
% GPT3 prompt-

\emph{The task is to reverse the role in the sentences. Generate more sentence like this:}

\emph{The journalist investigated which {\color{cyan}athlete} the {\color{orange}team} had {\color{green}recruited},} \emph{The journalist investigated which {\color{orange}team} the {\color{cyan}athlete} had {\color{green}joined},}

\emph{The detective interviewed which {\color{cyan}witness} the  {\color{orange}doctor} had {\color{green}suspected}, The detective interviewed which {\color{orange}doctor} the {\color{cyan}witness} had {\color{green}seen}.}

\emph{The teacher lectured which {\color{cyan}student} the  {\color{orange}class} had {\color{green}ignored}, The teacher lectured which {\color{orange}class} the {\color{cyan}student} had {\color{green}left},}

\emph{The police reported which {\color{cyan}criminal} the {\color{orange}witness} had {\color{green}described}, 
The police reported which {\color{orange}witness} the {\color{cyan}criminal} had {\color{green}robbed},}

\emph{The doctor treated which {\color{cyan}patient} the {\color{orange}nurse} had {\color{green}examined}, The doctor treated which {\color{orange}nurse} the {\color{cyan}patient} had {\color{green}injured},}
\\

 \subsection{NEG-1500-SIMP-GEN generation prompt}
An example prompt for generating NEG-1500-SIMP-GEN dataset is given below.\\

\emph{``The task is to generate affirmative sentences and its negation. The object of the sentence should be a hypernym of the subject of the sentence. Generate more sentence pairs like these: }

 \emph{A robin is a bird, A robin is not a tree,}
 
 \emph{An oak is a tree, An oak is not a flower,}
 
 \emph{A carrot is a vegetable, A carrot is not a bird,}
 
 \emph{A hammer is a tool, A hammer is not a tree,}''

\subsection{ROLE-1500 evaluation prompts with and without instructions}
Prompt with instruction for ROLE-1500: 

\emph{``The goal is to complete the given sentence with one English word. Avoid punctuation or a new line or space. The librarian documented which journalist the celebrities had''}. 
\\

The prompt without instruction: \emph{``The librarian documented which journalist the celebrities had''}.
The model predicts the next word in sentence. 
\\
Instruction is same for ROLE-1500 and NEG-1500-SIMP-GEN. Only the in-context example changes.
\\

\section{Manual cleaning of the datasets}
\subsection{NEG-1500-SIMP}
\label{manual-cleaning-neg1500simp}
For NEG-1500-SIMP-GEN, to get 1500 cleaned samples, we generated 12000 sentences. 87.5\% of the responses were rejected as they were a) duplicates (62.5\%) b) empty lines (15\%) c) only negated sentences (8.75\%) d) others (1.25\%). Others include sentences like ``A toy is a toy'' and ``A toy is an object'', as well as objects with multiple words and semantically wrong sentences (e.g., ``A flower is a rose'', ``A cloud is a weather''). The cost of generating NEG-SIMP-1500-GEN was \$35.

\subsection{ROLE-1500}
\label{manual-cleaning-role1500}
After generating GPT3 responses to these prompts, the samples were manually cleaned to get 1500 sentences (750 sentence pairs). We generated 4700 sentences (including empty, partial and no-pair sentences), out of which 68\% were removed, as a) 32.5\% were duplicates, b) 14.3\% missed on getting a pair or were simple sentences, c) 8.5\% were empty lines, d) 7.4\% were semantically wrong sentences or had a wrong role reversal (e.g., ``The camper reported which book the girl had eaten''), e) 5.3\% were repeating instructions or partial sentences. 
%
In some instances, generated examples included some repetition of the role nouns present in the in-context examples.
%Note that often the generated sentence pairs included a combination of the in-context examples presented to GPT3 via prompt.
%

\section{Rules to create NEG-1500-SIMP-GEN}
\label{rules}
An affirmative sentence and a negation sentence make a pair. Affirmative sentences follow the format of ``{subject} is an {object}'' whereas its negation form is ``{subject} is not an {object}''. Affirmative sentences can be, for example \emph{``Robin is a bird''} or \emph{``Robin is an animal''}, the subject word is \emph{``Robin''}, the object word is \emph{``bird''} and its immediate superordinate category name is \emph{``animal''}. The negation for any of these two affirmative sentences can be \emph{``Robin is not a plant'' or ``Robin is not a tree''}. The target completion ( e.g. \emph{``plant'' or ``tree''}) has to be an object or superordinate word from another category. Figure ~\ref{fig:neg} in the Appendix ~\ref{fig:neg} shows two categories (Animal and Plant) together with its respective subject and object words \cite{Battig1969CategoryNO}.

\begin{figure*}
    \centering
    \includegraphics[width=0.7\linewidth]{images/data-extention-neg-simp-drawio.pdf}
    \caption{Sentence subject word (Robin). Affirmative sentence completion are in green - object word(Bird) and super ordinate category name(Animal). Negative sentence completion are in red - object word(Tree) and super ordinate category name(Plant).  \cite{Battig1969CategoryNO}}
    \label{fig:neg}
\end{figure*}

\section{Top 20 target words for all datasets}
\label{toptarget}
Figure ~\ref{fig:neg-136-simp} and ~\ref{fig:role-88} show top 20 object words for original datasets NEG-136-SIMP and ROLE-88.  Figure ~\ref{fig:neg-1500-simp-temp}, ~\ref{fig:neg-1500-simp} and ~\ref{fig:role-1500} depict top 20 object words for original new extended datasets. Y axis represents the number of times the target words. NEG-136-SIMP has less than 20 categories, therefore all of them has been shown in the figure  ~\ref{fig:neg-136-simp}.

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{images/neg-136-simp.pdf}
    \caption{Top categories for NEG-136-SIMP}
    \label{fig:neg-136-simp}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{images/neg-1500-simp.pdf}
    \caption{Top 20 categories for NEG-1500-SIMP-TEMP}
    \label{fig:neg-1500-simp-temp}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{images/neg-1500-simp-gpt3.pdf}
    \caption{Top 20 categories for NEG-1500-SIMP-GEN}
    \label{fig:neg-1500-simp}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{images/role-1500.pdf}
    \caption{Top 20 categories for ROLE-1500}
    \label{fig:role-1500}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{images/role-88.pdf}
    \caption{Top 20 target words for ROLE-88}
    \label{fig:role-88}
\end{figure*}



\section{Result for all models}
Table ~\ref{tab:full=table-accuracy-top5} shows the top five accuracy for all the models.
%%%%%%% Full Table
\label{full-results-section}
\begingroup
\begin{table*}
\centering
\footnotesize
%\setlength{\tabcolsep}{-1 pt}
\addtolength{\tabcolsep}{-2.5pt} % reduce space by -4pt
\begin{tabular}{ l | c c c | c c c | c c}
\toprule
& \thead{ROLE-88} & \thead{NEG-136\\SIMP(Aff)} & \thead{NEG-136\\Sensitivity} & \thead{ROLE-\\1500} & \thead{NEG-1500\\SIMP\\TEMP(Aff)}  & \thead{NEG-1500\\SIMP\\GEN(Aff)} & \thead{NEG-1500\\SIMP-TEMP\\ Sensitivity} & \thead{NEG-1500\\SIMP-GEN\\ Sensitivity} \\
\midrule
        $\mathrm{BERT}_\mathrm{base}$  & 27.3 & \bf{100.0} & 16.7 & 20.3 & 58.4 & 55.3 & 53.5 & 35.9\\ 
        $\mathrm{BERT}_\mathrm{large}$ & 37.5 & \bf{100.0} & 33.3 & 21.5 & 65.1 & 53.8 & 53.5 & 40.3 \\
        $\mathrm{RoBERTa}_\mathrm{base}$  & 46.6 & 94.4 & 66.7 & 23.0  & 62.1 & 44.0 & 64.4 & 71.5 \\
        $\mathrm{RoBERTa}_\mathrm{large}$ & \bf{55.7} & 94.4 & 50.0 & 26.1 & 63.4 & 53.7 & 64.5 & 69.5 \\ 
        $\mathrm{DistilBERT}_\mathrm{base}$  & 28.4 & 94.4 &27.8 & 19.3 & 57.3 & 52.8 & 44.7 & 41.5 \\
        $\mathrm{AlBERTv1}_\mathrm{base}$ & 17.1 & 72.2 &22.2 & 10.4 & 37.1 & 36.4 & 40.0 & 35.6 \\
        $\mathrm{AlBERTv1}_\mathrm{large}$  & 26.1 & 83.3 & 22.2 & 17.4 & 48.4 & 42.4 & 38.6 & 32.9 \\
        $\mathrm{AlBERTv1}_\mathrm{xlarge}$  & 34.1 & 55.5 & 55.6 & 19.5 & 22.3 & 26.0 & 77.0 & 62.5 \\
        $\mathrm{AlBERTv1}_\mathrm{xxlarge}$  &  53.4 & 72.2 & 55.6 & 28.5 & 38.7 & 39.3 & 59.9 & 61.7\\
        $\mathrm{AlBERTv2}_\mathrm{base}$  & 26.1 & 33.3 & 38.9 & 15.3 & 10.0 & 11.7 & 37.3 & 35.9\\
        $\mathrm{AlBERTv2}_\mathrm{large}$  & 29.5 & 83.3 & 22.2 & 18.8 & 36.6 & 36.2 & 31.7 & 33.1 \\
        $\mathrm{AlBERTv2}_\mathrm{xlarge}$ & 37.5 & 94.4 & 27.8 & 21.1 & 40.4 & 47.8 & 52.7 & 51.1 \\
        $\mathrm{AlBERTv2}_\mathrm{xxlarge}$ &  50 & \bf{100.0} & 44.4 & \bf{29.0} & 42.9 & 45.3 & 55.7 & 61.5 \\
        $\mathrm{T5}_\mathrm{small}$  & 9.1 & 44.4 & 0.0 & 5.8 & 33.6 & 25.3 & 16.8 & 19.6 \\
        $\mathrm{T5}_\mathrm{base}$ & 27.3 & 88.9 & 27.8 & 14.8 & 58.2 & 45.1 & 46.5 & 33.5\\
        $\mathrm{T5}_\mathrm{large}$  & 36.4 & 94.4 & 50.0 & 18.2 & 60.4 & 49.8 & 44.0 & 0.0\\
        $\mathrm{T5}_\mathrm{xl}$ &   44.3 & 83.3 & 66.7 & 21.5 & 60.9 & 60.9 & 68.2 & 70.0 \\
        $\mathrm{GPT2}_\mathrm{base}$  &  0.0 & 0.0 & 66.7 & 11.2 & 48.3 & 37.7 & 60.4 & 56.4\\
        $\mathrm{GPT2}_\mathrm{medium}$ & 0.0 & 0.0 & 50.0 & 16.4 & 61.4 & 46.9 & 53.1 & 60.7\\
        $\mathrm{GPT2}_\mathrm{large}$  & 0.0 & 0.0 & 38.9 & 16.8 & 61.7 & 51.7 & 57.9 & 69.2 \\
        $\mathrm{GPT2}_\mathrm{xl}$ & 0.0 & 0.0 & 44.4 & 18.8 & 63.6 & 52.8 & 59.0 & 71.9 \\
        $\mathrm{GPT3}$ & 44.4 & 94.4 & \bf{100.0} & 24.6 & \bf{65.9} & \bf{63.3} & \bf{100.0} & \bf{100.0} \\
        $\mathrm{GPT3}_\mathrm{prompt}$ & 38.6 & 72.2 & \bf{100.0} & 24.4 & 55.9 & 55.2 & \bf{100.0} & \bf{100.0}\\
        \bottomrule
\end{tabular}
\caption{Zero-shot top-5 word prediction accuracy and sensitivity (top-5 over the whole vocabulary).
%Top-5 is selected over the whole vocabulary. 
ROLE-88 and NEG-136 are from \citet{Lialin2022LifeAB}. ROLE-1500 and NEG-1500 are the new datasets. The best result for each task is in bold. ``SIMP'' stands for simple, ``prompt'' stands for prompting. The negation task is evaluated in the affirmative form (\textit{Aff}).  Sensitivity is the percentage of sentence pairs for which the top-1 prediction changed.
}
\label{tab:full=table-accuracy-top5}
\end{table*}
\endgroup

%%%%%%%% Full Table

\section{Top 1, 10 and 20 prediction accuracy for all models}
\label{top20accuracy}
Table ~\ref{tab:neg_accuracy_top20} and ~\ref{tab:neg_temp_accuracy_top20} show top 1, 10 and 20 accuracy for new negation datasets. Table ~\ref{tab:role_accuracy_top20} depict top 1, 10 and 20 accuracy for new role reversal dataset. 
\begingroup
\begin{table*}[ht]
\centering
\small
\begin{tabular}{ l | c c c }
\toprule
NEG-1500-SIMP-TEMP & \thead{Top 1} & \thead{Top 10} & \thead{Top 20}  \\
\midrule
        $\mathrm{BERT}_\mathrm{base}$ & 28.5 & 64.7 & 71.4 \\ 
        $\mathrm{BERT}_\mathrm{large}$ & 34.2 & \bf{71.9} & \bf{76.5} \\ 
        $\mathrm{RoBERTa}_\mathrm{base}$ & 22.2 & 68.7 & 73.0 \\
        $\mathrm{RoBERTa}_\mathrm{large}$ & 30 & 69.2 & 74.4 \\ 
        $\mathrm{DistilBERT}_\mathrm{base}$  & 28.6 & 67.8 & 75.6 \\
        $\mathrm{AlBERTv1}_\mathrm{base}$ & 14.3 & 43.9 & 49.5 \\
        $\mathrm{AlBERTv1}_\mathrm{large}$  & 13.5 & 56.9 & 63.3 \\
        $\mathrm{AlBERTv1}_\mathrm{xlarge}$  & 10.3 & 28.0 & 32.6 \\
        $\mathrm{AlBERTv1}_\mathrm{xxlarge}$  & 12.1  & 48.6 & 57.3 \\
        $\mathrm{AlBERTv2}_\mathrm{base}$  & 2.0 & 18.8 &  29.2\\
        $\mathrm{AlBERTv2}_\mathrm{large}$  & 10.6 & 46.8 & 55.6 \\
        $\mathrm{AlBERTv2}_\mathrm{xlarge}$ & 24.7 & 45.2 & 50.0 \\
        $\mathrm{AlBERTv2}_\mathrm{xxlarge}$ & 14.8 & 53.4 & 62.8 \\
        $\mathrm{T5}_\mathrm{small}$  & 1.7 & 43.6 & 51.6 \\
        $\mathrm{T5}_\mathrm{base}$ & 21.4 & 65.6 & 71.3 \\
        $\mathrm{T5}_\mathrm{large}$  & 22.7 & 68.3 & 73.8 \\
        $\mathrm{T5}_\mathrm{xl}$ &  \bf{39.7} & 66.2 & 69.9 \\
        $\mathrm{GPT2}_\mathrm{base}$  &  0.0 & 57.1 &  63.6\\
        $\mathrm{GPT2}_\mathrm{medium}$ & 0.0 & 69.5 & 73.2 \\
        $\mathrm{GPT2}_\mathrm{large}$  & 0.0 & 70.0 &  75.7\\
        $\mathrm{GPT2}_\mathrm{xl}$ & 0.0 & 70.1 & 75.6 \\
        $\mathrm{GPT3}$ & 27.5 & N/A & N/A \\
        $\mathrm{GPT3}_\mathrm{prompt}$ & 21.8 & N/A & N/A  \\
        \midrule
        Human cloze completion & \textbf{58.5} & - & - \\
        \bottomrule
\end{tabular}
\caption{Zero-shot top-1,10 and 20 word prediction accuracy on NEG-1500-SIMP-TEMP. Top-5 is selected over the whole model vocabulary. The best result on each task is highlighted in bold. SIMP stands for simple, TEMP stands for template. Negation tasks are evaluated in the affirmative form (\textit{aff}). GPT3 only produces top 5 predictions. Human cloze completion accuracy is the average accuracy of two annotators.
}
\label{tab:neg_temp_accuracy_top20}
\end{table*}
\endgroup

\begingroup
\begin{table*}[ht]
\centering
\small
\begin{tabular}{ l | c c c }
\toprule
NEG-1500-SIMP-GEN & \thead{Top 1} & \thead{Top 10} & \thead{Top 20}  \\
\midrule
        $\mathrm{BERT}_\mathrm{base}$ & 18.8 & 66.0 & 73.3 \\ 
        $\mathrm{BERT}_\mathrm{large}$ & 22.8 & 64.3 &  72.0 \\ 
        $\mathrm{RoBERTa}_\mathrm{base}$ & 15.4 & 51.6 & 60.1 \\
        $\mathrm{RoBERTa}_\mathrm{large}$ & 24.4 & 61.6  & 71.7  \\ 
        $\mathrm{DistilBERT}_\mathrm{base}$  & 22.5 & 61.9 & 70.5  \\
        $\mathrm{AlBERTv1}_\mathrm{base}$ & 11.2 & 46.0 & 53.6  \\
        $\mathrm{AlBERTv1}_\mathrm{large}$   & 12.9 & 50.5  & 59.6  \\
        $\mathrm{AlBERTv1}_\mathrm{xlarge}$  & 7.2 & 34.4 & 41.6  \\
        $\mathrm{AlBERTv1}_\mathrm{xxlarge}$  & 12.4 & 50.7 & 60.7  \\
        $\mathrm{AlBERTv2}_\mathrm{base}$  & 2.5 & 22.2 & 32.3 \\
        $\mathrm{AlBERTv2}_\mathrm{large}$   & 10.7 & 44.8 & 54.7  \\
        $\mathrm{AlBERTv2}_\mathrm{xlarge}$ & 24.0 & 56.5 & 64.5  \\
        $\mathrm{AlBERTv2}_\mathrm{xxlarge}$ & 15.3 & 55.3 & 54.1  \\
        $\mathrm{T5}_\mathrm{small}$ & 2.9 & 36.3 &  45.6 \\
        $\mathrm{T5}_\mathrm{base}$ & 15.1 & 65.5 & 65.3  \\
        $\mathrm{T5}_\mathrm{large}$ & 15.1 & 60.5 & 68.3  \\
        $\mathrm{T5}_\mathrm{xl}$  & \textbf{39.7} & 66.2 & 69.9  \\
        $\mathrm{GPT2}_\mathrm{base}$ & 16.4 & 48.0 & 60.0 \\
        $\mathrm{GPT2}_\mathrm{medium}$ & 26.1 & 56.1 & 66.9  \\
        $\mathrm{GPT2}_\mathrm{large}$ & 29.3 & 60.7 & 69.6 \\
        $\mathrm{GPT2}_\mathrm{xl}$ & 30.4 & 60.1 & 70.4 \\
        $\mathrm{GPT3}$ & 26.5  & N/A & N/A \\
        $\mathrm{GPT3}_\mathrm{prompt}$ & 24.3  & N/A & N/A  \\
        \midrule
        Human cloze completion & \textbf{45.5} & - & - \\
        \bottomrule
\end{tabular}
\caption{Zero-shot top-1,10 and 20 word prediction accuracy on NEG-1500-SIMP-GEN. Top-5 is selected over the whole model vocabulary. The best result on each task is highlighted in bold. SIMP stands for simple, negation tasks is evaluated in the affirmative form. GPT3 allow only till top 5 predictions. 
}
\label{tab:neg_accuracy_top20}
\end{table*}
\endgroup

\begingroup
\begin{table*}[ht]
\centering
\small
\begin{tabular}{ l | c c c }
\toprule
ROLE-1500 & \thead{Top 1} & \thead{Top 10} & \thead{Top 20}  \\
\midrule
        $\mathrm{BERT}_\mathrm{base}$  & 6.7 & 28.1 & 38.9 \\ 
        $\mathrm{BERT}_\mathrm{large}$ & 9.1 & 30.9 & 40.7 \\ 
        $\mathrm{RoBERTa}_\mathrm{base}$  & 0 & 33.9 & 47.3 \\
        $\mathrm{RoBERTa}_\mathrm{large}$ &  0 & \bf{38.6} & \bf{52} \\ 
        $\mathrm{DistilBERT}_\mathrm{base}$  & 6.5 & 27.3 & 36.9 \\
        $\mathrm{AlBERTv1}_\mathrm{base}$ & 2.8 & 16.2 & 25.3 \\
        $\mathrm{AlBERTv1}_\mathrm{large}$  & 4.8 & 24.2 & 32.7 \\
        $\mathrm{AlBERTv1}_\mathrm{xlarge}$  & 7.2 & 27.3 & 35.5 \\
        $\mathrm{AlBERTv1}_\mathrm{xxlarge}$  &  \bf{12.2} & 37.2 & 45.1 \\
        $\mathrm{AlBERTv2}_\mathrm{base}$  & 6.2 & 22.7 & 29.9 \\
        $\mathrm{AlBERTv2}_\mathrm{large}$  & 5.9 & 27.0 & 36.1 \\
        $\mathrm{AlBERTv2}_\mathrm{xlarge}$ & 8.8 & 29.6 & 37.9 \\
        $\mathrm{AlBERTv2}_\mathrm{xxlarge}$ & 11.6 & 37.1 & 45.1 \\
        $\mathrm{T5}_\mathrm{small}$  & 1.3 & 12.1 & 18.3 \\
        $\mathrm{T5}_\mathrm{base}$ & 4.7 & 21.9 & 28.5 \\
        $\mathrm{T5}_\mathrm{large}$  & 6.2 & 25.3 & 31.3 \\
        $\mathrm{T5}_\mathrm{xl}$ & 7.9  & 29.0 & 36.5 \\
        $\mathrm{GPT2}_\mathrm{base}$  & 0  & 18.9 & 27.1 \\
        $\mathrm{GPT2}_\mathrm{medium}$ & 0 & 25.2 & 36.5 \\
        $\mathrm{GPT2}_\mathrm{large}$  & 0 & 27.0 & 37.7 \\
        $\mathrm{GPT2}_\mathrm{xl}$ & 0 & 29.9 & 38.8 \\
        $\mathrm{GPT3}$ & 7.7 & N/A & N/A \\
        $\mathrm{GPT3}_\mathrm{prompt}$ & 5.7 & N/A & N/A  \\
        \midrule
        Human cloze completion & \textbf{10.0} & - & - \\
      
        \bottomrule
\end{tabular}
\caption{Zero-shot top-1,10 and 20 word prediction accuracy on ROLE-1500. Top-5 is selected over the whole model vocabulary. The best result on each task is highlighted in bold. GPT3 produces only top 5 predictions. 
}
\label{tab:role_accuracy_top20}
\end{table*}


%%%%%%%%%%%%%%%%%%%%%% table for result analysis

\section{Results across model type and model size}
\label{analysis-model-type}
Table ~\ref{tab:model_type} and ~\ref{tab:model_size} show the change in the model accuracy for extended dataset as compared to the original dataset across model type and model size respectively.  NEG-1500 represents the average of NEG-1500-SIMP-TEMP and NEG-1500-SIMP-GEN. We didn't mention 1B and 175B model sensitivity in Table ~\ref{tab:model_size} as they were 100\% in original and extended datasets, therefore the difference is zero.
\begingroup
\begin{table*}[ht]
\centering
\small
\begin{tabular}{ l | c c | c }
\toprule
Model type & \thead{ROLE-1500} & \thead{NEG-1500} & \thead{NEG-1500 sentivity}  \\
\midrule
        Encoder-Only &  -15.32 & -39.52 & 13.07\\ 
        Seq-to-Seq & -14.20 & -28.48 & 1.20 \\ 
        Decoder-Only & 4.87 & 27.60 & 7.38 \\
        \bottomrule
\end{tabular}
\caption{Change in the model accuracy for extended dataset as compared to the original dataset across model type. Negative sign shows drop in the model performance whereas positive number shows the gain in model performance when dataset was extended.}
\label{tab:model_type}
\end{table*}
\endgroup

\begingroup
\begin{table*}[ht]
\centering
\small
\begin{tabular}{ l | c c | c }
\toprule
Model type & \thead{ROLE-1500} & \thead{NEG-1500} & \thead{NEG-1500 sentivity}  \\
\midrule
        <60M & -10.04  & -34.83 & 13.6\\ 
        ~100M & -6.47 & -13.83 & 6.98\\ 
        ~300M & -14.60 & -24.77 & 44.52\\ 
        ~1B & -1.35 & 13.3  & NA \\ 
        175B & -17.00 & -23.23 & NA \\ 
        \bottomrule
\end{tabular}
\caption{Change in the model accuracy for extended dataset as compared to the original dataset across model size. Negative sign shows drop in the model performance whereas positive number shows the gain in model performance when dataset was extended.}
\label{tab:model_size}
\end{table*}
\endgroup

\end{document}
