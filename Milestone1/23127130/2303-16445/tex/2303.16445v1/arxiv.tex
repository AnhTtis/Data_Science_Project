% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
%\usepackage[review]{EMNLP2022}
%\usepackage[review]{EACL2023}
\usepackage[]{EACL2023}


% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

\usepackage{xcolor}
\newcommand\todo[1]{\textcolor{red}{#1}}

% Importing packages
\usepackage{booktabs} % for table
\usepackage{makecell} % for table
\usepackage{xcolor} % for color
\usepackage{graphicx} % for images
\graphicspath{ {images/} }
\usepackage{comment}


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.


%Generating negation and role reversal data via in-context learning
% Extended Datasets Tell a Different Story
\title{Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning}
%\title{Extending Psycholinguistic Datasets Via In-Context Learning: Larger Probes Tell a Different Story}
% Scaling up psycholinguistic probing: the benefits of larger datasets


% \title{Can large language models really do everything? The benefits of extended psycholinguistic datasets}
% \title{Scaling up psycholinguistic probing: the benefits of larger datasets}
% \title{When data size matters: extending psycholinguistic datasets to study negation and role reversal}
% \title{When data size matters: extending psycholinguistic datasets via in-context learning}
% \title{Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-context Learning}
% \title{When size matters: extending psycholinguistic datasets via in-context learning}
% \title{Negation and role reversal: large-scale psycholinguistic probing of language models}
% \title{Extending Psycholinguistic Datasets Via In-Context Learning}
%\title{1500 Samples Are Better Than 44: Extending Psycholinguistic Datasets Via In-Context Learning}
%\title{Can Generate, But Not Understand: \\Extending Psycholinguistic Datasets Via In-Context Learning}
%\title{Can Generate, But Not Necessarily  Understand: \\Extending Psycholinguistic Datasets Via In-Context Learning}
%\title{Extending Psycholinguistic Datasets Via In-Context Learning}
%\title{(WIP title) Extending Psycholinguistic Datasets using template and GPT3}
%\title{(WIP title) GPT doesn't understand it, but it can generate it}
% \title{(WIP title) Negation, roles and other things LMs can't do.\\Now more of them.}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

%\author{Namrata Shivagunde \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  \texttt{nshivagu@cs.uml.edu} \\\And
%  Second Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  \texttt{email@domain} \\
%   Second Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  \texttt{email@domain} \\}

\author{
Namrata Shivagunde, Vladislav Lialin, and Anna Rumshisky\\
Department of Computer Science\\
University of Massachusetts Lowell\\
\texttt{\{nshivagu,vlialin,arum\}@cs.uml.edu}\\
}

\begin{document}
\maketitle
\begin{abstract}

% Older version:
% As the community invests considerable effort into creating, training, and deploying large language models (LMs), it is important to understand the datasets and tasks to which LMs might not be well-suited. The datasets NEG-136-SIMP and ROLE-88 used for Psycholinguistic diagnostics tests in  \cite{ettinger2020bert} are drawn from human experiments and found to be a very useful in understanding how well language model perform on negation and role reversal tasks. However, these are very small datasets and as small datasets do not have enough statistical power to be useful for model comparison (Card et al., 2020), we introduce large extensions to the existing datasets. For negation, we used a template following original source of dataset and increased from 18 to 770 sentence pairs. For role reversal, we used GPT3 with few-shot prompting and human verification to increase from 44 sentence pair to 750. We evaluated 22 models on these datasets following \cite{Lialin2022LifeAB} including GPT3 and we observed that GPT3 can generate ROLE-1500 but its prediction accuracy was not the best among all models. We also found that the performance of all the models dips 20-54\% on extended datasets and sensitivity to negation increased upto 4-36\% for most of it.

% Probing is one such method that allows us to evaluate specific capabilities of pre-trained models without the need for training data.

% New version:
% As the community invests considerable effort into creating, training, and deploying large language models (LMs), it is important to understand the datasets and tasks to which LMs might not be well-suited. One promising approach to this task are probing datasets that test specific model abilities, such as the ability to understand negation. However, frequently, these datasets are small and this limits their statistical power, thus, the utility in comparing different models. In this work, we introduce new datasets for negation and role reversal inspired by psycholinguistic studies. We dramatically extend NEG-136 and ROLE-88 datasets using rule-based generation and GPT3 increasing their size from 18 and 44 examples to 770 and 750 correspondingly. We evaluate 22 models on these datasets including GPT3 and show that the performance of all the models dips 20-54\% compared to the original, smaller datasets. Finally, we observe that while GPT3 has generated all the examples in ROLE-1500 its top-5 accuracy is only 24.5\%. More than that, RoBERTa and ALBERT outperform GPT3 on this dataset. Our experiments also show unexpected levels of negation sensitivity in models like RoBERTa and T5 demonstrating that previous findings might have been skewed due to smaller test sets.

% Version 3 (shorter):
%As the community invests considerable effort into creating, training, and deploying large language models, it is important to understand their capabilities and limitations. 
%the datasets and tasks to which language models might not be well-suited. 
%One common technique for this problem is probing, which tests specific model abilities using targeted datasets.%

% Probing is a technique often used to test specific capabilities of large language models using targeted datasets.
Language model probing is often used to test specific capabilities of these models.
However, conclusions from such studies may be limited when the probing benchmarks are small and lack statistical power. In this work, we introduce new, larger datasets for negation (NEG-1500-SIMP) and role reversal (ROLE-1500) inspired by psycholinguistic studies. We dramatically extend existing NEG-136 and ROLE-88 benchmarks using GPT3, increasing their size from 18 and 44 sentence pairs to 750 each. 
%Our study also includes 
We also create 
another version of extended negation dataset (NEG-1500-SIMP-TEMP), created using template-based generation. It consists of 770 sentence pairs. We evaluate 22 models on the extended datasets,
seeing model performance dip 
%and show that the performance of all the models dips 
20-57\% compared to the original smaller benchmarks. 
%Our experiments show 
We observe 
high levels of negation sensitivity in models like BERT and ALBERT demonstrating that previous findings might have been skewed due to smaller test sets. Finally, we observe that while GPT3 has generated all the examples in ROLE-1500 is only able to solve 24.6\% of them during probing.
\end{abstract}

\section{Introduction}
Understanding the limitations of large language models (LMs) becomes ever more important with their accelerated adoption and application to real-life tasks. After the original discovery that large LMs %language models (LMs) 
could perform simple NLP tasks without additional training
%any task-specific training data 
\cite{radford2019language}, the use of these models has rapidly grown, as have their capabilities \cite{brown2020language_gpt3,Sanh2021MultitaskPT,Chowdhery2022PaLMSL_PALM}.
As the community invests considerable effort into creating, training, and deploying these models \cite{Zhang2022OPTOP_OPT,gptneo}, it is important to understand the types of data and tasks they might not be well-suited.

The field of analysis of pre-trained models, 
%although still relatively young, 
has grown rapidly in recent years
\cite{Zagoury2021WhatsTB,Liu2021ProbingAT,Lialin2022LifeAB,Srivastava2022BeyondTI,aroger2020}.
%\cite{tenney2019bert_rediscovers,mccoy-etal-2019-right,talmor2019olmpics,Goldberg2019AssessingBS,ettinger2020bert,Kassner2020ArePL,Zagoury2021WhatsTB,Liu2021ProbingAT,Lialin2022LifeAB,Srivastava2022BeyondTI}.
Methods such as attention pattern analysis \cite{kovaleva2019revealing,kobayashi2020attention}, linear probing \cite{tenney2019bert_rediscovers}, and zero-shot
% a.k.a. behavioral 
probing \cite{belinkov-etal-2020-interpretability,talmor2019olmpics,ettinger2020bert,Lialin2022LifeAB} allow us to evaluate specific capabilities of pre-trained models. Zero-shot methods give us arguably the most clear picture, as they directly probe what the model learned through the upstream task and allow the researcher to target very specific skills such as understanding of negation or role. %the ability to object comparison.

However, even though these methods do not require training data, producing a good dataset for zero-shot evaluation of these language models is not an easy task. We want these datasets to be clean, diverse and to have enough statistical power to be useful for model comparison \cite{card-etal-2020-little_power}.
%
% First, we want it to be as clean as possible with close-to-zero mislabelled examples. Second, it should be large, as small datasets do not have enough statistical power to be useful for model comparison \cite{card-etal-2020-little_power}. And third, these datasets should be diverse and reflect the distribution of real-life texts.
%
Many existing probing datasets struggle with at least one of these requirements.

% Negation and role reversal datasets from \citet{ettinger2020bert} suffer from their limited size.
Psycholinguistic datasets used in a study by \citet{ettinger2020bert} have been particularly interesting in that they enabled a comparison between model behavior and human response, including both N400 effects and well-reasoned cloze judgments by human speakers. 
%
Despite being used in multiple studies since   \cite{Lialin2022LifeAB,aroger2020,Yian2020ett}, these datasets are quite small, ranging in size from 18 sentence pairs in negation (NEG-136-SIMP) to a maximum of 44 sentence pairs in the role-reversal dataset (ROLE-88).

%\citet{ettinger2020bert} tests BERT \cite{devlin2018bert} capabilities on extremely small datasets with the largest having 60 examples and the smallest just 18.

% \citet{talmor2019olmpics} and \citet{Kassner2020ArePL} extensively use template-based generation. {Why this is a problem?} 

In our %the present 
work, the NEG-136-SIMP and ROLE-88 datasets are dramatically extended. For each of them, we follow the original dataset collection method \cite{fischler1983brain,chow2016bag}, with the exception of N400 amplitude (requires electroencephalography) and cloze probability studies on humans \cite{Federmeier1999ARB}. We extended negation dataset using two methods 1) a template-based %method, 
and 2) using GPT3\footnote{We use \texttt{text-davinci-002} version of GPT3 in all our experiments} %including evaluation and dataset generation} 
with human-in-the-loop.\footnote{Datasets and code are available on https://github.com/text-machine-lab/extending\_psycholinguistic\_dataset}.
% OpenAI API.

%commented to make up for the page limit
%Our methods allow us to easily increase the sizes of ROLE-88, NEG-136 to 1500 sentences each. 17 fold and 11 fold respectively.

% For template-based generation, we use the original source of categories and subcategories from \citet{Battig1969CategoryNO} and generate data points using a template, increasing the dataset size from 18 to 770 sentence pairs (1540 sentences). To extend negation data via GPT3, we utilize
% the GPT3-davinci 175B API with
% few-shot prompting and human verification to produce 750 sentence pairs (1500 sentences).
% ROLE-88 is extended in a similar way from 88 to 750 sentence pairs.
% To extend ROLE-88, we use GPT3 API in a similar manner to generate 750 new sentence pairs.
% We extend ROLE-88 

%\todo{A note that GPT3 generation allows us to produce arguably more diverse examples than mechanical turkers. But how to phrase this?}

% \todo{finish this}.

To understand how well language models perform on these extended datasets, we evaluated 22 models, including GPT3,
% newly extended datasets by
following the methodology from \citet{Lialin2022LifeAB}. Compared to the original test sets, we see a significant drop (up to 58\%) in accuracy for both Role and Negation tasks. At the same time
% , all models except ALBERT-v2-base, T5-large, and GPT2-base,
most models show higher sensitivity to negation compared to the original dataset. Finally, while GPT3 has \textbf{generated all of the examples} in ROLE-1500, it is only able to predict the correct answer in \textbf{24.6\% cases} (top-5 accuracy).
% ALBERT-v1-xxlarge and ALBERT-v2-xxlarge surpass GPT3 by 3.9\% and 4.6\%, respectively.
ALBERT-v2-xxlarge surpasses GPT3 by 4.6\%.

%ALBERT-xxlarge both version surpasses GPT3 by around 4\%

% \begin{enumerate}
%     \item 
% \end{enumerate}

% In this work, we demonstrate that large language models are capable of generating training examples for ROLE-88 \cite{chow2016AM} dataset. \citet{ettinger2020bert} and \cite{Lialin2022LifeAB} demonstrated that this dataset is extremely chllenging for currently existing models, even at large scale. In this paper we show that the largest GPT3 (175B, davinchi-v2) \cite{brown2020language_gpt3} is only capable of solving it in THISMANY cases, however, it can produce valid training examples in THISMANY cases. More that that, we show that training on unfiltered generated examples can make the model solve these tasks with a high accuracy.

\section{Related Work}
Recent research has shown that large language models are capable of generating labeled data \cite{Anaby2020,Papanikolaou2020,kumar2020,Meng2020,Biswesh2020,Yiben2020}.
Most previous studies used GPT or GPT2 for dataset extension \cite{datagenSchick2010,Gao2022gpt2,Whitfield2021,Anaby2019}.
%\citet{datagenSchick2010} and \citet{Gao2022gpt2} used GPT2-XL; \citet{Whitfield2021} and \citet{Anaby2019} used GPT to generate data points
%
\citet{Smith2022} attempted to generate labels for the unlabelled dataset using GPT3. In our work, we generate the entire dataset, rather than just the labels. \citet{Bonifacio2022gpt3} used GPT3 to generate questions,  sampling from 100k documents to create the prompts. 
%In contrast, in the present work, existing datasets are too small to sample from. 
\citet{Han2021gpt3translation} and  \citet{Liu2022gpt3nli} prompted GPT3 to generate synthetic translation and NLI datasets, respectively. 

\citet{Lialin2022LifeAB} and \citet{ettinger2020bert} evaluated language models on smaller datasets for negation and role reversal. We extend these datasets to around 1500 data points and evaluate 22 models, including GPT3. To our knowledge, our work is the first to extend psycholinguistic datasets 
%sing GPT3 
and use it to evaluate an extended set of models. 

%\todo{\paragraph{Large language models} write this section}

%\todo{\paragraph{Prompting}write this section}

%\todo{\paragraph{Probing tasks} Some stuff about probing and then we'll have another paragraph that says that we're different from all the people. Should also cite the "step-by-step paper here". This work shows that probing tasks can miss some capabilities of pre-trained models. More that that, we show that a large generative model can produce valid training examples that that tuning the model on them can make it solve this task with a high accuracy.}


\section{Data generation}

\subsection{Negation Dataset: NEG-1500-SIMP}
% What does original data look like?
The existing negation dataset NEG-136-SIMP from \citet{ettinger2020bert} consists of 18 pairs of sentences. 
%The existing negation dataset from \citet{ettinger2020bert} is called NEG-136-SIMP consisting of 18 pairs of sentences.
Each pair is made of one affirmative and one negated sentence e.g. the sentences ``A robin is a bird'' (affirmative) and ``A robin is not a tree'' (negated) form a pair. % How do we generate new samples? state the rules
We extend this dataset using two methods: template-based and generation-based. We create 770 sentence pairs with the template-based method and generate 750 sentence pairs using GPT3. We will refer to these datasets as NEG-1500-SIMP-TEMP and NEG-1500-SIMP-GEN, respectively.

%\vspace{-3.5pt}
\paragraph{NEG-1500-SIMP-TEMP} Each pair in the original dataset follows a template. For affirmative sentences, the template is ``\emph{A/An \{subject\} is a/an \{object\}}''. %For negated sentences, 
Its negated version is ``\emph{A/An \{subject\} is not a/an \{another object\}}''. \citet{Battig1969CategoryNO} and \citet{fischler1983brain} 
%also provide
%provide these templates along with 
provide a template and a list of objects (e.g., robin, 
%lily, 
pine) and the corresponding categories (e.g., bird, 
%flower, 
tree) which are used to generate samples %can be used to generate from these templates.
\footnote{\citet{fischler1983brain} refers to these as ``subjects'' and ''objects'', respectively.}.
For instance, the category, ``bird'' in the example, ``A robin is a bird'' is replaced with another category (``tree'') to generate the negated example ``A robin is not a tree''.
%For example, in the sentence pair, ``A robin is a bird'' and ``A robin is not a tree'', ``robin'' is classified as a `` bird'', which changes to another, different category (``tree'') in the negated example.
%sentence however in the negation, the object changes to a different category ``tree''.

% Different methods we tried?
We experimented with using WordNet to generate from this template, but found that it required a careful curation of hypernym hierarchies. Since our goal was to reduce human effort and cost, we decided against it. We used a template from \citet{fischler1983brain} along with all the categories and subcategories listed in \citet{Battig1969CategoryNO} to create 1540 sentences (770 sentence pairs). Similar to \citet{ettinger2020bert}, we did not use multi-word category names.

%\vspace{-3.5pt}
\paragraph{NEG-1500-SIMP-GEN}
We use human-in-the-loop and few-shot prompted GPT3 to generate 750 pairs (1500 sentences). Each GPT3 prompt consists of an instruction and four randomly selected in-context examples. We used GPT3-text-davinci-002 with temperature 1, maximum tokens 150 and Top P set to 1. The cost of generating the dataset is around \$30. An example of the prompt is shown in the appendix~\ref{gpt3-prompt}. After generating samples from GPT3, the dataset was manually cleaned to filter out poorly generated examples. Details about manual filtering in mentioned in Appendix ~\ref{manual-cleaning-neg1500simp}.


%Another way we tried extending negation dataset was by using 
%We generated 1500 sentences (750 pairs) using GPT3 OpenAI API. We prompted GPT3 da-vinci model with an instruction and four in-context examples. The temperature was set to 1 and maximum tokens to 150. The four in-context pairs were chosen randomly from the original dataset NEG-136-SIMP. Example prompts are given in Appendix~\ref{gpt3-prompt}. The generation process was followed by manual cleaning to filter out poorly generated examples. The details on manual filtering are given in Appendix ~\ref{manual-cleaning-neg1500simp}.

%We generated 750 pairs (1500 samples) and call this dataset NEG-1500-SIMP-GEN. 
%An example of the prompt is given in Appendix~\ref{gpt3-prompt}.

% manual cleaning

%As NEG-1500-SIMP-TEMP was generated using a pre-defined template, it didn't require data cleaning however GPT3 generated samples had many mistakes and were manually filtered. 


% data analysis
Appendix~\ref{toptarget} shows top 20 categories in the new negation datasets. NEG-1500-SIMP-GEN has almost three times more examples in the ``animal'' category than ``tree'' or ``drink''. The distribution is more skewed compared to the template-based dataset. All the categories from the original dataset NEG-136-SIMP are represented in the top 20 (by frequency) categories in NEG-1500-SIMP-GEN (except ``insect'').  However, only four out of nine categories from the original data are present in the top 20 most frequent categories in the template-generated NEG-1500-SIMP-TEMP.

\subsection{Role-reversal Dataset: ROLE-1500}

% what was the original dataset?
The original ROLE-88 dataset \cite{ettinger2020bert,chow2016bag} is a role reversal dataset consisting 88 sentences (44 sentence pairs). Here is an example of a sentence pair:  \emph{``The librarian documented which journalist the celebrities had avoided.''
``The librarian documented which celebrities the journalist had interviewed''}. The first sentence has two words representing roles (here: journalist, celebrities), which are reversed in the second sentence. The target verb (the last verb in the sentence) is always preceded by the auxiliary ``had''. This dataset was created to observe the effect of role reversal on the target verb. We notice that all of the role words represent human roles (chef, worker, etc.) or animals (whale, dog, etc.). There were some pairs where the role reversal didn't change the target word, but they were semantically correct. % e.g. hired/hired

% methods we tried?
%We couldn't use WordNET for this task as the rules were not as simple as negation dataset, therefore 

% We use method same as NEG-1500-SIMP to generate ROLE-1500 but with temperature 0.64. 

%We use human-in-the-loop and few-shot prompted GPT3 with the above principles to generate 750 pairs (1500 sentences), to approximately 18 times the size of the original dataset. The cost of generating this dataset, which we will refer to as ROLE-1500, is \$25. Each GPT3 prompt consists of an instruction and four randomly selected in-context examples. We used GPT3-davinci with temperature 0.64, maximum tokens 100 and Top P set to 1. An example of the prompt is shown in the appendix~\ref{gpt3-prompt}. After generating samples from GPT3, the dataset was manually cleaned. Details about manual filtering in mentioned in Appendix ~\ref{manual-cleaning-role1500}.

% changes
To extend ROLE dataset, we used the same method as NEG-1500-SIMP-GEN and generated %750 pairs 
1500 sentences with temperature set to 0.64. We call this new dataset as ROLE-1500 and cost of generating it is \$25. %The cost of generating this dataset, which we will refer to as ROLE-1500, is \$25.
An example of the prompt is shown in the appendix~\ref{gpt3-prompt}. After generating samples from GPT3, the dataset was manually cleaned. Details about manual filtering in mentioned in Appendix ~\ref{manual-cleaning-role1500}. Appendix ~\ref{toptarget} shows top 20 target verbs in ROLE-88 and ROLE-1500. Except four, all of the top 20 verbs are common in both datasets.

\section{Evaluation on Extended Datasets}
% what are we doing here?
Following methodology from \citet{Lialin2022LifeAB}, we evaluated 22 models on the newly created negation and role reversal data (Figure \ref{tab:accuracy-top5}).
% The models include different sizes of BERT, RoBERTa, ALBERT, DistilBERT, T5, GPT2, and GPT3 \cite{devlin2018bert,liu2019roberta,sanh2019distilbert,lan2019albert,raffel2019exploring,radford2019language,brown2020language_gpt3} in a zero-shot setting. 
% explain lialin 2022 method
Both negation and role reversal tasks were first converted into a masked language modeling task, where the
% target word (
the category or the final verb was replaced with a mask token.
% ,\footnote{``[MASK]'' for BERT, DistilBERT and ALBERT, ``<mask> .'' for for RoBERTa, and ``<extra\_id\_0>'' for T5.} and  
%For BERT, DistilBERT and ALBERT, the target word (the category or the final verb) was replaced with a mask ``[MASK]''. For RoBERTa and T5, it was replaced with ``<mask> .'' and ``<extra\_id\_0>'', respectively. 
% the model had to predict the masked word.
For GPT2 and GPT3, the task was converted into a causal language modeling task, where the target was removed, and the model had to predict the target word. The responses of the models were evaluated against the true target.

% gpt3
For GPT3, we also performed zero-shot evaluation with two prompts: with and without instructions pre-pended to the input sentence (see Appendix ~\ref{gpt3-prompt}). We used the GPT3-text-davinci-002 model via OpenAI API with the same parameters as NEG-1500-SIMP-GEN. The temperature was set at 0.5, max\_tokens at 1 and logprobs at 5. GPT3 response was evaluated against gold label.

%--------------------TABLE START-----------------------
\begingroup
\begin{table*}
\centering
\footnotesize
%\setlength{\tabcolsep}{-1 pt}
\addtolength{\tabcolsep}{-2.5pt} % reduce space by -4pt
\begin{tabular}{ l | c c c | c c c | c c}
\toprule
& \thead{ROLE-88} & \thead{NEG-136\\SIMP(Aff)} & \thead{NEG-136\\Sensitivity} & \thead{ROLE-\\1500} & \thead{NEG-1500\\SIMP\\TEMP(Aff)}  & \thead{NEG-1500\\SIMP\\GEN(Aff)} & \thead{NEG-1500\\SIMP-TEMP\\ Sensitivity} & \thead{NEG-1500\\SIMP-GEN\\ Sensitivity} \\
\midrule
        $\mathrm{BERT}_\mathrm{base}$  & 27.3 & \bf{100.0} & 16.7 & 20.3 & 58.4 & 55.3 & 53.5 & 35.9\\ 
        $\mathrm{BERT}_\mathrm{large}$ & 37.5 & \bf{100.0} & 33.3 & 21.5 & 65.1 & 53.8 & 53.5 & 40.3 \\
        $\mathrm{RoBERTa}_\mathrm{base}$  & 46.6 & 94.4 & 66.7 & 23.0  & 62.1 & 44.0 & 64.4 & 71.5 \\
        $\mathrm{RoBERTa}_\mathrm{large}$ & \bf{55.7} & 94.4 & 50.0 & 26.1 & 63.4 & 53.7 & 64.5 & 69.5 \\ 
        $\mathrm{DistilBERT}_\mathrm{base}$  & 28.4 & 94.4 &27.8 & 19.3 & 57.3 & 52.8 & 44.7 & 41.5 \\
        %$\mathrm{AlBERTv1}_\mathrm{base}$ & 17.1 & 72.2 &22.2 & 10.4 & 37.1 & 36.4 & 40.0 & 35.6 \\
        %$\mathrm{AlBERTv1}_\mathrm{large}$  & 26.1 & 83.3 & 22.2 & 17.4 & 48.4 & 42.4 & 38.6 & 32.9 \\
        %$\mathrm{AlBERTv1}_\mathrm{xlarge}$  & 34.1 & 55.5 & 55.6 & 19.5 & 22.3 & 26.0 & 77.0 & 62.5 \\
        %$\mathrm{AlBERTv1}_\mathrm{xxlarge}$  &  53.4 & 72.2 & 55.6 & 28.5 & 38.7 & 39.3 & 59.9 & 61.7\\
        $\mathrm{AlBERTv2}_\mathrm{base}$  & 26.1 & 33.3 & 38.9 & 15.3 & 10.0 & 11.7 & 37.3 & 35.9\\
        %$\mathrm{AlBERTv2}_\mathrm{large}$  & 29.5 & 83.3 & 22.2 & 18.8 & 36.6 & 36.2 & 31.7 & 33.1 \\
        $\mathrm{AlBERTv2}_\mathrm{xlarge}$ & 37.5 & 94.4 & 27.8 & 21.1 & 40.4 & 47.8 & 52.7 & 51.1 \\
        $\mathrm{AlBERTv2}_\mathrm{xxlarge}$ &  50.0 & \bf{100.0} & 44.4 & \bf{29.0} & 42.9 & 45.3 & 55.7 & 61.5 \\
        %$\mathrm{T5}_\mathrm{small}$  & 9.1 & 44.4 & 0.0 & 5.8 & 33.6 & 25.3 & 16.8 & 19.6 \\
        %$\mathrm{T5}_\mathrm{base}$ & 27.3 & 88.9 & 27.8 & 14.8 & 58.2 & 45.1 & 46.5 & 33.5\\
        $\mathrm{T5}_\mathrm{large}$  & 36.4 & 94.4 & 50.0 & 18.2 & 60.4 & 49.8 & 44.0 & 0.0\\
        $\mathrm{T5}_\mathrm{xl}$ &   44.3 & 83.3 & 66.7 & 21.5 & 60.9 &  60.9 &  68.2 & 70.0 \\
        $\mathrm{GPT2}_\mathrm{base}$  &  0.0 & 0.0 & 66.7 & 11.2 & 48.3 & 37.7 & 60.4 & 56.4\\
        %$\mathrm{GPT2}_\mathrm{medium}$ & 0.0 & 0.0 & 50.0 & 16.4 & 61.4 & 46.9 & 53.1 & 60.7\\
        %$\mathrm{GPT2}_\mathrm{large}$  & 0.0 & 0.0 & 38.9 & 16.8 & 61.7 & 51.7 & 57.9 & 69.2 \\
        $\mathrm{GPT2}_\mathrm{xl}$ & 0.0 & 0.0 & 44.4 & 18.8 & 63.6 & 52.8 & 59.0 & 71.9 \\
        $\mathrm{GPT3}$ & 44.4 & 94.4 & \bf{100.0} & 24.6 & \bf{65.9} & \bf{63.3} & \bf{100.0} & \bf{100.0} \\
        $\mathrm{GPT3}_\mathrm{prompt}$ & 38.6 & 72.2 & \bf{100.0} & 24.4 & 55.9 & 55.2 & \bf{100.0} & \bf{100.0}\\
        \bottomrule
\end{tabular}
\caption{Zero-shot top-5 word prediction accuracy and sensitivity (top-5 over the whole vocabulary).
%Top-5 is selected over the whole vocabulary. 
ROLE-88 and NEG-136 are from \citet{Lialin2022LifeAB}. ROLE-1500 and NEG-1500 are the new datasets. The best result for each task is in bold. ``SIMP'' stands for simple, ``prompt'' stands for prompting(adding instruction). The negation task is evaluated in the affirmative form (\textit{Aff}).  Sensitivity is the percentage of sentence pairs for which the top-1 prediction changed. See Appendix \ref{full-results-section} for accuracy and sensitivity of all models on extended datasets.
}
\label{tab:accuracy-top5}
\end{table*}
\endgroup
%--------------------TABLE END-----------------------

Our evaluation metric is the top-5 prediction accuracy, following \citet{ettinger2020bert}. It is the percentage of the model responses where the gold label is among the top five predictions from the model. Table \ref{tab:accuracy-top5} shows the results for the original and extended datasets. 
% commented this for page limit %(ROLE-88, NEG-136-SIMP) and the extended datasets (ROLE-1500, NEG-1500-SIMP-TEMP, NEG-1500-SIMP-GEN).
We also included top-1, top-10, and top-20 accuracy predictions in Appendix ~\ref{top20accuracy}. 
For the negation dataset, we used model sensitivity as an additional metric. Since we didn't have N400 amplitude and cloze probability for the extended datasets, we defined  sensitivity as the percentage of sentence pairs for which the top-1 prediction changed, when ``not'' was added. Table \ref{tab:accuracy-top5} shows the sensitivity result. %gives sensitivity for the original and extended negation datasets. 
Results for all models are shown in Appendix \ref{full-results-section}. We could not compute sensitivity for ROLE-1500, since in some sentence pairs the target word was the same.

%\todo{I think it would be a good idea to compute the power of our datasets following \cite{card-etal-2020-little_power}}
%\todo{Copy the tables from Notion}
\section{Results}
%\vspace{-3.5pt}
\paragraph{Models performance dropped substantially on extended datasets.}
Model performance decreased by 40-50\% on negation (affirmative-only) and by 20-30\% on role reversal for most of the models. Even top-20 prediction accuracy couldn't reach the performance shown for the original datasets. For NEG-1500-SIMP-TEMP, BERT, RoBERTa, DistilBERT and T5 performance decreased around 30\% each, while ALBERT-xxlarge-v2 had the biggest drop from 100\% to 43\%. Compared to NEG-1500-SIMP-TEMP, NEG-1500-SIMP-GEN shows 5-10\% more (absolute) drop in the performance. In ROLE-1500, the performance of BERT, DistilBERT and T5 decreased by about 5-15\% each. RoBERTa and ALBERT showed the highest drop of 23-29\% on this task. Increasing dataset size had a larger effect on model accuracy for negation (especially NEG-1500-SIMP-GEN), than for the role-reversal task.
The models that performed best on the small datasets did not remain in the lead on the extended. For example, in ROLE, Roberta-large was the best model on the original dataset, but ALBERT-v2-xxlarge surpassed it on the extended one. For negation, BERT and ALBERT performed the best originally, but GPT3 surpassed them when the datasets became larger. % (both for template-based and generated data).

%\vspace{-3.5pt}

\paragraph{GPT3 cannot solve, but can generate such examples.}
While GPT3 is unable to reliably solve these tasks, it is perfectly capable of picking up the pattern and generating valid training examples. ROLE-1500 was generated by GPT3, and yet, RoBERTa-large, and %ALBERT-xxlarge-v1 and v2 
ALBERT-xxlarge perform better on it than GPT3. There is a gap of around 4.5\% between best model and GPT3. Changing the prompt by adding instructions didn't change the performance on ROLE-1500, but decreased the accuracy by 8-10\% on negation. Sensitivity to negation remains the same for GPT3 with and without instruction prompts.

%\vspace{-3.5pt}
\paragraph{GPT3 responses contains variety of mistakes.}
%As mentioned above, approximately 2/3 of the generated ROLE data had to be manually filtered out.
%To extend the ROLE dataset to 1500 sentences, we generated almost 4700 sentences and cleaned them manually. Due to the high rate of duplication, data generation was stopped after 750 pairs. 
%During this process, we observed that 14.3\% of responses were without a pair or were simple sentences. 
Approximately 2/3 of the generated ROLE data had to be manually filtered out. 14.3\% of responses were single sentences without a pair. 
For example, the model generated \emph{``the athlete reported which coach the player had injured,''} but not its pair \emph{``the athlete reported which player the coach had trained''}. %Many sentences did not follow the rules and just generated simple sentences, e.g., \emph{``The guest ordered the waiter.''}. 
7.4\% responses were semantically incorrect. For example, \emph{``the camper reported which girl the book had read''}. 
%, ``the camper reported which book the girl had eaten''}. 
Such responses were either removed or edited to match the format. 
Similar kind of errors had to be manually filtered out in the negation data as well.
%While extending the negation dataset, we encountered similar errors and manually filtered them.
% AR: add examples to appendix in camera-ready

%\vspace{-3.5pt}
\paragraph{Sampling in-context examples from a smaller dataset leads to more duplicate responses from GPT3.}
There were 44 sentence pairs to sample from in the role reversal data and only 18 pairs in the negation data.
%For the role dataset, for GPT3 prompts there were 44 pairs to sample in-context examples from whereas negation had just 18 pairs. 
62.5\% of negation data generated with GPT3 were duplicate entries, compared to 32.5\% for the role reversal data. To generate the same number of sentence pairs, we generated twice as many responses for negation than for role reversal, which led to twice the manual labor required for filtering.
%and therefore negation dataset generated via GPT3 required two times more manual labor than the role reversal dataset. 
%in previous section. 

%\paragraph{RoBERTa is sensitive to how a sentence starts.} It was found that if Roberta is presented with ``A robin is a <mask>'' versus 'a robin is a <mask>, the accuracy dips by 20\% on original NEG-136-SIMP and 4-5\% for extended NEG-1500.

%\vspace{-3.5pt}
\paragraph{Models are more sensitive to negation for extended dataset.}  All models except ALBERT-v2-base, T5-large, and GPT2-base show higher sensitivity to negation on both extended negation datasets compared to the original one. For NEG-1500-SIMP-TEMP, %(template-based dataset) 
the sensitivity for BERT and ALBERT-xl %(v1 and v2)
increased by 36.8\% and 21-25\%, respectively. For RoBERTa-base, T5-large and GPT2, sensitivity to negation dropped by 2.3-6\%. The sensitivity to negation on NEG-1500-SIMP-GEN either increased or remained the same compared to original data for all models, except ALBERT-v2-base, T5-large and GPT2-base. For BERT and RoBERTa the sensitivity increased by almost 20\%. Results demonstrate high levels of negation sensitivity in models like BERT and ALBERT, suggesting that previous findings might have been skewed due to smaller test sets. 

\vspace{-1pt}
\section{Conclusion}
We provide a new resource that dramatically extends existing probing data for negation and role reversal. The psycholinguistic datasets NEG-136-SIMP and ROLE-88 are extended to 1500 data points. We evaluate 22 models using the new data, observing that the absolute accuracy drops for most models on both tasks. However, most models do show an increased sensitivity to negation. Strikingly, as seen in the role reversal task, we show that GPT3 may be capable of generating the data for a task while failing to show top performance on it.
%extending the role dataset, fails to perform best on it. 

%\newpage
\section*{Limitations}
The current method did not include the N400 amplitude and the cloze probability to generate samples and was more based on a large language model picking up the pattern and generating samples. The other limitation was the diversity of datapoints generated using existing small dataset. We observed that there is a cap on how many datapoints we can generate with a limited number of original samples used via in-context learning. The less samples we have the more duplication we get in GPT3 responses. We also need to be careful in generating samples, as GPT3 responses can be expensive, especially when using more in-context examples.
% Therefore to extend the dataset further, we will need more GPT3 open AI credits and more in-context examples. 


% EMNLP 2022 requires all submissions to have a section titled ``Limitations'', for discussing the limitations of the paper as a complement to the discussion of strengths in the main text. This section should occur after the conclusion, but before the references. It will not count towards the page limit.  The discussion of limitations is mandatory. Papers without a limitation section will be desk-rejected without review. ARR-reviewed papers that did not include ``Limitations'' section in their prior submission, should submit a PDF with such a section together with their EMNLP 2022 submission.While we are open to different types of limitations, just mentioning that a set of results have been shown for English only probably does not reflect what we expect. Mentioning that the method works mostly for languages with limited morphology, like English, is a much better alternative. In addition, limitations such as low scalability to long text, the requirement of large GPU resources, or other things that inspire crucial further investigation are welcome.

\section*{Ethics Statement}
Using large closed-source language models to generate evaluation data, while highly effective, should be approached with caution.
First, neural networks of hundreds of billions of parameters are computationally expensive to infer and potential carbon dioxide emissions should be taken into consideration.
Second, while API access to such models allows to avoid many technical challenges, especially having enough resources to inference large models, it comes with limitations.
For example, GPT3 can only return the logprops of at most five top tokens over the vocabulary. Also, the API provides no control over the random seed used for sampling reducing the potential reprehensibility of the research.
Finally, without the direct access to the model weights, there is no guarantee that this version of the model will be always accessible to researchers in the future and won't be restricted, modified, deleted, or lost.

%Scientific work published at EMNLP 2022 must comply with the \href{https://www.aclweb.org/portal/content/acl-code-ethics}{ACL Ethics Policy}. We encourage all authors to include an explicit ethics statement on the broader impact of the work, or other ethical considerations after the conclusion but before the references. The ethics statement will not count toward the page limit (8 pages for long, 4 pages for short papers).

% Entries for the entire Anthology, followed by custom entries
\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}

\clearpage
\appendix
 \section{GPT3 prompt}
 \label{gpt3-prompt}
 \subsection{ROLE-1500 generation prompt}
An example prompt for generating ROLE-1500 dataset is given below.
The roles are colored orange and blue, whereas the target word is highlighted in green:

% \todo{figure out how to make it look good}
% GPT3 prompt-

\emph{The task is to reverse the role in the sentences. Generate more sentence like this:}

\emph{The journalist investigated which {\color{cyan}athlete} the {\color{orange}team} had {\color{green}recruited},} \emph{The journalist investigated which {\color{orange}team} the {\color{cyan}athlete} had {\color{green}joined},}

\emph{The detective interviewed which {\color{cyan}witness} the  {\color{orange}doctor} had {\color{green}suspected}, The detective interviewed which {\color{orange}doctor} the {\color{cyan}witness} had {\color{green}seen}.}

\emph{The teacher lectured which {\color{cyan}student} the  {\color{orange}class} had {\color{green}ignored}, The teacher lectured which {\color{orange}class} the {\color{cyan}student} had {\color{green}left},}

\emph{The police reported which {\color{cyan}criminal} the {\color{orange}witness} had {\color{green}described}, 
The police reported which {\color{orange}witness} the {\color{cyan}criminal} had {\color{green}robbed},}

\emph{The doctor treated which {\color{cyan}patient} the {\color{orange}nurse} had {\color{green}examined}, The doctor treated which {\color{orange}nurse} the {\color{cyan}patient} had {\color{green}injured},}
\\

 \subsection{NEG-1500-SIMP-GEN generation prompt}
An example prompt for generating NEG-1500-SIMP-GEN dataset is given below.\\

\emph{``The task is to generate affirmative sentences and its negation. The object of the sentence should be a hypernym of the subject of the sentence. Generate more sentence pairs like these: ‚Äù}

 \emph{A robin is a bird, A robin is not a tree,}
 
 \emph{An oak is a tree, An oak is not a flower,}
 
 \emph{A carrot is a vegetable, A carrot is not a bird,}
 
 \emph{A hammer is a tool, A hammer is not a tree,}''

\subsection{ROLE-1500 evaluation prompts with and without instructions}
Prompt with instruction for ROLE-1500: 

\emph{``The goal is to complete the given sentence with one English word. Avoid punctuation or a new line or space. The librarian documented which journalist the celebrities had''}. 
\\

The prompt without instruction: \emph{``The librarian documented which journalist the celebrities had''}.
The model predicts the next word in sentence. 
\\
Instruction is same for ROLE-1500 and NEG-1500-SIMP-GEN. Only the in-context example changes.
\\

\section{Manual cleaning of the datasets}
\subsection{NEG-1500-SIMP}
\label{manual-cleaning-neg1500simp}
For NEG-1500-SIMP-GEN, to get 1500 cleaned samples, we generated 12000 sentences. 87.5\% of the responses were rejected as they were a) duplicates (62.5\%) b) empty lines (15\%) c) only negated sentences (8.75\%) d) others (1.25\%). Others include sentences like ``A toy is a toy'' and ``A toy is an object'', as well as objects with multiple words and semantically wrong sentences (e.g., ``A flower is a rose'', ``A cloud is a weather''). The cost of generating NEG-SIMP-1500-GEN was \$35.

\subsection{ROLE-1500}
\label{manual-cleaning-role1500}
After generating GPT3 responses to these prompts, the samples were manually cleaned to get 1500 sentences (750 sentence pairs). We generated 4700 sentences (including empty, partial and no-pair sentences), out of which 68\% were removed, as a) 32.5\% were duplicates, b) 14.3\% missed on getting a pair or were simple sentences, c) 8.5\% were empty lines, d) 7.4\% were semantically wrong sentences or had a wrong role reversal (e.g., ``The camper reported which book the girl had eaten''), e) 5.3\% were repeating instructions or partial sentences. 
%
In some instances, generated examples included some repetition of the role nouns present in the in-context examples.
%Note that often the generated sentence pairs included a combination of the in-context examples presented to GPT3 via prompt.
%

\section{Rules to create NEG-1500-SIMP-GEN}
\label{rules}
An affirmative sentence and a negation sentence make a pair. Affirmative sentences follow the format of ``{subject} is an {object}'' whereas its negation form is ``{subject} is not an {object}''. Affirmative sentences can be, for example \emph{``Robin is a bird''} or \emph{``Robin is an animal''}, the subject word is \emph{``Robin''}, the object word is \emph{``bird''} and its immediate superordinate category name is \emph{``animal''}. The negation for any of these two affirmative sentences can be \emph{``Robin is not a plant'' or ``Robin is not a tree''}. The target completion ( e.g. \emph{``plant'' or ``tree''}) has to be an object or superordinate word from another category. Figure ~\ref{fig:neg} in the Appendix ~\ref{fig:neg} shows two categories (Animal and Plant) together with its respective subject and object words \cite{Battig1969CategoryNO}.

\begin{figure*}
    \centering
    \includegraphics[width=0.7\linewidth]{images/data-extention-neg-simp-drawio.pdf}
    \caption{Sentence subject word (Robin). Affirmative sentence completion are in green - object word(Bird) and super ordinate category name(Animal). Negative sentence completion are in red - object word(Tree) and super ordinate category name(Plant).  \cite{Battig1969CategoryNO}}
    \label{fig:neg}
\end{figure*}

\section{Top 20 target words for all datasets}
\label{toptarget}
Figure ~\ref{fig:neg-136-simp} and ~\ref{fig:role-88} show top 20 object words for original datasets NEG-136-SIMP and ROLE-88.  Figure ~\ref{fig:neg-1500-simp-temp}, ~\ref{fig:neg-1500-simp} and ~\ref{fig:role-1500} depict top 20 object words for original new extended datasets. Y axis represents the number of times the target words.

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{images/neg-136-simp.pdf}
    \caption{Top 20 categories for NEG-136-SIMP}
    \label{fig:neg-136-simp}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{images/neg-1500-simp.pdf}
    \caption{Top 20 categories for NEG-1500-SIMP-TEMP}
    \label{fig:neg-1500-simp-temp}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{images/neg-1500-simp-gpt3.pdf}
    \caption{Top 20 categories for NEG-1500-SIMP-GEN}
    \label{fig:neg-1500-simp}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{images/role-1500.pdf}
    \caption{Top 20 categories for ROLE-1500}
    \label{fig:role-1500}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{images/role-88.pdf}
    \caption{Top 20 target words for ROLE-88}
    \label{fig:role-88}
\end{figure*}



\section{Result for all models}
Table ~\ref{tab:full=table-accuracy-top5} shows the top five accuracy for all the models.
%%%%%%% Full Table
\label{full-results-section}
\begingroup
\begin{table*}
\centering
\footnotesize
%\setlength{\tabcolsep}{-1 pt}
\addtolength{\tabcolsep}{-2.5pt} % reduce space by -4pt
\begin{tabular}{ l | c c c | c c c | c c}
\toprule
& \thead{ROLE-88} & \thead{NEG-136\\SIMP(Aff)} & \thead{NEG-136\\Sensitivity} & \thead{ROLE-\\1500} & \thead{NEG-1500\\SIMP\\TEMP(Aff)}  & \thead{NEG-1500\\SIMP\\GEN(Aff)} & \thead{NEG-1500\\SIMP-TEMP\\ Sensitivity} & \thead{NEG-1500\\SIMP-GEN\\ Sensitivity} \\
\midrule
        $\mathrm{BERT}_\mathrm{base}$  & 27.3 & \bf{100.0} & 16.7 & 20.3 & 58.4 & 55.3 & 53.5 & 35.9\\ 
        $\mathrm{BERT}_\mathrm{large}$ & 37.5 & \bf{100.0} & 33.3 & 21.5 & 65.1 & 53.8 & 53.5 & 40.3 \\
        $\mathrm{RoBERTa}_\mathrm{base}$  & 46.6 & 94.4 & 66.7 & 23.0  & 62.1 & 44.0 & 64.4 & 71.5 \\
        $\mathrm{RoBERTa}_\mathrm{large}$ & \bf{55.7} & 94.4 & 50.0 & 26.1 & 63.4 & 53.7 & 64.5 & 69.5 \\ 
        $\mathrm{DistilBERT}_\mathrm{base}$  & 28.4 & 94.4 &27.8 & 19.3 & 57.3 & 52.8 & 44.7 & 41.5 \\
        $\mathrm{AlBERTv1}_\mathrm{base}$ & 17.1 & 72.2 &22.2 & 10.4 & 37.1 & 36.4 & 40.0 & 35.6 \\
        $\mathrm{AlBERTv1}_\mathrm{large}$  & 26.1 & 83.3 & 22.2 & 17.4 & 48.4 & 42.4 & 38.6 & 32.9 \\
        $\mathrm{AlBERTv1}_\mathrm{xlarge}$  & 34.1 & 55.5 & 55.6 & 19.5 & 22.3 & 26.0 & 77.0 & 62.5 \\
        $\mathrm{AlBERTv1}_\mathrm{xxlarge}$  &  53.4 & 72.2 & 55.6 & 28.5 & 38.7 & 39.3 & 59.9 & 61.7\\
        $\mathrm{AlBERTv2}_\mathrm{base}$  & 26.1 & 33.3 & 38.9 & 15.3 & 10.0 & 11.7 & 37.3 & 35.9\\
        $\mathrm{AlBERTv2}_\mathrm{large}$  & 29.5 & 83.3 & 22.2 & 18.8 & 36.6 & 36.2 & 31.7 & 33.1 \\
        $\mathrm{AlBERTv2}_\mathrm{xlarge}$ & 37.5 & 94.4 & 27.8 & 21.1 & 40.4 & 47.8 & 52.7 & 51.1 \\
        $\mathrm{AlBERTv2}_\mathrm{xxlarge}$ &  50 & \bf{100.0} & 44.4 & \bf{29.0} & 42.9 & 45.3 & 55.7 & 61.5 \\
        $\mathrm{T5}_\mathrm{small}$  & 9.1 & 44.4 & 0.0 & 5.8 & 33.6 & 25.3 & 16.8 & 19.6 \\
        $\mathrm{T5}_\mathrm{base}$ & 27.3 & 88.9 & 27.8 & 14.8 & 58.2 & 45.1 & 46.5 & 33.5\\
        $\mathrm{T5}_\mathrm{large}$  & 36.4 & 94.4 & 50.0 & 18.2 & 60.4 & 49.8 & 44.0 & 0.0\\
        $\mathrm{T5}_\mathrm{xl}$ &   44.3 & 83.3 & 66.7 & 21.5 & 60.9 & 60.9 & 68.2 & 70.0 \\
        $\mathrm{GPT2}_\mathrm{base}$  &  0.0 & 0.0 & 66.7 & 11.2 & 48.3 & 37.7 & 60.4 & 56.4\\
        $\mathrm{GPT2}_\mathrm{medium}$ & 0.0 & 0.0 & 50.0 & 16.4 & 61.4 & 46.9 & 53.1 & 60.7\\
        $\mathrm{GPT2}_\mathrm{large}$  & 0.0 & 0.0 & 38.9 & 16.8 & 61.7 & 51.7 & 57.9 & 69.2 \\
        $\mathrm{GPT2}_\mathrm{xl}$ & 0.0 & 0.0 & 44.4 & 18.8 & 63.6 & 52.8 & 59.0 & 71.9 \\
        $\mathrm{GPT3}$ & 44.4 & 94.4 & \bf{100.0} & 24.6 & \bf{65.9} & \bf{63.3} & \bf{100.0} & \bf{100.0} \\
        $\mathrm{GPT3}_\mathrm{prompt}$ & 38.6 & 72.2 & \bf{100.0} & 24.4 & 55.9 & 55.2 & \bf{100.0} & \bf{100.0}\\
        \bottomrule
\end{tabular}
\caption{Zero-shot top-5 word prediction accuracy and sensitivity (top-5 over the whole vocabulary).
%Top-5 is selected over the whole vocabulary. 
ROLE-88 and NEG-136 are from \citet{Lialin2022LifeAB}. ROLE-1500 and NEG-1500 are the new datasets. The best result for each task is in bold. ``SIMP'' stands for simple, ``prompt'' stands for prompting. The negation task is evaluated in the affirmative form (\textit{Aff}).  Sensitivity is the percentage of sentence pairs for which the top-1 prediction changed.
}
\label{tab:full=table-accuracy-top5}
\end{table*}
\endgroup

%%%%%%%% Full Table

\section{Top 1, 10 and 20 prediction accuracy for all models}
\label{top20accuracy}
Table ~\ref{tab:neg_accuracy_top20} and ~\ref{tab:neg_temp_accuracy_top20} show top 1, 10 and 20 accuracy for new negation datasets. Table ~\ref{tab:role_accuracy_top20} depict top 1, 10 and 20 accuracy for new role reversal dataset. 
\begingroup
\begin{table*}[ht]
\centering
\small
\begin{tabular}{ l | c c c }
\toprule
NEG-1500-SIMP-TEMP & \thead{Top 1} & \thead{Top 10} & \thead{Top 20}  \\
\midrule
        $\mathrm{BERT}_\mathrm{base}$ & 28.5 & 64.7 & 71.4 \\ 
        $\mathrm{BERT}_\mathrm{large}$ & 34.2 & \bf{71.9} & \bf{76.5} \\ 
        $\mathrm{RoBERTa}_\mathrm{base}$ & 22.2 & 68.7 & 73.0 \\
        $\mathrm{RoBERTa}_\mathrm{large}$ & 30 & 69.2 & 74.4 \\ 
        $\mathrm{DistilBERT}_\mathrm{base}$  & 28.6 & 67.8 & 75.6 \\
        $\mathrm{AlBERTv1}_\mathrm{base}$ & 14.3 & 43.9 & 49.5 \\
        $\mathrm{AlBERTv1}_\mathrm{large}$  & 13.5 & 56.9 & 63.3 \\
        $\mathrm{AlBERTv1}_\mathrm{xlarge}$  & 10.3 & 28.0 & 32.6 \\
        $\mathrm{AlBERTv1}_\mathrm{xxlarge}$  & 12.1  & 48.6 & 57.3 \\
        $\mathrm{AlBERTv2}_\mathrm{base}$  & 2.0 & 18.8 &  29.2\\
        $\mathrm{AlBERTv2}_\mathrm{large}$  & 10.6 & 46.8 & 55.6 \\
        $\mathrm{AlBERTv2}_\mathrm{xlarge}$ & 24.7 & 45.2 & 50.0 \\
        $\mathrm{AlBERTv2}_\mathrm{xxlarge}$ & 14.8 & 53.4 & 62.8 \\
        $\mathrm{T5}_\mathrm{small}$  & 1.7 & 43.6 & 51.6 \\
        $\mathrm{T5}_\mathrm{base}$ & 21.4 & 65.6 & 71.3 \\
        $\mathrm{T5}_\mathrm{large}$  & 22.7 & 68.3 & 73.8 \\
        $\mathrm{T5}_\mathrm{xl}$ &  \bf{39.7} & 66.2 & 69.9 \\
        $\mathrm{GPT2}_\mathrm{base}$  &  0.0 & 57.1 &  63.6\\
        $\mathrm{GPT2}_\mathrm{medium}$ & 0.0 & 69.5 & 73.2 \\
        $\mathrm{GPT2}_\mathrm{large}$  & 0.0 & 70.0 &  75.7\\
        $\mathrm{GPT2}_\mathrm{xl}$ & 0.0 & 70.1 & 75.6 \\
        $\mathrm{GPT3}$ & 27.5 & N/A & N/A \\
        $\mathrm{GPT3}_\mathrm{prompt}$ & 21.8 & N/A & N/A  \\
      
      
        \bottomrule
\end{tabular}
\caption{Zero-shot top-1,10 and 20 word prediction accuracy on NEG-1500-SIMP-TEMP. Top-5 is selected over the whole model vocabulary. The best result on each task is highlighted in bold. SIMP stands for simple, TEMP stands for template. Negation tasks are evaluated in the affirmative form (\textit{aff}). GPT3 only produces top 5 predictions. 
}
\label{tab:neg_temp_accuracy_top20}
\end{table*}
\endgroup

\begingroup
\begin{table*}[ht]
\centering
\small
\begin{tabular}{ l | c c c }
\toprule
NEG-1500-SIMP-GEN & \thead{Top 1} & \thead{Top 10} & \thead{Top 20}  \\
\midrule
        $\mathrm{BERT}_\mathrm{base}$ & 18.8 & 66.0 & 73.3 \\ 
        $\mathrm{BERT}_\mathrm{large}$ & 22.8 & 64.3 &  72.0 \\ 
        $\mathrm{RoBERTa}_\mathrm{base}$ & 15.4 & 51.6 & 60.1 \\
        $\mathrm{RoBERTa}_\mathrm{large}$ & 24.4 & 61.6  & 71.7  \\ 
        $\mathrm{DistilBERT}_\mathrm{base}$  & 22.5 & 61.9 & 70.5  \\
        $\mathrm{AlBERTv1}_\mathrm{base}$ & 11.2 & 46.0 & 53.6  \\
        $\mathrm{AlBERTv1}_\mathrm{large}$   & 12.9 & 50.5  & 59.6  \\
        $\mathrm{AlBERTv1}_\mathrm{xlarge}$  & 7.2 & 34.4 & 41.6  \\
        $\mathrm{AlBERTv1}_\mathrm{xxlarge}$  & 12.4 & 50.7 & 60.7  \\
        $\mathrm{AlBERTv2}_\mathrm{base}$  & 2.5 & 22.2 & 32.3 \\
        $\mathrm{AlBERTv2}_\mathrm{large}$   & 10.7 & 44.8 & 54.7  \\
        $\mathrm{AlBERTv2}_\mathrm{xlarge}$ & 24.0 & 56.5 & 64.5  \\
        $\mathrm{AlBERTv2}_\mathrm{xxlarge}$ & 15.3 & 55.3 & 54.1  \\
        $\mathrm{T5}_\mathrm{small}$ & 2.9 & 36.3 &  45.6 \\
        $\mathrm{T5}_\mathrm{base}$ & 15.1 & 65.5 & 65.3  \\
        $\mathrm{T5}_\mathrm{large}$ & 15.1 & 60.5 & 68.3  \\
        $\mathrm{T5}_\mathrm{xl}$  & 39.7 & 66.2 & 69.9  \\
        $\mathrm{GPT2}_\mathrm{base}$ & 16.4 & 48.0 & 60.0 \\
        $\mathrm{GPT2}_\mathrm{medium}$ & 26.1 & 56.1 & 66.9  \\
        $\mathrm{GPT2}_\mathrm{large}$ & 29.3 & 60.7 & 69.6 \\
        $\mathrm{GPT2}_\mathrm{xl}$ & 30.4 & 60.1 & 70.4 \\
        $\mathrm{GPT3}$ & 26.5  & N/A & N/A \\
        $\mathrm{GPT3}_\mathrm{prompt}$ & 24.3  & N/A & N/A  \\
      
        \bottomrule
\end{tabular}
\caption{Zero-shot top-1,10 and 20 word prediction accuracy on NEG-1500-SIMP-GEN. Top-5 is selected over the whole model vocabulary. The best result on each task is highlighted in bold. SIMP stands for simple, negation tasks is evaluated in the affirmative form. GPT3 allow only till top 5 predictions. 
}
\label{tab:neg_accuracy_top20}
\end{table*}
\endgroup

\begingroup
\begin{table*}[ht]
\centering
\small
\begin{tabular}{ l | c c c }
\toprule
ROLE-1500 & \thead{Top 1} & \thead{Top 10} & \thead{Top 20}  \\
\midrule
        $\mathrm{BERT}_\mathrm{base}$  & 6.7 & 28.1 & 38.9 \\ 
        $\mathrm{BERT}_\mathrm{large}$ & 9.1 & 30.9 & 40.7 \\ 
        $\mathrm{RoBERTa}_\mathrm{base}$  & 0 & 33.9 & 47.3 \\
        $\mathrm{RoBERTa}_\mathrm{large}$ &  0 & \bf{38.6} & \bf{52} \\ 
        $\mathrm{DistilBERT}_\mathrm{base}$  & 6.5 & 27.3 & 36.9 \\
        $\mathrm{AlBERTv1}_\mathrm{base}$ & 2.8 & 16.2 & 25.3 \\
        $\mathrm{AlBERTv1}_\mathrm{large}$  & 4.8 & 24.2 & 32.7 \\
        $\mathrm{AlBERTv1}_\mathrm{xlarge}$  & 7.2 & 27.3 & 35.5 \\
        $\mathrm{AlBERTv1}_\mathrm{xxlarge}$  &  \bf{12.2} & 37.2 & 45.1 \\
        $\mathrm{AlBERTv2}_\mathrm{base}$  & 6.2 & 22.7 & 29.9 \\
        $\mathrm{AlBERTv2}_\mathrm{large}$  & 5.9 & 27.0 & 36.1 \\
        $\mathrm{AlBERTv2}_\mathrm{xlarge}$ & 8.8 & 29.6 & 37.9 \\
        $\mathrm{AlBERTv2}_\mathrm{xxlarge}$ & 11.6 & 37.1 & 45.1 \\
        $\mathrm{T5}_\mathrm{small}$  & 1.3 & 12.1 & 18.3 \\
        $\mathrm{T5}_\mathrm{base}$ & 4.7 & 21.9 & 28.5 \\
        $\mathrm{T5}_\mathrm{large}$  & 6.2 & 25.3 & 31.3 \\
        $\mathrm{T5}_\mathrm{xl}$ & 7.9  & 29.0 & 36.5 \\
        $\mathrm{GPT2}_\mathrm{base}$  & 0  & 18.9 & 27.1 \\
        $\mathrm{GPT2}_\mathrm{medium}$ & 0 & 25.2 & 36.5 \\
        $\mathrm{GPT2}_\mathrm{large}$  & 0 & 27.0 & 37.7 \\
        $\mathrm{GPT2}_\mathrm{xl}$ & 0 & 29.9 & 38.8 \\
        $\mathrm{GPT3}$ & 7.7 & N/A & N/A \\
        $\mathrm{GPT3}_\mathrm{prompt}$ & 5.7 & N/A & N/A  \\
      
        \bottomrule
\end{tabular}
\caption{Zero-shot top-1,10 and 20 word prediction accuracy on ROLE-1500. Top-5 is selected over the whole model vocabulary. The best result on each task is highlighted in bold. GPT3 produces only top 5 predictions. 
}
\label{tab:role_accuracy_top20}
\end{table*}
\endgroup
\end{document}
