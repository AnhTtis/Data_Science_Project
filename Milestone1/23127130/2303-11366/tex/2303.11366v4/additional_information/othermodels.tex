We further investigated the applicability of trial-and-error problem-solving with
models of various strengths. We found that the ability to specify self-corrections
is an emergent quality of stronger, larger models.

\begin{table}[htbp]
  \centering
  \begin{tabular}{lll}
    \cmidrule(r){1-3}
    \textbf{Approach} & 
    \textbf{Pass@1 accuracy (avg over 8 trials)} &
    \textbf{Pass@1 accuracy (std)} \\
    \midrule
     Baseline & 0.26 & 0.00481 \\
     Reflexion & 0.26 & 0.00305 \\
    \bottomrule
  \end{tabular}
  \caption{Pass@1 accuracy on HumanEval Python using starchat-beta~\citep{li2023starcoder}.}
  \label{tbl:programming:starchat}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{lll}
    \cmidrule(r){1-3}
    \textbf{Model} & 
    \textbf{Baseline accuracy} &
    \textbf{Reflexion accuracy} \\
    \midrule
     CoT (GT) + text-davinci-003 & 0.60 & \textbf{0.77} \\
     CoT (GT) + gpt-3.5-turbo & 0.57 & \textbf{0.71} \\
     CoT (GT) + gpt-4 & 0.68 & \textbf{0.80} \\
     ReAct + text-davinci-003 & 0.30 & \textbf{0.55} \\
     ReAct + gpt-3.5-turbo & 0.26 & \textbf{0.38} \\
     ReAct + gpt-4 & 0.39 & \textbf{0.51} \\
    \bottomrule
  \end{tabular}
  \caption{Pass@1 accuracy on 100 HotPotQA using various models.}
  \label{tbl:reasoning:othermodels}
\end{table}