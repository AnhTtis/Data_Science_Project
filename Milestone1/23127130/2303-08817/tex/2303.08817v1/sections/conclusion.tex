\section{Conclusion}
In this paper, we shift our focus from designing reconstruction targets to the question of where to apply the reconstruction loss. 
We find intermediate features from shallower Transformer blocks also have predictive power for reconstruction and that improving these features during training improves the quality of learned representation over the whole model. 
Therefore, we propose \methodName that applies deep supervision on the intermediate features with extra decoders and hybrid targets to provide appropriate supervision for less discriminative intermediate features. 
Our experiments demonstrate that \methodName is compatible with a range masked image modeling frameworks and produces consistent improvements over strong baselines.