
\begin{table}[t]
% \small
\begin{center}
\caption{ \red{Comparison with translation model, \ie, M2M100-418M~\cite{fan2021beyond}, for multilingual generation. The Multilingual-CLIP$ \uparrow$ score over Crossmodal~\cite{thapliyal2022crossmodal} benchmark is reported here. GlueNetR denotes the re-weighted objective as described in Sec.~\ref{sec:cross-modal}.} }
\label{tabs:multilingual}
\scalebox{1}{
\begin{threeparttable}
 \centering
  \begin{tabular}{c c c c}
  \toprule[1.25pt]
\multicolumn{1}{c}{ } & {M2M100~\cite{fan2021beyond}} &
  
  {GlueNet} &
  
  {GlueNetR}
  
  \\
   \hline

{Chinese} &\bf 24.50 &22.01 &23.17   \\
{Franch} &\bf 25.08 &23.09  &23.91 \\
{Spanish} & 23.83 &22.91  &\bf24.18 \\
{Japanese} &23.73 & 23.99  &\bf24.23 \\
{Italian} &21.08 &22.40   &\bf 22.88 \\
  \hline
  {Average} &23.64 & 22.88   &\bf 23.67 \\
 \bottomrule[1.25pt]
\end{tabular}
\renewcommand{\labelitemi}{}
\end{threeparttable}
}
\end{center}
\end{table}