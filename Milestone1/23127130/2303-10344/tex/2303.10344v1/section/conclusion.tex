
\section{Conclusion}
Locale-aware indoor illumination estimation can be decomposed into three sub-tasks: depth-based image warping, panorama inpainting and HDR panorama reconstruction. In this paper, we propose a novel local-to-global panorama inpainting pipeline that well solves the second sub-task, significantly improving the performance of the spatially-varying indoor lighting estimation. In the pipeline, a depth-guided local inpainting module is first applied to fill holes due to pixel stretching. For global inpainting, we resort to a transformer-based network that captures distortion-free features from cubemap projection and enables physically-plausible reconstruction of global structures in the large out-of-view regions. We have validated our state-of-the-art performance through qualitative and quantitative comparisons against previous methods. Ablation studies further exemplify that the specially-designed large-scale panorama inpainting pipeline is able to produce perceptually plausible details coherent with the scene, leading to realistic shading after virtual object insertion. 
