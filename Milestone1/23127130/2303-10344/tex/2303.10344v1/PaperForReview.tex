% CVPR 2023 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
% \usepackage[review]{cvpr}      % To produce the REVIEW version
\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{color} 
\usepackage{multirow} 
\usepackage{algorithm}  
\usepackage{algpseudocode}  
\usepackage{amsmath}  
% \usepackage{authblk}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}  % Use Input in the format of Algorithm  
\renewcommand{\algorithmicensure}{\textbf{Output:}} % Use Output in the format of Algorithm  
% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{424} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Local-to-Global Panorama Inpainting for Locale-Aware Indoor Lighting Prediction}


\author{Jiayang Bai$^1$, Zhen He$^1$, Shan Yang$^1$, Jie Guo$^1$\footnotemark[1], Zhenyu Chen$^1$, Yan Zhang$^1$, YanwenGuo$^1$\\
$^{1}$Nanjing University, Nanjing, China\\
{\tt\small  \{jybai, hz,yangshan\}@smail.nju.edu.cn guojie@nju.edu.cn}\\
{\tt\small MF21330012@smail.nju.edu.cn \{zhangyannju, ywguo\}@nju.edu.cn}
}

% \author{Jiayang Bai\\
% Nanjing University\\
% {\tt\small jybai@smail.nju.edu.cn}
% % For a paper whose authors are all at the same institution,
% % omit the following lines up until the closing ``}''.
% % Additional authors and addresses can be added with ``\and'',
% % just like the second author.
% % To save space, use either the email address or home page, not both
% \and
% Zhen He\\
% % Nanjing University\\
% {\tt\small hz@smail.nju.edu.cn}
% \and
% Shan Yang\\
% Nanjing University\\
% {\tt\small yangshan@smail.nju.edu.cn}
% \and
% Jie Guo\\
% Nanjing University\\
% {\tt\small guojie@nju.edu.cn}
% \and
% Zhenyu Chen\\
% Nanjing University\\
% {\tt\small MF21330012@smail.nju.edu.cn}
% \and
% Yan Zhang\\
% Nanjing University\\
% {\tt\small zhangyannju@nju.edu.cn}
% \and
% Yanwen Guo\\
% Nanjing University\\
% {\tt\small ywguo@nju.edu.cn}
% }
% \maketitle

\twocolumn[{
\renewcommand\twocolumn[1][]{#1}
\maketitle
\centering
\vspace{-0.4cm}
\includegraphics[width=\textwidth]{figures/methods/teaser_v2.pdf}
\vspace{-0.5cm}
\captionsetup{type=figure}
\caption{We propose a locale-aware indoor illumination prediction method that can generate a full and texture-rich HDR panorama (the third column in each group) at any locale in the scene, enabling spatially-varying and consistent shading after virtual object insertion (the first and second columns).}
\label{fig:teaser}

\vspace{0.7cm}
}]
\footnotetext[1]{Corresponding author.}

%%%%%%%%% ABSTRACT
\begin{abstract}
Predicting panoramic indoor lighting from a single perspective image is a fundamental but highly ill-posed problem in computer vision and graphics. To achieve locale-aware and robust prediction, this problem can be decomposed into three sub-tasks: depth-based image warping, panorama inpainting and high-dynamic-range (HDR) reconstruction, among which the success of panorama inpainting plays a key role. Recent methods mostly rely on convolutional neural networks (CNNs) to fill the missing contents in the warped panorama. However, they usually achieve suboptimal performance since the missing contents occupy a very large portion in the panoramic space while CNNs are plagued by limited receptive fields. The spatially-varying distortion in the spherical signals further increases the difficulty for conventional CNNs.
To address these issues, we propose a \emph{local-to-global strategy} for large-scale panorama inpainting. In our method, a depth-guided local inpainting is first applied on the warped panorama to fill small but dense holes. Then, a transformer-based network, dubbed \emph{PanoTransformer}, is designed to hallucinate reasonable global structures in the large holes. 
To avoid distortion, we further employ cubemap projection in our design of PanoTransformer. The high-quality panorama recovered at any locale helps us to capture spatially-varying indoor illumination with physically-plausible global structures and fine details. 
\end{abstract}

%%%%%%%%% BODY TEXT
\input{section/introduction}

\input{section/related}

\input{section/method_v2}

\input{section/result}

\input{section/conclusion}

%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{acmart}
}

\end{document}
