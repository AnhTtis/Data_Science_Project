%%Conference:
% @STRING{ICLR  = " Proceedings of  International Conference on Learning Representations"}
% @STRING{ICCV  = "Proceedings of  IEEE International Conference on Computer Vision"}
% @STRING{MICCAI  = "Proceedings of  International Conference on Medical Image Computing and Computer-Assisted Intervention"}
% @STRING{CVPR  = "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"}
% @STRING{CVPRW = "Computer Vision and Pattern Recognition Workshops"}
% @STRING{ECCV  = "Proceedings of European Conference on Computer Vision"}
% @STRING{IJCAI = "Proceedings of  International Joint Conference on Artificial Intelligence"}
% @string{NIPS  = "Proceedings of International Conference and Workshop on Neural Information Processing Systems"}
% @string{BMVC  = "Proceedings of British Machine Vision Conference"}
% @STRING{ICIP  = "Proceedings of International Conference on Image Processing"}
% @STRING{ICPR  = "Proceedings of International Conference on Pattern Recognition"}
% @STRING{FG    = "Proceedings of International Conference on Automatic Face and Gesture Recognition"}
% @STRING{ICASSP= "Proceedings of International Conference on Acoustics, Speech and Signal Processing"}

@STRING{ICLR  = " ICLR"}
@STRING{ICML  = " ICML"}
@STRING{ICCV  = "ICCV"}
@STRING{MICCAI  = "MICCAI"}
@STRING{CVPR  = "CVPR"}
@STRING{CVPRW = "CVPRW"}
@STRING{ECCV  = "ECCV"}
@STRING{IJCAI = "IJCAI"}
@string{NIPS  = "NeurIPS"}
@string{BMVC  = "BMVC"}
@STRING{ICIP  = "ICIP"}
@STRING{ICPR  = "ICPR"}
@STRING{FG    = "FG"}
@STRING{ICASSP= "ICASSP"}
@STRING{ICRA  = "ICRA"}
@STRING{IROS  = "IROS"}
@STRING{AAAI  = "AAAI"}
@STRING{ThreeDV  = "3DV"}
@STRING{ACMMM  = "ACM MM"}
@STRING{ACL  = "ACL"}
%%Journal:
% @STRING{PAMI  = "IEEE Transactions on Pattern Analysis and Machine Intelligence"}
% @STRING{IJCV  = "International Journal of Computer Vision"}
% @STRING{CVIU  = "Computer Vision and Image Understanding"}
% @STRING{TNN   = "IEEE Transactions on Neural Networks"}
% @STRING{TIP   = "IEEE Transactions on Image Processing"}
% @STRING{TSP   = "IEEE Transactions on Signal Processing"}
% @STRING{PIEEE = "Proceedings of the IEEE"}
% @STRING{PRL   = "Pattern Recognition Letters"}
% @STRING{PR    = "Pattern Recognition"}
% @STRING{NC    = "Neural Computation"}
% @STRING{IVC   = "Image and Vision Computing"}
% @STRING{IJRR  = "International Journal of Robotics Research"}
% @STRING{JMLR  = "Journal of Machine Learning Research"}
% @STRING{CoRR  ="Computing Research Repository"}
@STRING{TPAMI  = "IEEE TPAMI"}
@STRING{TGRS  = "IEEE TGRS"}
@STRING{IJCV  = "IJCV"}
@STRING{CVIU  = "CVIU"}
@STRING{TNN   = "IEEE TNN"}
@STRING{TIP   = "IEEE TIP"}
@STRING{TSP   = "IEEE TSP"}
@STRING{TMM   = "IEEE TMM"}
@STRING{TMI   = "IEEE TMI"}
@STRING{PIEEE = "Proc. of the IEEE"}
@STRING{PRL   = "PRL"}
@STRING{PR    = "Pattern Recognition"}
@STRING{NC    = "Neural Computation"}
@STRING{IVC   = "IVC"}
@STRING{IJRR  = "IJRR"}
@STRING{JMLR  = "JMLR"}
@STRING{CoRR  ="Computing Research Repository"}
@STRING{TCSVT  = "IEEE TCSVT"}
@STRING{SPL  = "IEEE SPL"}
@STRING{TNNLS   = "IEEE TNNLS"}



%Survey
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Datasets%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%RGB SOD
@article{MSRA10K,
  title   = {Global contrast based salient region detection},
  author  = {Cheng, Ming-Ming and Mitra, Niloy J and Huang, Xiaolei and Torr, Philip HS and Hu, Shi-Min},
  journal = TPAMI,
  volume  = {37},
  pages   = {569--582},
  year    = {2014},
}

@article{MSRA-B,
  title   = {Learning to detect a salient object},
  author  = {Liu, Tie and Yuan, Zejian and Sun, Jian and Wang, Jingdong and Zheng, Nanning and Tang, Xiaoou and Shum, Heung-Yeung},
  journal = TPAMI,
  volume  = {33},
  pages   = {353--367},
  year    = {2010},
}

@article{BSDS500,
  title   = {Contour detection and hierarchical image segmentation},
  author  = {Arbelaez, Pablo and Maire, Michael and Fowlkes, Charless and Malik, Jitendra},
  journal = TPAMI,
  volume  = {33},
  pages   = {898--916},
  year    = {2010},
}

@inproceedings{ECSSD,
  title     = {Hierarchical saliency detection},
  author    = {Yan, Qiong and Xu, Li and Shi, Jianping and Jia, Jiaya},
  booktitle = CVPR,
  pages     = {1155--1162},
  year      = {2013},
}

@inproceedings{PASCAL-S,
  title     = {The secrets of salient object segmentation},
  author    = {Li, Yin and Hou, Xiaodi and Koch, Christof and Rehg, James M and Yuille, Alan L},
  booktitle = CVPR,
  pages     = {280--287},
  year      = {2014},
}

@article{PASCAL-VOC,
  title   = {The pascal visual object classes (voc) challenge},
  author  = {Everingham, Mark and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal = IJCV,
  volume  = {88},
  number  = {2},
  pages   = {303--338},
  year    = {2010},
}

@inproceedings{DUT-OMRON,
  title     = {Saliency detection via graph-based manifold ranking},
  author    = {Yang, Chuan and Zhang, Lihe and Lu, Huchuan and Ruan, Xiang and Yang, Ming-Hsuan},
  booktitle = CVPR,
  pages     = {3166--3173},
  year      = {2013},
}

@inproceedings{HKU-IS,
  title     = {Visual saliency based on multiscale deep features},
  author    = {Li, Guanbin and Yu, Yizhou},
  booktitle = CVPR,
  pages     = {5455--5463},
  year      = {2015},
}

@inproceedings{DUTS,
  title     = {Learning to detect salient objects with image-level supervision},
  author    = {Wang, Lijun and Lu, Huchuan and Wang, Yifan and Feng, Mengyang and Wang, Dong and Yin, Baocai and Ruan, Xiang},
  booktitle = CVPR,
  pages     = {136--145},
  year      = {2017},
}

%%%%%%%%%%%%%%%%%%%RGB-D SOD
@inproceedings{NJUD,
  title     = {Depth saliency based on anisotropic center-surround difference},
  author    = {Ju, Ran and Ge, Ling and Geng, Wenjing and Ren, Tongwei and Wu, Gangshan},
  booktitle = ICIP,
  pages     = {1115--1119},
  year      = {2014},
}

@inproceedings{RGBD135,
  title     = {Depth enhanced saliency detection method},
  author    = {Cheng, Yupeng and Fu, Huazhu and Wei, Xingxing and Xiao, Jiangjian and Cao, Xiaochun},
  booktitle = {ICIMCS},
  pages     = {23},
  year      = {2014},
}

@inproceedings{LFSD,
  title     = {Saliency detection on light field},
  author    = {Li, Nianyi and Ye, Jinwei and Ji, Yu and Ling, Haibin and Yu, Jingyi},
  booktitle = CVPR,
  pages     = {2806--2813},
  year      = {2014},
}

@inproceedings{SSD,
  title     = {A three-pathway psychobiological framework of salient object detection using stereoscopic technology},
  author    = {Zhu, Chunbiao and Li, Ge},
  booktitle = {ICCVW},
  pages     = {3008--3014},
  year      = {2017},
}

@inproceedings{DLFC,
  title     = {Depth from combining defocus and correspondence using light-field cameras},
  author    = {Tao, Michael W and Hadap, Sunil and Malik, Jitendra and Ramamoorthi, Ravi},
  booktitle = ICCV,
  pages     = {673--680},
  year      = {2013},
}

@article{D3Net_RGBDSOD,
  title   = {Rethinking RGB-D salient object detection: Models, data sets, and large-scale benchmarks},
  author  = {Fan, Deng-Ping and Lin, Zheng and Zhang, Zhao and Zhu, Menglong and Cheng, Ming-Ming},
  journal = TNNLS,
  volume  = {32},
  pages   = {2075--2089},
  year    = {2020},
}

@inproceedings{STERE,
  title     = {Leveraging stereopsis for saliency analysis},
  author    = {Niu, Yuzhen and Geng, Yujie and Li, Xueqing and Liu, Feng},
  booktitle = CVPR,
  pages     = {454--461},
  year      = {2012},
}

@article{DUTLF-V2,
  title   = {DUT-LFSaliency: Versatile Dataset and Light Field-to-RGB Saliency Detection},
  author  = {Piao, Yongri and Rong, Zhengkun and Xu, Shuang and Zhang, Miao and Lu, Huchuan},
  journal = {arXiv preprint arXiv:2012.15124},
  year    = {2020},
}

@inproceedings{DMRA_RGBDSOD,
  title     = {Depth-Induced Multi-Scale Recurrent Attention Network for Saliency Detection},
  author    = {Piao, Yongri and Ji, Wei and Li, Jingjing and Zhang, Miao and Lu, Huchuan},
  booktitle = ICCV,
  pages     = {7254--7263},
  year      = {2019},
}

@inproceedings{NLPR,
  title     = {RGBD salient object detection: A benchmark and algorithms},
  author    = {Peng, Houwen and Li, Bing and Xiong, Weihua and Hu, Weiming and Ji, Rongrong},
  booktitle = ECCV,
  pages     = {92--109},
  year      = {2014},
}



 %%%%%%%%%%%%%%%%%%%ORSI SOD
 @article{LV-Net_RSISOD,
  title   = {Nested network with two-stream pyramid for salient object detection in optical remote sensing images},
  author  = {Li, Chongyi and Cong, Runmin and Hou, Junhui and Zhang, Sanyi and Qian, Yue and Kwong, Sam},
  journal = TGRS,
  volume  = {57},
  pages   = {9156--9166},
  year    = {2019},
}

@article{DAFNet_RSISOD,
  title   = {Dense attention fluid network for salient object detection in optical remote sensing images},
  author  = {Zhang, Qijian and Cong, Runmin and Li, Chongyi and Cheng, Ming-Ming and Fang, Yuming and Cao, Xiaochun and Zhao, Yao and Kwong, Sam},
  journal = TIP,
  volume  = {30},
  pages   = {1305--1317},
  year    = {2020},
}

@article{MJRBM_RSISOD,
  title   = {ORSI Salient Object Detection via Multiscale Joint Region and Boundary Model},
  author  = {Zhengzheng Tu and Chao Wang and Chenglong Li and Minghao Fan and Haifeng Zhao and Bin Luo},
  journal = TGRS,
  year    = {2022},
  volume  = {60},
  pages   = {1-13},
}

@inproceedings{Cityscapes,
  title={The cityscapes dataset for semantic urban scene understanding},
  author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
  booktitle=CVPR,
  pages={3213--3223},
  year={2016}
}
 %%%%%%%%%%%%%%%%%%%COD

@article{CHAMELEON,
  title   = {Animal camouflage analysis: Chameleon database},
  author  = {Skurowski, P and Abdulameer, H and B{\l}aszczyk, J and Depta, T and Kornacki, A and Kozie{\l}, P},
  journal = {Unpublished Manuscript},
  year    = {2018},
}

@article{CAMO,
  title   = {Anabranch network for camouflaged object segmentation},
  author  = {Le, Trung-Nghia and Nguyen, Tam V and Nie, Zhongliang and Tran, Minh-Triet and Sugimoto, Akihiro},
  journal = CVIU,
  volume  = {184},
  pages   = {45--56},
  year    = {2019},
}

@inproceedings{SINet_COD,
  title     = {Camouflaged object detection},
  author    = {Fan, Deng-Ping and Ji, Ge-Peng and Sun, Guolei and Cheng, Ming-Ming and Shen, Jianbing and Shao, Ling},
  booktitle = CVPR,
  pages     = {2777--2787},
  year      = {2020},
}

@inproceedings{Rank-Net_COD,
  title     = {Simultaneously localize, segment and rank the camouflaged objects},
  author    = {Lv, Yunqiu and Zhang, Jing and Dai, Yuchao and Li, Aixuan and Liu, Bowen and Barnes, Nick and Fan, Deng-Ping},
  booktitle = CVPR,
  pages     = {11591--11601},
  year      = {2021},
}

 %%%%%%%%%%%%%%%%%%%DBD
@inproceedings{CUHK,
  title     = {Discriminative blur detection features},
  author    = {Shi, Jianping and Xu, Li and Jia, Jiaya},
  booktitle = CVPR,
  pages     = {2965--2972},
  year      = {2014},
}

@inproceedings{BTBNet_DBD,
  title     = {Defocus blur detection via multi-stream bottom-top-bottom fully convolutional network},
  author    = {Zhao, Wenda and Zhao, Fan and Wang, Dong and Lu, Huchuan},
  booktitle = CVPR,
  pages     = {3080--3088},
  year      = {2018},
}

 %%%%%%%%%%%%%%%%%%%Shadow detection
@inproceedings{SBU,
  title     = {Large-scale training of shadow detectors with noisily-annotated shadow examples},
  author    = {Vicente, Tom{\'a}s F Yago and Hou, Le and Yu, Chen-Ping and Hoai, Minh and Samaras, Dimitris},
  booktitle = ECCV,
  pages     = {816--832},
  year      = {2016},
}

@inproceedings{ISTD,
  title     = {Stacked conditional generative adversarial networks for jointly learning shadow detection and shadow removal},
  author    = {Wang, Jifeng and Li, Xiang and Yang, Jian},
  booktitle = CVPR,
  pages     = {1788--1797},
  year      = {2018},
}

@inproceedings{UCF,
  title     = {Learning to recognize shadows in monochromatic natural images},
  author    = {Zhu, Jiejie and Samuel, Kegan GG and Masood, Syed Z and Tappen, Marshall F},
  booktitle = CVPR,
  pages     = {223--230},
  year      = {2010},
}

 %%%%%%%%%%%%%%%%%%%Transparent detection
@inproceedings{TransLab_Transparent,
  title     = {Segmenting transparent objects in the wild},
  author    = {Xie, Enze and Wang, Wenjia and Wang, Wenhai and Ding, Mingyu and Shen, Chunhua and Luo, Ping},
  booktitle = ECCV,
  pages     = {696--711},
  year      = {2020},
}

@inproceedings{Trans2Seg_Transparent,
  title     = {Segmenting Transparent Objects in the Wild with Transformer},
  author    = {Xie, Enze and Wang, Wenjia and Wang, Wenhai and Sun, Peize and Xu, Hang and Liang, Ding and Luo, Ping},
  booktitle = IJCAI,
  pages     = {1194--1200},
  year      = {2021},
}

 %%%%%%%%%%%%%%%%%%%Glass detection
@inproceedings{GDNet_Glass,
  title     = {Don't hit me! glass detection in real-world scenes},
  author    = {Mei, Haiyang and Yang, Xin and Wang, Yang and Liu, Yuanyuan and He, Shengfeng and Zhang, Qiang and Wei, Xiaopeng and Lau, Rynson WH},
  booktitle = CVPR,
  pages     = {3687--3696},
  year      = {2020},
}

 %%%%%%%%%%%%%%%%%%%Mirror detection
@inproceedings{MirrorNet_Mirror,
  title     = {Where is my mirror?},
  author    = {Yang, Xin and Mei, Haiyang and Xu, Ke and Wei, Xiaopeng and Yin, Baocai and Lau, Rynson WH},
  booktitle = ICCV,
  pages     = {8809--8818},
  year      = {2019},
}

 %%%%%%%%%%%%%%%%%%%Polyp Segmentation
@article{CVC-ColonDB,
  title   = {Automated polyp detection in colonoscopy videos using shape and context information},
  author  = {Tajbakhsh, Nima and Gurudu, Suryakanth R and Liang, Jianming},
  journal = TMI,
  volume  = {35},
  pages   = {630--644},
  year    = {2015},
}

@article{CVC-ClinicDB,
  title   = {WM-DOVA maps for accurate polyp highlighting in colonoscopy: Validation vs. saliency maps from physicians},
  author  = {Bernal, Jorge and S{\'a}nchez, F Javier and Fern{\'a}ndez-Esparrach, Gloria and Gil, Debora and Rodr{\'\i}guez, Cristina and Vilari{\~n}o, Fernando},
  journal = {CMIG},
  volume  = {43},
  pages   = {99--111},
  year    = {2015},
}

@article{Endoscene,
  title   = {A benchmark for endoluminal scene segmentation of colonoscopy images},
  author  = {V{\'a}zquez, David and Bernal, Jorge and S{\'a}nchez, F Javier and Fern{\'a}ndez-Esparrach, Gloria and L{\'o}pez, Antonio M and Romero, Adriana and Drozdzal, Michal and Courville, Aaron},
  journal = {JHE},
  volume  = {2017},
  year    = {2017},
}

@article{ETIS,
  title   = {Toward embedded detection of polyps in wce images for early diagnosis of colorectal cancer},
  author  = {Silva, Juan and Histace, Aymeric and Romain, Olivier and Dray, Xavier and Granado, Bertrand},
  journal = {IJCARS},
  volume  = {9},
  pages   = {283--293},
  year    = {2014},
}

@inproceedings{Kvasir,
  title     = {Kvasir-seg: A segmented polyp dataset},
  author    = {Jha, Debesh and Smedsrud, Pia H and Riegler, Michael A and Halvorsen, P{\aa}l and Lange, Thomas de and Johansen, Dag and Johansen, H{\aa}vard D},
  booktitle = {MMM},
  pages     = {451--462},
  year      = {2020},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Metrics%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{colorcontrast_Fm,
  title     = {Frequency-tuned salient region detection},
  author    = {Achanta, Radhakrishna and Hemami, Sheila and Estrada, Francisco and S{\"u}sstrunk, Sabine},
  booktitle = CVPR,
  pages     = {1597--1604},
  year      = {2009},
}

@article{E-m,
  title   = {Enhanced-alignment measure for binary foreground map evaluation},
  author  = {Fan, Deng-Ping and Gong, Cheng and Cao, Yang and Ren, Bo and Cheng, Ming-Ming and Borji, Ali},
  journal = {arXiv preprint arXiv:1805.10421},
  year    = {2018},
}

@inproceedings{Fwb,
  title     = {How to evaluate foreground maps?},
  author    = {Margolin, Ran and Zelnik-Manor, Lihi and Tal, Ayellet},
  booktitle = CVPR,
  pages     = {248--255},
  year      = {2014},
}

@inproceedings{S-m,
  title     = {Structure-measure: A new way to evaluate foreground maps},
  author    = {Fan, Deng-Ping and Cheng, Ming-Ming and Liu, Yun and Li, Tao and Borji, Ali},
  booktitle = ICCV,
  pages     = {4548--4557},
  year      = {2017},
}

@inproceedings{MAE,
  title     = {Saliency filters: Contrast based filtering for salient region detection},
  author    = {Perazzi, Federico and Kr{\"a}henb{\"u}hl, Philipp and Pritch, Yael and Hornung, Alexander},
  booktitle = CVPR,
  pages     = {733--740},
  year      = {2012},
}

@inproceedings{BER,
  title     = {Leave-one-out kernel optimization for shadow detection},
  author    = {Vicente, Tom{\'a}s F Yago and Hoai, Minh and Samaras, Dimitris},
  booktitle = ICCV,
  pages     = {3388--3396},
  year      = {2015},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Methods%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%RGB SOD
@article{U2Net,
  title   = {U2-Net: Going deeper with nested U-structure for salient object detection},
  author  = {Qin, Xuebin and Zhang, Zichen and Huang, Chenyang and Dehghan, Masood and Zaiane, Osmar R and Jagersand, Martin},
  journal = {Pattern Recognition},
  volume  = {106},
  pages   = {107404},
  year    = {2020},
}

@inproceedings{R3Net,
  title     = {R3Net: Recurrent residual refinement network for saliency detection},
  author    = {Deng, Zijun and Hu, Xiaowei and Zhu, Lei and Xu, Xuemiao and Qin, Jing and Han, Guoqiang and Heng, Pheng-Ann},
  booktitle = IJCAI,
  pages     = {684--690},
  year      = {2018},
}

@inproceedings{SFCN,
  title     = {Salient Object Detection by Lossless Feature Reflection},
  author    = {Pingping Zhang and W. Liu and Huchuan Lu and Chunhua Shen},
  booktitle = IJCAI,
  pages     = {1149â€“1155},
  year      = {2018},
}

@inproceedings{BMPM,
  title     = {A bi-directional message passing model for salient object detection},
  author    = {Zhang, Lu and Dai, Ju and Lu, Huchuan and He, You and Wang, Gang},
  booktitle = CVPR,
  pages     = {1741--1750},
  year      = {2018},
}

@inproceedings{PiCANet,
  title     = {PiCANet: Learning Pixel-Wise Contextual Attention for Saliency Detection},
  author    = {Nian Liu and Junwei Han and Ming-Hsuan Yang},
  booktitle = CVPR,
  year      = {2018},
  pages     = {3089-3098},
}

@inproceedings{PAGRN,
  title     = {Progressive attention guided recurrent network for salient object detection},
  author    = {Zhang, Xiaoning and Wang, Tiantian and Qi, Jinqing and Lu, Huchuan and Wang, Gang},
  booktitle = CVPR,
  pages     = {714--722},
  year      = {2018},
}

@inproceedings{DGRL,
  title     = {Detect globally, refine locally: A novel approach to saliency detection},
  author    = {Wang, Tiantian and Zhang, Lihe and Wang, Shuo and Lu, Huchuan and Yang, Gang and Ruan, Xiang and Borji, Ali},
  booktitle = CVPR,
  pages     = {3127--3135},
  year      = {2018},
}

@inproceedings{RAS,
  title     = {Reverse attention for salient object detection},
  author    = {Chen, Shuhan and Tan, Xiuli and Wang, Ben and Hu, Xuelong},
  booktitle = ECCV,
  pages     = {234--250},
  year      = {2018},
}

@inproceedings{DEF,
  title     = {Deep embedding features for salient object detection},
  author    = {Zhuge, Yunzhi and Zeng, Yu and Lu, Huchuan},
  booktitle = AAAI,
  pages     = {9340--9347},
  year      = {2019},
}

@inproceedings{AFNet,
  title     = {Attentive feedback network for boundary-aware salient object detection},
  author    = {Feng, Mengyang and Lu, Huchuan and Ding, Errui},
  booktitle = CVPR,
  pages     = {1623--1632},
  year      = {2019},
}

@inproceedings{BASNet,
  title     = {BASNet: Boundary-Aware Salient Object Detection},
  author    = {Qin, Xuebin and Zhang, Zichen and Huang, Chenyang and Gao, Chao and Dehghan, Masood and Jagersand, Martin},
  booktitle = CVPR,
  pages     = {7479--7489},
  year      = {2019},
}

@inproceedings{MLMS,
  title     = {A Mutual Learning Method for Salient Object Detection With Intertwined Multi-Supervision},
  author    = {Wu, Runmin and Feng, Mengyang and Guan, Wenlong and Wang, Dong and Lu, Huchuan and Ding, Errui},
  booktitle = CVPR,
  pages     = {8150--8159},
  year      = {2019},
}

@inproceedings{CPD,
  title     = {Cascaded Partial Decoder for Fast and Accurate Salient Object Detection},
  author    = {Wu, Zhe and Su, Li and Huang, Qingming},
  booktitle = CVPR,
  pages     = {3907--3916},
  year      = {2019},
}

@inproceedings{Capsal,
  title     = {CapSal: Leveraging Captioning to Boost Semantics for Salient Object Detection},
  author    = {Zhang, Lu and Zhang, Jianming and Lin, Zhe and Lu, Huchuan and He, You},
  booktitle = CVPR,
  pages     = {6024--6033},
  year      = {2019},
}

@inproceedings{PoolNet,
  title     = {A simple pooling-based design for real-time salient object detection},
  author    = {Liu, Jiang-Jiang and Hou, Qibin and Cheng, Ming-Ming and Feng, Jiashi and Jiang, Jianmin},
  booktitle = CVPR,
  pages     = {3917--3926},
  year      = {2019},
}

@inproceedings{PSSOD,
  title     = {An Iterative and Cooperative Top-down and Bottom-up Inference Network for Salient Object Detection},
  author    = {Wang, Wenguan and Shen, Jianbing and Cheng, Ming-Ming and Shao, Ling},
  booktitle = CVPR,
  pages     = {5968--5977},
  year      = {2019},
}

@inproceedings{PASE,
  title     = {Salient object detection with pyramid attention and salient edges},
  author    = {Wang, Wenguan and Zhao, Shuyang and Shen, Jianbing and Hoi, Steven CH and Borji, Ali},
  booktitle = CVPR,
  pages     = {1448--1457},
  year      = {2019},
}

@inproceedings{PFA,
  title     = {Pyramid Feature Attention Network for Saliency Detection},
  author    = {Zhao, Ting and Wu, Xiangqian},
  booktitle = CVPR,
  pages     = {3085--3094},
  year      = {2019},
}

@inproceedings{SCRN,
  title     = {Stacked cross refinement network for edge-aware salient object detection},
  author    = {Wu, Zhe and Su, Li and Huang, Qingming},
  booktitle = ICCV,
  pages     = {7264--7273},
  year      = {2019},
}

@inproceedings{BANet,
  title     = {Selectivity or invariance: Boundary-aware salient object detection},
  author    = {Su, Jinming and Li, Jia and Zhang, Yu and Xia, Changqun and Tian, Yonghong},
  booktitle = ICCV,
  pages     = {3799--3808},
  year      = {2019},
}

@inproceedings{HRS,
  title     = {Towards High-Resolution Salient Object Detection},
  author    = {Zeng, Yi and Zhang, Pingping and Zhang, Jianming and Lin, Zhe and Lu, Huchuan},
  booktitle = ICCV,
  pages     = {7234--7243},
  year      = {2019},
}

@inproceedings{EGNet,
  title     = {EGNet: Edge guidance network for salient object detection},
  author    = {Zhao, Jia-Xing and Liu, Jiang-Jiang and Fan, Deng-Ping and Cao, Yang and Yang, Jufeng and Cheng, Ming-Ming},
  booktitle = ICCV,
  pages     = {8779--8788},
  year      = {2019},
}

@inproceedings{DUCRF,
  title     = {Structured modeling of joint deep feature and prediction refinement for salient object detection},
  author    = {Xu, Yingyue and Xu, Dan and Hong, Xiaopeng and Ouyang, Wanli and Ji, Rongrong and Xu, Min and Zhao, Guoying},
  booktitle = ICCV,
  pages     = {3789--3798},
  year      = {2019},
}

@inproceedings{TSPOANet,
  title     = {Employing Deep Part-Object Relationships for Salient Object Detection},
  author    = {Liu, Yi and Zhang, Qiang and Zhang, Dingwen and Han, Jungong},
  booktitle = ICCV,
  pages     = {1232--1241},
  year      = {2019},
}

@inproceedings{PFPN,
  title     = {Progressive feature polishing network for salient object detection},
  author    = {Wang, Bo and Chen, Quan and Zhou, Min and Zhang, Zhiqiang and Jin, Xiaogang and Gai, Kun},
  booktitle = AAAI,
  pages     = {12128--12135},
  year      = {2020},
}

@inproceedings{GCPANet,
  title     = {Global context-aware progressive aggregation network for salient object detection},
  author    = {Chen, Zuyao and Xu, Qianqian and Cong, Runmin and Huang, Qingming},
  booktitle = AAAI,
  pages     = {10599--10606},
  year      = {2020},
}

@inproceedings{F3Net,
  title     = {F$^3$Net: Fusion, Feedback and Focus for Salient Object Detection},
  author    = {Wei, Jun and Wang, Shuhui and Huang, Qingming},
  booktitle = AAAI,
  pages     = {12321--12328},
  year      = {2020},
}

@inproceedings{MSANet,
  title     = {Multi-type self-attention guided degraded saliency detection},
  author    = {Zhou, Ziqi and Wang, Zheng and Lu, Huchuan and Wang, Song and Sun, Meijun},
  booktitle = AAAI,
  pages     = {13082--13089},
  year      = {2020},
}

@inproceedings{MINet,
  title     = {Multi-Scale Interactive Network for Salient Object Detection},
  author    = {Pang, Youwei and Zhao, Xiaoqi and Zhang, Lihe and Lu, Huchuan},
  booktitle = CVPR,
  pages     = {9413--9422},
  year      = {2020},
}

@inproceedings{ITSD,
  title     = {Interactive Two-Stream Decoder for Accurate and Fast Saliency Detection},
  author    = {Zhou, Huajun and Xie, Xiaohua and Lai, Jian-Huang and Chen, Zixuan and Yang, Lingxiao},
  booktitle = CVPR,
  pages     = {9141--9150},
  year      = {2020},
}

@inproceedings{LDF,
  title     = {Label decoupling framework for salient object detection},
  author    = {Wei, Jun and Wang, Shuhui and Wu, Zhe and Su, Chi and Huang, Qingming and Tian, Qi},
  booktitle = CVPR,
  pages     = {13025--13034},
  year      = {2020},
}

@inproceedings{CSNet,
  title     = {Highly efficient salient object detection with 100k parameters},
  author    = {Gao, Shang-Hua and Tan, Yong-Qiang and Cheng, Ming-Ming and Lu, Chengze and Chen, Yunpeng and Yan, Shuicheng},
  booktitle = ECCV,
  pages     = {702--721},
  year      = {2020},
}

@inproceedings{GateNet,
  title     = {Suppress and balance: A simple gated network for salient object detection},
  author    = {Zhao, Xiaoqi and Pang, Youwei and Zhang, Lihe and Lu, Huchuan and Zhang, Lei},
  booktitle = ECCV,
  pages     = {35--51},
  year      = {2020},
}

@inproceedings{PFS,
  title     = {Pyramidal Feature Shrinking for Salient Object Detection},
  author    = {Mingcan Ma and Changqun Xia and Jia Li},
  booktitle = AAAI,
  pages     = {2311-2318},
  year      = {2021},
}

@inproceedings{KRN,
  title     = {Locate Globally, Segment Locally: A Progressive Architecture With Knowledge Review Network for Salient Object Detection},
  author    = {Xu, Binwei and Liang, Haoran and Liang, Ronghua and Chen, Peng},
  booktitle = AAAI,
  pages     = {3004--3012},
  year      = {2021},
}

@inproceedings{JSODCOD,
  title     = {Uncertainty-aware joint salient object and camouflaged object detection},
  author    = {Li, Aixuan and Zhang, Jing and Lv, Yunqiu and Liu, Bowen and Zhang, Tong and Dai, Yuchao},
  booktitle = CVPR,
  pages     = {10071--10081},
  year      = {2021},
}

@inproceedings{Auto-MSFNet,
  title     = {Auto-MSFNet: Search Multi-scale Fusion Network for Salient Object Detection},
  author    = {Zhang, Miao and Liu, Tingwei and Piao, Yongri and Yao, Shunyu and Lu, Huchuan},
  booktitle = {ACM MM},
  pages     = {667--676},
  year      = {2021},
}

@inproceedings{CTDNet,
  title     = {Complementary Trilateral Decoder for Fast and Accurate Salient Object Detection},
  author    = {Zhao, Zhirui and Xia, Changqun and Xie, Chenxi and Li, Jia},
  booktitle = {ACM MM},
  pages     = {4967--4975},
  year      = {2021},
}

@inproceedings{VST,
  title     = {Visual saliency transformer},
  author    = {Liu, Nian and Zhang, Ni and Wan, Kaiyuan and Shao, Ling and Han, Junwei},
  booktitle = ICCV,
  pages     = {4722--4732},
  year      = {2021},
}

@inproceedings{HRRN,
  title     = {Disentangled high quality salient object detection},
  author    = {Tang, Lv and Li, Bo and Zhong, Yijie and Ding, Shouhong and Song, Mofei},
  booktitle = ICCV,
  pages     = {3580--3590},
  year      = {2021},
}

@inproceedings{iNAS,
  title     = {iNAS: Integral NAS for Device-Aware Salient Object Detection},
  author    = {Gu, Yu-Chao and Gao, Shang-Hua and Cao, Xu-Sheng and Du, Peng and Lu, Shao-Ping and Cheng, Ming-Ming},
  booktitle = ICCV,
  pages     = {4934--4944},
  year      = {2021},
}

@inproceedings{SCA,
  title     = {Scene context-aware salient object detection},
  author    = {Siris, Avishek and Jiao, Jianbo and Tam, Gary KL and Xie, Xianghua and Lau, Rynson WH},
  booktitle = ICCV,
  pages     = {4156--4166},
  year      = {2021},
}

@article{PoolNet+,
  title={Poolnet+: Exploring the potential of pooling for salient object detection},
  author={Liu, Jiang-Jiang and Hou, Qibin and Liu, Zhi-Ang and Cheng, Ming-Ming},
  journal=TPAMI,
  volume={45},
  pages={887--904},
  year={2022}
}

@article{CSNet_pami,
  title={A highly efficient model to study the semantics of salient object detection},
  author={Cheng, Ming-Ming and Gao, Shang-Hua and Borji, Ali and Tan, Yong-Qiang and Lin, Zheng and Wang, Meng},
  journal=TPAMI,
  volume={44},
  pages={8006--8021},
  year={2021}
}

@article{EDN,
  title={EDN: Salient object detection via extremely-downsampled network},
  author={Wu, Yu-Huan and Liu, Yun and Zhang, Le and Cheng, Ming-Ming and Ren, Bo},
  journal=TIP,
  volume={31},
  pages={3125--3136},
  year={2022}
}

@inproceedings{RCSBNet,
  title={Recursive contour-saliency blending network for accurate salient object detection},
  author={Ke, Yun Yi and Tsubono, Takahiro},
  booktitle={WACV},
  pages={2940--2950},
  year={2022}
}
@inproceedings{SHNet,
  title={Saliency hierarchy modeling via generative kernels for salient object detection},
  author={Zhang, Wenhu and Zheng, Liangli and Wang, Huanyu and Wu, Xintian and Li, Xi},
  booktitle={ECCV},
  pages={570--587},
  year={2022}
}

@inproceedings{PGNet,
  title={Pyramid grafting network for one-stage high resolution saliency detection},
  author={Xie, Chenxi and Xia, Changqun and Ma, Mingcan and Zhao, Zhirui and Chen, Xiaowu and Li, Jia},
  booktitle=CVPR,
  pages={11717--11726},
  year={2022}
}

@article{BBRF,
  title={Boosting Broader Receptive Fields for Salient Object Detection},
  author={Ma, Mingcan and Xia, Changqun and Xie, Chenxi and Chen, Xiaowu and Li, Jia},
  journal=TIP,
  volume={32},
  pages={1026--1038},
  year={2023}
}

@article{RMFormer,
  title={Recurrent Multi-scale Transformer for High-Resolution Salient Object Detection},
  author={Deng, Xinhao and Zhang, Pingping and Liu, Wei and Lu, Huchuan},
  journal={arXiv preprint arXiv:2308.03826},
  year={2023}
}
@inproceedings{MENet,
  title={Pixels, Regions, and Objects: Multiple Enhancement for Salient Object Detection},
  author={Wang, Yi and Wang, Ruili and Fan, Xin and Wang, Tianzhu and He, Xiangjian},
  booktitle=CVPR,
  pages={10031--10040},
  year={2023}
}
%%%%%%%%%%%%%%%%%%%RGB-D SOD

@inproceedings{PDNet_RGBDSOD,
  title     = {Pdnet: Prior-model guided depth-enhanced network for salient object detection},
  author    = {Zhu, Chunbiao and Cai, Xing and Huang, Kan and Li, Thomas H and Li, Ge},
  booktitle = {ICME},
  pages     = {199--204},
  year      = {2019},
}

@inproceedings{PCA_RGBDSOD,
  title     = {Progressively complementarity-aware fusion network for RGB-D salient object detection},
  author    = {Chen, Hao and Li, Youfu},
  booktitle = CVPR,
  pages     = {3051--3060},
  year      = {2018},
}

@article{AF_RGBD,
  title   = {Adaptive Fusion for RGB-D Salient Object Detection},
  author  = {Wang, Ningning and Gong, Xiaojin},
  journal = {IEEE Access},
  volume  = {7},
  pages   = {55277--55284},
  year    = {2019},
}

@article{cmSalGAN_RGBDSOD,
  title   = {cmsalgan: Rgb-d salient object detection with cross-view generative adversarial networks},
  author  = {Jiang, Bo and Zhou, Zitai and Wang, Xiao and Tang, Jin and Luo, Bin},
  journal = TMM,
  volume  = {23},
  pages   = {1343--1353},
  year    = {2020},
}

@article{MMCI_RGBDSOD,
  title   = {Multi-modal fusion network with multi-scale multi-path and cross-modal interactions for RGB-D salient object detection},
  author  = {Chen, Hao and Li, Youfu and Su, Dan},
  journal = PR,
  volume  = {86},
  pages   = {376--385},
  year    = {2019},
}

@article{TANet_RGBDSOD,
  title   = {Three-stream attention-aware network for RGB-D salient object detection},
  author  = {Chen, Hao and Li, Youfu},
  journal = TIP,
  volume  = {28},
  pages   = {2825--2835},
  year    = {2019},
}

@inproceedings{CPFP_RGBDSOD,
  title     = {Contrast Prior and Fluid Pyramid Integration for RGBD Salient Object Detection},
  author    = {Zhao, Jia-Xing and Cao, Yang and Fan, Deng-Ping and Cheng, Ming-Ming and Li, Xuan-Yi and Zhang, Le},
  booktitle = CVPR,
  pages     = {3922-3931},
  year      = {2019},
}

@inproceedings{DMRA_RGBDSOD,
  title     = {Depth-Induced Multi-Scale Recurrent Attention Network for Saliency Detection},
  author    = {Piao, Yongri and Ji, Wei and Li, Jingjing and Zhang, Miao and Lu, Huchuan},
  booktitle = ICCV,
  pages     = {7254--7263},
  year      = {2019},
}

@article{D3Net_RGBDSOD,
  title   = {Rethinking RGB-D salient object detection: Models, data sets, and large-scale benchmarks},
  author  = {Fan, Deng-Ping and Lin, Zheng and Zhang, Zhao and Zhu, Menglong and Cheng, Ming-Ming},
  journal = TNNLS,
  volume  = {32},
  pages   = {2075--2089},
  year    = {2020},
}

@article{ICNet_RGBDSOD,
  title   = {ICNet: Information Conversion Network for RGB-D Based Salient Object Detection},
  author  = {Li, Gongyang and Liu, Zhi and Ling, Haibin},
  journal = TIP,
  volume  = {29},
  pages   = {4873--4884},
  year    = {2020},
}

@article{DisenFuse_RGBDSOD,
  title   = {RGBD salient object detection via disentangled cross-modal fusion},
  author  = {Chen, Hao and Deng, Yongjian and Li, Youfu and Hung, Tzu-Yi and Lin, Guosheng},
  journal = TIP,
  volume  = {29},
  pages   = {8407--8416},
  year    = {2020},
}

@article{TDESDF_RGBDSOD,
  title   = {Improved saliency detection in RGB-D images using two-phase depth estimation and selective deep fusion},
  author  = {Chen, Chenglizhao and Wei, Jipeng and Peng, Chong and Zhang, Weizhong and Qin, Hong},
  journal = TIP,
  volume  = {29},
  pages   = {4296--4307},
  year    = {2020},
}

@article{DPANet_RGBDSOD,
  title   = {DPANet: Depth potentiality-aware gated attention network for RGB-D salient object detection},
  author  = {Chen, Zuyao and Cong, Runmin and Xu, Qianqian and Huang, Qingming},
  journal = TIP,
  volume  = {30},
  pages   = {7012--7024},
  year    = {2020},
}

@inproceedings{JL-DCF_RGBDSOD,
  title     = {Jl-dcf: Joint learning and densely-cooperative fusion framework for rgb-d salient object detection},
  author    = {Fu, Keren and Fan, Deng-Ping and Ji, Ge-Peng and Zhao, Qijun},
  booktitle = CVPR,
  pages     = {3052--3062},
  year      = {2020},
}

@inproceedings{UCNet_RGBDSOD,
  title     = {UC-Net: Uncertainty inspired RGB-D saliency detection via conditional variational autoencoders},
  author    = {Zhang, Jing and Fan, Deng-Ping and Dai, Yuchao and Anwar, Saeed and Saleh, Fatemeh Sadat and Zhang, Tong and Barnes, Nick},
  booktitle = CVPR,
  pages     = {8582--8591},
  year      = {2020},
}

@inproceedings{A2dele_RGBDSOD,
  title     = {A2dele: Adaptive and Attentive Depth Distiller for Efficient RGB-D Salient Object Detection},
  author    = {Piao, Yongri and Rong, Zhengkun and Zhang, Miao and Ren, Weisong and Lu, Huchuan},
  booktitle = CVPR,
  pages     = {9060--9069},
  year      = {2020},
}

@inproceedings{SSF_RGBDSOD,
  title     = {Select, Supplement and Focus for RGB-D Saliency Detection},
  author    = {Zhang, Miao and Ren, Weisong and Piao, Yongri and Rong, Zhengkun and Lu, Huchuan},
  booktitle = CVPR,
  pages     = {3472--3481},
  year      = {2020},
}

@inproceedings{S2MA_RGBDSOD,
  title     = {Learning Selective Self-Mutual Attention for RGB-D Saliency Detection},
  author    = {Liu, Nian and Zhang, Ni and Han, Junwei},
  booktitle = CVPR,
  pages     = {13756--13765},
  year      = {2020},
}

@inproceedings{CoNet_RGBDSOD,
  title     = {Accurate rgb-d salient object detection via collaborative learning},
  author    = {Ji, Wei and Li, Jingjing and Zhang, Miao and Piao, Yongri and Lu, Huchuan},
  booktitle = ECCV,
  pages     = {52--69},
  year      = {2020},
}

@inproceedings{CMWNet_RGBDSOD,
  title     = {Cross-modal weighting network for rgb-d salient object detection},
  author    = {Li, Gongyang and Liu, Zhi and Ye, Linwei and Wang, Yang and Ling, Haibin},
  booktitle = ECCV,
  pages     = {665--681},
  year      = {2020},
}

@inproceedings{BBSNet_RGBDSOD,
  title     = {BBS-Net: RGB-D salient object detection with a bifurcated backbone strategy network},
  author    = {Fan, Deng-Ping and Zhai, Yingjie and Borji, Ali and Yang, Jufeng and Shao, Ling},
  booktitle = ECCV,
  pages     = {275--292},
  year      = {2020},
}

@inproceedings{HDFNet_RGBDSOD,
  title     = {Hierarchical dynamic filtering network for RGB-D salient object detection},
  author    = {Pang, Youwei and Zhang, Lihe and Zhao, Xiaoqi and Lu, Huchuan},
  booktitle = ECCV,
  pages     = {235--252},
  year      = {2020},
}

@inproceedings{DANet_RGBDSOD,
  title     = {A single stream network for robust and real-time rgb-d salient object detection},
  author    = {Zhao, Xiaoqi and Zhang, Lihe and Pang, Youwei and Lu, Huchuan and Zhang, Lei},
  booktitle = ECCV,
  pages     = {646--662},
  year      = {2020},
}

@inproceedings{PGAR_RGBDSOD,
  title     = {Progressively guided alternate refinement network for RGB-D salient object detection},
  author    = {Chen, Shuhan and Fu, Yun},
  booktitle = ECCV,
  pages     = {520--538},
  year      = {2020},
}

@inproceedings{JLDCF_RGBDSOD,
  title     = {Jl-dcf: Joint learning and densely-cooperative fusion framework for rgb-d salient object detection},
  author    = {Fu, Keren and Fan, Deng-Ping and Ji, Ge-Peng and Zhao, Qijun},
  booktitle = CVPR,
  pages     = {3052--3062},
  year      = {2020},
}

@inproceedings{CMMS_RGBDSOD,
  title     = {RGB-D salient object detection with cross-modality modulation and selection},
  author    = {Li, Chongyi and Cong, Runmin and Piao, Yongri and Xu, Qianqian and Loy, Chen Change},
  booktitle = ECCV,
  pages     = {225--241},
  year      = {2020},
}

@inproceedings{CAS-GNN_RGBDSOD,
  title     = {Cascade graph neural networks for rgb-d salient object detection},
  author    = {Luo, Ao and Li, Xin and Yang, Fan and Jiao, Zhicheng and Cheng, Hong and Lyu, Siwei},
  booktitle = ECCV,
  pages     = {346--364},
  year      = {2020},
}

@inproceedings{ATSA_RGBDSOD,
  title     = {Asymmetric two-stream architecture for accurate rgb-d saliency detection},
  author    = {Zhang, Miao and Fei, Sun Xiao and Liu, Jie and Xu, Shuang and Piao, Yongri and Lu, Huchuan},
  booktitle = ECCV,
  pages     = {374--390},
  year      = {2020},
}

@inproceedings{DASNet_RGBDSOD,
  title     = {Is depth really necessary for salient object detection?},
  author    = {Zhao, Jiawei and Zhao, Yifan and Li, Jia and Chen, Xiaowu},
  booktitle = {ACM MM},
  pages     = {1745--1754},
  year      = {2020},
}

@inproceedings{FRDT_RGBDSOD,
  title     = {Feature reintegration over differential treatment: A top-down and adaptive fusion network for RGB-D salient object detection},
  author    = {Zhang, Miao and Zhang, Yu and Piao, Yongri and Hu, Beiqi and Lu, Huchuan},
  booktitle = {ACM MM},
  pages     = {4107--4115},
  year      = {2020},
}

@inproceedings{MMNet_RGBDSOD,
  title     = {Mmnet: Multi-stage and multi-scale fusion network for rgb-d salient object detection},
  author    = {Liao, Guibiao and Gao, Wei and Jiang, Qiuping and Wang, Ronggang and Li, Ge},
  booktitle = {ACM MM},
  pages     = {2436--2444},
  year      = {2020},
}

@article{HAINet_RGBDSOD,
  title   = {Hierarchical alternate interaction network for RGB-D salient object detection},
  author  = {Li, Gongyang and Liu, Zhi and Chen, Minyu and Bai, Zhen and Lin, Weisi and Ling, Haibin},
  journal = TIP,
  volume  = {30},
  pages   = {3528--3542},
  year    = {2021},
}

@article{CDNet_RGBDSOD,
  title   = {CDNet: Complementary Depth Network for RGB-D Salient Object Detection},
  author  = {Jin, Wen-Da and Xu, Jun and Han, Qi and Zhang, Yi and Cheng, Ming-Ming},
  journal = TIP,
  volume  = {30},
  pages   = {3376--3390},
  year    = {2021},
}

@article{UTA_RGBDSOD,
  title   = {RGB-D Salient Object Detection With Ubiquitous Target Awareness},
  author  = {Zhao, Yifan and Zhao, Jiawei and Li, Jia and Chen, Xiaowu},
  journal = TIP,
  volume  = {30},
  pages   = {7717--7731},
  year    = {2021},
}

@article{DSNet_RGBDSOD,
  title   = {Dynamic Selective Network for RGB-D Salient Object Detection},
  author  = {Wen, Hongfa and Yan, Chenggang and Zhou, Xiaofei and Cong, Runmin and Sun, Yaoqi and Zheng, Bolun and Zhang, Jiyong and Bao, Yongjun and Ding, Guiguang},
  journal = TIP,
  volume  = {30},
  pages   = {9179--9192},
  year    = {2021},
}

@inproceedings{RD3D_RGBDSOD,
  title     = {RGB-D Salient Object Detection via 3D Convolutional Neural Networks},
  author    = {Chen, Qian and Liu, Ze and Zhang, Yi and Fu, Keren and Zhao, Qijun and Du, Hongwei},
  booktitle = AAAI,
  pages     = {1063--1071},
  year      = {2021},
}

@inproceedings{DSA2F_RGBDSOD,
  title     = {Deep RGB-D Saliency Detection with Depth-Sensitive Attention and Automatic Multi-Modal Fusion},
  author    = {Sun, Peng and Zhang, Wenhu and Wang, Huanyu and Li, Songyuan and Li, Xi},
  booktitle = CVPR,
  pages     = {1407--1417},
  year      = {2021},
}

@inproceedings{DCF_RGBDSOD,
  title     = {Calibrated RGB-D Salient Object Detection},
  author    = {Ji, Wei and Li, Jingjing and Yu, Shuang and Zhang, Miao and Piao, Yongri and Yao, Shunyu and Bi, Qi and Ma, Kai and Zheng, Yefeng and Lu, Huchuan and others},
  booktitle = CVPR,
  pages     = {9471--9481},
  year      = {2021},
}

@inproceedings{CMINet_RGBDSOD,
  title     = {Rgb-d saliency detection via cascaded mutual information minimization},
  author    = {Zhang, Jing and Fan, Deng-Ping and Dai, Yuchao and Yu, Xin and Zhong, Yiran and Barnes, Nick and Shao, Ling},
  booktitle = ICCV,
  pages     = {4338--4347},
  year      = {2021},
}

@inproceedings{SPNet_RGBDSOD,
  title     = {Specificity-preserving RGB-D saliency detection},
  author    = {Zhou, Tao and Fu, Huazhu and Chen, Geng and Zhou, Yi and Fan, Deng-Ping and Shao, Ling},
  booktitle = ICCV,
  pages     = {4681--4691},
  year      = {2021},
}

@inproceedings{DFM-Net_RGBDSOD,
  title     = {Depth Quality-Inspired Feature Manipulation for Efficient RGB-D Salient Object Detection},
  author    = {Zhang, Wenbo and Ji, Ge-Peng and Wang, Zhuo and Fu, Keren and Zhao, Qijun},
  booktitle = {ACM MM},
  pages     = {731--740},
  year      = {2021},
}

@inproceedings{TriTransNet_RGBDSOD,
  title     = {Tritransnet: Rgb-d salient object detection with a triplet transformer embedding network},
  author    = {Liu, Zhengyi and Wang, Yuan and Tu, Zhengzheng and Xiao, Yun and Tang, Bin},
  booktitle = {ACM MM},
  pages     = {4481--4490},
  year      = {2021},
}

@inproceedings{CDINet_RGBDSOD,
  title     = {Cross-modality Discrepant Interaction Network for RGB-D Salient Object Detection},
  author    = {Zhang, Chen and Cong, Runmin and Lin, Qinwei and Ma, Lin and Li, Feng and Zhao, Yao and Kwong, Sam},
  booktitle = {ACM MM},
  pages     = {2094--2102},
  year      = {2021},
}

@article{MAD_RGBDSOD,
  title={Improving RGB-D salient object detection via modality-aware decoder},
  author={Song, Mengke and Song, Wenfeng and Yang, Guowei and Chen, Chenglizhao},
  journal=TIP,
  volume={31},
  pages={6124--6138},
  year={2022}
}

@article{DCMF_RGBDSOD,
  title={Learning discriminative cross-modality features for RGB-D saliency detection},
  author={Wang, Fengyun and Pan, Jinshan and Xu, Shoukun and Tang, Jinhui},
  journal=TIP,
  volume={31},
  pages={1285--1297},
  year={2022}
}
@article{CIR-Net_RGBDSOD,
  title={CIR-Net: Cross-modality interaction and refinement for RGB-D salient object detection},
  author={Cong, Runmin and Lin, Qinwei and Zhang, Chen and Li, Chongyi and Cao, Xiaochun and Huang, Qingming and Zhao, Yao},
  journal=TIP,
  volume={31},
  pages={6800--6815},
  year={2022}
}

@article{DIGR-Net_RGBDSOD,
  title={Depth-induced gap-reducing network for RGB-D salient object detection: an interaction, guidance and refinement approach},
  author={Cheng, Xiaolong and Zheng, Xuan and Pei, Jialun and Tang, He and Lyu, Zehua and Chen, Chuanbo},
  journal=TMM,
  year={2022}
}

@article{C2DFNet_RGBDSOD,
  title={C $\^{}$\{$2$\}$ $ DFNet: Criss-Cross Dynamic Filter Network for RGB-D Salient Object Detection},
  author={Zhang, Miao and Yao, Shunyu and Hu, Beiqi and Piao, Yongri and Ji, Wei},
  journal=TMM,
  year={2022}
}
@article{MobileSal_pami_RGBDSOD,
  title={MobileSal: Extremely efficient RGB-D salient object detection},
  author={Wu, Yu-Huan and Liu, Yun and Xu, Jun and Bian, Jia-Wang and Gu, Yu-Chao and Cheng, Ming-Ming},
  journal=TPAMI,
  volume={44},
  pages={10261--10269},
  year={2021}
}

@article{DCBF_RGBDSOD,
  title={Delving into Calibrated Depth for Accurate RGB-D Salient Object Detection},
  author={Li, Jingjing and Ji, Wei and Zhang, Miao and Piao, Yongri and Lu, Huchuan and Cheng, Li},
  journal=IJCV,
  volume={131},
  pages={855--876},
  year={2023}
} 

@inproceedings{MVSalNet_RGBDSOD,
  title={Mvsalnet: Multi-view augmentation for rgb-d salient object detection},
  author={Zhou, Jiayuan and Wang, Lijun and Lu, Huchuan and Huang, Kaining and Shi, Xinchu and Liu, Bocong},
  booktitle=ECCV,
  pages={270--287},
  year={2022}
}

@inproceedings{SPSN_RGBDSOD,
  title={Spsn: Superpixel prototype sampling network for rgb-d salient object detection},
  author={Lee, Minhyeok and Park, Chaewon and Cho, Suhwan and Lee, Sangyoun},
  booktitle=ECCV,
  pages={630--647},
  year={2022}
}
@article{HRTransNet_RGBDSOD,
  title={HRTransNet: HRFormer-driven two-modality salient object detection},
  author={Tang, Bin and Liu, Zhengyi and Tan, Yacheng and He, Qian},
  journal=TCSVT,
  volume={33},
  pages={728--742},
  year={2022}
}
@article{CAVER_RGBDSOD,
  title={CAVER: Cross-modal view-mixed transformer for bi-modal salient object detection},
  author={Pang, Youwei and Zhao, Xiaoqi and Zhang, Lihe and Lu, Huchuan},
  journal=TIP,
  volume={32},
  pages={892--904},
  year={2023}
}
@inproceedings{PopNet_RGBDSOD,
  title={Source-free depth for object pop-out},
  author={Wu, Zongwei and Paudel, Danda Pani and Fan, Deng-Ping and Wang, Jingjing and Wang, Shuo and Demonceaux, C{\'e}dric and Timofte, Radu and Van Gool, Luc},
  booktitle=ICCV,
  pages={1032--1042},
  year={2023}
}
@article{CATNet_RGBDSOD,
  title={CATNet: A Cascaded and Aggregated Transformer Network For RGB-D Salient Object Detection},
  author={Sun, Fuming and Ren, Peng and Yin, Bowen and Wang, Fasheng and Li, Haojie},
  journal=TMM,
  year={2023}
}

%%%%%%%%%%%%%%%%%%%ORSI SOD

@article{LV-Net_RSISOD,
  title   = {Nested network with two-stream pyramid for salient object detection in optical remote sensing images},
  author  = {Li, Chongyi and Cong, Runmin and Hou, Junhui and Zhang, Sanyi and Qian, Yue and Kwong, Sam},
  journal = TGRS,
  volume  = {57},
  pages   = {9156--9166},
  year    = {2019},
}

@article{DAFNet_RSISOD,
  title   = {Dense attention fluid network for salient object detection in optical remote sensing images},
  author  = {Zhang, Qijian and Cong, Runmin and Li, Chongyi and Cheng, Ming-Ming and Fang, Yuming and Cao, Xiaochun and Zhao, Yao and Kwong, Sam},
  journal = TIP,
  volume  = {30},
  pages   = {1305--1317},
  year    = {2020},
}

@article{PDF-Net_RSISOD,
  title   = {A parallel down-up fusion network for salient object detection in optical remote sensing images},
  author  = {Li, Chongyi and Cong, Runmin and Guo, Chunle and Li, Hua and Zhang, Chunjie and Zheng, Feng and Zhao, Yao},
  journal = {Neurocomputing},
  volume  = {415},
  pages   = {411--420},
  year    = {2020},
}

@article{MFI-Net_RSISOD,
  title   = {Edge-Aware Multiscale Feature Integration Network for Salient Object Detection in Optical Remote Sensing Images},
  author  = {Xiaofei Zhou and Kunye Shen and Zhi Liu and Chen Gong and Jiyong Zhang and Chenggang Clarence Yan},
  journal = TGRS,
  year    = {2022},
  volume  = {60},
  pages   = {1-15},
}

@article{RRNet_RSISOD,
  title   = {{RRNet}: Relational Reasoning Network with Parallel Multi-scale Attention for Salient Object Detection in Optical Remote Sensing Images},
  author  = {Cong, Runmin and Zhang, Yumo and Fang, Leyuan and Li, Jun and Zhao, Yao and Kwong, Sam},
  journal = TGRS,
  volume  = {60},
  pages   = {1558-1644},
  year    = {2022},
}

@article{MCCNet_RSISOD,
  title   = {Multi-Content Complementation Network for Salient Object Detection in Optical Remote Sensing Images},
  author  = {Gongyang Li and Zhi Liu and Weisi Lin and Haibin Ling},
  journal = TGRS,
  year    = {2022},
  volume  = {60},
  pages   = {1-13},
}

@inproceedings{GGRNet_RSISOD,
  title     = {GGRNet: Global Graph Reasoning Network for Salient Object Detection in Optical Remote Sensing Images},
  author    = {Liu, Xuan and Zhang, Yumo and Cong, Runmin and Zhang, Chen and Yang, Ning and Zhang, Chunjie and Zhao, Yao},
  booktitle = {PRCV},
  pages     = {584--596},
  year      = {2021},
}

@article{MJRBM_RSISOD,
  title   = {ORSI Salient Object Detection via Multiscale Joint Region and Boundary Model},
  author  = {Zhengzheng Tu and Chao Wang and Chenglong Li and Minghao Fan and Haifeng Zhao and Bin Luo},
  journal = TGRS,
  year    = {2022},
  volume  = {60},
  pages   = {1-13},
}

@article{CorrNet_RSISOD,
  title={Lightweight salient object detection in optical remote-sensing images via semantic matching and edge alignment},
  author={Li, Gongyang and Liu, Zhi and Zhang, Xinpeng and Lin, Weisi},
  journal=TGRS,
  volume={61},
  pages={1--11},
  year={2023}
}

@article{MCCNet_RSISOD,
  title={Multi-content complementation network for salient object detection in optical remote sensing images},
  author={Li, Gongyang and Liu, Zhi and Lin, Weisi and Ling, Haibin},
  journal=TGRS,
  volume={60},
  pages={1--13},
  year={2021}
}

@article{HFANet_RSISOD,
  title={Hybrid feature aligned network for salient object detection in optical remote sensing imagery},
  author={Wang, Qi and Liu, Yanfeng and Xiong, Zhitong and Yuan, Yuan},
  journal=TGRS,
  volume={60},
  pages={1--15},
  year={2022}
}
@article{CIFNet_RSISOD,
  title={ORSI Salient Object Detection via Cross-Scale Interaction and Enlarged Receptive Field},
  author={Zheng, Jianwei and Quan, Yueqian and Zheng, Hang and Wang, Yibin and Pan, Xiang},
  journal={IEEE GRSL},
  volume={20},
  pages={1--5},
  year={2023}
}
@article{BAFS-Net_RSISOD,
  title={Orsi salient object detection via bidimensional attention and full-stage semantic guidance},
  author={Gu, Yubin and Xu, Honghui and Quan, Yueqian and Chen, Wanjun and Zheng, Jianwei},
  journal=TGRS,
  volume={61},
  pages={1--13},
  year={2023}
}
%%%%%%%%%%%%%%%%%%% COD
@inproceedings{SINet_COD,
  title     = {Camouflaged object detection},
  author    = {Fan, Deng-Ping and Ji, Ge-Peng and Sun, Guolei and Cheng, Ming-Ming and Shen, Jianbing and Shao, Ling},
  booktitle = CVPR,
  pages     = {2777--2787},
  year      = {2020},
}

@inproceedings{PFNet_COD,
  title     = {Camouflaged object segmentation with distraction mining},
  author    = {Mei, Haiyang and Ji, Ge-Peng and Wei, Ziqi and Yang, Xin and Wei, Xiaopeng and Fan, Deng-Ping},
  booktitle = CVPR,
  pages     = {8772--8781},
  year      = {2021},
}

@inproceedings{Rank-Net_COD,
  title     = {Simultaneously localize, segment and rank the camouflaged objects},
  author    = {Lv, Yunqiu and Zhang, Jing and Dai, Yuchao and Li, Aixuan and Liu, Bowen and Barnes, Nick and Fan, Deng-Ping},
  booktitle = CVPR,
  pages     = {11591--11601},
  year      = {2021},
}

@inproceedings{MGL_COD,
  title     = {Mutual graph learning for camouflaged object detection},
  author    = {Zhai, Qiang and Li, Xin and Yang, Fan and Chen, Chenglizhao and Cheng, Hong and Fan, Deng-Ping},
  booktitle = CVPR,
  pages     = {12997--13007},
  year      = {2021},
}

@inproceedings{JSODCOD,
  title     = {Uncertainty-aware joint salient object and camouflaged object detection},
  author    = {Li, Aixuan and Zhang, Jing and Lv, Yunqiu and Liu, Bowen and Zhang, Tong and Dai, Yuchao},
  booktitle = CVPR,
  pages     = {10071--10081},
  year      = {2021},
}

@inproceedings{UGTR_COD,
  title     = {Uncertainty-guided transformer reasoning for camouflaged object detection},
  author    = {Yang, Fan and Zhai, Qiang and Li, Xin and Huang, Rui and Luo, Ao and Cheng, Hong and Fan, Deng-Ping},
  booktitle = ICCV,
  pages     = {4146--4155},
  year      = {2021},
}

@article{MirrorNet_COD,
  title   = {MirrorNet: Bio-inspired camouflaged object segmentation},
  author  = {Yan, Jinnan and Le, Trung-Nghia and Nguyen, Khanh-Duy and Tran, Minh-Triet and Do, Thanh-Toan and Nguyen, Tam V},
  journal = {IEEE Access},
  volume  = {9},
  pages   = {43290--43300},
  year    = {2021},
}

@article{TANet_COD,
  title   = {Deep texture-aware features for camouflaged object detection},
  author  = {Ren, Jingjing and Hu, Xiaowei and Zhu, Lei and Xu, Xuemiao and Xu, Yangyang and Wang, Weiming and Deng, Zijun and Heng, Pheng-Ann},
  journal = TCSVT,
  year    = {2021},
}

@article{ERRNet_COD,
  title   = {Fast Camouflaged Object Detection via Edge-based Reversible Re-calibration Network},
  author  = {Ji, Ge-Peng and Zhu, Lei and Zhuge, Mingchen and Fu, Keren},
  journal = {Pattern Recognition},
  volume  = {123},
  pages   = {108414},
  year    = {2022},
}

@inproceedings{PreyNet_COD,
  title={Preynet: Preying on camouflaged objects},
  author={Zhang, Miao and Xu, Shuang and Piao, Yongri and Shi, Dongxiang and Lin, Shusen and Lu, Huchuan},
  booktitle={ACM MM},
  pages={5323--5332},
  year={2022}
}

@article{BGNet_COD,
  title={Boundary-guided camouflaged object detection},
  author={Sun, Yujia and Wang, Shuo and Chen, Chenglizhao and Xiang, Tian-Zhu},
  journal={arXiv preprint arXiv:2207.00794},
  year={2022}
}

@inproceedings{SegMaR_COD,
  title={Segment, magnify and reiterate: Detecting camouflaged objects the hard way},
  author={Jia, Qi and Yao, Shuilian and Liu, Yu and Fan, Xin and Liu, Risheng and Luo, Zhongxuan},
  booktitle=CVPR,
  pages={4713--4722},
  year={2022}
}

@inproceedings{FM_COD,
  title={Detecting camouflaged object in frequency domain},
  author={Zhong, Yijie and Li, Bo and Tang, Lv and Kuang, Senyun and Wu, Shuang and Ding, Shouhong},
  booktitle=CVPR,
  pages={4504--4513},
  year={2022}
}

@inproceedings{ZoomNet_COD,
  title={Zoom in and out: A mixed-scale triplet network for camouflaged object detection},
  author={Pang, Youwei and Zhao, Xiaoqi and Xiang, Tian-Zhu and Zhang, Lihe and Lu, Huchuan},
  booktitle=CVPR,
  pages={2160--2170},
  year={2022}
}
@article{SINet-v2_COD,
  title={Concealed object detection},
  author={Fan, Deng-Ping and Ji, Ge-Peng and Cheng, Ming-Ming and Shao, Ling},
  journal=TPAMI,
  volume={44},
  pages={6024--6042},
  year={2021}
}

@article{FAPNet_COD,
  title={Feature aggregation and propagation network for camouflaged object detection},
  author={Zhou, Tao and Zhou, Yi and Gong, Chen and Yang, Jian and Zhang, Yu},
  journal=TIP,
  volume={31},
  pages={7036--7047},
  year={2022}
}

@article{FindNet_COD,
  title={Findnet: Can you find me? boundary-and-texture enhancement network for camouflaged object detection},
  author={Li, Peng and Yan, Xuefeng and Zhu, Hongwei and Wei, Mingqiang and Zhang, Xiao-Ping and Qin, Jing},
  journal=TIP,
  volume={31},
  pages={6396--6411},
  year={2022
}

@article{R-MGL-V2_COD,
  title={Mgl: Mutual graph learning for camouflaged object detection},
  author={Zhai, Qiang and Li, Xin and Yang, Fan and Jiao, Zhicheng and Luo, Ping and Cheng, Hong and Liu, Zicheng},
  journal=TIP,
  volume={32},
  pages={1897--1910},
  year={2022}
}
@article{FPNet_COD,
  title={Frequency Perception Network for Camouflaged Object Detection},
  author={Cong, Runmin and Sun, Mengyao and Zhang, Sanyi and Zhou, Xiaofei and Zhang, Wei and Zhao, Yao},
  journal={arXiv preprint arXiv:2308.08924},
  year={2023}
}
@inproceedings{FSPNet_COD,
  title={Feature shrinkage pyramid for camouflaged object detection with transformers},
  author={Huang, Zhou and Dai, Hang and Xiang, Tian-Zhu and Wang, Shuo and Chen, Huai-Xin and Qin, Jie and Xiong, Huan},
  booktitle=CVPR,
  pages={5557--5566},
  year={2023}
}
@inproceedings{FEDER_COD,
  title={Camouflaged object detection with feature decomposition and edge reconstruction},
  author={He, Chunming and Li, Kai and Zhang, Yachao and Tang, Longxiang and Zhang, Yulun and Guo, Zhenhua and Li, Xiu},
  booktitle=CVPR,
  pages={22046--22055},
  year={2023}
}
@inproceedings{HitNet_COD,
  title={High-resolution iterative feedback network for camouflaged object detection},
  author={Hu, Xiaobin and Wang, Shuo and Qin, Xuebin and Dai, Hang and Ren, Wenqi and Luo, Donghao and Tai, Ying and Shao, Ling},
  booktitle=AAAI,
  volume={37},
  pages={881--889},
  year={2023}
}
%%%%%%%%%%%%%%%%%%% Defocus Blur Detection
@inproceedings{BTBNet_DBD,
  title     = {Defocus blur detection via multi-stream bottom-top-bottom fully convolutional network},
  author    = {Zhao, Wenda and Zhao, Fan and Wang, Dong and Lu, Huchuan},
  booktitle = CVPR,
  pages     = {3080--3088},
  year      = {2018},
}

@inproceedings{DeFusionNet_DBD,
  title     = {Defusionnet: Defocus blur detection via recurrently fusing and refining multi-scale deep features},
  author    = {Tang, Chang and Zhu, Xinzhong and Liu, Xinwang and Wang, Lizhe and Zomaya, Albert},
  booktitle = CVPR,
  pages     = {2700--2709},
  year      = {2019},
}

@inproceedings{CENet_DBD,
  title     = {Enhancing diversity of defocus blur detectors via cross-ensemble network},
  author    = {Zhao, Wenda and Zheng, Bowen and Lin, Qiuhua and Lu, Huchuan},
  booktitle = CVPR,
  pages     = {8905--8913},
  year      = {2019},
}

@inproceedings{R2MRF_DBD,
  title     = {R2MRF: Defocus Blur Detection via Recurrently Refining Multi-Scale Residual Features},
  author    = {Tang, Chang and Liu, Xinwang and Zhu, Xinzhong and Zhu, En and Sun, Kun and Wang, Pichao and Wang, Lizhe and Zomaya, Albert},
  booktitle = AAAI,
  pages     = {12063--12070},
  year      = {2020},
}

@article{BR2Net_DBD,
  title   = {BR2Net: Defocus Blur Detection Via a Bidirectional Channel Attention Residual Refining Network},
  author  = {Tang, Chang and Liu, Xinwang and An, Shan and Wang, Pichao},
  journal = TMM,
  volume  = {23},
  pages   = {624--635},
  year    = {2020},
}

@inproceedings{Depth-Distill_DBD,
  title     = {Defocus blur detection via depth distillation},
  author    = {Cun, Xiaodong and Pun, Chi-Man},
  booktitle = ECCV,
  pages     = {747--763},
  year      = {2020},
}

@article{IS2CNet_DBD,
  title   = {Image-Scale-Symmetric Cooperative Network for Defocus Blur Detection},
  author  = {Zhao, Fan and Lu, Huimin and Zhao, Wenda and Yao, Libo},
  journal = TCSVT,
  year    = {2021},
}

@inproceedings{SG_DBD,
  title     = {Self-generated Defocus Blur Detection via Dual Adversarial Discriminators},
  author    = {Zhao, Wenda and Shang, Cai and Lu, Huchuan},
  booktitle = CVPR,
  pages     = {6933--6942},
  year      = {2021},
}

@article{DENets_DBD,
  title   = {Defocus blur detection via boosting diversity of deep ensemble networks},
  author  = {Zhao, Wenda and Hou, Xueqing and He, You and Lu, Huchuan},
  journal = TIP,
  volume  = {30},
  pages   = {5426--5438},
  year    = {2021},
}
@inproceedings{APL_DBD,
  title={United defocus blur detection and deblurring via adversarial promoting learning},
  author={Zhao, Wenda and Wei, Fei and He, You and Lu, Huchuan},
  booktitle=ECCV,
  pages={569--586},
  year={2022}
}

@article{MA-GANet_DBD,
  title={MA-GANet: A Multi-attention generative adversarial network for defocus blur detection},
  author={Jiang, Zeyu and Xu, Xun and Zhang, Le and Zhang, Chao and Foo, Chuan Sheng and Zhu, Ce},
  journal=TIP,
  volume={31},
  pages={3494--3508},
  year={2022}
}

@article{CTCUG,
  title={DeFusionNET: Defocus blur detection via recurrently fusing and refining discriminative multi-scale deep features},
  author={Tang, Chang and Liu, Xinwang and Zheng, Xiao and Li, Wanqing and Xiong, Jian and Wang, Lizhe and Zomaya, Albert Y and Longo, Antonella},
  journal=TPAMI,
  volume={44},
  pages={955--968},
  year={2020}
}
@article{M2CS_DBD,
  title={From Global to Local: Multi-Patch and Multi-Scale Contrastive Similarity Learning for Unsupervised Defocus Blur Detection},
  author={Li, Jinxing and Liang, Beicheng and Lu, Xiangwei and Li, Mu and Lu, Guangming and Xu, Yong},
  journal=TIP,
  volume={32},
  pages={1158--1169},
  year={2023}
}
@article{MLDBD_DBD,
  title={Full-scene Defocus Blur Detection with DeFBD+ via Multi-Level Distillation Learning},
  author={Zhao, Wenda and Wei, Fei and Wang, Haipeng and He, You and Lu, Huchuan},
  journal=TMM,
  year={2023}
}

%%%%%%%%%%%%%%%%%%% Shadow Detection
@inproceedings{ST-CGAN_Shadow,
  title     = {Stacked conditional generative adversarial networks for jointly learning shadow detection and shadow removal},
  author    = {Wang, Jifeng and Li, Xiang and Yang, Jian},
  booktitle = CVPR,
  pages     = {1788--1797},
  year      = {2018},
}

@inproceedings{DSC_Shadow,
  title     = {Direction-aware spatial context features for shadow detection},
  author    = {Hu, Xiaowei and Zhu, Lei and Fu, Chi-Wing and Qin, Jing and Heng, Pheng-Ann},
  booktitle = CVPR,
  pages     = {7454--7462},
  year      = {2018},
}

@inproceedings{ADNet_Shadow,
  title     = {A+ d net: Training a shadow detector with adversarial shadow attenuation},
  author    = {Le, Hieu and Vicente, Tomas F Yago and Nguyen, Vu and Hoai, Minh and Samaras, Dimitris},
  booktitle = ECCV,
  pages     = {662--678},
  year      = {2018},
}

@inproceedings{BDRAR_Shadow,
  title     = {Bidirectional feature pyramid network with recurrent attention residual modules for shadow detection},
  author    = {Zhu, Lei and Deng, Zijun and Hu, Xiaowei and Fu, Chi-Wing and Xu, Xuemiao and Qin, Jing and Heng, Pheng-Ann},
  booktitle = ECCV,
  pages     = {121--136},
  year      = {2018},
}

@inproceedings{ARGAN_Shadow,
  title     = {Argan: Attentive recurrent generative adversarial network for shadow detection and removal},
  author    = {Ding, Bin and Long, Chengjiang and Zhang, Ling and Xiao, Chunxia},
  booktitle = ICCV,
  pages     = {10213--10222},
  year      = {2019},
}

@inproceedings{DSDNet_Shadow,
  title     = {Distraction-aware shadow detection},
  author    = {Zheng, Quanlong and Qiao, Xiaotian and Cao, Ying and Lau, Rynson WH},
  booktitle = CVPR,
  pages     = {5167--5176},
  year      = {2019},
}

@article{AFFPN_Shadow,
  title   = {Attentive Feedback Feature Pyramid Network for Shadow Detection},
  author  = {Kim, Jinhee and Kim, Wonjun},
  journal = SPL,
  volume  = {27},
  pages   = {1964--1968},
  year    = {2020},
}

@inproceedings{RCMPNet_Shadow,
  title     = {Shadow Detection via Predicting the Confidence Maps of Shadow Detection Methods},
  author    = {Liao, Jingwei and Liu, Yanli and Xing, Guanyu and Wei, Housheng and Chen, Jueyu and Xu, Songhua},
  booktitle = {ACM MM},
  pages     = {704--712},
  year      = {2021},
}

@inproceedings{MIB_Shadow,
  title     = {Mitigating Intensity Bias in Shadow Detection via Feature Decomposition and Reweighting},
  author    = {Zhu, Lei and Xu, Ke and Ke, Zhanghan and Lau, Rynson WH},
  booktitle = ICCV,
  pages     = {4702--4711},
  year      = {2021},
}

@article{FSDNet_Shadow,
  title   = {Revisiting shadow detection: A new benchmark dataset for complex world},
  author  = {Hu, Xiaowei and Wang, Tianyu and Fu, Chi-Wing and Jiang, Yitong and Wang, Qiong and Heng, Pheng-Ann},
  journal = TIP,
  volume  = {30},
  pages   = {1925--1934},
  year    = {2021},
}

@inproceedings{ECA_Shadow,
  title     = {Robust Shadow Detection by Exploring Effective Shadow Contexts},
  author    = {Fang, Xianyong and He, Xiaohao and Wang, Linbo and Shen, Jianbing},
  booktitle = {ACM MM},
  pages     = {2927--2935},
  year      = {2021},
}
@inproceedings{SILT_Shadow,
  title={SILT: Shadow-aware Iterative Label Tuning for Learning to Detect Shadows from Noisy Labels},
  author={Yang, Han and Wang, Tianyu and Hu, Xiaowei and Fu, Chi-Wing},
  booktitle=ICCV,
  pages={12687--12698},
  year={2023}
}
%%%%%%%%%%%%%%%%%%% Transparent Object Detection
@inproceedings{TOM-Net_Transparent,
  title     = {Tom-net: Learning transparent object matting from a single image},
  author    = {Chen, Guanying and Han, Kai and Wong, Kwan-Yee K},
  booktitle = CVPR,
  pages     = {9233--9241},
  year      = {2018},
}

@inproceedings{TransLab_Transparent,
  title     = {Segmenting transparent objects in the wild},
  author    = {Xie, Enze and Wang, Wenjia and Wang, Wenhai and Ding, Mingyu and Shen, Chunhua and Luo, Ping},
  booktitle = ECCV,
  pages     = {696--711},
  year      = {2020},
}

@inproceedings{Trans2Seg_Transparent,
  title     = {Segmenting Transparent Objects in the Wild with Transformer},
  author    = {Xie, Enze and Wang, Wenjia and Wang, Wenhai and Sun, Peize and Xu, Hang and Liang, Ding and Luo, Ping},
  booktitle = IJCAI,
  pages     = {1194--1200},
  year      = {2021},
}

@inproceedings{Transfusion_Transparent,
  title     = {Transfusion: A Novel SLAM Method Focused on Transparent Objects},
  author    = {Zhu, Yifan and Qiu, Jiaxiong and Ren, Bo},
  booktitle = ICCV,
  pages     = {6019--6028},
  year      = {2021},
}

%%%%%%%%%%%%%%%%%%% Glass Object Detection
@inproceedings{GDNet_Glass,
  title     = {Don't hit me! glass detection in real-world scenes},
  author    = {Mei, Haiyang and Yang, Xin and Wang, Yang and Liu, Yuanyuan and He, Shengfeng and Zhang, Qiang and Wei, Xiaopeng and Lau, Rynson WH},
  booktitle = CVPR,
  pages     = {3687--3696},
  year      = {2020},
}

@inproceedings{RCARP_Glass,
  title     = {Rich context aggregation with reflection prior for glass surface detection},
  author    = {Lin, Jiaying and He, Zebang and Lau, Rynson WH},
  booktitle = CVPR,
  pages     = {13415--13424},
  year      = {2021},
}

@inproceedings{EBLNet_Glass,
  title     = {Enhanced boundary learning for glass-like object segmentation},
  author    = {He, Hao and Li, Xiangtai and Cheng, Guangliang and Shi, Jianping and Tong, Yunhai and Meng, Gaofeng and Prinet, V{\'e}ronique and Weng, LuBin},
  booktitle = ICCV,
  pages     = {15859--15868},
  year      = {2021},
}

@article{PGSNet_Glass,
  title={Progressive glass segmentation},
  author={Yu, Letian and Mei, Haiyang and Dong, Wen and Wei, Ziqi and Zhu, Li and Wang, Yuxin and Yang, Xin},
  journal=TIP,
  volume={31},
  pages={2920--2933},
  year={2022}
}
@article{RFENet_Glass,
  title={RFENet: Towards Reciprocal Feature Evolution for Glass Segmentation},
  author={Fan, Ke and Wang, Changan and Wang, Yabiao and Wang, Chengjie and Yi, Ran and Ma, Lizhuang},
  journal={arXiv preprint arXiv:2307.06099},
  year={2023}
}
%%%%%%%%%%%%%%%%%%% Mirror Object Detection

@inproceedings{MirrorNet_Mirror,
  title     = {Where is my mirror?},
  author    = {Yang, Xin and Mei, Haiyang and Xu, Ke and Wei, Xiaopeng and Yin, Baocai and Lau, Rynson WH},
  booktitle = ICCV,
  pages     = {8809--8818},
  year      = {2019},
}

@inproceedings{PMD_Mirror,
  title     = {Progressive mirror detection},
  author    = {Lin, Jiaying and Wang, Guodong and Lau, Rynson WH},
  booktitle = CVPR,
  pages     = {3697--3705},
  year      = {2020},
}

@inproceedings{PDNet_Mirror,
  title     = {Depth-aware mirror segmentation},
  author    = {Mei, Haiyang and Dong, Bo and Dong, Wen and Peers, Pieter and Yang, Xin and Zhang, Qiang and Wei, Xiaopeng},
  booktitle = CVPR,
  pages     = {3044--3053},
  year      = {2021},
}
@inproceedings{LSA_Mirror,
  title={Learning semantic associations for mirror detection},
  author={Guan, Huankang and Lin, Jiaying and Lau, Rynson WH},
  booktitle=CVPR,
  pages={5941--5950},
  year={2022}
}
%%%%%%%%%%%%%%%%%%%Polyp Segmentation (Medical Image)
@article{UNet++,
  title   = {Unet++: Redesigning skip connections to exploit multiscale features in image segmentation},
  author  = {Zhou, Zongwei and Siddiquee, Md Mahfuzur Rahman and Tajbakhsh, Nima and Liang, Jianming},
  journal = TMI,
  volume  = {39},
  pages   = {1856--1867},
  year    = {2019},
}

@inproceedings{SFA_Polyp,
  title     = {Selective feature aggregation network with area-boundary constraints for polyp segmentation},
  author    = {Fang, Yuqi and Chen, Cheng and Yuan, Yixuan and Tong, Kai-yu},
  booktitle = MICCAI,
  pages     = {302--310},
  year      = {2019},
}

@inproceedings{ACSNet_Polyp,
  title     = {Adaptive Context Selection for Polyp Segmentation},
  author    = {Zhang, Ruifei and Li, Guanbin and Li, Zhen and Cui, Shuguang and Qian, Dahong and Yu, Yizhou},
  booktitle = MICCAI,
  pages     = {253--262},
  year      = {2020},
}

@inproceedings{PraNet_Polyp,
  title     = {Pranet: Parallel reverse attention network for polyp segmentation},
  author    = {Fan, Deng-Ping and Ji, Ge-Peng and Zhou, Tao and Chen, Geng and Fu, Huazhu and Shen, Jianbing and Shao, Ling},
  booktitle = MICCAI,
  pages     = {263--273},
  year      = {2020},
}

@article{ResUNet++_Polyp,
  title   = {A comprehensive study on colorectal polyp segmentation with ResUNet++, conditional random field and test-time augmentation},
  author  = {Jha, Debesh and Smedsrud, Pia H and Johansen, Dag and de Lange, Thomas and Johansen, H{\aa}vard D and Halvorsen, P{\aa}l and Riegler, Michael A},
  journal = {IEEE JBHI},
  volume  = {25},
  pages   = {2029--2040},
  year    = {2021},
}

@inproceedings{TransFuse_Polyp,
  title     = {Transfuse: Fusing transformers and cnns for medical image segmentation},
  author    = {Zhang, Yundong and Liu, Huiye and Hu, Qiang},
  booktitle = MICCAI,
  pages     = {14--24},
  year      = {2021},
}

@inproceedings{MSNet_Polyp,
  title     = {Automatic polyp segmentation via multi-scale subtraction network},
  author    = {Zhao, Xiaoqi and Zhang, Lihe and Lu, Huchuan},
  booktitle = MICCAI,
  pages     = {120--130},
  year      = {2021},
}

@inproceedings{EMS-Net_Polyp,
  title     = {EMS-Net: Enhanced Multi-Scale Network for Polyp Segmentation},
  author    = {Wang, Miao and An, Xingwei and Li, Yuhao and Li, Ning and Hang, Wei and Liu, Gang},
  booktitle = {IEEE EMBC},
  pages     = {2936--2939},
  year      = {2021},
}

@inproceedings{APRNet_Polyp,
  title     = {APRNet: Alternative Prediction Refinement Network for Polyp Segmentation},
  author    = {Shen, Yutian and Jia, Xiao and Pan, Jin and Meng, Max Q-H},
  booktitle = {IEEE EMBC},
  pages     = {3114--3117},
  year      = {2021},
}

@inproceedings{UACANet_Polyp,
  title     = {UACANet: Uncertainty Augmented Context Attention for Polyp Segmentation},
  author    = {Kim, Taehun and Lee, Hyemin and Kim, Daijin},
  booktitle = {ACM MM},
  pages     = {2167--2175},
  year      = {2021},
}

@inproceedings{SANet_Polyp,
  title     = {Shallow attention network for polyp segmentation},
  author    = {Wei, Jun and Hu, Yiwen and Zhang, Ruimao and Li, Zhen and Zhou, S Kevin and Cui, Shuguang},
  booktitle = MICCAI,
  pages     = {699--708},
  year      = {2021},
}

@inproceedings{LOD-Net_Polyp,
  title     = {Learnable Oriented-Derivative Network for Polyp Segmentation},
  author    = {Cheng, Mengjun and Kong, Zishang and Song, Guoli and Tian, Yonghong and Liang, Yongsheng and Chen, Jie},
  booktitle = MICCAI,
  pages     = {720--730},
  year      = {2021},
}

@inproceedings{CCBANet_Polyp,
  title     = {CCBANet: Cascading Context and Balancing Attention for Polyp Segmentation},
  author    = {Nguyen, Tan-Cong and Nguyen, Tien-Phat and Diep, Gia-Han and Tran-Dinh, Anh-Huy and Nguyen, Tam V and Tran, Minh-Triet},
  booktitle = MICCAI,
  pages     = {633--643},
  year      = {2021},
}

@inproceedings{PNS-Net_Polyp,
  title     = {Progressively normalized self-attention network for video polyp segmentation},
  author    = {Ji, Ge-Peng and Chou, Yu-Cheng and Fan, Deng-Ping and Chen, Geng and Fu, Huazhu and Jha, Debesh and Shao, Ling},
  booktitle = MICCAI,
  pages     = {142--152},
  year      = {2021},
}

@inproceedings{HRENet_Polyp,
  title     = {HRENet: A Hard Region Enhancement Network for Polyp Segmentation},
  author    = {Shen, Yutian and Jia, Xiao and Meng, Max Q-H},
  booktitle = MICCAI,
  pages     = {559--568},
  year      = {2021},
}

@inproceedings{SCR-Net_Polyp,
  title     = {Precise Yet Efficient Semantic Calibration and Refinement in ConvNets for Real-time Polyp Segmentation from Colonoscopy Videos},
  author    = {Wu, Huisi and Zhong, Jiafu and Wang, Wei and Wen, Zhenkun and Qin, Jing},
  booktitle = AAAI,
  pages     = {2916--2924},
  year      = {2021},
}

@inproceedings{TRFR-Net_Polyp,
  title={Task-Relevant Feature Replenishment for Cross-Centre Polyp Segmentation},
  author={Shen, Yutian and Lu, Ye and Jia, Xiao and Bai, Fan and Meng, Max Q-H},
  booktitle = MICCAI,
  pages={599--608},
  year={2022}
}

@inproceedings{LDNet_Polyp,
  title={Lesion-aware dynamic kernel for polyp segmentation},
  author={Zhang, Ruifei and Lai, Peiwen and Wan, Xiang and Fan, De-Jun and Gao, Feng and Wu, Xiao-Jian and Li, Guanbin},
  booktitle = MICCAI,
  pages={99--109},
  year={2022}
}
@inproceedings{BoxPolyp_Polyp,
  title={BoxPolyp: Boost Generalized Polyp Segmentation Using Extra Coarse Bounding Box Annotations},
  author={Wei, Jun and Hu, Yiwen and Li, Guanbin and Cui, Shuguang and Kevin Zhou, S and Li, Zhen},
  booktitle = MICCAI,
  pages={67--77},
  year={2022}
}
@inproceedings{PPFormer_Polyp,
  title={Using Guided Self-Attention with Local Information for Polyp Segmentation},
  author={Cai, Linghan and Wu, Meijing and Chen, Lijiang and Bai, Wenpei and Yang, Min and Lyu, Shuchang and Zhao, Qi},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={629--638},
  year={2022}
}
@article{CFANet_Polyp,
  title={Cross-level Feature Aggregation Network for Polyp Segmentation},
  author={Zhou, Tao and Zhou, Yi and He, Kelei and Gong, Chen and Yang, Jian and Fu, Huazhu and Shen, Dinggang},
  journal={Pattern Recognition},
  volume={140},
  pages={109555},
  year={2023}
}
@article{EMS-Net_Polyp,
  title={An Efficient Multi-Task Synergetic Network for Polyp Segmentation and Classification},
  author={Wang, Miao and An, Xingwei and Pei, Zhengcun and Li, Ning and Zhang, Li and Liu, Gang and Ming, Dong},
  journal={IEEE JBHI},
  year={2023
}


%%%% Task introduction
@article{classification,
  title   = {Region-based saliency detection and its application in object recognition},
  author  = {Ren, Zhixiang and Gao, Shenghua and Chia, Liang-Tien and Tsang, Ivor Wai-Hung},
  journal = TCSVT,
  volume  = {24},
  number  = {5},
  pages   = {769--779},
  year    = {2013},
}

@inproceedings{tracking,
  title     = {Saliency-based discriminant tracking},
  author    = {Mahadevan, Vijay and Vasconcelos, Nuno},
  booktitle = CVPR,
  year      = {2009},
}

@inproceedings{Reid,
  title     = {Unsupervised Salience Learning for Person Re-identification},
  author    = {Rui, Zhao and Ouyang, Wanli and Wang, Xiaogang},
  booktitle = CVPR,
  year      = {2013},
}

@inproceedings{RANet,
  title     = {Ranet: Ranking attention network for fast video object segmentation},
  author    = {Wang, Ziqin and Xu, Jun and Liu, Li and Zhu, Fan and Shao, Ling},
  booktitle = ICCV,
  pages     = {3978--3987},
  year      = {2019},
}

@article{SIM,
  title   = {Salient Image Matting},
  author  = {Deora, Rahul and Sharma, Rishab and Raj, Dinesh Samuel Sathia},
  journal = {arXiv preprint arXiv:2103.12337},
  year    = {2021},
}

@inproceedings{Imagecaption,
  title     = {From captions to visual concepts and back},
  author    = {Fang, Hao and Gupta, Saurabh and Iandola, Forrest and Srivastava, Rupesh K and Deng, Li and Doll{\'a}r, Piotr and Gao, Jianfeng and He, Xiaodong and Mitchell, Margaret and Platt, John C and others},
  booktitle = CVPR,
  pages     = {1473--1482},
  year      = {2015},
}

@inproceedings{Unet,
  title     = {U-net: Convolutional networks for biomedical image segmentation},
  author    = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle = MICCAI,
  pages     = {234--241},
  year      = {2015},
}

@inproceedings{FPN,
  title     = {Feature pyramid networks for object detection},
  author    = {Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle = CVPR,
  pages     = {2117--2125},
  year      = {2017},
}

@article{camouflage,
  title   = {Animal camouflage: current issues and new perspectives},
  author  = {Stevens, Martin and Merilaita, Sami},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume  = {364},
  pages   = {423--427},
  year    = {2009},
}

@article{DAS_shadow_removal,
  title   = {Direction-aware spatial context features for shadow detection and removal},
  author  = {Hu, Xiaowei and Fu, Chi-Wing and Zhu, Lei and Qin, Jing and Heng, Pheng-Ann},
  journal = TPAMI,
  volume  = {42},
  pages   = {2795--2808},
  year    = {2019},
}

@inproceedings{Shadow_scene_geometry,
  title     = {Estimating geo-temporal location of stationary cameras using shadow trajectories},
  author    = {Junejo, Imran N and Foroosh, Hassan},
  booktitle = ECCV,
  pages     = {318--331},
  year      = {2008},
}

@article{camera_parameters_shadow,
  title   = {Camera calibration and geo-location estimation from two shadow trajectories},
  author  = {Wu, Lin and Cao, Xiaochun and Foroosh, Hassan},
  journal = {CVIU},
  volume  = {114},
  pages   = {915--927},
  year    = {2010},
}

@inproceedings{shadow_improve_tracking,
  title     = {Improving shadow suppression in moving object detection with HSV color information},
  author    = {Cucchiara, Rita and Grana, Costantino and Piccardi, Massimo and Prati, Andrea and Sirotti, Stefano},
  booktitle = {ITSC},
  pages     = {334--339},
  year      = {2001},
}

@inproceedings{Deepsupervision,
  title        = {Deeply-supervised nets},
  author       = {Lee, Chen-Yu and Xie, Saining and Gallagher, Patrick and Zhang, Zhengyou and Tu, Zhuowen},
  booktitle    = {Artificial intelligence and statistics},
  pages        = {562--570},
  year         = {2015},
  organization = {PMLR},
}

%backbone
@article{VGG,
  title   = {Very deep convolutional networks for large-scale image recognition},
  author  = {Simonyan, Karen and Zisserman, Andrew},
  journal = {arXiv preprint arXiv:1409.1556},
  year    = {2014},
}

@inproceedings{Resnet,
  title     = {Deep residual learning for image recognition},
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = CVPR,
  pages     = {770--778},
  year      = {2016},
}

@inproceedings{Swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle=CVPR,
  pages={10012--10022},
  year={2021}
}

@inproceedings{CVT,
  title={Cvt: Introducing convolutions to vision transformers},
  author={Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},
  booktitle=ICCV,
  pages={22--31},
  year={2021}
}
@inproceedings{PVT,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle=ICCV,
  pages={568--578},
  year={2021}
}
@article{PVTv2,
  title={Pvt v2: Improved baselines with pyramid vision transformer},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  journal={Computational Visual Media},
  volume={8},
  pages={415--424},
  year={2022}
}


@inproceedings{DenseNet,
  title     = {Densely connected convolutional networks},
  author    = {Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle = CVPR,
  pages     = {4700--4708},
  year      = {2017},
}

@article{Res2Net,
  title   = {Res2net: A new multi-scale backbone architecture},
  author  = {Gao, Shang-Hua and Cheng, Ming-Ming and Zhao, Kai and Zhang, Xin-Yu and Yang, Ming-Hsuan and Torr, Philip},
  journal = TPAMI,
  volume  = {43},
  pages   = {652--662},
  year    = {2019},
}

@inproceedings{T2T,
  author    = {Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zi-Hang and Tay, Francis E.H. and Feng, Jiashi and Yan, Shuicheng},
  title     = {Tokens-to-Token ViT: Training Vision Transformers From Scratch on ImageNet},
  booktitle = ICCV,
  year      = {2021},
  pages     = {558-567},
}

@inproceedings{DeiT,
  title     = {Training data-efficient image transformers \& distillation through attention},
  author    = {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle = ICML,
  pages     = {10347--10357},
  year      = {2021},
}

@inproceedings{ResNeXt,
  title     = {Aggregated residual transformations for deep neural networks},
  author    = {Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle = CVPR,
  pages     = {1492--1500},
  year      = {2017},
}

@inproceedings{Xception,
  title     = {Xception: Deep learning with depthwise separable convolutions},
  author    = {Chollet, Fran{\c{c}}ois},
  booktitle = CVPR,
  pages     = {1251--1258},
  year      = {2017},
}

@inproceedings{MobileNetv2,
  title     = {Mobilenetv2: Inverted residuals and linear bottlenecks},
  author    = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle = CVPR,
  pages     = {4510--4520},
  year      = {2018},
}

@inproceedings{EfficientNet,
  title     = {Efficientnet: Rethinking model scaling for convolutional neural networks},
  author    = {Tan, Mingxing and Le, Quoc},
  booktitle = ICML,
  pages     = {6105--6114},
  year      = {2019},
}

@article{Mobilenet,
  title   = {Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author  = {Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal = {arXiv preprint arXiv:1704.04861},
  year    = {2017},
}

@inproceedings{PRelu,
  title     = {Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = ICCV,
  pages     = {1026--1034},
  year      = {2015},
}

@article{poly,
  title   = {Parsenet: Looking wider to see better},
  author  = {Liu, Wei and Rabinovich, Andrew and Berg, Alexander C},
  journal = {arXiv preprint arXiv:1506.04579},
  year    = {2015},
}

%%%%%%%%%%%%%%%%%%%Previous rgb sod
@inproceedings{DCL,
  title     = {Deep contrast learning for salient object detection},
  author    = {Li, Guanbin and Yu, Yizhou},
  booktitle = CVPR,
  pages     = {478--487},
  year      = {2016},
}

@inproceedings{DHS,
  title     = {Dhsnet: Deep hierarchical saliency network for salient object detection},
  author    = {Liu, Nian and Han, Junwei},
  booktitle = CVPR,
  pages     = {678--686},
  year      = {2016},
}

@inproceedings{NLDF,
  title     = {Non-local deep features for salient object detection},
  author    = {Luo, Zhiming and Mishra, Akshaya and Achkar, Andrew and Eichel, Justin and Li, Shaozi and Jodoin, Pierre-Marc},
  booktitle = CVPR,
  pages     = {6609--6617},
  year      = {2017},
}

@inproceedings{DSS,
  title     = {Deeply supervised salient object detection with short connections},
  author    = {Hou, Qibin and Cheng, Ming-Ming and Hu, Xiaowei and Borji, Ali and Tu, Zhuowen and Torr, Philip HS},
  booktitle = CVPR,
  pages     = {3203--3212},
  year      = {2017},
}

@inproceedings{SRM,
  title     = {A stagewise refinement model for detecting salient objects in images},
  author    = {Wang, Tiantian and Borji, Ali and Zhang, Lihe and Zhang, Pingping and Lu, Huchuan},
  booktitle = ICCV,
  pages     = {4019--4028},
  year      = {2017},
}

@inproceedings{Amulet,
  title     = {Amulet: Aggregating multi-level convolutional features for salient object detection},
  author    = {Zhang, Pingping and Wang, Dong and Lu, Huchuan and Wang, Hongyu and Ruan, Xiang},
  booktitle = ICCV,
  pages     = {202--211},
  year      = {2017},
}

%%%%%%  Multi-scale
@article{ASPP,
  title   = {Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs},
  author  = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L},
  journal = TPAMI,
  volume  = {40},
  pages   = {834--848},
  year    = {2017},
}

@inproceedings{DenseASPP,
  title     = {Denseaspp for semantic segmentation in street scenes},
  author    = {Yang, Maoke and Yu, Kun and Zhang, Chi and Li, Zhiwei and Yang, Kuiyuan},
  booktitle = CVPR,
  pages     = {3684--3692},
  year      = {2018},
}

@inproceedings{DilatedConvolution-SDC,
  author    = {Wang, Zhengyang and Ji, Shuiwang},
  title     = {Smoothed Dilated Convolutions for Improved Dense Prediction},
  year      = {2018},
  booktitle = {ACM SIGKDD},
  pages     = {2486--2495},
}

@inproceedings{DilatedConvolution-ESPNet,
  title     = {ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation},
  author    = {Sachin Mehta, Mohammad Rastegari, Anat Caspi, Linda Shapiro, and Hannaneh Hajishirzi},
  booktitle = {ECCV},
  year      = {2018},
}

@inproceedings{DilatedConvolution-TKCN,
  author    = {Wu, Tianyi and Tang, Sheng and Zhang, Rui and Cao, Juan and Li, JinTao},
  booktitle = {ICME},
  title     = {Tree-Structured Kronecker Convolutional Network for Semantic Segmentation},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {940--945},
}

@article{DilatedConvolution-C3Convolution,
  author  = {Park, Hyojin and Yoo, Youngjoon and Seo, Geonseok and Han, Dongyoon and Yun, Sangdoo and Kwak, Nojun},
  title   = {C3: Concentrated-Comprehensive Convolution and its application to semantic segmentation},
  journal = {arXiv preprint arXiv:1812.04920},
  year    = {2018},
}

@article{DilatedConvolution-ESDC,
  author  = {Ziegler, Thomas and Fritsche, Manuel and Kuhn, Lorenz and Donhauser, Konstantin},
  title   = {Efficient Smoothing of Dilated Convolutions for Image Segmentation},
  journal = {arXiv preprint arXiv:1903.07992},
  year    = {2019},
}

@inproceedings{DilatedConvolution-D3DNet,
  author    = {Takahashi, Naoya and Mitsufuji, Yuki},
  booktitle = {CVPR},
  title     = {Densely connected multidilated convolutional networks for dense prediction tasks},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {993--1002},
}

@inproceedings{boundarybackground,
  title     = {Saliency detection via graph-based manifold ranking},
  author    = {Yang, Chuan and Zhang, Lihe and Lu, Huchuan and Ruan, Xiang and Yang, Ming-Hsuan},
  booktitle = CVPR,
  pages     = {3166--3173},
  year      = {2013},
}

@inproceedings{centerprior,
  title     = {Submodular salient region detection},
  author    = {Jiang, Zhuolin and Davis, Larry S},
  booktitle = CVPR,
  pages     = {2043--2050},
  year      = {2013},
}

@article{Survey,
  title   = {Salient Object Detection in the Deep Learning Era: An In-Depth Survey},
  author  = {Wang, Wenguan and Lai, Qiuxia and Fu, Huazhu and Shen, Jianbing and Ling, Haibin},
  journal = {arXiv preprint arXiv:1904.09146},
  year    = {2019},
}

@inproceedings{PPM,
  title     = {Pyramid scene parsing network},
  author    = {Zhao, Hengshuang and Shi, Jianping and Qi, Xiaojuan and Wang, Xiaogang and Jia, Jiaya},
  booktitle = CVPR,
  pages     = {2881--2890},
  year      = {2017},
}

@inproceedings{gatedlabel,
  title     = {Gated feedback refinement network for dense image labeling},
  author    = {Amirul Islam, Md and Rochan, Mrigank and Bruce, Neil DB and Wang, Yang},
  booktitle = CVPR,
  pages     = {3751--3759},
  year      = {2017},
}

@inproceedings{Gate-RIGNet,
  author    = {Karim, Rezaul and Islam, Md Amirul and Bruce, Neil D. B.},
  booktitle = {WACV},
  title     = {Recurrent Iterative Gating Networks for Semantic Segmentation},
  year      = {2019},
  pages     = {1070-1079}
}

%%%%%%åŒ…è£…çš„ï¼Œç§‘å­¦æœºåˆ¶
@article{winner,
  title   = {Computational tradeoffs in biological neural networks: Self-stabilizing winner-take-all networks},
  author  = {Lynch, Nancy and Musco, Cameron and Parter, Merav},
  journal = {arXiv preprint arXiv:1610.02084},
  year    = {2016},
}

@article{NM,
  title   = {A dendritic disinhibitory circuit mechanism for pathway-specific gating},
  author  = {Yang, Guangyu Robert and Murray, John D and Wang, Xiao-Jing},
  journal = {Nature communications},
  volume  = {7},
  pages   = {12815},
  year    = {2016},
}

%%%%Previsous RGBD_SOD

@article{DCMC,
  title   = {Saliency detection for stereoscopic images based on depth confidence analysis and multiple cues fusion},
  author  = {Cong, Runmin and Lei, Jianjun and Zhang, Changqing and Huang, Qingming and Cao, Xiaochun and Hou, Chunping},
  journal = SPL,
  volume  = {23},
  number  = {6},
  pages   = {819--823},
  year    = {2016},
}

@inproceedings{MB,
  title     = {A multilayer backpropagation saliency detection algorithm based on depth mining},
  author    = {Zhu, Chunbiao and Li, Ge and Guo, Xiaoqiang and Wang, Wenmin and Wang, Ronggang},
  booktitle = {International Conference on Computer Analysis of Images and Patterns},
  pages     = {14--23},
  year      = {2017},
}

@inproceedings{CDCP,
  title     = {An innovative salient object detection using center-dark channel prior},
  author    = {Zhu, Chunbiao and Li, Ge and Wang, Wenmin and Wang, Ronggang},
  booktitle = ICCV,
  pages     = {1509--1515},
  year      = {2017},
}

@inproceedings{early_fusion_1,
  title     = {RGBD salient object detection: A benchmark and algorithms},
  author    = {Peng, Houwen and Li, Bing and Xiong, Weihua and Hu, Weiming and Ji, Rongrong},
  booktitle = ECCV,
  pages     = {92--109},
  year      = {2014},
}

@article{early_fusion_2,
  title   = {Depth-aware salient object detection and segmentation via multiscale discriminative saliency fusion and bootstrap learning},
  author  = {Song, Hangke and Liu, Zhi and Du, Huan and Sun, Guangling and Le Meur, Olivier and Ren, Tongwei},
  journal = TIP,
  volume  = {26},
  number  = {9},
  pages   = {4204--4216},
  year    = {2017},
}

@inproceedings{late_fusion,
  title     = {Salient region detection for stereoscopic images},
  author    = {Fan, Xingxing and Liu, Zhi and Sun, Guangling},
  booktitle = {International Conference on Digital Signal Processing},
  pages     = {454--458},
  year      = {2014},
}

@inproceedings{Middle_fusion,
  title     = {Local background enclosure for RGB-D salient object detection},
  author    = {Feng, David and Barnes, Nick and You, Shaodi and McCarthy, Chris},
  booktitle = CVPR,
  pages     = {2343--2350},
  year      = {2016},
}

@article{DF,
  title   = {RGBD salient object detection via deep fusion},
  author  = {Qu, Liangqiong and He, Shengfeng and Zhang, Jiawei and Tian, Jiandong and Tang, Yandong and Yang, Qingxiong},
  journal = TIP,
  volume  = {26},
  number  = {5},
  pages   = {2274--2285},
  year    = {2017},
}

@article{CTMF,
  title   = {CNNs-based RGB-D saliency detection via cross-view transfer and multiview fusion},
  author  = {Han, Junwei and Chen, Hao and Liu, Nian and Yan, Chenggang and Li, Xuelong},
  journal = {IEEE Transactions on Cybernetics},
  volume  = {48},
  number  = {11},
  pages   = {3171--3183},
  year    = {2017},
}

@article{AF_RGBD,
  title   = {Adaptive Fusion for RGB-D Salient Object Detection},
  author  = {Wang, Ningning and Gong, Xiaojin},
  journal = {IEEE Access},
  volume  = {7},
  pages   = {55277--55284},
  year    = {2019},
}

@inproceedings{CL_rgbd,
  title     = {Accurate rgb-d salient object detection via collaborative learning},
  author    = {Ji, Wei and Li, Jingjing and Zhang, Miao and Piao, Yongri and Lu, Huchuan},
  booktitle = ECCV,
  pages     = {52--69},
  year      = {2020},
}

%%%%%%%%%%%%%%%%%%%%%vos
@inproceedings{davis16,
  title     = {A benchmark dataset and evaluation methodology for video object segmentation},
  author    = {Perazzi, Federico and Pont-Tuset, Jordi and McWilliams, Brian and Van Gool, Luc and Gross, Markus and Sorkine-Hornung, Alexander},
  booktitle = CVPR,
  pages     = {724--732},
  year      = {2016},
}

@article{youtube-vos,
  title   = {Youtube-vos: A large-scale video object segmentation benchmark},
  author  = {Xu, Ning and Yang, Linjie and Fan, Yuchen and Yue, Dingcheng and Liang, Yuchen and Yang, Jianchao and Huang, Thomas},
  journal = {arXiv preprint arXiv:1809.03327},
  year    = {2018},
}

@inproceedings{LVO,
  title     = {Learning video object segmentation with visual memory},
  author    = {Tokmakov, Pavel and Alahari, Karteek and Schmid, Cordelia},
  booktitle = ICCV,
  pages     = {4481--4490},
  year      = {2017},
}

@inproceedings{ARP,
  title     = {Primary object segmentation in videos based on region augmentation and reduction},
  author    = {Jun Koh, Yeong and Kim, Chang-Su},
  booktitle = CVPR,
  pages     = {3442--3450},
  year      = {2017},
}

@inproceedings{PDB,
  title     = {Pyramid dilated deeper convlstm for video salient object detection},
  author    = {Song, Hongmei and Wang, Wenguan and Zhao, Sanyuan and Shen, Jianbing and Lam, Kin-Man},
  booktitle = ECCV,
  pages     = {715--731},
  year      = {2018},
}

@article{LSMO,
  title     = {Learning to segment moving objects},
  author    = {Tokmakov, Pavel and Schmid, Cordelia and Alahari, Karteek},
  journal   = IJCV,
  volume    = {127},
  number    = {3},
  pages     = {282--301},
  year      = {2019},
  publisher = {Springer},
}

@inproceedings{MotAdapt,
  title     = {Video object segmentation using teacher-student adaptation in a human robot interaction (hri) setting},
  author    = {Siam, Mennatullah and Jiang, Chen and Lu, Steven and Petrich, Laura and Gamal, Mahmoud and Elhoseiny, Mohamed and Jagersand, Martin},
  booktitle = {ICRA},
  pages     = {50--56},
  year      = {2019},
}

@article{EPO,
  title   = {Exploiting geometric constraints on dense trajectories for motion saliency},
  author  = {Faisal, Muhammad and Akhter, Ijaz and Ali, Mohsen and Hartley, Richard},
  journal = {arXiv preprint arXiv:1909.13258},
  year    = {2019},
}

@inproceedings{AGS,
  title     = {Learning unsupervised video object segmentation through visual attention},
  author    = {Wang, Wenguan and Song, Hongmei and Zhao, Shuyang and Shen, Jianbing and Zhao, Sanyuan and Hoi, Steven CH and Ling, Haibin},
  booktitle = CVPR,
  pages     = {3064--3074},
  year      = {2019},
}

@inproceedings{COSNet,
  title     = {See more, know more: Unsupervised video object segmentation with co-attention siamese networks},
  author    = {Lu, Xiankai and Wang, Wenguan and Ma, Chao and Shen, Jianbing and Shao, Ling and Porikli, Fatih},
  booktitle = CVPR,
  pages     = {3623--3632},
  year      = {2019},
}

@inproceedings{AnDiff,
  title     = {Anchor diffusion for unsupervised video object segmentation},
  author    = {Yang, Zhao and Wang, Qiang and Bertinetto, Luca and Hu, Weiming and Bai, Song and Torr, Philip HS},
  booktitle = ICCV,
  pages     = {931--940},
  year      = {2019},
}

@inproceedings{MATNet,
  title     = {Motion-Attentive Transition for Zero-Shot Video Object Segmentation.},
  author    = {Zhou, Tianfei and Wang, Shunzhou and Zhou, Yi and Yao, Yazhou and Li, Jianwu and Shao, Ling},
  booktitle = AAAI,
  volume    = {2},
  pages     = {3},
  year      = {2020},
}

@inproceedings{PWC,
  title     = {PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume},
  author    = {Sun, D and Yang, X and Liu, MY and Kautz, J},
  booktitle = CVPR,
  pages     = {8934â€“8943},
  year      = {2018},
}

@inproceedings{MSAPS,
  title     = {Multi-source fusion and automatic predictor selection for zero-shot video object segmentation},
  author    = {Zhao, Xiaoqi and Pang, Youwei and Yang, Jiaxing and Zhang, Lihe and Lu, Huchuan},
  booktitle = ACMMM,
  pages     = {2645--2653},
  year      = {2021},
}

%%%%%%Self supervised learning
@inproceedings{ImageNet,
  title     = {Imagenet: A large-scale hierarchical image database},
  author    = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle = CVPR,
  pages     = {248--255},
  year      = {2009},
}

@inproceedings{UVRL-context,
  title     = {Unsupervised visual representation learning by context prediction},
  author    = {Doersch, Carl and Gupta, Abhinav and Efros, Alexei A},
  booktitle = ICCV,
  pages     = {1422--1430},
  year      = {2015},
}

@inproceedings{UVRL-videos,
  title     = {Unsupervised learning of visual representations using videos},
  author    = {Wang, Xiaolong and Gupta, Abhinav},
  booktitle = ICCV,
  pages     = {2794--2802},
  year      = {2015},
}

@inproceedings{LSM,
  title     = {Learning to see by moving},
  author    = {Agrawal, Pulkit and Carreira, Joao and Malik, Jitendra},
  booktitle = ICCV,
  pages     = {37--45},
  year      = {2015},
}

@article{context1,
  title   = {A framework for learning predictive structures from multiple tasks and unlabeled data},
  author  = {Ando, Rie Kubota and Zhang, Tong},
  journal = {Journal of Machine Learning Research},
  volume  = {6},
  number  = {Nov},
  pages   = {1817--1853},
  year    = {2005},
}

%Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics
@inproceedings{context2,
  title     = {A discriminative language model with pseudo-negative samples},
  author    = {Okanohara, Daisuke and Tsujii, Junâ€™ichi},
  booktitle = {ACL},
  pages     = {73--80},
  year      = {2007},
}

@inproceedings{context3,
  title     = {A unified architecture for natural language processing: Deep neural networks with multitask learning},
  author    = {Collobert, Ronan and Weston, Jason},
  booktitle = ICML,
  pages     = {160--167},
  year      = {2008},
}

@inproceedings{context3,
  title     = {A unified architecture for natural language processing: Deep neural networks with multitask learning},
  author    = {Collobert, Ronan and Weston, Jason},
  booktitle = ICML,
  pages     = {160--167},
  year      = {2008},
}

@inproceedings{context4,
  title     = {Distributed representations of words and phrases and their compositionality},
  author    = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle = NIPS,
  pages     = {3111--3119},
  year      = {2013},
}

@inproceedings{CAM,
  title     = {Learning deep features for discriminative localization},
  author    = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  booktitle = CVPR,
  pages     = {2921--2929},
  year      = {2016},
}

@inproceedings{image_inpainting_ssl,
  title     = {Context encoders: Feature learning by inpainting},
  author    = {Pathak, Deepak and Krahenbuhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A},
  booktitle = CVPR,
  pages     = {2536--2544},
  year      = {2016},
}

@inproceedings{cluster_ssl,
  title     = {Deep clustering for unsupervised learning of visual features},
  author    = {Caron, Mathilde and Bojanowski, Piotr and Joulin, Armand and Douze, Matthijs},
  booktitle = ECCV,
  pages     = {132--149},
  year      = {2018},
}

@inproceedings{image_colorization_ssl,
  title     = {Colorization as a proxy task for visual understanding},
  author    = {Larsson, Gustav and Maire, Michael and Shakhnarovich, Gregory},
  booktitle = CVPR,
  pages     = {6874--6883},
  year      = {2017},
}

@inproceedings{temporal_order_verification_ssl,
  title     = {Shuffle and learn: unsupervised learning using temporal order verification},
  author    = {Misra, Ishan and Zitnick, C Lawrence and Hebert, Martial},
  booktitle = ECCV,
  pages     = {527--544},
  year      = {2016},
}

@inproceedings{visual_audio_correspondences_verification_ssl,
  title     = {Cooperative learning of audio and video models from self-supervised synchronization},
  author    = {Korbar, Bruno and Tran, Du and Torresani, Lorenzo},
  booktitle = NIPS,
  pages     = {7763--7774},
  year      = {2018},
}

@inproceedings{difficult_ssl,
  title     = {Scaling and benchmarking self-supervised visual representation learning},
  author    = {Goyal, Priya and Mahajan, Dhruv and Gupta, Abhinav and Misra, Ishan},
  booktitle = CVPR,
  pages     = {6391--6400},
  year      = {2019},
}

%%%%%%%%%LOSS
@article{BCE,
  title     = {A tutorial on the cross-entropy method},
  author    = {De Boer, Pieter-Tjerk and Kroese, Dirk P and Mannor, Shie and Rubinstein, Reuven Y},
  journal   = {Annals of operations research},
  volume    = {134},
  number    = {1},
  pages     = {19--67},
  year      = {2005},
  publisher = {Springer},
}

@inproceedings{SSIM,
  title     = {Multiscale structural similarity for image quality assessment},
  author    = {Wang, Zhou and Simoncelli, Eero P and Bovik, Alan C},
  booktitle = {The Thrity-Seventh Asilomar Conference on Signals, Systems \& Computers},
  volume    = {2},
  pages     = {1398--1402},
  year      = {2003},
}

%transformer

@inproceedings{transformer,
  title     = {Attention is all you need},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  booktitle = NIPS,
  pages     = {5998â€“6008},
  year      = {2017},
}

@inproceedings{DETR,
  title     = {End-to-end object detection with transformers},
  author    = {Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle = ECCV,
  pages     = {213--229},
  year      = {2020},
}

@inproceedings{transformer_classification,
  title     = {Generative pretraining from pixels},
  author    = {Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya},
  booktitle = ICLR,
  pages     = {1691--1703},
  year      = {2020},
}

@inproceedings{high_level_attention,
  title     = {Stand-Alone Self-Attention in Vision Models},
  author    = {Niki Parmar and
               Prajit Ramachandran and
               Ashish Vaswani and
               Irwan Bello and
               Anselm Levskaya and
               Jon Shlens},
  booktitle = NIPS,
  pages     = {68--80},
  year      = {2019},
}

@article{transformer_detection,
  title   = {Topological Planning with Transformers for Vision-and-Language Navigation},
  author  = {Chen, Kevin and Chen, Junshen K and Chuang, Jo and V{\'a}zquez, Marynel and Savarese, Silvio},
  journal = {arXiv preprint arXiv:2012.05292},
  year    = {2020},
}

@article{transformer_tracking,
  title   = {Transformer tracking},
  author  = {Chen, Xin and Yan, Bin and Zhu, Jiawen and Wang, Dong and Yang, Xiaoyun and Lu, Huchuan},
  journal = {arXiv preprint arXiv:2103.15436},
  year    = {2021},
}

@article{transformer_vis,
  title   = {End-to-End Video Instance Segmentation with Transformers},
  author  = {Wang, Yuqing and Xu, Zhaoliang and Wang, Xinlong and Shen, Chunhua and Cheng, Baoshan and Shen, Hao and Xia, Huaxia},
  journal = {arXiv preprint arXiv:2011.14503},
  year    = {2020},
}

@article{transformer_ss,
  title   = {Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers},
  author  = {Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others},
  journal = {arXiv preprint arXiv:2012.15840},
  year    = {2020},
}

@article{ViT,
  title   = {An image is worth 16x16 words: Transformers for image recognition at scale},
  author  = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal = {arXiv preprint arXiv:2010.11929},
  year    = {2020},
}

@inproceedings{depth3,
  title     = {Superdepth: Self-supervised, super-resolved monocular depth estimation},
  author    = {Pillai, Sudeep and Ambru{\c{s}}, Rare{\c{s}} and Gaidon, Adrien},
  booktitle = ICRA,
  pages     = {9250--9256},
  year      = {2019},
}

@article{depth4,
  title     = {Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer},
  author    = {Ranftl, Ren{\'e} and Lasinger, Katrin and Hafner, David and Schindler, Konrad and Koltun, Vladlen},
  journal   = TPAMI,
  year      = {2020},
  publisher = {IEEE},
}

@article{depth5,
  title   = {RealMonoDepth: Self-Supervised Monocular Depth Estimation for General Scenes},
  author  = {Ocal, Mertalp and Mustafa, Armin},
  journal = {arXiv preprint arXiv:2004.06267},
  year    = {2020},
}

@inproceedings{FCRN,
  title     = {Deeper depth prediction with fully convolutional residual networks},
  author    = {Laina, Iro and Rupprecht, Christian and Belagiannis, Vasileios and Tombari, Federico and Navab, Nassir},
  booktitle = ThreeDV,
  pages     = {239--248},
  year      = {2016},
}

@article{TL-Depth,
  title   = {High quality monocular depth estimation via transfer learning},
  author  = {Alhashim, Ibraheem and Wonka, Peter},
  journal = {arXiv preprint arXiv:1812.11941},
  year    = {2018},
}

@article{LAP-Depth,
  title     = {Monocular Depth Estimation Using Laplacian Pyramid-Based Depth Residuals},
  author    = {Song, Minsoo and Lim, Seokjae and Kim, Wonjun},
  journal   = TCSVT,
  year      = {2021},
  publisher = {IEEE},
}

%%%Multi-task
@inproceedings{MTL_NLP_1,
  title     = {Multi-task learning for multiple language translation},
  author    = {Dong, Daxiang and Wu, Hua and He, Wei and Yu, Dianhai and Wang, Haifeng},
  booktitle = ACL,
  pages     = {1723--1732},
  year      = {2015},
}

@inproceedings{MTL_NLP_2,
  title     = {A hierarchical multi-task approach for learning embeddings from semantic tasks},
  author    = {Sanh, Victor and Wolf, Thomas and Ruder, Sebastian},
  booktitle = AAAI,
  volume    = {33},
  number    = {01},
  pages     = {6949--6956},
  year      = {2019},
}

@inproceedings{MTL_CV_1,
  title        = {Facial landmark detection by deep multi-task learning},
  author       = {Zhang, Zhanpeng and Luo, Ping and Loy, Chen Change and Tang, Xiaoou},
  booktitle    = ECCV,
  pages        = {94--108},
  year         = {2014},
  organization = {Springer},
}

@inproceedings{MTL_CV_2,
  title     = {End-to-end multi-task learning with attention},
  author    = {Liu, Shikun and Johns, Edward and Davison, Andrew J},
  booktitle = CVPR,
  pages     = {1871--1880},
  year      = {2019},
}

@inproceedings{MTL_RL_1,
  title        = {Learning to push by grasping: Using multiple tasks for effective learning},
  author       = {Pinto, Lerrel and Gupta, Abhinav},
  booktitle    = ICRA,
  pages        = {2161--2168},
  year         = {2017},
  organization = {IEEE},
}

@inproceedings{MTL_RL_2,
  title        = {Learning synergies between pushing and grasping with self-supervised deep reinforcement learning},
  author       = {Zeng, Andy and Song, Shuran and Welker, Stefan and Lee, Johnny and Rodriguez, Alberto and Funkhouser, Thomas},
  booktitle    = IROS,
  pages        = {4238--4245},
  year         = {2018},
  organization = {IEEE},
}

@inproceedings{Hard_parameter_sharing,
  author    = {Rich Caruana},
  title     = {Multitask Learning: {A} Knowledge-Based Source of Inductive Bias},
  booktitle = ICML,
  pages     = {41--48},
  year      = {1993},
}

@inproceedings{soft_parameter_sharing,
  title     = {Low resource dependency parsing: Cross-lingual parameter sharing in a neural network parser},
  author    = {Duong, Long and Cohn, Trevor and Bird, Steven and Cook, Paul},
  booktitle = ACL,
  pages     = {845--850},
  year      = {2015},
}

@inproceedings{Hard_parameter_sharing_1,
  title     = {Learning Multiple Tasks with Multilinear Relationship Networks},
  author    = {Long, Mingsheng and CAO, ZHANGJIE and Wang, Jianmin and Yu, Philip S},
  booktitle = NIPS,
  pages     = {1593--1602},
  year      = {2017},
}

@inproceedings{Hard_parameter_sharing_2,
  title     = {Multi-Task Learning as Multi-Objective Optimization},
  author    = {Sener, Ozan and Koltun, Vladlen},
  booktitle = NIPS,
  pages     = {525--536},
  year      = {2018},
}

@inproceedings{Hard_parameter_sharing_3,
  title     = {Latent multi-task architecture learning},
  author    = {Ruder, Sebastian and Bingel, Joachim and Augenstein, Isabelle and S{\o}gaard, Anders},
  booktitle = AAAI,
  volume    = {33},
  number    = {01},
  pages     = {4822--4829},
  year      = {2019},
}

@inproceedings{Adam,
  title     = {Adam: A method for stochastic optimization},
  author    = {Kingma, Diederick P and Ba, Jimmy},
  booktitle = ICLR,
  year      = {2015},
}

@inproceedings{DIP,
  title     = {Deep image prior},
  author    = {Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  booktitle = CVPR,
  pages     = {9446--9454},
  year      = {2018},
}

@article{ImagePyramid,
  author  = {Adelson, Edward and Anderson, Charles and Bergen, James and Burt, Peter and Ogden, Joan},
  year    = {1983},
  month   = {11},
  pages   = {},
  title   = {Pyramid Methods in Image Processing},
  volume  = {29},
  journal = {RCA Eng.},
}

@inproceedings{LargeKernel,
  title     = {Large kernel matters--improve semantic segmentation by global convolutional network},
  author    = {Peng, Chao and Zhang, Xiangyu and Yu, Gang and Luo, Guiming and Sun, Jian},
  booktitle = CVPR,
  pages     = {4353--4361},
  year      = {2017},
}

@inproceedings{Nonlocal,
  title     = {Non-local neural networks},
  author    = {Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
  booktitle = CVPR,
  pages     = {7794--7803},
  year      = {2018},
}

@inproceedings{SENet,
  title     = {Squeeze-and-excitation networks},
  author    = {Hu, Jie and Shen, Li and Sun, Gang},
  booktitle = CVPR,
  pages     = {7132--7141},
  year      = {2018},
}

%rebuttal
@inproceedings{Osformer,
  title={Osformer: One-stage camouflaged instance segmentation with transformers},
  author={Pei, Jialun and Cheng, Tianyang and Fan, Deng-Ping and Tang, He and Chen, Chuanbo and Van Gool, Luc},
  booktitle=ECCV,
  pages={19--37},
  year={2022}
}
@inproceedings{DTIT,
  title={Boosting camouflaged object detection with dual-task interactive transformer},
  author={Liu, Zhengyi and Zhang, Zhili and Tan, Yacheng and Wu, Wei},
  booktitle={ICPR},
  pages={140--146},
  year={2022}
}
@inproceedings{HitNet,
  title={High-resolution iterative feedback network for camouflaged object detection},
  author={Hu, Xiaobin and Wang, Shuo and Qin, Xuebin and Dai, Hang and Ren, Wenqi and Luo, Donghao and Tai, Ying and Shao, Ling},
  booktitle={AAAI},
  volume={37},
  pages={881--889},
  year={2023}
}
@inproceedings{SSFormer,
  title={Stepwise feature fusion: Local guides global},
  author={Wang, Jinfeng and Huang, Qiming and Tang, Feilong and Meng, Jia and Su, Jionglong and Song, Sifan},
  booktitle={MICCAI},
  pages={110--120},
  year={2022}
}
@inproceedings{transformer_training_1,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={ICML},
  pages={10347--10357},
  year={2021}
}
@inproceedings{transformer_training_2,
  title={An empirical study of training end-to-end vision-and-language transformers},
  author={Dou, Zi-Yi and Xu, Yichong and Gan, Zhe and Wang, Jianfeng and Wang, Shuohang and Wang, Lijuan and Zhu, Chenguang and Zhang, Pengchuan and Yuan, Lu and Peng, Nanyun and others},
  booktitle={CVPR},
  pages={18166--18176},
  year={2022}
}
@article{transformer_training_3,
  title={A survey on efficient training of transformers},
  author={Zhuang, Bohan and Liu, Jing and Pan, Zizheng and He, Haoyu and Weng, Yuetian and Shen, Chunhua},
  journal={arXiv preprint arXiv:2302.01107},
  year={2023}
}
@inproceedings{FCN,
  title={Fully convolutional networks for semantic segmentation},
  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle=CVPR,
  pages={3431--3440},
  year={2015}
}
@inproceedings{EncNet,
  title={Context encoding for semantic segmentation},
  author={Zhang, Hang and Dana, Kristin and Shi, Jianping and Zhang, Zhongyue and Wang, Xiaogang and Tyagi, Ambrish and Agrawal, Amit},
  booktitle=CVPR,
  pages={7151--7160},
  year={2018}
}
@inproceedings{PSPNet,
  title={Pyramid scene parsing network},
  author={Zhao, Hengshuang and Shi, Jianping and Qi, Xiaojuan and Wang, Xiaogang and Jia, Jiaya},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2881--2890},
  year={2017}
}
@inproceedings{CCNet,
  title={Ccnet: Criss-cross attention for semantic segmentation},
  author={Huang, Zilong and Wang, Xinggang and Huang, Lichao and Huang, Chang and Wei, Yunchao and Liu, Wenyu},
  booktitle=ICCV,
  pages={603--612},
  year={2019}
}
@inproceedings{Deeplabv3+,
  title={Encoder-decoder with atrous separable convolution for semantic image segmentation},
  author={Chen, Liang-Chieh and Zhu, Yukun and Papandreou, George and Schroff, Florian and Adam, Hartwig},
  booktitle=ECCV,
  pages={801--818},
  year={2018}
}
@inproceedings{SETR,
  title={Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers},
  author={Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others},
  booktitle=CVPR,
  pages={6881--6890},
  year={2021}
}
@inproceedings{SegFormer,
  title={SegFormer: Simple and efficient design for semantic segmentation with transformers},
  author={Xie, Enze and Wang, Wenhai and Yu, Zhiding and Anandkumar, Anima and Alvarez, Jose M and Luo, Ping},
  booktitle={NeurIPS},
  pages={12077--12090},
  year={2021}
}
@inproceedings{Mask2Former,
  title={Masked-attention mask transformer for universal image segmentation},
  author={Cheng, Bowen and Misra, Ishan and Schwing, Alexander G and Kirillov, Alexander and Girdhar, Rohit},
  booktitle=CVPR,
  pages={1290--1299},
  year={2022}
}



%%%End