			\begin{tabular}{|c|c|r|c|c||c|c|c|c|}
				\hline\thickhline
				\rowcolor{mygray}
				
				% &\#&
				No.&Year&Methods&Publication &\tabincell{c}{Code\\Link}  &Backbone
				&\tabincell{c}{Learning\\Paradigm} &Training Dataset &\#Training  \\
												%遥感和医学图像
				\hline
				\hline
				\multicolumn{9}{|c|}{\multirow{2}{*}{\large\textbf{Salient Object Detection in Optical Remote Sensing Images}}}
				\\
				\multicolumn{9}{|c|}{}		\\
				\hline
				\hline
				%Nested Network With Two-Stream Pyramid for Salient Object Detection in Optical Remote Sensing Images
				105&	\multirow{9}{*}{\rotatebox{90}{2019--2023}} &LV-Net\cite{LV-Net_RSISOD} &TGRS &N/A &N/A &STL  &ORSSD~\cite{LV-Net_RSISOD}&600\\
				%Dense Attention Fluid Network for Salient ObjectDetection in Optical Remote Sensing Images
				106& &DAFNet\cite{DAFNet_RSISOD} &TIP &\href{https://github.com/rmcong/DAFNet_TIP20}{Pytorch$^{*}$} &VGG-16~\cite{VGG} &MTL  &ORSSD~\cite{LV-Net_RSISOD}/EORSSD~\cite{DAFNet_RSISOD}&600/1,400\\
				%A parallel down-up fusion network for salient object detection in optical remote sensing images
				107& &PDF-Net\cite{PDF-Net_RSISOD} &NC &N/A &VGG-16~\cite{VGG} &STL  &ORSSD~\cite{LV-Net_RSISOD}&600\\
				%Edge-Aware Multiscale Feature Integration Networkfor Salient Object Detection in OpticalRemote Sensing Images
				108& &MFI-Net\cite{MFI-Net_RSISOD} &TGRS &N/A &ResNet-34~\cite{Resnet}/VGG-16~\cite{VGG} &MTL  &ORSSD~\cite{LV-Net_RSISOD}/EORSSD~\cite{DAFNet_RSISOD}&600/1,400\\
				%RRNet : Relational Reasoning Network withParallel Multi-scale Attention for Salient ObjectDetection in Optical Remote Sensing Images  	
				109& &RRNet\cite{RRNet_RSISOD} &TGRS &\href{https://github.com/rmcong/RRNet_TGRS2021}{Pytorch} &Res2Net-50~\cite{Res2Net} &STL  &ORSSD~\cite{LV-Net_RSISOD}/EORSSD~\cite{DAFNet_RSISOD}&600/1,400\\
				%Multi-Content Complementation Networkfor Salient Object Detectionin Optical Remote Sensing Images
				%141& &MCCNet\cite{MCCNet_RSISOD} &TGRS &\href{https://github.com/MathLee/MCCNet}{Pytorch} &VGG-16~\cite{VGG} &STL  &ORSSD~\cite{LV-Net_RSISOD}/EORSSD~\cite{EORSSD}&600/1,400&Multi-content  complementation module; Fast inference speed &Progressive& &\yes &\yes\\
				% GGRNet: Global Graph ReasoningNetwork for Salient Object Detectionin Optical Remote Sensing Images
				110& &GGRNet\cite{GGRNet_RSISOD} &PRCV &N/A &ResNet-50~\cite{Resnet} &STL  &ORSSD~\cite{LV-Net_RSISOD}/EORSSD~\cite{DAFNet_RSISOD}&600/1,400\\
				% ORSI Salient Object Detection via Multiscale JointRegion and Boundary Model
				111& &MJRBM\cite{MJRBM_RSISOD} &TGRS &\href{https://github.com/wchao1213/ORSI-SOD}{Pytorch} &ResNet-50~\cite{Resnet}/VGG-16~\cite{VGG} &STL  &ORSSD~\cite{LV-Net_RSISOD}/EORSSD~\cite{DAFNet_RSISOD}/ORSI-4199~\cite{MJRBM_RSISOD} &600/1,400/2,000\\
    112& &CorrNet\cite{CorrNet_RSISOD} &TGRS &\href{https://github.com/MathLee/CorrNet}{Pytorch} &VGG-16~\cite{VGG} &STL  &ORSSD~\cite{LV-Net_RSISOD}/EORSSD~\cite{DAFNet_RSISOD} &600/1,400\\
113& &MCCNet\cite{MCCNet_RSISOD} &TGRS &\href{https://github.com/MathLee/MCCNet}{Pytorch} &VGG-16~\cite{VGG} &STL  &ORSSD~\cite{LV-Net_RSISOD}/EORSSD~\cite{DAFNet_RSISOD} &600/1,400\\
114& &HFANet\cite{HFANet_RSISOD} &TGRS &N/A &ResNet-50~\cite{Resnet}/VGG-16~\cite{VGG} &MTL  &ORSSD~\cite{LV-Net_RSISOD}/EORSSD~\cite{DAFNet_RSISOD}/ORSI-4199~\cite{MJRBM_RSISOD} &600/1,400/2,000\\
115& &CIFNet\cite{CIFNet_RSISOD} &GRSL &\href{https://github.com/ZhengJianwei2/BAFS-Net}{Pytorch} &Res2Net-50~\cite{Res2Net} &STL  &ORSSD~\cite{LV-Net_RSISOD}/EORSSD~\cite{DAFNet_RSISOD} &600/1,400\\
116& &BAFS-Net\cite{BAFS-Net_RSISOD} &TGRS &\href{https://github.com/ZhengJianwei2/BAFS-Net}{Pytorch} &ResNet-50~\cite{Resnet} &STL  &ORSSD~\cite{LV-Net_RSISOD}/EORSSD~\cite{DAFNet_RSISOD} &600/1,400\\

				\hline
				\hline
				\multicolumn{9}{|c|}{\multirow{2}{*}{\large\textbf{Camouflaged Object Detection}}}
				\\
				\multicolumn{9}{|c|}{}		\\
				\hline
				\hline
				117&	\multirow{9}{*}{\rotatebox{90}{2020--2021}} &SINet\cite{SINet_COD} &CVPR &\href{https://github.com/DengPingFan/SINet}{Pytorch} &ResNet-50~\cite{Resnet} &STL  &COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO}&4,040\\
				118&	&PFNet\cite{PFNet_COD} &CVPR &\href{https://mhaiyang.github.io/CVPR2021_PFNet/index.html}{Pytorch} &ResNet-50~\cite{Resnet} &STL  &COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO}&4,040\\
				119&	&Rank-Net\cite{Rank-Net_COD} &CVPR &\href{https://github.com/JingZhang617/COD-Rank-Localize-and-Segment}{Pytorch} &ResNet-50~\cite{Resnet} &STL  &COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO}&4,040\\
				120&	&MGL\cite{MGL_COD} &CVPR &\href{https://github.com/fanyang587/MGL}{Pytorch} &ResNet-50~\cite{Resnet} &MTL  &COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO}&4,040\\
				121&&JSODCOD\cite{KRN} &CVPR &\href{https://github.com/JingZhang617/Joint_COD_SOD}{Pytorch} &ResNet-50~\cite{Resnet} &MTL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO}+DUTS~\cite{DUTS} &14,593\\
				122&	&UGTR\cite{UGTR_COD} &ICCV &\href{https://github.com/fanyang587/UGTR}{Pytorch} &ResNet-50~\cite{Resnet} &STL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\
				%MirrorNet: Bio-Inspired Camouflaged Object Segmentation
				123&	&MirrorNet\cite{MirrorNet_COD} &Access &N/A &ResNet-50~\cite{Resnet} &STL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\
				%Deep Texture-Aware Features for Camouflaged Object Detection
				124&	&TANet\cite{TANet_COD} &TCSVT &N/A &ResNet-50~\cite{Resnet} &STL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\
				125&	&ERRNet\cite{ERRNet_COD} &PR &N/A &ResNet-50~\cite{Resnet} &STL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO}&4,040\\ 
    \hline
 126&	\multirow{9}{*}{\rotatebox{90}{2022}} 
   	&PreyNet\cite{PreyNet_COD} &ACM MM &\href{https://github.com/DUT-IIAU-OIP-Lab/PreyNet}{Pytorch} &ResNet-50~\cite{Resnet} &MTL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\
    127&	&BGNet\cite{BGNet_COD} &IJCAI&\href{https://github.com/thograce/BGNet}{Pytorch} &Res2Net-50~\cite{Res2Net} &MTL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\
    128&	&SegMaR\cite{SegMaR_COD} &CVPR&\href{https://github.com/dlut-dimt/SegMaR}{Pytorch} &ResNet-50~\cite{Resnet} &MTL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\
129&	&FM\cite{FM_COD} &CVPR&N/A &Res2Net-50~\cite{Res2Net}/ResNet-50~\cite{Resnet} &MTL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\
130&	&ZoomNet\cite{ZoomNet_COD} &CVPR&\href{https://github.com/lartpang/ZoomNet}{Pytorch}  &ResNet-50~\cite{Resnet} &STL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\
131&	&SINet-v2\cite{SINet-v2_COD} &T-PAMI&\href{https://github.com/DengPingFan/SINet}{Pytorch}  &ResNet-50~\cite{Resnet} &STL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\
132&	&FAPNet\cite{FAPNet_COD} &TIP&\href{https://github.com/taozh2017/FAPNet}{Pytorch}  &Res2Net-50~\cite{Res2Net} &MTL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\
133&	&FindNet\cite{FindNet_COD} &TIP&N/A  &ResNet-50~\cite{Resnet} &STL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\
134&	&R-MGL-V2\cite{R-MGL-V2_COD} &TIP&\href{https://github.com/fanyang587/MGL}{Pytorch}  &ResNet-50~\cite{Resnet} &MTL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\
\hline
135&\multirow{4}{*}{\rotatebox{90}{2023}}
 &FPNet\cite{FPNet_COD} &ACM MM &N/A &PVT~\cite{PVT} &STL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\
136& &FSPNet\cite{FSPNet_COD} &CVPR&\href{https://github.com/ZhouHuang23/FSPNet}{Pytorch}&ViT-B~\cite{ViT} &STL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\
137& &FEDER\cite{FEDER_COD} &CVPR&\href{https://github.com/ChunmingHe/FEDER}{Pytorch}&Res2Net-50~\cite{Res2Net}/ResNet-50~\cite{Resnet}&MTL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\
138& &HitNet\cite{HitNet_COD} &AAAI&N/A&PVT~\cite{PVT}&STL  & COD10K~\cite{SINet_COD}+CAMO~\cite{CAMO} &4,040\\



				\hline
				\hline
				\multicolumn{9}{|c|}{\multirow{2}{*}{\large\textbf{Defocus Blur Detection}}}
				\\
				\multicolumn{9}{|c|}{}		\\
				\hline
				\hline
				% Defocus Blur Detection via Multi-Stream Bottom-Top-Bottom Fully Convolutional Network
				139&	\multirow{11}{*}{\rotatebox{90}{2018--2023}} &BTBNet\cite{BTBNet_DBD} &CVPR &N/A &VGG-16~\cite{VGG} &STL  &CUHK~\cite{FSDNet_Shadow}+DUT~\cite{BTBNet_DBD}&1,204\\
				%DeFusionNET: Defocus Blur Detection via Recurrently Fusing and Refining Multi-scale Deep Features
				140& &DeFusionNet\cite{DeFusionNet_DBD} &CVPR &N/A &VGG-16~\cite{VGG} &STL  &CUHK~\cite{FSDNet_Shadow}+DUT~\cite{BTBNet_DBD}&1,204\\
				%Enhancing diversity of defocus blur detectors via cross-ensemble network
				141& &CENet\cite{CENet_DBD} &CVPR &\href{http://ice.dlut.edu.cn/ZhaoWenda/CENet.html}{Caffe} &VGG-16~\cite{VGG} &STL  &CUHK~\cite{FSDNet_Shadow}+DUT~\cite{BTBNet_DBD}&1,204\\
				%R2MRF: Defocus Blur Detection viaRecurrently Refining Multi-Scale Residual Features
				142& &R2MRF\cite{R2MRF_DBD} &AAAI &N/A&DenseNet-161~\cite{DenseNet}/VGG-16~\cite{VGG} &STL &CUHK~\cite{FSDNet_Shadow}+DUT~\cite{BTBNet_DBD}&1,204\\
				%BR2Net: Defocus Blur Detection Via a BidirectionalChannel Attention Residual Refining Network
				143& &BR2Net\cite{BR2Net_DBD} &TMM &N/A&ResNeXt~\cite{ResNeXt}/VGG-16~\cite{VGG} &STL  &CUHK~\cite{FSDNet_Shadow}+DUT~\cite{BTBNet_DBD}&1,204\\
				%Defocus Blur Detection via Depth Distillation
				144& &Depth-Distill\cite{Depth-Distill_DBD} &ECCV &\href{https://github.com/vinthony/depth-distillation}{Pytorch}&ResNeXt-101~\cite{ResNeXt}/VGG-19~\cite{VGG} &MTL  &CUHK~\cite{FSDNet_Shadow}+DUT~\cite{BTBNet_DBD}&1,204\\
				%Image-Scale-Symmetric Cooperative Network forDefocus Blur Detection
				145& &IS2CNet\cite{IS2CNet_DBD}&TCSVT &\href{https://github.com/wdzhao123/IS2CNet}{Caffe} &VGG-16~\cite{VGG}&STL &CUHK~\cite{FSDNet_Shadow}+DUT~\cite{BTBNet_DBD}&1,204\\
				%Self-generated Defocus Blur Detection via Dual Adversarial Discriminators
				146& &SG\cite{SG_DBD}&CVPR &\href{https://github.com/shangcai1/SG}{Pytorch} &VGG-16~\cite{VGG}&STL &CUHK~\cite{FSDNet_Shadow}+DUT~\cite{BTBNet_DBD}&1,204\\
				%Defocus Blur Detection via Boosting Diversityof Deep Ensemble Networks
				147& &DENets\cite{DENets_DBD}&TIP &\href{https://github.com/wdzhao123/DENets}{Pytorch} &VGG-16~\cite{VGG}&STL  &CUHK~\cite{FSDNet_Shadow}+DUT~\cite{BTBNet_DBD}&1,204\\
148& &APL\cite{APL_DBD}&ECCV &\href{https://github.com/wdzhao123/APL}{Pytorch} &VGG-16~\cite{VGG}&STL  &CUHK~\cite{FSDNet_Shadow}+DUT~\cite{BTBNet_DBD}&1,204\\
149& &MA-GANet\cite{MA-GANet_DBD}&TIP &N/A &VGG-16~\cite{VGG}&STL  &CTCUG~\cite{CTCUG}+DUT~\cite{BTBNet_DBD}&1,204\\
150& &M2CS\cite{M2CS_DBD}&TIP &\href{https://github.com/jerysaw/M2CS}{Pytorch} &VGG-16~\cite{VGG}&STL&CUHK~\cite{FSDNet_Shadow}/DUT~\cite{BTBNet_DBD}&704/60\\
151& &MLDBD\cite{MLDBD_DBD}&TMM &\href{https://github.com/wdzhao123/MLDBD}{Pytorch} &VGG-16~\cite{VGG}&STL&CUHK~\cite{FSDNet_Shadow}+DUT~\cite{BTBNet_DBD}&1,204\\
				
				\hline
				\hline
				\multicolumn{9}{|c|}{\multirow{2}{*}{\large\textbf{Shadow Detection}}}
				\\
				\multicolumn{9}{|c|}{}		\\
				\hline
				\hline
				
	
	
				%Stacked Conditional Generative Adversarial Networks for Jointly LearningShadow Detection and Shadow Removal
				%2018年
				152&	\multirow{12}{*}{\rotatebox{90}{2018--2023}} &ST-CGAN \cite{ST-CGAN_Shadow} &CVPR &N/A &ResNeXt-101~\cite{ResNeXt} &MTL  & ISTD~\cite{ST-CGAN_Shadow}/SBU~\cite{SBU}&1,330/4,089\\
				% Direction-aware Spatial Context Features for Shadow Detection
				153& &DSC \cite{DSC_Shadow} &CVPR &\href{https://github.com/xw-hu/DSC}{Caffe} &VGG-16~\cite{VGG} &STL  & SBU~\cite{SBU}&4,089\\
				%A+ D net: Training a shadow detector with adversarialshadow attenuation.
				154& &ADNet \cite{ADNet_Shadow} &ECCV &\href{https://github.com/lmhieu612/ADNET_demo}{Pytorch} &N/A &STL  & SBU~\cite{SBU}&4,089\\
				%Bidirectional Feature Pyramid Network withRecurrent Attention Residual Modulesfor Shadow Detection
				155& &BDRAR \cite{BDRAR_Shadow} &ECCV &\href{https://github.com/zijundeng/BDRAR}{Pytorch} &ResNeXt-101~\cite{ResNeXt} &STL  & SBU~\cite{SBU}&4,089\\
				%2019
				%ARGAN: Attentive Recurrent Generative Adversarial Network for ShadowDetection and Removal（ICCV2019）
				156& &ARGAN \cite{ARGAN_Shadow} &ICCV &N/A &VGG-16~\cite{VGG} &STL  & ISTD~\cite{ST-CGAN_Shadow}/SBU~\cite{SBU}&1,330/4,089\\
				%Distraction-aware Shadow Detection
				157& &DSDNet \cite{DSDNet_Shadow} &CVPR &\href{https://github.com/starkgate/Distraction-aware-Shadow-Detection}{Pytorch} &ResNeXt-101~\cite{ResNeXt} &STL  & ISTD~\cite{ST-CGAN_Shadow}/SBU~\cite{SBU}&1,330/4,089\\
				%2020   
				%Attentive Feedback Feature PyramidNetwork for Shadow Detection
				158& &AFFPN\cite{AFFPN_Shadow} &SPL &\href{https://github.com/JinheeKIM94/AFFPN_release}{Pytorch} &ResNeXt-101~\cite{ResNeXt} &STL  & ISTD~\cite{ST-CGAN_Shadow}/SBU~\cite{SBU}&1,330/4,089\\
				%2021   
				%Shadow Detection via Predicting the Confidence Mapsof Shadow Detection Methods
				159& &RCMPNet\cite{RCMPNet_Shadow} &ACM MM &N/A &ResNet~\cite{Resnet} &STL  & SBU~\cite{SBU}&4,089\\
				160& &MIB\cite{MIB_Shadow} &ICCV &N/A &EfficientNet-B3~\cite{EfficientNet}/ResNeXt-101~\cite{ResNeXt} &STL  &ISTD~\cite{ST-CGAN_Shadow}/SBU~\cite{SBU}&1,330/4,089\\
				161& &FSDNet\cite{FSDNet_Shadow} &TIP&\href{https://github.com/xw-hu/FSDNet}{Pytorch} &MobileNet-V2~\cite{MobileNetv2}  &STL  &CUHK-Shadow~\cite{FSDNet_Shadow}&7,350\\
				%Robust Shadow Detection by Exploring Effective Shadow Contexts
				162& &ECA\cite{ECA_Shadow} &ACM MM &N/A &ResNet-101~\cite{Resnet} &STL  &ISTD~\cite{ST-CGAN_Shadow}/SBU~\cite{SBU}/CUHK-Shadow ~\cite{FSDNet_Shadow}&1,330/4,089/7,350\\
				163& &SILT\cite{SILT_Shadow} &ICCV &\href{https://github.com/Cralence/SILT}{Pytorch} &PVT-v2-B5~\cite{PVTv2} &STL  &ISTD~\cite{ST-CGAN_Shadow}/SBU~\cite{SBU}/CUHK-Shadow ~\cite{FSDNet_Shadow}&1,330/4,089/7,350\\
				\hline
				\hline
				\multicolumn{9}{|c|}{\multirow{2}{*}{\large\textbf{Transparent Object Detection}}}
				\\
				\multicolumn{9}{|c|}{}		\\
				\hline
				\hline
				
				%TOM-Net: Learning Transparent Object Matting from a Single Image
				%2018年
				164&	\multirow{4}{*}{\tiny\rotatebox{90}{2018--2023}} &TOM-Net \cite{TOM-Net_Transparent} &CVPR &\href{https://github.com/guanyingc/TOM-Net}{Torch} &VGG-16~\cite{VGG} &MTL  & TOM-Net ~\cite{TOM-Net_Transparent}&178,000\\
				%Segmenting Transparent Objects in the Wild
				165& &TransLab \cite{TransLab_Transparent} &ECCV &\href{https://github.com/xieenze/Segment_Transparent_Objects}{Pytorch} &ResNet-50~\cite{Resnet} &MTL  & Trans10K~\cite{TransLab_Transparent}&5,000\\
				%Segmenting Transparent Object in the Wild with Transformer
				166& &Trans2Seg \cite{Trans2Seg_Transparent} &IJCAI &\href{https://github.com/xieenze/Trans2Seg}{Pytorch} &ResNet-50~\cite{Resnet} &STL  & Trans10K-v2~\cite{Trans2Seg_Transparent}&5,000\\
				167& &Transfusion \cite{Transfusion_Transparent} &ICCV &N/A &ResNet-50~\cite{Resnet} &MTL  & Trans10K~\cite{TransLab_Transparent}&5,000\\

				
				\hline
				\hline
				\multicolumn{9}{|c|}{\multirow{2}{*}{\large\textbf{Glass Object Detection}}}
				\\
				\multicolumn{9}{|c|}{}		\\
				\hline
				\hline
				
				
				%Don’t Hit Me! Glass Detection in Real-world Scenes
				%2020年
				168&	\multirow{5}{*}{\tiny{\rotatebox{90}{2020--2023}}} &GDNet \cite{GDNet_Glass} &CVPR &\href{https://mhaiyang.github.io/CVPR2020_GDNet/index}{Pytorch} &ResNeXt-101~\cite{ResNeXt} &STL  & GDD ~\cite{GDNet_Glass}&2,980\\
				169& &RCARP \cite{RCARP_Glass} &CVPR &N/A &ResNeXt-101~\cite{ResNeXt} &STL  & GSD ~\cite{RCARP_Glass}&3,202\\
				%Enhanced Boundary Learning for Glass-like Object Segmentation
				170& &EBLNet \cite{EBLNet_Glass} &ICCV &\href{https://github.com/hehao13/EBLNet}{Pytorch} &ResNeXt-101~\cite{ResNeXt} &MTL  & GDD ~\cite{GDNet_Glass}&2,980\\
	171& &PGSNet\cite{PGSNet_Glass} &TIP &N/A &ResNeXt-101~\cite{ResNeXt} &STL  & GDD~\cite{GDNet_Glass}/HSO~\cite{PGSNet}&2,980/3,070\\
	172& &RFENet\cite{RFENet_Glass} &IJCAI &\href{https://github.com/VankouF/RFENet}{Pytorch} &ResNeXt-101~\cite{ResNeXt} &MTL  & GDD~\cite{GDNet_Glass}&2,980\\
		

				\hline
				\hline
				\multicolumn{9}{|c|}{\multirow{2}{*}{\large\textbf{Mirror Object Detection}}}
				\\
						\multicolumn{9}{|c|}{}		\\
				\hline
				\hline
				
				
				%Where Is My Mirror
				%2020年
				173&	\multirow{4}{*}{\tiny{\rotatebox{90}{2019--2023}}} &MirrorNet \cite{MirrorNet_Mirror} &ICCV &\href{https://github.com/Mhaiyang/ICCV2019_MirrorNet}{Pytorch} &ResNeXt-101~\cite{ResNeXt} &STL  & MSD~\cite{MirrorNet_Mirror}&3,063\\
				%Progressive Mirror Detection
				
				174& &PMD \cite{PMD_Mirror} &CVPR &\href{https://www.cs.cityu.edu.hk/~rynson/projects/mirror_glass/MirrorGlassDetection.html}{Pytorch$^{*}$} &ResNeXt-101~\cite{ResNeXt} &MTL  & MSD~\cite{MirrorNet_Mirror}/PMD~\cite{PMD_Mirror}&3,063/5,095\\
				%Depth-Aware Mirror Segmentation
				175& &PDNet \cite{PDNet_Mirror} &CVPR &\href{https://github.com/Mhaiyang/CVPR2021_PDNet}{Pytorch} &ResNet-50~\cite{Resnet} &STL  & RGBD-Mirror ~\cite{PDNet_Mirror}&2,000\\
176& &LSA\cite{LSA_Mirror} &CVPR &\href{https://github.com/guanhuankang/Learning-Semantic-Associations-for-Mirror-Detection}{Pytorch} &ResNeXt-101~\cite{ResNeXt} &STL  & MSD~\cite{MirrorNet_Mirror}/PMD~\cite{PMD_Mirror}&3,063/5,095\\
				\hline
				\hline
				\multicolumn{9}{|c|}{\multirow{2}{*}{\large\textbf{Polyp Segmentation (Medical Image)}}}
				\\
				\multicolumn{9}{|c|}{}		\\
				\hline
				\hline
				%Polyp Segmentation in Colonoscopy ImagesUsing Fully Convolutional Network
				177&	\multirow{19}{*}{\rotatebox{90}{2020--2023}} &ACSNet\cite{ACSNet_Polyp} &MICCAI &\href{https://github.com/ReaFly/ACSNet}{Pytorch$^{*}$} &ResNet-34~\cite{Resnet} &STL  &  Kvasir-SEG~\cite{Kvasir}/EndoScene~\cite{Endoscene}&600/547\\
				178& &PraNet\cite{PraNet_Polyp} &MICCAI &\href{https://github.com/DengPingFan/PraNet}{Pytorch} &Res2Net-50~\cite{Res2Net} &STL  & Kvasir~\cite{Kvasir}+CVC-ClinicDB~\cite{ CVC-ClinicDB}&1,450\\
				% comprehensive study on colorectalpolyp  segmentation  with  resunet++,  conditional  random  field  and  test-time augmentation,
				179& &ResUNet++\cite{ResUNet++_Polyp} &JBHI &\href{https://github.com/DebeshJha/ResUNetPlusPlus-with-CRF-and-TTA}{TensorFlow$^{*}$} &ResNet~\cite{Resnet} &STL  & Kvasir~\cite{Kvasir}+CVC-ClinicDB~\cite{ CVC-ClinicDB}&1,450\\
				%TransFuse: Fusing Transformers and CNNs forMedical Image Segmentation
				180& &TransFuse\cite{TransFuse_Polyp} &MICCAI &N/A&ViT~\cite{ViT}/DeiT~\cite{DeiT}/Res2Net~\cite{Res2Net}/ResNet~\cite{Resnet}  &STL  & Kvasir~\cite{Kvasir}+CVC-ClinicDB~\cite{ CVC-ClinicDB}&1,450\\
				181& &MSNet\cite{MSNet_Polyp} &MICCAI &\href{https://github.com/Xiaoqi-Zhao-DLUT/MSNet}{Pytorch}&Res2Net-50~\cite{Res2Net}&STL  & Kvasir~\cite{Kvasir}+CVC-ClinicDB~\cite{ CVC-ClinicDB}&1,450\\
				182& &EMS-Net\cite{EMS-Net_Polyp} &EMBC &N/A&Res2Net-50~\cite{Res2Net}&STL& Kvasir~\cite{Kvasir}+CVC-ClinicDB~\cite{ CVC-ClinicDB}&1,450\\ 
				183& &APRNet\cite{APRNet_Polyp} &EMBC &N/A&ResNet-34~\cite{Resnet}&STL& Kvasir-SEG~\cite{Kvasir}/EndoScene~\cite{Endoscene}&600/547\\ 
				%UACANet: Uncertainty Augmented Context Attention for PolypSegmentation
				184& &UACANet\cite{UACANet_Polyp} &ACM MM &\href{https://github.com/plemeri/UACANet}{Pytorch}&Res2Net-50~\cite{Res2Net}&STL  & Kvasir~\cite{Kvasir}+CVC-ClinicDB~\cite{ CVC-ClinicDB}&1,450\\
				%Shallow Attention Network for PolypSegmentation
				185& &SANet\cite{SANet_Polyp} &MICCAI &\href{https://github.com/weijun88/SANet}{Pytorch}&Res2Net-50~\cite{Res2Net}&STL& Kvasir~\cite{Kvasir}+CVC-ClinicDB~\cite{CVC-ClinicDB}&1,450\\  
				%Learnable Oriented-Derivative Networkfor Polyp Segmentatio
				186& &LOD-Net\cite{LOD-Net_Polyp} &MICCAI &\href{https://github.com/midsdsy/LOD-Net}{Pytorch$^{*}$}&ResNet-101~\cite{Resnet}&STL& Kvasir~\cite{Kvasir}+CVC-ClinicDB~\cite{ CVC-ClinicDB}&1,450\\  
				%CCBANet: Cascading Contextand Balancing Attention for PolypSegmentation
				187& &CCBANet\cite{CCBANet_Polyp} &MICCAI &\href{https://github.com/ntcongvn/CCBANet}{Pytorch$^{*}$}&ResNet-34~\cite{Resnet}&STL& Kvasir~\cite{Kvasir}+CVC-ClinicDB~\cite{ CVC-ClinicDB}&1,450\\ 
				188& &HRENet\cite{HRENet_Polyp} &MICCAI &N/A&ResNet-34~\cite{Resnet}&MTL& Kvasir-SEG~\cite{Kvasir}/Kvasir~\cite{Kvasir}+CVC-ClinicDB~\cite{CVC-ClinicDB}&600/1,450\\
				%Precise yet Efficient Semantic Calibration and Refinement in ConvNetsfor Real-time Polyp Segmentation from Colonoscopy Videos
				189& &SCR-Net\cite{SCR-Net_Polyp} &AAAI &N/A&N/A&STL& Kvasir-SEG~\cite{Kvasir}&700\\
		190& &TRFR-Net\cite{TRFR-Net_Polyp} &MICCAI &N/A&ResNet-34~\cite{Resnet}&STL  &  Kvasir-SEG~\cite{Kvasir}/ETIS-Larib~\cite{ETIS}/CVC-ClinicDB~\cite{CVC-ClinicDB}&700/137/210\\
	191& &LDNet\cite{LDNet_Polyp} &MICCAI &\href{https://github.com/ReaFly/LDNet}{Pytorch$^{*}$}&Res2Net-50~\cite{Res2Net}&STL  &  Kvasir~\cite{Kvasir}+CVC-ClinicDB~\cite{ CVC-ClinicDB}&1,450\\	
192& &BoxPolyp\cite{BoxPolyp_Polyp} &MICCAI &N/A&Res2Net-50~\cite{Res2Net} + PVT~\cite{PVT}&STL  &  Kvasir~\cite{Kvasir}+CVC-ClinicDB~\cite{ CVC-ClinicDB}&1,450\\
193& &PPFormer\cite{PPFormer_Polyp} &MICCAI &N/A&VGG-16~\cite{VGG} + CVT~\cite{CVT}&STL  &  Kvasir~\cite{Kvasir}+CVC-ClinicDB~\cite{ CVC-ClinicDB}&1,450\\
194& &CFANet\cite{CFANet_Polyp} &PR &\href{https://github.com/taozh2017/CFANet}{Pytorch}&Res2Net-50~\cite{Res2Net}&MTL  &  Kvasir~\cite{Kvasir}+CVC-ClinicDB~\cite{ CVC-ClinicDB}&1,450\\
195& &EMS-Net\cite{EMS-Net_Polyp} &JBHI &N/A&Res2Net-50~\cite{Res2Net}&MTL  &  Kvasir~\cite{Kvasir}+CVC-ClinicDB~\cite{ CVC-ClinicDB}&1,450\\

\hline
			\end{tabular}