{
    "arxiv_id": "2303.15655",
    "paper_title": "Joint embedding in Hierarchical distance and semantic representation learning for link prediction",
    "authors": [
        "Jin Liu",
        "Jianye Chen",
        "Chongfeng Fan",
        "Fengyu Zhou"
    ],
    "submission_date": "2023-03-28",
    "revised_dates": [
        "2023-03-29"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CL"
    ],
    "abstract": "The link prediction task aims to predict missing entities or relations in the knowledge graph and is essential for the downstream application. Existing well-known models deal with this task by mainly focusing on representing knowledge graph triplets in the distance space or semantic space. However, they can not fully capture the information of head and tail entities, nor even make good use of hierarchical level information. Thus, in this paper, we propose a novel knowledge graph embedding model for the link prediction task, namely, HIE, which models each triplet (\\textit{h}, \\textit{r}, \\textit{t}) into distance measurement space and semantic measurement space, simultaneously. Moreover, HIE is introduced into hierarchical-aware space to leverage rich hierarchical information of entities and relations for better representation learning. Specifically, we apply distance transformation operation on the head entity in distance space to obtain the tail entity instead of translation-based or rotation-based approaches. Experimental results of HIE on four real-world datasets show that HIE outperforms several existing state-of-the-art knowledge graph embedding methods on the link prediction task and deals with complex relations accurately.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.15655v1"
    ],
    "publication_venue": "Submitted to Big Data research one year ago"
}