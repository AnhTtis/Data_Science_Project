\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{lipsum}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage[dvipsnames]{xcolor}
%\usepackage{tabularray}
 %\UseTblrLibrary{booktabs}
 \usepackage{booktabs}
 \usepackage[export]{adjustbox}
 \usepackage{capt-of}
 \usepackage{xparse}
 \usepackage{comment}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{natbib}
\usepackage{algorithm} %
\usepackage{algpseudocode} %



\usepackage[pagebackref=true,breaklinks=true,colorlinks=false,bookmarks=false,hidelinks]{hyperref}


\newcommand{\littletaller}{\mathchoice{\vphantom{\big|}}{}{}{}}
\newcommand{\restr}[2]{{%
  \left.\kern-\nulldelimiterspace%
  #1%
  \littletaller%
  \right|_{#2}%
  }}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand{\MAP}{\textsc{map}}
\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}


\iccvfinalcopy %



\begin{document}
\title{Laplacian Segmentation Networks: Improved Epistemic Uncertainty from Spatial Aleatoric Uncertainty} 

\author{Kilian Zepf$^{1,*}$, Selma Wanna$^{2,*}$, Marco Miani$^1$, Juston Moore$^3$,\\ Jes Frellsen$^1$, Søren Hauberg$^1$, Aasa Feragen$^1$, Frederik Warburg$^1$\\
\small $^1$Technical University of Denmark,
$^2$The University of Texas at Austin,
$^3$Los Alamos National Laboratory\\
\and
}

\maketitle
\ificcvfinal\thispagestyle{empty}\fi

\blfootnote{$^*$ denotes equal contribution. Correspondence to: \tt kmze@dtu.dk, slwanna@utexas.edu, mmia@dtu.dk, frwa@dtu.dk}
\begin{abstract}

Out of distribution (OOD) medical images are frequently encountered, e.g.~because of site- or scanner differences, or image corruption. OOD images come with a risk of incorrect image segmentation, potentially negatively affecting downstream diagnoses or treatment. To ensure robustness to such incorrect segmentations, we propose Laplacian Segmentation Networks (LSN) that jointly model epistemic (model) and aleatoric (data) uncertainty in image segmentation. We capture data uncertainty with a spatially correlated logit distribution. For model uncertainty, we propose the first Laplace approximation of the weight posterior that scales to large neural networks with skip connections that have high-dimensional outputs. Empirically, we demonstrate that modelling spatial pixel correlation allows the Laplacian Segmentation Network to successfully assign high epistemic uncertainty to out-of-distribution objects appearing within images.
\end{abstract}

\section{Introduction}
Image segmentation is a core component in the biomedical image analysis toolbox, used extensively both to quantify organs for use in scientific studies, as well as to inform clinicians by outlining relevant parts of the image. Its widespread use places high requirements for its safe and interpretable operation. %
However, neural networks, which form the backbones of most modern segmentation models, are infamous for being overconfident in their predictions outside the training distribution \citep{hendrycks2016baseline}. As a result, downstream predictions can be highly unreliable even though they might come with high accuracy on in-distribution data. 

Figure~\ref{fig:failure_case} shows an example derived from a U-net model. While the network has never seen images corrupted by synthetic noise during training %
it will confidently predict pixels replaced by noise as skin lesions. This renders every following analysis based on the prediction unreliable. While the example is synthetic, similar effects occur in images corrupted, for example, by polluted cameras, or data loss.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/failure_case_example.pdf}
    \caption{Corrupted images can lead to confident and wrong predictions by a U-net (fourth column). In automated downstream tasks, where predictions are not inspected by experts, this can remain undiscovered, leading to critical mistakes and wrong follow up treatment of patients. Our model assigns high epistemic uncertainty to the corrupted images.}
\label{fig:failure_case}
\vspace*{-\baselineskip}
\end{figure}

\textbf{In this work}, we introduce Laplace approximations (LA) for epistemic uncertainty quantification in binary image segmentation models. Current Laplace approximations \citep{daxberger2021laplaceredux} scale quadratically with the output dimension of the neural network, which prevent their usage in segmentation. We develop a fast Hessian approximation for deep architectures with skip connections, which are an integral part of modern segmentation networks such as the U-net \citep{ronneberger2015}. This enables us to combine the aleatoric logit distribution of Stochastic Segmentation Networks (SSN) \citep{monteiro2020} with post-hoc Laplace approximations for epistemic uncertainty quantification. Specifically, we propose to find the Gaussian approximation on the mean network of the SSN.
This can be viewed as combining an evidential deep learning (EDL) model~\citep{sensoy2018evidential,frellsen2021} with a LA approximation of epistemic uncertainty rather than the point estimate prevailingly used in EDL, and, to the best of our knowledge, this is the first work to propose this combination.
We demonstrate that the spatial correlation in the aleatoric component is essential for the quantification of epistemic uncertainty in the Laplace approximation. 

Joint modelling of epistemic and aleatoric segmentation uncertainty is not new \citep{kendall2017,popescu2021distributional,joy2021analyzing,fuchs2021practical}. The binary cross entropy loss typically used to train segmentation models makes an assumption of independent pixels. Segmentation models using this loss tend to get stuck in local minima when the target is small compared to the background, unless the classes are reweighted in the loss~\citep{lin2017}. We show experimentally that this changes when you spatially correlate pixels: The model can converge without reweighting the smaller class. As a result, the loss landscape also looks different, leading to a change in the LA estimation of epistemic uncertainty. In our experiments, we observe an effect of this in the form of improved OOD behavior.

In a series of experiments on two medical binary segmentation tasks, we show that the proposed method outperforms baselines on a variety of OOD scenarios, including the detection of distribution shifts on datasets and highlighting corrupted parts of an image, by assigning high uncertainty to respective pixels. Providing a more reliable model uncertainty, the proposed Laplacian Segmentation Networks contributes to the applicability and safety of binary segmentation models in practice. 

\section{Background and Related Work}

While several different sources and taxonomies of uncertainties have been proposed \citep{ditlevsen2008,gawlikowski2021}, the Bayesian framework \citep{bishop2006, kendall2017} distinguishes between two of them: aleatoric and epistemic. These appear directly in the predictive distribution
\begin{equation}
  \label{pred_dist}
   p(y \vert x, D) = \int \underbrace{p(y \vert x,\theta)}_\text{aleatoric} \underbrace{p(\theta \vert D)}_\text{epistemic} \diff \theta,
\end{equation}
where $(x, y)$ is an input-output pair, $D$ is the training data and $\theta$ the model parameters. The aleatoric (likelihood) density $p(y \vert x,\theta)$ models noise or variation in the data from which the model learns. This is typically caused either by ambiguities in the image or in the definition of the object to be annotated, for example tumor boundaries which are hard to define due to gradual tissue infiltration. The posterior density $p(\theta \vert D) \propto p(D | \theta) p(\theta)$ reflects the epistemic uncertainty of the estimated model, which quantifies the degree to which the model itself should be trusted. Here $p(\theta)$ is the prior over the parameters and $p(D | \theta)$ is the likelihood of the training data.

The intractable posterior distribution over the parameters prohibits the evaluation of the integral in Eq.~\eqref{pred_dist}. 
To overcome this, it is necessary to utilize suitable approximations for the predictive distribution itself or parts of the integral on the right hand side of Eq.~\eqref{pred_dist}. 

In standard image segmentation, the posterior distribution $p(\theta \vert D)$ is usually approximated with a Dirac distribution $\delta(\theta-\hat\theta)$, where $\hat\theta$ is the maximum a posteriori (MAP) or maximum likelihood (ML) estimate, which simplifies the posterior predictive to $p(y \vert x, D) = p(y \vert x, \hat\theta)$. The additional assumption of pixel-wise conditional independence within the segmentation mask gives the log-likelihood function
$
    \log p(y \vert x, \theta) = \sum_{s=1}^S \log p(y_s \vert x_s, \theta)
$,
where $s$ indexes pixels. If we assume a flat prior $p(\theta) = 1$, we recover the frequently used negative log-likelihood  loss 
\begin{equation}
\label{cross_entropy_loss_derivation}
L(\theta) = -\log p(D | \theta) = -\sum_{i=1}^{N} \sum_{s=1}^S \log p(y_{s,i} \vert x_{s,i}, \theta),
\end{equation}
where $i$ indexes the training data. Note that this equvivalent to the cross-entropy loss for a Bernoulli likelihood.

While a joint modelling objective for aleatoric and epistemic uncertainty for regression and classification tasks in computer vision was suggested by \citet{kendall2017}, most research has focused on either one or the other \citep{kohl2018probunet, monteiro2020}.

Methods that mainly focus on modelling aleatoric uncertainty in image segmentation have been proposed based on mixing deterministic segmentation architectures with generative components such as variational autoencoders and normalizing flows \citep{baumgartner2019phiseg,kohl2019hierarchical,selvan2020uncertainty}. Probabilistic graphical models and combinations with neural networks have also been introduced for this purpose, but their application is restricted due to computational expense during inference time \citep{markov2012batra,markov2015batra,kirillov2016joint,markov2018,KAMNITSASmarkov,NIPS2015markov}.
Ensemble and multi-head models \citep{blundell2016ensemble,rupprecht2017learning,lee2016stochastic} have been applied for both aleatoric and epistemic uncertainty quantification, training on multiple- or same annotations for aleatoric or epistemic uncertainty quantification, respectively. In particular, this results in a frequentist approach to estimate $p(\theta \vert D)$. 
A Bayesian way to approximate the posterior is Monte-Carlo Dropout, a variational method based on Bernoulli distributions, which can be easily implemented for neural networks \citep{gal2016dropout,gal2015bayesian,gal2016dropoutappendix}. Model uncertainty is retrieved by averaging multiple forward passes, while setting weights randomly to 0 with probability $p$, both during inference time and training.
Approaches that model both types of uncertainty in one model have been introduced based on the combination of Mean-Variance networks with diagonal covariance matrix and Dropout \citep{kendall2017} and Gaussian-Process based convolutional layers \citep{popescu2021distributional}.


\subsection{Post-hoc Laplace Approximation}
\label{laplace_approximation}
For Bayesian Neural Networks \citep{bishop2006} Laplace's method \citep{mackay1992bayesian} is used to approximate the intractable posterior distribution $p(\theta \vert D)$ with a Gaussian centered at a local mode $\theta_{\MAP}$. In a first step the mode of the posterior can be determined by iterative numerical optimization such as stochastic or conjugate gradient decent. Note that for the binary cross entropy loss case described in Eq.~\eqref{cross_entropy_loss_derivation} maximizing the log posterior is equivalent to minimizing the loss function. A second order Taylor expansion around $\theta_{\MAP}$ gives
\begin{align}
\label{taylor_expansion_posterior}
    \log p(\theta \vert D) \!\simeq\! \log(\theta_{\MAP} \vert D) \!-\! \frac{1}{2}(\theta \!-\! \theta_{\MAP})^{\!\top}\mathbf{H}(\theta \!-\! \theta_{\MAP})
\end{align}
where the first derivative vanishes because $\theta_{\MAP}$ is assumed to be a local mode. The Hessian $\mathbf{H}$ in Eq.~\eqref{taylor_expansion_posterior} is defined as 
\begin{equation}
    \mathbf{H} = - \nabla_{\theta} \nabla_{\theta} \log \restr{p(\theta \vert D)} {\theta = \theta_{\MAP}}.
\end{equation}
Applying the exponential function to Eq.~\eqref{taylor_expansion_posterior} gives an approximation $q(\theta)$ which is proportional to the density function of a multivariate normal distribution. The normalizing factor can be found by evaluating the determinant of $\mathbf{H}$ giving the final approximation to the posterior as 
\begin{equation}
   q(\theta)= \mathcal{N}(\theta \vert \theta_{\MAP}, \mathbf{H}^{-1}). 
\end{equation}

Evaluating the Hessian for such large functions is computationally infeasible because of the quadratic complexity in the network parameters and the usually large output dimensions in vision tasks. Approximations exist to overcome this \citep{botev2020} and frameworks for applying them are available \citep{software:stochman, daxberger2021laplaceredux}. 

We propose a fast Hessian approximation for models with skip connections (Sec.~\ref{sec:fastH}) that scales linearly with parameters and output resolution and makes a post-hoc Laplace approximation of the parameter posterior feasible. Further, we extend the mean-variance network in \cite{kendall2017} from heteroscedastic pixel-wise to spatially correlated aleatoric uncertainty using SSN. We quantify epistemic uncertainty by approximating the posterior on the mean network, and show that this yields reliable OOD detection. 
 
\section{Laplacian Segmentation Network}

To model the epistemic uncertainty in Eq.~\eqref{pred_dist} with a Laplace approximation,  we show that recent progress in scaling LA to images \citep{miani_2022_neurips} can be extended to segmentation networks using skip connections. 

\subsection{Laplace Approximation of Mean Network}

We can reformulate the integral for the predictive distribution in Eq.~\eqref{pred_dist} by integrating over logits $\eta$ to obtain 
\begin{equation}
    \label{pred_dist_with_logits}
 p(y \vert x, D) = \iint p(y \vert \eta) p(\eta \vert x,\theta) p(\theta \vert D) \diff \eta \diff \theta.
\end{equation}
This further factorization of Eq.~\eqref{pred_dist} corresponds to the model formulation used in Evidential Deep Learning \citep{sensoy2018evidential,frellsen2021}. Following \citet{monteiro2020} and \citet{kendall2017}, we model the conditional distribution over logits $p(\eta \vert x,\theta)$ as a normal distribution parametrized by neural networks $\mu$ and $\Sigma$ :
\begin{equation}
    \label{logit_dist}
    \eta \vert x \sim \mathcal{N}(\mu(x, \theta_1),\Sigma(x,\theta_2)),
\end{equation}
and assume pixel-wise independence for the predicted labels given the logits. Thus, we can model $p(y \vert \eta)$ for each pixel $i$ as a Bernoulli distribution parametrized by the softmax of the respective logit. 
Since the size of the covariance matrix $\Sigma$ scales quadratically with the number of pixels in the image, we use the low-rank parameterisation of \citet{monteiro2020}
\begin{equation}
    \Sigma(x) = D(x) + P(x)^T P(x),
\end{equation}
i.e.\@  the variance network $\Sigma(x)$ is implemented with two networks $D(x)$ and $P(x)$. 

The vectors $\theta_1 \in \Theta_1 = \mathbb{R}^T$ and $\theta_2 \in \Theta_2 = \mathbb{R}^T$ parameterize the mean and variance networks (c.f.\@ Eq.~\ref{logit_dist}) and share the first $t$ entries, i.e.\@ we define the shared weight vector $\theta_t$ of the network by 
\begin{equation}
    \theta_{t} \coloneqq (\theta_{1_1}, \ldots ,\theta_{1_t} ) = (\theta_{2_1}, \ldots ,\theta_{2_t} ) \in \Theta_t =\mathbb{R}^t.
\end{equation}
Then $\theta \in \Theta = \mathbb{R}^{(t+2\cdot(T-t))}$ contains all model parameters
\begin{equation}
    \theta \coloneqq (\theta_t, \theta_{1_{t+1}}, \ldots, \theta_{1_{T}}, \theta_{2_{t+1}}, \ldots, \theta_{2_{T}}).
\end{equation}
The post-hoc Laplace approximation first finds a mode $\theta_{\MAP}$ by minimizing the loss function
\begin{multline}
    \mathcal{L}(\theta) = - \log \mathbb{E}_{p(\eta \vert x, \theta)} [p(y \vert \eta)] - \log p(\theta) \approx  \\-\text{logsumexp}_{m=1}^M \Big(\sum_{s=1}^S \log p(y_s \vert \eta_s^{(m)})\Big) + \log(M) ,
\end{multline}
where $M$ logits $\eta$ are sampled from the distribution in Eq.~\eqref{logit_dist} and where the term $-\log p(\theta)$ vanishes assuming a flat prior $p(\theta) = 1$. 
Since current algorithms for fast Hessian computations have no implementation for this loss function, we instead make use of the shared weights in the parameter vectors. For $t \gg T-t$, the loss landscape is dominantly defined by the shared parameters. Current SSN implementations usually fulfil this criteria, since they estimate the mean and variance of the logit distribution based on the feature maps of a deep deterministic segmentation model, while using only one convolutional layer each for mean and variance estimation. We therefore discard the entries of the variance network on the parameter vector $\theta_{\MAP}$, i.e.\@ we set 
\begin{equation}
   \theta_{\MAP}^* \coloneqq \restr{\theta_{\MAP}}{(\theta_t, \theta_{1_{t+1}}, ..., \theta_{1_{T}})} \in \Theta_{\textrm{mean}} =\mathbb{R}^{T}.
\end{equation}
We can make use of the fact that the SSN loss function reduces to the binary cross entropy loss under zero variance, which allows us to fall back on the fast Hessian computation frameworks available. The posterior is then found by the Laplace approximation as described in Sec.~\ref{laplace_approximation} resulting in a Gaussian approximation in the parameter space $\Theta_{\textrm{mean}}$
\begin{equation}
    q(\theta^{*})= \mathcal{N}(\theta^{*} \vert \theta_{\MAP}^{*}, \mathbf{H^{*}}^{-1}), 
\end{equation}
with $\mathbf{H^*}$ defined as 
\begin{equation}
    \mathbf{H^*} = - \nabla_{\theta} \nabla_{\theta} \log \restr{p(\theta^{*} \vert D)} {\theta^{*} = \theta_{\MAP}^{*}}.
\end{equation}
Additionally to the aleatoric logit distribution, we can now investigate the epistemic component in form of the Laplace approximation for a given sample during inference time. Figure~\ref{fig:model_overview} gives an schematic overview of the proposed Laplacian Segmentation Network (LSN). 

\begin{figure*}[t]
\begin{center}
\includegraphics[width=0.9\linewidth]{figures/model_overview_alternative2.pdf}
\end{center}
   \caption{\textbf{Model overview.} Epistemic uncertainty maps are retrieved by sampling mean networks from the Laplace approximation $q(\theta^*)$ and calculating the variance on their outputs for $x$. The aleatoric logit distribution is predicted on the parameter configuration $\theta_{\MAP}$ akin to \citet{monteiro2020}.}
\label{fig:model_overview}
\vspace*{-\baselineskip}
\end{figure*}

\subsection{Fast Hessian Approximations for Segmentation Networks with Skip Connections}\label{sec:fastH}
Computation of second order derivatives for Segmentation Networks is expensive due to the vast amount of parameters and pixels in the output. Standard methods approximate the Hessian with the diagonal of the Generalized Gauss Newton (\textsc{ggn}) matrix \citep{foresee1997ggn, botev2020}. This approximation, besides enforcing positive definiteness, also allows for an efficient backpropagation-like algorithm. The required compute scales linearly in the number of parameters and quadratic in the number pixels. The quadratic dependency is prohibitive already with images of size $64 \times 64$. We therefore make use of the diagonal backpropagation ($\textsc{db}$) proposed by \citet{miani_2022_neurips}, which returns a trace-preserving approximation of the diagonal of the \textsc{ggn}. The complexity of this approximation scales linearly with the number of pixels, allowing the computation of the Hessian also for larger images. The idea is to add a diagonal operator $\mathfrak{D}$ in-between each backpropagation step. For each layer $l$
\begin{align}
    [\nabla_{\theta} & \nabla_{\theta} \log p(\theta \vert D)]_l
    \! \overset{\textsc{ggn}}{\approx} \!
    [J_\theta f_\theta (x)^\top H^{(L)} J_\theta f_\theta(x)]_l = \\ \nonumber
    & =
    J_\theta {f^{(l)}}^\top
        \left(
        \prod_{i=l+1}^L J_x {f^{(i)}}^\top
        H^{(L)}
        \prod_{i=L}^{l+1} J_x f^{(i)}
        \right)
    J_\theta f^{(l)} \\ \nonumber
    & \overset{\textsc{db}}{\approx}
    J_\theta {f^{(l)}}^\top
        \mathfrak{D}
        \left(
        J_x {f^{(l+1)}}^\top
        \mathfrak{D}
            \left(
            \dots
            \right)
        J_x f^{(l+1)}
        \right)
    J_\theta f^{(l)}
\end{align}
where $H^{(L)}$ is the Hessian of the binary cross entropy loss with respect to the logits, which can be expressed in closed form as diagonal plus outer product matrix.

Moreover, we extend the \texttt{StochMan} library \citep{software:stochman} with support for skip-connection layers. For a given submodule $f_\theta$, a skip-connection layer $\textsc{sc}_f$ concatenates the function with the identity, such that $\textsc{sc}_f(x) = (f_\theta(x), x)$. The Jacobian is then $J_x \textsc{sc}_f(x) := (J_x f_\theta(x), \mathbb{I}_x) $. We exploit the block structure and efficiently backpropagate the diagonal only. With a recursive call on the submodule $f$, the backpropagation supports nested skip-connections, i.e.\@ when some submodules of $f$ are skip-connections as well. This unlocks the use of various curvature-based methods for segmentation architectures with skip connection in future research. For a technical description of the used Hessian approximation we refer to \ref{appendix:hessian_details}. %

\section{Results}

In the following, we investigate the derived LSN and test it in different practical scenarios. We start by illustrating the effect of introducing spatial correlation between pixels in scenarios with strong class imbalance. When segmenting small objects from background, reweighting classes is often necessary to optimize the network; this, however, has an undesired effect on the estimated epistemic uncertainties. We show how LSNs incorporating spatial correlation do not have this problem, and illustrate how this results in epistemic uncertainty with superior OOD behavior.

Next, we compare how the two types of uncertainties behave when modelled together and how and whether they differ. Finally we investigate out-of-distribution capabilities of the considered models on three different tasks. First we show with a toy example to which extent the epistemic components of the models are able to detect corrupted white noise boxes that are added to the images. Second, we assess the ability to detect distribution shifts by comparing the ISIC dataset against two similar datasets containting images of skin without lesions. %

\subsection{Baselines \& Data} 

We compare our suggested model (LSN) to the following baselines in our experiments: (1) Ensemble of U-nets (Ensemble), were each member is trained on the same dataset (2) U-net with Monte-Carlo Dropout (U-net + Dropout) (3) U-net with post-hoc Laplace approximation (U-net + LA) (4) SSN with Dropout on the mean network (SSN + Dropout). Additionally, we consider the case of a diagonal covariance matrix, ignoring spatial correlation, for LSN and SSN + Dropout. We indicate this with a \textit{(diag)} tag. 

Training and experimental scripts are implemented in PyTorch and will be made available upon publication. All models share the same U-net backbone with five encoding blocks for comparability. Each block contains two convolution layers and uses the hyperbolic tangent activation function. For the estimation of $\mu$, $D$ and $P$ the last feature map of the U-net is passed through three separate $1 \times 1$ convolution layers, respectively. The ISIC19 dataset \citep{combalia2019bcn20000,codella2018skin,tschandl2018ham10000} is scaled to a resolution of $64 \times 64$ and  is split into 11028 images for training and 1379 images for each, validation and testing. We refer to appendix \ref{appendix:training_details} for further details on the training procedure.


\subsection{Spatial Correlation affects Class Imbalance affects Epistemic Uncertainty}
Class imbalance is a common challenge when segmenting small objects, often treated with methods of cost sensitive learning~\citep{elkan2001,kukar1998} deriving loss functions that penalize wrongly classified pixels of different classes differently~\citep{lin2017}. For the binary cross entropy loss, this is typically done by scaling the class-wise loss contributions with a factor that represents the imbalance between target and background. 

\begin{table}
\begin{center}
  \caption{Modelling the spatial correlation in the aleatoric logit distribution makes scaling the binary cross entropy loss unnecessary. IoU on the ISIC validation set after training for all models and different scaling factors of the loss function. Other learning parameters are kept equal. }
  \label{training_with_different_factors_table}
  \centering
  \resizebox{\linewidth}{!}{
  \begin{tabular}{lllll}
    \toprule
    & \multicolumn{4}{c}{Scaling Factor}\\
    \cmidrule(r){2-5}
    Model     & 1   & 2  & 4 & 8 \\
    \midrule
    Ensemble & $<10^{-10}$  & $<10^{-10}$ & $0.74$ & $0.72$ \\
    \midrule
    U-net + Dropout    & $<10^{-10}$  & $<10^{-10}$  & $0.64$ & $0.61$ \\
    SSN (diag) + Dropout    & $<10^{-10}$ & $<10^{-10}$ & $0.69$ & $0.65$ \\
    SSN + Dropout    & $0.73$  & $0.72$  & $0.68$ & $0.60$ \\
    \midrule
    U-net + LA     & $<10^{-10}$  &$<10^{-10}$  & $0.67$ & $0.70$ \\
    LSN (diag) & $<10^{-10}$  & $<10^{-10}$   & $0.67$ & $0.65$  \\
    LSN     & $0.71$  & $0.65$  & $0.58$ & $0.59$ \\
    \bottomrule
  \end{tabular}
  }
\end{center}
\end{table}

To compensate for class imbalance in the ISIC dataset (about 1:8), all models were trained with binary cross entropy, reweighting the underrepresented class with different factors. Table~\ref{training_with_different_factors_table} shows the validation set intersection-over-union (IoU) after the last epoch for different scaling factors of the loss function. We find that only the models including spatial variation reach a useful optimum when reweighting is not applied, illustrating that including spatial correlation into the modelling has a desired effect on training with imbalanced classes. We hypothesize that this is because the high correlation between pixels in the background effectively reduces their contribution to the loss.

But this spatial correlation does not only affect our ability to optimize models; this also affects our epistemic uncertainty estimates: The alternative rescaling of parts of the loss has an immediate effect on epistemic uncertainty , since the Gaussian Approximation found post-hoc depends on the curvature of the loss landscape. In Fig.~\ref{fig:loss_landscape_comparison} we illustrate this effect with a toy example, showing the landscape a function (left) and of a rescaled version of the same function (right), along with their post-hoc fitted Laplace approximations. As shown in the illustration, the scaled function exhibits higher curvature, and hence a lower epistemic uncertainty, than the original. In other words, we find that including spatial correlation between pixels in the aleatoric logit distribution should affect the resulting epistemic uncertainty given by a post-hoc Laplace approximation. In the next sections, we shall see this empirically by comparing LSN to the version LSN (diag), where the aleatoric uncertainty is modelled without spatial correlation.
 
\begin{figure}[t]
\begin{center}
\includegraphics[width=1\linewidth]{figures/scaled_loss_landscapes.pdf}
\end{center}

   \caption{Illustration of loss landscape (grey) with fitted post-hoc Laplace approximation (orange) around a local minimum $\theta_{MAP}$. On the right the loss landscape is scaled by a factor $>1$, as done when correcting for class imbalance. Note that the found Gaussian approximation's variance depends on the curvature at $\theta_{MAP}$.}
\label{fig:loss_landscape_comparison}

\end{figure}

\subsection{How do aleatoric and epistemic uncertainty differ when modelled jointly?}

The proposed model can quantify aleatoric and epistemic uncertainty via the logit distribution of the SSN and the post-hoc Laplace approximation. To evaluate how similar the modelled distributions are  we evaluate them in terms of segmentation performance. For each image in the ISIC test set, we draw 50 samples from the logit distribution, parameterized by $\theta_{\MAP}$. We then draw 50 mean networks from the parameter distribution given by the Laplace approximation. Retrieving samples from both components of the model is illustrated in Fig.~\ref{fig:model_overview}. Figure~\ref{fig:recall_precision_curves} shows Precision-Recall curves for the proposed model, as well as the baseline models that use the SSN and therefore model both uncertainties. Note, that the SSN (diag) + Dropout corresponds to the heteroscedastic Bayesian Neural Network with Dropout derived by \citet{kendall2017}.

First, we find that the aleatoric component, targeting the data variation, performs better in terms of segmentation performance than the epistemic component for our model. Further, the epistemic component of the LSN with diagonal covariance matrix performs worse (lower AUC), underpinning that the scaling of the loss has an effect on the post-hoc Laplace approximation. For the Dropout-based methods, on the other hand, we see virtually no difference between the epistemic and aleatoric components. This is in line with the findings of \citet{kendall2017}, that Dropout as the epistemic component imitates the aleatoric logit distribution, unable to capture the different types of uncertainty.%

What does this tell us? We see that the aleatoric and epistemic components of the LSN clearly capture different aspects of the model's uncertainty. To better understand where this difference comes from, Figure~\ref{fig:qualitative_example_difference_alea_epist} shows epistemic and aleatoric variance maps of sigmoids for a given ISIC test set sample. While the epistemic component assigns low variance to this in-distribution sample, the aleatoric component expresses the variation of plausible predictions for the image. We find this behavior attractive: In the Bayesian framework, the aleatoric component should play the role of the predictor, as it imitates the distribution of annotations found in the data. The epistemic component, conversely, should capture the model uncertainty, enabling the model to identify OOD samples. In the following experiments we will investigate to which extent the proposed model's epistemic component accomplishes this requirement. 

\begin{figure}[t]
\begin{center}
\includegraphics[width=1\linewidth]{figures/fig_precision_recall_curves.pdf}
\end{center}
   \caption{Precision-Recall plots for the ISIC test dataset show that aleatoric and epistemic variance in the LSN models (first row) are not the same, opposed to the SSN + Dropout models. The better performance of the aleatoric component (higher AUC) indicates that the model learns to separate data variation from model uncertainty. This is not the case for models with Dropout as an epistemic component, confirming the findings by \citet{kendall2017}. }
\label{fig:recall_precision_curves}
\end{figure}

\begin{figure}[t]
\begin{center}
\includegraphics[width=1\linewidth]{figures/qualitative_difference.pdf}
\end{center}
   \caption{Epistemic and aleatoric uncertainties differ for the LSN model. While the aleatoric component assigns high variance to the boundary, expressing how plausible segmentations could differ, the epistemic variance for this in-distribution sample is low.}
\label{fig:qualitative_example_difference_alea_epist}
\vspace*{-\baselineskip}
\end{figure}


\subsection{Detection of Within-Image Corruption}
\label{subsection:box_results}
To assess how well the different models are able to assign high epistemic variance to corrupted parts of an image, we distort in-distribution images by either adding squared white noise boxes, or cropping out black boxes, to the samples of the ISIC test set. This allows us to directly compare the epistemic components' variance predictions for ID and OOD pixels and investigate whether they are able to to assign high variance to the affected area within the image. Figure~\ref{fig:qualitative_results_isic} shows a sample from the ISIC dataset with its corrupted counterpart, along with the respective models' epistemic variance maps. The ensemble assigns high variance to the whole lesion since some members end up in suboptimal local minima and predict background only. Any meaningful epistemic uncertainty captured by the remaining models is clouded by this. While all models assign variance to the boundary of the lesion, the LSN assigns the variance more accurately to the white noise box. To quantify whether the models assign higher variance to the OOD samples compared to their ID counterparts, we define the Pixel Ratio for a given image $x$ as 
\begin{equation}
    \textit{Pixel Ratio}(x) = \frac{\sum_{s=1}^{S} \mathrm{Var}(\sigma(\eta_s (x_{\textrm{OOD}})))}{\sum_{s=1}^{S} \mathrm{Var}(\sigma(\eta_s (x)))}, 
\end{equation}
where $S$ is the number of pixels and $x_{OOD}$ the corrupted version of the image. While the Pixel Ratio detects increased variance across the entire image, it does not quantify whether the increase in prediction variance is localized at the corrupted box. To this end, we define the Box Ratio as\looseness=-1
\begin{equation}
    \textit{Box Ratio}(x_{\textrm{OOD}}) = \frac{\sum_{k=1}^{K} \mathrm{Var}(\sigma(\eta_k (x_{\textrm{OOD}})))}{\sum_{s=1}^{S} \mathrm{Var}(\sigma(\eta_s (x_{\textrm{OOD}})))}
\end{equation}

where $K$ is the index set for those pixels lying within the white noise box. The Box Ratio gives an indication to what extent the considered method assigns high variance to those pixels that have been distorted. In Table~\ref{white_noise_box_table}, we  provide both measures for the case of an added white noise box or a black crop box, where size and position of the box vary randomly for each image in the ISIC test set. Specifically, we sample positions $[0,40],[0,40]$ and side lengths $[10,20]$ of the boxes uniformly. All models assign higher variance to the OOD samples, indicated by Pixel Ratio values larger than 1. However, the LSN is able to better locate the corrupted boxes on average. The total sum of variance from ID to OOD does not increase much for the LSN, indicated by low Pixel Ratios. At the same time the high Box Ratio indicates that the LSN moves the variance from the boundary of the lesion to the corrupted box. This is also visible in the qualitative result in Fig.~\ref{fig:qualitative_results_isic}. This is illustrated by the examples in Figure~\ref{fig:qualitative_results_isic}, where we for instance see clearly that while the U-net + Dropout gets a top score on the Pixel Ratio, its low Box Ratio score uncovers the fact that the model did not really localize the corrupted box at all.


\begin{figure*}[h]
\begin{center}
\includegraphics[width=1\linewidth]{figures/box_qualitative_samples.pdf}
\end{center}
\vspace{-5mm}
   \caption{Predicted epistemic variance maps of two samples from the ISIC test set and counterparts with added white noise box and black crop for the different models. LSN assigns high variance to the white noise box as well as the black crop. }
   
\label{fig:qualitative_results_isic}
\vspace*{-\baselineskip}
\end{figure*}

\begin{table}
\begin{center}
\vspace*{-3mm}
  \caption{Average ratio of pixel sum of variance maps for ID and OOD samples (Pixel Ratio) and ratio between correctly assigned variance to the corrupted box and pixel sum of variance maps (Box Ratio) for all models on ISIC. Results are shown for OOD images generated by adding white noise box (Noise) or a black crop box (Black) at a randomly assigned position and size.}
\label{white_noise_box_table}
   \vspace{.5em}
  \centering
  \begin{tabular}{lllll}
    \toprule
    & \multicolumn{2}{c}{Pixel Ratio $\uparrow$}     & \multicolumn{2}{c}{Box Ratio $\uparrow$}      \\
    \cmidrule(r){2-3}
    \cmidrule(r){4-5}
    Model     & Black  & Noise & Black & Noise \\
    \midrule
    Ensemble &  1.00 & 0.95  & 0.14 & 0.13 \\
    \midrule
    U-net + Dropout    & \textbf{1.82}  & \textbf{1.80}  & 0.13 & 0.14 \\
    SSN (diag) + Dropout    & 1.09  & 1.20  & 0.15 & 0.17 \\
    SSN + Dropout    &  1.51 & 1.60  & 0.14 & 0.20 \\
    \midrule
    U-net + LA     & 1.14  & 1.47  & 0.17 & 0.24 \\
    LSN (diag)  & 1.33  & 1.23  & 0.23 & 0.24 \\
    LSN     &  1.29 & 1.64  & \textbf{0.26} & \textbf{0.29} \\
    \bottomrule
  \end{tabular}
\end{center}
\end{table}

\subsection{Distribution Shifts on ISIC dataset}
\label{subsection: isic_results}

Detecting gradual distribution shifts is critical in medical imaging, since downstream tasks might be sensitive to small systematic input changes. For example, a slightly flatter camera angle directly influences predicted area of a skin lesion, distorting decisions in automated systems. We evaluate OOD performance of all models, trained on the ISIC 2018 dataset and evaluated on an in-distribution test set and three OOD datasets: Derm-Skin (DERM), Clin-Skin (CLINIC) \citep{Pacheco2020} and the PAD-UFES-20 dataset \citep{pacheco2020pad}. The Derm-Skin dataset contains 1,565 images of healthy skin, cropped out of the ISIC dataset. The Clin-Skin dataset contains 723 images showing healthy skin gathered from social networks. The PAD-UFES-20 dataset contains 1570 photos of skin lesions collected from smartphone cameras. Figure \ref{fig:box_plots_ISIC} shows OOD detection capabilities for all models, while investigating the effects of different modeling on the epistemic component's predictive entropy. The distributions reported in Figure \ref{fig:box_plots_ISIC} relate to the average per pixel predictive entropy per image.

The models with the best separation between ID and OOD entropy are the Ensemble, SSN (diag) + Dropout, LSN and LSN (diag) methods. However, even among the best performing methods, there remains significant overlap in predictive entropy between the ID and OOD datasets. This lack in separation motivates future work in exploring alternative uncertainty quantification metrics.

\begin{figure*}[t]
\vspace{6mm}
\begin{center}
\includegraphics[width=0.9\linewidth]{figures/isic_box_plot_new.pdf}
\end{center}
\vspace*{-5mm}
   \caption{Box plot of entropy for all models on the in-distribution ISIC test set and the OOD datasets DERM, CLINIC and PAD-UFES-20. All models assign higher entropy to the OOD datasets.}

\label{fig:box_plots_ISIC}
\vspace*{-\baselineskip}
\end{figure*}


\section{Discussion and Conclusion}

In this paper, we have demonstrated how Laplace approximations can scale to image segmentation tasks, through a trace-preserving diagonal Hessian approximation. Importantly, this scales linearly with the number of image pixels, unlike past work which exhibited a quadratic complexity. We have demonstrated across different datasets and quality measures that this successfully captures the epistemic uncertainty of estimated model parameters, in contrast to existing methods.

While we have illustrated a promising potential for the LSN models, our current implementation still has some limitations. First, we currently tackle only binary segmentation problems, which are common in medical imaging. Moreover, our Laplace approximation currently estimates uncertainty in the mean function of a mean-variance network. However, a fully Bayesian approach would apply a Laplace approximation to the entire model, giving even more precise estimates of uncertainty.

We make the interesting experimental discovery that accurately capturing aleatoric uncertainty is essential to recover useful epistemic uncertainty estimates. In particular, we find that an explicit model of spatial correlation is essential. One hypothesis is that the epistemic uncertainty is forced to explain whichever uncertainty is left unexplained by the aleatoric component. A coarse (aleatoric) likelihood model that ignores spatial correlation, thus, force the epistemic component to capture spatial data correlations even if this is not epistemic. Such a hypothesis would suggest that richer correlation structures than those considered here (e.g.\@ based on attention mechanisms \citep{vaswani2017attention}) could yield even finer grained epistemic uncertainties.

\onecolumn
\section*{Acknowledgements}
This work was supported by a research grant (42062) from VILLUM FONDEN. This project received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement 757360). The work was partly funded by the Novo Nordisk Foundation through the Center for Basic Machine Learning Research in Life Science (NNF20OC0062606). The authors acknowledge the Pioneer Centre for AI, DNRF grant number P1. This research used resources provided by the Darwin testbed at Los Alamos National Laboratory (LANL) which is funded by the Computational Systems and Software Environments subprogram of LANL’s Advanced Simulation and Computing program (NNSA/DOE). This work was supported by the Laboratory Directed Research and Development program of LANL under project number 20210043DR. LANL is operated by Triad National Security, LLC, for the National Nuclear Security Administration of the U.S. Department of Energy (Contract No. 89233218CNA000001).

\appendix
\include{arxiv_appendix}


\newpage
\twocolumn
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}