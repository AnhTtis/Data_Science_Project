Segmentation is extensively used to quantify organs or anomalies and highlight important image features to clinicians. Its widespread application necessitates strict requirements for safe and interpretable operation. However, modern approaches rely on neural networks which are infamously overconfident on predictions outside of their training distributions \cite{hendrycks2016baseline}.  As a result, downstream predictions may be confidently incorrect despite their high accuracy on in-distribution (ID) data, rendering every following analysis based on the prediction unreliable. Thus, detecting gradual distribution shifts is crucial for medical imaging tasks.

\textbf{In this work}, we study Laplace approximations (LA) for epistemic uncertainty quantification in binary image segmentation models. Current Laplace approximations \cite{daxberger2021laplaceredux} scale quadratically with the output dimension of the neural network, which prevent their usage in segmentation. We develop a fast Hessian approximation for deep architectures with skip connections, which are integral components of segmentation networks, e.g., U-net \cite{ronneberger2015}. This enables us to combine the aleatoric logit distribution of Stochastic Segmentation Networks (SSN) \cite{monteiro2020} with Laplace approximations for epistemic uncertainty quantification.

We leverage aspects of the ValUES framework \cite{kahl2024values} to measure the effects of uncertainty estimation on OOD detection. We investigate how useful the inferred uncertainties are for OOD detection and how well LSNs can separate aleatoric and epistemic uncertainty. On three medical binary segmentation tasks, we show that the proposed method provides competitive outlier classification performance and assigns higher uncertainty to OOD datasets. The code is available.\footnote{\href{https://github.com/kilianzepf/laplacian_segmentation}{https://github.com/kilianzepf/laplacian\_segmentation}}
