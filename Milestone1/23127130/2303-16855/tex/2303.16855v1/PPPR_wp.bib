
@article{miller_eliciting_2005,
	title = {Eliciting {Informative} {Feedback}: {The} {Peer}-{Prediction} {Method}},
	volume = {51},
	issn = {0025-1909},
	shorttitle = {Eliciting {Informative} {Feedback}},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1050.0379},
	doi = {10.1287/mnsc.1050.0379},
	abstract = {Many recommendation and decision processes depend on eliciting evaluations of opportunities, products, and vendors. A scoring system is devised that induces honest reporting of feedback. Each rater merely reports a signal, and the system applies proper scoring rules to the implied posterior beliefs about another rater’s report. Honest reporting proves to be a Nash equilibrium. The scoring schemes can be scaled to induce appropriate effort by raters and can be extended to handle sequential interaction and continuous signals. We also address a number of practical implementation issues that arise in settings such as academic reviewing and online recommender and reputation systems.},
	number = {9},
	urldate = {2021-03-08},
	journal = {Management Science},
	author = {Miller, Nolan and Resnick, Paul and Zeckhauser, Richard},
	month = sep,
	year = {2005},
	note = {Number: 9
Publisher: INFORMS},
	pages = {1359--1373},
}

@article{johnson_efficiency_1990,
	title = {Efficiency {Despite} {Mutually} {Payoff}-{Relevant} {Private} {Information}: {The} {Finite} {Case}},
	volume = {58},
	issn = {0012-9682},
	shorttitle = {Efficiency {Despite} {Mutually} {Payoff}-{Relevant} {Private} {Information}},
	url = {https://www.jstor.org/stable/2938354},
	doi = {10.2307/2938354},
	abstract = {Individuals have or observe partly private information. They independently choose acts, possibly including messages. The center may also act. Individuals' utilities may depend on all acts and information, including others' private information. Are there incentives depending only on public information that make desired behavior a Bayesian equilibrium? Assume incentive payments are separable and fully transferable. Appropriate incentives exist either if the center's information--perhaps solely messages--depends stochastically, however slightly, on all relevant private information, or if individuals' relative valuations of acts, however divergent, are not too dissimilarly affected by different states of nature. More generally, we give necessary and sufficient conditions for existence whenever the strategy profile asks agents to reveal all private knowledge relevant to their beliefs about the center's information. We also develop equivalences on the possible values of private information--concepts of similarity of agent types--that are key to resolving existence questions without such responsiveness or requiring budget balance.},
	number = {4},
	urldate = {2021-03-08},
	journal = {Econometrica},
	author = {Johnson, Scott and Pratt, John W. and Zeckhauser, Richard J.},
	year = {1990},
	note = {Number: 4
Publisher: [Wiley, Econometric Society]},
	pages = {873--900},
}

@article{frey_towards_2017,
	title = {Towards an {Economics} of {Awards}},
	volume = {31},
	copyright = {© 2015 John Wiley \& Sons Ltd},
	issn = {1467-6419},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/joes.12127},
	doi = {https://doi.org/10.1111/joes.12127},
	abstract = {Awards are a widespread phenomenon. They cater to the fundamental desire for social recognition and serve as a valuable incentive to influence behaviour. The study of awards such as medals, prizes and titles has in recent years gained momentum in economics, complementing the longstanding focus on material incentives. To evaluate the effectiveness of awards as a motivator is difficult as the effect of awards must be separated from the fact that awards are meant to be given to the best. We show how research on awards has advanced over the last couple of years, thus providing points of departure for future work.},
	language = {en},
	number = {1},
	urldate = {2021-03-08},
	journal = {Journal of Economic Surveys},
	author = {Frey, Bruno S. and Gallus, Jana},
	year = {2017},
	note = {Number: 1
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/joes.12127},
	keywords = {Awards, Esteem, Incentives, Monetary rewards, Motivation, Performance},
	pages = {190--200},
}

@article{winkler_quantification_1967,
	title = {The {Quantification} of {Judgment}: {Some} {Methodological} {Suggestions}},
	volume = {62},
	issn = {0162-1459},
	shorttitle = {The {Quantification} of {Judgment}},
	url = {https://www.jstor.org/stable/2283764},
	doi = {10.2307/2283764},
	abstract = {The personalistic theory of probability prescribes that a person should use personal probability assessments in decision-making and that these assessments should correspond with his judgments. Since the judgments exist solely in the assessor's mind, there is no way to prove whether or not this requirement is satisfied. De Finetti has proposed the development of methods which should oblige the assessor to make his assessments correspond with his judgments. An ideal Assessor is hypothesized and his behavior is investigated under a number of such methods (including those suggested by de Finetti and others). The implications of these methods for the theory of personal probability are discussed. Finally, although the present interest is primarily normative, the practicability of the methods is also discussed.},
	number = {320},
	urldate = {2021-03-08},
	journal = {Journal of the American Statistical Association},
	author = {Winkler, Robert L.},
	year = {1967},
	note = {Number: 320
Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {1105--1120},
}

@inproceedings{agarwal_peer_2017,
	address = {New York, NY, USA},
	series = {{EC} '17},
	title = {Peer {Prediction} with {Heterogeneous} {Users}},
	isbn = {978-1-4503-4527-9},
	url = {https://doi.org/10.1145/3033274.3085127},
	doi = {10.1145/3033274.3085127},
	abstract = {Peer prediction mechanisms incentivize agents to truthfully report their signals, in the absence of a verification mechanism, by comparing their reports with those of their peers. Prior work in this area is essentially restricted to the case of homogeneous agents, whose signal distributions are identical. This is limiting in many domains, where we would expect agents to differ in taste, judgment and reliability. Although the Correlated Agreement (CA) mechanism [30] can be extended to handle heterogeneous agents, the new challenge is with the efficient estimation of agent signal types. We solve this problem by clustering agents based on their reporting behavior, proposing a mechanism that works with clusters of agents and designing algorithms that learn such a clustering. In this way, we also connect peer prediction with the Dawid and Skene [5] literature on latent types. We retain the robustness against coordinated misreports of the CA mechanism, achieving an approximate incentive guarantee of ε-informed truthfulness. We show on real data that this incentive approximation is reasonable in practice, and even with a small number of clusters.},
	urldate = {2021-03-26},
	booktitle = {Proceedings of the 2017 {ACM} {Conference} on {Economics} and {Computation}},
	publisher = {Association for Computing Machinery},
	author = {Agarwal, Arpit and Mandal, Debmalya and Parkes, David C. and Shah, Nisarg},
	month = jun,
	year = {2017},
	keywords = {clustering, information elicitation, peer prediction, tensor decomposition},
	pages = {81--98},
}

@article{radanovic_incentives_2014,
	title = {Incentives for {Truthful} {Information} {Elicitation} of {Continuous} {Signals}},
	volume = {28},
	copyright = {Copyright (c)},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/8797},
	language = {en},
	number = {1},
	urldate = {2021-03-27},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Radanovic, Goran and Faltings, Boi},
	month = jun,
	year = {2014},
	note = {Number: 1},
	keywords = {Peer Prediction},
}

@misc{team_analysis_2015,
	type = {Text},
	title = {Analysis of {Emerging} {Reputation} and {Funding} {Mechanisms} in the {Context} of {Open} {Science} 2.0},
	url = {https://ec.europa.eu/jrc/en/publication/analysis-emerging-reputation-and-funding-mechanisms-context-open-science-20},
	abstract = {Analysis of Emerging Reputation and Funding Mechanisms in the Context of Open Science 2.0},
	language = {en},
	urldate = {2021-03-27},
	journal = {EU Science Hub - European Commission},
	author = {team, FPFIS},
	month = may,
	year = {2015},
}

@inproceedings{gao_trick_2014,
	address = {New York, NY, USA},
	series = {{EC} '14},
	title = {Trick or treat: putting peer prediction to the test},
	isbn = {978-1-4503-2565-3},
	shorttitle = {Trick or treat},
	url = {https://doi.org/10.1145/2600057.2602865},
	doi = {10.1145/2600057.2602865},
	abstract = {Collecting truthful subjective information from multiple individuals is an important problem in many social and online systems. While peer prediction mechanisms promise to elicit truthful information by rewarding participants with carefully constructed payments, they also admit uninformative equilibria where coordinating participants provide no useful information. To understand how participants behave towards such mechanisms in practice, we conduct the first controlled online experiment of a peer prediction mechanism, engaging the participants in a multiplayer, real-time and repeated game. Using a hidden Markov model to capture players' strategies from their actions, our results show that participants successfully coordinate on uninformative equilibria and the truthful equilibrium is not focal, even when some uninformative equilibria do not exist or are undesirable. In contrast, most players are consistently truthful in the absence of peer prediction, suggesting that these mechanisms may be harmful when truthful reporting has similar cost to strategic behavior.},
	urldate = {2021-03-26},
	booktitle = {Proceedings of the fifteenth {ACM} conference on {Economics} and computation},
	publisher = {Association for Computing Machinery},
	author = {Gao, Xi Alice and Mao, Andrew and Chen, Yiling and Adams, Ryan Prescott},
	month = jun,
	year = {2014},
	keywords = {peer prediction, hidden markov models, online behavioral experiment},
	pages = {507--524},
}

@article{alfaro_incentives_2016,
	title = {Incentives for {Truthful} {Evaluations}.},
	volume = {abs/1608.07886},
	url = {http://arxiv.org/abs/1608.07886},
	journal = {CoRR},
	author = {Alfaro, Luca de},
	year = {2016},
}

@article{de_alfaro_incentives_2016,
	title = {Incentives for {Truthful} {Peer} {Grading}},
	url = {http://arxiv.org/abs/1604.03178},
	abstract = {Peer grading systems work well only if users have incentives to grade truthfully. An example of non-truthful grading, that we observed in classrooms, consists in students assigning the maximum grade to all submissions. With a naive grading scheme, such as averaging the assigned grades, all students would receive the maximum grade. In this paper, we develop three grading schemes that provide incentives for truthful peer grading. In the first scheme, the instructor grades a fraction p of the submissions, and penalizes students whose grade deviates from the instructor grade. We provide lower bounds on p to ensure truthfulness, and conclude that these schemes work only for moderate class sizes, up to a few hundred students. To overcome this limitation, we propose a hierarchical extension of this supervised scheme, and we show that it can handle classes of any size with bounded (and little) instructor work, and is therefore applicable to Massive Open Online Courses (MOOCs). Finally, we propose unsupervised incentive schemes, in which the student incentive is based on statistical properties of the grade distribution, without any grading required by the instructor. We show that the proposed unsupervised schemes provide incentives to truthful grading, at the price of being possibly unfair to individual students.},
	urldate = {2021-03-27},
	journal = {arXiv:1604.03178 [cs]},
	author = {de Alfaro, Luca and Shavlovsky, Michael and Polychronopoulos, Vassilis},
	month = apr,
	year = {2016},
	note = {arXiv: 1604.03178},
	keywords = {Computer Science - Computer Science and Game Theory},
	annote = {Comment: 26 pages},
}

@article{radanovic_incentives_2016,
	title = {Incentives for {Effort} in {Crowdsourcing} {Using} the {Peer} {Truth} {Serum}},
	volume = {7},
	issn = {2157-6904},
	url = {https://doi.org/10.1145/2856102},
	doi = {10.1145/2856102},
	abstract = {Crowdsourcing is widely proposed as a method to solve a large variety of judgment tasks, such as classifying website content, peer grading in online courses, or collecting real-world data. As the data reported by workers cannot be verified, there is a tendency to report random data without actually solving the task. This can be countered by making the reward for an answer depend on its consistency with answers given by other workers, an approach called peer consistency. However, it is obvious that the best strategy in such schemes is for all workers to report the same answer without solving the task. Dasgupta and Ghosh [2013] show that, in some cases, exerting high effort can be encouraged in the highest-paying equilibrium. In this article, we present a general mechanism that implements this idea and is applicable to most crowdsourcing settings. Furthermore, we experimentally test the novel mechanism, and validate its theoretical properties.},
	number = {4},
	urldate = {2021-03-27},
	journal = {ACM Transactions on Intelligent Systems and Technology},
	author = {Radanovic, Goran and Faltings, Boi and Jurca, Radu},
	month = mar,
	year = {2016},
	note = {Number: 4},
	keywords = {peer prediction, Crowdsourcing, mechanism design},
	pages = {48:1--48:28},
}

@inproceedings{witkowski_peer_2012,
	address = {New York, NY, USA},
	series = {{EC} '12},
	title = {Peer prediction without a common prior},
	isbn = {978-1-4503-1415-2},
	url = {https://doi.org/10.1145/2229012.2229085},
	doi = {10.1145/2229012.2229085},
	abstract = {Reputation mechanisms at online opinion forums, such as Amazon Reviews, elicit ratings from users about their experience with different products. Crowdsourcing applications, such as image tagging on Amazon Mechanical Turk, elicit votes from users as to whether or not a job was duly completed. An important property in both settings is that the feedback received from users (agents) is truthful. The peer prediction method introduced by Miller et al. [2005] is a prominent theoretical mechanism for the truthful elicitation of reports. However, a significant obstacle to its application is that it critically depends on the assumption of a common prior amongst both the agents and the mechanism. In this paper, we develop a peer prediction mechanism for settings where the agents hold subjective and private beliefs about the state of the world and the likelihood of a positive signal given a particular state. Our shadow peer prediction mechanism exploits temporal structure in order to elicit two reports, a belief report and then a signal report, and it provides strict incentives for truthful reporting as long as the effect an agent's signal has on her posterior belief is bounded away from zero. Alternatively, this technical requirement on beliefs can be dispensed with by a modification in which the second report is a belief report rather than a signal report.},
	urldate = {2021-03-26},
	booktitle = {Proceedings of the 13th {ACM} {Conference} on {Electronic} {Commerce}},
	publisher = {Association for Computing Machinery},
	author = {Witkowski, Jens and Parkes, David C.},
	month = jun,
	year = {2012},
	keywords = {information elicitation, peer prediction, mechanism design},
	pages = {964--981},
}

@article{schotter_belief_2014,
	title = {Belief {Elicitation} in the {Laboratory}},
	volume = {6},
	url = {https://doi.org/10.1146/annurev-economics-080213-040927},
	doi = {10.1146/annurev-economics-080213-040927},
	abstract = {One constraint we face as economists is not being able to observe all the relevant variables required to test our theories or make policy prescriptions. Laboratory techniques allow us to convert many variables (such as beliefs) that are unobservable in the field into observables. This article presents a survey of the literature on belief elicitation in laboratory experimental economics. We discuss several techniques available to elicit beliefs in an incentive-compatible manner and the problems involved in their use. We then look at how successful these techniques have been when employed in laboratory studies. We find that despite some problems, beliefs elicited in the laboratory are meaningful (i.e., they are generally used as the basis for behavior), and the process of eliciting beliefs seems not to be too intrusive. One hope for the future is that by eliciting beliefs, we may be able to develop better theories of belief formation.},
	number = {1},
	urldate = {2021-03-27},
	journal = {Annual Review of Economics},
	author = {Schotter, Andrew and Trevino, Isabel},
	year = {2014},
	note = {Number: 1
\_eprint: https://doi.org/10.1146/annurev-economics-080213-040927},
	pages = {103--128},
}

@inproceedings{witkowski_proper_2017,
	address = {San Francisco, California, USA},
	series = {{AAAI}'17},
	title = {Proper proxy scoring rules},
	abstract = {Proper scoring rules can be used to incentivize a forecaster to truthfully report her private beliefs about the probabilities of future events and to evaluate the relative accuracy of forecasters. While standard scoring rules can score forecasts only once the associated events have been resolved, many applications would benefit from instant access to proper scores. In forecast aggregation, for example, it is known that using weighted averages, where more weight is put on more accurate forecasters, outperforms simple averaging of forecasts. We introduce proxy scoring rules, which generalize proper scoring rules and, given access to an appropriate proxy, allow for immediate scoring of probabilistic forecasts. In particular, we suggest a proxy-scoring generalization of the popular quadratic scoring rule, and characterize its incentive and accuracy evaluation properties theoretically. Moreover, we thoroughly evaluate it experimentally using data from a large real world geopolitical forecasting tournament, and show that it is competitive with proper scoring rules when the number of questions is small.},
	urldate = {2021-03-26},
	booktitle = {Proceedings of the {Thirty}-{First} {AAAI} {Conference} on {Artificial} {Intelligence}},
	publisher = {AAAI Press},
	author = {Witkowski, Jens and Atanasov, Pavel and Ungar, Lyle H. and Krause, Andreas},
	month = feb,
	year = {2017},
	pages = {743--749},
}

@article{vaughan_making_2018,
	title = {Making {Better} {Use} of the {Crowd}: {How} {Crowdsourcing} {Can} {Advance} {Machine} {Learning} {Research}},
	volume = {18},
	issn = {1533-7928},
	shorttitle = {Making {Better} {Use} of the {Crowd}},
	url = {http://jmlr.org/papers/v18/17-234.html},
	number = {193},
	urldate = {2021-03-27},
	journal = {Journal of Machine Learning Research},
	author = {Vaughan, Jennifer Wortman},
	year = {2018},
	note = {Number: 193},
	pages = {1--46},
}

@article{kong_information_2019,
	title = {An {Information} {Theoretic} {Framework} {For} {Designing} {Information} {Elicitation} {Mechanisms} {That} {Reward} {Truth}-telling},
	volume = {7},
	issn = {2167-8375},
	url = {https://doi.org/10.1145/3296670},
	doi = {10.1145/3296670},
	abstract = {In the setting where information cannot be verified, we propose a simple yet powerful information theoretical framework—the Mutual Information Paradigm—for information elicitation mechanisms. Our framework pays every agent a measure of mutual information between her signal and a peer’s signal. We require that the mutual information measurement has the key property that any “data processing” on the two random variables will decrease the mutual information between them. We identify such information measures that generalize Shannon mutual information. Our Mutual Information Paradigm overcomes the two main challenges in information elicitation without verification: (1) how to incentivize high-quality reports and avoid agents colluding to report random or identical responses; (2) how to motivate agents who believe they are in the minority to report truthfully. Aided by the information measures, we found (1) we use the paradigm to design a family of novel mechanisms where truth-telling is a dominant strategy and pays better than any other strategy profile (in the multi-question, detail free, minimal setting where the number of questions is large); (2) we show the versatility of our framework by providing a unified theoretical understanding of existing mechanisms—Bayesian Truth Serum Prelec (2004) and Dasgupta and Ghosh (2013)—by mapping them into our framework such that theoretical results of those existing mechanisms can be reconstructed easily. We also give an impossibility result that illustrates, in a certain sense, the the optimality of our framework.},
	number = {1},
	urldate = {2021-03-27},
	journal = {ACM Transactions on Economics and Computation},
	author = {Kong, Yuqing and Schoenebeck, Grant},
	month = jan,
	year = {2019},
	note = {Number: 1},
	keywords = {mechanism design, crowdsourcing, information theory, Peer prediction},
	pages = {2:1--2:33},
}

@inproceedings{jurca_collusion-resistant_2007,
	address = {New York, NY, USA},
	series = {{EC} '07},
	title = {Collusion-resistant, incentive-compatible feedback payments},
	isbn = {978-1-59593-653-0},
	url = {https://doi.org/10.1145/1250910.1250940},
	doi = {10.1145/1250910.1250940},
	abstract = {Online reputation mechanisms need honest feedback to function effectively. Self-interested agents report the truth only when explicit rewards offset the potential gains obtained from lying. Feedback payment schemes (monetary rewardsfor submitted feedback) can make truth-telling rational based on the correlation between the reports of different buyers. In this paper we investigate incentive-compatible payment mechanisms that are also resistant to collusion: groups of agents cannot collude on a lying strategy without suffering monetary losses. We analyze several scenarios, where, for example, some or all of the agents collude. For each scenario we investigate both existential and implementation problems. Throughout the paper we use automated mechanism design to compute the best possible mechanism for a given setting.},
	urldate = {2021-03-26},
	booktitle = {Proceedings of the 8th {ACM} conference on {Electronic} commerce},
	publisher = {Association for Computing Machinery},
	author = {Jurca, Radu and Faltings, Boi},
	month = jun,
	year = {2007},
	keywords = {mechanism design, collusion resistance, incentive compatibility, reputation mechanisms},
	pages = {200--209},
}

@article{laffont_mechanism_2000,
	title = {Mechanism {Design} with {Collusion} and {Correlation}},
	volume = {68},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/2999429},
	abstract = {In a public good environment with positively correlated types, we characterize optimal mechanisms when agents have private information and can enter collusive agreements. First, we prove a weak-collusion-proof principle according to which there is no restriction for the principal in offering weak-collusion-proof mechanisms. Second, with this principle, we characterize the set of allocations that satisfy individual and coalitional incentive constraints. The optimal weakly collusion-proof mechanism calls for distortions away from first-best efficiency obtained without collusion. Allowing collusion restores continuity between the correlated and the uncorrelated environments. When the correlation becomes almost perfect, first-best efficiency is approached. Finally, the optimal collusion-proof mechanism is strongly ratifiable.},
	number = {2},
	urldate = {2021-03-27},
	journal = {Econometrica},
	author = {Laffont, Jean-Jacques and Martimort, David},
	year = {2000},
	note = {Number: 2
Publisher: [Wiley, Econometric Society]},
	pages = {309--342},
}

@article{brier_verification_1950,
	title = {{VERIFICATION} {OF} {FORECASTS} {EXPRESSED} {IN} {TERMS} {OF} {PROBABILITY}},
	volume = {78},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/78/1/1520-0493_1950_078_0001_vofeit_2_0_co_2.xml},
	doi = {10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d524e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}No Abstract Available.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {EN},
	number = {1},
	urldate = {2021-03-27},
	journal = {Monthly Weather Review},
	author = {Brier, Glenn W.},
	month = jan,
	year = {1950},
	note = {Number: 1
Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {1--3},
}

@techreport{jia_herding_2020,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Herding in {Probabilistic} {Forecasts}},
	url = {https://papers.ssrn.com/abstract=3674961},
	abstract = {Decision and policy makers often ask experts to forecast a future state. Experts, however, can be biased. In the economics and psychology literature, one extensively studied behavioral bias is called herding. Under strong levels of herding, it is generally known that disclosure of public information may lower forecasting accuracy. This result, however, has been derived only for point forecasts. In this paper, we consider probabilistic forecasts under herding and show that the negative externality of public information no longer holds. Furthermore, we show that the experts report too similar locations and inflate the variance of their forecasts due to herding. In addition to reacting to new information as expected, probabilistic forecasts contain more information about the experts’ full beliefs and interpersonal structure. This facilitates model estimation. To this end, we consider a one-shot setting with one forecast per expert and show that our model is identifiable up to an infinite number of solutions based on point forecasts, but up to two solutions based on probabilistic forecasts. We then provide a Bayesian estimation procedure for these two solutions and apply it to economic forecasting data collected by the European Central Bank. We find that, on average, the experts invest around 15\% of their efforts into making similar forecasts. The level of herding shows an increasing trend from 1999 to 2007 but drops sharply during the financial crisis of 2007-2008, and then rises again until 2019.},
	language = {en},
	number = {ID 3674961},
	urldate = {2021-03-30},
	institution = {Social Science Research Network},
	author = {Jia, Yanwei and Keppo, Jussi and Satopää, Ville},
	month = aug,
	year = {2020},
	doi = {10.2139/ssrn.3674961},
	note = {Issue: ID 3674961},
	keywords = {Asymmetric Information Game, Bayesian Statistics, Economic Forecasting, Public Disclosure},
}

@article{schotter_belief_2014-1,
	title = {Belief {Elicitation} in the {Laboratory}},
	volume = {6},
	url = {https://ideas.repec.org/a/anr/reveco/v6y2014p103-128.html},
	abstract = {One constraint we face as economists is not being able to observe all the relevant variables required to test our theories or make policy prescriptions. Laboratory techniques allow us to convert many variables (such as beliefs) that are unobservable in the field into observables. This article presents a survey of the literature on belief elicitation in laboratory experimental economics. We discuss several techniques available to elicit beliefs in an incentive-compatible manner and the problems involved in their use. We then look at how successful these techniques have been when employed in laboratory studies. We find that despite some problems, beliefs elicited in the laboratory are meaningful (i.e., they are generally used as the basis for behavior), and the process of eliciting beliefs seems not to be too intrusive. One hope for the future is that by eliciting beliefs, we may be able to develop better theories of belief formation.},
	language = {en},
	number = {1},
	urldate = {2021-03-30},
	journal = {Annual Review of Economics},
	author = {Schotter, Andrew and Trevino, Isabel},
	year = {2014},
	note = {Number: 1
Publisher: Annual Reviews},
	keywords = {decision theory, experiments},
	pages = {103--128},
}

@article{azoulay_toward_2018,
	title = {Toward a more scientific science},
	volume = {361},
	copyright = {Copyright © 2018 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. http://www.sciencemag.org/about/science-licenses-journal-article-reuseThis is an article distributed under the terms of the Science Journals Default License.},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/361/6408/1194},
	doi = {10.1126/science.aav2484},
	abstract = {Climb atop shoulders and wait for funerals. That, suggested Newton and then Planck, is how science advances (more or less). We've come far since then, but many notions about how people and practices, policies, and resources influence the course of science are still more rooted in traditions and intuitions than in evidence. We can and must do better, lest we resign ourselves to “intuition-based policy” when making decisions and investments aimed at driving scientific progress. Science invited experts to highlight key aspects of the scientific enterprise that are steadily yielding to empirical investigation—and to explain how Newton and Planck got it right (and Einstein got it wrong). —Brad Wible},
	language = {en},
	number = {6408},
	urldate = {2021-03-30},
	journal = {Science},
	author = {Azoulay, Pierre and Graff-Zivin, Joshua and Uzzi, Brian and Wang, Dashun and Williams, Heidi and Evans, James A. and Jin, Ginger Zhe and Lu, Susan Feng and Jones, Benjamin F. and Börner, Katy and Lakhani, Karim R. and Boudreau, Kevin J. and Guinan, Eva C.},
	month = sep,
	year = {2018},
	pmid = {30237341},
	note = {Number: 6408
Publisher: American Association for the Advancement of Science
Section: Policy Forum},
	pages = {1194--1197},
}

@article{dasgupta_simple_1987,
	title = {The {Simple} {Economics} of {Research} {Portfolios}},
	volume = {97},
	issn = {0013-0133},
	url = {https://www.jstor.org/stable/2232925},
	doi = {10.2307/2232925},
	number = {387},
	urldate = {2021-03-30},
	journal = {The Economic Journal},
	author = {Dasgupta, Partha and Maskin, Eric},
	year = {1987},
	note = {Number: 387
Publisher: [Royal Economic Society, Wiley]},
	pages = {581--595},
}

@article{armantier_eliciting_2013,
	title = {Eliciting beliefs: {Proper} scoring rules, incentives, stakes and hedging},
	volume = {62},
	issn = {0014-2921},
	shorttitle = {Eliciting beliefs},
	url = {https://www.sciencedirect.com/science/article/pii/S001429211300041X},
	doi = {10.1016/j.euroecorev.2013.03.008},
	abstract = {Proper Scoring Rules (PSRs) are popular incentivized mechanisms to elicit an agent's beliefs. This paper combines theory and experiment to characterize how PSRs bias reported beliefs when (i) the PSR payments are increased, (ii) the agent has a financial stake in the event she is predicting, and (iii) the agent can hedge her prediction by taking an additional action. In contrast with previous literature, the PSR biases are characterized for all PSRs and all risk averse agents. Our results reveal complex distortions of reported beliefs, thereby raising concerns about the ability of PSRs to recover truthful beliefs in general decision-making environments.},
	language = {en},
	urldate = {2021-03-30},
	journal = {European Economic Review},
	author = {Armantier, Olivier and Treich, Nicolas},
	month = aug,
	year = {2013},
	keywords = {Belief elicitation, Experimental economics, Scoring rules},
	pages = {17--40},
}

@article{gneiting_strictly_2007,
	title = {Strictly {Proper} {Scoring} {Rules}, {Prediction}, and {Estimation}},
	volume = {102},
	issn = {0162-1459},
	url = {https://doi.org/10.1198/016214506000001437},
	doi = {10.1198/016214506000001437},
	abstract = {Scoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is proper if the forecaster maximizes the expected score for an observation drawn from the distributionF if he or she issues the probabilistic forecast F, rather than G ≠ F. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster to make careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand. This article reviews and develops the theory of proper scoring rules on general probability spaces, and proposes and discusses examples thereof. Proper scoring rules derive from convex functions and relate to information measures, entropy functions, and Bregman divergences. In the case of categorical variables, we prove a rigorous version of the Savage representation. Examples of scoring rules for probabilistic forecasts in the form of predictive densities include the logarithmic, spherical, pseudospherical, and quadratic scores. The continuous ranked probability score applies to probabilistic forecasts that take the form of predictive cumulative distribution functions. It generalizes the absolute error and forms a special case of a new and very general type of score, the energy score. Like many other scoring rules, the energy score admits a kernel representation in terms of negative definite functions, with links to inequalities of Hoeffding type, in both univariate and multivariate settings. Proper scoring rules for quantile and interval forecasts are also discussed. We relate proper scoring rules to Bayes factors and to cross-validation, and propose a novel form of cross-validation known as random-fold cross-validation. A case study on probabilistic weather forecasts in the North American Pacific Northwest illustrates the importance of propriety. We note optimum score approaches to point and quantile estimation, and propose the intuitively appealing interval score as a utility function in interval estimation that addresses width as well as coverage.},
	number = {477},
	urldate = {2021-03-30},
	journal = {Journal of the American Statistical Association},
	author = {Gneiting, Tilmann and Raftery, Adrian E.},
	month = mar,
	year = {2007},
	note = {Number: 477
Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/016214506000001437},
	keywords = {Bayes factor, Bregman divergence, Brier score, Coherent, Continuous ranked probability score, Cross-validation, Entropy, Kernel score, Loss function, Minimum contrast estimation, Negative definite function, Prediction interval, Predictive distribution, Quantile forecast, Scoring rule, Skill score, Strictly proper, Utility function},
	pages = {359--378},
}

@article{huck_players_2002,
	title = {Do players correctly estimate what others do?: {Evidence} of conservatism in beliefs},
	volume = {47},
	issn = {0167-2681},
	shorttitle = {Do players correctly estimate what others do?},
	url = {https://www.sciencedirect.com/science/article/pii/S0167268101001706},
	doi = {10.1016/S0167-2681(01)00170-6},
	abstract = {In a simple experimental environment a group of subjects was asked to give estimates of a second group’s choice frequencies in a set of lottery-choice tasks. The results show that subjects in the first group are on average able to correctly predict the option that is chosen with higher frequency by the second group, but the predictions are systematically inaccurate in that they are distorted toward the uniform prior. Two mechanisms to elicit the expectations were used in the experiment, a quadratic scoring rule and a bidding mechanism. Aggregate results being similar under both mechanisms, the use of the former mechanism consistently yields more accurate predictions.},
	language = {en},
	number = {1},
	urldate = {2021-03-30},
	journal = {Journal of Economic Behavior \& Organization},
	author = {Huck, Steffen and Weizsäcker, Georg},
	month = jan,
	year = {2002},
	note = {Number: 1},
	keywords = {Beliefs, Elicitation, Experiments, Prediction accuracy},
	pages = {71--85},
}

@article{hyndman_convergence_2012,
	title = {Convergence: {An} {Experimental} {Study} of {Teaching} and {Learning} in {Repeated} {Games}},
	volume = {10},
	issn = {1542-4766},
	shorttitle = {Convergence},
	url = {https://doi.org/10.1111/j.1542-4774.2011.01063.x},
	doi = {10.1111/j.1542-4774.2011.01063.x},
	abstract = {Nash equilibrium can be interpreted as a steady state where players hold correct beliefs about the other players’ behavior and act rationally. We experimentally examine the process that leads to this steady state. Our results indicate that some players emerge as teachers—those subjects who, by their actions, try to influence the beliefs of their opponent and lead the way to a more favorable outcome—and that the presence of teachers appears to facilitate convergence to Nash equilibrium. In addition to our experiments, we examine games, with different properties, from other experiments and show that teaching plays an important role in these games. We also report results from treatments in which teaching is made more difficult. In these treatments, convergence rates go down and any convergence that does occur is delayed.},
	number = {3},
	urldate = {2021-03-30},
	journal = {Journal of the European Economic Association},
	author = {Hyndman, Kyle and Ozbay, Erkut Y. and Schotter, Andrew and Ehrblatt, Wolf Ze’ev},
	month = jun,
	year = {2012},
	note = {Number: 3},
	pages = {573--604},
}

@article{karni_mechanism_2009,
	title = {A {Mechanism} for {Eliciting} {Probabilities}},
	volume = {77},
	copyright = {© 2009 The Econometric Society},
	issn = {1468-0262},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA7833},
	doi = {https://doi.org/10.3982/ECTA7833},
	abstract = {This paper describes a direct revelation mechanism for eliciting agents' subjective probabilities. The game induced by the mechanism has a dominant strategy equilibrium in which the players reveal their subjective probabilities.},
	language = {en},
	number = {2},
	urldate = {2021-03-30},
	journal = {Econometrica},
	author = {Karni, Edi},
	year = {2009},
	note = {Number: 2
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.3982/ECTA7833},
	keywords = {direct revelation mechanism, Probability elicitation},
	pages = {603--606},
}

@article{harrison_eliciting_2014,
	title = {Eliciting subjective probabilities with binary lotteries},
	volume = {101},
	issn = {0167-2681},
	url = {https://www.sciencedirect.com/science/article/pii/S016726811400050X},
	doi = {10.1016/j.jebo.2014.02.011},
	abstract = {We evaluate a binary lottery procedure for inducing risk neutral behavior in a subjective belief elicitation task. Prior research has shown this procedure to robustly induce risk neutrality when subjects are given a single risk task defined over objective probabilities. Drawing a sample from the same subject population, we find evidence that the binary lottery procedure also induces linear utility in a subjective probability elicitation task using the Quadratic Scoring Rule. We also show that the binary lottery procedure can induce direct revelation of subjective probabilities in subjects with popular non-expected utility preference representations that satisfy weak conditions.},
	language = {en},
	urldate = {2021-03-30},
	journal = {Journal of Economic Behavior \& Organization},
	author = {Harrison, Glenn W. and Martínez-Correa, Jimmy and Swarthout, J. Todd},
	month = may,
	year = {2014},
	keywords = {Experimental economics, Binary lottery procedure, Risk neutrality, Subjective probability elicitation},
	pages = {128--140},
}

@article{offerman_truth_2009,
	title = {A {Truth} {Serum} for {Non}-{Bayesians}: {Correcting} {Proper} {Scoring} {Rules} for {Risk} {Attitudes}*},
	volume = {76},
	issn = {0034-6527},
	shorttitle = {A {Truth} {Serum} for {Non}-{Bayesians}},
	url = {https://doi.org/10.1111/j.1467-937X.2009.00557.x},
	doi = {10.1111/j.1467-937X.2009.00557.x},
	abstract = {Proper scoring rules provide convenient and highly efficient tools for incentive-compatible elicitations of subjective beliefs. As traditionally used, however, they are valid only under expected value maximization. This paper shows how they can be generalized to modern (“non-expected utility”) theories of risk and ambiguity, yielding mutual benefits: users of scoring rules can benefit from the empirical realism of non-expected utility, and analysts of ambiguity attitudes can benefit from efficient measurements using proper scoring rules. An experiment demonstrates the feasibility of our generalization.},
	number = {4},
	urldate = {2021-03-30},
	journal = {The Review of Economic Studies},
	author = {Offerman, Theo and Sonnemans, Joep and Van De Kuilen, Gijs and Wakker, Peter P.},
	month = oct,
	year = {2009},
	note = {Number: 4},
	pages = {1461--1489},
}

@article{offerman_whats_2004,
	title = {What’s {Causing} {Overreaction}? {An} {Experimental} {Investigation} of {Recency} and the {Hot}-hand {Effect}},
	volume = {106},
	issn = {1467-9442},
	shorttitle = {What’s {Causing} {Overreaction}?},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.0347-0520.2004.t01-1-00376.x},
	doi = {https://doi.org/10.1111/j.0347-0520.2004.t01-1-00376.x},
	abstract = {A substantial body of empirical literature provides evidence of overreaction in markets. Past losers outperform past winners in stock markets as well as in sports markets. Two hypotheses are consistent with this observation. The recency hypothesis states that traders overweight recent information; they are too optimistic about winners and too pessimistic about losers. According to the hot-hand hypothesis, traders try to discover trends in the past record of a firm or a team, and thereby overestimate the autocorrelation in the series. An experimental design allows us to distinguish between these hypotheses. The evidence is consistent with the hot-hand hypothesis.},
	language = {en},
	number = {3},
	urldate = {2021-03-30},
	journal = {The Scandinavian Journal of Economics},
	author = {Offerman, Theo and Sonnemans, Joep},
	year = {2004},
	note = {Number: 3
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.0347-0520.2004.t01-1-00376.x},
	keywords = {experiments, C91, D84, G12, hot hand, Overreaction, recency, scoring rule},
	pages = {533--554},
}

@article{selten_axiomatic_1998,
	title = {Axiomatic {Characterization} of the {Quadratic} {Scoring} {Rule}},
	volume = {1},
	issn = {1573-6938},
	url = {https://doi.org/10.1023/A:1009957816843},
	doi = {10.1023/A:1009957816843},
	abstract = {In the evaluation of experiments often the problem arises of how to compare the predictive success of competing probabilistic theories. The quadratic scoring rule can be used for this purpose. Originally, this rule was proposed as an incentive compatible elicitation method for probabilistic expert judgments. It is shown that up to a positive linear transformation, the quadratic scoring rule is characterized by four desirable properties.},
	language = {en},
	number = {1},
	urldate = {2021-03-30},
	journal = {Experimental Economics},
	author = {Selten, Reinhard},
	month = jun,
	year = {1998},
	note = {Number: 1},
	pages = {43--61},
}

@article{rutstrom_stated_2009,
	title = {Stated beliefs versus inferred beliefs: {A} methodological inquiry and experimental test},
	volume = {67},
	issn = {0899-8256},
	shorttitle = {Stated beliefs versus inferred beliefs},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825609000591},
	doi = {10.1016/j.geb.2009.04.001},
	abstract = {Belief elicitation in game experiments may be problematic if it changes game play. We experimentally verify that belief elicitation can alter paths of play in a two-player repeated asymmetric matching pennies game. Importantly, this effect occurs only during early periods and only for players with strongly asymmetric payoffs, consistent with a cognitive/affective effect on priors that may serve as a substitute for experience. These effects occur with a common scoring rule elicitation procedure, but not with simpler (unmotivated) statements of expected choices of opponents. Scoring rule belief elicitation improves the goodness of fit of structural models of belief learning, and prior beliefs implied by such models are both stronger and more realistic when beliefs are elicited than when they are not. We also find that “inferred beliefs” (beliefs estimated from past observed actions of opponents) can predict observed actions better than the “stated beliefs” from scoring rule belief elicitation.},
	language = {en},
	number = {2},
	urldate = {2021-03-30},
	journal = {Games and Economic Behavior},
	author = {Rutström, E. Elisabet and Wilcox, Nathaniel T.},
	month = nov,
	year = {2009},
	note = {Number: 2},
	keywords = {Experimental methods, Inferred beliefs, Repeated games, Stated beliefs},
	pages = {616--632},
}

@article{mann_power_2016,
	title = {The power of prediction markets},
	volume = {538},
	url = {http://www.nature.com/news/the-power-of-prediction-markets-1.20820},
	doi = {10.1038/538308a},
	abstract = {Scientists are beginning to understand why these ‘mini Wall Streets’ work so well at forecasting election results — and how they sometimes fail.},
	language = {en},
	number = {7625},
	urldate = {2021-03-30},
	journal = {Nature News},
	author = {Mann, Adam},
	month = oct,
	year = {2016},
	note = {Number: 7625
Section: News Feature},
	pages = {308},
}

@misc{good_judgment_project_ifpscsv_2016,
	title = {ifps.csv},
	url = {https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/BPCDH5/L8WZEF},
	abstract = {Psychologists typically measure beliefs and preferences using self-reports, whereas economists are much more likely to infer them from behavior. Prediction markets appear to be a victory for the economic approach, having yielded more accurate probability estimates than opinion polls or experts for a wide variety of events, all without ever asking for self-reported beliefs. We conduct the most direct comparison to date of prediction markets to simple self-reports using a within-subject design. Our participants traded on the likelihood of geopolitical events. Each time they placed a trade, they ﬁrst had to report their belief that the event would occur on a 0–100 scale. When previously validated aggregation algorithms were applied to self-reported beliefs, they were at least as accurate as prediction-market prices in predicting a wide range of geopolitical events. Furthermore, the combination of approaches was signiﬁcantly more accurate than prediction-market prices alone, indicating that self-reports contained information that the market did not eﬃciently aggregate. Combining measurement techniques across behavioral and social sciences may have greater beneﬁts than previously thought.},
	language = {en},
	urldate = {2021-03-30},
	publisher = {Harvard Dataverse},
	author = {{Good Judgment Project}},
	year = {2016},
	doi = {10.7910/DVN/BPCDH5/L8WZEF},
	note = {type: dataset},
}

@article{atanasov_distilling_2015,
	title = {Distilling the {Wisdom} of {Crowds}: {Prediction} {Markets} versus {Prediction} {Polls}},
	volume = {2015},
	issn = {0065-0668},
	shorttitle = {Distilling the {Wisdom} of {Crowds}},
	url = {https://journals.aom.org/doi/abs/10.5465/ambpp.2015.15192abstract},
	doi = {10.5465/ambpp.2015.15192abstract},
	abstract = {Crowd prediction methods offer the promised to collect valuable, widely dispersed information in organizations. To the extent that information is a source of power, crowdsourcing democratizes organizational governance. We report the results of the first large-scale, long-term, experimental test of crowd prediction methods. More than 2,400 participants made forecasts on 261 world events over two forecasting seasons, each lasting more than 9 months. Forecasters in prediction markets made trades about future events in a continuous double auction. Those in prediction polls submitted explicit probability judgments, independently or in teams. Probability values were aggregated statistically. In Study 1, which used full random assignment, prediction markets were more accurate than the unweighted mean of forecasts from prediction polls. However, team prediction polls aggregated with algorithms featuring decay, weighting and recalibration outperformed prediction markets by 12\% in terms of Brier score. This pattern persisted in Study 2, and was stable across scoring rules. Prediction polls’ advantage was largest at the start of long-duration questions. Prediction polls with proper scoring, algorithmic aggregation and teaming offer an attractive method for distilling crowd wisdom.},
	number = {1},
	urldate = {2021-03-30},
	journal = {Academy of Management Proceedings},
	author = {Atanasov, Pavel and Rescober, Philip and Stone, Eric and Swift, Samuel A and Servan-Schreiber, Emile and Tetlock, Philip E. and Ungar, Lyle and Mellers, Barbara},
	month = jan,
	year = {2015},
	note = {Number: 1
Publisher: Academy of Management},
	pages = {15192},
}

@misc{noauthor_evaluating_2021,
	title = {Evaluating replicability of laboratory experiments in economics {\textbar} {Science}},
	url = {https://science.sciencemag.org/content/351/6280/1433},
	urldate = {2021-03-30},
	month = mar,
	year = {2021},
}

@article{camerer_evaluating_2016,
	title = {Evaluating replicability of laboratory experiments in economics},
	volume = {351},
	copyright = {Copyright © 2016, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/351/6280/1433},
	doi = {10.1126/science.aaf0918},
	abstract = {Another social science looks at itself
Experimental economists have joined the reproducibility discussion by replicating selected published experiments from two top-tier journals in economics. Camerer et al. found that two-thirds of the 18 studies examined yielded replicable estimates of effect size and direction. This proportion is somewhat lower than unaffiliated experts were willing to bet in an associated prediction market, but roughly in line with expectations from sample sizes and P values.
Science, this issue p. 1433
The replicability of some scientific findings has recently been called into question. To contribute data about replicability in economics, we replicated 18 studies published in the American Economic Review and the Quarterly Journal of Economics between 2011 and 2014. All of these replications followed predefined analysis plans that were made publicly available beforehand, and they all have a statistical power of at least 90\% to detect the original effect size at the 5\% significance level. We found a significant effect in the same direction as in the original study for 11 replications (61\%); on average, the replicated effect size is 66\% of the original. The replicability rate varies between 67\% and 78\% for four additional replicability indicators, including a prediction market measure of peer beliefs.
By several metrics, economics experiments do replicate, although not as often as predicted.
By several metrics, economics experiments do replicate, although not as often as predicted.},
	language = {en},
	number = {6280},
	urldate = {2021-03-30},
	journal = {Science},
	author = {Camerer, Colin F. and Dreber, Anna and Forsell, Eskil and Ho, Teck-Hua and Huber, Jürgen and Johannesson, Magnus and Kirchler, Michael and Almenberg, Johan and Altmejd, Adam and Chan, Taizan and Heikensten, Emma and Holzmeister, Felix and Imai, Taisuke and Isaksson, Siri and Nave, Gideon and Pfeiffer, Thomas and Razen, Michael and Wu, Hang},
	month = mar,
	year = {2016},
	pmid = {26940865},
	note = {Number: 6280
Publisher: American Association for the Advancement of Science
Section: Report},
	pages = {1433--1436},
}

@article{andersen_estimating_2014,
	title = {Estimating subjective probabilities},
	volume = {48},
	issn = {1573-0476},
	url = {https://doi.org/10.1007/s11166-014-9194-z},
	doi = {10.1007/s11166-014-9194-z},
	abstract = {Subjective probabilities play a central role in many economic decisions and act as an immediate confound of inferences about behavior, unless controlled for. Several procedures to recover subjective probabilities have been proposed, but in order to recover the correct latent probability one must either construct elicitation mechanisms that control for risk aversion, or construct elicitation mechanisms which undertake “calibrating adjustments” to elicited reports. We illustrate how the joint estimation of risk attitudes and subjective probabilities can provide the calibration adjustments that theory calls for. We illustrate this approach using data from a controlled experiment with real monetary consequences to the subjects. This allows the observer to make inferences about the latent subjective probability, under virtually any well-specified model of choice under subjective risk, while still employing relatively simple elicitation mechanisms.},
	language = {en},
	number = {3},
	urldate = {2021-03-30},
	journal = {Journal of Risk and Uncertainty},
	author = {Andersen, Steffen and Fountain, John and Harrison, Glenn W. and Rutström, E. Elisabet},
	month = jun,
	year = {2014},
	note = {Number: 3},
	pages = {207--229},
}

@article{bickel_comparisons_2007,
	title = {Some {Comparisons} among {Quadratic}, {Spherical}, and {Logarithmic} {Scoring} {Rules}},
	volume = {4},
	issn = {1545-8490},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/deca.1070.0089},
	doi = {10.1287/deca.1070.0089},
	abstract = {Strictly proper scoring rules continue to play an important role in probability assessment. Although many such rules have been developed, relatively little guidance exists as to which rule is the most appropriate. In this paper, we discuss two important properties of quadratic, spherical, and logarithmic scoring rules. From an ex post perspective, we compare their rank order properties and conclude that both quadratic and spherical scoring perform poorly in this regard, relative to logarithmic. Second, from an ex ante perspective, we demonstrate that in many situations, logarithmic scoring is the method least affected by a nonlinear utility function. These results suggest that logarithmic scoring is superior when rank order results are important and/or when the assessor has a nonlinear utility function. In addition to these results, and perhaps more important, we demonstrate that nonlinear utility induces relatively little deviation from the optimal assessment under an assumption of risk neutrality. These results provide both comfort and guidance to those who would like to use scoring rules as part of the assessment process.},
	number = {2},
	urldate = {2021-03-30},
	journal = {Decision Analysis},
	author = {Bickel, J. Eric},
	month = jun,
	year = {2007},
	note = {Number: 2
Publisher: INFORMS},
	pages = {49--65},
}

@article{watson_molecular_1953,
	title = {Molecular {Structure} of {Nucleic} {Acids}: {A} {Structure} for {Deoxyribose} {Nucleic} {Acid}},
	volume = {171},
	copyright = {1953 Nature Publishing Group},
	issn = {1476-4687},
	shorttitle = {Molecular {Structure} of {Nucleic} {Acids}},
	url = {https://www.nature.com/articles/171737a0},
	doi = {10.1038/171737a0},
	abstract = {The determination in 1953 of the structure of deoxyribonucleic acid (DNA), with its two entwined helices and paired organic bases, was a tour de force in X-ray crystallography. But more significantly, it also opened the way for a deeper understanding of perhaps the most important biological process. In the words of Watson and Crick: "It has not escaped our notice that the specific pairing that we have postulated immediately suggests a possible copying mechanism for the genetic material." [Obituary of Francis Crick:},
	language = {en},
	number = {4356},
	urldate = {2021-04-13},
	journal = {Nature},
	author = {Watson, J. D. and Crick, F. H. C.},
	month = apr,
	year = {1953},
	note = {Number: 4356
Publisher: Nature Publishing Group},
	pages = {737--738},
}

@article{weitzman_recombinant_1998,
	title = {Recombinant {Growth}*},
	volume = {113},
	issn = {0033-5533},
	url = {https://doi.org/10.1162/003355398555595},
	doi = {10.1162/003355398555595},
	abstract = {This paper attempts to provide microfoundations for the knowledge production function in an idea-based growth model. Production of new ideas is made a function of newly reconfigured old ideas in the spirit of the way an agricultural research station develops improved plant varieties by cross-pollinating existing plant varieties. The model shows how knowledge can build upon itself in a combinatoric feedback process that may have significant implications for economic growth. The paper's main theme is that the ultimate limits to growth lie not so much in our ability to generate new ideas as in our ability to process an abundance of potentially new ideas into usable form.},
	number = {2},
	urldate = {2021-05-02},
	journal = {The Quarterly Journal of Economics},
	author = {Weitzman, Martin L.},
	month = may,
	year = {1998},
	note = {Number: 2},
	pages = {331--360},
}

@article{weitzman_recombinant_1998-1,
	title = {Recombinant {Growth}*},
	volume = {113},
	issn = {0033-5533},
	url = {https://doi.org/10.1162/003355398555595},
	doi = {10.1162/003355398555595},
	abstract = {This paper attempts to provide microfoundations for the knowledge production function in an idea-based growth model. Production of new ideas is made a function of newly reconfigured old ideas in the spirit of the way an agricultural research station develops improved plant varieties by cross-pollinating existing plant varieties. The model shows how knowledge can build upon itself in a combinatoric feedback process that may have significant implications for economic growth. The paper's main theme is that the ultimate limits to growth lie not so much in our ability to generate new ideas as in our ability to process an abundance of potentially new ideas into usable form.},
	number = {2},
	urldate = {2021-05-02},
	journal = {The Quarterly Journal of Economics},
	author = {Weitzman, Martin L.},
	month = may,
	year = {1998},
	note = {Number: 2},
	pages = {331--360},
}

@article{berliant_knowledge_2008,
	title = {Knowledge {Creation} as a {Square} {Dance} on the {Hilbert} {Cube}*},
	volume = {49},
	copyright = {© (2008) by the Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association},
	issn = {1468-2354},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-2354.2008.00512.x},
	doi = {https://doi.org/10.1111/j.1468-2354.2008.00512.x},
	abstract = {This article presents a micromodel of knowledge creation through the interactions among a group of people. The model features myopic agents in a pure externality model of interaction. Surprisingly, for a large set of initial conditions we find that the equilibrium process of knowledge creation converges to the most productive state, where the population splits into smaller groups of optimal size; close interaction takes place within each group only. This optimal size is larger as heterogeneity of knowledge is more important in the knowledge production process. Equilibrium paths are found analytically; they are a discontinuous function of initial heterogeneity.},
	language = {en},
	number = {4},
	urldate = {2021-05-02},
	journal = {International Economic Review},
	author = {Berliant, Marcus and Fujita, Masahisa},
	year = {2008},
	note = {Number: 4
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1468-2354.2008.00512.x},
	pages = {1251--1295},
}

@article{lucas_ideas_2009,
	title = {Ideas and {Growth}},
	volume = {76},
	issn = {0013-0427},
	url = {https://www.jstor.org/stable/40071767},
	abstract = {This paper introduces and partially develops a new model of endogenous technological change, viewed as the product of a class of problem-solving producers. The model, based on earlier work by Eaton and Kortum, is built up from the premise that all knowledge resides in the head of some individual person and the knowledge of a firm, or economy, or any group of people is simply the knowledge of the individuals that comprise it. The model is applied to an economy with a cohort structure. A calibration of the model using cross-section earnings data, in addition to aggregate GDP growth, is considered.},
	number = {301},
	urldate = {2021-05-02},
	journal = {Economica},
	author = {Lucas, Robert E.},
	year = {2009},
	note = {Number: 301
Publisher: [London School of Economics, Wiley, The London School of Economics and Political Science, The Suntory and Toyota International Centres for Economics and Related Disciplines]},
	pages = {1--19},
}

@article{jr_knowledge_2014,
	title = {Knowledge {Growth} and the {Allocation} of {Time}},
	volume = {122},
	url = {https://ideas.repec.org/a/ucp/jpolec/doi10.1086-674363.html},
	abstract = {We analyze a model economy with many agents, each with a different productivity level. Agents divide their time between two activities: producing goods with the production-related knowledge they already have and interacting with others in search of new, productivity-increasing ideas. These choices jointly determine the economy's current production level and its rate of learning and real growth. We construct the balanced growth path for this economy. We also study the allocation chosen by an idealized planner who takes into account and internalizes the external benefits of search. Finally, we provide three examples of alternative learning technologies and show that the properties of equilibrium allocations are quite sensitive to two of these variations.},
	language = {en},
	number = {1},
	urldate = {2021-05-02},
	journal = {Journal of Political Economy},
	author = {Jr, Robert E. Lucas and Moll, Benjamin},
	year = {2014},
	note = {Number: 1
Publisher: University of Chicago Press},
	pages = {1--51},
}

@article{thursby_prepublication_2018,
	title = {Prepublication disclosure of scientific results: {Norms}, competition, and commercial orientation},
	volume = {4},
	copyright = {Copyright © 2018 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution NonCommercial License 4.0 (CC BY-NC).. This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial license, which permits use, distribution, and reproduction in any medium, so long as the resultant use is not for commercial advantage and provided the original work is properly cited.},
	issn = {2375-2548},
	shorttitle = {Prepublication disclosure of scientific results},
	url = {https://advances.sciencemag.org/content/4/5/eaar2133},
	doi = {10.1126/sciadv.aar2133},
	abstract = {On the basis of a survey of 7103 active faculty researchers in nine fields, we examine the extent to which scientists disclose prepublication results, and when they do, why? Except in two fields, more scientists disclose results before publication than not, but there is significant variation in their reasons to disclose, in the frequency of such disclosure, and in withholding crucial results when making public presentations. They disclose results for feedback and credit and to attract collaborators. Particularly in formulaic fields, scientists disclose to attract new researchers to the field independent of collaboration and to deter others from working on their exact problem. A probability model shows that 70\% of field variation in disclosure is related to differences in respondent beliefs about norms, competition, and commercialization. Our results suggest new research directions—for example, do the problems addressed or the methods of scientific production themselves shape norms and competition? Are the levels we observe optimal or simply path-dependent? What is the interplay of norms, competition, and commercialization in disclosure and the progress of science?
To disclose results before publication or not? That is the question.
To disclose results before publication or not? That is the question.},
	language = {en},
	number = {5},
	urldate = {2021-05-03},
	journal = {Science Advances},
	author = {Thursby, Jerry G. and Haeussler, Carolin and Thursby, Marie C. and Jiang, Lin},
	month = may,
	year = {2018},
	note = {Number: 5
Publisher: American Association for the Advancement of Science
Section: Research Article},
	pages = {eaar2133},
}

@article{partha_toward_1994,
	series = {Special {Issue} in {Honor} of {Nathan} {Rosenberg}},
	title = {Toward a new economics of science},
	volume = {23},
	issn = {0048-7333},
	url = {https://www.sciencedirect.com/science/article/pii/0048733394010021},
	doi = {10.1016/0048-7333(94)01002-1},
	abstract = {Science policy issues have recently joined technology issues in being acknowledged to have strategic importance for national ‘competitiveness’ and ‘economic security’. The economics literature addressed specifically to science and its interdependences with technological progress has been quite narrowly focused and has lacked an overarching conceptual framework to guide empirical studies and public policy discussions in this area. The emerging ‘new economics of science’, described by this paper, offers a way to remedy these deficiencies. It makes use of insights from the theory of games of incomplete information to synthesize the classic approach of Arrow and Nelson in examining the implications of the characteristics of information for allocative efficiency in research activities, on the one hand, with the functionalist analysis of institutional structures, reward systems and behavioral norms of ‘open science’ communities-associated with the sociology of science in the tradition of Merton-on the other. An analysis is presented of the gross features of the institutions and norms distinguishing open science from other modes of organizing scientific research, which shows that the collegiate reputation-based reward system functions rather well in satisfying the requirement of social efficiency in increasing the stock of reliable knowledge. At a more fine-grain level of examination, however, the detailed workings of the system based on the pursuit of priority are found to cause numerous inefficiencies in the allocation of basic and applied science resources, both within given fields and programs and across time. Another major conclusion, arrived at in the context of examining policy measures and institutional reforms proposed to promote knowledge transfers between university-based open science and commercial R\&D, is that there are no economic forces that operate automatically to maintain dynamic efficiency in the interactions of these two (organizational) spheres. Ill-considered institutional experiments, which destroy their distinctive features if undertaken on a sufficient scale, may turn out to be very costly in terms of long-term economic performance.},
	language = {en},
	number = {5},
	urldate = {2021-05-03},
	journal = {Research Policy},
	author = {Partha, Dasgupta and David, Paul A.},
	month = sep,
	year = {1994},
	note = {Number: 5},
	pages = {487--521},
}

@article{murray_mice_2016,
	title = {Of {Mice} and {Academics}: {Examining} the {Effect} of {Openness} on {Innovation}},
	volume = {8},
	issn = {1945-7731},
	shorttitle = {Of {Mice} and {Academics}},
	url = {https://www.aeaweb.org/articles?id=10.1257/pol.20140062},
	doi = {10.1257/pol.20140062},
	abstract = {This paper argues that openness, by lowering costs to access existing research, can enhance both early and late stage innovation through greater exploration of novel research directions. We examine a natural experiment in openness: late-1990s NIH agreements that reduced academics' access costs regarding certain genetically engineered mice. Implementing difference-in-differences estimators, we find that increased openness encourages entry by new researchers and exploration of more diverse research paths, and does not reduce the creation of new genetically engineered mice. Our findings highlight a neglected cost of strong intellectual property restrictions: lower levels of exploration leading to reduced diversity of research output. (JEL I23, O31, O33, O34)},
	language = {en},
	number = {1},
	urldate = {2021-05-03},
	journal = {American Economic Journal: Economic Policy},
	author = {Murray, Fiona and Aghion, Philippe and Dewatripont, Mathias and Kolev, Julian and Stern, Scott},
	month = feb,
	year = {2016},
	note = {Number: 1},
	keywords = {Diffusion Processes, Intellectual Property and Intellectual Capital, Higher Education, Research Institutions, Innovation and Invention: Processes and Incentives, Technological Change: Choices and Consequences},
	pages = {212--252},
}

@article{jones_as_2011,
	title = {As {Science} {Evolves}, {How} {Can} {Science} {Policy}?},
	volume = {11},
	issn = {1531-3468},
	url = {https://www.journals.uchicago.edu/doi/full/10.1086/655820},
	doi = {10.1086/655820},
	abstract = {Getting science policy right is a core objective of government that bears on scientific advance, economic growth, health, and longevity. Yet the process of science is changing. As science advances and knowledge accumulates, ensuing generations of innovators spend longer in training and become more narrowly expert, shifting key innovations (i) later in the life cycle and (ii) from solo researchers toward teams. This paper summarizes the evidence that science has evolved—and continues to evolve—on both dimensions. The paper then considers science policy. The ongoing shift away from younger scholars and toward teamwork raises serious policy challenges. Central issues involve (a) maintaining incentives for entry into scientific careers as the training phase extends, (b) ensuring effective evaluation of ideas (including decisions on patent rights and research grants) as evaluator expertise narrows, and (c) providing appropriate effort incentives as scientists increasingly work in teams. Institutions such as government grant agencies, the patent office, the science education system, and the Nobel Prize come under a unified focus in this paper. In all cases, the question is how these institutions can change. As science evolves, science policy may become increasingly misaligned with science itself—unless science policy evolves in tandem.},
	urldate = {2021-05-03},
	journal = {Innovation Policy and the Economy},
	author = {Jones, Benjamin F.},
	month = jan,
	year = {2011},
	note = {Publisher: The University of Chicago Press},
	pages = {103--131},
}

@article{watson_molecular_1953-1,
	title = {Molecular {Structure} of {Nucleic} {Acids}: {A} {Structure} for {Deoxyribose} {Nucleic} {Acid}},
	volume = {171},
	copyright = {1953 Nature Publishing Group},
	issn = {1476-4687},
	shorttitle = {Molecular {Structure} of {Nucleic} {Acids}},
	url = {https://www.nature.com/articles/171737a0.},
	doi = {10.1038/171737a0},
	abstract = {The determination in 1953 of the structure of deoxyribonucleic acid (DNA), with its two entwined helices and paired organic bases, was a tour de force in X-ray crystallography. But more significantly, it also opened the way for a deeper understanding of perhaps the most important biological process. In the words of Watson and Crick: "It has not escaped our notice that the specific pairing that we have postulated immediately suggests a possible copying mechanism for the genetic material." [Obituary of Francis Crick:},
	language = {en},
	number = {4356},
	urldate = {2021-05-03},
	journal = {Nature},
	author = {Watson, J. D. and Crick, F. H. C.},
	month = apr,
	year = {1953},
	note = {Number: 4356
Publisher: Nature Publishing Group},
	pages = {737--738},
}

@article{nosek_preregistration_2018,
	title = {The preregistration revolution},
	volume = {115},
	copyright = {© 2018 . http://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/115/11/2600},
	doi = {10.1073/pnas.1708274114},
	abstract = {Progress in science relies in part on generating hypotheses with existing observations and testing hypotheses with new observations. This distinction between postdiction and prediction is appreciated conceptually but is not respected in practice. Mistaking generation of postdictions with testing of predictions reduces the credibility of research findings. However, ordinary biases in human reasoning, such as hindsight bias, make it hard to avoid this mistake. An effective solution is to define the research questions and analysis plan before observing the research outcomes—a process called preregistration. Preregistration distinguishes analyses and outcomes that result from predictions from those that result from postdictions. A variety of practical strategies are available to make the best possible use of preregistration in circumstances that fall short of the ideal application, such as when the data are preexisting. Services are now available for preregistration across all disciplines, facilitating a rapid increase in the practice. Widespread adoption of preregistration will increase distinctiveness between hypothesis generation and hypothesis testing and will improve the credibility of research findings.},
	language = {en},
	number = {11},
	urldate = {2021-05-03},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Nosek, Brian A. and Ebersole, Charles R. and DeHaven, Alexander C. and Mellor, David T.},
	month = mar,
	year = {2018},
	pmid = {29531091},
	note = {Number: 11
Publisher: National Academy of Sciences
Section: Colloquium Paper},
	keywords = {confirmatory analysis, exploratory analysis, methodology, open science, preregistration},
	pages = {2600--2606},
}

@article{song_extent_2009,
	title = {Extent of publication bias in different categories of research cohorts: a meta-analysis of empirical studies},
	volume = {9},
	issn = {1471-2288},
	shorttitle = {Extent of publication bias in different categories of research cohorts},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2789098/},
	doi = {10.1186/1471-2288-9-79},
	abstract = {Background
The validity of research synthesis is threatened if published studies comprise a biased selection of all studies that have been conducted. We conducted a meta-analysis to ascertain the strength and consistency of the association between study results and formal publication.

Methods
The Cochrane Methodology Register Database, MEDLINE and other electronic bibliographic databases were searched (to May 2009) to identify empirical studies that tracked a cohort of studies and reported the odds of formal publication by study results. Reference lists of retrieved articles were also examined for relevant studies. Odds ratios were used to measure the association between formal publication and significant or positive results. Included studies were separated into subgroups according to starting time of follow-up, and results from individual cohort studies within the subgroups were quantitatively pooled.

Results
We identified 12 cohort studies that followed up research from inception, four that included trials submitted to a regulatory authority, 28 that assessed the fate of studies presented as conference abstracts, and four cohort studies that followed manuscripts submitted to journals. The pooled odds ratio of publication of studies with positive results, compared to those without positive results (publication bias) was 2.78 (95\% CI: 2.10 to 3.69) in cohorts that followed from inception, 5.00 (95\% CI: 2.01 to 12.45) in trials submitted to regulatory authority, 1.70 (95\% CI: 1.44 to 2.02) in abstract cohorts, and 1.06 (95\% CI: 0.80 to 1.39) in cohorts of manuscripts.

Conclusion
Dissemination of research findings is likely to be a biased process. Publication bias appears to occur early, mainly before the presentation of findings at conferences or submission of manuscripts to journals.},
	urldate = {2021-05-03},
	journal = {BMC Medical Research Methodology},
	author = {Song, Fujian and Parekh-Bhurke, Sheetal and Hooper, Lee and Loke, Yoon K and Ryder, Jon J and Sutton, Alex J and Hing, Caroline B and Harvey, Ian},
	month = nov,
	year = {2009},
	pmid = {19941636},
	pmcid = {PMC2789098},
	pages = {79},
}

@article{song_extent_2009-1,
	title = {Extent of publication bias in different categories of research cohorts: a meta-analysis of empirical studies},
	volume = {9},
	issn = {1471-2288},
	shorttitle = {Extent of publication bias in different categories of research cohorts},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2789098/},
	doi = {10.1186/1471-2288-9-79},
	abstract = {Background
The validity of research synthesis is threatened if published studies comprise a biased selection of all studies that have been conducted. We conducted a meta-analysis to ascertain the strength and consistency of the association between study results and formal publication.

Methods
The Cochrane Methodology Register Database, MEDLINE and other electronic bibliographic databases were searched (to May 2009) to identify empirical studies that tracked a cohort of studies and reported the odds of formal publication by study results. Reference lists of retrieved articles were also examined for relevant studies. Odds ratios were used to measure the association between formal publication and significant or positive results. Included studies were separated into subgroups according to starting time of follow-up, and results from individual cohort studies within the subgroups were quantitatively pooled.

Results
We identified 12 cohort studies that followed up research from inception, four that included trials submitted to a regulatory authority, 28 that assessed the fate of studies presented as conference abstracts, and four cohort studies that followed manuscripts submitted to journals. The pooled odds ratio of publication of studies with positive results, compared to those without positive results (publication bias) was 2.78 (95\% CI: 2.10 to 3.69) in cohorts that followed from inception, 5.00 (95\% CI: 2.01 to 12.45) in trials submitted to regulatory authority, 1.70 (95\% CI: 1.44 to 2.02) in abstract cohorts, and 1.06 (95\% CI: 0.80 to 1.39) in cohorts of manuscripts.

Conclusion
Dissemination of research findings is likely to be a biased process. Publication bias appears to occur early, mainly before the presentation of findings at conferences or submission of manuscripts to journals.},
	urldate = {2021-05-03},
	journal = {BMC Medical Research Methodology},
	author = {Song, Fujian and Parekh-Bhurke, Sheetal and Hooper, Lee and Loke, Yoon K and Ryder, Jon J and Sutton, Alex J and Hing, Caroline B and Harvey, Ian},
	month = nov,
	year = {2009},
	pmid = {19941636},
	pmcid = {PMC2789098},
	pages = {79},
}

@article{dickersin_nih_1993,
	title = {{NIH} clinical trials and publication bias},
	volume = {Doc No 50},
	abstract = {To investigate the association between trial characteristics, findings, and publication. The major factor hypothesized to be associated with publication was "significant" results, which included both statistically significant results and results assessed by the investigators to be qualitatively significant, when statistical testing was not done. Other factors hypothesized to have a possible association with publication were funding institute, funding mechanism (grant versus contract versus intramural), multicenter status, use of comparison groups, large sample size, type of control (parallel versus nonparallel), use of randomization and masking, type of analysis (by treatment received versus by treatment assigned), and investigator sex and rank.
Follow-up, by 1988 interview with the principal investigator or surrogate, of all clinical trials funded by the National Institutes of Health (NIH) in 1979, to learn of trial results and publication status.
Two hundred ninety-three NIH trials, funded in 1979.
Publication of clinical trial results.
Of the 198 clinical trials completed by 1988, 93\% had been published. Trials with "significant" results were more likely to be published than those showing "nonsignificant" results (adjusted odds ratio [OR] = 12.30; 95\% confidence interval [CI], 2.54 to 60.00). No other factor was positively associated with publication. Most unpublished trials remained so because investigators thought the results were "not interesting" or they "did not have enough time" (42.8\%). Metaanalysis using data from this and 3 similar studies provided a combined unadjusted OR of 2.88 (95\% CI, 2.13 to 3.89) for the association between significant results and publication.
Even when the overall publication rate is high, such as for trials funded by the NIH, publication bias remains a significant problem. Given the importance of trials and their utility in evaluating medical treatments, especially within the context of metaanalysis, it is clear that we need more reliable systems for maintaining information about initiated studies. Trial registers represent such a system but must receive increased financial support to succeed.},
	journal = {The Online journal of current clinical trials},
	author = {Dickersin, Kay and Min, YI},
	month = may,
	year = {1993},
	pages = {[4967 words; 53 paragraphs]},
}

@inproceedings{gao_trick_2014-1,
	address = {New York, NY, USA},
	series = {{EC} '14},
	title = {Trick or treat: putting peer prediction to the test},
	isbn = {978-1-4503-2565-3},
	shorttitle = {Trick or treat},
	url = {https://doi.org/10.1145/2600057.2602865},
	doi = {10.1145/2600057.2602865},
	abstract = {Collecting truthful subjective information from multiple individuals is an important problem in many social and online systems. While peer prediction mechanisms promise to elicit truthful information by rewarding participants with carefully constructed payments, they also admit uninformative equilibria where coordinating participants provide no useful information. To understand how participants behave towards such mechanisms in practice, we conduct the first controlled online experiment of a peer prediction mechanism, engaging the participants in a multiplayer, real-time and repeated game. Using a hidden Markov model to capture players' strategies from their actions, our results show that participants successfully coordinate on uninformative equilibria and the truthful equilibrium is not focal, even when some uninformative equilibria do not exist or are undesirable. In contrast, most players are consistently truthful in the absence of peer prediction, suggesting that these mechanisms may be harmful when truthful reporting has similar cost to strategic behavior.},
	urldate = {2021-05-02},
	booktitle = {Proceedings of the fifteenth {ACM} conference on {Economics} and computation},
	publisher = {Association for Computing Machinery},
	author = {Gao, Xi Alice and Mao, Andrew and Chen, Yiling and Adams, Ryan Prescott},
	month = jun,
	year = {2014},
	keywords = {peer prediction, hidden markov models, online behavioral experiment},
	pages = {507--524},
}

@techreport{akcigit_dancing_2018,
	type = {Working {Paper}},
	title = {Dancing with the {Stars}: {Innovation} {Through} {Interactions}},
	shorttitle = {Dancing with the {Stars}},
	url = {https://www.nber.org/papers/w24466},
	abstract = {An inventor's own knowledge is a key input in the innovation process. This knowledge can be built by interacting with and learning from others. This paper uses a new large-scale panel dataset on European inventors matched to their employers and patents. We document key empirical facts on inventors' productivity over the life cycle, inventors' research teams, and interactions with other inventors. Among others, most patents are the result of collaborative work. Interactions with better inventors are very strongly correlated with higher subsequent productivity. These facts motivate the main ingredients of our new innovation-led endogenous growth model, in which innovations are produced by heterogeneous research teams of inventors using inventor knowledge. The evolution of an inventor's knowledge is explained through the lens of a diffusion model in which inventors can learn in two ways: By interacting with others at an endogenously chosen rate; and from an external, age-dependent source that captures alternative learning channels, such as learning-by-doing. Thus, our knowledge diffusion model nests inside the innovation-based endogenous growth model. We estimate the model, which fits the data very closely, and use it to perform several policy exercises, such as quantifying the large importance of interactions for growth, studying the effects of reducing interaction costs (e.g., through IT or infrastructure), and comparing the learning and innovation processes of different countries.},
	number = {24466},
	urldate = {2021-10-19},
	institution = {National Bureau of Economic Research},
	author = {Akcigit, Ufuk and Caicedo, Santiago and Miguelez, Ernest and Stantcheva, Stefanie and Sterzi, Valerio},
	month = mar,
	year = {2018},
	doi = {10.3386/w24466},
	note = {Series: Working Paper Series},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\8ULK3H43\\Akcigit et al. - 2018 - Dancing with the Stars Innovation Through Interac.pdf:application/pdf},
}

@article{jaravel_team-specific_2018,
	title = {Team-{Specific} {Capital} and {Innovation}},
	volume = {108},
	issn = {0002-8282},
	url = {https://www.aeaweb.org/articles?id=10.1257/aer.20151184},
	doi = {10.1257/aer.20151184},
	abstract = {We establish the importance of team-specific capital in the typical inventor's career. Using administrative tax and patent data for the population of US patent inventors from 1996 to 2012, we find that an inventor's premature death causes a large and long-lasting decline in their co-inventor's earnings and citation-weighted patents (–4 percent and –15 percent after 8 years, respectively). After ruling out firm disruption, network effects, and top-down spillovers as main channels, we show that the effect is driven by close-knit teams and that team-specific capital largely results from an "experience" component increasing collaboration value over time.},
	language = {en},
	number = {4-5},
	urldate = {2021-10-19},
	journal = {American Economic Review},
	author = {Jaravel, Xavier and Petkova, Neviana and Bell, Alex},
	month = apr,
	year = {2018},
	keywords = {Human Capital, Labor Productivity, Wage Level and Structure, Occupational Choice, Skills, Wage Differentials, Personnel Economics: Labor Management, Innovation and Invention: Processes and Incentives, Intellectual Property and Intellectual Capital},
	pages = {1034--1073},
	file = {Full Text:C\:\\Users\\aluga\\Zotero\\storage\\A767B25Y\\Jaravel et al. - 2018 - Team-Specific Capital and Innovation.pdf:application/pdf;Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\7DIHSXK8\\articles.html:text/html},
}

@article{franco_publication_2014,
	title = {Publication bias in the social sciences: {Unlocking} the file drawer},
	volume = {345},
	shorttitle = {Publication bias in the social sciences},
	url = {https://www.science.org/doi/abs/10.1126/science.1255484},
	doi = {10.1126/science.1255484},
	number = {6203},
	urldate = {2021-10-19},
	journal = {Science},
	author = {Franco, Annie and Malhotra, Neil and Simonovits, Gabor},
	month = sep,
	year = {2014},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {1502--1505},
}

@article{chandler_breaking_2013,
	title = {Breaking monotony with meaning: {Motivation} in crowdsourcing markets},
	volume = {90},
	issn = {0167-2681},
	shorttitle = {Breaking monotony with meaning},
	url = {https://www.sciencedirect.com/science/article/pii/S016726811300036X},
	doi = {10.1016/j.jebo.2013.03.003},
	abstract = {We conduct the first natural field experiment to explore the relationship between the “meaningfulness” of a task and worker effort. We employed about 2500 workers from Amazon's Mechanical Turk (MTurk), an online labor market, to label medical images. Although given an identical task, we experimentally manipulated how the task was framed. Subjects in the meaningful treatment were told that they were labeling tumor cells in order to assist medical researchers, subjects in the zero-context condition (the control group) were not told the purpose of the task, and, in stark contrast, subjects in the shredded treatment were not given context and were additionally told that their work would be discarded. We found that when a task was framed more meaningfully, workers were more likely to participate. We also found that the meaningful treatment increased the quantity of output (with an insignificant change in quality) while the shredded treatment decreased the quality of output (with no change in quantity). We believe these results will generalize to other short-term labor markets. Our study also discusses MTurk as an exciting platform for running natural field experiments in economics.},
	language = {en},
	urldate = {2021-10-19},
	journal = {Journal of Economic Behavior \& Organization},
	author = {Chandler, Dana and Kapelner, Adam},
	month = jun,
	year = {2013},
	keywords = {Crowdsourcing, Natural field experiment, Online labor markets, Worker motivation},
	pages = {123--133},
	file = {Submitted Version:C\:\\Users\\aluga\\Zotero\\storage\\F5ZHX69Y\\Chandler and Kapelner - 2013 - Breaking monotony with meaning Motivation in crow.pdf:application/pdf},
}

@article{boudreau_open_2015,
	title = {“{Open}” disclosure of innovations, incentives and follow-on reuse: {Theory} on processes of cumulative innovation and a field experiment in computational biology},
	volume = {44},
	issn = {0048-7333},
	shorttitle = {“{Open}” disclosure of innovations, incentives and follow-on reuse},
	url = {https://www.sciencedirect.com/science/article/pii/S0048733314001425},
	doi = {10.1016/j.respol.2014.08.001},
	abstract = {Most of society's innovation systems – academic science, the patent system, open source, etc. – are “open” in the sense that they are designed to facilitate knowledge disclosure among innovators. An essential difference across innovation systems is whether disclosure is of intermediate progress and solutions or of completed innovations. We theorize and present experimental evidence linking intermediate versus final disclosure to an ‘incentives-versus-reuse’ tradeoff and to a transformation of the innovation search process. We find intermediate disclosure has the advantage of efficiently steering development towards improving existing solution approaches, but also has the effect of limiting experimentation and narrowing technological search. We discuss the comparative advantages of intermediate versus final disclosure policies in fostering innovation.},
	language = {en},
	number = {1},
	urldate = {2021-10-19},
	journal = {Research Policy},
	author = {Boudreau, Kevin J. and Lakhani, Karim R.},
	month = feb,
	year = {2015},
	keywords = {Incentives, Disclosures, Innovation, Open innovation, Policy, Search},
	pages = {4--19},
}

@article{boudreau_open_2015-1,
	title = {“{Open}” disclosure of innovations, incentives and follow-on reuse: {Theory} on processes of cumulative innovation and a field experiment in computational biology},
	volume = {44},
	shorttitle = {“{Open}” disclosure of innovations, incentives and follow-on reuse},
	url = {https://ideas.repec.org/a/eee/respol/v44y2015i1p4-19.html},
	abstract = {Most of society's innovation systems – academic science, the patent system, open source, etc. – are “open” in the sense that they are designed to facilitate knowledge disclosure among innovators. An essential difference across innovation systems is whether disclosure is of intermediate progress and solutions or of completed innovations. We theorize and present experimental evidence linking intermediate versus final disclosure to an ‘incentives-versus-reuse’ tradeoff and to a transformation of the innovation search process. We find intermediate disclosure has the advantage of efficiently steering development towards improving existing solution approaches, but also has the effect of limiting experimentation and narrowing technological search. We discuss the comparative advantages of intermediate versus final disclosure policies in fostering innovation.},
	language = {en},
	number = {1},
	urldate = {2021-10-19},
	journal = {Research Policy},
	author = {Boudreau, Kevin J. and Lakhani, Karim R.},
	year = {2015},
	note = {Publisher: Elsevier},
	keywords = {Incentives, Disclosures, Innovation, Open innovation, Policy, Search},
	pages = {4--19},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\DJVXNJXD\\v44y2015i1p4-19.html:text/html},
}

@article{thursby_prepublication_nodate,
	title = {Prepublication disclosure of scientific results: {Norms}, competition, and commercial orientation},
	volume = {4},
	shorttitle = {Prepublication disclosure of scientific results},
	url = {https://www.science.org/doi/10.1126/sciadv.aar2133},
	doi = {10.1126/sciadv.aar2133},
	number = {5},
	urldate = {2021-11-07},
	journal = {Science Advances},
	author = {Thursby, Jerry G. and Haeussler, Carolin and Thursby, Marie C. and Jiang, Lin},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eaar2133},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\K4EGL5SE\\Thursby et al. - Prepublication disclosure of scientific results N.pdf:application/pdf},
}

@misc{noauthor_bayesian_nodate,
	title = {A {Bayesian} {Truth} {Serum} for {Subjective} {Data}},
	url = {https://www.science.org/doi/10.1126/science.1102081},
	urldate = {2021-11-08},
	file = {A Bayesian Truth Serum for Subjective Data:C\:\\Users\\aluga\\Zotero\\storage\\J9PZBM2Z\\science.html:text/html},
}

@article{prelec_bayesian_2004,
	title = {A {Bayesian} {Truth} {Serum} for {Subjective} {Data}},
	volume = {306},
	url = {https://www.science.org/doi/abs/10.1126/science.1102081},
	doi = {10.1126/science.1102081},
	number = {5695},
	urldate = {2021-11-08},
	journal = {Science},
	author = {Prelec, Dražen},
	month = oct,
	year = {2004},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {462--466},
}

@article{kruppa_probability_2014,
	title = {Probability estimation with machine learning methods for dichotomous and multicategory outcome: {Theory}},
	volume = {56},
	issn = {1521-4036},
	shorttitle = {Probability estimation with machine learning methods for dichotomous and multicategory outcome},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201300068},
	doi = {10.1002/bimj.201300068},
	abstract = {Probability estimation for binary and multicategory outcome using logistic and multinomial logistic regression has a long-standing tradition in biostatistics. However, biases may occur if the model is misspecified. In contrast, outcome probabilities for individuals can be estimated consistently with machine learning approaches, including k-nearest neighbors (k-NN), bagged nearest neighbors (b-NN), random forests (RF), and support vector machines (SVM). Because machine learning methods are rarely used by applied biostatisticians, the primary goal of this paper is to explain the concept of probability estimation with these methods and to summarize recent theoretical findings. Probability estimation in k-NN, b-NN, and RF can be embedded into the class of nonparametric regression learning machines; therefore, we start with the construction of nonparametric regression estimates and review results on consistency and rates of convergence. In SVMs, outcome probabilities for individuals are estimated consistently by repeatedly solving classification problems. For SVMs we review classification problem and then dichotomous probability estimation. Next we extend the algorithms for estimating probabilities using k-NN, b-NN, and RF to multicategory outcomes and discuss approaches for the multicategory probability estimation problem using SVM. In simulation studies for dichotomous and multicategory dependent variables we demonstrate the general validity of the machine learning methods and compare it with logistic regression. However, each method fails in at least one simulation scenario. We conclude with a discussion of the failures and give recommendations for selecting and tuning the methods. Applications to real data and example code are provided in a companion article (doi:10.1002/bimj.201300077).},
	language = {en},
	number = {4},
	urldate = {2023-02-13},
	journal = {Biometrical Journal},
	author = {Kruppa, Jochen and Liu, Yufeng and Biau, Gérard and Kohler, Michael and König, Inke R. and Malley, James D. and Ziegler, Andreas},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.201300068},
	keywords = {Bagged nearest neighbor, Nonparametric regression, Probability estimation, Random forest, Support vector machine},
	pages = {534--563},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\SBL6W57H\\bimj.html:text/html},
}

@article{malley_probability_2012,
	title = {Probability {Machines}},
	volume = {51},
	copyright = {Schattauer GmbH},
	issn = {0026-1270, 2511-705X},
	url = {http://www.thieme-connect.de/DOI/DOI?10.3414/ME00-01-0052},
	doi = {10.3414/ME00-01-0052},
	abstract = {Background: Most machine learning approaches only provide a classification for binary responses. However, probabilities are required for risk estimation using individual patient characteristics. It has been shown recently that every statistical learning machine known to be consistent for a nonparametric regression problem is a probability machine that is provably consistent for this estimation problem.

  Objectives: The aim of this paper is to show how random forests and nearest neighbors can be used for consistent estimation of individual probabilities.

  Methods: Two random forest algorithms and two nearest neighbor algorithms are described in detail for estimation of individual probabilities. We discuss the consistency of random forests, nearest neighbors and other learning machines in detail. We conduct a simulation study to illustrate the validity of the methods. We exemplify the algorithms by analyzing two well-known data sets on the diagnosis of appendicitis and the diagnosis of diabetes in Pima Indians.

  Results: Simulations demonstrate the validity of the method. With the real data application, we show the accuracy and practicality of this approach. We provide sample code from R packages in which the probability estimation is already available. This means that all calculations can be performed using existing software.

  Conclusions: Random forest algorithms as well as nearest neighbor approaches are valid machine learning methods for estimating individual probabilities for binary responses. Freely available implementations are available in R and may be used for applications.},
	language = {en},
	number = {1},
	urldate = {2023-02-13},
	journal = {Methods of Information in Medicine},
	author = {Malley, J. D. and Kruppa, J. and Dasgupta, A. and Malley, K. G. and Ziegler, A.},
	year = {2012},
	note = {Publisher: Schattauer GmbH},
	keywords = {Brier score, consistency, k nearest neighbor, logistic regression, probability estimation, random forest},
	pages = {74--81},
	file = {Accepted Version:C\:\\Users\\aluga\\Zotero\\storage\\ND7US8RJ\\Malley et al. - 2012 - Probability Machines.pdf:application/pdf},
}

@article{brodeur_methods_2020,
	title = {Methods {Matter}: p-{Hacking} and {Publication} {Bias} in {Causal} {Analysis} in {Economics}},
	volume = {110},
	issn = {0002-8282},
	shorttitle = {Methods {Matter}},
	url = {https://www.aeaweb.org/articles?id=10.1257/aer.20190687},
	doi = {10.1257/aer.20190687},
	abstract = {The credibility revolution in economics has promoted causal identification using randomized control trials (RCT), difference-in-differences (DID), instrumental variables (IV) and regression discontinuity design (RDD). Applying multiple approaches to over 21,000 hypothesis tests published in 25 leading economics journals, we find that the extent of p-hacking and publication bias varies greatly by method. IV (and to a lesser extent DID) are particularly problematic. We find no evidence that (i) papers published in the Top 5 journals are different to others; (ii) the journal "revise and resubmit" process mitigates the problem; (iii) things are improving through time.},
	language = {en},
	number = {11},
	urldate = {2023-02-14},
	journal = {American Economic Review},
	author = {Brodeur, Abel and Cook, Nikolai and Heyes, Anthony},
	month = nov,
	year = {2020},
	keywords = {and Selection, Hypothesis Testing: General, Model Evaluation, Sociology of Economics, Validation},
	pages = {3634--3660},
}

@article{askarov_significance_2022,
	title = {The {Significance} of {Data}-{Sharing} {Policy}},
	issn = {1542-4766},
	url = {https://doi.org/10.1093/jeea/jvac053},
	doi = {10.1093/jeea/jvac053},
	abstract = {We assess the impact of mandating data-sharing in economics journals on two dimensions of research credibility: statistical significance and excess statistical significance (ESS). ESS is a necessary condition for publication selection bias. Quasi-experimental difference-in-differences analysis of 20,121 estimates published in 24 general interest and leading field journals shows that data-sharing policies have reduced reported statistical significance and the associated t-values. The magnitude of this reduction is large and of practical significance. We also find suggestive evidence that mandatory data-sharing reduces ESS and hence decreases publication bias.},
	urldate = {2023-02-14},
	journal = {Journal of the European Economic Association},
	author = {Askarov, Zohid and Doucouliagos, Anthony and Doucouliagos, Hristos and Stanley, T D},
	month = sep,
	year = {2022},
	pages = {jvac053},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\KVKT566U\\6706852.html:text/html},
}

@misc{brodeur_pre-registration_2022,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Do {Pre}-{Registration} and {Pre}-{Analysis} {Plans} {Reduce} p-{Hacking} and {Publication} {Bias}?},
	url = {https://papers.ssrn.com/abstract=4180594},
	doi = {10.2139/ssrn.4180594},
	abstract = {Randomized controlled trials (RCTs) are increasingly prominent in economics, with pre-registration and pre-analysis plans (PAPs) promoted as important in ensuring the credibility of findings. We investigate whether these tools reduce the extent of p-hacking and publication bias by collecting and studying the universe of test statistics, 15,992 in total, from RCTs published in 15 leading economics journals from 2018 through 2021. In our primary analysis, we find no meaningful difference in the distribution of test statistics from pre-registered studies, compared to their non-pre-registered counterparts. However, pre-registered studies that have a complete PAP are significantly less p-hacked. These results point to the importance of PAPs, rather than pre-registration in itself, in ensuring credibility.},
	language = {en},
	urldate = {2023-02-14},
	author = {Brodeur, Abel and Cook, Nikolai and Hartley, Jonathan and Heyes, Anthony},
	month = dec,
	year = {2022},
	keywords = {p-Hacking, Pre-analysis Plan, Pre-registration, Publication Bias, Research Credibility},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\VXUAJGN5\\Brodeur et al. - 2022 - Do Pre-Registration and Pre-Analysis Plans Reduce .pdf:application/pdf},
}

@misc{korinek_preparing_2022,
	type = {Working {Paper}},
	series = {Working {Paper} {Series}},
	title = {Preparing for the ({Non}-{Existent}?) {Future} of {Work}},
	shorttitle = {Preparing for the ({Non}-{Existent}?},
	url = {https://www.nber.org/papers/w30172},
	doi = {10.3386/w30172},
	abstract = {This paper considers the labor market and distributional implications of a scenario of ever-more-intelligent autonomous machines that substitute for human labor and drive down wages. We lay out three concerns arising from such a scenario and evaluate recent predictions and objections to these concerns. Then we analyze how a utilitarian social planner would allocate work and income if these concerns start to materialize. As the income produced by autonomous machines rises and the value of labor declines, a utilitarian planner finds it optimal to phase out work, beginning with workers who have low labor productivity and job satisfaction, since they have comparative advantage in enjoying leisure. This is in stark contrast to welfare systems that force individuals with low labor productivity to work. If there are significant wage declines, avoiding mass misery will require other ways of distributing income than labor markets, whether via sufficiently well-distributed capital ownership or via benefits. Recipients could still engage in work for its own sake if they enjoy work amenities such as structure, purpose and meaning. If work gives rise to positive externalities such as social connections or political stability, or if individuals undervalue the benefits of work because of internalities, then a social planner would incentivize work. However, in the long run, the planner might be able to achieve a higher level of social welfare by adopting alternative ways of providing these benefits.},
	urldate = {2023-02-14},
	publisher = {National Bureau of Economic Research},
	author = {Korinek, Anton and Juelfs, Megan},
	month = jun,
	year = {2022},
	doi = {10.3386/w30172},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\ZGDDKHKR\\Korinek and Juelfs - 2022 - Preparing for the (Non-Existent) Future of Work.pdf:application/pdf},
}

@article{ross-hellauer_survey_2017,
	title = {Survey on open peer review: {Attitudes} and experience amongst editors, authors and reviewers},
	volume = {12},
	issn = {1932-6203},
	shorttitle = {Survey on open peer review},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0189311},
	doi = {10.1371/journal.pone.0189311},
	abstract = {Open peer review (OPR) is a cornerstone of the emergent Open Science agenda. Yet to date no large-scale survey of attitudes towards OPR amongst academic editors, authors, reviewers and publishers has been undertaken. This paper presents the findings of an online survey, conducted for the OpenAIRE2020 project during September and October 2016, that sought to bridge this information gap in order to aid the development of appropriate OPR approaches by providing evidence about attitudes towards and levels of experience with OPR. The results of this cross-disciplinary survey, which received 3,062 full responses, show the majority (60.3\%) of respondents to be believe that OPR as a general concept should be mainstream scholarly practice (although attitudes to individual traits varied, and open identities peer review was not generally favoured). Respondents were also in favour of other areas of Open Science, like Open Access (88.2\%) and Open Data (80.3\%). Among respondents we observed high levels of experience with OPR, with three out of four (76.2\%) reporting having taken part in an OPR process as author, reviewer or editor. There were also high levels of support for most of the traits of OPR, particularly open interaction, open reports and final-version commenting. Respondents were against opening reviewer identities to authors, however, with more than half believing it would make peer review worse. Overall satisfaction with the peer review system used by scholarly journals seems to strongly vary across disciplines. Taken together, these findings are very encouraging for OPR’s prospects for moving mainstream but indicate that due care must be taken to avoid a “one-size fits all” solution and to tailor such systems to differing (especially disciplinary) contexts. OPR is an evolving phenomenon and hence future studies are to be encouraged, especially to further explore differences between disciplines and monitor the evolution of attitudes.},
	language = {en},
	number = {12},
	urldate = {2023-02-14},
	journal = {PLOS ONE},
	author = {Ross-Hellauer, Tony and Deppe, Arvid and Schmidt, Birgit},
	month = dec,
	year = {2017},
	note = {Publisher: Public Library of Science},
	keywords = {Ecology and environmental sciences, Open access publishing, Open peer review, Open science, Peer review, Psychological attitudes, Social sciences, Surveys},
	pages = {e0189311},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\VPLB9Z2M\\Ross-Hellauer et al. - 2017 - Survey on open peer review Attitudes and experien.pdf:application/pdf},
}

@article{thursby_prepublication_2018-1,
	title = {Prepublication disclosure of scientific results: {Norms}, competition, and commercial orientation},
	volume = {4},
	shorttitle = {Prepublication disclosure of scientific results},
	url = {https://www.science.org/doi/full/10.1126/sciadv.aar2133},
	doi = {10.1126/sciadv.aar2133},
	abstract = {On the basis of a survey of 7103 active faculty researchers in nine fields, we examine the extent to which scientists disclose prepublication results, and when they do, why? Except in two fields, more scientists disclose results before publication than not, but there is significant variation in their reasons to disclose, in the frequency of such disclosure, and in withholding crucial results when making public presentations. They disclose results for feedback and credit and to attract collaborators. Particularly in formulaic fields, scientists disclose to attract new researchers to the field independent of collaboration and to deter others from working on their exact problem. A probability model shows that 70\% of field variation in disclosure is related to differences in respondent beliefs about norms, competition, and commercialization. Our results suggest new research directions—for example, do the problems addressed or the methods of scientific production themselves shape norms and competition? Are the levels we observe optimal or simply path-dependent? What is the interplay of norms, competition, and commercialization in disclosure and the progress of science?},
	number = {5},
	urldate = {2023-02-14},
	journal = {Science Advances},
	author = {Thursby, Jerry G. and Haeussler, Carolin and Thursby, Marie C. and Jiang, Lin},
	month = may,
	year = {2018},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eaar2133},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\BX8CRVWH\\Thursby et al. - 2018 - Prepublication disclosure of scientific results N.pdf:application/pdf},
}

@article{canetti_zero-knowledge_2023,
	title = {Zero-{Knowledge} {Mechanisms}},
	url = {https://arxiv.org/abs/2302.05590v1},
	doi = {10.48550/arXiv.2302.05590},
	abstract = {A powerful feature in mechanism design is the ability to irrevocably commit to the rules of a mechanism. Commitment is achieved by public declaration, which enables players to verify incentive properties in advance and the outcome in retrospect. However, public declaration can reveal superfluous information that the mechanism designer might prefer not to disclose, such as her target function or private costs. Avoiding this may be possible via a trusted mediator; however, the availability of a trusted mediator, especially if mechanism secrecy must be maintained for years, might be unrealistic. We propose a new approach to commitment, and show how to commit to, and run, any given mechanism without disclosing it, while enabling the verification of incentive properties and the outcome -- all without the need for any mediators. Our framework is based on zero-knowledge proofs -- a cornerstone of modern cryptographic theory. Applications include non-mediated bargaining with hidden yet binding offers.},
	language = {en},
	urldate = {2023-02-15},
	author = {Canetti, Ran and Fiat, Amos and Gonczarowski, Yannai A.},
	month = feb,
	year = {2023},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\KYSJ43G8\\Canetti et al. - 2023 - Zero-Knowledge Mechanisms.pdf:application/pdf},
}

@article{knochelmann_open_2019,
	title = {Open {Science} in the {Humanities}, or: {Open} {Humanities}?},
	volume = {7},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2304-6775},
	shorttitle = {Open {Science} in the {Humanities}, or},
	url = {https://www.mdpi.com/2304-6775/7/4/65},
	doi = {10.3390/publications7040065},
	abstract = {Open science refers to both the practices and norms of more open and transparent communication and research in scientific disciplines and the discourse on these practices and norms. There is no such discourse dedicated to the humanities. Though the humanities appear to be less coherent as a cluster of scholarship than the sciences are, they do share unique characteristics which lead to distinct scholarly communication and research practices. A discourse on making these practices more open and transparent needs to take account of these characteristics. The prevalent scientific perspective in the discourse on more open practices does not do so, which confirms that the discourse’s name, open science, indeed excludes the humanities so that talking about open science in the humanities is incoherent. In this paper, I argue that there needs to be a dedicated discourse for more open research and communication practices in the humanities, one that integrates several elements currently fragmented into smaller, unconnected discourses (such as on open access, preprints, or peer review). I discuss three essential elements of open science—preprints, open peer review practices, and liberal open licences—in the realm of the humanities to demonstrate why a dedicated open humanities discourse is required.},
	language = {en},
	number = {4},
	urldate = {2023-02-20},
	journal = {Publications},
	author = {Knöchelmann, Marcel},
	month = dec,
	year = {2019},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {digital humanities, open humanities, open science, peer review, scholarly communication},
	pages = {65},
	file = {Full Text PDF:C\:\\Users\\aluga\\Zotero\\storage\\DUWAFPUR\\Knöchelmann - 2019 - Open Science in the Humanities, or Open Humanitie.pdf:application/pdf},
}

@misc{parinov_end_2016,
	title = {End of {Publication}? {Open} access and a new scholarly communication technology},
	shorttitle = {End of {Publication}?},
	url = {http://arxiv.org/abs/1608.05505},
	doi = {10.48550/arXiv.1608.05505},
	abstract = {At this time, developers of research information systems are experimenting with new tools for research outputs usage that can expand the open access to research. These tools allow researchers to record research as annotations, nanopublications or other micro research outputs and link them by scientific relationships. If these micro outputs and relationships are shared by their creators publicly, these actions can initiate direct scholarly communication between the creators and the authors of the used research outputs. Such direct communication takes place while researchers are manipulating and organising their research results, e.g. as manuscripts. Thus, researchers come to communication before the manuscripts become traditional publications. In this paper, we discuss how this pre-publication communication can affect existing research practice. It can have important consequences for the research community like the end of publication as a communication instrument, the higher level of transparency in research, changes for the Open Access movement, academic publishers, peer-reviewing and research assessment systems. We analyse a background that exists in the economics discipline for experiments with the pre-publication communication. We propose a set of experiments with already existed and new tools, which can help with exploring the end of publication possible impacts on the research community.},
	urldate = {2023-02-20},
	publisher = {arXiv},
	author = {Parinov, Sergey and Antonova, Victoria},
	month = aug,
	year = {2016},
	note = {arXiv:1608.05505 [cs]},
	keywords = {68U35, Computer Science - Computers and Society, Computer Science - Digital Libraries, D.2.10, D.2.12, D.2.2, H.1.2, H.3.4, H.3.5, H.3.7, K.4},
	annote = {Comment: 8 pages, 3 figures},
	file = {arXiv Fulltext PDF:C\:\\Users\\aluga\\Zotero\\storage\\SGZ2F4LG\\Parinov and Antonova - 2016 - End of Publication Open access and a new scholarl.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\XATF7B65\\1608.html:text/html},
}

@article{shah_challenges_2022,
	title = {Challenges, experiments, and computational solutions in peer review},
	volume = {65},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3528086},
	doi = {10.1145/3528086},
	abstract = {Improving the peer review process in a scientific manner shows promise.},
	language = {en},
	number = {6},
	urldate = {2023-02-20},
	journal = {Communications of the ACM},
	author = {Shah, Nihar B.},
	month = jun,
	year = {2022},
	pages = {76--87},
	file = {Full Text:C\:\\Users\\aluga\\Zotero\\storage\\R69PDRMZ\\Shah - 2022 - Challenges, experiments, and computational solutio.pdf:application/pdf},
}

@article{soergel_open_nodate,
	title = {Open {Scholarship} and {Peer} {Review}: a {Time} for {Experimentation}},
	abstract = {Across a wide range of scientiﬁc communities, there is growing interest in accelerating and improving the progress of scholarship by making the peer review process more open. Multiple new publication venues and services are arising, especially in the life sciences, but each represents a single point in the multidimensional landscape of paper and review access for authors, reviewers and readers.},
	language = {en},
	author = {Soergel, David and Saunders, Adam and McCallum, Andrew},
	file = {Soergel et al. - Open Scholarship and Peer Review a Time for Exper.pdf:C\:\\Users\\aluga\\Zotero\\storage\\X236X33A\\Soergel et al. - Open Scholarship and Peer Review a Time for Exper.pdf:application/pdf},
}

@misc{noauthor_role_nodate,
	title = {The {Role} of {Peer} {Review} for {Scholarly} {Journals} in the {Information} {Age}},
	url = {https://doi.org/10.3998/3336451.0010.107},
	abstract = {This article discusses recent innovations in how peer review is conducted in light of the various functions journals fulfill in scholarly communities.},
	language = {en},
	urldate = {2023-02-20},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\FDXGLZWS\\3336451.0010.html:text/html},
}

@book{soergel_open_2013,
	title = {Open {Scholarship} and {Peer} {Review}: a {Time} for {Experimentation}},
	shorttitle = {Open {Scholarship} and {Peer} {Review}},
	abstract = {Across a wide range of scientific communities, there is growing interest in accelerating and improving the progress of scholarship by making the peer review process more open. Multiple new publication venues and services are arising, especially in the life sciences, but each represents a single point in the multi-dimensional landscape of paper and review access for authors, reviewers and readers. In this paper, we introduce a vocabulary for describing the landscape of choices regarding open access, formal peer review, and public commentary. We argue that the opportunities and pitfalls of open peer review warrant experimentation in these dimensions, and discuss desiderata of a flexible system. We close by describing OpenReview.net, our web-based system in which a small set of flexible primitives support a wide variety of peer review choices, and which provided the reviewing infrastructure for the 2013 International Conference on Learning Representations. We intend this software to enable trials of different policies, in order to help scientific communities explore open scholarship while addressing legitimate concerns regarding confidentiality , attribution, and bias.},
	author = {Soergel, David and Saunders, Adam and Mccallum, Andrew},
	month = jun,
	year = {2013},
}

@misc{noauthor_role_nodate-1,
	title = {The {Role} of {Peer} {Review} for {Scholarly} {Journals} in the {Information} {Age}},
	url = {https://doi.org/10.3998/3336451.0010.107},
	abstract = {This article discusses recent innovations in how peer review is conducted in light of the various functions journals fulfill in scholarly communities.},
	language = {en},
	urldate = {2023-02-20},
	file = {Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\GBUWCMJ8\\3336451.0010.html:text/html},
}

@misc{srinivasan_auctions_2021,
	title = {Auctions and {Prediction} {Markets} for {Scientific} {Peer} {Review}},
	url = {http://arxiv.org/abs/2109.00923},
	doi = {10.48550/arXiv.2109.00923},
	abstract = {Peer reviewed publications are considered the gold standard in certifying and disseminating ideas that a research community considers valuable. However, we identify two major drawbacks of the current system: (1) the overwhelming demand for reviewers due to a large volume of submissions, and (2) the lack of incentives for reviewers to participate and expend the necessary effort to provide high-quality reviews. In this work, we adopt a mechanism-design approach to propose improvements to the peer review process. We present a two-stage mechanism which ties together the paper submission and review process, simultaneously incentivizing high-quality reviews and high-quality submissions. In the first stage, authors participate in a VCG auction for review slots by submitting their papers along with a bid that represents their expected value for having their paper reviewed. For the second stage, we propose a novel prediction market-style mechanism (H-DIPP) building on recent work in the information elicitation literature, which incentivizes participating reviewers to provide honest and effortful reviews. The revenue raised by the Stage I auction is used in Stage II to pay reviewers based on the quality of their reviews.},
	urldate = {2023-02-21},
	publisher = {arXiv},
	author = {Srinivasan, Siddarth and Morgenstern, Jamie},
	month = aug,
	year = {2021},
	note = {arXiv:2109.00923 [cs, econ, q-fin]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning, Economics - General Economics},
	file = {arXiv Fulltext PDF:C\:\\Users\\aluga\\Zotero\\storage\\CTMEJZVY\\Srinivasan and Morgenstern - 2021 - Auctions and Prediction Markets for Scientific Pee.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\aluga\\Zotero\\storage\\6VAXK4FS\\2109.html:text/html},
}
