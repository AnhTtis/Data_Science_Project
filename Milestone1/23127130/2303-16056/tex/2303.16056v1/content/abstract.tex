The \gls{bss2} system implements physical models of neurons as well as synapses and aims for an energy-efficient and fast emulation of biological neurons.
When replicating neuroscientific experiment results, a major challenge is finding suitable model parameters.
This study investigates the suitability of the \gls{snpe} algorithm for parameterizing a multi-compartmental neuron model emulated on the \gls{bss2} analog neuromorphic hardware system.
In contrast to other optimization methods such as genetic algorithms or stochastic searches, the \gls{snpe} algorithms belongs to the class of \gls{abc} methods and estimates the posterior distribution of the model parameters; access to the posterior allows classifying the confidence in parameter estimations and unveiling correlation between model parameters.
In previous applications, the \gls{snpe} algorithm showed a higher computational efficiency than traditional \gls{abc} methods.

For our multi-compartmental model, we show that the approximated posterior is in agreement with experimental observations and that the identified correlation between parameters is in agreement with theoretical expectations.
Furthermore, we show that the algorithm can deal with high-dimensional observations and parameter spaces.

These results suggest that the \gls{snpe} algorithm is a promising approach for automating the parameterization of complex models, especially when dealing with characteristic properties of analog neuromorphic substrates, such as trial-to-trial variations or limited parameter ranges.
