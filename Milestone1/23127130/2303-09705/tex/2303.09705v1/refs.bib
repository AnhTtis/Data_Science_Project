@book{CART,
  title={Classification and Regression Trees},
  author={Breiman, Leo and Friedman, Jerome and Stone, Charles J and Olshen, Richard A},
  year={1984},
  publisher={CRC press}
}

@article{suko_alg,
  title={Prediction Algorithm for Decision Tree Model},
  author={Tota Suko and Ryo Nomura and Toshiyasu Matsushima and Shigeichi Hirasawa},
  journal={IEICE technical report. Theoretical foundations of Computing},
  year={2003},
  volume={103},
  pages={93-98},
  note={(in Japanese)}
}

@Article{MTRF,
AUTHOR = {Dobashi, Nao and Saito, Shota and Nakahara, Yuta and Matsushima, Toshiyasu},
TITLE = {Meta-Tree Random Forest: Probabilistic Data-Generative Model and {Bayes} Optimal Prediction},
JOURNAL = {Entropy},
VOLUME = {23},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {768},
URL = {https://www.mdpi.com/1099-4300/23/6/768},
ISSN = {1099-4300},
ABSTRACT = {This paper deals with a prediction problem of a new targeting variable corresponding to a new explanatory variable given a training dataset. To predict the targeting variable, we consider a model tree, which is used to represent a conditional probabilistic structure of a targeting variable given an explanatory variable, and discuss statistical optimality for prediction based on the Bayes decision theory. The optimal prediction based on the Bayes decision theory is given by weighting all the model trees in the model tree candidate set, where the model tree candidate set is a set of model trees in which the true model tree is assumed to be included. Because the number of all the model trees in the model tree candidate set increases exponentially according to the maximum depth of model trees, the computational complexity of weighting them increases exponentially according to the maximum depth of model trees. To solve this issue, we introduce a notion of meta-tree and propose an algorithm called MTRF (Meta-Tree Random Forest) by using multiple meta-trees. Theoretical and experimental analyses of the MTRF show the superiority of the MTRF to previous decision tree-based algorithms.},
DOI = {10.3390/e23060768}
}

@INPROCEEDINGS{CT,
  author={Matsushima, Toshiyasu and Hirasawa, Shigeich},
  booktitle={2009 IEEE International Symposium on Information Theory}, 
  title={Reducing the space complexity of a Bayes coding algorithm using an expanded context tree}, 
  year={2009},
  volume={},
  number={},
  pages={719-723},
  doi={10.1109/ISIT.2009.5205677}}

@misc{bayesml,
  author = {Nakahara, Yuta and Ichijo, Naoki and Shimada, Koshi and
            Iikubo, Yuji and Saito, Shota and Kazama, Koki and
            Matsushima, Toshiyasu and {BayesML Developers}},
  title = {{BayesML} 0.2.4},
  howpublished = {\url{https://github.com/yuta-nakahara/BayesML}},
  year = {2023}
}

@Article{full_rooted_trees,
AUTHOR = {Nakahara, Yuta and Saito, Shota and Kamatsuka, Akira and Matsushima, Toshiyasu},
TITLE = {Probability Distribution on Full Rooted Trees},
JOURNAL = {Entropy},
VOLUME = {24},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {328},
URL = {https://www.mdpi.com/1099-4300/24/3/328},
ISSN = {1099-4300},
ABSTRACT = {The recursive and hierarchical structure of full rooted trees is applicable to statistical models in various fields, such as data compression, image processing, and machine learning. In most of these cases, the full rooted tree is not a random variable; as such, model selection to avoid overfitting is problematic. One method to solve this problem is to assume a prior distribution on the full rooted trees. This enables the optimal model selection based on Bayes decision theory. For example, by assigning a low prior probability to a complex model, the maximum a posteriori estimator prevents the selection of the complex one. Furthermore, we can average all the models weighted by their posteriors. In this paper, we propose a probability distribution on a set of full rooted trees. Its parametric representation is suitable for calculating the properties of our distribution using recursive functions, such as the mode, expectation, and posterior distribution. Although such distributions have been proposed in previous studies, they are only applicable to specific applications. Therefore, we extract their mathematically essential components and derive new generalized methods to calculate the expectation, posterior distribution, etc.},
DOI = {10.3390/e24030328}
}