\section{Conclusion}
\label{Sec:Conclusion}

We have proposed a deep learning framework that creates 2D talking heads from the input audio. Besides an audio stream and an image, our framework utilizes a set of reference frames to learn the character style. Our proposed method can successfully extract and transfer the reference style to the output 2D talking head animation. In practice, our method successfully creates photo-realistic and high fidelity animations. Furthermore, apart from the normal talking style, our method can also work well with challenging singing styles such as \texttt{ballad}, \texttt{opera}, and \texttt{rap}, which requires an adaptable translation module to generate detailed and accurate animations. The intensive experiments show that our talking head results outperform other recent state-of-the-art approaches qualitatively and quantitatively. Our framework can be used in different applications such as dubbing, video conferencing, and virtual avatar assistant.

