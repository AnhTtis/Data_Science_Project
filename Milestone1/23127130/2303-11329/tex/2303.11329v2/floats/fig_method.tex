\begin{figure*}[t]
    \centering
    \upvspacefig
    \includegraphics[width=\linewidth]{figs/method.pdf}

    \begin{flushleft}
        \vspace{-4mm}
        \hspace{30mm} (a) Cross-view audio prediction \hspace{44.5mm} (b) Sound localization from motion
         \vspace{-3mm}
    \end{flushleft}    
    \caption{{\bf Method overview.} (a) We learn a feature representation by predicting how changes in images lead to changes in sound in a cross-view binauralization pretext task. We convert mono sound to binaural sound at a target viewpoint, after conditioning the model on observations from a source viewpoint. (b) We use the representation to jointly solve two pose estimation tasks: visual rotation estimation and binaural sound localization. We train the visual rotation angle, $\phi_{s,t}$, to be consistent with the difference in predicted sound angles $\theta_s$ and $\theta_t$. } 
    \label{fig:method}
\end{figure*}