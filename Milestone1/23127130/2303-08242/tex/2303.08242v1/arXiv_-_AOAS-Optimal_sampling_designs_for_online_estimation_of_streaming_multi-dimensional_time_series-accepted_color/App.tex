\documentclass[aoas]{imsart}

%% Packages
\RequirePackage{amsthm,amsmath,amsfonts,amssymb}
\RequirePackage[authoryear]{natbib}
% \RequirePackage[colorlinks,citecolor=blue,urlcolor=blue]{hyperref}
\RequirePackage{graphicx}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{natbib}
% \usepackage{url} % not crucial - just used below for the URL 
%\usepackage[cmbold]{mathtime}
\usepackage{bm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[ruled]{algorithm2e}
\usepackage{xcolor}
\usepackage{epstopdf}
\usepackage{amsthm}
\usepackage[colorlinks=true, citecolor=blue,urlcolor=blue]{hyperref}
% \usepackage{caption}
% \usepackage{subcaption}
\usepackage{xr}
\makeatletter

\newcommand*{\addFileDependency}[1]{% argument=file name and extension
\typeout{(#1)}% latexmk will find this if $recorder=0
% however, in that case, it will ignore #1 if it is a .aux or 
% .pdf file etc and it exists! If it doesn't exist, it will appear 
% in the list of dependents regardless)
%
% Write the following if you want it to appear in \listfiles 
% --- although not really necessary and latexmk doesn't use this
%
\@addtofilelist{#1}
%
% latexmk will find this message if #1 doesn't exist (yet)
\IfFileExists{#1}{}{\typeout{No file #1.}}
}\makeatother

\newcommand*{\myexternaldocument}[1]{%
\externaldocument{#1}%
\addFileDependency{#1.tex}%
\addFileDependency{#1.aux}%
}
%------------End of helper code--------------

% put all the external documents here!
\myexternaldocument{main_AoAS}
% \externaldocument{main_AoAS}
% \usepackage[a4paper]{geometry}


\startlocaldefs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Uncomment next line to change            %%
%% the type of equation numbering           %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\numberwithin{equation}{section}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% For Axiom, Claim, Corollary, Hypothesis, %%
%% Lemma, Theorem, Proposition              %%
%% use \theoremstyle{plain}                 %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{axiom}{Axiom}
\newtheorem{claim}[axiom]{Claim}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% For Assumption, Definition, Example,     %%
%% Notation, Property, Remark, Fact         %%
%% use \theoremstyle{remark}                %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{remark}
\newtheorem{definition}[theorem]{Definition}
\newtheorem*{example}{Example}
\newtheorem*{fact}{Fact}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Please put your definitions here:        %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \newtheorem{theorem}{Theorem}[section]
% \newtheorem{Thm}{Theorem}[section]
% \newtheorem{lemma}[theorem]{Lemma}
\newtheorem{Con}[theorem]{Conjecture}
\newtheorem{Cor}[theorem]{Corollary}
\newtheorem{Eg}[theorem]{Example}
\newtheorem*{Rem}{Remark}
% \newtheorem{definition}[theorem]{Definition}

\newcommand{\red}{\textcolor{red}}
\newcommand{\cl}{\mathcal}
\newcommand{ \tr}{\mathrm{tr}}
 \newcommand{\ec}{\wh{\mbf{c}}}
\newcommand{\wh}{\widehat}
\newcommand{\wt}{\widetilde}
\DeclareMathOperator{\vect}{vec}
\newcommand{\mbf}{\boldsymbol}
\newcommand{\bb}{\mathbb}
\newcommand{\mrm}{\mathrm}
\newcommand{\E}{{E}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Var}{\mathrm{var}}
\newcommand{\EqD}{\overset{d}{=}}
\newcommand{\ConvP}{\overset{P}{\rightarrow}}
\newcommand{\ConvD}{\overset{d}{\rightarrow}}
\newcommand{\ConvFDD}{\overset{f.d.d.}{\longrightarrow}}

\newcommand{\qcr}{\fontfamily{qcr}\selectfont}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\renewcommand{\theequation}{S.\arabic{equation}}
\endlocaldefs


%%% User-defined macros should be placed here, but keep them to a minimum.
% \usepackage[margin=1in]{geometry}


% %\pdfminorversion=4
% % NOTE: To produce blinded version, replace "0" with "1" below.
% \newcommand{\blind}{1}

% % DON'T change margins - should be 1 inch all around.
% \addtolength{\oddsidemargin}{-.5in}%
% \addtolength{\evensidemargin}{-.5in}%
% \addtolength{\textwidth}{1in}%
% \addtolength{\textheight}{-.3in}%
% \addtolength{\topmargin}{-.8in}%
% \title[Optimal Sampling Designs]{Optimal Sampling Designs for Online Estimation of Streaming Multi-dimensional Time Series}
% \author{Rui Xie}
% \address{University of Central Florida, Orlando, FL 32826 USA}

% \author{Shuyang Bai}
% \coaddress{Shuyang Bai, Department of Statistics, University of Georgia, Athens, GA 30602 USA. E-mail:{bsy9142@uga.edu}}

% % \address{University of Central Florida, Orlando, FL 32826 USA}
% % \email{bsy9142@uga.edu}

% \author[Rui Xie {\it et al.}]{Ping Ma  }
% \address{University of Georgia, Athens, GA 30602 USA}

\begin{document}

\begin{frontmatter}
\title{Supplement to Optimal Sampling Designs for   Multi-dimensional Streaming Time Series with Application to Power Grid Sensor Data}
%\title{A sample article title with some additional note\thanksref{t1}}
\runtitle{Supplement to Optimal Sampling Designs}
%\thankstext{T1}{A sample additional note to the title.}

\begin{aug}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Only one address is permitted per author. %%
%% Only division, organization and e-mail is %%
%% included in the address.                  %%
%% Additional information can be included in %%
%% the Acknowledgments section if necessary. %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author[A]{\fnms{Rui} \snm{Xie}\ead[label=e1]{rui.xie@ucf.edu}},
\author[B]{\fnms{Shuyang} \snm{Bai}\ead[label=e2,mark]{bsy9142@uga.edu}}
\and
\author[B]{\fnms{Ping} \snm{Ma}\ead[label=e3,mark]{pingma@uga.edu}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Addresses                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\address[A]{Department of Statistics and Data Science, University of Central Florida, Orlando, FL 32826 USA,
\printead{e1}}

\address[B]{Department of Statistics, University of Georgia, Athens, GA 30602 USA,
\printead{e2,e3}}
\end{aug}

\end{frontmatter}

 \pagenumbering{arabic} 
 \renewcommand*{\thepage}{S\arabic{page}}
% \appendix

% \appendixone
% \section{Appendix: proofs}\label{Sec:Proofs}
% \begin{supplement}
\section{Proof of Theorem \ref{Thm:asymp_normality}}
\begin{proof}
	Let $\mbf{z}_t=1\{U_t\le s(\mbf{x}_t)\}\mbf{x}_t$.
	By   equation (\ref{eq:stat sys}), we have
	\begin{equation}\label{eq:root}
		\sqrt{n}(\wh{B}_{n,I} -B)= \left(\frac{1}{n}\sum_{t=1}^n  \mbf{z}_t  \mbf{z}_t'\right)^{-1} \left(\frac{1}{\sqrt{n}}\sum_{t=1}^n \mbf{z}_t \mbf{e}_t'  \right),
	\end{equation}
	which is understood as zero matrix (or any arbitrary fixed matrix) if the invertibility fails.   Using \eqref{eq:e_t cov}, we have
	\begin{equation}\label{eq:cov}
		\E[ \vect(\mbf{z}_t\mbf{e}_t')\vect(\mbf{z}_t\mbf{e}_t')']= \E[ \E(\vect(\mbf{z}_t\mbf{e}_t')\vect(\mbf{z}_t\mbf{e}_t')' |\cl{F}_t]=  \Omega\otimes \Gamma(s).
	\end{equation}
	By   the ergodic theorem \cite[Theorem 10.6]{kallenberg:2002:foundations}   applied to each entry, one has almost surely as $n\rightarrow\infty$ that
	\begin{equation}\label{eq:den}
		\frac{1}{n}\sum_{i=1}^n  \mbf{z}_t  \mbf{z}_t' \rightarrow  \Gamma(s).
	\end{equation}
	For any column vector  $\mbf{a}\in \mathbb{R}^{Kp}$, the linear combination   $\mbf{a}' \vect( \mbf{z}_t\mbf{e}_t')$ forms a stationary martingale difference in $t$ with respect to the filtration $\cl{F}_t$  in view of \eqref{eq:md} and the joint stationarity of $(\mbf{x}_t;\mbf{e}_t)$. By (\ref{eq:cov}), \eqref{eq:den} and the martingale central limit theorem \cite[Theorem 35.12]{billingsley:1995:probability}, as $n\rightarrow\infty$,
	\[ 
	\frac{1}{\sqrt{n}}\sum_{t=1}^n \mbf{a}' \vect( \mbf{z}_t\mbf{e}_t') \ConvD N(0,   \mbf{a}' \Omega\otimes \Gamma(s) \mbf{a}),
	\]
	where  the Lindeberg   condition \cite[Eq.(36.36)]{billingsley:1995:probability} follows from  \eqref{eq:e_t cov} and stationarity (see also the proof of Theorem \ref{Thm:asymp_aux} below).
	In view of the Cram\'er-Wold device, we have thus shown that as $n\rightarrow\infty$,
	\begin{equation}\label{eq:num}
		\frac{1}{\sqrt{n}}\sum_{i=1}^n  \vect( \mbf{z}_t\mbf{e}_t') \ConvD N(\mbf{0}, \Omega\otimes \Gamma(s)).
	\end{equation}
	Next, notice that the  invertible matrices of a fixed size form an open subset  under the product topology. Hence  $\frac{1}{n}\sum_{i=1}^n  \mbf{z}_t  \mbf{z}_t'$ is invertible with probability tending to one as $n\rightarrow\infty$.
	Combining \eqref{eq:N/n}, (\ref{eq:root}),  (\ref{eq:den}), (\ref{eq:num}) and Slutsky's lemma yields the conclusion.
\end{proof}

\section{Proof of Theorem \ref{Thm:D-opt relax}}
\begin{proof}
	Let $\phi_\Sigma$ denote the distribution of $\mbf{x}_t\sim EC_p(\mbf{0},\Sigma,\nu)$ and let $\phi_I$ denote the distribution of $ EC_p(\mbf{0},I,\nu)$ where $I$ is the identity matrix.   By the change of variable $\mbf{z}=\Sigma^{-1/2} \mbf{x}$,
	\begin{equation}\label{eq:Gamma(s) simplify}
		\Gamma(s)=\int s(\mbf{x}) \mbf{x}  \mbf{x}' \phi_{\Sigma}(d\mbf{x}) =\Sigma^{1/2} \left(\int  s(  \Sigma^{1/2} \mbf{z}) \mbf{z}  \mbf{z}' \phi_{I}(  d\mbf{z})\right) \Sigma^{1/2}
	\end{equation}
	and 
	\[
	\E [ s(\mbf{x}_t)]=\int s( \Sigma^{1/2} \mbf{z}) \phi_I(d\mbf{z}).
	\]
	By the substitution $\wt{s}(\mbf{z})=s( \Sigma^{1/2} \mbf{z})-q_0$, in view of~\eqref{eq:Gamma(s) simplify}, the optimization problem~\eqref{eq:relax LSS opt} is equivalent to maximizing
	\begin{equation}\label{eq:opt det}
		\det\left(  \int  \wt s( \mbf{z}) \mbf{z}  \mbf{z}' \phi_{I}( d\mbf{z})\right) 
	\end{equation}
	under the constraint
	\begin{equation}\label{eq:rate constraint}
		\int \wt s( \mbf{z}) \phi_I(d\mbf{z})=q-q_0,\quad \wt s( \mbf{z})\in [0,1-q_0].
	\end{equation}
	In view of an arithmetic-geometric mean inequality for the eigenvalues, we have
	\begin{align}
		p\left(\det\left(  \int  \wt s( \mbf{z}) \mbf{z}  \mbf{z}' \phi_{I}(d\mbf{z}) \right)\right)^{1/p}&\le \tr\left(  \int  \wt s( \mbf{z}) \mbf{z}  \mbf{z}' \phi_{I}(d\mbf{z})  \right)\label{eq:art geo ineq} 
		=\int \wt{s}(\mbf{z}) \|\mbf{z}\|^2 \phi_I(d\mbf{z}).
	\end{align}
	Now we consider the maximization of the trace bound in \eqref{eq:art geo ineq}
	under the constraint  \eqref{eq:rate constraint}.
	We claim that this alternative problem  has   solution $\wt{s}= (1-q_0) 1_{D_r}$, where  $D_r=\{\mbf{x}\in \bb{R}^p:\ \|x\|>r\}$ and $r$ is as in \eqref{eq:threshold quantile relax}.
	If this is true, then by the isotropy of such $\wt{s}$ and $\phi_I$,  the matrix $\int  \wt s( \mbf{z}) \mbf{z}  \mbf{z}' \phi_{I}(d\mbf{z})$ is a nonzero multiple of the identity matrix, and hence  
	inequality in \eqref{eq:art geo ineq} is  an equality in this case.
	
	Indeed, suppose $s^*:\bb{R}^p\rightarrow [0,1-q_0]$ is another measurable function  satisfying the constraint \eqref{eq:rate constraint}. Let 
	\[A_1=\{\mbf{z}:\ \wt{s}(\mbf{z})>s^*(\mbf{z})\}=\{\mbf{z}:\ s^*(\mbf{z})<1-q_0,\ \|\mbf{z}\|> r\}
	\]and \[A_2=\{\mbf{z}:\ \wt{s}(\mbf{z})<s^*(\mbf{z})\}=\{\mbf{z}: \  s^*(\mbf{z})>0,\ \|\mbf{z}\|\le r\}.\]  Then the constraint \eqref{eq:rate constraint} implies 
	\begin{align}
		0&=\int [\wt{s}(\mbf{z})-s^*(\mbf{z}) ]   \phi_I(d\mbf{z}) 
		=\int_{A_1}[1-q_0-s^*(\mbf{z})]\phi_I(d\mbf{z}) -
		\int_{A_2} s^*(\mbf{z}) \phi_I(d\mbf{z}) .\label{eq:constraint imply}
	\end{align}
	On the other hand,
	\begin{align*}
		&\tr\left(  \int  \wt s( \mbf{z}) \mbf{z}  \mbf{z}' \phi_{I}(d\mbf{z})  \right)-\tr\left(  \int  s^*( \mbf{z}) \mbf{z}  \mbf{z}' \phi_{I}(d\mbf{z})\right) \\ =
		&\int [\wt{s}(\mbf z)-s^*(\mbf z)] \|\mbf{z}\|^2 \phi_I(d\mbf{z})
		\\=&\int_{A_1}[1-q_0-s^*(\mbf{z})]\|\mbf{z}\|^2\phi_I(d\mbf{z})-
		\int_{A_2} s^*(\mbf{z}) \|\mbf{z}\|^2\phi_I(d\mbf{z}) 
		\\\ge & r^2\left(\int_{A_1}[1-q_0-s^*(\mbf{z})] \phi_I(d\mbf{z})-
		\int_{A_2} s^*(\mbf{z}) \phi_I(d\mbf{z}) \right)=0,
	\end{align*}
	where in the   equality we  have used \eqref{eq:constraint imply}.  This   inequality is strict unless both $\phi_I(A_1)$ and $\phi_I(A_2)$ are zeros, which implies the uniqueness claimed in the theorem.
\end{proof}





\section{Proof of Theorem \ref{Thm:asymp_aux}}
\begin{proof}
	
	
	Write
	\[
	\sqrt{n}(\wh{B}_{n,s} -B)=\left( \frac{\sum_{t=1}^n  \wt{\mbf{u}}_t   \wt{\mbf{u}}_t'}{n}    \right)^{-1}  n^{-1/2} \left( \sum_{t=1}^n \wt{\mbf{u}}_t ( \wt{\mbf{y}}_t'  -\wt{\mbf{x}}_t' B )   \right)=\wt{A}_n^{-1} \wt{D}_n,
	\]
	where 
	\begin{equation}\label{eq:A tilde D tilde}
		\wt{A}_n:=\frac{1}{n} \sum_{t=1}^n  \wt{\mbf{u}}_t   \wt{\mbf{u}}_t',\quad \wt{D}_n= n^{-1/2} \left( \sum_{t=1}^n \wt{\mbf{u}}_t ( \wt{\mbf{y}}_t'  -\wt{\mbf{x}}_t' B )   \right).
	\end{equation}
	We shall assume that the invertibility of $\wt{A}_n$ holds always without loss of generality, since below we shall show that $\wt{A}_n$ converges in probability to a non-singular matrix (see the proof of Theorem \ref{Thm:asymp_normality}).
	
	\noindent \emph{Step 1}.
	In this step we show that as $n\rightarrow\infty$,
	\begin{equation}\label{eq:LLN aux}
		\wt{A}_n:=\frac{1}{n} \sum_{t=1}^n  \wt{\mbf{u}}_t   \wt{\mbf{u}}_t'     \ConvP  \Gamma (s),
	\end{equation}
	where 
	\[\wt{\mbf{u}}_t = \wt{\mbf{x}}_t    1_{\{U_t\le   \wh{s}_t \}}=(\mbf{x}_t-\wh{\mbf{\mu}}_{t,X})    1_{\{U_t\le   \wh{s}_t \}}
	\]
	and $\Gamma(s)$ is as in \eqref{eq:Gamma(s) center}.
	Let 
	\[\mbf{u}_t=(\mbf{x}_t-\mbf{\mu}_X)1_{\{U_t\le   s(\mbf{x}_t-\mbf{\mu}_X) \}}\] and set 
	\begin{equation}
		A_n=\frac{1}{n} \sum_{t=1}^n  \mbf{u}_t    \mbf{u}_t',
	\end{equation}
	Since $(\mbf{u}_t  )$ is stationary and ergodic, by the ergodic theorem, we have 
	\[
	A_n\ConvP \E [\mbf{u}_1 \mbf{u}_1']= \Gamma(s)
	\] as $n\rightarrow\infty$. Hence it is enough to
	\begin{equation*} 
		\E \|A_n-\wt{A}_n\|\rightarrow 0
	\end{equation*}
	as $n\rightarrow\infty$, for which  by a triangular inequality it  suffices to show that as $t\rightarrow\infty$.
	\begin{align}\label{eq:u u tilde quad form close}
		\E \| \mbf{u}_t    \mbf{u}_t'     -  \wt{\mbf{u}}_t   \wt{\mbf{u}}_t'   \|\le    \E (\| \mbf{u}_t\| +\|\wt{\mbf{u}}_{t}\|)     \|\mbf{u}_t -  \wt{\mbf{u}}_t     \| \rightarrow 0
	\end{align}
	Note that 
	\begin{align}\label{eq:tilde u t bound}
		\|\wt{\mbf{u}}_t\|\le    1_{\{U_t\le \wh{s}_t\}}\left( \|\mbf{x}_t-\mbf{\mu}_X\|+\|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_X\|\right).
	\end{align}
	Hence  by triangular and Cauchy-Schwartz inequalities,
	\begin{align*} 
		\E \| \mbf{u}_t    \mbf{u}_t'     -  \wt{\mbf{u}}_t   \wt{\mbf{u}}_t'   \|&\le   \E\left[  (2\|\mbf{x}_t-\mbf{\mu}_X\|+  \|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_X\| )  \|\mbf{u}_t -  \wt{\mbf{u}}_t     \|\right]\notag\\&\le     \left(  2[\E \|\mbf{x}_t-\mbf{\mu}_X\|^2]^{1/2} +[\E \|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_X\|^2]^{1/2}\right) (\E \|\mbf{u}_t -  \wt{\mbf{u}}_t     \|^2)^{1/2}.
	\end{align*}
	With a triangular inequality, we have
	\begin{align}\label{eq:u u tilde diff moment}
		(\E \|\mbf{u}_t -  \wt{\mbf{u}}_t     \|^2)^{1/2}\le  [\E  \|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_X \|^2]^{1/2}+ [\E    \|\mbf{x}_t-\mbf{\mu}_X \|^2 |1_{\{U_t\le   \wh{s}_t\}}-1_{\{U_t\le   s(\mbf{x}_t-\mbf{\mu}_X) \}}|]^{1/2}.
	\end{align}
	%Then by H\"older's inequality, 
	%\begin{align}\label{eq:holder}
	% &\E \left[   \|\mbf{x}_t-\mbf{\mu}_X \|^2 |1_{\{U_t\le   \wh{s}_t\}}-1_{\{U_t  \le   s(\mbf{x}_t-\mbf{\mu}_X) \}}|\right] \notag\\  \le & \left[\E    \|\mbf{x}_t-\mbf{\mu}_X \|^{2+\delta} \right]^{2/(2+\delta)}   \left[\E|1_{\{U_t\le   \wh{s}_t\}}-1_{\{U_t\le   s(\mbf{x}_t-\mbf{\mu}_X) \}}|\right]^{\delta/(2+\delta)},
	%\end{align}
	%where the first factor above is a finite constant by \eqref{eq:moment delta cond} and stationarity. 
	The assumption \eqref{eq:mu_X mean sq cons}, since $\alpha>2$, ensures that the first term   in \eqref{eq:u u tilde diff moment} tends to zero as $t\rightarrow\infty$. To show that this is also the case for the second term, note that by independence of $U_t$ from the other random variables, the assumption \eqref{eq:s consistent} and uniform integrability from boundedness, we have
	\begin{align} 
		\E|1_{\{U_t\le   \wh{s}_t\}}-1_{\{U_t\le   s(\mbf{x}_t-\mbf{\mu}_X) \}}| 
		&= \E |\wh{s}_t-s(\mbf{x}_t-\mbf{\mu}_X)   | \rightarrow 0\label{eq:bound sym dff U_t}.
	\end{align}
	So  in view of stationarity of $(\mbf{x}_t)$ we have $\|\mbf{x}_t-\mbf{\mu}_X \|^2|1_{\{U_t\le   \wh{s}_t\}}-1_{\{U_t\le   s(\mbf{x}_t-\mbf{\mu}_X) \}}| \ConvP 0$ as $t\rightarrow\infty$. Since
	\[
	\|\mbf{x}_t-\mbf{\mu}_X \|^2 |1_{\{U_t\le   \wh{s}_t\}}-1_{\{U_t\le   s(\mbf{x}_t-\mbf{\mu}_X) \}}|\le  \|\mbf{x}_t-\mbf{\mu}_X \|^2,
	\]
	we conclude by  stationarity and uniform integrability that the second term in \eqref{eq:u u tilde diff moment} also tends to zero as $t\rightarrow\infty$. Combining these we see that  \eqref{eq:u u tilde quad form close} holds  and hence so does    \eqref{eq:LLN aux}.
	\medskip 
	
	\noindent \emph{Step 2}.
	In this step, we  establish the asymptotic normality of a modified version of $\wt{D}_n$ in \eqref{eq:A tilde D tilde}, which is
	\begin{equation}\label{eq:D_n}
		D_n=n^{-1/2} \left( \sum_{t=1}^n  \wt{\mbf{u}_t} [  (\mbf{y}_t-\mbf{\mu}_Y)'  - (\mbf{x}_t-\mbf{\mu}_X)' B ]   \right)=n^{-1/2} \left( \sum_{t=1}^n  \wt{\mbf{u}}_t \mbf{e}_t'   \right).
	\end{equation}
	Note that  by \eqref{eq:u u tilde quad form close} we have
	$
	\E[\wt{\mbf{u}}_t \wt{\mbf{u}}_t' ]  \rightarrow \Gamma(s)
	$ as $t\rightarrow\infty$. Hence as with \eqref{eq:cov} we have \[E[ \vect(\wt{\mbf{u}}_t\mbf{e}_t')\vect(\wt{\mbf{u}}_t\mbf{e}_t')']\rightarrow \Omega\otimes \Gamma(s)\]
	as $t\rightarrow\infty$.  
	Similarly as in the proof of Theorem \ref{Thm:asymp_normality}, we can show using  Cram\'er-Wold device, \eqref{eq:LLN aux} and martingale central limit theorem   that as $n\rightarrow\infty$,
	\begin{equation}\label{eq:md clt aux}
		\vect(D_n)=\frac{1}{\sqrt{n}}\sum_{i=1}^n  \vect( \wt{\mbf{u}}_t\mbf{e}_t') \ConvD N(\mbf{0}, \Omega\otimes \Gamma(s)).
	\end{equation}
	In particular, to verify the Lindeberg  condition  \cite[Eq.(36.36)]{billingsley:1995:probability}, with the help of \eqref{eq:tilde u t bound} it suffices to show   for any $\epsilon>0$ that
	\begin{align}\label{eq:lindeberg}
		\frac{1}{n}\sum_{t=1}^n\E  \Big[  &(\|\mbf{x}_t-\mbf{\mu}_X\|^2+\|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_X\|^2)\|\mbf{e}_t\|^2 \times \notag  \\ &  \left( 1_{\{\|\mbf{x}_t-\mbf{\mu}_X\|\|\mbf{e}_t\|>n^{1/2}\epsilon\}}+ 1_{\{ \|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_X\|\|\mbf{e}_t\|>n^{1/2}\epsilon\}} \right)   \Big] \rightarrow 0
	\end{align}  
	as $n\rightarrow\infty$. To do so, we expand the expression above into three terms. The first term is  
	\[
	\frac{1}{n}\sum_{t=1}^n\E \left[\|\mbf{x}_t-\mbf{\mu}_X\|^2\|\|\mbf{e}_t\|^2 1_{\{  \|\mbf{x}_t-\mbf{\mu}_X\|\|\mbf{e}_t\|>n^{1/2}\epsilon\}}\right]=\E \left[\|\mbf{x}_1-\mbf{\mu}_X\|^2\|\|\mbf{e}_1\|^2 1_{\{  \|\mbf{x}_1-\mbf{\mu}_X\|\|\mbf{e}_1\|>n^{1/2}\epsilon\}}\right]
	\]
	by stationarity, which tends to zero as $n\rightarrow\infty$ by the dominated convergence theorem since by \eqref{eq:e_t cov},  
	\[
	E \left[ \|\mbf{x}_1-\mbf{\mu}_X\|^2\| \|\mbf{e}_1\|^2\right] = \E \left[ \|\mbf{x}_1-\mbf{\mu}_X\|^2 \E \left( \|\mbf{e}_1\|^2|\cl{F}_1\right)\right]=\E[\|\mbf{x}_1-\mbf{\mu}_X\|^2] \tr(\Omega)<\infty
	\] 
	The second term in the expansion of \eqref{eq:lindeberg} is
	\begin{align*}
		&\frac{1}{n}\sum_{t=1}^n\E \left[\|\mbf{x}_t-\mbf{\mu}_X\|^2\|\|\mbf{e}_t\|^2 1_{\{ \|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_X\|\|\mbf{e}_t\|>n^{1/2}\epsilon\}}\right]\\
		\le & \frac{1}{n}\sum_{t=1}^n\E \left[\|\mbf{x}_t-\mbf{\mu}_X\|^2\|\|\mbf{e}_t\|^2 1_{\{ \|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_X\|\|\mbf{e}_t\|>\epsilon\}}\right].
	\end{align*}
	To show this bound tends to zero as $n\rightarrow\infty$, it suffices to show that each $t$-term above tends to zero as $t\rightarrow\infty$. This follows from the fact that $\|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_X\|\ConvP 0$ as $t\rightarrow\infty$,    stationarity and uniform integrability. The third term in the expansion  of \eqref{eq:lindeberg} is
	\begin{align*}
		&\frac{1}{n}\sum_{t=1}^n\E \left[\|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_X\|^2\|\mbf{e}_t\|^2 \left(1_{\{  \|\mbf{x}_t-\mbf{\mu}_X\|\|\mbf{e}_t\|>n^{1/2}\epsilon\}}+1_{\{ \|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_X\|\|\mbf{e}_t\|>n^{1/2}\epsilon\}}  \right)\right]\\\le& \frac{2}{n}\sum_{t=1}^n\E\left[ \|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_X\|^2 \E \left( \|\mbf{e}_t\|^2 |\cl{F}_t\right)\right]= \frac{2\tr(\Omega)}{n}\sum_{t=1}^n\E  \|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_X\|^2   \rightarrow 0
	\end{align*}
	as $n\rightarrow\infty$,
	where we have applied \eqref{eq:e_t cov} and \eqref{eq:mu_X mean sq cons}.  
	
	\medskip
	\noindent \emph{Step 3}.
	In this step we shall control the difference between $\wt{D}_n$ in \eqref{eq:A tilde D tilde}  and $D_n$ in \eqref{eq:D_n}. In particular, we shall establish for some constant $c>0$ that 
	\begin{equation}\label{eq:D tilde D diff}
		\limsup_{n\rightarrow\infty }n^{-1/2}\sum_{t=1}^n \E \|\wt{D}_t-D_t\|\le c q^{1-2/\alpha}.
	\end{equation} Indeed,
	by the triangular inequality and \eqref{eq:tilde u t bound},
	\begin{align*}
		\|\wt{D}_n-D_n\|\le &  n^{-1/2}  \sum_{t=1}^n \|\wt{\mbf{u}}_t\| \left( \|B\|     \|\mbf{x}_t- \wt{\mbf{x}}_t\|+\|\mbf{y}_t- \wt{\mbf{y}}_t\|\right) \\\le&  n^{-1/2}     \sum_{t=1}^n 1_{\{U_t\le \wh{s}_t\}} ( \|\mbf{x}_t-\mbf{\mu}_X\|+\|\wh{\mbf{ \mu}}_{t,X}-\mbf{\mu}_X\|)  (\|B\| \|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_{X}\|+ \|\wh{\mbf{\mu}}_{t,Y}-\mbf{\mu}_{Y}\|  )\\
		=& n^{-1/2}\sum_{t=1}^n \left(E_t +F_t+G_t+H_t\right),
	\end{align*}
	where $E_t=1_{\{U_t\le \wh{s}_t\}} \|B\|  \|\mbf{x}_t-\mbf{\mu}_X\|  \|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_{X}\|$, $F_t=1_{\{U_t\le \wh{s}_t\}} \|B\|  \|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_{X}\|^2 $,  $G_t=1_{\{U_t\le \wh{s}_t\}} \|\mbf{x}_t-\mbf{\mu}_X\| \|\wh{\mbf{\mu}}_{t,Y}-\mbf{\mu}_{Y}\| $, $H_t= 1_{\{U_t\le \wh{s}_t\}}  \|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_{X}\| \|\wh{\mbf{\mu}}_{t,Y}-\mbf{\mu}_{Y}\|$.
	Note that by the generalized H\"older inequality,   and integrating out the randomness of $U_t$,
	\begin{align*}
		\E [E_t] \le \|B\|    \E[ \wh{s}_t]^{1-2/\alpha}   \E[ \|\mbf{x}_t-\mbf{\mu}_X\|^\alpha]^{1/\alpha}  \E[\|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_{X}\|^\alpha ]^{1/\alpha}.
	\end{align*}
	By the assumption \eqref{eq:s consistent},   uniform integrability and stationarity, we deduce that
	\[
	\E[  \wh{s}_t   ]\rightarrow  \E[   s(\mbf{x}_1-\mbf{\mu}_X)]=q
	\]
	as $t\rightarrow\infty$. Below  $c>0$ denotes a constant whose value may change from line to line and does not depend on $n$, $s$ or $q$. Then using   \eqref{eq:alpha moment}, \eqref{eq:mu_X mean sq cons} and the fact $\sum_{t=1}^n t^{-1/2}\le c n^{1/2}$, one can deduce that
	\begin{align*}
		\limsup_{n\rightarrow\infty }n^{-1/2}\sum_{t=1}^n \E [E_t] \le   c q^{1-2/\alpha}
	\end{align*}
	Similarly one has
	\begin{align*}
		\limsup_{n\rightarrow\infty }n^{-1/2}\sum_{t=1}^n \E [G_t] \le c q^{1-2/\alpha}. 
	\end{align*}
	On the other hand, 
	\[
	\E [F_t] \le \|B\| [\E\|\wh{\mbf{\mu}}_{t,X}-\mbf{\mu}_{X}\|^\alpha]^{2/\alpha}\le c t^{-1}
	\]
	and hence
	\[
	\limsup_{n\rightarrow\infty }n^{-1/2}\sum_{t=1}^n \E [F_t]=0.
	\]
	Similarly  
	\[
	\limsup_{n\rightarrow\infty }n^{-1/2}\sum_{t=1}^n \E [H_t]=0.
	\]
	Therefore, we conclude \eqref{eq:D tilde D diff}.
	
	
	\medskip
	\noindent \emph{Step 4}. Now we are ready to finish the proof.
	Let
	\[M_n=(N/n)^{1/2} \wt{A}_n^{-1}D_n,\] and set \[R_n=(N/n)^{1/2}\wt{A}_n^{-1} (\wt{D}_n-D_n).\] Then \eqref{eq:asymp norm lev aux} readily follows from \eqref{eq:N/n}, \eqref{eq:LLN aux}, \eqref{eq:md clt aux} and Slutsky. We are left to show \eqref{eq:R_n neg}. For a fixed $\gamma>1$, we have
	\begin{align*}
		&pr(\|(q^{-1}\Gamma(s))^{1/2}R_n\|>\delta)\\\le& pr(  q^{-1/2}\|\Gamma(s)^{1/2}\| (N/n)^{1/2} \|\wt{A}_n^{-1}\| \|\wt{D}_n-D_n\|>\delta) \\\le&  pr(\gamma\|\Gamma(s)^{-1}\|\|\Gamma(s)^{1/2}\| \|\wt{D}_n-D_n\|>\delta)+pr((N/n)^{1/2} \|\wt{A}_n^{-1}\| > \gamma q^{1/2}\|\Gamma(s)^{-1}\|)\\
		\le& \frac{ \gamma\|\Gamma(s)^{-1}\|\|\Gamma(s)^{1/2}\|}{\delta} \E \|\wt{D}_n-D_n\|+pr((N/n)^{1/2} \|\wt{A}_n^{-1}\| > \gamma q^{1/2}\|\Gamma(s)^{-1}\|).
	\end{align*}
	Hence combining  \eqref{eq:N/n},   \eqref{eq:LLN aux} and \eqref{eq:D tilde D diff}, we have
	\begin{align*}
		\limsup_{n\rightarrow\infty} pr(\|(q^{-1}\Gamma(s))^{1/2}R_n\|>\delta)\le\frac{c \gamma }{\delta}  \|\Gamma(s)^{-1}\|\|\Gamma(s)^{1/2}\| q^{1-2/\alpha},
	\end{align*}
	which by \eqref{eq:sampling fun cond aux} tends to zero as $q\rightarrow 0$.
	This implies \eqref{eq:R_n neg} in view of the identity 
% 	\cite[Item 11.16]{seber:2008:matrix}
\[P(s)^{1/2}\vect(R_n)=\vect(   (q^{-1}\Gamma(s))^{1/2} R_n \Omega^{-1/2})\] 
	and the fact that the norm of a matrix is equivalent to the norm of its vectorization.
\end{proof}

\section{Proof of Lemma \ref{Lem:aux}}
\begin{proof}
	
	~\\
	\noindent(a)
	In the case $s(\mbf{x})=q_0+(1-q_0) 1_{\{\mbf{x}'\Sigma^{-1}\mbf{x}>r\}}$, in view of \eqref{eq:x EC} and \eqref{eq:Gamma(s) simplify},  we have
	\begin{align*}
		\Gamma(s)&= q_0\Sigma+ (1-q_0)  \Sigma^{1/2}\left(\int_{\|\mbf{z}\|^2>r}   \operatorname{diag}(z_1^2,\ldots,z_p^2) \phi_{I}(  d\mbf{z})\right) \Sigma^{1/2}\\&=   \left(q_0+ \frac{(1-q_0)}{p}\int_{y^2>r} y^2 \nu(dy)\right) \Sigma,
	\end{align*}
	where for the second equality above we have used the following fact due to symmetry: \[\int_{\|\mbf{z}\|^2>r}   z_1^2 \phi_{I}(  d\mbf{z})=\ldots=  \int_{\|\mbf{z}\|^2>r}   z_p^2 \phi_{I}(  d\mbf{z}).\]
	Therefore 
	\begin{align} 
		\frac{q^{1-2/\alpha}\lambda_{\max}(\Gamma(s)^{1/2}}{\lambda_{\min}(\Gamma(s))}=\frac{\lambda_{\max}(\Sigma)^{1/2}}{\lambda_{\min}(\Sigma)}   \left(q^{4/\alpha-2}q_0+ \frac{1-q_0}{p} q^{4/\alpha-2}\int_{y^2>r} y^2 \nu(dy)\right)^{-1/2}.\label{eq:sampling fun cond aux check}
	\end{align}
	Note that $\nu(\sqrt{r},\infty)=\frac{q-q_0}{1-q_0}$. Define $T(w)=\inf\{x\in (0,\infty):\ \nu(\sqrt{x},\infty)=  w \}$, $w\in[0,1)$ (recall $\nu$ is absolutely continuous). Then
	\begin{equation}\label{eq:lower bound aux}
		q^{4/\alpha-2}\int_{y^2>r} y^2 \nu(dy) \ge q^{4/\alpha-2}  \frac{q-q_0}{1-q_0}   r^2 \ge  c q^{4/\alpha-1} T\left(\frac{q-q_0}{1-q_0}\right)^2,
	\end{equation}
	where we have used \eqref{eq:q_0 restr}. Note that   $\lim_{q\rightarrow 0}T\left(\frac{q-q_0}{1-q_0}\right)=\lim_{w\rightarrow 0}T(w)>0$ since $\nu$ is not concentrated at the origin.  
	
	
	If $\alpha>4$, then the last lower bound in \eqref{eq:lower bound aux} tends to $\infty$ as $q\rightarrow 0$, and hence \eqref{eq:sampling fun cond aux check} tends to $0$.  
	Suppose now $\alpha\in (2, 4]$. Since $\nu(\sqrt{x},\infty)>y$ implies $T(y)>x$,  
	it follows from
	\eqref{eq:tail lower bound} that for some constant $c>0$, $T(w)> c w^{-2/\beta}$ for all sufficiently small $w$. Since also $ \frac{q-q_0}{1-q_0} \le  2q$   for all sufficiently small $q$ (recall $q_0\rightarrow 0$), we have
	\begin{align*}
		q^{4/\alpha-1} T(\frac{q-q_0}{1-q_0})^2\ge    c q^{4/\alpha-4/\beta-1} \rightarrow\infty
	\end{align*}
	as $q\rightarrow 0$ since the assumption on $\beta$ implies that $4/\alpha-4/\beta-1<0$. Therefore (a) has been proved.
	
	\medskip
	\noindent(b) 
	We first assume that $\wh{\Sigma}^{-1}_t$ and   $\wh{r}_t$ are consistent.
	With the definition in \eqref{eq:s hat t}, we have
	\begin{align*} 
		&  \E |\wh{s}_t-s(\mbf{x}_t)   |\notag\\=   &(1-q_0) \E | 1_{\{ \wt{\ell}_t> \wh{r}_t\}} -   1_{\{  \ell_t> r\}}  | 
		\le   pr( \ell_t> r,\wt{\ell}_t\le \wh{r}_t) + pr( \ell_t\le  r,\wt{\ell}_t> \wh{r}_t), 
	\end{align*}
	where $\wt{\ell}_t$ is as in \eqref{eq:tilde ell} and (with a little abuse of notation) \begin{equation}\label{eq:ell_t oracle}
	    \ell_t:=(\mbf{x}_t-\mbf{\mu}_X)' \Sigma^{-1} (\mbf{x}_t-\mbf{\mu}_X).
	\end{equation} With the consistency assumptions on $\wh{\mbf{\mu}}_{t,X}$, $\wh{\Sigma}^{-1}_t$, $\wh{r}_t$ and stationarity of $(\mbf{x}_t)$,  it is elementary to show  that $ (\wt{\ell}_t-\wh{r}_t )- (\ell_t-r)  \ConvP \mbf{0}$ and hence $(\ell_t-r,\wt{\ell}_t-\wh{r}_t)\ConvD (\ell_1-r,\ell_1-r)$ as $t\rightarrow\infty$ by stationarity. Using now the continuity of the distribution of $\ell_1$ (recall the distribution of $\mbf{x}_t$ is absolutely   continuous as assumed in Section \ref{Sec:linear sys}),  we deduce that 
	\begin{equation}\label{eq:><=} 
		\lim_{t\rightarrow\infty } pr( \ell_t> r,\wt{\ell}_t\le \wh{r}_t) =pr( \ell_1> r, \ell_1\le r)=0
	\end{equation}
	and 
	\begin{align}\label{eq:<=>}
		\lim_{t\rightarrow\infty } pr( \ell_t\le  r,\wt{\ell}_t> \wh{r}_t)=pr(\ell_1\le r,  \ell_1>r)=0.
	\end{align}
	Hence we have proved (b) based on the consistency assumption of $\wh{\Sigma}^{-1}_t$ and $\wh{r}_t$.
	
It remains to show that 	$\wh{\Sigma}^{-1}_n$  in \eqref{sigma inv est} and $\wh{r}_n$ in \eqref{r_estimate} are consistent. To show the consistency of $\wh{\Sigma}^{-1}_n$, or equivalently, the consistency of $\wh{\Sigma}_n$,  we introduce its approximation $\wt{\Sigma}_n:=\frac{1}{M_n}\sum_{t=1}^n J_t (\mbf{x}_t- \mbf{\mu}_X) (\mbf{x}_t- \mbf{\mu}_X)'$. The convergence   $\wt{\Sigma}_n\ConvP \Sigma$ as $n\rightarrow\infty$ then follows from the fact $M_n/n\rightarrow u$ as $n\rightarrow\infty$ a.s.\ and the ergodic theorem. Furthermore,  
it is not hard to  verify  based on the assumptions that $\|\wh{\Sigma}_n-\wt{\Sigma}_n\|\ConvP 0$ as $n\rightarrow\infty$. So we have established the consistency of $\wh{\Sigma}_n$.
We now turn to the consistency of $\wh{r}_n$. Denote the empirical CDF of $\ell_t$ (cf.\ \eqref{eq:ell_t oracle}) and  $\wt{\ell}_t$ as $\wh{F}_n(r)$   and $\wt{F}_n(r)$, $r\ge 0$, respectively. We have $\E|\wt{F}_n(r)-\wh{F}_n(r)|\le \frac{1}{n}\sum_{t=1}^n   \E | 1_{\{ \wt{\ell}_t> r\}} -   1_{\{  \ell_t> r\}}| \rightarrow 0  $ as $n\rightarrow\infty$, which follows from an argument  similar to the one that leads to \eqref{eq:><=} and  \eqref{eq:<=>}.  On the other hand, the ergodic theorem entails the a.s.\ convergence $\wh{F}_n(r)\rightarrow F(r):=pr(\ell_1\le r)$, $r\ge0$, and hence $\wt{F}_n(r)\ConvP F(r)$ as $n\rightarrow\infty$. Recall that  $r(q-q_0)=\inf\{r\ge 0: \  F(r)\ge (q-q_0)/(1-q_0) \}$ and $\wh{r}_n= \inf\{r\ge 0: \  \wt{F}_n(r)\ge (q-q_0)/(1-q_0) \}$. Hence for any $\epsilon>0$ sufficiently small, 
\begin{equation*}
\begin{split}
pr&\left(r(q,q_0)-\epsilon<\wh{r}_n\le r(q,q_0)+\epsilon\right)   \\
&= pr\left(\wt{F}_n(r(q,q_0)-\epsilon)< \frac{q-q_0}{1-q_0}\le  \wt{F}_n(r(q,q_0)+\epsilon)\right)\rightarrow 1
\end{split}
\end{equation*}
as $n\rightarrow\infty$.

 

\end{proof} 
\bibliographystyle{chicago}
\bibliography{Bib}
% \end{supplement}
\end{document}
