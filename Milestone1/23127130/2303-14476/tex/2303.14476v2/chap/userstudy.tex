\section{User Interview}
\label{section:user_study}

We conduct a user interview to evaluate whether or not our approach provides users with effective interactions and to see how our methods can support users' analytical tasks.
As no previous work presented such interaction enhancement, we did not compare our approach with other studies.
From the creator's perspective, our method eliminates the need for writing interactive code, while from the user's standpoint, it is easy to comprehend. Therefore, our model is suitable for users with varying levels of experience. Consequently, we have invited participants with different levels of experience to engage with our method.


\subsection{Study Design}

\textbf{Participants}. 
We conducted a user study with a cohort of 10 participants (P1-P10).
These participants possessed varied educational backgrounds, spanning fields such as information science, data science, computer graphics, mathematics, among others.
We collected self-reported measures of their experience in the realm of visualization, assessed using a 5-point Likert scale.
This encompassed aspects such as their comprehension of data visualization (midian = 4, range = 2, IQR = 1),
familiarity with software-based visualization tools (midian = 3.5, range = 2, IQR = 1),
as well as utilization of programming for generating visualizations (midian = 3, range = 3, IQR = 0.75).

\textbf{Training and tasks.}
Prior to the commencement of the study, participants were furnished with a concise overview and demonstration of the system. Essential functionalities were expounded, encompassing the manipulation of visual entities, coordinate axes, and imposed constraints.
Subsequently, participants were allotted a span of 10 to 20 minutes to organically explore the system, acquainting themselves with its diverse capabilities. Following this preliminary training phase, participants were introduced to functionalities that had evaded their initial exploration.
Participants were tasked with manipulating two visualizations: the stacked area chart and the bubble chart elucidated in Section~\ref{section:use_scenario}.
Employing our system's manipulation features, participants were tasked with devising novel visual layouts and employing these configurations to fulfill specific tasks.
These tasks encompassed customary visualization undertakings as delineated in the literature~\cite{Brehmer2013TaskAbstract}, inclusive of identification, comparison, and summarization.
For the bubble chart, four tasks were presented:
\begin{itemize}
    \item \textbf{T1:} Present the ranking of different regions with vaccination rates between 30\% and 35\%.
    \item \textbf{T2:} Identify which region has the most counties with low vaccination rates.
    \item \textbf{T3:} Identify whether a county's vaccination rate is correlated to its population.
    \item \textbf{T4:} Identify which region within the high hesitancy and low vulnerability category has the largest population.
\end{itemize}
For the stacked area chart, we provided four tasks:
\begin{itemize}
    \item \textbf{T5:} Identify the maximum among the categories on June 12th.
    \item \textbf{T6:} Compare the values of the yellow category (i.e., dashboard filters) on Aug 16th and Aug 30th.
    \item \textbf{T7:} Present the trend of the combined values within the deep grey and yellow categories.
    \item \textbf{T8:} Show the difference in the trends of the deep grey and yellow categories.
\end{itemize}


\begin{figure}[htb]
    \centering
    \includegraphics[width=\columnwidth]{image/user_study_results}
    \caption{
    Representative results for different tasks.}
    \label{fig:results}
\end{figure}


Upon completing the tasks, we requested participants to upload screenshots of their manipulated visualizations and elucidate the rationale behind their chosen layout arrangements.
\autoref{fig:results} shows the representative results for 8 tasks.
On average, participants took approximately 20 minutes to conclude their user study.
We gauged the efficacy of user-uploaded screenshots in facilitating task comprehension.
For example, in Task 8, we anticipated participants to align and compare content from two distinct categories. Ratings were as follows: 1 point for complete task alignment, 0 points for lack of task alignment, and 0.5 points for partial task resolution.
Ultimately, the majority of participants successfully completed most tasks, yielding an average score of 85\%. User scores ranged from a high of 100\% (P2) to a low of 62.5\% (P5). Among the eight tasks, the average score for the four bubble chart tasks was 75\%, while the four stacked area chart tasks averaged 95\%. The stacked area chart significantly outperformed the bubble chart in performance.
This observation finds further support in the time spent and completion rate, as portrayed in \autoref{fig:costtime} and \autoref{fig:completion}. 
The time dedicated to bubble chart tasks (T1-T4) notably exceeded that of stacked area chart tasks (T5-T8) by a substantial margin.
This disparity is attributed to the fact that bubble chart tasks typically entail constraint establishment, whereas tasks linked to the stacked area chart commonly involve drag-and-drop interactions.
Subsequently, we administered a subjective-rating questionnaire and conducted interviews to gather feedback on the system's efficacy.


\begin{figure}[htb]
    \centering
    \includegraphics[width=\columnwidth]{image/costtime_boxplot}
    \caption{
    The time taken for different tasks. It is evident that tasks T1-T4 require a longer time to complete compared to tasks T5-T8.
    }
    \label{fig:costtime}
\end{figure}


\begin{figure}[htb]
    \centering
    \includegraphics[width=\columnwidth]{image/completion}
    \caption{
    The completion rate for different tasks. Tasks T1-T4 have lower completion rate compared to tasks T5-T8.
    }
    \label{fig:completion}
\end{figure}



\subsection{Feedback from Participants}





We solicited participant feedback regarding the comprehensibility of the optimization process after manipulation, the extent to which the manipulated layout facilitated user tasks, and the comprehensibility of representing visual objects with spatial constraints. Each aspect was evaluated using a 5-point scale (1: not effective at all, 2: not very effective, 3: neutral, 4: somewhat effective, and 5: very effective). The results demonstrated favorable responses across multiple dimensions.
The user feedback is summarized as follows:



\textbf{Manipulations are easy to learn and effective.}
Participants commonly employ our method to manipulate visualizations for task completion. Furthermore, users generally perceive that the manipulated visual outcomes aid in task accomplishment ($\mu=4.0$, $\sigma=0.82$).
Participants used a range of manipulation techniques, such as dragging selected data items to a new canvas (T1, T4, T7, T8), rearranging vertical or horizontal axes based on the color or size channel (T1, T2, T3, T4), breaking stacking relationships to facilitate comparisons (T5 and T8), and setting constraints to align visual objects (T6).
Participants emphasized that the system to be comprehensible (P2, P7). P2 suggests that \textit{``the system is highly beneficial for users to understand visualizations, as users can leverage their understanding of elements from the physical world to comprehend visualization elements, thereby facilitating a quicker grasp of visualization interactions.''}


\textbf{The position update process is intuitive.}
Participants demonstrated a high level of comprehension regarding the optimization process ($\mu=4.30$, $\sigma = 0.67$).
Several participants highlighted that the procedure for updating the positions of visual objects exhibited an intuitive nature and remained in line with their anticipations (P2, P4, P6, P7).
P7 particularly underscored that \textit{``the operations align with common-sense notions of physical principles, making the process of change easily understandable.''}
The clarity of the optimization process was evident in participants' grasp of the physical forces employed to simulate the interactions, a factor that significantly contributed to their comprehension of the positional adjustments within the visualization.


\textbf{Manipulating constraints increases flexibility.}
Many participants perceive the system as addressing the flexibility of the visualization interaction space (P1, P2, P5, P8, P9). For instance, P9 mentions that ``with the system, tasks can be accomplished more freely without relying on the original visualization interaction. The layout can be designed freely.'' These flexible approaches aid task completion (P5, P10). However, some users also note that while utilizing constraints significantly enriches the interactive operational space, facilitating more flexible adjustments to data distribution, it might pose challenges for newcomers. They express the desire for additional interactive cues that encompass the potential outcomes following operations and the interactive tasks that could be supported.


