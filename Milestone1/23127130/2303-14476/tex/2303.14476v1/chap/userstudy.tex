\section{User Interview}
\label{section:user_study}

We conduct a user interview to evaluate whether or not our approach provides users with effective interactions and to see how our methods can support users' analytical tasks.
As no previous work presented such interaction enhancement, we did not compare our approach with other studies.

\subsection{Study Design}

\textbf{Participants}. 
We conducted a user study with 10 participants (4 females and 6 males) (P1-P10) who ranged in age from 18 to 30 and had diverse educational backgrounds, including computer science, physics, law, and data science majors. Most participants had some experience with data visualization. They were recruited through social media and email advertisements and compensated for their time.

\textbf{Training and tasks.}
Prior to the study, we provided participants with a brief overview and a demonstration of the system. We explained the basic functionalities, including manipulate visual marks, axes, and constraints.
Participants then took 10 to 20 minutes to freely explore the system and experiment with its different features.
After this initial training, we introduced the functions that participants had ignored during their exploration.
We explained how these functions could be used to perform more complex tasks and encouraged participants to use these manipulation to answer the tasks.
We provided two visualizations for the study: the stacked area chart and the bubble chart described in Section~\ref{section:use_scenario}.
We asked the participants to perform several tasks with a manipulated visualization layout for each visualization.
For the bubble chart, the tasks included the following:
\begin{itemize}
    \item \textbf{T1:} Present the ranking of different regions with vaccination rates from 30\% to 35\%.
    \item \textbf{T2:} Identify which region has the lowest vaccination rate.
    \item \textbf{T3:} Judge whether a county's vaccination rate is correlated to its population.
    \item \textbf{T4:} Identify which region in the high hesitancy and low vulnerability category has the largest population.
\end{itemize}
For the stacked area chart, we provided four tasks:
\begin{itemize}
    \item \textbf{T5:} Identify the maximum among the categories on June 12th.
    \item \textbf{T6:} Compare the values of the yellow category (i.e., dashboard filters) on Aug 16th and Aug 30th.
    \item \textbf{T7:} Show the trend of the total value of the deep grey and yellow categories.
    \item \textbf{T8:} Show the difference in the trends of the deep grey and yellow categories.
\end{itemize}

After completing the tasks, we asked participants to upload screenshots of their manipulated visualizations and explain their reasoning for the layout choices they made.
On average, the participants took about 30 minutes to finish the study.
We then administered a subjective-rating questionnaire and conducted an interview to collect feedback on the system's usability, effectiveness, and learnability.

\subsection{Feedback from Participants}



We solicited feedback from participants on the comprehensibility of the optimization process, the effectiveness of the interactions, and the overall effectiveness of the system. Each aspect was scored on a scale of 1 to 5 (1: not effective at all, 2: not very effective, 3: neutral, 4: somewhat effective, and 5: very effective). The results showed that participants found the system to be effective ($\mu=4.1$, $\sigma=0.94$). Feedback from participants was summarized in the following paragraphs.


\textbf{Manipulations are easy to learn and effective.}
The majority of participants were able to manipulate the visualization to answer the given questions, and they regarded the interaction results highly effective ($\mu=4.20$, $\sigma=0.75$). Participants used a range of manipulation techniques, such as dragging selected data items to a new canvas (T1, T4, T7, T8), rearranging vertical or horizontal axes based on the color or size channel (T1, T2, T3, T4), breaking stacking relationships to facilitate comparisons (T5 and T8), and setting constraints to align visual marks (T6). Participants found the interactions to be effective as they provided a large space for exploration (P1, P2, P5, P7), and the results supported the completion of the tasks  (P6, P9).


\textbf{The position update process is intuitive.}
Participants can easily understand the optimization process ($\mu=4.30$, $\sigma = 0.78$).
Participants expressed that the process for updating the positions of visual marks was intuitive (P6, P10) and consistent with their expectations (P2, P4).
The comprehensibility of the optimization process was reflected in participants' understanding of the physical forces used to model the interactions, which helped them understand the position changes in the visualization.

\textbf{Manipulating constraints increases flexibility.}
Most participants found that manipulating constraints largely increased the flexibility of the interaction space(P2, P3, P4, P5, P9, P10).
However, it may also increased the difficulty of learning the system (P4, P5).
Manipulating constraints can break the initial structure of a visualization, and inappropriately setting constraints may result in a visualization layout that lacks meaning. 
P10 suggests highlighting the constraints when they have data meaning.


