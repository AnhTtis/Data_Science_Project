\section{Limitations and Conclusions}
The main limitation of our neural renderer is the absence of explicit modeling of light visibility, which is crucial for synthesizing shadowing effects.
Our use of a pre-integrated representation of environment light, assuming full visibility of the lights to the surface, may result in lower rendering quality of shaded surfaces in complex objects (e.g., the base of material balls in Fig. \ref{fig:indir_vs_dir}).
This issue is also present in other neural inverse rendering methods \citea{zhang2021physg, boss2021neural, munkberg2022extracting}.
Given the high-quality surface geometry reconstructed by our model, our future work could incorporate geometry-based visibility approximations in proposed recent works \citea{hasselgren2022shape, liang2022spidr} to deal with shadowing effects.
Other limitations of our approach include the lack of fine-grained rendering parameter decomposition, the inability to handle semi-transparent or unbounded scenes, 
and limited support for indirect illuminations only on low-roughness surfaces. 

To summarize, we show that our approximation of physically based rendering with decomposed neural net components can help implicit neural surface models improve rendering and reconstruction of glossy surfaces, with results on par with or better than the state-of-art for view synthesis and inverse rendering, while enabling more accurate surface reconstruction and scene editing. 
The design of our neural renderer is inspired by PBR and models the implicit interaction between material and environment lighting. We use various plausible scene relighting and material editing examples in the paper to show the applicability of our approach.
 We believe our approach can benefit other implicit neural representation methods, leading to higher rendering and reconstruction quality with enhanced scene editability.


% In conclusion, our work demonstrates the effectiveness of using decomposed neural network components to approximate physically based rendering for improved rendering and reconstruction of glossy surfaces in implicit neural surface models. Our proposed neural renderer leverages the interaction between surface material and environment lighting, and achieves results on par with or better than previous state-of-the-art methods for view synthesis and inverse rendering. 
% We also showcase the versatility of our approach with various scene relighting and material editing examples. We believe that our method can be beneficial to other implicit neural scene representation methods, leading to improved rendering and reconstruction quality with enhanced scene editability.
