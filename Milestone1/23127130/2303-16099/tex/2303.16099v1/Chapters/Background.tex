% Chapter Template

\chapter{Literature Review} % Main chapter title

\label{Chapter2} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}
\section{Computational Aided Diagnosis with Medical Image Analysis}
Computer-Aided Diagnosis (CAD) refers to the use of advanced computer software and hardware to process and analyse medical images, discover and detect lesions and their characteristics, and use the results as a second opinion for physicians' diagnosis reference. The purpose is to help physicians improve the accuracy, efficiency and reproducibility of diagnosis. In a narrow view, CAD mainly refers to a system that can be used for clinical application. The main purpose is to help physicians and doctors find diseases and assist them in judging the degree of diseases, that is, benign or malignant. With the rapid development of modern computing and imaging technology, today's CAD is no longer limited to a simple application system. CAD nowadays has been developed into a complex area involving medicine, computational intelligence, image analysis, data storage and mining. The application scenario of CAD has also been expanded from the early detection and diagnosis of certain diseases to a wider range of fields, such as epidemic screening, genetic diagnosis, and drug discovery. The systematic view of a CAD is shown in Fig. \ref{fig:CAD_System}.

The main working steps of CAD can be roughly divided into three steps:
\begin{enumerate}
\item Image acquisition, that is, to obtain digital images through specific equipment. Physicians usually expect to obtain images with a high signal-to-noise ratio (SNR), high resolution, and high contrast. High SNR refers to the intensity ratio of signal to noise contained in the image. When SNR is high, the interference of noise will be small, the signal transmission quality will be high, and the value of information obtained by imaging will be rich. The resolution has a great influence on the CAD system's performance. High-resolution images will display lesion details. High contrast makes the image better show the details of the unclear sections and further helps the CAD system to make decisions.

\item Feature extraction and quantification, that is, extract and quantify the features in the image through specific algorithms. The extracted features can be referred as pathological manifestations with actual diagnostic values, such as lesion size, density, shape. The extracted features can also be referred as the special coding used as the input of the learning system, such as the Fisher Vector.

\item Training and testing, that is, input the image representation obtained in the second part into a mathematical or statistical algorithm to fit and classify the images. Commonly used traditional machine learning systems include decision trees \cite{azar2013decision} and support vector machines \cite{rojas2017optimal}. In recent years, deep learning based CAD has gradually integrated the second and third steps jointly to achieve better diagnostic performance \cite{khachnaoui2018review}.
\end{enumerate}

\begin{figure*}[t]
\includegraphics[width=1\textwidth]{CADSystem.png}
\caption{A general framework of modern medical image analysis based CAD system}
\label{fig:CAD_System}
\end{figure*}

\begin{sidewaystable}
\centering
\footnotesize
\begin{tabular}{|c|l|l|l|l|l|}
\hline
No.                & \multicolumn{1}{c|}{Survey Title}                                                                                                                                             & \multicolumn{1}{c|}{Ref.} & \multicolumn{1}{c|}{Year} & \multicolumn{1}{c|}{Venue}                                                                              & \multicolumn{1}{c|}{Content}                                                                                                                            \\ \hline
\multirow{4}{*}{1} & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}Computer-Aided Diagnosis in \\ Chest Radiography: A Survey\end{tabular}}                                                           & \multirow{4}{*}{\cite{van2001computer}}         & \multirow{4}{*}{2001}     & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}IEEE Trans on \\ Medical Imaging\end{tabular}}               & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}A review of CAD in Chest \\ Radiography.\end{tabular}}                                                       \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\ \hline
\multirow{4}{*}{2} & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}Improve Computer-Aided Diagnosis \\ With Machine Learning Techniques \\ Using Undiagnosed Samples\end{tabular}}                    & \multirow{4}{*}{\cite{li2007improve}}         & \multirow{4}{*}{2007}     & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}IEEE Trans on Systems, \\ Man, and Cybernetics\end{tabular}} & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}A semi-supervised learning method \\ for improving CAD accuracy in \\ breast cancer detection.\end{tabular}} \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\ \hline
\multirow{4}{*}{3} & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}Computer-Aided Diagnosis in Medical \\ Imaging:Historical Review, Current \\ Status and Future Potential\end{tabular}}             & \multirow{4}{*}{\cite{doi2007computer}}         & \multirow{4}{*}{2007}     & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}Computerized Medical\\ Imaging and Graphics\end{tabular}}    & \multirow{4}{*}{A review of PACS based CAD systems.}                                                                                                    \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\ \hline
\multirow{4}{*}{4} & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}Computer-Aided Diagnosis System \\ Based on Fuzzy Logic for Breast \\ Cancer Categorization\end{tabular}}                          & \multirow{4}{*}{\cite{miranda2015computer}}         & \multirow{4}{*}{2014}     & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}Computers in Biology\\ and Medicine\end{tabular}}            & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}A review of fuzzy logic based CAD \\ in breast cancer categorization.\end{tabular}}                          \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\ \hline
\multirow{4}{*}{5} & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}Image Based Computer Aided Diagnosis \\ System for Cancer Detection\end{tabular}}                                                  & \multirow{4}{*}{\cite{lee2015image}}         & \multirow{4}{*}{2014}     & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}Expert Systems with\\ Applications\end{tabular}}             & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}Systematic review of imaging \\ based cancer detection system.\end{tabular}}                                 \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\ \hline
\multirow{4}{*}{6} & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}Clinical Evaluation of A Computer-Aided \\ Diagnosis System for Determining \\ Cancer Aggressiveness in Prostate MRI\end{tabular}} & \multirow{4}{*}{\cite{litjens2015clinical}}         & \multirow{4}{*}{2015}     & \multirow{4}{*}{European Radiology}                                                                     & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}Investigat the added value of \\ CAD on cancer diagnostic accuracy.\end{tabular}}                            \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\ \hline
\multirow{4}{*}{7} & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}Clinically Applicable Deep Learning \\ for Diagnosis and Referral in \\ Retinal Disease\end{tabular}}                              & \multirow{4}{*}{\cite{de2018clinically}}         & \multirow{4}{*}{2018}     & \multirow{4}{*}{Nature Medicine}                                                                        & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}A deep learning based CAD on \\ retinal disease segmentation.\end{tabular}}                                  \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\ \hline
\multirow{4}{*}{8} & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}Artificial Intelligence and Computer-Aided \\ Diagnosis in Colonoscopy: Current Evidence \\ and Future Directions.\end{tabular}}   & \multirow{4}{*}{\cite{ahmad2019artificial}}         & \multirow{4}{*}{2019}     & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}The Lancet Gastroenterology\\ \& Hepatology\end{tabular}}    & \multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}A review of modern AI based \\ CAD in colonoscopy.\end{tabular}}                                             \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\
                   &                                                                                                                                                                               &                           &                           &                                                                                                         &                                                                                                                                                         \\ \hline
\end{tabular}
\makeatletter\def\@captype{table}\makeatother\caption{Summary of CAD related review articles.}
\label{Tab: CAD_Review}
\end{sidewaystable}

For different physiological systems or diseases, the deployment and application of CAD could be different. For this reason, in Table \ref{Tab: CAD_Review}, we have listed some selected CAD survey articles, which relate to different physiological systems or diseases in recent years. Table \ref{Tab: CAD_Review} aims to help readers to understand the needs, current situation and development trends of different CAD systems in different fields.

As the core component of CAD, learning algorithm based medical image analysis has been developing rapidly. Based on the paradigm of feature extraction, we divide the learning algorithm based medical imaging analysis into two categories: medical image analysis with hand-crafted features and medical image analysis with deep learning. The rest two subsections of this chapter will discuss them respectively.

\section{Medical Image Analysis with Hand-Crafted Features}
In the early stage of medical image analysis based on traditional machine learning, the most critical is the feature extraction and optimization, which is also called feature engineering. The quality of feature extraction and optimization directly affects the performance of the downstream task-oriented models. A general workflow of traditional machine learning based medical image analysis is shown in Fig. \ref{fig:ml_workflow}. 

Compared with natural images captured by digital cameras, medical images are very different in visual perception, and their features are also very specific:

\begin{itemize}
\item Local similarity. In medical images, the components in a small region usually have similar appearance and structure. Sometimes there is little difference between images of diseased and healthy tissues.
\item	Low brightness and contrast. Due to the limitations of imaging methods and equipment properties, medical images generally have low brightness and contrast, and color changes are not very obvious. This will cause an insufficient number of features or unrepresentative features.
\item The characteristics are complex. Most medical images come from different imaging equipment, different patients, and different shooting times and environments. During the image generation, it is difficult to avoid adverse effects such as changes in illumination during shooting, individual physiological differences of patients, the influence of scanning positions and angles, and noise from equipment. Therefore, medical images often show great complexity and variability. Some methods that are applicable in one image may not be carried out in other images.
\end{itemize}

\begin{figure*}[t]
\includegraphics[width=1\textwidth]{MLWorkflow.png}
\caption{The general pipeline of traditional machine learning based medical image analysis.}
\label{fig:ml_workflow}
\end{figure*}

To solve the aforementioned problems, early feature engineering for medical image analysis tends to satisfy the following conditions. 
\begin{enumerate}
\item Features can make an accurate description of images. From images with similar textures and structures, features should be distinguishable and highly repetitive.
\item Feature extraction algorithm is required to have high stability and adaptability and have a certain degree of robustness to various unfavorable factors and complex environments that may appear.
\item In some applications, selected medical image analysis tools have strict requirements on processing time \cite{netsch2001towards}. Therefore the image feature extraction algorithm should be easy to implement, and the processing speed must be fast, and the computational complexity should be low.
\end{enumerate}

Features can be generally divided into global and local features. Global features describe the overall properties of the whole image or a large region of interest. Common global features include color or grey distribution and texture structure. Local features only describe some representative information such as special points, lines in a small patch of an image, or a small region of interest. The selection and combination of features is a key point of feature engineering. For different types of images and application requirements, selection and combination of features can be different.

\textbf{Global features.}  Global feature is the overall description of the whole image or a large region of interest. It is usually extracted from a certain mathematical method to count the color or texture information of all pixels.

The color feature is the simplest and most intuitive description of an image. It is usually generated from a set of statistical functions. The color feature is used to reflect the color information of the image. color histogram is the most common feature. The color distribution function is obtained by calculating the color value of all pixels in the color space and counting the frequency of each color value in the image. Color histogram is simple, fast to calculate, and will not be affected by image rotation and scale changes. It has been applied in the field of image retrieval in an early stage \cite{han2002fuzzy}. In recent years, many related studies have shown that color features can still be used as an effective supplement, combined with other advanced features, and play an important role in various application fields such as image matching \cite{li2002tongue}, medical image segmentation \cite{wei1997real}, and disease classification \cite{arjunan2009image}. However, color histogram has disadvantages. It only counts all the color values within the picture. Thus it is difficult to effectively reflect the information of the image itself, such as edge and texture. At the same time, color histogram is sensitive to noise and has low robustness.

The texture feature represents the structure that repeatedly appears in the image. Compared with color features, the calculation of texture features is not limited to the color value of a single pixel. Instead, it counts complex information such as intensity distribution, neighborhood relations, etc. The smallest texture structure is called a primitive. The texture feature is the composition of the texture primitive in the image and the frequency of its repetition. Texture feature is the most widely used global feature in image analysis. Commonly used texture feature extraction methods include statistics-based methods \cite{tesavr2008medical}, geometry-based methods \cite{patil2011geometrical}, model-based methods \cite{sertel2009histopathological}, and signal processing-based methods \cite{nanni2010local}. The texture reflects the semantic information contained in the image to a certain extent, but the texture also has its shortcomings. First of all, the texture is very sensitive to image resolution, and the calculated texture of the same object at different resolutions could be quite different. Second, when reflection or noise interferes with the image, the calculated texture will contain wrong information and can mislead the model.

\textbf{Local features.} The core idea of local features is that the image is divisible. It assumes that an image is a collection of many regions with different characteristics. Among them, the more prominent region (that is, the closest part to the observer) is called the foreground, and the remaining area is called the background. Generally, the foreground information reflects the main subject of the image, that is, the main semantic information contained in the image. In the research based on global features, people have found that the undifferentiated description of the entire image could not allow the algorithm to understand the semantic information of the image. Therefore, researchers have begun to search for an alternative description and proposed several local feature representations.

The SIFT operator proposed by Lowe \cite{lowe1999object} is a milestone in the field of local feature extraction. SIFT uses the Gaussian differential pyramid to approximate the extreme points of the Gaussian Laplacian space, which solves the problem of the latter’s calculation difficulties and realizes the extreme value in the multi-scale space. The feature points can be detected with invariant scales, and then obtains rotation invariance by determining the main direction of feature sampling points. On this basis, various local feature extraction methods have been proposed. The PCA-SIFT \cite{ke2004pca} operator uses the principal component analysis method to reduce the dimension of the SIFT descriptors to increase the calculation speed. GLOH (gradient location and orientation histogram) operator \cite{mikolajczyk2005performance} adjustment the shape of the sampling window in the calculation of the feature descriptor in the SIFT algorithm is used, and a radial circle is used to replace the original grid. The SUFR (Speeded-up robust features)\cite{bay2008speeded} operator is the most successful improvement method to SIFT, which uses the Harris space for extreme value detection, and then calculates the Haar wavelet feature acquisition descriptor in the neighborhood of feature points, which greatly reduces the complexity and computing time of feature extraction. It is worth noting that the SIFT operator can usually achieve good results in natural images. When directly applied to medical images, it may be due to problems such as uniform intensities, lack of obvious edges, etc. For example, some researchers use pre-set sampling points to omit the process of interest point detection \cite{detone2018superpoint}. These methods require prior knowledge to determine the size of the sampling window, usually without multi-scale transformation and extreme value detection, which are suitable for medical image feature extraction. However, when the edges of objects in the image are invisible, SIFT often fails to extract accurate feature points and results in poor performance.

In summary, the early learning systems used for medical image analysis were mostly based on manual feature engineering. The extraction and quantity method of manually defined features are important factors that determine the performance of the learning system. The traditional learning system has the advantages of simple structure and convenient implementation, but it also has disadvantages such as feature engineering cannot be jointly trained with downstream models, feature representation is simple, and higher-dimensional information representation cannot be learned. These shortcomings make the performance of the feature engineering based learning system is unsatisfactory in various medical image analysis tasks.

\section{Medical Image Analysis with Deep Learning}

In recent years, the application of traditional learning methods to medical image analysis has mainly faced two major problems. One is that the medical image data to be processed has a higher dimensionality and requires a model with stronger learning and adaptability. The second is that medical image big data is more fragmented, and the data structure is more complex, often requiring the integration of different information. When facing these demands, traditional artificial feature engineering is particularly weak. The main disadvantages are as follows:

\begin{itemize}
\item Manually selected features contain very limited content. Manually selected features are often limited to visible features, such as grayscale, color, and edges. Or inspired by the visual model, it is limited to relatively simple implicit expressions, such as HOG \cite{dalal2005histograms} and SIFT \cite{lowe1999object}. These feature extraction algorithms have the advantages of fast speed, low resource consumption, and high interpretability. However, with the increase in the complexity of tasks, researchers began to focus on how to effectively extract features with more expressive information, such as semantic information and attention information.

\item The types of manually selected features are limited. The complexity of feature engineering is proportional to the number of features. If too many types of features are selected, the corresponding computing will be time-consuming. If the selected feature types are too few, the feature space dimension is too low, and the data cannot be completely and effectively described.

\item Manually selected feature combination and optimization rely heavily on expert experience. Different features have different descriptions of data. Effective feature combination and optimization can fully explore and utilize the relationship between features, thus improving the performance of the model. However, this process relies heavily on the developer's experience and knowledge.

\item Feature engineering and downstream models cannot be updated jointly. In most traditional learning systems, the tuning of feature engineering is performed separately from the tuning of the downstream model. This makes it difficult to map the performance error of the model back to feature engineering and is also one of the reasons why most traditional learning systems have relatively mediocre performance.
\end{itemize}

\begin{figure*}[t]
\centering
\includegraphics[width=0.5\textwidth]{SelectedProblems.png}
\caption{Selection of some medical imaging analysis applications with state-of-the-art performance generated by deep learning frameworks. From top-left to bottom-right: Mammographic mass classification ( Kooi et al. \cite{kooi2017large} ). Brain white matter hyperintensity segmentation (Ghafoorian et al. \cite{ghafoorian2016non}). Air tree segmentation with leak localization ( Charbonnier et al. \cite{charbonnier2017improving} ).  Retinopathy classification (Kaggle Diabetic Retinopathy challenge 2015, van Grinsven et al. \cite{van2016fast}). Prostate segmentation (top rank in PROMISE12 challenge \cite{litjens2014evaluation}). Nodule classification (top ranking in LUNA16 challenge \cite{setio2017validation}). Breast cancer detection (top ranking and human expert performance in CAMELYON16 \cite{bejnordi2017diagnostic}). Skin lesion classification ( Esteva et al. \cite{esteva2017dermatologist}). Bone suppression (Yang et al. \cite{yang2017cascade}). Image courtesy of \citep{litjens2017survey}}
\label{fig:selected_problems}
\end{figure*}

Therefore, how to automatically learn high-level feature information from data, and to optimize the model and feature engineering together, has become the focus of attention of researchers in recent years, and has also become a focus of attention in the industry.

Deep learning is a new branch field and developing rapidly from traditional machine learning systems. It aims to automatically learn high-level discriminative features of various levels from data by simulating the human neural network perception. Since Hinton proposed a multi-layer restricted Boltzmann machine based on a probabilistic graph model in 2006 \cite{hinton2012practical}, deep learning has become a dominant tool in various fields including computer vision. In recent years, deep learning has achieved significant success in image recognition, speech recognition, natural language processing and other fields. Deep learning has triggered a wave of data mining and analysis in broader fields. In the field of medical image analysis, deep learning has also gained the attention of academia and industry.

\begin{figure*}[t]
\includegraphics[width=1\textwidth]{DLWorkflow.png}
\caption{The general pipeline of deep learning based medical image analysis.}
\label{fig:dl_workflow}
\end{figure*}

Deep learning was originally developed from artificial neural networks. In the 1980s, the BP algorithm for artificial neural networks was proposed \cite{rumelhart1986learning}, which started the upsurge of machine learning based on statistical learning. However, in the subsequent training process, it was found that the BP algorithm has some defects such as slow convergence speed and easy to fall into a local minimum. In the 1990s, shallow machine learning models such as boosting and SVM were proposed. These models have been successfully achieved in theory and application, making shallow machine learning popular for a long time. By 2006, the introduction of the Deep Belief Network (DBN) opened a new chapter in modern deep learning research \cite{hinton2006fast}. In 2012, Hinton used the CNN model to win the ImageNet challenge with an accuracy rate of more than 10 percent higher than the runner-up. This made a breakthrough in the field of computer vision. Since then, with the emergence of models such as recurrent neural networks (RNN) for sequence data modeling, deep residual networks for image processing, the improvement of GPU computing power, deep learning has been achieved great success in various fields. A general view of the deep learning system workflow is shown in Fig. \ref{fig:dl_workflow}.

Deep learning can learn high dimensional discriminative features by building a multiple hidden layer learning model with massive training data to improve the accuracy of classification or prediction. Compared with traditional machine learning, deep learning has the following advantages:

\begin{enumerate}
\item Automated feature learning. Deep learning methods can automatically learn the high dimensional discriminative feature representations from massive data according to different applications, and can better express the internal information of the data.

\item High generalization and transferability. A deep learning model structure is usually with 5 or more hidden layers, including more nonlinear transformations, which greatly enhances the ability to fit complex functions. The deep network can be applied to different tasks. The trained model can be reused through strategies such as transfer learning.

\end{enumerate}

Deep learning systems have been widely applied in medical image analysis on different tasks. Traditional machine learning based medical image analysis method is mostly based on multi-feature fusion, singular value decomposition and wavelet transform methods. Compared with traditional machine learning based medical image analysis, deep learning can model nonlinear relationships in medical images with higher feature extraction efficiency. In recent years, many research works have been proposed to apply deep learning on different medical image analysis tasks and these works have provided an important baseline for further clinical research (Fig. \ref{fig:selected_problems}). There are two basic medical image analysis tasks: medical image classification and segmentation. Medical image classification is carried out to determine whether a sample is sick or how severe it is, while medical image segmentation is the localization of a certain lesion and other parts of a medical image. At present, deep learning systems are widely used in the above two fields. At the same time, deep learning has also been widely used in other medical image analysis areas such as medical image registration. Due to limited space, we only review related works on medical image classification and segmentation. However, we select some representative state-of-the-art methods in various medical image analysis tasks and summarize them in Table \ref{Tab: DLMIA_Review}. The rest of this section mainly introduces the research progress of deep learning in medical image analysis in two aspects: disease classification and medical image segmentation.

\textbf{Medical Image Classification} is one of the earliest applications of deep learning in the field of medical image analysis. It refers to taking one or more modality images as input, processing it through a trained model, and outputting one label to indicate whether a patient has a certain disease or the severity degree of the disease. In the early stage, deep learning models focused on SAE, DBN, and DBM networks with unsupervised pre-training methods. The research mainly focuses on the analysis of neuroimaging, such as the diagnosis of Alzheimer’s disease (AD) or Mild Cognitive Impairment (MCI). These algorithms usually use multi-modal images as input to extract complementary feature information in modalities such as MRI, PET, and CSF. Suk et al. \cite{suk2013deep} used DBM and SAE to find the expression of potential hierarchical features from 3D neuroimaging images and constructed AD/MCI classification models. The results verified on the ADNI dataset \cite{petersen2010alzheimer} show that the classification performance of the proposed model using SAE is better than using DBM. There are also a small amount of medical image classification research based on unsupervised models. For example, Rahhal et al. \cite{al2018convolutional} used SSAE to learn features in a weakly-supervised manner to classify ECG signals. Abdel-Zaher et al. \cite{abdel2016breast} first tried unsupervised learning on DBN, and then used feedback supervised learning to adjust the network to classify the breast cancer from the Wisconsin dataset. Through the application of DBN and SAE, the performance of various medical image classification tasks has been improved to a certain extent. However, DBN and SAE have disadvantages such as slow convergence speed, long learning time, and easy to fall into local minima.

Nowadays, CNN (Convolutional Neural Network) is gradually becoming the standard technology in image classification. Arevalo et al. \cite{arevalo2015convolutional} proposed a feature learning framework for breast cancer diagnosis. The author applied CNN learning distinguishing features and classifying mammogram lesions. Kooi et al. \cite{kooi2017large} compared the manual design features and automatically extracted features from CNN in CAD. Both of these methods were trained on a large data set of about 45,000 mammograms. The results showed that CNN is superior to traditional manual feature extraction methods with low sensitivity. Xu et al. \cite{xu2016detecting} studied the use of deep CNN to automatically extract features, combined with multi-instance learning methods, to classify histopathological images of colon cancer in the case of few manual annotations. Gao et al. \cite{gao2015mci} discussed the importance of deep learning technology for brain CT image classification, especially the use of CNN to provide supplementary information for early diagnosis of AD. Payan et al. \cite{payan2015predicting} and Hosseiniasl et al. \cite{hosseini2016alzheimer} used 3D CNN to diagnose AD on neuroimaging. Some works combine CNN with RNN. For example, Gao et al. \cite{gao2015automatic} used CNN to extract the low-level local feature information in the slit lamp image, combined with RNN to further extract high-level features and classified nuclear cataracts. CNN has greatly improved the performance of deep models on various tasks, but CNN also has other shortcomings. For example, the pooling layer will lose local features and ignore the correlation between the local image patch and the global image. Also, CNN models lack Interpretability.

\textbf{Medical Image Segmentation} The segmentation of organs and their substructures in medical images has important clinical significance. On the one hand, accurate segmentation can be used to quantitatively analyze clinical parameters related to volume and shape, such as the ventricular volume and contraction ejection rate of the heart. On the other hand, when using radiotherapy technology to treat tumors, accurately segmenting the tumor can ensure that tumor cells are killed during the treatment while protecting normal tissues and organs. An accurate segmentation methodology usually needs to combine multi-modal image information and adaptive context information. Therefore, most of the current studies use multi-modal image information as the network model input, or use multi-scale stream networks, or even 3D kernels to directly extract features. Kamnitsas et al. \cite{kamnitsas2017efficient} used a multi-scale fully 3D CNN network to combine global and local contextual information. The results demonstrated excellent performance in the various challenging segmentation tasks including traumatic brain injury, glioma tumors and ischemic stroke lesion. The performance, especially in terms of the overall segmentation level of glioma tumors, has surpassed the level of human experts. Yu et al. \cite{yu2016automated} combined the residual connection and the fully convolutional network to construct a deep residual FCN network, which automatically segmented melanoma in the dermoscopic image and won second place in the ISBI2016 challenge \cite{li2018skin}.  The U-Net \cite{ronneberger2015u} based framework has also been adopted by many researchers. For example, Choi et al. \cite{choi2019brain} used two pathway CNN to improve the brain tissue segmentation accuracy. The global pathway with a large size kernel determines the approximate position of the striatum, and the local pathway with small size kernels is used to predict all voxel labels. This method achieves the current state-of-the-art performance with Dice similarity coefficients 0.893 in the segmentation of the brain striatum structure. Moeskops et al. \cite{moeskops2016automatic} used a multi-scale CNN method for brain tissue segmentation. This method achieves the best results on 8 tissue classifications. It was verified on 5 different age data sets. The Dice similarity coefficients of the segmentation results were 0.87, 0.82, 0.84, 0.86 and 0.91 respectively. These works use manually designed CNN network structures to effectively learn the features of the target to be segmented. 

In summary, most of the deep learning systems used for medical image analysis are based on deep neural networks. Deep learning can effectively use data to learn high-dimensional discriminative features. This automated feature learning process eliminates the intensive steps of manual feature engineering, enables model tuning and feature learning to be jointly trained, and greatly improves the performance of various medical image analysis tasks. However, in the aforementioned works, there is no work to model and utilize the relational information between different tumor regions or tissues. In contrast, we will propose our novel deep relational learning work in Chapters \ref{Chapter3} and \ref{Chapter4}. Our goal is to improve the accuracy of semantic segmentation by learning the relational information between different semantic regions.

\begin{sidewaystable}
\centering
\footnotesize
\begin{tabular}{|llll|}
\hline
\multicolumn{1}{|c|}{Ref}                       & \multicolumn{1}{c|}{Method} & \multicolumn{1}{c|}{Application} & \multicolumn{1}{c|}{Highlights}                                                   \\ \hline
\multicolumn{4}{|c|}{Disorder Classification}                                                                                                                                                        \\ \hline
Suk and Shen \cite{suk2013deep}           & SAE                         & AD/MCI Classification            & \begin{tabular}[c]{@{}l@{}}Using stacked auto-encoders with supervised fine-tuning for\\ AD/MCI classification\end{tabular} \\ \hline
Hosseini-Asl et al. \cite{hosseini2016alzheimer}    & CNN                         & AD/MCI/HC Classification         & Using 3D CNN to process 3D fMRI data for multi-stage classification.              \\ \hline
Suk and Shen et al. \cite{suk2016deep}    & CNN                         & AD/MCI/HC Classification         & CNN with sparse representations for disorder classification.                      \\ \hline
Lian et al. \cite{lian2018hierarchical}            & FCN                         & AD/MCI/HC Classification         & Hierachically FCN with location proposal for disorder classification.             \\ \hline
\multicolumn{4}{|c|}{Tumor Segmentation}                                                                                                                                                             \\ \hline
Havaei et al. \cite{havaei2017brain}          & CNN                         & Glioma Segmentation              & \begin{tabular}[c]{@{}l@{}}Two-path way CNN with variant path combination for \\ glioma segmentation.\end{tabular}           \\ \hline
Pereira et al. \cite{pereira2016brain}         & CNN                         & Glioma Segmentation              & CNN with multi-modality inputs for MRI glioma segmentation.                       \\ \hline
Kamnitsas et al. \cite{kamnitsas2017efficient}       & FCN                         & Tumor segmentation               & 3D FCN with post-processing CRF for various tumor segmentation.                   \\ \hline
Wang et al. \cite{wang2017automatic}            & FCN                         & Glioma Segmentaion               & Cascaded FCN for progressive glioma region segmentation.                          \\ \hline
Myronenko \cite{myronenko20183d}              & FCN                         & Glioma Segmentation              & \begin{tabular}[c]{@{}l@{}}3D FCN with additional autoencoder as regularization for \\ glioma segmentation.\end{tabular}     \\ \hline
\multicolumn{4}{|c|}{Retinal Image Analysis}                                                                                                                                                         \\ \hline
Fu et al. \cite{fu2016deepvessel}              & CNN                         & Blood Vessel Segmentation        & \begin{tabular}[c]{@{}l@{}}CNN with CRF to capture long-range information for \\ blood vessel segmentation.\end{tabular}     \\ \hline
Wu et al. \cite{wu2016deep}              & CNN                         & Blood Vessel Segmentation        & Patch-based CNN with PCA for last layer feature maps.                             \\ \hline
Zilly et al. \cite{zilly2017glaucoma}           & CNN                         & Optic Disk Segmentation          & CNN with boosting for kernel updating.                                            \\ \hline
\multicolumn{4}{|c|}{Chest X-Ray Image Analysis}                                                                                                                                                     \\ \hline
Bar et al. \cite{bar2015deep}             & CNN                         & Pathology Detection              & Pre-trained CNN with low level features for diseases detection.                   \\ \hline
Cicero et al. \cite{cicero2017training}          & CNN                         & Pathology Detection              & Using GoogleNet for large scale diseases detection validation.                    \\ \hline
Hwang et al. \cite{hwang2016novel}           & CNN                         & Tuberculosis Detection           & CNN for tuberculosis detection with entire radiographs as input.                  \\ \hline
\multicolumn{4}{|c|}{Breast Image Analysis}                                                                                                                                                          \\ \hline
Huynh et al. \cite{huynh2016digital}           & CNN                         & Mass Classification              & Pre-trained network for mass classification.                                      \\ \hline
Akselrod-Ballin et al. \cite{akselrod2016region} & RCNN                        & Mass Classification              & A region proposal based mass localization and classification.                     \\ \hline
Wang et al. \cite{wang2017detecting}                                     & CNN                         & Vessel Calcification             & A detection network based vessel calcification.                                   \\ \hline
Dalmis et al. \cite{dalmics2017using}          & CNN                         & Tissue Segmentation              & A deep CNN based breast and tissue segmentation.                                  \\ \hline
\multicolumn{4}{|c|}{Digital Pathology Image Analysis}                                                                                                                                               \\ \hline
Gao et al. \cite{gao2016hep}             & CNN                         & Nucleus Classification           & CNN based Hep2-cells classification.                                              \\ \hline
Janowczyk et al. \cite{janowczyk2017stain}       & DNN                         & Nucleus Segmentation             & Deep neural network based segmentation with resolution adaptive.                  \\ \hline
Xu and Huang \cite{xu2016detecting}           & DNN                         & Nucleus Detection                & DNN based cell detection with whole-slide image as input.                         \\ \hline
\end{tabular}
\makeatletter\def\@captype{table}\makeatother\caption{Summary of CAD related review articles.}
\label{Tab: DLMIA_Review}
\end{sidewaystable}

%\begin{table}[htbp]
%\centering
%\footnotesize
%\begin{tabularx}{1.1\textwidth}{|c|X|X|X|X|X|} \hline 
%\rowcolor[gray]{0.9}	Authors &Employed Methods 	&Strength 	&Weakness 	&Brief Introduction\\ \hline\hline
%Park et al. [53] & Sentiment analysis neural network + Logistics Regression & Analysis the polarity of user's posting text.
%&Extracted features are not comprehensive. &Propose a sentiment analysis neural network to analysis the polarity of users' posting content then use these features to train Logistic Regression classifier of classification.\\ \hline
%
%Nadeem et al. [50]&Four binary classifiers, i.e. Support Vector Machine, Logistic Regression, Naive Bayes and Decision tree &These classifiers are flexible and easy to use. &These classifiers have a poor fitness ability to handle complex datasets. &The extracted feature sets are used to train four binary classifiers. \\ \hline
%Choudhury et al. [19]&Principal component analysis (PCA) + Support Vector Machine with RBF kernel (SVM) &(1) This method is flexible and easy to use. (2) Use PCA to avoid over-fitting. &It is easy to be disturbed by noise information. &Use PCA to reduce the dimensionality of feature vectors and employ SVM to classify depression users. \\ \hline
%Shuai et al. [65] &Social Network Mental Detection-base Tensor Model (STM) &The method is designed to handle the sparse data from multiple online social networks.&This method aims to find the common features from different social networks and some unique features may be ignored and classification accuracy may be poor.& Extract the common features from multi-source social networks and then employ SVM as the classifier.\\ \hline
%Shen et al. [64] &Multi-modal depressive dictionary model (MDDL) &(1) Learn the latent and sparse representation of features. (2) Capture the common patterns from different feature groups.&(1) It shares the weaknesses with MOD being efficient only for signals with relatively low dimensionality and having the possibility of being stuck at local minima. (2) It is easy to be disturbed by noise information. &Create a sparse dictionary model for each of feature groups and combine it with Logistic Regression. \\ \hline
%
%\end{tabularx}
%\makeatletter\def\@captype{table}\makeatother\caption{Summary of methods for Social networks users depression classification.}
%\label{Tab:literature_compare}
%\end{table}
%
%

