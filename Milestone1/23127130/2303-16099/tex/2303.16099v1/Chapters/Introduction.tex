% Chapter 1

\chapter{Introduction} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------
\section{Research Background}
As an important means to assist doctors in diagnosis and treatment, automated medical imaging analysis provides doctors with rich and accurate diagnostic information. At the same time, medical image interpretation is also promoting the understanding of human physiological structure and drug discovery. With the rapid development and progress of computation and digital medical imaging, digital medical image analysis has gradually become one of the most important and valuable research fields. Automated medical image analysis is an interdisciplinary research field that integrates imaging technology, numerical calculation and modeling, digital image processing and artificial intelligence. In the early application of medical imaging technology, such as X-ray, doctors obtain and interpret the physiological simulation images of patients with years of learning and accumulated experience, and then give diagnosis conclusions and treatment suggestions. However, it is inefficient to rely on the experience and knowledge of doctors. During the period of large-scale investigation of specific diseases, the disadvantages of purely artificial analysis methods are exposed. Nowadays, medical imaging technology and its application have developed the diagnosis capability from a limited range of diseases with specific symptoms, such as breast cancer, to a wide range of diseases and application scenarios.

With the development of medical imaging technology and hardware equipment, the research and analysis of high-dimensional medical images, such as CT and MRI, are becoming the mainstream. The acquisition of high-dimensional information also makes automated medical image analysis more extensive. It can be extended to the imaging of multiple organ physiology, anatomical morphology, process function and then promotes the development of related fields such as psychology, sociology and sports.

In dealing with massive and complex medical image information, pure manual interpretation and understanding are greatly restricted, and the potential value of massive information cannot be fully exploited and utilized. Therefore, researchers are more focused on the development of automatic and accurate computer-aided algorithms to help clinicians and researchers process massive information and complex tasks more efficiently and effectively. Referring to the task division in traditional computer vision, there are three basic visual tasks for medical image analysis and application:

\begin{enumerate}
\item Image registration: the purpose of early medical image registration is to jointly display images with different information, such as structure map and function information map, in a unified coordinate system. With the development of using three-dimensional imaging to study complex organs, such as the brain, there has been a study of time-series image registration and standard atlas template registration. At the same time, in order to eliminate the motion artifact in the process of image generation, image registration is also the preprocessing work of most image analysis approaches. The basic task of medical image registration is to find the corresponding relationship of objects in different images by various methods. After registration and transformation, the involved images can be connected in the same space.

\item Medical image classification: for one or more input images, an automatic algorithm can accurately classify whether the input image contains disease or not. Afterward, the classification algorithm can classify the input image into different grades, such as mild or severe disease, benign or malignant tumors. Accurate classification information can help researchers and doctors understand the disease and then give treatment suggestions.

\item Medical image segmentation: segmentation in medical images is one of the basic, important, and widely studied subfields in medical image analysis. The aim is to segment the region of interest (ROI), such as pathological tissues and organs, from complex image background by automated or semi-automated methods. Accurate, robust and fast image segmentation provides important prior knowledge for downstream tasks such as quantitative analysis, 3D reconstruction, medical robot, and provides an important foundation for image-guided surgery and radiotherapy planning.
\end{enumerate}

In recent ten years, the application and development of deep learning technology in various fields, such as computer vision, natural language processing, speech recognition, has been growing explosively. As a representation learning method, deep learning uses multiple processing layers consisting of complex structures or multiple nonlinear transformations to abstract features at a high level. Deep learning networks can be understood as the extension of the traditional neural networks, which extract representative features using nonlinear functions such as convolution. Deep learning techniques replace the traditional method of extracting hand-crafted features so that the system can learn and produce reasonable features. This powerful feature extraction ability makes the deep learning technology, especially the deep neural network, receive increasing attention in medical image analysis, and become the mainstream method in medical image analysis. Therefore, how to effectively design deep learning architecture, integrate different levels of image information, and further improve the performance of the automated algorithm in medical image analysis, is a broad research and application prospect.
%
\section{Research Objective}
In the past two years, we have focused on developing more effective and generalized deep learning algorithms for medical image tasks. We focused on two tasks here: brain glioma segmentation and fetoscopic photography image mosaicing task. Although brain glioma segmentation and medical image mosaicing belong to two different types of visual tasks, their medical image understanding and machine learning perspectives have great similarities and similarities. First of all, the two types of tasks share similar processing pipelines, that is, building a visual model based on feature learning and extraction. Second, relational information plays an important role in both tasks. In brain glioma segmentation tasks, more accurate sub-region segmentation can be performed by learning the correlation information between different tissue regions. In the medical image mosaicing task, the relational information is reflected in the spatial position relationship between adjacent frames. Accurate relational information can help reduce drift errors. Finally, efficient and accurate automated quantification technology for these two types of tasks has high clinical application value, which can further help doctors to more accurately locate and analyze the disease.

Therefore, we first propose a more accurate segmentation algorithm for specific diseases such as glioma. Then, we propose a more effective network to estimate the relative homography, i.e. the registration between adjacent images, which is expected to achieve accurate image mosaicing applied on a set of medical images with limited field-of-view (FoV).

The development of medical image analysis systems can be roughly divided into three stages. The early-stage algorithms are mainly based on modeling specific geometric features, such as edges and circles. These systems are simple and direct, but the performance is unsatisfactory. In the 1990s, data-driven supervised learning systems have become the mainstream. The most widely used models include decision tree, random field and support vector machine. Traditional machine learning systems effectively use the information provided from data, and then learn and update the model parameters, which greatly improve the performance of the model in various tasks of medical image analysis. One of the shortcomings of the traditional machine learning systems is that the final performance of the model is highly dependent on manual feature selection and combination, namely feature engineering. Effective feature engineering refers to the manual extraction of various pre-defined features from data and the optimal combination based on a researcher's experience and task characteristics. Compared to deep learning, traditional work is labor-intensive and time-consuming. In the past decade, deep learning systems based on the deep neural network has promoted the performance of medical image analysis to a new level. Especially in the application of medical image segmentation and classification, new works have been proposed. However, most of the deep neural network models do not combine the relational information between organs and tissues. Besides, the generalization performance of recent works is poor and cannot be effectively transferred from one task domain to another. To address these challenges, the objectives of our research project are summarized as follows:

(1) The main goal of this research project is to build novel deep learning tools to effectively address various problems and tasks in medical image analysis.

(2) The learning systems for medical image analysis proposed in the previous works do not effectively utilize the relational information between organs and tissues in medical images. Therefore, our second goal is to propose a novel deep learning paradigm to better model the relationship between features of different organs or tissues. We then apply it to various medical image analysis tasks, such as glioma segmentation and medical image mosaicing.

(3) Our final goal is to evaluate the effectiveness of our proposed method by using multiple datasets on different medical image analysis tasks.


%
\section{Contributions}
\label{C1:Contributions}
In this thesis, we present our research project in two parts. In the first part, we propose a new automated glioma segmentation system which is presented in Chapter \ref{Chapter3}

(1) We propose a novel Hybrid Context Aware Feature Extractor (HCA-FE). HCA-FE is built with a 3D feature interaction graph neural network and a 3D encoder-decoder convolutional neural network. Different from previous works that usually extract features in the convolutional space, HCA-FE learns hybrid context guided features in both a convolutional space and a feature interaction graph space (the relationship between neighboring feature nodes is utilized and continuously updated). To our knowledge, this is the first practice on brain glioma segmentation, which incorporates adaptive contextual information with graph convolution updates.

(2) We further propose a novel Context Guided Attentive Conditional Random Field (CG-ACRF) strategy for feature fusion. CG-ACRF based fusion module can attentively aggregate features from the feature interaction graph and convolutional space. Moreover, we formulate the mean-field approximation of the inference in the proposed CG-ACRF as a convolution operation, enabling the CG-ACRF to be embedded within any deep neural network seamlessly to achieve end-to-end training.

(3) We conduct extensive evaluations and demonstrate that our proposed method outperforms several state-of-the-art technologies using difference measure metrics on Multimodal Brain Tumor Image Segmentation Challenge (BraTS) datasets, i.e. BraTS2017 and BraTS2018.

In the second phase of our research project, we mainly contribute to the improvement of medical image mosaicing task. At this stage, our contributions are summarized as follows:

(1) We propose a new deep hierarchical homography estimation network to automatically and hierarchically estimate the 8 degree-of-freedom homography, upon which multi-scale (local level between adjacent frames and non-local level between long-range frames) homography are jointly learned and optimized in a data-driven manner.

(2) Inspired by recent works on color homography \cite{finlayson2017color}, we propose a new data generation method called Partially Image Generation (PIG). PIG only perturb the color, rotation, and translation movement between adjacent frames. The generated frames by PIG can be used for evaluating model performance during network training.

(3) We conduct extensive experiments on five different video clips from UCL Fetoscopy Placenta dataset. The results show that our method achieves state-of-the-art performance and generalizes well on different clips under different numbers of frames and different acquisition methods.

%
\section{Thesis Outline}
In this chapter, we provide an overview of the whole thesis. In Chapter \ref{Chapter1}, we briefly introduce the research background and introduction and show the expected objectives and contributions of the research project.

In Chapter \ref{Chapter2}, we review the related works of learning system based medical image analysis. These works can be roughly divided into two categories according to the design principles: one is manual feature extraction learning, the other is the deep neural network based automatic feature extraction learning. We systematically analyze the representative works of these two kinds of systems and point out their advantages and disadvantages and improvement direction.

In Chapter \ref{Chapter3}, we introduce our first contribution to glioma segmentation and propose Context Aware Network (CANet) for 3D brain glioma segmentation. In this chapter, we introduce our new segmentation system in detail and discuss the experimental results in depth.

In Chapter \ref{Chapter4}, we propose a novel medical image mosaicing method. We show the new hierarchical neural homography estimation network and partially image generation in detail. We evaluate the effectiveness of our mosaicing method on different video clips.

In Chapter \ref{Chapter5}, we summarize the research work in this thesis and discuss the limitation of research at this stage. We present the plan and the direction of future work.

%
\section{Publication List}

The content of Chapter \ref{Chapter3} appears in:
\\

Liu, Zhihua, Lei Tong, Long Chen, Feixiang Zhou, Zheheng Jiang, Qianni Zhang, Yinhai Wang, Caifeng Shan, Ling Li, and Huiyu Zhou. "CANet: Context Aware Network for 3D Brain Tumor Segmentation." arXiv preprint arXiv:2007.07788 (2020). Submitted to IEEE Transactions on Medical Imaging.
\\

Liu, Zhihua, Long Chen, Lei Tong, Feixiang Zhou, Zheheng Jiang, Qianni Zhang, Caifeng Shan et al. "Deep Learning Based Brain Tumor Segmentation: A Survey." arXiv preprint arXiv:2007.09479 (2020). Submitted to Elsevier Journal on Computerized Medical Imaging and Graphics.
\\


\noindent
\textbf{Non-thesis research:} I have also contributed to the following publications:
\\

Chen, Long, Zhihua Liu, Lei Tong, Zheheng Jiang, Shengke Wang, Junyu Dong, and Huiyu Zhou. "Underwater object detection using Invert Multi-Class Adaboost with deep learning", Proc. of International Joint Conference on Neural Networks (IJCNN), Glasgow, UK, 19-24 July, 2020.
\\

Jiang Zheheng, Zhihua Liu, Long Chen, Lei Tong, Xiangrong Zhang, Xiangyuan Lan, Danny Crookes, Ming-Hsuan Yang and Huiyu Zhou. “Detection and Tracking of Multiple Mice Using Part Proposal Networks”. arXiv preprint arXiv:1906.02831 (2019). Submitted to IEEE Transactions on Neural Networks and Learning Systems.
\\

Tong Lei, Zhihua Liu, Zheheng Jiang, Feixiang Zhou, Long Chen, Jialin Lyu, Xiangrong Zhang, Qianni Zhang, Sadka Abdul, Yinhai Wang, Ling Li, Huiyu Zhou. "Cost-sensitive Boosting Pruning Trees for depression detection on Twitter". arXiv preprint arXiv:1906.00398 (2019). Submitted to IEEE Transactions on Affective Computing.
\\

Chen Long, Zheheng Jiang, Lei Tong, Zhihua Liu, Aite Zhao, Qianni Zhang, Junyu Dong, and Huiyu Zhou. "Detection perceptual underwater image enhancement with deep learning and physical priors". arXiv preprint arXiv:2008.09697 (2020). IEEE Transactions on Circuits and Systems for Video Technology.

