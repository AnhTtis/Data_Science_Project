\chapter{Conclusion and Future Works} 
\label{Chapter5}

\section{Conclusion}
Relational information is a key point for both computational models and clinical physicians to understand the diseases in medical images. In this research project, our goal is to explore the potential of deep relational learning applied to various medical image analysis tasks. We conclude the contribution as follows:
\begin{itemize}
\item \textbf{Context Aware Network for 3D Glioma Segmentation:} We propose an implicit paradigm of relational learning and utilize it to model the relational information between features. Specifically, we propose a novel Hybrid Context Aware Feature Extractor (HCA-FE) built with a 3D feature interaction graph neural network and a 3D encoder-decoder convolutional neural network. To aggregate the features from interaction graph space and convolution space effectively, we also design a Context Guided Attentive Conditional Random Field (CG-ACRF) to regulate the information flow from the HCA-FE. Experimental results on two BraTS dataset, BraTS2017 and BraTS2018, show that our proposed method outperforms state-of-the-art methods.

\item \textbf{Hierarchical Homography Estimation Network for Medical Image Mosaicing} We propose a novel Hierarchical Homography Estimation Network (HHEN) for medical image mosaicing. Specifically, HHEN can utilize both local information between adjacent frames and non-local information between long-range frames. HHEN explicitly learns the spatial relationship between two adjacent image frames, i.e. homography using 6 degree-of-freedom in a data-driven manner. We also propose the novel Partially Image Generation (PIG) to generate perturb patches during HHEN training. PIG can let HHEN learns the rotation and translation while avoiding interferences such as color restoration. Experimental results on 5 different video clips from UCL fetoscopic photography dataset show that our proposed method achieves the state-of-the-art mosaicing results on testing clips and high robustness on unseen clips using generated homography.
\end{itemize}
\section{Future Works}
We list several future research direction as follows:
\begin{enumerate}
\item \textbf{Designing the network automatically:} Like the other state-of-the-art methods, we propose our deep neural network model by manually designing the structure, the layer combination, even the training parameters such as learning rate and the batch size. However, designing an effective neural network model and finding the best combination of different operation layers requires a high-level expertise experience and complicated validation experiments, which makes the networking designing as hard as to win a lottery \cite{frankle2018lottery}. In the future, we hope to explore the automatic network design process, specifically the neural architecture search algorithms, and try to propose novel search algorithms and construct novel search space to search one or more effective network structure candidates on medical image analysis tasks.

\item \textbf{Learning the vision and language information with multi-modal inputs:}  At present, we only focus on learning information purely from medical images. However, in clinical scenarios, other modality data such as medical records and drug prescriptions, also play an important role for physicians. In the future, we may utilize the technologies from image caption \cite{xu2015show} and visual question answering \cite{anderson2018bottom} to explore how the relational information represents in both visual and textual format with multi-modal inputs.

\item \textbf{Deep relational learning on multi-task medical image analysis:} Currently we only complete improving the performance of a particular task, e.g. only for glioma segmentation and only for fetoscopic photography mosaicing. Recent research shows that different vision task contains auxiliary information for each other \cite{zamir2018taskonomy}. In the future, we may explore how to effectively fuse different relational information from different tasks and promote the final performance on multi-task learning (for example, how to use the relation information between different glioma segmented regions to improve the accuracy of glioma degree classification).
\end{enumerate}
