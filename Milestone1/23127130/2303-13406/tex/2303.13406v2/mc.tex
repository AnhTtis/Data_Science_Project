% !TEX root = ./CauchyCombination.tex
\section{Simulations}
\label{secSims}

In this section, we compare the performance of the SCC test against several popular multiple testing corrections in a simulation study, considering different forms of dependence. 
The benchmark procedures include four inequality-based approaches: the Bonferroni correction and its subsequent improvements proposed by  \citealp{holm1979simple}, \citealp{hommel1988stagewise} and \citealp{hochberg1988sharper}, as well as the Gumbel approach.  
Detailed discussions of these benchmark procedures can be found in the Online Supplement.  

\subsection{Under the null hypothesis}
\label{ssecAccuracy}

We assess the statistical performance of the different multiple testing corrections under the null hypothesis. 
To measure the empirical familywise error rate, we conduct $S=10^4$ replications for each method $m$, and calculate  $\widehat{FWER}_m$ as follows: 
\[
\widehat{FWER}_m=\frac{1}{S}\sum_{s=1}^{S} \bm{1}\left( \min_{i\in\left\{1,2,\cdots,d\right\}} \left\{p_{(m,i)}^{s}\right\}\leq\alpha\right),
\]
where $\bm{1}(.)$ is the indicator function, and $p_{(m,i)}^{(s)}$ represents the $p$-value of the $i$th hypothesis for method $m$ in the $s$th replication. 
When the test statistics exhibit strong dependence, we expect the  $\widehat{FWER}$ of the SCC test to be closer to the nominal level $\alpha$ compared to the other procedures. 

Under the null hypothesis, the test statistics $\bm{X}$ are generated from a $d$-variate normal distribution with zero mean and covariance matrix $\bm{\Sigma}$, i.e., $N_d(\bm{0}, \bm{\Sigma})$. 
We set the dimension $d$ to 100. 
The diagonal elements of the covariance matrix, $\sigma_{ii}$, are all equal to $1$, for $i=1,\ldots,d$. 
The off-diagonal element,  $\sigma_{ij}$ with $i\neq j$, adhere to three specific  specifications. 
\begin{itemize}
	
	\item Model 1. Exponential decay: $\sigma_{ij} = 	\theta^{\abs{i-j}}$ with $\theta= 0.2, 0.4, 0.6,$ $0.8, 0.90, 0.95$.
	
	\item Model 2. 	Polynomial decay: $\sigma_{ij} = \frac{1}{0.7 + \abs{i - j}^\theta}$ with $\theta =	1.0, 1.5, 2.0, 2.5$. 
			
	\item Model 3.	Block-diagonal:  $\bm{\Sigma} = \text{diag}\{A_1,\ldots, A_{d/10}\}$, for which each diagonal block $A_k$ is a $10 \times 10$ equi-correlation matrix with its off-diagonals $\sigma_{ij} = \theta$ and $\theta = 0.1, 0.3, 0.5, 0.7, 0.9$. 
	
\end{itemize}


Models 1 and 2 also appear in \citet{liu2020cauchy}. 
The exponentially decaying correlation structures in Model 1 are frequently observed in time series and financial econometrics. 
For instance, in Section \ref{ssecDB}, the sequence of drift burst test statistics constructed from overlapping rolling windows, exhibits an autoregressive process  and has an exponential decaying covariance structure, as shown by \citet{christensen2018drift}. 
The block-diagonal structure in Model 3 is commonly used 
when testing high-dimensional factor pricing models  \citep[see e.g., the Monte Carlo experiments in][]{fan2015power} and emulates a cross-sectional dependence structure. 


Table \ref{tabSizeGlobalSequentialOtherMethods} shows the superior performance of the SCC test in the presence of correlated test statistics under the null hypothesis. 
The empirical familywise error rate of the SCC test, reported in the last column, remains close to the nominal level $\alpha = 5\%$ across various correlation structures, demonstrating its robustness. These findings align with the theoretical discussions presented in Section \ref{secPrelims}. 
In contrast, the inequality-based procedures and the Gumbel method exhibit greater conservatism, as evidenced by their substantially lower FWERs (although slight variations exist depending on the correlation pattern). 
The SCC test stands out as the only  controlling procedure with an empirical FWER close to the nominal level (5\%) across all three  types of correlation structures in the test statistics.   


\begin{table}[htb!] 
	\centering
	\caption{Empirical FWERs (in\%) of the controling procedures}
	\label{tabSizeGlobalSequentialOtherMethods}
	\begin{adjustbox}{max width=\textwidth}
		\begin{tabular}{c ccccccc}
			\hline
			\multicolumn{1}{c}{$\theta$}
			&\multicolumn{1}{c}{Bonferroni}
			&\multicolumn{1}{c}{Holm} 
			&\multicolumn{1}{c}{Hommel}  
			&\multicolumn{1}{c}{Hochberg} 
			&\multicolumn{1}{c}{Gumbel}
			&\multicolumn{1}{c}{SCC} 
			\\
			\hline
			\multicolumn{7}{c}{\textbf{Model {1}:} Exponential decay} \\	
			0.2  & 4.68 & 4.68 & 4.68 & 4.68 & $\underline{3.30}$ &  4.94 \\ 
			0.4 & 4.88 & 4.88 & 4.88 & 4.88 &  $\underline{3.44}$ &  5.36 \\ 
			0.6 & 4.96 & 4.96 & 4.96 & 4.96 & $\underline{3.54}$ &  5.78 \\ 
			0.8  & $\underline{3.98}$ & $\underline{3.98}$ & $\underline{4.00}$ & $\underline{3.98}$ & $\underline{2.84}$ & 5.82 \\ 
			0.9 & $\underline{2.40}$ & $\underline{2.40}$ & $\underline{2.42}$ & $\underline{2.40}$ & $\underline{1.70}$ & 5.48 \\ 
			0.95 & $\underline{1.76}$ & $\underline{1.76}$ & $\underline{1.78}$ & $\underline{1.76}$ & $\underline{1.18}$   & 5.38 \\ \hline
			\multicolumn{7}{c}{{\textbf{Model {2}:} Polynomial decay}} \\	
			1.0 & 4.70 & 4.70 & 4.70 & 4.70 & $\underline{3.38}$  &  5.96 \\ 
			1.5  & 4.62 & 4.62 & 4.62 & 4.62 & $\underline{3.62}$ & 5.48 \\ 
			2.0  & 4.44 & 4.44 & 4.44 & 4.44 & $\underline{3.18}$ & 5.38 \\ 
			2.5  & 4.46 & 4.46 & 4.46 & 4.46 & $\underline{3.16}$  & 5.14 \\ \hline
			\multicolumn{7}{c}{\textbf{Model {3}:} Block-diagonal} \\	
			0.1  & 4.56 & 4.56 & 4.58 & 4.56 & $\underline{3.50}$ & 4.92 \\ 
			0.3  & 4.74 & 4.74 & 4.76 & 4.74  &   $\underline{3.74}$ & 5.32\\
			0.5 &  4.54 & 4.54 & 4.54 & 4.54 & $\underline{3.28}$ &  5.70 \\ 
			0.7  & $\underline{3.40}$ & $\underline{3.40}$ & $\underline{3.40}$ & $\underline{3.40}$ &  $\underline{2.46}$ & 5.62\\
			0.9 &  $\underline{1.88}$ & $\underline{1.88}$ & $\underline{1.92}$ & $\underline{1.88}$ &  $\underline{1.30}$ & 5.62\\ 
			\hline
			\hline
			
	\end{tabular}}
\end{adjustbox}	
\parbox{0.76\textwidth}{\footnotesize%
	\vspace{.1cm} % If wanted space after the bottomrule
	{Note}: We 	report the empirical FWERs (frequencies of falsely rejecting at least one hypothesis) of the controlling procedures. 
	The test statistics are generated from $N_d(\bm{0}, \bm{\Sigma})$ with different correlation structures. 
    The dimension $d$ is $100$ and the nominal significance level $\alpha$ is 5\%. The number of replications is $10^4$. 
	Instances with lower than 4\% FWER are underlined. 
}
\end{table}



\subsection{Under the alternative hypothesis}

Under the alternative hypothesis, the performance of the controlling procedures is assessed based on their global power (the percentage of replications that reject at least one hypothesis) and their successful detection rate (the percentage of overlapping hypotheses between the sets of false hypotheses  and discoveries). 
Given the improved accuracy of the SCC procedure in controlling the FWER under the null hypothesis (as demonstrated in Table \ref{tabSizeGlobalSequentialOtherMethods}), we anticipate that the SCC test will exhibit higher power when applied under the alternative hypothesis.
 
The test statistic vector $\bm{X}$ is generated from a $d$-variate normal distribution with mean vector $\bm{\mu} = (\mu_i)$  and a correlation matrix $\bm{\Sigma} = (\sigma_{ij})$, i.e., $N_d (\bm{\mu}, \bm{\Sigma})$. 
We adopt the same correlation matrices $\bm{\Sigma}$ as discussed in Section \ref{ssecAccuracy}.
The percentage of signals (i.e., non-zero $\mu_i$'s in the vector $\bm{\mu}$) is set to be 5\% (specifically, out of the 100 hypotheses, 5 are under the alternative).
All signals have the same strength $\abs{\mu_i} = \mu_0$ which is chosen to be relatively weak, i.e.,  $\pm2.1737$.\footnote{
	The chosen signal strength ensures that the test power  converges to unity as  $d \rightarrow \infty$ in the case of sparse signals, following the result presented in Theorem 3 of \citet[][]{liu2020cauchy}. 
	} 
The sign of the signal aligns with the sign of the test statistic under the null so that the signal always amplifies the magnitude of the test statistic.


\begin{table}[h] 
	\centering
	\caption{Global power (in\%) in a correlated setting with sparse signals}
	\label{tabPowerGlobalSequentialOtherMethods}
	\begin{adjustbox}{max width=\textwidth}
		\begin{tabular}{c cccccc}
			\hline
			\multicolumn{1}{c}{$\theta$}
			&\multicolumn{1}{c}{Bonferroni}
			&\multicolumn{1}{c}{Holm} 
			&\multicolumn{1}{c}{Hommel}  
			&\multicolumn{1}{c}{Hochberg} 
			&\multicolumn{1}{c}{Gumbel}
			&\multicolumn{1}{c}{SCC} \\
			\hline
			\multicolumn{7}{c}{{\textbf{Model 1:} Exponential decay}} \\
			0.2 & 66.50 & 66.50 & 66.62 & 66.50 & $\underline{59.32}$ & 76.20 \\ 
			0.4 & 66.48 & 66.48 & 66.60 & 66.48 & $\underline{59.86}$ & 76.84 \\ 
			0.6 & 65.70 & 65.70 & 65.74 & 65.70 & $\underline{58.58}$ &  75.82 \\ 
			0.8 & $\underline{63.86}$ & $\underline{63.86}$ & $\underline{63.90}$ & $\underline{63.86}$ & $\underline{56.90}$ & 72.74 \\ 
			0.9 & $\underline{60.62}$ & $\underline{60.62}$ & $\underline{60.78}$ & $\underline{60.64}$ & $\underline{53.90}$ & 68.42 \\ 
			0.95 & $\underline{57.24}$ & $\underline{57.24}$ & $\underline{57.30}$ & $\underline{57.24}$ & $\underline{50.58}$ & 63.94 \\ \hline
			\multicolumn{7}{c}{{\textbf{Model 2:} Polynomial decay}} \\
			1.0  & 66.04 & 66.04 & 66.14 & 66.04 & $\underline{58.76}$ &  74.82 \\ 
			1.5  & 65.88 & 65.88 & 66.00 & 65.88 & $\underline{58.46}$  &  75.10 \\ 
			2.0  & 65.88 & 65.88 & 66.00 & 65.88 & $\underline{58.84}$ & 75.20 \\ 
			2.5  & 65.22 & 65.22 & 65.28 & 65.22 & $\underline{58.22}$ & 74.66 \\ \hline
			\multicolumn{7}{c}{\textbf{Model {3}:} Block-diagonal} \\
			0.1 & 66.44 & 66.44 & 66.50 & 66.44 & $\underline{59.84}$ &   76.50 \\ 
			0.3  & 67.10 & 67.10 & 67.18 & 67.10 & $\underline{60.40}$  & 76.00 \\ 
			0.5  & 65.84 & 65.84 & 65.94 & 65.84 &$\underline{58.48}$ &  74.44 \\ 
			0.7 & $\underline{63.72}$ & $\underline{63.72}$ & $\underline{63.74}$ & $\underline{63.72}$ & $\underline{57.34}$ & 71.62 \\ 
			0.9 & $\underline{60.88}$ & $\underline{60.88}$ & $\underline{61.02}$ & $\underline{60.88}$ & $\underline{54.10}$ & 69.22 \\ 
			\hline
			\hline
	\end{tabular}}
\end{adjustbox}	
\parbox{0.76\textwidth}{\footnotesize%
	\vspace{.1cm} % If wanted space after the bottomrule
	{Note}: 
	We report the global powers (frequencies of rejecting at least one hypothesis), for various correlation matrices in the presence of sparse signals. 
	The test statistics are generated from $N_d(\bm{\mu}, \bm{\Sigma})$ with different correlation structures and sparse signals. 
	The dimension $d$ is fixed at $100$, and the percentage of signals is set to  $5\%$. All the signals have the same strength ($\pm2.1737$), with the sign depending on the sign of the test statistic under the null.
	We use a nominal significance level of 5\% and conduct $10^4$  replications. 
	We underline instances where the FWERs were lower than  4\% in Table \ref{tabSizeGlobalSequentialOtherMethods}. 
}
\end{table}


Table \ref{tabPowerGlobalSequentialOtherMethods}  shows the superior global power of the SCC test in the presence of correlated test statistics and sparse signals. 
The SCC test exhibits an approximate $10$\% power enhancement compared to the runner-up method. 
When the significance level $\alpha$ is set to $5\%$, the power of the SCC test ranges between  $69$\% and $77$\%. 
Although each statistical inequality-based method improves upon its predecessor in certain aspects, we do not observe a significant difference in the frequency of rejections among the four approaches. 
As anticipated, the Gumbel approach, which assumes independent test statistics,  is the most conservative test. 

Table \ref{tabPowerLocalSequentialOtherMethods} tells a similar story with respect to the average numbers of successful detections. The SCC testing procedure successfully detects approximately 1.2 out of 5 hypotheses (or $24\%$) under the alternative, even with sparse and weak signals.\footnote{The average number of false detections is slightly higher (not reported) for the SCC test, amounting to falsely rejecting on average 0.1 (out of 95) true hypotheses.} 
Meanwhile, the average number of successful detection for the  inequality-based procedures are around 0.95 (or $19\%$), whereas the value for the Gumbel procedure is about 0.81 (or $16.2\%$).


\begin{table}[!ht] % htb!
	\centering
	\caption{Successful detection rates (in\%)  in a correlated setting with sparse signals}
	\label{tabPowerLocalSequentialOtherMethods}
	\begin{adjustbox}{max width=\textwidth}
	\begin{tabular}{c cccccc}
	\hline
	\multicolumn{1}{c}{$\theta$}
	&\multicolumn{1}{c}{Bonferroni}
	&\multicolumn{1}{c}{Holm} 
	&\multicolumn{1}{c}{Hommel}  
	&\multicolumn{1}{c}{Hochberg} 
	&\multicolumn{1}{c}{Gumbel}
	&\multicolumn{1}{c}{SCC} 
	\\
	\hline
	\multicolumn{7}{c}{\textbf{Model {1}:} Exponential decay}  \\
	0.2 & 18.80 & 19.00 & 19.00 & 19.00 & $\underline{16.00}$ & 23.20 \\ 
	0.4 & 19.20 & 19.20 & 19.20 & 19.20 & $\underline{16.20}$ & 23.60 \\ 
	0.6 & 18.80 & 19.00 & 19.00 & 19.00 & $\underline{16.00}$ & 23.40 \\ 
	0.8 & $\underline{19.20}$ & $\underline{19.40}$ & $\underline{19.40}$ & $\underline{19.40}$ &  $\underline{16.20}$ & 24.00 \\ 
	0.9 &  $\underline{19.00}$ & $\underline{19.00}$ & $\underline{19.20}$ & $\underline{19.00}$ & $\underline{16.00}$  & 24.00 \\ 
	0.95 &  $\underline{19.20}$ & $\underline{19.20}$ & $\underline{19.20}$ & $\underline{19.20}$ & $\underline{16.20}$ & 24.40 \\ \hline
	\multicolumn{7}{c}{\textbf{Model {2}:} Polynomial decay}  \\
	1.0 & 19.00 & 19.20 & 19.20 & 19.20 & $\underline{16.00}$  & 23.60 \\ 
	1.5 & 19.00 & 19.20 & 19.20 & 19.20 &$\underline{16.00}$  & 23.40 \\ 
	2.0 & 19.00 & 19.20 & 19.20 & 19.20 &$\underline{16.00}$ & 23.60 \\ 
	2.5 & 18.80 & 18.80 & 18.80 & 18.80 & $\underline{16.00}$ & 23.40 \\ \hline
	\multicolumn{7}{c}{
	\textbf{Model {3}:} Block-diagonal
	} \\
	0.1 & 19.40 & 19.40 & 19.40 & 19.40 & $\underline{16.40}$  & 23.60 \\ 
	0.3 & 19.40 & 19.60 & 19.60 & 19.60 & $\underline{16.60}$  & 23.60 \\ 
	0.5 & 19.40 & 19.40 & 19.40 & 19.40 &  $\underline{16.40}$ & 23.80 \\ 
	0.7 & $\underline{19.20}$ & $\underline{19.40}$ & $\underline{19.40}$ & $\underline{19.40}$ & $\underline{16.40}$  & 23.80 \\ 
	0.9 & $\underline{19.00}$ & $\underline{19.00}$ & $\underline{19.00}$ & $\underline{19.00}$ & $\underline{16.20}$  & 23.80 \\ 
	\hline
	\hline
	\end{tabular}}
	\end{adjustbox}	
	\parbox{0.76\textwidth}{\footnotesize%
	\vspace{.1cm} % If wanted space after the bottomrule
	{Note}: 
	We report the successful detection rates (overlap between the sets of alternative hypotheses and discoveries). 
	The data-generating processes used are the same as those for Table \ref{tabPowerGlobalSequentialOtherMethods}.
	We use a nominal significance level of 5\% and conduct $10^4$  replications. 
	We underline instances where the FWERs were lower than  4\% in Table \ref{tabSizeGlobalSequentialOtherMethods}.
}
\end{table}
