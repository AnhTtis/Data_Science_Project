% !TEX root = ./CauchyCombination.tex
\section{Example 1: Monitoring Drift Burst }
\label{secApplDriftBurst}

The drift burst hypothesis, as proposed by \citet{christensen2018drift},  postulates the existence of locally explosive trends in high-frequency asset prices, resembling phenomena like flash crashes or gradual jumps. 
An infamous example of a flash crash occurred on May 6, 2010, when the Dow Jones Industrial Average rapidly dropped nearly 1,000 points within minutes, only to recover most of the losses shortly thereafter. 

The drift burst test serves to detect and timestamp these explosive trends. 
In our analysis, we compute the test statistic on a minute-by-minute basis. Since there are 6.5 trading hours per day, the test needs to be conducted 341 times per day, resulting in a multiple testing problem. 
The test statistics are computed using overlapping windows and are expected to exhibit high autocorrelation. Given that drift bursts are rare events, they can be considered as sparse signals, and the strength of these signals can vary. 
There are several approaches to deal with the false discovery problem in this context, including the benchmark procedures considered in Section \ref{secSims}, the SCC, test and a resampling procedure suggested by \citet{christensen2018drift}.

Section \ref{ssecDB} presents  the drift burst hypothesis  and the drift burst test as a means to detect these phenomena. 
In Section % \ref{ssecDBSim} 
S2.3
of the Online Supplement, we conduct a simulation study. We apply the controlling procedures to detect drift bursts in real-world data, specifically the Nasdaq composite index and S\&P 500 index ETFs, in Section \ref{ssecDBEmpirics}.
 
\subsection{Drift Burst Hypothesis and Test}\label{ssecDB}

 Under the null hypothesis of no drift burst, the frictionless log prices $P = (P_t)_{t \geq 0}$ follow an It\^o semi-martingale process defined on a filtered probability space $(\Omega, \mathcal{F}, (\mathcal{F})_{t \geq 0}, \Prob)$: 
\begin{eqnarray}
	\label{eqDGPNull}
	dP_t = \mu_t dt + \sigma_t dW_t,  %+ dJ_t
\end{eqnarray}
where $\mu_t$ is the instantaneous drift, and the diffusive component consists of the spot volatility $\sigma_t$ and a standard Brownian motion $W_t$.  The coefficients $\mu_t$ and $\sigma_t$ are locally bounded or ``non-explosive". The volatility process is assumed to follow a  \cite{heston1993closed}-type dynamics: 
\begin{equation*}
	d\sigma _{t}^{2}=\kappa \left( \omega -\sigma _{t}^{2}\right) dt+\xi \sigma
	_{t}dB_{t},
\end{equation*}
where $B_t$ is a standard Brownian motion and $E\left( dW_{t},dB_{t}\right) =r dt$.  

Under the alternative hypothesis, 
a drift-bursting term $\mu_t^\text{b}$ and a volatility-bursting component $\sigma_t^\text{b}$ are added to the standard It\^o semi-martingale process \eqref{eqDGPNull}, resulting in the following dynamics: 
\begin{eqnarray}
	\label{eqDGPAlt}
	d{P}_t =& 
	\mu_t dt 
	+ \sigma_t dW_t 
	+  \mu_t^\text{b }dt
	+ \sigma_t^\text{b} dW_t, 
\end{eqnarray}
where $\abs{\mu_t^\text{b}} / \sigma_t^\text{b} \rightarrow \infty$ as $t \rightarrow \tau_{\text{b}}$, with $\tau_{\text{b}}$ denoting the drift burst time.  An example of such an explosive process is given by: 
\begin{eqnarray}
	\label{simDB}
	\mu_t^\text{b} = 
	a \frac{\text{sign}(t-\tau_{\text{b}})}{\abs{\tau_{\text{b}}-t}^{\alpha^\text{b}}}
	\, \, \text{and} \, \, 
	\sigma_t^\text{b} = b \frac{\sqrt{\omega}}{\abs{\tau_{\text{b}} - t}^{\beta^\text{b}}},  
	\, \, \text{for} \, \, 
	t \in [\tau_\text{b} - \Delta t, \tau_\text{b} + \Delta t], 
\end{eqnarray}
where $2\Delta t$ represents the duration of the burst, $\alpha^\text{b}$ corresponds to the strength of the burst, $\beta^\text{b}$ is the strength of the volatility burst and $a$ and $b$ are constants. This data-generating process can capture various realistic patterns, including flash crashes and mildly explosive trends, and is used in the simulations in Section % \ref{ssecDBSim}.
S2.3.

Observations are recorded at equidistant intervals $0 = t_0 < t_1 < \ldots <t_n = T$, where $T$ represents a fixed time period, such as one trading day consisting of 6.5 trading hours. The distance between two consecutive observations is $\Delta_n=t_{i+1}-t_{i}$. The observed log price, contaminated by noise, is denoted as  $\widetilde{P}_{t_i} = P_{t_i} + \epsilon_{t_i}$, where the  $\epsilon$ is an error term (noise) and independent from the latent log price $P$.

The noise-robust drift burst statistic  \citep{christensen2018drift} is defined as: 
\begin{eqnarray}
	\label{eqDBTestStat}
	X_i = 	\sqrt{h}	\frac{\hat{\bar{\mu}}_{t_i}}{\sqrt{\hat{\bar{\sigma}}_{t_i}^{2}}},
\end{eqnarray}
where $h$ is the bandwidth of the mean estimator, $\hat{\bar{\mu}}_{t_i}$ is a noise-robust estimator for the local drift, and $\hat{\bar{\sigma}}_{t_i}^{2}$ is a noise-robust estimator for the local variance. 
The test is applied on a coarse sampling grid, and the null hypothesis of the drift burst test  asserts that `there is no drift bursting at time period $t_i$'. 
The drift burst test statistics are computed minute-by-minute using overlapping rolling windows. As a result, the dimension of the test statistic sequence $\bm{X}=\left\{X_i\right\}$ is large (with the parameters settings we end up with $d=341$ for the period of one day) and the tests are autocorrelated. 
For more information regarding the implementation of noise-robust estimators of the local drift and local variance, we refer the reader to the Online Supplement. 

Under the null hypothesis, 
as the sampling frequency approaches infinity ($\Delta_n\rightarrow 0$), 
the test statistic \eqref{eqDBTestStat} converges to the standard normal distribution, i.e., $X_i \rightarrow^{d} N(0,1)$, 
This implies that the test statistic satisfies the necessary assumptions required by the Cauchy combination test when the sampling frequency is sufficiently high under the null. 
Under the alternative hypothesis, the test statistic diverges when the drift term explodes fast enough relative to the volatility, i.e., $\abs{X_i} \rightarrow \infty$, at the drift burst time. 

To control the familywise error rate,  \citet[][Appendix B]{christensen2018drift} propose a resampling-based approach for generating critical values for the drift burst test. 
The resampling  approach approximates the dependence structure of the test statistic sequence under the null hypothesis with an autoregressive order one (i.e., AR(1)) model and to obtain its distribution via simulation. 

There are a few limitations associated with using simulated critical values in practice.  Since each sequence of test statistics (corresponding to each day in an empirical analysis or each sample path in a Monte Carlo study) requires a unique critical value, the resampling procedure is computationally intensive.\footnote{To expedite the process, a table can be prepared in advance containing the quantile functions of the normalized maxima for various values of the autoregressive coefficient $\theta$ and dimensions $d$.  However, an interpolation routine becomes necessary when the estimated first-order autocorrelation and dimension are not included in the table.}  It also imposes a strong parametric assumption on the dependence structure, which could be misspecified. Additionally, resampling attempts to reproduce the dependence structure under the null hypothesis using possibly contaminated data \citep[as seen in the attenuation bias reported in][]{christensen2018drift},  
which in turn can affect the estimation of the critical value.
Therefore, caution should be exercised when interpreting the results, and the potential biases associated with the parameter estimation must be considered. 
See the Online Supplement for more detailed  discussion of the resampling approach.
  
In the Online Supplement, we also evaluate the performance of the aforementioned controlling procedures in a  simulation setting. Specifically, we evaluate the performance of the four inequality-based procedures, the Gumbel method, the resampling approach, and the SCC testing procedure. 
Instead of directly simulating the test statistics as done in Section \ref{secSims},  we generate log prices from \eqref{eqDGPNull} under the null hypothesis and \eqref{simDB} under the alternative hypothesis, and then compute drift burst test statistics \eqref{eqDBTestStat} from the simulated prices. 
Two types of drifts bursts are considered: a V-shaped 20-minute flash crash and a three-day persistent expansion. 

Our findings suggest that the SCC procedure is the most preferred option for monitoring drift bursts.  
The inequality-based methods and the Gumbel method tend to be conservative when applied to the autocorrelated drift burst test statistics. 
While the resampling procedure shows slightly better performance in terms of power and successful detection rate for flash crashes, the SCC procedure significantly outperforms the resampling method in identifying persistent expansions. 
Although there might be a small loss in power observed in some specific cases, it is a reasonable trade-off for having a robust approach to monitor drift bursts.
Moreover, the SCC procedure procedure offers the advantage of being easier to implement and can accommodate arbitrary dependency structures without requiring simulations, making it a more practical choice overall. 
 

\subsection{Empirics}
\label{ssecDBEmpirics}

We apply  the same controlling procedures to the drift burst test 
using data from the Nasdaq ETF (ticker: IXIC) and  the S\&P 500 ETF (ticker: SPY) covering the period from 1996 to 2020.  
The data was obtained from the Refinitiv Tick History Database at a one-second frequency, and we follow the data cleaning rules outlined in \citet{barndorff2009realized}. 
We test for drift bursts on a minute-by-minute basis and control the familywise error rate at a level of $0.1$\%. 

The weekly prices of the Nasdaq and S\&P 500 ETFs are illustrated in Figure \ref{figEmpiricalPrices}, with grey bars indicating weeks that exhibit drift bursts. Drift bursts are determined using the test proposed by \cite{christensen2018drift} and the SCC controlling procedure. It is evident that the Nasdaq index experienced a higher number of drift bursts, particularly in the early 2000s following the collapse of the dot-com bubble. 
The S\&P 500 index barely has any rejections. 

\begin{figure}[!h] 
\caption{Drift bursts in the Nasdaq and S\&P 500 ETFs from 1996 to 2020}\label{figEmpiricalPrices}\centering	
	\subfloat[Nasdaq]{{\includegraphics[width=.38\textwidth,angle = -90]{weeklyPrices_Nasdaq2} }}
	\subfloat[S\&P 500]{{\includegraphics[width=.38\textwidth,angle = -90]{weeklyPrices_SPY2} }}	\\
	\begin{minipage}{1.0\linewidth}
	\begin{tablenotes}
	\small
	\item {
		\medskip	
		Note: The black lines are the weekly index ETF prices. The grey bars indicate the number of rejections of the `no drift burst' null within the week.	The darker the grey scale the more drift burst days we observe. 
		We use the drift burst test of \cite{christensen2018drift} and the SCC testing procedure to control for the FWER at the $0.1\%$ significance level.
		}
	\end{tablenotes}
	\end{minipage}	
\end{figure}

Table \ref{tabEmpiricalR} reports the rejection frequencies of the drift burst test using the aforementioned controlling procedures. 
Compared to the benchmark procedures, the SCC test demonstrates a higher sensitivity in detecting drift burst days (i.e., at least one rejection within the day) and time intervals (i.e., the total number of rejections) in the Nasdaq index. 
In the case of the S\&P 500 index ETF, the SCC testing procedure detects more drift burst days and intervals than the inequality-based and Gumbel methods, albeit slightly fewer than the resampling procedure. 
It is noteworthy that the bursting episodes in the S\&P 500 are relatively short-lived, aligning with  the Flash Crash data-generating process considered in our simulations. On the other hand, the Nasdaq index exhibits  persistent drifts \citep[as reported in][]{laurent2022unit}, akin to the persistent expansion data-generating process. 

\begin{table}[H]
			\caption{Rejection frequencies of the drift burst test: Nasdaq and S\&P 500 index ETFs}\label{tabEmpiricalR}
	\scalebox{0.95}[0.95]{
	\begin{tabular}{lccccccc}
		\hline
		\multicolumn{1}{l}{} 
		&\multicolumn{1}{l}{Bonferroni} 
		&\multicolumn{1}{l}{Holm}
		&\multicolumn{1}{l}{Hommel}  
		&\multicolumn{1}{l}{Hochberg}  
		&\multicolumn{1}{l}{Gumbel} 
		&\multicolumn{1}{c}{Resampling} 
		&\multicolumn{1}{l}{SCC} 
		\\
		\hline
		% hn = 600
				\multicolumn{8}{c}{Nasdaq}  \\
		Days (in\%)   
		& 18.840
		& 18.840
		& 18.840 
		& 18.840
		& 11.662
		& 23.357
		& 23.522 
		\\
		% 
		Intervals (in\#) 
		&   6,479 
		&   6,540 
		&   6,559
		&   6,540
		&   3,823
		&   8,633
		& 10,944
		%
		\\\hline
		\multicolumn{8}{c}{S\&P 500}  \\	
		Days (in\%)   
		& 0.526
		& 0.526
		& 0.526
		& 0.526
		& 0.247
		& 0.641
		& 0.576
		\\
		
		Intervals (in\#) 
		& 41
		& 41
		& 41
		& 41
		& 18
		& 55
		& 50
		\\	

		% replace by hn = 300
		\hline
		\hline	
\end{tabular}}
\begin{minipage}{1\linewidth}
\begin{tablenotes}
\small
\item {
	\medskip
	Note: 
	The drift burst days are percentages of days over the full sample period with at least one rejection. 
	The figures in rows labelled intervals (in\#) are the total number of rejections over the entire sample period.
}
\end{tablenotes}
\end{minipage}
\end{table}

