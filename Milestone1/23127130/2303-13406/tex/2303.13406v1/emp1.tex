% !TEX root = ./CauchyCombination.tex
\section{Example 1: Monitoring Drift Burst in Financial Assets}
\label{secApplDriftBurst}

The drift burst hypothesis of \citet{christensen2018drift} postulates the existence of locally explosive trends (like flash crashes or gradual jumps) in high-frequency asset prices. 
The drift burst test detects the presence and timestamps these explosive trends. 
The test statistic is computed minute-by-minute. 
%  using observations from $[t-h,t]$, where $h$ is a bandwidth parameter. 
Assuming 6.5 trading hours per day, the test needs to be conducted 341 times per day (with a burn-in period of 49 minutes) and is thus a % difficult 
multiple testing problem. 
The test statistics are computed from overlapping intra-day windows and are expected to be highly autocorrelated. Drift bursts are rare events 
% (i.e., sparse signals) 
and the strength of the signals varies. 
There are several approaches to deal with the false discovery problem. 
\citet{christensen2018drift} propose a resampling procedure which generates simulated critical values for the drift burst test. 
We gauge the performance of the SCC procedure and the benchmark approaches in both simulation and empirical settings. 

Section \ref{ssecDB} introduces the drift burst hypothesis  and the drift burst test. 
Section \ref{secResampling} describes the resampling procedure proposed by \citet{christensen2018drift}. 
A simulation study is conducted in Section \ref{ssecDBSim}. Unlike the simulation conducted in Section \ref{secSims}, we simulate asset prices and compute the drift burst test statistics, instead of directly simulating test statistics. The controlling procedures are applied to detect drift bursts in the Nasdaq composite index and S\&P 500 index ETFs in Section \ref{ssecDBEmpirics}.
 
\subsection{Drift Burst Hypothesis and Test}\label{ssecDB}

The noisy asset log price $\widetilde{P}_{t_i} = P_{t_i} + \epsilon_{t_i}$, is recorded at equidistant intervals $0 = t_0 < t_1 < \ldots <t_n = T$, where $T$ is fixed (e.g., one trading day consisting of 6.5 trading hours), $P$ is the latent log price process, and $\epsilon$ is an additive error term (noise) which is independent from $P$. The distance between two consecutive observations is $\Delta=t_{i+1}-t_{i}$. The frictionless log prices $P = (P_t)_{t \geq 0}$ follow an It\^o semi-martingale process defined on a filtered probability space $(\Omega, \mathcal{F}, (\mathcal{F})_{t \geq 0}, \Prob)$: 
\begin{eqnarray}
	\label{eqDGPNull}
	dP_t = \mu_t dt + \sigma_t dW_t,  %+ dJ_t
\end{eqnarray}
in which $\mu_t$ is the instantaneous drift and the diffusive component consists of the spot volatility $\sigma_t$ and a standard Brownian motion $W_t$. 

Under the null hypothesis, the coefficients $\mu_t$ and $\sigma_t$ are locally bounded or non-explosive. Over a vanishing time interval $\Delta \rightarrow 0$ the drift is $O_p (\Delta)$ and swamped by the diffusive component of a larger order $O_p (\sqrt{\Delta})$, because $\Delta  \ll \sqrt{\Delta}$, meaning that over short time intervals the main contributor to the log return is volatility. 

Under the alternative hypothesis,  a drift-bursting term $\mu_t^\text{b}$ and a volatility-bursting component $\sigma_t^\text{b}$ are added to the standard It\^o semi-martingale process \eqref{eqDGPNull} such that: 
\begin{eqnarray}
	\label{eqDGPAlt}
	d{P}_t =& 
	\mu_t dt 
	+ \sigma_t dW_t 
	+  \mu_t^\text{b }dt
	+ \sigma_t^\text{b} dW_t, 
\end{eqnarray}
for which $\abs{\mu_t^\text{b}} / \sigma_t^\text{b} \rightarrow \infty$ as $t \rightarrow \tau_{\text{b}}$ with $\tau_{\text{b}}$ being the drift burst time.  An example of such an explosive process is the following: 
\begin{eqnarray}
	\label{simDB}
	\mu_t^\text{b} = 
	a \frac{\text{sign}(t-\tau_{\text{b}})}{\abs{\tau_{\text{b}}-t}^{\alpha^\text{b}}}
	\, \, \text{and} \, \, 
	\sigma_t^\text{b} = b \frac{\sqrt{\theta}}{\abs{\tau_{\text{b}} - t}^{\beta^\text{b}}},  
	\, \, \text{for} \, \, 
	t \in [\tau_\text{b} - \Delta t, \tau_\text{b} + \Delta t], 
\end{eqnarray}
in which $2\Delta t$ is the duration of the burst, $\alpha^\text{b}$ is the strength of the burst, $\beta^\text{b}$ is the strength of the volatility burst and $a$ and $b$ are constants. This data-generating process can generate many realistic patterns including Flash Crashes and mildly explosive trends and is used in the simulations in Section \ref{ssecDBSim}.%\footnote{\citet{christensen2014fact} only allows volatility bursts and \citet{andersen2020drift} only consider drift bursts.} 


The noise-robust drift burst statistic of \citet{christensen2018drift} is defined as: 
\begin{eqnarray}
	\label{eqDBTestStat}
	X_i = 	\sqrt{h}	\frac{\hat{\bar{\mu}}_{t_i}}{\sqrt{\hat{\bar{\sigma}}_{t_i}^{2}}},
\end{eqnarray}
in which $h$ is the bandwidth of the mean estimator, $\hat{\bar{\mu}}_{t_i}$ is a noise-robust estimator for the local drift, and $\hat{\bar{\sigma}}_{t_i}^{2}$ is a noise-robust estimator for the local variance. 
The test is applied on a coarse sampling grid. The null hypothesis of the drift burst test is therefore that `there is no drift bursting at time period $t_i$'.
We refer to Appendix \ref{AppDBEstim} for details on the implentation of the noise-robust estimators for the local drift and the local variance. 

The size and power theorems in \citet[][Theorems 5 and 6, respectively]{christensen2018drift} formalize the limiting behavior of the test statistic under the null and the alternative.
Under the null hypothesis, the test statistic \eqref{eqDBTestStat} converges to the standard normal distribution as $\Delta\rightarrow 0$, i.e., $X_i \rightarrow^{d} N(0,1)$, The test statistic fulfills the assumptions required by the Cauchy combination test when the sampling frequency is sufficiently high (i.e., $\Delta\rightarrow 0)$ under the null. Under the alternative hypothesis, the test statistic diverges when the drift term explodes fast enough relative to the volatility, i.e., $\abs{X_i} \rightarrow \infty$, at the drift burst time. 

The drift burst test statistics are computed minute-by-minute from overlapping rolling windows. Figure \ref{figTestStatistic} shows the dependence of the drift burst test statistics.  Panel (a) shows  second-by-second prices generated using \eqref{eqDGPAlt} under the null hypothesis and under the alternative hypothesis of a 20-minute V-patterned drift burst in the middle of the day. Panel (b) shows the corresponding minute-by-minute drift burst test statistics (with a burn-in sample of 49 minutes). The test statistic sequence is very smooth, with a first-order autocorrelation coefficient of $0.885$ under the null hypothesis and $0.895$ under the alternative hypothesis. The autocorrelation function resembles that of an AR(1) process, decaying at an exponential rate as in Model 1 in the previous section. %with the exception that the test statistics are computed from simulated log prices, instead of being simulated directly from an underlying process

\begin{figure}[!h] % 
		\caption{Persistence in the drift burst test statistics for a day without and with a 20-minute drift/volatility burst} 
		\label{figTestStatistic}\centering
		
		\subfloat[Log prices ]{{\includegraphics[width=.35\textwidth,angle = -90]{fc_price} }}
		\subfloat[Drift burst test statistics]{{\includegraphics[width=.35\textwidth,angle = -90]{fc_test} }}
		
		\vspace{.5cm}
		
		\subfloat[
			Autocorrelogram of the test statistics
		]{{\includegraphics[width=.35\textwidth,angle = -90]{acf_fc_both} }}
		
		
		\begin{minipage}{1.0\linewidth}
			\begin{tablenotes}
				\small
				\item {
					\medskip
					Note: 
					This figure highlights the smoothness of the computed drift burst test statistic sequence. Panel (a) shows the simulated log prices at the one-second frequency with a 20-minute Flash Crash. In Panel (b) we show the corresponding 341 drift burst test statistics (calculated minute-by-minute with a burn-in of 49 minutes). In Panel (c), we show the autocorrelogram of the drift burst test statistics and the implied autocorrelations from an AR(1) process. The drift burst statistic is highly autocorrelated. The estimated first-order autocorrelation of the test statistic $\hat{\theta}$ equals $0.8847$ for the sample path under the null and $0.8949$ for the sample path under the alternative. 
			}
			\end{tablenotes}
		\end{minipage}
	\end{figure}

The number of tests or the dimension of the test statistic sequence $\bm{X}=\left\{X_i\right\}$ is large (e.g., $d=341$ for the period of one day). 
%If quantiles of the standard normal distribution are used for critical values, the probability of falsely detecting at least one signal within a day is close to one. 
To control for FWER, the aforementioned controlling procedures can be used, including the four inequality-based procedures, the Gumbel, and the SCC procedure. Since the test statistics are highly correlated, the Gumbel procedure is expected to be conservative.  

\subsection{Resampling-based Method}
\label{secResampling}

\citet[][Appendix B]{christensen2018drift} propose a resampling-based approach for generating critical values of the drift burst test to control the familywise error rate. Resampling aims to approximate the dependence structure of the test statistic sequence under the null hypothesis and to obtain its distribution via simulation. Specifically, the dependence structure is approximated by a stationary Gaussian AR(1) process such that:  
\begin{equation} 
	\label{eqXAR1}
	X_{i}=\theta X_{i-1}+\epsilon _{i}, 
	\, 
	\text{for } i = 1, \ldots, d,
	\text{ with }\abs{\theta}<1\text{ and }%
	\epsilon _{i}\overset{i.i.d.}{\sim }N(0,1-\theta^{2})\text{.}
\end{equation}
Under the specification of \eqref{eqXAR1}, the autocovariance function of $X_i$ is $cov\left( X_{i},X_{j}\right) =\theta^{\left\vert i-j\right\vert }$, which decays exponentially. 
% and coincides with Model 1 considered in Section \ref{secSims}.  
The idea is to generate $R$ sequences of test statistics from \eqref{eqXAR1}, compute $X_{m}^{r} = \max_{i = 1, \ldots, d} \abs{X^r_i}$ for each $r=1,\ldots,R$, and take the $1-\alpha $ quantile of the simulated maxima $\left\{ X_{m}^{r}\right\} _{r=1}^{R}$ as the critical value of the two-sided drift burst test. The autoregressive coefficient $\theta$ can be replaced with an estimate from the observed test statistic sequence $\left\{X_{i}\right\} _{i=1}^{d}$ using  conditional maximum likelihood.
When the autocorrelation structure of $X_i$ indeed follows an AR(1) process and when the estimate is precise ($\hat{\theta}$ is close to $\theta$), the resampling-based method is expected to be less conservative than the inequality-based methods and the Gumbel, since it accounts for  data-specific dependence. 

The critical value is unique for each sequence of test statistics (each day in an empirical analysis or each sample path in a Monte Carlo study) and obtained from simulations.  It is therefore more computationally demanding than other multiple testing procedures. We can save time by preparing a table with the quantile functions of the normalized maxima for different values of the autoregressive coefficient $\theta$ and dimensions $d$, but an interpolation routine is required when the estimated first-order autocorrelation and dimension are not included in the table. 

Figure \ref{figCOR18_fig8} plots the simulated critical values as a function of the autoregressive coefficient $\theta$ for $d = 2,500$ at three significance levels (i.e., 1\%, 5\%, and 10\%), as in \citet[][Figure 8]{christensen2018drift}.\footnote{The number of replications $R=10^7$ with a burn-in of $10^4$ observations.}  The parameter $\theta$ varies from $-0.5$ to $0.99$.
% \footnote{Unlike \cite{christensen2018drift}, we also consider negative $\theta$s.} 
These simulated finite-sample critical values are compared to the ones from the asymptotic Gumbel distribution. When the degree of autocorrelation is low (i.e., $\theta \approx 0$) and the confidence level is $10\%$, the gap between the Gumbel and simulated critical values is small. However, the gap becomes more pronounced as we move further to the tail (e.g., $\alpha=1\%$) even when the test statistics are uncorrelated, as the convergence in law of the maximum term to the Gumbel is known to be slow \citep[see e.g., the discussion in][Appendix B, and references therein]{christensen2018drift}. The gap starts to grow noticeably wider in the region where the autoregressive coefficient exceeds $0.7$, a situation we often encounter in rolling window implementations.
 
\begin{figure}[!ht]
	\centering
	\caption{Simulated critical values for the drift burst test}
	
	\includegraphics[width=.8\textwidth,angle = 0]{cv_sim_edit}
	
	\label{figCOR18_fig8}%
	
	\begin{minipage}{1.0\linewidth}
		\begin{tablenotes}
			\small
			\item {
				\medskip
				Note: 
				This figure plots the (resampling-based critical values of the maxima when $d = 2,500$ and the Gumbel critical values. The figure shows how the varying degree of dependence (captured by $\theta$) affect the critical values at three different confidence levels. It extends \citet[][Figure 8]{christensen2018drift} to allow $\theta$ to take negative values.
			}
		\end{tablenotes}
	\end{minipage}
\end{figure}

In practice, the degree of dependence under the null (i.e., $\theta$) is estimated from contaminated data (test statistics computed from data generated under both the null and alternative) and hence the autocorrelation and the simulated critical value could be biased. The Flash Crash in Figure \ref{figTestStatistic} includes about 20 (out of 341) time intervals under the alternative, which leads to slightly upward biased the first-order autocorrelation ($0.885$ \textit{vs.} $0.895$). The bias can be much larger when there are more observations under the alternative hypothesis or when the explosive trend does not have a reversal like in the V-pattern. Note that with the high autocorrelation of the drift burst statistics, we are operating on the far right of Figure \ref{figCOR18_fig8}. Even small downward (resp. upward) biased estimates of the autocorrelation under the null hypothesis lead to a loss of (resp. spurious) power. The bias is expected to be significantly larger in the case of a long-lasting drift burst as we see in the Nasdaq composite index (see Section \ref{ssecDBEmpirics}). We believe this mixing of intervals under the null and the alternative hypotheses in empirical data manifests in the attenuation bias reported  in \citet[][Appendix B, pp. 494]{christensen2018drift}:  ``The estimated ACF [of an AR(1)]  is close to the observed one [for the simulated data], although there is a slight attenuation bias for the empirical estimates". 

Obviously, when the underlying correlation structure is far from an AR(1), the approximation \eqref{eqXAR1} is not appropriate and might lead to incorrect inferences. In contrast, the SCC test solves the problem of dependence in a much simpler way and accommodates arbitrary dependency structures in the test statistics.


\subsection{Simulation Study}\label{ssecDBSim}

We compare the finite sample performance of the SCC test with existing controlling procedures (including the four inequality-based, Gumbel and the resampling-based methods) for the drift burst test. 

\subsubsection{Data-generating processes}

Instead of simulating directly the test statistics as in Section \ref{secSims}, we generate the log prices from the data generating process \eqref{eqDGPNull}. Under the null hypothesis we set $\mu_t^b=\sigma_t^b=0$ in \eqref{eqDGPAlt} while under the alternative we set $\mu_t^b$ and $\sigma_t^b$ as in \eqref{simDB}. 

The diffusion coefficient $\sigma_t$ is assumed to follow a \citet{heston1993closed} process:  
	\begin{equation}
		d\sigma_t^2 = \kappa (\theta - \sigma_t^2)dt + \xi \sigma_t dB_t, 
		\text{with} \, t \in [0,1], 
	\end{equation}
where $B_t$ is a standard Brownian motion and correlated with $W_t$, the standard Brownian motion of the mean equation \eqref{eqDGPAlt}, i.e., $E[dW_t,dBt] = \delta dt$. As in \citet{christensen2018drift}, we assume the annualized parameters of the variance process are $(\kappa, \theta, \xi, \delta) = (5, 0.0225, 0.4, -\sqrt{0.5})$. The parameter $\theta$ corresponds to a return volatility of roughly 20\% per annum. In each simulation, $\sigma_t^2$ is initiated at a random draw from its stationary law $\sigma_t \sim \text{Gamma} (2 \kappa \theta \xi^{-2}, 2 \kappa \xi^{-2})$. The drift coefficient $\mu_t$ is set to zero. 

Under the alternative, we consider two different settings for the drift- and volatility-bursting coefficients: 
\begin{itemize}
\item Flash Crash. The price experiences a short-lived, V-shaped Flash Crash which lasts about $20$ minutes ($\Delta t = 0.025$) in the middle of the trading day, $\tau_{\text{b}} = 0.5$ \cite[as in][]{christensen2018drift}. Signals are sparse: the percentage of signals is about 6\% (20 out of 341 time intervals). Obviously, the strength of the signal is not constant. It is the strongest at the bottom of the ``V".  The drift burst rate $\alpha^\text{b} = 0.65$ with $a = 3$ and the volatility-burst rate $\beta^\text{b} = 0.4$ with $b = 0.15$. The parameter setting leads to a mild burst event.

%\item \textbf{Crash} The price experiences a one-directional crash which lasts for the whole day (i.e., $\Delta t = 1$ and $\tau_{\text{b}} = 1$). The percentage of signals is 100\% (all intervals are under the alternative). The drift burst rate $\alpha^\text{b} = 0.9$ and the volatility-burst rate $\beta^\text{b} = 0.3$. {\color{red} Shuping: what about the two constants?}

\item Persistent Expansion. The price experiences  an upward trend which lasts 3 days as in \cite{laurent2020drift} and \cite{laurent2020volatility,laurent2022unit}, starting at the beginning of day one with an upward trend peaking at the end of the third day. The percentage of signals is 100\% and the signal strength is increasing over the three days. We set $\alpha^\text{b} = 0.75$ with $a = 3$ and $\beta^\text{b} = 0.40$ with $b = 0.15$. 
% {\color{red} Shuping: what about the two constants? NB: They're the same as in the first setting.}
\end{itemize}
The log prices are contaminated by a noise term $\epsilon_{t_i} \sim	N(0, n^{-1/2}\gamma\sigma_{t_i})$,  	in which the noise-to-volatility ratio $\gamma$ is set to $0.5$. The noise term is conditionally heteroskedastic and serially dependent (through $\sigma_{t_i}$). We simulate data at the one-second frequency (assuming 6.5 trading hours each day), implying $23,401$ observations each day. 


\subsubsection{Simulation results}

We detect drift bursts on a one-minute grid. Each day is treated separately with a burn-in period of 49 minutes, leaving us with 341 drift burst tests per day. 
We treat these 341 drift burst tests on a day as a family and control the FWER rate at 5\%. 
% We measure the performance of the tests by computing the empirical FWERs under the null hypothesis and the global empirical power and the successful detection rates under the alternative hypothesis. 
The simulation is
repeated 1,000 times.

% 
Table \ref{tabSimsDriftBurst} reports the 
familywise error rate, global power, and successful detection rates
of different controlling procedures % for the drift burst test. 
under the given empirical setting.
We also report the average estimated first-order autocorrelation coefficient of the test statistics $\bar{\hat{\rho}}$ in the third column. There are moderate differences in $\bar{\hat{\rho}}$ under the null and the alternative hypotheses ($0.894$ under the null and higher under the alternative). The difference is larger when the signal lasts longer, e.g. $\bar{\hat{\rho}}=0.94 $ on the third day of the persistent expansion process.
	
	\begin{table}[!ht] % htb!
		\centering
		\caption{Finite sample performance of the controlling procedures for the drift burst test}
		\label{tabSimsDriftBurst}
		\begin{adjustbox}{max width=\textwidth}
			\begin{tabular}{l l | c | ccccccc}
				\hline
				\vspace{-.4cm} \\
				\multicolumn{2}{c}{DGP}
				&\multicolumn{1}{c}{$\bar{\hat{\rho}}$} 
				&\multicolumn{1}{c}{Bonferroni}
				&\multicolumn{1}{c}{Holm} 
				&\multicolumn{1}{c}{Hommel}  
				&\multicolumn{1}{c}{Hochberg} 
				& \multicolumn{1}{c}{Gumbel} 
				&\multicolumn{1}{c}{Resampling}
				&\multicolumn{1}{c}{SCC} \\
				\hline
				\multicolumn{10}{c}{Empirical FWER} \\ 
				\multicolumn{1}{l}{Stochastic volatility}
				& 
				& 0.89
				& 2.40 & 2.40 & 2.40 & 2.40
				& 1.90 & 4.60 & 4.80
				\\\hline
				\multicolumn{10}{c}{Global power} \\ 
				\multicolumn{1}{l}{Flash Crash} 
				% bandwidth: hn = 600			
				&
				& 0.90
				& 69.20 
				& 69.20 
				& 69.20 
				& 69.20 
				& 66.80 
				& 75.10 
				& 70.90 
				\\
				\multicolumn{1}{l}{Persistent Expansion}
				& \text{Day 1}
				& 0.89
				& 5.60
				& 5.60
				& 5.60
				& 5.60
				& 4.70
				& 10.20
				& 15.50
				\\
				& \text{Day 2}
				& 0.89
				& 12.90
				& 12.90
				& 12.90
				& 12.90
				& 10.40
				& 20.00
				& 30.00
				\\
				& \text{Day 3}
				& 0.94
				& 100.00
				& 100.00
				& 100.00
				& 100.00
				& 100.00
				& 100.00
				& 100.00
				\\
				\hline
				\multicolumn{10}{c}{Successful detection rates} \\ 
				\multicolumn{1}{l}{Flash Crash} 
				& 
				& 0.90
				& 6.48 
				& 6.49 
				& 6.49 
				& 6.49 
				& 6.13 
				& 7.64 
				& 6.93 
				\\ 
				%			\multicolumn{1}{l}{\textbf{3b:} Crash}
				%			& 
				%			& 0.940
				%			& 5.93
				%			& 6.02
				%			& 6.06
				%			& 6.02
				%			&  5.74
				%			&  7.08
				%			&  6.53
				%			& 9.28
				%			\\ 
				\multicolumn{1}{l}{Persistent Expansion} 
				& \text{Day 1}
				& 0.89
				& 0.04
				& 0.04
				& 0.04
				& 0.04
				& 0.03
				& 0.10
				& 0.35
				\\
				& \text{Day 2}
				& 0.89
				& 0.11
				& 0.12
				& 0.12 
				& 0.12
				& 0.09
				& 0.21
				& 1.30
				\\
				& \text{Day 3}
				& 0.94
				& 11.29
				& 11.67
				& 12.12
				& 11.67
				& 10.80
				& 13.84
				& 23.83
				\\
				\hline
				\hline
		\end{tabular}}
	\end{adjustbox}	
	\parbox{\textwidth}{\footnotesize%
		\vspace{.1cm} % If wanted space after the bottomrule
		{Note}: 
		We report the finite sample performance of the SCC procedure and its benchmarks for the drift burst test statistic. We report the FWERs (Panel 1), the global powers (Panel 2) and the successful detection rates (Panel 3). We consider different types of signals (Flash Crash and Persistent Expansion) and set the nominal level $\alpha$ to 5\%. The simulation is repeated $2,000$ times.
		}
\end{table}

The SCC test and the resampling approach perform well under the null hypothesis with a FWER of $4.8\%$ and $4.6$\%, respectively, for a nominal  level of 5\%. The inequality-based  approaches and the Gumbel method are much more conservative, with their empirical FWERs falling between $1.6\%$ and $2.4$\% for a nominal level of 5\%. Interestingly, the SCC test always has a higher power and successful detection rate than the inequality-based approaches and the Gumbel method. The global power of SCC and the successful detection rate are higher than those of the resampling approach when the signals are strong (i.e., Day 2 and Day 3 of Persistent Expansion). 
% For instance, in the last row, which reports the successful detection rate for the third day of the persistent expansion process, the SCC test detects about 24\% of intervals while the resampling method rejects 14\% of the cases. 
On the third day of the persistent expansion, the SCC test successfully detects about 24\% of intervals under the alternative hypotheses while the resampling method only detects 14\% of intervals.
In contrast, the resampling approach works better when the duration of the signal is relatively short, e.g., Flash Crash. However, as discussed earlier, resampling is much more computationally costly than SCC and it is exposed to the attenuation bias in the empirics.
	
Figure \ref{figLocalRejections} shows a typical sample path of the DGPs in the first column and the successful detection rates of the drift burst tests with the SCC procedure at each  time interval. As expected, the rejection rate is the highest when the signal strength is the strongest (i.e., at the bottom of the Flash Crash and at the end of the persistent expansion).\footnote{The drift burst test only detects the left-side of the V-pattern because the test is backward-looking by construction (see Appendix \ref{AppDBEstim}).}

\begin{figure}[!h] % htb!
\centering
\caption{A typical sample path of the DGP under the alternative and successful detection rates of SCC for the drift burst test}
\label{figLocalRejections}

\subfloat[log Price with Flash Crash]{{\includegraphics[width=.4\textwidth,angle = 0]{price_drift_a065b040} }}
\subfloat[Rejections with Flash Crash]{{\includegraphics[width=.4\textwidth,angle = 0]{db_local_drift_a065b040} }}	

%\par
%
%\subfloat[log Price with crash]{{\includegraphics[width=.4\textwidth,angle = 0]{price_crash} }}	
%\subfloat[Rejections with crash ]{{\includegraphics[width=.4\textwidth,angle = 0]{db_local_crash} }}	

\par

\subfloat[log Price with three-day rise]{{\includegraphics[width=.4\textwidth,angle = 0]{price_3drise} }}	
\subfloat[Rejections with three-day rise]{{\includegraphics[width=.4\textwidth,angle = 0]{test_3drise} }}	

\begin{minipage}{1.0\linewidth}
	\begin{tablenotes}
		\small
		\item {
			\medskip
			Note: 
			We plot a typical sample path of the DGPs in the first column and rejection frequencies of the drift burst tests with the SCC procedure for each interval in the second column. The grey color bar indicates the intervals under the alternative: 20 intervals (out of 390) for the Flash Crash and all intervals for the Persistent Expansion process. The first 49 intervals of each day are used as a burn-in period for the drift burst test.} 
	\end{tablenotes}
\end{minipage}
\end{figure}

\subsection{Empirics}
\label{ssecDBEmpirics}

For the empirical application, we apply 
%  the same seven versions of the drift burst test % not a different test.
the same controlling procedures on the drift burst test 
as in the previous section on the Nasdaq ETF (ticker: IXIC) and  the S\&P 500 ETF (ticker: SPY) for the period spanning from 1996 to 2020.  The data was collected from the Refinitiv Tick History Database at the one-second frequency and we use the rules in \citet{barndorff2009realized} to clean the raw data. We test for drift bursts minute-by-minute and control the familywise error rate at  $0.1$\%. 

Figure \ref{figEmpiricalPrices}  plots the weekly Nasdaq and S\&P 500 ETFs. The identified drift bursting weeks (with at least one rejections within the week) are indicated with grey bars. 
 The Nasdaq index bursts particularly often in the early 2000s after the collapse of the dot-com bubble. The S\&P 500 index barely has any rejections. The autocorrelation of the drift burst statistic are higher for the Nasdaq than for the S\&P 500 ($0.926$ vs. $0.861$). This is consistent with our observations in Table \ref{tabSimsDriftBurst} that the estimated autocorrelation coefficient is higher for processes with longer-lasting signals (i.e., more observations under the alternative hypothesis).

\begin{figure}[!h] 
\caption{Drift bursts in the Nasdaq and S\&P 500 ETFs from 1996 to 2020}\label{figEmpiricalPrices}\centering	
	\subfloat[Nasdaq]{{\includegraphics[width=.38\textwidth,angle = -90]{weeklyPrices_Nasdaq2} }}
	\subfloat[S\&P 500]{{\includegraphics[width=.38\textwidth,angle = -90]{weeklyPrices_SPY2} }}	\\
	\begin{minipage}{1.0\linewidth}
	\begin{tablenotes}
	\small
	\item {
		\medskip	
		Note: The black lines are the weekly index ETF prices. The grey bars indicate weeks with at least one rejection of the `no drift burst" null hypothesis within the day. 
		The darker the grayscale the more drift burst days we observe. 
		We use the drift burst test of \cite{christensen2018drift} and the SCC procedure to control for the FWER at the $0.1\%$ significance level.
		}
	\end{tablenotes}
	\end{minipage}	
\end{figure}

Table \ref{tabEmpiricalR} reports the rejection frequencies of the drift burst test with the seven FWER controlling procedures. Compared to the benchmark procedures, the SCC test detects more drift burst days (i.e., at least one rejection within the day) and intervals (i.e., total number of rejections) in the Nasdaq index. For the S\&P 500 index ETF, the SCC procedure detects more drift burst days and intervals than the inequality-based and Gumbel methods but slightly less than the resampling procedure. The bursting episodes in the S\&P 500 are relatively short-lived which is in line with the Flash Crash DGP considered in our simulations, while the Nasdaq index has persistent drifts as shown in \citet{laurent2022unit}, resembling the persistent expansion DGP. 
Our simulations show that the SCC test has higher power in detecting persistent drifts, whereas the resampling procedure performs slightly better in detecting short flash crashes. 

\begin{table}[H]
			\caption{Rejection frequencies of the null of the drift burst hypothesis for the Nasdaq and S\&P 500 index ETFs}\label{tabEmpiricalR}
	\scalebox{0.95}[0.95]{
	\begin{tabular}{lccccccc}
		\hline
		\multicolumn{1}{l}{} 
		&\multicolumn{1}{l}{Bonferroni} 
		&\multicolumn{1}{l}{Holm}
		&\multicolumn{1}{l}{Hommel}  
		&\multicolumn{1}{l}{Hochberg}  
		&\multicolumn{1}{l}{Gumbel} 
		&\multicolumn{1}{c}{Resampling} 
		&\multicolumn{1}{l}{SCC} 
		\\
		\hline
		% hn = 600
				\multicolumn{8}{c}{Nasdaq}  \\
		Days (in\%)   
		& 18.840
		& 18.840
		& 18.840 
		& 18.840
		& 11.662
		& 23.357
		& 23.522 
		\\
		% 
		Intervals (in\#) 
		&   6,479 
		&   6,540 
		&   6,559
		&   6,540
		&   3,823
		&   8,633
		& 10,944
		%
		\\
		\multicolumn{8}{c}{S\&P 500}  \\	
		Days (in\%)   
		& 0.526
		& 0.526
		& 0.526
		& 0.526
		& 0.247
		& 0.641
		& 0.576
		\\
		
		Intervals (in\#) 
		& 41
		& 41
		& 41
		& 41
		& 18
		& 55
		& 50
		\\	

		% replace by hn = 300
		\hline
		\hline	
\end{tabular}}
\begin{minipage}{1.0\linewidth}
\begin{tablenotes}
\small
\item {
	\medskip
	Note: We report the empirical rejections of the drift burst test with various controlling procedures.  The drift burst days are percentages of days over the full sample period with at least one rejection. 
	% The intervals are the total number of rejections over the entire sample period. 
	The figures in rows labelled intervals (in\#) are the total number of rejections over the entire sample period.
}
\end{tablenotes}
\end{minipage}
\end{table}

