\section{Preliminaries}

\begin{figure}[tb!]
    \centering
    \includegraphics[width=0.76\linewidth]{ddpm-fig1_004_.pdf}
    \caption{Illustration of denoising diffusion process. }
    \label{fig:ddpm}
\end{figure}


\subsection{Diffusion Models}
\label{sec:2.1}

Diffusion models refer to denoising diffusion probabilistic models \cite{ho2020denoising}, which have  demonstrated great potential in generating high-quality images. A diffusion model defines a Markov chain to represent the sample forward and reverse diffusion process, as shown in \Cref{fig:ddpm}. In the forward diffusion process, the diffusion model produces a sequence of noisy samples $\vec{T}_1,...,\vec{T}_K$ by iteratively adding Gaussian noise to the original sample $\vec{T}_0$ in $K$ steps, where the noise level is controlled by a variance schedule $\left\{ \beta_k \in (0,1) \right\}_{k=1}^K$:
\begin{equation}
    \vec{q}\left(\vec{T}_k | \vec{T}_{k-1}\right) := \mathcal{N}\left(\vec{T}_k ; \sqrt{1-\beta_k} \vec{T}_{k-1}, \beta_k \vec{I}\right).
    \label{eq:ddpm-forward}
\end{equation}

When $K$ is large, the noisy sample at the final iteration $\vec{T}_K$ will have an almost Gaussian distribution, which inspires the diffusion model to construct a reverse diffusion process to produce fresh data samples from randomly drawn Gaussian noise. The goal of the reverse diffusion process is to learn the  distribution of inverting the explained forward diffusion process, which will be used to generate fresh data samples from a Gaussian noise input. However, a proper inversion of the distribution requires  an expressive model, and therefore we use a deep neural network with learnable parameters $\vec{\theta}$ to learn the distribution,
% \begin{equation}
% p_\theta\left(\vec{x}_{0: T}\right)=p\left(\vec{T}_k\right) \prod_{t=1}^T p_\theta\left(\vec{T}_{k-1} \mid \vec{T}_k\right)
% \end{equation}
\begin{equation}
    \vec{p}_{\vec{\theta}} \left(\vec{T}_{k-1} | \vec{T}_k\right) := \mathcal{N}\left(\vec{T}_{k-1} ; \vec{\mu}_{\vec{\theta}} \left(\vec{T}_k, k\right), \vec{\Sigma}_{\vec{\theta}} \left(\vec{T}_k, k\right)\right).
    \label{eq:ddpm-reverse}
\end{equation}

Similar to variational autoencoders (VAEs), the training of diffusion models aims to maximize the log-likelihood function by optimizing the variational lower bound.
\begin{equation}
    L_{\mathrm{VLB}} = D_{\mathrm{KL}}\left(\vec{q}\left(\vec{T}_K | \vec{T}_0\right) \parallel \vec{p}_{\vec{\theta}}\left(\vec{T}_K\right)\right) + \sum_{k=2}^{K} L_{k} -\log \vec{p}_{\vec{\theta}}\left(\vec{T}_0 | \vec{T}_1\right),
    \label{eq:ddpm-loss}
\end{equation}
where $ L_k = D_{\mathrm{KL}}\left(\vec{q}\left(\vec{T}_{k-1} | \vec{T}_{k}, \vec{T}_0\right) \parallel \vec{p}_\theta\left(\vec{T}_{k-1} | \vec{T}_{k}\right)\right)$, $D_{\mathrm{KL}}$ is the KL divergence, and the term $\vec{q}\left(\vec{T}_{k-1} | \vec{T}_k, \vec{T}_0\right)$ can be derived a closed form of Gaussian distribution according to \Cref{eq:ddpm-forward} and Bayes' theorem.
% \begin{equation}
% \begin{aligned}
% q\left(\vec{T}_{k-1} | \vec{T}_k, \vec{T}_0\right)&=\frac{q\left(\vec{T}_k | \vec{T}_{k-1}, \vec{T}_0\right) q\left(\vec{T}_{k-1} | \vec{T}_0\right)}{q\left(\vec{T}_k | \vec{T}_0\right)}
% \end{aligned}
% \end{equation}


After training the diffusion model, we can simply sample from a standard Gaussian distribution and remove the noise in an iterative fashion according to \Cref{eq:ddpm-reverse} that follows the reverse diffusion process, resulting in new samples that follow the original sample distribution.

% Furthermore, in order to be able to apply diffusion models on discrete data for the corresponding generation task, the discrete denoising diffusion probability model (D3PM) was proposed by \cite{austin2021structured}, which defines the probability transition matrix $Q$ to replace the Gaussian probability distribution in the original diffusion model. The probability transition matrix $Q$ is used to describe the state transition probability between discrete variables at different times. D3PM has been shown to work well for the generation of natural images such as cifar10 \cite{austin2021structured}, by treating the pixel value of each pixel as a variable with 256 discrete states and defining the transition probability matrix as a discrete Gaussian matrix. 

% \begin{equation}
% \begin{aligned}
% L_{\mathrm{VLB}} & =L_K+L_{K-1}+\cdots+L_0 \\
% \text { where } L_K & =D_{\mathrm{KL}}\left(q\left(\vec{T}_K | \vec{T}_0\right) \parallel p_\theta\left(\vec{T}_K\right)\right) \\
% L_k & =D_{\mathrm{KL}}\left(q\left(\vec{T}_k | \vec{T}_{k+1}, \vec{T}_0\right) \parallel p_\theta\left(\vec{T}_k | \vec{T}_{k+1}\right)\right) \text { for } 1 \leq k \leq K-1 \\
% L_0 & =-\log p_\theta\left(\vec{T}_0 | \vec{T}_1\right)
% \end{aligned}
% \end{equation}

% \begin{equation}
% p_\theta\left(\mathbf{x}_{0: T}\right)=p\left(\mathbf{x}_T\right) \prod_{t=1}^T p_\theta\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t\right)
% \end{equation}
% \begin{equation}
% p_\theta\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t\right)=\mathcal{N}\left(\mathbf{x}_{t-1} ; \boldsymbol{\mu}_\theta\left(\mathbf{x}_t, t\right), \boldsymbol{\Sigma}_\theta\left(\mathbf{x}_t, t\right)\right)
% \end{equation}

% \todo{Add necessary explanation of following formulas}
% $$
% q\left(x_{t-1} \mid x_t, x_0\right)=\mathcal{N}\left(x_{t-1} ; \tilde{\mu}\left(x_t, x_0\right), \tilde{\beta_t} \mathbf{I}\right)
% $$

% $$
% \tilde{\mu}_t=\frac{1}{\sqrt{\bar{a}_t}}\left(x_t-\frac{\beta_t}{\sqrt{1-\bar{a}_t}} \bar{z}_t\right)
% $$

% $$
% \mu_\theta\left(x_t, t\right)=\frac{1}{\sqrt{\bar{a}_t}}\left(x_t-\frac{\beta_t}{\sqrt{1-\bar{a}_t}} z_\theta\left(x_t, t\right)\right)
% $$


%%% The advantages of the diffusion model compared to other models can be omitted if the space is not enough. %%%
% Due to its unique idea of adding noise and denoising, the diffusion model keeps latent variables of the same dimension as the input rather than embedding them in a lower dimension, which also makes the diffusion model have a larger feature representation space than the other generative models mentioned above. 
% In addition, unlike VAEs that require a trade-off between generative diversity and generative similarity, GANs whose training process is unstable due to adversarial training, and Flow-based models that require building complex reversible transformations and specific architectures, diffusion The model can directly use the general neural network architecture, and has a stable training loss function, while ensuring the diversity and similarity of the generated samples.

\subsection{Squish Pattern Representation}
\label{subsection:quish}

A typical layout pattern consists of a stack of polygons and is information-sparse, which leads to unnecessary computational costs and additional overfitting risk for neural network methods. The squish pattern \cite{gennari2014topology} is a lossless and efficient representation method which encodes a layout into pattern topology matrix and geometric information $\Delta_x,\, \Delta_y$, as shown in \Cref{fig:squishpattern}. The layout is split into grids by a set of scan lines that walk along the edges of polygons. The interval length of every adjacent scan line pair is stored in the $\Delta$ vectors. Every entry of the topology matrix is either zero or one, which indicates shape or zeros respectively. Every squish pattern is extended to a square with fixed side length by the method introduced in \cite{yang2019detecting}.
%To push model acceleration a step ahead, we proposed Deep Squish Pattern Representation, which has larger information density and is friendly to neural network. We will detail it in \Cref{subsec:compact}.


\begin{figure}[tb!]
    \centering
    \includegraphics[width=0.92\linewidth]{topology_009_.pdf}
    \caption{Squish Pattern Representation.}
    \label{fig:squishpattern}
\end{figure}

\subsection{Problem Formulation}
\label{sec:2.3}

%\noindent \textbf{Pattern Diversity}.
The diversity of generated patterns is a critical metric for the layout pattern generation task. As introduced in \cite{yang2019deepattern}, the complexity of a layout pattern is defined as $(c_x, c_y)$, where $c_x$ and $c_y$ are the numbers of scan lines subtracted by one along the x-axis and y-axis, respectively. Then we have,

%\noindent {\bf Pattern Diversity}
\begin{mydefinition}
The diversity of the patterns library, denoted by $H$, is defined as the Shannon Entropy of the distribution of the pattern complexities as follows:
\begin{equation}
    H = - \sum_i \sum_j P(c_{xi}, c_{yj})\log{P(c_{xi}, c_{yj})},
    \label{eq:diveristy}
\end{equation}
where $P(c_{xi}, c_{yj})$ is the probability of a pattern with complexity $(c_{xi}, c_{yj})$ sampled from the library.
\end{mydefinition}

In a typical case, a greater pattern diversity $H$ indicates that the library contains more widely distributed patterns.

%\textbf{Pattern Legality}.
Based on the related works \cite{zhang2020layout,wen2022layoutransformer}, the generated patterns should satisfy several pre-defined design rules of IC layout. As illustrated in \Cref{fig:drc_rule}, `Space' represents the distance between two adjacent polygons. `Width' measures the size of a shape in one direction. And `Area' denotes the area of a polygon. Based on these geometric measurements, we have,

\begin{mydefinition}[Pattern Legality]
We call a layout pattern {\it legal} if the layout pattern is DRC-clean, given the design rules.
\end{mydefinition}


\begin{figure}
    \centering
    \includegraphics[width=0.68\linewidth]{drc_rule_002_.pdf}
    \caption{Illustration of design rules.}
    \label{fig:drc_rule}
\end{figure}

%\noindent {\bf Pattern Validity}.
% When we aim to synthesis realistic patterns, we hope the generated patterns share similar local features with existing layout patterns. To evaluate how realistic the generated patterns are, \cite{zhang2020layout} defines pattern validity as,

% \begin{mydefinition}{Pattern Validity}
%     Pattern validity is the ratio of realistic patterns to total generated patterns. 
% \end{mydefinition}

% In \Cref{subsection:validity}, we gives the scheme to measure the validity of the given pattern set, and we further discuss the limitation of validity. 
Based on the above evaluation metrics, the pattern generation problem can be formulated as follows,

\begin{myproblem}[Pattern Generation]
    Given a set of design rules and existing patterns, the objective of pattern generation is to synthesize a legal pattern library such that the pattern diversity of the layout patterns in the library are maximized.
\end{myproblem}
