
\section{Conclusions}
We present \NAME, a new automatic text-to-image faithfulness evaluation metric using VQA. Compared with prior metrics, \NAME is fine-grained, interpretable, and better aligned with human judgments. Based on this metric, we introduce the \NAME v1.0, a large-scale text-to-image benchmark containing 4K prompts and 25K questions. We conduct a comprehensive study of current text-to-image models using \NAME v1.0 and highlight the limitations of current generative models.
We quantitatively show that current image generation models still struggle in counting, spatial relations, and composing multiple objects.
Finally, we conduct extensive analysis and human evaluation, demonstrating that \NAME is robust to different VQA models.
We hope \NAME will help evaluate future works on image generation, and become increasingly sophisticated as it is upgraded with new LM, QA, and VQA components.


\section{Acknowledgements}
We thank Zirong Ye, Cheng-Yu Hsieh, Oscar Michel, Enhao Zhang, Jiafei Duan, Weijia Shi, Jieyu Zhang, the TIAL group, the ARK group,  and the GRAIL lab at UW for their helpful feedback on this work.