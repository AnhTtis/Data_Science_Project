
This paper provides a review of some of the recent development of machine learning methods for stochastic optimal control and games, with a special focus on emerging applications of deep learning and reinforcement learning to these problems. Despite the rapidly growing number of recent works, many questions remain to be investigated further. We hope this survey can trigger interest and attract more researchers to work on this topic. Besides the material already reviewed in this survey, we outline a few research directions below.

First, most of the methods presented here lack full analysis on the theoretical side. The mathematical foundations of deep learning are attracting growing interest, and recent results could help analyze the methods described in this paper. The main motivation underlying the use of deep networks is their ability to cope with the curse of dimensionality. However, rigorously phrasing and proving such a statement has been done only in particular cases. Analyzing the generalization capability of neural networks is typically done by splitting the analysis into several types of errors, such as approximation, estimation, and optimization errors. Bounds on the approximation and estimation errors can generally be obtained based on the regularity of the function to be approximated, which can be difficult in the context of differential games. Furthermore, bounding the optimization error is even more challenging since it involves not only the definition of the game but also the optimization algorithm. Due to these difficulties, estimating these errors remains an open question for most methods discussed in this survey. 







From a practical viewpoint, an important question related to neural network-based methods is the choice of hyperparameters. The most obvious one is the architecture of the neural network. In many cases, a feedforward fully connected architecture provides good performances ({\it e.g.}, for deep BSDE, DBDP, Sig-DFP). However, in other cases ({\it e.g.}, DGM, RNN for problems with delay, as discussed in this survey), ad hoc architectures seem necessary to reach the best results. In any case, architectures undoubtedly play a crucial role in the performance of every deep learning method, and a careful design is, in general, what leads to state of the art results in high dimension. So far, most deep learning methods for differential games have focused on providing proof of concepts. Given these baselines, it is now a natural question to try more sophisticated architectures in order to achieve better numerical performance. %
Once the architecture is fixed, the hyperparameters of the optimization method need to be determined. For example, the initialization of the network parameters, the learning rate, and the mini-batch size are important factors ensuring fast convergence. Their role is crucial for training deep and sophisticated architectures. However, finding a systematic rule for choosing these hyperparameters a priori remains difficult. A popular approach to identify suitable ranges of values is to try several values and measure the empirical convergence speed on problems for which the solution is known, using either an analytical formula or another numerical method. The task is quite complex because the hyperparameters' influences are interdependent. For problems without benchmarks, finding good hyperparameters values is even more challenging. To the best of our knowledge, the literature does not yet provide a detailed understanding of how to choose hyperparameters and how to measure algorithms' performance without knowing benchmark solutions. We did not discuss this aspect in the present survey for brevity, but finding efficient heuristics is certainly an interesting direction. A related question is how to assess convergence of algorithms computing Nash equilibria in games, since the goal is to find a fixed point and not an optimizer. 


Regarding specific problems related to MFGs, a direction that has received little attention thus far is numerical methods that can work even when there is a common noise affecting the whole population. The type of difficulties that arise numerically is connected to the difficulty of solving such MFGs from a theoretical viewpoint. We have exposed the Sig-DFP method to tackle MFGs with common noise, focusing on mean-field interactions through moments. Common noise appears in applications, for instance, in the form of aggregate shocks in macroeconomics. Hence it is worth developing further machine learning algorithms to deal with MFGs with common noise and general interactions. So far, we lack efficient ways to parameterize, represent, and discretize probability measures defined on a continuous-state space.  

Another aspect related to concrete applications of the methods presented in this survey pertains to the resources needed to train deep neural networks. For model-based methods and even more for model-free reinforcement learning methods, sophisticated models typically need a vast number of training episodes, leading to two challenges. First, as the model complexity grows, the massive computational cost required to learn the solution becomes prohibitive. Second, for real-world applications, Monte Carlo simulations will be replaced by real data, but we generally have much fewer data points than the number of samples used by most deep learning methods described in this survey. It will thus be very interesting to design more sample-efficient methods and establish sharp estimates of their sample complexity. 


Last but not least, to the best of our knowledge, the methods presented in this survey have been applied only to relatively simple models for the purpose of academic research. But a significant motivation for the development of machine learning methods is that they will allow us to efficiently solve more realistic optimal control problems and games. We hope that this survey can contribute to fostering interactions between theoretical research and applied research communities, and lead to concrete applications in real-world problems. 
