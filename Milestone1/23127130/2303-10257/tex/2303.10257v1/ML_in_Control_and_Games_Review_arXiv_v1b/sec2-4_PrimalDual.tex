

The Deep BSDE method presented above tackles directly a BSDE, without making explicit use from the fact that, in our context, the BSDE comes from an optimal control problem. In this context and under suitable assumptions, we can rely on a dual formulation to introduce primal-dual deep learning methods. Such methods have been studied, {\it e.g.}, in~\cite{henrylabordere2017deep,benderschweizerzhuo2017primal,daveyzheng2020deep} and have applications to several problems in finance. 

Recall that the stochastic optimal control we consider is given by~\eqref{def:control-Xt}--\eqref{def:control-cost}. 
Using the aforementioned methods ({\it e.g.}, Deep BSDE or DBDP), it is generally hard to know how close to being optimal the neural network solution is. This is because we do not know \emph{a priori} the minimal cost. However, we are always sure that these methods provide an upper bound since, given any admissible control $\tilde\alpha$ ({\it e.g.}, in the form of a neural network as in the Deep BSDE method), we can compute $J(\tilde\alpha)$ which is at least as large as the infimum $J^* = \inf_{\alpha} J(\alpha)$. So to claim that $\tilde\alpha$ is almost optimal, it is enough to exhibit a lower bound on $J^*$ that is close to $J(\tilde\alpha)$.

Except in special cases, there is no analytical expression for a good lower bound, and traditional numerical methods might be inefficient if the problem is in high dimension. Fortunately, the optimal value can be computed through a dual problem which is formulated as a maximization problem and hence yields a lower bound.  We refer to {\it e.g.}~\cite{henrylabordere2016dual} for more details.

Formally, the dual problem can be expressed as
$$
    \sup_{\varphi} \EE\left[ \inf_{\alpha} \Phi^{\varphi,\alpha} \right],
$$
where
$$
    \Phi^{\varphi,\alpha} = g(X^\alpha_T) +  \int_0^T f(t, X^\alpha_t, \alpha_t) dt - \int_0^T \varphi(t, X^\alpha_t) \sigma(t, X_t^\alpha) \ud W_t,
$$
and the superscript $\alpha$ in $X_t^\alpha$ emphasizes the dependence on the control $\alpha$. Here the infimum over $\alpha$ is a pathwise optimization since it is inside the expectation. In some cases, it can be solved explicitly. Then we are left with a more standard optimal control problem with feedback control $\varphi$. The latter can be solved for instance using ideas similar to the ones presented in the previous sections such as the direct parameterization or the Deep BSDE method, see Sections~\ref{sec:control-direct} and~\ref{sec:BSDE}. We refer to {\it e.g.}~\cite{henrylabordere2017deep} for more details and numerical examples.
