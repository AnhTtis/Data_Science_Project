
In direct parameterization approaches as discussed above, the neural network is used to approximate the optimal control or the value function. The type of inputs depends on the class of controls considered in the optimal control problem. For Markovian controls, which are used in \cite{han2016deep-googlecitations} and \cite{bachouch2021deepnumerical}, the input shall be $\checkX_{t_n}$ for $\alpha_{t_n}(\cdot; \theta_n)$. For open-loop controls, one can naturally consider $(\check W_{t_0}, \ldots, \check W_{t_n})$, while for closed-loop controls, one can use $(\checkX_{t_0}, \ldots, \checkX_{t_n})$ as inputs of the neural network. 
However the sequence length increases with the number of time steps, which leads to a high computational cost. Furthermore, passing the whole sequence as a single input does not make use of the time structure. For these reasons, other architectures have been considered.


We now illustrate the direct parameterization methods by studying SC problems with delay. Such problems have found many applications, \textit{e.g.}, modeling systems with the aftereffect in mechanics and engineering, biology, and medicine \cite[Chapter 1]{kolmanovskiui1996control}, time-to-build problems in economics \cite{kydland1982time,asea1999time}, modeling the ``carryover'' or ``distributed lag''   advertising effect in marketing \cite{gozzi200513,gozzi2009controlled}, and portfolio selection under the market with memory and delayed responses in finance \cite{oksendal2000maximum,federico2011stochastic,elsanosi2001optimal,li2018portfolio}. 



Note that feedforward neural network (FNN) architecture is the most common architecture in deep learning and performs well as function approximators of Markovian controls. Another popular type of neural networks is recurrent neural networks (RNNs). In a study by Han and Hu \cite{han2020rnn}, it is shown that RNNs have better performance in control problems with a delay effect. 


To distinguish between the value of a process at a given time and the portion of trajectory ending at time $t$ with $\delta$ history, for any process $P$, we denote by $\underline P_t = (\underline P_t\bigl(s)\bigr)_{s \in [-\delta, 0]}$ the trajectory of $P$ from time $t-\delta$ to $t$, \emph{i.e.}, $\underline P_t(s) = P_{t+s}$, for $-\delta \leq s \leq 0$. Specifically, we consider a SC problem in which the state process $X$ is characterized by a stochastic delay differential equation (SDDE),
\begin{equation}\label{def:delay-Xt}
\begin{dcases}
    \ud X_t = b(t, \underline X_{t}, \ctrl_t) \ud t + \sigma(t, \underline X_t, \ctrl_t) \ud W_t,  & t \in [0, T],\\
    X_t = \varphi_t, & t \in [-\delta, 0],
\end{dcases}
\end{equation}
and the objective function is given by
\begin{equation}\label{def:delay-cost}
J(\alpha) = \EE\left[\int_0^T f(t, \underline X_t, \ctrl_t) \ud t  + g(\underline X_T)\right].
\end{equation}
Here $\delta \geq 0$ is the fixed delay, and $(\varphi_t)_{t \in [-\delta, 0]}$ is a given process on $[-\delta, 0]$ for the initial condition of $X$, and $X_t$ denotes the value of the state process at time $t$ as usual. The SDDE \eqref{def:delay-Xt} has been well studied in the literature \cite{mohammed1984stochastic,mohammed1998stochastic} (see also Appendix~\ref{supp:SDDE} some preliminaries on SDDEs).



The key difficulty is that, when optimizing over closed-loop controls, one should in principle take into account the whole trajectory of the state, which is computationally costly. The authors in \cite{han2020rnn} analyzed this problem with a focus on the deep neural networks' (DNNs) architecture design in order to handle the high-dimensionality arising from the delay. 
Without loss of generality, let us consider that the fixed delay $\delta <\infty$ covers $N_\delta$ subintervals, {\it i.e.}, $\delta = N_\delta \Delta t$,
the partition on $[0,T]$ is extended to $[-\delta, 0]$,
\begin{equation}
 \; -\delta = t_{-N_\delta} \leq t_{-N_\delta+1} \leq \ldots \leq t_0 = 0, \text{ with } t_{n+1} - t_n \equiv \Delta t, \; \forall n = -N_\delta, \ldots, -1.
\end{equation}
and the discretized version of \eqref{def:delay-Xt}--\eqref{def:delay-cost} becomes
\begin{align}
    & \check X_{t_{n+1}} = \check X_{t_n} + b(t_n, \check{\underline{X}}_{t_n}, \ctrl_{t_n}) \Delta t + \sigma(t_n, \check{\underline X}_{t_n}, \ctrl_{t_n}) \Delta \check W_{t_n}, \label{def:Xtdiscrete} \\
    & \inf_{\{\ctrl_{t_n}\}_{n=0}^{N_T-1}} \EE\left[\sum_{n=0}^{N_T-1} f(t_n, \check{\underline X}_{t_n}, \ctrl_{t_n}) \Delta t + g(\check {\underline X}_T)\right], \label{def:costdiscrete}
\end{align}
where for each $n$,  $\check {\underline X}_{t_n}$ represents the discrete path with $N_\delta$ lags and $\Delta \check W_{t_n}$ is the increment in Brownian motions,
\begin{equation}
    \check {\underline X}_{t_n} = (\check X_{t_{n-N_\delta}},\ldots, \check X_{t_n}), \quad \Delta \check W_{t_n} = \check W_{t_{n+1}} - \check W_{t_n}.
\end{equation}
Here $\ctrl_{t_n}$ is a function of time and the past state trajectory $\check{\underline X}_{t_n}$ taking values in $\RR^k$. 
The next two architectures are proposed for approximating $\ctrl_{t_n}$. 

\medskip

\noindent \textbf{Feedforward architecture.}
Motivated by the path-dependent structure of the considered problems (the change of current state only depends on the history up to lag $\delta$), a natural idea is to approximate $\ctrl_{t_n}$ by a feedforward neural network taking the state history up to lag $\bar{\delta}$ as the input. Note here it could be $\bar{\delta}\neq \delta$ since one may not know the underlying true $\delta$ a priori.
Without loss of generality, one can assume $\bar{\delta}=N_{\bar{\delta}}h~ (N_{\bar{\delta}}\in\mathbb{N}^+$) and define
$\bar{X}_{t_n} \equiv (\check X_{t_{n-N_{\bar{\delta}}}},\ldots, \check X_{t_n})\in \RR^{d\times (N_{\bar{\delta}}+1)}$. Then the control at time $t_n$ can be approximated by a feedforward fully connected network taking $\bar X_{t_n}$ as input. 

\medskip

\noindent\textbf{Recurrent architecture.} 
Alternatively, the sequence $\bar X_{t_n}$ can be processed by a recurrent neural network (RNN), such as a long-short term memory (LSTM) neural network. The basic principle of an RNN is that the elements of the sequence are processed one by one by applying the same neural network in a recurrent manner, and some information is saved between two applications until the output is calculated. Here, we can use a single RNN for all time steps. At time $t_n$, to produce the value of the control, it uses $\check{X}_{t_n}$ as an input, along with the information saved from the previous time step. We refer to Appendix~\ref{sec:RNNdetails} and Appendix~\ref{sec:LSTMdetails} for more details. 



\begin{remark}
Although for both feedforward neural networks and RNN, the input dimensions remains constant as $k$ changes, using the former requires prior knowledge of $\delta$. For the feedforward fully connected neural network, one feeds the discretized state values \eqref{def:Xtdiscrete} of length $N_{\bar\delta} + 1$, so to obtain the best performance, one needs to get a good estimate $\bar\delta$ of $\delta$ first. On the other hand, for the RNN, one only needs to provide the current state value $X_{t_n}$. Notice that in an LSTM all input information up to time $t_n$ is summarized by the $n^{th}$ cell, but if the optimal control depends only on the past up to $\delta$, the forget gates allows to drop out the unneeded information. The exact way information should be dropped is determined by the neural network parameters training. %
Though the authors in \cite{han2020rnn} only experimented LSTM, other variations of RNNs such as gated recurrent units (GRUs)~\cite{cho2014learning} or peephole LSTM~\cite{gers2002learning} can be considered. 

\end{remark}

Before illustrating the above method, we stress that other methods also exist. For example, \cite{lefebvre2021linear} uses a deep learning technique inspired by the physics-informed neural networks (PINNs) and applies it to solve a mean-variance portfolio selection with execution delay.




\paragraph*{Numerical illustration: a linear-quadratic regulator problem with delay.} 
LQ problems with delay was first investigated by Kolmanovski{\u{\i}} and Sha{\u{\i}}khet \cite{kolmanovskiui1996control}. In the version presented here, the aim is to minimize 
\begin{align}
&\EE_{\varphi} \left[\int_0^T (X_t + e^{\lambda \delta}A_3 Y_t)\transpose Q(t) (X_t + e^{\lambda \delta}A_3 Y_t) + \ctrl_t\transpose R(t)\ctrl_t\ud t \right.+ (X_T + e^{\lambda\delta} A_3Y_T)\transpose G (X_T + e^{\lambda\delta} A_3Y_T)\Bigg], \\
&\text{subject to } \ud X_t = (A_1(t)X_t + A_2(t)Y_t + A_3 Z_t + B(t)\ctrl_t) \ud t + \sigma(t) \ud W_t, \quad t  \in[0,T],\label{eq:lq}
\end{align}
where $X_0 = \varphi \in L^2(\Omega, C([-\delta, 0], \RR^d))$ is a given initial segment, $Y_t = \int_{-\delta}^0 e^{\lambda s} X_{t+s} \ud s$ is the distributed delay and $Z_t = X_{t-\delta}$ is the discrete delay,
$A_1, A_2, Q \in L^\infty([0,T]; \RR^{d\times d})$, $B \in L^\infty([0,T]; \RR^{d \times k})$, $R \in L^\infty([0,T]; \RR^{k\times k})$ are deterministic matrix-valued functions, $\sigma \in L^2([0,T]; \RR^{d \times m})$ is a deterministic matrix-valued function, $A_3, G \in \RR^{d \times d}$ are deterministic matrices. It is assumed that $Q(t), G$ are positive semi-definite and $R(t)$ is positive definite for all $t \in [0,T]$ and continuous on $[0,T]$. To have a tractable solution, a further relation is prescribed,
\begin{equation}\label{lq:parameters}
A_2(t) = e^{\lambda\delta}(\lambda I_d + A_1(t) + e^{\lambda\delta} A_3) A_3,
\end{equation}
where $I_d$ is the identity matrix with rank $d$. This example was studied in
\cite[Section 4]{bauer2005stochastic}, and the main results are also summarized in \cite{han2020rnn}. %

We present below results for a ten-dimensional example. The model parameters are chosen as follows. The dimensions are $d = k = m = 10$, and $\lambda=0.1$.
In~\eqref{eq:lq}, $A_1, A_3, B, \sigma$ are constant coefficient matrices (generated randomly), $Q, R, G$ are constant matrices proportional to identity matrices, and $A_2$ is determined by~\eqref{lq:parameters}. For implementation details, we refer to~\cite{han2020rnn}. The left panel of Figure~\ref{fig:lq_train_curve} displays the total cost on the validation data against training time. The values are averaged every 200 steps. The feedforward model takes the state history as inputs up to lag $\bar{\delta}=\delta$ with $N_{\bar{\delta}}=40$.
The right panel of Figure~\ref{fig:lq_train_curve} displays the optimized cost as a function of the processed lag time $\bar{\delta}$ from $0.2$ to $1$ with step size 0.1, while the actual lag $\delta=1$. If the chosen lag time $\bar{\delta}$ is smaller than the actual lag $\delta$ time, there is a loss of information when the feedforward network processes the data. As expected, we observe that the cost increases as the lag time processed by the feedforward model decreases. A higher optimized cost indicates that the model can only find a strictly sub-optimal strategy due to the lack of information.
Figure~\ref{fig:lq_path_lstm_shff} displays one sample path (first five dimensions only) of the optimal state $X$ and control $\ctrl$ provided by two neural networks in comparison with the analytical solution, in which the LSTM architecture presents a better agreement. 
The lag time $\bar{\delta}$ processed by the feedforward model is chosen to be the same as $\delta$.
One main drawback of the feedforward model is that it requires to know the true lag time $\delta$ a priori to determine the network's size. 


\begin{figure}[!htb]
\centering
\includegraphics[width=0.45\textwidth]{figure/lq-d10_train_curve.pdf}
\includegraphics[width=0.45\textwidth]{figure/lq-d10_shff_lag.pdf}
  \caption{The linear-quadratic regulator problem with delay in Section~\ref{sec:sc_delay}. Left: Training curve of two models in the example of linear-quadratic problem. Right: The effect of lag time $\bar{\delta}$ processed by the feedforward model in the example of linear-quadratic problem. The lag time $\delta$ in the actual system is $1$. %
  }
  \label{fig:lq_train_curve}
\end{figure}

\begin{figure}[!htb]
\centering
\includegraphics[width=0.98\textwidth, trim = {0, 18em, 0, 18em}, clip]{figure/lq-d10_lstm_path.pdf}\\
\includegraphics[width=0.98\textwidth,  trim = {0, 18em, 0, 18em}, clip]{figure/lq-d10_shff_path.pdf}
  \caption{The linear-quadratic regulator problem with delay in Section~\ref{sec:sc_delay}. 
      A sample path of the first 5 dimensions of the state $X_t$ and control $\ctrl_t$ obtained from the LSTM (top) model and FNN (top) model.
      Left: the optimal state process discretized from the analytical solution $(X_t)_i$ (solid lines) and its approximation $(\hat{X}_t)_i$ (dashed lines) provided by the approximating control, under the same realized path of Brownian motion.
      Right: comparisons of the optimal control $(\ctrl_t)_i$ (solid lines) and $(\hat{\ctrl}_t)_i$ (dashed lines). %
  }
  \label{fig:lq_path_lstm_shff}
\end{figure}




