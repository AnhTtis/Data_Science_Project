



















As seen in Definition~\ref{def:MFGeq-finitehorizon}, a mean-field equilibrium is a standard control problem (corresponding to the first item in the definition) plus a fixed point problem (corresponding to the second item). Motivated by MFG models with common noise,   
Min and Hu \cite{MinHu:21} proposed an algorithm called Sig-DFP utilizing the concept of signature in rough path theory \cite{LyonsTerryJ2007DEDb} and fictitious play from game theory \cite{Br:49,Br:51}. Signature is used to accurately represent the conditional distribution of the state given the common noise, and fictitious play is used to solve the fixed-point problem and identify the equilibrium \cite{cardaliaguet2015learning}.

For a path $x:[0,T]\to \RR^d$, the $p$-variation is defined by 
\begin{equation}
    \|x\|_{p} = \left( \sup_{D\subset[0,T]} \sum_{n=0}^{r-1} \|x_{t_{n+1}}-x_{t_n}\|^p \right)^{1/p},
\end{equation} 
where $D \subset [0,T]$ denotes a partition $0 \leq t_0 < t_1 < \ldots < t_r \leq T$. Let $T((\R^d))=\bigoplus_{k=0}^\infty (\R^d)^{\bigotimes k}$ be the tensor algebra. Let  $\mathcal{V}^p([0,T], \R^d)$ be the space of continuous mappings from $[0,T]$ to $\R^d$ with finite $p$-variation, equipped with norm $\|\cdot\|_{\mathcal{V}^p}=\|\cdot\|_{\infty}+\|\cdot\|_{p}$. 

\begin{defn}[Signature]
Let $X\in \mathcal{V}^p([0,T], \R^d)$ such that the following integral is well defined. The signature of $X$, denoted by $S(X)$, is the element of $T((\R^d))$ defined by $S(X) = (1, X^1, \cdots, X^k \cdots)$ with
\begin{equation}\label{def:signature}
    X^k = \int_{0<t_1<t_2<\cdots<t_k<T} \ud X_{t_1}\otimes\cdots\otimes \ud X_{t_k}.
\end{equation}
Denoting by $S^M(X)$ the truncated signature of $X$ of depth $M$, {\it i.e.}, $S^M(X) = (1, X^1, \cdots, X^M)$ which has the dimension $\frac{d^{M+1}-1}{d-1}$.
\end{defn}
In the current setting, $X$ is a semi-martingale, thus equation \eqref{def:signature} is understood in the Stratonovich sense. The signature has many nice properties, including the following ones. First, it characterizes paths uniquely up to the tree-like equivalence, and the equivalence is removed if at least one dimension of the path is strictly increasing \cite{boedihardjo2014signature}. Therefore, in practice one usually augments the original path $X_t$ with the time dimension, {\it i.e.}, working with $\hat{X}_t = (t, X_t)$ since $S(\hat{X})$ characterizes paths $\hat{X}$ uniquely. Second, terms in the signature present a factorial decay property \cite{lyons2002system}, which implies that a path can be well approximated with just a few terms in the signature ({\it i.e.}, a small $M$). Last, As a feature map of sequential data, the signature has a universality property \cite{NEURIPS2019_deepsig}, which is summarized below. 


    Let $p\ge 1$ and $f: \mathcal{V}^p([0,T], \R^d)\to \R$ be a continuous function. For any compact set $K\subset \mathcal{V}^p([0,T], \R^d)$, if $S(x)$ is a geometric rough path (see \cite[Definition 3.13]{LyonsTerryJ2007DEDb} for a detailed definition) for any $x\in K$, then for any $\eps >0$, there exists a linear functional $l$ in the dual space of  $\in T((\RR^d))$ such that
    \begin{equation}
        \sup_{x\in K} |f(x) - \langle l, S(x) \rangle| <\epsilon.
    \end{equation}

Motivated by the unique characterization of $(W_s^0)_{s \in [0,t]}$ by $S(\hat W_t^0)$ and the factorial decay property, one can approximate 
\begin{equation}
  \nu_t \equiv \mc{L}(X_t, \alpha_t \vert \mc{F}_t^0 ) = \mc{L}(X_t, \alpha_t \vert S(\hat W_t^0)), \label{eq:propbysig}
\end{equation}
by $\mc{L}(X_t, \alpha_t \vert S^M(\hat W_t^0))$, for $\hat W^0_t = (t, W^0_t)$. 
In particular, if the mean-field interaction is through moments $\bar\nu_t = \EE[\iota(X_t, \alpha_t) \vert \F_t^0]$, for some measurable function $\iota$, the approximation can be arbitrarily accurate for sufficiently large $M$, see \cite[Lemma 4.1]{MinHu:21}. Then \cite{MinHu:21} proposed to use the approximation
\begin{equation}\label{eq:mfg_cn_linearregression}
    \bar\nu_t \approx \langle \tilde l, S^M(\hat W_t^0) \rangle, \; \text{ where } \tilde l =  \argmin_{\bm\beta} \|\bm y - \bm X \bm\beta\|^2,  \;
    \bm y = \{\iota(X_t(\omega_i), \alpha_t(\omega_i))\}_{i=1}^N,\;    \bm X = \{S^M(\hat{W}^{0}_{t}(\omega_i))\}_{i=1}^N,
\end{equation}
where $\omega_i$ denotes the $i^{th}$ sample path. The rational behind this approximation is the universality of signatures and the interpretation of ordinary linear regression: the least square minimization gives the best possible prediction of $\EE[\bm y | \bm X]$ using linear relations. Once $\tilde l$ is obtained, the prediction on an unseen common noise is efficient: $\bar\nu_t(\tilde\omega)\approx \langle \tilde l, S^M(\hat{W}^0_{t}(\tilde\omega)) \rangle$ for any $\tilde \omega$ and $t$.


Then finding the mean-field equilibrium is broken down into the following steps. We start with an initial value $\bar\nu^{(0)}$. Then, we solve the standard control problem given $\bar\nu^{(0)}$ in \eqref{subchapRCML-num-eq:def-J-MFG} in the spirit of \cite{han2016deep-googlecitations}. From here, we approximate $\bar\nu^{(1)}$ via signature using \eqref{eq:mfg_cn_linearregression}, i.e., compute $\tilde l^{(1)}$. These steps are repeated until convergence. The update of $\bar\nu_t$ from step to step is done by averaging $\tilde l^{(n)}$. The Sig-DFP algorithm consists of repeatedly solving \eqref{eq:dyn-X-general-MFG}--\eqref{subchapRCML-num-eq:def-J-MFG} for a given $\bar\nu$ using deep learning in the spirit of \cite{han2016deep-googlecitations}, and passing the obtained $\bar\nu$ to the next iteration by using signatures. A flowchart illustrating the ideas is given in Figure~\ref{fig:algo}.

\begin{figure}
    \centering
    \includegraphics[width = 0.7\textwidth]{figure/algoGraph.png}
    \caption{Flowchart of one iteration in the Sig-DFP Algorithm. Input: idiosyncratic noise $W$, common noise $W^0$, initial position $X_0$ and vector $\hat{\nu}^{(\mt{k}-1)}$ from the last iteration. Output: vector $\hat{\nu}^{(\mt{k})}$ for the next iteration. %
    }
    \label{fig:algo}
\end{figure}

More precisely, at each step, given a proxy $\hat \nu^{(\mt{k-1})}$ of the equilibrium distribution $\hat \nu$, the problem \eqref{eq:dyn-X-general-MFG}--\eqref{subchapRCML-num-eq:def-J-MFG} becomes a standard stochastic control and is solved by using the direct parameterization approach reviewed in Section~\ref{sec:direct-global-local}: the loss function will be the discretized version of \eqref{subchapRCML-num-eq:def-J-MFG},  $\check X$ will be follow the Euler scheme of \eqref{eq:dyn-X-general-MFG} with $\nu$ replaced by $\hat \nu^{(\mt{k}-1)}$ and so do $f$ and $g$, and the control $\alpha_{t_n}$ is parameterized by a neural network of the following form
\begin{equation}
     \alpha_{t_n}= \alpha(t_{n}, \check X_{t_n}, \hat\nu^{(\mt{k}-1)}_{t_n}; \theta),
\end{equation}
which takes $\hat\nu^{(\mt{k}-1)}_{t_n}$ as an extra input on top of $(t_{n}, \check X_{t_n})$. 
The optimizer $\theta^\ast$ obtained in this way gives $\alpha_{t_n}^{(\mt k)}$, with which the optimized state process paths are simulated. The conditional law, denoted by $\nu^{(\mt k)}$, is approximated using signatures via \eqref{eq:mfg_cn_linearregression}. This finishes one iteration of fictitious play. Denote by $\tilde\nu^{(\mt k)}$ the approximation of $\nu^{(\mt k)}$, we then pass $\tilde\nu^{(\mt k)}$ to the next iteration via updating $\hat\nu^{(\mt k)} = \frac{1}{\mt k}\tilde\nu^{(\mt k)} + \frac{\mt k-1}{\mt k}\hat \nu^{(\mt k-1)}$ by averaging the coefficients obtained in \eqref{eq:mfg_cn_linearregression}. We summarize it in Algorithm \ref{alg:sig-dfp} in Appendix~\ref{supp:pseudocode}; see~\cite[Appendix B]{MinHu:21} for the implementation details. %








    






\begin{rem}[Theoretical analysis]
In \cite{MinHu:21} Min and Hu provided a proof of convergence of this algorithm showing that, under suitable assumptions, the difference between the $\mt{k}^{th}$ iteration solution and the mean-field equilibrium can be made arbitrarily small, provided that $\mt{k}$ is sufficient large and $\nu^{(\mt k)}$ can be approximated sufficiently well by truncated signatures.
\end{rem}




\paragraph*{Numerical illustration: MFG of optimal consumption and investment.}\label{sec:MFG-sig} 

We consider an extended heterogeneous MFG proposed by \cite{lacker2020many}, where agents interact via both states and controls. The setup is similar to \cite{LaZa:17} except for including consumption and using power utilities. Each agent's type is characterized by a random vector $\zeta=(\xi, \delta, \theta, b, \sigma, \sigma^0, \epsilon)$, and the optimization problem reads
\begin{equation}
        \sup_{\pi, c} \EE\biggl[ 
    \int_0^T U(c_t X_t(\Gamma_t m_t)^{-\theta}; \delta)\ud t + \epsilon U(X_T m^{-\theta}_T;\delta)
    \biggr],     
 \label{def: InvestConsumpValue}
\end{equation}
where 
$U(x; \delta) = \frac{1}{1-\frac{1}{\delta}}x^{1-\frac{1}{\delta}}$, $\delta\ne 1$, is the power utility function,
$X_t$ follows
\begin{equation}
    \ud X_t = \pi_t X_t(b \ud t + \sigma \ud W_t + \sigma^0 \ud W_t^0) - c_tX_t \ud t,  \label{def: InvestConsumpSDE}
\end{equation}
and $X_0 = \xi$. The processes $\Gamma_t = \exp\EE[\log c_t |\mcF^0_t]$ and $m_t = \exp\EE[\log X_t |\mcF^0_t]$ are the mean-field interactions from the control and state processes. Two constraints are posed: $X_t \geq 0$, $c_t \geq 0$.

The interpretation of this problem is as follows. There are infinitely many agents trade in a common investment horizon $[0,T]$, each invests between a bond (with constant return rate $r$) and a private stock with dynamics $\ud S_t/S_t = b \ud t + \sigma \ud W_t + \sigma^0\ud W_t^0$, and consume $c_t$ of his wealth at time $t$. The portion of wealth into $S_t$ is denoted by $\pi_t$. Assuming $r \equiv 0$ without loss of generality, the wealth process reads \eqref{def: InvestConsumpSDE}. Then each agent aims to maximize his utility of consumption plus his terminal wealth compared to his peers' averages $\Gamma_t$ and $m_t$. To relate it to the formulation \eqref{eq:dyn-X-general-MFG}--\eqref{subchapRCML-num-eq:def-J-MFG}, $\ctrl \equiv (\alpha^1, \ctrl^2) = (\pi, c)$ will be a 2D control with the constraint $\alpha^2_t \geq 0$, $b(t, x, \nu, \alpha) = b\alpha^1 x  - \alpha^2 x$, $\sigma(t, x, \nu, \alpha) = \sigma \alpha^1 x$, $\sigma^0(t, x, \nu, \alpha) = \sigma^0 \alpha^1 x$, $f = -U$ and $g = -U$. The explicit solutions is derived in \cite{lacker2020many} and also summarized in \cite[Appendix D]{MinHu:21}.

For this experiment, we use truncated signatures of depth $M=4$. The optimal controls $(\pi_t, c_t)_{0\le t\le 1}$ are parameterized by two neural networks $\pi(\cdot; \theta)$ and $c(\cdot; \theta)$, each with three hidden layers of size 64 and taking $(\zeta, t, X_t, m_t, \Gamma_t)$ as inputs due to the nature of heterogeneous extended MFG. Due to the extended mean-field interaction term $\Gamma_t$, we will propagate two conditional distribution flows, {\it i.e.}, two linear functionals $\hat {l}^{(\mt{k})}, \hat {l}_c^{(\mt{k})}$ during each iteration of fictitious play. Instead of estimating $m_t, \Gamma_t$ directly, we estimate $\EE[\log X_t|\mcF^0_t], \EE[\log c_t|\mcF^0_t]$ by $\langle \hat {l}^{(\mt{k})}, S^4(W_t^0) \rangle$, $\langle \hat{l}_c^{(\mt{k})}, S^4(W_t^0) \rangle$ and then take exponential to get $m_t, \Gamma_t$. To ensure the non-negativity condition of $X_t$, we evolve $\log X_t$ and then take exponential to get $X_t$. For optimal consumption, $c(\cdot; \theta)$ is used to predicted $\log c_t$ and thus $\exp c(\cdot; \theta)$ gives the predicted $c_t$. With 600 iterations of fictitious play and a learning rate of 0.1 decaying by a factor of 5 for every 200 iterations, the relative $L^2$ errors for $\pi_t, c_t, m_t, \Gamma_t$ are 0.1126, 0.0614, 0.0279, 0.0121, respectively. Figure \ref{fig:OCI} compares $X$ and $m$ to their approximations, and plots the maximized utilities. Further comparison with the existing literature, different choices of truncation $M$, and the ability to deal with higher $m_0$ are also discussed in \cite{MinHu:21}. 




\begin{figure}[hbt!]
    \centering
    \subfloat[$X_t$]{
         \includegraphics[width=0.32\columnwidth]{figure/InvestConsumption/SDE.pdf}
     }
     \subfloat[$m_t =  \exp\EE(\log X_t |\mcF^B_t)$]{
         \includegraphics[width=0.32\columnwidth]{figure/InvestConsumption/Xbar.pdf}
     }
     \subfloat[Maximized Utility]{
         \includegraphics[width=0.32\columnwidth, trim = {0em 15em 0 10em}]{figure/InvestConsumption/valid_util2.pdf}}
    
    \caption{MFG of optimal consumption and investment in Section~\ref{sec4_MFG_with_CN}. Panels (a) and (b) give three trajectories of $X_t$ and $m_t=\exp\bigl(\EE(\log X_t |\mcF^0_t)\bigr)$ (solid lines) and their approximations $\hat X_t$ and $\hat m_t$ (dashed lines) using different $(X_0, W, W^0)$ from validation data. Panel (c) shows the maximized utility computed using validation data over fictitious play iterations. Parameter choices are: $\delta \sim U(2, 2.5), b \sim U(0.25, 0.35), \sigma\sim U(0.2, 0.4), \theta, \xi \sim U(0,1), \sigma^0\sim U(0.2, 0.4)$, $\epsilon\sim U(0.5, 1)$. %
    }
    \label{fig:OCI}
\end{figure}











