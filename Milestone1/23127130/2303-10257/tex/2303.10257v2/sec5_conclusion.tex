
This paper reviews recent developments in machine learning methods for stochastic optimal control and games, with a special focus on emerging applications of deep learning and reinforcement learning to these problems. Despite the rapidly growing number of recent works, many questions remain to be investigated further. We hope this survey will generate more interest in this topic and attract more researchers to work on it. Besides the material already reviewed in this survey, we outline a few research directions below.


First, the main goal of this survey was to provide an overview of existing methods, with a harmonized presentation of the types of problems studied in this field. However, the literature still lacks unified and thorough comparison of all existing methods on common benchmark problems. Indeed, most existing works use different assumptions for the their theoretical analysis and, on the numerical side, focus on illustrating the performance of one method on examples which are not necessarily the same as examples considered in other works. To understand better in which case each method is the most suitable, it would be important to provide a detailed comparison of the assumptions required for the analysis and to perform rigorous numerical comparisons on common problems.

Most of the methods presented here lack full analysis on the theoretical side. The mathematical foundations of deep learning are attracting growing interest, and recent results could help analyze the methods described in this paper. The main motivation underlying the use of deep networks is their ability to cope with the curse of dimensionality. However, rigorously phrasing and proving such a statement has only been done in particular cases. Analyzing the generalization capability of neural networks is typically done by splitting the analysis into several types of errors, such as approximation, estimation, and optimization errors. Bounds on the approximation and estimation errors can generally be obtained based on the regularity of the function to be approximated, which can be difficult in the context of differential games. Furthermore, bounding the optimization error is even more challenging since it involves not only the definition of the game but also the optimization algorithm. Due to these difficulties, estimating these errors remains an open question for most methods discussed in this survey. 







From a practical viewpoint, an important question related to neural network-based methods is the choice of hyperparameters. The most obvious one is the architecture of the neural network. In many cases, a feedforward fully connected architecture provides good performances ({\it e.g.}, for deep BSDE, DBDP, Sig-DFP). However, in other cases ({\it e.g.}, DGM, RNN for problems with delay, as discussed in this survey), ad hoc architectures seem necessary to reach the best results. In any case, architectures undoubtedly play a crucial role in the performance of every deep learning method, and a careful design is, in general, what leads to state-of-the-art results in high dimensions. However, most deep learning methods for differential games presented in this survey have been limited to proof of concepts. As such, exploring more sophisticated architectures is a natural progression towards achieving better numerical performance. Once the neural network architecture is fixed, the next important step is to determine the hyperparameters of the optimization method, such as the initialization of network parameters, the learning rate, and the mini-batch size, which are crucial factors for ensuring fast convergence. However, finding a systematic rule for choosing these hyperparameters {\it a priori} remains a challenge. A common approach is to try several values and measure the empirical convergence speed on problems for which the solution is known, using either an analytical formula or another numerical method. This task is complex due to the interdependent influences of hyperparameters. For problems without benchmarks, finding suitable hyperparameters is even more challenging. To the best of our knowledge, the literature does not yet provide a comprehensive understanding of how to choose hyperparameters and measure algorithm performance without benchmark solutions. Although we did not discuss this aspect in the present survey, finding efficient heuristics for hyperparameter tuning is certainly an interesting direction. Another related question is how to assess the convergence of algorithms that compute Nash equilibria in games since the objective is to find a fixed point, not an optimizer.


A direction that has received little attention thus far regarding specific problems related to MFGs is numerical methods that can work even when a common noise affects the entire population. The difficulties that arise numerically are connected to the difficulty of solving such MFGs from a theoretical viewpoint. We have presented the Sig-DFP method to tackle MFGs with common noise, focusing on mean-field interactions through moments. Common noise appears in applications, for instance, in the form of aggregate shocks in macroeconomics. Therefore, it is worth developing further machine learning algorithms to deal with MFGs with common noise and general interactions. Currently, we lack efficient ways to parameterize, represent, and discretize probability measures defined on a continuous-state space.

Another aspect related to concrete applications of the methods presented in this survey pertains to the resources needed to train deep neural networks. For model-based methods and even more for model-free reinforcement learning methods, sophisticated models typically need a vast number of training episodes, leading to two challenges. First, as the model complexity grows, the massive computational cost required to learn the solution becomes prohibitive. Second, for real-world applications, Monte Carlo simulations will be replaced by real data, but we generally have much fewer data points than the number of samples used by most deep learning methods described in this survey. Therefore, it will be very interesting to design more sample-efficient methods and establish sharp estimates of their sample complexity. 


Last but not least, to the best of our knowledge, the methods presented in this survey have only been applied to relatively simple models for academic research purposes. However, a significant motivation for the development of machine learning methods is to enable us to efficiently solve more realistic optimal control problems and games. We hope that this survey can contribute to fostering interactions between theoretical research and applied research communities, leading to concrete applications in real-world problems.
