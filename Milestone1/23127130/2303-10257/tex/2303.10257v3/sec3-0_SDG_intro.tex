

The previous section is dedicated to studying how a single agent makes strategic decisions in a random environment. This section will focus on stochastic differential games, which model and analyze the interactions between multiple rational agents in a dynamical random system; see \textit{e.g.}~\cite{bacsar1986tutorial,isaacs1999differential,yong2014differential,carmona2016lectures}, and \cite[Chapter 16]{bensoussan2018estimation} for more background on differential games. In games, an important concept is the so-called Nash equilibrium, which refers to a situation in which no one has an incentive to deviate. Finding a Nash equilibrium is one of the core problems in noncooperative game theory. However, the computation of Nash equilibria is extremely time-consuming and memory-demanding for large populations of players \cite{DaGoPa:2009}. 

When the number of player $N$ becomes extremely large, the recently developed theory of mean-field game (MFG)  \cite{HuMaCa:06,HuCaMa:07,LaLi1:2006,LaLi:2007} provides an approximation to $N$-player Nash equilibria if individuals interact symmetrically \cite{CaDe:13}. Despite the huge model reduction from modeling $N$ players to 
one representative player interacting with the population distribution, the MFG itself is still hard to solve numerically if this representative player's state is in a high-dimensional space, or if its evolution involves delay features, common noise, or complicated constraints. 


A rich literature on game theory has been developed to study the consequences of strategies on interactions between a large group of rational ``agents'', {\it e.g.}, system risk caused by inter-bank borrowing and lending \cite{CaFoSu:15}, price impacts imposed by agents' optimal liquidation \cite{cardaliaguet2017mean}, market price from the monopolistic competition, and optimal investment with relative performance concerns \cite{LaZa:17,lacker2020many,hu2021n}. This makes it crucial to develop efficient theory and fast algorithms for computing Nash equilibria of $N$-player stochastic differential games and MFGs. 


Various numerical methods for differential games have been proposed in the literature. In particular, some of the classical methods for stochastic optimal control problems mentioned at the end of Section~\ref{sec:control_intro} have been extended to treat games, since each player needs to solve an optimal control problem. Differential games typically leads to systems of HJ or HJB equations, which can be tackled using classical numerical schemes for PDEs ({\it e.g.} ~\cite{falcone2006numerical,bardi1999stochastic}). The case of pursuit-evation games has attracted particular attention and leads to Hamilton-Jacobi-Isaacs equations, which can also be treated using classical methods such as semi-Lagrangian schemes ({\it e.g.}~\cite{bardi1999numerical}). Nash equilibria can also be characterized using systems of FBSDEs, which can be solved numerically by adapting existing methods for FBSDEs ({\it e.g.}~\cite{exarchos2019stochastic}). The Markov chain approximation method for optimal control problems has also been extended to games in various settings~\cite{kushner2002numerical,kushner2004numerical,kushner2007numerical}. Besides classical differential games, MFGs have also attracted a growing interest from the numerical viewpoint. Numerical methods to solve the PDE system typically rely on a finite-difference scheme introduced by Achdou {\it et al.}~\cite{MR2679575,MR3097034}; extensions include~\cite{achdouKobeissi2020mfgcfinitediff} for MFGs of control and~\cite{camilli2021approximation} for MFGs-type systems with time-fractional derivatives. Semi-Lagrangian schemes have also been investigated~\cite{MR3148086,MR3392626,MR3828859}. A scheme based on Markov chain approximation has been proposed in~\cite{bayraktar2018numerical}. When the MFG is of variational form, optimization methods can be applied; see~\cite{MR3395203,MR3772008,MR3731033,BricenoAriasetalCEMRACS2017}.


As discussed in the previous sections, deep neural networks with many layers have been shown to solve efficiently stochastic control problems.  
These deep learning techniques also brought the possibility of computing equilibria in high-dimensional games, although extra difficulties arise since in general Nash equilibria are fixed point problems and are not optimization problems. 

Next, we review deep learning algorithms for solving stochastic (moderately large) $N$-player games, and mean-field games as an approximation for extremely large $N$-player games. In particular, the strategy of {\it deep fictitious play}, which integrates fictitious play (a learning scheme in game theory \cite{Br:49,Br:51}) into deep neural network designs, will be used frequently to develop parallelizable deep learning algorithms for computing Nash equilibria of stochastic differential games.
