To conclude this part of the survey, we discuss PDE-based approaches. As discussed in Section~\ref{sec:control_intro}, the optimal control can be identified by solving the corresponding HJB equation \eqref{def:control-HJB}.

The Deep Galerkin Method (DGM) proposed by Sirignano and Spiliopoulos \cite{SiSp:18} aims at approximating the solution of the parabolic PDE with a deep neural network. In fact, the DGM can tackle PDEs of other (potentially nonlinear) types, with terminal (or initial) condition and boundary conditions. To focus on the main ideas, we present the algorithm for a generic PDE on a spatial domain $\dom \subseteq \RR^d$ and a time interval $[0,T]$,
\begin{equation}
\begin{cases}
     \partial_t u(t, x) + \mc{L}u(t, x) = 0, \quad (t, x) \in [0,T] \times \dom , \\
    u(T, x) = u_T(x), \quad x \in \dom , \\
    u(t, x) = \Gamma(t, x), \quad x \in [0,T] \times \partial \dom.
\end{cases}
\end{equation}
Here $\mc{L}$ is an operator in $x$, possibly nonlinear. A Dirichlet boundary condition is considered although other boundary conditions (Neumann, Robin) can also be treated in this framework.  

The DGM algorithm proposes to replace  $u$ by a deep neural network, denoted by $u(t, x; \theta)$, and minimizes the following loss function
\begin{align}
\label{eq:loss-DGM-HJB-PDE} 
    J(\theta) 
    &= \eta \left\| \partial_t u(t, x;\theta)  + \mc{L}u(t, x; \theta) \right\|^2_{L^2([0,T] \times \dom; \mu_1)} 
    + \eta_I \left\| u(T, x; \theta) - u_T(x) \right\|^2_{L^2(\dom; \mu_2)} \\
    &\quad + \eta_{BC} \left\| u(t, x ;\theta) - \Gamma(t, x) \right\|^2_{L^2([0,T] \times \partial\dom; \mu_3)},
\end{align}
where $\mu_i$, $i=1,2,3$, are probability distributions on the corresponding domains, and $\|f(y)\|^2_{L^2(\mc{Y}; \mu)} = \int_{\mc{Y}} |f(y)|^2 \mu(\ud y)$. The first term is for the PDE residual, the second one is for the terminal condition and the third term is for the boundary condition. The positive constants $\eta, \eta_I$ and $\eta_{BC}$ give more or less importance to each component. The differential operators $\partial_t u(t, x; \theta)$ and $\mc{L}u(t, x; \theta)$ can be computed exactly using automatic differentiation.  However, most of the time, the second derivatives are computationally costly of $\mc{O}(d^2 \times N_{\mathrm{Batch}})$ and third-order  derivatives $\grad_\theta \Hess_x u(t, x; \theta)$ are also needed for SGD algorithms. A fast computation of second derivatives using a Monte Carlo method was proposed in \cite[Section 3]{SiSp:18}.  The squared $L^2$ norm of each term in \eqref{eq:loss-DGM-HJB-PDE} is calculated as the average of the squared value evaluated at random points drawn according to respective probability densities. Then we use SGD (see Algorithm~\ref{algo:SGD-generic}) to minimize the loss function $J$ defined in~\eqref{eq:loss-DGM-HJB-PDE}. One sample is $\xi = ((t,x), x', x'') \in ([0,T] \times \dom) \times \dom \times \partial\dom$, picked according to the distribution $\mu_1 \otimes \mu_2 \otimes \mu_3$. 

When applying the DGM to the HJB equation \eqref{def:control-HJB} associated with the control problem \eqref{def:control-Xt}--\eqref{def:control-cost}, one uses the terminal condition $u_T(x) = g(x)$ and omits the boundary condition if none is present. 


\begin{remark}
 
The DGM method can, at least in principle, be applied to a large variety of PDEs. Its flexibility is a key advantage. However, many choices need to be made in practice when implementing this method. First, the sampling distributions $(\mu_i)_{i=1,2,3}$  strongly influence the training process and thus the learned function. Choosing a suitable distribution inside the domain and on its boundary is sometimes not trivial, particularly since one needs to sample from this distribution efficiently. Furthermore, when dealing with a loss function composed of several terms (as {\it e.g.}~\eqref{eq:loss-DGM-HJB-PDE}), balancing the various terms can be challenging but is important to ensure that no term dominates the loss or is obliterated by the other terms. If some weight is too small, the neural network will tend to neglect the corresponding term. On the other hand, if some weight is much larger than needed, it will obfuscate the other terms. Overall, the choice of suitable coefficients seems important to efficiently guide the neural network towards a good local minimum. 

BSDE-based algorithms, as introduced in Section~\ref{sec:BSDE}, also necessitate the selection of a sampling distribution. In the global in time approach, this translates into the choice of the forward process. In the local in time approach, one needs to choose how to sample points during training at each time step. However, these methods do not require domain truncation. Monte Carlo simulations are naturally driven by the realizations of the Brownian motion path.
\end{remark}  




\begin{remark}[Theoretical analysis]
    Sirignano and Spiliopoulos showed in~\cite[Theorems 7.1 and 7.3]{SiSp:18}, assuming that the PDE is quasilinear parabolic and has a smooth enough solution, that for any level $\epsilon$, there exists a wide-enough neural network that can make the $L^2$ error $J(\theta)$ smaller than $\epsilon$. They also show, under stronger conditions, how one can obtain a sequence of neural networks converging to the PDE solution. To the best of our knowledge, the convergence of this algorithm remains to be studied for more general PDEs.

\end{remark}


The DGM can be applied to PDE system characterizing solutions to mean-field control problems; see~\cite{carmona2019convergence1} in the ergodic setting. For MFC (see Section~\ref{sec:directMethod}) with nonsmooth costs, Reisinger,  Stockinger and Zhang \cite{reisinger2021fast} developed an iterative algorithm  incorporating the gradient information and the proximal map of the nonsmooth cost. We will explain how to adapt the DGM to PDE systems when discussing applications to MFGs in Section~\ref{sec:MFPDE-deeplearning}. 


The DGM has also been extended to deal with path-dependent PDEs in~\cite{saporitoZhang2021PDGM}, which used an LSTM network to capture the dependence on the path, and then passed this information to a feed-forward network in charge of learning the PDE solution. It has also been extended to address HJB equations, solving for both the value function and the optimal control simultaneously and characterizing both as deep neural networks \cite{al2022extensions, barnett2023deep, duarte2024machine}. Other closely related works are the physics-informed neural networks (PINNs)~\cite{raissi2019physics}, which is introduced to approximate solutions to equations arising in physics; and the deep Ritz method \cite{yu2018deep} which solves variational problems that arise from PDEs. The key idea is, here again, to look for the solution to the equation among a class of neural networks. The error analysis has been discussed in \cite{van2022optimally,mishra2022estimates,de2022error,de2022error2,de2022generic,mishra2022estimates2} for various types of PDEs and operators. 