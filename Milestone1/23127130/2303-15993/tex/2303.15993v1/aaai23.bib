@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}


@inproceedings{song2015tvsum,
  title={Tvsum: Summarizing web videos using titles},
  author={Song, Yale and Vallmitjana, Jordi and Stent, Amanda and Jaimes, Alejandro},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5179--5187},
  year={2015}
}

@inproceedings{gygli2014creating,
  title={Creating summaries from user videos},
  author={Gygli, Michael and Grabner, Helmut and Riemenschneider, Hayko and Gool, Luc Van},
  booktitle={European conference on computer vision},
  pages={505--520},
  year={2014},
  organization={Springer}
}

@inproceedings{smeaton2006evaluation,
  title={Evaluation campaigns and TRECVid},
  author={Smeaton, Alan F and Over, Paul and Kraaij, Wessel},
  booktitle={Proceedings of the 8th ACM international workshop on Multimedia information retrieval},
  pages={321--330},
  year={2006}
}

@article{soomro2012ucf101,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={arXiv preprint arXiv:1212.0402},
  year={2012}
}

@inproceedings{otani2019rethinking,
  title={Rethinking the evaluation of video summaries},
  author={Otani, Mayu and Nakashima, Yuta and Rahtu, Esa and Heikkila, Janne},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7596--7604},
  year={2019}
}

@inproceedings{tran2018closer,
  title={A closer look at spatiotemporal convolutions for action recognition},
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={6450--6459},
  year={2018}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}

@inproceedings{zhang2016video,
  title={Video summarization with long short-term memory},
  author={Zhang, Ke and Chao, Wei-Lun and Sha, Fei and Grauman, Kristen},
  booktitle={European conference on computer vision},
  pages={766--782},
  year={2016},
  organization={Springer}
}

@InProceedings{Mahasseni_2017_CVPR,
author = {Mahasseni, Behrooz and Lam, Michael and Todorovic, Sinisa},
title = {Unsupervised Video Summarization With Adversarial LSTM Networks},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}

@InProceedings{Cai_2018_ECCV,
author = {Cai, Sijia and Zuo, Wangmeng and Davis, Larry S. and Zhang, Lei},
title = {Weakly-supervised Video Summarization using Variational Encoder-Decoder and Web Prior},
booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
}

@inproceedings{jung2020global,
  title={Global-and-local relative position embedding for unsupervised video summarization},
  author={Jung, Yunjae and Cho, Donghyeon and Woo, Sanghyun and Kweon, In So},
  booktitle={European Conference on Computer Vision},
  pages={167--183},
  year={2020},
  organization={Springer}
}

@inproceedings{liu2020transforming,
  title={Transforming multi-concept attention into video summarization},
  author={Liu, Yen-Ting and Li, Yu-Jhe and Wang, Yu-Chiang Frank},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  year={2020}
}

@inproceedings{zhou2018deep,
  title={Deep reinforcement learning for unsupervised video summarization with diversity-representativeness reward},
  author={Zhou, Kaiyang and Qiao, Yu and Xiang, Tao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  year={2018}
}

@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@inproceedings{mahasseni2017unsupervised,
  title={Unsupervised video summarization with adversarial lstm networks},
  author={Mahasseni, Behrooz and Lam, Michael and Todorovic, Sinisa},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={202--211},
  year={2017}
}

@inproceedings{jung2019discriminative,
  title={Discriminative feature learning for unsupervised video summarization},
  author={Jung, Yunjae and Cho, Donghyeon and Kim, Dahun and Woo, Sanghyun and Kweon, In So},
  booktitle={Proceedings of the AAAI Conference on artificial intelligence},
  volume={33},
  pages={8537--8544},
  year={2019}
}

@article{apostolidis2020ac,
  title={Ac-sum-gan: Connecting actor-critic and generative adversarial networks for unsupervised video summarization},
  author={Apostolidis, Evlampios and Adamantidou, Eleni and Metsai, Alexandros I and Mezaris, Vasileios and Patras, Ioannis},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={31},
  number={8},
  pages={3278--3292},
  year={2020},
  publisher={IEEE}
}

@article{agarap2018deep,
  title={Deep learning using rectified linear units (relu)},
  author={Agarap, Abien Fred},
  journal={arXiv preprint arXiv:1803.08375},
  year={2018}
}

@article{Hendrycks2016GaussianEL,
  title={Gaussian Error Linear Units (GELUs)},
  author={Dan Hendrycks and Kevin Gimpel},
  journal={arXiv: Learning},
  year={2016}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{DBLP:journals/corr/abs-2106-01345,
  author    = {Lili Chen and
               Kevin Lu and
               Aravind Rajeswaran and
               Kimin Lee and
               Aditya Grover and
               Michael Laskin and
               Pieter Abbeel and
               Aravind Srinivas and
               Igor Mordatch},
  title     = {Decision Transformer: Reinforcement Learning via Sequence Modeling},
  journal   = {CoRR},
  volume    = {abs/2106.01345},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.01345},
  eprinttype = {arXiv},
  eprint    = {2106.01345},
  timestamp = {Thu, 10 Jun 2021 16:34:18 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-01345.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1809-04281,
  author    = {Cheng{-}Zhi Anna Huang and
               Ashish Vaswani and
               Jakob Uszkoreit and
               Noam Shazeer and
               Curtis Hawthorne and
               Andrew M. Dai and
               Matthew D. Hoffman and
               Douglas Eck},
  title     = {An Improved Relative Self-Attention Mechanism for Transformer with
               Application to Music Generation},
  journal   = {CoRR},
  volume    = {abs/1809.04281},
  year      = {2018},
  url       = {http://arxiv.org/abs/1809.04281},
  eprinttype = {arXiv},
  eprint    = {1809.04281},
  timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1809-04281.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Arnab2021ViViTAV,
  title={ViViT: A Video Vision Transformer},
  author={Anurag Arnab and Mostafa Dehghani and Georg Heigold and Chen Sun and Mario Lucic and Cordelia Schmid},
  journal={2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021},
  pages={6816-6826}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff and others},
  journal={arXiv preprint arXiv:1503.02531},
  volume={2},
  number={7},
  year={2015}
}

@inproceedings{zhang2019fast,
  title={Fast human pose estimation},
  author={Zhang, Feng and Zhu, Xiatian and Ye, Mao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3517--3526},
  year={2019}
}

@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}


@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{grill2020bootstrap,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21271--21284},
  year={2020}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@inproceedings{chen2021exploring,
  title={Exploring simple siamese representation learning},
  author={Chen, Xinlei and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15750--15758},
  year={2021}
}

@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9650--9660},
  year={2021}
}

@inproceedings{li2021weakly,
  title={Weakly supervised deep reinforcement learning for video summarization with semantically meaningful reward},
  author={Li, Zutong and Yang, Lei},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3239--3247},
  year={2021}
}


@inproceedings{fu2019attentive,
  title={Attentive and adversarial learning for video summarization},
  author={Fu, Tsu-Jui and Tai, Shao-Heng and Chen, Hwann-Tzong},
  booktitle={2019 IEEE Winter Conference on applications of computer vision (WACV)},
  pages={1579--1587},
  year={2019},
  organization={IEEE}
}

@inproceedings{zhang2019dtr,
  title={Dtr-gan: Dilated temporal relational adversarial network for video summarization},
  author={Zhang, Yujia and Kampffmeyer, Michael and Zhao, Xiaoguang and Tan, Min},
  booktitle={Proceedings of the ACM Turing Celebration Conference-China},
  pages={1--6},
  year={2019}
}

@inproceedings{apostolidis2020unsupervised,
  title={Unsupervised video summarization via attention-driven adversarial learning},
  author={Apostolidis, Evlampios and Adamantidou, Eleni and Metsai, Alexandros I and Mezaris, Vasileios and Patras, Ioannis},
  booktitle={International Conference on multimedia modeling},
  pages={492--504},
  year={2020},
  organization={Springer}
}

@article{li2021exploring,
  title={Exploring global diverse attention via pairwise temporal relation for video summarization},
  author={Li, Ping and Ye, Qinghao and Zhang, Luming and Yuan, Li and Xu, Xianghua and Shao, Ling},
  journal={Pattern Recognition},
  volume={111},
  pages={107677},
  year={2021},
  publisher={Elsevier}
}

@article{Zhao2017HierarchicalRN,
  title={Hierarchical Recurrent Neural Network for Video Summarization},
  author={Bin Zhao and Xuelong Li and Xiaoqiang Lu},
  journal={Proceedings of the 25th ACM international conference on Multimedia},
  year={2017}
}

@article{ji2019video,
  title={Video summarization with attention-based encoder--decoder networks},
  author={Ji, Zhong and Xiong, Kailin and Pang, Yanwei and Li, Xuelong},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={30},
  number={6},
  pages={1709--1717},
  year={2019},
  publisher={IEEE}
}

@article{Szegedy2015GoingDW,
  title={Going deeper with convolutions},
  author={Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott E. Reed and Dragomir Anguelov and D. Erhan and Vincent Vanhoucke and Andrew Rabinovich},
  journal={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2015},
  pages={1-9}
}

@inproceedings{Noroozi2016UnsupervisedLO,
  title={Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles},
  author={Mehdi Noroozi and Paolo Favaro},
  booktitle={ECCV},
  year={2016}
}

@article{Gidaris2018UnsupervisedRL,
  title={Unsupervised Representation Learning by Predicting Image Rotations},
  author={Spyros Gidaris and Praveer Singh and Nikos Komodakis},
  journal={ArXiv},
  year={2018},
  volume={abs/1803.07728}
}

@inproceedings{Larsson2016LearningRF,
  title={Learning Representations for Automatic Colorization},
  author={Gustav Larsson and Michael Maire and Gregory Shakhnarovich},
  booktitle={ECCV},
  year={2016}
}

@article{He2020MomentumCF,
  title={Momentum Contrast for Unsupervised Visual Representation Learning},
  author={Kaiming He and Haoqi Fan and Yuxin Wu and Saining Xie and Ross B. Girshick},
  journal={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020},
  pages={9726-9735}
}

@article{caron2020unsupervised,
  title={Unsupervised learning of visual features by contrasting cluster assignments},
  author={Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9912--9924},
  year={2020}
}

@article{Li2021WeaklySD,
  title={Weakly Supervised Deep Reinforcement Learning for Video Summarization With Semantically Meaningful Reward},
  author={Zu-Hua Li and Lei Yang},
  journal={2021 IEEE Winter Conference on Applications of Computer Vision (WACV)},
  year={2021},
  pages={3238-3246}
}

@article{Pan2022ExploringGD,
  title={Exploring Global Diversity and Local Context for Video Summarization},
  author={Yingchao Pan and Ouhan Huang and Qinghao Ye and Zhongjin Li and Wen-Jie Wang and Guodun Li and Yuxing Chen},
  journal={IEEE Access},
  year={2022},
  volume={10},
  pages={43611-43622}
}

@article{Dosovitskiy2021AnII,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  journal={ArXiv},
  year={2021},
  volume={abs/2010.11929}
}

@inproceedings{
    dosovitskiy2021an,
    title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
    author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
    booktitle={International Conference on Learning Representations},
    year={2021},
    url={https://openreview.net/forum?id=YicbFdNTTy}
}

@INPROCEEDINGS{8099801,  author={Mahasseni, Behrooz and Lam, Michael and Todorovic, Sinisa},  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Unsupervised Video Summarization with Adversarial LSTM Networks},   year={2017},  volume={},  number={},  pages={2982-2991},  doi={10.1109/CVPR.2017.318}}

@inproceedings{zhao2018hsa,
  title={Hsa-rnn: Hierarchical structure-adaptive rnn for video summarization},
  author={Zhao, Bin and Li, Xuelong and Lu, Xiaoqiang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7405--7414},
  year={2018}
}

@article{haopeng2022video,
  title={Video Summarization Based on Video-text Modelling},
  author={Haopeng, Li and Qiuhong, Ke and Mingming, Gong and Rui, Zhang},
  journal={arXiv preprint arXiv:2201.02494},
  year={2022}
}

@inproceedings{rochan2018video,
  title={Video summarization using fully convolutional sequence networks},
  author={Rochan, Mrigank and Ye, Linwei and Wang, Yang},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={347--363},
  year={2018}
}

@inproceedings{NEURIPS2021_7503cfac,
 author = {Narasimhan, Medhini and Rohrbach, Anna and Darrell, Trevor},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {13988--14000},
 publisher = {Curran Associates, Inc.},
 title = {CLIP-It! Language-Guided Video Summarization},
 url = {https://proceedings.neurips.cc/paper/2021/file/7503cfacd12053d309b6bed5c89de212-Paper.pdf},
 volume = {34},
 year = {2021}
}

@article{Zhao2022ReconstructiveSN,
  title={Reconstructive Sequence-Graph Network for Video Summarization},
  author={Bin Zhao and Haopeng Li and Xiaoqiang Lu and Xuelong Li},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2022},
  volume={44},
  pages={2793-2801}
}

@inproceedings{Park2020SumGraphVS,
  title={SumGraph: Video Summarization via Recursive Graph Modeling},
  author={Jungin Park and Jiyoung Lee and Ig-Jae Kim and Kwanghoon Sohn},
  booktitle={ECCV},
  year={2020}
}

@inproceedings{Chowdhury2021AudViSumSD,
  title={AudViSum: Self-Supervised Deep Reinforcement Learning for Diverse Audio-Visual Summary Generation},
  author={Sanjoy Chowdhury and Aditya Patra and Subhrajyoti Dasgupta and Ujjwal Bhattacharya},
  booktitle={BMVC},
  year={2021}
}

@article{Kitaev2020ReformerTE,
  title={Reformer: The Efficient Transformer},
  author={Nikita Kitaev and Lukasz Kaiser and Anselm Levskaya},
  journal={ArXiv},
  year={2020},
  volume={abs/2001.04451}
}

@article{Zaheer2020BigBT,
  title={Big Bird: Transformers for Longer Sequences},
  author={Manzil Zaheer and Guru Guruganesh and Kumar Avinava Dubey and Joshua Ainslie and Chris Alberti and Santiago Onta{\~n}{\'o}n and Philip Pham and Anirudh Ravula and Qifan Wang and Li Yang and Amr Ahmed},
  journal={ArXiv},
  year={2020},
  volume={abs/2007.14062}
}