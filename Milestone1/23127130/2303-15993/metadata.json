{
    "arxiv_id": "2303.15993",
    "paper_title": "SELF-VS: Self-supervised Encoding Learning For Video Summarization",
    "authors": [
        "Hojjat Mokhtarabadi",
        "Kave Bahraman",
        "Mehrdad HosseinZadeh",
        "Mahdi Eftekhari"
    ],
    "submission_date": "2023-03-28",
    "revised_dates": [
        "2023-03-29"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Despite its wide range of applications, video summarization is still held back by the scarcity of extensive datasets, largely due to the labor-intensive and costly nature of frame-level annotations. As a result, existing video summarization methods are prone to overfitting. To mitigate this challenge, we propose a novel self-supervised video representation learning method using knowledge distillation to pre-train a transformer encoder. Our method matches its semantic video representation, which is constructed with respect to frame importance scores, to a representation derived from a CNN trained on video classification. Empirical evaluations on correlation-based metrics, such as Kendall's $τ$ and Spearman's $ρ$ demonstrate the superiority of our approach compared to existing state-of-the-art methods in assigning relative scores to the input frames.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.15993v1"
    ],
    "publication_venue": "9 pages, 5 figures"
}