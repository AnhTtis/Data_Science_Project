\section{Robust Deep Neural Networks}\label{sec:prelim}
% \subsection{Neural Networks}
% We focus on neural networks for image classification tasks. 
% A typical neural network takes each pixel value of an image as an input and outputs its classification result. 

% Training a neural network is a gradient-based learning process~\cite{lecun1998gradient, DBLP:journals/neco/LeCunBDHHHJ89} consisting of both forward propagation and backward propagation. A predictive value $\hat{y}$ can be obtained after the forward process with an assignment of all the parameters of the model. Then we can use a loss function $\mathcal{L} = \ell(y, \hat{y})$ to measure the discrepancy between the ground-truth label $y$ and the output $\hat{y}$. In backward propagation, the parameters are updated according to the gradient of the loss function until the termination condition is reached.

% \subsection{Interval-Based Robustness Verification}

Huber~\cite{DBLP:books/wi/Huber81} introduces the concept of robustness in a broader sense: (\romannumeral1) the efficiency of the model should be reasonably good, and (\romannumeral2) the small disturbance applied to the input should only have a slight impact on the result of the model. 
The problem of robustness verification has been formally defined by Lyu \etal~\cite{DBLP:conf/cvpr/LyuGWXZL21}: 

\begin{definition}[Robustness verification]
Robustness verification aims to guarantee that a neural network outputs consistent classification results for all inputs in a set which is usually represented as an $l_p$ norm ball around the clean image $x$: $\mathbbm{B}(x, \epsilon) = \{x' |\left \Vert x' - x \Vert_p \leq \epsilon \right \}$. 
\end{definition}

The problem of neural network robustness verification has intrinsically high complexity  \cite{DBLP:journals/corr/abs-2208-09872}. Many approaches rely on symbolic interval bound propagation to 
simplify the problem at the price of sacrificing the completeness 
 \cite{DBLP:journals/corr/abs-2208-09872,DBLP:conf/cav/JinTZWZ22,DBLP:conf/cvpr/LyuGWXZL21,DBLP:conf/iclr/ZhangCXGSLBH20}. Figure \ref{fig:ibp} illustratively compares the difference of interval bound propagation (IBP) and SIP. 
 Intuitively, when we know the domain of each input, we can estimate the output range by propagating the inputs symbolically throughout the neural network. According to the output range, we can prove/disprove the robustness of the neural network. See \cite{DBLP:conf/uss/WangPWYJ18} for more details. 
 


To accelerate the propagation, the non-linear activation functions need to over-approximate using linear constraints, therefore rendering the output range overestimated. 
More hidden layers in a network imply a larger overestimation because the overestimation is accumulated layer by layer. A large overestimation easily causes failure to verification. Therefore, many efforts are being made to tighten the over-approximation \cite{zhang2018efficient,boopathy2019cnn,wu2021tightening}. Unfortunately, it has been proved there is a theoretical barrier \cite{salman2019convex,DBLP:journals/corr/abs-2208-09872,tjandraatmadja2020convex}. 



\begin{figure}
 \begin{subfigure}{0.49\linewidth}
	\centering
	\includegraphics[width=0.9\linewidth]{naive.pdf}
	\caption{IBP}
\end{subfigure}
\centering
\begin{subfigure}{0.49\linewidth}
	\includegraphics[width=0.9\linewidth]{symbol.pdf}
	\caption{SIP}
\end{subfigure}
\vspace{-2mm}
\caption{IBP and SIP \cite{DBLP:conf/uss/WangPWYJ18}.}
\vspace{-5mm}
\label{fig:ibp}
\end{figure}


 