\section{The Abstraction-Based Training  Approach}\label{sec:method}

In this section, we present our abstraction-based method for training neural networks. We define the training problem in Section \ref{3.1}. Section \ref{3.2} and Section \ref{3.3} give the abstraction procedure and the training procedure. 
Throughout these two sections, we also illustrate how varying
network inputs can affect the loss function,  which in turn contributes to the robustness of trained models.

\subsection{Formulating the Training Problem}
\label{3.1}

We solve the following training problem:

\begin{center}
	\begin{tcolorbox}[colback=gray!10,%gray background
		colframe=blue!40!white,% black frame colour
		% width=8cm,% Use 8cm total width,
		% arc=1mm, auto outer arc,
		boxrule=0.5pt,
		]
		\emph{Given a training set and a testing set of images and a perturbation distance $\epsilon$, our goal is to train an image classifier $f$ that is provably robust on $\mathbb{B}(x,\epsilon)$ for each image $x$ in the set while $f$ has a low verified error on the testing set. }
	\end{tcolorbox}
\end{center}

As the target image classifier $f$ must be guaranteed robust on $\mathbb{B}(x,\epsilon)$, $f$ returns the same classification results for all the perturbed images in $\mathbb{B}(x,\epsilon)$. Our idea is to (i) map $\mathbb{B}(x,\epsilon)$ to an interval vector $(I_1,I_2,\ldots I_n)$ by an abstraction function $\phi$ such that $\phi(\mathbb{B}(x,\epsilon))=(I_1,I_2,\ldots I_n)$, and (ii) train an image classifier $f'$ which takes as input the interval vector  and returns a classification result as $x$ is labeled, i.e., $\arg\max_{y\in Y}f'(I_1,I_2,\ldots,I_n)=y_{true}$ with $y_{true}$ the ground truth label of $x$.  The target image classifier $f$ is a composition of $f'$ and $\phi$. Apparently, $f$ is provably robust on  $\mathbb{B}(x,\epsilon)$ since all the images in $\mathbb{B}(x,\epsilon)$ are mapped to $(I_1,I_2,\ldots,I_n)$ which is classified to $y_{true}$ by $f'$. 


To feed the training intervals to the neural network, the number of neurons in the input layer is doubled. As shown in Figure \ref{training}, the upper bound and lower bound of each training interval are input to these neurons. 
Namely, the neurons in the input layer do not correspond to a pixel but the upper and lower bounds of each training interval. Any perturbation interval mapped to the same training interval will be fed into the neural network with the same upper and lower bounds. Other training parameters and settings are the same as the traditional training process.

\subsection{Abstraction of Perturbed Images}
\label{3.2}
\subsubsection{From Perturbed Interval to Training Interval}

We first introduce the abstraction function $\phi:\mathcal{I}^n\rightarrow \mathbb{I}^n$, where 
$\mathcal{I}^n$ is the set of all interval vectors,  
$\mathbb{I}^n$ is a finite set of interval vectors on which neural networks are trained, and $n$ denotes the size of the interval vectors. The 
norm ball $\mathbb{B}(x,\epsilon)$ of
$x$ under $\epsilon$ is essentially an interval vector in $\mathcal{I}^n$. We call the elements in $\mathcal{I}^n$ \textit{perturbation interval vectors}. 
 
Let $[-1, 1]$ be the range of the complete input space. We divide $[-1, 1]$ evenly into sub-intervals of size $d_i$ and denote the set of all the sub-intervals as $\mathbb{I}_i$. Then, we obtain $\mathbb{I}^n$ as the Cartesian product of all $\mathbb{I}_i$, i.e., $\Pi^{n}_{i=1} \mathbb{I}_i$. 
Because we train image classifiers on $\mathbb{I}^n$, we call the elements in $\mathbb{I}^n$ \textit{training interval vectors}. 
We use $\overline{d}$ to denote the integer vector $(d_1,d_2,\ldots,d_n)$ and call it \emph{abstraction granularity}. In our abstraction process, all values in $\overline{d}$ are the same, so we use a constant $d$ to represent it. 

Because perturbation interval vectors are infinite, it is impossible to enumerate all perturbation interval vectors for training. We abstract and map them onto a finite number of training interval vectors in $\mathbb{I}^n$. The purpose of the abstraction is to ease the follow-up robustness verification by restricting the infinite perturbation space to finite training space. In addition, the abstraction function is an element-wise operation. In such cases, we introduce our mapping function with an interval as an example. 

\begin{figure}
	\centering
	\includegraphics[width=0.48\textwidth]{train.pdf}
	\caption{Training on numerical intervals. 
	}
	\label{training}
 \vspace{-1mm}
\end{figure}


In order to ensure that the perturbation interval can only be mapped to a unique training interval, we make the following constraints on the mapping process: We first restrict the abstraction granularity $d$ to be greater than or equal to twice the perturbation size $\epsilon$, for the purpose of guaranteeing that a perturbation interval has an intersection with at most two training intervals. We divide the mapping into three cases: (1) If a training interval contains the perturbation interval, the perturbation interval will be mapped to the training interval; (2) If the perturbation interval has an intersection with two training intervals unequally, the perturbation interval will be mapped to the training interval with the larger coverage area; (3) If the perturbation interval has an intersection with two training intervals equally, the perturbation interval will be mapped to the training interval with a larger value. In this way, we map the perturbation interval on the unique training interval, and then we can train the neural network on these training intervals. 





\setlength{\textfloatsep}{10pt}
\begin{algorithm}[t]
	\renewcommand{\thealgocf}{1}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
	\caption{ Abstraction of Perturbations $\phi$.}
	\label{abstraction_alg}
	\Input{~$\mathcal{I}$: perturbation interval vector;\\
		$d$: abstraction granularity}
	\Output{~$\mathbb{I}$: training interval vector}
	Initialize $I_{init}', \mathbb{I}$\tcp*{ $I_{init}'$ is [-1,1], and $\mathbb{I}$ is an empty vector}
	$I'$ $\leftarrow$ Divide($I_{init}'$, $d$)\tcp*{Get sub-intervals with size d}
		\For{i in len($\mathcal{I}$)}{ 
			\For{j in len($I'$)}{
				\If{min($\mathcal{I}_{i}$) $>$ max($I_j'$)}{
					Continue \tcp*{No intersection}
				}
				\If{$\mathcal{I}_{i} \in I_j'$}{
					$\mathbb{I}_{i} = I_j'$\tcp*{$I_j'$ contains $\mathcal{I}_{i}$}
				}
				\Else{
					$len_r$ = max($\mathcal{I}_{i}$) - min($I_{j+1}'$); \\
					$len_l$ = max($I_j'$) - min($\mathcal{I}_{i}$);\\
					\If{$len_r\geq len_l$}{
						$\mathbb{I}_{i} = I_{j+1}'$\tcp*{Map to numerically larger}
					}
					\Else{
						$\mathbb{I}_{i} = I_j'$\tcp*{Map to numerically smaller}
					}
				}
			}
		}
	Return ${\mathbb{I}}$;
\end{algorithm}



Algorithm \ref{abstraction_alg} shows our abstraction function. Firstly, we initialize the complete input interval and an training interval vector (Line 1). Then,
we obtain the sub-intervals which each size is $d$ (Line 2).
If a training interval contains the perturbation interval, the perturbation interval will be mapped to the training interval (Lines 7-8). The perturbation interval at most intersects with two training intervals at the same time as $d \geq 2*\epsilon$. Let $len_r$ be the size of the intersection of the perturbation interval and the numerically larger training interval (Line 10). Let $len_l$ be the size of the intersection of the perturbation interval and the numerically smaller training interval (Line 11). If $len_r\geq len_l$, the perturbation interval will be mapped to the numerically larger training interval (Lines 12-13); otherwise, it will be mapped to the numerically smaller training interval (Lines 14-15).

\vspace{-2mm}
\subsubsection{Effect of Abstraction on Input}
\vspace{-2mm}
We now explain that the abstraction process results in a smaller variance of training intervals. 

In our training method, the value of each pixel is normalized to $[-1, 1]$. Considering the arbitrariness of the input value distribution, we assume that the input values are evenly distributed in $[-1, 1]$. We calculate the variance of input, and in such cases, the value we get is the maximum likelihood estimation of the actual value.

We calculate the variance of the input values with $d$ representing abstraction granularity and $\mathbb{I}$ representing the training intervals of an image. Note that in conventional methods, it is equivalent to $d = 0$, while in our method, $d$ is a positive number. In this way, for an input image, the variance of it after the abstraction process is:
\begin{align}
	\label{variance}
	D(\mathbb{I}) & = E((\mathbb{I})^2) - E(\mathbb{I})^2 \notag\\
	% & = E((\mathbb{I})^2) \notag\\
	& = \underbrace{(-1 + \frac{d}{2})^2 + (-1 + \frac{3d}{2}^2) + \ldots + (1 - \frac{d}{2})^2}_{2/d \enspace items} \\
	% & = 2 * \underbrace{((\frac{d}{2})^2 + \ldots + (1 - \frac{d}{2})^2)}_{1/d \enspace items} \\
	% & \overset{\text{let n = 1/d}}{=} 2 * \underbrace{((\frac{1}{2n})^2 + \ldots + (\frac{2n-1}{2n})^2)}_{n \enspace items} \notag\\
	% & = \frac{1^2 + 3^2 + \ldots + (2n-1)^2}{2n^2} * n \notag\\
%	& = \frac{\frac{n(2n-1)(2n+1)}{3}}{2n} \notag\\
	& = \frac{4n^2-1}{6}. \notag
\end{align}
\noindent In Equation \ref{variance}, the variance of training interval is computed by the upper and lower bounds. For an abstraction-based trained neural network, a large abstraction granularity $d$ implies a small $n$, and consequently the variance of the training intervals becomes small. Apparently, intervals have a smaller variance than  concrete pixel values.
% We say that the training intervals $\mathbb{I}$ have \textit{small variance}.


\begin{algorithm}[t]
    % \setcounter{algorithm}{2}
    \renewcommand{\thealgocf}{2}
	\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
	\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
	\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
	\label{train_alg}
	\caption{\mbox{ Abstraction-based Training: \textsc{AbsTrain}}}
	\label{train_alg}
	\Input{~$\mathbf{X}$: training data; \\ ~$\mathbf{Y}$: ground-truth labels of training data; \\ ~$\epsilon$: perturbation radius; \\ ~$d$: abstraction granularity}
	\Output{~$f'$: a neural network, $\ell$: training loss}
	Initialize $f'$, $\ell$; \\ 
	\For{($X$, $Y$) in ($\bf X, \bf Y$)}{
    \For{($x$, $y$) in ($X$, $Y$)}{
		$\mathbb{I}$ $\leftarrow \phi(\mathbb{B}(x$, $\epsilon$), $d$) \tcp*{Get training intervals.} 
		$\ell \leftarrow \ell + $ $\mathcal{L}$($f'(\mathbb{I})$, $\mathbf{y}$) \tcp*{Accumulate the loss.}
	  }
        $f'\leftarrow$ Update($f'$, $\ell$) \tcp*{Update the parameters in $f'$.}
	}
	Return $f'$, $\ell$;
\end{algorithm}

\subsection{Training on Intervals}
\label{3.3}
\subsubsection{The Training Method}


When we get the training intervals, hyperparameter settings, such as the number of layers, the number of neurons in hidden layers, the loss function during training, etc., are all the same as the traditional training methods except for the number of neurons in the input layer.

Algorithm \ref{train_alg} shows the pseudo-code of the algorithm for training a neural network. The training dataset $\mathbf{X}$, the ground-truth labels $\mathbf{Y}$ corresponding to the dataset, the perturbation radius $\epsilon$, and the abstraction granularity $d$ are used as inputs. Firstly, a neural network is initialized. That is, the adjustable parameters of the neural network are initialized randomly (Line 1). 
For each image of training dataset $\mathbf{X}$,
the perturbation intervals are mapped to training intervals (Line 4). According to the current adjustable parameters, 
% the classification labels of the neural network for the training intervals are obtained, and 
the cross-entropy loss is calculated (Line 5). Finally, the backward propagation is performed according to the cross-entropy loss, and the values of the adjustable parameters are updated (Line 6). A trained neural network is returned when the loss no longer decreases.





% \input{proof}

\vspace{-2mm}
\subsubsection{Smoothing Loss Landscape}

We illustrate that the small variance of input results in a smooth loss landscape during training. Loss landscape is the characterization of loss functions. For example, smooth loss landscape means that the size of 
the connected region around the minimum where the training loss remains low, showing convex contours in the center, 
while sharp loss landscape shows not convex but chaotic to that region~\cite{DBLP:conf/nips/Li0TSG18}. 

We investigate the smoothness of the loss landscape from both theoretical and experimental perspectives. 
For a classification problem, the loss function is usually cross-entropy loss. We use $y$ to represent 
the ground-truth label, and $\hat{y}$ to represent the prediction of the neural network. In such cases, we explore the relationship 
between $\mathbb{I}$ and loss function. 
\begin{equation}
	\begin{aligned}
		\mathcal{L}(y, \hat{y}) 
		& = CrossEntropyLoss(y, \hat{y}) \\
		& = \sum_{i=1}^{c}y_i \cdot (-log(\hat{y_i})) \\
		% & = -log(y_{true}) \\
		& = -log(max(A \cdot \mathbb{I} + b))
		\label{eq:lossfunction}
	\end{aligned}
\end{equation}
where $c$ represents the number of 
classes, $y_i$ is the one-hot encoding of labels, 
$y_{true}$ is the output value corresponding to the correct label, and $A$ and $b$ are the parameters of the neural network.
For parameter space, a smooth loss landscape means that when the value of trainable parameters of the neural network gradually deviates 
from the optimal value, the loss increases slowly with it. In other words, the first-order partial derivative of 
Equation \ref{eq:lossfunction} with respect to $A$ and $b$ should be a constant or a value with less variation. 
The two partial derivatives are:
\begin{equation}
	\begin{aligned}
		\frac{\partial \mathcal{L}(y, \hat{y})}{\partial A} 
		& = \frac{\partial (-log(max(A \cdot \mathbb{I} + b)))}{\partial A} \\
		& = -\frac{\mathbb{I}}{max(A \cdot \mathbb{I} + b)}
		\label{eq:derivative_A}
	\end{aligned}
\end{equation}
\begin{equation}
	\begin{aligned}
		\frac{\partial \mathcal{L}(y, \hat{y})}{\partial b} 
		& = \frac{\partial (-log(max(A \cdot \mathbb{I} + b)))}{\partial b} \\
		& = -\frac{1}{max(A \cdot \mathbb{I} + b)}
		\label{eq:derivative_b}
	\end{aligned}
\end{equation}

With fixed $A$ and $b$, we discuss the value of Equation \ref{eq:derivative_A} for different training intervals.
If $b = 0$, we get a constant $-\frac{1}{A}$. Obviously, the loss landscape is smooth in this case. If $b \neq 0$, we write the derivative as $-\frac{1}{A + b \cdot (\mathbb{I})^{-1}}$. In our method, the variance of $\mathbb{I}$ is small. 
That is, the value of $\mathbb{I}$ concentrates around a fixed value. Thus, the value of the derivative varies in a small range, and the loss landscape is smoother. For Equation \ref{eq:derivative_b}, $max(A \cdot \mathbb{I} + b)$ is large as it is the value corresponding to the ground-truth label.
Hence, Equation \ref{eq:derivative_b} is close to $0$, and the loss landscape is smooth. 

\begin{figure}
	\centering
	\begin{subfigure}{0.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{lossLandscapeD0.pdf}
		\caption{$d = 0$}
	\end{subfigure}
	\centering
	\begin{subfigure}{0.49\linewidth}
		\includegraphics[width=\linewidth]{lossLandscapeD025.pdf}
		\caption{$d = 0.025$}
	\end{subfigure}
	\caption{Visualization of DM-small's loss landscape ~\cite{DBLP:conf/iclr/ZhangCXGSLBH20} trained when $d = 0$ and $d = 0.025$. 
	}
	\label{fig:loss_landscape}
\end{figure}

In summary, the small variance of $\mathbb{I}$ results in a smooth loss landscape. 
As an example, we utilize the tool in \cite{DBLP:conf/nips/Li0TSG18} to visualize in Figure \ref{fig:loss_landscape} the loss landscape of two neural networks that are trained with $d = 0$ and $d = 0.025$, respectively. 
Figure \ref{fig:loss_landscape} depicts that the neural network trained with $d = 0.025$ has a broader loss landscape than the one trained with $d=0$, and the loss increases more smoothly in every direction.

\vspace{-3mm}
\subsubsection{The Robustness of Trained Neural Networks}

Training on numerical intervals guarantees that all the perturbed intervals that are mapped to the same numerical interval will have the same classification result. Intuitively, if a numerical interval represents more concrete values, even if the concrete value is slightly disturbed, these disturbed values will be mapped to the same numerical interval with a high probability. Consequently, the classification of the numerical interval according to the neural network still remains unchanged. In this sense, we say that the perturbation is \textit{dissolved} by the abstraction, and therefore the neural network's robustness is improved. 

Theoretically, we show that the smooth loss landscape due to the abstraction in  training contributes to the robustness of neural networks. 
As shown in Figure \ref{fig:loss_landscape}, 
% Figure \ref{fig:loss_landscape} shows that 
the loss of DM-small trained by \textsc{AbsCert} increases slowly and uniformly with the change of parameters, meaning that the growth rate of loss is slow in all directions of parameters' change. However, neural networks trained by conventional methods have a steep slope, which means that there is a direction where the loss increases rapidly. Obviously, smooth loss landscape is helpful for the optimization in training phase to find a global optimum. 

Moreover, in the process of our abstraction, an original pixel is first perturbed to a perturbed interval which is then mapped to a training interval for classification. This indicates that the loss is a constant because all the perturbed images of an image are mapped to a fixed set of training intervals, and the $\mathbb{I}^n$ in Equation \ref{eq:lossfunction} is never changed. 

Neural networks trained by our abstraction-based training method is more robust as the loss landscape is smooth in both parameter space and input space~\cite{DBLP:conf/ijcai/YuQLZWC19}. In particular, for parameter space, the model tends to find a global optimum in a reasonably efficient manner~\cite{DBLP:conf/nips/Li0TSG18, DBLP:conf/nips/WuX020}; for input space, the model is insensitive to the input perturbations ~\cite{DBLP:conf/cvpr/Moosavi-Dezfooli19}.