% CVPR 2022 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
%\usepackage[review]{cvpr}      % To produce the REVIEW version
% \usepackage{cvpr}              % To produce the CAMERA-READY version
\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version
\makeatletter
\@namedef{ver@everyshi.sty}{}
\makeatother
\usepackage{tikz}

% \usepackage[accsupp]{axessibility}  % Improves PDF readability for those with disabilities.

% Include other packages here, before hyperref.
\usepackage{multirow}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{assumption}{Assumption}
\newcounter{example}
\newenvironment{example}[1][]{\refstepcounter{example}\par\medskip
	\noindent \textbf{Example~\theexample. #1} \rmfamily}{\medskip}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{tcolorbox}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
% \usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{bbm}
\usepackage{changepage}
\usepackage{balance}
\usepackage{amsmath}
\allowdisplaybreaks[4]
\definecolor{atomictangerine}{rgb}{1.0, 0.6, 0.4}
\definecolor{apricot}{rgb}{0.98, 0.81, 0.69}
\definecolor{antiquewhite}{rgb}{0.98, 0.92, 0.84}
\definecolor{Gray}{gray}{0.40}
\definecolor{LightCyan}{rgb}{0.88,1,1}
\definecolor{ashgrey}{rgb}{0.7, 0.75, 0.71}
\definecolor{darkgray}{gray}{0.80}
\definecolor{lightorange}{rgb}{0.98, 0.75, 0.56}
\definecolor{lo1}{rgb}{0.98, 0.93, 0.84}
\definecolor{lo2}{rgb}{0.98, 0.81, 0.69}
\definecolor{lo3}{rgb}{0.98, 0.60, 0.41}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\newcommand{\zhangzhaodi}[1]{\textcolor{red}{\textbf{[zzd: #1]}}}
\newcommand{\note}[1]{\textcolor{red}{\textbf{[#1]}}}
\newcommand{\chenyang}[1]{\textcolor{atomictangerine}{\textbf{[cy: #1]}}}
\newcommand{\xuezhiyi}[1]{\textcolor{blue}{\textbf{[xzy: #1]}}}

\newcommand{\todo}[1]{\textcolor{cyan}{\textbf{#1}}}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
% \usepackage[pagebackref,breaklinks]{hyperref}
% \urlstyle{rm}

% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{927} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}

\newcommand\mycommfont[1]{\footnotesize\it\textcolor{Gray}{#1}}
\SetCommentSty{mycommfont}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE

\title{%\textsc{AbsCert}:
Boosting Verified Training for Robust Image Classifications via Abstraction}

\author{Zhaodi Zhang $^{1,2,4}$, Zhiyi Xue $^2$, Yang Chen $^2$, Si Liu $^3$, Yueling Zhang $^2$, Jing Liu $^1$, Min Zhang $^2$\\
 $^1$ Shanghai Key Laboratory of Trustworthy Computing \\
 $^2$ East China Normal University \\
 $^3$ ETH Z{\"u}rich $^4$ Chengdu Education Research Institute%\\
%{\tt\small \{zdzhang, 51255902046, 51255902034\}@stu.ecnu.edu.cn}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
% \and
% Si Liu\\
% ETH Z{\"u}rich\\
% {\tt\small si.liu@inf.ethz.ch}
% \and
% Min Zhang, Jing Liu\\
% School of Software Engineering\\
% East China Normal University, Shanghai, China\\
% {\tt\small \{zhangmin,jliu\}@sei.ecnu.edu.cn}
}


\maketitle

% Paper formatting: Papers are limited to eight pages, including figures and tables, in the CVPR style. Additional pages containing only cited references are allowed. 

% Paper Registration Deadline*: Fri, Nov 4, 2022 11:59pm Pacific Time
% Submission Deadline*: Fri, Nov 11, 2022 11:59pm Pacific Time
% Supplementary Materials Deadline: Fri, Nov 18, 2022 11:59pm Pacific Time
% Reviews Released: Tue, Jan 24, 2023
% Rebuttal Period: Tue, Jan 24-31, 2023
% Final Decisions: Mon, Feb 27, 2023

%%%%%%%%% ABSTRACT
\input{abstract}


%%%%%%%%% BODY TEXT
\input{intro}

\input{prelim}

\input{method}

\input{verification}

% \input{proof}

\input{expri}

\input{related}

\input{conclu}

\vspace{2mm}
\noindent
\textbf{ACKNOWLEDGMENTS}
\vspace{1mm}

\noindent
% \section*{Acknowledgments}
% The authors thank the reviewers for their constructive comments. 
This work was supported by the National Key Research and Development (2019YFA0706404), the National Nature Science Foundation of China (61972150), Huawei Technologies, the NSFC-ISF Joint Program (62161146001), the Fundamental Research Funds for Central Universities, Shanghai Trusted Industry Internet Software Collaborative Innovation Center, and Shanghai International Joint Lab of Trust-worthy Intelligent Software
% Grant No. 
(22510750100).
 Corresponding authors are Jing Liu and Min Zhang (\texttt{\{jliu, zhangmin\}@sei.ecnu.edu.cn}).

\clearpage
%%%%%%%%% REFERENCES
\small
\balance 
\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{DBLP:conf/icml/AthalyeC018}
Anish Athalye, Nicholas Carlini, and David~A. Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In {\em {ICML}}, volume~80, pages 274--283, 2018.

\bibitem{DBLP:conf/iclr/BalunovicV20}
Mislav Balunovic and Martin~T. Vechev.
\newblock Adversarial training and provable defenses: Bridging the gap.
\newblock In {\em {ICLR}}, 2020.

\bibitem{beheshti1998interval}
Mohsen Beheshti, Ali Berrached, Andr{\'e} de Korvin, Chenyi Hu, and Ongard
  Sirisaengtaksin.
\newblock On interval weighted three-layer neural networks.
\newblock In {\em ANSS}, pages 188--194, 1998.

\bibitem{boopathy2019cnn}
Akhilan Boopathy, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu, et~al.
\newblock {CNN-C}ert: An efficient framework for certifying robustness of
  convolutional neural networks.
\newblock In {\em AAAI}, pages 3240--3247, 2019.

\bibitem{DBLP:conf/iclr/BuckmanRRG18}
Jacob Buckman, Aurko Roy, Colin Raffel, and Ian~J. Goodfellow.
\newblock Thermometer encoding: One hot way to resist adversarial examples.
\newblock In {\em {ICLR}}, 2018.

\bibitem{DBLP:conf/ccs/Carlini017}
Nicholas Carlini and David~A. Wagner.
\newblock Adversarial examples are not easily detected: Bypassing ten detection
  methods.
\newblock In {\em AISec@CCS}, pages 3--14, 2017.

\bibitem{DBLP:conf/sp/Carlini017}
Nicholas Carlini and David~A. Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In {\em {SP}}, pages 39--57, 2017.

\bibitem{DBLP:conf/acl/HsiehYCZC18}
Hongge Chen, Huan Zhang, Pin{-}Yu Chen, Jinfeng Yi, et~al.
\newblock Attacking visual language grounding with adversarial examples: {A}
  case study on neural image captioning.
\newblock In {\em {ACL}}, pages 2587--2597, 2018.

\bibitem{DBLP:conf/cvpr/DengDSLL009}
Jia Deng, Wei Dong, Richard Socher, Li{-}Jia Li, et~al.
\newblock Imagenet: {A} large-scale hierarchical image database.
\newblock In {\em {CVPR}}, pages 248--255, 2009.

\bibitem{DBLP:conf/cvpr/EykholtEF0RXPKS18}
Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li, et~al.
\newblock Robust physical-world attacks on deep learning visual classification.
\newblock In {\em {CVPR}}, pages 1625--1634, 2018.

\bibitem{DBLP:conf/aaai/FanL21}
Jiameng Fan and Wenchao Li.
\newblock Adversarial training and provable robustness: {A} tale of two
  objectives.
\newblock In {\em {AAAI}}, pages 7367--7376, 2021.

\bibitem{DBLP:journals/corr/GoodfellowSS14}
Ian~J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In {\em {ICLR}}, 2015.

\bibitem{DBLP:journals/corr/abs-1810-12715}
Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, et~al.
\newblock On the effectiveness of interval bound propagation for training
  verifiably robust models.
\newblock abs/1810.12715, 2018.

\bibitem{DBLP:conf/iccv/GowalDSBQUAMK19}
Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, et~al.
\newblock Scalable verified training for provably robust image classification.
\newblock In {\em {ICCV}}, pages 4841--4850, 2019.

\bibitem{DBLP:conf/iclr/GuoRCM18}
Chuan Guo, Mayank Rana, Moustapha Ciss{\'{e}}, and Laurens van~der Maaten.
\newblock Countering adversarial images using input transformations.
\newblock In {\em {ICLR}}, 2018.

\bibitem{DBLP:conf/cvpr/HeZRS16}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em {CVPR}}, pages 770--778, 2016.

\bibitem{DBLP:books/wi/Huber81}
Peter~J. Huber.
\newblock {\em Robust Statistics}.
\newblock 1981.

\bibitem{DBLP:conf/cav/JinTZWZ22}
Peng Jin, Jiaxu Tian, Dapeng Zhi, Xuejun Wen, and Min Zhang.
\newblock Trainify: {A CEGAR-D}riven training and verification framework for
  safe deep reinforcement learning.
\newblock In {\em CAV}, volume 13371, pages 193--218, 2022.

\bibitem{DBLP:conf/cav/KatzBDJK17}
Guy Katz, Clark~W. Barrett, David~L. Dill, Kyle Julian, et~al.
\newblock Reluplex: An efficient {SMT} solver for verifying deep neural
  networks.
\newblock In {\em CAV}, volume 10426, pages 97--117, 2017.

\bibitem{DBLP:journals/corr/KingmaB14}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In {\em {ICLR}}, 2015.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{DBLP:journals/cacm/KrizhevskySH17}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E. Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock 60:84--90, 2017.

\bibitem{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock 86:2278--2324.

\bibitem{DBLP:conf/nips/LeeLPL21}
Sungyoon Lee, Woojin Lee, Jinseong Park, and Jaewook Lee.
\newblock Towards better understanding of training certifiably robust models
  against adversarial examples.
\newblock In {\em {NeurIPS}}, pages 953--964, 2021.

\bibitem{DBLP:conf/nips/Li0TSG18}
Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, et~al.
\newblock Visualizing the loss landscape of neural nets.
\newblock In {\em NeurIPS}, pages 6391--6401, 2018.

\bibitem{DBLP:conf/cvpr/LyuGWXZL21}
Zhaoyang Lyu, Minghao Guo, Tong Wu, Guodong Xu, et~al.
\newblock Towards evaluating and training verifiably robust neural networks.
\newblock In {\em {CVPR}}, pages 4308--4317, 2021.

\bibitem{DBLP:conf/iclr/Ma0WEWSSHB18}
Xingjun Ma, Bo Li, Yisen Wang, Sarah~M. Erfani, et~al.
\newblock Characterizing adversarial subspaces using local intrinsic
  dimensionality.
\newblock In {\em {ICLR}}, 2018.

\bibitem{DBLP:conf/iclr/MadryMSTV18}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, et~al.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In {\em {ICLR}}, 2018.

\bibitem{DBLP:conf/icml/MirmanGV18}
Matthew Mirman, Timon Gehr, and Martin~T. Vechev.
\newblock Differentiable abstract interpretation for provably robust neural
  networks.
\newblock In {\em {ICML}}, volume~80, pages 3575--3583, 2018.

\bibitem{DBLP:conf/cvpr/Moosavi-Dezfooli19}
Seyed{-}Mohsen Moosavi{-}Dezfooli, Alhussein Fawzi, Jonathan Uesato, and Pascal
  Frossard.
\newblock Robustness via curvature regularization, and vice versa.
\newblock In {\em {CVPR}}, pages 9078--9086, 2019.

\bibitem{oala2020interval}
Luis Oala, Cosmas Hei{\ss}, Jan Macdonald, Maximilian M{\"a}rz, Wojciech Samek,
  and Gitta Kutyniok.
\newblock Interval neural networks: Uncertainty scores.
\newblock {\em arXiv preprint arXiv:2003.11566}, 2020.

\bibitem{DBLP:conf/sp/PapernotM0JS16}
Nicolas Papernot, Patrick~D. McDaniel, Xi Wu, Somesh Jha, and Ananthram Swami.
\newblock Distillation as a defense to adversarial perturbations against deep
  neural networks.
\newblock In {\em {SP}}, pages 582--597, 2016.

\bibitem{prabhakar2019abstraction}
Pavithra Prabhakar and Zahra~Rahimi Afzal.
\newblock Abstraction based output range analysis for neural networks.
\newblock In {\em NeurIPS}, pages 15788--15798, 2019.

\bibitem{DBLP:conf/iclr/RaghunathanSL18}
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
\newblock Certified defenses against adversarial examples.
\newblock In {\em {ICLR}}, 2018.

\bibitem{roque2007imlp}
Antonio Mu{\~n}oz~San Roque, Carlos Mat{\'e}, Javier Arroyo, and {\'A}ngel
  Sarabia.
\newblock i{MLP}: Applying multi-layer perceptrons to interval-valued data.
\newblock {\em Neural Processing Letters}, 25(2):157--169, 2007.

\bibitem{salman2019convex}
Hadi Salman, Greg Yang, Huan Zhang, Cho-Jui Hsieh, and Pengchuan Zhang.
\newblock A convex relaxation barrier to tight robustness verification of
  neural networks.
\newblock {\em NeurIPS'19}, 32, 2019.

\bibitem{DBLP:conf/iclr/SamangoueiKC18}
Pouya Samangouei, Maya Kabkab, and Rama Chellappa.
\newblock Defense-gan: Protecting classifiers against adversarial attacks using
  generative models.
\newblock In {\em {ICLR}}, 2018.

\bibitem{DBLP:journals/corr/SimonyanZ14a}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In {\em {ICLR}}, 2015.

\bibitem{DBLP:conf/nips/SinghGPV19}
Gagandeep Singh, Rupanshu Ganvir, Markus P{\"{u}}schel, and Martin~T. Vechev.
\newblock Beyond the single neuron convex barrier for neural network
  certification.
\newblock In {\em NeurIPS}, pages 15072--15083, 2019.

\bibitem{DBLP:journals/pacmpl/SinghGPV19}
Gagandeep Singh, Timon Gehr, Markus P{\"{u}}schel, and Martin~T. Vechev.
\newblock An abstract domain for certifying neural networks.
\newblock {\em Proc. {ACM} Program. Lang.}, 3:41:1--41:30, 2019.

\bibitem{DBLP:conf/iclr/SongKNEK18}
Yang Song, Taesup Kim, Sebastian Nowozin, Stefano Ermon, et~al.
\newblock {P}ixel{D}efend: Leveraging generative models to understand and
  defend against adversarial examples.
\newblock In {\em {ICLR}}, 2018.

\bibitem{DBLP:conf/cvpr/SzegedyLJSRAEVR15}
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, et~al.
\newblock Going deeper with convolutions.
\newblock In {\em {CVPR}}, pages 1--9, 2015.

\bibitem{titano2018automated}
Joseph~J Titano, Marcus Badgeley, Javin Schefflein, Margaret Pain, et~al.
\newblock Automated deep-neural-network surveillance of cranial images for
  acute neurologic events.
\newblock {\em Nature medicine}, 24(9):1337--1341, 2018.

\bibitem{tjandraatmadja2020convex}
Christian Tjandraatmadja, Ross Anderson, Joey Huchette, Will Ma, Krunal~Kishor
  Patel, and Juan~Pablo Vielma.
\newblock The convex relaxation barrier, revisited: Tightened single-neuron
  relaxations for neural network verification.
\newblock {\em NeurIPS'20}, 33:21675--21686, 2020.

\bibitem{DBLP:conf/nips/WangPWYJ18}
Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, et~al.
\newblock Efficient formal safety analysis of neural networks.
\newblock In {\em NeurIPS}, pages 6369--6379, 2018.

\bibitem{DBLP:conf/uss/WangPWYJ18}
Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, et~al.
\newblock Formal security analysis of neural networks using symbolic intervals.
\newblock In {\em {USENIX} Security}, pages 1599--1614, 2018.

\bibitem{DBLP:conf/nips/WangZXLJHK21}
Shiqi Wang, Huan Zhang, Kaidi Xu, Xue Lin, et~al.
\newblock Beta-{CROWN}: Efficient bound propagation with per-neuron split
  constraints for neural network robustness verification.
\newblock In {\em NeurIPS}, pages 29909--29921, 2021.

\bibitem{DBLP:conf/emnlp/WolfDSCDMCRLFDS20}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, et~al.
\newblock Transformers: State-of-the-art natural language processing.
\newblock In {\em {EMNLP}}, pages 38--45, 2020.

\bibitem{DBLP:conf/icml/WongK18}
Eric Wong and J.~Zico Kolter.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In {\em {ICML}}, volume~80, pages 5283--5292, 2018.

\bibitem{DBLP:conf/nips/WongSMK18}
Eric Wong, Frank~R. Schmidt, Jan~Hendrik Metzen, and J.~Zico Kolter.
\newblock Scaling provable adversarial defenses.
\newblock In {\em {NeurIPS}}, pages 8410--8419, 2018.

\bibitem{Wu_2017_CVPR_Workshops}
Bichen Wu, Forrest Iandola, Peter~H. Jin, and Kurt Keutzer.
\newblock Squeezedet: Unified, small, low power fully convolutional neural
  networks for real-time object detection for autonomous driving.
\newblock In {\em CVPR}, 2017.

\bibitem{DBLP:conf/nips/WuX020}
Dongxian Wu, Shu{-}Tao Xia, and Yisen Wang.
\newblock Adversarial weight perturbation helps robust generalization.
\newblock In {\em NeurIPS}, 2020.

\bibitem{wu2021tightening}
Yiting Wu and Min Zhang.
\newblock Tightening robustness verification of convolutional neural networks
  with fine-grained linear approximation.
\newblock In {\em AAAI}, pages 11674--11681, 2021.

\bibitem{DBLP:conf/iccv/XiaoDLLEYSLM19}
Chaowei Xiao, Ruizhi Deng, Bo Li, Taesung Lee, et~al.
\newblock Advit: Adversarial frames identifier based on temporal consistency in
  videos.
\newblock In {\em ICCV}, pages 3967--3976, 2019.

\bibitem{DBLP:conf/eccv/XiaoDLYLS18}
Chaowei Xiao, Ruizhi Deng, Bo Li, Fisher Yu, et~al.
\newblock Characterizing adversarial examples based on spatial consistency
  information for semantic segmentation.
\newblock In {\em ECCV}, volume 11214, pages 220--237, 2018.

\bibitem{DBLP:conf/ijcai/XiaoLZHLS18}
Chaowei Xiao, Bo Li, Jun{-}Yan Zhu, Warren He, et~al.
\newblock Generating adversarial examples with adversarial networks.
\newblock In {\em {IJCAI}}, pages 3905--3911, 2018.

\bibitem{DBLP:conf/cvpr/XiaoYLDL19}
Chaowei Xiao, Dawei Yang, Bo Li, Jia Deng, et~al.
\newblock Meshadv: Adversarial meshes for visual recognition.
\newblock In {\em {CVPR}}, pages 6898--6907, 2019.

\bibitem{DBLP:conf/iclr/XiaoZ0HLS18}
Chaowei Xiao, Jun{-}Yan Zhu, Bo Li, Warren He, et~al.
\newblock Spatially transformed adversarial examples.
\newblock In {\em {ICLR}}, 2018.

\bibitem{DBLP:conf/iclr/XuLZCZFEWL19}
Kaidi Xu, Sijia Liu, Pu Zhao, Pin{-}Yu Chen, et~al.
\newblock Structured adversarial attack: Towards general implementation and
  better interpretability.
\newblock In {\em {ICLR}}, 2019.

\bibitem{yang2012smoothing}
Dakun Yang and Wei Wu.
\newblock A smoothing interval neural network.
\newblock {\em Discrete Dynamics in Nature and Society}, 2012:1--25, 2012.

\bibitem{DBLP:conf/ijcai/YuQLZWC19}
Fuxun Yu, Zhuwei Qin, Chenchen Liu, Liang Zhao, et~al.
\newblock Interpreting and evaluating neural network robustness.
\newblock In {\em {IJCAI}}, 2019.

\bibitem{DBLP:conf/iclr/ZhangCSBDH19}
Huan Zhang, Hongge Chen, Zhao Song, Duane~S. Boning, et~al.
\newblock The limitations of adversarial training and the blind-spot attack.
\newblock In {\em {ICLR}}, 2019.

\bibitem{DBLP:conf/iclr/ZhangCXGSLBH20}
Huan Zhang, Hongge Chen, Chaowei Xiao, Sven Gowal, et~al.
\newblock Towards stable and efficient training of verifiably robust neural
  networks.
\newblock In {\em {ICLR}}, 2020.

\bibitem{zhang2018efficient}
Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, et~al.
\newblock Efficient neural network robustness certification with general
  activation functions.
\newblock In {\em NeurIPS}, pages 4944--4953, 2018.

\bibitem{DBLP:journals/corr/abs-2208-09872}
Zhaodi Zhang, Yiting Wu, Si Liu, Jing Liu, and Min Zhang.
\newblock Provably tightest linear approximation for robustness verification of
  {Sigmoid-like} neural networks.
\newblock In {\em ASE}, 2022.

\end{thebibliography}

\clearpage
\nobalance
\input{appendix}

\end{document}
