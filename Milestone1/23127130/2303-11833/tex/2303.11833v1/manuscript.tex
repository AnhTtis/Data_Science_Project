%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%


%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

% \documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
% \documentclass[sn-mathphys]{sn-jnl}% Math and Physical Sciences Reference Style
\documentclass[sn-mathphys,Numbered]{sn-jnl}
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[sn-vancouver]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style
%%\documentclass[sn-standardnature]{sn-jnl}% Standard Nature Portfolio Reference Style
%%\documentclass[default]{sn-jnl}% Default
%%\documentclass[default,iicol]{sn-jnl}% Default with double column layout

%%%% Standard Packages
%%<additional latex packages if required can be included here>
%%%%

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 

%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%


\jyear{2023}%

%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%
\newcommand{\ignore}[1]{}


\raggedbottom

\usepackage{graphics}
\usepackage{natbib}
\usepackage{lipsum}
\usepackage{pdfpages}

% \usepackage{suffix}
% \usepackage{amsmath, amssymb}
% \usepackage{calligra}
% \usepackage{calrsfs}
% \usepackage[mathscr]{euscript}
% \usepackage{xparse}
% \usepackage{enumitem,booktabs}
\usepackage[referable]{threeparttablex}

\DeclareMathOperator{\E}{\mathbb{E}}

%%\unnumbered% uncomment this for unnumbered level heads

\begin{document}

\title[ ]{Materials Discovery with Extreme Properties via AI-Driven Combinatorial Chemistry}

%%=============================================================%%
%% Prefix	-> \pfx{Dr}
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% NatureName	-> \tanm{Poet Laureate} -> Title after name
%% Degrees	-> \dgr{MSc, PhD}
%% \author*[1,2]{\pfx{Dr} \fnm{Joergen W.} \spfx{van der} \sur{Ploeg} \sfx{IV} \tanm{Poet Laureate} 
%%                 \dgr{MSc, PhD}}\email{iauthor@gmail.com}
%%=============================================================%%

\author[1]{\fnm{Hyunseung} \sur{Kim}}
\equalcont{These authors contributed equally to this work.}

\author[2,3]{\fnm{Haeyeon} \sur{Choi}}
\equalcont{These authors contributed equally to this work.}

\author[1]{\fnm{Dongju} \sur{Kang}}
\equalcont{These authors contributed equally to this work.}

\author*[1]{\fnm{Won Bo} \sur{Lee}}\email{wblee@snu.ac.kr}

\author*[2,3]{\fnm{Jonggeol} \sur{Na}}\email{jgna@ewha.ac.kr}

\affil[1]{\orgdiv{School of Chemical and Biological Engineering}, \orgname{Seoul National University}, \orgaddress{\street{Gwanak-ro 1, Gwanak-gu}, \city{Seoul}, \postcode{08826}, \country{Republic of Korea}}}

\affil[2]{\orgdiv{Department of Chemical Engineering and Materials Science}, \orgname{Ewha Womans University}, \orgaddress{\street{52, Ewhayeodae-gil, Seodaemun-gu}, \city{Seoul}, \postcode{03760}, \country{Republic of Korea}}}

\affil[3]{\orgdiv{Graduate Program in System Health Science and Engineering}, \orgname{Ewha Womans University}, \orgaddress{\street{52, Ewhayeodae-gil, Seodaemun-gu}, \city{Seoul}, \postcode{03760}, \country{Republic of Korea}}}

%%==================================%%
%% sample for unstructured abstract %%
%%==================================%%

\abstract{The goal of most materials discovery is to discover materials that are superior to those currently known. Fundamentally, this is close to extrapolation, which is a weak point for most machine learning models that learn the probability distribution of data. Herein, we develop AI-driven combinatorial chemistry, which is a rule-based inverse molecular designer that does not rely on data. Since our model has the potential to generate all possible molecular structures that can be obtained from combinations of molecular fragments, unknown materials with superior properties can be discovered. We theoretically and empirically demonstrate that our model is more suitable for discovering better materials than probability distribution-learning models. In an experiment aimed at discovering molecules that hit seven target properties, our model discovered 1,315 of all target-hitting molecules and 7,629 of five target-hitting molecules out of 100,000 trials, whereas the probability distribution-learning models failed. To illustrate the performance in actual problems, we also demonstrate that our models work well on two practical applications: discovering protein docking materials and HIV inhibitors.}

%\def\thefootnote{†}\footnotetext{These authors contributed equally to this work}

%%================================%%
%% Sample for structured abstract %%
%%================================%%

% \abstract{\textbf{Purpose:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Methods:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Results:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Conclusion:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.}

\keywords{Materials discovery, Materials extrapolation, Out-of-distribution, AI-driven combinatorial chemistry, Fragment-based RL}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle
\section{Introduction}\label{sec1}

The task of discovering materials that are superior to those currently known is a challenging problem in various fields of materials science, including pharmaceutical materials\cite{pommier2005integrase, yang2021hit, kitchen2004docking, gottipati2020learning}, electrical and electronic materials\cite{klein2010conductors, greenaway2021integrating, sylvinson2019OLED, kim2018OLED, LOCO, ext_limit1, pyzer2015HTS}, energy materials\cite{pyzer2015HTS, liu2022QSPR, dan2020unconditionedGAN, sv2022multi}, metals and ceramics\cite{ext_limit1}, nanomaterials\cite{dong2020RCGAN}, and polymeric materials\cite{lyu2015plastics, stauber2007plastics}. Some of these studies aim to discover materials with two or more target properties that contradict each other, meaning it is difficult for them to coexist\cite{zunger2018inverse}. For example, super engineering plastics used in automobiles should be lighter than metals yet have similar mechanical strength\cite{lyu2015plastics, stauber2007plastics}. Similarly, transparent conductors used in display panels should be both optically transparent (requiring a large bandgap) and electrically conductive (requiring high carrier concentration, which generally has a low bandgap)\cite{zunger2018inverse, klein2010conductors}. In some  cases, the aim is to discover materials that have properties with either extremely high or low values. For example, the development of a better organic light-emitting diode (OLED) requires chemists to discover novel materials with higher efficiency and stability\cite{greenaway2021integrating, sylvinson2019OLED, kim2018OLED}. Here, the problem is that there are no (or few) known samples that have such properties compared to common materials. This makes it difficult for chemists to gain insights or knowledge from the known materials, that could help to infer the molecular structures of the desired materials. Unfortunately, this situation also holds for most machine learning models that learn the data. Therefore, it is necessary to develop a model that can discover materials, even in regions with little or no known data. In this paper, we refer to this problem as \textit{materials extrapolation}.

In recent years, it has been reported that machine learning techniques can solve many challenging problems in a wide range of fields, including materials discovery. In particular, models for goal-directed inverse molecular design are attractive because they can directly infer the molecular structures that meet a set of given target conditions such as scaffolds\cite{mendez2020cGAN, yang2021hit}, physical properties\cite{dong2020RCGAN, lim2018cVAE_seongokRyu, Kim2021GCT, kotsias2020cRNN}, and biological activities\cite{kotsias2020cRNN, gottipati2020learning, yang2021hit}. Some of these studies have proposed models based on neural machine translation (NMT) such as seq2seq\cite{sutskever2014seq2seq_original, kotsias2020cRNN} and Transformer\cite{vaswani2017Transformer_original}, which translate input target conditions to corresponding molecular structures. Models based on conditional generative models have also been proposed, such as conditional generative adversarial networks (cGANs)\cite{mirza2014cGAN_original} and conditional variational autoencoders (cVAEs)\cite{sohn2015cVAE_original}. These models directly generate molecular structures to meet a set of given target conditions\cite{dong2020RCGAN, mendez2020cGAN, lim2018cVAE_seongokRyu, Kim2021GCT}. In contrast, there are also ways to obtain the desired materials from unconditional generative models, such as generative adversarial networks (GANs)\cite{goodfellow2014GAN_original} and variational autoencoders (VAEs)\cite{kingma2013VAE_original}. These approaches use additional methods to find appropriate latent code, which is required to generate the target-hitting materials. Navigating policies of latent space trained by reinforcement learning (RL)\cite{guimaraes201GAN+RL, sanchez2017GAN+RL} and optimization techniques\cite{blaschke2018VAE+BayesianOpt, griffiths2020VAE+BayesianOpt} belong here.

\begin{figure}[t!]
    \centering
    \includegraphics[width=1.0\textwidth]{Figs/figure1.jpg}
    \caption{\textbf{Comparison of molecular data distribution.} The red dots in the left-hand side figure denote the molecules in MOSES\cite{polykovskiy2020moses} training data. The other dots denote the molecules generated by MOSES baseline models which were trained with MOSES training data. Since the MOSES baseline models are probability distribution-learning models such as NMT, GAN, VAE, and AAE, the distribution of generated molecules approximates the distribution of their training data. The magenta triangles and blue diamonds indicate real molecules in ChEMBL\cite{mendez2019chembl} database, which have extrapolated properties from MOSES training data distribution.}\label{fig:moses_distribution}
\end{figure}

Unfortunately, all of the previously mentioned models (NMT, GAN, and VAE-based) are difficult to use in materials extrapolation for discovering novel materials with properties that are out of training data distribution (Fig. ~\ref{fig:moses_distribution}). To generate realistic molecules with these models, the models should be trained to generate molecular data that approximate the probability distribution of the chemical system. However, since it is impossible to know the true probability of the chemical system, the models are trained to generate data that approximate the empirical probability of the training data. Hence, the \textit{probability distribution-learning models} are not suitable for generating materials in regions with little or no known data (such as materials extrapolation). In addition, there are several ongoing discussions about whether probability distribution-learning models are suitable for extrapolation problems\cite{LOCO, ext_limit1, polykovskiy2020moses}.

Combinatorial chemistry\cite{combinatorial_chemistry} was invented in the 1980s and can generate molecules with properties out of known data. These types of methods use a set of molecular fragments and rules for fragment combination. Breaking of retrosynthetically interesting chemical substructures (BRICS)\cite{degen2008BRICS} is an example of combinatorial chemistry. This technique involves combining randomly selected BRICS fragments with their template-based fragment combination rules, which is similar to assembling Lego blocks. Therefore, combinatorial chemistry can create all physically possible molecular structures that can be obtained from the combination of molecular fragments. According to our estimation, approximately $4\times 10^{16}$ types of small molecules ($\leq 500$ $Da$) can be combined with 2,207 BRICS fragments. Considering that the total number of small molecules is known to be $10^{60}$\cite{bohacek199610^60}, this means that it can cover a fairly wide area. However, there is the limitation that the combinatorial chemistry-based molecular generator does not know which molecular fragments to be selected to complete the desired material. In other words, it has no policy to guide the selection of molecular fragments to obtain the target material. Hence, it proceeds with countless attempts to combine randomly selected fragments and selects the best compound from the generated material candidates, which can result in a combinatorial explosion\cite{klaus1986web}. If we assume that it takes 1 s to assemble one molecule, it would take $1.27\times10^{9}$ years to enumerate all possible small organic molecules using 2,207 molecular fragments; $4\times10^{16}$ molecules $\times 1$ second $= 1.27\times10^{9}$ years.

Herein, we introduce RL to provide combinatorial chemistry with a molecular fragment selection policy that guides the generating molecule towards the target. With a randomly selected initial fragment, the AI-driven policy iteratively selects the next fragment to be combined. In the training phase, the policy is learned by giving a higher reward if the properties of the generated molecule are closer to the target. Therefore, the learned policy enables an efficient search of chemical space and helps to escape from the combinatorial explosion problem by providing direction to the target. Moreover, the proposed model\textemdash \textit{AI-driven combinatorial chemistry}\textemdash enables materials extrapolation, which is impossible for probability distribution-learning models. To demonstrate this concept empirically, we apply AI-driven combinatorial chemistry and two probability distribution-learning models to a discovery problem of extreme materials that hit multiple target properties simultaneously. The results indicate that our model can discover extreme target materials that probability distribution-learning models cannot reveal. Furthermore, we theoretically demonstrate why the probability distribution-learning models are not suitable for problems involving materials extrapolation. To illustrate the performance in actual problems, we conduct two practical experiments on materials extrapolation. The first is to discover protein docking materials to a 5-hydroxytryptamine receptor 1B (5-HT\textsubscript{1B} receptor) with high binding affinity. The second is the discovery of human immunodeficiency virus (HIV) inhibitors with high potency. These two experiments demonstate that the proposed model can solve various problems involving materials extrapolation.

%In fact, this kind of inverse materials design is not entirely new\cite{gottipati2020learning, sv2022multi, yang2021hit, flam2022scalable}, but to the best of our knowledge, there has been no discussion about the use of RL rather than probability distribution-learning models for the purpose of materials extrapolation. In this study, we propose an AI-driven combinatorial chemistry with BRICS that can be used to discover materials with extreme properties, namely, materials extrapolation. This study makes three major contributions. First, we theoretically show that the probability distribution-learning models (e.g., NMT, GAN, and VAE-based models) are not suitable for the problems of materials extrapolation. Second, we demonstrate it empirically through two experiments to discover drug-like compounds that hit the extrapolated targets of five to seven auxiliary drug indicators. Here, we quantitatively compare the hitting abilities of our AI-driven combinatorial chemistry model and two probability distribution-learning models. One is conditional recurrent neural network (cRNN)\cite{kotsias2020cRNN}, an NMT-based translator. The other is generative chemical Transformer (GCT)\cite{Kim2021GCT}, a cVAE-based generative model. The results show that both probability distribution-learning models do not work at all for the extrapolated targets outside the trained area (materials extrapolation), however, AI-driven combinatorial chemistry can do. Third, we show that the proposed model is a universal model by applying it to two practical applications of materials discovery. One of them is the ligands discovery used for protein-ligand docking. This problem is to discover a small molecule (ligand) that can bind to a target protein receptor. For the 5-hydroxytryptamine receptor 1B (5-HT\textsubscript{1B} receptor), it is confirmed that our model discovers ligands with a binding affinity higher than that of known drug-like materials. The other is an experiment to discover inhibitors that are active against the human immunodeficiency virus (HIV). Benchmark results show that the discovered inhibitors are estimated to have higher pIC50 compared to those of reference models, which indicates that have higher drug activity.

\section{Results}\label{results}

\subsection{Theoretical review of probability distribution-learning models}\label{results_limit_of_dist}

Inverse molecular design models based on NMT, VAE, and GAN learn the empirical probability distribution of training data $P_{data}$. Let $X,Y=({X}_1, {Y}_1),...,({X}_N, {Y}_N)$ denote $N$-sampled training data. Here, ${X}_i=(x_{i,1},...,x_{i,T'})$ denotes sequence data of the $i$-th molecular structure, and ${Y}_i=(y_{i,1},...,y_{i,T})$ denote a set of properties of the $i$-th molecule. The NMT-based models are trained to translate the input ${Y}_i=(y_{i,1},...,y_{i,T})$ into a paired output sequence ${X}_i=(x_{i,1},...,x_{i,T'})$. Here, $x_{i,t}$ is a one-hot encoded vector of the $t$-th token constituting a molecule ${X}_i$. The $\theta$-parameterized translator $G_\theta^{NLP}$ should be trained to select a token $x_{i,t}$ iteratively over $t=1,...,T'$, by maximizing the likelihood $\prod_{i=1}^{N}\prod_{t=1}^{T'} G_{\theta}^{NLP}\left(x_{i,t} \mid Y_i,x_{i,1:t-1}\right)$ empirically. The actual training process is conducted by minimizing its negative log-likelihood $-\sum_{i=1}^{N}\sum_{t=1}^{T'} \log G_{\theta}^{NLP}\left(x_{i,t} \mid Y_i,x_{i,1:t-1}\right)$, which is equivalent to minimizing cross-entropy $H(\cdot\,,\cdot)$ of hypothesis $\hat{X}_\theta$ from training data $X$:

\begin{equation} \label{eqn:loss_CE}
\begin{split}
H(X, \hat{X}_\theta) & = -\sum_{i=1}^{N} \sum_{t=1}^{T'} P(X) \log P(\hat{X}_\theta) \\
 & = H\left(X\right) + D_{KL}\left(P(X) \parallel P(\hat{X}_\theta)\right)
\end{split}
\end{equation}

\noindent where $H(X)=-\sum_{i=1}^{N} \sum_{t=1}^{T'} P(X)\log P(X)$ denotes the entropy\cite{shannon2001entropy} of training data X, and $D_{KL}(P(X) \parallel P(\hat{X}_\theta))$ is the Kullback–Leibler (KL) divergence\cite{kullback1951KLD} of hypothesis probability $P(\hat{X}_\theta)$ from $P_{data}$. Since $H(X)$ is not a function of trainable parameter $\theta$, minimizing the cross-entropy $H(X, \hat{X}_\theta)$ is equivalent to minimizing the KL divergence term in Equation (\ref{eqn:loss_CE}). Thus, the optimal $G_{\theta^*}^{NLP}$ is obtained by approximating $P(\hat{X}_\theta)$\textemdash which is the probability distribution of data generated by $G_{\theta}^{NLP}$\textemdash to $P_{data}$. It means that $G_{\theta}^{NLP}$ learns the empirical probability distribution of training data $P_{data}$, not the true probability distribution of the system $P$.

Second, VAE-based models are types of generative self-learning models that learn the empirical probability distribution of training data $P_{data}$. The models are trained to encode training data $X=X_1,...,X_N$ in the latent space with encoder $Q_{\phi}^{VAE}$ and reconstruct it with decoder $G_{\theta}^{VAE}$. The difference from autoencoders is that the latent variables $z$ are constrained to follow a prior distribution such as normal distribution. The VAEs are trained using the following objective function\cite{kingma2013VAE_original}:

\begin{equation}
\label{eqn:negative-elbo}
\operatorname*{argmin}_{\phi,\theta} \sum_{i=1}^{N} -\mathbb{E}_{Q_{\phi}^{VAE}(z \mid X_i)} \left[\log G_{\theta}^{VAE}(X_i \mid z)\right] + D_{KL}\left(Q_{\phi}^{VAE}(z \mid X_i) \parallel P(z)\right)\\
\end{equation}

When looking at the VAEs from the perspective of a generative model, the KL divergence term simply acts like a regularizer in the training process. The expectation term measures the  reconstruction error of $G_{\theta}^{VAE}$ and it is approximated by using the following $L$-number of Monte-Carlo sampling:

\begin{equation}
\label{eqn:reformulated_negative-elbo}
-\mathbb{E}_{Q_{\phi}^{VAE}(z \mid X_i)} \left[\log G_{\theta}^{VAE}(X_i \mid z)\right] \approx -\frac{1}{L}\sum_{z_j=1}^L \log\left(G_{\theta}^{VAE}(X_i \mid z_j)\right)\\
\end{equation}

Here, the approximated reconstruction error term is a form of negative log-likelihood over training data $X$. Hence, it is equivalent to minimizing the cross-entropy $H(\cdot\,,\cdot)$ of hypothesis $\hat{X}_{\theta,z}$ from training data $X$:

\begin{equation} \label{eqn:loss_CE_VAE}
\begin{split}
H(X, \hat{X}_{\theta,z}) & = -\sum_{i=1}^{N} \sum_{t=1}^{T'} P(X) \log P(\hat{X}_{\theta,z}) \\
 & = H\left(X\right) + D_{KL}\left(P(X) \parallel P(\hat{X}_{\theta,z})\right)
\end{split}
\end{equation}

As mentioned above, this is also equivalent to minimizing the KL divergence term in Eqation (\ref{eqn:loss_CE_VAE}), since $H(X)$ is not a function of trainable parameter $\theta$. Hence, the optimal $G_{\theta^*}^{VAE}$ is obtained by approximating the probability distribution of hypothesis $P(\hat{X}_{\theta,z})$ to the $P_{data}$. This means that $G_{\theta}^{VAE}(X \mid z)$ with $z\sim Q_{\phi}^{VAE}\left(z \mid X\right)$ approximates $P_{data}$.

Third, GAN is also a model to obtain a generator $G_{\theta}^{GAN}$ that approximates $P_{data}$. Here, $G_{\theta}^{GAN}$ learns the $P_{data}$ in the learning process to generate data that sufficiently resembles training data $X$ to deceive the discriminator $D_{\phi}^{GAN}$. Note that it has been proved that the global minimum of the virtual training criterion of the generator is achieved if (and only if) $P_{data} = G_{\theta}^{GAN}(z)$\cite{goodfellow2014GAN_original}. This means that the optimal $G_{\theta^*}^{GAN}$ is obtained by approximating the hypothesis probability $P(\hat{X}_{z})$ to the probability of training data $P_{data}$.

Therefore, it can be concluded that models based on NMT, VAE, and GAN used for inverse molecular design are models to derive an approximator of $P_{data}$. Unfortunately, since $P_{data}$ derived from the observed empirical data is not equal to the true probability $P$, it cannot guarantee that the probability-distribution learning models will work well for problems involving materials extrapolation.

\subsection{AI-driven combinatorial chemistry with BRICS}\label{results_modeling}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=1.0\textwidth]{Figs/figure2.jpg}
    \caption{\textbf{Overview of AI-driven combinatorial chemistry with BRICS.} \textbf{a} Training loop. Depending on the given task, target error function $\varepsilon$, rewards $r$, and termination conditions $c$ are designed. Each episode involves a maximum of $T$ iterations of selecting and combining molecular fragments. If one of termination condition $c$ is met, the process is terminated early before reaching the maximum step $T$. In this process, the model learns a policy that selects a molecular fragment $a_{t}$ to bind to the molecule at step $t$ $(s_{t})$ to maximize the final reward $r_{T+1}$. \textbf{b} Environment at step $t$. To evaluate a molecular property, the tested molecule must not have unfilled binding sites. Accordingly, hydrogen is attached to the remaining binding sites of the combined molecule $s_{t+1}$. Here, $s'_{t+1}$ denotes a potential output molecule at step $t$. \textbf{c} Two types of tasks. Task A refers to a task to find multiple target-hitting molecules. Task B refers to a task to find a molecule that maximizes a property. \textbf{d} Types of evaluators. \textbf{e} Modified BRICS\cite{degen2008BRICS} fragment combination rules. Here, the RDKit\cite{rdkit} version 2020.09.1.0 of the modified BRICS rules is adopted. There are 16 templates of BRICS molecular fragments with unique binding sites (colored red). The fragment template with 2*-binding site is removed in the modified version. This figure is modified from Degen et al., 2008, \emph{ChemMedChem}, 10(3): 1503-1507\cite{degen2008BRICS}, with permission of Wiley-VCH GmbH. \textbf{f} Fragment set $B$. Here, $B\cup\{end\}$ is defined as action space. \textbf{g} Action masking example. An example of generating a target-hitting molecule is shown in \textbf{h} and \textbf{i}.}\label{fig:model_scheme}
\end{figure}

The AI-driven combinatorial chemistry, illustrated in Fig. \ref{fig:model_scheme} is universally applicable to a variety of material discovery tasks, by designing a target molecule with a randomly selected molecular fragment. A trained AI-driven policy iteratively selects the next fragment to be combined. Here, the AI-driven policy serves as a guide to generate a target-hitting molecule. This approach has three main phases: configuration settings (Fig. \ref{fig:model_scheme}c\textrm{--}f), training (Fig. \ref{fig:model_scheme}a,b), and inference (Fig. \ref{fig:model_scheme}h,i).

In the configuration settings phase, all settings necessary for reinforcement learning are customized. Accordingly, the task for materials discovery must be specified. There are two types of tasks for this (Fig. \ref{fig:model_scheme}c): the discovery of materials to hit the multiple target properties (Task A), and the discovery of materials to maximize or minimize a specific property (Task B). Depending on the type of given task, the user designs the reward function $r$, target error function $\varepsilon$, and termination conditions $c$. The reward function $r$ is designed to give a higher reward the better a given task is performed. For Task A, the target error function $\varepsilon$ and reward function $r$ are designed as sum errors for the multiple target properties and the reciprocal of the target error function $\varepsilon$, respectively. In the case of Task B, the property itself is used as the reward function $r$; hence, maximizing $r$ is equivalent to maximizing the property. For the minimization case of Task B, the negative property is used as the reward function $r$. We can also consider the constraints $p$, which are reflected in the reward function $r$ by giving penalties if one of the constraints $p$ is not satisfied. Here, the minimum molecular weight ($MW_{min}$) and minimum number of fragments ($n_{min}$) that make up a molecule can be used as constraints $p$. These enable the model to generate various molecules by preventing premature termination, which would cause the generation of molecules that were too small and uniform.

The termination conditions ($c$) pertain to deciding when to terminate the process of selecting and combining additional molecular fragments, which determines the characters of the final output molecule. Hence, the termination conditions $c$ are designed considering the given task. The molecular generation process is terminated early if one of the termination conditions $c$ is satisfied. Accordingly, the maximum target error ($\varepsilon_{max}$), maximum molecular weight ($MW_{max}$), and maximum number of fragments ($n_{max}$) are used to design the termination conditions ($c$). It should be noted that the process is also terminated if there are no more sites for binding fragments to the combined molecule at step $t$ $(s_{t+1})$ or if the action at step $t$ ($a_t$) is the \textit{end} action. These are also included in the termination conditions $c$.

To evaluate the previously mentioned functions and conditions, the evaluators for the interesting properties (Fig. \ref{fig:model_scheme}d) are utilized selectively to calculate the properties of potential output molecule at step $t$ $(s^{'}_{t+1})$. Here, $s^{'}_{t+1}$ is a molecule derived by attaching hydrogen to the unfilled binding sites of the combined molecule at step $t$ $(s_{t+1})$ if $s_{t+1}$ has any unfilled binding site (See Fig. \ref{fig:model_scheme}b). Here, RDKit\cite{rdkit} was used selectively to evaluate the calculated octanol-water partition coefficient (logP)\cite{logP}, topological polar surface area (TPSA)\cite{TPSA}, quantitative estimates of drug-likeness (QED)\cite{QED}, number of hydrogen bond acceptors (HBA), number of hydrogen bond donors (HBD), and molecular weight (MW). A quantitative structure-activity relationship (QSAR) model\cite{kotsias2020cRNN} and QVina2\cite{alhossary2015fast}\textemdash, which is a tool for discovering the minimum-energy docking conformation of a tested molecule and calculating its docking score, are also selectively used to evaluate drug activity for dopamine receptor D2 (DRD2) and the binding affinity to the 5-HT\textsubscript{1B} receptor, respectively.

For combinatorial chemistry, fragment set $B$ and its combination rules should be set. Accordingly, a modified version\cite{rdkit} of the BRICS\cite{degen2008BRICS} system was adopted (Fig. \ref{fig:model_scheme}e,f). Since the best performance was achieved for approximately 2k action spaces in the preliminary experiments (Supplementary Note 2), approximately 2k fragments were sampled from BRICS 40k for fragment set $B$. The BRICS fragment combination rules are rules to bind 16 molecular templates, where each template has a unique binding site (red digit in Fig. \ref{fig:model_scheme}e).

%The model learns an action policy to iteratively select the next molecular fragment to complete a compound that is suited to a given task. e.g., a task to find compounds that are likely to hit a set of target properties or a task to find compounds that maximize or minimize some specific properties. The given tasks are used to set up the basic configuration of RL such as reward function, termination conditions, penalty function, and the set of molecular fragments (Step 1 in Fig. \ref{fig:model_scheme}b). The reward function is designed to give a higher reward if the better the given task is performed. For example, if the given task is to maximize a score, the score function itself can be used as a reward function. If the given task is to hit a set of given targets, a form of reciprocal of z-score normalized residual sum square (RSS) may be used as the reward function. Furthermore, some constraints can be reflected in the reward function by giving penalties if the constraints are not satisfied. For example, a lower-bound of molecular weight (MW) or a minimum number of fragments that make up a compound can be used as one of the constraints. These enable the model to produce various compounds by avoiding early termination. The game of fragment selection is terminated if one of the termination conditions is satisfied. Here, the termination conditions may include things like whether the evaluated properties of the current intermediate (potential output at current state) are within the target bound, or whether the maximum MW or the maximum number of fragments has been exceeded. Here, the action space (the set of molecular fragments) is set with 2K BRICS fragments sampled from BRICS 40K, which appear most in the molecules in the training data set. This can be found by referring to Supplementary Notes and Supplementary Figure 1.

In the training phase, our model was trained using the proximal policy optimization (PPO) algorithm\cite{schulman2017PPO}, which is known to perform well in RL problems with discrete actions. This is because it has the advantages of stable training, sample efficiency, scalability, and flexibility. In the preliminary experiments, PPO performed optimally for our problem among several state-of-the-art RL algorithms (Supplementary Note 3). An episode iteratively proceeds the process of selecting and combining molecular fragments from steps 0 to $T$ (Fig. \ref{fig:model_scheme}a). If one of the termination conditions $c$ is satisfied, the episode is prematurely terminated at the step (Fig. \ref{fig:model_scheme}b). At step 0, an episode is started with a randomly selected fragment $s_0$, and the randomness makes the final output molecule $s^{'}_{T+1}$ various. Subsequently, action masking is performed, which masks the actions that are not applicable to $s_0$. Fig. \ref{fig:model_scheme}g displays an example of action masking at step $t$, in which molecule $s_t$ has an unfilled binding site of 11*. As shown in Fig. \ref{fig:model_scheme}e, the 11*-binding site can bind to the 4*, 13*, 14*, 15*, and 16*-binding sites. Hence, blocks $b_4, b_6, b_8, b_{10}, ..., b_{L}$ that do not have any binding sites of 4*, 13*, 14*, 15*, and 16* are masked. Thereby, the fragment selection policy is enforced not to select the masked actions. This action masking helps to generate molecules that do not violate the chemical valence rule and enables efficient learning by reducing the action space. In this way, the fragment selection policy selects an action at step 0 ($a_0$) from the unmasked actions.

If the selected action at step $t$ ($a_t$) is the \textit{end}-action, the molecule at step $t$ ($s_t$) becomes $s_{t+1}$ (Fig. \ref{fig:model_scheme}b). Moreover, if $a_t$ is a fragment, $a_t$ is combined with $s_t$ to make a combined molecule at step $t$ ($s_{t+1}$). To evaluate the properties of a molecule, the molecule should not have any unfilled binding sites. Hence, the potential output molecule at step $t$ ($s^{'}_{t+1}$) is derived by attaching hydrogen to the remaining binding site of $s_{t+1}$. Then, the interesting properties of $s^{'}_{t+1}$ are evaluated to obtain the target error $\varepsilon_{t+1}$ and reward $r_{t+1}$ at step $t$. Now, to check whether one of the termination conditions $c$ is satisfied, $a_t$, $\varepsilon_{t+1}$, and $r_{t+1}$ are considered. If one of the termination conditions $c$ is satisfied, the reward $r_{t+1}$ and the potential output molecule $s_{t+1}$ at step $t$ are treated as the final reward $r_{T+1}$ and the final output molecule $s^{'}_{T+1}$, respectively. Then, the episode is terminated and the learner updates the fragment selection policy with $r_{T+1}$ (Fig. \ref{fig:model_scheme}a,b). If any of the termination conditions $c$ are not satisfied, the environment outputs the combined molecule $s_{t+1}$. Then, the model iteratively proceeds to the next step of the process until either one of the termination conditions $c$ is satisfied or the maximum step $T$ is reached. This process is repeated for a preset number of iterations to train the model.

%Accordingly, the starting fragment is treated as the current intermediate in the first round. In Step 2b, the available actions which are combinable to the current intermediate are masked based on the BRICS combination rules. Then, the policy network selects the next fragment among the masked fragments which will be combined with the current intermediate. In Step 2c, the selected fragment is combined with the current intermediate with the BRICS combination rules. Then, the current intermediate is updated to the combined compound. Now, the current intermediate may or may not have an unoccupied site. In the former case, hydrogen atoms are attached to the unoccupied sites according to the chemical valence rules. Note that the hydrogen-attached molecule is a potential output that has an intact molecular structure. In the latter case, the current intermediate is an intact potential output itself. The intact molecule is evaluated to get the properties of the current state which are needed to diagnose the current state (Step 2d). Then, the evaluated properties are used to calculate the reward. If one of the termination conditions is satisfied, it terminates the episode and updates the policy with the calculated reward (Step 2e). If none of the termination conditions is satisfied, it iterates Step 2b to Step 2d until one of the termination conditions is satisfied. The episode training is conducted repeatedly until the reward converges.

%After the basic configuration setup is completed, the policy network is trained using PPO algorithm\cite{schulman2017PPO} (Step 2 in Fig. \ref{fig:model_scheme}b). PPO is known to perform well in problems of RL with discrete action because it has advantages of stable trainning, sample efficiency, scalability, and flexibility. In the training phase, a game proceeds in such a way that each fragment is iteratively selected for an episode until one of the termination conditions is satisfied. The game is started with a randomly selected fragment (Step 2a). Here, the randomness makes the output compound various. In this paper, we will name the compound to be combined with a newly selected molecular fragment as the current intermediate. Accordingly, the starting fragment is treated as the current intermediate in the first round. In Step 2b, the available actions which are combinable to the current intermediate are masked based on the BRICS combination rules. Then, the policy network selects the next fragment among the masked fragments which will be combined with the current intermediate. In Step 2c, the selected fragment is combined with the current intermediate with the BRICS combination rules. Then, the current intermediate is updated to the combined compound. Now, the current intermediate may or may not have an unoccupied site. In the former case, hydrogen atoms are attached to the unoccupied sites according to the chemical valence rules. Note that the hydrogen-attached molecule is a potential output that has an intact molecular structure. In the latter case, the current intermediate is an intact potential output itself. The intact molecule is evaluated to get the properties of the current state which are needed to diagnose the current state (Step 2d). Then, the evaluated properties are used to calculate the reward. If one of the termination conditions is satisfied, it terminates the episode and updates the policy with the calculated reward (Step 2e). If none of the termination conditions is satisfied, it iterates Step 2b to Step 2d until one of the termination conditions is satisfied. The episode training is conducted repeatedly until the specified training iteration was reached.

After the training is completed, the trained policy is used to generate a target molecule in the inference phase. Fig. \ref{fig:model_scheme}h,i displays an example of molecular generation, in which new molecular fragments are selected and combined to complete a target molecule from steps 0 to 3. In the process, the properties of the generated potential output molecules ($s^{'}_1$ to $s^{'}_4$), which are derived from hydrogen attachment of the combined molecules ($s_1$ to $s_4$), change from the properties of a randomly selected molecular fragment ($s_0$) to the target properties (logP: $-0.488$, TPSA: $220.83$, QED: $0.207$, HBA: $9$, HBD: $8$). In step 3, the properties of the potential output molecule $s^{'}_4$ (logP: $-0.488$, TPSA: $211.09$, QED: $0.205$, HBA: $10$, HBD: $8$) are close to the target properties (Fig. \ref{fig:model_scheme}h). Since the target error $\varepsilon_4$ is lower than the maximum target error $\varepsilon_{max}$, the process is terminated at step 3. Hence, the potential output molecule at step 3 ($s^{'}_{4}$) becomes the final output molecule.

% Hit-like materials can be directly designed by using the trained policy (Step 3). Note that if a set of target properties changes, our RL model must be re-trained with the changed reward function. This is because it is hard to obtain a universal policy that works well on the changing targets. From the point of view of the optimization process to find an optimal policy, it is difficult to find a good solution if the target-dependent reward function\textemdash which is similar to the objective function\textemdash changes during the optimization process. This could be a limitation of AI-driven combinatorial chemistry, however, it is still meaningful in that it enables materials extrapolation which is impossible with the existing probability distribution-learning models. Our claim has been demonstrated empirically by the following experiments.

\subsection{Materials extrapolation to hit multiple extreme target properties}\label{results_chembl}

In this section, we empirically demonstrate that AI-driven combinatorial chemistry enables materials extrapolation, which is not possible with probability distribution-learning models. To achieve this, we adopt two different types of probability distribution-learning models and compare their performance with our model in terms of materials extrapolation. One of the adopted models is a conditional recurrent neural network (cRNN)\cite{kotsias2020cRNN} (an NMT-based translator), while the other is the generative chemical transformer (GCT)\cite{Kim2021GCT} (a cVAE-based generative model).

For the demonstration, we conducted experiments on generating molecules to hit multiple target properties. The experimental setup was borrowed from ref. \cite{kotsias2020cRNN}. In the experiments, the following seven drug-related target properties were given to the models to generate target-hitting molecules: logP, TPSA, QED, HBA, HBD, MW, and DRD2. Detailed information about the properties is summarized in Methods \ref{Molecular Descriptors}. Here, RDKit and a QSAR model for DRD2\cite{kotsias2020cRNN} were adopted as evaluators.

\begin{table}[t]
\centering
\caption{The target-hitting errors for materials interpolation}\label{tab:chembl_interpolation}
\begin{tabular}[t]{lccc}
\toprule
 & \multicolumn{2}{c}{$RMSE_i$} & \multicolumn{1}{c}{$\overline{RMSE_i}^{a}$\tnote{a}} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-4}
&cRNN\cite{kotsias2020cRNN}&GCT\cite{Kim2021GCT}&Average\tnotex{11}\\
\midrule
logP &0.379&0.368&0.373\\
TPSA &5.476&5.109&5.292\\
QED &0.081&0.075&0.078\\
HBA &0.932&1.204&1.068\\
HBD &0.223&0.247&0.235\\
MW &5.954&8.272&7.113\\
DRD2 &0.113&0.098&0.105\\
\bottomrule
\end{tabular}
\footnotetext[]{$^{a}\overline{RMSE_i}$ refers average $RMSE$ of target property $i\in \{logP, TPSA, QED, HBA, HBD, MW, DRD2\}$ for cRNN\cite{kotsias2020cRNN} and GCT\cite{Kim2021GCT}.}
\end{table}

First, the original performances of cRNN\cite{kotsias2020cRNN} and GCT\cite{Kim2021GCT} were evaluated to demonstate how their performance degraded on materials extrapolation. The two models were trained and tested with data sets\cite{kotsias2020cRNN} curated from the ChEMBL database\cite{mendez2019chembl}. Here, the original performance means how well target-hitting molecules were generated for the given target properties C0\textemdash which were gathered from 149,679 molecules in the curated ChEMBL test data\cite{kotsias2020cRNN}. For each of the 149,679 C0 targets, a molecular generation was tried with cRNN and GCT. Since the distributions of the test and training data were similar, the original performance evaluated for the test data could be considered the same as the performance for \textit{materials interpolation}.

To conduct the experiments on materials extrapolation, we adopted another molecular dataset with properties that were more widely distributed than the trained data\cite{kotsias2020cRNN}: PubChem SARS-CoV-2 clinical trials \cite{PubChemCovid19} (Fig. \ref{fig:chembl_results}a). Among the molecules in this dataset, 10 molecules were sampled whose properties were outside the trained data, which were then set as the extrapolated targets (C1 to C10). Since these 10 molecules were real molecules that exist in the real world, their properties would be physically feasible targets to generate. For each extrapolated target, 10,000 molecular generations were tried with cRNN\cite{kotsias2020cRNN} and GCT\cite{Kim2021GCT}.

To evaluate the performance of generating molecules that hit multiple target properties, the criteria for determining whether each target property was hit should be defined. Accordingly, in the experiment of materials interpolation with cRNN\cite{kotsias2020cRNN} and GCT\cite{Kim2021GCT}, the root mean squared error of each target property $i$ ($RMSE_{i}$) was analysed (Table \ref{tab:chembl_interpolation}). Since all $RMSE_{i}$ for cRNN and GCT were not significantly different from each other, we determined that the magnitude of the average $RMSE_{i}$ ($\overline{RMSE_{i}}$) represents the difficulty of generating molecules that hit the target property $i$. Therefore, by setting $\pm \overline{RMSE_{i}}$ as the target bound of $i$, a wide bound was assigned to targets that were difficult to hit and a narrow bound was assigned to any targets that were easy to hit. Furthermore, we introduced a relative error measurement metric ($pRMSE_{i}$), as follows:

\begin{equation}
\label{eqn:prmse}
pRMSE_i = \frac{\mid y_i - \hat{y}_i\mid}{\overline{RMSE_i}}
\end{equation}

\noindent where $y_i$ and $\hat{y}_i$ refer to the target property $i$ and the evaluated property $i$ of a generated molecule, respectively. To assess the overall performance of discovering target-hitting molecules, we also introduced the following aggregated scoring metric $score$

\begin{equation}
\label{eqn:score}
score = \frac{1}{\sum_{i} pRMSE_i}
\end{equation}

%The performances of materials extrapolation for the two models and AI-driven combinatorial chemistry are evaluated. The experimental setup was made based on the cRNN since only trained cRNN is available to use. The cRNN is a model that generates hit-like materials with seven target indicators: calculated octanol-water partition coefficient (logP)\cite{logP}, topological polar surface area (TPSA)\cite{TPSA}, quantitative estimates of drug-likeness (QED)\cite{QED}, hydrogen bond acceptor (HBA), hydrogen bond donor (HBD), MW, and drug-activity for dopamine receptor D2 (DRD2). The cRNN was trained on a curated data set of ChEMBL\cite{mendez2019chembl} which was standardized and filtered to only contain the atoms H, C, N, F, S, Cl, and Br with total heavy atoms less than 50. The training data set of cRNN consisted of 1,347,173 molecular samples and the test set consisted of 149,679 molecular samples, which are labelled with their seven properties. All of the properties except DRD2 were calculated by RDKit, and DRD2 was estimated through a support vector machine (SVM)-based model of ref.\cite{kotsias2020cRNN}. To evaluate the original performance of the trained model, each set of seven properties for 149,679 molecular samples in the test set (target C0) is used. It is the performance evaluation for materials interpolation. The GCT was also trained and evaluated with the same experimental setup.

%Table \ref{tab:chembl_interpolation} shows the $RMSE_{i}$ of cRNN and GCT for materials interpolation. Note that the materials interpolation for the AI-driven combinatorial chemistry was not conducted. Since AI-driven combinatorial chemistry requires re-training if the target is changed, it is difficult to re-train the model on the 149,679 target sets in the test data. The $RMSE_{i}$ can show how well the model fits each target indicator $i$, however, it cannot inform whether the generated molecule hits the seven targets simultaneously. For this reason, it is necessary to introduce a separate criterion for evaluating whether the generated molecule hits the given target $i$. Thus, we tried to introduce a target bound for each $i$. Each target bound should be set relatively by considering both the range of each $i$ and its hitting difficulty. Hence, we used $\pm$Average $RMSE_{i}$ as the target bound of $i$, which reflects the range and the hitting difficulty of $i$ indirectly.

%Now, it is needed to set the targets for materials extrapolation. To this end, we additionally introduced a data set distributed over a wider range than ChEMBL, PubChem SARS-Cov-2 clinical trials\cite{PubChemCovid19} consisting of 560 molecules. Since these materials are actually existing materials, the properties of these materials can be used as physically feasible targets for the materials extrapolation. We selected 10-target points from the data set (Fig. \ref{fig:chembl_results}a). The five points of them (C1 to C5) were sampled from the points deviating from the TPSA-logP distribution, and the other five points (C6 to C10) were sampled from the points deviating from the TPSA-QED distribution. Then, we tried to generate 10,000 molecules for each extrapolation target.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=1.0\textwidth]{Figs/figure3.jpg}
    \caption{\textbf{Experimental results for generating multiple target-hitting molecules.} \textbf{a} Distribution of the curated ChEMBL training data\cite{kotsias2020cRNN} and the extrapolation targets C1 to C10. \textbf{b} Results comparison of AI-driven combinatorial chemistry, cRNN\cite{kotsias2020cRNN}, and GCT\cite{Kim2021GCT}. The left-hand side table shows the number of molecules that hit the target bounds. The blue-red colored lines in the right-hand side parallel coordinates plot indicate materials within the green target bounds of logP, TPSA, QED, HBA, and HBD simultaneously. The blue-red colored lines were colored according to the log-scaled aggregated score. The 10 yellow lines indicate the target properties of the 10 targets.% \textbf{c} A result that hits all of the target properties except MW and DRD2 for the target C10\textemdash a target that deviates the most from the distribution of the trained data. \textbf{d} Maximum reward curve for training steps. Transparent lines in the back indicate the maximum reward curve for targets C1, C2, C3, C4, and C6\textemdash succeeded to hit all of the target properties simultaneously. \textbf{e} All generated molecules for target C5, C7, C8, C9, and C10\textemdash fail to hit all of the target properties simultaneously. \textbf{f} Generated molecules that hit all of the target properties except MW and DRD2 for target C5, C7, C8, C9, and C10.
    }\label{fig:chembl_results}
\end{figure}

Fig. \ref{fig:chembl_results}b displays the results for materials interpolation (targets C0) and extrapolation (targets C1 to C10). Since the number of attempted molecular generations for materials interpolation and extrapolation were different, the rescaled results based on 10,000 trials are summarized in the left-hand side of Fig. \ref{fig:chembl_results}b for comparison. For materials interpolation (targets C0 in Fig. \ref{fig:chembl_results}b), the cRNN\cite{kotsias2020cRNN} generated 3,479 molecules that hit all of the seven targets (logP, TPSA, QED, HBA, HBD, MW and DRD2) simultaneously and 4,453 molecules hit the five targets (logP, TPSA, QED, HBA, and HBD) simultaneously. With the same criteria, the GCT\cite{Kim2021GCT} generated 2,664 molecules that hit all seven targets and 3,994 molecules hit the five targets simultaneously. These results confirmed that both models were able to generate hit-like materials in the trained region.

Both probability distribution-learning models achieved poor results in terms of molecular extrapolation. For each target from C1 to C10 outside the trained data, we conducted 10,000 trials to generate the molecules per target. As displayed in the results for the targets C0 to C10 of Fig. \ref{fig:chembl_results}b, both the probability distribution-learning models failed to generate molecules that hit all of the targets and did not generate molecules that hit the five targets. Even GCT\cite{Kim2021GCT} only succeeded in generating seven valid and unique molecules that satisfied the chemical valence rule out of 100,000 trials, with four and three molecules being generated for targets C1 and C3, respectively. In comparison, cRNN\cite{kotsias2020cRNN} generated 15,068 chemically valid molecules, although only 21 were unique. In particular, 15,054 out of the 15,068 valid molecules were nonsensical outcomes that were overlapped and too small, such as $CH_4$, $CH_4S$, $H_2O$, $H_2S$, $SO$, $H_2OS$, and $H_2S_2$. Considering that the target MWs of C1 to C10 were distributed in the range of 1,026 to 3,124 $Da$, it was difficult to determine whether it operated correctly. Moreover, other generated molecules exhibited considerable deviations from the intended targets. Detailed information on the generated molecules is summarized in Supplementary Table 1-4.

For targets C1, C2, C3, C4, and C6, our AI-driven combinatorial chemistry generated 1,315 target-hitting molecules that hit all seven targets simultaneously. Here, 355, 366, 233, 50, and 311 molecules that hit alltargets were generated for the targets C1, C2, C3, C4, and C6, respectively. For targets C5, C7, C8, C9, and C10, AI-driven combinatorial chemistry could not generate molecules that hit all targets. However, it successfully generated 828 molecules that hit five targets that failed with the probability distribution-learning models. Here, 14, 321, 181, 289, and 23 molecules that hit five targets were generated for targets C5, C7, C8, C9, and C10, respectively. In addition, all of the generated molecules were chemically valid. 

Also, in fact, it is hard to assert that it completely failed to hit the seven target properties simultaneously for the targets C5, C7, C8, C9, and C10. For these targets, the generated molecules exhibited lower $pRMSE$s (see $pRMSE$s of RL displayed in Fig. \ref{fig:chembl_results}b). This means that if the target bounds were more broadly set, there would be more molecules that were counted as molecules that hit all targets. It should be noted that the employed MW target bound $\pm$7.113 $Da$ and DRD2 target bound $\pm$0.105 were fairly narrow (Table \ref{tab:chembl_interpolation}). The target bound of MW 7.113 $Da$ was so small that it was less than one atom apart. Furthermore, the target bound of DRD2 was considerably smaller than the commonly known drug activity prediction accuracy of QSAR models. In \cite{kotsias2020cRNN}, the QSAR model for DRD2 was used as a binary classifier to evaluate as either active (when the predicted value was $\geq$ 0.5) or inactive ($\leq$ 0.5). For this reason, we believe that the number of molecules hitting the targets MW and DRD2 was less counted than the number of molecules hitting the other targets (See MW-axis and DRD2-axis of RL in the left-hand side Table of Fig. \ref{fig:chembl_results}b). Hence, we conducted a supplementary experiment on another dataset to generate five target-hitting molecules that excluded for MW and DRD2 (Supplementary Note 1). As a result, we confirmed that our model successfully generated molecules with extreme properties outside the known materials, which is not possible with probability distribution-learning models.

%Interestingly, we were able to identify the limitations of AI-driven combinatorial chemistry that should be solved in future studies, namely, sparse reward problem. Fig. \ref{fig:chembl_results}d shows the maximum reward of each training step for the failed targets. Here, the transparent lines in the back indicate the maximum reward for the succeeded targets. As shown in the figure, the converged maximum rewards of C7 and C8 were not significantly different from the converged maximum rewards of successful targets. When looking at the average of the last five checkpoints that measured the maximum reward, the converged maximum rewards of C7 and C8 were 26.2 and 26.9, respectively, and the average of the converged maximum rewards of the successful targets was 29.8. Perhaps for this reason, when additional 10,000 attempts to generate materials for each target were made, a molecule that hits all targets for C8 simultaneously was found. However, except for C1, it is confirmed that peaks near 100-reward were obtained at a much higher frequency in the successful targets than in C7 and C8; note that the density of training data around C1 is also quite sparse compared to other successful targets. Also, the case of C5, C9, and C10\textemdash which deviated further from the distribution of the training data\textemdash showed low as 10 or less of the converged maximum reward. This phenomenon is also seen in Fig. \ref{fig:chembl_results}e,f; Fig. \ref{fig:chembl_results}e shows all generated materials for the failed targets, and Fig. \ref{fig:chembl_results}f shows only those materials that hit all targets except MW and DRD2 simultaneously. In particular, as shown in Fig. \ref{fig:chembl_results}f, although the molecules generated for the target C7 and C8 are filtered materials that hit all targets except for MW and DRD2, their median values were close to their target MW. On the other hand, for C5, C9, and C10, it is confirmed that the median values of the materials slightly exceed 3,500 $Da$ since the materials that hit all targets simultaneously were not found until the allowed maximum MW 3,500 $Da$ (red dotted-line, a termination condition) was exceeded. Considering these, for the failed targets, it is presumed that it was not easy to obtain episodes with high rewards that could provide high-quality opportunities to update the policy. Considering the nature of AI-driven combinatorial chemistry, it would be probabilistically not easy for the near-random combination in the early stage of training to discover high-reward episodes that require a complete compound to hit the not-common extreme target. Therefore, this kind of sparse reward problem requires a large number of training episodes until a high reward episode is obtained through exploration. This is the limitation of AI-driven combinatorial chemistry in the materials extrapolation to be solved in future studies.


%remove the following section: MOSES experiment
\ignore{

\subsection{Materials extrapolation to hit five drug targets}\label{results_exp1-B}

\begin{figure}[b]
    \centering
    \includegraphics[width=1.0\textwidth]{Figs/figure4.png}
    \caption{\textbf{Results for materials extrapolation to hit five drug indicators.} \textbf{a} Distribution of the curated ChEMBL training set\cite{kotsias2020cRNN} and the extrapolation targets M1 to M10. \textbf{b} Results comparison of AI-driven combinatorial chemistry and GCT. The left table shows the number of molecules that hit each target bound. The blue-red colored lines in the right parallel coordinates plot indicate materials within the target bounds (green) of logP, TPSA, QED, HBA, and HBD simultaneously. The yellow line indicates each target. The blue-red colored lines were colored according to the log-scale score. \textbf{c} MW distribution of fragments in the fragments set and extrapolation targets. \textbf{d} An extrapolation result for target M2.}\label{fig:moses_results}
\end{figure}

This section describes a supplementary experiment to the previous section, which is materials extrapolation with five indicators: logP, TPSA, QED, HBA, and HBD. MW and DRD2 which caused problems in the performance evaluation are excluded. Here, MOSES data sets containing much smaller molecules with MW between 250 and 350 $Da$ are used for the training and testing of GCT. The training data contains 1,584,664 molecules and the test data contains 176,074 molecules. In addition, 10-targets for materials extrapolation (M1 to M10) are selected from the PubChem anticancer set that covers a wider range than the MOSES data set (Fig. \ref{fig:moses_results}a). M1 to M5 are selected from anticancer samples deviating from the TPSA-logP distribution of the training data, and M6 to M10 are selected from samples deviating from the TPSA-QED distribution.

\begin{table}[b]
\begin{center}
\begin{minipage}{\textwidth}
\caption{Performance of materials interpolation to hit five drug indicators for MOSES test set M0}\label{tab:moses_interpolation}
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}lccccc@{\extracolsep{\fill}}}
\toprule%
& \multicolumn{5}{@{}c}{$RMSE_{i}$}
\\\cmidrule{2-6}%
Model & logP & TPSA & QED & HBA & HBD \\
\midrule
GCT                               & 0.214 & 3.225 & 0.037 & 0.180 & 0.106\\
\botrule
\end{tabular*}
\end{minipage}
\end{center}
\end{table}

Before conducting materials extrapolation, we evaluated the target-hitting performance of GCT on the MOSES test data set whose distribution is similar to the trained data. Table \ref{tab:moses_interpolation} summarizes the RMSE for GCT's materials interpolation on the MOSES test data set with five target properties. The RMSEs of GCT for the five indicators were decreased compared to the results of the previous section. This is because the range of molecular properties on the MOSES training data is narrower than the curated ChEMBL training data (compare Fig.\ref{fig:chembl_results}a and Fig. \ref{fig:moses_results}a). Hence, the target bounds for the evaluation were set as the RMSEs shown in Table \ref{tab:moses_interpolation}.

Fig. \ref{fig:moses_results}b shows that GCT discovered 5,365 target-hitting materials out of 10,000 trials for materials interpolation (target M0). However, GCT failed to discover the five target-hitting materials for the extrapolated targets except for only six trials on target M9. In contrast, AI-driven combinatorial chemistry worked well on materials extrapolation. However, AI-driven combinatorial chemistry also failed to discover target-hitting materials on the target M6. It is inferred that the cause lies in the way the fragments set was constructed. The x-makers shown in Fig. \ref{fig:moses_results}c indicate the MWs of the reference molecules for the target M1 to M10, which are borrowed from the PubChem anticancer set; the other markers indicate the Mws of molecular fragments constituting the fragments set. The MW of the target M6 is 167 g$/$mol, which is significantly smaller than the other extrapolation targets. Note that the logP, TPSA, HBA, and HBD are scores that are calculated by summing each score of molecular fragments constituting the molecule. Hence, the indicators have very large correlations with molecular size which is also correlated with MW. Therefore, the combinations of properties are likely to be found only in materials with a certain level of MW. Since the MW of 167 g$/$mol is a level that can be composed of one or two molecular fragments in the fragments set, it might be difficult to complete target-hitting materials with a randomly selected initial fragment. In addition, the reference molecule of the target M6 was the only molecule that are not completely fragmented into molecular fragments constituting the fragments set. Therefore, the fragment set should be designed with smaller fragments if the targets are small.
}


\subsection{Application to the discovery of protein docking materials}\label{subresults5}

The discovery of small molecules that dock to a target protein is a practical problem in drug discovery. Moreover, binding affinity to a target receptor is an important indicator for measuring drug-target interactions\cite{kitchen2004docking}. Since materials with higher binding affinity to the target protein (compared to other proteins) can be considered as having high selectivity and docking ability, the discovery of materials that maximize target binding affinity is a key objective in protein docking drug discovery\cite{binding_affinity}. Along with the previous experiment, maximizing the binding affinity is one of the material-extrapolation problems for discovering better materials.

In this section, we demonstrate that AI-driven combinatorial chemistry can discover materials that maximize the binding affinity towards the 5-hydroxytryptamine receptor 1B (5-HT\textsubscript{1B} receptor), which is related to mental diseases. A detailed description of the 5-HT\textsubscript{1B} receptor is summarized in Methods \ref{Molecular Descriptors}. We adopted QVina2\cite{alhossary2015fast} (a molecular docking simulator) to discover the minimum-energy docking conformation. This simulator evaluates the docking score fast and reliably. Since the docking score is an indicator that is inversely proportional to the binding affinity, the reward function was set as the negative docking score. 

\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\textwidth]{Figs/figure4.png}
    \caption{\textbf{Generated 5-HT\textsubscript{1B} receptor docking materials.} \textbf{a} Comparison of docking scores for the three molecular sets. The red color indicates the docking scores of 10,000 generated molecules from AI-driven combinatorial chemistry. The green color indicates the docking scores of 10,000 drug-like molecules that were randomly sampled from ChEMBL\cite{mendez2019chembl} database. The blue color indicates the docking scores of 1,871 molecules generated by FREED\cite{yang2021hit}, which has been reported in the paper. The 1,871 molecules have been reported as de novo cases with 4-step in their paper. Note that the maximum number of fragments constituting a compound is the same as ours. The docking scores of the 1,871 molecules were re-evaluated using QVina2\cite{alhossary2015fast} under the same calculation configuration as ours. \textbf{b} Three molecular examples that were generated by AI-driven combinatorial chemistry, which exactly matched with active drug molecules reported in the PubChem Bioassay database\cite{wang2012pubchem}.}\label{fig:docking_results}
\end{figure}

To evaluate the performance of AI-driven combinatorial chemistry, the docking scores of 10,000 generated molecules from our model were compared with the docking scores of two other molecular sets. One was a set of 1,871 molecules that were generated to maximize the negative docking score towards the 5-HT\textsubscript{1B} receptor using fragment-based generative RL with explorative experience replay for drug design (FREED)\cite{yang2021hit}, which is reported in the paper. The other set was 10,000 molecules that were randomly sampled from ChEMBL\cite{mendez2019chembl} drug-like molecules. The docking scores of the three sets are summarized in Fig. \ref{fig:docking_results}a, which were calculated with QVina2. The calculation configuration is described in Supplementary Note 4. The best molecule with the lowest docking score was discovered from our model and the median docking score for the sets was also the lowest.

To check if potential drug molecules were found among the 10,000 generated molecules, we investigated whether any generated molecules were an exact match with the drug-like molecules in the ChEMBL\cite{mendez2019chembl} database. There were 23 molecules whose molecular structures exactly matched with real drug-like molecules in the ChEMBL database, of which 13 out of the 23 molecules had labels on drug activity (active or inactive). It should be noted that the number of small organic molecules reached approximately $10^{60}$\cite{bohacek199610^60}, of which only $2.2\times 10^6$ were included in the ChEMBL database\cite{mendez2019chembl}. Hence, it was difficult to find molecules with an exact match. An interesting finding is that five (CHEMBL1583499, CHEMBL1726441, CHEMBL412355, CHEMBL2261013, and CHEMBL99068) of the 13 molecules had been reported as active for some targets. Among these, three (CHEMBL1583499, CHEMBL1726441, and CHEMBL412355) were active in the related roles in which the 5-HT\textsubscript{1B} docking materials have been reported to have an effect. For example, CHEMBL1726441 is reported to be active for various targets such as Corticotropin-releasing factor receptor 2, Rap guanine nucleotide exchange factor 4, Nuclear factor erythroid 2-related factor 2, and Geminin. These targets have been reported to act in the human brain and peripheral tissues, playing a psychopathological role\cite{hillhouse2001control} and controlling brain function\cite{kawasaki1998family}. These investigations were conducted with the PubChem Bioassay database\cite{wang2012pubchem}. The other investigated results are summarized in Supplementary Table 7.
  

\subsection{Application to discovery of HIV inhibitors}\label{subresults6}
\begin{figure}[b]
    \centering
    \includegraphics[width=1.0\textwidth]{Figs/figure5.png}
    \caption{\textbf{Results for HIV inhibitors discovery with high pIC\textsubscript{50} for three HIV inhibition targets: CCR5, INT, and RT.} \textbf{a} Comparison of pIC\textsubscript{50} for two molecular sets. Red indicates pIC\textsubscript{50} for a set of 10,000 molecules generated by AI-driven combinatorial chemistry. Blue indicates pIC\textsubscript{50} for a set of 10,000 drug-like molecules that were randomly sampled from the ChEMBL database\cite{mendez2019chembl}. \textbf{b} Policy changes in BRICS molecular fragment selection according to the training steps. The left-hand side of the figure shows the number of appearances for 25 molecular fragments with the biggest change. The vertical and horizontal axes of the left-hand side blue-red plot represent the type of fragment and the training iteration, respectively. Blue-red indicates the number of generated molecules that have the fragment among the 10,000 generated molecules.
    }\label{fig:HIV_results}
\end{figure}

This section describes experiments in which AI-driven combinatorial chemistry was applied to discover HIV inhibitors. Here, we selected three HIV inhibition targets: C-C chemokine receptor type 5 (CCR5), HIV integrase (INT), and HIV reverse transcriptase (RT). Detailed information about the targets is summarized in Methods \ref{Molecular Descriptors}. \ignore{The first target is the immune system-related protein CCR5, which is found on the surface of white blood cells. Along with C-X-C chemokine receptor 4, it is a key co-receptor for HIV entry\cite{huang1996role}. The second target is INT, which is involved in viral replication. It facilitates the viral cDNA’s insertion into the infected cells\cite{pommier2005integrase}. RT is the final one; it triggers the reverse transcription process. It has significant ramifications that mutation and recombination form the genetic diversity of HIV, enabling the formation of viral variants that may evade host immune responses\cite{sarafianos2009structure}. }To evaluate the HIV inhibition potency of molecules, pIC\textsubscript{50} predictors\cite{gottipati2020learning} for the three HIV inhibition targets were adopted. It should be noted that pIC\textsubscript{50} is equal to $-$logIC\textsubscript{50}, where IC\textsubscript{50} is an indicator that measures the amount of a particular inhibitory substance required to inhibit a given biological process or biological component by 50\%. In other words, the lower the value of IC\textsubscript{50}, the higher the HIV inhibition potency. Moreover, the higher the value of pIC\textsubscript{50}, the higher the HIV inhibition potency. Therefore, we set pIC\textsubscript{50} as the reward function to make our model discover HIV inhibitors with high potency.

In total, 10,000 generated molecules from our model were compared with the same number of molecules randomly combined by no-policy combinatorial chemistry (Fig. \ref{fig:HIV_results}a). For all the HIV inhibition targets, molecules generated by our model exhibited significantly higher pIC\textsubscript{50} values compared to those of random combination without a policy (original combinatorial chemistry). This result indicated that our model learned the fragment-selection policy to discover the intended materials. The benchmark results compared to the other six generators for HIV inhibitors are summarized in Supplementary Table 9, in which our model achieved the highest pIC\textsubscript{50} values for targets CCR5 and RT.

To analyze the policy change of molecular fragment selection in the training phase, we generated 10,000 molecules at the end of every training iteration. The derived frequencies for 25 fragments with the biggest change (how many molecules had the fragment) are plotted on the left of Fig. \ref{fig:HIV_results}b. In the initial state (where no policy was learned), the frequency of all fragments was similar. As the training progressed, the frequency of each fragment became varied. Although the selected frequency of some fragments increased as training proceeded, some of them decreased at certain points. This is because the agent found the combinations of molecular fragments that provided a high reward. Hence, the selection of other fragments that did not have any merit in the pIC\textsubscript{50} score rapidly decreased. The most selected fragments differed according to the type of HIV inhibition targets. Since the fragments were most often used to maximize the pIC\textsubscript{50} for each target, we believe they may be key structures for HIV inhibitors on each target.

\section{Conclusion}\label{discussion}
From a data science perspective, the discovery of better than previously known is to find materials with properties outside outliers\textemdash materials extrapolation. Most of the reported inverse molecular design models are based on data probability distribution-learning models, such as machine translators and generative models (including Seq2Seq\cite{sutskever2014seq2seq_original}, Transformer\cite{vaswani2017Transformer_original}, GAN\cite{goodfellow2014GAN_original}, and VAE\cite{kingma2013VAE_original}). However, these models are too limited for use in materials extrapolation, which requires generating materials in the untrained area. To solve this problem, we adopted combinatorial chemistry\cite{combinatorial_chemistry}, which generates molecules from combinations of randomly selected molecular fragments. Fundamentally, it is a rule-based data-free molecular designer for generating all physically possible molecular structures that can be obtained from the combination of molecular fragments. However, since the lack of a molecular fragment selection policy can cause a combinatorial explosion\cite{klaus1986web}, RL is applied to train its fragment-selection policy to provide a direction toward target materials.

This paper contains three major contributions. First, we theoretically demonstrated that most inverse molecular design models based on probability distribution-learning of data are too limited for use in materials extrapolation. Second, we empirically demonstrated that our proposed AI-driven combinatorial chemistry works well on various problems of materials extrapolation, such as the discovery of multiple target-hitting materials, protein docking materials, and HIV inhibitors. This demonstrated that our model could be applied universally in various problems pertaining to materials extrapolation. Third, the limitations of our model were also analysed (Methods \ref{further findings}). One of these was that re-training would be required if the target was changed. The other limitation was a sparse reward problem that interrupted the discovery of materials with extreme properties. However, since studies to solve these limitations have already been reported, we plan to address these issues in future studies.

Furthermore, since the BRICS\cite{degen2008BRICS} system is designed based on drug-like materials, our applications were limited to drug discovery. Therefore, we plan to extend our approach to various problems of discovering better materials in the fields of OLEDs, battery materials, and polymers.



\section{Methods}\label{methods}

\subsection{Molecular Descriptors}\label{Molecular Descriptors}

For the experiment in materials extrapolation, where the aim was to hit multiple extreme target properties, seven properties were set: logarithm of the calculated octanol-water partition coefficient (logP)\cite{logP}; topological polar surface area (TPSA)\cite{TPSA}; quantitative estimate of drug-likeness (QED)\cite{QED}; number of hydrogen bond acceptors (HBA); number of hydrogen bond donors (HBD); molecular weight (MW); and drug activity for dopamine receptor D2 (DRD2). Each property is considered important in the field of drug discovery. The term logP is a descriptor for the lipophilicity of a molecule, which refers to a molecule’s capacity to dissolve in fats or oils. This is an important property in drug design since it has an impact on the molecule’s capacity for penetrating cell membranes and reaching its intended target. The term TPSA is a calculated descriptor of the polar surface area (PSA) of a molecule, which refers to the area of a molecule having polar functional groups that could form hydrogen bonds with water molecules. A molecule is less polar and more likely to be able to penetrate cell membranes if it has a lower PSA value. The terms HBA and HBD are also important properties in drug design because they can affect a molecule’s capacity to interact with other molecules through hydrogen bonding. Hydrogen bonding is frequently used in drug design to facilitate the binding of a molecule to the target receptor. Moreover, hydrogen bonding can affect a drug molecule’s solubility and permeability, which influence its pharmacological properties. Term MW is a descriptor used in drug discovery, as it can affect a drug’s pharmacokinetics, efficacy, and safety. This is because the size of the molecules can influence a drug’s absorption, distribution, metabolism, or degree of penetration into the cell membrane. The correct molecular weight of a drug depends on its application. However, most drugs generally comprise small molecules with a molecular weight of less than 500 $Da$. This is because drug molecules have a higher likelihood of passing through a cell’s membrane and have a lower likelihood of being affected by biometabolic reactions. The term QED is a metric used to evaluate a molecule’s overall drug-likeness, which is a geomteric mean of logP, HBA, HBD, PSA, number of rotatable bonds (ROTB), number of aromatic rings (AROM), and number of structural alerts (ALERTS). A molecule with a high QED value is more likely to be a promising drug candidate. Finally, DRD2 refers to a drug's activity toward dopamine receptor D2. The dopaminergic neurotransmission is regulated by the G protein-coupled receptor dopamine receptor D2, which is mainly expressed in the brain.

In the experiment aimed at discovering protein docking materials, QVina2\cite{alhossary2015fast}\textemdash a tool to discover the minimum-energy docking conformation and calculate its docking score\textemdash was employed to compute a docking score. This score is proportional to the binding strength between a drug molecule and its target. QVina2 calculates the docking score by simulating how a drug molecule interacts with a given target receptor in a three-dimensional simulation box. We targeted the protein receptor 5-HT\textsubscript{1B}. Many studies have reported that activating 5-HT\textsubscript{1B} receptors outside the brain has vascular effects (such as pulmonary vasoconstriction, which can help treat angina\cite{morecroft19995}). Moreover, reduced 5-HT\textsubscript{1B} heteroreceptor activity can increase impulsive behaviour, whereas reduced 5-HT\textsubscript{1B} autoreceptor activity can have an antidepressant-like effect\cite{nautiyal2015distinct, clark20015}.

In the experiment aimed at discovering HIV inhibitors, we selected three HIV-related targets: C-C chemokine receptor 5 (CCR5), HIV integrase (INT), and HIV reverse transcriptase (RT). Here, CCR5 is the immune system-related protein, which is found on the surface of white blood cells. Along with C-X-C chemokine receptor 4, it is a key co-receptor for HIV entry\cite{huang1996role}. The second target was INT, which is involved in viral replication and facilitates the viral cDNA’s insertion into the infected cells\cite{pommier2005integrase}. The final target was RT, which triggers the reverse transcription process. Moreover, it has significant ramifications that mutation and recombination form the genetic diversity of HIV, enabling the formation of viral variants that could evade host immune responses, rendering the virus resistant to medication treatments\cite{sarafianos2009structure}. For each target in the experiment, we tried to maximize its pIC\textsubscript{50} value, which is a descriptor for the potency of a drug in inhibiting a biological activity. It is calculated as the negative logarithm of the IC\textsubscript{50} value, which is the amount of a drug that inhibits 50\% of the biological activity. In other words, the drug's potency increases as the IC\textsubscript{50} value decreases. In the realm of drug discovery, IC\textsubscript{50} is commonly utilized to compare the effectiveness of potential drug candidates.


\subsection{Fragment set configuration}\label{fragment set}
Two types of fragment sets were used in this study. One set contained 2,207 BRICS fragments that appeared more than 150 times in the training set\cite{kotsias2020cRNN} curated from the ChEMBL database\cite{kotsias2020cRNN} (release version 25). This fragment set was used for the three major experiments: the discovery of seven target-hitting molecules, protein docking materials, and HIV inhibitors. For the supplementary experiment aimed at discovering five target-hitting molecules (Supplementary Note 1), another fragment set containing 2,547 BRICS fragments that appeared more than 100 times in the training set of the MOSES database\cite{polykovskiy2020moses} was used. The detailed reasoning for using these fragment sets is described in Supplementary Note 2.

\subsection{Action masking}\label{action masking}
For efficient learning, we applied action masking to our model (Fig. \ref{fig:model_scheme}g). Based on the molecule in the current state, the list of actions that the agent can choose is limited by action masking. Since our model combines fragments according to BRICS fragment combination rules, the fragments that could not be connected to the molecule in the current state were masked. Thereby, more efficient learning was possible since the number of selectable actions in the current state was reduced, which improved the performance of our model (Supplementary Fig. 3b).


\subsection{Target properties and calculation of molecular descriptors}\label{properties and calculation}

In this study, three major experiments were conducted to generate molecules with extreme properties. In the first experiment, discovering molecules that could hit the multiple target properties was attempted. In the other experiments, discoveries of molecules that either maximized or minimized interesting properties were attemped. Accordingly, the interesting properties could be calculated by the evaluators in the environment of the RL model.

For the first experiment on materials extrapolation to hit multiple extreme target properties, seven molecular descriptors were set as the targets: logP\cite{logP}, TPSA\cite{TPSA}, QED\cite{QED}, HBA, HBD, MW, and DRD2\cite{kotsias2020cRNN}. Here, the DRD2 was calculated using a QSAR model for DRD2\cite{kotsias2020cRNN}, while the other descriptors were calculated using RDKit\cite{rdkit}. We selected 10 target sets of molecular properties out of known molecular data and attempted to generate the target-hitting molecules to demonstrate that our model would work well in terms of materials extrapolation. These 10 target sets of extreme properties were taken from an untrained dataset\textemdash PubChem SARS-CoV-2 clinical trials\cite{PubChemCovid19}\textemdash whose molecular properties are more widely distributed than the training data set\cite{kotsias2020cRNN} training (Fig. \ref{fig:chembl_results}a). Since the ten target sets of extreme properties were taken from real molecules, they could be considered chemically feasible targets to discover.

For the experiment to discover protein docking materials, the calculated docking score between a docking molecule and HT\textsubscript{1B} protein receptor was set as the target. The docking score was calculated using QVina2\cite{alhossary2015fast}, which calculates the docking score of a docking molecule by searching for its minimum-energy docking conformation. This program employs an empirical scoring function to predict the docking score, which includes a number of terms that incorporate various physical and chemical interactions between the ligand and protein. These interactions include van der Waals interactions, electrostatic interactions, hydrogen bonds, and solvation effects. Moreover, QVina2 makes use of finely tuned scoring function parameters that are derived using many experimentally-identified ligand-protein complexes. It calculates a docking score for each docking posture it produces, with the lowest value being the most energetically favourable binding conformation. The detailed calculation configuration for QVina2 is illustrated in Supplementary Note 4.

For the experiment to discover HIV inhibitors, the target property was set to maximize the pIC\textsubscript{50} score to three HIV-related targets: CCR5, INT, and RT. Each pIC\textsubscript{50} score was calculated by the light gradient boosting machine (LGBM)\cite{ke2017lightgbm}-based QSAR models for the three HIV-related targets\cite{gottipati2020learning}. In addition, the QSAR model was trained to predict the pIC\textsubscript{50} value for each target using the ChEMBL dataset\cite{mendez2019chembl}.


\subsection{Training loop}\label{training loop}

To maximize the cumulative reward for sequential actions, RL trains its agent to learn which action to choose at each step. When the agent performs an action in the training process, the next state and reward are generated through the environment. In this study, the action was a selection of a molecular fragment and the next state was the molecule combined with the selected molecular fragment. The reward is the value calculated with the evaluator(s) by the experiment-specific reward function. By repeating this process, the policy that selects an action that can maximize the cumulative reward is gradually updated. After sufficient learning, the policy could then select sequential actions to generate a desired molecule that fits the given task.

The episode proceeds from steps 0 to $T$, where $T$ is the designated maximum fragment number of the molecule. To produce diverse molecules, the first fragment is randomly selected. When selecting the next molecular fragment to be combined with the current molecule, action masking is conducted. In the process of action masking, the molecular fragments that cannot be combined with the current molecule are masked according to the BRICS fragmentation combination rules. Subsequently, the policy selects a molecular fragment from the unmasked fragments and binds it to an unfilled binding site. If the combined molecule still has any unfilled binding sites, hydrogen atoms are attached to derive a complete molecule and evaluate its properties of the current state. When a molecule that meets the set of criteria (or one of the termination conditions) is generated, the fragment attachment is stopped and the episode ends early before reaching step $T$. Otherwise, the process is repeated during step $T$. After the final output molecule is generated, a reward for the episode is calculated depending on how closely the targets are hit. By iteratively conducting the training episodes, the agent of RL learns a policy that maximizes the given reward function. The episode training is repeated until a preset number of training iterations is reached. For each experiment, the training iteration was set to 750, 80, and 250 times.


\subsection{Rewards and terminations}\label{rewards and terminations}
In RL, it is important to have an appropriate set of termination conditions to learn a decent policy. In all three experiments conducted in this study, there were two common termination conditions. First, molecular generation was terminated when the number of fragments that make up a compound in the current state $n_{eval.}$ exceeded the maximum number of fragments ($n_{max}$), which was set to 50, 4, and 6 for each experiment. Second, the process was terminated when the number of unfilled binding sites ($n_{L}$) was equal to zero.

For the experiment on materials extrapolation to hit multiple extreme target properties, two more termination conditions were applied. First, the process was terminated if the $MW$ in the current state ($MW_{eval.}$) exceeded the maximum $MW$ ($MW_{max} = 3500 Da$). Second, the process was terminated if the error ($\epsilon$) was less than the error threshold $\epsilon_{th}=0.05$. Here, $\varepsilon$ was calculated as
\begin{equation}
\varepsilon = \sum_{y\in prop.} \left ( \frac{y_{trg.}-y_{eval.}}{\sigma _{y}} \right )^{2}
\end{equation}
where $y_{trg.}$, $y_{eval.}$, and $ \sigma _{y}$ denote the target $y$, evaluated $y$, and standard deviation of $y$ for the curated ChEMBL training set\cite{kotsias2020cRNN}, respectively. Here, $prop$ is a set of properties that includes logP, TPSA, QED, HBA, HBD, MW, and DRD2.

The design of the reward function is also important since RL is performed based on the reward obtained by taking an action. Moreover, a penalty can be given to avoid any undesired actions. For the experiment on materials extrapolation to hit multiple extreme target properties, the reward function $r$ was designed as follows:
\begin{equation} \label{eqn:reward_1}
    r =\left\{\begin{matrix}
    &0,& &\textup{if} \left\{ \left [ MW_{eval.} < MW_{min.} \right ]\vee \left [ n_{eval.} < n_{min.} \right ]\right\}\wedge \left [ n_{L}\neq 0 \right ], \\
    &-50,& &\textup{if} \left\{ \left [ MW_{eval.} < MW_{min.} \right ]\vee \left [ n_{eval.} < n_{min.} \right ]\right\}\wedge \left [ n_{L}=  0 \right ], \\
    &\frac{100}{\varepsilon+1},& & \textup{else if} \ \varepsilon < \varepsilon_{th.}, \\ 
    &\frac{30}{\varepsilon+1},& & \textup{otherwise.} \\
    \end{matrix}\right.
\end{equation}

Here, $MW_{min}$ and $n_{min}$ were set to generate various compounds by avoiding premature termination, which would generate uniform molecules that were too small. For this purpose, when the number of unfilled binding sites $n_L$ was not equal to zero, a zero reward was given if $MW_{eval.}$ was less than $MW_{min}$ or $n_{eval.}$ was less than $n_{min}$. When $n_L$ was equal to zero, a reward of $-50$ was given if $MW_{eval.}$ was less than $MW_{min}$ or $n_{eval.}$ was less than $n_{min}$. However, if it deviated from the above two cases, a reward proportional to the degree of proximity to the target was awarded.

For the other two experiments (discovery of protein docking materials and HIV inhibitors), the reward function $r$ was designed as follows:
\begin{equation} \label{eqn:reward_2}
    r =\left\{\begin{matrix}
    &0,& &\textup{if} \left\{ \left [ MW_{eval.} < MW_{min.} \right ]\vee \left [ n_{eval.} < n_{min.} \right ]\right\}\wedge \left [ n_{L}\neq 0 \right ], \\
    &-50,& &\textup{if} \left\{ \left [ MW_{eval.} < MW_{min.} \right ]\vee \left [ n_{eval.} < n_{min.} \right ]\right\}\wedge \left [ n_{L}=  0 \right ], \\
    &\textup{Predicted Score},& & \textup{otherwise.} \\
    \end{matrix}\right.
\end{equation}

Here, the predicted score refers to the calculated docking and pIC\textsubscript{50} scores of the HIV-related target, respectively.


\subsection{RL algorithm} \label{algorithm}

We performed benchmark testing against the following state-of-the-art RL algorithms: IMPALA\cite{espeholt2018impala}, APPO\cite{schulman2017proximal}, A2C \& A3C\cite{mnih2016asynchronous}, and PPO\cite{schulman2017PPO}. The detailed results of the benchmarking are summarized in Supplementary Note 3. From the benchmark results, we confirmed that PPO\textemdash which is a model-free, on-policy, actor-critic, and policy-gradient algorithm\textemdash was the most suitable for our problems, with a very large discrete action space of over 2,000. Moreover, PPO is known for its good performance, stability, and good sample efficiency, which makes the training process more stable by avoiding large policy updates with importance sampling and reusing learning data on the trust region. Hence, we applied PPO for all experiments conducted in this study. The objective function of PPO is defined as follows:

\begin{equation}\label{eqn:PPO}
\begin{split}
L^{CLIP}(\theta)=\hat{E}[\textup{min}(r_{t}(\theta )\hat{A_{t}}, clip(r_{t})(\theta ), 1-\epsilon , 1+\epsilon )\hat{A_{t}}], \\
\text{where}\ r_{t}(\theta)=\frac{\pi_{\theta}(a_{t}\mid s_{t})}{\pi_{\theta_{\textup{old}}}(a_{t}\mid s_{t})}
\end{split}
\end{equation}


\noindent where $\hat{E}_{t}$ represents the expected value at time step $t$. Term ${r}_{t}$ denotes the ratio between the new policy $\pi_{\theta}$ and the old policy $\pi_{\theta_{\textup{old}}}$. The policy is expressed as $\pi_{\theta }({a}_{t}\mid{s}_{t})$, where ${a}_{t}$ and ${s}_{t}$ are the action and state at timestep $t$, respectively. In Equation \ref{eqn:PPO}, $\hat{A_{t}}$ denotes the advantage function at time step $t$, which estimates the result of the step action more effectively than the behaviour of the default policy.

\ignore{
\subsection{Performance Evaluation}\label{performance}

To compare with other methodologies, a performance evaluation was conducted. As mentioned above, different target properties were set for each experiment. Therefore, different reward functions were used for each experiment. In this section, we will explain the package or program used for calculating the target property, along with how the performance assessment criteria were established.

For the experiment on materials extrapolation to hit multiple extreme target properties, the RDKit python package was used to predict six properties, which are logP, TPSA, QED, HBA, HBD, and MW, and the QSAR model was used to predict the activity for DRD2. Of the six properties obtained using the RDKit package, TPSA, HBA, HBD, and MW can be obtained directly from the structure of the molecule, logP is predicted using the ALOGPS program, and QED is calculated based on a given machine earning model considering various physicochemical and pharmacodynamic properties, including logP, MW, HBA, HBD, etc. Based on the properties calculated in this way, the generated molecules are evaluated after setting the target bound to RMSE for each property. For each target set, the number of molecules entering the target boundary simultaneously out of 10,000 molecules generated using the three comparative methodologies was used as a performance comparison index.

For the experiment on application to the discovery of protein docking materials, the docking score was calculated using QVina2, which is a molecular docking software. QVina2 employs an empirical scoring function to predict the docking score. This function includes a number of terms that incorporate various physical and chemical interactions between the ligand and protein, including van der Waals interactions, electrostatic interactions, hydrogen bonds, and solvation effects. Moreover, QVina2 makes use of finely tuned scoring function parameters that are derived using a large number of experimentally identified ligand-protein complexes. It calculates a docking score for each docking posture it produces, with the lowest value being the most energetically favorable binding conformation. That being so, in the experiment, the standard for performance evaluation was set to how low a molecule with a docking score was generated.

For the experiment on application to the discovery of HIV inhibitors, the predicted pIC\textsubscript{50} values for the three HIV-related target values were predicted using the QSAR model. The corresponding QSAR model is trained to predict the pIC\textsubscript{50} value for each target using the ChEMBL dataset\cite{mendez2019chembl}. The pIC\textsubscript{50} value is a negative logarithm of the IC\textsubscript{50} value, which is the concentration of the drug needed to reduce the activity of the target protein by 50\%. The efficacy of a drug is an important factor in drug discovery because it determines the minimum amount of drug needed to achieve the effect for a particular disease. More powerful drugs require smaller doses to achieve the same effect, which can reduce the risk of side effects, and toxicity compared to drugs that require higher doses. Therefore, pIC\textsubscript{50} is an important indicator considered for drug discovery, and the larger this value, the better the drug can be evaluated. Thus, in the experiment, we aimed to maximize the pIC\textsubscript{50} value of each target model.
}

\subsection{Further findings}\label{further findings}

We empirically demonstrated that our methodology can discover novel materials with extreme properties, which is impossible to accomplish with existing models that learn the probability distribution of data. However, there were two limitations with our model, which could be solved through further studies. First, the model should be re-trained if the target changes because the reward function depends on the given target. Therefore, the model must learn the policy from the start each time a new target is set. To solve this problem, a methodology such as meta-learning may be applied in future studies. With meta-learning, it is possible to predict the results of a new task or recommend hyperparameters based on the learning results from another task. Therefore, when a new task is assigned, it will be possible to learn through the experiences that have been taught in the past, requiring less additional training. For example, using methods such as MetaGenRL\cite{kirsch2019improving}, which applies meta-learning to reinforcement learning, the model outperformed the existing reinforcement learning algorithm while exhibiting similar performance for completely different tasks. Second, there was a sparse reward problem, which occured because the agent received little feedback or reward for the action from the environment, rendering it difficult to learn efficient policies and satisfy the desired goal. Since molecules with extreme properties are rarer than common molecules, the probability of experiencing an episode in which a rare molecule is obtained through a random combination of molecular fragments is relatively low. To solve this problem, we could adopt methods that encourage more exploration with curiosity. This would allow experiencing more episodes that could provide higher rewards. In addition, hierarchical reinforcement learning\cite{riedmiller2018learning} could be applied, which is a methodology that utilizes prior knowledge of the given problem to set sub-goals that are easier to achieve than the original goal. Accordingly, it learns a policy that can achieve the original goal through policies learned from sub-goals.


\backmatter

\bmhead{Supplementary information}
Supplementary Information is available at url (TBA).

\bmhead{Data availability}
The curated ChEMBL datasets and MOSES data sets for training and testing cRNN\cite{kotsias2020cRNN} and GCT\cite{Kim2021GCT} are publically available at \url{https://github.com/MolecularAI/Deep-Drug-Coder} and \url{https://github.com/molecularsets/moses}, respectively.

\bmhead{Code availability}
The code for this study is available upon reasonable request to the corresponding authors.

\bmhead{Competing interest}
The authors have no competing interests to declare.

\bmhead{Author contributions}
H.K. proposed the concept of materials extrapolation and the scheme of AI-driven combinatorial chemistry. H.K., H.C., and J.N. designed the experiments, and they were implemented by H.K., H.C., and D.K. All authors analysed the results and discussed them. H.K., H.C., and D.K. wrote the manuscript, and all authors reviewed it. J.N. and W.B.L. supervised the project.

\bmhead{Acknowledgments}
This research was supported by the National Research Foundation of Korea (NRF) grant funded by the Korean Government through the Ministry of Science and ICT (MSIT) (NRF-2021R1C1C1012031, NRF-2021R1A4A3025742, NRF-2020M3F7A1094299, and NRF-2018M3D1A1058633).

\bibliography{references}

% {\raggedright
% \includepdf[pages={1-}]{Supplementary_Information.pdf}
% }

\end{document}