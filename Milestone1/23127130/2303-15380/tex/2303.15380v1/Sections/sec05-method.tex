% !TeX root = ../main.tex

\section{Instance Segmentation During Interaction}
\label{sec: method}

\input{Algorithms/algorithm}
Given pre-built individual implicit avatars obtained in  \secref{subsec: prior_intro}, our goal is to track and segment the 4D scans through extended periods of dynamic physical contact. 
To this end, we leverage the avatars as priors to compensate for ambiguities caused by contact.
The process includes the following steps: 
i) given the last frame $t_0$ before contact, we initialize pose parameters from the still separated scans (\secref{subsec: init}); 
ii) starting from the first frame with contact, we then jointly refine the pose parameters $\boldsymbol{\Theta}_t^p$ for all $P$ subjects $p \in \{1,\dots,P\}$ in the scene via minimization of a surface energy term (\secref{subsec: pose_opt}); iii) we further refine the implicit shape network weights ${\sigma}_t^p$ on the fly throughout the interaction sequence, using the optimized poses and raw scans which at this point are merged. This leads to maximal preservation of details and allows modelling of contact-aware deformations (\secref{subsec: shape_refine}). Steps ii) and iii) are performed in an alternating fashion for $N$ steps. To be noted, this is a tracking process over time. The method is illustrated in \figref{fig: alternating_opt} and Alg.~\ref{alg: algorithm}. 

\subsection{Initialization}
\label{subsec: init}
We denote the last frame without physical contact by $t_0$ and denote the last frame with contact by $t_\tau$. 
We register the SMPL model to separated scans to obtain the initial pose parameters $\boldsymbol{\Theta}_{0}^{p}$ for each subject. 
We further use $\boldsymbol{\Theta}_{0}^{p}$ and the corresponding avatar to extract the canonical shape $\mathcal{C}_{0}^p$ for each subject $p$ via \equref{eq: MISE}.
During frames $t \in \{t_1, \dotsc, t_\tau \}$ with physical contact, the raw scan ${M_{t}^{raw}}$ is fused together. To track through this period, we initialize the shape $\mathcal{C}_t^p$ for each subject from the last frame $\boldsymbol{\Theta}_{t-1}^{p}$.

\subsection{Pose Optimization}
\label{subsec: pose_opt}
To obtain the SMPL parameters $\boldsymbol{\Theta}_{t}^{p}$ for contact frames, we optimize the following objective:
%
\begin{equation}
        \mathcal{L} =\lambda_{s2m} \mathcal{L}_{s2m}({M_{t}^{raw}},\bigcup_{p=1}^{P}  \mathcal{D}_t^p) + \lambda_{\text {reg}}\mathcal{L}_{\text {reg}} , 
\label{eq: pose_opt}
\end{equation}
%
where $\mathcal{L}_{s2m}$ encourages the union of the posed meshes $\mathcal{D}_t^p = LBS(\mathcal{C}_{t}^p, \mathbf{w}_{\sigma_w}, \boldsymbol{\Theta}_{t}^{p})$ (\equref{eq: LBS}) to align with the fused input scan ${M_{t}^{raw}}$ by optimizing the SMPL parameters of each subject $\boldsymbol{\Theta}_{t}^{p}$ jointly.
$\mathcal{L}_{\text {reg}}$ is a regularization term:
\begin{equation}
    \mathcal{L}_{\text{reg}} = \sum^{P}_{p=1} \mathcal{L}_{s2m}(\mathcal{D}_t^p, {\mathcal{M}}_{t}^{p}) + \lambda_{\Theta}\mathcal{L}_{\Theta} (\boldsymbol{\Theta}_{t}^{p}) .
    \label{eq: pose_reg}
\end{equation}
The term $\mathcal{L}_{s2m}(\mathcal{D}_t^p, {\mathcal{M}}^{p})$ 
ensures that the SMPL template $\mathcal{M}^{p}$ aligns well with each subject's deformed surface and $\mathcal{L}_{\Theta}$ is a prior penalizing unrealistic human poses (\cf~\cite{bogo2016simplify}) and $\lambda_{(\cdot)}$ denote the corresponding weights. The scan-to-mesh loss term $\mathcal{L}_{s2m}$ is defined in Supp. Mat.

\subsection{Shape Refinement}
\label{subsec: shape_refine}
After the pose optimization stage, we refine the shape networks $f_{\sigma_{t}^{p}}$ of each avatar  to retain high-frequency details and to model contact-induced deformations. 
To achieve this, we sample points $\boldsymbol{x}_d$ on the raw scan ${M_{t}^{raw}}$ and find canonical correspondences $\boldsymbol{x}^{p}_c$ per subject, given the optimized poses $\boldsymbol{\Theta}_{t}^{p}$. For each $\boldsymbol{x}_c$, the shape network $f_{\sigma_{t}^{p}}$ predicts the subject-specific occupancy $\hat{o}_{t}^{p}$ (\cref{subsubsec: correspondence}). The final occupancy prediction $\hat{o}_{t}$ of the sampled query point $\boldsymbol{x}_d$ is composited as the union over the individual predictions $\hat{o}_{t}^{p}$:
%
\begin{equation}
    \hat{o}_{t} = \max_{p\in \{1,\dots, P\}}[\hat{o}_{t}^{p}] =\max_{p\in \{1,\dots, P\}}[f_{\sigma_{t}^{p}}(\boldsymbol{x}_d,\boldsymbol{\Theta}_{t}^p)].
\end{equation}
We then refine the shape network weights $\sigma_{t}^{p}$ of the avatars by minimizing the loss: 
%
\begin{equation}
\mathcal{L} = \mathcal{L}_{\text{BCE}}(\hat{o}_{t}, {{o}}_{t}^{raw})+ \lambda_{\text{coll}} \mathcal{L}_{\text{coll}}
\label{eq: shape_refine}
\end{equation}
where $\mathcal{L}_{\text{BCE}}(\hat{o}_{t}, {{o}}_{t}^{raw})$ is the binary cross entropy between the composited occupancy prediction and the corresponding point ${{o}}_{t}^{raw}$ on the input  scan. This encourages segmented avatars to, together, align well with the fused scan.

A key challenge is to correctly model contact-induced deformation. Recall that the avatars are initialized from non-contact frames and hence do not yet account for the flattening of clothing and soft tissue due to contact. Therefore, the pose optimization step will cause surfaces that are in contact to intersect.     
To alleviate this, we select points that are predicted to be inside multiple subjects by querying the individual occupancies. 
We denote this subset of points as $\mathcal{S} = \{ \boldsymbol{x}_d \mid \hat{o}_{t}^{i}(\boldsymbol{x}_d) > 0.5, \hat{o}_{t}^{j}(\boldsymbol{x}_d) > 0.5 \ \forall \ i \in \{1,\dots,P\}, j \in \{1,\dots,P\}, i \neq j  \}$.
We then penalize interpenetration of surfaces via $\mathcal{L}_{\text{coll}}$: 
%
\begin{equation}
    \mathcal{L}_{\text{coll}}= \dfrac{1}{|{\mathcal{S}}|}\sum_{ \boldsymbol{x}_d \in \mathcal{S}} \phi(\hat{o}_{t}^{i}(\boldsymbol{x}_d)) \cdot \phi(\hat{o}_{t}^{j}(\boldsymbol{x}_d)) ,
    \label{eq: collision}
\end{equation}
where $\phi(\hat{o}_{t}(\boldsymbol{x}_d)) = \max(\hat{o}_{t}(\boldsymbol{x}_d)-0.5, 0)$. 
%
Intuitively, we ask that the uniformly sampled 3D points do not result in occupancy values of $1$ (i.e., inside) for multiple shapes simultaneously. Instead, the shape networks are optimized such that the surfaces adhere to contact deformation.
