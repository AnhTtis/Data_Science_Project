% !TeX root = ../main.tex

\section{Introduction}
\label{sec:intro}

%%% Fig2 in Page 2 %%%
\input{Tables/dataset.tex}
%%%

%
While computer vision systems have made rapid progress in estimating the 3D body pose and shape of individuals
%
and well-spaced groups,
%
currently there are no methods that can robustly disentangle and reconstruct \emph{closely} interacting people. 
%
This is in part due to the lack of suitable datasets.
While some 3D datasets exist that contain human-human interactions, 
like ExPI \cite{guo2021expi} and CHI3D \cite{fieraru2020chi},
%
they typically lack high-fidelity dynamic textured geometry, do not always provide registered parametric body models and do not always provide rich contact information and are therefore not well suited to study closely interacting people. 

Taking a first step towards future AI systems that are able to interpret the interactions of multiple humans in close physical interaction and under strong occlusion, we propose a method and dataset that enables the study of this new setting.
%
Specifically, we propose \datasetname, a comprehensive dataset that contains segmented, yet complete 4D textured geometry of \textit{closely} interacting humans, alongside corresponding registered parametric human models, instance segmentation masks in 2D and 3D, and vertex-level contact annotations (see \cref{fig: teaser}). 
%
To enable research towards automated analysis of close human interactions, we contribute experimental protocols for computer vision tasks that are enabled by \datasetname.


Capturing such a dataset and the corresponding annotations is a very challenging endeavor in itself. 
% 
While multi-view, volumetric capture setups can reconstruct high-quality 4D textured geometry of individual subjects, even modern multi-view systems typically fuse 3D surfaces of spatially proximal subjects into a single, connected mesh (see \figref{fig: teaser}, A).
%
Thus deriving and maintaining complete, per subject 4D surface geometry, parametric body registration, and contact information from such reconstructions is non-trivial.
%
In contrast to the case of rigid objects, simple tracking schemes fail due to very complex articulations and thus strong changes in terms of geometry. Moreover, contact itself will further deform the shape.
%

To address these problems, we propose a novel method to track and segment the 4D surface of multiple closely interacting people through extended periods of dynamic physical contact. 
%
Our key idea is to make use of emerging neural implicit surface representations for articulated shapes, specifically SNARF \cite{chen2021snarf}, and create personalized human avatars of each individual (see \figref{fig: method}, A). These avatars then serve as strong personalized priors to track and thus segment the fused geometry of multiple interacting people (see \figref{fig: method}, B). To this end, we alternate between pose optimization and shape refinement  (see \figref{fig: alternating_opt}). The optimized pose and refined surfaces yield precise segmentations of the merged input geometry.
The tracked 3D instances (\figref{fig: teaser}, B) then provide 2D and 3D instance masks (\figref{fig: teaser}, C), vertex-level contact annotations (\figref{fig: teaser}, B), and can be used to register parametric human models (\figref{fig: teaser}, D). 

Equipped with this method, we capture \datasetname, which stands for \underline{H}umans \underline{i}nteracting in \underline{4D}, a dataset of humans in close physical interaction alongside high-quality 4D annotations. The dataset contains 20 pairs of subjects (24 male, 16 female), and 100 sequences with more than 11K frames. To our best knowledge, ours is the first dataset containing rich interaction-centric annotations and high-quality 4D textured geometry of closely interacting humans. 


To provide baselines for future work, we evaluate several state-of-the-art methods for multi-person pose and shape modeling from images on \datasetname in different settings such as monocular and multi-view human pose estimation and detailed geometry reconstruction. Our baseline experiments show that our dataset provides diverse and challenging benchmarks, opening up new directions for research. 
%
\noindent In summary, we contribute:
\begin{compactitem}
    \item A novel method based on implicit avatars to track and segment 4D scans of closely interacting humans. 
    \item \datasetname, a dataset of 4D textured scans with corresponding multi-view RGB images, parametric body models, instance segmentation masks and vertex-level contact.
    \item Several experimental protocols for computer vision tasks in the close human interaction setting.
\end{compactitem}

