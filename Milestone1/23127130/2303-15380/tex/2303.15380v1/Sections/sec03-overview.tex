% !TeX root = ../main.tex

\section{Approach Overview}
\vspace{-0.2em}
Vision-based disentanglement of in-contact subjects is a challenging task due to strong occlusions and a priori unknown geometries. 
Hence, multi-view systems typically fuse 3D surfaces of close subjects into a single, connected mesh.
%
Here we detail our method to segment 4D scans of closely interacting people to obtain instance-level annotations. 
%
Our method makes use of three components: 
i) we fit individual neural implicit avatars to frames without contact (\cf \figref{fig: method}, A \& \cref{subsec: prior_intro}); 
ii) these serve as personalized priors in an alternating optimization scheme that refines pose (\cref{subsec: pose_opt}) and surface (\cref{subsec: shape_refine}) through periods of close proximity; and 
iii) thus segment the fused 4D raw scans into individual instances (\cf \figref{fig: method}, B \& \cref{sec: method}).

