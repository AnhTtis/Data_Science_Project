\section{Related Work}
\label{sec:related}

We now briefly summarize prior work on standard video compression, learned image compression, and learned video compression.

\textbf{Standard Video Compressors:} Video compression has been attracting attention from the early 2000s due to increasing video content in live streaming and real-time communication. More recently, with the wide spread of COVID-19 across the world, we have seen the importance of reliable and fast communication of high-resolution video content for remote lectures and remote meetings. Standard video compression frameworks typically consist of transform coding, intra-prediction, motion prediction, motion compensation, and entropy coding blocks. The large number of blocks to be designed and optimized for the best rate-distortion performance resulted in many different video coding standards such as ISO/IEC MPEG series \cite{tudor1995mpeg, haskell1996digital, sikora1997mpeg, li2001overview}, ITU-T H.26x series \cite{wiegand2003overview, sullivan2012overview, sze2014high, sullivan2004h, vetro2011overview}, AVS series \cite{yu2009overview, ma2013overview, zhang2019recent}, VP9 \cite{mukherjee2013latest}, and AV1 \cite{chen2018overview, han2021technical}. In our experiments, we use H.264 as the standard video codec between the neural pre-processor and post-processor. Hence, the differential proxy in Figure~\ref{fig:diagram} is designed to best approximate H.264 while maintaining the computational efficiency. \berivan{revisit the baselines once we get the new results.} 

\textbf{Learned Image Compression:}
Since the early work on learned image compression \cite{toderici2015variable}, the rate-distortion performance of learned compressors have gradually outperformed the standard image codecs \cite{balle2016end, balle2016end2, balle2018efficient, balle2016end_pcs, balle2018variational, hu2021learning, minnen2018joint, toderici2017full, mentzer2020high}. This was achieved thanks to the non-linear transforms \cite{balle2020nonlinear} learned through the end-to-end optimization of the Lagrangian loss function $L(\theta)=D(\theta)+\lambda R(\theta)$, where $D(\theta)$ is an expected distortion, $R(\theta)$ is an expected rate, and $\lambda >0$ is a Lagrange multiplier, using a differentiable proxy for the quantizer, mostly modeled as additive uniform noise or bypassed through a straight-through estimator. While they exceed the performance of the standard image codec, learned image compressors require a much greater complexity. Sandwiched image compression \cite{guleryuz2021sandwiched} is one way of breaking the tension between the flexibility and the computational complexity that the neural networks bring. Having a standard image codec between two lightweight neural pre- and post-processor networks, sandwiched image model improved the rate-distortion performance over the standard codec used alone by learning non-linear transforms without increasing the computational complexity much compared to other learned image compression frameworks. Our experiment on compressing a video clip by applying the sandwiched image model on each frame individually verifies that sandwiched image model gives more than 25 dB better reconstructions than the image codec applied alone. See Figure~\ref{fig:intra-comparison} for the experiments with JPEG and H264 (intra codec version) used with grayscale coding. With the sandwiched video model, our goal is to achieve better rate-distortion points than the sandwiched image baseline by training the model with a carefully designed video codec proxy.


\begin{figure}
    \centering
    \subfigure[\em ]{\includegraphics[width=0.45\linewidth]{ICIP/figures/jpeg.png}}
    \subfigure[\em ]{\includegraphics[width=0.45\linewidth]{ICIP/figures/h264_intra.png}}
    \caption{Comparison of (a) JPEG vs. sandwiched JPEG and (b) H264-intra vs sandwiched H264-intra.}
    \label{fig:intra-comparison}
    \vspace{-0.2in}
\end{figure}

\textbf{Learned Video Compression:}
\berivan{Fernando's paper?}

