\section{Conclusion}
\label{sec:conclusion}
\vspace{-.1cm}

In this work, we extend the sandwich architecture to video compression by carefully designing a video codec proxy and training it with neural pre- and post-processors in an end-to-end fashion. The proposed sandwich model outperforms the standard codec HEVC under various settings, including YUV 4:0:0 and YUV 4:4:4 LR formats; and under $\ell_2$ and LPIPS distortion, with gains of 8 dB (4:0:0), 6.5 dB (4:4:4 LR), and $\sim 30\%$ improvements in rate (LPIPS), respectively. We show that slim, light-weight networks with $57$K parameters can be used to closely approximate these results. The sandwich system can not only achieve a rate-distortion performance that is substantially superior to the standard video codec but it can do so without compromising computational efficiency through the use of light-weight networks. Our results clearly demonstrate that the sandwich system can re-purpose a standard codec to compression scenarios outside its immediate scope of design, from seamlessly increasing its resolution to optimizing it for a leading perceptual quality metric, all with significant improvements.

%As can be seen from our plots, sandwiched video compression is a promising direction to outperform standard video codecs. However, we believe the video codec proxy we use could be improved significantly. For instance, switching to another motion flow method other than UFlow might be helpful in making our proxy closer to the existing video codec. After all, H264 does not use UFlow to generate the motion vectors. Another future direction is to explore ways to make the training procedure more stable. Since the end-to-end framework in Figure~\ref{fig:diagram} has several important blocks that should be optimized jointly, a more careful adjustment of the hyperparameters or dividing the training into phases such that each phase would focus on a specific block in the framework could potentially improve our results. \berivan{TODO: continue}
