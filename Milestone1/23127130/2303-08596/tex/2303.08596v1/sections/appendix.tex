% !TEX root = ../main_duality.tex

\section{Duality between height functions and spin models} \label{ap:duality}
Let $G = (V, E)$ be a finite graph and write $\vec{E}$ for its oriented edges. Here and in what follows, we will always fix an implicit embedding $E \hookrightarrow \vec{E}$, 
which fixes for each edge a prescribed orientation. The particular embedding chosen is of no importance. 

Recall that the two Hilbert spaces $\Omega^0(\RR), \Omega^1(\RR)$ are equipped with the natural inner products:
\[
(f, g)_{\Omega^0} := \sum_{x \in V} f_x g_x \quad \text{ and } \quad 
	(\epsilon, \omega)_{\Omega^1} := \frac{1}{2}\sum_{\vec{e} \in \vec{E}} \epsilon_{\vec{e}} \:\omega_{\vec{e}}
\]
respectively, and it is standard to see that $\d$ and $\d^*$ are adjoints: for all $f \in \Omega^0(\RR)$ and $\omega \in \Omega^1(\RR)$
\[
	(\d f, \omega)_{\Omega^1} = (f, \d^* \omega)_{\Omega^0}.
\]
We will use the embedding $\mathbb{S} \hookrightarrow \RR$ uniquely defined by identifying $e^{i \theta} \leftrightarrow \theta$ 
in such a way that $\theta \in (-\pi, \pi]$.

Recall the definition for any $1$-form $\epsilon \in \Omega^1(\RR)$ of the twisted partition function
\[
	Z_{\#}(\epsilon) = \int_{H_{\#}(G, \mathbb{S})} \prod_{e \in E} w(\J_e + \epsilon_e)  d\J.
\]
We wish to emphasize again that when $\# = \coclosed$, unlike in the case of planar graphs, this does not generally correspond to a spin model on vertices, 
but rather to a measure on $1$-forms taking value in the group $\mathbb{S}$ and satisfying $\d^* \J = 0$. 


We will need an appropriate description of the Haar measure on $H_{\#}(G, \mathbb{S})$. 
Let us start with the case $\#  =  \exact$. 

\begin{lemma} \label{Lapp: Hcycle def}
	For any function $F: \Omega^1(G, \mathbb{S}) \to \RR$
	\[
		\int_{\Hcycle(G, \mathbb{S})} F(\J) d \J = \int_{\mathbb{S}^V} F(\d \theta) d \theta
	\]
	where $d\theta$ is the product uniform measure on $\mathbb{S}^V$. 
\end{lemma}

\begin{proof}
	We first note that the measure $\nu$ on $\Hcycle(E, \mathbb{S})$ defined via
	\[
		\nu(A) := \int_{\mathbb{S}^V} \id_{A}(\d \theta) d \theta
	\]
	is a Radon probability measure. We are left to argue that it is invariant under the group action, since then it is the unique Haar measure. 
	To that end, let $\J' \in \Hcycle$ and recall that we use additive notation for abelian groups. Note that $\J' = \d \theta'$ for some $\theta' \in \mathbb{S}^V$, so that $\J'+\d \theta= \d\theta' +\d \theta = \d(\theta' +\theta)$. 
	In particular, 
	\[
		\nu( A-J') = \int_{\mathbb{S}^V} \id_{A-J'}(\d \theta) d \theta = \int_{\mathbb{S}^V} \id_{A}(\d (\theta'+ \theta)) d \theta = \nu(A),
	\]
	where the last equality follows as $d \theta$ is the product Lebesgue measure and hence invariant under rotations (translations) of each of the coordinates. 
\end{proof}

For the case $\# = \coclosed$, we will need a different argument. 
An element $\J \in H_{\coclosed}(\mathbb{S})$ satisfies $d^* \J \equiv 0$ by definition. 
Therefore, knowing the value of $\J$ at all edges containing a vertex $x$ but one, 
uniquely determines the value of $\J$ on the last edge. 
Let $T\subset E$ be a spanning tree of $G = (V, E)$ (the exact choice does not matter). Let $G_T=(V,E\setminus T)$.
If $\partial \in V$ is a chosen root, then $T$ can be oriented towards the root and as such, 
each vertex in $V \setminus \{\partial\}$ satisfies that there is exactly one edge in the oriented tree pointing out of $x$. 
Therefore, for each $\J\in \Omega^{1}(G_T, \mathbb{S})$, there is a unique way to extend $\J$ to ${E}$ in such a way that
$\J \in \Hstar(G, \mathbb{S})$, and we will write $\bar{\J}$ for this extension. 

\begin{lemma} \label{Lapp: Hstar def}
	For any function $F: \Omega^1(G, \mathbb{S}) \to \RR$, we have
	\[	
		\int_{\Hstar(\mathbb{S})} F(\J) d \J = \int_{\mathbb{S}^{E \setminus T}} F(\bar{\J}) d \J, 
	\]
	where the measure on the right-hand side is the product uniform measure on $\mathbb{S}^{E \setminus T}$. 
	In particular, the right-hand side does not depend on $T$. 
\end{lemma}
	
\begin{proof}
	Define the measure $\nu$ on $\Hstar(G, \mathbb{S})=\ker(\d^*)$ through $\nu(A) := \int_{\mathbb{S}^{E \setminus T}} \id_{A}(\bar{\J}) d \J$.
	It is enough to show that $\nu$ is invariant under the group action. 
	Indeed, for any $\tau \in \mathbb{S}^{E \setminus T}$, we have 
	\[
	\nu( A-\bar\tau) = \int_{\mathbb{S}^{E \setminus T}} \id_{A}(\overline{\J+\tau}) d \J = \int_{\mathbb{S}^{E \setminus T}} \id_{A}(\bar{\J}) d \J=\nu(A),
	\]
	since the product uniform measure is invariant under the group action. This ends the proof. 
\end{proof}





We will also need the following classical results from Fourier series theory. For proofs, see e.g.~\cite{Bash} or \cite[Theorem IV.2.9]{Wer_FA} (in German).
\begin{lemma} \label{lem:fform}
	 Let $f: \mathbb S\to \mathbb R$ be continuously differentiable. 
	 Then $f(\theta)=\lim_{K\to \infty} f_K(\theta)$, with
	 \[
	 f_K(\theta)=a_0 + \sum_{k=1}^K (a_k e^{i k \theta} + a_{-k} e^{-i k \theta} ), \qquad \text{where} \qquad a_k=  \int_{\mathbb S} e^{- i k \theta}f(\theta){d} \theta.
	 \]
	 Moreover, the convergence is uniform on $\mathbb S$. Finally
	 \[
	  f_K(\theta) =  \int_{\mathbb S} \Big(\sum_{k=-K}^Ke^{ik (\theta'-\theta)}\Big) f(\theta' ){d}  \theta'.
	 \]
\end{lemma}




\begin{proof}[Proof of Lemma \ref{lem:duality}]
	\textbf{Case I: $\nu_{\coclosed}$.} 
		It follows from condition~\ref{eq:Vsum} and from the dominated convergence theorem that for any $\epsilon \in \Omega^1(\mathbb R)$, we have
	\begin{align*}
		Z_{\exact}(\epsilon) &= \int_{H_{\exact}(\mathbb{S})} \prod_{e \in E} w(\J_e + \epsilon_e) d \J \\
		&= \int_{H_{\exact}(\mathbb{S})} \sum_{\n: E \to \ZZ} \prod_{e \in E} e^{i \n_e(\J_e + \epsilon_e)} \exp(-\c{V}(\n_e)) d \J \\
		&= \sum_{\n: E \to \ZZ} e^{i (\n, \epsilon)}\prod_{e \in E}\exp(-\c{V}(\n_e)) \int_{H_{\exact}(\mathbb{S})} e^{ i (\n, \J)} d \J. 
	\end{align*}
	Moreover, by Lemma~\ref{Lapp: Hcycle def} we have
	\begin{align*}
		\int_{\Hcycle(\mathbb{S})} e^{i(\n, \J)} d \J = \int_{\mathbb{S}^V} e^{i(\n, \d \theta)} d \theta 
		= \int_{\mathbb{S}^V} e^{i(\d^*\n, \theta)} d \theta = \prod_{x \in V} \int_{\mathbb{S}} e^{i \d^*\n_x\theta_x} d \theta_x = \mathbf 1\{ \n \in H_{\coclosed} (\mathbb Z)\},
	\end{align*}
	which ends the proof of case I.
	
	\textbf{Case II: $\nu_{\exact}$.} We will show equality of partition functions with $\epsilon =0$, and the general case follows the same steps. By Lemma~\ref{lem:fform} we have
	\begin{align*}
		\prod_{e \in E} \exp(-\mathcal V(\d h_e)) &=  \prod_{e \in E} \int_{\mathbb S} e^{ i \d h_e \theta_e}w(\theta_e){d} \theta_e \\
		&= \int_{\mathbb S^E}  e^{ i (\d h, \theta)_{\Omega_1}} \prod_{e \in E}w(\theta_e)\prod_{e \in E}{d} \theta_e \\
		&= \int_{\mathbb S^E}  e^{ i (h, \d^*\theta)_{\Omega_0}} \prod_{e \in E}w(\theta_e)\prod_{e \in E} {d}\theta_e,	
	\end{align*}
	and hence
	\begin{align}
	&\mathop{\sum_{h: V\to \mathbb Z}}_{h_\partial =0} \prod_{e \in E} \exp(-\mathcal V(\d h_e))  = \lim_{K_{v_n}\to \infty} \cdots  \lim_{K_{v_1}\to \infty}\nonumber
	 \sum_{h_{v_n}\in I_{K_{v_n}}}\cdots \sum_{h_{v_1}\in I_{K_{v_1}}} \prod_{e \in E}\exp(-\mathcal V(\d h_e)) \nonumber \\
	 &=  \lim_{K_{v_n}\to \infty} \cdots  \lim_{K_{v_1}\to \infty} \sum_{h_{v_n}\in I_{K_{v_n}}}\cdots \sum_{h_{v_1}\in I_{K_{v_1}}} \int_{\mathbb S^E}  e^{i (h, \d^*\theta)_{\Omega_0}} \prod_{e \in E}w(\theta_e)\prod_{e \in E} {d}\theta_e, \label{eq:bigone}
	\end{align}
	where $I_K=\{-K,\ldots,K\}$, and $v_1, v_2, \ldots, v_n$ is any ordering of $V\setminus \{\partial\}$ that explores the tree $T$ from the leaves towards the root $\partial$.
	
	We will now evaluate the expression above with the use of Lemma~\ref{lem:fform} by iteratively (over $i$) exchanging the order of summation of $h_{v_i}$ with the integration over $\theta_{e_{v_i}}$, and then takin the $K_{v_i}\to \infty $ limit.
	To this end, we orient each edge in $T$ towards the root vertex $\partial$, and to each vertex $v\neq \partial$ we assign the unique outgoing edge $e_v$ from $v$.
	
	In the first step we choose the leaf vertex $v=v_1$, and write
	\[
		\d^* \theta_v = \sum_{w \sim v} \theta_{wv} = -\theta_{e_v} + \theta_{e_1} + \ldots + \theta_{e_{l}},
	\]
	where $l+1$ is the degree of $v$ in $G$, and $e_1, \ldots, e_l$ are the remaining edges in $E$ incident to $v$ and pointing at $v$. 
	Let $x$ be the other endpoint of the edge $e_{v}$, so that $e_{v} = (v, x)$. 
		Given $h_x \in I_{K_x}$ and $(\theta_e)_{e \in E \setminus \{e_v\}}$ apply Lemma~\ref{lem:fform} (separately to the imaginary and real part) with $f(\theta_{e_v}) := w(\theta_{e_v}) e^{i h_x d^* \theta_x}$ to get
		\[
			\int_{\mathbb S} \Big( \sum_{h_v \in I_{K_v}} e^{i h_v \d^*\theta_v}\Big) w(\theta_{e_v})e^{i h_x d^* \theta_x} {d} \theta_{e_v} = f_{K_v}( \theta_{e_1} + \ldots + \theta_{e_{l}}) \to f( \theta_{e_1} + \ldots + \theta_{e_{l}}), 
		\]
		as $K_v \to \infty$ uniformly in $\theta_{e_1} + \ldots + \theta_{e_l}$. This means that we can take $K_v \to \infty$ inside the integral over $\mathbb{S}^{E \setminus \{e_v\}}$. All in all this removes the variables $h_v$, $K_v$ from~\eqref{eq:bigone}, and $\theta_{e_v}$ is replaced it by $\theta_{e_1} + \ldots + \theta_{e_l}$. Define now $\theta^{(1)}_e = \theta_e$ for $e \in E \setminus \{e_v\}$ and $\theta^{(1)}_{e_v} = \theta_{e_1} + \ldots + \theta_{e_l}$. 
		In other words, after step one, \eqref{eq:bigone} becomes
		\[
			 \lim_{K_{v_n}\to \infty} \cdots  \lim_{K_{v_2}\to \infty} \sum_{h_{v_n}\in I_{K_{v_n}}}\cdots \sum_{h_{v_2}\in I_{K_{v_2}}} \int_{\mathbb S^{E \setminus \{e_{v_1}\}}}  \prod_{w \in V \setminus \{v_1\}} e^{i h_w (\d^*\theta^{1})_w} \prod_{e \in E}w(\theta^{1}_e)\prod_{e \in E \setminus \{e_{v_1}\}} {d}\theta_e. 
		\]
		
		We continue this procedure for edge $e_{v_2}$ where we take the corresponding $f$ ($x$ is replaced by the other endpoint of $e_{v_2}$). 
		In this step we remove the variables $h_{v_2}, K_{v_2}$ and $\theta^{(1)}_{e_{v_2}}$, and replace the latter by $\theta^{(1)}_{e_1} + \ldots + \theta^{(1)}_{e_l}$ (where $l$ depends on $v_2$ now). Define then $(\theta^2_e)_{e \in E}$ through $\theta^{(2)}_e = \theta^{(1)}_e$ on $e \in E \setminus \{e_{v_2}\}$ and 
		$\theta^{(2)}_{e_{v_2}} = \theta^{(1)}_{e_1} + \ldots + \theta^{(1)}_{e_l}$. 
		We iterate the procedure until we have done so for all vertices of $V \setminus \{\partial\}$ and arrive at $\theta^{(n)}$. 
		It is clear that $(\d^* \theta^{(n)})_x = 0$ for all $x \in V \setminus \{\partial \}$, and therefore
		\[
			(\d^* \theta^{(n)})_{\partial} = (\d^*\theta^{(n)}, 1)_{\Omega^0} = (\theta^{(n)}, \d 1)_{\Omega^1} = 0, 
		\]
		so that $\d^* \theta^{(n)}$ vanishes on all of $V$. 
		
		Now let $(J_e)_{e \in E \setminus T} = (\theta_e)_{e \in E \setminus T}$ and define $\bar{J}$ the unique extension to $\Hstar(G, \mathbb{S})$ as before. 
		It is easy to check that $\bar{J}$ equals $\theta^{(n)}$. 
		Therefore, at the end of the iterative procedure, we have that~\eqref{eq:bigone} becomes
		\[
			 \int_{\mathbb S^{E\setminus T}} \prod_{e \in E}w(\bar J_e)\prod_{e \in E \setminus T} {d}J_e=Z_{\coclosed}(0), 
		\]
		where the equality follows from Lemma~\ref{Lapp: Hstar def}. This ends the proof of case II.
\end{proof}

\section{Proof of the Ginibre inequality} \label{ap:Gin}
We focus here only on the case where $\J$ takes values in $\Hstar$, as the other case is just the classical Ginibre inequality \cite{Gin}. 
To be precise, we will prove the following fact, from which Lemma \ref{L: Ginibre} follows immediately. 

\begin{lemma}\label{L: Ginibre 2}
	Consider the setup as in Section \ref{sec:setup2}. Let $F, F': \mathbb{S} \to \RR$ be two positive definite functions. Then 
	\[
		\mu_{\beta, \coclosed}(FF') - \mu_{\beta, \coclosed}(F)\mu_{\beta, \coclosed}(F') \geq 0. 
	\]
\end{lemma}

As in the classical proof by Ginibre \cite{Gin}, we will rely on the following result. 

\begin{lemma} \label{L: Ginibre core}
	For any $n \in \NN$ and $(m_i)_{i = 1}^n \in \ZZ^n$, we have 
	\[
		\int_{\Hstar(\mathbb{S})^2} \prod_{i = 1}^n (\cos(m_i\J_{e_i}))  \pm \cos(m_i\J_{e_i}'))d\J d \J' \geq 0, 
	\]
	where the signs $\pm$ might be different for each $i$.
\end{lemma}

\begin{proof}
	We begin by noticing that for any linear $M: \RR^{E} \to \RR$,
	\begin{align*}
		&\cos(M \J) + \cos(M \J') = 2\cos\left(M \frac{\J - \J'}{2}\right) \cos\left(M\frac{\J + \J'}{2}\right), \quad \text{and}\\
		&\cos( M \J) - \cos(M \J') = 2\sin\left( M \frac{\J - \J'}{2}\right) \sin\left(M \frac{\J + \J'}{2}\right). 
	\end{align*}
	Let $T\subset E$ be a spanning tree of $G = (V, E)$ and recall for $J \in \Omega^1(G_T, \mathbb{S})$ the definition of $\bar{J}$ as in Lemma~\ref{Lapp: Hstar def}. By Lemma~\ref{Lapp: Hstar def} we have
	\[
		\int_{\Hstar(\mathbb{S})^2} \prod_{i = 1}^n (\cos(m_i\J_{e_i}))  \pm \cos(m_i\J_{e_i}'))d\J d \J' = \int_{(\mathbb{S}^{E \setminus T})^2} \prod_{i = 1}^n (\cos(m_i\bar{\J}_{e_i}))  \pm \cos(m_i\bar{\J}_{e_i}'))d\J d \J'. 
	\]
	Now consider $J$ in $\Omega^1(G_T, \RR)$ (via the usual identification of $\mathbb{S}$ with $(-\pi, \pi]$) and define by $A_T J$ the unique extension of $J$ to $\Omega^1(G, \RR)$ so that $J \in \Hstar(G, \RR)$, i.e. so that  $\d^* (A_T J) = 0$ in $\RR$. Notice that $A_T J$ and $\bar{J}$ (seen in $\RR$) are equal on all edges in $E \setminus T$, while on an edge $e_i \in T$, the difference is of the form $2\pi k_{i}$ for some integer $k_i$.
	Since the cosine is $2\pi$-periodic, we notice that each factor where the edge $e_i$ is in $T$ is of the form $\cos(m_i(A_T \J)_{e_i}) \pm \cos(m_i(A_T \J')_{e_i})$. 
	All together, we can thus write
	\[
		\int_{\Hstar(\mathbb{S})^2} \prod_{i = 1}^n (\cos(m_i\J_{e_i}))  \pm \cos(m_i\J_{e_i}'))d\J d \J' = \int_{(\mathbb{S}^{E \setminus T})^2}F\left(\frac{\J + \J'}{2}\right)F\left(\frac{\J - \J'}{2}\right)d \J d \J'
	\]
	for some function $F: \mathbb{S}^{E \setminus T} \to \RR$. 	
	Next, make the change of variables via $\tau_e := \frac{\J_e - \J_e'}{2}$ and $\tau'_{e} = \frac{\J_e + \J'_e}{2}$, so that
	%We will view $(\tau, \tau')$ as a single $1$-form taking values in $\mathbb{S}^2$, and as such it satisfies the relations (in the group $\mathbb{S}$)
	%\[
	%\d^*(\tau + \tau') = 0 \qquad \text{and} \qquad \d^*(\tau - \tau') = 0. 
	%\]
	%Thus, if we know $(\tau, \tau')$ on $E \setminus T$, then we can recover $(\tau, \tau')$ on $E$ uniquely. In particular, the above implies
	\begin{align*}
		\int_{(\mathbb{S}^{E \setminus T})^2}F\left(\frac{\J + \J'}{2}\right)F\left(\frac{\J - \J'}{2}\right)d \J d \J' &= \int_{ (\mathbb{S}^{E \setminus T})^2} F(\tau)F(\tau') d\tau d\tau' \\
		&= \Big(\int_{ (\mathbb{S}^{E \setminus T})^2} F(\tau)d\tau\Big)^2\geq 0.
	\end{align*}
	This ends the proof.
\end{proof}

Note that the collection of functions $t \mapsto \cos(mt)$, $m \in \ZZ$,
generates the positive cone of (real) positive definite functions. 
Since the integral appearing in Lemma \ref{L: Ginibre core} 
is stable under taking convex combinations, this implies that
for any collection $\{ F_i\}$ of positive definite functions $\mathbb{S} \to \RR$, we have
\[
	\int_{\Hstar(\mathbb{S})^2} \prod_{i=1}^n (F_i(\J_{e_i}) \pm F_i(\J_{e_i}')) d \J d \J' \geq 0.
\]
This last remark is also the content of Propositions 1 and Example 4 of \cite{Gin}. 
From this, Lemma \ref{L: Ginibre 2} can be proved in exactly the same way as in \cite[Proposition 3]{Gin}.

\section{Reflection positivity.} \label{ap:RP}
We recall briefly a condition for potentials to be reflection positive. 
For further reference, see e.g. \cite{Biskup} and \cite{FriVel}. 
Fix the torus $\mathbb{T}_n = (\mathbb{Z} / n\ZZ)^d$ and let $\Theta$ be any reflection
(either through edges or through vertices). 
This naturally splits the torus into two parts $\mathbb{T}_n^+$ and $\mathbb{T}_n^-$. 
Let $\mathscr{U}^{\pm}$ be the set of real-valued functions on $\mathbb{T}_n$ depending only on $\mathbb{T}_n^{\pm}$. 
Then $\Theta$ induces a map $\Theta: \mathscr{U}^{\pm} \to \mathscr{U}^{\mp}$.
We will say that a probability measure $\mu$ on $\mathbb{S}^{\mathbb{T}_n}$ is reflection positive with respect to $\Theta$ if
\vspace{0.2cm}
\begin{enumerate}[\hspace{0.5cm}(a)]
	\item $\mu(g \Theta f) = \mu(f \Theta g)$ for all $f, g \in \mathscr{U}^+$, 
	\item $\mu(g \Theta g) \geq 0$. 
\end{enumerate}
\vspace{0.2cm}
\noindent Although the property (a) is not important for us, it is also the easier part and it holds precisely for all measures that are invariant under the reflection $\Theta$. 
It is not hard to see that \emph{all} measures we consider in this text thus satisfy (a). 
We recall the following lemma. 

\begin{lemma} \label{L: RP condition}
	Let $\c{H}_n:\mathbb{S}^{\mathbb{T}_n} \to \RR$ be the Hamiltonian of a spin-system on the torus satisfying
	\[
		-\c{H}_n = A + \Theta A + \sum_{i} C_i \Theta C_i
	\]
	for some functions $A, C_{i} \in \mathscr{U}^+$. Then $\mu_n \propto e^{-\c{H}_n}$ is reflection positive w.r.t. $\Theta$. 
\end{lemma}

For a proof we refer to e.g.~\cite{Biskup} or \cite[Lemma 10.8]{FriVel}. 
%We will briefly argue that for all potentials $\c{U}$ nice enough, the lemma holds. 
We point out already that for reflections going through vertices, 
the decomposition of Lemma \ref{L: RP condition} is trivial as we consider only nearest-neighbor interactions. 

For reflection through edges, we need that we can decompose
\[
	-\c{U}(t_x - t_y) = \sum_{i} F_{i}(t_x)F_{i}(t_y), 
\]
for some collection of functions $\{F_{i}\}$. 
By classical trigonometric identities, this can be easily deduced whenever $-\c{U}$ is positive definite and regular enough so that  
\[
	-\c{U}(t_x - t_y) = \sum_{i = 0}^\infty \alpha_i \cos(i(t_x - t_y)) = \sum_{i = 0}^\infty \alpha_i (\cos(it_x)\cos(it_y) + \sin(it_x)\sin(it_y)), 
\]
with $\alpha_i\geq0$.

\section{Positive definite functions} \label{ap:div}
We will call an even function $F:\mathbb{S} \to \RR$ \textit{conditionally positive definite} if for any vector $\xi = (\xi_1, \ldots, \xi_n) \in \RR^n$ with mean $0$ and all $t_1, \ldots, t_n \in \mathbb{S}$ it holds that
\[
	\sum_{i, j} \xi_i\xi_j F(t_i - t_j) \geq 0
\]
\begin{lemma}
	A function $F$ is conditionally positive definite if and only if $e^{cF}$ is positive definite for each $c > 0$. 
\end{lemma}
\begin{proof}
	Assume that $e^{cF}$ is p.d. for each $c > 0$. Then
	\[
		\frac{1}{c} \sum_{i, j} \xi_i\xi_j (e^{cF(t_i - t_j)} - 1) = \frac{1}{c} \sum_{i, j} \xi_i\xi_j e^{cF(t_i - t_j)}  \geq 0, 
	\]
	and taking $c \to 0$ shows one implication, since the derivative at zero of $e^{cF}$ is $F$. 
	The other implication follows from expanding the exponential and using that the space of conditional positive definite functions is closed under addition, 
	multiplication by nonnegative reals and multiplication. 
\end{proof}

Without proof, we will also state the following result. 

\begin{lemma} \label{L: cond PD -> PD}
	If $F:\mathbb{S} \to \RR$ is conditionally positive definite, then there exists a positive definite function $\varphi:\mathbb{S} \to \RR$ and a constant $c$ such that $F = \varphi - c$. 
\end{lemma}

\begin{proof}
	See e.g. Corollary 2.10.3 in \cite{BdlHV}. 
\end{proof}

Let us apply this to the potentials $\c{V}$ with dual potential $\c{U}$. Suppose that $\c{V}$ is divisible, i.e. that there exists a potential $\c{V}^{1}:\ZZ \to \RR$ such that
	\[
		e^{-\c{V}^1} * e^{-\c{V}^1} = e^{-\c{V}}. 
	\]
	This means that the Fourier transform $g$ of $e^{-\c{V}^1}$ satisfies $g^2 = e^{-\mathcal U}$. Assuming that $g$ is nonnegative, this implies in particular that the dual potential $\c{U}^{1}$ corresponding to $\c{V}^{1}$ equals $-\c{U}/2$. Moreover, $g = e^{-\c{U}/2}$ is positive definite (because its Fourier transform is non-negative). 
	
	Under the assumption that $e^{-\c{V}}$ is infinitely divisible, it is true that $\c{V}^1$ is also infinitely divisible. 
	Therefore, the $g$ is nowhere zero, which implies that its sign is fixed. However, $g(0) = 1$ so that $g > 0$ everywhere. 
	This implies in particular that $g = e^{-c \c{U}}$ must be positive definite for each $c > 0$ and hence we deduce that $-\c{U}$ is conditionally positive definite. 
	Lemma \ref{L: cond PD -> PD} then implies that we can take $-\c{U}$ to be positive definite since adding constants does not change the Gibbs measure. 



