\section{Problem Statement}
\label{sec:ps}

\begin{figure}[tb]
\centering
  \includegraphics[width=\textwidth]{figs/al-pipeline.pdf}
  % \caption{Our \emph{coarse-to-fine} AL for part segmentation workflow. We first perform \emph{coarse} AL on the interact direction predicted in the \emph{Coarse} stage. With ground truth interact directions, \emph{Fine} stage makes the \xeable part mask predictions. In \emph{fine} AL, we leverage an iteratively training method, which includes human verification and annotation of the part mask, to obtain }
  \caption{Our coarse-to-fine Active Learning (AL) training pipeline. The \emph{coarse} AL applys on interaction directions and retains high-quality predictions while manually rectifying the rest. These rectified predictions form a constructive prior for refined mask prediction. Subsequently, the \emph{fine} AL stage utilizes these refined masks, employing an iterative training method with continuous human intervention for accurate part mask annotation.}
  \label{fig:al-pipeline}
  \vspace{-20 pt}
\end{figure}

% \agp{
% AGP: An interconnection of static and moveable parts compose what are typically referred to as articulated objects. Let $D$ be a real-world image dataset of articulated objects. Given an RGB image $I\in D$ containing one or more articulated objects $\{o_{j}\}$ as input, our goal is to output a set of 2D bounding boxes, $\{b_i\}$, segmentation masks, $\{m_{i}\}$, and semantic labels, $l_i \in \{\text{door}, \text{drawer}\}$ corresponding to all openable parts, $\{p_i\}$, for each object $o\in \{o_{j}\}.$
% An interconnection of static and moveable parts compose what are known as articulated objects
% }
\agp{
Given a set of images $D$ captured from the real-world scene, our input is a single RGB image $I \in D$ containing one or more articulated objects $o_{i}$ from one or more categories $c_{i} \in \{\text{cabinet}, \text{dishwasher}, \text{fridge}, \text{microwave}, \text{oven}, \text{washer}\}$. We assume that each object $o_{i}$ has more than one \xeable parts $P = \{p_1, \dots, p_k\}$ according to its functionality. Our first goal is to predict the 2D bounding box $b_i$, the segmentation mask $m_i$ represented by a 2D polygon and the semantic label $l_i \in \{\text{door}, \text{drawer}\}$ for each \xeable part. 
%
Extending the above goal, we also aim to build a labeled image dataset that provides accurate 2D segmentation masks and labels for all $p_{i}$'s, for all $I \in D$.
}



