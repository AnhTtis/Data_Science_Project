%%%% 5-Conclusion.tex starts here %%%%

\section{Conclusion and Future Work}
In this work, we present a novel unified framework, namely UCAST, for the task of arbitrary image style transfer. 
Instead of relying on second-order metrics such as Gram matrix or mean/variance of deep features, we use image features directly by introducing an MSP module for style encoding. 
We develop a parallel contrastive learning scheme to leverage the available multi-style information in the existing collection of artwork and help train the MSP module and the generative style transfer network.
We propose an adaptive contrastive learning for style transfer process implemented by a dual input-dependent temperature.
We further propose a DE scheme to effectively model the distribution of realistic and artistic image domains. 
Extensive experimental results demonstrate that our proposed UCAST method is effective for various generative backbones and achieves superior arbitrary style transfer results compared with state-of-the-art approaches. 
In the future, we plan to improve the contrastive style learning process by considering artist and category information.


%%%% 5-Conclusion.tex ends here %%%%