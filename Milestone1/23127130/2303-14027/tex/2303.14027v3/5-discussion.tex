In this paper we propose Poincar\'e ResNet and make several contributions. First, we formulate the Poincar\'e residual block including convolutions, batchnorm, and ReLU's.
Second, we introduce an initialization that prevents vanishing signals and allows for the training of deeper models. Third, we propose a new hyperbolic batch normalization based on the Poincar\'e midpoint, which substantially increases efficiency at no cost to its performance. Fourth, we manually derive the backward pass for several operations within the Poincar\'e ball to decrease the size of the computation graphs.
Empirically, we perform initial explorations into fully hyperbolic neural networks, showing that Poincar\'e Resnets are (i) more robust to out-of-distribution samples, (ii) more robust to adversarial attacks and (iii) complementary to Euclidean networks.
