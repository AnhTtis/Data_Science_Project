In this paper we have made a step towards fully hyperbolic neural networks in computer vision and proposed Poincar\'e ResNet. We have made several contributions. First, we have formulated the Poincar\'e residual block including 2D Poincar\'e convolutions, Poincar\'e batch normalization and a Poincar\'e version of the ReLU nonlinearity. Second, we have introduced an initialization that prevents vanishing signals and allows for the training of deeper models. Third, we have proposed a new hyperbolic batch normalization based on the Poincar\'e midpoint, which substantially increases efficiency at no cost to its performance. Third, we have manually derived the backward pass for several operations within the Poincar\'e ball to decrease the size of the computation graphs.
Empirically, we have performed initial explorations into the benefits of fully hyperbolic neural networks, showing that Poincar\'e Resnets are (i) more robust to out-of-distribution samples, (ii) more robust to adversarial attacks and (iii) complementary to Euclidean networks. We believe that these results only scratch the surface of the potential of fully hyperbolic learning in computer vision and allude to intriguing properties compared to their Euclidean counterparts. For example, we expect further advances when integrating our approach into existing methods that perform the final classification in hyperbolic space.
