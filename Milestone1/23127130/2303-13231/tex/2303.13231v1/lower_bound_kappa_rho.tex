    We consider a single group consisting of $\nworker = \nmalicious + \nhonest$ workers. Since the datasets per group as well as the sets of workers are disjoint, the communication necessary for $\ngroup$ groups of size $\ngrad/\ngroup$ is at least as big as for $\ngroup^\prime=1$ group of size $\ngrad/\ngroup$.
    Further, we assume the behaviour of the malicious workers as in \cref{sec:attack}.

    To proceed with the proof, we need the following direct consequence of the proof technique used to prove \cref{thm:converse_C}.

\begin{corollary}[Computation of Disagreement Gradients]\label{cor:disagreement}
    For any (\nround,\localcomp,\replfact,\commoh)-\BGC scheme (\allocmat, \encfunset, \decfun, \proto), with $\replfact = \nmalicious + \nhonest$ and \allocmat\ as in \eqref{eq:fractional_repetition},
    if the adversary behaves according to \cref{sec:attack}, then the list of locally computed gradients must contain the list of all gradients on which the workers disagree, i.e.,
  $\forall \widetilde{\gind} \in \disagreegradset:  \widetilde{\gind} \in \lgindset^{(\nround)}$.
    \label{cor:comp_disag_grads}
\end{corollary}
\begin{IEEEproof}
    The proof follows the same steps as for \cref{thm:converse_C}. Note that if there exists an index $\widetilde{\gind} \in \disagreegradset: \widetilde{\gind} \notin \lgindset^{(\nround)}$, there are two cases that cannot be distinguished based on the information available at the \master.
\end{IEEEproof}

    According to \cref{cor:comp_disag_grads}, for $\localcomp = \lfloor \frac{\nmalicious}{\nhonest} \rfloor$, we require every item of $\disagreegradset$ to be in $\lgindset^{(T)}$, while $\localcomp = |\lgindset^{(\nround)}| = |\disagreegradset| = \compbound$.
    In other words, the \master must exactly compute all the gradients in $\disagreegradset$ locally. If there is a non-zero probability that a different gradient is computed locally, the scheme cannot be a valid \BGC scheme.
    Overall, $\disagreegradset$ must be uniquely determined by the \master's available information at the end of the protocol, leading to
        $\En(\disagreegradset \given \wtmdata, \locgradset) = 0$,
    where $\wtmdata$ denotes the list of random variables corresponding to all data transmitted from all workers to the \master and \locgradset denotes the list of the random variables corresponding to the values of the locally computed gradients.

    Using this we have
    \begin{align}
        \En(\wtmdata \given \locgradset) 
                    \label{eq:defmi}
                    &\geq \I(\wtmdata; \disagreegradset \given \locgradset) \\ 
                    \notag
                    &= \En(\disagreegradset \given \locgradset) - \En(\disagreegradset \given \locgradset, \wtmdata) \\
                    \notag
                    %\label{eq:apply_decodability}
                    &= \En(\disagreegradset \given \locgradset) \\
                    \label{eq:indep_disagreegradset}
                    &= \En(\disagreegradset) \\
                    &= \log_\alphasize \binom{\ngrad / \ngroup}{\lfloor \nmalicious / \nhonest \rfloor},\label{eq:uniform}
\end{align}
where \eqref{eq:defmi} follows from the definition of mutual information, 
\eqref{eq:indep_disagreegradset} follows since $\disagreegradset$ is independent from $\locgradset$ and \eqref{eq:uniform} holds since $\disagreegradset$ is a uniform selection of $\localcomp = \lfloor \nmalicious / \nhonest \rfloor$ indices out of $[\ngrad / \ngroup]$.
    To transmit the information in $\wtmdata$ with zero error to the \master, the workers need to send at least $\log_\alphasize \binom{\ngrad / \ngroup}{\lfloor \nmalicious / \nhonest \rfloor}$ symbols from $\galpha$.
