Initially, we make the following observations about the fundamental limits:
\begin{observation}[Converse on $\replfact$]
    \label{obs:min_replfact}
    In any \BGC, the gradient $\pgrad$ for any sample $\sample$ must either be computed by at least $\nmalicious+1$
    workers or by the \master
    \begin{equation*}
        \sum_{\wind \in \range{\nworker}} \allocmat[{\gind,\wind}] \leq
        \nmalicious
        \implies \gind \in \lgindset^{(\nround)}.
    \end{equation*}
    
    If each sample is replicated equally often, i.e., $\sum_{\wind \in \range{\nworker}} \allocmat[1, \wind]= \dots = \sum_{\wind \in \range{\nworker}} \allocmat[\ngrad, \wind]$, and the \master does not compute all partial gradients locally, i.e., $\localcomp < \ngrad$, then $\replfact \geq \nmalicious + 1$. In particular, this holds for fractional repetition data assignments.
\end{observation}

\begin{observation}
    \label{obs:DRACO}
    DRACO, the schemes in \cite{chenDRACOByzantineresilientDistributed2018}, are $(\nround=0, \localcomp=0, \replfact=2\nmalicious+1, \commoh=0)$ \BGC schemes.
    For $\nround=0$, $\localcomp=0$, and $\commoh=0$, they achieve the optimal replication factor $\replfact$.
\end{observation}
