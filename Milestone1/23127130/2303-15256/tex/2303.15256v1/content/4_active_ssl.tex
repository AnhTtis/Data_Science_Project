\section{PAL: Positive Active Learning}
\label{sec:PAL}

Now that we demonstrated how one should focus on the graph $\mG$, rather than the (self-)supervised loss, we turn our focus into getting that graph $\mG$. 
In particular, we propose an active learning framework that discovers $\mG$ through efficient, low-cost queries.

\subsection{One Framework to Rule Them All}

From our understanding (\cref{thm:recovery}), the difficulties of both supervised learning and SSL are the same: they need a correct graph $\mG$, i.e they need to identify samples that are semantically similar, either through label annotations or through the right design of DA.

\begin{algorithm}[ht]
\KwData{$\mX\in\R^{N\times D}$; unknown graph $\mG = \mG^{(\sup)}$.}
\KwResult{Embedding $f_\theta:\R^D \to \R^K$.}
Initialization: weights $\theta_0$, scheduler $(\gamma_t)$; $T\in\N$;\\
\For{$t \in [T]$}{
Collect $I_t, J_t\leftarrow$ from {\color{blue} sampler};\\
Collect $(\mG_{ij} = \ind{y_i=y_j})_{(i,j)\in I_t}$ from {\color{blue} labelers};\\
Update $\theta_{t+1} \leftarrow \theta_t - \gamma_t \nabla_{\theta} \mL(\theta_t; \mG, I_t, J_t)$.
}
\caption{PAL framework with {\color{blue} oracle}}
\label{alg:pal}
\end{algorithm}

Our framework suggests a generic way to proceed, having fixed the samples $\mX$ in advance, and without much {\em a priori} knowledge on the similarity graph $\mG$.
In an active learning spirit, one would like to design a query strategy to discover $\mG$, and an update rule for the learned parameter $\theta$.
To ground the discussion, let us focus on VICReg.
The variance-covariance term can be rewritten with $R(a, b) = (a^\top b)^2 - \norm{a}^2 - \norm{b}^2$, this leads to the formula, proven in \cref{proof:vic-2},
\begin{gather}
    \gL_{\rm VIC^2}(\theta; \mG, I, J) = \sum_{(i,j)\in I} \mG_{i,j} \norm{f_\theta(\vx_i) - f_\theta(\vx_j)}^2
    \\+ \sum_{(i,j)\in J} R(f_\theta(\vx_i), f_\theta(\vx_j)),
    \label{eq:vic_sgd}
\end{gather}
where $I = J = [N]^2$.
An oracle would typically consider two small sets of indices $I, J \subset [N]^2$, asks labelers to provide $\mG_{ij}$ for $i,j\in I$, and, given a step size $\gamma_t$, update the weights with
\begin{align}
    \theta_{t+1} = \theta_t - \gamma_t \nabla_{\theta} \mL(\theta_t; \mG, I, J),
    \label{eq:weight_update}
\end{align}
which could be performed with the sole access to $(\mG_{ij})_{(i,j)\in I}$.
The pairs in $J$ are used to compute the variance-covariance regularization term.
The complete picture leads to PAL, \cref{alg:pal}.
A particularly useful features of SGD for active learning is its robustness to labeling noise \cite{Cabannes2022active}.
In other terms, {\em \cref{alg:pal} is robust to noise in the query answers}.

We will now dive more in-depth into two variants of oracles: passive and active ones. As we will see, passive oracles can recover traditional SSL as special cases, but will be much less efficient in learning good representation than active strategies.

\subsection{Passive Oracles}

Passive variations of the PAL algorithm consist in fixing the oracle behavior at iterations $t\in [T]$ before starting the training. This formulation, under which the oracle does not leverage any information collected along training, recovers both SSL and supervised learning, based on the different querying strategies.

{\bf Self-Supervised Oracle.}~%
Probably the simplest oracle to describe is the one corresponding to the SSL strategy.
The original VICReg algorithm \cite{bardes2021vicreg} is made of $t$ gradient updates over $T = N_0 E$ iterations with $N = N_0 V E$ samples, where $N_0$ is the number of original samples, $E$ is the number of epochs, $V$ the number of views.
At time $t\in[T]$, $I_t$ is chosen as $\brace{(2t+1, 2(t+1))}$, describing a positive pairs generated on the fly from one original sample $\vx_i$ for $i = t \,\operatorname{mod. }\, N_0$; and $J_t$ is chosen as some mini-batch to estimate the covariance matrix of the features at the current epoch.
Because it has been built to remove human feedback, SSL actually does not need to ask for labelers to query $\mG_{s,s+1}$ (where $s = 2t+1$), since it is known by construction that those entries are going to be one.

{\bf Supervised Oracle.}~When it comes to a supervised learning oracle, the supervised learning loss provided in \cref{lemma:characterization} --which is known to recover $\mY$ (given class templates) as per \cref{thm:recovery}-- is easily minimized with gradient descent based on \eqref{eq:vic_sgd}.
Hence a simple oracle to solve the supervised learning problem based on stochastic gradient descent: at time $t$, consider a random pair of indices $(i_t, j_t)$ and set $I_t = J_t \leftarrow \brace{(i_t,j_t)}$.
The querying of $\mG_{i_t,j_t}$ can either be done on the fly, or if the dataset is already annotated, it can be deduced from the knowledge of $\mG_{i_t, j_t} = \ind{y_{i_t} = y_{j_t}}$.

\begin{algorithm}[ht]
    SSL oracle: \\
    \hspace{.3cm} Sampler: $I_t = \brace{(i_{2t+1}, i_{2(t+1)})}$, $J_t$ a minibatch,\\
    \hspace{.3cm} Labeler: $\mG_{2t+1,2(t+1)} = 1$.\\
    Supervised oracle: \\
    \hspace{.3cm} Sampler: $I_t = J_t = \brace{(i_t, j_t)}$ random in $[N]^2$,\\
    \hspace{.3cm} Labeler: $\mG_{i,j} = \ind{y_i = y_j}.$
    \caption{Passive Oracle Specifications}
    \label{alg:passive}
\end{algorithm}

{\bf Theoretical Remarks.}~%
Remarking that \eqref{eq:vic_sgd} is an unbiased formulation of VICReg, in the sense that
\[
    \gL_{\rm VIC^2}(\mZ) = \E_{I,J\sim \uniform{[N]^2}}\bracket{\gL_{\rm VIC^2}(\mZ; I, J)}.
\]
As a consequence, when $\theta \mapsto \norm{f_\theta(\mX) f_\theta(\mX)^\top - \mG}^2$ is strongly convex, \cref{alg:active} with either the self-supervised or the supervised oracle will converge to the minimizer of the VICReg loss in $O(1/T)$ \cite{Bubeck2015}.
Moreover, while this results holds for the empirical loss with resampling, it is equally possible to get a similar result for the minimization of the infinite-data (aka population) version of the VICReg loss and the recovery of the ideal embedding representation, when performing a single pass over the data.
In particular, by making sure that $J$ only charges pairs $(i, j)$ for $i$ and $j$ in two disjoint  subsets of $[N]$, one can prove convergence rates in $O(1/N)$ (Theorem 3 in \cite{cabannes2023ssl}).

Moreover, because the VICReg loss in \cref{thm:recovery} is nothing but a matrix factorization problem, one can directly translate results from this literature body into PAL. In particular, recent works have derived theoretical results regarding the matrix factorization problem based on toy models of neural networks, which might be plugged directly in here to claim theoretical results about the soundness of the PAL algorithm with neural networks \cite{Ye2021,Du2018,Jian2022}.
Since those results hold for any graph $\mG$, such results directly apply to both SSL and supervised learning, highlighting how PAL jointly derives results for SSL and supervised learning. 

\begin{figure}[t]
    \centering
\begin{tikzpicture}
\node[inner sep=0pt]  (title) at (0,-.1) {Level lines of $\ve3^\top f_\theta$ at snapshots (learned with VICReg)};

\node (fig11) at (-3, -1.25)  {
    \includegraphics[width=.2\linewidth]{figures/active_empty.pdf}
};

\node[right=0.2cm of fig11] (fig12)  {
    \includegraphics[width=.2\linewidth]{figures/passive_mixed.pdf}
};

\node[right=0.2cm of fig12] (fig13)  {
    \includegraphics[width=.2\linewidth]{figures/active_mixed.pdf}
};

\node[right=0.2cm of fig13] (fig14)  {
    \includegraphics[width=.2\linewidth]{figures/active_full.pdf}
};

\node[inner sep=0pt]  (title2) at (0,-2.5) {Optimal linear probe $w^\top f_\theta$ for downstream task};

\node (fig1) at (-3, -3.65)  {
    \includegraphics[width=.2\linewidth]{figures/learned_empty.pdf}
};

\node[right=0.2cm of fig1] (fig2)  {
    \includegraphics[width=.2\linewidth]{figures/learned_passive.pdf}
};

\node[right=0.2cm of fig2] (fig3)  {
    \includegraphics[width=.2\linewidth]{figures/learned_mixed.pdf}
};

\node[right=0.2cm of fig3] (fig4)  {
    \includegraphics[width=.2\linewidth]{figures/learned_full.pdf}
};


\node (main) at (0, -7) {\includegraphics{figures/active.pdf}};

\draw[<-, very thick, draw opacity=.5] (fig1.south) -- ([shift=({-2.15,3.65})]main.south); 
\draw[<-, very thick, draw opacity=.5] (fig2.south) -- ([shift=({-.95,2.35})]main.south); 
\draw[<-, very thick, draw opacity=.5] (fig3.south) -- ([shift=({-.95,1.7})]main.south); 
\draw[<-, very thick, draw opacity=.5] (fig4.south) -- ([shift=({3.22,1.25})]main.south); 

\draw[->, draw opacity=.25] ([shift=({0,.3})]fig11.south) -- ([shift=({0,-.1})]fig1.north); 
\draw[->, draw opacity=.25] ([shift=({0,.3})]fig12.south) -- ([shift=({0,-.1})]fig2.north); 
\draw[->, draw opacity=.25] ([shift=({0,.3})]fig13.south) -- ([shift=({0,-.1})]fig3.north); 
\draw[->, draw opacity=.25] ([shift=({0,.3})]fig14.south) -- ([shift=({0,-.1})]fig4.north); 

\end{tikzpicture}
    \caption{Comparison the active oracle of \cref{alg:active} and the passive supervised one of \cref{alg:passive}.
    Given $q$ queries made, and the consequent reconstructed graph $\mG_q$, we learn $f_{\theta_t}:\X\to\R^C$ by minimizing $\gL_{\rm VIC^2}$, and plot the downstream mean-square error of the optimal a linear classifier $w^\top f_{\theta_t}$ for the best $w\in \R^C$.
    Here $\X = \R^2$, and $y\in[4]$ spans four concentric circles (represented by the blue, red, green and orange classes), $N=100$, query batches are chosen of size 10 and results are average over 100 trials (standard deviations being represented by the colorized regions). 
    Snapshots at different points on the curve show the third coordinates of the reconstructed $f_{\theta_t}$, and the ideal linear classifier that can be learned based on this embedding.
    }
    \label{fig:active}
\end{figure}

\subsection{Active Oracles}
Seen through the eyes of PAL, supervised and SSL --which employ passive querying-- can be improved by refining the oracle to choose the next indices $I_t$ and $J_t$ to process at time $t$.

{\bf Low-Cost and Efficient Active Learning.}~%
A crucial point of this study is that the active learning framework stemming from PAL differs fundamentally from classic active learning.
In the latter, at time $t$, one asks for a fresh label $y_{i_t}$ for some chosen index $i_t$.
Instead, PAL considers a batch of data $I_t$ and asks for pairwise comparisons $\ind{y_i\sim y_j}$ for $(i, j) \in I$.
Rather than asking labelers for fine-grained labels, such as ``caracal'' or ``numbfish'' on ImageNet, PAL would rather asks labelers if two images are related, or even to spot outliers in a set of images compared to a template, as illustrated on \cref{fig:pal}.\footnote{This ``spot-the-outliers'' strategy is formalized with $I_t = \{(i_t, j)\,\vert\, j \in \tilde{I}_t\}$ for $i_t$ representing the class template, and $\tilde{I}_t$ capturing the batch of data to spot outliers in.}
This is particularly useful when the cost of spotting a few outliers in a batch of $M$ images is much less costly than annotating $M$ data points.
On such instances, Criteo engineers found that batches of 15 images was a sweet spot in terms of labeling efficiency \cite{criteo}; while ImageNet was annotated by querying images on search engines, and spotting outliers among the results \cite{ImageNet}.
Meanwhile, reCaptcha (illustrated on \cref{fig:pal}) is said to have helped annotate millions of images \cite{captcha}.
We refer the curious reader to \cite{Simard2017} and references therein regarding the design of efficient user interfaces for those labeling tasks.

{\bf Zoo of Active Learning Strategies.}~%
By introducing PAL, we open a way to match the practice of active learning and its theory through a grounded framework that encompasses current heuristics to annotate big chunks of data.
While the optimal oracle depends on the problem idiosyncrasies, as well as the labeling cost model, the vast literature body on active learning provides many heuristics to design sophisticated or intricate oracles under different structural assumptions.
One could query information based on the least certain predictions \cite{Hanneke2014,Ash2020}; based on the distance to the decision boundaries \cite{pruning2022}; by comparing predictions made by different methods in an ensemble \cite{Bilgic2010active,ensemble2021}; or by finding the queries whose answers are the most likely to modify the current guess for $f_\theta$ \cite{Yang2016active,Knuth1977,Karzand2020}.
Throughout reviews, adaptations to PAL, ablation studies and comparisons on different benchmarks of those strategies is left for future work.

{\bf PAL {\em \`a la} Captcha.}~%
A natural and easy property to leverage in order to build active learning strategies is the fact that the $N^2$-entry matrix $\mG$ is actually derived from the $NC$-entry matrix $\mY$.
In particular, one can recover the full graph $\mG = \mG^{(\sup)}$ with less than $NC$ pairwise queries, and in the best case only $N$ queries --compare this to the $N^2$-entries that are queried by the supervised learning oracle.
This idea is captured formally with the oracle described in \cref{alg:active}, where the matrix $\mQ$ remembered past queries, and illustrated on \cref{fig:active}.
At time $t$, this oracle chooses to query against the class with the least numbers of known instances, and choose $M$ data points, ask if they match this class, and update known labels as a consequence.
An advantage of the query strategy of \cref{alg:active} is that one can stop at any time $t$ and have a balanced labeled dataset to learn with.

\begin{algorithm}[ht]
    \KwData{Class templates $(\vmu_1, \cdots, \vmu_C) \in \X^C$, $\mQ \in \R_{N\times C}$ initialized at zero.}
    Choose the class with least known examples $j = \argmin_j {\bf 1}^\top \mQ_t \ve_j \in [C]$;\\
    Collect pairwise comparison $\mQ_{ij} \leftarrow \ind{\vx_i \sim \mu_j}$ for $i$ in a batch $B \subset [N] \setminus \mK_t$ where $\mK_t$ remove queries with known results based on $\mQ_t$;\\
    Sampler: $I_t = J_t$ all the new entries deduced in $\mG$.\\
    Labeler: Human feedback $\mQ_{ij}$; deduction to fill $\mG$.
    \caption{Oracle {\em \`a la} Captcha}
    \label{alg:active}
\end{algorithm}

The basic \cref{alg:active} can be improved in several ways.
First, class templates can be deduced based on initial queries: the first data point $\mu_1 = \vx_1$ provides a first class template; after querying $\ind{\vx_2\sim \vx_1}$ if the answer is negative, $\mu_2 = \vx_2$ provides a second class template (otherwise it is part of class one); so forth and so on (if $\ind{\vx = \mu_1} = \cdots = \ind{\vx=\mu_k} = 0$, set $\mu_{k+1} = \vx$).
Those templates could be refined during training by defining the templates as the example the most at the center of the classes examples with some well-thought notion of distance (either in the input space or the embedding space).
Second, when classes are unbalanced and class probabilities are roughly known, one should rather choose $y(t)$ to be the class that minimizes the number of known examples in this class divided by the probability of this class.
Third, if $C$ the number of classes is small, random sampling of the batch $B$ will work well enough.
Yet, when $C$ is big, random sampling will mainly lead to negative observations and too few positive ones.
In this situation, the algorithm is improved by training a classifier based on known labels at time $t$ (eventually incorporating unlabeled data with semi-supervised learning techniques), and querying labels that were classified as the same class.
Finally, to avoid only getting negative pairs on datasets with many classes, one could leverage hierarchy in the labels: if dealing with the classes of ImageNet, one can first ask reviewers coarse-grained information, e.g. flag pictures that are not fishes; before going deeper in the taxonomy.
