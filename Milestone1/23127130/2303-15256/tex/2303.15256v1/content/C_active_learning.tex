\section{Active Learning Algorithms}
\label{app:active}

{\bf NNCLR oracle.}~%
State-of-the-art the year of its release, \cite{dwibedi2021little} proposes a variation of SSL, that does not need human feedback but does update the similarity graph based on past observation.
This furnishes strong evidence for the usefulness of active learning algorithms, even without human feedback.
The NNCLR oracle consists in setting $I_t = J_t$ equals to some minibatch at time $t$, but to labels positive pairs in $\mG_{ij}$ only for nearest neighbors, i.e.
\[
    \mG^{(t)}_{ij} = \ind{\vz_i\in{\cal N}(\vz_j, I)} \triangleq \ind{ \norm{\vz_i - \vz_j} = \min_{j\in I_t} \norm{\vz_i - \vz_k}}.
\]
We describe the corresponding active oracle in \cref{alg:nnclr}.

\begin{algorithm}[ht]
    NNCLR oracle: \\
    \hspace{.3cm} Sampler: $I_t = J_t$ is some minibatch,\\
    \hspace{.3cm} Labeler: $\mG_{i,j} = \ind{\vz_i\in{\cal N}(\vz_j; I)}$ where ${\cal N}(\vz; I)$ design the nearest neighbor of $\vz$ in the batch $I$.
    \caption{Active Oracle with No Human Feedback as per \cite{dwibedi2021little}}
    \label{alg:nnclr}
\end{algorithm}

{\bf The New Rise of Active Learning.}~%
Recently, active learning has become a focus of the machine learning community when training big models, as those models performance are known to depend on the order they process data \cite{curriculum}, as well as in the percentage of data of different type they ingests \cite{llama}.
In particular, the best paper award at NeurIPS last year \cite{pruning2022} has suggested that the distance to the decision boundary could be leveraged smartly to reduce the number of data needed by current AI algorithms to train state of the art models (as compared to the scaling law of \cite{scaling2020}).
We describe their sampling oracle in \cref{alg:boundary}.
Note that in the original paper, they query the exact labels of the selected points, while PAL only needs to query pairwise comparison.
In the meantime, \cite{ensemble2021} suggested using ensemble active learning, while \cite{Ash2020} suggested a model based uncertain predictions through gradient computation in deep learning models.

\begin{algorithm}[ht] 
    Perform k-means clustering on $\mZ_t = f_{\theta_t}$.\\
    For each unlabeled points, compute cosine distance to its cluster center.\\
    \eIf{Few examples have been labels}{$I_t=J_t\leftarrow$ points near cluster centers,}{$I_t=J_t\leftarrow$ points far from cluster centers.}
    \caption{Active Oracle with Data Pruning as per \cite{pruning2022}}
    \label{alg:boundary}
\end{algorithm}

{\bf From Coarse to Fine-grained Query.}
While active learning usually assumes that the cost of answering any questions is constant, in practice, some queries might be easier to answer than others.
For example, if a child has never seen some objects, such as a sophisticated designer chair, they might not easily provide pairwise comparison regarding those objects, e.g. they would be puzzled by the designer chair, and would hesitate to say that this is a chair.
Similarly, it might be easier for human labelers to recognize attributes in an image, e.g. sandy fur, desert background, tufted ear, feline; rather than precise species, such as ``caracal''.
This has been the basis for weakly supervised learning \cite{Cour2011,Ratner2020}.
It has also motivated some bandit models, such as \cite{Cesa-Bianchi2006,Fiez2019}.
More generally, it suggests that one could efficiently learn by first querying weak, coarse-grained information, before refining queries to get precise, fine-grained feedback.
We illustrate this high-level idea with \cref{alg:hierarchical}.

\begin{algorithm}[ht]
    Samplers: Your favorite active learning sampler.\\
    \eIf{$f_{\theta_t}$ has not formed strong opinions on clusters}{Labelers: Human feedback for coarse-grained information (e.g. click on all animals with fur...),}{Labelers: Human feedback with fine-grained information (e.g. click on fishes that match a precise species).}
    \caption{Active Oracle with Hierarchical Taxonomy}
    \label{alg:hierarchical}
\end{algorithm}
