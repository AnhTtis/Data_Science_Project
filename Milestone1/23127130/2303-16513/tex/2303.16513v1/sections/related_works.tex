\section{Related Work}
\label{sec::related_works}

\paragraph{Implicit neural representation.}
Implicit neural representation is a technique for representing continuous-domain signals via coordinate-based multi-layer perceptrons (MLPs). Its concept has been adopted in various 3D tasks,~\eg, 3D object shape modeling~\cite{chen2019, deepsdf, mescheder2019, genova2020, sal}, 3D scene reconstruction~\cite{srn, jiang2020, chabra2020, peng2020}, and 3D structure rendering~\cite{nerf, niemeyer2020, nsvf, mipnerf}.  For example, NeRF~\cite{nerf} employs implicit neural representation to perform novel view synthesis, which maps coordinates to RGB colors for a specific scene. In the past few years, 2D applications of implicit neural representation have been attempted as well, such as image representation~\cite{klocek2019, siren} and super-resolution~\cite{liif, ultrasr, ipe, lte, itsrn}. Our work is related to a technique called `\textit{local implicit neural representation}'~\cite{liif, lte}, which encodes LR images to feature embeddings such that similar information could be shared within local regions. Such local implicit neural representations are exploited to upscale LR images to HR ones.

\paragraph{Single image super-resolution.}
In the past several years, various deep neural network (DNN) based architectures~\cite{srcnn, vdsr, fsrcnn, espcn, lapsrn, srresnet, edsr, esrgan, rdn, rcan, san, csnl, ipt, swinir, hat} have been proposed for SISR. Among these works, SRCNN~\cite{srcnn} pioneered the use of convolutional neural networks (CNNs) to achieve SISR in an end-to-end manner. It is later followed by several subsequent works that incorporated more complicated model architectures, such as residual blocks~\cite{edsr, srresnet}, dense connections~\cite{rdn, esrgan}, attention based mechanisms~\cite{rcan, san, csnl}, or cascaded frameworks~\cite{lapsrn, csrip, cdpn}, to extract more effective feature representations for SISR. Recently, transformer-based methods~\cite{ipt, swinir, hat} were introduced to SISR and achieved promising performance.

\paragraph{Arbitrary-scale super-resolution.}
As discussed in Section~\ref{sec::introduction}, most of the contemporary SISR works limit their upsampling scales to specific integer values, and are required to train a distinct model for each upsampling scale. To overcome such a limitation, several approaches~\cite{metasr, liif, ultrasr, ipe, itsrn, lte} were proposed to train a unified model for arbitrary upsampling scales. Meta-SR~\cite{metasr} proposed a meta-upscale module for predicting the weights of their convolutional filters from coordinates and scales. The predicted weights are then utilized to perform convolutions to generate HR images. In contrast to Meta-SR, LIIF~\cite{liif} employs an MLP as a local implicit function, which takes a queried coordinate in an HR image, its nearby feature representations extracted from the corresponding LR image, as well as a cell size to predict an RGB value for that coordinate. UltraSR~\cite{ultrasr} and IPE~\cite{ipe} extended LIIF by replacing coordinates with the embedded ones to deal with the spectral bias issue~\cite{nerf, rahaman2019, basri2020, siren, tancik2021} inherent in MLPs. LTE~\cite{lte} further introduced a local texture estimator that transforms coordinates into Fourier domain information to enrich the representational capability of its local implicit function. Different from the above approaches, our proposed methodology exploits a novel local attention mechanism and a cascaded framework to deal with the arbitrary-scale SR. In order to fairly compare with the above approaches, we similarly adopt EDSR~\cite{edsr}, RDN~\cite{rdn} and SwinIR~\cite{swinir} as the encoders for our LIT and CLIT.
