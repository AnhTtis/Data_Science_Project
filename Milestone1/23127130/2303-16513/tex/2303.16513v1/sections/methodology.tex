\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{figures/architecture.pdf}
    \caption{The proposed LIT framework. The local sampling operation samples input embeddings based on a grid of coordinates.}
    \label{fig:architecture}
\end{figure*}

\section{Methodology}
\label{sec::methodology}
In this section, we first provide an overview of the proposed LIT framework, followed by the implementation details of it and its main modules.We then discuss our cumulative training strategy, as well as the framework of CLIT. 

\subsection{Overview of the LIT Framework}
\label{subsec::overview}
LIT is a framework that employs a novel cross-scaled local attention mechanism and a local frequency encoding technique to perform arbitrary-scale SR tasks. Fig.~\ref{fig:architecture}~(a) provides an overview of the proposed framework, which aims at producing an HR image $I^{HR} \in \mathbb{R}^{r_{h}H \times r_{w}W \times 3}$ at 2D HR coordinates $\mathbf{x}^{HR} \in \mathcal{X}$ from a given LR image $I^{LR} \in \mathbb{R}^{H \times W \times 3}$ at 2D LR coordinates $\mathbf{x}^{LR} \in \mathcal{X}$ based on an arbitrary upsampling scale $\mathbf{r} = \left \{r_{h}, r_{w} \right \}$, where $\mathcal{X}$ is the 2D coordinate space that is used to represent an image in the continuous domain. An encoder $E_{\theta}$ first extracts a feature embedding $\mathcal{Z} \in \mathbb{R}^{H \times W \times C}$ from $I^{LR}$.  The extracted $\mathcal{Z}$ is then forwarded into LIT along with the 2D coordinates of $I^{HR}$ and a cell = $(2/s_{h}, 2/s_{w})$ to generate the RGB values of a residual image $I^{HR}_{r} \in \mathbb{R}^{r_{h}H \times r_{w}W \times 3}$ in a pixel-wise fashion. Lastly, the residual image $I^{HR}_{r}$ is combined with a bilinearly upsampled image $I^{HR}_{\uparrow}\in \mathbb{R}^{r_{h}H \times r_{w}W \times 3}$ via element-wise addition to derive the final HR image $I^{HR}$. 

\subsection{Local Implicit Transformer}
\label{subsec::lit}
LIT is developed for mapping any 2D coordinate in the continuous image domain to an RGB color. As highlighted in Fig.~\ref{fig:architecture}~(b), it is composed of a cross-scale local attention block (CSLAB) and a decoder $D_{\phi}$ paraterizerized by $\phi$. CSLAB is responsible for estimating a local latent embedding $\tilde{z} \in \mathbb{R}^{G_{h}G_{w} \times C}$, where $G_{h}$ and $G_{w}$ denote the height and width of local grids employed for performing local coordinate sampling, as depicted in Fig.~\ref{fig:local_coord}. On the other hand, $D_{\phi}$ utilizes these embeddings along with the provided cell to generate $I^{HR}_{r}$. More specifically, LIT first projects $\mathcal{Z}$ using four separate convolutional layers to obtain three latent embeddings, corresponding to query $q$, key $k$, and value $v$. Based on a queried HR coordinate $x_{q} \in \mathbf{x}^{HR}$, CSLAB estimate $\tilde{z}$ as follows:
\begin{equation}
    \tilde{z} = CSLAB(\delta x, q, k, v), 
\label{equation1}
\end{equation}
\begin{equation}
    \delta \mathbf{x} =  \left \{x_{q} - x^{(i, j)} \right \}_{i \in \left \{1, 2, ..., G_{h}\right \}, j \in \left \{1, 2, ..., G_{w}\right \}}, 
\label{equation3}
\end{equation}
where $x^{(i, j)} \in \mathbf{x}^{LR}$ denotes an LR coordinate in the local grid indexed by $(i, j)$, and $\delta \mathbf{x}$ represents the set of local relative coordinates defined by Eq.~(\ref{equation3}). The local grid is sampled in a manner that positions its center $x^{(\left \lfloor G_{h}/2 \right \rfloor +1, \left \lfloor G_{w}/2 \right \rfloor +1)}$ at the LR coordinate closest to $x_{q}$. The query latent vector $q \in \mathbb{R}^{1 \times C}$ at the HR coordinate $x_{q}$ is computed by bilinear interpolation, while the remainder of the local latent embeddings $k \in \mathbb{R}^{G_{h}G_{w} \times C}$ and $v \in \mathbb{R}^{G_{h}G_{w} \times C}$ are sampled at the local LR coordinates $\mathbf{x} = \{x^{i,j}\}_{i \in \left \{1, 2, ..., G_{h}\right \}, j \in \left \{1, 2, ..., G_{w}\right \}}$. With the local latent embedding $\tilde{z}$, the function of $D_{\phi}$ is formulated as follows:
\begin{equation}
    I^{r}(x_{q}) =  D_{\phi}(\tilde{z}, c),
\label{equation4}
\end{equation}
where $I^r(x_{q})$ is the predicted RGB value at the queried coordinate $x_{q}$, and $c = \{HR_{\Delta h}, HR_{\Delta w}\}$ denotes the cell that represents the height and width of a pixel in an HR image, as illustrated in Fig.~\ref{fig:local_coord}. $D_{\phi}$ is implemented as a five-layer MLP utilizing Gaussian Error Linear Unit (GELU) activation~\cite{gelu}, and is employed consistently across all images.

\paragraph{Cross-scale local attention block.}
LIT exploits CSLAB to perform a local attention mechanism over a local grid to generate a local latent embedding $\tilde{z}$ for each HR coordinate, as illustrated in Fig.~\ref{fig:architecture}~(c). CSLAB first calculates the inner product of $q$ and $k$, adds the relative positional bias $B$ to the result, and obtains an attention matrix. This attention matrix is subsequently normalized by a Softmax operation to produce a local attention map. Finally, CSLAB performs element-wise multiplication of $v$ and the local attention map to derive $\tilde{z}$. The overall procedure is formulated as follows:
\begin{equation}
    \tilde{z} =  softmax(\frac{qk^{\top}}{\sqrt{C}} + B) \times v ,
\label{equation5}
\end{equation}
\begin{equation}
    B =  FC(\gamma (\delta \mathbf{x})) ,
\label{equation6}
\end{equation}
\begin{equation}
\begin{aligned}
    \gamma(\delta \mathbf{x}) &= [\sin{(2^{0} \delta \mathbf{x})}, \cos{(2^{0} \delta \mathbf{x})}, ... \\
    & ,\sin{(2^{L-1} \delta \mathbf{x})}, \cos{(2^{L-1}  \delta \mathbf{x})}],
\end{aligned}
\label{equation7}
\end{equation}
where $C$ denotes the channel dimension of the local key latent embedding $k$, $FC$ represents a fully-connected layer, $\gamma$ is the positional encoding function, and $L$ is a hyperparameter. In this work, $L$ is set to $10$, and the multi-head attention mechanism adopted is formulated in Eq.~(\ref{equation8}) as follows:
\begin{equation}
    \tilde{z} =  concat(softmax(\frac{q_{i}k_{i}^{\top}}{\sqrt{C/H}} + B_{i}) \times v_{i}) ,
\label{equation8}
\end{equation}
where $H$ is the number of attention heads and $i \in [1,..., H]$.

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{figures/local_coord.pdf}
    \caption{An illustration of the proposed local coordinate sampling scheme. The \textcolor{red}{red} rectangular region, outlined by a dashed line, represents the local grid with dimensions $G_{h} \times G_{w}$. The \textcolor{red}{red dots} indicate the sampled local LR coordinates, while the \textcolor{gray}{gray dots} correspond to the HR coordinates. The grid dimensions $LR_{\Delta_{h, w}}$ and $HR_{\Delta_{h, w}}$ represent the unit sizes of pixels in LR and HR images, respectively.}
    \label{fig:local_coord}
\end{figure}

\subsection{Cumulative Training Strategy}
\label{subsec::cumulative_training_strategy}
In this section, we discuss our proposed  cumulative training strategy, which is developed for enhancing the performance of arbitrary-scale SR.  The cumulative training strategy focuses on the schedule of the cell sizes selected during the training phase, as ``cell decoding" has been recognized as an essential input to a local implicit image function~\cite{liif}. Recent studies~\cite{liif,ipe} have observed that the effect of cell decoding on the performance of arbitrary-scale SR is prominent for in-distribution upsampling, but degrades significantly for out-of-distribution large-scale upsampling. Such trends are demonstrated in Table~3 of~\cite{liif} and Table~4 of~\cite{ipe}. 
The authors in~\cite{lte} also constrained their cell sizes to in-distribution ranges to mitigate the negative impact during evaluation. To overcome the degradation issue for out-of-distribution cell sizes, incorporating large cell sizes during training appears to be a promising solution. However, simply training the local implicit image function with a diverse range of cell sizes at once leads to a performance drop. According to our experimental observations presented in Section~\ref{subsec::ablation_studies}, we find that training the local implicit image function by alternatively switching between large and small cells offers positive impacts on the performance. Based on the above observations, we propose a cumulative training strategy which first trains the local implicit image function with large cell sizes, and finetunes it with the alternative training strategy to improve the performance on different upsampling scales. More quantitative results of our training strategies can be found in Section~\ref{subsec::ablation_studies}.

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{figures/clit.pdf}
    \caption{An overview of the proposed CLIT framework.}
    \label{fig:cascaded_lit}
\end{figure}

\input{tables/div2k_results.tex}

\subsection{Cascaded Local Implicit Transformer}
\label{subsec::clit}
Previous works~\cite{liif, lte} typically address arbitrary-scale SR through a single step of upsampling. 
However, one-step upsampling struggles to reconstruct an HR image when the upsampling scale is large~\cite{lapsrn, csrip, cdpn}. In light of this, we propose a cascaded upsampling strategy, called ``\textit{Cascaded LIT (CLIT)}" to predict residual images from multi-scale feature embeddings. In an $N$-branched CLIT, the multi-scale feature embeddings $\mathcal{Z}^{1}, \mathcal{Z}^{2}, ..., \mathcal{Z}^{N}$ are derived as follows:
\begin{equation}
\begin{aligned}
    &\mathcal{Z}^{N} = \mathcal{Z}\uparrow_{s^{1} \times s^{2} \times ... \times s^{N-1}}, \\
    &\mbox{where } s^{1} = 1 \mbox{ and } s \in \mathbf{s},
\label{equation9}
\end{aligned}
\end{equation}
where $\uparrow$ is a bilinear upsampling function and $\mathbf{s}$ is a set of scaling factors, which are configurable hypermeters. For a branch $i, i\in[1,...,N]$, LIT$^{i}$ estimates the residual image $I^{i}_{r}$ from the feature embedding $\mathcal{Z}^{i}$ with the coordinate and the corresponding cells. Lastly, the final HR image $I^{HR}\in \mathbb{R}^{r_{h}H \times r_{w}W \times 3}$ can be estimated as the following equation:
\begin{equation}
    I^{HR} =  \lambda^{N-1} I^{1}_{r} + \lambda^{N-2} I^{2}_{r} + ... + \lambda^{0} I^{N}_{r} + I^{HR}_{\uparrow}.
\label{equation10}
\end{equation}
where $\lambda$ is a discount factor, with a default value of $0.75$. During the training phase, CLIT is trained using the proposed cumulative training strategy.  Initially, LIT$^{1}$ is trained with the strategy employed by~\cite{liif}. Subsequently, LIT$^{1}$ is fine-tuned and LIT$^{2}$ is initialized by applying the alternative training strategy. By incrementally incorporating LITs into CLIT, the performance is progressively enhanced. The details of the training strategies are specified in Section~\ref{sec::experimentas}.

