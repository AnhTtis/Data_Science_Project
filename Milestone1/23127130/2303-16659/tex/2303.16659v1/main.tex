\documentclass[twocolumn]{autart}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{cuted}
\usepackage[hyphens]{url}
\usepackage{booktabs}
\usepackage{graphicx}  
\usepackage{subfigure}
\usepackage{xcolor}
\usepackage{subfloat}
\usepackage{placeins}

\allowdisplaybreaks[4]

%\usepackage{cite}
%\usepackage[sorting=none,firstinits=true]{biblatex}
%\usepackage[colorlinks=true,linkcolor=blue,allcolors=blue]{hyperref}

\algrenewcommand\algorithmicrequire{\textbf{Input:}}
\algrenewcommand\algorithmicensure{\textbf{Output:}}
\algrenewcommand\algorithmicforall{\textbf{For}}
%\renewcommand*{\bibfont}{\normalfont\small}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{property}{Property}
\newtheorem{definition}{Definition} 
\newtheorem{remark}{Remark}
\newtheorem{standing}{Standing Assumption}
\newtheorem{assumption}{Assumption}
\setcounter{assumption}{0}
\newtheorem{example}{Example}


\begin{document}
\begin{frontmatter}

\title{Safe Zeroth-Order Optimization Using Quadratic Local Approximations} 

\author[DECODE]{Baiwei Guo}\ead{baiwei.guo@epfl.ch},    % Add the 
\author[Predict]{Yuning Jiang}\ead{yuning.jiang@epfl.ch},    
\author[DECODE]{Giancarlo Ferrari-Trecate}\ead{giancarlo.ferraritrecate@epfl.ch},
\author[Sycamore]{Maryam Kamgarpour}\ead{maryam.kamgarpour@epfl.ch}
\address[DECODE]{DECODE group, Institute of Mechanical Engineering, EPFL, Switzerland} 
\address[Predict]{PREDICT group, Institute of Mechanical Engineering, EPFL, Switzerland}
\address[Sycamore]{SYCAMORE group, Institute of Mechanical Engineering, EPFL, Switzerland}
% full addresses

          
\begin{keyword}                           % Five to ten keywords,  
Zeroth-order optimization; Safe controller tuning.               % chosen from the IFAC 
\end{keyword}                             % 
\begin{abstract}                          % Abstract of not more than 200 words.
This paper addresses black-box smooth optimization problems, where the objective and constraint functions are not explicitly known but can be queried. The main goal of this work is to generate a sequence of feasible points converging towards a KKT primal-dual pair. Assuming to have prior knowledge on the smoothness of the unknown objective and constraints, we propose a novel zeroth-order method that iteratively computes quadratic approximations of the constraint functions, constructs local feasible sets and optimizes over them. Under some mild assumptions, we prove that this method returns an $\eta$-KKT pair (a property reflecting how close a primal-dual pair is to the exact KKT condition) within $O({1}/{\eta^{2}})$ iterations. Moreover, we numerically show that our method can achieve faster convergence compared with some state-of-the-art zeroth-order approaches. The effectiveness of the proposed approach is also illustrated by applying it to nonconvex optimization problems in optimal control and power system operation.
\end{abstract}

\end{frontmatter}

\section{Introduction}
\label{sec: introduction}
%% opening remark
Applications ranging from power network operations \cite{chu2021frequency}, machine learning \cite{chen2020DFO} and trajectory optimization \cite{manchester2016derivative} to optimal control~\cite{rao1998application,xu2022vabo} require solving complex optimization problems where feasibility (i.e., the fulfillment of the hard constraints) is essential. However, in practice, we do not always have access to the expressions of the objective and constraint functions or sufficient data of feasible system trajectories for modelling. 

To address an unmodeled constrained optimization, in this paper we develop a safe zeroth-order optimization method. Zeroth-order methods rely only on sampling (i.e., evaluating the unknown objective and constraint functions at a set of chosen points) \cite{Bajaj2021}. Safety, herein referring to feasibility of the samples, is essential in several real-world problems, e.g., medical applications \cite{yousefi2017formally}  and racing car control \cite{hewing2019cautious}. Below, we review the pertinent literature on zeroth-order optimization, highlighting specifically safe zeroth-order methods. 

%% literature review
Classical techniques for zeroth-order optimization can be classified as direct-search-based (where a set of points around the current point is searched for a lower value of the objective function), gradient-descent-based (where the gradients are estimated based on samples) and model-based (where a local model of the objective function around the current point is built and used for local optimization)~\cite[Chapter~9]{jorge2006numerical}. Examples of these three categories for unconstrained optimization are, respectively, pattern search methods \cite{lewis2000pattern}, randomized stochastic gradient-free methods \cite{ghadimi2013stochastic} and trust region methods \cite{conn2000trust}. Pattern search methods are extended in \cite{lewis2002globally} to solve optimization problems with known constraints and an unmodelled objective. 

In case the explicit formulations of both objective and constraint functions are not available, the work \cite{usmanova2019safe} proposes a variant of the Frank-Wolfe algorithm, which enjoys sample feasibility and convergence towards a neighborhood of the optimal point with high probability. However, this method only addresses convex objectives and polytopic constraints. When the unmodelled constraints are nonlinear, one can use two-phase methods \cite{echebest2017inexact,bajaj2018trust} where an optimization phase reduces the objective function subject to relaxed constraints and a restoration phase modifies the result of the first phase to regain feasibility. A drawback of these approaches is the lack of guarantee for sample feasibility.

For sample feasibility, the zeroth-order methods of \cite{sui2015safe,turchetta2019safe,sabug2022smgo}, including SafeOPT and its variants, assume the knowledge of a Lipschitz constant of the objective and constraint functions, while \cite{vinod2022constrained} utilizes the Lipschitz constants of the gradients of these functions (the smoothness constants). With these quantities, one can build local proxies for the constraint functions and provide a confidence interval for the true function values. By starting from a feasible point, \cite{sui2015safe,sabug2022smgo,vinod2022constrained} utilize the proxies to search for potential minimizers. However, for each search, one may have to use a global optimization method to solve a non-convex problem, which makes the algorithm computationally intractable if there are many decision variables.

Another research direction aimed at feasibility of the samples is to include barrier functions in the objective to penalize the proximity to the boundary of the feasible set \cite{lewis2002globally,audet2009progressive}. By adopting log barrier functions, extremum seeking methods estimate the gradient of the new objective function by adding sinusoidal perturbations to the decision variables~\cite{arnold2015model}. However, due to the perturbations, these methods have to adopt a sufficiently large penalty coefficient to ensure all the samples fall in the feasible region. This strategy sacrifices optimality, since deriving a near-optimal solution requires a small penalty coefficient.  In contrast, the 0-LBM algorithm proposed in~\cite{usmanova2019log} ensures feasibility of the samples despite a small penalty coefficient. After calculating a descent direction for the cost function with log-barrier penalties, this method exploits the Lipshcitz and smoothness constants of the constraint functions to build local safe sets for selecting the step size of the descent. Although 0-LBM comes with a worst-case complexity that is polynomial in problem dimension, it might converge slowly, {\color{black}even for convex problems}. The reason is that as the iterates approach the boundary of the feasible set, the log-barrier function and its derivative become very large, leading to very conservative local feasible sets and slow progress of the iterates. 

Zeroth-order optimization methods can be used to solve optimal control problems in the presence of unknown dynamics, considering that system identification might be hard to do especially when the order of the ground-truth model is unknown or sufficient excitation required for modelling might lead to infeasibility. However, the performance of the existing zeroth-order methods are not satisfactory due to the lack of guarantees for sample feasibility or the high sampling and computation complexities. For example, \cite{qin2022sablas} learns Control Barrier Functions to tune a parameterized policy for robot trajectory planning. Although the final policy guarantees collision avoidance, crashes might happen during the training phase. Other examples include \cite{xu2022vabo} which proposes Violation-Aware Bayesian Optimization to optimize three set points of a vapor compression system, \cite{berkenkamp2016safe} which utilizes SafeOPT to tune a linear control law with two parameters for quadrotors and \cite{konig2021safe} which implements the Goal Oriented Safe Exploration algorithm in \cite{turchetta2019safe} to optimize a PID controller with three parameters for a rotational axis drive. Although these methods offer guarantees on sample feasibility, they scale poorly to high-dimensional systems due to the non-convexity of the subproblems and the need of numerous samples.


\textit{Contributions:} In this work, we  develop a zeroth-order method with guarantees of sample feasibility for smooth optimization problems by using quadratic local proxies based on Lipschitz and smoothness constants of the objective and constraint functions. Preliminary results, presented in \cite{guo2022safe}, focused on convex optimization. There, we built local feasible sets based on quadratic proxies of the objective and constraint functions, and proposed an algorithm that sequentially solves convex Quadratically Constrained Quadratic Programming (QCQP) subproblems. We showed that all the samples are feasible and one accumulation point of the iterates is the minimizer. This paper significantly extends \cite{guo2022safe} in the following aspects:

\begin{enumerate}
\item we show in Section \ref{sec: convergence of x_K} that, under mild assumptions, our safe zeroth-order algorithm has iterates whose accumulation points are KKT pairs even for \textbf{non-convex} problems;
\item given $\eta>0$, we add \textbf{termination conditions} to the zeroth-order algorithm and guarantee in Section \ref{sec: eta-KKT} that the returned primal-dual pair is an \textbf{$\eta$-KKT} pair (see Definition \ref{def: KKT}) of the optimization problem. We further show in Section \ref{sec: complexity_analysis} that under mild assumptions our algorithm terminates in $O(\frac{1}{\eta^2})$ iterations and requires $O(\frac{1}{\eta^2})$ samples.
\item we present in Section \ref{sec: experiments} a numerical example demonstrating that our algorithm achieves faster convergence than state-of-the-art methods. We further apply the algorithm to optimal control and optimal power flow problems, showing the results returned by our algorithm are almost identical to those provided by commercial solvers utilizing the true model.
\end{enumerate}


\textit{Notations:}
We use $e_i\in\mathbb R^d$ to define the $i$-th standard basis of vector space $\mathbb{R}^d$ and $\|\cdot\|$ to denote the two norm throughout the paper. Given a vector $x\in \mathbb{R}^d$ and a scalar $\epsilon>0$, we write $x = [x^{(1)}, \ldots, x^{(d)}]^\top$, $\mathcal B_\epsilon(x)=\{y:\|y-x\|\leq \epsilon\}$ and $\mathcal{SP}_\epsilon(x)=\{y:\|y-x\|= \epsilon\}$. We use $\mathbb{Z}_i^j=\{i,i+1,\ldots,j\}$ to define the set of integers ranging from $i$ to $j$ with $i<j$. 

\section{Problem Formulation}
\label{sec::Prob}
We address the constrained optimization problem
\begin{equation}
\label{eq: optimization problem}
\min_{x\in \mathbb{R}^d}  \;\; f_0(x)\quad \text{subject to}\;\;
x\in \Omega,
\end{equation}
where $\Omega:=\{x\in \mathbb{R}^d: f_i(x)\leq 0, i\in\mathbb Z_1^m\}$ is the feasible set.
We consider the setting where the continuously differentiable functions $f_i:\mathbb R^d\to\mathbb R$, are not explicitly known but can be queried. In this paper, we aim to derive a local optimization algorithm that for any given $\eta>0$ returns an $\eta$-approximate KKT pair of \eqref{eq: optimization problem} defined as follows.
\begin{definition}[\cite{dutta2013approximate}]
\label{def: KKT}
For $\eta>0$, a pair $(x,\lambda)$ with $x\in \Omega$ and $\lambda\in \mathbb{R}^m_{\geq 0}$ is an $\eta$-approximate KKT ($\eta$-KKT for short) pair of the problem \eqref{eq: optimization problem} if 
\begin{subequations}
\label{eq:kkt}
\begin{align}
\|\nabla f_0(x) + \sum^m_{i=1}\lambda^{(i)}\nabla f_i(x)\| &\leq \eta,\\
|\lambda^{(i)}f_i(x)| &\leq \eta,\quad i\in \mathbb{Z}^{m}_{1}.
\end{align}
\end{subequations}
If $(x^*,\lambda^*)\in \Omega\times \mathbb{R}^m_{\geq 0}$ fulfills~\eqref{eq:kkt} with $\eta = 0$, we say that it is a KKT pair.
\end{definition}
For any optimization problem with differentiable objective and
constraint functions for which strong duality holds, any pair of primal and dual optimal points must be a KKT pair. If the optimization problem is furthermore convex, any KKT pair satisfies primal and dual optimality \cite{boyd2004convex}. The optimization methods that aim to obtain a KKT pair, such as Newton-Raphson and interior point methods, might converge to a local optimum. Despite this drawback, these local methods are extensively applied, because local algorithms are more efficient to implement and KKT pairs are good enough for some applications, such as machine learning \cite{jain2017non}, optimal control \cite{rawlings2017model} and optimal power flow \cite{kundur2022power}. Considering that, in general, numerical solvers cannot return an exact KKT pair, the concept of $\eta$-KKT pair indicates how close primal and dual solutions are to a KKT pair \cite{dutta2013approximate}. In many numerical optimization methods \cite{grapiglia2022tensor,dussault2020approximate}, one can trade off accuracy against efficiency by tuning $\eta$.

We assume, without loss of generality, the objective function $f_0(x)$ is explicitly known and linear. Indeed, when the function $f_0(x)$ in \eqref{eq: optimization problem} is not known but can be queried, the problem in \eqref{eq: optimization problem} can be written as 
\begin{align*}
\min_{(x,\gamma)\in \mathbb{R}^{d+1}
} \quad & \gamma\\
\mathrm{subject\;to}  \quad & f_0(x)-\gamma\leq 0,\\
& f_i(x)\leq 0, \quad i \in\mathbb Z_1^m,
\end{align*}
where the objective function is now known and linear. 
Throughout this paper, we make the following assumptions on the smoothness of the objective and constraint functions and the availability of a strictly feasible point.
\begin{assumption}
\label{ass: smoothness}
The functions $f_i(x)$, $i\in\mathbb Z_0^m$ are continuously differentiable and we know constants $L_i,M_i>0$ such that for any $x_1$, $x_2\in \mathbb{R}^d$,
\begin{subequations}
\label{eq: smoothness}
\begin{align}
\label{eq: smoothness_1}
|f_i(x_1)-f_i(x_2)|&\leq L_i\|x_1-x_2\|,\\
\label{eq: smoothness_2}
\|\nabla f_i(x_1)-\nabla f_i(x_2)\|&\leq M_i\|x_1-x_2\|.
\end{align}
\end{subequations}
We also assume that the known Lipschitz and smoothness constants ${L}_i$ and ${M}_i$ verify that 
\begin{equation}
\label{eq: LANDM}
{L}_i>L_{i,\mathrm{inf}} \text{ and }{M}_i> M_{i,\mathrm{inf}},
\end{equation}
where \begin{align*}
L_{i,\mathrm{inf}}:=&\inf\{L_i: \text{ }\eqref{eq: smoothness_1} \text{ holds},\forall x_1,x_2\in \Omega\},\\
M_{i,\mathrm{inf}}:=&\inf\{M_i: \text{ }\eqref{eq: smoothness_2} \text{ holds},\forall x_1,x_2\in \Omega\}.
\end{align*}
\end{assumption}
In the remainders of this paper, we also define $L_{\max} = \max_{i\geq 1}L_i$ and  $M_{\max} = \max_{i\geq 1}M_i$.
\begin{remark}
The bounds in \eqref{eq: smoothness} are utilized in several works on zeroth-order optimization, e.g., \cite{wibisono2012finite,conn2009introduction}. As it will be clear in the sequel, these bounds allow one to estimate the error of local approximations of the unknown functions and their derivatives. In practice, it is usually impossible to obtain $L_{i,\mathrm{inf}}$ and $M
_{i,\mathrm{inf}}$, thus we only assume to know the upperbounds ${L}_i>L_{i,\mathrm{inf}}$ and ${M}_i> M_{i,\mathrm{inf}}$. In case ${L}_i$ and ${M}_i$ are not known, we regard them as hyperparameters and describe how to tune them in Remark \ref{rmk: LM}.
%We will discuss approaches to selection of $L_i$ and $M_i$ in Remark \ref{rmk: LM}.
\end{remark}
\begin{assumption}
\label{ass: strict feasible}
There exists a known strictly feasible point $x_0$, i.e., $f_i(x_0)<0$ for all $i\in\mathbb Z_1^m$. 
\end{assumption}
\begin{remark}
The existence of a strictly feasible point is called Slater's Condition and commonly assumed in several optimization methods \cite{boyd2004convex}. Moreover, several works on safe learning \cite{sui2015safe,usmanova2019log} assume a strictly feasible point used for initializing the algorithm. Assumption \ref{ass: strict feasible} is necessary for designing an algorithm whose iterates remain feasible since the constraint functions are unknown a priori. Practically, it holds in several applications. For example, in any robot mission planning,  the robot is placed initially at a safe point and needs to gradually explore the neighboring regions while ensuring feasibility of its trajectory. Similarly, in the optimization of manufacturing processes, often an initial set of (suboptimal) design parameters satisfying the problem constraints are known \cite{rupenyan2021performance}. Another example is frequency control of power grids, where the initial frequency is guaranteed to lie within certain bounds by suitably regulating the power reserves and loads \cite{kundur2022power}. 
\end{remark}
\begin{assumption}
\label{ass: bounded_sublevel}
There exists $\beta\in \mathbb{R}$ such that the sublevel set $\mathcal{P}_\beta=\{x\in \Omega:f_0(x)\leq \beta\}$ is bounded and includes the initial feasible point $x_0$.
\end{assumption}
Under Assumption \ref{ass: bounded_sublevel}, for any iterative algorithm producing non-increasing objective function values $\{f_0(x_k)\}_{k\geq 0}$, we ensure the iterates $\{x_{k}\}_{k\geq 0}$ to be within the bounded set $\mathcal{P}_\beta$.

We highlight that Assumptions 1-3 stand \textit{throughout this paper}. By exploiting them, we design in the following section an algorithm that iteratively optimizes $f_0(x)$. 

\section{The Proposed Zeroth-Order Algorithm}
\label{sec: algorithm_tot}
Before stating the iterative algorithm, this section proposes an approach to construct local feasible sets by using samples around a given strictly feasible point. To do so, we recall properties of a gradient estimator constructed through finite differences.

The gradients of the unknown functions $\{f_i\}_{i=1}^m$ can be approximated as  
\begin{equation}
\label{eq: gradient approximation}
{\nabla}^\nu f_i\left(x\right):=\sum_{j=1}^{d} \frac{f_i\left(x+\nu e_{j}\right)-f_i\left(x\right)}{\nu} e_{j}
\end{equation}
where $\nu>0$. From Assumption \ref{ass: smoothness}, we have the following result about the estimation error
$$\Delta^\nu_i(x):={\nabla}^\nu f_i\left(x\right)-\nabla f_i(x).$$
\begin{lemma}[\cite{berahas2021theoretical}, Theorem 3.2]
\label{lmm: gradient estimation error}
Under Assumption \ref{ass: smoothness}, we have
\begin{equation}
\left\|\Delta^\nu_i(x)\right\|_{2} \leq \alpha_i \nu, \text{ with } \alpha_i = \frac{\sqrt{d}  M_i}{2}.
\label{eq: gradient approximation error}
\end{equation}
\end{lemma}

\subsection{Local feasible set construction}
\label{sec: Safesetconstruction}
Based on \eqref{eq: gradient approximation} and \eqref{eq: gradient approximation error}, we build a local feasible set around a strictly feasible point $x_0$ as follows. 
\begin{theorem}
\label{thm: safesetconstruction}
For any strictly feasible point $x_0$, let 
\begin{equation}
\label{eq: l_0}
l_0^* = \min_{i\in\{1, \dots, m\}}\;-f_i(x_0)/L_{\mathrm{max}}, 
\end{equation}
and $\nu_0^* = l_0^*/\sqrt{d}$, where $L_{\mathrm{max}} = \max_{i\geq 1}L_i$. Define 
\begin{equation}
\label{eq:safe_set}
\begin{aligned}
\mathcal{S}^{(0)}_i(x_0) :=&\big\{x: f_i(x_0)+{\nabla}^{\nu_0^*} f_i\left(x_0\right)^\top(x-x_0)+\\
&\qquad\qquad\qquad\qquad 2M_i\|x-x_0\|^2\leq 0 \big\}.  
\end{aligned}
\end{equation}
Under Assumption \ref{ass: smoothness}, all the samples needed for computing ${\nabla}^{\nu_0^*} f_i\left(x_0\right)$ are feasible and the set $\mathcal{S}^{(0)}(x_0):=\bigcap^m_{i=1}\mathcal{S}^{(0)}_i(x_0)$  satisfies $\mathcal{S}^{(0)}(x_0) \subset \Omega$.
\end{theorem}

The proof of Theorem \ref{thm: safesetconstruction} is in Appendix \ref{sec: proofofsafeset}. By construction, we see that if $x_0$ is strictly feasible, then $x_0$ belongs to the interior of $\mathcal{S}^{(0)}(x_0)$ and thus $\mathcal{S}^{(0)}(x_0)\neq\emptyset$. Moreover, the set $\mathcal{S}^{(0)}(x_0)$ is convex since $\mathcal{S}^{(0)}(x_0) = \cap^{m}_{i=1}\mathcal{S}^{(0)}_i(x_0)$ and $\mathcal{S}^{(0)}_i(x_0)$ is a $d$-dimensional ball for any $i$. We call $\mathcal{S}^{(0)}(x_0)$ a \textit{local feasible set around} $x_0$.
\begin{remark}
\label{rmk: LM}
The feasibility of $\mathcal{S}^{(0)}(x_0)$ is a consequence of Assumption \ref{ass: smoothness}. Next, we comment on the missing knowledge of $L_i$ and $M_i$ verifying \eqref{eq: LANDM}. In this case, the set $\mathcal{S}^{(0)}(x_0)$ built based on the initial guesses, $L_i$ and $M_i$, might not be feasible. When infeasible samples are generated, one can multiply $L_i$ and $M_i$ for $i\in\mathbb{Z}^m_1$ by  $\beta>1$. This way, at most  $m+\sum^m_{i=1}\max\{\log_\beta(L_{i,\mathrm{inf}}/L_i),\log_\beta(M_{i,\mathrm{inf}}/M_i)\}$ infeasible samples are encountered, where $L_i$ and $M_i$ are the initial guesses. At the same time, one should avoid using a too large value for $M_i$, since if $M_i\gg M_{i,\mathrm{inf}}$, the approximation used to construct $\mathcal{S}^{(0)}(x_0)$ can be very conservative. We refer the readers to Theorem \ref{thm: complexity}, for a discussion on the growth of the complexity of the proposed method with $L_{\max}+M_{\max}$, and Section \ref{sec: experiments}, for an example illustrating the impact of $M_{\max}$ on the convergence.
\end{remark}
One can find in \cite{usmanova2019log} and  \cite{sui2015safe} a different formulation of local feasible sets. In Appendix \ref{sec: comparison of local safe sets}, we compare the two formulations and explain why $S^{(0)}(x_0)$ is the less conservative.




\subsection{The proposed algorithm}
\label{sec: algorithm}
The proposed method to solve problem \eqref{eq: optimization problem} is summarized in Algorithm~\ref{alg:sslo}, called Safe Zeroth-Order Sequential QCQP (SZO-QQ). 
The main idea is to start from the strictly feasible initial point $x_0$ and iteratively solve \eqref{eq: starstar} in Algorithm~\ref{alg:sslo} until two termination conditions are satisfied. Next, we discuss the main steps of the algorithm.

\textbf{Providing input data}.
The input to Algorithm 
\ref{alg:sslo} includes an initial feasible point $x_0$ (see Assumption \ref{ass: strict feasible}) and three parameters $\mu,\xi,\Lambda$. We will describe in Section \ref{sec: accumulation_point} the selection of $\xi$ and $\Lambda$ to ensure that Algorithm \ref{alg:sslo} returns an $\eta$-KKT pair of \eqref{eq: optimization problem}. The impact of $\mu$ on the convergence will be shown in Theorem \ref{thm: complexity}.

\textbf{Building local feasible sets} (Line 4). For a strictly feasible $x_k$, we use \eqref{eq: l_0} to define $l_k^*$ and let the step size of the finite differences for gradient estimation be
\begin{equation}
\nu_k^* =\min\{ \frac{l_k^*}{\sqrt{d}},\frac{1}{k},\frac{\eta}{12\alpha_{\max}m\Lambda}\}.
\label{eq: stepsize_2}
\end{equation} 
Moreover, we use \eqref{eq:safe_set} to define
$\mathcal{S}^{(k)}(x_k)$ in \eqref{eq: starstar}. The bounds $v^*_k\leq 1/k$  and  $v^*_k\leq{\eta}/(12\alpha_{\max}m\Lambda)$ in \eqref{eq: stepsize_2} are utilized to verify the approximate KKT conditions \eqref{eq:kkt} (see Theorem \ref{prop: eta-KKT}). 

\textbf{Solving a subproblem} (Line 5). Based on the local feasible set, we formulate the subproblem \eqref{eq: starstar} of Algorithm \ref{alg:sslo}. By adding the penalty term $\mu\|x_{k+1}-x_k\|^2$, we ensure that $\|x_{k+1}-x_k\|$ converges to 0 (see Theorem \ref{thm: main_theorem}). Since $f_0$ is assumed, without loss of generality, to be known and linear (see Section \ref{sec::Prob}), \eqref{eq: starstar} is a known convex QCQP. We let $(x_{k+1},\lambda^\circ_{k+1})$ be the optimal primal and dual solutions to \eqref{eq: starstar}. As shown in the proof of Theorem~\ref{thm: safesetconstruction}, the bound $M_i>M_{i,\mathrm{inf}}$ from Assumption \ref{ass: smoothness} implies that $x_{k+1}
\in \Omega$   is strictly feasible.

\textbf{Checking termination conditions} (Line 6-11). We introduce two termination conditions guaranteeing that the pair $(\tilde{x},\tilde{\lambda})$ returned by Algorithm \ref{alg:sslo} is an $\eta$-KKT pair. The first one (Line 6) requires that $\|x_{k+1}-x_k\|$ is smaller than a given threshold $\xi$ while the second requires that the solution to the optimization problem \eqref{eq: SP2} is small enough (Line 8). The constraint of \eqref{eq: SP2} is 
\begin{equation}
\label{eq: approximateKKT_subproblem}
\max\Big\{\delta_1(k,\lambda_{k+1}), \max\{\delta^{(i)}_2(k,\lambda_{k+1}):i\geq 1 \}\Big\}\leq\frac{\eta}{2},
\end{equation}
where
\begin{align}\notag
\delta_1(k,\lambda_{k+1})& :=  \Big\|{\nabla} f_0\left(x_{k+1}\right) + 2\mu (x_{k+1}-x_k) \\\notag
 +\sum^{m}_{i=1} \lambda_{k+1}^{(i)}&\left({\nabla}^{\nu_{k}^*} f_i\left(x_{k}\right)+4M_i(x_{k+1}-x_{k})\right)\Big\|,\\\notag
\delta^{(i)}_2(k,\lambda_{k+1}) &:=\Big|\lambda_{k+1}^{(i)} \Big(f_i(x_k)+{\nabla}^{\nu_k^*} f_i\left(x_k\right)(x_{k+1}-x_k)\\\label{eq: definition_delta}
&+2M_i\|x_{k+1}-x_k\|^2\Big)\Big|.
\end{align}
Observe that $\delta_1(k,\lambda_{k+1})$ and $\delta^{(i)}_2(k,\lambda_{k+1})$ in \eqref{eq: definition_delta} originate from the KKT conditions for \eqref{eq: starstar}. Therefore, by solving \eqref{eq: SP2} we obtain the smallest-norm vector $\lambda_{k+1}$ such that $(x_{k+1},\lambda_{k+1})$ is a $\eta/2$-KKT pair of \eqref{eq: starstar}. To solve \eqref{eq: SP2}, we reformulate it as a convex QCQP and use $\lambda^\circ_{k+1}$ as an initial feasible solution. If the two conditions are satisfied at the $(k+1)$-th iteration, then the algorithm outputs in Line 9 are $\tilde{x} = x_{k+1}$, $\tilde{\lambda} = \lambda_{k+1}$ and $\tilde{k} = k+1$.

\vspace{0.3cm}
\begin{algorithm}[htbp!]
\caption{Safe Zeroth-Order Sequential QCQP (SZO-QQ)}
\textbf{Input:} $\mu,\xi,\Lambda>0$, initial feasible point $x_0\in\Omega$\\
\textbf{Output:} $\tilde{x}$, $\tilde{\lambda}$, $\tilde{k}$
\begin{algorithmic}[1]
	\State Choose $M_i >M_{i,\mathrm{inf}}$, for $i\in \mathbb{Z}^m_1$
	\State $k\gets 0, \textsc{TER}= 0$ 
	\While{$\textsc{TER} = 0$}
	\State Compute $\mathcal{S}^{(k)}(x_{k})$ based on \eqref{eq:safe_set} and \eqref{eq: stepsize_2}.
	\State 
	Compute the optimal primal and dual solutions $(x_{k+1},\lambda^\circ_{k+1})$ of 
 \begin{equation}
 \label{eq: starstar}
     \min_{x\in \mathcal{S}^{(k)}(x_{k})} f_0(x)+\mu \|x-x_k\|^2  \tag{SP1}
 \end{equation}
	\If{$\|x_{k+1}-x_{k}\|\leq \xi$}
	\State
 \begin{equation}
 \label{eq: SP2}
 \lambda_{k+1}\gets \underset{\lambda_{k+1}\in \mathbb{R}^m_{+} 
	}{\text{argmin}}   \|\lambda_{k+1}\|_{\infty} \text{ s.t. }  \eqref{eq: approximateKKT_subproblem} \tag{SP2}
 \end{equation}	\If{$\|\lambda_{k+1}  \|_\infty\leq 2\Lambda$}
	\State $\tilde{x}\gets x_{k+1},\tilde{\lambda}\gets \lambda_{k+1}$, $\tilde{k}\gets k+1$, $\textsc{TER}\gets 1$
	\EndIf
	\EndIf
	\State $k\gets k+1$
	\EndWhile
\end{algorithmic}
\label{alg:sslo}
\end{algorithm}

Algorithm \ref{alg:sslo} is similar to Sequential QCQP (SQCQP)~\cite{fukushima2003sequential}. In SQCQP, at each iteration, quadratic proxies for constraint functions are built based on the local gradient vectors and Hessian matrices. The application of SQCQP to optimal control has received increasing attention \cite{messerer2020determining,messerer2021survey}, due to the development of efficient solvers for QCQP subproblems \cite{frison2022introducing}. Different from SQCQP \cite{fukushima2003sequential}, Algorithm~\ref{alg:sslo} can guarantee sample feasibility and does not require the knowledge of Hessian matrices, which are costly to obtain for zeroth-order methods. As Hessian matrices are essential for proving the convergence of SQCQP in \cite{fukushima2003sequential}, we cannot use the same arguments in \cite{fukushima2003sequential} to show the properties of SZO-QQ's iterates. In the following two sections, we state the properties of $(\tilde{x},\tilde{\lambda})$ and analyze the efficiency of the algorithm.  

\section{On the properties of SZO-QQ's iterates and output} 
\label{sec: accumulation_point}
In this section, we aim to show that, for a suitable $\xi$, the pair $(\tilde{x},\tilde{\lambda})$ derived in Algorithm~\ref{alg:sslo} is $\eta$-KKT. We start by considering the infinite sequence of Algorithm~\ref{alg:sslo}'s iterates $\{x_k\}_{k\geq 1}$ when the termination conditions in Line 6 and 8 of Algorithm \ref{alg:sslo} are removed. We show that the sequence $\{x_k\}_{k\geq 1}$ has accumulation points and, for any accumulation point $x_c$, under mild assumptions, there exists $\lambda_c\in\mathbb{R}^m_{\geq 0}$ such that $(x_c,\lambda_c)$ is a KKT pair of \eqref{eq: optimization problem}. Based on this result, we then study the activation of the two termination conditions and prove that they are satisfied within a finite number of iterations. Finally, we show that if $\xi$ is carefully chosen, the derived pair $(\tilde{x},\tilde{\lambda})$ is $\eta$-KKT. 

\subsection{On the accumulation points of $\{x_k\}_{k\geq 1}$}
\label{sec: convergence of x_K}
\begin{theorem}
\label{thm: main_theorem}
If the termination conditions are removed, the sequence $\{x_k\}_{k\geq 1}$ in Algorithm~\ref{alg:sslo} has the following properties:
\begin{itemize}
\item[1.] the sequence $\{f_0(x_k)\}_{k\geq 1}$ is non-increasing;
\item[2.] $\{x_k\}_{k\geq 1}$ has at least one accumulation point $x_c$ and $\{\|x_{k+1}-x_k\|\}_{k\geq 1}$ converges to 0;
\item [3.] $\lim_{k\rightarrow \infty}f_0(x_k)=f_0(x_c)> -\infty$. 
\end{itemize}
\end{theorem}
The proof is provided in Appendix \ref{sec: 1st argument of thm2}. It mainly exploits the following inequality,
\begin{equation}
\label{eq: monotonicity_inequality}
f_0(x_{k+1})+\mu\|x_{k+1}-x_k\|^2\leq f_0(x_{k}),
\end{equation}
which is due to the optimality of $x_{k+1}$ for~\eqref{eq: starstar} in Algorithm \ref{alg:sslo}. The monotonicity of $f_0(x_k)$ and the convergence of $\|x_{k+1}-x_k\|$ are direct consequences of \eqref{eq: monotonicity_inequality}. By utilizing the monotonicity, we have that, for any $k\geq 1$, $x_k$ belongs to the bounded set $ \mathcal{P}_\beta$ (see Assumption \ref{ass: bounded_sublevel} for the definition of $\mathcal{P}_\beta$). Due to Bolzanoâ€“Weierstrass theorem, there exists an accumulation point of $\{x_k\}_{k\geq 1}$. The continuity of $f_0(x)$ gives us Point 3 of Theorem \ref{thm: main_theorem}. 

Based on Theorem \ref{thm: main_theorem}, we can show that, under Assumption \ref{ass:LICQ} below, there exists an accumulation point of $\{x_k\}_{k\geq 1}$ that allows one to build a KKT pair.
\begin{assumption}
\label{ass:LICQ}
There exists an accumulation point $x_c$ of $\{x_k\}_{k\geq 1}$ such that 
the~\textit{Linear Independent Constraint Qualification (LICQ)} holds at $x_c$ for \eqref{eq: optimization problem}, which is to say the gradients $\nabla f_i(x_c)$ with $i\in \mathcal{A}(x_c):=\{i: f_i(x_c)=0\}$ are linearly independent.
\end{assumption}


Assumption \ref{ass:LICQ} is widely used in optimization \cite{wachsmuth2013licq}. For example, it is used to prove the properties of the limit point of the Interior Point Method \cite{jorge2006numerical}. With this assumption, if there exists $\lambda_c\in \mathbb{R}^m_{\geq 0}$ such that $(x_c,\lambda_c)$ is an optimal primal-dual pair, then the pair is KKT, which will be used in the proof of Theorem \ref{thm: accumulationKKT}.

\begin{theorem}
\label{thm: accumulationKKT}
Under Assumption \ref{ass:LICQ}, let $x_c$ be an accumulation point of $\{x_k\}_{k\geq 1}$ where LICQ is verified. Then, there exists a unique $\lambda_c\in \mathbb{R}^m_{\geq0}$ such that $(x_c,\lambda_c)$ is a KKT pair of the problem \eqref{eq: optimization problem}.
\end{theorem}

In the proof of Theorem \ref{thm: accumulationKKT}, provided in Appendix \ref{sec: proof_of_accumulationKKT}, we exploit a preliminary result (Lemma \ref{lmm: non_empty_interior}, stated and proved in Appendix \ref{sec: preliminary results for Lemma xcandlambdac}) where we construct an auxiliary problem \eqref{eq: x_c_optimization} and show that $x_c$ is an optimum to \eqref{eq: x_c_optimization}. We notice that the KKT conditions of \eqref{eq: x_c_optimization} evaluated at $x_c$ coincide with those of \eqref{eq: optimization problem} evaluated at the same point. Due to LICQ, there exists a unique $\lambda_c\in \mathbb{R}_{\geq0}$ such that $(x_c,\lambda_c)$ is a common KKT pair of \eqref{eq: x_c_optimization} and \eqref{eq: optimization problem}.
\subsection{The output of Algorithm \ref{alg:sslo} is an $\eta$-KKT pair}
\label{sec: eta-KKT}
The result in Theorem \ref{thm: accumulationKKT} is asymptotic, but in practice only finitely many iterations can be computed. From now on, we take the termination conditions of Algorithm~\ref{alg:sslo} into account and show that, given any $\eta>0$, by suitably tuning $\xi>0$,  Algorithm \ref{alg:sslo} returns an $\eta$-KKT pair. To begin, we make the following assumption.
\begin{assumption}
\label{ass: magnitude_dual_variable}
The KKT pair $(x_c,\lambda_c)$ in Theorem~\ref{thm: accumulationKKT} satisfies $\|\lambda_c\|_{\infty}<\Lambda$, where $\Lambda >0$ is the input in Algorithm \ref{alg:sslo}.
\end{assumption}
Assumptions on the bound of the dual variable are adopted in the literature of primal-dual methods including \cite{usmanova2021fast} and \cite{zhu2016distributed}. We illustrate this assumption in Appendix~\ref{sec: characterization of lambda} where we show in an example that $\Lambda$ is related to the geometric properties of the feasible region. 

\begin{remark}
\label{rmk: on Lambda}
In case it is hard to choose a value of $\Lambda$ fulfilling Assumption \ref{ass: magnitude_dual_variable}, we can replace $\Lambda$ with $\gamma\|\lambda_{k+1}\|_\infty$, where $\gamma>1$ and $\lambda_{k+1}$ is the solution to the problem \eqref{eq: SP2} in Algorithm \ref{alg:sslo}, every time the second termination condition (Line 8 in Algorithm \ref{alg:sslo}) is violated. Note that every time $\Lambda$ gets updated it becomes at least $2\gamma-1$ times larger. Similar updating rules can also be found in \cite{usmanova2021fast}. In this way, we are guaranteed to find $\Lambda$ that satisfies Assumption~\ref{ass: magnitude_dual_variable} after a finite number of iterations. However, we also notice that this updating mechanism generates a conservative guess for $\Lambda$ if $\|\lambda_{k}\|_\infty\gg \|\lambda_c\|_\infty$ for some $k$. In Theorem \ref{prop: eta-KKT}, we will set $\xi$ in Algorithm \ref{alg:sslo} to be proportional to $\Lambda^{-1}$ so that the returned pair is an $\eta$-KKT pair. Consequently, a conservative $\Lambda$ can increase the number of iterations required by Algorithm \ref{alg:sslo}.
\end{remark}



\begin{theorem}
\label{thm: algorithm_termination}
If Assumptions \ref{ass:LICQ} and \ref{ass: magnitude_dual_variable} hold, Algorithm \ref{alg:sslo} terminates in a finite number of iterations.
\end{theorem}
According to Theorem \ref{thm: main_theorem}, the first termination condition is satisfied in Algorithm \ref{alg:sslo} whenever $k$ is sufficiently large. In the proof of Theorem \ref{thm: algorithm_termination} (provided in Appendix \ref{sec: algorithm_termination}), we show that $\lambda_{k+1}=\lambda_c$ is a feasible solution to \eqref{eq: SP2} when $x_{k+1}$ is close enough to $x_c$. Thus, for sufficiently large $k$, the second termination is satisfied since $\|\lambda_c\|_\infty<\Lambda$ .


Recall that Algorithm \ref{alg:sslo} returns $\tilde{x},\tilde{\lambda}$ and $\tilde{k}$, which are dependent on the chosen value for $\xi$. For a given accuracy indicator $\eta>0$, in the following we show how to select $\xi$ such that $(\tilde{x},\tilde{\lambda})$ is an $\eta$-KKT pair.
\begin{theorem}
\label{prop: eta-KKT}
Under Assumptions \ref{ass:LICQ} and \ref{ass: magnitude_dual_variable}, we let
\begin{equation}
\label{eq: xi}
\begin{aligned}
\xi=h(\eta) :=\min\Big\{ &\frac{\eta}{60\Lambda\sum^m_{i=1}M_i},\frac{\eta}{12\mu}, 1\\ 
&\frac{\eta}{4\Lambda(   \alpha_{\max}+2{L_{\max}} + 2{M_{\max}})}\Big\},
\end{aligned}
\end{equation}
where $\mu$ is a parameter of \eqref{eq: starstar}, $\alpha_{\max} = \max_{1\leq i\leq m} \alpha_i$ and $\alpha_i$ is defined in \eqref{eq: gradient approximation error}.
Then the output $(\tilde{x},\tilde{\lambda})$ of Algorithm \ref{alg:sslo} is an $\eta$-KKT pair of \eqref{eq: optimization problem} .
\end{theorem}
The proof of Theorem \ref{prop: eta-KKT} can be found in Appendix \ref{sec: proof_of_xi}. In summary, to ensure that the pair $(\tilde{x},\tilde{\lambda})$ is an $\eta$-KKT pair, we need to set $\xi$ in Algoirthm \ref{alg:sslo} to be $h(\eta)$ in \eqref{eq: xi} while selecting $L_i$, $M_i$ and $\Lambda$ to satisfy Assumptions \ref{eq: smoothness} and \ref{ass: magnitude_dual_variable} (see Remark \ref{rmk: LM} and \ref{rmk: on Lambda}).

\section{Complexity analysis}
\label{sec: complexity_analysis}
In this section, we aim to give an upperbound, dependent on $\eta$, for the number of iterations of Algorithm \ref{alg:sslo}. To this purpose, we consider the following assumption.
\begin{assumption}
\label{ass: assumption for convergence}
The accumulation point $x_c$ in Assumption \ref{ass:LICQ}, which is already known to define a KKT pair, is a strict local minimizer, i.e., there exists a neighborhood $\mathcal{N}$ of $x_c$ such that $f_0(x)>f_0(x_c)$ for any $x\in \mathcal{N}\cap \Omega\setminus x_c$.
\end{assumption}
Assumption \ref{ass: assumption for convergence}, not relying on the twice differentiability of the objective and constraint functions, is a necessary condition of Second-Order Sufficient Condition (SOSC) for optimality \cite[Chapter 12.5]{jorge2006numerical}, which is commonly assumed in the literature of optimization
\cite{diehl2005real,izmailov2004newton}. 
\begin{lemma}
\label{lmm: convergence}
If Assumption \ref{ass: assumption for convergence} holds, $\{x_k\}_{k\geq 1}$ converges.
\end{lemma}
In the remainders of this section, we consider Assumption \ref{ass: assumption for convergence}. Let $x_c$ be the limit point of $\{x_k\}_{k\geq 1}$ and note that there exists $\lambda_c$ such that $(x_c,\lambda_c)$ is a KKT pair. Then we aim to show in Lemma \ref{lmm: convergence of the dual variable} that $\lambda^\circ_{k}$, the optimal solution to the dual variable of \eqref{eq: starstar}, converges to $\lambda_c$. 

To account for the influence of $x_k$ and $\nu^*_k$ on $\lambda^\circ_{k+1}$, we let $\mathcal{D}_\lambda(y,\nu)\subset \mathbb{R}^m$ be the optimal solution set of the dual of the following convex problem:
\begin{equation}
\begin{aligned}
\mathsf{P}(y,\nu): \min_{x\in\mathbb R^d} & \quad f_0(x)+\mu \|x-y\|^2\\
\text{subject to} &  \quad f_i(y) + \Big(\underbrace{\Delta^\nu_i(y) + \nabla f_i(y)}_{\nabla^\nu_i f_i(y) }\Big)^\top(x-y)\\
&\quad+2M_i\|x-y\|^2\leq 0.
\end{aligned}
\end{equation} 
We notice that $\mathsf{P}(x_k,\nu^*_k)$ coincides with \eqref{eq: starstar} in Algorithm~\ref{alg:sslo} and thus $\lambda^\circ_{k+1}\in \mathcal{D}_\lambda(x_k,\nu^*_k)$. If we can show the continuity of $\mathcal{D}_\lambda(y,\nu)$ with respect to $y$ and $\nu$, we immediately have that $\lambda^\circ_{k}$ converges to $\lambda_c$ because $(x_k, \nu^*_k)$ converges to $(x_c,0)$. However, $\mathcal{D}_\lambda(y,\nu)\subset \mathbb{R}^m$ is not necessarily a singleton and thus continuity is not applicable. As a similar concept, we define upper semicontinuity for multifunctions in the following.
\begin{definition}
Let $W$ and $V$ be two vector spaces. A multifunction $F: W\rightarrow \mathcal{P}(V)$, where $\mathcal{P}:=\{P: P\subset V\}$, is said to be upper semicontinuous at $w_0$ if for any neighborhood $\mathcal{N}_{V}$ of $F(w_0)$, there exists a neighborhood $\mathcal{N}_W$ of $w_0$ such that the inclusion $F(w)\subset \mathcal{N}_{V}$ holds for any $w\in\mathcal{N}_W$.
\end{definition}
By exploiting perturbation theory for optimization problems \cite{bonnans2013perturbation}, one can prove the upper semicontinuity of $\mathcal{D}_\lambda(y,\nu)$ at $ (x_c,0)$. Since $\mathcal{D}_\lambda(x_c,0) = \{\lambda_c\}$ (according to Theorem \ref{thm: accumulationKKT}) and $(x_{k},\nu^*_{k})$ converges to $(x_c,0)$, the upper semicontinuity directly translates into the convergence of $\{\lambda^\circ_{k}\}_{k\geq 1}$ to $\lambda_c$. To elaborate on these arguments, we have the following lemma and show the proof in Appendix \ref{sec: lambda_conv}.
\begin{lemma}
\label{lmm: convergence of the dual variable}
If Assumptions \ref{ass:LICQ}, \ref{ass: magnitude_dual_variable} and \ref{ass: assumption for convergence} hold, $\lambda^\circ_{k}$ converges to $\lambda_c$.    
\end{lemma}
Based on this lemma, we can obtain an upperbound for $\tilde{k}$, the number of iterations required by Algorithm \ref{alg:sslo}. The proof of Theorem~\ref{thm: complexity} is in Appendix \ref{sec: proof_of_complexity}.

\begin{theorem}
\label{thm: complexity}
If Assumptions \ref{ass:LICQ}, \ref{ass: magnitude_dual_variable} and \ref{ass: assumption for convergence} hold, there exists $\bar{\eta}>0$ such that, for any $\eta<\bar{\eta}$, Algorithm \ref{alg:sslo} terminates within $\overline{\mathcal{K}}(\eta)+1$ iterations, where 
$$ \overline{\mathcal{K}}(\eta) = \frac{f_0(x_0) - \inf\{f_0(x): x\in \Omega\}}{\mu(h(\eta))^2},$$
$\mu$ is the coefficient of the quadratic penalty term in \eqref{eq: starstar}  and $h(\eta)$ is defined in \eqref{eq: xi}. Thus, for any $\eta>0$, Algorithm~\ref{alg:sslo} takes at most  $O(\frac{(M_{\max}+L_{\max})^2}{\eta^2})$~iterations to return $(\tilde{x},\tilde{\lambda})$, an $\eta$-KKT pair of the problem~\eqref{eq: optimization problem}.
\end{theorem}

\textbf{Discussion}:\vspace{0.2cm}\\
We compare the sample and computation complexity of SZO-QQ with two other existing safe zeroth-order methods, namely, 0-LBM in \cite{usmanova2019log} and SafeOPT in \cite{berkenkamp2016safe}. We remind the readers that these methods have different assumptions. Specifically, given the black-box optimization problem \eqref{eq: optimization problem}, SafeOPT assumes that $f_i(x), i\in \mathbb{Z}^m_{i=0}$, has bounded norm in a suitable Reproducing Kernel Hilbert Space while both SZO-QQ and 0-LBM are based on the assumption of the smoothness constants. Regarding sample complexity, SZO-QQ needs $O(\frac{1}{\eta^2})$ samples under Assumption \ref{ass: assumption for convergence} to generate an $\eta$-KKT pair while 0-LBM  and SafeOPT in  require $O(\frac{1}{\eta^3})$ \cite[Theorem 2]{usmanova2019log} and $O(\frac{1}{\eta^2})$ \cite[Theorem 1]{sui2015safe} samples respectively. We also highlight that the computational complexity of each iteration of both 0-LBM and SZO-QQ stays fixed while the computation time required for the Gaussian Process regression involved in each iteration of SafeOPT increases as the data set gets larger. The high computational cost is one of the main reasons why SafeOPT scales poorly to high-dimensional problems. Numerical results comparing the computation time and the number of samples required by these methods are provided in Section~\ref{sec: toy example}.

In contrast, the Interior Point Method, based on the assumption of $f_i(x)$ being twice continuously differentiable, achieves superlinear convergence \cite{jorge2006numerical} by utilizing the true model of the optimization problem, which translates into at most $O(\mathrm{log}\frac{1}{\eta})$ iterations. The gap between $O(\frac{1}{\eta^2})$ of SZO-QQ and $O(\mathrm{log}\frac{1}{\eta})$ may be either the price we pay for the lack of the first-order information of the objective and constraint functions or due to the conservative analysis in Theorem \ref{thm: complexity}. To see whether there exists a tighter complexity bound than $O(\frac{1}{\eta^2})$ for Algorithm \ref{alg:sslo}, an analysis on the convergence rate is needed, which is left as future work.




\section{Numerical Results}
\label{sec: experiments}
In this section, we present 3 numerical experiments to test the performance of Algorithm \ref{alg:sslo}. The first is a two-dimensional problem where we compare SZO-QQ with other existing zeroth-order methods and discuss the impact of parameters. In the remaining two examples, which have more dimensions and constraints, we apply our method to solve optimal control and optimal power flow problems. All the numerical experiments have been executed on a PC with an Intel Core i9 processor.
\subsection{Solving an unknown non-convex QCQP}
\label{sec: toy example}
We evaluate SZO-QQ and compare it with alternative safe zeroth-order methods in the following non-convex example,
\[
    \begin{aligned}
    \min_{x \in \mathbb{R}^2} & \quad  f_0(x)=0.1\times (x^{(1)})^2+x^{(2)}\\
     \text{subject to}  & \quad f_1(x) =0.5-\|x+[0.5 \; -0.5]^\top\|^2 \leq 0,\\
     &\quad f_2(x)=x^{(2)}-1\leq 0,\\
    & \quad f_3(x) = (x^{(1)})^2-x^{(2)}\leq 0.
    \end{aligned}
\]
We assume that the functions $f_i(x), i=1,2,3,$ are unknown but can be queried. A strictly feasible initial point $x_0 = [0.9 \,\,\, 0.9]^\top$ is given. The unique optimum  $x_* = [0\,\,\,0]^\top $ is not strictly feasible. According to Theorem \ref{thm: accumulationKKT}, the iterates of SZO-QQ will get close to $x_*$, which allows us to see whether SZO-QQ stays safe and whether the convergence is fast when the iterates are close to the feasible region boundary. The experiment results allow us to discuss the following three aspects, respectively on derivation of a $10^{-2}$-KKT pair, performance evaluation and parameter tuning.

a. \textbf{Selection of $\xi$ for deriving a $10^{-2}$-KKT pair}

To begin with, we fix $\eta = 10^{-2}$ and aim to derive an $\eta$-KKT pair. By setting $\Lambda = 1.5$ and $L_i=5$, $M_i=3$ for any $i\geq 1$, we calculate $\xi=1.51\times 10^{-5}$ according to~\eqref{eq: xi}. With these values, SZO-QQ returns in 3.3 seconds an $\eta'$-KKT pair with $\eta'=9.21\times 10^{-4}<\eta$. We also observe that $\|{\lambda}_{k}\|_\infty$ converges to 1 and thus the original guess $\Lambda=1.5$ satisfies Assumption \ref{ass: magnitude_dual_variable}. Now we see that we indeed derive an $\eta$-KKT pair, which coincides with Theorem \ref{prop: eta-KKT}. To further evaluate the performance of SZO-QQ in terms of how fast the objective function value decreases, we eliminate the termination conditions in the remainders of Section \ref{sec: toy example}.

b. \textbf{Performance comparison with other methods}

We run SZO-QQ with $\xi=0$ and compare with 0-LBM \cite{usmanova2019log}, Extremum Seeking \cite{arnold2015model} and SafeOptSwarm\footnote{SafeOptSwarm is a variant of SafeOpt (recall Section \ref{sec: introduction}). The former adds heuristics to make SafeOpt in \cite{sui2015safe} more tractable for higher dimensions.}~\cite{berkenkamp2016safe}. Among these methods, SZO-QQ, 0-LBM and SafeOpt-Swarm have theoretical guarantees for sample feasibility (at least with a high probability). Only SZO-QQ and 0-LBM require Assumption \ref{ass: smoothness} on Lipschitz and smoothness constants. For these two approaches, by trial and error (see Remark \ref{rmk: LM}), we choose $L_{i} = 5$ and $M_{i}= 3$ for any $i\geq 1$. The penalty coefficient $\mu$ of Algorithm \ref{alg:sslo} in \eqref{eq: starstar} is set to be $ 0.001$. For both 0-LBM and Extremum Seeking are log-barrier-based, we use the reformulated unconstrained problem $\min_x f_{\mathrm{log}}(x,\mu_{\log})$, where $f_{\mathrm{log}}(x,\mu_{\log}):=f_0(x) - \mu_{\mathrm{log}}\sum^4_{i=1}\log(-f_i(x))$, and $\mu_{\log} = 0.001$.
\begin{figure}[htbp!]
    \centering
    \includegraphics[width=0.9\linewidth]{comparison.pdf}
    \caption{Objective value as a function of computation time.}
    \label{fig:objective_decrease}
\end{figure}

In Fig. \ref{fig:objective_decrease}, we show the objective function values versus the computation time. During the experiments, none of the methods violates the constraints. Regarding the convergence to the minimum, we see that 0-LBM is has the most decrease in the objective function value in the first 1.5 seconds, which is due to the low complexity of each iteration. In these 1.5 seconds, 0-LBM utilizes 67856 function samples while SZO-QQ only 252. Afterwards, SZO-QQ achieves a better solution. In the first 6 seconds, SZO-QQ shows a clear trend of convergence to the optimum, which is consistent with Theorem~\ref{thm: accumulationKKT}, while SafeOptSwarm only finishes 6 iterations and 28 function samples. 

0-LBM slows down when the iterates are close to the boundary of the feasible set (see Appendix \ref{sec: comparison of local safe sets} for the explanation for this phenomenon). Meanwhile, the slow convergence of Extremum Seeking is due to its small learning rate. If the learning rate is large, the iterates might be brought too close to the boundary of the feasible set and then the perturbation added by this method would lead to constraint violation. These considerations constitute the main dilemma in parameter tuning for Extremum Seeking. Meanwhile, the exploration of the unknown functions in SafeOptSwarm is based on Gaussian Process (GP) regression models instead of local perturbations. Since SafeOptSwarm does not exploit the convexity of the problem, it maintains a safe set and tries to expand it for finding the global minimum. Empirically, this method samples many points close to the boundary of the feasible region, which is also observed in \cite{turchetta2019safe}. These samples along with the computational complexity of GP regression are the main reason of the slow convergence of SafeOptSwarm. 
o
We also run 0-LBM and Extremum Seeking with different penalty coefficients $\mu_{\mathrm{log}}$ to check whether the slow convergence is due to improper parameter tuning. We see that with larger $\mu_{\mathrm{log}}$ the performance of the log-barrier-based methods deteriorates. This is probably because the optimum of the unconstrained problem $f_{\log}(x,\mu_{\log})$ deviates more from the optimum as $\mu_{\mathrm{log}}$ increases. With smaller $\mu_{\mathrm{log}}$,  the Extremum Seeking method leads to constraint violation while the performance of 0-LBM barely changes. 

c. \textbf{Impact of the parameters $L_i$ and $M_i$}

To show the impact of conservative guesses of $L_i$ and $M_i$, we consider 9 test cases of different values for the pair $(L,M)$. We use $L$ as the Lipschitz constant for all the objective and constraint functions and $M$ as the smoothness constant. We illustrate in Figures \ref{fig:objective_decrease:M fixed} and \ref{fig:objective_decrease:Lfixed} the decrease of the objective function values when SZO-QQ and 0-LBM are applied to solve the 9 test cases. From the figures, we see that the time required by SZO-QQ to achieve an objective function value less than $10^{-2}$ grows with $M_i$. Despite this, across all the cases SZO-QQ is the first to achieve a objective function value of $10^{-2}$. Another observation is that the performance of SZO-QQ is more sensitive to varying $M$ while 0-LBM is more sensitive to varying $L$. This is due to the differences in the local feasible set formulations in both methods. Indeed, in SZO-QQ the constant $L_i$ is only related to the gradient estimation and the size of the local feasible set $\mathcal{S}_i(\cdot)$ in \eqref{eq:safe_set} is mainly decided by $M_i$, while in 0-LBM the size of $\mathcal{T}^{(k)}(\cdot)$, for any $k$, is mainly dependent on the Lipschitz constants $L_i$ for $i\geq 1$. 

We also study the case where the initial guesses of Lipschitz and smoothness constants are wrong, i.e., \eqref{eq: smoothness} in Assumption \ref{ass: smoothness} is violated. With $L=0.2$ and $M=0.2$, we encounter an infeasible sample. Then we follow the method in Remark \ref{rmk: LM} to multiply the constants by 2 every time an infeasible sample is generated. With $L=M=0.8$, every sample is feasible and we derive in 2 seconds an objective function value of $4\times10^{-7}$. In total, we generate two infeasible samples. Although the setting $L=M=0.8$ still fails to satisfy Assumption~\ref{ass: smoothness}, with these constants, SZO-QQ is able to generate iterates which have a subsequence converging to a KKT pair. The readers can check that Theorem \ref{thm: accumulationKKT} holds even if the guesses for Lipschitz and smoothness constants do not verify 
\eqref{eq: smoothness} in Assumption \ref{ass: smoothness} (see the proof of Theorem \ref{thm: accumulationKKT} in Appendix \ref{sec: proof_of_accumulationKKT}).


\begin{figure}[htbp!]
    \centering
    \includegraphics[width=1\linewidth]{LM.pdf}
    \caption{Objective value as a function of computation time:\\ $\text{ }$ $\;\, \quad \quad M_0=3$ fixed and $L_0$ varied}
    \label{fig:objective_decrease:M fixed}
\end{figure}
\begin{figure}[htbp!]
    \centering
    \includegraphics[width=\linewidth]{LM2.pdf}
    \caption{Objective value as a function of computation time:\\ $\text{ }$ $\;\, \quad \quad L_0=5$ fixed and $M_0$ varied}
    \label{fig:objective_decrease:Lfixed}
\end{figure}


\subsection{Open-loop optimal control with unmodelled disturbance}
SZO-QQ can be applied to deterministic optimal control problems with unknown nonlinear dynamics by using only feasible samples. To illustrate, we consider a nonlinear system with dynamics $x_{k+1} = Ax_k+Bu_k + \delta(x_k)[1\;0]^\top$, where $x_k\in \mathbb{R}^2$ for $k\geq 0$ and $x_0 = [1\;1]^\top$. The matrices
$$A = \begin{bmatrix}1.1 & 1\\-0.5& 1.1 \end{bmatrix}, B  = \begin{bmatrix}1 & 0 \\0& 1 \end{bmatrix}$$
and the expression of the disturbance $\delta(x):=0.1*(x^{(2)})^2$ are unknown. We aim to design the input $u_k$ for $i\in \mathbb{Z}^5_{0}$ to minimize the cost
$\sum^{5}_{k=0}\left(x_{k+1}^\top Q x_{k+1} +u_k^\top R u_k\right) $ where $Q= 0.5\,\mathbf I_2$ and $R = 2\,\mathbf I_2$ with identity matrix $\mathbf I_2\in\mathbb R^{2\times 2}$ while enforcing $\|x_{k+1}\|_\infty\leq 0.7$ and $\|u_k\|_\infty\leq 1.5$ for $0\leq k\leq 5$. Since we assume all the states are measured, we can evaluate the objective and constraints. In this example, we assume to have a feasible sequence of inputs $\{u_k\}_{0\leq k \leq 5}$ (as in Assumption \ref{ass: strict feasible}) that leads to a safe trajectory and results in a cost of 6.81. Different from the settings in the model-based safe learning control methods \cite{fan2020deep,hewing2019cautious}, we do not assume that this safe trajectory is sufficient for identifying the system dynamics with small error bounds. If the error bounds are huge, the robust control problems formulated in \cite{fan2020deep,hewing2019cautious} may become infeasible.

We run SZO-QQ to further decrease the cost resulting from the initial safe trajectory and derive within 146 seconds of computation an input sequence that satisfies all the constraints and achieves a cost of 5.96. This cost is the same as the one obtained when assuming the dynamics are known and applying the solver IPOPT~\cite{wachter2006implementation}. This observation is consistent with Theorem \ref{thm: accumulationKKT} on the convergence to a KKT pair. In this experiment, we set $L_i=M_i=20$ for $i\geq 1$, $\mu = 10^{-4}$ and $\eta = 10^{-1}$. Thus, the parameter $\xi$ adopted is $2\times 10^{-5}$ according to \eqref{eq: xi}.

\subsection{Optimal power flow for an unmodelled electric network}
In this section, we apply SZO-QQ to solve the AC Optimal Power Flow (OPF) for the IEEE 30-bus system, described in~\cite{christie2000power}. In real-world power systems, it is often hard to obtain an accurate model of a power grid, due to unmodelled disturbances (including aging of the devices and external attacks \cite{chuMitigating22}). In \cite{arnold2015model}, extremum seeking is used to solve OPF in a model-free way. As discussed in Section \ref{sec: toy example}, the use of perturbation signals makes it difficult to select the barrier function coefficient. In this experiment, we aim to compare the results provided by SZO-QQ, which is model-free, with those produced by an OPF solver that utilizes the perfect model.

In the IEEE 30-bus system, the loads in the network are assumed to be fixed. Six generators are installed, among which one is the slack bus. The slack bus is assumed to provide the active power that is needed to maintain the AC frequency. The 11 decision variables are the voltage magnitude of the 6 generator nodes and the active power generations of the generators except the slack bus. The cost is a quadratic function of the power generations and 142 constraints are posed such that the power transmitted through any line is less than the rated value and the voltage magnitude of any bus is within the safe range.

We do not assume to know the system model when it comes to the optimization tasks. However, given a set of values for all the 11 decision variables, we can utilize a black-box simulation model in Matpower \cite{zimmerman2010matpower} to 
sample the voltages of all the 30 buses and the power through all the transmission lines in this network. We also assume to have initial values for all the decision variables such that the constraints are satisfied. In practice, initial values of the decision variables verifying the safety constraints in power systems is not hard to find due to various mechanisms for robust operation, e.g., droop control for power generation, shunt capacitor control and load shedding. 

In this experiment, we set $\mu=0.001$, $\xi = 0.002$, $\Lambda=2$, $M_i=0.2$ and $L_i=1$ for $i\geq 1$. In Figure \ref{fig:objective_decrease:opf}, we illustrate the decrease of the cost and compare with the cost derived by using Gurobi~\cite{gurobi} to solve the model-based optimal power flow. We see that the achieved cost within 1400 seconds is close to what the model-based method derives, which is again consistent with Theorem \ref{thm: accumulationKKT}. Meanwhile, from Figure \ref{fig:largest_constraint_function:opf}, which depicts the largest constraint function value with respect to the computation time, we see that, even though the decision variables can get very close to the boundary of the feasible set, the constraints are never violated. 

Compared with only 1 second used by the model-based method to derive the solution, SZO-QQ is slow. One reason is that solving the QCQP subproblems of SZO-QQ takes too much time for this experiment. Our future work is to see whether the subproblems can be modified to be quadratic programs or even linear programs which allow for more efficient solvers.
\begin{figure}[htbp!]
    \centering
    \includegraphics[width=0.5\textwidth]{cost.pdf}
    \caption{Objective value as a function of computation time}
    \label{fig:objective_decrease:opf}
\end{figure}

\begin{figure}[htbp!]
    \centering
    \includegraphics[width=0.5\textwidth]{large_con.pdf}
    \caption{Largest constraint value as a function of computation time}
    \label{fig:largest_constraint_function:opf}
\end{figure}

\section{Conclusions}
For safe black-box optimization problems, we proposed a method, SZO-QQ, based on samples of the objective and constraint functions to iteratively optimize over local feasible sets. Each iteration of our algorithm involves a QCQP subproblem, which can be solved efficiently. We showed that a subsequence of the algorithm's iterates converges to a KKT pair and no infeasible samples are generated. Given any $\eta>0$, we proposed termination conditions dependent on $\eta$ such that the values returned by the algorithm form an $\eta$-KKT pair. The number of samples required is shown to be $O(\frac{1}{\eta^2})$ under mild assumptions. In comparison, the state-of-the-art methods 0-LBM and SafeOPT require $O(\frac{1}{\eta^3})$ and $O(\frac{1}{\eta^2})$ samples respectively. From numerical experiments, we see that our method can be faster than existing zeroth-order approaches including 0-LBM, SafeOptSwarm and Extremum Seeking. Furthermore, the results derived by SZO-QQ are very close to those generated by model-based methods. Future research directions include the derivation of a tighter complexity bound and a generalization of the method for guaranteeing safety even when the samples are noisy.

\begin{ack}
	This work was supported by the Swiss National Science Foundation under the NCCR Automation (grant agreement 51NF40\textunderscore 80545).
\end{ack}
\bibliographystyle{abbrv}
\bibliography{reference}


%\textbf{Appendix}
\appendix
{\footnotesize
\section{Proof of Theorem \ref{thm: safesetconstruction}}
\label{sec: proofofsafeset}
We notice that $\nu_0^*\leq  l_0^*$ and, from Assumption \ref{ass: smoothness}, $f_i(x_0+\nu_0^*e_j)<f_i(x_0)+l_0^*L_{\max}=0$ for any $i\in \mathbb{Z}_1^m, \, j\in \mathbb{Z}_1^d$. which shows the samples' feasibility.
To show the feasibility of $\mathcal{S}^{(0)}(x_0)$,
we first partition $\mathcal{S}^{(0)}_i(x_0)$ as 
\[
\mathcal{S}^{(0)}_i(x_0) = \left(\mathcal{S}^{(0)}_i(x_0)\bigcap \mathcal B_{l^*_{0}}(x_0)\right)\left.\left.\bigcup\right(\mathcal{S}^{(0)}_i(x_0)\setminus \mathcal B_{l^*_{0}}(x_0)\right)
\] 
and notice that $\mathcal{S}^{(0)}_i(x_0)\bigcap \mathcal B_{l^*_{0}}(x_0)\subseteq \Omega$. Then, it only remains to show $\mathcal{S}^{(0)}_i(x_0)\setminus \mathcal B_{l^*_{0}}(x_0)\subseteq \Omega.$

For $x\in \mathcal{S}^{(0)}_i(x_0)\setminus B_{l^*_{0}}(x_0)$, we have ${\sqrt{d}\nu^*_0}= l^*_{0} \leq\|x-x_0\|.$
By the mean value theorem, for any $i$ there exists $\theta_i\in [0,1]$ such that 
\begin{align}\label{eq: meanvaluetheorem}
f_i(x)
=&  f_i(x_0)+\nabla f_i\left(x_0 + \theta_i(x-x_0)\right)^\top(x-x_0)\\\notag
= &f_i(x_0) + \nabla f_i\left(x_0 \right)^\top(x-x_0) +\\\notag
& \left(\nabla f_i\left(x_0 + \theta_i(x-x_0)\right) - \nabla f_i\left(x_0 \right)\right)^\top(x-x_0)\\\notag
\leq& f_i(x_0) + {\nabla}^{\nu^*_0} f_i\left(x_0\right)^\top(x-x_0)\\\notag
&+ \frac{\sqrt{d}\nu^*_0 M_i}{2}\|x-x_0\| + M_i\|x-x_0\|^2\\\notag
\leq& f_i(x_0) + {\nabla}^{\nu^*_0} f_i\left(x_0\right)^\top(x-x_0) + 2M_i\|x-x_0\|^2\\\notag
\leq& 0,
\end{align}
where the first inequality is due to Assumption \ref{ass: smoothness} while the second one can be derived from the definition of $\nu^*_0$ in Theorem \ref{thm: safesetconstruction}. Hence, $\mathcal{S}^{(0)}_i(x_0)\setminus \mathcal B_{l^*_{0}}(x_0)\subseteq \Omega.$ Since $\mathcal{S}^{(0)}_i(x_0)\subseteq \Omega, \forall i$, then $\mathcal{S}^{(0)}(x_0)\subseteq \Omega$. \hfill$\blacksquare$

\section{Comparison between two different formulations of local safe sets}
\label{sec: comparison of local safe sets}
The works ~\cite{usmanova2019log,sui2015safe} adopt an alternative approximation of the constraints and in particular form a local feasible set 
\[
\mathcal{T}^{(0)}(x_0):=\bigcap^m_{i=1}\left\{x:\|x-x_0\|\leq -\frac{f_i(x_0)}{L_i}\right\}.
\]
We see that $\mathcal{T}^{(0)}(x_0)= \{x:F^L_i(x)\leq0,\forall i \}$ where $F^L_i(x):=f_i(x_0)+L_i\|x-x_0\|$ is linear in $\|x-x_0\|$. In contrast, $\mathcal{S}^{(0)}(x_0)=\{x:F^M_i(x)\leq0,\forall i \}$ where $F^M_i(x):=f_i(x_0)+{\nabla}^{\nu^*_0} f_i\left(x_0\right)^\top(x-x_0)+2{M}_i\|x-x_0\|^2$ is a quadratic approximation of $f_i(x)$. In the following proposition, we show that, if $x_0$ is sufficiently close to the boundary of the feasible set, $\mathcal{T}^{(0)}(x_0)\subset \mathcal{S}^{(0)}(x_0)$, which means that $\mathcal{S}^{(0)}(x_0)$ is less conservative.
\begin{proposition}
\label{prop: conservative of L}
Let ${\ell_{\min}} = \min_{i\geq 1} (L_i-L_{i,\mathrm{inf}})$. For $x_0$, if 
\begin{equation}
\label{eq: conditionforconservativeness}
{\min_{i\geq 1}} -f_i(x_0)\leq \frac{L_{\max}{\ell_{\min}}}{4{M_{\max}}}, 
\end{equation}
then $\mathcal{T}^{(0)}(x_0)\subset \mathcal{S}^{(0)}(x_0)$.
\end{proposition}
\textbf{Proof.} For any $x\in \mathcal{T}^{(0)}(x_0)$, we have
$$\|x -x_0\|\leq {\frac{\min -f_i(x_0)}{L_{\max}}}\leq{\frac{{\ell_{\min}}}{4M_{\max}} }$$
and thus
\begin{equation}
\label{eq: second_order_inequality}
2{M_{\max}}\|x -x_0\|^2\leq \frac{\ell_{\min}}{2}\|x-x_0\|.
\end{equation}
Considering $\nu^*_0 = \frac{\min-f_i(x_0)}{\sqrt{d}{{L_{\max}}}}$ and \eqref{eq: gradient approximation error}, we have
$$\left\|\Delta^{\nu^*_0}_i(x)\right\|_{2} \leq \frac{\ell_{\min}}{2}$$
and thus 
\begin{equation}
\label{eq: first_order_inequality}
\begin{aligned}
\nabla^{\nu^*_0}f_i(x_0)^\top(x-x_0)=&(\nabla f_i(x_0)+\Delta_i^{\nu^*_0}(x))^\top(x-x_0)\\
\leq&L_{i,\mathrm{inf}} \|x-x_0\|+\frac{\ell_{\min}}{2}\|x-x_0\|
\end{aligned}
\end{equation}
By summing up \eqref{eq: second_order_inequality} and \eqref{eq: first_order_inequality}, we have for any $x\in \mathcal{T}^{(0)}(x_0)$
$$F^M_i(x) \leq f_i(x_0)+ {{L_i}}\|x-x_0\|=F^L_i(x)\leq 0,$$
and thus $x\in \mathcal{S}^{(0)}(x_0)$. \hfill$\blacksquare$

\section{Proof of Theorem \ref{thm: main_theorem}}
\label{sec: 1st argument of thm2}
Proof of Point 1. Given any $k$, we have $x_k\in \mathcal{S}^{(k)}(x_k)$ and $x_{k+1} = \argmin_{x\in \mathcal{S}^{(k)}(x_{k})} f_0(x)+\mu \|x-x_k\|^2$. Thus, 
\begin{equation}
\label{eq:imp_inequality}
\begin{aligned}
&f_0(x_{k+1})+\mu\|x_{k+1}-x_{k}\|^2 \\
\leq\;&  f_0(x_{k})+\mu\|x_{k}-x_{k}\|^2= f_0(x_k).
\end{aligned}
\end{equation}


Proof of Point 2. For $k\geq 0$, one has $f_0(x_k)\leq f_0(x_0)< \beta$ according to Assumption~\ref{ass: bounded_sublevel}. Now we know $\{x_k\}_{k\geq 1}$ is within the set $\mathcal{P}_\beta$. Due to the boundedness of the set $\mathcal{P}_\beta$, we can use Bolzanoâ€“Weierstrass theorem to conclude that there exists a subsequence of $\{x_k\}_{k\geq 1}$ that converges. Hence, $\{x_k\}_{k\geq 1}$ has at least one accumulation point $x_c$. According to \eqref{eq:imp_inequality}, $f_0(x_{k+1})\leq  f_0(x_1)-\mu\sum_{i=1}^k \|x_{i+1}-x_{i}\|^2$. Since $f_0(x)$ is a continuous function on the compact set $\mathcal{P}_\beta$, $\mathrm{inf}_{x\in\mathcal{P}_\beta} f_0(x)>-\infty$. Therefore, $\sum_{i=1}^\infty \|x_{i+1}-x_{i}\|^2<\infty$ and $\|x_{k+1}-x_{k}\|$ converges to 0.



Proof of Point 3. The sequence $\{f_0(x_k)\}_{k\geq 1}$ converging to $f_0(x_c)$ is a direct consequence of Point 2 in Theorem \ref{thm: main_theorem} and the continuity of $f_0(x)$. \hfill$\blacksquare$

\section{Preliminary results towards the proof of Theorem \ref{thm: accumulationKKT}}
\label{sec: preliminary results for Lemma xcandlambdac}
\begin{lemma}
\label{lmm: preliminary results for Lemma xcandlambdac}
If Assumption \ref{ass:LICQ} holds, then

1. there exists $x\in\Omega$ that is strictly feasible with respect to $\mathcal{S}(x_c)$, i.e. for any $i\geq 1$, $f^c_i(x)<0$ where
\begin{equation*}
f^c_i(x):=f_i(x_c)+\nabla f_i(x_c)^\top (x-x_c)+2M_i\|x-x_c\|^2.
\end{equation*}
For any $x\in \Omega$ verifying $f^c_i(x)<0$ for any $i$, there exists $k\in \mathbb{N}$ such that $x$ belongs to $\mathcal{S}^{(k)}(x_k)$;

2. there exists $x_s\in \mathcal{S}(x_c)$ such that $x_s\neq x_c$. For any such $x_s$ and any $0<t<1$, we let $x(t) = tx_c+(1-t)x_s$ and have that $x(t)$ is strictly feasible with respect to $\mathcal{S}(x_c)$. 
\end{lemma}
\textbf{Proof of Point 1}. We let $\mathcal{A}(x_c)=\{i_1,\ldots,i_l\}$. There exists $y\in \mathbb{R}^d$ such that 
\begin{equation}
\label{eq: steering}
Jy = \begin{bmatrix} -1\\ \vdots \\ -1\end{bmatrix}\text{, where } J=\begin{bmatrix}\nabla f_{i_1}(x_c)^\top \\
\vdots \\ \nabla f_{i_l}(x_c)^\top\end{bmatrix},
\end{equation}
because $J$ is full row rank due to LICQ. For any $y$ satisfying~\eqref{eq: steering}, if $\epsilon_0 = 1/(4M_{\max}\|y\|)$, then, for any $\epsilon<\epsilon_0$, $x = x_c+\epsilon y/\|y\|$ and $i\in \mathcal{A}(x_c),$
\begin{equation*}
f^c_i(x)=0-\epsilon/\|y\|+2M_i\epsilon^2< 0.
\end{equation*}
Since $f_i(x_c)<0$ for any $i\notin \mathcal{A}(x_c)$, there exists $\epsilon_c>0$ such that, for $\epsilon<\epsilon_c$ and $x = x_c+\epsilon_c y/\|y\|$, $f^c_i(x)<0$ for any $i\notin \mathcal{A}(x_c)$. Thus, with $\epsilon = \min\{\epsilon_0,\epsilon_c\}$ and $x = x_c+\epsilon y/\|y\|$,  we have $f^c_i(x)<0$ for any $i$. Since $x_c$ is an accumulation point, there exists $k\in \mathbb{N}$ such that $x$ belongs to $\mathcal{S}^{(k)}(x_k)$. $\hfill\blacksquare$

\textbf{Proof of Point 2}. We utilize the first point and the fact that $x_c$ is not strictly feasible with respect to $\mathcal{S}(x_c)$ to conclude that there exists $x_s\in \mathcal{S}(x_c)$ verifying $x_s\neq x_c$. Considering that $f^c_i(x)$ is strongly convex, we have, for any $i$ and any $0<t<1$, $ f^c_i(x(t))<\max\{f^c_i(x_c),f^c_i(x_s)\}\leq 0. $ $\hfill\blacksquare$

Before stating another preliminary result, we have the following notations based on the feasible region $\mathcal{S}^{(k)}(x_k)$ of the subproblem \eqref{eq: starstar} of Algorithm \ref{alg:sslo}. We define for strictly feasible $x\in \Omega$,
\begin{equation}
\label{eq: center and radius}
\begin{aligned}
O^{(k)}_i(x) :=& x-\frac{\nabla^{\nu^*_{k}} f_i(x)}{2M_i},\\ 
\left(r^{(k)}_i(x)\right)^2 :=&-\frac{f_i(x)}{M_i}+\frac{\|\nabla^{\nu^*_{k}} f_i(x)\|^2}{4M_i^2},
\end{aligned}
\end{equation} 
which allows us to write $$\mathcal{S}^{(k)}_i(x_k) = \mathcal{B}_{r^{(k)}_i(x_k)}(O^{(k)}_i(x_k)).$$
We let $\{x_{k_p}\}_{p\geq 1}$ be a subsequence converging to $x_c$. Since $\{\nu^*_k\}_{k\geq 1}$ converges to 0 (see \eqref{eq: stepsize_2}), we have 
\begin{equation}
\label{eq: convergence_of_origin_radius}
O^{(k)}_i(x_{k})\rightarrow O_i(x_c),\text{ }r^{(k)}_i(x_{k})\rightarrow r_i(x_c)\text{ as }k\rightarrow \infty,
\end{equation}
where 
$$O_i(x_c) := x_c-\frac{\nabla f_i(x_c)}{2M_i} \text{, } \left(r_i(x_c)\right)^2 :=-\frac{f_i(x)}{M_i}+\frac{\|\nabla f_i(x_c)\|^2}{4M_i^2}.$$ 
Then, we write
$$ \mathcal{S}_i(x_c) := \mathcal{B}_{r_i(x_c)}(O_i(x_c)),\mathcal{S}(x_c):=\bigcap^m_{i=1}\mathcal{S}_i(x_c).$$ 
With these notations, we can state and prove the following lemma.
\begin{lemma}
\label{lmm: non_empty_interior}
Under Assumption \ref{ass:LICQ}, the accumulation point $x_c$, where LICQ holds, is the unique optimum of the convex optimization 
\begin{equation}
\label{eq: x_c_optimization}
\min_{x\in \mathcal{S}(x_c) } f_0(x)+\mu\|x-x_c\|^2.
\end{equation}
Moreover, the optimizer $\lambda_c$ for the dual variable of \eqref{eq: x_c_optimization} is also unique.
\end{lemma}
\textbf {Proof.} We prove the optimality of $x_c$ by contradiction. Assume $x_c$ is not the optimum of \eqref{eq: x_c_optimization}, then there exists $x_s\in \mathcal{S}(x_c)$ verifying $f_0(x_s)+\mu\|x_s-x_c\|^2< f_0(x_c)$. According to the second point of Lemma \ref{lmm: preliminary results for Lemma xcandlambdac} in Appendix \ref{sec: preliminary results for Lemma xcandlambdac} and the continuity of $f_0(x)$, there exists $0<t<1$ such that with $x(t) = tx_c+(1-t)x_s$ we have $f_0(x(t))+\mu\|x(t)-x_c\|^2< f_0(x_c)$ and $x(t)$ is strictly feasible with respect to $\mathcal{S}(x_c)$. We let $\{x_{k_p}\}_{p\geq 1}$ be a subsequence of $\{x_k\}_{k\geq 1}$ that converges to $x_c$. Considering the first point of Lemma \ref{lmm: preliminary results for Lemma xcandlambdac}, there exists $p$ such that $x(t)\in \mathcal{S}^{(k_p)}(x_{k_p})$. Because of the convergence of the subsequence, we can assume without loss of generality that $p$ is sufficiently large so that $f_0(x(t))+\mu\|x(t)-x_{k_p}\|^2< f_0(x_c)$. Due to the optimality of $x_{k_p+1}$ for the problem \eqref{eq: starstar} in Algorithm~\ref{alg:sslo} when $k=k_p$, we have $f_0(x_{k_p+1})+ \mu\|x_{k_p+1}-x_{k_p}\|^2<f_0(x_c)$, which contradicts the monotonicity of $\{f_0(x_k)\}_{k\geq 1}$ in Theorem~\ref{thm: main_theorem}.  Due to optimality of $x_c$ and LICQ, there exists $\lambda_c\in \mathbb{R}^m$ such that $(x_c,\lambda_c)$ is a KKT pair of \eqref{eq: x_c_optimization}.

We prove the uniqueness of $x_c$ and $\lambda_c$ also by contradiction. Assume there exists $x_o\in \mathcal{S}(x_c)\setminus\{x_c\}$ such that  $f_0(x_o)+\mu\|x_o-x_c\|^2= f_0(x_c)$. Due to the strong convexity of the function $f_0(x)+\mu\|x-x_c\|^2$, we know
$$f_0(\frac{x_o+x_c}{2})+\mu\|\frac{x_o+x_c}{2}-x_c\|^2< f_0(x_c),$$
which contradicts the optimality of $x_c$ for \eqref{eq: x_c_optimization}. Assume $(x_c,\lambda_{c,1})$ and $(x_c,\lambda_{c,2})$ are two KKT pairs of \eqref{eq: x_c_optimization} with $\lambda_{c,1}\neq \lambda_{c,2}$, then for $j=1,2$, $\lambda_{c,j}^{(i)}=0$ for any $i\neq \mathcal{A}(x_c)$,
$$ \sum^m_{i=1}\lambda_{c,j}^{(i)}\nabla f_i(x_c) = - \nabla f_0(x_c) $$
and thus 
$$ \sum^m_{i=1}(\lambda_{c,1}^{(i)}-\lambda_{c,2}^{(i)})\nabla f_i(x_c)=0.$$
This contradicts LICQ at $x_c$ since $\lambda_{c,1}-\lambda_{c,2}\neq 0.$ \hfill$\blacksquare$

\section{Proof of Theorem \ref{thm: accumulationKKT}}
\label{sec: proof_of_accumulationKKT}
According to Lemma \ref{lmm: non_empty_interior}, there exists a $\lambda_c\in\mathbb{R}^m$ such that $(x_c,\lambda_c)$ is a KKT pair of \eqref{eq: x_c_optimization}, i.e., 
$$
\begin{aligned}
&\nabla f_0(x_c) + \sum_{i\in\mathcal{A}(x_c)}\lambda_c^{(i)}\nabla f_i(x_c) = 0 \\
\text{and }\; &\lambda_c^{(i)} = 0\text{ for }i\notin\mathcal{A}(x_c)\text{, } 
\end{aligned}
$$ 
which coincides with KKT conditions of \eqref{eq: optimization problem}. Thus, $(x_c,\lambda_c)$ is also a KKT pair of of \eqref{eq: optimization problem}. Following the same arguments used in the proof of Lemma \ref{lmm: non_empty_interior}, one can exploit LICQ to show that there does not exist $\lambda_{c,2}\neq \lambda_c$ such that $(x_c,\lambda_{c,2})$ is a KKT pair of \eqref{eq: optimization problem}.\hfill$\blacksquare$

\section{Geometric illustration of an upperbound to $\|\lambda_c\|_\infty$}
\label{sec: characterization of lambda}

We consider an instance of the optimization problem \eqref{eq: optimization problem} where $d=2$, the feasible region is convex, and $(x_c,\lambda_c)$ is a KKT pair. We only consider the non-degenerate case where $\mathcal{A}(x_c)=\{1,2\}$ and assume LICQ holds at $x_c$, i.e., $\nabla f_i(x_c)$ are linearly independent for $i=1,2.$ The objective and constraint functions are normalized at $x_c$, i.e., $\|\nabla f_i(x_c)\| = 1$ for $i\in\mathbb{Z}^{2}_{0}.$ Then, we use coordinate transformation such that $\nabla f_0(x_c) = \begin{bmatrix}0 &  -1\end{bmatrix}^\top.$ Since $\mathcal{A}(x_c)=\{1,2\}$, the KKT pair $(x_c,\lambda_c)$ satisfies that $\lambda_c^{(1)},\lambda_c^{(2)}\geq 0$ and
\begin{equation}
\label{eq: example_kkt}
\begin{aligned}
 f_1(x_c)\leq 0, \text{ } f_2(x_c)&\leq 0\\
\nabla f_0(x_c)+\lambda^{(1)}_c\nabla f_1(x_c)+\lambda^{(2)}_c\nabla f_2(x_c) & = 0\\
 \lambda^{(1)}_c f_1(x_c) = 0,\text{ } \lambda^{(2)}_c f_2(x_c) & = 0.
\end{aligned}
\end{equation}
Let $\theta_i$ be the angle between $-\nabla f_0(x_c)$ and $\nabla f_i(x_c)$ for $i = 1,2.$ Due to the convexity of the feasible region, $0<\theta_1+\theta_2<\pi.$ By solving \eqref{eq: example_kkt}, we have that 
$$\lambda^{(1)}_c = \frac{|\sin \theta_2|}{\sin(\theta_1+\theta_2)},\;\lambda^{(2)}_c = \frac{|\sin \theta_1|}{\sin(\theta_1+\theta_2)}.$$
We illustrate in Fig. \ref{fig:illustration} how to construct $\theta_1$ and $\theta_2$.

We notice that  
$$\|\lambda_c\|_\infty<(\sin\theta)^{-1},$$
where $\theta = \pi -\theta_1-\theta_2$ is the angle between the two lines $l_1:=\{x:(x-x_c)^\top\nabla f_1(x_c)=0\}$ and $l_2:=\{x:(x-x_c)^\top\nabla f_2(x_c)=0\}$. These two lines are actually the boundaries formed by the constraint functions $f_1(x)$ and $f_2(x)$ linearized at $x=x_c$. From the above conclusions, we see that for 2-dimensional optimization problems we need a large $\Lambda$ to satisfy Assumption \ref{ass: magnitude_dual_variable} only when the angle $\theta$ is small.
\begin{figure}[htbp!]
    \centering
\includegraphics[width=0.7\linewidth]{illustration.pdf}
    \caption{The illustration of angles $\theta_1$ and $\theta_2$}
    \label{fig:illustration}
\end{figure}

\section{Proof of Lemma \ref{lmm: convergence}}
\label{sec: proof of convergence lemma}
We assume $x_\tau$ is an accumulation point of $\{x_k\}_{k\geq 1}$ and is also a strict local minimizer. We show the convergence of $\{x_k\}_{k\geq 1}$ by contradiction and assume that $\mathcal{C}\setminus \{x_\tau\}\neq \emptyset$, where $\mathcal{C}$ is the set of accumulation points of $\{x_k\}_{k\geq 1}$. Then, there exists $\epsilon>0$ such that $\mathcal{C}\cap (\Omega\setminus\mathcal{B}_\epsilon(x_\tau))\neq \emptyset$ and any $x\in \mathcal{B}_\epsilon(x_\tau)\setminus\{x_\tau\}$ verifies $f_0(x_\tau)<f_0(x)$. Since the sphere $\mathcal{SP}_\epsilon(x_\tau)=\{x:\|x-x_\tau\| = \epsilon\}$ is compact, we let $\sigma = \inf_{x\in\mathcal{SP}_\epsilon(x_\tau)} f_0(x)$ and have $\sigma>f_0(x_\tau)$. Therefore, there exists $k_\alpha>0$ such that $f_0(x_{k_\alpha})<(\sigma+f_0(x_\tau))/2$. 

Since there exists an accumulation point outside $\mathcal{B}_\epsilon(x_\tau)$ and $\{x_{k+1}-x_k\}_{k\geq 1}$ converges to 0, we can find $k_\beta>k_\alpha$ such that $x_{k_\beta}\in \mathcal{B}_\epsilon(x_\tau)$, $x_{k_\beta+1}\notin \mathcal{B}_\epsilon(x_\tau)$ and $\|x_{k_\beta+1}-x_{k_\beta}\|\leq (\sigma-f_0(x_\tau))/(4L_{\max})$. Let $\tilde{x} = \{x: \text{there exists }t\in[0,1] \text{ such that ${x} = tx_{k_\beta}+(1-t)x_{k_\beta+1}$}\}\cap \mathcal{SP}_\epsilon(x_\tau)$, i.e., $\tilde{x}$ is the intersection of $\mathcal{SP}_\epsilon(x_\tau)$ and the line segment between $x_{k_\beta}$ and $x_{k_\beta+1}$. Then, $\|x_{k_\beta}-\tilde{x}\|\leq (\sigma-f_0(x_\tau))/(4L_{\max})$ and thus
\begin{equation*}
\begin{aligned}
f_0(x_{k_\beta})&\geq f_0(\tilde{x})-\frac{\sigma-f_0(x_\tau)}{4}\\
&\geq \sigma -\frac{\sigma-f_0(x_\tau)}{4}\\
&> (\sigma+f_0(x_\tau))/2> f_0(x_{k_\alpha}),
\end{aligned}
\end{equation*}
which contradicts with the monotonicity of $\{f_0(x_k)\}_{k\geq 1 }$ shown in Theorem \ref{thm: main_theorem}. \hfill$\blacksquare$
  



\section{Proof of Theorem \ref{thm: algorithm_termination}}
\label{sec: algorithm_termination}

Since $(x_c,\lambda_c)$ is a KKT pair where $\|\lambda_c\|_{\infty}<\Lambda$, by using triangular inequalities on the norm terms defining $\delta_1(k,\lambda_c)$, we obtain 
\begin{align*}
&\delta_1(k,\lambda_c)\\
\leq & \|{\nabla} f_0(x_c)  + \sum^{m}_{i=1} \lambda_{c}^{(i)}{\nabla} f_i\left(x_{c}\right) \|+ \|{\nabla} f_0(x_k) - {\nabla} f_0(x_c) \| \\
&+4\mu \|x_{k+1}-x_k\|
+\sum^{m}_{i=1} \Lambda\Big(\|{\nabla}^{\nu_{k}^*} f_i\left(x_{k}\right)-{\nabla} f_i\left(x_{k}\right)\| \\&+ \|{\nabla} f_i\left(x_{k}\right)- {\nabla} f_i\left(x_{c}\right)\|\Big)+4m{M_{\max}}\Lambda\|x_{k+1}-x_{k}\|.
\end{align*}
Similar computations for $\delta^{(i)}_2(k,\lambda_c)$ give
\begin{align*}
\delta^{(i)}_2(k,\lambda_c)
\leq&  |\lambda^{(i)}_c f_i(x_c)|+\Lambda|f_i(x_k)-f_i(x_c)| 
\\&+\Lambda\Big( L_i|x_{k+1}-x_k|+2M_i\|x_{k+1}-x_k\|^2\Big).
\end{align*}
We let $\{x_{k_p}\}_{p\geq 1}$ be an subsequence that converges to $x_c$. Considering that the gradient estimation error converges to 0 (see \eqref{eq: stepsize_2} and Lemma \ref{lmm: gradient estimation error}), we know the term $\|{\nabla}^{\nu_{k_p}^*} f_i\left(x_{k_p}\right)-{\nabla} f_i\left(x_{k_p}\right)\|$ converges to 0 as $p$ goes to infinity. Therefore, we have $$\lim_{p\rightarrow \infty}\delta_1(k_p,\lambda_c) = 0\text{  and }\lim_{p\rightarrow \infty}\max_{1\leq i \leq m}|\delta^{(i)}_2(k_p,\lambda_c)| = 0.$$
Thus, for any $k_0$ and $\eta>0$, one can find $k_{\Lambda}>k_0$ such that $\max\{\delta_1(k_{\Lambda},\lambda_c),\max_{1 \leq i\leq m}|\delta^{(i)}_2(k_{\Lambda},\lambda_c)| \}<\eta/2$. For $k=k_{\Lambda}$ in SZO-QQ, we have that $\lambda_{k_{\Lambda}+1}$, the solution to \eqref{eq: SP2}, has an infinite norm less than $2\Lambda$ because $\lambda_c$ is a feasible solution to \eqref{eq: SP2} and $\|\lambda_c\|_\infty<2\Lambda$, which is to say that the second termination condition of Algorithm \ref{alg:sslo} is satisfied when $k=k_{\Lambda}$.

Since $\|x_{k+1}-x_k\|$ converges to 0 as $k$ goes to infinity (see Theorem \ref{thm: main_theorem}), we can choose $k_0$ to be sufficiently large so that, for any $k>k_0$, $\|x_{k+1}-x_k\|\leq \xi$. Thus, when $k=k_{\Lambda}$, the two termination conditions are satisfied. \hfill$\blacksquare$

\section{Proof of Theorem \ref{prop: eta-KKT} }
\label{sec: proof_of_xi}
The pair $(\tilde{x},\tilde{\lambda})$ and the index $\tilde{k}$ returned by Algorithm \ref{alg:sslo} satisfy $\tilde{x} = x_{\tilde{k}}$ and 
\begin{equation}
\label{eq: inequality_delta}
\max\Big\{\delta_1(\tilde{k},\tilde{\lambda}), \max\{\delta^{(i)}_2(\tilde{k},\tilde{\lambda}):i\geq 1 \}\Big\}\leq\frac{\eta}{2}.
\end{equation}
By using triangular inequalities we have for any $i$,
\begin{align}\notag
& \|{\nabla}^{\nu_{\tilde{k}-1}^*} f_i\left(x_{\tilde{k}-1}\right) - {\nabla} f_i\left(x_{\tilde{k}}\right)\|\\\notag
\leq & \|{\nabla}^{\nu_{\tilde{k}-1}^*} f_i\left(x_{\tilde{k}-1}\right) - {\nabla} f_i\left(x_{\tilde{k}-1}\right)\| \\\notag
&\qquad\qquad\qquad\qquad + \|{\nabla} f_i\left(x_{\tilde{k}}\right) - {\nabla} f_i\left(x_{\tilde{k}-1}\right)\|\\\label{eq:first_inequality}
\leq & \alpha \xi + L_i\xi.
\end{align}
Then, based on \eqref{eq: xi}, \eqref{eq: inequality_delta} and \eqref{eq:first_inequality}, we have
\begingroup\makeatletter\def\f@size{8}\check@mathfonts
\begin{align*}
&||\nabla f_0\left(x_{\tilde{k}}\right) +\sum^{m}_{i=1} \tilde{\lambda}^{(i)}{\nabla} f_i\left(x_{\tilde{k}}\right)\| \\
\leq & \Big\|\nabla f_0\left(x_{\tilde{k}}\right) +\sum^{m}_{i=1} \tilde{\lambda}^{(i)}\left({\nabla}^{\nu_{\tilde{k}-1}^*} f_i\left(x_{\tilde{k}-1}\right)+4M_i(x_{\tilde{k}}-x_{\tilde{k}-1})\right)\\
&+2\mu(x_{\tilde{k}}-x_{\tilde{k}-1}) \Big\| + \|2\mu(x_{\tilde{k}}-x_{\tilde{k}-1})\|\\
& +2\Lambda \sum^m_{i=1}\Big(4\left\|M_i(x_{\tilde{k}}-x_{\tilde{k}-1})\right\| + \left\|  {\nabla}^{\nu_{\tilde{k}-1}^*} f_i\left(x_{\tilde{k}-1}\right) - {\nabla} f_i\left(x_{\tilde{k}}\right)\right\|\Big)\\
\leq & \eta/2 + 2\Lambda\sum^m_{i=1}\left(5M_i\xi+\alpha_i \nu^*_{\tilde{k}-1}\right) +2\mu\xi \leq  \eta,
\end{align*}
\endgroup
and
\begin{align*}
&\left\|\tilde{\lambda}^{(i)}f_i(x_{\tilde{k}})\right\| \\
\leq & \Big\|\tilde{\lambda}^{(i)} \Big(f_i(x_{\tilde{k}-1})+{\nabla}^{\nu_{\tilde{k}-1}^*} f_i\left(x_{\tilde{k}-1}\right)(x_{\tilde{k}}-x_{\tilde{k}-1})\\
& +2M_i\|x_{\tilde{k}}-x_{\tilde{k}-1}\|^2\Big)\Big\| + 
2\Lambda\Big(\|f_i(x_{\tilde{k}}) - f_i(x_{\tilde{k}-1})\|+\\
&\|{\nabla}^{\nu_{\tilde{k}-1}^*} f_i\left(x_{\tilde{k}-1}\right) - {\nabla} f_i\left(x_{\tilde{k}-1}\right)\|\cdot \|x_{\tilde{k}}-x_{\tilde{k}-1}\|+ \\
& \|\nabla f_i(x_{\tilde{k}-1})\|\cdot\|x_{\tilde{k}}-x_{\tilde{k}-1}\| + 2M_i\|x_{\tilde{k}}-x_{\tilde{k}-1}\|^2\Big)\\
\leq & \eta/2 + 2\Lambda( 2L_i \xi + \alpha_i \xi^2   + 2M_i\xi^2)\\
\leq& \eta/2 + 2\Lambda( 2L_i + \alpha_i + 2M_i)\xi \leq \eta,
\end{align*}
which concludes the proof.
\hfill$\blacksquare$
\section{Proof of Lemma \ref{lmm: convergence of the dual variable}}
\label{sec: lambda_conv}

We start by charaterizing $\mathcal{D}_\lambda(y,\nu)$. Since any $\lambda\in\mathcal{D}_\lambda(y,\nu)$ is an optimal solution to the dual variable, we have that
\[
\begin{aligned}
\mathcal{D}_\lambda&(y,\nu) :=\\
& \argmax_{\lambda\geq 0}\min_{x} f_0(x)+\mu \|x-y\|^2
+\sum_{i=1}^m\lambda^{(i)}\Big(f_i(y)\\
&\quad + \Big(\Delta^\nu_i(y) + \nabla f_i(y)\Big)^\top(x-y) +2M_i\|x-y\|^2\Big).
\end{aligned}
\]
By computing the inner minimization problem which is an unconstrained convex quadratic programming, we know that there exist $p\in\mathbb{R}^{m\times 1}_{\geq 0}$ and $a\in\mathbb{R}_{>0}$, independent of $y$ and $\nu$, such that
\[
\mathcal{D}_\lambda(y,\nu)= \argmax_{\lambda\geq 0}G(\lambda,y,\nu),
\]
where for $\lambda\in\mathbb{R}^m_{\geq0}$, 
\[
G(\lambda,y,\nu):=\frac{\lambda^\top Q(y,\nu)\lambda + q^\top(y,\nu)\lambda+b(y,\nu)}{p^\top \lambda + a},
\] 
the functions $Q(y,\nu)\in\mathbb{R}^{m\times m}, q(y,\nu)\in\mathbb{R}^{m\times 1}, b(y,\nu)\in\mathbb{R}$ are continuous in $(y,\nu)$ and $Q(y,\nu)$ is negative definite. 

From the continuity of $Q(y,\nu), q(y,\nu)$ and $b(y,\nu)$, the function $G(\lambda,y,\nu)$ is continuous in all arguments for $\lambda\geq 0$. Due to the continuity and  the uniqueness of the optimal dual solution $\mathcal{D}_\lambda(x_c,0) = \{\lambda_c\}$ (see Lemma \ref{lmm: non_empty_interior}), we can use perturbation theory \cite[Proposition 4.4]{bonnans2013perturbation} to conclude that $\mathcal{C}_{\lambda}(y,\nu)$ is upper semicontinuous at $(y,\nu)=(x_c,0)$. Considering the definition of upper semicontinuity and the convergence of $(x_k,\nu^*_k)$ to $(x_c,0)$, for any $\delta>0$, there exists $k_\delta>0$ such that $\mathcal{D}_\lambda(x_k,\nu^*_k)\subset\mathcal{B}_\delta(\lambda_c)$ for any $k>k_\delta$. Since $\lambda^\circ_{k+1}\in\mathcal{D}_\lambda(x_k,\nu^*_k)\subset\mathcal{B}_\delta(\lambda_c) $, we have $\lambda^\circ_{k+1}\in\mathcal{B}_\delta(\lambda_c)$ for any $k>k_\delta$.
\hfill$\blacksquare$
\section{Proof of Theorem \ref{thm: complexity}}
\label{sec: proof_of_complexity}
According to Lemma \ref{lmm: convergence of the dual variable}, there exists $\bar{k}>0$ such that $\|\lambda^\circ_{k+1}\|_\infty\leq 2\Lambda$ for any $k\geq \bar{k}$. Since $\lambda^\circ_{k+1}$ is a feasible solution of \eqref{eq: SP2} in Algorithm \ref{alg:sslo}, $\lambda_{k+1}$, the optimal solution of \eqref{eq: SP2}, also satisfies  $\|\lambda_{k+1}\|_\infty\leq 2\Lambda$. 

We let $\bar{\xi} := \inf_{k\leq \bar{k}} \|x_{k+1}-x_k\|$, $\bar{\eta} := \inf\{\eta: h(\eta)\geq \bar{\xi}/2\}$ and consider the case where $\eta<\bar{\eta}$. We first notice that if $\|x_{k+1}-x_k\|\leq h(\eta)$, we have $\|x_{k+1}-x_{k}\|<\bar{\xi}$ and thus $k> \bar{k}$. We then let $\mathcal{K}(\eta) := \max\{k:\|x_{k+1}-x_k\|>h(\eta)\}+1$. Since $\|x_{\mathcal{K}(\eta)+1}-x_{\mathcal{K}(\eta)}\|\leq h(\eta)$, we have that $\mathcal{K}(\eta)>\bar{k}$ and thus $\|\lambda_{k+1}\|_\infty\leq 2\Lambda$, which is equivalent to say that with $k = \mathcal{K}(\eta)$, the two termination conditions in Algoirthm~\ref{alg:sslo} are satisfied. Then $\tilde{k}$, the iteration number returned by Algorithm~\ref{alg:sslo}, verifies that $\tilde{k}\leq \mathcal{K}(\eta)+1$. According to \eqref{eq: monotonicity_inequality},
\begin{equation}
\begin{aligned}
f_0(x_0)- \inf\{f_0(x): x\in \Omega\}&\geq f_0(x_0)-  f_0(x_{\mathcal{K}(\eta)})\\
&\geq \mu\mathcal{K}(\eta)(h(\eta))^2
	\end{aligned}
\end{equation}
and thus $\tilde{k}\leq \mathcal{K}(\eta)+1\leq \overline{\mathcal{K}}(\eta)+1$. Therefore, according to the definition of $h(\eta)$ in \eqref{eq: xi} there exists $A_1>0$ such that $\mathcal{K}(\eta)+1\leq A_1((L_{\max}+M_{\max})/\eta)^{2}$. 

For $\eta\geq\bar{\eta}$, we let $A_2 = \sup_{\eta\geq \bar{\eta}}\frac{(\mathcal{K}(\eta)+1)(L_{\max}+M_{\max})^2}{\eta^2}$. According to the definition of $\mathcal{K}(\eta)$, we have that $\mathcal{K}(\eta)$ is monotonously decreasing with respect to $\eta$. Therefore, $\mathcal{K}(\eta)\leq \mathcal{K}(\bar{\eta})\leq  \overline{\mathcal{K}}(\bar{\eta})$ and thus $A_2$ is finite. Since $\mathcal{K}(\eta)+1\leq A_2((L_{\max}+M_{\max})/\eta)^{2}$, by letting $A = \max\{A_1,A_2\}$, we have for any $\eta>0$, $\mathcal{K}(\eta)+1\leq A((L_{\max}+M_{\max})/\eta)^{2}.$ 	\hfill$\blacksquare$}

\end{document}