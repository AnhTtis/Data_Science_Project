{
    "arxiv_id": "2303.11828",
    "paper_title": "The Treasure Beneath Multiple Annotations: An Uncertainty-aware Edge Detector",
    "authors": [
        "Caixia Zhou",
        "Yaping Huang",
        "Mengyang Pu",
        "Qingji Guan",
        "Li Huang",
        "Haibin Ling"
    ],
    "submission_date": "2023-03-21",
    "revised_dates": [
        "2023-03-22"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Deep learning-based edge detectors heavily rely on pixel-wise labels which are often provided by multiple annotators. Existing methods fuse multiple annotations using a simple voting process, ignoring the inherent ambiguity of edges and labeling bias of annotators. In this paper, we propose a novel uncertainty-aware edge detector (UAED), which employs uncertainty to investigate the subjectivity and ambiguity of diverse annotations. Specifically, we first convert the deterministic label space into a learnable Gaussian distribution, whose variance measures the degree of ambiguity among different annotations. Then we regard the learned variance as the estimated uncertainty of the predicted edge maps, and pixels with higher uncertainty are likely to be hard samples for edge detection. Therefore we design an adaptive weighting loss to emphasize the learning from those pixels with high uncertainty, which helps the network to gradually concentrate on the important pixels. UAED can be combined with various encoder-decoder backbones, and the extensive experiments demonstrate that UAED achieves superior performance consistently across multiple edge detection benchmarks. The source code is available at \\url{https://github.com/ZhouCX117/UAED}",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.11828v1"
    ],
    "publication_venue": "CVPR2023"
}