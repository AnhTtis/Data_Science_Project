%%%%%%%%% Related Work
\section{Related Work}

\bdtitle{Semi-supervised learning (SSL) LiDAR semantic segmentation} is a special instance of weak supervision that combines a small amount of labeled, with a large amount of unlabeled point cloud during training. Numerous approaches have been explored for LiDAR semantic segmentation. 
Projection-based approaches~\cite{kong2022lasermix,wu2018squeezesega,wu2019squeezesegv2a,milioto2019rangenet,kochanov2020kprnet,xu2020squeezesegv3,liong2020amvnet} make full use of 2D-convolution kernels by using range or other 2D image-based spherical coordinate representations of point clouds. Conversely, voxel-based approaches~\cite{tang2020searching,zhu2021cylindrical,kong2022lasermix,Unal_2022_CVPR} transform irregular point clouds to regular 3D grids and then apply 3D convolutional neural networks with a better balance of the efficiency and effectiveness. Pseudo-labeling is generally applied to alleviate the side effect of intra-class negative pairs in feature learning from the teacher network~\cite{jiang2021guided,yan2021sparse,Unal_2022_CVPR,kong2022lasermix}. However, such methods only utilize samples with reliable predictions and thus ignore the valuable information that unreliable predictions carry. In our work, we combined a novel SSL framework with the mean teacher paradigm ~\cite{tarvainen2017mean}, demonstrating the utilization of unreliable pseudo-labels to improve segmentation performance.

\begin{figure*}[thp]
    \centering
    \includegraphics[width=1\textwidth]{figures/model_2.pdf}
     \caption{Our proposed architecture for unreliable pseudo-labels LiDAR semantic segmentation involves three stages: training, pseudo-labeling, and distillation with unreliable learning. We apply {\samplshort} sampling before training the Mean Teacher on available annotations.}
    \vspace{-0.3cm}
    \label{fig:model}
\end{figure*}

\bdtitle{Depthwise separable convolution}\cite{sifre2014rigidmotiona} is a depthwise convolution followed by a pointwise convolution, to reduce both model size and complexity. Being a more computationally efficient alternative than standard convolution, it is used for mobile applications~\cite{howard2017mobilenets,sandler2018mobilenetv2,howard2019searching} and hardware accelerators~\cite{masters2021making}. Furthermore, it is a building block of Xception~\cite{chollet2017xception}, a deep convolutional neural network architecture that achieves state-of-the-art performance on the ImageNet~\cite{deng2009imagenet} classification task, via more efficient use of model parameterization. In this work, we propose a novel sparse variant of depthwise separable convolution, which has both the efficiency advantages of depthwise separable convolution and those of sparse convolution for processing spatially-sparse data~\cite{graham20183d}.

\bdtitle{Temporal redundancy} is highly prevalent within video ~\cite{zhu2017deep,wang2022longshort} and radar~\cite{li2022exploiting} sequences alike. Existing semi-supervised 3D LiDAR segmentation methods~\cite{kong2022lasermix,Unal_2022_CVPR} utilize a passive uniform sampling strategy to filter unlabeled points from a fully-labeled point cloud dataset. Active learning frameworks handle the redundancy to reduce annotation or training efforts by selecting informative and diverse sub-scenes for label acquisition\cite{duong2017reducing,hu2022lidal,wu2021redala}.
We propose a novel temporal-redundancy-based sampling strategy with comparable time cost to uniform sampling, 
to reduce the inter-frame spatio-temporal redundancy and maximize data diversity.
