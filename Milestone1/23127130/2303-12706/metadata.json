{
    "arxiv_id": "2303.12706",
    "paper_title": "Multi-modal Variational Autoencoders for normative modelling across multiple imaging modalities",
    "authors": [
        "Ana Lawry Aguila",
        "James Chapman",
        "Andre Altmann"
    ],
    "submission_date": "2023-03-16",
    "revised_dates": [
        "2023-05-23"
    ],
    "latest_version": 3,
    "categories": [
        "cs.CV",
        "cs.LG"
    ],
    "abstract": "One of the challenges of studying common neurological disorders is disease heterogeneity including differences in causes, neuroimaging characteristics, comorbidities, or genetic variation. Normative modelling has become a popular method for studying such cohorts where the 'normal' behaviour of a physiological system is modelled and can be used at subject level to detect deviations relating to disease pathology. For many heterogeneous diseases, we expect to observe abnormalities across a range of neuroimaging and biological variables. However, thus far, normative models have largely been developed for studying a single imaging modality. We aim to develop a multi-modal normative modelling framework where abnormality is aggregated across variables of multiple modalities and is better able to detect deviations than uni-modal baselines. We propose two multi-modal VAE normative models to detect subject level deviations across T1 and DTI data. Our proposed models were better able to detect diseased individuals, capture disease severity, and correlate with patient cognition than baseline approaches. We also propose a multivariate latent deviation metric, measuring deviations from the joint latent space, which outperformed feature-based metrics.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.12706v1",
        "http://arxiv.org/pdf/2303.12706v2",
        "http://arxiv.org/pdf/2303.12706v3"
    ],
    "publication_venue": null
}