% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage[]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.
\newcommand{\method}{ContraSim}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{subcaption}
\usepackage{booktabs} % for professional tables
\usepackage{bm}
\usepackage{multirow}
\usepackage{xcolor}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\title{\method{} -- Analyzing Neural Representations Based on Contrastive Learning}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
\author{Adir Rahamim
\hspace{10em}
  Yonatan Belinkov \\
    \texttt{adir.rahamim@cs.technion.ac.il} \hspace{2em} 
  \texttt{belinkov@technion.ac.il} \\
  Technion -- Israel Institute of Technology}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{Adir Rahamim \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}

\begin{document}
\maketitle
\begin{abstract}
Recent work has compared neural network representations via similarity-based analyses to improve model interpretation.
  The quality of a similarity measure is typically evaluated by its success in assigning a high score to representations that are expected to be matched. 
  However, existing similarity measures perform mediocrely on standard benchmarks. 
  In this work, we develop a new similarity measure, dubbed \method{}, based on contrastive learning. In contrast to common closed-form similarity measures, \method{} learns a parameterized measure by using both similar and dissimilar examples. 
 We perform an extensive experimental evaluation of our method, with both language and vision models, on the standard layer prediction benchmark and two new benchmarks that we introduce: the multilingual benchmark and the image--caption benchmark. In all cases, \method{} achieves much higher accuracy than previous similarity measures, even when presented with challenging examples. Finally, \method{} is more suitable for the analysis of neural networks, revealing new insights not captured by previous measures.\footnote{Code is available at: \url{https://github.com/technion-cs-nlp/ContraSim}.}
\end{abstract}

\input{Sections_aaai/introduction.tex}
\input{Sections_aaai/related.tex}
\input{Sections_aaai/problem.tex}
\input{Sections_aaai/method.tex}
\input{Sections_aaai/evaluation_methods.tex}
\input{Sections_aaai/experiments.tex}
\input{Sections_aaai/conclusion.tex}
% Entries for the entire Anthology, followed by custom entries
\bibliography{custom}

\clearpage
\appendix
\input{Sections_aaai/appendix.tex}

\end{document}
