\noindent
In this work, we proposed a learned two-plane perspective prior which incorporates rough geometric constraints from 3D scene interpretations of 2D images to improve object detection. We demonstrated that (a) Geometrically defined spatial sampling prior significantly improves detection performance over multiple axes (accuracy, latency and memory) in terms of both single-frame accuracy and accuracy with real-time constraints over other methods. (b) Not only is our approach is more accurate when adaptively down-sampling at all scales, it degrades much more gracefully for small objects, resulting in latency and memory savings. (c) As our prior is learned end-to-end, we can improve a detector's performance at lower scales for ``free''. (d) Our approach generalizes better to new camera viewpoints and enables efficient city-scale sensing applications. Vanishing point estimation is the bottleneck of our approach~\cite{coughlan2000manhattan, zhou2019neurvps, lin2022deep, liu2021vapid} for general scenes, and increasing efficiency of its computation we will see substantial improvements. Investigating geometric constraints to improve other aspects of real-time perception systems as future work, like object tracking and trajectory understanding and forecasting, is promising. 

\noindent 
\textbf{Societal Impact} Our approach has strong implications for autonomous-driving and city-scale sensing for smart city applications, wherein efficient data processing would lead to more data-driven decision-making and public policies. However, privacy is a concern, and we shall release the datasets after anonymizing people and license plates.

\noindent 
\textbf{Acknowledgements:} This work was supported in part by an NSF CPS Grant CNS-2038612, a DOT RITA Mobility-21 Grant 69A3551747111 and by General Motors Israel.