\noindent
Real-time efficient perception is critical for autonomous navigation and city scale sensing. Orthogonal to architectural improvements, streaming perception approaches have exploited adaptive sampling improving real-time detection performance. In this work, we propose a learnable geometry-guided prior that incorporates rough geometry of the 3D scene (a ground plane and a plane above) to resample images for efficient object detection. This significantly improves small and far-away object detection performance while also being more efficient both in terms of latency and memory. For autonomous navigation, using the same detector and scale, our approach improves detection rate by \green{+4.1 $AP_{S}$} or \textbf{+$39\%$} and in real-time performance by \green{+5.3 $sAP_{S}$} or \textbf{+$63\%$} for small objects over state-of-the-art (SOTA). For fixed traffic cameras, our approach detects small objects at image scales other methods cannot. At the same scale, our approach improves detection of small objects by \textbf{$195\%$} (\green{+12.5 $AP_{S}$}) over naive-downsampling and \textbf{$63\%$} (\green{+4.2 $AP_S$}) over SOTA.