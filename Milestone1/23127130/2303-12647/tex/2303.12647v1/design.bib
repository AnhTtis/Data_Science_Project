@article{dow2010parallel,
  title={Parallel prototyping leads to better design results, more divergence, and increased self-efficacy},
  author={Dow, Steven P and Glassco, Alana and Kass, Jonathan and Schwarz, Melissa and Schwartz, Daniel L and Klemmer, Scott R},
  journal={ACM Transactions on Computer-Human Interaction (TOCHI)},
  volume={17},
  number={4},
  pages={1--24},
  year={2010},
  publisher={ACM New York, NY, USA}
}

@article{schon1984architectural,
  title={The architectural studio as an exemplar of education for reflection-in-action},
  author={Sch{\"o}n, Donald A},
  journal={Journal of Architectural Education},
  volume={38},
  number={1},
  pages={2--9},
  year={1984},
  publisher={Taylor \& Francis}
}

@article{kwon2022diffusion,
  title={Diffusion models already have a semantic latent space},
  author={Kwon, Mingi and Jeong, Jaeseok and Uh, Youngjung},
  journal={arXiv preprint arXiv:2210.10960},
  year={2022}
}
% Model references
@inproceedings{ramesh2021DallE,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@article{zhou2021lafite,
  title={Lafite: Towards language-free training for text-to-image generation},
  author={Zhou, Yufan and Zhang, Ruiyi and Chen, Changyou and Li, Chunyuan and Tensmeyer, Chris and Yu, Tong and Gu, Jiuxiang and Xu, Jinhui and Sun, Tong},
  journal={arXiv preprint arXiv:2111.13792},
  year={2021}
}

@article{nichol2021glide,
  title={Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
  author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  journal={arXiv preprint arXiv:2112.10741},
  year={2021}
}
% END model refernces

% Benchmark references
@inproceedings{lin2014microsoftCOCO,
  title={Microsoft COCO: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@phdthesis{yang2020profiling,
  title={Profiling Artificial Intelligence as a Material for User Experience Design},
  author={Yang, Qian},
  year={2020},
  school={Carnegie Mellon University}
}

@inproceedings{kantosalo2016modes,
  title={Modes for creative human-computer collaboration: Alternating and task-divided co-creativity},
  author={Kantosalo, Anna and Toivonen, Hannu},
  booktitle={Proceedings of the seventh international conference on computational creativity},
  pages={77--84},
  year={2016}
}

@article{ghajargar2018thinking,
  title={Thinking with interactive artifacts: Reflection as a concept in design outcomes},
  author={Ghajargar, Maliheh and Wiberg, Mikael},
  journal={Design Issues},
  volume={34},
  number={2},
  pages={48--63},
  year={2018},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}
@article{schon1968reflective,
  title={The reflective practitioner},
  author={Schon, Donald A},
  journal={New York},
  year={1968}
}
@book{fauconnier2008way,
  title={The way we think: Conceptual blending and the mind's hidden complexities},
  author={Fauconnier, Gilles and Turner, Mark},
  year={2008},
  publisher={Basic books}
}

@inproceedings{marks1997design,
  title={Design galleries: A general approach to setting parameters for computer graphics and animation},
  author={Marks, Joe and Andalman, Brad and Beardsley, Paul A and Freeman, William and Gibson, Sarah and Hodgins, Jessica and Kang, Thomas and Mirtich, Brian and Pfister, Hanspeter and Ruml, Wheeler and others},
  booktitle={Proceedings of the 24th annual conference on Computer graphics and interactive techniques},
  pages={389--400},
  year={1997}
}

@inproceedings{dasgupta2016remixing,
  title={Remixing as a pathway to computational thinking},
  author={Dasgupta, Sayamindu and Hale, William and Monroy-Hern{\'a}ndez, Andr{\'e}s and Hill, Benjamin Mako},
  booktitle={Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work \& Social Computing},
  pages={1438--1449},
  year={2016}
}

@inproceedings{marlow2014rookie,
  title={From rookie to all-star: professional development in a graphic design social networking site},
  author={Marlow, Jennifer and Dabbish, Laura},
  booktitle={Proceedings of the 17th ACM conference on Computer supported cooperative work \& social computing},
  pages={922--933},
  year={2014}
}

@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}


@Article{aguera2017ArtInAI,
AUTHOR = {Agüera y Arcas, Blaise},
TITLE = {Art in the Age of Machine Intelligence},
JOURNAL = {Arts},
VOLUME = {6},
YEAR = {2017},
NUMBER = {4},
ARTICLE-NUMBER = {18},
URL = {https://www.mdpi.com/2076-0752/6/4/18},
ISSN = {2076-0752},
ABSTRACT = {In this wide‐ranging essay, the leader of Google’s Seattle AI group and founder of the Artists and Machine Intelligence program discusses the long‐standing and complex relationship between art and technology. The transformation of artistic practice and theory that attended the 19th century photographic revolution is explored as a parallel for the current revolution in machine intelligence, which promises not only to mechanize (or democratize) the means of reproduction, but also of production.},
DOI = {10.3390/arts6040018}
}

@article{oviatt2000multimodalnatural,
author = {Oviatt, Sharon and Cohen, Philip},
title = {Perceptual User Interfaces: Multimodal Interfaces That Process What Comes Naturally},
year = {2000},
issue_date = {March 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {3},
issn = {0001-0782},
url = {https://doi.org/10.1145/330534.330538},
doi = {10.1145/330534.330538},
journal = {Commun. ACM},
month = {mar},
pages = {45–53},
numpages = {9}
}

@Article{mazzone2019ArtCreativityAI,
AUTHOR = {Mazzone, Marian and Elgammal, Ahmed},
TITLE = {Art, Creativity, and the Potential of Artificial Intelligence},
JOURNAL = {Arts},
VOLUME = {8},
YEAR = {2019},
NUMBER = {1},
ARTICLE-NUMBER = {26},
URL = {https://www.mdpi.com/2076-0752/8/1/26},
ISSN = {2076-0752},
ABSTRACT = {Our essay discusses an AI process developed for making art (AICAN), and the issues AI creativity raises for understanding art and artists in the 21st century. Backed by our training in computer science (Elgammal) and art history (Mazzone), we argue for the consideration of AICAN&rsquo;s works as art, relate AICAN works to the contemporary art context, and urge a reconsideration of how we might define human and machine creativity. Our work in developing AI processes for art making, style analysis, and detecting large-scale style patterns in art history has led us to carefully consider the history and dynamics of human art-making and to examine how those patterns can be modeled and taught to the machine. We advocate for a connection between machine creativity and art broadly defined as parallel to but not in conflict with human artists and their emotional and social intentions of art making. Rather, we urge a partnership between human and machine creativity when called for, seeing in this collaboration a means to maximize both partners&rsquo; creative strengths.},
DOI = {10.3390/arts8010026}
}

@misc{AIwinsst11:online,
  author = {Edwards, Benj},
  title = {AI wins state fair art contest, annoys humans},
  publisher = {Ars Technica},
  url = {https://arstechnica.com/information-technology/2022/08/ai-wins-state-fair-art-contest-annoys-humans/},
  month = {Aug},
  year = {2022},
  note = {(Accessed on 09/02/2022)}
}