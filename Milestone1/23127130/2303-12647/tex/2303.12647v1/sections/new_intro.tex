\section{Introduction} 
Recent advances in text-to-image generation models, or \LPIMs{} (LPIMs), allow users to generate high-quality images based on a text description or ``prompt''. 
% There has been significant interest both in the popular press and in artistic communities \cite{aguera2017ArtInAI, mazzone2019ArtCreativityAI} in exploring the abilities of these models to generate high-quality images. 
% Using computation to support creative work is not a new endeavor, and research has already explored AI-based tool support for drawing \cite{oh2018Drawing, karimi2019Drawing}, creative writing \cite{clark2018Writing, gero2019Metaphoria}, design ideation \cite{ jeon2021Fashion, quanz2020machine} or music creation \cite{louie2020Music, huang2020AISong}.  %move to related work?

But similar to large language-models (i.e. text-to-text generation models),  where increasing size has discontinuous benefits~\cite{wei2022emergent}, the increased size of recent \LPIMs{} has yielded discontinuous and qualitative differences in the quality of images produced~\cite{saharia2022Imagen}. Consequently, \LPIMs{} have led to both communities of practice, where enthusiasts share designs and prompts, and artists have used these models to create artifacts that are so surprisingly good that they even won a prestigious art competition \cite{AIwinsst11:online}. 

Together, these developments allow the research community to rethink significant aspects of the design process. Such as how designers delegate parts of the creative process to automated systems, how the nature and the style of creative design change, and how designers should best share and collaborate on multimodal creative processes (i.e., using text and image). 


% In particular, non-professional designers benefit from being able to rapidly prototype, see and borrow from examples, and share multiple designs \cite{dow2010parallel}. Since LPIMs may empower those without professional artistic or design training to create images with a textual description alone rapidly, we are motivated to study how practices of non-professional designers might change. %Could be condensed and moved to section 3, (before 3.1) if we want to keep this


Therefore, this paper investigates how the creative design processes of non-professional designers change while using LPIMs. Furthermore, design practices often emerge through social interactions -- for instance, as designers work together in a studio or share their work online. Recent work suggests that deep generative AI may play a role in influencing social dynamics between pairs of people~\cite{suh2021GenerativeMusic}. With the advent of ``prompting'' as a new form of interacting with AI, we build on this emerging body of literature by investigating how prompting may affect social dynamics during collaborative design. 


Specifically, our paper examines the following two research questions. 
\begin{itemize}
    \item RQ1: How does using prompt-based image generation change the design process of non-professional designers?
    \item RQ2: How do prompt-based image generation models change collaborative dynamics during design?
\end{itemize}


Note that while prior work on human-AI co-creative systems has uncovered challenges that frequently arise when users co-create with AI, e.g., users must deal with uncertainty in the capabilities of AI capabilities while simultaneously making sense of complex outputs from the system \cite{yang2020DesignAI}, it is unknown how these challenges manifest when users interact with prompt-based models. It is also unclear what other challenges are unique to working with these models and how we might best address them when designing new interfaces for these systems. Addressing these research questions is the focus of this paper.


To address these research questions, we present the results of a design study with participants from a large technology company who use prompt-based image models in a non-professional capacity. In our controlled study, participants worked in pairs and created graphic designs with or without the assistance of a prompt-based image generation model. We present results in this paper from our direct observations of the designer pairs, conversations during this design session, and post-study interviews. We also compare the artifacts produced by participants for creativity, completeness, and appropriateness to the design brief. 

Overall, we found that LPIMs change the design process by allowing designers to create images \textit{declaratively}, i.e., through a simple description of the desired image. This declarative design changes existing design practices in two ways. First, because it is much faster to type a prompt than to create digital images, TTI models allow faster and broader exploration of the design space, potentially leading to more creative design. Second, because prompts are text, prompt-based image generation leads to easier sharing of design ideas, allowing designers to collaborate and build on each others' work more successfully. 

Throughout our study, we observed that prompts played a central role in the design process and collaboration (See Figure~\ref{teaserfigure}). This leads us to argue that prompts act as a \textit{reflective design material} in the design process. Specifically, we found that our participants developed a \textit{tacit}, rather than technical, understanding of how different aspects of prompts (such as specific keywords) influence the image generated. 

In addition, prompts enabled fluid collaborations between participants as they shared, modified, and iteratively improved each others' prompts. The ability to easily edit and refine an image via a text interface made the design process more fluid, and sharing prompts easily aided collaboration, which uniquely placed prompts as design material in a multimodal creative setting.

Prompts also allowed participants to engage in reflective practice with the AI model. Specifically, the LPIM outputs made it seem like a somewhat opinionated ``design partner'' in its preference to generate certain kinds of images, or when the images generated were wildly different from the prompt's intent or were challenging to modify. Participants leveraged prompts to reflect on the model's results (i.e., reflection-on-action~\cite{schon1968reflective}). In their ability to ``talk back'' to the designer, prompts for LPIMs are also similar to Turkle's notion of ``objects to think with'' \cite{turkle2005second} where the designer engages in an iterative process where they get to refine both their creative ideas and their ways to express them via prompts based on the model's response. 

In short, prompts enabled rapid exploration and reflection-in-action, where participants engaged in reflective conversations with each other through their prompts, envisioning novel designs they did not foresee~\cite{schon1984architectural,ghajargar2018thinking} and reflection-on-action, where participants reflected on the images generated by the LPIM based on their prompt and revised the prompt based on these results. 

In sum, this paper contributes results from a 14-person mixed-methods user study, with the following key findings on how the recent emergence of LPIM models affects design practice:
\begin{itemize}
    \item \textbf{Differences in perceived creativity} We find that users perceived their work to be significantly more creative when using LPIM compared to image search. However, external raters found no significant difference. 
    \item \textbf{Changes in the design process} We articulate ways in which LPIMs, and prompts in particular, changed the design process: by enabling the rapid realization of novel ideas and unlikely combinations (e.g., a giraffe in a Lamborghini) and by enabling greater creative freedom through \textit{indirect} manipulation of images (through text). However, because low-level factors (e.g., cropping, position, text) were difficult to control, participants also wrestled with the model's opinionated idiosyncrasies.  
    \item \textbf{Changes in collaborative practices} We identify ways prompts changed collaborative dynamics during design. While prompts empowered collaborators to combine multiple people's disparate ideas fluidly, their non-determinism hindered coordination, and its indirect nature led to asymmetric access between partners.
    \item \textbf{Prompts as a design material} Finally, we conceptualize how prompts act as a new design material by enabling rapid exploration of a design space and blurring the distinction between means and ends. 
\end{itemize}
Together, our results illustrate prompt-based image generation models' role in a collaborative design process. As other multimodal AI models are developed, such as image-to-image models whose outputs can be controlled with a text prompt, we expect that our conceptualizations of prompts as design materials and how they change design processes and collaboration will inform how future design tools could be designed and how users might interact with them. 


