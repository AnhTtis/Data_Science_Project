\section{Related Work}
This paper builds on three areas of related work: large machine-learning models generally, Human-AI collaboration issues, and the use of AI to support creativity and design. We briefly outline significant findings from prior work below and how this paper extends these findings.

\subsection{Large machine learning models and their use in rapid prototyping}
Recent advances in deep neural networks have enabled the creation of large language models (LLMs) capable of generating highly realistic language output \cite{NEURIPS2020_1457c0d6, lieberjurassic}. When provided with brief contextual information, such as a textual description of the task, these models can mimic the performance of models specially trained for particular tasks such as classification (``Classify whether this review is positive or negative"), question answering (``Given the information below, answer the following questions") and summarization (``Summarize this article''),  i.e., they act as zero- or few-shot learners for a wide array of problems \cite{betz2021Aloud, liu2021InContext, lu2021PromptOrder}. Designing the form of contextual information to provide to the model is referred to as \textit{prompt programming} or \textit{prompt engineering} \cite{wu2022AIChains}. Our work adds to this rich scholarship by examining how designers can engineer prompts to generate images collaboratively. While prior work in this space has generally focused on identifying new capabilities of prompt engineering, our study focuses primarily on how these new capabilities are used.


A parallel line of research has explored generative models for images \cite{gan2014Goodfellow, Zhu_2017_ICCV, Karras_2019_CVPR, gan2018Brock}. Critically, Mansimov et al. \cite{mansimov2015ImgFromCaption} showed that generative image models conditioned on image captions can generate images from natural language input. Leveraging the technological advances in LLMs, a significant number of large prompt-based image-generation models have since been created in the last two years -- including DALL·E \cite{pmlr-v139-ramesh21a, dalle1Web} and DALL·E 2 \cite{ramesh2022DALLE2, dalle2Web}, Parti \cite{yu2022Parti, partiWeb} and Imagen \cite{saharia2022Imagen, imagenWeb}, Stable Diffusion \cite{Rombach_2022_CVPR, stableDiffusionWeb}, and Midjourney \cite{midjourneyWeb}. Given the ability of these \LPIMs{} to generate highly detailed images in a vast array of styles based on the user's prompt, these models present a significant opportunity for application to creative visual tasks \cite{bommasani2021Foundation}. In this work, we investigate the use of text-to-image model's impact on collaborative design tasks.

\subsection{Human-AI co-creation}
The question of what role AI systems play in mediating communication between collaborators \cite{hancock2020AICommunication}, and how AI systems can act as teammates has been widely debated \cite{seeber2020AITeammates,wang2020HumanAi}. Prior work has found that while Human-AI collaboration can improve the abilities of unassisted humans and AI systems without human input, designing such collaborative systems remains challenging~\cite{yang2020profiling}. Particular challenges are a lack of clarity on the capabilities and limitations of AI,  the complexity of output of AI systems, and the role of randomness in AI outputs, both of which impede a designerly understanding of AI~\cite{yang2020DesignAI}. To this literature, we contribute an account of how \textit{prompts} emerge as a reflective design material that help non-professional designers explore the design space of possibilities, and collaborate with each other.

Designing \textit{co-creative} systems (as opposed to decision support systems, for instance) have particular challenges~\cite{buschek2021nine}. Key to our current study is the potential for AI systems to be a ``time-waster'' that user interfaces may impose a “bottleneck” on creative use of the AI, and that AI provides overwhelming amount/detail of content that distracts or creates choice-overload~\cite{buschek2021nine}, resulting in poor design.

This paper enriches this literature by describing how pairs of non-professional designers navigate a \LPIM{}. In this respect, they extend our understanding of interacting with \textit{multimodal} AI co-creation. At the same time, multimodal systems have long been known to improve users' expressive power and efficiency~\cite{oviatt2000multimodalnatural}, our findings on how AI models such as \LPIMs{} can modulate expressivity and efficiency.



   
\subsection{Collaborative Creativity Support and the use of AI}
Tools that support creative tasks have been widely studied in the fields of HCI and psychology \cite{frih2019CSTinHCI}, both for individuals and groups, and from both a human-centric perspective and a computational perspective \cite{kantosalo2016modes}. Given the focus of this paper on collaborative design, we focus this section on creativity support tools for groups (see~\cite{wang2017literature} for an overview of tools for individual support). Tools supporting groups collaborating on creative tasks have studied both the creative process and the communities of practice in which such processes are situated~\cite{ScratchI75:online, Dynamicl51:online, bruckman1998community}. For example, Scratch~\cite{ScratchI75:online} supports collaborative game development through a block-based programming language and supports self-directed discovery-based learning among children~\cite{roque2016supporting}. The critical learning mechanism in Scratch beyond self-directed discovery is ``re-mixing'' or a creative bricolage of other creators' ideas~\cite{dasgupta2016remixing}. Similarly, online communities, such as Dribbble, allow designers to find and build on collaborators' ideas as a critical mechanism to improve creative output~\cite{bruckman1998community,marlow2014rookie}. This paper extends this scholarship by describing how collaborating designers re-mix each others' ideas when creating AI-assisted images. 


In recent years, creativity support tools that use AI have been growing in popularity and have been studied in domains such as creative writing \cite{clark2018Writing, gero2019Metaphoria}, music creation \cite{mccormack2019Music, louie2020Music, huang2020AISong, suh2021GenerativeMusic}, and drawing \cite{davis2015Drawing, davis2016Drawing, oh2018Drawing, karimi2019Drawing}, and design ideation \cite{koch2019Ideation, Sbai_2018_ECCV_Workshops, jeon2021Fashion, quanz2020machine}. In addition, several systems have been designed to support the collaborative generation of creative content. Together, studies of these systems suggest that AI models can shape interactions between collaborating partners and individual and group cognitive processes. This work informs our focus on how \LPIMs{} change collaboration during design and extends the scholarship on how multimodal AI models (i.e., using text to generate images) influence collaboration. 


