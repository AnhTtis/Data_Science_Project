 \section{Related Work}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.46\textwidth]{image/main2.png}
    \caption{Structures of our \method{}. We add two implicit layers, which are only injected in front of the input and behind the output of the pre-trained backbone respectively, as the vision prompts to enrich the vision input and representation. }
    \label{fig:framework}
\end{figure}

\subsection{Vision Fine-tuning}
Recently, more and more works fine-tune the pre-trained models as the backbone for downstream tasks \cite{zaken2022bitfit,croce2022adversarial,wortsman2022model,yu2023visual}, which are trained on large-scale image datasets for common tasks like image classification.
Fine-tuning is highly flexible: it can be applied to new input domains or tasks with different output semantics.

Some work has focused on developing fine-tuning methods that allow for the adaptation of the entire network~\cite{houlsby2019parameter,pfeiffer2020adapterfusion,pfeiffer2020adapterhub}, rather than just a subset of layers.
Another line of related work has focused on developing fine-tuning methods that can be used in a transfer learning setting~\cite{ijcai2022p769,sung2022vl,lin2020exploring,houlsby2019parameter}, where the pre-trained model is adapted to a new task in a different domain.




\subsection{Prompt-based Learning}
Prompt-based learning~\cite{liu2021pre} is a technique that utilizes task-specific descriptions to enhance the understanding of downstream tasks by pre-trained models. This approach was popularized by the GPT series~\cite{brown2020language,radford2018improving,radford2019language} in the field of NLP. This has led to many studies focused on developing effective prompt strategies for extracting knowledge from pre-trained language models. Similarly, recent vision-language models~\cite{lester2021power,gao2020making,li2021prefix,schick2020exploiting,yang2022diffusion,yang2023improving,yu2023visual,wang2023parameter} have achieved impressive performance on various vision tasks without the need for fine-tuning. However, these prompt-based tuning methods are not suitable for pre-trained vision models. Our work aims to bridge this gap by developing a parameter-efficient prompt tuning approach specifically for vision models, to adapt frozen pre-trained vision models to downstream tasks across a broad distribution.


\subsection{Deep Implicit Models}
There has been a growing interest in using implicit layers in deep learning. Researchers have explored different approaches to utilizing numerical analysis methods to replace the representation mechanism in existing deep networks. Some notable examples include SparseMAP \cite{niculae2018sparsemap}, OptNet \cite{amos2017optnet}, and SATNet \cite{wang2019satnet}. These approaches have shown promising results in improving the efficiency and performance of deep learning models.
One particular type of implicit model that has gained attention is Deep Equilibrium Models (DEQ) \cite{bai2019deep}. DEQ is an implicit model with infinite depth, yet it is interesting as a single-layer network because it allows for analytical backpropagation through the equilibrium point. Regardless of the depth of the network, training and predicting with DEQ only require constant memory. Moreover, DEQ has achieved comparable performance with efficient memory cost, as illustrated in \cite{xie2021optimization}.
Another advantage of DEQ is its interpretability. The use of implicit models can make it difficult to interpret the behavior of the network, but DEQ provides a transparent mechanism for understanding the network's inner workings. These advantages make DEQ a suitable candidate for constructing lightweight vision prompt layers.



