\section{Description of the Probabilistic Method} \label{sec:method}

In this section, we describe the probabilistic representation of the solution vector as well as a practical algorithm for approximating the action of the Mittag-Leffler function over a vector using this representation. With slight modifications, the algorithm can either calculate a single entry of the solution vector or the full solution. We also present a way to sample random numbers from the Mittag-Leffler distribution.

\subsection{Mathematical description} \label{sec:theory}

Consider: $\mat{A}=(a_{ij})$, a general {\it n}-by-{\it n} matrix with $a_{ii} < 0$ $\forall i$; $\vec{u}$, a given {\it n}-dimensional vector; and $\vec{y}$, an {\it n}-dimensional vector. This last vector corresponds to
the solution vector after computing the action of the Mittag-Leffler function over the vector $\vec{u}$, that is $\vec{y}=E_{\alpha,\beta} (\mat{A}\, t^{\alpha})\,{\bf u}$ with $0<\alpha\le 1$, $\beta>0$ and $t \geq 0$. Here $t$ denotes the value of time when the solution is computed.

Let us define the following matrices: a diagonal matrix $\mat{D}$, represented hereafter as a vector ${\bf d}$, with entries $d_{ij}=0$ for $\forall i\ne j$ and $d_{ii}=d_i=a_{ii}$ for $i=1,\ldots,n$; $\mat{M}$, a matrix obtained as $\mat{M} = \mat{A} - \mat{D}$, and hence with zero diagonal entries; $\mat{Q}$, the matrix with entries $q_{ij}$ given by
\begin{equation}
q_{ij}=
    \begin{cases}
      0, & \text{if}\ i=j \\
     \frac{|m_{ij}|}{\sum_{j=1}^n|m_{ij}|},  & \text{otherwise;}
    \end{cases}\label{def.Q}
\end{equation}
$\mat{G}$, a matrix with entries $g_{ij}$ taking values $1$ when $m_{ij}\ge 0$, and $-1$ otherwise; and finally $\mat{R}$, a matrix with entries
\begin{equation}
r_{ij}=
    \begin{cases}
      r_i=\frac{\sum_{j=1}^n|m_{ij}|}{d_i}, & \text{if}\ i=j \\
     0,  \quad \text{otherwise;}
    \end{cases}\label{def.R}
\end{equation}
Note that $\sum_{j=1}^n q_{ij}=1 \;\;\forall i$,  and therefore matrix $\mat{Q}$ can be used as the transition rate matrix of a given Markov chain. Furthermore, it holds that $\mat{M} = \mat{D}\,\mat{R}\,(\mat{G}*\mat{Q})$, where $*$ denotes element-wise matrix multiplication.

\begin{theorem}
\label{theorem1}
Let $\{X_t:t\ge 0\}$ be a stochastic process with finite state space $\Omega~=~\{1,2,\dots,n\}$ given by
\begin{equation}
X_t=\sum_{m=1}^{\infty} Z_{m-1}\mathds{1}_{[T_{m-1}\leq t \leq T_{m}]}.
\end{equation}
Such process changes states according to a Markov chain $Z=(Z_m)_{m\in \mathbb{N}}$, which takes values in $\Omega$ and $\mat{Q}$ is the corresponding transition matrix. Here, $T_k$ is the time of the $k$-th event, and $\mathds{1}_E$ denotes the indicator function, being $1$ or $0$ depending on whether the event $E$ occurs. The sojourn times in the $i$-th state follow the Mittag-Leffler distribution $ML_\alpha(d_i)$. Then, we have that any entry $i$ of the solution vector $\vec{y}$ can be represented probabilistically as
\begin{equation}
y_i=\mathds{E} \left[ u_{X_0}\mathds{1}_{[T_0>t]}+ \left(\prod_{j=1}^\eta r_{X_{T_{j-1}}}\, g_{X_{T_{j-1}},X_{T_{j}}} \right) u_{X_{T_\eta}} \mathds{1}_{[T_0\leq t]}\right],\label{prob_rep}
\end{equation}
where $X_0=i$. Here $\mathds{E}$ is the expected value with respect to the joint distribution function of the random variables $T$ and $\eta$, where $\eta$ is the number of events occurring between $0$ and $t$.
 \end{theorem}

\begin{proof}
Our goal is to prove that the expected value of the functional of the stochastic process $X_t$ in (\ref{prob_rep}) coincides with the vector solution $\vec{y}$. As a first step in the proof, it is required to compute the joint distribution function of the random variables $T$ and $\eta$. This function depends on the probability of jumping from state $i$ to state $j$ at time $t$, $\mathds{P}(X_t=j|X_0=i)$. Let us define $\mat{P}$ as the probability matrix such that $\mat{P}(t)=(p_{ij})=\mathds{P}(X_t=j|X_0=i)$, then it holds that
\begin{equation}
p_{ij}(t)=\delta_{ij}\,\mathds{P}(t_i>t)+\int_0^t ds\, f_i(s) \sum_{l\ne i} \mathds{P}(X_\tau=l,X_t=j|\tau=s), 
\label{prob_def1}
\end{equation}
where $t_i$ corresponds to the instant of time of a first event when the state is $i$. 
Here the function $f_i(s) = -d_i\, s^{\alpha-1}\,E_{\alpha,\alpha}(d_i\, s^{\alpha})$  is a density function. In fact, it satisfies that 
\begin{equation}
\int_0^{\infty}ds\,f_i(s)=1,
\end{equation}
and is called the Mittag-Leffler density function \cite{gorenflo_mittag-leffler_2020}. Then the probability of no events taking place in the interval of time $[0,t]$,  $\mathds{P}(t_i>t)$,  is given by
\begin{equation}
\mathds{P}(t_i>t)=\int_t^{\infty}ds\,f_i(s)=E_{\alpha}(d_i\, t^{\alpha}).
\end{equation}
Therefore, it follows that
\begin{equation}
p_{ij}(t)=\delta_{ij}\,E_{\alpha}(d_i\, t^{\alpha})+\int_0^t ds\, f_i(s) \sum_{l\ne i} q_{il}\, p_{lj}(t-s).
\label{prob_def2}
\end{equation}
This is an integral equation for $p_{ij}(t)$ that can be solved recursively, and the solution can be rewritten formally as
\begin{equation}
p_{ij}(t)=\sum_{\eta=0}^\infty p_{ij}^{(\eta)}(t),
\end{equation}
where $p_{ij}^{(\eta)}(t)$ denotes the probability of having a transition from $i$ to $j$ when $\eta$ events occur during the time interval $[0, t]$. Let $\nu_i^{(\eta)}$ be the corresponding contribution to the solution $y_i$ for $\eta$ events. If no events occur, the contribution to the solution $\nu_i^{(0)}$ can be readily obtained as $E_{\alpha}(d_i\, t^{\alpha})\,u_i$. The remaining contributions can be obtained as follows. For one event, from (\ref{prob_def2}) the probability is given by
\begin{equation}
p_{ij}^{(1)}(t)=\int_0^t ds\, f_i(s) \sum_{l\ne i}  q_{il}\,\delta_{lj}\, E_{\alpha}(d_l\, (t-s)^{\alpha}),
\end{equation}
and thus the corresponding contribution to the solution is
\begin{equation}
\nu_i^{(1)}=\sum_{j=1}^n \int_0^t ds\, f_i(s)\sum_{l\ne i} r_i\, g_{il}\, q_{il}\, \delta_{lj} E_{\alpha}(d_l\, (t-s)^{\alpha})\,u_j.
\end{equation}
Note that the equation above can be rewritten equivalently in matrix form as
\begin{equation}
\boldsymbol{\nu}^{(1)}=\int_0^t ds\, {\bf f}(s) \mat{R}\,(\mat{G}*\mat{Q})\, E_{\alpha}(\mat{D}\, (t-s)^{\alpha})\,{\bf u},
\end{equation}
where $\boldsymbol{\nu}^{(1)}$ and ${\bf f}(s)$ are vectors with components $\nu_i^{(1)}$ and $f_i(s)$, respectively. Since  $\mat{R}\,(\mat{G}*\mat{Q}) = \mat{D}^{-1}\,\mat{M}$, then
\begin{equation}
\boldsymbol{\nu}^{(1)}=-\int_0^t ds\,  s^{\alpha-1}\,E_{\alpha,\alpha}(\mat{D}\, s^{\alpha}) \mat{M}\, E_{\alpha}(\mat{D}\, (t-s)^{\alpha})\,{\bf u}.
\end{equation}
The contribution corresponding to two events is
\begin{equation}
\boldsymbol{\nu}^{(2)}=\int_0^t ds_1 {\bf f}(s_1)\, \mat{D}^{-1} \mat{M}\, \int_0^{t-s_1} ds_2  {\bf f}(s_2)\,\mat{D}^{-1} \mat{M}\, E_{\alpha}(\mat{D}\, (t-s_1-s_2)^{\alpha})\,{\bf u}.
\end{equation}
For arbitrary number of events $\eta$, the contribution can be readily computed, and written compactly as follows
\begin{equation}
\boldsymbol{\nu}^{(\eta)}=(-1)^\eta\, \mat{H}^\eta E_{\alpha}(\mat{D}\,t)\,{\bf u},\quad \forall k\geq 0.
\end{equation}
Here $\mat{H}$ is an integral operator $\mat{H}$ defined as
\begin{equation}
\mat{H}\psi(t):= \int_0^t ds\, {\bf f}(s) \mat{D}^{-1} \mat{M} \psi(t-s).
\end{equation}
The solution $\vec{y}$ is finally obtained summing all those partial contributions, and yields 
\begin{equation}
\vec{y}=\sum_{\eta=0}^\infty \boldsymbol{\nu}^{(\eta)}=(\mat{I} + \mat{H})^{-1}\, E_{\alpha}(\mat{D}\,t)\,{\bf u},
\end{equation}
which can be expressed equivalently as an integral equation in the form
\begin{equation}
\vec{y}=E_{\alpha}(\mat{D}\,t)\,{\bf u}-\int_0^t ds\, {\bf f}(s) \mat{D}^{-1} \mat{M}\, {\vec{y}}(t-s).
\end{equation}
Taking the Laplace transform, and using that~\cite{gorenflo_mittag-leffler_2020} 
\begin{equation}
 \mathscr{L}\{t^{\beta-1} E_{\alpha,\beta}(c\,t^\alpha)\}=s^{-\beta} (1-c\,s^{-\alpha})^{-1},\label{Laplace_MLF}
\end{equation}
we obtain
\begin{equation}
{\hat {\vec{y}}}(s)=\frac{s^{-1}}{\mat{I} - \mat{D}\,s^{-\alpha}}\,{\bf u}+\frac{\mat{D}\,s^{-\alpha}}{\mat{I}- \mat{D}\,s^{-\alpha}}\, \mat{D}^{-1} \mat{M}\,{\hat{\vec{y}}},
\end{equation}
where ${\hat {\vec{y}}}(s)=\mathscr{L}\{y(t)\}$. The solution is
\begin{equation}
{\hat {\vec{y}}}=\frac{s^{-1}}{\mat{I}- \mat{D}\,s^{-\alpha}- \mat{D}\,s^{-\alpha}\, \mat{D}^{-1} \mat{M}} \,{\bf u}.
\end{equation}
After applying the inverse Laplace transform and using again (\ref{Laplace_MLF}), we obtain
\begin{equation}
{\vec{y}}=E_{\alpha}((\mat{D}+\mat{M})t^{\alpha})\,{\bf u}=E_{\alpha}(\mat{A}\,t^{\alpha})\,{\bf u},
\end{equation}
which concludes the proof.
\end{proof}

\subsection{Implementation} \label{sec:implementation}

\begin{algorithm}[t]
\caption{Calculates the $i$-th entry of $\vec{y} = E_\alpha (\mat{A} \, t^\alpha) \, \vec{u}$ based on Theorem~\ref{theorem1}. $N_p$ indicates the number of random paths.} \label{code:ml_ctrw}

\begin{algorithmic}[1]
\Function{MCML\_Single}{$\mat{A}$, $\vec{u}$, $\alpha$, $i$, $N_p$, $t$}

\State $y_i = 0$

\For{\textbf{each} random path}
    \State $X_0 = i; \omega = 1$; $k = 0$
    \State Generate $Z_\alpha \sim ML_\alpha(d_{X_0})$
    \State $\tau = Z_\alpha$
    
    \While{$\tau < t$}
        \State $X_{k + 1} =$ \Call{SelectNextState}{$X_k$, $\mat{Q}$}
        \State $\omega = \omega \times r_{X_k} g_{X_k, X_{k + 1}}$
        \State Generate $Z_\alpha \sim ML_\alpha(d_{X_k})$
        \State $\tau = \tau + Z_\alpha$
        \State $k = k + 1$
    \EndWhile
    
    \State $y_i = y_i + \omega \, u_{X_k}$
\EndFor
\State $y_i = y_i / N_p$
\State \Return $y_i$
\EndFunction

\end{algorithmic}
\end{algorithm}

According to Theorem~\ref{theorem1}, the value of the $i$-th entry of the solution vector $\vec{y}$ can be estimated through the simulation of the stochastic process $X_t$, which consists in generating random paths from the Markov chain $Z$ and then computing the realization of a random variable $\omega$ over these paths. Each random path starts at state $X_0$ and time $\tau = 0$ and then jumps from one state to the next until it reaches the time $\tau = t$. The next state is always selected at random based on the transition matrix $\mat{Q}$ and the sojourn time in each state follows an ML distribution. For a sequence of states $X_0, X_1, \ldots, X_\eta$, the value of $\omega$ associated with this random path can be calculated as

\begin{equation*}
    \omega = \left (\prod_{j=1}^\eta r_{X_{j-1}}\, g_{X_{j-1},X_{j}} \right) u_{X_\eta}
\end{equation*}

The procedure for simulating the process $X_t$ is described in Algorithm~\ref{code:ml_ctrw}. In order for the computation to be practical, Algorithm~\ref{code:ml_ctrw} can only generate a finite number $N_p$ of random paths and approximate the value of $y_i$ as
\begin{equation}
    y_i \approx \frac{1}{N_p} \sum_{j = 1}^{N_p}{\omega_j}
    \label{eq:single_solution}
\end{equation}
where $\omega_j$ is the realization of $\omega$ over the random path $j$. Naturally, replacing the expected value in (\ref{prob_rep}) by the arithmetic mean over a finite sample size $N_p$ in (\ref{eq:single_solution}) leads to a numerical error $\epsilon$ of order of $O(N_p^{-1/2})$. In fact, it is well-known that the arithmetic mean provides the best unbiased estimator for the expected value, and, for large number $N_p$ of random paths, the error $\epsilon$ is approximately a random variable distributed according to a normal distribution with standard deviation $\epsilon \approx \sigma N_p^{-1/2}$ \cite{berry_accuracy_1941}. Here $\sigma$ denotes the standard deviation of the random variable $\omega$. Note that there is no other source of error in Algorithm~\ref{code:ml_ctrw}. 

The main limitation of Algorithm \ref{code:ml_ctrw} is that it can only estimate one entry of $\vec{y}$ at a time, requiring a separated set of random paths to calculate the solution in each point in the domain. Therefore, it is better suited for estimating the solution locally (\ie, for a specific set of number of points) than the complete solution. A more efficient method for computing the solution for the entire domain is presented next.

\subsection{Computing the full solution vector} \label{sec:full_vec_method}

\begin{algorithm}[t]
\caption{Calculates $\vec{y} = E_\alpha (\mat{A} \, t^\alpha) \, \vec{u}$ based on its full probabilistic representation. $N_p$ indicate the number of random paths.} \label{code:ml_ctrw_full}

\begin{algorithmic}[1]
\Function{MCML\_Full}{$\mat{A}$, $\vec{u}$, $\alpha$, $N_p$, $t$}

\State $\vec{y} = 0$
\State $\vec{p}^{(0)} = \left \{ p_i^{(0)} = \cfrac{|u_i|}{\|\vec{u}\|_1} \right \}$

\For{\textbf{each} random path}
    \State $k = 0$
    \State $X_0 =$ \Call{SelectInitialState}{$\vec{p}^{(0)}$}
    \State $\omega = \cfrac{u_{X_0}}{|u_{X_0}|} \|\vec{u}\|_1$
    \State Generate $Z_\alpha \sim ML_\alpha(d_{X_0})$
    \State $\tau = Z_\alpha$
    
    \While{$\tau < t$}
        \State $X_{k + 1} =$ \Call{SelectNextState}{$X_k$, $\mat{Q}^\intercal$}
        \State $\omega = \omega \times r_{X_k} g_{X_k, X_{k + 1}}$
        \State Generate $Z_\alpha \sim ML_\alpha(d_{X_k})$
        \State $\tau = \tau + Z_\alpha$
        \State $k = k + 1$
    \EndWhile
    
    \State $y_{X_0} = y_{X_0} + \omega$
\EndFor
\State $\vec{y} = \vec{y} / N_p$
\State \Return $\vec{y}$
\EndFunction

\end{algorithmic}
\end{algorithm}

Theorem~\ref{theorem1} can be conveniently modified to represent the complete solution vector $\vec{y}$ rather than a single entry. The procedure is identical to the case of the matrix exponential (namely $\alpha=\beta=1$), which is described fully in~\cite{acebron_highly_2020}. For completeness, we present here the main details. The representation requires generating random paths, which now start at a randomly chosen state $j$ and time $t=0$ according to a suitable distribution probability $p_j^{(0)}=\mathds{P}(X_0=j)$, ending at state $i$ at time $t$. Those paths evolve in time changing states governed now  by $\mat{Q}^\intercal$ as the corresponding transition matrix of the Markov chain. This can be explained resorting to the Bayes' theorem. In fact, it holds that
\begin{align*}
    p_{ji} &= \mathds{P}(X_t=i|X_0=j) \\
           &= \mathds{P}(X_t=j|X_0=i) \frac{\mathds{P}(X_t=i)}{\mathds{P}(X_0=j)} \\
           &= p_{ij} \frac{p_i}{p_j^{(0)}} \\
           &= (\mat{P}^\intercal)_{ji} \frac{p_i}{p_j^{(0)}} 
\end{align*}
where $p_i=\mathds{P}(X_t=i)$. Note that the matrix probability $(\mat{P}^\intercal)$ corresponds to a Markov chain governed now by the transition matrix $\mat{Q}^\intercal$. As it was explained in~\cite{acebron_highly_2020}, the distribution function $p_j^{(0)}$ can be arbitrarily chosen. However, the choice may have a direct impact on the variance, and, in turn, on the performance of the algorithm. For simplicity, we use here the more reasonable choice corresponding to $p_j^{(0)}$ proportional to $|u_j|$, since this resembles the well known importance sampling method for variance reduction, where the sampling is done according to the importance of the data. 

Algorithm \ref{code:ml_ctrw_full} describes the stochastic method based on this alternative representation. The main advantage of this method is the ability to estimate the entire solution vector with a single set of random paths, naturally distributing the contribution of each random path over all points in the domain. Due to this property, Algorithm \ref{code:ml_ctrw_full} is often more efficient than Algorithm \ref{code:ml_ctrw} for estimating the entire solution.

\subsection{Generating random numbers from a Mittag-Leffler distribution}

For every state in the random path, Algorithms~\ref{code:ml_ctrw} and~\ref{code:ml_ctrw_full} generate a random number $Z_\alpha$ from the ML probability distribution to determine the time spent in this state. The value of $Z_\alpha$ is then later added to the total time $\tau$ of the random path. The random path ends when $\tau \geq t$. 

Considering that an ML random variable follows the Geometric Stable Laws~\cite{kozubowski_univariate_1999, kozubowski_fractional_2001}, it can be represented as a combination of an exponential and a stable random variable~\cite{kozubowski_exponential_2000, kozubowski_computer_2000}. Using this representation, Kozubowski~\cite{kozubowski_computer_2000} deducted the following formula for generating $Z_\alpha \sim ML_\alpha(\gamma)$ for $0~<~\alpha~\leq~1$:
\begin{equation}
    \label{eq:ml_rand}
    Z_\alpha = - |\gamma|^{-\frac{1}{\alpha}} \, \ln{(U)} \, [\sin(\alpha\pi) \cot(\alpha \pi V) - \cos(\alpha\pi)]^{\frac{1}{\alpha}}
\end{equation}
where $U, V$ are random numbers from the uniform distribution over the $[0, 1]$ interval and $\gamma$ is the rate parameter. For $\alpha = 1$, (\ref{eq:ml_rand}) reduces to the inversion formula for the exponential distribution: $Z_1 = - |\gamma|^{-1} \ln{U}$. Note that for $\alpha > 1$, the ML function is not monotonic and, thus, cannot be considered a probability distribution~\cite{pillai_mittag-leffler_1990}. It is worth mentioning that the \textit{rejection sampling} technique~\cite{devroye_non-uniform_1986, marsaglia_ziggurat_2000, rubin_efficient_2006} can also be used for generating the ML random numbers, however it requires the construction of a pointwise representation directly from (\ref{eq:ml_def}), which can be quite expensive due to the slow convergence of the series~\cite{fulger_random_2013}. 
