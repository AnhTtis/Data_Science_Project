\section{Introduction}\label{sec:intro}

Among the many non-conventional statistical phenomena observed experimentally in the last few years and characterized typically by unusual scaling exponents, the anomalous diffusion stands out for its major impact in a variety of scientific disciplines~\cite{metzler_random_2000}.
To cite just a few relevant examples, it has been already observed in turbulent atmospheres, transport in amorphous solids, diffusion in the cell nucleus, magnetic resonance imaging, search behaviour, and in finance for accurate modelling of the stock price fluctuations.

In the anomalous diffusion, the mean squared displacement (MSD) varies nonlinearly in time, \ie, $\langle x^2(t) \rangle \sim t^{\alpha}$ with $\alpha \ne 1$, during the entire process. Here $x(t)$ is the relative position at time $t$ of a particle with respect to a given reference point. This contrasts with the classical diffusion problems, modelled typically by a Brownian motion, where it is well known that the MSD grows linearly in time. In practice, there are two different types of regimes according to the value of the scaling exponent $\alpha$. The phenomenon is termed as subdiffusion when $\alpha<1$ and, superdiffusion when $\alpha>1$. It has been proposed in the literature several pathways leading to anomalous diffusion. The most commonly found are the presence of long-range correlations, non-identical displacements, or non-finite mean or variance of the probability density function for the trajectory displacements.

Within this context, fractional calculus has been proven to be extremely useful in order to provide realistic models for many real-life processes and phenomena \cite{west_fractional_2016, lischke_what_2020}. The main reason for this is due to fractional derivative operators being in practice non-local operators, and therefore they are especially suited for describing the long-time memory and spatial heterogeneity effects typically found in any anomalous diffusion problem.

The formal solution to the simplest dynamic problem defined by a system of linear fractional rate equations for an $n$-dimensional process $\vec{y}(t)$ subject to a given initial condition $\vec{y}(0)={\bf y_0}$ is

\begin{equation}\label{eq:n-dim-sol}
\vec{y}(t)=E_{\alpha}(\mat{A} \,t^{\alpha}) \, {\bf y_0},
\end{equation}
where $\mat{A}$ is an $n\times n$ matrix of constant coefficients. When $\alpha=1$, the Mittag-Leffler (ML) function $E_{\alpha}(\mat{A} \,t^{\alpha})$ reduces to the matrix exponential $e^{\mat{A} \,t}$. The ML function also appears in other scientific domains, such as biology \cite{estrada_fractional_2020, magin_fractional_2004}, physics \cite{hilfer_applications_2000, sabatier_advances_2007, mainardi_fractional_2010}, control systems \cite{sabatier_advances_2007, chen_fractional_2009} and complex network analysis \cite{arrigo_ml_network_2021, martinez_world-wide_2022}. It is important to remark here that this system of linear rate equations serves as building blocks for more complex systems, and therefore becomes of paramount importance in investigating algorithms capable of computing it efficiently.

However, an efficient algorithm for solving large-scale problems is still missing. Therefore, the main contribution of this paper is to propose a probabilistic method for the efficient computation of the ML matrix function. This method is based on random walks that change states according to a suitable continuous-time Markov chain, whose sojourn times follow a Mittag-Leffler distribution.
Note that a random process governed by the ML distribution is no longer Markovian due to the presence of long-term memory between states.
%\jnote{Rather than the classical Poisson process, which is Markovian,  a random process governed by the ML distribution is no longer Markovian but of long-memory type}.
The method we proposed allows us to compute the ML matrix function for large-scale matrices, focusing primarily on the action of the function over a vector. Our second contribution is an extensive analysis of the performance and convergence of our method using a few relevant numerical examples, including a formal description of the variance and a performance comparison against classical algorithms. Our third and last contribution was to parallelize and analyze the scalability of the stochastic algorithm for a large number of processors (up to $16,384$ CPU cores) in the Karolina Supercomputer located in IT4Innovations National Supercomputing Centre.

The paper is organized as follows. In the next section, we give an overview of the state of the art in this area. Section \ref{sec:method} describes the probabilistic method and its practical implementation. This section also shows how a program can generate random numbers from the Mittag-Leffler probability distribution. In Section \ref{sec:results}, several numerical experiments are presented in order to characterize the performance and numerical errors of the stochastic method compared to classical approaches. Finally, in Section \ref{sec:conclusion}, we highlight the main results and conclude the paper.
