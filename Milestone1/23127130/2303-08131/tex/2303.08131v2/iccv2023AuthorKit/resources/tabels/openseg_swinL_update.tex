


\begin{table}
\centering
\tablestyle{3pt}{0.95}
% \setlength{\extrarowheight}{0pt}
% \addtolength{\extrarowheight}{\aboverulesep}
\addtolength{\extrarowheight}{\belowrulesep}
% \setlength{\aboverulesep}{0pt}
% \setlength{\belowrulesep}{0pt}
\caption{\textbf{One suit of weights} for open-vocabulary segmentation on multiple datasets in a zero-shot manner. Our model is pre-trained on COCO and Objects365 data. 'SEG' indicates segmentation data (COCO), 'DET' indicates detection data (Objects365), and ITP indicates image-text pairs/referring/captioning data. The values in gray are supervised results. $\star$ X-Decoder (L) is not open-source, so we cannot evaluate its performance on LVIS.}
\label{tab_supp:open_seg_swinl}
\footnotesize
\resizebox{0.99\linewidth}{!}{\begin{tabular}{l|ccc|cccc} 
\toprule
\multirow{2}{*}{Method} & \multicolumn{3}{c|}{Training Data} & \multicolumn{4}{c|}{ADE}   \\
 &SEG&DET&ITP & PQ & mask AP & box AP & {mIoU}  \\ 
\hline
% X-Decoder (B) &\cmark&\xmark   &\cmark     & 21.1& 11.7 &$-$&27.2 &39.5 &22.3& 50.8& $-$ &   $-$ & 17.1&45.1 &35.4&40.3&24.9&39.6&14.7      \\
X-Decoder (L)~\cite{zou2022generalized} &\cmark&\xmark   &\cmark     &  21.8 &13.1&$-$& 29.6 \\
\rowcolor[rgb]{0.961,0.961,0.961} {\ourmodel{} (L)}  &\cmark&\cmark &\xmark & 20.3 & \textbf{15.0} & \textbf{18.3} & 23.6 
  \\
\bottomrule
\end{tabular}}
\vspace{0.2cm}
\end{table}