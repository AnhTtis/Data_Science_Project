\section{Related Work}
\noindent
\textbf{Generic Segmentation and Detection.}
Detection and segmentation have been long-standing problems in the vision community~\cite{fu1981survey,felzenszwalb2009object,zou2019object,minaee2021image}. Both tasks require understanding what and where the visual concepts are but with different spatial granularities. Generic segmentation mainly includes instance, semantic and panoptic segmentation~\cite{he2017mask,chen2017deeplab,kirillov2019panoptic}, with respect to different semantics. Recently, Detection Transformer (DETR)~\cite{carion2020end} that is based on Transformer~\cite{vaswani2017attention} has achieved significant progress in many detection~\cite{zhu2020deformable, liu2022dabdetr, meng2021conditional, li2022dn, zhang2022dino} and segmentation models~\cite{li2022panoptic, cheng2022masked, li2022mask, jain2022oneformer}. However, all these methods are constrained to a limited vocabulary size.
\\
\noindent
\textbf{Open-Vocabulary Segmentation. } Many open-vocabulary segmentation models~\cite{li2022language, ghiasi2021open, huynh2022open, ding2022open} leverages large pretrained vision-language models (\textit{e.g.}, CLIP~\cite{jia2021scaling} or ALIGN\cite{radford2021learning}) to distill or transfer the visual-semantic knowledge. Apart from using foundation models, DenseCLIP~\cite{rao2022denseclip} and GroupViT~\cite{xu2022groupvit} show that fine-tuning from a foundation model or training from scratch can also yield superior zero-shot performance. Recently, X-Decoder~\cite{zou2022generalized} proposes to unify all types of segmentation tasks and several vision-language tasks for open-vocabulary segmentation. In ODISE~\cite{xu2023open}, the authors study a new way of using a text-to-image diffusion model as the backbone for open-vocabulary segmentation. Unlike the previous works, our model instead explores connecting segmentation and detection which have cleaner data and closer gap between each other.
\\
\noindent
\textbf{Open-Vocabulary Detection}. Similarly, some open-vocabulary detection models directly leverage foundation models for distillation or transfer like OV-DETR~\cite{zareian2021open} and VILD~\cite{XiuyeGu2021OpenvocabularyOD}. Recently, GLIP~\cite{li2022grounded} formulates detection as a special grounding problem to unify detection and phrase grounding tasks. These grounding data help improve the alignment between phrases and regions for open detection. RegionCLIP~\cite{zhong2022regionclip} and DetCLIP~\cite{LeweiYao2022DetCLIPDV} generate pseudo box labels from image-text pairs for more generalized detection. 
\\
\noindent
\textbf{Weakly-Supervised Segmentation}. Weakly-supervised segmentation typically only uses box annotation as supervision to generate segmentation. Prominent methods design teacher models or weak supervision loss, like BoxInst~\cite{tian2021boxinst},  Box2Mask~\cite{li2022box}, DiscoBox~\cite{lan2021discobox} and Mask Auto-Labelers~\cite{lan2023vision}. All these models are with closed-set and usually inferior to models with segmentation supervision. In contrast, we attempt to leverage as much supervision as possible from both segmentation and detection for an open-vocabulary model.
\\
\noindent
\textbf{Learning from Box and Mask}. There are primarily two ways to learn from both box and mask. The first one is to train on a single dataset with both box and mask annotations. Prominent methods include Mask R-CNN~\cite{he2017mask} and HTC~\cite{chen2019hybrid}. However, they are constrained to foreground instances. The second way is to pretrain with only box supervision and then transfer to segmentation. For example, HTC~\cite{chen2019hybrid} and Mask DINO~\cite{li2022mask} can both learn from large-scale detection data and then be fine-tuned to a specific segmentation dataset. However, such a pretrain-and-finetune protocol leads to two separate models that are only capable of either detection or segmentation. Moreover, both models are closed-set and thus not transferable to novel concepts.
% We could make a table to cover different open-vocabulary models. 

% 2. open-vocabulary detection and segmentation; we are the first work to jointly learn from box and mask supervision to enhance the segmentation while still maintaining a competitive detection performance.

% 3. need to cover weakly supervised segmentation methods using boxes as supervisions. not open-vocabulary and usually inferior to supervisedly trained model

% 4. learning from both box and mask. two main ways: 1) learn on a single dataset that contains both box and mask, e.g., Mask R-CNN, HTC, however only constrained on foreground instances. 2) first learn from box and then transfer to mask, such as Mask-DINO. Not open-vocabulary, the ability to detect hundreds of categories is lost, not to say segment them. 
