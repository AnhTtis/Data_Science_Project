
\vspace{-1ex}
\section{Conclusion}
\vspace{-1ex}

In this paper, we rethink model ensemble in black-box adversarial attacks. We engage in a theoretical analysis, exploring the relationship among the transferability of adversarial samples, the Hessian matrix's F-norm, and the distance between the local optimum of each model and the convergence point. Stemming from these insights, we define common weaknesses and propose effective algorithms to find common weaknesses of the model ensemble. Through comprehensive experiments in both image classification and object detection, we empirically demonstrate that our algorithm excels in finding common weakness, thereby enhancing the transferability of adversarial examples.

%Our algorithm is not only efficient, but also effective, especially when there are many kind of training models and when attacking the adversarially trained model, which outperforms previous methods by 30\% in average. We hope our algorithm can be applied to real scenarios as an effective and straightforward attacker.





\section*{Ethics Statement}

A potential negative impact of our approach is that malicious attackers could use our method to attack large commercial models, leading to toxic content generation or privacy leakage. As people currently focus on improving big models due to their excellent performance, it's even more important to explore and address the vulnerability of deep learning models which could be targeted by black-box attacks without knowing specific details of the target models. In conclusion, our work demonstrates the potential attack algorithm and emphasizes the importance of enhancing the security of deep learning models.



\section*{Acknowledgements}



This work was supported by the NSFC Projects (Nos. 62276149, U2341228, 62061136001, 62076147), BNRist (BNR2022RC01006), Tsinghua Institute for Guo Qiang, and the High Performance Computing Center, Tsinghua University. Y. Dong was also supported by the China National Postdoctoral Program for Innovative Talents and Shuimu Tsinghua Scholar Program. J. Zhu was also supported by the XPlorer Prize.






