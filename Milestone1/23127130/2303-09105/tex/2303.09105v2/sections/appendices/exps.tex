
\section{Additional Experiments}
\label{sec:moreexp}

\subsection{Main Experiment Settings}
\label{sec:black_box_models}



\textbf{Target Models:} We evaluate the performance of different attacks on 31 black-box models, including 16 normally trained models with different architectures --- AlexNet \citep{alexnet}, VGG-16 \citep{vgg}, GoogleNet \citep{googlenet}, Inception-V3 \citep{inception}, ResNet-152 \citep{resnet}, DenseNet-121 \citep{densenet}, SqueezeNet \citep{iandola2016squeezenet}, ShuffleNet-V2 \citep{ma2018shufflenet}, MobileNet-V3 \citep{mobilenet}, EfficientNet-B0 \citep{tan2019efficientnet}, MNasNet \citep{tan2019mnasnet}, ResNetX-400MF \citep{regnet}, ConvNeXt-T \citep{liu2022convnext}, ViT-B/16 \citep{vit}, Swin-S \citep{liu2021swin}, MaxViT-T \citep{tu2022maxvit}, and 8 adversarially trained models~\citep{pgd,wei2023cfa} available on RobustBench \citep{croce2020robustbench} --- FGSMAT \citep{adversarialMLAtScale} with Inception-V3, Ensemble AT (EnsAT) \citep{tramer2017ensemble} with Inception-ResNet-V2, FastAT \citep{wong2020fast} with ResNet-50, PGDAT \citep{Engstrom2019Robustness,salman2020adversarially} with ResNet-50, ResNet-18, Wide-ResNet-50-2, a variant of PGDAT tuned by bag-of-tricks (PGDAT$^\dagger$) \citep{debenedetti2022light} with XCiT-M12 and XCiT-L12. Most defense models are state-of-the-art on RobustBench \citep{croce2020robustbench}. Regarding defenses other than adversarial training, we consider 7 defenses (\ie, HGD~\citep{liao2018defense_HGD}, R\&P~\citep{xie2017mitigating_randomization_RandP}, 
Bit (BitDepthReduction in \citet{guo2018countering_JPEG}), JPEG~\citep{guo2018countering_JPEG},
RS~\citep{cohen2019certified_r},
NRP~\citep{naseer2020self_NRP},
DiffPure~\citep{nie2022diffpure}) that are robust against black-box attacks.

\subsection{Comparison with \citet{Naseer_2021_ICCV_on_generating}}

In order to show that our method works well under different surrogate models and target models, we supplement an experiment following the setting in \citet{Naseer_2021_ICCV_on_generating}:



\begin{table}[htbp]
\centering
\caption{\textbf{Attack success rate (\%,$\uparrow$).}}
\footnotesize
\begin{tabu}{l|l|ccccc} 
\hline
           Surrogates               &  Methods  &  VGG19$_{bn}$      & Dense121       & Res50        & Res152       & WRN50-2         \\ 
\hline
\multirow{2}{*}{$V_{ens}$} &   \citet{Naseer_2021_ICCV_on_generating}   & 97.34           & 71.41          & 71.68           & 50.78           & 48.03           \\
                           & MI-CWA & \textbf{100.00} & \textbf{94.50} & \textbf{94.30}  & \textbf{81.50}  & \textbf{89.20}  \\ 
\hline
\multirow{2}{*}{$D_{ens}$} &   \citet{Naseer_2021_ICCV_on_generating}   & 76.96           & 96.25          & 88.81           & 83.48           & 81.85           \\
                           & MI-CWA & \textbf{99.60}  & \textbf{99.90} & \textbf{99.80}  & \textbf{99.50}  & \textbf{99.60}  \\ 
\hline
\multirow{2}{*}{$R_{ens}$} &    \citet{Naseer_2021_ICCV_on_generating}  & 90.43           & 94.39          & 96.67           & 95.48           & 92.63           \\
                           & MI-CWA & \textbf{99.50}  & \textbf{99.70} & \textbf{100.00} & \textbf{100.00} & \textbf{99.90}  \\
\hline
\end{tabu}
\label{table:nasser_ensemble}
\end{table}

Here, $V_{ens}$ represents the ensemble comprising VGG-11, VGG-13, VGG-16, and VGG-19. $R_{ens}$ denotes the ensemble of ResNet-18, ResNet-50, ResNet-101, and ResNet-152. Similarly, $D_{ens}$ corresponds to the ensemble of DenseNet-121, DenseNet-161, DenseNet-169, and DenseNet-201. In this configuration, surrogate models exhibit high similarity. Therefore, it is effective to assess the algorithm's capacity for generalization to unseen target models, particularly those that differ significantly from the surrogate models.

As shown in \cref{table:nasser_ensemble}, our method surpasses previous techniques by an average of approximately 20\%, underscoring the efficacy of our approach in attacking unseen target models.




\subsection{Attacking using less diverse surrogate models}

To further illustrate the efficacy of the CWA algorithm even with a limited diversity of surrogate models, we conducted additional experiments in this section. Specifically, we limit our selection to models of the ResNet family, employing only ResNet-18, ResNet-32, ResNet-50, and ResNet-101~\citep{resnet} as surrogate models. As shown in \cref{table:extraexp}, our SSA-CWA still achieves superior results than other attackers. These results suggest that even when the diversity of surrogate models is limited, adversarial examples generated using the CWA attacker are less prone to overfitting to those surrogate models and continue to generalize effectively to previously unseen target models.



\begin{table}
\centering
\footnotesize
\setlength{\tabcolsep}{2.3pt}
\caption{\textbf{Black-box attack success rate (\%, $\uparrow$) on NIPS2017 dataset.} Surrogates are ResNet18, ResNet32, ResNet50 and ResNet101.}
\label{table:extraexp}
\scalebox{0.8}{
\begin{tabu}{l|l|cccccccccc|cccc} 
\hline
Method                            & Backbone        & FGSM & BIM  & MI   & DI   & TI   & VMI           & SVRE & PI   & SSA           & RAP  & MI-SAM & MI-CSE       & MI-CWA       & SSA-CWA        \\ 
\hline
\multirow{16}{*}{Normal}          & AlexNet         & 77.6 & 69.2 & 74.9 & 79.2 & 78.2 & 85.3          & 80.9 & 82.6 & 89.7          & 81.9 & 79.5   & 83.1         & 82.9         & \textbf{92.7}  \\
                                  & VGG-16          & 71.3 & 91.0 & 90.8 & 95.8 & 84.7 & 97.0          & 97.3 & 91.0 & 99.1          & 94.1 & 96.7   & 99.1         & 99.4         & \textbf{100.0}   \\
                                  & GoogleNet       & 58.8 & 88.4 & 87.7 & 95.4 & 79.6 & 96.7          & 96.5 & 88.3 & 98.8          & 90.5 & 94.2   & 98.3         & 98.4         & \textbf{99.9}  \\
                                  & Inception-V3    & 58.7 & 79.0 & 81.6 & 91.8 & 77.1 & 94.1          & 92.2 & 80.9 & 97.0          & 84.0 & 88.1   & 92.4         & 91.3         & \textbf{98.7}  \\
                                  & ResNet-152      & 60.2 & 96.6 & 96.1 & 96.8 & 89.9 & 98.5          & 99.5 & 96.4 & 99.1          & 96.2 & 99.1   & \textbf{100.0} & \textbf{100.0} & \textbf{100.0}   \\
                                  & DenseNet-121    & 63.1 & 96.2 & 95.2 & 97.2 & 90.3 & 98.2          & 99.3 & 96.0 & 99.4          & 95.0 & 99.0   & 99.8         & 99.8         & \textbf{100.0}   \\
                                  & SqueezeNet      & 86.4 & 89.8 & 90.2 & 95.7 & 86.7 & 96.2          & 96.7 & 93.2 & 98.6          & 93.7 & 94.8   & 98.0         & 98.6         & \textbf{99.8}  \\
                                  & ShuffleNet-V2   & 83.1 & 78.1 & 83.3 & 86.8 & 78.8 & 91.2          & 89.4 & 85.1 & 95.1          & 89.1 & 88.1   & 91.5         & 91.8         & \textbf{97.8}  \\
                                  & MobileNet-V3    & 60.6 & 65.6 & 69.5 & 80.6 & 77.3 & 89.7          & 78.2 & 80.4 & 92.2          & 77.1 & 78.2   & 80.2         & 79.9         & \textbf{95.7}  \\
                                  & EfficientNet-B0 & 55.6 & 89.3 & 87.7 & 94.7 & 77.9 & 96.8          & 96.9 & 86.6 & 98.8          & 92.5 & 95.5   & 98.1         & 97.9         & \textbf{99.9}  \\
                                  & MNasNet         & 66.8 & 87.1 & 84.8 & 93.5 & 75.6 & 96.4          & 95.0 & 84.3 & 98.1          & 92.1 & 94.8   & 97.5         & 97.0         & \textbf{99.9}  \\
                                  & RegNetX-400MF   & 60.3 & 87.9 & 86.8 & 94.9 & 86.0 & 97.2          & 94.9 & 89.3 & 98.7          & 91.3 & 94.4   & 97.6         & 97.5         & \textbf{100.0}   \\
                                  & ConvNeXt-T      & 42.7 & 80.8 & 77.6 & 88.2 & 57.0 & 94.0          & 87.6 & 69.3 & 94.9          & 86.5 & 89.4   & 90.2         & 87.9         & \textbf{97.4}  \\
                                  & ViT-B/16        & 37.0 & 51.7 & 52.9 & 64.3 & 53.8 & \textbf{81.7} & 60.5 & 55.8 & 81.4          & 50.2 & 61.9   & 48.8         & 46.6         & 71.7           \\
                                  & Swin-S          & 36.0 & 62.3 & 60.3 & 72.4 & 39.4 & 83.8          & 70.4 & 48.9 & \textbf{84.2} & 61.5 & 70.8   & 59.5         & 58.2         & 80.7           \\
                                  & MaxViT-T        & 34.1 & 63.0 & 61.6 & 73.1 & 31.9 & 85.1          & 68.6 & 43.9 & \textbf{86.7} & 58.9 & 70.5   & 56.7         & 54.5         & 79.0           \\ 
\hline
FGSMAT~                           & Inception-V3    & 55.3 & 51.2 & 55.2 & 59.2 & 65.6 & 73.9          & 61.1 & 66.2 & \textbf{84.4} & 59.6 & 58.6   & 60.1         & 60.3         & 78.2           \\ 
\cline{1-2}
EnsAT~                            & IncRes-V2       & 35.6 & 37.6 & 38.6 & 51.1 & 56.7 & 66.7          & 41.8 & 52.5 & \textbf{74.7} & 35.4 & 39.9   & 38.0         & 38.2         & 59.9           \\ 
\cline{1-2}
FastAT                            & ResNet-50       & 45.2 & 42.3 & 44.6 & 44.2 & 46.7 & 47.5          & 45.3 & 48.5 & \textbf{50.4} & 46.6 & 45.3   & 46.2         & 46.2         & 49.6           \\ 
\cline{1-2}
PGDAT~                            & ResNet-50       & 35.9 & 31.2 & 34.1 & 35.1 & 38.4 & 41.3          & 35.7 & 42.0 & \textbf{43.7} & 36.5 & 36.1   & 35.7         & 35.7         & 40.3           \\ 
\cline{1-2}
\multirow{2}{*}{PGDAT~}           & ResNet-18       & 47.1 & 42.0 & 45.4 & 45.3 & 47.6 & 47.2          & 45.6 & 50.4 & 50.6          & 47.8 & 45.8   & 46.8         & 46.9         & \textbf{50.7}  \\
                                  & WRN-50-2        & 28.1 & 22.7 & 25.6 & 27.4 & 31.2 & 32.6          & 27.3 & 33.9 & \textbf{35.3} & 27.7 & 28.0   & 27.6         & 26.7         & 31.7           \\ 
\cline{1-2}
\multirow{2}{*}{PGDAT$^\dagger$~} & XCiT-M12        & 21.7 & 16.8 & 18.5 & 19.9 & 22.9 & 25.0          & 20.7 & 25.3 & \textbf{28.1} & 22.0 & 20.9   & 21.3         & 21.2         & 26.5           \\
                                  & XCiT-L12        & 18.7 & 14.9 & 16.3 & 17.3 & 20.9 & 21.6          & 18.6 & 22.3 & \textbf{26.0} & 18.4 & 18.4   & 18.5         & 18.2         & 22.6           \\ 
\hline
HGD                               & IncRes-V2       & 37.8 & 77.4 & 75.4 & 91.1 & 73.0 & 94.2          & 85.5 & 77.9 & 94.7          & 76.9 & 86.7   & 85.8         & 83.6         & \textbf{97.8}  \\
R\&P                & ResNet-50       & 69.7 & 97.5 & 96.8 & 97.9 & 94.3 & 98.8          & 99.7 & 97.7 & 99.6          & 96.9 & 99.3   & \textbf{100.0} & \textbf{100.0} & \textbf{100.0}   \\
Bit                               & ResNet-50       & 73.2 & 98.4 & 98.4 & 97.7 & 96.6 & 99.1          & 99.9 & 99.2 & 99.7          & 98.7 & 99.6   & \textbf{100.0} & \textbf{100.0} & \textbf{100.0}   \\
JPEG                              & ResNet-50       & 70.5 & 98.1 & 97.8 & 97.2 & 96.3 & 98.9          & 98.7 & 98.5 & 99.7          & 98.1 & 99.5   & \textbf{100.0} & \textbf{100.0} & \textbf{100.0}   \\
RS                                & ResNet-50       & 66.7 & 97.2 & 96.7 & 97.3 & 93.1 & 98.7          & 99.5 & 97.0 & 99.5          & 96.6 & 99.4   & \textbf{100.0} & \textbf{100.0} & \textbf{100.0}   \\
NRP                               & ResNet-50       & 41.0 & 90.4 & 77.0 & 66.4 & 76.0 & \textbf{82.6} & 80.2 & 34.1 & 73.2          & 25.1 & 68.8   & 40.6         & 38.6         & 36.0           \\
DiffPure                          & ResNet-50       & 57.7 & 68.6 & 75.0 & 84.1 & 88.6 & 95.9          & 85.8 & 89.4 & 96.0          & 76.4 & 84.9   & 81.2         & 79.5         & \textbf{95.0}  \\
\hline
\end{tabu}
}
\end{table}
















%------------------------------


\subsection{Attacking using the surrogate in \citet{MI}}

We also evaluate our methods using surrogate models from \citet{MI}, which include Inc-v3, Inc-v4, IncRes-v2, and Res-152 from TensorFlow model garden~\citep{tensorflowmodelgarden2020}. Note that these models are different from the corresponding models in TorchVision. This configuration ensures that the majority of the target models are dissimilar to the surrogate models, providing a robust assessment of our algorithm's capability to generate adversarial examples that effectively transfer to diverse and previously unseen models.

As demonstrated in \cref{table:classification_tfsurrogate}, SSA-CWA outperforms previous methods significantly when attacking both normally trained models and defended models. Notably, our SSA-CWA achieves a remarkable 94.6\% attack success rate against challenging DiffPure defenses~\citep{nie2022diffpure}. This underscores the effectiveness of our approach in targeting state-of-the-art defense mechanisms.







\begin{table}[t]
\centering
\footnotesize
\setlength{\tabcolsep}{2.4pt}
\caption{\textbf{Black-box attack success rate (\%,$\uparrow$) on NIPS2017 dataset.} Surrogate models are Inc-v3, Inc-v4, IncRes-v2 and Res-152 from \citet{MI}.}
\label{table:classification_tfsurrogate}
\scalebox{0.8}{
\begin{tabu}{l|l|cccccccccc|ccccc}
\hline
Method                            & Backbone        & FGSM & BIM  & MI   & DI   & TI   & VMI  & SVRE & PI   & SSA           & RAP  & MI-SAM  & MI-CSE           & MI-CWA           & SSA-CWA        \\ 
\hline
\multirow{16}{*}{Normal}          & AlexNet         & 75.8 & 64.2 & 71.3 & 73.3 & 73.5 & 77.6 & 74.8 & 80.2 & 80.1          & 80.4 & 73.7 & 76.8          & 77.8          & \textbf{86.0}  \\
                                  & VGG-16          & 75.3 & 79.8 & 82.6 & 90.8 & 73.9 & 93.0 & 89.5 & 85.2 & 94.9          & 94.1 & 88.9 & 96.0          & 96.3          & \textbf{99.2}  \\
                                  & GoogleNet       & 61.3 & 78.3 & 79.4 & 91.5 & 74.5 & 94.3 & 87.9 & 84.0 & 96.1          & 93.3 & 88.1 & 96.1          & 95.3          & \textbf{99.4}  \\
                                  & Inception-V3    & 70.6 & 91.5 & 92.3 & 97.3 & 90.1 & 97.4 & 94.4 & 94.6 & 97.8          & 96.0 & 95.8 & 97.6          & 97.5          & \textbf{99.7}  \\
                                  & ResNet-152      & 54.9 & 81.4 & 80.3 & 91.9 & 71.1 & 95.6 & 87.0 & 82.0 & 96.3          & 93.1 & 89.8 & 94.7          & 95.4          & \textbf{99.3}  \\
                                  & DenseNet-121    & 64.1 & 85.7 & 85.4 & 94.7 & 80.6 & 95.8 & 91.3 & 89.2 & 97.0          & 94.9 & 92.4 & 97.4          & 97.1          & \textbf{99.7}  \\
                                  & SqueezeNet      & 85.9 & 80.1 & 84.3 & 89.6 & 78.5 & 90.3 & 89.0 & 87.1 & 92.9          & 92.8 & 87.9 & 91.9          & 93.3          & \textbf{97.6}  \\
                                  & ShuffleNet-V2   & 81.1 & 71.3 & 76.5 & 81.3 & 69.8 & 82.8 & 81.9 & 81.2 & 84.4          & 85.7 & 80.2 & 84.9          & 84.7          & \textbf{91.4}  \\
                                  & MobileNet-V3    & 63.6 & 60.1 & 65.0 & 74.0 & 71.1 & 82.4 & 72.2 & 75.5 & 86.5          & 77.9 & 70.1 & 76.3          & 77.2          & \textbf{91.1}  \\
                                  & EfficientNet-B0 & 60.3 & 77.3 & 77.9 & 90.9 & 68.2 & 94.4 & 86.7 & 80.1 & 95.7          & 93.9 & 88.1 & 93.9          & 93.6          & \textbf{99.2}  \\
                                  & MNasNet         & 67.1 & 70.3 & 74.2 & 87.0 & 63.9 & 89.6 & 84.7 & 72.8 & 92.0          & 91.0 & 81.8 & 91.7          & 90.8          & \textbf{98.3}  \\
                                  & RegNetX-400MF   & 63.6 & 72.1 & 75.8 & 86.3 & 70.3 & 90.6 & 85.1 & 79.3 & 94.6          & 91.2 & 83.9 & 91.1          & 92.1          & \textbf{98.7}  \\
                                  & ConvNeXt-T      & 45.2 & 71.9 & 71.8 & 85.3 & 47.5 & 91.6 & 77.0 & 64.8 & 93.0          & 89.2 & 83.2 & 84.4          & 84.3          & \textbf{96.2}  \\
                                  & ViT-B/16        & 37.8 & 47.1 & 51.6 & 60.4 & 49.1 & 79.6 & 57.4 & 55.9 & \textbf{82.3} & 56.8 & 60.3 & 53.4          & 53.0          & 81.3\textbf{}  \\
                                  & Swin-S          & 37.4 & 54.4 & 58.2 & 71.9 & 38.0 & 82.0 & 63.6 & 47.5 & \textbf{85.2} & 65.9 & 65.4 & 60.4\textbf{} & 59.1          & 84.2           \\
                                  & MaxViT-T        & 35.9 & 57.6 & 60.0 & 74.0 & 29.9 & 83.6 & 64.4 & 42.0 & \textbf{87.1} & 66.0 & 68.9 & 63.9          & 61.7          & 86.9\textbf{}  \\ 
\hline
FGSMAT~                           & Inception-V3    & 61.2 & 54.8 & 57.1 & 62.4 & 68.7 & 73.8 & 61.9 & 68.1 & 79.9          & 63.3 & 60.9 & 63.2          & 63.4          & \textbf{80.2}  \\ 
\cline{1-2}
EnsAT~                            & IncRes-V2       & 36.0 & 39.8 & 40.7 & 57.4 & 61.0 & 72.5 & 45.4 & 55.7 & \textbf{79.9} & 39.1 & 44.1 & 43.0          & 44.5          & 74.3\textbf{}  \\ 
\cline{1-2}
FastAT                            & ResNet-50       & 44.8 & 41.4 & 43.2 & 43.6 & 44.5 & 44.6 & 45.0 & 46.9 & 47.6          & 46.2 & 44.9 & 46.7          & 45.1\textbf{} & \textbf{48.2}  \\ 
\cline{1-2}
PGDAT~                            & ResNet-50       & 35.5 & 30.2 & 32.7 & 33.8 & 36.2 & 37.1 & 34.8 & 39.3 & \textbf{41.6} & 36.6 & 34.2 & 32.3          & 35.1          & 39.8           \\ 
\cline{1-2}
\multirow{2}{*}{PGDAT~}           & ResNet-50       & 46.5 & 40.8 & 43.6 & 43.9 & 45.1 & 45.6 & 45.1 & 47.3 & 47.6          & 47.3 & 45.2 & 45.9          & 46.0\textbf{} & \textbf{49.1}  \\
                                  & WRN-50-2        & 27.5 & 22.3 & 25.2 & 25.9 & 29.2 & 29.7 & 26.8 & 31.4 & \textbf{33.1} & 28.8 & 26.8 & 26.7          & 26.8\textbf{} & 31.5           \\ 
\cline{1-2}
\multirow{2}{*}{PGDAT$^\dagger$~} & XCiT-M12        & 21.1 & 17.1 & 18.8 & 19.7 & 22.1 & 24.5 & 20.6 & 24.5 & \textbf{29.0} & 21.7 & 19.8 & 20.4          & 20.1\textbf{} & 26.9           \\
                                  & XCiT-L12        & 18.9 & 15.0 & 18.0 & 19.5 & 19.3 & 21.8 & 18.5 & 21.1 & \textbf{26.3} & 19.3 & 19.1 & 18.2          & 17.0\textbf{} & 22.9           \\ 
\hline
HGD                               & IncRes-V2       & 45.7 & 82.3 & 81.9 & 93.2 & 78.4 & 96.1 & 84.3 & 86.4 & 96.4          & 90.7 & 90.3 & 93.1          & 92.4          & \textbf{99.5}  \\
R\&P                & ResNet-50       & 65.3 & 79.8 & 80.6 & 93.1 & 74.9 & 93.8 & 86.0 & 84.0 & 95.6          & 92.6 & 87.5 & 93.8          & 94.6          & \textbf{99.1}  \\
Bit                               & ResNet-50       & 64.8 & 78.0 & 81.3 & 92.0 & 72.6 & 94.7 & 87.1 & 83.1 & 96.4          & 93.6 & 88.9 & 94.4          & 94.8\textbf{} & \textbf{99.3}  \\
JPEG                              & ResNet-50       & 61.2 & 78.5 & 79.7 & 90.5 & 77.0 & 94.2 & 88.8 & 82.8 & 95.8          & 92.1 & 87.6 & 92.1          & 93.3          & \textbf{99.2}  \\
RS                                & ResNet-50       & 61.3 & 81.1 & 80.8 & 91.8 & 74.3 & 94.2 & 88.6 & 83.1 & 95.8          & 93.5 & 89.8 & 94.6          & 94.9\textbf{} & \textbf{99.0}  \\
NRP                               & ResNet-50       & 10.0 & 36.6 & 23.2 & 29.3 & 37.0 & 37.7 & 20.9 & 11.4 & \textbf{33.0} & 8.9  & 15.6 & 16.1          & 14.1          & 16.3           \\
DiffPure                          & ResNet-50       & 52.3 & 51.9 & 62.0 & 72.9 & 73.5 & 86.2 & 67.5 & 76.8 & 89.9          & 70.2 & 68.8 & 67.1          & 67.9          & \textbf{94.6}  \\
\hline
\end{tabu}
}
\end{table}













%----------------------------------------------
\subsection{Experiments on $\epsilon=4/255$}
Many adversarially trained models and defenses are predominantly examined within the context of the $\epsilon=4/255$ threat model. To remain consistent with these evaluations, we have also carried out an additional experiment under this specific perturbation budget, $\epsilon=4/255$.


As demonstrated in \cref{table:4/255}, our methods still achieve superior results on most target models. Notably, when attacking the adversarially trained models, our methods outperform previous methods by about 5\% on average. 
This demonstrates the strong efficacy of our methods when attacking with a small perturbation budget, especially adversarially trained models.

\begin{table}[t]
\centering
\footnotesize
\setlength{\tabcolsep}{2pt}
\caption{\textbf{Black-box attack success rate (\%, $\uparrow$) on NIPS2017 dataset}. Settings are same as \cref{sec:classification}, except for $\epsilon$, which is set to $4/255$.}
\label{table:4/255}
\scalebox{0.75}{
\begin{tabu}{l|l|cccccccccc|ccccc} 
\hline
Method                            & Backbone        & FGSM & BIM  & MI   & DI            & TI            & VMI           & SVRE & PI   & SSA  & RAP  & MI-SAM & MI-CSE & MI-CWA        & VMI-CWA       & SSA-CWA        \\ 
\hline
\multirow{16}{*}{Normal}          & AlexNet         & 43.4 & 44.2 & 45.8 & 50.3          & 47.6          & 48.5          & 48.9 & 47.8 & 55.3 & 47.7 & 49.5   & 54.9   & 54.8          & 56.6          & \textbf{59.8}  \\
                                  & VGG-16          & 39.0 & 62.2 & 67.0 & 78.7          & 50.5          & 76.4          & 71.5 & 60.4 & 72.1 & 55.6 & 76.8   & 79.3   & 76.5          & \textbf{83.1} & 77.4           \\
                                  & GoogleNet       & 35.9 & 49.3 & 54.8 & 72.8          & 41.8          & 65.4          & 58.8 & 50.8 & 70.1 & 45.4 & 63.2   & 68.4   & 64.0          & 73.4          & \textbf{76.8}  \\
                                  & Inception-V3    & 35.1 & 43.3 & 47.5 & 62.2          & 42.6          & 55.6          & 53.5 & 46.1 & 65.8 & 44.6 & 54.7   & 63.1   & 60.3          & 65.9          & \textbf{71.1}  \\
                                  & ResNet-152      & 41.7 & 79.7 & 83.7 & 83.7          & 57.6          & 90.0          & 84.5 & 75.3 & 75.8 & 59.1 & 90.4   & 90.3   & 87.3          & \textbf{93.7} & 79.8           \\
                                  & DenseNet-121    & 42.2 & 72.1 & 78.7 & 82.4          & 62.1          & 86.5          & 81.2 & 71.6 & 77.2 & 57.4 & 87.7   & 87.5   & 84.5          & \textbf{90.8} & 81.7           \\
                                  & SqueezeNet      & 49.2 & 63.3 & 67.5 & 76.1          & 56.7          & 74.4          & 73.6 & 63.3 & 76.4 & 60.7 & 73.3   & 80.3   & 79.3          & 83.7          & \textbf{84.3}  \\
                                  & ShuffleNet-V2   & 44.9 & 49.6 & 53.8 & 59.7          & 47.2          & 57.3          & 57.2 & 52.4 & 63.3 & 50.6 & 56.7   & 65.9   & 64.8          & 67.8          & \textbf{70.4}  \\
                                  & MobileNet-V3    & 33.3 & 39.9 & 42.7 & 52.2          & 46.4          & 49.5          & 44.5 & 46.8 & 56.6 & 43.3 & 47.9   & 55.2   & 54.9          & 59.7          & \textbf{65.5}  \\
                                  & EfficientNet-B0 & 29.8 & 49.7 & 57.7 & 71.2          & 37.3          & 67.9          & 55.1 & 48.2 & 62.6 & 44.3 & 66.3   & 69.0   & 64.8          & \textbf{76.2} & 69.9           \\
                                  & MNasNet         & 37.6 & 58.2 & 62.4 & 75.9          & 41.7          & 73.3          & 63.5 & 53.4 & 65.0 & 51.9 & 71.9   & 73.3   & 70.5          & \textbf{77.6} & 71.4           \\
                                  & RegNetX-400MF   & 37.0 & 56.6 & 63.4 & 75.3          & 51.7          & 74.3          & 67.1 & 59.0 & 71.7 & 51.7 & 72.5   & 79.9   & 75.9          & \textbf{83.7} & 82.4           \\
                                  & ConvNeXt-T      & 19.2 & 34.6 & 40.4 & 55.3          & 18.8          & \textbf{50.9} & 34.9 & 27.8 & 34.7 & 31.3 & 48.7   & 41.9   & 35.8          & 46.0          & 32.0           \\
                                  & ViT-B/16        & 16.0 & 16.2 & 20.5 & 24.5          & 21.6          & 26.5          & 18.0 & 23.1 & 21.8 & 20.0 & 24.0   & 25.6   & 24.6          & \textbf{26.8} & 23.4           \\
                                  & Swin-S          & 16.5 & 21.2 & 26.8 & 38.1          & 16.2          & \textbf{31.8} & 24.0 & 20.3 & 24.1 & 23.9 & 32.1   & 27.3   & 24.8          & 29.1          & 24.2           \\
                                  & MaxViT-T        & 17.1 & 21.7 & 26.3 & 39.3          & 11.2          & \textbf{32.8} & 22.5 & 18.4 & 23.4 & 23.1 & 32.2   & 25.5   & 22.4          & 28.6          & 23.7           \\ 
\hline
FGSMAT~                           & Inception-V3    & 35.5 & 35.5 & 38.1 & 40.2          & 40.8          & 39.9          & 39.3 & 38.9 & 50.6 & 40.3 & 40.0   & 51.1   & 50.1          & 50.9          & \textbf{56.3}  \\ 
\cline{1-2}
EnsAT~                            & IncRes-V2       & 21.0 & 21.2 & 22.0 & 26.8          & 28.1          & 24.7          & 23.1 & 24.9 & 32.4 & 23.5 & 23.8   & 31.0   & 31.3          & 30.8          & \textbf{36.7}  \\ 
\cline{1-2}
FastAT                            & ResNet-50       & 38.8 & 39.3 & 39.3 & 39.8          & 40.2          & 39.5          & 39.9 & 40.1 & 42.2 & 39.9 & 39.9   & 45.6   & \textbf{46.1} & \textbf{46.1} & 45.4           \\ 
\cline{1-2}
PGDAT~                            & ResNet-50       & 25.7 & 26.7 & 27.4 & 28.0          & 28.3          & 27.9          & 27.9 & 27.9 & 30.2 & 27.9 & 27.9   & 36.7   & \textbf{36.7} & 36.2          & 33.7           \\ 
\cline{1-2}
\multirow{2}{*}{PGDAT~}           & ResNet-18       & 38.3 & 38.6 & 39.0 & 39.5          & 40.8          & 39.1          & 39.6 & 40.0 & 41.7 & 39.6 & 39.5   & 45.9   & \textbf{45.8} & 45.6          & 45.7           \\
                                  & WRN-50-2        & 17.9 & 18.4 & 18.7 & 19.7          & 20.0          & 18.9          & 19.2 & 19.4 & 20.9 & 19.9 & 19.4   & 28.1   & \textbf{28.1} & 27.4          & 25.5           \\ 
\cline{1-2}
\multirow{2}{*}{PGDAT$^\dagger$~} & XCiT-M12        & 13.3 & 13.5 & 14.0 & 15.0          & 15.5          & 14.9          & 15.1 & 15.2 & 15.4 & 15.2 & 14.8   & 25.5   & \textbf{25.6} & 24.9          & 19.9           \\
                                  & XCiT-L12        & 12.5 & 13.4 & 14.0 & 14.0          & 14.7          & 14.4          & 14.8 & 15.0 & 15.2 & 15.2 & 14.6   & 23.3   & \textbf{22.9} & 22.3          & 18.8           \\ 
\hline
HGD                               & IncRes-V2       & 18.7 & 26.8 & 31.9 & \textbf{50.8} & 30.7          & 43.4          & 26.6 & 32.3 & 31.8 & 24.5 & 39.0   & 34.0   & 29.8          & 38.7          & 33.5           \\
R\&P                & ResNet-50       & 51.9 & 86.3 & 89.7 & 91.4          & 76.6          & 93.1          & 93.5 & 85.5 & 85.4 & 67.8 & 93.0   & 94.8   & 93.8          & \textbf{95.9} & 89.0           \\
Bit                               & ResNet-50       & 56.8 & 95.0 & 95.9 & 88.1          & 82.5          & 96.5          & 98.0 & 92.0 & 91.0 & 81.4 & 97.1   & 99.0   & 99.3          & \textbf{99.8} & 95.6           \\
JPEG                              & ResNet-50       & 52.4 & 82.3 & 88.3 & 82.4          & 83.0          & 93.9          & 88.5 & 86.9 & 83.0 & 66.0 & 93.3   & 90.8   & 89.6          & \textbf{97.3} & 87.9           \\
RS                                & ResNet-50       & 47.2 & 86.3 & 89.1 & 86.8          & 67.3          & 92.7          & 91.0 & 82.3 & 83.5 & 68.5 & 93.0   & 94.8   & 93.4          & \textbf{96.2} & 88.5           \\
NRP                               & ResNet-50       & 47.0 & 78.7 & 81.9 & 76.1          & 65.6          & 87.3          & 86.0 & 72.0 & 72.6 & 60.7 & 88.3   & 78.0   & 76.7          & \textbf{83.6} & 69.6           \\
DiffPure                          & ResNet-50       & 23.9 & 22.0 & 25.6 & 33.1          & \textbf{40.4} & 28.8          & 23.6 & 35.2 & 31.5 & 26.4 & 28.2   & 28.7   & 29.0          & 30.8          & 33.2           \\
\hline
\end{tabu}
}
\end{table}


%----------------------------------------











\begin{table}[t]
\centering
\small
\caption{\textbf{Black-box attack success rate (\%, $\uparrow$)} of our methods without incorporating with MI.}
\label{table:withoutMI}
\begin{tabu}{l|l|ccclll} 
\hline
Method                            & Backbone        & FGSM & BIM  & MI   & SAM  & CSE  & CWA   \\ 
\hline
\multirow{16}{*}{Normal}          & AlexNet         & 76.4 & 54.9 & 73.2 & 69.5 & 88.1 & 87.3  \\
                                  & VGG-16          & 68.9 & 86.1 & 91.9 & 94.3 & 92.5 & 87.6  \\
                                  & GoogleNet       & 54.4 & 76.6 & 89.1 & 92.5 & 92.8 & 88.5  \\
                                  & Inception-V3    & 54.5 & 64.9 & 84.6 & 84.4 & 90.4 & 88.4  \\
                                  & ResNet-152      & 54.5 & 96.0 & 96.6 & 98.0 & 95.3 & 89.1  \\
                                  & DenseNet-121    & 57.4 & 93.0 & 95.8 & 97.7 & 95.5 & 88.1  \\
                                  & SqueezeNet      & 85.0 & 80.4 & 89.4 & 91.3 & 94.6 & 91.2  \\
                                  & ShuffleNet-V2   & 81.2 & 65.3 & 79.9 & 82.4 & 91.9 & 90.9  \\
                                  & MobileNet-V3    & 58.9 & 55.6 & 71.8 & 73.1 & 90.6 & 89.7  \\
                                  & EfficientNet-B0 & 50.8 & 80.2 & 90.1 & 93.6 & 93.3 & 87.6  \\
                                  & MNasNet         & 64.1 & 80.8 & 88.8 & 93.0 & 90.9 & 87.2  \\
                                  & RegNetX-400MF   & 57.1 & 81.1 & 89.3 & 92.9 & 93.6 & 90.1  \\
                                  & ConvNeXt-T      & 39.8 & 68.6 & 81.6 & 86.7 & 83.0 & 72.5  \\
                                  & ViT-B/16        & 33.8 & 35.0 & 59.2 & 55.8 & 84.5 & 83.2  \\
                                  & Swin-S          & 34.0 & 48.2 & 66.0 & 69.6 & 80.2 & 72.0  \\
                                  & MaxViT-T        & 31.3 & 49.7 & 66.1 & 71.1 & 78.5 & 69.0  \\ 
\hline
FGSMAT~                           & Inception-V3    & 53.9 & 43.4 & 55.9 & 55.7 & 88.5 & 89.8  \\ 
\cline{1-2}
EnsAT~                            & IncRes-V2       & 32.5 & 28.5 & 42.5 & 40.3 & 82.1 & 83.4  \\ 
\cline{1-2}
FastAT                            & ResNet-50       & 45.6 & 41.6 & 45.7 & 46.0 & 72.2 & 74.7  \\ 
\cline{1-2}
PGDAT~                            & ResNet-50       & 36.3 & 30.9 & 37.4 & 36.5 & 70.2 & 72.9  \\ 
\cline{1-2}
\multirow{2}{*}{PGDAT~}           & ResNet-18       & 46.8 & 41.0 & 45.7 & 43.6 & 70.8 & 73.6  \\
                                  & WRN-50-2        & 27.7 & 20.9 & 27.8 & 26.4 & 64.7 & 68.1  \\ 
\cline{1-2}
\multirow{2}{*}{PGDAT$^\dagger$~} & XCiT-M12        & 23.0 & 16.4 & 22.8 & 22.8 & 73.0 & 77.7  \\
                                  & XCiT-L12        & 19.8 & 15.7 & 19.8 & 20.5 & 67.1 & 72.0  \\ 
\hline
HGD                               & IncRes-V2       & 36.0 & 78.0 & 76.2 & 82.8 & 86.4 & 81.9  \\
R\&P                & ResNet-50       & 67.9 & 95.8 & 96.3 & 98.3 & 95.0 & 88.7  \\
Bit                               & ResNet-50       & 69.1 & 97.0 & 97.3 & 98.8 & 97.5 & 89.3  \\
JPEG                              & ResNet-50       & 68.5 & 96.0 & 96.3 & 98.6 & 96.1 & 89.0  \\
RS                                & ResNet-50       & 60.9 & 96.1 & 95.6 & 98.2 & 95.8 & 89.9  \\
NRP                               & ResNet-50       & 36.6 & 88.7 & 72.4 & 92.4 & 82.9 & 62.7  \\
DiffPure                          & ResNet-50       & 50.9 & 68.5 & 76.0 & 67.9 & 83.3 & 82.8  \\
\hline
\end{tabu}
\end{table}




























%------------------------------------------

\subsection{Visualization of Adversarial Patches}


\begin{figure}[h]
\centering
\subfigure[YOLOv3]{
\includegraphics[width=2.1cm]{./figures/v3.png}
}
\quad
\subfigure[YOLOv5]{
\includegraphics[width=2.1cm]{./figures/v5.png}
}
\quad
\subfigure[Loss Avg]{
\includegraphics[width=2.1cm]{./figures/ensemble.png}
}
\quad
\subfigure[Adam-CWA]{
\includegraphics[width=2.1cm]{./figures/CW.png}
}
\quad
\subfigure[Strongest]{
\includegraphics[width=2.1cm]{figures/strongest_patch.png}
\label{figure:strongestpatch}
}
\caption{\textbf{Visualization of adversarial patches from different methods.} The patch simply trained by loss ensemble looks like the fusion of those trained by YOLOv3 and YOLOv5. Adam-CWA captures the common weakness of YOLOv3 and YOLOv5, and therefore generates an completely different patch.}
\vspace{-2ex}
\label{figure:patch}
\end{figure}


As illustrated in \cref{figure:patch}, we observe that YOLOv5 is more vulnerable to adversarial attacks compared to YOLOv3. Consequently, the patch generated by the Loss Ensemble method resembles the one obtained by YOLOv5, resulting in similar performance for both patches. We hypothesize that the Loss Ensemble method does not attack the common weakness of YOLOv3 and YOLOv5, and instead nearly solely relies on information from YOLOv5. Contrarily, our proposed method, aims to exploit this common vulnerability and generates a patch that differs significantly from both YOLOv3 and YOLOv5. As a result, our patch are more effective in attacking the object detectors.





In order to craft the strongest universal adversarial patch for object detectors, we ensemble all the models in \citet{tsea} and craft an adversarial patch by our CWA algorithm. The patch is visualized in \cref{figure:strongestpatch}. Our patch outperforms previous patches by a large margin. Compared to the previous state-of-the-art methods~(\ie, the loss ensemble by enhanced baseline in \citet{tsea}), our approach improves by 4.26\%, achieving 4.69\% mAP on eight testing models in \cref{table:detection}.































%--------------------------------------------------------


\subsection{Ablation studies}
In this section, we investigate the roles of the two additional hyperparameters: the reverse step size $r$ and the inner step size $\beta$. We use the same experimental settings as \cref{sec:classification}, and average the attack success rates across all target models.

\begin{figure*}[h]
\centering
\subfigure[$\beta$]{
\includegraphics[width=4cm]{./figures/ablateinnerstepsize.pdf}
\label{figure:ablatebeta}
}
\subfigure[$r$]{
\includegraphics[width=4cm]{./figures/ablater.pdf}
\label{figure:ablater}
}
\subfigure[$\alpha$]{
\includegraphics[width=4cm]{./figures/ablate_alpha.pdf}
\label{figure:ablate_alpha}
}
\end{figure*}

\textbf{Ablation study on inner step size $\beta$. }
Our MI-CSE algorithm could be viewed as optimizing the original loss using the learning rate $\beta$ and the cosine similarity regularization term using the learning rate $\frac{\beta^2}{2}$. As shown in \cref{figure:ablatebeta}, as $\beta$ increases, the proportion of the regularization term gradually increases, leading to an increase in the attack success rate. However, when $\beta$ becomes too large, the error of our algorithm also increases, causing the attack success rate to plateau or decrease. Therefore, we need to choose an appropriate value of $\beta$ to balance between the effectiveness of the regularization term and the overall performance of the algorithm.


\textbf{Ablation study on reverse step size $r$. }
\cref{figure:ablater} shows that the attack success rate initially increases and then decreases as $16/255/r$ increases. This is because when the reverse step size is too large, the optimization direction is opposite to the forward step, leading to a decrease in the attack success rate. Thus, decreasing the reverse step size initially increases the attack success rate. As the reverse step size continues to decrease, MI-CWA gradually degrade to MI-CSE, causing the attack success rate to converge to MI-CSE.



\textbf{Ablation study on step size $\alpha$. } 
We evaluate the average attack success rate for various $\alpha$, ranging from 16/255/1 to 16/255/20. As depicted in \cref{figure:ablate_alpha}, When $\alpha < 0.01$, the reverse step size surpass the forward step size. This results in opposing optimization directions and subsequently causes a sharp decline in the efficacy of our method. For $\alpha > 0.01$, the attack success rate remains relatively consistent regardless of specific value of $\alpha$. This showcases our method's resilience to hyper-parameter variations.






\textbf{Ablation study on momentum.} 
We also conduct an experiment where our methods are not combined with MI-FGSM. It is important to note that in other experiments, our methods and the baselines we compare against, except for BIM and FGSM, are combined with MI-FGSM. As shown in \cref{table:withoutMI}, our methods still achieve superior results than FGSM and BIM. However, it is notable that there is a significant decrease in performance compared with the results that incorporate MI-FGSM. This experiment demonstrates that MI-FGSM has become a popular plug-and-play module capable of efficiently enhancing the performance of various attack algorithms, and it has even become a fundamental and indivisible component in the development of advanced attack algorithms.

