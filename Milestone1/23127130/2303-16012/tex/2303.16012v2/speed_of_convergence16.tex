%% LyX 2.3.6 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass{article}
\usepackage{lmodern}
\renewcommand{\sfdefault}{lmss}
\renewcommand{\ttdefault}{lmtt}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{xcolor}
\usepackage[english]{babel}
\usepackage{array}
\usepackage{verbatim}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[round]{natbib}
\usepackage{breakcites}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 0},pdfborderstyle={},backref=false,colorlinks=false]
 {hyperref}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}[section]
\theoremstyle{plain}
\newtheorem{lem}[thm]{\protect\lemmaname}
\theoremstyle{definition}
\newtheorem{example}[thm]{\protect\examplename}
\theoremstyle{remark}
\newtheorem{rem}[thm]{\protect\remarkname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage[round]{natbib}

\makeatother

\providecommand{\examplename}{Example}
\providecommand{\lemmaname}{Lemma}
\providecommand{\remarkname}{Remark}
\providecommand{\theoremname}{Theorem}

\begin{document}
\title{How to handle the COS method for option pricing}
\author{Gero Junike\thanks{Carl von Ossietzky Universität, Institut für Mathematik, 26129 Oldenburg,
Germany, E-mail: gero.junike@uol.de}}
\maketitle
\begin{abstract}
The Fourier Cosine Expansion (COS) method is used to price European
options numerically in a very efficient way. To apply the COS method,
one has to specify two parameters: a truncation range for the density
of the log-returns and a number of terms $N$ to approximate the truncated
density by a cosine series. How to choose the truncation range is
already known. Here, we are able to find an explicit and useful bound
for $N$ as well. We further show that the COS method has at least
an exponential order of convergence when the density is smooth and
decays exponentially. However, when the density is smooth and has
heavy tails, as in the Finite Moment Log Stable model, the COS method
does not have exponential order of convergence. Numerical experiments
confirm the theoretical results.
\end{abstract}
\begin{comment}
todo:
\begin{itemize}
\item define series truncation error somewhere before Section ``how to
find N''
\item add literature for FMLS, Mandelbrot etc and references from Carr-Wu
\item Add why stable is $C^{\infty}$
\item add to table Junike\&Pank: We solved the minimization problem in Equation
(\ref{eq:N_NIG}) by testing all $j\leq10^{6}$. 
\item add ``in a numerical fast way'' in Remark \ref{rem:Theorem_A}
\item How to optimize $j$ and cpu time.
\item add to remark after first theorem: The minimization task in Equation
(\ref{eq:N_J>0}) can also be determined numerically efficiently.
\item add to Remark \ref{rem:Theorem_A} ``The bounds Hj are explicitly
known for some models ... and can be estimated as well, see Section
\ref{sec:Numerical-experiments}''
\item Add Stefan Tappe comment.
\item Add reference for
\[
\left\Vert f_{L}-\sum_{k=0}^{N}{}^{\prime}a_{k}e_{k}\right\Vert _{2}=\sqrt{\sum_{k=N+1}^{\infty}|a_{k}|^{2}}
\]
\item Use L'Hôpital's\_rule to show that $H_{j}$ of NIG dominates any f\textasciicircum (j)
is $\delta$ large enough.
\item Discuss with Marcus:
\begin{itemize}
\item Assumptions
\item fitting NIG
\item remove Cauchy
\end{itemize}
\end{itemize}
\end{comment}


\section{Introduction}

For model calibration, it is of utmost importance to price European
options very quickly because stock price models are typically calibrated
to given prices of liquid call and put options by minimizing the mean-square-error
between model prices and given market prices. During the optimization
routine, the model prices of call and put options need to be evaluated
very often for different model parameters, see \cite{fang2009novel,junike2022precise}. 

To compute the price of a European option, one must solve an integral
involving the product of the density of the log-returns at maturity
and the payoff function. However, for many financial models, the density
$f$ of the log-returns is unknown. Fortunately, the characteristic
function of the log-returns is often given in closed-form and can
be used to obtain the density. 

In their seminal paper, \cite{fang2009novel} proposed the COS method,
which is a very efficient way to approximate the density and to compute
option prices. The COS method requires two parameters: a truncation
range for the density of the log-returns and a number of terms $N$
to approximate the truncated density by a cosine series. While it
is known how to choose the truncation range, see \cite{junike2022precise},
the choice of $N$ is largely based on trial and error. The COS method
has been extensively extended and applied, see \cite{fang2009pricing, fang2011fourier, grzelak2011heston,ruijter2012two,zhang2013efficient, leitao2018data, liu2019neural, liu2019pricing, oosterlee2019mathematical,bardgett2019inferring}.
Other Fourier pricing techniques are discussed e.g. by \cite{carr1999option, lord2008fast, ortiz2013robust, ortiz2016highly}.

With respect to these papers we make two main contributions: a) we
develop an explicit, useful and rigorous bound for $N$ and b) we
analyze the order of convergence of the COS method in detail.

\cite{fang2009novel} proposed to approximate the (unknown) density
in three steps: i) Truncate the density $f$, i.e. approximate $f$
by a function $f_{L}$ with finite support on some (sufficiently large)
interval $[-L,L]$. ii) Approximate $f_{L}$ by a Fourier cosine expansion
$\sum a_{k}e_{k}(x)$, where $a_{k}$ are Fourier coefficients of
$f_{L}$ and $e_{k}$ are cosine basis functions. iii) Approximate
$a_{k}$ by some coefficients $c_{k}$ which can be obtained directly
from the characteristic function of $f$. Thus, to apply the COS method,
two decisions must to be made: find a suitable truncation range $[-L,L]$
and identify the number $N$ of cosine functions.

\cite{junike2022precise} applied a simple triangle equation to bound
the error of the three approximations and obtained:
\begin{equation}
\bigg\| f-\sideset{}{'}\sum_{k=0}^{N}c_{k}e_{k}\bigg\|_{2}\leq\big\Vert f-f_{L}\big\Vert_{2}+\Big\Vert f_{L}-\sideset{}{'}\sum_{k=0}^{N}a_{k}e_{k}\Big\Vert_{2}+\Big\Vert\sideset{}{'}\sum_{k=0}^{\infty}(a_{k}-c_{k})e_{k}\Big\Vert_{2}.\label{eq:error_bound}
\end{equation}
The first, second and third terms at the right-hand-side of Inequality
(\ref{eq:error_bound}) correspond to approximations due to i), ii),
and iii), respectively. 

\cite{junike2022precise} developed explicit expressions for bounds
for the first and third terms on the right-hand-side of Inequality
(\ref{eq:error_bound}), which depend only on the choice of $L$,
not on the choice of $N$. When $f$ has semi-heavy tails, i.e. the
tails decay exponentially, \cite{junike2022precise} applied Markov's
inequality to obtain an explicit and useful expression for $L$. 

Recently, \cite{aimi2023fast} proposed some hints on how to choose
$N$. But, to the best of our knowledge, a rigorous bound on $N$
to ensure a certain precision of the COS method is not yet known.
On the other hand, it is well known that the series truncation error,
i.e. the second term on the right-hand-side of Inequality (\ref{eq:error_bound}),
can be bounded using integration by parts, see \cite{boyd2001chebyshev}.
In this article, we use this idea to find an explicit and useful bound
for $N$, which involves the bound of the $j^{th}$-derivative of
the density $f$. 

For some models such as the Black-Scholes model, see \cite{black1973pricing},
the Normal Inverse Gaussian (NIG) model, see \cite{barndorff1997normal},
or the Finite Moment Log Stable (FMLS) model, see \cite{carr2003finite},
we find sharp bounds for all derivatives of the density of $f$ in
closed-form. In general, those bounds can also be estimated numerically.
We obtain an explicit and useful bound for $N$, which is provably
large enough to ensure that the COS method converges within a predefined
error tolerance.%
\begin{comment}
For other models like the Heston model, see \cite{heston1993closed},
we propose to fit a flexible density like the NIG density to the moments
of the log-returns in the Heston model and then use the explicit bounds
from the NIG model to estimate the bounds of the derivative of the
density in the Heston model. This is numerically very efficient and
it works well as shown by extensive numerical experiments.
\end{comment}

\cite{fang2009novel} also analyzed the order of convergence of the
COS method focusing on the second term on the right-hand-side of Inequality
(\ref{eq:error_bound}). They concluded that with a properly chosen
truncation range, the overall error converges exponentially for smooth
density functions and compares favorably to the Carr-Madan formula,
see \cite{carr1999option}. 

In this article, we also consider the errors introduced by the truncation
range, i.e., errors due to i), ii), and iii) and establish upper bounds
for the order of convergence of the COS method. We confirm, both theoretically
and empirically, that the COS method indeed converges exponentially
for smooth density functions if in addition, the tails of the density
decay at least exponentially. 

However, for fat-tailed and smooth densities such as the Cauchy density
or the density of the log-returns in the FMLS model, the truncation
error due to i) and iii) becomes much more relevant compared to densities
with semi-heavy tails. We show theoretically that the COS method converges
at least as fast as $O(N^{-\alpha})$ for $N\to\infty$, where $\alpha>0$
is the Pareto tail index, e.g. for the Cauchy density, $\alpha=1$
and for the FMLS model $\alpha\in(1,2)$. Empirical experiments indicate
that the COS method converges as fast as $O(N^{-\alpha})$, i.e. the
theoretical bound is sharp.

This article is structured as follows: Section \ref{sec:Overview:-the-COS}
gives an overview of the technical details of the COS method. Section
\ref{sec:How-to-find} gives explicit formulas for the truncation
range $L$ and the number of terms $N$. Section \ref{sec:Convergence-rate-of}
analyzes the order of convergence of the COS method. In Sections \ref{sec:How-to-find}
and \ref{sec:Convergence-rate-of}, we distinguish between models
with semi-heavy tails and models with heavy tails. Section \ref{sec:Numerical-experiments}
contains numerical experiments which confirm the theoretical results.
Section \ref{sec:Conclusions} concludes. 

\section{\label{sec:Overview:-the-COS}Overview: the COS method for option
pricing.}

We model the stock price over time by a stochastic process $(S_{t})_{t\geq0}$
on a filtered probability space. We assume that there is a bank account
paying continuous compound interest $r\in\mathbb{R}$. The market
is assumed to be arbitrage free and we denote by $Q$ the risk-neutral
measure. All expectations are taken under $Q$. 

There is a European option with maturity $T>0$ and payoff $g(S_{T})$
at $T$, where $g:[0,\infty)\to\mathbb{R}$. For example, a European
put option with strike $K>0$ can be described by $g(x)=\max(K-x,0)$,
$x\geq0$. 

In several places, we assume that the payoff function is bounded.
The prices of European call options are not bounded, but can be obtained
from the prices of put options by the put-call parity.

Provided that the characteristic function $\varphi_{\log(S_{T})}$
of $\log(S_{T})$ is given in closed-form, the COS method is able
to price the European option numerically very quickly as follows:
we denote by
\[
X:=\log(S_{T})-E[\log(S_{T})],
\]
the \emph{centralized log-returns}. The expectation can be computed
by
\[
E[\log(S_{T})]=-i\varphi_{\log(S_{T})}^{\prime}(0).
\]
The characteristic function $\varphi$ of $X$ is then given by
\[
\varphi(u)=\varphi_{\log(S_{T})}(u)\exp(-iuE[\log(S_{T})]),\quad u\in\mathbb{R}.
\]
We assume that $X$ has a density $f$, but the exact structure of
$f$ need not be known. Since the density of $X$ is centered around
zero, it is justified to truncate the density $f$ on a symmetric
interval $[-L,L]$, see \cite{junike2022precise}. Define
\[
v(x):=e^{-rT}g(\exp(x+E[\log(S_{T})]),\quad x\in\mathbb{R}.
\]
The price of the European option is then given by
\begin{align*}
e^{-rT}E[g(S_{T})] & =\int_{\mathbb{R}}v(x)f(x)dx.
\end{align*}
We need some abbreviations to discuss the COS method: for $L>0$ let
$f_{L}:=1_{[-L,L]}f$. Define the basis functions 
\[
e_{k}(x)=\cos\left(k\pi\frac{x+L}{2L}\right),\quad k=0,1,...
\]
and the Fourier coefficients of $f_{L}$ are given by $a_{k}$ and
approximated by $c_{k}$, where 
\[
a_{k}:=\frac{1}{L}\int_{-L}^{L}f(x)e_{k}(x)dx\quad\text{and}\quad c_{k}:=\frac{1}{L}\int_{\mathbb{R}}f(x)e_{k}(x)dx,\quad k=0,1,...
\]
Observe
\[
c_{k}=\frac{1}{L}\Re\bigg\{\varphi\bigg(\frac{k\pi}{2L}\bigg)e^{i\frac{k\pi}{2}}\bigg\},\quad k=0,1,...,
\]
i.e. the coefficients $c_{k}$ can be obtained explicitly if $\varphi$
is given in closed-form. Here, $\Re(z)$ denotes the real part of
a complex number $z$. For $0<M\leq L$ define
\begin{equation}
v_{k}:=\int_{-M}^{M}v(x)e_{k}(x)dx,\quad k=0,1,...\label{eq:vk}
\end{equation}
To keep the notation simple, we suppress the dependence of $e_{k}$
and $c_{k}$ on $L$ and the dependence of $v_{k}$ on $M$. The COS
method states that the price of the European option can be approximated
by
\begin{equation}
\int_{\mathbb{R}}v(x)f(x)dx\approx\int_{-M}^{M}v(x)\sideset{}{'}\sum_{k=0}^{N}c_{k}e_{k}(x)dx=\sum_{k=0}^{N}{}^{\prime}c_{k}v_{k},\label{eq:COS_method}
\end{equation}
where $\sum{}^{\prime}$ indicates that the first summand (with $k=0$)
is weighted by one-half. The coefficients $c_{k}$ are given in closed-form
when $\varphi$ is given analytically and the coefficients $v_{k}$
can also be computed explicitly in important cases, e.g. for plain
vanilla European put or call options and digital options, see for
instance appendix in \cite{junike2022precise}. This makes the COS
method numerically very efficient and robust. 

To give the approximation in line (\ref{eq:COS_method}) a precise
meaning, we need a bound for the term
\begin{equation}
B(L):=\sum_{k=0}^{\infty}\frac{1}{L}\left|\int_{\mathbb{R}\setminus[-L,L]}f(x)\cos\left(k\pi\frac{x+L}{2L}\right)dx\right|^{2},\quad L>0.\label{eq:B(L)}
\end{equation}
\cite{junike2022precise} called integrable functions $f$ with $B(L)\to0$,
$L\to\infty$ \emph{COS-admissible.} The term $\sqrt{B(L)}$ is equal
to third term at the right-hand-side of Inequality (\ref{eq:error_bound}). 

The class of COS-admissible densities is very large, in particular
it includes bounded densities with existing first and second moments.
The next Lemma \ref{lem:cor8} is taken from \cite{junike2022precise}.
Theorem \ref{thm:find_N_A_B} and Theorem \ref{thm:find_N_C} apply
Lemma \ref{lem:cor8} and provide explicit formulas for the parameters
$M$, $L$ and $N$ of the COS method for densities with semi-heavy
tails and heavy tails, respectively.
\begin{lem}
\label{lem:cor8}Let $f$ be integrable and COS-admissible. Let $v:\mathbb{R}\to\mathbb{R}$
be bounded, with $|v(x)|\le K$ for all $x\in\mathbb{R}$ and some
$K>0$. Let $\varepsilon>0$. Let $M>0$ so that
\[
\int_{\mathbb{R}\setminus[-M,M]}v(x)f(x)dx\leq\frac{\varepsilon}{2}.
\]
Define $\xi=\sqrt{2M}K$. Let $L\geq M$ so that
\[
\left\Vert f-f_{L}\right\Vert _{2}\leq\frac{\varepsilon}{6\xi},\quad\text{and}\quad\sqrt{B(L)}\leq\frac{\varepsilon}{6\xi}.
\]
Choose $N_{L}$ large enough so that
\[
\left\Vert f_{L}-\sum_{k=0}^{N}{}^{\prime}a_{k}e_{k}\right\Vert _{2}\leq\frac{\varepsilon}{6\xi}.
\]
Then it holds for all $N\geq N_{L}$ that
\[
\left|\int_{\mathbb{R}}v(x)f(x)dx-\sum_{k=0}^{N}{}^{\prime}c_{k}v_{k}\right|\leq\varepsilon.
\]
\end{lem}

\begin{proof}
\citet[Cor. 8]{junike2022precise}.
\end{proof}
Often, it is fine to choose $M=L$, e.g. when applying the COS method
to densities with semi-heavy tails. However, if the density has heavy
tails, it is usually numerically more efficient to choose $L$ and
$M$ differently.

The main requirement for applying the COS method is the availability
of the characteristic function in closed-form. Many models satisfy
this requirement and we list a some examples: 
\begin{description}
\item [{BS}] the Black-Scholes model with volatility $\sigma$, see \cite{black1973pricing}, 
\item [{MJD}] the Merton jump diffusion model with intensity $\eta>0$,
instantaneous variance of returns (conditional on no arrival of jumps)
$\sigma>0$, expected percentage jump-size $\kappa\in(-1,\infty)$
and standard deviation of the logarithmic jumps $\text{\ensuremath{\delta>0}}$,
see \cite{merton1976option},
\item [{Heston}] the Heston model with speed of mean-reversion $\kappa>0$,
level of mean-reversion $\eta>0$, vol of var $\theta>0$, initial
vol $v_{0}>0$ and correlation $\rho\in[-1,1]$, see \cite{heston1993closed}, 
\item [{VG}] the variance gamma model with parameters $\sigma>0$, $\theta\in\mathbb{R}$
and $\nu>0$, see \cite{madan1998variance},
\item [{NIG}] the normal inverse Gaussian model with parameters $\alpha>0$,
$\beta\in(-\alpha,\alpha)$ and $\delta>0$, see \cite{barndorff1997normal}
and \citet[Sec. 5.3.8]{schoutens2003levy}.
\item [{CGMY}] the CGMY model with parameters $C>0$, $G>0$, $M>0$, $Y<2$,
see \cite{carr2002fine},
\item [{FMLS}] the Finite Moment Log Stable model with parameters $\sigma>0$
and $\alpha\in(1,2)$, see \cite{carr2003finite}.
\end{description}
To use the COS method, two parameters must be specified: $L>0$ to
define the truncation range and $N\in\mathbb{N}$ to set the number
of terms. The former can be estimated by making assumptions on the
tail-behavior of the density. The latter depends on the smoothness
of the density. 

The densities of the models listed above have the following properties
regarding tail-behavior and smoothness: The density of the log-returns
in the BS, NIG, Heston models and the CGMY model with parameter $Y\in(0,1)$,
is infinitely many times differentiable and has semi-heavy tails,
i.e. the tails decay exponentially, see \cite{kuchler2013tempered, asmussen2022role,albin2009asymptotic,schoutens2003levy,dragulescu2002probability}. 

The density of the VG model at time $T>0$ has semi-heavy tails, see
\citet[Example 7.5]{albin2009asymptotic} and is $(J+1)$-times continuously
differentiable if $J+2<\frac{2T}{\nu}$, see \citet[Thm. 4.1]{kuchler2008shapes}.

The stable law has been used to model stock prices since \cite{mandelbrot1997variation}
and \cite{fama1965behavior}. The density of the FMLS model also belongs
to the family of stable densities with maximum negative skewness.
It is infinitely many times differentiable and has a heavy left tail
with Pareto index $\alpha$, i.e. the left tail decays like $|x|^{-1-\alpha}$,
$x\to-\infty$, but the right tail decays exponentially, see \cite{carr2003finite}.
This makes the FMLS very attractive from a theoretical point of view:
put and call option prices and all moments of the underlying stock
price $S_{T}$ exist. The expectation of the log-returns also exists,
but the log-returns do not have finite variance. Fitting the FMLS
model to real market data shows very satisfactory results, see \cite{carr2003finite}. 

\section{\label{sec:How-to-find}How to find $M$, $L$ and $N$}

We summarize the assumptions about the density $f$ of the log-returns
in order to find explicit expressions for $L$ and $N$.

Let $\mathbb{N}_{0}=\{0\}\cup\mathbb{N}$ and $J\in\mathbb{N}_{0}$.
We denote by $C_{b}^{J+1}(\mathbb{R})$ the $(J+1)$-times, continuously
differentiable functions from $\mathbb{R}$ to $\mathbb{R}$ which
are bounded with bounded derivatives. 

By $f^{(j)}$ we denote the $j^{th}$-derivative of $f$. We use the
convention $f^{(0)}\equiv f$. We denote by $H_{j}>0$ a bound for
$f^{(j)}$, i.e. $|f^{(j)}(x)|\leq H_{j}$, $x\in\mathbb{R}$. 

Let $C_{1},C_{2},C_{3}>0$ be suitable constants. Let $L_{0}>0$ be
large enough. Suppose that $f$ satisfies one of the following assumptions:
\begin{description}
\item [{Assumption~A:}] $f\in C_{b}^{J+1}(\mathbb{R})$ is integrable
and $f$ has semi-heavy tails, i.e.
\begin{equation}
|f^{(j)}(x)|\leq C_{1}e^{-C_{2}|x|},\quad j=0,...,J+1,\quad|x|\geq L_{0}.\label{eq:A}
\end{equation}
\item [{Assumption~B:}] $f\in C_{b}^{J+1}(\mathbb{R})$ is integrable
and $f$ has heavy tails with index $\alpha>0$, i.e.
\begin{equation}
|f^{(j)}(x)|\leq C_{3}|x|^{-1-\alpha-j},\quad j=0,...,J+1,\quad|x|\geq L_{0}.\label{eq:B}
\end{equation}
\end{description}
We use the following abbreviations: the maximum of two real numbers
$x,y$, is denoted by $x\lor y$. For $L>0$ we define $f_{L}:=1_{[-L,L]}f$.
By $\Gamma$ we denote the gamma function
\[
\thinspace\Gamma(z)=\int_{0}^{\infty}u^{z-1}e^{-u}du,\quad\Re(z)>0.
\]

The following lemma allows to bound the series-truncation error, which
depends only on the choice of $N$. It is known in a similar form
in the literature, see e.g. Theorem 1.39 in \cite{plonka2018numerical},
Theorem 4.2 in \cite{wright2015extension} or Theorem 6 in \cite{boyd2001chebyshev}
and can be proved by integration by parts. It is usually stated for
functions with range $[-1,1]$ or $[0,2\pi]$. Here, we explicitly
need the dependence of the series-truncation error on the truncation
range $[-L,L]$, so we give the full proof. 
\begin{lem}
\label{lem:A2}Let $J\in\mathbb{N}_{0}$. If $f\in C_{b}^{J+1}(\mathbb{R})$
it holds for $J\geq1$
\begin{equation}
\left\Vert f_{L}-\sum_{k=0}^{N}{}^{\prime}a_{k}e_{k}\right\Vert _{2}\leq\sum_{j=1}^{J}\frac{2^{j+1}}{j\pi^{j+1}}\frac{L^{j}}{N^{j}}\left(|f^{(j)}(-L)|+|f^{(j)}(L)|\right)+\frac{2^{J+2}H_{J+1}}{J\pi^{J+1}}\frac{L^{J+1}}{N^{J}}\label{eq:trun_error}
\end{equation}
and for $J=0$
\[
\left\Vert f_{L}-\sum_{k=0}^{N}{}^{\prime}a_{k}e_{k}\right\Vert _{2}\leq\frac{4H_{1}}{\pi}\frac{L}{\sqrt{N}}.
\]
\end{lem}

\begin{proof}
It holds for any $\nu>0$ by integration by parts, see \citet[Eq. 1.3]{lyness1971adjusted},
\begin{align}
\int_{-L}^{L}f(x)e^{i\nu x}dx= & \sum_{j=0}^{J}\frac{i^{j+1}}{\nu^{j+1}}\left(e^{-i\nu L}f^{(j)}(-L)-e^{i\nu L}f^{(j)}(L)\right)\nonumber \\
 & +\frac{i^{J+1}}{\nu^{J+1}}\int_{-L}^{L}f^{(J+1)}(x)e^{i\nu x}dx.\label{eq:lyness}
\end{align}
For $k\in\mathbb{N}$, we apply Equation (\ref{eq:lyness}) for $\nu:=\frac{k\pi}{2L}$.
Then it follows that
\begin{align*}
|a_{k}|= & \frac{1}{L}\left|\int_{-L}^{L}f(x)\cos\left(k\pi\frac{x+L}{2L}\right)dx\right|\\
= & \frac{1}{L}\left|\Re\left\{ e^{i\frac{k\pi}{2}}\int_{-L}^{L}f(x)e^{i\frac{k\pi}{2L}x}dx\right\} \right|\\
= & \frac{1}{L}\bigg|\Re\bigg\{\sum_{j=0}^{J}i^{j+1}\frac{(2L)^{j+1}}{(k\pi)^{j+1}}\left(f^{(j)}(-L)-(-1)^{k}f^{(j)}(L)\right)\\
 & +e^{i\frac{k\pi}{2}}i^{J+1}\frac{(2L)^{J+1}}{(k\pi)^{J+1}}\int_{-L}^{L}f^{(J+1)}(x)e^{i\frac{k\pi}{2L}x}dx\bigg\}\bigg|\\
\leq & \sum_{j=1}^{J}\frac{2^{j+1}}{\pi^{j+1}}\frac{L^{j}}{k^{j+1}}\left(|f^{(j)}(-L)|+|f^{(j)}(L)|\right)+\frac{2^{J+2}H_{J+1}}{\pi^{J+1}}\frac{L^{J+1}}{k^{J+1}}.
\end{align*}
Observe:
\begin{equation}
\left\Vert f_{L}-\sum_{k=0}^{N}{}^{\prime}a_{k}e_{k}\right\Vert _{2}=\sqrt{\sum_{k=N+1}^{\infty}|a_{k}|^{2}}\leq\sum_{k=N+1}^{\infty}|a_{k}|.\label{eq:||f-ae||}
\end{equation}
By the integral test for convergence
\begin{equation}
\sum_{k=N+1}^{\infty}\frac{1}{k^{j+1}}\leq\int_{N}^{\infty}x^{-j-1}dx=\frac{1}{j}N^{-j},\quad j\geq1,\label{eq:sum1/k^j+1}
\end{equation}
which implies Eq. (\ref{eq:trun_error}) for $J\geq1$. If $J=0$,
apply the first Equality from (\ref{eq:||f-ae||}) and the Inequality
(\ref{eq:sum1/k^j+1}). 
\end{proof}
Given $L>0$, we need an estimate for $H_{J+1}$ to find an upper
bound for the series truncation error by Inequality (\ref{eq:trun_error}).
$L$ can be found by applying Markov's inequality, see \cite{junike2022precise}
or Theorem \ref{thm:find_N_A_B} below. Next, we provide ideas and
examples for estimating $H_{J+1}$. If $f\in C_{b}^{J+1}(\mathbb{R})$
is a density with characteristic function $\varphi$, then it holds
that%
\begin{comment}
\[
f^{(j)}(x)=\frac{1}{2\pi}\int_{\mathbb{R}}(-iu)^{j}e^{-iux}\varphi(u)du,\quad j=0,1,...,J+1,\quad x\in\mathbb{R}.
\]
Hence,
\end{comment}
\begin{equation}
H_{j}:=\sup_{x\in\mathbb{R}}|f^{(j)}(x)|\leq\frac{1}{2\pi}\int_{\mathbb{R}}|u|^{j}|\varphi(u)|du,\quad j=0,1,...,J+1.\label{eq:H_j}
\end{equation}
The Inequality (\ref{eq:H_j}) provides explicit expressions for the
term $H_{j}$, $j=0,..,J+1$ for several models as the next examples
show. The right-hand-side of Inequality (\ref{eq:H_j}) can also be
solved numerically, this is done in Section \ref{subsec:BS-model}.
\begin{example}
\label{exa:stable}The density $f_{\text{Stable}}\in C_{b}^{\infty}(\mathbb{R})$
of the family of stable distributions with stability parameter $\alpha\in(0,2]$,
skewness $\beta\in[-1,1]$, scale $c>0$ and location $\theta\in\mathbb{R}$
has characteristic function 
\begin{align*}
u\mapsto & \exp\left(iu\theta-|uc|{}^{\alpha}(1-i\beta\text{sgn}(u)\Phi_{\alpha}(u)\right),\\
 & \Phi_{\alpha}(u)=\begin{cases}
\tan\frac{\pi\alpha}{2} & ,\alpha\neq1\\
-\frac{2}{\pi}\log(|u|) & ,\alpha=1.
\end{cases}
\end{align*}
It follows by Inequality (\ref{eq:H_j}) that
\begin{align}
\sup_{x\in\mathbb{R}}|f_{\text{Stable}}^{(j)}(x)| & \leq\frac{1}{\pi\alpha c^{j+1}}\int_{0}^{\infty}t^{\frac{j+1}{\alpha}-1}e^{-t}dt\nonumber \\
 & \leq\frac{\Gamma\left(\frac{j+1}{\alpha}\right)}{\pi\alpha c^{j+1}},\quad j=0,1,2,...\label{eq:stable_bound}
\end{align}
\end{example}

\begin{example}
\label{exa:Gauss}In the BS model with volatility $\sigma>0$, the
centralized log-returns at time $T>0$ have Gaussian density $f_{\text{BS}}$
with mean zero and variance $\sigma^{2}T$. Since the normal distribution
is a member of the stable distributions, we obtain with the help of
Equation (\ref{eq:stable_bound}) that
\begin{align*}
\sup_{x\in\mathbb{R}}|f_{\text{BS}}^{(j)}(x)| & \leq\begin{cases}
j!\left(\sigma^{j+1}T^{\frac{j+1}{2}}\sqrt{2\pi}2^{\frac{j}{2}}\left(\frac{j}{2}\right)!\right)^{-1} & ,j=0,2,4,6...\\
2^{\frac{j-1}{2}}\left(\frac{j-1}{2}\right)!\left(\sigma^{j+1}T^{\frac{j+1}{2}}\pi\right)^{-1} & ,j=1,3,5,...
\end{cases}
\end{align*}
\end{example}

\begin{example}
\label{exa:FMLS}In the FMLS model with parameters $\alpha\in(1,2)$
and $\sigma>0$, the centralized log-returns at time $T>0$ are stably
distributed with stability parameter $\alpha$, skewness $\beta=-1$,
scale $c=\sigma T^{\frac{1}{\alpha}}$, and location $\theta=0$,
see \cite{carr2002fine}. An upper bound for the density $f_{\text{FMLS}}$
of the log-returns and its derivatives can be obtained directly from
Inequality (\ref{eq:stable_bound}).
\end{example}

\begin{example}
\label{exa:NIG}In the symmetric NIG model with parameters $\alpha>0$,
$\beta=0$ and $\delta>0$, the centralized log-returns at time $T>0$
have density $f_{\text{NIG}}\in C_{b}^{\infty}(\mathbb{R})$, whose
characteristic function is given by
\[
u\mapsto\exp\left(-\delta T\sqrt{\alpha^{2}+u^{2}}+\delta T\alpha\right),\quad u\in\mathbb{R},\quad\alpha>0,\quad\delta>0,
\]
see \cite{barndorff1997normal} and \citet[Sec. 5.3.8]{schoutens2003levy}.
We obtain by Equation (\ref{eq:H_j}) and using $\alpha^{2}+u^{2}\geq u^{2}$
that
\begin{align*}
\sup_{x\in\mathbb{R}}|f_{\text{NIG}}^{(j)}(x)| & \leq\frac{e^{T\delta\alpha}j!}{\pi(T\delta)^{j+1}},\quad j=0,1,2,...
\end{align*}
\end{example}

In Theorem \ref{thm:find_N_A_B} we provide explicit formulas for
$N$ and $L$ when $f$ satisfies Assumption A, to ensure that the
COS method approximates the true price within a predefined error tolerance
$\varepsilon>0$. Theorem \ref{thm:find_N_A_B} extends \citet[Cor. 9]{junike2022precise}.
\begin{thm}
\label{thm:find_N_A_B}($M$, $L$ and $N$ for densities with semi-heavy
tails). Let $v:\mathbb{R}\to\mathbb{R}$ be bounded, with $|v(x)|\le K$
for all $x\in\mathbb{R}$ and some $K>0$. Let $\varepsilon>0$ be
small enough. Suppose $J\in\mathbb{N}_{0}$ and $f$ satisfies Assumption
A and is a density. For some even $n\in\mathbb{N}$ let
\begin{equation}
L=M=\sqrt[n]{\frac{2K\mu_{n}}{\varepsilon}},\label{eq:M}
\end{equation}
where $\mu_{n}$ is the $n^{th}-$moment of $f$, i.e.
\begin{equation}
\mu_{n}=\frac{1}{i^{n}}\left.\frac{\partial^{n}}{\partial u^{n}}\varphi(u)\right|_{u=0}.\label{eq:nth momen}
\end{equation}
Let $\xi=\sqrt{2M}K$. If $J\geq1$ let $j\in\{1,...,J\}$ and
\begin{align}
N & \geq\frac{4L}{\pi}\lor\left(\frac{2^{j+3}H_{j+1}L^{j+1}}{j\pi^{j+1}}\frac{6\xi}{\varepsilon}\right)^{\frac{1}{j}}.\label{eq:N_J>0}
\end{align}
If $J=0$ let
\begin{equation}
N\geq\left(\frac{4H_{1}L}{\pi}\frac{6\xi}{\varepsilon}\right)^{2}.\label{eq:N_j=00003D0}
\end{equation}
In both cases it holds that
\begin{equation}
\left|\int_{\mathbb{R}}v(x)f(x)dx-\sum_{k=0}^{N}{}^{\prime}c_{k}v_{k}\right|\leq\varepsilon.\label{eq:vf-sum ck vk}
\end{equation}
\end{thm}

\begin{proof}
The $n^{th}-$moment of $f$ can be obtained from the $n^{th}$ derivative
of the characteristic function of $f$ by Equation (\ref{eq:nth momen}).
It holds by Markov's inequality and the definition of $M$ that
\begin{equation}
\int_{\mathbb{R}\setminus[-M,M]}\big|v(x)f(x)\big|dx\leq K\int_{\mathbb{R}\setminus[-M,M]}f(x)dx\leq K\frac{\mu_{n}}{M^{n}}\leq\frac{\varepsilon}{2}.\label{eq:Markov_semi}
\end{equation}
For $\varepsilon$ small enough, $M$ is large enough so that Assumption
A holds, i.e. $L_{0}\leq M\leq L$. Further,
\begin{align}
\left\Vert f-f_{L}\right\Vert _{2} & \leq\sqrt{2C_{1}^{2}\int_{L}^{\infty}e^{-2C_{2}x}dx}\nonumber \\
 & =\frac{C_{1}}{\sqrt{C_{2}}}e^{-C_{2}L}\label{eq:A1_semi}\\
 & \leq\frac{\varepsilon}{6\xi},\nonumber 
\end{align}
the last inequality holds true if
\begin{equation}
L\geq-\frac{1}{C_{2}}\log\left(\frac{\sqrt{C_{2}}}{C_{1}}\frac{\varepsilon}{6\xi}\right).\label{eq:L1_semi}
\end{equation}
Proposition 2 in \cite{junike2022precise} shows that
\[
B(L)\leq\frac{2}{3}\frac{\pi^{2}}{L^{2}}\int_{\mathbb{R}\setminus[-L,L]}|xf(x)|^{2}dx.
\]
We then have
\begin{align}
\sqrt{B(L)}\leq & \sqrt{\frac{4}{3}\frac{\pi^{2}C_{1}^{2}}{L^{2}}\int_{L}^{\infty}x^{2}e^{-2C_{2}x}dx}\nonumber \\
= & \frac{2\pi C_{1}}{\sqrt{6C_{2}}}e^{-C_{2}L}\sqrt{1+\frac{1}{LC_{2}}+\frac{1}{2L^{2}C_{2}^{2}}}\label{eq:B(L)_semi}\\
\leq & \frac{2\pi C_{1}}{\sqrt{6C_{2}}}\sqrt{1+\frac{1}{MC_{2}}+\frac{1}{2M^{2}C_{2}^{2}}}e^{-C_{2}L}\nonumber \\
\leq & \frac{\varepsilon}{6\xi},\nonumber 
\end{align}
the last inequality holds true if 
\begin{equation}
L\geq-\frac{1}{C_{2}}\log\left(\left(\frac{2\pi C_{1}}{\sqrt{6C_{2}}}\sqrt{1+\frac{1}{MC_{2}}+\frac{1}{2M^{2}C_{2}^{2}}}\right)^{-1}\frac{\varepsilon}{6\xi}\right).\label{eq:L_B_semi}
\end{equation}
Assume $J\geq1$. By Equation (\ref{eq:N_J>0}) we have $\frac{\pi}{4}\geq\frac{L}{N}$
and it follows that
\begin{align*}
 & \sum_{j=1}^{J}\frac{2^{j+1}}{j\pi^{j+1}}\frac{L^{j}}{N^{j}}\left(|f^{(j)}(-L)|+|f^{(j)}(L)|\right)\\
\leq & \frac{8}{\pi^{2}}C_{1}e^{-C_{2}L}\frac{L}{N}\sum_{k=0}^{\infty}\left(\frac{2L}{\pi N}\right)^{k}\\
\leq & \frac{8}{\pi^{2}}C_{1}e^{-C_{2}L}\frac{\pi}{4}\frac{1}{1-\frac{2L}{\pi N}}\\
\leq & \frac{4C_{1}}{\pi}e^{-C_{2}L}\leq\frac{\varepsilon}{12\xi},
\end{align*}
the last inequality holds true if
\begin{equation}
L\geq-\frac{1}{C_{2}}\log\left(\frac{\pi}{4C_{1}}\frac{\varepsilon}{12\xi}\right).\label{eq:L_N_semi}
\end{equation}
By Equation (\ref{eq:M}), $L$ is of order $\varepsilon^{-\frac{1}{n}}$$.$
Hence, for $\varepsilon$ small enough, Inequalities (\ref{eq:L1_semi}),
(\ref{eq:L_B_semi}) and (\ref{eq:L_N_semi}) are indeed satisfied
because the right-hand-sides of those Inequalities are of order $\log(\varepsilon)$.
By the definition of $N$ in Equation (\ref{eq:N_J>0}), we also have
\[
\frac{2^{j+2}H_{j+1}}{j\pi^{j+1}}\frac{L^{j+1}}{N^{j}}\leq\frac{\varepsilon}{12\xi}.
\]
By Lemma \ref{lem:A2} it follows that that
\begin{equation}
\left\Vert f_{L}-\sum_{k=0}^{N}{}^{\prime}a_{k}e_{k}\right\Vert _{2}\leq\frac{\varepsilon}{6\xi}.\label{eq:<lesp/6xi}
\end{equation}
As $B(L)\to0$, $L\to\infty$, $f$ is COS-admissible. Apply Lemma
\ref{lem:cor8} arrive at Equation (\ref{eq:vf-sum ck vk}). Now assume
$J=0$. By the definition of $N$ in Equation (\ref{eq:N_j=00003D0}),
Lemma \ref{lem:A2} implies again Inequality (\ref{eq:<lesp/6xi}).
Apply as before Lemma \ref{lem:cor8} to conclude.
\end{proof}
\begin{rem}
\label{rem:Theorem_A}If $v$ is a European put option, $K$ can be
set to the strike of the option. $\varepsilon$ denotes some error
tolerance. Numerical experiments in \cite{junike2022precise} suggest
to choose $n\in\{4,6,8\}$ for $\mu_{n}$. According to Theorem \ref{thm:find_N_A_B},
any $j\in\{1,...,J\}$ is allowed to define $N$ by Equation (\ref{eq:N_J>0}).
In the applications, one could minimize $N$ over all admissible $j$.
But this could be time-consuming and in Sections (\ref{subsec:BS-model})
and (\ref{subsec:FMLS-model}) we set $j$ to a fixed value. The bounds
$H_{j}$ are explicitly known for some models, see Examples \ref{exa:NIG},
\ref{exa:Gauss} and \ref{exa:FMLS} and can also be obtained numerically,
see Section \ref{subsec:BS-model}. Section \ref{sec:Numerical-experiments}
contain examples indicating that the bound in Equation (\ref{eq:N_J>0})
is often sharp and very useful in applications.
\end{rem}

To extend Theorem \ref{thm:find_N_A_B} to the case that $f$ satisfies
Assumption B, i.e. $f$ has heavy tails, we need a bound for the term
$B(L)$, see Equation (\ref{eq:B(L)}). Proposition 2 in \cite{junike2022precise}
provides a bound for $B(L)$, but we cannot apply it to all densities
of the stable distributions because the assumptions in that Proposition
are not satisfied for all stability parameters $\alpha\in(0,2]$ of
the stable law. Therefore, we need the following lemma:%
\begin{comment}
The bound by the lemma is also sharper than the bound in Prop 2:

while(T)\{

mat=rexp(1)

alpha=runif(1,1,2)

sigma=rexp(1)

eps=10\textasciicircum -4

K=runif(1,50,150)

C3=alpha{*}(1-alpha)/(gamma(2-alpha){*}cos(pi{*}alpha/2)){*}sigma\textasciicircum alpha{*}mat

tmp0=(4{*}C3{*}K/(eps{*}alpha))\textasciicircum (1/alpha)

myxi=sqrt(2{*}tmp0){*}K

tmp1=(sqrt(2){*}6{*}C3{*}myxi/(sqrt(1+2{*}alpha){*}eps))\textasciicircum (2/(1+2{*}alpha))

tmp2=(12{*}C3{*}sqrt(1/alpha\textasciicircum 2+2/3){*}myxi/eps)\textasciicircum (2/(1+2{*}alpha))

tmp3=(2{*}pi{*}C3/(sqrt(3{*}sqrt(2{*}alpha-1))){*}6{*}myxi/eps)\textasciicircum (2/(1+2{*}alpha))

round(c(tmp0,tmp1,tmp2,tmp3),0)

if(tmp2>tmp3)

break

\}
\end{comment}

\begin{lem}
\label{lem:COS}Let $f\in C_{b}^{1}(\mathbb{R})$ be an unimodal and
integrable such that $f$ is square-integrable and 
\[
xf^{2}(x)\to0,\quad x\to\pm\infty.
\]
If the mode of $f$ is within $[-L,L]$ then 
\[
B(L)\leq\frac{1}{L}\left(\int_{\mathbb{R}\setminus[-L,L]}f(x)dx\right)^{2}+\frac{8}{3}L\left(f^{2}(L)\lor f^{2}(-L)\right).
\]
\end{lem}

\begin{proof}
As $f$ is unimodal and the mode is in $[-L,L]$, it follows that
\[
f^{\prime}(x)\geq0,\quad x\leq-L\quad\text{and}\quad f^{\prime}(x)\leq0,\quad x\geq L.
\]
It holds $f(x)\to0$, $x\to\pm\infty$ and

\[
\int_{L}^{\infty}\left|f^{\prime}(x)\right|dx=-\int_{L}^{\infty}f^{\prime}(x)dx=f(L).
\]
Note that for all $k\in\mathbb{N}$, 
\begin{align*}
\int_{L}^{\infty}f(x)\cos\left(k\pi\frac{x+L}{2L}\right)dx= & \underbrace{\left[f(x)\sin\left(k\pi\frac{x+L}{2L}\right)\frac{2L}{k\pi}\right]_{L}^{\infty}}_{=0}\\
 & -\frac{2L}{k\pi}\int_{L}^{\infty}f^{\prime}(x)\sin\left(k\pi\frac{x+L}{2L}\right)dx,
\end{align*}
implying 
\begin{align*}
\frac{1}{L}\left|\int_{L}^{\infty}f(x)\cos\left(k\pi\frac{x+L}{2L}\right)dx\right|^{2}= & \frac{4}{\pi^{2}k^{2}}L\left|\int_{L}^{\infty}f^{\prime}(x)\sin\left(k\pi\frac{x+L}{2L}\right)dx\right|^{2}\\
\leq & \frac{4}{\pi^{2}k^{2}}Lf^{2}(L).
\end{align*}
Similarly, 
\[
\frac{1}{L}\left|\int_{-\infty}^{-L}f(x)\cos\left(k\pi\frac{x+L}{2L}\right)dx\right|^{2}\leq\frac{4}{\pi^{2}k^{2}}Lf^{2}(-L).
\]
Using 
\[
\sum_{k=1}^{\infty}\frac{1}{k^{2}}=\frac{\pi^{2}}{6}\quad\text{and}\quad|a+b|^{2}\leq4(a^{2}\lor b^{2}),
\]
we arrive at 
\begin{align*}
\sum_{k=0}^{\infty} & \frac{1}{L}\left|\int_{\mathbb{R}\setminus[-L,L]}f(x)\cos\left(k\pi\frac{x+L}{2L}\right)dx\right|^{2}\\
 & \leq\frac{1}{L}\left|\int_{\mathbb{R}\setminus[-L,L]}f(x)dx\right|^{2}+4\left(\frac{4\pi^{2}}{6\pi^{2}}Lf^{2}(L)\lor\frac{4\pi^{2}}{6\pi^{2}}Lf^{2}(-L)\right)\\
 & =\frac{1}{L}\left|\int_{\mathbb{R}\setminus[-L,L]}f(x)dx\right|^{2}+\frac{8}{3}L\left(f^{2}(L)\lor f^{2}(-L)\right).
\end{align*}
\end{proof}
\begin{example}
\label{exa:f B uni}If $f\in C_{b}^{1}(\mathbb{R})$ satisfies Assumption
B and is unimodal it also satisfies the assumption of Lemma \ref{lem:COS}.
To see this, note that $f$ is bounded and therefore quadratically
integrable. Further,
\[
|xf^{2}(x)|\leq C_{3}^{2}|x|^{-1-2\alpha}\to0,\quad x\to\pm\infty.
\]
\end{example}

In Theorem \ref{thm:find_N_C} we provide explicit formulas for $M$,
$N$ and $L$ if $f$ satisfies Assumption B and is unimodal, to ensure
that the COS method approximates the true price within a predefined
error tolerance $\varepsilon>0$. In particular, the density of the
stable law is unimodal, see \cite{yamazato1978unimodality}. 
\begin{thm}
\label{thm:find_N_C}($M$, $L$ and $N$ for densities with heavy
tails). Let $v:\mathbb{R}\to\mathbb{R}$ be bounded, with $|v(x)|\le K$
for all $x\in\mathbb{R}$ and some $K>0$. Let $\varepsilon>0$ be
small enough. Suppose $J\in\mathbb{N}$ and $f$ satisfies Assumption
B and is unimodal. Let
\begin{align}
M & =\left(\frac{4C_{3}K}{\varepsilon\alpha}\right)^{\frac{1}{\alpha}},\label{eq:M_stable}
\end{align}
$\xi:=\sqrt{2M}K$ and
\begin{equation}
L=M\lor\left(12C_{3}\sqrt{\frac{1}{\alpha^{2}}+\frac{2}{3}}\frac{\xi}{\varepsilon}\right)^{\frac{2}{1+2\alpha}}.\label{eq:L_stable}
\end{equation}
\begin{comment}
L=(4{*}C3{*}K/(eps{*}alpha))\textasciicircum (1/alpha)

xi=sqrt(2{*}L){*}K

tmp1=(sqrt(2){*}6{*}C3{*}xi/(sqrt(1+2{*}alpha){*}eps))\textasciicircum (2/(1+2{*}alpha))

tmp2=(12{*}C3{*}sqrt(1/alpha\textasciicircum 2{*}2/3){*}xi/eps)\textasciicircum (2/(1+2{*}alpha))
\end{comment}
Let $j\in\{1,...,J\}$ and
\begin{align}
N\geq\frac{4L}{\pi}\lor\left(\frac{2^{j+3}H_{j+1}L^{j+1}}{j\pi^{j+1}\theta}\frac{6\xi}{\varepsilon}\right)^{\frac{1}{j}}.\label{eq:N_stable}
\end{align}
Then
\begin{equation}
\left|\int_{\mathbb{R}}v(x)f(x)dx-\sum_{k=0}^{N}{}^{\prime}c_{k}v_{k}\right|\leq\varepsilon.\label{eq:vf-sum ck vk-1}
\end{equation}
\end{thm}

\begin{proof}
$M$ is of order $\varepsilon^{-\frac{1}{\alpha}}$. For $\varepsilon$
small enough, $M$ is large enough so that Assumption B holds, i.e.
$L_{0}\leq M\leq L$. The inequality 
\[
\int_{\mathbb{R}\setminus[-M,M]}\big|v(x)f(x)\big|dx\leq K\int_{\mathbb{R}\setminus[-M,M]}f(x)dx\leq\frac{2KC_{3}}{\alpha}M^{-\alpha}\leq\frac{\varepsilon}{2}
\]
is satisfied by the definition of $M$. \textcolor{gray}{{} }A little
calculation shows
\[
L\geq\left(\frac{\sqrt{2}6C_{3}\xi}{\sqrt{1+2\alpha}\varepsilon}\right)^{\frac{2}{1+2\alpha}},
\]
which implies
\begin{align*}
\big\Vert f-f_{L}\big\Vert_{2} & \leq\sqrt{2\int_{L}^{\infty}C_{3}^{2}x^{-2-2\alpha}dx}\\
 & =\frac{\sqrt{2}C_{3}}{\sqrt{1+2\alpha}}L^{-\frac{1+2\alpha}{2}}\\
 & \leq\frac{\varepsilon}{6\xi}.
\end{align*}
The function $f$ satisfies the condition of Lemma \ref{lem:COS}
by Example \ref{exa:f B uni}. Using the bound for $B(L)$ from Lemma
\ref{lem:COS}, we obtain
\begin{align}
\sqrt{B(L)} & \leq\sqrt{\frac{1}{L}\left(2\int_{L}^{\infty}C_{3}x^{-1-\alpha}dx\right)^{2}+\frac{8}{3}LC_{3}^{2}L^{-2\alpha-2}}\nonumber \\
 & =\sqrt{\frac{4C_{3}^{2}}{\alpha^{2}}L^{-2\alpha-1}+\frac{8}{3}C_{3}^{2}L^{-2\alpha-1}}\nonumber \\
 & =2C_{3}\sqrt{\frac{1}{\alpha^{2}}+\frac{2}{3}}L^{-\frac{1+2\alpha}{2}}\label{eq:B(L)_stable}\\
 & \leq\frac{\varepsilon}{6\xi},\nonumber 
\end{align}
\begin{comment}
\#checked empirically

C3=rexp(1)

alpha=rexp(1)

L=rexp(1)

tmp=function(x)\{C3{*}x\textasciicircum (-1-alpha)\}

sqrt(1/L{*}(2{*}integrate(tmp,L,Inf)\$value)\textasciicircum 2+8/3{*}L{*}C3\textasciicircum 2{*}L\textasciicircum (-2{*}alpha-2))

2{*}C3{*}sqrt(1/(alpha\textasciicircum 2)+2/3){*}L\textasciicircum (-(1+2{*}alpha)/2)
\end{comment}
the last Inequality holds by the definition of $L$. As in the proof
of Theorem \ref{thm:find_N_A_B} one can show that by the definition
of $N$ 
\[
\left\Vert f_{L}-\sum_{k=0}^{N}{}^{\prime}a_{k}e_{k}\right\Vert _{2}\leq\frac{\varepsilon}{6\xi}.
\]
As $B(L)\to0$, $L\to\infty$, $f$ is COS-admissible. Apply Lemma
\ref{lem:cor8} to conclude.
\end{proof}
\begin{example}
\label{exa:C3}Recall that the log-returns of the FMLS model are stably
distributed. Let $F_{\text{Stable}}$ be the cumulative distribution
function for the stable density $f_{\text{Stable}}$ with stability
parameter $\alpha\in(0,2)$, skewness $\beta\in[-1,1]$, scale $c>0$
and location $\theta\in\mathbb{R}$. By \citet[Property 1.2.15]{samorodnitsky2017stable}
it holds that
\begin{align*}
\lim_{x\to\infty}x^{\alpha}(1-F_{\text{Stable}}(x)) & =C_{\alpha}\frac{1+\beta}{2}c^{\alpha},\\
\lim_{x\to\infty}x^{\alpha}(F_{\text{Stable}}(-x)) & =C_{\alpha}\frac{1-\beta}{2}c^{\alpha},
\end{align*}
where
\[
C_{\alpha}=\begin{cases}
\frac{1-\alpha}{\Gamma(2-\alpha)\cos\big(\frac{\pi\alpha}{2}\big)} & ,\alpha\neq1\\
\frac{2}{\pi} & ,\alpha=1.
\end{cases}
\]
For stable densities we therefore suggest to set $C_{3}$ in Equation
(\ref{eq:M}) at least as large as $\alpha C_{\alpha}\frac{1+|\beta|}{2}c^{\alpha}$
to obtain $L$. The number of terms $N$ can be found using Equation
(\ref{eq:N_stable}) and the bounds $H_{j}$ are explicitly given
in Example \ref{exa:stable}.
\end{example}


\section{\label{sec:Convergence-rate-of}Order of Convergence}

The main Theorem \ref{thm:asy} in this section describes the order
of convergence of the COS method if we allow $N\to\infty$ and choose
$M$ and $L$ depending on $N$. We describe only the asymptotic behavior
of the COS method and we assume $M=L$ in this section to keep the
notation simple. We establish a bound of the order of convergence
of the error of the COS method with parameters $L$ and $N$, i.e.,
\begin{equation}
\text{err}(L,N)=\left|\int_{\mathbb{R}}v(x)f(x)dx-\sum_{k=0}^{N}{}^{\prime}c_{k}v_{k}\right|.\label{eq:errCOS}
\end{equation}

We use big $O$ notation: for functions $g,h:\mathbb{N}\to\mathbb{R}$,
we write $h(N)=O(g(N))$ as $N\to\infty$, if the absolute value of
$h(x)$ is at most a positive constant multiple of $g(x)$ for all
sufficiently large values of $N$. %
\begin{comment}
Let $q>0$ and $(L(N))_{N\in\mathbb{N}}$ be a positive, non-decreasing
sequence. We say the COS method \emph{converges at least with order
of convergence $O(N^{-q})$ }if 
\[
\text{err}(L(N),N)\leq O(N^{-q}),\quad N\to\infty.
\]
For $q=1$ ($q=2$) we speak of a linear (quadratic) order of convergence.
The COS method is said to converge at least \emph{exponentially} if
the COS method converges at least with rate of convergence\emph{ $O(N^{-q})$
}for all $q>0$.
\end{comment}

\begin{thm}
\label{thm:asy}Let $v:\mathbb{R}\to\mathbb{R}$ be bounded, with
$|v(x)|\le K$ for all $x\in\mathbb{R}$ and some $K>0$. Assume $J\in\mathbb{N}$.
\\
(i) Let $f$ satisfy Assumption A. Let $\beta\in\left(0,\frac{2J}{2J+3}\right)$
and $\gamma>0$. If $L=\gamma N^{\beta}$ it holds that
\[
\text{err}(L(N),N)\leq O\left(N^{-J(1-\beta)+\frac{3}{2}\beta}\right),\quad\text{as }N\to\infty.
\]
(ii) Let $f$ be unimodal and satisfy Assumption B. Let $\beta\in\left(0,\frac{2J}{2J+3+2\alpha}\right)$
and $\gamma>0$. If $L=\gamma N^{\beta}$ it holds that
\[
\text{err}(L(N),N)\leq O\left(N^{-\alpha\beta}\right),\quad\text{as }N\to\infty.
\]
In both cases we have $\text{err}(L(N),N)\to0$, $N\to\infty.$%
\begin{comment}
\#checked numerically

alpha=runif(1,1,2)

beta=seq(0,1,length.out=100)

J=ceiling(rexp(1))

l1=-alpha{*}beta

l2=beta{*}(alpha+3/2)-1

l3=beta{*}(J+3/2)-J

plot(c(0,1),c(min(l1,l2,l3),max(l1,l2,l3)),type=\textquotedbl l\textquotedbl ,col=\textquotedbl white\textquotedbl )

lines(beta,l1,col=\textquotedbl black\textquotedbl )

lines(beta,l2,col=\textquotedbl red\textquotedbl )

lines(beta,l3,col=\textquotedbl green\textquotedbl )

lines(beta,pmax(l1,l2,l3),lty=2,lwd=3)

abline(v=2/(4{*}alpha+3),col=\textquotedbl grey\textquotedbl )

abline(h=-2{*}alpha/(4{*}alpha+3),col=\textquotedbl grey\textquotedbl )

f=function(alpha)\{-2{*}alpha/(4{*}alpha+3)\}

curve(f,1,2)
\end{comment}
\end{thm}

\begin{proof}
Let $v_{L}:=1_{[-L,L]}v$. As in the proof of Corollary 8 in \cite{junike2022precise},
one can show that
\begin{align}
\Big|\int_{\mathbb{R}}v(x)f(x)dx-\sideset{}{'}\sum_{k=0}^{N}c_{k}v_{k}\Big|\leq & A_{0}(L)+\|v_{L}\|_{2}(A_{1}(L)+A_{2}(L,N)+\sqrt{B(L)}),\label{eq:asy_sum}
\end{align}
where $B(L)$ as in Equation (\ref{eq:B(L)}) and
\begin{align*}
A_{0}(L)= & \int_{\mathbb{R}\setminus[-L,L]}\big|v(x)f(x)\big|dx\\
A_{1}(L)= & \left\Vert f-f_{L}\right\Vert _{2}\\
A_{2}(L,N)= & \big\Vert f_{L}-\sideset{}{'}\sum_{k=0}^{N}a_{k}e_{k}\big\Vert_{2}.
\end{align*}
We will state upper bounds for $A_{0}$, $A_{1}$ and $B$ depending
on the tail behaviour of $f$, i.e. for the different cases i) and
ii) in Theorem \ref{thm:asy}. An upper bound for $A_{2}$ can be
obtained from Lemma \ref{lem:A2}. Note that 
\[
\|v_{L}\|_{2}\leq\sqrt{2L}K=\sqrt{2\gamma}KN^{\frac{\beta}{2}}.
\]
We now proof (i). We have for $L$ large enough
\[
A_{0}(L)\leq2KC_{1}\int_{L}^{\infty}e^{-C_{2}x}dx=\frac{2KC_{1}}{C_{2}}e^{-C_{2}L}.
\]
Further, by Inequality (\ref{eq:A1_semi}), it holds that
\begin{align*}
A_{1}(L) & \leq\frac{C_{1}}{\sqrt{C_{2}}}e^{-C_{2}L}.
\end{align*}
Assuming $L\geq1$ and applying Inequality (\ref{eq:B(L)_semi}),
it follows that 
\begin{align*}
\sqrt{B(L)}\leq & \frac{2\pi C_{1}}{\sqrt{6C_{2}}}\sqrt{1+\frac{1}{C_{2}}+\frac{1}{2C_{2}^{2}}}e^{-C_{2}L}.
\end{align*}
\begin{comment}
\#checked numerically

C1=rexp(1)

C2=rexp(1)

L=rexp(1)

tmp=function(x)\{4/3{*}pi\textasciicircum 2{*}C1\textasciicircum 2/L\textasciicircum 2{*}x\textasciicircum 2{*}exp(-2{*}C2{*}x)\}

sqrt(integrate(tmp,L,Inf)\$value)

2{*}pi{*}C1/sqrt(6{*}C2){*}exp(-C2{*}L){*}sqrt(1+1/(L{*}C2)+1/(2{*}L\textasciicircum 2{*}C2\textasciicircum 2))
\end{comment}
Inequality (\ref{eq:trun_error}) implies 
\begin{align*}
A_{2}(L,N) & \leq\sum_{j=1}^{J}\frac{2^{j+1}}{j\pi^{j+1}}\frac{L^{j}}{N^{j}}\left(2C_{1}e^{-C_{2}L}\right)+\frac{2^{J+2}H_{J+1}}{J\pi^{J+1}}\frac{L^{J+1}}{N^{J}}\\
 & \leq e^{-C_{2}L}\sum_{j=1}^{J}\frac{2^{j+2}C_{1}\gamma^{j}}{j\pi^{j+1}}+\frac{2^{J+2}H_{J+1}}{J\pi^{J+1}}\frac{L^{J+1}}{N^{J}},
\end{align*}
where we used $\frac{L}{N}\leq\gamma$. 

Let $b_{1},...,b_{4}>0$ be suitable constants. By Inequality (\ref{eq:asy_sum}),
it follows for $N$ large enough
\begin{align}
\Big|\int_{\mathbb{R}}v(x)f(x)dx-\sideset{}{'}\sum_{k=0}^{N}c_{k}^{L}v_{k}^{M}\Big|\leq & b_{1}e^{-C_{2}\gamma N^{\beta}}+b_{2}N^{\frac{\beta}{2}}\big(b_{3}e^{-C_{2}\gamma N^{\beta}}+b_{4}N^{\beta(J+1)-J}\big)\nonumber \\
\leq & O\left(N^{-J(1-\beta)+\frac{3}{2}\beta}\right),\quad N\to\infty.\label{eq:asy_cos_semi}
\end{align}
$\beta<\frac{2J}{2J+3}$ implies $-J(1-\beta)+\frac{3}{2}\beta<0$
and the right-hand-side of (\ref{eq:asy_cos_semi}) converges to zero
for $N\to\infty$. 

We show (ii). It holds for $L$ large enough that
\begin{align*}
A_{0}(L) & \leq2KC_{3}\int_{L}^{\infty}x^{-1-\alpha}dx\leq\frac{2KC_{3}}{\alpha}L^{-\alpha},\\
A_{1}(L) & \leq\sqrt{2C_{3}^{2}\int_{L}^{\infty}x^{-2(1+\alpha)}dx}=\sqrt{\frac{2C_{3}^{2}}{1+2\alpha}}L^{-\frac{1}{2}-\alpha}
\end{align*}
\begin{comment}
\#checked numerically

C3=rexp(1)

alpha=rexp(1)

L=rexp(1)

tmp=function(x)\{2{*}C3\textasciicircum 2{*}x\textasciicircum (-2{*}(1+alpha))\}

sqrt(integrate(tmp,L,Inf)\$value)

sqrt(2{*}C3\textasciicircum 2/(1+2{*}alpha)){*}L\textasciicircum (-0.5-alpha)
\end{comment}
and using Inequality (\ref{eq:B(L)_stable})
\begin{align*}
\sqrt{B(L)} & \leq2C_{3}\sqrt{\frac{1}{\alpha^{2}}+\frac{2}{3}}L^{-\frac{1}{2}-\alpha}.
\end{align*}
Inequality (\ref{eq:trun_error}) implies 
\begin{align*}
A_{2}(L,N) & \leq\sum_{j=1}^{J}\frac{2^{j+2}C_{3}\gamma^{-1-\alpha}}{j\pi^{j+1}}N^{\beta(-1-\alpha)-j}+\frac{2^{J+2}H_{J+1}}{J\pi^{J+1}}\frac{L^{J+1}}{N^{J}}.
\end{align*}
Hence, by Inequality (\ref{eq:asy_sum}), it follows for $N$ large
enough and some some suitable constants $b_{1},...,b_{4}>0$ and $a_{1},...,a_{J}>0$
that
\begin{align*}
 & \Big|\int_{\mathbb{R}}v(x)f(x)dx-\sideset{}{'}\sum_{k=0}^{N}c_{k}v_{k}\Big|\\
 & \leq b_{1}N^{-\alpha\beta}+b_{2}N^{\frac{\beta}{2}}\bigg(b_{3}N^{-\beta(\alpha+\frac{1}{2})}+\sum_{j=1}^{J}a_{j}N^{\beta(-1-\alpha)-j}+b_{4}N^{\beta(J+1)-J}\bigg)\\
 & \leq b_{1}N^{-\alpha\beta}+b_{2}\bigg(b_{3}N^{-\beta\alpha}+\sum_{j=1}^{J}a_{j}N^{-\beta(\alpha+\frac{1}{2})-j}+b_{4}N^{\beta\left(J+\frac{3}{2}\right)-J}\bigg)\\
 & \leq O\left(N^{-\alpha\beta}\right),\quad N\to\infty.
\end{align*}
The last inequality can be seen as follows: as $0<\beta$, we have
\[
-\beta\alpha\geq-\beta\big(\alpha+\frac{1}{2}\big)-j,\quad j=1,...,J.
\]
Further, as $\beta\leq\frac{J}{J+\frac{3}{2}+\alpha}$, it follows
\[
-\alpha\beta\geq\beta(J+\frac{3}{2})-J.
\]
\end{proof}
\begin{rem}
The COS method converges exponentially, i.e. faster than $O(N^{-q})$
for any $q>0$, if $f$ is smooth and has semi-heavy tails. To see
this, let $0<\beta<1$ then 
\[
-J(1-\beta)+\frac{3}{2}\beta\to-\infty,\quad J\to\infty.
\]
\end{rem}

\begin{rem}
By Theorem \ref{thm:find_N_C}, the COS method converges at least
like $N^{-\alpha}$ if $f$ is smooth and has heavy tails with Pareto
index $\alpha>0$. Numerical experiments indicate that the COS method
does not converge faster than $O(N^{-\alpha})$ for the FMLS model,
see Section \ref{subsec:Convergence-Rate}, i.e. the bound in Theorem
\ref{thm:find_N_C}(ii) is sharp.
\end{rem}


\section{\label{sec:Numerical-experiments}Numerical experiments}

All numerical experiments are compared with the Carr-Madan formula,
see \cite{carr1999option}, which is applicable when the characteristic
function of the log-returns is given in closed-form and when $E[S_{T}^{1+\gamma}]$
is finite for some $\gamma>0$, called \emph{damping factor}. Unless
otherwise stated, we use the Carr-Madan formula with $N=2^{17}$ terms,
we set the damping factor equal to $\gamma=0.1$, and we use a Fourier
truncation range of $1200$ to compute the reference prices. We implemented
the Carr-Madan formula using Simson's rule without applying the fast
Fourier transform.

All numerical experiments are performed on a modern laptop (Intel
i7-10750H) using the software R and vectorized code without parallelization.

\subsection{\label{subsec:BS-model}BS model}

How sharp is the bound for $N$ in Theorem \ref{thm:find_N_A_B}?
For the BS model, we compute $L$ by Equation (\ref{eq:M}) and $N$
by Equation (\ref{eq:N_J>0}) and compare $N$ with $N_{\min}$, which
is the minimal number of terms such that the absolute difference of
the price of the COS method and the Black-Scholes price are less than
the error tolerance. Table \ref{tab:BS} shows that $N$ is only about
$40\%$ larger than $N_{\min}$. 

How can the number of terms $N$ be estimated if there are no closed-form
solutions available for the bounds of the derivatives of the density
of the log-returns? We suggest solving the right-hand-side of Inequality
(\ref{eq:H_j}) numerically to obtain $H_{j+1}$. Here, we use R's
\emph{integrate} function with default values. The CPU time of the
COS method and the numerical integration routine to obtain $H_{j+1}$
are of similar magnitude, see Table \ref{tab:BS}. 

The value for $N$ does not change when using numerical integration
to obtain $H_{j+1}$ compared to the closed-form solution for $H_{j+1}$
from Example \ref{exa:Gauss}. In this example, $j=40$ works well.
We also we use $j=40$ in Section \ref{subsec:FMLS-model}. 

\begin{table}[H]
\begin{centering}
\begin{tabular}{|>{\centering}p{4cm}|c|c|c|c|c|c|c|}
\hline 
$j$ & 10 & 20 & 30 & 40 & 50 & 60 & 70\tabularnewline
\hline 
$N$  & 897 & 271 & 200 & 179 & 172 & 170 & 171\tabularnewline
\hline 
CPU time COS method & 0.18 & 0.09 & 0.09 & 0.07 & 0.08 & 0.07 & 0.08\tabularnewline
\hline 
CPU time numeric integration for $H_{j+1}$ & 0.15 & 0.09 & 0.09 & 0.10 & 0.09 & 0.10 & 0.09\tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:BS}$L$ and $N$ in the BS model for a put option with
$T=1$, $\sigma=0.2$, $r=0$, $K=S_{0}=100$ and $\varepsilon=10^{-8}$
compared to the minimal number of terms $N_{\min}=120$ of the COS
method to stay below the error tolerance. We used $n=8$ moments to
obtain $L$. CPU time is measured in milliseconds. The COS method
with $N_{\min}=120$ takes about 0.068 milliseconds. }
\end{table}


\subsection{\label{subsec:VG-model}VG model}

Using the VG model as an example, this section shows that Theorem
\ref{thm:find_N_A_B} does not help in finding the number of terms
$N$ for the COS method if the density of the log-returns is not sufficiently
smooth. 

Let $f_{\text{VG}}$ denote the density of the log-returns in the
VG model at maturity $T>0$ with parameters $\sigma>0$, $\theta=0$
and $\nu>0$. If $T<\frac{\nu}{2}$, the density $f_{\text{VG}}$
is unbounded and Theorem \ref{thm:find_N_A_B} cannot be used to find
$N$. If $T\in\left(\nu,\frac{3\nu}{2}\right)$, the derivative of
$f_{\text{VG}}$ is continuous, but the second derivative of $f_{\text{VG}}$
is unbounded, see \citet[Thm. 4.1 and Thm. 6.1]{kuchler2008shapes}. 

We can apply Theorem \ref{thm:find_N_A_B} with $J=0$ if $T\in\left(\nu,\frac{3\nu}{2}\right)$
but the value for $N$ is somewhat useless from a practical point
of view as the following experiment shows: Consider a European call
option and the following parameters: 
\[
\varepsilon=0.01,\quad\sigma=0.1,\quad\nu=0.2,\quad T=0.25,\quad S_{0}=K=100,\quad r=0.
\]
By Equation (\ref{eq:M}), we set $L=0.91$ using $n=4$ moments.
By numerically optimizing the derivative of the density $f_{\text{VG}}$,
we obtain $H_{1}=218$ and Theorem \ref{thm:find_N_A_B} suggests
$N\approx8\cdot10^{12}$. 

We calulated a reference price $\pi_{CM}=1.809833$ using the Carr-Madan
formula. Using the COS method, already $N=50$ is sufficient to approximate
the reference price within the error tolerance. 

\subsection{\label{subsec:FMLS-model}FMLS model}

In this section, we consider the FMLS model with parameters $\alpha\in(1,2)$
and $\sigma>0$ at maturity $T>0$. Recall that the centralized log-returns
at time $T>0$ have heavy tails and are stably distributed with stability
parameter $\alpha$, skewness $\beta=-1$, scale $c=\sigma T^{\frac{1}{\alpha}}$
and location $\theta=0$. 

\cite{carr2003finite} calibrated the FMLS model to real market data
and estimated $\alpha=1.5597$ and $\sigma=0.1486$. We test the formulas
for $L$ and $N$ for the FMLS model with these parameters for a European
call option with the following parameters: 
\[
\varepsilon=10^{-2},\quad T=1,\quad S_{0}=K=100,\quad r=0.
\]
To apply the COS method we define $M$ and $L$ as in Equations (\ref{eq:M_stable})
and (\ref{eq:L_stable}). Motivated by Example \ref{exa:C3}, we suggest
to set the variable $C_{3}$ appearing in Equation (\ref{eq:M_stable})
to
\[
C_{3}:=\alpha\frac{1-\alpha}{\Gamma(2-\alpha)\cos\big(\frac{\pi\alpha}{2}\big)}\sigma^{\alpha}T.
\]
Figure \ref{fig:Density-of-FMLS} shows the density of the log-returns
in the FMLS model and asymptotic tail behavior, i.e. the function
$x\mapsto C_{3}|x|^{-1-\alpha}$. The left tail does indeed decay
like Pareto tails, the asymptotic tail behavior is very close to the
density. The right tail decays faster, it decays exponentially, see
\cite{carr2003finite}.

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.5]{FMLS_dens}
\par\end{centering}
\caption{\label{fig:Density-of-FMLS}Density of the log-returns in the FMLS
model and asymptotic tail behavior.}

\end{figure}

The reference price is 9.7433708 by the Carr-Madan formula and we
confirm the reference price by the COS method with $L=10^{5}$ and
$N=10^{7}$. Using the explicit formula for $H_{j+1}$ from Example
\ref{exa:FMLS} and Equation (\ref{eq:N_stable}) find $N=5451$,
where we set $j=40$. According to Theorem \ref{thm:find_N_C}, any
other choice for $j$ is possible but another value for $j$ does
not significantly improve $N$.

Applying Equations (\ref{eq:M_stable}) and (\ref{eq:L_stable}),
we get $M=69$ and $L=176$. With these parameters, the COS method
prices the call option within the error tolerance in about 1.5 milliseconds.
The minimal $N$ to stay below the error tolerance is $N_{\min}=1200$
and the CPU time using $N_{\min}$ is about 0.4 milliseconds. 

We also apply the Carr-Madan formula with the ``default parameters'',
see \cite{carr1999option}, which are also recommended by \citet[Sec. 3.1]{madan2016applied},
i.e. $4096$ terms, a damping factor equal to $1.5$ and a Fourier
truncation range of $1024$. With these default parameters, the Carr-Madan
formula prices the option within the error tolerance in about 1.1
milliseconds. 

The value for the CPU time is about three times higher when using
Theorem \ref{thm:find_N_C} to get $N$ compared to the optimized
value for $N$, which is acceptable from our point of view. The computational
time of the COS method using Theorem \ref{thm:find_N_C} and the Carr-Madan
formula with standard parameters are of similar magnitude. 

\subsection{\label{subsec:Convergence-Rate}Order of Convergence}

In this section, we empirically analyze the order of convergence of
the COS method for the BS model with parameter $\sigma>0$ and the
FMLS model with parameters $\alpha\in(1,2)$ and $\sigma>0$ and compare
the results with Theorem \ref{thm:asy}. We also consider the Cauchy
density.

In the BS model, the density of the log-returns is arbitrarily smooth
and the tails decay even faster than exponentially. In Figure \ref{fig:Convergence-rate-BS}
we analyze how the error of the COS method behaves in the BS model
for large $N$ and different choices of $L$. 

In particular, we see that the COS method seems to converge exponentially
at the beginning for moderate $N$ if we choose $L$ constant, i.e.
independent of $N$. But for constant $L$, e.g. $L=4\sigma$ or $L=6\sigma$,
the COS method does not converge for $N\to\infty$ but the error remains
constant for a certain level of $N$. This can be explained by Inequality
(\ref{eq:error_bound}). While the second term on the right-hand-side
of Inequality (\ref{eq:error_bound}) converges to zero for $N\to\infty$
and $L$ fixed, the first and third terms on the right-hand-side of
Inequality (\ref{eq:error_bound}) do not improve as $N$ is increased
but $L$ is kept constant.

For large $L$, such as $L=20\sigma$, this effect disappears somewhat
because the tails of the Gaussian distribution decay so rapidly that,
up to fixed-precision arithmetic\footnote{The software package R operates with a precision of 53 bits conforming
to the IEC 60559 standard, see R Core Team (2021). R: A language and
environment for statistical computing. R Foundation for Statistical
Computing, Vienna, Austria. URL https://www.R-project.org/.}, the Gaussian density can be thought of as a density with finite
support. Using arbitrary-precision arithmetic instead should show
that even for $L=20\sigma$, the error of the COS method does not
converge to zero for $N\to\infty$. 

If we choose $L=L(N)=\sigma\sqrt{N}$, Theorem \ref{thm:asy}(i) indicates
that the error of the COS method converges exponentially to zero.
This is confirmed empirically in Figure \ref{fig:Convergence-rate-BS}.
Other choices for $L$ also work well, e.g. $L=\frac{\sigma}{5}N$. 

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.4]{BS_convergence_rate}
\par\end{centering}
\caption{\label{fig:Convergence-rate-BS}Order of Convergence of the COS method
for a call option in the BS model with $\sigma=0.2$, $T=1$, $K=S_{0}=100$,
$r=0$ and different choices for the truncation range $[-L,L]$.}
\end{figure}

We test Theorem \ref{thm:asy}(ii) for the density of the Cauchy distribution
and the density of the log-returns in the FMLS model. Both densities
belong to the family of stable densities and have heavy tails. In
the case of the Cauchy density, we set
\[
f_{\text{Cauchy}}(x)=\frac{1}{\pi(1+x^{2})}\quad\text{and}\quad v(x)=1_{(-\infty,1.23]}(x),\quad x\in\mathbb{R}.
\]
The integral $\int_{\mathbb{R}}f_{\text{Cauchy}}(x)v(x)dx$ is equal
to the value of the cumulative distribution function of $f_{\text{Cauchy}}$
at $1.23$ and is given in closed-form. The Pareto index of $f_{\text{Cauchy}}$
is $\alpha=1$.

For the FMLS model we use the parameters $\alpha=1.5597$ and $\sigma=0.1486$,
these values are taken from \cite{carr2003finite}, who calibrated
the FMLS model to real market data. We then compute the price of a
European call option with maturity $T=1$, $S_{0}=K=100$ and $r=0$
using the Carr-Madan formula.

For the Cauchy and the FMLS models, we compute $L_{\text{optimal}}$
for a fixed $N\in\mathbb{N}$ minimizing $\text{err}(L,N)$, i.e.
for each $N$ we choose the truncation range such that the error of
the COS method is minimal, compare with Equation (\ref{eq:errCOS}).
We then compare the empirical order of convergence of $\text{err}(L_{\text{optimal}}(N),N)$
with the theoretical bound $O(N^{-\alpha})$ from Theorem \ref{thm:asy}(ii).
In particular, for each $N\in\{2^{i},\,i=4,5,...,20\}$ we define
\[
L_{\text{optimal}}(N):=\text{argmin}_{L\in\mathbb{L}}\text{err}(L,N),
\]
where 
\[
\mathbb{L}=\{\exp(0.07i),\quad i=0,1,...,200\},
\]
is a sufficiently fine grid of the interval $[1,10^{6}]$. Figure
\ref{fig:L_optimal} shows $L_{\text{optimal}}$ over $N$ for the
Cauchy and FMLS model. We see that the relationship between $\log(N)$
and $\log(L_{\text{optimal}})$ is approximately linear with slope
$0.95$ for the Cauchy model and slope $0.86$ for the FMLS model. 

In Figures \ref{fig:Convergence-rate-cauchy} and \ref{fig:Convergence-rate-FMLS}
we compute the order of convergence of the COS method for different
strategies to define $L$. If $L$ is constant, the COS method does
not converge at all. 

For the Cauchy model, the order of convergence can be estimated from
Figure \ref{fig:Convergence-rate-cauchy} to be $O(N^{-0.92})$, if
we choose $L=\frac{1}{10}N$. The order of convergence using $L_{\text{optimal}}$
is of similar magnitude. This order of convergence is very close to
the theoretical bound of $O(N^{-1})$ predicted by Theorem \ref{thm:asy}(ii). 

For the FMLS model the empirical order of convergence is $O(N^{-1.57})$
if we choose $L=\frac{1}{100}N$, which is also very close to its
theoretical bound of $O(N^{-1.5597})$ and does not differ much if
we use $L_{\text{optimal}}$ instead. 

In particular the numerical experiments indicate that the order of
convergence is not exponential for heavy tail models even though the
corresponding densities are arbitrarily smooth. 

In Figure \ref{fig:Convergence-rate-FMLS} we also plot the empirical
order of convergence of the Carr-Madan formula for the FMLS model
with damping factor of $0.1$ and a Fourier truncation range of $1200$.
The Figure indicates an exponential order of convergence for the Carr-Madan
formula.

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.4]{Optimal_L}
\par\end{centering}
\caption{\label{fig:L_optimal}$L_{\text{optimal}}$ for Cauchy and FMLS. The
horizontal lines corresponds to the grid $\mathbb{L}$ where we searched
for the optimal truncation range.}
\end{figure}

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.4]{Cauchy_convergence_rate}
\par\end{centering}
\caption{\label{fig:Convergence-rate-cauchy}Order of convergence of the COS
method for the Cauchy model with different choices for the truncation
range $[-L,L]$.}
\end{figure}

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.4]{FMLS_convergence_rate}
\par\end{centering}
\caption{\label{fig:Convergence-rate-FMLS}Order of convergence of the COS
method for a call option in the FMLS model with $\alpha=1.5597$,
$\sigma=0.1486$, $T=1$, $K=S_{0}=100$, $r=0$ and different choices
for the truncation range $[-L,L]$. The reference price is 9.743370825229...}
\end{figure}
 

\section{\label{sec:Conclusions}Conclusions}

In this research we analyzed the COS method, which is used for efficient
option pricing. The COS method requires two parameters: the truncation
range $[-L,L]$ to truncate the density of the log-returns and the
number of terms $N$ to approximate the truncated density by cosine
functions. We considered stock price models where the density of the
log-returns is smooth and has either semi-heavy tails, i.e. the tails
decay exponentially, or heavy tails, i.e. Pareto tails. 

In both cases, we found explicit and useful bounds for $L$ and $N$
and showed in numerical experiments the usefulness of these formulas
in applications. The densities of the log-returns are smooth for many
models in finance, such as the BS, NIG, Heston or FMLS models.

If the density is not differentiable, neither Theorem \ref{thm:find_N_A_B}
nor \ref{thm:find_N_C} can be used to find a bound for $N$. If the
density is only differentiable a few times, which is the case for
the VG model for some parameters and short maturities, our bound for
$N$ is too large to be useful in most practical applications. A solution
might be to use the NIG model instead of the VG model. Both are flexible,
three-parameter Lévy models.

We further analyzed the order of convergence of the COS method and
observed both theoretically and empirically that the models enjoy
exponential convergence when the densities of the log-returns are
smooth and have semi-heavy tails. However, when the density of the
log-returns is smooth and has \emph{heavy} \emph{tails}, the order
of convergence of the COS method can be bounded by $O(N^{-\alpha})$,
where $\alpha>0$ is the Pareto tail index. This is the case, for
example, for the FMLS model where $\alpha\in(1,2)$. Numerical experiments
indicate that the bound $O(N^{-\alpha})$ is sharp.

\bibliographystyle{plainnat}
\bibliography{biblio}

\end{document}
