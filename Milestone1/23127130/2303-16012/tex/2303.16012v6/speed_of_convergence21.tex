%% LyX 2.3.6 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass{article}
\usepackage{lmodern}
\renewcommand{\sfdefault}{lmss}
\renewcommand{\ttdefault}{lmtt}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{xcolor}
\usepackage[american,english]{babel}
\usepackage{array}
\usepackage{verbatim}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 0},pdfborderstyle={},backref=false,colorlinks=false]
 {hyperref}
  \usepackage{breakurl}
 \hypersetup{
    breaklinks=true, 
    colorlinks=false,    
    pdfusetitle=true, 
}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}[section]
\theoremstyle{plain}
\newtheorem{lem}[thm]{\protect\lemmaname}
\theoremstyle{remark}
\newtheorem{rem}[thm]{\protect\remarkname}
\theoremstyle{definition}
\newtheorem{example}[thm]{\protect\examplename}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage[round]{natbib}
\numberwithin{equation}{section}
\newtheorem{assumption}{Assumption}
\renewcommand\theassumption{A\arabic{assumption}}

\makeatother

\addto\captionsamerican{\renewcommand{\examplename}{Example}}
\addto\captionsamerican{\renewcommand{\lemmaname}{Lemma}}
\addto\captionsamerican{\renewcommand{\remarkname}{Remark}}
\addto\captionsamerican{\renewcommand{\theoremname}{Theorem}}
\addto\captionsenglish{\renewcommand{\examplename}{Example}}
\addto\captionsenglish{\renewcommand{\lemmaname}{Lemma}}
\addto\captionsenglish{\renewcommand{\remarkname}{Remark}}
\addto\captionsenglish{\renewcommand{\theoremname}{Theorem}}
\providecommand{\examplename}{Example}
\providecommand{\lemmaname}{Lemma}
\providecommand{\remarkname}{Remark}
\providecommand{\theoremname}{Theorem}

\begin{document}
\title{How to handle the COS method for option pricing}
\author{Gero Junike\thanks{Carl von Ossietzky Universität, Institut für Mathematik, 26129 Oldenburg,
Germany, E-mail: gero.junike@uol.de}}
\maketitle
\begin{abstract}
The Fourier Cosine Expansion (COS) method is used to price European
options numerically in a very efficient way. To apply the COS method,
one has to specify two parameters: a truncation range for the density
of the log-returns and a number of terms $N$ to approximate the truncated
density by a cosine series. How to choose the truncation range is
already known. Here, we are able to find an explicit and useful bound
for $N$ as well for pricing and for the sensitivities, i.e., the
Greeks Delta and Gamma. We further show that the COS method has an
exponential order of convergence when the density is smooth and decays
exponentially. However, when the density is smooth and has heavy tails,
as in the Finite Moment Log Stable model, the COS method does not
have exponential order of convergence. Numerical experiments confirm
the theoretical results.
\end{abstract}
\begin{comment}
todo:
\begin{itemize}
\item Add Stefan Tappe comment.
\item How can Assumptions A and B be obtained from the Fourier transform
?
\end{itemize}
\end{comment}


\section{Introduction}

For model calibration, it is crucial to price European options quickly
because stock price models are typically calibrated to given prices
of liquid call and put options by minimizing the mean-square-error
between model prices and given market prices. During the optimization
routine, the model prices of call and put options need to be evaluated
often for different model parameters, see \cite{fang2009novel,junike2022precise}. 

To compute the price of a European option, one must solve an integral
involving the product of the density of the log-returns at maturity
and the payoff function. However, for many financial models, the density
$f$ of the log-returns is unknown. Fortunately, the characteristic
function of the log-returns is often given in closed form and can
be used to obtain the density. 

In their seminal paper, \cite{fang2009novel} proposed the COS method,
which is a very efficient way to approximate the density and to compute
option prices. The COS method requires two parameters: a truncation
range for the density of the log-returns and a number of terms $N$
to approximate the truncated density by a cosine series. While it
is known how to choose the truncation range, see \cite{junike2022precise},
the choice of $N$ is largely based on trial and error. 

The COS method has been extensively extended and applied, see \cite{fang2009pricing, fang2011fourier, grzelak2011heston,ruijter2012two,zhang2013efficient, leitao2018data, liu2019neural, liu2019pricing, oosterlee2019mathematical,bardgett2019inferring,junike2022precise}.
Other Fourier pricing techniques are discussed e.g. by \cite{carr1999option, lord2008fast, ortiz2013robust, ortiz2016highly}.

With respect to these papers we make the following three main contributions:
we develop an explicit, useful and rigorous bound for $N$; we analyze
the order of convergence of the COS method in detail; and we rigorously
analyze how the Greeks of an option can be approximated by the COS
method.

\cite{fang2009novel} propose to approximate the (unknown) density
in three steps: i) Truncate the density $f$, i.e., approximate $f$
by a function $f_{L}$ with finite support on some (sufficiently large)
interval $[-L,L]$. ii) Approximate $f_{L}$ by a Fourier cosine expansion
$\sum a_{k}e_{k}(x)$, where $a_{k}$ are Fourier coefficients of
$f_{L}$ and $e_{k}$ are cosine basis functions. iii) Approximate
$a_{k}$ by some coefficients $c_{k}$ which can be obtained directly
from the characteristic function of $f$. Thus, to apply the COS method,
two decisions must to be made: find a suitable truncation range $[-L,L]$
and identify the number $N$ of cosine functions.

\cite{junike2022precise} apply a simple triangle inequality  to bound
the error of the three approximations and obtain:
\begin{equation}
\bigg\| f-\sideset{}{'}\sum_{k=0}^{N}c_{k}e_{k}\bigg\|_{2}\leq\big\Vert f-f_{L}\big\Vert_{2}+\Big\Vert f_{L}-\sideset{}{'}\sum_{k=0}^{N}a_{k}e_{k}\Big\Vert_{2}+\Big\Vert\sideset{}{'}\sum_{k=0}^{\infty}(a_{k}-c_{k})e_{k}\Big\Vert_{2}.\label{eq:error_bound}
\end{equation}
The first, second and third terms at the right-hand side of Inequality
(\ref{eq:error_bound}) correspond to approximations due to i), ii)
and iii), respectively. 

\cite{junike2022precise} developed explicit expressions for bounds
for the first and third terms on the right-hand side of Inequality
(\ref{eq:error_bound}), which depend only on the choice of $L$,
not on the choice of $N$. When $f$ has semi-heavy tails, i.e., the
tails decay exponentially, \cite{junike2022precise} apply Markov's
inequality to obtain an explicit and useful expression for $L$. 

Recently, \cite{aimi2023fast} proposed some hints on how to choose
$N$. To the best of our knowledge, however, a rigorous bound on $N$
to ensure a certain precision of the COS method is not yet known.
On the other hand, it is well known that the series truncation error,
i.e., the second term on the right-hand side of Inequality (\ref{eq:error_bound}),
can be bounded using integration by parts, see \cite{boyd2001chebyshev}.
We use this idea in order to find an explicit and useful bound for
$N$, which involves the bound of the $j^{th}$-derivative of the
density $f$. 

For some models, such as the Black-Scholes model (see \cite{black1973pricing}),
the Normal Inverse Gaussian (NIG) model (see \cite{barndorff1997normal})
and the Finite Moment Log Stable (FMLS) model (see \cite{carr2003finite}),
we find sharp bounds for all derivatives of the density of $f$ in
closed-form. In general, these bounds can also be estimated numerically.
One contribution of this article is to obtain an explicit and useful
bound for $N$, which is provably large enough to ensure that the
COS method converges within a predefined error tolerance.%
\begin{comment}
For other models like the Heston model, see \cite{heston1993closed},
we propose to fit a flexible density like the NIG density to the moments
of the log-returns in the Heston model and then use the explicit bounds
from the NIG model to estimate the bounds of the derivative of the
density in the Heston model. This is numerically very efficient and
it works well as shown by extensive numerical experiments.
\end{comment}

\cite{fang2009novel} also analyzed the order of convergence of the
COS method, focusing on the second term on the right-hand side of
Inequality (\ref{eq:error_bound}). They concluded that with a properly
chosen truncation range, the overall error converges exponentially
for smooth density functions and compares favorably to the Carr-Madan
formula, see \cite{carr1999option}. 

Another contribution of this article is to also consider the errors
introduced by the truncation range, i.e., the errors due to i), ii)
and iii), and to establish upper bounds for the order of convergence
of the COS method. We confirm, both theoretically and empirically,
that the COS method indeed converges exponentially for smooth density
functions if, in addition, the tails of the density decay at least
exponentially. However, for fat-tailed and smooth densities, such
as the density of the log-returns in the FMLS model, the truncation
error due to i) and iii) becomes much more relevant compared to densities
with semi-heavy tails. We show theoretically that the COS method converges
at least as fast as $O(N^{-\alpha})$ for $N\to\infty$, where $\alpha>0$
is the Pareto tail index, e.g., for the FMLS model $\alpha\in(1,2)$.
Empirical experiments indicate that the COS method converges for such
densities as fast as $O(N^{-\alpha})$, i.e., the theoretical bound
is sharp and the COS method does not converge exponentially but the
order of convergence is $\alpha$.

\emph{Greeks}, also known as option \emph{sensitivities}, play an
important role in risk management. The Greek letters Delta or Gamma
respectively represent the first and second derivatives of the price
of the option with respect to the current price of the underlying
asset. There are ideas in the literature on how to approximate the
Delta and Gamma of the option using the COS method, see \citet[Rem. 3.2]{fang2009novel}
or \citet{leitao2018data}. However, to the best of our knowledge,
there is still no rigorous understanding of how to approximate the
Greeks using the COS method. Another contribution of this article
is thus to show the conditions under which Delta and Gamma can be
safely approximated by the COS method. 

This article is structured as follows: Section \ref{sec:Overview:-the-COS}
gives an overview of the technical details of the COS method. Section
\ref{sec:How-to-find} gives explicit formulas for the truncation
range $L$ and the number of terms $N$. Section \ref{sec:Convergence-rate-of}
analyzes the order of convergence of the COS method. In Sections \ref{sec:How-to-find}
and \ref{sec:Convergence-rate-of}, we distinguish between models
with semi-heavy tails and models with heavy tails. Section \ref{sec:Greeks-by-the}
discusses the numerical computation of the Greeks using the COS method.
Section \ref{sec:Numerical-experiments} contains numerical experiments
that confirm the theoretical results. Section \ref{sec:Conclusions}
concludes. 

\section{\label{sec:Overview:-the-COS}Overview: the COS method for option
pricing.}

We model the stock price over time by a stochastic process $(S_{t})_{t\geq0}$
on a filtered probability space. We assume that there is a bank account
paying continuous compound interest $r\in\mathbb{R}$. The market
is assumed to be arbitrage free, and we denote by $Q$ the risk-neutral
measure. All expectations are taken under $Q$. 

There is a European option with maturity $T>0$ and payoff $g(S_{T})$
at $T$, where $g:[0,\infty)\to\mathbb{R}$. For example, a European
put option with strike $K>0$ can be described by the payoff $g(x)=\max(K-x,0)$,
$x\geq0$. 

In several places, we assume that the payoff function is bounded.
The prices of European call options are not bounded, but can be obtained
from the prices of put options by the put-call parity.

Provided that the characteristic function $\varphi_{\log(S_{T})}$
of $\log(S_{T})$ is given in closed form, the COS method is able
to price the European option numerically very quickly as follows:
we denote by
\[
X:=\log(S_{T})-E[\log(S_{T})]
\]
the \emph{centralized log-returns}. The expectation can be computed
by
\[
E[\log(S_{T})]=-i\varphi_{\log(S_{T})}^{\prime}(0).
\]
The characteristic function $\varphi$ of $X$ is then given by
\[
\varphi(u)=\varphi_{\log(S_{T})}(u)\exp(-iuE[\log(S_{T})]),\quad u\in\mathbb{R}.
\]
We assume that $X$ has a density $f$, but the exact structure of
$f$ need not be known. Since the density of $X$ is centered around
zero, it is justified to truncate the density $f$ on a symmetric
interval $[-L,L]$, see \cite{junike2022precise}. Define
\[
v(x):=e^{-rT}g(\exp(x+E[\log(S_{T})]),\quad x\in\mathbb{R}.
\]
The price of the European option with payoff $g$ is then given by
\begin{align}
e^{-rT}E[g(S_{T})] & =\int_{\mathbb{R}}v(x)f(x)dx.\label{eq:price}
\end{align}
We need some abbreviations to discuss the COS method: suppose $f$
is $J+1$ times continuously differentiable for $J\geq0$. We will
approximate $f$ by cosine functions to solve the integral at the
right-hand side of Equation (\ref{eq:price}) numerically. We also
approximate the derivatives of $f$ by cosine functions in order to
approximate the Greeks, i.e., the sensitivities of the option, numerically. 

By $f^{(j)}$ we denote the $j^{th}$-derivative of $f$. For $L>0$
, let $f_{L}^{(j)}:=1_{[-L,L]}f^{(j)}$, $j=0,...,J+1$. Suppose that
$f^{(j)}$ is integrable and vanishes at $\pm\infty$. By integration
by parts, the Fourier transform of $f^{(j)}$ is given by
\begin{equation}
\int_{\mathbb{R}}f^{(j)}(x)e^{iux}dx=(-iu)^{j}\varphi(u),\quad j=0,...,J+1.\label{eq:Fourier_transofrm}
\end{equation}
Define the basis functions 
\[
e_{k}(x)=\cos\left(k\pi\frac{x+L}{2L}\right),\quad k=0,1,...
\]
The Fourier coefficients of $f_{L}^{(j)}$ are defined by $a_{k}^{j}$
and approximated by $c_{k}^{j}$, where 
\begin{align*}
a_{k}^{j}:= & \frac{1}{L}\int_{-L}^{L}f^{(j)}(x)e_{k}(x)dx,\\
c_{k}^{j}:= & \frac{1}{L}\int_{\mathbb{R}}f^{(j)}(x)e_{k}(x)dx,\quad k=0,1,...,\quad j=0,...,J+1.
\end{align*}
We also write $a_{k}$ and $c_{k}$ instead of $a_{k}^{0}$ and $c_{k}^{0}$,
respectively. Intuitively, we then have
\[
f^{(j)}\approx f_{L}^{(j)}=\sum_{k=0}^{\infty}{}^{\prime}a_{k}^{j}e_{k}\approx\sum_{k=0}^{N}{}^{\prime}a_{k}^{j}e_{k}\approx\sum_{k=0}^{N}{}^{\prime}c_{k}^{j}e_{k},
\]
where $\sum{}^{\prime}$ indicates that the first summand (with $k=0$)
is weighted by one-half. A little analysis, see \cite{fang2009novel},
shows that 
\[
c_{k}^{j}=\frac{1}{L}\Re\bigg\{\bigg(-i\frac{k\pi}{2L}\bigg)^{j}\varphi\bigg(\frac{k\pi}{2L}\bigg)e^{i\frac{k\pi}{2}}\bigg\},\quad k=0,1,...,\quad j=0,...,J+1,
\]
i.e., the coefficients $c_{k}^{j}$ can be obtained explicitly if
$\varphi$ is given in closed form. Here, $\Re(z)$ denotes the real
part of a complex number $z$. For $0<M\leq L$ define
\begin{equation}
v_{k}:=\int_{-M}^{M}v(x)e_{k}(x)dx,\quad k=0,1,...\label{eq:vk}
\end{equation}
To keep the notation simple, we suppress the dependence of $e_{k}$
and $c_{k}^{j}$ on $L$ and the dependence of $v_{k}$ on $M$. The
COS method states that the price of the European option can be approximated
by
\begin{equation}
\int_{\mathbb{R}}v(x)f(x)dx\approx\int_{-M}^{M}v(x)\sideset{}{'}\sum_{k=0}^{N}c_{k}e_{k}(x)dx=\sum_{k=0}^{N}{}^{\prime}c_{k}v_{k}.\label{eq:COS_method}
\end{equation}
The coefficients $c_{k}$ are given in closed form when $\varphi$
is given analytically and the coefficients $v_{k}$ can also be computed
explicitly in important cases, e.g., for plain vanilla European put
or call options and digital options, see for the instance appendix
in \cite{junike2022precise}. This makes the COS method numerically
very efficient and robust. 

To give the approximation in line (\ref{eq:COS_method}) a precise
meaning, we need a bound for the term
\begin{equation}
B_{f}(L):=\sum_{k=0}^{\infty}\frac{1}{L}\left|\int_{\mathbb{R}\setminus[-L,L]}f(x)\cos\left(k\pi\frac{x+L}{2L}\right)dx\right|^{2},\quad L>0.\label{eq:B(L)}
\end{equation}
\cite{junike2022precise} call integrable functions $f$ with $B_{f}(L)\to0$,
$L\to\infty$ \emph{COS-admissible.} The term $\sqrt{B_{f}(L)}$ is
equal to the third term at the right-hand side of Inequality (\ref{eq:error_bound}),
see proof of Theorem 7 in \cite{junike2022precise}. 

The class of COS-admissible densities is very large; in particular,
it includes bounded densities with existing first and second moments
and stable densities, see \cite{junike2022precise}. Lemma \ref{lem:cor8}
gives the approximation in line (\ref{eq:COS_method}) a precise meaning.
\begin{lem}
\label{lem:cor8}Let $f:\mathbb{R}\to\mathbb{R}$ be integrable and
COS-admissible. Let $v:\mathbb{R}\to\mathbb{R}$ be bounded, with
$|v(x)|\le K$ for all $x\in\mathbb{R}$ and some $K>0$. Let $\varepsilon>0$.
Let $M>0$ so that
\begin{equation}
\int_{\mathbb{R}\setminus[-M,M]}v(x)f(x)dx\leq\frac{\varepsilon}{2}.\label{eq:Cor8_1}
\end{equation}
Define $\xi=\sqrt{2M}K$. Let $L\geq M$ so that
\begin{equation}
\left\Vert f-f_{L}\right\Vert _{2}\leq\frac{\varepsilon}{6\xi}\quad\text{and}\quad\sqrt{B_{f}(L)}\leq\frac{\varepsilon}{6\xi}.\label{eq:Cor8_2}
\end{equation}
Choose $N_{L}$ large enough so that
\begin{equation}
\left\Vert f_{L}-\sum_{k=0}^{N}{}^{\prime}a_{k}e_{k}\right\Vert _{2}\leq\frac{\varepsilon}{6\xi}.\label{eq:Cor8_3}
\end{equation}
Then it holds for all $N\geq N_{L}$ that
\[
\left|\int_{\mathbb{R}}v(x)f(x)dx-\sum_{k=0}^{N}{}^{\prime}c_{k}v_{k}\right|\leq\varepsilon.
\]
\end{lem}

\begin{proof}
\citet[Cor. 8]{junike2022precise}.
\end{proof}
Theorem \ref{thm:find_N_A_B} and Theorem \ref{thm:find_N_C} apply
Lemma \ref{lem:cor8} and provide explicit formulas for the parameters
$M$, $L$ and $N$ of the COS method for densities with semi-heavy
tails and heavy tails, respectively.

Often, it is fine to choose $M=L$, e.g., when applying the COS method
to densities with semi-heavy tails. However, if the density has heavy
tails, it is usually numerically more efficient to choose $L$ and
$M$ differently.

For some models, e.g., the FMLS model, the exact tail behavior of
the density of the log-returns is known and the Inequalities (\ref{eq:Cor8_1})
and (\ref{eq:Cor8_2}) can be solved explicitly for $M$ and $L$.
For most other models, e.g., the Heston model, we only know that the
tails of the density of the log-returns decay exponentially, but we
do not know the exact behavior of the tails. For such densities, \cite{junike2022precise}
propose using Markov's inequality to obtain explicit bounds for $M$
and $L$.

The main requirement for applying the COS method is the availability
of the characteristic function of the log-returns in closed form.
Many models satisfy this requirement and we list some examples: 
\begin{description}
\item [{BS}] the Black-Scholes model with volatility $\sigma>0$, see \cite{black1973pricing}. 
\item [{Heston}] the Heston model with speed of mean-reversion $\kappa>0$,
level of mean-reversion $\eta>0$, vol of var $\theta>0$, initial
vol $v_{0}>0$ and correlation $\rho\in[-1,1]$, see \cite{heston1993closed}.
\item [{VG}] the variance gamma model with parameters $\sigma>0$, $\theta\in\mathbb{R}$
and $\nu>0$, see \cite{madan1998variance},
\item [{NIG}] the normal inverse Gaussian model with parameters $\alpha>0$,
$\beta\in(-\alpha,\alpha)$ and $\delta>0$, see \cite{barndorff1997normal}
and \citet[Sec. 5.3.8]{schoutens2003levy}.
\item [{CGMY}] the CGMY model with parameters $C>0$, $G>0$, $M>0$, $Y<2$,
see \cite{carr2002fine}.
\item [{FMLS}] the Finite Moment Log Stable model with parameters $\sigma>0$
and $\alpha\in(1,2)$, see \cite{carr2003finite}.
\end{description}
To use the COS method, the following parameters must be specified:
$M>0$ and $L>0$ to define the truncation range and $N\in\mathbb{N}$
to set the number of terms. $M$ and $L$ can be estimated by making
assumptions on the tail-behavior of the density. $N$ depends on the
smoothness of the density. 

The densities of the models listed above have the following properties
regarding tail-behavior and smoothness: The density of the log-returns
in the BS, NIG and Heston models, and in the CGMY model with parameter
$Y\in(0,1)$, is infinitely many times differentiable and has semi-heavy
tails, i.e., the tails decay exponentially, see \cite{kuchler2013tempered, asmussen2022role,albin2009asymptotic,schoutens2003levy,dragulescu2002probability}. 

The density of the VG model at time $T>0$ has semi-heavy tails, see
\citet[Example 7.5]{albin2009asymptotic}, and is $(J+1)$-times continuously
differentiable if $J+2<\frac{2T}{\nu}$, see \citet[Thm. 4.1]{kuchler2008shapes}.

The stable law has been used to model stock prices since \cite{mandelbrot1997variation}
and \cite{fama1965behavior}. The FMLS model models the log-returns
by a stable process with maximum negative skewness. The density of
the log-returns is infinitely many times differentiable and has a
heavy left tail with Pareto index $\alpha$, i.e., the left tail decays
like $|x|^{-1-\alpha}$, $x\to-\infty$, but the right tail decays
exponentially, see \cite{carr2003finite}. This makes the FMLS very
attractive from a theoretical point of view: put and call option prices
and all moments of the underlying stock price $S_{T}$ exist. The
expectation of the log-returns also exists, but the log-returns do
not have finite variance. Fitting the FMLS model to real market data
shows very satisfactory results, see \cite{carr2003finite}. 

\section{\label{sec:How-to-find}How to find $M$, $L$ and $N$}

We summarize the assumptions about the density $f$ of the log-returns
in order to find explicit expressions for $L$ and $N$. We denote
by $C_{b}^{J+1}(\mathbb{R})$ the set of bounded functions from $\mathbb{R}$
to $\mathbb{R}$ which are $(J+1)$-times, continuously differentiable
with bounded derivatives. By $f^{(j)}$ we denote the $j^{th}$-derivative
of $f\in C_{b}^{J+1}(\mathbb{R})$. We use the convention $f^{(0)}\equiv f$.
By $\left\Vert .\right\Vert _{\infty}$ and $\left\Vert .\right\Vert _{2}$
we denote the supremum norm and the $L^{2}$ norm, i.e.,
\[
\left\Vert f\right\Vert _{\infty}=\sup_{x\in\mathbb{R}}f(x),\quad\left\Vert f\right\Vert _{2}=\sqrt{\int_{\mathbb{R}}(f(x))^{2}dx}.
\]

Let $\mathbb{N}_{0}=\{0\}\cup\mathbb{N}$ and $J\in\mathbb{N}_{0}$.
Let $C_{1}>0$, $C_{2}>1$ and $C_{3}>0$ be suitable constants. Let
$L_{0}>0$. Suppose that $f$ satisfies one of the following assumptions:

\begin{assumption}\label{A1} 	
$f\in C_{b}^{J+1}(\mathbb{R})$ and $f$ has semi-heavy tails, i.e., 
\begin{equation} 
|f^{(j)}(x)|\leq C_{1}C_{2}^{j}e^{-C_{2}|x|},\quad j=0,...,J+1,\quad|x|\geq L_{0}.\label{eq:A} 
\end{equation}
\end{assumption}

\begin{assumption}\label{A2}	
$f\in C_{b}^{J+1}(\mathbb{R})$ and $f$ has heavy tails with index $\alpha>0$, i.e., \begin{equation}
|f^{(j)}(x)|\leq C_{3}|x|^{-1-\alpha-j},\quad j=0,...,J+1,\quad|x|\geq L_{0}.\label{eq:B} 
\end{equation}
\end{assumption}

We use the following abbreviations: the maximum of two real numbers
$x,y$, is denoted by $x\lor y$, the minimum is denoted by $x\land y$.
By $\Gamma$ we denote the gamma function
\[
\thinspace\Gamma(z)=\int_{0}^{\infty}u^{z-1}e^{-u}du,\quad\Re(z)>0.
\]

\begin{rem}
It is well known that $f^{(J+1)}$ exists and is bounded and continuous
if $\varphi$ decays fast enough, e.g., exponentially, for $u\to\pm\infty$.
In exceptional cases, the constants $C_{1}$ and $C_{2}$ are explicitly
known, see Example \ref{exa:Lapalce}. However, it should be pointed
out that in Theorem \ref{thm:find_N_A_B} we obtain bounds for $M$,
$L$ and $N$ for models with semi-heavy tails without knowing $C_{1}$
or $C_{2}$. In Theorem \ref{thm:find_N_C} we treat models with heavy-tails
and we assume that $C_{3}$ is known. The exact tail-behavior of the
density of the log-returns is indeed known for the FMLS model, see
Example \ref{exa:C3}.
\end{rem}

\begin{example}
\label{exa:Lapalce}Let $\sigma>0$. In the Laplace model, see \cite{madan2016adapted},
the log-returns at maturity $T>0$ have the density
\[
f_{\text{Lap}}(x)=\frac{1}{\sqrt{2}\sigma\sqrt{T}}e^{-\sqrt{2}\frac{|x|}{\sigma\sqrt{T}}},\quad x\in\mathbb{R}.
\]
To ensure stock prices are finite, we need $\sigma\sqrt{T}<\sqrt{2}$,
see \citet[Example 3]{guillaume2019implied}. It holds that
\[
|f_{\text{Lap}}^{(j)}(x)|=\frac{1}{\sqrt{2}\sigma\sqrt{T}}\left(\frac{\sqrt{2}}{\sigma\sqrt{T}}\right)^{j}e^{-\sqrt{2}\frac{|x|}{\sigma\sqrt{T}}},\quad x\in\mathbb{R}\setminus\{0\},\quad j=0,1,2,...
\]
Let $L_{0}>0$. Choose $C_{1}=\frac{1}{\sqrt{2}\sigma\sqrt{T}}$ and
$C_{2}=\frac{\sqrt{2}}{\sigma\sqrt{T}}$. Then $f_{\text{Lap}}^{(j)}$
satisfies Inequality (\ref{eq:A}) in Assumption \ref{A1}. 
\end{example}

The following lemma makes it possible to bound the series-truncation
error, which depends only on the choice of $N$. It is known in a
similar form in the literature, see e.g., Theorem 1.39 in \cite{plonka2018numerical},
Theorem 4.2 in \cite{wright2015extension} and Theorem 6 in \cite{boyd2001chebyshev}.
It can be proved by integration by parts. It is usually stated for
functions with range $[-1,1]$ or $[0,2\pi]$. Here, we explicitly
need the dependence of the series-truncation error on the truncation
range $[-L,L]$, so we give the full proof. 
\begin{lem}
\label{lem:A2}Let $J\in\mathbb{N}_{0}$. Suppose $f\in C_{b}^{J+1}(\mathbb{R})$.
It holds for $J\geq1$ that
\begin{align}
\left\Vert f_{L}-\sum_{k=0}^{N}{}^{\prime}a_{k}e_{k}\right\Vert _{2}\leq & \sum_{j=1}^{J}\frac{2^{j+1}}{j\pi^{j+1}}\frac{L^{j}}{N^{j}}\left(|f^{(j)}(-L)|+|f^{(j)}(L)|\right)\nonumber \\
 & +\frac{2^{J+2}\|f^{(J+1)}\|_{\infty}}{J\pi^{J+1}}\frac{L^{J+1}}{N^{J}}\label{eq:trun_error}
\end{align}
and for $J=0$ that
\[
\left\Vert f_{L}-\sum_{k=0}^{N}{}^{\prime}a_{k}e_{k}\right\Vert _{2}\leq\frac{4\|f^{(1)}\|_{\infty}}{\pi}\frac{L}{\sqrt{N}}.
\]
\end{lem}

\begin{proof}
It holds for any $\nu>0$ by integration by parts, see \citet[Eq. 1.3]{lyness1971adjusted},
that
\begin{align}
\int_{-L}^{L}f(x)e^{i\nu x}dx= & \sum_{j=0}^{J}\frac{i^{j+1}}{\nu^{j+1}}\left(e^{-i\nu L}f^{(j)}(-L)-e^{i\nu L}f^{(j)}(L)\right)\nonumber \\
 & +\frac{i^{J+1}}{\nu^{J+1}}\int_{-L}^{L}f^{(J+1)}(x)e^{i\nu x}dx.\label{eq:lyness}
\end{align}
For $k\in\mathbb{N}$, we apply Equation (\ref{eq:lyness}) for $\nu:=\frac{k\pi}{2L}$.
Then it follows that
\begin{align*}
|a_{k}|= & \frac{1}{L}\left|\int_{-L}^{L}f(x)\cos\left(k\pi\frac{x+L}{2L}\right)dx\right|\\
= & \frac{1}{L}\left|\Re\left\{ e^{i\frac{k\pi}{2}}\int_{-L}^{L}f(x)e^{i\frac{k\pi}{2L}x}dx\right\} \right|\\
= & \frac{1}{L}\bigg|\Re\bigg\{\sum_{j=0}^{J}i^{j+1}\frac{(2L)^{j+1}}{(k\pi)^{j+1}}\left(f^{(j)}(-L)-(-1)^{k}f^{(j)}(L)\right)\\
 & +e^{i\frac{k\pi}{2}}i^{J+1}\frac{(2L)^{J+1}}{(k\pi)^{J+1}}\int_{-L}^{L}f^{(J+1)}(x)e^{i\frac{k\pi}{2L}x}dx\bigg\}\bigg|\\
\leq & \sum_{j=1}^{J}\frac{2^{j+1}}{\pi^{j+1}}\frac{L^{j}}{k^{j+1}}\left(|f^{(j)}(-L)|+|f^{(j)}(L)|\right)+\frac{2^{J+2}\left\Vert f^{(J+1)}\right\Vert _{\infty}}{\pi^{J+1}}\frac{L^{J+1}}{k^{J+1}}.
\end{align*}
As $(e_{k})_{k\in\mathbb{N}}$ is a Orthonormal basis it follows that
\begin{equation}
\left\Vert f_{L}-\sum_{k=0}^{N}{}^{\prime}a_{k}e_{k}\right\Vert _{2}=\sqrt{\sum_{k=N+1}^{\infty}|a_{k}|^{2}}\leq\sum_{k=N+1}^{\infty}|a_{k}|.\label{eq:||f-ae||}
\end{equation}
By the integral test for convergence,
\begin{equation}
\sum_{k=N+1}^{\infty}\frac{1}{k^{j+1}}\leq\int_{N}^{\infty}x^{-j-1}dx=\frac{1}{j}N^{-j},\quad j\geq1,\label{eq:sum1/k^j+1}
\end{equation}
which implies Eq. (\ref{eq:trun_error}) for $J\geq1$. If $J=0$,
apply the first Equality from (\ref{eq:||f-ae||}) and the Inequality
(\ref{eq:sum1/k^j+1}). 
\end{proof}
Given $L>0$, we need to find an upper bound for $\left\Vert f^{(j)}\right\Vert _{\infty}$
to estimate the series truncation error by Inequality (\ref{eq:trun_error}).
$L$ can be found by applying Markov's inequality, see \cite{junike2022precise},
or Theorem \ref{thm:find_N_A_B} below. Next, we provide ideas and
examples for estimating $\|f^{(j)}\|_{\infty}$. If $f\in C_{b}^{J+1}(\mathbb{R})$
is a density with characteristic function $\varphi$, then it follows
by the inverse Fourier transform and Equation (\ref{eq:Fourier_transofrm})
that%
\begin{comment}
\[
f^{(j)}(x)=\frac{1}{2\pi}\int_{\mathbb{R}}(-iu)^{j}e^{-iux}\varphi(u)du,\quad j=0,1,...,J+1,\quad x\in\mathbb{R}.
\]
Hence,
\end{comment}
\begin{equation}
\|f^{(j)}\|_{\infty}\leq\frac{1}{2\pi}\int_{\mathbb{R}}|u|^{j}|\varphi(u)|du,\quad j=0,1,...,J+1.\label{eq:H_j}
\end{equation}
Inequality (\ref{eq:H_j}) provides explicit expressions to find a
bound for the term $\|f^{(j)}\|_{\infty}$, $j=0,..,J+1$ for several
models, as the next examples show. The right-hand side of Inequality
(\ref{eq:H_j}) can also be solved numerically, which is done in Section
\ref{subsec:BS-model}.
\begin{example}
\label{exa:stable}The density $f_{\text{Stable}}\in C_{b}^{\infty}(\mathbb{R})$
of the family of stable distributions with stability parameter $\alpha\in(0,2]$,
skewness $\beta\in[-1,1]$, scale $c>0$ and location $\theta\in\mathbb{R}$
has the characteristic function 
\begin{align*}
u\mapsto & \exp\left(iu\theta-|uc|{}^{\alpha}(1-i\beta\text{sgn}(u)\Phi_{\alpha}(u)\right),\\
 & \Phi_{\alpha}(u)=\begin{cases}
\tan\frac{\pi\alpha}{2} & ,\alpha\neq1\\
-\frac{2}{\pi}\log(|u|) & ,\alpha=1,
\end{cases}
\end{align*}
see \cite{zolotarev1986one}. It follows by Inequality (\ref{eq:H_j})
that
\begin{align}
\|f_{\text{Stable}}^{(j)}\|_{\infty} & \leq\frac{1}{\pi\alpha c^{j+1}}\int_{0}^{\infty}t^{\frac{j+1}{\alpha}-1}e^{-t}dt\nonumber \\
 & \leq\frac{\Gamma\left(\frac{j+1}{\alpha}\right)}{\pi\alpha c^{j+1}},\quad j=0,1,2,...\label{eq:stable_bound}
\end{align}
\end{example}

\begin{example}
\label{exa:Gauss}In the BS model with volatility $\sigma>0$, the
centralized log-returns at time $T>0$ have Gaussian density $f_{\text{BS}}$
with mean zero and variance $\sigma^{2}T$. The normal distribution
is a member of the stable distributions: choose $\alpha=2$, $\beta=0$,
$c=\frac{\sigma\sqrt{T}}{\sqrt{2}}$ and $\theta=0$. An upper bound
for the density $f_{\text{BS}}$ of the log-returns and its derivatives
can be obtained directly from Inequality (\ref{eq:stable_bound}).
\end{example}


\begin{example}
\label{exa:NIG}In the symmetric NIG model with parameters $\alpha>0$,
$\beta=0$ and $\delta>0$, the centralized log-returns at time $T>0$
have density $f_{\text{NIG}}\in C_{b}^{\infty}(\mathbb{R})$, whose
characteristic function is given by
\[
u\mapsto\exp\left(-\delta T\sqrt{\alpha^{2}+u^{2}}+\delta T\alpha\right),\quad u\in\mathbb{R},
\]
see \cite{barndorff1997normal} and \citet[Sec. 5.3.8]{schoutens2003levy}.
We obtain, by Inequality (\ref{eq:H_j}) and using $\alpha^{2}+u^{2}\geq u^{2}$,
that
\begin{align*}
\|f_{\text{NIG}}^{(j)}\|_{\infty} & \leq\frac{e^{T\delta\alpha}j!}{\pi(T\delta)^{j+1}},\quad j=0,1,2,...
\end{align*}
\end{example}

\begin{example}
\label{exa:FMLS}In the FMLS model with parameters $\alpha\in(1,2)$
and $\sigma>0$, the centralized log-returns at time $T>0$ are stably
distributed with stability parameter $\alpha$, skewness $\beta=-1$,
scale $c=\sigma T^{\frac{1}{\alpha}}$ and location $\theta=0$, see
\cite{carr2003finite}. An upper bound for the density $f_{\text{FMLS}}$
of the log-returns and its derivatives can be obtained directly from
Inequality (\ref{eq:stable_bound}).
\end{example}

In Theorem \ref{thm:find_N_A_B} we provide explicit formulas for
$M$, $N$ and $L$ when $f$ satisfies Assumption \ref{A1} to ensure
that the COS method approximates the true price within a predefined
error tolerance $\varepsilon>0$. Theorem \ref{thm:find_N_A_B} extends
\citet[Cor. 9, Rem 11]{junike2022precise}. 

We also include the derivatives of $f$ in Theorem \ref{thm:find_N_A_B}
in order to be able approximate the sensitivities (Greeks) of the
price of the option, see Section \ref{sec:Greeks-by-the}. To approximate
the price of the option by Theorem \ref{thm:find_N_A_B}, set $\ell=0$.
We will see that Theorem \ref{thm:find_N_A_B} with $\ell\in\{1,2\}$
is useful for the sensitivities Delta and Gamma.
\begin{thm}
\label{thm:find_N_A_B}($M$, $L$ and $N$ for densities with semi-heavy
tails). Let $v:\mathbb{R}\to\mathbb{R}$ be bounded, with $|v(x)|\le K$
for all $x\in\mathbb{R}$ and some $K>0$. Let $\varepsilon>0$ be
small enough. Suppose $J\in\mathbb{N}_{0}$. Let $f$ be a density
satisfying Assumption \ref{A1}. Let $\ell\in\{0,...,J-1\}$. For
some even $n\in\mathbb{N}$ let
\begin{equation}
L=M=\sqrt[n]{\frac{2K\mu_{n}}{\varepsilon}},\label{eq:M}
\end{equation}
where $\mu_{n}$ is the $n^{th}-$moment of $f$, i.e.,
\begin{equation}
\mu_{n}=\frac{1}{i^{n}}\left.\frac{\partial^{n}}{\partial u^{n}}\varphi(u)\right|_{u=0}.\label{eq:nth momen}
\end{equation}
Let $\xi=\sqrt{2M}K$. If $J\geq1$, let $k\in\{1,...,J-\ell\}$ and
\begin{align}
N & \geq\left(\frac{2^{k+2}\left\Vert f^{(k+1+\ell)}\right\Vert _{\infty}L^{k+1}}{k\pi^{k+1}}\frac{12\xi}{\varepsilon}\right)^{\frac{1}{k}}.\label{eq:N_J>0}
\end{align}
If $J=0$, let
\begin{equation}
N\geq\left(\frac{4\left\Vert f^{(1)}\right\Vert _{\infty}L}{\pi}\frac{6\xi}{\varepsilon}\right)^{2}.\label{eq:N_j=00003D0}
\end{equation}
In both cases it holds that
\begin{equation}
\left|\int_{\mathbb{R}}v(x)f^{(\ell)}(x)dx-\sum_{k=0}^{N}{}^{\prime}c_{k}^{\ell}v_{k}\right|\leq\varepsilon.\label{eq:vf-sum ck vk}
\end{equation}
\end{thm}

\begin{proof}
The $n^{th}-$moment of $f$ can be obtained from the $n^{th}$ derivative
of the characteristic function of $f$ by Equation (\ref{eq:nth momen}).
It holds by Markov's inequality and the definition of $M$ that
\begin{equation}
\int_{\mathbb{R}\setminus[-M,M]}\big|v(x)f(x)\big|dx\leq K\int_{\mathbb{R}\setminus[-M,M]}f(x)dx\leq K\frac{\mu_{n}}{M^{n}}\leq\frac{\varepsilon}{2},\label{eq:Markov_semi}
\end{equation}
i.e., Inequality (\ref{eq:Cor8_1}) in Lemma \ref{lem:cor8} is satisfied
for $f$. For $\varepsilon$ small enough, $M$ is large enough so
that Assumption \ref{A1} holds, i.e., $L_{0}\leq M=L$. It follows
that
\begin{equation}
\int_{\mathbb{R}\setminus[-M,M]}\big|v(x)f^{(\ell)}(x)\big|dx\leq K\int_{\mathbb{R}\setminus[-M,M]}C_{1}C_{2}^{\ell}e^{-C_{2}|x|}(x)dx\leq\frac{\varepsilon}{2};\label{eq:A0_semi_eps}
\end{equation}
the last inequality holds true if
\begin{equation}
M\geq-\frac{1}{C_{2}}\log\left(\frac{1}{KC_{1}C_{2}^{\ell-1}}\frac{\varepsilon}{4}\right).\label{eq:M_semi}
\end{equation}
Further,
\begin{align}
\left\Vert f^{(\ell)}-f_{L}^{(\ell)}\right\Vert _{2} & \leq\sqrt{2C_{1}^{2}C_{2}^{2\ell}\int_{L}^{\infty}e^{-2C_{2}x}dx}\nonumber \\
 & =\frac{C_{1}C_{2}^{\ell}}{\sqrt{C_{2}}}e^{-C_{2}L}\label{eq:A1_semi}\\
 & \leq\frac{\varepsilon}{6\xi};\label{eq:A_1_semi_eps}
\end{align}
the last inequality holds true if
\begin{equation}
L\geq-\frac{1}{C_{2}}\log\left(\frac{\sqrt{C_{2}}}{C_{1}C_{2}^{\ell}}\frac{\varepsilon}{6\xi}\right).\label{eq:L1_semi}
\end{equation}
Proposition 2 in \cite{junike2022precise} shows that
\[
B_{f^{(\ell)}}(L)\leq\frac{2}{3}\frac{\pi^{2}}{L^{2}}\int_{\mathbb{R}\setminus[-L,L]}|xf^{(\ell)}(x)|^{2}dx.
\]
We then have
\begin{align}
\sqrt{B_{f^{(\ell)}}(L)}\leq & \sqrt{\frac{4}{3}\frac{\pi^{2}C_{1}^{2}C_{2}^{2\ell}}{L^{2}}\int_{L}^{\infty}x^{2}e^{-2C_{2}x}dx}\nonumber \\
= & \frac{2\pi C_{1}C_{2}^{\ell}}{\sqrt{6C_{2}}}e^{-C_{2}L}\sqrt{1+\frac{1}{LC_{2}}+\frac{1}{2L^{2}C_{2}^{2}}}\label{eq:B(L)_semi}\\
\leq & \frac{\varepsilon}{6\xi};\label{eq:B(L)_semi_eps}
\end{align}
the last inequality holds true if 
\begin{equation}
L\geq-\frac{1}{C_{2}}\log\left(\left(\frac{2\pi C_{1}C_{2}^{\ell}}{\sqrt{6C_{2}}}\sqrt{1+\frac{1}{LC_{2}}+\frac{1}{2L^{2}C_{2}^{2}}}\right)^{-1}\frac{\varepsilon}{6\xi}\right).\label{eq:L_B_semi}
\end{equation}
Assume $J\geq1$. For $\varepsilon$ small enough, we have 
\begin{equation}
N\geq\frac{3LC_{2}}{\pi},\label{eq:N>=00003D3LC2/pi}
\end{equation}
because the right-hand side of Inequality (\ref{eq:N>=00003D3LC2/pi})
is of order $\varepsilon^{-n}$ while the right-hand side of Inequality
(\ref{eq:N_J>0}) is of order $\varepsilon^{-(n+\frac{3n}{2k}+\frac{1}{k})}$.
By Inequality (\ref{eq:N_J>0}) it follows that
\begin{align*}
 & \sum_{j=1}^{k}\frac{2^{j+1}}{j\pi^{j+1}}\frac{L^{j}}{N^{j}}\left(|f^{(j+\ell)}(-L)|+|f^{(j+\ell)}(L)|\right)\\
\leq & \sum_{j=1}^{k}\frac{2^{j+1}}{j\pi^{j+1}}\frac{L^{j}}{N^{j}}\left(2C_{1}C_{2}^{j+\ell}e^{-C_{2}L}\right)\\
\leq & \frac{8}{\pi^{2}}C_{1}C_{2}^{1+\ell}e^{-C_{2}L}\frac{L}{N}\sum_{j=0}^{\infty}\left(\frac{2LC_{2}}{\pi N}\right)^{j}\\
\leq & \frac{8}{\pi^{2}}C_{1}C_{2}^{1+\ell}e^{-C_{2}L}\frac{\pi}{3C_{2}}\frac{1}{1-\frac{2LC_{2}}{\pi N}}\\
\leq & \frac{8C_{1}C_{2}^{\ell}}{\pi}e^{-C_{2}L}\leq\frac{\varepsilon}{12\xi};
\end{align*}
the last inequality holds true if
\begin{equation}
L\geq-\frac{1}{C_{2}}\log\left(\frac{\pi}{8C_{1}C_{2}^{\ell}}\frac{\varepsilon}{12\xi}\right).\label{eq:L_N_semi}
\end{equation}
By Equation (\ref{eq:M}), $M$ and $L$ are of order $\varepsilon^{-\frac{1}{n}}$$.$
Hence, for $\varepsilon$ small enough, Inequalities (\ref{eq:M_semi}),
(\ref{eq:L1_semi}), (\ref{eq:L_B_semi}) and (\ref{eq:L_N_semi})
are indeed satisfied because the right-hand sides of these Inequalities
are of order $\log(\varepsilon)$. By the definition of $N$ in Inequality
(\ref{eq:N_J>0}), we also have 
\[
\frac{2^{k+2}\left\Vert f^{(k+1+\ell)}\right\Vert _{\infty}}{k\pi^{k+1}}\frac{L^{k+1}}{N^{k}}\leq\frac{\varepsilon}{12\xi}.
\]
By Lemma \ref{lem:A2} it follows that 
\begin{equation}
\left\Vert f_{L}^{(\ell)}-\sum_{k=0}^{N}{}^{\prime}a_{k}^{\ell}e_{k}\right\Vert _{2}\leq\frac{\varepsilon}{6\xi}.\label{eq:<lesp/6xi}
\end{equation}
As $B_{f^{(\ell)}}(L)\to0$, $L\to\infty$, $f^{(\ell)}$ is COS-admissible.
Inequalities (\ref{eq:A0_semi_eps}), (\ref{eq:A_1_semi_eps}), (\ref{eq:B(L)_semi_eps}),
(\ref{eq:<lesp/6xi}) and Lemma \ref{lem:cor8} imply Inequality (\ref{eq:vf-sum ck vk}).
Now assume $J=0$. By the definition of $N$ in Inequality (\ref{eq:N_j=00003D0}),
Lemma \ref{lem:A2} again implies Inequality (\ref{eq:<lesp/6xi}).
Apply Lemma \ref{lem:cor8} to conclude.
\end{proof}
\begin{rem}
\label{rem:Theorem_A}If $v$ is a European put option with maturity
$T$, $K$ can be set to the strike of the option times $e^{-rT}$.
$\varepsilon$ denotes some error tolerance. Numerical experiments
in \cite{junike2022precise} suggest choosing $n\in\{4,6,8\}$ for
$\mu_{n}$. According to Theorem \ref{thm:find_N_A_B}, any $k\in\{1,...,J-\ell\}$
is allowed to define $N$ by Inequality (\ref{eq:N_J>0}). In the
applications, one could minimize $N$ over all admissible $k$. But
this could be time-consuming, and in Sections \ref{subsec:BS-model}
and \ref{subsec:FMLS-model} we set $k$ to a fixed value, i.e., $k=40$.
Bounds for $\|f^{(k+1+\ell)}\|_{\infty}$ are explicitly known for
some models, see Examples \ref{exa:Gauss}, \ref{exa:FMLS} and \ref{exa:NIG}.
These bounds can also be obtained numerically, see Section \ref{subsec:BS-model}.
Section \ref{sec:Numerical-experiments} contains examples indicating
that the bound in Inequality (\ref{eq:N_J>0}) for $N$ is often sharp
and very useful in applications.
\end{rem}

To extend Theorem \ref{thm:find_N_A_B} to the case in which $f$
satisfies Assumption \ref{A2}, i.e., $f$ has heavy tails, we need
a bound for the term $B_{f}(L)$, see Equation (\ref{eq:B(L)}). Proposition
2 in \cite{junike2022precise} provides a bound for $B_{f}(L)$, but
we cannot apply it to all densities of the stable distributions because
the assumptions in that Proposition are not satisfied for all stability
parameters $\alpha\in(0,2]$ of the stable law. Therefore, we need
the following lemma:%
\begin{comment}
The bound by the lemma is also sharper than the bound in Prop 2:

while(T)\{

mat=rexp(1)

alpha=runif(1,1,2)

sigma=rexp(1)

eps=10\textasciicircum -4

K=runif(1,50,150)

C3=alpha{*}(1-alpha)/(gamma(2-alpha){*}cos(pi{*}alpha/2)){*}sigma\textasciicircum alpha{*}mat

tmp0=(4{*}C3{*}K/(eps{*}alpha))\textasciicircum (1/alpha)

myxi=sqrt(2{*}tmp0){*}K

tmp1=(sqrt(2){*}6{*}C3{*}myxi/(sqrt(1+2{*}alpha){*}eps))\textasciicircum (2/(1+2{*}alpha))

tmp2=(12{*}C3{*}sqrt(1/alpha\textasciicircum 2+2/3){*}myxi/eps)\textasciicircum (2/(1+2{*}alpha))

tmp3=(2{*}pi{*}C3/(sqrt(3{*}sqrt(2{*}alpha-1))){*}6{*}myxi/eps)\textasciicircum (2/(1+2{*}alpha))

round(c(tmp0,tmp1,tmp2,tmp3),0)

if(tmp2>tmp3)

break

\}
\end{comment}

\begin{lem}
\label{lem:COS}Let $f\in C_{b}^{1}(\mathbb{R})$ be integrable and
square-integrable such that 
\[
xf^{2}(x)\to0,\quad x\to\pm\infty.
\]
Let $L>0$. If 
\begin{equation}
f^{\prime}(x)\geq0,\quad x\leq-L\quad\text{and}\quad f^{\prime}(x)\leq0,\quad x\geq L\label{eq:lemma_monotone}
\end{equation}
then
\[
B_{f}(L)\leq\frac{1}{L}\left(\int_{\mathbb{R}\setminus[-L,L]}f(x)dx\right)^{2}+\frac{8}{3}L\left(f^{2}(L)\lor f^{2}(-L)\right).
\]
\end{lem}

\begin{proof}
It holds that $f(x)\to0$, $x\to\pm\infty$ and

\[
\int_{L}^{\infty}\left|f^{\prime}(x)\right|dx=-\int_{L}^{\infty}f^{\prime}(x)dx=f(L).
\]
Note that for all $k\in\mathbb{N}$, 
\begin{align*}
\int_{L}^{\infty}f(x)\cos\left(k\pi\frac{x+L}{2L}\right)dx= & \underbrace{\left[f(x)\sin\left(k\pi\frac{x+L}{2L}\right)\frac{2L}{k\pi}\right]_{L}^{\infty}}_{=0}\\
 & -\frac{2L}{k\pi}\int_{L}^{\infty}f^{\prime}(x)\sin\left(k\pi\frac{x+L}{2L}\right)dx,
\end{align*}
implying 
\begin{align*}
\frac{1}{L}\left|\int_{L}^{\infty}f(x)\cos\left(k\pi\frac{x+L}{2L}\right)dx\right|^{2}= & \frac{4}{\pi^{2}k^{2}}L\left|\int_{L}^{\infty}f^{\prime}(x)\sin\left(k\pi\frac{x+L}{2L}\right)dx\right|^{2}\\
\leq & \frac{4}{\pi^{2}k^{2}}Lf^{2}(L).
\end{align*}
Similarly, 
\[
\frac{1}{L}\left|\int_{-\infty}^{-L}f(x)\cos\left(k\pi\frac{x+L}{2L}\right)dx\right|^{2}\leq\frac{4}{\pi^{2}k^{2}}Lf^{2}(-L).
\]
Using 
\[
\sum_{k=1}^{\infty}\frac{1}{k^{2}}=\frac{\pi^{2}}{6}\quad\text{and}\quad|a+b|^{2}\leq4(a^{2}\lor b^{2}),
\]
we arrive at 
\begin{align*}
\sum_{k=0}^{\infty} & \frac{1}{L}\left|\int_{\mathbb{R}\setminus[-L,L]}f(x)\cos\left(k\pi\frac{x+L}{2L}\right)dx\right|^{2}\\
 & \leq\frac{1}{L}\left|\int_{\mathbb{R}\setminus[-L,L]}f(x)dx\right|^{2}+4\left(\frac{4\pi^{2}}{6\pi^{2}}Lf^{2}(L)\lor\frac{4\pi^{2}}{6\pi^{2}}Lf^{2}(-L)\right)\\
 & =\frac{1}{L}\left|\int_{\mathbb{R}\setminus[-L,L]}f(x)dx\right|^{2}+\frac{8}{3}L\left(f^{2}(L)\lor f^{2}(-L)\right).
\end{align*}
\end{proof}
\begin{example}
\label{exa:f B uni}Let $f$ be a unimodal density satisfying Assumption
\ref{A2}. Then $f$ also satisfies the assumption of Lemma \ref{lem:COS}.
To see this, note that $f$ is bounded and therefore square-integrable.
The unimodality implies the assertion in line (\ref{eq:lemma_monotone}).
Further,
\[
|xf^{2}(x)|\leq C_{3}^{2}|x|^{-1-2\alpha}\to0,\quad x\to\pm\infty.
\]
\end{example}

In Theorem \ref{thm:find_N_C} we provide explicit formulas for $M$,
$N$ and $L$ if $f$ satisfies Assumption \ref{A2} and is unimodal,
to ensure that the COS method approximates the true price within a
predefined error tolerance $\varepsilon>0$. In particular, the density
of the stable law is unimodal, see \cite{yamazato1978unimodality}. 
\begin{thm}
\label{thm:find_N_C}($M$, $L$ and $N$ for densities with heavy
tails). Let $v:\mathbb{R}\to\mathbb{R}$ be bounded, with $|v(x)|\le K$
for all $x\in\mathbb{R}$ and some $K>0$. Let $\varepsilon>0$ be
small enough. Suppose $J\in\mathbb{N}$. Let $f$ be a unimodal density
satisfying Assumption \ref{A2}. Let
\begin{align}
M & =\left(\frac{4C_{3}K}{\varepsilon\alpha}\right)^{\frac{1}{\alpha}},\label{eq:M_stable}
\end{align}
$\xi:=\sqrt{2M}K$ and
\begin{equation}
L=M\lor\left(12C_{3}\sqrt{\frac{1}{\alpha^{2}}+\frac{2}{3}}\frac{\xi}{\varepsilon}\right)^{\frac{2}{1+2\alpha}}.\label{eq:L_stable}
\end{equation}
\begin{comment}
M=(4{*}C3{*}K/(eps{*}alpha))\textasciicircum (1/alpha)

xi=sqrt(2{*}M){*}K

tmp1=(sqrt(2){*}6{*}C3{*}xi/(sqrt(1+2{*}alpha){*}eps))\textasciicircum (2/(1+2{*}alpha))

tmp2=(12{*}C3{*}sqrt(1/alpha\textasciicircum 2{*}2/3){*}xi/eps)\textasciicircum (2/(1+2{*}alpha))

tmp3=(96{*}xi{*}C3/pi\textasciicircum 2)\textasciicircum (1/(1+alpha)) 
\end{comment}
Let $k\in\{1,...,J\}$ and
\begin{align}
N\geq\left(\frac{2^{k+2}\left\Vert f^{(k+1)}\right\Vert _{\infty}L^{k+1}}{k\pi^{k+1}}\frac{12\xi}{\varepsilon}\right)^{\frac{1}{k}}.\label{eq:N_stable}
\end{align}
Then it holds that
\begin{equation}
\left|\int_{\mathbb{R}}v(x)f(x)dx-\sum_{k=0}^{N}{}^{\prime}c_{k}v_{k}\right|\leq\varepsilon.\label{eq:vf-sum ck vk-1}
\end{equation}
\end{thm}

\begin{proof}
For $\varepsilon$ small enough, $M$ is large enough so that Assumption
\ref{A2} holds, i.e. $L_{0}\leq M\leq L$. The inequality 
\[
\int_{\mathbb{R}\setminus[-M,M]}\big|v(x)f(x)\big|dx\leq K\int_{\mathbb{R}\setminus[-M,M]}f(x)dx\leq\frac{2KC_{3}}{\alpha}M^{-\alpha}\leq\frac{\varepsilon}{2}
\]
is satisfied by the definition of $M$. \textcolor{gray}{{} }A little
calculation shows that the definition of $L$ implies
\[
L\geq\left(\frac{\sqrt{2}6C_{3}\xi}{\sqrt{1+2\alpha}\varepsilon}\right)^{\frac{2}{1+2\alpha}},
\]
therefore
\begin{align*}
\big\Vert f-f_{L}\big\Vert_{2} & \leq\sqrt{2\int_{L}^{\infty}C_{3}^{2}x^{-2-2\alpha}dx}\\
 & =\frac{\sqrt{2}C_{3}}{\sqrt{1+2\alpha}}L^{-\frac{1+2\alpha}{2}}\\
 & \leq\frac{\varepsilon}{6\xi}.
\end{align*}
The density $f$ satisfies the condition of Lemma \ref{lem:COS} by
Example \ref{exa:f B uni}. Using the bound for $B_{f}(L)$ from Lemma
\ref{lem:COS}, we obtain
\begin{align}
\sqrt{B_{f}(L)} & \leq\sqrt{\frac{1}{L}\left(2\int_{L}^{\infty}C_{3}x^{-1-\alpha}dx\right)^{2}+\frac{8}{3}LC_{3}^{2}L^{-2\alpha-2}}\nonumber \\
 & =\sqrt{\frac{4C_{3}^{2}}{\alpha^{2}}L^{-2\alpha-1}+\frac{8}{3}C_{3}^{2}L^{-2\alpha-1}}\nonumber \\
 & =2C_{3}\sqrt{\frac{1}{\alpha^{2}}+\frac{2}{3}}L^{-\frac{1+2\alpha}{2}}\label{eq:B(L)_stable}\\
 & \leq\frac{\varepsilon}{6\xi},\nonumber 
\end{align}
\begin{comment}
\#checked empirically

C3=rexp(1)

alpha=rexp(1)

L=rexp(1)

tmp=function(x)\{C3{*}x\textasciicircum (-1-alpha)\}

sqrt(1/L{*}(2{*}integrate(tmp,L,Inf)\$value)\textasciicircum 2+8/3{*}L{*}C3\textasciicircum 2{*}L\textasciicircum (-2{*}alpha-2))

2{*}C3{*}sqrt(1/(alpha\textasciicircum 2)+2/3){*}L\textasciicircum (-(1+2{*}alpha)/2)
\end{comment}
the last Inequality holds by the definition of $L$. For $\varepsilon$
small enough, we have $N\geq2$, which implies 
\begin{equation}
\frac{1}{N}\frac{1}{1-\frac{2}{N\pi}}\leq\sqrt{\frac{2}{3}}\leq\sqrt{\frac{1}{\alpha^{2}}+\frac{2}{3}}.\label{eq:1/N}
\end{equation}
For $\varepsilon$ small enough, it holds that $L\geq1$. Using Inequality
(\ref{eq:1/N}), the definition of $L$ and $\frac{1}{1+\alpha}\leq\frac{2}{1+2\alpha}$,
a straightforward calculation shows that
\begin{equation}
L\geq\left(\frac{96C_{3}\xi}{\pi^{2}\varepsilon}\frac{1}{N}\frac{1}{1-\frac{2}{N\pi}}\right)^{\frac{1}{1+\alpha}}.\label{eq:1/N_L}
\end{equation}
It follows that
\begin{align*}
 & \sum_{j=1}^{k}\frac{2^{j+1}}{j\pi^{j+1}}\frac{L^{j}}{N^{j}}\left(|f^{(j)}(-L)|+|f^{(j)}(L)|\right)\\
\leq & \sum_{j=1}^{k}\frac{2^{j+1}}{j\pi^{j+1}}\frac{L^{j}}{N^{j}}\left(2C_{3}L^{-1-\alpha-j}\right)\\
\leq & \frac{8}{\pi^{2}}C_{3}L^{-1-\alpha}\frac{1}{N}\sum_{j=0}^{\infty}\left(\frac{2}{N\pi}\right)^{j}\\
\leq & \frac{8}{\pi^{2}}C_{3}L^{-1-\alpha}\frac{1}{N}\frac{1}{1-\frac{2}{N\pi}}\\
\leq & \frac{\varepsilon}{12\xi},
\end{align*}
the last inequality holds by Inequality (\ref{eq:1/N_L}). By the
definition of $N$ in Inequality (\ref{eq:N_J>0}), we also have 
\[
\frac{2^{k+2}\left\Vert f^{(k+1)}\right\Vert _{\infty}}{k\pi^{k+1}}\frac{L^{k+1}}{N^{k}}\leq\frac{\varepsilon}{12\xi}.
\]
By Lemma \ref{lem:A2} it follows that 
\begin{equation}
\left\Vert f_{L}-\sum_{k=0}^{N}{}^{\prime}a_{k}e_{k}\right\Vert _{2}\leq\frac{\varepsilon}{6\xi}.\label{eq:<lesp/6xi-1}
\end{equation}
As $B_{f}(L)\to0$, $L\to\infty$, $f$ is COS-admissible. Apply Lemma
\ref{lem:cor8} to conclude.
\end{proof}
\begin{example}
\label{exa:C3}Recall that the log-returns of the FMLS model are stably
distributed. Let $F_{\text{Stable}}$ be the cumulative distribution
function for the stable density $f_{\text{Stable}}$ with stability
parameter $\alpha\in(0,2)$, skewness $\beta\in[-1,1]$, scale $c>0$
and location $\theta\in\mathbb{R}$. By \citet[Property 1.2.15]{samorodnitsky2017stable}
it holds that
\begin{align*}
\lim_{x\to\infty}x^{\alpha}(1-F_{\text{Stable}}(x)) & =C_{\alpha}\frac{1+\beta}{2}c^{\alpha},\\
\lim_{x\to\infty}x^{\alpha}(F_{\text{Stable}}(-x)) & =C_{\alpha}\frac{1-\beta}{2}c^{\alpha},
\end{align*}
where
\[
C_{\alpha}=\begin{cases}
\frac{1-\alpha}{\Gamma(2-\alpha)\cos\big(\frac{\pi\alpha}{2}\big)} & ,\alpha\neq1\\
\frac{2}{\pi} & ,\alpha=1.
\end{cases}
\]
For stable densities we therefore suggest to set $C_{3}$ in Theorem
\ref{thm:find_N_C} at least as large as $\alpha C_{\alpha}\frac{1+|\beta|}{2}c^{\alpha}$
to obtain $M$ and $L$. The number of terms $N$ can be found using
Inequality (\ref{eq:N_stable}) and bounds for $\|f^{(j)}\|_{\infty}$
are explicitly given in Example \ref{exa:stable}.
\end{example}


\section{\label{sec:Convergence-rate-of}Order of Convergence}

The main Theorem \ref{thm:asy} in this section describes the order
of convergence of the COS method if we allow $N\to\infty$ and choose
$M$ and $L$ depending on $N$. We describe only the asymptotic behavior
of the COS method and we assume $M=L$ in this section to keep the
notation simple. We establish a bound of the order of convergence
of the error of the COS method with parameters $L$ and $N$, i.e.,
\begin{equation}
\text{err}(L,N)=\left|\int_{\mathbb{R}}v(x)f(x)dx-\sum_{k=0}^{N}{}^{\prime}c_{k}v_{k}\right|.\label{eq:errCOS}
\end{equation}
We say the error of the COS method converges \emph{with order $\rho>0$},
if there is a constant $\kappa>0$ such that
\begin{equation}
\forall N\in\mathbb{N}\,:\,\text{err}(L(N),N)\leq\frac{\kappa}{N^{\rho}}.\label{eq:order of con}
\end{equation}
The error is of \emph{infinite order} or \emph{converges exponentially},
if Inequality (\ref{eq:order of con}) holds for any $\rho$, see
\citet[Sec. 2.3]{boyd2001chebyshev}. We use big $O$ notation: for
functions $g,h:\mathbb{N}\to\mathbb{R}$, we write $h(N)=O(g(N))$
as $N\to\infty$, if the absolute value of $h(N)$ is at most a positive
constant multiple of $g(N)$ for all sufficiently large values of
$N$. 
\begin{thm}
\label{thm:asy}(Bounds for the order of convergence). Let $v:\mathbb{R}\to\mathbb{R}$
be bounded, with $|v(x)|\le K$ for all $x\in\mathbb{R}$ and some
$K>0$. Assume $J\in\mathbb{N}$. \\
(i) Let $f$ be a density satisfying Assumption \ref{A1}. Let $\beta\in\left(0,\frac{2J}{2J+3}\right)$
and $\gamma>0$. If $L=\gamma N^{\beta}$ it holds that
\[
\text{err}(L(N),N)\leq O\left(N^{-J(1-\beta)+\frac{3}{2}\beta}\right),\quad\text{as }N\to\infty.
\]
(ii) Let $f$ be a unimodal density satisfying Assumption \ref{A2}.
Let $\beta\in\left(0,\frac{2J}{2J+3+2\alpha}\right)$ and $\gamma>0$.
If $L=\gamma N^{\beta}$ it holds that
\[
\text{err}(L(N),N)\leq O\left(N^{-\alpha\beta}\right),\quad\text{as }N\to\infty.
\]
In both cases we have $\text{err}(L(N),N)\to0$, $N\to\infty.$%
\begin{comment}
\#checked numerically

alpha=runif(1,1,2)

beta=seq(0,1,length.out=100)

J=ceiling(rexp(1))

l1=-alpha{*}beta

l2=beta{*}(alpha+3/2)-1

l3=beta{*}(J+3/2)-J

plot(c(0,1),c(min(l1,l2,l3),max(l1,l2,l3)),type=\textquotedbl l\textquotedbl ,col=\textquotedbl white\textquotedbl )

lines(beta,l1,col=\textquotedbl black\textquotedbl )

lines(beta,l2,col=\textquotedbl red\textquotedbl )

lines(beta,l3,col=\textquotedbl green\textquotedbl )

lines(beta,pmax(l1,l2,l3),lty=2,lwd=3)

abline(v=2/(4{*}alpha+3),col=\textquotedbl grey\textquotedbl )

abline(h=-2{*}alpha/(4{*}alpha+3),col=\textquotedbl grey\textquotedbl )

f=function(alpha)\{-2{*}alpha/(4{*}alpha+3)\}

curve(f,1,2)
\end{comment}
\end{thm}

\begin{proof}
Let $v_{L}:=1_{[-L,L]}v$. As in the proof of Corollary 8 in \cite{junike2022precise},
one can show that
\begin{align}
\Big|\int_{\mathbb{R}}v(x)f(x)dx-\sideset{}{'}\sum_{k=0}^{N}c_{k}v_{k}\Big|\leq & A_{0}(L)+\|v_{L}\|_{2}(A_{1}(L)+A_{2}(L,N)+\sqrt{B_{f}(L)}),\label{eq:asy_sum}
\end{align}
where $B_{f}(L)$ as in Equation (\ref{eq:B(L)}) and
\begin{align*}
A_{0}(L)= & \int_{\mathbb{R}\setminus[-L,L]}\big|v(x)f(x)\big|dx\\
A_{1}(L)= & \left\Vert f-f_{L}\right\Vert _{2}\\
A_{2}(L,N)= & \big\Vert f_{L}-\sideset{}{'}\sum_{k=0}^{N}a_{k}e_{k}\big\Vert_{2}.
\end{align*}
We will state upper bounds for $A_{0}$, $A_{1}$ and $B_{f}$ depending
on the tail behaviour of $f$, i.e., for the different cases i) and
ii) in Theorem \ref{thm:asy}. An upper bound for $A_{2}$ can be
obtained from Lemma \ref{lem:A2}. Note that 
\[
\|v_{L}\|_{2}\leq\sqrt{2L}K=\sqrt{2\gamma}KN^{\frac{\beta}{2}}.
\]
We now prove (i). For $L$ large enough, we have
\[
A_{0}(L)\leq2KC_{1}\int_{L}^{\infty}e^{-C_{2}x}dx=\frac{2KC_{1}}{C_{2}}e^{-C_{2}L}.
\]
Further, by Inequality (\ref{eq:A1_semi}), it holds that
\begin{align*}
A_{1}(L) & \leq\frac{C_{1}}{\sqrt{C_{2}}}e^{-C_{2}L}.
\end{align*}
Assuming $L\geq1$ and applying Inequality (\ref{eq:B(L)_semi}),
it follows that 
\begin{align*}
\sqrt{B_{f}(L)}\leq & \frac{2\pi C_{1}}{\sqrt{6C_{2}}}\sqrt{1+\frac{1}{C_{2}}+\frac{1}{2C_{2}^{2}}}e^{-C_{2}L}.
\end{align*}
\begin{comment}
\#checked numerically

C1=rexp(1)

C2=rexp(1)

L=rexp(1)

tmp=function(x)\{4/3{*}pi\textasciicircum 2{*}C1\textasciicircum 2/L\textasciicircum 2{*}x\textasciicircum 2{*}exp(-2{*}C2{*}x)\}

sqrt(integrate(tmp,L,Inf)\$value)

2{*}pi{*}C1/sqrt(6{*}C2){*}exp(-C2{*}L){*}sqrt(1+1/(L{*}C2)+1/(2{*}L\textasciicircum 2{*}C2\textasciicircum 2))
\end{comment}
Inequality (\ref{eq:trun_error}) implies 
\begin{align*}
A_{2}(L,N) & \leq\sum_{j=1}^{J}\frac{2^{j+1}}{j\pi^{j+1}}\frac{L^{j}}{N^{j}}\left(2C_{1}C_{2}^{j}e^{-C_{2}L}\right)+\frac{2^{J+2}\left\Vert f^{(J+1)}\right\Vert _{\infty}}{J\pi^{J+1}}\frac{L^{J+1}}{N^{J}}\\
 & \leq e^{-C_{2}L}\sum_{j=1}^{J}\frac{2^{j+2}C_{1}C_{2}^{j}\gamma^{j}}{j\pi^{j+1}}+\frac{2^{J+2}\left\Vert f^{(J+1)}\right\Vert _{\infty}}{J\pi^{J+1}}\frac{L^{J+1}}{N^{J}},
\end{align*}
where we used $\frac{L}{N}\leq\gamma$. 

Let $b_{1},...,b_{4}>0$ be suitable constants. By Inequality (\ref{eq:asy_sum}),
it follows for $N$ large enough that
\begin{align}
\Big|\int_{\mathbb{R}}v(x)f(x)dx-\sideset{}{'}\sum_{k=0}^{N}c_{k}^{L}v_{k}^{M}\Big|\leq & b_{1}e^{-C_{2}\gamma N^{\beta}}+b_{2}N^{\frac{\beta}{2}}\big(b_{3}e^{-C_{2}\gamma N^{\beta}}+b_{4}N^{\beta(J+1)-J}\big)\nonumber \\
\leq & O\left(N^{-J(1-\beta)+\frac{3}{2}\beta}\right),\quad N\to\infty.\label{eq:asy_cos_semi}
\end{align}
$\beta<\frac{2J}{2J+3}$ implies $-J(1-\beta)+\frac{3}{2}\beta<0$
and the right-hand side of (\ref{eq:asy_cos_semi}) converges to zero
for $N\to\infty$. 

We show (ii). It holds for $L$ large enough that
\begin{align*}
A_{0}(L) & \leq2KC_{3}\int_{L}^{\infty}x^{-1-\alpha}dx\leq\frac{2KC_{3}}{\alpha}L^{-\alpha},\\
A_{1}(L) & \leq\sqrt{2C_{3}^{2}\int_{L}^{\infty}x^{-2(1+\alpha)}dx}=\sqrt{\frac{2C_{3}^{2}}{1+2\alpha}}L^{-\frac{1}{2}-\alpha}
\end{align*}
\begin{comment}
\#checked numerically

C3=rexp(1)

alpha=rexp(1)

L=rexp(1)

tmp=function(x)\{2{*}C3\textasciicircum 2{*}x\textasciicircum (-2{*}(1+alpha))\}

sqrt(integrate(tmp,L,Inf)\$value)

sqrt(2{*}C3\textasciicircum 2/(1+2{*}alpha)){*}L\textasciicircum (-0.5-alpha)
\end{comment}
and, using Inequality (\ref{eq:B(L)_stable}),
\begin{align*}
\sqrt{B_{f}(L)} & \leq2C_{3}\sqrt{\frac{1}{\alpha^{2}}+\frac{2}{3}}L^{-\frac{1}{2}-\alpha}.
\end{align*}
Inequality (\ref{eq:trun_error}) implies %
\begin{comment}
\begin{align*}
A_{2}(L,N) & \leq\sum_{j=1}^{J}\frac{2^{j+1}}{j\pi^{j+1}}\frac{L^{j}}{N^{j}}\left(|f^{(j)}(-L)|+|f^{(j)}(L)|\right)+\frac{2^{J+2}H_{J+1}}{J\pi^{J+1}}\frac{L^{J+1}}{N^{J}}\\
 & \leq\sum_{j=1}^{J}\frac{2^{j+1}}{j\pi^{j+1}}\frac{L^{j}}{N^{j}}\left(2C_{3}L^{-1-\alpha-j}\right)+\frac{2^{J+2}H_{J+1}}{J\pi^{J+1}}\frac{L^{J+1}}{N^{J}}\\
 & \leq\sum_{j=1}^{J}\frac{2^{j+1}}{j\pi^{j+1}}\frac{\gamma^{j}N^{\beta j}}{N^{j}}\left(2C_{3}\gamma^{-1-\alpha-j}N^{\beta(-1-\alpha-j)}\right)+\frac{2^{J+2}H_{J+1}}{J\pi^{J+1}}\frac{L^{J+1}}{N^{J}}\\
 & \leq\sum_{j=1}^{J}\frac{2^{j+2}}{j\pi^{j+1}}C_{3}\gamma^{-1-\alpha}N^{\beta(-1-\alpha)-j}+\frac{2^{J+2}H_{J+1}}{J\pi^{J+1}}\frac{L^{J+1}}{N^{J}}.
\end{align*}
\end{comment}
\begin{align*}
A_{2}(L,N) & \leq\sum_{j=1}^{J}\frac{2^{j+2}}{j\pi^{j+1}}C_{3}\gamma^{-1-\alpha}N^{\beta(-1-\alpha)-j}+\frac{2^{J+2}\left\Vert f^{(J+1)}\right\Vert _{\infty}}{J\pi^{J+1}}\frac{L^{J+1}}{N^{J}}.
\end{align*}
Hence, by Inequality (\ref{eq:asy_sum}), it follows for $N$ large
enough and some suitable constants $b_{1},...,b_{4}>0$ and $a_{1},...,a_{J}>0$
that
\begin{align*}
 & \Big|\int_{\mathbb{R}}v(x)f(x)dx-\sideset{}{'}\sum_{k=0}^{N}c_{k}v_{k}\Big|\\
 & \leq b_{1}N^{-\alpha\beta}+b_{2}N^{\frac{\beta}{2}}\bigg(b_{3}N^{-\beta(\alpha+\frac{1}{2})}+\sum_{j=1}^{J}a_{j}N^{\beta(-1-\alpha)-j}+b_{4}N^{\beta(J+1)-J}\bigg)\\
 & \leq b_{1}N^{-\alpha\beta}+b_{2}\bigg(b_{3}N^{-\beta\alpha}+\sum_{j=1}^{J}a_{j}N^{-\beta(\alpha+\frac{1}{2})-j}+b_{4}N^{\beta\left(J+\frac{3}{2}\right)-J}\bigg)\\
 & \leq O\left(N^{-\alpha\beta}\right),\quad N\to\infty.
\end{align*}
The last inequality can be seen as follows: as $0<\beta$, we have
\[
-\beta\alpha\geq-\beta\big(\alpha+\frac{1}{2}\big)-j,\quad j=1,...,J.
\]
Further, as $\beta\leq\frac{J}{J+\frac{3}{2}+\alpha}$, it follows
that
\[
-\alpha\beta\geq\beta(J+\frac{3}{2})-J.
\]
\end{proof}
\begin{rem}
The COS method converges exponentially, i.e., faster than $O(N^{-q})$
for any $q>0$ if $f$ is smooth and has semi-heavy tails. To see
this, let $0<\beta<1$: then,
\[
-J(1-\beta)+\frac{3}{2}\beta\to-\infty,\quad J\to\infty.
\]
\end{rem}

\begin{rem}
By Theorem \ref{thm:find_N_C}, the COS method converges at least
like $N^{-\alpha}$ if $f$ is smooth and has heavy tails with Pareto
index $\alpha>0$. Numerical experiments indicate that the COS method
does not converge faster than $O(N^{-\alpha})$ for the FMLS model,
see Section \ref{subsec:Convergence-Rate}, i.e., the bound in Theorem
\ref{thm:find_N_C}(ii) is sharp.
\end{rem}


\section{\label{sec:Greeks-by-the}Greeks by the COS method}

The \emph{Greeks }or \emph{sensitivities }of a European option play
an important role in hedging and risk management. The most important
Greeks are Delta and Gamma, which are the first and second derivative
of the price of a European option with respect to the current underlying
price $S_{0}>0$. 

Without proof, \citet[Rem. 3.2]{fang2009novel} states formulas for
the approximation of Delta and Gamma by the COS method. In this section,
we proof these formulas and discuss how to choose $M$, $L$ and $N$
for the Greeks. 

In this section we assume $S_{t}=S_{0}\bar{S}_{t}$ for some stochastic
process $(\bar{S}_{t})_{t\geq0}$, which does not depend on $S_{0}$
anymore. This assumption is a very typical one, see \citet[Sec. 3.1.2]{madan2016applied}.
As in Section \ref{sec:Overview:-the-COS}, we consider a European
option with maturity $T>0$ and payoff $g(S_{T})$ for some $g:[0,\infty)\to\mathbb{R}$.
Let $\eta:=E[\log(S_{T})]-\log(S_{0})$. Then $\eta$ does not depend
on $S_{0}$. Define

\begin{equation}
v(x,s):=e^{-rT}g(\exp(x+\log(s)+\eta)),\quad x\in\mathbb{R},\quad s>0.\label{eq:v_Greek}
\end{equation}
The price of the European option is then given by
\begin{align*}
e^{-rT}E[g(S_{T})] & =\int_{\mathbb{R}}v(x,S_{0})f(x)dx.
\end{align*}
As before, $f$ is the density of the centralized log-returns. Delta
and Gamma are defined by
\begin{equation}
\frac{\partial^{\ell}}{\partial S_{0}^{\ell}}\int_{\mathbb{R}}v(x,S_{0})f(x)dx,\quad\ell=1,2\label{eq:DeltaGamma}
\end{equation}
if the partial derivatives exist. \textcolor{gray}{}%
\begin{comment}
\textcolor{gray}{Remove later?? A function is called }\textcolor{gray}{\emph{integrable}}\textcolor{gray}{{}
if it is Lebesgue integrable}
\begin{lem}
\textcolor{gray}{Let I be an interval of $\mathbb{R}$. Let $h:\mathbb{R}\times I\to\mathbb{R}$
such that}

\textcolor{gray}{a) $x\mapsto h(x,s)$ is integrable for all $s\in I$,}

\textcolor{gray}{b) $\frac{\partial}{\partial s}h(x,s)$ exists for
all $(x,s)\in\mathbb{R}\times I$,}

\textcolor{gray}{c) There is an integrable function $m:\mathbb{R}\to[0,\infty)$
such that
\[
\left|\frac{\partial}{\partial s}h(s,x)\right|\leq m(x),\quad(x,s)\in\mathbb{R}\times I.
\]
Then the function
\begin{align*}
F(s) & =\int_{\mathbb{R}}h(x,s)dx,\quad s\in I.
\end{align*}
is differentiable for all $s\in I$, and it holds that
\[
F^{\prime}(s)=\int_{\mathbb{R}}\frac{\partial}{\partial s}h(x,s)dx,\quad s\in I.
\]
}
\end{lem}

\begin{proof}
\textcolor{gray}{Lemma 2.8 in Grubb.}
\end{proof}
\end{comment}
The next lemma provides some conditions to interchange integration
and differentiation in Equation (\ref{eq:DeltaGamma}).
\begin{lem}
\label{lem:diff_lemma}Let $g$ be bounded. Let $v$ be defined as
in Equation (\ref{eq:v_Greek}). Assume $J\in\mathbb{N}_{0}$ and
$f$ satisfies Assumption \ref{A1}. It follows that

\begin{equation}
\frac{\partial}{\partial S_{0}}\int_{\mathbb{R}}v(x,S_{0})f(x)dx=-\frac{1}{S_{0}}\int_{\mathbb{R}}v(x,S_{0})f^{(1)}(x)dx\label{eq:delta_interchange}
\end{equation}
and if $J\geq1$
\begin{equation}
\frac{\partial^{2}}{\partial S_{0}^{2}}\int_{\mathbb{R}}v(x,S_{0})f(x)dx=\frac{1}{S_{0}^{2}}\int_{\mathbb{R}}v(x,S_{0})\big(f^{(1)}(x)+f^{(2)}(x)\big)dx.\label{eq:gamma_interchange}
\end{equation}
\end{lem}

\begin{proof}
Let $\underline{s},\overline{s}\in\mathbb{R}$ such that $0<\underline{s}<S_{0}<\overline{s}$.
Let $h(x,s):=f(x-\log(s))$. Then $x\mapsto h(x,s)$ is integrable
for all $s\in(\underline{s},\overline{s})$ and the partial derivative
\[
\frac{\partial}{\partial s}h(x,s)=-\frac{1}{s}f^{(1)}(x-\log(s))
\]
exists for all $(x,s)\in\mathbb{R}\times(\underline{s},\overline{s})$.
Define $x_{0}:=L_{0}+|\log(\overline{s})|+|\log(\underline{s})|$.
Then,
\[
|x-\log(s)|\geq L_{0},\quad(x,s)\in\mathbb{R}\setminus[-x_{0},x_{0}]\times(\underline{s},\overline{s}).
\]
Let
\begin{align*}
m(x) & :=\begin{cases}
\underline{s}^{-1}\left\Vert f^{(1)}\right\Vert _{\infty} & ,x\in[-x_{0},x_{0}]\\
\underline{s}^{-C_{2}-1}C_{1}C_{2}e^{C_{2}x} & ,x<-x_{0}\\
\underline{s}^{-1}\overline{s}^{C_{2}}C_{1}C_{2}e^{-C_{2}x} & ,x>x_{0}.
\end{cases}
\end{align*}
\begin{comment}
Hints: consider the case $x>x_{0}$. Show $x-\log(s)\geq L_{0}>0$.
Use the bound for $f^{(1)}$.
\end{comment}
Then $|\frac{\partial}{\partial s}h(x,s)|\leq m(x)$ for all $(x,s)\in\mathbb{R}\times(\underline{s},\overline{s})$
and $x\mapsto m(x)$ is integrable. Then, interchanging differentiation
and integration is allowed by the dominated convergence theorem, see
e.g., \citet[Lemma 2.8]{grubb2008distributions}, and it follows that
\begin{align*}
\frac{\partial}{\partial S_{0}}\int_{\mathbb{R}}v(x,S_{0})f(x)dx & =\frac{\partial}{\partial S_{0}}\int_{\mathbb{R}}v(x,1)f(x-\log(S_{0}))dx\\
 & =-\frac{1}{S_{0}}\int_{\mathbb{R}}v(x,1)f^{(1)}(x-\log(S_{0}))dx\\
 & =-\frac{1}{S_{0}}\int_{\mathbb{R}}v(x,S_{0})f^{(1)}(x)dx.
\end{align*}
If $J\geq1$, $f$ is twice differentiable. Apply the arguments above
to $f^{(1)}$ to conclude.
\end{proof}
In Theorem \ref{thm:Greeks} we provide explicit formulas for $M$,
$N$ and $L$ when $f$ satisfies Assumption \ref{A1} to ensure that
the COS method approximates the price and the Greeks Delta and Gamma
within a predefined error tolerance $\varepsilon>0$. One can use
the same parameters $M$, $N$ and $L$ to obtain both the price and
the Greeks. 
\begin{thm}
\label{thm:Greeks}($M$, $L$ and $N$ for the price, Delta and Gamma).
Let $g$ be bounded. Let $v$ be defined as in Equation (\ref{eq:v_Greek}).
Let $\varepsilon>0$ be small enough. Let 
\[
\gamma=\varepsilon\land\varepsilon S_{0}\land\frac{\varepsilon S_{0}^{2}}{2}.
\]
Suppose $J\geq3$. Let $f$ be a density satisfying Assumption \ref{A1}.
For some even $n\in\mathbb{N}$ define
\begin{equation}
L=M=\sqrt[n]{\frac{2K\mu_{n}}{\gamma}},\label{eq:M-1}
\end{equation}
where $\mu_{n}$ is the $n^{th}-$moment of $f$, i.e.,
\[
\mu_{n}=\frac{1}{i^{n}}\left.\frac{\partial^{n}}{\partial u^{n}}\varphi(u)\right|_{u=0}.
\]
Let $\xi=\sqrt{2M}K$, $k\in\{1,...,J-2\}$ and
\begin{align}
N & \geq\left(\frac{2^{k+2}\left(\max_{\ell\in\{0,1,2\}}\left\Vert f^{(k+1+\ell)}\right\Vert _{\infty}\right)L^{k+1}}{k\pi^{k+1}}\frac{12\xi}{\gamma}\right)^{\frac{1}{k}}.\label{eq:N_J>0-1}
\end{align}
It follows that the price and the Greeks Delta and Gamma can be approximated
by the COS method, i.e.,
\begin{align*}
\bigg|\int_{\mathbb{R}}v(x,S_{0})f(x)dx-\sum_{k=0}^{N}{}^{\prime}c_{k}v_{k}\bigg| & \leq\varepsilon,\\
\bigg|\frac{\partial}{\partial S_{0}}\int_{\mathbb{R}}v(x,S_{0})f(x)dx-\bigg(-\frac{1}{S_{0}}\sum_{k=0}^{N}{}^{\prime}c_{k}^{1}v_{k}\bigg)\bigg| & \leq\varepsilon,\\
\bigg|\frac{\partial^{2}}{\partial S_{0}^{2}}\int_{\mathbb{R}}v(x,S_{0})f(x)dx-\frac{1}{S_{0}^{2}}\sum_{k=0}^{N}{}^{\prime}(c_{k}^{1}+c_{k}^{2})v_{k}\bigg| & \leq\varepsilon.
\end{align*}
\end{thm}

\begin{proof}
Theorem \ref{thm:find_N_A_B} ensures that the price can be approximated
by the COS method. By Lemma \ref{lem:diff_lemma} and Theorem \ref{thm:find_N_A_B},
it holds that
\begin{align*}
\bigg|\frac{\partial}{\partial S_{0}}\int_{\mathbb{R}}v(x,S_{0})f(x)dx & -\bigg(-\frac{1}{S_{0}}\sum_{k=0}^{N}{}^{\prime}c_{k}^{1}v_{k}\bigg)\bigg|\\
 & =\frac{1}{S_{0}}\left|\int_{\mathbb{R}}v(x,S_{0})f^{(1)}(x)dx-\sum_{k=0}^{N}{}^{\prime}c_{k}^{1}v_{k}\right|\\
 & \leq\frac{\gamma}{S_{0}}\leq\varepsilon.
\end{align*}
Using the triangle inequality, we can see that
\begin{align*}
\bigg|\frac{\partial^{2}}{\partial S_{0}^{2}}\int_{\mathbb{R}}v(x,S_{0})f(x)dx & -\frac{1}{S_{0}^{2}}\sum_{k=0}^{N}{}^{\prime}(c_{k}^{1}+c_{k}^{2})v_{k}\bigg|\\
= & \frac{1}{S_{0}^{2}}\bigg|\int_{\mathbb{R}}v(x,S_{0})\big(f^{(1)}(x)+f^{(2)}(x)\big)dx-\sum_{k=0}^{N}{}^{\prime}(c_{k}^{1}+c_{k}^{2})v_{k}\bigg|\\
\leq & \frac{1}{S_{0}^{2}}\bigg(\bigg|\int_{\mathbb{R}}v(x,S_{0})f^{(1)}(x)dx-\sum_{k=0}^{N}{}^{\prime}c_{k}^{1}v_{k}\bigg|\\
 & +\bigg|\int_{\mathbb{R}}v(x,S_{0})f^{(2)}(x)dx-\sum_{k=0}^{N}{}^{\prime}c_{k}^{2}v_{k}\bigg|\bigg)\\
\leq & \frac{2\gamma}{S_{0}^{2}}\leq\varepsilon.
\end{align*}
\end{proof}

\section{\label{sec:Numerical-experiments}Numerical experiments}

All numerical experiments are compared with the Carr-Madan formula,
see \cite{carr1999option}, which is applicable when the characteristic
function of the log-returns is given in closed form and when $E[S_{T}^{1+\gamma}]$
is finite for some $\gamma>0$, which is the \emph{damping factor}.
Unless otherwise stated, we use the Carr-Madan formula with $N=2^{17}$
terms, we set the damping factor equal to $\gamma=0.1$ and we use
a Fourier truncation range of $1200$ to compute the reference prices.
We implemented the Carr-Madan formula using Simson's rule without
applying the fast Fourier transform.

All numerical experiments were performed on a modern laptop (Intel
i7-10750H) using the software R and vectorized code without parallelization.

\subsection{\label{subsec:BS-model}BS model}

How sharp is the bound for $N$ in Theorem \ref{thm:find_N_A_B} and
Theorem \ref{thm:Greeks}? We make the following experiment. Consider
a put option with parameters:
\[
\varepsilon=10^{-8},\quad\sigma=0.2,\quad T=1,\quad S_{0}=K=100,\quad r=0.
\]
We used $n=8$ moments to obtain $M=L=6.94$ by Equation (\ref{eq:M-1}).
We set $k=40$ to obtain $N=179$ by Inequality (\ref{eq:N_J>0-1}).
Other values for $k$ and $N$ are reported in Table \ref{tab:BS}.
Theorem \ref{thm:Greeks} indicates that $M,$ $L$ and $N$ serves
to approximate both the price and the Greeks Delta and Gamma using
the COS method. This can be confirmed by an experiment: $N_{\min}=120$
is the minimal number of terms such that the absolute differences
of the approximation by the COS method and the closed form solution
by the Black-Scholes formula for price, Delta and Gamma; are less
than the error tolerance. $N$ is only about $40\%$ larger than $N_{\min}$. 

How can the number of terms $N$ be estimated if there are no closed
form solutions available for the bounds of the derivatives of the
density of the log-returns? We suggest solving the right-hand side
of Inequality (\ref{eq:H_j}) numerically to find a bound for $\|f^{(k+1)}\|_{\infty}$.
Here, we use R's \emph{integrate} function with default values. The
CPU time of the COS method and the numerical integration routine to
obtain a bound for $\|f^{(k+1)}\|_{\infty}$ are of similar magnitude:
see Table \ref{tab:BS}. 

The value of $N$ does not change when using numerical integration
to obtain a bound for $\|f^{(k+1)}\|_{\infty}$ compared to the closed
form solution for the bound of $\|f^{(k+1)}\|_{\infty}$ from Example
\ref{exa:Gauss}. In this example, $k=40$ works well. We will also
use $k=40$ in Section \ref{subsec:FMLS-model}.

\begin{table}[H]
\begin{centering}
\begin{tabular}{|>{\centering}p{4cm}|c|c|c|c|c|c|c|}
\hline 
$k$ & 10 & 20 & 30 & 40 & 50 & 60 & 70\tabularnewline
\hline 
$N$  & 897 & 271 & 200 & 179 & 172 & 170 & 171\tabularnewline
\hline 
CPU time COS method & 0.18 & 0.09 & 0.09 & 0.07 & 0.08 & 0.07 & 0.08\tabularnewline
\hline 
CPU time numeric integration for $\|f^{(k+1)}\|_{\infty}$ & 0.15 & 0.09 & 0.09 & 0.10 & 0.09 & 0.10 & 0.09\tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:BS}Approximation of the price of a put option by the COS
method: $N$ depending on $k$ by Inequality (\ref{eq:N_J>0}). CPU
time is measured in milliseconds. The COS method with $N_{\min}=120$
takes about 0.068 milliseconds. }
\end{table}


\subsection{\label{subsec:VG-model}VG model}

Using the VG model as an example, this section shows that Theorem
\ref{thm:find_N_A_B} does not help in finding the number of terms
$N$ for the COS method if the density of the log-returns is not sufficiently
smooth. 

Let $f_{\text{VG}}$ denote the density of the log-returns in the
VG model at maturity $T>0$ with parameters $\sigma>0$, $\theta=0$
and $\nu>0$. If $T<\frac{\nu}{2}$, the density $f_{\text{VG}}$
is unbounded and Theorem \ref{thm:find_N_A_B} cannot be used to find
$N$. If $T\in\left(\nu,\frac{3\nu}{2}\right)$, the derivative of
$f_{\text{VG}}$ is continuous, but the second derivative of $f_{\text{VG}}$
is unbounded, see \citet[Thm. 4.1 and Thm. 6.1]{kuchler2008shapes}. 

We can apply Theorem \ref{thm:find_N_A_B} with $J=0$ if $T\in\left(\nu,\frac{3\nu}{2}\right)$,
but the value for $N$ is somewhat useless from a practical point
of view, as the following experiment shows: Consider a European call
option with the following parameters: 
\[
\varepsilon=0.01,\quad\sigma=0.1,\quad\nu=0.2,\quad T=0.25,\quad S_{0}=K=100,\quad r=0.
\]
By Equation (\ref{eq:M}), we set $L=0.91$ using $n=4$ moments.
By numerically optimizing the derivative of the density $f_{\text{VG}}$,
we obtain $\|f^{(1)}\|_{\infty}=218$, and Theorem \ref{thm:find_N_A_B}
suggests $N\approx8\cdot10^{12}$. 

We calculated a reference price $\pi_{CM}=1.809833$ using the Carr-Madan
formula. Using the COS method, $N=50$ is already sufficient to approximate
the reference price within the error tolerance. 

\subsection{\label{subsec:FMLS-model}FMLS model}

In this section, we consider the FMLS model with parameters $\alpha\in(1,2)$
and $\sigma>0$ at maturity $T>0$. Recall that the centralized log-returns
at time $T>0$ have heavy tails and are stably distributed with stability
parameter $\alpha$, skewness $\beta=-1$, scale $c=\sigma T^{\frac{1}{\alpha}}$
and location $\theta=0$. 

\cite{carr2003finite} calibrated the FMLS model to real market data
and estimated $\alpha=1.5597$ and $\sigma=0.1486$. We test the formulas
for $L$ and $N$ for the FMLS model with these parameters for a European
call option with the following parameters: 
\[
\varepsilon=10^{-2},\quad T=1,\quad S_{0}=K=100,\quad r=0.
\]
The reference price is 9.7433708 by the Carr-Madan formula, and we
confirm the reference price by the COS method with $L=10^{5}$ and
$N=10^{7}$. 

Motivated by Example \ref{exa:C3}, we suggest setting the variable
$C_{3}$ in Equation (\ref{eq:M_stable}) to
\[
C_{3}:=\alpha\frac{1-\alpha}{\Gamma(2-\alpha)\cos\big(\frac{\pi\alpha}{2}\big)}\sigma^{\alpha}T.
\]
 Figure \ref{fig:Density-of-FMLS} shows the density of the log-returns
in the FMLS model and asymptotic tail behavior, i.e., the function
$x\mapsto C_{3}|x|^{-1-\alpha}$. The left tail does indeed decay
like Pareto tails and the asymptotic tail behavior is very close to
the density. The right tail decays faster; in fact it decays exponentially,
see \cite{carr2003finite}.

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.38]{FMLS_dens}
\par\end{centering}
\caption{\label{fig:Density-of-FMLS}Density of the log-returns in the FMLS
model and asymptotic tail behavior.}
\end{figure}

To apply the COS method we define $M=69$ and $L=176$, as in Equations
(\ref{eq:M_stable}) and (\ref{eq:L_stable}). We set $N=5451$, using
Example \ref{exa:FMLS} and Inequality (\ref{eq:N_stable}) with $k=40$.
According to Theorem \ref{thm:find_N_C}, any other choice for $k$
is possible, but another value for $k$ does not significantly improve
$N$.

With these parameters, the COS method prices the call option within
the error tolerance in about 1.5 milliseconds. The minimal $N$ to
stay below the error tolerance is $N_{\min}=1200$ and the CPU time
using $N_{\min}$ is about 0.4 milliseconds. 

We also apply the Carr-Madan formula with the ``default parameters'',
see \cite{carr1999option}, which are also recommended by \citet[Sec. 3.1]{madan2016applied},
i.e., $4096$ terms, a damping factor equal to $1.5$ and a Fourier
truncation range of $1024$. With these default parameters, the Carr-Madan
formula prices the option within the error tolerance in about 1.1
milliseconds. We also implemented the Carr-Madan formula using the
fast Fourier transform but we found no speed advantage, compare also
with \cite{crisostomo2018speed}.

The value for the CPU time is about three times higher when using
Theorem \ref{thm:find_N_C} to get $N$ compared to the optimized
value for $N$, which is acceptable from our point of view. The computational
time of the COS method using Theorem \ref{thm:find_N_C} and that
of the Carr-Madan formula with standard parameters are of similar
magnitude. 

\subsection{\label{subsec:Convergence-Rate}Order of Convergence}

In this section, we empirically analyze the order of convergence of
the COS method for the BS model with parameter $\sigma>0$ and the
FMLS model with parameters $\alpha\in(1,2)$ and $\sigma>0$ and compare
the results with Theorem \ref{thm:asy}. 

The order of convergence in (\ref{eq:order of con}) can be estimated
straightforwardly by a simulation, see \cite{leisen1996binomial}.
As 
\[
\log\left(\frac{\kappa}{N^{\rho}}\right)=\log(\kappa)-\rho\log(N),
\]
the negative slope of a straight line obtained from a log-log plot
of the errors $\text{err}(L(N),N)$ against $N$ can be used as an
indicator for $\rho$.

\subsubsection{Black-Scholes Model}

In the BS model, the density of the log-returns is arbitrarily smooth,
and the tails decay even faster than exponentially. In Figure \ref{fig:Convergence-rate-BS}
we analyze how the error of the COS method behaves in the BS model
for large $N$ and for different choices of $L$. 

In particular, we see in Figure \ref{fig:Convergence-rate-BS} that
the COS method seems to converge exponentially at the beginning for
moderate $N$ if we choose $L$ constant, i.e., independent of $N$.
But for constant $L$, e.g., $L=4\sigma$ or $L=6\sigma$, the COS
method does not converge for $N\to\infty$ but the error remains constant
for a certain level of $N$. This can be explained by Inequality (\ref{eq:error_bound}):
While the second term on the right-hand side of Inequality (\ref{eq:error_bound})
converges to zero for $N\to\infty$ and $L$ fixed, the first and
third terms on the right-hand side of Inequality (\ref{eq:error_bound})
do not improve as $N$ is increased but $L$ is kept constant.

\begin{figure}[H]
\begin{centering}
\includegraphics[scale=0.38]{BS_convergence_rate}
\par\end{centering}
\caption{\label{fig:Convergence-rate-BS}Order of convergence of the COS method
for a call option in the BS model with different choices for the truncation
range $[-L,L]$.}
\end{figure}

For large $L$, such as $L=20\sigma$, this effect disappears somewhat
because the tails of the Gaussian distribution decay so rapidly that,
up to fixed-precision arithmetic\footnote{The software package R operates with a precision of 53 bits conforming
to the IEC 60559 standard, see R Core Team (2021). R: A language and
environment for statistical computing. R Foundation for Statistical
Computing, Vienna, Austria. URL https://www.R-project.org/.}, the Gaussian density can be thought of as a density with finite
support. Using arbitrary-precision arithmetic instead should show
that even for $L=20\sigma$, the error of the COS method does not
converge to zero for $N\to\infty$. 

If we choose $L=L(N)=\sigma\sqrt{N}$, Theorem \ref{thm:asy}(i) indicates
that the error of the COS method converges exponentially to zero.
This is confirmed empirically in Figure \ref{fig:Convergence-rate-BS}.
Other choices for $L$ also work well, e.g., $L=\frac{\sigma}{5}N$. 

\subsubsection{FMLS model}

We test Theorem \ref{thm:asy}(ii) for the density of the log-returns
in the FMLS model, which belongs to the family of stable densities
and has heavy tails. For the FMLS model we use the parameters $\alpha=1.5597$
and $\sigma=0.1486$: these values are taken from \cite{carr2003finite},
who calibrated the FMLS model to real market data. We use the same
reference price for the price of a European call option with maturity
$T=1$, $S_{0}=K=100$ and $r=0$ as in Section \ref{subsec:FMLS-model}.

\selectlanguage{american}%
\begin{figure}[H]
\selectlanguage{english}%
\begin{centering}
\includegraphics[scale=0.38]{FMLS_convergence_rate}
\par\end{centering}
\selectlanguage{american}%
\caption{\foreignlanguage{english}{\label{fig:Order-of-convergence}Order of convergence of the COS method
with different choices for the truncation range $[-L,L]$\foreignlanguage{american}{
for the }FMLS model.}}
\end{figure}

\selectlanguage{english}%
We compute $L_{\text{optimal}}$ for a fixed $N\in\mathbb{N}$ minimizing
$\text{err}(L,N)$, i.e. for each $N$ we choose the truncation range
such that the error of the COS method is minimal, compare with Equation
(\ref{eq:errCOS}). In particular, for each $N\in\{2^{i},\,i=4,5,...,20\}$
we define
\[
L_{\text{optimal}}(N):=\text{argmin}_{L\in\mathbb{L}}\text{err}(L,N),
\]
where 
\[
\mathbb{L}=\{\exp(0.07i),\,i=0,1,...,200\},
\]
is a sufficiently fine grid of the interval $[1,10^{6}]$. 

In Figure \ref{fig:Order-of-convergence}, we compute the order of
convergence of the COS method for different strategies to define $L$.
If $L$ is constant, the COS method does not converge at all. 

For the FMLS model the empirical order of convergence is $1.57$,
i.e., the error behaves like $O(N^{-1.57})$ for large $N$ if we
choose $L=\frac{1}{100}N$, which is very close to its theoretical
bound of $O(N^{-1.5597})$, and does not differ much if we use $L_{\text{optimal}}$
instead. 

In particular, the numerical experiments indicate that the order of
convergence is not exponential for heavy tail models even though the
corresponding densities are arbitrarily smooth. In Figure \ref{fig:Order-of-convergence}
we also plot the empirical order of convergence of the Carr-Madan
formula for the FMLS model with damping factor of $0.7$ and a Fourier
truncation range of $1200$. The Figure indicates an exponential order
of convergence for the Carr-Madan formula.


\section{\label{sec:Conclusions}Conclusions}

In this research we analyzed the COS method, which is used for efficient
option pricing. The sensitivities, i.e., the Greeks, can also be efficiently
approximated. The COS method requires two parameters: the truncation
range $[-L,L]$ to truncate the density of the log-returns and the
number of terms $N$ to approximate the truncated density by cosine
functions. We considered stock price models where the density of the
log-returns is smooth and has either semi-heavy tails, i.e., the tails
decay exponentially or faster, or heavy tails, i.e., Pareto tails. 

In both cases, we found explicit and useful bounds for $L$ and $N$
and showed in numerical experiments the usefulness of these formulas
in applications to obtain the price of an option and the Greeks Delta
and Gamma. The densities of the log-returns are smooth for many models
in finance, such as the BS, NIG, Heston and FMLS models.

If the density is not differentiable, neither Theorem \ref{thm:find_N_A_B}
nor \ref{thm:find_N_C} can be used to find a bound for $N$. If the
density is only differentiable a few times, which is the case for
the VG model for some parameters and short maturities, our bound for
$N$ is too large to be useful in most practical applications. A solution
might be to use the NIG model instead of the VG model. Both are flexible,
three-parameter Lévy models.

We further analyzed the order of convergence of the COS method and
observed both theoretically and empirically that the models enjoy
exponential convergence when the densities of the log-returns are
smooth and have semi-heavy tails. However, when the density of the
log-returns is smooth and has \emph{heavy} \emph{tails}, the error
of the COS method can be bounded by $O(N^{-\alpha})$, where $\alpha>0$
is the Pareto tail index. This is the case, for example, for the FMLS
model where $\alpha\in(1,2)$. Numerical experiments indicate that
the bound $O(N^{-\alpha})$ is sharp.

\bibliographystyle{plainnat}
\bibliography{biblio}

\end{document}
