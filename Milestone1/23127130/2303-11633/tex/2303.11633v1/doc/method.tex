\section{Our Method}
\label{sec:method}

\subsection{Motivation}
A generic deep model can be deemed as a composition of two modules: 1) feature generator $\mathcal{G}$ and 2) classifier $\mathcal{C}$. The feature generator $\mathcal{G}$ receives the input image $x$ and projects it into high-dimensional feature $\vec{f} \in \mathcal{R}^{[hw \times d]}$ where $h$, $w$ and $d$ denote the height, width and dimension number of the feature $\vec{f}$, respectively. Necessary contextual information is enriched in the extracted feature by the feature generator, ensuring the classifier $\mathcal{C}\in \mathcal{R}^{[n \times d]}$ can make prediction $\vec{p}\in \mathcal{R}^{[hw \times n]}$ for $n$ classes on different positions individually. Put differently, the aforementioned process implies that the classifier should serve as a feature descriptor whose weights are used as decision boundaries in the high-dimensional feature space, decently describing the feature distribution and making the judgment, \ie, pixel-wise predictions.

However, images for semantic segmentation usually have distinct contextual hints, thus we conjecture that using the universal feature descriptor, \ie, classifier, shared by all testing samples might not be the optimal choice for parsing local details for the individual ones. This inspires us to explore a feasible way by which the classifier becomes ``context-aware'' to different samples, improving the performance but keeping the structure of the feature generator intact, as abstracted in Figure~\ref{fig:overview}. 

\begin{figure}[!t]
	\centering
	\begin{minipage}   {0.95\linewidth}
		\centering
		\includegraphics [width=0.95\linewidth,height=0.65\linewidth]
		{figure/cac-1.pdf}
	\end{minipage}     
	%\vspace{-0.2cm}
	\caption{Comparison between (a) the vanilla and (b) our proposed pipelines. }
	\label{fig:overview}
\end{figure}

\subsection{Is Context-Aware Classifier Necessary? }
\label{sec:oracle_case}
With an eye towards enriching contextual cues to the classifier, essential information should be mined from the extracted features. To verify the hypothesis that the proposed context-aware classifier is conducive to the model performance, we start with a case study regarding the oracle situation where the contextual information is exactly enriched with the guidance of ground-truth annotation that can offer precise contextual prior.

Specifically, given the extracted feature map $\vec{f} \in \mathcal{R}^{[hw \times d]}$ and the vanilla classifier $\mathcal{C}\in \mathcal{R}^{[n \times d]}$ of $n$ classes, the pixel-wise ground-truth annotation $\vec{y} \in \mathcal{R}^{[hw]}$ can be accordingly transformed into $n$ binary masks $\vec{y}_{*} \in \mathcal{R}^{[n \times hw]}$ 
indicating the existence of $n$ classes in $\vec{y}$. 
Then, we can obtain the categorical prototypes $\mathcal{C}_y \in \mathcal{R}^{[n, d]}$ by applying masked average pooling (MAP) with $\vec{y}_{*}$ and $\vec{f}$:
\begin{equation}
    \label{eq:oracle_proto}
    \mathcal{C}_y = \frac{\vec{y}_{*} \times \vec{f}}{\sum_{j=1}^{hw} \vec{y}_{*}(\cdot, j)}.
\end{equation}
Then, the oracle context-aware classifier $\mathcal{A}_{y} \in \mathcal{R}^{[n, d]}$ is yielded by taking the merits from both $\mathcal{C}_y$ and $\mathcal{C}$  with a light-weight projector $\theta_y$ that is composed of two linear layers. This process can be expressed as
\begin{equation}
    \label{eq:oracle_cls}
    \mathcal{A}_y = \theta_y(\mathcal{C}_y \oplus \mathcal{C}),
\end{equation}
where $\oplus$ denotes the concatenation on the second dimension. An alternative choice is simply adding $\mathcal{C}_y$ and $\mathcal{C}$, while experimental results in Table~\ref{tab:ablation_alternative_designs} show that concatenation with projection leads to better performance. Finally, the prediction $\vec{p}_{y}$ obtained with the oracle context-aware classifier $\mathcal{A}_y$ is yielded as:
\begin{equation}
    \label{eq:oracle_pred}
    \vec{p}_{y} = \tau \cdot \eta(\vec{f}) \times \eta(\mathcal{A}_y)^\top,
\end{equation}
where $\eta$ is the L-2 normalization operation along the second dimension, thus Eq.~\eqref{eq:oracle_pred} is calculating the cosine similarities. $\tau$ scales the output value range from [-1,1] to [-$\tau$, $\tau$], so that $\vec{p}_{y}$ can be decently optimized by the standard cross-entropy loss. We empirically set $\tau$ to 15 in experiments. The necessity of cosine similarity and sensitivity analysis regarding  $\tau$ are discussed in Section~\ref{sec:ablation_study}. 



\begin{figure}[!t]
	\centering     
    \begin{minipage}   {0.49\linewidth}
        \centering
        \includegraphics [width=1\linewidth,height=0.8\linewidth]
        {figure/compare_train_miou_larger_crop.jpg}
    \end{minipage} 
    \begin{minipage}   {0.49\linewidth}
        \centering
        \includegraphics [width=1\linewidth,height=0.8\linewidth]
        {figure/compare_miou_larger_crop.jpg}
    \end{minipage}    
	%\vspace{-0.2cm}
	\footnotesize
	\caption{Visual comparison between \textit{train} (left) and \textit{val} (right) mIoU curves. Results are obtained with UperNet+Swin-Tiny~\cite{upernet,swin} on ADE20K~\cite{ade20k}. }
	\label{fig:tsne_vis}
	%\vspace{-0.1cm} 
\end{figure}





\mypara{Results and discussion. }
As shown by the red and blue curves in Figure~\ref{fig:tsne_vis}, by simply substituting the original classifier $\mathcal{C}$ with the oracle context-aware classifier $\mathcal{A}_{y}$, samples of different classes can be better distinguished via a better feature descriptor serving as the decision boundary. It implies that additional detailed co-occurring semantic cues conditioned on individual testing samples have been exploited by $\mathcal{A}_{y}$, so as to achieve preferable performance on both training and validation sets during both training and testing phases.


However, $\mathcal{A}_{y}$ is obtained with the ground-truth annotation that is only available during model training. To make it tractable for boosting the testing performance, learning to form such  context-aware classifiers conditioned on the content of individual samples takes the next step.

\begin{figure}[!t]
	\centering
	\begin{minipage}   {0.95\linewidth}
		\centering
		\includegraphics [width=1\linewidth] %,height=0.4\linewidth]
		{figure/cac-2.pdf}
	\end{minipage}     
	%\vspace{-0.2cm}
	\caption{Pipeline for learning context-aware classifier. }
	\label{fig:detail}
	%\vspace{-0.1cm} 
\end{figure}

\subsection{Learning Context-Aware Classifier}
\label{sec:learning_cwc}
% %\vspace{-0.2cm}
Without ground-truth labels, a natural modification to the oracle case is to use prediction $\vec{p}$ instead of ground-truth label $\vec{y}_{*}$ to approximate the oracle contextual prior. The overall learning process is illustrated in Figure~\ref{fig:detail}. 

Specifically, we note that the prediction $\vec{p}\in \mathcal{R}^{[hw \times n]}$ refers to the results got with the original classifier, \ie,  $\vec{p} = \vec{f} \times \mathcal{C}^\top$.  Therefore, the estimated contextual prototypes $\mathcal{C}_p \in \mathcal{R}^{[n \times d]}$ are yielded with $\vec{p}$ as  
\begin{equation}
    \label{eq:pred_proto}
    \mathcal{C}_p = \frac{\sigma(\vec{p})^\top \times \vec{f}}{\sum_{j=1}^{hw} \sigma(\vec{p})^\top(\cdot, j)} 
                  = \frac{\sigma(\vec{f} \times \mathcal{C}^\top)^\top \times \vec{f}}{\sum_{j=1}^{hw} \sigma(\vec{f} \times \mathcal{C}^\top)^\top(\cdot, j)},
\end{equation}
where $\sigma$ is Softmax operation applied on the second dimension.
Similar to Eq.~\eqref{eq:oracle_cls}, the context-aware classifier $\mathcal{A}_p  \in \mathcal{R}^{[n, d]}$ is yielded by processing the concatenation of the estimated contextual prior $\mathcal{C}_p$ and the original classifier $\mathcal{C}$ as shown in Eq.~\eqref{eq:estimate_cls}:
\begin{equation}
    \label{eq:estimate_cls}
    \mathcal{A}_p = \theta_p(\mathcal{C}_p \oplus \mathcal{C}),
\end{equation}
where $\theta_p$ denotes the projector that has the same structure as $\theta_y$. Also, prediction $\vec{p}_{p}$ represents the result got from the temporarily estimated context-aware classifier $\mathcal{A}_p$ as shown in Eq~\eqref{eq:estimate_pred}. 
\begin{equation}
    \label{eq:estimate_pred}
    \vec{p}_{p} = \tau \cdot \eta(\vec{f}) \times \eta(\mathcal{A}_p)^\top.
\end{equation}
We find that adopting the context-aware classifier to calculate the cosine similarities yields better results than the commonly used dot product, because the former helps alleviate the issues that stem from the instability of the individually generated $\mathcal{A}_y$ and $\mathcal{A}_p$. Contrarily, simply replacing the dot product used by the original classifier with cosine similarity is not profitable to the overall performance. More detailed discussions and experiments are shown in Section~\ref{sec:ablation_study}. 

\mypara{Optimization. }
Using a single pixel-wise cross-entropy (CE) loss $\mathcal{L}_{p}^{ce}$ to supervise $\vec{p}_{p}$ seems feasible for learning the context-aware classifier. However, as shown in later experiments in Table~\ref{tab:ablation_loss}, standard CE loss brings incremental improvement to the baseline because, compared to the precise prior offered by the ground-truth $\vec{y}$, the uncertainty contained in $\vec{p}$ makes the estimated categorical prototypes $\mathcal{C}_p$ less reliable than the universally shared  classifier $\mathcal{C}$, potentially making the projector $\theta_p$ tend to trivially neglect $\mathcal{C}_p$.

As discussed in Section~\ref{sec:oracle_case}, the oracle context-aware classifier $\mathcal{A}_y$ yielded with ground-truth label is a better distribution descriptor for each sample, thus it achieves much better performance than the original classifier $\mathcal{C}$. 
Therefore, inspired by the practices in knowledge distillation~\cite{kd_hinton} and incremental learning~\cite{lwf}, as a means to transfer or retain necessary information, we additionally incorporate KL divergence $\mathcal{L}_{KL}$ to regularize the model such that it is encouraged to yield more informative $\mathcal{A}_p$ by mimicking the prediction $\vec{p}_{y}$ of the oracle situation $\mathcal{A}_y$. In other words, useful knowledge is distilled from $\mathcal{A}_y$ to $\mathcal{A}_p$:
\begin{equation}
    \label{eq:init_kl_loss}
    \mathcal{L}_{KL} = -\frac{1}{hw} \sum_{i=1}^{hw} \sum_{j=1}^{n} \sigma(\vec{p}_{y})^{i,j} \cdot \log \sigma(\vec{p}_{p})^{i,j},
\end{equation}
where $h$, $w$ and $n$ denote height, width and class number, and $\sigma$ represents the Softmax operation applied to the second dimension of $\vec{p}_{y}\in \mathcal{R}^{[hw, n]}$ and $\vec{p}_{p}\in \mathcal{R}^{[hw, n]}$. Gradients yielded by $\mathcal{L}_{KL}$ will not be back-propagated to $\vec{p}_{y}$. 

In addition to $\mathcal{L}_{p}^{ce}$ and $\mathcal{L}_{KL}$, CE losses applied to $\vec{p}$ and $\vec{p}_y$, denoted as $\mathcal{L}^{ce}$ and $\mathcal{L}_{y}^{ce}$ respectively, are also optimized, intending to ensure the quality of the estimated and the oracle prototypes. 
To this end, the training objective $\mathcal{L}$ is:
\begin{equation}
    \label{eq:init_loss}
    \mathcal{L} = \mathcal{L}^{ce} + \mathcal{L}_{p}^{ce} + \mathcal{L}_{y}^{ce} + \lambda_{KL}\mathcal{L}_{KL}.
\end{equation}










\mypara{Entropy-aware distillation. }
The KL divergence $\mathcal{L}_{KL}$ introduced in Eq.~\eqref{eq:init_kl_loss} distills the categorical information from $\mathcal{A}_y$ to $\mathcal{A}_p$, so as to let the model learn to approximate the oracle case.  Also, for segmentation, the one-hot label is not always semantically accurate because it cannot reveal the actual categorical hints in each image, but soft targets $\vec{p}_y$ that are estimated in the local oracle situation can offer such information for distillation. Still, even if individual co-occurring contextual cues have been considered in the above-mentioned method, we observe another issue that inhibits the improvement in semantic segmentation. 

However, the impact of the informative soft targets may be overwhelmed by those less informative because they are treated equally in Eq.~\eqref{eq:init_kl_loss}, causing inferior performance as verified in later experiments. Therefore, adjusting the contribution of each element according to the level of information could be beneficial for transferring knowledge in Eq.~\eqref{eq:init_kl_loss}.

In information theory, entropy $\mathcal{H}$ measures the ``amount of information'' in a variable. For the $i$-th element on the pixel-wise prediction $\vec{p}_y \in \mathcal{R}^{[hw, n]}$, $\mathcal{H}^i$ is calculated as:
\begin{equation}
    \label{eq:entropy}
    \mathcal{H}^i = -\sum_{j=1}^{n} \sigma(\vec{p}_y)^{i,j} \cdot \log \sigma(\vec{p}_y)^{i,j} \quad i \in \{1, ..., hw\},
\end{equation}
where $\sigma$ represents the Softmax operation on the second dimension of $\vec{p}_y$. As shown in later experiments, adopting the prediction $\vec{p}_y$ yielded with the oracle contextual prior to estimate $\mathcal{H}$ brings preferable results than $\vec{p}_p$ and $\vec{p}$. 
Then, by incorporating the entropy mask $\mathcal{H} \in \mathcal{R}^{[hw]}$, the distillation loss $\mathcal{L}_{KL}$ introduced in Eq.~\eqref{eq:init_kl_loss} is accordingly updated as:
\begin{equation}
    \label{eq:init_entropy_kl}
    \mathcal{L}_{KL} = \frac{-1}{{\sum_{i=1}^{hw} \mathcal{H}^{i}}} \sum_{i=1}^{hw} \sum_{j=1}^{n} 
                        \mathcal{H}^{i} \sigma(\vec{p}_{y})^{i,j} \log \sigma(\vec{p}_{p})^{i,j}.
\end{equation}

Besides, in semantic segmentation, multiple classes usually exist in a single image, thus the propagated information may still bias towards the classes of the majority. To alleviate this issue, the distillation loss is calculated independently for different categories. Finally, $\mathcal{L}_{KL}$ is formulated as:
\begin{equation}
    \label{eq:final_entropy_kl}
    \mathcal{L}_{KL} = \frac{-1}{n} \sum_{k=1}^{n} \frac {\sum_{i=1}^{hw} \sum_{j=1}^{n} 
                        \mathcal{M}_{k}^{i} \mathcal{H}^{i} \sigma(\vec{p}_{y})^{i,j} \log \sigma(\vec{p}_{p})^{i,j}}
                        {{\sum_{i=1}^{hw} \mathcal{M}_{k}^{i} \mathcal{H}^{i}}}
\end{equation}
where the binary mask $\mathcal{M}_k = (\vec{y} == k)$ indicates the existence of the $k$-th class. 

We note that though it seems to be attainable to directly apply $\mathcal{L}_{KL}$ to regularize the original output $\vec{p}$ instead of $\vec{p}_p$ yielded by the estimated context-aware classifier, experiments in Table~\ref{tab:ablation_alternative_designs} show that applying $\mathcal{L}_{KL}$ to $\vec{p}$ is less effective, certifying the importance of the context-aware classifier. On the other hand, as shown in Table~\ref{tab:ablation_loss}, removing $\mathcal{L}_{KL}$ results in inferior performance, manifesting the fact that both $\mathcal{L}_{KL}$ and context-aware classifier are indispensable.


\mypara{Discussion with self-attention. }
Self-attention (SA) dynamically adapts to different inputs via the weighing matrix obtained by multiplying the key and query vectors yielded by individual inputs. 
Yet, the intrinsic difference is that SA only adjusts features to diverse contexts, leaving the decision boundary in the latent space, \ie, the classifier, untouched, while the proposed method works in another direction by altering the decision boundary according to the contents of various scenarios. As shown in Section~\ref{sec:results}, our method is complimentary to popular SA-based designs, \eg, Swin Transformer~\cite{swin} and OCRNet~\cite{ocr}, by achieving preferable improvements without deprecating the efficiency.
