\section{Introduction}
As a fundamental tool, semantic segmentation has profited a wide range of applications~\cite{zhang2022mediseg,tian2019lase}.
Recent advances regarding model structure for boosting segmentation performance are fastened to stronger backbones and decoder heads, focusing on delicate designs to yield high-quality features, and then they all apply a classifier to make predictions.

However, the classifier in the recent literature is composed of a set of parameters shared by all images, leading to an inherent challenge during testing that the fixed parameters are required to handle diverse contexts contained in various samples with different co-occurring objects and scenes, e.g., domain adaptation~\cite{lai2021cac} Even for pixels in the same category, embeddings from different images cannot be well clustered as shown in Figure~\ref{fig:init_tsne}, potentially inhibiting the segmentation performance with the fixed classifier. This observation induces a pertinent question: \textit{whether the classifier can be enriched with contextual information for individual images.}





Consequently, in this paper, we attempt to yield context-aware classifier whose content is data-conditioned, decently describing different latent distributions and thence making accurate predictions.
To investigate the feasibility, we start from an ideal scenario where the precise contextual hints are provided to the classifier by the ground-truth label that enables forming perfect categorical feature prototypes to supplement the original classifier. 
As illustrated in Figure~\ref{fig:tsne_vis}, the classifier enriched with impeccable contextual priors significantly outperforms the baseline in both training and testing phases, certifying the superior performance upper bound achieved by the context-aware classifier. 

Yet, ground-truth label is not available during testing; therefore, in an effort to approximate the aforementioned oracle situation, we instead let the model learn to yield the context-aware classifier by mimicking the predictions made by the oracle counterpart. 
Nevertheless, treating elements equally during the imitation process is found deficient, in that the informative cues may be suppressed by those not instructive. To alleviate this issue, the class-wise entropy is leveraged to accommodate the learning process. 

\begin{figure}[!t]
	\centering
	\begin{minipage}   {0.72\linewidth}
		\centering
		\includegraphics [width=1\linewidth] % ,height=0.8\linewidth]
		{figure/new_init_tsne/partial_images_new.pdf}
	\end{minipage}       
	\begin{minipage}   {0.24\linewidth}
		\centering
		\includegraphics [width=1\linewidth ,height=0.7\linewidth]
		{figure/new_init_tsne/tsne.pdf}
	\end{minipage}              
	%\vspace{-0.2cm}
	\caption{Visualizations of latent features of \textit{Bed} in different scenes. \textit{Red}, \textit{blue} and \textit{green} represent features belonging to \textit{Bed} in the left three images respectively, and gray denotes the embeddings of the other co-occurring classes.}
%	\vspace{-0.5cm}
	\label{fig:init_tsne}
\end{figure}

The proposed method is model-agnostic, thus it can be applied to a wide collection of semantic segmentation models with generic encoder-decoder structures. 
To this end, with our method, as shown in Figure~\ref{fig:statistics}, significant performance gains have been constantly brought to both small and large models without compromising the model efficiency, \ie, only about 2\% increase on inference time and a few additional parameters, even boosting the small model OCRNet (HR18)~\cite{ocnet,hrnet_cvpr} to reach higher performance than the competitors with much more parameters. 
To summarize, our contributions are as follows. 
%\vspace{-0.2cm}
\begin{itemize}
    \item We propose to learn the context-aware classifier whose content varies according to different samples, instead of a static one used in common practice.
    \item To make the context-aware classifier learning tractable, an entropy-aware KL loss is designed to mitigate the adverse effects brought by information imbalance. 
    \item Our method is easy to be plugged into other existing segmentation models, achieving considerable improvement with little compensation on efficiency. 
    
\end{itemize}


\begin{figure}[!t]
	\centering
	\begin{minipage}   {0.48\linewidth}
		\centering
		\includegraphics [width=1\linewidth ,height=0.8\linewidth]
%		{figure/compare.pdf}
		{figure/compare_larger_crop.jpg}	
	\end{minipage}    
	\begin{minipage}   {0.48\linewidth}
		\centering
		\includegraphics [width=1\linewidth ,height=0.8\linewidth]
%		{figure/compare_flops.pdf}
		{figure/compare_flops_larger_crop.jpg}
	\end{minipage}        
	%\vspace{-0.2cm}
	\caption{Effects on model performance (mIoU) and efficiency (parameters and inference time) on ADE20K~\cite{ade20k}. Detailed results are shown in Table~\ref{tab:results_ade20k}. }
	%\vspace{-0.5cm}
	\label{fig:statistics}
\end{figure}

