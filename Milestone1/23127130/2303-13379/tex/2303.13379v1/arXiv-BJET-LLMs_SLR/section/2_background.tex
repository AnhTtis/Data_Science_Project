\section{Background}
\label{Definitions}

In this section, we first establish the definitions for the key terminologies, specifically the definitions of practicality and ethicality in the context of educational technology. We then provided an overview of prior systematic literature reviews on LLMs in education. Then, we present the research questions based on the gaps identified in the existing literature.

\subsection{Practicality}

Several theoretical frameworks have been proposed regarding the practicality of integrating technological innovations in educational settings. For example, Ertmer's \cite{ertmer1999addressing} first- and second-order barriers to change focused on the external conditions of the educational system (e.g., infrastructure readiness) and teachers' internal states (e.g., personal beliefs). Becker \cite{becker2000findings} further suggested that for technological innovations to have actual benefits in supporting pedagogical practices, these innovations should be convenient to access, support constructivist pedagogical beliefs, be adaptable to changes in the curriculum, and be compatible to teachers' level of knowledge and skills. These factors were also presented in an earlier framework of the practicality index \cite{doyle1977practicality}, which summarised three critical components for integrating educational technologies, including the degree of adoption feasibility, the cost and benefit ratio, and the alignment with existing practices and beliefs. Based on these prior theoretical frameworks and considering the recentness of LLMs-based innovations (which only emerged in the past five years), the practical challenges of LLMs-based innovations in automating educational tasks can be assessed from three primary perspectives. First, evaluating the technological readiness of these innovations is essential for determining whether there is empirical evidence to support successful integration and operation in authentic educational contexts. Second, assessing the model performance could contribute valuable insights into the cost and benefits of adopting these innovations, such as comparing the benefits of automation with the costs of inaccurate predictions. Finally, understanding whether these innovations are methodologically replicable could be important for future studies to investigate their alignment with different educational contexts and stakeholders. We elaborated on the evaluation items for each challenge in Section \ref{sec:analysis}. 

\subsection{Ethicality}

Ethical AI is a prevalent topic of discussion in multiple communities, such as learning analytics, AI in education, educational data mining, and educational technology communities \cite{adams2021artificial,pardo2014ethical}. There are ongoing debates regarding AI ethics in education with a mixture of focuses on algorithmic and human ethics among educational data mining and AI in education communities \cite{holmes2022ethics}. As such debates continue, it is difficult to identify an established definition of ethical AI from these fields. Whereas, ethicality has already been thoroughly investigated and addressed in a closed field to AI in education, namely, the field of learning analytics \cite{pardo2014ethical,selwyn2019s}. Drawing on the established definition of ethicality from the field of learning analytics \cite{pardo2014ethical}, the ethicality of LLMs-based innovations can thus be defined as the systematisation of appropriate and inappropriate functionalities and outcomes of these innovations, as determined by all stakeholders (e.g., students, teachers, parents, and institutions). For example, Khosravi et al. \cite{khosravi2022explainable} explained that the ethicality of AI-powered educational technology systems needs to involve the consideration of accountability, explainability, fairness, interpretability, and safety of these systems.
%Recent studies on the ethicality of AI-powered educational technology systems often focused on the accountability, explainability, fairness, interpretability, and safety of these systems \cite{khosravi2022explainable}. 
These different domains of ethical AI are all closely related and can be addressed by considering system transparency. Transparency is a subset of ethical AI that involves making all information, decisions, decision-making processes, and assumptions available to stakeholders, which in turn enhances their comprehension of the AI systems and related outputs \cite{chaudhry2022transparency}. Additionally, for LLMs-based innovations, Weidinger et al. \cite{weidinger2021ethical} suggested six types of ethical risks, including 1) discrimination, exclusion, and toxicity, 2) information hazards, 3) misinformation harms, 4) malicious uses, 5) human-computer interaction harms, and 6) automation, access, and environmental harms. These risks can be further aggregated into three fundamental ethical issues, such as privacy concerns regarding educational stakeholders' personal data, equality concerns regarding the accessibility of stakeholders with different backgrounds, and beneficence concerns about the potential harms and negative impacts that LLMs-based innovations may have on stakeholders \cite{ferguson2016guest}. These three fundamental ethical issues were considered in the analysis of the reviewed literature, further details were available in Section \ref{sec:analysis}. 

\subsection{Related Work}

Prior systematic literature reviews have focused primarily on reviewing a specific application scenario (e.g., question generation, automated feedback, chatbots and essay scoring) of natural language processing and LLMs. For example, Kurdi et al. \cite{kurdi2020systematic} have systematically reviewed empirical studies that aimed to tackle the problem of automatic question generation in educational domains. They comprehensively summarised the different generation methods, generation tasks, and evaluation methods presented in prior literature. In particular, LLMs could potentially benefit the semantic-based approaches for generating meaningful questions that are closely related to the source contents. Likewise, Cavalcanti et al. \cite{cavalcanti2021automatic} have systematically reviewed different automated feedback systems regarding their impacts on improving students' learning performances and reducing teachers' workloads. Despite half of their reviewed studies showing no evidence of reducing teachers' workloads, as these automated feedback systems were mostly rule-based and required extensive manual efforts, they identified that using natural language generation techniques could further enhance such systems' generalisability and potentially reduce manual workloads. On the other hand, Wollny et al. \cite{wollny2021we} have systematically reviewed areas of education where chatbots have already been applied. They concluded that there is still much to be done for chatbots to achieve their full potential, such as making them more adaptable to different educational contexts. A systematic literature review has also investigated the various automated essay scoring systems \cite{ramesh2022automated}. The findings have revealed multiple limitations of the existing systems based on traditional machine learning (e.g., regression and random forest) and deep learning algorithms (e.g., LSTM and BERT). In sum, these previous systematic literature reviews have identified room for improvement that can be potentially addressed using state-of-the-art LLMs (e.g., GPT-3 or Codex). However, none of the prior systematic literature reviews has investigated the practical and ethical issues related to LLMs-based innovations in education generally rather than particularly (e.g., limited to a specific task).

The recent hype around one of the latest LLMs-based innovations, ChatGPT, has intensified the discussion about the practical and ethical challenges related to using LLMs in education. For example, in a position paper, Kasneci et al. \cite{kasneci2023chatgpt} provided an overview of some existing LLMs research and proposed several practical opportunities and challenges of LLMs from students' and teachers' perspectives. Likewise, Rudolph et al. \cite{rudolph2023chatgpt} also provided an overview of the potential impacts, challenges, and opportunities that ChatGPT might have on future educational practices. Although these studies have not systematically reviewed the existing educational literature on LLMs, their arguments resonated with some of the pressing issues around LLMs and ethical AI, such as data privacy, bias, and risks. On the other hand, Sallam \cite{sallam2023utility} systematically reviewed the implications and limitations of ChatGPT in healthcare education and identified potential utility around personalisation and automation. However, it is worth noting that most papers reviewed in Sallam's study were either editorials, commentaries, or preprints. This lack of peer-reviewed empirical studies on ChatGPT is understandable as it has only been released since late 2022 \cite{openai2022chatgpt}. None of the existing work has systematically reviewed the peer-reviewed literature on prior LLMs-based innovations, such investigations could provide more reliable and empirically-based evidence regarding the potential opportunities and challenges of LLMs on educational practices. Thus, the current study aimed to address this gap in the literature by conducting a systematic literature review of prior educational research on LLMs. Specifically, the following research questions were investigated to guide this review: 

\begin{itemize}
\item \noindent\textbf{RQ1}: What is \textit{the current state of research} on using LLMs to automate educational tasks, specifically through the lens of educational tasks, stakeholders, LLMs, and machine-learning tasks\footnote[1]{Such as classification, prediction, clustering, etc.}?

\item \noindent\textbf{RQ2}: What are the \textit{practical} challenges of LLMs in automating educational tasks, specifically through the lens of technological readiness, model performance, and model replicability?

\item \noindent\textbf{RQ3}: What are the \textit{ethical} challenges of LLMs in automating educational tasks, specifically through the lens of system transparency, privacy, equality, and beneficence?

\end{itemize}
