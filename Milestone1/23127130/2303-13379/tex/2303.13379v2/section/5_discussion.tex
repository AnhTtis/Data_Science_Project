\section{Discussion}

\subsection{Main Findings}

The current study systematically reviewed 118 peer-reviewed empirical studies that used LLMs to automate educational tasks. For the first research question (RQ1), we illustrated the current state of educational research on LLMs. Specifically, we identified 53 types of application scenarios of LLMs in automating educational tasks, summarised into nine general categories, including profiling and labelling, detection, assessment and grading, teaching support, prediction, knowledge representation, feedback, content generation, and recommendation. While some of these categories resonate with the utilities proposed in prior positioning works (e.g., feedback, content generation, and recommendation) \citep{kasneci2023chatgpt,rudolph2023chatgpt}, novel directions such as using LLMs to automate the creation of knowledge graph and entity further indicated the potential of LLMs-based innovations in supporting institutional practices (e.g., creating knowledge-based search engines across multiple disciplines). These identified directions could benefit from the state-of-the-art LLMs (e.g., GPT-3 and Codex) as most of the reviewed studies (92\%) focused on using BERT-based models, which often required manual effort for fine-tuning. Whereas, the state-of-the-art LLMs could potentially achieve similar performance with a zero-shot approach \citep{bang2023multitask}. While the majority of the reviewed studies (63\%) focused on using LLMs to automate classification tasks, there could be more future studies that aimed to tackle the automation of prediction and generation tasks with the more capable LLMs \citep{sallam2023utility}. Likewise, although supporting teachers are the primary focus (72\%) of the existing LLMs-based innovations, students and institutions could also benefit from such innovations as novel utilities could continue to emerge from the educational technology literature. Together, the findings of the first research question could spark educational researchers with ideas of exploring the potential of state-of-the-art LLMs in augmenting educational practices, specifically, the identified 53 types of application scenarios may all worth to re-explore in the light of ChatGPT and other powerful generative AI models \citep{kasneci2023chatgpt}.

Regarding the second research question (RQ2), we identified several practical challenges that need to be addressed for LLMs-based innovations to have actual educational benefits. The development and educational research on LLMs-based innovations are still in the early stages. Most of the innovations demonstrated a low level of technology readiness, where the innovations have yet to be fully integrated and validated in authentic educational contexts. This finding resonates with previous systematic reviews on related educational technologies, such as reviews on automated question generation \citep{kurdi2020systematic}, feedback provision \citep{cavalcanti2021automatic}, essay scoring \citep{ramesh2022automated}, and chatbot systems \citep{wollny2021we}. There is a pressing need for in-the-wild studies that provide LLMs-based innovations directly to educational stakeholders for supporting actual educational tasks instead of testing on different datasets or in laboratory settings. Such authentic studies could also validate whether the existing innovations can achieve the reported high model performance in real-life scenarios, specifically in prediction and generation tasks, instead of being limited to prior datasets. This validation process is vital for preventing inadequate usage, such as adopting a subject-specific prediction model for unintended subjects. Researchers need to carefully examine the extent of generalisability of their innovations and inform the limitations to stakeholders \citep{gavsevic2016learning}. However, addressing such needs could be difficult considering the current literature's poor replicability, which increases the barriers for others to adopt LLMs-based innovations in authentic educational contexts or validate with different samples. Similar replication issues have also been identified in other areas of educational technology research \citep{yan2022scalability}.

For the third research question (RQ3), we identified several ethical challenges regarding LLMs-based innovations. In particular, most of the existing LLMs-based innovations (92\%) were only transparent to AI researchers and practitioners (Tier 1), with only nine studies that can be considered transparent to educational technology experts and enthusiasts (Tier 2). The primary reason behind this low transparency can be attributed to the lack of human-in-the-loop components in prior studies. This finding resonates with the call for explainable and human-centred AI, which stresses the vital role of stakeholders in developing meaningful and impactful educational technology \citep{khosravi2022explainable,yang2021human}. Involving stakeholders during the development and evaluation of LLMs-based innovations is essential for addressing both practical and ethical issues. For example, as the current findings revealed, LLMs-based innovations are subject to data privacy issues but were rarely mentioned or investigated in the literature \citep{merine2022risks}, which may be due to the little voice that stakeholders had in prior research. The several concerning issues around beneficence also demand the involvement of stakeholders as their perspectives are vital for shaping the future directions of LLMs-based innovations, such as how responsible decisions can be made with these AI systems \citep{schneider2022towards}. Likewise, the equality issue regarding the financial burdens that may occur when adopting innovations that leverage commercial LLMs (e.g., GPT-3 and Codex) can also be further studied with institutional stakeholders. 

\subsection{Implications}

The current findings have several implications for education research and practice with LLMs, which we have summarised into three recommendations that aim to support future studies to develop practical and ethical innovations that can have actual benefits to educational stakeholders. First, the wide range of application scenarios of LLMs-based innovations can further benefit from the improvements in the capability of LLMs. Updating existing innovations with state-of-the-art LLMs may further reduce the amount of manual effort required for fine-turning and achieve similar performances \citep{bang2023multitask}. Considering the 53 identified use cases of LLMs in education, there are multiple research trajectories that could foster the development of practical educational technologies. These avenues have the potential to address some of the pressing challenges that plague the global education system. Particularly, the use cases involving teaching support, assessment and grading, feedback, and content generation categories (Table \ref{tab:educational-tasks}) could act as catalysts for the development of educational technologies that could alleviate teachers' workload and mental stress by automating the laborious tasks associated with creating, evaluating, and providing feedback for student assessments \citep{carroll2022teacher}. Similarly, further exploration of the use cases in profiling and labelling, detection, prediction, and recommendation could lead to the development of educational technologies that can deliver personalised learning support for each student across various disciplines \citep{wollny2021we}. Such improvements could enhance the overall well-being of teachers and increase students' learning opportunities, thereby contributing to the achievement of SDG 4 by 2030 \citep{boeren2019understanding}. Nonetheless, researchers should also be mindful of the potential financial and resource burdens that could be imposed on educational stakeholders when innovating with the commercial LLMs (e.g., GPT-3/4 and ChatGPT).

The unrivalled natural language generation capabilities exhibited by ChatGPT and other cutting-edge LLMs (e.g., LLaMA and PaLM 2) might also inspire future studies to delve into a broader spectrum of research directions. These include comparisons between the quality of student-generated and ChatGPT-generated writings \citep{li2023can} and evaluating these LLMs' capability to tackle educational assessments \citep{gilson2023does}. Such explorations would not only unveil the potential of LLMs and generative AI models in educational content generation and evaluation tasks but also expose the possible threats that these models pose to academic integrity, a pervasive issue across the education sector \citep{kasneci2023chatgpt}. Intriguingly, leveraging the use cases of LLMs in tasks such as creating knowledge representation \citep{zheng2023automatic} and classifying cognitive levels \citep{liu2022automated} could potentially facilitate the transition from outcome-focused to process-focused assessments. Here, LLMs and generative AI models could be employed for learning assessments in a manner similar to learning analytics \citep{gasevic2022towards}. Consequently, future studies may begin to explore methods of addressing the potential threats of LLMs with LLMs-based solutions.

For LLMs-based innovations to achieve a high level of technology readiness and performance, the current reporting standards must be improved. Future studies should support the initiative of open-sourcing their models/systems when possible and provide sufficient details about the test datasets, which are essential for others to replicate and validate existing innovations across different contexts, preventing the potential pitfall of another replication crisis \citep{maxwell2015psychology}. This initiative is particularly vital in the era of generative AI models as most of these models, especially the commercial ones (e.g., ChatGPT and the GPT series), are proprietary. Thus, when using these LLMs for augmenting educational practices, such as scoring student essays \citep{doewes2021limitations}, providing real-time feedback \citep{zheng2022effects}, or generating questions for learning activities \citep{sarsa2022automatic}, researchers need to be systematic and transparent about the reporting of the model usage and prompts \citep{wu2022analysis}. For example, when using the ChatGPT API for question generation at scale, researchers should at least report the exact models, prompts, and model temperature used in the process, as different models may differ in their ability to generate accurate and reliable content and the prompts are essential for others to replicate the same or similar results \citep{kasneci2023chatgpt}.

Apart from the aforementioned technical and methodological details, researchers and educational policymakers should also consider the potential wider impacts of LLMs-based solutions on different stakeholders. For example, in terms of detection and academic integrity, some institutions have rapidly adopted AI-detection tools that claim to have high accuracy and a low false positive rate. Yet, as disclosed in a recent report by Turnitin, a company whose AI-detection function has been utilised on more than 38.5 million student submissions, the real-world performance of their solution resulted in a significantly higher occurrence of false positives compared to their laboratory findings \citep{turnitin2023ai}. Such negligence can be devastating for students who have been falsely accused of academic misconduct, as well as for educators who must handle the repercussions. This example reinforced the importance of conducting rigorous scientific studies with key stakeholders when adopting any LLMs-based solutions that have direct or indirect impacts on students, educators, and other stakeholders. Likewise, the reporting of such studies should also adhere to high standards, incorporating both methodological specifics and detailed data descriptions. These details are especially pertinent when considering the diverse cultural backgrounds of students and the fact that most LLMs are primarily trained on English datasets, which could potentially introduce biases towards non-native English students \citep{liang2023gpt}.

Adopting a human-centred approach when developing and evaluating LLMs-based innovations are essential for ensuring these innovations remain ethical in practice, especially as ethical principles may not guarantee ethical AI due to their top-down manners (e.g., developed by regulatory bodies) \citep{mittelstadt2019principles}. Future studies need to consider the ethical issues that may arise from their specific application scenarios and actively involve stakeholders to identify and address such issues. Specifically, LLM-based innovations should aim to reach at least Tier 3 in the transparency index and TRL-7 in technology readiness. This involves a fully functional system being integrated into authentic learning environments and validated by students and educators in terms of its practicality and ethical considerations. For any decisions made by the LLM-based innovations, the relevant stakeholders should be informed about how the decision was reached, as well as the potential risks and biases involved. For instance, when students receive an assessment that has been automatically graded, these grades should be accompanied by a warning message indicating that they have been graded by LLMs and AI \citep{angelone2022improved}. Students should also have the opportunity to consult their teacher regarding any concerns.

The active involvement of stakeholders should also extend beyond the education sector, also involving policymakers and industry companies to establish the guidelines for adopting LLMs-based innovations in learning and teaching practices, as such adoptions could have broader implications on society beyond the education sector. For example, human-AI collaboration might become an essential skill for students to succeed in the job market as AI solutions become an integral component of productivity in the industrial sector \citep{wang2020human}. Therefore, institutions that aim to prohibit AI tools could inadvertently place their students at a disadvantage compared to other institutions that proactively welcome such changes. This could be achieved by consistently refining their policy regarding the use of LLMs and generative AI solutions, based on stakeholder feedback and empirical evidence.

\subsection{Limitations}

The current findings should be interpreted with several limitations in mind. First, although we assessed the practicality and ethicality of LLMs-based innovations with seven different items, there could be other aspects of these multi-dimensional concepts that we omitted. Nevertheless, these assessment items were chosen directly from the corresponding definitions and related to the pressing issues in the literature \citep{adams2021artificial,weidinger2021ethical}. Second, we only included English publications, which could have biased our findings regarding the availability of LLMs-based innovations among different countries. Thirdly, as we strictly followed the PRISMA protocol and only included peer-reviewed publications, we may have omitted the emerging works published in different open-sourced archives. These studies may contain interesting findings regarding the latest LLMs (e.g., ChatGPT). Additionally, this review focused on the potential of LLMs-based innovations in automating educational tasks, and thus, other pressing issues, such as the potential threat to academic integrity, were outside of the scope of this systematic scoping review. We briefly touched on these pressing issues in the implications and illustrated the importance of the current findings in supporting future educational studies to address these issues. Moreover, since this study is a systematic scoping review, we did not assess the quality of the included studies, and thus, the findings, particularly, the performance metrics extracted from the reviewed studies, may need further evaluation. The goal of this study is to provide an overview of the different educational tasks that can be augmented by LLMs and generative AI models, which can serve as a reference point for future studies to further develop on using the state-of-the-art models (e.g., ChatGPT and PaLM 2). Furthermore, the transparency index that we adopted for RQ3 did not consider the transparency to students, which could be an important direction for future human-centred AI studies. Finally, we recognise the rapid development in the field of artificial intelligence in education. It is pertinent to mention that a number of recent workshops and preliminary papers, while contributing to this field, were not incorporated in this scoping review due to time constraints \citep{leiker2023prototyping,ma2023better,caines2023application}. Their exclusion represents a limitation to the breadth of this study, acknowledging the relentless pace of scholarly advancements in this area.




