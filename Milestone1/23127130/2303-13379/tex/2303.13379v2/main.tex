%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% A template for Wiley article submissions developed by 
% Overleaf for the Overleaf-Wiley pilot which ran 
% during 2017 and 2018.
% 
% This template is no longer supported, but is provided
% for historical reference. Last updated January 2019.
%
% Please note that whilst this template provides a 
% preview of the typeset manuscript for submission, it 
% will not necessarily be the final publication layout.
%
% Document class options:
% =======================
% blind: Anonymise all author, affiliation, correspondence
%        and funding information.
%
% lineno: Adds line numbers.
%
% serif: Sets the body font to be serif. 
%
% twocolumn: Sets the body text in two-column layout. 
% 
% num-refs: Uses numerical citation and references style 
%           (Vancouver-authoryear).
%
% alpha-refs: Uses author-year citation and references style
%             (rss).
%
% Using other bibliography styles:
% =======================
%
% To specify a different bibiography style
%
% 1) Do not use either num-refs or alpha-refs in documentclass.
% 2) Load natbib package with the options set as needed.
% 3) Use the \bibliographystyle command to specify the style
% 
% Included NJD styles are: 
%   WileyNJD-ACS
%   WileyNJD-AMA
%   WileyNJD-AMS
%   WileyNJD-APA
%   WileyNJD-Harvard
%   WileyNJD-VANCOUVER
%
% or you may upload an alternative .bst file 
% (if requested by the journal).
%
% Examples:
% =======================
%% Example: Using numerical, sort-by-authors citations.
% \documentclass[num-refs]{wiley-article}

%% Example: Using author-year citations and anonymising submission
% \documentclass[num-refs]{wiley-article}
\documentclass[alpha-refs]{wiley-article}

%% Example: Using unsrtnat for numerical, in-sequence citations
% \documentclass{wiley-article}
% \usepackage{natbib}
% \bibliographystyle{WileyNJD-APA}

%% Example: Using WileyNJD-AMA reference style and superscript
%%          citations, two-column and serif fonts for AIChE
% \documentclass[serif,twocolumn,lineno]{wiley-article}
% \usepackage[super]{natbib}
% \bibliographystyle{WileyNJD-AMA}
% \makeatletter
% \renewcommand{\@biblabel}[1]{#1.}
% \makeatother

% Add additional packages here if required
\usepackage{siunitx}
\usepackage{soul,xcolor} %strikethrough with color options
\usepackage{ulem}
% Update article type if known
\papertype{Review Article}

\title{Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review}

% Include full author names and degrees, when required by the journal.
% Use the \authfn to add symbols for additional footnotes and present addresses, if any. Usually start with 1 for notes about author contributions; then continuing with 2 etc if any author has a different present address.
\author[1]{Lixiang Yan}
\author[1]{Lele Sha} 
\author[1]{Linxuan Zhao}
\author[1]{Yuheng Li}
\author[1]{Roberto Martinez-Maldonado} 
\author[1]{Guanliang Chen} 
\author[1]{Xinyu Li}
\author[1]{Yueqiao Jin}
\author[1]{Dragan Gašević}


% Include full affiliation details for all authors
\affil[1]{Centre for Learning Analytics at Monash, Faculty of Information Technology, Monash University, Clayton, Victoria, Australia}

\corraddress{Lixiang Yan, Centre for Learning Analytics at Monash, Faculty of Information Technology, Monash University, 20 Exhibition Walk, Clayton, VIC 3800, Australia}
\corremail{jimmie.yan@monash.edu}

\fundinginfo{This research was at least in part funded by the Australian Research Council (DP210100060) and Jacobs Foundation (Research Fellowship).}

% Include the name of the author that should appear in the running header
\runningauthor{Yan et al.}

\begin{document}
\setstcolor{red} % set the color for strikethrough
\begin{frontmatter}
\maketitle

\begin{abstract}

Educational technology innovations leveraging large language models (LLMs) have shown the potential to automate the laborious process of generating and analysing textual content. While various innovations have been developed to automate a range of educational tasks (e.g., question generation, feedback provision, and essay grading), there are concerns regarding the practicality and ethicality of these innovations. Such concerns may hinder future research and the adoption of LLMs-based innovations in authentic educational contexts. To address this, we conducted a systematic scoping review of 118 peer-reviewed papers published since 2017 to pinpoint the current state of research on using LLMs to automate and support educational tasks. The findings revealed 53 use cases for LLMs in automating education tasks, categorised into nine main categories: profiling/labelling, detection, grading, teaching support, prediction, knowledge representation, feedback, content generation, and recommendation. Additionally, we also identified several practical and ethical challenges, including low technological readiness, lack of replicability and transparency, and insufficient privacy and beneficence considerations. The findings were summarised into three recommendations for future studies, including updating existing innovations with state-of-the-art models (e.g., GPT-3/4), embracing the initiative of open-sourcing models/systems, and adopting a human-centred approach throughout the developmental process. As the intersection of AI and education is continuously evolving, the findings of this study can serve as an essential reference point for researchers, allowing them to leverage the strengths, learn from the limitations, and uncover potential research opportunities enabled by ChatGPT and other generative AI models.


% Please include a maximum of seven keywords
\keywords{large language models, pre-trained language models, artificial intelligence, education, systematic scoping review, GPT-3, BERT, ChatGPT}
\end{abstract}
\end{frontmatter}

% \section*{Author Bio}

% Lixiang Yan is a PhD candidate in the Faculty of Information Technology at Monash University. His research interests include artificial intelligence, multimodal learning analytics, collaborative learning, and applied machine learning. Roberto Martinez-Maldonado is a senior lecturer of learning analytics and human-computer interaction in the Faculty of Information Technology at Monash University. His current research is in the area of learning and teamwork analytics, in which he utilises his expertise in human-computer interaction, collaborative learning and artificial intelligence. Linxuan Zhao is a PhD candidate in the Faculty of Information Technology at Monash University. His research interests include audio analytics, multimodal learning analytics, and collaborative learning. Xinyu Li is a research fellow in the Faculty of Information Technology at Monash University. His main research areas include self-regulated learning analytics, the application of computer vision in collaborative learning and multimodal learning analytics. Yueqiao Jin is a research assistant at the Centre for Learning Analytics at Monash. Her research interests include human-centred learning analytics and artificial intelligence. Dragan Gašević is a distinguished professor of learning analytics in the Faculty of Information Technology and director of the Centre for Learning Analytics at Monash University. His research interests are learning analytics, educational data mining, self-regulated learning, and collaborative learning. 

\section*{Practitioner notes}
What is currently known about this topic
\begin{itemize}
    \item Generating and analysing text-based content are time-consuming and laborious tasks.    
    \item Large language models are capable of efficiently analysing an unprecedented amount of textual content and completing complex natural language processing and generation tasks.
    \item Large language models have been increasingly used to develop educational technologies that aim to automate the generation and analysis of textual content, such as automated question generation and essay scoring.
\end{itemize}
What this paper adds
\begin{itemize}
    \item A comprehensive list of 53 different educational tasks that could potentially benefit from LLMs-based innovations through automation.
    \item A structured assessment of the practicality and ethicality of existing LLMs-based innovations from seven important aspects using established frameworks. 
    \item Three recommendations that could potentially support future studies to develop LLMs-based innovations that are practical and ethical to implement in authentic educational contexts.
\end{itemize}
Implications for practitioners
\begin{itemize}
    \item Updating existing innovations with state-of-the-art models may further reduce the amount of manual effort required for adapting existing models to different educational tasks.
    \item The reporting standards of empirical research that aims to develop educational technologies using large language models need to be improved.
    \item Adopting a human-centred approach throughout the developmental process could contribute to resolving the practical and ethical challenges of large language models in education. 
\end{itemize}

\input{section/1_introduction}
\input{section/2_background}
\input{section/3_methods}
\input{section/4_results}
\input{section/5_discussion}
\input{section/6_conclusion}

\printendnotes

\bibliography{reference.bib}

\end{document}