\clearpage
\onecolumn
\section*{Supplemental Materials}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\subsection*{A. SimCLR Augmentations for SAR Data}

In this section we will discuss the augmentation pipeline used to train the SimCLR model in more detail. 
Fig.~\ref{fig:app1} shows the PyTorch transform block that defines the augmentations.
Notice, several of the operations are from \texttt{torchvision.transforms} and we leave description of those to the official docs (\url{https://pytorch.org/vision/0.8/transforms.html}).
The remaining transforms are defined as follows:
\begin{itemize}
    \item \texttt{ClipAndScale(a,b)} - linearly re-scale the range of pixel values in the image given a randomly chosen maximum value between \texttt{a} and \texttt{b}. Pseudo: $\text{max\_val}=random.uniform(a,b); x_{new}=clip(x_{orig}, 0, \text{max\_val})/\text{max\_val}$. 
    \item \texttt{PowScale(a,b)} - pixel-wise exponentiation using a randomly selected value between \texttt{a} and \texttt{b}. Pseudo: $\text{val}=random.choice([random.uniform(a,1),random.uniform(1,b)]); x_{new}=(x_{orig})^\text{val}$. 
    \item \texttt{SpeckleNoise(a,b)} - randomly replace a subset of pixel values with values chosen from a Uniform(0,1) distribution. The size of the subset in \% total pixels is decided with $random.uniform(a,b)$.
    \item \texttt{GaussianNoise(a,b)} - apply pixel-wise additive Gaussian noise using $stdev=random.uniform(a,b)$.  
    \item \texttt{GaussianBlur} - convolve the chip with a Gaussian filter. 
\end{itemize}
Finally, Fig.~\ref{fig:app2} shows several examples of augmented pairs that are generated with this transform block. Recall, the SimCLR training objective encourages the two different views in the pair to lie near each-other in projection space, while views from different pairs should lie far away.

\begin{figure}[h]
\centering
\begin{minipage}{.52\textwidth}
    \vspace{7mm}
  \centering
  \includegraphics[width=\linewidth]{figures/sup_transforms.png}
  \vspace{1mm}
  \caption{PyTorch-like code describing transforms used to train SimCLR model.}
  \label{fig:app1}
\end{minipage}\hfill
\begin{minipage}{.45\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/sup_augpairs.png}
  \caption{Examples of augmented pairs.}
  \label{fig:app2}
\end{minipage}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\subsection*{B. Comparison With A Powerful Recent Method for Few-Shot MSTAR}

In the main document we do not compare our method to meta-learning-based FSL algorithms. 
As mentioned several times, this is because meta-learning approaches assume the existence of a labeled dataset for pretraining the feature extractor, which is a violation of our basic assumption set. 
However, for the sake of completeness we now present a detailed comparison with a state-of-the-art meta-learning approach to few-shot MSTAR called Domain Knowledge Powered Two Stream Deep Network (DKTS-N) \cite{dktsn}. Below are some notable points in no particular order:
\begin{itemize}
    \item DKTS-N uses the labeled SARSIM dataset \cite{sarsim_dataset} as the source of pretraining data for meta-learning. We argue that this is essentially an ideal scenario because SARSIM is specifically/conveniently synthesized to match the conditions of MSTAR (i.e., the downstream FSL task). We believe that this implies a more significant assumption than any we make in our work. Also, it is unclear if the method would be nearly as effective if the pretraining dataset was not so closely related to the downstream task. Finally, although our method is not reliant on such a related dataset, in practice we could leverage more data by adding it to $\mathcal{D}_{pretrain}$.
    \item DKTS-N reports results using a preprocessing function that performs perfect azimuth angle normalization on both the training and test data. We believe this is done using meta-data provided in the MSTAR dataset. They also show that as the normalization function incurs errors, performance can degrade significantly. It is unclear how one would achieve perfect azimuth angle normalization in the ``wild,'' and thus we do not use it here. However, if such a function were developed, we believe it could complement our model in a similar way to theirs.
    \item DKTS-N does not consider OOD detection in the few-shot classifier and thus is susceptible to producing erroneous predictions on OOD data at test time.
    \item DKTS-N involves a time-intensive inference procedure which scales poorly as \#-shots increases  (refer Table VII of \cite{dktsn}). This is because for each test input it performs an iterative optimization procedure w.r.t~each support sample. Our inference procedure is not nearly as complex, and is a single forward pass through a DNN (e.g., a RN18).
    \item While DKTS-N shows very high performance in MSTAR SOC, our method actually outperforms it in several of the EOC settings. Specifically, in the (4-way, 10-shot) and (4-way, 25-shot) cases our method is over 3\% more accurate. 
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\newpage
\subsection*{C. Additional results using a different self-supervised pretraining algorithm}

In the main manuscript we use the SimCLR algorithm to pretrain the feature extractor in Stage 1 of the pipeline. 
SimCLR is often used as a standard baseline for comparison in Self-Supervised Learning (SSL) literature and our intention is to use it as a representative of the SSL-class of algorithms.
To be clear, our framework is not tied to the SimCLR algorithm and we believe that any modern SSL algorithm may be used for pretraining.
To show the potential impact of a different SSL algorithm we run experiments with the Bootstrap Your Own Latent$^\dagger$ (BYOL) method.
BYOL uses a non-contrastive distillation scheme to perform the representation learning. 
This is thought to offer some advantages over SimCLR because the learning signal is not reliant on many negative samples to contrast the positive pair with.
Because the field of SSL is advancing so quickly it is unclear which SSL paradigm will ultimately emerge as the ``best,'' but for now these two methodologies make for an interesting comparison.
As mentioned in the paper, an important future work is still to consider using different SSL algorithms for pretraining within our framework.



Table~\ref{tab:mstar_soc_BYOL} shows the extended few-shot classification results in MSTAR Standard Operation Conditions, where the Scratch and SimCLR numbers are copy-pasted from Table~\ref{tab:mstar_soc} in the main paper.
The BYOL training parameters are nearly identical to the SimCLR parameters, including the extractor architecture, optimization procedure, augmentation scheme, and training schedule. 
The only method specific parameter is the EMA momentum which we set to $\tau=0.9995$. 
In the table we see that BYOL actually outperforms the Scratch and SimCLR models in all scenarios. 
Interestingly, the benefits of BYOL over SimCLR are most clear in the very low-shot scenarios (i.e., 1- and 5-shots) where the average margin of improvement is $\sim$5\%.
Focusing on the 10-way scenario, BYOL outperforms the best scratch model by at least 12\% in the 1-10 shot range.
Finally, we note that BYOL-based models trained with 10-shots perform on par with Scratch models trained with 20-shots!
The ease at which BYOL is swapped into our framework is a key advantage and speaks to the flexibility and extendability we were striving for. 


\input{tables/table_mstar_soc_BYOL}

\vspace{4mm}
\noindent
[$\dagger$] Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre H. Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Daniel Guo, Mohammad Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu, Rémi Munos, and Michal Valko. ``Bootstrap your own latent: A new approach to self-supervised learning.'' In \textit{Advances in Neural Information Processing Systems}, 2020.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% \subsection*{D. EXTRA RESULTS FOR MY EYES ONLY}

% \input{IEEEtran/tables/table_mstar_soc_EXTRA}

% \input{IEEEtran/tables/table_mstar_eoc_EXTRA}