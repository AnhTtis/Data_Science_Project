\section{Related Works}

\subsection{Social Correction on Social Media Platforms}


Misinformation widely spreads on social media platforms, which has caused detrimental effects on society~\cite{starbird2014rumors, arif2018acting, colliander2019fake}, including harassment and personal attacks~\cite{micallef2020role}. To combat misinformation, users actively employ various strategies~\cite{Mu2022IdentifyingAC}, including replying to and commenting on misinformation~\cite{vo2019learning, miyazaki2022fake, kligler2022collective}.
This debunking behavior can broadly reduce the misinformed beliefs of the author and the audience who see the misinformation~\cite{chan2017debunking, bode2018see}. Notably, current research works have shown the promising impact of debunking~\cite{chan2017debunking, bode2018see} in both curbing the perception of misinformation and reducing the belief of false information~\cite{chan2017debunking}. 
In this work, we deep-dive into this misinformation-countering behavior by looking at both the misinformation posts and the counter-misinformation replies to these posts. Since user response information can indicate the textual properties of misinformation posts that are highly likely to get countered, our work sheds light on better understanding of misinformation-countering behavior, especially, understanding the misinformation tweets that get countered. 

\subsection{Analysis of Counter-misinformation}\label{sec:related_work_analysis}
Due to the significance of counter-misinformation messages in curbing misinformation, much research has been focused on analyzing and understanding counter-misinformation~\cite{micallef2020role,vo2019learning}.


One type of work is to analyze and compare misinformation and counter-misinformation messages~\cite{micallef2020role,vo2019learning}. For instance, \citet{micallef2020role} first created a textual classifier to classify tweets into misinformation, counter-misinformation, and irrelevant groups, and then analyzed the tweets in each group. Interestingly, they find that a surge in misinformation tweets results in a corresponding  increase in tweets that reject such misinformation.
\citet{vo2019learning} first identified fact-checking replies by checking whether a reply contains a fact-checking URL toward two trustworthy fact-checking websites (i.e., Snopes.com and Politifact.com). Then, they retrieved the corresponding misinformation tweet toward which the fact-checking post replies to, and use them to construct pairs of misinformation posts and fact-checking replies for fact-checking content analysis and reply generation.

Meanwhile, ~\citet{miyazaki2022fake} curated a large-scale dataset containing pairs of misinformation tweets and debunking replies, by first crawling COVID-19 related misinformation tweets from existing research~\cite{cui2020coaid, kim2021fibvid, hossain2020covidlies, memon2020characterizing, shahi2021exploratory} and then recruiting crowd-sourcing workers via Amazon Mechanical Turk to annotate responses to these tweets as being debunking or not. They then perform analysis to illustrate who counters misinformation and how they do so.
However, contrary to this work, 
we conduct an in-depth \textit{stratified} analysis of the replies to examine which features matter during the countering. Stratification helps to compare similar tweets by controlling for the number of replies it receives. Furthermore, we also conduct analysis of whether tweets get a high or low proportion of countering replies. Importantly, we also build two new tasks of predicting which misinformation posts will get countered and to what degree they get countered.
Our work complements the existing counter-misinformation studies. 

\subsection{Birdwatch (a.k.a. Community Note)}
Twitter launched Birdwatch (recently renamed to Community Note) to facilitate misinformation detection by ordinary users. On the platform, users can report suspicious and/or misleading tweets, as well as annotate tweets reported by others. Many have investigated this kind of countering~\cite{allen2022birds, mujumdar2021hawkeye} and derived different patterns among this collective countering. For instance, ~\citet{allen2022birds} looks at the impact of partisanship during the crowds' annotation by analyzing existing data from the Birdwatch/Community Note platform; they find its users are more likely to (1) give negative annotations of tweets from counter-partisans, and (2) rate annotations from counter-partisans as unhelpful. Though Birdwatch/Community Note enables community-based detection of misinformation, it does not provide a way for users to counter misinformation. Notably, users provide inputs within the Birdwatch ecosystem only, which is restricted and does not reflect the larger dynamics of information flow on Twitter. 
Recent research has also shown that Birdwatch can be manipulated by motivated bad actors~\cite{mujumdar2021hawkeye}.
Therefore, we focus on the misinformation that spreads on Twitter and is countered by ordinary users for a more complete and comprehensive study. 



