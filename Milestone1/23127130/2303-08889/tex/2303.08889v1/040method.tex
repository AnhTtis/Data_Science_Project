\section{Characterization of Counter-reply}\label{sec:feature_analysis}

In this section, we analyze the properties of misinformation tweets with respect to the degree to which their misinformation gets countered. In order to do so, we identify the tweets that see a high proportion of their replies being counter-replies, and compare it to the group that see a low proportion of their replies being counter-replies.

To avoid skewing the results due to extreme data points, for this analysis, we do not consider tweets at the two extremes of the ``reply count'' distribution -- specifically, we remove tweets with fewer than three replies, as well as the top 2\% of tweets that have the greatest number of replies, following similar tweet filtering procedures in existing research works~\cite{yuan2016will, aleksandric2022twitter, alvarez2016topic}.
This is done to remove dataset noise related to low-engagement tweets, along with outliers associated with the highest engagement tweets. After this process, we are left with 74,663 misinformation tweets, with reply counts ranging from 3 to 52 (both inclusive).

\begin{figure}[h]
    \centering
    \includegraphics [width=0.4\textwidth, keepaspectratio]{figures/disbelief_proportion.jpg}
    \caption{Distribution of proportion of counter-replies for each stratum. Each boxplot represents a stratum, displaying the minimum, maximum, quartiles, and (any) outliers.}
    \label{fig:disbelief_prop}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics [width=0.4\textwidth, keepaspectratio]{figures/low_vs_high.jpg}
    \caption{Number of tweets in each of the ``Low Countered'' (yellow) and ``Highly Countered'' (red) groups for each stratum, presented on a log scale.}
    \label{fig:low_vs_high}
\end{figure}

\subsection{Stratified Dataset Creation}\label{sec:feature_analysis_strat}

The linguistic, engagement, and user-level properties of tweets that get a low number of replies are different from those of tweets that receive many replies~\cite{matsumoto2019analysis, bruns2013towards, bruns2012quantitative}. Thus, to avoid conflating the factors that lead to receiving a high number of replies with the factors to receive counter-replies, we define and create several strata based on the number of replies that a misinformation tweet receives. 
Specifically, the strata are defined as follows: \textit{[3, 5], [6, 10], [11, 15], ..., [46, 50]}. 
Each stratum contains similar misinformation tweets that receive a similar number of replies, with some tweets that get countered and others that do not. We then compare these two groups within each stratum.
Figure \ref{fig:disbelief_prop} shows the distribution of counter-reply proportion within each stratum. We observe that, with the exception of tweets with a lower number of replies (that have more tweets with relatively fewer counter-replies), the distribution is similar across reply counts.

Within each stratum, we assign tweets to a ``Highly Countered'' group if its counter-reply proportion is in the top quartile (also within that stratum), a ``Low Countered'' group if its counter-reply proportion is in the bottom quartile (within that stratum), or discard it if it does not fall into either of the two groups. 
Figure \ref{fig:low_vs_high} shows the distribution of the tweets in the two relevant categories.

Within each stratum, we compare misinformation tweets between the two groups. We identify three types of attributes to perform this comparison along:
\begin{enumerate}
    \item \textbf{Tweet linguistic attributes}, to analyze the degree to which the tweet falls into meaningful personal, psychological, topical, emotion, and other content-related categories.
    \item \textbf{Tweet engagement attributes}, to analyze how and how much the tweet is interacted with among online users.
    \item \textbf{Tweet poster attributes}, to analyze the behavior, popularity, and status of the user behind the tweet.
\end{enumerate}
Table~\ref{tab:attr_list} displays the full list of attributes we study within each of these categories. We present results in the following subsections.

\begin{table*}[ht!]
    \centering
    \setlength\extrarowheight{-5pt}
    \begin{tabular}{p{0.15\linewidth} | p{0.8\linewidth}}
     \toprule
      Attribute type & List of attributes  \\
        \midrule
      Tweet linguistic & \tabitem number of words in the tweet*** \\
      & \tabitem VADER~\cite{Hutto_Gilbert_2014} positive sentiment, negative sentiment***, and compound sentiment*** of the tweet \\
      & \tabitem Politeness*** and impoliteness*** scores of the tweet, computed as the total number of linguistic strategy instances in the tweet positively and negatively correlated (respectively) with politeness as proposed by~\cite{DanescuNiculescuMizil2013ACA}. \\
      & \tabitem For each of the 65 (47*** + 18) dimensions of the LIWC~\cite{pennebaker2001linguistic} 2007 lexicon, the number of words for that dimension. \\
      \midrule
      Tweet engagement & \tabitem number of replies***, likes***, retweets*** (RTs), and quote tweets (QTs)*** \\
      & \tabitem number of likes, retweets (RTs), and quote tweets (QTs)***, each divided by the number of replies \\
      \midrule
      Tweet poster & \tabitem number of followers, number of users following***, whether the user is verified (1) or not (0)*** \\
      & \tabitem Total number of tweets the user has posted since account creation*** \\
      & \tabitem In the week (7 days) leading up to the misinformation tweet: the average \# of tweets posted per day***, the median count of likes*** and retweets*** received on their tweets, the number of tweets the user posted about COVID-19 vaccines***, and the proportion of COVID-19 vaccine tweets that are misinformation. \\
      \bottomrule
    \end{tabular}
    \caption{List of linguistic, engagement, and poster attributes considered for the analysis in Section~\ref{sec:feature_analysis}. A set of three asterisks(***) next to the attribute indicates a statistical test result of p < 0.001.\protect\footnotemark  This subset of statistically significant attributes is considered for the predictive tasks in Section~\ref{sec:prediction}.}
    \label{tab:attr_list}
\end{table*}



\begin{figure*}[h]
    \centering
    \begin{subfigure}[t]{0.24\textwidth}
        \raisebox{-\height}{\includegraphics[width=\textwidth]{figures/tweet_liwc_Affect.jpg}}
        \caption{LIWC Affect score}
        \label{subfig:liwc_affect}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.24\textwidth}
        \raisebox{-\height}{\includegraphics[width=\textwidth]{figures/vader_neg.jpg}}
        \caption{VADER negative sentiment}
        \label{subfig:vader_neg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.24\textwidth}
        \raisebox{-\height}{\includegraphics[width=\textwidth]{figures/tweet_liwc_Anger.jpg}}
        \caption{LIWC Anger score}
        \label{subfig:liwc_anger}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.24\textwidth}
        \raisebox{-\height}{\includegraphics[width=\textwidth]{figures/impoliteness_score.jpg}}
        \caption{Impoliteness score}
        \label{subfig:politeness}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.24\textwidth}
        \raisebox{-\height}{\includegraphics[width=\textwidth]{figures/tweet_liwc_Health.jpg}}
        \caption{LIWC Health score}
        \label{subfig:liwc_health}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.24\textwidth}
        \raisebox{-\height}{\includegraphics[width=\textwidth]{figures/tweet_liwc_SheHe.jpg}}
        \caption{LIWC SheHe score}
        \label{subfig:liwc_shehe}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.24\textwidth}
        \raisebox{-\height}{\includegraphics[width=\textwidth]{figures/scaled_quote_count.jpg}}
        \caption{Fraction of quote tweets (QTs) among all the replies}
        \label{subfig:scaled_qt}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.24\textwidth}
        \raisebox{-\height}{\includegraphics[width=\textwidth]{figures/scaled_retweet_count.jpg}}
        \caption{Fraction of retweets (RTs) among all the replies}
        \label{subfig:scaled_rt}
    \end{subfigure}
    \caption{Means and 95\% confidence intervals of the linguistic and engagement attributes of misinformation tweets that get highly countered versus those that do not.}
    \label{fig:stratified_results}
\end{figure*}

\footnotetext{This statistical test was performed using Welch's unequal variances \textit{t}-test between the upper and lower quartiles (with respect to the proportion of counter-replies) of the data visualized in Figure~\ref{fig:disbelief_prop}.}

\subsection{Linguistic Attributes of Tweets that are Countered}\label{sec:feature_analysis_linguistic}



First, we observe from Figure \ref{subfig:liwc_affect} that on average, ``Highly Countered'' tweets contain 32.1\% higher usage of affective language (words and phrases that appeal more to emotions) than ``Low Countered'' tweets (p < 0.05 for all strata\footnote{all p-values in Sections ~\ref{sec:feature_analysis_linguistic},  ~\ref{sec:feature_analysis_engagement}, and ~\ref{sec:feature_analysis_user} are calculated using Welch's unequal variances \textit{t}-tests.}; average Cohen's d = 0.277)\footnote{``average Cohen's d'' here (and elsewhere in this paper) refers to the unweighted average of Cohen's d values of each stratum.}. This indicates that those who post counter-replies tend to gravitate more towards replying to misinformation that induces a stronger emotional reaction in them. This is consistent with the finding that emotional content gets more attention on social media in existing research works~\cite{schreiner2021impact}.
Further, we find that ``Highly Countered'' tweets express significantly higher negative sentiment than ``Low Countered'' tweets across all strata. Figure \ref{subfig:vader_neg} shows this result for VADER negative sentiment (p < 0.05 for all strata; average Cohen's d = 0.304); we find similar results for the ``negative emotion'' dimension of the LIWC lexicon (p < 0.05 for all strata; average Cohen's d = 0.279). In particular, we find that on average, ``Highly Countered'' tweets contain 104\% more anger-related words than ``Low Countered'' tweets (see Figure \ref{subfig:liwc_anger}) (p < 0.01 for all strata; average Cohen's d = 0.347). This implies that the negative tone of misinformation tweets attract more attention~\cite{huang2007attention, haselmayer2019fighting}, and therefore, more counter-replies. 

In addition, we measure differences in the degree to which the misinformation tweet expresses politeness and impoliteness. We do this by identifying the sets of linguistic strategies associated with each as presented in \cite{DanescuNiculescuMizil2013ACA}, and compute the total number of linguistic instances associated with each set to derive the ``politeness'' and ``impoliteness'' score, respectively. As shown in Figure \ref{subfig:politeness}, on average, ``Highly Countered'' tweets utilize 23.1\% more strategies associated with impoliteness than ``Low Countered'' tweets (p < 0.05 for all but one stratum; average Cohen's d = 0.248); this finding is consistent with the previous findings involving negative sentiment. Meanwhile, we do not find a significant difference between the groups for strategies associated with politeness, implying that trying to be polite in presenting a misinformation tweet does not significantly impact the chance of being countered.

Next, we find that there exist differences in topical presence between ``Highly Countered'' and ``Low Countered'' tweets. Figure~\ref{subfig:liwc_health} shows that on average, ``Highly Countered'' tweets utilize 28.7\% fewer health-related terms than ``Low Countered'' tweets (p < 0.05 for all but one stratum; average Cohen's d = 0.220). This suggests that for the average counter-reply poster, the inclusion of more technical medical terminology might pose a barrier for their willingness or ability to post an effective debunking response. One possible reason is that the inclusion of technical health-related terms can signal authority over the topic and be more convincing to the reader~\cite{buehl2001profiling, habernal2016makes}.

We also find that ``Highly Countered'' tweets use 2.5 times more third-person pronouns (e.g., `he', `she', `they', `them', etc.) than ``Low Countered'' tweets (p < 0.05 for all but one stratum; average Cohen's d = 0.259; see Figure~\ref{subfig:liwc_shehe}). 

\subsection{Engagement Attributes of Tweets that are Countered}\label{sec:feature_analysis_engagement}

In this subsection, we study the impact of engagement attributes (e.g., likes, retweets, etc.) on whether misinformation gets countered. There are two possibilities: (1) first, misinformation tweets with higher engagement get countered more often because the misinformation gets more attention and therefore, have a higher likelihood of becoming accessible to someone who would counter it; (2) second, misinformation tweets that get countered are less likely to be liked or retweeted by others. We investigate which of the two possibilities hold as per the data. 

In addition to the reply count, we compare tweets using the number of likes, retweets (RT), and quotes (QT) they receive. As these methods of engagement on the platform serve a different purpose and have different functionality than the ``reply'' method, it is worth using these metrics in our cross-group comparison. In order to effectively capture these differences with respect to reply count, we first perform a scaling of these attributes by dividing by the reply count, then performing comparisons of this quotient across the two groups.

Figure \ref{subfig:scaled_qt} shows that on average, ``Highly Countered'' tweets receive 37.6\% fewer QTs relative to replies on average (p < 0.05 for all strata). This difference is very small at the lowest stratum (8.9\% fewer; Cohen's d = 0.05), but is much higher on the highest stratum (57.4\% fewer; Cohen's d = 0.37). 
We receive similar results for retweets and likes; on average, ``Highly Countered'' tweets receive 27.4\% fewer retweets relative to replies (p < 0.05 for all but one stratum; see Figure \ref{subfig:scaled_rt}) and 25.6\% fewer likes relative to replies (p < 0.05 for all but 3 strata).

These findings show that the presence of counter-replies on a tweet organically decreases engagement by average users, suggesting that the practice of countering is potentially effective at reducing the spread of misinformation~\cite{colliander2019fake, wijenayake2020effect,friggeri2014rumor}. 


\subsection{User Attributes of Tweet Posters that are Countered}\label{sec:feature_analysis_user}
First, we study the impact of the user being verified on Twitter on the tweet getting countered. We find that, on average, the proportion of ``Highly Countered''  misinformation posters that are verified is 16.8\% higher than that for ``Low Countered'' misinformation posters (p < 0.05 in all but 3 strata; average Cohen's d = 0.143). 

Since the majority of the posters on Twitter are non-verified, we study that set of users next. We compare the attributes of non-verified users in the ``Highly Countered'' group versus the ``Low Countered'' group. 
For the remainder of the attributes, we found none of them to be statistically different across the two groups. 
Thus, together with the linguistic results presented in Section \ref{sec:feature_analysis_linguistic}, we find that the content of the misinformation tweet is more important in attracting countering than the user who posts the misinformation.


\section{Inequality In Social Correction}\label{sec:ineq}
We further investigate the potential inequality in social correction. This can help identify whether certain types of users are less likely to be countered, leading to an increase in disparity. 
Motivated by existing work~\cite{verma2022examining}, we use education level as a key demographic variable to illustrate the potential inequality between different users. Since lack of education and literacy play a crucial role in believing in misinformation~\cite{roozenbeek2020susceptibility, georgiou2020covid, van2017education}, it is important to study whether it also impacts correction.  


We derived the education level of users by quantifying the readability of their posts using the Automated Readability Index (ARI), which is known to produce an approximate representation of education level in prior works~\cite{senter1967automated, flekova2016exploring, rajadesingan2015sarcasm}. A higher ARI corresponds to a higher education level.
We use the ``pre-misinformation'' posts of each user (i.e., posts made within the 7 days prior to posting the misinformation tweet) to calculate that user's ARI. 
Then, for each post, we compute the ARI score~\cite{senter1967automated, flekova2016exploring, rajadesingan2015sarcasm}. Finally, we compute the average of these scores, and use it as the final ARI value to present the education level of the user.
Thus, it should be noted that the ARI score is \textit{not} the education level portrayed in the misinformation tweet, but instead, the education level derived across the \textit{historical} posts of the user who spread misinformation tweets. We randomly sampled 10,000 users who spread misinformation in our dataset to illustrate the inequality phenomenon.

As shown in Figure~\ref{fig:education_demo}, we find that misinformation posts made by users with lower education levels have a higher likelihood of getting corrected. 
There is a systematically negative trend with an increase in the user's (perceived) education level. This highlights a need to pay attention to misinformation spread by users who portray a higher education level, since ordinary users are less likely to correct them.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.42\textwidth]{figures/ari_plot.png}
    \caption{Comparison of user communities with different education levels. As shown, users with lower education levels will have higher possibilities of getting countered when sending misinformation tweets. 
    }
    \label{fig:education_demo}
\end{figure}


