\section{Related Work}
\label{sec:Related Work}

\begin{figure*}[!th]
\begin{center}
\centerline{\includegraphics[width=1.0\textwidth]{img/frame.pdf}}
\caption{The left side of the figure is a brief example of our memory bank(MB) that stores the softmax output of the model for the last $t$ epochs, which is updated by the FIFO (First In First Out) principle; the middle is the cross selection strategy: within each epoch, data subsets $\mathcal{D}_{\mathrm{sel}}$ with confident pseudo-labels are selected from the MB of each network, which produce loss function $\mathcal{L}_{\mathrm{l}}$ to the training process for the other network;
% core part of our method, the process of cross-selecting confident pseudo labels, and the loss function of each model during training;
the right side illustrates our co-mix regularization term and the corresponding loss function $\mathcal{L}_{\mathrm{cr}}$ .}
\label{fig:overview}
\end{center}
\vspace{-0.5cm}
\end{figure*}


\noindent \textbf{Partial-label learning.\quad} This setting allows each training example to be annotated with a set of candidate labels for which the ground truth label is guaranteed to be included. However, \emph{label ambiguity} can pose a significant challenge in PLL. Early methods use an averaging strategy, which tends to treat each candidate label equally.~\cite{cour2011learningPLL2,zhang2017plldisambiguation} But such methods are easily affected by negative labels in the candidate label set, thus forming wrong classification boundaries. Afterwards, identification-based methods ~\cite{jin2002learningmultiplelabels,yu2016pllidentimaximum,liu2012PLL-idnbase} have received more attention from the community, which regard the ground-truth label as a latent variable, and will maintain a confidence score for each candidate label. For instance, Yu \emph{et al.}~\cite{yu2016pllidentimaximum} introduced the maximum margin constraint to PLL, trying to optimize the margin between the model outputs from candidate labels and other negative labels. 

% This method has shown better performance in disambiguating labels.

Recently, partial-label learning has been combined with deep networks, leading to significant improvements in performance. Feng \emph{et al.}~\cite{feng2020provably} assumed that partial labels come from a uniform generation model and provided a mathematical formulation, which is adopted by most of the algorithms proposed later~\cite{wang2022pico,xu2023pop,he2023candidateselect,wen2021LWS}. Based on this, they also propose an algorithm for classification consistency and risk consistency. PRODEN~\cite{lv2020proden} assumes the true label should be the one with the smallest loss among the candidate labels, and improves the classification risk algorithm accordingly. Wen \emph{et al.}~\cite{wen2021LWS} proposed a risk-consistent leveraged weighted loss with label-specific candidate label sampling.
PiCO~\cite{wang2022pico} innovatively introduces contrastive learning~\cite{oord2018contrastive} to the field and provides a solid theoretical analysis based on the EM (Expectation-Maximum) algorithm.
% Zhang \emph{et al.}~\cite{zhang2020GANPLL} and Li \emph{et al.}~\cite{li2021tripleGANPLL}, combine the idea of adversarial learning, using GAN to solve such problems.
% CRDPLL~\cite{wu2022CRDPLL} proposed a new consistency loss item in this field and treat the parts that are not selected as candidate labels as supervision information. SoLar~\cite{wang2022solar} focuses on solutions to PLL problems in more realistic scenarios such as class-imbalanced settings. 
POP~\cite{xu2023pop} updates
the model and purifies each candidate label set progressively in every epoch and eventually approximates the Bayes optimal classifier with mild assumptions.

\noindent\textbf{Sample selection.\quad} Sample selection is a popular technique in deep learning, especially for learning with noisy labels \cite{liu2015classification,patrini2017making,zhang2018generalized,xia2019anchor,yao2020dual,wei2022smooth,wei2022learning,cheng2023mitigating}. Then an obvious idea is to separate the clean samples and noisy samples in the mixed dataset. 
To address this issue, many existing works adopt the small loss criterion~\cite{han2018coteaching,jiang2018mentornet,wei2020jocor}, which assumes that clean samples tend to have a smaller loss than noisy samples during training.
% Small loss~\cite{han2018coteaching,jiang2018mentornet} criterion is the mainstream strategy adopted by most existing works, which is based on a conjecture that clean samples tend to have a smaller loss than noisy samples during the training phase.
MentorNet~\cite{jiang2018mentornet} is a representative work that makes the teacher model pick up clean samples for the student model. Co-teaching~\cite{han2018coteaching} constructs a double branches network to select clean samples for each branch, which is different from the teacher-student approach since none of the models supervise the other but rather help each other out. This idea was improved by some research later~\cite{yu2019coteachingimprove1,wang2019coteachingimprove2}.
% DivideMix~\cite{li2020dividemix} switched the tool of selection to a Gaussian mixture model fitted with a loss function, and combined it with MixMatch. 
Curriculum learning is also applied to this field~\cite{han2018CLlabelnoise1}, which considers clean labeled data as an easy task, while noisily labeled data as a harder task. 
Guo \emph{et al.}~\cite{guo2018curriculumnet} splitted data into subgroups according to their complexities, in order to optimize the training objectives in the early stage of course learning. 
OpenMatch~\cite{saito2021openmatch} trains $n$ OVA classifiers to select the in-distribution samples under the open set setting. 
Generative models such as Beta Mixture Model ~\cite{arazo2019betamixture} and Gaussian Mixture Model~\cite{li2020dividemix} are also used to fit loss functions to distinguish clean labels from noisy labels. Recently, the fluctuation magnitude of the output~\cite{wei2022self,yuan2023late} and normalized entropy~\cite{he2023candidateselect} are also considered as an important credential to judge whether the label is clean.

