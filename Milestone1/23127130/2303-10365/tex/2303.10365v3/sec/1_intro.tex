\section{Introduction}
\label{sec:intro}

The past few years have seen an increased interest in deep learning due to its outstanding performance in various application domains, including image processing~\cite{chen2021imageprocession}, automatic driving~\cite{xiong2019autodriving}, and medical diagnosis~\cite{park2018medical}. The success of deep learning heavily relies on a massive amount of fully labeled data. However, it is challenging to obtain a large-scale dataset with completely accurate annotations in the real world. To address this challenge, many researchers have explored a promising weakly supervised learning problem called partial-label learning (PLL)~\cite{cour2011learningPLL2,feng2020provably,xu2021instance,wen2021LWS,wang2022pico,wu2022CRDPLL,hong2023long,qiao2023fredis, xu2023progressive,qiao2023decompositional}, where each training example to have a set of candidate labels that includes the true label. This problem arises in many real-world tasks such as automatic image annotation~\cite{chen2017autoimageannotation} and facial age estimation~\cite{panis2015faceage}.


As PLL focuses on multi-class classification, there is only one ground-truth label for each training example, and other labels in the candidate label set are actually wrong (false positive) labels, which would have a negative impact on model training. Therefore, there exists the challenge of \emph{label ambiguity} in PLL. To address this challenge, the current mainstream solution is to disambiguate the candidate labels so as to figure out the true label for each training instance~\cite{jin2002learningmultiplelabels,yu2016pllidentimaximum,liu2012PLL-idnbase,feng2020provably,lv2020proden}.
% To address this challenge, there are currently two main types of disambiguation methods, which are average-based methods~\cite{cour2011learningPLL2,zhang2017plldisambiguation} and identification-based methods~\cite{feng2020provably,lv2020proden}.
% The average-based methods treat every candidate label equally, while the identification-based methods regard the ground-truth label as a latent variable and try to figure out the true label in the candidate label set. 
% The identification-based methods have achieved better performance than the average-based methods and gradually become the mainstream solution for PLL. 
However, most of the existing disambiguation methods normally leverage simple heuristics to iteratively update the labeling confidences or pseudo labels~\cite{feng2018leveraging,feng2020provably,lv2020proden,wang2022pico,wu2022CRDPLL}, which could not achieve convincing performance in identifying the true label during the training phase. Generally, if more true labels of training instances can be identified, we can train a better model. 
This serves as our primary motivation for identifying as many true labels as possible for training instances, ultimately resulting in the creation of a desired model.
% This motivates us to focus on identifying the true labels of training instances as many as possible, thereby training a desired model.

In this paper, we propose a method called \textbf{CroSel} (\textbf{Cro}ss \textbf{Sel}ection of Confident Pseudo Labels), which leverages historical prediction from deep neural networks to accurately identify true labels for most training examples. Our selecting criteria are based on the assumption that if a model consistently predicts the same label for an input image with high confidence and low volatility, then that label has a high probability of being the true label for that example. Using the cross selection strategy, the true labels of the vast majority of training examples can be accurately identified, with only negligible noise. Moreover, in order to avoid sample waste and tiny noise resulting from the selection, we also propose a co-mix consistency regularization to generate trainable targets for all examples. This regulation term serves as an essential complement to our method, which can further enhance the scope and accuracy of our selection of ``true" labels. The algorithm details are shown in Section \ref{section:method}.

Our main contribution can be summarized as follows:
\begin{itemize}
\item We propose a cross selection strategy to select confident pseudo labels in the candidate label set based on historical prediction. Our approach demonstrates a notable combination of high precision and ratio in selecting "true" labels within candidate label sets.
% This strategy shows high selection precision and selection ratio of ``true" labels in the experiment.
\item We introduce a new consistency regularization term that can leverage MixUp~\cite{zhang2017mixup} to enhance the data and generate trainable targets for all examples, serving as an important supplement to our method.
\item We experimentally show that CroSel achieves state-of-the-art performance on common benchmark datasets. We also provide extensive ablation studies to examine the effect of the different components of CroSel.
\end{itemize}

%-------------------------------------------------------------------------