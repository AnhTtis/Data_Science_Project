\subsection{Identifying the dynamics of the Kraichnan-Orszag system from data}\label{subsec:example_4}
In this example, we demonstrate the versatility of our Riccati-based approach by showing how it can be combined with existing methods to solve more general problems (see Section~\ref{subsec:method_4}).
Consider the Kraichnan-Orszag (K-O) system \cite{wan2006multi, zou2022neuraluq, zhang2023discovering}
\begin{equation}\label{eq:ko}
\begin{dcases}
  \frac{dx_1}{d\tau} = x_2x_3,\\
  \frac{dx_2}{d\tau} = x_1x_3,\\
  \frac{dx_3}{d\tau} = -2x_1x_2,
\end{dcases}
\end{equation}
with initial conditions $x_1(0) = 1, x_2(0) = 0.8, x_3(0) = 0.5$. Our goal is to identify the dynamics (the right-hand side of~\eqref{eq:ko}) of the K-O system  using measurements of $x_i$ and $\frac{d x_i}{d\tau}, i=1,2,3$ at different times. We identify the dynamics by learning the linear models $\frac{dx_i}{d\tau} = \sum_{k=1}^n\weight_k^i\phi_k, i = 1, 2, 3$. Following the general framework of the SINDy method \cite{brunton2016discovering}, we use the following quadratic basis functions ($n = 10$) for the dynamics:
\begin{equation*}\label{eq:ko:basis}
    \{\MLbasis_k(x_1, x_2, x_3)\}_{k=1}^n = \{1, x_1, x_2, x_3, x_1^2, x_2^2, x_3^2, x_1x_2, x_2x_3, x_1x_3\},
\end{equation*}
and impose $\ell_1$-regularization on $\weightvec$ to promote sparse identification of the dynamics. 
Then, we learn each $\weightvec^i$ independently and in parallel by minimizing the loss functions
\begin{equation}\label{eq:ko:loss}
    \mathcal{L}_i(\weightvec^i) = \frac{1}{2}\sum_{j=1}^N \lambda_j \left[\left(\frac{dx_i}{d\tau}\right)_j - \sum_{k=1}^{n} \weight^i_k \phi_k((x_1)_j, (x_2)_j, (x_3)_j)\right]^2 + \sum_{k=1}^n \MLreg_k|\weight_k^i|,
\end{equation}
where $\mathcal{L}_i$ denotes the loss function for equation $i$, $(x_i)_j$ and $(\frac{dx_i}{dt})_j$ denote the measurements of $x_i$ and $\frac{dx_i}{d\tau}$, respectively, at time $\tau_j$, $i=1,2,3,j=1,...,N$. Note that \eqref{eq:ko:loss} corresponds to setting $R = \|\cdot\|_1$ and $\HJx = 0$ in the linear regression problem~\eqref{eqt:loss_fn_general_reg}. Thus, solving this learning problem is equivalent to evaluating the solution to the corresponding multi-time HJ PDE at $(0, \lambda_1, \dots, \lambda_n)$. 
In our numerical experiments, we generate data points for training and testing by solving~\eqref{eq:ko} numerically for $x_1, x_2, x_3\in[0, 10]$ \updatetwo{using MATLAB \textit{ode45} \cite{MATLAB} and then} using a central finite difference scheme to approximate the time derivatives. We set $\lambda_j=1, \forall j$ and $\MLreg_k=0.1, \forall k$.

Instead of the sparse regression techniques employed by SINDy, 
we use PDHG to minimize~\eqref{eq:ko:loss} (see Section~\ref{subsec:method_4}). Each iteration of PDHG involves minimizing a loss function of the form~\eqref{eq:ko:loss}, but with $\ell_2$-regularization instead of $\ell_1$. Hence, this sub-problem can be solved using our Riccati-based methods. As discussed in Section~\ref{subsec:method_4}, note that we only need to apply RK4 for the first iteration of PDHG, and every subsequent iteration can be solved using a change of bias. As such, we do not suffer from any error accumulation related to repeated applications of RK4.
In Table~\ref{tab:sindy:1}, we see that we do indeed recover a sparse identification of the dynamics. However, we also incorrectly identify non-zero coefficients for the basis functions $x_2$ and $x_3$. We note that this misidentification may be the result of a lack of unique identifiability of the system from the data points sampled. In fact, Table~\ref{tab:sindy:3} shows that the errors in the solution $x_1,x_2,x_3$ of the identified system versus the solution of the true system~\eqref{eq:ko} are relatively small, which corroborates that identifiability may have been an issue.



\begin{table}[ht]
    \footnotesize
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
    \hline
         & $1$ & $x_1$ & $x_2$ & $x_3$ & $x_1^2$ & $x_2^2$ & $x_3^2$ & $x_1x_2$ & $x_2x_3$ & $x_1x_3$ \\
         \hline
         $\weightvec^{1, *}$ & $0$ & $0$ & $0$ & $0$ & $0$ & $0$ & $0$ & $0$ & $0.9931$ & $0$\\
         \hline
         $\weightvec^{2, *}$ & $0$ & $0$ & $0$ & $0.0160$ & $0$ & $0$ & $0$ & $0$ & $0$ & $0.9761$\\
         \hline
         $\weightvec^{3, *}$ & $0$ & $0$ & $-0.0165$ & $0$ & $0$ & $0$ & $0$ & $-1.9777$ & $0$ & $0$\\
         \hline
    \end{tabular}
\caption{Results of sparse identification of the K-O system~\eqref{eq:ko} using PDHG to minimize the $\ell_1$-regularized losses~\eqref{eq:ko:loss}. The true solution is 0 for all entries, except $\weightvec^{1, *} = 1$ for $x_2x_3$, $\weightvec^{2, *} = 1$ for $x_1x_3$, and $\weightvec^{3, *} = -2$ for $x_1x_2$. We recover the dynamics reasonably well, albeit with some slight misidentification of $\weightvec^{2, *}, \weightvec^{3, *}$.}
    \label{tab:sindy:1}
\end{table}



\begin{table}[ht]
    \footnotesize
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
         & $x_1$ & $x_2$ & $x_3$ \\
       \hline
       relative $L^2$ error (\%) & $0.2144$ & $0.3718$ & $0.3152$\\
       \hline
    \end{tabular}
    \caption{Errors of the solution $x_1, x_2, x_3$ of the system identified using PDHG compared to the true solution of the K-O system. The reference is obtained by numerically solving the true system~\eqref{eq:ko} using a central finite difference scheme. These errors indicate that the errors in the system identification in Table~\ref{tab:sindy:1} may be due to a lack of unique identifiability of the system using the given data points.}
    \label{tab:sindy:3}
\end{table}


