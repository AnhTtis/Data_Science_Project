\def\LQRu{\ba_u}
\def\LQRx{\ba_x}
\def\LQRTx{\bb}
\def\Cx{\bv_x}
\def\Cp{\bv_p}
\newpage
\section{Glossary of related terms in each problem}\label{appendix:glossary}
\begin{table}[h!]
    \centering
    \begin{adjustbox}{width=\textwidth}
    \begin{tabular}{c|c|c|c}
         \textbf{Learning Problem} & \textbf{Multi-Time HJ PDE} & \textbf{Optimal Control} & \textbf{Relation} \\
         \hline \hline
         \begin{tabular}{c}
              minimal loss function \\ $\min_{\weightvec\in\weightspace}\mathcal{L}(\weightvec)$
         \end{tabular} & \begin{tabular}{c}
              solution \\ $S(\HJx, \HJt_1, \dots, \HJt_N)$
         \end{tabular} & \begin{tabular}{c}
              value function \\ $S(\HJx, \HJt_1, \dots, \HJt_N)$
         \end{tabular} & \begin{tabular}{c}
              $\min_{\weightvec\in\weightspace}\mathcal{L}(\weightvec) =-S(\HJx, \HJt_1, \dots, \HJt_N)$ \update{$+c(\HJx)$}
         \end{tabular} \\
         \hline
         \begin{tabular}{c}
              optimal parameters $\weightvec^*$
         \end{tabular} & \begin{tabular}{c}
              spatial gradient \\ $\nabla_\HJx S(\HJx, \HJt_1, \dots, \HJt_N)$; \\
              maximizer $\HJmom^*$ \\ in the Hopf formula
         \end{tabular} & \begin{tabular}{c}
              optimal control $\HJu^*(\cdot)$
         \end{tabular} & \begin{tabular}{c}
              $\weightvec^* = \HJmom^* = \nabla_\HJx S(\HJx, \HJt_1, \dots, \HJt_N)$; \\
              $\HJu^*(s) \in \argmax_{\HJu\in\R^m} \{\langle -f_i(\HJu), \HJmom^*\rangle - L_i(\HJu)\},$ \\ $ s \in \left(\sum_{j=1}^{i-1}\HJt_j, \sum_{j=1}^{i}\HJt_j\right]$
         \end{tabular} \\
         \hline
         \begin{tabular}{c}
              data fitting weights $\param_i$
         \end{tabular} & \begin{tabular}{c}
              time $\HJt_i$ 
         \end{tabular} & \begin{tabular}{c}
              piecewise time horizons $T_j$ 
         \end{tabular} & \begin{tabular}{c}
              $\param_i = \HJt_i, i = 1, \dots, \numt$; \\ $T_j = \sum_{i=1}^j \HJt_i, j = 0, \dots, \numt$
         \end{tabular}\\
         \hline
         \begin{tabular}{c}
              data fitting loss \\ $\lossfunc_i(\mathcal{A}F(\bz_i;\cdot), \by_i)$
         \end{tabular} & \begin{tabular}{c}
              Hamiltonian $\Hamiltonian_i(\cdot)$ 
         \end{tabular} & \begin{tabular}{c}
              running cost $L_i(\HJu)$, \\ dynamics $f_i(\HJu)$ 
         \end{tabular} & \begin{tabular}{c}
              $\lossfunc_i(\mathcal{A}F(\bz_i;\cdot), \by_i) = \Hamiltonian_i(\cdot) =$ \\ $\sup_{\HJu\in\R^m} \{\langle -f_i(\HJu), \cdot\rangle - L_i(\HJu)\}$
         \end{tabular}\\
         \hline
         \begin{tabular}{c}
              regularization $\regfunc(\cdot)$
         \end{tabular} & \begin{tabular}{c}
              initial data $\HJIC(\cdot)$, \\ spatial variable $\HJx$
         \end{tabular} & \begin{tabular}{c}
              terminal cost $\HJIC(\cdot)$, \\ initial position $\HJx$
         \end{tabular} & \begin{tabular}{c}
              $\regfunc(\HJmom) = \HJIC^*(\HJmom) - \langle \HJx,\HJmom\rangle + c(\HJx)$, \\ where $c(\HJx)$ is a constant (possibly 0) \\ that may depend on $\HJx$
         \end{tabular}\\
         \hline
         \begin{tabular}{c}
              \# of learnable \\ parameters $n$
         \end{tabular} & \begin{tabular}{c}
              spatial dimension $n$
         \end{tabular} & \begin{tabular}{c}
              dimension of \\ state space $n$
         \end{tabular} & \begin{tabular}{c}
              same number $n$
         \end{tabular} \\
         \hline
         \begin{tabular}{c}
              \# of data points $N$
         \end{tabular} & \begin{tabular}{c}
              \# of times $N$
         \end{tabular} & \begin{tabular}{c}
              \# of time intervals $N$
         \end{tabular} & \begin{tabular}{c}
              same number $N$
         \end{tabular} \\
         \hline
         \begin{tabular}{c}
              dimension of measured data $m$ \\ (e.g., $\mathcal{A}F(\cdot;\weightvec), \by_i\in \R^m$)
         \end{tabular} & \begin{tabular}{c}
              Hamiltonian $H_i(\cdot)$
         \end{tabular} & \begin{tabular}{c}
              dimension of \\ control space $m$
         \end{tabular} & \begin{tabular}{c}
              $\Hamiltonian_i(\cdot) =\sup_{\HJu\in\R^m} \{\langle -f_i(\HJu), \cdot\rangle - L_i(\HJu)\}$
         \end{tabular}
    \end{tabular}
    \end{adjustbox}
    \caption{\updateone{Glossary of the mathematical relations between the quantities in the regularized learning problem~\eqref{eqt:general_learning}, the multi-time HJ PDE~\eqref{eqt:multitimeHJPDE}, and the associated optimal control problem~\eqref{eqt:optimal_control_standardform}. These mathematical relations allow us to form our theoretical connection in Section~\ref{sec:general_connection_Hopf}. Note that the variables $\HJx, \HJt$ in the HJ PDE become hyper-parameters in the learning problem, and we can treat them as constants when optimizing the learning problem~\eqref{eqt:general_learning} with respect to $\weightvec = \HJmom$.}}
    \label{tab:glossary}
\end{table}


\section{A more general version of LQR}\label{appendix:general_LQR}
In Section~\ref{sec:intro_LQR}, we presented a concise overview of the LQR problem in its canonical form. However, this paper establishes a linkage between regression problems and LQR problems with lower-order terms. Thus, in this section, we discuss an LQR problem with lower-order terms that more closely aligns with those used to establish our connections. We note that the notation employed in this section differs slightly from the notation utilized in the main body of the paper. The finite-horizon, continuous-time LQR with lower-order terms can be expressed as follows:
\begin{multline}\label{eqt:LQR_general_lower_order}
    S(\HJx,\HJt) = \min_{\HJu(\cdot)} \Bigg\{\int_0^\HJt \Big(\frac{1}{2}\bx(s)^T\LQRxx\bx(s) + \frac{1}{2}\HJu(s)^T\LQRuu\HJu(s) + \bx(s)^T\LQRxu\HJu(s) \\
    - \LQRu^T\bu(s) - \LQRx^T\bx(s) \Big) ds  + \frac{1}{2}\bx(\HJt)^T\LQRTC\bx(\HJt) + \LQRTx^T \bx(\HJt): \\
    \dot\bx(s) = \LQRA\bx(s) + \LQRB\HJu(s) \forall s\in(0,t], \bx(0) = \HJx\Bigg\},
\end{multline}
where $\LQRxx, \LQRTC \in\R^{n\times n}$ and $\LQRuu\in\R^{m\times m}$ are symmetric positive definite, $\LQRxu\in\R^{n\times m}$, $\LQRA\in\R^{n\times n}$, $\LQRB\in\R^{n\times m}$, $\LQRx,\LQRTx\in \Rn$, and $\LQRu\in\R^m$. The corresponding HJ PDE is 
\begin{equation}
    \begin{dcases}
    \frac{\partial S(\HJx,\HJt)}{\partial \HJt} + \Hamiltonian(\HJx,\nabla_\HJx S(\HJx,\HJt)) = 0 & \HJx\in\R^n, \HJt > 0, \\
    S(\HJx,0) = \HJIC(\HJx)  & \HJx\in\R^n,
    \end{dcases}
\end{equation}
where the initial data of the HJ PDE is given by the terminal cost $\HJIC(\HJx) := \frac{1}{2}\HJx^T\LQRTC\HJx + \LQRTx^T \bx$ of the optimal control problem~\eqref{eqt:LQR_general_lower_order} and the Hamiltonian $\Hamiltonian$ is defined by
\begin{equation}
    \begin{aligned}
    \Hamiltonian&(\HJx,\HJmom)  = \sup_{\HJu\in\R^m} \langle -f(\HJx,\HJu), \HJmom \rangle - L(\HJx,\HJu) \\
     &=  -\langle \LQRA\HJx, \HJmom\rangle - \frac{1}{2}\langle \HJx, \LQRxx\HJx\rangle + \LQRx^T \bx+ \frac{1}{2}\langle \LQRB^T\HJmom + \LQRxu^T\HJx - \LQRu, \LQRuu^{-1}(\LQRB^T\HJmom + \LQRxu^T\HJx  - \LQRu) \rangle,
    \end{aligned}
\end{equation}
where $f(\HJx,\HJu) = \LQRA\HJx + \LQRB\HJu$ is the source term of the dynamics and $L(\HJx,\HJu) = \frac{1}{2}\HJx^T\LQRxx\HJx + \frac{1}{2}\HJu^T\LQRuu\HJu + \HJx^T\LQRxu\HJu - \LQRu^T \bu - \LQRx^T \bx$ is the running cost.



It is well-known that this LQR problem can be solved using the Riccati equation as follows. Define $\Cpp = \LQRB \LQRuu^{-1}\LQRB^T$, $\Cxx = -\LQRxu\LQRuu^{-1}\LQRxu^T + \LQRxx$, $\Cxp = \LQRA - \LQRB \LQRuu^{-1}\LQRxu^T$, $\Cx = \LQRx - \LQRxu \LQRuu^{-1}\LQRu$, and $\Cp = \LQRB\LQRuu^{-1} \LQRu$. 
Then, the solution is given by
$S(\HJx,\HJt) = \frac{1}{2} \HJx^T \Sxx(\HJt)\HJx + \Sx(\HJt)^T\HJx + \Sc(\HJt)$, 
where the function $\Sxx: [0,\infty)\to\R^{n\times n}$ which takes values in the space of symmetric positive definite matrices, $\Sx\colon [0,+\infty)\to\Rn$, and $\Sc\colon[0,+\infty)\to\R$ solve the following Riccati ODE system:
\begin{equation} 
{\small
    \begin{dcases}
    \dot{\Sxx}(\HJt) =  -\Sxx(\HJt)^T\Cpp\Sxx(\HJt) + \Sxx(\HJt)^T\Cxp + \Cxp^T\Sxx(\HJt) + \Cxx &\HJt\in(0,+\infty),\\
    \dot{\Sx}(\HJt) = -\Sxx(\HJt)^T \Cpp \Sx(\HJt) + \Cxp^T \Sx(\HJt) - \Cx + \Sxx(\HJt)^T \Cp &\HJt\in(0,+\infty),\\
    \dot{\Sc}(\HJt) = -\frac{1}{2}\|\LQRuu^{-1/2}(\LQRB^T\Sx(\HJt) - \LQRu)\|^2 &\HJt\in(0,+\infty),\\
    \Sxx(0) = \LQRTC, \Sx(0) = \LQRTx, \Sc(0) = 0.
    \end{dcases}
    }
\end{equation}



\section{Details of the methodology}
\subsection{Algorithm for deleting one data point} \label{appendix:method_delete_data}
Here, we provide details for the algorithm for deleting one data point from Section~\ref{subsec:method_2}.
Removing the $j$-th data point corresponds to removing the term $\frac{1}{2}\lambda_{j}\|\Phi_{j} \weightvec - \MLy_{j}\|_2^2 $ in the loss function~\eqref{eq:loss_function} or, equivalently, removing the Hamiltonian $\frac{1}{2}\|\Phi_{j} \weightvec - \MLy_{j}\|_2^2$ from the multi-time HJ PDE and removing the pieces $L_{j}(s, \HJu) = \frac{1}{2}\HJu^T\HJu - \MLy_{j}$ and $f(s,\HJu) = \Phi_{j}^T\HJu$ from the running cost and dynamics, respectively, of the corresponding piecewise LQR problem.
Hence, numerically, we can remove the $j$-th data point by solving the following Riccati ODE
\begin{equation}\label{eqt:regression_2Riccati}
    \begin{dcases}
    \dot{\tilde\Sxx}(\HJt) =  -\tilde\Sxx(\HJt)^T\MLbasismat_{j}^T\MLbasismat_{j}\tilde\Sxx(\HJt) &\HJt<\lambda_j,\\
    \dot{\tilde\Sx}(\HJt) = -\tilde\Sxx(\HJt)^T\MLbasismat_{j}^T(\MLbasismat_{j}\tilde\Sx(\HJt) - \MLy_{j})&\HJt<\lambda_j
    \end{dcases}
\end{equation}
with terminal condition $\tilde\Sxx(\lambda_j) = \Sxx\left(T_N\right)$ and $\tilde\Sx(\lambda_j) = \Sx\left(T_N\right)$, where $\Sxx\left(T_N\right)$ and $\Sx\left(T_N\right)$ are obtained from solving the learning problem~\eqref{eq:loss_function} with all $N$ data points. Then, the solution to the new learning problem with the $j$-th point removed is given by~\eqref{eqt:sec42_newoptimizer}, where $\tilde\Sxx = \tilde\Sxx(0)$ and $\tilde \Sx = \tilde \Sx(0)$ are the solution to~\eqref{eqt:regression_2Riccati}.


\subsection{Algorithm for tuning the regularization weights}\label{appendix:hyperparam_tuning}
Here, we provide details for the algorithm for \updatetwo{tuning the regularization weights} from Section~\ref{subsec:method_3}.
We consider the case where we change each regularization parameter $\MLreg_k$ to $\tilde\MLreg_k$. This change can be regarded as two steps: first, we change all parameters $\MLreg_k$ for the indices $k$ such that $\tilde\MLreg_k > \MLreg_k$, and then we change the other parameters. Define the index set $\mathcal{K} $ to be $\mathcal{K} = \{k\colon \tilde\MLreg_k > \MLreg_k\}$. 

The first step is equivalent to adding the term $\sum_{k\in \mathcal{K}}\frac{\tilde\MLreg_k - \MLreg_k}{2}(\weight_k - \MLcenter_k)^2$ to the loss function~\eqref{eq:loss_function}. We can interpret this as adding an $(N+1)$-th Hamiltonian $\frac{1}{2}\weightvec^T\MLregmat_{+}\weightvec$ with corresponding time variable $\HJt_{N+1} = 1$ to the multi-time HJ PDE, where $\MLregmat_+$ is a diagonal matrix whose $k$-th diagonal element is $\tilde\MLreg_k - \MLreg_k$ if $k\in\mathcal{K}$ and $0$ otherwise.
Therefore, the solution to this new multi-time HJ PDE can be solved by the following Riccati equation:
\begin{equation}\label{eqt:riccati_increase_regweight}
\begin{dcases}
\dot{\Sxx}_+(\HJt) =  -\Sxx_+(\HJt)^T\MLregmat_+\Sxx_+(\HJt) &\HJt\in \left(0,1\right),\\
\dot{\Sx}_+(\HJt) = -\Sxx_+(\HJt)^T\MLregmat_+\Sx_+(\HJt)&\HJt\in \left(0, 1\right),
\end{dcases}
\end{equation}
with initial condition $\Sxx_+(0)$ and $\Sx_+(0)$, which are the corresponding solutions to the Riccati equations before changing the weights $\MLreg_k, k\in\mathcal{K}$. In other words, we set $\Sxx_+(0) = \Sxx\left(T_N\right)$ and $\Sx_+(0) = \Sx\left(T_N\right)$, where $\Sxx(T_N), \Sx(T_N)$ are obtained from solving the original learning problem~\eqref{eq:loss_function} with the original values of $\MLreg_k$.

The second step is equivalent to removing the term $\sum_{k\not\in\mathcal{K}}\frac{\MLreg_k - \tilde\MLreg_k}{2}(\weight_k - \MLcenter_k)^2$ from the loss function~\eqref{eq:loss_function}. This is equivalent to solving a single-time HJ PDE with a terminal condition at time $1$ and Hamiltonian $\frac{1}{2}\weightvec^T\MLregmat_{-}\weightvec$, where $\MLregmat_-$ is a diagonal matrix whose $k$-th diagonal element is $\MLreg_k - \tilde\MLreg_k$ if $k\not\in\mathcal{K}$ and $0$ otherwise.
Then, the solution can be obtained by solving the following Riccati equation:
\begin{equation}\label{eqt:riccati_decrease_reg_weight}
\begin{dcases}
\dot{\Sxx}_-(\HJt) =  -\Sxx_-(\HJt)^T\MLregmat_-\Sxx_-(\HJt) &\HJt\in \left(0,1\right),\\
\dot{\Sx}_-(\HJt) = -\Sxx_-(\HJt)^T\MLregmat_-\Sx_-(\HJt)&\HJt\in \left(0, 1\right)
\end{dcases}
\end{equation}
with terminal condition $\Sxx_-(1) = \Sxx_+(1)$ and $\Sx_-(1) = \Sx_+(1)$, where $\Sxx_+, \Sx_+$ are obtained from the solution to~\eqref{eqt:riccati_increase_regweight}.

Finally, the minimizer of the new learning problem after changing all of the weights $\MLreg_k$ in the regularization term is given by ${\Sxx}_-(0) \tilde\MLregmat \MLcentervec+ {\Sx}_-(0)$, where ${\Sxx}_-, {\Sx}_-$ are obtained from the solution to~\eqref{eqt:riccati_decrease_reg_weight} and $\tilde\MLregmat$ is a diagonal matrix whose $k$-th diagonal element is the new regularization parameter $\tilde\MLreg_k$.

\section{Computational complexity of the methodology}\label{appendix:comp_complexity}
\updatethree{In this section, we compare the computational complexity of our Riccati-based methodology (using RK4) from Section~\ref{sec:method} to that of the method of least squares.}

\subsection{Initial training}\label{sec:computational_complexity_initial_training}
\updatethree{First, we consider solving the learning problem~\eqref{eq:loss_function} with $N$ points, which may be considered as an initial training step with $N$ data points.}

\updatethree{In this case, our Riccati-based methodology requires us to solve a sequence of $N$ Riccati ODEs of the form~\eqref{eqt:sequentialRiccatiODEs}. Using RK4 to solve each ODE involves computing $\Phi_i^T\Phi_i$ (recall that $\Phi_i\in\R^{m\times n}$), which requires $O(mn^2)$ operations, and multiplying several $n\times n$ matrices together, which requires $O(n^3)$ operations. In other words, solving one step of Riccati ODEs (i.e., adding one data point to our training set) requires $O(mn^2 + n^3)$ operations. Thus, the overall computational complexity of our Riccati-based methodology for training on $N$ points is $O(Nmn^2 + Nn^3)$.}

\updatethree{In contrast, using the method of least squares to solve~\eqref{eq:loss_function} with $N$ points involves computing $\Phi_i^T\Phi_i$ for each point, which requires $O(mn^2)$ operations for each point or $O(Nmn^2)$ operations for all $N$ points, and then solving an $n\times n$ linear system, which requires $O(n^3)$ operations. Thus, the overall computational complexity of the method of least squares for training on $N$ points is $O(Nmn^2 + n^3)$.}

\updatethree{As expected, the method of least squares beats our Riccati-based methodology in this case, but as we discussed previously, our methodology is advantageous when changing the training set or hyper-parameters.}


\subsection{Continual learning} 
\updatethree{In this section, we discuss adding data points to the training set (as in Section~\ref{subsec:method_2}), where we update our learned models as soon as a new data point becomes available (e.g., as in continual learning). We consider the initial training set to have $N$ points and then sequentially incorporate $K$ more data points.}

\updatethree{As discussed in Section~\ref{sec:computational_complexity_initial_training}, adding one data point using our Riccati-based methodology requires $O(mn^2 + n^3)$ operations. Thus, the overall computational complexity of using our methodology to perform the initial training and then to retrain $K$ times is $O((N+K)mn^2 + (N+K)n^3)$. }
\updatethree{Adding the $i$-th data point using the method of least squares requires $O((N+i)mn^2 + n^3)$ operations. Thus, the overall computational complexity of using the method of least squares to perform the initial training and then to retrain $K$ times is $\sum_{i=0}^{K} O((N+i)mn^2 + n^3) = O((KN + K^2)mn^2 + Kn^3)$. }
\updatethree{Thus, our Riccati-based methodology becomes increasingly more advantageous over the method of least squares as the number of points added $K$ increases.}


\subsection{Tuning the bias}
\updatethree{As discussed in Section~\ref{subsec:method_3}, tuning the bias $\MLcentervec$ using our Riccati-based methodology is accomplished via the update~\eqref{eqt:minimizer_changeofbias}. This update only involves a matrix-vector multiplication (recall that $\Gamma$ is diagonal) and vector addition. Thus, tuning the bias using our methodology requires $O(n^2)$ operations. In contrast, tuning the bias using the method of least squares requires retraining on the entire dataset. Thus, if the training set has size $N$, then the computational complexity of the method of least squares in this case is $O(Nmn^2 + n^3)$. Hence, our methodology is much more efficient than the method of least squares in this case. Note that these same calculations also apply to using our methodology vs the method of least squares to perform the first step in each iteration of PDHG~\eqref{eq:pdhg}, which, as discussed previously, is equivalent to performing a change of bias.}


\section{Riccati ODEs and Recursive Least Squares}\label{sec:RLS}
In Section~\ref{subsec:method_2}, we discuss adding or removing data using our Riccati-based methodology. However, data points could also be added or removed incrementally using recursive least squares. In this section, we discuss the connections between our Riccati-based methodology and recursive least squares. Namely, we show that the recursive least squares method for this problem can be considered as a special case of our Riccati-based methodology. Note that in this section, we focus on adding data points, but the results for removing data points can be derived similarly. For generality, we consider the more general learning problem~\eqref{eqt:regression_multidata} in Section~\ref{sec:LQR_multiptregression}, and the results for the more specific learning problem in Section~\ref{subsec:method_2} can be recovered using the identifications listed in Section~\ref{subsec:method_1}.

The analytical solution to the Riccati ODEs~\eqref{eqt: odeP_piecewise},~\eqref{eqt: odeq_piecewise} is given by
\begin{equation*}
\Sxx_N = \left(\LQRTC^{-1} + \sum_{i=1}^N t_i\LQRB_i\LQRuu_i^{-1}\LQRB_i^T\right)^{-1}, 
\end{equation*}
\begin{equation*}
    \Sx_N = \left(\LQRTC^{-1} + \sum_{i=1}^N t_i\LQRB_i\LQRuu_i^{-1}\LQRB_i^T\right)^{-1}\left(\LQRTC^{-1}\bb + \sum_{i=1}^N t_i\LQRB_i\LQRuu_i^{-1} \ba_i\right),
\end{equation*}
where $\Sxx_N = \Sxx\left(\sum_{i=1}^N t_i\right)$ and $\Sx_N = \Sx\left(\sum_{i=1}^N t_i\right)$. 
Then, using the Woodbury matrix identity, the recursive least squares solution is given by
\begin{equation}\label{eq:RLS}
\begin{aligned}
    \Sxx_N &= \Sxx_{N-1} - t_N\Sxx_{N-1}\LQRB_N\left(\LQRuu_N + t_N\LQRB_N^T \Sxx_{N-1} \LQRB_N\right)^{-1}\LQRB_N^T\Sxx_{N-1}, \\
    \Sx_N &= \Sx_{N-1} + t_N\Sxx_N\LQRB_N\LQRuu_N^{-1}\ba_N - t_N\Sxx_{N-1}\LQRB_N\left(\LQRuu_N + t_N\LQRB_N^T \Sxx_{N-1} \LQRB_N\right)^{-1}\LQRB_N^T\Sx_{N-1}.
\end{aligned}
\end{equation}

\begin{prop}
    The recursive least squares solution~\eqref{eq:RLS} is a discretization of the Riccati ODEs~\eqref{eqt: odeP_piecewise},~\eqref{eqt: odeq_piecewise}.
\end{prop}

\begin{proof}
    We begin by proving the result for $\Sxx$. Let $\Sxx(\cdot)$ be the solution to the Riccati ODEs. Then $\Sxx(s)$ is invertible for all $s\in \left[0, \sum_{i=1}^N t_i\right]$, which gives us that 
    $\frac{d\Sxx^{-1}}{ds} = -\Sxx^{-1}\frac{d\Sxx}{ds}\Sxx^{-1}.$
    Plugging this identity into~\eqref{eqt: odeP_piecewise}, we have that
    \begin{equation}\label{eq:RLS_dPinv}
        \frac{d\Sxx^{-1}(s)}{ds} = \LQRB_i\LQRuu_i^{-1}\LQRB_i^T \quad s\in[T_{i-1}, T_i), \quad \Sxx^{-1}(0) = \LQRTC^{-1}.
    \end{equation}
    The solution to this ODE is given by 
    $$\Sxx^{-1}(s) = \LQRTC^{-1} + \sum_{j = 1}^i t_j\LQRB_j\LQRuu_j^{-1}\LQRB_j^T + (s - T_{i-1})\LQRB_i\LQRuu_i^{-1}\LQRB_i^T, \forall s\in[T_{i-1}, T_i), i = 0, \dots, N.$$
    If we only consider the values of $\Sxx^{-1}(s)$ at the discrete times $s = T_0, T_1, \dots, T_N$, then this solution can be defined recursively as 
    \begin{equation*}
        \Sxx^{-1}(T_i) = \Sxx^{-1}(T_{i-1}) + t_i\LQRB_i\LQRuu_i^{-1}\LQRB_i^T,
    \end{equation*}
    or, in other words,  we have that
    \begin{equation*}
    \Sxx(T_i) = (\Sxx^{-1}(T_{i-1}) + t_i\LQRB_i\LQRuu_i^{-1}\LQRB_i^T)^{-1}.
    \end{equation*}
    By applying the Woodbury matrix identity, we recover the recursive least squares solution for $\Sxx$ in~\eqref{eq:RLS}.
    Next, we prove the result for $\Sx$. Consider 
    \begin{equation*}\label{eq:RLS_dPinvq}
        \frac{d(\Sxx^{-1}\Sx)}{ds}(s) = \frac{d\Sxx^{-1}}{ds}\Sx + \Sxx^{-1}\frac{d\Sx}{ds} = \LQRB_i\LQRuu_i^{-1}\LQRB_i^T\Sx + \Sxx^{-1}\frac{d\Sx}{ds} = \LQRB_i\LQRuu_i^{-1}\ba_i
    \end{equation*}
    for $s\in[T_{i-1}, T_i)$ and with initial condition $(\Sxx^{-1}\Sx) (0) = -\LQRTC^{-1}\bb$, where the second equality follows from~\eqref{eq:RLS_dPinv} and the third equality follows from multiplying~\eqref{eqt: odeq_piecewise} by $\Sxx^{-1}$ on the left. Then, the solution to this ODE gives us that
    $$\Sx(s) = \Sxx(s)\Sxx^{-1}(T_{i-1})\Sx(T_{i-1}) + (s-T_{i-1})\Sxx(s)\LQRB_i\LQRuu_i^{-1}\ba_i,  \forall s\in[T_{i-1}, T_i), i = 0, \dots, N,$$
    which defines $\Sx(s)$ recursively. If we only consider the values of $\Sx(s)$ at the discrete times $s = T_0, T_1, \dots, T_N$, then using this recursive definition of $\Sx$ simplifies to
    \begin{equation*}
        \Sx(T_i) = \Sxx(T_i)\left(\Sxx^{-1}(T_{i-1})\Sx(T_{i-1}) + t_i\LQRB_i\LQRuu_i^{-1}\ba_i\right).
    \end{equation*}
    Finally, applying the recursive least squares solution for $\Sxx(T_i)$ in~\eqref{eq:RLS} to the definition of $\Sx(T_i)$ above gives us the recursive least squares solution for $\Sx$ in~\eqref{eq:RLS}.
\end{proof}

Thus, we have shown that the recursive least squares solution represents a special case (in the form of a discretization) of the Riccati ODEs, and hence, we may regard the recursive least squares update~\eqref{eq:RLS} as an alternative method for solving the Riccati ODEs~\eqref{eqt: odeP_piecewise},~\eqref{eqt: odeq_piecewise}, if we only care about the solution at the discrete times $s = T_0, \dots, T_N$. For instance, in Section~\ref{subsec:example_3}, we show how using more general numerical methods like RK4 naturally expose 1D curves along the Pareto front of solutions, which aligns with the Riccati ODEs as a continuous formulation; in contrast, the discretization used by the recursive least squares update would only allow for discrete points on the Pareto front. Moreover, we note that there are some cases in which recursive least squares is known to be numerically unstable~\cite{ljung1985error, liavas1998numerical, liavas1999numerical}, whereas Runge-Kutta methods have well-established stability and accuracy results \cite{butcher2016numerical}. 




\section{Additional results for example 2}\label{appendix:1}
In Section~\ref{subsec:example_2}, we consider a 1D steady-state reaction-diffusion equation~\eqref{eq:reaction} and discuss three different types of post-training calibrations: adding new data points to compensate for a lack of knowledge in the regular training, enforcing the fitting of some data points by increasing the weights $\lambda_i$ of their respective terms in the loss function~\eqref{eq:calibration:loss}, and removing some data points so that their  effects are eliminated. In this section, we present the results for the last case \updatethree{and then provide a large-scale continual learning example for solving~\eqref{eq:reaction}}. In Figure~\ref{fig:calibration:2}, we remove two outliers one-by-one and observe that their removal does successfully increase the accuracy of the learned model. Again, using our Riccati-based approach, the removal of these points is done using only knowledge about the point to be removed and the results of the previous training step. 

\begin{figure}[ht]
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width = 0.3\textwidth]{calibration/f_1_new.png}
        \includegraphics[width = 0.3\textwidth]{calibration/f_2_new.png}
        \includegraphics[width = 0.3\textwidth]{calibration/f_3_new.png}
        \caption{}
    \end{subfigure}
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width = 0.3\textwidth]{calibration/u_1_new.png}
        \includegraphics[width = 0.3\textwidth]{calibration/u_2_new.png}
        \includegraphics[width = 0.3\textwidth]{calibration/u_3_new.png}
        \caption{}
    \end{subfigure}
    \caption{Results of solving the 1D steady-state reaction-diffusion equation~\eqref{eq:reaction} with noisy measurements of the source term $f$ in the domain and noiseless measurements of the solution $u$ on the boundary. (a) results for $f$; (b) results for $u$. \textbf{Left}: results of regular training using our Riccati-based method in Section~\ref{subsec:method_1}; \textbf{middle} and \textbf{right}: calibrating the results of regular training by eliminating two outlier measurements of $f$ using the methodology described in Section~\ref{subsec:method_2}. Calibrations are employed without re-training or access to the data from the previous training.}
    \label{fig:calibration:2}
\end{figure}

\begin{table}[ht]
    \footnotesize
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
         & $N=100$ & $N=1000$ & $N=50000$ \\
       \hline
       Error of $u$ & $72.59\%$ & $22.55\%$ & $1.76\%$\\
       \hline
       Error of $f$ & $89.65\%$ & $29.76\%$ & $3.35\%$\\
       \hline
    \end{tabular}
\caption{Errors of $u$ and $f$ when solving the 1D steady-state reaction-diffusion equation \eqref{eq:reaction} with different numbers $N$ of noisy measurements of $f$ using our Riccati-based approach. The errors represent the relative $L^2$ errors on a uniform grid of $[0, 1]$. New measurements are incorporated following the continual learning framework, and, using our Riccati-based methodology, incorporating new data points does not require retraining on or access to any of the previous data points. Qualitative results can be found in Figure \ref{fig:example_2:3}.}
\label{tab:example_2:2}
\end{table}

\begin{figure}[ht]
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width = 0.3\textwidth]{example_2_new/f_1.png}
        \includegraphics[width = 0.3\textwidth]{example_2_new/f_2.png}
        \includegraphics[width = 0.3\textwidth]{example_2_new/f_3.png}
        \caption{}
    \end{subfigure}
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width = 0.3\textwidth]{example_2_new/u_1.png}
       \includegraphics[width = 0.3\textwidth]{example_2_new/u_2.png}
       \includegraphics[width = 0.3\textwidth]{example_2_new/u_3.png}
        \caption{}
    \end{subfigure}
    \caption{Continual learning of the source term $f$ and solution $u$ to the 1D steady-state reaction-diffusion equation~\eqref{eq:reaction} our Riccati-based approach as more data becomes available. Measurements of the source term $f$ are corrupted by additive Gaussian noise with noise scale two. Our Riccati-based approach allows us to incrementally update the learned coefficients as more data becomes available without requiring access to the previous data or re-training on the entire dataset, which provides advantages in both memory and computations over conventional learning methods.}
    \label{fig:example_2:3}
\end{figure}

Next, we provide a large-scale continual learning example for solving the 1D steady-state reaction-diffusion equation~\eqref{eq:reaction}. Similar to Section \ref{subsec:example_1}, the measurements of the source term $f$ are corrupted by additive Gaussian noise with a relatively large noise scale. Hence, we need a large amount of data to solve~\eqref{eq:reaction} accurately. We again follow the continual learning setup and assume that the measurements of $f$ must be accessed in a stream, such that the historical data is not available after it is incorporated into our learned model. Specifically, each new data point of $f$ comes from uniformly randomly sampling a point $x\in[0, 1]$ and is corrupted by additive Gaussian noise with noise scale two. The same basis functions and loss function listed in Section~\ref{subsec:example_2} are used in this case. The results are presented in Figure \ref{fig:example_2:3} and Table \ref{tab:example_2:2}. We observe that the accuracy of our inferences of $u$ and $f$ is improved continuously as new measurements of $f$ are incorporated. This process does not require storage or use of historical data, which again highlights the computational and memory advantages of our Riccati-based approach.






\section{Details of the hyper-parameters in the numerical examples}\label{sec:details}
\updatetwo{In this section, we include additional details of the numerical examples from Section~\ref{sec:numerics}. Recall that RK4 is used to numerically solve the associated Riccati ODEs. The step size of RK4, denoted as $h$, is chosen based on three principles: high accuracy, efficient computations, and avoiding computational overflow. Unless otherwise stated, we use Python, the NumPy library \cite{harris2020array}, the TensorFlow library \cite{tensorflow2015-whitepaper}, and double precision in all of the numerical examples.}

\updatetwo{In the first example (Section~\ref{subsec:example_1}), $\lambda_i=1, \forall i$, $\MLreg_k=0.1, \forall k$, and the step size $h$ of RK4 is set to be $0.001, 0.0005, 0.0001$. A uniform grid with size $1001$ on $[0, 10]$ is used for evaluation (computing relative $L^2$  error). 
In the second example (Section~\ref{subsec:example_2}), we change $\lambda_b$ from $1$ to $10$ and the rest of the hyper-parameters remain the same as the regular training. The time step of RK4 is $h=0.0001$. A uniform grid with size $257$ on $[0, 1]$ is used for evaluation.
In the third example (Section~\ref{subsec:example_3}), the multi-head PINN used to obtain the basis functions has three hidden layers, each of which is equipped with hyperbolic tangent activation functions and $100$ neurons. The multi-head PINN is trained with the Adam optimizer \cite{kingma2014adam}, where the learning rate is $1\times 10^{-3}$ and the other hyperparameters are set to their default TensorFlow values. The training data for $f$ are evaluated on a $33\times 33$ uniform grid on $[0, 1]^2$ and the inference of $u$ is evaluated on a $257\times 257$ uniform grid.
The results of the regular training are obtained using $\lambda_i=1, \forall i$, $\MLreg_k=1, \forall k$, and $h=0.001$. When tuning $\MLreg$ and visualizing the Pareto front, we use the values of $\MLreg$ and the step size $h$ of RK4 listed in Table~\ref{tab:hyperparameter}. In the last example (Section~\ref{subsec:example_4}), we set $\lambda_i=1, \forall i$, $\MLreg_k=0.1, \forall k$, and $h=0.001$. In our implementation of the PDHG method, we set $\sigma_\weightvec = \sigma_{\pdhgdual} = 0.5$. The solution $x_1, x_2, x_3$ of the system identified is evaluated on a uniform grid of $10001$ on $[0, 10]$.}

\begin{table}[ht]
    \footnotesize
    \centering
    
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    $\MLreg$ & $1\rightarrow 10^{-1}$ & $10^{-1}\rightarrow 10^{-2}$ & $10^{-2}\rightarrow 10^{-3}$ & $10^{-3}\rightarrow 10^{-4}$ & $10^{-4}\rightarrow 10^{-5}$ \\
    \hline
    $h$ & $10^{-2}$ & $10^{-3}$ & $10^{-4}$ & $10^{-6}$ & $10^{-7}$ \\
    \hline
    \end{tabular}
    \caption{\updatetwo{Step size $h$ of RK4 when tuning $\MLreg$ in the hyper-parameter tuning/Pareto front visualization example in Section~\ref{subsec:example_3}. $\MLreg_0 \rightarrow \MLreg_1$ represents the case when tuning $\MLreg$ from $\MLreg_0$ to $\MLreg_1$. }}
    \label{tab:hyperparameter}
\end{table}


