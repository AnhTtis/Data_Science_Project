\section{Summary}\label{sec:conclusion}
In this paper, we established a novel theoretical connection between certain learning problems and the multi-time Hopf formula. In doing so, we showed that when we solve certain learning problems, we actually solve certain multi-time HJ PDEs and their corresponding optimal control problems. In this work, we focused on the development of the connection between regularized linear regression and the LQR problem. By leveraging this novel connection, we developed new methodology based on solving Riccati ODEs that allows us to design novel training approaches for certain machine learning applications, including continual learning, post-training calibration, hyper-parameter tuning and exploration of the associated Pareto front, and sparse dynamics identification. We also showed that our Riccati-based approach yields some promising computational advantages over conventional learning methods; after the original training, the models learned using our approach can be continually updated without having to retrain the entire model or having access to all of the previous data, which could be particularly useful in continual learning \cite{parisi2019continual, kirkpatrick2017overcoming, van2019three} and federated learning \cite{li2020federated, kairouz2021advances}.

Thus, our novel theoretical connection and our Riccati-based methodology present many exciting opportunities. Some possible future directions are as follows. While our Riccati-based methodology allows us to alter the hyper-parameters and data points used in the learning problem without having to retrain on all previous data, it also requires that the original training be done using our Riccati-based methodology. It would allow for increased versatility if we could more easily combine our Riccati-based approach with other training methods. 
Additionally, in Sections~\ref{subsec:method_4} and~\ref{subsec:example_4}, we showed that our Riccati-based approach allows computations to be reused when using non-quadratic regularizations. However, in this case, the training process still had to be restarted if the hyper-parameters, dataset, or regularization type is changed. It would allow for more flexibility if we could develop more adaptive processes for changing these aspects of the learning problem when the regularization is not quadratic. 

In Section~\ref{sec:LQR}, we focused on LQR problems, where the dynamics are independent of the trajectory, but it would be worthwhile to investigate what connections LQR problems with  general linear dynamics may yield (e.g., LQR problems with general linear dynamics may be reformulated as LQR problems with state-independent dynamics using a change of variable \cite{Darbon2016Algorithms}). 
Another natural extension would be to consider nonlinear models, which currently pose challenges in both scientific machine learning and optimal control and hence, connections drawn in this case would benefit both fields.
Alternatively, if we relax our assumption on convexity by allowing for nonconvex loss functions (or equivalently, nonconvex Hamiltonians), we could also extend our connection to be between learning problems and differential games \cite{evans1984differentialgames} instead of optimal control. However, even with convex losses, there are already many interesting potential applications in machine learning to pursue. For example, the theoretical connection presented in Section~\ref{sec:general_connection_Hopf} provides a formula for the optimal learning parameters $\weightvec^*$ in terms of the hyper-parameters. This connection could be leveraged to simplify the bi-level optimization in meta-learning applications to a single-level, constrained optimization problem. As another example, we could generalize our theory to instead consider the viscous HJ PDE, which adds a Laplacian term to the right-hand side of the HJ PDEs~\eqref{eqt:singletimeHJPDE} and~\eqref{eqt:multitimeHJPDE}. Then, by leveraging the recently established connection between viscous HJ PDEs and Bayesian modeling \cite{langlois2021HJvariational}, we could extend our work to applications in Bayesian inference.

