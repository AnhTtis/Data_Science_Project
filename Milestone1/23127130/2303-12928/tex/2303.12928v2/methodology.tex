\section{Methodology}\label{sec:method}
In the previous section, we established a novel theoretical connection between certain multi-time HJ PDEs, LQR problems, and regularized linear regression problems. In this section, we leverage this theoretical connection to design novel algorithms for solving various learning problems.
The connection between the learning problem of interest, the Hopf formula, and the corresponding optimal control problem is summarized in Figure~\ref{fig:connection_Riccati_learning} and Table~\ref{tab:learning_problems}.

\subsection{Solving the regularized linear regression problem using Riccati ODEs}\label{subsec:method_1}
\begin{figure}[htbp]
    \centering
\begin{adjustbox}{width=\textwidth}
\begin{tikzpicture}[node distance=2cm]
    \node (min) [nobox, yshift=-0.2cm] {$\min$};
    \node (minarg) [boxsmall, right of=min, xshift=-1.5cm, yshift=-0.37cm, draw=cyan!60, fill=cyan!5] {$\text{}_{\weightvec\in\weightspace}$};
    \node (sum) [nobox, right of=minarg, xshift=-1.0cm] {$\sum_{i=1}^\numt$};
    \node (param) [box, right of=sum, xshift=-0.7cm, draw=magenta!60, fill=magenta!5] {$\param_i$};
    \node (loss) [box, right of=param, xshift=0.3cm, draw=green!60, fill=green!5] {$\frac{1}{2}\left\|\Phi_i \weightvec - \MLy_i\right\|_2^2$ };
    \node (plus) [nobox, right of=loss, xshift=0.55cm] {$+$};
    \node (regLeft) [nobox, right of=loss, xshift=2.4cm] {};
    \node (regularization) [box, right of=regLeft, xshift=-0.5cm, draw=blue!60, fill=blue!5] { $\frac{1}{2}\sum_{k=1}^n\MLreg_k (\weight_k - \MLcenter_k)^2$};
    \node (regRight) [nobox, right of=regularization, xshift=-0.1cm] {};
    
    \node (sup) [nobox, below of=min, xshift=-0cm] {$\min$};
    \node (suparg) [boxsmall, right of=sup, xshift=-1.5cm, yshift=-0.37cm, draw=cyan!60, fill=cyan!5] {$\text{}_{\HJmom\in\HJstatespace}$};
    \node (sum) [nobox, below of=sum] {$\sum_{i=1}^\numt$};
    \node (time) [box, below of=param, xshift=-0cm, draw=magenta!60, fill=magenta!5] {$\HJt_i$};
    \node (equals) [nobox, left of=sup, xshift=1.45cm] {$=$};
    \node (S) [box, left of=equals, xshift=0.1cm, draw=red!60, fill=red!5] {$S(\MLregmat\MLcentervec, \HJt_1, \dots, \HJt_\numt)$};
    \node (minus2) [nobox, left of=S, xshift=0.15cm] {$-$};
    \node (Hamiltonian) [box, below of=loss, draw=green!60, fill=green!5] {$\frac{1}{2}\left\|\Phi_i \HJmom - \MLy_i\right\|_2^2$};
    \node (plus2) [nobox, right of=Hamiltonian,xshift=0.15cm] {$+$};
    \node (IC) [box, below of=regLeft, draw=blue!60, fill=blue!5] {$\frac{1}{2}\left\|\MLregmat^{1/2}\HJmom\right\|_2^2$};
    \node (linear) [box, below of=regRight, draw=blue!60, fill=blue!5] {$-\langle \MLregmat\MLcentervec, \HJmom\rangle$};

    \node (OCmin) [nobox, below of=sup, yshift=-0.3cm] {$\min$};
    \node (OCS) [box, below of=S, xshift=0cm, yshift=-0.35cm, draw=red!60, fill=red!5] {$S(\MLregmat\MLcentervec, \HJt_1, \dots, \HJt_\numt)$};
    \node (OCequals) [nobox, below of=equals, xshift=0cm, yshift=-0.35cm] {$=$};
    \node (OCint) [nobox, below of=time, xshift=-1.1cm] {$\sum_{i=1}^\numt \int_{\sum_{j=1}^{i-1}\HJt_j}^{\sum_{j=1}^{i}} $};
    \node (OCt) [boxsmall, right of=OCint, xshift=-0.9cm, yshift=0.2cm, draw=magenta!60, fill=magenta!5] {$\text{}^{\HJt_j}$};
    \node (OCHamiltonian) [box, below of=Hamiltonian, xshift=-0cm, draw=green!60, fill=green!5] {$\left(\frac{1}{2}\HJu(s)^T\HJu(s) -\MLy_i^T\HJu(s)\right)$};
    \node (OCds) [nobox, right of=OCHamiltonian, xshift=0.15cm] {$ds$};
    \node (OCplus) [nobox, right of=OCds, xshift=-1.6cm] {$+$};
    \node (OCIC) [box, below of=IC, draw=blue!60, fill=blue!5] {$\frac{1}{2}\bx(T_\numt)^T\MLregmat^{-1}\bx(T_\numt)$};
    \node (OCdynam) [box, right of=OCIC, xshift=2.25cm, draw=green!60, fill=green!5] {$\dot\bx(s) = \Phi_i^T\HJu(s)\forall s\in \left(T_{i-1}, T_i\right]$};
    \node (OCinitialposition) [box, right of=OCdynam, xshift=1.85cm, draw=blue!60, fill=blue!5] {$\bx(0) = \MLregmat\MLcentervec$};
    \node (leftbracket) [nobox, left of=OCint, xshift=0.8cm] {$\Bigg\{$};
    \node (colon) [nobox, right of=OCIC, xshift=-0.3cm] {$:$};
    \node (comma) [nobox, right of=OCdynam, xshift=0.5cm, yshift=-0.11cm] {,};
    \node (rightbracket) [nobox, right of=OCinitialposition, xshift=-0.7cm] {$\Bigg\}$};

    \node (LPequal) [nobox, above of=equal] {$=$};
    \node (minloss) [box, above of=S, draw=red!60, fill=red!5] {$\min_{\weightvec\in\weightspace}\mathcal{L}(\weightvec)$};
    \draw [dottedarrow] (S) -- (minloss);
    
    \draw [doublearrow] (loss) -- (Hamiltonian);
    \draw [dottedarrow] (regularization) -- (IC);
    \draw [dottedarrow] (regularization) -- (linear);
    \draw [doublearrow] (minarg) -- (suparg);
    \draw [doublearrow] (OCS) -- (S);
    \draw [doublearrow] (OCt) -- (time);
    \draw [dottedarrow] (OCHamiltonian) -- ++(0,1.5cm);
    \draw [dottedarrow] (OCIC) -- (IC);
    \draw [dottedarrow] (OCdynam) -- (Hamiltonian);
    \draw [doublearrow] (time) -- (param);
    \draw [dottedarrow] (linear) -- (OCinitialposition);
\end{tikzpicture}
\end{adjustbox}
    \caption{(See Section~\ref{sec:method}) Mathematical formulation describing the connection between our model linear regression problem with quadratic regularization (\textbf{top}), the multi-time Hopf formula (\textbf{middle}), and a piecewise LQR problem (\textbf{bottom}). Note that $T_i = \sum_{j=1}^i t_j$. The content of this illustration is a special case of the connection in Figure~\ref{fig:connection_LQR} using $\LQRuu_i = I$, $B_i = \Phi_i^T$, $\ba_i = \MLy_i$, $\LQRTC = \MLregmat^{-1}$, $\bb = 0$, and $\HJx = \MLregmat\MLcentervec$. We use this connection to develop our Riccati-based methodology (Section~\ref{sec:method}) and perform our numerical examples (Section~\ref{sec:numerics}). The colors indicate the associated quantities between each problem. The solid-line arrows denote direct equivalences. The dotted arrows represent additional mathematical relations.}
    \label{fig:connection_Riccati_learning}
\end{figure}

\begin{table}[ht]
    \footnotesize
    \centering
    \begin{adjustbox}{width=\textwidth}
    \begin{tabular}{c|c|c|c}
    \hline\hline
        \begin{tabular}{c}
            \textbf{Terms in the} \\ \textbf{loss function~\eqref{eq:loss_function}}
        \end{tabular} & \begin{tabular}{c}
            \textbf{Terms in the} \\ \textbf{Hopf formula}
        \end{tabular} & \begin{tabular}{c}
            \textbf{Terms in the optimal} \\
            \textbf{ control problem}
        \end{tabular} & \textbf{Learning problems} \\
        \hline
        $\Phi_i, \MLy_i$ & Hamiltonian & Running cost, dynamics & \begin{tabular}{c}
            Continual learning (Section~\ref{subsec:example_1}); \\ Post-training calibration (Section~\ref{subsec:example_2})
        \end{tabular} \\
        \hline
        $\param_i$ & Time & Time & Post-training calibration (Section~\ref{subsec:example_2})\\
        \hline
        $\MLreg_k$ & \begin{tabular}{c}
            Hamiltonian; \\ Initial condition
        \end{tabular}
        & \begin{tabular}{c}
            Running cost, dynamics; \\ Terminal cost
        \end{tabular} & \begin{tabular}{c}
        Hyper-parameter tuning, \\ flow along the Pareto front (Section~\ref{subsec:example_3}) 
        \end{tabular} \\
         \hline
        $\MLcenter_k$ & Spatial variable & Initial position & Generalized regularization functions (Section~\ref{subsec:example_4}) \\
        \hline \hline
    \end{tabular} 
    
    \end{adjustbox}
    \caption{Summary of the learning problems and corresponding numerical examples presented in this work. Each row summarizes which terms in the loss function~\eqref{eq:loss_function}, the Hopf formula, and the optimal control problem must be changed to match the context of various learning problems.}
    \label{tab:learning_problems}
\end{table}


A linear regression problem with quadratic data fitting loss and quadratic regularization is formulated as follows. 
The goal of this learning problem is to fit $N$ data points $(\bz_i, \MLy_i)\in\R^m\times\R^M$ with the linear prediction model $\Phi_i \weightvec\approx \MLy_i$, where $\Phi_i = [\phi_1(\bz_i), ..., \phi_n(\bz_i)]\in\R^{M\times n}$ is the matrix whose columns are the basis functions $\phi_j:\R^m\to\R^M$, $j=1, \dots, n$ evaluated at $\bz_i$ and $\weightvec = [\weight_1, \dots, \weight_n]^T\in\Rn$ are unknown trainable coefficients. We learn $\weightvec\in\Rn$ by minimizing the following loss function:
\begin{align}\label{eq:loss_function}
    \mathcal{L}(\weightvec) = \frac{1}{2}\sum_{i=1}^N\lambda_i\|\Phi_i \weightvec - \MLy_i\|_2^2 + \frac{1}{2}\sum_{k=1}^n\MLreg_k (\weight_k - \MLcenter_k)^2,
\end{align}
where $\lambda_i\geq 0, i=1,...,N$ are tunable hyper-parameters for the data fitting losses, $\MLreg_k>0, k=1,...,n$ are tunable hyper-parameters for the regularization terms, and $\MLcenter_k \in \R$ is a prior on the unknown coefficients that biases $\weight_k$ to be close to $\MLcenter_k$. Note that the above loss function~\eqref{eq:loss_function} is strictly convex, and hence it has a unique global minimizer. Since this loss function is quadratic in $\weightvec$, it can be minimized exactly using the method of least squares. However, we explore a different approach for minimizing~\eqref{eq:loss_function}, which, in certain learning contexts, yields computational advantages over conventional approaches like the method of least squares.

Note that this learning problem is in the form of~\eqref{eqt:regression_multidata}; i.e., set $\LQRuu_i = I_{M\times M}$, $B_i = \Phi_i^T$, $\ba_i = \MLy_i$, $\LQRTC = \MLregmat^{-1}$, where $\MLregmat\in\R^{n\times n}$ is the diagonal matrix whose $i$-th entry is $\MLreg_i$, $\bb = 0$, and $\HJx = \MLregmat\MLcentervec$. Then, this learning problem is related to an LQR problem, and we summarize this connection in Figure~\ref{fig:connection_Riccati_learning}.
Thus, this learning problem can alternatively be solved via the following Riccati ODEs:
\begin{equation}\label{eqt:sequentialRiccatiODEs}
    \begin{dcases}
    \dot{\Sxx}(\HJt) =  -\Sxx(\HJt)^T\MLbasismat_i^T\MLbasismat_i\Sxx(\HJt) &\HJt\in \left(T_{i-1}, T_i\right),\\
    \dot{\Sx}(\HJt) = -\Sxx(\HJt)^T\MLbasismat_i^T(\MLbasismat_i\Sx(\HJt) - \MLy_i)&\HJt\in \left(T_{i-1}, T_i\right),
    \end{dcases}
\end{equation}
with initial condition $\Sxx(0) = \MLregmat^{-1}$, $\Sx(0) = 0$.
Note that here we disregard the ODE for $\Sc$ since, for the learning problem, we are only concerned with the value of the minimizer $\weightvec^*$, which only requires the values of $\Sxx,\Sx$ (e.g., see~\eqref{eqt:singlept_minimizer}, \eqref{eqt:multipt_minimizer}), whereas recovering the minimal objective value $\L(\weightvec^*)$ (which is generally not needed in the context of learning) would require all three values $\Sxx,\Sx,\Sc$. 
There are many numerical methods for solving the Riccati ODEs~\eqref{eqt:sequentialRiccatiODEs} in the literature. In this paper, we use the 4th-order Runge-Kutta method (RK4) \cite{butcher2016numerical}.


At first glance, solving this linear regression problem via the Riccati ODEs \eqref{eqt:sequentialRiccatiODEs} may seem unnecessary given the existence of other well-established methods for minimizing~\eqref{eq:loss_function} (e.g., the method of least squares). However, note that~\eqref{eqt:sequentialRiccatiODEs} is actually a sequence of Riccati ODEs. Thus, using our theoretical connection (and hence, these sequential Riccati ODEs to minimize~\eqref{eq:loss_function}) means that we have the flexibility to handle sequential changes to the learning problem.
In the remainder of Section~\ref{sec:method}, 
we identify several applications in learning (summarized in Table~\ref{tab:learning_problems}), for which this Riccati-based approach yields computational advantages over traditional learning methods (especially when the number of data points $N$ is large), and we describe how standard Riccati solvers can be adapted for these contexts.




\subsection{Adding or removing data}\label{subsec:method_2}
Since our theoretical connection gives us access to the Riccati ODEs~\eqref{eqt:sequentialRiccatiODEs}, which are solved sequentially, we have the flexibility to handle sequential changes to the learning problem~\eqref{eq:loss_function}. In this section, we focus on the sequential addition or removal of data. Some related machine learning examples are provided in Sections~\ref{subsec:example_1} and \ref{subsec:example_2}.


First, we discuss the addition of one data point; i.e., we increase the number of data points from $N$ to $N+1$. This case corresponds to updating our learned model as new data is collected, which is crucial for many practical machine learning applications. 
To add  one data point, we adapt the Riccati ODEs~\eqref{eqt:sequentialRiccatiODEs} as follows. 
Adding the $(N+1)$-th data point corresponds to adding the term $\frac{1}{2}\lambda_{N+1}\|\Phi_{N+1} \weightvec - \MLy_{N+1}\|_2^2 $ in the loss function~\eqref{eq:loss_function} or, equivalently, to adding the Hamiltonian $\frac{1}{2}\|\Phi_{N+1} \weightvec - \MLy_{N+1}\|_2^2$ to the multi-time HJ PDE and the pieces $L_{N+1}(s, \HJu) = \frac{1}{2}\HJu^T\HJu - \MLy_{N+1}^T\HJu$ and $f(s,\HJu) = \Phi_{N+1}^T\HJu, s\in(T_N, T_{N+1})$ to the running cost and dynamics, respectively, of the corresponding piecewise LQR problem.
Thus, minimizing this new loss function is equivalent to solving the following Riccati ODE:
\begin{equation}\label{eqt:regression_1Riccati}
    \begin{dcases}
    \dot{\tilde\Sxx}(\HJt) =  -\tilde\Sxx(\HJt)^T\MLbasismat_\indexRiccati^T\MLbasismat_\indexRiccati\tilde\Sxx(\HJt) &\HJt>0,\\
    \dot{\tilde\Sx}(\HJt) = -\tilde\Sxx(\HJt)^T\MLbasismat_\indexRiccati^T(\MLbasismat_\indexRiccati\tilde\Sx(\HJt) - \MLy_\indexRiccati)&\HJt>0,
    \end{dcases}
\end{equation}
where the index $\indexRiccati=N+1$ and
with initial condition $\tilde\Sxx(0) = \Sxx\left(T_N\right)$ and $\tilde\Sx(0) = \Sx\left(T_N\right)$, where $\Sxx\left(T_{N}\right)$ and $\Sx\left(T_{N}\right)$ are obtained from solving the learning problem~\eqref{eq:loss_function} with $N$ data points. Then, the solution to the new learning problem with an additional point is given by
\begin{equation}\label{eqt:sec42_newoptimizer}
 \tilde\weightvec^* = \tilde\Sxx\MLregmat\MLcentervec + \tilde\Sx,
\end{equation}
where $\tilde\Sxx = \tilde\Sxx(\lambda_{N+1}) (=\Sxx(T_{N+1}))$ and $\tilde \Sx = \tilde \Sx(\lambda_{N+1}) (=\Sx(T_{N+1}))$ are the solution to~\eqref{eqt:regression_1Riccati}; i.e., we have evolved the solution of the new corresponding multi-time HJ PDE in the time variable $t_{N+1}$ from $S(\HJx, \HJt_1, \dots, \HJt_N, 0)$ to $S(\HJx, \HJt_1, \dots, \HJt_N, \lambda_{N+1})$. Using the same methodology described above, note that we can also interpret adding one data point as solving a one-point linear regression problem~\eqref{eqt:loss_1ptregression} and its corresponding single-piece LQR problem~\eqref{eqt:optctrl_1pt}.



Removing one data point (i.e., decreasing the number of data points from $N$ to $N-1$) corresponds to calibrating our learned model by removing possible outliers and/or overly noisy data. 
To remove one data point, we reverse time and solve a terminal value Riccati ODE~\eqref{eqt:regression_2Riccati}. The solution to the new learning problem is then given by~\eqref{eqt:sec42_newoptimizer}, where $\tilde \Sxx$, $\tilde\Sx$ are given by the solution to the time-reversed Riccati ODEs. For more details and the mathematical derivation, see Appendix~\ref{appendix:method_delete_data}.


Note that in both cases, the above approach only requires information about the data point to be added or removed and the results of the previous training. 
Thus, we can add and remove data without retraining on the entire dataset or requiring access to all of the previous data. In contrast, traditional approaches to minimizing~\eqref{eq:loss_function} (e.g., the method of least squares) would require memory of all previous data and then retraining on the entire updated data set. Hence, our approach provides promising computational and memory savings over conventional methods.




\subsection{Hyper-parameter tuning}\label{subsec:method_3}
In the loss function~\eqref{eq:loss_function}, we have three types of hyper-parameters: the weights $\lambda_i$ of the data fitting terms, the weights $\MLreg_k$ of the regularization term, and the bias $\MLcentervec$ on the trainable coefficients $\weightvec$. 
In this section, we discuss how we adapt the Riccati ODEs to tune each of these hyper-parameters.




First, we discuss tuning the weights of the data fitting terms; e.g., as in post-training calibration and federated learning (Section~\ref{subsec:example_2}). Consider changing the weight on the $i$-th data fitting term from $\lambda_i$ to $\tilde\lambda_i$, which corresponds to changing the time $\HJt_i = \lambda_i$ to $\HJt_i = \tilde\lambda_i$ in the multi-time HJ PDE and corresponding piecewise LQR problem. Then, the methodology is similar to that in Section~\ref{subsec:method_1}. 


If $\tilde\lambda_i > \lambda_i$, then the solution to the learning problem with the new data fitting weight $\tilde\lambda_i$ is given by~\eqref{eqt:sec42_newoptimizer}, where $\tilde\Sxx = \tilde\Sxx( \tilde\lambda_i - \lambda_i)$ and $\tilde\Sx = \tilde\Sx( \tilde\lambda_i - \lambda_i)$ are the solutions to the Riccati ODEs~\eqref{eqt:regression_1Riccati} with $j=i$, at time $(\tilde\lambda_i - \lambda_i)$, and with initial condition $\tilde\Sxx(0) = \Sxx\left(T_N\right)$ and $\tilde\Sx(0) = \Sx\left(T_N\right)$, where $\Sxx(T_N), \Sx(T_N)$ are obtained from solving the original learning problem~\eqref{eq:loss_function} with the original value of $\lambda_i$. Similarly, if $\lambda_i > \tilde \lambda_i$, then the solution to the learning problem with the new data fitting weight $\tilde\lambda_i$ is given by~\eqref{eqt:sec42_newoptimizer}, where $\tilde\Sxx = \tilde\Sxx(0)$ and $\tilde\Sx = \tilde\Sx(0)$ are the solutions to the time-reversed Riccati ODEs~\eqref{eqt:regression_2Riccati} with $j=i$, at time 0, and with terminal condition $\tilde\Sxx(\lambda_i - \tilde\lambda_i) = \Sxx\left(T_N\right)$ and $\tilde\Sx(\lambda_i - \tilde\lambda_i) = \Sx\left(T_N\right)$, where $\Sxx\left(T_N\right), \Sx\left(T_N\right)$ are obtained from solving the original learning problem~\eqref{eq:loss_function} with the original value of $\lambda_i$.



Next, we discuss tuning the weights of the regularization terms; e.g., as in the hyper-parameter tuning example in Section~\ref{subsec:example_3}. Note that in the original formulation of the Riccati ODEs~\eqref{eqt:sequentialRiccatiODEs}, the regularization weights appear in the initial condition for $\Sxx$. Changing a hyper-parameter $\MLreg_k$ by changing this initial condition would require re-solving the entire sequence of Riccati ODEs and hence retraining on the entire dataset. However, since we have freedom in how we formulate the corresponding multi-time HJ PDE, we can avoid this retraining as follows. Note that here, instead of sequentially changing each regularization weight $\MLreg_k$ one-by-one, we can actually update all of the regularization weights at once.  


We update the regularization weights in two steps. First, we update the weights whose values we increase by adding an additional Hamiltonian to the multi-time HJ PDE. This yields an initial value Riccati ODE~\eqref{eqt:riccati_increase_regweight}. Second, we update the remaining weights by reinterpreting the problem as a terminal condition, single-time HJ PDE. We then evolve this HJ PDE backward in time using a terminal condition Riccati ODE~\eqref{eqt:riccati_decrease_reg_weight}. Finally, the minimizer to the new learning problem resulting from changing all of the regularization weights is the given by the solutions to the time-reversed Riccati ODE~\eqref{eqt:riccati_decrease_reg_weight} at time 0. For more details, see Appendix~\ref{appendix:hyperparam_tuning}.




Finally, we discuss tuning the bias $\MLcentervec$ on the trainable coefficients $\weightvec$; e.g., as in the generalized regularization example in Section~\ref{subsec:example_4}. In the context of the learning problem, we interpret $\MLcentervec$ as the center of a Gaussian prior on $\weightvec$. Using our theoretical connection, changing $\MLcentervec$ is also equivalent to evaluating the corresponding multi-time HJ PDE and piecewise LQR problem at a different point in space. Specifically, changing $\MLcentervec$ to $\MLcenternewvec$ means that instead of evaluating the multi-time HJ PDE and piecewise LQR problem at $\HJx = \MLregmat\MLcentervec$, we evaluate them at $\HJx = \MLregmat\MLcenternewvec$. Then, the solution to the learning problem with the new bias $\MLcenternewvec$ is given by 
\begin{equation}\label{eqt:minimizer_changeofbias}
    \Sxx(T_N)\MLregmat\MLcenternewvec + \Sx(T_N),
\end{equation}
where $\Sxx(T_N)$ and $\Sx(T_N)$ are obtained from solving the original learning problem~\eqref{eq:loss_function} with the original value of $\MLcentervec$. In other words, shifting the bias involves neither retraining nor access to any of the data points nor solving Riccati ODEs. Instead, we only require some matrix multiplication and addition involving the results of the previous training and the new bias $\MLcenternewvec$. 




\subsection{General convex regularization functions}\label{subsec:method_4}


So far, we have only considered quadratic regularizations. In this section, we will consider the linear regression problem with an arbitrary convex regularization term.
Specifically, consider the general regularization term $R(\weightvec) - \langle \HJx, \weightvec\rangle$, where $R:\weightspace\to\R$ is a convex function. Then, the loss function of the learning problem is given by
\begin{align}  \label{eqt:loss_fn_general_reg}
    \mathcal{L}(\weightvec) = \frac{1}{2}\sum_{i=1}^N\lambda_i\|\Phi_i \weightvec - \MLy_i\|_2^2 + R(\weightvec) - \langle \HJx, \weightvec\rangle.
    % \label{loss:poisson:2}
\end{align}
This learning problem corresponds to a multi-time HJ PDE~\eqref{eqt:multitimeHJPDE}, where the $i$-th Hamiltonian is $H_i(\HJmom) = \frac{1}{2}\lambda_i\|\Phi_i \HJmom - \MLy_i\|_2^2$ and the initial condition is $J = R^*$, which  is the Fenchel-Legendre transform of $R$. The corresponding optimal control problem is given by~\eqref{eqt:optimal_control_standardform}, with terminal time $\sum_{i=1}^N\lambda_i$, piecewise running costs  $L_i(\HJu) = \frac{1}{2}\|\HJu\|^2 - \langle \MLy_i, \HJu\rangle$ and piecewise dynamics $f_i(\HJu) = \MLbasismat_i^T\HJu$ on $(\sum_{j=1}^{i-1}\lambda_j, \sum_{j=1}^{i}\lambda_j]$, and terminal cost $R^*$.
Then, the solution $\weightvec^*$ to the learning problem~\eqref{eqt:loss_fn_general_reg}  is equivalent to the spatial gradient $\nabla_\HJx S(\HJx, \lambda_1, \dots, \lambda_N)$ of the solution to the multi-time HJ PDE, and the minimal value of the loss function~\eqref{eqt:loss_fn_general_reg} is equivalent to $-S(\HJx, \lambda_1, \dots, \lambda_N)$. 

Since the loss function~\eqref{eqt:loss_fn_general_reg} is convex, it can be minimized using any appropriate convex optimization algorithm.
In this paper, we demonstrate how our Riccati-based approach can be combined with PDHG \cite{chambolle2011pdhg} to solve this learning problem. Note that PDHG can be applied to this learning problem~\eqref{eqt:loss_fn_general_reg} as long as the proximal point of $R$ or $R^*$ is numerically computable. For instance, $R$ could be a quadratic function $\langle \cdot, M\cdot\rangle$, a quadratic norm $\sqrt{\langle \cdot, M\cdot\rangle}$, $\|\cdot\|_1$, $\|\cdot\|_1^2$, $\|\cdot\|_\infty^2$, a polynomial function, or the Fenchel-Legendre transformation of any of these functions \cite{Darbon2016Algorithms}.
To compute the solution $\weightvec^*$ of this learning problem, PDHG iterates the following:
\begin{equation}\label{eq:pdhg}
\begin{dcases}
\weightvec^{\ell +1} = \argmin_{\weightvec\in\Rn}
\frac{1}{2}\sum_{i=1}^N\lambda_i\|\Phi_i \weightvec - \MLy_i\|_2^2 
+ \frac{1}{2\sigma_\weightvec}\left\|\weightvec - (\weightvec^\ell - \sigma_\weightvec (\pdhgdual^\ell-\HJx))\right\|_2^2,\\
\bar \weightvec^{\ell+1} = 2\weightvec^{\ell+1} - \weightvec^{\ell},\\
\pdhgdual^{\ell+1} = \argmin_{\pdhgdual\in\Rn}  R^*(\pdhgdual) + \frac{1}{2\sigma_{\pdhgdual}}\left\|\pdhgdual - (\pdhgdual^\ell + \sigma_{\pdhgdual} \bar \weightvec^{\ell+1})\right\|_2^2,
\end{dcases}
\end{equation}
where $\sigma_\weightvec$, $\sigma_{\pdhgdual}$ are positive step-size parameters satisfying $\sigma_\weightvec \sigma_{\pdhgdual} < 1$. 
In each iteration, we need to solve two minimization problems. Updating $\weightvec^{\ell}$ is equivalent to solving the learning problem with quadratic regularization.
Specifically, updating $\weightvec^{\ell}$ is the same as changing the bias $\MLcenter$ in the loss function~\eqref{eq:loss_function}. Therefore, we only need to solve the Riccati ODEs~\eqref{eqt:sequentialRiccatiODEs} once (to compute $\weightvec^{1}$) and every other iterate can be computed using~\eqref{eqt:minimizer_changeofbias}.  
Updating $\pdhgdual^{\ell}$ is equivalent to computing the proximal point of $R^*$. Depending on $R^*$, there may already exist efficient solvers or explicit formulas for computing its proximal point. 


Note that with non-quadratic regularization, if we change the weights $\lambda_k$ of the data fitting losses, change $\HJx$ (which is related to the bias on $\weightvec$), or add or remove data points, then we will need to restart PDHG to solve the resulting learning problem with these new hyper-parameter values or updated datasets. However, we can reuse some of the computations between runs. Namely, we only need to solve the full sequence of Riccati ODEs~\eqref{eqt:sequentialRiccatiODEs} once (to compute $\weightvec^1$ in the first run of PDHG). Then, the solution to those Riccati ODEs can be reused in combination with the methods described in Sections~\ref{subsec:method_2} and~\ref{subsec:method_3} (according to how the learning problem is modified) in subsequent iterations and runs of PDHG. 

