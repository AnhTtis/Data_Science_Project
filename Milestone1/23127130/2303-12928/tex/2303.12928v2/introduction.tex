\section{Introduction}

 
It is well-known that Hamilton-Jacobi partial differential \linebreak equations (HJ PDEs) have deep connections to optimal control \cite{Bardi1997Optimal}, differential games \cite{evans1984differentialgames}, and imaging sciences \cite{darbon2015convex,darbon2022imagedenoising}, among many other fields. 
When the Hamiltonians are convex and only depend on the momentum, the solution to the HJ PDEs can be represented by a Hopf formula, which converts the solution of the PDE to the solution of an optimization problem. Multi-time HJ PDEs were originally introduced in economics~\cite{rochet1985multitimeHJ}. The solution to certain multi-time HJ PDEs was then shown to be able to be represented by a multi-time Hopf formula~\cite{lions1986hopf}, which is a generalization of the single-time case and has  been shown to have connections with imaging sciences~\cite{darbon2019decomposition}. 

In this paper, we establish a novel theoretical connection between certain optimization problems arising in machine learning and the multi-time Hopf formula (Section~\ref{sec:Hopf}). Specifically, we show that there are one-to-one correspondences between the loss functions in certain learning problems and the objective function of the multi-time Hopf formula, which in turn yields connections to certain optimal control problems. See Figure~\ref{fig:intro_connection_in_words} for an illustration of these correspondences. As such, our novel connection increases the interpretability of the training process of certain machine learning applications by showing that when we solve these learning problems, we actually solve a multi-time HJ PDE and by extension, its corresponding optimal control problem. In this paper, we show that our novel connection allows us to leverage HJ PDE and optimal control theory to solve optimization problems arising in certain machine learning applications, and we reserve the reverse direction for future work.

\begin{figure}[t!]
\begin{adjustbox}{width=\textwidth}
\begin{tikzpicture}[node distance=2cm]
    \node (min) [nobox, yshift=-0.2cm] {$\min$};
    \node (minarg) [boxsmall, right of=min, xshift=-1.5cm, yshift=-0.4cm, draw=cyan!60, fill=cyan!5] {$\text{}_\text{weights}$};
    \node (sum) [nobox, right of=min, xshift=-0.6cm] {$\sum$};
    \node (param) [box, right of=sum, xshift=-0.8cm, text width=1.6cm, draw=magenta!60, fill=magenta!5] {hyper- parameter};
    \node (loss) [box, right of=param, xshift=0.1cm, draw=green!60, fill=green!5, text width=1.7cm] {data fitting loss};
    \node (plus) [nobox, right of=loss, xshift=0.7cm] {$+$};
    \node (regLeft) [nobox, right of=loss, xshift=1cm] {};
    \node (regularization) [box, right of=regLeft, xshift=0.55cm, draw=blue!60, fill=blue!5] {regularization};
    \node (regRight) [nobox, right of=regularization, xshift=0.55cm] {};
    
    \node (sup) [nobox, below of=min, xshift=-0cm] {$\min$};
    \node (suparg) [boxsmall, right of=sup, xshift=-1.5cm, yshift=-0.37cm, draw=cyan!60, fill=cyan!5] {$\text{}_\text{momentum}$};
    \node (sum2) [nobox, below of=sum, xshift=0.2cm] {$\sum$};
    \node (time) [box, below of=param, xshift=-0cm, draw=magenta!60, fill=magenta!5] {time};
    \node (equals) [nobox, left of=sup, xshift=1.4cm] {$=$};
    \node (S) [box, left of=equals, xshift=0.6cm, text width=2cm, draw=red!60, fill=red!5] {solution to HJ PDE};
    \node (minus) [nobox, left of=S, xshift=0.65cm] {$-$};
    \node (Hamiltonian) [box, below of=loss, draw=green!60, fill=green!5] {Hamiltonian};
    \node (plus2) [nobox, right of=Hamiltonian, xshift=-0.55cm] {$+$};
    \node (IC) [box, below of=regLeft, text width=2cm, draw=blue!60, fill=blue!5] {Fenchel transform of initial data};
    \node (linear) [box, below of=regRight, draw=blue!60, fill=blue!5] {linear term};
    \node (plus3) [nobox, below of=regularization, xshift=-0cm] {$+$};
    

    \node (minloss) [box, above of=S, text width=2cm, draw=red!60, fill=red!5] {minimal loss value};
    \node (LPequals) [nobox, above of=equals] {$=$};
    
    \node (OCmin) [nobox, below of=sup, xshift=0.55cm] {$\min$};
    \node (OCS) [box, below of=S, xshift=0cm, draw=red!60, fill=red!5] {value function};
    \node (OCequals) [nobox, below of=equals, xshift=0cm] {$=$};
    \node (OCint) [nobox, below of=time, xshift=-0.5cm] {$\int$};
    \node (OCt) [boxsmall, right of=OCint, xshift=-1.5cm, yshift=-0.35cm, draw=magenta!60, fill=magenta!5] {time};
    \node (OCHamiltonian) [box, below of=Hamiltonian, draw=green!60, fill=green!5] {running cost};
    \node (OCds) [nobox, right of=OCHamiltonian, xshift=-0.7cm] {$ds$};
    \node (OCplus) [nobox, below of=plus2, xshift=0.2cm] {$+$};
    \node (OCIC) [box, below of=IC, draw=blue!60, fill=blue!5] {terminal cost};
    \node (OCdynam) [box, right of=OCIC, xshift=0.6cm, text width=2cm, draw=green!60, fill=green!5] {dynamics};
    \node (OCinitialposition) [box, below of=linear, text width=2cm, draw=blue!60, fill=blue!5] {initial position};
    \node (comma) [nobox, right of=OCdynam, xshift=-0.8cm] {,};
    \node (leftbracket) [nobox, left of=OCint, xshift=1.6cm] {$\Bigg\{$};
    \node (colon) [nobox, right of=OCIC, xshift=-0.75cm] {$:$};
    \node (rightbracket) [nobox, right of=OCinitialposition, xshift=-0.55cm] {$\Bigg\}$};
    
    \draw [doublearrow] (loss) -- (Hamiltonian);
    \draw [dottedarrow] (regularization) -- (IC);
    \draw [dottedarrow] (regularization) -- (linear);
    \draw [doublearrow] (minarg) -- (suparg);
    \draw [doublearrow] (OCS) -- (S);
    \draw [doublearrow] (OCt) -- (time);
    \draw [dottedarrow] (OCHamiltonian) -- (Hamiltonian);
    \draw [dottedarrow] (OCIC) -- (IC);
    \draw [dottedarrow] (OCdynam) -- (Hamiltonian);
    \draw [doublearrow] (time) -- (param);
    \draw [dottedarrow] (OCinitialposition) -- (linear);
    \draw [dottedarrow] (S) -- (minloss);
\end{tikzpicture}
\end{adjustbox}

    \caption{(See Section~\ref{sec:Hopf}) Illustration of a connection between a regularized learning problem (\textbf{top}), the multi-time Hopf formula (\textbf{middle}), and an optimal control problem (\textbf{bottom}). The colors indicate the associated quantities between each problem. For example, the optimal weights in the learning problem are equivalent to the momentum in the HJ PDE (\textcolor{cyan}{cyan}), and the hyper-parameters for the data fitting terms correspond to the time variables in the HJ PDE and the time horizon in the optimal control problem (\textcolor{magenta}{magenta}). This color scheme is reused in the subsequent illustrations of our connection. The solid-line arrows denote direct equivalences. The dotted arrows represent additional mathematical relations.}
    \label{fig:intro_connection_in_words}
\end{figure}

We focus on the connection between the regularized linear regression problem and the Linear Quadratic Regulator (LQR) (Section~\ref{sec:LQR}). We use this case to gain a deeper understanding of our novel connection and illustrate its potential benefits. Linear regression consists of learning a linear prediction model and is one of the fundamental learning problems in supervised machine learning \cite{russell2010artificial, mohri2018foundations, weisberg2005applied}. LQR \cite{TrentelmanControlLinearSystems} is a well-studied optimal control problem with certain quadratic running and terminal costs and linear dynamics and is typically solved using the Riccati ordinary differential equations (ODEs) \cite{mceneaney2006max,Darbon2023Neural,Nakamura2021QRnet}. Through our novel connection, we establish that solving certain regularized linear regression problems is equivalent to solving certain LQR problems. As a result, we can leverage standard LQR solvers to design new training approaches for machine learning. In particular, we develop new methodology for solving certain regularized linear regression problems by adapting solvers for the Riccati ODEs to these new settings (Section~\ref{sec:method}).

To highlight the versatility and possible computational advantages of our new Riccati-based approach, we apply our methodology to several test problems in machine learning (Section~\ref{sec:numerics}).
In the first example, we consider a function approximation problem to demonstrate the computational and memory advantages of our Riccati-based approach in the context of continual learning \cite{parisi2019continual, kirkpatrick2017overcoming, van2019three}. Specifically, we show that our Riccati-based approach naturally enables us to continually adapt the learned model to new data without having to store or retrain on the previous data (which is especially significant given the rise of big data), while also avoiding catastrophic forgetting~\cite{kirkpatrick2017overcoming, parisi2019continual}. 
In the second example, we demonstrate how our Riccati-based approach can be used to perform post-training calibrations. In particular, our approach gives us the flexibility to add or remove data points and tune hyper-parameters to increase the accuracy of the learned model without having to retrain it entirely, which again provides computational and memory advantages over conventional learning methods. 
In the third example, we use our Riccati-based method to fit the last layer of a physics-informed neural network (PINN) \cite{raissi2019physics} using transfer learning \cite{zou2023hydra, desai2021one}. In this application, we demonstrate that as we change the value of the hyper-parameters, solving the associated Riccati ODEs not only provides the solution to the updated problem, but also a \textit{continuum} of solutions along a 1D curve on the Pareto front of the data fitting losses and regularization. 
Finally, in the fourth example, we highlight the versatility of our Riccati-based approach by showing how it can be combined with existing optimization methods (e.g., the primal-dual hybrid gradient (PDHG) algorithm \cite{chambolle2011pdhg}) to perform sparse dynamics identification \cite{brunton2016discovering}.

The main contributions of this work are the development of a new theoretical connection between learning problems and the Hopf formula and a new Riccati-based approach for solving regularized linear regression problems.
While we demonstrate promising results, the work presented here has some limitations. For example, while we establish our novel theoretical connection between more general learning problems, multi-time HJ PDEs, and optimal control problems, we have yet to fully explore non-linear learning models, general convex Hamiltonians, or non-linear control dynamics. Additionally, as discussed previously, we have also not yet investigated what possible advantages our novel connection provides for solving HJ PDEs and optimal control problems. In particular, many efficient solvers for high-dimensional problems in machine learning exist~\cite{lecun2015deep, goodfellow2016deep}; it would be desirable to be able to leverage our connection to reuse this machinery for HJ PDEs and optimal control. Thus, our novel connection presents many exciting opportunities.
We discuss some other possible future directions in Section~\ref{sec:conclusion}.
The overall structure of this paper is illustrated in Figure~\ref{fig:illustration}.

\begin{figure}[t!]
\centering
\includegraphics[width = 0.8\textwidth]{illustration/illustration_Hopf_learning_3.png}
\caption{
Overview of the overall structure of this paper, the learning problems considered, our new theoretical connection, and our new Riccati-based algorithm. We show the learning problem in the \textbf{left} (\textcolor{myorange}{orange}), the theoretical connection in the \textbf{middle} (\textcolor{myblue}{blue}), and the algorithm in the \textbf{right} (\textcolor{mygreen}{green}). The \textbf{top} row contains the general connection between learning problems and HJ PDEs (see Section~\ref{sec:Hopf}), the \textbf{middle} row contains the connection between the regularized linear regression problem and LQR (see Section~\ref{sec:LQR}), and the \textbf{bottom} row contains the connection between applications in machine learning and our Riccati-based algorithm (see Sections~\ref{sec:method} and~\ref{sec:numerics}).
}
\label{fig:illustration}
\end{figure}

