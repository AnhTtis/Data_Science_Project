\documentclass[lettersize,journal]{IEEEtran}
\usepackage{amsmath,amsfonts,amssymb,amsthm}
%\usepackage{algorithmic}
%\usepackage{algorithm}
\usepackage{array}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
%\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{xcolor}
\usepackage{booktabs}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\SetKwInput{KwInput}{Input}                % Set the Input
\SetKwInput{KwOutput}{Output}  
\usepackage{algpseudocode}
\usepackage{url}
\usepackage{multirow}
\usepackage{enumerate}
\usepackage{diagbox}
\usepackage{colortbl}
\usepackage{subcaption}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
% updated with editorial comments 8/9/2021

\begin{document}

\title{Uncertainty Calibration for Counterfactual Propensity Estimation in Recommendation}

%\author{IEEE Publication Technology,~\IEEEmembership{Staff,~IEEE,}
        % <-this % stops a space
%\thanks{This paper was produced by the IEEE Publication Technology Group. They are in Piscataway, NJ.}% <-this % stops a space
%\thanks{Manuscript received April 19, 2021; revised August 16, 2021.}}
\author{Wenbo Hu,~\IEEEmembership{Member,~IEEE,} Xin Sun,~\IEEEmembership{Member,~IEEE,} Qiang Liu,~\IEEEmembership{Member,~IEEE,}\\ Le Wu,~\IEEEmembership{Member,~IEEE,} Liang Wang,~\IEEEmembership{Fellow,~IEEE,}
\thanks{This work is jointly supported by National Natural Science Foundation of China (No. 62306098), the Open Projects Program of State Key Laboratory of Multimodal Artificial Intelligence Systems and the Fundamental Research Funds for the Central Universities (No. JZ2024HGTB0256).}
\thanks{Wenbo Hu and Le Wu are with the School of Computer and Information, Hefei University of Technology, Hefei, China (Email: \{wenbohu,lewu\}@hfut.edu.cn). Xin Sun is with the University of Science and Technology of China (Email: sunxin000@mail.ustc.edu.cn) . Qiang Liu and Liang Wang are with the Institute of Automation, Chinese Academy of Sciences(Email: \{qiang.liu,wangliang\}@nlpr.ia.ac.cn).}
\thanks{The first two authors contributed equally. }
\thanks{Corresponding author: Qiang Liu.}
}

% The paper headers
\markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2021}%
{Shell \MakeLowercase{\textit{et al.}}: A Sample Article Using IEEEtran.cls for IEEE Journals}

%\IEEEpubid{0000--0000/00\$00.00~\copyright~2021 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\maketitle

\begin{abstract}
Post-click conversion rate (CVR) is a reliable indicator of online customers' preferences, making it crucial for developing recommender systems. A major challenge in predicting CVR is severe selection bias, arising from users' inherent self-selection behavior and the system's item selection process. To mitigate this issue, the inverse propensity score (IPS) is employed to weight the prediction error of each observed instance. However, current propensity score estimations are unreliable due to the lack of a quality measure. To address this, we evaluate the quality of propensity scores from the perspective of uncertainty calibration, proposing the use of expected calibration error (ECE) as a measure of propensity-score quality. We argue that the performance of IPS-based recommendations is hampered by miscalibration in propensity estimation. We introduce a model-agnostic calibration framework for propensity-based debiasing of CVR predictions. Theoretical analysis on bias and generalization bounds demonstrates the superiority of calibrated propensity estimates over uncalibrated ones. Experiments conducted on the Coat, Yahoo and KuaiRand datasets show improved uncertainty calibration, as evidenced by lower ECE values, leading to enhanced CVR prediction outcomes.
\end{abstract}
%In recommendation systems, addressing selection bias is crucial for improving fairness and diversity. Propensity score-based debiasing methods, such as the Inverse Propensity Scoring (IPS) approach, often suffer from high variance and miscalibration issues. This paper introduces an uncertainty calibration framework for propensity score estimation, utilizing Expected Calibration Error (ECE) to assess the quality of propensity scores. We explore three calibration methods: MC Dropout, Deep Ensembles, and Platt Scaling, comparing their effectiveness in reducing calibration error and improving recommendation accuracy. Theoretical analysis demonstrates that calibrated IPS exhibits smaller bias, and experimental results on two representative datasets, Coat Shopping and Yahoo! R3, validate the significant improvement in recommendation performance with calibrated propensity scores. Additionally, we show that our method can enhance other state-of-the-art CVR prediction models, further proving the robustness and generalizability of our approach. Efficiency experiments indicate that Platt Scaling and MC Dropout are computationally efficient, while Deep Ensembles, though effective, incur higher computational costs. Our findings highlight the importance of accurate propensity score calibration in mitigating selection bias and enhancing recommendation system performance.


\begin{IEEEkeywords}
Post-click conversion rate, inverse propensity score, expected calibrated error, uncertainty calibration.
\end{IEEEkeywords}

\section{Introduction}
The post-click conversion rate (CVR) represents the likelihood of a user consuming an online item after clicking on it. Predicting CVR is essentially a counterfactual problem, as it involves estimating the conversion rates of all user-item pairs under the hypothetical scenario that all items are clicked by all users. However, this scenario contradicts reality due to selection bias. Users freely choose which items to rate, resulting in observed user-item feedback that is not representative of all possible user-item pairs. Consequently, the feedback data is often missing not at random (MNAR)~\cite{guo2021enhanced, dai2022generalized, wang2022escm, zhou2023generalized, liu2022rmt}.


\begin{figure}[htbp]
\centering
\subcaptionbox{Coat Shopping}{\includegraphics[width=.45\columnwidth]{coat_intro.pdf}}
\subcaptionbox{{Yahoo R3!}}{\includegraphics[width=.45\columnwidth]{yahoo_intro.pdf}}
\caption{For recommendation with MNAR on the Coat shopping dataset, we use the raw inverse propensity estimator with and without the platt scaling calibration and give the scatter plot of the expected propensity vs the fraction of observed ratings. The diagonal line is the perfect uncertainty calibration result. As can be seen, the raw propensity estimations are severely miscalibrated.}
\label{fig:intro-miscalibration}
\end{figure}

To address this problem, the inverse propensity score (IPS) approach is employed to handle selection bias~\cite{seaman2013review, little2019statistical}. This approach treats recommendation as an intervention, analogous to treating a patient with a specific drug. In both scenarios, we have only partial knowledge of how certain treatments (items) benefit certain patients (users), with outcomes for most patient-treatment (user-item) pairs remaining unobserved. For recommendations, IPS inversely scores the prediction error of each feedback using the propensity of that feedback~\cite{swaminathan2015self, schnabel2016recommendations}. Doubly robust (DR) learning approaches, which combine IPS and error imputation (EIB) methods, also achieve state-of-the-art performance in debiasing CVR prediction~\cite{wang2019doubly, saito2020doubly, guo2021enhanced, dai2022generalized}. The robustness and accuracy of propensity estimates are crucial for propensity-based debiasing in recommendation systems. Unfortunately, there is no systematic investigation into reliable quality measures for propensity scores. As a result, miscalibrated propensity score estimates are often overlooked, potentially diminishing the effectiveness of debiasing methods.

In machine learning methods widely used in recommendation systems, uncertainty quantification is often poorly characterized, leading to over-confident predictions. This issue is prevalent not only in deep learning models~\cite{guo2017calibration} but also in shallow models, such as logistic regression~\cite{vaicenavicius2019evaluating}. The uncertainty of personalized ranking probabilities can be learned through uncertainty calibration methods~\cite{menon2012predicting, kweon2022obtaining} and applied in online advertising systems~\cite{wei2022posterior, xu2022ukd}.

Despite this, propensity scores are frequently miscalibrated, limiting the effectiveness of IPS, even though IPS has been validated in recommendation systems and other applications. As illustrated in Fig.~\ref{fig:intro-miscalibration}, expected propensity scores are not calibrated with the fraction of observed samples, deviating from perfect calibration (the diagonal line). In terms of uncertainty calibration, expected propensity scores, such as 95\%, should correspond to the same level of observed sample fraction (95\%). The uncertainty originates from inaccurate propensity score predictions, leading to inaccurate recommendations when dealing with MNAR data using miscalibrated propensity scores.


In this paper, we propose using expected calibration error (ECE) as a quality measure for the reliability of propensity scores and highlight the miscalibration issue in current propensity estimation. Additionally, we introduce a model-agnostic uncertainty calibration framework for propensity estimation. Extensive experiments demonstrate that lower ECE values in propensity scores result in better CVR prediction outcomes.



The contribution of this paper are as follows:
\begin{itemize}
    \item We identify the miscalibration issue in propensity estimation and propose using ECE as a quality measure for the reliability of propensity scores.
    \item We demonstrate that miscalibration of propensity scores limits the debiasing performance of propensity-based CVR prediction and propose a thoughtful uncertainty calibration methodology for propensity scores.
    \item We provide theoretical analysis and experimental results to show the superiority of uncertainty-calibrated propensity scores for unbiased CVR prediction.
\end{itemize}

\section{Preliminaries}
In this section, we introduce the preliminaries of counterfactual propensity estimation and uncertainty quantification. 
Table I in Supplemental Materials describes the main symbols used in this paper.

\subsection{Propensity-based Debiasing Recommendation}
Let $\mathcal{U} = \{u_1, u_2,\dots, u_m\}$ and $\mathcal{I} = \{i_1, i_2, \dots, i_n\}$ be the sets of $m$ users and $n$ items. The set of user-item pairs is denoted as $\mathcal{D} = \mathcal{U} \times \mathcal{I}$. We use $\mathbf{R} \in \{0,1\}^{m\times n}$ to represent the conversion matrix where each entry $r_{u,i}$ indicates an observed conversion label. Let $\hat{\mathbf{R}} \in [0,1]^{m\times n}$ be the predicted conversion rate matrix and each entry $\hat{r}_{u,i} \in [0,1]$ represent the predicted conversion rate, which is obtained by the conversion model $f_\theta$ with parameter $\theta$. Additionally, we denote $o_{u,i}$ as the click event indicator and $\mathcal{O}$ as the click label matrix. We denote the  observed conversion label matrix as $\mathbf{R^{o}} = \mathbf{R} \odot \mathcal{O}$, where $\odot$ is hadamard product operator. If all conversion labels are available , the prediction errors $\mathbf{E} = \{e_{u,i} | (u, i) \in \mathcal{D}\}$ can be calculated, the ideal loss function is:
\begin{equation}
\label{eqn:ideal}
\mathcal{L}_{ideal}(\mathbf{\hat{R}}, \mathbf{R}) = \frac{1}{|\mathcal{D}|} \sum_{u,i\in \mathcal{D}} e_{u,i},   
\end{equation}
where $e_{u,i}$ is the prediction error and we adopt the cross entropy in this paper. 
We adopt the cross entropy $e_{u,i} = CE(r_{u,i}, \hat{r}_{u,i}) = -r_{u,i}\log \hat{r}_{u,i} - (1-r_{u,i}) \log (1-\hat{r}_{u,i})$. 

In practice, only part of the conversion label are available. The naive estimate of ideal loss function is to  averages the prediction errors of the available items:
\begin{equation}
  \label{eqn:naive}
    \mathcal{L}_{naive}(\mathbf{\hat{R}}, \mathbf{R}) =\frac{1}{|\mathcal{D}|}\sum_{o_{u,i}=1,u,i\in\mathcal{D}}e_{u,i} = \frac{1}{|\mathcal{D}|} \sum_{(u,i)\in \mathcal{D}} o_{u,i}e_{u,i}.
\end{equation}
The naive estimator is biased when the conversion labels are Missing Not At Random which is resulted from the selection biases of the real recommendation system~\cite{marlin2007collaborative}, i.e., 
\begin{equation}
    \mathbb{E}_\mathcal{O} [\mathcal{L}_{naive}(\mathbf{\hat{R}}, \mathbf{R})] \neq \mathcal{L}_{ideal}(\mathbf{\hat{R}}, \mathbf{R}).
\end{equation}

To reduce the selection bias of the naive estimator, the inverse propensity score considers reweighting the error of the observed ratings of the inverse propensity score~\cite{swaminathan2015self,sato2020unbiased}. In CVR prediction task, $p_{u,i}$ represents the probability of a user $u$ clicks an item $i$ and $p_{u,i} = \mathbb{P} (o_{u,i}=1) = \mathbb{E}[o_{u,i}]$, which is also known as click-through rate (CTR) in the CVR prediction task setting. 
Specifically, the $p_{u,i}$  is estimated using a machine learning classifier $g_\phi$, such as naive Bayes. We call the model $g_\phi$ as propensity estimation model. The estimated value of $p_{u,i}$ is denoted as $\hat{p}_{u,i}$. The matrices $\mathcal{P}$ and $\mathcal{\hat{P}}$ represent the propensity score matrix and estimated propensity score matrix, respectively.
With the inverse propensity scores, the prediction error of IPS is obtained via:
\begin{equation}
  \label{eqn:IPS}
    \mathcal{L}_{\textrm{IPS}}(\mathbf{\hat{R}}, \mathbf{R})=\frac{1}{|\mathcal{D}|}\sum_{(u,i)\in\mathcal{D}}\frac{o_{u,i}e_{u,i}}{\hat{p}_{u,i}}.
\end{equation}

% Another line of research aim to use an imputation model to predict the more accurate rating predictions~\cite{steck2010training}. The imputation error is denoted as $\hat{e}_{u,i}$ and this the  error-imputation-based (EIB) estimator has the following prediction error: 
% \begin{equation}
%     \mathcal{L}_{\text{EIB}}(\mathbf{\hat{R}}, \mathbf{R})=\frac{1}{|\mathcal{D}|}\sum_{u,i\in\mathcal{D}}\left(o_{u,i}e_{u,i}+(1-o_{u,i}\hat{e}_{u,i})\right).
% \end{equation}
A more recent progress, the doubly robust estimator, is to combine the IPS and the error-imputation-based (EIB) estimators via joint learning to have the best of the both worlds~\cite{wang2019doubly, guo2021enhanced}. Given the imputed errors $\mathbf{\hat{E}} = \{\hat{e}_{u,i} | (u, i) \in \mathcal{D}\}$ , its loss function is formulated as:
\begin{equation}
    \mathcal{L}_{\text{DR}}(\mathbf{\hat{R}}, \mathbf{R})=\frac{1}{|\mathcal{D}|}\sum_{u,i\in\mathcal{D}}\left(\hat{e}_{u,i}+\frac{o_{u,i}(e_{u,i}-\hat{e}_{u,i})}{\hat{p}_{u,i}}\right).
    \label{eq: dr}
\end{equation}
Doubly robust joint learning(DR-JL) approach\cite{wang2019doubly} estimates the CVR prediction model $f_\theta$ and error imputation model $\hat{e}_{u,i} = h_\psi(x_{u,i}) $ alternately: given $\hat{\psi}$ , $\theta$ is updated by minimizing Eqn.~\ref{eq: dr}; given $\hat{\theta}$, $\psi$ is updated by minimizing:
\begin{equation}
\mathcal{L}_e^{D R-J L}(\psi)=\sum_{u, i\in \mathcal{D}} \frac{o_{u, i}\left(\hat{e}_{u, i}-e_{u, i}\right)^2}{\hat{p}_{u, i}}
\label{eq: drjl}
\end{equation}

Recently, the more robust doubly robust (MRDR) method~\cite{guo2021enhanced} enhances the robustness of DR-JL by optimizing the variance of the DR estimator with the imputation model. Specifically, MRDR keeps the loss of the CVR prediction model in Eqn.~\ref{eq: dr} unchanged, which replacing the loss of the imputation model in Eqn.~\ref{eq: drjl} with the following loss
\begin{equation}
\mathcal{L}_e^{M R D R}(\theta)=\sum_{(u, i) \in \mathcal{D}} \frac{o_{u, i}\left(\hat{e}_{u, i}-e_{u, i}\right)^2}{\hat{p}_{u, i}} \cdot \frac{1-\hat{p}_{u, i}}{\hat{p}_{u, i}}
\label{eq: mrdr}
\end{equation}
This substitution can help reduce the variance of Eqn.~\ref{eq: dr} and hence get a more robust estimator.


% The inverse propensity score is applied to the recommendation, post-click conversion rate and click-through rate with MNAR~\cite{yuan2019improving,guo2021enhanced}.
\subsection{Trustworthy Machine Learning and Probability  Uncertainty for Relibility}
Machine learning, particularly deep learning methods, has achieved pervasive success in various domains, including vision, speech, natural language processing, control, and computer Go~\cite{lecun2015deep,silver2016mastering}. Despite their dominant prediction performance across these areas~\cite{lecun2015deep,liu2017multi}, such as computer vision, natural language processing, and recommendation systems, deep learning models often produce overconfident and miscalibrated predictions~\cite{guo2017calibration}. Overconfident predictions can undermine the accuracy, robustness, and reliability of these models.
Therefore, it is imperative to characterize the uncertainty in deep learning models~\cite{kendall2017uncertainties,abdar2021review}. Safety-critical tasks are ubiquitous, including autonomous driving~\cite{leibig2017leveraging}, medical diagnoses~\cite{michelmore2020uncertainty}, weather forecasting~\cite{gneiting2005weather}, load forecasting~\cite{taylor2002neural}, social network analysis~\cite{akcora2019graphboot}, anomaly detection~\cite{xu2024calibrated}, and traffic flow forecasting~\cite{qian2023towards}. In these real-world application scenarios, diverse probabilistic uncertainties in model predictions arise from measurement noise, external changes, data missingness, etc. This necessitates that deep learning models not only produce accurate predictions but also provide insights into the reliability of these predictions in terms of uncertainty.

In machine learning, there are two types of uncertainty: \emph{aleatoric} uncertainty and \emph{epistemic} uncertainty (also known as data uncertainty and model uncertainty)~\cite{kendall2017uncertainties}. Aleatoric uncertainty captures the inherent noise in the data, which may arise from sources such as sensor noise or motion noise. Epistemic uncertainty, on the other hand, pertains to the uncertainty in the model parameters and structure. It can be fully captured given sufficient data. In many scenarios, epistemic uncertainty is commonly referred to as model uncertainty.

\iffalse
Specifically, a supervised machine learning model learns a mapping function $f$ from a feature vector $x$ to a label $y$: $  \hat{y}=f(x)$.
The label $y$ can be either discrete or continuous, which corresponds to classification or regression problems respectively. 
A widely-used mapping function is a linear feature combination plus an activation function $\sigma$:
$\hat{y}=f(x)=\sigma\left(\textbf{w}^{\top}x\right)$,
where $\textbf{w}$ is a coefficient vector. 
A representative example is a binary classification method, logistic regression whose activation function is the sigmoid function.
Based on the simple structure, we obtain multifarious deep learning methods, by stacking multiple layers of the coefficient vectors and using some advanced units, such as CNN, RNN and attention~\cite{lecun2015deep}.

In ordinary deep learning settings, only the point estimates are produced by $f$. However, for many safety-critical tasks, the uncertainty estimates are of great significance. There are two types of uncertainty quantification for deep learning: classification and regression:
\begin{itemize}
	\item UQ for classification: for a k-class classification task, UQ should estimate the assigning Dirichlet probabilities for each class: $$\textrm{Dir}(\alpha_1, \alpha_2, \cdots, \alpha_k), \sum_{i=1}^{k}\alpha_i=1;$$
	\item UQ for regression: for a real-value regression problem, UQ should estimate a specific probability distribution (for example Gaussian), or a series of quantiles.  
\end{itemize}
\fi

\subsection{Uncertainty Calibration for Deep Learning}
To formalize, the propensity score is well-calibrated if it equals the correctness ratio of the available conversion labels~\cite{kull2017beta}. For instance, if the propensity estimation model $g_\phi$ outputs 100 predictions, each with a confidence (i.e., uncalibrated propensity score) of 0.95, then 95\% of the conversion labels are expected to be available. We define perfect calibration of propensity estimation as:

\begin{equation}
    \mathbb{P}(o = 1 | \hat{p} = p) = p, \quad \forall p \in [0,1],
\end{equation}
where $\hat{p}$ is the output of $g_\phi$. Miscalibration can be measured by the Expected Calibration Error (ECE), which is the expectation of the coverage probability difference of the prediction intervals. In practice, we partition propensity predictions into $M$ bins of equal width and calculate the weighted sum of all bins via:
\begin{equation}
\label{eqn:ece}
\mathrm{ECE(g_\phi)}=\sum_{m=1}^M \frac{\left|B_m\right|}{n}\left|\operatorname{freq}\left(B_m\right)-\operatorname{conf}\left(B_m\right)\right|,
\end{equation}
where $n$ is the number of samples and $B_m$ is the set of indices of samples whose propensity prediction falls into the interval $I_m = (\frac{m-1}{M}, \frac{m}{M}]$. $\operatorname{conf}(B_m)$ and $\operatorname{freq}(B_m)$ are defined as:
\begin{gather}
    \operatorname{conf}\left(B_m\right) = \frac{1}{|B_m|} \sum_{u, i \in B_m} \hat{p}_{u,i} \\
    \operatorname{freq}\left(B_m\right) = \frac{1}{|B_m|} \sum_{u, i \in B_m} \mathbf{1}(o_{u,i} = 1),
\end{gather}

% TODO, ece as the indicator.....

Regarding calibration methodologies, one effective approach is Bayesian generative modeling, with representative models including Bayesian neural networks and deep Gaussian processes~\cite{wilson2020bayesian,wang2020survey}. Bayesian neural networks are generally computationally expensive to train, so approximate methods have been developed, such as MC-Dropout~\cite{kendall2017uncertainties} and deep ensembles~\cite{lakshminarayanan2017simple}. Alternatively, uncertainties can be obtained from the calibration of inaccurate uncertainties. Methods employing scaling and binning for calibration are used for both classification and regression models~\cite{platt1999probabilistic,niculescu2005predicting,guo2017calibration,kuleshov2018accurate,cui2020calibrated,he2023investigating,liu2023deep}. An additional advantage of calibration methods is their model-agnostic nature, making them applicable to any IPS-based model.


\section{Uncertainty Calibration for Propensity Estimation}
In this section, we present our approach to counterfactual propensity estimation with uncertainty calibration. We also provide a theoretical guarantee for our uncertainty calibration model in recommendation systems with Missing Not At Random (MNAR) data.


\subsection{Propensity Estimation Procedure}
The propensity probability $p$ is critical for the inverse propensity score, which ensures the unbiasedness of the IPS estimator when the inverse propensity score is accurate~\cite{vermeulen2015bias}. Propensities are learned using a machine learning model $g_\phi: x_{u,i} \rightarrow p_{u,i}$, where $p_{u,i} \in [0, 1]$. This model can be naive Bayes, logistic regression, or deep neural networks. We utilize neural networks to fit $g_\phi$. The objective is to find model parameters $\phi$ that maximize $P(\mathcal{O}|X, \phi)$, where $x_{u,i}$ is the vector encoding all observable information about a user-item pair and $X$ is the set of such vectors. The loss function is given by:
\begin{equation}
\label{eqn:ctr}
    \mathcal{L}_{g_\phi} = -\sum_{(u,i) \in \mathcal{D}} [o_{u,i} \cdot \log \hat{p}_{u,i} + (1 - o_{u,i})\cdot \log (1-\hat{p}_{u,i})] 
\end{equation}
\subsection{Uncertainty Calibration for Propensity Estimation}
As illustrated in Fig.~\ref{fig:intro-miscalibration}, raw propensity estimation models are generally miscalibrated, often producing overconfident probability predictions. To reduce biases and achieve calibrated propensity scores, we consider a model-agnostic uncertainty calibration $q$ in conjunction with the propensity learning model $g_\phi$. Specifically, two model-agnostic methods are considered for propensity probability calibration: 1) uncertainty probability quantification and 2) post-processing uncertainty calibration.

\subsubsection{Uncertainty Probability Quantification for Propensity scores}
The uncertainty probability quantification considers a generative probability quantification model $q(P|\Theta)$, where $\Theta$ represents the model parameters.

Due to the challenges and high computational cost associated with fully Bayesian models, we propose two approximate uncertainty quantification methods for propensity estimation: 1) Monte Carlo Dropout~\cite{gal2016dropout} and 2) deep ensembles~\cite{lakshminarayanan2017simple}.


\textbf{Monte Carlo (MC) Dropout} involves randomly deactivating neurons during testing in the originally trained deep neural network. Multiple samples ($T$) are taken to produce an approximate posterior distribution through model averaging:
\begin{equation}\label{eqn:model_average}
  q(p|x,\Theta)\sim\frac{1}{T}\sum_{t}^{T} q_{t}(p|x, g_\phi(x), \Theta_{t}).
\end{equation}

\textbf{Deep Ensembles} involve training multiple model replicas with different random initializations, without interactions during training. The approximate propensity probability distribution is obtained by combining and averaging the replicas as shown in Eqn.~\ref{eqn:model_average}. Compared to MC-Dropout, deep ensembles tend to perform better because the model ensembles learn distinct model distributions, whereas MC-Dropout only varies during the testing stage. However, deep ensembles are generally more computationally expensive since the models are trained multiple times.

\subsubsection{Post-processing Calibration for Propensity scores}
In addition to direct uncertainty quantification, post-processing calibration can be applied to derive accurate predictive uncertainties from inaccurate softmax probabilities (or other model output probabilities)~\cite{platt1999probabilistic, guo2017calibration}.


\textbf{Platt Scaling} adjusts the original propensity outputs to learn accurate inverse propensities via:
\begin{equation}
    \label{eqn:platt}
    q(g_\phi(x))=\sigma(b\cdot g_\phi(x)+c),
\end{equation}
where $g_\phi(x)$ represents the original propensity outputs, $\sigma$ is the sigmoid function, and $b, c$ are learnable parameters of the sigmoid function~\cite{platt1999probabilistic}. Platt scaling is equivalent to class-conditional Gaussian likelihoods with the same variance. For multi-class classification, Platt scaling can be augmented with a temperature parameter to soften the softmax output, known as temperature scaling~\cite{guo2017calibration}. In this paper, we employ Platt scaling for the NMAR binary setting.
\begin{algorithm}
\caption{Uncertainty calibration for IPS in CVR prediction task}\label{alg:cap}

\KwInput{$X$: set of item-user features, $\mathcal{O}$: click label matrix, $\mathbf{R^o}$: observed conversion label matrix}
\KwOutput{$\theta$}
Initialize the parameter $\phi,\theta$\;
\For{number of steps for training propensity estimation model $g_\phi$}
{
Sample a batch from $X$ and $\mathcal{O}$\;
Update $\phi$ by descending along the gradient $\nabla_\phi \mathcal{L}_{g_\phi}(\phi)$\;
}

\If{Uncertainty Quantification is used}
{
    Obtain multiple model ensemble/non-ensemble model using Eqn.~\ref{eqn:model_average}\;

}
\ElseIf{Post-processing Calibration is used}
{
    Calibrating the overconfident predicts to calibrated ones using Eqn.~\ref{eqn:platt}\;
}
Output propensity scores $\mathcal{\hat{P}}$ using $g_\phi$ for observed samples\;
\For{number of steps training the CVR prediction model $f_\theta$}
{
Sample a batch from $\mathbf{R^o}$ and $\mathcal{\hat{P}}$\;
Update $\theta$ by descending along the gradient $\nabla_\theta \mathcal{L}_{\textrm{IPS}}(\theta)$\;
}

\end{algorithm}

With the calibrated propensity scores, we can train the propensity-based CVR prediction debiasing model in two steps: first, train the propensity estimation model $g_\phi$, obtain the calibrated propensity scores, and then train the CVR prediction model $f_\theta$ using these inverse calibrated propensities. This process is detailed in Algorithm~\ref{alg:cap}.

\subsubsection{Computational Complexity Analysis}
\label{sec:computational complexity}
The computational complexity of the calibration methods for propensity score estimation varies significantly across techniques. The choice of calibration method greatly impacts computational costs. Deep ensembles are likely the most computationally expensive due to the necessity of multiple training cycles, followed by Monte Carlo Dropout, which scales with the number of samples. Post-processing calibration methods typically involve lighter computations on the outputs of an existing model. Below is a comprehensive analysis of each method.
\begin{itemize}
    \item {Monte Carlo Dropout involves sampling the model output multiple times (denoted as $T$) with randomly deactivated neurons. Each sample incurs a forward pass through the neural network, thus making the computational cost proportional to $T$ times the cost of a single forward pass. The complexity is therefore $O(T \times C)$ where $C$ represents the computational cost of one forward pass through the network.}
    \item {Deep Ensembles, on the other hand, requires training multiple independent models from scratch with different initializations. Assuming each model has a training complexity of $O(M)$, where $M$ represents the training complexity of one model (typically including several epochs and forward-backward passes), and there are $N$ such models, the total computational cost would be $O(N \times M)$. The cost can be substantially higher than Monte Carlo Dropout, especially if $N$ and the complexity of individual model training are large. To mitigate the high computational demand of traditional deep ensembles, the BatchEnsemble method can be incorporated, which shares parameters across different models in the ensemble, thereby reducing both memory usage and computational overhead while preserving model diversity~\cite{wen2019batchensemble}.}
    \item {Post-Processing Calibration (e.g., Platt Scaling) involves adjusting the outputs of an already trained model using additional parameters (like $b$ and $c$ in Platt scaling). The primary computational expense here is the forward pass to compute $g_\phi(x)$ and the subsequent optimization to learn the calibration parameters. This can generally be much less computationally intensive compared to the previous methods, as it typically involves simpler operations over the modelâ€™s outputs and potentially fewer parameters to optimize.}
\end{itemize}



\subsection{Theoretical Analysis of Uncertainty Calibration using Expected Calibration Errors}
By calibrating the propensity uncertainty, the expected calibration error can be reduced, leading to improved CVR predictions. We now provide a theoretical analysis of the proposed method.

We first derive the bias of the IPS estimator in Eqn.~\ref{eqn:IPS}:
\begin{lemma}
    \label{lemma:bias}
    Given inverse propensities of all user-item pairs $\hat{p}_{u,i}$, the bias of the IPS estimator in Eqn.~\ref{eqn:IPS} and the propensity bias are:
  \begin{eqnarray}
    \mathcal{E}_{\text{IPS}}=\left|\sum_{u,i\in\mathcal{D}}\frac{\nabla_{u,i}e_{u,i}}{|\mathcal{D}|}\right|, \\
        \nabla=\frac{\hat{p}_{u,i}-p_{u,i}}{\hat{p}_{u,i}}.
  \end{eqnarray}
\end{lemma}
Lemma \ref{lemma:bias}, as proved and cited from~\cite{wang2019doubly}, demonstrates that the bias of the IPS estimator is proportional to the biases in propensity scores.It follows directly that if the IPS estimator is well-calibrated, the bias term in Lemma~~\ref{lemma:bias} will be zero, indicating that a well-calibrated IPS estimator yields an unbiased estimate.

\begin{theorem}
    \label{theorem:upper_bound}
  For a calibrated IPS estimator, the bias is smaller than the uncalibrated IPS estimator:
    \begin{equation}
        \left|\sum_{u,i\in\mathcal{D}}\frac{\tilde{\nabla}_{u,i}e_{u,i}}{|\mathcal{D}|}\right|  
    \leq \left|\sum_{u,i\in\mathcal{D}}\frac{{\nabla}_{u,i}e_{u,i}}{|\mathcal{D}|}\right| ,
    \end{equation}
if the propensity is calibrated:
\begin{equation}
  \tilde{\nabla}_{u,i}=\frac{\tilde{p}_{u,i}-p_{u,i}}{\tilde{p}_{u,i}}\leq \nabla_{ui}, \tilde{p}=q(f(x)),
\end{equation}
where $q$ is a specific uncertainty calibration method, such as MC-Dropout, deep ensembles and the platt scaling.
\end{theorem}
\begin{proof}
  For a calibrated propensity, the propensity bias has a smaller bias and then the estimator bias smaller according to Lemma~\ref{lemma:bias}.
\end{proof}
Theorem~\ref{theorem:upper_bound} provides insights into the importance of uncertainty and Expected Calibration Error (ECE) in the Inverse Propensity Score (IPS) estimation. As demonstrated in the experiments, a significant reduction in the ECE of IPS leads to improved counterfactual recommendation results under Missing Not At Random (MNAR) conditions.

It has been rigorously analyzed in the literature that not only deep learning models but also shallow models, such as logistic regression, are inherently overconfident. The ECE of a well-specified logistic regression model is positive and cannot be completely eliminated. For further details, refer to~\cite{bai2021don,vaicenavicius2019evaluating}. Consequently, the original IPS estimator is also susceptible to miscalibrated uncertainty and large bias.

\begin{corollary}
  The unbiased and better calibration arguments in Theorem~\ref{theorem:upper_bound} also holds for the doubly robust estimator in~\cite{wang2019doubly}, which consists of the IPS estimator and the error-imputation-based estimator.
\end{corollary}
\begin{proof}
  It was shown in~\cite{wang2019doubly} that the bias term of the doubly estimator is also proportional to the IPS bias:
  \begin{equation}
    \mathcal{E}_{\text{IPS}}=\left|\sum_{u,i\in\mathcal{D}}\frac{\tilde{\nabla}_{u,i}\delta_{u,i}}{|\mathcal{D}|}\right|,
  \end{equation}
  where $\delta_{u,i}$ is the error derivation for missing ratings.
  This completes the proof.
\end{proof}
The prediction inaccuracy of a model is expected to be reduced through uncertainty calibration for the IPS estimator. Given the observed rating matrix $R$, the optimal rating prediction $\hat{R}^{*}$ is learned by the calibrated IPS estimator over the hypothesis space $\mathcal{H}$. We then present the generalization bound and the bias-variance decomposition of the calibrated IPS estimator using the expected calibration errors~\cite{schnabel2016recommendations,wang2019doubly}.
\begin{theorem}\label{theorem:generalization-bound}
  For any finite hypothesis space $\mathcal{H}$ of the recommendation prediction estimations, the prediction error of the optimal prediction matrix $\hat{R}^{*}$ using the calibrated inverse propensity score estimator has the following generalization bound:
    \begin{equation}\label{eqn:generalization-bound}
       \mathcal{E}(\hat{R}^{*},R^{o})+
       \sum_{u,i\in\mathcal{D}}\frac{\tilde{\nabla}_{u,i}}{|\mathcal{D}|}+
       \sqrt{\frac{\log \frac{2|\mathcal{H}|}{\eta}}{2|\mathcal{D}|^2}\sum_{u,i\in\mathcal{D}}\frac{1}{\hat{p}_{ui}^2}},
    \end{equation}
    where the star superscript means the optimal prediction and the tilde means the calibrated IPS estimator.
    $R^{o}$ is the observed rating matrix $R^{o}=\{r_{ui}, o_{ui}=1\}$.
    The second term and third corresponds to the bias term and variance term respectively.
\end{theorem}
\begin{proof}
  Following the generalization bounds of the IPS and DR scoring models in \cite{schnabel2016recommendations,wang2019doubly}, we replace the propensity error with the calibrated one $\tilde{\nabla}$ and get the generalization bound of the calibrated IPS model.
\end{proof}
Theorem~\ref{theorem:generalization-bound} reveals the bias-variance tradeoff in the real-world performance of the calibrated inverse propensity score estimator. A smaller bias results from reduced propensity bias. Additionally, lower propensity estimation error and expected calibration error (ECE) lead to better recommendation results.

We assume that the calibrated IPS has lower estimation error and calibration loss. Furthermore, IPS predictions are generally overestimated. With these two assumptions, we derive the following corollary.

\begin{corollary}\label{corollary:bias-variance}
Compared with the inverse propensity score estimator, the prediction error bound of the calibrated doubly robust estimator has a smaller bias and has a upper bound that is propotional to $\text{ECE}$:
    \begin{equation}\label{eqn:ece-bound}
        \sum_{u,i\in\mathcal{D}}\frac{\tilde{\nabla}_{u,i}}{|\mathcal{D}|} \leq \sum_{u,i\in\mathcal{D}}\frac{n\cdot\text{ECE}}{|\mathcal{D}|},
    \end{equation}
    where $n$ is the number of the bins for ECE.
\end{corollary}
\begin{proof}
  The calibrated propensity has a lower bias so the bias term of the calibrated IPS is reduced:
  \begin{equation}
    \sum_{u,i\in\mathcal{D}}\frac{\tilde{\nabla}_{u,i}}{|\mathcal{D}|} < \sum_{u,i\in\mathcal{D}}\frac{{\nabla}_{u,i}}{|\mathcal{D}|}.
  \end{equation}
  For the upper bound that consists of ECE, we first rewrite ECE as:
  \begin{equation}
    \text{ECE}=\sum_{j=1}^{n}|\xi_{j}-\hat{\xi}_{j}|=\sum_{i=1}^{n}\left|\sum_{i=1}^{B_{j}}p_{ji}-\sum_{i=1}^{B_{j}}\tilde{p}_{ji}\right|,
  \end{equation}
  where $B_{ji}$ is the number of samples in the $j$-th bin and $p_{ji}$ is the propensity of the $i$-th sample in the $j$-th bin.
  By taking the absolute value for every bin , we can get the result of Eqn.~
  \ref{eqn:ece-bound}.
\end{proof}

%We defer the proofs to Appendix~\ref{appendix:bias-ips} and \ref{appendix:generalization-bound} due to the lack of space.

Corollary~\ref{corollary:bias-variance} demonstrates that the expected calibration error (ECE) effectively bounds the final prediction error.

\section{Experiments}
In this section, we will first provide an overview of the experimental setting, which includes details about the dataset, metrics, and baselines. We will then present our findings on calibration and CVR prediction based on two real-world datasets. Our experiments aim to address three key research questions (RQs):



\begin{enumerate}[(1)]
    \item To what extent is raw propensity estimation miscalibrated? How much improvement can be achieved through our uncertainty calibration module in terms of ECE?
    \item Why is ECE a reliable indicator of propensity score quality? Does a lower ECE result in increased CVR prediction task performance?
    \item How does uncertainty calibration enhance state-of-the-art models in terms of debiasing recommendation performance?
\end{enumerate}


\subsection{Experimental Setting}


\textbf{Datasets and Preprocessing} \\
To assess the debiasing capability of recommendation methods, it is crucial to have a Missing At Random (MAR) testing set. To achieve this, we utilize three prominent datasets: Coat Shopping, Yahoo! R3, and KuaiRand. These datasets contain MAR test sets that enable us to evaluate the performance of CVR prediction without bias~\cite{schnabel2016recommendations,wang2019doubly}.
\begin{itemize}
    \item \textbf{Coat Shopping}\footnote{\url{https://www.cs.cornell.edu/~schnabts/mnar/}}: The coat shopping dataset was collected to simulate the missing not at random data of user shopping for coats online. The costumers were ordered to find their favorite coats in the online store. After browsing, the users were asked to rate 24 coats they had explored before and 16 randomly picked ones on a five point scale. It contains ratings from 290 users of 300 items. There are 6960 MNAR ratings  and 4640 MAR ratings. 
    \item \textbf{Yahoo! R3}\footnote{\url{http://webscope.sandbox.yahoo.com/}}: This dataset contains ratings for music collected from two different ways. The first source consists of ratings supplied by users during interaction with Yahoo Music services, which means that the data collected from this source suffer from Missing Not At Random problem. The second source consists of ratings to the music randomly recommended to users during an online survey which means that the data collected from this source is Missing Completely At Random. It includes approximately 300K ratings among which 54000 are MAR ratings.
    \item {\textbf{KuaiRand}\footnote{\url{https://kuairand.com/}}: this datasets includes 7583 videos and 27285 users, containing 1436609 biased data and 1186509 unbiased data. Following recent work\cite{song2023cdr}, we regard the biased dsata as the training set, and utilize the unbiased data for model validation (10\%) and evaluation (90\%).} 
\end{itemize}

To ensure consistency with the CVR prediction task, we preprocess the three datasets using methods established in previous studies~\cite{guo2021enhanced,saito2020doubly,dai2022generalized}. Here are the specific steps:
\begin{enumerate}[(1)]
    \item The conversion label $r_{u,i}$ is assigned a value of 1 if the rating for the user-item pair is greater than or equal to 4; otherwise it is assigned a value of 0. 
    \item Similarly, the click label $o_{u,i}$ is set to 1 if user $u$ has rated item $i$, and 0 otherwise.
    \item  We obtain the post-click conversion datasets as $\{(u,i,r_{u,i}) | o_{u,i} = 1, \forall (u,i) \in \mathcal{D}\}$
\end{enumerate}
Subsequently, we randomly split both datasets into training and validation sets. For MNAR ratings, 90\% of the ratings are allocated to the training set, while the remaining 10\% are reserved for the validation set. The MAR ratings are kept separate and used as a test set for evaluation purposes.


\noindent\textbf{Calibration Methods Settings} \\
We employ the aforementioned calibration methods for the uncalibrated inverse propensity score and select Neural Collaborative Filtering (\textit{NeuMF}) as the base recommendation method~\cite{he2017neural}. We denote the representative IPS models with and without calibration as follows:
\begin{itemize}
    \item \textbf{Raw Method:} We train a raw propensity estimation model that is not calibrated.
    \item \textbf{MC Dropout}~\cite{gal2016dropout}: Dropout is kept active during the inference stage. For a given user-item pair during testing, we pass it through the propensity model ten times with dropout active, averaging the results to obtain a calibrated propensity score.
    \item \textbf{Deep Ensembles}~\cite{lakshminarayanan2017simple}: We initialize ten models with different random seeds and shuffle the training dataset independently for each model. During testing, we aggregate predictions from these ten models and average the results to obtain calibrated propensity scores.
    \item \textbf{Platt Scaling}~\cite{platt1999probabilistic}: We optimize the cross-entropy loss using LBFGS to learn parameters \( b \) and \( c \) in Eqn.~\ref{eqn:platt} for calibrating the propensity scores.
\end{itemize}


\noindent \textbf{Baselines}


We validate the effectiveness of our methods on three baselines, including two benchmark doubly robust (DR) methods, DR-JL~\cite{wang2019doubly} and MRDR~\cite{guo2021enhanced}, and one classical baseline, Inverse Propensity Scoring (IPS)~\cite{schnabel2016recommendations}. We also compare the calibrated and improved MRDR with four state-of-the-art methods: two are based on multi-task learning, ESCM$^2$-DR~\cite{wang2022escm} and DR-V2~\cite{pmlr-v202-li23ah}; the other two methods improve the propensity score estimation (GPL~\cite{10.1145/3583780.3614760}) and imputation error~\cite{song2023cdr}, respectively.

\noindent\textbf{Evaluation Metric}\\
For uncertainty calibration, we assess the expected calibration error (ECE) using Eqn.~\ref{eqn:ece}.

For evaluating recommendation results, we employ two metrics: discount cumulative gain (DCG) and Recall. These are defined as:
\begin{eqnarray}
    \label{eqn:dcg}
    {\rm DCG}(K) = \sum_{k=1}^K \frac{Rel_{k}}{\log_2 (k+1)}, \\
    \label{eqn:recall}
    {\rm Recall}(K) = \sum_{k=1}^K Rel_{k},
\end{eqnarray}
where $k$ represents the ranking order, $K$ is a hyperparameter of the DCG metric, and $Rel_k$ is a binary indicator indicating whether the $k$-th sample is a positive sample.

Further implementation details, including evaluation metrics, optimization, and hyperparameters for all baselines, can be found in Section II in Supplemental Materials.

\subsection{Calibration Results of propensity scores(RQ1)}
We applied the three calibration methods for propensity scores and plotted the calibration curves along with the estimated Expected Calibration Error (ECE) for the propensity model. The ECE was computed using 100 bins.
\begin{table}[htbp]
\centering
\begin{tabular}{c|cc}
\toprule
\diagbox{Methods}{Datasets}    & Coat shopping & Yahoo! R3 \\ \midrule
raw         & 0.1458        & 0.1131    \\
MC Dropout     & 0.1369        & 0.1064    \\
Deep Ensemble    & 0.1408        & 0.1039    \\
Platt Scaling &\textbf{0.0433} & \textbf{0.0301}\\ 

\bottomrule
\end{tabular}
\caption{Expectation Calibration Errors of Calibrated Propensity Scores}
\label{tb:ece}
\end{table}

As shown in Table~\ref{tb:ece}, the calibration methods, especially Platt scaling, significantly reduce the Expected Calibration Error (ECE). Compared to uncalibrated propensity scores, Platt scaling reduces the ECE by more than a factor of three.
Figure~\ref{fig:coat} presents the calibration curves and propensity histograms of the calibrated propensity scores, where "Raw" denotes uncalibrated propensity scores. In Figure~\ref{fig:coat}(a), calibration narrows the gap between the raw propensity model and the perfect propensity model (represented by the diagonal line). Since propensity-based debiasing methods rely solely on propensity scores from click events, the right side of the calibration curve further validates the effectiveness of propensity score calibration.


\begin{figure}[htbp!]
    \centering
    \subcaptionbox{Calibration Curve}{\includegraphics[width=0.3\textwidth]{coat_curve.pdf}}
    \subcaptionbox{propensity scores Histgram}{\includegraphics[width=0.3\textwidth]{coat_hist.pdf}}
    \caption{Calibration Curve and Propensity Histograms of Calibrated propensity scores on the Coat Shopping Dataset}
    \label{fig:coat}
\end{figure}

\begin{figure}[htbp!]
    \centering
    \subcaptionbox{Calibration Curve}{\includegraphics[width=0.3\textwidth]{yahoo_curve.pdf}}
    \subcaptionbox{propensity scores Histogram}{\includegraphics[width=0.3\textwidth]{yahoo_hist.pdf}}
    \caption{Calibration Curve and Propensity Histogram of Calibrated Propensity scores on the Yahoo! R3 Shopping Dataset}
    \label{fig:yahoo-calibration}
\end{figure}

\begin{table*}[!htbp]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{llccccccc}
\toprule
\multirow{2}{*}{Datasets}      & \multirow{2}{*}{Methods} & \multicolumn{3}{c}{DCG@K}                     & \multicolumn{3}{c}{Recall@K}          & \multirow{2}{*}{Average}        \\ \cmidrule(r){3-5} \cmidrule(r){6-8} 
&   & K=2  & K=4   & K=6 & K=2 & K=4 & K=6           \\ \midrule\


\multirow{5}{*}{Coat Shopping} 
& ${\rm Neumf}_{base}$ & 0.7478 & 1.0152 & 1.1989 & 0.8705 & 1.4435 & 1.9371 & 1.2021 \\

& Raw & 0.7472{\tiny $\pm$0.0143} & 1.0204{\tiny $\pm$0.0124} & 1.2010{\tiny $\pm$0.0111} & 0.8738{\tiny $\pm$0.0176} & 1.4591{\tiny $\pm$0.0177} & 1.9451{\tiny $\pm$0.0227} & 1.2077\\

& MC Dropout  & \textbf{0.7651{\tiny $\pm$0.0242}} & \underline{1.0322{\tiny $\pm$0.0172}} & \underline{1.2101{\tiny $\pm$0.0145}} & \textbf{0.8962{\tiny $\pm$0.0283}} & \underline{1.4675{\tiny $\pm$0.0266}} & 1.9443{\tiny $\pm$0.0209} & \underline{1.2192}\\

& Deep Ensembles           & 0.7584{\tiny$\pm$0.0271} & 1.0256{\tiny$\pm$0.0232} & 1.2065{\tiny$\pm$0.0225} & 0.8848{\tiny$\pm$0.0342} & 1.4574{\tiny $\pm$0.0341} & \underline{1.9454{\tiny $\pm$0.0322}} & 1.2127\\

& Platt Scaling            & \underline{0.7627{\tiny $\pm$0.0155}} & \textbf{1.0405{\tiny $\pm$0.0215}} & \textbf{1.2259{\tiny $\pm$0.0171}} & \underline{0.8890{\tiny $\pm$0.0168}} & \textbf{1.4823{\tiny $\pm$0.0374}} & \textbf{1.9806{\tiny $\pm$0.0229}} & \textbf{1.2301} \\

\midrule \midrule

\multirow{5}{*}{Yahoo! R3}     
& ${\rm Neumf}_{base}$ & 0.5277{\tiny $\pm$0.0209} & 0.7352{\tiny $\pm$0.0209} & 0.8630{\tiny $\pm$0.0209} & 0.6333{\tiny $\pm$0.0209} & 1.0769{\tiny $\pm$0.0209} & 1.4202{\tiny $\pm$0.0209} & 0.8760\\

& Raw & \underline{0.5433{\tiny $\pm$0.0056}} & 0.7395{\tiny $\pm$0.0065} & 0.8669{\tiny $\pm$0.0062} & \underline{0.6468{\tiny $\pm$0.0048}} & 1.0661{\tiny $\pm$0.0063} & 1.4086{\tiny $\pm$0.0057} & 0.8785\\

& MC Dropout  & 0.5410{\tiny $\pm$0.0178} & 0.7406{\tiny $\pm$0.0202} & 0.8663{\tiny $\pm$0.0187} & 0.6452{\tiny $\pm$0.0197} & 1.0720{\tiny $\pm$0.0248} & 1.4094{\tiny $\pm$0.0211} & 0.8790\\

& Deep Ensembles & 0.5342{\tiny $\pm$0.0043} & \underline{0.7412{\tiny $\pm$0.0047}} & \underline{0.8692{\tiny $\pm$0.0027}} & 0.6404{\tiny $\pm$0.0049} & \underline{1.0831{\tiny $\pm$0.0068}} & \underline{1.4270{\tiny $\pm$0.0047}} & \underline{0.8825}\\

& Platt Scaling & \textbf{0.5470{\tiny $\pm$0.0065}} & \textbf{0.7535{\tiny $\pm$0.0033}} & \textbf{0.8778{\tiny $\pm$0.0039}} & \textbf{0.6528{\tiny $\pm$0.0088}} & \textbf{1.0941{\tiny $\pm$0.0053}} & \textbf{1.4275{\tiny $\pm$0.0060}} & \textbf{0.8921}\\

\bottomrule
\end{tabular}
}
\caption{Overall IPS-based recommendation performance on Coat Shopping and Yahoo! R3. The best results are shown in boldface and the second best results are marked using underline.}
\label{tb:rec_results}
\end{table*}


Figure~\ref{fig:coat}(b) shows the propensity histograms of the calibrated IPS methods trained on the Coat Shopping dataset. It can be observed that the calibrated propensity scores not only exhibit lower ECE but also demonstrate reduced polarization. Both ECE and polarization are crucial aspects of propensity scores. The calibration curve and propensity histograms for the Yahoo! R3 dataset are detailed in Figure~\ref{fig:yahoo-calibration}, which supports the findings from Figure~\ref{fig:coat}.

\subsection{CVR Prediction Results of IPS(RQ2)}

We utilize both uncalibrated and calibrated propensity scores to train the debiasing CVR models $f_\theta$, respectively. As a baseline, we train the recommendation model without using propensity scores, implying that all samples are given equal weight for loss. Table~\ref{tb:rec_results} presents the overall IPS debiasing performance in terms of DCG@K and Recall@K ($K=2,4,6$) on three real-world datasets\footnote{Recall refers to the recall number, which may exceed 1 based on the equation in Eqn.~\ref{eqn:recall}}. We repeat the experiments ten times and report the mean results to mitigate randomness. From the table, it can be observed that the IPS method with uncalibrated propensity scores achieves marginal improvement in recommendation performance compared to the baseline methods. Interestingly, the recall metric for the Yahoo! R3 dataset even shows a slight decrease, indicating that poorly calibrated propensity scores do not effectively aid the IPS-based training process.


With calibrated propensity scores, the IPS debiasing method shows significant improvement. As demonstrated in Table~\ref{tb:rec_results} and Table~\ref{tb:kuairand}, Platt scaling calibrated propensity scores outperform the uncalibrated ones in terms of DCG@K and Recall@K ($K=2,4,6$) on three real-world datasets. Specifically, Platt scaling shows a substantial relative improvement of 2.08\%, 1.98\%, and 2.07\% over the uncalibrated method for DCG@2, DCG@4, and DCG@6, respectively.


From the results presented in Table~\ref{tb:ece} and Table~\ref{tb:rec_results}, it is evident that propensity scores with lower calibration errors yield better recommendation results. The propensity scores calibrated by Platt scaling exhibit the lowest calibration error and outperform other calibration techniques across most recommendation evaluation metrics. Hence, ECE serves as a reliable measure of the effectiveness of propensity scores in mitigating bias in recommendations.

\subsection{CVR predcition Results of SOTA debiasing methods(RQ3)}

As our method improves the quality of propensity score estimation, it can readily be extended to other propensity score-based debiasing methods. We conducted experiments on six state-of-the-art CVR prediction models: DR-JL~\cite{wang2019doubly}, MRDR~\cite{guo2021enhanced}, GPL~\cite{zhou2023generalized}, CDR~\cite{song2023cdr}, DR-V2~\cite{pmlr-v202-li23ah}, and ESCM$^2$~\cite{wang2022escm}. Table~\ref{tb:dr} demonstrates that calibrated propensity scores outperform raw propensity scores on all evaluation metrics, highlighting the effectiveness of uncertainty calibration for other propensity score-based methods. Table~\ref{tb:sota} shows that our method surpasses current state-of-the-art (SOTA) approaches in terms of performance.

\subsection{{Efficiency experiment}}

\begin{table}[h]
\begin{tabular}{ccccc}
\toprule
Methods  & Raw  & Platt Scaling & MC Dropout & Deep Ensembles    \\  \midrule
Training & 34.12s  & 36.31s         & 34.12s     & 246.34s                   \\
Inference     & 2.51s & 2.53s          & 5.78s      & 6.11s                    \\ \bottomrule
\end{tabular}
\caption{The time consumption of the Propensity estimation model employing different calibration techniques on dataset Coat Shopping in seconds. }
\end{table}

Table 4 presents the time consumption of the propensity estimation model using different calibration techniques on the Coat Shopping dataset. The efficiency experiment was conducted on a single 3090 GPU. It is evident that both Platt scaling and MC dropout techniques exhibit low time costs, whereas Deep Ensemble incurs higher costs due to the necessity of training multiple models. Therefore, the BatchEnsembles method~\cite{wen2019batchensemble} can be employed to reduce the overall computation cost. These efficiency experiment results are consistent with the complexity analysis in Section~\ref{sec:computational complexity}.



\begin{table*}[!htbp]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c|ccccccccc}
\toprule
\multicolumn{1}{c}{}& & & \multicolumn{3}{c}{DCG@K} & \multicolumn{3}{c}{Recall@K} \\ \cmidrule(r){4-6} \cmidrule(r){7-9} 
\multicolumn{1}{c}{\multirow{-2}{*}{Baseline}} & \multirow{-2}{*}{Dataset}  & \multirow{-2}{*}{Methods} & K=2 & K=4  & K=6 & K=2  & K=4 & K=6  & \multirow{-2}{*}{Average} \\ \midrule

& & Raw & 0.7454{\tiny $\pm$0.0158} & 1.0185{\tiny $\pm$0.0196} & 1.2014{\tiny $\pm$0.0126} & 0.8717{\tiny $\pm$0.0214} & 1.4570{\tiny $\pm$0.0243} & 1.9489{\tiny $\pm$0.0209} & 1.2071 \\

& & Dropout  & 0.7496{\tiny $\pm$0.0205} & \underline{1.0271{\tiny $\pm$0.0165}} & 1.2073{\tiny $\pm$0.0157} & \underline{0.8835{\tiny $\pm$0.0249}} & \underline{1.4764{\tiny $\pm$0.0216}} & 1.9603{\tiny $\pm$0.0286} &1.2173 \\

& & Ensembles & \textbf{0.7546{\tiny $\pm$0.0160}} & 1.0254{\tiny $\pm$0.0110} & \underline{1.2132{\tiny $\pm$0.0119}} & \underline{0.8835{\tiny $\pm$0.0228}} & 1.4637{\tiny $\pm$0.0126} & \underline{1.9684{\tiny $\pm$0.0232}} & \underline{1.2181}\\

& \multirow{-4}{*}{Coat Shopping} 

& Platt  & \underline{0.7539{\tiny $\pm$0.0201}} & \textbf{1.0389{\tiny $\pm$0.0208}} & \textbf{1.2241{\tiny $\pm$0.0170}} & \textbf{0.8852{\tiny $\pm$0.0235}} & \textbf{1.4940{\tiny $\pm$0.0290}} & \textbf{1.9928{\tiny $\pm$0.0208}} & \textbf{1.2315}\\ 

\cmidrule(r){2-10} \cmidrule(r){2-10}

& & Raw & 0.5450{\tiny $\pm$0.0093} & 0.7405{\tiny $\pm$0.0097} & \underline{0.8779{\tiny $\pm$0.0091}} & 0.6402{\tiny $\pm$0.0113} & 1.0587{\tiny $\pm$0.0143} & 1.4112{\tiny $\pm$0.0141} & 0.8789\\

& & Dropout & \underline{0.5501{\tiny $\pm$0.0152}} & \underline{0.7597{\tiny $\pm$0.0126}} & 0.8774{\tiny $\pm$0.0103} & \underline{0.6539{\tiny $\pm$0.0161}} & 1.0822{\tiny $\pm$0.0124} & 1.4183{\tiny $\pm$0.0065} & \underline{0.8902}\\

& & Ensembles & 0.5431{\tiny $\pm$0.0053} & 0.7491{\tiny $\pm$0.0043} & 0.8747{\tiny $\pm$0.0050} & 0.6510{\tiny $\pm$0.0044} & \underline{1.0923{\tiny $\pm$0.0054}} & \underline{1.4293{\tiny $\pm$0.0068}} & 0.8899\\
\multirow{-8}{*}{DR-JL} & \multirow{-4}{*}{Yahoo! R3} 

& Platt  & \textbf{0.5532{\tiny $\pm$0.0058}} & \textbf{0.7555{\tiny $\pm$0.0042}} & \textbf{0.8816{\tiny $\pm$0.0034}} & \textbf{0.6602{\tiny $\pm$0.0059}} & \textbf{1.0926{\tiny $\pm$0.0073}} & \textbf{1.4314{\tiny $\pm$0.0062}} & \textbf{0.8957}\\

\midrule \midrule 

& & Raw    & 0.6830{\tiny $\pm$0.0151} &  0.9661{\tiny $\pm$0.0131} &  1.1578{\tiny $\pm$0.0101} &  0.8185{\tiny $\pm$0.0163} &  1.4261{\tiny $\pm$0.0192} &  1.9409{\tiny $\pm$0.0205} &  1.1654\\

& & Dropout & 0.7255{\tiny $\pm$0.0200} & 0.9946{\tiny $\pm$0.0138} & \underline{1.1847{\tiny $\pm$0.0127}} & 0.8438{\tiny $\pm$0.0257} & 1.4177{\tiny $\pm$0.0247} & \underline{1.9282{\tiny $\pm$0.0312}} & 1.1824\\

& & Ensembles & \underline{0.7292{\tiny $\pm$0.0273}} & \underline{1.0001{\tiny $\pm$0.0192}} & 1.1846{\tiny $\pm$0.0182} & \underline{0.8523{\tiny $\pm$0.0352}} & \underline{1.4303}{\tiny $\pm$0.0190} & \underline{1.9282{\tiny $\pm$0.0299}} & \underline{1.1875}\\

& \multirow{-4}{*}{Coat Shopping}
& Platt  & \textbf{0.7648{\tiny $\pm$0.0190}} & \textbf{1.0155{\tiny $\pm$0.0170}} & \textbf{1.2223{\tiny $\pm$0.0165}} & \textbf{0.8987{\tiny $\pm$0.0230}} & \textbf{1.4688{\tiny $\pm$0.0258}} & \textbf{1.9957{\tiny $\pm$0.0395}} &  \textbf{1.2276} \\

\cmidrule(r){2-10} 

& & Raw & 0.5371{\tiny $\pm$0.0447} & 0.7441{\tiny $\pm$0.0502} & 0.8636{\tiny $\pm$0.0455} & 0.6383{\tiny $\pm$0.0508} & 1.0808{\tiny $\pm$0.0638} & 1.4006{\tiny $\pm$0.0524} & 0.8774 \\

& & Dropout & \underline{0.5458{\tiny $\pm$0.0194}} & \underline{0.7461{\tiny $\pm$0.0240}} & 0.8718{\tiny $\pm$0.0225} & \underline{0.6547{\tiny $\pm$0.0209}} & \underline{1.0821{\tiny $\pm$0.0363}} & 1.4199{\tiny $\pm$0.0382} &  \underline{0.8867}\\

& & Ensembles & 0.5410{\tiny $\pm$0.0093} &  0.7443{\tiny $\pm$0.0098} &  \underline{0.8731{\tiny $\pm$0.0090}} &  0.6444{\tiny $\pm$0.0120} &  1.0809{\tiny $\pm$0.0133} &  \underline{1.4256{\tiny $\pm$0.0127}} & 0.8847\\

\multirow{-8}{*}{MRDR} & \multirow{-4}{*}{Yahoo! R3} & Platt & \textbf{0.5623{\tiny $\pm$0.0092}} & \textbf{0.7571{\tiny $\pm$0.0066}} & \textbf{0.8858{\tiny $\pm$0.0072}} & \textbf{0.6687{\tiny $\pm$0.0103}} & \textbf{1.0862{\tiny $\pm$0.0080}} & \textbf{1.4326{\tiny $\pm$0.009}} & \textbf{0.8988}
\\
\bottomrule

\end{tabular}
}
\caption{DRJL and MRDR CVR prediction performance on Coat Shopping and Yahoo! R3. The best results are shown in boldface and the second best results are marked using underline.}

\label{tb:dr}
\end{table*}


% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage[table,xcdraw]{xcolor}
% Beamer presentation requires \usepackage{colortbl} instead of \usepackage[table,xcdraw]{xcolor}
% \usepackage[normalem]{ulem}
% \useunder{\uline}{\ul}{}
\begin{table*}[]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{ccccccccc}
\toprule
\multicolumn{2}{c}{}                          & \multicolumn{3}{c}{DCG@K}                        & \multicolumn{3}{c}{Recall@K}                     &                           \\ \cmidrule(r){3-5} \cmidrule(r){6-8}
\multicolumn{2}{c}{\multirow{-2}{*}{Methods}} & K=2                    & K=4                    & K=6                    & K=2                    & K=4                    & K=6                    & \multirow{-2}{*}{Average} \\ \midrule
                           & Raw              & 0.4426{\tiny $\pm$ 0.0076}          & 0.6728{\tiny $\pm$ 0.0110}          & 0.8471{\tiny $\pm$ 0.0108}          & 0.5404{\tiny $\pm$ 0.0096}          & 1.0351{\tiny $\pm$ 0.0166}          & 1.5028{\tiny $\pm$ 0.0163}          & 0.8401                                            \\
                           & MC Dropout       & 0.4515{\tiny $\pm$ 0.0063}          & 0.6855{\tiny $\pm$ 0.0064}          & 0.8593{\tiny $\pm$ 0.0069}          & 0.5520{\tiny $\pm$ 0.0073}          & 1.0545{\tiny $\pm$ 0.0080}          & 1.5208{\tiny $\pm$ 0.0101}          & 0.8539                                            \\
                           & Deep Ensembles   & \underline{0.4562{\tiny $\pm$ 0.0045}}    & \underline{0.6893{\tiny $\pm$ 0.0048}}    & \underline{0.8627{\tiny $\pm$ 0.0042}}    & \underline{0.5579{\tiny $\pm$ 0.0052}}    & \underline{1.0575{\tiny $\pm$ 0.0063}}    & \underline{1.5228{\tiny $\pm$ 0.0058}}    & \underline{0.8577}                                      \\
\multirow{-4}{*}{IPS}      & Platt Scaling    & \textbf{0.4657{\tiny $\pm$ 0.0030}} & \textbf{0.7021{\tiny $\pm$ 0.0025}} & \textbf{0.8774{\tiny $\pm$ 0.0026}} & \textbf{0.5677{\tiny $\pm$ 0.0029}} & \textbf{1.0754{\tiny $\pm$ 0.0030}} & \textbf{1.5455{\tiny $\pm$ 0.0036}} & \textbf{0.8723}                                   \\ \midrule
                           & Raw              & 0.4442{\tiny $\pm$ 0.0083}          & 0.6742{\tiny $\pm$ 0.0111}          & 0.8481{\tiny $\pm$ 0.0115}          & 0.5420{\tiny $\pm$ 0.0096}          & 1.0362{\tiny $\pm$ 0.0160}          & 1.5026{\tiny $\pm$ 0.0170}          & 0.8412                                            \\
                           & MC Dropout       & 0.4504{\tiny $\pm$ 0.0042}          & 0.6839{\tiny $\pm$ 0.0044}          & 0.8580{\tiny $\pm$ 0.0052}          & 0.5504{\tiny $\pm$ 0.0041}          & 1.0520{\tiny $\pm$ 0.0047}          & 1.5189{\tiny $\pm$ 0.0071}          & 0.8523                                            \\
                           & Deep Ensembles   & \underline{0.4524{\tiny $\pm$ 0.0064}}    & \underline{0.6854{\tiny $\pm$ 0.0039}}    & \underline{0.8606{\tiny $\pm$ 0.0043}}    & \underline{0.5528{\tiny $\pm$ 0.0051}}    & \underline{1.0530{\tiny $\pm$ 0.0048}}    & \underline{1.5231{\tiny $\pm$ 0.0067}}    & \underline{0.8546}                                      \\
\multirow{-4}{*}{DR-JL}    & Platt Scaling    & \textbf{0.4701{\tiny $\pm$ 0.0073}} & \textbf{0.7070{\tiny $\pm$ 0.0079}} & \textbf{0.8834{\tiny $\pm$ 0.0080}} & \textbf{0.5733{\tiny $\pm$ 0.0081}} & \textbf{1.0823{\tiny $\pm$ 0.0095}} & \textbf{1.5553{\tiny $\pm$ 0.0096}} & \textbf{0.8786}                                   \\ \midrule
                           & Raw              & 0.4369{\tiny $\pm$ 0.0246}          & 0.6531{\tiny $\pm$ 0.0287}          & 0.8144{\tiny $\pm$ 0.0295}          & 0.5305{\tiny $\pm$ 0.0292}          & 0.9957{\tiny $\pm$ 0.0376}          & 1.4290{\tiny $\pm$ 0.0401}          & 0.8099                                            \\
                           & MC Dropout       & \underline{0.4412{\tiny $\pm$ 0.0125}}    & 0.6659{\tiny $\pm$ 0.0183}          & 0.8305{\tiny $\pm$ 0.0200}          & 0.5376{\tiny $\pm$ 0.0152}          & 1.0205{\tiny $\pm$ 0.0275}          & 1.4630{\tiny $\pm$ 0.0302}          & 0.8265                                            \\
                           & Deep Ensembles   & 0.4406{\tiny $\pm$ 0.0101}          & \underline{0.6681{\tiny $\pm$ 0.0127}}    & \underline{0.8432{\tiny $\pm$ 0.0135}}    & \underline{0.5390{\tiny $\pm$ 0.0131}}    & \underline{1.0275{\tiny $\pm$ 0.0171}}    & \underline{1.4972{\tiny $\pm$ 0.0215}}    & \underline{0.8359}                                      \\
\multirow{-4}{*}{MRDR}     & Platt Scaling    & \textbf{0.4928{\tiny $\pm$ 0.0057}} & \textbf{0.7259{\tiny $\pm$ 0.0076}} & \textbf{0.8963{\tiny $\pm$ 0.0079}} & \textbf{0.5971{\tiny $\pm$ 0.0070}} & \textbf{1.0972{\tiny $\pm$ 0.0109}} & \textbf{1.5549{\tiny $\pm$ 0.0119}} & \textbf{0.8940}                                   \\ \bottomrule
\end{tabular}}
\caption{Overall performance on KuaiRand.}
\label{tb:kuairand}

\end{table*}




% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage[table,xcdraw]{xcolor}
% Beamer presentation requires \usepackage{colortbl} instead of \usepackage[table,xcdraw]{xcolor}
% \usepackage[normalem]{ulem}
% \useunder{\uline}{\ul}{}
\begin{table*}[]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c|cccccccc}
\toprule
                     &           & \multicolumn{3}{c}{DCG@K} & \multicolumn{3}{c}{Recall@K} &  \\ \cmidrule(r){3-5}\cmidrule(r){6-8}
\multirow{-2}{*}{Datasets}      & \multirow{-2}{*}{Methods} & K=2                    & K=4                    & K=6                    & K=2                     & K=4                     & K=6                     & \multirow{-2}{*}{Average} \\ \midrule
                                & MRDR-GPL                                         & 0.7488{\tiny $\pm$ 0.0201}          & 1.0061{\tiny $\pm$ 0.0222}          & 1.1949{\tiny $\pm$ 0.0243}          & 0.8734{\tiny $\pm$ 0.0287}           & 1.4219{\tiny $\pm$ 0.0301}           & 1.9283{\tiny $\pm$ 0.0405}           & 1.1956                                            \\
                                & MRDR-CDR                                         & 0.7579{\tiny $\pm$ 0.0201}          & \underline{1.0192{\tiny $\pm$ 0.0192}}    & 1.1991{\tiny $\pm$ 0.0198}          & 0.8903{\tiny $\pm$ 0.0204}           & 1.4515{\tiny $\pm$ 0.0277}           & 1.9325{\tiny $\pm$ 0.0402}           & 1.2084                                            \\
                                & DR-V2                                               & \textbf{0.7746{\tiny $\pm$ 0.0188}} & 1.0116{\tiny $\pm$ 0.0164}          & 1.2076{\tiny $\pm$ 0.0176}          & 0.8841{\tiny $\pm$ 0.0184}           & 1.4568{\tiny $\pm$ 0.0152}           & 1.9494{\tiny $\pm$ 0.0324}           & 1.2140                                            \\
                                & ESCM$^2$-DR                                               & 0.7528{\tiny $\pm$ 0.0177}          & \textbf{1.0273{\tiny $\pm$ 0.0189}} & \underline{1.2081{\tiny $\pm$ 0.0229}}    & 0.8945{\tiny $\pm$ 0.0186}           & \textbf{1.4810{\tiny $\pm$ 0.0162}}  & 1.9662{\tiny $\pm$ 0.0299}           & \underline{1.2217}                                      \\ \rowcolor{lightgray}
\cellcolor{white}\multirow{-5}{*}{Coat Shopping} & MRDR-CAL(Ours)                                   & \underline{0.7648{\tiny $\pm$ 0.0190}}    & 1.0155{\tiny $\pm$ 0.0170}          & \textbf{1.2223{\tiny $\pm$ 0.0165}} & \textbf{0.8987{\tiny $\pm$ 0.0230}}  & \underline{1.4688{\tiny $\pm$ 0.0258}}     & \textbf{1.9957{\tiny $\pm$ 0.0395}}  & \textbf{1.2276}                                   \\ \midrule
                                & MRDR-GPL                                         & 0.5384{\tiny $\pm$ 0.0194}          & 0.7369{\tiny $\pm$ 0.0252}          & 0.8605{\tiny $\pm$ 0.0211}          & 0.6408{\tiny $\pm$ 0.0197}           & 1.0657{\tiny $\pm$ 0.0222}           & 1.3982{\tiny $\pm$ 0.0241}           & 0.8734                                            \\
                                & MRDR-CDR                                         & 0.5417{\tiny $\pm$ 0.0162}          & 0.7456{\tiny $\pm$ 0.0123}          & 0.8698{\tiny $\pm$ 0.0125}          & 0.6490{\tiny $\pm$ 0.0202}           & \underline{1.0842{\tiny $\pm$ 0.0182}}     & 1.4175{\tiny $\pm$ 0.0147}           & 0.8846                                            \\
                                & DR-V2                                               & 0.5518{\tiny $\pm$ 0.0125}          & 0.7479{\tiny $\pm$ 0.0143}          & 0.8732{\tiny $\pm$ 0.0156}          & \underline{0.658{\tiny $\pm$ 0.0111}}      & 1.0784{\tiny $\pm$ 0.0181}           & 1.4154{\tiny $\pm$ 0.0158}           & 0.8875                                            \\
                                & ESCM$^2$-DR                                                & \underline{0.5541{\tiny $\pm$ 0.0144}}    & \underline{0.7502{\tiny $\pm$ 0.0126}}    & \underline{0.8771{\tiny $\pm$ 0.0171}}    & 0.6564{\tiny $\pm$ 0.0156}           & 1.0772{\tiny $\pm$ 0.0175}           & \underline{1.4183{\tiny $\pm$ 0.0154}}     & \underline{0.8889}                                      \\ \rowcolor{lightgray}
\cellcolor{white}\multirow{-5}{*}{Yahoo! R3}     & MRDR-CAL(Ours)                                   & \textbf{0.5623{\tiny $\pm$ 0.0092}} & \textbf{0.7571{\tiny $\pm$ 0.0066}} & \textbf{0.8858{\tiny $\pm$ 0.0072}} & \textbf{0.6687{\tiny $\pm$ 0.0103}}  & \textbf{1.0862{\tiny $\pm$ 0.0080}}  & \textbf{1.4326{\tiny $\pm$ 0.0090}}  & \textbf{0.8988}                                   \\ \midrule
                                & MRDR-GPL                                         & 0.4335{\tiny $\pm$ 0.0123}          & 0.6446{\tiny $\pm$ 0.0178}          & 0.8049{\tiny $\pm$ 0.0143}          & 0.5261{\tiny $\pm$ 0.0171}           & 0.9792{\tiny $\pm$ 0.0178}           & 1.4101{\tiny $\pm$ 0.0146}           & 0.7997                                            \\
                                & MRDR-CDR                                         & 0.4326{\tiny $\pm$ 0.0098}          & 0.6573{\tiny $\pm$ 0.0145}          & 0.8297{\tiny $\pm$ 0.0132}          & 0.5289{\tiny $\pm$ 0.0126}           & 1.0111{\tiny $\pm$ 0.0146}           & 1.4739{\tiny $\pm$ 0.0165}           & 0.8223                                            \\
                                & DR-V2                                              & 0.4465{\tiny $\pm$ 0.0078}          & 0.6795{\tiny $\pm$ 0.0121}          & 0.8533{\tiny $\pm$ 0.0098}          & 0.5452{\tiny $\pm$ 0.0100}           & 1.0459{\tiny $\pm$ 0.0122}           & 1.5117{\tiny $\pm$ 0.0123}           & 0.8470                                            \\
                                & ESCM$^2$-DR                                             & \underline{0.4773{\tiny $\pm$ 0.0101}}    & \underline{0.7059{\tiny $\pm$ 0.0155}}    & \underline{0.8760{\tiny $\pm$ 0.0121}}    & \underline{0.5781{\tiny $\pm$ 0.0143}}     & \underline{1.0694{\tiny $\pm$ 0.0143}}     & \underline{1.5258{\tiny $\pm$ 0.0152}}     & \underline{0.8721}                                      \\ \rowcolor{lightgray}
\cellcolor{white}\multirow{-5}{*}{KuaiRand}      &   MRDR-CAL(Ours)                                   & \textbf{0.4928{\tiny $\pm$ 0.0057}} & \textbf{0.7259{\tiny $\pm$ 0.0076}} & \textbf{0.8963{\tiny $\pm$ 0.0079}} & \textbf{0.5971{\tiny $\pm$ 0.0070}}  & \textbf{1.0972{\tiny $\pm$ 0.0109}}  & \textbf{1.5549{\tiny $\pm$ 0.0119}}  & \textbf{0.8940}                                   \\ \bottomrule
\end{tabular}}
\caption{The comparison with the SOTA methods}
\label{tb:sota}
\end{table*}

\section{Related Works}

\subsection{Approaches to CVR Estimation}

In practical applications, CTR prediction models are often adapted for CVR prediction tasks due to their conceptual similarities. These approaches encompass various methods, including logistic regression-based models \cite{Richardson2007PredictingCE}, factorization machine-based models \cite{Juan2016FieldawareFM, Rendle2010FactorizationM}, and deep learning-based models \cite{Cheng2016WideD, Wang2017DeepC, Guo2017DeepFMAF}. Moreover, several techniques specifically address unique challenges in CVR prediction, such as delayed feedback \cite{Chapelle2014ModelingDF, Su2020AnAM}, data sparsity \cite{Ma2018EntireSM, Wen2019EntireSM}, and selection bias \cite{guo2021enhanced, Zhang2019LargescaleCA}. This paper focuses primarily on mitigating selection bias issues.

\subsection{Recommendation with Selection Bias}

Bias in recommendation systems is a significant concern in current research \cite{chen2023bias, zhao2022popularity, wang2021samwalker++}, impacting the fairness and diversity of recommendations.

Selection bias, particularly missing-not-at-random, is common in recommender systems where feedback is observed only for displayed user-item pairs \cite{marlin2009collaborative, sato2020unbiased, yang2015boosting}. To mitigate this bias, the inverse propensity score (IPS) approach \cite{schnabel2016recommendations, swaminathan2015self} re-weights observed samples using inverse displayed probabilities. However, IPS estimators often suffer from high variance \cite{gilotte2018offline}, which can be mitigated by self-normalized inverse propensity score (SNIPS) estimators \cite{schnabel2016recommendations}. 

Note that the inherent nature of selection bias is that the data is missing not at random. A straightforward solution for selection bias is to impute the missing entries with pseudo-labels, aiming to make the observed data distribution $p(u, i| o=1)$ resemble the ideal uniform distribution $p(u, i)$. For instance, \cite{steck2010training, steck2013evaluation} propose a light imputation strategy that directly assigns a specific value to missing data. However, since these imputed ratings are heuristic, such methods often suffer from empirical inaccuracies, which can propagate into the training of recommendation models, resulting in sub-optimal performance.

Doubly Robust (DR) estimators \cite{jiang2016doubly, wang2019doubly} simultaneously account for imputation errors and propensities to reduce variance in IPS. Recent improvements include asymmetric tri-training \cite{saito2020asymmetric}, information theory considerations \cite{wang2020information}, adversarial training \cite{xu2020adversarial}, enhanced doubly robust estimators \cite{guo2021enhanced}, knowledge distillation \cite{xu2022ukd}, bias-variance trade-off \cite{dai2022generalized}, and multi-task learning \cite{wang2022escm}.

Some approaches rely on small amounts of randomly unbiased data \cite{bonner2018causal, yuan2019improving, chen2021autodebias}, which can be costly in real-world applications.

Existing models often face challenges in calibrating propensity score estimations, leading to inaccuracies in debiasing methods like IPS and DR. Addressing these calibration issues is the primary focus of this paper.



% {In the context of the latest advancements in recommender systems of the self-supervised learning methods~\cite{wei2022contrastive,xia2022self}, our calibration framework offers a significant enhancement. We discuss how our model-agnostic calibration can be seamlessly integrated with these systems to improve prediction accuracy and uncertainty estimates, providing a comprehensive enhancement to the robustness and reliability of recommendations. This integration not only boosts performance but also extends the applicability of our approach across diverse recommender system architectures.}

\subsection{Uncertainty Calibration and Quantification}

Beyond Platt scaling, temperature scaling has been proposed for uncertainty calibration in multi-class classification \cite{guo2017calibration}. Platt scaling and temperature scaling both assume a Gaussian distribution. For distributions that are richer and more skewed, Beta calibration is another effective method \cite{kull2017beta}. 

In addition to parametric methods that assume distributional assumptions, non-parametric techniques can also be considered. These include histogram binning \cite{zadrozny2001obtaining} and isotonic regression \cite{zadrozny2002transforming}.

From a Bayesian generative model perspective, this paper focuses on approximate methods like MC Dropout and Deep Ensembles for uncertainty quantification in IPS. While Gaussian processes, Bayesian neural networks, and other probabilistic graphical models can also quantify uncertainty in IPS \cite{zhu2017big}, practical approximate inference on large-scale datasets poses significant challenges \cite{liao2020uncertainty, mccandless2009bayesian}.



{Existing methods to address selection bias in recommender systems include deep ensembles, Platt scaling, and Monte Carlo Dropout. However, each comes with notable shortcomings:}
\begin{enumerate}
    \item {{Deep ensembles}, while providing robust uncertainty estimates, are \textit{computationally expensive} due to the necessity of training multiple models \cite{lakshminarayanan2017simple}. Hence the BatchEnsembles method can be used to reduce the overall computation cost as detailed in Sec.~\ref{sec:computational complexity}~\cite{wen2019batchensemble}.}
    \item {{Platt scaling} requires a \textit{separate validation set} to fine-tune its parameters, which can be a limitation in scenarios with limited data availability \cite{platt1999probabilistic}.}
    \item {{Monte Carlo Dropout} offers a practical approach to approximate Bayesian inference but can lead to \textit{unstable calibration performance}, particularly sensitive to the choice of dropout rate and the architecture of the underlying neural network \cite{gal2016dropout}.}
\end{enumerate}


\section{Conclusions}

In this paper, we first propose the use of Expected Calibration Error (ECE) to assess the quality of propensity scores and highlight their uncertainty miscalibration in recommendation scenarios with data missing not at random. We introduce uncertainty calibration methods for propensity score estimation and compare three calibration techniques for this purpose. Our theoretical analysis demonstrates that calibrated Inverse Propensity Scores (IPS) exhibit reduced bias.

Experimental results on two representative datasets, Coat Shopping and Yahoo! R3, confirm that calibrated inverse propensities significantly enhance recommendation accuracy. These findings underscore the importance of addressing propensity score uncertainty in mitigating bias and improving recommendation systems.


%\section*{Acknowledgments}
%This should be a simple paragraph before the References to thank those individuals and institutions who have supported your work on this article.


\iffalse
{\appendix[Proof of the Zonklar Equations]
Use $\backslash${\tt{appendix}} if you have a single appendix:
Do not use $\backslash${\tt{section}} anymore after $\backslash${\tt{appendix}}, only $\backslash${\tt{section*}}.
If you have multiple appendixes use $\backslash${\tt{appendices}} then use $\backslash${\tt{section}} to start each appendix.
You must declare a $\backslash${\tt{section}} before using any $\backslash${\tt{subsection}} or using $\backslash${\tt{label}} ($\backslash${\tt{appendices}} by itself
 starts a section numbered zero.)}



%{\appendices
%\section*{Proof of the First Zonklar Equation}
%Appendix one text goes here.
% You can choose not to have a title for an appendix if you want by leaving the argument blank
%\section*{Proof of the Second Zonklar Equation}
%Appendix two text goes here.}



\section{References Section}
You can use a bibliography generated by BibTeX as a .bbl file.
 BibTeX documentation can be easily obtained at:
 http://mirror.ctan.org/biblio/bibtex/contrib/doc/
 The IEEEtran BibTeX style support page is:
 http://www.michaelshell.org/tex/ieeetran/bibtex/
 
 % argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
\section{Simple References}
You can manually copy in the resultant .bbl file and set second argument of $\backslash${\tt{begin}} to the number of references
 (used to reserve space for the reference number labels box).
\fi
\bibliography{refs}
\bibliographystyle{ieeetr}




\vfill
\end{document}


