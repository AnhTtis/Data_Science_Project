\section{Matrix encoding}\label{sec:matrix}

In this section, we introduce the notion of \emph{labelled transition matrices}
and give a bijection between DOAGs and these matrices, thus offering an
alternative point of view on DOAGs.
These results are key ingredients of the paper, since they enable us, in the
next two sections, to prove an asymptotic equivalence for the number of DOAGs
with~$n$ vertices, and to design a efficient uniform random sampler for those
DOAGs.
We also recall here the definition and basic properties of variations, which are
an elementary combinatorial object playing a central role in our analysis.

\subsection{The encoding}

The decomposition scheme described in Section~\ref{sec:def} corresponds to a
traversal of the DOAG\@.
This traversal induces a labelling of the vertices from~$1$ to~$n$, which allows
us to associate the vertices of the graph to these integers in a canonical way.
We then consider its transition matrix using these labels as indices.
Usually, the transition matrix of a directed graph~$D$ is defined as the
matrix~${(a_{i,j})}_{1 \leq i, j \leq n}$ such that~$a_{i,j}$ is~$1$ if there is
an edge from vertex~$i$ to vertex~$j$ in~$D$, and~$0$ otherwise.
This representation encodes the set of the edges of a DAG but not the edge
ordering of DOAGs.
In order to take this ordering into account, we use a slightly different
encoding.

\begin{definition}[Labelled transition matrix of a DOAG]
  Let~$D$ be a DOAG with~$n$ vertices.
  We associate the vertices of~$D$ to the integers from~$1$ to~$n$ corresponding
  to their order in the vertex-by-vertex decomposition.
  The \emph{labelled transition matrix} of~$D$ is the matrix~${(a_{i,j})}_{1
  \leq i, j \leq n}$ with integer coefficients such that~$a_{i,j} = k > 0$ if
  and only if there is an edge from vertex~$i$ to vertex~$j$ and this edge is
  the~$k$-th outgoing edge of~$i$.
  Otherwise~$a_{i,j} = 0$.
\end{definition}

An example of a DOAG and its transition matrix are pictured in
Figure~\ref{fig:matrix}.
The thick lines are not part of the encoding and their meaning will be explained
later when we characterise which integer matrices can be a labelled transition
matrix.
Let~$\phi$ denote the function mapping a DOAG to its labelled transition matrix.
This function is clearly injective as the edges of the graph can be recovered as
the non-zero entries of the matrix, and the ordering of the outgoing edges of
each vertex is given by the values of the corresponding entries in each row.
Characterising the image of~$\phi$ however requires more work.

\begin{figure}[htb]
  \centering
  \includegraphics[scale=1]{images-matrix}
  \caption{An example DOAG and its labelled transition matrix, the zeros are
  represented by the absence of a number.}%
  \label{fig:matrix}
\end{figure}

We can make some observations.
First, by definition of the traversal of the DOAG, the labelled transition
matrix of a DOAG is strictly upper triangular.
Indeed, since the decomposition algorithm removes one \emph{source} at a time,
the labelling it induces is a topological sorting of the graph.
Moreover, since the non-zero entries of row~$i$ encode the \emph{ordered} set of
outgoing edges of vertex~$i$, these non-zero entries form a permutation. More
formally:
\begin{itemize}
  \item a non-zero value cannot be repeated within a row;
  \item and if a row contains~$d \geq 1$ non-zero entries, then these are the
    integers from~$1$ to~$d$, in any order.
\end{itemize}
Informally, these two properties ensure that a matrix encodes a labelled DOAG (a
DOAG endowed with a labelling of its vertices) and that this labelling is a
topological sorting of the graph.
However, they are not enough to ensure that this topological sorting is
precisely the one that is induced by the decomposition.
The matrices satisfying these two properties will play an important role in the
rest of the paper.
We call them ``variation matrices''.

\pagebreak

\begin{definition}[Variation]\label{def:var}
  A variation is a finite sequence of non-negative integers such that
  \begin{enumerate}
    \item each strictly positive number appears at most once;
    \item if~$0 < i < j$ and~$j$ appears in the sequence, then~$i$ appears too.
  \end{enumerate}
  The size of a variation is its length.
\end{definition}
For instance, the sequence~$(6, 2, 3, 0, 0, 1, 4, 0, 5)$ is a variation of
size~$9$ but the two sequences~$(1, 0, 3)$ and~$(1, 0, 3, 2, 3)$ are not variations
because the number~$2$ is missing in the first one and the second contains two
occurrences of the number~$3$.
Variations can also be defined as interleavings of a permutation with a
sequence of zeros.
One of the earliest references to these objects dates back
to~\citeyear{Izquierdo1659} in Izquierdo's
\citetitle{Izquierdo1659}~\cite[Disputatio 29]{Izquierdo1659}.
They also appear in Stanley's book as the second entry of his \emph{Twelvefold
Way}~\cite[page 79]{Stanley2011}, a collection of twelve basic but fundamental
counting problems.
Knuth gives a few ancient references on this topic in~\cite{Knuth2011} and in an
quote (without reference) that can be found on the OEIS page of variations
at~\href{https://oeis.org/A007526}{A007526}.
Variations are relevant to our problem as they naturally appear as rows of the
labelled transition matrices defined in this section.
Some of their combinatorial properties will be exhibited in the next section.

\begin{definition}[Variation matrix]
  Let~$n > 0$ be a positive integer.
  A matrix of integers~${(a_{i,j})}_{1 \leq i, j \leq n}$ is said to be a
  variation matrix if
  \begin{itemize}
    \item it is strictly upper triangular;
    \item for all~$1 \leq i \leq n - 1$, the sub-row~${(a_{i,j})}_{i < j \leq
      n}$ is a variation (of size~$n-i$).
  \end{itemize}
  From an enumerative point of view, a variation matrix can be seen as a
  sequence of variations~$(v_1, v_2, \ldots, v_{n-1})$ where for all~$1 \leq i
  \leq n - 1$, the variation~$v_i$ has size~$i$.
\end{definition}

We have established that all labelled transition matrices of DOAGs are variation
matrices.
Note that the converse is not true.
For instance, the matrix pictured in Figure~\ref{fig:invalid} is a variation
matrix of size~$3$ that does not correspond to any DOAG\@.
The property of this matrix which explains why it cannot be the image of a DOAG
is pictured in red on the Figure.
The rest of this section is devoted to characterising which of those variation
matrices can be obtained as the labelled transition matrix of a DOAG\@.

\begin{figure}[htb]
  \centering
  \includegraphics[scale=1]{images-invalid1}
  \caption{An example of a matrix of variations that cannot be obtained as a
  labelled transition matrix of a DOAG\@.
  The labelled DOAG that it encodes is not labelled according to the
  decomposition order.}%
  \label{fig:invalid}
\end{figure}

Consider a DOAG and its labelled transition matrix.
Note that in any column~$j$, the non-zero entry with the \emph{highest}
index~$i$ (that is in the lowest row on the picture with a non-zero element in
column~$j$) has a special role: it corresponds to the last edge pointing to
vertex~$j$ when decomposing the DOAG\@.
This is pictured in Figure~\ref{fig:matrix-tree} where we drew, the same DOAG as
in Figure~\ref{fig:matrix} and added:
\begin{itemize}
  \item on the right (in the matrix): thick red underlines to show the last
    non-zero entry of each column;
  \item on the left (in the graph): thick red decorations on the last incoming
    edge (in decomposition order) of each vertex.
\end{itemize}
When a column has no non-zero entry at all, the top line is pictured in thick
red instead.
This is the case in the three first columns of the matrix in
Figure~\ref{fig:matrix-tree}.
Still in the figure: in order to make those three extra lines correspond to
something in the graph, we added an artificial extra source, connected to all
other sources (there is a unique way to do this).
Those three extra edges are indeed the last incoming edges of the vertices
labelled 1, 2, and 3, that naturally correspond to the red part of the three
first columns of the matrix.
Note that the thick red edges in the graph on the left of
Figure~\ref{fig:matrix-tree} form a \emph{spanning tree} of the graph, and that
the labelling induced by the decomposition coincides exactly with the natural
BFS order of the tree.

\begin{figure}[htb]
  \centering
  \vspace*{1em}
  \includegraphics[scale=1,page=2]{images-matrix.pdf}
  \caption{The same example as Figure~\ref{fig:matrix} with extra decorations to
    highlight the correspondence between the last incoming edge (in
    decomposition order) of each vertex and the last non-zero entry of the
    columns of its labelled transition matrix.
    An artificial~$\bot$ vertex, connected to every source, has been added in
    the graph in order to show that the thick red edges form a spanning tree of
    the graph.}
  \label{fig:matrix-tree}
\end{figure}


Another important remark is that, when several underlined cells occur on the
same row~$i$ in the matrix, they correspond to several sources that are
discovered at the same decomposition step of the DOAG (upon removing the same
source).
Recall that the decomposition
\begin{wrapfigure}{r}{.22\linewidth}
  \centering
  \includegraphics[width=.6\linewidth]{images-constraints-order.pdf}
  \caption{\small Same-row underlined entries are sorted.}%
  \label{fig:constraint:order}
  \vspace*{-1em}
\end{wrapfigure}
algorithm sorts the labels of these new sources by
following the total order of the outgoing edges of vertex~$i$.
This implies that the underlined entries within the same row have to be
increasingly sorted (from left to right).
For instance, observe that there are three consecutive underlined cells in the
first row of the matrix in Figure~\ref{fig:matrix-tree}.
Indeed, when removing the first source of the DOAG on the left, we uncover three
new sources which are respectively in first, second and fourth position in the
outgoing edges order of the removed source.

\begin{wrapfigure}{r}{.22\linewidth}
  \centering
  \includegraphics[width=.8\linewidth]{images-constraints-dyck.pdf}
  \caption{\small Thick red lines draw a descending staircase.}%
  \label{fig:constraint:dyck}
\end{wrapfigure}

A second key property is that if more than one underlined cell occur in a row of
the matrix, these are always the first non-zero entries in that row.
This is because, the decomposition algorithm consumes sources in the same order
in discovers them.
As a consequence, for a given vertex~$i$, those of its children that become
sources upon removing~$i$ will be processed before any other children, and thus
appear first in the list of the non-zero entries of the~$i$-th row.
Put differently, the red thick lines drawn in Figure~\ref{fig:matrix} is
visually a staircase that only goes down when moving toward the right of the
matrix.

% \todo[inline]{The alignment of the two figures above is fragile. Check that
% everything is fine before sending the paper.}

The two properties that we just described actually characterise the variation
matrices that can be obtained as the labelled transition matrices of a DOAG\@.
This is stated in a more formal manner in Theorem~\ref{thm:matrix}.

\begin{theorem}\label{thm:matrix}
  All labelled transition matrices of DOAGs are variation matrices.
  Furthermore, let~$A = {(a_{i, j})}_{1 \leq i, j \leq n}$ be a variation
  matrix, and for all~$j \in \llbracket 1; n \rrbracket$, let~$b_j$ denote the
  largest~$i \leq n$ such that~$a_{i,j} > 0$ if such an index exists and~$0$
  otherwise.
  Then,~$A$ is the labelled transition matrix of some DOAG if and only if the
  two following properties hold:
  \begin{itemize}
    \item the sequence~$j \mapsto b_j$ is weakly increasing;
    \item whenever~$0 < b_j = b_{j+1}$, we have that~$a_{b_j,j} < a_{b_j,j+1}$.
  \end{itemize}
\end{theorem}

The sequence~$(b_j)_{1 \leq j \leq n}$ from the theorem is the formalisation of
the thick red lines from Figure~\ref{fig:matrix-tree}.
The first condition from the theorem corresponds to the ever-descending nature
of the ``staircase'', as illustrated in Figure~\ref{fig:constraint:dyck}
The second condition corresponds to the ordering of underlined cells within a
row, as illustrated in Figure~\ref{fig:constraint:order}.

\begin{proof}
  The fact that the labelled transition matrix of a DOAG is a variation matrix
  is clear from the definition.
  We prove the rest of the theorem in two steps.

  \medskip
  \noindent
  \textbf{Step 1: labelled transition matrices satisfy the conditions.}\quad
  Let~$D$ be a DOAG of size~$n$ and let~$A$ be its labelled transition matrix.
  Let~$b={(b_j)}_{1 \leq j \leq n}$ be defined as in the statement of the
  theorem.
  We shall prove that it satisfies the two properties of the theorem.
  The case~$n=1$ is trivially and we proceed by induction when~$n \geq 2$.

  When~$n \geq 2$, we can decompose~$D$ as a quadruplet~$(D', s, I, f)$ and we
  have that the labelled transition matrix of~$D'$ is the sub-matrix~$A'$ of~$A$
  obtained by removing its first row and first column, that
  is~$A'=(a_{i+1,j+1})_{1 \leq i, j \leq n - 1}$.
  We can define the sequence~$b' = (b_j')_{1 \leq j \leq n - 1}$ corresponding
  to~$A'$ similarly to the sequence~$b$.

  We distinguish between three cases.
  \begin{itemize}
    \item If~$j$ is such that~$b_j = 0$, then~$b_j \leq b_{j+1}$ automatically,
      and there is no second condition to check.

    \item If~$j$ is such that~$b_j = 1$, then~$b_{j+1}$ cannot be zero,
      otherwise that would mean that the vertex labelled~$(j+1)$ is a source
      of~$D$ but the vertex labelled~$j$ is not.
      Indeed, since the sources of~$D$ are processed before any other vertex by
      the decomposition algorithm, they get the smallest labels.
      Hence~$b_j \leq b_{j+1}$.

      In addition, if~$b_j = b_{j+1} = 1$, then the vertices labelled~$j$
      and~$(j+1)$ both become sources, \emph{at the same time}, upon removing
      the first vertex.
      By construction of the decomposition, they get labels in an order
      compatible with the order of the outgoing edges of the first source, and
      thus we have~$a_{1,j} < a_{1,j+1}$.

    \item Finally, if~$j$ is such that~$b_j \geq 2$, then we have~$b_j =
      b_{j-1}' + 1$.
      By induction we also have that~$b_j' \leq b_{j-1}'$, which, in particular,
      implies that there is at least one non-zero entry in the~$j$-th column
      of~$A'$ and thus in the~$(j+1)$-th column of~$A$.
      It follows that~$b_{j+1} = b_j' + 1$ and finally~$b_j \leq b_{j+1}$
      and~$b_j = b_{j+1} \implies a_{b_j,j} < a_{b_j,j+1}$ by induction.
  \end{itemize}

  \medskip
  \noindent
  \textbf{Step 2: any matrix satisfying the conditions is a labelled transition
  matrix.}\quad
  Let~$A$ be a variation matrix of size~$n$ and let~$b$ be as in the statement
  of the theorem and satisfying the two given properties.
  We shall prove that~$A$ is the image by~$\phi$ of some DOAG\@.

  Let~$V = \llbracket 1; n \rrbracket$ and~$E = \left\{(i, j) \in \llbracket 1;
  n \rrbracket^2~|~a_{i,j} > 0\right\}$.
  We have that~$(V, E)$ defines an acyclic graph since~$A$ is strictly
  upper-triangular.
  In addition, for each~$v \in V$, define~$\prec_v$ to be the total order on the
  outgoing edges of~$v$ in~$(V, E)$ such that~$u \prec_v u'$ if and only
  if~$a_{v,u} < a_{v,u'}$ in~$A$.
  This is well defined since the outgoing edges of~$v$ are precisely the
  integers~$j$ such that~$a_{v,j} > 0$ and since the non-zero entries of the
  row~$v$ are all different by definition of variation matrices.
  Finally, define~$\prec_\top$ to be the total order on the sources of~$(V, E)$
  such that~$u \prec_\top v$ if and only if~$u < v$ as integers.
  Let~$D$ be the DOAG given by~$(V, E, {(\prec_v)}_{v\,\in V \cup
  \{\top\}})$.

  Remember that DOAGs are considered up to a permutation of their vertices that
  preserves~$E$ and~$\prec$.
  In order to finish this proof, we have to check that the particular labelling
  encoded by~$V$ is indeed the labelling induced by the decomposition of~$D$.
  Then it will be clear that~$\phi(D) = A$ and we will thus have exhibited a
  pre-image of~$A$.

  First, since~$A$ is strictly upper-triangular, its first column contains only
  zeros and thus~$1$ is necessarily a source of~$D$.
  In addition, by definition of~$\prec_\top$, it must be the smallest
  source.
      Then, upon removing~$i$, one of two things can happen:
      \begin{itemize}
        \item either~$D$ has more than one source, in which case~$2$ is the
          second source by monotony of the sequence~${(b_j)}_{1 \leq j \leq n}$;
        \item or~$1$ was the unique source of~$D$, in which case the next source
          to be processed is its first child.
          The children of~$1$ are the integers~$j$ such that~$b_j = 1$.
          By monotony of~$b_j$ again (or triangularity of the matrix),~$2$ is
          necessarily a child of~$1$.
          Moreover, by the second property of the sequence~$b$, we have that for
          all~$j < j'$ such that~$b_j = b_{j'} = 1$,~$a_{1,j} < a_{1,j'}$.
      \end{itemize}
      In both case, we proved that~$2$ is the second vertex to be processed.
      We can then repeat this argument on the DOAG obtained by removing~$1$,
      which corresponds to the matrix~${(a_{i,j})}_{2 \leq i, j \leq n}$ and
      conclude by induction.\qedhere
\end{proof}

We have now established that the encoding~$\phi$ of DOAGs as labelled transition
matrices is a bijection from DOAGs to the matrices described in
Theorem~\ref{thm:matrix}.
From now on, we will write ``a labelled transition matrix'' to refer to such a
matrix.
We can also state a few simple properties of these matrices.
By definition we have that
\begin{itemize}
  \item the number of vertices of a DOAG is the dimension of its labelled
    transition matrix;
  \item the number of edges of a DOAG is the number of non-zero entries of the
    matrix;
  \item the sinks of the DOAG correspond to the zero-filled rows of the matrix;
  \item the sources of the DOAG correspond to the zero-filled columns of the
    matrix.
\end{itemize}
Furthermore, the first property of the sequence~${(b_j)}_{1 \leq j \leq n}$
defined in Theorem~\ref{thm:matrix} implies that the zero-filled columns of the
matrix must be contiguous and on the left of the matrix.
The number of sources of the DOAG is thus the maximum~$j$ such that column~$j$
is filled with zeros.

We will see in the next section that working at the level of the labelled
transition matrices, rather than at the level of the graphs, is more handy to
exhibit asymptotic behaviours.
This will also inspire an efficient uniform random sampler of DOAGs with~$n$
vertices in Section~\ref{sec:sampling:rej}.
