\section{Earlier results on counting and recursive sampling}\label{sec:sampling:rec}

In this section we summarise our earlier results on the counting and random
sampling problem for DOAGs when all three parameters (number of vertices, edges
and sources) are fixed.
The theorems are stated in a slightly more general setting here than
in~\cite{GPV2021} so as to capture all variants of the model as described in
Section~\ref{sec:subclasses}.
However, there is no technical difficulty in the generalisation so that the
proofs from~\cite{GPV2021} still apply, almost without modification.

We first present a utility result: computing all the numbers~$D_{n,m,k}^{\mathcal
P}$ up to a certain bound on~$n$,~$m$, and~$k$ can be done in polynomial time.
This is of moderate interest in itself, but this is a requirement for our
samplers, that compute theses values as a pre-processing step.
Our algorithm is based on the so-called ``recursive method'' from~\cite{NW1978}.

\subsection{Counting}

As mentioned above, tabulating the values of the sequence~$D_{n,m,k}^{\mathcal
P}$ can be done in polynomial time. This means that this counting pre-processing
step is tractable up to a certain point.

\begin{theorem}\label{thm:counting:cost}
  Let~$N, M > 0$ be two integers.
  And let~$\mathcal P$ be a subset of~$\mathbb N$ such that~$\mathcal P \cap
  \llbracket 0; n\rrbracket$ can be enumerated in linear time in~$n$.
  Computing~$D_{n, m, k}^{\mathcal P}$ for all~$n \leq N$, all~$m \leq M$, and
  all possible~$k$ can be done with~$O(N^4 M)$ multiplications of integers of
  size at most~$O(\max(M, N) \ln N)$.
\end{theorem}

The bound given here is independent of~$\mathcal P$ and thus pessimistic.
If~$\mathcal P$ is bounded (bounded out-degree DOAGs) or sparse, the algorithm
will perform better.
In practice, the cost of the counting process is actually the limiter factor for
the recursive sampler presented below.
Indeed, it is hard to reach sizes of the order of the thousands because of the
large amount of time and memory necessary to compute and store all the numbers.

\subsection{Recursive random sampling}

A straightforward application of the recursive method from Nijenhuis and Wilf
\cite{NW1978} leads to Algorithm~\ref{algo:sample:DOAG}, which is presented here
in a high level fashion.

\begin{algorithm}[htb]
  \caption{Recursive uniform sampler of DOAGs}%
  \label{algo:sample:DOAG}

  \begin{algorithmic}[1]
    \Require{Three integers~$(n, m, k)$ such that~$D_{n,m,k}^{\mathcal P} > 0$}
    \Ensure{A uniform random DOAG with~$n$ vertices (including $k$ sources)
    and~$m$ edges}
    \Function{UnifDOAG${}^{\mathcal P}$}{$n, m, k$}
      \If{$n=0$ \textbf{or} $n = 1$}
        {generate the (unique) DOAG with~$n$ vertex}
      \Else{}
        \State{\textbf{pick}~$(p, i)$ with probability
          $\displaystyle {D_{n-1, m-p, k-1+p-i}^{\mathcal P} \binom{n-k-p+i}{i} \binom{p}{i}
          i{!}} / {D_{n, m, k}^{\mathcal P}}$}%
          \label{algo:line:pick}
        \State{$D' \gets \text{\Call{UnifDOAG${}^{\mathcal P}$}{$n-1, m-p, k-1+p-i$}}$}%
        \label{algo:line:nsrc:begin}
        \State{$I \gets$ a uniform subset of size~$i$ of the inner vertices
        of~$D'$}\label{algo:line:subset}
        \State{$f \gets \text{a uniform injection from~$I$
        to~$\llbracket 1; p\rrbracket$}$}\label{algo:line:f}
        \return{$\decomp^{-1}(D', p-i, I, f)$}
      \EndIf{}
    \EndFunction{}
  \end{algorithmic}
\end{algorithm}

In~\cite[\S 3]{GPV2021}, we discuss how to implement
Algorithm~\ref{algo:sample:DOAG} efficiently.
In particular we suggest a data-structure to represent DOAGs that allows for
an efficient selection of the subset~$I$ at line~\ref{algo:line:subset} and the
function~$f$ at line~\ref{algo:line:f}.
In addition, implementation considerations are also given for the~\textbf{pick}
instruction at line~\ref{algo:line:pick}, which is the core of the ``recursive
method''.
As mentioned above, the numbers~$D_{n,m,k}^{\mathcal P}$ either have to be
pre-computed for Algorithm~\ref{algo:sample:DOAG} to work, or must be lazily
computed and memoised on the fly.

In practice, pre-computing all the necessary numbers to sample a uniform DOAG
with~$50$ vertices (without any constraint on~$m$ and on the out-degree)
using our library already takes about~$8$ seconds on a standard laptop.
This running time rapidly increases, which makes the cost generating large
structures prohibitive.
However, when limiting the number of edges and using a finite set~$\mathcal P$,
one can achieve much better results.
For instance generating the four large bounded-degree DOAGs from
Figure~\ref{fig:bigdoag:random} takes about~$11$ seconds on the same laptop,
most of this time being spent in the pre-computation.

\begin{theorem}\label{thm:sample:cost}
  Algorithm~\ref{algo:sample:DOAG} computes a uniform random DOAG with~$n$
  vertices (among which~$k$ are sources) and~$m$ edges by
  performing~$O\left(\sum_{v} d_v^2 \right)$ multiplications of a small integer
  by a large integer, where~$v$ ranges over the vertices of the resulting graph
  and $d_v$ is the out-degree of~$v$.
\end{theorem}

Note that the sum~$\sum_v d_v^2$ is of the order of~$m^2$ in the worst case but
can be significantly smaller, in particular if~$\mathcal{P}$ is bounded or
sparse. In the best case we have~$d_v \sim \frac{m}{n}$ for most of the vertices
and as a consequence~$\sum_v d_v^2 \sim {m^2} / {n}$.
Also note that in order for the algorithm to be made generic in~$\mathcal P$, we
only have to use the sequence~$D_{n,m,k}^{\mathcal P}$ rather than~$D_{n,m,k}$,
which reflects the generality of the recursive method.

Four random DOAGs, drawn using Algorithm~\ref{algo:sample:DOAG} with~$\mathcal P
= \{0, 1, 2\}$,~$n=1250$,~$m=1300$ and~$k=1$ are pictured in
Figure~\ref{fig:bigdoag:random}.
As a comparison, a truncated version of the Git history of the linux kernel is
pictured on the left in Figure~\ref{fig:bigdoag:linux}.
Expectedly, the Git history looks more structured.
This is because developers work on short-lived branches, consisting of chains of
commits, generally starting from the main branch and merged back on main after
the new feature (or bug fix, etc.) has been completed, reviewed and accepted.

\begin{figure}[H]
  \centering
  \begin{subfigure}{.365\linewidth}
    \centering
    \includegraphics[width=.936\linewidth]{images-big-linux_70.pdf}
    \caption{The Git history of the Linux kernel, truncated at depth~$70$, as
      of the 14th of April 2025, just after the release of version
      \texttt{6.15-rc2}. It has~$1270$ vertices and~$1431$
      edges.\label{fig:bigdoag:linux}
  }
  \end{subfigure}
  \hfill
  \begin{subfigure}{.592\linewidth}
    \centering
    \noindent\includegraphics[width=.43\linewidth]{images-big-doag_1.pdf}
    \hfill
    \noindent\includegraphics[width=.43\linewidth]{images-big-doag_2.pdf}

    \noindent\includegraphics[width=.43\linewidth]{images-big-doag_3.pdf}
    \hfill
    \noindent\includegraphics[width=.43\linewidth]{images-big-doag_4.pdf}

    \caption{Four DOAGs drawn uniformly at random amongst all DOAGs with~$1250$
    vertices,~$1300$ edges and with out-degree bounded
    by~$2$.\label{fig:bigdoag:random}}
  \end{subfigure}
  \caption{The graphical representation of a (truncated) Git history and four
  bounded-degree random DOAGs.\label{fig:bigdoag}}
\end{figure}

This explains the chains of unary vertices and the triangular patterns.
Although the random DOAGs look more ``random'', they exhibit similar
smaller-scale structures such as triangular patterns and locally denser areas.
It has to be noted that in order to obtain those pictures, we had to reduce the
number of edges compared to the Git graph on the left as uniform DOAGs
with~$n=1270$ and~$m=1431$ are already visually too dense to look like a Git
graph.
We recall that the DOAG model presented in this paper aims at being a general
purpose modelling tool and thus does not integrate Git specific constraints.
In this regard, a random DOAG is not expected to have all the structural
properties of a Git graph.
However, the comparison in Figure~\ref{fig:bigdoag} showcases that the model can
be \emph{tweaked} (here by controlling~$m$ and the out-degree) in order to
resemble some application-inspired graphs.
In the case of Git, we obtain a somewhat similar shape.
