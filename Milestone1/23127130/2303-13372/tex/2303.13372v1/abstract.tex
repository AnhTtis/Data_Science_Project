Malware detection has long been a stage for an ongoing arms race between malware authors and anti-virus systems.
Solutions that utilize machine learning (ML) gain traction as the scale of this arms race increases. 
This trend, however, makes performing attacks directly on ML an attractive prospect for adversaries.
We study this arms race from both perspectives in the context of MalConv, a popular convolutional neural network-based malware classifier that operates on raw bytes of files.
First, we show that MalConv is vulnerable to adversarial patch attacks: appending a byte-level patch to malware files bypasses detection $94.3\%$ of the time.
Moreover, we develop a universal adversarial patch (UAP) attack where a single patch can drop the detection rate in constant time of any malware file that contains it by $80\%$.
These patches are effective even being relatively small with respect to the original file size---between $2\%-8\%$.
As a countermeasure, we then perform window ablation that allows us to apply de-randomized smoothing, a modern certified defense to patch attacks in vision tasks, to raw files.
The resulting `smoothed-MalConv' can detect over $80\%$ of malware that contains the universal patch and provides certified robustness up to $66\%$, outlining a promising step towards robust malware detection.
To our knowledge, we are the first to apply universal adversarial patch attack and certified defense using ablations on byte level in the malware field.

%\wwx{things that are not yet mentioned: data collection, data visualization}

%\wwx{regarding Smoothed-MalConv, do we have any results related to its certified robustness? It seems that currently we only have empirical robustness in the evaluation; If we are not gonna include certified robustness results, we need to emphasize on the empirical robustness of randomized ablation}


%Malware has long continued to evolve to more complex and sophisticated programs requiring stronger and more robust detection means. As a result, it has turned into a repeating game between anti-virus (AV) systems and malware developers -- the former ones performing adversarial training and the latter ones evading the re-trained model. In this paper, we first look into the attacker's side and explore evasion attacks to learning-based byte-level malware classifiers. We further outline the effectiveness of universal adversarial patch (UAP) attacks to these learning-based classifiers by generating a patch that consistently evades the detection of MalConv, a convolution neural network malware classifier. We achieved more than 80\% evasion rate on MalConv model even with a universal patch of just 160KB (4\% of the input size). Borrowing the idea from vision transformers, we propose a defense, named MalConv-ViT, against patch based attacks, achieving greater success at detecting adversarial malware in the byte-level space. MalConv-ViT was successful at detecting more than 90\% adversarial samples that evaded MalConv at the first place. To our knowledge, we are the first to apply UAP attack and certified defense using ablations in malware field.