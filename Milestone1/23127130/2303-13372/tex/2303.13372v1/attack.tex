\subsection{Input-specific Patch Attack} \label{subsec:FGM attack}

There are multiple ways to perform append attack on malware files. The first append attack on MalConv model was presented by \cite{8553214}. In their work, they demonstrated random append and gradient append, and showed gradient append performs significantly better than the former one. However, in gradient append strategy the convergence time grows linearly with the number of appended bytes. So, we used the FGSM (Fast Gradient Sign Method) that was first proposed by \cite{goodfellow2014explaining}. Such FGSM attack has been adopted for malware perturbation by \cite{kreuk2018deceiving}. However, we follow an advanced approach that was proposed by \cite{suciu2019exploring} demonstrated in Algorithm \ref{alg:FGMattack}.

\begin{algorithm}[h!]
%\caption{EmbeddingMapping ($e_x$)}
\begin{algorithmic}

\FUNCTION {$\text{EmbeddingMapping}$ ($e_x$)}
\STATE $e \leftarrow \text{ARRAY}(256)$
\FOR{$byte$ in $0...255$} 
    \STATE {$e[byte] \leftarrow \text{GetEmbeddings}[byte]$} 
\ENDFOR
\FOR{$i$ in $0...|e_x|$} 
    \STATE $x^*[i] \leftarrow argmin_{b \in {0...255}(||e_x[i]-e[b]||_2)}$
\ENDFOR \\
\textbf{return} $x^*$
%\RETURN $x^*$
\ENDFUNCTION
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h!]
\caption{The FGSM Append attack}\label{alg:FGMattack}
\begin{algorithmic}
\FUNCTION {$\text{FGMAPPEND} (x_0,numBytes,\epsilon)$}
\STATE $x_0\leftarrow\text{PadRandom}(x_0,numBytes)$
\STATE $e\leftarrow\text{GetEmbeddings}(x_0)$
\STATE $e_p\leftarrow\text{GradientAttack}(e,\epsilon)$
\FOR{$i$ in $|x_0| ...|x_0|+numBytes-1$} 
    \STATE {$e[i] \leftarrow e_p[i]$} 
\ENDFOR
\STATE $x^* \leftarrow \text{EmbeddingMapping}(e)$ \\
    \textbf{return} $x^*$
\ENDFUNCTION

\FUNCTION {$\text{GradientAttack}$ ($e,\epsilon$)}
\STATE $e_u \leftarrow e - \epsilon*sign(\nabla_l(e))$ \\
    \textbf{return} $e_u$
\ENDFUNCTION

\end{algorithmic}
\end{algorithm}




In this attack, we start by appending random bytes of $numBytes$ size at the end of original malware sample $x_0$. Since back-propagation of gradient is not possible on embedding layer, we calculate the embedding representation $e$ for $x_0$ and run the FGSM on $e$. This method updates the each value of $e$ by a pre-specified amount $\epsilon$ depending on the sign of the gradient $\nabla_l$. In this paper, we used $L_\infty$ as our distance metric. For the non-differentiability of embedding layer, we mapped the updated embedding value to the byte value using $L_2$ distance metric. We experimented with nearest neighbor and inverse multiplication of embedding matrix, and found that different approach does not affect the evasion rate significantly. We have discussed the performance in \ref{result_adv_patch}.



\subsection{Universal (Input-agnostic) Patch Attack} \label{subsec:uap}

\begin{algorithm}[h!]
\caption{The Universal FGSM Append attack}\label{alg:FGMattack_uni}
\begin{algorithmic}

\FUNCTION{$\text{UniversalPatch} (X, numBytes, \epsilon)$}
\STATE $e_{init} \leftarrow \text{Random[1, numBytes]}$
\FOR{$i$ in $0 ... |X|$}
    \STATE  $ e \leftarrow \text{PERTURB EMBEDDING}(x_i, e_{init}, \epsilon) $
    \STATE $e_{list}.append(e)$
\ENDFOR
\STATE $e_{universal} \leftarrow avg(e_{list})$
\STATE $x_{universal} \leftarrow \text{EmbeddingMapping}(e_{universal})$ \\
\textbf{return} $x_{universal}$
\ENDFUNCTION

\FUNCTION {$\text{PerturbEmbedding} (x_0, e_0,\epsilon)$}
\STATE $e_x\leftarrow\text{GetEmbeddings}(x_0)$
\STATE $e\leftarrow\text{Append}(e_x,e_0)$
%\State $e\leftarrow\text{GetEmbeddings}(x_0)$
\STATE $e_p\leftarrow\text{GradientAttack}(e,\epsilon)$ \\
\textbf{return} $e_p[|x_0|:|x_0|+|e_0|]$
\ENDFUNCTION

\FUNCTION {$\text{GradientAttack} (e,\epsilon)$}
\STATE $e_u \leftarrow e - \epsilon*sign(\nabla_l(e))$ \\
    \textbf{return} $e_u$
\ENDFUNCTION

\end{algorithmic}
\end{algorithm}

Besides input-specific patch attack, we implemented a universal attack strategy that is more-realistic. For this attack, our goal was to generate a universal patch $x_{universal}$ of size $numBytes$ that can be appended at the end of any malware sample $x$, generating $x^{'}$ that results into $F_{\theta}(x^{'}) < 0.5$. The detailed algorithm is shown in \ref{alg:FGMattack_uni}.

For this attack, we started with generating random patch-embedding $e_{init}$ and appended them at the end of the embedding of multiple malware binaries from $X$ set. Then the perturbation for the embedding is generated just like \ref{subsec:FGM attack}. Instead of directly mapping the bytes from the embedding, we collect the perturbed embedding for all malware files and take the average which can be denoted as the embedding representation of the universal patch. Then the mapping of this embedding representation to byte level gives the universal patch that can be used later for evasion. 
We tested our generated universal patch on new diverse unseen malware and the performance details can be found in \ref{result_adv_patch_uni}.



