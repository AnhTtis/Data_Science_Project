\label{sec:intro}

%ML in Malware detection
Machine learning (ML) has started to see more and more adoption in static malware detection, as it also has in many other mission-critical applications. Traditionally, ML models that use static features~\citep{anderson2018ember} require a feature engineering step due to the large size and complex nature of programs. More recently, however, researchers have proposed models like MalConv~\citep{raff2018malware} that can consume whole program simply as raw binary executable to eliminate this step. As expected, there has been a rise in studies showing the adversarial vulnerability of these models in the last few years~\citep{kreuk2018deceiving, lucas2021malware}, resulting in an ongoing arms race.

%Defenses like Adv training and Non-neg suffers
Currently, existing defenses, such as non-negative or monotonic classifier~\citep{fleshman2018non, romeo2018adversarially} and adversarial training~\citep{lucas2023adversarial}, not only introduce sizable drops in standard accuracy but also provide robustness only to specific attacks while still being vulnerable to the rest.

\iffalse
Machine learning has started to see more and more adoption in malware detection, as in many other mission-critical applications.
However, unlike other applications, malware detection is inherently adversarial in nature.
Defenders, such as anti-virus vendors, continually develop new solutions, and adversaries find ways to evade them either by developing novel malware or, more commonly, by making minor but deliberate changes to existing malware~\citep{graziano2015needles}.
In this arms race, because of their efficiency and low-resource demand, vendors often prefer static analysis features that are extracted from programs without executing them.

Traditionally, ML models that use static features~\citep{anderson2018ember} have required a feature engineering step due to the large size and complex nature of programs.
More recently, however, researchers have proposed models that can consume whole programs simply as binary files to eliminate this step.
Notably, MalConv~\citep{raff2018malware}, which uses a convolutional neural network, has achieved state-of-the-art results and pioneered the efforts into applying deep learning advances in malware detection.

%Defenses like Adv training and Non-neg suffers
Unfortunately, there has not been a significant improvement in terms of proposing a robust defense in this domain. Prior defenses like non-negative classifier~\citep{fleshman2018non}, adversarial training~\citep{lucas2023adversarial} suffers from a drop in standard accuracy which make them nonviable for real-world settings. Moreover, these defenses provide robustness to a small subset of attacks, still being vulnerable to most of the attacks.
\wwx{The above part is a bit too long for setting up the theme. A \textit{slightly} more detailed version of the corresponding part in abstract should suffice. }

%Adversarial Attack 
As expected, there has been a rise in researches showing the vulnerability in these models in the last few years. 
Range of such attacks varies from a straightforward version, such as appending noise at the end of file~\citep{kreuk2018deceiving}, to a complex one, such as applying different code transformations~\citep{lucas2021malware}. Figure \ref{fig:intro_problem} shows such an example where the MalConv model misclassifies an `adversarial malware' as `benign'.
\fi


While certified robustness has been studied by many \citep{cohen2019certified, lecuyer2019certified, salman2019provably, levine2020randomized, levine2020robustness}, it remains under-explored in the context of malware detection.
%
To fill this gap, we redesign the \textit{de-randomized smoothing} scheme, a certified defense originally developed for images~\citep{levine2020randomized}, to detect malware from raw bytes.
%
With MalConv \citep{raff2018malware} as the base classifier, we use DRSM (De-Randomized Smoothed MalConv) to denote the resulting defense.
%
To our knowledge, DRSM is the first defense offering \textit{certified robustness} for malware executable detection.
%\can{I'm not entirely sure about this claim, it's too broad. For example, Adversarially Robust Malware Detection Using Monotonic Classification by Incer et al. also provides a provable/verifiable  robustness guarantee with monotonicity, or On Training Robust PDF Malware Classifiers by Chen et al. considers some provable robustness properties for PDF malware classifiers. We need to tune this claim down a bit throughout the paper, it's easy to shoot it down.}

%To our knowledge, we are the first to introduce in malware detection. 


\begin{figure}[tbp]
        \centering
        \includegraphics[width=0.95\linewidth]{images/intro_problem3.pdf}
        \caption{Overview of a prototypical adversarial attack on MalConv and DRSM model. MalConv misclassifies the adversarial malware file as `benign'. Our DSRM creates ablated sequences of the file and makes predictions on each, among which, the majority (\emph{winning}) class is still `malware'.}
        \label{fig:intro_problem}
\end{figure}


%De-randomized smoothing
% In defense of adversarial attack in computer vision (CV), different smoothing schemes have been heavily used for a long time. 
% Recent work ~\citep{levine2020randomized} has improved the \textit{certified robustness} for images by proposing different ablation techniques. Despite of its potential in defending against adversarial attacks, it has still remain untouched by the malware community. 
% We are the first to introduce \textit{de-randomized smoothing} into malware domain and propose \textit{certified robustness}. \wwx{$\Leftarrow$such claim can easily cause trouble;} Using MalConv as the base classifier, we name our proposed model DRSM (De-Randomized Smoothed MalConv). 

%Intrducing DRSM framework
It is challenging for malware domain to utilize de-randomized smoothing scheme due to the inherent difference between image and raw byte file structure. As a solution, we propose a \textit{window ablation} scheme that generates a set of ablated sequences by 
%sliding the window on raw bytes of an input file. 
dividing the input sequence into non-overlapping windows.
%We train the base classifier on these ablated sequences, and consider predictions for each of them. 
For each of these ablated sequences, we train a base classifier keeping the ground truth from original input. At inference, DRSM take the majority of predictions from these base classifiers as its final prediction.
%Aggregating these predictions, DRSM takes the winning class as its final prediction. 
Figure \ref{fig:intro_problem} shows a simplified toy example: An adversarial attack may successfully evaded MalConv model with the presented small changes to the raw executables, but it would still be detected by DRSM if the perturbation could not manipulate sufficient votes.

%Why and how it works?
% Specifically, we propose a \textit{`window ablation'} scheme to address the differences between images and raw byte files, which is an analogue of band ablation in image as illustrated in Figure \ref{fig:drsm_archi}. Intuitively, DRSM should still be able to learn malicious features from its ablated inputs as we are using MalConv model as its base classifier.\wwx{the intuition is not clear} Meanwhile, the perturbed bytes change only a subset of ablated inputs for DRSM model, and therefore its impact on the final prediction can be limited.
% \wwx{It is unclear what these mean without introducing the de-randomized smoothing scheme; either explain de-randomized smoothing earlier or omit these 'intuitions' in intro (the first one is recommended in general) }



%Evaluation
We find that our DRSM ($98.18\%$) can achieve comparable standard accuracy to MalConv ($98.61\%$), and outperforms a prior defense MalConv(NonNeg) ($88.36\%$) by a large margin.
Besides our theoretical formulation for DRSM's certified robustness, we show that it can provide up to $53.97\%$ certified accuracy depending on the attacker's capability. We discuss the performance-robustness trade-offs, and its adaptability upon demand. Moreover, we evaluate the empirical robustness of our DRSM model against $9$ different attacks in both white and black box settings, including attacks outside of the intended threat model of De-Randomized Smoothing. Depending on the attack, even the least robust DRSM model can provide $87.9\% {\sim} 26.5\%$ better robustness than MalConv.


%We experiment with different sizes for our \textit{window ablation} in DRSM models and evaluate their standard and certified accuracy. We find that DRSM ($98.18\%$) can achieve comparable standard accuracy to MalConv model ($98.61\%$), and outperforms MalConv(NonNeg) ($88.36\%$) defense by a large margin. We also provide theoretical formulation of our `certified robustness'  and evaluate it under different perturbation budget. DRSM can provide $53.97\%{\sim}12.2\%$ certified accuracy depending on the ablated window size. We show the trade-off between standard and certified accuracy of DRSM which makes it suitable for different demands. Moreover, we empirically evaluate the robustness of our DRSM model against $9$ different attacks in both white and black box settings, including attacks that fall outside of our threat model. Varying from simple to sophisticated attacks, even the least robust DRSM model can provide $87.9\% {\sim} 26.5\%$ better robustness than MalConv model. 
%\wwx{a bit too detailed; summarizing qualitatively + showing a couple representative results will suffice}

%Dataset and implementation
A practical difficulty in malware research is collecting benign raw executables, due to copyrights and legal restrictions~\cite{anderson2018ember}.
%
%For this work, we collect $15.5K$ fairly recent and diverse benign executables by crawling different sources and compile a dataset of total size $1.1M$ by including datasets from prior studies
Throughout this work, we collect $15.5K$ fairly recent and diverse benign executables from different sources, which can be better representative of the real-world. 
These will be made public as a new dataset, namely PACE (Publicly Accessible Collection(s) of Executables), to alleviate the accessibility issue of benign executables and facilitate future research.
\footnote{Our open-source code and dataset: \url{https://github.com/ShoumikSaha/DRSM/}}
%
%\blfootnote{We implement DSRM on \texttt{secml-malware} Python library with an addition of a minimal number of files, which will be open-sourced to facilitate easy access and extension by future researchers and practitioners.}


Our major contributions include:

\begin{itemize}
    \item A new defense, DRSM (De-Randomized Smoothed MalConv), that pioneers certified robustness in the executable malware domain (Section \ref{sec:de_random_smoothing});
    \item A thorough evaluation of DRSM regarding its performance and certified robustness, which suggests DRSM offers certified robustness with only mild performance degradation (Section \ref{sec:eval});
    \item A thorough evaluation of DRSM regarding its empirical robustness against 9 empirical attacks covering both white-box and black-box settings, which suggests DRSM is empirically robust to some extents against diverse attacks. (Section \ref{sec:emp_robustness})
    \item A collection of $15.5K$ benign binary executables from different sources, which will be made public as a part of our new dataset PACE. (Section \ref{sec:dataset})
    %\item We develop our DRSM framework with minimal addition to the \texttt{secml-malware} Python library which makes it easily adoptable to other different models. We are going to open source our implementation.
    %\item We open source our implementation for DRSM framework, based on \texttt{secml-malware} Python library.
\end{itemize}


