\label{sec:emp_robustness}

Beyond theoretical robustness, we also evaluate the empirical robustness of our DRSM-n models. Recall from Section \ref{sec:threat_model} that -- in our threat model (any de-randomized smoothing scheme), attackers can add, or modify bytes in a contiguous portion of a malware file, to get it misclassified as a benign one. However, in real-life settings, attackers can be more capable and can deploy complex attacks where they can find multiple contiguous blocks to perturb. 
%Moreover, there are very recent works where attacker can even apply different code transformations guided by the model to modify bytes at many different places all over the file. 

%For a security-sensitive application like malware detection, a careful evaluation against different attacks is necessary, irrespective of the threat model. 
%Unfortunately, most prior defenses have neglected this. 
In this work, we consider $9$ different attacks in both white and black box settings and categorize them into $3$ types based on their alignment with our threat model. \textbf{Fully Aligned: }if an attack perturbs bytes in one contiguous block; \textbf{Partially Aligned: }if an attack perturbs bytes in multiple different contiguous blocks; \textbf{Not Aligned: }if an attack applies code transformation and changes bytes all over the file (not limited to any contiguous block). Table \ref{table:attacks} shows the list of attacks that have been considered in this work along with their type, settings, and short description. For more details about individual attacks and their implementation, see Appendix \ref{app:attack_app}.

\iffalse
\begin{itemize}[leftmargin=*]
    \item If an attack perturbs bytes in one contiguous block, then it is \textbf{fully inside} our threat model. Example - FGSM Append, DOS Extension, DOS Modification (Partial, Full), etc.
    \item If an attack perturbs bytes in multiple different contiguous blocks, then it is \textbf{partially inside} our threat model. This threat model subsumes the previous one. Example - Slack Append, Header Field Modification, GAMMA, etc.
    \item If an attack applies code transformation and changes bytes all over the file (not limited to any contiguous block), then it is \textbf{outside} of our threat model. Example - Disp, IPR, etc.
\end{itemize}
\fi

%Since attacks in the white-box setting is more powerful (or capable) than the balck-box one, our major focus was on the former one. However, we included some black-box attacks as well. 


\begin{table}[h]
  %\centering
  \caption{Attacks evaluated. \emptycirc[0.75ex] - Fully Aligned, \halfcirc[0.75ex] - Partially Aligned and \fullcirc[0.75ex] - Not Aligned describe the alignment of the attacks to our primary threat model (see Section \ref{sec:threat_model}).}
\begin{center}
\resizebox{\linewidth}{!}{
\begin{tabular}{ lcccp{6cm} }
    \hline
      \multirow{2}{*}{Attack}  & Threat & \multicolumn{2}{c}{Settings} & Short Description \\\cline{3-4}
             &   Model   &    White-box & Black-box & \\
     \toprule 
    \multirow{2}{*}{\shortstack[l]{FGSM Append \\ \citep{kreuk2018deceiving}}} & \multirow{2}{*}{\emptycirc[1ex]} & \multirow{2}{*}{\CheckmarkBold} &  & Appends random bytes at the end of the file generated by FGSM \\ \midrule
    
    \multirow{2}{*}{\shortstack[l]{Slack Append \\ \citep{suciu2019exploring}}} & \multirow{2}{*}{\halfcirc[1ex]} & \multirow{2}{*}{\CheckmarkBold} &  & Injects non-functional bytes in slack regions generated by FGSM \\ \midrule
    
    \multirow{2}{*}{\shortstack[l]{DOS Extension \\ \citep{demetrio2021adversarial}}} & \multirow{2}{*}{\emptycirc[1ex]} & \multirow{2}{*}{\CheckmarkBold} &  & Extends the DOS header and injects adversarial noise\\ \midrule
    
    \multirow{2}{*}{\shortstack[l]{DOS Modification (Partial) \\ \citep{demetrio2019explaining}}} & \multirow{2}{*}{\emptycirc[1ex]} & \multirow{2}{*}{\CheckmarkBold} & \multirow{2}{*}{\CheckmarkBold} & Puts adversarial noise in between of \texttt{MZ} and offset \texttt{0x3c} in the DOS header\\ \midrule
    
    \multirow{2}{*}{\shortstack[l]{DOS Modification (Full) \\ \citep{demetrio2021adversarial}}} & \multirow{2}{*}{\emptycirc[1ex]} & \multirow{2}{*}{\CheckmarkBold} & \multirow{2}{*}{\CheckmarkBold} & Modifies every byte in the DOS header without corrupting the file\\ \midrule
    
    \multirow{2}{*}{\shortstack[l]{Header Field Modification \\ \citep{nisi2021lost}}} & \multirow{2}{*}{\halfcirc[1ex]} & \multirow{2}{*}{\CheckmarkBold} & \multirow{2}{*}{\CheckmarkBold} & Modifies fields in PE header\\ \\ \midrule
    
    \multirow{2}{*}{\shortstack[l]{Disp \\ \citep{lucas2021malware}}} & \multirow{2}{*}{\fullcirc[1ex]} & \multirow{2}{*}{\CheckmarkBold} &  & Displaces code instructions using \texttt{jmp} and semantic \texttt{nop} \\ \midrule
    
    \multirow{2}{*}{\shortstack[l]{IPR \\ \citep{lucas2021malware}}} & \multirow{2}{*}{\fullcirc[1ex]} & \multirow{2}{*}{\CheckmarkBold} &  & Replaces instructions in multiple ways (equiv. replace, register reassign, reorder, etc.) without altering functionalities\\ \midrule
    
    \multirow{2}{*}{\shortstack[l]{GAMMA \\ \citep{demetrio2021functionality}}} & \multirow{2}{*}{\halfcirc[1ex]} &  & \multirow{2}{*}{\CheckmarkBold} & Extracts payloads from benign programs and injects them in malware\\
      \midrule
\end{tabular}
}
\end{center}

\label{table:attacks}
\end{table}



%\subsection{Attack Evaluation}
To evaluate the attacks against MalConv, MalConv (NonNeg) and DRSM-n models, we randomly sampled $200$ malware from the test-set of our dataset that are correctly classified by the model before attack. Let us call this subset of malware the `attack set'. 
%We could use higher number of samples, but some attacks take very long time to generate an adversarial sample and for a fair comparison, we wanted to use the same set for every attack.
We call an attack `successful' if the attack can generate a functional adversarial malware that can change the model's prediction from `malware' to `benign'.
Even though the majority voting in DRSM-n is not differentiable, it can still be attacked by targeting its base classifiers. Correspondingly, whenever necessary, we generate adversarial malware from the `attack set' by differentiating through the base classifier.
%Note that, for non-negative weight constraint, it is not possible to directly attack MalConv (NonNeg) model.

%\citep{wang2022black, ceschin2019shallow, lucas2021malware, wang2023mpass} -- shows that Non-Neg MalConv is vulnerable

\begin{figure}[tbp]
    \subfloat{
    \includegraphics[clip,width=1.0\linewidth]{images/wb_ASR2.pdf}%
    }\\[-3ex]
    \subfloat{
    \includegraphics[clip,width=1.0\linewidth]{images/wb_ASR3.pdf}%
    }
    \caption{Attack Succes Rate (ASR) \% for white-box attacks on all models}
    \label{fig:wb_asr}
\end{figure}


Figure \ref{fig:wb_asr} shows the attack success rate (ASR) for different attacks in the white-box setting. We find that -- most attacks have less ASR on DRSM-n models than MalConv by a large margin. For example, FGSM append attack has $82.50\%$ ASR on MalConv whereas $10.0\%$ and $7.0\%$ on DRSM-4 and DRSM-8, respectively.
Moreover, for $n \geq 16$ in DRSM-n models, the ASR for all white-box attacks is $(1\%{\sim}5\%)$. 
%Moreover, ASR on DRSM-12, DRSM-16, DRSM-20, and DRSM-24 models is very marginal. 
We got the highest ASRs on MalConv model for DOS Extension ($98.00\%$) and Disp ($89.50\%$) attack, while the ASRs on DSRM-n models were in range of $(1\% {\sim} 72\%)$ and $(1\% {\sim} 42\%)$, respectively. 
%Recall from the Section \ref{sec:evaluation} that -- `$n$ in DRSM-n' has a positive correlation with certified robustness. While this pattern is still existent in empirical robustness (from Figure \ref{fig:wb_asr}), it is not as dominant as the theoretical one. 

%Interestingly, we found that -- the attacks that modify the header fields has marginally higher ASR on DRSM-8 than DRSM-4. It can be the case that -- DRSM-8 generates the ablated sequences from original file in a way that -- `perturbation in header fields' impact higher number of windows than other DRSM models. 

Though Disp and IPR attacks fall outside of our threat model, surprisingly, DRSM-n can still provide good robustness against them (Figure \ref{fig:wb_asr}). 
Here is a potential explanation: Transformed bytes by Disp and IPR at different places get divided into multiple ablated sequences and thus, they become less impactful in altering multiple predictions compared to one prediction. An interesting observation is that the attacks that modify the header fields have marginally higher ASR on DRSM-8 than on DRSM-4: Potentially, this is because for DRSM-8 the perturbed positions in header fields happen to cover more windows than other cases. 
%Finding from our primary investigation is -- when Disp and IPR attacks are run against the base classifier MalConv, they transform code at multiple different places to evade the prediction by the model. However, those transformations become less influential when they get divided into multiple ablated sequences and they have to alter multiple predictions. Thus, our DRSM-n model can provide better robustness even against such sophisticated attacks.  




We also evaluated the models against black-box attacks using genetic optimizers. For example, GAMMA attack extracts payload from benign programs and injects them into malware by querying the model. From Figure \ref{fig:bb_asr}, GAMMA has $24\%$ ASR on MalConv whereas $(4{\sim}1)\%$ on DRSM-n models. While it is true that -- these black-box attacks have less ASR on MalConv compared to the white-box ones, still DRSM-n models outperform. Interestingly, we found that MalConv(NonNeg) suffers in query-based black-box attacks, though it has been believed as a robust model for a long time. Our results are consistent with some recent works, e.g., Dropper attack by \citet{wang2022black}, MPass, GAMMA attack by \citet{wang2023mpass}, Goodware string append by \citet{ceschin2019shallow}.


\begin{figure}[tbp]
        \centering
        \includegraphics[width=1.0\linewidth]{images/bb_ASR3.pdf}
        \caption{Attack Succes Rate (ASR) \% for black-box attacks on different models}
        \label{fig:bb_asr}
\end{figure}



