\label{sec:de_random_smoothing}


%For certified defense against the adversarial attack, smoothed vision models have long been used in the vision domain. However, such defense method is still untouched by malware community. 
%The intuition behind incorporating the `de-randomized smoothing' technique with raw binary file is -- when the attacker generates a byte perturbation attacking the base classifier, it is not necessary that those bytes will have the same impact on all ablated inputs of the smoothed classifier. Besides, the bytes that contain the malicious features remain preserved in the ablated versions, and hence, the smoothed classifier can still learn the malicious features. 

Since the malware detection problem cannot be directly mapped to typical vision problems, we had to redesign the `de-randomized smoothing' scheme to make it compatible. Unlike images, our input samples are one-dimensional sequences of bytes, which makes the common vision-oriented ablation techniques, e.g., adding noise, masking pixels, block ablations, etc., infeasible. Additionally, even a random byte change in a file may cause a behavior change or prevent the sample from executing. 

\begin{figure}[h]
        \centering
        \includegraphics[width=1.0\linewidth]{images/drsm_archi3.pdf}
        \caption{DRSM (De-Randomized Smoothed MalConv) model framework}
        \label{fig:drsm_archi}
\end{figure}



So, we introduce the \textit{`window ablation'} strategy which involves segmenting the input sample into multiple contiguous sequences of equal size. If the input length of the base classifier is $L$, and the size of the ablated window is $w$, then there will be $\lceil \frac{L}{w} \rceil$ ablated sequences of length $w$ resulting in the ablated sequence set $S(x)$. So, even if an attacker generates a byte perturbation of size $p$, it can modify at most $ \Delta = \lceil \frac{p}{w} \rceil + 1$ ablated sequences ($+1$ when a perturbation overlaps $2$ windows). Since a perturbation can only influence a limited number of ablated sequences, it cannot directly change the decision of the smoothed-classifier model -- which was our prior motivation to integrate this technique. A visual representation of our strategy is provided in Figure \ref{fig:drsm_archi}. 

The goal of the defender is to -- using $F_\theta$ as the base classifier, find a \textit{de-randomized smoothed model} $G_\theta$  that can detect any adversarial malware $x^{'}$ generated using a perturbation $\delta$. $G_\theta$ takes in each sequence $s$ from the ablated sequence set $S(x)$, and returns the most frequent predicted class. Specifically, for an input file $x$, ablated sequence set $S(x)$, and base classifier $F_\theta$, the \textit{de-randomized smoothed model} $G_\theta$ can be defined as:
$$ G_{\theta}(x) = \arg \max_{c} n_c(x) $$
where, 
$$ n_c(x) = \sum_{x^{'} \in S(x)} I\{F_{\theta}(x^{'})=c\} $$ denotes the number of ablated sequences that were predicted as class $c$. The percentage of files that are correctly classified by the \textit{de-randomized smoothed model} $G_\theta$ is the \textbf{`standard accuracy'}. 

We say the classifier $G_\theta$ \textit{certifiably robust} on an ablated sequence set if the number of predictions for the correct class exceeds the incorrect one by a `large margin' (dictated by byte size of perturbation). This `large margin' puts a lower bound on attacker's success in altering predictions of the classifier $G_\theta$ since a perturbation $\delta$ of size $p$ can, at most, impact  $\Delta = \lceil \frac{p}{w} \rceil + 1$ ablated sequences.

Mathematically, the \textit{de-randomized smoothed model} $G_{\theta}$ is `certifiably robust' on input $x$ for predicting class $c$ if:
$$ n_c(x) > max_{c \neq c^{'}} n_{c^{'}}(x) + 2 \Delta $$
Since our problem is a binary classification problem, this can be rewritten as:
\begin{equation} \label{eqn:cond_certtify}
\begin{split}
 n_m(x) > n_b(x) + 2 \Delta \ \ \ \ \ & \text{; if $true{-}label(x) = malware$}\\
 n_b(x) > n_m(x) + 2 \Delta \ \ \ \ \ & \text{; if $true{-}label(x) = benign$}
\end{split}
\end{equation}

%$$ n_m(x) > n_b(x) + 2 \Delta $$
where, $n_m(x)$ and $n_b(x)$ are the number of ablated sequences predicted as malware and benign by the \textit{de-randomized smoothed model} $G_{\theta}$, respectively. The percentage of file that holds the inequality \ref{eqn:cond_certtify} for $G_{\theta}$ is the \textbf{`certified accuracy'}.

%\smk{Should I omit the following paragraph here? and introduce DRSM in evaluation section?}

%As the base classifier, we used MalConv model, and so named the de-randomized smoothed model  as DRSM (De-Randomized Smoothed MalConv). 
For simplicity, we will use DRSM-n to denote DRSM with the number of ablated sequences $|S(x)| = \text{n}$, e.g. DRSM-4 means $4$ ablated sequences on input $x$ will be generated for DRSM.