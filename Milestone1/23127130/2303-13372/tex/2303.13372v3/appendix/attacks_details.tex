\label{app:attack_app}

\begin{figure}[h]
        \centering
        \includegraphics[width=1.0\linewidth]{images/attack_pe_image.pdf}
        \caption{Graphical Representation of the locations perturbed by different attacks with adversarial payloads}
        \label{fig:attack_pe}
\end{figure}

\blfootnote{Figure \ref{fig:attack_pe} is taken from \citet{demetrio2021adversarial}.}

\subsubsection{FGSM Append Attack}
Append attack in adversarial malware was first proposed by \citet{kolosnjaji2018malware}. In this attack, authors added some noise at the end of a malware file computes by gradient of the model. However, the first proposed method was computationally heavy. Later, it was improved by \citet{kreuk2018deceiving} using Fast Gradient Signed Method (FGSM) motivated by \citet{goodfellow2014explaining}. In Figure \ref{fig:attack_pe}, the `Padding' label (purple) depicts the FGSM Padding (or Append) attack.

In our experiment, we kept a padding budget of $10$KB ($=0.5\%$ of the input file size) and ran the attack for $10$ iterations. We noticed that, for some malwares the model prediction was $1.0$ for which the attack failed.

\subsubsection{Slack Append Attack}
This attack was an incremental work on \citet{kreuk2018deceiving} by \citet{suciu2019exploring}. Unlike the previous one, the attacker can inject the payload in between of sections. The find the gaps between consecutive sections (called `slack spaces') in a binary by $RawSize - VirtualSize$, and use  that gap to inject gradient-generated adversarial bytes. Since these slack spaces can be at multiple places, this attack is partially inside our threat model. In Figure \ref{fig:attack_pe}, the `Slack Space' label (grey) indicates this attack.

In our experiment, we followed the same parameter as the previous one, and ran it for 10 iterations by keeping the padding budget $10$KB. We want to mention that -- though this attack seems more evasive than the previous one, for larger perturbation budget FGSM Append is more successful than this one. This was found in original paper, and our result is consistent with this finding too. 

\subsubsection{DOS Extension Attack}
This attack creates a new space by extending the DOS header. Attacker increases the offset to PE header and modify the file structure accordingly. In these extended spaces, attacker can put adversarial bytes to evade a model \citep{demetrio2021adversarial}. Since the extension is on a contiguous portion (header) of the file, it falls under our threat model. In Figure \ref{fig:attack_pe}, the `Extend' label (green) refers to this attack.
We ran this attack on our `attack set' for $10$ iterations with $10^{-3}$ penalty regularizer.

\subsubsection{DOS Modification Attack}
There are 2 versions of this attack -- Partial\citep{demetrio2019explaining}, and Full\citep{demetrio2021adversarial}. In DOS header, two important bytes are -- magic number \texttt{MZ} and real offset \texttt{0x3c}. The former attack modifies bytes in between of these two bytes while the latter one modified every bytes in the DOS header except those two. So, the `full' modification version is more evasive than the `partial' one. This attack is shown in blue and yellow color in Figure \ref{fig:attack_pe}. We ran this attack on our models for 10 iterations.


\subsubsection{Header Field Modification Attack}
This attack was proposed by \citet{nisi2021lost}. They analyzed the discrepancies among tools and PE file formats. Thus, they found a set of bytes (or modifications) that can potentially evade a malware classifier. Since this attack modifies bytes at multiple different places but they are constrained only in the PE header, it is partially inside our threat model. In Figure \ref{fig:attack_pe}, the `Header Fields' label (black) shows how this attack changes header fields in PE header. We ran this attack for $20$ iterations.  

\subsubsection{Disp (Code Displacement) Attack}
In this attack, the attacker has to use to disassemble a malware first. Then the attacker displace consecutive instructions in a basic block. Such displacements are usually done \texttt{jmp} and \texttt{nop} instructions. \citet{lucas2021malware} proposed this attack for the first time. Figure \ref{fig:disp} shows an example of such attack.


\begin{figure}[h]
        \centering
        \includegraphics[width=0.4\linewidth]{images/disp_example.pdf}
        \caption{An example of Disp attack}
        \label{fig:disp}
\end{figure}

We collected the private implementation of the guided version of this attack from the authors. We ran Disp-1 (the perturbation budget is $1\%$ of the binary size) for 100 iterations. 

\subsubsection{IPR (In-Place Randomization) Attack}
Like the previous attack, attacker has to disassemble the malware here. Then attacker can apply four types of transformations -- 
i) replacing instructions with equivalent ones, ii) reassigning registers, iii) reordering instructions using dependency graph, and iv) altering register's push and pop order.
These transformations do not necessarily change the file size but it modifies the code at many different places. So, this attack falls outside of our threat model. Figure \ref{fig:ipr} shows the transformation types with an example. We collected the private implementation for this attack from authors of \citet{lucas2021malware}.


\begin{figure}[h]
        \centering
        \includegraphics[width=1.0\linewidth]{images/ipr_example.pdf}
        \caption{An illustration of IPR attack}
        \label{fig:ipr}
\end{figure}

\subsubsection{GAMMA Attack}
This attack was first proposed by \citet{demetrio2021functionality}. Though it was a common belief that -- goodware (or benign) payload (or string) can be added to a malware to evade a model, they are the first to propose a query-based black-box method for this. In this attack, the attacker generates payload from some benign programs, then inject them into a malware and return the best subset of generations by querying the model. Figure \ref{fig:gamma} shows the overview of the attack.


\begin{figure}[h]
        \centering
        \includegraphics[width=1.0\linewidth]{images/gamma_overview.pdf}
        \caption{Overview of GAMMA attack}
        \label{fig:gamma}
\end{figure}


In our experiment, we ran the hard-label version of GAMMA attack with section injection. We set the population size and query as $200$, and ran it for $20$ iterations. For payload extraction, we used the \texttt{.data} section of benign files.

\blfootnote{For Disp and IPR attacks, we used IDAPro disassembler.}
\blfootnote{Figure \ref{fig:disp} and \ref{fig:ipr} are taken from \citet{lucas2021malware}.}
\blfootnote{Figure \ref{fig:gamma} is taken from \citet{demetrio2021functionality}.}