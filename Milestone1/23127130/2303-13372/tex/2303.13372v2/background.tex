\begin{figure*}
        \centering
        \includegraphics[width=0.85\textwidth]{Images/malconv_archi_2.png}
        \caption{Architecture of MalConv model}
        \label{fig:malconv}
\end{figure*}

In this paper, we used MalConv model by Raff et.al. \cite{raff2018malware} for malware vs benign binary file detection, depicted in figure \ref{fig:malconv} \footnote{Taken from \cite{8553214}}. We denote the set of all bytes as $X \subseteq [0, N-1]$, where $ N = 256$.
A binary file is a sequence of k bytes $x = (x_1, x_2, x_3, ... x_k)$, where $ x_i \in X$ for all $1 \leq i \leq k$. Note that the length $k$ varies for different files, thus $k$ is not fixed. However, the input vector fed into the network has to be of a fixed dimension. So, we extract the first $D$ bytes from $x$, or pad zeros at the end of $x$ if $k < D$, to fix the input length to $D$. Each byte $x_i$ is then passed to an embedding layer with embedding matrix $ Z \in \mathbb{R}^{D \times 8}$, which generates an embedding vector $z_i = \phi (x_i)$ of 8 elements.
This vector is then passed through two convolution layers, using ReLU and sigmoid activation functions respectively. These activation outputs are combined through a gating which performs an element-wise multiplication to mitigate the vanishing gradient problem.
The output is then fed into a temporal max pooling layer, followed by a fully connected layer. Finally, a softmax layer calculates the probability of $x$ being a malware or not. In short, MalConv is a CNN-based network preceded by an embedding layer, and let us represent the whole model as $F_{\theta} : X \rightarrow [0,1]$ with a set of parameters $\theta$ that it learns through training. If the output of $F_{\theta}(x)$ is greater than $0.5$ then the prediction is considered as 1 or malicious, and vice versa.