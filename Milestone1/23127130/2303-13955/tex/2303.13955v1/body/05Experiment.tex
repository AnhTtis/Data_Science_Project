% 本节我们验证了MOAMT框架的有效性，并且将MOMAT与其他对抗训练方法相结合。此外还验证了NMSE loss也可以提升模型的鲁棒性。
% In this section, we set up experiments to verify the advantages of \name framework and show that it can effectively improve the efficacy and stability of adversarial training when combined with other adversarial training methods. Moreover, we verify that NMSE loss can also effectively enhance the model's adversarial robustness performance.

In this section, we conduct experiments on several benchmark datasets to evaluate the defense efficacy of our \name framework and NMSE regularization. We also verify that \name could boost the model robustness when combined with various AT methods. 

\subsection{Experimental Setup}
% 介绍了使用的数据集，网络.
\textbf{Datasets and Models} \quad
We conduct experiments on three benchmark datasets including CIFAR10~\cite{CIFAR100}, CIFAR100~\cite{CIFAR100}, and SVHN~\cite{SVHN}. All images are normalized into \([0, 1]\). We evaluate on two models, ResNet18~\cite{Resnet18} and WRN-32-10~\cite{WRN}, to verify the efficacy of %\name framework.
our method. 
% in combination with other adversarial training. 
% In our experiments, we normalize each pixel value into $[0,1]$. 


% MOMAT和Trade-off,PGD-AT,MART,GAIRAT方法结合的结果。同时给出了用于测试防御的对抗攻击方法。
\textbf{Evaluation Details} \quad
We compare the \name combined with NMSE regularization with the following AT baselines: TRADES~\cite{Trade-off}, MART~\cite{MART}, and GAIRAT~\cite{GAIRAT}. To thoroughly evaluate the defense efficacy
of our method and the baselines, we adopt various adversarial attacks including PGD~\cite{PGD}, MIM~\cite{MIM}, CW~\cite{CW}, and AA~\cite{AA}.
% We combine the \name framework with PGD adversarial training and add NMSE loss as the regularization to compare with several classical adversarial training methods, TRADES~\cite{Trade-off}, MART~\cite{MART}, and GAIRAT~\cite{GAIRAT}. In this experiment, We evaluate adversarial training methods using several advanced adversarial attacks, including PGD~\cite{PGD}, MIM~\cite{MIM}, CW~\cite{CW}, and AA~\cite{AA}.

% 模型训练的参数和优化器参数的选择
\textbf{Training Details} \quad
% We choose Resnet18~\cite{Resnet18} as the network of baseline.
For all the experiments, we train ResNet18 (WRN-32-20) using SGD with 0.9 momentum for 120 (180) epochs. The weight decay is $3.5\times10^{-3}$ for ResNet18 and $7\times 10^{-4}$ for WRN-32-10 on three datasets. The initial learning rate for ResNet18 (WRN-32-10) is 0.01 (0.1) till epoch 60 (90) and then linearly decays to 0.001 (0.01), 0.0001 (0.001) at epoch 90 (135) and 120 (180).
%For 
To address the cold boot problem of training, we perform standard training on the clean data for the first 10 epochs, and then perform adversarial training. For crafting adversarial examples, the maximum perturbation of each pixel is $\epsilon=\frac{8}{255}$ with the PGD step size $\kappa=\frac{2}{255}$ and step number of 10. 
% All experiments are set up according to the above parameters. 
For the baseline of TRADES, we adopt $\beta$ = 6 for the best robustness.

\input{tab/MOMAT_WRN_Part}

\input{tab/Parameter_NMSE_Part}
% 分别分析MOMAT算法框架在Resnet18和WRN-32-10上的效果.

\input{fig/MOMAT_Other}

\subsection{Evaluation on Defense Efficacy}
\label{Result}
% 使用MOMAT方法后，在防御能力得到全方面的提升，且在CIFAR100上的提升效果更加显著，说明即使数据集更加难，我们的方法依然是十分有效的.
% \textbf{Combined with \name framework and NMSE Loss} \quad
We compare the defense efficacy of our method with four AT baselines including PGD-AT, TRADES, MART and GAIRAT. 
Table~\ref{table 1: Combination with other defense methods} reports the accuracy of ResNet18 model trained with our method or the defense baselines under various adversarial attacks on three datasets.


% Combining \name framework and NMSE loss, the model has better performance to defend adversarial attacks on all datasets. 
As shown in Table~\ref{table 1: Combination with other defense methods}, our method  (\name + NMSE) exhibits the best performance except for the PGD and MIM attack on CIFAR10 dataset. Under the AA attack, our method achieves 48.80\%, 25.79\% and 51.29\% accuracy on CIFAR10, CIFAR100 and SVHN datasets. Compared to the best results of defense baselines, we gain an improvement of 0.76\%, 1.07\% and 5.50\% on the three datasets, respectively, indicating the great superiority of our method.

We do further evaluation on the WRN-32-10 model, which is much larger than ResNet18, and compare our method with PGD-AT and TRADES. 
% Since it is much larger than ResNet18, we only compare our method with PGD-AT and TRADES. 
The results are reported in Table~\ref{tab:MOMAT_WRN_Part}. Similar to the results on ResNet18, our method achieves the dominant robustness with a clear margin, especially on CIFAR10 dataset.
% \HK{add} 

% either in ResNet18 or WRN-32-10, our method has a large margin which indicates the good flexibility of our method.
% Importantly, our method gains \textbf{0.76\%}, \textbf{1.07\%} and \textbf{5.50\%} in robustness on CIFAR10, CIFAR100 and SVHN using ResNet18, respectively.

% 验证模型同时使用MOMAT和NMSE loss与其他对抗训练防御效果的比较。我们的方法在各个数据集上与其他方法相比都达到SOTA。
% \textbf{MOMAT Combined with NMSE Loss} \quad
\input{fig/Hyperparameter_NMSE}
\input{fig/MOMAT_model_loss}

\subsection{Ablation Study}

\textbf{\name Framework} \quad
Since \name is a general framework, we %combine it with other AT methods 
incorporate other AT methods into \name 
to demonstrates its defense efficacy. 
% To evaluate the efficacy of our \name framework, we combine with standard adversarial training. 
Figure~\ref{fig:MOMAT combined with classical adversarial training} illustrates the accuracy of \name framework combined with TRADES, MART, and GAIRAT, respectively, under the AA attack on the three datasets. 

As shown in Figure~\ref{fig:MOMAT combined with classical adversarial training}, over all the three datasets, \name boosts the robustness of various AT methods against the AA attack. The results demonstrate that we can easily %combine \name to other AT methods 
 incorporate other AT methods into our \name framework 
without incurring any additional cost to achieve better robustness and performance. 
% our \name framework can boost the robust accuracy stably for any basic adversarial training.
% Especially, GAIRAT has worse performance on AA compared with TRADES and MART, but our framework signficantly improves the robustness especially on CIFAR100 and SVHN. 

% We also train robust WRN-32-10 model which has larger-scale than ResNet18 and reports experiment results in Table~\ref{tab:MOMAT_WRN_Part}. 
% Specifically, \name framework boosts robust accuracy of TRADES, gaining absolute improvement of $\mathbf{+3.35\%}$ and $\mathbf{+2.49\%}$ on CIFAR10 and CIFAR100 under AA attack. 
% Our framework leads to higher robust accuracy when it combined with other classical adversarial methods, which means the \name framework outperforms better even when the size of DNN scales, indicating our framework has good flexibility and generalization.

We also %evaluate 
do ablation study 
on the WRN-32-10 model and report the results in Table~\ref{tab:MOMAT_WRN_Part}. 
Specifically, \name framework significantly boosts the robust accuracy of TRADES, gaining absolute improvement of $3.35\%$ and $2.49\%$ on CIFAR10 and CIFAR100 under the AA attack, respectively. 
% Our framework leads to higher robust accuracy when it combined with other classical adversarial methods, which means the \name framework outperforms better even when the size of DNN scales, indicating our framework has good flexibility and generalization.
Our framework leads to higher robust accuracy when combined with other AT methods on two models, indicating that \name has good flexibility and generalization.


% 验证模型是否使用NMSE loss，对于对抗训练效果的提升，从而分析NMSE loss在对抗训练过程中所起的作用。
\textbf{NMSE Regularization} \quad
% To exclude the influence of \name framework, we evaluate NMSE loss with and without \name framework.
To evaluate the effectiveness of our proposed NMSE regularization, we observe the performance of PGD-AT and \name with or without NMSE regularization. Table~\ref{table 3: NMSE_table_part} reports the accuracy of ResNet18 models against PGD and AA attack on the CIFAR10 and CIFAR100 datasets.

As shown in Table~\ref{table 3: NMSE_table_part},  
both PGD-AT and \name achieve better robustness with NMSE regularization than that without NMSE. For instance, the accuracy of PGD-AT against AA attack gains absolutely 0.37\% and 1.62\% on CIFAR10 and CIFAR100, respectively. It indicates that the NMSE regularization greatly helps the model learn the features of adversarial examples. 

% Specifically, combined with NMSE loss, the robust accuracy of standard adversarial training on AA gains \textbf{0.37\%} and \textbf{1.62\%} on CIFAR10 and CIFAR100. Moreover, \name framework also outperforms better, obtaining \textbf{48.70\%} and \textbf{25.79\%}. 

% Furthermore, NMSE also improves the accuracy on clean examples, 

% 消融实验和NMSE loss超参数的选择进行了比较,并且对比了MOMAT方法和标准对抗训练的landscape。
\subsection{Further Analysis}
\label{sec:furtherStudy}
We continue to analyze the sensitivity of hyper-parameters in our method. 
% study the $\mu$ in NMSE loss of model robustness. Our further experiments are set up on CIFAR10 and CIFAR100 datasets. 
Besides, we draw a 3D visual landscape of loss function to further compare our method and PGD-AT. 

% \input{tab/Parameter_NMSE.tex}

% NMSE loss的超参数选择与分析
\textbf{Hyper-parameter Analysis} \quad
The hyper-parameter \(\lambda\) in Eq.~\ref{eq:MOMAT} is used to control the trade-off between previous and current parameters for \name. In Section~\ref{section:3}, we intuitively suggest that \(\lambda\) should change over the course of training, instead of using a fixed value. 
To verify this point, we compare the accuracy of \name combined with NMSE using fixed $\lambda=0,0.1,0.3,0.5,0.7,0.9$ and our variable \(\lambda\) as in Eq.~\ref{eq5}. Figure~\ref{fig:MOMAT_test_accuracy} illustrates the results on the CIFAR10 dataset. It is obvious that the variable strategy of  \(\lambda\) is vital to alleviate the oscillations in the early stage and the overfitting issue in the later stage of the AT process. 
% When $\lambda=0$, it is standard adversarial training. 
% When $\lambda=0.9$, the model's convergence speed and accuracy rate in the early stage are much lower than others, but there is no overfitting issue in the later stage of training. 
% Although the convergence speed is fast in the early training stage, the overfitting issue appears like standard adversarial training for other values. 
% The above results in 
% \input{PIAT/tab/Parameter_NMSE_Part}

The hyper-parameter \(\mu\) in Eq.~\ref{Total Loss} is used to trade off the cross-entropy loss on adversarial examples and the NMSE regularization term. We study the accuracy of \name combined with NMSE using different \(\mu\). 
% results of different $\mu$ to study the influence in NMSE loss for model.
Figure~\ref{fig:Hyperparameter of NMSE} illustrates the results on the CIFAR10 dataset when we take $\mu=3,4,5,6$.
% When it combines with \name framework, we take $\mu=3,4,5,6$ on CIFAR10 dataset. 
It indicates that the defense efficacy of our method is not sensitive to $\mu$. 
Similar observations can be obtained on the CIFAR-100 dataset.
Therefore, we set $\mu=5$ in our experiments for %a proper
an appropriate 
trade-off between the accuracy on clean and adversarial examples. 

\textbf{Loss Landscape} \quad
%It is difficult to comprehensively evaluate the efficacy with only using loss or accuracy on the datasets.
%Therefore, 
To comprehensively evaluate the efficacy of our framework,  
we refer to the method proposed by Li \etal~\cite{visual_network} and compare the model obtained by \name framework and PGD-AT in 3D. 
Let $\mathbf{u}$ and $\mathbf{v}$ be two random direction vectors sampled from the Gaussian distribution. We plot the loss landscape around $\boldsymbol{\theta}$ of the following equation when inputting the same data:
\begin{equation}
    \mathcal{L}(\boldsymbol{\theta};\mathbf{u};\mathbf{v})=\mathcal{L}\left(\boldsymbol{\theta}+m_1\frac{\mathbf{u}}{||\mathbf{u}||}+m_2\frac{\mathbf{v}}{||\mathbf{v|}|}\right),
\end{equation}
where \(m_1,m_2 \in [-1,1]\).

Figure~\ref{fig:MOMAT model loss} illustrates the shape of the 3D landscape map. We observe that compared with the PGD-AT, the model trained using the \name framework exhibits less fluctuation in the loss landscape under the same perturbation.
% indicating that the \name framework makes the model achieve better results. 
Compared with the PGD-AT, the 3D landscape obtained using the \name framework indicates that the model converges to a flatter area and has better robust accuracy.
% is almost a plane. This shows that the model trained by \name framework converges to a flatter area, improving the robustness.