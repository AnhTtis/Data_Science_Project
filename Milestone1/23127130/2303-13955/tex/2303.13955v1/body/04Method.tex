% 这一节主要介绍了MOMAT算法的实现和与其他对抗训练方法结合。
\input{fig/MOMAT_test_accuracy.tex}
\input{alg/PIAT}
In this section, we introduce the realization of the \name framework. We also describe how to %combine other %classical
%incorporate other typical adversarial training methods into our framework and 
combine with our proposed Normalized Mean Square Error (NMSE). 



% 介绍MOMAT对抗训练算法的具体实现细节，以及对于参数的分析与选取。
\subsection{The \name Framework}
% Based on the momentum idea, we propose \name framework algorithm\ref{alg: MOMAT} to fully use the historical information of the model. When$\lambda=0$, standard adversarial training is a special case of our framework. 
% For fully utilizing the historical training information, we adopt the parameter interpolation to consider the parameters of previous epochs when staring a new epoch, which can be formulated as:
To fully utilize the historical information during training, at the end of each epoch, \name tunes the model parameters as the interpolation of parameters of the previous and current epochs, which can be %formulated as:
formalized as:
\begin{equation}
    \boldsymbol{\theta_t'}=\lambda\cdot\boldsymbol{\theta_{t-1}'}+(1-\lambda)\cdot\boldsymbol{\theta_t}, \quad 0 \leq \lambda \leq 1 , 
    \label{eq:MOMAT}
\end{equation}
% where $\boldsymbol{\theta_{t-1}'}$ is the initial parameters of the current epoch before training, and $\boldsymbol{\theta_t}$ is the parameters of this epoch after training, $\boldsymbol{\theta_t'}$ is the current parameters of the model.
where \(\boldsymbol{\theta_{t-1}'}\) is the model parameters of the previous epoch after interpolation, and \(\boldsymbol{\theta_t}\) is current parameters before interpolation at the end of the training epoch.  
% $\boldsymbol{\theta_t'}$ is the current parameters of the model.
Then, before starting the next epoch, we tune the parameters to \(\boldsymbol{\theta_t'}\). The hyper-parameter \(\lambda\) controls the %weight between previous and current parameters when interpolation.
trade-off between previous and current parameters. 

% We consider the value of \(\lambda\) from the following aspects. 
The value of \(\lambda\) is critical to \name.
In the early stage of AT, the model has not yet fit the training data well enough. Thus, the model is not robust enough against adversarial attacks, and its parameters are not very informative. 
If \(\lambda\) is too large, the model mainly relies on previous parameters and learns the training data in small steps, leading to slow convergence.
% It indicates the model can not learn the main features from the adversarial examples because of the little change of the decision boundary. 
Therefore, \(\lambda\) should be small in the early stage. 

As the training continues, the model starts to learn enough information from the adversarial examples and attains adversarial robustness. 
%If \(\lambda\) is too small, the model will be affected easily by a new epoch of training. 
% The decision boundary of the model will overfit the adversarial examples which is roughly invariable in the later stage, resulting in the overfitting issue. 
% If \(\lambda\) is still small, it is easy for the model to 
% the model tends to 
% discard useful information learned over the history process and overfit the adversarial examples, which are roughly invariable\HK{?} in the later stage.
In the later stage, the model has learned enough information and gained good robustness. 
\(\lambda\) should be close to 1, otherwise the model tends to discard useful information learned over the training process and overfit the current adversarial examples.


% According to the analysis, taking a value of \(\lambda\) that changes with the training epochs instead of a fixed value will improve the training performance. 

% We compare the result of $\lambda=0,0.1,0.3,0.5,0.7,0.9$. When $\lambda=0$, it is standard adversarial training. When $\lambda=0.9$, the model's convergence speed and accuracy rate in the early stage are much lower than others, but there is no overfitting issue in the later stage of training. Although the convergence speed is fast in the early training stage, the overfitting issue appears like standard adversarial training for other \(\lambda\). The above results in Figure~\ref{fig:MOMAT test accuracy} confirm our analysis. 

According to the above analysis, \(\lambda\) should change over the course of training, instead of using a fixed value. 
The value of \(\lambda\) should be small in the early stage of training and gradually increase along with the training, which not only ensures the convergence speed but also alleviates the overfitting issue in AT. In this paper, we set \(\lambda\) as follows:
\begin{equation}
\label{eq5}
    \lambda=g(n)=\frac{n+1}{n+c}, \quad  c \geq 1 ,
\end{equation}
where \(n\) denotes the current number of training epochs. \(c\) is a hyper-parameter and we set \(c = 10\) in this work. The accuracy curves of different \(\lambda\) values are as shown in Figure~\ref{fig:MOMAT_test_accuracy}. We will verify that a dynamic \(\lambda\) that varies with the number of training epochs has better robustness against a fixed value in Section~\ref{sec:furtherStudy}.

Algorithm \ref{alg: MOMAT} concludes the overall framework.
Since \name does not restrict the type of loss function in the framework, it is flexible and can be combined with various adversarial training methods such as TRADES~\cite{Trade-off}, MART~\cite{MART} and GAIRAT~\cite{GAIRAT}. % with a good flexibility.

\input{tab/MOMAT_method.tex}

% \textbf{Normalized Mean Square Error (NMSE)}
\subsection{The NMSE Regularization}
According to the discussion in Section~\ref{section:3}, instead of aligning the clean and adversarial examples by classification probabilities, we utilize the output logits normalized with \(l_2\)-norm.
% , which can be formulated by:
% \begin{equation}
%     \label{eq:2-norm}
%         \emph{p}_{2-norm}=\frac{f_{\boldsymbol{\theta}}(\mathbf{x}')}{||f_{\boldsymbol{\theta}}(\mathbf{x}')||_{2}}
% \end{equation}
% where $\mathbf{x}'$ is the adversarial example. $f_{\boldsymbol{\theta}}(\mathbf{x}')$ is the output logits of the model. $||\cdot||_2$ denotes \(l_2\)-norm of vector.




We align the clean and adversarial examples by minimizing the mean square error between their normalized output logits. Besides, we set \((1-p_{clean})\) as the weight for different adversarial examples so that the model will pay more attention to the clean examples which are vulnerable. We formulate the Normalized Mean Square Error (NMSE) regularization as follows:
\begin{equation}
    \mathcal{L}_{NMSE}=(1-p_{clean})\cdot
    \left\|\frac{f_{\boldsymbol{\theta}}(\mathbf{x})}{||f_{\boldsymbol{\theta}}(\mathbf{x})||_{2}}-\frac{f_{\boldsymbol{\theta}}(\mathbf{x}')}{||f_{\boldsymbol{\theta}}(\mathbf{x}')||_{2}}\right\|_2^2,
\end{equation}
where \(\mathbf{x}'\) is the adversarial example, \(f_{\boldsymbol{\theta}}(\mathbf{x})\) is the output logits of the model, and \(||\cdot||_2\) denotes \(l_2\)-norm of vector.

% According to Equation~\ref{Total Loss}, we can replace the loss function in \name framework to get the final training method.

%In this work, 
In summary, the overall loss function in \name framework with NMSE is as follows:
\begin{equation}
    \mathcal{L}= \mathcal{L}_{CE}+ \mu \cdot \mathcal{L}_{NMSE}, 
    \label{Total Loss}
\end{equation}
where \(\mu\) is a hyper-parameter to %control the weight between 
trade off 
the cross-entropy loss \(\mathcal{L}_{CE}\) on adversarial examples and the NMSE regularization term \(\mathcal{L}_{NMSE}\).

