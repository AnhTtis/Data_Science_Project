\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs, array}
\usepackage{multirow}
\usepackage{comment}
\usepackage{color, colortbl}
\usepackage{enumitem}
\usepackage{bbding}
\usepackage{pifont}
\usepackage{caption}
\usepackage{subcaption}\usepackage{wasysym}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\usepackage{bbm}

\setcounter{figure}{1}
\definecolor{LightYellow}{rgb}{1,1,0.7}


\definecolor{gold}{rgb}{1.0, 0.874, 0}
\definecolor{silver}{rgb}{0.77,0.77,0.77}
\definecolor{brown}{rgb}{0.95, 0.678, 0.4}

\newcommand{\gold}[1]{\colorbox{gold}{\textbf{#1}}}
\newcommand{\silver}[1]{\colorbox{silver}{\textbf{#1}}}
\newcommand{\bronze}[1]{\colorbox{brown}{\textbf{#1}}}



\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy 

\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\newcommand{\netname}{DSR-EI}

\begin{document}

\title{Depth Super-Resolution from Explicit and Implicit High-Frequency Features}

\author{Xin Qiao$^{1}$ \hspace{0.5cm} Chenyang Ge$^{1}$ \hspace{0.5cm} Youmin Zhang$^{2}$ \hspace{0.5cm}
Yanhui Zhou$^{1}$ \\  Fabio Tosi$^{2}$ \hspace{0.5cm} Matteo Poggi$^{2}$ \hspace{0.5cm} Stefano Mattoccia$^{2}$ \\ \vspace{-0.3cm} \\
$^{1}$ Xi'an Jiaotong University \hspace{1cm} $^{2}$ University of Bologna \\
}

\twocolumn[{
\renewcommand\twocolumn[1][]{#1}
\maketitle
\begin{center}
    \vspace{-0.5cm}
    \includegraphics[width=0.95\textwidth]{figs/teaser/teaser.pdf} 
    \label{fig:teaser}
\end{center}
\vspace{-0.3cm}
\small \hypertarget{fig:teaser}{Figure 1.} \textbf{Depth Super-Resolution exploiting explicit and implicit high-frequency features.} On the left, an overview of our framework, combining the power of both explicit and implicit high-frequency information extracted from the inputs. On the right, qualitative examples with (a) RGB images, (b) ground truth depth and error maps by existing methods (c -- d) and ours (e).
\vspace{0.5cm}
}]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  figure end
\maketitle

%%%%%%%%% ABSTRACT
\begin{abstract}

We propose a novel multi-stage depth super-resolution network, which progressively reconstructs high-resolution depth maps from explicit and implicit high-frequency features. The former are extracted by an efficient transformer processing both local and global contexts, while the latter are obtained by projecting color images into the frequency domain. Both are combined together with depth features by means of a fusion strategy within a multi-stage and multi-scale framework. Experiments on the main benchmarks, such as NYUv2, Middlebury, DIML and RGBDD, show that our approach outperforms existing methods by a large margin ($\sim20\%$ on NYUv2 and DIML against the contemporary work DADA, with $16\times$ upsampling), establishing a new state-of-the-art in the guided depth super-resolution task.

\end{abstract}


%%%%%%%%% BODY TEXT
\input{1-Introduction}
\input{2-RelatedWork}
\input{3-Approach}
\input{4-Experiments}
\input{5-Conclusion}
\input{6-Acknowledgments}


%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{reference}
}

\end{document}