\section{Related Work}


% \vicki{TODO: check five years influential articles}

% 1. One long paragraph covering how intelligence reports are prepared and how existing AI (can include CV too)/NLP approaches assist them. (We can refer to https://www.sciencedirect.com/science/article/pii/S2667305322000886 for related work) \cite{toniolo2023human} ---> include similar tasks and current status: what tools are used now by analysts 
% 2. Short paragraph detailing what is missing and how  Smartbook tackles that 

Intelligence is more than data aggregation and hypothesis formation.
Automatic tools assist intelligence analysts in data collection~\cite{stottlemyre2015humint, billman2006collaborative,pohl2012automatic}, data inspection and visualization~\cite{prunckun2010handbook},
evidence credibility assessment~\cite{toniolo2014making,barnes2016making}, 
scenario-based question answering~\cite{small-etal-2004-hitiqa-scenario},
hypotheses generation~\cite{heuer1999psychology, cerutti2018cispaces}, 
and quality evaluation~\cite{brody2011automatic}.
However, most current tools still require expensive crowd-sourcing~\cite{van2020improving, xia2019trace} or human-machine collaboration~\cite{pirolli2005sensemaking, pioch2006polestar, toniolo2023human} in report generation. To save human labor, SmartBook aims to provide analysts with an initial draft of the situation report so that they can focus on thinking critically about information and making in-depth assessments. SmartBook contains automatically generated strategic questions for different events, and helps topic discovery from large-scale data by addressing the conundrum of ``you don't know what you don't know''. Analysts can leverage Smartbook to discover new patterns and explore alternative hypotheses with potentially conflicting information.


% Intelligence analysts face a never-ending stream of articles and reports, but intelligence is more than just mining data and documenting events. SmartBook aims to provide analysts with an initial draft of the intelligence report so that they can focus on thinking critically about information and making in-depth assessments. SmartBook contains automatically generated strategic questions for different events, and helps topic discovery from large-sclae data by addressing the conundrum of ``you don't know what you don't know''. Thereby, analysts can leverage Smartbook to discover new patterns and explore alternative hypotheses with potentially conflicting information.




%%%%%%%%%%%%%%%%%%%%%%%%%
% 3. Long paragraph that compares our approach against existing summarization approaches. Current I feel the related work section is just (c), so weâ€™ll need to compress it by 50% maybe and make way for a) and b)  --> all model component comparison?


Summarizing multiple news articles into an situation analysis report falls into the scope of multi-document summarization~\cite{fabbri-etal-2019-multi, abdi2017query, li2014improving, xiong2018multi, abdi2018qmos, abdi2018machine}, which aims to extract critical information across multiple documents with particular guidance, such as sentiments~\citep{abdi2018machine}, queries \citep{abdi2018qmos}, and document structures~\citep{deyoung2021ms2}, into a few-sentence summary~\citep{fabbri-etal-2019-multi}.
In comparison, the guidance in our query-based situation report summarization is the identified and organized event knowledge in real-world scenarios (e.g., COVID and Russia-Ukraine Crisis), and the summary is a comprehensive detailed report supporting deep-dive actions.
Our work is also closely related to knowledge-enhanced summarization, which extracts useful information with prior knowledge, such as sentence similarity~\cite{wan2008exploration}, semantic role \citep{yan2014srrank, khan2015framework, khan2015genetic, alshaina2017multi}, Yago knowledge base~\citep{baralis2013multi}, and dependency parsing~\cite{kurisinkel2017abstractive}.
Nevertheless, the above methods fail to generate situation reports because their outputs are typically short and unable to organize events described in multiple documents, as opposed to our event-organized detailed report generation.




% Multi-document text summarization \cite{fabbri-etal-2019-multi, abdi2017query, li2014improving, xiong2018multi, abdi2018qmos, abdi2018machine} aims to extract critical information across multiple documents. The summarization can have a different emphasis, such as sentiment-oriented \citep{abdi2018machine}, query-based \citep{abdi2018qmos}, or medical-oriented \citep{deyoung2021ms2} summarization. Our focus is situation report generation, which is query-based summarization and aims to extract fact knowledge with comprehensive details that support deep-dive actions (e.g., decision-making). The challenge of our focus is to identify and organize complicated event knowledge in real-world scenarios (e.g., COVID and Russia-Ukraine Crisis), and generate a detailed report rather than just a few-sentence  summary \citep{fabbri-etal-2019-multi}.

% Extract-then-summarize methods query the documents to extract useful information with prior knowledge, such as token positions and keywords, then summarize the retrieved information. Explicit extraction is more common in extractive summarization methods~\cite{DBLP:conf/acl/GuAH22, DBLP:conf/emnlp/JuLKJDP21}, while \cite{DBLP:conf/acl/MaoWN0Z0DZAR22} jointly trains the extractor and the generator and keeps the extracted text snippets latent for abstractive summarization.
% \ken{Since the proposed method adopts an extract-then-summarize pipeline, maybe you should also discuss the related work of extract-then-summarize models?}

% Previous work \citep{wan2008exploration, verma2019mcrmr,yan2014srrank, baralis2013multi, khan2015framework, khan2015genetic, alshaina2017multi, kurisinkel2017abstractive} has explored various kinds of knowledge to help summarization. Wan \cite{wan2008exploration} utilizes structural knowledge by treating each sentence as a node and using similarity-based edges to build graphs to help rank. Verma and Om \cite{verma2019mcrmr} ensemble coverage, non-redundancy, and relevancy features together to boost summarization quality. Semantic roles \citep{yan2014srrank, khan2015framework, khan2015genetic, alshaina2017multi} are also beneficial for multi-document summarization (e.g., removing redundant sentences that have the same semantic meaning \citep{khan2015genetic}). Ontologies such as Yago \citep{suchanek2008yago} have proven to be effective when incorporated into the summarization process \citep{baralis2013multi}. Kurisinkel \cite{kurisinkel2017abstractive} uses partial dependency tree extraction, recombination, and linearization to improve consistency and coherence.

% Nevertheless, the generated summaries of the above methods fail to serve as situation reports as they are typically short (several sentences) and fail to organize numerous and complicated events that are described in multiple documents. To this end, information retrieval for situation reports was first explored by the SIGIR RIA workshop \cite{10.1145/1041394.1041404}. Brody and Kantor \cite{brody2011automatic} revisited the problem by proposing summarization-based metrics for coverage quality to support report ranking. Our methods first use information retrieval (IR) to collect documents, then use information extraction and question-answering techniques to address problems in situation reports.

% \Yi{Should we add \cite{10.1145/1041394.1041404} and \cite{brody2011automatic} into related work?} \ziqi{Done}
% Information retrieval for intelligence reports was first explored by the SIGIR RIA workshop \cite{10.1145/1041394.1041404}. The common approach is first to conduct information extraction (IE) on collected data and then use NLP techniques to generate natural language sentences.


% Brody and Kantor \cite{brody2011automatic} revisited the problem by proposing summarization-based metrics for coverage quality to support report ranking. The traditional way is to use rule-based methods \cite{}.

% The common approach is first to conduct information extraction (IE) \cite{} on collected data and then use NLP techniques, such as topic modeling and summarization, to generate natural language sentences.
