\begin{abstract}
Timely and comprehensive understanding of emerging events is crucial for effective decision-making; automating situation report generation can significantly reduce the time, effort, and cost for intelligence analysts. In this work, we identify intelligence analysts' practices and preferences for AI assistance in situation report generation to guide the design strategies for an effective, trust-building interface that aligns with their thought processes and needs. Next, we introduce \name{}, an automated framework designed to generate situation reports from large volumes of news data, creating structured reports by automatically discovering event-related strategic questions. These reports include multiple hypotheses (claims), summarized and grounded to sources with factual evidence, to promote in-depth situation understanding.
Our comprehensive evaluation of \name{}, encompassing a user study alongside a content review with an editing study, reveals \name{}'s effectiveness in generating accurate and relevant situation reports. Qualitative evaluations indicate over 80\% of questions probe for strategic information, and over 90\% of summaries produce tactically useful content, being consistently favored over summaries from a large language model integrated with web search. The editing study reveals that minimal information is removed from the generated text (under 2.5\%), suggesting that \name{} provides analysts with a valuable foundation for situation reports.

\end{abstract}

 %\footnote{We mourn the loss of our project contributor, Paul, who passed away before this paper's publication. His contributions were invaluable, and we honor his memory and dedication to the pursuit of knowledge.}