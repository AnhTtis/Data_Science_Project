\begin{table}
\centering
\begin{tabular}{lcccc}
\hline
\textit{Summary-Type} & \textit{Background} &  \textit{Coherence} & \textit{Relevance}  &\textit{Usefulness} \\
\hline
% (1) Query-Focused & News & 87.90& 76.93& 75.47\\
% (2) Web Search + LLM & Web &88.80 & 81.33& 76.53\\
% (3) SmartBook & News & \textbf{91.20} & \textbf{84.67} & \textbf{83.47}\\

(1) Query-Focused & News & 4.39& 3.85& 3.77\\
(2) Web Search + LLM & Web &4.44 & 4.07& 3.83\\
(3) SmartBook & News & \textbf{4.56} & \textbf{4.23} & \textbf{4.17}\\


\hline
\end{tabular}
\caption{Results of human evaluation comparing the summaries within SmartBook (3) against those either generated directly from news articles via query-focused summarization (1) or obtained from the internet by web search combined with generation from a large language model (2). Results are on a 1-5 scale (worst to best). 50 summaries were evaluated with a text evaluator coverage of 3.}
\label{tab:sum_human}
\vspace{-2em}
\end{table}

