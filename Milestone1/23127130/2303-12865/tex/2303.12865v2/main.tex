\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{wrapfig}


\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi


\begin{document}

%%%%%%%%% TITLE
% \title{Learning Efficient and 3D-Consistent NeRF-free generation by  Distillation}
\title{NeRF-GAN Distillation for Memory-Efficient 3D-Aware Generation with Convolutions}
% \title{Distilling NeRF-GANs into Convolutional Networks for Efficient 3D-Consistent Generation}
% \title{Elevating Convolutional GANs by NeRF-GAN Distillation for Efficient 3D-aware Generation}

\author{
Mohamad Shahbazi\textsuperscript{\rm 1} \and Evangelos Ntavelis\textsuperscript{\rm 1,3} \and Alessio Tonioni\textsuperscript{\rm 2} \and Edo Collins\textsuperscript{\rm 2} \and Danda Pani Paudel\textsuperscript{\rm 1} \and Martin Danelljan\textsuperscript{\rm 1} \and  Luc Van Gool\textsuperscript{\rm 1} \and \\
\textsuperscript{\rm 1}Computer Vision Lab, ETH Z\"urich\quad\textsuperscript{\rm 2}Google Z\"urich\quad\textsuperscript{\rm 3}ML \& Robotics, CSEM, Switzerland \\
\tt\small{\{mshahbazi, entavelis, paudel, martin.danelljan, vangool\}@vision.ee.ethz.ch}, \and \tt\small{\{alessiot, edocollins\}@google.com}
}
\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi


%%%%%%%%% ABSTRACT
\begin{abstract}
Pose-conditioned convolutional generative models struggle with high-quality 3D-consistent image generation from single-view datasets, due to their lack of sufficient 3D priors. Recently, the integration of Neural Radiance Fields (NeRFs) and generative models, such as Generative Adversarial Networks (GANs), has transformed 3D-aware generation from single-view images. NeRF-GANs exploit the strong inductive bias of 3D neural representations and volumetric rendering at the cost of higher computational complexity. This study aims at revisiting pose-conditioned 2D GANs for memory-efficient 3D-aware generation at inference time by distilling 3D knowledge from pretrained NeRF-GANS. We propose a simple and effective method, based on re-using the well-disentangled latent space of a pre-trained NeRF-GAN in a pose-conditioned convolutional network to directly generate 3D-consistent images corresponding to the underlying 3D representations. Experiments on several datasets demonstrate that the proposed method obtains results comparable with volumetric rendering in terms of quality and 3D consistency while benefiting from the superior computational advantage of convolutional networks. The code will be available at: \url{https://github.com/mshahbazi72/NeRF-GAN-Distillation}
\end{abstract}

%%%%%%%%% BODY TEXT
\input{1_introduction}
\input{2_related}
\input{3_method}
\input{4_experiments}
\input{5_conclusion}

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\input{6_supp}

\end{document}