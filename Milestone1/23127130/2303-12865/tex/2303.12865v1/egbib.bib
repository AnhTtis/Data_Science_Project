%Famous GANs
@inproceedings{goodfellow2014gans,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2672--2680},
  year={2014}
}

@inproceedings{karras2018progressive,
  title     = {Progressive Growing of {GAN}s for Improved Quality, Stability, and Variation},
  author    = {Tero Karras and Timo Aila and Samuli Laine and Jaakko Lehtinen},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  year      = {2018}
}

@inproceedings{choi2020starganv2,
  title={StarGAN v2: Diverse Image Synthesis for Multiple Domains},
  author={Yunjey Choi and Youngjung Uh and Jaejun Yoo and Jung-Woo Ha},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2020}
}


@InProceedings{Sauer2021ARXIV,
  author    = {Axel Sauer and Katja Schwarz and Andreas Geiger},
  title     = {StyleGAN-XL: Scaling StyleGAN to Large Diverse Datasets},
  journal   = {arXiv.org},
  volume    = {abs/2201.00273},
  year      = {2022},
  url       = {https://arxiv.org/abs/2201.00273},
}

@inproceedings{Sauer2021ProjectedGC,
  title={Projected GANs Converge Faster},
  author={Axel Sauer and Kashyap Chitta and Jens Muller and Andreas Geiger},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{Karrasstyle,
author = {Karras, Tero and Laine, Samuli and Aila, Timo},
year = {2019},
month = {06},
pages = {4396-4405},
title = {A Style-Based Generator Architecture for Generative Adversarial Networks},
doi = {10.1109/CVPR.2019.00453}
}

@article{mirza2014conditional,
  title={Conditional Generative Adversarial Nets},
  author={Mirza, Mehdi and Osindero, Simon},
  journal={arXiv preprint arXiv:1411.1784},
  year={2014}
}


@inproceedings{yu2018generative,
  title={Generative image inpainting with contextual attention},
  author={Yu, Jiahui and Lin, Zhe and Yang, Jimei and Shen, Xiaohui and Lu, Xin and Huang, Thomas S},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5505--5514},
  year={2018}
}

@misc{jahanian2020steerability,
      title={On the "steerability" of generative adversarial networks}, 
      author={Ali Jahanian and Lucy Chai and Phillip Isola},
      year={2020},
      eprint={1907.07171},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{zhu2017unpaired,
  title={Unpaired image-to-image translation using cycle-consistent adversarial networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2223--2232},
  year={2017}
}


@inproceedings{xu2018attngan,
  title={Attngan: Fine-grained text to image generation with attentional generative adversarial networks},
  author={Xu, Tao and Zhang, Pengchuan and Huang, Qiuyuan and Zhang, Han and Gan, Zhe and Huang, Xiaolei and He, Xiaodong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1316--1324},
  year={2018}
}




@inproceedings{odena2017acgan,
  title={Conditional Image Synthesis with Auxiliary Classifier GANs},
  author={Odena, Augustus and Olah, Christopher and Shlens, Jonathon},
  booktitle={International conference on machine learning},
  pages={2642--2651},
  year={2017},
}



@inproceedings{gupta2019lvis,
  title={LVIS: A dataset for large vocabulary instance segmentation},
  author={Gupta, Agrim and Dollar, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5356--5364},
  year={2019}
}





@inproceedings{
miyato2018cgans,
title={c{GAN}s with Projection Discriminator},
author={Miyato, Takeru and Koyama, Masanori},
booktitle={International Conference on Learning Representations},
year={2018},
}

@inproceedings{park2019SPADE,
  title     = {Semantic Image Synthesis with Spatially-Adaptive Normalization},
  author    = {Park, Taesung and Liu, Ming-Yu and Wang, Ting-Chun and Zhu, Jun-Yan},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2019}
}

@inproceedings{zhang2019sagan,
  title={Self-attention generative adversarial networks},
  author={Zhang, Han and Goodfellow, Ian and Metaxas, Dimitris and Odena, Augustus},
  booktitle={International conference on machine learning},
  pages={7354--7363},
  year={2019},
  organization={PMLR}
}

@article{brock2018large,
  title={Large scale gan training for high fidelity natural image synthesis},
  author={Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
  journal={arXiv preprint arXiv:1809.11096},
  year={2018}
}

@inproceedings{karras2019style,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4401--4410},
  year={2019}
}

@inproceedings{Karras2019stylegan2,
  title     = {Analyzing and Improving the Image Quality of {StyleGAN}},
  author    = {Tero Karras and Samuli Laine and Miika Aittala and Janne Hellsten and Jaakko Lehtinen and Timo Aila},
  booktitle = {Proc. CVPR},
  year      = {2020}
}

@inproceedings{Karras2020ada,
  title     = {Training Generative Adversarial Networks with Limited Data},
  author    = {Karras, Tero and Aittala, Miika and Hellsten, Janne and Laine, Samuli and Lehtinen, Jaakko and Aila, Timo},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2020}
}

@article{karras2021alias,
  title={Alias-free generative adversarial networks},
  author={Karras, Tero and Aittala, Miika and Laine, Samuli and H{\"a}rk{\"o}nen, Erik and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={852--863},
  year={2021}
}

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{kang2020ContraGAN,
  title   = {{ContraGAN: Contrastive Learning for Conditional Image Generation}},
  author  = {Minguk Kang and Jaesik Park},
  booktitle = {Conference on Neural Information Processing Systems (NeurIPS)},
  year    = {2020}
}

@article{pix2pix2017,
  title={Image-to-Image Translation with Conditional Adversarial Networks},
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  journal={CVPR},
  year={2017}
}

% Datasets
@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009}
}

@inproceedings{liu2019few,
  title={Few-Shot Unsupervised Image-to-Image Translation},
  author={Ming-Yu Liu and Xun Huang and Arun Mallya and Tero Karras and Timo Aila and Jaakko Lehtinen and Jan Kautz},
  booktitle={IEEE International Conference on Computer Vision (ICCV)},
  year={2019}
}

@article{Zhangzhang2011animal,
  title={Learning Hybrid Image Templates (HIT) by Information Projection},
  author={Si, Zhangzhang and Zhu, Song-Chun},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={34},
  number={7},
  pages={1354--1367},
  year={2011},
  publisher={IEEE}
}

@techreport{WahCUB_200_2011,
	Title = {The Caltech-UCSD Birds-200-2011 Dataset},
	Author = {Wah, C. and Branson, S. and Welinder, P. and Perona, P. and Belongie, S.},
	Year = {2011},
	Institution = {California Institute of Technology},
	Number = {CNS-TR-2011-001}
}

@inproceedings{bossard14,
  title = {Food-101 -- Mining Discriminative Components with Random Forests},
  author = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
  booktitle = {European Conference on Computer Vision},
  year = {2014}
}

@article{krizhevsky2009cifar,
  title={Learning Multiple Layers of Features from Tiny Images},
  author={Krizhevsky, Alex},
  journal={Tech Report},
  year={2009},
}

%Method
@inproceedings{salimans2016improved,
  title={Improved Techniques for Training GANs},
  author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford Alec and Chen Xi},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@inproceedings{
zhou2018activation,
title={Activation Maximization Generative Adversarial Nets},
author={Zhiming Zhou and Han Cai and Shu Rong and Yuxuan Song and Kan Ren and Weinan Zhang and Jun Wang and Yong Yu},
booktitle={International Conference on Learning Representations},
year={2018},
}


@InProceedings{kavalerov20a,
  title = {A study of quality and diversity in {K+1} {GANs}},
  author = {Kavalerov, Ilya and Czaja, Wojciech and Chellappa, Rama},
  booktitle = {Proceedings on "I Can't Believe It's Not Better!" at NeurIPS Workshops},
  year={2020}
}

%Related work
@inproceedings{
lee2018harmonizing,
title={Harmonizing Maximum Likelihood with {GAN}s for Multimodal Conditional Generation},
author={Soochan Lee and Junsoo Ha and Gunhee Kim},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HJxyAjRcFX},
}

@inproceedings{sameera2021rethinking,
  title={Rethinking conditional GAN training: An approach using geometrically structured latent manifolds},
  author={Ramasinghe, Sameera and Farazi, Moshiur and Khan, Salman and  Barnes, Nick and Gould, Stephen},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{lugmayr2020srflow,
  title={SRFlow: Learning the Super-Resolution Space with Normalizing Flow},
  author={Lugmayr, Andreas and Danelljan, Martin and Van Gool, Luc and Timofte, Radu},
  booktitle={ECCV},
  year={2020}
}

@InProceedings{Lugmayr_2022_WACV,
    author    = {Lugmayr, Andreas and Danelljan, Martin and Yu, Fisher and Van Gool, Luc and Timofte, Radu},
    title     = {Normalizing Flow as a Flexible Fidelity Objective for Photo-Realistic Super-Resolution},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month     = {January},
    year      = {2022},
    pages     = {1756-1765}
}

@inproceedings{shahbazi2021cGANTransfer,
  title={Efficient Conditional GAN Transfer with Knowledge Propagation across Classes},
  author={Shahbazi, Mohamad and Huang, Zhiwu and Paudel, Danda Pani and Chhatkuli Ajad and Van Gool, Luc},
  booktitle={IEEE conference on computer vision and pattern recognition},
  year={2021}
}

@inproceedings{wang2018transferring,
  title={Transferring GANs: generating images from limited data},
  author={Wang, Yaxing and Wu, Chenshen and Herranz, Luis and van de Weijer, Joost and Gonzalez-Garcia, Abel and Raducanu, Bogdan},
  booktitle={Proceedings of the European Conference on Computer Vision},
  pages={218--234},
  year={2018}
}

@article{mo2020freeze,
  title={Freeze Discriminator: A Simple Baseline for Fine-tuning GANs},
  author={Mo, Sangwoo and Cho, Minsu and Shin, Jinwoo},
  journal={arXiv preprint arXiv:2002.10964},
  year={2020}
}

@inproceedings{wang2020minegan,
  title={MineGAN: effective knowledge transfer from GANs to target domains with few images},
  author={Wang, Yaxing and Gonzalez-Garcia, Abel and Berga, David and Herranz, Luis and Khan, Fahad Shahbaz and Weijer, Joost van de},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9332--9341},
  year={2020}
}

@article{zhao2020leveraging,
  title={On Leveraging Pretrained GANs for Limited-Data Generation},
  author={Zhao, Miaoyun and Cong, Yulai and Carin, Lawrence},
  journal={arXiv preprint arXiv:2002.11810},
  year={2020}
}

@inproceedings{noguchi2019image,
  title={Image generation from small datasets via batch statistics adaptation},
  author={Noguchi, Atsuhiro and Harada, Tatsuya},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2750--2758},
  year={2019}
}

@inproceedings{zhao2020differentiable,
  title={Differentiable augmentation for data-efficient gan training},
  author={Zhao, Shengyu and Liu, Zhijian and Lin, Ji and Zhu, Jun-Yan and Han, Song},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{
    liu2021towards,
    title={Towards Faster and Stabilized {\{}GAN{\}} Training for High-fidelity Few-shot Image Synthesis},
    author={Liu, Bingchen and Zhu, Yizhe and Song, Kunpeng and Elgammal, Ahmed},
    booktitle={Submitted to International Conference on Learning Representations},
    year={2021},
}

@inproceedings{lecamgan,
  author = {Tseng, Hung-Yu and Jiang, Lu and Liu, Ce and Yang, Ming-Hsuan and Yang, Weilong},
  title = {Regularing Generative Adversarial Networks under Limited Data},
  booktitle = {CVPR},
  year = {2021}
}

% Metrics
@article{Kynkaanniemi2019,
  author    = {Tuomas Kynkäänniemi and Tero Karras
               and Samuli Laine and Jaakko Lehtinen
               and Timo Aila},
  title     = {Improved Precision and Recall Metric for Assessing Generative Models},
  journal   = {CoRR},
  volume    = {abs/1904.06991},
  year      = {2019},
}

@inproceedings{heusel2017fid,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6626--6637},
  year={2017}
}

@inproceedings{
binkowski2018kid,
title={Demystifying {MMD} {GAN}s},
author={Mikołaj Bińkowski and Danica J. Sutherland and Michael Arbel and Arthur Gretton},
booktitle={International Conference on Learning Representations},
year={2018},
}

%controllable 2D GANs
@inproceedings{shen2020interpreting,
  title     = {Interpreting the Latent Space of GANs for Semantic Face Editing},
  author    = {Shen, Yujun and Gu, Jinjin and Tang, Xiaoou and Zhou, Bolei},
  booktitle = {CVPR},
  year      = {2020}
}

% 3d generation
@inproceedings{Liao2020CVPR,
  title = {Towards Unsupervised Learning of Generative Models for 3D Controllable Image Synthesis},
  author = {Liao, Yiyi and Schwarz, Katja and Mescheder, Lars and Geiger, Andreas},
  booktitle = { Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
  year = {2020}
}

@inproceedings{chan2021pi,
  title={pi-gan: Periodic implicit generative adversarial networks for 3d-aware image synthesis},
  author={Chan, Eric R and Monteiro, Marco and Kellnhofer, Petr and Wu, Jiajun and Wetzstein, Gordon},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5799--5809},
  year={2021}
}

@inproceedings{chan2022efficient,
  title={Efficient geometry-aware 3D generative adversarial networks},
  author={Chan, Eric R and Lin, Connor Z and Chan, Matthew A and Nagano, Koki and Pan, Boxiao and De Mello, Shalini and Gallo, Orazio and Guibas, Leonidas J and Tremblay, Jonathan and Khamis, Sameh and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16123--16133},
  year={2022}
}
          
@InProceedings{orel2022styleSDF,
    title     = {Style{SDF}: {H}igh-{R}esolution {3D}-{C}onsistent {I}mage and {G}eometry {G}eneration},
    author    = {Or-El, Roy and 
    		 Luo, Xuan and 
		 Shan, Mengyi and 
		 Shechtman, Eli and 
		 Park, Jeong Joon and 
		 Kemelmacher-Shlizerman, Ira}, 
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {13503-13513}
}

@inproceedings{gu2021stylenerf,
  title={StyleNeRF: A Style-based 3D Aware Generator for High-resolution Image Synthesis},
  author={Gu, Jiatao and Liu, Lingjie and Wang, Peng and Theobalt, Christian},
  booktitle={International Conference on Learning Representations},
  year={2022}
}  

@article{epigraf,
    title={EpiGRAF: Rethinking training of 3D GANs},
    author={Skorokhodov, Ivan and Tulyakov, Sergey and Wang, Yiqun and Wonka, Peter},
    journal={arXiv preprint arXiv:2206.10535},
    year={2022},
}

@inproceedings{Schwarz2020NEURIPS,
  title = {GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis},
  author = {Schwarz, Katja and Liao, Yiyi and Niemeyer, Michael and Geiger, Andreas},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2020}
}

@inproceedings{niemeyer2021giraffe,
  title={Giraffe: Representing scenes as compositional generative neural feature fields},
  author={Niemeyer, Michael and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11453--11464},
  year={2021}
}

@InProceedings{Shi_2021_CVPR,
    author    = {Shi, Yichun and Aggarwal, Divyansh and Jain, Anil K.},
    title     = {Lifting 2D StyleGAN for 3D-Aware Face Generation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {6258-6266}
}

@inproceedings{kwak2022injecting,
  title={Injecting 3D Perception of Controllable NeRF-GAN into StyleGAN for Editable Portrait Image Synthesis},
  author={Kwak, Jeong-gi and Li, Yuanming and Yoon, Dongsik and Kim, Donghyeon and Han, David and Ko, Hanseok},
  booktitle={European Conference on Computer Vision},
  pages={236--253},
  year={2022},
  organization={Springer}
}

@article{chen2016infogan,
  title={Infogan: Interpretable representation learning by information maximizing generative adversarial nets},
  author={Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{harkonen2020ganspace,
  title={Ganspace: Discovering interpretable gan controls},
  author={H{\"a}rk{\"o}nen, Erik and Hertzmann, Aaron and Lehtinen, Jaakko and Paris, Sylvain},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9841--9850},
  year={2020}
}

@inproceedings{shen2021closed,
  title={Closed-form factorization of latent semantics in gans},
  author={Shen, Yujun and Zhou, Bolei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1532--1540},
  year={2021}
}

@inproceedings{yuksel2021latentclr,
  title={Latentclr: A contrastive learning approach for unsupervised discovery of interpretable directions},
  author={Y{\"u}ksel, O{\u{g}}uz Kaan and Simsar, Enis and Er, Ezgi G{\"u}lperi and Yanardag, Pinar},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={14263--14272},
  year={2021}
}
%NeRFs

@inproceedings{mildenhall2020nerf,
 title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
 author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
 year={2020},
 booktitle={ECCV},
}

@InProceedings{Riser_2021_ICCV,
    author    = {Reiser, Christian and Peng, Songyou and Liao, Yiyi and Geiger, Andreas},
    title     = {KiloNeRF: Speeding Up Neural Radiance Fields With Thousands of Tiny MLPs},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {14335-14345}
}

@article{chen2022tensorf,
  title={TensoRF: Tensorial Radiance Fields},
  author={Chen, Anpei and Xu, Zexiang and Geiger, Andreas and Yu, Jingyi and Su, Hao},
  journal={arXiv preprint arXiv:2203.09517},
  year={2022}
}

@article{muller2022instant,
  title={Instant neural graphics primitives with a multiresolution hash encoding},
  author={M{\"u}ller, Thomas and Evans, Alex and Schied, Christoph and Keller, Alexander},
  journal={arXiv preprint arXiv:2201.05989},
  year={2022}
}
@inproceedings{sun2022direct,
  title={Direct voxel grid optimization: Super-fast convergence for radiance fields reconstruction},
  author={Sun, Cheng and Sun, Min and Chen, Hwann-Tzong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5459--5469},
  year={2022}
}
@inproceedings{kurz2022adanerf,
  title={AdaNeRF: Adaptive Sampling for Real-Time Rendering of Neural Radiance Fields},
  author={Kurz, Andreas and Neff, Thomas and Lv, Zhaoyang and Zollh{\"o}fer, Michael and Steinberger, Markus},
  booktitle={European Conference on Computer Vision},
  pages={254--270},
  year={2022},
  organization={Springer}
}

@inproceedings{choi2020stargan,
  title={Stargan v2: Diverse image synthesis for multiple domains},
  author={Choi, Yunjey and Uh, Youngjung and Yoo, Jaejun and Ha, Jung-Woo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8188--8197},
  year={2020}
}

@article{chang2015shapenet,
  title={Shapenet: An information-rich 3d model repository},
  author={Chang, Angel X and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and others},
  journal={arXiv preprint arXiv:1512.03012},
  year={2015}
}

@InProceedings{richardson2021encoding,
      author = {Richardson, Elad and Alaluf, Yuval and Patashnik, Or and Nitzan, Yotam and Azar, Yaniv and Shapiro, Stav and Cohen-Or, Daniel},
      title = {Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation},
      booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
      month = {June},
      year = {2021}
}
@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}
@inproceedings{deng2018arcface,
title={ArcFace: Additive Angular Margin Loss for Deep Face Recognition},
author={Deng, Jiankang and Guo, Jia and Niannan, Xue and Zafeiriou, Stefanos},
booktitle={CVPR},
year={2019}
}


@article{styleflow,
author = {Abdal, Rameen and Zhu, Peihao and Mitra, Niloy J. and Wonka, Peter},
title = {StyleFlow: Attribute-Conditioned Exploration of StyleGAN-Generated Images Using Conditional Continuous Normalizing Flows},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/3447648},
doi = {10.1145/3447648},
journal = {ACM Trans. Graph.},
month = may,
articleno = {21},
numpages = {21},
keywords = {image editing, Generative adversarial networks}
}

@inproceedings{styleEMB_neurips2021,
 author = {Nie, Weili and Vahdat, Arash and Anandkumar, Anima},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {13497--13510},
 publisher = {Curran Associates, Inc.},
 title = {Controllable and Compositional Generation with Latent-Space Energy-Based Models},
 url = {https://proceedings.neurips.cc/paper/2021/file/701d804549a4a23d3cae801dac6c2c75-Paper.pdf},
 volume = {34},
 year = {2021}
}

@article{mipnerf,
   title={Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields},
   url={http://dx.doi.org/10.1109/ICCV48922.2021.00580},
   DOI={10.1109/iccv48922.2021.00580},
   journal={2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
   publisher={IEEE},
   author={Barron, Jonathan T. and Mildenhall, Ben and Tancik, Matthew and Hedman, Peter and Martin-Brualla, Ricardo and Srinivasan, Pratul P.},
   year={2021},
   month={Oct} }

@article{nerftex,
author = {Baatz, H. and Granskog, J. and Papas, M. and Rousselle, F. and Novák, J.},
title = {NeRF-Tex: Neural Reflectance Field Textures},
journal = {Computer Graphics Forum},
volume = {41},
number = {6},
pages = {287-301},
keywords = {ray tracing, rendering, appearance modeling, modelling, reflectance & shading models},
doi = {https://doi.org/10.1111/cgf.14449},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14449},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14449},
abstract = {Abstract We investigate the use of neural fields for modelling diverse mesoscale structures, such as fur, fabric and grass. Instead of using classical graphics primitives to model the structure, we propose to employ a versatile volumetric primitive represented by a neural reflectance field (NeRF-Tex), which jointly models the geometry of the material and its response to lighting. The NeRF-Tex primitive can be instantiated over a base mesh to ‘texture’ it with the desired meso and microscale appearance. We condition the reflectance field on user-defined parameters that control the appearance. A single NeRF texture thus captures an entire space of reflectance fields rather than one specific structure. This increases the gamut of appearances that can be modelled and provides a solution for combating repetitive texturing artifacts. We also demonstrate that NeRF textures naturally facilitate continuous level-of-detail rendering. Our approach unites the versatility and modelling power of neural networks with the artistic control needed for precise modelling of virtual scenes. While all our training data are currently synthetic, our work provides a recipe that can be further extended to extract complex, hard-to-model appearances from real images.},
year = {2022}
}

@misc{nerfinthewild,
  doi = {10.48550/ARXIV.2008.02268},
  url = {https://arxiv.org/abs/2008.02268},
  author = {Martin-Brualla, Ricardo and Radwan, Noha and Sajjadi, Mehdi S. M. and Barron, Jonathan T. and Dosovitskiy, Alexey and Duckworth, Daniel},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{wu2021diver,
      title={DIVeR: Real-time and Accurate Neural Radiance Fields with Deterministic Integration for Volume Rendering}, 
      author={Liwen Wu and Jae Yong Lee and Anand Bhattad and Yuxiong Wang and David Forsyth},
      year={2021},
      eprint={2111.10427},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@InProceedings{nerfren,
      author    = {Guo, Yuan-Chen and Kang, Di and Bao, Linchao and He, Yu and Zhang, Song-Hai},
      title     = {NeRFReN: Neural Radiance Fields With Reflections},
      booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
      month     = {June},
      year      = {2022},
      pages     = {18409-18418}
}

@article{roich2022pivotal,
  title={Pivotal tuning for latent-based editing of real images},
  author={Roich, Daniel and Mokady, Ron and Bermano, Amit H and Cohen-Or, Daniel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={42},
  number={1},
  pages={1--13},
  year={2022},
  publisher={ACM New York, NY}
}

@article{schwarz2022voxgraf,
  title={Voxgraf: Fast 3d-aware image synthesis with sparse voxel grids},
  author={Schwarz, Katja and Sauer, Axel and Niemeyer, Michael and Liao, Yiyi and Geiger, Andreas},
  journal={arXiv preprint arXiv:2206.07695},
  year={2022}
}

@inproceedings{HoloGAN2019,
  title={ HoloGAN: Unsupervised Learning of 3D Representations From Natural Images  },
  author={Nguyen-Phuoc, Thu and Li, Chuan and Theis, Lucas and Richardt, Christian and Yang, Yong-Liang},
  booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
 month = {Nov},
 year = {2019} 
}

@inproceedings{rigstyle,
author = {Tewari, Ayush and Elgharib, Mohamed and Bharaj, Gaurav and Bernard, Florian and Seidel, Hans-Peter and Perez, Patrick and Zollhofer, Michael and Theobalt, Christian},
year = {2020},
month = {06},
pages = {6141-6150},
title = {StyleRig: Rigging StyleGAN for 3D Control Over Portrait Images},
doi = {10.1109/CVPR42600.2020.00618}
}

@inproceedings{KowalskiECCV2020Config,
    author = {Kowalski, Marek and Garbin, Stephan J. and Estellers, Virginia and Baltrušaitis, Tadas and Johnson, Matthew and Shotton, Jamie},
    title = {CONFIG: Controllable Neural Face Image Generation},
    booktitle = {European Conference on Computer Vision (ECCV)},
    year = {2020}
}

@inproceedings{deng2020disco,
	title={Disentangled and Controllable Face Image Generation via 3D Imitative-Contrastive Learning},
	author={Yu Deng and Jiaolong Yang and Dong Chen and Fang Wen and Xin Tong},
    booktitle={IEEE Computer Vision and Pattern Recognition},
    year={2020}
}

@inproceedings{BlockGAN2020,
  title={ BlockGAN: Learning 3D Object-aware Scene Representations from Unlabelled Images  },
  author={Nguyen-Phuoc, Thu and Richardt, Christian and Mai, Long and Yang, Yong-Liang and Mitra, Niloy},
  booktitle =  {Advances in Neural Information Processing Systems 33},
 month = {Nov},
 year = {2020}
}

@inproceedings{pan2020gan2shape,
  title   = {Do 2D GANs Know 3D Shape? Unsupervised 3D Shape Reconstruction from 2D Image GANs},
  author  =  {Pan, Xingang and Dai, Bo and Liu, Ziwei and Loy, Chen Change and Luo, Ping},
  booktitle = {International Conference on Learning Representations},
  year    = {2021}
}

@inproceedings{liftgan,
author = {Shi, Yichun and Aggarwal, Divyansh and Jain, Anil},
year = {2021},
month = {06},
pages = {6254-6262},
title = {Lifting 2D StyleGAN for 3D-Aware Face Generation},
doi = {10.1109/CVPR46437.2021.00619}
}

@InProceedings{Hu_2022_CVPR,
    author    = {Hu, Tao and Liu, Shu and Chen, Yilun and Shen, Tiancheng and Jia, Jiaya},
    title     = {EfficientNeRF  Efficient Neural Radiance Fields},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {12902-12911}
}

@inproceedings{yu2021plenoctrees,
      title={{PlenOctrees} for Real-time Rendering of Neural Radiance Fields},
      author={Alex Yu and Ruilong Li and Matthew Tancik and Hao Li and Ren Ng and Angjoo Kanazawa},
      year={2021},
      booktitle={ICCV},
}

@article{Garbin21arxiv_FastNeRF,
	Archiveprefix = {arXiv},
	Author = {Stephan J. Garbin and Marek Kowalski and Matthew Johnson and Jamie Shotton and Julien Valentin},
        booktitle={ICCV},
	Title = {FastNeRF: High-Fidelity Neural Rendering at 200FPS},
	Year = {2021}
}

@article {neff2021donerf,
  journal = {Computer Graphics Forum},
  title = {{DONeRF: Towards Real-Time Rendering of Compact Neural Radiance Fields using Depth Oracle Networks}},
  author = {Neff, Thomas and Stadlbauer, Pascal and Parger, Mathias and Kurz, Andreas and Mueller, Joerg H. and Chaitanya, Chakravarty R. Alla and Kaplanyan, Anton S. and Steinberger, Markus},
  year = {2021},
  publisher = {The Eurographics Association and John Wiley & Sons Ltd.},
  ISSN = {1467-8659},
  DOI = {10.1111/cgf.14340},
  url = {https://doi.org/10.1111/cgf.14340},
  volume = {40},
  number = {4},
}

@article{hedman2021snerg,
    title={Baking Neural Radiance Fields for
           Real-Time View Synthesis},
    author={Peter Hedman and Pratul P. Srinivasan and
            Ben Mildenhall and Jonathan T. Barron and
            Paul Debevec},
    journal={ICCV},
    year={2021}
}

@article{hu2018rotation,
    Author    = {Yibo Hu and Xiang Wu and Bing Yu and Ran He and Zhenan Sun},
    Title     = {Pose-guided photorealistic face rotation},
    Journal   = {CVPR},
    Year      = {2018}}

@inproceedings{
pan2021do,
title={Do 2D {\{}GAN{\}}s Know 3D Shape? Unsupervised 3D Shape Reconstruction from 2D Image {\{}GAN{\}}s},
author={Xingang Pan and Bo Dai and Ziwei Liu and Chen Change Loy and Ping Luo},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=FGqiDsBUKL0}
}

@InProceedings{Shoshan_2021_gancontrol,
    author    = {Shoshan, Alon and Bhonker, Nadav and Kviatkovsky, Igor and Medioni, G\'erard},
    title     = {GAN-Control: Explicitly Controllable GANs},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {14083-14093}
}

@inproceedings{gmpi2022,
            title = {Generative Multiplane Images: Making a 2D GAN 3D-Aware},
            author = {Xiaoming Zhao
                and Fangchang Ma
                and David Güera
                and Zhile Ren
                and Alexander G. Schwing
                and Alex Colburn},
            booktitle = {Proc. ECCV},
            year = {2022},
}

@article{mueller2022instant,
    author = {Thomas M\"uller and Alex Evans and Christoph Schied and Alexander Keller},
    title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding},
    journal = {ACM Trans. Graph.},
    issue_date = {July 2022},
    volume = {41},
    number = {4},
    month = jul,
    year = {2022},
    pages = {102:1--102:15},
    articleno = {102},
    numpages = {15},
    url = {https://doi.org/10.1145/3528223.3530127},
    doi = {10.1145/3528223.3530127},
    publisher = {ACM},
    address = {New York, NY, USA},
}

@inproceedings{TensoRF,
  author = {Anpei Chen and Zexiang Xu and Andreas Geiger and Jingyi Yu and Hao Su},
  title = {TensoRF: Tensorial Radiance Fields},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year = {2022}
}

@inproceedings{Wizadwongsa2021NeX,
    author = {Wizadwongsa, Suttisak and Phongthawee, Pakkapon and Yenphraphai, Jiraphon and Suwajanakorn, Supasorn},
    title = {NeX: Real-time View Synthesis with Neural Basis Expansion},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
    year = {2021},
}

@inproceedings{plenoxels,
      title={Plenoxels: Radiance Fields without Neural Networks},
      author={{Sara Fridovich-Keil and Alex Yu} and Matthew Tancik and Qinhong Chen and Benjamin Recht and Angjoo Kanazawa},
      year={2022},
      booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
}

@InProceedings{single_view_mpi,
  author = {Tucker, Richard and Snavely, Noah},
  title = {Single-view View Synthesis with Multiplane Images},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2020}
}

@inproceedings{deng2019accurate,
    title={Accurate 3D Face Reconstruction with Weakly-Supervised Learning: From Single Image to Image Set},
    author={Yu Deng and Jiaolong Yang and Sicheng Xu and Dong Chen and Yunde Jia and Xin Tong},
    booktitle={IEEE Computer Vision and Pattern Recognition Workshops},
    year={2019}
}


@misc{inversion,
  title={EG3D Inversion Projector},
  howpublished={\url{https://github.com/oneThousand1000/EG3D-projector}}
}