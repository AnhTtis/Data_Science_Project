\vspace{-1mm}\section{Chordal Centroids on Flag Manifolds}\vspace{-1mm}\label{sec:method}
We begin by providing the necessary definitions related to flag manifolds before presenting our chordal flag-mean and -median algorithms. 




\begin{dfn}[Matrix groups] The \textbf{orthogonal group} $O(d)$ denotes the group of distance-preserving transformations of a Euclidean space of dimension $d$. $SO(d)$ is the \textbf{special orthogonal group} containing matrices in $O(d)$ determinant $1$. The \textbf{Stiefel manifold} $St(k,d)$, a.k.a. the set of all orthonormal $k$-frames in $\R^d$, can be represented as the quotient group: $St(k,d) = O(d)/O(d-k)$. A point on the Stiefel manifold is parameterized by a tall-skinny $d \times k$ real matrix with orthonormal columns.
The \textbf{Grassmannian}, $Gr(k, d)$, represents the collection of points parameterizing the $k$-dimensional subspaces of a fixed $d$-dimensional vector space, \eg $\R^d$. For our purposes, $Gr(k, d)$ is a \emph{real matrix manifold}, where each point is identified with an \emph{equivalence class of orthogonal matrices}, \ie $Gr(k, d)=O(d)/O(k)\times O(d-k)$. \\
\textbf{Notation:} We represent $[\X] \in Gr(k,d)$ using the truncated unitary matrix $\X \in \R^{d \times k}$. For this paper $[\X]$ is used to denote the subspace spanned by the columns of $\X$.
\end{dfn}


\begin{figure}[t]
        \includegraphics[width=\columnwidth]{figures/flags.pdf}
	\caption{Illustration of a nested sequence of subspaces corresponding to
a point on the flag manifold. }
	\label{fig:flag}
\end{figure}
\begin{dfn}[Flag]\label{def:flagobj}
A \emph{flag} in a finite dimensional vector space $\mathcal{V}$ over a field is a sequence of nested subspaces with \emph{increasing} dimension (\cf~\cref{fig:flag}), each containing its predecessor, \ie the filtration: $\{\emptyset \}=\mathcal{V}_0 \subset \mathcal{V}_1 \subset \dots \subset \mathcal{V}_{k} \subset \mathcal{V}$ with $0=d_0<d_1<\dots<d_k<d$ where $\mathrm{dim} \mathcal{V}_i=d_i$ and $\mathrm{dim} \mathcal{V}=d$. We say this flag is of \emph{type} or \emph{signature} $(d_1, \dots ,d_k,d)$. A flag is called \emph{complete} if $d_i = i,\,\forall i$. Otherwise the flag is \emph{incomplete} or \emph{partial}. 

\noindent\textbf{\emph{Notation}:} A flag, $[[\X]]$ of type $(d_1, \dots ,d_k,d)$, is represented by a truncated unitary matrix $\X \in \R^{n \times d_k}$. Let $m_j = d_j-d_{j-1}$ for $j=1,2,\dots, k$, and $\X_j  \in \R^{d \times m_j}$ for $j=1,2,\dots, k$ whose columns are the $d_{j-1}+1$ to $d_{j}$ columns of $\X$. $[[\X]]$ is
\begin{equation}
     [ \X_1 ]  \subset [\X_1, \X_2] \subset \dots \subset  [\X_1, \dots, \X_k] = [\X] \subset \R^d.\nonumber
\end{equation}
\end{dfn}

\begin{dfn}[Flag manifold]
The aggregate of all flags of the same type, \ie a certain collection of ordered sets of vector subspaces, admit the structure of manifolds. We refer to this \emph{flag manifold} %
as $\flag(d_1, ..., d_k; d)$ or equivalently as $\flag(d+1)$\footnote{Note that we will use $\flag(d_1, ..., d_k; d)$ and $\flag(d+1)$ interchangeably in the rest of the manuscript.}. The points of $\flag(d+1)$
parameterize all flags of type $(d_1, ..., d_k,d)$. 
Flag manifolds generalize Grassmannians because $\flag(k; d)=\Gr(k,d)$. $\flag(d+1)$ can be thought of as a quotient of groups ~\cite{ma2022self}:
\begin{equation*}
\flag(d+1) = SO(d)/S(O(m_1) \times O(m_2) \times \cdots \times O(m_k)).
\end{equation*}
\end{dfn}

\begin{dfn}[Chordal distance on the flag manifold~\cite{pitaval2013flag}]\label{def:flagdist}
For $[[\X]], [[\Y]] \in \flag(d+1)$, the \emph{chordal distance} is a map $d_c: \flag(d+1) \times \flag(d+1) \to \R$:
\begin{equation}\label{eq: chordal distance}
    d_c([[\X]], [[\Y]]) := \sqrt{\sum_{j=1}^k m_j - \tr(\X_j^T \Y_j \Y_j^T \X_j)}.
\end{equation}
\end{dfn}
We now endow flags with \emph{orientation}, which is required in certain applications such as motion averaging. 
\begin{dfn}[Oriented flag manifold~\cite{selig2005study, ma2022self}]
An \emph{oriented flag manifold}, $\flag^+(d+1)$, contains only flags with subspaces with compatible orientations. Algebraically:
\begin{equation*}
    \flag^+(d+1) = SO(d)/(SO(m_1) \times SO(m_2) \times \cdots \times SO(m_k)). 
\end{equation*}
Two oriented vector spaces have the same orientation if the determinant of the unique linear transformation between them is positive~\cite{alberti2005geometric}.
\end{dfn}
















 
 




\subsection{The Chordal Flag-mean}
Armed with notation for flags (\cref{def:flagobj}) and ways to measure distance between them (\cref{def:flagdist}), we are prepared to state the chordal flag-mean estimation problem formally.

\begin{dfn}[Weighted chordal flag-mean]
Let $\{ [[\X^{(i)}]] \}_{i=1}^p \subseteq \flag(d+1)$ be a set of points on a flag manifold with weights $\{\alpha_i\}_{i=1}^p \subset \R$ where $\alpha_i \geq 0$. The chordal flag-mean $[[\bm{\mu}]]$ of these points solves:
\begin{equation} \label{eq: chordal flag mean opt}
    \argmin_{[[\Y]]\in \flag(d+1)} \sum_{i=1}^p \alpha_i d_c([[\X^{(i)}]], [[\Y]])^2.
\end{equation}
\end{dfn}
\textit{Note: for $\flag(k;n)$, this amounts to the Grassmannian-mean by Draper~\etal~\cite{draper2014flag}.}
\begin{prop}\label{prop: flag mean}
The chordal flag-mean optimization problem in \cref{eq: chordal flag mean opt} can be phrased as the Stiefel manifold optimization problem: %
\begin{equation} \label{eq: stiefel opt}
    \argmin_{[\Y] \in St(d_k,d)} \sum_{j=1}^k m_j -  \tr \left( \I_j \Y^T \mathbf{P}_j  \Y \right). 
\end{equation}
where the matrices $\I_j$ and $\mathbf{P_j}$ are given below
\begin{equation}\label{eq: Ij}
    (\I_j)_{i,l} = 
    \begin{cases}
        1, & i = l \in \{ d_{j-1} + 1, 
 d_{j-1} + 2, \dots, d_j\} \\
        0, &\text{ otherwise}\nonumber \\
    \end{cases},
\end{equation}
\begin{equation}\label{eq: Pj}
    \mathbf{P}_j =  \sum_{i=1}^p \alpha_j \X_j^{(i)} {\X_j^{(i)}}^T.
\end{equation}
\end{prop}
\begin{proof}[Sketch of the proof]
We use truncated unitary representations for points on the Stiefel and flag manifolds.
By the equivalence of minimization problems we write~\cref{eq: chordal flag mean opt} as
\begin{equation*}
 \argmin_{[\Y] \in St(d_k,d)}\sum_{j=1}^k  m_j -  \sum_{j=1}^k \sum_{i=1}^p \alpha_i \tr\left( \Y_j^T\X_j^{(i)} {\X_j^{(i)}}^T\Y_j \right).
\end{equation*}
$\I_j$ allows us to write $\Y_j \Y_j^T = \Y \I_j \Y^T$. Using this, properties of trace, and our definition of $\mathbf{P}_j$ we write~\cref{eq: chordal flag mean opt} as
\begin{equation*}
\argmin_{[\Y] \in St(d_k,d)]} \sum_{j=1}^k m_j - \tr \left( \I_j \Y^T\mathbf{P}_j\Y \right).
\end{equation*}
\end{proof}
We provide the full proof in 
the appendix. We now extend the chordal mean to the case of a certain family of \emph{complete} and \emph{oriented} \emph{flags}.




\begin{prop}\label{prop:eucmean}
Let $ \{ \x^{(i)} \}_{i=1}^p \subset \R^d$. Then suppose ${\x^{(i)}}^T \x^{(j)} > 0$ for all $i,j$. Then the naive Euclidean mean $\bm{z} = \frac{1}{n}\sum_{i=1}^p\x^{(i)}$ has the same orientation as each $\x^{(i)}$. 
\end{prop}
\begin{proof}
    The proof follows from the simple derivation:
\begin{align*}
{\x^{(j)}}^T \bm{z} = {\x^{(j)}}^T \frac{1}{n}\sum_{i=1}^p\x^{(i)}
= \frac{1}{n}\sum_{i=1}^p {\x^{(j)}}^T \x^{(i)} > 0.
\end{align*}
\end{proof}
\begin{dfn}[$\flag^+(1,\dots,d-1;d)$ chordal flag-mean]\label{def:reorient}
Let $\{[[\X^{(i)}]]\}_{i=1}^p \subset \flag(1,2,\dots,d-1;d)$  where for each $j$ and any $i$ and $k$, ${\X_j^{(i)}}^T{\X_j^{(k)}} > 0$. Let $[[\bm{\mu}]]$ be the chordal flag-mean (e.g.,~\cref{eq: chordal flag mean opt}) and $\bm{z}_j$ be the Euclidean mean of $\{ \X_j^{(i)}\}_{i=1}^p \in \R^d$. Then the oriented chordal flag-mean is defined as $[[\bm{\mu}^+]] \in \flag^+(1,\dots,d-1;d)^+$:
\begin{equation}\label{eq: orientation ex}
    \bm{\mu}^+_j =
    \begin{cases}
        \Y_j, & \bm{z}_j^T \Y_j \geq 0\\
        -\Y_j, & \text{otherwise}.
    \end{cases}
\end{equation}
\end{dfn}
\begin{remark}
The ordering of the columns of $\bm{\mu}$ is the same as that of each $\X^{(i)}$ because the chordal distance on the flag manifold respects the ordering of the vectors in the flag representation by only comparing $\bm{\mu}_j$ to $\X_j^{(i)}$. So, we only need to correct for the sign of the columns of $\bm{\mu}$.
By ~\cref{prop:eucmean}, we know that the Euclidean mean, $\bm{z}$, 
has the same orientation as each of $\X_j^{(i)}$. We use ~\cref{eq: orientation ex} to force $\bm{\bm{z}}_j^T\bm{\mu}_j^* \geq 0$.
\cref{def:reorient} gives us a way to choose which chordal flag-mean representatives are best for averaging representations of motions in $\flag^+(1,2,3;4)$ in~\cref{sec:motavg}.
\end{remark}





\input{content/alg_chordalavg.tex}

















To compute the proposed mean, we optimize ~\cref{eq: stiefel opt} via RTR methods~\cite{absil2007trust,boumal2014manopt} and re-orient the mean using~\cref{def:reorient}.
\begin{remark}
    The geodesic distance averages on the Grassmannian (e.g. $\ell_2$-median and Karcher mean) are known to be unique only for certain subsets of the Grassmannian \cite{afsari2011riemannian}. The proof of this revolves around finding the region of convexity of the geodesic distance function and its square.
    Uniqueness for Grassmannian chordal distance averages (\eg the GR-mean \cite{draper2014flag} and -median \cite{mankovich2022flag}) is largely unstudied. It is known that the chordal distance on the Grassmannian approximates the geodesic distance, but its region of convexity %
    is an open problem to the best of our knowledge.
    Determining the convexity of our chordal flag-mean and -median would boil down to finding the region of convexity of the chordal distance function and its square on the flag manifold. Additionally, one could generalize geodesic distance averages to the flag manifold using Riemannian operators on flags~\cite{ye2022optimization}, find an algorithm to compute them and their region of convexity. We leave these projects to future work.
\end{remark}

\subsection{The Chordal Flag-median}
We are now ready to provide our iterative algorithm for robust centroid estimation.
\begin{dfn}[Weighted chordal flag-median]
Let $\{ [[\X^{(i)}]] \}_{i=1}^p \subseteq \flag(d+1)$ be a set of points on a flag manifold with weights $\{\alpha_i\}_{i=1}^p \subset \R$ where $\alpha_i \geq 0$. The chordal flag-median, $[[\bm{\eta}]]$, of these points solves
\begin{equation} \label{eq: chordal flag median opt}
    \argmin_{[[\Y]] \in \flag(d+1)} \sum_{i=1}^p \alpha_i d_c([[\X^{(i)}]], [[\Y]]).
\end{equation}
\end{dfn}
\textit{Note: for $\flag(k;n)$, this amounts to the Grassmannian-median by Mankovich~\etal~\cite{mankovich2022flag}.}


\begin{prop}\label{prop: flag median}
The flag-median optimization problem in \cref{eq: chordal flag median opt} can be phrased with weights $w_i([[\Y]])$ in: 
\begin{equation}\label{eq: irls weights}
    w_i([[\Y]]) =  \frac{\alpha_i}{\max\{d_c([[\X^{(i)}]], [[\Y]]), \epsilon\}},
\end{equation}
\begin{equation}\label{eq: median equiv}
 \argmin_{[[\Y]] \in \flag(d+1)}\sum_{i=1}^p \sum_{j=1}^k m_j - w_i([[\Y]]) \tr\left( \Y_j^T \X_j^{(i)}{\X_j^{(i)}}^T \Y_j \right).
\end{equation}
where $\epsilon = 0$ as long as $d_c([[\X^{(i)}]], [[\Y]]) \neq 0$ for all $i$.
\end{prop}

\begin{proof}[Sketch of the proof] 
We can encode the constraints and our optimization problem into the Lagrangian:
\begin{align}
\begin{aligned}%
    \nabla_{\Y_j} \mathcal{L}
    &=  -2 \sum_{i=1}^p \frac{\alpha_i \X_j^{(i)}{\X_j^{(i)}}^T \Y_j}{\sqrt{\sum_{j=1}^k m_j - \tr \left( {\X_j^{(i)}}^T \Y_j \Y_j^T \X_j^{(i)} \right) } } \nonumber\\
    &+2\sum_{j=1}^k \lambda_{i,j}\Y_i\Y_i^T \Y_j,\\
     \nabla_{\lambda_{i,j}} \mathcal{L} &=  m_j \delta_{i,j} - \tr\left( \Y_i^T\Y_j\Y_j^T \Y_i \right).
\end{aligned}
\end{align}
Then we take the gradient of the Lagrangian with respect to $\Y_j$ and $\lambda_{i,j}$ and set it equal to zero. So, for each $j$, we have 
\begin{equation*}
m_j \lambda_{j,j} =  \sum_{i=1}^p \frac{\alpha_i \tr \left( \Y_j^T \X_j^{(i)}{\X_j^{(i)}}^T \Y_j \right) }{d_c([[\X^{(i)}]], [[\Y]]) }.
\end{equation*}
We use equivalences of optimization problems to reformulate this as~\cref{eq: median equiv}.







\end{proof}

\begin{prop}\label{prop: irls iteration}
 Fixing $[[\Z]] \in \flag(d+1)$, \cref{eq: median equiv}, with $w_i([[\Z]])$, becomes
 \begin{equation*}
  \argmin_{[[\Y]] \in \flag(d+1)}\sum_{i=1}^p \sum_{j=1}^k m_j - w_i([[\Z]]) \tr\left( \Y_j^T \X_j^{(i)}{\X_j^{(i)}}^T \Y_j \right)
 \end{equation*}
 and is equivalent to a chordal flag-mean with weights $w_i([[\Z]])$.
 Note: $\epsilon = 0$ as long as $d_c([[\X^{(i)}]], [[\Z]]) \neq 0$ for all $i$.
\end{prop}
\begin{proof}[Proof sketch] 
This follows from the proof of~\cref{prop: flag mean}.
\end{proof}

\input{content/alg_chordalmedian.tex}
~\cref{prop: flag median} simplifies our optimization problem to \cref{eq: median equiv}. Given an estimate for the chordal flag-median, $[[\Z]]$, \cref{prop: irls iteration} shows that solving a weighted chordal flag mean problem will approximate the solution to \cref{eq: median equiv}. Using the propositions, we are now ready to present our iterative algorithm for flag-median estimation in~\cref{alg:chordalmedian}.

The convergence of Weiszfeld-type algorithms are well studied in the literature~\cite{aftab2015convergence,beck2015weiszfeld,zhao2020quaternion} and our IRLS algorithm for the chordal flag-median can be proven to  decrease its respective objective function value over iterations. This is what we establish next in~\cref{prop: flagirls decreasing}, inspired by the proof methods given in~\cite{beck2015weiszfeld}.%

\begin{prop}\label{prop: flagirls decreasing}
Let $[[\Y]] \in \flag(d+1)$. Suppose $d([[\Y]],[[\X^{(i)}]]) > \epsilon$ for $i = 1,2, \dots, p$. Also define the maps: $T:\flag(d+1) \rightarrow \flag(d+1)$ as an iteration of~\cref{alg:chordalmedian} and $f:\flag(d+1) \rightarrow \R$ as the chordal flag-median objective function value. Then
\begin{equation}
f(T([[\Y]])) \leq f([[\Y]]).
\end{equation}
\end{prop}
\begin{proof}[Proof sketch] 
We define the function 
\begin{equation}
h([[\Z]],[[\Y]]) = \sum_{i=1}^p w_i([[\Z]]) d_c([[\X^{(i)}]],[[\Y]])^2.
\end{equation}
We use $h$ and $2a- b < \frac{a^2}{b}$ for $a,b \in \R$, $b > 0$ to find 
\begin{align}
2f(T([[\Y]]) - f([[\Y]]) &\leq h(T([[\Y]]),  [[\Y]]),  \\
h(T([[\Y]]),  [[\Y]]) &\leq h([[\Y]], [[\Y]]) \leq f([[\Y]]).\nonumber
\end{align}
From our string of inequalities, we have the desired result. We leave the full proof to our supplementary material.
\end{proof}
\begin{remark}
The distance vanishes when $[[\Y]] = [[\X^{(i)}]]$ (e.g., $d_c([[\Y]],[[\X^{(i)}]]) =0$). In this case, \cref{alg:chordalmedian} gets stuck at $[[\X^{(i)}]]$ and the result in~\cref{prop: flagirls decreasing} becomes
\begin{equation}
f(T([[\Y]])) \leq f([[\Y]]) + {p \epsilon}/{2}.
\end{equation}
This singularity can be removed even for a general Weiszfeld iteration, simply by replacing the weights~\cite{aftab2014generalized}.
\end{remark}


\begin{prop}\label{cor: flagirls obj converges}
Let $[[\Y_k]] \in \flag(d+1)$ be an iterate of~\cref{alg:chordalmedian} and $f:\flag(d+1) \rightarrow \R$ denote the chordal flag-median objective value. $f([[\Y_k]])$ converges as $k \rightarrow \infty$ as long as $d_c([[\Y]],[[\X_i]]) >\epsilon$ for $i=1,2,\dots,p$ and each $k$.
\end{prop}

\begin{proof}
 Notice that the real sequence with terms $f([[\Y_k]]) \in \R$ is bounded below by $0$ and is decreasing by~\cref{prop: flagirls decreasing}. So it converges as $k \rightarrow \infty$.
\end{proof}







