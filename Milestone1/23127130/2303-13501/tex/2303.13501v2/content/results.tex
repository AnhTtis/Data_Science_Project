\section{Results}\label{sec:results}
%\vspace{-1mm}
%We now evaluate our method to average points on flag manifolds and rigid motions ($SE(3))$. \vspace{-2mm}
% We provide further evaluations in our supplementary material.
\subsection{Averaging on Flag Manifolds}%\vspace{-1mm}
We first consider examples of data naturally existing as flags. 
% In this section we investigate examples where averages of points on a flag manifold improve upon averages on the Grassmannian. \textcolor{blue}{These data naturally exist as flags, but can also be interpreted as points on Grassmannians by using the largest subspace in the flag.} 
We work with $5$ data sets: $2$ synthetic ones, MNIST digits \cite{deng2012mnist}, the Yale Face Database \cite{belhumeur1997eigenfaces}, and the Cats and Dogs dataset~\cite{yambor2000analysis}. We provide further evaluation of our flag averages that result in improved clustering on the UFC YouTube dataset~\cite{liu2009recognizing} in the supplementary material. In one synthetic experiment, we compare our Stiefel Riemannian Trust-Regions (RTR) method in Alg.~\ref{alg:chordalavg} for computing the flag-mean to the Flag RTR by Nguyen~\etal \cite{nguyen2022closed}. In the rest of the experiments, %we compare chordal distance averages to one another. Specifically, 
we compare our \textit{chordal} flag (FL)-mean \& -median to the Grassmannian (GR)-mean~\cite{draper2014flag} \& -median~\cite{mankovich2022flag}, as well as Euclidean averaging, where the matrices are simply averaged and projected onto the flag manifold via QR decomposition. 
%For GR-means and -medians we interpret the data as points on Grassmannians by using the largest dimensional subspace in the flag.
GR-means and -medians, \cite{draper2014flag, mankovich2022flag} input data a points on Grassmannians by using the largest dimensional subspace in the flag ($[\X^{(i)}] \in \Gr(k,d)$) and output an average as a flag of type $(1,2,\dots,k,d)$. So all the methods considered in this section result in averages which live on a flag manifold. In this section we compare methods for data representation: the flag vs. Grassmannian vs. Euclidean space. 
% \textcolor{blue}{Nate: I added the final sentence to drive home the point that all averages natrually live on flags, we just change data representation. Delete if you don't think that's clear}
%\textcolor{blue}{Nate: do you think we need to reference~\cite{draper2014flag} \&~\cite{mankovich2022flag} only one time at the beginning of this section?}\tolga{I know.. maybe it's enough?}\textcolor{blue}{Nate: I think it's good enough. It saves space.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%
%the submitted table
% \begin{table}[t]
% \setlength{\tabcolsep}{3mm}
%     \centering
%     \begin{tabular}{l| c c}
%          & Dist. to $\mathbf{C}$ & Obj. Fn. Value \\
%          \toprule
%         Ours & $(1.4 \pm 0.2) \times 10^{-4}$ & $(2.1 \pm 0.05) \times 10^{-4}$\\
%          \cite{nguyen2022closed} & $(1.4 \pm 0.2) \times 10^{-2}$ & $(2.1 \pm 0.5) \times 10^{-2}$ \\
%          \bottomrule
%     \end{tabular}
%     \caption{Robustness to initialization:~\cref{alg:chordalavg} versus Flag RTR from Nguyen~\etal \cite{nguyen2022closed}. Data: $100$ points on $\flag(1,2,3;10)$.\vspace{-4mm}}
%     \label{tab:initrobust}
% \end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%

%new results
\begin{table}[t]
\setlength{\tabcolsep}{3mm}
    \centering
    \begin{tabular}{l| c c}
         & Dist. to $\mathbf{C}$ & Obj. Fn. Value \\
         \toprule
        Ours & $(1.4 \pm 0.2) \times 10^{-4}$ & $(2.1 \pm 0.05) \times 10^{-4}$\\
         \cite{nguyen2022closed} & $(3.0 \pm 2.1) \times 10^{-3}$ & $(1.6 \pm 1.6) \times 10^{-3}$ \\
         \bottomrule
    \end{tabular}
    \caption{Robustness to initialization: Alg.~\ref{alg:chordalavg} versus Flag RTR from Nguyen~\etal \cite{nguyen2022closed}. Data: $100$ points on $\flag(1,2,3;10)$.\vspace{-4mm}}
    \label{tab:initrobust}
\end{table}

%The goal of~\cref{fig:flagmeancompare} is to compare our flag averages to Euclidean and Grassmannian averages. Additionally, we compare~\cref{alg:chordalavg} to Nguyen et al.\ for computing the flag-mean \cite{nguyen2022closed}. 
\paragraph{Synthetic data}
Both our synthetic experiments use the same methodology for generating data sets on the Grassmannian and flag. We begin by computing a ``center'' representative, $\mathbf{C} \in \R^{10 \times 3}$, as the first $3$ columns of the QR decomposition of a random matrix in $\R^{10 \times 3}$ with entries sampled from the uniform distribution over $[-.5,.5)$, $\mathcal{U}[-.5,.5)$. The representative for the $i^{\text{th}}$ data point, $\X_i$, is computed by sampling $\mathbf{Z}_i \in \R^{10 \times 3}$ with entries from $\mathcal{U}[-.5,.5)$ and defined as the first $3$ columns of the QR decomposition of $\mathbf{C} + \delta \mathbf{Z}_i$ for a noise parameter $\delta \geq 0$. 

\paragraph{Averaging synthetic flag data}
We use synthetic data sets with $100$ points, on $\Gr(3;10)$ and $\flag(1,3;10)$. For the left plot in Fig.~\ref{fig:flagmeancompare} we vary $\delta$ to compute our data sets. For the right plot we have $m$ outliers computed with $\delta = 1$ and the rest of the data are computed with $\delta = 0.001$. We compute the error as the chordal distance on $\flag(1,3;10)$ between the predicted average and $[\![\mathbf{C}]\!]$. In addition to comparing our averages to Grassmannian (GR) averages, we compare Alg.~\ref{alg:chordalavg} to Nguyen \etal~\cite{nguyen2022closed} for computing the flag-mean. Our results indicate that our algorithm improves both upon GR, Euclidean, and Nguyen~\etal~\cite{nguyen2022closed} averages in the sense that flag averages are closer to $[\![\mathbf{C}]\!]$. Specifically, our flag-median is more robust to outliers than our flag-mean. Note: Euclidean out preforms GR averaging because Euclidean averaging respects column order (e.g., the flag structure) for matrix representatives of the data, whereas GR averaging does not.  % and our algorithm improves flag-mean computation.

\paragraph{Comparisons to Riemannian flag optimization}
In a second experiment, we compare the convergence of Alg.~\ref{alg:chordalavg} to that of Flag RTR~\cite{nguyen2022closed}. To this end, we generate $100$ points on $\flag(1,2,3;10)$ using $\delta = 0.001$ and run $50$ random trials with different initializations and compute $3$ items (i) the number of iterations to convergence, (ii) the chordal distance on $\flag(1,2,3;10)$ between the flag-mean and $[\![\mathbf{C}]\!]$, (iii) the cost function values from Eq.~\ref{eq: chordal flag mean opt}. We find that in every experiment Alg. \ref{alg:chordalavg} converges in \textit{2 iterations} and Flag RTR converges, on average, in $9.74 \pm 2.76$ iterations. In Tab.~\ref{tab:initrobust} we see that our method is one order of magnitude closer to the ground truth centroid $[\![\mathbf{C}]\!]$ and produces a one order of magnitude smaller objective function value.
%old (in submitted version)
%hits its maximum number of iterations: $1000$. 
% In~\cref{tab:initrobust} we see that our method is two orders of magnitude closer to the ground truth centroid $[\![\mathbf{C}]\!]$ and produces a two orders of magnitude smaller objective function value.

% \paragraph{Datasets}

% \paragraph{Baselines}
% For face averaging, we take three faces from the Yale Face Database with different illuminations: center, left and right. 
\paragraph{Averaging under varying illumination}
To further demonstrate the efficacy of our averages over the standard Grassmanians, we leverage face images from Yale Face Database~\cite{belhumeur1997eigenfaces} with central ($c$), left ($l$), and right ($r$) illuminations, respectively. Let $\mathbf{A_c}, \mathbf{A_l}, \mathbf{A_r} \in \R^{243 \times 320}$ be these three images of a person.
% Let $\mathbf{A_c}, \mathbf{A_l}, \mathbf{A_r} \in \R^{d}$ where $d = 243 \times 320$, be the three images of a person. \textcolor{blue}{Nate: I changed the sentence above.} 
We represent a face as a point $[\![\X]\!] \in \flag(1,3;d)$ as $[\![\X]\!] = [\X_1] \subset [\X] \subset \R^{d}$ and as $[\X] \in \Gr(3,d)$ using the following three steps: (i) Set $\mathbf{v_i} = \text{vec} \left(\mathbf{A_i} \right)$ for $i=c,l,r$; (ii) take $\X = \mathbf{Q}_{:,1:3}$ where $\mathbf{Q}$ is from the QR decomposition of $[\mathbf{v_c}, \mathbf{v_l}, \mathbf{v_r}]$.
% \begin{enumerate}[leftmargin=*,itemsep=0pt,topsep=1pt]
%     \item Set $\mathbf{v_i} = \text{vec} \left(\mathbf{A_i} \right)$ for $i=c,l,r$.
%     \item Perform QR decomposition: $\mathbf{Q}\mathbf{R} = [\mathbf{v_c}, \mathbf{v_l}, \mathbf{v_r}]$
%     \item $\X = \mathbf{Q}_{:,1:3}$.
% \end{enumerate}
% \textit{Note: we think of} $[\![\X]\!] \in \flag(1,3;d)$ \textit{as}
% \begin{equation*}
    % [\![\X]\!] = [\X_1] \subset [\X_1, \X_2, \X_3] \subset \R^{d}.
% \end{equation*}
Repeating this process for three faces gives us three points: $[\X_1],[\X_2],[\X_3] \in \Gr(3,d)$ and $[\![\X_1]\!],[\![\X_2]\!],[\![\X_3]\!] \in \flag(1,3;d)$.
Then we calculate the Grassmannian-mean of the points in $\Gr(3,d)$ which is the flag: $[\![\bm{\nu}]\!] = [\bm{\nu}_1] \subset [\bm{\nu}_1, \bm{\nu}_2] \subset [\bm{\nu}_1,\bm{\nu}_2,\bm{\nu}_3]$
and the flag-mean (ours) of the points in $\flag(1,3;d)$: $[\![\bm{\mu}]\!]  = [\bm{\mu}_1] \subset [\bm{\mu}_1,\bm{\mu}_2,\bm{\mu}_3] $.
% \begin{equation*}
% [\![\bm{\nu}]\!] = [\bm{\nu}_1] \subset [\bm{\nu}_1,\bm{\nu}_2,\bm{\nu}_3] \subset \R^4
% \end{equation*}
A plot of reshaped $\bm{\mu}_1$ and $\bm{\nu}_1$ for a set of three faces in Fig.~\ref{fig:face_averages1}. We would expect the first dimension of both means to look like a face with center illumination. However, only the flag-mean appears to be center-illuminated. 

\begin{figure}[t]
        \includegraphics[width=\columnwidth]{figures/faces1.pdf}
	\caption{Averaging a collection of faces belonging to three different people, captured under varying illumination: center, left and right. Notice that the first dimension of the flag representations is center illuminated, better representing the mean compared to Grassmannian.\vspace{-4.5mm}}
	\label{fig:face_averages1}
\end{figure}

\paragraph{MNIST representation}
We run two experiments similar to what was done in~\cite{mankovich2022flag} with MNIST digits. However, our representations differ since we represent a digit as $[\X_j] \in \Gr(2, 784)$ and $[\![\X_j]\!] \in \flag(1,2;784)$. We generate $p$ representations of a digit, $\{\X_j\}_{j=1}^p$, by sampling a set of $p$ images without replacement from the test partition. Then we vectorize each image into $\mathbf{v}_j \in \R^{784}$ and run $k$ nearest neighbors on $\{\mathbf{v_j}\}_{i=1}^p$ with $k=2$ using the cosine distance. 
Say $\mathbf{v}_j$ and $\mathbf{v}_k$ are the $2$ nearest neighbors of $\mathbf{v}_j$, then the representation for sample $j$ is $\X_j = \mathbf{Q}_{:,:2}$ from the QR decomposition of $[\mathbf{v}_j, \mathbf{v}_k]$.

\paragraph{Robustness to Neural Network (NN) predictions} For the first MNIST experiment, we use the method above to create $20$ data sets on $\Gr(2, 784)$ and $\flag(1,2; 784)$ 
 corresponding to $i=0,1,2,\dots, 19$. The $i$th data set contains $20$ representations of the digit $1$ and $i$ representations for the digit $9$. We calculate a GR-mean and -median of each of the $i$ data sets on $\Gr(2, 784)$ and our flag-mean and -median for the data sets on $\flag(1, 2, 784)$. Note: all of these averages live on $\flag(1, 2, 784)$.
We then use a NN (trained on the original training data and producing a $97\%$ test accuracy on the original test data) to predict the label of the first dimension of each average for $i=0,1,2,\dots, 19$. As plotted in Fig.~\ref{fig: MNIST}, the NN incorrectly predicts the class of the GR-mean and -median for each data set. In contrast, the flag-mean and -median are all predicted as $1$s with data sets with fewer than $11$ representations of the $9$s digits. The flag-mean is the first flag average to be incorrectly predicted, since it is not as robust to outliers as the flag-median.

\begin{figure}[t]
    \includegraphics[width=\linewidth]{figures/predictions_dim0_qr.pdf}
    \caption{Neural network predictions for the first dimension of different averages $i=0,1,2,\dots,19$ MNIST data sets. The $i$th data set has $i$ representations of the $9$s digit and $20$ representations of the $1$s digit.\vspace{-5mm}}
    \label{fig: MNIST}
\end{figure}

\paragraph{Visualizing robustness}
Our second MNIST experiment is with $20$ representations of $6$s and with $i$ outlier representations of $7$s for $i=0,4,8,12$. We use the workflow from Fig.~\ref{fig: MNIST} to represent the MNIST digits on $\Gr(2,748)$ and $\flag(1,2;748)$. For each $i$, we compute averages of a data set with $i$ representations of $7$s. A chordal distance matrix on $\flag(1,2;798)$ between all the averages and data is used to preform Multidimensional Scaling (MDS)~\cite{kruskal1978multidimensional} for visualization in Fig.~\ref{fig:mnist_outliers}. 
%The averages move from the right to the left as we average data sets as we gradually add more representations of $7$s. 
The best averages should barely move (right to left) as we add outlier representations of $7$s. Our flag-mean and -median are moved the least with the addition of representations of $7$s with the median moving less than the mean. In contrast, the Grassmannian-mean and -median \cite{mankovich2022flag} move more than the compared baselines as we add $7$s.

\begin{figure}[t]
    \includegraphics[width=\linewidth]{figures/mds_plot.pdf}\vspace{-3mm}
    \caption{MDS embedding of MNIST digits and Grassmannian and flag averages. Each ``x'' is an average of $20$ representations of $6$s as we gradually add $i$ outlier representations of $7$s for $i=0,4,8,12$ data sets. The averages move from right to left as we add more $7$s.\vspace{-5mm}}
    %\tolga{reads weird to me :/}
    %\tolga{We shall write in the caption what the figure depicts. What are we averaging? all of them?} \textcolor{blue}{Nate: modification added...}
    \label{fig:mnist_outliers}
\end{figure}

\paragraph{PCA by flag statistics}
We use the Cats and Dogs dataset~\cite{yambor2000analysis} to compute $3$-dimensional PCA~\cite{hotelling1933analysis} weights, $\mathbf{W}^* \in \R^{4096 \times 3}$, of the data matrix, $\mathbf{X} \in \R^{198 \times 4096}$. Then we randomly split the $m$ subjects into $p$ evenly sized groups to generate $p$ data matrices each of size $p_i$: $\{\mathbf{X_i}\}_{i=1}^p \subset \R^{p_i \times 4096}$. PCA weights of each $\mathbf{X_i}$ are computed as $\mathbf{W_i}\in \R^{4096 \times 3}$. $\mathbf{W}^*$ is predicted by averaging $\{\mathbf{W_i}\}_{i=1}^p$ as points on $\flag(1,2,3; 4096)$ and $\Gr(3; 4096)$. Specifically, we compute the flag-mean (ours), Grassmannian-mean,  Euclidean-mean, and a random point. Then we record the chordal distance on $\flag(1,2,3; 4096)$ (reconstruction error) between the average and $[\![\mathbf{W}^*]\!] \in \flag(1,2,3; 4096)$. Our flag-mean is closer to $[\![\mathbf{W}^*]\!]$ for $p=1,2,\dots,6$.


% \begin{figure}[t]
%     \begin{subfigure}{\linewidth}  
%         \includegraphics[width=\linewidth]{figures/predictions_dim0_svd.png}
%         \caption{SVD}
%     \end{subfigure}
%     \begin{subfigure}{\linewidth} 
%         \includegraphics[width=\linewidth]{figures/predictions_dim0_qr.png}
%         \caption{QR Decomposition}
%     \end{subfigure}
% 	\caption{Different pre-processing leads to different results. \tolga{can you send me the data so that I can plot them in the same style?} \nate{I will save them as csvs in the github}}
% 	\label{fig:MNIST}
% \end{figure}


\subsection{Averaging Rigid Motions}
We now evaluate our algorithm in robust averaging of a set of points represented on the $SE(3)$-manifold. To this end, we synthesize a dataset of 400 rigid motions (rotations and translations) around multiple randomly drawn central points in $SE(3)$. 
These points are generated with increasing noise levels. Particularly, for rotations we perturb the rotation axis using variances of $[0, 5, 10, 15, 20, 25]$ degrees,
    while the translations are perturbed in the levels of $[0, 0.02, 0.05, 0.1, 0.2, 0.3]$. For each noise level, we run 50 experiments and use $\lambda=1$ to ensure that translations and rotations are well balanced.
We then run our algorithms for the flag-mean and -median. These algorithms are compared to standard Govindu~\cite{govindu2004lie}, and baseline (QT) where translations and quaternions are averaged independently using Markley's method~\cite{markley2007averaging}. We also ran dual quaternion averaging of Torsello~\etal~\cite{torsello2011multiview} and found it produced identical results to Govindu.
%de-facto standard of Govindu~\cite{govindu2004lie}. We also compared dual quaternion averaging of Torsello~\etal~\cite{torsello2011multiview} but got almost identical results to Govindu~\cite{govindu2004lie}. We also include a baseline (QT) where translations and quaternions are averaged indepdently. For the latter, we used Markley's method~\cite{markley2007averaging}. 
%\textcolor{blue}{Nate: I re-worded the paragraph above}
Our results in Fig.~\ref{fig:se3avg} show that both of our algorithms surpass classical motion averages with our flag-median producing more robust estimates. 
\begin{figure}[t]
    \includegraphics[width=\linewidth]{figures/pca_res.pdf}
    \vspace{-4mm}\caption{Reconstruction error for PCA weights as a function of Number of Splits, $p$.\vspace{-2mm}}
    \label{fig:pca_exp}
\end{figure}
\begin{figure}[t]
        \includegraphics[width=\columnwidth]{figures/se3_exp.pdf}
	\vspace{-4mm}\caption{Single motion averaging experiments for increasing levels of $SE(3)$-noise and outlier ratios.\vspace{-4mm}}
	\label{fig:se3avg}
\end{figure}