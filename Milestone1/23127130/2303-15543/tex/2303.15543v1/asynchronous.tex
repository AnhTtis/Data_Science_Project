% IMPORTANT NOTE TO SELF
% DO NOT FORGET TO REFER TO https://gecco-2022.sigevo.org/Paper-Submission-Instructions
% TO ENSURE ALL REQUIREMENTS ARE MET FOR SUBMISSION.

%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[dvipsnames,format=sigconf]{acmart}
% Set class to anonymous=true,review=true for submission
% 
%\usepackage[false]{anonymous-acm}
% \usepackage[true]{anonymous-acm}
\usepackage{tabularray}
\UseTblrLibrary{siunitx}

% \usepackage{csquotes}

% \usepackage[subtle]{savetrees}

% Halve the caption skips: my figures and tables have their own spacing built in, halving will make the spacing nicer.
\captionsetup[table]{skip=5pt}
\captionsetup[figure]{skip=5pt}
\setlength{\textfloatsep}{5pt}
\setlength{\dbltextfloatsep}{5pt}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
% \setcopyright{rightsretained}
% \acmDOI{10.1145/3512290.3528828}

% %% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[GECCO '22]{The Genetic and Evolutionary Computation Conference 2022}{July 9--13, 2022}{Boston, USA}
% \acmYear{2022}
% \copyrightyear{2022}
% \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\copyrightyear{2023}
\acmYear{2023}
\setcopyright{rightsretained}
\acmConference[GECCO '23]{Genetic and Evolutionary Computation Conference}{July 15--19, 2023}{Lisbon, Portugal}
\acmBooktitle{Genetic and Evolutionary Computation Conference (GECCO '23), July 15--19, 2023, Lisbon, Portugal}
% \acmDOI{}
% \acmISBN{}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{The Impact of Asynchrony on Parallel Model-Based EAs}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
%\authoranon{
\author{Arthur Guijt}
% \authornote{Both authors contributed equally to this research.}
\email{Arthur.Guijt@cwi.nl}
\orcid{0000-0002-0480-2129}
\affiliation{%
  \institution{Centrum Wiskunde \& Informatica}
%   \streetaddress{TODO}
  \city{Amsterdam}
%   \state{TODO}
  \country{The Netherlands}
%   \postcode{TODO}
}

\author{Dirk Thierens}
% \authornote{Both authors contributed equally to this research.}
\email{D.Thierens@uu.nl}
\orcid{0000-0002-9308-5159}
\affiliation{%
  \institution{Utrecht University}
%   \streetaddress{TODO}
  \city{Utrecht}
%   \state{TODO}
  \country{The Netherlands}
%   \postcode{TODO}
}

\author{Tanja Alderliesten}
% \authornote{Both authors contributed equally to this research.}
\email{T.Alderliesten@lumc.nl}
\orcid{0000-0003-4261-7511}
\affiliation{%
  \institution{Leiden University Medical Center}
%   \streetaddress{TODO}
  \city{Leiden}
%   \state{TODO}
  \country{The Netherlands}
%   \postcode{TODO}
}

\author{Peter A.N. Bosman}
% \authornote{Both authors contributed equally to this research.}
\email{Peter.Bosman@cwi.nl}
\orcid{0000-0002-4186-6666}
\affiliation{%
  \institution{Centrum Wiskunde \& Informatica}
%   \streetaddress{TODO}
  \city{Amsterdam}
%   \state{TODO}
  \country{The Netherlands}
%   \postcode{TODO}
}
\affiliation{%
  \institution{Delft University of Technology}
%   \streetaddress{TODO}
  \city{Delft}
%   \state{TODO}
  \country{The Netherlands}
%   \postcode{TODO}
}
%}


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Arthur Guijt, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
    In a parallel EA one can strictly adhere to the generational clock, and wait for all evaluations in a generation to be done. However, this idle time limits the throughput of the algorithm and wastes computational resources. Alternatively, an EA can be made asynchronous parallel. However, EAs using classic recombination and selection operators (GAs) are known to suffer from an evaluation time bias, which also influences the performance of the approach.
    Model-Based Evolutionary Algorithms (MBEAs) are more scalable than classic GAs by virtue of capturing the structure of a problem in a model. If this model is learned through linkage learning based on the population, the learned model may also capture biases. Thus, if an asynchronous parallel MBEA is also affected by an evaluation time bias, this could result in learned models to be less suited to solving the problem, reducing performance.
    Therefore, in this work, we study the impact and presence of evaluation time biases on MBEAs in an asynchronous parallelization setting, and compare this to the biases in GAs.
    We find that a modern MBEA, GOMEA, is unaffected by evaluation time biases, while the more classical MBEA, ECGA, is affected, much like GAs are.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003752.10003809.10003716.10011136.10011797.10011799</concept_id>
<concept_desc>Theory of computation~Evolutionary algorithms</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10002950.10003714.10003716.10011136.10011797.10011799</concept_id>
<concept_desc>Mathematics of computing~Evolutionary algorithms</concept_desc>
<concept_significance>500</concept_significance>
</concept>

<concept>
<concept_id>10010147.10010178.10010205.10010207</concept_id>
<concept_desc>Computing methodologies~Discrete space search</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<!--<concept>
<concept_id>10010147.10010178.10010205.10010209</concept_id>
<concept_desc>Computing methodologies~Randomized search</concept_desc>
<concept_significance>500</concept_significance>
</concept>-->
</ccs2012>
\end{CCSXML}

%\ccsdesc[500]{Computing methodologies~Discrete space search}
%\ccsdesc[500]{Computing methodologies~Randomized search}
%\ccsdesc[500]{Theory of computation~Evolutionary algorithms}
\ccsdesc[500]{Mathematics of computing~Evolutionary algorithms}
\ccsdesc[500]{Theory of computation~Parallel computing models}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Genetic Algorithms, Model-Based Evolutionary Algorithms, Linkage Learning, Parallel Algorithms, Asynchronous Algorithms}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

% \vspace*{-3mm}
\section{Introduction}\label{sec:introduction}
For the optimization of many real-world problems the assessment of the quality of a solution (evaluation) involves a time-consuming process, e.g., the training of a neural network. Problems with such evaluation functions are called expensive optimization problems.
% % Under a time limit, Making use of additional computational resources is always a way to further enhance effectivity.

More often than not, the amount of wall time spent should be minimized. Rather than using the resources to perform these evaluations sequentially, it is preferred to use the resources simultaneously, to run evaluations in parallel. As evaluations are also commonly independent, the parallelization potential is significant, allowing us to save significant amounts of time.

However, the generational nature of an EA may limit how parallelizable the algorithm is.
EAs often follow a loop of generating offspring, evaluating them, and performing selection. Selection is only performed once all offspring solutions are evaluated, and new solutions are only generated and evaluated once selection has been performed. This describes a standard generational scheme. Alternatively, the population can be altered incrementally. For example, by generating a single solution at a time and attempting to introduce it into the population immediately after evaluation, resulting in a steady-state scheme.

In a parallel EA, unless very large population sizes are used, this limited number of solutions per generation means that processors may run out of solutions to evaluate until the next generation starts, i.e., when new offspring will be generated. Before continuing, these processors must wait on the other processors to ensure all evaluations have finished. This waiting on other processors is also called \emph{synchronization}.

Synchronizing is however only required if one wishes to have the exact same behavior as the sequential implementation of the EA. Alternatively, one can also asynchronously sample, evaluate, and apply selection, as is the case for the asynchronous steady-state GA~\cite{scottUnderstandingSimpleAsynchronous2015}. This may be beneficial as waiting wastes computational resources. For example, in a situation with many computing nodes, a slower node or evaluation may stop all other nodes from progressing, introducing a bottleneck into the optimization process, see Figure~\ref{fig:sync-vs-async} for an illustrative example. 
Furthermore, in the case of node or network failures, synchronization will even lock up the optimization process indefinitely.
In the remainder of this work we will refer to approaches employing synchronization as \emph{synchronous} approaches, and approaches that forgo this as \emph{asynchronous}.

\begin{figure}
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/2023-02-09-sync-vs-async-mod.pdf}
    \vspace{-1.0em}
    \caption{Resource consumption of synchronous and asynchronous approaches under heterogeneous evaluation times. Ideally, without synchronization the target solution can be found earlier (in this example: the most expensive solution of the second 'generation').}
    \label{fig:sync-vs-async}
\end{figure}

However, not synchronizing does not guarantee better overall performance of the EA. For example, while in~\cite{churchillToolSequenceOptimization2013} the asynchronous configuration outperformed the synchronous configuration, in~\cite{yagoubiAsynchronousMasterSlave2012} performance degraded when using an asynchronous approach. 
Evaluation time biases were investigated in~\cite{scottUnderstandingSimpleAsynchronous2015,scottEvaluationTimeBiasAsynchronous2015,scottEvaluationTimeBiasQuasiGenerational2016}, in which was shown that there exists an evaluation time bias, i.e., the distribution of the population is biased such that it is correlated with the corresponding evaluation times, such that this bias is not explained by fitness based selection. They note that this bias depends on both the distribution of evaluation times and the number of processors. More specifically, a preference towards both short and long evaluation times on a flat fitness landscape was observed.

Even so, it is difficult to determine based on current literature, when asynchronous execution of an EA is problematic. This is in part due to how comparisons are often performed.
First, the selection procedure is often altered when switching from synchronous to asynchronous, making it impossible to distinguish effects caused by asynchrony from those caused by steady-state selection and variation.
Selection and variation are key aspects of an EA, and should also be considered as an additional influence. Furthermore, in order for effects of time biases to be interpretable, the time distributions of evaluations need to be known as well.
% Removed: besides the point - although it is a problem that I am trying to avoid in this work that occurs in previous works.
% Simultaneously, in order to observe an evaluation time bias that could negatively influence the behavior of the approach, the distribution of evaluation times needs to have particular properties as well. First of all, the distribution must be so that the evaluation times in the population are heterogeneous during a large enough proportion of the run. An especially notable case is if there exists a perfect correlation between fitness and evaluation time of a solution. In this case the evaluation time distribution is proportional to fitness. Yet, selection makes fitness values more homogeneous, thus making the evaluation time distribution more homogeneous too. Furthermore, in~\cite{scottUnderstandingSimpleAsynchronous2015} this evaluation times and fitness were perfectly correlated and no bias (compared to synchronous) was observed.
% Simultaneously, evaluation times don't just need to be heritable as defined by Scott and De Jong in~\cite{scottUnderstandingSimpleAsynchronous2015}, i.e. tied to the genotype, but be local under recombination as well. Without this any evaluation time bias would not be represented by the sampled offspring, even if the evaluation time is fully determined by the genotype. Effectively, as fitness should be local under recombination for good performance too, some correlation between fitness and solution quality should be present. For many works it is unclear whether and to what degree these properties hold.

More generally, for EAs the population size is important as well. Different approaches may require different population sizes to perform best, especially if variation and selection are different. When switching between synchronous and asynchronous the population size should therefore be tuned again to avoid giving preferential treatment to the approach for which the population size was tuned.

Given all of this, we are particularly interested in the impact of selection and variation on the behavior of the EA. Together they induce a bias towards higher fitness solutions in the population. An oversight in how these operators work could very well induce, preserve, or halt evaluation time biases too.

In this work, we will explicitly also consider Model-based Evolutionary Algorithms (MBEAs). Through the use of linkage learning (LL) in MBEAs, variation can be performed based on inferred variable dependencies. This can result in significant performance improvements. 
To our knowledge, no prior work has studied the impact of asynchronous parallelization on MBEAs. Yet this is of interest, LL infers the structure of a problem through the use of the population. If the composition of the population is based not only on the fitness, but also the evaluation time associated with these solutions, then this will also affect the structure learning process. Therefore, while LL is known to improve performance, this could be disrupted by biases, such as evaluation time biases. % acting upon the population
% In contrast, MBEAs use the model to adjust the recombination process. If recombination plays a large role in the development or propagation of these biases, then if the right model is learnt, it could counteract any bias from occurring. For this reason it is unclear to us whether linkage learning will continue to work. Yet, to our knowledge no prior work has investigated this topic.

% \begin{displayquote}
{
\vspace{0.5em}
\noindent Our research questions are therefore:
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  How does selection affect performance, the ability to find a solution with target fitness, under various evaluation time distributions in an asynchronous setting?
\item
  How does variation affect performance under various evaluation time distributions in an asynchronous setting?
\item
  More specifically, how are MBEAs like GOMEA and ECGA affected by the evaluation time distribution when made (a)synchronous parallel?
\end{enumerate}
}
% \end{displayquote}

\noindent The remainder of this work is structured as follows. First, in Section~\ref{sec:approaches} we will describe the EAs used in this work.
Following that, in Section~\ref{sec:problems}, the artificial benchmark functions and the evaluation time distributions used, in addition to a real-world NAS benchmark are described.
The remainder of experimental considerations is described in Section~\ref{sec:experimental-setup}. We discuss the results in Section~\ref{sec:results} and conclude in Section~\ref{sec:conclusion}.

\section{Approaches}\label{sec:approaches}
% In this work we will study the impact of evaluation time biases on performance, and how these biases are influenced by variation and selection. 
In this work, we include a Simple GA as described in Subsection~\ref{ssec:genetic-algorithm-ga}. To study how linkage learning (LL) and evaluation time biases interact, we use both a classic MBEA named the Extended Compact Genetic Algorithm (ECGA) and a modern MBEA named the Gene-pool Optimal Mixing Evolutionary Algorithm (GOMEA) as described in Subsections~\ref{ssec:extended-compact-genetic-algorithm-ecga} and~\ref{ssec:gene-pool-optimal-mixing-evolutionary-algorithm-gomea} respectively.
% As GOMEA combines selection and variation into a single operator named Gene-pool Optimal Mixing (GOM), we cannot easily modify the selection procedure as we will do for the GA. As this would restrict us from investigating the impact of selection.

\subsection{Genetic Algorithm (GA)}\label{ssec:genetic-algorithm-ga}

In previous works, selection in GAs is often altered simultaneously with the (a)synchronous nature of the approach. For example, in~\cite{scottUnderstandingSimpleAsynchronous2015}, the synchronous configuration uses a generational selection scheme, whereas the asynchronous configuration is steady-state. A steady-state configuration exhibits different behavior compared to GAs employing a generational selection scheme \cite{syswerdaStudyReproductionGenerational1991}. We therefore also investigate  a `synchronous' steady-state variant and an asynchronous `generational' approach in addition to the original two configurations. Pseudocode for these approaches can be found in the supplementary material.

For the synchronous steady-state approach we operate in batches of $|P|$ offspring, generating each offspring at the start of the evaluation, and synchronizing until all $|P|$ offspring solutions are sampled and evaluated. Steady-state selection is then performed once the evaluation of an offspring solution is finished. For this we opt to randomly select a solution from the population and replace this solution if it is worse than the newly evaluated offspring solution. This ensures that the population's average fitness cannot decrease, and thus stops any bias contrary of improvement to fitness from taking over the population.
 When using generational selection in an asynchronous setting, every solution that completes evaluation is added into a selection pool first, similar to the approach described in \cite{scottEvaluationTimeBiasQuasiGenerational2016}. Once this pool has reached the prerequisite size, we apply the generational selection operator, replacing the entire population with the end result. We perform generational selection using a Parent + Offspring (P+O) tournament of size 4, where the number of offspring is equal to the population size. Tournaments are created based on shuffling, then by splitting the population in blocks of the tournament size, repeating as often as necessary to select P solutions.

For recombination, we use Uniform Crossover (UX) and Two-point Crossover (TPX). In addition to Subfunction Crossover (SFX) for problems for which subfunction information is available. While UX is included as a baseline, TPX and SFX are included as they suit the structure of at least one of the artificial benchmark functions described in Subsection~\ref{ssec:artificial-benchmark-functions}. Specifically, in SFX each block of variables that forms a subfunction is exchanged with $p=0.5$, perfectly mixing the blocks of the concatenated DT function, whereas TPX is especially suited for the ANKL problem due to its sequential adjacent structure. These operators should showcase how the behavior changes when a well-suited operator is used from the start and throughout the search, also providing an idealized reference for approaches employing LL.

% \vspace*{-3mm}
\subsection{Extended Compact Genetic Algorithm
(ECGA)}\label{ssec:extended-compact-genetic-algorithm-ecga}

ECGA is one of the first approaches employing LL. Unlike GOMEA, explained in the next subsection, this approach still has separate recombination / variation and selection steps. This allows us to use exactly the same selection procedures as for the GA.

With ECGA, a marginal product model (MPM) is learned using a metric based on model complexity and population compression after applying selection \cite{harikLinkageLearningProbabilistic2006}. For this selection step, we apply tournament selection of size $4$. In the resulting model every variable is grouped disjoint subsets, thereby modeling each subset of variables jointly. For example, given MPM $\mathcal{M} = \{\{0, 1\}, \{2, 3\}\}$ and population (after selection) $P_M = {0011, 1100}$, allows us to sample $00$ and $11$ with, for each subset of variables, equal likelihood. Therefore, allowing us to sample $0000$, $0011$, $1100$, and $1111$.
% As the values for variables correlate strongly, the MPM learned will also be more group more variables together. This will result in less diverse offspring and more exploitation. If this happens too quickly, for example due to an evaluation time biases skewing the distribution of the population, this could in the worst case result in premature convergence.
% Variation is then performed by sampling the values for each subset of variables jointly, i.e. such that the values of every subset of variables originates from a single solution from the population on which selection was applied. However, in order to ensure that a meaningful model can be learnt, ECGA generally employs additional selection pressure. As such, on the population used for learning a model, we additionally apply tournament selection of size 4.

Learning a model is costly. Therefore, performing continuous updates of this model for every solution sampled is too computationally expensive to be benchmarked properly. As such, for the asynchronous configuration the model is updated only when \(|P|\) (population size) evaluations finish. Thereby updating the model with the same frequency as the generational approach (generationally).  
While this reduced update frequency should not have too significant an impact on the learning of the MPM, solutions are sampled using out-of-date frequency estimates.

\subsection{Gene-pool Optimal Mixing Evolutionary Algorithm
(GOMEA)}\label{ssec:gene-pool-optimal-mixing-evolutionary-algorithm-gomea}

While ECGA utilizes LL, it does so differently from most modern MBEAs. Modern model-based approaches like P3 ~\cite{goldmanParameterlessPopulationPyramid2014,goldmanFastEfficientBlack2015}, DSGMA-II ~\cite{hsuOptimizationPairwiseLinkage2015,chenTwoedgeGraphicalLinkage2017}, and GOMEA~\cite{dushatskiyParameterlessGenepoolOptimal2021} all use an incremental change and accept/deny mechanism, reminiscent of local search. This allows these approaches to utilize
non-disjoint models, like the Incremental Linkage Set (ILS) in DSMGA and the Linkage Tree (LT) in GOMEA and P3. In this work we will be using the LT, which is constructed through UPGMA hierarchical clustering applied to normalized mutual information (NMI) of the variables in the population.  Each of these models are often represented as a Family of Subsets (FOS), i.e., a list of subsets containing variables to which variation should be applied jointly. For the LT the resulting tree is flattened such that each node in the tree corresponds to a subset of variables. 
% With the FOS being determined by a measure based on population statistics, a skewed distribution of the genotypes in the population will lead to a different LT. Unlike the MPM used in ECGA however, the LT always considers all the single-variable FOS elements.

Variation and selection are performed using Gene-pool Optimal Mixing (GOM). In GOM changes are made to subsets of variables as defined by a Family of Subsets, sampled from the population. After each change solutions immediately compete against their parent. Because of this, changes are evaluated more directly, preventing changes to other variables from being a source of noise for assessing the quality of the current change~\cite{dushatskiyParameterlessGenepoolOptimal2021}. If no change was made to a solution through all steps in GOM, or the strict non-improvement stretch of a solution ($1 + \left\lfloor\log_2(|P|)\right\rfloor$) was reached, Forced Improvements (FI) are applied. FI is GOM where the donor is the current best solution (elitist). If FI fails to improve a solution, the solution is replaced with the current elitist.
% Simultaneously, this competition against the original solution also results in niching behavior. 
While this integrated variation and selection operator prevents us from changing the selection operator, this combined recombination and selection process is interesting in itself. 

\subsubsection{Synchronous} The synchronous approach closely follows the sequential version of GOMEA. Every generation starts with learning a linkage model. Then, an offspring population is made, initially containing a copy of each individual in the population. GOM and potentially FI are then scheduled to be applied in parallel on each of these offspring solutions, leaving the population from which is sampled during GOM, unchanged. When processors are available, and there are still offspring solutions left on which GOM needs to be applied, GOM is applied to of the offspring solutions in parallel. Each application of GOM is scheduled continuously until all involved evaluations have completed. Once GOM (and FI) complete the processor is freed up again. A generation ends once all solutions had GOM applied to it once.

\subsubsection{Asynchronous} When making GOMEA asynchronous, there is no longer a generational offspring population which is generationally improved. Instead, GOM is scheduled to be applied after initialization, and after completing GOM, using a queue. Once a processor has finished its current task, the next task from the queue gets executed. % Specifically, GOM is applied to the solution on top of the queue. 
At the start of (asynchronous) GOM, if GOM has been applied $|P|$ (population size) times, a new FOS is learned. Furthermore, a copy of the population is made. This effectively turns every application of GOM into its own mini-generation.  Consequently, at the end of GOM we copy the generated offspring to the population from which is sampled. We label this configuration "a/e", for \emph{asynchronous end}. However, this configuration leads to significant use of out-of-date information: none of the accepted changes of solutions undergoing GOM are visible to other solutions. As such we also evaluate an alternative configuration that copies the offspring to the shared population at \emph{intermediate} stages during GOM, not just at the end. This configuration is labelled "a/i".

\section{Problems}\label{sec:problems}

Previous work has indicated that heritable heterogeneous evaluation times can negatively influence the behavior of an asynchronous EA~\cite{scottUnderstandingSimpleAsynchronous2015}. Heritable heterogeneous evaluation times concern variations in evaluation time associated with the genotype itself, rather than external factors like machine load. A good example of a problem with this property is training a neural network, which we will discuss in Subsection~\ref{ssec:nasbench-301}.

% However, if the bias observed by Scott and de Jong in~\cite{scottUnderstandingSimpleAsynchronous2015,scottEvaluationTimeBiasAsynchronous2015,scottEvaluationTimeBiasQuasiGenerational2016}
% also occur with different landscapes, then different associations of
% evaluation times to the search space can lead to different solutions
% being preferred and found. In their work they note that a single
% expensive evaluation may finish after many cheap evaluations. Different
% scales of evaluation times can therefore also potentially lead to
% different results and preferences. Having two solutions finish
% evaluation in the time of a single evaluation of another can lead to
% different effects than when 10 solutions finish, or even 100.
However, both the fitness landscape and evaluation times of such a problem are generally complex, which may complicate analysis. We will therefore first describe  benchmark functions with varying kinds of landscapes and structure, for which we will also vary the evaluation times associated with the solutions, in Subsection~\ref{ssec:artificial-benchmark-functions}.

\subsection{Artificial Benchmark
Functions}\label{ssec:artificial-benchmark-functions}
In~\cite{scottUnderstandingSimpleAsynchronous2015} it is indicated that evaluation times need to be heritable, and as such we will focus on this aspect. Similarly, evaluation times need to be preserved under variation too, as otherwise no time bias can develop. Furthermore, in~\cite{scottUnderstandingSimpleAsynchronous2015} settings in which the evaluation cost was perfectly positively and negatively correlated were investigated - and found no significant difference in performance. As any bias contrary to the improvement of fitness would be unlikely to survive selection, performance of an EA is likely not impacted. 
% Furthermore, perfect correlation with fitness will also cause the distribution of evaluation times to be strongly selected upon. As any bias counter to fitness would be unlikely to survive selection, performance of an EA is likely not impacted.  
We therefore select a distribution based on the genotype which is not a simple function of the fitness.

Furthermore, as the results in~\cite{scottEvaluationTimeBiasAsynchronous2015} indicate a bias towards the extreme evaluation times, we will control where in our benchmark functions these extremes are located. The evaluation time setting in this work is expressed as a ratio \(a:b\), where $b$ is the cost of the optimum \(s^{*}\) and $a$ is the cost of the bitwise complement \(\bar{s^{*}}\) - i.e., the solution with all bits flipped. The evaluation time \(E(s)\) of a solution $s$, given the normalized Hamming distance \(H(s,\ s^{*})\) between this solution $s$ and the optimum $s^{*}$ is then:
\begin{align}
E(s) = H\left( s,\ s^{*} \right)\ a + \left( 1 - H\left( s,s^{*} \right) \right)\ b
\end{align}
% The Hamming distance is likely to be preserved by most common crossovers as each bit has its own corresponding contribution, this ensures that evaluation times are local. Meanwhile, this also results in evaluation times that are not perfectly correlated with our benchmark functions.
We choose to use the ratios $100:1$, $10:1$, $2:1$, $1:1$, $1:2$, $1:10$ and $1:100$, that is, ranging from a cheaper optimum to a more expensive optimum.
% This is to capture both differences in scale, i.e. the number of solutions that can evaluate during a more expensive evaluation, and to study the setting in which optimum is cheaper or more expensive than all other solutions.

%{[}Note on linearity \& proximity to optimum != good predictor for fitness necessarily.{]}

\subsubsection{Concatenated Deceptive Trap
(DT)}\label{ssec:concatenated-deceptive-trap-dt}

The first problem we will use is the concatenated DT
function~\cite{debSufficientConditionsDeceptive1994, whitleyFundamentalPrinciplesDeception1991}. It consists of \(n\) blocks of size \(k\) which are concatenated together, forming a full string of length $\ell = nk$. In this work, we will only consider the case for \(k = 5\). 
In order to evaluate the function, first the number of `1' bits within the block \(b\) is counted. Following that, the \(DT\) function is applied to the unitation of each block $0$ through $n - 1$ and aggregated by summation:
\begin{align}
DT(u) &= \left\{ \ \begin{matrix}
k & u = k \\
k - u - 1 & \text{otherwise} \\
\end{matrix} \right.\\\
f(x) &= \sum_{b=0}^{n-1}{DT\left(\sum_{i=bk}^{bk+k-1}x_i\right)}
\end{align}

% As the second expression holds for the largest portion of the search space, and 
As there are many search paths indicating that more zeroes is better, high-fitness solutions consisting of zeroes are easiest to find. The solution consisting of all zeroes is referred to as the deceptive attractor. Yet, the needle in a haystack where \(u = k\), has better fitness: \(k\) as opposed to \(k - 1\) for the deceptive attractor. It is therefore all ones that is actually the optimum to this function. In order to solve this problem in a scalable manner, variables should be exchanged at the level of these blocks~\cite{thierensScalabilityProblemsSimple1999}, for example by recognizing block structure by using linkage learning. 

% While for a single block of variables finding this optimum by chance is feasible for small k (\(p = 2^{- k}\)), this does not hold for a full string consisting of these blocks: one would need to find the exact solution within the search space. Recombining uniformly does not help, as only a single zero from another solution is enough to break the needle of the respective block. Only if one recombines on the level of full blocks will there be a search path towards the solution consisting of all ones, the optimum.

The complement of the optimum to this problem consists of all zeroes, and is the solution consisting of only attractors. We have defined the range of evaluation times depending on these two solutions. A preference towards cheaper solutions could therefore make a cheap-to-evaluate attractor even more attractive.
% - This correlation is an important point referring to the issue described above, but I'll leave it be - not too important:
% Therefore, even as fitness increases, evaluation times will stay heterogeneous.

\subsubsection{Adjacent NK-Landscapes
(ANKL)}\label{sssec:adjacent-nk-landscapes-ankl}

While the (additively decomposable) concatenated DT function is difficult to solve with a local searcher, it is separable. This makes the problem easy to solve if the separability is known, or when this separability can be inferred. We therefore also consider the non-separable problem of ANKL. This problem consists of overlapping blocks consisting of \(k\) adjacent variables with some stride \(s\) from block to block. In this work, we consider \(k = 5\) and \(s = 2\). For each block $i$ a randomly generated function $f_i$ is defined that maps each genotype of this block to a value ranging from $[0, 1]$. Given random functions \(f_{0}\) through \(f_{n-1}\), where $x$ is a genotype of length $\ell = sn+k-1$:
\begin{align}
f(x) = \sum_{i = 0}^{n-1}{f_{i}\left( x_{si},\ldots, \ x_{si + k - 2},\ x_{si + k - 1} \right)}
\end{align}
% Similar to the deceptive trap function, the random nature of each of these subfunctions will generally make it more difficult to find the optimum. Unlike the Deceptive Trap function, the distance between the optimum and any other local optima is not necessarily maximal. Furthermore, due to overlap between subfunctions the optima of each subfunction do not necessarily compose together, i.e. the optimum of a subfunction \(f_{i}\) is not necessarily part of the optimum of \(f\).

Due to this more complex overlapping structure as well as the random nature of the subfunctions, it will be more difficult for the linkage learning approaches to configure the linkage model appropriately. As a result, such approaches require more generations to obtain a suitable model. This may therefore provide more time for any evaluation-time biases to steer the population towards or away from the optimum, potentially causing structure to be found earlier, or preventing the structure from being found at all.

\subsection{NASBench 301}\label{ssec:nasbench-301}

While benchmark functions are interesting and useful for analysis, they are not necessarily representative of practical problems. Real-world problems often contain elements that simpler benchmark functions do not  account for.

We will therefore apply the aforementioned approaches to the Neural Architecture Search benchmark NASBench 301~\cite{zelaSurrogateNASBenchmarks2022}. NASBench 301 is a benchmark for neural architecture search applied to the DARTS search space. In this search space, each network is trained from scratch. In order to make this less expensive as a benchmark, the benchmark provides both a surrogate model for the fitness and the corresponding evaluation time. This allows for an efficient simulation of a run on this problem without requiring a GPU for hours.

We use version 0.9 of the XGB surrogate model for performance and LGB model for runtime. As noisy objective functions are not a subject of research for this work, we have disabled noise for the performance model. For this experiment only the runtime model is used as an evaluation time distribution. The runtime model does not contain noise. 

% Other Notes

\section{Experimental Setup}\label{sec:experimental-setup}
For all problems, a run using a specific population size is stopped if it has reached the target value, or if it has converged, i.e., when all genotypes in the population are identical. As there will be configurations and problem pairs for which the target value is not reached within a reasonable amount of time, for each set of problems, we will also be limiting the amount of time spent on a full bisection run. If bisection was terminated prematurely we will select the smallest successful population size found by bisection within the time limit.

Statistical tests are performed using the Mann-Whitney U-test~\cite{mannTestWhetherOne1947,fayWilcoxonMannWhitneyTtestAssumptions2010} with $p=0.05$ with Holm-Bonferroni~\cite{holmSimpleSequentiallyRejective1979} correction where applicable. All experiments are carried out on a machine with two AMD EPYC 7282 16-Core Processors \@ 2.8GHz, with 252~GB of RAM. Source code will be made available.


\subsection{Artificial Benchmark Functions}
Prior work~\cite{scottUnderstandingSimpleAsynchronous2015,scottEvaluationTimeBiasAsynchronous2015,scottEvaluationTimeBiasQuasiGenerational2016} investigated the distribution of evaluation times. However, if an approach is influenced such that the distribution of evaluation times is biased, this does necessarily indicate a negative impact on the performance of an approach, like the time required to reach the optimum. We will focus on performance under various evaluation time configurations.

However, using standard performance metrics is problematic. When using the number of evaluations required to reach a target fitness, synchronous approaches are favored as waiting does not incur any penalty, whereas utilizing these resources with additional evaluations does count as additional evaluations. For our first experiment, we will be changing the distribution of evaluation times, and compare all investigated distributions. Using the wall time in this comparison is problematic as the total wall time spent will change with the distribution. For example, scaling all evaluation times by $10$ will not change the evaluation times with respect to one another. As such a run will proceed identically, except with evaluation times that are $10$ times larger. For more complex distributions it would be hard to say whether the approach is actually negatively affected by the change in evaluation times, or whether the solutions to be evaluated are more costly.

We instead choose a measure that stays constant if behavior is the same, yet still indicates when performance worsens. For this we use the minimally required population size to reach a target value as determined by bisection. This measure works for a convergent EA as the population acts as a buffer for diversity loss, the larger the population the longer it takes for biases to take over the population. If a bias leads to a decrease in diversity such that the target fitness is no longer reached, increasing the population size will likely allow for solving the problem again (assuming no limits are hit).
% Bisection will determine the minimal population size required. An increase in this value is indicative that reaching the target fitness is more difficult, whereas a decrease indicates that the problem has become easier.

Furthermore, we will perform these first experiments with the number of processors equal to \(|P|\) (the population size) as this maximizes the degree of parallelization proportional to the number of evaluations performed. Additionally, given this setting, the evaluations with a fast evaluation time will also be the first to complete, which is not guaranteed with low degrees of parallelization.

The minimally required population size cannot be readily compared across different approaches for performance. 
% For example, an approach \(a\) may perform more evaluations for each member of the population than another approach \(b\).
Even if an approach has a smaller minimally required population size it may still perform more evaluations and spend more time finding the optimum than another approach. Furthermore, the number of times offspring are generated also impacts the amount of used resources. Yet as before, measuring this invariant to the evaluation time distribution is difficult. Instead, we compare how the minimally required population size scales across varying evaluation time distributions.

For these experiments, each configuration will be evaluated for 100 random seeds, with each bisection run limited to 1 hour. This is orders of magnitude more than what most approaches need, and ensures even the worst performing algorithms have a chance.

\subsection{NASBench 301}
While comparing how approaches scale across different time distributions will allow us to study the impact of evaluation time biases, a practical problem often only has a single evaluation time distribution associated with it. Furthermore, the amount of computational hardware available is not unbounded in practice. If this were not the case, one could evaluate the entire search space in parallel at the cost of the most expensive solution. A more practical goal for parallelization for a specific problem is to minimize the amount of wall time spent to hit a target fitness given a limited amount of resources. As we only regard a single evaluation time distribution, aforementioned concerns do not apply to the NASBench 301 experiment.

Therefore, for the NASBench 301 experiment we will run experiments for the simulated wall time required to reach a target value. Here, first a range bounding this minimal evaluation time is determined, followed by a modified golden section search~\cite{kieferSequentialMinimaxSearch1953}, detailed further in the supplementary material. This is to find the population size that minimizes the corresponding wall time to ensure that each approach can be compared fairly.

% This search starts off with finding a population size \(P_{1}\) for which the problem is solved, followed by evaluating the time necessary for a population twice the size \(P_{2} = 2P_{1}\). If the time required to solve the problem at this population size is larger, we can immediately continue with the triplet \((P_{0} = \frac{P_{1}}{2},P_{1},P_{2})\). Otherwise, we continue doubling \(P_{1}\) until this is the case. Given the triplet \((P_{0},\ P_{1},\ P_{2})\) of population sizes, we sample \(P_{3}\) at \(\frac{1}{3}\) or \(\frac{2}{3}\) between \(P_{0}\) and \(P_{2}\), such that it lies in the longest segment between \((P_{0},\ P_{1})\) or \(\left( P_{1},\ P_{2} \right)\), respectively. If the time required for \(P_{3}\) is greater than \(P_{1}\), we continue with the triplet \((P_{0},\ P_{1},\ P_{3})\), otherwise we continue with \((P_{1},P_{3},\ P_{2})\). The algorithm terminates with \(P_{1}\ \)if there are no new unevaluated population sizes between \(P_{0}\) and \(P_{2}\).
For this experiment the number of processors is restricted to 64. Each configuration is evaluated for 20 different random seeds for at most 16 hours, due to the more costly nature of using the surrogate over a benchmark function. As in preliminary experiments this time limit was found to be insufficient due to wasting a significant amount of time on small population sizes, we additionally require an improvement to be found every \(2e + 10P\) evaluations, where \(e\) is the number of evaluations issued at the last improvement and \(P\) is the population size.

% \vspace*{-5mm}
\section{Results and Discussion}\label{sec:results}
\begin{figure*}[tbp]
    \centering
    % \includegraphics[width=1.0\textwidth]{figures/2023-01-06-plot-async-both-scatter-inc-fails-log.pdf}
    \vspace{-0.5em}
    \includegraphics[width=1.0\textwidth]{figures/2023-01-11-plot-async-both-scatter-inc-fails-log-w.pdf}
    \vspace{-2em}
    \caption{Correlation between time distribution and minimally required population size, with to the left the optimum being cheaper and to the right the optimum being more expensive than its complement. All runs are plotted as a point with opacity. Only asynchronous configurations are shown. For the creation of the regression lines we assume that failed runs used the maximum population size tested and are not drawn if more than half of the runs did not find the optimum. (Left: Concatenated DT $l=50$, $k=5$, Right: ANKL $l=40$, $s=2$, $k=5$)}
    \label{fig:async-regression}
\end{figure*}

\begin{table*}[tbp]
    \centering
    \vspace{-0.5em}
    \caption{Median minimally required population size on DT for $\ell=50$, $k=5$. Extended table in supplementary material.}
    \label{tab:table-dt}
    % tabulararray is not supported on arxiv due to outdated LaTeX - use prerendered table instead.
    % \include{tables/results-deceptive-trap-tblr.tex}
    \includegraphics{tables/results-deceptive-trap-tblr-crop.pdf}
\end{table*}
\begin{table*}[tbp]
    \centering
    \vspace{-0.5em}
    \caption{Median minimally required population size for ANKL for $\ell=40$, $s=2$, $k=5$. Extended table in supplementary material.}
    \label{tab:table-ankl}
    % tabulararray is not supported on arxiv due to outdated LaTeX - use prerendered table instead.
    % \include{tables/results-adjacent-nk-landscapes-tblr.tex}
    \includegraphics{tables/results-adjacent-nk-landscapes-tblr-crop.pdf}
\end{table*}
% Table moved from nasbench section.
\begin{table*}[tbp]
  \centering
  \vspace{-0.5em}
  \caption{Median of minimally required amount of time to find a solution with an accuracy of 95.2727 or higher on NASBench 301 and corresponding median population size. Sample count is even, median is midpoint average.}
  \label{tab:table-nasbench}
  % tabulararray is not supported on arxiv due to outdated LaTeX - use prerendered table instead.
  % \include{tables/results-nasbench301-tblr.tex}
  \includegraphics{tables/results-nasbench301-tblr-crop.pdf}
\end{table*}

First, we will discuss the results on the artificial benchmark functions (Table~\ref{tab:table-dt} for DT and Table~\ref{tab:table-ankl} for ANKL). After this, we will discuss the results on
NASBench 301.

\subsection{Artificial Benchmark Functions} From Figure~\ref{fig:async-regression} it is apparent that asynchronous configurations experience an evaluation time bias that leads to a change in behavior. Specifically, the required population size is lower when the optimum is cheaper, i.e., is faster to evaluate, and larger when the optimum is more expensive, i.e., takes longer to evaluate. Simultaneously, synchronous approaches are invariant to the distribution of evaluation times investigated. This is in line with what would be expected based on the results in literature~\cite{scottUnderstandingSimpleAsynchronous2015,scottEvaluationTimeBiasAsynchronous2015,scottEvaluationTimeBiasQuasiGenerational2016}.

However, the extent of the differences in minimally required population size is highly dependent on the crossover used. When the most suitable crossover is used, i.e., SFX for DT and TPX for ANKL, the differences between the timing settings are small. At the same time, when an unsuitable crossover is used, differences in required population size range \emph{across orders of magnitude}. In the worst case, the problem is not solved within the allotted time for more expensive optima, as such evaluation time biases can negatively impact the performance of an approach.

The selection method can also impact how the approach scales across different evaluation time settings.
For example, on ANKL the asynchronous steady-state GAs with UX and SFX degrade substantially, even to the point of failure, whereas the same GA, but with a (pseudo-)generational scheme degrades substantially less, by at most a factor 5. Yet, with the right crossover, steady-state actually has a smaller minimally required population size, and degradation between both configurations is at most a factor of 2.

We conjecture that this is caused by the following. In a steady-state approach the solution is immediately integrated into the population.
Additionally, it is also immediately available to be used by crossover to generate new offspring. These offspring are now more likely to be fast evaluating solutions, depending on how well variation will preserve the evaluation time of a solution. This effect can accumulate over time, leading to premature convergence.

On the other hand, in a generational scheme these solutions are not immediately integrated into the population. Newly generated offspring are hence distributed according to the original distribution of solutions -- with less evaluation time bias affecting them.
Simultaneously, solutions with longer evaluation times will take longer for a processor to evaluate. During this time, no other solutions will be sampled for evaluation on this processor. In effect, the pool of currently evaluating solutions performs selection against short evaluation times. This will cause the amount of resources allotted to fast evaluating solutions to be lower. Finally, this results in less accumulation of evaluation time bias towards fast evaluating solutions, avoiding premature convergence towards such solutions.

Variation also has a notable impact on the impact of evaluation times. When variation aligns with the problem's structure, the different selection schemes unexpectedly scale similarly across evaluation time settings.
% Therefore, while both selection and crossover play key roles in how an EA will behave if made asynchronous. 
Picking the right crossover operator will help with avoiding significant degradation for asynchronous approaches, even if the approach is in a steady-state configuration.
% As such, automatically learning how to perform crossover could also be a large step towards improving performance and reliability for asynchronous approaches.

These results are promising for MBEAs because in MBEAs problem structure is automatically learned to inform its variation operator. One could therefore expect performance to always be reasonable, resulting in the precise selection scheme mattering less.

Before we discuss the results for ECGA, we repeat that ECGA's steady-state configuration is not truly steady-state, but only applies steady-state like selection. This is because ECGA only updates its model once \(|P|\) (population size) solutions finish evaluating, as stated in
Section~\ref{ssec:extended-compact-genetic-algorithm-ecga}. This results in an approach with behavior more closely resembling that of the generational approach. The differences between the two selection methods is negligible if the distribution updates less frequently, as is the case for ECGA.
% Therefore, a comparison against the steady-state GAs may not be as suitable in this case.

First of all, there is the oddity that the constant time distribution requires a larger population size in order to find the optimum than the other asynchronous configurations for ECGA. The required population size is more in line with the synchronous configuration than the other time distributions. We explain this as follows. In an asynchronous setting with heterogeneous evaluation times, after the first few solutions finish evaluation, not enough solutions have finished evaluation yet to update the model. As such, the next solutions to be evaluated are still sampled from the initial random model.
These solutions are therefore additional random solutions. Conversely, in the case where the evaluation time distribution is constant, all evaluations finish at the same time. This results in the model being updated. Therefore, the next solutions to be evaluated on the freed up processors, will be sampled using an \emph{updated} model, potentially with some (evaluation time) bias.

After a model update, only the solutions that are currently being evaluated can originate from an older model. There are at most "number of processors" such solutions.
In the case of the experiments above, this would be equal to the population size. This is reflected in the results: the minimally required population size is approximately twice as big, only for the constant evaluation time. The set of solutions that are currently evaluating may therefore act like an extension of the population itself.

When observing how ECGA's minimally required population size scales for different evaluation time settings in Figure~\ref{fig:async-regression}, note that it scales worse compared to a GA with a suitable crossover for ANKL, and even with a non-suitable crossover with generational selection. Variation is more than the subsets of variables that are captured in the MPM model. How the model is used is just as important. In this case, the global sampling for each subset seems to be worse than the recombinative crossover of a GA. In conclusion, though not necessarily the fault of LL, LL within an MBEA is no guarantee that variation will perform well. 
% Yet, as a model is learned from the population the initial model is seemingly not as suitable as this predetermined crossover, resulting in an increased impact of evaluation time biases in the time period until suitable model is learned.

In contrast to ECGA and the GAs, GOMEA is found to be invariant to the evaluation time setting in most cases. There exists only a single time setting and problem combination for GOMEA for which the medians are statistically significantly different from the rest: 'a/e' on DT for 1:100, see Table~\ref{tab:table-dt}.
%The most similar time configuration is 1:2 (with $p=0.004$ and $U=3813$, $100$ samples).
This is likely due to the combined variation and selection method used in GOMEA. As changes are made to individuals, they only compete against their parent. When parent and offspring are similar in evaluation time, this automatically results in niching behavior with respect to the evaluation times of solutions. In comparison to global selection, this approach stops solutions that evaluate quicker from taking over the population, in effect removing a large source of evaluation time bias.
% TODO: Keep? Remove?
% We will however indicate that this combined variation and selection operator is inherently sequential and performs many evaluations. The inclusion of such an operator causes approaches like GOMEA to not parallelize to the same degree per evaluation as the GA or ECGA.

% Begin: NASBench 301
% Table moved up - next to the other tables.
% \begin{table*}[tbp]
%     \centering
%     \caption{Median of minimally required amount of time to find a solution with accuracy of 95,2727 or higher on NASBench 301 and corresponding population size.}
%     \label{tab:table-nasbench}
%     \include{tables/results-nasbench301-tblr.tex}
% \end{table*}
\begin{figure}[bt] %h?
    \centering
    % \includegraphics{figures/scatter-eval-acc-nasbench.png}
    \includegraphics[width=0.8\columnwidth]{figures/2023-01-05-hexdensity-nasbench.pdf}
    \caption{Objective (accuracy of the trained network) versus evaluation time sampled by runs of the approaches for NASBench 301. Showing the experienced correlation between the two for the approaches.}
    \label{fig:scatter-eval-time-acc-nasbench}
\end{figure}

\subsection{NASBench 301} For NASBench 301 the distribution of the objective and evaluation time of a solution is shown in Figure~\ref{fig:scatter-eval-time-acc-nasbench}. From the positive correlation and observations on the benchmarks one would expect to see asynchronous configurations to be outperformed by their corresponding synchronous approaches. Yet, if one refers to Table~\ref{tab:table-nasbench}, this is not the case. As a matter of fact, some of the best performing approaches are asynchronous.
We explain this as follows.

Referring to Figure~\ref{fig:scatter-eval-time-acc-nasbench}, one may note that the correlation is not perfect. The target solution for this problem is not actually the most expensive or least expensive solution, as was the case for the artificial benchmark functions.
Additionally, an EA does not utilize all of these solutions simultaneously. If we look at the correlation from a particular fitness value onwards, i.e., truncating the population, the correlation decreases as this fitness threshold increases.
Eventually, this correlation even becomes slightly negative for these data points: a setting which would actually be considered beneficial for steady-state asynchronous GAs based on our previous results.

For ECGA this is particularly notable. The approach itself is known to have trouble working with certain multi-modal functions~\cite{chuangMultivariateMultimodelApproach2010}, and it seems NASBench 301 is among these problems. Even so, the asynchronous approach has runs in which a solution with at least the target fitness was found, whereas the synchronous approach does not. This could be due to evaluation time biases helping the approach, much like what happens with the asynchronous steady-state GA for ANKL. It is therefore plausible that evaluation time biases may in part be responsible for the improvements in performance observed for asynchronous approaches, rather than only the improvements in throughput.

Furthermore, we have observed ECGA to prematurely merge FOS elements together on NASBench 301. As the model is unlikely to merge variables if they are not correlated, such a merge seems to only further reinforce correlation for this problem. Combined with the high selection pressure, this is likely to result in premature convergence to a single mode. In contrast, the linkage tree used in GOMEA does not suffer from this issue. The LT FOS always includes the univariate FOS elements: subsets with each variable on their own. Combined with the niching behavior described above, this significantly reduces the possibility of premature convergence no matter the source.

This further reinforces that an MBEA not only has to learn the right linkage from the population, but also use it in the right manner. 

For GOMEA we would expect a difference between the time required for the synchronous and asynchronous approach. Since with GOM many similar variation steps are done to a single solution sequentially, the variance in evaluation times is potentially amplified. Furthermore, population sizes are relatively small compared to the GA and ECGA. We would therefore expect the throughput for asynchronous GOMEA to be considerably higher, and as such the time required to be lower.

However, no statistically significant difference in time between the \emph{a}synchronous/e and \emph{s}ynchronous approach is observed ($p=0.52$, $U=224$, $20$ samples). Furthermore, a more detailed investigation of a single run does indicate that the amount of time spent idle for the synchronous approach is notable, on average $140059$s per processor over the entire run. In contrast, there is a statistically significant difference for the time required between the asynchronous/i and synchronous approach ($p=0.007 < 0.05$, $U=100$, $20$ samples). Effectively, when using outdated parents, offspring are more likely to have a lower fitness value. This degrades the performance of the approach, counteracting any gains in throughput.

For an asynchronous MBEA to actually gain performance compared to its synchronous counterpart, model updates should not be too infrequent and material with which is recombined should be recent. GOMEA could still be improved in this regard: each run of GOM keeps a copy of the population for sampling. As this population was created at the start of GOM, prior to the first evaluation, this population will gradually become outdated. Updating this population during GOM could result in recombination with more up-to-date solutions, potentially further improving performance.

%Synchronizing ensures that solutions are always recent at the cost of waiting. Yet, for an asynchronous EA this is an aspect that needs to be accounted for in the design.
% Potential addition : both consistently solve the problem

\section{Conclusions}\label{sec:conclusion}

% From our results we can conclude that variation and selection have a key influence on the influence of heterogeneous evaluation times on an asynchronous EA. Regarding RQ 1 and 2, the impact of selection and variation, 
Answering RQ 1, we have observed that steady-state asynchronous EAs are much more vulnerable to the biases induced by heterogeneous evaluation times, compared to asynchronous EAs using a generational scheme.
Furthermore, answering RQ 2, when paired with a variation operator that is not competent in terms of improving fitness, the impact on an algorithm's capability to solve a problem can be severe. In contrast, when using well suited variation and selection operators, any differences between synchronous and asynchronous configurations become much smaller. 

For the first time we have investigated the impact of heterogeneous evaluation times on parallel MBEAs and linkage learning (LL).
The addition of LL promises to automatically align a variation operator with the structure of a problem. However, answering RQ 3, there are significant differences in the impact of evaluation times on the performance of ECGA, and GOMEA. While LL is not affected to the extent that evaluation time biases prevent the approach from finding high quality solutions, its performance greatly depends on how variation and selection are performed.

Finally, rather than negatively impacting the results, LL, when paired with the right variation and selection scheme can be a useful tool for obtaining good performance in general, even when an EA is asynchronous. GOMEA is an example of such an EA. GOMEA gets selection and variation right for all the problems evaluated, and is invariant to the choice between a synchronous or asynchronous configuration.
% Applying a similar operator for other approaches may be beneficial as well.

\begin{acks}
This publication is part of the project "DAEDALUS - Distributed and Automated Evolutionary Deep Architecture Learning with Unprecedented Scalability" with project number \grantnum{NWO}{18373} of the research programme \grantnum{NWO}{Open Technology Programme} which is (partly) financed by the \grantsponsor{NWO}{Dutch Research Council (NWO)}{}. Other financial contributions as part of this project have been provided by 
\grantsponsor{CElekta}{Elekta AB}{}
 and 
\grantsponsor{CORTECLC}{Ortec Logiqcare B.V.}{}.
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliography.bib}

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
