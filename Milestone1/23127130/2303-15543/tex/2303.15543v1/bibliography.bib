@inproceedings{albaAnalysisSynchronousAsynchronous1999,
  title = {An Analysis of Synchronous and Asynchronous Parallel Distributed Genetic Algorithms with Structured and Panmictic {{Islands}}},
  booktitle = {Parallel and {{Distributed Processing}}},
  author = {Alba, Enrique and Troya, Jos{\'e} Ma},
  editor = {Rolim, Jos{\'e} and Mueller, Frank and Zomaya, Albert Y. and Ercal, Fikret and Olariu, Stephan and Ravindran, Binoy and Gustafsson, Jan and Takada, Hiroaki and Olsson, Ron and Kale, Laxmikant V. and Beckman, Pete and Haines, Matthew and ElGindy, Hossam and Caromel, Denis and Chaumette, Serge and Fox, Geoffrey and Pan, Yi and Li, Keqin and Yang, Tao and Chiola, G. and Conte, G. and Mancini, L. V. and M{\'e}ry, Domenique and Sanders, Beverly and Bhatt, Devesh and Prasanna, Viktor},
  year = {1999},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {248--256},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/BFb0097906},
  abstract = {In a parallel genetic algorithm (PGA) several communicating nodal GAs evolve in parallel to solve the same problem. PGAs have been traditionally used to extend the power of serial GAs since they often can be tailored to provide a larger efficiency on complex search tasks. This has led to a considerable number of different models and implementations that preclude direct comparisons and knowledge exchange. To fill this gap we begin by providing a common framework for studying PGAs. This allows us to analyze the importance of the synchronism in the migration step of parallel distributed GAs. We will show how this implementation issue affects the evaluation effort as well as the search time and the speedup. In addition, we consider popular evolution schemes of panmictic (steady-state) and structured-population (cellular) GAs for the islands. The evaluated PGAs demonstrate linear and even super-linear speedup when run in a cluster of workstations. They also show important numerical benefits when compared with their sequential counterparts. In addition, we always report lower search times for the asynchronous versions.},
  isbn = {978-3-540-48932-0},
  langid = {english}
}

@inproceedings{chenTwoedgeGraphicalLinkage2017,
  title = {Two-Edge Graphical Linkage Model for {{DSMGA-II}}},
  booktitle = {Proceedings of the {{Genetic}} and {{Evolutionary Computation Conference}}},
  author = {Chen, Ping-Lin and Peng, Chun-Jen and Lu, Chang-Yi and Yu, Tian-Li},
  year = {2017},
  month = jul,
  series = {{{GECCO}} '17},
  pages = {745--752},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3071178.3071236},
  url = {http://doi.org/10.1145/3071178.3071236},
  urldate = {2022-04-06},
  abstract = {DSMGA-II, a model-based genetic algorithm, is capable of solving optimization problems via exploiting sub-structures of the problem. In terms of number of function evaluations (NFE), DSMGA-II has shown superior optimization ability to LT-GOMEA and hBOA on various benchmark problems as well as real-world problems. This paper proposes a two-edge graphical linkage model, which customizes recombination masks for each receiver according to its alleles, to further improve the performance of DSMGA-II. The new linkage model is more expressive than the original dependency structure matrix (DSM), providing far more possible linkage combinations than the number of solutions in the search space. To reduce unnecessary function evaluations, the two-edge model is used along with the supply bounds from the original DSM. Some new techniques are also proposed to enhance the model selection efficiency. Combining these proposed techniques, the empirical results show an average of 12.2\% NFE reduction on eight benchmark problems compared with the original DSMGA-II.},
  isbn = {978-1-4503-4920-8}
}

@inproceedings{chuangMultivariateMultimodelApproach2010,
  title = {Multivariate Multi-Model Approach for Globally Multimodal Problems},
  booktitle = {Proceedings of the 12th Annual Conference on {{Genetic}} and Evolutionary Computation},
  author = {Chuang, Chung-Yao and Hsu, Wen-Lian},
  year = {2010},
  month = jul,
  series = {{{GECCO}} '10},
  pages = {311--318},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1830483.1830544},
  url = {https://doi.org/10.1145/1830483.1830544},
  urldate = {2023-02-10},
  abstract = {This paper proposes an estimation of distribution algorithm (EDA) aiming at addressing globally multimodal problems, i.e., problems that present several global optima. It can be recognized that many real-world problems are of this nature, and this property generally degrades the efficiency and effectiveness of evolutionary algorithms. To overcome this source of difficulty, we designed an EDA that builds and samples multiple probabilistic models at each generation. Different from previous studies of globally multimodal problems that also use multiple models, we adopt multivariate probabilistic models. Furthermore, we have also devised a mechanism to automatically estimate the number of models that should be employed. The empirical results demonstrate that our approach obtains more global optima per run compared to the well-known EDA that employs the same class of probabilistic models but builds a single model at each generation. Moreover, the experiments also suggest that using multiple models reduces the generations spent to reach convergence.},
  isbn = {978-1-4503-0072-8}
}

@inproceedings{churchillToolSequenceOptimization2013,
  title = {Tool Sequence Optimization Using Synchronous and Asynchronous Parallel Multi-Objective Evolutionary Algorithms with Heterogeneous Evaluations},
  booktitle = {2013 {{IEEE Congress}} on {{Evolutionary Computation}}},
  author = {Churchill, Alexander W. and Husbands, Phil and Philippides, Andrew},
  year = {2013},
  month = jun,
  pages = {2924--2931},
  issn = {1941-0026},
  doi = {10.1109/CEC.2013.6557925},
  abstract = {Selecting the sequence of tools to use for the rough machining of components is an important task in manufacturing, which greatly affects the overall machining time and cost of the process. In this paper a multi-objective approach is presented, which supports the use of tools with different geometrical properties and offers the process planner a set of Pareto optimal solutions. An industrial simulator is employed, which allows important information to be captured in the model but has the disadvantage of being computationally expensive. A master/slave approach to parallelization is implemented, which can be used on existing grid or cloud computing infrastructures. Synchronous generational and asynchronous steady-state multi-objective algorithms are compared on their search performance and runtimes on two components. Particular attention is paid to potential problems faced by asynchronous search caused by heterogeneous evaluation times due to characteristics present in individual tool sequences. Results show that the algorithms achieve a similar search performance, with the synchronous algorithm occasionally finding a slightly more diverse spread of solutions. However, the asynchronous algorithm is considerably faster, and provides good solutions in a short runtime that means this approach could be easily and inexpensively implemented in an industrial setting.}
}

@article{debSufficientConditionsDeceptive1994,
  title = {Sufficient Conditions for Deceptive and Easy Binary Functions},
  author = {Deb, Kalyanmoy and Goldberg, David E.},
  year = {1994},
  month = dec,
  journal = {Annals of Mathematics and Artificial Intelligence},
  volume = {10},
  number = {4},
  pages = {385--408},
  issn = {1573-7470},
  doi = {10.1007/BF01531277},
  url = {https://doi.org/10.1007/BF01531277},
  urldate = {2022-02-02},
  abstract = {This paper finds sufficient conditions for fully or partially deceptive binary functions by calculating schema average fitness values. Deception conditions are first derived for functions of unitation (functions that depend only on the number of 1s in the string) and then extended for any binary function. The analysis is also extended to find a set of sufficient conditions for fully easy binary functions. It is found that the computational effort required to investigate full or partial deception in a problem of sizel using these sufficient conditions isO(2l) and using all necessary conditions of deception isO(4l). This calculation suggests that these sufficient conditions can be used to quickly test deception in a function. Furthermore, it is found that these conditions may also be systematically used to design a fully deceptive function by performing onlyO(l2) comparisons and to design a partially deceptive function to orderk by performing onlyO(kl) comparisons. The analysis shows that in the class of functions of unitation satisfying these conditions of deception, an order-k partially deceptive function is also partially deceptive to any lower order. Finally, these sufficient conditions are used to investigate deception in a number of currently-used deceptive problems.},
  langid = {english}
}

@incollection{durilloEffectSteadyStateSelection2009,
  title = {On the {{Effect}} of the {{Steady-State Selection Scheme}} in {{Multi-Objective Genetic Algorithms}}},
  booktitle = {Evolutionary {{Multi-Criterion Optimization}}},
  author = {Durillo, Juan J. and Nebro, Antonio J. and Luna, Francisco and Alba, Enrique},
  editor = {Ehrgott, Matthias and Fonseca, Carlos M. and Gandibleux, Xavier and Hao, Jin-Kao and Sevaux, Marc},
  year = {2009},
  volume = {5467},
  pages = {183--197},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-01020-0_18},
  url = {http://link.springer.com/10.1007/978-3-642-01020-0_18},
  urldate = {2022-12-22},
  isbn = {978-3-642-01019-4 978-3-642-01020-0}
}

@article{dushatskiyParameterlessGenepoolOptimal2021,
  title = {Parameterless {{Gene-pool Optimal Mixing Evolutionary Algorithms}}},
  author = {Dushatskiy, Arkadiy and Virgolin, Marco and Bouter, Anton and Thierens, Dirk and Bosman, Peter A. N.},
  year = {2021},
  month = sep,
  eprint = {2109.05259},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2109.05259},
  urldate = {2022-01-28},
  abstract = {When it comes to solving optimization problems with evolutionary algorithms (EAs) in a reliable and scalable manner, detecting and exploiting linkage information, i.e., dependencies between variables, can be key. In this article, we present the latest version of, and propose substantial enhancements to, the Gene-pool Optimal Mixing Evoutionary Algorithm (GOMEA): an EA explicitly designed to estimate and exploit linkage information. We begin by performing a large-scale search over several GOMEA design choices, to understand what matters most and obtain a generally best-performing version of the algorithm. Next, we introduce a novel version of GOMEA, called CGOMEA, where linkage-based variation is further improved by filtering solution mating based on conditional dependencies. We compare our latest version of GOMEA, the newly introduced CGOMEA, and another contending linkage-aware EA DSMGA-II in an extensive experimental evaluation, involving a benchmark set of 9 black-box problems that can only be solved efficiently if their inherent dependency structure is unveiled and exploited. Finally, in an attempt to make EAs more usable and resilient to parameter choices, we investigate the performance of different automatic population management schemes for GOMEA and CGOMEA, de facto making the EAs parameterless. Our results show that GOMEA and CGOMEA significantly outperform the original GOMEA and DSMGA-II on most problems, setting a new state of the art for the field.},
  archiveprefix = {arXiv}
}

@article{fayWilcoxonMannWhitneyTtestAssumptions2010,
  title = {Wilcoxon-{{Mann-Whitney}} or t-Test? {{On}} Assumptions for Hypothesis Tests and Multiple Interpretations of Decision Rules},
  shorttitle = {Wilcoxon-{{Mann-Whitney}} or t-Test?},
  author = {Fay, Michael P. and Proschan, Michael A.},
  year = {2010},
  journal = {Statistics surveys},
  volume = {4},
  pages = {1--39},
  issn = {1935-7516},
  doi = {10.1214/09-SS051},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2857732/},
  urldate = {2022-01-18},
  abstract = {In a mathematical approach to hypothesis tests, we start with a clearly defined set of hypotheses and choose the test with the best properties for those hypotheses. In practice, we often start with less precise hypotheses. For example, often a researcher wants to know which of two groups generally has the larger responses, and either a t-test or a Wilcoxon-Mann-Whitney (WMW) test could be acceptable. Although both t-tests and WMW tests are usually associated with quite different hypotheses, the decision rule and p-value from either test could be associated with many different sets of assumptions, which we call perspectives. It is useful to have many of the different perspectives to which a decision rule may be applied collected in one place, since each perspective allows a different interpretation of the associated p-value. Here we collect many such perspectives for the two-sample t-test, the WMW test and other related tests. We discuss validity and consistency under each perspective and discuss recommendations between the tests in light of these many different perspectives. Finally, we briefly discuss a decision rule for testing genetic neutrality where knowledge of the many perspectives is vital to the proper interpretation of the decision rule.},
  pmcid = {PMC2857732},
  pmid = {20414472}
}

@article{goldmanFastEfficientBlack2015,
  title = {Fast and {{Efficient Black Box Optimization Using}} the {{Parameter-less Population Pyramid}}},
  author = {Goldman, B. W. and Punch, W. F.},
  year = {2015},
  month = sep,
  journal = {Evolutionary Computation},
  volume = {23},
  number = {3},
  pages = {451--479},
  issn = {1063-6560, 1530-9304},
  doi = {10.1162/EVCO_a_00148},
  url = {https://direct.mit.edu/evco/article/23/3/451-479/997},
  urldate = {2021-11-23},
  abstract = {The parameter-less population pyramid (P3) is a recently introduced method for performing evolutionary optimization without requiring any user-specified parameters. P3's primary innovation is to replace the generational model with a pyramid of multiple populations that are iteratively created and expanded. In combination with local search and advanced crossover, P3 scales to problem difficulty, exploiting previously learned information before adding more diversity. Across seven problems, each tested using on average 18 problem sizes, P3 outperformed all five advanced comparison algorithms. This improvement includes requiring fewer evaluations to find the global optimum and better fitness when using the same number of evaluations. Using both algorithm analysis and comparison, we find P3's effectiveness is due to its ability to properly maintain, add, and exploit diversity. Unlike the best comparison algorithms, P3 was able to achieve this quality without any problem-specific tuning. Thus, unlike previous parameter-less methods, P3 does not sacrifice quality for applicability. Therefore we conclude that P3 is an efficient, general, parameter-less approach to black box optimization which is more effective than existing state-of-the-art techniques.},
  langid = {english}
}

@inproceedings{goldmanParameterlessPopulationPyramid2014,
  title = {Parameter-Less Population Pyramid},
  booktitle = {Proceedings of the 2014 {{Annual Conference}} on {{Genetic}} and {{Evolutionary Computation}}},
  author = {Goldman, Brian W. and Punch, William F.},
  year = {2014},
  month = jul,
  series = {{{GECCO}} '14},
  pages = {785--792},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2576768.2598350},
  url = {https://doi.org/10.1145/2576768.2598350},
  urldate = {2021-01-01},
  abstract = {Real world applications of evolutionary techniques are often hindered by the need to determine problem specific parameter settings. While some previous methods have reduced or removed the need for parameter tuning, many do so by trading efficiency for general applicability. The Parameter-less Population Pyramid (P3) is an evolutionary technique that requires no parameters and is still broadly effective. P3 strikes a balance between continuous integration of diversity and exploitative elitist operators, allowing it to solve easy problems quickly and hard problems eventually. When compared with three optimally tuned, state of the art optimization techniques, P3 always finds the optimum at least a constant factor faster across four benchmarks (Deceptive Trap, Deceptive Step Trap, HIFF, Rastrigin). More importantly, on three randomized benchmarks (NK Landscapes, Ising Spin Glasses, MAX-SAT), P3 has a lower order of computational complexity as measured by evaluations. We also provide outlines for expected runtime analysis of P3, setting the stage for future theory based conclusions. Based on over 1 trillion evaluations, our results suggest P3 has wide applicability to a broad class of problems.},
  isbn = {978-1-4503-2662-9}
}

@article{haradaComparisonSynchronousAsynchronous2022,
  title = {Comparison of Synchronous and Asynchronous Parallelization of Extreme Surrogate-Assisted Multi-Objective Evolutionary Algorithm},
  author = {Harada, Tomohiro and Kaidan, Misaki and Thawonmas, Ruck},
  year = {2022},
  month = jun,
  journal = {Natural Computing},
  volume = {21},
  number = {2},
  pages = {187--217},
  issn = {1567-7818, 1572-9796},
  doi = {10.1007/s11047-020-09806-2},
  url = {https://link.springer.com/10.1007/s11047-020-09806-2},
  urldate = {2022-12-22},
  abstract = {Abstract             This paper investigates the integration of a surrogate-assisted multi-objective evolutionary algorithm (MOEA) and a parallel computation scheme to reduce the computing time until obtaining the optimal solutions in evolutionary algorithms (EAs). A surrogate-assisted MOEA solves multi-objective optimization problems while estimating the evaluation of solutions with a surrogate function. A surrogate function is produced by a machine learning model. This paper uses an extreme learning surrogate-assisted MOEA/D (ELMOEA/D), which utilizes one of the well-known MOEA algorithms, MOEA/D, and a machine learning technique, extreme learning machine (ELM). A parallelization of MOEA, on the other hand, evaluates solutions in parallel on multiple computing nodes to accelerate the optimization process. We consider a synchronous and an asynchronous parallel MOEA as a master-slave parallelization scheme for ELMOEA/D. We carry out an experiment with multi-objective optimization problems to compare the synchronous parallel ELMOEA/D with the asynchronous parallel ELMOEA/D. In the experiment, we simulate two settings of the evaluation time of solutions. One determines the evaluation time of solutions by the normal distribution with different variances. On the other hand, another evaluation time correlates to the objective function value. We compare the quality of solutions obtained by the parallel ELMOEA/D variants within a particular computing time. The experimental results show that the parallelization of ELMOEA/D significantly reduces the computational time. In addition, the integration of ELMOEA/D with the asynchronous parallelization scheme obtains higher quality of solutions quicker than the synchronous parallel ELMOEA/D.},
  langid = {english}
}

@incollection{harikLinkageLearningProbabilistic2006,
  title = {Linkage {{Learning}} via {{Probabilistic Modeling}} in the {{Extended Compact Genetic Algorithm}} ({{ECGA}})},
  booktitle = {Scalable {{Optimization}} via {{Probabilistic Modeling}}},
  author = {Harik, Georges R. and Lobo, Fernando G. and Sastry, Kumara},
  editor = {Kacprzyk, Janusz and Pelikan, Martin and Sastry, Kumara and Cant{\'u}Paz, Erick},
  year = {2006},
  volume = {33},
  pages = {39--61},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-34954-9_3},
  url = {http://link.springer.com/10.1007/978-3-540-34954-9_3},
  urldate = {2022-03-03},
  abstract = {For a long time, genetic algorithms (GAs) were not very successful in automatically identifying and exchanging structures consisting of several correlated genes. This problem, referred in the literature as the linkage-learning problem, has been the subject of extensive research for many years. This chapter explores the relationship between the linkage-learning problem and that of learning probability distributions over multi-variate spaces. Herein, it is argued that these problems are equivalent. Using a simple but effective approach to learning distributions, and by implication linkage, this chapter reveals the existence of GA-like algorithms that are potentially orders of magnitude faster and more accurate than the simple GA.},
  isbn = {978-3-540-34953-2 978-3-540-34954-9},
  langid = {english}
}

@article{holmSimpleSequentiallyRejective1979,
  title = {A {{Simple Sequentially Rejective Multiple Test Procedure}}},
  author = {Holm, Sture},
  year = {1979},
  journal = {Scandinavian Journal of Statistics},
  volume = {6},
  number = {2},
  pages = {65--70},
  publisher = {{[Board of the Foundation of the Scandinavian Journal of Statistics, Wiley]}},
  issn = {0303-6898},
  url = {https://www.jstor.org/stable/4615733},
  urldate = {2022-01-18},
  abstract = {This paper presents a simple and widely applicable multiple test procedure of the sequentially rejective type, i.e. hypotheses are rejected one at a time until no further rejections can be done. It is shown that the test has a prescribed level of significance protection against error of the first kind for any combination of true hypotheses. The power properties of the test and a number of possible applications are also discussed.}
}

@inproceedings{hsuOptimizationPairwiseLinkage2015,
  title = {Optimization by {{Pairwise Linkage Detection}}, {{Incremental Linkage Set}}, and {{Restricted}} / {{Back Mixing}}: {{DSMGA-II}}},
  shorttitle = {Optimization by {{Pairwise Linkage Detection}}, {{Incremental Linkage Set}}, and {{Restricted}} / {{Back Mixing}}},
  booktitle = {Proceedings of the 2015 {{Annual Conference}} on {{Genetic}} and {{Evolutionary Computation}}},
  author = {Hsu, Shih-Huan and Yu, Tian-Li},
  year = {2015},
  month = jul,
  series = {{{GECCO}} '15},
  pages = {519--526},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2739480.2754737},
  url = {https://doi.org/10.1145/2739480.2754737},
  urldate = {2021-01-01},
  abstract = {This paper proposes a new evolutionary algorithm, called DSMGA-II, to efficiently solve optimization problems via exploiting problem substructures. The proposed algorithm adopts pairwise linkage detection and stores the information in the form of dependency structure matrix (DSM). A new linkage model, called the incremental linkage set, is then constructed by using the DSM. Inspired by the idea of optimal mixing, the restricted mixing and the back mixing are proposed. The former aims at efficient exploration under certain constrains. The latter aims at exploitation by refining the DSM so as to reduce unnecessary evaluations. Experimental results show that DSMGA-II outperforms LT-GOMEA and hBOA in terms of number of function evaluations on the concatenated/folded/cyclic trap problems, NK-landscape problems with various degrees of overlapping, 2D Ising spin-glass problems, and MAX-SAT. The investigation of performance comparison with P3 is also included.},
  isbn = {978-1-4503-3472-3}
}

@inproceedings{kaidanIntegratingSurrogateEvaluation2017,
  title = {Integrating Surrogate Evaluation Model and Asynchronous Evolution in Multi-Objective Evolutionary Algorithm for Expensive and Different Evaluation Time},
  booktitle = {Proceedings of the {{Genetic}} and {{Evolutionary Computation Conference Companion}}},
  author = {Kaidan, Misaki and Harada, Tomohiro and Thawonmas, Ruck},
  year = {2017},
  month = jul,
  series = {{{GECCO}} '17},
  pages = {1833--1840},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3067695.3084215},
  url = {https://doi.org/10.1145/3067695.3084215},
  urldate = {2022-02-14},
  abstract = {This paper proposes Extreme Learning Surrogate assisted Asynchronous Multi-Objective Optimization Based on Decomposition (AELMOEA/D) that solves multi-objective optimization problems with expensive and different evaluation time by integrating a surrogate evaluation model and an asynchronous evolution method. Extreme Learning Surrogate assisted Multi-Objective Optimization Based on Decomposition (ELMOEA/D), which is a surrogate-assisted MOEA/D, was proposed to reduce the number of actual evaluations, while asynchronous evolution methods were proposed to reduce the waiting time for evaluation of solutions in a parallel evolutionary algorithm. This paper employs ELMOEA/D as a surrogate assisted EA and introduces an asynchronous manner into it. Our experiment proves that our proposed AELMOEA/D can obtain optimal solutions faster than ELMOEA/D without performance deterioration.},
  isbn = {978-1-4503-4939-0}
}

@article{kieferSequentialMinimaxSearch1953,
  title = {Sequential Minimax Search for a Maximum},
  author = {Kiefer, J.},
  year = {1953},
  journal = {Proceedings of the American Mathematical Society},
  volume = {4},
  number = {3},
  pages = {502--506},
  issn = {0002-9939, 1088-6826},
  doi = {10.1090/S0002-9939-1953-0055639-3},
  url = {https://www.ams.org/proc/1953-004-03/S0002-9939-1953-0055639-3/},
  urldate = {2023-01-25},
  abstract = {Advancing research. Creating connections.},
  langid = {english}
}

@article{mannTestWhetherOne1947,
  title = {On a {{Test}} of {{Whether}} One of {{Two Random Variables}} Is {{Stochastically Larger}} than the {{Other}}},
  author = {Mann, H. B. and Whitney, D. R.},
  year = {1947},
  month = mar,
  journal = {The Annals of Mathematical Statistics},
  volume = {18},
  number = {1},
  pages = {50--60},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177730491},
  url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-18/issue-1/On-a-Test-of-Whether-one-of-Two-Random-Variables/10.1214/aoms/1177730491.full},
  urldate = {2022-01-18},
  abstract = {Let \$x\$ and \$y\$ be two random variables with continuous cumulative distribution functions \$f\$ and \$g\$. A statistic \$U\$ depending on the relative ranks of the \$x\$'s and \$y\$'s is proposed for testing the hypothesis \$f = g\$. Wilcoxon proposed an equivalent test in the Biometrics Bulletin, December, 1945, but gave only a few points of the distribution of his statistic. Under the hypothesis \$f = g\$ the probability of obtaining a given \$U\$ in a sample of \$n x's\$ and \$m y's\$ is the solution of a certain recurrence relation involving \$n\$ and \$m\$. Using this recurrence relation tables have been computed giving the probability of \$U\$ for samples up to \$n = m = 8\$. At this point the distribution is almost normal. From the recurrence relation explicit expressions for the mean, variance, and fourth moment are obtained. The 2rth moment is shown to have a certain form which enabled us to prove that the limit distribution is normal if \$m, n\$ go to infinity in any arbitrary manner. The test is shown to be consistent with respect to the class of alternatives \$f(x) {$>$} g(x)\$ for every \$x\$.}
}

@inproceedings{riversAsynchronousParallelEvolutionary2015,
  title = {Asynchronous {{Parallel Evolutionary Algorithms}}: {{Leveraging Heterogeneous Fitness Evaluation Times}} for {{Scalability}} and {{Elitist Parsimony Pressure}}},
  shorttitle = {Asynchronous {{Parallel Evolutionary Algorithms}}},
  booktitle = {Proceedings of the {{Companion Publication}} of the 2015 {{Annual Conference}} on {{Genetic}} and {{Evolutionary Computation}}},
  author = {Rivers, Rebecca and Bertels, Alex R. and Tauritz, Daniel R.},
  year = {2015},
  month = jul,
  series = {{{GECCO Companion}} '15},
  pages = {1429--1430},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2739482.2764718},
  url = {https://doi.org/10.1145/2739482.2764718},
  urldate = {2022-02-14},
  abstract = {Many important problem classes lead to large variations in fitness evaluation times, such as is often the case in Genetic Programming where the time complexity of executing one individual may differ greatly from that of another. Asynchronous Parallel Evolutionary Algorithms (APEAs) omit the generational synchronization step of traditional EAs which work in well-defined cycles. This paper provides an empirical analysis of the scalability improvements obtained by applying APEAs to such problem classes, aside from the speed-up caused merely by the removal of the synchronization step. APEAs exhibit bias towards individuals with shorter fitness evaluation times, because they propagate faster. This paper demonstrates how this bias can be leveraged in order to provide a unique type of "elitist" parsimony pressure which rewards more efficient solutions with equal solution quality.},
  isbn = {978-1-4503-3488-4}
}

@inproceedings{scottEvaluationTimeBiasAsynchronous2015,
  title = {Evaluation-{{Time Bias}} in {{Asynchronous Evolutionary Algorithms}}},
  booktitle = {Proceedings of the {{Companion Publication}} of the 2015 {{Annual Conference}} on {{Genetic}} and {{Evolutionary Computation}}},
  author = {Scott, Eric O. and De Jong, Kenneth A.},
  year = {2015},
  month = jul,
  series = {{{GECCO Companion}} '15},
  pages = {1209--1212},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2739482.2768482},
  url = {https://doi.org/10.1145/2739482.2768482},
  urldate = {2022-02-14},
  abstract = {Parallelization of fitness evaluation is an established practice in evolutionary computation, and is a necessity in applications where fitness functions are computationally expensive. Traditional master-slave EAs based on a synchronous, generational model incur idle time when there is variance in the time it takes for individuals to have their fitness evaluated. Asynchronous evolutionary algorithms based on a steady-state model can make more efficient use of parallelization by eliminating idle time and reclaiming CPU resources. It is believed, however, that asynchronous EAs are biased toward regions of the search space where solutions take less time to evaluate, and away from regions where fitnesses evaluation is expensive. We show experimentally that asynchronous EAs do indeed exhibit an evaluation-time bias. This bias can either cause or prevent premature convergence. We also show, however, that on a flat fitness landscape, the asynchronous EA is attracted to both fast and slow regions of the search space, and away from medium-speed solutions. This indicates that further work is needed to understand the implications that asynchrony has for EA applications.},
  isbn = {978-1-4503-3488-4}
}

@inproceedings{scottEvaluationTimeBiasQuasiGenerational2016,
  title = {Evaluation-{{Time Bias}} in {{Quasi-Generational}} and {{Steady-State Asynchronous Evolutionary Algorithms}}},
  booktitle = {Proceedings of the {{Genetic}} and {{Evolutionary Computation Conference}} 2016},
  author = {Scott, Eric O. and De Jong, Kenneth A.},
  year = {2016},
  month = jul,
  series = {{{GECCO}} '16},
  pages = {845--852},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2908812.2908934},
  url = {https://doi.org/10.1145/2908812.2908934},
  urldate = {2022-02-14},
  abstract = {A number of papers have emerged in the last two years that apply and study asynchronous master-slave evolutionary algorithms based on a steady-state model. These efforts are largely motivated by the observation that, unlike traditional (synchronous) EAs, asynchronous EAs are able to make maximal use of many parallel processors, even when some individuals evaluate more slowly than others. Asynchronous EAs do not behave the same as their synchronous counterparts, however, and as of yet there is very little theory that makes it possible to predict how they will perform on new problems. Of some concern is evidence suggesting that the steady-state versions tend to be biased toward regions of the search space where fitness evaluation is cheaper. This has led some authors to suggest a so-called `quasi-generational' asynchronous EA as an intermediate solution that incurs neither idle time nor significant bias toward fast solutions. We perform experiments with the quasi-generational EA, and show that it does not deliver the promised benefits: it is, in fact, just as biased toward fast solutions as the steady-state approach is, and it tends to converge even more slowly than the traditional, generational EA.},
  isbn = {978-1-4503-4206-3}
}

@inproceedings{scottUnderstandingSimpleAsynchronous2015,
  title = {Understanding {{Simple Asynchronous Evolutionary Algorithms}}},
  booktitle = {Proceedings of the 2015 {{ACM Conference}} on {{Foundations}} of {{Genetic Algorithms XIII}}},
  author = {Scott, Eric O. and De Jong, Kenneth A.},
  year = {2015},
  month = jan,
  series = {{{FOGA}} '15},
  pages = {85--98},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2725494.2725509},
  url = {https://doi.org/10.1145/2725494.2725509},
  urldate = {2022-02-14},
  abstract = {In many applications of evolutionary algorithms, the time required to evaluate the fitness of individuals is long and variable. When the variance in individual evaluation times is non-negligible, traditional, synchronous master-slave EAs incur idle time in CPU resources. An asynchronous approach to parallelization of EAs promises to eliminate idle time and thereby to reduce the amount of wall-clock time it takes to solve a problem. However, the behavior of asynchronous evolutionary algorithms is not well understood. In particular, it is not clear exactly how much faster the asynchronous algorithm will tend to run, or whether its evolutionary trajectory may follow a sub-optimal search path that cancels out the promised benefits. This paper presents a preliminary analysis of simple asynchronous EA performance in terms of speed and problem-solving ability.},
  isbn = {978-1-4503-3434-1}
}

@incollection{syswerdaStudyReproductionGenerational1991,
  title = {A {{Study}} of {{Reproduction}} in {{Generational}} and {{Steady-State Genetic Algorithms}}},
  booktitle = {Foundations of {{Genetic Algorithms}}},
  author = {Syswerda, Gilbert},
  year = {1991},
  volume = {1},
  pages = {94--101},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-08-050684-5.50009-4},
  url = {https://linkinghub.elsevier.com/retrieve/pii/B9780080506845500094},
  urldate = {2022-12-01},
  isbn = {978-0-08-050684-5},
  langid = {english}
}

@article{thierensScalabilityProblemsSimple1999,
  title = {Scalability {{Problems}} of {{Simple Genetic Algorithms}}},
  author = {Thierens, Dirk},
  year = {1999},
  month = dec,
  journal = {Evolutionary Computation},
  volume = {7},
  number = {4},
  pages = {331--352},
  issn = {1063-6560, 1530-9304},
  doi = {10.1162/evco.1999.7.4.331},
  url = {https://www.mitpressjournals.org/doi/abs/10.1162/evco.1999.7.4.331},
  urldate = {2021-01-01},
  abstract = {Scalable evolutionary computation has become an intensively studied research topic in recent years. The issue of scalability is predominant in any field of algorithmic design, but it became particularly relevant for the design of competent genetic algorithms once the scalability problems of simple genetic algorithms were understood. Here we present some of the work that has aided in getting a clear insight in the scalability problems of simple genetic algorithms. Particularly, we discuss the important issue of building block mixing. We show how the need for mixing places a boundary in the GA parameter space that, together with the boundary from the schema theorem, delimits the region where the GA converges reliably to the optimum in problems of bounded difficulty. This region shrinks rapidly with increasing problem size unless the building blocks are tightly linked in the problem coding structure. In addition, we look at how straightforward extensions of the simple genetic algorithm\textemdash namely elitism, niching, and restricted mating are not significantly improving the scalability problems.},
  langid = {english}
}

@article{whitleyFundamentalPrinciplesDeception1991,
  title = {Fundamental {{Principles}} of {{Deception}} in {{Genetic Search}}},
  author = {Whitley, L. Darrell},
  editor = {Rawlins, GREGORY J. E.},
  year = {1991},
  month = jan,
  journal = {Foundations of Genetic Algorithms},
  volume = {1},
  pages = {221--241},
  doi = {10.1016/B978-0-08-050684-5.50017-3},
  url = {https://www.sciencedirect.com/science/article/pii/B9780080506845500173},
  urldate = {2022-02-02},
  abstract = {This paper presents several theorems concerning the nature of deception and the central role that deception plays in function optimization using genetic algorithms. A simple proof is offered which shows that the only problems which pose challenging optimization tasks are problems that involve some degree of deception and which result in conflicting k-arm bandit competitions between hyperplanes. The concept of a deceptive attractor is introduced and shown to be more general than the deceptive optimum found in the deceptive functions that have been constructed to date. Also introduced are the concepts of fully deceptive problems as well as less strict consistently deceptive problems. A proof is given showing that deceptive attractors must have a complementary bit pattern to that found in the binary representation of the global optimum if a function is to be either fully deceptive or consistently deceptive. Some empirical results are presented which demonstrate different methods of dealing with deception and poor linkage during genetic search.},
  langid = {english}
}

@inproceedings{yagoubiAsynchronousEvolutionaryMultiObjective2011,
  title = {Asynchronous {{Evolutionary Multi-Objective Algorithms}} with Heterogeneous Evaluation Costs},
  booktitle = {2011 {{IEEE Congress}} of {{Evolutionary Computation}} ({{CEC}})},
  author = {Yagoubi, Mouadh and Thobois, Ludovic and Schoenauer, Marc},
  year = {2011},
  month = jun,
  pages = {21--28},
  issn = {1941-0026},
  doi = {10.1109/CEC.2011.5949593},
  abstract = {Master-slave parallelization of Evolutionary Algorithms (EAs) is straightforward, by distributing all fitness computations to slaves. The benefits of asynchronous steady state approaches are well-known when facing a possible heterogeneity among the evaluation costs in term of runtime, be they due to heterogeneous hardware or non-linear numerical simulations. However, when this heterogeneity depends on some characteristics of the individuals being evaluated, the search might be biased, and some regions of the search space poorly explored. Motivated by a real-world case study of multi-objective optimization problem the optimization of the combustion in a Diesel Engine the consequences of different components of heterogeneity in the evaluation costs on the convergence of two Evolutionary Multi-objective Optimization Algorithms are investigated on artificially-heterogeneous benchmark problems. In some cases, better spread of the population on the Pareto front seem to result from the interplay between the heterogeneity at hand and the evolutionary search.}
}

@inproceedings{yagoubiAsynchronousMasterSlave2012,
  title = {Asynchronous Master/Slave Moeas and Heterogeneous Evaluation Costs},
  booktitle = {Proceedings of the 14th Annual Conference on {{Genetic}} and Evolutionary Computation},
  author = {Yagoubi, Mouadh and Schoenauer, Marc},
  year = {2012},
  month = jul,
  series = {{{GECCO}} '12},
  pages = {1007--1014},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2330163.2330303},
  url = {https://doi.org/10.1145/2330163.2330303},
  urldate = {2022-02-15},
  abstract = {Parallel master-slave evolutionary algorithms easily lead to linear speedups in the case of a small number of nodes... and homogeneous computational costs of the evaluations. However, modern computer now routinely have several hundreds of nodes - and in many real-world applications in which fitness computation involves heavy numerical simulations, the computational costs of these simulations can greatly vary from one individual to the next. A simple answer to the latter problem is to use asynchronous steady-state reproduction schemes. But the resulting algorithms then differ from the original sequential version, with two consequences: First, the linear speedup does not hold any more; Second, the convergence might be hindered by the heterogeneity of the evaluation costs. The multi-objective optimization of a diesel engine is first presented, a real-world case study where evaluations are very heterogeneous in terms of CPU cost. Both the speedup of asynchronous parallel algorithms in case of large number of nodes, and their convergence toward the Pareto Front in case of heterogeneous computation times, are then experimentally analyzed on artificial test functions. An alternative selection scheme involving the computational cost of the fitness evaluation is then proposed, that counteracts the effects of heterogeneity on convergence toward the Pareto Front.},
  isbn = {978-1-4503-1177-9}
}

@article{zavoianuPerformanceComparisonGenerational2015a,
  title = {Performance Comparison of Generational and Steady-State Asynchronous Multi-Objective Evolutionary Algorithms for Computationally-Intensive Problems},
  author = {Z{\u a}voianu, Alexandru-Ciprian and Lughofer, Edwin and Koppelst{\"a}tter, Werner and Weidenholzer, G{\"u}nther and Amrhein, Wolfgang and Klement, Erich Peter},
  year = {2015},
  month = oct,
  journal = {Knowledge-Based Systems},
  volume = {87},
  pages = {47--60},
  issn = {09507051},
  doi = {10.1016/j.knosys.2015.05.029},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705115002154},
  urldate = {2022-12-22},
  langid = {english}
}

@incollection{zavoianuPerformanceMasterSlaveParallelization2013,
  title = {On the {{Performance}} of {{Master-Slave Parallelization Methods}} for {{Multi-Objective Evolutionary Algorithms}}},
  booktitle = {Artificial {{Intelligence}} and {{Soft Computing}}},
  author = {Z{\u a}voianu, Alexandru-Ciprian and Lughofer, Edwin and Koppelst{\"a}tter, Werner and Weidenholzer, G{\"u}nther and Amrhein, Wolfgang and Klement, Erich Peter},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Rutkowski, Leszek and Korytkowski, Marcin and Scherer, Rafa{\l} and Tadeusiewicz, Ryszard and Zadeh, Lotfi A. and Zurada, Jacek M.},
  year = {2013},
  volume = {7895},
  pages = {122--134},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-38610-7_12},
  url = {http://link.springer.com/10.1007/978-3-642-38610-7_12},
  urldate = {2022-12-22},
  isbn = {978-3-642-38609-1 978-3-642-38610-7}
}

@misc{zelaSurrogateNASBenchmarks2022,
  title = {Surrogate {{NAS Benchmarks}}: {{Going Beyond}} the {{Limited Search Spaces}} of {{Tabular NAS Benchmarks}}},
  shorttitle = {Surrogate {{NAS Benchmarks}}},
  author = {Zela, Arber and Siems, Julien and Zimmer, Lucas and Lukasik, Jovita and Keuper, Margret and Hutter, Frank},
  year = {2022},
  month = apr,
  number = {arXiv:2008.09777},
  eprint = {2008.09777},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2008.09777},
  url = {http://arxiv.org/abs/2008.09777},
  urldate = {2022-10-19},
  abstract = {The most significant barrier to the advancement of Neural Architecture Search (NAS) is its demand for large computational resources, which hinders scientifically sound empirical evaluations of NAS methods. Tabular NAS benchmarks have alleviated this problem substantially, making it possible to properly evaluate NAS methods in seconds on commodity machines. However, an unintended consequence of tabular NAS benchmarks has been a focus on extremely small architectural search spaces since their construction relies on exhaustive evaluations of the space. This leads to unrealistic results that do not transfer to larger spaces. To overcome this fundamental limitation, we propose a methodology to create cheap NAS surrogate benchmarks for arbitrary search spaces. We exemplify this approach by creating surrogate NAS benchmarks on the existing tabular NAS-Bench-101 and on two widely used NAS search spaces with up to \$10\^\{21\}\$ architectures (\$10\^\{13\}\$ times larger than any previous tabular NAS benchmark). We show that surrogate NAS benchmarks can model the true performance of architectures better than tabular benchmarks (at a small fraction of the cost), that they lead to faithful estimates of how well different NAS methods work on the original non-surrogate benchmark, and that they can generate new scientific insight. We open-source all our code and believe that surrogate NAS benchmarks are an indispensable tool to extend scientifically sound work on NAS to large and exciting search spaces.},
  archiveprefix = {arXiv}
}
