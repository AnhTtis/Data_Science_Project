\documentclass[journal]{IEEEtran}
% \documentclass[onecolumn,conference,draftclsnofoot,12pt]{IEEEtran}
%  \usepackage{lineno}
%  \linenumbers

\pagestyle{plain}

\makeatletter\def\input@path{{current}}\makeatother

\input{auxiliary/packages}
\input{auxiliary/preamble}
\input{auxiliary/definitions}
\input{auxiliary/graphics}
\input{auxiliary/tables}

\IEEEoverridecommandlockouts
\begin{document}

\graphicspath{{./figures/}}

\input{includes/title_and_authors}
%% \tableofcontents %%

\begin{abstract}
    \label{abstract}
    Cyber resilience is the ability of a system to resist and recover from a cyber attack, thereby    restoring the system’s functionality. Effective design and development of a cyber resilient system requires experimental methods and tools for quantitative measuring of cyber resilience. This paper describes an experimental method and test bed for obtaining resilience-relevant data as a system (in our case -- a truck) traverses its route, in repeatable, systematic experiments. We model a truck equipped with an autonomous cyber-defense system and which also includes inherent physical resilience features. When attacked by malware, this ensemble of cyber-physical features (i.e., ``bonware'') strives to resist and recover from the performance degradation caused by the malware’s attack. We propose parsimonious mathematical models to aid in quantifying systems' resilience to cyber attacks. Using the models, we identify quantitative characteristics obtainable from experimental data, and show that these characteristics can serve as useful quantitative measures of cyber resilience.
\end{abstract}



\section{Introduction}

Resilience continues to gain attention as a key property of cyber and cyber-physical systems, for the purposes of cyber defense. Although definitions vary, it is generally agreed that cyber resilience refers to the ability of a system to resist and recover from a cyber compromise that degrades the performance of the system \cite{kott2022, weisman23, kott2019cyber}. One way to conceptualize resilience is as the ability of a system to absorb stress elastically and return to the original functionality once the stress is removed or nullified \cite{smith23towards}. Resilience should not be conflated with risk or security \cite{linkov2018risk}.

To make the discussion more concrete, consider the example of a truck which attempts to complete its goal of delivering heavy cargo. The cyber adversary's malware successfully gains access to the Controller Area Network (CAN bus) of the truck \cite{bozdal2018august}. Then, the malware executes cyber attacks by sending a combination of messages intended to degrade the truck's performance and diminish its ability to complete its goal. We assume that the malware is at least partly successful, and the truck indeed begins to experience a degradation of its goal-relevant performance.

At this point, we expect the truck's resilience-relevant elements to resist the degradation and then to recover its performance to a satisfactory level, within an acceptably short time period. These ``resilience-relevant elements'' might be of several kinds. First, because the truck is a cyber-physical system, certain physical characteristics of the truck's mechanisms will provide a degree of resilience. For example, the cooling system of the truck will exhibit a significant resistance to overheating even if the malware succeeds in misrepresenting the temperature sensors data. Second, appropriate defensive software residing on the truck continually monitors and analyzes the information passing through the CAN bus \cite{kott2018}. When the situation appears suspicious, it may take actions such as blocking or correcting potentially malicious messages. Third, it is possible that a remote monitoring center, staffed with experienced human cyber defenders, will detect a cyber compromise and will provide corrective actions remotely \cite{kott2021cyber}.

For the purposes of this paper, we assume that the remote monitoring and resilience via external intervention is impossible \cite{kott2020doers}. This may be the case if the truck cannot use radio communications due to environmental constraints (e.g., operating in a remote mountainous area), or if the malware spoofs or blocks communication channels of the truck. Therefore, in this paper we assume that resilience is provided by the first two classes of resilience-relevant elements. Here, by analogy with malware, we call these ``bonware'' -- a combination of physical and cyber features of the truck that serve to resist and recover from a cyber compromise.

A key challenge in the field of cyber resilience is quantifying or measuring resilience. Indeed, no engineering discipline achieved significant maturity without being able to measure the properties of phenomena relevant to the discipline \cite{kott2021cyber}. Developers of systems like a truck must be able to quantify the resilience of the truck under development in order to know whether the features they introduce in the truck improve its cyber resilience, or make it worse. Similarly, buyers of the truck need to know how to specify quantitatively the resilience of the truck, and how to test resilience quantitatively in order to determine whether the product meets their specifications. 

In this paper, we report results of a project called \textit{Quantitative Measurement of Cyber Resilience} (QMoCR) in which our research team seeks to identify quantitative characteristics of systems' responses to cyber compromises that can be derived from repeatable, systematic experiments. Briefly, we have constructed a test-bed in which a surrogate truck is subjected to controlled cyber attacks produced by malware. The truck is equipped with an autonomous cyber-defense system \cite{kott2018,kott2020doers} and also has some inherent physical resilience features. This ensemble of cyber-physical features (i.e., bonware) strives to resist and recover from the performance degradation caused by the malware's attack. The test bed is instrumented in such a way that we can measure observable manifestations of this contest between the malware and bonware, especially the performance parameters of the truck.

The remainder of the paper is organized as follows. In the next section, we briefly describe prior work related to quantification of cyber resilience. In the following section, we propose a class of parsimonious models in which effects of both malware and bonware are approximated as deterministic, continuous differentiable variables, and we explore several variations of such models. In addition, we discuss how parameters of such models can be obtained from experimental data and whether these parameters might be considered quantitative characteristics (i.e., measurements) of the bonware's cyber resilience. In the next section, we introduce the experimental approach we used to obtain resiliency-relevant data; we describe various components of the overall experimental apparatus and the process of performing experiments. The ensuing sections illustrate the experimentation and analysis using a case study, discuss the experimental results, and offer conclusions. 



\section{Prior work}\label{sec:prior-work}

A growing body of literature explores quantification of resilience in general and cyber resilience in particular. Approximately, the literature can be divided into two categories: (1) qualitative assessments of a system (actually existing or its design) by subject matter experts (SMEs) \cite{alexeev2017constructing, henshel} and (2) quantitative measurements based on empirical or experimental observations of how a system (or its high-fidelity model) responds to a cyber compromise \cite{kott2019cyber, ligo2021how}.  In the first category, a well-cited example is the approach called the cyber-resilience matrix \cite{linkov2013resilience}. In this approach, a system is considered as spanning four domains: (1) physical (i.e., the physical resources of the system, and the design, capabilities, features and characteristics of those resources); (2) informational (i.e., the system's availability, storage, and use of information); (3) cognitive (i.e., the ways in which informational and physical resources are used to comprehend the situation and make pertinent decisions); and (4) social (i.e., structure, relations, and communications of social nature within and around the system). For each of these domains of the system, SMEs are asked to assess, and to express in metrics, the extent to which the system exhibits the ability to (1) plan and prepare for an adverse cyber incident; (2) absorb the impact of the adverse cyber incident; (3) recover from the effects of the adverse cyber incident; and (4) adapt to the ramifications of the adverse cyber incident. In this way, the approach defines a 4-by-4 matrix that serves as a framework for structured assessments by SMEs.     

Another example within the same category (i.e., qualitative assessments of a system by SMEs) is a recent, elaborate approach proposed by \cite{beling2021developmental}. The approach is called Framework for Operational Resilience in Engineering and System Test (FOREST), and a key methodology within FOREST is called Testable Resilience Efficacy Elements (TREE). For a given system or subsystem, the methodology requires SMEs to assess, among others, how well the resilience solution is able to (1) sense or discover a successful cyber-attack; (2) identify the part of the system that has been successfully attacked; (3) reconfigure the system in order to mitigate and contain the consequences of the attack. Assessment may include tests of the system, although the methodology does not prescribe the tests. 

Undoubtedly, such methodologies can be valuable in finding opportunities in improvements of cyber-resilience in a system that is either at the design stage or is already constructed. Still, these are essentially qualitative assessments, not quantitative measurements derived from an experiment. 

In the second category (i.e., quantitative measurements based on empirical or experimental observations of how a system, or its high-fidelity model, responds to a cyber compromise), most approaches tend to revolve around a common idea we call here the area under the curve (AUC) method \cite{hosseini2016review, kott2021to}.

The general idea is depicted in Figure~\ref{fig:tub}. The functionality is plotted over time $t$. At time $t = t_0,$ a cyber attack begins to degrade the functionality of the system, as compared to the normal level of functionality. The system resists the effects of the cyber attack, and eventually stabilizes the functionality at a reduced level. At $t = t_1,$ the system resilience mechanisms begin to overcome the effect of the attack and eventually recover the functionality to a normal level. The area under the curve (AUC) reflects the degree of resilience -- the closer AUC is to its normal level, the higher is the system's resilience.

\begin{figure}[th]
    \centering
    \zzz{prod-figure1.pdf}
    \caption{The functionality $F(t)$ is plotted over time $t$. At time $t = t_0,$ a cyber attack begins to degrade the functionality of the system, as compared to the normal level of functionality. The system resists the effects of the cyber attack, and eventually stabilizes the functionality at a reduced level. At $t = t_1,$ the system resilience mechanisms begin to overcome the effect of the attack and eventually recover the functionality to a normal level. The area under the curve (AUC) reflects the degree of resilience -- the closer AUC is to its normal level, the higher is the system's resilience.}
    \label{fig:tub}
\end{figure}

In an experiment/test, a system engages in the performance of a representative goal, and then is subjected to an ensemble or sequence of representative cyber attacks. A goal-relevant quantitative functionality of the system is observed and recorded. The resulting average functionality, divided by normal functionality, can be used as a measure of resilience.  

However, AUC-based resilience measures are inherently cumulative, aggregate measures, and do not tell us much about the underlying processes. For example, is it possible to quantify the resilience \impact{} of the bonware of the given system? Similarly, is it possible to quantify the \impact{} of malware? In addition, is it possible to gain insights into how these values of \impactfulness{} vary over time during an incident? We will offer steps toward answering such questions in addition to evaluating the AUC as a resilience measure.

With respect to experimental approaches, much of the early experimental work on the cybersecurity of automobiles used actual vehicles \cite{hoppe2007sniffing, koscher2010experimental, miller2013adventures, miller2015remote, foster2015fast}. This approach offers high fidelity but also high costs, especially when multiple experimental runs are required.

Other approaches avoided the expensive use of actual vehicles by connecting multiple electronic control units (ECUs) together on a Controller Area Network (CAN) bus independent of a vehicle \cite{ daily2016towards, bozdal2018hardware, wang2018delay}.  This is an inexpensive method to test malware and bonware in a vehicular network; however, it cannot characterize impacts on the vehicle's performance parameters.
 
Yet another experimental approach is to use a Digital Twin: a system to reproduce real-world events in a digital environment, e.g., \cite{shikata2019digital}. A virtualized vehicle with realistic virtual performance would provide high fidelity at low cost in terms of time to test and measure cyber resilience. However, constructing a virtual vehicle can be prohibitively expensive, too.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Section III:  Mathematical Modeling
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Quantitative Measurement of Cyber Resilience}\label{sec:theory}

In this section, we will first formalize our thinking about cyber resilience, and then use our new formalism to define the AUC-based measures of resilience as well as the mathematical models that we will apply to our experimental runs.

\subsection{Formal Definition of Concepts}
We define goal-relevant resilience as the ability of a system to accomplish its goal---or at least maximize the degree of accomplishment of its goal---in spite of effects of a cyber attack, as a run unfolds over time. To this end, we postulate that for a given run, there exists a function $\ma(t)$ that represents accomplishment and that is cumulative from the run start time $t_0$ up until the present time $t$.  We define functionality, $\functionality(t)$, to be the time derivative of goal accomplishment.  Thus,
\begin{equation}
  \label{eq:ma}
  \functionality(t) = \frac{d \ma }{dt}, \quad \ma(t) = \int_{t_0}^t \functionality(\tau) \, d\tau.
\end{equation}
Note that, in practice, functionality may vary with time, even when the system performs normally and is not experiencing the effects of a cyber attack.  To be able to account for this, we will often distinguish between performance under baseline conditions, $F_\text{baseline}(t)$ and performance during an attack scenario, $F_\text{attack}(t)$. We will require $F_\text{baseline}(t)>0$ everywhere where it is defined.

\subsection{Resilience Based on Area Under the Curve}\label{sec:auc based}

In Section~\ref{sec:prior-work}, we discussed the area under the functionality curve, which is precisely normalized goal accomplishment $\ma(T)$ evaluated at the final time of the run:
\begin{equation*}
  \text{AUC} = \frac{1}{T-t_0} \int_{t_0}^T F(\tau)\, d\tau.
\end{equation*}

Here we expand on this concept to make a measure of resilience that calculates the accomplishment---that is, the area under the functionality curve---in a cyber attack scenario relative to the accomplishment in a baseline scenario:
\begin{equation}
\label{eq:R}
R = \frac{\int_{t_0}^{T} \functionality_\text{attack}(\tau) \, d\tau}{\int_{t_0}^{T} \functionality_\text{baseline}(\tau) \, d\tau} = \frac{\ma_\text{attack}(T)}{\ma_\text{baseline}(T)}.
\end{equation}
As a measure of resilience, $R$ has a number of advantages.  By contrasting behavior in an attack scenario to behavior in a comparable baseline scenario, it is able to account for idiosyncratic differences between vehicles, terrain, or any other features we hold constant between the two scenarios.  Additionally, $R$ can be interpreted as the \textit{fraction of normal functionality maintained} during a cyber attack.  If it is close to $1.0$, then the effect of the attack was small; if it is $0.0$, then functionality was completely disrupted.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Finally, there may be multiple objectives to be considered jointly.  Given a vector of resiliences, $\mathbf{R} =(R_1,R_2, \hdots, R_j, \hdots, R_n)$, we define the overall cyber resilience to be a weighted average of the various objectives, using each $R_j$'s utility $u_j$ as a weight:
$
\bigR = { \sum_{j=1}^n {u_j R_j}}
$,
where  $\sum_{j=1}^n {u_j = 1.}$  The utilities $u_j$ must be determined by subject matter experts and may be situationally dependent.  


\section{Mathematical Modeling}

Here we introduce a class of parsimonious models in which effects of both malware and bonware on goal accomplishments are approximated as deterministic, continuous differentiable variables. Our models describe the behavior of a system's functionality over the course of a run during which it is being attacked by malware and defended by bonware.
To simplify our modeling, we assume the normal functionality to be constant in time, $\Fnominal(t)=\Fnominal$.  When we apply our mathematical models to our experimental results in Section~\ref{sec:experimental data}, we will ensure this assumption by explicitly dividing the functionality during a cyber attack scenario, $F_\text{attack}(t)$, by the functionality during a baseline scenario, $F_\text{baseline}(t)$, to obtain $F(t)$.  With this definition of $F(t)$, we ensure $\Fnominal(t)= \Fnominal=1.$ 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


In the first set of models, we assume that there is an observable, sufficiently smooth function representing goal accomplishment, and we define functionality to be its time derivative.  Then, we motivate a parsimonious model for the differential equation governing functionality, give the general solution, and discuss a few specific cases.

\subsection{Linear Differential Equation and General Solution}\label{sec:continuous}

We make the assumption that goal accomplishment is twice continuously differentiable: $\ma\in C^2$, and thus functionality is continuously differentiable:  $\functionality \in C^1$. 


Malware degrades the system's functionality while bonware aims to increase functionality over time.  We define the \impact{} of malware, $\malware{},$ to be a function that, in the absence of bonware, when multiplied by the functionality at the present time, causes the time rate of change in functionality to decrease by that amount:
\begin{equation}
  \frac{dF_\malware(t)}{dt} = - \malware(t) F(t).
\end{equation}
Similarly, the \impact{} of bonware, $\bonware$, restores the functionality by causing the time rate of change in functionality to increase by the product of $\bonware$ with the difference between normal and current functionality:
\begin{equation}
  \frac{dF_\bonware(t)}{dt} = \bonware(t) (\Fnominal (t) - F(t)).
\end{equation}

Both malware \impact{} and bonware \impact{} are continuous functions of time, $\malware, \bonware \in C^0.$ The \impact{} on functionality is the sum of the \impacts{} of malware and bonware:  $\frac{dF(t)}{dt}= \frac{dF_\malware(t)}{dt}+\frac{dF_\bonware(t)}{dt} $, thus
\begin{equation}
    \frac{d\functionality}{dt} + \Qware(t) \functionality(t) = \Fnominal \bonware (t),
    \label{eq:00}
\end{equation}
where $\Qware(t)=\malware(t)+\bonware(t).$

Since we expect bonware to help (or at least not harm) and malware to not help, we assume $\bonware(t) \ge 0$ and $\malware(t) \ge 0$.  We also assume normal functionality is positive, $\Fnominal > 0,$ and functionality is always positive and less than or equal to normal functionality, $0 < \functionality(t) \le \Fnominal.$ This first-order linear differential equation has the following solution: 

\small
\begin{equation*}
    F(t)  = \expminus \left( F(0) + \bintegral \right).
\end{equation*}
\normalsize
To help us understand how the model works, we find explicit solutions for a number of examples.


\subsection{Constant model}

Assuming $\malware, \bonware,$ and $\Qware$ are constant, we have
\begin{equation}  \label{eq:1}
    \frac{d\functionality}{dt} + \Qware \functionality(t) =  \Fnominal \bonware.
\end{equation}
 
      
\subsubsection{No bonware}

If $\bonware=0$, then Equation~\ref{eq:1} reduces to $\frac{d\functionality}{dt} + \malware \functionality(t) =  0$ and $\functionality(t) = \functionality(0) e^{-\malware t}$. If also $\malware=0$ (no bonware and no malware), then $\frac{d\functionality}{dt}=0$ and $\functionality(t)=\functionality(0)$.
 
  
\subsubsection{Bonware}\label{sec:4.2}

With bonware present, the solution is 
\begin{equation} \label{eq:3}
    \functionality(t) = \left[\functionality(0) - \frac{\Fnominal \bonware}{ \Qware } \right] e^{-\Qware t} + \frac{\Fnominal \bonware}{\Qware}.
\end{equation}

\begin{figure}[th]
    \centering
    \zzz{prod-figure2.pdf}
    \caption{Normalized functionality, $\functionality(t)/\Fnominal$, is shown for various values of $\malware$ (malware attacking) and $\bonware$ (bonware defending) and initial condition $\functionality(0)=\Fnominal$.  The functionality over time depends on the relative strengths of bonware and malware.  With the system initially at normal functionality and malware \impact{} nonzero, functionality exhibits exponential decay.}
    \label{fig:2}
\end{figure}

If $\functionality(0)>\sfrac{\Fnominal\bonware}{\Qware},$ then $\functionality(t)$, initially at $\functionality(0)$ at time $t~=~0$, will decrease to $\sfrac{\Fnominal\bonware}{\Qware}$ (see Figure~\ref{fig:2}).  If  $\functionality(0)~>~\sfrac{\Fnominal\bonware}{\Qware},$ then the function $\functionality(t) = \functionality(0)$ will be constant.  If $\functionality(0)<\sfrac{\Fnominal \bonware}{\Qware},$ the function will start at $\functionality=\functionality(0)$ and increase to $\sfrac{\Fnominal \bonware}{\Qware}.$ The plots for $\malware>0$ in Figure~\ref{fig:2} show that even in the presence of bonware, malware has an impact on the system.  \blue{The steady-state of the system is obtained either by setting $\frac{d\functionality}{dt}=0$ in Equation~\ref{eq:1} or letting $t\to\infty:$}
\begin{equation} \label{eq:5}
    \functionality_\infty=  \lim_{t\to\infty} \functionality(t)  =\Fnominal\frac{\bonware}{\malware+\bonware}
\end{equation}
so that the antidote to malware is to overwhelm it with bonware.  \blue{The exponent, $-\Qware t = (-\malware-\bonware)t$ in the solution given by Equation $\ref{eq:3}$ indicates that increasing the \impact{} of either malware or bonware will cause the system to more quickly approach steady-state.}{}  At steady-state,
\begin{equation}\label{eq:5a}
    \begin{aligned}
        \frac{ \Fnominal -\functionality_\infty}{\functionality_\infty}  =  \frac{\malware}{\malware+\bonware}. 
    \end{aligned}
\end{equation}
Equation~\ref{eq:5a} gives us further insight into the trade-off between \impacts{} of both malware and bonware.  The relative decrease of the function from normal functionality is equal to the ratio of malware \impact{} to the sum of malware and bonware \impacts{}.
\subsection{Piecewise constant model}\label{subsection:piecewise constant model}

If either malware's or bonware's \impact{} diminishes at some point in the incident, the model may switch from one set of constants defining malware and bonware to another set of constants.  The differential equation (Eq.~\ref{eq:00}) may now be expressed as
\begin{equation}
    \frac{d\functionality}{dt} = \sum_{j=0}^{N-1}(\Fnominal-\functionality(t)) \bonware_j(t) -  \functionality(t) \malware_j (t),
    \label{eq:000}
\end{equation}
where the vectors $\boldsymbol{\malware} =( {\malware}_0, {\malware}_1, \cdots {\malware}_{N-1} )$ and $\boldsymbol{\bonware} =( {\bonware}_0,  {\bonware}_1,\cdots, {\bonware}_{N-1})$ contain the malware \impacts{} and bonware \impacts{} within time windows whose end points are defined by  $\{t_0, t_1, \cdots, t_N \}$. The solution will be a function which, in each time interval, is the solution found in Equation~\ref{eq:3}:
\begin{align*} \label{eq:piecewise:constant}
    \functionality(t)     = \left[\functionality(t_j) - \frac{\Fnominal \bonware_j}{ \Qware_j } 
    \right] e^{-\Qware_j\cdot (t-t_j)} + \frac{\Fnominal \bonware_j}{\Qware_j},                 \\
    \quad (t_j \le t < t_{j+1}), \quad (j=0,\cdots, N-1)                                        
\end{align*}
where $\Qware_j = \malware_j + \bonware_j$.  The purple curve in Figure~\ref{fig:notional} is an example realization of this model.
\begin{figure}[hb]
    \centering
    \zzz{prod-figure3.pdf}
    \caption{The smooth curve is an example functionality curve with piecewise constant malware and bonware \impacts{}.  The notional data and piecewise constant model fit are described in Section \ref{sec:parameters}.}
    \label{fig:notional}
\end{figure}
\subsection{Linear model}  \label{sec:linear}

\newcommand{\tempa}{\Omega(t)}
\newcommand{\tempb}{\Lambda}

The \impacts{} of malware and bonware may also be linear functions of $t$, so that $\malware(t) = \nu-\mu t$, $\bonware(t)~=~\alpha~-~\beta~t$, and $\Qware(t) = \lambda - \omega t$, where $\lambda = \alpha + \nu$ and $\omega  = \beta + \mu$.  Under this linear model, Equation~\ref{eq:00} becomes
\begin{equation}
    \frac{d\functionality}{dt} + (\lambda - \omega t) \functionality(t) = \Fnominal (\alpha - \beta t).
    \label{eq:linear:model}
\end{equation}
The solution can be expressed in terms of the error function
% $\erf(\cdot)$:
$\blue{\erf(z)=\frac{2}{\sqrt{\pi }}\int_0^z e^{-\tau^2}\,d\tau}$:
\begin{equation}
    \label{eq:6}
    \begin{aligned}
        \frac{\functionality(t)}{\Fnominal} 
            & = \frac{1}{\tempa} \left\{                                
                \frac{\functionality(0)}{\Fnominal}
               -\frac{\beta}{\omega}\left(1-{\tempa}\right) +(\alpha \omega
                -\beta \lambda )
            \right.\\
            \times
            & \left.  \frac{\sqrt{\frac{\pi }{2}} e^{\tempb^2} }{\omega^{3/2}}\left[\erf\left(\tempb\right)+\erf\left(\frac{\omega t}{\sqrt{2 \omega }}-\tempb\right)\right] \right\}
    \end{aligned}
\end{equation}
\normalsize
where $\tempa = e^{\lambda  t-\frac{1}{2}\omega t^2}$, and $\tempb = \sfrac{\lambda}{\sqrt{2 \omega }}$.


\subsection{Piecewise linear model}

\newcommand{\tcj}{\Omega_j(t)}  
\newcommand{\td}{\Lambda}

Both malware and bonware \impacts{} may initially be linear, but if the situation changes and a different linear model holds after a time, the model should be able to account for it.  In particular, if malware \impact{} is decreasing over time, at some point we will reach $\malware=0$ and the model switches to a new linear model. Equation~\ref{eq:linear:model} can be written
\begin{equation*}
    \frac{d\functionality}{dt} = \sum_{j=0}^{N-1}  \left[ (\lambda_j - \omega_j t) \functionality(t) -  \Fnominal (\alpha_j - \beta_j t) \right]. \label{eq:piecewise:linear}
\end{equation*}
The solution follows from Equation~\ref{eq:6}:
\small
\begin{align*} \label{eq:piecewise:linear:solution}
    \frac{\functionality(t)}{\Fnominal} & = \frac{1}{\tcj} 
    \left\{ 
    \frac{\functionality(t_j)}{\Fnominal}-\frac{\beta_j}{\omega_j }\left(1-\tcj\right) +(\alpha_j  \omega_j -\beta_j  \lambda_j )\right.\\
    \times                              & \left. \frac{\sqrt{\frac{\pi }{2}} e^{\td_j^2 }}{\omega_j^{3/2}} \left[\text{erf}\left(\td_j\right)+\text{erf}\left(\frac{\omega_j (t-t_j) }{\sqrt{2 \omega_j }}-\td_j\right)\right] \right\}, \\
                                        & \quad (t_j \le t < t_{j+1}), \quad (j=0,\cdots, N-1)
\end{align*} \normalsize
where $\tcj=e^{\lambda_j (t-t_j)-\frac{1}{2}\omega_j (t-t_j)^2 }$ and $\td_j=\sfrac{\lambda_j }{\sqrt{2 \omega_j }}$.  

Example realizations of the piecewise linear models are shown in Figure~\ref{fig:piecewise:linear}.

\begin{figure}[th]
    \centering
    \zzz{prod-figure4.pdf}
    \caption{Normalized functionality, $\functionality(t)/\Fnominal$,
        is shown for piecewise linear models and initial condition
        $F(0)=\Fnominal$. Both malware and bonware \impacts{} are
        initially linear functions of time: $\malware~=~\max(0.5-0.1t,0), \bonware = b_0+0.04t.$ When malware \impact{} reaches $\malware=0$, bonware \impact{} continues to increase.}
    \label{fig:piecewise:linear}
\end{figure}


\subsection{Obtaining model parameters}\label{sec:parameters}
Given data that represents functionality over the course of an incident where malware and bonware are active, we develop a fast method to estimate the continuous model parameters for a curve that approximates the data, and use these parameters to generate further realizations based on this model.  In Figure~\ref{fig:notional}, notional data is shown (in orange) and the parameters $\malware$ and $\bonware$ are estimated and a fit for the functionality $F(t)$ is found that solves the piecewise constant model expressed by Equation~\ref{eq:000}. 
In this section, we illustrate our fast method to extract the model parameters from this curve.  %The method was used to determine the coefficients $\malware_i$ and $\bonware_i$ in the piecewise model fit to our experimental data.  For example, in Figure~\ref{fig:model fits}, a continuous fit to the experimental data is shown, and the parameters $\malware_i$ and $\bonware_i$ are estimated.

The set $P=\{t_0, \hdots, t_K\}$ partitions the scenario timeline, and malware and bonware are constant in each interval $(t_{i-1},t_i), \,\, i=1, \hdots, K. \,\,$  In each interval, $\Qware_i=\malware_i+\bonware_i$ and the differential equation governing Continuous Model I is $\frac{dF(t)}{dt}+\Qware_i F(t) = \Fnominal (t) \bonware_i.$  Thus, in each interval $(t_{i-1},t_i),$ the solution is 
\begin{equation*}
    \functionality(t)     =
    \left[\functionality(t_{i-1}) - \frac{\Fnominal \bonware_i}{
        \Qware_i } \right]  e^{-\Qware_i (t-t_{i-1})} + \frac{\Fnominal \bonware_i}{\Qware_i}.
\end{equation*}
We compute the \impact{} of malware $\malware_i$ and the \impact{} of bonware $\bonware_i$ in each interval.

We observe that there is a unique switching time $\tchange$ where the functionality's trend reverses, and thus we take $K=2.$ Before the switch, the \impact{} of malware is greater than that of bonware. From the time of the switch until the end of the run, bonware is stronger.  To estimate the switching time $\tchange$, we find the minimum of the data to occur over the interval from 64 s to 75 s. There, the minimum value of the data curve is $m=0.27$.  Taking the midpoint, our estimate for $\tchange$ is 69.5 s.

We numerically solve this system of equations:
\begin{align*}
    \alpha m & = \Fnominal \bonQone,                                                               \\
    m        & = \functionality(0)  -\Fnominal \bonQone e^{-\Qware_1 \tchange}+\Fnominal \bonQone. 
\end{align*}
The first equation says that where the curve meets the minimum of the data, it has experienced exponential decay of $\alpha$ toward the asymptotic minimum.  We take $\alpha$ to be $\alpha=1-\sfrac{1}{e}$. The second equation says that the minimum occurs at the switching time (the time when the model switches from malware dominating bonware, to bonware dominating malware).  Solving this system of equations yields (with $\malware_1=\Qware_1-\bonware_1$), $\malware_1 \approx  0.025$ and $\bonware_1 \approx 0.005$.  To the right of $t^\star$, we fit an exponentially increasing function by numerically solving this system of equations:
\newcommand\FBonQtwo[1]{\frac{#1 \bonware_2}{\Qware_2}}
\begin{align*}
    \zeta                & = \FBonQtwo{F(0)},                     \\
    \tilde{\alpha} \zeta & = \left(m- \FBonQtwo{\Fnominal}\right) 
    \!\! \left(e^{-\Qware_2 (125-t^\star)}+\FBonQtwo{\Fnominal}\right).
\end{align*}
We have found that $\tilde{\alpha}=1-e^{-4}$ and $\zeta=0.95$ are satisfactory values to use for these hyperparameters.  We compute $\malware_2 \approx 0.005$ and $\bonware_2 \approx 0.088$.



\section{Experimental Testbed and Method}\label{sec:components}

A key role of the mathematical models presented above is to help analyze results of actual experimental measurements of resilience. In this section, we introduce the experimental test bed and experimental process we use to observe and characterize cyber resilience of a truck \cite{ellis2022experimental}. In a typical resilience-measuring experiment, the following occurs, conceptually: (1) The truck is assigned a goal (delivering a cargo to a destination, along a specified route). The truck begins to accomplish the goal. The driver controls the truck aiming to maximize probability of the goal's success. (2) At some point along the route, an adversarial cyber effect is activated and begins to degrade goal-relevant performance of the truck. (3) Physical and cyber elements within the truck begin to resist the impact of the cyber effect. After some time, these elements (i.e., bonware, collectively) may succeed in recovering some or all of the degraded performance. (4) The data collection and logging system obtains and records the performance parameters of the truck over time, from the beginning of the run until its end (successful or otherwise). The data are later analyzed using the models presented earlier. 

These processes and functions are implemented in several components of the test bed, which include automotive hardware and simulation software: the \ac{PASTA} by Toyota Motor Corporation, the Unity game development platform, \ac{ADF} developed at the DEVCOM Army Research Laboratory, and the OpenTAP test automation framework by Keysight Technologies. These components and their roles are described in subsections below. In terms of interactions between the components, Unity generates messages via the \ac{MQTT} publish-subscribe network protocol. \ac{ADF} ingests these messages and translates them to \ac{CAN} format, which are then injected onto the appropriate \ac{CAN} bus within \ac{PASTA}. Figure~\ref{fg:datamodel} illustrates the flow of data between components.  

\begin{figure}[tbp]
    \centerline{\includegraphics[trim=0 10 0 15,scale=.95]{dataflow.png}}
    \caption{
        A high-level overview of the data flow between components.
        Portions are derived from \cite{toyama2018pasta}.
    }
    \label{fg:datamodel}
\end{figure}


\subsection{\ac{PASTA}}\label{subsection:pasta}

\ac{PASTA} is a cyber-physical product by Toyota, intended to develop and evaluate new vehicle security technology and approaches on realistic ``white-box'' \acp{ECU} \cite{toyama2018pasta}. There are three vehicle \acp{ECU} provided within the product, each with its own \ac{CAN} bus: powertrain, body, and chassis. These three \acp{ECU} are responsible for their respective group of messages, each generating and responding to traffic on their bus. A fourth \ac{ECU}, the \ac{CGW}, acts as a junction between the three previously mentioned buses. Based on the message and source bus, the \ac{CGW} ferries messages to their appropriate destination bus. The firmware for all \acp{ECU} is open-source, and is accompanied by an \ac{IDE}.

\ac{PASTA} includes simulation boards which calculate how the current \ac{CAN} messages on the buses would physically influence a commercial sedan. These boards then update the vehicle \acp{ECU} with appropriate values. For example, when acceleration pedal operation is inputted, the chassis \ac{ECU} sends a message with the indicated value. The simulation boards observe this message and calculate the physical effects that would result from the input. The results are used to update the values reported by the powertrain \ac{ECU}, which it outputs onto its bus. In this instance, the powertrain \ac{ECU} would send messages indicating the new engine throttle position, \ac{RPM}, and speed. 
Unfortunately, we found the simulation boards rather constraining, for our purposes. We cannot alter, for instance, the parameters involving the engine (e.g., torque and horsepower), the weight of the vehicle, or the terrain that the boards are assuming is being traversed. To overcome these constraints, we integrated a simulation engine (Unity, see below) that would allow for user-defined vehicle details as well as custom terrain. In this configuration, \ac{PASTA} becomes hardware-in-the-loop for the simulation engine. Cyber attacks or defenses that affect the \acp{ECU} present in \ac{PASTA} will also affect the performance of the truck within the simulation.


\subsection{Unity}\label{subsection:unity}

Unity is a widely used game development platform \cite{unity2021unity}. In particular, Unity provides built-in assets and classes regarding vehicle physics, which we leverage to model interactions between our simulated truck and custom terrain.

\subsubsection{Simulated Trucks}

We implemented three types of truck within Unity – light, medium, and heavy. They are designed to interface with data inputs from the white-box \acp{ECU} within \ac{PASTA}. In an experiment, the current chosen truck produces inputs in response to the simulated terrain. These inputs are sent to the corresponding \acp{ECU} within \ac{PASTA}. We then gather responses to these inputs from the \acp{ECU} and send them back to the truck, which it uses to calculate parameters like torque and fuel consumption. For example, assume the truck reports that the accelerator is set to 50\%. This message is injected into \ac{PASTA} as if the chassis \ac{ECU} had generated it. The powertrain \ac{ECU} responds to the message with the corresponding amount of engine throttle. A message with the engine throttle is sent back to Unity, which is then applied to engine power calculations. With this flow, any cyber attacks impacting the \acp{ECU} within \ac{PASTA} will affect the truck.

An automated driver is responsible for generating steering, acceleration, and braking inputs as the truck traverses the terrain. Steering is guided using a waypoint system. Both acceleration and braking inputs are calculated via a \ac{PID} controller guided by a target speed. The controller responds to changes in the terrain or truck performance, and maintains the target speed while preventing oscillation. Optional target speed variability simulates driver attention drift, which may be used to generate multiple unique realizations of the simulation under otherwise identical conditions.

Engine performance is calculated through the use of torque, horsepower, and \ac{BSFC} curves. Engine RPM is derived using the speed, wheel circumference, and effective gear ratio. Using this \ac{RPM} value, the curves are evaluated to discern the corresponding torque, horsepower, and \ac{BSFC} value. Torque is multiplied by the throttle and the current effective gear ratio to obtain the total amount of torque that can be applied to the wheels. Since our trucks are \ac{AWD}, each wheel receives the total amount of torque divided by the number of wheels on the truck. Horsepower and the \ac{BSFC} value are used in conjunction to calculate the amount of fuel that has been used per physics update.

The truck is capable of providing sensor information that is either not present in \ac{PASTA} or needs its functionality altered for our purposes. Currently, this applies to the engine coolant temperature, attitude sensor, and a set of backup engine \acp{ECU}. Engine temperature is present in \ac{PASTA}, but is aligned to the temperature characteristics of a static commercial sedan. Within Unity, we implemented a temperature model that can be controlled by an external fan controller \ac{ECU}. The fan controller monitors the coolant temperature reported by the truck and dictates the operation of a simulated fan on the truck. The fan itself takes significant power to operate, which results in a drop in the available torque that can be applied to the wheels.

\subsubsection{Terrain}

The truck within Unity traverses a custom terrain map that is roughly 81.8 km by 100 km with altitudes up to 910 m. We crafted a course approximately 151 km in length across the map that encompasses multiple terrain types: flat main road, flat off-road, hilly, prolonged ascent, and prolonged descent. On a flat main road, the target speed is 60 km per hour. Otherwise, the target speed is 40 km per hour.


\subsection{Active Defense Framework}

\ac{ADF} is a government-developed framework for prototyping active cyber-defense techniques. \ac{ADF} currently supports \ac{IP} networks and vehicle control networks, namely the \ac{CAN} bus and \ac{SAE} J1708 bus. The framework acts as an intermediary for network traffic, as depicted in Figure~\ref{fg:datamodel}, allowing it to control network message flow, as well as inspect, modify, drop, or generate network messages. In our experimental test bed, \ac{ADF} enables communication between \ac{PASTA} and Unity by translating \ac{CAN} messages to and from \ac{MQTT}, a standard publish-subscribe \ac{IP}-based messaging protocol. \ac{ADF} plugins are also used to provide simulated \ac{ECU} hardware, and to implement cyber attack and defense methods on the CAN bus via ADF’s ability to monitor, modify, inject, or drop CAN traffic.

\subsubsection{Unity-to-PASTA Message Translation}

\ac{ADF} and Unity run on a standalone laptop and are connected to \ac{PASTA} via two \ac{USB} \ac{SLCAN} interface modules. One module is connected to the powertrain \ac{CAN} bus, and the other module is connected to the chassis \ac{CAN} bus. The \ac{PASTA} \ac{CGW} is disconnected from the CAN buses for our experiments, and the body \ac{CAN} bus and body \ac{ECU} are not used. \ac{ADF} is configured to serve as a \ac{CGW} between Unity and \ac{PASTA}. Since Unity does not natively communicate with \ac{CAN} interfaces, \ac{ADF} translates \ac{CAN} messages in real-time to \ac{MQTT} messages and back. Unlike the \ac{PASTA} \ac{CGW}, \ac{ADF} does not relay messages between the powertrain and chassis \ac{CAN} buses themselves. \ac{ADF} relays powertrain \ac{CAN} messages between Unity and \ac{PASTA}, and sends parameters from Unity to the chassis \ac{CAN} bus for display on the \ac{PASTA} instrument cluster. All communication channels are two-way.

\subsubsection{Virtual \acp{ECU} within \ac{ADF}}

For some cyber attacks, a virtual \ac{ECU} is needed. For example, as mentioned before, the \ac{PASTA} platform does not simulate a controllable cooling fan or provide fan controller \ac{ECU} functionality. Therefore, we simulate a fan controller \ac{ECU} using an \ac{ADF} plugin. The fan controller engages the engine cooling fan on the truck when the engine coolant temperature reaches a defined upper limit, and disengages the fan when temperature drops below a lower limit. For the purposes of our experiments, the fan controller \ac{ECU} plugin can simulate an attack on its own firmware, stop the attack, or reset/``re-flash'' itself (i.e., replace the \ac{ECU} firmware). During a reset, the fan controller is offline for a period of time. Use of \ac{ADF} enables creation of other simulated \acp{ECU} and corresponding cyber attacks.

\subsubsection{Performing Cyber Attacks via \ac{ADF}}

A class of attacks on a vehicle bus involves injecting messages. Messages are broadcast on a \ac{CAN} bus, so one message injected at any point on the bus will reach all \acp{ECU} on the bus. While injection attacks cannot block or modify normal \ac{CAN} bus traffic, they can impact vehicle performance if injected messages cause undesired vehicle behavior. If an attacker can physically sever the \ac{CAN} bus wiring at a strategic point and place additional hardware there, it is possible to block or modify the normal bus traffic. Cyber attacks that block or modify messages can prevent \acp{ECU} from controlling the vehicle or falsify vehicle data.

As a man-in-the-middle between \ac{PASTA} and Unity, \ac{ADF} can execute any of these bus-level attack types.

Cyber attacks on \ac{ECU} firmware, by embedding malware, are also feasible. We have simulated the effects of embedded malware in three instances: on the fan controller, the suspension controller, and the main engine \ac{ECU}. Malware on the fan controller simulates a ``stuck fan'' attack in which malware has modified the fan control \ac{ECU} to not disengage the fan once engaged, even when the coolant temperature has dropped below the minimum operational temperature; the suspension controller attack creates the appareance that the truck is abnormally tilted, forcing the truck into a safe ``limp home” mode that reduces the amount of available gears; the main engine \ac{ECU} attack causes erratic performance behavior.

\subsubsection{Performing Cyber Defensive Actions via \ac{ADF}}

Defending against message injection, blocking, and modification at the bus-level requires detecting and filtering injected messages before they reach the \ac{ECU}. The \ac{CAN} bus can be split at potential access points and hardware placed in-line, hardware can be placed between the \ac{CAN} bus and critical \acp{ECU}, or defenses can be integrated into the \acp{ECU} themselves. Examples of these defenses implemented previously using \ac{ADF} include cryptographic watermarking and modeling observable vehicle states to compare current parameters to the model's prediction.

Cyber attacks on \acp{ECU} themselves must be approached differently. If an \ac{ECU} is compromised, measures need be taken to restore proper \ac{ECU} function. Many \acp{ECU} can be re-flashed while the vehicle is operational. The \ac{ECU} may or may not be functional for some duration while being reset or re-flashed, and the impact this will have on vehicle performance depends on the function of the \ac{ECU}. For the \acp{ECU} simulated by ADF plugins, the behavior is to make the \ac{ECU} unresponsive for a set duration, after which normal \ac{ECU} operation is restored. Note, for \acp{ECU} like the main engine \ac{ECU}, this is not possible because the vehicle will become inoperable in its absence. To address this, a manually-crafted \ac{ECU} backup is used while the main \ac{ECU} is re-flashed. 


\subsection{OpenTAP and Data Collection}

OpenTAP is an open-source test automation framework developed by Keysight Technologies \cite{opentap2021whitepaper}. It provides a test sequencer to promote test repeatability, a customizable plugin facility capable of integrating plugin classes implemented in C\# or Python, and result listeners responsible for capturing test data for further analysis. OpenTAP is used to automate the execution of experiments and provide a GUI for testing practitioners to configure experiment steps.

Data are captured from the truck. Examples of data are fuel efficiency, speed, engine torque, and acceleration pedal input; each data value comes with a timestamp of the value occurrence. 

\subsection{Execution of Experiments}

Each individual experimental run follows the same set of steps.  During setup, we establish \ac{CAN} connections to \ac{PASTA}, ensure the messaging infrastructure is running, and start Unity.  During parameter selection, we determine the truck type, cargo weight, type of cyber attack, etc., and designate the number of runs.  During execution, we run automated test scripts with the given parameters and capture the data in a desired format.  Finally, we parse and preprocess the data, fit our mathematical models, and generate graphs and results.

An experiment reflects execution of a single run as described in the beginning of this section. On our terrain, a typical run would take 2-3 hours to traverse in its entirety. However, we focus on shorter 15-minute runs that encompass a cyber attack at variable moments within the run and a potential recovery. Note that it may take the truck several minutes to recover from the attack. We are also capable of executing faster-than-real-time when using solely simulated components, further decreasing execution time of experiment runs.

To form a series of experiments, within our test bed, there are multiple parameters that can be configured to generate varied data captures. Currently, these include: truck type, experiment duration, cyber attack start time, terrain type(s), starting location, ending location, target speed, cyber attack-defense pairings, cargo weight, and target speed variability. 



\section{Experimental Data}\label{sec:experimental data}

Using our test bed, we conducted a series of experimental runs in which a truck is subjected to a cyber attack. Here we focus on one of these series. In this series of experiments, we considered three types of trucks with four possible cargo weights including $0$, the five unique terrains described above, and three types of cyber attacks, including one ``baseline'' scenario with no cyber attack (see Table~\ref{tab:design}).  
For each combination of these, we conducted 30 experimental runs and recorded the truck's speed, fuel efficiency, and other operating parameters. The 30 runs were made unique by adding random variability to the driver's interaction with the accelerator (i.e., ``driver attention drift'' as described in Subsection~\ref{subsection:unity}).

\begin{figure}[tbh]
    \centering
    \includegraphics[trim=0 29 0 0,clip]{prod-averageDataPlot-vehicle3-route4-engineECUAttack300-0-fuelEfficiency.pdf}
    \includegraphics[trim=0 15 0 22,clip]{prod-averageDataPlot-vehicle3-route4-engineECUAttack300-0-speed.pdf}
%     \includegraphics[trim=0 5 0 3,clip]{prod-averageDataPlot-vehicle3-route4-engineECUAttack300-[0, 3000, 6000, 9000]-fuelEfficiency.pdf}
    \includegraphics[trim=0 5 0 3,clip]{fuelEfficiency.pdf}
    \caption{
        Examples of experimental data, illustrating that cyber attacks reduce performance both in fuel efficiency (top panel) and speed (middle panel), and that changes in cargo weight reduce fuel efficiency in the expected manner (bottom panel). \textbf{Top panel:} The fuel efficiency of a heavy truck, carrying no cargo, during a run on hilly terrain. The orange curve indicates the fuel efficiency in the ``engine ECU attack'' run, which is contrasted with the (partly occluded)  cyan curve that indicates the baseline run. \textbf{Middle panel:} Recorded speed during the same run. \textbf{Bottom panel:} Fuel efficiency, now for all four cargo conditions (from top to bottom: 0, 3,000, 6,000, and 9,000kg).
    }
    \label{fig:simulated data}
\end{figure}

\begin{table}[b]
    \centering
    \caption{Overview of Experimental Design}
    \begin{tabular}{p{1.1in}p{1.7in}}\hline
        Independent variable     & Possible values                                                      \\\hline
        3 trucks               & \{ Light, Medium, Heavy \}                                           \\ 
        5 terrains               & \{ Steady Descent, Flat Road, Flat Off-Road, Hilly, Steady Ascent \} \\
        4 cyber attack scenarios & \{ Baseline, Fan, ECU, Suspension \}                                 \\ 
        4 cargo weights          & \{ None, Light, Medium, Heavy \}                                     \\ 
        30 random seeds          & \{1 \ldots 30\}                                                      \\\hline
    \end{tabular}
    \label{tab:design}
\end{table}


\subsection{Data Preprocessing}

\begin{figure*}[!!ht]
    \centering
    \includegraphics[width=\textwidth,bb=0 307 757 537]{insetPlot.pdf}
    \caption{An illustration of the resilience measure $R$. The central panel shows the value of $R$ for 20 different conditions (five subroutes and four cargo weights). Each marker shows $R$ computed using the average of 30 runs of a suspension cyber attack and the average of 30 baseline runs (error bars indicating 95\% confidence intervals), in this case by a medium-weight truck. The panel thus summarizes 1,200 experimental runs. The four side panels illustrate the construction of $R$. Each side panel shows the construction of one marker in the central panel. The blue (upper) curve indicates functionality under the baseline scenario. Note that the baseline functionality differs between subroutes (left vs.\ right panels) and between cargo weight conditions (top vs.\ bottom). The orange (bottom) curve indicates the functionality during the cyber attack. The shaded yellow region between the curves is the effect of the attack: a temporary reduction in functionality. $R$ is the ratio of area under the orange curve to that under the blue curve (Eq.~\ref{eq:R}) and can be interpreted as a measure of resilience: it is the remaining fraction of functionality while under attack. Those values of $R$ are displayed in the central panel, which shows that resilience is high on flat road, but lower on hilly terrain. It further shows a notable effect of cargo weight in the hilly terrain as well as during the steady ascent, but no effect of cargo weight in the steady descent, flat road, or flat off-road subroutes.}
    \label{fig:auc explainer}
\end{figure*}

The operating parameters were recorded at a relatively high frequency of about 50~Hz, which sometimes causes numerical instability (e.g., in calculating fuel efficiency over a 20~ms period).  For this reason, we first applied a smoothing filter to the data.  We chose a running median filter with a window of 72~s.  The running median has the advantage that it downweights extreme values that might result from numerical inaccuracy.  We then took the mean of the 30 runs in each condition to obtain the relatively smooth time series seen in Figure~\ref{fig:simulated data}.

The three panels of Figure~\ref{fig:simulated data} each show the time course of a performance parameter. The top two panels each show one curve for the baseline run (cyan) and one for an attack run (orange). The bottom panel shows four attack runs with different cargo weights.


\subsection{Resilience $R$}

We will use the experimental data to compute the $R$ statistic introduced in Equation~\ref{eq:R} in subsection~\ref{sec:auc based}.  The computation of $R$ is illustrated in Figure~\ref{fig:auc explainer}.  The calculation involves (1) finding the area $\ma_\text{attack}$ under the performance curve during the time when the cyber attack is active, then (2) finding the corresponding area $\ma_\text{baseline}$ under the baseline performance curve, and (3) dividing the former by the latter.  If the resulting $R$ is $1.0$, then the cyber attack had no detrimental effect on performance.  $R$ of $0.0$ means that performance was reduced by 100\%.


\subsection{Modeling Approach}
\label{modeling:approach}

Our modeling approach requires one further data processing step, which is illustrated in Figure~\ref{fig:model fits}. The top panel shows a baseline and attack performance curve. The ratio of these curves (i.e., performance under attack divided by the baseline value) is shown in the middle panel -- this ratio is close to $1.0$ when performance under cyber attack is similar to the baseline performance, and less than $1.0$ when the cyber attack is detrimental to performance. This performance ratio is the measure of functionality that we use for our modeling. In the bottom panel, we show the fitted ``piecewise constant'' model that is described in Subsection~\ref{subsection:piecewise constant model}. The red and green intervals indicate the activity periods of the malware and bonware, respectively. When they are inactive, these effectiveness parameters are $0$, otherwise they are $M$ and $B$ respectively. We can see that the model captures the drop in performance when the malware is active.

\begin{figure}[bt]
    \centering
    \includegraphics[trim=0 29 0 0,clip]{prod-averageDataPlot-vehicle3-route1-engineECUAttack300-0-fuelEfficiency}
    %\includegraphics[trim=0 5 0 22,clip]{prod-odeRecoveryPlot-vehicle3-route1-engineECUAttack300-0-fuelEfficiency}
    \includegraphics[trim=0 5 0 22,clip]{prod-odeRecoveryPlot-vehicle3-route1-engineECUAttack300-0-fuelEfficiency-shift}
    \caption{
        Progression of data over time. 
        \textbf{Top panel:} Fuel efficiency of a heavy truck, carrying no cargo, during a run on steadily descending terrain (orange: Engine ECU attack run; cyan: baseline run). 
        \textbf{Bottom panel:}
        The fuel efficiency ratio (solid grey line) is the performance in the attack run divided by the performance in the baseline run. The overlaid, blue dashed line, is the fit of the continuous model. The green and red horizontal lines at the top and bottom indicate the times when the bonware and malware (resp.) are active. The model captures the rapid decline to an equilibrium state around 92\% performance as well as the more gradual recovery after the cyber attack.
    }
    \label{fig:model fits}
\end{figure}

To summarize and interpret our data, we applied this model to the data from each experimental condition separately.  In order to automate the parameter estimation process, we implemented our piecewise constant model using a Bayesian inference engine \cite{pyjags,Matzke2017}.  To further facilitate the automation, we additionally allowed the model to estimate the time points  where performance begins to decline ($t_1$) and recover ($t_2$).
This implementation is considerably slower than the fast method developed above in subsection~\ref{sec:parameters}, but it has the advantage of being fully automatic and easily extendable for future projects. The method has the additional advantage that it lets us quantify the uncertainty in parameter estimates.


\section{Discussion of Results}

\subsection{Experimental Results}

Considering the large scope of our experiment, we focus on examples of the types of conclusions we are able to draw.

First, as Figures~\ref{fig:simulated data}, \ref{fig:auc explainer}, and~\ref{fig:model fits} show, our cyber attacks cause decreases in performance in the expected parameters at the expected times.  For example, the cyber attack on the suspension causes a reduction in fuel efficiency and speed compared to the baseline scenario.  We also see a slight square-wave pattern with a period of 72~s, corresponding to the normal behavior of the engine cooling fan periodically engaging and disengaging.  We also see that fuel efficiency decreases as cargo weight increases.


\subsection{Resilience $R$}

Figure~\ref{fig:auc explainer} illustrates that the resilience measure $R$ (based on the area under the curve concept) follows our intuitive understanding of what a measure of cyber resilience should do: it is higher if performance is impacted by cyber attack less, and lower if it is impacted more. It is relatively unimpacted in cases where no impact was expected (e.g., on the flat road subroutes in Fig.~\ref{fig:auc explainer}, there is no difference between cargo weight conditions), and it gives orderly results when differences are expected (e.g., when in Fig.~\ref{fig:auc explainer} the $R$ is affected by cargo weights, it
is consistently lower for heavier cargo).

The top panel of Figure~\ref{fig:interaction plot} shows results for the same truck when it is subjected to the cyber attack on the engine fan controller. Here, we see a different pattern of results, with the effect generally being greater when the cargo is lighter. However, the results remain ordered and show a great deal of consistency. There seems to be much less difference between subroutes during this attack. Also, on average, the loss of functionality due to this attack is smaller than that due to the attack on the engine ECU.

Taken together, our experimental data support the validity of the $R$ measure as a quantitative measure of cyber resilience.


\subsection{Modeling Results}

As illustrated in Figure~\ref{fig:model fits}, our mathematical model and the experimental data exhibit a similar pattern and the model produces a good fit. Moreover, the estimates of parameters $M$ and $B$ attain values that reflect the temporal behaviors of experimental data (e.g., high $B$ is associated with rapid recovery, and the ratio of $B/(M+B)$ approximates the performance equilibrium when the cyber attack is active).

The modeling approach allows us to summarize complex time series with two interpretable parameters: the malware effectiveness $M$ and the bonware effectiveness $B$. This facilitates comparison of the cyber resilience of our trucks under various conditions. For example, Figure~\ref{fig:interaction plot} shows the pattern of results of an engine ECU cyber attack on a heavy truck (note: higher $B$ means more effective bonware and higher $M$ means more effective malware). At a glance at the middle panel, we can determine that the truck resists the cyber attack better when it is not hauling cargo (blue markers are always higher), and especially so when the terrain is a steady ascent (the difference is especially pronounced in that subroute). The bottom panel shows that the cyber attack is relatively more effective when the cargo is light (blue markers are often higher) and especially the road is flat (the blue line has its peak there). Comparing the magnitude of the parameter estimates between the two panels ($B$ is greater than $M$ by at least an order of magnitude) tells us that this cyber attack, even at its most effective, only has a modest effect on functionality.


\begin{figure}[t]
    \centering
    \includegraphics[trim=0 0 0 0,clip]{outsetPlot-FMTV-fanAttack450-fuelEfficiency}
    \includegraphics[trim=0 18 0 0,clip]{prod-subroutePayloadPlotJoint-vehicle3-engineECUAttack300-B-speed}
    \includegraphics[trim=0 0 5 15,clip]{prod-subroutePayloadPlotJoint-vehicle3-engineECUAttack300-M-speed}
    \vspace{-2ex}
    \caption{Example results of experiments. Round markers indicate parameter estimates, the intervals around the markers are 95\% credible intervals. Each panel summarizes 1,200 runs (5 terrains by 4 cargo weights by 30 repetitions, once under baseline and once under cyber attack). \textbf{Top:} The $R$ measure for a medium truck subjected to a fan cyber attack. \textbf{Middle and bottom:} Parameter estimates of the piecewise continuous model applied to performance of a heavy truck under a cyber attack on the engine ECU. The middle panel displays the effectiveness of the bonware as a function of terrain and cargo weight, while the bottom panel displays effectiveness of the malware. One observation is that the effectiveness of the bonware is generally much higher than that of the malware, largely due to the physical resilience of the truck machinery.}
    \label{fig:interaction plot}
\end{figure}


\section{Conclusions and Future Work}

We have reported results of the \textit{Quantitative Measurement of Cyber Resilience} project, in which we obtain experimental data with physical-digital twins of several cargo trucks and analyze the data with mathematical modeling of time series in order to quantify and measure the cyber resilience of the trucks.  We were successful in generating data with apparent fidelity, showing that changes in the setup of the experimental runs (e.g., heavier cargo, more challenging terrain) result in differences in performance that accord with our subject matter expertise as well as common sense expectations.

We proposed two types of summary statistics. One is a measure of resilience based on the area under the performance curve. Another type is based on fits of a mathematical model to temporal evolution of the performance curve, and measures the effectiveness of malware and bonware. These measures seem to capture the salient patterns in the experimental data succinctly, supporting their use as quantitative measures of cyber resilience.

We believe there is much that could still be learned with our (or a similar) test bed. Data is relatively easy and fast to gather, and more variables can still be introduced. Additionally, similar test beds could be constructed for other types of vehicles, but also for other diverse types of complex equipment, infrastructure, or critical digital services. For the trucks, the test bed could still be augmented with additional derived measures of functionality, such as maneuverability.

Similarly, there are further potential developments in the mathematical modeling aspect. New models could be implemented to allow for multivariate functionality, to account for trade-offs between different performance parameters. 

%\makeatletter
%\@ifpackageloaded{ulem}{\todo{Note: ulem \LaTeX{} package interferes with references section; be sure to remove it.}}{}
%\makeatother


\small

\bibliographystyle{IEEEtran}
\IEEEtriggeratref{25}
\bibliography{joint.bib}\null
\input{includes/symbols}

\end{document}
