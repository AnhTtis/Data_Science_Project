



\begin{abstract}
% Recent works have shown progress in opinion summarization where general summaries are automatically generated from salient opinions expressed in reviews of products. In this work, we propose two simple yet effective approaches to generate aspect and general opinion summaries without human supervision by training on synthetic datasets. Our first approach, \textit{Seed Words Based Leave-One-Out} (\textsc{SW-LOO}), constructs synthetic datasets with aspect-related sentences identified simply by hard matching aspect seed words and outperforms existing methods on \textsc{Space} and \textsc{Oposum+} datasets. Our second approach, \textit{Natural Language Inference Based Leave-One-Out} (\textsc{NLI-LOO}) identifies aspect-related sentences to build synthetic datasets utilizing an NLI model in the more strict setting where aspect seed words are not available. Being the first approach that generates aspect summaries without using seed words, \textsc{NLI-LOO} achieves comparable or even better performance against existing methods on \textsc{Space} and \textsc{Oposum+} datasets.



% Recent works have shown progress in opinion summarization where general summaries are automatically generated from salient opinions expressed in product reviews. 

Opinion summarization provides an important solution for summarizing opinions expressed among a large number of reviews. However, generating aspect-specific and general summaries is challenging due to the lack of annotated data. In this work, we propose two simple yet effective unsupervised approaches to generate both aspect-specific and general opinion summaries by training on synthetic datasets constructed with aspect-related review contents. 
Our first approach, \textit{Seed Words Based Leave-One-Out} (\textsc{SW-LOO}), identifies aspect-related portions of reviews simply by exact-matching aspect seed words and outperforms existing methods by $3.4$ ROUGE-L points on \textsc{Space} and $0.5$ ROUGE-1 point on \textsc{Oposum+} for aspect-specific opinion summarization.
Our second approach, \textit{Natural Language Inference Based Leave-One-Out} (\textsc{NLI-LOO}) identifies aspect-related sentences utilizing an NLI model in a more general setting without using seed words and outperforms existing approaches by $1.2$ ROUGE-L points on \textsc{Space} for aspect-specific opinion summarization and remains competitive on other metrics. 

%where aspect seed words are not available. Being the first approach that generates aspect summaries without using seed words, \textsc{NLI-LOO} achieves comparable or even better performance against existing methods on both datasets.

% Experiments on two benchmark datasets \textsc{Space} and \textsc{Oposum+} show the effectiveness of our approaches.
% \end{abstract}


% %% commented version
% Recent works have shown progress in opinion summarization where general summaries are automatically generated from salient opinions expressed in product reviews. In this work, we propose two simple yet effective unsupervised approaches to generate aspect and general opinion summaries by training on synthetic datasets constructed with aspect-related review sentences. Our first approach, \textit{Seed Words Based Leave-One-Out} (\textsc{SW-LOO}), identifies aspect-related sentences simply by hard matching \shuai{let's not use the term "hard matching". How about exact matching?} aspect seed words and outperforms existing methods on \textsc{Space} and \textsc{Oposum+} datasets. Our second approach, \textit{Natural Language Inference Based Leave-One-Out} (\textsc{NLI-LOO}) identifies aspect-related sentences utilizing an NLI model in a more realistic setting \shuai{Sounds a bit weird. Does it mean that the 1st approach is not realistic? How about "relaxed setting" or "general setting". } where aspect seed words are not available. Being the first approach that generates aspect summaries without using seed words, \textsc{NLI-LOO} achieves comparable or even better performance against existing methods on both datasets.
\end{abstract}