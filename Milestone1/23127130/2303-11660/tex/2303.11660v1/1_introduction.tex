

\section{Introduction}
\label{sec:intro}
Customer reviews play a vital role in decision-making for customers and product (or business) providers, as customers usually resort to reviews to guide their purchasing decisions and product providers improve their products based on reviews as feedback. However, it becomes hard for customers or product providers to read through all reviews before making decisions with the explosion of online reviews in recent years. Opinion summarization \cite{hu2006opinion, wang-ling-2016-neural, angelidis-lapata-2018-summarizing, brazinskas-etal-2020-unsupervised,  brazinskas-etal-2022-efficient, angelidis-etal-2021-extractive, amplayo-etal-2021-aspect, basu-roy-chowdhury-etal-2022-unsupervised}, the task of generating a general summary of \textit{salient} opinions expressed among reviews, provides a feasible solution to this problem. 
% amplayo-lapata-2020-unsupervised, chu2019meansum

Different from summarization in Wikipedia and news domains \cite{nallapati-etal-2016-abstractive, narayan-etal-2018-dont, see-etal-2017-get, narayan-etal-2018-ranking, liu-lapata-2019-text, cachola-etal-2020-tldr}, opinion summarization cannot rely on reference summaries for model training since it is difficult and expensive to annotate large scale reviews-summary pairs. Also, customers usually care about specific aspects of a product instead of a \textit{general} high-level summary. Thus, fine-grained \textit{aspect-specific} opinion summaries are required, and this makes the annotation process even more difficult and expensive.

\citet{amplayo-etal-2021-aspect} propose an abstractive approach to generate aspect-specific opinion summaries by training on synthetic datasets. They construct synthetic datasets with review elements (words, phrases, or sentences) identified by a multiple instance learning (MIL) module \cite{keeler1991self} learned with silver-standard labels obtained using aspect seed words. We first follow this direction to propose a more straightforward and effective method that excludes the complex learning module to identify aspect-related elements to construct synthetic datasets. Moreover, aspect seed words, which again require human efforts, may not always be available when moving to new domains. Thus we propose another more general solution without the curation and supervision of aspect seed words.


% Moreover, since it is not realistic to assume aspects seed words, which require some human efforts to obtain, and not salable, are readily available when moving to new domains, we seek to explore method without using aspect seed words to generate aspect summarization.

% To tackle unsupervised \shuai{remove. we cannot call it unsupervised, as seed words are used in the 1st approach} aspect-based opinion summarization, 

Specifically, we propose two simple yet effective methods to identify aspect-related review sentences and construct aspect-specific synthetic datasets in a \textit{\underline{L}eave-\underline{O}ne-\underline{O}ut} (\textsc{LOO}) \cite{brazinskas-etal-2020-unsupervised, elsahar-etal-2021-self, brazinskas-etal-2022-efficient} style and then finetune pretrained language models (PLMs) on the synthetic datasets: (a) \textsc{SW-LOO} identifies aspect-related sentences by simply exact-matching aspect seed words and outperforms existing approaches by $3.4$ ROUGE-L points and $0.5$ ROUGE-1 point on aspect opinion summaries of \textsc{Space} and \textsc{Oposum+} respectively; (b) \textsc{NLI-LOO} identifies aspect-related sentences with a finetuned NLI \cite{bowman-etal-2015-large, williams-etal-2018-broad} model. Being the first approach that does not use aspect seed words, it outperforms existing approaches on aspect opinion summarization by $1.2$ ROUGE-L points for \textsc{Space} and falls behind at most $1$ ROUGE point on other metrics.   





% In summary, our contributions are twofold.
% % \addtolength\itemsep{-4mm}
% \begin{itemize}[leftmargin=*,topsep=4pt]
% \addtolength\itemsep{-3mm}
%     \item We propose SW-LOO, a simple yet effective unsupervised abstractive approach that generates both general and aspect opinion summaries, and outperforms previous methods on \textsc{Space} and \textsc{Oposum+} datasets.
%     \item We propose NLI-LOO, the first approach to generate aspect summaries without using aspect seed words, and still achieves comparable or even better performance with \textsc{SOTA} methods.
% \end{itemize}

% opinion mining \cite{pang2008opinion, miao2020snippext} whose ultimate goal is to collect customers' opinions regarding an entity has been rapidly pushed forward. Different aspects of opinion mining have been studied including sentiment analysis \cite{pang-etal-2002-thumbs}, which assigns sentiment labels to reviews or review sentences, aspect extraction \cite{mukherjee-liu-2012-aspect, he-etal-2017-unsupervised}, which extracts related aspects of an entity, opinion extraction \cite{angelidis-lapata-2018-summarizing}, which extracts opinion phrases paired with sentiment labels, and probably the most notable topic in recent years, opinion summarization \cite{hu2006opinion, wang-ling-2016-neural, angelidis-lapata-2018-summarizing, chu2019meansum, brazinskas-etal-2020-unsupervised, amplayo-lapata-2020-unsupervised}, which generate a textual summary for salient opinions expressed in reviews.
