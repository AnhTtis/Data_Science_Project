\section{Preliminaries and Definitions}
\label{sec:prelim}

\smallskip\noindent \textbf{Feasibility of MILP.} Let $\realvars$ be a set of \emph{real variables}. A \emph{linear constraint} has the form $\sum_{x_i\in \realvars}c_i \cdot x_i \bowtie d$, where $\bowtie\ \in \{\leq, <, =\}$ and the $c_i$'s and $d$ are rational constants. An \emph{integral constraint} has the form $x \in \Z$, and a \emph{binary constraint} has the form $x\in\{0, 1\}$, where $x\in \realvars$.
A \emph{solution} $\solution:\realvars\mapsto\R$ is a mapping from variables to real values. $\alpha$ is a \emph{feasible} solution for a set of constraints $\phi$, written $\alpha\models \phi$, if replacing each variable $x$ in $\phi$ by $\alpha(x)$ results in a set of true statements. If no feasible solution exists for $\phi$, $\phi$ is \emph{infeasible}. The MILP feasibility problem is to determine whether a feasible solution exists for a set of constraints.

A \emph{convex relaxation} $\rlx{\phi}$ of $\phi$ can be obtained by dropping all the integral constraints in $\phi$ and replacing binary constraints $x\in\{0,1\}$ with $0\le x\le 1$. The feasibility of $\rlx{\phi}$ can be determined with convex optimization (e.g., the simplex algorithm~\cite{dantzig1955generalized}). If $\rlx{\phi}$ is infeasible, then $\phi$ is infeasible. But the reverse is not true, because a feasible solution to $\rlx{\phi}$ might not satisfy the integral or binary constraints.

\smallskip\noindent \textbf{One-hot constraints.} One-hot constraints can encode requirements like ``the system must be in exactly one mode.'' For example, in locomotion, the modes could correspond to the regions where the robot can step~\cite{deits2014footstep}; and in manipulation, the modes could correspond to disjoint contact scenarios (e.g., contact and no contact)~\cite{marcucci2019mixed}. A one-hot constraint can be encoded over a set $\binvars$ of real variables as follows.

\begin{align}\label{eq:onehotA}
\onehot(\binvars) := \Big(\sum_{x_i \in \binvars} x_i = 1\Big) \land \Big(\bigwedge_{x_i \in \binvars} x_i \in \{0, 1\}\Big)    
\end{align}
Equation~\ref{eq:onehotA} states that exactly one variable in $\binvars$ is 1 and the rest must be 0. For a PWA system with $m$ modes, $\binvars$ would contain $m$ variables, each corresponding to one mode. Alternatively, the one-hot constraint can be encoded in propositional logic. One way to do this is by introducing a set $\pvars=\{p_1, \ldots, p_m\}$ of propositional variables, one for each mode.  The constraint is then:
\begin{align}\label{eq:onehotL}
\onehot_L(\pvars) := \big(\bigvee_{p\in \pvars} p\big) \land \big(\bigwedge_{1\leq i < j \leq m}(\neg p_i \lor \neg p_j)\big)
\end{align}
The first conjunct requires at least one variable in $\pvars$ to be \true, and the rest enforce that at most one variable in $\pvars$ is \true. In order to be able to use both arithmetic and logical constraints together, we need a way to connect the variables.  We assume a bijection $\prop:\binvars\mapsto\pvars$ from real variables to the corresponding propositional variables (e.g., $\prop(x_i) = p_i$).


\smallskip \noindent \textbf{PWA Control as MILP.} When each mode is a polytope (i.e., a bounded polyhedron), PWA dynamics can be encoded with one-hot constraints and linear constraints.
%The latter describe the state-input region of each mode and the affine system behavior within a mode.
%(e.g., in the form of an indicator constraint). 
A PWA control problem is defined with respect to an initial condition, a goal, and a horizon $T$.  The question is whether the system can reach the goal within $T$ steps starting from the initial condition.  This can be encoded with a constraint of the form: 
\begin{equation}\label{eq:pwamilp}
\phi := \C_{init}(\realvars^1) \land \bigwedge_{t=1}^{T}(\C_{pwa}(\realvars^t) \land \onehot(\binvars^t))  \land \C_{goal}(\realvars^T)
\end{equation}
where $\realvars^t \in \realvars$ are real variables for step $t$ and $\binvars^t\subset\realvars^t$ correspond to the modes at step $t$.
$\C_{init}$ describes the initial state, and $\C_{goal}$ describes the goal. In this paper, we assume $\C_{init}$ and $\C_{goal}$ only contain linear constraints, so $\phi$ is a set of linear and one-hot constraints. Solving the PWA control problem amounts to checking the feasibility of $\phi$


\smallskip \noindent \textbf{Sum-of-Infeasibilities.} In convex optimization~\cite{boyd2004convex,king2013simplex},
the \emph{sum-of-infeasibilities} (SoI) method can be used to check the feasibility of a set of linear constraints: the feasibility problem is cast as an optimization problem, with a cost function $f(\realvars)$ representing the total \emph{violation} of the constraints by the current solution (e.g.., the sum of the distances from each out-of-bounds variable to its closest bound). The lower bound of $f$ is 0 and is achieved only if the current solution is feasible. In Section~\ref{sec:soi}, below, we build on this idea, proposing a cost function $\soi(\realvars)$ that represents the total violation of the one-hot constraints by the current solution and a stochastic minimization solution.

