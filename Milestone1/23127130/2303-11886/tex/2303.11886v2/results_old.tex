

\Otman{talk about global support of modes? Maybe that's not desireable? Need to change this once I experiment with local support}


\section {Results}
Our method specializes in applications that require dynamically changing control of high-resolution, elastic materials with complex rigs. We show real-time results for augmenting AR based skeleton-tracking with secondary motion, and discuss how our method could easily be incorporated into a character controller in a game engine.      


\subsection{AR Manipulation of Various Rigs}
We show that our approach can be used on any arbitrary rig, so long as we can define its rig Jacobian. We show a user controlling a wide range of geometry and rig combinations in Figure \ref{fig:ARDifferentRigs}. Fast Complementary Dynamics allows for a user to creatively explore how they wish to best interact with their scene. Note that some rigs control motion that is not trivially obtainable from physical simulation, such as the twisting motion obtained by QBS. \Otman{I want a really exotic rig, something like PSD}
\begin{figure}
\includegraphics[width=2cm,height=3cm,keepaspectratio]{images/white.png}
\caption{User controlling a Linear Blend Skinning rig, mapping their arms to the wings (left). User controlling a point handle rig, animating a walking velociraptor with their hand (middle). User controlling 4 seperate bones of a 4-legged monster with their legs and arms (right). User controlling a tall giraffe, twisting the giraffe's neck with a dual quaternion skinning rig.}
\label{fig:ARDifferentRigs}
\end{figure}


\subsection{Skeleton Tracking Affine Rig}
We use our method to augment rig motion obtained from a real-time skeleton pose-tracker. We make use of a publically available set of Deep Learning based tools in Mediapipe \cite{lugaresi2019mediapipe}, that capture a video live stream and outputs any detected skeletal joint positions in screen space and in world space. 

Figure \ref{fig:ARAffineRigElepehantDemo} shows a user manipulating an elephant with an affine rig. The user makes us all the rig's degrees of freedom, translating and rotating the elephant. This rig motion is given as input to our method and we obtain intuitive secondary motion, such as the trunk and ears moving around.

In comparison we show a similar framework, where a user controls the affine motion that is then a constraint on central vertices of the elephant. Notice that as the use moves the elephant around, we can clearly see undesired artifacts, anchoring the rest of the elephant around its seemingly steel center. 

\begin{figure}
\includegraphics[width=\linewidth, keepaspectratio]{rough_images/octopus_pinned_vs_cd.jpg}
\caption{A user controlling octopus tentacles with their hand through a live video stream hand tracker. We enforce rig-control through constraining vertices lying within the skeleton "bones" (top) and our real-time complementary dynamics with reduced subspace degrees of freedom and deformation gradient clustering(bottom). Real-time complementary dynamics naturally lets the tentacles wiggle and move freely, while directly enforcing vertex positions robs the simulation of rich secondary dynamics and leads to an overly stiff animation.}
\label{fig:octopus_pinned_cd_comparison}
\end{figure}


\begin{figure*}
\includegraphics[width=\textwidth]{images/pinned_vs_cd_fig.pdf}
\caption{
\alec{The left most figure confuses the setup. The reader has never seen the rest state of the octopus so they will assume that it's this image. I'd show the rig in its rest state and rely on the video timestamp (where are these?) to point readers to see the rig motion.}
Pinning vertices to enforce control over a simulation leads to strong visual artefacts, and a simulation that is difficult to control. Carefully choosing which vertices to pin is a burdensome experience for a user. Instead, enforcing control through our rig-complementary modes results in smooth and controllable behavior, staying faithful to the input rig motion while adapting it to a dynamic simulation.
\alec{Our deformation still exhibits some ``kinks'' at the tips. How come?}
}
\label{fig:octopus_pinned_cd_comparison}
\end{figure*}



\subsection{Fast CD vs Coarse Mesh CD}
We compare our fast Complementary Dynamics to simply results obtained from coarsening our mesh. Figure  that for the same computational budget, we can obtain much more rich deformation. 
We stress test our method directly on large tetrahedral meshes (500k vertices, 1.5 million tets). We show that we can maintain interactive frame rates for such high quality meshes. 

\begin{figure}
\includegraphics[width=\linewidth,keepaspectratio]{images/coarse_vs_reduced_fig.pdf}
\caption{
\alec{Try to eliminate any wasted white space. Think about the figure layout \emph{before} collecting the raw footage. This model is very tall, so it's harder to achieve a good horizontal layout. Maybe add another frame to make the figure 4-across with the cage inset.}
Reduced animation (50 modes, 50 clusters), vs full complementary dynamics on a coarser mesh.  Both take the same amount of time, but coarsening the mesh destroys so much animation detail. Look at the tongue on the velociraptor mesh and see how a coarse mesh groups the tongue with the rest of the mouth, same with the small arms and the torso, but our method lets the tongue be separate and free moving}
\label{fig:CoarseComparison}
\end{figure}

\begin{figure}
\includegraphics[width=\linewidth,keepaspectratio]{images/rig_space_physics_fig.pdf}
\caption{
\alec{white space again. For digaonally angled models you can even nest them a bit. This'll work even better if they're a bit more horizontally diagonal.
}
\alec{don't forget to add timestamps for all of these.}
}
\label{fig:RSPComparison}
\end{figure}

\subsection{Constrained Modes vs Unconstrained Modes}
We evaluate the effectiveness of using our modes, inherently satisfying the complementary constraint versus using unconstrained modes and enforcing the complementary constraint at run-time via lagrange multipliers.


\subsection{Augmenting Rigid Body motion}
Interactive rigid body simulations are commonly used in video games. We can augment such rigid body simulators with our pipeline with soft body wiggles, much like in \cite{Zhang:CompDynamics:2020}.
\Otman{bonus}
\section{Conclusion}
\Otman{Not done}

\section{Limitations}
\Otman{Express ingredients of our method :
Hessian at rest state
gradient evaluation of energy
energy expressed as a sum over elements that is a function of F
}
\Otman{Talk about nonlinear subspaces}

\Otman{Talk about clustering on different energies}

\Otman{Talk about exotic deep learning energies, finding deformation gradient}

\Otman{Clustering for different distributions of deformation spaces (bimodal multimodal ones)}

\Otman{ UV-mapping/parameterizations: use gradients to flatten}

\Otman{Deep learning : use gradients to perturb examples}

\Otman{ We're basically making a very weird look-up tables}

\Otman{ Our method : deformations obtained from rest-state features}

\Otman{Recursively subdivide pre-existing clusters for faster clusters}

\Otman{Help the user find the clusters}

\Otman{Rigid Body simulation}

\Otman{ How can we transform pre-computed parameters from one shape to a closely related shape}

\Otman{Eigen decomposition timings}
\Otman{Re-use precomputed modes to 
warm-start modal decomposition}