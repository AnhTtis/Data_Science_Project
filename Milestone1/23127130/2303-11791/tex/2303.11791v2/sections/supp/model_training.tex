\section{PAC-Net}

\subsection{Model Details}

We use PyTorch~\cite{Paszke_PyTorch_An_Imperative_2019} to build and train our neural networks. Besides ResNets~\cite{he2016deep}, there are only two other basic components
in our model, which are GRU cells \cite{KyunghyunCho2014GRU} and a self-designed MLP decoder. 
The vector dimension of extracted features and hidden state $\mathbf{h}$ are both 128.
Before loading the pre-trained weights of ResNets, we substitute the last linear layer in ResNets with another one with an output dimension of 128. 
The two-layer MLP decoder takes in the hidden state $\mathbf{h}$ as input. The 64-dimensional intermediate vector is activated by a ReLU, followed by a final linear layer that outputs the 2-dimensional coordinate.

\subsection{Model Training}

During offline training, we use an equivalent implementation of networks to improve the training efficiency. Instead of extracting feature frame-by-frame, we use two ResNets in PAC-Cell to extract features from raw frames and difference frames all at once after loading a video clip. Then static features (from raw frames) and dynamic features (from difference frames) are fed to P-GRU and C-GRU alternatively.
\looseness=-1

For all networks, we train models for 70 epochs using AdamW~\cite{loshchilov2017decoupled} optimizer with a weight decay of 2e-3. The learning rate is set to 3e-4 and follows the cosine annealing schedule~\cite{loshchilov2016sgdr}. The batch size is set to 32.

During training, we load a random $T'$-frame clip from the whole video clip of $T$ frames, where $T'\le T$. This practice further enhances the diversity of datasets.