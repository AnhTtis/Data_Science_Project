\section{Tracking Method}

When a person is walking in the hidden room, there is a live streaming video coming from the camera shooting at the relay wall. This raw frame stream $\{I_t\}$ incorporates a series of discrete static position information. 
We can readily separate the difference frame stream $\{\Delta I_t\}$ from the raw frame stream, which contains the dynamic motion information instead.
To exploit both motion and position information conveyed by two streams, we propose a concise dual architecture, PAC-Net (\textbf{P}ropagation \textbf{A}nd \textbf{C}alibration \textbf{Net}work). Instead of using two-branch architectures \cite{simonyan2014two} to process two streams separately, PAC-Net integrates the motion continuity prior to its workflow with a specially designed alternating recurrent architecture.


\subsection{PAC-Net} \label{sec:pac-net}

The architecture of PAC-Net and the corresponding real-time tracking pipeline are illustrated in \cref{fig:pipeline}. The design notion of PAC-Net is to process difference and raw stream in an alternate manner, namely \textit{propagate} and \textit{calibrate}. Based on this, we design a dual architecture using the main component, \textit{PAC-Cell}. Within a PAC-Cell, there are two symmetric cells, Propagation-Cell and Calibration-Cell \footnote{Hereafter referred to as P-Cell and C-Cell.}.
Since difference frames convey significant dynamic motion
information as shown in \cref{eq:delta_I}, P-Cell first \textit{propagates} the hidden state between two observations with a difference frame $\Delta I_{T-1}$. Then the newly incoming raw frame $I_T$ introduces absolute position messages, allowing C-Cell to \textit{calibrates} the hidden state to a more accurate one. The whole procedure is as below:
% \looseness=-1
\begin{equation} \label{eq:prop_calib}
\begin{aligned}
&\mathrm{Propagate:}~&\Tilde{\mathbf{h}}_T &= \text{P-Cell} \left( \mathbf{h}_{T-1}, \textcolor{myGreen!90!black}{\Delta I_{T-1}} \right), \\
&\mathrm{Calibrate:}~&\mathbf{h}_T &= \text{C-Cell} \left( \Tilde{\mathbf{h}}_T, \textcolor{myBlue!90!black}{I_T} \right).
\end{aligned}
\end{equation}

In this paper, we use GRU cell \cite{KyunghyunCho2014GRU} as a recurrent cell and ResNet-18 \cite{he2016deep} as a feature extractor, which allow real-time inference with low computational cost. The decoder in \cref{fig:pipeline} is a two-layer Multilayer Perceptron (MLP). In fact, PAC-Net is a framework-level architecture for reconstruction tasks with temporally dense observations. The aforementioned components could be selected accordingly in other tasks.

At each time step $T$, the current position $\Vec{x}_T$ can be decoded from the hidden state $\mathbf{h_T}$. So on and so forth, the trajectory of a moving subject can be tracked in real time. Some tracking results are demonstrated in \cref{fig:pc_compare_render} and \cref{fig:model_compare_real}. Note red squares in \cref{fig:pc_compare_render} highlight the difference between trajectories after propagation and calibration. 

Note that the alternating recurrent workflow plays an indispensable role to allow the hidden state $\mathbf{h}$ to propagate stably between observations. Formally, the process of a recurrent neural network (RNN) updating the hidden state could be reformulated as the discretized first-order method for integrating ordinary differential equations (ODEs)~\cite{chen2018neural, de2019gru}:
\begin{equation} \label{eq:rnn_ode}
\begin{aligned}
\frac{d \mathbf{h}(t)}{d t}=f(\mathbf{h}(t), t, \theta) \Longrightarrow  \mathbf{h}_{t} &=\mathbf{h}_{t-1}+f\left(\mathbf{h}_{t-1}, \theta_{t-1}\right) \\
\Longrightarrow \mathbf{h}_{t} &= \Tilde{f} \left( \mathbf{h}_{t-1}, x_{t}\right),
\end{aligned}
\end{equation}
where $x_t$ is the newly incoming observation and $\theta$ represents the parameters. It is natural to consider taking advantage of this intrinsic nature of RNNs to perform tracking. However, our experiments expose the defect of the first-order method (See \cref{sec:results} for more details) that the tracking results either maintain poor continuity or diverge over time. In contrast, the alternating workflow allows PAC-Net to integrate dynamic and static information. This behavior is similar to predictor-corrector methods for solving ODEs, which can ensure numerical convergence via alternately predicting and correcting. Such methods can be formulated as follows:
\looseness=-1
\begin{equation}
\begin{aligned}
    \Tilde{\mathbf{h}}_{t,0} & = \mathbf{h}_{t-1} + f \left(\mathbf{h}_{t-1}, \theta_{t-1}\right), \\
    \Tilde{\mathbf{h}}_{t,n} & = \mathbf{h}_{t-1} + \Tilde{f} \left(\mathbf{h}_{t-1}, \Tilde{\mathbf{h}}_{t,n-1},\theta_{t-1}\right),
\end{aligned}
\end{equation}
where $n=1,2,...,N$ and $N$ denotes the total number of corrections. After predicting with motion information of difference frames, PAC-Net performs a correction with static information of raw frames. This way, PAC-Net can perform tracking coherently and accurately without divergence.

The tracking procedure allows end-to-end training of the model via minimizing the loss with respect to ground truth trajectory. The loss function is composed of position error $loss_x$ and velocity(displacement) error $loss_v$ with an adjustment parameter $\alpha_v$, controlling the weight of $loss_v$. Both of them follow a Mean-Square Error (MSE) fashion:
\looseness=-1
\begin{equation}
\begin{aligned}
    Loss &= loss_x + \alpha_v \cdot loss_v \\
    &= MSE(\{\Tilde{\Vec{x}}_t\}, \{\Vec{x}_t\}) + \alpha_v \cdot MSE(\{\Delta \Tilde{\Vec{x}}_t\}, \{\Delta \Vec{x}_t\}),
\end{aligned}
\end{equation}
where $\alpha_v$ is set to 500 in all experiments to align the orders of magnitude of $loss_x$ and $loss_v$. The velocity loss ensures the model learns a reasonable representation from difference frames and accelerates the convergence of trajectory continuity. Please refer to the supplementary material for more details about model training.

\begin{figure*}[t]
    \centering
%   \fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
    \includegraphics[width=\linewidth]{images/pc_compare.pdf}
    \caption{\textbf{Visualization of tracking results with PAC-Net on synthetic data.} Two rows indicate trajectories decoded from P-Cell and C-Cell respectively, called P-trajectory and C-trajectory. Each column indicates different warm-up steps $W$. 
    Grey dashed lines represent the course of the warm-up. 
    Two color gradients for mapping step numbers are applied to ground truths (green) and tracking results respectively. 
    For neat visualization, trajectories are normalized with the room size so that each sub-figure is a square.
    All columns titled $W=0$ share the same color bar as the first column.
    Red squares denote where trajectories are refined by C-Cell. (Best viewed in color.)}
    \label{fig:pc_compare_render}
    % \vspace{-10pt}
\end{figure*}

\subsection{Warm-up} \label{sec:warmup}

Since we have no knowledge about the hidden scene before the video stream comes in, we apply a zero-initialization to the hidden state $\mathbf{h}$ in the GRU cell. Although the principle is different, we observe a similar phenomenon as described in keyhole imaging \cite{metzler2020keyhole} -- The tracking trajectories deviate from the ground truth during early steps and gradually converge over time (visualized in columns titled $W=0$ in \cref{fig:pc_compare_render}). This is reasonable because a ``well-defined" hidden state $\mathbf{h}$ doesn't come from nowhere. The convergence over time may indicate gradually gaining knowledge of the unknown room since there are various room sizes and wall materials in our dataset. 
% \looseness=-1

A natural idea is that we could disentangle a few early steps as \textit{Warm-up Stage} from the original tracking procedure. Therefore, we construct two independent PAC-Cells in PAC-Net. The first one is called \textit{Warm-up PAC-Cell}, which is responsible for ``pulling" the hidden state $\mathbf{h}$ from zero initialization to a reasonable distribution, literally, ``warming up" the model. This way, another PAC-Cell, \textit{Tracking PAC-Cell}, could concentrate on accurately tracking by encoding each subsequent frame into a more accurate embedding. In \cref{fig:pc_compare_render} we visualize the course of warm-up with grey dashed lines. The Warm-up Stage could be regarded as an indirect way to find an appropriate initial hidden state $\mathbf{h}$ for the Tracking Stage.
Note if there is a Warm-up Stage, \ie, $W>0$, we only use the inferred trajectory in Tracking Stage to supervise the model training. We compare different steps to perform warm-up and report the results in \cref{sec:results}.
