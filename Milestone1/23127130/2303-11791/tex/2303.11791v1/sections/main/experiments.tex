\section{Experiments} \label{sec:experiment}

In this section, we first introduce our proposed dataset, NLOS-Track, then some quality metrics for evaluating the tracking results, and finally verify the effectiveness of our proposed method with experimental studies.

\input{sections/main/dataset}

\subsection{Metrics}
As suggested by Klein \etal \cite{klein2018quantitative}, the root-mean-square (RMS) error could be used to evaluate the position inference and tracking quality by directly computing the Euclidean distance between tracking and GT trajectory. Since RMS error is positively correlated with the loss function (MSE) we use, we refer to other three metrics for a comprehensive evaluation -- area between two curves (Area) \cite{jekel2019similarity}, dynamic time warping (DTW) \cite{senin2008dynamic}, and partial curve mapping (PCM) \cite{witowski2012parameter}. All three metrics are based on similarity measures between two curves. To specify, metrics reported in \cref{tab:ablation} are only computed in the Tracking Stage and are normalized by trajectory length for fairness.
% \looseness=-1


\subsection{Results}\label{sec:results}

\begin{figure*}[t]
    \centering
%   \fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
    \includegraphics[width=\linewidth]{images/model_compare.pdf}
    \caption{\textbf{Visualization of tracking results with different models on the real-shot dataset.} Rows indicate different methods and columns indicate different trajectories sampled from the Train and Test set. Color gradients share the same meaning as in \cref{fig:pc_compare_render}.
     (Best viewed in color.)\looseness=-1
    }
    \label{fig:model_compare_real}
    % \vspace{-5pt}
\end{figure*}

In this section, we describe the experimental results of our proposed method, along with the baseline method and ablation study. It is worth mentioning that we don't compare different choices of components (\eg, various feature extractors, different RNN cells, dimension of decoder) in experiments because our goal is to demonstrate the effectiveness of PAC-Net's architecture, not to improve the performance.
\looseness=-1
% Different components are only used to align the number of parameters in different models for fairness

\noindent \textbf{PAC-Net.}~
To verify our design notion of PAC-Net, we illustrate trajectory output by P-Cell and C-Cell separately in two rows of \cref{fig:pc_compare_render}, which are called P-trajectory and C-trajectory. 
P-Cell first uses motion information conveyed by difference frames to step forward, which forms P-trajectory. Then under collaboration with C-Cell, P-trajectory is refined into the more accurate C-trajectory with position information introduced by raw frames. In \cref{fig:pc_compare_render} we use red squares to denote sudden changes of velocity, where C-Cell plays a clear calibrating role. Numerical metrics reported in \cref{tab:ablation} show that PAC-Net not only achieves a centimeter-level precision in Tracking Stage but also demonstrates robustness on both real-shot data and synthetic data, thus outperforming other methods. 

To validate the effectiveness of our method, we construct two degenerated models by removing P-Cell or C-Cell from PAC-Cell, called C-Net and P-Net respectively. Each of the two degenerated models only takes in raw frames or difference frames. We also evaluate a CNN-based baseline model, fed with raw frames. Note we use a ResNet-34 and a two-layer GRU in degenerated models and a ResNet-50 as CNN baseline to align the parameter number.

\begin{figure}[t]
\vspace{-15pt}
    \centering
    % \fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
    \begin{subfigure}{0.32\linewidth}
        \includegraphics[width=\linewidth]{images/area.pdf}
        \caption{Area ($\downarrow$)}
        \label{fig:diff_warmup-a}
    \end{subfigure}
    \begin{subfigure}{0.32\linewidth}
        \includegraphics[width=\linewidth]{images/dtw.pdf}
        \caption{DTW ($\downarrow$)}
        \label{fig:diff_warmup-b}
    \end{subfigure}
    \begin{subfigure}{0.32\linewidth}
        % \includegraphics[width=\linewidth]{images/pcm.pdf}
        \includegraphics[width=\linewidth]{images/pcm.pdf}
        \caption{PCM ($\downarrow$)}
        \label{fig:diff_warmup-c}
    \end{subfigure}
    \caption{\textbf{Comparison of different warm-up steps on synthetic data.} Both C-Net and PAC-Net have better tracking performance as warm-up steps increase with a gradual saturation.}
    \label{fig:diff_warmup}
    \vspace{-15pt}
\end{figure}

\noindent \textbf{Baseline.}~ There are obvious jitters in reconstructed trajectories using vanilla CNN, which is shown in the first row of \cref{fig:model_compare_real}. Poor statistic metrics reported in \cref{tab:ablation} prove the necessity of taking advantage of recurrent structure to maintain the trajectory continuity.

\noindent \textbf{C-Net (without dynamic motion information).}~ \label{sec:c-net}
Although C-Net stabilizes the trajectory to some extent via recurrent structure, as shown in the second row of \cref{fig:model_compare_real}, there are still jitters and discontinuities in trajectories. This observation indicates that it is not sufficient to only use position information in passive NLOS tracking.
% \looseness=-1

\noindent \textbf{P-Net (without static position information).}~ \label{sec:p-net}
P-Net has the same structure as C-Net, but takes as input difference frames and reconstructs displacement (velocity) between observations instead. 
To compute metrics using motion information independently, we provide the true initial position so P-Net can accumulate velocities into a complete trajectory. 
As shown in the third row of \cref{fig:model_compare_real}, P-Net is capable of maintaining better smoothness and stability than C-Net, but there is an obvious overall translation with respect to ground truth.
% \looseness=-1

\begin{table*}[t]
\vspace{5pt}
\centering
\begin{tabular}{@{}cccccccc@{}}
    \toprule
    \multirow{2}*{Datasets} & \multicolumn{2}{c}{Methods} & \multicolumn{5}{c}{Metrics} \\
    \cmidrule(lr){2-3} \cmidrule(l){4-8}
    ~ & Type & Model & RMS$_x(\times 10^{-2})$ & RMS$_v(\times 10^{-3})$ & Area~($\downarrow$) & DTW~($\downarrow$) & PCM~($\downarrow$) \\
    \cmidrule{1-8}
    \multirow{6}*{Real-shot}
    ~ & CNN                         & ResNet-50         & 2.60           & 2.94            & 0.01184           & 0.8559            & 0.8171 \\
    \specialrule{0em}{2pt}{1pt}
    ~ & \multirow{3}*{ConvRNN}      & C-Net             & 1.65           & 2.24            & 0.00644           & 0.4617            & 0.4819 \\
    ~ & ~                           & C-Net + Warm-up   & 1.55           & 2.17            & 0.00601           & 0.4371            & 0.4392 \\
    ~ & ~                           & P-Net             & 4.03           & 2.87            & 0.01137           & 0.9727            & 1.211 \\
    \specialrule{0em}{2pt}{1pt}
    ~ & \multirow{2}*{\textbf{Ours}}& PAC-Net           & 1.46           & \textbf{1.17}   & \textbf{0.004347} & 0.3367            & 0.3313 \\
    ~ & ~                           & PAC-Net + Warm-up & \textbf{1.37}  & 1.28            & 0.004388          & \textbf{0.3348}   & \textbf{0.3027} \\
    \midrule
    \specialrule{0em}{1pt}{1pt}
    \midrule
    \multirow{6}*{Synthetic}
    ~ & CNN                         & ResNet-50         & 22.0             & 3.90             & 0.2807            & 21.891            & 316.806 \\
    \specialrule{0em}{2pt}{1pt}
    ~ & \multirow{3}*{ConvRNN}      & C-Net             & 15.5             & 3.31             & 0.2248            & 12.703            & 6.151 \\
    ~ & ~                           & C-Net + Warm-up   & 15.1             & 3.16            & 0.2138            & 11.572            & 5.286 \\
    ~ & ~                           & P-Net             & 11.3             & 2.17            & 0.1251            & 5.774             & 2.826 \\
    \specialrule{0em}{2pt}{1pt}
    ~ & \multirow{2}*{\textbf{Ours}}& PAC-Net           & 9.70            & 2.21            & 0.1117            & 5.576             & \textbf{2.225} \\
    ~ & ~                           & PAC-Net + Warm-up & \textbf{8.78}   & \textbf{1.79}   & \textbf{0.08413}  & \textbf{4.391}    & 2.268 \\
    \bottomrule
\end{tabular}
\caption{\textbf{Evaluation metrics of different models on different datasets.} In metric columns with a down arrow $\downarrow$, the lower metric denotes the better performance of the corresponding model. 
Note that P-Net doesn't have a warm-up stage because the initial position is given. 
% We report performance of models with warm-up steps $W=32$ in rows labeled ``+ Warm-up". 
Models with ``+ Warm-up" use warm-up steps $W=32$. 
\textbf{Bold} denotes the best-performing models on each metric.}
\label{tab:ablation}
\vspace{-5pt}
\end{table*}

\noindent \textbf{Different Warm-up Steps.}~ 
To evaluate the contribution of the Warm-up Stage, we evaluate PAC-Net and C-Net with different warm-up steps. Note that a longer Warm-up Stage doesn't introduce extra computational cost during inference, but only delays the beginning of the Tracking Stage.
In \cref{fig:pc_compare_render} we demonstrate some tracking results with different warm-up steps. With more steps to warm up, the trajectory will be more accurate when the tracking stage begins. We also observe a gradual saturation of the model's performance as warm-up steps increase. This trend can be clearly seen with statistic metrics shown in \cref{fig:diff_warmup} and warm-up course (grey dashed lines) demonstrated in \cref{fig:pc_compare_render}. With a warm-up step $W \approx 48$, the Warm-up PAC-Cell has taken in sufficient frames to warm up the hidden state $\mathbf{h}$ thus providing a reasonable initialization for the following Tracking Stage.
\looseness=-1

\noindent \textbf{Real-time Inference.}~
We run our model on a laptop with 8-core AMD Ryzen 7 5800H CPU and an Nvidia GeForce RTX 3060 laptop GPU. We achieve an inference speed of approximately 900 frames per second and therefore adequate for real-time inference. The single-scene inference speed on one card of NVIDIA A100 is about 5000 FPS.
\looseness=-1

% \noindent \textbf{Relative Position v.s. Absolute Position.}~ 
% When all position coordinates of a trajectory is divided by the room size, the range of absolute position is normalized to $[0,1]$ and becomes relative position. Both kind of position can be used to supervise the training of model. We compare both setting and find something interesting. 
% On the synthetic dataset, both setting works; however, on the real-shot dataset, the model cannot learn anything and mode collapse occurs when use absolute position to supervise.

