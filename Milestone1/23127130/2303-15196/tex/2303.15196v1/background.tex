\section{Background}
\vspace{-0.1cm}
\subsection{Tracking local curvature}\label{sec:curvature}

Solely observing the convergence performance of an optimiser will show which optimiser is the best for a given task but  will give limited information as to why. To move a step towards explaining why one optimiser is better than another, we analyze the trajectory of every optimiser in their local reference frame.% by introducing local trajectory curvatures.

To begin, let $\omegavec$ be the neural network parameters, the weight update rule for update $k$ is defined as $\Delta \boldsymbol{\omega}_k \equiv  \boldsymbol{\omega}_{k+1} - \boldsymbol{\omega}_k = \mathbf{V}(\boldsymbol{\omega}_k, \boldsymbol{\eta})$, where $\boldsymbol{\eta}$ are the model hyperparameters. Assuming the continuum time limit, the trajectory in the parameter space during training can be described by:
\begin{equation}\label{eq:V}
    \omegadot = \mathbf{V}(\boldsymbol{\omega}, \boldsymbol{\eta}),    
\end{equation}
where the overdot corresponds to a time derivative, i.e. $\omegadot = \mathrm{d} \omegavec/\mathrm{d}t$. When using gradient descent, \cref{eq:V} can be interpreted as the equation of motion of a classical particle in a friction-dominated setup and $\mathbf{V}(\boldsymbol{\omega}, \lambda) = -\lambda \frac{1}{n}\sum_i\nabla_{\boldsymbol{\omega}}\,\, \mathcal{L}(\mathbf{x}^{(i)}, \boldsymbol{\omega})$. Here, $\lambda$ is the learning rate, $n$ is the number of samples in the training set $\{\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \cdots, \mathbf{x}^{(n)}\}$, and $\mathcal{L}$ is the loss function.
For other optimisation algorithms, the definition of $\V$ changes and the ODE in \cref{eq:V} is no longer obtained via the Euler--Lagrange equations. Therefore, it does not have a dynamic interpretation. 
However, \cref{eq:V} can be efficiently used to understand the kinematics of the optimiser trajectories. This aspect is discussed further in \cref{sec:results}. 

To examine the motion in parameter space described by \cref{eq:V}, we introduce the unit vector tangential to the training trajectory, defined as
\begin{equation}
     \That = \frac{\omegadot}{\omegadotnorm}, \quad \textrm{with} \quad  \|\omegadot\|_2 = \sqrt{\langle\omegadot, \omegadot\rangle}.
\end{equation}
Here, $\That$ is a time-dependent vector in a $N_{\boldsymbol{w}}$-dimensional space, for a $N_{\boldsymbol{w}}$ parameter NN. To track the local training trajectory curvature in this time-dependent reference frame, we can define  the local (time-dependent) curvature, $\kappa_t$. This is the rate at which the tangent unit-vector changes with respect to time, and is given by:
\begin{equation}\label{eq:kappa}
    \kappa_t = \left\|\dx{\That}{t}\right\|_2 = \frac{1}{\omegadotnorm} \left[\omegaddot \cdot \omegaddot - \left(\dx{\omegadotnorm}{t}\right)^2\right]^{1/2}.
\end{equation}



Another parametrisation with a clearer geometric meaning is $\kappa_\omega=\left\|\dx{\That}{\omega}\right\|_2=\kappa_t/\|\omegadot\|_2$. This represents a local geometric quantity, i.e., the local curvature in the parameter space, removing the effects of time and trajectory speed\footnote{This is the local curvature of the training trajectory, not the curvature of the space of weights, which is flat.}. To calculate the curvature at each training step a first-order approximation is used, details of which are given in \cref{app:curvature_discretised}. 

In comparison with a Hessian-based curvature calculation, the method presented here has a significantly lower computational cost as it does not require the Hessian of the loss function. Furthermore, in most cases, an optimiser does not solely follow the gradient loss and it is generally non-trivial to find the function relating the loss, its derivatives, and the trajectory followed by the optimiser.
Therefore, although every optimiser is constructed with the aim of sharing its minima with the loss function, analyzing the loss Hessian may not characterise the optimiser trajectories and may not explain why a certain minimum is found. Moreover, different optimisers are based on different assumptions---such as energy conservation, friction-dominated motion, or others---further modifying the loss seen by the optimiser. \cref{fig:loss_trajectory} in \cref{app:curvature_discretised} gives a pictorial representation of the loss function (or its distorted version seen by the optimiser) and its relationship to the trajectory in the parameter space.

\vspace{-0.2cm}


\subsection{Linear Advection}\label{sec:linear_advection}
 The PDE used for the tests in this work was the one-dimensional linear advection equation on the periodic spatial domain $\Omega=[0,2\pi)$, given by
\begin{subequations}\label{eq:linadvec}
    \begin{align}
        \px{u}{t} + \beta \px{u}{x} &= 0, \quad \rm{for} \quad u:T\times\Omega\mapsto\mathbb{R}, \quad \Omega=[0,2 \pi), T \in [0,1], \\
        u(x,0) &= u_0(x), \\
        u(0,t) &= u(2 \pi, t), 
    \end{align}
\end{subequations}

where $\beta$ is the wave speed and $u_0(x)$ is the initial condition. The exact solution of this system can be straightforwardly found using the superposition of Bloch waves. To find approximate solutions to this system we applied PINNs with  loss functions similar to those used by \citet{Krishnapriyan2021}, defined as
\begin{subequations}
    \begin{align}
    \label{eq:loss}
        \mathcal{L}(\theta) &= \frac{1}{N_u} \sum_{i=1}^{N_u} \left(\hat{u} - u_0^i \right)^2  + \frac{1}{N_f} \sum_{i=1}^{N_f} \lambda_i \left(\px{\hat{u}}{t} + \beta \px{\hat{u}}{x} \right)^2 + \frac{1}{N_b} \sum_{i=1}^{N_b} \left(\hat{u}(\theta, 0, t) - \hat u(\theta, 2\pi, t)\right)^2.
    \end{align}
\end{subequations}
Here $\hat{u} = \hat{u}(\theta, x, t)$ is the neural network output, parameterised by $\theta$. The initial condition used through out this work was $u(x,0) = \sin(x)$ and $u(0,t)= u(2\pi,t)$. For all the experiments we fix $\lambda_i = 1$.



