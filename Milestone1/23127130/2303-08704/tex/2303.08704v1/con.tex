\section{Conclusion}
High Dynamic Range (HDR) Imaging is a desirable function for modern digital cameras. To overcome the hardware limitation of current camera sensors in dynamic range, we have described a new neural model to blend low dynamic range images captured at tri-exposures into HDR images. We have shown that, by integrating the gating mechanism with the shifted-window self-attention mechanism, our model progressively aligns the cross-exposure images and screen outliers caused by large motion from HDR fusion. We have also demonstrated that, in the framework of multi-scale encoder-decoder, the Gated Swin Transformer achieves global reception, long-range matching and adaptive fusion. Extensive ablation study has been presented to validate the effectiveness of our model in addressing large motion in HDR imaging.