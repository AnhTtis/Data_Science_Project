    \begin{table*}[t]
    \centering
    \small
    \setlength{\tabcolsep}{7pt}
        \begin{tabular}{l c c c c c c c c }
        \toprule
        Method \& Arch. &   Pretrain    &  \makecell{Model \\ \# Params}   & \makecell{Trainable \\ \# Params}      & GFLOPs    & R@1 & R@5 &   Views  \\ 
        \midrule
        \multicolumn{5}{l}{\hspace{-6pt}\textit{Full-tuning}} \\ 
        SlowFast+NL~\cite{slowfast}          &    -   &   60M     &  60M  &     7020     &  79.8  & 93.9    &   16$\times$3$\times$10   \\
        MViT-B~\cite{multiscale}          &    -   &   37M     &  37M  &     4095     &  81.2  & 95.1    &   64$\times$3$\times$3   \\
        UniFormer-B~\cite{uniformer}          &    IN-1K   &   50M     &  50M  &     3108     &  83.0  & 95.4    &   32$\times$4$\times$3   \\
        TimeSformer-L~\cite{space-time}          &    IN-21K   &   121M     &  121M  &     7140     &  80.7  & 94.7    &   64$\times$1$\times$3   \\
        ViViT-L/16$\times$2 FE~\cite{vivit}          &    IN-1K   &   311M     &  311M  &     3980     &  80.6  & 92.7    &   32$\times$1$\times$1   \\
        VideoSwin-L~\cite{video-swin}          &    IN-21K   &   197M     &  197M  &     7248     &  83.1  & 95.9    &   32$\times$4$\times$3   \\
        MViTv2-L~\cite{multiscale-v2}          &    IN-21K   &   218M     &  218M  &     42420     &  86.1  & 97.0    &   32$\times$3$\times$5   \\
        MTV-L~\cite{multiview}         &    JFT   &   876M     &  876M  &     18050     &  84.3  & 96.3    &   32$\times$4$\times$3   \\
        TokenLearner-L/10~\cite{tokenlearner}         &    JFT   &   450M     &  450M  &     48912     &  85.4  & 96.3    &   64$\times$4$\times$3   \\
        ActionCLIP~\cite{actionclip}         &    CLIP   &   142M     &  142M  &     16890     &  83.8  & 97.1    &   32$\times$10$\times$3   \\
        X-CLIP-L/14~\cite{x-clip}          &    CLIP   &   420M     &  420M  &     7890     &  87.1  & 97.6    &   8$\times$4$\times$3   \\ 
        
        \midrule
        \multicolumn{5}{l}{\hspace{-6pt}\textit{Parameter Efficient Tuning}} \\ 
        EVL~\cite{frozen-clip} w/ ViT-L/14          &    CLIP   &   368M     &  59M  &     8088     &  87.3  & -    &   32$\times$3$\times$1   \\ 
        ST-Adapter~\cite{st-adapter} w/ ViT-B/16     &    CLIP   &   93M     &  7M  &    1821      &  82.7  & 96.2    &   32$\times$3$\times$1   \\
        \rowcolor{Light} \textbf{\method} w/ ViT-B/16        &  CLIP  &  96M  &  10M  &  710 &85.4  &97.1   &  32$\times$3$\times$1  \\
        \rowcolor{Light} \textbf{\method} w/ ViT-L/14        &  CLIP  &  330M  &  27M  &  1868 & 
 87.7  &  97.8   &  32$\times$3$\times$1  \\
        \bottomrule
        \end{tabular}\vspace{-5pt}
    \caption{Performance comparisons for action recognition on the Kinetics-400~\cite{k400} dataset. 
    Note that Views = \#frames $\times$ \#clips $\times$ \#spatial.}\vspace{-5pt}\label{tab:k400}
    \end{table*}