\documentclass[twocolumn,secnumarabic,amssymb, nobibnotes, aps, prd]{revtex4-1}
%groupedaddress


\usepackage{wrapfig}
\usepackage{dsfont}
\usepackage{amscd}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{newtxtext}
\usepackage{booktabs,caption} 

%---------From Valerio%
\usepackage{comment}
\usepackage[tikz]{bclogo}
\presetkeys{bclogo}{
ombre=true,
epBord=1,
couleur = blue!15!white,
couleurBord = red,
arrondi = 0.2,
logo=\bctrombone
}{}

%\usepackage[colorlinks=true, pdfstartview=FitV, linkcolor=blue, citecolor=blue, urlcolor=blue]{hyperref} 
            
            
\usepackage{subcaption}
\captionsetup{font=footnotesize,justification=raggedright,singlelinecheck=false}
\captionsetup[subfigure]{font=footnotesize,justification=justified,singlelinecheck=false}
\usepackage{sidecap}
\usepackage{grffile}
\usepackage{xcolor}
\usepackage{scalerel}
%%%%%%%%%%%%%%%%%%%%%

\setcounter{MaxMatrixCols}{30}
\newcommand\wh[1]{\hstretch{2}{\hat{\hstretch{.6}{#1}}}}

\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}

\newcommand*{\myfont}{\fontfamily{palatino}\selectfont}

%-- marcros from revtex template------------------------
\newcommand{\revtex}{REV\TeX\ }
\newcommand{\classoption}[1]{\texttt{#1}}
\newcommand{\macro}[1]{\texttt{\textbackslash#1}}
%\newcommand{\m}[1]{\macro{#1}}
\newcommand{\env}[1]{\texttt{#1}}
\setlength{\textheight}{9.5in}
%----------------------------------------------------------------




\definecolor{rred}{rgb}{0.7,0,0.1}
\definecolor{greenrb}{rgb}{0.2,0.6,0.2}
\newcommand{\mg}{\color{blue}}
\newcommand{\cm}[1]{{\color{magenta}\sl(#1)}}
\newcommand{\attn}{\color{greenrb}} % attention

\newcommand{\mk}{\color{black}}
\newcommand{\val}{\color{blue}}

%%%%%%%%%%%%%%%%%%

\def\bi{\begin{itemize}}
\def\ei{\end{itemize}}

\def\bea{\begin{equation} \begin{aligned}}
\def\eea{\end{aligned} \end{equation}}
\def\beas{\begin{equation*} \begin{aligned}}
\def\eeas{\end{aligned} \end{equation*}}
\def\bes{\begin{equation*}}
\def\ees{\end{equation*}}
\def\d{\, \mathrm{d}}
\def\be{\begin{equation}}
\def\ee{\end{equation}}
%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%
\renewcommand\d{\, \mathrm{d}}
\renewcommand\Vert{\: \vert \:}
\newcommand{\ellL}{\mathcal{L}}

\newcommand\cX{\mathcal X}
\newcommand\cY{\mathcal Y}

\newcommand{\X}{\mathbf{X}}


\def\x{\boldsymbol{x}}
\def\y{\boldsymbol{y}}
\def\Y{\boldsymbol{Y}}
\def\z{\boldsymbol{z}}
\def\net{\mathrm{net}}
\def\Fb{\boldsymbol{F}}
\def\Sigmab{\boldsymbol{\Sigma}}
\def\Cb{\boldsymbol{C}}

%%%%%%%%%%%%%%%%%%%%%%%

\def\e{{\color{black} \epsilon}}
\def\F{{\color{black}{\mathcal{F}}}}

\def\W{{\boldsymbol{W}_t}}
\def\C{{\boldsymbol{C}}}
\def\kb{{\boldsymbol{k}}}  
\def\qb{{\boldsymbol{q}}}  
\def\pb{{\boldsymbol{p}}}  
\def\M{\mathcal M}  
\def\m{\mathfrak m}  


%Mathbb
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}

%Calligraphic Math
\newcommand{\XXX}{\mathcal{X}}
\newcommand{\BBB}{\mathcal{B}}
\newcommand{\PPP}{\mathcal{P}}
\newcommand{\UUU}{\mathcal{U}}
\newcommand{\MMM}{\mathcal{M}}
\newcommand{\AAA}{\mathcal{A}}
\newcommand{\EEE}{\mathcal{E}}
\newcommand{\SSS}{\mathcal{S}}
\newcommand{\GGG}{\mathcal{G}}
\newcommand{\QQQ}{\mathcal{Q}}
\newcommand{\LLL}{\mathcal{L}}

%Boldface
\newcommand{\xx}{\mathbf{x}}
\newcommand{\yy}{\mathbf{y}}
\newcommand{\rr}{\mathbf{r}}
\newcommand{\zz}{\mathbf{z}}
\newcommand{\zero}{\mathbf{O}}
\newcommand{\uu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\CC}{\mathbf{C}}
\newcommand{\XX}{\mathbf{X}}
\newcommand{\YY}{\mathbf{Y}}
\newcommand{\FF}{\mathbf{F}}
\newcommand{\GG}{\mathbf{G}}
\newcommand{\HH}{\mathbf{H}}
\newcommand{\pp}{\mathbf{p}}
\newcommand{\eee}{\mathbf{e}}

%Math Roman
\newcommand{\dd}{\mathrm{d}}
\newcommand{\CCCC}{\mathrm{C}}

%Parenthesis and angles
\newcommand{\lp}{\left(}
\newcommand{\rp}{\right)}
\newcommand{\lelan}{\left\langle}
\newcommand{\rilan}{\right\rangle}

%Equations
\newcommand{\beq}{\begin{equation}}
\newcommand{\eeq}{\end{equation}}
\newcommand{\beqs}{\begin{subequations}}
\newcommand{\eeqs}{\end{subequations}}
\newcommand{\balign}{\begin{align}}
\newcommand{\ealign}{\end{align}}



%Theorems, Remarks, Propositions
\newtheorem{remark}{Remark}[section]
\newtheorem{lem}{Lemma}[section]




\begin{document}


\title{Hasselmann's Program and Beyond: New Theoretical Tools for Understanding the Climate Crisis}    
 \author{Valerio Lucarini}
\email{Corresponding author. Email address: \texttt{v.lucarini@reading.ac.uk}}\affiliation{Department of Mathematics and Statistics, University of Reading, Reading, RG6 6AX, UK}
 \affiliation{Centre for the Mathematics of Planet Earth, University of Reading, Reading, RG6 6AX, UK}
 
  \author{Micka\"el D. Chekroun}
\email{Email address: \texttt{mchekroun@atmos.ucla.edu}} \affiliation{Department of Earth and Planetary Sciences, Weizmann Institute of Science, Rehovot 76100, Israel,}
 \affiliation{Department of Atmospheric and Oceanic Sciences, University of California, Los Angeles, CA 90095-1565, USA}
 
 

\date{\today}% It is always \today, today,
             %  but any date may be explicitly specified



\begin{abstract}
Klaus Hasselmann's revolutionary intuition was to take advantage of the stochasticity associated with fast weather processes to probe the slow dynamics of the climate system. This has led to fundamentally new ways to study the response of climate models to perturbations, and to perform detection and attribution for climate change signals. Hasselmann's program has been extremely influential in climate science and beyond. We first summarise the main aspects of such a program using modern concepts and tools of statistical physics and applied mathematics. We then provide an overview of some promising scientific perspectives that might better clarify the science behind the climate crisis and that stem from Hasselmann's ideas. We show how to perform rigorous model reduction by constructing parametrizations in systems that do not necessarily feature a time-scale separation between unresolved and resolved processes. We propose a general framework for explaining the relationship between climate variability and climate change, and for  performing climate change projections. This leads us seamlessly to explain some key general aspects of climatic tipping points. Finally, we show that response theory provides a solid framework supporting optimal fingerprinting methods for detection and attribution.
\end{abstract}


\maketitle    

\section{Introduction}
The climate is a complex and complicated system comprising of five subsystems - the atmosphere, the hydrosphere, the cryosphere, the biosphere, and the land surface - which differ for physical-chemical features, dominants dynamical processes, and characteristic time scales. Such subsystems are coupled through a complex array of processes of exchange of mass, momentum, and energy \cite{Peixoto1992,Lucarini.ea.2014}.  The climate system is multiscale as it features variability over a vast range of scales, as a result of the interplay of a very diverse array of forcings, instabilities, and feedbacks \cite{Mitchell1976,Ghil.2019}, with different subsystems playing the dominant role in different considered temporal (and spatial) ranges \cite{vonderHeydt2021}; see Fig. \ref{Fig_Anna}. Major knowledge gaps on the climate system comes from the lack of homogeneous, high-resolution, and coherent observations, because of a) the sheer size and practical accessibility of the climate subdomains, b) changes in the technology of data collection in the industrial era, and c) the need to resort to proxy (hence, indirect) data for the pre-industrial epoch. Thus, it is extremely challenging to construct satisfactory theories of climate dynamics and is virtually impossible to develop numerical models able to describe accurately climatic processes over all scales. Typically, different classes of models and different phenomenological theories have been and are still being developed by focusing on specific scales of motion and specific processes \cite{GhilLucarini2020}. 

As a result of the presence of unsteady external forcings and of a very nontrivial internal multiscale dynamics, and of the fact that we experience only one realization of the state of the climate, it is hard to clearly separate climate variability from any climate change signal \cite{Ghil2015}. As documented in successive assessment reports of the Intergovernmental Panel for Climate Change the scientific community has painstakingly come to an agreement regarding %global scientific efforts directed at the recent history of the climate system have painstakingly led in the past decades to key scientific advances, namely understanding  
1) the presence of a statistically significant climate change signal %that there is statistically significant change of the state of the climate systems 
with respect to the conditions prevailing in the XIX century; and 2) the possibility of attributing such a signal to anthropogenic causes. The detection and attribution of the climate change signal to specific forcings (anthropogenic or otherwise) requires being able to compare the state of the climate system with the outputs of carefully devised model simulation, taking into account the unavoidable uncertainty due to natural variability and model error \cite{IPCC2022}. 


\begin{figure}
\includegraphics[width=0.45\textwidth]{Anna_2021}
\caption{\small A Mitchell's diagram \cite{Mitchell1976}  depicting a qualitative representation of the climate variability across a vast range of scales, with indication of the relative role of each climatic subcomponent, and indication, on top, of the acting forcings. From \cite{vonderHeydt2021}.}\label{Fig_Anna}
\end{figure}

In the course of the years, the research focus has progressively shifted from making statements on globally averaged climatic quantities, to assessing  climate change at regional level, to studying the changes in the higher statistical moments and in extreme events, and to investigating how the climate change can manifest itself in the form of critical transitions. The current focus on the study of extremes \cite{IPCC12} and critical phenomena  (often referred to as tipping points \cite{Lenton.tip.08,Ashwin2012}) has led the scientific community to use expressions like \textit{climate crisis} or \textit{climate emergency} instead of \textit{climate change} \cite{Ripple2021}

\subsection{A Brief Summary of Hasselmann's Program}
In the latter part of the XX century,  Hasselmann proposed a coherent scientific angle on the climate system, with the goal of %providing concepts and tools for  
understanding %the nature of 
climate variability, of detecting and interpreting the climate change signal, and of characterizing the  behaviour of climate models. %, in order to extract maximum information from their simulations. 
A very informative summary of the so-called Hasselmann program, of some of its key developments in climate science, and of some of its implications for mathematics and physics at large is given in \cite{Imkeller2001}. We  discuss  below three main axes of Hasselmann's program. 

\subsubsection{Stochastic Climate Models}\label{stochasticcm}
The  starting point of this journey  {\mk comes with the seminal work} \cite{Hasselmann1976}, where Hasselmann  proposed {\mk to seek for improvement of the modeling of slow climate variables by parameterizing the influence of fast  weather variables by means of an appropriate stochastic forcing.} 
 % separate slow climatic variables from fast meteorological variables. 
%His interest was in 
{\mk At the core of this Hasselmann's stochastic program, lies thus the derivation of an} effective model with improved capability to capture the dynamics and the statistical properties of the slow variables. 
%His ingenuous idea was to  incorporate the influence of the weather into climate in the form of a stochastic forcing. 
Following \cite{Arnold2001}, {\mk we assume that our climate model writes as the following large-dimensional system of ordinary differential equations}
%one starts from general equations of the form
\bea\label{fastslow}
&\dot{\x}=f(\x,\y), \;\; \x \; \textrm{slow climate variables},\\ 
&\dot{\y}=\frac{1}{\delta}g(\x,\y), \;\;\y \; \textrm{fast weather variables},
\eea
where $\x$ (resp.~$\y$) lies in $\mathbb{R}^{d}$ (resp.~$\mathbb{R}^{D}$), and $f$ (resp.~$g$) is a smooth mapping from   
$\mathbb{R}^{d+D}$ into $\mathbb{R}^{d}$ (resp.~$\mathbb{R}^{D}$).
%$f:\mathbb{R}^{d+D}\rightarrow \mathbb{R}^{d} $ 
%where $\y\mathbb{R}^{D}$ and $\xx\in\mathbb{R}^{d}$ correspond to fast weather and slow climate variables, 
%respectively, with $f:\mathbb{R}^{d+D}\rightarrow \mathbb{R}^{d} $ and $g:\mathbb{R}^{d+D}\rightarrow \mathbb{R}^{D} $ being smooth fields. 




The parameter $\delta$ is aimed at describing the existence of a tentative time scale separation between the dynamics of the two sets of variables, hence typically one assumes $0<\delta\ll1$. 
%Indeed, %^Assuming that the characteristic time scales of the $\yy$ variables are much shorter than those of the $\xx$ variables, 
%Hasselmann {\attn posited that}  in the $\delta\rightarrow 0$ limit,
{\mk In mathematical language, the Hasselmann's program consists of deriving in the $\delta\rightarrow 0$ limit, an effective reduced equation of Eq.~\eqref{fastslow} to approximate the statistical behavior of the climate variables.  
When $\y$ follows some fast chaotic dynamics, the latter is known to take the form of the following   
system of It\^o stochastic differential equations (SDEs),} 
\begin{equation}\label{Hass1}
\d \x= \FF(\x)\d t +\Sigmab(\x)\d \W.
\end{equation}
{\mk The derivation of such a limiting SDE in the presence of infinite timescale separation has a long history \cite{beck1990brownian, just2001stochastic,majda2001mathematical,Pavliotis2008,Gottwald2013} and may be obtained through diverse routes  pertaining to homogenization \cite{Pavliotis2008}, averaging \cite{khas1963principle}, or singular perturbation techniques \cite{kurtz1973limit,Papanicolaou1974}. The MTV approach \cite{majda2001mathematical,majda2003systematic} building up on such techniques provides a modern treatment of the topic in the context of climate dynamics, including rigorous results when nonlinear self-interactions between e.g.~the fast waves can be modeled by means of Ornstein-Uhlenbeck  processes.}  
%%[Cite MTV, Gottwald \& co, Imkeller]
%A more precise mathematical formulations of Eq.~\eqref{fastslow} with suitable choice of small parameters able to clarify the existence of time-scale separation between the dynamics of the two groups of variables is at the basis of homogenization theory, which discusses under which conditions the solution of a fast-slow system converge (in probability) to that of a suitably derived SDE in the limit of infinite time-scale separation \cite{Pavliotis2008,Gottwald2013}. Along these lines, a popular approach for the development of parametrizations, \textit{i.e.}, the explicit derivation of Eq.~\eqref{Hass1} from Eq.~\eqref{fastslow} is the so-called MTV approach, which takes advantage of earlier results by Papanicolaou \cite{Papanicolaou1974} and Kurtz  relies on making few extra assumptions such as that the unperturbed fast variability can be modelled as an Ornstein-Uhlenbeck process \cite{majda2001mathematical,majda2003systematic}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%MC--->VL: BE CAUTIOUS HERE, the MTV does NOT consists of replacing the fast variability by OU, but rather the fast-fast interactions; see the long 2001 MTV paper. %%%%%%%%%%%%%%%%%

{\mk The terms $\FF$ and $\Sigmab$ in Eq.~\eqref{Hass1}  have then intuitive interpretations.  
Typically, the deterministic component $F$ (also called drift term) provides the average contribution of $f(\x,\y)$ to the dynamics of the slow variables, after averaging out the fast variables \cite{just2001stochastic}. 
The second term, is aimed at parameterizing the effects of the fluctuations left over due to averaging, and takes the form of a state-dependent noise, in which the $d\times p$-matrix $\Sigma$ with (possible) nonlinear entries in $\x$, is driven a vector of increments $\d \W$ (white noise) of a $p$-dimensional Wiener process $ \W$.}


%The previous SDE is written using the It\^o interpretation of the stochastic term \cite{Pavliotis2008}. 

{\mk Physically, getting to the limit \eqref{Hass1} allows for interpreting the  fast weather dynamics as inducing a diffusion process. As such, the understanding of the complex nonlinear interactions of e.g.~unstable modes with (possibly deep) stable ones \cite{chekroun2022transitions},  at the core of the chaotic nature of many geophysical flows  \cite{GhilChildress1987,dijkstra2005nonlinear,DG05} is replaced by the understanding of the interactions between noise and nonlinear effects \cite{CLW15_vol1,CLW15_vol2,chekroun2023transitions}.} 




%Equation \eqref{Hass1} {\attn implies that all climate models %, regardless of their specific formulation, 
%need to be cast according to SDEs}, 

{\mk As appealing are such attributes, the  infinite timescale separation assumption underlying Eq.~\eqref{Hass1} is often challenged in climate applications and we discuss  below how to amend Hasselmann's program in such situations, either by seeking for natural extensions to Eq.~\eqref{Hass1} (Sec.~\ref{Sec_MZ}), or stochastic alternatives (Sec.~\ref{Sec_L80}).} In the climate system, there is actually a multiplicity of spatio-temporal scales interacting across a wealth of processes (Fig.~\ref{Fig_Anna}) and the Hasselmann ansatz, whilst indeed inspiring, {\mk calls for its revision}. 
  
In any event, because the impact of unresolved scales of motion on the scales of interest cannot be  approximately reproduced by using bulk formulas (contributing to the drift term) only. This is the fundamental motivation behind the development of stochastic parametrizations for weather and climate models, {\mk some of which used in operational situations \cite{palmer_stochastic_2009,Berner2017}.} 

%Since in the climate system there is no real time-scale separation between the various processes, as shown also in Fig.~\ref{Fig_Anna}, the Hasselmann ansatz, whilst indeed inspiring, is not wholly accurate. 


%We specifically address these concerns in Sect. \ref{modelreduction} by showing how the procedure can be generalised to the case where no time scale separation is present between the two sets of variables.}

%As clarified by the Mori-Zwanzig \cite{mori_transport_1965,zwanzig_memory_1961}, the effective dynamics defining the evolution on the projected space of the variables of interest entails deterministic, stochastic, and non-markovian components even if the dynamics of the whole system is purely deterministic \cite{Chorin2000,wouters2013,CLW15_b,Lin.Lu.2021}. The stochastic terms are proportional to Wiener processes and the memory term drops out if one in the case of infinite time-scale separation \cite{SantosGutierrez2021}. 

An important implication of Hasselmann's {\mk approach though} is the provision of a probabilistic interpretation of climate dynamics, going beyond the study of individual trajectories. Indeed, the SDE \eqref{Hass1} can then be translated into a Fokker-Planck equation (FPE)  {\mk providing the probability distribution of the climate's states}, $\rho(\x,t)$, according to  %$\partial _t\rho= \mathcal{L}_0\rho$, where $\mathcal{L}_0(\bullet)=-\nabla \cdot  \lp \FF(\xx)\bullet \rp 
%  +\frac{1}{2}\nabla \cdot \nabla \Big(\Sigma \Sigma^{T}(\x) \bullet \Big)$ is the Fokker-Planck operator \cite{Risken1989}.
\be\label{eq:fpe 1}
\partial _t\rho= \mathcal{L}_0\rho=-\nabla \cdot  \lp \FF(\x)\rho \rp 
 +\frac{1}{2}\nabla \cdot \nabla \Big(\Sigmab \Sigmab^{T}(\x) \rho \Big).
\ee
%
%where $\rho(\xx,t)$   is 
In practice, $\rho(\x,t)$ is constructed using an ensemble of trajectories; see \cite{Maher2021} for a recent summary of the use of ensembles in climate modeling.  $\Sigmab \Sigmab^{T}$ is the non-negative definite noise covariance matrix.  
The unperturbed climate is then given by the stationary solution $\rho_0(\x)$ to the FPE defined by $\ellL_0 \rho_0 = -\nabla \cdot  \Big(\FF \rho_0\Big) +\frac{1}{2}\nabla \cdot \nabla \Big(\Sigmab \Sigmab^{T}\rho_0 \Big)=0$
%\begin{equation}\label{eq:fpe 2}
%\ellL_0 \rho_0 = -\nabla \cdot  \Big(\FF(\x) \rho_0\Big) +\frac{1}{2}\nabla \cdot \nabla \Big(\Sigma \Sigma^{T} (\x)\rho_0 \Big)=0.
%\end{equation} 

When the noise term in Eq.~\eqref{Hass1} is sufficiently non-degenerate, i.e.~when, roughly speaking, the noise propagates out in the whole phase space
 through interactions with the nonlinear terms, the probability density $\rho_0$ is smooth; see e.g.~\cite[Appendix A.2]{Chekroun_al_RP2}. In contrast, when $\Sigmab=0$,  Eq.~\eqref{eq:fpe 1} becomes the Liouville equation and, in the case of dissipative chaotic systems, the  {\mk probability distribution $\rho_0$ is typically}  singular with respect to the Lebesgue volume in $\R^d$ \cite{eckmann_ruelle}.


%\bea\label{eq:fpe 2}
%\partial _t\rho_0(\xx) =\LLL_0 \rho_0(\xx)= &-\nabla \cdot \lp \FF(\xx)\rho_0(\xx) \rp   \\
%&+\frac{1}{2}\nabla^2:\lp  \Sigma(\xx) \Sigma(\xx)^{\top}\rho_0(\xx) \rp=0.
%\eea
%where ``$:$'' denotes the Frobenius inner product, and $\Sigma \Sigma^{\top}$ is the noise covariance matrix. As well known, the presence of non-vanishing noise, by introducing diffusion, makes sure that the measure is smooth. 
Assuming that  $\int\mathrm{d}\x\rho_0(\x)=1$, the reference climatological mean for a general observable $\Psi$ is $\langle \Psi \rangle_0= \int\mathrm{d}\x\rho_0(\x)\Psi(\x)$.  The function $\Psi$ could be any quantity of climatic interest, corresponding to local properties described at a specific grid point, or spatially averaged ones. It makes sense to associated possible $\Psi$'s with essential climate variables (ECVs), which are key physical, chemical, or biological variables  that critically contribute to the characterization of Earth's climate and are targeted for observations \cite{Bojinski2014}, or the quantities used for defining performance metrics for Earth System Models \cite{Eyring2020}.  This viewpoint allows for casting the problem of climate change as the response of the {\mk system's probability} distribution or in the statistics of the $\Psi$'s to (possibly time-dependent) perturbations to the drift term or the noise law  in Eq.~\eqref{Hass1}  
\cite{GhilLucarini2020,Tel2020}. 
%are altered, possibly through time-dependent terms 
%If the extra forcings are stationary, the comparison of the unperturbed invariant measure with the perturbed one allows us to frame in general term the concept of climate sensitivity. If the extra forcings are non-stationary, the system will not reach a new steady state, but rather have time-dependent statistical properties, describing how climate is changing with time  

\subsubsection{Climate Response to Forcings}\label{responseHasselmann}
A second {\mk landmark} of the Hasselmann research program %, which is methodologically partly separated from what described above, despite close thematic proximity, 
deals with the study of the response of climate models to perturbations. Aiming at studying how a climate model relaxes to steady state conditions or responds to perturbations, {\mk like} a sudden CO$_2$ increase, %acting after such steady state has been reached
Hasselmann and collaborators heuristically proposed a methodology inspired by the dynamics of linear systems \cite{Maier-Reimer1987,Hasselmann1993}.  They showed that one can express the {\mk variation} $\delta \Psi(t)$ describing the departure of the model from steady state conditions (or convergence to it) by performing the convolution of a suitably defined causal Green's function $G_\Psi(t)$ with the time modulation of the acting perturbation $f(s)$:
\be\label{GHass}
\delta \Psi(t)=\int \d s G_\Psi(t-s)f(s), 
\ee
where $\Psi$ describes a climate variable of interest. This amounts to treating the problem of climate change %how the statistical properties of the climate system change as a result of a forcing 
using response theory. Leith pioneered this angle \cite{Leith1975} by proposing the use of the fluctuation-dissipation theorem (FDT) \cite{kubo1966} for expressing the Green's functions in terms of readily accessible correlations of climatic observables in the unperturbed state. Additionally, %taking advantage of the adopted linear framework, 
Hasselmann and collaborators expressed the Green's function $G_\Psi$ as a sum of exponential terms: 
\be\label{GHassExp}
G_\Psi(t)=\sum_k \alpha^k_\Psi \exp(\lambda^\Psi_k t),
\ee
where each of the $\lambda_k$ encode an acting feedback  and can be deduced from the properties of the linear system describing the dynamics. The Green's function-based method was shown to have good skill in performing climate change projections for individual model runs, after  filtering the natural variability \cite{Hasselmann1993} and %associated with the chaotic nature of the flow). 
for studying the carbon cycle in a climate model \cite{Maier-Reimer1987}. %This angle on climate response as represented by models does not encompass the random nature of the signal coming from  individual model runs, which results from the chaotic nature of the flow. 
%In Sect. \ref{climateresponse} we critically revise this approach by discussing how and in which sense response theory can be used to perform climate change projections, and  clarify  the meaning of the $\lambda's$. 

\subsubsection{Detection and Attribution of Climate Change}\label{DAHasselmann}
%As mentioned above, the stochastic angle proposed by Hasselmann makes it extremely clear that 
Using stochastic climate models one can make statements on climate change in terms of probability distributions, averages, and higher statistical moments, whereas we live in a single realization of the process. Separating climate variability and  climate change in the course of such a single realization is clearly a hard task. Additionally, since we cannot run the climate experiment again, it is even harder to attribute climate change to any specific forcing. %This imposes that any statement we can make about climate change can only be probabilistic and based on some given null hypotheses. 
In the  '90s Hasselmann and collaborators proposed the basic conceptual framework for performing detection and attribution studies of climate change. %aim at quantifying the evidence %for a causal link between external forcings and observed climate change 
\cite{Hasselmann1993b,Hegerl1996,Hasselmann1997}. This has played a major role in clarifying that we are presently experiencing a statistically relevant and physically attributable shift from previous climatic conditions \cite{Bindoff2013}. Following \cite{Hannart2014}, the problem can be cast as follows: 
\begin{equation}
\label{eq:da3}
Y_k=\sum_{p=1}^M\tilde{X}_k^p\beta_p+\mathcal{R}_k \quad \tilde{X}_k^p={X}_k^p+\mathcal{Q}_k^{p}
\end{equation}
with $k=1,\ldots,N$ hereby a vector describing the observed climate change with components $Y_k$ modelled as a linear combination of $M$ regressors or fingerprints, i.e.~externally forced signals $\tilde{X}_k^p$ associated with $M$ different forcing, plus a vector describing the natural variability of the system \cite{Hasselmann1993b,Hegerl1996,Hasselmann1997,Allen1999,Allen2003}. The $p^{th}$ fingerprint $\tilde{X}_k^p$ is obtained from several climate models runs, all targeted to the $p^{th}$ considered forcing, e.g. by performing ensemble averaging. Hence, what we can practically have access to is its approximation ${X}_k^p$, whereby the difference $\mathcal{Q}_k^{p}$ with respect to the true value is associated with our incomplete sampling of the model response and with model error. In many applications, information coming from different climate models is bundled together \cite{hegerl2011use}. 

%%%%MC--->VL: No NEED to SPECIFY  where p and k live below. It's already said above. So I suppressed it which makes the economy of a few symbols%%%%

The goal is to perform an optimal inference of the  coefficients {\mk $\beta_p$} given the uncertainties described by  $\mathcal{R}_k$ and $\mathcal{Q}_k^p$, hence the expression \textit{optimal fingerprinting}. 
%  Hannart et al. \cite{Hannart2014} provides a rather clear and informative summary of both the basic aspects of the more advanced developments of optimal fingerprinting methods. 
Usually the vectors column errors $\mathcal{R}_k$ and $\mathcal{Q}_k^p$, are modelled as independent, normally distributed stochastic vectors with zero mean and covariance matrices {\mk $\Cb$} and $\Omega_p$, respectively. 
%%%%%%MC--->VL: I've changed the usage of \Sigma here as it is confusing with the Sigma in the SDE%%%%%% 
The matrix $\Cb$ is constructed taking into account the correlations of the climatic variables in the unperturbed climate. %Instead, putting aside for the moment the use of a Gaussian approximation, the theory of linear response imposes that the statistical properties of the residual should be constructed using the statistics of the snapshot attractor attractor. Note that, following \cite{LucariniWouters2017}, the difference between correlation properties of the unperturbed and forced model is to a first order linear with the acting forcing. 
%Hence, the optimization procedure described in Eq. \ref{eq:da3} neglects to consider the forced change in the variability of the system. 
%
A simpler  version of the theory above assumes $\Omega_p=0$ {\mk for all $p$} \cite{Allen1999}. In this case, via linear algebra one derives a relatively simple expression for the best estimates for the $\beta$'s {\mk along with} their  uncertainties. As a next step, if one assumes that the natural variability simulated by the climate models {\mk matches that of} the observations and one estimates  $\tilde{X}^p_k$ as the average of $L$ runs from a single climate model under the $p^{th}$ forcing, then, under the approximation above, one gets  $\Omega_p = \Cb/L$ \cite{Allen2003}. %Neglecting the difference between the variability of the system in the unforced vs. forced scenario and using the response theory framework discussed above, the latter statement can be justified by considering that the actual response signals are ergodic averages. Hence, by the central limit theorem, their uncertainty decreases with the inverse of the number of ensemble members used for the estimating them. More generally, one can define $\Omega_p = \Sigma/L +\Lambda$, where $\Lambda$ is the covariance associated with the model error. Using these more general formulations, the optimization problem becomes more difficult yet manageable; see discussion in \cite{Hannart2014}.

One speaks of detection of climate change for the $p^{th}$ fingerprint is the confidence interval of $\beta_p$ does not intersect zero and includes positive values, and attribution of climate change if such confidence interval includes the value one. The procedure is truly successful if the confidence intervals for the $\beta_p$'s are not too spread out.  Optimal fingerprinting relies critically on the {\mk implicit linear dependence} of the response to forcing. Additionally, the method, despite its great success, has recently been criticised as it has been suggested that uncertainties in the inference are sometimes underestimated \cite{Li2021}, or, more radically, on the basis that the statistical foundation of the procedure are not very solid \cite{McKitrick2022}; see also discussion in \cite{Chen2022}. {\mk In Sec.~\ref{climateresponse} below, we describe how the Hasselmann's optimal fingerprinting method benefits of new insights when reframed within the response theory of dynamical systems.}

%In Sect. \ref{optimalfingerprinting} we discuss optimal fingerprinting through the angle of response theory.




%\subsubsection{Climate Response}


%Following Hasselmann \cite{Hasselmann1993b,Hegerl1996,Hasselmann1997}, it has been  proposed to treat the problem of climate change attribution as an optimization problem where one tries to see to what extent a vector describing the observed climate change can be described as a linear combination with given parameters of various  externally forced signals. Such forced signals, the fingerprints, are deduced from the output of one or more climate models which follow a specific protocol describing one of the acting natural (e.g. volcanic emissions) or anthropogenic (e.g. CO$_2$  emissions) forcing. The best estimate of the fitting parameters indicate the extent to which the observed climate change signal can be attributed to the acting forcings. Under suitable statistocal assumptions, it has been shown that this procedure leads to obtaining optimal fingerprinting \cite{Allen1999,Allen2003,Hannart2014}. Clearly, the attribution is blurred by the presence of the natural variability of the system, by the uncertainties on the models' ability to reproduce the impact of the individual forcings, and by the adopted linear approximation.  

%For the fundamental reason that we cannot run %the ongoing In the presence of very strong natural and forced variability, attributing observed climate change to specific acting forcings is extremely nontrivial because we cannot run 
%the climate change experiment multiple times  \cite{Lucarini2002}, the use of many tools of statistical mechanics, which are based on the use of the concept of ensemble, is not straightforward. Linear response theory for nonequilibrium systems \cite{ruellegeneral1998,ruelle2009,Hairer2010} has been amply shown to be a powerful and flexible tool for studying the impact of forcings on a large variety of complex systems; see discussion in \cite{Baiesi2013,Barbier2018,Lucarini2018JSP,Sarracino2019,Gottwald2020,Lucarini2020PRSA,Santos2022} and references therein. 



\subsection{This Review}

Our goal here is to give a critical appraisal of the Hasselmann programme based on some ideas and concepts that have emerged in statistical mechanics and functional analysis, for the most part, in the last two decades. %From this standpoint, 
We also propose a comprehensive framework for understanding the multiscale nature of climate variability and climate response to forcing and for fundamentally advancing our understanding of the ongoing climate crisis. This paper is structured as follows. 

Section \ref{modelreduction}  is devoted to exploring possible avenues to devise rigorous theory-informed and effective data-driven model reduction strategies and to highlight connections and integration between between the top-down and bottom-up approaches, in order to relax the assumption of infinite time-scale separation discussed in Sect. \ref{stochasticcm}. There, we show how to relax the assumptions of (strong) time-scale separation between the variables of interest and those we want to parametrize. Reduced order modelling is inextricably associated with performing partial observations, i.e.~gaining only a partial, imperfect knowledge of the properties of a system.  As clarified by the Mori-Zwanzig (MZ) formalism \cite{mori_transport_1965,zwanzig_memory_1961}, the effective dynamics defining the evolution on the projected space of the variables of interest Markovian deterministic, stochastic, and non-Markovian components even if the dynamics of the whole system is purely deterministic; see e.g.~\cite{Chorin_al02,GKS04}. Based on recent results from the literature, accounting for possibly the usage of neural parameterizations, we clarify physical situations in which the role of memory effects is secondary compared to that played by the conditional expectation and stochastic effects due to the unobserved variables in the reduced model. For the sake of completeness, we also review the different approaches for approximating the memory effects, and clarify the challenges posed by situations in which the time-scale separation between the resolved and unresolved variables is weak. 
%Mathematically, this leads to studying generalized Langevin equations (GLEs) \cite{pavliotisbook2014}. %The stochastic terms are proportional to Wiener processes and the memory term drops out if one in the case of infinite time-scale separation \cite{SantosGutierrez2021}. 
% As suggested by the Mori-Zwanzig \cite{theory, such observations can be used to deduce the fluctuating and delayed effects of the unobserved variables in the reduced model. Mathematically, this leads to using generalised Langevin equations (GLEs), which are able to incorporate the effect of deterministic drift, noise, and memory.
In Sect. \ref{climateresponse} we show how response theory for nonequilibrium systems \cite{ruellegeneral1998,ruelle2009,Hairer2010,Baiesi2013,Sarracino2019,Gottwald2020,Santos2022} allows one to find explicit formulas and to devise clear experimental protocols aimed at computing such time-varying statistics, hence allowing for performing climate change projections using climate models of different levels of complexity \cite{ragone2016,Lucarini2017,Aengenheyster2018,Lembo2020}. Hence, we shed light of some of the key aspects discussed in Sect. \ref{responseHasselmann}. We show that the use of a formalism based on Green's functions does not requires assuming linearity of the model, but just to linearize the properties of the model around it steady state, but requires considering ensemble averages. Taking advantage of the Koopman operator formalism \cite{Mezic2005,Budinisic2012,Kutz2016}, we show that it is indeed possible to write any Green's function as a weighted sum of exponentials, and we  carefully explain the meaning of the weights and of the decay rates. This angle  also facilitates understanding the basic properties of tipping points,  and  associating their presence to the divergence of the response operators \cite{Tantet2018,Chekroun_al_RP2,Santos2022}. 
In Sect. \ref{optimalfingerprinting} we show how the linear response formalism developed in Sect. \ref{climateresponse} provides the mathematical and physical backbone behind the optimal fingerprinting method for detection and attribution of the climate change signal presented in Sect. \ref{DAHasselmann}. Additionally, our angle allows one to better appreciate the approximations taken in the practice of detection and attribution studies (especially regarding the definition of the error terms), clarify some fundamental issues associated with the use of mixtures of different climate models in the definition of the fingerprints, and elucidate why the fitting strategy might fail in the proximity of tipping points. This allows to convincingly prove the strong link between the three  main axes of Hasselmann's research programme. 
In Sect. \ref{conclusions} we present our conclusions and perspectives for future work.


\section{Theory-Guided and Data-driven Model Reduction}\label{modelreduction}


\subsection{Mori-Zwanzig decomposition from perturbation theory of the Koopman semigroup}\label{Sec_MZ}
We consider a dynamical system
\be\label{EqF}
\dot{X}=F(X), \;\; X\in \mathbb{R}^N, \;\;N\gg 1.
\ee
Denoting by $X^x_t$ the solution to Eq.~\eqref{EqF} emanating from $x$ in $\mathbb{R}^N$ at $t=0$, we 
 assume that Eq.~\eqref{EqF} possesses a stationary statistical equilibrium $\mu$ (invariant probability measure) that satisfies 
\be\label{Eq_phys_rev}
\underset{T\rightarrow \infty}\lim \frac{1}{T} \int_0^{T}  \varphi(X^x_t) \d t =\int  \varphi( X) \d \mu ( X), 
\ee
for almost  every  $x$  (in the Lebesgue sense) that lies in the basin of attraction of $\mu$, for any sufficiently smooth observable $\varphi$. In general $\varphi$ is a field quantity which represents perturbations of, e.g., density, pressure, electrostatic potential, etc. Note that when a  global attractor exists, a statistical equilibrium $\mu$ satisfying \eqref{Eq_phys_rev} is  supported by the global attractor; see e.g.~\cite{CGH12}. 

Given an observable $\varphi: \mathbb{R}^N \rightarrow \mathbb{R}$, recall that the evolution of this observable along the flow associated with Eq.~\eqref{EqF} is given by the Koopman semigroup, $K_t$, defined as \cite{Budinisic2012} $K_t \varphi(x) =\varphi(X^x_t)$
%\bes
%K_t \varphi(x) =\varphi(X^x_t),
%\ees
that satisfies the Liouville equation $ \partial_t K_t \varphi=\mathcal{L} K_t \varphi$
% \be
 %\partial_t K_t \varphi=\mathcal{L} K_t \varphi,
 %\ee
 with $\mathcal{L} \varphi = \Big(\sum_{j=1}^N F^j (x) \partial_j\Big) \varphi,$ denoting the Lie derivative along the vector field $F$. 


We are now given decomposition $X=(a,b)$ in which $a$ denotes $p$ relevant variables (those resolved, typically), while $b$ denotes the $q=N-p$ neglected ones.
We are interested in describing the evolution of any (sufficiently smooth) observable $v$ of the variable $a$ without having to resolve the $b$-equation in Eq.~\eqref{EqF}. In climate dynamics, this is motivated for instance by predicting/simulating a scalar field of interest (e.g.~temperature, pression) over a coarse grid without having to resolve the subgrid processes (closure problem).    
In operator form, this operation consisting of parameterizing the coefficients depending of $b$ in the transport equation
\bea\label{Eq_Liouville}
\partial_t v =\Big(\sum_{j=1}^p F^j (a_t^x,b_t^x) \partial_j\Big) v,
\eea
This {\mk partial differential equation (PDE)} describes how the observable $v$ depending on the $a$-variable only (coarse variable) is advected by the flow of Eq.~\eqref{EqF} (accounting for the interactions with the subgrid variables $b$); it is obtained by observing that 
$\partial_t v(a_t^x)=\nabla v \cdot \partial_t a_t^x$. 
  

To address this closure problem we introduce the conditional expectation operator 
\be\label{Eq_averaging_ope}
\big[ P \Psi\big] (a) = \int \Psi(a,b) \d \mu_a (b)=\overline{\Psi},
\ee
in which $\mu_a$ denotes the disintegration of the invariant probability measure $\mu$ \cite[Theorem 5.3.1]{ambrosio2008gradient}; roughly speaking it gives the distribution of the $b$-variable on the attractor when the coarse-variable is frozen to $a$.
The operator $P$ corresponds thus to an averaging with respect to the neglected variable $b$ as conditioned on $a$. Note that  $\mu_a\neq \mu_{a'}$ for $a\neq a'$ for complex systems causing the variable $b$ not to be   identically and independently distributed (i.e.~not i.i.d.). 
 
 Now, by rewriting the transport equation \eqref{Eq_Liouville} as $ \partial_t (K_t v) =K_t \M v$ with $\M=\sum_{j=1}^p F^j  \partial_j$, we have that  
 \be\label{Eq_basic_pert}
 \partial_t (K_t v) =K_t P \M v+K_t (\M v -P\M v).
 \ee 
 Here, $ P\M =\sum_{j=1}^p \overline{F^j}(a) \partial_j$
 denotes the averaged advection operator with respect to the neglected, ``fast,'' variable $b$.
 %%%%%%%%%%%%%%%%%%%%%%%%%%
  \begin{bclogo}{\small Box 1: Derivation of the GLE}
  \footnotesize
 In Eq.~\eqref{Eq_basic_pert}, the operator,
$$\M  -P\M=\sum_{j=1}^p \big(F^j (a,b)-\overline{F^j}(a)\big) \partial_j,$$ accounts for the fluctuations with respect to the conditional average and $K_t (\M v -P\M v)$ informs thus on how these fluctuations are transported by the flow of Eq.~\eqref{EqF}.    
Hence, the operator  $\bm{\delta}f = (Id- P)\M  f= Q \M f$
encodes the fluctuations terms.  It defines a fluctuation semigroup $e^{t \bm{\delta}}$ that is very useful to close Eq.~\eqref{Eq_Liouville}. This can be accomplished by application of the perturbation theory  of semigroups,  in the Miyadera-Voigt  variation-of-constants formulation \cite{miyadera1966perturbation,voigt1977perturbation}, to the Koopman and fluctuation semigroups; see \cite[Sec.~3.c]{engel2000} for a rigorous treatment.

The  Miyadera-Voigt perturbation theorem gives then that
\be\label{Eq_MZ_decomp}
K_t  f =e^{t\bm{\delta}} f +\int_{0}^t K_{t-s} P\M e^{s \bm{\delta}} f \d s,
\ee 
for any observable $f$  for which $\bm{\delta} f $ is well defined. Note that $P e^{t \bm{\delta}} f=0$ if $P f =0$, i.e.~the {\it orthogonal complement}  of $P$,  is invariant under $e^{t\bm{\delta}}$. Note that the fluctuation semigroup $e^{t \bm{\delta}}$ gives the solution of the orthogonal dynamics equation
\be\label{Eq_ortho}
\partial_t e^{t \bm{\delta}} f= Q \M e^{t \bm{\delta}} f.
\ee
We refer to \cite{givon2005existence} for the study of existence of solutions to Eq.~\eqref{Eq_ortho}. 
 
Now let us take $f=\M v-P\M v=Q \M v$ in \eqref{Eq_MZ_decomp} and observe that $P f=0$. Then Eq.~\eqref{Eq_basic_pert} becomes:
\bea\label{Eq_f0}
\partial_t K_t v &=K_t P \M v+e^{t \bm{\delta}} f +\int_{0}^t K_{t-s} P\M e^{s \bm{\delta}}  f  \d s\\
&=K_tP \M v\hspace{-.2ex} +\hspace{-.2ex}\int_0^t \hspace{-.2ex} K_{t-s} \Gamma(s) v  \d s +\eta(t)v,
\eea
with  $\eta(t)v=e^{t \bm{\delta}} Q\M v$
%\bes
%\eta(t)v=e^{t \bm{\delta}} Q\M v,
%\ees
denoting the orthogonal element of the MZ decomposition (since   $P Q \M v=0$ implying that $\eta(t)v$ lies in ker($P$)), while 
$\Gamma(s)$ defines the  operator $\Gamma(s)=P\M \eta(s)$
%\bes
%\Gamma(s)=P\M \eta(s). 
%\ees
\end{bclogo}
%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% A SMALL CUT HERE.
By performing the change of variable $s \leftarrow t-s$ in the integral term of Eq.~\eqref{Eq_f0} in Box 1, we arrive finally at the following equivalent formulation of Eq.~\eqref{Eq_f0}
\bea\label{Eq_GLE}
\partial_t v(a_t^x)=P \M v (a_t^x) +\hspace{-.2ex}\int_0^t  \Gamma(t-s) & v (a_{s}^x) \d s +[\eta(t)v](x),
\eea
which gives the desired closure of Eq.~\eqref{Eq_Liouville}. 

Eq.~\eqref{Eq_GLE} is  the  {\it Generalized Langevin Equation (GLE)}  \cite{pavliotisbook2014} or the {\it Mori-Zwanzig (MZ) decomposition}. The effective dynamics defining the evolution of any observable 
of the reduced state space can be achieved by determining the 
Markovian, stochastic, and non-Markovian components appearing in Eq.~\eqref{Eq_GLE} making the GLE, the fundamental equation to determine in the Mori-Zwanzig approach to closure 
\citep{zwanzig_memory_1961,mori_transport_1965,Chorin_al02,GKS04,Chorin_Hald-book}.
As we clarify below, not all the terms are needed though in this triptych decomposition depending on the situations.   
 In any event,  MZ decompositions have attracted a lot of attention in the last two decades as a promising description for reduced modeling of coarse-grained variables \cite{GKS04,Chorin_Hald-book,hijon2010mori}, in many areas such as molecular dynamics \cite{izvekov2006modeling,chen2014computation,ma2016derivation}, climate dynamics \cite{chekroun2011predicting,Majda_Harlim2012,wouters2013multi,ghil2015collection,MSM2015,chekroun2017data,Boers_al17,KCYG_2018_arctic,falkena2019derivation}, or fluid problems \cite{parish2017dynamic,parish2017non,Kondrashov_al2018_QG,wang2020recurrent} to name a few. 



In Eq.~\eqref{Eq_GLE}, the  kernel  $\Gamma(t-s)$ is typically a time-lagged damping kernel and $\eta(t)$ is interpreted as an effective random forcing uncorrelated with the time-evolution of the resolved variable, $a_t^x$, but can be strongly correlated in time; see Sec.~\ref{Sec_L80} below.  In the slow-fast system metaphor, the Markovian term $P \M$ provides the slow component of the dynamics,  $\eta(t)$ is void of slow oscillations, while $\Gamma$ is supposed to account for the disparate interactions between the timescales.  

As elegant it may be,  the MZ decomposition is a technically challenging solution to the closure problem of disparate scale interactions and various assumptions about the memory kernel $\Gamma$ are typically made to propose approximations to the GLE. 

The memory kernel  $\Gamma$ and the "noise" operator $\eta(t)$ involve the implicit knowledge of the fluctuation semigroup  $e^{s \bm{\delta}}$, accounting for the effects of the neglected variables on the fluctuations with respect to the average slow motion. This operator is difficult to resolve as it boils down of solving the orthogonal dynamics equation Eq.~\eqref{Eq_ortho}  \cite{stinis_Higher-order}. 

The noise and memory terms can be extremely complicated to calculate, especially in cases with weak or no obvious timescale separation between the resolved and unresolved variables. The approximation of these terms constitutes thus the main theme of most research on the MZ decomposition.


Many techniques have been proposed to address this problem in practice and can be grouped in two categories: (i) data-driven methods, and  (ii) methods based on analytical insights tied to the very derivation of the MZ decomposition. Data-driven methods aim at recovering the MZ memory integral and fluctuation terms based on data, by exploiting sample trajectories of the full system.
 Data-driven methods can yield accurate results, but they often require a large number of sample trajectories to faithfully capture memory effects \cite{li2015incorporation,lei2016data,li2017computing,brennan2018data}.
Typical examples include the NARMAX (nonlinear auto-regression moving average with exogenous input) technique developed by \cite{chorin2015discrete,lu2017data,Lin.Lu.2021}, the rational function approximation  proposed in \cite{lei2016data}, the conditional expectation techniques of \cite{brennan2018data}, and methods based on Markovian approximations  by means of surrogate hidden variables \cite{Majda_Harlim2012,MSM2015,lei2016data}. 


Methods based on analytical considerations aim at approximating the MZ memory integral and fluctuation terms based on the original equations, without using any simulation data. The first effective method developed within this class can be traced back to the continued fraction expansion of Mori \cite{mori1965continued}, which can be conveniently formulated in terms of recurrence relations \cite{lee1982solutions,florencio1985exact}; see also \cite{kupferman2004fractional}. Other analytical methods to compute the memory and fluctuations terms in the MZ decomposition include optimal prediction methods  \cite{Chorin_al_2002,chorin2007problem,Stinis06}, mode coupling techniques \cite{gotze1999recent,reichman2005mode}, methods based on approximations of the orthogonal equations \cite{darve2009computing}, matrix function methods \cite{chen2014computation}, series expansion methods \cite{stinis2015renormalized,parish2017non,parish2017dynamic, zhu2018estimation,zhu2018faber}, perturbation methods \cite{venturi2014convolutionless}, and methods based on Ruelle's response theory  \cite{wouters2012,wouters2013multi}. These analytically grounded methods can lead to the effective calculations of the non-Markovian effects in various applications such as e.g.~in coarse-grained particle simulations \cite{yoshimoto2013bottom,hijon2010mori} or some fluid problems \cite{parish2017dynamic,parish2017non}, including intermediate complexity climate models \cite{Demaeyer2018}. However, these calculations are often quite involved and they do not generalize well to systems with no scale separation \cite{GKS04}; see, instead, an example of scale adaptivity in \cite{Vissio2018a}. 

In fact to better appreciate the difficulty posed by the lack of timescale separation it is useful to recall that for instance long-range memory approximation consisting of keeping the zeroth order term in a Taylor expansion of the memory integrand in Eq.~\eqref{Eq_GLE} allows for simplifying significantly the memory term calculation, but at the price of  restrictive conditions. Indeed, such a long-range approximation shows relevance if the  unresolved modes exhibit sufficiently slow decay of correlations ($t$-model \cite{hald2007optimal,chorin2007problem}), essentially by assuming information about initial value to be sufficient to make predictions. Assuming the unresolved modes to have fast decay of correlations, one is left with short-range memory approximation schemes. 
As was shown in  \cite{chorin2007problem}, the two cases, of extreme or very weak non-locality in time, are the two sides of the same coin. Most of the challenging cases for closure lies thus in the intermediate
cases \cite{Stinis06}, for which there is no neat separation of timescales such as populating climate science \cite{GhilLucarini2020}. 


Keeping higher-order terms in the Taylor expansion of the memory integrand is a natural way to handle cases of weak timescale separation. It is illuminating in many ways, including to design data-driven methods, as explained below.
This   higher-order  approximation approach of the memory integrand has been retained by Stinis in \cite{stinis_Higher-order} and further developed and analyzed by Zhu et al.~in \cite{zhu2018estimation}. The approach consists of breaking down the memory approximation problem into a  hierarchy of auxiliary Markovian equations. 


Denoting by $\m_0(t)$ the integral term in Eq.~\eqref{Eq_GLE}, such a Markovian approximation is accomplished by observing  that $\m_0(t)=\int_0^t K_s P \M e^{(t-s) Q\M} Q \M$ satisfies the following  infinite-dimensional system of PDEs \cite{stinis_Higher-order,zhu2018estimation}
%%%%%%%%
%\bea\label{Eq_Hmodel}
%\frac{\d \m_0}{\d t}&=K_t P\M Q\M v+\m_1(t),\\
%\frac{\d \m_1}{\d t}&= K_t P\M (Q\M)^2 v+\m_2(t),\\
%&\vdots\\
%\frac{\d \m_{n-1}}{\d t}&= K_t P\M (Q\M)^nv+\m_{n}(t),\\
%&\vdots
%\eea
%\end{comment}
\be\label{Eq_Hmodel}
\frac{\d \m_{n-1}}{\d t}= K_t P\M (Q\M)^nv+\m_{n}(t),\quad n=1,\ldots.
\ee
Integrating Eq.~\eqref{Eq_Hmodel} backward, i.e., from the ``last'' equation to the first one, to obtain  a Dyson series representation of $\m_0(t)$ involving repeated integrals \cite{zhu2018estimation}.  
In practice, one performs a truncation of Eq.~\eqref{Eq_Hmodel}, which consists of keeping the first $n$ equations, while closing the last equation by using an ansatz in place of  $\m_{n}(t)$, such as $\m_{n}(t)=0$   \cite{stinis_Higher-order} or  $m_n(t)$ given by Chorin's $t$-model; see \cite{zhu2018estimation} for other choices.  Depending on the the order of truncation retained and the corresponding choice of the ansatz for $\m_n$,  error estimates with respect  to the genuine memory integral in Eq.~\eqref{Eq_GLE} are available  \cite{zhu2018estimation}. 
The implementation of such Markovian schemes is however not trivial to conduct as it requires computing $(Q\M)^n$ to a high-order in $n$,  a delicate operation to accomplish especially when the original system is large, recalling that $Q\M$ is the generator of the orthogonal equation \eqref{Eq_ortho}. 

%This is not straightforward, especially for nonlinear dynamical systems.

Nevertheless, the layered structure of  Eq.~\eqref{Eq_Hmodel} and related error estimates provide a strong basis for the design of data-driven methods based on Markovianization ideas to approximate the memory integral term. We mention that such ideas are commonly used for the mathematical analysis of physical models involving integro-differential equations; see e.g.~\cite{Chek_al11_memo,chekroun_glatt-holtz} and references therein.  

Although not aware of such theoretical foundations not even with the connection with the MZ-decomposition pointed out only later on in \cite{MSM2015}, the 
 data-driven approach proposed initially by Kravtsov et al.~in \cite{kravtsov2005multilevel} is intimately related to such Markovianization ideas. The class of data-driven models of  \cite{kravtsov2005multilevel} involves also mulitlayered SDEs of a structure very similar to that of Eq.~\eqref{Eq_Hmodel} that has been generalized in  \cite{MSM2015} to handle the approximation of more complex memory kernels, from a data-driven perspective. The usage of such mulitlayered SDEs to provide approximation of the GLE is further discussed in Sec.~\ref{Sec_variational} below.

%The data-driven methods have often a motivation that is grounded on numerical  heuristics or theoretical considerations. 
%In that respect, 



 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




Efforts to approximate the memory and noise terms should not, however, make us lose sight of another key problem, namely the problem of approximating the conditional expectation, namely the Markovian terms in Eq.~\eqref{Eq_GLE}. This is where recent hybrid approaches exploiting the original equations and simulated data have shown relevance.    

In that respect, the data-informed and theory-guided variational approach introduced in \cite{CLM19_closure}  allows indeed for computing approximations  of the conditional expectation term, $P\M$, by relying on the concept of the optimal parameterizing manifold (OPM) \cite[Theorem 5]{CLM19_closure}.  The OPM is the manifold that averages out optimally the neglected variables as conditioned on the resolved ones \cite[Theorem 4]{CLM19_closure}. The approach to determine OPMs  consists at first deriving analytic parametric  formulas that match rigorous leading approximations of unstable/center manifolds or slow manifolds near e.g.~the onset of instability, and then to perform a data-driven optimization of the manifold formulas' parameters to handle regimes further away from that instability onset  \cite[Sec.~4]{CLM19_closure}.    
There, the optimization stage allows for alleviating the small denominator problems rooted in small spectral gaps, and derive thereby meaningful parameterizations in regimes where constraining spectral gap or timescale separation conditions are responsible for the well-known failure of standard invariant/inertial or slow manifolds.


 For multiscale dynamics,  failure in resolving accurately the conditional expectation results typically into a residual that contains too many spurious frequencies 
to be efficiently resolved by data-driven methods based e.g.~on the aforementioned multilayered SDEs, the latter exploiting either polynomial libraries of functions or other specified interaction laws \cite{MSM2015} between the resolved and unresolved variables.  




Lately, much efforts relying on machine learning (ML) techniques have been devoted for the learning of memory terms in MZ-decompositions  \citep{fu2020learning,wang2020recurrent,gupta2021neural}. These go beyond prior efforts involving 
polynomial libraries of specific interaction laws between the slow and fast variables \citep{wouters2013multi,kravtsov2005multilevel,MSM2015}. However, these recent ML works advocate too often an excessive usage of complex neural architectures that hide the simple structures at work for an efficient design of the noise terms, obstructing physical interpretations {\mk as the examples discussed below show}. 



\subsection{Variational approach to closure}\label{Sec_variational}

In the context of subgrid parameterizations, {\it nonlocality} in time in the GLE \eqref{Eq_GLE} means that the subgrid variables exert reactive as well as resistive forces on the resolved variables, and as noted in \cite{kraichnan1987eddy} this may play an important role in reproducing finite-amplitude instabilities and other properties of these variables. Actually, such a situation is expected to occur  in presence of a lack of clean separation between explicit and subgrid variables. In this case, the latter variables exert fluctuating driving forces on the explicit variables which are conceptually distinct from eddy viscosity (or even negative eddy viscosity) \cite{rose1977eddy}. 

%%%%%%%%%%%

We assume thus that $F$ in Eq.~\eqref{EqF} proceeds from a forced fluid model, i.e.~that $F(X)=LX+ B(X,X)+f$ with $B$ denoting a bilinear operator, $L$ a linear operator, and $f$ a force. We are interested in finding an accurate closure in the slow/coarse-scale $a$-variable. To achieve this goal, the parameterization of the $a$-$b$ and $b$-$b$ interaction-terms in the original $a$-equation,  i.e.~the terms accounting for the disparate-scale and fast-scale interactions, is the key issue.  Denoting by $\boldsymbol{\tau}_{int}$ the grouping of these interaction terms, a convenient way to address this problem is by seeking for $\boldsymbol{\tau}_{opt}$ that solves the minimization problem 
\be\label{Min_tau_int}
\underset{\boldsymbol{\tau}}\min  \int_0^{T} \bigg\| \boldsymbol{\tau}(a(t))- \boldsymbol{\tau}_{int}(a(t),b(t)) \bigg\|^2 \mathrm{d} t, \; T\gg 1.
\ee
{\mk The optimal parameterization, $\boldsymbol{\tau}_{opt}$, relates naturally to the conditional expectation of $F$ given by \eqref{Eq_averaging_ope} as $\boldsymbol{\tau}_{opt} (a) =  \overline{F}$ minus the linear and $a$-$a$ interaction  terms that project onto the coarse-scale variables. } 

%%%%%%%%%MC--->Valerio: The paragraph below has been simplified (one formula saved!) %%%%
%Denoting by $V$ the subspace of slow/coarse-scale variables, solving \eqref{Min_tau_int} consists of finding $\boldsymbol{\tau}_{opt} $ that satisfies,   
%$\Pi_V\Big(La+ B (a,a)\Big) + \boldsymbol{\tau}_{opt} (a) =  \overline{F}$,
%where  $\overline{F}$ denotes the conditional expectation of $F$ given by \eqref{Eq_averaging_ope} and $\Pi_V$ denotes the projector onto $V$.
%%%%%%%%%%%%%%%%%%%


%\begin{comment}
{\mk The aforementioned OPM, $\Phi_{opt}$, providing the best approximation in a least-square sense of $b$ as a mapping of $a$, satisfies then that 
$\boldsymbol{\tau}_{int}(a,\Phi_{opt}(a)) \approx  \boldsymbol{\tau}_{opt}(a)$,
with a small residual error when the $b$-$b$ interaction terms are negligible after averaging in the original $a$-equation (such as \cite[Assump.~A4]{majda2001mathematical}); 
see \cite[Theorem 5]{CLM19_closure}. At this stage, knowing $  \boldsymbol{\tau}_{opt}$ or $\Phi_{opt}$  allows us thus to approximate the  average motion of $a(t)$ when averaging is performed  over the ``fast'' variable $b(t)$.}
  
%\end{comment}
% A SMALL CUT HERE---MC: These few lines are important for the applications, so I kept them. 
If one wants to recover beyond averaging,  the effects of the (fast) fluctuations onto  the dynamics of $a(t)$, then the MZ formalism recalled in Sec.~\ref{Sec_MZ} invites us  to revise the minimization problem \eqref{Min_tau_int} into solving the following one 
\begin{widetext}
\be\label{Eq_min_memory}
\underset{\boldsymbol{\tau},\Gamma } \min  \int_0^T\bigg\| \boldsymbol{\tau}(a(t))+ \int_0^t \Gamma (t-s) \boldsymbol{\tau}(a(s))\d s - \boldsymbol{\tau}_{int}(a(t),b(t)) \bigg\|^2 \mathrm{d} t, \; T\gg 1.
\ee
\end{widetext}


Solving this second minimization problem consists thus of decomposing 
the nonlinear interaction term  to account for a memory function and a fluctuating force, namely
\bea\label{Min_tau_int2}
\boldsymbol{\tau}_{int}(a(t),b(t)) \approx &\boldsymbol{\tau}(a(t))\\
&\;+ \int_0^t \Gamma (t-s) \boldsymbol{\tau}(a(s))\d s +f(t). 
\eea
The minimization of  \eqref{Eq_min_memory} can be addressed by means of recurrent neural networks such as long short-term memory NNs \cite{fu2020learning,wang2020recurrent,gupta2021neural}, but their constitutive elements suffer from interpretability and do not easily allow for anticipating the need of memory and/or noise terms.

Another approach consists of pursuing the minimization of \eqref{Eq_min_memory} via Markovianization which consists of breaking down the memory terms and noise terms by means of SDEs with a multilayer structure (similar to Eq.~\eqref{Eq_Hmodel}) whose coefficients are learned successively via recursive regressions using surrogate, stochastic, variables that account for the residual errors produced by the successive regressions until a white noise limit is reached  \cite{Majda_Harlim2012,MSM2015}. 
This data-driven approach \cite{kravtsov2005multilevel} has led to striking results in many fields of applications such as for the modeling of El-Ni\~no-Southern Oscillation (ENSO) \cite{kkg05_enso,ckg11,chen2016diversity}, extratropical atmospheric dynamics \cite{kkg06}, {\mk paleoclimate \cite{Boers_al17},} or the Madden-Julian Oscillation \cite{kcg_13MJO} to name a few. 

These regression-based multilayered SDEs to approximate the MZ decomposition Eq.~\eqref{Eq_GLE} benefit furthermore from useful theoretical insights. Indeed, intimate connections with the multilayered SDEs  derived in \cite{wouters2012,wouters2013multi} based on Ruelle's response theory \cite{santos2021reduced}, were shown to hold  for a subclass of   multilayered SDEs considered in \cite{Majda_Harlim2012,MSM2015}; see \cite{santos2021reduced}.  These connections allow in particular for clarifying circumstances of success for multilayered SDEs with linear coupling terms between the layers corresponding to approximating the memory integrand $\Gamma$ in Eq.~\eqref{Eq_GLE} by repeated convolutions of exponentially decaying kernels  \cite{MSM2015}. The multilayered SDEs of this form were shown to be particularly relevant for weakly coupled slow-fast systems  and the corresponding   memory and noise terms were shown to relate naturally to the Koopman eigen-elements of the ``unperturbed weather'' Koopman semigroup $K_t^w$ whose generator is $\sum  G^j(b) \partial_j$  when $g(a,b)=G(b)+\epsilon C(a,b)$ in Eq.~\eqref{fastslow} with $\epsilon$ small; see \citep[Theorem 2.1]{santos2021reduced}. The approximation of the MZ decomposition Eq.~\eqref{Eq_GLE} via Markovianization sheds thus new lights onto Koopman modes \cite{Budinisic2012} and related dynamic mode decomposition (DMD), widely praised in fluid dynamics over the last decade \citep{Rowley2009, Schmid2010,Kutz2016}, and as such with the Principal Oscillation Pattern modal proposed earlier in atmospheric sciences by Hasselmann \citep{Hasselmann.POPs.1988, Tu.ea.2014}. 





However as mentioned earlier,  it is not always required, depending on the problem, to determine the memory and/or noise terms, and we should thus always look first for the virtue of solving the minimization problem \eqref{Min_tau_int} in the first place instead of solving the more 
challenging minimization problem \eqref{Min_tau_int2} (see Sec.~\ref{Sec_ML_turb} below), which may involve memory or  noise terms of negligible importance for closure. 

% A SMALL CUT HERE: NO REAL NEED TO TALK ABOUT K-S (TACTICAL SACRIFICE IF YOU AGREE)---
%%%MC: I have reduced it, and displaced it to the turbulence section. It is more suited over there, as it allows also to say %%%that memory is not always needed in turbulent regimes (also in the KS realm) as my work with Jim & Honghu demonstrates.  
 An emblematic example is found the context of the Primitive Equations of the atmosphere, it is known  that at low Rossby number, the conditional expectation coinciding with the Balance Equation  is amply sufficient for an accurate closure \cite{chekroun2017emergence}.  However, once a critical Rossby number is crossed, the Balance Equation needs to be seriously amended to capture the complex interactions between the Rossby waves and  inertia gravity waves; the latter becoming non-negligible at large Rossby number. %As shown recently in \cite{chekroun2021stochastic}, this is accomplished  by the inclusion of  stochastic terms to the BE that go beyond white noise or red noise ansatz to properly model the bursts of inertia gravity waves that occur on top of the slow geostrophic motion.  % IT IS AMPLY DISCUSSED LATER; NO NEED HERE----MC: OK
 The next section reviews such a physical example. rich of teachings in terms of MZ-decomposition. 
 



%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}
\includegraphics[width=0.95\textwidth, height=0.35\textwidth]{OPM_SLOs_v3}
\caption{\small {\bf An example of no need of memory but noise term in the MZ-decomposition Eq.~\eqref{Eq_GLE}.} Example from the atmospheric Lorenz 80 (L80) model \cite{Lorenz80} following \cite[Sec.~3.4]{CLM19_closure} and \cite{chekroun2021stochastic}. {\bf Panel A:} The OPM is the BE manifold shown by blue dots. It provides the slow motion of the L80 dynamics. The L80 dynamics (black curve) evolves onto this manifold and experiences excursions off this manifold, corresponding to bursts of fast oscillations  caused by IGWs (see Box 2).  The residual off the BE manifold is 
mainly orthogonal to it causing memory terms to be negligible, and making their stochastic modeling central 
as the $\eta(t)$-term in the MZ decomposition Eq.~\eqref{Eq_GLE}. {\bf Panel B}:  {\mk This residual in the time-domain is  strongly correlated in time and can be grouped in pairs that are} narrowband in frequency and modulated in amplitude with {\mk possible combination of `tones' (bottom panel)}.  {\bf Panel C}:  {\mk Networks of stochastic oscillators such as given in \cite[Eq.~12]{chekroun2021stochastic} are well suited to model such properties}.}\label{Fig_OPMSLO}
\vspace{-2ex}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%


\vspace{-.25cm}
\subsection{The atmospheric Lorenz 1980 model: Markovian and noise terms but no memory}\label{Sec_L80}
\vspace{-.25cm}

Atmospheric and oceanic flows constrained by Earth's rotation
   satisfy an approximately geostrophic momentum balance on larger
   scales, associated with slow evolution on time scales of days, but
   they also exhibit fast inertia-gravity wave oscillations.  The
   problems of identifying the slow component (e.g., for weather
   forecast initialization \cite{bolin1955numerical,baer1977complete,machenhauer1977dynamics,daley1981normal}) and of characterizing slow-fast
   interactions are central to geophysical fluid dynamics. The former was first coined as a slow manifold problem by Leith \cite{leith1980nonlinear}.  
   The Lorenz 63  model \cite{lorenz1963deterministic} famous for its chaotic strange attractor is a paradigm for the
   geostrophic component, while the Lorenz 80 (L80) model \cite{Lorenz80}  is its paradigmatic successor both
   for the generalization of slow balance and for slow-fast coupling. 
   
  %%%%%%%%%%%%%%%%%%%%%%%%%%%% 
  \vspace{-.5ex}
  \begin{bclogo}{\small Box 2: The L80 model and bursts of inertia-gravity waves}
  \footnotesize
   The L80 model, obtained as a nine-dimensional truncation of the PE onto three Fourier modes with low wavenumbers \cite{Lorenz80}, can be written as \cite{CLM16_Lorenz9D}:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\beas \label{Eq_L9D}
 a_i \frac{\d x_i}{\d t} &= \e a_i b_ix_jx_k -  c(a_i - a_k) x_j y_k - c^2y_jy_k\\
& \hspace{-1ex}+  c(a_i - a_j) y_j x_k  -  N_0 a_i^2 x_i + \e^{-2}a_i(y_i - z_i), \\
a_i \frac{\d y_i}{\d t} &=  -  \e a_k b_k x_jy_k - \e a_jb_j y_jx_k 
\hspace{-.2ex}+ \hspace{-.2ex}c(a_k-a_j)y_jy_k\\
& \quad -a_i x_i-N_0a_i^2y_i, \\
\frac{\d x_i}{\d t} &=  - \e b_kx_j(z_k-H_k) -\e  b_j(z_j-H_j)x_k \\ 
&+ cy_j(z_k-H_k)  - c(z_j-H_j)y_k + g_0 a_ix_i\\
&\qquad -K_0a_iz_i + \F_i. 
\eeas


The variables $(\x,\y,\z)$ are amplitudes for the divergent velocity potential, streamfunction, and dynamic height, respectively.
Transitions to chaos occurs as the Rossby number $\e$ is increased; see \cite{Gent_McWilliams82,CLM16_Lorenz9D}. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{SCfigure}
\begin{wrapfigure}[9]{R}{0.55\textwidth}
\vspace{-3ex}
\centering
\includegraphics[width=.55\textwidth, height=.35\textwidth]{surf_BE.jpg} 
\caption*{}\label{BE_visual}
%\end{SCfigure}
\end{wrapfigure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
At small $\e$, the solutions to the L80 model remain entirely slow for all time (i.e.~dominated by Rossby waves) whereas spontaneous emergences of fast oscillations get superimpose to such slow solutions as the Rossby number is further increased.  In such regimes, the balance equation (BE) manifold on which lie balanced solutions \cite{mcwilliams1980intermediate,Gent_McWilliams82} is no longer able to encode the dynamics (see schematic), as the L80 dynamics associated inertia gravity waves (IGWs) get transverse to the BE manifold \cite[Sec.~3.4]{CLM19_closure}.
These regimes with energetic bursts  of IGWs  lie beyond the parameter range Lorenz initially explored in  \cite{Lorenz80} (see \cite{mcwilliams2019perspective}) as well as beyond other regimes with exponential smallness of IGW amplitudes  as encountered in the subsequent Lorenz 86 model \cite{lorenz1986existence,lorenz1987nonexistence,vanneste2008exponential} and the full PE \cite{temam2011slow}  at smaller Rossby numbers; see \cite{vanneste2013balance}.    
\end{bclogo}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Contrarily to other slow-fast systems, this physically-based model exhibits regimes with energetic bursts of fast oscillations superimposed on slow ones that complicate greatly their parameterization \cite{CLM16_Lorenz9D}; see Box 2.    
Regimes beyond exponential smallness of the fast oscillations are not only intimate to the L80 model.  They have been observed in other PE models as conspicuously generated by fronts and jets \cite{plougonven2007inertia,polichtchouk2020spontaneous}, and 
in cloud-resolving models in which large-scale convectively coupled gravity waves spontaneously develop  \cite{tulich2007vertical}. Regions of organized convective activity in the tropics generates also gravity waves leading to a spectrum that contains notable contributions from horizontal wavelengths of 10 km through to scales beyond 1000 km \cite{lane2015gravity} and such IGWs have been also identified from satellite observation of continental shallow convective cumulus  forming organized mesoscale patterns over forests and vegetated areas \cite{Dror2021}.
   


The L80 model provides a remarkable metaphor of such regimes with  a lack of timescale separation at large Rossby numbers, in which the solutions have slow and fast components (mixture of high and low frequencies (HLF)) exhibited by all the components of the model causing a breakdown of slaving relationships {\mk where the fast variables at time $t$ are a function of the slow variables at the same time instant}, calling thus for a revision of slow manifold methods \cite{leith1980nonlinear} and the like. 

Only recently, the generic elements for solving such hard closure problems  with lack of timescale separation, have been identified \cite{chekroun2021stochastic}.  Key to its solution is the Balance Equation (BE) manifold  \cite{mcwilliams1980intermediate,Gent_McWilliams82} as rooted in the works of Monin \cite{Monin1952}, Charney and Bolin \cite{charney1955use,bolin1955numerical} and Lorenz \cite{lorenz1960energy}.  The BE manifold has been shown to provide, even for large Rossby number, the slow trend motion of HLF solutions to the L80 model as it  optimally averages out the fast oscillations; nearing this way the OPM, $\Phi_{opt}$, to a high precision \cite{CLM16_Lorenz9D}. 


For such regimes, the L80 dynamics evolves onto this manifold and experiences excursions off this manifold, corresponding to bursts of fast oscillations caused by IGWs; see Box 2 and Fig.~\ref{Fig_OPMSLO}A.  The residual off the BE manifold is 
mainly orthogonal to it,  causing the memory terms  to be negligible \cite{chekroun2021stochastic} and making the stochastic modeling of the $\eta(t)$-term central 
 in the MZ decomposition Eq.~\eqref{Eq_GLE}. An inspection of this residual in the time-domain shows that it is  strongly correlated in time, narrowband in frequency and modulated in amplitude  (Fig.~\ref{Fig_OPMSLO}B). 
 Recent progresses in characterizing the spectral signature in terms of Ruelle-Pollicott resonances and Koopman eigenvalues (and the like \cite{chekroun2017data,zhen2022eigenvalues}) of such time series  \cite{Chekroun_al_RP2,Tantet_al_Hopf}, 
allow for inferring that such residuals can be efficiently modeled by means of a network of Stuart-Landau oscillators  (SLOs) of the form
\bea\label{Eq_SLOs}
\dot{z}_j=(\mu+i \omega) z_j &- (\alpha + i \beta) z_j |z_j|^2\\
&\; \; + \textrm{'coupling terms'} + \textrm{'white noise'};
% + \textrm{'coupling'} + \textrm{'white noise'};
\eea
see Fig.~\ref{Fig_OPMSLO}C and \cite{chekroun2021stochastic} for more details. 
The BE manifold operates here a remarkable feast: It provides a nonlinear separation of variables allowing for decomposing the mixed HLF dynamics of the L80 model into a slow component captured by the BE, and a fast one modeled by a network of SLOs.  



The resulting closure takes then the OPM-SLO form
\be\label{OPM_SLO}
\frac{\d a}{\d t}=\Pi (L a +B(a+\Phi_{opt}(a)+\xi_t,a+\Phi_{opt}(a)+\xi_t)),
\ee
in which {\mk $\Pi$ denotes the projector onto the coarse variables},  and  $\xi_t$, modeled by means of the auxiliary networks of SLOs \eqref{Eq_SLOs} allow---through its interactions with the parameterization of the slow motion $\Phi_{opt}(a)$ (and the $a$-variable)---to recover,  with a remarkable ability the multiscale dynamics of the L80 model along with its complex bursts of fast oscillations caused by IGWs; see \cite[Fig.~7]{chekroun2021stochastic}. 


In terms of Hasselmann's program, the L80 model is thus rich of teachings.   It shows that an efficient modeling of regimes with a lack of timescale separation characterized by a mixture of intertwined slow and fast motions, requires (i) a good approximation of the OPM capturing the  slow motion, (ii) to go beyond stochastic homogenization and the like \cite{majda2001mathematical} to model the noise; the use of network of SLOs showing a great deal of promises in that respect.  


Finally it is worth noting that thinking of the bilinear terms $B$ in Eq.~\eqref{OPM_SLO}  as proceeding from advective terms in the L80 model, one may interpret the nonlinear terms involving $\xi_t$ in the stochastic OPM-SLO closure \eqref{OPM_SLO} as stochastic advective terms.  Other recent approaches have shown the relevance of such terms to derive stochastic formulations of fluid flows as well as for emulating suitably the coarse-grained dynamics \cite{holm2015variational,cotter2019numerically,resseguier2017geophysical}. 

From a practical viewpoint, the interest of disposing of an accurate stochastic closure such as Eq.~\eqref{OPM_SLO} lies in its ability of  simulating key feature aspects of the multiscale dynamics, offline, in an uncoupled way (here the IGWs) by the network of SLOs \eqref{Eq_SLOs}.  
 
 

The OPM-SLO approach is thus promising to be further applied to the closure of other more complex slow-fast systems, in strongly coupled regimes.   In particular, regimes exhibiting a mixture of fast oscillations superimposed on slower timescales such as displayed by the L80 model provide a challenging ground for closure in more sophisticated fluid problems.  Such regimes are known to arise in multilayer shallow water models; see e.g.~\cite[Fig.~5]{simonnet2003low}.
In certain regions of the oceans, it has been shown  that IGWs can account for roughly half of the near-surface kinetic energy at scales between 10 and 40 km  \cite{rocha2016mesoscale}, making IGWs energetic on surprisingly large scales. Thus, geophysical kinetic energy spectra can exhibit a band of wavenumbers within which waves and turbulence are equally energetic  \cite{young2021inertia}. We believe in the ability of the OPM-SLO approach to show closure skills for such problems. There, the approximation of the OPM/conditional expectation should benefit from recent progresses accomplished  in neural turbulent closures, as explained below, and the fast component of the motion should also benefit from the wealth of dynamics that networks of SLOs can embody (see Sec.~\ref{Sec_too_manyfreq} below).


\subsection{Neural turbulent closures: No memory, no noise, but spatially non-local Markovian terms}\label{Sec_ML_turb}

Much efforts have been devoted lately into the learning of successful neural parameterizations for the closure of fluid models in turbulent regimes such as the forced Navier-Stokes equations or quasi-geostrophic flow models on a $\beta$-plane; see e.g.~\cite{bolton2019applications,maulik2019,kochkov2021,zanna2020,subel2022explaining}.

These neural closure results are typically obtained with convolutional neural networks (CNNs) \cite{goodfellow2016} that are by definition non-local in space and aim at parameterizing the sub-grid scale stress (SGS) tensor in terms of coarse-grained variables. Among the achievements accomplished by these neural closures, have been reported their ability to provide accurate closures for cutoffs within the
inertial range and for high Reynolds numbers, outperforming more standard schemes such as based on the Smagorinsky parameterizations and the like. 



This problem is known to be
difficult as small errors at the level of the SGS typically amplify the errors
at the large scales due to the inverse cascade
\citep{piomelli1991subgrid,jansen2014parameterizing}. To dispose of SGS
parameterizations  at low cutoff levels for such turbulent flows with a
controlled error is thus one of the challenges to resolve.  The accuracy and
stability of the closure results in \cite{bolton2019applications,maulik2019,kochkov2021,zanna2020,subel2022explaining}. are thus strongly supportive for the existence
of a nonlinear function $\boldsymbol{\tau}_{CNN}$ such that the SGS, $\boldsymbol{\tau}$, satisfies, after
spin up, a relation of the form
%
\beq\label{Eq_fundamental_relation}
\boldsymbol{\tau}=\boldsymbol{\tau}_{CNN}(\overline{u},\overline{v})+\epsilon,
\eeq
%
where the residual $\epsilon$ is a spatio-temporal function whose fluctuations
are controlled and small in a mean square sense, while $\overline{u}$ and $\overline{v}$ denote the coarse-grained velocity variables. 
Actually, \eqref{Eq_fundamental_relation} is a consequence  of the very construction of $\Phi_{CNN}$ obtained by minimization of loss functions of the form \eqref{Min_tau_int} up to some regularization term.



In
Eq.~\eqref{Eq_fundamental_relation}, $\boldsymbol{\tau}_{CNN}$ denotes the function found by
means of shallow CNNs trained by minimizing a loss function reminiscent to that involved in \eqref{Eq_min_memory}. The
relation \eqref{Eq_fundamental_relation} based on the quality of the closure 
results reported in \cite{bolton2019applications,maulik2019,kochkov2021,zanna2020,subel2022explaining} suggests thus that $\boldsymbol{\tau}_{CNN}$, in the respective cases, is close to the conditional expectation $\overline{\boldsymbol{\tau}}$ \citep{CLM19_closure}, namely the best
nonlinear functional averaging out the unresolved variables as conditioned on
the coarse variables. Thus, finding a good approximation of $\overline{\boldsymbol{\tau}}$ is
sufficient for the closure of forced two-dimensional turbulence problems at
high $Re$. 

As such, these neural closure results rule out  for turbulent problems, even at low cutoffs,  the use of memory  terms in the 
Mori-Zwanzig interpretation (Sec.~\ref{Sec_MZ}); memory terms that have been thus unecessarily praised 
in other closure studies relying on the MZ formalism; see
e.g.~\citep{miyanawala2017efficient,parish2017non,ma2019model}. 
{\mk Similarily, memory terms have been advocated for the closure of Kuramoto-Sivashinsky turbulence in the reduced state space spanned by the unstable modes \cite{lu2017data,ma2019model}, whereas a good learning of the conditional expectation has been shown to be also amply sufficient for closure in such reduced state spaces, for even more turbulent regimes \cite[Sec.~6]{CLM19_closure}.}

%%%MC: I've made the blending of the content below more suited in this Section. Thank you for this good catch! 
%\begin{comment}
%{\mk For instance, the closure results shown in \cite{lu2017data,ma2019model} for  the Kuramoto-Sivashinsky (KS) model rely on the unnecessary learning of  memory terms. Indeed, regimes considered therein correspond to weakly turbulent ones with 3 pairs of unstable modes for which a closure is pursued for a reduced state space $V$ spanned by these unstable pairs and a few stable ones. As shown in through a careful analysis \cite[Sec.~6]{CLM19_closure}, the good learning of the OPM (and thus the conditional expectation) is however amply sufficient to derive closures of high accuracy for much more turbulent regimes (with up to 99 pairs of unstable modes) and for $V$ taken to be exactly spanned by the unstable modes with no stable modes included whatsoever; the memory terms showing their relevance only when some unstable modes are left in the modes to be parameterized.}
%{\mk Another }
%\end{comment}


%To the
%contrary, 
The neural turbulent closure results of \cite{bolton2019applications,maulik2019,kochkov2021,zanna2020,subel2022explaining} restore thus some credentials to ideas proposed in the late 80s by
\cite{FMT88,foias1991approximate} envisioning two-dimensional turbulence as
essentially finite-dimensional with turbulent solutions lying in some thin
neighborhood, in a mean square sense, of a finite-dimensional manifold \citep[Eq.~(1.5)]{CLM19_closure};  ideas that were  watered down as
shown to be valid, only for cutoff wave numbers within or close to the dissipation range \citep{pascal1992nonlinear} when relying on
{\it traditional analytic parameterizations} such as initially proposed in \citep{FMT88}.
 The usage of neural
networks shed thus new lights on this old problem as pushing the validity of
relationships such as \eqref{Eq_fundamental_relation} for cutoff within the
inertial range. 

 %%%%%%%%%%%%%%%%%%%%%%%%
  \begin{figure*}
	\centering
		\includegraphics[width=.85\textwidth,height=0.45\textwidth]{Turbulence_Fig_rev}
		\vspace{-1.4ex}
	\caption{\small {\bf Upper-ocean potential vorticity (PV) anomalies, its time-evolution,  
	and standard deviation: QG vs MSLM} (from \cite{Kondrashov_al2018_QG}). {\bf Panel (A)}:  Instantaneous upper-ocean PV anomaly field from a high-resolution simulation (HRS) of a baroclinic QG turbulent model. {\bf Panel (B)}: Standard deviation of this HRS over a $64\times 26$ coarse-grid. 
{\bf Panel (C)}:  Standard deviation as simulated by the MSLM reduced model over the same coarse grid. 
	{\bf Panels (D) and (E)}:  Instantaneous upper-ocean PV anomalies  from the coarse-grained QG model and its MSLM reduced model, respectively.
{\bf Panel (F) and (G)}: First PC of the coarse QG's (resp.~the MSLM) upper-ocean PV, and its decadal LFV content shown in red (resp.~blue). The MSLM is able to remarkably reproduce the multiscale temporal variability of the QG coarse-grained dynamics.}
	\label{QG_FLD}
	\vspace{-1ex}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{The good choice of resolved variables: A baroclinic ocean model example}\label{Sec_too_manyfreq}
We should not loose sight that the MZ framework is conditioned to the choice of resolved and neglected variables inherent to that of the reduced state space in which a closure is sought. This is actually a key step in data-driven modeling where one typically compress the original field into a few variables to model. Principal components (PCs) as extracted from an empirical orthogonal function (EOF) decomposition \cite{lorenz_1956,jolliffe2002principal} are usually used for that purpose as in \cite{kkg05_enso,ckg11,chen2016diversity,KCYG_2018_arctic}, but many other decompositions may be used such as nonlinear \cite{scholkopf1998nonlinear,mukhin2015principal} or probabilistic versions \cite{tipping1999probabilistic} of EOFs, {\mk spectral versions of EOFs \cite{schmidt2019spectral} and the like \cite{chekroun2017data,zerenner2021harmonic}} or techniques reflecting the  the (local) geometry and density of the data \cite{giannakis2013nonlinear}, to name a few.  %{\attn VAE...}

Whatever the decomposition method retained one may face the problem of mixture of timescales as encountered in Sec.~\ref{Sec_L80} for the L80 model, depending on the timescale of interest one wishes to resolve via a reduced model. This is for instance encountered in wind-driven baroclinic quasi-geostrophic (QG) models of the ocean on decadal timescales. The ocean circulation of eddy-resolving simulation with $\sim 10^6$ spatial degrees of freedom at reference model parameters \cite{berloff2015dynamically} is characterized by a robust large-scale decadal low-frequency variability (LFV) with a dominant 17-yr cycle, involving coherent meridional shifts of the eastward jet extension separating the gyres; see Fig.~\ref{QG_FLD}A. {\mk To this decadal variability is superimposed an interannual variability caused by the eddy dynamics; see  \cite{Kondrashov_al2018_QG}.}
Due to this highly turbulent and multiscale nature of the flow,  the capture of {\mk the eddies' dynamics} on a coarse-grid by a reduced model is highly challenging.  

Within the reduced state space of (the first few dominant) PCs this challenge is manifested by the multiscale nature of the PCs' temporal evolution; a slow evolution (decadal) contaminated by ``fast'' interannual oscillations (due to the eddy-dynamics); see {\mk Fig.~\ref{QG_FLD}F}.  
Such multiscale features constitute the main cause behind the failure of multilayered SDEs such as those of \cite{kravtsov2005multilevel,Majda_Harlim2012}  in approximating, here,  the memory and noise terms in the MZ-decomposition, in spite of their successes  in other geophysical problems  as recalled in Sec.~\ref{Sec_variational}.   
The reason behind lies in the set of predictor functions used for the learning of the multilayered SDEs ingredients, either responsible for an explanatory deficit, or victim of a spectral bias if neural networks are employed \cite{rahaman2019spectral}.  

This is where, multivariate signal decomposition methods such as  \cite{GhilEtAl_RG02,chekroun2017data} offer a precious alternative for remedying to such issues {\mk by extracting empirical modes of variability}. Indeed, such methods, when effective in separating the slow and fast temporal components of the PCs (or analogues), provide a natural ground for the modeling of these temporal components by means of stochastic SLOs such as in Eq.~\eqref{Eq_SLOs}, this time ranked by frequency to be resolved, and introduced as Multiscale Stuart-Landau Models (MLSMs) in \cite{chekroun2017data}.  The fact that such MSLMs provide remarkable closure skills for such challenging QG turbulent problems (see  \cite{Kondrashov_al2018_QG} and Fig.~\ref{QG_FLD}), invites for more studies exploiting MSLMs and signal decomposition methods to tackle the closure of more realistic PE models, as well as for more understanding.    The MSLMs being stochastic oscillators, it raises the question whether the original quasiperiodic Landau's view of turbulence \cite{ruelle1971nature,landau2013fluid}, with the amendment of the inclusion of stochasticity, may be in the end well suited to describe turbulence.





\section{Describing the Climate Crisis via Response Theory}\label{climateresponse}

\begin{comment}The key step in linear response theory amount to estimating the Green function relative to a specific forcing for the observables of interest. Near equilibrium, the standard form of the fluctuation-dissipation theorem (FDT) \cite{kubo1966} allows to express Green function in terms of readily accessible and intuitive correlations of observables in the unperturbed system.
The FDT for near-equilibrium systems has been applied in the past to the output of climate models to predict the climate response to changes in the solar irradiance \cite{North1993}, GHGs concentration \cite{Cionni2004,Langen2005} as well as to study the impact of localised heating anomalies \cite{gritsun2007}. Nonetheless, the implicit assumptions lead to potentially large errors in the estimate of the response \cite{gritsun2017}. In order to bypass the problem of using the FDT, a possible strategy is to estimate the Green functions for the observable(s) of interest from a set of suitably defined simulations.  As shown in \cite{ragone2016,Lucarini2017,Lembo2020} for the case of CO$_2$ forcing, it is convenient to derive the Green functions of interest by performing an ensemble of $N$ simulations where the CO$_2$ concentration is instantaneously doubled, and the runs continue until the new steady state is obtained. The Green function is then stimated by taking the time derivative of the ensemble average of the response of the model to such a forcing. %The Green function can then be used for performing  projections of climate response to arbitrary protocols of CO$_2$ increase, see Fig. \ref{fig:Lembo}.
Response theory can be used also for other problems of great practical relevance in climate science, like estimating the point of no return for climate action \cite{Aengenheyster2018}, elucidating the fundamental issues and uncertainties associated with the deployment of geoengineering strategies related to the injection of aerosols in the stratosphere \cite{Bodai2020}. 
\end{comment}
We can address the problem of quantifying the  climatic response to forcings by considering the impact of perturbations on the statistical properties of ensemble of trajectories evolving according to a given SDE. %applied to a stochastic differential equations (SDE) impact the properties of ensemble. 
%We want to be as general as possible and c
%We consider the case of general time-dependent perturbations acting on either the deterministic component (a parametric modulation of the system) or in the stochastic component (a perturbation to the noise law, associated with changes in the properties of the unresolved degrees of freedom). %This is a rather general setting to treat a variety of climate change scenarios. 
Hence, we consider the following $d$-dimensional It\^o SDE 
% \begin{equation}\label{eq:sto ode 2}
%\dd \xx (t) = \left[\FF (\xx)  + \sum_{u=1}^U\varepsilon^u_1 g^u_1(t)\GG_u(\xx) \right]\dd t+\left[\Sigma(\xx) +\sum_{v=1}^V\varepsilon^v_2g^v_2(t)\Gamma_v(\xx)\right]\dd W_{t},
%\end{equation}
%%%%%%%%%%%%%%%%%% 
\begin{equation} \begin{aligned}\label{eq:sto ode 2}
\d \x  = &\left[\FF (\x)  + \sum_{u=1}^U\varepsilon^u_1 g^u_1(t)\GG_u(\x) \right]\d t\\
&+\left[\Sigmab(\x)+\sum_{v=1}^V\varepsilon^v_2g^v_2(t)\Gamma_v(\x)\right]\d \W, 
\end{aligned}\end{equation}
%%%%%%%%%%%%%%%%%%%
where %$\W$ denotes a $p$-dimensional Wiener process, $p\geq 1$.
%In Eq.~\eqref{eq:sto ode 2}, 
the unperturbed dynamics is  given by Eq.~\eqref{Hass1}.
%$\d \x =\FF(\x) \d t +\Sigmab(\x) \d \W$ (see Eq.~\eqref{Hass1}). %  whose 
%drift term is given by a smooth vector field $\FF$ on $\R^d$, and the noise term by the $d\times p$  matrix-valued function $\Sigma(\x)$.
We consider the case of general time-dependent perturbations acting on either the deterministic component (a parametric modulation of the system) or in the stochastic component (a perturbation to the noise law) associated e.g.~with changes in the properties of the unresolved degrees of freedom. The perturbations to the drift term are  embodied by the vector fields $\GG_u$, each modulated by a {\mk (scalar) amplitude function} $g^u_1(t)$ and a small parameter $\varepsilon_u$. The perturbations to the noise term are embodied by the $d\times p$ matrices $\Gamma_v$, {\mk whose amplitude are controlled by the functions $g^v_2(t)$ and the small parameters $\varepsilon_v$.}

%each modulated by a scalar-valued bounded function $g^v_2$ and by a small constant . 


%The unperturbed dynamics is defined by the deterministic drift $\FF : \R^d \longrightarrow \R^d$ and by the noise law given by the $d\times p$ matrix $\Sigma \in \R^{d\times p}$, $p\geq 1$. Additionally, $W_t$ is a $p$-dimensional Wiener process. The perturbations to the drift terms is associated with the vector fields  $\GG_u:\R^d \longrightarrow \R^d$, modulated by the bounded functions $g^u_1: \R \longrightarrow \R$, $u=1,\ldots,U$, respectively. The perturbation to the noise law is  expressed in terms of the matrices $\Gamma_v(\xx)\in \R^{d\times p}$ and are modulated by  the bounded functions $g^v_2: \R \longrightarrow \R$, $v=1,\ldots,V$, respectively. We define $M=U+V$. Finally,  $\varepsilon^u_1,\varepsilon^v_2\geq0$, $u=1,\ldots,U$, $v=1,\ldots,V$ are real numbers that control the intensity of the perturbations. %We assume that the SDE \eqref{eq:sto ode 2} generates a process $\xx(t)$ in $\R^d$ for an initial condition at a certain value of time. T
\begin{comment}
Under suitable conditions of regularity, the reference, unperturbed climate is given by the stationary solution $\rho_0(\x)$ of the Fokker-Planck equation corresponding to the SDE \ref{eq:sto ode 2} when  $\varepsilon^u_1=\varepsilon^v_2=0$ $\forall u=1,\ldots,U$ and $\forall v=1,\ldots,V$:
\begin{equation}\label{eq:fpe 2}
\partial _t\rho_0(\x) =\LLL_0 \rho_0(\x)= -\nabla \cdot \lp \FF\rho_0(\x) \rp   +\frac{1}{2}\nabla^2:\lp  \Sigma \Sigma^{\top}\rho_0(\x) \rp=0,
\end{equation}
where ``$:$'' denotes the Frobenius inner product, and $\Sigma \Sigma^{\top}$ is the noise covariance matrix. As well known, the presence of non-vanishing noise, by introducing diffusion, makes sure that the measure is smooth. At practical level, the measure $\rho_0$ corresponds to what in the The invariant measure can be normalized to one so that we can write the expectation value of a general observable $\Psi$ as $\langle \Psi \rangle_0= \int\mathrm{d}\x \rho_0(\x)\Psi(\x)$. The function $\Psi$ could in principle be any quantity of climatic interest, corresponding to local properties described at a specific grid point, or spatially averaged ones. It makes sense to associated possible $\Psi$'s with essential climate variables (ECVs), which are key physical, chemical, or biological variables  that critically contribute to the characterization of Earth's climate and are targeted for observations \cite{Bojinski2014}, of the variables used in the definition of performance metrics developed for testing the performance of Earth System Models \cite{Eyring2020}. 
\end{comment}

%Climate change manifests itself as the change in the measure of the system, due to the presence of the time-dependent forcing associated with the perturbations of intensity $\varepsilon_1$ and $\varepsilon_2$. 
If one considers a background deterministic dynamics {\mk ($\Sigmab(\x)=0$) and the time-dependent forcing
in the drift terms are non-vanishing}, finding the solution $\rho_\varepsilon(\x,t)$ of the FPE corresponding to Eq.~\eqref{eq:sto ode 2} amounts to studying the  properties of the {\mk statistical equilibrium supported by the system's} pullback attractor \cite{Chekroun2011,CLR13,TelJSP,PieriniJSP}.  
%Recently, this construction has been generalised also for the case of SDEs \cite{Graceffa2021}.} %Following the classical results by Kubo \cite{kubo1966}, 
%Modern development version of response theory \cite{ruellegeneral1998,ruelle2009,Hairer2010} provide practically usable tools for predicting in a vast class of systems how the acting forcings impact the statistical properties of the system. 
Following \cite{Santos2022}, let us assume that $\rho_\varepsilon(\x,t)$ %of the Fokker-Planck equation corresponding to Eq.~\eqref{eq:sto ode 2} 
can be written as:
%\begin{equation}\label{eq:expansion time dependent density}
\bes
\rho_\varepsilon(\x,t) = \rho_0(\x) + \sum_{u=1}^U\varepsilon^u_1  \rho^u_{1,d}(\x,t) + \sum_{v=1}^V\varepsilon^v_2 \rho^v_{1,s}(\x,t) + h.o.t.
\ees
%\end{equation}
Such an asymptotic expansion is the starting point of virtually {\mk any} linear response formulas for statistical mechanical systems; see \cite{Lucarini2016,SantosJSP} for a discussion of the radius of convergence of the expansion above.
%In our case, we assume that  the basis of linear response theory.  widely used in the literature--- see, e.g. \cite{kubo,pavliotisbook2014}--- but its validity can be made rigorous in the context of the work of \cite{Hairer2010}.}
%The expectation value of a general observable $\Psi$ with respect $\rho(\cdot,t)$ can be written as:
%\begin{align}
%	\left \langle \Psi , \rho_\varepsilon(\cdot,t) \right \rangle = \int  \dd \xx \rho_0(\xx) \Psi(\xx) + \sum_{u=1}^U\varepsilon^u_1   \int \dd \xx \rho^u_{1,d}(\xx,t)  \Psi(\xx)  + \sum_{v=1}^V\varepsilon^v_2  \int \dd \xx \rho^v_{1,s}(\xx,t)  \Psi(\xx)  +  h.o.t. \label{eq:response function a}.
%\end{align}
%It is important to note that such average is computed with respect to the measure supported on the snapshot attractor at time $t$, and cannot, in the case of time-dependent forcings, be readily approximated with time-averaging as ergodicity does not apply \cite{Tel2020,Drotos2022}.  
The expected value of 
$\Psi$ at time $t$ is %respect to the measure $\rho_\varepsilon^t=\rho_\epsilon(\cdot,t)$ is 
%\begin{equation} \begin{aligned}\label{eq:response function a}
%	\langle \Psi \rangle_{\rho_\varepsilon^t}&= \int  \d \rho_\varepsilon(\xx,t) \Psi(\xx)\\
%	&= \int  \d  \rho_0(\xx) \Psi(\xx) + \sum_{u=1}^U\varepsilon^u_1   \int \d  \rho^u_{1,d}(\xx,t)  \Psi(\xx)  \\
%	&+ \sum_{v=1}^V\varepsilon^v_2  \int \d \rho^v_{1,s}(\xx,t)  \Psi(\xx)  +  h.o.t.
%\end{aligned}\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{equation}\label{eq:response function a}
\bes
	\langle \Psi \rangle_{\rho_\varepsilon^t}=\int  \d  \rho_\varepsilon(\x,t) \Psi(\x) =  \langle \Psi \rangle_0+  \delta^{(1)}[\Psi] (t)  +  h.o.t.
\ees
%\end{equation}
where %$ \langle \Psi \rangle_0=\int  \d  \rho_0(\xx) \Psi(\xx) $ and 
the \emph{linear response} is: %accounting for the first order corrections is:
%\begin{equation}
\bea\label{eq:linear response time dependent}
\delta^{(1)}[\Psi] (t) = \sum_{u=1}^U\varepsilon^u_1 &  \left(g^u_1 \bullet \GGG^u_{d,\Psi} \right) (t) \\
&\qquad+ \sum_{v=1}^V\varepsilon^v_2  \left( g^v_2 \bullet \GGG^v_{s,\Psi} \right) (t)
\eea
%\end{equation}
where``$\bullet$'' indicates the convolution product between the {\mk forcing amplitudes} $g^{u/v}_{1/2}$ and the Green functions $\GGG_{d/s,\Psi}^{u/v}$;  see \cite[Eq.~(8)]{Santos2022} {\mk and Box 3 for the latter}. 



As discussed in \cite{Pedram1}, having  analytic formulas for the linear response of a climate model to perturbation would entail having an exact theory for determining {\mk in particular} the eddy-mean flow feedback. This {\mk is clearly not an easy task as} it would require a fully coherent theory of climate dynamics, which is still far from having been achieved. Hence, we need to find ways to estimate the response operators. The Green's functions shown in the Box 3 {\mk (Eq.~\eqref{eq:Green})} can be interpreted as lagged correlations between the  observables $\Phi=\ellL_{1,d/s}^{u/v}(\log \rho_0)$ and $\Psi$. This indicates a generalisation of the classical FDT \cite{kubo1966,abramov2007,pavliotisbook2014}. %since according to \eqref{eq:Green}, Green functions  are interpreted as  
%the  $\GGG^{d/s}$'s are 
%lagged correlations between the  observables $\Phi=\ellL_{1,d/s}^{u/v}(\log \rho_0)$ and $\Psi$. 
 %These formulas provide the basis for success of the linear response approach discussed in \cite{Maier-Reimer1987,Hasselmann1993b}; see Eq.~\eqref{GHass}.
%Equation \ref{GreenH} provides the starting point for treating climate response as an inverse problem, where one tries to estimate the $\lambda_j$'s and the  $\alpha_j^((k))$'s from data, in order to get a comprehensive understanding of the internal and forced variability of the climate. This has been recently attempted in some rather interesting studies \cite{Torres2021a,Torres2021b,Bastiaansen2021}, where, unfortunately, the $\lambda_j$'s are assumed to have only real values. As mentioned above, this assumption is rather problematic as decaying oscillatory behaviour is filtered out or misrepresented.
The FDT has been applied in the past to the output of climate models to predict the climate response to changes in the solar irradiance \cite{North1993}, GHGs concentration \cite{Cionni2004,Langen2005} as well as to study the impact of localised heating anomalies \cite{gritsun2007}. Nonetheless, the use of gaussian or quasi-gaussian approximations for $\rho_0$, which leads to using Green-Kubo formulas in the context of a non-equilibrium system, leads to potentially large errors in the estimate of the response \cite{gritsun2017}. In \cite{Pedram2} one can find a rather detailed analysis of the reasons why classical FDT methods fail in reproducing the response operators, pointing, instead, to fundamental issues with data reduction techniques used to preprocess the data: features associated with weak modes of natural variability (which are possibly filtered out) can have {\mk an important} role in determining the response. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{bclogo}{{\small Box 3: Green's Functions and Sensitivity}}\label{GF}
\footnotesize{The Green's functions $\GGG_{d/s,\Psi}^{u/v}$ are key tools for computing a {\mk system's linear} response  to perturbations. {\mk They can be written as} 
%\begin{subequations}
%\begin{align}\label{eq:Green}
\bes%\label{eq:Green}
\GGG_{d/s,\Psi}^{u/v}(t) =\Theta(t) \hspace{-1ex}\int  \hspace{-1ex}\d \rho_0(\x) e^{t\ellL^{\ast}_0} \Psi(\x) \LLL_{1,d/s}^{\mk u/v}(\log(\rho_0(\x))), \mbox{i.e.}
\ees
%\Theta(t)\int \dd \xx \rho_0(\xx) e^{t\LLL^{\ast}_0}
\bea\label{eq:Green}
\GGG_{d/s,\Psi}^{u/v}(t) 
 &=\Theta(t)\int \dd \x \rho_0(\x)
 \Psi(\x(t)) \Phi(x)\\
 &=\Theta(t){\mk C_{\Psi,\Phi}(t)},
\eea
%\end{align}
%\end{subequations}
where $\Theta(t)$ is the Heaviside distribution which ensures causality  \cite{ruelle2009,Lucarini2017,Lucarini2018JSP}. 
The operators $\ellL_0^\ast$, $\ellL^u_{1,d}$ and $\ellL^v_{1,s}$ are: %\cite[Remark 2.1]{Santos2022}
\begin{subequations}
\begin{align}
& \ellL_0^\ast \Psi = \FF \cdot \nabla \Psi  + \frac{1}{2}\Sigma\Sigma^{T}: \nabla ^2  \Psi, \label{L0aststo} \\
& \ellL^u_{1,d} \rho = -  \nabla \cdot\left( \GG_u  \rho\right), \; 1\leq u\leq U,\\ 
& \ellL^v_{1,s}\rho = \frac{1}{2}\nabla ^2  : \lp \lp \Sigma_v\Gamma^{T} + \Gamma\Sigma_v^{T} \rp \rho\rp,\; 1\leq v\leq V.\label{L1asta}
\end{align}
\end{subequations}
In \eqref{L0aststo}, $\ellL_0^\ast$ is the Kolmogorov operator, the dual of the Fokker-Planck operator $\ellL_0$ associated  with the unperturbed SDE given in Eq.~\eqref{Hass1}, while ":" denotes the Hadamard product. 

The sensitivity of the system as measured by the observable $\Psi$ with respect to the forcing encoded by $\GGG_{d/s,\Psi}^{u/v}(t)$ measures the long-term impact of switching on the forcing and keeping it at a constant value, which corresponds  to choosing a constant (unitary  time modulation). Hence, such sensitivity can be written as $S_{d/s,\Psi}^{u/v}=\int_0^\infty \mathrm{d}t\GGG_{d/s,\Psi}^{u/v}(t)$.  %$\ellL_0^\ast$ is the Kolmogorov operator %and $e^{t\ellL^{\ast}_0}$ as the Markov semigroup  \cite{Chekroun_al_RP2} 
}\end{bclogo}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

A possible way forward  is to estimate the Green's functions for the observable(s) of interest from a set of suitably defined simulations. %, and then perform predictions for arbitrary choices of the modulating function $g_1$ and $g_2$. 
As shown in \cite{ragone2016,Lucarini2017,Lembo2020} for the case of CO$_2$ forcing, it is convenient to %derive the Green's functions of interest by 
perform an ensemble of $N$ simulations where the CO$_2$ concentration is instantaneously doubled, and the runs continue until the new steady state is obtained. The Green's functions are estimated by taking the time derivative of the ensemble average of the response of the model to such a forcing, and can then be used for performing  projections of climate response to arbitrary protocols of CO$_2$ increase. 

 Figure \ref{fig:Lembo} portrays the application of response theory to an Earth System Model, where accurate projections are obtained for the globally averaged surface temperature and for the Atlantic Meridional Overturning Circulation (AMOC) strength \cite{Dijkstra2005low,Kuhlbrodt2007} for a 1\% increase of the CO$_2$ concentration from pre-industrial conditions up to doubling. Note the very pronounced {\mk weakening} of the AMOC and the slow recovery after the applied forcing stabilizes; see discussion in {\mk Sec.~\ref{TPs} below}.

Response theory can be used also for other problems of  practical relevance in climate science, like estimating the point of no return for climate action \cite{Aengenheyster2018} and explaining whether, along the lines of defining causal links, one can use a climate observable as a surrogate forcing acting on another observable of interest \cite{Lucarini2018JSP,Tomasini2020}. 
In \cite{Pedram1} one can find a very useful discussion of additional potential uses of response theory in a climatic context. It can be used to solve an inverse problem like determining the forcing needed to achieve a given response {\mk and relates in that sense to (optimal) control ideas \cite[Sec.~3]{CKL17}}. A relevant application in this regard pertains the analysis of basic issues and uncertainties associated with geoengineering strategies related to the injection of aerosols in the stratosphere \cite{Bodai2020}. Additionally, one can use response theory to determine the forcing (of given norm) producing the largest response. 
%Being more specific, it allows to formalise well-know facts in climate change science like that increase in the surface temperature of the oceans due to global warming typically lead to increased precipitation \cite{IPCC13}. Clearly, formally speaking, the only acting forcing is the increase in the GHGs. Yet, as a result of the time scales of the physical processes leading to condensation of water vapour and eventually and to precipitation, it is true that anomalies in surface temperature cause anomalies in the precipitation.

 %Additionally, it can be used in  but we can also find the forcing needed to achieve a prescribed response (the inverse problem), the most effective forcing (i.e., forcing producing the largest response), and the most excitable dynamical mode;  \cite{Pedram1}

\begin{figure}
    \centering
   a)\includegraphics[width=0.4\textwidth]{Lemboetal2020_fig1.jpg}\\
   b)\includegraphics[width=0.4\textwidth,trim=0 5.2cm 0 .2cm,clip]{Lemboetal2020_fig2.jpg}
    \caption{Prediction of a) Globally averaged surface temperature and b) Atlantic Meridional Overturning Circulation (AMOC) strength as a result of an annual 1\% increase of the CO$_2$ concentration from pre-industrial conditions up to doubling. {\mk In each panel} the blue {\mk curve} indicates the {\mk prediction by application of response theory while} the thick red {\mk curve} shows the ensemble mean of the model runs (yellow {\mk curves}).) From \cite{Lembo2020}.}
    \label{fig:Lembo}
\end{figure}

\subsection{Response, Feedbacks, and Koopman Modes}\label{sec:spectral time dependent}

Response theory allows one to frame classical concepts of climate science in a much broader context. Equilibrium Climate Sensitivity (ECS) is the long-term globally averaged surface air temperature increase due to a doubling of the CO$_2$ concentration \cite{IPCC13}. From Box 3, one derives a formal definition of such a quantity as the time integral from 0 to $\infty$ of the Green's function describing the response of the globally averaged surface temperature to increases in the CO$_2$ concentration; see also \cite{GhilLucarini2020} .  Transient climate response (TCR) is the globally averaged surface air temperature increases recorded at the time at which CO$_2$ has doubled as a result of 1\% annual increase rate, i.e. roughly after 70 years \cite{Otto2013}. Intuitively, one has that ECS is larger than the TCR because of the thermal inertial of the climate system, namely the fact that following the forcing due to increased CO$_2$ concentration, the system needs some time to adjust to its final, steady state temperature. As shown in \cite{ragone2016}, it is possible to find an explicit formula relating ECS and TCR, which shows that the difference between the two quantities is associated with the properties of the Green's function at all temporal scales. 

%This indicates that 
Response theory makes it possible to investigate the key features of the climatic feedbacks acting on different time scales. % and, especially of the  time scales characterising their operation. 
%In order to substantiate this, 
We provide a rewriting of the Green's functions in terms of individual components specifically associated with the eigenmodes of the unperturbed Kolmogorov operator $\LLL_0^\ast$ {\mk (Box 3)}.  Let $\{ \lambda_j \}_{j=1}^{M}$ be $M$ eigenvalues of finite algebraic multiplicity {\mk $m_j$} with largest real part. The $\lambda_j$ are either real or come in complex conjugate pairs. {\mk In the case of vanishing noise}, these are the dominant Koopman {\mk eigenfunctions} of the system.  Namely, if $\lambda_j$ is an eigenvalue of $\LLL_0^\ast$ with eigenfunction $\psi^\ast_j$, so is $e^{\lambda_jt}$ of ${K}_t=e^{t\LLL^\ast_0}$ relative to the same eigenfunction. The eigenfunctions  $\psi^\ast_j$ {\mk are the analogue of the Koopman eigenfunctions in presence of noise and encode the stochastic system's natural variability, decay of correlations and (temporal) power spectra; see \cite{Chekroun_al_RP2}.}
% is a so-called Koopman mode 
%%%%%%%%MC--->VL: We have to be CAREFUL not to CONFUSE Koopman modes with Koopman eigenfunctions, the former are functional of the latter. 
%%%\cite{Schmid2010,Kutz2015,Kutz2016,Lusch2018}. 
Koopman analysis {\mk and related methods} have {\mk demonstrated great promises over the last decade} in capturing  modes of climate variability from high-dimensional model and observational data \cite{Froyland2021}.

Following \cite{Tantet2018,Chekroun_al_RP2}, it was shown in \cite{Santos2022} that using the Koopman mode formalism it is possible to express %spectral elements of the Koopman/Kolmogorov operators provide a precise characterization of 
the  Green's functions $\mathcal{G}_{k,p}$ introduced in Eq.~\eqref{eq:Green} as a sum of exponential functions (possibly multiplied by polynomials):\be\label{GreenH}
\GGG^k_{d/s,\Psi}(t) =  \Theta(t) \sum_{j=1}^{{\mk \mathcal{Z}}}\sum_{\ell=0}^{m_j-1} \alpha_j^{\ell,k,s/d}(\Psi)\frac{1}{\ell!} e^{\lambda_jt}t^{\ell},
\ee
where the coefficient $\alpha_j^{\ell,k,s/d}(\Psi)$ are discussed in Box 4, whereas their expression can be found in \cite{Santos2022}.
%
In Eq.~\eqref{GreenH} we are neglecting the contribution to the response coming from the essential component of the spectrum of the Koopman/Kolmogorov operator \cite{Santos2022}. This point is often implicitly assumed when performing {\mk extended} DMD \cite{williams2015data}. This derivation explains why the  formula presented in Eq.~\eqref{GHassExp} allowed to correctly interpret the climate feedbacks in \cite{Maier-Reimer1987,Hasselmann1993b}. We stress here that the $\lambda_j$ do not depend on either the observable or the forcing considered, but are instead a fundamental property of {\mk the reference system's dynamics}.

\subsection{Impact of Tipping Points}\label{TPs}
Since any Green's function for the observable $\Psi$ can be interpreted as a correlation function between $\Psi$ and a suitably defined observable $\Phi$ {\mk (Box 3)}, it should not come to a surprise that, considering Eq.~\eqref{GreenH}, one has:
\be\label{CorrelationH}
{\mk C_{\Psi_1,\Psi_2}(t)}=  \sum_{j=1}^{{\mk \mathcal{Z}}}\sum_{\ell=0}^{m_j-1} \beta_j^{\ell,k}(\Psi_1,\Psi_2)\frac{1}{\ell!} e^{\lambda_jt}t^{\ell},
\ee
for any pair of observables $\Psi_1,\Psi_2$. {\mk Actually \eqref{CorrelationH} can be derived as a consequence of the decomposition formula of correlation functions for stochastic systems, in terms of the spectral elements of the Kolmogorov operator \cite[Corollary 1]{Chekroun_al_RP2}.} 
From Eqns.~\eqref{GreenH}-\eqref{CorrelationH} it is clear that the rate of decay of any Green's function as well as of any lagged correlation is dominated over large time horizons by the real part of the subdominant pair of the {\mk Kolmogorov} spectrum. The  {\mk eigenfunctions} correspond to the slowly decaying eigenvalues are the rigorous counterpart of the so-called neutral climate modes that have been widely discussed in the literature \cite{Navarra1993,Palmer1999,Pedram2,Lu2020}.

If we assume that say one {\mk parameter $\gamma$} of our system is such that the spectral gap $\gamma=\mathfrak{Re}(\lambda_1)$ vanishes as $\gamma\rightarrow\gamma_c$, we have that as $\gamma$ nears it critical value $\gamma_c$:
%%%%%%%%%
\vspace{-.5ex}
\begin{itemize}
\item[(i)] Any Green function  and any lagged correlation
decays sub-exponentially unless the corresponding factors ($\alpha$'s and $\beta$'s, respectively) vanish;
\item[(ii)] {\mk Due to the sensitivity formula} given in Box 3, one immediately derives that as we near a tipping point, the sensitivity of the system become larger and larger; {\mk see also \cite{Chek_al14_RP}.}
\vspace{-.5ex}
\end{itemize}
These two phenomena---critical slowing down and diverging sensitivity---are key manifestations of the proximity of tipping points \cite{Lenton.tip.08}. In the case the dynamics of the system of interest can be approximated, in coarse grained sense, by a Ornstein-Uhlenbeck process, another manifestation of being near a tipping point is  
\begin{itemize}
\item[(iii)] The increase in the variance of signal \cite{Held2004,Boettner2022}.
\vspace{-.5ex}
\end{itemize} 
Indeed, in more general terms, item (iii) can be seen as increased sensitivity of the system to the presence of background noise, see \cite{Lucarini2012,Santos2022}. %%%%%%%%%%%%%%

The AMOC has long been seen as a climatic subsystem with potential tipping behaviour as a result of changing climatic conditions, and, specifically, of alternations in the hydrological cycle in the Atlantic basin \cite{Rahmstorf1995,Dijkstra2005low,Kuhlbrodt2007}. Figure \ref{fig:Boers} shows {\mk results from \cite{Boers2021} and \cite{caesar2018observed}} describing {\mk signs from observations that support a nearing of the} AMOC to a {\mk highly plausible} critical transition. {\mk These signs are typically characterized by an increase of the sensitivity and in the variance of an AMOC index tied to the sea surface temperature (SST), as well as by a decrease of the rate of decay of correlations of the same} index; {\mk see also \cite[Fig.~4]{Boers2021}}. Large sensitivity and slow recovery of the same {\mk large-scale climate driver has} already been discussed in a modelling context in Fig.~\ref{fig:Lembo}.

We can learn more about such critical behaviour by taking the Fourier transform of the Green function given in Eq.~\eqref{eq:Green}:
\bea\label{eq:susceptibility transform}
\mathfrak{F}\left[\GGG^k_{d/s,\Psi} \right](\omega)=%& = \sum_{j=1}^{M}\sum_{k=1}^{a_j-1} \alpha_j^{l,k,s/d}\frac{1}{k!}\mathfrak{F} \left[  \Theta e^{\lambda_j \circ }\circ^k \right](\omega)\\
%&=
\sum_{j=1}^{{\mk \mathcal{Z} }}\sum_{l=0}^{{\mk m_j}-1} \frac{\alpha_j^{\ell,k,s/d}(\Psi)}{\lp i\omega - \lambda_j \rp^{l+1}}.
\eea
%%%%%MC--->VL: M is used before and later for other purposes%%%%

%\begin{align}\label{eq:susceptibility simple}
%	\mathfrak{F}\left[\delta^{(1)}\Psi (t)  \right](\omega)= \sum _{j=1}^M \alpha_{j} \mathfrak{F}\left[ g \ast \GGG  \right](\omega) = \mathfrak{F}\left[g\right](\omega)\sum_{j=1}^{M}\frac{\alpha_j}{\omega - \lambda_j}.
%\end{align} 
%The susceptibility function $\mathfrak{F}\left[\GGG\right]$ can be meromorphically extended to all values of $\omega$ in $\mathbb{C}$ such that $\mathfrak{Im}\omega > \omega _{ess}$, where the poles \cite{Ruelle1986} correspond to those of the resolvent norm $\| R(\cdot,\LLL_0) \|$ which are precisely given by the eigenvalues of $\LLL_0$ with the exception of that at $\omega = 0$ by the observation made below Eq.~\eqref{eq:alphas definition}. 
%From the previous expression, it is clear that the $\alpha's$ are the non-equilibrium, classical equivalent of the well-known oscillator strengths discussed in spectroscopy \cite{Hilborn1982,Lucarini2005}. 
\begin{bclogo}{{\small Box 4: Nonequilibrium Oscillator Strengths}}
\footnotesize{Equation \eqref{eq:susceptibility transform} indicates that the coefficient $\alpha_j^{\ell,k,s/d}(\Psi)$ weight the contributions to the frequency-dependent response coming from the  eigenmode(s) corresponding to the eigenvalue $\lambda_j$ (which has in general multiplicity $m_j$) for a given combination of observable and forcing. Note that there is a total of $\mathcal{Z}=\mathcal{Z}_1+2\mathcal{Z}_2$ eigenvalues. Of these, $\mathcal{Z}_1$ are real, and 2$\mathcal{Z}_2$ are complex conjugate pairs. Hence, the $\alpha's$ are the non-equilibrium, classical equivalent of the well-known oscillator strengths discussed in spectroscopy, which weight the contributions to the optical susceptibility from each of the allowed quantum transitions from the ground states to the accessible excited states \cite{Hilborn1982,Lucarini2005}. {\mk Thus}, Eq.~\eqref{eq:susceptibility transform} provides the basis for a spectroscopy of general nonequilibrium systems, and, specifically, of the climate system. Resonant terms are associated with tipping phenomena. }
%As shown in Eq. \ref{eq:susceptibility transform}, if one neglects degeneracies in the spectrum ($a_j=1/2$ in the real/complex case for all $j's$),  
%\begin{eqnarray}\label{Eq_alpha} 
 % &\alpha_j^{\ell,k,s/d}(\Psi)=\\&\int\d\xx \rho_0(\xx) (\ellL^{\ast}_0 - \lambda_j)^{\ell}\Pi^{\ast}_j\Psi (\xx)\ellL^k_{1,s/d}(\log(\rho_0(\xx))),
%\end{eqnarray}
%where $\Pi^\ast_j$ denotes the projector of the observable $\Psi$ onto the eigenfunction $\varphi_j$, of  the Kolmogorov operator associated with the eigenvalue $\lambda_j$ (of multiplicity $a_j$),  ordered according to decreasing real part. Thus, the  $\alpha$-coefficients  weight the contribution of the various  eigenmodes of the response for a given combination of observable and forcing. 
\end{bclogo}


The poles of the susceptibility are located at $\omega= -i\lambda_j$. %On the other hand, the spectral coefficients $\alpha^{(k)}_j$ also known as residues \cite{Ruelle1986}, do depend on the observable and on the applied forcing. %The formulas given in Eqs. \ref{eq:eigenvalues linear response time dependent} and \ref{eq:susceptibility transform} correspond to those presented in \cite{Chekroun_al_RP2} for the time correlation functions and co-spectra of observables in SDEs.
Equation ~\eqref{eq:susceptibility transform} implies the existence of resonances in the response for real frequencies $\omega=\mathfrak{Im}(\lambda_j)$. Neglecting the possible existence of nonunitary algebraic multiplicities, the susceptibility at the resonance $j$ is proportional to $1/\mathfrak{Re}(\lambda_j)$. Hence, as $\gamma\rightarrow\gamma_c$, the susceptibility for $\omega=\mathfrak{Im}(\lambda_1)$ diverges, thus implying a breakdown of the response operator. If at criticality $\mathfrak{Im}(\lambda_1)=0$, the static response of the system diverges, indicating a saddle-node-like bifurcation phenomenon {\mk (turning point)}. If, instead, $\mathfrak{Im}(\lambda_1)\neq0$, we face an oscillatory unstable phenomenon that is reminiscent to a Hopf bifurcation \cite{Tantet_al_Hopf,TantetJSPIII}. The viewpoint proposed here allows to link the {\mk fundamental features} of the tipping phenomenology within a coherent framework.

\begin{figure}
    \centering
 \includegraphics[width=0.49\textwidth,height=0.4\textwidth]{Tipping_combo}   
 \caption{(Adapted from \cite{Boers2021} and \cite{caesar2018observed}) {\bf Panel A}: AMOC index SST$_{\tiny\mbox{SG-GM}}$ \cite{caesar2018observed}  as a function of global mean temperature (GMT) and least-squares fit of the fixed point of a conceptual AMOC model from \cite{Boers2021}.
 {\bf Panel B}: The SST-based AMOC index SST$_{\tiny \mbox{SG-GM}}$, constructed by subtracting the global mean SSTs from the average SSTs of the subpolar gyre region (black), supplemented by the same least-squares fit (red) \cite{Boers2021}. 
  {\bf Panel C}: Variance of fluctuations of the AMOC index around the fixed point (red) and corresponding sensitivity of the model, with control parameter $T$ given by the global mean SSTs. These variances are estimated over a sliding temporal window and the results are plotted at the centre point of that window \cite{Boers2021}. 
 {\bf Panel D}: Observational evidence of the nearing of the AMOC tipping point during the last century from \cite{caesar2018observed}. Shown are time series of SST anomalies with respect to the global mean SST in the subpolar
gyre (sg) and the Gulf Stream (gs) regions (HadISST data).}
    \label{fig:Boers}
\end{figure}
%%%%%%%%MC--->VL: I sticked to AMOC instead of diverting to Arctic Sea Ice. The results shown here are from time series, except the fits that use fixed point of an AMOC model.%%%%%% The Fig. 4 of Boers is REALLY NOT INTUITIVE! %%%So instead I refer to it for the decrease of correlations. 


%\includegraphics[width=0.45\textwidth]{Boers2021.jpg}\\
%    \caption{Observational evidence of the nearing of the AMOC tipping point during the last century. First panel: increase of the sensitivity of the system. Second panel: slowing down of the decay of correlations and increase in the variance. Results are based on specific AMOC indices. Adapted from \cite{Boers2021}.}

\section{Detection and Attribution of Climate Change}\label{optimalfingerprinting}
%Detection and attribution studies aim at quantifying the evidence for a causal link between external forcings and observed climate change \cite{Hasselmann1993b,Hegerl1996,Hasselmann1997} and have played a major role in clarifying that we are presently experiencing a statistically relevant and physically attributable shift from previous climatic conditions \cite{Bindoff2013}. 
The statistical mechanical tools discussed above allow for performing climate change projections for ensembles of trajectories: statements are made in terms of (changes of) the expectation value of general observables. Clearly this is a mathematical construction that does not fully comply with the requirements of climate science, as we experience only one realisations of the dynamics of climate and we do not have to access to the hypothetical multiverse comprising of other statistically equivalent realisations. Nonetheless, linear response theory applied to climate provides a solid setting for detection and attribution studies.

Let $\Psi_k$, $k=1,\ldots,N$ be a collection of climate variables. % (possibly, but not necessarily, associated with a gridded field). 
{\mk Consider also} the possibility that the forcing to the climate system comes from $M$ different sources, be them anthropogenic or natural. We rewrite  Eq. \eqref{eq:linear response time dependent} by clamping together all the $M$ acting forcings as $
\delta^{(1)}[\Psi_k] (t) = \sum_{p=1}^M\varepsilon_p  \left(g_{p} \bullet \GGG_{p,k} \right) (t)$. Hence we have that, at first order, 
%\begin{equation}
%\label{eq:da2}
%Y_k(t)=\Psi_k(t) -\langle \Psi_0 \rangle = \sum_{p=1}^M\varepsilon_p  \left(g_{p} \bullet \GGG_{p,k} \right) (t) +\mathcal{R}_k(t)=\sum_{p=1}^M\tilde{X}_k^p(t) +\mathcal{R}_k(t),, \quad k=1,\ldots,N
%\end{equation}
%where $\Psi_k(t)$ is the actual value of the variable $\Psi_k$ at time $t$ according to the evolution of the system, $Y_k(t)$ is the corresponding anomaly with respect to the background climatology, $\tilde{X}_k^p(t)=\varepsilon_p  \left(g_{p} \bullet \GGG_{p,k} \right) (t)$ and $\mathcal{R}_k(t)=Y_k(t)-\langle\Psi_k\rangle_\epsilon(t)$ is a random vector with covariance defined by the intrinsic climate variability, where such variability, rigorously speaking, has to be computed according to the ensemble supported on the snapshot attractor at time $t$ \cite{Tel2020}, and not, as typically done in detection and attribution studies, according to the unperturbed natural variability. Instead, the theory of linear response imposes that the statistical properties of the residual should be constructed using the statistics of the snapshot attractor attractor. 
%
\begin{equation} \begin{aligned}
\label{eq:da2}
Y_k(t)=\Psi_k(t) -\langle \Psi_k\rangle_0=
%&= \Psi_k(t) -\langle \Psi \rangle_{\rho_\varepsilon^t}+\langle \Psi \rangle_{\rho_\varepsilon^t} - \langle \Psi_k\rangle_0 \\
%&=
\sum_{p=1}^M\tilde{X}_k^p(t) +\mathcal{R}_k(t), %\quad k=1,\ldots,N,
\end{aligned}\end{equation} 
where 
%$\langle \cdot \rangle_0$
%denotes the (unperturbed) background climatology,  
the terms
$\tilde{X}_k^p(t)=\varepsilon_p  \left(g_{p} \bullet \GGG_{p,k} \right) (t)$ %,
%\ee
account for the forced variability, and
$\mathcal{R}_k(t)=\Psi_k(t) -\langle \Psi \rangle_{\rho_\varepsilon^t}$ is a random vector whose correlations are {\mk governed by} the {\mk probability distribution} $\rho_\varepsilon^t$ {\mk solving the FPE associated with Eq.~\eqref{eq:sto ode 2}.} %When $\Sigma=0$ and the time-dependent forcing in the drift terms are non-vanishing, this quasi-equilibrium is carried by the system's pullback attractor at time $t$ \cite{Chekroun2011,CLR13,CGN17} also known as the snapshot attractor \cite{TelJSP,Tel2020}. 
%Note that, following \cite{LucariniWouters2017}, the difference between correlation properties of the unperturbed and perturbed model is to a first order linear with the acting forcing. Hence, in principle, one should describe the correlation properties of the error term $\mathcal{R}_k$  by using $\Sigma_\beta=\Sigma+\sum_{p=1}^M\tilde{Z}_k^p\beta_p$, where the $\tilde{Z}$ are estimates of the fingerprints of how climate change impacts the correlation matrix $\Sigma$.

Equation \eqref{eq:da2} is %already 
cast into a form that is very close to the usual mathematical formulation of optimal fingerprinting for climate change given in Eq.~\eqref{eq:da3}. 
\begin{comment}
where the idea is to find the optimal solution to the problem 
\begin{align}
\label{eq:da3}
Y_k&=\sum_{p=1}^M\tilde{X}_k^p\beta_p+\mathcal{R}_k, \quad k=1,\ldots,N\\
\tilde{X}_k^p&={X}_k^p+\mathcal{Q}_k^{p}
\end{align}
whereby a vector describing the observed climate change with components $Y_k$ is modelled as a linear combination of $M$ regressors or fingerprints, i.e. externally forced signals $\tilde{X}_k^p$ associated with $M$ different forcing, plus a vector describing the natural variability of the system \cite{Hasselmann1993b,Hegerl1996,Hasselmann1997,Allen1999,Allen2003}. The $p^{th}$ fingerprint $\tilde{X}_k^p$ is obtained by merging data obtained from several climate models runs, all targeted to the $p^{th}$ considered forcing, e.g. by performing ensemble averaging. Hence, what we can practically have access to is its approximation ${X}_k^p$, whereby the difference $\mathcal{Q}_k^{p}$ with respect to the true value is associated with our incomplete sampling of the model response and, possible, with model error. Note that, in many applications, information coming from different climate models is bundled together \cite{Hegerl2011}. Following \cite{Hannart2014}, the goal is to perform an optimal inference of the regression coefficients $\beta_j$, $j=1,\ldots,p$ given the uncertainties associated with the terms $\mathcal{R}_k$ and $\mathcal{Q}_k^p$. 
\end{comment}
%Clearly, according to Eq.  \ref{eq:da2}, 
Response theory indicates that if we use the forced run of a model to perform detection and attribution of climate change as simulated by the same model, and if we are in the linear regime of response, all the $\beta_p$'s should be unitary, apart from uncertainty. %But there is a gap between climate models and the real world: hence, one speaks of detection of climate change for the $p^{th}$ fingerprint is the confidence interval of $\beta_p$ does not intersect zero and includes positive values, and attribution of climate change if such confidence interval includes the value one. The procedure is truly successful if the confidence intervals for the $\beta_p$'s are not too spread out. 
We stress that the linear response theory indicates that the optimal fingerprinting procedure could be applied seamlessly for different time horizons of the climate change signal and for suitably linearly filtered signals (e.g. considering time averages).  This suggests that one should perform the optimal fingerprinting for different time horizons at the same time, and check the consistency of the obtained results (in terms of confidence intervals for the $\beta$'s) across the time of the hindcast. Additionally, the fact that linear response theory applies for a large class of forcings and can even be adapted for studying extremes \cite{LKFW14} explains why optimal fingerprinting finds such a broad range of applications.

The term $\mathcal{R}_k(t)$ in Eq.~\eqref{eq:da2} is not associated with the variability of the unperturbed climate---compare with Eq.~\eqref{eq:da3}---but {\mk rather is tied to the system's variability encoded by the probability distribution} $\rho_\epsilon^t$; see {\mk also} discussions on time-dependent {\mk probability measures and pullback attractors} in \cite{Chekroun2011,CLR13,CGN17,TelJSP,Tel2020,Chekroun_al22SciAdv}. 
%%%%MC-->VL: I MAINTAIN the "ALSO" here!! Time-dependent measures supported by the pullback attractor ARE NOT this \rho_\epsilon^t as the latter solves a FKPE with a diffusion operator. They coincide ONLY when the noise=0.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
{\mk Such remarks allow us to point out} that the classical formulation of optimal fingerprinting lacks {\mk the proper framework to account for changes in variability due to} climate change. 

%Equation \ref{GreenH} shows that any Green function is written as a sum of exponentials (times polynomials in the case of degeneracies) controlled by constants (the $\lambda_j's$) that depend uniquely on the background dynamics.  If $\lambda_j$ is real, it describes a decay rate and $-1/\lambda_j$ is the characteristic time scale of the acting feedback. If $\lambda_j$ is complex, its imaginary part defines the frequency of oscillation of the mode, whose decaying rate is given by the real part of $\lambda_j$. Such $\lambda$'s provide a  generalization of the classical concept of climatic feedback \cite{Peixoto1992}. 

The expression for the Green function given in Eq.~\eqref{GreenH} provides useful information for better understanding the robustness of the optimal fingerprinting method. The model error manifests itself in the difference between the spectrum of eigenvalues (and {\mk eigenfunctions}) of the Koopman operator of the ``real'' climate and that of the model used for constructing the fingerprints. Additionally, different climate models will in general feature different Koopman modes and associated eigenvalues. Hence, constructing fingerprints by bundling together information derived from different models seems not so promising in terms of reducing model error.

%From the discussion following Eq.~\eqref{GreenH}, 
It is also clear that if only one between the actual climate system and the model used for optimal fingerprinting are close to a tipping point, one expects  major uncertainties and biases because of the qualitative mismatch between the leading $j=1$ term of all the involved Green functions, and, hence, between the model fingerprints and the actual climatic response to the considered forcings. This becomes even more critical if more models are used for estimating of the fingerprints, because  heavily spurious information could be could added. %, leading to potentially uncontrollable errors. 


\begin{comment}
Hannart et al. \cite{Hannart2014} provides a rather clear and informative summary of both the basic aspects of the more advanced developments of optimal fingerprinting methods. Usually the vectors column errors $\mathcal{R}_k$ and $\mathcal{Q}_k^p$, where $k=1,\ldots,N$ and  $p=1,\ldots,M$ are modelled as independent, normally distributed stochastic vectors with zero mean and covariance matrices $\Sigma$ and $\Omega_p$, $p=1,\ldots,M$, respectively. 

The matrix $\Sigma$ is constructed taking into account the correlations of the climatic variables in the unperturbed climate. Instead, putting aside for the moment the use of a Gaussian approximation, the theory of linear response imposes that the statistical properties of the residual should be constructed using the statistics of the snapshot attractor attractor. Note that, following \cite{LucariniWouters2017}, the difference between correlation properties of the unperturbed and forced model is to a first order linear with the acting forcing. Hence, the optimization procedure described in Eq. \ref{eq:da3} neglects to consider the forced change in the variability of the system, thus effectively imposing a truncation. In principle, one should describe the correlation properties of the error term $\mathcal{R}_k$  by using $\Sigma_\beta=\Sigma+\sum_{p=1}^M\tilde{Z}_k^p\beta_p$, where the $\tilde{Z}$ are estimates of the fingerprints of how climate change impacts the correlation matrix $\Sigma$.

A simplified version of the theory above assumes $\Omega_p=0$, $p=1,\ldots,M$ \cite{Allen1999}. In this case, via linear algebra one derives a relatively simple expression for the best estimates for the $\beta$'s and their  uncertainties. As a next step, if one assumes that the natural variability simulated by the climate models is the same as in the observations and one estimates  $\tilde{X}^p_k$ is the average of $L$ runs from a single climate model under the $p^{th}$ forcing, then, under the approximation above, one gets  $\Omega_p = \Sigma/L$ \cite{Allen2003}. Neglecting the difference between the variability of the system in the unforced vs. forced scenario and using the response theory framework discussed above, the latter statement can be justified by considering that the actual response signals are ergodic averages. Hence, by the central limit theorem, their uncertainty decreases with the inverse of the number of ensemble members used for the estimating them. More generally, one can define $\Omega_p = \Sigma/L +\Lambda$, where $\Lambda$ is the covariance associated with the model error. Using these more general formulations, the optimization problem becomes more difficult yet manageable; see discussion in \cite{Hannart2014}.

\end{comment}

%Instead, putting aside for the moment the use of a Gaussian approximation, the theory of linear response imposes that the statistical properties of the residual should be constructed using the statistics of the snapshot attractor attractor. Note that, following \cite{LucariniWouters2017}, the difference between correlation properties of the unperturbed and forced model is to a first order linear with the acting forcing. Hence, iIn principle, one should describe the correlation properties of the error term $\mathcal{R}_k$  by using $\Sigma_\beta=\Sigma+\sum_{p=1}^M\tilde{Z}_k^p\beta_p$, where the $\tilde{Z}$ are estimates of the fingerprints of how climate change impacts the correlation matrix $\Sigma$.

%Neglecting the difference between the variability of the system in the unforced vs. forced scenario and using the response theory framework discussed above, the latter statement can be justified by considering that the actual response signals are ergodic averages. Hence, by the central limit theorem, their uncertainty decreases with the inverse of the number of ensemble members used for the estimating them. More generally, one can define $\Omega_p = \Sigma/L +\Lambda$, where $\Lambda$ is the covariance associated with the model error. Using these more general formulations, the optimization problem becomes more difficult yet manageable; see discussion in \cite{Hannart2014}.


%\section{Conclusions}\label{conclusions}

\section{Discussion}\label{conclusions}
The Hasselmann program has had a great influence in the modern development of climate science, both regarding its everyday practice and its more foundational aspects. The fundamental idea boils down to treating noise not like a nuisance one needs to filter out to gather useful information, but rather as a key aspect of the climate system one needs to fully explore and appreciate in order to further its understanding and to link model output and observational data. This is key for making progress in detecting and attributing the climate change signals at different spatial and temporal scales. 

The emphasis on the role of noise in creating - somewhat counterintuitively - meaningful signal at lower frequencies has led to fundamental discoveries like in the case of the mechanism of stochastic resonance, which stemmed as a direct application of Hasselmann paradigm in a climatic context \cite{Benzi1981,Nicolis1981,Benzi1982,Nicolis1982} but has since had huge success in a plethora of other research areas \cite{gammaitoni1998}.  Another important are of application of Hasselmann paradigm deals with one of the age-old problems of dynamical meteorology: the  fast atmospheric processes due to baroclinic disturbances have been interpreted as acting as effective noise responsible for the low-frequency variability of the mid-latitudes due with the transitions betweeen competing regimes of circulations, mainly associated with zonal flow and blockings, respectively \cite{Charney1979,Benzi1986,Benzi1989,Kimoto1993a,Itoh.Kimoto.1996}.  More recently, the stochastic formulation of climate dynamics, taking advantage of Fredilin-Wentzell theory of noise-induced escapes from attractors \cite{freidlin1998} and of large deviation theory \cite{T09}, has been instrumental for developing a theory of metastability for geophysical flows \cite{Bouchet2012,Herbert2015} and for the climate system \cite{LucariniBodai2019PRL,LucariniBodai2020,Margazoglou2021}. We also remark that more general classes of noise laws - specifically $\alpha$-stable L\'evy processes - are sometimes invoked for studying climatic transitions where sudden jumps between competing states are observed \cite{Ditlevsen1999,Gottwald2021,LucariniSM2022}. For reasons of space and internal coherence, we have chosen not to cover these important research areas in this review.

The Hasselmann program, by construction, leaves out the problem of finding the root causes of the noise that impacts the slow climatic variables In this sense, it can be seen as proposing a heuristic theory of climate. As well known, the noise comes from the fast fluid dynamical instabilities occurring at different scales, in the atmosphere and in the ocean, leading to chaotic behaviour \cite{Ghil2015,Ghil.2019}. The details of the fast processes, in fact, do matter, exactly because there is no time separation one can use to separate the variables of interest from those one wants to parametrize, so that the kind of parsimony one would derive from the use of homogeneization theory cannot be recovered \cite{pavliotisbook2014}. On the other hand, there is no dichotomy between deterministic behaviour and stochastic representation, because chaos generates stochastic processes. In order to advance in the direction of constructing a theory of climate able to account for variability and response to forcings, and able to provide useful and usable information  to address the climate crisis, there is need to inform the stochastic angle on climate with the key details obtained by a  multiscale analysis of the dynamical processes. This review is a preliminary attempt to go in this direction.





\begin{comment}
\subsection{Role of Feedbacks}

The evolution of observables of the unperturbed system can be described in terms of the linear, infinite dimensional Koopman operator \cite{Mezic2005}. The dominating eigenvectors and corresponding eigenvalues of such an operator can be {\mk constructed} using the so-called {\mk extended} dynamic mode decomposition (EDMD) \cite{williams2015data}, which has established itself as a very powerful methods for studying the variability of complex systems \cite{Schmid2010,Kutz2015,Kutz2016}. As discussed in \cite{Santos2022}, following \cite{Tantet2018,Chekroun_al_RP2}, at practical level it is possible to rewrite the Green functions $\mathcal{G}_{k,p}$ introduced in Eq. \ref{eq:Green} as:
	\begin{equation}
		\GGG^k_{d/s,\Psi}(t) =  \Theta(t) \sum_{j=1}^{M}\sum_{l=1}^{a_j-1} \alpha_j^{l,k,s/d}\frac{1}{l!} e^{\lambda_jt}t^l,\quad \alpha_j^{l,k,s/d}\int\dd\xx \rho_0(\xx) (\LLL^{\ast}_0 - \lambda_j)^l\Pi^{\ast}_j\Psi (\xx)\LLL^k_{1,s/d}(\log(\rho_0(\xx))).\label{GreenH}
	\end{equation}
%where the coefficients $\alpha_j^{(k)}$ are defined as:
%\begin{equation}\label{eq:alphas definition}
%\alpha^{(k),{s/d}}_j=\int\dd\xx \rho_0(\xx) (\LLL^{\ast}_0 - \lambda_j)^k\Pi^{\ast}_j\Psi (\xx)\frac{\LLL^{s/d}_1 \rho_0(\xx)}{\rho_0(\xx)}.
%\end{equation}
where $\Pi^\ast_j$ is the projector of the observable $\Psi$ on the $j^{th}$ Koopman mode and  $\lambda_j$ is the corresponding eigenvalue, ordered according to decreasing real part. The $\alpha$ coefficients  weight the contribution of the various modes of the response for a given combination of observable and forcing. %Note that in Eq. \ref{GreenH} we are neglecting the contribution to the response coming from the essential component of the spectrum of the Koopman operator \cite{Santos2022}. This  is often implicitly assumed when performing dynamic model decomposition.

Equation \ref{GreenH} shows that any Green function is written as a sum of exponentials (times polynomials in the case of degeneracies) controlled by constants (the $\lambda_j's$) that depend uniquely on the background dynamics.  If $\lambda_j$ is real, it describes a decay rate and $-1/\lambda_j$ is the characteristic time scale of the acting feedback. If $\lambda_j$ is complex, its imaginary part defines the frequency of oscillation of the mode, whose decaying rate is given by the real part of $\lambda_j$. Such $\lambda$'s provide a  generalization of the classical concept of climatic feedback \cite{Peixoto1992}. 

The expression for the Green function given in Eq. \ref{GreenH}, which has been recently exploited in a climate modelling context by \cite{Torres2021a,Bastiaansen2021}, along the lines of an earlier intuition by Hasselmann et al. \cite{Hasselmann1993}, provides useful information for better understanding the robustness of the optimal fingerprinting methods.
Clearly there is mismatch between the $\lambda$'s of the real climate system and those of any climate model used to describe it. This is the primary, structural source of model error. Note that different climate models will feature a different spectrum of eigenvalues (and eigenvectors) of the Koopman operator. Hence, it seems extremely hard to justify clamping together fingerprints from different models in the hope of getting a better estimate of the true fingerprints. 

\subsection{Nearing Tipping Points}
The rate of decay of the Green function asymptotically depends on the real part $\gamma$ of the subdominant $\lambda_1$ (it could be two of them  $\lambda_1$ and  $\lambda_2$ if they come in conjugate pairs) is very small. If we assume that say one parameter $\pi$ of our system is such that the spectral gap $\gamma=\mathfrak{Re}(\lambda_1)$ vanishes as $\gamma\rightarrow\gamma_c$, we have that as $\gamma$ nears it critical value $\gamma_c$, any Green function (for all choices of observables and forcings) decays sub-exponentially (unless the corresponding $\alpha's$ vanish). This is one of the manifestations of the critical slowing down, which characterise the proximity of tipping points. Since the total response is obtained by summing over all forcings the convolution of each Green function with the  time modulation of the corresponding forcing, it is clear that the response might diverge \cite{Tantet2018,Chekroun_al_RP2,AshwinJSP,Santos2022}.  

From the discussion following Eq. \ref{GreenH}, it is clear that if only one between the actual climate system and the model used for optimal fingerprinting are close to a tipping point, the optimal fingerprinting strategy is deemed to experience major uncertainties and biases because there would be a qualitative mismatch between the leading $j=1$ term of all the involved Green functions. The situations becomes even more critical if one includes multiple models in the estimates of the fingerprints, because  heavily spurious information could be could added to the procedure, leading to potentially uncontrollable errors. 

\section{Conclusions}
The strategy of optimal fingerprinting  has enjoyed enormous success in the climate scientific community and has had a key importance in convincing people well beyond science that climate change is not only real but that we as humans are responsible for it. Optimal fingerprinting methods have recently been criticised as it has been suggested that uncertainties in the inference are sometimes underestimated \cite{Li2021}, or, more radically, on the basis that the statistical foundation of the procedure are not very solid \cite{McKitrick2022}; see also discussion in \cite{Chen2022}. By looking at climate change  through the lens of linear response theory, we have shown here how to critically appraise the optimal fingerprinting method. We have been able to derive the fundamental equations and explain its terms, hence providing dynamical support to an otherwise eminently statistical procedure. The attribution is perfect in the perfect model scenario and under the hypothesis that linearity applies regarding the impact of the various forcings. We have better clarified the source of uncertainties in the fingerprinting procedure, and explained that the correlation matrix describing the uncertainties due to climate variability should be cast in terms of the properties of the snapshot attractor of the perturbed climate, rather than of the attractor of the unperturbed climate. Response formulas, when cast in the functional form suggested by the spectral theorem that takes into account the Koopman modes of the unperturbed system, indicate why merging information coming from different climate models to produce estimates of the fingerprints is a dangerous operation that can lead to potentially uncontrollable errors. Instead, merging data from different runs of the same model follow exactly the mathematical procedure behind the construction of response formulas and seems exactly the way to go. Finally, we have clarified that near tipping points the optimal fingerprinting methods might be prone to large bias and/or uncertainty, as a result of the model error.  
\end{comment}
\begin{comment}
We can learn more about such critical behaviour by taking the Fourier transform of the Green function given in Eq. \ref{eq:Green}):

\begin{align}\label{eq:susceptibility transform}
\mathfrak{F}\left[\GGG \right](\omega) = \sum_{j=1}^{M}\sum_{k=1}^{a_j-1} \alpha_j^{(k)}\frac{1}{k!}\mathfrak{F} \left[  \Theta e^{\lambda_j \circ }\circ^k \right](\omega)=\sum_{j=1}^{M}\sum_{k=1}^{a_j-1} \frac{\alpha_j^{(k)}}{\lp i\omega - \lambda_j \rp^{k+1}}.
\end{align} 
The poles of the susceptibility are located at $\omega= -i\lambda_j$. 
Equation \eqref{eq:susceptibility transform} implies the existence of resonances in the response for real frequencies $\omega=\mathfrak{Im}(\lambda_j)$, $j=1,\ldots,M$. Neglecting the possible existence of nonunitary algebraic multiplicities, the susceptibility at the resonance $j$ is proportional to $1/\mathfrak{Re}(\lambda_j)$. Hence, as $\gamma\rightarrow\gamma_c$, the susceptibility for $\omega=\mathfrak{Im}(\lambda_1)$ diverges, thus implying a breakdown of the response operator. If at criticality $\mathfrak{Im}(\lambda_1)=0$, the static response of the system explodes. indicating a saddle-node-like bifurcation phenomenon. If, instead, $\mathfrak{Im}(\lambda_1)\neq0$, we face an oscillatory unstable phenomenon that is reminiscent of a Hopf bifurcation \cite{Chekroun_al_RP2}.
\end{comment}

\section*{Acknowledgements}
VL acknowledges the support received by the European Union's Horizon 2020 research and innovation program through the projects TiPES (Grant Agreement No. 820970) and CriticalEarth (Grant Agreement No. 956170) and by the EPSRC through the Grant EP/T018178/1. MDC acknowledges the European Research Council  under the European Union's Horizon 2020 research and innovation program (grant no.~810370) and the Ben May Center grant for theoretical and/or computational research. {\mk This work has been also partially supported by the Office of Naval Research (ONR) Multidisciplinary University Research Initiative (MURI) grant N00014-20-1-2023.}
Finally, the authors are grateful to many close collaborators over the years without whom this review would have not been possible: Richard Blender, Tamas Bodai, Niklas Boers, Henk Dijkstra, B\'ereng\`ere Dubrulle, Davide Faranda, Klaus Fraedrich, Vera Melinda Galfi, Giovanni Gallavotti, {\mk Nathan Glatt-Holtz, Andrey Gritsun, Anna von der Heydt,  Dmitri Kondrashov, Ilan Koren, Honghu Liu, Frank Lunkeit, David Neelin, Greg Pavliotis, C\'ecile Penland, Francesco Ragone, Lionel Roques, Jean Roux, Manuel Santos-Guti\'errez, Eric Simonnet, Antonio Speranza, Kaushik Srinivisan, Alexis Tantet, Stephane Vannitsem, Shouhong Wang, Jeroen Wouters, Niccol\'o Zagli, with a special gratitude expressed to {\mk Alexandre Chorin}, Michael Ghil, James C.~McWilliams, David Ruelle, and Roger Temam} for their {\mk invaluable} guidance and inspirational works.
%%%%I had many discussions with Alexandre Chorin in the past. 



%\bibliographystyle{aipnum4-1}
%\bibliography{tesis_cleaned,Burgers_bib2} 
%\bibliographystyle{ieeetr}

\begin{thebibliography}{100}

\bibitem{Peixoto1992}
J.~P. Peixoto and A.~H. Oort, {\em {Physics of Climate}}.
\newblock New York: AIP Press, 1992.

\bibitem{Lucarini.ea.2014}
V.~Lucarini, R.~Blender, C.~Herbert, F.~Ragone, S.~Pascale, and J.~Wouters,
  ``{Mathematical and physical ideas for climate science},'' {\em Rev.
  Geophys.}, vol.~52, no.~4, pp.~809--859, 2014.

\bibitem{Mitchell1976}
J.~Mitchell, ``An overview of climatic variability and its causal mechanisms,''
  {\em Quaternary Research}, vol.~6, no.~4, pp.~481--493, 1976.

\bibitem{Ghil.2019}
M.~Ghil, ``{A century of nonlinearity in the geosciences},'' {\em Earth and
  Space Science}, vol.~6, pp.~1007--1042, 2019.

\bibitem{vonderHeydt2021}
A.~S. {von der Heydt}, P.~Ashwin, C.~D. Camp, M.~Crucifix, H.~A. Dijkstra,
  P.~Ditlevsen, and T.~M. Lenton, ``Quantification and interpretation of the
  climate variability record,'' {\em Global and Planetary Change}, vol.~197,
  p.~103399, 2021.

\bibitem{GhilLucarini2020}
M.~Ghil and V.~Lucarini, ``{The physics of climate variability and climate
  change},'' {\em Reviews of Modern Physics}, 2020.

\bibitem{Ghil2015}
M.~Ghil, ``{A mathematical theory of climate sensitivity or, How to deal with
  both anthropogenic forcing and natural variability?},'' in {\em Climate
  Change : Multidecadal and Beyond} (C.~P. Chang, M.~Ghil, M.~Latif, and J.~M.
  Wallace, eds.), pp.~31--51, World Scientific Publishing Co./Imperial College
  Press, 2015.

\bibitem{IPCC2022}
IPCC, {\em Climate Change 2021: The Physical Science Basis. Contribution of
  Working Group I to the Sixth Assessment Report of the Intergovernmental Panel
  on Climate Change}, vol.~In Press.
\newblock Cambridge, United Kingdom and New York, NY, USA: Cambridge University
  Press, 2021.

\bibitem{IPCC12}
IPCC, {\em {Managing the Risks of Extreme Events and Disasters to Advance
  Climate Change Adaptation. A Special Report of Working Groups I and II of the
  Intergovernmental Panel on Climate Change}}.
\newblock Cambridge and New York: Cambridge University Press, 2012.

\bibitem{Lenton.tip.08}
T.~Lenton, H.~Held, E.~Kriegler, J.~Hall, W.~Lucht, S.~Rahmstorf, and
  H.~Schellnhuber, ``{Tipping elements in the {\{}Earth's climate
  system{\}}},'' {\em Proc. Natl. Acad. Sci. USA}, vol.~105, pp.~1786--1793,
  2008.

\bibitem{Ashwin2012}
P.~Ashwin, S.~Wieczorek, R.~Vitolo, and P.~Cox, ``{Tipping points in open
  systems: Bifurcation, noise-induced and rate-dependent examples in the
  climate system},'' {\em Philosophical Transactions of the Royal Society A:
  Mathematical, Physical and Engineering Sciences}, vol.~370, no.~1962,
  pp.~1166--1184, 2012.

\bibitem{Ripple2021}
W.~J. Ripple, C.~Wolf, T.~M. Newsome, J.~W. Gregg, T.~M. Lenton, I.~Palomo,
  J.~A.~J. Eikelboom, B.~E. Law, S.~Huq, P.~B. Duffy, and J.~Rockstr\"{o}m,
  ``{World Scientists' Warning of a Climate Emergency 2021},'' {\em
  BioScience}, vol.~71, pp.~894--898, 07 2021.

\bibitem{Imkeller2001}
P.~Imkeller and J.~S. von Storch, {\em Stochastic Climate Models}.
\newblock Basel: Birkhauser, 2001.

\bibitem{Hasselmann1976}
K.~Hasselmann, ``{Stochastic climate models Part I. Theory},'' {\em Tellus},
  vol.~28, no.~6, pp.~473--485, 1976.

\bibitem{Arnold2001}
L.~Arnold, ``Hasselmann's program revisited: the analysis of stochasticity in
  deterministic climate models,'' in {\em Stochastic Climate Models}
  (P.~Imkeller and J.-S. von Storch, eds.), (Basel), pp.~141--157,
  Birkh{\"a}user Basel, 2001.

\bibitem{beck1990brownian}
C.~Beck, ``Brownian motion from deterministic dynamics,'' {\em Physica A:
  Statistical Mechanics and its Applications}, vol.~169, no.~2, pp.~324--336,
  1990.

\bibitem{just2001stochastic}
W.~Just, H.~Kantz, C.~R{\"o}denbeck, and M.~Helm, ``Stochastic modelling:
  replacing fast degrees of freedom by noise,'' {\em Journal of Physics A:
  Mathematical and General}, vol.~34, no.~15, p.~3199, 2001.

\bibitem{majda2001mathematical}
A.~J. Majda, I.~Timofeyev, and E.~Vanden-Eijnden, ``A mathematical framework
  for stochastic climate models,'' {\em Comm.~Pure Appl. Math}, vol.~54, no.~8,
  pp.~891--974, 2001.

\bibitem{Pavliotis2008}
G.~A. Pavliotis and A.~M. Stuart, {\em {Multiscale Methods}}.
\newblock New York: Springer, 2008.

\bibitem{Gottwald2013}
G.~A. Gottwald and I.~Melbourne, ``{Homogenization for deterministic maps and
  multiplicative noise},'' {\em Proceedings of the Royal Society A:
  Mathematical, Physical and Engineering Sciences}, vol.~469, no.~2156,
  p.~20130201, 2013.

\bibitem{khas1963principle}
R.~Khasminsky, ``{Principle of averaging for parabolic and elliptic
  differential equations and for Markov processes with small diffusion},'' {\em
  Theory of Probability \& Its Applications}, vol.~8, no.~1, pp.~1--21, 1963.

\bibitem{kurtz1973limit}
T.~Kurtz, ``A limit theorem for perturbed operator semigroups with applications
  to random evolutions,'' {\em Journal of Functional Analysis}, vol.~12, no.~1,
  pp.~55--67, 1973.

\bibitem{Papanicolaou1974}
G.~C. Papanicolaou and W.~Kohler, ``Asymptotic theory of mixing stochastic
  ordinary differential equations,'' {\em Communications on Pure and Applied
  Mathematics}, vol.~27, no.~5, pp.~641--668, 1974.

\bibitem{majda2003systematic}
A.~J. Majda, I.~Timofeyev, and E.~Vanden-Eijnden, ``Systematic strategies for
  stochastic mode reduction in climate,'' {\em J. Atmos. Sci.}, vol.~60,
  no.~14, pp.~1705--1722, 2003.

\bibitem{chekroun2022transitions}
M.~Chekroun, H.~Dijkstra, T.~{\c{S}}eng{\"u}l, and S.~Wang, ``Transitions of
  zonal flows in a two-layer quasi-geostrophic ocean model,'' {\em Nonlinear
  Dynamics}, vol.~109, no.~3, pp.~1887--1904, 2022.

\bibitem{GhilChildress1987}
M.~Ghil and S.~Childress, {\em {Topics in Geophysical Fluid Dynamics:
  Atmospheric Dynamics, Dynamo Theory, and Climate Dynamics}}.
\newblock Berlin: Springer-Verlag, 1987.

\bibitem{dijkstra2005nonlinear}
H.~Dijkstra, {\em {Nonlinear physical oceanography: A dynamical systems
  approach to the large-scale ocean circulation and El Ni{\~n}o}}, vol.~532.
\newblock Springer, 2005.

\bibitem{DG05}
H.~A. Dijkstra and M.~Ghil, ``{Low-frequency variability of the large-scale
  ocean circulation: A dynamical systems approach},'' {\em Reviews of
  Geophysics}, vol.~43, no.~3, p.~RG3002, 2005.

\bibitem{CLW15_vol1}
M.~D. Chekroun, H.~Liu, and S.~Wang, {\em {Approximation of Stochastic
  Invariant Manifolds: Stochastic Manifolds for Nonlinear SPDEs I}}.
\newblock New York: Springer Briefs in Mathematics, Springer, 2015.

\bibitem{CLW15_vol2}
M.~D. Chekroun, H.~Liu, and S.~Wang, {\em {Stochastic Parameterizing Manifolds
  and Non-Markovian Reduced Equations: Stochastic Manifolds for Nonlinear SPDEs
  II}}.
\newblock Springer Briefs in Mathematics, Springer, 2015.

\bibitem{chekroun2023transitions}
M.~Chekroun, H.~Liu, J.~McWilliams, and S.~Wang, ``{Transitions in stochastic
  non-equilibrium systems: Efficient reduction and analysis},'' {\em Journal of
  Differential Equations}, vol.~346, pp.~145--204, 2023.

\bibitem{palmer_stochastic_2009}
T.~N. Palmer and P.~Williams, eds., {\em {Stochastic Physics and Climate
  Modelling}}.
\newblock Cambridge: Cambridge University Press, nov 2009.

\bibitem{Berner2017}
J.~Berner, U.~Achatz, L.~Batt{\'{e}}, L.~Bengtsson, A.~de~la C{\'{a}}mara,
  H.~M. Christensen, M.~Colangeli, D.~R.~B. Coleman, D.~Crommelin, S.~I.
  Dolaptchiev, and C.~L. Franzke, ``{Stochastic parameterization: {\{}Toward a
  new view of weather and climate models{\}}},'' {\em Bulletin of the American
  Meteorological Society}, vol.~98, no.~3, pp.~565--588, 2017.

\bibitem{Maher2021}
N.~Maher, S.~Milinski, and R.~Ludwig, ``Large ensemble climate model
  simulations: introduction, overview, and future prospects for utilising
  multiple types of large ensemble,'' {\em Earth System Dynamics}, vol.~12,
  no.~2, pp.~401--418, 2021.

\bibitem{Chekroun_al_RP2}
M.~Chekroun, A.~Tantet, H.~Dijkstra, and J.~D. Neelin, ``{Ruelle-Pollicott
  Resonances of Stochastic Systems in Reduced State Space. Part I: Theory},''
  {\em J.~Stat.~Phys.}, vol.~179, pp.~1366--1402, 2020.

\bibitem{eckmann_ruelle}
J.-P. Eckmann and D.~Ruelle, ``Ergodic theory of chaos and strange
  attractors,'' {\em Rev. Modern Phys.}, vol.~57, pp.~617--656, 1985.

\bibitem{Bojinski2014}
S.~Bojinski, M.~Verstraete, T.~C. Peterson, C.~Richter, A.~Simmons, and
  M.~Zemp, ``The concept of essential climate variables in support of climate
  research, applications, and policy,'' {\em Bulletin of the American
  Meteorological Society}, vol.~95, no.~9, pp.~1431 -- 1443, 2014.

\bibitem{Eyring2020}
V.~Eyring, L.~Bock, A.~Lauer, M.~Righi, M.~Schlund, B.~Andela, E.~Arnone,
  O.~Bellprat, B.~Br\"otz, L.-P. Caron, N.~Carvalhais, I.~Cionni, N.~Cortesi,
  B.~Crezee, E.~L. Davin, P.~Davini, K.~Debeire, L.~de~Mora, C.~Deser,
  D.~Docquier, P.~Earnshaw, C.~Ehbrecht, B.~K. Gier, N.~Gonzalez-Reviriego,
  P.~Goodman, S.~Hagemann, S.~Hardiman, B.~Hassler, A.~Hunter, C.~Kadow,
  S.~Kindermann, S.~Koirala, N.~Koldunov, Q.~Lejeune, V.~Lembo, T.~Lovato,
  V.~Lucarini, F.~Massonnet, B.~M\"uller, A.~Pandde, N.~P\'erez-Zan\'on,
  A.~Phillips, V.~Predoi, J.~Russell, A.~Sellar, F.~Serva, T.~Stacke,
  R.~Swaminathan, V.~Torralba, J.~Vegas-Regidor, J.~von Hardenberg, K.~Weigel,
  and K.~Zimmermann, ``Earth system model evaluation tool (esmvaltool) v2.0 --
  an extended set of large-scale diagnostics for quasi-operational and
  comprehensive evaluation of earth system models in cmip,'' {\em Geoscientific
  Model Development}, vol.~13, no.~7, pp.~3383--3438, 2020.

\bibitem{Tel2020}
T.~T{\'e}l, T.~B{\'o}dai, G.~Dr{\'o}tos, T.~Haszpra, M.~Herein, B.~Kasz{\'a}s,
  and M.~Vincze, ``The theory of parallel climate realizations,'' {\em Journal
  of Statistical Physics}, vol.~179, no.~5, pp.~1496--1530, 2020.

\bibitem{Maier-Reimer1987}
E.~Maier-Reimer and K.~Hasselmann, ``{Transport and storage of CO2 in the
  ocean---an inorganic ocean-circulation carbon cycle model},'' {\em Climate
  Dynamics}, vol.~2, no.~2, pp.~63--90, 1987.

\bibitem{Hasselmann1993}
K.~Hasselmann, R.~Sausen, E.~Maier-Reimer, and R.~Voss, ``On the cold start
  problem in transient simulations with coupled atmosphere-ocean models,'' {\em
  Climate Dynamics}, vol.~9, no.~2, pp.~53--61, 1993.

\bibitem{Leith1975}
C.~Leith, ``{Climate response and fluctuation dissipation},'' {\em {Journal of
  the Atmospheric Sciences}}, vol.~{32}, no.~{10}, pp.~{2022--2026}, {1975}.

\bibitem{kubo1966}
R.~Kubo, ``{The fluctuation-dissipation theorem},'' {\em Reports on Progress in
  Physics}, vol.~29, no.~1, pp.~255--284, 1966.

\bibitem{Hasselmann1993b}
K.~Hasselmann, ``Optimal fingerprints for the detection of time-dependent
  climate change,'' {\em Journal of Climate}, vol.~6, no.~10, pp.~1957 -- 1971,
  1993.

\bibitem{Hegerl1996}
G.~C. Hegerl, H.~von Storch, K.~Hasselmann, B.~D. Santer, U.~Cubasch, and P.~D.
  Jones, ``Detecting greenhouse-gas-induced climate change with an optimal
  fingerprint method,'' {\em Journal of Climate}, vol.~9, no.~10, pp.~2281 --
  2306, 1996.

\bibitem{Hasselmann1997}
K.~Hasselmann, ``Multi-pattern fingerprint method for detection and attribution
  of climate change,'' {\em Climate Dynamics}, vol.~13, no.~9, pp.~601--611,
  1997.

\bibitem{Bindoff2013}
N.~L. Bindoff, P.~A. Stott, K.~M. AchutaRao, M.~R. Allen, N.~Gillett,
  D.~Gutzler, K.~Hansingo, G.~Hegerl, Y.~Hu, S.~Jain, I.~I. Mokhov,
  J.~Overland, J.~Perlwitz, R.~Sebbari, and X.~Zhang, {\em Detection and
  attribution of climate change: From global to regional}, pp.~867--952.
\newblock Cambridge, UK: Cambridge University Press, 2013.

\bibitem{Hannart2014}
A.~Hannart, A.~Ribes, and P.~Naveau, ``Optimal fingerprinting under multiple
  sources of uncertainty,'' {\em Geophysical Research Letters}, vol.~41, no.~4,
  pp.~1261--1268, 2014.

\bibitem{Allen1999}
M.~Allen and S.~Tett, ``Checking for model consistency in optimal
  fingerprinting,'' {\em Climate Dynamics}, vol.~15, pp.~419--434, 06 1999.

\bibitem{Allen2003}
M.~Allen and S.~Tett, ``Estimating signal amplitudes in optimal fingerprinting,
  part i: theory,'' {\em Climate Dynamics}, vol.~21, no.~5, pp.~477--491, 2003.

\bibitem{hegerl2011use}
G.~Hegerl and F.~Zwiers, ``Use of models in detection and attribution of
  climate change,'' {\em Wiley interdisciplinary reviews: climate change},
  vol.~2, no.~4, pp.~570--591, 2011.

\bibitem{Li2021}
Y.~Li, K.~Chen, J.~Yan, and X.~Zhang, ``Uncertainty in optimal fingerprinting
  is underestimated,'' {\em Environmental Research Letters}, vol.~16,
  p.~084043, aug 2021.

\bibitem{McKitrick2022}
R.~McKitrick, ``Checking for model consistency in optimal fingerprinting: a
  comment,'' {\em Climate Dynamics}, vol.~58, no.~1, pp.~405--411, 2022.

\bibitem{Chen2022}
H.~Chen, S.~X. Chen, and M.~Mu, ``A review on the optimal fingerprinting
  approach in climate change studies,'' 2022.

\bibitem{mori_transport_1965}
H.~Mori, ``{Transport, Collective Motion, and Brownian Motion},'' {\em Progress
  of Theoretical Physics}, vol.~33, pp.~423--455, mar 1965.

\bibitem{zwanzig_memory_1961}
R.~Zwanzig, ``{Memory effects in irreversible thermodynamics},'' {\em Physical
  Review}, vol.~124, no.~4, pp.~983--992, 1961.

\bibitem{Chorin_al02}
A.~J. Chorin, O.~H. Hald, and R.~Kupferman, ``Optimal prediction with memory,''
  {\em Physica D}, vol.~166, no.~3, pp.~239--257, 2002.

\bibitem{GKS04}
D.~Givon, R.~Kupferman, and A.~Stuart, ``Extracting macroscopic dynamics: model
  problems and algorithms,'' {\em Nonlinearity}, vol.~17, no.~6, pp.~R55--R127,
  2004.

\bibitem{ruellegeneral1998}
D.~Ruelle, ``{General linear response formula in statistical mechanics, and the
  fluctuation-dissipation theorem far from equilibrium},'' {\em Physics
  Letters, Section A: General, Atomic and Solid State Physics}, vol.~245,
  no.~3-4, pp.~220--224, 1998.

\bibitem{ruelle2009}
D.~Ruelle, ``{A review of linear response theory for general differentiable
  dynamical systems},'' {\em Nonlinearity}, vol.~22, no.~4, pp.~855--870, 2009.

\bibitem{Hairer2010}
M.~Hairer and A.~J. Majda, ``{A simple framework to justify linear response
  theory},'' {\em Nonlinearity}, vol.~23, no.~4, pp.~909--922, 2010.

\bibitem{Baiesi2013}
M.~Baiesi and C.~Maes, ``An update on the nonequilibrium linear response,''
  {\em New Journal of Physics}, vol.~15, p.~013004, jan 2013.

\bibitem{Sarracino2019}
A.~Sarracino and A.~Vulpiani, ``On the fluctuation-dissipation relation in
  non-equilibrium and non-hamiltonian systems,'' {\em Chaos}, vol.~29,
  p.~083132, 2019.

\bibitem{Gottwald2020}
G.~A. Gottwald, ``{Introduction to Focus Issue: Linear response theory:
  Potentials and limits},'' {\em Chaos: An Interdisciplinary Journal of
  Nonlinear Science}, vol.~30, no.~2, p.~20401, 2020.

\bibitem{Santos2022}
M.~Santos~Guti{\'e}rrez and V.~Lucarini, ``On some aspects of the response to
  stochastic and deterministic forcings,'' {\em Journal of Physics A:
  Mathematical and Theoretical}, vol.~55, p.~425002, oct 2022.

\bibitem{ragone2016}
F.~Ragone, V.~Lucarini, and F.~Lunkeit, ``{A new framework for climate
  sensitivity and prediction: a modelling perspective},'' {\em Climate
  Dynamics}, vol.~46, no.~5, pp.~1459--1471, 2016.

\bibitem{Lucarini2017}
V.~Lucarini, F.~Ragone, and F.~Lunkeit, ``{Predicting Climate Change Using
  Response Theory: Global Averages and Spatial Patterns},'' {\em Journal of
  Statistical Physics}, vol.~166, pp.~1036--1064, feb 2017.

\bibitem{Aengenheyster2018}
M.~Aengenheyster, Q.~Y. Feng, F.~van~der Ploeg, and H.~A. Dijkstra, ``{The
  point of no return for climate action: effects of climate uncertainty and
  risk tolerance},'' {\em Earth System Dynamics}, vol.~9, no.~3,
  pp.~1085--1095, 2018.

\bibitem{Lembo2020}
V.~Lembo, V.~Lucarini, and F.~Ragone, ``{Beyond Forcing Scenarios: Predicting
  Climate Change through Response Operators in a Coupled General Circulation
  Model},'' {\em Scientific Reports}, vol.~10, no.~1, p.~8668, 2020.

\bibitem{Mezic2005}
I.~Mezi{\'c}, ``Spectral properties of dynamical systems, model reduction and
  decompositions,'' {\em Nonlinear Dynamics}, vol.~41, no.~1, pp.~309--325,
  2005.

\bibitem{Budinisic2012}
M.~Budi\v{s}i\'c, R.~Mohr, and I.~Mezi{\'{c}}, ``Applied koopmanism,'' {\em
  Chaos}, vol.~22, no.~4, p.~047510, 2012.

\bibitem{Kutz2016}
J.~Kutz, S.~Brunton, B.~Brunton, and J.~Proctor, {\em Dynamic Mode
  Decomposition: Data-Driven Modeling of Complex Systems}.
\newblock Other Titles in Applied Mathematics, Philadelphia: Society for
  Industrial and Applied Mathematics, 2016.

\bibitem{Tantet2018}
A.~Tantet, V.~Lucarini, and H.~A. Dijkstra, ``{Resonances in a Chaotic
  Attractor Crisis of the Lorenz Flow},'' {\em Journal of Statistical Physics},
  vol.~170, no.~3, pp.~584--616, 2018.

\bibitem{CGH12}
M.~D. Chekroun and N.~E. Glatt-Holtz, ``{Invariant measures for dissipative
  dynamical systems: Abstract results and applications},'' {\em Commun. Math.
  Phys.}, vol.~316, pp.~723--761, 2012.

\bibitem{ambrosio2008gradient}
L.~Ambrosio, N.~Gigli, and G.~Savar{\'e}, {\em {Gradient Flows in Metric Spaces
  and in the Space of Probability Measures}}.
\newblock Springer Science \& Business Media, 2008.

\bibitem{miyadera1966perturbation}
I.~Miyadera, ``On perturbation theory for semi-groups of operators,'' {\em
  Tohoku Mathematical Journal, Second Series}, vol.~18, no.~3, pp.~299--310,
  1966.

\bibitem{voigt1977perturbation}
J.~Voigt, ``On the perturbation theory for strongly continuous semigroups,''
  {\em Mathematische Annalen}, vol.~229, no.~2, pp.~163--171, 1977.

\bibitem{engel2000}
K.-J. Engel and R.~Nagel, {\em {One-Parameter Semigroups for Linear Evolution
  Equations}}.
\newblock New York: Springer-Verlag, 2000.

\bibitem{givon2005existence}
D.~Givon, R.~Kupferman, and O.~Hald, ``{Existence proof for orthogonal dynamics
  and the Mori-Zwanzig formalism},'' {\em Israel Journal of Mathematics},
  vol.~145, pp.~221--241, 2005.

\bibitem{pavliotisbook2014}
G.~A. Pavliotis, {\em {Stochastic Processes and Applications}}, vol.~60.
\newblock Springer, New York, 2014.

\bibitem{Chorin_Hald-book}
A.~Chorin and O.~Hald, {\em {Stochastic Tools in Mathematics and Science}}.
\newblock No.~147 in {Surveys and Tutorials in the Applied Mathematical
  Sciences}, Springer New York, 2006.

\bibitem{hijon2010mori}
C.~Hij{\'o}n, P.~Espa{\~n}ol, E.~Vanden-Eijnden, and R.~Delgado-Buscalioni,
  ``Mori--zwanzig formalism as a practical computational tool,'' {\em Faraday
  discussions}, vol.~144, pp.~301--322, 2010.

\bibitem{izvekov2006modeling}
S.~Izvekov and G.~Voth, ``{Modeling real dynamics in the coarse-grained
  representation of condensed phase systems},'' {\em The Journal of Chemical
  Physics}, vol.~125, no.~15, p.~151101, 2006.

\bibitem{chen2014computation}
M.~Chen, X.~Li, and C.~Liu, ``{Computation of the memory functions in the
  generalized Langevin models for collective dynamics of macromolecules},''
  {\em The Journal of Chemical Physics}, vol.~141, no.~6, p.~064112, 2014.

\bibitem{ma2016derivation}
L.~Ma, X.~Li, and C.~Liu, ``{The derivation and approximation of coarse-grained
  dynamics from Langevin dynamics},'' {\em The Journal of chemical physics},
  vol.~145, no.~20, p.~204117, 2016.

\bibitem{chekroun2011predicting}
M.~D. Chekroun, D.~Kondrashov, and M.~Ghil, ``{Predicting stochastic systems by
  noise sampling, and application to the El Ni{\~n}o-Southern Oscillation},''
  {\em Proc. Natl. Acad. Sci. USA}, vol.~108, no.~29, pp.~11766--11771, 2011.

\bibitem{Majda_Harlim2012}
A.~J. Majda and J.~Harlim, ``{Physics constrained nonlinear regression models
  for time series},'' {\em Nonlinearity}, vol.~{26}, no.~{1}, pp.~{201--217},
  2013.

\bibitem{wouters2013multi}
J.~Wouters and V.~Lucarini, ``{Multi-level dynamical systems: Connecting the
  Ruelle response theory and the Mori-Zwanzig approach},'' {\em Journal of
  Statistical Physics}, vol.~151, no.~5, pp.~850--860, 2013.

\bibitem{ghil2015collection}
M.~Ghil, M.~Chekroun, and G.~Stepan, ``{A collection on 'Climate dynamics:
  multiple scales and memory effects'},'' 2015.

\bibitem{MSM2015}
D.~Kondrashov, M.~D. Chekroun, and M.~Ghil, ``{Data-driven non-Markovian
  closure models},'' {\em Physica D.}, vol.~297, pp.~33--55, 2015.

\bibitem{chekroun2017data}
M.~D. Chekroun and D.~Kondrashov, ``Data-adaptive harmonic spectra and
  multilayer {S}tuart-{L}andau models,'' {\em Chaos}, vol.~27, no.~9,
  p.~093110, 2017.

\bibitem{Boers_al17}
N.~Boers, M.~D. Chekroun, H.~Liu, D.~Kondrashov, D.-D. Rousseau, A.~Svensson,
  M.~Bigler, and M.~Ghil, ``{Inverse stochastic-dynamic models for
  high-resolution Greenland ice-core records},'' {\em Earth System Dynamics},
  vol.~8, pp.~1171--1190, 2017.

\bibitem{KCYG_2018_arctic}
D.~Kondrashov, M.~D. Chekroun, X.~Yuan, and M.~Ghil, ``{Data-adaptive harmonic
  decomposition and stochastic modeling of Arctic sea ice},'' in {\em Advances
  in Nonlinear Geosciences} ({A. Tsonis}, ed.), pp.~179--205, Springer, 2018.

\bibitem{falkena2019derivation}
S.~Falkena, C.~Quinn, J.~Sieber, J.~Frank, and H.~Dijkstra, ``{Derivation of
  delay equation climate models using the Mori-Zwanzig formalism},'' {\em
  Proceedings of the Royal Society A}, vol.~475, no.~2227, p.~20190075, 2019.

\bibitem{parish2017dynamic}
E.~J. Parish and K.~Duraisamy, ``{A dynamic subgrid scale model for Large Eddy
  Simulations based on the Mori--Zwanzig formalism},'' {\em Journal of
  Computational Physics}, vol.~349, pp.~154--175, 2017.

\bibitem{parish2017non}
E.~Parish and K.~Duraisamy, ``{Non-Markovian closure models for large eddy
  simulations using the Mori-Zwanzig formalism},'' {\em Physical Review
  Fluids}, vol.~2, no.~1, p.~014604, 2017.

\bibitem{Kondrashov_al2018_QG}
D.~Kondrashov, M.~Chekroun, and P.~Berloff, ``Multiscale {S}tuart-{L}andau
  emulators: {A}pplication to wind-driven ocean gyres,'' {\em Fluids}, vol.~3,
  no.~1, p.~21, 2018.

\bibitem{wang2020recurrent}
Q.~Wang, N.~Ripamonti, and J.~S. Hesthaven, ``{Recurrent neural network closure
  of parametric POD-Galerkin reduced-order models based on the Mori-Zwanzig
  formalism},'' {\em Journal of Computational Physics}, vol.~410, p.~109402,
  2020.

\bibitem{stinis_Higher-order}
P.~Stinis, ``{Higher order Mori-Zwanzig models for the Euler equations},'' {\em
  Multiscale Model. \& Simul.}, vol.~6, no.~3, pp.~741--760, 2007.

\bibitem{li2015incorporation}
Z.~Li, X.~Bian, X.~Li, and G.~Karniadakis, ``{Incorporation of memory effects
  in coarse-grained modeling via the Mori-Zwanzig formalism},'' {\em The
  Journal of Chemical Physics}, vol.~143, no.~24, p.~243128, 2015.

\bibitem{lei2016data}
H.~Lei, N.~Baker, and X.~Li, ``Data-driven parameterization of the generalized
  langevin equation,'' {\em Proceedings of the National Academy of Sciences},
  vol.~113, no.~50, pp.~14183--14188, 2016.

\bibitem{li2017computing}
Z.~Li, H.~Lee, E.~Darve, and G.~Karniadakis, ``{Computing the non-Markovian
  coarse-grained interactions derived from the Mori--Zwanzig formalism in
  molecular systems: application to polymer melts},'' {\em The Journal of
  chemical physics}, vol.~146, no.~1, p.~014104, 2017.

\bibitem{brennan2018data}
C.~Brennan and D.~Venturi, ``Data-driven closures for stochastic dynamical
  systems,'' {\em Journal of Computational Physics}, vol.~372, pp.~281--298,
  2018.

\bibitem{chorin2015discrete}
A.~J. Chorin and F.~Lu, ``Discrete approach to stochastic parametrization and
  dimension reduction in nonlinear dynamics,'' {\em Proc. Natl. Acad. Sci.
  USA}, vol.~112, no.~32, pp.~9804--9809, 2015.

\bibitem{lu2017data}
F.~Lu, K.~K. Lin, and A.~J. Chorin, ``{Data-based stochastic model reduction
  for the Kuramoto-Sivashinsky equation},'' {\em Physica D}, vol.~340,
  pp.~46--57, 2017.

\bibitem{Lin.Lu.2021}
K.~K. Lin and F.~Lu, ``{Data-driven model reduction, Wiener projections, and
  the Koopman-Mori-Zwanzig formalism},'' {\em Journal of Computational
  Physics}, vol.~424, p.~109864, jan 2021.

\bibitem{mori1965continued}
H.~Mori, ``A continued-fraction representation of the time-correlation
  functions,'' {\em Progress of Theoretical Physics}, vol.~34, no.~3,
  pp.~399--416, 1965.

\bibitem{lee1982solutions}
M.~Lee, ``{Solutions of the generalized Langevin equation by a method of
  recurrence relations},'' {\em Physical Review B}, vol.~26, no.~5, p.~2547,
  1982.

\bibitem{florencio1985exact}
J.~Florencio~Jr and M.~H. Lee, ``Exact time evolution of a classical
  harmonic-oscillator chain,'' {\em Physical Review A}, vol.~31, no.~5,
  p.~3231, 1985.

\bibitem{kupferman2004fractional}
R.~Kupferman, ``{Fractional kinetics in Kac--Zwanzig heat bath models},'' {\em
  Journal of Statistical Physics}, vol.~114, pp.~291--326, 2004.

\bibitem{Chorin_al_2002}
A.~J. Chorin, O.~H. Hald, and R.~Kupferman, ``{Optimal prediction with
  memory},'' {\em Physica D: Nonlinear Phenomena}, vol.~166, no.~3-4,
  pp.~239--257, 2002.

\bibitem{chorin2007problem}
A.~Chorin and P.~Stinis, ``Problem reduction, renormalization, and memory,''
  {\em Com. Appl. Math. Comp. Sci.}, vol.~1, no.~1, pp.~1--27, 2007.

\bibitem{Stinis06}
P.~Stinis, ``A comparative study of two stochastic mode reduction methods,''
  {\em Physica D}, vol.~213, no.~2, pp.~197--213, 2006.

\bibitem{gotze1999recent}
W.~G{\"o}tze, ``Recent tests of the mode-coupling theory for glassy dynamics,''
  {\em Journal of Physics: condensed matter}, vol.~11, no.~10A, p.~A1, 1999.

\bibitem{reichman2005mode}
D.~Reichman and P.~Charbonneau, ``Mode-coupling theory,'' {\em Journal of
  Statistical Mechanics: Theory and Experiment}, vol.~2005, no.~05, p.~P05013,
  2005.

\bibitem{darve2009computing}
E.~Darve, J.~Solomon, and A.~Kia, ``{Computing generalized Langevin equations
  and generalized Fokker--Planck equations},'' {\em Proceedings of the National
  Academy of Sciences}, vol.~106, no.~27, pp.~10884--10889, 2009.

\bibitem{stinis2015renormalized}
P.~Stinis, ``{Renormalized Mori-Zwanzig-reduced models for systems without
  scale separation},'' {\em Proceedings of the Royal Society A: Mathematical,
  Physical and Engineering Sciences}, vol.~471, no.~2176, p.~20140446, 2015.

\bibitem{zhu2018estimation}
Y.~Zhu, J.~Dominy, and D.~Venturi, ``{On the estimation of the Mori-Zwanzig
  memory integral},'' {\em Journal of Mathematical Physics}, vol.~59, no.~10,
  p.~103501, 2018.

\bibitem{zhu2018faber}
Y.~Zhu and D.~Venturi, ``{Faber approximation of the Mori--Zwanzig equation},''
  {\em Journal of Computational Physics}, vol.~372, pp.~694--718, 2018.

\bibitem{venturi2014convolutionless}
D.~Venturi and G.~Karniadakis, ``{Convolutionless Nakajima-Zwanzig equations
  for stochastic analysis in nonlinear dynamical systems},'' {\em Proceedings
  of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  vol.~470, no.~2166, p.~20130754, 2014.

\bibitem{wouters2012}
J.~Wouters and V.~Lucarini, ``Disentangling multi-level systems: averaging,
  correlations and memory,'' {\em J. Stat. Mech.}, p.~P03003, 2012.

\bibitem{yoshimoto2013bottom}
Y.~Yoshimoto, I.~Kinefuchi, T.~Mima, A.~Fukushima, T.~Tokumasu, and S.~Takagi,
  ``{Bottom-up construction of interaction models of non-Markovian dissipative
  particle dynamics},'' {\em Physical Review E}, vol.~88, no.~4, p.~043305,
  2013.

\bibitem{Demaeyer2018}
J.~Demaeyer and S.~Vannitsem, ``Comparison of stochastic parameterizations in
  the framework of a coupled ocean--atmosphere model,'' {\em Nonlinear
  Processes in Geophysics}, vol.~25, no.~3, pp.~605--631, 2018.

\bibitem{Vissio2018a}
G.~Vissio and V.~Lucarini, ``{A proof of concept for scale-adaptive
  parametrizations: the case of the Lorenz '96 model},'' {\em Quarterly Journal
  of the Royal Meteorological Society}, vol.~144, no.~710, pp.~63--75, 2018.

\bibitem{hald2007optimal}
O.~H. Hald and P.~Stinis, ``{Optimal prediction and the rate of decay for
  solutions of the Euler equations in two and three dimensions},'' {\em Proc.
  Natl. Acad. Sci. USA}, vol.~104, no.~16, pp.~6527--6532, 2007.

\bibitem{Chek_al11_memo}
M.~D. Chekroun, F.~Di~Plinio, N.~E. Glatt-Holtz, and V.~Pata, ``Asymptotics of
  the {C}oleman-{G}urtin model,'' {\em Discrete Contin. Dyn. Syst. Ser. S},
  vol.~4, no.~2, pp.~351--369, 2011.

\bibitem{chekroun_glatt-holtz}
M.~D. Chekroun and N.~E. Glatt-Holtz, ``Invariant measures for dissipative
  dynamical systems: abstract results and applications,'' {\em Commun. Math.
  Phys.}, vol.~316, no.~3, pp.~723--761, 2012.

\bibitem{kravtsov2005multilevel}
S.~Kravtsov, D.~Kondrashov, and M.~Ghil, ``{Multilevel regression modeling of
  nonlinear processes: Derivation and applications to climatic variability},''
  {\em Journal of Climate}, vol.~18, no.~21, pp.~4404--4424, 2005.

\bibitem{CLM19_closure}
M.~D. Chekroun, H.~Liu, and J.~C. McWilliams, ``{Variational approach to
  closure of nonlinear dynamical systems: Autonomous case},'' {\em J.~Stat.
  Phys.}, vol.~179, pp.~1073--1160, 2020.

\bibitem{fu2020learning}
X.~Fu, L.-B. Chang, and D.~Xiu, ``Learning reduced systems via deep neural
  networks with memory,'' {\em Journal of Machine Learning for Modeling and
  Computing}, vol.~1, no.~2, 2020.

\bibitem{gupta2021neural}
A.~Gupta and P.~F.~J. Lermusiaux, ``Neural closure models for dynamical
  systems,'' {\em Proceedings of the Royal Society A}, vol.~477, no.~2252,
  p.~20201004, 2021.

\bibitem{kraichnan1987eddy}
R.~H. Kraichnan, ``{Eddy viscosity and diffusivity: Exact formulas and
  approximations},'' {\em Complex Systems}, vol.~1, no.~4-6, pp.~805--820,
  1987.

\bibitem{rose1977eddy}
H.~A. Rose, ``Eddy diffusivity, eddy noise and subgrid-scale modelling,'' {\em
  Journal of Fluid Mechanics}, vol.~81, no.~4, pp.~719--734, 1977.

\bibitem{kkg05_enso}
D.~Kondrashov, S.~Kravtsov, A.~W. Robertson, and M.~Ghil, ``{A hierarchy of
  data-based ENSO models},'' vol.~18, pp.~4425--4444, 2005.

\bibitem{ckg11}
M.~D. Chekroun, D.~Kondrashov, and M.~Ghil, ``{Predicting stochastic systems by
  noise sampling, and application to the El Ni{\~n}o-Southern Oscillation},''
  {\em Proceedings of the National Academy of Sciences}, vol.~108, no.~29,
  pp.~11766--11771, 2011.

\bibitem{chen2016diversity}
C.~Chen, M.~A. Cane, N.~Henderson, D.~E. Lee, D.~Chapman, D.~Kondrashov, and
  M.~D. Chekroun, ``Diversity, nonlinearity, seasonality, and memory effect in
  {ENSO} simulation and prediction using empirical model reduction,'' {\em
  Journal of Climate}, vol.~29, no.~5, pp.~1809--1830, 2016.

\bibitem{kkg06}
D.~Kondrashov, S.~Kravtsov, and M.~Ghil, ``Empirical mode reduction in a model
  of extratropical low-frequency variability,'' vol.~63, pp.~1859--1877, 2006.

\bibitem{kcg_13MJO}
D.~Kondrashov, M.~D. Chekroun, A.~W. Robertson, and M.~Ghil, ``{Low-order
  stochastic model and ``past-noise forecasting" of the Madden-Julian
  Oscillation},'' vol.~{40}, pp.~5305--5310, 2013.
\newblock doi:10.1002/grl.50991.

\bibitem{santos2021reduced}
M.~Santos~Guti{\'e}rrez, V.~Lucarini, M.~D. Chekroun, and M.~Ghil,
  ``{Reduced-order models for coupled dynamical systems: Data-driven methods
  and the Koopman operator},'' {\em Chaos}, vol.~31, no.~5, p.~053116, 2021.

\bibitem{Rowley2009}
C.~W. Rowley, I.~Mezi{\'{c}}, S.~Bagheri, P.~Schlatter, and D.~S. Henningson,
  ``{Spectral analysis of nonlinear flows},'' {\em Journal of Fluid Mechanics},
  vol.~641, pp.~115--127, 2009.

\bibitem{Schmid2010}
P.~J. Schmid, ``Dynamic mode decomposition of numerical and experimental
  data,'' {\em Journal of Fluid Mechanics}, vol.~656, pp.~5--28, 2010.

\bibitem{Hasselmann.POPs.1988}
K.~Hasselmann, ``{PIPs and POPs: the reduction of complex dynamical systems
  using principal interaction and oscillation patterns},'' {\em Journal of
  Geophysical Research}, vol.~93, no.~D9, pp.~11015--11021, 1988.

\bibitem{Tu.ea.2014}
J.~H. Tu, C.~W. Rowley, D.~M. Luchtenburg, S.~L. Brunton, and J.~N. Kutz, ``{On
  dynamic mode decomposition: Theory and applications},'' {\em Journal of
  Computational Dynamics}, vol.~1, no.~2, pp.~391--421, 2014.

\bibitem{chekroun2017emergence}
M.~D. Chekroun, H.~Liu, and J.~C. McWilliams, ``The emergence of fast
  oscillations in a reduced primitive equation model and its implications for
  closure theories,'' {\em Computers \& Fluids}, vol.~151, pp.~3--22, 2017.

\bibitem{Lorenz80}
E.~N. Lorenz, ``Attractor sets and quasi-geostrophic equilibrium,'' {\em J.
  Atmos. Sci.}, vol.~37, no.~8, pp.~1685--1699, 1980.

\bibitem{chekroun2021stochastic}
M.~Chekroun, H.~Liu, and J.~McWilliams, ``Stochastic rectification of fast
  oscillations on slow manifold closures,'' {\em Proc. Natl. Acad. Sci. USA},
  vol.~118, no.~48, p.~e2113650118, 2021.

\bibitem{bolin1955numerical}
B.~Bolin, ``Numerical forecasting with the barotropic model,'' {\em Tellus},
  vol.~7, no.~1, pp.~27--49, 1955.

\bibitem{baer1977complete}
F.~Baer and J.~J. Tribbia, ``On complete filtering of gravity modes through
  nonlinear initialization,'' {\em Monthly Weather Review}, vol.~105, no.~12,
  pp.~1536--1539, 1977.

\bibitem{machenhauer1977dynamics}
B.~Machenhauer, ``On the dynamics of gravity oscillations in a shallow water
  model with applications to normal mode initialization,'' {\em Beitr. Phys.
  Atmos}, vol.~50, pp.~253--271, 1977.

\bibitem{daley1981normal}
R.~Daley, ``Normal mode initialization,'' {\em Reviews of Geophysics}, vol.~19,
  no.~3, pp.~450--468, 1981.

\bibitem{leith1980nonlinear}
C.~Leith, ``Nonlinear normal mode initialization and quasi-geostrophic
  theory,'' {\em J. Atmos. Sci.}, vol.~37, no.~5, pp.~958--968, 1980.

\bibitem{lorenz1963deterministic}
E.~N. Lorenz, ``Deterministic nonperiodic flow,'' {\em {J. Atmos. Sci.}},
  vol.~20, no.~2, pp.~130--141, 1963.

\bibitem{CLM16_Lorenz9D}
M.~Chekroun, H.~Liu, and J.~C. McWilliams, ``{The emergence of fast
  oscillations in a reduced primitive equation model and its implications for
  closure theories},'' {\em Comp.~\& Fluids}, vol.~151, pp.~3--22, 2017.

\bibitem{Gent_McWilliams82}
P.~R. Gent and J.~C. McWilliams, ``{Intermediate model solutions to the Lorenz
  equations: Strange attractors and other phenomena},'' {\em J. Atmos. Sci.},
  vol.~39, no.~1, pp.~3--13, 1982.

\bibitem{mcwilliams1980intermediate}
J.~McWilliams and P.~Gent, ``Intermediate models of planetary circulations in
  the atmosphere and ocean,'' {\em J. Atmos. Sci.}, vol.~37, no.~8,
  pp.~1657--1678, 1980.

\bibitem{mcwilliams2019perspective}
J.~C. McWilliams, ``A perspective on the legacy of {E}dward {L}orenz,'' {\em
  Earth and Space Science}, vol.~6, no.~3, pp.~336--350, 2019.

\bibitem{lorenz1986existence}
E.~Lorenz, ``On the existence of a slow manifold,'' {\em {J. Atmos. Sci.}},
  vol.~43, no.~15, pp.~1547--1558, 1986.

\bibitem{lorenz1987nonexistence}
E.~N. Lorenz and V.~Krishnamurthy, ``On the nonexistence of a slow manifold,''
  {\em {J. Atmos. Sci.}}, vol.~44, no.~20, pp.~2940--2950, 1987.

\bibitem{vanneste2008exponential}
J.~Vanneste, ``Exponential smallness of inertia--gravity wave generation at
  small rossby number,'' {\em J. Atmos. Sci.}, vol.~65, no.~5, pp.~1622--1637,
  2008.

\bibitem{temam2011slow}
R.~Temam and D.~Wirosoetisno, ``Slow manifolds and invariant sets of the
  primitive equations,'' {\em J. Atmos. Sci.}, vol.~68, no.~3, pp.~675--682,
  2011.

\bibitem{vanneste2013balance}
J.~Vanneste, ``Balance and spontaneous wave generation in geophysical flows,''
  {\em Ann. Rev. Fluid Mech.}, vol.~45, pp.~147--172, 2013.

\bibitem{plougonven2007inertia}
R.~Plougonven and C.~Snyder, ``{Inertia--gravity waves spontaneously generated
  by jets and fronts. Part I: Different baroclinic life cycles},'' {\em Journal
  of the atmospheric sciences}, vol.~64, no.~7, pp.~2502--2520, 2007.

\bibitem{polichtchouk2020spontaneous}
I.~Polichtchouk and R.~Scott, ``Spontaneous inertia-gravity wave emission from
  a nonlinear critical layer in the stratosphere,'' {\em Quarterly Journal of
  the Royal Meteorological Society}, vol.~146, no.~728, pp.~1516--1528, 2020.

\bibitem{tulich2007vertical}
S.~Tulich, D.~Randall, and B.~Mapes, ``Vertical-mode and cloud decomposition of
  large-scale convectively coupled gravity waves in a two-dimensional
  cloud-resolving model,'' {\em J. Atmos. Sci.}, vol.~64, no.~4,
  pp.~1210--1229, 2007.

\bibitem{lane2015gravity}
T.~P. Lane, ``Convectively generated gravity waves,'' in {\em Encyclopedia of
  Atmospheric Sciences (2nd Edition)}, pp.~171--179, Elsevier, 2015.

\bibitem{Dror2021}
T.~Dror, M.~D. Chekroun, O.~Altaratz, and I.~Koren, ``{Deciphering organization
  of GOES--16 green cumulus, through the EOF Lens},'' {\em Atmos. Chem. Phys.},
  vol.~21, pp.~12261--12272, 2021.

\bibitem{Monin1952}
A.~Monin, ``Change of pressure in a barotropic atmosphere,'' {\em Akad. Nauk.
  Izv. Ser. Geofiz.}, vol.~4, pp.~76--85, 1952.

\bibitem{charney1955use}
J.~Charney, ``The use of the primitive equations of motion in numerical
  prediction,'' {\em Tellus}, vol.~7, no.~1, pp.~22--26, 1955.

\bibitem{lorenz1960energy}
E.~Lorenz, ``Energy and numerical weather prediction,'' {\em Tellus}, vol.~12,
  no.~4, pp.~364--373, 1960.

\bibitem{zhen2022eigenvalues}
Y.~Zhen, B.~Chapron, E.~M{\'e}min, and L.~Peng, ``{Eigenvalues of
  autocovariance matrix: A practical method to identify the Koopman
  eigenfrequencies},'' {\em Physical Review E}, vol.~105, no.~3, p.~034205,
  2022.

\bibitem{Tantet_al_Hopf}
A.~Tantet, M.~Chekroun, H.~Dijkstra, and J.~D. Neelin, ``{Ruelle-Pollicott
  Resonances of Stochastic Systems in Reduced State Space. Part II: Stochastic
  Hopf Bifurcation},'' {\em J.~Stat.~Phys.}, vol.~179, pp.~1403--1448, 2020.

\bibitem{holm2015variational}
D.~D. Holm, ``Variational principles for stochastic fluid dynamics,'' {\em
  Proceedings of the Royal Society A: Mathematical, Physical and Engineering
  Sciences}, vol.~471, no.~2176, p.~20140963, 2015.

\bibitem{cotter2019numerically}
C.~Cotter, D.~Crisan, D.~D. Holm, W.~Pan, and I.~Shevchenko, ``Numerically
  modeling stochastic lie transport in fluid dynamics,'' {\em Multiscale
  Modeling \& Simulation}, vol.~17, no.~1, pp.~192--232, 2019.

\bibitem{resseguier2017geophysical}
V.~Resseguier, E.~M{\'e}min, and B.~Chapron, ``{Geophysical flows under
  location uncertainty, Part I: Random transport and general models},'' {\em
  Geophysical \& Astrophysical Fluid Dynamics}, vol.~111, no.~3, pp.~149--176,
  2017.

\bibitem{simonnet2003low}
E.~Simonnet, M.~Ghil, K.~Ide, R.~Temam, and S.~Wang, ``{Low-frequency
  variability in shallow-water models of the wind-driven ocean circulation.
  Part II: Time-dependent solutions},'' {\em Journal of Physical Oceanography},
  vol.~33, no.~4, pp.~729--752, 2003.

\bibitem{rocha2016mesoscale}
C.~B. Rocha, T.~K. Chereskin, S.~T. Gille, and D.~Menemenlis, ``Mesoscale to
  submesoscale wavenumber spectra in drake passage,'' {\em Journal of Physical
  Oceanography}, vol.~46, no.~2, pp.~601--620, 2016.

\bibitem{young2021inertia}
W.~R. Young, ``Inertia-gravity waves and geostrophic turbulence,'' {\em Journal
  of Fluid Mechanics}, vol.~920, p.~F1, 2021.

\bibitem{bolton2019applications}
T.~Bolton and L.~Zanna, ``Applications of deep learning to ocean data inference
  and subgrid parameterization,'' {\em Journal of Advances in Modeling Earth
  Systems}, vol.~11, no.~1, pp.~376--399, 2019.

\bibitem{maulik2019}
R.~Maulik, O.~San, A.~Rasheed, and P.~Vedula, ``Subgrid modelling for
  two-dimensional turbulence using neural networks,'' {\em Journal of Fluid
  Mechanics}, vol.~858, pp.~122--144, 2019.

\bibitem{kochkov2021}
D.~Kochkov, J.~Smith, A.~Alieva, Q.~Wang, M.~P. Brenner, and S.~Hoyer,
  ``Machine learning--accelerated computational fluid dynamics,'' {\em
  Proceedings of the National Academy of Sciences}, vol.~118, no.~21,
  p.~e2101784118, 2021.

\bibitem{zanna2020}
L.~Zanna and T.~Bolton, ``Data-driven equation discovery of ocean mesoscale
  closures,'' {\em Geophysical Research Letters}, vol.~47, no.~17,
  p.~e2020GL088376, 2020.

\bibitem{subel2022explaining}
A.~Subel, Y.~Guan, A.~Chattopadhyay, and P.~Hassanzadeh, ``Explaining the
  physics of transfer learning a data-driven subgrid-scale closure to a
  different turbulent flow,'' {\em arXiv preprint arXiv:2206.03198}, 2022.

\bibitem{goodfellow2016}
I.~Goodfellow, Y.~Bengio, and A.~Courville, {\em Deep learning}.
\newblock MIT press, 2016.

\bibitem{piomelli1991subgrid}
U.~Piomelli, W.~H. Cabot, P.~Moin, and S.~Lee, ``Subgrid-scale backscatter in
  turbulent and transitional flows,'' {\em Physics of Fluids A: Fluid
  Dynamics}, vol.~3, no.~7, pp.~1766--1771, 1991.

\bibitem{jansen2014parameterizing}
M.~F. Jansen and I.~M. Held, ``Parameterizing subgrid-scale eddy effects using
  energetically consistent backscatter,'' {\em Ocean Modelling}, vol.~80,
  pp.~36--48, 2014.

\bibitem{miyanawala2017efficient}
T.~P. Miyanawala and R.~K. Jaiman, ``{An efficient deep learning technique for
  the Navier-Stokes equations: Application to unsteady wake flow dynamics},''
  {\em arXiv preprint arXiv:1710.09099}, 2017.

\bibitem{ma2019model}
C.~Ma, J.~Wang, and E.~Weinan, ``Model reduction with memory and the machine
  learning of dynamical systems,'' {\em Communications in Computational
  Physics}, vol.~25, no.~4, pp.~947--962, 2019.

\bibitem{FMT88}
C.~Foias, O.~Manley, and R.~Temam, ``Modeling of the interaction of small and
  large eddies in two-dimensional turbulent flows,'' {\em RAIRO Mod\'el. Math.
  Anal. Num\'er.}, vol.~22, no.~1, pp.~93--118, 1988.

\bibitem{foias1991approximate}
C.~Foias, O.~P. Manley, and R.~Temam, ``Approximate inertial manifolds and
  effective viscosity in turbulent flows,'' {\em Physics of Fluids A: Fluid
  Dyn.}, vol.~3, no.~5, pp.~898--911, 1991.

\bibitem{pascal1992nonlinear}
F.~Pascal and C.~Basdevant, ``{Nonlinear Galerkin method and subgrid-scale
  model for two-dimensional turbulent flows},'' {\em Theor. and Comp. Fluid
  Dyn.}, vol.~3, no.~5, pp.~267--284, 1992.

\bibitem{lorenz_1956}
E.~N. Lorenz, ``Empirical orthogonal functions and statistical weather
  prediction,'' {\em Scientific Report no. 1, Statistical Forecasting Project},
  1956.

\bibitem{jolliffe2002principal}
I.~Jolliffe, {\em Principal component analysis}.
\newblock Wiley Online Library, 2002.

\bibitem{scholkopf1998nonlinear}
B.~Sch{\"o}lkopf, A.~Smola, and K.-R. M{\"u}ller, ``Nonlinear component
  analysis as a kernel eigenvalue problem,'' {\em Neural computation}, vol.~10,
  no.~5, pp.~1299--1319, 1998.

\bibitem{mukhin2015principal}
D.~Mukhin, A.~Gavrilov, A.~Feigin, E.~Loskutov, and J.~Kurths, ``Principal
  nonlinear dynamical modes of climate variability,'' {\em Scientific reports},
  vol.~5, 2015.

\bibitem{tipping1999probabilistic}
M.~E. Tipping and C.~M. Bishop, ``Probabilistic principal component analysis,''
  {\em Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, vol.~61, no.~3, pp.~611--622, 1999.

\bibitem{schmidt2019spectral}
O.~Schmidt, G.~Mengaldo, G.~Balsamo, and N.~Wedi, ``Spectral empirical
  orthogonal function analysis of weather and climate data,'' {\em Monthly
  Weather Review}, vol.~147, no.~8, pp.~2979--2995, 2019.

\bibitem{zerenner2021harmonic}
T.~Zerenner, M.~Goodfellow, and P.~Ashwin, ``Harmonic cross-correlation
  decomposition for multivariate time series,'' {\em Physical Review E},
  vol.~103, no.~6, p.~062213, 2021.

\bibitem{giannakis2013nonlinear}
D.~Giannakis and A.~J. Majda, ``{Nonlinear Laplacian spectral analysis:
  capturing intermittent and low-frequency spatiotemporal patterns in
  high-dimensional data},'' {\em Statistical Analysis and Data Mining: The ASA
  Data Science Journal}, vol.~6, no.~3, pp.~180--194, 2013.

\bibitem{berloff2015dynamically}
P.~Berloff, ``{Dynamically consistent parameterization of mesoscale eddies.
  Part I: Simple model},'' {\em Ocean Modelling}, vol.~87, pp.~1--19, 2015.

\bibitem{rahaman2019spectral}
N.~Rahaman, A.~Baratin, D.~Arpit, F.~Draxler, M.~Lin, F.~Hamprecht, Y.~Bengio,
  and A.~Courville, ``On the spectral bias of neural networks,'' in {\em
  International Conference on Machine Learning}, pp.~5301--5310, PMLR, 2019.

\bibitem{GhilEtAl_RG02}
M.~Ghil, M.~R. Allen, M.~D. Dettinger, K.~Ide, D.~Kondrashov, M.~E. Mann, A.~W.
  Robertson, A.~Saunders, Y.~Tian, F.~Varadi, and P.~Yiou, ``Advanced spectral
  methods for climatic time series,'' {\em Rev. Geophys.}, vol.~40, no.~1,
  p.~1003, 2002.

\bibitem{ruelle1971nature}
D.~Ruelle and F.~Takens, ``On the nature of turbulence,'' {\em Commun. math.
  phys}, vol.~20, no.~3, pp.~167--192, 1971.

\bibitem{landau2013fluid}
L.~Landau and E.~M. Lifshitz, {\em {Fluid Mechanics: Landau and Lifshitz:
  Course of Theoretical Physics, Volume 6}}, vol.~6.
\newblock Elsevier, 2013.

\bibitem{Chekroun2011}
M.~D. Chekroun, E.~Simonnet, and M.~Ghil, ``{Stochastic climate dynamics:
  Random attractors and time-dependent invariant measures},'' {\em Physica D:
  Nonlinear Phenomena}, vol.~240, no.~21, pp.~1685--1700, 2011.

\bibitem{CLR13}
A.~N. Carvalho, J.~A. Langa, and J.~C. Robinson, {\em Attractors for
  {I}nfinite-{D}imensional {N}on-autonomous {D}ynamical {S}ystems}, vol.~182 of
  {\em Applied Mathematical Sciences}.
\newblock Springer, New York, 2013.

\bibitem{TelJSP}
T.~T{\'{e}}l, T.~B{\'{o}}dai, G.~Dr{\'{o}}tos, T.~Haszpra, M.~Herein,
  B.~Kasz{\'{a}}s, and M.~Vincze, ``{The Theory of Parallel Climate
  Realizations},'' {\em Journal of Statistical Physics}, 2019.

\bibitem{PieriniJSP}
S.~Pierini, ``{Statistical significance of small ensembles of simulations and
  detection of the internal climate variability: An excitable ocean system case
  study},'' {\em Journal of Statistical Physics}, vol.~179, no.~5-6,
  pp.~1475--1495, 2020.

\bibitem{Lucarini2016}
V.~Lucarini, ``{Response Operators for Markov Processes in a Finite State
  Space: Radius of Convergence and Link to the Response Theory for Axiom A
  Systems},'' {\em Journal of Statistical Physics}, vol.~162, pp.~312--333, jan
  2016.

\bibitem{SantosJSP}
M.~Santos~Guti{\'{e}}rrez and V.~Lucarini, ``{Response and Sensitivity Using
  Markov Chains},'' {\em Journal of Statistical Physics}, vol.~179,
  pp.~1572--1593, 2020.

\bibitem{Pedram1}
P.~Hassanzadeh and Z.~Kuang, ``The linear response function of an idealized
  atmosphere. part i: Construction using green's functions and applications,''
  {\em Journal of the Atmospheric Sciences}, vol.~73, no.~9, pp.~3423 -- 3439,
  2016.

\bibitem{abramov2007}
R.~V. Abramov and A.~J. Majda, ``{Blended response algorithms for linear
  fluctuation-dissipation for complex nonlinear dynamical systems},'' {\em
  Nonlinearity}, vol.~20, no.~12, p.~2793, 2007.

\bibitem{North1993}
G.~R. North, R.~E. Bell, and J.~W. Hardin, ``Fluctuation dissipation in a
  general circulation model,'' {\em Climate Dynamics}, vol.~8, pp.~259--264,
  Jul 1993.

\bibitem{Cionni2004}
I.~Cionni, G.~Visconti, and F.~Sassi, ``Fluctuation dissipation theorem in a
  general circulation model,'' {\em Geophysical Research Letters}, vol.~31,
  no.~9, 2004.

\bibitem{Langen2005}
P.~L. Langen and V.~A. Alexeev, ``Estimating 2  co2 warming in an aquaplanet
  gcm using the fluctuation-dissipation theorem,'' {\em Geophysical Research
  Letters}, vol.~32, no.~23, 2005.

\bibitem{gritsun2007}
A.~Gritsun and G.~Branstator, ``Climate response using a three-dimensional
  operator based on the fluctuation--dissipation theorem,'' {\em Journal of the
  Atmospheric Sciences}, vol.~64, no.~7, pp.~2558--2575, 2007.

\bibitem{gritsun2017}
A.~Gritsun and V.~Lucarini, ``{Fluctuations, response, and resonances in a
  simple atmospheric model},'' {\em Physica D: Nonlinear Phenomena}, vol.~349,
  pp.~62--76, 2017.

\bibitem{Pedram2}
P.~Hassanzadeh and Z.~Kuang, ``The linear response function of an idealized
  atmosphere. part ii: Implications for the practical use of the
  fluctuation--dissipation theorem and the role of operator's nonnormality,''
  {\em Journal of the Atmospheric Sciences}, vol.~73, no.~9, pp.~3441 -- 3452,
  2016.

\bibitem{Lucarini2018JSP}
V.~Lucarini, ``{Revising and Extending the Linear Response Theory for
  Statistical Mechanical Systems: Evaluating Observables as Predictors and
  Predictands},'' {\em Journal of Statistical Physics}, vol.~173,
  pp.~1698--1721, dec 2018.

\bibitem{Dijkstra2005low}
H.~A. Dijkstra and M.~Ghil, ``{Low-frequency variability of the large-scale
  ocean circulation: A dynamical systems approach},'' {\em Reviews of
  Geophysics}, vol.~43, no.~3, 2005.

\bibitem{Kuhlbrodt2007}
T.~Kuhlbrodt, A.~Griesel, M.~Montoya, A.~Levermann, M.~Hofmann, and
  S.~Rahmstorf, ``{On the driving processes of the Atlantic meridional
  overturning circulation},'' {\em Reviews of Geophysics}, vol.~45, no.~2,
  2007.

\bibitem{Tomasini2020}
U.~M. Tomasini and V.~Lucarini, ``Predictors and predictands of linear response
  in spatially extended systems,'' {\em The European Physical Journal Special
  Topics}, vol.~230, no.~14, pp.~2813--2832, 2021.

\bibitem{CKL17}
M.~D. Chekroun, A.~Kr\"oner, and H.~Liu, ``{Galerkin approximations of
  nonlinear optimal control problems in Hilbert spaces},'' {\em Electronic
  Journal of Differential Equations}, vol.~189, pp.~1--40, 2017.

\bibitem{Bodai2020}
T.~B\'odai, V.~Lucarini, and F.~Lunkeit, ``Can we use linear response theory to
  assess geoengineering strategies?,'' {\em Chaos: An Interdisciplinary Journal
  of Nonlinear Science}, vol.~30, no.~2, p.~023124, 2020.

\bibitem{IPCC13}
IPCC, {\em {Climate Change 2013: The Physical Science Basis. Contribution of
  Working Group I to the Fifth Assessment Report of the Intergovernmental Panel
  on Climate Change}}.
\newblock Cambridge: Cambridge University Press, 2014.

\bibitem{Otto2013}
A.~Otto, F.~E.~L. Otto, O.~Boucher, J.~Church, G.~Hegerl, P.~M. Forster, N.~P.
  Gillett, J.~Gregory, G.~C. Johnson, R.~Knutti, N.~Lewis, U.~Lohmann,
  J.~Marotzke, G.~Myhre, D.~Shindell, B.~Stevens, and M.~R. Allen, ``Energy
  budget constraints on climate response,'' {\em Nature Geoscience}, vol.~6,
  no.~6, pp.~415--416, 2013.

\bibitem{Froyland2021}
G.~Froyland, D.~Giannakis, B.~R. Lintner, M.~Pike, and J.~Slawinska, ``Spectral
  analysis of climate dynamics with operator-theoretic approaches,'' {\em
  Nature Communications}, vol.~12, no.~1, p.~6570, 2021.

\bibitem{williams2015data}
M.~O. Williams, I.~G. Kevrekidis, and C.~W. Rowley, ``{A data-driven
  approximation of the Koopman operator: Extending dynamic mode
  decomposition},'' {\em Journal of Nonlinear Science}, vol.~25, no.~6,
  pp.~1307--1346, 2015.

\bibitem{Navarra1993}
A.~Navarra, ``A new set of orthonormal modes for linearized meteorological
  problems,'' {\em Journal of Atmospheric Sciences}, vol.~50, no.~16, pp.~2569
  -- 2583, 1993.

\bibitem{Palmer1999}
T.~N. Palmer, ``A nonlinear dynamical perspective on climate prediction,'' {\em
  Journal of Climate}, vol.~12, no.~2, pp.~575 -- 591, 1999.

\bibitem{Lu2020}
J.~Lu, F.~Liu, L.~R. Leung, and H.~Lei, ``Neutral modes of surface temperature
  and the optimal ocean thermal forcing for global cooling,'' {\em npj Climate
  and Atmospheric Science}, vol.~3, no.~1, p.~9, 2020.

\bibitem{Chek_al14_RP}
M.~D. Chekroun, J.~D. Neelin, D.~Kondrashov, J.~C. McWilliams, and M.~Ghil,
  ``{Rough parameter dependence in climate models: The role of Ruelle-Pollicott
  resonances},'' {\em {Proc. Natl. Acad. Sci USA}}, vol.~111, no.~5,
  pp.~1684--1690, 2014.

\bibitem{Held2004}
H.~Held and T.~Kleinen, ``Detection of climate system bifurcations by
  degenerate fingerprinting,'' {\em Geophysical Research Letters}, vol.~31,
  no.~23, 2004.

\bibitem{Boettner2022}
C.~Boettner and N.~Boers, ``Critical slowing down in dynamical systems driven
  by nonstationary correlated noise,'' {\em Phys. Rev. Res.}, vol.~4,
  p.~013230, Mar 2022.

\bibitem{Lucarini2012}
V.~Lucarini, ``{Stochastic Perturbations to Dynamical Systems: A Response
  Theory Approach},'' {\em Journal of Statistical Physics}, vol.~146, no.~4,
  pp.~774--786, 2012.

\bibitem{Rahmstorf1995}
S.~Rahmstorf, ``Bifurcations of the atlantic thermohaline circulation in
  response to changes in the hydrological cycle,'' {\em Nature}, vol.~378,
  no.~6553, pp.~145--149, 1995.

\bibitem{Boers2021}
N.~Boers, ``Observation-based early-warning signals for a collapse of the
  atlantic meridional overturning circulation,'' {\em Nature Climate Change},
  vol.~11, no.~8, pp.~680--688, 2021.

\bibitem{caesar2018observed}
L.~Caesar, S.~Rahmstorf, A.~Robinson, G.~Feulner, and V.~Saba, ``{Observed
  fingerprint of a weakening Atlantic Ocean overturning circulation},'' {\em
  Nature}, vol.~556, no.~7700, pp.~191--196, 2018.

\bibitem{Hilborn1982}
R.~C. Hilborn, ``Einstein coefficients, cross sections, f values, dipole
  moments, and all that,'' {\em American Journal of Physics}, vol.~50, no.~11,
  pp.~982--986, 1982.

\bibitem{Lucarini2005}
V.~Lucarini, J.~J. Saarinen, K.-E. Peiponen, and E.~M. Vartiainen, {\em
  Kramers-Kronig relations in Optical Materials Research}.
\newblock New York: Springer, 2005.

\bibitem{TantetJSPIII}
A.~Tantet, M.~Chekroun, J.~Neelin, and H.~Dijkstra, ``{Ruelle--Pollicott
  Resonances of Stochastic Systems in Reduced State Space. Part III:
  Application to the Cane--Zebiak Model of the El Ni{\~{n}}o--Southern
  Oscillation},'' {\em Journal of Statistical Physics}, vol.~179,
  pp.~1449--1474, 2020.

\bibitem{LKFW14}
V.~Lucarini, T.~Kuna, D.~Faranda, and J.~Wouters, ``{Towards a General Theory
  of Extremes for Observables of Chaotic Dynamical Systems},'' {\em Journal of
  Statistical Physics}, vol.~154.

\bibitem{CGN17}
M.~D. Chekroun, M.~Ghil, and J.~D. Neelin, ``{Pullback attractor crisis in a
  delay differential ENSO model},'' in {\em {Advances in Nonlinear
  Geosciences}} (A.~Tsonis, ed.), pp.~1--33, Springer, 2018.

\bibitem{Chekroun_al22SciAdv}
M.~D. Chekroun, I.~Koren, H.~Liu, and H.~Liu, ``Generic generation of
  noise-driven chaos in stochastic time delay systems: Bridging the gap with
  high-end simulations,'' {\em Science Advances}, vol.~8, no.~46, p.~eabq7137,
  2022.

\bibitem{Benzi1981}
R.~Benzi, A.~Sutera, and A.~Vulpiani, ``The mechanism of stochastic
  resonance,'' {\em Journal of Physics A: Mathematical and General}, vol.~14,
  pp.~L453--L457, nov 1981.

\bibitem{Nicolis1981}
C.~Nicolis, ``Solar variability and stochastic effects on climate,'' {\em Solar
  Physics}, vol.~74, no.~2, pp.~473--478, 1981.

\bibitem{Benzi1982}
R.~Benzi, G.~Parisi, A.~Sutera, and A.~Vulpiani, ``Stochastic resonance in
  climatic change,'' {\em Tellus}, vol.~34, no.~1, pp.~10--16, 1982.

\bibitem{Nicolis1982}
C.~Nicolis, ``Stochastic aspects of climatic transitions - response to a
  periodic forcing,'' {\em Tellus}, vol.~34, no.~3, pp.~308--308, 1982.

\bibitem{gammaitoni1998}
L.~Gammaitoni, P.~H\"{a}nggi, P.~Jung, and F.~Marchesoni, ``{Stochastic
  resonance},'' {\em Rev. Mod. Phys.}, vol.~70, no.~1, pp.~223--287, 1998.

\bibitem{Charney1979}
J.~G. Charney and J.~G. DeVore, ``Multiple flow equilibria in the atmosphere
  and blocking,'' {\em J. Atmos. Sci.}, vol.~36, pp.~1205--1216, 1979.

\bibitem{Benzi1986}
R.~Benzi, P.~Malguzzi, A.~Speranza, and A.~Sutera, ``The statistical properties
  of general atmospheric circulation: observational evidence and a minimal
  theory of bimodality,'' {\em {Q. J. R. Meteorol. Soc.}}, vol.~112,
  pp.~661--674, July 1986.

\bibitem{Benzi1989}
R.~Benzi and A.~Speranza, ``Statistical properties of low-frequency variability
  in the northern hemisphere,'' {\em Journal of Climate}, vol.~2, no.~4,
  pp.~367--379, 1989.

\bibitem{Kimoto1993a}
M.~Kimoto and M.~Ghil, ``{Multiple flow regimes in the Northern Hemisphere
  winter. Part I: Methodology and hemispheric regimes},'' {\em {J. Atmos.
  Sci.}}, vol.~50, pp.~2625--2643, {1993a}.

\bibitem{Itoh.Kimoto.1996}
H.~Itoh and M.~Kimoto, ``Multiple attractors and chaotic itinerancy in a
  quasigeostrophic model with realistic topography: Implications for weather
  regimes and low-frequency variability,'' {\em {J. Atmos. Sci.}}, vol.~53,
  pp.~2217--2231, Aug. 1996.

\bibitem{freidlin1998}
M.~I. Freidlin and A.~D. Wentzell, {\em Random perturbations of dynamical
  systems}.
\newblock New York: Springer, 1998.

\bibitem{T09}
H.~Touchette, ``{The large deviation approach to statistical mechanics},'' {\em
  Physics Reports}, vol.~478, pp.~1--69, 2009.

\bibitem{Bouchet2012}
F.~Bouchet and A.~Venaille, ``Statistical mechanics of two-dimensional and
  geophysical flows,'' {\em Physics Reports}, vol.~515, no.~5, pp.~227--295,
  2012.
\newblock Statistical mechanics of two-dimensional and geophysical flows.

\bibitem{Herbert2015}
C.~Herbert, {\em An Introduction to Large Deviations and Equilibrium
  Statistical Mechanics for Turbulent Flows}, pp.~53--84.
\newblock Cham: Springer International Publishing, 2015.

\bibitem{LucariniBodai2019PRL}
V.~Lucarini and T.~B{\'{o}}dai, ``{Transitions across Melancholia States in a
  Climate Model: Reconciling the Deterministic and Stochastic Points of
  View},'' {\em Phys. Rev. Lett.}, vol.~122, p.~158701, apr 2019.

\bibitem{LucariniBodai2020}
V.~Lucarini and T.~B{\'{o}}dai, ``Global stability properties of the climate:
  Melancholia states, invariant measures, and phase transitions,'' {\em
  Nonlinearity}, vol.~33, pp.~R59--R92, jul 2020.

\bibitem{Margazoglou2021}
G.~Margazoglou, T.~Grafke, A.~Laio, and V.~Lucarini, ``{Dynamical landscape and
  multistability of a climate model},'' {\em Proceedings of the Royal Society
  A: Mathematical, Physical and Engineering Sciences}, vol.~477, p.~20210019,
  2021.

\bibitem{Ditlevsen1999}
P.~D. Ditlevsen, ``Observation of $\alpha$-stable noise induced millennial
  climate changes from an ice-core record,'' {\em Geophysical Research
  Letters}, vol.~26, no.~10, pp.~1441--1444, 1999.

\bibitem{Gottwald2021}
G.~A. Gottwald, ``A model for dansgaard--oeschger events and millennial-scale
  abrupt climate change without external forcing,'' {\em Climate Dynamics},
  vol.~56, no.~1, pp.~227--243, 2021.

\bibitem{LucariniSM2022}
V.~Lucarini, L.~Serdukova, and G.~Margazoglou, ``{L\'evy noise versus
  Gaussian-noise-induced transitions in the Ghil--Sellers energy balance
  model},'' {\em Nonlinear Processes in Geophysics}, vol.~29, no.~2,
  pp.~183--205, 2022.

\end{thebibliography}


\end{document}
