\section{Notation and Proofs}
\label{sec:all_proofs}
\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|}
        \hline
        $[a,b]$& the set $\{a,\ldots,b\}$ where $a,b \in \mathbb{Z}$\\
        $(a_i)_1^k$& the sequence $a_1,\ldots,a_k$ where $a_i$ is a scalar/vector/matrix\\
        $\mathbf{e}^p_q$& a vector of zeros of length $p$ with $1$ at the $q$th location\\
        $\mathbf{1}^{p}_q$& a vector of zeros of length $p$ whose first $q$ elements are $1$s\\
        $\mathbf{1}_p$& $\mathbf{1}^{p}_p$\\
        $\mathbf{0}_p$ & a vector of zeros of length $p$\\
        $\mathbf{0}_{m \times n}$ & a matrix of zeros with $m$ rows and $n$ columns\\
        $\mathbf{I}_d$& the identity matrix of size $d$\\
        $[\mathbf{A}_i]_1^n$& a matrix obtained by vertically stacking the matrices $(\mathbf{A}_i)_1^m$\\
        $[\mathbf{A}]_1^n$& $[\mathbf{A}_i]_1^n$ where $\mathbf{A}_i = \mathbf{A}$ for all $i \in [1,n]$\\
        $\mathbf{I}^m_d$ & $[\mathbf{I}_d]_1^m$\\
        $\mathbf{A}_i$ & $i$th row block of $\mathbf{A}$$^\sharp$\\
        $\mathbf{A}_{ij}$ & $(i,j)$th block of the block matrix $\mathbf{A}$$^\sharp$\\
        $\vecz (\mathbf{A})$ & the column-major vectorization of the matrix $\mathbf{A}$\\
        $\blockdiag((\mathbf{A}_i)_1^m)$ & a block diagonal matrix with $\mathbf{A}_i$ as the $i$th block\\
        $\diag (\mathbf{v})$ & a diagonal matrix with $\mathbf{v}(i)$ as the $i$th diagonal element\\
        $\mathbf{A}(k,:)$ ($\mathbf{A}(:,k)$) & $k$th row (column) of $\mathbf{A}$\\
        $\mathbf{A}(i:j,:)$ ($\mathbf{A}(:,i:j)$)& a matrix obtained by stacking $i$th to $j$th rows (columns) of $\mathbf{A}$\\
        $\mathbb{O}(n)$ & the set of orthogonal matrices of size $n$\\
        $\Sym (n)$, $\Skew (n)$, & the set of symmetric and skew-symmetric matrices of size $n$\\
        $\Sym(\mathbf{A})$, $\Skew(\mathbf{A})$ & $(\mathbf{A}+\mathbf{A}^T)/2$, $(\mathbf{A}-\mathbf{A}^T)/2$\\
        $\mathbf{A} \succeq 0$ ($\mathbf{A} \preceq 0$) &  $\mathbf{A}$ is symmetic and positive (negative) semidefinite\\
        $\mathbf{A} \succ 0$ ($\mathbf{A} \prec 0$) & $\mathbf{A}$ is symmetric and positive (negative) definite\\
        $\delta_{ij}$ & equals $1$ if and only if $i$ equals $j$ otherwise it is zero\\
        $\mathbf{A}^\dagger$ & the pseudoinverse i.e. the Moore-Penrose inverse of $\mathbf{A}$.\\
        $\mathbf{A} \otimes \mathbf{B}$ & the Kronecker product of $\mathbf{A}$ and $\mathbf{B}$\\
        WLOG & without loss of generality\\
        \hline
        \multicolumn{2}{l}{\footnotesize{$^\sharp$Dimensions are contextual.}}
    \end{tabular}
    \caption{Notation.}
    \label{tab:notation}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Section 2 Proofs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\proofof{Proposition~\ref{prop:A_0_2_A_1}}
By differentiating the objective in Eq.~(\ref{eq:A_1}) with respect to $\mathbf{x}_k$, the optimal value is
\begin{align}
    \mathbf{x}_k^* \coloneqq \mathbf{x}_k((\mathbf{S}_i)_1^m,(\mathbf{t}_i)_1^m) &= \frac{\sum_{(k,i)\in E(\Gamma)}(\mathbf{S}_i^T\mathbf{x}_{k,i}+\mathbf{t}_i)}{|\{i:(k,i)\in E(\Gamma)\}|}\label{eq:opt_x_k}
\end{align}
which is the consensus of all the views for the $k$th point. Since
\begin{align}
    \sum_{(k,i)\in E(\Gamma)}(\mathbf{S}_i^T\mathbf{x}_{k,i}+\mathbf{t}_i-\mathbf{x}_k^*) = 0,
\end{align}
by adding and subtracting $\mathbf{x}_k^*$, we obtain
\begin{align}
    \sum_{\substack{(k,i)\in E(\Gamma)\\(k,j)\in E(\Gamma)}}\left\|(\mathbf{S}_i^T\mathbf{x}_{k,i}+\mathbf{t}_i)-(\mathbf{S}_j^T\mathbf{x}_{k,j}+\mathbf{t}_j)\right\|^2_2 = 2\sum_{(k,i)\in E(\Gamma)}\left\|(\mathbf{S}_i^T\mathbf{x}_{k,i}+\mathbf{t}_i)-\mathbf{x}_k^*\right\|^2_2
\end{align}
and the result follows. The above equation also shows that the minimizers $(\mathbf{S}_i)_1^m$ and $(\mathbf{t}_i)_1^m$ of Eq.~(\ref{eq:A_0}) and Eq.~(\ref{eq:A_1}) are the same. \hfill$\blacksquare$

\proofof{Proposition~\ref{prop:kerB}}
Let $\mathbf{u} \in \mathbb{R}^{n+m}$. Since $\boldsymbol{\mathcal{L}}_{\Gamma} \succeq 0$, $\boldsymbol{\mathcal{L}}_{\Gamma}\mathbf{u} = 0 \iff \mathbf{u}^T\boldsymbol{\mathcal{L}}_{\Gamma}\mathbf{u} = 0$. From Eq.~(\ref{eq:L_Gamma}), the latter holds if and only if $\mathbf{e}_{ki}^T\mathbf{u} = 0$ for all $(k,i) \in E(\Gamma)$. Thus, using Eq.~(\ref{eq:B}), $\boldsymbol{\mathcal{L}}_{\Gamma}\mathbf{u} = 0$ implies $\mathbf{B}\mathbf{u} = 0$. \hfill$\blacksquare$

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Section 3 Proofs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\proofoffirst{Proposition~\ref{prop:V_S_H_S}}
Using the constraints characterizing $\pi^{-1}(\widetilde{\mathbf{S}})$ as in Eq.~(\ref{eq:pi_inv_wtS}), 
\begin{align}
    \mathcal{V}_{\mathbf{S}} &= T_{\mathbf{S}}\pi^{-1}(\widetilde{\mathbf{S}})\\
    &= \{\mathbf{Z} \in \mathbb{R}^{md \times d}: \mathbf{Z}_i\mathbf{S}_1^T+\mathbf{S}_i\mathbf{Z}_1^T = 0, \mathbf{Z}_j\mathbf{S}_j^T+\mathbf{S}_j\mathbf{Z}_j^T=0, i \in [2,m], j \in [1,m]\}\\
    &= \{[\mathbf{S}_i\boldsymbol{\Omega}_i]_1^m: \boldsymbol{\Omega}_i \in \Skew(d), \boldsymbol{\Omega}_i+\boldsymbol{\Omega}_1^T = 0, i \in [1,m]\}\\
    &= \{\mathbf{S}\boldsymbol{\Omega}: \boldsymbol{\Omega} \in \Skew(d)\}.
\end{align}

Then note that the objective in Eq.~(\ref{eq:P^v_S}) is strictly convex in $\boldsymbol{\Omega}$. Therefore, it suffices to solve for the critical point and the Eq.~(\ref{eq:P^v_S}) follows immediately.

Then, using Eq.~(\ref{eq:g_Z_W}),
\begin{align}
    \mathcal{H}_{\mathbf{S}} &= \mathcal{V}_{\mathbf{S}}^\perp = \{\mathbf{W} \in T_{\mathbf{S}}\mathbb{O}(d)^m: \text{Tr}(\mathbf{Z}^T\mathbf{W}) = 0 \text{ for all } \mathbf{Z} \in \mathcal{V}_{\mathbf{S}}\}\\
    &= \left\{[\mathbf{S}_i\boldsymbol{\Omega}_i]_1^m: \boldsymbol{\Omega}_i \in \Skew(d) \text{ and }\text{Tr}\left(\boldsymbol{\Omega}^T\left(\sum_1^m\boldsymbol{\Omega}_i\right)\right) = 0 \text{ for all } \boldsymbol{\Omega}\in \Skew(d)\right\}\\
    &= \left\{[\mathbf{S}_i\boldsymbol{\Omega}_i]_1^m, \boldsymbol{\Omega}_i \in \Skew(d), \sum_1^m \boldsymbol{\Omega}_i \in \Sym(d)\right\}\\
    &= \left\{[\mathbf{S}_i\boldsymbol{\Omega}_i]_1^m, \boldsymbol{\Omega}_i \in \Skew(d), \sum_1^m \boldsymbol{\Omega}_i= 0\right\}.
\end{align}

Finally, since the horizontal space $\mathcal{H}_{\mathbf{S}}$ is the orthogonal complement to the vertical space $\mathcal{V}_{\mathbf{S}}$ in $T_{\mathbf{S}}\mathbb{O}(d)^m$, Eq.~(\ref{eq:P^h_S}) follows trivially.\hfill$\blacksquare$

\proofof{Proposition~\ref{prop:hlift_char}}
By Eq.~(\ref{eq:hlift_def}), for each $i \in [1,m-1]$ we obtain,
\begin{align}
    \lim_{t \rightarrow 0}\frac{\pi(\mathbf{S}+t\mathbf{Z})_i-\pi(\mathbf{S})_i}{t} = \widetilde{\mathbf{Z}}_i \implies \mathbf{S}_{i+1}\mathbf{Z}_1^T + \mathbf{Z}_{i+1}\mathbf{S}_1^T = \widetilde{\mathbf{Z}}_i. \label{lifted_vec}
\end{align}
Since $T_{\widetilde{\mathbf{S}}}\mathbb{O}(d)^m/\sim$ is identified with $T_{\widetilde{\mathbf{S}}}\mathbb{O}(d)^{m-1}$, therefore there exist $(\widetilde{\boldsymbol{\Omega}}_i)_1^{m-1} \subseteq \Skew(d)$, such that $\widetilde{\mathbf{Z}}_i = \widetilde{\mathbf{S}}_i\widetilde{\boldsymbol{\Omega}}_i$. Also, since $\mathbf{Z} \in \mathcal{H}_{\mathbf{S}}$, there exist $(\boldsymbol{\Omega}_i)_1^m \subseteq \Skew(d)$ such that $\sum_1^m \boldsymbol{\Omega}_i = 0$ and $\mathbf{Z}_i=\mathbf{S}_i\boldsymbol{\Omega}_i$. Substituting $\widetilde{\mathbf{Z}}_i = \widetilde{\mathbf{S}}_i\widetilde{\boldsymbol{\Omega}}_i$ and $\mathbf{Z}_i=\mathbf{S}_i\boldsymbol{\Omega}_i$ in the above equation, we obtain
\begin{align}
    \mathbf{S}_{i+1}\boldsymbol{\Omega}_1^T\mathbf{S}_1^T + \mathbf{S}_{i+1}\boldsymbol{\Omega}_{i+1}\mathbf{S}_1^T = \widetilde{\mathbf{S}}_i\widetilde{\boldsymbol{\Omega}}_i \implies \boldsymbol{\Omega}_{i+1}-\boldsymbol{\Omega}_1 = \mathbf{S}_{1}^T\widetilde{\boldsymbol{\Omega}}_i\mathbf{S}_{1}, i \in [1,m-1], \label{eq:eq1_}
\end{align}
where we used the fact that $\widetilde{\mathbf{S}}_i = \mathbf{S}_{i+1}\mathbf{S}_1^T$. It is easy to see that the linear system of equations in $[\boldsymbol{\Omega}_i]_1^m$ is of full rank. Summation over $i$ from $1$ to $m-1$ and using $\sum_1^m \mathbf{\Omega}_i = 0$ gives Eq.~(\ref{eq:hlift1}) and (\ref{eq:hlifti}).\hfill$\blacksquare$

\proofof{Proposition~\ref{prop:g_tilde}}
It suffices to show that $g(\mathbf{Z}, \mathbf{W})$ does not depend on the choice of $\mathbf{S} \in \pi^{-1}(\widetilde{\mathbf{S}})$. Let $\{\widetilde{\mathbf{U}}_i,\widetilde{\mathbf{V}}_i\}_1^{m-1},\{\mathbf{U}_i,\mathbf{V}_i\}_1^m$ be elements of $\Skew(d)$ such that $\widetilde{\mathbf{Z}}_i = \widetilde{\mathbf{S}}_i\widetilde{\mathbf{U}}_i$, $\widetilde{\mathbf{W}}_i = \widetilde{\mathbf{S}}_i\widetilde{\mathbf{V}}_i$, $\mathbf{Z}_i = \mathbf{S}_i\mathbf{U}_i$ and $\mathbf{W}_i = \mathbf{S}_i\mathbf{V}_i$. By the definition of $\mathcal{H}_{\mathbf{S}}$, $\sum_1^m\mathbf{U}_i = \sum_1^m \mathbf{V}_i = 0$ and the relation between $\mathbf{U}_i$ and $\widetilde{\mathbf{U}}_i$, and $\mathbf{V}_i$ and $\widetilde{\mathbf{V}}_i$ is given by Eq.~(\ref{eq:hlift1}, \ref{eq:hlifti}) (through Eq.~(\ref{eq:eq1_})). Then we have
\begin{align}
    &g(\mathbf{Z}, \mathbf{W})\\
    &= \sum_1^m \text{Tr}(\mathbf{Z}_i^T\mathbf{W}_i) = \sum_1^m \text{Tr}(\mathbf{U}_i^T\mathbf{V}_i) = \sum_1^m \text{Tr}((\mathbf{U}_i-\mathbf{U}_1)^T\mathbf{V}_i) + \text{Tr}(\mathbf{U}_1^T\mathbf{V}_i)\\
    &= \sum_1^m \text{Tr}((\mathbf{U}_i-\mathbf{U}_1)^T\mathbf{V}_i) = \sum_1^m \text{Tr}((\mathbf{U}_i-\mathbf{U}_1)^T(\mathbf{V}_i-\mathbf{V}_1)) + \text{Tr}((\mathbf{U}_i-\mathbf{U}_1)^T\mathbf{V}_1)\\
    &= \sum_1^{m-1} \text{Tr}((\mathbf{U}_{i+1}-\mathbf{U}_1)^T(\mathbf{V}_{i+1}-\mathbf{V}_1)) - \text{Tr}(\mathbf{U}_1^T\mathbf{V}_1) = \sum_1^{m-1}\text{Tr}(\widetilde{\mathbf{U}}_{i}^T\widetilde{\mathbf{V}}_{i}) - \text{Tr}(\mathbf{U}_1^T\mathbf{V}_1)\\
    &= \sum_1^{m-1}\text{Tr}(\widetilde{\mathbf{U}}_{i}^T\widetilde{\mathbf{V}}_{i}) - \frac{1}{m^2}\sum_{i,j=1}^{m-1}\text{Tr}(\widetilde{\mathbf{U}}_i^T\widetilde{\mathbf{V}}_j).
\end{align}
We observe that the last equation is independent of the choice of $\mathbf{S}$, therefore, the result follows.\hfill$\blacksquare$

\proofof{Proposition~\ref{prop:gradFS}}
Using Proposition~\ref{prop:T_SOdm} and \citeb[Section 3.6.2]{absil2009optimization},
\begin{align}
    \overline{\grad \widetilde{F}(\widetilde{\mathbf{S}})} &= \grad F(\mathbf{S}) = \mathbf{P}_{\mathbf{S}}(\nabla F(\mathbf{S})) = \mathbf{P}_{\mathbf{S}}(2\mathbf{C}\mathbf{S})\\
    &= [2\mathbf{S}_i\text{skew}(\mathbf{S}_i^T[\mathbf{C}\mathbf{S}]_i])]_1^m\\
    &= [\mathbf{C}\mathbf{S}]_i - \mathbf{S}_i[\mathbf{C}\mathbf{S}]_i^T\mathbf{S}_i\\
    &= \mathbf{S}_i (\mathbf{S}_i^T[\mathbf{C}\mathbf{S}]_i - [\mathbf{C}\mathbf{S}]_i^T\mathbf{S}_i).
\end{align}
Using the fact that $C$ is symmetric, the result follows. \hfill$\blacksquare$

\proofof{Proposition~\ref{prop:DgradFSZ}}
For each $i \in [1,m]$, 
\begin{align}
    &D\grad F(\mathbf{S})[\mathbf{Z}]_i\\
    &= \lim_{t \rightarrow 0}\frac{\grad F(\mathbf{S}+t\mathbf{Z})_i-\grad F(\mathbf{S})_i}{t}\\
    &= \lim_{t \rightarrow 0}\frac{([\mathbf{C}(\mathbf{S}+t\mathbf{Z})]_i - (\mathbf{S}_i+t\mathbf{Z}_i)[\mathbf{C}(\mathbf{S}+t\mathbf{Z})]_i^T(\mathbf{S}_i+t\mathbf{Z}_i)) - ([\mathbf{C}\mathbf{S}]_i - \mathbf{S}_i[\mathbf{C}\mathbf{S}]_i^T\mathbf{S}_i)}{t}\\
    &= [\mathbf{C}\mathbf{Z}]_i - \mathbf{S}_i[\mathbf{C}\mathbf{Z}]_i^T\mathbf{S}_i - \mathbf{S}_i[\mathbf{C}\mathbf{S}]_i^T\mathbf{Z}_i -\mathbf{Z}_i[\mathbf{C}\mathbf{S}]_i^T\mathbf{S}_i\\
    &= \mathbf{S}_i(\mathbf{S}_i^T[\mathbf{C}\mathbf{Z}]_i - [\mathbf{C}\mathbf{Z}]_i^T\mathbf{S}_i - [\mathbf{C}\mathbf{S}]_i^T\mathbf{Z}_i - \mathbf{S}_i^T\mathbf{Z}_i[\mathbf{C}\mathbf{S}]_i^T\mathbf{S}_i).
\end{align}
Note that we have not yet used the fact that $\widetilde{\mathbf{S}} \in \widetilde{\mathcal{C}}$ or equivalently, $[\mathbf{C}\mathbf{S}]_i = \mathbf{S}_i[\mathbf{C}\mathbf{S}]_i^T\mathbf{S}_i$ (see the proof of Proposition~\ref{prop:gradFS}) and $\mathbf{Z} \in T_{\mathbf{S}}\mathbb{O}(d)^m$ or equivalently, $\mathbf{S}_i^T\mathbf{Z}_i + \mathbf{Z}_i^T\mathbf{S}_i = 0$ (see Eq.~(\ref{eq:T_SOdm}) in Proposition~\ref{prop:T_SOdm}). Combining the two, we get $\mathbf{S}_i^T\mathbf{Z}_i[\mathbf{C}\mathbf{S}]_i^T\mathbf{S}_i = -\mathbf{Z}_i^T[\mathbf{C}\mathbf{S}]_i$ and the result follows.\hfill$\blacksquare$

\proofof{Proposition~\ref{prop:HessFSZ}}
Using Proposition~\ref{prop:T_SOdm}, \ref{prop:V_S_H_S} and \ref{prop:DgradFSZ}, and \citeb[Chapter 5]{absil2009optimization},
\begin{align}
    \overline{\Hess \widetilde{F}(\widetilde{\mathbf{S}})[\widetilde{\mathbf{Z}}]} &= \overline{\widetilde{\nabla}_{\widetilde{\mathbf{Z}}}\grad \widetilde{F}(\widetilde{\mathbf{S}})} = P^{h}_{\mathbf{S}}(\nabla_{\overline{\widetilde{\mathbf{Z}}}}\overline{\grad \widetilde{F}(\widetilde{\mathbf{S}})}) = P^{h}_{\mathbf{S}}(\nabla_{\mathbf{Z}}\grad F(\mathbf{S}))\\
    &= P^{h}_{\mathbf{S}}(P_{\mathbf{S}}(D\grad F(\mathbf{S})[\mathbf{Z}]))\\
    &= P^{h}_{\mathbf{S}}\left(\left[\mathbf{S}_i(\mathbf{S}_i^T[\mathbf{C}\mathbf{Z}]_i - [\mathbf{C}\mathbf{Z}]_i^T\mathbf{S}_i - [\mathbf{C}\mathbf{S}]_i^T\mathbf{Z}_i + \mathbf{Z}_i^T[\mathbf{C}\mathbf{S}]_i)\right]_1^m\right)\\
    &= P^h_{\mathbf{S}}([\mathbf{S}_i\widehat{\boldsymbol{\Omega}}_i]_1^m) = [\mathbf{S}_i(\widehat{\boldsymbol{\Omega}}_i-\overline{\widehat{\boldsymbol{\Omega}}})]_1^m
\end{align}
where
\begin{align}
    \overline{\widehat{\boldsymbol{\Omega}}} &= \frac{1}{m}\sum_1^m\widehat{\boldsymbol{\Omega}}_i = \frac{1}{m}\sum_1^m (\mathbf{S}_i^T[\mathbf{C}\mathbf{Z}]_i - [\mathbf{C}\mathbf{Z}]_i^T\mathbf{S}_i - [\mathbf{C}\mathbf{S}]_i^T\mathbf{Z}_i + \mathbf{Z}_i^T[\mathbf{C}\mathbf{S}]_i)\\
    &= \frac{1}{m}(\mathbf{S}^T\mathbf{C}\mathbf{Z}-\mathbf{Z}^T\mathbf{C}\mathbf{S}-\mathbf{S}^T\mathbf{C}\mathbf{Z}+\mathbf{Z}^T\mathbf{C}\mathbf{S}) = 0.
\end{align}
This validates that $\overline{\Hess \widetilde{F}(\widetilde{\mathbf{S}})[\widetilde{\mathbf{Z}}]} = [\mathbf{S}_i\widehat{\boldsymbol{\Omega}}_i]_1^m$ indeed lies in $\mathcal{H}_{\mathbf{S}}$ (see Proposition~\ref{prop:V_S_H_S}).\hfill$\blacksquare$

\proofof{Proposition~\ref{prop:Omega_hat_compact}}
Since $\mathbf{Z} \in \mathcal{H}_{\mathbf{S}}$, using Proposition~\ref{prop:V_S_H_S}, there exist $\boldsymbol{\Omega} = [\boldsymbol{\Omega}_i]_1^m$ such that $\boldsymbol{\Omega}_i \in \Skew(d)$, $\sum_1^m\boldsymbol{\Omega}_i = 0$ and $\mathbf{Z}_i = \mathbf{S}_i\boldsymbol{\Omega}_i$. Then
\begin{align}
    \widehat{\boldsymbol{\Omega}}_i &= (\mathbf{S}_i^T[\mathbf{C}\mathbf{Z}]_i - [\mathbf{C}\mathbf{Z}]_i^T\mathbf{S}_i) - ([\mathbf{C}\mathbf{S}]_i^T\mathbf{Z}_i - \mathbf{Z}_i^T[\mathbf{C}\mathbf{S}]_i)\\
    &= ([\mathbf{C}(\mathbf{S})\boldsymbol{\Omega}]_i - [\mathbf{C}(\mathbf{S})\boldsymbol{\Omega}]_i^T) - ( [\widehat{\mathbf{C}}(\mathbf{S})\boldsymbol{\Omega}]_i - [\widehat{\mathbf{C}}(\mathbf{S})\boldsymbol{\Omega}]_i^T)\\
    &= [\mathbf{L}(\mathbf{S})\boldsymbol{\Omega}]_i^T - [\mathbf{L}(\mathbf{S})\boldsymbol{\Omega}]_i.
\end{align}\hfill$\blacksquare$

\proofof{Proposition~\ref{prop:HessFSZZ}}
Using Proposition~\ref{prop:g_tilde}, \ref{prop:HessFSZ} and \ref{prop:Omega_hat_compact},
\begin{align}
    \widetilde{g}(\Hess \widetilde{F}(\widetilde{\mathbf{S}})[\widetilde{\mathbf{Z}}],\widetilde{\mathbf{Z}}) &= g(\overline{\Hess \widetilde{F}(\widetilde{\mathbf{S}})[\widetilde{\mathbf{Z}}]},\overline{\widetilde{\mathbf{Z}}}) = g(\overline{\Hess \widetilde{F}(\widetilde{\mathbf{S}})[\widetilde{\mathbf{Z}}]},\mathbf{Z})\\
    &= \sum_{1}^{m}\text{Tr}((\mathbf{S}_i\widehat{\boldsymbol{\Omega}}_i)^T(\mathbf{S}_i\boldsymbol{\Omega}_i)) = \sum_{1}^{m}\text{Tr}(\widehat{\boldsymbol{\Omega}}_i^T\boldsymbol{\Omega}_i)\\
    &= \sum_{1}^{m}\text{Tr}([\mathbf{L}(\mathbf{S})\boldsymbol{\Omega}]_i\boldsymbol{\Omega}_i - [\mathbf{L}(\mathbf{S})\boldsymbol{\Omega}]_i^T\boldsymbol{\Omega}_i)\\
    &= -2\text{Tr}(\boldsymbol{\Omega}^T\mathbf{L}(\mathbf{S})\boldsymbol{\Omega})
\end{align}\hfill$\blacksquare$

\proofof{Proposition~\ref{prop:Omega^TLSOmega2}}
Using the fact that $\vecz (\mathbf{A}\mathbf{X}\mathbf{B}) = (\mathbf{B}^T \otimes \mathbf{A})\vecz (\mathbf{X})$,
\begin{align}
    \text{Tr}(\boldsymbol{\Omega}^T\mathbf{L}(\mathbf{S})\boldsymbol{\Omega}) &= \text{Tr}((\mathbf{P}\boldsymbol{\Omega})^T\mathbf{P}\mathbf{L}(\mathbf{S})\mathbf{P}^T(\mathbf{P}\boldsymbol{\Omega}))\\
    &= \vecz (\mathbf{P}\boldsymbol{\Omega})^T\vecz (\mathcal{L}(\mathbf{S}) (\mathbf{P}\boldsymbol{\Omega}))\\
    &= \vecz (\mathbf{P}\boldsymbol{\Omega})^T(\mathbf{I}_d \otimes \mathcal{L}(\mathbf{S}))\vecz (\mathbf{P}\boldsymbol{\Omega})\\
    &= \boldsymbol{\boldsymbol{\omega}}^T\overline{\mathbf{P}}(\mathbf{I}_d \otimes \mathcal{L}(\mathbf{S}))\overline{\mathbf{P}}^T\boldsymbol{\boldsymbol{\omega}}\\
    &= \boldsymbol{\boldsymbol{\omega}}^T\mathbb{L}(\mathbf{S})\boldsymbol{\boldsymbol{\omega}}.
\end{align}\hfill$\blacksquare$

\proofof{Theorem~\ref{thm:non_deg_loc_min}}
$1$, $2$ and $3$ are equivalent by definitions and Proposition~\ref{prop:HessFSZZ}. For ($3 \iff 4$), by comparing dimensions, we note that the set of $\boldsymbol{\Omega} = [\boldsymbol{\Omega}_i]_1^m$ where $\boldsymbol{\Omega}_i \in \Skew(d)$ and $\sum_1^m \boldsymbol{\Omega}_i = 0$, is the same as the set of $\boldsymbol{\Omega} = [\boldsymbol{\Omega}_i-\boldsymbol{\Omega}_0]_1^m$ where $\boldsymbol{\Omega}_i \in \Skew(d)$ and $\boldsymbol{\Omega}_0 = \frac{1}{m}\sum_1^m\boldsymbol{\Omega}_i$. Using Remark~\ref{rmk:C_hat_L_structure}, we know that $\mathbf{L}(\mathbf{S})=\mathbf{L}(\mathbf{S})^T$ and $\mathbf{L}(\mathbf{S})[\boldsymbol{\Omega}_0]_1^m = 0$. Thus $(\boldsymbol{\Omega}-[\boldsymbol{\Omega}_0]_1^m)^T\mathbf{L}(\mathbf{S})(\boldsymbol{\Omega}-[\boldsymbol{\Omega}_0]_1^m) = \boldsymbol{\Omega}^T\mathbf{L}(\mathbf{S})\boldsymbol{\Omega}$ and the result follows.

($4 \iff 5$): follows directly from the definition of $\boldsymbol{\boldsymbol{\omega}}$ and Proposition~\ref{prop:Omega^TLSOmega2}.

($5 \iff 6$): follows from Remark~\ref{rmk:mathbb_L_structure}.\hfill$\blacksquare$

\proofof{Proposition~\ref{prop:one_all1}}
It suffices to pick conditions 4 and 6 (one involving $\mathbf{L}(\mathbf{S})$ and one involving $\mathbb{L}(\mathbf{S})$). Suppose $\mathbf{L}(\mathbf{S})$ satisfies condition 4 and let $\boldsymbol{\Omega}$ be as described in the condition. Then using Remark~\ref{rmk:C_hat_L_structure},
\begin{align}
    \text{Tr}(\boldsymbol{\Omega}^T\mathbf{L}(\mathbf{S}\mathbf{\mathbf{Q}})\boldsymbol{\Omega}) &= \text{Tr}(\boldsymbol{\Omega}^T(\mathbf{I}_m \otimes \mathbf{Q})^T\mathbf{L}(\mathbf{S})(\mathbf{I}_m \otimes \mathbf{Q})\boldsymbol{\Omega})\\
    &= \text{Tr}(\mathbf{Q}\boldsymbol{\Omega}^T(\mathbf{I}_m \otimes \mathbf{Q})^T\mathbf{L}(\mathbf{S})(\mathbf{I}_m \otimes \mathbf{Q})\boldsymbol{\Omega} \mathbf{Q}^T)\\
    &= \text{Tr}(\overline{\boldsymbol{\Omega}}^T \mathbf{L}(\mathbf{S})\overline{\boldsymbol{\Omega}}) < 0
\end{align}
because $\overline{\boldsymbol{\Omega}}_i = \mathbf{Q}\boldsymbol{\Omega}_i\mathbf{Q}^T \in \Skew(d)$ for all $i \in [1,m]$ and not all $\overline{\boldsymbol{\Omega}}_i$ are equal (if $\overline{\boldsymbol{\Omega}}_i = \overline{\boldsymbol{\Omega}}_j$ then $\boldsymbol{\Omega}_i = \boldsymbol{\Omega}_j$, a contradiction). Thus the condition 4 holds for $\mathbf{S}\mathbf{Q}$ too.

Now, suppose $\mathbb{L}(\mathbf{S})$ satisfy condition 6. Then using Remark~\ref{rmk:mathbb_L_structure}, we conclude that $\mathbf{S}\mathbf{Q}$ also satisfies condition 6.\hfill$\blacksquare$

\proofof{Corollary~\ref{cor:suff_non_deg_loc_min}}
Since the rank of $\mathbf{L}(\mathbf{S})$ is $(m-1)d$, using Remark~\ref{rmk:C_hat_L_structure}, $\mathbf{L}(\mathbf{S})[\boldsymbol{\Omega}_i]_1^m = 0$ (equivalently, $\text{Tr}(([\boldsymbol{\Omega}_i]_1^m)^T\mathbf{L}(\mathbf{S})[\boldsymbol{\Omega}_i]_1^m) = 0$) if and only if $\boldsymbol{\Omega}_i = \boldsymbol{\Omega}_0$ for all $i \in [1,m]$ and for some $\boldsymbol{\Omega}_0 \in \Skew(d)$. Thus the condition~$4$ in Theorem~\ref{thm:non_deg_loc_min} is satisfied. \hfill$\blacksquare$

\proofof{Theorem~\ref{thm:non_deg_two_views_gen_setting}} The proof is divided into three parts specialized to the three conditions in the statement.

\textbf{Part 1}. First note that $\mathbf{S} \in \mathcal{C}$ if and only if $\mathbf{S}_i^T[\mathbf{C}\mathbf{S}]_i = [\mathbf{C}\mathbf{S}]_i^T\mathbf{S}_i$ for $i = 1,2$ (see Eq.~(\ref{eq:crit_pts2})). Since $\mathbf{S}_1^T[\mathbf{C}\mathbf{S}]_1 - [\mathbf{C}\mathbf{S}]_1^T\mathbf{S}_1 =  [\mathbf{C}\mathbf{S}]_2^T\mathbf{S}_2 - \mathbf{S}_2^T[\mathbf{C}\mathbf{S}]_2$ and
\begin{align}
    \mathbf{S}_1^T[\mathbf{C}\mathbf{S}]_1 - [\mathbf{C}\mathbf{S}]_1^T\mathbf{S}_1 &= \mathbf{S}_1^T\mathbf{B}_1\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}_2^T\mathbf{S}_2 - \mathbf{S}_2^T\mathbf{B}_2\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}_1^T\mathbf{S}_1\\
    &= \mathbf{B}(\mathbf{S})_1\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_2^T- \mathbf{B}(\mathbf{S})_2\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_1^T,
\end{align}
thus $\mathbf{S} \in \mathcal{C}$ if and only if $\mathbf{B}(\mathbf{S})_1\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_2^T$ is symmetric. At this point, we note that the forms of $\mathbf{B}(\mathbf{S})_{1}$ and $\mathbf{B}(\mathbf{S})_{2}$ are
\begin{align}
    \begin{matrix}
        \mathbf{B}(\mathbf{S})_1 & = & [ & \mathbf{X}_1 & \mathbf{0}_{d \times n_2} & \mathbf{X}_3 & -(\mathbf{X}_1\mathbf{1}_{n_1} + \mathbf{X}_3\mathbf{1}_{n_3}) & \mathbf{0}_{d} & ]\\
        \mathbf{B}(\mathbf{S})_2 & = & [ & \mathbf{0}_{d \times n_1} & \mathbf{Y}_2 & \mathbf{Y}_3 & \mathbf{0}_{d} & -(\mathbf{Y}_2\mathbf{1}_{n_2} + \mathbf{Y}_3\mathbf{1}_{n_3}) & ]
    \end{matrix}
\end{align}
where (see Remark~\ref{rmk:L0DB}) $\mathbf{X}_1 \in \mathbb{R}^{d \times n_1}$ and $\mathbf{X}_3 \in \mathbb{R}^{d \times n_3}$ correspond to the local coordinates, due to the first view, of the $n_1$ points that lie exclusively in the first view and the $n_3$ points that lie on the overlap of both views, respectively. Similarly, $\mathbf{Y}_2 \in \mathbb{R}^{d \times n_2}$ and $\mathbf{Y}_3 \in \mathbb{R}^{d \times n_3}$ correspond to the local coordinates, due to the second view, of the $n_2$ points that lie exclusively in the second view and the $n_3$ points which lie on the overlap of both views, respectively. In particular, $\mathbf{X}_3 = \mathbf{B}(\mathbf{S})_{1,2}$ and $\mathbf{Y}_3 = \mathbf{B}(\mathbf{S})_{2,1}$ (perhaps after permuting the points). Moreover,
\begin{align}
    \boldsymbol{\mathcal{L}}_{\Gamma} &= \begin{bmatrix}
    \mathbf{I}_{n_1} & & & -\mathbf{1}_{n_1} & \mathbf{0}_{n_1}\\
     & \mathbf{I}_{n_2} & & \mathbf{0}_{n_2} & -\mathbf{1}_{n_2}\\
    &  & 2\mathbf{I}_{n_3} & -\mathbf{1}_{n_3} & -\mathbf{1}_{n_3}\\
    -\mathbf{1}_{n_1}^T & \mathbf{0}_{n_2}^T & -\mathbf{1}_{n_3}^T & n_1+n_3 & \\
    \mathbf{0}_{n_1}^T & -\mathbf{1}_{n_2}^T & -\mathbf{1}_{n_3}^T &  & n_2+n_3\end{bmatrix}.
\end{align}
Through simple calculations, we obtain
\begin{align}
    \boldsymbol{\mathcal{L}}_{\Gamma}^\dagger &= \frac{1}{2n_3}\begin{bmatrix}
    2n_3\mathbf{I}_{n_1} + \mathbf{1}_{n_1}\mathbf{1}_{n_1}^T & -\mathbf{1}_{n_1}\mathbf{1}_{n_2}^T & & \mathbf{1}_{n_1} & -\mathbf{1}_{n_1}\\
    -\mathbf{1}_{n_2}\mathbf{1}_{n_1}^T & 2n_3\mathbf{I}_{n_2} + \mathbf{1}_{n_2}\mathbf{1}_{n_2}^T & & -\mathbf{1}_{n_2} & \mathbf{1}_{n_2}\\
    &  & n_3\mathbf{I}_{n_3} &  & \\
    \mathbf{1}_{n_1}^T & -\mathbf{1}_{n_2}^T &  & 1 & -1\\
    -\mathbf{1}_{n_1}^T & \mathbf{1}_{n_2}^T & &  -1 & 1\end{bmatrix}.
\end{align}
Thus,
\begin{align}
    \mathbf{B}(\mathbf{S})_1\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger = \begin{bmatrix}\mathbf{X}_1 - \frac{\mathbf{X}_3\mathbf{1}_{n_3}\mathbf{1}_{n_1}^T}{2n_3}, & \frac{\mathbf{X}_3\mathbf{1}_{n_3}\mathbf{1}_{n_2}^T}{2n_3}, & \frac{1}{2}\mathbf{X}_3, & -\frac{\mathbf{X}_3\mathbf{1}_{n_3}}{2n_3}, & \frac{\mathbf{X}_3\mathbf{1}_{n_3}}{2n_3} \end{bmatrix}
\end{align}
and (since $\mathbf{S} \in \mathcal{C}$ and part (i) of the proof),
\begin{align}
    \mathbf{B}(\mathbf{S})_2\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_1^T &= \mathbf{B}(\mathbf{S})_1\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_2^T\\
    %&= \begin{bmatrix}\mathbf{X}_1 - \frac{\mathbf{X}_3\mathbf{1}_{n_3}\mathbf{1}_{n_1}^T}{2n_3} & \frac{\mathbf{X}_3\mathbf{1}_{n_3}\mathbf{1}_{n_2}^T}{2n_3} & \frac{1}{2}\mathbf{X}_3 & -\frac{\mathbf{X}_3\mathbf{1}_{n_3}}{2n_3} & \frac{\mathbf{X}_3\mathbf{1}_{n_3}}{2n_3} \end{bmatrix}\begin{bmatrix}0 \\ \mathbf{Y}_2^T \\ \mathbf{Y}_3^T \\ 0 \\ -(\mathbf{1}_{n_2}^T\mathbf{Y}_2^T + \mathbf{1}_{n_3}^T\mathbf{Y}_3^T)\end{bmatrix}\\
    &= \frac{1}{2}\mathbf{X}_3\left(\mathbf{I}_{n_3}-\frac{1}{n_3}\mathbf{1}_{n_3}\mathbf{1}_{n_3}^T\right)\mathbf{Y}_3^T\\
    &= \frac{1}{2}\mathbf{B}(\mathbf{S})_{1,2}\left(\mathbf{I}_{n_3}-\frac{1}{n_3}\mathbf{1}_{n_3}\mathbf{1}_{n_3}^T\right)\left(\mathbf{I}_{n_3}-\frac{1}{n_3}\mathbf{1}_{n_3}\mathbf{1}_{n_3}^T\right)^T\mathbf{B}(\mathbf{S})_{2,1}^T\\
    &= \frac{1}{2}\overline{\mathbf{B}(\mathbf{S})}_{1,2}\overline{\mathbf{B}(\mathbf{S})}_{2,1}^T
\end{align}
Combining the above equations, we conclude that $\mathbf{S} \in \mathcal{C}$ if and only if $\overline{\mathbf{B}(\mathbf{S})}_{1,2}\overline{\mathbf{B}(\mathbf{S})}_{2,1}^T$ is symmetric. 

\textbf{Part 2}. For $\mathbf{S} \in \mathcal{C}$, from the Remark~\ref{rmk:C_hat_L_structure} and Part 1, we have,
\begin{align}
    \mathbf{L}(\mathbf{S}) &= \begin{bmatrix}
    -\mathbf{B}(\mathbf{S})_1\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_2^T & \mathbf{B}(\mathbf{S})_1\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_2^T\\
    \mathbf{B}(\mathbf{S})_2\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_1^T & -\mathbf{B}(\mathbf{S})_2\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_1^T
    \end{bmatrix}\\
    &= \begin{bmatrix}
    -\mathbf{B}(\mathbf{S})_1\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_2^T & \mathbf{B}(\mathbf{S})_1\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_2^T\\
    \mathbf{B}(\mathbf{S})_1\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_2^T & -\mathbf{B}(\mathbf{S})_1\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_2^T
    \end{bmatrix}. \label{eq:LS_two_views}
\end{align}
Let $\boldsymbol{\Omega}_1,\boldsymbol{\Omega}_2 \in \Skew(d)$ such that $\boldsymbol{\Omega}_1 + \boldsymbol{\Omega}_2 = 0$. Then, using the above equations,
\begin{align}
    \text{Tr}\left(\begin{bmatrix}
        \boldsymbol{\Omega}_1^T & \boldsymbol{\Omega}_2^T
    \end{bmatrix} \mathbf{L}(\mathbf{S}) \begin{bmatrix}
        \boldsymbol{\Omega}_1\\\boldsymbol{\Omega}_2
    \end{bmatrix}\right) &= \text{Tr}\left(\begin{bmatrix}
        -\boldsymbol{\Omega}_1 & \boldsymbol{\Omega}_1
    \end{bmatrix} \mathbf{L}(\mathbf{S}) \begin{bmatrix}
        \boldsymbol{\Omega}_1\\-\boldsymbol{\Omega}_1\\
    \end{bmatrix}\right)\\
    &= -2 \text{Tr}(\boldsymbol{\Omega}_1^T\overline{\mathbf{B}(\mathbf{S})}_{1,2}\overline{\mathbf{B}(\mathbf{S})}_{2,1}^T\boldsymbol{\Omega}_1).
\end{align}
Combining the above equation and Part 1 with Proposition~\ref{prop:HessFSZZ}, we conclude that $\pi(\mathbf{S})$ is a local minimum of $\widetilde{F}$ if and only if the first two conditions of the statement are met.

\textbf{Part 3}. Here we deal with the non-degeneracy of $\widetilde{\mathbf{S}} = \pi(\mathbf{S})$. For $d=1$, $\widetilde{\mathbf{S}}$ is trivially non-degenerate. So we assume that $d \geq 2$. From Part 2, we note that for $\boldsymbol{\Omega}_1,\boldsymbol{\Omega}_2 \in \Skew(d)$ such that $\boldsymbol{\Omega}_1 + \boldsymbol{\Omega}_2 = 0$, $\mathbf{L}(\mathbf{S})[\boldsymbol{\Omega}_i]_1^2 = 0$ if and only if $\overline{\mathbf{B}(\mathbf{S})}_{1,2}\overline{\mathbf{B}(\mathbf{S})}_{2,1}^T\boldsymbol{\Omega} = 0$. Thus $\widetilde{\mathbf{S}}$ is non-degenerate if and only if $\overline{\mathbf{B}(\mathbf{S})}_{1,2}\overline{\mathbf{B}(\mathbf{S})}_{2,1}^T\boldsymbol{\Omega} = 0 \iff \boldsymbol{\Omega} = 0$. It suffices to show that $\overline{\mathbf{B}(\mathbf{S})}_{1,2}\overline{\mathbf{B}(\mathbf{S})}_{2,1}^T\boldsymbol{\Omega} = 0$  if and only if $\rank (\overline{\mathbf{B}(\mathbf{S})}_{1,2}\overline{\mathbf{B}(\mathbf{S})}_{2,1}^T) \geq d-1$.

($\impliedby$) Suppose $\rank (\overline{\mathbf{B}(\mathbf{S})}_{1,2}\overline{\mathbf{B}(\mathbf{S})}_{2,1}^T) \geq d-1$ then the null space of $\overline{\mathbf{B}(\mathbf{S})}_{1,2}\overline{\mathbf{B}(\mathbf{S})}_{2,1}^T$ is at most one-dimensional. Moreover, rank of a non-zero skew symmetric matrix of size $d \geq 2$, is at least two. Thus $\overline{\mathbf{B}(\mathbf{S})}_{1,2}\overline{\mathbf{B}(\mathbf{S})}_{2,1}^T\boldsymbol{\Omega} = 0 \iff \boldsymbol{\Omega} = 0$. We conclude that $\mathbf{L}(\mathbf{S})$ has trivial certificates only, and thus $\widetilde{\mathbf{S}}$ is non-degenerate.

$(\implies)$ Suppose $\rank (\overline{\mathbf{B}(\mathbf{S})}_{1,2}\overline{\mathbf{B}(\mathbf{S})}_{2,1}^T) \leq d-2$, then there exist non-zero vectors $\mathbf{u},\mathbf{v} \in \mathbb{R}^d$ in the kernel of $\overline{\mathbf{B}(\mathbf{S})}_{1,2}\overline{\mathbf{B}(\mathbf{S})}_{2,1}^T$ such that $\mathbf{u}^T\mathbf{v} = 0$. Let $\boldsymbol{\Omega} = \mathbf{u}\mathbf{v}^T - \mathbf{v}\mathbf{u}^T$ then clearly $\boldsymbol{\Omega} \in \Skew(d)$, $\boldsymbol{\Omega} \neq 0$ and $\overline{\mathbf{B}(\mathbf{S})}_{1,2}\overline{\mathbf{B}(\mathbf{S})}_{2,1}^T\boldsymbol{\Omega} = 0$. \hfill$\blacksquare$

\proofof{Theorem~\ref{thm:uniq_two_views_gen_setting}}
Let $\mathbf{S}$ be an optimal alignmrnt i.e. a global minimum of $F$, then from the proof of Theorem~\ref{thm:non_deg_two_views_gen_setting} we have
\begin{align}
    \mathbf{C}(\mathbf{S})_{1,2} = -\mathbf{B}(\mathbf{S})_1\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_2^T = -\frac{1}{2}\mathbf{S}_1^T\overline{\mathbf{B}}_{1,2}\overline{\mathbf{B}}_{2,1}^T\mathbf{S}_2 .%= \frac{1}{2}\mathbf{S}_2^T\overline{\mathbf{B}}_{2,1}\overline{\mathbf{B}}_{1,2}^T\mathbf{S}_1 = \mathbf{B}(\mathbf{S})_2\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_1^T = \mathbf{C}(\mathbf{S})_{21}.
\end{align}
Then note that the minimizer of $\text{Tr}(\mathbf{C}\mathbf{S}\mathbf{S}^T)$ is same as the minimizer of $\text{Tr}(\mathbf{C}(\mathbf{S})_{1,2})$ because $\mathbf{S}_1\mathbf{S}_1^T = \mathbf{S}_2\mathbf{S}_2^T = \mathbf{I}_d$ and $\mathbf{C}_{2,1} = \mathbf{C}_{1,2}^T$ is symmetric. WLOG, take $\mathbf{S}_1 = \mathbf{I}_d$. Then it suffices to show that the following problem has unique solution
\begin{align}
    \min_{\mathbf{S}_2\in\mathbb{O}(d)}\text{Tr}(\mathbf{C}(\mathbf{S})_{12}) = -\frac{1}{2}\max_{\mathbf{S}_2\in\mathbb{O}(d)} \text{Tr}(\overline{\mathbf{B}}_{1,2}\overline{\mathbf{B}}_{2,1}^T\mathbf{S}_2)
\end{align}
if and only if $\rank (\overline{\mathbf{B}}_{1,2}\overline{\mathbf{B}}_{2,1}^T) = d$.

Let $\overline{\mathbf{B}}_{1,2}\overline{\mathbf{B}}_{2,1}^T = \mathbf{U}\mathbf{\Sigma}\mathbf{V}^T$ be its singular value decomposition. Note that $\mathbf{\Sigma} \succeq 0$. If $\rank (\overline{\mathbf{B}}_{1,2}\overline{\mathbf{B}}_{2,1}^T) = d$ then $\mathbf{\Sigma} \succ 0$ and clearly, the unique optimizer is $\mathbf{S}_2=\mathbf{V}\mathbf{U}^T$. If $\rank (\overline{\mathbf{B}}_{1,2}\overline{\mathbf{B}}_{2,1}^T) \leq d-1$ then there exist orthogonal matrix $\mathbf{U}' \neq \mathbf{I}_d$ such that $\boldsymbol{\Sigma} = \mathbf{U}'\boldsymbol{\Sigma}$ and thus $\mathbf{V}\mathbf{U}^T \neq \mathbf{V}(\mathbf{U}'\mathbf{U})^T$ are both optimizers of the above objective. \hfill$\blacksquare$

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Section 4 Proofs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\proofof{Proposition~\ref{prop:noiseless_setting1}}
Since $\mathbf{S}$ is a perfect alignment $F(\mathbf{S}) = \text{Tr}(\mathbf{C}\mathbf{S}\mathbf{S}^T) = 0$. Since $\mathbf{C} \succeq 0$, the columns of $\mathbf{S}$ lie in the kernel of $\mathbf{C}$. In particular $\mathbf{C}\mathbf{S} = \mathbf{0}$. It follows that $\widehat{\mathbf{C}}(\mathbf{S}) = \mathbf{0}$ (see Eq.~(\ref{eq:C_hat})). We conclude that $\mathbf{L}(\mathbf{S}) = -\mathbf{C}(\mathbf{S})$.\hfill$\blacksquare$

\proofof{Theorem~\ref{thm:loc_rigid}}
First note that under Assumption~\ref{assump:non_deg_views}, the equation $\Theta(\mathbf{O}) = \Theta(\mathbf{S}\mathbf{Q})$ in Definition~\ref{def:loc_rigid} is equivalent to $\pi(\mathbf{S}) = \pi(\mathbf{O})$.

($\impliedby$) Suppose $\mathbf{S}$ is a degenerate perfect alignment. Thus $\pi(\mathbf{S})$ is degenerate (see Definition~\ref{def:non_deg_alignment0}). Let $\epsilon > 0$ be arbitrary and define
\begin{align}
    \eta \coloneqq \left\|\mathbf{B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger(:,1:n)\left(\mathbf{I}_n - n^{-1}\mathbf{1}_{n}\mathbf{1}_{n}^T\right)\right\|_F.
\end{align}
Then there exists another perfect alignment $\mathbf{O} \in \mathbb{O}(d)^m$ such that $\left\|\mathbf{S}-\mathbf{O}\right\|_F < \epsilon / \eta$ and $\pi(\mathbf{S}) \neq \pi(\mathbf{O})$. Due to Assumption~\ref{assump:non_deg_views}, we have $\Theta(\mathbf{O}) \neq \Theta(\mathbf{S}\mathbf{Q})$ for any $\mathbf{Q} \in \mathbb{O}(d)$, however, (from Definition~\ref{def:realization}),
\begin{align}
    \left\|\Theta(\mathbf{O})-\Theta(\mathbf{S})\right\|_F \leq \left\|\mathbf{S}-\mathbf{O}\right\|_F\left\|\mathbf{B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger(:,1:n)\left(\mathbf{I}_n - n^{-1}\mathbf{1}_{n}\mathbf{1}_{n}^T\right)\right\|_F < \eta\left\|\mathbf{S}-\mathbf{O}\right\|_F < \epsilon.
\end{align}
Since $\epsilon$ is arbitrary, we conclude that $\Theta(\mathbf{S})$ is not locally rigid.

($\implies$) Let $\epsilon > 0$ be arbitrary. Suppose $\Theta(\mathbf{S})$ is not locally rigid, then there exist another perfect alignment $\mathbf{O}_\epsilon \in \mathbb{O}(d)^m$ such that $\left\|\Theta(\mathbf{O}_\epsilon)-\Theta(\mathbf{S})\right\|_F < \epsilon$ but $\Theta(\mathbf{O}_\epsilon) \neq \Theta(\mathbf{S}\mathbf{Q})$, equivalently $\left\|\mathbf{O}_\epsilon-\mathbf{S}\right\|_F < \epsilon$ but $\pi(\mathbf{O}_\epsilon) \neq \pi(\mathbf{S})$. Since this true for all $\epsilon > 0$, we conclude that $\pi(\mathbf{S})$ is degenerate.\hfill$\blacksquare$

\proofof{Theorem~\ref{thm:nec_cond_loc_rigid_of_views}}
Consider a partition of $[1,m]$ into two non-empty subsets $A$ and $B$. Suppose rank of $\overline{\mathbf{B}(\mathbf{S})}_{A, B}$ is at most $d-2$. Let $\boldsymbol{\Omega}_0 \in \Skew(d)$ be such that $\boldsymbol{\Omega}_0 \neq 0$ and $\overline{\mathbf{B}(\mathbf{S})}_{A,B}^T\boldsymbol{\Omega}_0 = 0$ (the existence of $\boldsymbol{\Omega}_0$ follows from the third part of the proof of Theorem~\ref{thm:non_deg_two_views_gen_setting}). WLOG assume that $\mathbf{B}(\mathbf{S})_{A,B}\mathbf{1}_{n'} = 0$ (here $n'$ is as in Definition~\ref{def:BSAcapB}) (perhaps by translating all aligned views by $-\mathbf{B}(\mathbf{S})_{A,B}\mathbf{1}_{n'}$). Then $\mathbf{B}(\mathbf{S})_{A,B}^T\boldsymbol{\Omega}_0 = 0$.

Let $\boldsymbol{\Omega} = [\boldsymbol{\Omega}_i]_1^m$ be such that $\boldsymbol{\Omega}_i = \boldsymbol{\Omega}_0$ for $i \in A$ and $\boldsymbol{\Omega}_i = -\boldsymbol{\Omega}_0$ for $i \in B$. Clearly, $\boldsymbol{\Omega} \in \Skew(d)^m$ such that not all $\boldsymbol{\Omega}_i$ are equal. It suffices to show that $\boldsymbol{\Omega}$ is a nontrivial certificate of $\mathbf{L}(\mathbf{S})$, equivalently $\text{Tr}(\boldsymbol{\Omega}^T\mathbf{L}(\mathbf{S})\boldsymbol{\Omega}) = 0$.
 
 For $i \in A$,
\begin{align}
    [\mathbf{L}(\mathbf{S}) \boldsymbol{\Omega}]_i &= (-\mathbf{B}(\mathbf{S})_i\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})^T\mathbf{I}^m_d + \sum_{j \in A}\mathbf{B}(\mathbf{S})_i\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_j^T - \sum_{j \in B}\mathbf{B}(\mathbf{S})_i\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_j^T)\boldsymbol{\Omega}_0\\
    &= -2 \sum_{j \in B}\mathbf{B}(\mathbf{S})_i\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_j^T \boldsymbol{\Omega}_0
\end{align}
and similarly, for $i \in B$
\begin{align}
    [\mathbf{L}(\mathbf{S}) \boldsymbol{\Omega}]_i &= 2 \sum_{j \in A}\mathbf{B}(\mathbf{S})_i\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}(\mathbf{S})_j^T \boldsymbol{\Omega}_0.
\end{align}
Denote by $\mathbf{B}_A$ and $\mathbf{B}_B$, the matrices $\sum_{i \in A}\mathbf{B}(\mathbf{S})_i$ and $\sum_{j \in B}\mathbf{B}(\mathbf{S})_j$, respectively. Thus,
\begin{align}
    \text{Tr}(\boldsymbol{\Omega}^T\mathbf{L}(\mathbf{S})\boldsymbol{\Omega}) = -4\text{Tr}(\boldsymbol{\Omega}_0^T \mathbf{B}_A\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}_B^T \boldsymbol{\Omega}_0). \label{eq:Omega0TLSOmega0}
\end{align}
% \begin{align}
%     \text{Tr}(\boldsymbol{\Omega}^T\mathbf{L}(\mathbf{S})\boldsymbol{\Omega}) = -4\text{Tr}\left(\boldsymbol{\Omega}_0^T \left(\sum_{i \in A}\mathbf{B}(\mathbf{S})_i\right)\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \left(\sum_{j \in B}\mathbf{B}(\mathbf{S})_j^T\right) \boldsymbol{\Omega}_0\right). \label{eq:Omega0TLSOmega0}
% \end{align}

% Then, since $\mathbf{L}(\mathbf{S}) \preceq 0$,
% \begin{align}
%     \text{Tr}(\boldsymbol{\Omega}_0^T \mathbf{B}_A\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}_B^T \boldsymbol{\Omega}_0) \geq 0. \label{eq:TrOmega0LOmega0_lb}
% \end{align}
We are going to show that the above evaluates to zero. Note that the following calculations up to Eq.~(\ref{eq:eq11}) are general and will be reused in the proof of Theorem~\ref{thm:nec_cond_glob_rigid_views}. 

WLOG assume that the first $n_1$ points lie in the views with indices in $A \setminus B$, next $n_2$ points  lie in the views with indices in $B \setminus A$ and the remaining $n_3$ points lie in the views with indices in $A \cap B$. Note that $n_1 + n_2 + n_3 = n$ and $|A| + |B| = m$. Then the matrices $\mathbf{B}_A$ and $\mathbf{B}_B$ (perhaps after permuting the views) have the following structure. 
\begin{align}
    \begin{matrix}
        \mathbf{B}_A & = & [ & \mathbf{X}_{1} & \mathbf{0}_{d \times n_2} & \mathbf{X}_{3} & \mathbf{U}_{1} + \mathbf{U}_{3} & \mathbf{0}_{d \times |B|} & ]\\
        \mathbf{B}_B & = & [ & \mathbf{0}_{d \times n_1} & \mathbf{Y}_{2} & \mathbf{Y}_{3} & \mathbf{0}_{d \times |A|} & \mathbf{V}_{2} + \mathbf{V}_{3} & ]
    \end{matrix}
\end{align}
where $\mathbf{X}_{1} \in \mathbb{R}^{d \times n_1}$ and $\mathbf{Y}_{2} \in \mathbb{R}^{d \times n_2}$ contain the sum of the local coordinates of the $n_1$ and $n_2$ points, respectively. Also, $\mathbf{X}_{3} \in \mathbb{R}^{d \times n_3}$ and $\mathbf{Y}_{3} \in \mathbb{R}^{d \times n_3}$ contain the sum of the local coordinates of the remaining $n_3$ points due to the views with indices in $A$ and $B$ respectively. The matrices $\mathbf{U}_{1} \in \mathbb{R}^{d \times |A|}$, $\mathbf{V}_{2} \in \mathbb{R}^{d \times |B|}$, $\mathbf{U}_{3} \in \mathbb{R}^{d \times |A|}$ and $\mathbf{V}_{3} \in \mathbb{R}^{d \times |B|}$ follow from Remark~\ref{rmk:L0DB}.

Further define
\begin{align}
    \begin{matrix}
         \mathbf{B}_{A \setminus B} & \coloneqq & [ & \mathbf{X}_{1} & 0 & 0 & \mathbf{U}_{1} & 0 & ]\\
         \mathbf{B}_{A,B} & \coloneqq & [ & 0 & 0 & \mathbf{X}_{3} & \mathbf{U}_{3} & 0 & ]\\
         \mathbf{B}_{B \setminus A} & \coloneqq & [ & 0 & \mathbf{Y}_{2} & 0 & 0 & \mathbf{V}_{2} & ]\\
         \mathbf{B}_{B,A} & \coloneqq & [ & 0 & 0& \mathbf{Y}_{3} & 0 & \mathbf{V}_{3} & ]
    \end{matrix} \label{eq:eq8}
\end{align}
then $\mathbf{B}_A = \mathbf{B}_{A \setminus B} + \mathbf{B}_{A,B}$ and $\mathbf{B}_B = \mathbf{B}_{B \setminus A} + \mathbf{B}_{B,A}$. Note that $\mathbf{1}_{n+m}$ lies in the kernel of the four matrices defined above (see Remark~\ref{rmk:L0DB}) and, $\mathbf{B}_{A \setminus B}\mathbf{B}_{B\setminus A}^T = 0$, $\mathbf{B}_{A \setminus B}\mathbf{B}_{B,A}^T = 0$ and $\mathbf{B}_{B \setminus A}\mathbf{B}_{A,B}^T = 0$.

Now, the structure of $\boldsymbol{\mathcal{L}}_{\Gamma}$ is as follows,
\begin{align}
    \boldsymbol{\mathcal{L}}_{\Gamma} &= \begin{bmatrix}
        \mathbf{\mathcal{D}}_{1} & & & -\mathbf{\mathcal{K}}_{1} & \\
        & \mathbf{\mathcal{D}}_{2} & &  & -\mathbf{\mathcal{K}}_{2}\\
        & &\mathbf{\mathcal{D}}_{3} + \mathbf{\mathcal{D}}_{3} & -\mathbf{\mathcal{K}}_{A_3} & -\mathbf{\mathcal{K}}_{B_3}\\
        -\mathbf{\mathcal{K}}_{1}^T & & -\mathbf{\mathcal{K}}_{A_3}^T & \mathbf{\mathcal{D}}_{A} & \\
        & -\mathbf{\mathcal{K}}_{2}^T & -\mathbf{\mathcal{K}}_{B_3}^T & & \mathbf{\mathcal{D}}_{B}
    \end{bmatrix}
\end{align}

where $\mathbf{\mathcal{K}}_{1} \in \mathbb{R}^{n_1 \times |A|}$ is the adjacency between the first $n_1$ points and the views with indices in $A$, $\mathbf{\mathcal{K}}_{2} \in \mathbb{R}^{n_2 \times |B|}$ is the adjacency between the next $n_2$ points and the views with indices in $B$, and $\mathbf{\mathcal{K}}_{A_3} \in \mathbb{R}^{n_3 \times |A|}$ and $\mathbf{\mathcal{K}}_{B_3} \in \mathbb{R}^{n_3 \times |B|}$ are the adjacencies between the remaining $n_3$ points and the views with indices in $A$ and $B$ respectively. As for the remaining matrices, $\mathbf{\mathcal{D}}_{i} = \diag(\mathbf{\mathcal{K}}_{i}\mathbf{1}_{|A|})$ represents the degrees of the points in the bipartite adjacency $\mathbf{\mathcal{K}}_{i}$, $\mathbf{\mathcal{D}}_{A} = \diag(\mathbf{\mathcal{K}}_{1}^T\mathbf{1}_{n_1} + \mathbf{\mathcal{K}}_{A_3}^T\mathbf{1}_{n_3})$ represents the degree of the views i.e. the number of points contained in the views with indices in $A$, Similarly, $\mathbf{\mathcal{D}}_{j} = \diag(\mathbf{\mathcal{K}}_{j}\mathbf{1}_{|B|})$. and $\mathbf{\mathcal{D}}_{B} = \diag(\mathbf{\mathcal{K}}_{2}^T\mathbf{1}_{n_2} + \mathbf{\mathcal{K}}_{B_3}^T\mathbf{1}_{n_3})$. 

Since $\mathbf{S}$ is a perfect alignment, the local coordinates of a point due to all the views containing it are the same. Using the fact that $\mathbf{B}(\mathbf{S})_{A,B}$ represent the local coordinates of the $n_3$ points contained in views with indices in $A \cap B$ (see Definition~\ref{def:BSAcapB}), we obtain the following equations,
\begin{align}
    \begin{matrix}
        \mathbf{X}_{3} &=& \mathbf{B}(\mathbf{S})_{A,B}\mathbf{\mathcal{D}}_{3}\\
        \mathbf{Y}_{3} &=& \mathbf{B}(\mathbf{S})_{A,B}\mathbf{\mathcal{D}}_{3}\\
        \mathbf{U}_{3} &=& -\mathbf{B}(\mathbf{S})_{A,B}\mathbf{\mathcal{K}}_{A_3}\\
        \mathbf{V}_{3} &=& -\mathbf{B}(\mathbf{S})_{A,B}\mathbf{\mathcal{K}}_{B_3}.
    \end{matrix}\label{eq:eq9}
\end{align} 
Analogous to the above equations, it follows that $\mathbf{U}_1 = \mathbf{X}_1\mathbf{\mathcal{D}}_{1}^{-1}\mathbf{\mathcal{K}}_{1}$ and $\mathbf{V}_2 = \mathbf{Y}_2\mathbf{\mathcal{D}}_{2}^{-1}\mathbf{\mathcal{K}}_{2}$. Thus,
\begin{align}
    \begin{matrix}
         \mathbf{B}_{A \setminus B} & = & [ & \mathbf{X}_{1}\mathbf{\mathcal{D}}_{1}^{-1} & \mathbf{0}_{d \times n_2} & \mathbf{0}_{d \times n_3} & \mathbf{0}_{d \times |A|} & \mathbf{0}_{d \times |B|} & ]\boldsymbol{\mathcal{L}}_{\Gamma}\\
         \mathbf{B}_{B \setminus A} & = & [ & \mathbf{0}_{d \times n_1} & \mathbf{Y}_{2}\mathbf{\mathcal{D}}_{2}^{-1} & \mathbf{0}_{d \times n_3} & \mathbf{0}_{d \times |A|} & \mathbf{0}_{d \times |B|} & ]\boldsymbol{\mathcal{L}}_{\Gamma}
    \end{matrix}\label{eq:eq14_}
\end{align}
% A final observation regarding the matrix $\mathbf{B}_{A \setminus B}$ and $\mathbf{B}_{B \setminus A}$ in Eq.~(\ref{eq:eq8}) is that it is the analog of $\mathbf{S}^T\mathbf{B}$ in Eq.~(\ref{eq:opt_Z}) when the local coordinates of the last $n_2 + n_3$ points due to the views containing them are forced to be zeros, while the local coordinates of the first $n_1$ points are the same as above and in particular (just like Eq.~(\ref{eq:eq9})) equal $\mathbf{X}_{1}\mathbf{\mathcal{D}}_{1}^{-1}$. Similar premise holds for $\mathbf{B}_{B \setminus A}$. Since, even after forcing certain local coordinates to be zeros, the views are perfectly aligned, using Eq.~(\ref{eq:opt_Z}) and Eq.~(\ref{eq:H}), it follows that
Subsequently,
\begin{align}
    \begin{matrix}
         \mathbf{B}_{A \setminus B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger & = & [ & \mathbf{X}_{1}\mathbf{\mathcal{D}}_{1}^{-1} & \mathbf{0}_{d \times n_2} & \mathbf{0}_{d \times n_3} & \mathbf{0}_{d \times |A|} & \mathbf{0}_{d \times |B|} & ] & + & \mathbf{t}_{A \setminus B}\mathbf{1}_{n+m}^T\\
         \mathbf{B}_{B \setminus A}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger & = & [ & \mathbf{0}_{d \times n_1} & \mathbf{Y}_{2}\mathbf{\mathcal{D}}_{2}^{-1} & \mathbf{0}_{d \times n_3} & \mathbf{0}_{d \times |A|} & \mathbf{0}_{d \times |B|} & ]& + & \mathbf{t}_{B \setminus A}\mathbf{1}_{n+m}^T
         %(\mathbf{B}_{A,B}+\mathbf{B}_{B,A})\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger & = & [ & 0 & 0 & \mathbf{B}(\mathbf{S})_{A,B} & 0 & 0 & ] & + & \mathbf{t}\mathbf{1}_{n+m}^T\\
    \end{matrix}\label{eq:eq14}
\end{align}
for some translation vectors $\mathbf{t}_{A \setminus B}, \mathbf{t}_{B \setminus A} \in \mathbb{R}^d$. Since $\mathbf{1}_{n+m}$ lies in $\ker(\mathbf{B}_{A \setminus B})$ and $\ker(\mathbf{B}_{A \setminus B})$ (see the paragraph after Eq.~(\ref{eq:eq8})), thus
\begin{align}
    \mathbf{B}_{A \setminus B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}_{B\setminus A}^T = \mathbf{B}_{A \setminus B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}_{B,A}^T = \mathbf{B}_{B \setminus A}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}_{A,B}^T = 0. \label{eq:eq11}
\end{align}

% Finally, note that since $\overline{\mathbf{B}(\mathbf{S})}_{A, B}^T\boldsymbol{\Omega}_0 = 0$, we have $\mathbf{B}(\mathbf{S})_{A, B}^T\boldsymbol{\Omega}_0 = \mathbf{1}_{n_3}\mathbf{v}^T$ for some $\mathbf{v} \in \mathbb{R}^d$.
% Let $\mathbf{\mathcal{D}}_{A} \in \mathbb{R}^{|A| \times |A|}$ and $\mathbf{\mathcal{D}}_{B} \in \mathbb{R}^{|B| \times |B|}$ be the diagonal matrices whose $i$th element on the diagonal is the number of points in the $i$th and $(|A|+i)$th view, respectively. Then,
% \begin{align}
%     \boldsymbol{\Omega}_0^T\mathbf{X}_{3} &= \mathbf{v}\mathbf{1}_{n_3}^T\mathbf{\mathcal{D}}_{3}\\
%     \boldsymbol{\Omega}_0^T\mathbf{Y}_{3} &= \mathbf{v}\mathbf{1}_{n_3}^T\mathbf{\mathcal{D}}_{3}\\
%     \boldsymbol{\Omega}_0^T\mathbf{U}_{3} &= -\mathbf{v}\mathbf{1}_{|A|}^T\mathbf{\mathcal{D}}_{A}\\
%     -\boldsymbol{\Omega}_0^T\mathbf{V}_{3} &= \mathbf{v}\mathbf{1}_{|B|}^T\mathbf{\mathcal{D}}_{B}
% \end{align}
% and
% \begin{align}
%     \begin{matrix}
%         \boldsymbol{\Omega}_0^T\mathbf{B}_{A,B} & = & [ & 0 & 0 & \mathbf{v}\mathbf{1}_{n_3}^T\mathbf{\mathcal{D}}_{3} & -\mathbf{v}\mathbf{1}_{|A|}^T\mathbf{\mathcal{D}}_{A} & 0 & ]\\
%         \boldsymbol{\Omega}_0^T\mathbf{B}_{B,A} & = & [ & 0 & 0 & \mathbf{v}\mathbf{1}_{n_3}^T\mathbf{\mathcal{D}}_{3} &  0 & -\mathbf{v}\mathbf{1}_{|B|}^T\mathbf{\mathcal{D}}_{B} & ]
%     \end{matrix}
% \end{align}
% Using the above equation and the fact that $\mathbf{1}_n \in \ker(\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger)$ and $\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \succeq 0$, we obtain
% \begin{align}
%     \text{Tr}(\boldsymbol{\Omega}_0^T \mathbf{B}_A\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}_B^T \boldsymbol{\Omega}_0) &= \text{Tr}(\boldsymbol{\Omega}_0^T (\mathbf{B}_{A \setminus B}+\mathbf{B}_{A,B})\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger (\mathbf{B}_{B\setminus A} + \mathbf{B}_{B,A})^T \boldsymbol{\Omega}_0)\\
%     &= \text{Tr}(\boldsymbol{\Omega}_0^T \mathbf{B}_{A,B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger\mathbf{B}_{B,A}^T \boldsymbol{\Omega}_0)\\
%     &\leq \text{Tr}(\boldsymbol{\Omega}_0^T (\mathbf{B}_{A,B} + \mathbf{B}_{B,A})\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger(\mathbf{B}_{A,B} + \mathbf{B}_{B,A})^T \boldsymbol{\Omega}_0)\\
%     &= \text{Tr}(\begin{bmatrix} 0 & 0 & \boldsymbol{\Omega}_0^T\mathbf{B}(\mathbf{S})_{A,B} & 0 & 0\end{bmatrix}(\mathbf{B}_{A,B} + \mathbf{B}_{B,A})^T \boldsymbol{\Omega}_0)\\
%     &= 0
% \end{align}
% where the last equation follows from the fact that $\mathbf{B}(\mathbf{S})_{A,B}^T\boldsymbol{\Omega}_0 = 0$. Combining the above equation with Eq.~(\ref{eq:TrOmega0LOmega0_lb}), we conclude that $\boldsymbol{\Omega}$ is a non-trivial certificate of $\mathbf{L}(\mathbf{S})$ and thus $\pi(\mathbf{S})$ is degenerate.

Since $\mathbf{B}(\mathbf{S})_{A,B}^T\boldsymbol{\Omega}_0 = 0$ (by assumption), combining it with Eq.~(\ref{eq:eq9}) and Eq.~(\ref{eq:eq8}) yields
\begin{align}
\begin{matrix}
    \mathbf{B}_{A,B}^T\boldsymbol{\Omega}_0 &=& 0\\
    \mathbf{B}_{B,A}^T\boldsymbol{\Omega}_0 &=& 0.
\end{matrix}\label{eq:eq10}
\end{align}
Substituting the above equation and Eq.~(\ref{eq:eq11}) into Eq.~(\ref{eq:Omega0TLSOmega0}), we obtain
\begin{align}
    \text{Tr}(\boldsymbol{\Omega}_0^T \mathbf{B}_A\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}_B^T \boldsymbol{\Omega}_0) &= \text{Tr}(\boldsymbol{\Omega}_0^T (\mathbf{B}_{A \setminus B}+\mathbf{B}_{A,B})\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger (\mathbf{B}_{B\setminus A} + \mathbf{B}_{B,A})^T \boldsymbol{\Omega}_0)\\
    &= \text{Tr}(\boldsymbol{\Omega}_0^T \mathbf{B}_{A,B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger\mathbf{B}_{B,A}^T \boldsymbol{\Omega}_0) = 0.
\end{align}
We conclude that $\boldsymbol{\Omega}$ is a non-trivial certificate of $\mathbf{L}(\mathbf{S})$ and thus $\pi(\mathbf{S})$ is degenerate.\hfill$\blacksquare$

\proofof{Lemma~\ref{lem:subproblem_cert}} 
WLOG, let the $m$th vertex be removed. The setup is as follows. Let $\Gamma$ be the bipartite graph representing the correspondence between $m$ views and $n$ vertices, as described in Section~\ref{sec:setup}. Let $\Gamma_{-}$ be the bipartite graph obtained after the removal of the vertices representing the $m$th view and the points which lie exclusively in it. Let $\mathbf{D} \in \mathbb{R}^{md \times md}$, $\mathbf{B} \in \mathbb{R}^{md \times (n+m)}$, $\mathbf{D}_{-} \in \mathbb{R}^{(m-1)d\times (m-1)d}$ and $\mathbf{B}_{-} \in \mathbb{R}^{(m-1)d \times (n_1+n_2+m-1)}$ be the matrices defined in Remark~\ref{rmk:L0DB} for graphs $\Gamma$ and $\Gamma_{-}$. The structure of the combinatorial Laplacian of $\Gamma$ and $\Gamma_{-}$ are
    
\begin{align}
    \boldsymbol{\mathcal{L}}_{\Gamma} &= \begin{bmatrix}
        \mathbf{\mathcal{D}}_1 &  &  & -\mathbf{\mathcal{K}}_1 & \mathbf{0}_{n_1}\\
         & \mathbf{\mathcal{D}}_2 + \mathbf{I}_{n_2} &  & -\mathbf{\mathcal{K}}_2 & -\mathbf{1}_{n_2}\\
         &  & \mathbf{I}_{n_3} & \mathbf{0}_{n_3 \times (m-1)} & -\mathbf{1}_{n_3}\\
        -\mathbf{\mathcal{K}}_1^T & -\mathbf{\mathcal{K}}_2^T & \mathbf{0}_{n_3}^T & \overline{\mathbf{\mathcal{D}}} & \mathbf{0}_{m-1}\\
        \mathbf{0}_{n_1}^T & -\mathbf{1}_{n_2}^T & -\mathbf{1}_{n_3}^T & \mathbf{0}_{m-1}^T & n_2+n_3
    \end{bmatrix}
\end{align}
and
\begin{align}
    \boldsymbol{\mathcal{L}}_{\Gamma_{-}} &= \begin{bmatrix}
        \mathbf{\mathcal{D}}_1 &  & -\mathbf{\mathcal{K}}_1\\
         & \mathbf{\mathcal{D}}_2 & -\mathbf{\mathcal{K}}_2\\
        -\mathbf{\mathcal{K}}_1^T & -\mathbf{\mathcal{K}}_2^T & \overline{\mathbf{\mathcal{D}}}
    \end{bmatrix},
\end{align}
respectively, where 
\begin{itemize}
    \item $\mathbf{\mathcal{K}}_1 \in \mathbb{R}^{n_1 \times (m-1)}$ is the bipartite adjacency matrix between the first $m-1$ views and the $n_1$ points which lie exclusively in them. Note that the adjacency between such points and the $m$th view is $\mathbf{0}_{n_1}$.
    \item $\mathbf{\mathcal{K}}_2 \in \mathbb{R}^{n_2 \times (m-1)}$ is the bipartite adjacency matrix between the first $m-1$ views and the $n_2$ points which lie on the overlap of the $m$th view and the union of the first $m-1$ views. Note that the adjacency between such points and the $m$th view is $\mathbf{1}_{n_2}$.
    \item the fifth and the third column in $\boldsymbol{\mathcal{L}}_{\Gamma}$ correspond to the  $m$th view and the $n_3$ points that lie exclusively in it, respectively. The adjacency between such points and the first $m-1$ views is $\mathbf{0}_{n_3 \times (m-1)}$, and that with the $m$th view is $\mathbf{1}_{n_3}$.
    \item $\mathbf{\mathcal{D}}_1 = \diag (\mathbf{\mathcal{K}}_1\mathbf{1}_{m-1})$, $\mathbf{\mathcal{D}}_2 = \diag (\mathbf{\mathcal{K}}_2\mathbf{1}_{m-1})$ and $\overline{\mathbf{\mathcal{D}}} = \diag (\mathbf{\mathcal{K}}_1^T\mathbf{1}_{n_1} + \mathbf{\mathcal{K}}_2^T\mathbf{1}_{n_2})$.
\end{itemize}
Note that since $\Gamma$ is connected by assumption in this work, $n_2 > 0$.

The matrices $\boldsymbol{\mathcal{L}}_{\Gamma}$ and $\boldsymbol{\mathcal{L}}_{\Gamma_{-}}$ are related as follows. There exist a permutation matrix
\begin{align}
    \mathbf{\mathcal{P}}_{0} &= \begin{bmatrix}
        \mathbf{I}_{n_1} &  &  &  & \\
        & \mathbf{I}_{n_2} &  &  &  \\
        & & & \mathbf{I}_{n_3}& \\
        & & \mathbf{I}_{m-1}& & \\
        & & & & 1
    \end{bmatrix}
\end{align}
and a diagonal matrix $\mathbf{\mathcal{D}}_0 = \diag ((\mathbf{0}_{n_1},\mathbf{1}_{n_2},\mathbf{0}_{m-1}))$ such that
\begin{align}
    \mathbf{\mathcal{P}}_{0}\boldsymbol{\mathcal{L}}_{\Gamma}\mathbf{\mathcal{P}}_{0}^T &= \begin{bmatrix}\mathbf{A}_{11}&\mathbf{A}_{12}\\\mathbf{A}_{21}&\mathbf{A}_{22}\end{bmatrix} = \begin{bmatrix}
        &&&\mathbf{0}_{n_1 \times n_3} & \mathbf{0}_{n_1}\\
        & \boldsymbol{\mathcal{L}}_{\Gamma_{-}} + \mathbf{\mathcal{D}}_0 & & \mathbf{0}_{n_2 \times n_3} & -\mathbf{1}_{n_2}\\
        &&& \mathbf{0}_{(m-1) \times n_3} & \mathbf{0}_{m-1}\\
        \mathbf{0}_{n_1 \times n_3}^T & \mathbf{0}_{n_2 \times n_3}^T & \mathbf{0}_{(m-1) \times n_3}^T & \mathbf{I}_{n_3} & -\mathbf{1}_{n_3}\\
        \mathbf{0}_{n_1}^T & -\mathbf{1}_{n_2}^T & \mathbf{0}_{m-1}^T & -\mathbf{1}_{n_3}^T & n_2+n_3
    \end{bmatrix} \label{eq:eq15}
\end{align}

The rest is divided into three parts. First, we derive the pseudoinverse of the above block matrix using \citeb[Section 3.6.2]{gentle2007matrix}. Then we show that $\mathbf{S}_{-} \coloneqq \mathbf{S}_{-m}$ is a perfect alignment of the $m-1$ views and finally we show that $[\boldsymbol{\Omega}_i]_{1}^{m-1}$ is a certificate of $\mathbf{L}_{-}(\mathbf{S}_{-}) \coloneqq \mathbf{L}_{-m}(\mathbf{S}_{-m})$ when $[\boldsymbol{\Omega}_i]_{1}^{m}$ is a certificate of $\mathbf{L}(\mathbf{S})$.

\textbf{Part 1}. Here we derive the pseudoinverse of the block matrix in Eq.~(\ref{eq:eq15}). First, we need the following result,
\begin{prop}
\label{prop:LplusD0}
$\boldsymbol{\mathcal{L}}_{\Gamma_{-}} + \mathbf{\mathcal{D}}_0 \succ 0$.
\end{prop}
\begin{proof}
Since $\boldsymbol{\mathcal{L}}_{\Gamma_{-}} \succeq 0$ and $\mathbf{\mathcal{D}}_0 \succeq 0$, it suffices to show that $\ker (\boldsymbol{\mathcal{L}}_{\Gamma_{-}}) \cap \ker (\mathbf{\mathcal{D}}_0) = \{0\}$. Recall that the $m$th view contains $n_2 + n_3$ points where $n_2>0$ points lie on the overlap of $m$th view and the union of first $m-1$ views, and $n_3$ points lie exclusively in the $m$th view. Removal of the $m$th view and the $n_3$ points that lie exclusively in it may disconnect $\Gamma$ to produce $\Gamma_{-}$ with at most $n_2$ connected components. The binary vectors $\mathbf{u}_i$ with ones at the indices of the vertices in the $i$th component and zeros elsewhere, form an orthogonal basis of the $\ker(\boldsymbol{\mathcal{L}}_{\Gamma_{-}})$. Note that there exists at least one $k \in [n_1+1, n_1+n_2]$ such that $\mathbf{u}_i(k) = 1$. Thus $\mathbf{u}_i^T\mathbf{\mathcal{D}}_0\mathbf{u}_i > 0$. Moreover, for $i \neq j$, $\mathbf{u}_i^T\mathbf{\mathcal{D}}_0\mathbf{u}_j = 0$. The result follows.
\end{proof}
Since $\boldsymbol{\mathcal{L}}_{\Gamma_{-}} + \mathbf{\mathcal{D}}_0 \succ 0$, thus $(\boldsymbol{\mathcal{L}}_{\Gamma_{-}}+\mathbf{\mathcal{D}}_0)^\dagger = (\boldsymbol{\mathcal{L}}_{\Gamma_{-}}+\mathbf{\mathcal{D}}_0)^{-1}$ and
\begin{align}
    (\boldsymbol{\mathcal{L}}_{\Gamma_{-}}+\mathbf{\mathcal{D}}_0)  \begin{bmatrix}\mathbf{1}_{n_1}\\ \mathbf{1}_{n_2} \\ \mathbf{1}_{m-1}\end{bmatrix} =  \begin{bmatrix}\mathbf{0}_{n_1}\\ \mathbf{1}_{n_2} \\ \mathbf{0}_{m-1}\end{bmatrix} \implies (\boldsymbol{\mathcal{L}}_{\Gamma_{-}}+\mathbf{\mathcal{D}}_0)^\dagger \begin{bmatrix}\mathbf{0}_{n_1}\\ \mathbf{1}_{n_2} \\ \mathbf{0}_{m-1}\end{bmatrix} = \begin{bmatrix}\mathbf{1}_{n_1}\\ \mathbf{1}_{n_2} \\ \mathbf{1}_{m-1}\end{bmatrix}.
\end{align}
Using the above equation, the matrix $\mathbf{Z} \coloneqq [(\mathbf{\mathcal{P}}_{0}\boldsymbol{\mathcal{L}}_{\Gamma}\mathbf{\mathcal{P}}_{0}^T)^\dagger]_{22} = \mathbf{A}_{22} - \mathbf{A}_{21}\mathbf{A}_{11}^\dagger \mathbf{A}_{12}$ and its pseudoinverse is,
\begin{align}
    \mathbf{Z} &= \begin{bmatrix}
        \mathbf{I}_{n_3} & -\mathbf{1}_{n_3}\\
        -\mathbf{1}_{n_3}^T & n_3
    \end{bmatrix} \implies  \mathbf{Z}^\dagger = \begin{bmatrix}
        \mathbf{I}_{n_3}  & \mathbf{0}_{n_3}\\
        \mathbf{0}_{n_3}^T & 0
    \end{bmatrix}.
\end{align}
Next,
\begin{align}
&[(\mathbf{\mathcal{P}}_{0}\boldsymbol{\mathcal{L}}_{\Gamma}\mathbf{\mathcal{P}}_{0}^T)^\dagger]_{11}\\
&= (\boldsymbol{\mathcal{L}}_{\Gamma_{-}}+\mathbf{\mathcal{D}}_0)^\dagger + ((\boldsymbol{\mathcal{L}}_{\Gamma_{-}}+\mathbf{\mathcal{D}}_0)^\dagger \mathbf{A}_{12})\mathbf{Z}^{\dagger}(\mathbf{A}_{21}(\boldsymbol{\mathcal{L}}_{\Gamma_{-}}+\mathbf{\mathcal{D}}_0)^\dagger)\\
    &= (\boldsymbol{\mathcal{L}}_{\Gamma_{-}}+\mathbf{\mathcal{D}}_0)^\dagger + \begin{bmatrix}\mathbf{0}_{n_1 \times n_3} & \mathbf{1}_{n_1}\\ \mathbf{0}_{n_2 \times n_3} & \mathbf{1}_{n_2} \\ \mathbf{0}_{(m-1) \times n_3} & \mathbf{1}_{m-1}\end{bmatrix}\begin{bmatrix}
        \mathbf{I}_{n_3}  & \mathbf{0}_{n_3}\\
        \mathbf{0}_{n_3}^T & 0
    \end{bmatrix} \begin{bmatrix}\mathbf{0}_{n_1 \times n_3}^T & \mathbf{0}_{n_2 \times n_3}^T & \mathbf{0}_{(m-1) \times n_3}^T \\ \mathbf{1}_{n_1}^T & \mathbf{1}_{n_2}^T & \mathbf{1}_{m-1}\end{bmatrix}\\
    &= (\boldsymbol{\mathcal{L}}_{\Gamma_{-}}+\mathbf{\mathcal{D}}_0)^\dagger \label{eq:pinvA11}
\end{align}
As above, $[(\mathbf{\mathcal{P}}_{0}\boldsymbol{\mathcal{L}}_{\Gamma}\mathbf{\mathcal{P}}_{0}^T)^\dagger]_{12} = -(\mathbf{A}_{11}^\dagger \mathbf{A}_{12}) \mathbf{Z}^\dagger = 0$ and similarly $[(\mathbf{\mathcal{P}}_{0}\boldsymbol{\mathcal{L}}_{\Gamma}\mathbf{\mathcal{P}}_{0}^T)^\dagger]_{21} = 0$. Thus,
    \begin{align}(\mathbf{\mathcal{P}}_{0}\boldsymbol{\mathcal{L}}_{\Gamma}\mathbf{\mathcal{P}}_{0}^T)^\dagger &= 
    \begin{bmatrix}
        (\boldsymbol{\mathcal{L}}_{\Gamma_{-}}+\mathbf{\mathcal{D}}_0)^\dagger & & \\
        & \mathbf{I}_{n_3}  & \\
        & & 0
    \end{bmatrix}.
\end{align}

\textbf{Part 2}. Now, let $\mathbf{S} = [\mathbf{S}_i]_1^{m}$ and $\mathbf{S}_{-} = [\mathbf{S}_i]_1^{m-1}$. Intuitively, it should be clear that $\mathbf{S}_{-}$ is a perfect alignment for the $m-1$ views. Since $\mathbf{S}$ is a perfect alignment, the alignment error $\text{Tr}(\mathbf{S}^T(\mathbf{D}-\mathbf{B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger\mathbf{B}^T)\mathbf{S}) = 0$ (see Eq.~(\ref{eq:GPOP})). Here we will show that the alignment error after the removal of the $m$th view is still zero i.e. $\text{Tr}(\mathbf{S}_{-}^T(\mathbf{D}_{-}-\mathbf{B}_{-}\boldsymbol{\mathcal{L}}_{\Gamma_{-}}\mathbf{B}_{-}^T)\mathbf{S}_{-}) = 0$.

Let $\mathbf{B}^*_{1} \in \mathbb{R}^{d \times n_1}$, $\mathbf{B}^*_{2} \in \mathbb{R}^{d \times n_2}$ and $\mathbf{B}^*_{3} \in \mathbb{R}^{d \times n_3}$ contain the coordinates (after alignment with $\mathbf{S}$) of the $n_1$ points that lie exclusively in the first $m-1$ views, of the $n_2$ points that lie on the overlap of the $m$th view with the remaining views, and of the $n_3$ points that lie exclusively in the $m$th view, respectively. Then, it suffices to show the following (by taking the trace of the difference of the two equations below, the result follows),
\begin{prop}
    \begin{align}
    \mathbf{S}^T\mathbf{B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger\mathbf{B}^T\mathbf{S} &=  \mathbf{S}_{-}^T\mathbf{B}_{-}\boldsymbol{\mathcal{L}}_{\Gamma_{-}}^\dagger \mathbf{B}_{-}^T\mathbf{S}_{-} + \mathbf{B}^*_{2}\mathbf{B}^{*^T}_{2} + \mathbf{B}^*_{3}\mathbf{B}^{*^T}_{3}
\end{align}
\end{prop}
and 
\begin{align}
    \mathbf{S}^T\mathbf{D}\mathbf{S} &= \mathbf{S}_{-}^T\mathbf{D}_{-}\mathbf{S}_{-} + \mathbf{B}^*_{2}\mathbf{B}^{*^T}_{2} + \mathbf{B}^*_{3}\mathbf{B}^{*^T}_{3}.
\end{align}
\begin{proof}
The second equation follows trivially from Eq.~(\ref{eq:D}), Remark~\ref{rmk:L0DB} and the fact that, since the $m$ views are perfectly aligned, the local coordinates of the points are the same as those in the matrices $\mathbf{B}^*_{1}$,  $\mathbf{B}^*_{2}$ and  $\mathbf{B}^*_{3}$. We proceed to prove the first equation.

Since $\mathbf{\mathcal{P}}_0$ is a permutation matrix, $\mathbf{S}^T\mathbf{B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger\mathbf{B}^T\mathbf{S} = (\mathbf{S}^T\mathbf{B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger\mathbf{\mathcal{P}}_{0}^T)(\mathbf{\mathcal{P}}_{0}\mathbf{B}^T\mathbf{S})$. Then, using the same idea as in Eq.~(\ref{eq:eq9}), Eq.~(\ref{eq:eq14_}) and Eq.~(\ref{eq:eq14}) in the proof of Theorem~\ref{thm:nec_cond_loc_rigid_of_views}, we obtain
\begin{align}
    \mathbf{S}^T\mathbf{B} &= \begin{bmatrix}
        \mathbf{B}^*_{1}\mathbf{\mathcal{D}}_1 & \mathbf{B}^*_{2}(\mathbf{\mathcal{D}}_2 + \mathbf{I}_{n_2}) & \mathbf{B}^*_{3} & -(\mathbf{B}^*_{1}\mathbf{\mathcal{K}}_1+\mathbf{B}^*_{2}\mathbf{\mathcal{K}}_2) & -(\mathbf{B}^*_{2}\mathbf{1}_{n_2}+\mathbf{B}^*_{3}\mathbf{1}_{n_3})
    \end{bmatrix} \label{eq:STB}\\
    &= \begin{bmatrix}
        \mathbf{B}^*_{1} & \mathbf{B}^*_{2} & \mathbf{B}^*_{3} & \mathbf{0}_{d \times (m-1)} & \mathbf{0}_{d}
    \end{bmatrix}\boldsymbol{\mathcal{L}}_{\Gamma}
\end{align}
and thus
\begin{align}
    \mathbf{S}^T\mathbf{B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger &= \begin{bmatrix}
        \mathbf{B}^*_{1} & \mathbf{B}^*_{2} & \mathbf{B}^*_{3} & \mathbf{0}_{d \times (m-1)} & \mathbf{0}_{d}
    \end{bmatrix} + \mathbf{t}\mathbf{1}_{n+m}^T \label{eq:STBL_GammaBTS}
\end{align}
for some translation vector $\mathbf{t} \in \mathbb{R}^d$. Similarly,
\begin{align}
    \mathbf{S}_{-}^T\mathbf{B}_{-} &= \begin{bmatrix}
        \mathbf{B}^*_{1}\mathbf{\mathcal{D}}_1 & \mathbf{B}^*_{2} \mathbf{\mathcal{D}}_2 & -(\mathbf{B}^*_{1}\mathbf{\mathcal{K}}_1+\mathbf{B}^*_{2}\mathbf{\mathcal{K}}_2)
    \end{bmatrix} = \begin{bmatrix}
        \mathbf{B}^*_{1} & \mathbf{B}^*_{2} & \mathbf{0}_{d \times (m-1)}
    \end{bmatrix}\boldsymbol{\mathcal{L}}_{\Gamma_{-}} \label{eq:SmTBm1}
\end{align}
and thus
\begin{align}
    \mathbf{S}_{-}^T\mathbf{B}_{-}\boldsymbol{\mathcal{L}}_{\Gamma_{-}}^\dagger  &= \begin{bmatrix}
        \mathbf{B}^*_{1} & \mathbf{B}^*_{2} & \mathbf{0}_{d \times (m-1)}
    \end{bmatrix} + \mathbf{t}_{-}\mathbf{v}_{-}^T
\end{align}
for some translation vector $\mathbf{t}_{-} \in \mathbb{R}^d$ and $\mathbf{v}_{-} \in \ker(\boldsymbol{\mathcal{L}}_{\Gamma_{-}})$. From Proposition~\ref{prop:kerB}, we have $\ker(\boldsymbol{\mathcal{L}}_{\Gamma_{-}}) \subseteq \ker(\mathbf{B}_{-})$, thus
\begin{align}
    \mathbf{S}_{-}^T\mathbf{B}_{-}\boldsymbol{\mathcal{L}}_{\Gamma_{-}}^\dagger \mathbf{B}_{-}^T\mathbf{S}_{-}  = \begin{bmatrix}
        \mathbf{B}^*_{1} & \mathbf{B}^*_{2} & \mathbf{0}_{d \times (m-1)}
    \end{bmatrix}\mathbf{B}_{-}^T\mathbf{S}_{-}. \label{eq:eq20}
\end{align}
Now, combining Eq.~(\ref{eq:STB}) and Eq.~(\ref{eq:SmTBm1}) we obtain
\begin{align}
    \mathbf{S}^T\mathbf{B}\mathbf{\mathcal{P}}_{0}^T &= \begin{bmatrix}
        \mathbf{B}^*_{1}\mathbf{\mathcal{D}}_1 & \mathbf{B}^*_{2}(\mathbf{\mathcal{D}}_2 + \mathbf{I}_{n_2}) & -(\mathbf{B}^*_{1}\mathbf{\mathcal{K}}_1+\mathbf{B}^*_{2}\mathbf{\mathcal{K}}_2)  & \mathbf{B}^*_{3} & -(\mathbf{B}^*_{2}\mathbf{1}_{n_2}+\mathbf{B}^*_{3}\mathbf{1}_{n_3})
    \end{bmatrix}\\
    &= \begin{bmatrix}
        \mathbf{S}_{-}^T\mathbf{B}_{-} & \mathbf{0}_{d \times n_3} & \mathbf{0}_{d}
    \end{bmatrix} + \begin{bmatrix}
        \mathbf{0}_{d \times n_1} & \mathbf{B}^*_{2} &  \mathbf{0}_{d \times (m-1)} &  \mathbf{B}^*_{3} & -(\mathbf{B}^*_{2}\mathbf{1}_{n_2}+\mathbf{B}^*_{3}\mathbf{1}_{n_3})
    \end{bmatrix}.
\end{align}
By observing that $\mathbf{1}_{n+m}$ is in the kernel of $\mathbf{S}^T\mathbf{B}\mathbf{\mathcal{P}}_{0}^T$, combining the above equation with Eq.~(\ref{eq:STBL_GammaBTS}), and using Eq.~(\ref{eq:eq20}), we obtain
\begin{align}
    &\mathbf{S}^T\mathbf{B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger\mathbf{B}^T\mathbf{S}\\
    &= (\mathbf{S}^T\mathbf{B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger\mathbf{\mathcal{P}}_{0}^T)(\mathbf{\mathcal{P}}_{0}\mathbf{B}^T\mathbf{S})\\
    &= \left(\begin{bmatrix}
        \mathbf{B}^*_{1} & \mathbf{B}^*_{2} &  \mathbf{0}_{d \times (m-1)} & \mathbf{B}^*_{3} & \mathbf{0}_{d}
    \end{bmatrix} + \mathbf{t}\mathbf{1}_{n+m}^T\right)(\mathbf{\mathcal{P}}_{0}\mathbf{B}^T\mathbf{S})\\
    &= \begin{bmatrix}
        \mathbf{B}^*_{1} & \mathbf{B}^*_{2} &  \mathbf{0}_{d \times (m-1)} & \mathbf{B}^*_{3} & \mathbf{0}_{d}
    \end{bmatrix}\begin{bmatrix}
        \mathbf{S}_{-}^T\mathbf{B}_{-} & \mathbf{0}_{d \times n_3} & \mathbf{0}_{d}
    \end{bmatrix}^T + \mathbf{B}^*_{2}\mathbf{B}^{*^T}_{2} + \mathbf{B}^*_{3}\mathbf{B}^{*^T}_{3}\\
    &= \mathbf{S}_{-}^T\mathbf{B}_{-}\boldsymbol{\mathcal{L}}_{\Gamma_{-}}^\dagger \mathbf{B}_{-}^T\mathbf{S}_{-} + \mathbf{B}^*_{2}\mathbf{B}^{*^T}_{2} + \mathbf{B}^*_{3}\mathbf{B}^{*^T}_{3}
\end{align}
\end{proof}

\textbf{Part 3}. Now let $\mathbf{L}(\mathbf{S})$ and $\mathbf{L}_{-}(\mathbf{S}_{-})$ be the matrices, as described in Eq.~(\ref{eq:L_of_S}) for the two graphs $\Gamma$ and $\Gamma_{-}$ and the corresponding views. Let $\boldsymbol{\Omega} = [\boldsymbol{\Omega}_i]_1^m$ be a certificate of $\mathbf{L}(\mathbf{S})$. By Remark~\ref{rmk:C_hat_L_structure}, $\boldsymbol{\Omega}^{'} = \boldsymbol{\Omega} - [\boldsymbol{\Omega}_m]_1^m$ is also a certificate of $\mathbf{L}(\mathbf{S})$ and in particular $\boldsymbol{\Omega}^{'}_m = 0$. Define $\boldsymbol{\Omega}_{-} = [\boldsymbol{\Omega}^{'}_i]_1^{m-1}$. We are going to show that $\text{Tr}(\boldsymbol{\Omega}_{-}^T\mathbf{L}_{-}(\mathbf{S}_{-})\boldsymbol{\Omega}_{-}) = 0$ i.e. $\boldsymbol{\Omega}_{-}$ is a certificate of $\mathbf{L}_{-}(\mathbf{S}_{-})$. Then using Remark~\ref{rmk:C_hat_L_structure}, it follows that $[\boldsymbol{\Omega}_i]_1^{m-1}$ (which equals $\boldsymbol{\Omega}_{-} + [\boldsymbol{\Omega}_m]_1^{m-1}$) is a certificate of $\mathbf{L}_{-}(\mathbf{S}_{-})$.

% One way to show that $\text{Tr}(\boldsymbol{\Omega}_{-}^T\mathbf{L}_{-}(\mathbf{S}_{-})\boldsymbol{\Omega}_{-}) = 0$ is: define a curve $\mathbf{S}(t) \in \mathbb{O}(d)^m$ where $t \in [0,\epsilon)$ for small enough $\epsilon$ such that $\mathbf{S}'(0) = [\mathbf{S}_i\boldsymbol{\Omega}^{'}_i]_1^m$. Similarly, define a curve $\mathbf{S}_{-}(t) \in \mathbb{O}(d)^{m-1}$ where $t \in [0,\epsilon_{-})$ for small enough $\epsilon_{-}$ such that $\mathbf{S}_{-}'(0) = [\mathbf{S}_{-_i}\boldsymbol{\Omega}_{-_i}]_1^{m-1}$. 

First, we note that
\begin{align}
    \mathbf{B}(\mathbf{S})\mathbf{\mathcal{P}}_{0}^T &= \begin{bmatrix}
        \mathbf{B}_{-}(\mathbf{S}_{-}) &  \mathbf{0}_{(m-1)d \times n_3} & \mathbf{0}_{(m-1)d}\\
        \begin{bmatrix}\mathbf{0}_{d \times n_1} & \mathbf{B}^*_{2} & \mathbf{0}_{d \times (m-1)} \end{bmatrix} &\mathbf{B}^*_{3} & -(\mathbf{B}^*_{2}\mathbf{1}_{n_2}+\mathbf{B}^*_{3}\mathbf{1}_{n_3})
    \end{bmatrix}\\
    \mathbf{D}(\mathbf{S}) &= \begin{bmatrix}
        \mathbf{D}_{-}(\mathbf{S}_{-}) & \\
        & \mathbf{B}^*_{2}\mathbf{B}^{*^T}_{2} + \mathbf{B}^*_{3}\mathbf{B}^{*^T}_{3}
    \end{bmatrix}
\end{align}
and then using the fact that $\boldsymbol{\Omega}^{'}$ is a certificate of $\mathbf{L}(\mathbf{S})$, then $\boldsymbol{\Omega}^{'}_m = 0$, followed by the above equations and Eq.~(\ref{eq:pinvA11}), we obtain
\begin{align}
    0 &= \text{Tr}(\boldsymbol{\Omega}^{'^T}\mathbf{L}(\mathbf{S})\boldsymbol{\Omega}^{'})\\
    &= \text{Tr}(\boldsymbol{\Omega}^{'^T}(\mathbf{B}(\mathbf{S})\mathbf{\mathcal{P}}_{0}^T\mathbf{\mathcal{P}}_{0}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger\mathbf{\mathcal{P}}_{0}^T\mathbf{\mathcal{P}}_{0} \mathbf{B}(\mathbf{S})^T - \mathbf{D}(\mathbf{S}))\boldsymbol{\Omega}^{'})\\
    &= \text{Tr}(\boldsymbol{\Omega}^{'^T}(\mathbf{B}(\mathbf{S})\mathbf{\mathcal{P}}_{0}^T(\mathbf{\mathcal{P}}_{0}\boldsymbol{\mathcal{L}}_{\Gamma}\mathbf{\mathcal{P}}_{0}^T)^\dagger\mathbf{\mathcal{P}}_{0} \mathbf{B}(\mathbf{S})^T - \mathbf{D}(\mathbf{S}))\boldsymbol{\Omega}^{'})\\
    &= \text{Tr}(\boldsymbol{\Omega}_{-}^T(\mathbf{B}_{-}(\mathbf{S}_{-}) (\mathbf{\mathcal{P}}_{0}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger\mathbf{\mathcal{P}}_{0}^T)_{11} \mathbf{B}_{-}(\mathbf{S}_{-})^T - \mathbf{D}_{-}(\mathbf{S}))\boldsymbol{\Omega}_{-})\\
    &= \text{Tr}(\boldsymbol{\Omega}_{-}^T(\mathbf{B}_{-}(\mathbf{S}_{-})(\boldsymbol{\mathcal{L}}_{\Gamma_{-}}+\mathbf{\mathcal{D}}_0)^\dagger \mathbf{B}_{-}(\mathbf{S}_{-})^T - \mathbf{D}_{-}(\mathbf{S}))\boldsymbol{\Omega}_{-})
\end{align}
From Proposition~\ref{prop:noiseless_setting1} and Eq.~(\ref{eq:C_of_S}), we have $\mathbf{L}_{-}(\mathbf{S}_{-}) = \mathbf{B}_{-}(\mathbf{S}_{-})\boldsymbol{\mathcal{L}}_{\Gamma_{-}}^\dagger \mathbf{B}_{-}(\mathbf{S}_{-})^T - \mathbf{D}_{-}(\mathbf{S}_{-})$, thus
\begin{align}
    \text{Tr}(\boldsymbol{\Omega}_{-}^T(\mathbf{B}_{-}(\mathbf{S}_{-}) ((\boldsymbol{\mathcal{L}}_{\Gamma_{-}}+\mathbf{\mathcal{D}}_0)^\dagger - \boldsymbol{\mathcal{L}}_{\Gamma_{-}}^\dagger) \mathbf{B}_{-}(\mathbf{S}_{-})^T )\boldsymbol{\Omega}_{-}) + \text{Tr}(\boldsymbol{\Omega}_{-}^T\mathbf{L}_{-}(\mathbf{S}_{-})\boldsymbol{\Omega}_{-}) = 0
\end{align}
Since $\mathbf{L}_{-}(\mathbf{S}_{-}) \preceq 0$, to show that $\text{Tr}(\boldsymbol{\Omega}_{-}^T\mathbf{L}_{-}(\mathbf{S}_{-})\boldsymbol{\Omega}_{-}) = 0$, it suffices to show the following
\begin{prop}
\begin{align}
    \mathbf{B}_{-}(\mathbf{S}_{-}) ((\boldsymbol{\mathcal{L}}_{\Gamma_{-}}+\mathbf{\mathcal{D}}_0)^\dagger - \boldsymbol{\mathcal{L}}_{\Gamma_{-}}^\dagger) \mathbf{B}_{-}(\mathbf{S}_{-})^T \preceq 0.
\end{align}    
\end{prop}
\begin{proof}
Since $\boldsymbol{\mathcal{L}}_{\Gamma_{-}} \succeq 0$, consider the decomposition
\begin{align}
    \boldsymbol{\mathcal{L}}_{\Gamma_{-}} = \mathbf{U}\boldsymbol{\Lambda}\mathbf{U}^T = \begin{bmatrix}
        \mathbf{U}_1 & \mathbf{U}_2
    \end{bmatrix}\begin{bmatrix}
        \mathbf{\Lambda}_1 & \\
        & 0
    \end{bmatrix}\begin{bmatrix}
        \mathbf{U}_1^T\\
        \mathbf{U}_2^T
    \end{bmatrix}
\end{align}
where the $1 \leq n' \leq n_2$ columns of $\mathbf{U}_2 \in \mathbb{R}^{(n_1+n_2+m-1) \times n'}$ form the orthogonal basis of the $\ker (\boldsymbol{\mathcal{L}}_{\Gamma_{-}})$ as described in the proof of Proposition~\ref{prop:LplusD0}, and $\mathbf{\Lambda}_1 \succ 0$. From Proposition~\ref{prop:kerB} and Eq.~(\ref{eq:BofS}), $\mathbf{B}_{-}(\mathbf{S}_{-})\mathbf{U}_2 = 0$. Thus, 
\begin{align}
\mathbf{B}_{-}(\mathbf{S}_{-})\mathbf{U} = \begin{bmatrix}
    \mathbf{B}_{-}(\mathbf{S}_{-})\mathbf{U}_1 & 0 \label{eq:BS_U}
\end{bmatrix}    
\end{align}
Then note that,
\begin{align}
    ((\boldsymbol{\mathcal{L}}_{\Gamma_{-}}+\mathbf{\mathcal{D}}_0)^\dagger - \boldsymbol{\mathcal{L}}_{\Gamma_{-}}^\dagger) &= \mathbf{U} \left\{\left(\begin{bmatrix}
        \mathbf{\Lambda}_1 & \\
        & 0
    \end{bmatrix} + \mathbf{U}^T\mathbf{\mathcal{D}}_0\mathbf{U}\right)^\dagger-\begin{bmatrix}
        \mathbf{\Lambda}_1^{-1} & \\
        & 0
    \end{bmatrix}\right\}\mathbf{U}^T. \label{eq:eq30}
\end{align}
Using \citea{kovanic1979pseudoinverse}[Eq.~(10,11,17,19)] and straightforward calculations, we obtain
\begin{align}
    \left(\begin{bmatrix}
        \mathbf{\Lambda}_1 & \\
        & 0
    \end{bmatrix} + \mathbf{U}^T\mathbf{\mathcal{D}}_0\mathbf{U}\right)^\dagger &= \begin{bmatrix}
        \mathbf{\Lambda}_1^{-1} & \\
        & 0
    \end{bmatrix} + \begin{bmatrix}
        \mathbf{W}_1 &\\
        & \mathbf{W}_2
    \end{bmatrix}
\end{align}
where $\mathbf{W}_1 = -\mathbf{\Lambda}_1^{-1}\mathbf{U}_1^T\mathbf{\mathcal{D}}_0(\mathbf{I} + \mathbf{\mathcal{D}}_0\mathbf{U}_1\mathbf{\Lambda}_1^{-1}\mathbf{U}_1^T\mathbf{\mathcal{D}}_0)^{-1}\mathbf{\mathcal{D}}_0\mathbf{U}_1\mathbf{\Lambda}_1^{-1}$ and $\mathbf{W}_2 = (\mathbf{U}_2^T\mathbf{\mathcal{D}}_0\mathbf{U}_2)^\dagger$. In particular $\mathbf{W}_1 \preceq 0$ and $\mathbf{W}_2 \succeq 0$.
Combining above equation with Eq.~(\ref{eq:BS_U}) and Eq.~(\ref{eq:eq30}),
\begin{align}
    \mathbf{B}_{-}(\mathbf{S}_{-}) ((\boldsymbol{\mathcal{L}}_{\Gamma_{-}}+\mathbf{\mathcal{D}}_0)^\dagger - \boldsymbol{\mathcal{L}}_{\Gamma_{-}}^\dagger) \mathbf{B}_{-}(\mathbf{S}_{-})^T &= \mathbf{B}_{-}(\mathbf{S}_{-})\mathbf{U}_1\mathbf{W}_1\mathbf{U}_1^T\mathbf{B}_{-}(\mathbf{S}_{-})^T \preceq 0.
\end{align}
\end{proof}
\noindent We conclude that $\text{Tr}(\boldsymbol{\Omega}_{-}^T\mathbf{L}_{-}(\mathbf{S}_{-})\boldsymbol{\Omega}_{-}) = 0$ and thus $\boldsymbol{\Omega}_{-}$ is a certificate of $\mathbf{L}_{-}(\mathbf{S}_{-})$.
\hfill$\blacksquare$

\proofof{Proposition~\ref{prop:same_conn_comp_non_deg}}
It suffices to show that if the $i$th and $j$th vertices are adjacent in $\mathbb{G}$ then $\boldsymbol{\Omega}_i = \boldsymbol{\Omega}_j$. For $m=2$, the result is a direct consequence of Theorem~\ref{thm:nec_suff_cond_loc_rigid_two_views}. Suppose the result holds for $m-1$ views for some $m > 2$. We show that the result holds for $m$ views. If there are no edges in $\mathbb{G}$, then the result holds trivially. Suppose $i$th and $j$th vertices are adjacent in $\mathbb{G}$. Let $r \in [1,m] \setminus \{i,j\}$. We remove the $r$th view and the points which lie exclusively in it. Then by Lemma~\ref{lem:subproblem_cert}, $[\boldsymbol{\Omega}_k]_{k \in [1,m] \setminus r}$ is a certificate of $\mathbf{L}_{-r}(\mathbf{S}_{-r})$. Now construct $\mathbb{G}_{-r}$ (in the same way as $\mathbb{G}$) and note that the vertices corresponding to the $i$th and $j$th views are still adjacent. Thus, by the induction hypothesis we conclude that $\boldsymbol{\Omega}_i = \boldsymbol{\Omega}_j$.\hfill$\blacksquare$

\proofof{Theorem~\ref{thm:G_star_1}}
The result holds for two views (see Theorem~\ref{thm:nec_suff_cond_loc_rigid_two_views}). Suppose the result holds for $m-1$ views for some $m > 2$. We will show that the result holds for $m$ views. Suppose $|\mathbb{G}^*(\mathbf{S})|=1$. Let $\boldsymbol{\Omega}$ be a certificate of $\mathbf{L}(\mathbf{S})$. We need to show that $\boldsymbol{\Omega}$ is trivial. Since $|\mathbb{G}^*(\mathbf{S})|=1$, $\mathbb{G}$ must have a connected component with at least two views. Pick one such component and note that there exist a view in it such that removing it will not disconnect the component. Let it be the $i$th view. Consider removing the $i$th view and the points which lie exclusively in it. Note that for the new set of views we still have $|\mathbb{G}^*(\mathbf{S}_{-i})|=1$ (where $\mathbb{G}^*_{-i}(\mathbf{S}_{-i})$ is constructed in the same manner as $\mathbb{G}^*(\mathbf{S})$). By Lemma~\ref{lem:subproblem_cert} and the induction hypothesis, we conclude that $[\boldsymbol{\Omega}_j]_{j \in [1,m]\setminus \{i\}}$ must be trivial. Then, by Proposition~\ref{prop:same_conn_comp_non_deg} we conclude that $\boldsymbol{\Omega}$ is trivial.\hfill$\blacksquare$

\proofof{Theorem~\ref{thm:nec_cond_glob_rigid_views}}
Consider a partition of $[1,m]$ into two non-empty subsets $A$ and $B$. Suppose the rank of $\overline{\mathbf{B}(\mathbf{S})}_{A, B}$ is at most $d-1$. As in the proof of Theorem~\ref{thm:nec_cond_loc_rigid_of_views}, WLOG assume that $\mathbf{B}(\mathbf{S})_{A, B}\mathbf{1}_{n'} = 0$ (where $n'$ is as in Definition~\ref{def:BSAcapB}). Then the rank of $\mathbf{B}(\mathbf{S})_{A, B}$ is at most $d-1$. We are going to construct another perfect alignment $\mathbf{S}'$ such that $\pi(\mathbf{S}) \neq \pi(\mathbf{S}')$, thus concluding that $\mathbf{S}$ is not unique.

Let $\mathbf{V}_1, \mathbf{V}_2 \in \mathbb{O}(d)$ and $\mathbf{\Sigma}$ be the diagonal matrix containing the singular values of $\mathbf{B}(\mathbf{S})_{A, B}$ such that $\mathbf{B}(\mathbf{S})_{A, B} = \mathbf{V}_1\mathbf{\Sigma}\mathbf{V}_2^T$. Since rank of $\mathbf{B}(\mathbf{S})_{A, B} \leq d-1$, there exist $\mathbf{U} \in \mathbb{O}(d)$ such that $\mathbf{U} \neq \mathbf{I}_d$ and $\mathbf{\Sigma} = \mathbf{U}\mathbf{\Sigma}$. Define $\mathbf{Q} = \mathbf{V}_1\mathbf{U}^T\mathbf{V}_1^T$. Then $\mathbf{Q} \neq \mathbf{I}_d$ and 
\begin{align}
    \mathbf{Q}^T\mathbf{B}(\mathbf{S})_{A, B} = \mathbf{B}(\mathbf{S})_{A, B}. \label{eq:QTBSAB}
\end{align}
Define $\mathbf{S}' \in \mathbb{O}(d)^m$ such that $\mathbf{S}'_i = \mathbf{S}_i\mathbf{Q}$ for all $i \in A$ and $\mathbf{S}'_j = \mathbf{S}_j$ for all $j \in B$. Clearly, $\mathbf{S}' \neq \mathbf{S}$. We will show that $\mathbf{S}'$ is another perfect alignment. To this end,
\begin{align}
    \text{Tr}(\mathbf{S}'^T\mathbf{C}\mathbf{S}') &= \sum_{i = 1}^{m}\sum_{j=1}^{m}\text{Tr}(\mathbf{S}'^T_i\mathbf{C}_{ij}\mathbf{S}'_j)\\
    &= \sum_{\substack{i \in A, j \in A\\i \in B, j \in B}}\text{Tr}(\mathbf{S}_i^T\mathbf{C}_{ij}\mathbf{S}_j) + 2 \sum_{i \in A}\sum_{j \in B}\text{Tr}(\mathbf{Q}^T\mathbf{S}_i^T\mathbf{C}_{ij}\mathbf{S}_j).
\end{align}
Since, for $i \in A$ and $j \in B$, $\mathbf{C}_{ij} = \mathbf{B}_i \boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}_j^T$, it suffices to show that 
\begin{align}
    \text{Tr}\left(\left(\sum_{i \in A}\mathbf{B}(\mathbf{S})_i\right)\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \left(\sum_{j \in B}\mathbf{B}(\mathbf{S})_j^T\right)\right)  = \text{Tr}\left(\mathbf{Q}^T\left(\sum_{i \in A}\mathbf{B}(\mathbf{S})_i\right)\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \left(\sum_{j \in B}\mathbf{B}(\mathbf{S})_j^T\right)\right) 
\end{align}
Define $\mathbf{B}_A$, $\mathbf{B}_B$,  $\mathbf{B}_{A\setminus B}$, $\mathbf{B}_{A,B}$, $\mathbf{B}_{B\setminus A}$ and $\mathbf{B}_{B,A}$ as in the proof of Theorem~\ref{thm:nec_cond_loc_rigid_of_views}, then it suffices to show that $\text{Tr}(\mathbf{Q}^T \mathbf{B}_A\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}_B^T) = \text{Tr}( \mathbf{B}_A\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}_B^T)$. Using Eq.~(\ref{eq:QTBSAB}, \ref{eq:eq8}, \ref{eq:eq9}) we obtain $\mathbf{Q}^T \mathbf{B}_{A,B} = \mathbf{B}_{A,B}$ and this combined with Eq.~(\ref{eq:eq11}), yields
\begin{align}
    \text{Tr}(\mathbf{Q}^T \mathbf{B}_A\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}_B^T) &= \text{Tr}(\mathbf{Q}^T (\mathbf{B}_{A \setminus B}+\mathbf{B}_{A,B})\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger (\mathbf{B}_{B\setminus A} + \mathbf{B}_{B,A})^T )\\
    &= \text{Tr}(\mathbf{Q}^T \mathbf{B}_{A,B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger\mathbf{B}_{B,A}^T)\\
    &= \text{Tr}( \mathbf{B}_{A,B}\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger\mathbf{B}_{B,A}^T)\\
    &= \text{Tr}((\mathbf{B}_{A \setminus B}+\mathbf{B}_{A,B})\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger (\mathbf{B}_{B\setminus A} + \mathbf{B}_{B,A})^T )\\
    &= \text{Tr}(\mathbf{B}_A\boldsymbol{\mathcal{L}}_{\Gamma}^\dagger \mathbf{B}_B^T).
\end{align}\hfill$\blacksquare$

\proofof{Proposition~\ref{prop:same_conn_comp_uniq}} By replacing $\mathbb{G}$ with $\overline{\mathbb{G}}$ and Theorem~\ref{thm:nec_suff_cond_loc_rigid_two_views} with Theorem~\ref{thm:nec_suff_cond_glob_rigid_two_views}, the inductive proof is essentially same as the proof of Proposition~\ref{prop:same_conn_comp_non_deg}.\hfill$\blacksquare$
%It suffices to show the result for adjacent vertices in $\overline{\mathbb{G}}$. For two views, the result follows from Theorem~\ref{thm:nec_suff_cond_glob_rigid_two_views}. Suppose the result holds for $m-1$ views for some $m > 2$. Then we show the result for $m$ views. If there are no edges in $\overline{\mathbb{G}}$ then the result is trivially valid. Suppose $i$th and $j$th vertices are adjacent in $\overline{\mathbb{G}}$. Let $r \in [1,m] \setminus \{i,j\}$. We remove the $r$th view and the points which lie exclusively in it. Then, by Lemma~\ref{lem:subproblem_cert}, $\mathbf{S}_{-r} = [\mathbf{S}_{k}]_{k \in [1,m] \setminus \{r\}}$ is a perfect alignment of the remaining views. Now, construct $\overline{\mathbb{G}}_{-r}$ (in the same way as $\overline{\mathbb{G}}$) and note that the vertices corresponsing to $i$th and $j$th views are still adjacent in $\overline{\mathbb{G}}_{-r}$. By the induction hypothesis we conclude the result.\hfill$\blacksquare$

\proofof{Theorem~\ref{thm:overline_G_star_1}} Again, by replacing $\mathbb{G}$ with $\overline{\mathbb{G}}$, Theorem~\ref{thm:nec_suff_cond_loc_rigid_two_views} with Theorem~\ref{thm:nec_suff_cond_glob_rigid_two_views} and Proposition~\ref{prop:same_conn_comp_non_deg} with Proposition~\ref{prop:same_conn_comp_uniq}, the inductive proof is essentially same as the proof of Theorem~\ref{thm:G_star_1}.\hfill$\blacksquare$

%The result holds for two views (see Theorem~\ref{thm:nec_suff_cond_glob_rigid_two_views}). Suppose the result holds for $m-1$ views for some $m > 2$. We will show that the result holds for $m$ views. Suppose $|\overline{\mathbb{G}}^*(\mathbf{S})|=1$. Let $\mathbf{S}'$ be a perfect alignment. We need to show that $\mathbf{S}' = \mathbf{S}\mathbf{Q}$ for some $\mathbf{Q} \in \mathbb{O}(d)$. Since $|\overline{\mathbb{G}}^*(\mathbf{S})|=1$, $\overline{\mathbb{G}}$ must have a connected component with at least two views. Pick one such component and note that there exist a view in it such that removing it will not disconnect the component. Let it be the $i$th view. Consider removing the $i$th view and the points that lie exclusively in it. Note that for the new set of views we still have $|\overline{\mathbb{G}}^*_{-i}(\mathbf{S}_{-i})|=1$ (where $\overline{\mathbb{G}}^*_{-i}(\mathbf{S}_{-i})$ is constructed in the same manner as $\overline{\mathbb{G}}^*(\mathbf{S})$). By Lemma~\ref{lem:subproblem_cert} and the induction hypothesis, we conclude that $\mathbf{S}'_{-i} = \mathbf{S}_{-i}\mathbf{Q}$ for some $\mathbf{Q} \in \mathbb{O}(d)$. Then, by Proposition~\ref{prop:same_conn_comp_uniq} we conclude that $\mathbf{S}' = \mathbf{S}\mathbf{Q}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Section 5 Proofs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\proofof{Proposition~\ref{prop:second_order_boundedness_of_RQR}}
Fix $\phi = 1/2$. Then $\left\|\boldsymbol{\xi}_i\right\|_F \leq 1/2$. From Proposition~\ref{prop:liu_qr},
\begin{align}
    \left\|R_{\QR }(\mathbf{S}, \boldsymbol{\xi}) - (\mathbf{S} + \boldsymbol{\xi})\right\|_F^2 &= \sum_1^m \left\|\qf (\mathbf{S}_i + \boldsymbol{\xi}_i) - (\mathbf{S}_i + \boldsymbol{\xi}_i)\right\|_F^2 \leq M^2 \sum_1^m \left\|\boldsymbol{\xi}_i\right\|_F^4\\
    &\leq M^2 \left(\sum_1^m \left\|\boldsymbol{\xi}_i\right\|_F^2\right)^2 = M^2 \left\|\boldsymbol{\xi}\right\|_F^4.
\end{align}
Thus, the result follows for the same values of $\phi$ and $M$ as in Proposition~\ref{prop:liu_qr}.\hfill$\blacksquare$

\proofof{Proposition~\ref{prop:alpha_grad}}
The proof is essentially the same as the one in \citea{liu2019quadratic}. Due to (A2) in Section~\ref{subsec:loc_sub_conv}, WLOG we assume that $\grad F(\mathbf{S}^k) \neq 0$ for all $k \geq 0$. Then, from the proof of Proposition~\ref{prop:gradFS}, since $\grad F(\mathbf{S})_i = \frac{1}{2}\left(\nabla F(\mathbf{S})_i - \mathbf{S}_i\nabla F(\mathbf{S})_i^T\mathbf{S}_i\right)$, thus
\begin{align}
    g(\nabla F(\mathbf{S}^k)_i, \grad F(\mathbf{S}^k)_i) &= \frac{1}{2}\left(\left\|\nabla F(\mathbf{S}^k)_i\right\|_F^2 -g(\nabla F(\mathbf{S}^k)_i,\mathbf{S}^k_i\nabla F(\mathbf{S}^k)_i^T\mathbf{S}^k_i)\right)\\
    &= \frac{1}{4} \left\|\nabla F(\mathbf{S}^k)_i - \mathbf{S}^k_i\nabla F(\mathbf{S}^k)_i^T\mathbf{S}^k_i\right\|_F^2\\
    &= \left\|\grad F(\mathbf{S}^k)_i\right\|_F^2.
\end{align}
Subsequently,
\begin{align}
    g(\nabla F(\mathbf{S}^k), \grad F(\mathbf{S}^k)) &= \sum_1^m g(\nabla F(\mathbf{S}^k)_i, \grad F(\mathbf{S}^k)_i)\\
    &= \sum_1^m \left\|\grad F(\mathbf{S}^k)_i\right\|_F^2 = \left\|\grad F(\mathbf{S}^k)\right\|_F^2.
\end{align}
This, together with lines $3$ and $4$ of Algorithm~\ref{algo:rgd}, and Eq.~(\ref{eq:armijo_step}), implies that
\begin{align}
    F(\mathbf{S}^{k+1})-F(\mathbf{S}^{k}) \leq -\gamma \alpha_k \left\|\grad F(\mathbf{S}^k)\right\|_F^2 \label{eq:eq1}
\end{align}
Since $\mathbb{O}(d)^m$ is compact and $F$ is analytic, thus $F$ is bounded. Since $\alpha_k \in (0,1]$ for all $k \geq 0$, using the above equation,
\begin{align}
    \sum_0^\infty \alpha_k^2 \left\|\grad F(\mathbf{S}^k)\right\|_F^2 &\leq \sum_0^\infty \alpha_k \left\|\grad F(\mathbf{S}^k)\right\|_F^2 \leq \frac{1}{\gamma}(F(\mathbf{S}^0) - \lim F(\mathbf{S}^k)) < \infty.
\end{align}
The result follows.\hfill$\blacksquare$

\proofof{(A1) in Section~\ref{subsec:loc_sub_conv}}
From Proposition~\ref{prop:alpha_grad}, there exists $k_1 \geq 0$ such that $\alpha_k\left\|\grad F(\mathbf{S}^k)\right\| \leq 1/2$ for all $k \geq k_1$. Then from Proposition~\ref{prop:second_order_boundedness_of_RQR}, for all $k \geq k_1$, we have
\begin{align}
    \left\|\mathbf{S}^{k+1} - \mathbf{S}^k\right\|_F &= \left\|R_{QR}(\mathbf{S}^k, -\alpha_k\grad F(\mathbf{S}^k)) - \mathbf{S}^k\right\|_F\\
    &\leq M \alpha_k^2 \left\|\grad F(\mathbf{S}^k)\right\|_F^2 + \alpha_k\left\|\grad F(\mathbf{S}^k)\right\|_F\\
    &\leq (M/2+1)\alpha_k \left\|\grad F(\mathbf{S}^k)\right\|_F.
\end{align}
Finally, for all $k \geq k_1$, using Eq~(\ref{eq:eq1}),
\begin{align}
    F(\mathbf{S}^{k+1})-F(\mathbf{S}^{k}) \leq -\frac{2\gamma}{M+2} \left\|\grad F(\mathbf{S}^k)\right\|_F \cdot \left\|\mathbf{S}^{k+1}-\mathbf{S}^k\right\|_F.
\end{align}
Thus, (A1) holds for $\kappa_0 = 2\gamma/(M+2)$.\hfill$\blacksquare$

\proofof{(A3) in Section~\ref{subsec:loc_sub_conv}}
Since $\nabla F(\mathbf{S}) = 2\mathbf{C}\mathbf{S}$ is Lipschitz with Lipschitz constant $L_F \leq 2\left\|\mathbf{C}\right\|_F$, the proof of (A3) is exactly same as in \citeb[Pg. 235]{liu2019quadratic} or alternatively \citeb[Theorem 2.10]{schneider2015convergence}.
% The proof is essentially the same as the one in \citea{liu2019quadratic}. Due to (A2) in Section~\ref{subsec:loc_sub_conv}, WLOG we assume that $\grad F(\mathbf{S}^k) \neq 0$ for all $k \geq 0$. Then, using line 5 in Algorithm~\ref{algo:rgd} and Proposition~\ref{prop:second_order_boundedness_of_RQR}, we obtain
% \begin{align}
%     \left\|\mathbf{S}^{k+1} - \mathbf{S}^k\right\|_F &= \left\|R_{QR}(\mathbf{S}^k, -\alpha_k\grad F(\mathbf{S}^k)) - \mathbf{S}^k\right\|_F\\
%     &= \left\|R_{QR}(\mathbf{S}^k, -\alpha_k\grad F(\mathbf{S}^k)) - (\mathbf{S}^k-\alpha_k\grad F(\mathbf{S}^k)) -\alpha_k\grad F(\mathbf{S}^k)\right\|_F\\
%     &\geq \left\|\alpha_k\grad F(\mathbf{S}^k)\right\|_F - \left\|R_{QR}(\mathbf{S}^k, -\alpha_k\grad F(\mathbf{S}^k)) - (\mathbf{S}^k-\alpha_k\grad F(\mathbf{S}^k))\right\|_F\\
%     &\geq \left\|\alpha_k\grad F(\mathbf{S}^k)\right\|_F - M \alpha_k^2 \left\|\grad F(\mathbf{S}^k)\right\|_F^2
% \end{align}
% Dividing by $\left\|\alpha_k\grad F(\mathbf{S}^k)\right\|_F^2$ and using Proposition~\ref{prop:alpha_grad}, we obtain
% \begin{align}
%     \lim \frac{\left\|\mathbf{S}^{k+1} - \mathbf{S}^k\right\|_F}{|\alpha_k|\left\|\grad F(\mathbf{S}^k)\right\|_F} \geq 1
% \end{align}
\hfill$\blacksquare$

\proofof{Proposition~\ref{prop:morse_bott_1}}
 Since $\pi(\mathbf{S}^*)$ is non-degenerate, $\widetilde{F}$ being Morse-Bott at $\pi(\mathbf{S}^*)$ follows from \cite[Definition 6.5]{usevich2020approximate}. Since non-degenerate critical points of a smooth function are isolated from other critical points, it follows again from \citea{usevich2020approximate} that $\widetilde{F}$ is Morse-Bott in a sufficiently small neighborhood of $\pi(\mathbf{S}^*)$. 
 
 Then, since the action of $\mathbb{O}(d)$ on $\mathbb{O}(d)^m$ is free and the function $F$ is invariant under the action of $\mathbb{O}(d)$ ($\mathbf{S}\mathbf{Q} = \mathbf{S} \iff \mathbf{Q} = \mathbf{I}_d$ and $F(\mathbf{S}\mathbf{Q}) = F(\mathbf{S})$ for all $\mathbf{S} \in \mathbb{O}(d)^m, \mathbf{Q} \in \mathbb{O}(d)$), the result follows from \citeb[Section 15.2]{cohen_iga_norbury_2006}.% and \citea{austin1995morse}.
 \hfill$\blacksquare$