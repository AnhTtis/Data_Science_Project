\section{Conclusion}
We present a novel setting for affordance grounding, which utilizes the 2D interactive semantics to guide the grounding of 3D object affordance, it has the potential to serve embodied systems when collaborating with multi-modal grounding systems \cite{liu2019adaptive, tan2020learning, yang2019making}. Besides, We collect the PIAD dataset as the first test bed for the proposed setting, it contains paired image-point cloud affordance data. Plus, we propose a novel framework to correlate affordance regions of objects that are from different sources and model interactive contexts to ground 3D object affordance. Comprehensive experiments on PIAD display the reliability of the setting, and we believe it could offer fresh insights and facilitate research in the affordance area. \\
\textbf{Acknowledgments} This work is supported by National Key R\&D Program of China under Grant 2020AAA0105700, National Natural Science Foundation of China (NSFC) under Grants 62225207, U19B2038 and 62121002.