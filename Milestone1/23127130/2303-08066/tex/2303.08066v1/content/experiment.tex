\section{Evaluation}

% Here the methodology of the whole experiment is first described.

\subsection{Methodologies}

% Here the simulator, used data flow (workflow info such as cold/hot ratio etc.), evaluated metrics and compared methods are described here.
% The controller is implemented in a simulator currently. It will be deployed in embedded systems such as FPGA.


\noindent\textbf{Testbed.} To verify the effectiveness of \Pascal{}, all experiments are conducted in a commercial HSS, Huawei OceanStor Dorado 5210 V5. The storage system is with 24-core 2.6GHZ CPU*2, 64GB RAM*8 (as caching tier), 0.96TB SSD*8 (as SSD tier) and 0.96T SAS*48 (as HDD tier).
% we additionally design and implement a hierarchical storage simulating system as shown in Figure~\ref{fig: simulator}.  The simulating system could facilitate the test and evaluation \Pascal{} under different workloads with various parameter setting, which is comprised of three components, namely IO queue, resource monitor, multi-layer hierarchical storage module. Specifically, the IO queues received IO requests derived from workloads, where the read request is prioritized to be processed than write one. For each request, its arrival follows a \textit{Poisson} process. And its access address and amount of system resource consumption are drawn from two various uniform distributions which are unknown to \Pascal{}. The resource monitor is responsible for simulating the resource consumption described above. In details, a given amount of system resource (based on hardware configuration) is reset before the starting of a time interval. And the monitor will update the available resource after each IO request being processed. Once the available resource is exhausted in this time interval then the rest of IO requests will be left to the next time interval. Besides, the hierarchical storage module is used to simulate the hierarchical storage structure. Inside the module, there are total three tiers representing the Flash tier, SSD tier and HDD tier respectively. They all have the same maximum bandwidth of 3680 MB/s. They are different in the maximum capacity (Flash: 78 GB, SSD: 780 GB and HDD: 4521 GB) and speed (Flash: 0.03 ms, SSD: 0.34 ms and HDD: 7.4 ms). And the data migration relation inside them is in accordance with description in Section~\ref{sec: problem_definition}.


% The simulator is designed capable to compare different algorithms in a convincing manner. It is mainly constructed by three modules, namely an IO queue, a resource monitor, and a multi-layer model formed to imitate a hierarchical storage system.

% While the simulator is working, IO queue receives IO requests continuously and stores it orderly. Meanwhile, the requests having already waited in the queue are processed and popped out of the queue. Considering that the latency of read request is more sensitively perceived by users, read requests are always processed preferentially in practical. The same rule is migrated to our simulator as a matter of course. More specifically, in every tiny time period that is divided, system resources are first allocated to conduct read requests. These read requests is aiming to access information stored somewhere in storage system, which probably is cache, SSD or HDD. For any certain read request, the access address and how much resource it is consuming is generated randomly. Therefore, the sum of resource that is consumed by read requests are also unpredictable and random. In another words, a black box is created to function as a processor of read requests, whose mechanism is invisible for the outside. The only information that comes out of the black box is the consumption of resources, that is, resources cannot be utilized by the write 
% requests. Not until there is no read request left in queue, the write request is arranged to be processed.

% The module dominate the allocation and supervision of resource is so called resource monitor. For a short time interval, resource monitor gives a certain amount of resource that is viable for IO procession.  simultaneously as the requests is processed, resource monitor takes statistics of resource consumption. Once a kind of resource is exhausted, resource monitor raises an alert immediately, forcing the procession of IO request to stop. This static situation will last until next time interval is arriving and additional resource is available.

% Besides those two parts, the most significant module of the simulator is a multi-layer model, which is strictly designed as is described in \textit{problem definition} part. Three tier is constructed and connected sequentially, which are cache, SSD and HDD. The properties of them is set based on the values obtained from the actual test.  


\noindent\textbf{Workloads.} Two categories of workload, i.e., the synthetic workloads and real-world workloads are used in the experiments. The synthetic workloads are generated using the open-source benchmarking toolkit Vdbench~\cite{2010VDBench} which is commonly used to evaluate the storage system. We can easily generate 20 workloads via tuning the parameters of the tool (such read/write mix, queue depth, block size, IO size, etc). While five real-world workloads are collected from our customers, which is anonymized due to the business security requirements. For conciseness of experiments, within each category we merge different workloads and process them into one workload which lasts 25,000 seconds.

% A workload pattern is actually a specific combination of read requests and write requests. To create a request, whether a read one or a write one, several attributes is previously configured. For instance, the average size and distribution range of records that could be accessed. In addition to that, the number of requests per second, the proportion of operations should be reads and writes are required to be predefined. In such manner, a distinct workload is generated.

% To make the test more challenged, several patterns of workload is predefined, each of whom has a unique set of configurations. During the test, various workload would be switched chaotically.


\noindent\textbf{Comparing targets.}
% To compare the performance of \Pascal{}, we have devised three heuristic method as baseline. The details of them will be described as follow:
Three rule-based methods are used as baseline to evaluate \Pascal{}, of which each is described concisely below:
\begin{itemize}[leftmargin=*]
    \item Baseline 1 is a rule-based control method modified from LBICA~\cite{2019LBICA}, which is implemented at each tier. In simple terms, for one storing tier, Baseline 1 will greatly reduce the bandwidth of data migration into the tier once it finds that the capacity utilization of the tier is beyond a given threshold.
    \item Baseline 2 is a derivative of the classic PID controller~\cite{2005PID}, where bandwidth is the controlling object and we replace the integral of the bandwidth with corresponding watermark level. 
    
    % Therefore, using the amount of corresponding waterlevel as the integral ingredient in the PID controller is effectively.
    \item Baseline 3 is a systematic bandwidth control scheme adopted in Huawei's current storage products. The detailed techniques can be referred to~\cite{oceanstor}.
    
\end{itemize}


\noindent\textbf{Metrics of interest.}
The \textit{99\%th tail latency}, \textit{mean throughput} and \textit{throughput jitter} are mainly considered in our evaluation. Note that the throughput jitter is measured using 
\begin{equation}
     \sqrt{\frac{\sum_{t = 0}^{T}(I_t - \overline{I_t})^2}{T}}/ \overline{I_t} \quad\quad\quad 
    %  \sum_{t=1}^T (I_t - I_{t-1})^2
     \label{eq: obj_jitter}
\end{equation} 
where $I_t$ is the throughput at time interval $t$ and $\overline{I_t}$ is the average throughput during the workloads. We expect the storage system to have low IO latency, low throughput jitter and high mean throughput simultaneously.
\vspace{-2ex}
% IO latency and throughput.

% The relation between above metrics and flush rate.

\subsection{Performance evaluation}

The performance comparison among \Pascal{} and baselines were carried out over the two workloads. The results are reported in Table~\ref{tab: overall_performance}. To be more intuitive, the above results are visualized in Figure~\ref{fig: Overall}. As is shown in Figure~\ref{fig: Overall}, \Pascal{}
outperforms all compared baselines in terms of throughput jitter (at least 2X improvement) and tail latency (at least 1.95X improvement), which achieves parts of our optimization goals. Meanwhile, \Pascal{} is able to maintain high mean throughput. Specifically, on the synthetic workload \Pascal{} can achieve the highest mean throughput (1282.98 MB/s) among all compared methods; For the real-world workload, the mean throughput performance with \Pascal{} is a little bit lower than that of other methods but still comparable. That \Pascal{} achieves such a good performance on tail latency and throughput jitter is due to the global view of data migration planning. Besides, \Pascal{} prefers to sacrifice throughput to gain the improvement of performance stability, which is in accordance with the purpose of clients.
\vspace{-2ex}
% performs obviously in a superior way, comparing to other methods in terms of stability. Benefited from its holistic decision-making mechanism, the throughput controlled by \Pascal{} shows nearly no noisy disturbance. Besides, though the average throughput of \Pascal{} is close to others'. It behaves outstandingly in decreasing the tail latency. As \Pascal{} makes a great effort in guaranteeing the security of system, procession bottlenecks are greatly reduced, which leads to a significant improvement of tail latency.



\begin{table}[t]
\begin{center}
\caption{Summary of performance evaluation results}
\scalebox{0.78}
{
\begin{tabular}{|c|c|c|c|c|}
\hline
Workload & Method & Mean throu. (MB/s) & Tail latency (ms) & Throu. jitter \\
\hline
\multirow{4}*{Synthetic} & Ours & \textbf{1282.98} & \textbf{22.36} & \textbf{3.37e-02} \\
\cline{2-5}
~ & Baseline 1 & 1269.97 & 150.97  & 7.95e-02 \\
\cline{2-5}
~ & Baseline 2 & 1273.08 & 244.69 & 1.49e-01 \\
\cline{2-5}
~ & Baseline 3 & 1253.17 & 170.62 & 7.53e-02 \\
\hline
\multirow{4}*{Real-world} &Ours & 1277.56 & \textbf{52.31} & \textbf{3.87e-02} \\
\cline{2-5}
~ & Baseline 1 & \textbf{1310.23} & 129.85 & 9.02e-02 \\
\cline{2-5}
~ & Baseline 2 & 1303.14 & 252.40 & 1.50e-01 \\
\cline{2-5}
~ & Baseline 3 & 1283.61 & 155.92 & 7.61e-02 \\
\hline
\end{tabular}
}
\label{tab: overall_performance}
\end{center}
\end{table}

% \begin{figure}[t]
% \centering

% \begin{subfigure}
%     % include first image
% \includegraphics[width=1.0\linewidth]{figure/comparison_0.pdf}  
% %   \caption{Put your sub-caption here}
% \label{fig:sub-first}
% \end{subfigure}
    
% \begin{subfigure}
%     % include second image
% \includegraphics[width=1.0\linewidth]{figure/comparison_1.pdf}  
% %   \caption{Put your sub-caption here}
% \label{fig:sub-second}
% \end{subfigure}

% \label{fig:fig}
% \caption{Overall performance evaluation results}
% \end{figure}

\begin{figure}[t]
	\centering
	\subfigure[Compared results over synthetic workload]{
		\includegraphics[width=0.8\linewidth]{figure/comparison_0.pdf}
		\label{fig:syn-workload}
	}
	\subfigure[Compared results over real-world workload]{
		\includegraphics[width=0.8\linewidth]{figure/comparison_1.pdf}
		\label{fig:real-workload}
	}
	\caption{Visualization of overall performance evaluation}
	\label{fig: Overall}
\end{figure}


% % \begin{figure}[t]
% % \centering
 
% %     \begin{subfigure}
% %     % include first image
% %     \includegraphics[width=1.0\linewidth]{figure/ablation_Bayesian_0.pdf}  
% % %   \caption{Put your sub-caption here}
% %     \label{fig:sub-first}
% %     \end{subfigure}
    
% %     \begin{subfigure}
% %     % include second image
% %     \includegraphics[width=1.0\linewidth]{figure/ablation_Bayesian_1.pdf}  
% % %   \caption{Put your sub-caption here}
% %     \label{fig:sub-second}
% %     \end{subfigure}
    
% %     \begin{subfigure}
% %     % include first image
% %     \includegraphics[width=1.0\linewidth]{figure/ablation_No-Bayesian_0.pdf}  
% % %   \caption{Put your sub-caption here}
% %     \label{fig:sub-first}
% %     \end{subfigure}
    
% %     \begin{subfigure}
% %   % include second image
% %     \includegraphics[width=1.0\linewidth]{figure/ablation_No-Bayesian_1.pdf}  
% % %   \caption{Put your sub-caption here}
% %     \label{fig:sub-second}
% %     \end{subfigure}

\begin{figure}[t]
	\centering
	\subfigure[Bayesian optimization inside \Pascal{} on synthetic workload]{
		\includegraphics[width=0.8\linewidth]{figure/ablation_Bayesian_0.pdf}
% 		\label{fig:real-nuv}
	}
	\subfigure[Bayesian optimization inside \Pascal{} on real-world workload]{
		\includegraphics[width=0.8\linewidth]{figure/ablation_Bayesian_1.pdf}
% 		\label{fig:real-moc}
	}
	\subfigure[Without Bayesian optimization inside \Pascal{} on synthetic workload]{
		\includegraphics[width=0.8\linewidth]{figure/ablation_No-Bayesian_0.pdf}
% 		\label{fig:real-nuv}
	}
	\subfigure[Without Bayesian optimization inside \Pascal{} on real-world workload]{
		\includegraphics[width=0.8\linewidth]{figure/ablation_No-Bayesian_0.pdf}
% 		\label{fig:real-moc}
	}
	\caption{Evaluation result of ablation studies}
	\label{fig: ablation study}
\end{figure}
    

    
% \label{fig:fig}
%     \caption{Ablation studies}
% \end{figure}

% \noindent\textbf{Performance under static workload.}

% \noindent\textbf{Performance under dynamic workload.}

% \noindent\textbf{Memory footprint and computing cost.}


\subsection{Ablation studies}
\label{sec: ablation study}

% Here it will be discussed and justify the necessaries of each component in the proposed method.
% Comparing the testing results with and without Bayesian optimization, an apparent conclusion can be drawn out that Bayesian optimization enhances the performance remarkably, whether in respect of stability or mean throughput. As for resource predictor, three extremely simple methods are applied for constructing a \Pascal{} controller. the performance of whom is almost even. Due to the outstanding security of \Pascal{}, bias of prediction impacts negligibly in damaging the normal operation of the system. Actually, the main function of predictors is helping to make full use or resources. Besides, the prediction has better to be stable, as the volatility of it effects the throughput finally.

According to the discussion in Section~\ref{sec: discussion}, many alternative algorithms can be incorporated into \Pascal{} to further improve its performance. 
% Here we perform \Pascal{} over the same workload as above with and without Bayesian optimization to testify the importance of cooperation. Besides, 
Here we first investigate how \Pascal{} behaves with and without Bayesian optimization to testify the significance of cooperation. The form of mapping function is fixed as follows:
\begin{equation}
    p = p^* (\frac{1-w^*}{1-w})^\alpha
\end{equation}
where $\alpha$ and $w^*$ are the hyperparameters need to be tuned.
% Usually, the value of $\alpha$ is determined by human expert. Here we resort to Bayesian optimization~\cite{0BOA} method to tune the hyperparameter.
Besides, we investigate how \Pascal{} behaves with various implementations of resource efficiency prediction. Three simple methods as the predicting function are adopted, namely Exponential Moving Average (EMA)~\cite{DBLP:journals/eswa/NakanoTT17}, mean and min function of historical data. To this end, a queue with length of 50 is maintained to store the historical resource efficiency data.
With above setting, the ablation studies were performed over the two workloads. The results are reported in Figure~\ref{fig: ablation study}. Observed from the results, it is obvious that \Pascal{} with Bayesian optimization performs much better than one without finely tuned mapper function in terms of throughput jitter. Besides we also find that \Pascal{} is not much sensitive to the accuracy of resource efficiency prediction because there is no great difference in terms of throughput jitter when using various resource prediction function. However, more advanced prediction tools and models such as transformer~\cite{DBLP:journals/corr/VaswaniSPUJGKP17} might bring more performance improvement into \Pascal{}, which is left to the future work.

% \vspace{-2ex}