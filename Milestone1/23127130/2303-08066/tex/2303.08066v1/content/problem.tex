
\section{Background}

% \subsection{Multi-level hierarchical Storage Architecture}

% Nowadays, more and more enterprise storage systems adopts the hierarchical storage architecture, which is also known as multi-layer storage system~\cite{1995Three, 2014Proactive, Vengerov08}. The architecture is made of various storage medias which are different in the terms of speed, efficiency, capacity and price, such as tape, HDDs, SSDs, Flash, etc. The storage medias are placed at different levels of the architecture to meet the demand of both performance and cost. For example, the fast storage tiers usually are expensive and smaller in capacity, such as SSD and Flash. Whereas the slow one are relatively cheap and significantly large in capacity, such disk and tape. Within such a hierarchical storage architecture, stored data are distributed at above storage tiers according to some specific indicators (such as hotness level~\cite{Vengerov08}). The architecture is considered to be an ideal model which could achieve the best performance with the lowest cost simultaneously~\cite{DBLP:journals/fcsc/XuLLZSDZWZCXY14, DBLP:journals/corr/abs-1207-0147}. 
 
% Figure~\ref{fig:problem_description} gives an example of three-tier hierarchical storage architecture, which is defined by the access speed, storage capacity and corresponding price. The fastest tier is comprised of memory or Flash, which are the most expensive and small in capacity; The middle tier is made of SSD, which is relatively less expensive and larger in capacity; The slowest tier consists of HDD, which is the cheapest and largest in capacity. In general, it is desirable to place the `hot' data, that is requested most frequently in recent periods, in fast tiers while keeping `cold' data that is requested less frequently at the slow tiers. The stored data could be moved between each tiers (i.e., data migration) within the hierarchical storage architecture to improve the availability of data and performance of the whole system. Many data migration policies~\cite{Vengerov08} have been proposed to optimally migrate data in order to minimize the average system response time given a fixed bandwidth limit for each tier. This paper would like to investigate the problem in another angle of view, that is how to optimally control the bandwidth for each tier given a specific data migration policy.

% %  Generally, the forthcoming storage product of HUAWEI is with hierarchical storage architecture, where flash, SSD and HDD are placed in different layers of the three-layer architecture so as to maximize the hardware performance. One I/O request entering into the system will flow each layer of the system (see Figure~\ref{fig:problem_description}). 

% \begin{figure}[h]
% 	\centering
% 	\includegraphics[width=0.85\linewidth]{figure/problem_description.pdf}
% 	\caption{Multi-layer bandwidth control problem in Huawei OceanStor}
% 	\label{fig:problem_description}
% \end{figure}

% Firstly, several fundamental concepts and holistic structure of our system are presented, such as the operation of flush, tierdown etc. The data flow in above operation can be seen in Figure~\ref{fig:data_flow}.
% ==============================================================================

% \begin{figure*}[h]
% 	\centering
% 	\includegraphics[width=0.75\linewidth]{figure/dac_figure_flow.pdf}
% 	\caption{The data migration in hierarchical storage system can be mapped into a Directed Acyclic Graph (DAG).}
% 	\label{fig: prob_map}
% \end{figure*}

% \section{Analysis of hierarchical storage architecture}
% First we analyze the bottleneck and limitation of current hierarchical storage architecture via presenting some preliminary experimental results.

% The challenges and issues of solving the problem are presented.

\subsection{System Overview}
\label{sec: system_overview}
A three-tier hierarchical storage system as an example is given in Figure~\ref{fig: problem_description}. The fastest (top) tier is comprised of Flash, which is the most expensive and the smallest in capacity. The middle tier is made of SSD, which is relatively less expensive and larger in capacity. The slowest (bottom) tier consists of HDD, which is the cheapest and largest in capacity. The whole system receives IO requests from client servers and store them at above tiered storage media. And the data can migrate between above tiers. There are mainly three classes of data migration. The first class is that data comes from outside into HSS, i.e., IO requests issued by client server, which is called \textit{Throughput} in this paper (as shown in Figure~\ref{fig: problem_description}). The second class is that data migrates between tiers within HSS, such as Flush, Tierdown presented in above figure. The third one is that data will be cleaned out from HSS to make room for new data, such as Garbage Collection (GC). Generally, only tiers of large capacity (e.g., SSD, HDD) have GC tasks.
% \vspace{-4ex}
\subsection{Problem Description}
\label{sec: formulation}
For above data migration processes, there is a theoretical maximum size of data transfer from source to destination within a time period, namely, bandwidth. In HSS, the bandwidth control is to simultaneously adjust the bandwidth value of various data migration tasks in real time. Usually, the client servers care more about the throughput and related metrics (such as throughput stability and tail latency) than the bandwidth of internal data migration task (e.g. flush, tierdown and GC). Thus, for bandwidth control in HSS, our goal is to make the bandwidth of throughput as high as possible and meanwhile maintain it stable. It has to be noted that there are some constraints need to be considered during bandwidth control. First, the bandwidth control is supposed to assure that the capacity utilization of each tier is within an appropriate range. Specifically, the resource goes to waste and the performance degrades, when the capacity utilization of high speed storing tier (e.g. Flash) is too low; the data migration will be blocked or even worse the system collapses if the capacity utilization of one or more storing tiers is too high. Secondly, the bandwidth control is subject to real-time system resource condition such as the  idle CPU core.

It is very challenging to design a good bandwidth control policy for HSS. The challenges are listed below:
1) It is apparently that there are many data migration tasks involved in bandwidth control, which should be adjusted coordinately. 2) A data migration task is a complex process since that the data stored in HSS is further discriminated in each tier actually. Specifically, some data will be classified as valid and other is labeled as garbage, which is considered in data migration tasks. For examples, the tierdown task only migrates those valid data stored in SSD tier to HDD tier. Meanwhile, valid data being migrated is labelled as garbage in SSD tier, which is equal to that the data is migrated from the valid class to the garbage class. Besides, the data migrated by flush task will both change the size of valid/garbage data in SSD tier, as shown in Figure~\ref{fig: problem_description}. 3) There are many random factors that affect the data migration, such as data access pattern of incoming IO requests and resource contention with other system processes. It is hard to accurately predict the behavior of above random processes; 4) Multiple optimization objectives need to be achieved simultaneously. Some of objectives might contradict with each other such as the performance maximization and its stability. All of above aspects are required to be considered in designing bandwidth control policy.


% There are mainly five background tasks related to bandwidth control, namely throughput, flush, tierdown and garbage collection. The bandwidth of throughput determines the total size of data of IO requests issued to the storage system per unit time, which is directly perceived by the client server.
% And the bandwidth of flush and tierdown controls the total size of data migration between tiers per unit time. As shown in Figure~\ref{fig: problem_description}, the flush task is responsible for migrating data from Flash tier to SSD tier and the duty of tierdown is to migrate data from SSD tier to HDD tier. It should be noted that during the process of flush and tierdown, the data to be migrated is written to the destined tier and also kept at its origin tier. Obviously, the kept data is duplicated (also called garbage data), which will be cleaned by garbage collection (GC) task to make room (i.e., free block) for new data. Thus the bandwidth of GC determines the total size of garbage data being cleaned per unit time.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\linewidth]{figure/problem_description.pdf}
	\caption{A three-tier hierarchical storage system (left part). The data migration and bandwidth control between tiers can be mapped into a Directed Acyclic Graph (DAG).}
	\label{fig: problem_description}
\end{figure}

% In general, it is desirable to place the `hot' data, that is requested most frequently in recent periods, in fast tiers while keeping `cold' data that is requested less frequently at slow tiers. The stored data could be moved via different tasks (such as throughput, flush, tierdown, garbage collection shown in Figure~\ref{fig: problem_description}) between each tiers, i.e., data migration, within the hierarchical storage architecture to improve the availability of data and performance of the whole system. Many data migration policies for hierarchical storage system~\cite{Vengerov08, 2014Proactive} have been proposed to optimally migrate data in order to minimize the average system response time. In these work~\cite{Vengerov08, 2014Proactive}, the authors always assume that there is a bandwidth limit for each tier. However, 
% The recent storage systems are capable of adjusting bandwidth at run time. 

% There are five data migration tasks marked in the figure, which can be grouped into three categories. The first class of data migration is so called throughput, which is equal to the net inflow of the whole system. As for the system shown in the Figure~\ref{fig: problem_description}, bandwidth of throughput is essentially the size of data moving into the cache. Throughput affects the procession speed of write requests directly. Hence, a low or over fluctuating throughput could be easily sensed by host side, which makes throughput control indispensable for improving  the performance of storage system.

% Another class of data migration is those between the tiers, e.g., flush and tierdown noted in ~\ref{fig: problem_description}. The data migration from one tier to another not always obeys the same rule. For example, the job of flush is simply moving data from cache to SSD. However, to move data from SSD to HDD, it first need to copy the appointed data in SSD. Then the copied data is pasted to HDD and the origin data is signed as garbage data. 

% The last class of data migration tasks is garbage collection(GC), whose target is to delete the duplicated data and increase the available space. Garbage collection is also a complex process including several steps.Taking the GC of SSD tier(GC0) as an example, it actually consists of three steps. First, several storage regions in the SSD is chosen according to a predefined algorithm. Then, all the valid data stored in those regions is copied and pasted to the other regions. Finally, all the chosen regions is formatted so that the space of them is available again.

% For a system with more tiers or more complicated structure, there are naturally more data migration tasks. However, all of them still can be grouped to the categories described above. Coordination those tasks properly helps to improve the performance significantly meanwhile ensure the security of the system. 

% There are many previous work that investigates the bandwidth control for the cache~\cite{DBLP:conf/sigmod/KunjirFMB17, 2018LBICA, Jaehyung2017Selective}.

\subsection{Motivations}

The bandwidth control policy proposed for caching and networking optimization cannot be directly applied in HSS without non-trivial modification. To prove it, we design a rule-based bandwidth control policy modified from LBICA~\cite{2018LBICA} and deploy it at each tier of a commercial HSS. The experimental results suggest that it cannot perform as good as in non-hierarchical storage system, which is recorded as \textbf{Baseline 1} in Table~\textcolor{red}{\ref{tab: overall_performance}} and Figure~\textcolor{red}{\ref{fig: Overall}}.
It can be inferred that the poor performance of LBICA-like control method in HSS is due to that it cannot cooperatively control multiple bandwidths. 

Certainly, the existing bandwidth control policies could still perform good in HSS via elaborate modification but the process must need human experts to make lots of efforts and be time-consuming. Besides, it is expected that the architecture of HSS becomes more complex with the rapid development of storage medium. Then the expert-driven design is undesirable in the future. Thus we would like to design a cooperative bandwidth control policy for HSS which could easily adapt to new architecture with the help of machine learning techniques.

% The most basic motivation for bandwidth control is to keep the size of data stored in a certain media within a proper range, namely water level control. For instance, it is desirable to place the data requested most frequently in cache to reduce the response time of read requests. Naturally, the more data stored in cache, the more possible that the read requests hit the cache. Therefore, there is a lower limit for the water level of cache for the purpose of improving the performance of system. However, high water level also causes  the danger of exceeding the capacity of cache,  to avoid whom a upper limit of the water level is given also. Furthermore, there may be more than one water level indicator in a single tier. That is because the data stored in a tier is divided into several categories according to its attributions. For instance, the data stored in SSD is labeled as valid data or garbage data. The proportion of valid data to the total capacity of SSD is so called valid water level. Meanwhile, the water level of the sum of data is namely physical water level. Both of the water level mentioned need to be kept in the predefined range.

% If there was only one tier need controlled, the challenge to maintain the water level would mainly arise from the uncertainty of migration efficiency. It has been indicated above that data migration tasks could be a complex process. Hence, though a certain number of threads can be assigned to conduct data migration tasks, the effect is though unpredictable due to its complexity.

% In addition to water level control, bandwidth control also benefits to improve throughput of the system. By adjusting bandwidth at run time, the throughput of whole system can be as maximized and stable as possible. In order to achieve this purpose, more indicators are taken into consideration, such as the resource utilization of the system. In general, the throughput is increased while there is still resource available. 

% Many previous works studied the bandwidth control problem for a single task or a single tier~\cite{DBLP:conf/sigmod/KunjirFMB17, 2018LBICA, Jaehyung2017Selective}. However, controlling all the bandwidth in the system  separately always leads to inefficiency and conflict among tasks. The target of one task may be contradictory to it of another and the action of one controller may mislead others to taking undesirable control measures. 

% In order to achieve all of the above objectives simultaneously meanwhile avoid separate regulation, a cooperative control scheme is of significant importance. Hence, we propose \Pascal{} to solve the problem. By introducing the technique in details, a well-defined model is first formulated, which is extremely beneficial for understanding the mechanism of \Pascal{}.

% Many previous works~\cite{Vengerov08, 2014Proactive} mainly studied the data migration problem where each storage tier is given a limited bandwidth and the bandwidth is shared between file IO requests and file transfers among tiers. In above work, the bandwidth is fixed for each tier at any point of time. However, in recent storage system, the bandwidth can be changed via adjusting the number of concurrent thread of corresponding task~\cite{}. Thus there is a bandwidth control problem in storage system and many previous related work~\cite{DBLP:conf/sigmod/KunjirFMB17, 2018LBICA, Jaehyung2017Selective} studied it well. It should be noted that in hierarchical storage system, few research pays attention to the bandwidth control problem, especially under the online scenario. This work dedicates to optimize the online bandwidth control problem in the hierarchical storage system. It should be admitted that considering both data migration policy and bandwidth control policy simultaneously is extremely hard. Besides, to draw a clear boundary line between the two distinct problems, the following assumptions are first made. 

% Then the mathematical model is presented.

% Assumption regarding the data migration policy.

% \begin{assumption} [IO request routing policy] IO requests (such as read, write and update requests) arrive in the system stochastically for each file. We assume that a certain policy exists in the system for routing new IO requests. For a file write request, it will write the file to the fastest tier that has enough space for the file; for a file read request, the request will be routed to the tier that has the smallest expected response time among all tiers containing that file; for a file update request, it will be routed to all tiers containing that file. 
% \end{assumption}

% \begin{assumption}[Data migration policy]
% For files stored within the hierarchical storage system, they can be moved among the tiers. The data migration could occurs in a proactive way or be triggered by IO requests. We assume that there is a certain policy (such as size-temperature replacement policy~\cite{Vengerov08}) for data migration.
% \end{assumption}
% \vspace{-2ex}
\section{Design of \Pascal{}}
\label{sec: design}

% Based on above assumptions, our goal is to \textit{make the throughput of whole system as maximized and stable as possible} via coordinating the bandwidth of corresponding storage tiers.
% Based on problem description,  our goal is to \textit{make the throughput of whole system as maximized and stable as possible } via coordinating the bandwidth of corresponding storage tiers, while \textit{keeping some necessary water levels within a proper range}.

% It is mentioned above that the data in a single tier can be further classed to different categories, which generated several water level for control problem. Thus, it can be considered equivalently as several areas making up the tier. Therefore, a virtual concept, node, is proposed to represent those areas. For example, under this assumption, the SSD tier can be represented by a valid data node and a garbage data node. The advantage of this notation is that the data migration tasks can be simply represented as a set of edges, which are the connections between nodes. For example, tierdown consists of two edges. One is an edge from the valid node of SSD to the garbage node of SSD. Another is the valid node of SSD to the node of HDD. 
\subsection{Formulation}
In this paper, we use a Directed Acyclic Graph (DAG) $G=(V,E)$ to model the data migration process in HSS,
where each node $i \in V$ represents one of the storage tiers (or a class of data stored within a tier such as valid/garbage data in SSD tier) and each directed edge $e_{i,j}\in E$ $(i,j\in V)$ that connects with one pair of nodes $(i,j)$ denotes the data migration relation between the two nodes (see Figure~\ref{fig: problem_description}). 
% To generalize the bandwidth control problem in the hierarchical storage system, we map the system to a Directed Acyclic Graph (DAG) $G=(V,E)$, where each node $i \in V$ represents one of the storage tiers (or part of data stored within the tier such as hot/cold/garbage data in SSD tier) and each directed edge $e_{i,j}\in E$ $(i,j\in V)$ that connects with one pair of nodes $(i,j)$ denotes the data migration relation between the two nodes (see Figure~\ref{fig: prob_map}). 
The structure of the DAG can be represented by a matrix $\mathbf{E} = (\mathbf{e}_{ij})_{i,j\in V}$, where the value of $e_{i,j}$ is defined as:
\begin{equation}
    e_{ij} =\left\{
    \begin{array}{lr}
    -1, \text{if } i\to j \\
    1,  \text{if } j \to i \\
    0,  \text{if } i \nleftrightarrow j
    \end{array}
    \label{eq: vec_edge}
\right.
\end{equation}
In the equation above, $\to$ denotes the direction of data migration; $\nleftrightarrow$ represents that there is no connecting relation between the two nodes. 
For each node $i$, it is described by some indicators including real-time watermark level $w_i$ (capacity utilization), maximum capacity $C_i\in\mathbb{R}^+$, and the lower and upper bound of watermark level ($\underline{w}_i, \overline{w}_i \in[0,1]$ and $\underline{w}_i\leq \overline{w}_i$). For each edge $e_{i,j}$, its direction denotes the direction of the corresponding data migration and its width $x_{i,j}\in\mathbb{R}$  
represent the amount of data migrated from node $i$ to node $j$. For the h$th$ data migration task $\mathbb{B}_h$, it comprises one or several edges, which is represented as $e_{i,j} \in \mathbb{B}_h$ (see Figure~\ref{fig: problem_description}). The data migrated by the task is denoted as $d_h$ meanwhile the bandwidth assigned to it is denoted as $b_h$, which is considered as a consumption of resource. 
Besides, the bandwidth control will consume a certain amount of other kinds of system resource such as CPU, memory, etc. It is appropriate to assume that there are totally $K$ kinds of resource within the system, each of whom is associated with a upper limit $R_k\in\mathbb{R}^+$ ($k\in\{1,2,...,K\}$) predefined by the hardware. And $r_{h}^k\in\mathbb{R}^+$ denotes the amount of resource $k$ consumed by one unit of $d_h$. 
% It should be noted that the structure of DAG is defined by both the software and hardware. Thus the relation between nodes is known apriori and constant in the whole control process. Besides, 
The bandwidth control is a continuous-time process. However,  we do not adjust the bandwidth in a high frequency in practice. Instead, for a given time duration $T$ (such as an integral workload or infinite time horizon), it is split into time intervals of equal length $T_0$. Thus some above variables will be attached with the timestamp $t$, such as $w_{i}^t, x_{i,j}^t, b_{h}^t$. Noting that in a real system, the resource consumption per unit bandwidth $r_{h}^{k}$ is indeed time-varying. It can be considered as a random variable subject to time interval $t$ and other system random factors $\xi$. 
% Due to the hierarchical property of hierarchical storage system, not every bandwidth will be revealed to the client but only that of top-level tier (such as the writing bandwidth into the cache). Thus we only demand the bandwidth of top-level tier to meet the goal. 
Our goal is to maximize the throughput and meanwhile maintain it stable. Based on above, a mathematical model is given below:

% Recalling our optimization goal, hence we only demand
% is supposed to be optimized but that of top-level tier (such as the write bandwidth into the cache). Because in such a multi-layer hierarchical storage system, the performance of top-level tier is the only metric perceived by the customer. 

% To clearly and generally describe the problem, a stochastic programming model is given below:

% Assumption regarding the data access distribution.

% Assumption regarding that the bandwidth of tierup is fixed at 200mb.

% Then the multi-layer bandwidth control problems are formally defined, including the constraints, optimization objectives. (mathematical formulation is preferred and why linear programming fails to solve the above formulation.)\\

% In general cases, a storage system can be equivalently mapped to a directed acyclic graph (DAG). The nodes and edges in the graph represent storage areas and data migration respectively. To be more specific, if a certain storage area is expected to maintain a proper waterlevel, a corresponding node will be assigned to represent it. This storage area can either be a whole tier of the system, such as HDD tier, or just a part of a a tier, such as the garbage area of SSD. In the system, the direction of data migration is known and constant. 
% To simulate it, the edges in graph is connected following the same way. Namely two nodes will be connected if there are data migrated from one to another in the real system, and the direction should also be consistent with real scene. Following the trail described above, a  directed acyclic graph (DAG) is constructed to symbolise the storage system. Based on above assumptions, a stochastic programming model is given below. 
% For ease of read, the meaning of variables involved in the formulation is summarized in Table~\ref{tab: variable_meaning}.

% meaning of variables in the formulation is shown below. 

% For any container needed to be controlled, whether a total storage medium or a part of it, a vertex will be assigned to it, whose value is exactly the waterlevel of the container. During the whole experiment period, waterlevels should be kept within target range for the sake of safety and efficiency of the system. Assume that there are m vertexes in the system, represented by $v_i, i \in [1, m]$, with $n$ edges connecting them, whose flow size is represented by $e_{i,j}, i, j \in [1, m], i \neq j $. One of the major problem to implement a global regulation is that edges cannot be controlled precisely or completely. There are only limited tasks in the system can be set to a certain number, denoted by $x_i, i \in [1, k], k<n$. These tasks, together with some random events, finally determine the size of data flowing among vertexes. The allocation policy of tasks is mainly aiming at a well performance of the key data flow, namely a high and stable write bandwidth. While assigning bandwidth to each tasks, the resources, including calculation resource and bandwidth resource, is limited and changing by time, as other tasks with higher priority may occupy some of them. \\

% \begin{table}[]
% \centering
% \caption{The meaning of used variables}
% \label{tab: variable_meaning}
%     \begin{tabular}{|c|c|}
%             \hline $v_{i, t}, i \in [1, m]$ & water level of node $i$\\
%             \hline $e_{ij, t}, i, j \in [1, m], i \neq j $  & amount of data moved from node $i$ to node $j$ \\
%             \hline $x_i, i \in [1, k], k<n$  &  task $i$ in the system which can be controlled\\
%             \hline $r_{ij,t}$   &  consumption of resource j per unit of task $i$\\
%             \hline $R_{i}$  &  upper limit of resource $i$\\
%             \hline $T_{min, i}$  & lower bound of the water level of node $i$ \\
%             \hline $T_{max, i}$  & upper bound of the water level of node $i$ \\
%             \hline $\xi$ & random variable \\
%             \hline
%     \end{tabular}
% \end{table}

% For any time point $t \in [0, T]$, there are some certain objectives and constraints:

\noindent\textbf{Objective}
% \begin{align}
%     & \max \quad \sum_{t=0}^T x_{1, t} \\
%     & \min \quad \sum_{t=1}^T (x_t - x_{t-1})^2 
% \end{align}

\begin{equation}
     \max \quad \sum_{t=0}^{\lceil T/T_0 \rceil} x_{0, 1}^t
     \label{eq: obj_max}
\end{equation}
\begin{equation}
     \min \quad \sum_{t=1}^{\lceil T/T_0 \rceil} (x_{0,1}^t - x_{0,1}^{t-1})^2
     \label{eq: obj_stable}
\end{equation}

\noindent\textit{s.t.}

\noindent\textbf{Watermark Constraints}
\begin{equation}
     w_{i}^t = (w_{i}^{t-1} \times C_i + \sum_{i \neq j }x_{j,i}^{t-1} - \sum_{i \neq j}x_{i,j}^{t-1}) / C_i \quad \forall i,j,t  
     \label{eq: constr_waterlevel} 
\end{equation}
\begin{equation}
     \underline{w}_i \leq w_{i}^t \leq \overline{w}_i \quad \forall i,t
     \label{eq: constr_waterlevel_threshold}
\end{equation}
\noindent\textbf{Data Migration Constraints}
\begin{equation}
    x_{i,j} =  m_{i,j,h}  d_h \quad e_{i,j} \in \mathbb{B}_h
    \label{eq: constr_data_migration1}
\end{equation}

% \begin{equation}
%      x_{i,j}^t \sim \mathcal{P}(b_h^t,t|\xi) \quad \forall i,j,h,t 
%      \label{eq: constr_data_migration1}
% \end{equation}
% \begin{equation}
%      \sum_{i,j\leftrightarrow h} x_{i,j}^t \leq b_{h}^{t} \quad \forall i,j,h,t 
%      \label{eq: constr_data_migration2}
% \end{equation}
\noindent\textbf{Resource Constraints}
% \begin{equation}
%      r_{h}^{k} \sim \mathcal{P}(t|\xi) \quad \forall h,k,t
%      \label{eq: constr_resource1}
% \end{equation}
% \begin{equation}
%      \sum_{h} b_{h}^t r_{h}^{k} \leq R_k
%       \quad \forall h,k,t 
%       \label{eq: constr_resource2}
% \end{equation}
\begin{equation}
     r_{h}^{k} \sim \mathcal{P}(t|\xi) \quad \forall h,k,t
     \label{eq: constr_resource1}
\end{equation}
\begin{equation}
     \sum_{h} d_{h}^t r_{h}^{k} \leq R_k
      \quad \forall h,k,t 
      \label{eq: constr_resource2}
\end{equation}


% \begin{align}
%     & v_{i,t} = v_{i,t-1} + \sum_{i \neq j }e_{ji, t-1} - \sum_{i \neq j}e_{ij, t-1}\\
%     & e_{ij,t} = f(\mathbf{x}, \xi)\\
%     & T_{min,i}<v_{i,t} < T_{max,i}\\
%     & r_{i_t} = f(\xi)\\
%     & \sum_{i=1}^N x_{i,t} r_{i,t} \leq R_t
% \end{align}

We consider two objectives simultaneously in our problems, namely Eq.(\ref{eq: obj_max}) and Eq.(\ref{eq: obj_stable}). In above objectives, $x_{0,1}^t$ denotes the amount of top-level data migration, which is the throughput of the whole system perceived by client severs. As for the constraints, six categories are included. Eq.(\ref{eq: constr_waterlevel}) defines the watermark level according to the data migration relation; Eq.(\ref{eq: constr_waterlevel_threshold}) constrains the watermark level of each node to be within a given range; Eq.(\ref{eq: constr_data_migration1}) represents that the amount of data migrated by an edge is proportional to the amount of data migrated by the corresponding task. Besides, resource consumption is a random process denoted by Eq.(\ref{eq: constr_resource1}). The total resource consumption by kinds of data migration task is supposed to be less than resource upper limits, denoted by Eq.(\ref{eq: constr_resource2}).

% \subsection{Motivations}
% Since there are random variables involved in above formulation, the presented mathematical model is categorized as stochastic programming. Often there are ways to solve the stochastic programming~\cite{Spall2006Theoretical}, such as random search~\cite{1991Theory}, simultaneous perturbation stochastic approximation~\cite{2009DISCRETE, 2011Discrete}, genetic algorithms~\cite{2003Rate}, etc. However, all above methods are inappropriate for being implemented in a hierarchical storage systems, especially on the online scenario. An ideal control framework within such a system is supposed to be light-weight, robust and interpretable.
\subsection{Core idea}
\label{sec: methodologies}
Based on above formulation, we propose our bandwidth control policy, named \Pascal{}, which is inspired by the concept of equilibrium in physics. 
Generally, an equilibrium state is stable if it always automatically restores to the original state, even though it deviates from the balance position by disturbance. Furthermore, if there is only one attainable equilibrium among all possible states, the system will always be in a trend of approaching to that equilibrium state. This character is helpful to maintain the watermark levels within proper range, therefore, \Pascal{} is designed to control the HSS  by imitating the action of a system with stable equilibrium. The stable equilibrium in HSS is defined as a state when the system's watermarks keep at a certain level and bandwidths stay fixed. Assuming that the array of data migration size is denoted as $\mathbf{x}$, the equilibrium state can be represented via:
\begin{align}
%   \begin{aligned}
     \mathbf{\Delta w} \cdot  \mathbf{c}
     & =\mathbf{x} \times \mathbf{E}\\
     & =\mathbf{d} \times \mathbf{M} \times \mathbf{E}\\
     & = \mathbf{0}
% \end{aligned} 
\label{eq: equilibrium}
\end{align}
where $\mathbf{M}$ refers to the mapping matrix of data migration tasks to edges (see Eq. ~(\ref{eq: constr_data_migration1})). 
For the purpose claimed above, an abstract indicator, namely pressure, is created  for each node to guide the data migration relevant with the node. Essentially, pressure is a value mapped from the current state of the node. For any task in the system, its bandwidth depends on the pressure of all the nodes directly effected by it. Generally, the increase of one node's pressure leads to an increase of the data migrated out the node and a decrease of the data migrated in the node. By this means, the pressure of every node stays constant when the whole system is in equilibrium. On the contrast, if there is any deviation from the equilibrium, the value of pressure goes to change and causes the system return to the equilibrium. 
Moreover, machine learning method is applied to \Pascal{} to make it work in a cooperative manner. In the HSS, different nodes have typical functions. As a consequence, the rule to calculate value of pressure is required to be customized, which can be well conducted by machine learning method.

% \vspace{-2ex}