\begin{figure}[t]
  \centering
  %\subfigure[This figure shows the impact of pseudo-labeled data size for VEIL-SBUCaps on its performance on SBUCaps-Test VPEL Detection. VEIL only needs 10\% of the data to beat No Vetting,
    %(XX vs 0.633 F1),     and 50\% of the labeled data (80K samples) to beat CLIP.]{
    \includegraphics[width=0.47\textwidth]{iccv2023AuthorKit/figures/images/veil_quals.png}
    % %} \subfigure[Caption for subfigure 2]{
    % \includegraphics[width=0.2\textwidth]{iccv2023AuthorKit/figures/images/.png}
    % %}
    % \includegraphics[width=0.2\textwidth]{iccv2023AuthorKit/figures/images/.png}
  \caption{Qualitative examples of extracted labels after vetting on RedCaps-Test. These are additional completely absent VAEL examples from CLaN with their linguistic indicators and similar context annotations, and only VEIL-based methods are able to overcome these three noise types.}
\label{fig:vetting_quals}
\end{figure}