% \begin{table}[t] %[h]
% \begin{center}
% \small
% \begin{tabular}{p{1.72in}|p{0.75in}|p{0.75in}}
% \hline
% \textbf{Method (Train Data Size in Thousands)} &\textbf{VOC Det. mAP} ($\Delta$) &\textbf{VOC Rec. mP} ($\Delta$) \\
% \hline
% No Vetting & 31.2 & 65.3 \\
% GT* & 40.0 \textcolor{green}{(28.2\%)} & 69.0 \textcolor{green}{(5.7\%)}\\
% Large Loss \cite{Kim2022LargeLM} &  \textcolor{red}{()} &   \textcolor{red}{(\%)}\\
% LocalCLIP-E \cite{Radford2021LearningTV} & 37.1 \textcolor{green}{(18.9\%)} & 70.7 \textcolor{green}{(8.2\%)}\\
% VEIL$_{\text{ST}}$-R,CC & \underline{37.8} \textcolor{green}{(21.2)} & 71.4 \textcolor{green}{(9.2\%)} \\
% VEIL-SBUCaps & \textbf{40.5} (29.8\%) & 74.3 (13.8\%) \\
% \hline
% \end{tabular}
% \end{center}
% \caption{Impact of vetting on WSOD performance on VOC-07 and COCO-14 datasets. There is a significant difference in detection and recognition on VOC-07 illustrated by $\Delta$, relative performance change w.r.t. VEIL-SBUCaps on the same column. This highlights that VEIL variants filter out labels harmful to localization. (GT*) directly vets labels using the pretrained object detectors which were used to train VEIL.} 
% \label{tab:det_v_recognition}
% \end{table}
\begin{table}[t] %[h]
\begin{center}
\small
\begin{tabular}{p{1.72in}|p{0.3in}|p{0.3in}|p{0.3in}}
\hline
\textbf{Method} & \scriptsize{ VOC Det. $\text{mAP}_{50}$}  &\scriptsize{VOC Rec. mAP} &\scriptsize{COCO Det $\text{mAP}_{50}$}\\
\hline
GT* (upper bound) & 40.0 & 69.0 & 9.2\\\hline
No Vetting & 31.2 & 65.3 & 7.7\\
Large Loss \cite{Kim2022LargeLM} & 30.9 & 65.3 & 7.5\\
LocalCLIP-E \cite{Radford2021LearningTV} & 37.1  & 70.7 & 7.9\\
VEIL$_{\text{ST}}$-R,CC & \underline{37.8}  &\underline{71.4} & \underline{8.6}\\
VEIL-SBUCaps & \textbf{40.5}  & \textbf{74.3} & \textbf{10.4}\\
\hline
\end{tabular}
\end{center}
\caption{Impact of vetting on WSOD performance on VOC-07 and COCO-14. 
%There is a significant difference in detection and recognition on VOC-07 illustrated by $\Delta$, relative performance change w.r.t. no vetting on the same column. 
%VEIL variants filter out labels harmful to localization. 
(GT*) directly vets labels using the pretrained recognition models used to train VEIL. Bold indicates best performance in column excluding GT*.} 
\label{tab:det_v_recognition}
\end{table}