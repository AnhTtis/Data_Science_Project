\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage{iccv2023AuthorKit/iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{array}
\usepackage{makecell}
\usepackage{tabu, booktabs}
\usepackage{xcolor,colortbl}
\usepackage{newtxtext,newtxmath}
% \usepackage{fontspec}
% \usepackage{emoji}
\usepackage{enumitem}
\usepackage{subfigure}
\usepackage{bbm}
% \setlength{\textheight}{8.875in}
% \setlength{\textwidth}{6.875in}
% \setlength{\columnsep}{0.3125in}
% \setlength{\topmargin}{0in}
% \setlength{\headheight}{0in}
% \setlength{\headsep}{0in}
% \setlength{\parindent}{1pc}
% \setlength{\oddsidemargin}{-.304in}
% \setlength{\evensidemargin}{-.304in}
\definecolor{lightgreen}{rgb}{0.60, 0.78, 0.75}
\definecolor{lightorange}{rgb}{1.0, 0.949, 0.80}
\definecolor{verylightorange}{rgb}{1.0, 0.875, 0.502}
\definecolor{verylightgreen}{rgb}{0.796, 0.886, 0.871}
	
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{2211} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
% \title{ELaVET \emoji{raising-hands}: Combatting visual absence in in-the-wild captions by Extracted Label Vetting} woman-with-veil
%\title{VEIL\emoji{woman-with-veil}: Combatting visual absence by Vetting Extracted Image Labels from in-the-wild captions}
\title{VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for Weakly-Supervised Object Detection}

\author{Arushi Rai\\
University of Pittsburgh\\
%Institution1 address\\
{\tt\small arr159@pitt.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until thess closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Adriana Kovashka\\
University of Pittsburgh\\
%First line of institution2 address\\
{\tt\small kovashka@cs.pitt.edu}
}
% \date{\vspace{-5ex}}
\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi


%%%%%%%%% ABSTRACT
\begin{abstract}
The use of large-scale vision-language datasets is limited for object detection due to the negative impact of label noise on localization. Prior methods have shown how such large-scale datasets can be used for pretraining, which can provide initial signal for localization, but is insufficient without clean bounding-box data for at least some categories. We propose a technique to ``vet'' labels extracted from noisy captions. Our method trains a classifier that predicts if an extracted label is actually present in the image or not. Our classifier generalizes across dataset boundaries and shows promise for generalizing across categories as well. We compare the classifier to eleven baselines on five datasets, and demonstrate that it can improve weakly-supervised detection without label vetting by 80\% (16.0 to 29.1 mAP when evaluated on PASCAL VOC). 
\end{abstract}

\input{iccv2023AuthorKit/sections/introduction.tex}
\input{iccv2023AuthorKit/sections/related_works.tex}
\input{iccv2023AuthorKit/sections/in_the_wild_take2}
\input{iccv2023AuthorKit/sections/label_noise_taxonomy.tex}
\input{iccv2023AuthorKit/sections/method_rewrite.tex}
\input{iccv2023AuthorKit/sections/experiments2.tex}
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}
\input{iccv2023AuthorKit/supp}
%\input{iccv2023AuthorKit/supp}
\end{document}
