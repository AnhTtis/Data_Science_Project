

\begin{table}[]
    \centering
    \small
    \begin{tabular}{c|c|c|c|c}\hline
Method & $p_m$ & ST & Prec/Rec & F1 \\\hline
No Vetting & - &  & 0.486 / 1.000 & \underline{0.654} \\\hline
ID & 0.00 &  & \underline{0.693} / \textbf{0.700} & \textbf{0.697} \\\hline
OOD & 0.00 &  &\textbf{ 0.745} / 0.142 & 0.239\\\hline
OOD & 0.15 &  & \textcolor{green}{0.763} / \textcolor{green}{0.351} &\textcolor{green}{0.481} \\\hline
OOD & 0.25 &  & \textcolor{green}{0.752} / \textcolor{green}{0.375} & \textcolor{green}{0.501}\\\hline
OOD & 0.50 &  & \textcolor{green}{0.784} / \textcolor{green}{ 0.336 }& \textcolor{green}{0.471 }\\\hline
OOD & 0.00 & \checkmark & 0.713 / \textcolor{green}{0.509} & \textcolor{green}{0.594}  \\\hline
OOD & 0.25 & \checkmark & 0.709 / \textcolor{green}{0.456} & \textcolor{green}{0.555}\\\hline
    \end{tabular}
    \caption{VEIL category generalization on SBUCaps-Test ID. Green text indicates better than OOD baseline. (ST) stands for special token and $p_m$ is the extracted label masking probability.}
    %All models are evaluated on a balanced in-domain test subset containing categories intersecting with VOC classes (7). The use of a special token for predictions significantly improves recall in the out of domain models, however this appears to be incompatible with masking, which degrades performance. This could mean that this setup decreases the category-specific dependency of determining whether an object mention is noisy. Green text indicates better than OOD baselines}
    \label{tab:cross_category}
\end{table}