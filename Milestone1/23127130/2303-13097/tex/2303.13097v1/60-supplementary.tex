\twocolumn[{
\begin{center}
\textbf{\Large Supplementary Materials for \\
CP$^3$: Channel Pruning Plug-in for Point Cloud Network}
\end{center}
}]
In the supplementary material, we provide more experimental comparisons on object detection in Sec.~\ref{supp:od} and segmentation tasks in Sec.~\ref{supp:ss} , and we showcase the effectiveness of the proposed knowledge recycling module in Sec.~\ref{supp:kr}, we also analyzed the pruning rates of different layers in Sec.~\ref{supp:al}.

\section{More Experimental Results on 3D Object Detection}
\label{supp:od}
To further illustrate the effectiveness of our proposed \cpt, we incorporated CP$^3$ with pruning methods HRank~\cite{jia2021arank} and CHIP~\cite{sui2021chip} to prune VoteNet~\cite{qi2019deep} on ScanNetV2~\cite{dai2017scannet} and SUN RGB-D~\cite{song2015sun} for 3D object detection.



\input{table/votenet_scannet_supp.tex}
\para{ScanNetv2}
Tab.~\ref{tabl1_vsn_supp} shows the comparison results of directly applying advanced pruning methods (HRank, CHIP) and implementation them with \cpt.
%
Overall, CP$^3$ consistently improved the performance of existing advanced CNN pruning methods under different pruning rates.
%
For instance, in the case of applying HRank with 67.7\% FLOPs reduction, by incorporating \cpt, the mAP@0.50 increased 3.17\% (35.95\% vs. 39.15\%) while achieving 1.2\% more FLOPs reduction (67.7\% vs. 68.9\%).


\input{table/votenet_sunrgbd_supp.tex}
\para{SUN RGB-D}
We reported the comparison results on the {SUN RGB-D} dataset in Tab.~\ref{table2_vsun_supp}.
%
For both HRank and CHIP, the implementation with {\cpt} achieved higher accuracy performance with higher FLOPs reduction, similar to our observations on other tasks and datasets.


\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figs/variance.pdf}
    \caption{The variance of the importance score of each channel in the 10-th layer of PointNeXt-S. The x-axis represents channel indices, and the y-axis represents the variances of each channel importance scores, which are calculated by 2,468 input samples.}
    \label{variance}
\end{figure*}

\section{More Experimental Results on Semantic Segmentation}
\label{supp:ss}

To investigate the generality of our work, we extended the comparisons on semantic segmentation. We conducted the experiment on the S3DIS~\cite{DBLP:conf/cvpr/ArmeniSZJBFS16} dataset of PointNeXt-S and PointNeXt-XL, and two advanced pruning methods are evaluated.

\input{table/seg_supp_ps.tex}

\para{PointNext-S}
Compared to other PointNeXt zoos, besides the fewer parameters, PointNeXt-S is designed with no InvResMLP blocks and is a simpler network architecture.
%
The comparison result in Tab.~\ref{seg_s3dis_supp_ps} showed that the consistent outperformance of {\cpt} compared to directly using HRank and CHIP \textbf{without} \cpt.
%
In the case of applying CHIP with 57.5\% FLOPs reduction, by incorporating \cpt, the mAcc increases 2.8 \% while achieving 1.4 \% more FLOPs reduction.
%
The result indicated that even for a simpler network architecture, the accuracy performance degradation still occurred when directly implementation of CNN pruning methods, verifying the necessity of the implementation with \cpt.


\input{table/seg_d3dis_supp.tex}

\para{PointNext-XL}
We further investigated on the more complex and larger network PointNext-XL. Similar observations on the improvement by {{\cpt}} can be found in Tab.~\ref{seg_s3dis_supp}.
For instance, our approach can achieve 69.8 \% and 69.9  \% storage and computation reductions, respectively, with a 1.3 \% and 1.7\% accuracy increase for mAcc and mIoU over the baseline model.


\begin{table}[h]
\centering
\caption{Comparisons on the SemanticKITTI with RandLA-Net.}
\label{tab_2}
\resizebox{0.42\textwidth}{!}{
\begin{tabular}{l|ccc}
\toprule
\multicolumn{1}{l|}{\multirow{1}{*}{Method}}
& \multicolumn{1}{c}{mIoU} & \multicolumn{1}{c}{Params. (M)} & \multicolumn{1}{c}{FLOPs (\%)}
 \\ \midrule
Baseline (RandLA-Net)          &50.30   &0.95     &100                   \\ \cmidrule{1-4}
CHIP               &49.12  &0.20    &21.7                   \\
CHIP+CP$^3$        &50.21  &0.18    &19.8 \\ \bottomrule
\end{tabular}}
\end{table}

\para{Outdoor Experiments}
%
{\cpt} focuses on point-based networks (PNNs), and by following prevailing PNN works, we have experimented on the popular large-scale datasets such as ScanObjectNN and S3DIS and achieved promising results in the paper. To further illustrate the validity of our method, we experimented on a outdoor dataset (SemanticKITTI) with RandLA-Net and CHIP. The results are shown in Tab.~\ref{tab_2}.


\section{Exploration on Knowledge Recycling}
\label{supp:kr}

In this section, we took a deeper look into the Knowledge Recycling~(KR) module.
%
To verify the effectiveness of KR, we performed pruning methods and statistically analyzed the positive effect of KR.
We took the PointNeXt-S with dataset ModelNet40 as an example.
We performed the comparison between directly implementing HRank and HRank with \cpt.
%
And we focus on the KR scores generated by the KR module (with discarded points) and HRank scores \textbf{without} KR module.
We calculated the variances of scores to justify the robustness of \cpt.
Fig.~\ref{variance} shows the statistics comparison results on the 10-th layer with 512 channels on 2468 test meshed CAD models.
%
Among 512 channels in the 10-th layer, the percentage is 93.2\% in the case of the KR score variances lower than the original score variances. For instance, in the case of the 25-th channel, the KR score variance is much lower than the original score variance (0.21 vs. 0.89).
%
Similar results can be found on other layers. These results verify that the KR module enabled the channel importance calculation to be more stable and robust.


\section{Analysis of the layer-wise redundancy}
\label{supp:al}
We take the pruned PointNet++ on ScanObjectNN as an example and show the pruning rates for each layer in Fig.~\ref{fig_channel}.
Pruning with {\cpt} eliminates more redundancy on shallow layers and less on $6$th and $7$th layers.
{\cpt} on ResRep achieved higher accuracy (84.80\% vs 83.79\%) with higher FLOPs reduction (84.8\% vs 83.0\%), indicating pruning with CP$^3$ effectively identifies the redundancy in point-based networks.
\begin{figure}[t]
\centering
\includegraphics[width=0.45\textwidth]{figs/channel.pdf}
\caption{Different layer pruning rate. } \label{fig_channel}
\end{figure} 
