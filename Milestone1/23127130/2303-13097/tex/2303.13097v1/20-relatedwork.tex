
\subsection{2D Channel Pruning}
Channel pruning (a.k.a., filter pruning) methods reduce the redundant filters while maintaining the original structure of CNNs and is friendly to prevailing inference acceleration engines such as TensorFlow-Lite~(TFLite)~\cite{TensorFlow-Lite} and Mobile Neural Network~(MNN)~\cite{Ali-MNN}.
%
Mainstream channel pruning methods~\cite{ding2019centripetal,meng2020pruning,ding2021resrep,guan2022dais} usually first evaluate the importance of channels by certain metrics and then prune (i.e., remove) the less important channels.
%
Early work~\cite{li2016pruning} uses the $l_1$ norm of filters as importance score for channel pruning.
%
Afterwards, learning parameters, such as the scaling factor $\gamma$ in the batch norm layer~\cite{liu2017learning} and the reconstruction error in the final network layer~\cite{yu2018nisp}, are considered as the importance scores for channel selection.
%
The importance sampling distribution of channels~\cite{DBLP:conf/iclr/LiebenweinBLFR20} is also used for pruning.
%
Recent works~\cite{DBLP:conf/cvpr/HouQSMYXC00K22,sui2021chip} measure the correlation of multiple feature maps to determine the importance score of the filter for pruning.
%
HRank~\cite{lin2020hrank} proposes a method for pruning filters based on the theory that low-rank feature maps contain less information.
\cite{ye2020accelerating} leverages the statistical distribution of activation gradient and takes the smaller gradient as low importance score for pruning.
%
\cite{DBLP:conf/ijcai/WangFGCH19} calculates  the average importance of both the input feature maps and their corresponding output feature maps to determine the overall importance.
%
\cite{DBLP:conf/icml/000100CHL00L21, han2020model} compress CNNs from multiple dimensions
While most channel pruning methods are designed for and tested on 2D CNNs, our {\cpt} can work in tandem with existing pruners for 3D point-based networks.

\subsection{Point-based Networks for Point Cloud Data}
Point-based Neural Networks~(PNNs) directly process point cloud data with a flexible range of receptive field,
have no positioning information loss,
and thus keep more accurate spatial information.
%
As a pioneer work, PointNet~\cite{qi2017pointnet} learns the spatial encoding directly from the input point clouds and uses the characteristics of all points to obtain the global representations.
%
PointNet++~\cite{qi2017pointnet++} further proposes a multi-level feature extraction structure to extract local and global features more effectively.
%
KPConv~\cite{2019KPConv} proposes a new point convolution operation to learn local movements applied to kernel points.
%
ASSANet~\cite{2021ASSANet} proposes a separable set abstraction module that decomposes the normal SA module in PointNet++ into two separate learning phases for channel and space.
%
PointMLP~\cite{DBLP:conf/iclr/MaQYR022} uses residual point blocks to extract local features, transforms local points using geometric affine modules, and extracts geometric features before and after the aggregation operation.
%
PointNeXt~\cite{qian2022pointnext} uses inverted residual bottleneck and separable multilayer perceptrons to achieve more efficient model scaling.
%
Besides classification,
PNNs also serve as backbones for other 3D tasks.
VoteNet~\cite{qi2019deep} effectively improves the 3D object detection accuracy through the Hough voting mechanism~\cite{DBLP:journals/ijcv/LeibeLS08}.
PointTransformer~\cite{DBLP:conf/iccv/ZhaoJJTK21} designs models improving prior work across domains and tasks.
GroupFree3D~\cite{liu2021group1} uses the attention mechanism to automatically learn the contribution of each point to the object.
%
In this paper, we show that {\cpt} can be widely applied to point-based networks on a variety of point cloud benchmarks and representative original networks.
