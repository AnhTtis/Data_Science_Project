Convolutional Neural Networks (CNNs) often encounter the problems of overloaded computation and overweighted storage.
%
The cumbersome instantiation of a CNN model leads to inefficient, uneconomic, or even impossible deployment in practice.
%
Therefore, light-weight models that provide comparable results with much fewer computational costs are in great demand for nearly all applications.
%
Channel pruning is a promising solution to delivering efficient networks.
%
In recent years, 2D CNN channel pruning, e.g., pruning classical VGGNets~\cite{simonyan2014very}, ResNets~\cite{he2016deep}, MobileNets~\cite{howard2017mobilenets}, and many other neural networks for processing 2D images~\cite{liu2017learning,ding2019centripetal,lin2020hrank,meng2020pruning,ding2021resrep,sui2021chip,guan2022dais}, has been successfully conducted.
%
Most channel pruning approaches focus on identifying redundant convolution filters (i.e., channels) by evaluating their importance.
%
The cornerstone of 2D channel pruning methods is the diversified yet effective channel evaluation metrics.
%
For instance, HRank~\cite{lin2020hrank} uses the rank of the feature map as the pruning metric and removes the low-rank filters that are considered to contain less information.
%
CHIP~\cite{sui2021chip} leverages channel independence to represent the importance of each feature mapping and eliminates less important channels.


With the widespread application of depth-sensing technology, 3D vision tasks~\cite{gong2022posetriplet,10.1007/978-3-031-19824-3_41,DBLP:conf/cvpr/FazlaliXRL22,DBLP:conf/cvpr/WangWCXQQFT22} are a rapidly growing field starving for powerful methods.
%
Apart from straightforwardly applying 2D CNNs, models built with Point-based Neural Networks~(PNNs), which directly process point clouds from the beginning without unnecessary rendering,
%
show their merits and are widely deployed on edge devices for various applications such as robots~\cite{DBLP:conf/iros/YangPCF20, li2022efficientgrasp} and self-driving~\cite{DBLP:conf/cvpr/ZhengTJF21,DBLP:conf/aaai/ChenCZT22}.
%
Compressing PNNs is crucial due to the limited resources of edge devices and multiple models for different tasks are likely to run simultaneously~\cite{Pham_2019_CVPR, DUBEY2022100275}.
%
Given the huge success of 2D channel pruning and the great demand for efficient 3D PNNs, we intuitively raise one question: \emph{shall we directly implement the existing pruning methods to PNNs following the proposed channel importance metrics in 2D CNNs pruning?}


With this question in mind, we investigate the fundamental factors that potentially impair 2D pruning effectiveness on PNNs.
%
Previous works~\cite{koppula2011semantic,xu2021image2point} have shown that point clouds record visual and semantic information in a significantly different way from 2D images.
%
Specifically, a point cloud consists of a set of unordered points on objects' and environments' surfaces, and each point encodes its features,
such as intensity along with the spatial coordinates $(x, y, z)$.
%
In contrast, 2D images organize visual features in a dense and regular pixel array.
%
Such data representation differences between 3D point clouds and 2D images lead to a) different ways of exploiting information from data and b) contrasting network architectures of PNNs and 2D CNNs.
It is credible that only the pruning methods considering the two aspects (definitely not existing 2D CNN pruners) may obtain superior performance on PNNs.


From the perspective of data representations,
%
3D point clouds provide more 3D feature representations than 2D images, but the representations are more sensitive to network channels.
%
To be more specific, for 2D images, all three RGB channels represent basic information in an isotropic and homogeneous way so that the latent representations extracted by CNNs applied to the images.
%
On the other hand, point clouds explicitly encode the spatial information in three coordinate channels, which are indispensable for extracting visual and semantic information from other channels.
%
Moreover, PNNs employ the coordinate information in multiple layers as concatenated inputs for deeper feature extraction.
%
Nevertheless, existing CNN pruning methods are designed only suitable for the plain arrangements of 2D data but fail to consider how the informative 3D information should be extracted from point clouds.

Moreover, the network architectures of PNNs are designed substantially different from 2D CNNs.
% 
While using smaller kernels~\cite{simonyan2014very} is shown to benefit 2D CNNs~\cite{simonyan2014very}, it does not apply to networks for 3D point clouds.
%
On the contrary, PNNs leverage neighborhoods at multiple scales to obtain both robust and detailed features.
%
The reason is that small neighborhoods (analogous to small kernels in 2D CNNs) in point clouds consist of few points for PNNs to capture robust features.
%
Due to the necessary sampling steps, the knowledge insufficiency issue becomes more severe for deeper PNN layers.
%
In addition, PNNs use the random input dropout procedure during training to adaptively weight patterns detected at different scales and combine multi-scale features.
%
This procedure randomly discards a large proportion of points and loses much exclusive information of the original data.
%
Thus, the architecture disparity between 2D CNNs and PNNs affects the performance of directly applying existing pruning methods to PNNs.


In this paper, by explicitly dealing with the two characteristics of 3D task, namely the data representation and the PNN architecture design,
we propose a \textbf{C}hannel \textbf{P}runing \textbf{P}lug-in for \textbf{P}oint-based network named {\cpt},
%
which can be applied to most 2D channel pruning methods for compressing PNN models.
%
The proposed {\cpt} refines the channel importance, the key factor of pruning methods, from two aspects.
Firstly, considering the point coordinates ($x$, $y$, and $z$) encode the spatial information and deeply affects feature extraction procedures in PNN layers,
we determine the channel importance by evaluating the correlation between the feature map and its corresponding point coordinates by introducing a coordinate-enhancement module.
%
Secondly, calculating channel importance in channel pruning is data-driven and sensitive to the input, and the intrinsic sampling steps in PNN naturally makes pruning methods unstable.
%
To settle this problem, we make full use of the discarded points in the sampling process via a knowledge recycling module to supplement the evaluation of channel importance.
%
This reduces the data sampling bias impact on the channel importance calculation and increases the robustness of the pruning results.
%
Notably, both the coordinates and recycled points in {\cpt} do not participate in network training (with back-propagation) but only assist channel importance calculation in the reasoning phase.
Thus, {\cpt} does not increase any computational cost of the pruned network.
%
The contributions of this paper are as follows:
\begin{itemize}[itemsep=1pt,topsep=1pt,parsep=1pt,leftmargin=10pt] %leftmargin=10pt
\item We systematically consider the characteristics of PNNs and propose a channel pruning plug-in named CP$^3$ to enhance 2D CNN channel pruning approaches on 3D PNNs. To the best of our knowledge, CP$^3$ is the first method to export existing 2D pruning methods to PNNs.

\item We propose a coordinate-enhanced channel importance score to guide point clouds network pruning, by evaluating the correlation between feature maps and corresponding point coordinates.

\item We design a knowledge recycling pruning scheme that increases the robustness of the pruning procedure, using the discarded points to improve the channel importance evaluation.

\item We show that using CP$^3$ is consistently superior to directly transplanting 2D pruning methods to PNNs by extensive experiments on three 3D tasks and five datasets with different PNN models and pruning baselines.
\end{itemize}
