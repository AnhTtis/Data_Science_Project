\begin{figure*}[t]
    \centering
    \includegraphics[width=0.99\textwidth]{figs/framework.pdf}
    \vspace{-5pt}
    \caption{
    The framework of~{\cpt}. The figure shows the specific pruning process of one of the SA blocks.
    Whether a channel in a PNN is pruned is determined by three parts:
    1) Original channel importance: obtained from the original CNNs channel pruning method~(e.g., HRank \cite{lin2020hrank}, CHIP \cite{sui2021chip}).
    2) Discarded channel importance: obtained from the Knowledge-Recycling module by leveraging the discarded points in the network to supplement the channel importance evaluation of the corresponding points and improve the robustness of the channel selection.
    3) CE (Coordinate-Enhanced) channel importance: obtained from calculating the correlation between the feature map and its corresponding points coordinates to guide point clouds network pruning.
}
    \label{fig_my_graph}
\vspace{-5pt}
\end{figure*}

Although point-based networks are similar to CNN in concrete realization, they have fundamental differences in data representation and network architecture design.
To extend the success of CNN pruning to PNN, two modules are proposed in~{\cpt} taking advantage from the dimensional information and discarded points:
1) coordinate-enhancement~(CE) module, which produces a coordinate-enhanced score to estimate the channel importance by combining dimensional and feature information,
and 2) knowledge recycling module reusing the discarded points to improve the channel importance evaluation criteria and increase the robustness.

\subsection{Formulations and Motivation}
\label{sec3.1}
\para{Point-based networks}
%
PNN is a unified architecture that directly takes point clouds as input.
It builds hierarchical groups of points and progressively abstracts larger local regions along the hierarchy.
%
PNN is structurally composed by a number of set abstraction~(SA) blocks.
%
Each SA block consists of
1) a sampling layer iteratively samples the farthest point to choose a subset of points from input points,
%
2) a group layer gathers neighbors of centroid points to a local region,
%
3) a set of shared Multi-Layer Perceptrons~(MLPs) to extract features,
%
and 4) a reduction layer to aggregate features in the neighbors.
%
Formally speaking, a SA block takes an $n_{i-1} \times (d+c_{i-1})$ matrix as input that is from $n_{i-1}$ points with $d$-dim coordinates and $c_{i-1}$-dim point feature. It outputs an $n_i \times (d + c_i)$ matrix of $n_i$ subsampled points with $d$-dimensional coordinates (i.e., $d=3$) and new $c_i$-dimensional feature vectors summarizing local context.
The SA block is formulated as:
\begin{equation}
\label{point_based_eq}
\mathbf{F}_i^{l+1}=\mathcal{R}\left\{h_{\Theta}\left(\left[\mathbf{F}_j^l ; \mathbf{x}_j^l-\mathbf{x}_i^l\right]\right)\right\},
\end{equation}
where $h_{\Theta}$ is MLPs to extract grouped points feature, $\mathcal{R}$ is the reduction layer (e.g. max-pooling)  to aggregate features in the neighbors $\{j:(i, j) \in \mathcal{N}\}$, $F_j^l$ is the features of neighbor $j$ in the $l$-th layer, $x_i^l$ and $x_j^l$ are input points coordinates and coordinates of neighbor $j$ in the $l$-th layer.


\para{Channel pruning}
Assume a pre-trained PNN model has a set of $K$ convolutional layers, and $\mathcal{A}^l$ is the $l$-th convolution layer. The parameters in $\mathcal{A}^l$ can be represented as a set of filters $\mathcal{W}_{\mathcal{A}^l}=\left\{\mathbf{w}_1^l, \mathbf{w}_2^l, \ldots, \mathbf{w}_{c_l}^l\right\} \in \mathbb{R}^{(d + c_l) \times (d + c_{l-1}) \times k_l \times k_l}$, where $j$-th filter is $\mathbf{w}_j^l \in \mathbb{R}^{(d + c_{l-1}) \times k_l \times k_i}$. $(d +c_l)$ represents the number of filters in $\mathcal{A}^l$ and $k_l$ denotes the kernel size. The outputs of filter, i.e., feature map, are denoted as $\mathcal{F}^l=\left\{\mathbf{f}_1^l, \mathbf{f}_2^l, \ldots, \mathbf{f}_{n_i}^l\right\} \in \mathbb{R}^{n_i \times (d+c_i)}$.
Channel pruning aims to identify and remove the less importance filter from the original networks. In general, channel pruning can be formulated as the following optimization problem:
\begin{equation}
\label{filter_pruning}
\min _{\delta_{i j}} \sum_{i=1}^K \sum_{j=1}^{n_i} \delta_{i j} \mathcal{L}\left(\mathbf{w}_j^i\right) \text {, s.t. }\sum_{j=1}^{n_i} \delta_{i j}=k_l,
\end{equation}
where $\delta_{i j}$ is an indicator which is 1 if $\mathbf{w}_j^i$ is to be pruned or 0 if  $\mathbf{w}_j^i$ is to be kept, $\mathcal{L}(\cdot)$ measures the importance of a filter and $k_l$ is the kept filter number.

\para{Robust importance metric for channel pruning}
The metrics for evaluating the importance of filters is critical. Existing CNN pruning methods design a variety of $\mathcal{L}(\cdot)$ on the filters.
Consider the feature maps, contain rich and important information of both filter and input data, approaches using feature information have become popular and achieved state-of-the-art performance for channel pruning.
%
The results of the feature maps may vary depending on the variability of the input data. Therefore, when the importance of one filter solely depends on the information represented by its own generated feature map, the measurement of the importance may be unstable and sensitive to the slight change of input data.
%
So we have taken into account the characteristics of point clouds data and point-based networks architecture to improve the robustness of channel importance in point-based networks.
On the one hand, we propose a coordinate-enhancement module by evaluating the correlation between the feature map and its corresponding points coordinates to guide point clouds network pruning, which will be described in Sec. \ref{sec3.2}.  On the other hand, we design a knowledge recycling pruning schema, using discarded points to improve the channel importance evaluation criteria and increase the robustness of the pruning module, which will be described in detail in Sec.~\ref{sec3.3}.


\subsection{Coordinate-Enhanced Channel Importance} \label{sec3.2}
%
Dimensional information is critical in PNNs. The dimensional information (i.e., coordinates of the points) are usually adopted as input for feature extraction. Namely, the input and output of each SA block are concatenated with the coordinates of the points.
%
Meanwhile, the intermediate feature maps reflect not only the information of the original input data but also the corresponding channel information.
%
Therefore, the importance of the channel can be obtained from the feature maps, i.e., the importance of the corresponding channel.
%
The dimensional information is crucial in point-based tasks and should be considered as part of importance metric.
%
Thus the critical problem falls in designing a function that can well reflect the dimensional information richness of feature maps.
%
The feature map, obtained by encoding points spatial $x$, $y$, and $z$ coordinates, should be closely related to the original corresponding points coordinates.
%
Therefore, we use the correlation between the current feature map and the corresponding input points coordinates to determine the importance of the filter.
%
The designed Coordinate-Enhancement (CE) module based on Eq.~\eqref{filter_pruning}:
\begin{equation}
\label{filter_pruning_c}
\min _{\delta_{i j}} \sum_{i=1}^K \sum_{j=1}^{n_i} \delta_{i j} \mathcal{L}_c\left(\mathbf{F}_j^i\right) \text {, s.t. }\sum_{j=1}^{n_i} \delta_{i j}=k_l,
\end{equation}
where $\delta_{i j}$ is an indicator which is 1 if $\mathbf{w}_j^i$ is to be pruned or 0 if  $\mathbf{w}_j^i$ is to be kept and $k_l$ is the kept channel number. $\mathcal{L}_c(\cdot)$ measures the importance of a channel from take account of the relationship between feature map and points coordinates which can be formulated as:
\begin{equation}
\label{ce_pruned}
\mathcal{L}_c\left(F_j^i\right)=\mathcal {M}\{\operatorname {CE}\left(F_j^i, x^i\right)\},
\end{equation}
where $\operatorname {CE}$ obtains the coordinate-enhanced score by calculating correlation of each channel in the feature map with the original coordinates, and $\mathcal {M}$ takes the maximum value.
Hence, higher coordinate-enhanced score (i.e., $\mathcal{L}_c$) serve as a reliable measurement for information richness.

\begin{figure}[t]
  \centering
  \includegraphics[width=.8\columnwidth]{figs/ce_filter_cropped.pdf}
  \vspace{-5pt}
  \caption{Comparisons on the pruned model accuracy with different pruning metrics with CE scores. Results are on ModelNet40 with PointNeXt-S~(C=64).}
  \label{cd_filter}
  \vspace{-5pt}
\end{figure}

We evaluated the effectiveness of the CE module on ModelNet40 with PointNeXt-S~(C=64).
%
To demonstrate the experiment's validity, we compared the overall accuracy (OA) for pruning rates of 40\%, 50\%, 60\%, and 70\%, respectively.
%
Three sets of experiments are carried out. First, the `CE' group selected filters in order of value from the CE module. Secondly, the `Random' group is used to randomly select filters for pruning, and finally, the `Reverse' is used to select filters according to the coordinate-enhanced score from low to high. As shown in Fig.~\ref{cd_filter}, the channel with a higher coordinate-enhanced score has higher accuracy, which means that the channel with a higher coordinate-enhanced score has higher importance and should be retained in the pruning process.
\subsection{Knowledge Recycling}\label{sec3.3}

Sec.~\ref{sec3.2} shows that feature maps can reflect the importance of the corresponding channels.
%
Another problem is that the importance determination may be unstable and sensitive to small changes in the input data as the feature maps are highly related to the samples of input data.
%
Therefore, we aim to reduce the impact of such data variation.
%
Through the analysis of the PNNs in Sec.~\ref{sec3.1}, we found that some points are discarded to obtain hierarchical points set feature.
%
These discarded points are informative as well since the sampling mechanism are highly random and can be leveraged to reduce the impact of data variation.
%
The Knowledge Recycling~(KR) module is proposed to reuse the discarded points to improve the robustness of channel pruning.
%
\input{table/modelnet_new.tex}

For those centroids that are computed in $(l-1)$-th layer but discarded in $l$-th layer due to sampling, which are equivalent to the sampled points.
%
Therefore, the discarded centroids $x_{dis}$ are feeded into $l$-th convolutional layer to generate the feature map $\mathbf{f_{dis}}^l$, and $\mathcal{L}_k\left(F_{dis_j}^i\right)$ is taken in use for the evaluation of channel importance.


We calculate the relevant feature maps from the network parameters trained from the sampled points and use them as part of the importance calculation for the current SA layer channels.
Specifically, for each layer in the SA module, we obtain the features of the discard points by Eq. 1:
$$
\mathcal{F}_{dis}^l=\left\{\mathbf{f_{dis}}_1^l, \mathbf{f_{dis}}_2^l, \ldots, \mathbf{f_{dis}}_{n_i}^l\right\} \in \mathbb{R}^{n_i \times (3+c_i)},
$$
where $n_i$ is sampled points number, $c_i$ is the points feature dimension.
So the supplement importance is:
\begin{equation}
\label{kr_prund}
\begin{aligned}
\mathcal{L}_k\left(F_j^i\right)&=\mathcal{L}_k\left(F_{dis_j}^i\right)\\
                     &=\mathcal {M}\{\operatorname {CE}\left(F_j^i, x_{dis}^i\right)\},
\end{aligned}
\end{equation}
where $x_{dis}^i$ are discard points for recycling.

It should be noted that the KR module only needs to calculate $\mathcal{F}_{dis}^l$ from the parameters trained by the sampled points and does not incur much additional overhead.

\subsection{Using {\cpt} in Pruning Methods}

The overall {\cpt} improve the existing CNNs pruning methods by considering the input data of PNNs and the PNN structure in Sec.~\ref{sec3.2} and Sec.~\ref{sec3.3}, respectively.
%
In fact, {\cpt} can complement the existing pruning methods, i.e., as a plug-in to the existing pruning methods, to improve the pruning performance on PNNs.
%
Specifically, combining Eq.~\eqref{ce_pruned} and Eq.~\eqref{kr_prund}, we obtain the final pruning formula according to Eq.~\eqref{filter_pruning}:
\begin{equation}
\begin{aligned}
\min _{\delta_{i j}} \sum_{i=1}^K \sum_{j=1}^{n_i} \delta_{i j} (&\mathcal{L}\left(\mathbf{w}_j^i\right)+\mathcal{L}_c\left(F_j^i\right)+\mathcal{L}_k\left(F_j^i\right)), \\
&\text {s.t. }\sum_{j=1}^{n_i} \delta_{i j}=k_l,
\end{aligned}
\end{equation}
where $\delta_{i j}$ is an indicator which is 1 if $\mathbf{w}_j^i$ is to be pruned or 0 if  $\mathbf{w}_j^i$ is to be kept, $\mathcal{L}(\cdot)$ is original CNNs pruning method measure importance of a channel, $\mathcal{L}_c$ and $\mathcal{L}_k$ are coordinate-enhanced score and knowledge-recycling score, $k_l$ is the kept channel number. 
