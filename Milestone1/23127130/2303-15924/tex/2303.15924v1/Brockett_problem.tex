\documentclass[letterpaper, 10 pt, conference]{ieeeconf}
\overrideIEEEmargins
\IEEEoverridecommandlockouts

%\documentclass[a4paper, 10pt, conference]{ieeeconf}

%\documentclass{ieeetran}

\usepackage{amssymb}
\usepackage{graphicx}   % need for figures
\usepackage{amsmath}    % need for subequations
\usepackage{graphicx}   % need for figures
\usepackage{verbatim}   % useful for program listings
\usepackage{color}      % use if color is used in text
\usepackage{subfigure}  % use for side-by-side figures
% \usepackage{hyperref}   % use for hypertext links, including those to external documents and URLs
\usepackage{float}
\usepackage{cite}
\usepackage{bm}
\usepackage{enumerate}  
% \usepackage{epsfig} % for postscript graphics files
% \usepackage{amsgen}
% \usepackage{amsmath}
% \usepackage{amstext}
% \usepackage{amsgen}
% \usepackage{amsbsy}
% \usepackage{amsopn}
% \usepackage{amsfonts}
% \usepackage{graphics}
% \usepackage{epsfig}
% \usepackage{lscape}


%\usepackage{epstopdf}

\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{assumption}{Assumption}
\newtheorem{remark}{Remark}
\newtheorem{corollary}{Corollary}
\newtheorem{problem}{Problem}
\newtheorem{definition}{Definition}
\newcommand*{\QEDB}{\null\nobreak\hfill\ensuremath{\square}}%

\title{\LARGE \bf
A time-varying matrix solution \\ to the Brockett decentralized stabilization problem}

\author{Zhiyong Sun
\thanks{Control Systems Group, Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands. Email: \texttt{sun.zhiyong.cn@gmail.com, z.sun@tue.nl}}%
}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
This paper proposes a time-varying matrix solution to the Brockett stabilization problem. The key matrix condition shows that if the system matrix product $CB$ is a Hurwitz H-matrix, then there exists a time-varying diagonal gain matrix $K(t)$ such that the closed-loop minimum-phase linear system with decentralized output feedback is exponentially convergent. The proposed solution involves several analysis tools such as diagonal stabilization properties of special matrices, stability conditions of diagonal-dominant linear systems, and solution bounds of linear time-varying integro-differential systems. A review of other solutions to the general Brockett stabilization problem (for a general unstructured time-varying gain matrix $K(t)$) and a comparison study are also provided. 
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
In \cite{brockett1999stabilization}, Brockett proposed the following stabilization problem
\begin{itemize}
    \item ``Given  a family of constant matrices 
    \begin{align}
        (A, B_1, B_2, \cdots B_r, C_1, C_2,\cdots, C_r)
    \end{align}
    under what circumstances do there exist \textit{time-dependent} matrices $$K_1(t),K_2(t),\cdots, K_r(t)$$ such that the system
    \begin{align}
        \dot x(t) = Ax(t) +\sum_{i=1}^r B_i K_i(t) C_i x(t) 
    \end{align}
    is   asymptotically stable?"
\end{itemize}

This paper aims to provide  a time-varying matrix solution and controller design method to the Brockett stabilization problem with a structured time-dependent diagonal gain matrix $K(t) = \text{diag}(K_i(t))$. 




% IMPORTANT PAPERS:
% MATRIX MEASURES, STABILITY AND CONTRACTIONTHEORY FOR DYNAMICAL SYSTEMS ON TIME SCALESGiovanni Russo

% https://math.stackexchange.com/questions/2006223/proof-of-coppels-inequality-for-the-matrix-measure

% Vector norms as Lyapunov functions for linear systems


 

  
\subsection{Background  and relevant literature}
Output feedback stabilization has been a classical problem in the development of linear control theory. Early development and solutions of \textit{static} output feedback include the decision method  and   algebraic geometry method \cite{anderson1975output, anderson1977output},  Lyapunov   and linear matrix inequality method \cite{boyd1994linear}, and polynomial function method \cite{byrnes1984output} etc., which were reviewed in \cite{syrmos1997static}. The problem of \textit{decentralized} stabilization, where the output gain matrix $K$ has structured conditions such as a (block) diagonal matrix, was first discussed in the seminal paper \cite{wang1973stabilization} that presented conditions for decentralized stabilizability. The development of decentralized stabilization is also rich in the literature; see e.g., \cite{ravi1995decentralized} on decentralized pole placement and stabilization, and \cite{davison2020decentralized} for the most recent update on decentralized   control systems. 

The Brockett time-varying stabilization problem \cite{brockett1999stabilization} suggests the  means of using   \textit{memoryless} output feedback with \textit{time-varying} gain matrix for system stabilization, which is  one of the challenging open problems in systems and control as documented in \cite{blondel2012open}.  
In the general setting with no diagonal structure constraint on $K(t)$ of the Brockett stabilization problem, there are several partial solutions reported in the literature  \cite{moreau2000note, allwright2005note, boikov2005brockett}. These solutions involve either periodic \textit{scalar} control gains \cite{moreau2000note, allwright2005note, leonov2010stabilization}, or some very strong conditions on the system matrix \cite{boikov2005brockett}, which may not be satisfied in practice. 
A more recent review on the linear time-invariant system stabilization problem and available solutions to output stabilization control is presented in \cite{shumafov2019stabilization}. However, a solution to the Brockett decentralized stabilization under a structural gain matrix $K(t)$ still remains open. 
 

% Brian's method in 

% decentralizerd output stabilization proposed in ...

% A key condition on minimum phase condition [][][].

% For the Brockett stabilization problem, there exists some solututions, but some of them are hard to check, and some involve very strong matrix conditions etc.

% The diagonal structure of $K$ enables a decoupling of each individual output   $y_i(t)$  from the feedback control \eqref{eq:output_feedback} such that each individual control signal $u_i(t)$ only uses the output measurement $y_i(t)$ in each feedback channel. We therefore term such a feedback control structure  as `decentralized output feedback'. 


% The motivation of considering a \textit{diagonal} matrix gain $K$ instead of a scalar gain function or a general matrix  is best described by applications in large-scale stabilization control of networked systems, and distributed control for multi-agent systems. In these control scenarios very often each individual system is associated with some local gain functions associated with local output measurement while a global and uniform gain is not available. 

% Application examples in complex networks and interconnected systems  also motivate diagonal  matrix gains in stabilization control. 

\subsection{Solutions proposed in this paper}
This paper presents a first attempt to solve the Brockett decentralized stabilization problem under a time-varying diagonal gain matrix. The proposed solution has its root in the stabilization control of minimum-phase linear systems \cite{isidori2017stabilization}, while we incorporate several analysis tools including the properties of special matrices, stability conditions of diagonal-dominant linear systems, and solution bounds of linear time-varying integro-differential systems. The key matrix condition shows that if the system matrix product $CB$ is a Hurwitz H-matrix, then there exists a time-varying diagonal gain matrix $K(t)$ such that the closed-loop minimum-phase linear system is exponentially convergent. We also present several easy-to-verify lower bounds to guarantee the existence of a time-varying gain $K(t)$ for system stabilization. 

The paper is organized as follows. Section~\ref{sec:formulation} provides a formal formulation of the time-varying stabilization problem under a diagonal gain $K(t)$. Preliminaries and supporting lemmas are provided in Section~\ref{sec:preliminary}. The main result with the key matrix condition is discussed in Section~\ref{sec:main_result}, with a detailed proof of the time-varying matrix solution. Section~\ref{sec:discussion} gives a review and discussion of other solutions to the Brockett stabilization problem, followed by conclusions in Section~\ref{sec:conclusion} that close this paper. 

% \subsection{Related papers and challenges}
% \begin{itemize}

%     \item The seminal paper on decentralized stabilization \cite{wang1973stabilization}. 
%     \item Brian's papers \cite{anderson1975output, anderson1977output} on output feedback stabilization via decision methods, the  Tarski-Seidenberg approach.  
    
%     \item The paper on decentralized pole placement and stabilization \cite{ravi1995decentralized}. 
    
%     \item The long survey paper on matrix stability and diagonal stability \cite{kushel2019unifying}.  
    
%     \item Isidori's book on multivarible control systems \cite{isidori2017lectures}. 
    
%     \item The review note \cite{Zhiyong_diagonal_2023} and the note on diagonal dominant matrix \cite{sun2023note}. 

%     \item Other solutions to the Brockett stabilization problem; see e.g., \cite{boikov2005brockett}. 
    
    
% \end{itemize}

% \subsection{Contributions  and paper organization}

% The main contribution of this paper is a comprehensive study of decentralized adaptive stabilization theory, while we also present several conditions on   matrix high-gain  stabilizability of  uncertain linear systems. Applications to nonlinear networked systems and adaptive synchronization will also be shown, which provide  novel insights on the general design of adaptive coupling weights to ensure network synchronization. 
% A preliminary version was presented in \cite{sun2019adaptive}. In this paper we will generalize the matrix condition (while in \cite{sun2019adaptive} we focused on the M-matrix condition), and  will further present a complete study on decentralized adaptive stabilization for both systems (I) and (II), based on some new applications of tools such as H-matrix and matrix measure theory. In the development of the main results, the paper will also prove some interesting results on exponential convergence of time-varying linear systems.

% \section{Basic definitions and notation}\label{sec:basics}
 

 

 

%% \linenumbers

%% main text
\section{Problem formulation} \label{sec:formulation}
Motivated by the Brockett stabilization problem reviewed in Introduction, we formally formulate the stabilization problem as follows. 
Consider the following multivariable multi-input multi-output (MIMO) linear  system with $m$  local control stations:
\begin{align} \label{eq:linear_system}
    \dot x(t) &=  Ax(t) + \sum_{i=1}^m B_i u_i(t), \nonumber \\
    y_i(t) & =   C_i x(t),
\end{align}
where $x \in \mathbb{R}^n$ is the state,  $u_i \in \mathbb{R}$ and $y_i \in \mathbb{R}$  are, respectively, the input and output of the $i$-th local control station; $A\in \mathbb{R}^{n \times n}$ is the system matrix, and $B_i \in \mathbb{R}^{n \times 1}$ and $C_i  \in \mathbb{R}^{1 \times n}$ are constant vectors for each stabilization channel. We define 
$u = [u_1, u_2, \cdots, u_m]^T \in \mathbb{R}^{m}$ as the control input vector, and $y = [y_1, y_2, \cdots, y_m]^T \in \mathbb{R}^m$ as the output vector. 
The stabilization control law  is  a memoryless output feedback control
\begin{align} \label{eq:output_feedback}
    u(t) =  Ky(t),
\end{align}
where $K(t) = \text{diag}(k_i(t)) \in \mathbb{R}^{m \times m}$ is the (possibly time-varying) control gain matrix. Now we define 
\begin{align}
    B = [B_1, B_2. \cdots, B_m]\in \mathbb{R}^{n \times m}, C =  \left[\begin{array}{c} C_1 \\ C_2 \\ \vdots \\C_m  \end{array} \right] \in \mathbb{R}^{m \times n}.
\end{align} 
The linear MIMO square system \eqref{eq:linear_system} with the output feedback  control \eqref{eq:output_feedback} results in a closed-loop system 
\begin{align}  \label{eq:closed_loop}
    \dot x(t) &=  Ax(t) + \sum_{i=1}^m B_iK_iC_i x(t) \nonumber \\
    &= Ax(t) + BKC x(t) = (A + BKC) x(t),
\end{align}
and we denote $A_K = A + BKC$ for later use. In this paper, we will study the Brockett stabilization problem with structured time-dependent gain matrix $K(t) = \text{diag}(k_i(t))$. With the gain matrix $K(t)$ in a diagonal form, we call the control of Eq.~\eqref{eq:output_feedback} \textit{decentralized} output feedback. First, we make the following assumption on the system matrices. 

\begin{assumption}
 The system matrices $B$ and $C$ are of full rank, i.e., $\text{rank}(B) = \text{rank}(C) = m$; and the matrix product $CB$ is non-singular, i.e., $\text{rank}(CB) = m$. 
\end{assumption}

\begin{remark}
In decentralized feedback control, each sub-system (called ``agent") in a local control station uses independent channel for the feedback stabilization, which implies that the columns of $B$ and the rows of $C$ are, respectively, linearly independent that justifies the rank conditions. The rank condition $\text{rank}(CB) = m$ is the same to that the MIMO system realization is of relative degree one. 
\end{remark}
 
In this paper we aim to address the following problem.
\begin{problem} Find matrix conditions and design output feedback control laws to solve the Brockett decentralized stabilization problem with a time-varying diagonal gain matrix $K(t)$. 
\end{problem}
 
 
 
 


\section{Preliminaries and supporting results} \label{sec:preliminary}
\subsection{Notations}
The notations in this paper are fairly standard.      The notation   $I_n$ denotes an $n \times n$ identity matrix.   For a vector $x \in \mathbb{R}^n$, the notation $\|x\|_1$ denotes the vector 1-norm, i.e., $\|x\|_1 = \sum_{i=1}^n |x_i|$. By default, the notation $\|x\|$ for a vector $x \in \mathbb{R}^n$ is interpreted as the 2-norm, unless otherwise specified. We use `$\text{diag}(\cdot)$' (resp. `$\text{blk-diag}(\cdot)$') to denote  a diagonal (resp. block diagonal) matrix.  

 Consider a function $f(t) : \mathbb{R}_{\geq 0} \to \mathbb R$ that is locally integrable. Given a fixed $p\in (0, \infty)$, we say that $f(t)$ belongs to the $\mathcal{L}^p$ space (i.e., $f(t) \in \mathcal{L}^p$) if $\int_0^{\infty} |f(s)|^p ds < \infty$.

\subsection{Special matrices}
We present definitions of certain special matrices which will be frequently used in this paper. All matrices discussed in this paper are real-valued matrices. 
 
    

\begin{itemize}
     \item A real square matrix $A \in \mathbb{R}^{n \times n}$ is   \textbf{Hurwitz}  if all its eigenvalues have negative  parts.  
    \item A real square matrix $A \in \mathbb{R}^{n \times n}$ is called an M-matrix, if its non-diagonal entries are non-positive and its  eigenvalues have positive real parts. 
% \item  A real matrix $A  = \{a_{ij}\}\in \mathbb{R}^{n \times n}$ is  \textbf{\textit{\textbf{row}}-diagonal dominant}, if the absolute value of each diagonal entry is greater than   the sum of the absolute values of off-diagonal entries in that row;  i.e., $|a_{ii}|  \geq \sum_{j=1, j \neq i}^{n} |a_{ij}|, \forall i = 1, 2, \cdots, n$.
\item 
A real  square matrix $A  = \{a_{ij}\}\in \mathbb{R}^{n \times n}$ is   \textbf{generalized   \textit{\textbf{row}}-diagonal dominant}, if there exists $x = (x_1, x_2, \cdots, x_n) \in \mathbb{R}^n$ with $x_i >0$, $\forall i$, such that
\begin{align}
    |a_{ii}| x_i > \sum_{j=1, j \neq i}^{n} |a_{ij}|x_j, \forall i = 1, 2, \cdots, n.
\end{align}

\item A real  square matrix $A  = \{a_{ij}\} \in \mathbb{R}^{n \times n}$ is   \textbf{generalized   \textit{\textbf{column}}-diagonal dominant}, if there exists $x = (x_1, x_2, \cdots, x_n) \in \mathbb{R}^n$ with $x_i >0$, $\forall i$, such that
\begin{align}
    |a_{jj}| x_j > \sum_{i=1, i \neq j}^{n} |a_{ij}|x_i, \forall j = 1, 2, \cdots, n.
\end{align}

% \item  A real matrix $A  = \{a_{ij}\}\in \mathbb{R}^{n \times n}$ is  \textbf{\textit{\textbf{column}}-diagonal dominant}, if the absolute value of each diagonal entry is greater than   the sum of the absolute values of off-diagonal entries in that column;  i.e., $|a_{jj}|  \geq \sum_{j=1, j \neq i}^{n} |a_{ij}|, \forall j = 1, 2, \cdots, n$.

\item (\textbf{Comparison matrix and $H$-matrix})
For a real matrix $A = \{a_{ij}\} \in \mathbb{R}^{n \times n}$, we associate it with a  comparison matrix $M_A = \{m_{ij}\} \in \mathbb{R}^{n \times n}$, defined by 
\begin{align}
    m_{ij} =   \left\{
       \begin{array}{cc}
       |a_{ij}|,  &\text{  if  } \,\,\,\,j  = i;  \\ \nonumber
       -|a_{ij}|,  &\text{  if  } \,\,\,\, j  \neq i.   \nonumber  
       \end{array}
      \right.
\end{align}
A given matrix $A$ is called an \textbf{H-matrix} if its comparison matrix $M_A$ is an M-matrix. 

 
\end{itemize}
 
 
Apparently, the set of M-matrices is a subset of H-matrices.   For  readers' convenience,  a more comprehensive survey on relevant matrices in the stability and stabilization analysis for linear time-invariant/time-varying systems is presented in   \cite{Zhiyong_diagonal_2023} and   \cite{sun2023note}. 
The following more general result  shows the equivalence between  generalized row-diagonal dominance,   generalized column-diagonal dominance, and  H-matrices.  

\begin{theorem} \label{theorem:_H_matrix}
Given a matrix $A = \{a_{ij}\} \in \mathbb{R}^{n \times n}$, the following statements are equivalent. 
\begin{enumerate}  
 \label{claim:H_matrix}
    \item $A$ is an $H$-matrix;
    \item $A$ is generalized \textit{row}-diagonal dominant;
    \item There exists a positive diagonal matrix $\bar D = \text{diag}\{\bar d_1, \bar d_2, \cdots, \bar d_n\}$, such that $\bar D^{-1} A \bar D$ is row-diagonal dominant; 
    \item $A$ is generalized \textit{column}-diagonal dominant;
    \item There exists a positive diagonal matrix $\tilde D = \text{diag}\{\tilde d_1, \tilde d_2, \cdots, \tilde d_n\}$, such that $\tilde D A \tilde D^{-1}$ is column-diagonal dominant. \QEDB
\end{enumerate}   
\end{theorem}

The proof is presented in \cite{sun2021distributed}. Applying the   Gershgorin circle theorem \cite{roger1994topics}, we immediately obtain the following result as a direct consequence of Theorem~\ref{theorem:_H_matrix}. 

\begin{proposition} \label{pro:H_Hurwitz}
Let $B =\{b_{ij}\} \in \mathbb{R}^{n\times n}$ be an $H$-matrix.  Then $B$ is non-singular. Further suppose that all diagonal entries of $B$ are negative, i.e., $b_{ii} <0, \forall i$. Then all of its eigenvalues have negative real parts; i.e.,   $B$ is a   Hurwitz matrix.   \QEDB
\end{proposition}
 
 
 
% \subsection{Minimum phase systems}
% A characterization of the minimum phase condition for state space system is given in the following conditions \cite{ilchmann1993non}.
% \begin{lemma}
% A state-space realization $(A, B, C) \in \mathbb{R}^{n \times n}\times \mathbb{R}^{n \times m} \times \mathbb{R}^{m \times n}$ satisfies
% \begin{align}
%     \text{det} \left[\begin{array}{cc} sI_n - A & -B \\ -C  &  0\end{array} \right] \neq 0, \,\,\,\forall s \in \mathbb{C}^+
% \end{align}
% if and only if the following conditions hold.
% \begin{itemize}
%  \item The matrix pair $(A, B)$ is    stabilizable by state feedback;
%  \item The matrix pair $(A, C)$ is observable;
%  \item The associated transfer matrix $G(s)$ has no zeros in $\mathbb{C}^+$. 
% \end{itemize}

 

% \end{lemma}
 
% \subsection{Exponential convergence of diagonal dominant time-varying  systems}
% In this section, by applying the theory of matrix measures (see Appendix),   we develop some results on the solution bound and exponential convergence of time-varying linear systems with diagonal dominant system matrices. 

% \begin{lemma} \label{lemma:row_dd_system}
% (Row-diagonal dominant linear system)
% Consider a time-varying linear system $\dot x(t) = A(t)x(t)$, where $A(t)$ is a continuous-time Hurwitz matrix with row-diagonal dominant entries $\forall t \geq t_0$. Then it holds that
% \begin{align}
%         \|x(t)\|_\infty \leq \|x(t_0)\|_\infty e^{\int_{t_0}^{t} \alpha_r(t') \text{d}t'},  \forall t \geq t_0, 
% \end{align}
% where $\alpha_r(t') = \text{max}_{i =1, 2, \cdots, n} \left(a_{ii}(t') +\sum_{j=1, j\neq i}^n |a_{ij}(t')|\right)$ and $\alpha_r(t')<0$.
% \end{lemma}

% \begin{proof}
% Applying Lemma~\ref{theorem:measure_exponential}, and choosing the vector norm as the infinity norm with the matrix measure induced by infinity vector norm in \eqref{eq:measure_infinity_norm} (in Appendix), gives the desired result. Note that $A(t)$ being Hurwitz and row-diagonal dominant implies that $\alpha_r(t')<0$.
% \end{proof}

% In particular, 
% consider a time-varying system $\dot x = -A(t) x$ with $A(t) : = \{a_{ij}(t)\} \in \mathbb{R}^{n \times n}$ satisfying
%  \begin{align} \label{eq:column_dDD}
%     a_{ii}(t) - \sum_{j =1, i\neq j}^n |a_{ij}(t)| \geq \delta >0, \forall i = 1,2,\cdots, n, \forall t \geq \bar t,
% \end{align}
% with a finite time $\bar t$.  Then all of its solutions converge to zero exponentially fast with the rate $e^{-\delta t}$ as $t \rightarrow \infty$. In fact, it holds that
% \begin{align} \label{eq:exponential_bound1}
%    |x_i(t)| \leq  \|x(t)\|_\infty \leq  \|x(\bar t)\|_\infty e^{-\delta t}, \forall i, \forall t \geq \bar t.  
% \end{align}

% \begin{lemma} \label{lemma:column_exponential}
% (Column-diagonal dominant linear system)
% Consider a time-varying linear  system $\dot x(t) = A(t)x(t)$, where $A(t)$ is a continuous-time Hurwitz matrix with column-diagonal dominant entries $\forall t \geq t_0$. Then it holds that
% \begin{align}
%         \|x(t)\|_1 \leq \|x(t_0)\|_1 e^{\int_{t_0}^{t} \alpha_c(t') \text{d}t'}, \forall t \geq t_0, 
% \end{align}
% where $\alpha_c(t') = \text{max}_{j =1, 2, \cdots, n} \left(a_{jj}(t') +\sum_{i=1, i\neq j}^n |a_{ij}(t')|\right)$ and $\alpha_c(t')<0$.
% \end{lemma}
% \begin{proof}
% Applying Lemma~\ref{theorem:measure_exponential}, and choosing the vector norm as the one-norm with the matrix measure induced by the vector one-norm in \eqref{eq:measure_one_norm} (in Appendix), gives the desired result. Note that $A(t)$ being Hurwitz and column-diagonal dominant implies that $\alpha_c(t')<0$.
% \end{proof}


 
% In particular, 
% consider a time-varying system $\dot x = -A(t) x$ with $A(t) : = \{a_{ij}(t)\} \in \mathbb{R}^{n \times n}$ satisfying
%  \begin{align} \label{eq:column_dDD}
%     a_{jj}(t) - \sum_{i =1, i\neq j}^n |a_{ij}(t)| \geq \delta >0, \forall j = 1,2,\cdots, n, \forall t \geq \bar t 
% \end{align}
% with a finite time $\bar t$. Then all of its solutions converge to zero exponentially fast with the lower bound rate $e^{-\delta t}$ as $t \rightarrow \infty$. In fact, it holds that
% \begin{align} \label{eq:exponential_bound1}
%    |x_i(t)| \leq  \sum_{i = 1}^n |x_i(t)| \leq e^{-\delta t} \sum_{i = 1}^n |x_i(\bar t)|, \forall i,  \forall t \geq \bar t.   
% \end{align}
% We note that the solution bound and exponential convergence in \eqref{eq:exponential_bound1} under the condition of \eqref{eq:column_dDD} for column-diagonal  dominant  linear  systems generalize the main Theorem of \cite{kahane1972stability}. 
 

\subsection{Matrix measure and its applications to diagonal dominant time-varying  systems} 
The matrix measure (or ``logarithmic norm") plays an important role in bounding the solution of differential equations.  We introduce the definition and some properties of matrix measure from \cite{desoer1975feedback} as follows.

\begin{definition}(Matrix measure)
Given a real $n \times n$ matrix  $A$, the  matrix measure   $\mu(A)$ is defined as 
\begin{align}
    \mu(A) = \text{lim}_{\epsilon \downarrow 0} \frac{\|I + \epsilon A\| - 1}{\epsilon},
\end{align}
where $\|\cdot\|$ is a matrix norm on $\mathbb{R}^{n \times n}$ induced by a vector norm $\|\cdot\|'$ on $\mathbb{R}^n$.  \QEDB
\end{definition}

The matrix measure is always well-defined, and can take positive or negative values. Different matrix norms  on $\mathbb{R}^{n \times n}$ induced by a corresponding  vector norm $\|\cdot\|'$ give  rise to different matrix measures.  
In particular,   if the vector norm $\|\cdot\|'$ is chosen as the 1-norm, i.e.,  $\|\cdot\|' = \|\cdot\|_1$, then the induced matrix norm is the column-sum norm, i.e., $\|A\| = \|A\|_{\text{col}} = \text{max}_j \sum_i |a_{ij}|$. The corresponding matrix measure is 
    \begin{align} \label{eq:measure_one_norm}
        \mu(A) = \text{max}_{j =1, 2, \cdots, n} \left(a_{jj} +\sum_{i=1, i\neq j}^n |a_{ij}|\right).
    \end{align}
 
As a direct application of matrix measure in the study of time-varying linear systems,  
we recall the following result (the Coppel inequality \cite{coppel1965stability}) that bounds the solution of a time-varying linear system via matrix measures (see e.g., Chapter 2 of \cite{desoer1975feedback}). 
\begin{lemma} \label{theorem:measure_exponential}
Let $t \rightarrow A(t)$ be a continuous matrix function from $\mathbb{R}^+$ to $\mathbb{R}^{n \times n}$. Then the solution of the time-varying linear system 
\begin{align}
    \dot x(t) = A(t)x(t)
\end{align}
satisfies the inequalities
\begin{align}
    \|x(t_0)\|' e^{- \int_{t_0}^{t} \mu(-A(t'))\text{d}t'}  \leq \|x(t)\|' &  \leq \|x(t_0)\|' e^{\int_{t_0}^{t} \mu(A(t'))\text{d}t'} \nonumber \\
    & \forall t \geq t_0,
\end{align}
where $\|\cdot\|'$ denotes a vector norm that is compatible with the norm in the matrix measure $\mu(A)$.  \QEDB
\end{lemma}

\begin{lemma} \label{lemma:column_exponential}
(Column-diagonal dominant linear system)
Consider a time-varying linear  system $\dot x(t) = A(t)x(t)$, where $A(t)$ is a continuous-time Hurwitz matrix with column-diagonal dominant entries $\forall t \geq t_0$. Then it holds that
\begin{align}
        \|x(t)\|_1 \leq \|x(t_0)\|_1 e^{\int_{t_0}^{t} \alpha_c(t') \text{d}t'}, \forall t \geq t_0, 
\end{align}
where $\alpha_c(t') = \text{max}_{j =1, 2, \cdots, n} \left(a_{jj}(t') +\sum_{i=1, i\neq j}^n |a_{ij}(t')|\right)$ and $\alpha_c(t')<0$. \QEDB
\end{lemma}
\begin{proof}
Applying Lemma~\ref{theorem:measure_exponential}, and choosing the vector norm as the one-norm with the matrix measure induced by the vector one-norm in \eqref{eq:measure_one_norm}, gives the desired result. Note that $A(t)$ being Hurwitz and column-diagonal dominant implies that $\alpha_c(t')<0$.
\end{proof}

\subsection{Solution bounds of time-varying linear integro-differential systems}
 In this subsection we recall the following conditions for the solution bounds of time-varying linear integro-differential systems, which will be used in the proof of the main results. 
\begin{theorem} \label{thm:exp_int_diff}  (Conditions for exponential convergence of linear integro-differential systems, \cite{ngoc2017new})
Consider the following integro-differential system
\begin{align} \label{eq:integro-differential2}
    \dot x(t) = a(t) x(t) + \int_0^t b(t-s) x(s) \text{d} s.
\end{align}
Suppose $b(t) \in \mathcal{L}^1$ and $a(t) \leq -\gamma, \forall t \geq 0$ with
\begin{align}
    -\gamma + \int_0^\infty b(t) \text{d} t <0.
\end{align}
Then the system \eqref{eq:integro-differential2} is uniformly asymptotically stable. In addition, if there exists a positive constant $\epsilon$ such that 
\begin{align}
    \int_0^\infty |b(t-s)| e^{\epsilon t} \text{d} t < \infty.
\end{align}
Then the solution to \eqref{eq:integro-differential2} is exponentially convergent.  \QEDB

\end{theorem}

% \begin{remark}
% The solution bounds and conditions for exponential stability in Theorem~\ref{thm:solution_bound} are more conservative than these in Theorem~\ref{thm:exp_int_diff}. 
% \end{remark}
The following lemma presents conditions for the exponential convergence of linear time-varying integro-differential systems with exponentially decaying perturbations. The proof, which is omitted here,  follows similar steps as in \cite{ngoc2017new} and the GrÃ¶nwall's inequality.
\begin{lemma}
Consider the  integro-differential system \eqref{eq:integro-differential2} and its perturbed version with a perturbation term
\begin{align} \label{eq:integro-differential2_pert}
    \dot x(t) = a(t) x(t) + \int_0^t b(t-s) x(s) \text{d} s + f(t),
\end{align}
where $|f(t)| \leq M e^{-\beta t}$ with positive constants $M > 0, \beta > 0 $. If the solution to \eqref{eq:integro-differential2} is exponentially convergent, then the solution to \eqref{eq:integro-differential2_pert} is also exponentially convergent. \QEDB
\end{lemma}
 

%  \section{Main result}

%  In this section, we discuss some matrix conditions for system stabilizability   with decentralized output feedback. 
%  \begin{theorem} \label{thm:condition}
% Consider the multivariable MIMO linear system \eqref{eq:linear_system} with a minimum state-space realization $\{A, B, C\}$. Suppose that the system is of minimum phase (i.e., the system zeros have negative real parts), or the system has no zeros. Then the necessary and sufficient condition for the system to be stabilizable by decentralized output feedback with a   diagonal matrix gain $K$ is that the  matrix product $CB$ is \textbf{diagonal stabilizable}.  
%  \end{theorem}
 
%  \begin{proof}
%      Firstly we follow the system decomposition technique in \cite{kouvaritakis1976geometric, isidori2017stabilization}  to perform a coordinate transform for the multivariable  linear system \eqref{eq:linear_system} under the minimum-phase condition.  Choose matrices $M \in \mathbb{R}^{n \times (n-m)}, N\in \mathbb{R}^{(n-m)\times n}$, such that 
%       \begin{align} \label{eq:matrix_NM}
%           NB = 0, CM = 0, N = (M^TM)^{-1}M^T (I_n - B(CB)^{-1}C).
%       \end{align}
%       Note that $NM = I_{n-m}$. Consider the system coordinate transformation $\bar x = T x$, with the transformation matrix 
%       \begin{align}  \label{eq:T}
%           T = \left[\begin{array}{c} N \\ C  \end{array} \right], \,\,\,\text{with}\,\,\,T^{-1} = \left[\begin{array}{cc} M, \,\, B(CB)^{-1}  \end{array} \right].
%       \end{align}
%       The transformed closed-loop linear system is described by $ \dot {\bar x} = T A_K T^{-1} \bar x : = \bar A_K \bar x$, with
%       \begin{align} \label{eq:transform_minimum_phase1}
%           \bar A_K &= T A_K T^{-1} \nonumber \\
%                   &= T A  T^{-1} + T (BKC)  T^{-1} \nonumber \\
%                   & = \left[\begin{array}{cc} NAM & NA B(CB)^{-1} \\ CAM &  CA B(CB)^{-1} \end{array} \right] + \left[\begin{array}{cc} 0 & 0 \\ 0 & CBK \end{array} \right]  \nonumber \\
%                   &= \left[\begin{array}{cc} NAM & NA B(CB)^{-1} \\ CAM &  CA B(CB)^{-1} + CBK\end{array} \right]  .
%       \end{align}
%       The minimum phase condition implies that the submatrix $NAM$ is Hurwitz \cite{kouvaritakis1976geometric, isidori2017stabilization}. 
%       For notational convenience we denote $\bar A_{11} : = NAM, \bar A_{12} := NA B(CB)^{-1}, \bar A_{21} := CAM$ and $\bar A_{22} : = CA B(CB)^{-1}$. The condition that $CB$ is diagonal stabilizable   implies the existence of a set of   diagonal matrix $\bar K$, such that the matrix product $CB \bar K$ is   Hurwitz. By Lyapunov theory there exist two positive definite symmetric matrices $P_1, P_2$, such that 
%       \begin{align} \label{eq:Lya_2}
%          P_1 \bar A_{11}  + \bar A_{11}^T P_1  &\prec 0;  \nonumber \\
%           P_2 (CB \bar K)  +  (CB \bar K)^T P_2 &\prec 0. 
%       \end{align}
%       Now we consider 
%       \begin{align} \label{eq:matrix_transform}
%          & \text{blk-diag}(P_1, P_2) (T A_{ K} T^{-1})  +  (T A_{ K} T^{-1})^T \text{blk-diag}(P_1, P_2) \nonumber \\
%          & =  \left[\begin{array}{cc} P_1 \bar A_{11} +  \bar A_{11}^T P_1 & P_2 \bar A_{12} + \bar A_{22}^T P_1 \\ P_1 \bar A_{21} + \bar A_{12}^T P_2 & P_2 \bar A_{22}  +  \bar A_{22}^T P_2 + P_2 (CB{ K})  +  (CB{ K})^T P_2 \end{array} \right] , 
%       \end{align}
%       where we intend to find a diagonal constant gain matrix ${K}$ such that the matrix \eqref{eq:matrix_transform} is negative definite.   According to the Schur Complement Lemma~\ref{lemma:Schur_com}, the negative definiteness of \eqref{eq:matrix_transform} is equivalent to 
%       \begin{align} \label{Eq:schur_ND}
%          &  P_1 \bar A_{11}  +  \bar A_{11}^T P_1 \prec 0;     \nonumber \\
%          &  P_2 (CB{  K})  +  (CB{  K})^T P_2     \nonumber \\
%          &  + \underbrace {P_2 \bar A_{22}  +  \bar A_{22}^T P_2 -   (P_1 \bar A_{21} + \bar A_{12}^T P_2) (P_1 \bar A_{11} +  \bar A_{11}^T P_1)^{-1} (P_2 \bar A_{12} + \bar A_{22}^T P_1) }_{: = N_{A, P}} \prec 0.    \nonumber \\
%       \end{align}
%       Let $ K = \bar \alpha \bar K$, where $\bar \alpha > \alpha$ and $\alpha$ is a positive constant satisfying  
%       \begin{align} \label{eq:alpha}
%           \alpha > \frac{\lambda_{max} (N_{A, P})}{\lambda_{min} \left(-(P_2 (CB \bar K)  +  (CB \bar K)^T P_2)\right)}  .
%       \end{align} 
%       which guarantees the  negative definiteness of \eqref{eq:matrix_transform}. 
      
%       In the case that the system has no zeros (which is equivalent to that the system matrices $B$ and $C$ are   square matrices of full rank), the transformation matrix $T$ can be chosen as $T = C$ and the transformed system matrix  \eqref{eq:transform_minimum_phase} simplifies to 
%       \begin{align} \label{eq:transform_simplied}
%           \bar A_K &= T A_K T^{-1}  =  C A  C^{-1} + C (BKC)  C^{-1} \nonumber \\
%                   & = CA C^{-1}  + CBK  .
%       \end{align}
      
%       Again, the condition that $CB$ is diagonal stabilizable   implies the existence of a set of positive diagonal matrix $\bar K$, such that the matrix product $CB \bar K$ in \eqref{eq:transform_simplied} is   Hurwitz. Then, by letting $ K = \bar \alpha \bar K$ with a sufficiently large  $\bar \alpha$ we can guarantee that the overall matrix in  \eqref{eq:transform_simplied} is Hurwitz. The remaining proofs follow similarly. 
      
%       Therefore,  under the given conditions, one concludes that the MIMO system \eqref{eq:linear_system} can be stabilized by decentralized output feedback with a diagonal gain matrix $\bar K$. The proof is completed. 
%  \end{proof}



% \begin{remark} Some remarks of  Theorem \ref{thm:condition} are in order. 
% \begin{itemize}
%     \item In   decentralized control of multivariable LTI systems, a well-known result on the necessary and sufficient condition for stabilizability (the  existence of a set of local feedback control laws) is that the set of fixed modes (if they exist)  of the system   are stable, i.e., they are located in the open left half plane (see \cite{wang1973stabilization, anderson1981algebraic, liu2019overcoming}). The minimum phase condition in Theorem \ref{thm:condition} is essentially the same to the stable fixed-mode condition. 
%     %We also note that the minimum phase condition the eigenvalues of $NAM$ are the transmission zeros of the system.
%     \item The condition on minimum phase (or empty zeros) is necessary for the existence of decentralized feedback gain matrix with output feedback stabilization.  
%     \item In the statement of Theorem~\ref{thm:condition}, if the matrix product $CB$ is already Hurwitz, then the diagonal matrix $\bar K$ can be chosen as the identity matrix. This case reduces to the classical result on scalar-gain adaptive control as studied in e.g., \cite{byrnes1984adaptive,corless1991simple,hackl2012non}. 
%     \item The proof of Theorem~\ref{thm:condition} also suggests a feasible way to find a diagonal gain matrix for decentralized stabilization. 
% \end{itemize}


% \end{remark}

% Based on the Fisher-Fuller Theorem~\ref{thm:Disher}, we also give a sufficient condition for decentralized output feedback stabilization. 
% \begin{corollary}
% Suppose that the system is of minimum phase, and the matrix product $CB$ has  positive leading principle minors. Then the system can be stabilized by decentralized output feedback with a positive diagonal matrix gain $K$.
% \end{corollary}
% \begin{proof}
% This is an immediate  consequence of Theorem~\ref{thm:condition} and the  Fisher-Fuller condition in Theorem~\ref{thm:Disher} of~\cite{fisher1958stabilization}.  
% \end{proof}

 


% \section{Feedback positive realness with decentralized output feedback}
% \subsection{Background: positive real systems}
% The following well-known result characterizes a time-domain condition for positive real systems.

% \begin{lemma} \label{lm:PR_lemma} {\cite{anderson1967system}}
% The linear MIMO system $\{A, B, C\}$ in \eqref{eq:linear_system}  with the transfer function $T(s) = C(sI - A)^{-1}B$ is positive real, if and only if there exist   positive definite real symmetric matrices $P = P^T \in \mathbb{R}^{n \times n}, Q = Q^T \in \mathbb{R}^{n \times n}$ such that
% \begin{align}
%     PA +A^T P &= -Q; \nonumber \\
%     PB &= C^T.
% \end{align}
% \end{lemma}

% \begin{definition}
% (Feedback positive realness) A closed-loop  MIMO system \eqref{eq:closed_loop} with a  state-space realization $\{A_K, B, C\}$ and output feedback $ u = Ky$ is called feedback positive real, if there exist  a feedback matrix $K$ and two  positive definite real symmetric matrices $P = P^T \in \mathbb{R}^{n \times n}, Q = Q^T \in \mathbb{R}^{n \times n}$ such that
% \begin{align} \label{eq:FPR}
%     P(A + BKC) +(A + BKC)^T P &= -Q; \nonumber \\
%     PB &= C^T.
% \end{align}
% \end{definition}

% \subsection{Feedback positive real system with general output feedback}
% The following result has been reported repeatedly in the literature. 
% \begin{lemma} {\cite{huang1999design, barkana2004comments}}
% Suppose that the matrix product $CB$ is  
% positive definite symmetric. Then  a strictly proper   minimum-phase system $\{A, B, C\}$ can be made    positive real via a
% constant output feedback. 
% \end{lemma}

% Note that the condition that `$CB$ is  
% positive definite symmetric' also implies that the matrix $CB$ is diagonal dominant. The symmetry condition of $CB$ looks restrictive, and has been relaxed in \cite{fradkov2003passification, barkana2006mitigation}. Specifically, it is proved in \cite{barkana2006mitigation} that  an associated transfer function $T(s) = WC(sI - A)^{-1}B$ can be made strictly positive real by output feedback, if there exists a positive definite symmetric matrix $W$ such that the matrix product $W(CB)$ is positive definite symmetric. A similar condition, termed `$G$-minimum phase' is discussed in \cite{fradkov2003passification}, while the matrix equality  in \eqref{eq:FPR} is replaced by $PB = (GC)^T$ by a positive definite symmetric matrix $G$. Inspired by \cite{owens1987positive}, in the following we choose the matrix condition $PB (CB)^{-1} = C^T$ to evaluate the feedback positive realness of the MIMO system \eqref{eq:linear_system} under decentralized output feedback. 

% \subsection{Feedback positive realness with decentralized output feedback}

% \begin{theorem} \label{thm:feedback_PR}
% Suppose that the MIMO system \eqref{eq:linear_system} is of minimum phase, and the matrix product $CB$ is \textbf{diagonal stable}. Then the system with an associated transfer function $T_1(s) = C(sI - A)^{-1} B (CB)^{-1}$ can be made strictly positive real via a
% decentralized output feedback under a diagonal gain matrix $K$.

% \end{theorem}

% \begin{proof}
% By Lemma  \ref{lm:PR_lemma} the statement in the theorem is equivalent to the following: there exist  a  diagonal feedback gain matrix $K$ and two  positive definite real symmetric matrices $P = P^T \in \mathbb{R}^{n \times n}, Q = Q^T \in \mathbb{R}^{n \times n}$ such that
% \begin{align}  \label{eq:positive_real_matrix}
%     P(A + BKC) +(A + BKC)^T P &= -Q; \nonumber \\
%     PB (CB)^{-1} &= C^T.
% \end{align}
% Consider the matrix 
% \begin{align} \label{eq:matrix_P}
%      P = N^T P_1 N + C^T C,
% \end{align}
% where $N$ is defined in \eqref{eq:matrix_NM}, and $P_1$ is a positive definite symmetric matrix satisfying the Lyapunov equation 
% \begin{align}
%    P_1(NAM)+(NAM)^TP_1 = -Q_1   \prec 0.
% \end{align}
% Since $NAM$ is Hurwitz, for a positive definite symmetric matrix $Q_1$, a positive definite symmetric solution   $P_1$ always exists. 

% We remark that the real symmetric matrix   $P$ constructed in \eqref{eq:matrix_P} is  positive definite. This is because $\text{range}(N) = \text{range}(N^T P_1 N) = \mathbb{R}^{n-m}$, $\text{range}(C^T C) = \mathbb{R}^{m}$, and $\text{range}(N^T P_1 N) \oplus	\text{range}(C^T C) = \mathbb{R}^m$. Therefore,   $P$ is of full range and thus is positive definite. 

% Now we prove the matrix equalities in \eqref{eq:positive_real_matrix} by showing the existence of the matrices $K$ and $Q$. First, note that
% \begin{align} \label{eq:PAK}
%            P A_K + A_K^T P   = & N^T P_1 NA + C^TC A + C^TCBKC \nonumber \\
%                      &+  A^T N^T P_1 N + A^T C^T C + (BKC)^T C^T C
% \end{align}
% Consider the congruent  transformation
% \begin{small}
% \begin{align} \label{eq:negative_definite}
% & T^T (P A_K + A_K^T P) T \nonumber \\
% & = \left[\begin{array}{cc} P_1 NAM + (P_1 NAM)^T & P_1 NAB (CB)^{-1} + (CAM)^T\\ (P_1 NAB (CB)^{-1})^T + CAM &  CAB (CB)^{-1} + (CAB (CB)^{-1})^T  + CBK + (CBK)^T\end{array} \right]. \nonumber \\
% \end{align} 
% \end{small}
% For notational convenience we denote $A_{T12} =  P_1 NAB (CB)^{-1} + (CAM)^T,  A_{T21} = A_{T12}^T$, and $A_{T22} = CAB (CB)^{-1} + (CAB (CB)^{-1})^T$. 

% By Schur complement theorem, the negative definiteness of \eqref{eq:negative_definite} (or equivalently, the negative definiteness of \eqref{eq:PAK}) is equivalent to 
% \begin{align}
%     P_1 NAM + (P_1 NAM)^T  = -Q_1 & \prec 0; \nonumber \\
%       CBK + (CBK)^T + \underbrace{A_{T22} - A_{T21} (P_1 NAM + (P_1 NAM)^T) A_{T12}}_{M_{A, P}} & \prec 0 .\nonumber \\
% \end{align}

% By the diagonal stability condition of $CB$,   there exists a diagonal matrix $\bar K$ such that $ CB \bar K + (CB\bar K)^T$ is negative definite.  Let $K = \alpha \bar K$, where $\alpha > \bar \alpha$ and $\bar \alpha$ is a positive constant satisfying 
% \begin{align}
%     \alpha = \frac{\lambda_{max}(M_{A, P})}{\lambda_{min}(-(CBK + (CBK)^T))},
% \end{align}
% which guarantees the negative definiteness of \eqref{eq:PAK}.
%   This completes the proof. 

% \end{proof}
 
% An equivalent formulation of Theorem~\ref{thm:feedback_PR} is the following: Suppose that a MIMO system \eqref{eq:linear_system} is of minimum phase, and the matrix product $CB$ is  
% diagonal stable. Then the system with an associated transfer function $T_1(s) = (CB)^TC(sI - A)^{-1} B $  can be made strictly positive real via a
% decentralized output feedback under a diagonal gain matrix $K$.

% Positive real structure of linear systems has a close implication to high-gain stabilization and adaptive control \cite{owens1987positive, anderson1990robust}, which will be discussed in the following sections. 
 
% A block diagram showing the decentralized feedback passivity for an LTI system is dipicted in Fig.~\ref{fig:PR}. 

%Remark: the condition of Theorem~\ref{thm:feedback_PR} seems to be

% \begin{figure} 
% \centering
% \includegraphics[width=5.0in]{control.eps}
% \caption{Interpretation of a feedback passivity system, by diagonal output feedback}
% \label{tetra2}
% \end{figure}
 
%  \begin{figure} 
% \centering
% \includegraphics[width=5.0in]{Control2.eps}
% \caption{Interpretation of a decentralized feedback passive system, by diagonal output feedback.}
% \label{fig:PR}
% \end{figure}
 
 
%  \section{High-gain feedback positive realness with decentralized output feedback}

% \begin{theorem}
% Suppose that a MIMO system is of minimum phase, and the matrix product $CB$ is  
% an H-matrix. Then the system with the transfer function $T_1(s) = C(sI - A)^{-1} B (CB)^-1$ can be made strictly positive real via a
% decentralized output feedback under a diagonal high-gain matrix $K = \diag\{k_1, k_2, \cdots, k_n\}$ where $k_i \geq \bar k, \forall i$. 

% \end{theorem}
 
 
\section{Main result} \label{sec:main_result}
In this section, we present the main result that involves a key matrix condition to solve the Brockett decentralized stabilization problem. 
% \subsection{Matrix diagonal conditions for decentralized stabilization}






%   \begin{theorem} \label{thm:high-gain}
% Consider the multivariable MIMO linear system \eqref{eq:linear_system} with a minimum state-space realization $\{A, B, C\}$. Suppose that the system is of minimum phase, and the matrix product $CB$ is \textbf{diagonal stabilizable}. Then the system can be stabilized by decentralized high gains in terms of a diagonal  gain matrix $K = \text{diag}\{k_1, k_2, \cdots, k_n\}$ with $k_i >\bar k, \forall i$, where  $\bar k$ is  a positive constant. 
%  \end{theorem}



% The proof is based on the generalized diagonal dominant property of $H$-matrix, and will be provided soon. 

 
 


% \begin{theorem} \label{theorem:infinite_gain}
% (High gain stabilizability) Consider the uncertain linear system \eqref{eq:system} with unknown system matrices $A$ and/or $B$.  Suppose $B$ is an \textbf{$H$-matrix with   positive diagonal entries}, and each individual gain function $k_i(t)$ in the matrix gain $K(t)$ is a monotonically increasing function approaching infinity as $t \rightarrow \infty$. Then the uncertain linear system \eqref{eq:system} is exponentially convergent to zero. 




% Consider the multivariable MIMO linear system \eqref{eq:linear_system} with a minimum state-space realization $\{A, B, C\}$. Suppose that the system is of minimum phase, and the matrix product $CB$ is diagonal stabilizable. Then the system can be stabilized by decentralized high gains in terms of a diagonal  gain matrix $K = \text{diag}\{k_1, k_2, \cdots, k_n\}$ with $k_i >\bar k, \forall i$, where  $\bar k$ is  a positive constant. 
% \end{theorem}



% \begin{theorem} \label{theorem:infinite_gain}
% Suppose $(A, B, C)$ is minimum phase and $K(t) = \text{diag}(k_1(t), k_2(t), \cdots, k_n(t))$ where $k_i(t) >0$ and the diagonal gain matrix $K(t)$ is monotonically increasing. Consider the time-varying decentralized output feedback $u(t) = K(t) y(t)$.  
% \end{theorem}


% \begin{theorem} \label{theorem:infinite_gain}
% (High gain stabilizability) Consider the uncertain linear system \eqref{eq:system} with unknown system matrices $A$ and/or $B$.  Suppose $B$ is an \textbf{$H$-matrix with   positive diagonal entries}, and each individual gain function $k_i(t)$ in the matrix gain $K(t)$ is a monotonically increasing function approaching infinity as $t \rightarrow \infty$. Then the uncertain linear system \eqref{eq:system} is exponentially convergent to zero. 




% Consider the multivariable MIMO linear system \eqref{eq:linear_system} with a minimum state-space realization $\{A, B, C\}$. Suppose that the system is of minimum phase, and the matrix product $CB$ is diagonal stabilizable. Then the system can be stabilized by decentralized high gains in terms of a diagonal  gain matrix $K = \text{diag}\{k_1, k_2, \cdots, k_n\}$ with $k_i >\bar k, \forall i$, where  $\bar k$ is  a positive constant. 
% \end{theorem}


\begin{theorem} \label{thm:gain_condition}
Suppose the system \eqref{eq:linear_system} with $(A, B, C)$ is of minimum phase and consider a time-varying decentralized output feedback $u(t) = K(t) y(t)$, with time-varying diagonal matrix gain $K(t)$. 
 
Suppose the matrix $CB$ is \textbf{Hurwitz H-matrix}.  Then there exist individual  positive constants $\bar k_i, i = 1,2, \cdots n$ and finite time $\bar t$ such that if the time-varying  scalar gain functions $k_i(t)$ are chosen to satisfy $k_i(t) \geq \bar k_i >0, \forall t \geq \bar t$, the closed-loop system is exponentially convergent  with the decentralized output feedback gain $K(t) = \text{diag}\{k_1(t), k_2(t), \cdots, k_n(t)\}$.  \QEDB
 
\end{theorem}
\begin{proof}
Firstly we follow the system decomposition technique in \cite{kouvaritakis1976geometric, isidori2017stabilization}  to perform a coordinate transform for the multivariable  MIMO linear system \eqref{eq:linear_system} under the minimum-phase condition.  Choose matrices $M \in \mathbb{R}^{n \times (n-m)}, N\in \mathbb{R}^{(n-m)\times n}$, such that 
      \begin{align} \label{eq:matrix_NM}
          NB = 0, CM = 0, N = (M^TM)^{-1}M^T (I_n - B(CB)^{-1}C).
      \end{align}
      Note that $NM = I_{n-m}$. Consider the system coordinate transformation $\bar x = T x$, with the transformation matrix 
      \begin{align}  \label{eq:T}
          T = \left[\begin{array}{c} N \\ C  \end{array} \right], \,\,\,\text{with}\,\,\,T^{-1} = \left[\begin{array}{cc} M, \,\, B(CB)^{-1}  \end{array} \right].
      \end{align}
We obtain the following transformed system matrix 
\begin{align} \label{eq:transform_minimum_phase}
    \bar A_{K(t)} &= T A_{K(t)} T^{-1} \nonumber \\
                  &= T A  T^{-1} + T (BK(t)C)  T^{-1} \nonumber \\
                  & = \left[\begin{array}{cc} NAM & NA B(CB)^{-1} \\ CAM &  CA B(CB)^{-1} \end{array} \right] + \left[\begin{array}{cc} 0 & 0 \\ 0 & CBK(t) \end{array} \right]  \nonumber \\
                  &= \left[\begin{array}{cc} NAM & NA B(CB)^{-1} \\ CAM &  CA B(CB)^{-1} + CBK(t)\end{array} \right]  \nonumber \\
                  & := \left[\begin{array}{cc} \bar A_{11} & \bar A_{12} \\ \bar A_{21} &  \bar A_{22} + CBK(t)\end{array} \right] .
\end{align}
The minimum phase condition implies that the submatrix $\bar A_{11} :=NAM$ (if the system zeros exist) is Hurwitz \cite{kouvaritakis1976geometric, isidori2017stabilization}. 


 According to Theorem~\ref{theorem:_H_matrix} and Proposition~\ref{pro:H_Hurwitz}, with the condition that  $CB$ is a \textit{Hurwitz H-matrix},  there  exists a diagonal matrix $D$, such that $D(CB)D^{-1}$ is Hurwitz and column-diagonal dominant. Note that all diagonal entries of $D(CB)D^{-1}$ are negative. 
    
    Now  consider a block diagonal matrix $\bar D = \text{blk-diag}(I, D)$ with the above chosen diagonal matrix $D$ such that 
\begin{align} \label{eq:transform_D}
    \bar A_{DK(t)} &= \bar D \bar A_{K(t)} \bar D^{-1} \nonumber \\
                  & = \left[\begin{array}{cc} \bar A_{11} & \bar A_{12} D^{-1} \\  D \bar  A_{21} &  D \bar A_{22}D^{-1} + D CBK(t) D^{-1}\end{array} \right] .
\end{align}
where $D CBK(t) D^{-1} = D CB D^{-1} K(t)$ since   $D^{-1}$ and $K(t)$  commute as both are  diagonal matrices. With the above two transformations in \eqref{eq:transform_minimum_phase} and \eqref{eq:transform_D}, we obtain the transformed system states 
\begin{align}
    \bar x = \left[\begin{array}{c} \bar x_1 \\ \bar x_2 \end{array} \right] = \bar D T x
\end{align}
with $ \bar x_1 \in \mathbb{R}^{n-m}$ and $\bar x_2 \in \mathbb{R}^{m}$ corresponding to the sub-states after the coordinate transformation. 
The dynamics of the transformed system are given by 
\begin{subequations}
\begin{align}
    \dot {\bar x}_1 &= \bar A_{11} {\bar x}_1 + \bar A_{12} D^{-1} {\bar x}_2,  \label{eq:bar_x1D} \\
    \dot {\bar x}_2 &= D \bar  A_{21} {\bar x}_1 + \left(D \bar A_{22}D^{-1} + (D CBD^{-1}) K(t) \right) {\bar x}_2, \label{eq:bar_x2D}
\end{align}
\end{subequations}
where we recall that $\bar A_{11}$ is Hurwitz and $D CB D^{-1}$is column-diagonal dominant. To ease notations, we now denote $\tilde  A_{12} :=\bar A_{12} D^{-1}$, $\tilde  A_{21} :=D \bar  A_{21}$, and $\tilde  A_{22, K(t)} :=D \bar A_{22}D^{-1} + (D CBD^{-1}) K(t)$. 

% \begin{align}
%     \dot x &= \tilde A_{11} x + \tilde A_{12}  y \nonumber \\
%     \dot y &=  \tilde  A_{21} x + (\tilde A_{22} + (D CBD^{-1}) K ) y
% \end{align}


The solution to the above sub-system \eqref{eq:bar_x1D} is given in the  form of  
\begin{align} \label{eq:solution_x1}
    {\bar x}_1(t)  = e^{\bar A_{11} t} {\bar x}_1(0) +\int_0^t e^{\bar A_{11} (t-s)} \tilde  A_{12} {\bar x}_2(s) \text{d}  s,
\end{align}
and therefore
\begin{align}
    \dot {\bar x}_2 & = {\left(\tilde  A_{22, K(t)} \right)} {\bar x}_2 \nonumber \\
    & + \tilde  A_{21}  \left( e^{\bar A_{11} t} {\bar x}_1(0) +\int_0^t e^{\bar A_{11} (t-s)} \tilde  A_{12} {\bar x}_2(s) \text{d}  s\right) .
\end{align}
Since $\bar A_{11}$ is Hurwitz, there exist positive constants $M_{11} >0, \beta_{11} >0$ such that \begin{align} \label{eq:A11_EXP}
    \|e^{\bar A_{11} t}\| \leq M_{11} e^{-\beta_{11} t}, M_{11} >0, \beta_{11}>0,\,\,\,\forall t \geq 0.
\end{align}
Let $\mu_1(\tilde  A_{22, K(t)})$ denote the matrix measure of $\tilde  A_{22, K(t)}$ induced by the vector 1-norm. For the evolution of the 1-norm of the solution vector $\bar x_2(t)$, we obtain the following bound inequality of \eqref{eq:y_one_norm} (shown in the next page), where $D^+$ denotes the upper right-hand Dini derivative \cite{khalil1996nonlinear}.
% We consider the evolution of the 1-norm, $\|y(t)\|_1$
% \begin{align}
%     \frac{d \|y(t)\|_1}{dt} &= \text{sign} (y(t))^T \dot y(t) \nonumber \\
%     &= \text{sign} (y(t))^T \bar A_{K(t), 11} +...\nonumber \\
%     &= \mu(\bar A_K) y(t) + 
% \end{align}

% For the first term, we have
% \begin{align}
%     \sum_{i=1}^m \frac{x_{2i}}{|x_{2i}|} \dot x_{2i} &= \sum_{i=1}^m \frac{x_{2i}}{|x_{2i}|} \left( \sum_{i=1}^m  A_{ij} x_{2i} \right) \nonumber \\
%     & = \sum_{i=1}^m \left(\frac{x_{2i}}{|x_{2i}|} A_{ii} x_{2i} +    \sum_{i=1, i \neq j}^m   \frac{x_{2i}}{|x_{2i}|} A_{ij} x_{2i} \right)   \nonumber \\
%     & \leq \sum_{i=1}^m \left(A_{ii} |x_{2i}| +    \sum_{i=1, i \neq j}^m    |A_{ij}| |x_{2i}| \right) \nonumber \\
% \end{align}
% where we have used the equality $\frac{x_{2i}}{|x_{2i}|}   x_{2i} = |x_{2i}|$, and the second inequality is obtained by taking the absolute values of all components in the right-hand side. Furthermore, we have 

% \begin{align}
%     \sum_{i=1}^m \frac{x_{2i}}{|x_{2i}|} \dot x_{2i} &= \sum_{i=1}^m \frac{x_{2i}}{|x_{2i}|} \left( \sum_{i=1}^m  A_{ij} x_{2i} \right) \nonumber \\
%     & \leq \sum_{i=1}^m \left(A_{ii} |x_{2i}| +    \sum_{i=1, i \neq j}^m    |A_{ij}| |x_{2i}| \right) \nonumber \\
%     & \leq  \text{max}_{i =1, 2, \cdots, n} \left(A_{ii}  +    \sum_{i=1, i \neq j}^m    |A_{ij}|  \right)  \sum_{i=1}^m |x_{2i}|  \nonumber \\
%     & = \mu(A_K) \|x_{2}\|_1
% \end{align}
% where $\mu(A_K)$ denotes the matrix measure of $A_K$ induced by the vector 1-norm. 
\begin{figure*}
 
\begin{align} \label{eq:y_one_norm}
    D^+ \|{\bar x}_2(t)\|_1 \leq   \mu_1(\tilde  A_{22, K(t)}) \| {\bar x}_2(t)\|_1 + \|\tilde  A_{21}\| \|{\bar x}_1(0)\|  M_{11} e^{-\beta_{11} t}  
      + M_{11} \|\tilde  A_{21} \| \| \tilde  A_{12}\| \left(\int_0^t e^{-\beta_{11} (t-s)} \||{\bar x}_2(s)\|_1 \text{d} s \right) .
\end{align}
\end{figure*}

 Combining all terms of  \eqref{eq:y_one_norm},  we further consider the following scalar system of $z(t)$ in an integro-differential  form
\begin{align} \label{eq:integro-differential_DH}
    \dot z = & \mu_1\left(\tilde  A_{22, K(t)} \right) z(t) + \|\tilde  A_{21}\| \|{\bar x}_1(0)\|  M_{11} e^{-\beta_{11} t} \nonumber \\
    & + M_{11} \|\tilde  A_{21} \| \| \tilde  A_{12}\| \left(\int_0^t e^{-\beta_{11} (t-s)} z(s) \text{d} s \right) .
\end{align}
The comparison lemma for  integro-differential systems (see e.g.,  \cite[Theorem 1.4.2]{lakshmikantham1995theory}) indicates that $\|\bar x_2(t)\|_1 \leq z(t)$ if $\|\bar x_2(0)\|_1 = z(0) >0$. If $z(t)$ is exponentially convergent, then the evolution of $\|\bar x_2(t)\|_1$ is upper bounded by exponentially convergent function, which in turn implies that the solution $\bar x_2(t)$ is also exponentially convergent by the equivalence of the vector norms.
According to Theorem~\ref{thm:exp_int_diff}, a sufficient condition to ensure the exponential convergence of the solution $z(t)$ is that there exists a finite time $\bar t$, such that 
\begin{align} \label{eq:ex_condition_ide}
     \mu_1\left(\tilde  A_{22, K(t)} \right) &=  \mu_1\left(D \bar A_{22}D^{-1} + (D CBD^{-1}) K \right) \nonumber \\
     &< - \gamma, \,\,\,\,\,\,\,\forall t \geq \bar t, 
    \end{align}
    where
    \begin{align} 
      \gamma = M_{11} \|\tilde  A_{21} \| \| \tilde  A_{12}\| \int_0^\infty e^{-\beta_{11}t} \text{d} s = M_{11} \|\tilde  A_{21} \| \| \tilde  A_{12}\|/\beta_{11}.
\end{align}
We claim that with sufficiently large $k_i$, the above integro-differential \eqref{eq:integro-differential_DH}  system is exponentially stable by meeting the matrix measure condition of \eqref{eq:ex_condition_ide}. 
Again, we recall that the matrix condition of $CB$ being an H-matrix implies that there exists a positive   diagonal matrix $ D = \text{diag}\{ d_1,  d_2, \cdots,  d_n\}$ such that $\tilde B = \{\tilde b_{ij}\} := D CB   D^{-1}$ is  strictly  column-diagonal dominant. 

Note  that the diagonal entries of $D CBD^{-1}$ satisfy $\tilde b_{jj} : = ({D CBD^{-1}})_{jj} = ({CB})_{jj}, \forall j$, which are negative by the condition that $CB$ is a Hurwitz H-matrix; i.e., 
\begin{align}
    \tilde b_{jj} &<0, \,\,\,\,\,\forall j; \nonumber \\
    \tilde b_{jj} + \sum_{i=1, i\neq j}|\tilde b_{ij}| &<0, \,\,\,\,\,\forall j.
\end{align}

Let $\tilde a_{ij}$ denote  the $(ij)$-th entry of the matrix $D \bar A_{22}D^{-1}$. 
Now by choosing $\tilde k_j$ such that  
\begin{align}  \label{eq:key_condition2}
     k_j(t) > \tilde k_j  = \frac{\sum_{i=1, i\neq j}  |\tilde a_{ij}| + \tilde a_{jj}   +\gamma}{-\left(\tilde b_{jj} + \sum_{i=1, i\neq j}|\tilde b_{ij}|\right)}, 
\end{align}
it holds that
\begin{align} \label{eq:diagonal_inequality}
     k_j(t)\tilde b_{jj} + \tilde a_{jj}  + \left(\sum_{i=1, i\neq j}  (  |\tilde a_{ij}| + k_j(t)|\tilde b_{ij}|  )  \right) < - \gamma.
\end{align}

Since all entries of the constant matrices $D CBD^{-1}$ and $\tilde B$ are bounded, all $\tilde k_j, \forall j$ are also bounded.  Choose $\tilde k := \text{max}_j \tilde k_j$ and further let $k_j(t) \geq \tilde k, \forall j, \forall t>\bar t$. Then we obtain the key condition of \eqref{eq:key_condition} (shown in the next page), which is exactly the matrix measure condition in \eqref{eq:ex_condition_ide}. By Theorem~\ref{thm:exp_int_diff}, this proves that the $z$ system \eqref{eq:integro-differential_DH}  converges to zero exponentially fast $\forall t >\bar t$. This in turn implies that the transformed system state $\bar x$ of the linear time-varying system \eqref{eq:bar_x1D} and \eqref{eq:bar_x2D} converges to zero exponentially fast, and so is the original system state $x(t)$ with the convergence scaled by the coordinate transform  $x := (\bar D T)^{-1} \bar x$.  
\begin{figure*}
 
\begin{align} \label{eq:key_condition}
    \text{max}_{j =1, 2, \cdots, n} \left(k_j(t)\tilde b_{jj} + \tilde a_{jj}  + k_j(t)\sum_{i=1, i\neq j}|\tilde b_{ij}| + \sum_{i=1, i\neq j}^n |a_{ij}|\right) < -\gamma.
\end{align}
\end{figure*}



 
      In the case that the system has no zeros (which is equivalent to that the system matrices $B$ and $C$ are   square matrices of full rank), the transformation matrix $T$ can be chosen as $T = C$ and the transformed system matrix  \eqref{eq:transform_minimum_phase} simplifies to 
      \begin{align} \label{eq:transform_simplied}
          \bar A_K &= T A_K T^{-1}  =  C A  C^{-1} + C (BKC)  C^{-1} \nonumber \\
                  & = CA C^{-1}  + CBK  .
      \end{align}
In this case, the above proof can be further simplified by only considering the exponential convergence of the transformed system $\dot {\bar x}_2  =  \left(D \bar A_{22}D^{-1} + (D CBD^{-1}) K(t) \right) {\bar x}_2  $ while  the remaining steps of the proof remain the same. This completes the proof of the theorem. 
 
\end{proof}

\begin{remark} Some remarks of  Theorem~\ref{thm:gain_condition} are in order. 
\begin{itemize}
    \item In   decentralized control of multivariable linear systems, a well-known result on the necessary and sufficient condition for stabilizability (the  existence of a set of local feedback control laws) is that the set of fixed modes (if they exist)  of the system   are stable, i.e., they are located in the open left half plane (see \cite{wang1973stabilization, anderson1981algebraic, liu2019overcoming}). The minimum phase condition (i.e., all system zeros are located in the open left half plane) in Theorem~\ref{thm:gain_condition} follows essentially   the stable fixed-mode condition in decentralized control with memoryless output feedback. 
    \item The proof of Theorem~\ref{thm:gain_condition} also presents a feasible way to find a diagonal gain matrix  $K(t)$  for decentralized stabilization, which is presented in \eqref{eq:key_condition2}. Note the diagonal gain matrix that satisfies \eqref{eq:key_condition2} can also be a constant matrix. 
    \item The H-matrix condition for the product $CB$ resembles a similar key matrix condition of the distributed adaptive stabilization design in \cite{sun2021distributed}, which enables an adaptive gain tuning approach to adaptively update  a suitable diagonal gain matrix  $K(t)$ (e.g., a distributed high-gain control method). This also suggests an alternative solution based on the distributed adaptive again updating method to solve the Brockett stabilization problem, even when the system matrices $A$ and $CB$ are unknown.   \QEDB
\end{itemize}    
 \end{remark}

% \begin{remark}
% The distinct features of uniform scaling and decentralized scaling... 

% \begin{enumerate}
%     \item Uniform scaling;
%     \item Individual scaling. 
% \end{enumerate}
% \end{remark}
% \begin{remark}  \label{remark:for_theorem2}
% Some remarks of Theorem~\ref{theorem:infinite_gain} are in order. 
% \begin{itemize}
%     \item The condition $k_i(t) \rightarrow \infty$ as $t \rightarrow \infty$ is not really used in the proof.   So long as the condition in \eqref{eq:diagonal_inequality_row} is satisfied that guarantees $k_i(t) \geq \bar k, \forall i, \forall t>\bar t$, the linear system \eqref{eq:z_system_row_dd} is exponentially convergent with a rate $e^{-\delta (t - \bar t)}$, $\forall t >\bar t$. Nevertheless,  we follow the same spirit of scalar high-gain stabilizability (\cite[Theorem 3.5]{maartensson1986adaptive} and \cite[Proposition 2.1]{ilchmann1987high}) to state the matrix high-gain stabilizability in Theorem~\ref{theorem:infinite_gain}. 
%     \item  With the condition  $k_i(t) \rightarrow \infty$ as $t \rightarrow \infty$, one can claim a stronger result termed   \textit{arbitrarily fast exponential convergence} \cite{ilchmann1987high}; i.e., the exponential rate $\delta(t)$ is a monotonically increasing function of the time $\forall t> \bar t$, and $\delta(t) \rightarrow \infty$ as $t \rightarrow \infty$. This is also evident   by   Lemma~\ref{lemma:row_dd_system}. 
%     \item The sufficient condition for the uncertain system \eqref{eq:system} being matrix high-gain stabilizable is that, {\color{blue} with a sufficiently large diagonal matrix gain $K(t)$, the system \eqref{eq:system} should become a generalized  diagonally row dominant  system at some finite time $\bar t$ and will remain it $\forall t>\bar t$ so as to ensure the exponential stability of the system states. } Note that the exponential rate also grows with the growing $k_i(t)$, for $t> \bar t$.
%     %\item Matrix high-gain stabilizability requires stronger conditions on the matrix $B$. The set of  H-matrix is a subset of the Hurwitz matrix. Necessary and sufficient condition: 
% \end{itemize}
% \end{remark}

% \begin{corollary} \label{theorem:infinite_gain}
% (High gain stabilizability) Consider the uncertain linear system \eqref{eq:system} with unknown system matrices $A$ and/or $B$.  Suppose $B$ is an \textbf{$H$-matrix with   positive diagonal entries}, and each individual gain function $k_i(t)$ in the matrix gain $K(t)$ is a monotonically increasing function approaching infinity as $t \rightarrow \infty$. Then the uncertain linear system \eqref{eq:system} is exponentially convergent to zero. 
% \end{corollary}




 
 
 

 
 
 

 %\section{Examples and simulations}
 
% Now we consider the following system
% \begin{align}
%     \bar A_K &= T A_K T^{-1} \nonumber \\
%                   &= T A  T^{-1} + T (BKC)  T^{-1} \nonumber \\
%                   & = \left[\begin{array}{cc} NAM & NA B(CB)^{-1} \\ CAM &  CA B(CB)^{-1} \end{array} \right] + \left[\begin{array}{cc} 0 & 0 \\ 0 & CBK \end{array} \right]  \nonumber \\
%                   &= \left[\begin{array}{cc} NAM & NA B(CB)^{-1} \\ CAM &  CA B(CB)^{-1} + CBK\end{array} \right]  \nonumber \\
%                   & = \left[\begin{array}{cc} \bar A_{11} & \bar A_{12} \\ \bar A_{21} &  \bar A_{22} + CBK\end{array} \right] 
% \end{align}
% There there exists a matrix $\bar D = \text{blk-diag}(I, D)$ such that 
% \begin{align}
%     \bar A_{DK} &= \bar D \bar A_K \bar D^{-1} \nonumber \\
%                   & = \left[\begin{array}{cc} \bar A_{11} & \bar A_{12} D^{-1} \\  D \bar  A_{21} &  D \bar A_{22}D^{-1} + D CBK D^{-1}\end{array} \right] 
% \end{align}
% where $D CBK D^{-1} = D CB D^{-1} K$ and $D CB D^{-1}$is diagonal dominant. 
% with the system
% \begin{align}
%     \dot x &= \bar A_{11} x + \bar A_{12} D^{-1} y \nonumber \\
%     \dot y &= D \bar  A_{21} x + (D \bar A_{22}D^{-1} + (D CBD^{-1}) K ) y
% \end{align}
% where $\bar A_{11}$ is Hurwitz and $D CB D^{-1}$is diagonal dominant. Since $\bar A_{11}$ is Hurwitz, there exist positive constant $M, \epsilon$ such that
% \begin{align}
%     \|e^{\bar A_{11} t}\| \leq M e^{-\epsilon t}, \,\,\,\forall t \geq 0
% \end{align}

% \begin{align}
%     \dot x &= \tilde A_{11} x + \tilde A_{12}  y \nonumber \\
%     \dot y &=  \tilde  A_{21} x + (\tilde A_{22} + (D CBD^{-1}) K ) y
% \end{align}
% We claim that with sufficiently large $k_i$, the above system is exponentially stable. 

% The solution to the above system is writen as 
% \begin{align}
%     \dot y  = (D \bar A_{22}D^{-1} + (D CBD^{-1}) K ) y + D \bar  A_{21}  \left( e^{\bar A_{11} t} x(0) +\int_0^t e^{\bar A_{11} (t-s)} \tilde  A_{21} y(s) \text{d}  s\right) 
% \end{align}

% We consider the evolution of the 1-norm, $\|y(t)\|_1$
% \begin{align}
%     \frac{d \|y(t)\|_1}{dt} &= \text{sign} (y(t))^T \dot y(t) \nonumber \\
%     &= \text{sign} (y(t))^T \bar A_{K(t), 11} +...\nonumber \\
%     &= \mu(\bar A_K) y(t) + 
% \end{align}

% For the first term, we have
% \begin{align}
%     \sum_{i=1}^m \frac{x_{2i}}{|x_{2i}|} \dot x_{2i} &= \sum_{i=1}^m \frac{x_{2i}}{|x_{2i}|} \left( \sum_{i=1}^m  A_{ij} x_{2i} \right) \nonumber \\
%     & = \sum_{i=1}^m \left(\frac{x_{2i}}{|x_{2i}|} A_{ii} x_{2i} +    \sum_{i=1, i \neq j}^m   \frac{x_{2i}}{|x_{2i}|} A_{ij} x_{2i} \right)   \nonumber \\
%     & \leq \sum_{i=1}^m \left(A_{ii} |x_{2i}| +    \sum_{i=1, i \neq j}^m    |A_{ij}| |x_{2i}| \right) \nonumber \\
% \end{align}
% where we have used the equality $\frac{x_{2i}}{|x_{2i}|}   x_{2i} = |x_{2i}|$, and the second inequality is obtained by taking the absolute values of all components in the right-hand side. Furthermore, we have 

% \begin{align}
%     \sum_{i=1}^m \frac{x_{2i}}{|x_{2i}|} \dot x_{2i} &= \sum_{i=1}^m \frac{x_{2i}}{|x_{2i}|} \left( \sum_{i=1}^m  A_{ij} x_{2i} \right) \nonumber \\
%     & \leq \sum_{i=1}^m \left(A_{ii} |x_{2i}| +    \sum_{i=1, i \neq j}^m    |A_{ij}| |x_{2i}| \right) \nonumber \\
%     & \leq  \text{max}_{i =1, 2, \cdots, n} \left(A_{ii}  +    \sum_{i=1, i \neq j}^m    |A_{ij}|  \right)  \sum_{i=1}^m |x_{2i}|  \nonumber \\
%     & = \mu(A_K) \|x_{2}\|_1
% \end{align}
% where $\mu(A_K)$ denotes the matrix measure of $A_K$ induced by the vector 1-norm. 


% Therefore, we have 
% \begin{align}
%     D^+ \|y(t)\|_1 \leq \mu(A_K) \|x_{2}\|_1 + M_1 e^{-\epsilon t} \zeta + M_2 \left(\int_0^t e^{-\epsilon (t-s)} z(s) \text{d} s \right) 
% \end{align}
% Combining all terms of (??),  we consider the following scalar system
% \begin{align}
%     \dot z = \mu(\bar A_K(t)) z(t) + M_1 e^{-\epsilon t} \zeta + M_2 \left(\int_0^t e^{-\epsilon (t-s)} z(s) \text{d} s \right) 
% \end{align}
% which converges to zero exponentially fast. 

% Then there exists a positive time, and a scalar such that the following condition is satisfied
% \begin{align}
%   \int_0^t |c(u, t)| \text{d}u+  \int_t^\infty |c(u, t)| \text{d}u - 2|a(t)| \leq -\alpha
% \end{align}
% The condition is simplified as
% \begin{align}
%     -\mu(\bar A_K(t))  \geq \int_{0}^\infty
% \end{align}
 

\section{Discussions and comparisons with other solutions}  \label{sec:discussion}

%\subsection{Mtrix diagonal conditions and their relations}
\subsection{The Brockett stabilization problem with unstructured time-varying $K(t)$} 
In \cite{brockett1999stabilization} Brockett also proposed the following  stabilization problem
\begin{itemize}
    \item ``Given a triple constant matrices $(A, B, C)$ under what circumstances does there exist a time-dependent matrix $K(t)$ such that the system
    \begin{align}
        \dot x(t) = Ax +BK(t)Cx
    \end{align}
    is   asymptotically stable?"
\end{itemize}

In the general case where there is no structural constraints on $K(t)$, the problem still remains open though   some partial solutions (in terms of either necessary or sufficient conditions) are available. In the below, we review some matrix conditions and control design solutions reported in the literature, and compare them with the solution proposed in this paper. 

\subsection{Scalar/matrix gain conditions and time-varying stabilization solutions in the literature}
A common attempt to solve the Brockett stabilization problem with a time-varying gain matrix is to employ periodic scalar gains. For example, the paper \cite{moreau2000note} suggested the following periodic gain function
\begin{align}
    k(t) = k_1 + k_2 \omega \text{sin}(\omega t),  \omega  \gg 1
\end{align}
for a  single-input  single-output (SISO) second-order system, and a similar periodic gain function
\begin{align}
    k(t) = k_1 + k_2 \omega^2 \text{sin}(\omega t),  \omega  \gg 1
\end{align}
for a  third-order system. These methods are based on averaging theory and time-varying coordinates transformation, while the structured gain matrix $K(t)$ was not considered. 

Furthermore,  the paper  \cite{allwright2005note} presented a first step toward the solution of the general Brockett problem  based on periodic and piecewise constant output feedback, while the scalar gain matrix $k(t)$ is designed to switch between two constants. The proposed condition 
for asymptotic  stabilization with periodic output feedback in \cite{allwright2005note} involves the checking of  all eigenvalues of a matrix exponential of state matrices. A modified condition is also proposed in \cite{allwright2005note}  that involves a bilinear matrix inequality. A comprehensive study of non-stationary stabilization of controllable linear systems with periodic control gains is reported in \cite{leonov2010stabilization}.   We note that these conditions, which are limited to SISO systems or lower-order systems,  may also be hard to verify and compute in practice. 

In the general setting of linear MIMO systems with output feedback and time-varying matrix gains, the paper \cite{boikov2005brockett} proposed several matrix conditions involving logarithmic norms and Hurwitz matrix property. One such condition is summarized as below:
\begin{enumerate} 
    \item The time-varying matrix $Q(t) : =A +BK(t)C$ is Hurwitz and diagonal dominant; and
    \item The matrices $B$ and $C$ are square and inevitable.
\end{enumerate}
Then a simple yet trivial result follows for the time-varying gain $K(t)$   as 
\begin{align}\label{eq:strong_condition}
    K(t) =  B^{-1} (Q(t) -A) C^{-1}. 
\end{align}  
These matrix conditions are very strong and restrictive, though they are simply to verify in practice. The trivial solution of \eqref{eq:strong_condition} under the strong matrix conditions still does not consider the structured constraint on $K(t)$, and it does not guarantee  that the obtained gain matrix $K(t)$ is diagonal (or block diagonal) either. 

% A more general problem with structured constraints on $K(t)$ was also suggested in \cite{brockett1999stabilization}:
% \begin{itemize}
%     \item ``Given  a family of constant matrices 
%     \begin{align}
%         (A, B_1, B_2, \cdots B_r, C_1, C_2,\cdots, C_r)
%     \end{align}
%     under what circumstances do there exist time-dependent matrices $$K_1(t),K_2(t),\cdots, K_r(t)$$ such that the system
%     \begin{align}
%         \dot x(t) = Ax(t) +\sum_{i=1}^r B_i K_i(t) C_i x 
%     \end{align}
%     is   asymptotically stable?"
% \end{itemize}


%  We recall the following lemma, firstly proved in [xxx]. 
 
%  \begin{proof}
%  Consider The transformed closed-loop linear system is described by $ \dot {\bar x} = T A_K T^{-1} \bar x : = \bar A_K \bar x$, with
%       \begin{align}
%           \bar A_K &= T A_K T^{-1} \nonumber \\
%                   &= T A  T^{-1} + T (-BKC)  T^{-1} \nonumber \\
%                   & = \left[\begin{array}{cc} NAM & NA B(CB)^{-1} \\ CAM &  CA B(CB)^{-1} \end{array} \right] + \left[\begin{array}{cc} 0 & 0 \\ 0 & CBK \end{array} \right]  \nonumber \\
%                   &= \left[\begin{array}{cc} NAM & NA B(CB)^{-1} \\ CAM &  CA B(CB)^{-1} + CBK\end{array} \right]  
%       \end{align}
%       Now we prove that with large enough diagonal $K$ and the H-matrix $CB$, the matrix 
      
%  \end{proof}

 A more recent review on the stabilization problem and available solutions is presented in \cite{shumafov2019stabilization}. Compared to these available design solutions in  \cite{moreau2000note, allwright2005note, boikov2005brockett}  and more recent solutions reviewed in \cite{shumafov2019stabilization}, this paper presents the first step with simple-to-verify matrix conditions that solve the Brockett stabilization problem with structured time-dependent gain matrix $K(t) = \text{diag}(k_i(t))$ in a diagonal form. 
 
 
\section{conclusion}  \label{sec:conclusion}
In this paper we revisit the Brockett stabilization problem proposed in \cite{brockett1999stabilization}, under a structured condition that the time-varying gain matrix $K(t)$ is a diagonal matrix. This structural stabilization problem has remained open in the literature, while in this paper we present a critical matrix condition to solve this stabilization problem. The key condition is that the system matrix product $CB$ is a Hurwitz H-matrix, which guarantees the existence of a time-varying diagonal gain matrix $K(t)$ such that the closed-loop  minimum-phase linear system with decentralized output feedback is exponentially stable. The proof of the main result involves a close interplay of several analysis tools including the properties of special matrices such as H-matrix, the matrix measure and convergence conditions of diagonal-dominant linear systems, and solution bounds of linear time-varying integro-differential systems. 

The main result can be generalized to the more general structural setting that the output feedback gain matrix $K(t)$ is a  time-varying  \textit{block-diagonal} matrix. In addition,  the H-matrix condition for the product $CB$ also suggests an adaptive control solution (which follows the distributed adaptive stabilization design in \cite{sun2021distributed}) to solve the Brockett stabilization problem with unknown system matrices. These results will be reported in a future paper. 

\bibliography{Brockett_problem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{IEEEtran}
 

\end{document}