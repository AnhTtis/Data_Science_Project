\section{Methodology}


We now describe the proposed SIO as a two-step procedure, including several technical details.
See Figure \ref{fig:method} for an overview.



\subsection{Generating synthetic ID training set $\Dins$}
\label{sec:3.1}


Given the real ID training set $\Dinr$, we train a generative model to capture the ID data distribution, which can then be used to generate a large number of synthetic ID images by sampling from the synthetic distribution $\Dins$.
The training step can be skipped if pre-trained generative models are available. For instance, we utilize off-the-shelf generative models that are pre-trained on standard ID datasets (\eg, CIFAR-10) in most of our experiments.
It is worth noting that a generator trained on a different (potentially larger) dataset can also be used, as long as it knows the concept of ID categories (\eg, an ImageNet generator can be employed for a Tiny ImageNet classifier).



The way the labels of synthetic samples are obtained can vary depending on the case. 
If the real ID dataset $\Dinr$ has labels (which is typically the case), the generative model can be trained in a class-conditional way, and we can directly sample labeled synthetic data $(\tilde{\bm{x}},\tilde{y})\sim\Dins$. 
If $\Dinr$ is unlabeled (\eg, in a self-supervised setting) or the generative model is unconditional, we can only sample unlabeled synthetic data $\tilde{\bm{x}}\sim\Dins$. 
In this case, we use a classifier $f$ pre-trained on the real data to produce pseudo-labels, i.e., $\tilde{y}=\argmax_if(\tilde{\bm{x}})_i$. 
By default, we assume that the generative model is conditional unless otherwise stated.


In this work, we consider the generation step as offline, meaning that we pre-generate a fixed number of synthetic images.
Therefore, it does not add any complexity to the online training step. 
However, if there are sufficient computing resources, synthetic samples can certainly be generated on the fly. In fact, our experiments indicate that more synthetic samples generally lead to better performance.



\input{tables/cifar_results_resnet18}



\subsection{Training with real and synthetic ID samples}
\label{sec:3.2}

Subtle differences or shifts can exist between the synthetic and real distributions \cite{cas}.
To avoid bias towards the synthetic distribution, we train the model using real and synthetic data together.
Concretely, we design a weighted objective, which is essential for obtaining superior performance as shown in later experiments:
\begin{multline}
    \min_f\left[\alpha\cdot\mathbb{E}_{(\bm{x},y)\sim \Dinr}L(\bm{x},y;f)+\right.\\ \left. \quad \quad (1-\alpha)\cdot\mathbb{E}_{(\tilde{\bm{x}},\tilde{y})\sim \Dins}L(\tilde{\bm{x}},\tilde{y};f)\right],
\label{eq:SIO_id_only_training}
\end{multline}
where $\alpha\in[0,1]$ is the weighting term.
Note that, similarly to Equation \ref{eq:id_only_training}, $L$ could be any specific loss function of existing OOD training algorithms.
SIO can also be seamlessly integrated with methods that incorporate OOD samples during the training (Equation \ref{eq:id_ood_training}).
In such cases, the objective is:
\begin{multline}
    \min_f\left[\alpha\cdot\mathbb{E}_{(\bm{x},y)\sim \Dinr,\hat{\bm{x}}\sim\Dout}L(\bm{x},y,\hat{\bm{x}};f)+\right.\\ \left. \quad \quad (1-\alpha)\cdot\mathbb{E}_{(\tilde{\bm{x}},\tilde{y})\sim \Dins,\hat{\bm{x}}\sim\Dout}L(\tilde{\bm{x}},\tilde{y},\hat{\bm{x}};f)\right].
\label{eq:SIO_id_ood_training}
\end{multline}



In practice, SIO is implemented in an equivalent but much more efficient way than its basic form in Equation \ref{eq:SIO_id_only_training} and \ref{eq:SIO_id_ood_training}.
Instead of performing two separate forward passes and computing the weighted loss, we do the weighting inside each mini-batch by replacing a certain amount of real ID samples with synthetic ones such that the ratio between real and synthetic ID samples is $\alpha:1-\alpha$ within each batch (see Figure \ref{fig:method}).
Such implementation avoids additional computation overhead and allows fair comparison to real data-only training since each model is trained under the exact same budget.
