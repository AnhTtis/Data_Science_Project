







In recent years, denoising diffusion models~\cite{sohl2015nonequ,ho2020ddpm,2021Scoresde,nichol2021iddpm} have emerged as a promising new class of deep generative models due to their remarkable ability to model complicated distributions. Compared to prior Generative Adversarial Networks (GANs), diffusion models have demonstrated superior performance across a range of generation tasks in various modalities, including text-to-image generation~\cite{ramesh2022dalle2,saharia2022imagen,rombach2022ldm,gu2022vqdiffusion}, image manipulation~\cite{kim2021diffusionclip,meng2021sdedit,brooks2022instructpix2pix,yang2022paint}, video synthesis~\cite{Ho2022imagenvideo,Singer2022makeavideo,ho2022video}, text generation~\cite{li2022diffusion-lm,gongsequence,zhu2022exploring}, 3D avatar synthesis~\cite{poole2022dreamfusion,wang2022rodin}, etc.
A key limitation of present denoising diffusion models is their slow convergence rate, requiring substantial amounts of GPU hours for training~\cite{rombach2022ldm,ramesh2022hierarchical}. This constitutes a considerable challenge for researchers seeking to effectively experiment with these models.

 In this paper, we first conducted a thorough examination of this issue, revealing that the slow convergence rate likely arises from conflicting optimization directions for different timesteps during training. In fact, we find that by dedicatedly optimizing the denoising function for a specific noise level can even harm the reconstruction performance for other noise levels, as shown in Figure~\ref{fig:ft-loss-curve}. This indicates that the optimal weight gradients for different noise levels are in conflict with one another. Given that current denoising diffusion models~\cite{ho2020ddpm,dhariwal2021adm,nichol2021iddpm,rombach2022ldm} employ shared model weights for various noise levels, the conflicting weight gradients will impede the overall convergence rate, if without careful consideration on the balance of these noise timesteps.
 



\begin{figure}[t]
\begin{center}
\vspace{-0.1cm}
    \includegraphics[width=0.47\textwidth]{figs/teaser.pdf}
\end{center}
\vspace{-0.7cm}
   \caption{By leveraging a non-conflicting weighting strategy, our method can converge 3.4 times faster than baseline, resulting in superior performance.}
\label{fig:teaser}
\end{figure}





To tackle this problem, we propose the \textbf{Min-SNR-$\gamma$} loss weighting strategy. This strategy treats the denoising process of each timestep as an individual task, thus diffusion training can be considered as a multi-task learning problem. To balance various tasks, we assign loss weights for each task according to their difficulty. Specifically, we adopt a clamped signal-to-noise ratio (SNR) as loss weight to alleviate the conflicting gradients issue. By organizing various timesteps using this new weighting strategy, the diffusion training process can converge much faster than previous approaches, as illustrated in Figure~\ref{fig:teaser}.



Generic multi-task learning methods usually seek to mitigate conflicts between tasks by adjusting the loss weight of each task based on their gradients. One classical approach~\cite{desideri2012mgda,sener2018mto}, Pareto optimization, aims to seek a gradient descent direction to improve all the tasks. However, these approaches differ from our Min-SNR-$\gamma$ weighting strategy in three aspects: 1) \textbf{Sparsity}. Most previous studies in the generic multi-task learning field have focused on scenarios with a small number of tasks, which differs from the diffusion training where the number of tasks can be up to thousands. As in our experiments, Pareto optimal solutions in diffusion training tend to set loss weights of most timesteps as 0. In this way, many timesteps will be left without any learning, and thus harm the entire denoising process. 2) \textbf{Instability}. The gradients computed for each timestep in each iteration are often noisy, owing to a limited number of samples for each timestep. This hampers the accurate computation of Pareto optimal solutions. 3) \textbf{Inefficiency}. The calculation of Pareto optimal solutions is time-consuming, significantly slowing down the overall training.



Our proposed Min-SNR-$\gamma$ strategy is a predefined global step-wise loss weighting setting, instead of run-time adaptive loss weights for each iteration as in the original Pareto optimization, thus avoiding the sparsity issue. Moreover, the global loss weighting strategy eliminates the need for noisy computation of gradients and the time-consuming Pareto optimization process, making it more efficient and stable. Though suboptimal, the global strategy can be also almost as effective: Firstly, the optimization dynamics of each denoising task are largely shaped by the task's noise level, without the need to account for individual samples too much. Secondly, after a moderate number of iterations, the gradients of the majority subsequent training process become more stable, thus it can be approximated by a stationery weighting strategy.

To validate the effectiveness of the Min-SNR-$\gamma$ weighting strategy, we first compute its Pareto objective value and compare it with the optimal step-wise loss weights obtained by directly solving the Pareto problem. Together, we also compare it with several conventional loss weighting strategies, including constant weighting, SNR weighting, and SNR with an lower bound. Figure~\ref{fig:object-value} shows that our Min-SNR-$\gamma$ weighting strategy produces Pareto objective values almost as low as the optimal one, significantly better than other existing works, indicating a significant alleviation of the gradient conflicting issue. As a result, the proposed weighting strategy not only converges much faster than previous approaches, but is also effective and general for various generation scenarios. It achieves a new record of FID score 2.06 on the ImageNet 256$\times$256 benchmark, and proves to also improve models using other prediction targets and network architectures.




Our contributions are summarized as follows:
\begin{itemize}
    \item We have uncovered a compelling explanation for the slow convergence issue in diffusion training: a conflict in gradients across various timesteps.
    \item %
    We have proposed a new loss weighting strategy for diffusion model training, which greatly mitigates the conflicting gradients across timesteps and results in a marked acceleration of convergence speed.
    \item We have established a new FID score record on the ImageNet $256\times 256$ image generation benchmark.
\end{itemize}
