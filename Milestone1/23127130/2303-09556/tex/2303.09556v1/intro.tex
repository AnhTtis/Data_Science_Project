% ------------------- v0 -------------------
% Diffusion models have achieved great success ...

% % Training diffusion models consume a lot of compute resources. Efficiency ... 

% Diffusion process contains thousands of denoising steps which have varying degrees of difficulty. 
% Most methods share weights across different steps,...
% ERNIE-ViLG 2.0~\cite{feng2022ernie2} adopts experts to handle different timesteps ... Ediff-I~\cite{balaji2022eDiff-I} designs xxx 

% The optimization process of diffusion models can be viewed as multi-task learning.
% Optimizing on specific range of timestamps may help perform well on ... but ... Our goal is to make loss relative low at ..., which is also referred as Pareto optimality. Naive method to achieve Pareto optimality.
% However, there are drawbacks of above naive methods.
% ...

% To ease the xxx.
% Loss weight design is seldom explored ...
% Ho et al.~\cite{ho2020ddpm} found that a simple loss function performs better than optimizing the variational lower bound.
% Progressive Distillation~\cite{salimans2022distillprogressive} ...
% We find a fixed strategy works well. Achieve great results on ...

% 1. Diffusion models have made great success
% 2. Decomposing a complex problem into multiple sub-problems[]. Considering the large number of tasks, share weright. limits the model capacity. Previous works[], however.
% 3. In this paper, we formulate the diffusion models from a multi-task learning perspective. First, we explore the relations among different tasks. Specifically,...
% 4. previous work[] finds a well-designed loss weighting strategy based on gradient may achive a Pareto optimal state. However, .... Instead, ... (Maybe expand, more details for these two parts)
% 5. Our solution are general, ... faster convergence and better results. Experiments ...
% 6. Contribution.


%Denoising diffusion models~\cite{ho2020ddpm,2021Scoresde,nichol2021iddpm} have emerged as a new family of deep generative models in recent years for their unique ability to model complex distributions. Compared with the previous Generative Adversarial Networks (GANs), diffusion models have shown superior performance in multiple generation tasks in various modalities, such as text to image generation~\cite{ramesh2022dalle2,saharia2022imagen,rombach2022ldm,gu2022vqdiffusion}, image manipulation~\cite{kim2021diffusionclip,meng2021sdedit,brooks2022instructpix2pix}, video synthesis~\cite{Ho2022imagenvideo,Singer2022makeavideo}, text generation~\cite{li2022diffusion-lm,gongsequence,zhu2022exploring}, and even 3D avatar synthesis~\cite{wang2022rodin}.

In recent years, denoising diffusion models~\cite{sohl2015nonequ,ho2020ddpm,2021Scoresde,nichol2021iddpm} have emerged as a promising new class of deep generative models due to their remarkable ability to model complicated distributions. Compared to prior Generative Adversarial Networks (GANs), diffusion models have demonstrated superior performance across a range of generation tasks in various modalities, including text-to-image generation~\cite{ramesh2022dalle2,saharia2022imagen,rombach2022ldm,gu2022vqdiffusion}, image manipulation~\cite{kim2021diffusionclip,meng2021sdedit,brooks2022instructpix2pix,yang2022paint}, video synthesis~\cite{Ho2022imagenvideo,Singer2022makeavideo,ho2022video}, text generation~\cite{li2022diffusion-lm,gongsequence,zhu2022exploring}, 3D avatar synthesis~\cite{poole2022dreamfusion,wang2022rodin}, etc.
A key limitation of present denoising diffusion models is their slow convergence rate, requiring substantial amounts of GPU hours for training~\cite{rombach2022ldm,ramesh2022hierarchical}. This constitutes a considerable challenge for researchers seeking to effectively experiment with these models.

%One of the major challenges for current diffusion models is their slow convergence rate, which can take thousands of GPU hours for training~\cite{rombach2022ldm,ramesh2022hierarchical}. This presents a high bar for researchers to work with diffusion models effectively. In this paper, we carefully analyze this issue and uncover that it may stem from the conflicting optimization directions at different timesteps. Specifically, most previous studies ~\cite{ho2020ddpm,dhariwal2021adm,nichol2021iddpm,rombach2022ldm} have employed shared-weight models to tackle varying noise levels. However, the differing requirements from various noise levels result in conflicting backpropagated gradients, making it challenging to achieve convergence.
 In this paper, we first conducted a thorough examination of this issue, revealing that the slow convergence rate likely arises from conflicting optimization directions for different timesteps during training. In fact, we find that by dedicatedly optimizing the denoising function for a specific noise level can even harm the reconstruction performance for other noise levels, as shown in Figure~\ref{fig:ft-loss-curve}. This indicates that the optimal weight gradients for different noise levels are in conflict with one another. Given that current denoising diffusion models~\cite{ho2020ddpm,dhariwal2021adm,nichol2021iddpm,rombach2022ldm} employ shared model weights for various noise levels, the conflicting weight gradients will impede the overall convergence rate, if without careful consideration on the balance of these noise timesteps.
 
 %and the varying denoising requirements of different noise levels result in conflicting weight gradients, hampering the convergence rate.


% The key factor for the success of diffusion models is to decompose a complex task into multiple simpler subtasks. Specifically, the diffusion process gradually adds noise to corrupt the image, while the denoising process attempts to denoise the corrupted image at various noise levels. Given the large number of subtasks, and the fact that all of these subtasks focus on image denoising, most previous studies~\cite{ho2020ddpm,dhariwal2021adm,nichol2021iddpm,rombach2022ldm} have leveraged shared-weight models to handle different noise levels. However, this may limit the model capacity, and constantly switching parameters for different tasks may impede the convergence~\cite{nakamura2022leveraging}. As an alternative, some studies~\cite{feng2022ernie2,balaji2022eDiff-I} adopted Mixture of Experts (MoE) to handle noise from different levels. These approaches, however, requires significantly more parameters and longer training time compared to shared-weight models.

\begin{figure}[t]
\begin{center}
\vspace{-0.1cm}
% \fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
    \includegraphics[width=0.47\textwidth]{figs/teaser.pdf}
\end{center}
\vspace{-0.7cm}
   \caption{By leveraging a non-conflicting weighting strategy, our method can converge 3.4 times faster than baseline, resulting in superior performance.}
\label{fig:teaser}
\end{figure}

%As illustrated in Figure~\ref{fig:teaser}, our method can successfully balance different tasks, convergences significantly faster than previous approaches, and achieves better performance. Additionally, the strategy is general and can be easily applied to a variety of network backbones and generation tasks. Our experiments validate the effectiveness of this strategy and establish a new record of FID score on the ImageNet $256\times 256$ synthesis.

%In this paper, we propose a simple yet effective loss weight strategy to avoid the aforementioned issues. We call it the Min-SNR-$\gamma$ strategy. On the one hand, it avoids the large computation cost of iterative optimization. On the other hand, it considers the relationship among different timesteps and does not neglect any of them. As illustrated in Figure~\ref{fig:teaser}, our method can successfully balance different tasks, convergences significantly faster than previous approaches, and achieves better performance. Additionally, the strategy is general and can be easily applied to a variety of network backbones and generation tasks. Our experiments validate the effectiveness of this strategy and establish a new record of FID score on the ImageNet $256\times 256$ synthesis.

%In this paper, we formulate the diffusion training process from a multi-task learning perspective. Specifically, we treat each denoising timestep as a separate task, and investigate the relationships among different tasks. By conducting a thorough analysis, we discover that tasks with similar noise intensities have strong similarities, while tasks with far apart noise intensities have little correlation and may even conflict with each other. As a result, it is critical to find a way for various tasks to work together effectively, instead of hindering or canceling each other out.

%Previous studies~\cite{desideri2012mgda,sener2018mto} have found that by carefully adjusting the weights according to the gradients from different tasks, we can achieve a Pareto optimal solution, which decreases all the training loss functions simultaneously (excluding the trivial solutions). Considering the diffusion models generate images through all timesteps, we involve a regularization term to ensure none of the timesteps will be ignored. However, applying this weighting strategy to the diffusion training process still has two major challenges. Firstly, it necessitates additional optimization at each training iteration, significantly slowing down the training time. Secondly, using a limited number of samples to calculate the gradients could lead to instability in the optimized weights, making the entire diffusion training process less efficient.

To tackle this problem, we propose the \textbf{Min-SNR-$\gamma$} loss weighting strategy. This strategy treats the denoising process of each timestep as an individual task, thus diffusion training can be considered as a multi-task learning problem. To balance various tasks, we assign loss weights for each task according to their difficulty. Specifically, we adopt a clamped signal-to-noise ratio (SNR) as loss weight to alleviate the conflicting gradients issue. By organizing various timesteps using this new weighting strategy, the diffusion training process can converge much faster than previous approaches, as illustrated in Figure~\ref{fig:teaser}.

% To address this problem, we propose the \textbf{Min-SNR-$\gamma$} loss weighting strategy. It uses different loss weights for different noise levels to alleviate the conflicting gradients issue. Specifically, for each timestep, we adopt a clamped signal-to-noise ratio (SNR) as its loss weight. By organizing various timesteps using this new weighting strategy, the diffusion training process can converge much faster than previous approaches, as illustrated in Figure~\ref{fig:teaser}.

% Our approach is inspired by the field of genetic multi-task learning. In fact, by treating the denoising process of each timestep in diffusion training as an individual task, we can consider diffusion training as a multi-task learning problem. In generic multi-task learning, the methods usually seek to mitigate conflicts between tasks by adjusting the loss weight of each task based on their gradients. One classical approach~\cite{desideri2012mgda,sener2018mto}, Pareto optimization, seeks either a descent direction to improve all tasks or is set 0 to not harm any tasks.

Generic multi-task learning methods usually seek to mitigate conflicts between tasks by adjusting the loss weight of each task based on their gradients. One classical approach~\cite{desideri2012mgda,sener2018mto}, Pareto optimization, aims to seek a gradient descent direction to improve all the tasks. However, these approaches differ from our Min-SNR-$\gamma$ weighting strategy in three aspects: 1) \textbf{Sparsity}. Most previous studies in the generic multi-task learning field have focused on scenarios with a small number of tasks, which differs from the diffusion training where the number of tasks can be up to thousands. As in our experiments, Pareto optimal solutions in diffusion training tend to set loss weights of most timesteps as 0. In this way, many timesteps will be left without any learning, and thus harm the entire denoising process. 2) \textbf{Instability}. The gradients computed for each timestep in each iteration are often noisy, owing to a limited number of samples for each timestep. This hampers the accurate computation of Pareto optimal solutions. 3) \textbf{Inefficiency}. The calculation of Pareto optimal solutions is time-consuming, significantly slowing down the overall training.

% To address this problem, we draw inspiration from the field of generic multi-task learning. In fact, by treating the denoising process of each timestep in diffusion training as an individual task, we can consider diffusion training as a multi-task learning problem. In generic multi-task learning, the methods usually seek to mitigate conflicts between tasks by adjusting the loss weight of each task based on their gradients. One classical approach~\cite{desideri2012mgda,sener2018mto}, Pareto optimization, seeks either a descent direction to improve all tasks or is set 0 to not harm any tasks. However, these conventional approaches in generic multi-task learning are often unsuitable to be directly applied to diffusion training due to several difficulties. Firstly, most previous studies in the generic multi-task learning field have focused on scenarios with a small number of tasks, which differs from the diffusion training where the number of tasks can be up to thousands. As in our experiments, Pareto optimal solutions in diffusion training tend to set loss weights of most timesteps as 0. In this way, many timesteps will be left without any learning, and thus harm the entire denoising process. Secondly, the gradients computed for each timestep in each iteration are often noisy, owing to a limited number of samples for each timestep. This hampers the accurate computation of Pareto optimal solutions. Lastly, the calculation of Pareto optimal solutions is time-consuming, significantly slowing down the overall training.

% In addressing the first difficulty, we incorporate an additional regularization term into the classical Pareto optimization method, which encourages the loss weights of all timesteps to be equal. Though this additional regularization term faces a risk of increased conflicts between timesteps, the benefits of better accounting all timesteps can outweigh the losses.
% For the second and third difficulties, we propose the utilization of a global step-wise loss weighting strategy, instead of run-time adaptive loss weights for each iteration as in the original Pareto optimization. The global loss weighting strategy eliminates the need for noisy computation of gradients and the time-consuming Pareto optimization process, making it more practical. Moreover, though suboptimal, the global strategy can be also almost as effective: firstly, the optimization dynamics of each denoising task are largely shaped by the task's noise level, without the need to account for individual samples too much. Secondly, after a moderate number of iterations, the gradients of the majority subsequent training process become more stable, thus it can be approximated by a stationery weighting strategy.

Our proposed Min-SNR-$\gamma$ strategy is a predefined global step-wise loss weighting setting, instead of run-time adaptive loss weights for each iteration as in the original Pareto optimization, thus avoiding the sparsity issue. Moreover, the global loss weighting strategy eliminates the need for noisy computation of gradients and the time-consuming Pareto optimization process, making it more efficient and stable. Though suboptimal, the global strategy can be also almost as effective: Firstly, the optimization dynamics of each denoising task are largely shaped by the task's noise level, without the need to account for individual samples too much. Secondly, after a moderate number of iterations, the gradients of the majority subsequent training process become more stable, thus it can be approximated by a stationery weighting strategy.

To validate the effectiveness of the Min-SNR-$\gamma$ weighting strategy, we first compute its Pareto objective value and compare it with the optimal step-wise loss weights obtained by directly solving the Pareto problem. Together, we also compare it with several conventional loss weighting strategies, including constant weighting, SNR weighting, and SNR with an lower bound. Figure~\ref{fig:object-value} shows that our Min-SNR-$\gamma$ weighting strategy produces Pareto objective values almost as low as the optimal one, significantly better than other existing works, indicating a significant alleviation of the gradient conflicting issue. As a result, the proposed weighting strategy not only converges much faster than previous approaches, but is also effective and general for various generation scenarios. It achieves a new record of FID score 2.06 on the ImageNet 256$\times$256 benchmark, and proves to also improve models using other prediction targets and network architectures.

% To obtain an effective global loss weighting strategy, we first analyze the Pareto objective values of several conventional loss weighting strategies, including constant weighting, SNR (signal-to-noise ratio), and SNR with an upper bound. Our results show that these strategies produce significantly higher Pareto objective values compared to the optimal objective values by directly solving the Pareto problem. We then propose a novel and simple weighting strategy, named Min-SNR-$\gamma$, which clamps the SNR with a bound value of $\gamma$. The inspiration of this strategy comes from the shape of the optimal step-wise loss weights obtained by directly solving the Pareto problem. Figure~\ref{fig:object-value} shows that this new weighting strategy produces Pareto objective values almost as low as the optimal one, indicating a significant alleviation of the gradient conflicting issue. As a result, the proposed weighting strategy converges much faster than previous approaches, as illustrated in Figure~\ref{fig:teaser}. The proposed strategy is also effective and general. It achieves a new record of FID score 2.06 on the ImageNet 256$\times$256 benchmark, and proves to also improve models using other prediction targets and network architectures.


%In this paper, we propose a simple yet effective loss weight strategy to avoid the aforementioned issues. We call it the Min-SNR-$\gamma$ strategy. On the one hand, it avoids the large computation cost of iterative optimization. On the other hand, it considers the relationship among different timesteps and does not neglect any of them. As illustrated in Figure~\ref{fig:teaser}, our method can successfully balance different tasks, convergences significantly faster than previous approaches, and achieves better performance. Additionally, the strategy is general and can be easily applied to a variety of network backbones and generation tasks. Our experiments validate the effectiveness of this strategy and establish a new record of FID score on the ImageNet $256\times 256$ synthesis.

Our contributions are summarized as follows:
%To summarize, we make the following contributions:
\begin{itemize}
    \item We have uncovered a compelling explanation for the slow convergence issue in diffusion training: a conflict in gradients across various timesteps.
    %In order to address the challenge of slow convergence in diffusion models, we performed a comprehensive analysis and found that it stems from the conflicting gradients from different timesteps.
    \item %We propose a simple yet effective loss weighting strategy to train diffusion models, it can better balance various tasks and greatly accelerate the convergence.
    We have proposed a new loss weighting strategy for diffusion model training, which greatly mitigates the conflicting gradients across timesteps and results in a marked acceleration of convergence speed.
    %can better balance various tasks and greatly accelerate the convergence.
    \item We have established a new FID score record on the ImageNet $256\times 256$ image generation benchmark.
    %We extensively evaluate our method on various tasks and show significant improvement over strong baselines. Furthermore, we achieve state-of-the-art performance on ImageNet $256\times 256$ synthesis.
\end{itemize}