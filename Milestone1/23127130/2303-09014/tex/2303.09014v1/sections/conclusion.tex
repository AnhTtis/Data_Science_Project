%Chain of thought (CoT) prompting yields impressive results on complex NLP tasks, which are further boosted by delegating intermediate sub-tasks to external tools like Python interpreters and search engines. 
We introduce \sys, a gradient-free approach for automatic multi-step reasoning generation and automatic tool-use for a large black-box language model. 
% Prior work on CoT prompting and tool use requires manual effort in hand-crafting task-specific demonstrations and interleaving model generations with tool use. 
Our main contributions include a lightweight grammar to represent multi-step reasoning as a program (with tool calls and arguments), an extensible library of seed tasks for which programs are authored, and a tool library that consists of useful external utilities like search, code generation, and execution. The interpretable reasoning framework also allows humans to improve task decomposition and tool use to boost performance. 
\sys achieves a substantial improvement over few-shot prompting and automatic generation of CoT reasoning on unseen tasks in the BigBench and MMLU benchmarks, and substantially exceeds performance on hand-crafted CoT prompts when human feedback is incorporated.
\sys also benefits from approaches such as self-consistency, or from new and more powerful LLMs trained for tool use.% to improve performance on downstream applications. 
% In future work, we intend to explore efficient and effective approaches to task selection and techniques for better human feedback. 
% \sameer{like this a lot, esp description of contributions, use some of it in the abstract}

% \section*{Limitations}
