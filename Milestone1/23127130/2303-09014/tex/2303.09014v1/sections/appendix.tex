\subsection{Task Library}
\label{appendix:tasklibrary}

\paragraph{Library Design}
% How task clusters were created. Include the task list and skills.
We analyzed input-output instances of all 200 tasks in BigBench, filtered out text classification and short answer generation tasks in English, and created a list of reasoning skills that were relevant to solving each task. We do not focus on long text understanding, long text generation, and multi-lingual tasks in this work. 
We find that most of these tasks rely on a few common skills mentioned below: \\
Visual Reasoning, Temporal Reasoning, Propositional logic, Natural Logic, Machine Translation, Web Search, Knowledge Base or Database lookup, Recursive sub-question decomposition, Long text understanding, Database Operations, Algebra and Arithmetic, Code Generation and Editing, Text Tagging/Annotation(linguistic markers), Specialized Search(eg. looking up linguistic knowledge, scientific knowledge etc), String editing, Recursive operations over multiple choices, Topic classification, Evidence extraction, conditional Text Generation/Editing, and Sentence similarity.

\noindent In this work, we choose to focus on the five most used skills that cover a significant proportion of BigBench tasks for classification (over 50 of the 91 tasks that remained after filtrating out long-text understanding, generation, and multi-lingual tasks). We randomly select 2-4 tasks from each of these 5 task clusters and author decomposed programs with appropriate tool use for these tasks. This results in a total of 15 tasks that compose the \emph{task library}. 

\begin{itemize}[noitemsep]
\item Arithmetic: Elementary MathQA, Grade school math (GSM8K), arithmetic Questions about ratios (Aqua-Rat), Navigate 
\item Code: Auto Debugging, Code Description
\item Search and question decomposition: Anachronims, Multi-step question answering (Musique), Hindu Knowledge, Known Unknown
% \item Multiple-choice tasks: Choose one or more of N options (overlaps with other categories)
\item Free-form reasoning: Formal fallacies, Hyperbation
\item String Operations: Kth letter concatenation, Language games, Date understanding
\end{itemize}

\begin{table*}[]
    \centering
    \small
    \begin{tabularx}{\linewidth}{ X }
    \toprule
    String Operations \\
    \midrule
In these examples, you are given a task description and an input. Break the input down into subtasks in order to solve the task. You can use string operations like splitting, reformatting, editing or merging. You can also use other operations like arithmetic and logic.\\
Description: (Date Understanding) Find the required date in MM/DD/YYYY using information about related events and dates in the input. Clue: First find what day is today.\\
Input: The deadline is Jun 1, 2021, which is 2 days away from now. What is the date 24 hours later in MM/DD/YYYY?\\
Q1: [string reformat] Jun 1, 2021 in MM/DD/YYYY\\
\#1: 06/01/2021\\
Q2: [arithmetic] 06/01/2021 is 2 days away from now. What date is today?\\
\#2: Today is 04/01/2021\\
Q3: [arithmetic] What date is 24 hours later than today?  \\
\#3: 05/01/2021\\
Q4: [EOQ]\\
Ans: 05/31/2021\\
----\\
Description: (Language games) Translate English into Pig Latin.\\
Input: (English) Sami made his way across the bar and hugged Layla.\\
Q1: [string split] What are the words in "Sami made his way across the bar and hugged Layla."?\\
\#1: ["Sami", "made", "his", "way", "across", "the",  "bar", "and", "hugged", "Layla", "."]\\
Q2: [string edit] Transfer the initial consonant of each word to the end of the word and adding "ay" after it.\\
\#2: ["Amisay", "ademay", "ishay", "ayway", "acrossyay", "ethay", "arbay", "andyay", "uggedhay", "Aylalay", "."]\\
Q3: [string merge] Concatenate \#2 into a full sentence.\\
\#3: Amisay ademay ishay ayway acrossyay ethay arbay andyay uggedhay Aylalay.\\
Q4: [EOQ]\\
Ans: Amisay ademay ishay ayway acrossyay ethay arbay andyay uggedhay Aylalay.\\
----\\
Description: (Kth letter concatenation) Take the letters at position 3 of the words in a list of words and concatenate them using a space.\\
Input: Take the letters at position 3 of the words in "Savita Saeed Ramos Sato Yadav" and concatenate them using a space.\\
Q1: [string split] What are the words in "Savita Saeed Ramos Sato Yadav"?\\
\#1: ["Savita", "Saeed", "Ramos",  "Sato",  "Yadav"]\\
Q2: [string index] What is the third letter of words in the list in \#1?\\
\#2: ["v", "e", "m", "t", "d"]\\
Q3: [string merge] Concatenate \#2 with spaces\\
\#3: "v e m t d"\\
Q4: [EOQ]\\
Ans: v e m t d\\
----\\
Descripton: \%s\\
Input: \%s\\
Q1:\\
\bottomrule
    \end{tabularx}
    \caption{Programs in the task library for tasks requiring string manipulation.}
    \label{tab:cluster_programs_string}.
\end{table*}

\begin{table*}[]
    \centering
    \small
    \begin{tabularx}{\linewidth}{ X }
    \toprule
    Arithmetic\\
    \midrule
In these examples, you are given a task description and an input. Break the input down into subtasks in order to solve the task. You can generate python code to solve arithmetic and algebra equations in using functions from sympy.\\
from sympy import Symbol\\
from sympy import simplify\\
import math\\
from sympy import solve_it\\
\# solve_it(equations, variable): solving the equations and return the variable value.\\
\\
Description: (Aqua-rat) Solve the following arithmetic problems on ratios and fractions, writing out intermediate arithmetic calculations as python code. Store your result as a variable named 'ans'.\\
Input:  In a flight of 600 km, an aircraft was slowed down due to bad weather. Its average speed for the trip was reduced by 200 km/hr and the time of flight increased by 30 minutes. The duration of the flight is:  A)1 hour B)2 hours C)3 hours D)4 hours E)5 hours\\
Q1: [generate python code] write python code to solve the problem, using math and sympy.\\
\#1:\\
duration = Symbol('duration', positive=True)\\
delay = 30 / 60\\
total_disntace = 600\\
original_speed = total_disntace / duration\\
reduced_speed = total_disntace / (duration + delay)\\
solution = solve_it(original_speed - reduced_speed - 200, duration)\\
ans = solution[duration]\\
print(ans)\\
Q2: [code execute] Execute the python code in \#1 and get the value of "ans"\\
\#2:\\
1.0\\
Q3: [compare] Which of the options among A)1 hour B)2 hours C)3 hours D)4 hours E)5 hours is most similar to the answer? \\
\#3: A\\
Q4: [EOQ]\\
Ans: A\\
----\\
Description: (Elementary Math) Solve the following middle-school arithmetic problems, writing out intermediate arithmetic calculations as python code. Store your result as a variable named 'ans'.\\
Input: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for \$2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\\
Q1: [generate python code] write down the arithmetic or algebra equations as python code, storing the answer as 'ans'\\
\#1:\\
total_eggs = 16\\
eaten_eggs = 3\\
baked_eggs = 4\\
sold_eggs = total_eggs - eaten_eggs - baked_eggs\\
dollars_per_egg = 2\\
ans = sold_eggs * dollars_per_egg\\
print(ans)\\
Q2: [code execute] Execute the python code in \#1 and get the value of "ans"\\
\#2: 18\\
Q3: [EOQ]\\
Ans:18\\
----\\
Description: (Grage school Math) Solve the following middle-school arithmetic problems, writing out intermediate arithmetic calculations as python code. Store your result as a variable named 'ans'.\\
Input: Joseph and Getty went to buy ice creams, they together bought 36 ice creams. On the way back, Joseph ate 12 of the ice creasm, and he has 2 ice creams left now. \\
Q1: [generate python code] write down the arithmetic or algebra equations as python code, storing the answer as 'ans'\\
\#1:\\
num_ice_creams_bought_by_joseph = 2 + 12\\
total_ice_creams = 36\\
ans = total_ice_creams - num_ice_creams_bought_by_joseph\\
print(ans)\\
Q2: [code execute] Execute the python code in \#1 and get the value of "ans"\\
\#2: 22\\
Q3: [EOQ]\\
Ans: 22\\
----\\
Descripton: \%s\\
Input: \%s\\
Q1:\\
\bottomrule
    \end{tabularx}
    \caption{Programs in the task library for tasks requiring arithmetic operations.}
    \label{tab:cluster_programs_arithmetic}.
\end{table*}

\begin{table*}[]
    \centering
    \small
    \begin{tabularx}{\linewidth}{ X }
    \toprule
    Search \\
    \midrule
In these examples, you are given a task description and an input. Break the input down into subtasks in order to solve the task. You can use search functions like Google search in one or more of your substeps, if there in insufficient information. Other functions like arithmetic and logical operations can also be used.\\
Description: (Knwon or Unknwon) Choose the option that best answers the question. If the question does not have a known answer, choose "Unknown".\\
Input: How many hairs were on Neil Armstrong's head when he landed on the moon?\\
  choice: Unknown\\
  choice: Five million\\
Q1: [search] How many hairs were on Neil Armstrong's head when he landed on the moon? \\
\#1:\\
Apollo 11 (July 16–24, 1969) was the American spaceflight that first landed humans on the Moon. Commander Neil Armstrong and lunar module pilot Buzz Aldrin.\\
Neil Alden Armstrong (August 5, 1930 – August 25, 2012) was an American astronaut and aeronautical engineer who became the first person to walk on the Moon.\\
Q2: [subquestion] Does the information help answer the question? There could be no definitive answer because the question is too specific, about personal details not in public record, because the answer is not yet known, or the question is opinion-based.\\
\#2: No. The question is too specific\\
Q3: [compare] What is the final answer?\\
\#3: Unknown\\
Q4: [EOQ]\\
Ans: Unknown\\
----\\
Description: (Anachronisms) An anachronism is a mistake in chronology, or a person, thing, or event that is out of its proper time. Does the sentence contain an anachrornism? Answer Yes/No.\\
Input: President George H. W. Bush called his generals to the Oval Office at the outset of the Gulf War.\\
Q1: [tag] What are the entities in this sentence?\\
\#1:\\
President George H. W. Bush\\
Gulf War\\
Q2: [search] When was President George H. W. Bush president?\\
\#2: George H. W. Bush's tenure as the 41st president of the United States began with his inauguration on January 20, 1989, and ended on January 20, 1993.\\
Q3: [search] When was the Gulf War fought?\\
\#3: The Gulf War[b] was a 1990–1991 armed campaign waged by a 35-country military coalition in response to the Iraqi invasion of Kuwait.\\
\#4: [subquestion] Could these entities have co-existed based on thier time periods alone?\\
Yes. Their time periods intersect.\\
Q5: [generate output] Is this an anachronism?\\
\#5: No\\
Q6: [EOQ]\\
Ans: No\\
----\\
Description: (Hindu Knowledge) Answer questions about Hindu mythology by choosing the option that best answers the question.\\
Input: In the Mahabharata, Karna is cursed to forget the incantations needed to use which weapon?\\
  choice: Anjalikastra\\
  choice: Narayanastra\\
  choice: Agneyastra\\
  choice: Brahmastra\\
Q1: [search] In the Mahabharata, Karna is cursed to forget the incantations needed to use which weapon?\\
\#1: As a result, he cursed Karna, saying that HIS MARTIAL SKILLS, including the use of BRAHMASTRA, would abandon him when he needed them most. Indra, the King of Gods, stung Karna in the form of a bee to get him cursed by Parshuram. Karna walked through the woods in despair, feeling dejected by the curse. A skilled \& devoted warrior...\\
Q2: [compare] Which option is the answer in \#3 most similar to?\\
\#2: Brahmastra\\
Q3: [EOQ]\\
Ans: Brahmastra\\
----\\
Descripton: \%s\\
Input: \%s\\
Q1:\\
\bottomrule
    \end{tabularx}
    \caption{Programs in the task library for tasks requiring search for world knowledge.}
    \label{tab:cluster_programs_search}.
\end{table*}

\begin{table*}[]
    \centering
    \small
    \begin{tabularx}{\linewidth}{ X }
    \toprule
    Code Generation and Editing \\
    \midrule
In these examples, you are given a task description and an input. Break the input down into subtasks in order to solve the task. You can use a python code generation and execution function in one or more of your substeps, if required. Other functions like arithmetic and logical operations can also be used.\\
Description: (Auto Debugging) Debug the following code snippets by finding the answer or the error message.\\
Input: \\
```\\
if x < 5:\\
    pass\\
```\\
What error does this program surface?\\
Q1: [execute] Execute the following python code snippet.\\
if x < 5:\\
    pass\\
\#1:\\
Traceback (most recent call last):\\
  File "<stdin>", line 1, in <module>\\
NameError: name 'x' is not defined\\
Q2: [generate answer] What is the final error message?\\
\#2: NameError: name 'x' is not defined\\
Q3: [EOQ]\\
Ans: NameError: name 'x' is not defined\\
----\\
Description: (Code description) Given a python code snippet, choose the option that is the best description of the code snippet.\\
Input:\\
Python code:\\
try:\\
$\quad$n = int(input())\\
$\quad$m = int(input())\\
$\quad$integer_sum = int(n) + int(m)\\
$\quad$print(integer_sum)\\
except:\\
$\quad$print('error')\\
  choice: prints number between 5 and 6\\
  choice: try input and except error\\
  choice: inputs the string 'try'\\
  choice: prints sum of two input numbers only if they are integers otherwise raises error\\
Q1: [code generate] prints number between 5 and 6\\
\#1:\\
import random\\
print(random.uniform(5,6))\\
Q2: [code generate] try input and except error\\
\#2:\\
try:\\
$\quad$file = open(file_name, "r")\\
$\quad$data = file.read()\\
$\quad$file.close()\\
except:\\
$\quad$print('error')\\
Q3: [code generate] inputs the string 'try'\\
\#3: print('try')\\
Q4: [code generate] prints sum of two input numbers only if they are integers otherwise raises error\\
\#4:\\
\#!/usr/bin/python\\
\\
a=raw_input("enter first number: ")\\
b=raw_input("enter second number: ")\\
try:\\
$\quad$    sum=int(a)+int(b)\\
$\quad$    print "sum is: ",sum\\
except:\\
$\quad$    print "enter integer values only"\\
Q5: [compare] Which of the generated code snippets are most like the original one?\\
\#5: prints sum of two input numbers only if they are integers otherwise raises error\\
Q6: [EOQ]\\
Ans: prints sum of two input numbers only if they are integers otherwise raises error\\
----\\
Descripton: \%s\\
Input: \%s\\
Q1:\\
\bottomrule
    \end{tabularx}
    \caption{Programs in the task library for tasks requiring code generation or editing.}
    \label{tab:cluster_programs_code}.
\end{table*}

\begin{table*}[]
    \centering
    \small
    \begin{tabularx}{\linewidth}{ X }
    \toprule
    CoT Reasoning \\
    \midrule
In these examples, you are given a task description and an input. Break the input down into subtasks in order to solve the task. Thinking though the problem explicitly can be one of the substeps you use.\\
Description: (Sports Understanding) Determine whether an artificially constructed sentence relating to sports is plausible. The final answer should be "yes" or "no".\\
Input: Is the following sentence plausible? "Santi Cazorla scored a touchdown."\\
Q1: [think step-by-step] \\
\#1: Let's think step-by-step. Santi Cazorla is a soccer player. Touchdown is part of American football and rugby. So the answer is no.\\
Q2: [EOQ]\\
Ans: no\\
----\\
Description: (Hyperbation) Identify correct adjective ordering from the two choices. This involves selecting what would be considered the more inexplicably "intuitive" sentence by a native English speaker.\\
Input: Which sentence has the correct adjective order:\\
Options:\\
(A) repulsive small Brazilian exercise ship\\
(B) Brazilian repulsive exercise small ship\\
Q1: [think step-by-step] \\
\#1: Let's think step-by-step. When there is more than one adjective before a noun, the adjectives need to respect the following order before a noun: "[1. opinion] [2. size] [3. age] [4. shape] [5. color] [6. origin] [7. material] [8. purpose] noun".\\
Option (A): "repulsive small Brazilian exercise ship". (1) "repulsive" falls into the opinion category. (2) "small" falls into the size category. (3) "Brazilian" falls into the origin category. (4) "exercise" falls into the purpose category. Option (A) has the following adjective order: [1. opinion] [2. size] [6. origin] [8. purpose] (or, in numeric terms, 1 2 6 8). Because 1 < 2 < 6 < 8 is correct, (A) has the correct ordering.\\
Option (B): "Brazilian repulsive exercise small ship". Option (B) has the following adjective order: [6. origin] [1. opinion] [8. purpose] [2. size] (or, in numeric terms, 6 1 8 2). Because 6 < 1 < 8 < 2 is not correct, (B) does not have the correct ordering. So the answer is (A).\\
Q2: [EOQ]\\
Ans: (A)\\
----\\
Description: (Formal Fallacies) Distinguish deductively valid syllogistic arguments from formal fallacies, paying specific attention to negations.\\
Input: "It is not always easy to see who is related to whom -- and in which ways. The following argument pertains to this question: To begin with, Lesley is a close friend of Fernando. Moreover, being a close friend of Fernando or a schoolmate of Lowell is sufficient for being a great-grandfather of Leroy. It follows that Lesley is a great-grandfather of Leroy."\\
Is the argument, given the explicitly stated premises, deductively valid or invalid?\\
Options:\\
- valid\\
- invalid\\
Q1: [think step-by-step] \\
\#1:\\
Let's think step-by-step.\\
(1) Lesley is a close friend of Fernando: Lesley = friend(Fernando).\\
(2) Being a close friend of Fernando or a schoolmate of Lowell is sufficient for being a great-grandfather of Leroy: If X = friend(Fernando) OR SCHOOLMATE(Lowell), then X = great-grandfather(Leroy).\\
Hypothesis: Does it follow that Lesley is a great-grandfather of Leroy: Lesley = great-grandfather(Leroy)?\\
Let’s see whether the Hypothesis can be deduced from the arguments (1) and (2) by logical reasoning?\\
By (1), we have Lesley = friend(Fernando). By (2), we have if Lesley = friend(Fernando), then Lesley = great-grandfather(Leroy).\\
So, it is true that Lesley is a great-grandfather of Leroy. So the answer is valid.\\
Q2: [EOQ]\\
Ans: valid\\
----\\
Description: (Reasoning about colored objects) Given a collection of colored objects in the text input, answer the question at the end of the input.\\
Input: On the nightstand, there is a red pencil, a purple mug, a burgundy keychain, a fuchsia teddy bear, a black plate, and a blue stress ball. What color is the stress ball?\\
Q1: [think step-by-step] \\
\#1: Let's think step-by-step. According to this question, the color of the stress ball is blue. So the answer is blue.\\
Q2: [EOQ]\\
Ans: blue\\
----\\
Descripton: \%s\\
Input: \%s\\
Q1:"""\\
\bottomrule
    \end{tabularx}
    \caption{Programs in the task library for tasks requiring free-form chain-of-thought style reasoning about logic and lingusitics.}
    \label{tab:cluster_programs_cot}.
\end{table*}


\paragraph{Cluster Programs}
The programs written for tasks in each task cluster are shown in Table~\ref{tab:cluster_programs_string} for tasks involving string editing and manipulation, in Table~\ref{tab:cluster_programs_arithmetic} for arithmetic and algebra tasks, in Table~\ref{tab:cluster_programs_code} for code generation, editing and debugging tasks, in Table~\ref{tab:cluster_programs_search} for tasks benefit from  search of world knowledge, and in Table~\ref{tab:cluster_programs_cot} for tasks that benefit from eliciting chain-of-thought reasoning following the prompt ``Let's think step-by-step''.

\paragraph{Program Format}
We define a parsing expression grammar (PEG) (shown in  Figure~\ref{fig:peg_grammar}) that describes the language used to write multi-step reasoning programs. This grammar is designed to parse full programs of the form \exinline{Input: ... $Q_1$: ... \#1:... $Q_n$: [EOQ] Ans: }. We use the python library \emph{parsimoneous}\footnote{\url{https://pypi.org/project/parsimonious/}} to construct the grammar and parse programs generated by LLMs.

\subsection{Task Selection}
\label{appendix:taskselection}
When provided new task description and input instance, ART retrieves N tasks from the task library to constructs a dynamic multi-task prompt. We explore two strategies for task selection.

\paragraph{Task-Cluster based}
50 examples used for tuning except in cases with fewer than 100 examples, where we reduce this number to 10. 

We iterate over all five task clusters in the library, prompting the LLM with demonstration programs from just one cluster at a time. For example, we only use programs from arithmetic tasks as demonstrations in the prompt in one such iteration.
The task cluster with the highest performance on the held-out set of examples (~50) is chosen. This strategy requires as many API calls as there are task clusters, and a held-out set of input-output pairs for the new task. Note that no additional supervision is needed for the new task to generate a decomposed  program. 

\paragraph{LLM-Similarity based}
The LLM is prompted with pairs of tasks. Some pairs contain two tasks from the same cluster and are labeled "Similar" while some pairs don't and are labeled "Not similar". Additionally, we also provide reasoning for the decision --- \emph{``Elementary math QA and GSM8K are related tasks because they both require solving arithmetic word problems"}. 
A task in this prompt is represented by its name, an instruction, and a few input-output pairs.  We use the prompt in Table~\ref{tab:llm_similar_prompt} to prompt LLMs. 

The LLM is prompted for a decision for every library task paired with the new task. We choose the top-N tasks ranked by the ratio of log probabilities of "Similar" to "Not similar". This strategy requires fewer held-out examples but is prone to high variance in performance based on the tasks chosen in every experimental run. For PQA, the most similar tasks chosen based on the LLM-based similarity are anachronisms and GSM8K.

In Table \ref{tab:selection}, we examine the effect of changing the task selection strategy in \sys. Instead of choosing the task cluster with the highest held-out performance over ~50 examples, we use the LLM-based similarity score to choose task programs for the prompt. This strategy is worse on average compared to tuning performance on a held-out set and has high variance over several runs where different tasks are chosen by the LLM.
Selecting similar tasks that share sub-tasks and tools (without any supervision) is still a challenging task for LLMs, and will explore this direction further in future work.


\begin{table*}[]
    \centering
    \small
    \begin{tabular}{l|cccccc}
    \toprule
      & \bf Simple Text  & \bf CS  & \bf Strategy QA &\bf  Physics & \bf Unit  & \bf Reasoning about \\
     & \bf Editing & \bf Algorithms & &\bf  Questions & \bf Interpretation & \bf colored objects \\
     \midrule
    \bf Best task cluster & 27.65 & 88.11 & 66.44 & 20.37 & 53.99 & 64.34 \\
    \bf LLM-based task sim. & 38.30 & 83.71 & 60.39 & 14.06 & 43.56 & 62.00 \\
    % \bf Self Consistency & 30.67 & 90.99 & 70.76 & 24.07 & 57.20 & 69.11\\
    \bottomrule
    \end{tabular}
    \caption{Comparing \sys results on GPT3 (175B) model with two similar task selection strategies. LLM-based similarity is worse on average compared to just choosing the best task cluster.}
    \label{tab:selection}
\end{table*}

\begin{figure*}[htb!]
    \centering
    \includegraphics[scale=0.4]{sections/resources/peg_grammar.pdf}
    \caption{PeG Grammar used to parse \sys programs}
    \label{fig:peg_grammar}
\end{figure*}


\begin{table*}[]
    \centering
    \small
    \begin{tabularx}{\linewidth}{ X }
    \toprule
    Prompt to LLM for selecting similar tasks \\
    \midrule
Give two tasks with their descriptions and examples of inputs and outputs for the tasks, determine if they are similar. Two tasks are similar if require common subtasks like string operations, web search, translation, arithmetic, code execution, etc.\\
----\\
Task1: [Date understanding] Find the required date in MM/DD/YYYY using information about related events and dates in the input. Input: The deadline is Jun 1, 2021, which is 2 days away from now. What is the date 24 hours later in MM/DD/YYYY? The final answer is 05/01/2021.\\
Task2: [Language Games] Translate English into Pig Latin. Input: English sentence is "Sami made his way across the bar and hugged Layla". The final answer is "Amisay ademay ishay ayway acrossyay ethay arbay andyay uggedhay Aylalay."\\
Are these similar? Yes. They both require answering in a spcific string format. \\
----\\
Task1: [K'th letter concatenation] Take the letters at position 3 of the words in a list of words and concatenate them using a space. Input: What are the words in "Savita Saeed Ramos Sato Yadav"? The final answer is "v e m t d".\\
Task2: [Language Games] Translate English into Pig Latin. Input: English sentence is "Sami made his way across the bar and hugged Layla". The final answer is "Amisay ademay ishay ayway acrossyay ethay arbay andyay uggedhay Aylalay."\\
Are these similar? Yes. They both require accessing and manipulating characters in strings.\\
----\\
Task1: [K'th letter concatenation] Take the letters at position 3 of the words in a list of words and concatenate them using a space. Input: What are the words in "Savita Saeed Ramos Sato Yadav"? The final answer is "v e m t d".\\
Task2: [Known Unknown] Choose the option that best answers the question. If the question does not have a known answer, choose "Unknown". Input: How many hairs were on Neil Armstrong's head when he landed on the moon? The final answer is "Unknown".\\
Are these similar? No. Task 1 requires manipulating strings and Task 2 requires answering a question by possibly looking up information on the web. \\
----\\
Task1: [Anachronisms] An anachronism is a mistake in chronology, or a person, thing, or event that is out of its proper time. Does the sentence contain an anachrornism? Input: Kurt Cobain starred in the 1980 television show "Twin Peaks". The final answer is "Yes".\\
Task2: [Known Unknown] Choose the option that best answers the question. If the question does not have a known answer, choose "Unknown". Input: Where was Mark Twain born? The final answer is Florida, Missouri. \\
Are these similar? Yes. They both require searching information about entities mentioned in the text, like Kurt Cobain or Mark Twain.\\
----\\
Task1: [Hindu Knowledge] Answer questions about Hindu mythology by choosing the option that best answers the question. Input: In the Mahabharata, Karna is cursed to forget the incantations needed to use which weapon? Choices: Anjalikastra, Narayanastra, Agneyastra, Brahmastra. The final answer is Brahmastra.\\
Task2: [Code Debugging] Debug the following code snippets by finding the answer or the error message. Input: \\
if x < 5:\\
$\quad$pass\\
The final answer is\\
Traceback (most recent call last):\\
  File "<stdin>", line 1, in <module>\\
NameError: name 'x' is not defined\\
Are these similar? No. Task 1 is about asnswering a question and requires searching information about entities mentioned in the text. Task 2 is a question about debugging code and may require a Python interpreter.\\
Task 1: \%s\\
Task 2: \%s\\
Are these similar? \\
\bottomrule
    \end{tabularx}
    \caption{Programs in the task library.}
    \label{tab:llm_similar_prompt}.
\end{table*}


\subsection{Tool Use}
\label{appendix:toolise}

\paragraph{Code Generation}
% Mention how a multiline comment is constructed. Mention how ans is introduced for consistency
% To generate code, 

We use the Codex \citep{chen2021evaluating} model for code generation. Argument for code generation is the previous sub-task's answer sequence \exinline{``$\#i-1:\dots$"}  and the sequence generated by the LM after the sub-task query symbol \exinline{``$Qi: [generate\; python\; code]$"}. When $i=1$, the instance input is used as the first argument. We include the previous answer/input since it often contains information relevant to generating accurate code, like the arithmetic word problem for which code needs to be generated (see Table~\ref{tab:cluster_programs_arithmetic} for examples). Both arguments are provided to Codex as a multi-line python comment, while maintaining their original formatting.  To keep the answer variable consistent, we also append an additional instruction: Store the final answer in variable 'ans' and print it.
For example:\\
\begin{lstlisting}
Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers market daily for \$2 per fresh duck egg. How much in dollars does she make every day at the farmers market?
\end{lstlisting}
is used to prompt Codex as follows:
\begin{lstlisting}
"""
Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers market daily for \$2 per fresh duck egg. How much in dollars does she make every day at the farmers market?
Write down the arithmetic or algebra equations as python code, storing the answer as 'ans' and print it.
"""
\end{lstlisting}
Codex generation temperature is set to 0.3 and the maximum length to 500 tokens, with \exinline{print(ans)} used as the stopping criterion.


% Mention how a multiline comment is constructed. Mention how errors are reported back or the code is again edited to store the variable asked in ans.
\paragraph{Code Editing}
We use the Codex \citep{chen2021evaluating} model for code generation and code editing. Arguments for both include the previous sub-task's answer sequence \exinline{$\#i-1:\dots$} (or the input if $i=1$), and the sequence generated by the LM after the sub-task query symbol \exinline{$Qi: [generate\; python\; code]$}.
The first argument is the code snippet that needs to be edited and the second argument is a multi-line comment in Python used as the instruction for editing/generation. To ensure that subsequent code execution results in the generation of an answer string independent of variable name, the edit instruction is to \emph{print} the required variable.
For example, for the auto debugging task in the task library, the following program snippet:
\begin{lstlisting}
Input:
```
x = set([1, 1, 2, 3])
```
What is the value of x after this program executes?
Q1: [code edit] Edit the code to print the value of x
\end{lstlisting}
is used to prompt Codex in edit mode as follows. For code input:
\begin{lstlisting}
x = set([1, 1, 2, 3])
\end{lstlisting}
For edit instruction: 
\begin{lstlisting}
Edit the code to print the value of x
\end{lstlisting}



\begin{table}[]
    \centering
    \small
    \begin{tabularx}{\linewidth}{ X }
from sympy.solvers import solve\\
from sympy import Symbol, Eq, simplify\\
import math\\
import numpy as np\\
import cvxpy as cp\\
import statistics\\
\\
def solve_it(equation, variable):\\
$\quad$solution=solve(equation, variable, dict=True)\\
$\quad$if not solution:\\
$\quad$$\quad$if isinstance(variable, list):\\
$\quad$$\quad$$\quad$solution={v: None for v in variable}\\
$\quad$$\quad$else:\\
$\quad$$\quad$$\quad$solution={variable: None}\\
$\quad$$\quad$return solution\\
$\quad$else:\\
$\quad$$\quad$solution = solution[0]\\
$\quad$$\quad$return solution\\
    \end{tabularx}
    \caption{Code prefix appended before a code snippet prior to execution.}
    \label{tab:tool_use_prefix}
\end{table}




\paragraph{Code Execution}
We run python code in a virtual python environment with arithmetic, symbolic, and scientific computing packages pre-installed. The arguments to code execute include the previous sub-task's answer sequence ``$\#i-1:\dots$", which is the python code snippet that requires executing. If $i=1$, the input contains the code.
The other argument is the  sequence generated by the LM after the sub-task query symbol ``$Qi: [execute\; code]$" (which is simply to the code snippet as a comment). Again, to encourage executable code with consistent variable usage, we also append the sequence "Store your final answer is variable 'ans'" to the comment.  
The results of the execution call are used to replace the answer sequence generated by the language model. Finally, we prepend a code snippet consisting of useful module and function imports so that function calls external modules like numpy and scipy are executed successfully. This code prefix is shown in Table~\ref{tab:tool_use_prefix}. We use the \emph{exec} native python function to execute the code snippet and access the 'ans' local variable if it exists.



\paragraph{Knowledge Base lookup}
This tool is added in the Word Unscrambling task. This function call is used to look up data by keys in a relational knowledge base. For example, we use dictionary lookup for the Word Unscrambling task. The input to this function is again the previous sub-task's answer sequence (if it exists, or the original input is used) and the sequence generated by the LM after the function name symbol. The first argument is parsed as a python code snippet and interpreted as a list of lookup keys. The second argument is parsed as a code generation prompt which is consequently executed. For example, the first argument of \emph{l = ['yob', 'boy', 'oyb']} and the second argument \emph{Check which of these list of words is a word in English. Store the final answer is 'ans' and print it.} results in the following code snippet and final answer \emph{'boy'}:
\begin{verbatim}
def lookup(word_list):
  import enchant
  d = enchant.Dict("en_US")
  valid_list = []
  for word in word_list:
    if d.check(word):
      valid_list.append(word)
  return valid_list
\end{verbatim}
While this is a restricted definition for a general knowledge base lookup or query, we explore how human-in-the-loop feedback can be used to create custom lookup tools.

\paragraph{Prolog Engine}
This tool is added in the formal fallacies task. This task consits of first-order logic statements stated in natural language, as follows:
\begin{lstlisting}
To begin with, Bonnie is a schoolmate of Miranda. Moreover, whoever is a workmate of Aubrey is not a schoolmate of Miranda. All this entails that Bonnie is not a workmate of Aubrey.
Is the argument, given the explicitly stated premises, deductively valid or invalid?
\end{lstlisting}
% This tool is added in the Navigation task.
This can be written in Prolog \footnote{\url{https://en.wikipedia.org/wiki/Prolog}} as:\\
\begin{lstlisting}
workmate(X, aubrey) :- \+ schoolmate(X, miranda).
schoolmate(bonnie, miranda).
?- workmate(bonnie, aubrey).
\end{lstlisting}
Humans provide feedback by authoring such prolog statements for a few instances with a new tool symbol \exinline{[translate to prolog]}. They then author a new tool that calls a python prolog parsing engine to execute the prolog code and determine the binary value of the final expression. This is integrated back into the program.


\subsection{Baselines}
\label{appendix:baselines}


\paragraph{Few-shot baseline}
This is the direct prompting baseline where the prompt consists of input-output pairs only and no additional intermediate reasoning steps. Following prior work that reports results with direct prompting \citep{suzgun2022challenging, wei2022chain}, we use 3 randomly chosen input-output instances. We run direct prompting for both, InstructGPT (text-davinci-002) \citep{ouyang2022training} and Codex (code-davinci-002) \citep{chen2021evaluating} and report the higher performance. This follows from \cite{chung2022scaling}, where they find that Codex models are better at analytical tasks than text models, even with direct prompting.

\paragraph{Auto CoT}
A baseline that generates automatic CoT-style multi-step reasoning in a free-form natural language (as done in AutoCoT~\citep{zhang2022automatic}). A randomly selected subset of examples in the dataset is used to prompt the LLM to elicit CoT-style reasoning (\emph{Input + Let's think step-by-step.}). Since CoT-style generation is free-form and parsing potential tool use symbols is harder, we don't use tools for this baseline. This baseline specifically measures the effectiveness of a custom query language (and PeG grammar) we use to write programs and parse tool calls; 
While \cite{zhang2022automatic} cluster training examples to provide diverse demonstrations to the LLM, we choose a random selection of 5 examples. A careful selection of demonstration examples may also be used for \sys, and we leave an exploration of this choice to future work.
We parse the generated CoT-style reasoning to extract the answer string and add the phrase ``The final answer i'' along with the answer string to the end of the reasoning. This pattern is used for evaluation.


\begin{table*}[]
    \centering
    \small
    \begin{tabular}{l|cc|cc|l}
    \toprule
    % &  \multicolumn{2}{c}{Human-in-the-loop improvement} \\
    % \midrule
     \bf Task & \multicolumn{2}{c}{\bf CoT} &  \multicolumn{2}{c}{\bf \sys} & \bf Human feedback \\
      % &\multicolumn{2}{c}{CoT} & \bf & \\
      & & \bf +Human & & \bf + Human \\
     \midrule
     Kth letter concat* & 0.64 & 59.40 & 40.0 & 100.0 & Code C: k'th letter extraction and merge for a list of words \\
     Language Games* & 18.58 & 26.08 & 23.08 & 35.38 & Code  C: Eng->Pig Latin and vice-versa\\
     Anachronisms*   & 51.48 & 49.82 & 75.66 & 82.91 & C: search query constrained to extract time-periods \\
     % & & & of the entities \\
     Auto Debugging* &38.24 & 61.18 & 62.94  & 67.05 & Code C: Code edit fixed to print variable asked in input \\
     & & & & & A: ``[generate answer] What is the final error message?'' \\
     Navigate & 61.7 & 85.9 & 72.4 & 80.89 & Code C: correct forward, backward, right, left distances\\
     Date Understanding & 38.9 & 70.4 & 52.05 & 65.45 & A: First find what date is today \\
     Formal Fallacies & 56.4 & 56.4 & 64.76 & 74.39 & T: Translate to Prolog and add prolog engine \\
    \bottomrule
    \end{tabular}
    \caption{Improving \sys and free-form CoT via self-consistency and human-in-the-loop feedback on library tasks. (*) indicates that human-in-the-loop improvement was done over automatically generated CoT reasoning for these tasks.}
    \label{tab:model_improvements_lib}
\end{table*}


\paragraph{Best GPT-3 Approaches}
We briefly describe the GPT-3 best results reported in Tables~\ref{tab:main_result_table_library} and Tables~\ref{tab:main_result_table_test}, which correspond to the best GPT-3 results reported in  approaches that use multi-step reasoning (like CoT) and tool use,  with human supervision for both.
\begin{itemize}[noitemsep]
    \item \cite{suzgun2022challenging}: Human-authored CoT reasoning for several tasks in BigBench. A closer inspection of their hand-crafted prompts revealed that they cast BigBench tasks to multiple-choice tasks (selecting between options A,B,C,...), which differs from the more challenging format proposed originally and used in this work. Hence, we modify their prompt to generate answers in the output space, which is a fair comparison with \sys. Hence, the results reported in Table~\ref{tab:main_result_table_library} and Table~\ref{tab:main_result_table_test} may differ from the results reported in \cite{suzgun2022challenging} 
    \item \cite{khot2022decomposed}: Decomposed prompting for list reveral and kth letter comaparison.
    \item \cite{press2022measuring}: Decomposed multi-step QA for musique.
    \item \cite{chen2022program}: Program-of-though: Promtps are designed to convert Arithmetic problems into code and execute them.
    \item \cite{ouyang2022training}: InstructGPT
    \item \cite{chung2022scaling}: PaLM language model. Note that we only consider the highest reported text-davinci-002 or code-davinci-002 results from this paper to compare with \sys.
    \item \cite{chen2021evaluating}: Codex
\end{itemize}

% \subsection{Additional Results}
% \label{appendix:additional}
% Put table with standard dev here.

\subsection{Human Feedback}
\label{appendix:human_feedback}
% Detail about how feedback was solicited.
% More examples for task improvement. 
We present feedback provided by humans for five BigBench tasks.
\begin{itemize}[noitemsep]
    \item Table~\ref{tab:hf:colored_objects} for reasoning about colored objects, where code is edited  introduces a consistent data structure to represent the input.
    \item Table~\ref{tab:hf:physics} for physics, where substeps is introduced that prompt for given physical quantities, required quantity and a physics formula that connects them together.
    \item Table~\ref{tab:hf:temporal_sequences} for temporal sequences, where substeps are introduced that go over all options one by one to determine whether the subject in the input is busy with an activity at those times.
    \item Table~\ref{tab:hf:shuffled_objects} for tracking shuffled objects, where code is edited  introduces a consistent data structure to represent the input and swap logic is corrected.
    \item Table~\ref{tab:hf:word_unscrambling} for unscrambling english words, where code is edited in step 2 to get correct permutations and a new tool is defined in step 3 to lookup the english dictionary and return permutations that are actual words.
\end{itemize}
In Table~\ref{tab:model_improvements_lib}, we present human feedback results for training tasks in the task library.




\begin{table*}[]
    \centering
    \small
    \begin{tabularx}{\linewidth}{ X }
    \toprule
    Reasoning about colored objects\\
    \midrule
    Before \\
    \midrule
Input: On the nightstand, there are two silver textbooks and three silver cat toys. If I remove all the cat toys from the nightstand, how many fuchsia things remain on it?\\
Q1: [generate python code] write down the arithmetic or algebra equations as python code, storing the answer as ’ans’\\
1:\\
num_of_silver_textbooks = 2\\
num_of_silver_cat_toys = 3\\
num_of_fuchsia_things = num_of_silver_textbooks\\
num_of_things_on_nightstand = num_of_silver_textbooks + num_of_silver_cat_toys\\
ans = num_of_things_on_nightstand - num_of_silver_cat_toys\\
print(ans)\\
Q2: [code execute] Execute the python code and get the value of "ans"\\
2: 2\\
Q3: [EOQ]\\
Ans: 2\\
    \midrule
    After \\
    \midrule
Input: On the nightstand, there are two silver textbooks and three silver cat toys. If I remove all the cat toys from the nightstand, how many fuchsia things remain on it?\\
Q1: [generate python code] Write python code to find if I remove all the cat toys from the nightstand, how many fuchsia things remain on it\\
\#1:\\
color_object_count = [("silver", "textbooks", 2), ("silver", "cat toys", 3)]\\
removed_objects = [("silver", "cat toys", 3)]\\
def remove_objects(color_object_count, removed_objects):\\
$\quad$color_object_count_updated = []\\
$\quad$for color, object, count in color_object_count:\\
$\quad$$\quad$for color2, object2, count2 in removed_objects:\\
$\quad$$\quad$$\quad$if color == color2 and object == object2:\\
$\quad$$\quad$$\quad$$\quad$count -= count2\\
$\quad$$\quad$color_object_count_updated.append([color, object, count])\\
$\quad$return color_object_count_updated\\
color_object_count = remove_objects(color_object_count, removed_objects)\\
ans = 0\\
for color, object, count in color_object_count:\\
$\quad$if color == "fuchsia":\\
$\quad$$\quad$ans = count\\
print(ans)\\
Q2: [code execute] Execute the python snippet.\\
\#2: 0\\
Q3: [EOQ]\\
Ans: 0\\
    \bottomrule
    \end{tabularx}
    \caption{Human feedback: Reasoning about colored objects}
    \label{tab:hf:colored_objects}
\end{table*}

\begin{table*}[]
    \centering
    \small
    \begin{tabularx}{\linewidth}{ X }
    \toprule
    Physics \\
    \midrule    
    Before \\
    \midrule
Input: Identify the physics formula that would be most useful for finding the answer to each of the following word problems.A particle of mass 6.8 * 10 ^ -5 g and charge 58 mC moves in a region of space where the electric field is uniform and is 7.2 N/C in the x direction and zero in the y and z direction. If the initial velocity of the particle is given by vy = 1.7 * 10 ^ 6 m/s, vx = vz = 0, what is the speed of the particle at 0.7 s?\\
  choice: F = m * a\\
  choice: v = dx / dt\\
  choice: E = q / ($\epsilon$ * A * cos($\theta$))\\
  choice: a = dv / dt\\
Q1: [subquestion] Can this question be answered step-by-step?\\
\#1: Yes.\\
Q2: [search] A particle of mass 6.8 * 10 ^ -5 g and charge 58 mC moves in a region of space where the electric field is uniform and is 7.2 N/C in the x direction and zero in the y and z direction. If the initial velocity of the particle is given by vy = 1.7 * 10 ^ 6 m/s, vx = vz = 0, what is the speed of the particle at 0.7 s?\\
\#2: v = dx / dt A particle of mass 6.6 × 10-5 g and charge 22 mC moves in a region of space where the electric field is uniform and is 5.6 N/C in the x direction and zero ...\\
Q3: [compare] Which option is the answer in \#2 most similar to?\\
\#3: v = dx / dt\\
Q4: [EOQ]\\
Ans: v = dx / dt\\
    \midrule
    After \\
    \midrule
% Input: Identify the physics formula that would be most useful for finding the answer to each of the following word problems. A proton is located at A, 1.0 m from a fixed +2.2 *10^-6 C charge. If the proton started from rest at A, what would be its speed at B?\\
%   choice: U_E = k * q * q / r\\
%   choice: v = $\lambda$ * f\\
%   choice: K = 1/2 * m * v ^ 2\\
%   choice: dv = a * dt\\
% Q1: [subquestion] What quantity is being asked for in "A proton is located at A, 1.0 m from a fixed +2.2 *10^-6 C charge. If the proton started from rest at A, what would be its speed at B?"\\
% \#1: The speed of the proton.\\
% Q2: [subquestion] What other information is given in "A proton is located at A, 1.0 m from a fixed +2.2 *10^-6 C charge. If the proton started from rest at A, what would be its speed at B?"\\
% \#2: Distance (1.0m), charge(+2.2 *10^-6 C), initial speed (0)\\
% Q3: [search] Given Distance, charge and initial speed, what can we compute for proton? Give the physics formula.\\
% \#3: Given the distance, charge, and initial speed of a proton, you can compute the total energy of the proton. From Eq. 2.3, the magnitude of the E field due to a point charge q at a distance r is given by. E = k|q| r2. Here we are given E and r, so we can solve for ...\\
% Q4: [compare] What is the physics formula in the choices that is closest to E = k|q| r2.\\
% \#4: U_E = k * q * q / r\\
% Q5: [EOQ]\\
% Ans: U_E = k * q * q / r\\
% ----\\
Input: Identify the physics formula that would be most useful for finding the answer to each of the following word problems.A particle of mass 6.8 * 10 ^ -5 g and charge 58 mC moves in a region of space where the electric field is uniform and is 7.2 N/C in the x direction and zero in the y and z direction. If the initial velocity of the particle is given by vy = 1.7 * 10 ^ 6 m/s, vx = vz = 0, what is the speed of the particle at 0.7 s?\\
  choice: F = m * a\\
  choice: v = dx / dt\\
  choice: E = q / ($\epsilon$ * A * cos($\theta$))\\
  choice: a = dv / dt\\
Q1: [subquestion] What quantity is being asked for in "A particle of mass 6.8 * 10 ^ -5 g and charge 58 mC moves in a region of space where the electric field is uniform and is 7.2 N/C in the x direction and zero in the y and z direction. If the initial velocity of the particle is given by vy = 1.7 * 10 ^ 6 m/s, vx = vz = 0, what is the speed of the particle at 0.7 s"\\
\#1: speed of the particle\\
Q2: [subquestion] What other information is given in "A particle of mass 6.8 * 10 ^ -5 g and charge 58 mC moves in a region of space where the electric field is uniform and is 7.2 N/C in the x direction and zero in the y and z direction. If the initial velocity of the particle is given by vy = 1.7 * 10 ^ 6 m/s, vx = vz = 0, what is the speed of the particle at 0.7 s"\\
\#2: mass of particle (6.8 * 10 ^ -5 g), charge(58 mC), electric field (7.2 N/C), initial velocity (vy = 1.7 * 10 ^ 6 m/s, vx = vz = 0)\\
Q3: [search] Given mass of the particle, charge and initial velocity of particle, and electric field, what can we compute for the particle? Give the physics formula.\\
\#3: \\
We can compute acceleration of the particle, as follows:\\
a = (q/m) * E\\
This formula is derived from the Lorentz force law, which states that the force (F) on a particle of charge q in an electric field E is given by the equation:\\
F = ma = qE\\
Q4: [subquestion] What is the physics formula in the choices that is closest to F = ma = qE, a = (q/m) * E\\
\#4: F = m * a\\
Q5: [EOQ]\\
Ans: F = m * a\\
    \bottomrule
    \end{tabularx}
    \caption{Human feedback: Physics}
    \label{tab:hf:physics}
\end{table*}


\begin{table*}[]
    \centering
    \small
    \begin{tabularx}{\linewidth}{ X }
    \toprule
        Temporal sequences \\
    \midrule
    Before \\
    \midrule
Input: Today, Tiffany went to the swimming pool. Between what times could they have gone?\\
We know that: \\
Tiffany woke up at 6am.\\
Jessica saw Tiffany waiting at the airport from 6am to 10am.\\
William saw Tiffany attending class at the school from 12pm to 5pm.\\
David saw Tiffany walking towards the Statue of Liberty from 5pm to 6pm.\\
James saw Tiffany reading at the library from 6pm to 8pm.\\
The swimming pool was closed after 8pm.\\
Between what times could Tiffany have gone to the swimming pool?\\
  choice: 12pm to 5pm\\
  choice: 6pm to 8pm\\
  choice: 10am to 12pm\\
  choice: 6am to 10am\\
Q1: [think step-by-step]\\
\#1: Let’s think step-by-step. Tiffany went to the swimming pool today. We need to find out when she could have gone.\\
- Tiffany woke up at 6am.\\
- Jessica saw Tiffany waiting at the airport from 6am to 10am.\\
- William saw Tiffany attending class at the school from 12pm to 5pm.\\
- David saw Tiffany walking towards the Statue of Liberty from 5pm to 6pm.\\
- James saw Tiffany reading at the library from 6pm to 8pm.\\
- The swimming pool was closed after 8pm.\\
The swimming pool was closed after 8pm, so Tiffany couldn’t have gone at 6pm to 8pm. She was reading at the library from\\
6pm to 8pm, so she couldn’t have gone at 10am to 12pm. She was waiting at the airport from 6am to 10am, so she couldn’t\\
have gone at 6am to 10am. That leaves 12pm to 5pm. So the answer is 12pm to 5pm.\\
Q2: [EOQ]\\
Ans: 12pm to 5pm\\
    \midrule
    After \\
    \midrule
Q1: [subquestion] Is Tiffany free 12pm to 5pm?\\
\#1: No, she is attending classes at the school.\\
Q2: [subquestion] Is Tiffany free 6pm to 8pm?\\
\#2: No, she is reading at the library.\\
Q3: [subquestion] Is Tiffany free 10am to 12pm?\\
\#3: Yes, there is no other activity in her scehdule.\\
Q4: [subquestion] Is Tiffany free 6am to 10am?\\
\#4: No, she is waiting at the airport.\\
Q5: [subquestion] Is the swimming pool open from 10am to 12pm?\\
\#5: Yes, the swimming pool is open from 10am to 8pm.\\
Q6: [get answer] In conclusion, when should she go to the swimming pool?\\
\#6: Tiffany should go to the swimming pool from 10am to 12pm.\\
Q7: [EOQ]\\
Ans: 10am to 12pm\\
    \bottomrule
    \end{tabularx}
    \caption{Human feedback: Temporal sequences}
    \label{tab:hf:temporal_sequences}
\end{table*}


\begin{table*}[htb!]
    \centering
    \small
    \begin{tabularx}{\linewidth}{ X }
    \toprule
    Tracking shuffled objects \\
    \midrule
    Before \\
    \midrule
Input: Alice, Bob, Claire, Dave, and Eve are playing a game. At the start of the game, they are each holding a ball: Alice has a pink ball, Bob has a white ball, Claire has a red ball, Dave has a purple ball, and Eve has a yellow ball. \\
As the game progresses, pairs of players trade balls. First, Alice and Dave swap balls. Then, Claire and Eve swap balls. Then, Alice and Bob swap balls. Then, Dave and Claire swap balls. Finally, Alice and Claire swap balls. At the end of the game, Claire has the\\
Q1: [generate python code] write down the arithmetic or algebra equations as python code, storing the answer as 'ans'\\
\#1:\\
Alice = "pink"\\
Bob = "white"\\
Claire = "red"\\
Dave = "purple"\\
Eve = "yellow"\\
Alice_and_Dave = [Alice, Dave]\\
Claire_and_Eve = [Claire, Eve]\\
Alice_and_Bob = [Alice, Bob]\\
Dave_and_Claire = [Dave, Claire]\\
Alice_and_Claire = [Alice, Claire]\\
ans = Claire\\
print(ans)\\
Q2: [code execute] Execute the python code and get the value of "ans"\\
\#2: red\\
Q3: [EOQ]\\
Ans: red\\
    \midrule
    After \\
    \midrule
Q1: [generate python code] write down the arithmetic or algebra equations as python code, storing the answer as 'ans'\\
\#1:\\
players = ['Alice', 'Bob', 'Claire', 'Dave', 'Eve']\\
balls = ['pink', 'white', 'red', 'purple', 'yellow']\\
swap_list = [[0, 3], [2, 4], [0, 1], [3, 2], [0, 2]]\\
for swap in swap_list:\\
$\quad$balls[swap[0]], balls[swap[1]] = balls[swap[1]], balls[swap[0]]\\
ans = [players[i] + ' has a ' + balls[i] for i in range(5)]\\
print(ans)\\
Q2: [code execute] Execute the python code and get the value of "ans"\\
\#2: ['Alice has a pink', 'Bob has a purple', 'Claire has a white', 'Dave has a yellow', 'Eve has a red']\\
Q3: [subquestion] At the end, what color does Claire have?\\
\#3: white\\
Q3: [EOQ]\\
Ans: white \\
    \bottomrule
    \end{tabularx}
    \caption{Human feedback: Tracking shuffled objects}
    \label{tab:hf:shuffled_objects}
    \begin{tabularx}{\linewidth}{ X }
    \toprule
    Tracking shuffled objects \\
    \midrule
    Before \\
    \midrule
Input: The word illoctnecos is a scrambled version of the English word \\
Q1: [string split] What are the letters in "illoctnecos"?\\
\#1: ["i", "l", "l", "o", "c", "t", "n", "e", "c", "o", "s"]\\
Q2: [string permutation] What are the possible permutations of the letters in \#1?\\
\#2: ["i", "l", "l", "o", "c", "t", "n", "e", "c", "o", "s"], ["i", "l", "l", "o", "c", "t", "n", "e", "o", "c", "s"], ["i", "l", "l", "o", "c", "t", "e", "n", "c", "o", "s"], ["i", "l", "l", "o", "c", "t", "e", "n", "o", "c", "s"], ["i", "l", "l", "o", "c", "n", "t", "e", "c", "o", "s"], ... \\
Q3: [string check] Among the permutations in \#2, which one is an English word?\\
\#3: ["i", "l", "l", "o", "c", "t", "n", "e", "c", "o", "s"]\\
Q4: [EOQ]\\
Ans: ["i", "l", "l", "o", "c", "t", "n", "e", "c", "o", "s"]\\
    \midrule
    Word Unscrambling: After \\
    \midrule
Q1: [string split] What are the letters in "illoctnecos"?\\
\#1: ["i", "l", "l", "o", "c", "t", "n", "e", "c", "o", "s"]\\
Q2: [string permutation] What are the possible permutations of the letters in \#1?\\
\#2: ["illoctnecos", "illoctneocs", "illoctenocs", "illoctencos", "illotnencos", ...]\\
Q3: [word lookup] Among the permutations in \#2, which one is an English word?\\
\#3: collections \\
Q4: [EOQ]\\
Ans: collections \\
    \bottomrule
    \end{tabularx}
    \caption{Human feedback: Word Unscrambling}
    \label{tab:hf:word_unscrambling}
\end{table*}


% \begin{table*}[htb!]
%     \centering
%     \small
%     \begin{tabularx}{\linewidth}{ X }
%     \toprule
%     Tracking shuffled objects \\
%     \midrule
%     Before \\
%     \midrule
% Input: The word illoctnecos is a scrambled version of the English word \\
% Q1: [string split] What are the letters in "illoctnecos"?\\
% \#1: ["i", "l", "l", "o", "c", "t", "n", "e", "c", "o", "s"]\\
% Q2: [string permutation] What are the possible permutations of the letters in \#1?\\
% \#2: ["i", "l", "l", "o", "c", "t", "n", "e", "c", "o", "s"], ["i", "l", "l", "o", "c", "t", "n", "e", "o", "c", "s"], ["i", "l", "l", "o", "c", "t", "e", "n", "c", "o", "s"], ["i", "l", "l", "o", "c", "t", "e", "n", "o", "c", "s"], ["i", "l", "l", "o", "c", "n", "t", "e", "c", "o", "s"], ... \\
% Q3: [string check] Among the permutations in \#2, which one is an English word?\\
% \#3: ["i", "l", "l", "o", "c", "t", "n", "e", "c", "o", "s"]\\
% Q4: [EOQ]\\
% Ans: ["i", "l", "l", "o", "c", "t", "n", "e", "c", "o", "s"]
%     \midrule
%     Word Unscrambling: After \\
%     \midrule
% Q1: [string split] What are the letters in "illoctnecos"?\\
% \#1: ["i", "l", "l", "o", "c", "t", "n", "e", "c", "o", "s"]\\
% Q2: [string permutation] What are the possible permutations of the letters in \#1?\\
% \#2: ["illoctnecos", "illoctneocs", "illoctenocs", "illoctencos", "illotnencos", ...]\\
% Q3: [word lookup] Among the permutations in \#2, which one is an English word?\\
% \#3: collections \\
% Q4: [EOQ]\\
% Ans: collections \\
%     \bottomrule
%     \end{tabularx}
%     \caption{Human feedback: Word Unscrambling}
%     \label{tab:hf:word_unscrambling}
% \end{table*}