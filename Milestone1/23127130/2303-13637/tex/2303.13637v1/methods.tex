\section{Compound and Direct HRV Estimation}
\label{sec:method}

In this section, we present our signal processing and machine learning combined method for direct HRV estimation.
% Firstly, the monitor system is introduced and we show each system module. 
% Then we illustrate the methodology for HR and HRV estimation separately. 
% More specifically, for HR estimation, we present our method to predict HR using the ISPC dataset and our collected data.
% For HRV estimation, since ISPC data length is about 5 minutes, which is too short for HRV calculation that we cannot obtain enough HRV samples for ML, we present our method to estimate HRV based on our collected data only.

% There are three approaches to calculating HR. 
% The conventional approach is calculating HR based on the ECG RR intervals.
% The second approach is to obtain HR directly from the PPG signal.
% Likewise, we concentrate on the third approach which exploits ML to estimate HR based on PPG HR.
% The ML algorithm takes the PPG HR obtained in the second approach as features and ECG HR in the first approach as labels, trying to estimate HR with higher accuracy.

% There are three approaches to calculating HRV. 
% The traditional and the most accurate approach is using an ECG to obtain ECG RR intervals, and then calculate HRV based on the ECG RR intervals.
% The second approach is using PPG. 
% We first obtain HR from the PPG signal, and then derive RR intervals based on the HR. 
% After that, we calculate PPG HRV based on the PPG RR intervals.
% The third approach is what we focused on and tried to optimize, utilizing ML to estimate HRV based on the PPG signal.
% The ML algorithm takes the PPG HR and PPG HRV in the second approach as features and ECG HRV in the first approach as labels, trying to improve the accuracy of HRV estimation in the second method.

\subsection{Data Collection}~\label{sec:data_collection}
A single HRV estimation typically requires 30 seconds to 5 minutes of PPG/ECG monitoring~\cite{acharya2006heart}. Moreover, typically, a sequence of five minutes to 24 hours of HRV data is used in medical practice~\cite{2012-Xhyheri-HRVToday}. Therefore, studying HRV estimation requires hours of PPG/ECG monitoring data to provide enough data points. As there lack of such public datasets, our first task in this research was to collect longer traces of PPG and ECG data.

One subject participated in this data collection. The subject had a PPG sensor attached to the fingertip and an ECG monitor attached to the chests at the same time. The PPG data were collected as features/inputs for the HRV inference, whereas the ECG data were used as the labels for model training and as the groundtruth in model testing/evaluation. To reduce the energy consumption caused by the PPG sensors, we collected PPG readings at a frequency of 25Hz, rather than the 125Hz used by the ISPC dataset and other studies~\cite{zhang2015photoplethysmography,bashar2019machine,puranik2019heart,chang2021deepheart}.

The subject conducted three activities during the data collection, including sitting, sleeping, and office work. The office work activity includes actions such as working in front of a computer, walking, and drinking water. For each activity, more than two hours of PPG/ECG data were collected, which gave about 180193 to 180271 PPG readings per activity.
% the total number of signals in our experiment is 180271 PPG signals for sit, 180193 for sleep, and 180227 for daily
\subsection{Workflow for HRV Inference}

\begin{figure*}
  \centering
  \includegraphics[width=0.8\linewidth]{pic/HRV_workfflow.pdf}
  \caption{The workflow of our compound and direct HRV inference.}
  \label{fig:stage2}
\end{figure*}

Figure~\ref{fig:stage2} gives the overall workflow of our HRV inference methodology. This workflow includes three major steps, PPG data collection, signal processing, and machine learning-based HRV inference. The following paragraphs provide a detailed description of each step.

\subsubsection{Step 1: PPG Monitoring} 
As our HRV inference is based on PPG sensors, the first step is to collect the PPG light signals reflected from the blood flow. Here, we employed a sampling rate of 25Hz, i.e., 25 signals are collected every second. This sampling rate is lower than the 125Hz used by many prior studies~\cite{zhang2015photoplethysmography,bashar2019machine,puranik2019heart,chang2021deepheart}, and it is employed to reduce the power consumption of sensing, as prior work~\cite{bhowmik2017novel} has shown that high sampling frequency incurs high power usage. Low sampling frequency, however, may negatively affect HRV inference accuracy. As discussed later, we rely on signal processing and machine learning to compensate for this negative accuracy impact. Let $\{l_1, l_2, l_3, \dots, l_{25n}\}$ denotes the sequence of the $25n$ light signals over $n$ seconds. These signals are fed to step 2 for processing.

\subsubsection{Step 2: Signal Processing} 
The primary goal of our signal processing is to remove the noises due to motion artifacts with outlier adjustment and data smoothing. The secondary goal of our signal processing is to generate HR estimations to be used later as features for ML models.

\textbf{Step 2.1: Signal Processing to Generate HR Estimations}. In this step, we convert the PPG light signals collected in Step 1 into four heart rate estimations per second using signal processing. This processing essentially applied a peak detection algorithm to the PPG signals. These peaks can be viewed as "heartbeats", and hence, their counts can be used to estimate HR \cite{ppg_allen2007photoplethysmography}. After this conversion, there are $4n$ HR estimations over $n$ seconds, denoted as $\{HR_1, HR_2, HR_3, \dots, HR_{4n}\}$.

This conversion serves two purposes. First, this conversion simplifies the noise removal (i.e., outlier adjustment and smoothing) conducted later. Motion artifacts typically affect a sequence of PPG light signals, and it can be challenging to distinguish erratic signals from real HR fluctuations when working on raw signals. Converting to HR estimations reduces the number of data points, making it easier for noise removal. Second, these converted HRs are also used as the features of our ML models in Step 3.
%, since HRV is just a variation of HRs. 

\textbf{Step 2.2: Z-score Based Outlier Adjustment}. Many noisy signals can be simply viewed as outliers. Therefore, outlier identification algorithms can be used to remove these signal noises. More specially, we applied the popular Z-score-based outlier filter algorithm~\cite{zscore1_mendenhall2016statistics, zscore2_spiegel2018schaum}.

The Z-score filter identifies the outliers by picking out the data points that deviate the most from the mean. Concretely, consider a large sequence of HR estimations, $\{HR_1, HR_2, \dots\}$, with mean $\mu$ and standard deviation $\delta$. If the difference between a data point $HR_i$ and $\mu$ ( i.e., $|HR_i-\mu|$) is larger than a threshold, then $HR_i$ can be viewed as an outlier. This threshold is typically defined based on the standard deviation $\delta$. Particularly, the threshold is defined as $z\_score\times\delta$. In this work, we used a z\_score of $3$, following common practices~\cite{zscore3_zhang2011illustration, zscore4_vysochanskij1980justification}. That is, if the difference between HR estimation $HR_i$ and the mean $\mu$ is larger than $3\delta$, then $HR_i$ is deemed as an outlier.

 We do not remove outliers because HR estimations are time series, and removing estimations would create "holes" within the time series. Consequently, after the outliers are identified, their values are just adjusted to be the average of their neighboring estimations. That is, given an outlier $HR_i$, its value is adjusted to be $\frac{HR_{i-1} + HR_{i+1}}{2}$.
 
 \textbf{Step 2.3: Data Smoothing}. The above outlier adjustment only identifies data points with large noises, i.e., data points deviate greatly from the overall mean. However, there could still be HR estimations that deviate significantly from local HR averages. These deviating HR estimations usually manifest themselves as abnormal local peaks/valleys. These local peaks/valleys are usually caused by signal noises, because normally, a person's heart rate does not increase (or drop) abruptly and drops (or increases) back within one second. 
 
 To remove these local noises, we apply moving average data smoothing. More specifically, this data smoothing converts the four rough HRs within a second into one HR estimation per second by computing their averages to reduce the impact of the abnormal local peaks and valleys.
 After the smoothing, there are $n$ smoothed HR estimations over $n$ seconds, denoted by $\{sHR_1, sHR_2, sHR_3, \dots\, sHR_n\}$. 
 
 % The first operation converts the four rough HRs within a second into one HR estimation per second by computing their averages. The second operation limits the neighboring HR fluctuations to only 5\%. This limitation is applied based on our observations with the ground truth ECG data, where two consecutive ECG HRs never differ by more than 5\%. Intuitively, this limitation reflects the fact that HR does not abruptly change within only two seconds. Hence, in our data smoothing, if an HR estimation is more than 5\% higher/lower than its previous HR, then it is reduced to 5\% higher/lower than the previous HR. After the smoothing, there are $n$ smoothed HR estimations over $n$ seconds, denoted by $\{sHR_1, sHR_2, sHR_3, \dots\, sHR_n\}$. 

\subsubsection{Step 3: ML-based HRV Inference}\label{sec:ml_hrv_models} 
The last step of our methodology employs ML to infer HRV. As stated previously, the ML models are trained to serve two purposes simultaneously. First, they are trained to further remove/reduce the noises that cannot be filtered by signal processing. These additional noises may include long motion artifacts that affect several seconds of PPG signals, the sensor bias (e.g., sensor sensitivity and calibration issues), and
the errors due to our low sampling frequency. Second, with further reduced noises, these ML models estimates the final HRV. These models directly infer SDNN/RMSSD, instead of the RR intervals.

The main input features to the ML models are the smoothed HR estimations over $n$ seconds from Step 2, i.e., the vector $\{sHR_1, sHR_2, sHR_3, \dots\, sHR_n\}$. These smoothed HR estimations are also used to derive a rough HRV (SDNN or RMSSD) estimation, denoted by $rHRV$, using the Equations~(\ref{eq:sdnn}) and~(\ref{eq:rmssd}). This rough HRV is used as a constructed feature for our ML models. As shown with Equations~(\ref{eq:sdnn}) and~(\ref{eq:rmssd}), computing HRV requires exponentiation and square root operations, which may require large ML models to simulate. Therefore, employing a computed rough HRV estimation as a feature can potentially reduce the trained model size. 

In summary, the features of our ML models are the vector,
$\{sHR_1, sHR_2, sHR_3, \dots\, sHR_n, rHRV\}$. The output of our models is the HRV estimation for the past $n$ seconds in SDNN or RMSSD. Note that, $n$ represents the number of seconds of PPG monitoring, which is a tuneable parameter depending on the HRV use case. In the experimental evaluation (Section~\ref{sec:Evaluation}), we evaluated different values for $n$.

\subsection{Model Training}
During our PPG data collection (described in Section~\ref{sec:data_collection}), the subject also had an ECG attached to collect groundtruth HRV readings. The groundtruth HRVs are used both as the labels in the training data and validation/testing data. 

We partitioned the collected data into training and testing datasets with a split of 80\% and 20\%. All models were also optimized with hyperparameter tuning~\cite{bergstra2012random} to find the model with the best accuracy. The specific hyperparameters for each type of model are given in Section~\ref{sec:hyperparams}. Note that, we limited hyperparameter search space to avoid generating models that are too large for small embedded devices.



%The collected datasets are then partitioned into training and testing datasets, with a split of 80\% and 20\%, respectively. All ML models also went through random search-based hyperparameter tuning~\cite{bergstra2012random} to find the best model.


% \subsection{PPG based monitor system}\label{sec:ppg_system}

% %In this section, we present the details of our monitor system.
% %The monitor system architecture is shown in Fig.\ref{fig:system}.
% \begin{figure}
%   \centering
%   \includegraphics[width=1\linewidth]{pic/systemv6.pdf}
%   \caption{The architecture of the PPG-based monitor system.}
%   \label{fig:system}
% \end{figure}

% Fig.\ref{fig:system} shows the architecture of our HR/HRV monitoring system, which has four stages.
% In stage 1, data collection modules collect the PPG signals. Here, a PPG sensor is attached to the subject's fingertip, which outputs red and infrared light signals.
% In stage 2, the data processing module reduces noises in PPG data and generates rough estimations for HR and HRV.
% %, ECG HR, and ECG HRV for the next stage. 
% In Stage 3, an ML module takes the rough HRs/HRVs to produce more accurate HR/HRV estimations.
% Finally, in stage 4, a report module reports the estimated HRs or HRVs to users or saves them to the cloud for further analysis. 
% The rest of this section provides a detailed description of stages 2 and 3.

% \subsection{HR and HRV Estimation}

% Figure~\ref{fig:stage2} provides the detailed processing steps of our HR monitoring system, which are described as follows.

% \subsubsection{Signal Processing based HR Estimation (stage 2)}
% \paragraph{PPG Data collection (step a1)}
% The data generated by PPG are time-series signals, which show the light signal reflected by blood under the skin. Let [$s_1$, $s_2$, $s_3$, ..., $s_{25}$] denotes a sequence of light signals. 
% We employed a sampling rate of 25 Hz, i.e., 25 signal samples every second.

% \paragraph{Initial HR estimation (step a2.1 and a2.2)}
% The processing in step a2.1 %a script is used to extract PPG HR. 
% %Based on the principle of PPG sensor works for obtaining heart rate, 
%  takes the PPG light signals from step a1, finds the local peaks within the light sequence, and then calculated by counting the number of peaks to estimate HR~\cite{ppg_allen2007photoplethysmography}. Our current script converts 25 signals in a second to 4 HR estimations for that second (step a2.2).
% %The output of step a2.1 is the calculated PPG HR, as shown in a2.2.

% %\subsubsection{Initial HR outlier removal (step a2.3 and step a2.4)}

% %to PPG HR to make it more reliable, stable, and less noisy. 

% \paragraph{Z-score outlier filter (step a2.3)}
% %The input for the Z-score filter is the PPG HR data in step a2.2, which was derived by the HR calculation algorithm based on the PPG raw signal data, and has a sample rate of \TODO{4Hz}. 
% Due to motion artifact (MA), there may be large noises in PPG signals, leading to outliers in the initial HR estimations from step a2.1. To eliminate these outliers, a Z-score outlier filter is applied.

% Z-score filter is a popular method used to find outliers. Given a data point, its z-score represents the distance (i.e., deviation) between its value and the mean of all data points, measured by multiples of standard deviation ($std$)~\cite{zscore1_mendenhall2016statistics, zscore2_spiegel2018schaum}. For example, if a data point's z-score is 3, then the difference between this data point and the mean is $3\times std$.
% Therefore, if the z-score (i.e., distance) is larger than a threshold, then the data point can be viewed as an outlier. 
% Here, we set the threshold z-score to 3 following common practice~\cite{zscore3_zhang2011illustration, zscore4_vysochanskij1980justification}. 

% However, we cannot simply remove the outliers because HR is a time series. Deleting any values will possibly lose the time-related information. Therefore, we choose to revise the outliers' value to be the average of their two surrounding HR estimations.

% \paragraph{Smoothing (step a2.3)}
% Even after the Z-score filter, there still could be abrupt peak or valley HR estimations that are overly higher or lower than its surrounding estimations due to PPG signal noises,
% Therefore, to further reduce the PPG HR fluctuation, we applied additional data smoothing. 

% To smooth, we first take an average of the four HR estimations within a second to convert them into one HR per second. This smoothing removes fluctuations in the estimations within a second. It also reduces the number of HRs to be input to the ML models in stage 3.

% Moreover, normally, a person's HR does not change abruptly in one second and returns back in the next second. That is, an HR estimation should not be significantly different than the HRs before and after it. Hence, it is possible to smooth the HR estimations based on a specific upper and lower boundary to further restrict the PPG HR fluctuation. In our experiment, we set the boundary to 5\%. That is, an HR estimation can only be less than or equal to 5\% above or below its predecessor.
% For HR estimations that are more than 5\% higher (or lower) than the previous value, their values are changed to be 5\% higher (or lower) than the previous value. This 5\% boundary is determined based on the fluctuation range monitored from the more reliable ECG data.

% \subsubsection{ML-based HR/HRV Estimation (stage 3)}\label{sec:ml_estimation}
% \paragraph{ML-based HR Estimation (step a3.1)}
% Finally, the rough HR estimations generated by signal processing (denoted as PPG-HR) in stage 2 are passed to an ML model to generate a more accurate HR estimation. As our PPG sensor samples at 25Hz preserve energy, the PPG-HRs from these samples may still contain large errors. The ML model is particularly trained to reduce errors due to the low sampling frequency. 

% More specifically, the ML model takes a sequence of the last $k$ PPG-HR estimations to generate the current HR estimation. Intuitively, the ML model uses these $k$ PPG-HRs to assess the potential errors in them to produce a more accurate HR estimation. We evaluated different values for $k$ in our experiments. We also evaluated different types of ML models, including Decision Tree (DT), Random Forest (RF), K-nearest neighbor (KNN), Support vector machines (SVM), and Multi-layer Perceptron (MLP). These evaluation results are reported in Section~\ref{sec:Evaluation}.

% \paragraph{ML-based HRV Estimation (step a3.1)}
% Similar to the HR estimation, an ML model is trained to estimate the HRV based on the last $k$ PPG-HR estimations. As stated previously, this ML model directly generates HRV estimation, instead of estimating RR intervals and using RR intervals to compute HRV. We also evaluated different values of $k$ and different types of ML models, which are reported in Section~\ref{sec:Evaluation}.

% We directly predict HRV because errors in RR interval estimations tend to amplify when they are converted to HRV. As shown in Equations~\ref{eq:sdnn} and~\ref{eq:rmssd}, computing HRV requires computing the square of the differences between RR intervals, which easily amplifies the errors of RR intervals. 

% To further illustrate this error amplification, we conducted a simulation with different RR interval errors and computed their corresponding HRV errors, which are given in Table~\ref{tab:rr_vs_hrv}.
% As shown in Table \ref{tab:rr_vs_hrv}, if the RR has 1\% MAPE (mean average percentage error), the calculated RMSSD will have MAPE 5.76\%.
% And if the RR has MAPE 3\%, the corresponding RMSSD will have a MAPE of 38.43\%, which is too large and not acceptable.
% %This might be because the HRV calculation expands the error. 
% With this error amplification, even if the ML model achieves low MAPE when predicting RR interval, the calculated HRV may still be inaccurate.
% Therefore, it is better to use ML models to estimate HRV directly.

% \begin{table}
% \caption{RR error vs. calculated RMSSD HRV error.}
% \centering
% \renewcommand{\arraystretch}{1.5}
% \begin{tabular}{|c|c|}
% \hline
% RR MAPE & HRV RMSSD MAPE \\ \hline
% 1\%     & 5.76\%   \\ \hline
% 2\%     & 18.8\%   \\ \hline
% 3\%     & 38.43\%  \\ \hline
% 4\%     & 59.62\%  \\ \hline
% 5\%     & 87.66\%  \\ \hline
% \end{tabular}
% \label{tab:rr_vs_hrv}
% \end{table}

%Stage 1 is the same for both HR and HRV estimation.

% At the same time, an ECG is installed and running, which outputs a bin file that can be further analyzed with the software is provided.

% After that, stage 2 extracts PPG HR from PPG light signals, and extracts ECG RR with the ECG software from the ECG bin file.
% This stage will also apply some noise removal techniques to reduce the outliers in the PPG HR and ECG RR.
% Then PPG HRV is calculated based on PPG HR.
% And ECG HR and ECG HRV are calculated based on ECG RR.
% The output of this stage includes the PPG HR, PPG HRV, ECG HR, and ECG HRV, which will be the features and labels for ML models in the next stage.

% For the ML module, when we train the ML model and evaluate our system, we need the ECG data as labels. 
% For the HR prediction model, ECG HR is the label and for the HRV model, ECG HRV is the label.
% But when the system is deployed for users, there will be no ECG.
% The ML model will only take PPG data as input and give prediction results to users.
% For HR prediction, PPG HR is the features and for HRV prediction, PPG HR and PPG HRV are the features.
% Since HR and HRV estimation, and their processing flow are different, we will present more details about our HR and HRV estimation methodology separately in the following section.

% The conventional method to estimate HR from PPG is using the signal processing method. 
% Recently, ML is found to be a promising method to estimate HR from PPG because it is powerful in summarising patterns from big data.
% As shown in section \ref{sec:related_work}, for both existing signal processing-based work and existing ML-based work, the input is the PPG light signal. 
% Besides, the signal processing methods usually need accelerometer signals to better remove the motion artifacts in the PPG signals to make sure it can estimate HR more accurately.
% Similarly, some ML-based models also include accelerometer signals as input features. 
% However, the input feature size could be very large when it includes both PPG light signals and accelerometer signals, which could result in a heavy and complex algorithm/model.
% Moreover, complicated signal processing method usually requires a higher sampling rate which will cause a resource burden to the wearable device and edge device.
% In this work, we combine signal processing with ML - the input for the learning model is not a light signal but processed PPG HR.
% In this way, the ML can ease the burden of the signal processing algorithm, as the result the processing algorithm can be simpler, the PPG sensor sampling rate can be smaller for wearable device resource consumption, and the ML model size can be smaller because the input dimension is smaller.

% In this section, we present the HR estimation method we used for our collected data, and since the ISPC dataset is a popular dataset to evaluate the HR monitor system, we also consider the ISPC dataset in our HR estimation.
% First, we present how we collect our data and process it in stages 1 and stage 2.
% For the ISPC dataset, there is no collection stage.
% And since there are many great existing signal processing methods proposed for the ISPC dataset, we simplify the method in \cite{zhang2014troika} and use it as the processing method in stage 2.
% The ML module in stage 3 is similar to both our data and the ISPC data, hence we present the ML module at the end of this section.

% \subsubsection{Our Data Processing}
% \label{sec:method_hrstage2}

% The major purpose of stage 2 is to provide quality data for ML models.
% Therefore, we extract PPG HR from PPG light signal, remove noise and outliers, and feed the processed PPG HR into the ML model.
% The details is shown in Fig.\ref{fig:stage2}. 
% Firstly, the PPG device and ECG device recorded the PPG raw data and ECG raw data simultaneously and respectively in stage 1. 
% Once the recording is done, the PPG sensor will export the raw data that contains the red light and infrared light time-domain sequence as shown in step a1. 
% And the ECG will generate a bin file that contains the ECG signals as shown in step b1.

% Then, at the beginning of stage 2, a script is utilized to extract PPG HR as shown in step a2.1.
% Based on the theory of how the PPG sensor works for obtaining heart rate \cite{ppg_allen2007photoplethysmography}, the script will take the PPG light signal from step a1, find the local peaks during the light sequence, and then the PPG HR can be calculated by counting the number of peaks in 1 minute. 
% The output of step a2.1 is the calculated PPG HR, as shown in a2.2.
% Besides, as shown in step b2.1, the associate ECG analysis software will extract the RR interval from the ECG bin file in step b1, and generate the ECG RR in step b2.2.

% After that, to eliminate the HR outlier, a Z-score outlier filter (step a2.3) and a smoothing algorithm (step a2.4) are applied to PPG HR to make it more reliable, stable, and less noisy. 
% Similarly, we preprocess the ECG RR intervals to eliminate the outliers using the Z-score outlier filter (step b2.3) and calculate ECG HR based on the processed ECG RR interval (step b2.4). 
% Next, we normalize the processed PPG HR and sent it to the ML model in stage 3 along with the ECG HR as shown in steps a2.5 and b2.4.
% Finally, the ML model in step 3.1 will be trained and make predictions, and we obtain the estimation results in step 3.2.
% Details of the Z-score outlier filter and the smoothing algorithm are as follows.

% \paragraph{Z-score outlier filter}

% The input for the Z-score filter is the PPG HR data in step a2.2, which was derived by the HR calculation algorithm based on the PPG raw signal data, and has a sample rate of 4Hz. 
% The Z-score filter is a popular method used to find outliers.
% For a certain sample, its z-score absolute value represents the distance between its value and the mean of all samples' values in the units of standard deviation \cite{zscore1_mendenhall2016statistics, zscore2_spiegel2018schaum}.
% If the distance is too large, we consider it to be an outlier.
% Therefore, we can locate outliers after we set a distance threshold, which usually is set to 3 \cite{zscore3_zhang2011illustration, zscore4_vysochanskij1980justification}. 

% After locating the outliers, we cannot just remove them because HR is a time-domain series data and simply deleting any values will possibly lose the time-related information.
% Hence, in this paper, we revise the outliers' value to be the average value of their surrounding samples.

% \paragraph{Smoothing}

% After the Z-score filter, the PPG HR sample rate is still 4Hz, which means there are four HR readings per second.
% To pair the PPG HR to the ECG HR, which has 1 reading per second, we designed a smoothing algorithm as shown in step a2.4 to reduce the PPG HR sampling rate to be the same as ECG data and in the meantime further reduce the PPG HR fluctuation.

% The smoothing algorithm consists of two parts. 
% The first part is to discard a specific number of maximum and minimum values in a subset of data and take the average of the remaining samples and use that average value as the reading.
% In our experiment, we choose the 4 samples in the same second as a subset and do not discard any value because 4 is already a small number and we want to keep the processing algorithm to be simple to make sure it can run fast on the resource-limited edge device.
% But the subset ranges can be extended to longer time horizons if desired.
% After this, there will be one PPG HR reading every second.

% The second part is to adjust the data value based on a specific upper and lower boundary to further restrict the PPG HR fluctuation.
% The limitation can be a percentage or an absolute difference.
% And the boundary threshold can be determined by the fluctuation of ECG data, or by a given value. 
% In our experiment, we set the boundary to 5\%, this means a sample can only be less than or equal to 5\% above or below its predecessor.
% For outliers that are more than 5\% higher or lower than the previous value, we change their value to be 5\% higher or lower than the previous value.

% \subsection{Model Training}
% During our PPG data collection (described in Section~\ref{sec:data_collection}

% As discussed previously, the features of our ML models are $k$ last PPG-HR estimations, i.e., the PPG-HR estimations from the last $k$ seconds given one PPG-HR per second. The labels (i.e., ground truth HR/HRV) are obtained by ECG. During data collection, our subject wears the PPG monitoring system (described in Section~\ref{sec:ppg_system} and ECG electrodes at the same time for data recording. Hence, the ECG can provide ground truth HR/HRV for corresponding PPG signals and PPG-HRs. The subject engaged in three activities, sitting, sleeping, and conducting daily activities. The daily activity includes office working, walking, drinking water, etc. Each recording lasted for 2 hours.

% The collected datasets are then partitioned into training and testing datasets, with a split of 80\% and 20\%, respectively. All ML models also went through random search-based hyperparameter tuning~\cite{bergstra2012random} to find the best model.

% \subsubsection{ISPC datasets and Model Training}
% To show that the accuracy benefit from our combined signal processing and ML method is generic, we also applied our method to a popular PPG HR monitoring dataset, denoted as the ISPC dataset~\cite{zhang2014troika}. This dataset provides raw PPG signals at 125Hz along with ground truth HR readings. Hence, it can be directly applied to signal processing and ML model training.

% Note that, because ISPC datasets used a different PPG sensor, our signal processing steps cannot be applied to it. Therefore, we applied the signal processing steps in the original paper of the ISPC dataset~\cite{zhang2014troika}. Moreover, because the source code of the ISPC dataset's signal processing is not publicly released, and because of the potential changes of the dataset after its publication, the HR estimation errors from our reproduced signal processing are not completely the same as those in the original paper~\cite{zhang2014troika}. Additionally, the ISPC dataset does not have HRV readings, and hence, can only be used to evaluate HR estimations.

% \subsubsection{ISPC Data Processing}

% The experiment flow is similar to ISPC data except that the data processing method is different.
% Since our data are collected under different settings, for example, our subjects engaged in light activity, while ISPC subjects engaged in vigorous exercise thus there are more motion artifacts in ISPC data, and the processing algorithm for our data cannot be applied to ISPC data. 
% Therefore, we designed a different stage 2 processing algorithm for the ISPC data.

% % There is a more intensive activity in ISPC data, hence more motion artifacts that need to be removed.
% Many existing signal processing methods were proposed for the ISPC dataset and worked well, but they tend to be complex.
% In this work, since we are combining the signal processing method with ML, we can let the ML model share the burden and thus simplify the signal processing algorithm.
% Inspired by the TROIKA \cite{zhang2014troika}, we designed a similar but simpler algorithm to process PPG signals and obtain PPG HR. 
% The algorithm contains four steps: bandpass, decomposition, reconstruction, and verification. 
% The bandpass and decomposition steps are similar to TROIKA. 
% The main difference between our ISPC data processing algorithm and TROIKA is in the reconstruction and verification phase.

% \paragraph{Reconstruction}

% In TROIKA, they proposed and performed the temporal difference algorithm and the FOCUSS algorithm. 
% However, in our work, we just identify the motion artifacts by applying the periodogram function to the decomposed signals and removing the noise.

% \paragraph{Verification}

% In TROIKA, they implemented 2 rules for the verification. 
% The first rule is used to prevent a large change in the estimated HR values in 2 successive time windows. 
% The second rule is to prevent losing tracking HR over a long time. 
% However, in our work, we only use the first rule because the second rule requires a lot of extra memory and computation.

% \subsubsection{ML method for HR}

% Once the ECG data and PPG data are possessed, the ML model in stage 3 can be trained and tested with them. 
% The input data for the ML model contains many rows, and each row is an instance of the ML algorithm. 
% Each row contains the data to predict HR for one second, which includes several PPG HR for that second and before, and one ECG HR for that second.
% For each instance, the PPG HR is the features, and the ECG HR is the label.
% Here, the size of the features, i.e. the number of historical PPG HR used, is a parameter that we can tune. 
% In section \ref{sec:Evaluation}, we investigate the effect of the different numbers of historical PPG HR on estimation accuracy.

% The output of the ML model is the predicted HR for that second. 
% We can evaluate the estimation accuracy by comparing the predicted HR with the label.
% In the experiment, features, and labels will be split into a training set and a testing set, and different ML algorithms will be trained on the training set and evaluated with the testing set.

% \subsection{HRV Prediction}

% In this section, we show our methodology to evaluate HRV from PPG data.
% Since ISPC data is too short for HRV calculation, we use our collected data for HRV estimation only.
% Firstly, we give proof of why we predict HRV instead of RR interval like the existing works do.
% Then, we present details of the monitor system.
% Since the stage 1, data collection module is similar to the HR prediction, we mainly focus on stage 2, the processing module, and stage 3, the ML module.

% \subsubsection{HRV estimation vs. RR estimation}
% \label{sec:method_hrv_vs_rr}
% In this section, we prove that although we can predict RR with a small error, the calculated HRV still has a large error and as the result, we should predict HRV directly and optimize HRV instead of predicting RR.

% For collected ECG RR, we create RR data that have a random error in it, calculate the HRV using the RR with errors, and obtain the error rate of HRV.
% For example, if we set the RR as 1\% mean absolute percentage error (MAPE), then for each RR value $x$, we reset it to be a random number between $0.99x$ and $1.01x$.
% As shown in Table \ref{tab:rr_vs_hrv}, if the RR has 1\% MAPE, the calculated RMSSD will have MAPE 5.76\%.
% And if the RR has MAPE 5\%, the according to RMSSD will have a MAPE of more than 87\%, which is too large and not acceptable.
% This might be because the HRV calculation expands the error. 
% Therefore, even if the ML model achieves low MAPE when predicting RR interval, the calculated HRV may still be inaccurate.
% Therefore, it is better to use the ML model to estimate HRV directly.

% \begin{table}[!htbp]
% \caption{RR error vs. calculated RMSSD HRV error.}
% \centering
% \renewcommand{\arraystretch}{1.5}
% \begin{tabular}{|c|c|}
% \hline
% RR MAPE & HRV RMSSD MAPE \\ \hline
% 1\%     & 5.76\%   \\ \hline
% 2\%     & 18.8\%   \\ \hline
% 3\%     & 38.43\%  \\ \hline
% 4\%     & 59.62\%  \\ \hline
% 5\%     & 87.66\%  \\ \hline
% \end{tabular}
% \label{tab:rr_vs_hrv}
% \end{table}

% \subsubsection{our data processing for HRV}

% Similar to HR estimation, after PPG light signal and ECG bin file, are collected, in stage 2, we will process them and extract PPG HR, PPG HRV, and ECG HRV.

% The initial steps to process the PPG signals are the same as stage 2 in HR estimation in section \ref{sec:method_hrstage2}.
% The difference is that after we obtain the processed PPG HR, we need to further calculate the PPG HRV by first converting the HR to RR, and then calculating HRV based on the converted RR.
% Since the HRV is calculated based on the RR within a given time interval, the length of the time interval is also a tunable parameter.
% In section \ref{sec:Evaluation}, we investigate the impact of different lengths of the time interval in HRV calculation on estimation accuracy.

% Besides, instead of calculating ECG HR, we calculate ECG HRV based on the processed ECG RR intervals.
% The length of time interval used for ECG HRV calculation is the same as that of PPG HRV.

% \subsubsection{ML method for HRV}

% For HRV estimation, in stage 3, the PPG HR and the calculated PPG HRV based on the PPG HR are passed to the ML algorithm as features. 
% For example, if a PPG HRV at time $t$ are calculated from $k$ RR interval from time $t-k$ to $t$, then there are $k+1$ features, which contains $k$ PPG HR from time $t-k$ to $t$ and the calculated HRV.
% And the ECG HRV at time $t$, which is calculated from ECG RR during time $t-k$ to $t$, is passed to the ML model as the label.
% Here, the number of calculated PPG HR $k$ is a configurable parameter. 
% Usually, the RMSSD and SDNN are calculated using 5 minutes history RR, this means 300 historically calculated PPG HR and a PPG HRV calculated based on them will be passed to the ML model as features.
% The more PPG HR we used in the prediction, the estimated HRV will be accurate but the ML model size will also be larger.
% We investigate the impact of $k$ on the estimation accuracy and model size in section \ref{sec:Evaluation}.

% Similar to the HR estimation method, the output of the ML model is the predicted HRV, and there will be one predicted HRV per second.
