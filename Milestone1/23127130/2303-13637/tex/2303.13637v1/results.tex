\section{Experimental Evaluation}
\label{sec:Evaluation}

This section presents the evaluation results, focusing on the HRV inference accuracy, ML model sizes, and inference time.

\subsection{Experiment Setup}

%In this section, we introduce the experiment settings, including the ISPC dataset, the monitor system setting when we collect our data, and the ML algorithm implementation details.

% \subsubsection{ISPC dataset}
% The ISPC dataset contains one channel of ECG data, 2 channels of PPG data, and 3-axis acceleration signals. There are 12 healthy subjects and each of them is required to do a series of exercises to generate 5-minute long recordings with a PPG sampling rate of 125 Hz. Although there are two channels of PPG signals, we only used one channel that has lower noise for HR estimation for better reproduction accuracy. 80\% of the data are used for training, and 20\% are used for testing.
% % There is an ECG HR every 8s with 6s overlap.
% % Their PPG is installed on the wrist.
% %Since the ISPC 2015 is designed for HR analysis, the duration of each instance or subject is too short which is not sufficient for HRV analysis.  Therefore, we also collect our data which is long enough for HRV estimation.
% As stated previously, the ISPC data is not long enough for HRV analysis. Therefore, it is not used for HRV evaluation.

\subsubsection{Hardware used in Data Collection and Inference}

% \begin{figure}
%   \centering
%   \includegraphics[width=0.6\linewidth]{pic/pi.png}
%   \caption{Connections between Pi and sensors.}
%   \label{fig:pi}
% \end{figure}

Our dataset contains one channel of PPG data. %, 3-axis acceleration signals, and 3-lead ECG signals.
%We collected data in three typical usage scenarios: when the subject is sitting, sleeping, and conducting daily activities such as walking and typing keyboard. 
%Each recording lasts for about 2 hours.
The subject simultaneously wore the PPG sensor on the fingertip 
%accelerometer on arm, 
and ECG electrodes. The PPG sensor %and the accelerometer 
is connected to a Raspberry Pi 4B through an i2C bus to record the data.
% , as shown in Figure~\ref{fig:pi}.
%To ensure the stability of acquiring the sensor data, the connections between the communication pins on these 2 sensors and the DuPont wires are fixed by using solder, and then another end of the DuPont wires is pinned to the breadboard. 
The hardware components are: 1) a Raspberry Pi 4B with 4 GB RAM; 2) a Maxim MAXREFDES117 HR monitor with a MAX30102 PPG sensor; and 3) a TLC5007 Dynamic ECG. 
PPG data and ECG data are synchronized according to their timestamps.
The Raspberry Pi is also used to measure the inference latency of the signal processing and ML models.

% \paragraph{Edge device}

% A Raspberry Pi 4B with 4 GB RAM and a 1.5 GHz quad-core Arm A72 CPU is utilized to communicate with the sensors and run the monitor system. 

% \paragraph{PPG sensor}

% MAXREFDES117 is chosen as the PPG sensor since it provides a reliable light signal. 
% The MAXREFDES117 contains a MAX30102 which is in charge of monitoring the pulse oximeter and heart rate, and it has other associated parts which can filter out some noise. 
% It also provides a convenient pins interface for easy data accessing through the i2C bus.

% \paragraph{ECG device}

% TLC5007 Dynamic ECG is selected to record the ECG signals of the subjects and used as the ground truth.
% It has a 3-lead portable holter that can collect ECG waveform. After recording, it can be connected to a computer to export the recording file. %which is a bin file.
% During our experiment, 5 disposable electrodes are mounted on the subject's torso and connected to the device through cables. 
% It also came with analysis software that can extract the RR intervals based on the recording file.

\subsubsection{ML Models and Hyperparamter Configurations}~\label{sec:hyperparams}
% \TODO{change MLP for using tf}
DT, RF, KNN, and SVM models were implemented using Scikit-learn~\cite{scikit-learn} and MLP was implemented using Keras.
ML models were saved with $joblib$.
% MLP was implemented using Keras~\cite{chollet2015keras} and saved in HDF5 format.
% We used the random search function $RandomizedSearchCV$ in Scikit-learn and $RandomSearch$ in keras-tuner~\cite{omalley2019kerastuner} to tune the model hyperparameters. 
We used the random search function $RandomizedSearchCV$ in Scikit-learn and $RandomSearch$ in Keras-tuner to tune the model hyperparameters. 
The hyperparameters are: 
1) For DT, the maximum depth of the tree ranges from 3 to 20; 
2) For RF, the number of trees is between 2 to 128, and the maximum tree depth is between 3 to 20;
3) For KNN, the number of neighbors is between 2 to 30, and the distance can be Manhattan or Euclidean; 
4) For SVM, the kernel may be among RBF, sigmoid and polynomial, and regularization (i.e., $C$) may be between 0.00001 to 10; 
%For polynomial kernels, the degree is between 3 to 8.
%For , we searched the hyper-parameter $C$ from 0.00001 to 10.
5) For MLP, there are 1 to 5 hidden layers, each with 1 to 100 neurons, and the activation function can be $relu$ or $tanh$.

\subsubsection{Metrics}~\label{sec:metrics}
For HRV estimation accuracy evaluation, we used the metric MAPE (Mean Absolute Percentage Error) between the HRV estimations and groundtruths. 
Given $m$ HRV estimations, the definition of MAPE is,
\begin{equation}
    MAPE = \frac{100\%}{m}\sum^{m}_{i=1}\bigg| \frac{HRV_{est,i}-HRV_{true,i}}{HRV_{true,i}}\bigg|.
\end{equation}

For model size evaluation, we report the sizes in KB (kilobytes) or MB (megabytes).
For inference time evaluation, we report the average time it takes to make an inference in microseconds ($\mu$s) or milliseconds (ms). 

\subsection{Accuracy Evaluation}

\begin{figure*}
  \subfloat[Office Work.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221220daily_dim_rmssdmape-test.pdf}\label{fig:mape_rmssd_daily}}
  \hfill
  \subfloat[Sleep.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221220sleep_dim_rmssdmape-test.pdf}\label{fig:mape_rmssd_sleep}}
  \hfill
  \subfloat[Sit.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221220sit_dim_rmssdmape-test.pdf}\label{fig:mape_rmssd_sit}}
  \caption{MAPEs for HRV/RMSSD estimations for different activities.}
  \label{fig:mape_rmssd}
\end{figure*}

\begin{figure*}
  \subfloat[Office Work.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221220daily_dim_sdnnmape-test.pdf}\label{fig:mape_sdnn_daily}}
  \hfill
  \subfloat[Sleep.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221220sleep_dim_sdnnmape-test.pdf}\label{fig:mape_sdnn_sleep}}
  \hfill
  \subfloat[Sit.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221220sit_dim_sdnnmape-test.pdf}\label{fig:mape_sdnn_sit}}
  \caption{MAPEs for HRV/SDNN estimations for different activities.}
  \label{fig:mape_sdnn}
\end{figure*}

% \begin{figure*}
%   %\vspace{-4mm}
%   \subfloat[Office Work.\label{fig:mape_rmssd_daily}]
%   {\input{figures/rmssd_daily_mape}}
%   \hfill
%   \subfloat[Sleep.\label{fig:mape_rmssd_sleep}]
%   {\input{figures/rmssd_sleep_mape}}
%   \hfill
%   \subfloat[Sit.\label{fig:mape_rmssd_sit}]
%   {\input{figures/rmssd_sit_mape}}
%   \caption{MAPEs for HRV/RMSSD estimations for different activities. \TODO{New Data}.}
%   \label{fig:mape_rmssd2}
% \end{figure*}

% \begin{figure}
%   \centering
%   \input{figures/average_mapes}
%   %\vspace{-4mm}
%   \caption{Average MAPEs across all activities.}
%   \label{fig:average_mapes}
%   %\vspace{-4mm}
% \end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.8\linewidth]{pic/mydata_hrv_plot221220_averageMAPEfor2measure.pdf}
  \caption{Average MAPEs across all activities and all monitoring lengths.}
  \label{fig:average_mapes}
\end{figure}


Figure~\ref{fig:mape_rmssd} and Figure~\ref{fig:mape_sdnn} give the MAPE of our compound and direct methods, using different types of ML algorithms at different monitoring lengths (i.e., the $n$ seconds in Section~\ref{sec:ml_hrv_models}). The figures also give the errors of the signal-processing-only method ("Sig-proc Only"). The following paragraphs discuss these accuracy results in detail.


\subsubsection{Overall Accuracy of Our Method}
Figure~\ref{fig:mape_rmssd} and Figure~\ref{fig:mape_sdnn} show that our compound and direct prediction methods usually had errors between $3.5\%$ to $25.7\%$. % depending on the activity, HRV metric (RMSSD or SDNN), model type, and monitoring length. 
The highest error was $25.7\%$, which was for the KNN model for SDNN estimation under the office work scenario with 30 seconds monitoring length (Figure~\ref{fig:mape_sdnn_daily}). The lowest error was only $3.5\%$, for the MLP model for RMSSD inference under sit scenario with 300 seconds monitoring length (Figure~\ref{fig:mape_rmssd_sit}). 

For the majority of the models, the errors of our method were less than 20\%. Figure~\ref{fig:average_mapes} also shows that the overall average MAPEs for different ML models (overall activities for both RMSSD and SDNN) are all less than 13.2\%. MLP models have the lowest overall average MAPEs of only 9.1\%. These results show that our compound and direct method has high accuracy for HRV estimation.

\subsubsection{Comparison with Signal Processing Only}
Figure~\ref{fig:mape_rmssd} and Figure~\ref{fig:mape_sdnn} also show that our method was usually more accurate than the signal-processing-only method ("Sig-proc Only"). In the case of RMSSD estimation (Figure~\ref{fig:mape_rmssd}), the signal-processing-only method usually had errors above 20\%, whereas our method's errors are usually less than 20\%.  

In the SDNN estimations (Figure~\ref{fig:mape_sdnn}), 
%the error differences between our method and the signal-processing-only method were smaller. 
the signal-processing-only method had lower errors than their RMSSD estimations, because SDNN measures long-term HRV and is less sensitive to signal noises. We had a similar observation for the ISPC dataset as discussed in Section~\ref{sec:motivation}. Nonetheless, our method usually still had lower errors than the signal-processing-only method for SDNN estimations. 

The only exceptions were for SDNN estimations in sit scenario with 240/300 seconds monitoring lengths (Figure~\ref{fig:mape_sdnn_sit}, where our method with some ML models (e.g., SVM) had higher errors than the signal-processing-only method. However, the error difference was small -- only 2.2\% at most. Moreover, our method with the MLP model was still more accurate than signal-processing-only in these cases.
% for sit 300 knn sdnn case, the difference is the largest

Overall, Figure~\ref{fig:average_mapes} shows that the signal-processing-only method has an overall average MAPE of 25\%, which is higher than the overall average MAPEs (about 12\%) of our compound and direct method using any ML model. 

% \vspace{-2.5mm}
\subsubsection{Traces of HRV Estimation}

\begin{figure*}
  \centering
  \includegraphics[width=1\linewidth]{pic/Bsleep1-dis00_mlp_kt180result_rmssd_traceallall.pdf}
  \caption{RMSSD estimation trace (sleep activity, monitoring length of 180sec). The yellow line separates training and test data.} %The ML predicted HRV is obviously closer to the ECG HRV compared with the signal-processed HRV.}
  \label{fig:trace_rmssd}
\end{figure*}

\begin{figure*}
  \centering
  \includegraphics[width=1\linewidth]{pic/Bsleep1-dis00_mlp_kt180result_sdnn_traceallall.pdf}
  \caption{SDNN estimation trace (sleep activity, monitoring length of 180sec). The yellow line separates training and test data.} %The ML predicted HRV is obviously closer to the ECG HRV compared with the signal-processed HRV.}
  \label{fig:trace_sdnn}
\end{figure*}

Figure~\ref{fig:trace_rmssd} and Figure~\ref{fig:trace_sdnn} give the traces of the RMSSD HRVs from the groundtruth (ECG), signal-processing-only method, and our method with MLP model for the sleep activity data. These traces illustrate that our MLP models reduce at least two types of noises after signal processing. The first type of noise is mostly errors due to either sensor bias or low sampling frequency. For example, for the 5600'th to 5750'th HRVs in Figure~\ref{fig:trace_rmssd}, signal-processing HRVs had similar fluctuation trends as the ECG HRVs, but they deviate by roughly 10. The MLP model, however, was trained to correct this "deviation" and produced more accurate HRVs. This same issue can also be observed for the SDNN estimations in Figure~\ref{fig:trace_sdnn}. The second type of noise is usually from motion artifact noises that affect a longer period. For example, for the 5900'th to 6200'th HRVs in Figure~\ref{fig:trace_rmssd}, signal-processing HRVs were flat then dropped, whereas the ECG HRVs were sharply increasing. These longer errors were also detected and corrected by our MLP model to produce HRVs increasing from 38 to 50, similar to the ECG.

The same conclusion can be drawn from the traces for other models, activities, and monitoring lengths. However, due to space limitations, these traces are omitted.

\subsubsection{Impact of Type of Activity and HRV Metric}
Across the results for the three activities in Figure~\ref{fig:mape_rmssd} and Figure~\ref{fig:mape_sdnn}, HRV estimations for sit had the lowest MAPEs. These low errors were because when the subjects sat, they had little movement, hence, lower motion artifacts. 
%The PPG sensors also attached better when the subjects sat than sleeping. 
In this work, we built one ML model for each activity. However, if only one ML model is built to cover all activities, then these MAPE differences suggest that more sensors/features (e.g., accelerometer or gyroscope) may be needed to conduct noise correction differently for different activities.


Moreover, %Figure~\ref{fig:mape_rmssd}, Figure~\ref{fig:mape_sdnn}, and 
Figure~\ref{fig:average_mapes} also show that our method's average MAPEs only differ slightly for RMSSD and SDNN estimations, indicating that our method works for both short-term or long-term HRV monitoring. However, the signal-processing-only method had considerably lower errors for SDNN (long-term) estimations than RMSSD (short-term) estimations.

\subsubsection{Accuracy Impact of Model Types}
%Most of our ML models had similar MAPEs in Figure~\ref{fig:mape_rmssd}, Figure~\ref{fig:mape_sdnn}, and Figure~\ref{fig:average_mapes}. 
Figure~\ref{fig:average_mapes} shows that MLP models were generally more accurate than other ML models in our method, with average MAPEs for RMSSD, SDNN, and "overall" being only 6.9\%, 11.3\%, and 9.1\%, respectively. Nonetheless, the differences in average MAPEs among model types in Figure~\ref{fig:average_mapes} are less than 4\%. 
These similar MAPEs match the recently proposed "Rashomon" theory~\cite{Rashomon-ML}, which states that there could be multiple ML models having similar accuracy for the same dataset. A group of models with similar accuracy implies that it is beneficial to conduct ML model exploration to search for models that fit certain non-functional requirements, such as low model sizes and fast inference time in the embedded applications. 
% Combining Figure~\ref{fig:average_mapes}, we can find that MLP has a lower MAPE compared to other ML models, which shows its ability to eliminate the different sources of noise and retrieve accurate HRV

%There are several explanations for the Rashomon theory. However, in our case, we believe the similar accuracy is primarily due to the limited model sizes. As we show later in Section~\ref{sec:complex_MLP}, when there was no limit on the model sizes, MLP models could have MAPEs as low as \TODO{3\%}.

\begin{figure*}
  \subfloat[Office Work.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221220daily_dim_rmssdfilesizeKB.pdf}\label{fig:size_rmssd_daily}}
  \hfill
  \subfloat[Sleep.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221220sleep_dim_rmssdfilesizeKB.pdf}\label{fig:size_rmssd_sleep}}
  \hfill
  \subfloat[Sit.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221220sit_dim_rmssdfilesizeKB.pdf}\label{fig:size_rmssd_sit}}
  \caption{Sizes of HRV/RMSSD models for different activities.}
  \label{fig:size_rmssd}
\end{figure*}

\begin{figure*}
  \subfloat[Office Work.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221220daily_dim_sdnnfilesizeKB.pdf}\label{fig:size_sdnn_daily}}
  \hfill
  \subfloat[Sleep.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221220sleep_dim_sdnnfilesizeKB.pdf}\label{fig:size_sdnn_sleep}}
  \hfill
  \subfloat[Sit.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221220sit_dim_sdnnfilesizeKB.pdf}\label{fig:size_sdnn_sit}}
  \caption{Sizes of HRV/SDNN models for different activities.}
  \label{fig:size_sdnn}
\end{figure*}
\subsubsection{Accuracy Impact of Monitoring Length}
Figure~\ref{fig:mape_rmssd} and Figure~\ref{fig:mape_sdnn} also show that another factor that impacts the accuracy of our method is the monitoring length $n$. That is, the longer the monitoring length, the lower the HRV estimation error. And the HRV estimations for the monitoring length at 300 seconds usually had the lowest errors. An HRV estimation for longer monitoring is usually less susceptible to a few noisy PPG signals, and therefore, it tends to have lower errors.

Note that, the required HRV monitoring length depends on the use case~\cite{2012-Xhyheri-HRVToday}. For example, 300-second monitoring is applied for caring for chronic renal failure and diabetes~\cite{acharya2006heart}. The fact that errors vary with monitoring lengths also suggests the applicability of PPG-based HRV monitoring to medical use needs to be evaluated case by case.
%Nonetheless, our results show that PPG sensors may be more suitable for use cases that require an HRV inferred every 120 seconds (or longer).


\subsubsection{Comparison with the ML-only Method}
We also experimented with the ML-only method to directly infer HRV using the original PPG data collected from the sensors. However, we were not able to obtain any ML-only HRV models with good accuracy, or even meaningful estimations. These models typically have accuracy similar to, sometimes even worse than, the signal-processing-only method. For the case of MLP, the HRV estimations produced by each MLP model are mostly the same value, making the estimations practically useless. These MLP models also have average sizes of 6.7MB and maximum size of 26.6MB, larger than the MLP models in our compound method.

We believe the main cause of the low accuracy was the small hyperparameter search space. Recall that we limited the hyperparameter search space to limit the ML model sizes, which also limits the model complexity. However, it typically needs very complex ML models to infer HRV using only the original PPG signals. Because of the poor results of the ML-only HRV models, we did not include them in the paper.

%Due to space limitations, we can not provide detailed results. Instead, we summarize these results in this paragraph. Except when using MLP models, the accuracy of the ML-only method is usually lower than our compound and direct method. This low accuracy is mostly because the non-neural network models are not powerful enough to learn all noise removal/reduction operations required for processing raw PPG data. The accuracy of the ML-only method with MLP models has \TODO{13\%} overall average MAPE, similar to our compound and direct method. However, these MLP models are at least 1.8MB, making them too large for small embedded devices.

\begin{figure*}
  \subfloat[Office Work.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221221daily_dim_rmssdpredictT.pdf}\label{fig:time_rmssd_daily}}
  \hfill
  \subfloat[Sleep.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221221sleep_dim_rmssdpredictT.pdf}\label{fig:time_rmssd_sleep}}
  \hfill
  \subfloat[Sit.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221221sit_dim_rmssdpredictT.pdf}\label{fig:time_rmssd_sit}}
  \caption{ML model inference time for HRV/RMSSD estimations for different activities.}
  \label{fig:rmssd_inference_time}
\end{figure*}


\begin{figure*}
  \subfloat[Office Work.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221221daily_dim_sdnnpredictT.pdf}\label{fig:time_sdnn_daily}}
  \hfill
  \subfloat[Sleep.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221221sleep_dim_sdnnpredictT.pdf}\label{fig:time_sdnn_sleep}}
  \hfill
  \subfloat[Sit.]
  {\includegraphics[width=0.33\textwidth]{pic/mydata_hrv_plot221221sit_dim_sdnnpredictT.pdf}\label{fig:time_sdnn_sit}}
  \caption{ML model inference time for HRV/SDNN estimations for different activities.}
  \label{fig:sdnn_inference_time}
\end{figure*}

\subsection{Model Size Evaluation}



Figure~\ref{fig:size_rmssd} and Figure~\ref{fig:size_sdnn} give the sizes of the ML models generated by our direct and compound HRV inference method. As both figures show, the ML model sizes ranged from 2.8KB to 12.4MB. The figures also show that the model sizes are less affected by the type of activities and the HRV metric (RMSSD or SDNN). Monitoring lengths have a higher impact on the model size -- the longer the monitoring length, the more input features, and hence, larger models.

The largest factor for model size is the type of model. RF, KNN, and SVM models are usually large and approaching 10MB. 
As the input HRs to the ML models are generated from PPG signals, they are usually "messy" and lack a clear "pattern." Hence, RF/KNN/SVM requires large numbers of internal parameters to learn their "patterns." 
The MLP models, however, are smaller -- most MLP models are below 200KB, with the smallest model being 63.4KB (Figure~\ref{fig:size_rmssd_sit} at 30s) and the largest model being 468.5KB (Figure~\ref{fig:size_sdnn_daily} at 240s). DT models are even smaller, -- most DT models are below 10KB, with the smallest model being 2.8KB (Figure~\ref{fig:size_rmssd_sit} at the 30s) and the largest model is 35.4KB (Figure~\ref{fig:size_rmssd_sleep} at 120s). Considering DT and MLP models can fit in on-chip memory of hundreds of KB, they are better candidates for deploying to tiny embedded devices.



\subsection{Inference Time Evaluation}

Figure~\ref{fig:rmssd_inference_time} and Figure~\ref{fig:sdnn_inference_time} give the inference time of our compound and direct method. As both figures show, the inference time for all models was less than 7.3ms (max 7295$\mu$s). DT models are the fastest models due to their small sizes -- the inference time for DT models is between only 2.9$\mu$s to 10$\mu$s. The inference time of RF models is also fast, ranging between 17.6$\mu$s to 57.2$\mu$s. The SVM models are the slowest due to their large sizes, and their inference time ranges from 0.7ms to 7.3ms. Nonetheless, even 7.3ms is fast enough for HRV inference, indicating that all models under our methodology are fast enough for HRV monitoring with embedded devices.

The signal processing takes 65.74ms on average and 68.31ms at maximum, which is significantly slower than ML model inference.\footnote{This 65.74ms is also the average processing time for the signal only method.} Nonetheless, the signal processing is still fast enough for HRV monitoring. Note that, the total computation time for our method includes both the signal processing time and ML inference time.

