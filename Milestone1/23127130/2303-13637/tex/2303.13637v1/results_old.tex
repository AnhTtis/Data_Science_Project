\section{Experimental Evaluation}
\label{sec:Evaluation}

This section presents the experimental evaluation results.
%For the evaluation results, we present the HR results and HRV results separately.

\subsection{Experiment Setup}

%In this section, we introduce the experiment settings, including the ISPC data setting, the monitor system setting when we collect our data, and the ML algorithm implementation details.

\subsubsection{ISPC dataset}
The ISPC data set contains one channel of ECG data, 2 channels of PPG data, and 3-axis acceleration signals. There are 12 healthy subjects and each of them is required to do a series of exercises to generate 5-minute long recordings with a PPG sampling rate of 125 Hz. Although there are two channels of PPG signals, we only used one channel that has lower noise for HR estimation for better reproduction accuracy. 80\% of the data are used for training, and 20\% are used for testing.
% There is an ECG HR every 8s with 6s overlap.
% Their PPG is installed on the wrist.
%Since the ISPC 2015 is designed for HR analysis, the duration of each instance or subject is too short which is not sufficient for HRV analysis.  Therefore, we also collect our data which is long enough for HRV estimation.
As stated previously, the ISPC data is not long enough for HRV analysis. Therefore, it is not used for HRV evaluation.

\subsubsection{Our dataset}

\begin{figure}
  \centering
  \includegraphics[width=0.7\linewidth]{pic/pi.png}
  \caption{Connections between Pi and sensors.}
  \label{fig:pi}
\end{figure}

Our data set contains one channel of PPG data, 3-axis acceleration signals, and 3-lead ECG signals.
%We collected data in three typical usage scenarios: when the subject is sitting, sleeping, and conducting daily activities such as walking and typing keyboard. 
%Each recording lasts for about 2 hours.
The subject simultaneously wore the PPG sensor on the fingertip, accelerometer on arm, and ECG electrodes. The PPG sensor and the accelerometer are connected to a Raspberry Pi 4B through an i2C bus to record the data, as shown in Fig.\ref{fig:pi}.
%To ensure the stability of acquiring the sensor data, the connections between the communication pins on these 2 sensors and the DuPont wires are fixed by using solder, and then another end of the DuPont wires are pinned to the breadboard. 
The hardware component models are: 1) a Raspberry Pi 4B with 4 GB RAM; 2) a Maxim MAXREFDES117 HR monitor with a MAX30102 PPG sensor \TODO{[cite]}; and 3) a TLC5007 Dynamic ECG.

% \paragraph{Edge device}

% A Raspberry Pi 4B with 4 GB RAM and a 1.5 GHz quad-core Arm A72 CPU is utilized to communicate with the sensors, and run the monitor system. 

% \paragraph{PPG sensor}

% MAXREFDES117 is chosen as the PPG sensor since it provides a reliable light signal. 
% The MAXREFDES117 contains a MAX30102 which is in charge of monitoring the pulse oximeter and heart rate, and it has other associated parts which can filter out some noise. 
% It also provides a convenient pins interface for easy data accessing through the i2C bus.

% \paragraph{ECG device}

% TLC5007 Dynamic ECG is selected to record ECG signals of the subjects and used as the ground truth.
% It has a 3-lead portable holter that can collect ECG waveform. After recording, it can be connected to a computer to export the recording file. %which is a bin file.
% During our experiment, 5 disposable electrodes are mounted on the subject's torso and connected to the device through cables. 
% It also came with analysis software that can extract the RR intervals based on the recording file.

\subsubsection{ML Configurations}~\label{sec:hyperparams}
ML algorithms are implemented using Scikit-learn~\cite{scikit-learn}.
We used the random search function RandomizedSearchCV in Scikit-learn to tune the model hyperparameters. The hyperparameters are: 
1) For DT, the maximum depth of the tree ranges from 1 to 20. 
2) For RF, the number of trees is between 1 to 30, and the maximum tree depth is between from 3 to 7. 
3) For KNN, the number of neighbors is between 1 to 30, and the distance can be Manhattan or Euclidean. 
4) For SVM, the kernel may be among RBF, sigmoid and polynomial, and regularization (i.e., $C$) may be between 0.00001 to 10. 
%For polynomial kernels, the degree is between 3 to 8.
%For , we searched the hyper-parameter $C$ from 0.00001 to 10.
5) For MLP, there are 3 hidden layers with 2 to \TODO{a few hundred} neurons from.
The activation function can be relu or tanh. The regularization hyper-parameter \TODO{?} search range is from 0.00001 to 10.

\begin{figure}
  \centering
  \includegraphics[width=1\linewidth]{pic/ispc_hr_plot220728mlp_dim2_mape-test.pdf}
  \caption{HR estimation MAPE for different subjects in the ISPC data set. "MLP" stands for our method that combines signal processing and MLP modeling, and "sig-proc" stands for the signal-processing-only method reproduced based on the ISPC paper~\cite{zhang2014troika}.}
%   (when using MLP and the number of features is 2). The ML predicted HR has lower error compared with only signal processing method for most subjects.}
  \label{fig:hr_mape_sub}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=1\linewidth]{pic/ispc_hr_plot220728DATA_11_TYPE02_PPG_mlp_search10ppg1resultsmall.pdf}
  \caption{HR estimation trace for subject 11 in the ISPC data set (MLP model's feature size is \TODO{10}). The vertical line is the dividing line for training and testing. \TODO{only this has vertical line?}}
  \label{fig:hr_ispc}
\end{figure}



\begin{table*}
\caption{MAPE and SD for different number of features when estimating ISPC HR (MAPE±SD).}
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multicolumn{1}{|l|}{\multirow{2}{*}{}}& \multicolumn{6}{c|}{Number of features}  \\ \hline
\multicolumn{1}{|l|}{} & 2             & 4             & 6             & 8             & 10            & 15            \\ \hline\
DT                     & 3.86\%±5.26\% & 3.77\%±4.91\% & 3.58\%±4.14\% & 3.4\%±3.64\%  & 3.41\%±3.53\% & 2.76\%±1.89\% \\ \hline
RF                     & 3.14\%±3.45\% & 3.29\%±3.4\%  & 2.9\%±2.37\%  & 2.79\%±2.08\% & 2.7\%±1.87\%  & 2.62\%±1.91\% \\ \hline
KNN                    & 2.89\%±2.6\%  & 2.89\%±2.2\%  & 2.9\%±1.87\%  & 3.08\%±1.75\% & 3.55\%±2.33\% & 3.69\%±1.94\% \\ \hline
SVM                    & 3.81\%±2.5\%  & 5.14\%±6.18\% & 4.71\%±5.49\% & 3.83\%±2.2\%  & 5.11\%±5.41\% & 4.06\%±2.49\% \\ \hline
MLP                    & 3.33\%±5.86\% & 3.26\%±5.2\%  & 3.38\%±5.49\% & 4.53\%±5.78\% & 3.4\%±4.41\%  & 4.81\%±4.46\% \\ \hline
\end{tabular}
\label{tab:hr_numofFeature_ispc}
\end{table*}

\begin{figure*}
  \centering
  \includegraphics[width=1\linewidth]{pic/ispc_plot_dim_filesize(KB).pdf}
  \caption{Model sizes for different number of features when estimating ISPC HR. The y-axis is a logarithmic scale.}
  \label{fig:hr_modelsize_ispc}
\end{figure*}

\subsection{Heart Rate Estimation Results}
% In this section, we present the HR estimation results on ISPC data and our collected data.

\subsubsection{HR Estimation Accuracy for ISPC Data Set}
Figure~\ref{fig:hr_ispc} gives the HR estimations errors for the ISPC data sets, including the MAPEs of our method that combines signal processing and MLP models, and the MAPEs of signal-processing-only method. Note that, the MLP model here has \TODO{two} features (i.e., two PPG-HRs as features). As Figure~\ref{fig:hr_ispc}, our combined method usually had lower errors than the signal-processing-only method. On average, our method had only \TODO{4\%} error, which is \TODO{6\%} lower than the signal-processing-only method. To further compare the accuracy differences, Figure~\ref{fig:hr_mape_sub} gives the HR estimations of our combined method, the signal-processing-only method, along with the ECG groundtruth. As Figure~\ref{fig:hr_mape_sub}, our HR estimations are more close to ECG readings. Our HR estimations are also less fluctuating than those from the signal-processing-only method, suggesting that the MLP model in our method could indeed reduce the random errors from the HRs generated by signal processing.

Figure~\ref{fig:hr_ispc} also showed that, for most subjects, the HR estimation errors are below \TODO{3\%}, suggesting the PPG based HR monitoring can have high accuracy. The only two exceptions are subject 2 and subject 10, where the PPG signals were more noisy and random, likely due to worse MA effects during data collection. The same issue were also observed by other studies \TODO{~\cite{}}. Nonetheless, even for subjects 2 and 10, our combined method is still significantly more accurate than signal-processing-only.

\subsubsection{HR ML Model Exploration for ISPC Data Set}
Besides MLP with \TODO{two} features, we also explored with ML models and feature sizes to search for a configuration that can provide good accuracy with low model size. Table~\ref{tab:hr_numofFeature_ispc} gives the detailed MAPEs for different ML models and feature sizes (i.e., PPG-HR input sizes). Note that, the MAPEs in Table~\ref{tab:hr_numofFeature_ispc} are the average MAPEs for all 12 subjects for each configuration along with the standard deviation. As Table~\ref{tab:hr_numofFeature_ispc} shows, while all configurations have similar low errors, RF with 15 features has the lowest 2.62\% average MAPE, with the 2.76\% of DT and 15 features a close second.

Figure~\ref{fig:hr_modelsize_ispc} gives the models sizes of different ML configurations, which shows that DT and SVM usually have lower model sizes. Considering the lower error from DT, these results suggest that DT with 15 features is a better configuration that provides both high accuracy and low model size.

\subsubsection{HR estimation Accuracy for Our Data Set}

\begin{figure}
  \centering
  \includegraphics[width=1\linewidth]{pic/mydata_hr_plot220726_alg10mape-test.pdf}
  \caption{HR estimation MAPEs for different scenarios and ML algorithms using our data set.}
  %when estimating HR using \10 HR as features. Sleep scenario has slightly higher error.}
  \label{fig:hr_alg_mape}
\end{figure}

\begin{figure*}
  \centering
  \includegraphics[width=1\linewidth]{pic/Bdaily1-dis00_mlp10resultplottempsub.pdf}
  \caption{HR estimation trace for daily activities scenario (MLP model's feature size is 10).}% The ML model is MLP and the number of features is 10.}
  \label{fig:hr_ecgSensorPredicted}
\end{figure*}

Figure~\ref{fig:hr_alg_mape} gives the HR estimation error using our data set. Note that, the ML models here have \TODO{10} features (i.e., 10 PPG-HRs as features). As Figure~\ref{fig:hr_alg_mape} shows, our combined method with either DT, RF, KNN, SVM, and MLP models always has lower error than the signal-processing-only model (Sig-proc) for all activity scenarios. Moreover, the errors of our method are always below 6\%, showing that our method is highly accurate. Figure~\ref{fig:hr_ecgSensorPredicted} further gives the HR traces for our method with an MLP model, the signal-processing-only model, and the ECG ground truth. Similar to the ISPC evaluation, HRs from our combined method in Figure~\ref{fig:hr_ecgSensorPredicted} are usually more close to ECG readings. Our HR estimations are also less fluctuating than those from the signal-processing-only method, suggesting that our method could reduce the random noises in the PPG signals when the PPG signal is only at 25Hz.

\subsubsection{HR ML Model Exploration for Our Data Set}

\begin{figure*}
  \centering
  \includegraphics[width=1\linewidth]{pic/mydata_hr_plot220728daily_dim_mape-testsub.pdf}
  \caption{HR estimation MAPE for different number of features with our collected daily scenario data.} %The accuracy of different number of features and different ML models are similar.}
  \label{fig:hr_numofFeature}
\end{figure*}

\begin{figure*}
  \centering
  \includegraphics[width=1\linewidth]{pic/mydata_hr_plot220727daily_dim_filesize(KB).pdf}
  \caption{ML model size for different number of features when estimating HR using our collected daily scenario data. DT, MLP, and RF have smaller model size compared with KNN and SVM.}
  \label{fig:hr_modelsize}
\end{figure*}

Again, we also explored with ML models and feature sizes using our data set to search for a configuration with both good accuracy and low model size. Figure~\ref{fig:hr_numofFeature} gives the MAPEs for different ML models and feature sizes (i.e., PPG-HR input sizes) for the daily activity scenario. We can see from Figure~\ref{fig:hr_numofFeature}, the errors for all types of ML models are similarly low when there are more than 10 features, suggesting 10 to 20 features could be enough for our data set.

Figure~\ref{fig:hr_modelsize} gives the models sizes of different ML configurations, which shows that DT models are consistently lowest. Considering the lower error from DT, these results suggest that DT with 10 to 20 features is a better configuration that provides both high accuracy and low model size.


% %For the ISPC data, we split the PPG data into 8:2 ratios and use the 80\% data to train and the rest 20\% to test.
% % Since there are using a two-channel PPG, we named the two PPG signals PPG1 and PPG2.
% % In this paper, we use PPG1 only to estimate ECG HR since there is much noise in PPG2.
% For example, the HR results for subject 11 are shown in Fig. \ref{fig:hr_ispc}.
% We can find that PPG1 HR is closer to ECG HR than PPG2 HR.
% The blue line shows the estimated HR from an MLP model using 10 PPG1 HRs as features.
% As shown in Fig. \ref{fig:hr_ispc}, the estimated HR is closer to ECG HR than PPG1 HR, which shows the effectiveness of the estimation algorithm.

% For 12 different ISPC subjects, MAPE varies considerably among them, and for most subjects, the ML predicted HR has less error compared with the HR before ML.
% For example, Fig. \ref{fig:hr_mape_sub} shows the RF models' MAPE when the number of features is 2.
% MAPEs for most subjects are below 2\%.
% But there are subject that has MAPE over 10\%.
% The reason might be the input for ML models contains more noise, which is related to the experiment collection process.
% The trends are similar for the other number of features and other ML algorithms.

% To evaluate the HR estimation method quantitatively, we present the HR estimation mean absolute percentage error (MAPE) in Table \ref{tab:hr_numofFeature_ispc}. 
% The average MAPE and standard deviation (SD) are the average or SD for the 12 subjects in ISPC.
% % The HR estimation of \cite{tor} is 1.82\%±2.07\%).
% We use different numbers of HR as the features to predict.
% For example, let $P_t^{hr}$ denote PPG HR at time $t$.
% To estimate HR at time $t$, we use $x$ PPG HR ($P_{t-x+1}^{hr} \thicksim P_t^{hr}$) as features for ML models.
% From the table, we can find that as the number of features increases, MAPE does not increase significantly.
% Therefore, smaller numbers of features are preferable to balance the estimation accuracy and the ML model complexity.
% Besides, The MAPE between different ML models is similar, except for SVM, which is the only ML algorithm that has MAPE higher than 5\%.

% The ML model sizes are shown in Fig. \ref{fig:hr_modelsize_ispc}.
% The model size is the average model size for the 12 ISPC subjects. 
% It can be easily found that the model sizes of DT, RF, and MLP have no major increase when adding more features. 
% However, KNN and SVM sizes change proportionally when increasing the number of features. 
% Usually, with more features, more buffers are required to store them, and more complex logic is needed for predication which also requires more memory.
% The model size of DT depends on the depth of the tree, consequently, the DT model sizes have limited changes. 
% Similarly, the RF model relies on the configuration of the forest, like the number of trees and the size of each tree, hence the model size may not change much if the configuration is fixed, and due to hyper-parameter searching, The size of RF happen to varies a little for different number of features cases. 

% Considering the prediction accuracy and model size jointly, we recommend DT, RF, and MLP. 
% Besides, we recommend using fewer PPG HR'  as features since fewer features do not affect accuracy much but contribute to smaller model size.






% \subsubsection{HR Estimation Results for Our Dataset}

% Our collected PPG HR, estimated HR, and collected ECG HR are shown in Fig. \ref{fig:hr_ecgSensorPredicted}. 
% In this figure, the estimated HR is obtained with an MLP model when the number of features is 10.
% As we can see, the MLP model obtained a high accuracy that helps to make the estimated HR closer to the ECG HR. 
% For example, when the time index is around 5800, the PPG HR contains some outliers but the ML model predicted results correctly and the estimated HR is closer to the label.

% We also compared the performance in different scenarios and the results are shown in Fig. \ref{fig:hr_alg_mape}.
% The number of features is 10. 
% The sit scenario and daily (activity) scenario have lower MAPE while the sleep scenario has higher MAPE.
% However, the MAPE difference between different scenarios are within 2\%, which is not too high.
% The trend for other number of features cases is similar.
% For all scenario, The MAPE of HR after ML is about 1\% to 2\% lower than that of HR before ML.

% To further analyze the effect of the number of input features on the HR estimation, the results of MLP models with different number of features are provided in Fig. \ref{fig:hr_numofFeature}.
% This figure shows results in the sitting scenario and the x-axis is the number of features.
% With a larger number of features, the MAPE decreases but the ML model needs more memory and time to train and run. 
% Hence, there is a trade-off between the number of features and the estimation accuracy.
% According to the results, 10 historical PPG HRs as features are preferable as they achieve good accuracy while consuming fewer resources.
% Besides, the MAPE difference between different ML models are small (mostly within 1\%).

% We also investigate the model size changes for different the number of features and the results are shown in Fig. \ref{fig:hr_modelsize}.
% This figure used the sitting scenario data but the trend is similar for other scenarios.
% The model size is mainly decided by the ML algorithm and the number of features.
% With more features, the ML algorithm needs more complex logic and a larger buffer to estimate HR, as a result, the ML model size might be larger. 
% From the figure, we can conclude that DT needs less memory while KNN and SVM require more memory.
% Therefore, much the same as the ISPC conclusion, we recommend DT, RF, and MLP as the estimation algorithms by making a trade off between accuracy and memory consumption.

\begin{figure}
  \centering
  \includegraphics[width=1\linewidth]{pic/mydata_hrv_plot220728daily_dim_rmssdmape-test.pdf}
  \caption{HRV estimation MAPE for daily scenario when using RMSSD.} %Signal processing incorporated with ML has lower error than using only the signal processing method.}
  \label{fig:hrv_dim_mape_rmssd}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=1\linewidth]{pic/mydata_hrv_plot220803Bdaily1-dis00flucHP55-hrhrv2hrv-rmssd60c_mlpresult6125to6525.pdf}
  \caption{RMSSD HRV estimation trace for daily activity scenario (MLP model's feature size 60).} %The ML predicted HRV is obviously closer to the ECG HRV compared with the signal processed HRV.}
  \label{fig:mydata_hrv}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=1\linewidth]{pic/mydata_hrv_plot220728daily_dim_sdnnmape-test.pdf}
  \caption{HRV estimation MAPE for daily scenario when using SDNN.}% Signal processing incorporated with ML has lower error than using only the signal processing method.}
  \label{fig:hrv_dim_mape_sdnn}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=1\linewidth]{pic/mydata_hrv_plotdaily_dim_rmssdfilesize(KB).pdf}
  \caption{Model size for daily scenario when using RMSSD. DT has the smallest model size.}
  \label{fig:hrv_dim_size_rmssd}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=1\linewidth]{pic/mydata_hrv_plotdaily_dim_sdnnfilesize(KB).pdf}
  \caption{Model size for daily scenario when using SDNN. DT has the smallest model size.}
  \label{fig:hrv_dim_size_sdnn}
\end{figure}

\subsection{HRV Estimation Results}
\subsubsection{HRV Estimation Accuracy}
This section presents the HRV estimation results. As stated previously, the ISPC data set is too short for HRV analysis. Therefore, we only evaluated HRV estimations with our own data set. Additionally, due to space limitation, we only report the detailed HRV results for daily activity scenario. The results for sleeping and sitting are similar.
% We collected PPG and ECG data for 2 hours in three different settings (e.g., sitting, sleeping, daily) to train and evaluate ML models. 
% Daily setting means the object is sitting for most of the time but also has some low-intensity activities such as walking, drinking water, etc.
The MAPEs for HRV estimations are given in Figure~\ref{fig:hrv_dim_mape_rmssd} for RMSSD HRV (Equation~\ref{eq:rmssd}) and in Figure~\ref{fig:hrv_dim_mape_sdnn} for SDNN HRV (Equation~\ref{eq:sdnn}). Both figures show that our combined method always has lower error than signal-processing only. Moreover, Figure~\ref{fig:mydata_hrv} gives the RMSSD HRV estimation trace for the daily activity scenario, where the HRV estimations from our combined method are significantly better than just signal processing. 

\subsubsection{HRV ML Model Exploration}
We also evaluated different types of ML models and feature sizes. HRV is a measurement of variation, its estimation required at least 30 PPG-HRs. Therefore, our feature sizes are 30, 60 or 300 (PPG-HRs). Note that, as stated in Section~\ref{sec:ml_estimation}, besides the PPG-HRs, the signal-processing-generated HRV is also used as an additional feature.
Figure~\ref{fig:hrv_dim_mape_rmssd} and Figure~\ref{fig:hrv_dim_mape_sdnn} also give the MAPEs of HRV estimations for different ML configurations. The figures show that ML models with 300 features usually have lower errors than 30 and 60 features. Moreover, with 300 features, the models have similar accuracy, with the difference in MAPE being less than \TODO{5\%}.

Figure~\ref{fig:hrv_dim_size_rmssd} and Figure~\ref{fig:hrv_dim_mape_sdnn} also give the model size of each configuration. Both figure show that DT models are significantly smaller than other models. Considering the above accuracy results, a DT model with 300 features strikes a good balance between good HRV accuracy and small model size.

% The SDNN estimation results are shown in Fig. \ref{fig:mydata_hrv}. 
% This picture shows the PPG HRV, ECG HRV and estimation HRV using MLP in the sleep scenario and the number of features for ML is 301 (300 PPG HR' and the PPG HRV).
% HRV predicted by MLP is closer to ECG HRV than the PPG HRV which shows the ML predicted HRV has higher accuracy than HRV before ML.

% The MAPE for daily scenario is in Fig. \ref{fig:hrv_dim_mape_rmssd} and Fig. \ref{fig:hrv_dim_mape_sdnn}. 
% The ML predicted HRV for different ML models have similar accuracy.
% For both RMSSD and SDNN measure method, for all number of features, and for all ML models, the predicted HRV error is lower compare with the Signal processed HRV (Sig-proc). 
% The accuracy improvement is higher for RMSSD than SDNN and is higher for smaller number of features.
% For example, for the RMSSD cases, when the number of PPG HR' is 30 and 60, the MAPE of the ML predicted result is more than half less than that without ML.
% For both RMSSD and SDNN, with more features, the accuracy increases significantly. 
% For example, when the measure is RMSSD, the average MAPE for 5 ML models reduce from 17.25\% when input features contain 30 PPG HR' to 10.66\% when the input features contain 300 PPG HR'.
% When the measure is SDNN, the average MAPE for 5 ML models reduce from 25.49\% when input features contain 30 PPG HR' to 15.37\% when the input features contain 300 PPG HR'.
% The trends for sit and sleep scenario are approximate.
% For example, the signal processed HRV MAPE is 38.56\% for sit data and MLP cut it down to 14.18\% when the input features contain 30 PPG HR'.
% In sit scenario, the average ML predicted HRV MAPE drop from 13.93\% to 9.01\% for RMSSD and from 16.68\% to 6.91\% for SDNN when the number of PPG HR' in features increases from 30 to 300.
% Similarly, in sleep scenario, it shrink from 15.96\% to 8.18\% for RMSSD and from 20.74\% to 9.51\% for SDNN.

% The model size for daily scenario is shown in Fig. \ref{fig:hrv_dim_size_rmssd} and Fig. \ref{fig:hrv_dim_size_sdnn}.
% The trends in other scenarios are similar.
% We can conclude that the DT model has the smallest model size, while others have similar model sizes.
% Furthermore, with more features, the model sizes become larger.
% Considering both estimation accuracy and model size, we recommend DT, RF, and MLP as the ML algorithms, which are similar to our HR estimation results.
