% !TeX root = paper.tex
% !Tex program=pdflatex
% !TeX spellcheck = en_US

\section{Conclusion}

This paper has studied the task of learning inherently interpretable anomaly detectors in the form of DFAs.
We have defined two unsupervised learning setups, studied their properties (e.g., their computational complexity), and developed two learning algorithms that utilize off-the-shelf constraint optimization tools.
In addition, we have shown how regularization can improve the interpretability of the learned DFAs.
Our empirical evaluation has demonstrated that our approach can efficiently generate anomaly detectors for various tasks of the ALFRED data set.

We see various promising directions for future research.
First, we intend to relax the requirement to provide bounds on the number of anomalies in the sample.
Our idea here is to use a similarity measure, similar to clustering, and learn automata that minimize the similarity between normal data while maximizing the similarity to anomalies.
Second, we plan to develop heuristics that sacrifice the optimality of a solution in favor of computational efficiency.
Third, we want to extend our approach to more expressive automata classes, such as register automata, to handle data over continuous domains.

%\begin{itemize}
%  \item Richer automaton models (e.g., RAs, timed automata, â€¦)
%  \item Approach 3 (no bounds)
%  \item more / better interpretability constraints
%  \item use human advice for defining interpretable automata
%  \item empirical user case study: interpretability
%  \item heuristical poly-time approaches
%\end{itemize}