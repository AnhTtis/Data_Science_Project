{
    "arxiv_id": "2303.10930",
    "paper_title": "Semantic 3D scene segmentation for robotic assembly process execution",
    "authors": [
        "Andreas Wiedholz",
        "Stefanie Wucherer",
        "Simon Dietrich"
    ],
    "submission_date": "2023-03-20",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.RO"
    ],
    "abstract": "Adapting robot programmes to changes in the environment is a well-known industry problem, and it is the reason why many tedious tasks are not automated in small and medium-sized enterprises (SMEs). A semantic world model of a robot's previously unknown environment created from point clouds is one way for these companies to automate assembly tasks that are typically performed by humans. The semantic segmentation of point clouds for robot manipulators or cobots in industrial environments has received little attention due to a lack of suitable datasets. This paper describes a pipeline for creating synthetic point clouds for specific use cases in order to train a model for point cloud semantic segmentation. We show that models trained with our data achieve high per-class accuracy (> 90%) for semantic point cloud segmentation on unseen real-world data. Our approach is applicable not only to the 3D camera used in training data generation but also to other depth cameras based on different technologies. The application tested in this work is a industry-related peg-in-the-hole process. With our approach the necessity of user assistance during a robot's commissioning can be reduced to a minimum.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10930v1"
    ],
    "publication_venue": null
}