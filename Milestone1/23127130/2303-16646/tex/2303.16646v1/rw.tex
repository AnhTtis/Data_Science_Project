%Establishing correspondences between two images is a key step for many applications in computer vision including 3D reconstruction,
%image retrieval, visual localization, etc.
This section provides a brief overview of the methods related to local feature matching.
% \noindent\textbf{Sparse Matching Methods.}
% The sparse matching methods~\cite{tian2017l2,ono2018lf,dusmanu2019d2,luo2020aslfeat,r2d2,sarlin2020superglue}.

\noindent\textbf{Detector-Based Local Feature Matching}.
Detector-based methods, also referred to as \textit{extract-to-match} or \textit{sparse} methods, involve three main stages: feature detection, feature description, and feature matching.
Local features such as hand-crafted SIFT~\cite{lowe2004distinctive} and ORB~\cite{rublee2011orb} are the most widely used.
Recently, learning-based methods like LIFT~\cite{yi2016lift} and SuperPoint~\cite{detone2018superpoint} have been shown to significantly improve performance compared to classical methods.
Some researchers also focus on enhancing the feature matching stage. Nearest Neighbor Search is the most popular classical matching method.
Learning-based approaches such as D2Net~\cite{dusmanu2019d2} combine the detection and description stages, while Revaud et al.~\cite{r2d2} trains the R2D2 to identify reliable and repeatable local features. SuperGlue~\cite{sarlin2020superglue} introduces an attention-based GNN network which archives a significant performance improvement.
Nevertheless, detector-based methods rely on keypoint detectors, which limits the performance in challenging scenarios such as repetitive textures, weak textures, and illumination changes.

\noindent\textbf{Detector-Free Local Feature Matching.}
% Detector-free approaches, which do not require a local feature detector and instead directly match dense features between pixels, are often referred to as \textit{dense} methods.
Detector-free approaches directly match dense features between pixels without the local feature detector, which are also named \textit{dense} methods.
While classical methods like Lucas-Kanade~\cite{lucas1981iterative} and Horn-Schunck~\cite{horn1981determining} exist, few of them outperform detector-based methods.
Learning-based methods have revolutionized this field, with cost-volume-based methods and Transformer-based methods leading the charge.
While NCNet~\cite{rocco2018neighbourhood} was the precursor of cost volume, its large computational and memory overhead limits its performance.
DRC-Net~\cite{li20dualrc} improves upon NCNet~\cite{rocco2018neighbourhood} by building cost volumes at two different scales and fuses them to obtain dense matches, while GLU-Net~\cite{truong2020glu} also uses a multi-level structure to combine global and local correlations in a feature pyramid.
GOCor~\cite{truong2020gocor} disambiguates repeated patterns with improved feature correlation layers.
Considering the limited perceptual field of CNNs, Transformer-based approaches have also been proposed in recent years.
COTR~\cite{jiang2021cotr} employs a Transformer decoder to determine the matching point for any given query point.
LoFTR~\cite{sun2021loftr}, following SuperGlue~\cite{sarlin2020superglue}, uses self and cross attention to update dense features during the coarse stage and refines matches in the fine stage. 
MatchFormer~\cite{wang2022matchformer} proposes a multi-scale fusion approach, while Aspanformer~\cite{chen2022aspanformer} uses flow maps and probabilistic models to select an adaptive attention span.
Given that detector-free methods have been shown to perform better in local feature matching, we have chosen this paradigm as our baseline approach, and use our proposed new module to overcome the challenging scenarios.

% \noindent\textbf{Attention Mechanism.}



% Transformer~\cite{vaswani2017attention} has been proven to be better at capturing long-range correlations than CNN.
% While becoming a popular method in NLP, Transformer has also been widely used in vision tasks~\cite{dosovitskiy2020image,carion2020end,sun2021loftr}.
% Despite the great success, the computational cost of vanilla attention at high resolution is unacceptable, so some approximations~\cite{katharopoulos2020transformers,liu2021swin,tang2022quadtree,wang2020linformer} have been proposed, which inevitably leads to performance degradation.
% Linear Attention~\cite{katharopoulos2020transformers} approximates softmax with ELU~\cite{clevert2015fast} to reduce the computational complexity to linear but degrades the focusing ability of attention. Swin-Transformer~\cite{liu2021swin} limits attention in local windows, which harms the ability to establish long-range associations.
% At the same time, QuadTree~\cite{tang2022quadtree} calculates attention in a coarse-to-fine manner, and ASpanFormer~\cite{chen2022aspanformer} proposes an adaptive method for selecting attention spans, but few of them consider local consistency.
% % but they both lack local consistency.
% Different from the existing attention mechanism, we explicitly model local consistency in our spot-guided attention without introducing excessive computation and memory costs.
% % {\color{blue}Our method outperform vanilla attention in feature matching while greatly reduce computational overhead, and explicitly models local consistency.}

\noindent\textbf{Geometry Prior in Local Feature Matching.}
The significance of geometric priors in local feature matching has been explored in previous works.
GeoWrap~\cite{berton2021viewpoint} uses a learned pairwise warping to increase visual overlap between images.
Toft et al. \cite{toft2020single} propose a method to remove perspective distortion based on single-image depth estimation.
RoRD~\cite{parihar2021rord} generate rotation-robust descriptors via orthographic viewpoint projection.
COTR~\cite{jiang2021cotr} also estimates scale by finding co-visible region, and uses recursive zooming to enable the matcher to sense geometry scale.
Patch2Pix~\cite{zhou2021patch2pix} uses the consistent with the epipolar geometry of an input image pair to supervise the training.
In our research, we delve deeper into the role of geometric prior in local feature matching and propose a novel and effective method to leverage epipolar constraint and relative position information in handling challenging scenes.
