Local feature matching, which aims to find correspondences between a pair of images, is essential for many important tasks in computer vision, such as Structure-from-Motion (SfM)~\cite{schonberger2016structure}, 3D reconstruction~\cite{dai2017bundlefusion}, visual localization~\cite{sattler2018benchmarking, taira2018inloc}, and pose estimation~\cite{grabner20183d, persson2018lambda}.
Given its broad application, local feature matching has received significant attention, leading to the development of many research studies.
Despite this, accurate local feature matching remains a challenging task, particularly in scenarios with poor texture, repetitive texture, illumination variations, and scale changes.

Numerous methods~\cite{detone2018superpoint, li20dualrc, r2d2, rocco2018neighbourhood, sun2021loftr} have been proposed to overcome the challenges mentioned above, which can be divided into two major groups: detector-based methods~\cite{barroso2019key, detone2018superpoint, dusmanu2019d2, ono2018lf, r2d2, sarlin2020superglue} and detector-free methods~\cite{huang2019dynamic, li20dualrc, rocco2020efficient, rocco2018neighbourhood, sun2021loftr, chen2022aspanformer,yu2023adaptive,edstedt2022deep}.
The detector-based approach consists of three separate stages: first, extracting keypoints from the images; then, generating descriptors of the keypoints; and finally, finding correspondences between keypoints using a matcher.
The performance of the detector-based method highly relies on the quality of keypoints.
Unfortunately, reliable keypoint detection in textureless or repetitive texture areas is a highly challenging problem that limits the final performance of detector-based methods.
In comparison, detector-free approaches build dense correspondences between pixels instead of extracted keypoints.
Recent works show that this method can handle poor textured regions better and demonstrate excellent performance.
Some recent works~\cite{sun2021loftr,jiang2021cotr,chen2022aspanformer,wang2022matchformer} leverage the Transformer architecture and shows impressive performance.
% As a representative method, LoFTR~\cite{sun2021loftr} leverages the Transformer architecture and shows impressive performance.
However, most of these works use an all-pixel-to-all-pixel matching process, which introduces irrelevant pixels and negatively affects the result in some scenes, such as regions with repetitive textures.

\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{graph/motivation_s.pdf}
    \caption{
    With the help of anchor points (marked in {\color{red} red}), we can correctly match point $A$ to point $C$ and remove interference from point $B$.
    }\label{fig:motivation_s}
    \vspace{-3 mm}
\end{figure}

Upon studying the previous matching methods, we have identified two issues that cannot be ignored in obtaining dense correspondences between images:
% (1) \textbf{How to extract more robust features that are more distinguishable in areas with poor or repetitive textures.}
(1) \textbf{How to extract more distinguishable features in areas with poor or repetitive textures.}
Existing methods focus on extracting features from appearance, which is not distinguishable enough.
As shown in motivation Figure~\ref{fig:motivation_s}, points $A$, $B$ and $C$ are similar in appearance, making it difficult to obtain accurate correspondence.
In contrast, textured anchor points (marked in {\color{red} red}) can  easily match with the correct correspondence through appearance.
We have discovered an interesting fact that by using the relative positional relationship between point $A$ and other anchor points, we can easily determine the correct matching position of $A$.
Therefore, it is necessary to consider the relative positional relationship with the anchor point during matching, which can help us make better judgments.
(2) \textbf{How to filter out irrelevant regions as much as possible during the matching process.}
Existing methods usually use Transformers for global feature update and matching, which would make matching process influenced by unrelated areas.
As shown in motivation Figure~\ref{fig:motivation_e}, the correct match of point $D$ is point $E$.
If point $D$ aggregates the features of point $F$, it will confuse the network to determine the final matching result.
Therefore, it is necessary to design a way to filter out the negative influence of irrelevant areas such as $F$.

\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{graph/motivation_e.pdf}
    \caption{
    Using the epipolar geometry prior to calculate the candidate matching area of point $D$, we can exclude the influence of point $F$ on $D$.
    }\label{fig:motivation_e}
    \vspace{-3 mm}
\end{figure}

To address the aforementioned issues, we propose the \textbf{Structured Epipolar Matcher} (SEM) with an \textbf{Iterative Epipolar Coarse Matching} stage, which consists of a \textbf{Structured Feature Extractor} and \textbf{Epipolar Attention/Matching Module}.
In the Structured Feature Extractor, we select high-confidence matching pixels as anchor points, and encode the relative position between each point of the image and the anchor points in a scale and rotation invariant manner as a supplement to the appearance features, making the features more discriminating.
In the Epipolar Attention/Matching Module, we consider the epipolar geometry prior to filter out candidate matching regions.
First we select points with high confidence, which is used to calculate the relative pose of the camera. 
And then, we use the epipolar area corresponding to each point as the valid area (painted in {\color{blue} blue} in Figure~\ref{fig:motivation_e}) for feature interaction and matching.
The entire Iterative Epipolar Coarse Matching process is iterated to gradually optimize the matching results.

The contributions of our method could be summarized into three-fold:
(1) We proposed a novel Structured Epipolar Matcher (SEM), which includes a Structured Feature Extractor and Epipolar Attention/Matching Module in a unified architecture.
(2) We design the Structured Feature Extractor, which can generate structured feature to complement the appearance features, making them more discriminating.
Also, we design Epipolar Attention/Matching Module, which uses epipolar geometry prior to filter out irrelevant matching regions as much as possible, and Iterative Epipolar Coarse Matching process will gradually optimize the matching results.
(3) Extensive experimental results on four challenging benchmarks show that our proposed method performs favorably against state-of-the-art image matching methods.