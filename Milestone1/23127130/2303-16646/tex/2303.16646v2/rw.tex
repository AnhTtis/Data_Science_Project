%Establishing correspondences between two images is a key step for many applications in computer vision including 3D reconstruction,
%image retrieval, visual localization, etc.
This section provides a brief overview of the methods related to local feature matching.
% \noindent\textbf{Sparse Matching Methods.}
% The sparse matching methods~\cite{tian2017l2,ono2018lf,dusmanu2019d2,luo2020aslfeat,r2d2,sarlin2020superglue}.

% \noindent\textbf{Detector-Based Local Feature Matching}.
% Detector-based methods, also referred to as \textit{extract-to-match} or \textit{sparse} methods, involve three main stages: feature detection, feature description, and feature matching.
% Local features such as hand-crafted SIFT~\cite{lowe2004distinctive} and ORB~\cite{rublee2011orb} are the most widely used.
% Recently, learning-based methods like LIFT~\cite{yi2016lift} and SuperPoint~\cite{detone2018superpoint} have been shown to significantly improve performance compared to classical methods.
% Some researchers also focus on enhancing the feature matching stage. Nearest Neighbor Search is the most popular classical matching method.
% Learning-based approaches such as D2Net~\cite{dusmanu2019d2} combine the detection and description stages, while Revaud et al.~\cite{r2d2} trains the R2D2 to identify reliable and repeatable local features. SuperGlue~\cite{sarlin2020superglue} introduces an attention-based GNN network which archives a significant performance improvement.
% Nevertheless, detector-based methods rely on keypoint detectors, which limits the performance in challenging scenarios such as repetitive textures, weak textures, and illumination changes.

% \noindent\textbf{Detector-Free Local Feature Matching.}
% % Detector-free approaches, which do not require a local feature detector and instead directly match dense features between pixels, are often referred to as \textit{dense} methods.
% Detector-free approaches directly match dense features between pixels without the local feature detector, which are also named \textit{dense} methods.
% While classical methods like Lucas-Kanade~\cite{lucas1981iterative} and Horn-Schunck~\cite{horn1981determining} exist, few of them outperform detector-based methods.
% Learning-based methods have revolutionized this field, with cost-volume-based methods and Transformer-based methods leading the charge.
% While NCNet~\cite{rocco2018neighbourhood} was the precursor of cost volume, its large computational and memory overhead limits its performance.
% DRC-Net~\cite{li20dualrc} improves upon NCNet~\cite{rocco2018neighbourhood} by building cost volumes at two different scales and fuses them to obtain dense matches, while GLU-Net~\cite{truong2020glu} also uses a multi-level structure to combine global and local correlations in a feature pyramid.
% GOCor~\cite{truong2020gocor} disambiguates repeated patterns with improved feature correlation layers.
% Considering the limited perceptual field of CNNs, Transformer-based approaches have also been proposed in recent years.
% COTR~\cite{jiang2021cotr} employs a Transformer decoder to determine the matching point for any given query point.
% LoFTR~\cite{sun2021loftr}, following SuperGlue~\cite{sarlin2020superglue}, uses self and cross attention to update dense features during the coarse stage and refines matches in the fine stage. 
% MatchFormer~\cite{wang2022matchformer} proposes a multi-scale fusion approach, while Aspanformer~\cite{chen2022aspanformer} uses flow maps and probabilistic models to select an adaptive attention span.
% Given that detector-free methods have been shown to perform better in local feature matching, we have chosen this paradigm as our baseline approach, and use our proposed new module to overcome the challenging scenarios.

\noindent\textbf{Local Feature Matching}.
The popular local feature matching methods can be divided into two paradigms: detector-based methods and detector-free methods.
Detector-based methods involve three main stages: feature detection, feature description, and feature matching.
Hand-crafted local features such as SIFT~\cite{lowe2004distinctive} and ORB~\cite{rublee2011orb} are the most widely used.
Recently, learning-based local features like LIFT~\cite{yi2016lift} and SuperPoint~\cite{detone2018superpoint} have been shown to significantly improve performance compared to classical methods.
Some researchers also focus on enhancing the feature matching stage, representative works include D2Net~\cite{dusmanu2019d2}, R2D2~\cite{r2d2} and SuperGlue~\cite{sarlin2020superglue}.
% Learning-based approaches such as D2Net~\cite{dusmanu2019d2} combine the detection and description stages, while Revaud et al.~\cite{r2d2} trains the R2D2 to identify reliable and repeatable local features. SuperGlue~\cite{sarlin2020superglue} introduces an attention-based GNN network which archives a significant performance improvement.
Nevertheless, detector-based methods rely on keypoint detectors, which limits the performance in challenging scenarios such as repetitive textures, weak textures, and illumination changes.
On the contrary,  Detector-free approaches directly match dense features between pixels without the local feature detector.
While classical methods~\cite{lucas1981iterative,horn1981determining} exist, few of them outperform detector-based methods.
Learning-based methods have revolutionized this field, with cost-volume-based methods~\cite{rocco2018neighbourhood,li20dualrc,truong2020glu,truong2020gocor,truong2021pdc} and Transformer-based methods~\cite{jiang2021cotr,sun2021loftr,wang2022matchformer,chen2022aspanformer,yu2023adaptive} leading the charge.
While cost-volume-based methods archive promising performance, the limited perceptual field of CNNs is its inescapable shortcoming.
Recently, Transformer-based methods overcome this problem and leads the benchmark.
% While NCNet~\cite{rocco2018neighbourhood} was the precursor of cost volume, its large computational and memory overhead limits its performance.
% DRC-Net~\cite{li20dualrc} improves upon NCNet~\cite{rocco2018neighbourhood} by building cost volumes at two different scales and fuses them to obtain dense matches, while GLU-Net~\cite{truong2020glu} also uses a multi-level structure to combine global and local correlations in a feature pyramid.
% GOCor~\cite{truong2020gocor} disambiguates repeated patterns with improved feature correlation layers.
% Considering the limited perceptual field of CNNs, Transformer-based approaches have also been proposed in recent years.
% COTR~\cite{jiang2021cotr} employs a Transformer decoder to determine the matching point for any given query point.
% LoFTR~\cite{sun2021loftr}, following SuperGlue~\cite{sarlin2020superglue}, uses self and cross attention to update dense features during the coarse stage and refines matches in the fine stage. 
% MatchFormer~\cite{wang2022matchformer} proposes a multi-scale fusion approach, while Aspanformer~\cite{chen2022aspanformer} uses flow maps and probabilistic models to select an adaptive attention span.
Given that detector-free methods have been shown to perform better in local feature matching, we have chosen this paradigm as our baseline approach, and use our proposed new module to overcome the challenging scenarios.

\noindent\textbf{Geometry Prior in Local Feature Matching.}
The significance of geometric priors in local feature matching has been explored in previous works.
GeoWrap~\cite{berton2021viewpoint} uses a learned pairwise warping to increase visual overlap between images.
Toft et al. \cite{toft2020single} propose a method to remove perspective distortion based on single-image depth estimation.
RoRD~\cite{parihar2021rord} generate rotation-robust descriptors via orthographic viewpoint projection.
COTR~\cite{jiang2021cotr} also estimates scale by finding co-visible region, and uses recursive zooming to enable the matcher to sense geometry scale.
Patch2Pix~\cite{zhou2021patch2pix} uses the consistent with the epipolar geometry of an input image pair to supervise the training.
In our research, we delve deeper into the role of geometric prior in local feature matching and propose a novel and effective method to leverage epipolar constraint and relative position information in handling challenging scenes.

\noindent\textbf{Iterative Optimization.}
Iterative optimization is a common paradigm in computer vision and has been explored in many previous work~\cite{sun2020acne,sun2023neuralbf,teed2020raft,jiang2021cotr,truong2020glu,truong2021pdc}.
For example, RAFT~\cite{teed2020raft} iteratively updates a flow field through a recurrent unit that performs lookups on the correlation volumes, ACNe~\cite{sun2020acne} uses an robust iterative optimization to build permutation-equivariant network, and NeuralBF~\cite{sun2023neuralbf} proposes an iterative bilateral filtering with learned kernels for instance segmentation on point clouds.
The iterative optimization is also deployed by some works in local feature matching, such as PDC-Net~\cite{truong2021pdc}, GLU-Net~\cite{truong2020glu} and COTR~\cite{jiang2021cotr}.
In this work, we follow this tried and tested paradigm and combine it with geometry priors.



