@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{Arango2019-sigir,
author = {Arango, Aym\'{e} and P\'{e}rez, Jorge and Poblete, Barbara},
title = {Hate Speech Detection is Not as Easy as You May Think: A Closer Look at Model Validation},
year = {2019},
isbn = {9781450361729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331184.3331262},
doi = {10.1145/3331184.3331262},
abstract = {Hate speech is an important problem that is seriously affecting the dynamics and usefulness of online social communities. Large scale social platforms are currently investing important resources into automatically detecting and classifying hateful content, without much success. On the other hand, the results reported by state-of-the-art systems indicate that supervised approaches achieve almost perfect performance but only within specific datasets. In this work, we analyze this apparent contradiction between existing literature and actual applications. We study closely the experimental methodology used in prior work and their generalizability to other datasets. Our findings evidence methodological issues, as well as an important dataset bias. As a consequence, performance claims of the current state-of-the-art have become significantly overestimated. The problems that we have found are mostly related to data overfitting and sampling issues. We discuss the implications for current research and re-conduct experiments to give a more accurate picture of the current state-of-the art methods.},
booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {45–54},
numpages = {10},
keywords = {experimental evaluation, social media, deep learning, hate speech classification},
location = {Paris, France},
series = {SIGIR'19}
}

@inproceedings{measurement_hs,
author = {Mondal, Mainack and Silva, Leandro Ara\'{u}jo and Benevenuto, Fabr\'{\i}cio},
title = {A Measurement Study of Hate Speech in Social Media},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078723},
doi = {10.1145/3078714.3078723},
abstract = {Social media platforms provide an inexpensive communication medium that allows anyone to quickly reach millions of users. Consequently, in these platforms anyone can publish content and anyone interested in the content can obtain it, representing a transformative revolution in our society. However, this same potential of social media systems brings together an important challenge---these systems provide space for discourses that are harmful to certain groups of people. This challenge manifests itself with a number of variations, including bullying, offensive content, and hate speech. Specifically, authorities of many countries today are rapidly recognizing hate speech as a serious problem, specially because it is hard to create barriers on the Internet to prevent the dissemination of hate across countries or minorities. In this paper, we provide the first of a kind systematic large scale measurement and analysis study of hate speech in online social media. We aim to understand the abundance of hate speech in online social media, the most common hate expressions, the effect of anonymity on hate speech and the most hated groups across regions. In order to achieve our objectives, we gather traces from two social media systems: Whisper and Twitter. We then develop and validate a methodology to identify hate speech on both of these systems. Our results identify hate speech forms and unveil a set of important patterns, providing not only a broader understanding of online hate speech, but also offering directions for detection and prevention approaches.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {85–94},
numpages = {10},
keywords = {hate speech, anonymity, social media, pattern recognition, whisper, twitter},
location = {Prague, Czech Republic},
series = {HT '17}
}

@article{Sarwar_Murdock_2022, 
title={Unsupervised Domain Adaptation for Hate Speech Detection Using a Data Augmentation Approach}, volume={16}, 
number={1}, journal={Proceedings of the International AAAI Conference on Web and Social Media}, 
author={Sarwar, Sheikh Muhammad and Murdock, Vanessa}, 
year={2022}, month={May}, pages={852-862},
url={https://ojs.aaai.org/index.php/ICWSM/article/view/19340}, 
abstractNote={Online harassment in the form of hate speech has been on the rise in recent years. Addressing the issue requires a combination of content moderation by people, aided by automatic detection methods. As content moderation is itself harmful to the people doing it, we desire to reduce the burden by improving the automatic detection of hate speech. Hate speech presents a challenge as it is directed at different target groups using a completely different vocabulary. Further the authors of the hate speech are incentivized to disguise their behavior to avoid being removed from a platform. This makes it difficult to develop a comprehensive data set for training and evaluating hate speech detection models because the examples that represent one hate speech domain do not typically represent others, even within the same language or culture. We propose an unsupervised domain adaptation approach to augment labeled data for hate speech detection. We evaluate the approach with three different models (character CNNs, BiLSTMs and BERT) on three different collections. We show our approach improves Area under the Precision/Recall curve by as much as 42\% and recall by as much as 278\%, with no loss (and in some cases a significant gain) in precision.}, 
}


@article{Wullach,  author={Wullach, Tomer and Adler, Amir and Minkov, Einat},  journal={IEEE Internet Computing},   title={Towards Hate Speech Detection at Large via Deep Generative Modeling},   year={2021},  volume={25},  number={2},  pages={48-57},  doi={10.1109/MIC.2020.3033161}}


@article{automated_hs, 
    title={Automated Hate Speech Detection and the Problem of Offensive Language}, 
    volume={11}, 
    url={https://ojs.aaai.org/index.php/ICWSM/article/view/14955}, 
    number={1}, 
    journal={Proceedings of the International AAAI Conference on Web and Social Media}, 
    author={Davidson, Thomas and Warmsley, Dana and Macy, Michael and Weber, Ingmar}, 
    year={2017}, 
    month={May}, 
    pages={512-515},
}

@article{Alkomah_lit_review,
author = {Alkomah, Fatimah and Ma, Xiaogang},
year = {2022},
month = {05},
pages = {273},
title = {A Literature Review of Textual Hate Speech Detection Methods and Datasets},
volume = {13},
journal = {Information},
doi = {10.3390/info13060273}
}

@inproceedings{solid,
    title = "{SOLID}: A Large-Scale Semi-Supervised Dataset for Offensive Language Identification",
    author = "Rosenthal, Sara  and
      Atanasova, Pepa  and
      Karadzhov, Georgi  and
      Zampieri, Marcos  and
      Nakov, Preslav",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.80",
    doi = "10.18653/v1/2021.findings-acl.80",
    pages = "915--928",
}

@inproceedings{offenseval-2020,
    title = "{S}em{E}val-2020 Task 12: Multilingual Offensive Language Identification in Social Media ({O}ffens{E}val 2020)",
    author = {Zampieri, Marcos  and
      Nakov, Preslav  and
      Rosenthal, Sara  and
      Atanasova, Pepa  and
      Karadzhov, Georgi  and
      Mubarak, Hamdy  and
      Derczynski, Leon  and
      Pitenis, Zeses  and
      {\c{C}}{\"o}ltekin, {\c{C}}a{\u{g}}r{\i}},
    booktitle = "Proceedings of the Fourteenth Workshop on Semantic Evaluation",
    month = dec,
    year = "2020",
    address = "Barcelona (online)",
    publisher = "International Committee for Computational Linguistics",
    url = "https://aclanthology.org/2020.semeval-1.188",
    doi = "10.18653/v1/2020.semeval-1.188",
    pages = "1425--1447",
    abstract = "We present the results and the main findings of SemEval-2020 Task 12 on Multilingual Offensive Language Identification in Social Media (OffensEval-2020). The task included three subtasks corresponding to the hierarchical taxonomy of the OLID schema from OffensEval-2019, and it was offered in five languages: Arabic, Danish, English, Greek, and Turkish. OffensEval-2020 was one of the most popular tasks at SemEval-2020, attracting a large number of participants across all subtasks and languages: a total of 528 teams signed up to participate in the task, 145 teams submitted official runs on the test data, and 70 teams submitted system description papers.",
}

@article{Fortuna-2018,
author = {Fortuna, Paula and Nunes, S\'{e}rgio},
title = {A Survey on Automatic Detection of Hate Speech in Text},
year = {2018},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3232676},
doi = {10.1145/3232676},
abstract = {The scientific study of hate speech, from a computer science point of view, is recent. This survey organizes and describes the current state of the field, providing a structured overview of previous approaches, including core algorithms, methods, and main features used. This work also discusses the complexity of the concept of hate speech, defined in many platforms and contexts, and provides a unifying definition. This area has an unquestionable potential for societal impact, particularly in online communities and digital media platforms. The development and systematization of shared resources, such as guidelines, annotated datasets in multiple languages, and algorithms, is a crucial step in advancing the automatic detection of hate speech.},
journal = {ACM Comput. Surv.},
month = {jul},
articleno = {85},
numpages = {30},
keywords = {opinion mining, literature review, natural language processing, Hate speech, text mining}
}

@inproceedings{ranasinghe-zampieri-2020-multilingual,
    title = "Multilingual Offensive Language Identification with Cross-lingual Embeddings",
    author = "Ranasinghe, Tharindu  and
      Zampieri, Marcos",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.470",
    doi = "10.18653/v1/2020.emnlp-main.470",
    pages = "5838--5844",
    abstract = "Offensive content is pervasive in social media and a reason for concern to companies and government organizations. Several studies have been recently published investigating methods to detect the various forms of such content (e.g. hate speech, cyberbulling, and cyberaggression). The clear majority of these studies deal with English partially because most annotated datasets available contain English data. In this paper, we take advantage of English data available by applying cross-lingual contextual word embeddings and transfer learning to make predictions in languages with less resources. We project predictions on comparable data in Bengali, Hindi, and Spanish and we report results of 0.8415 F1 macro for Bengali, 0.8568 F1 macro for Hindi, and 0.7513 F1 macro for Spanish. Finally, we show that our approach compares favorably to the best systems submitted to recent shared tasks on these three languages, confirming the robustness of cross-lingual contextual embeddings and transfer learning for this task.",
}

@inproceedings{basile-etal-2019-semeval,
    title = "{S}em{E}val-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in {T}witter",
    author = "Basile, Valerio  and
      Bosco, Cristina  and
      Fersini, Elisabetta  and
      Nozza, Debora  and
      Patti, Viviana  and
      Rangel Pardo, Francisco Manuel  and
      Rosso, Paolo  and
      Sanguinetti, Manuela",
    booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S19-2007",
    doi = "10.18653/v1/S19-2007",
    pages = "54--63",
    abstract = "The paper describes the organization of the SemEval 2019 Task 5 about the detection of hate speech against immigrants and women in Spanish and English messages extracted from Twitter. The task is organized in two related classification subtasks: a main binary subtask for detecting the presence of hate speech, and a finer-grained one devoted to identifying further features in hateful contents such as the aggressive attitude and the target harassed, to distinguish if the incitement is against an individual rather than a group. HatEval has been one of the most popular tasks in SemEval-2019 with a total of 108 submitted runs for Subtask A and 70 runs for Subtask B, from a total of 74 different teams. Data provided for the task are described by showing how they have been collected and annotated. Moreover, the paper provides an analysis and discussion about the participant systems and the results they achieved in both subtasks.",
}

@inproceedings{cyberbullying-in-games,
author = {Kwak, Haewoon and Blackburn, Jeremy and Han, Seungyeop},
title = {Exploring Cyberbullying and Other Toxic Behavior in Team Competition Online Games},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702529},
doi = {10.1145/2702123.2702529},
abstract = {In this work we explore cyberbullying and other toxic behavior in team competition online games. Using a dataset of over 10 million player reports on 1.46 million toxic players along with corresponding crowdsourced decisions, we test several hypotheses drawn from theories explaining toxic behavior. Besides providing large-scale, empirical based understanding of toxic behavior, our work can be used as a basis for building systems to detect, prevent, and counter-act toxic behavior.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3739–3748},
numpages = {10},
keywords = {trolling, team competition, toxic playing, cyberbullying, moba, online video game, crowdsourcing, league of legends},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}


@inproceedings{olid,
    title = "Predicting the Type and Target of Offensive Posts in Social Media",
    author = "Zampieri, Marcos  and
      Malmasi, Shervin  and
      Nakov, Preslav  and
      Rosenthal, Sara  and
      Farra, Noura  and
      Kumar, Ritesh",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1144",
    doi = "10.18653/v1/N19-1144",
    pages = "1415--1420",
    abstract = "As offensive content has become pervasive in social media, there has been much research in identifying potentially offensive messages. However, previous work on this topic did not consider the problem as a whole, but rather focused on detecting very specific types of offensive content, e.g., hate speech, cyberbulling, or cyber-aggression. In contrast, here we target several different kinds of offensive content. In particular, we model the task hierarchically, identifying the type and the target of offensive messages in social media. For this purpose, we complied the Offensive Language Identification Dataset (OLID), a new dataset with tweets annotated for offensive content using a fine-grained three-layer annotation scheme, which we make publicly available. We discuss the main similarities and differences between OLID and pre-existing datasets for hate speech identification, aggression detection, and similar tasks. We further experiment with and we compare the performance of different machine learning models on OLID.",
}



@inproceedings{Sanh2019,
abstract = {As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing (NLP), operating these large models in on-the-edge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation model, called DistilBERT, which can then be fine-tuned with good performances on a wide range of tasks like its larger counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a BERT model by 40\%, while retaining 97\% of its language understanding capabilities and being 60\% faster. To leverage the inductive biases learned by larger models during pre-training, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device study.},
archivePrefix = {arXiv},
arxivId = {1910.01108},
author = {Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
booktitle = {5th Workshop on Energy Efficient Machine Learning and Cognitive Computing @ NeurIPS 2019},
eprint = {1910.01108},
file = {:Users/shanest/Documents/Library/Sanh et al/5th Workshop on Energy Efficient Machine Learning and Cognitive Computing @ NeurIPS 2019/Sanh et al. - 2019 - DistilBERT, a distilled version of BERT smaller, faster, cheaper and lighter.pdf:pdf},
keywords = {model},
title = {{DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter}},
url = {http://arxiv.org/abs/1910.01108},
year = {2019}
}

@inproceedings{robust-learning-for-txt-clf,
author = {Xu, Guowei and Ding, Wenbiao and Fu, Weiping and Wu, Zhongqin and Liu, Zitao},
title = {Robust Learning for Text Classification with Multi-Source Noise Simulation and Hard Example Mining},
year = {2021},
isbn = {978-3-030-86516-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Many real-world applications involve the use of Optical Character Recognition (OCR) engines to transform handwritten images into transcripts on which downstream Natural Language Processing (NLP) models are applied. In this process, OCR engines may introduce errors and inputs to downstream NLP models become noisy. Despite that pre-trained models achieve state-of-the-art performance in many NLP benchmarks, we prove that they are not robust to noisy texts generated by real OCR engines. This greatly limits the application of NLP models in real-world scenarios. In order to improve model performance on noisy OCR transcripts, it is natural to train the NLP model on labelled noisy texts. However, in most cases there are only labelled clean texts. Since there is no handwritten pictures corresponding to the text, it is impossible to directly use the recognition model to obtain noisy labelled data. Human resources can be employed to copy texts and take pictures, but it is extremely expensive considering the size of data for model training. Consequently, we are interested in making NLP models intrinsically robust to OCR errors in a low resource manner. We propose a novel robust training framework which 1) employs simple but effective methods to directly simulate natural OCR noises from clean texts and 2) iteratively mines the hard examples from a large number of simulated samples for optimal performance. 3) To make our model learn noise-invariant representations, a stability loss is employed. Experiments on three real-world datasets show that the proposed framework boosts the robustness of pre-trained models by a large margin. We believe that this work can greatly promote the application of NLP models in actual scenarios, although the algorithm we use is simple and straightforward. We make our codes and three datasets publicly available ().},
booktitle = {Machine Learning and Knowledge Discovery in Databases. Applied Data Science Track: European Conference, ECML PKDD 2021, Bilbao, Spain, September 13–17, 2021, Proceedings, Part V},
pages = {285–301},
numpages = {17},
keywords = {Text mining, Robust representation},
location = {Bilbao, Spain},
url = {https://doi.org/10.1007/978-3-030-86517-7_18},
doi = {10.1007/978-3-030-86517-7_18},
}

@misc{Yuan,
  author = {Yuan, Lanqin and Rizoiu, Marian-Andrei},
  keywords = {Computation and Language (cs.CL), Computers and Society (cs.CY), Social and Information Networks (cs.SI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Detect Hate Speech in Unseen Domains using Multi-Task Learning: A Case Study of Political Public Figures},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International},
  doi = {10.48550/ARXIV.2208.10598},
  url = {https://arxiv.org/abs/2208.10598},
}

@inproceedings{Waseem2018BridgingTG,
  title={Bridging the Gaps: Multi Task Learning for Domain Transfer of Hate Speech Detection},
  author={Zeerak Waseem and James Thorne and Joachim Bingel},
  year={2018}
}

@article{Koksal2022ImprovedHE,
  title={Improved Hard Example Mining Approach for Single Shot Object Detectors},
  author={Aybora Koksal and Onder Tuzcuoglu and Kutalmis Gokalp Ince and Y. Ataseven and A. Aydin Alatan},
  journal={ArXiv},
  year={2022},
  volume={abs/2202.13080}
}

@INPROCEEDINGS{8575283,  author={Smirnov, Evgeny and Ivanova, Elizaveta and Melnikov, Aleksandr and Kalinovskiy, Ilya and Oleinik, Andrei and Luckyanets, Eugene},  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},   title={Hard Example Mining with Auxiliary Embeddings},   year={2018},  volume={},  number={},  pages={37-3709},  doi={10.1109/CVPRW.2018.00013}}

@article{CHEN2020259,
title = {Hard sample mining makes person re-identification more efficient and accurate},
journal = {Neurocomputing},
volume = {382},
pages = {259-267},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.11.094},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219316984},
author = {Kezhou Chen and Yang Chen and Chuchu Han and Nong Sang and Changxin Gao},
keywords = {Person re-identification, Hard sample mining, Deep learning},
abstract = {In recent years, the field of person re-identification has made significant advances riding on the wave of deep learning. However, owing to the fact that there are much more easy examples than those meaningful hard examples in a dataset, the training tends to stagnate quickly and the model may suffer from over-fitting, which leads to some error matching of models especially for some hard samples during the test process. Therefore, the hard sample mining method is fateful to optimize the model and improve the learning efficiency. In this paper, an Adaptive Hard Sample Mining algorithm is proposed for training a robust person re-identification model. No need for hand-picking the images in the batch or designing the loss function for both positive and negative pairs, we can briefly calculate the hard level by comparing the prediction result with the true label of the sample. Meanwhile, taking into account the change in the number of samples required for the model during training process, an adaptive threshold of hard level can make the algorithm not only stay in step with training process harmoniously but also alleviate the under-fitting and over-fitting problem simultaneously. Besides, the designed network to implement the approach is very efficient and has good generalization performance that can be combined with various existing models readily. Experimental results on Market-1501, DukeMTMC-reID and CUHK03 datasets clearly demonstrate the effectiveness of the proposed algorithm.}
}

@inproceedings{korencic-etal-2021-block,
    title = "To Block or not to Block: Experiments with Machine Learning for News Comment Moderation",
    author = "Korencic, Damir  and
      Baris, Ipek  and
      Fernandez, Eugenia  and
      Leuschel, Katarina  and
      S{\'a}nchez Salido, Eva",
    booktitle = "Proceedings of the EACL Hackashop on News Media Content Analysis and Automated Report Generation",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.hackashop-1.18",
    pages = "127--133",
    abstract = "Today, news media organizations regularly engage with readers by enabling them to comment on news articles. This creates the need for comment moderation and removal of disallowed comments {--} a time-consuming task often performed by human moderators. In this paper we approach the problem of automatic news comment moderation as classification of comments into blocked and not blocked categories. We construct a novel dataset of annotated English comments, experiment with cross-lingual transfer of comment labels and evaluate several machine learning models on datasets of Croatian and Estonian news comments. Team name: SuperAdmin; Challenge: Detection of blocked comments; Tools/models: CroSloEn BERT, FinEst BERT, 24Sata comment dataset, Ekspress comment dataset.",
}

@inproceedings{de-gibert-etal-2018-hate,
    title = "Hate Speech Dataset from a White Supremacy Forum",
    author = "de Gibert, Ona  and
      Perez, Naiara  and
      Garc{\'\i}a-Pablos, Aitor  and
      Cuadros, Montse",
    booktitle = "Proceedings of the 2nd Workshop on Abusive Language Online ({ALW}2)",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-5102",
    doi = "10.18653/v1/W18-5102",
    pages = "11--20",
    abstract = "Hate speech is commonly defined as any communication that disparages a target group of people based on some characteristic such as race, colour, ethnicity, gender, sexual orientation, nationality, religion, or other characteristic. Due to the massive rise of user-generated web content on social media, the amount of hate speech is also steadily increasing. Over the past years, interest in online hate speech detection and, particularly, the automation of this task has continuously grown, along with the societal impact of the phenomenon. This paper describes a hate speech dataset composed of thousands of sentences manually labelled as containing hate speech or not. The sentences have been extracted from Stormfront, a white supremacist forum. A custom annotation tool has been developed to carry out the manual labelling task which, among other things, allows the annotators to choose whether to read the context of a sentence before labelling it. The paper also provides a thoughtful qualitative and quantitative study of the resulting dataset and several baseline experiments with different classification models. The dataset is publicly available.",
}

@inproceedings{singapore,
author = {Almerekhi, Hind and Kwak, Haewoon and Jansen, Jim and Salminen, Joni},
year = {2019},
month = {09},
pages = {291-292},
title = {Detecting Toxicity Triggers in Online Discussions},
isbn = {978-1-4503-6885-8},
doi = {10.1145/3342220.3344933}
}

@article{Li_Ning_2022, title={Anti-Asian Hate Speech Detection via Data Augmented Semantic Relation Inference}, volume={16}, url={https://ojs.aaai.org/index.php/ICWSM/article/view/19319}, DOI={10.1609/icwsm.v16i1.19319}, abstractNote={With the spreading of hate speech on social media in recent years, automatic detection of hate speech is becoming a crucial task and has attracted attention from various communities. This task aims to recognize online posts (e.g., tweets) that contain hateful information. The peculiarities of languages in social media, such as short and poorly written content, lead to the difficulty of learning semantics and capturing discriminative features of hate speech. Previous studies have utilized additional useful resources, such as sentiment hashtags, to improve the performance of hate speech detection. Hashtags are added as input features serving either as sentiment-lexicons or extra context information. However, our close investigation shows that directly leveraging these features without considering their context may introduce noise to classifiers. In this paper, we propose a novel approach to leverage sentiment hashtags to enhance hate speech detection in a natural language inference framework. We design a novel framework SRIC that simultaneously performs two tasks: (1) semantic relation inference between online posts and sentiment hashtags, and (2) sentiment classification on these posts. The semantic relation inference aims to encourage the model to encode sentiment-indicative information into representations of online posts. We conduct extensive experiments on two real-world datasets and demonstrate the effectiveness of our proposed framework compared with state-of-the-art representation learning models.}, number={1}, journal={Proceedings of the International AAAI Conference on Web and Social Media}, author={Li, Jiaxuan and Ning, Yue}, year={2022}, month={May}, pages={607-617} }


@inproceedings{dong,
author = {Dong, Qi and Gong, Shaogang and Zhu, Xiatian},
year = {2017},
month = {10},
pages = {1869-1878},
title = {Class Rectification Hard Mining for Imbalanced Deep Learning},
doi = {10.1109/ICCV.2017.205},
}


@article{HFTransformers,
  author    = {Thomas Wolf and
               Lysandre Debut and
               Victor Sanh and
               Julien Chaumond and
               Clement Delangue and
               Anthony Moi and
               Pierric Cistac and
               Tim Rault and
               R{\'{e}}mi Louf and
               Morgan Funtowicz and
               Jamie Brew},
  title     = {HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  journal   = {CoRR},
  volume    = {abs/1910.03771},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.03771},
  eprinttype = {arXiv},
  eprint    = {1910.03771},
  timestamp = {Tue, 02 Jun 2020 12:49:01 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-03771.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{Masko2015TheIO,
   author = {Masko, David and Hensman, Paulina},
   institution = {KTH, School of Computer Science and Communication (CSC)},
   title = {The Impact of Imbalanced Training Data for Convolutional Neural Networks},
   year = {2015}
}

@inproceedings{Byrd2018WhatIT,
  title={What is the Effect of Importance Weighting in Deep Learning?},
  author={Jonathon Byrd and Zachary Chase Lipton},
  booktitle={International Conference on Machine Learning},
  year={2018}
}

@article{Padurariu,
author = {Padurariu, Cristian and Breaban, Mihaela},
year = {2019},
month = {01},
pages = {736-745},
title = {Dealing with Data Imbalance in Text Classification},
volume = {159},
journal = {Procedia Computer Science},
doi = {10.1016/j.procs.2019.09.229}
}

 @misc{wfa_2022, 
 title={Garm brand Safety Floor + Suitability Framework}, 
 url={https://wfanet.org/knowledge/item/2022/06/17/GARM-Brand-Safety-Floor--Suitability-Framework-3}, 
 institution={World Federation of Advertisers}, 
 author={WFA}, 
 year={2022}} 

@misc{Jafariakinabad,
author = {Jafariakinabad, Fereshteh and Tarnpradab, Sansiri and Hua, Kien},
year = {2019},
month = {02},
pages = {},
title = {Syntactic Recurrent Neural Network for Authorship Attribution}
}
 