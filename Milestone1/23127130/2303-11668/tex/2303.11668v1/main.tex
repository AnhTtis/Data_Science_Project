% EarthVision 2023 Paper Template based on the 
% CVPR 2023 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
%\usepackage[review]{cvpr}      % To produce the REVIEW version
%\usepackage{cvpr}              % To produce the CAMERA-READY version
\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{26} % *** Enter the EarthVision Paper ID here (taken from CMT)
\def\confName{EarthVision}
\def\confYear{2023}
\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Focus or Not: A Baseline for Anomaly Event Detection \\On the Open Public Places with Satellite Images}

\author{Yongjin Jeon\textsuperscript{\rm 1}\thanks{Equal Contribution}\and Youngtack Oh\textsuperscript{\rm 1}\protect\footnotemark[1]\and Doyoung Jeong\textsuperscript{\rm 1} \and Hyunguk Choi\textsuperscript{\rm 1} \and Junsik Kim\textsuperscript{\rm 2}\thanks{Corresponding Author}\\
{\textsuperscript{\rm 1} AI Research Center, SI-Analytics}\\
Daejeon, Republic of Korea\\
{\tt\small \{yongjin117,ytoh96,doyoungi,hyunguk\}@si-analytics.ai}
\and
{\textsuperscript{\rm 2} School of Engineering and Applied Science, Harvard University}\\
Boston, United States of America\\
{\tt\small mibastro@gmail.com}
}
\maketitle
%%%%%%%%% ABSTRACT

\begin{abstract}
   In recent years, monitoring the world wide area with satellite images has been emerged as an important issue.
   Site monitoring task can be divided into two independent tasks; 1) Change Detection and 2) Anomaly Event Detection.
   Unlike to change detection research is actively conducted based on the numerous datasets(\eg LEVIR-CD, WHU-CD, S2Looking, xView2 and etc...) to meet up the expectations of industries or governments, research on AI models for detecting anomaly events is passively and rarely conducted.
   In this paper, we introduce a novel satellite imagery dataset(AED-RS) for detecting anomaly events on the open public places. 
   AED-RS Dataset contains satellite images of normal and abnormal situations of 8 open public places from all over the world. 
   Each places are labeled with different criteria based on the difference of characteristics of each places. 
   With this dataset, we introduce a baseline model for our dataset TB-FLOW, which can be trained in weakly-supervised manner and shows reasonable performance on the AED-RS Dataset compared with the other NF(Normalizing-Flow) based anomaly detection models. Our dataset and code will be publicly open in \url{https://github.com/SIAnalytics/RS_AnomalyDetection.git}.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
\label{sec:intro}

\begin{figure*}[t]
    \begin{center}
    \includegraphics[width=470pt]{Figures/1_dataset_display.pdf} 
    \caption{Samples of AED-RS Dataset. The inside area of red polygons in each images are target area. For the task of anomaly event localization, binary mask is additionally given.}
    \label{fig:dataset}
    \end{center}
    \vspace{-2mm}
\end{figure*}

% task history 
Site monitoring using satellite imagery is a task for remotely assessing the information of a particular area.  
Along with the increasing range of area can be covered by satellite and it's decreasing revisit-time, the demand on the site monitoring technique is rapidly rising.  
To meet up these expectations, site monitoring has been researched in the way of change detection that detects the change of interests in the sensed images by comparing with the reference image~\cite{fang2021snunet,chen2021remote,zheng2021change,fang2022changer,seo2023self}. %[CD reference]  
However, methods for change detection have limitation that couldn't recognize the unclarified events which can be considered as anomalies.  
To be more specific, most of researches on change detection is being carried out only for a narrow range of targets such as building changes or road changes. 
Additionally, problems comes from detecting anomalies in the satellite images can't be solved by main-stream change detection models which are designed to compare the input pairs.  
For the non-mainstream change detection researches, L-UNet~\cite{papadomanolaki2021deep} takes multiple images to learn the semantic and changed information, but still it's impossible to capture the anomaly events.  
To overcome this limitation, we exploit the concept of anomaly detection in the research on the site monitoring with satellite imagery.  
Recent deep learning based anomaly detection researches are focused on the modeling the distribution of normal cases in controlled environment(\eg MVTec Anomaly Detection Dataset~\cite{bergmann2019mvtec})\cite{defard2021padim, wang2103student, roth2022towards, deng2022anomaly}.
Inspired by this principle of deep learning based anomaly detection, we design the anomaly event detection task into modeling the normal cases only in the area of interest(AoI, target area) in the given satellite images.  

% task introduction
The goal of proposed anomaly event detection is accurately localize the anomaly events which happened only on the open public places(\eg square, beach, airport, etc...) in the full scene.  
We conduct pre-research on training NF-based anomaly detection(AD) models on our AED-RS dataset and identify two challenges.  
First, model should recognize and localize the exact target area(open public place) from the training dataset.  
As shown in Fig. \ref{fig:dataset}, the target area that require monitoring are surrounded by objects with diverse visual features such as buildings and vehicles, and these objects are showing different characteristics depending on the time and spatial relation between target and satellite camera(in Fig. \ref{fig:domain_challenge}).
\begin{figure*}[h]
    \begin{center}
    \includegraphics[width=450pt]{Figures/2_domain_challenge.pdf}
    \caption{An example of domain challenge. The three displayed images are taken at the same location under different time stamp and various shooting conditions. Orange boxes in each images are having same position in each image and showing different visual characteristics(\eg color, size of shadow, shape of object, noise ratio in the image) for the same object.}
    \label{fig:domain_challenge}
    \end{center}
    \vspace{-8mm}
\end{figure*}
The varying features of static objects caused by environmental changes make NF-based AD models to struggle focusing on the events in the target and distract to the anomaly features in the outside of the target.  
To avoid this phenomenon, the proposed baseline model is designed to model the distribution of normal features separately for the target area and the non-target area by modifying the former NF-based AD models to have two NF branches.
This allows one branch to focus solely on the target and the other on the non-target.   
Second, in the training phase, model should learns the normal feature variations in the target area to identify the features of anomalies.  
The challenge of detecting anomalies located on the target area in satellite images is compounded by factors such as small scaled training dataset, sensor noise, insufficient semantic information due to blurring and shadows from large objects outside the target area.  
These factors make it difficult to effectively training the visual variations of normal cases using existing solutions, however our proposed baseline model has shown that it can also effectively learn and perform anomaly detection even in these situations.  

To summarize, our main contributions are as follows:
\begin{itemize}
  \item We firstly design and propose anomaly event detection task in the satellite imagery domain.
  \item We build a novel dataset named as AED-RS for deep learning research on anomaly event detection with satellite images. The details of AED-RS dataset is explained in Section~\ref{sec:dataset} and Appendix.
  \item We propose a baseline model which has two NF-branches for the decoding part that can capture the normality of target area and non-target area separately. Our baseline model obtained enhanced result compared to the other NF-based anomaly detection models.
\end{itemize}
\vspace{-4mm}
%-------------------------------------------------------------------------
\section{AED-RS Dataset}
\label{sec:dataset}
\subsection{Data Collection and Preprocessing}
\label{subsec:dataset collection}
AED-RS dataset is constructed with collected images from Google Earth.  
We collect 634 satellite images of 8 places over the global region.
Each images are collected with zoom-level of 20.  
After that, the target areas are centered and 1024 $\times$ 1024 size of images are produced through center cropping.  

The criteria for identifying anomaly events in each places are built and designed differently, taking into consideration the purpose of their usage and the various circumstances of the respective nation.  
Based on the designed criteria of describing the anomaly event, AED-RS dataset is divided into two groups; one for anomaly event scene classification and the other for going further into localizing the exact anomaly events. 
In here, we labeled the binary semantic mask of the position of anomaly events only on the group for localization task. 
The binary semantic segmentation masks of samples from anomaly event localization dataset are annotated by 8 experts in the field of interpreting remote sensing imagery.

\subsection{Dataset for Anomaly Event Scene Classification}
\label{subsec:anomaly scene classification dataset}
The anomaly events in this group are defined by temporary events such as large-scale construction works or public concerts.  
In this group, 4 places are included; 1) 2 squares 2) 1 airport 3) 1 beach, and the images of 4 places are labeled as anomaly if they contains the event of construction work or public concerts or the other unusual incidents. 
Such anomalies in this dataset are not having formal shape or size or patterns so that we exploit the evaluation concept of scene-level land-use classification in the satellite imagery domain.  
The statistics and samples of this dataset are shown in the Appendix 1.2.
\vspace{-1mm}
\subsection{Dataset for Anomaly Event Localization}
For the task of anomaly event localization, we find 4 places(4 squares) from the global region and collect the images.
In this dataset, binary masks of anomaly sites in anomaly samples are offered with different criteria for each places.  
The places in this group serve one of two purposes: either as a public rest area, or as a non-public area.
Places for public rest are labeled as anomalous scene if they feature temporary buildings, clusters of vehicles, dense crowds, or non-formal events such as construction work.  
In contrast, places that are not for public use are labeled much more sensitively under the same criteria.
The classification and creating binary masks of all samples in this group are labeled by human with aforementioned anomaly criteria and the details of this dataset are shown in the Appendix 1.1.

%\subsection{Mathematics}
%Please number all of your sections and displayed equations as in these examples:
%\begin{equation}
%  E = m\cdot c^2
%  \label{eq:important}
%\end{equation}
%and
%\begin{equation}
%  v = a\cdot t.
%  \label{eq:also-important}
%\end{equation}
%It is important for readers to be able to refer to any particular equation.
%Just because you did not refer to it in the text does not mean some future reader might not need to refer to it.
%It is cumbersome to have to use circumlocutions like ``the equation second from the top of page 3 column 1''.
%(Note that the ruler will not be present in the final copy, so is not an alternative to equation numbers).
%All authors will benefit from reading Mermin's description of how to write mathematics:
%\url{http://www.pamitc.org/documents/mermin.pdf}.

%\subsection{Miscellaneous}
%\noindent
% Compare the following:\\
% \begin{tabular}{ll}
%  \verb'$conf_a$' &  $conf_a$ \\
%  \verb'$\mathit{conf}_a$' & $\mathit{conf}_a$
% \end{tabular}\\
% See The \TeX book, p165.

% The space after \eg, meaning ``for example'', should not be a sentence-ending space.
% So \eg is correct, {\em e.g.} is not.
% The provided \verb'\eg' macro takes care of this.

% When citing a multi-author paper, you may save space by using ``et alia'', shortened to ``\etal'' (not ``{\em et.\ al.}'' as ``{\em et}'' is a complete word).
% If you use the \verb'\etal' macro provided, then you need not worry about double periods when used at the end of a sentence as in Alpher \etal.
% However, use it only when there are three or more authors.
% Thus, the following is correct:
%    ``Frobnication has been trendy lately.
%    It was introduced by Alpher~\cite{Alpher02}, and subsequently developed by
%    Alpher and Fotheringham-Smythe~\cite{Alpher03}, and Alpher \etal~\cite{Alpher04}.''

% This is incorrect: ``... subsequently developed by Alpher \etal~\cite{Alpher03} ...'' because reference~\cite{Alpher03} has just two authors.

% Update the cvpr.cls to do the following automatically.
% For this citation style, keep multiple citations in numerical (not
% chronological) order, so prefer \cite{Alpher03,Alpher02,Authors14} to
% \cite{Alpher02,Alpher03,Authors14}.


% \begin{figure*}
%   \centering
%   \begin{subfigure}{0.68\linewidth}
%     \fbox{\rule{0pt}{2in} \rule{.9\linewidth}{0pt}}
%     \caption{An example of a subfigure.}
%     \label{fig:short-a}
%   \end{subfigure}
%   \hfill
%   \begin{subfigure}{0.28\linewidth}
%     \fbox{\rule{0pt}{2in} \rule{.9\linewidth}{0pt}}
%     \caption{Another example of a subfigure.}
%     \label{fig:short-b}
%   \end{subfigure}
%   \caption{Example of a short caption, which should be centered.}
%   \label{fig:short}
% \end{figure*}
\vspace{-1mm}
\section{Preliminaries}
\subsection{Normalizing Flow}
The research on the anomaly event detection task starts from the studies on anomaly detection models which utilize the normalizing flow to model the distribution of normal cases.
Normalizing flow(NF) is a powerful tool that can approximate the true posterior distribution of continuous latent space.
From the study of Rezende \textit{et al.}~\cite{rezende2015variational} and Dinh \textit{et al}
~\cite{dinh2016density}, the formula of estimating the posterior distribution of data variable $x \in X$ from the observed latent variable $z \in Z$ with bijective mapping function $f: \mathrm{X}\rightarrow \mathrm{Z}, g: \mathrm{Z} \rightarrow \mathrm{X}$ is as follows:
\vspace{-1mm}
\begin{equation}
p_{\mathrm{X}}(x) = p_{\mathrm{Z}}(z)\left|\det\left( \frac{\partial f(x)}{\partial x^{T}}\right)\right|
\label{eq:first_eq}
\end{equation}
and equation \eqref{eq:first_eq} can be simply decomposed into sum of two terms through logarithms.
\begin{equation}
\log p_{\mathrm{X}}(x) = \log p_{\mathrm{Z}}(z) + \log\left(\left| \det\left(\frac{\partial f(x)}{\partial x^{T}} \right) \right|\right)
\label{eq:log-term}
\end{equation}
However, estimating the posterior distribution with equation \eqref{eq:log-term} is limited due to intractable computation of the second term(determinants).
Based on the possibility of tractability and flexiblity on training bijective model that showed in ~\cite{dinh2014nice}, Dinh \textit{et al}~\cite{dinh2016density} designed bijective function as an affine coupling layers by stacking the sequences of bijective invertible mappings.
%-------------------------------------------------------------------------
\subsection{Normalizing Flow based Anomaly Detection}
Estimating posterior distribution of normal samples in the dataset with normalizing flow is formerly proposed in CFLOW-AD~\cite{gudovskiy2022cflow}. CFLOW-AD utilize the flexible and tractable bijective invertible function proposed by Real NVP~\cite{dinh2016density} to designed multi-scale decoder architecture that estimates the log-likelihoods of 1-D feature vectors of normal samples embedded by feature extractor (CNN) $f: X\rightarrow Z,$ with additional condition $\mathbf{c}$. To optimize the CFLOW-AD, model is trained to minimize the reverse KL-Divergence~\cite{papamakarios2021normalizing} between distributions of embedded feature vector $p_\mathrm{Z}(z)$ and predictions from the bijective invertible model $ \hat{p}_{\mathrm{Z}} (z,\mathbf{c},\theta)$. The final objective function of CFLOW-AD is as follows:
\begin{equation}
    \mathcal{L}(\theta)=D_{KL}[p_Z(z)\parallel \hat{p}_Z(z,c,\theta)]
    \label{eq:cflow objective}
\end{equation}
and equation \eqref{eq:cflow objective} can be approximated by under equation
\begin{equation}
    \mathcal{L}(\theta) \approx \frac{1}{N}\Sigma^{N}_{i=1}\left[\frac{\parallel u_i \parallel^2_2}{2} - \log\left|\det \mathbf{J}_i\right| \right]
    \label{eq:cflow objective approx}
\end{equation}
In equation \eqref{eq:cflow objective approx}, $\theta$ denotes the parameter of conditional normalizing flow model, and $N$ denotes the number of samples in the training dataset. 

CFLOW-AD has successfully applied the power of normalizing flows to the task of anomaly detection. 
However, due to dealing with 1-D feature vectors, it depends on the multi-scale aggregation module and positional encoding vector $\mathbf{c} $ to model the distribution of spatial relationships between global and local features. 
To overcome this problem, Yu \textit{et al.}~\cite{yu2021fastflow} proposed FastFlow which can leverage the information from the 2D space. Yu \textit{et al.} designed FastFlow by stacking flow modules based on $3\times3$ and $1\times1$ convolutions and achieved higher scores in the image-level AUC evaluation on the MVTec AD Dataset compared to CFLOW-AD and even to memory-based methods such as Patch Core. 
%-------------------------------------------------------------------------
\begin{figure}[t]
    \centering
    \includegraphics[width=0.4\textwidth]{Figures/3_results_formermethod.pdf} 
    \caption{Anomaly detection results of CFLOW-AD in AED-RS Dataset. (a) Result of normal samples from CFLOW-AD with original setting. (b) Result of abnormal samples from CFLOW-AD with original setting. (c) Result of CFLOW-AD with color-jittering augmentation. (d) Result of CFLOW-AD with gray-scaling augmentation. The results shown in (c) may appear to be an improvement compared to other results, but it only shows a reduction in the anomaly score variance across the entire scene and still the issue of showing high anomaly scores around the target area's periphery remains unresolved.}
    \label{fig:formermodels_result}
    \vspace{-4mm}
\end{figure}

\section{A Baseline for AED-RS Dataset}
%-------------------------------------------------------------------------
\subsection{Limitation of Estimating Multi-Variate Gaussian Distribution}

The task of detecting anomalies in the satellite images contains prediction and localization problem with additional domain problems such as different visual characteristics of the same object depend on the factors such as angle of satellite camera, shooting time, climate condition. 
One of the major challenges of anomaly event detection with satellite imagery comes from this domain problems. 
Before designing our proposed method, we experiment CFLOW-AD and FastFlow on our AED-RS dataset and observed that the surroundings of the target area such as buildings, parks are showing lower likelihood score then anomalies in target area and detected as anomalies in the most of cases of the test dataset as shown in Fig.~\ref{fig:formermodels_result}. 
The major reason of this phenomenon is the high discrepancy of the variance of distribution between target and the other areas. 
As shown in Fig.~\ref{fig:data_statistic}, target area shows low variance and the other areas are observing high variance.
Based on this condition, former NF-based anomaly detection models struggle to model the distribution of normal features for target area. 
To alleviate this situation, we exploit data augmentation and curriculum learning techniques, but they were ineffective.
% \begin{table}
%   \centering
%   \begin{tabular}{@{}lc@{}}
%     \toprule
%     Method & Frobnability \\
%     \midrule
%     Theirs & Frumpy \\
%     Yours & Frobbly \\
%     Ours & Makes one's heart Frob\\
%     \bottomrule
%   \end{tabular}
%   \caption{Results.   Ours is better.}
%   \label{tab:example}
% \end{table}
\begin{figure}[t]
    \begin{center}
    \includegraphics[width=190pt]{Figures/4_variance_map.pdf} 
    \caption{Pixel-wise variance map of 8places in our AED-RS Dataset. From these images, we can observe the tendency of the variation between target and non-target areas.}
    \label{fig:data_statistic}
    \end{center}
    \vspace{-4mm}
\end{figure}
%-------------------------------------------------------------------------
\subsection{Decompose the Region}
Based on the statistics of the training dataset through Fig. \ref{fig:data_statistic}, we hypothesize that decomposing the areas with high(non-target) and low(target) variances in the images and processing them separately would enable anomaly event detection for the AED-RS dataset. 
Before spatially discriminate the target and non-target area of specific place $K$, we create the per pixel variance map $M^{var} \in \mathbb{R}^{H\times W}$ with all gray-scaled training images $x\sim p^K(x), x\in \mathbb{R}^{H\times W}$ of place $K$, as shown in Fig~\ref{fig:data_statistic}. 
\begin{equation}
    M^{var} = Normalize(var_{i=1,j=1}^{H,W}(x^1_{i,j}, x^2_{i,j}, \cdot\cdot\cdot , x^N_{i,j}))
    \label{eq:varmap_org}
\end{equation}
In the \eqref{eq:varmap_org}, $(\cdot\cdot\cdot,)$ denotes the channel-wise concatenation function and $N$ denotes the total number of training samples for place $K$. Then, we binarize the variance map by thresholding to achieve initial target area(T) and non-target area(NT) guidance map $M^{var}$.
\begin{equation}
    M^{var} \begin{cases} 0 & M^{var}_{i,j} < \alpha , Target \\ 1 & M^{var}_{i,j} \geq \alpha , Non\:Target \end{cases}
    \label{eq:binarize}
\end{equation}
The alpha $\alpha$ in the \eqref{eq:binarize} is set to the mean of normalized variance map.
After the initial T-NT guide map is attained, feature map $f^l$ which extracted from $l$-th layer of the feature extractor(CNN) is decomposed based on the T-NT map and fed to each of the normalizing flow models.
The two normalization flow models($D^{T}, D^{NT}$) are trained to estimate log-likelihood for each of the target area and the non-target area. 
\begin{figure*}[t]
    \begin{center}
    \includegraphics[width=470pt]{Figures/5_TBFlow_architecture.pdf} 
    \caption{The overall architecture of TB-CFLOW.}
    \label{fig:architecture_detail}
    \end{center}
    %\vspace{-4mm}
\end{figure*}
After each stage of training, the T-NT map is updated by sending the top $\beta \%$ of pixels in T to the NT and the bottom $\beta \%$ of pixels in the NT to the T based on the statistics of anomaly score of training samples.
The reason why training samples are used in this process is that all training samples are assumed to be in a normal cases.
For this reason, the pixels in T with high anomaly scores could be considered as a part of the NT and the pixels in the NT with low anomaly scores may need to be revive to the T. 
The overall T-NT map update algorithm in the validation phase is shown in Algorithm \ref{alg:map_update}. 
\begin{algorithm}[h]
\caption{T-NT map update in the validation phase}\label{alg:map_update}
\begin{algorithmic}[1]
\Require $\{x_n\}_{n=1}^{N}, M^{var}, E, D^{T}, D^{NT}, buf^T, buf^{NT}$
\While{$n\leq N$}
\State $z_n = E(x_n)$
\State $z^T_n, z^{NT}_n = decompose(z_n, M^{var})$
\State $\hat{z}^T_n,\hat{z}^{NT}_n = D^{T}(z^T_n), D^{NT}(z^{NT}_n)$
\State $buf^T \leftarrow (buf^T, \hat{z}^T_n)$, $buf^{NT} \leftarrow (buf^{NT}, \hat{z}^NT_n)$
\EndWhile{}
% \State $\hat{M}^{var,T}_{new} = Normalize(buf^T)$
% \State $\hat{M}^{var,NT}_{new} = Normalize(buf^{NT})$
% \State $\beta = 0.1\times \cos(\frac{2\times current\_epoch \times \pi}{180})+0.9$
% \State $\alpha^T = \max(\hat{M}^{var,T}_{new})*(\beta)$
% \State $\alpha^{NT} = \min(\hat{M}^{var,NT}_{new})*(1-\beta)$
% \State $M^{var,T}_{new} = Threshold^T(\hat{M}^{var,T}_{new}, \alpha^T)$
% \State $M^{var,NT}_{new} = Threshold^{NT}(\hat{M}^{var,NT}_{new}, \alpha^{NT})$
% \State $M^{var}_{new} = Aggregate(M^{var,T}_{new}, M^{var,NT}_{new})$

% \State $YT$
\State $\hat{M}^{var,T}_{new} = Normalize(buf^T)$
\State $\hat{M}^{var,NT}_{new} = Normalize(buf^{NT})$
%\State $\beta = 1-(0.1\times \cos(\frac{2\times current\_epoch \times \pi}{180})+0.9)$
\State $\beta = f_{schedule}(current\_epoch)$
\State $top^{T} = percentile(\hat{M}^{var,T}_{new}, 100-\beta)$
\State $bottom^{NT}= percentile(\hat{M}^{var,NT}_{new}, \beta)$
\State $M^{var,T}_{new} = Threshold(\hat{M}^{var,T}_{new}, top^{T})$
\State $M^{var,NT}_{new} = Threshold(\hat{M}^{var,NT}_{new}, bottom^{NT})$
\State $M^{var}_{new} = Aggregate(M^{var,T}_{new}, M^{var,NT}_{new})$
\end{algorithmic}
\end{algorithm}
In here, $E, D^T, D^{NT}$ are notation of encoder and normalizing flow based decoders for target area and non-target area. 
The $(\cdot , \cdot)$ in line 5 denotes channel-wise concatenation. 
When the validation step is finished and the new T-NT map $M^{var}_{new}$ is acquired, new training step is start with updated T-NT map.
%-------------------------------------------------------------------------

\subsection{Employ TB-Flow}
As mentioned earlier, the approach we propose to decompose the mixed distribution and model each one separately requires two decoders. 
To exploit our approach to CFLOW-AD and FastFlow, decoding architecture needs to be modified into having two normalizing flow branches.
Fig.~\ref{fig:architecture_detail} describes the overall architecture of modified CFLOW-AD. 
Distributor module in Fig.~\ref{fig:architecture_detail}  is equal to the $decompose$ function in Algorithm \ref{alg:map_update} however implementation is differently conducted in CFLOW-AD and FastFlow as described in Fig.~\ref{fig:decompose_module}. 
In CFLOW-AD, pixels of target and non-target area are split based on T-NT map, while 2D feature vector is multiplied to each 2D binary masks($M^T_{new}, M^{NT}_{new}$) in FastFlow to preserve the spatial information.
\begin{figure*}[t]
    \begin{center}
    \includegraphics[width=470pt]{Figures/6_decompose_module.pdf} 
    \caption{Figure of the decompose module that are exploited in CFLOW-AD(a) and FastFlow(b). Operation $\odot$ in (b) denotes the element-wise multiplication.}
    \label{fig:decompose_module}
    \end{center}
\end{figure*}
%------------------------------------------------------------------------
\section{Experiments}
\subsection{Experiment setting}
\paragraph{Dataset}
Due to the small number of samples for each places, we evaluate TB-Flow method based on 5-fold cross validation (3 folds for training and one fold for validation and the other for testing). 
After that, to understand the affection of input size to the anomaly event detection performance, images are resized into 3 different scales (256$\times$256, 512$\times$512, 1024$\times$1024) and experimented based on the assumption that the distribution of visual features would vary depending on the level of detail. 

To evaluate the anomaly scene-level classification performance of TB-Flow method, whole places in the dataset are used, while only 4 places(images of place 1-4 are offered with ground-truth binary semantic masks) are used in the evaluation of anomaly event localization task.

\paragraph{Architecture Details}
The most of hyperparameter settings for TB-CFLOW and TB-FastFlow architecture are following its reference architectures. 
Wide-ResNet50-2 is used for a backbone network and the features of the last layer in the first three blocks are fed to the decoder. 
In the decoder part, number of flow steps for both model are equally set to 8. 
For the T-NT map updating process in Algorithm \ref{alg:map_update}, we use cosine based schedule function $f_{schedule}$ as follows:
\begin{equation}
    f_{schedule} = 1-(0.1\times \cos(\frac{2\times current\_epoch \times \pi}{180})+0.9)
    \label{eq:schedule_func}
\end{equation}
The cosine-based schedule function creates a cycle where the T-NT map update process starts out passively, then gradually becomes more aggressive before returning to a passive state. This prevents the model from experiencing unstable optimization due to overly aggressive T-NT map updates.

Training epoch for TB-CFLOW and TB-FastFlow are set to 50(100 in CFLOW-AD) and 300(500 in FastFlow) each due to the size of AED-RS Dataset.

\subsection{Metrics for Evaluation}
To evaluate the performance of TB-Flow methods on the anomaly scene-level classification task, AUROC is employed. %with additional condition.
% Typically, evaluation at the image-level is performed soley on the classification result for the full scene.
% However, for the proposed anomaly scene classification task, full scene classification must be performed based only on anomalies within the target area, and considered as a failure case if the scene classification result is correct while an anomaly event is detected only in the non-target area.

For the localization task, the performance of our method is measured by instance-based F1-Score and image-level AUROC.
We have introduced the instance-based F1-Score as a modified version of the standard F1-Score, taking into account the fact that although the goal of localizing anomaly events in satellite images is the same as general anomaly detection, the predicted results of anomaly events from applications in the satellite imagery domain require immediate human verification.
Instance-based F1-Score is same as F1-Score formula but has a difference in computing Precision and Recall value. Precision and Recall of instance-based F1-Score are formulated as $\frac{TP_{\alpha}}{N_p}$ and $\frac{TP_{\alpha}}{K_p}$($\alpha$ is IoU threshold(\eg 10$\%$) for counting true positive instances and $N_p$ and $K_p$ are total number of ground truth anomaly instances and predicted anomaly instances of each place $p$). 

In this paper, we also present the false alarm rate which hinders the provision of objective information.
False alarms are counted when the predicted anomaly sites are not satisfying the condition of $\alpha\%$ IoU, or localized on the non-target area and shown in Tab.\ref{table:false_alarm}. 

\subsection{Experiment Results}
\setlength{\tabcolsep}{1pt}
\begin{table*}[t]
\begin{center}
\caption{Comparison of the anomaly event scene classification performance(AUROC Score) on the AED-RS dataset between TB-Flow based Methods and FastFlow. Place1 to place4 are in the anomaly event localization group and the other four places are in the anomaly scene classification group.}
\label{table:main_cls_result}
\resizebox{\textwidth}{!}{%
\begin{tabular}{c|cccccccc}
\hline 
{\scriptsize{\textbf{Models}}}
&{\scriptsize Place1}
&{\scriptsize Place2}
&{\scriptsize Place3}
&{\scriptsize Place4}
&{\scriptsize Place5}
&{\scriptsize Place6}
&{\scriptsize Place7}
&{\scriptsize Place8} \\
\hline

% {\scriptsize CFLOW-AD}
% &{\scriptsize 0.6964$\pm$0.129} 
% &{\scriptsize \textbf{0.6560}$\pm$0.042} 
% &{\scriptsize 0.7878$\pm$0.102} 
% &{\scriptsize 0.6286$\pm$0.228} 
% &{\scriptsize 0.6219$\pm$0.135} 
% &{\scriptsize 0.8595$\pm$0.055}
% &{\scriptsize 0.5383$\pm$0.057}
% &{\scriptsize 0.7134$\pm$0.138}\\

{\scriptsize TB-CFLOW} 
&{\scriptsize 0.6848$\pm$0.115} 
&{\scriptsize 0.6480$\pm$0.065} 
&{\scriptsize 0.6556$\pm$0.085} 
&{\scriptsize 0.5619$\pm$0.278} 
&{\scriptsize 0.6604$\pm$0.083} 
&{\scriptsize 0.8137$\pm$0.081}
&{\scriptsize 0.4881$\pm$0.052}
&{\scriptsize \textbf{0.8653$\pm$0.065}}\\

{\scriptsize FastFlow} 
&{\scriptsize 0.6006$\pm$0.061} 
&{\scriptsize 0.5992$\pm$0.134} 
&{\scriptsize 0.7322$\pm$0.089} 
&{\scriptsize \textbf{0.7238$\pm$0.149}} 
&{\scriptsize 0.6607$\pm$0.092} 
&{\scriptsize \textbf{0.9750$\pm$0.038}}
&{\scriptsize 0.6274$\pm$0.164}
&{\scriptsize 0.6954$\pm$0.102}\\

{\scriptsize \textbf{TB-FastFlow}} 
&{\scriptsize \textbf{0.7842$\pm$0.111}} 
&{\scriptsize \textbf{0.6540$\pm$0.090}}
&{\scriptsize \textbf{0.7844$\pm$0.062}}
&{\scriptsize 0.6095$\pm$0.083} 
&{\scriptsize \textbf{0.7722$\pm$0.064}} 
&{\scriptsize 0.9706$\pm$0.033}
&{\scriptsize \textbf{0.7314$\pm$0.104}}
&{\scriptsize 0.6750$\pm$0.095}\\
\hline
\end{tabular}
}
\end{center}
\end{table*}
\setlength{\tabcolsep}{1pt}
We train TB-CFLOW and TB-FastFlow and compare the performance with FastFlow\cite{yu2021fastflow} for each places in each tasks.
The AUROC scores and instance-based F1 scores recorded on the experimental tables in this paper are the values selected for each experiment, after finding the best-performing model over the entire epochs.

Tab.~\ref{table:main_cls_result} shows the anomaly event scene classification results on our AED-RS Dataset.
Our proposed method demonstrated effectiveness by achieving higher AUROC scores in five places(place 1,2,3,5,7) compared to other mono-branch methods when applied to the 2D normalizing flow based architecture.
Also, except for place4, TB-FastFlow achieved results to the near of the best score for the rest of places.
However, our two branch based region decomposing method showed negligible improvement when applied to the 1D normalizing flow model.

\setlength{\tabcolsep}{1pt}
\begin{table}[h]
\begin{center}
\caption{Comparison of the anomaly event localization performance(Instance F1-Score) on the AED-RS dataset between TB-FastFlow and FastFlow. For the TB-FastFlow, constant-linear function(l) with value of 0.1 and cosine based function(c) are experimented.}
\label{table:main_det_result}
\begin{tabular}{c|cccc}
\hline 
{\scriptsize{\textbf{Models}}}
&{\scriptsize Place1}
&{\scriptsize Place2}
&{\scriptsize Place3}
&{\scriptsize Place4} \\
\hline

% {\scriptsize CFLOW-AD}
% &{\scriptsize 77.21$\pm$5.48} 
% &{\scriptsize 75.77$\pm$5.36} 
% &{\scriptsize 86.84$\pm$4.39} 
% &{\scriptsize 74.00$\pm$xx}\\
% {\scriptsize TB-CFLOW} 
% &{\scriptsize -$\pm$-} 
% &{\scriptsize -$\pm$-} 
% &{\scriptsize -$\pm$-} 
% &{\scriptsize -$\pm$-}\\

{\scriptsize FastFlow} 
&{\scriptsize 0.0938$\pm$0.040} 
&{\scriptsize 0.1237$\pm$0.062} 
&{\scriptsize 0.0696$\pm$0.032} 
&{\scriptsize 0.0416$\pm$0.028}
\\

{\scriptsize TB-FastFlow$_{l}$} 
&{\scriptsize 0.1089$\pm$0.027} 
&{\scriptsize 0.1347$\pm$0.021} 
&{\scriptsize \textbf{0.0964$\pm$0.061}}
&{\scriptsize \textbf{0.1474$\pm$0.082}}
\\
{\scriptsize TB-FastFlow$_{c}$} 
&{\scriptsize \textbf{0.1347$\pm$0.021}}
&{\scriptsize \textbf{0.1474$\pm$0.082}} 
&{\scriptsize 0.0746$\pm$0.053}
&{\scriptsize 0.0042$\pm$0.008}
\\
\hline
\end{tabular}
\end{center}
\end{table}
\setlength{\tabcolsep}{1pt}

The results of anomaly event localization is written in the Tab. \ref{table:main_det_result}. 
In the localization evaluation, 10$\%$ is used for IoU threshold value.
The threshold value is decided based on the view point of monitoring that recall should be close to 1 while preventing the models to predict whole scene as anomaly site or false alarming.
Interestingly, linear scheduled TB-FastFlow achieved highest instance-based recall score in place 3 and place 4 while cosine based scheduled TB-FastFlow achieved highest instance-based recall in place 1 and place 2. 

From the results in Tab.~\ref{table:false_alarm}, our proposed methodology has improved the false alarm score compared to other methodologies, but it still shows a high value due to its weakly-supervised learning manner that there is no supervision of anomaly sites to the model while training.
\setlength{\tabcolsep}{1pt}
\begin{table}[h]
\begin{center}
\caption{False alarm rate of each models on the AED-RS localization dataset. The place 5 to 8 are not used to check false alarm rate due to requirement of anomaly semantic mask.}
\label{table:false_alarm}
\begin{tabular}{c|cccc}
\hline 
{\scriptsize{\textbf{Models}}}
&{\scriptsize Place1}
&{\scriptsize Place2}
&{\scriptsize Place3}
&{\scriptsize Place4} \\
\hline

% {\scriptsize CFLOW-AD}
% &{\scriptsize 77.21$\pm$5.48} 
% &{\scriptsize 75.77$\pm$5.36} 
% &{\scriptsize 86.84$\pm$4.39} 
% &{\scriptsize 74.00$\pm$xx}\\
% {\scriptsize TB-CFLOW} 
% &{\scriptsize -$\pm$-} 
% &{\scriptsize -$\pm$-} 
% &{\scriptsize -$\pm$-} 
% &{\scriptsize -$\pm$-}\\

{\scriptsize FastFlow} 
&{\scriptsize 0.9015$\pm$0.032} 
&{\scriptsize 0.9064$\pm$0.053} 
&{\scriptsize 0.8587$\pm$0.067} 
&{\scriptsize 0.9482$\pm$0.048}
\\
{\scriptsize TB-FastFlow$_{l}$} 
&{\scriptsize 0.8354$\pm$0.018} 
&{\scriptsize \textbf{0.8344$\pm$0.037} }
&{\scriptsize 0.9223$\pm$0.054} 
&{\scriptsize \textbf{0.8937$\pm$0.071}}
\\
{\scriptsize TB-FastFlow$_{c}$} 
&{\scriptsize \textbf{0.8344$\pm$0.037} }
&{\scriptsize 0.8937$\pm$0.071} 
&{\scriptsize \textbf{0.7845$\pm$0.092} }
&{\scriptsize 0.9962$\pm$0.007}
\\
\hline
\end{tabular}
\end{center}
\end{table}
\setlength{\tabcolsep}{1pt}

\section{Analysis}
In this section we presents various analytic experiments to analyze the affection of factors such as scale of image, number of training samples, various schedule function of T-NT map update process to the anomaly event detection performance. 
\paragraph{Scale of Image}
From the EDA(exploratory dataset analysis) on AED-RS dataset, we anticipate that distribution of visual features would appear differently depending on the degree of detail. 
In other words, a size of 1024$\times$1024 contains the largest amount of information compared to other scale settings to the extent that can observe the texture of buildings from the image, while even hard to identify the existence of the windows in the building in the 256$\times$256 images.
The performance of anomaly event detection along with the input size are checked with TB-FastFlow and the results are shown in Tab.~\ref{table:result_inputscale}.
\setlength{\tabcolsep}{1pt}
\begin{table}[h]
\begin{center}
\caption{Experiment result of TB-FastFlow on AED-RS localization dataset with varing input scales(256$\times$256, 512$\times$512, 1024$\times$1024). In this table, $cls$ and $loc$ denotes scene-classification task(AUROC) and localization task(Instance F1-Score) each.}
\label{table:result_inputscale}
\begin{tabular}{c|cccc}
\hline 
{\scriptsize{\textbf{Input Scale}}}
&{\scriptsize Place1}
&{\scriptsize Place2}
&{\scriptsize Place3}
&{\scriptsize Place4} \\
\hline
{\scriptsize 256$\times$256$_{cls}$} 
&{\scriptsize 0.7721$\pm$0.047} 
&{\scriptsize 0.6115$\pm$0.024} 
&{\scriptsize 0.6689$\pm$0.151} 
&{\scriptsize 0.6476$\pm$0.065}
\\
{\scriptsize 512$\times$512$_{cls}$} 
&{\scriptsize \textbf{0.7842$\pm$0.111}}
&{\scriptsize 0.6540$\pm$0.090} 
&{\scriptsize 0.7314$\pm$0.1049} 
&{\scriptsize \textbf{0.6750$\pm$0.095}}
\\
{\scriptsize 1024$\times$1024$_{cls}$} 
&{\scriptsize 0.7140$\pm$0.128} 
&{\scriptsize \textbf{0.6607$\pm$0.088}}
&{\scriptsize \textbf{0.8600$\pm$0.054}}
&{\scriptsize 0.6143$\pm$0.250}
\\\hline
{\scriptsize 256$\times$256$_{loc}$} 
&{\scriptsize \textbf{0.1587$\pm$0.042}}
&{\scriptsize \textbf{0.1835$\pm$0.091}}
&{\scriptsize 0.0603$\pm$0.029} 
&{\scriptsize 0.0094$\pm$0.013}
\\
{\scriptsize 512$\times$512$_{loc}$} 
&{\scriptsize 0.1347$\pm$0.021}
&{\scriptsize 0.1474$\pm$0.082} 
&{\scriptsize 0.0746$\pm$0.053}
&{\scriptsize 0.0042$\pm$0.008}
\\
{\scriptsize 1024$\times$1024$_{loc}$} 
&{\scriptsize 0.0736$\pm$0.030} 
&{\scriptsize 0.0703$\pm$0.025} 
&{\scriptsize \textbf{0.1187$\pm$0.049}}
&{\scriptsize 0.0082$\pm$0.016}
\\
\hline
\end{tabular}
\end{center}
\end{table}
\setlength{\tabcolsep}{1pt}
\paragraph{Schedule Function of T-NT Update Process}
The T-NT map update process is one of the most significant features of our approach. 
To refine the guidance of target and non-target areas, we leverage a scheduling function to dynamically adjust the number of pixels to be removed or revived.
We use constant-linear and cosine-based functions to perform performance analysis based on the degree of change in the number of pixels in the target area during training phase.  
The experiment results are shown in Tab.~\ref{table:result_schedule_func}.
\setlength{\tabcolsep}{1pt}
\begin{table*}[t]
\begin{center}
\caption{Anomaly event scene classification performance(AUROC Score) of TB-FastFlow on the AED-RS dataset with various schedule functions. Linear 0.1$\%$ moves 0.1$\%$ of pixels among total pixels in the image based on the anomaly score, and cosine moves the pixels based on the ratio defined by (\ref{eq:schedule_func}).}
\label{table:result_schedule_func}
\resizebox{\textwidth}{!}{%
\begin{tabular}{c|cccccccc}
\hline 
{\scriptsize{\textbf{S.F. Setting}}}
&{\scriptsize Place1}
&{\scriptsize Place2}
&{\scriptsize Place3}
&{\scriptsize Place4}
&{\scriptsize Place5}
&{\scriptsize Place6}
&{\scriptsize Place7}
&{\scriptsize Place8} \\
\hline

{\scriptsize Linear 0.1}
&{\scriptsize 0.7800$\pm$0.111} 
&{\scriptsize 0.6048$\pm$0.123} 
&{\scriptsize 0.7189$\pm$0.087} 
&{\scriptsize 0.5952$\pm$0.252} 
&{\scriptsize 0.7189$\pm$0.140} 
&{\scriptsize 0.9912$\pm$0.012}
&{\scriptsize 0.6173$\pm$0.157}
&{\scriptsize 0.7854$\pm$0.025}\\

{\scriptsize Linear 0.2} 
&{\scriptsize 0.7442$\pm$0.107} 
&{\scriptsize \textbf{0.6793$\pm$0.085}} 
&{\scriptsize 0.7389$\pm$0.040} 
&{\scriptsize 0.4571$\pm$0.264}
&{\scriptsize 0.7248$\pm$0.089} 
&{\scriptsize 0.9884$\pm$0.014} 
&{\scriptsize 0.7068$\pm$0.071} 
&{\scriptsize 0.7411$\pm$0.098}
\\

{\scriptsize Linear 0.4} 
&{\scriptsize 0.7388$\pm$0.139} 
&{\scriptsize 0.5996$\pm$0.090} 
&{\scriptsize 0.7344$\pm$0.098} 
&{\scriptsize 0.5048$\pm$0.155}
&{\scriptsize 0.6804$\pm$0.070} 
&{\scriptsize \textbf{0.9999$\pm$0.0}}
&{\scriptsize 0.7006$\pm$0.169} 
&{\scriptsize \textbf{0.7946$\pm$0.064}}
\\

{\scriptsize Cosine} 
&{\scriptsize \textbf{0.7842$\pm$0.111}}
&{\scriptsize 0.6540$\pm$0.090} 
&{\scriptsize \textbf{0.7844$\pm$0.062}}
&{\scriptsize \textbf{0.6095$\pm$0.083}}
&{\scriptsize \textbf{0.7722$\pm$0.064}}
&{\scriptsize 0.9706$\pm$0.033}
&{\scriptsize \textbf{0.7314$\pm$0.104}}
&{\scriptsize 0.6750$\pm$0.095}\\
\hline
\end{tabular}
}
\end{center}
\end{table*}
\setlength{\tabcolsep}{1pt}
\paragraph{Qualitative Analysis}
Qualitative analysis of our method are listed in the Appendix.
We display the visualization of the anomaly score and predicted anomaly sites based on the output of TB-method and the evolving T-NT area guide map during training phase.
The figures of qualitative results in Appendix show that our method can focus more on the target area while ignoring objects in the non-target area. 
Also results of our method give more acceptable and understandable anomaly score map compared to mono-branch models(\eg FastFlow). 

% While doing qualitative analysis, we gain unexpected anomaly information of the place 7 that didn't consider as an anomaly during the dataset construction stage.
% It presents that our method can capture more useful information to detect anomaly events.
% This case is also displayed in Appendix. 

\section{Limitations and conclusion}
 TB-FLOW based anomaly detection has shown better performance than previous methodologies, it still suffers from the issue of excessive reliance on threshold values in classifying pixels as normal or abnormal based on the anomaly score, which is a problem that former anomaly detection methodologies have also encountered. 

In the target area guiding part, limitation of our method comes from the shadows in the target area by objects in the non-target area. 
Shadows are appeared rarely with various shapes due to solar elevation, solar azimuth angle and satellite camera position and causing a high pixel-wise variance problem that can be a reason of misguiding the target area. 
Additionally, even in the normal scene, these types of shadows could lead a high anomaly score at the inference stage. 

The main critical limitation of our method is that it can only be tested on open public places that are well maintained throughout the four seasons by human management. 
Due to this reason, AED-RS dataset is constructed with carefully selected 8 open public places.

We propose a novel task in the satellite imagery domain with datasets and a baseline model.
The proposed anomaly detection models based on the two-branch normalizing flows demonstrate experimentally that separating the spatial regions of normal samples into two groups(target and non-target) based on pixel-wise variance allows for more accurate and efficient modeling of the desired normal distribution compared to the former methods.

\section{Acknowledgement}
This project has been supported by 2 groups; GIST (Gwangju Institue of Science and Technology) HPC-AI Open Infrastructure and SI-Analytics GeoAI Platform Group. 
We appreciate the GPU computing support of HPC-AI Open Infrastructure via GIST SCENT and the data manager Dongjin Kim in SI-Analytics GeoAI Platform Group.
%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
