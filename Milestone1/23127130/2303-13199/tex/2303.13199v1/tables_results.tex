\documentclass{article}
\usepackage{chngpage}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{dirtytalk}
\usepackage{multirow}
\usepackage[margin=3cm,showframe=false]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{bbm}
\usepackage{xparse}
\usepackage[version=3]{mhchem}
\usepackage{array}
\usepackage{tabularx}
\usepackage{ragged2e}
\usepackage{multicol}
\usepackage{lineno}
%\usepackage[justification=centering]{caption}
%\usepackage[singlelinecheck=false]{caption}

% Formatting packages
\usepackage{float}
\usepackage{xcolor}

% In paragraph enumerate
\usepackage{paralist}

\usepackage{arydshln}

%\title{Toyota project}
%\author{}
%\date{March 2022}
\newcommand{\argmin}{\mathop{\mathrm{argmin}}}  
\newcommand{\argmax}{\mathop{\mathrm{argmax}}} 

\newcommand{\dx}{\mathrm{d}x}
\newcommand{\dy}{\mathrm{d}y}
\newcommand{\dz}{\mathrm{d}z}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\zV}{\mathbf{0}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cU}{\mathcal{U}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\hp}{\hat{\phi}}
\newcommand{\ap}{\alpha}
\newcommand{\eps}{\epsilon}
\newcommand{\veps}{\varepsilon}
\newcommand{\Sp}{\Omega}
\newcommand{\D}{\delta}
\newcommand{\W}{\mathrm{W}}
\newcommand{\PD}{D_\phi}
\newcommand{\KL}{\mathrm{KL}}
\newcommand{\JF}{\mathrm{JF}}
\newcommand{\JS}{\mathrm{JS}}
\newcommand{\SH}{\mathrm{H}^2}
\newcommand{\TV}{\mathrm{TV}}
\newcommand{\CS}{\chi^2}
\newcommand{\HA}{\mathcal{H}_\alpha}
\newcommand{\PQ}[1]{(P_{#1},Q_{#1})}
\newcommand{\LHS}{\textrm{LHS}}
\newcommand{\RHS}{\textrm{RHS}}
\newcommand{\vspan}{\mathrm{span}}
\newcommand{\cl}{\mathrm{cl}}
\newcommand{\trace}{\mathrm{Tr}}
\newcommand{\var}{\mathrm{Var}}
\newcommand{\cov}{\mathrm{Cov}}
\newcommand{\dom}{\mathrm{dom}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\nn}{\textrm{nn}}
\newcommand{\phii}{e}
\newcommand{\xii}{\boldsymbol{\omega}}

\DeclareMathOperator{\tr}{tr}
\newcommand{\bB}{\mathcal{B}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bm}{\mathbf{m}}
\newcommand{\bn}{\mathbf{n}}
\newcommand{\bS}{\mathbf{S}}
\newcommand{\bk}{\mathbf{k}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bff}{\mathbf{f}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bh}{\mathbf{h}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\balpha}{\boldsymbol{\alpha}}
\newcommand{\bsigma}{\boldsymbol{\sigma}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bdelta}{\boldsymbol{\delta}}
\newcommand{\bzeta}{\boldsymbol{\zeta}}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\bxi}{\boldsymbol{\xi}}
\newcommand{\bnu}{\boldsymbol{\nu}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\Op}{\mathcal{O}}
\newcommand{\boldeta}{\boldsymbol{\eta}}
\newcommand{\kk}{t}
\newcommand{\la}{\mathbf{\ell}}


\begin{document}

\begin{table}
%\vspace*{1.5 cm}
%\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{small}
%\begin{sc}
\caption{Last session's test accuracy (\%) ($\uparrow$) and the PPDR (\%) ($\downarrow$) in parentheses, for the high-shot CIL setting . The last column reports the average accuracy difference across all datasets between  a baseline and NA. GDumb  is the only memory-based method used for comparisons; we use a buffer size equal to $\min (1\text{k}, N_1)$ (or $5$k) where $N_1$ is first session's number of images. The best results across all methods are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k is used as a backbone for all methods.}
\label{table:cifar100_core50_fullshots}
\begin{tabular}{l c c c c c c c }
\toprule
%& \multicolumn{5}{c}{\textbf{Datasets}} \\
%\cmidrule(lr){2-6}
\textbf{Method} & \textbf{CIFAR} & \textbf{CORE} & \textbf{SVHN} &  \textbf{dSprites-loc} &  \textbf{FGVC} & {\textbf{Cars}}  & {\textbf{Letters}} \\
 \midrule
NA & 68.2 (26.8) & 82.6 (14.2) & 39.9 (51.1) & 20.6 (54.0) & 41.3 (1.7) & 43.3 (40.3) &  68.4 (24.1) \\
\hdashline
%GDumb-1k & 48.8 (48.6) & 81.2 (15.9) \\
GDumb-1k & 54.5 (42.2) & 82.4 (15.0) & \textbf{78.2} (\textbf{19.6}) & 79.5 (12.9) & 25.3 (56.9)  & 14.2 (82.6) & 70.1 (27.0) \\
GDumb-5k & 69.3 (28.6) & \textbf{88.1} (\textbf{7.9}) & \textbf{93.2} (\textbf{5.5}) & \textbf{99.4} (\textbf{0.1}) & 25.3 (56.9)  & 14.2 (82.6) & \textbf{82.6} (\textbf{16.9}) \\
\hdashline
E-EWC+SDC & 32.4 (66.7) &  21.7 (78.1) & 39.5 (60.1) & 18.6 (81.4) & 25.6 (55.8) & 30.0 (62.6) & 33.6 (66.3) \\
FACT & 10.2 (89.4) & 22.0 (77.7) & 33.8 (65.9) & 6.4 (93.6) & 4.7 (90.3) & 0.6 (99.3) &  20.9 (79.1) \\
ALICE & 52.4 (45.8) & 72.8 (25.8) & 46.1 (53.6) & 68.3 (31.7) & 39.8 (35.0)& 36.4 (56.0)& 75.7 (24.2) \\
FSA & 62.8 (34.5) & 82.8 (15.5)  & 71.3 (26.6) & \underline{\textbf{91.5}} (\underline{\textbf{8.5}}) & 50.8 (6.3)  & 50.3 (36.6)  & 78.4 (21.4) \\
FSA-LL & 60.5 (37.2) & 79.0 (19.2) & 64.6 (33.1) & 91.3 (8.5) & 45.4 (21.7) & 45.7 (43.8) & 77.2 (22.7) \\
FSA-FiLM & \underline{\textbf{73.8}} (\underline{\textbf{23.4}}) & \underline{\textbf{85.4}} (\underline{\textbf{13.3}})  & \underline{75.9} (\underline{23.4}) &  76.9 (22.8)  &  \underline{\textbf{55.9}} (\underline{\textbf{-5.7}}) & \underline{\textbf{55.9}} (\underline{\textbf{30.2}})  & \underline{\textbf{79.7}} (\underline{\textbf{20.0}})\\
\midrule
Offline-FiLM & 76.5 & 88.4 & 94.3  & 66.8 & 67.7 & 99.7 & 83.4 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
%\endgroup
%\vspace*{-0.2cm}
\end{table}




\vspace*{2cm}

\begin{table}[htb]
\begingroup
\setlength{\tabcolsep}{25.4pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{footnotesize}
%\begin{sc}
\caption{Baseline comparison under the few-shot+ CIL setting. We report the accuracy (\%) ($\uparrow$) of the last session and the PPDR (\%) ($\downarrow$) in parentheses.}
\label{table:fact_vs_our}
\begin{tabular}{l c c c}
\toprule
& & \multicolumn{2}{c}{ \textbf{Datasets}} \\
\cmidrule(lr){3-4}  \textbf{Method} & \textbf{Backbone} &  \textbf{CIFAR100} &  \textbf{CUB200} \\
\midrule
NA & \multirow{6}{*}{EN-B0} & 55.2 (25.8) &  63.2 (\textbf{19.6}) \\ 
FACT & & 56.5 (34.6) & 62.9 (23.3) \\ 
ALICE & & 62.7 (28.4) &  \textbf{63.5} (22.2) \\ 
FSA-LL &  & 61.4 (25.7) & 55.9 (22.3) \\ 
FSA-FiLM &  & 61.8 (\textbf{22.4}) & 62.9 (20.4) \\ 
FSA &  &  \textbf{66.1} (24.6) & 63.4 (20.9) \\ 
\midrule
Offline & EN-B0 & 67.0 & 65.1 \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{footnotesize}
\endgroup
\end{table}

\begin{table*}[htb]
%\vspace*{1.5 cm}
%\begingroup
\setlength{\tabcolsep}{10.0pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{small}
%\begin{sc}
\caption{Accuracy (\%) ($\uparrow$)  of the last session and PPDR (\%) ($\downarrow$) in parentheses for the few-shot CIL setting.  GDumb  is the only memory-based method used for comparisons; we use a buffer size equal to the first session's number of images $N_1$. The best results across all methods are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k is used as a backbone for all methods.}
\label{table:50shot_CL_acc_ppd}
\begin{tabular}{l c c c c c c c}
\toprule
 \textbf{Method/Dataset} & \textbf{CIFAR100} & \textbf{SVHN} &  \textbf{dSprites-loc} &  \textbf{FGVC-Aircraft} & \textbf{Letters} \\
 \midrule
NA & 57.4 (28.4) & 28.3 (61.5) & 11.9 (66.6) & 41.0 (-15.5) & 57.6 (29.9) \\
\hdashline
GDumb & 55.7 (33.7) & 21.0 (73.1) & 16.4 (55.0) & 38.6 (24.5) & 41.2 (54.8) \\
\hdashline
FACT & 16.8 (79.7) & 24.1 (66.2) & 11.7 (64.1) & 8.3 (79.9) & 49.8 (40.9) \\
ALICE & 58.0 (33.8) & 23.0 (65.9) & 23.0 (46.0) & 42.0 (27.5) & 66.5 (31.4) \\
FSA & 60.3 (27.0) & 32.9 (53.5) & 33.7 (\underline{\textbf{41.3}}) & 50.1 (-16.8) & 62.2 (28.5) \\
FSA-LL & 62.0 (25.7) & 43.5 (47.0) & 18.8 (61.7) & 45.8 (-2.1) & 69.4 (26.1) \\
FSA-FiLM & \underline{\textbf{70.9}} (\underline{\textbf{20.5}}) & \underline{\textbf{51.3}} (\underline{\textbf{43.5}}) & \underline{\textbf{35.7}} (43.1) & \underline{\textbf{55.8}} (\underline{\textbf{-19.8}}) & \underline{\textbf{73.4}} (\underline{\textbf{22.1}})\\
\midrule
Offline-FiLM & 73.8 & 77.2 & 83.7 & 65.1 & 79.7 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
%\endgroup
\end{table*}


\iffalse

%\maketitle
\section{Methods-Acronyms}
\paragraph{LDA-iso:} A classifier based on Mahalanobis head with isotropic covariance matrix, i.e. a nearest-mean classifier.

\paragraph{LDA:} A classifier based on Mahalanobis head.

\paragraph{Linear:} A classifier based on linear head.

\paragraph{NO Adapt:} A pretrained backbone (mainly on ImageNet-1K) without being adapted during training.

\paragraph{ML:} The adaptation of the backbone is based on the FiLM parameters generated by a FiLM generator as described in \cite{bronskill2021memory} using a Meta-Learning (ML).

\paragraph{FT:} The adaptation of the backbone is based on the FiLM parameters which are learnt from the data, i.e. via fine-tuning (FT).

\paragraph{FENC:} First encoding strategy for Continual learning experiments. We always use an LDA classifier and fine-tuned FiLM parameters from the first session.

\paragraph{Full Body Adaptation (FBA):} Learning all the parameters of the backbone from the data.

\paragraph{ALL DATA:} Use the full dataset for training.

\section{CNN Architectures}

\paragraph{EffNet-B0 (or EN-B0):} An EfficentNet-B0 \cite{tan2019efficientnet} architecture. \# parameters: $4,007,548$~~
\# FiLM parameters: $170,688$. (Pretrained on ImageNet-1K)

\paragraph{ConvNext (or CVXT):} A ConvNeXt \cite{liu2022convnet} architecture.  \# parameters: $348,147,968$.  (Pretrained on ImageNet-22K)


\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c}
\toprule
\textbf{Datasets}       &   \textbf{\# Classes} & \textbf{\# training images} \\
\midrule
Caltech101 & 102 & $3,060$ \\
CIFAR100 & 100 & $50,000$  \\
Flowers102 & 102 & $1,020$  \\
Pets & 37 & $3,680$  \\
Sun397 & 397  & $76,127$  \\
SVHN & 10 & $73,257$   \\
DTD & 47 & $1,880$   \\
\midrule
EuroSAT & 10  & $27,000$ \\
Resics45 & 45 & $31,500$ \\
Patch Camelyon & 2  & $262,144$ \\
Retinopathy & 5 & $35,126$  \\
\midrule
CLEVR-count & 8 & $70,000$ \\
CLEVR-dist & 6  & $70,000$\\
dSprites-loc & 16 & $737,280$  \\
dSprites-ori  & 16  & $737,280$\\
SmallNORB-azi & 18 & $24,300$  \\
SmallNORB-elev  & 9 & $24,300$ \\
DMLab & 6 & $65,550$  \\
KITTI-dist & 4 & $6,347$  \\
\midrule
FGVC-Aircraft & 100 & $6,667$   \\
Cars & 196 & $8,144$  \\
Letters & 64 & $74,107$  \\
DomainNet & 345 ($60^*$) & $569,010$   \\
i-Naturalist & 10,000 ($100^*$)  & $2,686,843$ ($500,000^*$) \\
Core50 & $50$ & $119,894$ \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
\caption{Datasets information. $*$ indicates a continual learning setting.}
\label{table2}
\end{table}
%---------------------------------------------------------------------------------------------------------

\section{Experimental results}
For each section we first introduce the questions we would like to answer based on the google doc file and then we present the corresponding results that answer these questions.

\subsection{Does using a Mahalanobis head lose you much over a linear head + what body adaptation should you use (if any)}


%------------------------------------------------------------------------------
% No Adaptation
%------------------------------------------------------------------------------

\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
&  \multicolumn{3}{c}{\textbf{No adaptation - 5 shots}}  \\
\cmidrule(lr){2-4} 
        &   \textbf{LDA-iso} & \textbf{LDA} & \textbf{Linear}\\
\midrule
\midrule
\textbf{EffNet-B0} & & &  \\
\midrule
Caltech101 & 85.7 (0.9) & \textbf{88.2 (0.8)} & 87.2 (0.7) \\
CIFAR100 & 40.2 (1.5) & \textbf{42.7 (1.6)} & 42.3 (1.3) \\
Flowers102 & 71.5 (0.6) & \textbf{76.1 (0.4)} & 75.7 (0.8) \\
Pets & \textbf{83.0 (1.5)} & 82.4 (1.6) & 82.5 (1.5) \\
Sun397 & 41.0 (0.9) & 41.9 (1.0) & \textbf{42.9 (0.7)} \\
SVHN & 13.5 (1.6) & \textbf{16.5 (1.1)} & 15.0 (1.4) \\
DTD & 48.2 (1.0) & 48.9 (1.7) & \textbf{49.2 (1.8)} \\
\midrule
EuroSAT & 72.1 (1.9) & \textbf{76.3 (1.8)} & 74.6 (2.0) \\
Resics45 & 55.2 (1.2) & 58.8 (1.4) & \textbf{58.9 (1.2)} \\
\midrule
Patch Camelyon & 59.6 (8.7) & \textbf{59.8 (7.2)} & 59.0 (6.4) \\
Retinopathy & \textbf{26.3 (2.5)} & 25.6 (1.6) & 24.3 (1.7) \\
\midrule
CLEVR-count & 22.2 (0.8) & \textbf{23.1 (1.1)} & 22.6 (0.7) \\
CLEVR-dist & 23.0 (2.7) & \textbf{24.5 (2.3)} & 24.4 (2.2) \\
dSprites-loc & 7.5 (0.7) & \textbf{8.5 (0.6)} & 7.3 (0.6) \\
dSprites-ori & 13.1 (1.2) & \textbf{16.2 (0.8)} & 14.8 (1.1) \\
SmallNORB-azi & 6.8 (0.6) & \textbf{9.3 (0.8)} & 8.8 (1.0) \\
SmallNORB-elev & 13.0 (1.5) & \textbf{15.1 (0.6)} & 14.5 (0.9) \\
DMLab & 22.2 (0.8) & 22.1 (1.3) & \textbf{23.8 (0.8)} \\
KITTI-dist & 50.0 (1.3) & 51.4 (2.7) & \textbf{51.9 (3.1)} \\
\midrule
FGVC-Aircraft & 19.4 (0.6) & 22.1 (1.0) & \textbf{22.7 (0.6)} \\
Cars & 20.0 (0.6) & \textbf{22.6 (0.6)} & 22.0 (0.7) \\
Letters & 28.3 (1.8) & \textbf{36.1 (2.1)} & 34.0 (1.3) \\
\midrule
Average acc & 37.4 (1.7) & \textbf{39.5 (1.4)} & 39.0 (1.2) \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
%\caption{VTAB accuracy using 5 shots and EffNet-B0 as backbone.}
\label{table2}
\end{table}

\begin{table}
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
&  \multicolumn{3}{c}{\textbf{No adaptation - 10 shots}}  \\
\cmidrule(lr){2-4} 
        &   \textbf{LDA-iso} & \textbf{LDA} & \textbf{Linear}\\
\midrule
\midrule
\textbf{EffNet-B0} & & &  \\
\midrule
Caltech101 & 88.5 (0.9) & \textbf{90.0 (0.8)} & 89.6 (0.7) \\
CIFAR100 & 45.8 (1.0) & \textbf{50.1 (1.5)} & 49.2 (1.1) \\
Flowers102 & 77.2 (0.2) & \textbf{83.9 (0.3)} & 81.9 (0.2) \\
Pets & 85.8 (1.0) & \textbf{86.4 (0.7)} & 86.1 (0.5) \\
Sun397 & 47.1 (1.3) & 49.0 (1.3) & \textbf{49.7 (0.8)} \\
SVHN & 15.5 (2.3) & \textbf{19.4 (2.9)} & 18.1 (2.6) \\
DTD & 53.8 (0.3) & 55.6 (0.6) & \textbf{56.3 (0.7)} \\
\midrule
EuroSAT & 76.6 (1.2) & \textbf{82.1 (0.9)} & 80.2 (0.9) \\
Resics45 & 60.7 (1.3) & 65.5 (1.1) & \textbf{65.9 (1.2)} \\
\midrule
Patch Camelyon & 63.0 (5.3) & \textbf{66.5 (3.7)} & 65.3 (4.7) \\
Retinopathy & \textbf{27.5 (3.2)} & 27.1 (2.2) & 26.1 (1.8) \\
\midrule
CLEVR-count & 24.0 (0.4) & \textbf{25.7 (0.6)} & 24.9 (0.6) \\
CLEVR-dist & 24.2 (1.2) & \textbf{26.3 (1.1)} & 26.3 (1.4) \\
dSprites-loc & 7.5 (0.5) & \textbf{8.7 (0.3)} & 7.9 (0.3) \\
dSprites-ori & 14.2 (0.9) & \textbf{18.2 (0.7)} & 16.4 (1.0) \\
SmallNORB-azi & 8.4 (0.4) & 9.5 (1.1) & \textbf{9.5 (0.7)} \\
SmallNORB-elev & 13.6 (0.8) & \textbf{16.5 (1.1)} & 16.2 (0.7) \\
DMLab & 25.1 (1.1) & 25.7 (1.2) & \textbf{27.2 (1.3)} \\
KITTI-dist & 50.1 (0.8) & \textbf{52.9 (1.5)} & 52.0 (1.8) \\
\midrule
FGVC-Aircraft & 23.1 (0.4) & \textbf{28.5 (0.4)} & 27.0 (0.4) \\
Cars & 25.4 (0.5) & 30.4 (0.5) & \textbf{30.7 (0.4)} \\
Letters & 34.2 (0.8) & \textbf{45.6 (0.8)} & 45.2 (1.4) \\
\midrule
Average acc & 40.5 (1.1) & \textbf{43.8 (0.8)} & 43.3 (1.0) \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
%\caption{VTAB accuracy using 5 shots and EffNet-B0 as backbone.}
\label{table2}
\end{table}

\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
&  \multicolumn{3}{c}{\textbf{No adaptation - 50 shots}}  \\
\cmidrule(lr){2-4} 
        &   \textbf{LDA-iso} & \textbf{LDA} & \textbf{Linear}\\
\midrule
\midrule
\textbf{EffNet-B0} & & &  \\
\midrule
Caltech101 & 90.4 (0.6) & 91.9 (0.5) & \textbf{93.0 (0.4)} \\
CIFAR100 & 52.0 (0.9) & 57.4 (1.0) & \textbf{60.9 (1.0)} \\
Flowers102 & 77.2 (0.2) & \textbf{83.9 (0.3)} & 81.9 (0.2) \\
Pets & 88.2 (0.3) & 89.5 (0.4) & \textbf{89.9 (0.6)} \\
Sun397 & 52.6 (1.1) & 55.9 (1.0) & \textbf{58.4 (0.8)} \\
SVHN & 19.3 (1.7) & 28.3 (1.1) & \textbf{28.9 (1.1)} \\
DTD & 58.5 (0.0) & 61.1 (0.0) & \textbf{65.4 (0.2)} \\
\midrule
EuroSAT & 81.7 (0.6) & 87.7 (0.9) & \textbf{88.2 (0.7)} \\
Resics45 & 66.6 (0.7) & 73.5 (0.9) & \textbf{78.2 (0.7)} \\
\midrule
Patch Camelyon & 70.9 (5.4) & \textbf{76.2 (1.1)} & 76.2 (1.5) \\
Retinopathy & 29.2 (2.2) & \textbf{32.9 (2.2)} & 32.9 (1.9) \\
\midrule
CLEVR-count & 26.3 (1.5) & 30.1 (1.0) & \textbf{31.2 (1.0)} \\
CLEVR-dist & 27.8 (0.8) & \textbf{32.2 (1.1)} & 31.7 (1.0) \\
dSprites-loc & 9.3 (0.8) & \textbf{11.9 (0.4)} & 9.9 (0.6) \\
dSprites-ori & 14.9 (0.5) & \textbf{20.1 (1.1)} & 18.7 (2.2) \\
SmallNORB-azi & 9.5 (0.6) & \textbf{12.3 (0.8)} & 12.1 (1.1) \\
SmallNORB-elev & 15.2 (1.3) & 19.1 (0.7) & \textbf{20.0 (0.5)} \\
DMLab & 29.1 (0.3) & 30.6 (0.3) & \textbf{32.3 (0.7)} \\
KITTI-dist & 53.2 (0.9) & \textbf{61.4 (2.3)} & 60.7 (3.2) \\
\midrule
FGVC-Aircraft & 30.9 (0.5) & 41.0 (0.7) & \textbf{46.1 (0.6)} \\
Cars & 33.7 (0.0) & 43.3 (0.0) & \textbf{46.5 (0.2)} \\
Letters & 43.1 (1.0) & 57.6 (0.8) & \textbf{65.9 (1.1)} \\
\midrule
Average acc & 44.5 (1.1) & 49.9 (0.6) & \textbf{51.3 (0.7)} \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
%\caption{VTAB accuracy using 5 shots and EffNet-B0 as backbone.}
\label{table2}
\end{table}


\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
&  \multicolumn{3}{c}{\textbf{No adaptation - All Data}}  \\
\cmidrule(lr){2-4} 
        &   \textbf{LDA-iso} & \textbf{LDA} & \textbf{Linear}\\
\midrule
\midrule
\textbf{EffNet-B0} & & &  \\
\midrule
Caltech101 & 90.4 (0.6) & 91.9 (0.5) & \textbf{93.0 (0.4)} \\
CIFAR100 & 53.5 (1.6) & 60.1 (1.7) & \textbf{68.3 (0.8)} \\
Flowers102 & 77.2 (0.2) & \textbf{83.9 (0.3)} & 81.9 (0.3) \\
Pets & 88.7 (0.2) & 89.9 (0.2) & \textbf{90.7 (0.3)} \\
Sun397 & 53.9 (1.1) & 56.9 (1.2) & \textbf{58.4 (0.6)} \\
SVHN & 24.5 (0.4) & 36.8 (0.6) & \textbf{40.8 (0.8)} \\
DTD & 58.5 (0.0) & 61.1 (0.0) & \textbf{65.3 (0.3)} \\
\midrule
EuroSAT & 82.4 (0.3) & 88.1 (0.1) & \textbf{93.2 (0.2)} \\
Resics45 & 67.1 (0.2) & 74.6 (0.2) & \textbf{81.8 (0.4)} \\
\midrule
Patch Camelyon & 72.9 (0.0) & 79.1 (0.0) & \textbf{79.7 (0.5)} \\
Retinopathy & 33.0 (0.3) & 40.4 (0.3) & \textbf{46.9 (0.4)} \\
\midrule
CLEVR-count & 28.9 (0.3) & 40.1 (0.4) & \textbf{50.3 (0.3)} \\
CLEVR-dist & 29.2 (0.5) & 38.7 (0.4) & \textbf{45.5 (1.3)} \\
dSprites-loc & 14.6 (0.6) & 20.9 (0.7) & \textbf{30.8 (1.4)} \\
dSprites-ori & 15.5 (0.4) & 22.5 (0.6) & \textbf{33.3 (0.9)} \\
SmallNORB-azi & 11.5 (0.5) & 14.1 (0.7) & \textbf{14.2 (0.7)} \\
SmallNORB-elev & 19.3 (0.4) & 24.1 (0.5) & \textbf{26.3 (0.8)} \\
DMLab & 35.4 (0.4) & 39.7 (0.3) & \textbf{44.4 (0.4)} \\
KITTI-dist & 53.4 (0.0) & 66.7 (0.0) & \textbf{69.8 (0.4)} \\
\midrule
FGVC-Aircraft & 31.8 (0.0) & 42.0 (0.0) & \textbf{45.8 (0.4)} \\
Cars & 33.7 (0.0) & 43.3 (0.0) & \textbf{46.6 (0.3)} \\
Letters & 44.9 (1.3) & 59.7 (0.5) & \textbf{69.5 (0.5)} \\
\midrule
Average acc & 46.4 (0.4) & 53.4 (0.4) & \textbf{58.0 (0.3)} \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
%\caption{VTAB accuracy using 5 shots and EffNet-B0 as backbone.}
\label{table2}
\end{table}

%-----------------------------------------------------------------------------------------
% FiLM Adaptation
%-----------------------------------------------------------------------------------------
\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
&  \multicolumn{3}{c}{\textbf{FiLM adaptation - 5 shots}}  \\
\cmidrule(lr){2-4} 
        &   \textbf{LDA-iso} & \textbf{LDA} & \textbf{Linear}\\
\midrule
\midrule
\textbf{EffNet-B0} & & &  \\
\midrule
Caltech101 & 86.6 (0.5) & \textbf{89.0 (0.6)} & 88.5 (0.4) \\
CIFAR100 & 47.4 (1.2) & \textbf{51.8 (1.3)} & 50.3 (1.4) \\
Flowers102 & 80.2 (0.4) & \textbf{85.0 (0.8)} & 83.5 (0.5) \\
Pets & 81.8 (1.5) & 81.8 (1.7) & \textbf{82.6 (1.6)} \\
Sun397 & 40.9 (0.7) & \textbf{40.9 (0.7)} & 38.1 (1.0) \\
SVHN & 28.6 (3.8) & \textbf{31.7 (3.7)} & 30.1 (4.5) \\
DTD & 49.6 (1.5) & 50.2 (0.9) & \textbf{50.8 (1.3)} \\
\midrule
EuroSAT & 75.8 (1.5) & 78.1 (1.2) & \textbf{78.3 (1.2)} \\
Resics45 & 62.7 (1.1) & 64.7 (1.2) & \textbf{65.8 (0.7)} \\
\midrule
Patch Camelyon & 64.7 (5.8) & \textbf{64.9 (6.6)} & 62.9 (5.4) \\
Retinopathy & \textbf{27.4 (3.1)} & 26.0 (2.0) & 25.2 (2.4) \\
\midrule
CLEVR-count & \textbf{24.0 (1.3)} & 23.4 (1.4) & 23.2 (0.7) \\
CLEVR-dist & 23.1 (1.4) & 23.1 (1.1) & \textbf{24.0 (1.3)} \\
dSprites-loc & 19.5 (1.8) & \textbf{19.8 (2.0)} & 16.7 (5.9) \\
dSprites-ori & 20.6 (1.6) & \textbf{26.5 (0.8)} & 25.5 (1.4) \\
SmallNORB-azi & 9.0 (1.0) & 10.1 (0.6) & \textbf{10.3 (0.6)} \\
SmallNORB-elev & 14.6 (0.9) & 15.4 (0.7) & \textbf{15.5 (0.8)} \\
DMLab & 23.4 (2.3) & 23.3 (1.9) & \textbf{24.8 (0.9)} \\
KITTI-dist & \textbf{55.7 (3.6)} & 52.7 (3.5) & 53.2 (1.8) \\
\midrule
FGVC-Aircraft & 28.7 (0.7) & 32.6 (0.9) & \textbf{33.1 (1.3)} \\
Cars & 22.7 (0.5) & \textbf{28.1 (0.4)} & 27.2 (0.7) \\
Letters & 52.2 (2.9) & 55.9 (2.5) & \textbf{56.4 (3.2)} \\
\midrule
Average acc & 42.7 (1.3) & \textbf{44.3 (1.4)} & 43.9 (1.5) \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
%\caption{VTAB accuracy using 5 shots and EffNet-B0 as backbone.}
\label{table2}
\end{table}

\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
&  \multicolumn{3}{c}{\textbf{FiLM adaptation - 10 shots}}  \\
\cmidrule(lr){2-4} 
        &   \textbf{LDA-iso} & \textbf{LDA} & \textbf{Linear}\\
\midrule
\midrule
\textbf{EffNet-B0} & & &  \\
\midrule
Caltech101 & 89.9 (0.2) & \textbf{91.5 (0.4)} & 91.1 (0.6) \\
CIFAR100 & 59.2 (1.7) & \textbf{62.8 (1.1)} & 60.6 (0.5) \\
Flowers102 & 86.2 (0.5) & 91.1 (0.3) & \textbf{91.2 (0.3)} \\
Pets & 85.8 (1.0) & 86.3 (0.8) & \textbf{86.6 (0.8)} \\
Sun397 & 48.5 (0.8) & \textbf{49.3 (0.6)} & 44.8 (1.2) \\
SVHN & 40.3 (2.5) & \textbf{45.3 (3.0)} & 43.9 (3.3) \\
DTD & 58.3 (0.8) & 59.1 (0.8) & \textbf{59.2 (1.1)} \\
\midrule
EuroSAT & 81.9 (1.4) & \textbf{84.4 (1.6)} & 83.5 (0.7) \\
Resics45 & 70.2 (1.1) & 73.0 (1.3) & \textbf{73.5 (0.7)} \\
\midrule
Patch Camelyon & \textbf{69.2 (5.2)} & 68.5 (6.1) & 67.1 (4.8) \\
Retinopathy & 26.7 (1.3) & \textbf{26.9 (1.1)} & 25.6 (1.0) \\
\midrule
CLEVR-count & \textbf{30.1 (1.9)} & 27.6 (1.6) & 29.2 (1.2) \\
CLEVR-dist & 25.3 (1.7) & 26.2 (1.3) & \textbf{26.5 (0.7)} \\
dSprites-loc & \textbf{26.2 (11.4)} & 26.1 (10.6) & 24.2 (14.7) \\
dSprites-ori & 26.7 (2.4) & \textbf{34.0 (2.6)} & 33.8 (2.4) \\
SmallNORB-azi & 11.0 (0.8) & \textbf{11.7 (1.2)} & 11.3 (1.4) \\
SmallNORB-elev & 15.6 (0.7) & 16.3 (0.4) & \textbf{16.6 (0.3)} \\
DMLab & 27.2 (1.9) & 26.6 (1.5) & \textbf{29.3 (1.7)} \\
KITTI-dist & \textbf{56.7 (3.7)} & 55.4 (3.7) & 56.2 (4.5) \\
\midrule
FGVC-Aircraft & 37.5 (0.7) & 43.3 (1.1) & \textbf{43.4 (1.5)} \\
Cars & 36.3 (0.8) & \textbf{43.1 (1.0)} & 42.1 (1.0) \\
Letters & 64.0 (1.5) & 67.5 (1.3) & \textbf{68.1 (1.4)} \\
\midrule
Average acc & 48.8 (2.3) & \textbf{50.7 (2.3)} & 50.4 (3.0) \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
%\caption{VTAB accuracy using 5 shots and EffNet-B0 as backbone.}
\label{table2}
\end{table}

\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
&  \multicolumn{3}{c}{\textbf{FiLM adaptation - 50 shots}}  \\
\cmidrule(lr){2-4} 
        &   \textbf{LDA-iso} & \textbf{LDA} & \textbf{Linear}\\
\midrule
\midrule
\textbf{EffNet-B0} & & &  \\
\midrule
Caltech101 & 93.4 (0.7) & \textbf{93.8 (0.5)} & 93.5 (1.0) \\
CIFAR100 & 72.6 (0.7) & \textbf{73.8 (0.9)} & 73.7 (0.5) \\
Flowers102 & 86.2 (0.5) & 91.1 (0.3) & \textbf{91.2 (0.3)} \\
Pets & 89.3 (0.6) & \textbf{89.9 (0.7)} & 89.9 (0.7) \\
Sun397 & 58.5 (0.7) & 59.7 (0.6) & \textbf{60.8 (0.7)} \\
SVHN & 73.9 (1.1) & \textbf{77.2 (0.8)} & 76.8 (1.0) \\
DTD & 66.8 (0.3) & 68.4 (0.2) & \textbf{68.7 (0.7)} \\
\midrule
EuroSAT & 91.0 (0.6) & 93.0 (0.6) & \textbf{93.2 (0.6)} \\
Resics45 & 81.7 (0.2) & 83.4 (0.6) & \textbf{85.3 (0.6)} \\
\midrule
Patch Camelyon & \textbf{78.5 (2.0)} & 77.9 (2.4) & 78.1 (2.4) \\
Retinopathy & 34.2 (1.6) & \textbf{35.2 (1.2)} & 33.5 (1.9) \\
\midrule
CLEVR-count & \textbf{56.8 (0.9)} & 46.6 (1.1) & 53.1 (1.1) \\
CLEVR-dist & 40.2 (1.8) & 38.8 (1.0) & \textbf{41.2 (1.5)} \\
dSprites-loc & 73.6 (19.2) & \textbf{73.7 (19.3)} & 65.6 (30.1) \\
dSprites-ori & 41.2 (0.8) & 52.1 (1.3) & \textbf{53.8 (1.4)} \\
SmallNORB-azi & 17.0 (0.8) & 16.8 (0.8) & \textbf{17.5 (1.0)} \\
SmallNORB-elev & 23.1 (1.2) & 22.9 (0.5) & \textbf{24.0 (0.6)} \\
DMLab & 35.0 (0.6) & 34.6 (0.6) & \textbf{35.8 (0.4)} \\
KITTI-dist & \textbf{67.3 (2.1)} & 66.8 (3.0) & 66.5 (2.7) \\
\midrule
FGVC-Aircraft & 60.6 (0.9) & 65.1 (0.7) & \textbf{68.0 (0.6)} \\
Cars & 60.9 (0.2) & 67.9 (0.2) & \textbf{74.5 (0.4)} \\
Letters & 76.7 (0.5) & 79.7 (0.4) & \textbf{81.9 (0.8)} \\
\midrule
Average acc & 62.7 (3.8) & 64.0 (3.9) & \textbf{64.8 (6.1)} \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
%\caption{VTAB accuracy using 5 shots and EffNet-B0 as backbone.}
\label{table2}
\end{table}


\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
&  \multicolumn{3}{c}{\textbf{FiLM adaptation - All Data}}  \\
\cmidrule(lr){2-4} 
        &   \textbf{LDA-iso} & \textbf{LDA} & \textbf{Linear}\\
\midrule
\midrule
\textbf{EffNet-B0} & & &  \\
\midrule
Caltech101 & 93.6 (0.4) & \textbf{94.4 (0.3)} & 94.1 (0.6) \\
CIFAR100 & 77.4 (1.1) & 78.2 (1.1) & \textbf{82.1 (1.1)} \\
Flowers102 & 88.6 (0.6) & \textbf{91.2 (0.4)} & 90.6 (0.5) \\
Pets & 90.2 (0.2) & 90.8 (0.3) & \textbf{91.0 (0.4)} \\
Sun397 & 61.4 (0.5) & 62.1 (0.3) & \textbf{63.7 (0.9)} \\
SVHN & 92.9 (0.4) & 93.1 (0.4) & \textbf{95.1 (0.4)} \\
DTD & 64.8 (0.2) & 66.8 (0.5) & \textbf{67.6 (0.6)} \\
\midrule
EuroSAT & 96.5 (0.3) & 97.2 (0.1) & \textbf{98.1 (0.3)} \\
Resics45 & 88.0 (0.3) & 89.4 (0.4) & \textbf{94.2 (0.4)} \\
\midrule
Patch Camelyon & 84.3 (1.5) & \textbf{85.9 (1.2)} & 85.8 (1.6) \\
Retinopathy & 52.3 (0.7) & 52.6 (0.8) & \textbf{59.5 (0.8)} \\
\midrule
CLEVR-count & 94.5 (0.2) & 93.5 (0.7) & \textbf{95.3 (0.6)} \\
CLEVR-dist & 79.3 (1.4) & 80.1 (2.3) & \textbf{84.5 (2.0)} \\
dSprites-loc & 98.0 (0.5) & 98.5 (0.6) & \textbf{99.3 (0.4)} \\
dSprites-ori & 69.8 (2.4) & 80.0 (0.8) & \textbf{90.7 (0.8)} \\
SmallNORB-azi & \textbf{26.1 (1.2)} & 24.4 (0.6) & 23.5 (0.5) \\
SmallNORB-elev & 47.0 (0.9) & \textbf{47.9 (1.2)} & 47.9 (1.4) \\
DMLab & 60.2 (0.6) & 61.3 (0.5) & \textbf{65.8 (1.0)} \\
KITTI-dist & 78.5 (0.9) & \textbf{80.1 (1.1)} & 79.7 (0.4) \\
\midrule
FGVC-Aircraft & 63.3 (0.2) & 67.5 (0.4) & \textbf{71.5 (0.5)} \\
Cars & 60.1 (0.1) & 67.3 (0.3) & \textbf{73.6 (0.3)} \\
Letters & 77.1 (0.3) & 81.7 (0.4) & \textbf{85.2 (0.3)} \\
\midrule
Average acc & 74.7 (0.6) & 76.6 (0.5) & \textbf{79.0 (0.4)} \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
%\caption{VTAB accuracy using 5 shots and EffNet-B0 as backbone.}
\label{table2}
\end{table}


%------------------------------------------------------------------------------
% Full-Body Adaptation
%------------------------------------------------------------------------------

\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
&  \multicolumn{3}{c}{\textbf{Full-body adaptation - 5 shots}}  \\
\cmidrule(lr){2-4} 
        &   \textbf{LDA-iso} & \textbf{LDA} & \textbf{Linear}\\
\midrule
\midrule
\textbf{EffNet-B0} & & &  \\
\midrule
Caltech101 & 87.1 (0.6) & \textbf{89.4 (0.7)} & 86.1 (0.9) \\
CIFAR100 & 48.1 (0.7) & \textbf{49.3 (1.1)} & 49.2 (1.0) \\
Flowers102 & 81.5 (0.8) & 81.7 (0.6) & \textbf{83.6 (0.8)} \\
Pets & \textbf{80.9 (1.7)} & 80.8 (1.7) & 71.1 (1.2) \\
Sun397 & 35.5 (0.3) & 35.2 (0.5) & \textbf{37.2 (0.3)} \\
SVHN & 19.1 (1.5) & \textbf{19.6 (1.2)} & 19.2 (1.8) \\
DTD & 48.4 (1.3) & \textbf{49.0 (1.3)} & 41.6 (0.8) \\
\midrule
EuroSAT & 75.4 (4.1) & 76.7 (2.9) & \textbf{78.5 (1.2)} \\
Resics45 & 61.7 (2.3) & 62.3 (2.5) & \textbf{63.5 (2.5)} \\
\midrule
Patch Camelyon & 59.2 (4.9) & 59.4 (4.9) & \textbf{60.5 (7.0)} \\
Retinopathy & 24.6 (2.7) & 24.5 (2.5) & \textbf{26.1 (2.4)} \\
\midrule
CLEVR-count & 23.9 (2.9) & 23.5 (3.0) & \textbf{24.2 (3.1)} \\
CLEVR-dist & 25.1 (3.3) & 25.6 (3.5) & \textbf{25.6 (2.4)} \\
dSprites-loc & 26.1 (2.7) & \textbf{27.1 (1.6)} & 25.5 (3.6) \\
dSprites-ori & 18.3 (1.6) & \textbf{19.9 (1.5)} & 15.6 (1.9) \\
SmallNORB-azi & 10.0 (0.7) & \textbf{10.4 (0.8)} & 10.3 (0.9) \\
SmallNORB-elev & 15.8 (1.1) & \textbf{16.2 (1.1)} & 15.6 (0.8) \\
DMLab & 21.3 (1.6) & 22.1 (1.3) & \textbf{22.6 (0.9)} \\
KITTI-dist & 51.1 (2.5) & \textbf{52.8 (2.5)} & 52.1 (2.0) \\
\midrule
FGVC-Aircraft & 23.8 (0.7) & 23.6 (0.8) & \textbf{25.1 (1.0)} \\
Cars & 23.1 (0.3) & 23.5 (0.3) & \textbf{25.3 (0.5)} \\
Letters & 35.5 (3.3) & 35.7 (3.3) & \textbf{37.0 (3.2)} \\
\midrule
Average acc & 40.7 (1.2) & \textbf{41.3 (1.2)} & 40.7 (1.4) \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
%\caption{VTAB accuracy using 5 shots and EffNet-B0 as backbone.}
\label{table2}
\end{table}

\begin{table}
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
&  \multicolumn{3}{c}{\textbf{Full-body adaptation - 10 shots}}  \\
\cmidrule(lr){2-4} 
        &   \textbf{LDA-iso} & \textbf{LDA} & \textbf{Linear}\\
\midrule
\midrule
\textbf{EffNet-B0} & & &  \\
\midrule
Caltech101 & 90.4 (0.8) & \textbf{91.7 (0.7)} & 89.3 (0.8) \\
CIFAR100 & 58.8 (0.4) & \textbf{59.5 (0.3)} & 59.5 (0.8) \\
Flowers102 & 89.9 (0.6) & 90.0 (0.5) & \textbf{91.3 (0.6)} \\
Pets & 85.5 (0.9) & \textbf{85.7 (0.5)} & 78.4 (1.7) \\
Sun397 & 45.2 (0.7) & 45.0 (0.4) & \textbf{46.3 (0.3)} \\
SVHN & 26.4 (3.4) & \textbf{27.1 (3.8)} & 26.4 (3.6) \\
DTD & 55.2 (0.8) & \textbf{56.7 (1.0)} & 48.0 (0.8) \\
\midrule
EuroSAT & 83.9 (1.5) & 84.9 (1.5) & \textbf{86.3 (1.5)} \\
Resics45 & 72.6 (1.2) & 72.8 (1.3) & \textbf{74.3 (1.1)} \\
\midrule
Patch Camelyon & 61.3 (4.5) & 61.2 (4.5) & \textbf{63.0 (5.1)} \\
Retinopathy & 25.1 (4.2) & 24.6 (3.3) & \textbf{27.5 (2.0)} \\
\midrule
CLEVR-count & 28.0 (1.9) & 27.7 (2.0) & \textbf{28.7 (2.1)} \\
CLEVR-dist & \textbf{30.1 (4.1)} & 30.0 (4.2) & 29.9 (3.6) \\
dSprites-loc & 40.9 (6.5) & \textbf{42.8 (3.7)} & 40.2 (4.2) \\
dSprites-ori & 22.4 (3.0) & \textbf{25.6 (2.7)} & 17.6 (3.2) \\
SmallNORB-azi & \textbf{12.2 (0.6)} & 11.5 (0.8) & 11.7 (0.6) \\
SmallNORB-elev & 18.2 (1.3) & \textbf{18.3 (1.5)} & 17.3 (1.1) \\
DMLab & 25.3 (1.2) & 25.6 (1.3) & \textbf{26.1 (1.1)} \\
KITTI-dist & 53.5 (2.3) & \textbf{54.9 (1.3)} & 52.2 (2.1) \\
\midrule
FGVC-Aircraft & 37.4 (0.5) & 36.7 (0.6) & \textbf{38.6 (0.4)} \\
Cars & 43.8 (0.8) & 43.5 (0.6) & \textbf{46.9 (0.8)} \\
Letters & 55.8 (1.5) & 55.2 (1.3) & \textbf{56.6 (1.4)} \\
\midrule
Average acc & 48.3 (1.6) & \textbf{48.7 (1.3)} & 48.0 (1.3) \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
%\caption{VTAB accuracy using 5 shots and EffNet-B0 as backbone.}
\label{table2}
\end{table}

\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
&  \multicolumn{3}{c}{\textbf{Full-body adaptation - 50 shots}}  \\
\cmidrule(lr){2-4} 
        &   \textbf{LDA-iso} & \textbf{LDA} & \textbf{Linear}\\
\midrule
\midrule
\textbf{EffNet-B0} & & &  \\
\midrule
Caltech101 & 92.8 (0.3) & \textbf{93.9 (0.3)} & 92.6 (0.5) \\
CIFAR100 & 72.9 (0.9) & \textbf{73.1 (0.7)} & 72.7 (0.8) \\
Flowers102 & 89.9 (0.6) & 90.0 (0.5) & \textbf{91.3 (0.6)} \\
Pets & 88.7 (0.5) & \textbf{89.6 (0.6)} & 84.9 (1.1) \\
Sun397 & 59.9 (0.6) & 60.4 (0.6) & \textbf{62.4 (0.4)} \\
SVHN & 63.9 (1.5) & 64.5 (1.3) & \textbf{64.6 (1.6)} \\
DTD & 60.9 (0.3) & \textbf{64.4 (0.2)} & 57.4 (0.7) \\
\midrule
EuroSAT & 93.8 (0.5) & \textbf{94.1 (0.6)} & 93.9 (1.0) \\
Resics45 & 87.4 (0.8) & 87.6 (0.7) & \textbf{88.0 (0.8)} \\
\midrule
Patch Camelyon & 71.6 (1.7) & 72.2 (1.8) & \textbf{74.4 (1.8)} \\
Retinopathy & 31.1 (3.3) & 31.3 (2.9) & \textbf{31.9 (2.2)} \\
\midrule
CLEVR-count & \textbf{46.5 (1.0)} & 45.2 (1.1) & 45.4 (1.9) \\
CLEVR-dist & 44.0 (2.1) & 44.7 (2.2) & \textbf{45.7 (2.2)} \\
dSprites-loc & 77.3 (19.5) & \textbf{83.1 (9.9)} & 73.2 (23.2) \\
dSprites-ori & 42.6 (3.2) & \textbf{44.8 (2.3)} & 39.3 (4.7) \\
SmallNORB-azi & \textbf{19.6 (0.6)} & 18.3 (0.7) & 19.1 (1.1) \\
SmallNORB-elev & \textbf{31.4 (1.4)} & 31.3 (1.7) & 31.3 (2.1) \\
DMLab & 32.6 (1.4) & 32.7 (1.6) & \textbf{34.0 (0.9)} \\
KITTI-dist & 65.8 (2.1) & \textbf{66.9 (2.2)} & 65.8 (1.8) \\
\midrule
FGVC-Aircraft & 74.2 (0.8) & 73.5 (0.4) & \textbf{74.6 (0.3)} \\
Cars & 79.3 (0.1) & 79.4 (0.1) & \textbf{81.5 (0.2)} \\
Letters & 82.1 (0.7) & 82.3 (0.9) & \textbf{83.1 (0.6)} \\
\midrule
Average acc & 64.0 (3.9) & \textbf{64.7 (2.0)} & 64.0 (4.7) \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
%\caption{VTAB accuracy using 5 shots and EffNet-B0 as backbone.}
\label{table2}
\end{table}


\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
&  \multicolumn{3}{c}{\textbf{Full-body adaptation - All Data}}  \\
\cmidrule(lr){2-4} 
        &   \textbf{LDA-iso} & \textbf{LDA} & \textbf{Linear}\\
\midrule
\midrule
\textbf{EffNet-B0} & & &  \\
\midrule
Caltech101 & 94.2 (0.5) & 94.6 (0.3) & \textbf{94.8 (0.3)} \\
CIFAR100 & 84.2 (1.2) & 84.3 (0.9) & \textbf{85.0 (1.1)} \\
Flowers102 & 90.3 (0.3) & 90.3 (0.4) & \textbf{91.4 (0.5)} \\
Pets & 89.7 (0.4) & 89.5 (0.3) & \textbf{90.0 (0.4)} \\
Sun397 & 65.9 (0.3) & 66.1 (1.0) & \textbf{66.7 (0.4)} \\
SVHN & \textbf{95.6 (0.2)} & 95.3 (0.5) & 95.5 (0.3) \\
DTD & 67.6 (0.8) & 68.1 (0.4) & \textbf{68.5 (0.5)} \\
\midrule
EuroSAT & 98.1 (0.2) & 98.5 (0.3) & \textbf{98.6 (0.2)} \\
Resics45 & 95.3 (0.1) & 95.5 (0.2) & \textbf{95.9 (0.1)} \\
\midrule
Patch Camelyon & 81.1 (2.2) & 85.0 (0.7) & \textbf{86.5 (0.9)} \\
Retinopathy & 55.8 (0.9) & 56.1 (1.4) & \textbf{57.7 (0.7)} \\
\midrule
CLEVR-count & 98.5 (0.3) & \textbf{98.7 (0.3)} & 98.3 (0.3) \\
CLEVR-dist & 89.0 (0.6) & 89.0 (0.6) & \textbf{89.4 (1.5)} \\
dSprites-loc & 99.7 (0.3) & \textbf{99.8 (0.1)} & 99.6 (0.4) \\
dSprites-ori & 89.2 (1.0) & \textbf{94.0 (0.7)} & 93.0 (1.1) \\
SmallNORB-azi & \textbf{29.8 (1.0)} & 28.7 (0.6) & 28.9 (0.8) \\
SmallNORB-elev & 74.3 (4.3) & \textbf{81.8 (3.1)} & 77.2 (4.6) \\
DMLab & 64.8 (0.6) & \textbf{65.7 (0.4)} & 65.6 (0.7) \\
KITTI-dist & 78.2 (0.7) & 82.1 (0.6) & \textbf{82.3 (1.1)} \\
\midrule
FGVC-Aircraft & 76.0 (0.5) & 75.8 (0.7) & \textbf{76.7 (0.8)} \\
Cars & 79.1 (0.1) & 78.9 (0.2) & \textbf{81.3 (0.2)} \\
Letters & 86.0 (0.5) & 85.7 (0.5) & \textbf{87.2 (0.3)} \\
\midrule
Average acc & 81.0 (0.9) & 82.0 (0.6) & \textbf{82.3 (0.9)} \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
%\caption{VTAB accuracy using 5 shots and EffNet-B0 as backbone.}
\label{table2}
\end{table}

\begin{figure*}[h!]
\centering
\includegraphics[width = \textwidth]{plots/no_adaptation_barplot_compare_heads} 
\caption{Head comparison using no-adaptation on VTAB$+$.}
\label{fig:no_adaptation}
\end{figure*}

\begin{figure*}[h!]
\centering
\includegraphics[width = \textwidth]{plots/film_adaptation_barplot_compare_heads} 
\caption{Head comparison using FiLM adaptation on VTAB$+$.}
\label{fig:no_adaptation}
\end{figure*}

\begin{figure*}[h!]
\centering
\includegraphics[width = \textwidth]{plots/full-body-adaptation_barplot_compare_heads} 
\caption{Head comparison using full-body adaptation on VTAB$+$.}
\label{fig:no_adaptation}
\end{figure*}

\textbf{Conclusions}
\begin{itemize}
    \item As we increase the number of shots linear head outperforms the other two head.
    \item LDA has the best performance on low-shot regime.
    \item LDA-iso is outperformed by the two other methods regardless adaptation and number of shots.
    \item The more parameters we use for adaptation the smaller the performance gap between the three heads.
\end{itemize}

\subsection{VTAB+ first encoding continual learning experiments: first encoding is hard to beat [not much gap between batch encoding and first encoding for even fairly small first stages of continual learning]
}

\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
&  \multicolumn{3}{c}{\textbf{Shots=50 - 10 classes per session}}  \\
\cmidrule(lr){2-4} 
        &   \textbf{NO Adaptation} & \textbf{FENC} & \textbf{BATCH}\\
\midrule
\midrule
\textbf{EffNet-B0} & & &  \\
\midrule
Caltech101 & \textbf{91.9 (0.5)} & 90.1 (0.3) & 93.8 (0.5) \\
CIFAR100 & \textbf{57.4 (1.0)} & 56.3 (1.1) & 73.8 (0.9) \\
Flowers102 & 83.9 (0.3) & \textbf{84.5 (0.3)} & 91.1 (0.3) \\
Pets & \textbf{89.5 (0.4)} & 89.2 (0.4) & 89.9 (0.7) \\
Sun397 & \textbf{55.9 (1.0)} & 49.9 (0.5) & 59.7 (0.6) \\
DTD & 61.1 (0.0) & \textbf{64.0 (0.2)} & 68.4 (0.2) \\
Resics45 & 73.5 (0.9) & \textbf{75.1 (0.7)} & 83.4 (0.6) \\
dSprites-loc & 11.9 (0.4) & \textbf{38.1 (22.7)} & 73.7 (19.3) \\
dSprites-ori & 20.1 (1.1) & \textbf{49.0 (1.0)} & 52.1 (1.3) \\
SmallNORB-azi & 12.3 (0.8) & \textbf{17.1 (1.1)} & 16.8 (0.8) \\
FGVC-Aircraft & 41.0 (0.7) & \textbf{49.8 (0.3)} & 65.1 (0.7) \\
Cars & \textbf{43.3 (0.0)} & 41.1 (0.1) & 67.9 (0.2) \\
Letters & 57.6 (0.8) & \textbf{65.8 (0.6)} & 79.7 (0.4) \\
\midrule
Average acc & 53.8 (0.4) & \textbf{59.2 (5.9)} & 70.4 (5.0) \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
%\caption{VTAB accuracy using 5 shots and EffNet-B0 as backbone.}
\label{table2}
\end{table}

%---------------------------------------------------------------------

\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c}
\toprule
&  \multicolumn{2}{c}{\textbf{FENC-FiLM}}  \\
\cmidrule(lr){2-3} 
        &   \textbf{10-shot/10-way} & \textbf{50-shot/2-way} \\
\midrule
\textbf{EffNet-B0} & &   \\
\midrule
Caltech101 & 88.7 (0.4) & \textbf{89.8 (0.2)} \\
CIFAR100 & 49.5 (1.4) & \textbf{49.7 (1.5)} \\
Flowers102 & \textbf{84.5 (0.3)} & 81.0 (0.4) \\
Pets & 86.6 (0.6) & \textbf{88.4 (0.5)} \\
Sun397 & 43.4 (0.7) & \textbf{49.7 (0.6)} \\
DTD & 58.0 (0.9) & \textbf{62.1 (0.1)} \\
Resics45 & 69.2 (0.9) & \textbf{71.0 (0.4)} \\
dSprites-loc & \textbf{28.8 (9.4)} & 22.6 (7.6) \\
dSprites-ori & \textbf{33.2 (1.8)} & 32.9 (1.7) \\
SmallNORB-azi & 11.1 (0.9) & \textbf{14.1 (1.1)} \\
FGVC-Aircraft & 37.6 (0.5) & \textbf{48.9 (0.4)} \\
Cars & 30.3 (0.4) & \textbf{40.3 (0.1)} \\
Letters & 56.8 (0.8) & \textbf{62.8 (0.4)} \\
\midrule
Average acc & 52.1 (2.3) & \textbf{54.9 (1.9)} \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
%\caption{VTAB accuracy using 5 shots and EffNet-B0 as backbone.}
\label{table2}
\end{table}

%---------------------------------------------------------------------
% Baselines-CL

\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
& & \multicolumn{2}{c}{} \\
\cmidrule(lr){3-4}  \textbf{Method} & \textbf{CNN} &  \textbf{CIFAR100} &  \textbf{CUB200} \\
\midrule
FACT & Resnet20 & 52.10 & - \\ 
FENC-FB & Resnet20 & 51.98 & - \\ 
\midrule
NA & Resnet18 & 50.42 & 49.96 \\ 
FACT & Resnet18 & 49.46 & 56.94 \\ 
FENC-FiLM & Resnet18 & 55.20 & 51.96 \\ 
FENC-FB & Resnet18 & 61.44 & 57.61 \\ 
\midrule
NA & EffnetB0 & 55.22 &  \textbf{63.20} \\ 
FACT & EffnetB0 & 56.51 & 62.86 \\ 
FENC-FiLM & EffnetB0 & 61.75 & 62.88 \\ 
FENC-FB & EffnetB0 &  \textbf{66.05} & 63.14 \\ 
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
%\caption{VTAB accuracy using 5 shots and EffNet-B0 as backbone.}
\label{table2}
\end{table}

%---------------------------------------------------------------------

\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c c c c c c c c}
\toprule
& & \multicolumn{9}{c}{\textbf{CIFAR100 - Accuracy in each session (\%) $\uparrow$}} \\
 \cmidrule(lr){3-11} \\
\textbf{Backbone} & \textbf{Method} & \textbf{1} & \textbf{2} &  \textbf{3} &  \textbf{4} &  \textbf{5} &  \textbf{6} &  \textbf{7} &  \textbf{8} &  \textbf{9} \\
 \midrule
\multirow{2}{*}[-0.72ex]{Resnet-20} & FACT* & 74.6 & 72.1 & 67.6 & 63.5 & 61.4 & 58.4 & 56.3 & 54.2 & 52.1 \\
                                    & FENC & 75.1 & 71.2 & 67.5 & 63.2 & 60.0 & 57.6 & 55.5 & 54.2 & 52.0 \\
\midrule
\multirow{4}{*}[-0.72ex]{Resnet-18} &
NA & 68.9 & 65.4 & 62.4 & 58.7 & 57.2 & 54.7 & 53.3 & 51.9 & 50.4 \\
& FACT & 75.8 & 71.0 & 66.3 & 62.5 & 59.1 & 56.3 & 54.1 & 51.8 & 49.5 \\
& FENC-FiLM & 73.0 & 69.7 & 66.3 & 63.2 & 61.9 & 59.3 & 58.3 & 57.2 & 55.2 \\
& FENC & 82.0 & 78.2 & 74.8 & 70.2 & 68.7 & 66.2 & 65.3 & 63.8 & 61.4 \\
\midrule
\multirow{4}{*}[-0.72ex]{Effnet-B0}
& NA & 74.4 & 70.4 & 67.4 & 63.4 & 62.3 & 59.8 & 58.4 & 56.9 & 55.2 \\
& FACT & 86.3 & 80.6 & 75.6 & 71.1 & 67.6 & 64.4 & 61.8 & 59.1 & 56.5 \\
& FENC-FiLM & 79.6 & 75.6 & 72.9 & 68.8 & 68.2 & 65.4 & 64.9 & 63.9 & 61.8 \\
& FENC & \textbf{87.6} & \textbf{83.5} & \textbf{79.7} & \textbf{75.4} & \textbf{73.8} & \textbf{70.9} & \textbf{70.2} & \textbf{68.8} & \textbf{66.0} \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
\caption{Accuracy for each incremental session on CIFAR100 dataset. The first session contains all the available images of the first 60 classes. The rest of the sessions include 5 classes with 5 images each (5-way/5-shot). Asterisk (*) indicates that the reported results have been taken from \cite{zhou2022forward}.}
\label{table2}
\end{table}

\begin{table}[h!]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c c c c c c c c c c}
\toprule
& & \multicolumn{11}{c}{\textbf{CUB200 - Accuracy in each session (\%) $\uparrow$}} \\
 \cmidrule(lr){3-13} \\
\textbf{Backbone} & \textbf{Method} & \textbf{1} & \textbf{2} &  \textbf{3} &  \textbf{4} &  \textbf{5} &  \textbf{6} &  \textbf{7} &  \textbf{8} &  \textbf{9} &  \textbf{10} &  \textbf{11} \\
\midrule
\multirow{4}{*}[-0.72ex]{Resnet-18} &
NA & 70.7 & 66.7 & 63.4 & 59.0 & 58.2 & 56.4 & 54.0 & 52.3 & 50.5 & 50.5 & 50.0 \\
 & FACT* & 75.9 & 73.2 & 70.8 & 66.1 & 65.6 & 62.1 & 61.7 & 59.8 & 58.4 & 57.9 & 56.9 \\
 & FENC-FiLM & 72.7 & 68.2 & 64.9 & 60.8 & 60.2 & 58.1 & 55.4 & 54.8 & 53.5 & 53.4 & 52.6 \\
 & FENC & 76.1 & 72.6 & 69.6 & 65.0 & 64.6 & 62.3 & 61.6 & 59.6 & 58.2 & 58.2 & 57.6 \\
\midrule
\multirow{4}{*}[-0.72ex]{Effnet-B0}
& NA & 78.6 & 75.8 & 73.4 & 69.5 & 69.2 & \textbf{67.3} & \textbf{66.5} & 64.3 & 62.7 & 63.0 & 63.2 \\
 & FACT & \textbf{82.0} & \textbf{77.5} & \textbf{74.4} & \textbf{70.0} & 69.3 & 66.6 & 66.2 & 64.7 & \textbf{64.0} & 63.3 & 62.9 \\
 & FENC-FiLM & 79.0 & 75.3 & 72.7 & 69.5 & 68.3 & 66.5 & 65.2 & 64.1 & 62.8 & 62.9 & 62.9 \\
 & FENC & 80.2 & 77.1 & 74.2 & 69.3 & \textbf{69.3} & 66.9 & 66.4 & \textbf{64.8} & 63.6 & \textbf{63.8} & \textbf{63.4} \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
\caption{Accuracy for each incremental session on CUB200 dataset. The first session contains all the available images of the first 100 classes. The rest of the sessions include 5 classes with 5 images each (10-way/5-shot). Asterisk (*) indicates that the reported results have been taken from \cite{zhou2022forward}.}
\label{table2}
\end{table}

%--------------------------------------------------------------------------------------

\begin{table}[ht]
%\vspace*{1.5 cm}
\begingroup
\setlength{\tabcolsep}{3.9pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{lcccccccccc}
\toprule
& \multicolumn{10}{c}{\textbf{CIFAR100 - Accuracy in each session (\%) $\uparrow$}} \\
\cmidrule(lr){2-11} \\
 \textbf{Method} & \textbf{1} & \textbf{2} &  \textbf{3} &  \textbf{4} &  \textbf{5} &  \textbf{6} &  \textbf{7} &  \textbf{8} &  \textbf{9} &  \textbf{10} \\
 \midrule
NA & 93.15 &  87.13 &  81.89 &  80.20 &   76.82 &  74.33 &  72.78 &  70.57 &  70.07 &  68.23 \\
FACT & 96.56 & 48.24 & 32.76 & 24.22 & 19.30 & 16.37 & 13.94 & 12.50 & 11.29 & 10.21 \\
GDumb &\textbf{97.03} & \textbf{91.63} & \textbf{88.14} & \textbf{85.06} & 81.76 & 77.87 & 75.6 & 73.16 & 71.79 & 69.28 \\
FENC & 95.95 & 86.30 &  80.53 & 77.73 & 74.22 & 70.93 & 68.23 & 65.82 & 64.16 & 62.84 \\
FENC-FiLM & 96.42 &  90.38 &  86.77 &  84.69 &  \textbf{81.99} &  \textbf{79.77} &  \textbf{78.18} &  \textbf{76.14} &  \textbf{75.68} &  \textbf{73.84} \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
\caption{Accuracy for each incremental session on CIFAR100 dataset. The first session contains all the images for each of the  first 10 classes. The rest of the sessions include 10 classes using all the available training images of these classes.}
\label{table2}
\end{table}

\begin{table}[ht]
%\vspace*{1.5 cm}
\begingroup
\setlength{\tabcolsep}{3.9pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{lccccccccc}
\toprule
& \multicolumn{9}{c}{\textbf{CORE50 - Accuracy in each session (\%) $\uparrow$}} \\
\cmidrule(lr){2-10} \\
 \textbf{Method} & \textbf{1} & \textbf{2} &  \textbf{3} &  \textbf{4} &  \textbf{5} &  \textbf{6} &  \textbf{7} &  \textbf{8} &  \textbf{9} \\
 \midrule
NA & 96.35 & 94.51 & 91.63 & 89.90 &  87.67 & 84.81 & 81.98 & 82.78 & 82.63 \\
FACT & 98.47 & 66.94 & 50.55 &, 40.35 & 33.75 & 28.87 & 25.30 & 23.88 & 21.99 \\
GDumb & 97.47 & \textbf{96.67} & \textbf{94.59} & \textbf{92.72} & \textbf{91.83} & \textbf{90.29} & \textbf{89.00} & \textbf{90.03} & \textbf{90.03} \\
FENC & 97.98 & 93.60 &  89.84 & 88.84 & 86.75 & 84.42 & 81.74 & 82.29 & 82.78 \\
FENC-FiLM & \textbf{98.50} & 96.03 & 92.61 & 90.64 & 89.48 & 87.28 & 84.98 & 85.58 & 85.4 \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
\caption{Accuracy for each incremental session on CORE50 dataset. The first session contains all the images for each of the  first 10 classes. The rest of the sessions include 5 classes using all the available training images of these classes.}
\label{table2}
\end{table}

\begin{figure*}[h!]
\centering
\includegraphics[width = \textwidth]{plots/cifar100_full_shots_gdumb_barplot_compare_acc_time} 
\caption{Accuracy and time Comparison on CIFAR100 between FENC-FILM and GDumb-$m$ where $m \in \{ 200, 500, 1000, 2000, 5000 \}$ is the size of the memory buffer. The accuracy of the last session is reported here.}
\label{fig:no_adaptation}
\end{figure*}

\begin{figure*}[h!]
\centering
\includegraphics[width = \textwidth]{plots/core50_full_shots_gdumb_barplot_compare_acc_time} 
\caption{Accuracy and time Comparison on CORE50 between FENC-FILM and GDumb-$m$ where $m \in \{ 200, 500, 1000, 2000, 5000, 10000 \}$ is the size of the memory buffer. The accuracy of the last session is reported here.}
\label{fig:no_adaptation}
\end{figure*}


%--------------------------------------------------------------------------------------
\newpage

\begin{table}[ht]
\vspace*{1.5 cm}
\begingroup
\setlength{\tabcolsep}{1.5pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{small}
%\begin{sc}
\begin{tabular}{lccccccccc}
\toprule
& \multicolumn{9}{c}{\textbf{CIFAR100 - Accuracy in each session (\%) $\uparrow$}} \\
\cmidrule(lr){2-10} \\
 \textbf{Method} & \textbf{1} & \textbf{2} &  \textbf{3} &  \textbf{4} &  \textbf{5} &  \textbf{6} &  \textbf{7} &  \textbf{8} &  \textbf{9} \\
 \midrule
NA & 80.2 (0.9) & 76.2 (0.7) & 72.4 (1.5) & 68.7 (1.5) & 65.2 (1.4) & 63.5 (1.3) & 60.8 (1.3) & 59.5 (1.9) & 57.3 (1.0) \\
FACT & 83.0 (1.2) & 54.5 (1.4) & 40.7 (1.0) & 32.6 (1.0) & 27.6 (0.9) & 23.8 (0.7) & 20.8 (0.5) & 18.7 (0.4) & 16.8 (0.3) \\
GDumb & 83.9 (1.4) & 80.1 (0.5) & 77.6 (1.6) & 71.7 (2.2) & 67.5 (1.8) & 64.0 (1.5) & 59.4 (1.2) & 58.6 (1.9) & 55.7 (1.0) \\
FENC & 82.7 (2.1) & 75.4 (1.7) & 72.5 (1.8) & 69.5 (1.6) & 66.8 (1.8) & 64.5 (1.4) & 63.1 (1.5) & 62.7 (1.5) & 60.3 (1.3) \\
FENC-FiLM & \textbf{89.2 (0.9)} & \textbf{85.8 (1.3)} & \textbf{84.3 (1.3)} & \textbf{81.0 (1.3)} & \textbf{77.9 (1.7)} & \textbf{75.9 (1.0)} & \textbf{74.3 (1.4)} & \textbf{74.2 (1.1)} & \textbf{70.9 (1.0)} \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\endgroup
\caption{Accuracy for each incremental session on CIFAR100 dataset, based on the VTAB setting. The first session contains 50 images for each of the  first 20 classes. The rest of the sessions include 10 classes with 50 images each (10-way/50-shot).}
\label{table2}
\end{table}

\begin{table}[ht]
%\vspace*{1.5 cm}
\begingroup
\setlength{\tabcolsep}{1.5pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{lccccc}
\toprule
& \multicolumn{5}{c}{\textbf{SVHN - Accuracy in each session (\%) $\uparrow$}} \\
\cmidrule(lr){2-6} \\
 \textbf{Method} & \textbf{1} & \textbf{2} &  \textbf{3} &  \textbf{4} &  \textbf{5} \\
 \midrule
NA & 73.5 (4.6) & 53.3 (3.7) & 37.3 (1.8) & 33.6 (1.5) & 28.1 (1.1) \\
FACT & 71.3 (1.0) & 46.6 (3.5) & 34.0 (1.9) & 27.7 (2.5) & 24.1 (2.0) \\
GDumb & 78.2 (4.9) & 46.7 (5.1) & 35.2 (1.6) & 23.3 (3.8) & 21.0 (2.1) \\
FENC & 70.7 (2.9) & 50.8 (3.9) & 38.4 (3.2) & 35.7 (1.6) & 32.9 (1.0) \\
FENC-FiLM & \textbf{90.7 (1.8)} & \textbf{70.4 (1.4)} & \textbf{60.5 (1.5)} & \textbf{55.5 (2.3)} & \textbf{51.3 (2.1)} \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
\caption{Accuracy for each incremental session on SVHN dataset, based on the VTAB setting. The first session contains 50 images for each of the first 2 classes. The rest of the sessions include 2 classes with 50 images each (2-way/50-shot).}
\label{table2}
\end{table}

\begin{table}[ht]
\vspace*{1.5 cm}
\begingroup
\setlength{\tabcolsep}{1.5pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{lccccccc}
\toprule
& \multicolumn{7}{c}{\textbf{dSprites-pos - Accuracy in each session (\%) $\uparrow$}} \\
\cmidrule(lr){2-8} \\
 \textbf{Method} & \textbf{1} & \textbf{2} &  \textbf{3} &  \textbf{4} &  \textbf{5} &  \textbf{6} &  \textbf{7} \\
 \midrule
NA & 35.7 (1.4) & 26.4 (1.7) & 22.1 (1.7) & 18.1 (1.2) & 15.4 (0.8) & 13.5 (0.7) & 11.8 (0.4) \\
FACT & 32.6 (1.4) & 22.7 (2.2) & 18.4 (2.1) & 14.4 (1.9) & 12.4 (1.5) & 11.9 (1.6) & 11.7 (1.7) \\
GDumb & 36.4 (7.9) & 29.9 (6.3) & 20.3 (3.6) & 22.1 (5.5) & 13.1 (2.1) & 11.7 (3.2) & 16.4 (2.6) \\
FENC & 57.4 (2.3) & 44.8 (2.8) & 39.3 (1.6) & 34.8 (2.1) & 32.9 (1.9) & 33.2 (2.6) & 33.7 (1.7) \\
FENC-FiLM & \textbf{62.7 (2.1)} & \textbf{50.2 (2.4)} & \textbf{46.9 (2.3)} & \textbf{40.1 (2.2)} & \textbf{37.3 (2.5)} & \textbf{36.1 (2.2)} & \textbf{35.7 (2.1)} \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
\caption{Accuracy for each incremental session on dSprites-pos dataset, based on the VTAB setting. The first session contains 50 images for each of the first 4 classes. The rest of the sessions include 2 classes with 50 images each (10-way/50-shot).}
\label{table2}
\end{table}

\begin{table}[ht]
\vspace*{1.5 cm}
\begingroup
\setlength{\tabcolsep}{1.5pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{small}
%\begin{sc}
\begin{tabular}{lccccccccc}
\toprule
& \multicolumn{9}{c}{\textbf{FGVC-Aircraft - Accuracy in each session (\%) $\uparrow$}} \\
\cmidrule(lr){2-10} \\
 \textbf{Method} & \textbf{1} & \textbf{2} &  \textbf{3} &  \textbf{4} &  \textbf{5} &  \textbf{6} &  \textbf{7} &  \textbf{8} &  \textbf{9} \\
 \midrule
NA & 35.5 (0.9) & 28.7 (0.7) & 36.4 (0.8) & 42.8 (0.4) & 40.0 (0.4) & 39.4 (0.6) & 41.4 (0.7) & 40.3 (0.9) & 40.7 (0.6) \\
FACT & 41.4 (0.6) & 25.9 (0.9) & 19.6 (0.4) & 16.3 (0.4) & 13.7 (0.4) & 11.3 (0.5) & 10.4 (0.5) & 9.4 (0.6) & 8.3 (0.6) \\
GDumb & \textbf{51.1 (1.7)} & \textbf{45.4 (1.2)} & 46.9 (1.8) & 52.2 (1.0) & 45.4 (1.7) & 42.5 (1.6) & 41.8 (0.9) & 39.5 (1.9) & 38.6 (1.0) \\
FENC & 42.9 (2.6) & 39.5 (2.0) & 45.5 (1.5) & 51.6 (1.7) & 48.2 (1.8) & 47.3 (1.4) & 49.8 (1.5) & 49.1 (1.7) & 50.1 (1.5) \\
FENC-FiLM & 46.6 (1.9) & 44.8 (1.1) & \textbf{49.4 (0.8)} & \textbf{52.9 (1.6)} & \textbf{54.0 (0.7)} & \textbf{53.5 (1.0)} & \textbf{55.8 (0.7)} & \textbf{55.2 (0.5)} & \textbf{55.8 (0.6)} \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\endgroup
\caption{Accuracy for each incremental session on FGVC-Aircraft dataset. The first session contains 50 images for each of the first 20 classes. The rest of the sessions include 10 classes with 50 images each (10-way/50-shot).}
\label{table2}
\end{table}

\begin{table}[ht]
\vspace*{1.5 cm}
\begingroup
\setlength{\tabcolsep}{1.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{small}
%\begin{sc}
\hskip-2.3cm
\begin{tabular}{lccccccccccc}
\toprule
& \multicolumn{11}{c}{\textbf{Letters - Accuracy in each session (\%) $\uparrow$}} \\
\cmidrule(lr){2-12} \\
 \textbf{Method} & \textbf{1} & \textbf{2} &  \textbf{3} &  \textbf{4} &  \textbf{5} &  \textbf{6} &  \textbf{7} &  \textbf{8} &  \textbf{9} &  \textbf{10} &  \textbf{11} \\
 \midrule
NA & 82.1 (0.8) & 76.6 (0.9) & 73.0 (1.5) & 69.6 (1.0) & 69.0 (1.3) & 67.6 (1.3) & 65.8 (1.2) & 64.1 (1.0) & 60.4 (0.6) & 59.0 (0.8) & 57.6 (0.8) \\
FACT & 84.3 (1.4) & 72.0 (1.2) & 68.0 (2.2) & 63.2 (1.0) & 62.3 (1.0) & 59.5 (1.2) & 58.0 (1.0) & 55.8 (1.0) & 52.8 (0.7) & 51.7 (0.8) & 49.8 (0.8) \\
GDumb & 91.3 (1.6) & \textbf{91.8 (1.2)} & 80.0 (1.4) & 72.0 (1.9) & 69.2 (3.0) & 63.5 (1.5) & 59.9 (1.1) & 54.5 (0.3) & 48.0 (0.4) & 44.3 (1.9) & 41.2 (1.7) \\
FENC & 87.0 (1.4) & 79.6 (1.1) & 76.4 (0.9) & 72.7 (0.7) & 73.0 (0.9) & 71.3 (0.4) & 69.7 (0.4) & 68.4 (0.4) & 64.7 (0.5) & 62.9 (0.4) & 62.2 (0.4) \\
FENC-FiLM & \textbf{94.3 (0.9)} & 90.6 (0.3) & \textbf{88.6 (1.0)} & \textbf{85.1 (0.6)} & \textbf{84.9 (0.4)} & \textbf{84.0 (0.4)} & \textbf{82.5 (0.7)} & \textbf{81.1 (0.4)} & \textbf{76.8 (0.4)} & \textbf{75.0 (0.4)} & \textbf{73.4 (0.4)} \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\endgroup
\caption{Accuracy for each incremental session on Letters dataset. The first session contains 50 images for each of the first 12 classes. The rest of the sessions include 5 classes with 50 images each (5-way/50-shot).}
\label{table2}
\end{table}

\begin{table}[ht]
\vspace*{1.5 cm}
\begingroup
\setlength{\tabcolsep}{1.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{small}
%\begin{sc}
\hskip-.6cm
\begin{tabular}{lccccccccc}
\toprule
& \multicolumn{9}{c}{\textbf{DomainNet - Accuracy in each session (\%) $\uparrow$}} \\
\cmidrule(lr){2-10} \\
 \textbf{Method} & \textbf{1} & \textbf{2} &  \textbf{3} &  \textbf{4} &  \textbf{5} &  \textbf{6} &  \textbf{7} &  \textbf{8} &  \textbf{9} \\
 \midrule
NA & 83.3 (0.9) & 62.6 (0.5) & 60.9 (0.4) & 61.5 (0.7) & 68.3 (0.5) & 71.1 (0.6) & 72.0 (0.3) & 70.8 (0.5) & 69.0 (0.4) \\
FACT & 84.3 (1.1) & 53.6 (0.9) & 43.0 (0.7) & 35.9 (0.8) & 28.3 (0.7) & 24.2 (0.6) & 22.6 (0.8) & 22.0 (0.7) & 20.6 (0.6) \\
GDumb & \textbf{88.3 (0.8)} & 63.6 (0.9) & 58.6 (0.7) & 56.4 (0.9) & 66.0 (1.1) & 68.7 (0.8) & 68.9 (0.8) & 65.8 (0.6) & 63.2 (0.7) \\
FENC & 85.2 (0.6) & 63.3 (0.7) & 61.4 (0.5) & 61.6 (0.3) & 68.5 (0.4) & 71.2 (0.5) & 72.2 (0.3) & 71.2 (0.4) & 70.3 (0.3) \\
FENC-FiLM & 87.7 (0.4) & \textbf{68.5 (0.5)} & \textbf{66.9 (0.4)} & \textbf{66.7 (0.2)} & \textbf{73.7 (0.3)} & \textbf{76.0 (0.4)} & \textbf{76.0 (0.3)} & \textbf{75.0 (0.2)} & \textbf{74.0 (0.2)} \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\endgroup
\caption{Accuracy for each incremental session on DomainNet dataset. The first session contains 50 images for each of the first 10 classes. The rest of the sessions include 10 classes with 50 images each (5-way/50-shot).}
\label{table2}
\end{table}

\begin{table}[ht]
\vspace*{1.5 cm}
\begingroup
\setlength{\tabcolsep}{5.5pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
%\hskip-.6cm
\begin{tabular}{lccccccccc}
\toprule
& \multicolumn{9}{c}{\textbf{iNaturalist - Accuracy in each session (\%) $\uparrow$}} \\
\cmidrule(lr){2-10} \\
 \textbf{Method} & \textbf{1} & \textbf{2} &  \textbf{3} &  \textbf{4} &  \textbf{5} &  \textbf{6} &  \textbf{7} &  \textbf{8} &  \textbf{9} \\
 \midrule
NA & 51.9 & 52.8 & 44.9 & 46.8 & 49.3 & 51.7 & 54.4 & 53.8 & 49.7 \\
FACT & 54.9 & 29.9 & 24.6 & 23.8 & 20.4 & 17.8 & 15.7 & 16.4 & 14.3 \\
GDumb & 56.4 & 50.1 & 36.3 & 47.5 & 44.2 & 44.7 & 46.4 & 40.9 & 40.4 \\
FENC & 52.1 & 53.6 & 40.0 & 47.8 & 49.2 & 51.3 & 55.1 & 55.1 & 51.5 \\
FENC-FiLM & \textbf{61.8} & \textbf{61.6} & \textbf{52.0} & \textbf{56.5} & \textbf{57.0} & \textbf{59.4} & \textbf{61.8} & \textbf{61.2} & \textbf{58.8} \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
\caption{Accuracy for each incremental session on iNaturalist dataset. The first session contains 50 images for each of the 20 first classes. The rest of the sessions include 10 classes with 50 images each (10-way/50-shot).}
\label{table2}
\end{table}

\begin{table}[ht]
\begingroup
\setlength{\tabcolsep}{5.1pt} % Default value: 6pt
\renewcommand{\arraystretch}{1.1}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c c}
\toprule
\textbf{No adaptation} & \textbf{Aqua} & \textbf{DevFurn} &  \textbf{Vehicles} \\
 \midrule
57.4 (1.0) & 66.11 (1.61) & 66.21 (1.94) & 67.88 (1.24) \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
\caption{Accuracies of FENC-FiLM for three different continual learning settings on CIFAR-100. We split the data into 19 sessions using 50 shots. The first session includes 10 classes from super-classes (i) aquatic mammals and fish (\textbf{Aqua}), (ii) electric devices and furniture (\textbf{DevFurn}), and (iii) Vehicles 1 and Vehicles 2 (\textbf{Vehicles}). Each of the other 18 sessions include images from the remaining 18 super-classes. }
\label{table2}
\end{table}

\begin{table}[ht]
\begingroup
\setlength{\tabcolsep}{5.1pt} % Default value: 6pt
\renewcommand{\arraystretch}{1.1}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c c}
\toprule
\textbf{No adaptation} & \textbf{Elect-Real} & \textbf{Furn-Clipart} &  \textbf{Transp-sketch} \\
 \midrule
69.00 (0.43) & 70.62 (0.57) & 71.68 (0.63) & 72.77 (0.45) \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
\caption{Accuracies of FENC-FiLM for three different continual learning settings on DomaiNet. We split the data into 6 sessions using 50 shots with 10 classes in each session. The first session includes 10 classes of (i) the ``electricity'' superclass of the real domain (\textbf{Elect-Real}), (ii) the ``furniture'' superclass of the clipart domain (\textbf{Furn-Clipart}), and (iii) the ``transportation'' superclass of the sketch domain (\textbf{Transp-sketch}).}
\label{table2}
\end{table}

\bibliography{refs}
\bibliographystyle{plain}
\fi

\end{document}
