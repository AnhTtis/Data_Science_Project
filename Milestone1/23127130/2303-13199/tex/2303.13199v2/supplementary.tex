\appendix

\section{Datasets}\label{sec:dataset_info}
The exact numbers of training samples and classes for each dataset used in the experiments of Section 4 in the main paper are given in \Cref{table:all_datasets_info}. For datasets with more than 120k training instances in VTAB+, due to hardware limitations, we randomly sample 120k images and the associated labels and we consider this subset as the full training set. For instance, when we use dSprites-location dataset in a 50-shot setting, we first randomly sample 120k examples and then we randomly pick 50 images for each one of the 16 classes. For DomainNet and iNaturalist we apply a different procedure (see \Cref{sec:splits} for details).

For evaluation, we consider the protocol used in \cite{zhai2019large} on the 19 datasets in VTAB, where a balanced dataset of $2$k images is created by randomly sampling images from the full test dataset. For FGVC-Aircraft, Cars, and Letters the full test dataset is utilized. We also use the full test dataset for evaluation in the high-shot Class-Incremental Learning (CIL) setting.

% Vtab+ datasets info
\begin{table*}[ht]
%\begingroup
\setlength{\tabcolsep}{7.8pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{normalsize}
%\begin{sc}
\begin{tabular}{l c c  c  c}
\toprule
\textbf{Datasets}       &   \textbf{\# Classes} & \textbf{\# Train instances} & \textbf{ALL} & \textbf{CIL}  \\
\midrule
Caltech101~\cite{fei2006one} & $102$ & $3,060$ & \cmark & \xmark \\
CIFAR100~\cite{krizhevsky2009learning} & $100$ & $50,000$  & \cmark & \cmark \\
Flowers102~\cite{nilsback2008automated} & $102$ & $1,020$  & \cmark & \xmark \\
Pets~\cite{parkhi2012cats}  & $37$ & $3,680$ & \cmark & \xmark  \\
Sun397~\cite{xiao2010sun} & $397$  & $76,127$  & \cmark & \xmark \\
SVHN~\cite{netzer2011reading} & $10$ & $73,257$  & \cmark & \cmark  \\
DTD~\cite{cimpoi2014describing} & $47$ & $1,880$  & \cmark & \xmark  \\
\midrule
EuroSAT~\cite{helber2019eurosat} & $10$  & $27,000$ & \cmark & \xmark \\
Resics45~\cite{cheng2017remote} & $45$ & $31,500$ & \cmark & \xmark \\
Patch Camelyon~\cite{veeling2018rotation} & $2$  & $262,144$ & \cmark & \xmark \\
Retinopathy~\cite{kaggle2015diabetic} & $5$ & $35,126$  & \cmark & \xmark \\
\midrule
CLEVR-count~\cite{johnson2017clevr} & $8$ & $70,000$ & \cmark & \xmark \\
CLEVR-dist~\cite{johnson2017clevr} & $6$  & $70,000$ & \cmark & \xmark \\
dSprites-loc~\cite{dsprites17} & $16$ & $737,280$  & \cmark & \cmark \\
dSprites-ori~\cite{dsprites17} & $16$  & $737,280$ & \cmark & \xmark\\
SmallNORB-azi~\cite{lecun2004learning} & $18$ & $24,300$ & \cmark & \xmark  \\
SmallNORB-elev~\cite{lecun2004learning} & $9$ & $24,300$ & \cmark & \xmark  \\
DMLab~\cite{beattie2016deepmind} & $6$ & $65,550$  & \cmark & \xmark  \\
KITTI-dist~\cite{geiger2013vision} & $4$ & $6,347$  & \cmark & \xmark  \\
\midrule
FGVC-Aircraft~\cite{maji2013fine} & $100$ & $6,667$ & \cmark & \cmark   \\
Cars~\cite{krause20133d} & $196$ & $8,144$ & \cmark & \cmark  \\
Letters~\cite{deCampos2009character} & $62$ & $74,107$ & \cmark & \cmark  \\
\midrule
\midrule
DomainNet~\cite{peng2019moment} &  $60$ ($345^\dagger$) & $569,010$ & \xmark & \cmark   \\
iNaturalist~\cite{van2018inaturalist} & $100$ ($10,000^\dagger$)  & $500,000$ & \xmark & \cmark  \\
Core50~\cite{lomonaco2017core50} & $50$ & $119,894$ & \cmark & \cmark \\
CUB200~\cite{WahCUB_200_2011} & $200$ & $11,788$ & \xmark & \cmark  \\
\bottomrule
\end{tabular}
%\end{sc}
\end{normalsize}
\end{center}
\caption{Information concerning all datasets used in the experiments. $\dagger$ denotes the number of classes of the original dataset before they are modified for the continual learning scenarios (see \Cref{sec:splits} for more details). The first 22 datasets form the VTAB+ collection. We also indicate whether a dataset has been used in the offline experiments in Section 4.2 of the main paper which use all the available training data (ALL). Similarly, we indicate which datasets are considered for the Class-Incremental Learning settings in Section 4.}
\label{table:all_datasets_info}
%\endgroup
\end{table*}

%---------------------------------------------

\section{Dataset Information for the Class-Incremental Learning Experiments}\label{sec:splits}
% 3 tables; one for each CIL setting
In \Cref{table:cil_datasets_splits_info}, we present detailed information about the Class-Incremental Learning Experiments (CIL) experiments that are in Section 4.3 in the main paper, such as the number of total sessions, number of train instances, and classes per session. Next, we discuss the exact setup for DomainNet and iNaturalist.

\begin{table}[ht]

%\begingroup
\setlength{\tabcolsep}{2.2pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
    
\begin{small}
%\begin{sc}
\begin{tabular}{l c c c c c c c}
\toprule
\textbf{CIL setting}  & \textbf{Datasets}  &   \textbf{$S$} & \textbf{$N_1$} & \textbf{$|\cY_1|$} & \textbf{$N_s$} & \textbf{$|\cY_s|$} \\
\midrule
 \multirow{4}{*}{High-shot} & CIFAR100 & $10$ & $5$k & $10$ & $5$k & $10$ \\
 & SVHN   & $5$ & $\sim 19$k & $2$ & $\sim 14$k & $2$  \\
 & dSprites-loc  & $7$ & $24$k & $4$ & $12$k & $2$  \\
 & FGVC-Aircraft & $10$ & $667$ & $10$ & $\sim 670$ & $10$  \\
 & Cars & $10$ & $652$ & $15$ & $\sim 830$ & $20$  \\
 & Letters & $11$ & $\sim 11$k & $12$ & $\sim 5$k & $5$  \\
 & Core50  & $9$ & $\sim 24$k & $10$ & $\sim 12$k & $5$  \\
\midrule
 \multirow{2}{*}{Few-shot+} & CIFAR100  & $9$ & $30$k & $60$ & $25$ & $5$  \\
 & CUB200   & $11$ & $3$k & $100$ & $50$ & $10$  \\
\midrule
 \multirow{7}{*}{Few-shot} & CIFAR100  & $9$ & $1$k & $20$ & $500$ & $10$  \\
 & SVHN   & $5$ & $100$ & $2$ & $100$ & $2$  \\
 & dSprites-loc  & $7$ & $200$ & $4$ & $100$ & $2$  \\
 & FGVC-Aircraft & $9$ & $1$k & $20$ & $500$ & $10$  \\
 & Cars & $9$ & $1484$ & $36$ & $\sim 830$ & $20$  \\
 & Letters & $11$ & $600$ & $12$ & $250$ & $5$  \\
 & DomainNet & $9$ & $600$ & $12$ & $300$ & $6$  \\
 & iNaturalist & $9$ & $1$k & $20$ & $500$ & $10$  \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\end{center}
\caption{Detailed CIL settings for the experiments of Section 4.3. We report the total number of sessions ($S$), the number of train instances ($N_1$), and the number of classes ($|\cY_1|$) of the first session and the rest of the sessions ($N_s, |\cY_s|, s>1$).}
\label{table:cil_datasets_splits_info}
%\endgroup
\end{table}

\paragraph{DomainNet \& iNaturalist.} DomainNet and iNaturalist are the only datasets for which we follow a different pre-processing procedure from the one described in \Cref{sec:dataset_info} in order to create a few-shot CIL scenario similar to the ones considered in the literature. This is due to the large number of classes (iNaturalist has $10,000$ classes) and different domains (DomainNet includes images from 6 domains) these datasets have.

\begin{table*}[ht]
\begin{center}
    
\setlength{\tabcolsep}{2.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{small}
%\begin{sc}
%\begin{tabular}{l c c c c c c c c c c c c}
\begin{tabular}{l c c c c c c}
\toprule
%\textbf{Domain}  & \textbf{Superclass}  &  \multicolumn{10}{c}{\textbf{Classes}}  \\
%\midrule  
%Clipart & Furniture & Couch (1) & Fence (2) & Streetlight (3) & Table (4) & Toothbrush (5) & Vase (6) & Bed (7) & Fireplace (8) & Teapot (9) & Lantern (10) \\
%Infograph & Mammal & Cat (11) & Dolphin (12) & Squirrel (13) & Zebra (14) & Cow (15) & Elephant (16) & Pig (17) & Tiger (18) & Dog (19) & Rabbit (20) \\
%Painting & Tool & Anvil (21) & Basket (22) & Rifle (23) & Axe (24) & Dumbbell (25) & Pliers (26) & Saw (27) & Skateboard (28) & Bandage (29) & Paint Can (30) \\
%Quickdraw & Cloth & Belt (31) & Camouflage (32) & Eyeglasses (33) & Helmet (34) & Necklace (35) & Rollerskates (36) & Sock (37) & Underwear (38) & Bowtie (39) & Crown (40) \\
%Real & Electricity & Calculator (41) & Computer (42) & Fan (43) & Oven (44) & Dishwasher (45) & %Headphones (46) & Microwave (47) & Radio (48) & Stereo (49) & Toaster (50) \\
%Sketch & Road Transportation & Ambulance (51) & Bus (52) & Motorbike (53) & Train (54) & Bicycle (55) & Car (56) & Truck (57) & Bulldozer (58) & Firetruck (59) & Tractor (60) \\
\textbf{Domain} & Clipart & Infograph & Painting & Quickdraw & Real & Sketch \\
\midrule
\textbf{Superclass} & Furniture & Mammal & Tool & Cloth & Electricity &  Road Transportation \\
\midrule
\multirow{10}{*}{\textbf{Classes}} & Clipart & Infograph & Painting & Quickdraw & Real & Sketch \\
 & Furniture & Mammal & Tool & Cloth & Electricity & Road Transportation \\
 & Couch (1) & Cat (11) & Anvil (21) & Belt (31) & Calculator (41) & Ambulance (51) \\
 & Fence (2) & Dolphin (12) & Basket (22) & Camouflage (32) & Computer (42) & Bus (52) \\
 & Streetlight (3) & Squirrel (13) & Rifle (23) & Eyeglasses (33) & Fan (43) & Motorbike (53) \\
 & Table (4) & Zebra (14) & Axe (24) & Helmet (34) & Oven (44) & Train (54) \\
 & Toothbrush (5) & Cow (15) & Dumbbell (25) & Necklace (35) & Dishwasher (45) & Bicycle (55) \\
 & Vase (6) & Elephant (16) & Pliers (26) & Rollerskates (36) & Headphones (46) & Car (56) \\
 & Bed (7) & Pig (17) & Saw (27) & Sock (37) & Microwave (47) & Truck (57) \\
 & Fireplace (8) & Tiger (18) & Skateboard (28) & Underwear (38) & Radio (48) & Bulldozer (58) \\
 & Teapot (9) & Dog (19) & Bandage (29) & Bowtie (39) & Stereo (49) & Firetruck (59) \\
 & Lantern (10) & Rabbit (20) & Paint Can (30) & Crown (40) & Toaster (50) & Tractor (60) \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\end{center}
\caption{DomainNet classes (class id in parentheses) used for the few-shot CIL setting.}
\label{table:domainnet_classes}
%\endgroup
\end{table*}

DomainNet is a large-scale dataset of $\sim 0.6$M images lying in 6 different domains (clipart, infograph, painting, quickdraw, real, sketch) and categorized into 365 distinct classes. These classes can be grouped into 24 superclasses: furniture, mammal, tool, cloth, electricity, building, office, human
body, road transportation, food, nature, cold-blooded,
music, fruit, sport, tree, bird, vegetable, shape, kitchen,
Water transportation, sky transportation, insects, and others. In our CIL experiments, we use 60 classes from the superclasses with an adequate number of instances ($>150$): furniture, mammal, tool, cloth, electricity, and road transportation. To the best of our knowledge, this is the first time such a dataset is considered for CIL problems. \Cref{table:domainnet_classes} summarizes the DomainNet classes we use for the CIL experiments. To build the 50-shot CIL setting of Section 4.3, we randomly sample 50 images per class and the rest of the images are used for evaluation. 

The iNaturalist is another large-scale dataset. comprising $\sim 2.7$ million images of $10,000$ species. The species can be divided into 10 general categories: amphibians, animalia, arachnids, birds, fungi, insects, mammals, mollusks, plants, and reptiles. Due to the dataset's large size, we have opted to use the ``mini'' version of the training dataset\footnote{We use the data from the 2021 competition, available at \url{https://github.com/visipedia/inat_comp/tree/master/2021}.} which has 50 images per class, and thus, this is the only dataset from the few-shot CIL experiments that we do not repeat for 5 times since the (mini) train dataset is already in a 50-shot setting. For evaluation, we use the validation data with 10 images per class. The number of classes considered for the CIL experiments is reduced from $10,000$ to 100; 10 classes per superclass (10 superclasses/sessions). Specific details are given in Tables   \ref{table:inaturalist_classes_1} and \ref{table:inaturalist_classes_2}.

\begin{table*}[ht]

%\begingroup
\setlength{\tabcolsep}{8.pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
    
\begin{tiny}
%\begin{sc}
\begin{tabular}{l c c c c c c}
\toprule
  &  \multicolumn{5}{c}{\textbf{Superclass}}  \\
\cmidrule(lr){2-7} 
   & \textbf{Amphibians} & \textbf{Animalia} & \textbf{Arachnids} & \textbf{Birds} & \textbf{Fungi} \\
\textbf{Session} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} \\
\midrule  
 \multirow{10}{*}{Classes} & Ascaphus truei & Lumbricus terrestris & Eratigena duellica & Accipiter badius & Herpothallon rubrocinctum \\
 & Bombina orientalis & Sabella spallanzanii & Atypoides riversi & Accipiter cooperii & Chrysothrix candelaris \\
 & Bombina variegata & Serpula columbiana & Aculepeira ceropegia & Accipiter gentilis & Apiosporina morbosa \\
 & Anaxyrus americanus & Spirobranchus cariniferus & Agalenatea redii & Accipiter nisus & Acarospora socialis \\
 & Anaxyrus boreas & Hemiscolopendra marginata & Araneus bicentenarius & Accipiter striatus & Physcia adscendens \\
 & Anaxyrus cognatus & Scolopendra cingulata & Araneus diadematus & Accipiter trivirgatus & Physcia aipolia \\
 & Anaxyrus fowleri & Scolopendra heros & Araneus marmoreus & Aegypius monachus & Physcia millegrana \\
 & Anaxyrus punctatus & Scolopendra polymorpha & Araneus quadratus & Aquila audax & Physcia stellaris \\
 & Anaxyrus quercicus & Scutigera coleoptrata & Araneus trifolium & Aquila chrysaetos & Candelaria concolor \\
 & Anaxyrus speciosus & Ommatoiulus moreleti & Araniella displicata & Aquila heliaca & Cladonia chlorophaea \\
\bottomrule
\end{tabular}
%\end{sc}
\end{tiny}
\end{center}
\caption{Classes used from iNaturalist to create the few-shot CIL setting. (table continues to \Cref{table:inaturalist_classes_2}).}
\label{table:inaturalist_classes_1}
%\endgroup
\end{table*}


\begin{table*}[ht]

%\begingroup
\setlength{\tabcolsep}{7.pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
    
\begin{tiny}
%\begin{sc}
\begin{tabular}{l c c c c c c}
\toprule
  &  \multicolumn{5}{c}{\textbf{Superclass}}  \\
\cmidrule(lr){2-7} 
   & \textbf{Insects} & \textbf{Mammals} & \textbf{Mollusks} & \textbf{Plants} & \textbf{Reptiles} \\
\textbf{Session} & \textbf{6} & \textbf{7} & \textbf{8} & \textbf{9} & \textbf{10} \\
\midrule  
 \multirow{10}{*}{Classes} & Aptera fusca & Antilocapra americana & Ensis leei & Bryum argenteum & Alligator mississippiensis \\
 & Panchlora nivea & Balaenoptera acutorostrata & Clinocardium nuttallii & Rhodobryum ontariense & Caiman crocodilus \\
 & Pycnoscelus surinamensis & Megaptera novaeangliae & Dinocardium robustum & Leucolepis acanthoneura & Crocodylus acutus \\
 & Blatta orientalis & Aepyceros melampus & Tridacna maxima & Plagiomnium cuspidatum & Crocodylus moreletii \\
 & Periplaneta americana & Alcelaphus buselaphus & Donax gouldii & Plagiomnium insigne & Crocodylus niloticus \\
 & Periplaneta australasiae & Antidorcas marsupialis & Donax variabilis & Rhizomnium glabrescens & Crocodylus porosus \\
 & Periplaneta fuliginosa & Bison bison & Dreissena polymorpha & Dicranum scoparium & Sphenodon punctatus \\
 & Pseudomops septentrionalis & Bos taurus & Mya arenaria & Ceratodon purpureus & Acanthocercus atricollis \\
 & Arrhenodes minutus & Boselaphus tragocamelus & Cyrtopleura costata & Leucobryum glaucum & Agama atra \\
 & Agrilus planipennis & Bubalus bubalis & Geukensia demissa & Funaria hygrometrica & Agama picticauda \\
\bottomrule
\end{tabular}
%\end{sc}
\end{tiny}
\end{center}
\caption{Classes used from iNaturalist to create the few-shot CIL setting. The first part can be found in \Cref{table:inaturalist_classes_1}.}
\label{table:inaturalist_classes_2}
%\endgroup
\end{table*}



%----------------------------------------------

\section{Extra Training Details}
Due to the large number of experiments and datasets we tried to keep the hyperparameter tuning to a minimum by choosing a set of hyperparameters that works fairly well across all datasets and settings. We have not used any data augmentation in our experiments and all images have been scaled to $224 \times 224$ pixels. The only exception is the experiments on CIFAR100, and CUB200 under the few-shot+ setting. There, for comparability reasons, we followed the exact experimental settings as in \cite{zhou2022forward} where standard data augmentation techniques (e.g.~random flips and crops) were utilized. Moreover, when we used ResNet-20 for CIFAR100 we maintained the original image size ($32 \times 32$).


\paragraph{Computing Infrastructure Details \& Code.} All the experiments of Section 4 have been carried out on a Linux machine with a single NVIDIA-A100 (80GB memory) GPU. Our PyTorch-based code will be made available via a public repository after the review period. 

\paragraph{Optimization Details.} 
In all experiments, we train the models using a batch size of 256. Apart from GDumb, for the rest of the methods, EfficientNet-B0 backbones are optimized with the Adam optimizer \cite{kingma2014adam} while for ResNet architectures we opt for SGD with momentum set to 0.9. For GDumb, we follow \cite{prabhu2020gdumb} and we use SGD with momentum. For FACT~\cite{zhou2022forward} and FSA with pre-trained EfficientNet-B0 backbone, we set the initial learning rate to 0.0001 with scheduled decays by a factor of 0.5 every 50 epochs while for FSA-FiLM, we set it to 0.005. We train all full-body adaptation methods for 200 epochs and the FSA-FiLM for 150 epochs (except for the high-shot setting where we use 200 epochs for fair time comparisons). For the few-shot+ CIL scenario, we follow the training setup of~\cite{zhou2022forward}. The weights of the pre-trained EfficientNet-B0 have been obtained from \url{https://github.com/lukemelas/EfficientNet-PyTorch} while for the pre-trained weights of ResNet-18 and ConvNext, we use the following repository  \url{https://github.com/rwightman/pytorch-image-models}.

\paragraph{Competitors.} We found empirically that the recommended hyperparameter values (learning rates, cutmix parameters, SGDR schedule) for GDumb in~\cite{prabhu2020gdumb} work well in practice and we use these throughout the experiments. Similarly, for FACT, we use the default values $\alpha=0.5, \gamma=0.01, V = \text{number of new classes in total}$~\cite{zhou2022forward}. For ALICE, following~\cite{peng2022few}, the projection head is a two-layer MLP with a hidden feature size of
2048 and ReLU as the activation function. All the other hyperparameters (scale factor $s$, margin $m$, etc.) are set as in~\cite{peng2022few}. For E-EWC+SDC, a triplet loss~\cite{hoffer2015deep} is used as in~\cite{yu2020semantic} and the final embeddings of 640 dimensions are normalized.



%----------------------------------------------

\section{Additional Results}
In this section, we provide tables with the exact accuracies for each one of the datasets used in the experiments under different settings. We have run extra experiments on VTAB+ using meta-learned FiLM adapters in the offline setting and we report accuracies. Additionally, we perform a comparison between different backbones in the offline setting:  EfficientNet-B0 and ResNet-18. For the high-shot setting, apart from the four datasets utilized in the main paper, we also deploy the methods on SVHN and present accuracies by session. Finally, accuracies at each session for all three CIL settings are provided.

\paragraph{Head Comparison.} Here we provide the exact accuracies for each dataset based on Section 4.2 and Figure 1 of the main paper. Tables \ref{table:head_comparison_na_5shots}, \ref{table:head_comparison_na_10shots}, \ref{table:head_comparison_na_50shots}, and \ref{table:head_comparison_na_alldata} give the offline accuracies for the no adaptation (NA) method for 5, 10, 50 shots, and all training data, respectively. Similar information for the FiLM adaptation method (A-FiLM) is given in Tables \ref{table:head_comparison_film_5shots}, \ref{table:head_comparison_film_10shots}, \ref{table:head_comparison_film_50shots}, and \ref{table:head_comparison_film_alldata}. Finally, Tables \ref{table:head_comparison_full_5shots}, \ref{table:head_comparison_full_10shots}, \ref{table:head_comparison_full_50shots}, and \ref{table:head_comparison_full_alldata} provide the corresponding accuracies for the full-body adaptation method (A-FB).

\paragraph{Meta-learned FiLM Adapters.} We consider experiments in the offline setting with meta-learned FiLM adapters. We use the meta-trained FiLM adapters as presented in \cite{bronskill2021memory}. The results for meta-learned FiLM adapters, as well as for no-adaptation (NA), FiLM (fine-tuned) adaptation (FiLM), and full body adaptation methods, are summarized in Tables \ref{table:meta_effenet_5shots}, \ref{table:meta_effenet_10shots}, and \ref{table:meta_effenet_50shots}, for 5, 10, and 50 shots, respectively. We observe that the meta-trained FiLM adapters work better than NA in all cases, but they fail to compete with the fine-tuned FiLM adapters. Notice that as the number of shots increases, the accuracy difference between meta-learned and fine-tuned FiLM adapters also increases.


\paragraph{FiLM Adaptation: EfficientNet-B0 vs ResNet-18.} To assess how different backbone architectures affect the performance of the no-adaptation and FiLM adaptation method, we compare ResNet-18 and EfficientNet-B0 (EN) backbones in Tables \ref{table:resnet18_vs_effnet_film_5shots}, \ref{table:resnet18_vs_effnet_film_10shots}, and \ref{table:resnet18_vs_effnet_film_50shots}, for 5, 10, and 50 shots, respectively. All tables demonstrate the superiority of EfficientNet-B0, regardless of the adaptation method. The tables also show that, regardless of backbone architecture and number of shots, FiLM adaptation provides significant performance benefits. 

\paragraph{High-shot CIL: Accuracies per Session.} We provide detailed accuracies for each incremental session for all baselines in the high-shot CIL setting. The accuracies for CIFAR100, CORE50, SVHN, dSPrites-loc, FGVC-Aircraft, Cars, and Letters can be found in Tables \ref{table:high_shot_cifar100}, \ref{table:high_shot_core50}, \ref{table:high_shot_svhn}, \ref{table:high_shot_dspritesloc}, \ref{table:high_shot_fgvcaircraft}, \ref{table:high_shot_cars}, and
\ref{table:high_shot_letters}, respectively. For GDumb, we provide results with a memory buffer of size 1k and 5k.


\begin{figure*}[htb]
\centering
\includegraphics[width = \textwidth]{plots/cifar100_core50_full_shots_acc_time} 
\caption{Last session's test accuracy ($\uparrow$) and run time ($\downarrow$)  for the ``high-shot CIL'' setting of \cref{sec:cil_comparisons}. GDumb-$m$ refers to memory buffer sizes $m \in \{ 200, 500, 1\text{k}, 2\text{k}, 5\text{k}, 10\text{k}^*  \}$. We use a memory buffer of 10k images only for CORE50.}
\label{fig:gdumb_cifar100_core50_time_acc}
\end{figure*}

\paragraph{Few-shot+ CIL: Accuracies per Session.}
We provide detailed accuracy for each incremental session for all baselines in the few-shot+ CIL setting. The accuracies for CIFAR100 and CUB200 can be found in Tables \ref{table:few_shot_plus_cifar100} and
\ref{table:few_shot_plus_cub200}, respectively. 

\paragraph{Few-shot CIL: Accuracies per Session.}
We provide detailed accuracy (+ error bars) for each incremental session for all baselines in the few-shot CIL setting. The accuracies for CIFAR100, SVHN, dSprites-location, FGVC-Aircraft, Letters, DomainNet, and iNaturalist can be found in Tables \ref{table:few_shot_cifar100}, \ref{table:few_shot_svhn}, \ref{table:few_shot_dsprites}, \ref{table:few_shot_fgvcaircraft}, \ref{table:few_shot_letters}, \ref{table:few_shot_domainnet}, and
\ref{table:few_shot_inaturalist}, respectively. 


\paragraph{FSA-FiLM vs GDumb} The trade-off between accuracy and training time for different continual learning methods on CIFAR100 and CORE50 is illustrated in Fig.~\ref{fig:gdumb_cifar100_core50_time_acc}. Several different memory sizes are used for GDumb. FSA-FiLM attains the highest accuracy (and the lowest PPDR) $\approx$13.5x faster than GDumb with a 5k memory buffer on CIFAR100 while on CORE50, GDumb requires at least a 5K memory buffer to outperform FSA-FiLM and $\approx$3x more training time than FSA-FiLM. Notice that FACT is unable to perform well under this setting due to the small number of available classes in the first
session.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tables for head comparisons %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%
% NA %%%
%%%%%%%%

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{6.5pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
    
\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
 \textbf{Dataset} & \textbf{NCM} & \textbf{LDA} &  \textbf{Linear} \\
 \midrule
Caltech101 & 85.7 {\tiny $\pm 0.9$} & \textbf{88.2} {\tiny $\pm \textbf{0.8}$} & 87.2 {\tiny $\pm 0.7$} \\
CIFAR100 & 40.2 {\tiny $\pm 1.5$} & \textbf{42.7} {\tiny $\pm \textbf{1.6}$} & 42.3 {\tiny $\pm 1.3$} \\
Flowers102 & 71.5 {\tiny $\pm 0.6$} & \textbf{76.1} {\tiny $\pm \textbf{0.4}$} & 75.7 {\tiny $\pm 0.8$} \\
Pets & \textbf{83.0} {\tiny $\pm \textbf{1.5}$} & 82.4 {\tiny $\pm 1.6$} & 82.5 {\tiny $\pm 1.5$} \\
Sun397 & 41.0 {\tiny $\pm 0.9$} & 41.9 {\tiny $\pm 1.0$} & \textbf{42.9} {\tiny $\pm \textbf{0.7}$} \\
SVHN & 13.5 {\tiny $\pm 1.6$} & \textbf{16.5} {\tiny $\pm \textbf{1.1}$} & 15.0 {\tiny $\pm 1.4$} \\
DTD & 48.2 {\tiny $\pm 1.0$} & 48.9 {\tiny $\pm 1.7$} & \textbf{49.2} {\tiny $\pm \textbf{1.8}$} \\
\midrule
EuroSAT & 72.1 {\tiny $\pm 1.9$} & \textbf{76.3} {\tiny $\pm \textbf{1.8}$} & 74.6 {\tiny $\pm 2.0$} \\
Resics45 & 55.2 {\tiny $\pm 1.2$} & 58.8 {\tiny $\pm 1.4$} & \textbf{58.9} {\tiny $\pm \textbf{1.2}$} \\
\midrule
Patch Camelyon & 59.6 {\tiny $\pm 8.7$} & \textbf{59.8} {\tiny $\pm \textbf{7.2}$} & 59.0 {\tiny $\pm 6.4$} \\
Retinopathy & \textbf{26.3} {\tiny $\pm \textbf{2.5}$} & 25.6 {\tiny $\pm 1.6$} & 24.3 {\tiny $\pm 1.7$} \\
\midrule
CLEVR-count & 22.2 {\tiny $\pm 0.8$} & \textbf{23.1} {\tiny $\pm \textbf{1.1}$} & 22.6 {\tiny $\pm 0.7$} \\
CLEVR-dist & 23.0 {\tiny $\pm 2.7$} & \textbf{24.5} {\tiny $\pm \textbf{2.3}$} & 24.4 {\tiny $\pm 2.2$} \\
dSprites-loc & 7.5 {\tiny $\pm 0.7$} & \textbf{8.5} {\tiny $\pm \textbf{0.6}$} & 7.3 {\tiny $\pm 0.6$} \\
dSprites-ori & 13.1 {\tiny $\pm 1.2$} & \textbf{16.2} {\tiny $\pm \textbf{0.8}$} & 14.8 {\tiny $\pm 1.1$} \\
SmallNORB-azi & 6.8 {\tiny $\pm 0.6$} & \textbf{9.3} {\tiny $\pm \textbf{0.8}$} & 8.8 {\tiny $\pm 1.0$} \\
SmallNORB-elev & 13.0 {\tiny $\pm 1.5$} & \textbf{15.1} {\tiny $\pm \textbf{0.6}$} & 14.5 {\tiny $\pm 0.9$} \\
DMLab & 22.2 {\tiny $\pm 0.8$} & 22.1 {\tiny $\pm 1.3$} & \textbf{23.8} {\tiny $\pm \textbf{0.8}$} \\
KITTI-dist & 50.0 {\tiny $\pm 1.3$} & 51.4 {\tiny $\pm 2.7$} & \textbf{51.9} {\tiny $\pm \textbf{3.1}$} \\
\midrule
FGVC-Aircraft & 19.4 {\tiny $\pm 0.6$} & 22.1 {\tiny $\pm 1.0$} & \textbf{22.7} {\tiny $\pm \textbf{0.6}$} \\
Cars & 20.0 {\tiny $\pm 0.6$} & \textbf{22.6} {\tiny $\pm \textbf{0.6}$} & 22.0 {\tiny $\pm 0.7$} \\
Letters & 28.3 {\tiny $\pm 1.8$} & \textbf{36.1} {\tiny $\pm \textbf{2.1}$} & 34.0 {\tiny $\pm 1.3$} \\
\midrule
Average acc & 37.4 & \textbf{39.5} & 39.0 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\end{center}
\caption{Accuracy comparison between NCM, LDA, and Linear head without using any adaptation (\textbf{NA} method). The reported results are based on \textbf{5} shots and averaged over 5 runs (mean±std). A pre-trained EfficientNet-B0 is used as a backbone in all cases.}
\label{table:head_comparison_na_5shots}
%\endgroup
\end{table}

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{6.5pt} % Default value: 6pt %\renewcommand{\arraystretch}{.9} \begin{center}
%\renewcommand{\arraystretch}{.9}
\begin{center}
    
\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
 \textbf{Dataset} & \textbf{NCM} & \textbf{LDA} &  \textbf{Linear} \\
 \midrule
Caltech101 & 88.5 {\tiny $\pm 0.9$} & \textbf{90.0} {\tiny $\pm \textbf{0.8}$} & 89.6 {\tiny $\pm 0.7$} \\
CIFAR100 & 45.8 {\tiny $\pm 1.0$} & \textbf{50.1} {\tiny $\pm \textbf{1.5}$} & 49.2 {\tiny $\pm 1.1$} \\
Flowers102 & 77.2 {\tiny $\pm 0.2$} & \textbf{83.9} {\tiny $\pm \textbf{0.3}$} & 81.9 {\tiny $\pm 0.2$} \\
Pets & 85.8 {\tiny $\pm 1.0$} & \textbf{86.4} {\tiny $\pm \textbf{0.7}$} & 86.1 {\tiny $\pm 0.5$} \\
Sun397 & 47.1 {\tiny $\pm 1.3$} & 49.0 {\tiny $\pm 1.3$} & \textbf{49.7} {\tiny $\pm \textbf{0.8}$} \\
SVHN & 15.5 {\tiny $\pm 2.3$} & \textbf{19.4} {\tiny $\pm \textbf{2.9}$} & 18.1 {\tiny $\pm 2.6$} \\
DTD & 53.8 {\tiny $\pm 0.3$} & 55.6 {\tiny $\pm 0.6$} & \textbf{56.3} {\tiny $\pm \textbf{0.7}$} \\
\midrule
EuroSAT & 76.6 {\tiny $\pm 1.2$} & \textbf{82.1} {\tiny $\pm \textbf{0.9}$} & 80.2 {\tiny $\pm 0.9$} \\
Resics45 & 60.7 {\tiny $\pm 1.3$} & 65.5 {\tiny $\pm 1.1$} & \textbf{65.9} {\tiny $\pm \textbf{1.2}$} \\
\midrule
Patch Camelyon & 63.0 {\tiny $\pm 5.3$} & \textbf{66.5} {\tiny $\pm \textbf{3.7}$} & 65.3 {\tiny $\pm 4.7$} \\
Retinopathy & \textbf{27.5} {\tiny $\pm \textbf{3.2}$} & 27.1 {\tiny $\pm 2.2$} & 26.1 {\tiny $\pm 1.8$} \\
\midrule
CLEVR-count & 24.0 {\tiny $\pm 0.4$} & \textbf{25.7} {\tiny $\pm \textbf{0.6}$} & 24.9 {\tiny $\pm 0.6$} \\
CLEVR-dist & 24.2 {\tiny $\pm 1.2$} & \textbf{26.3} {\tiny $\pm \textbf{1.1}$} & 26.3 {\tiny $\pm 1.4$} \\
dSprites-loc & 7.5 {\tiny $\pm 0.5$} & \textbf{8.7} {\tiny $\pm \textbf{0.3}$} & 7.9 {\tiny $\pm 0.3$} \\
dSprites-ori & 14.2 {\tiny $\pm 0.9$} & \textbf{18.2} {\tiny $\pm \textbf{0.7}$} & 16.4 {\tiny $\pm 1.0$} \\
SmallNORB-azi & 8.4 {\tiny $\pm 0.4$} & 9.5 {\tiny $\pm 1.1$} & \textbf{9.5} {\tiny $\pm \textbf{0.7}$} \\
SmallNORB-elev & 13.6 {\tiny $\pm 0.8$} & \textbf{16.5} {\tiny $\pm \textbf{1.1}$} & 16.2 {\tiny $\pm 0.7$} \\
DMLab & 25.1 {\tiny $\pm 1.1$} & 25.7 {\tiny $\pm 1.2$} & \textbf{27.2} {\tiny $\pm \textbf{1.3}$} \\
KITTI-dist & 50.1 {\tiny $\pm 0.8$} & \textbf{52.9} {\tiny $\pm \textbf{1.5}$} & 52.0 {\tiny $\pm 1.8$} \\
\midrule
FGVC-Aircraft & 23.1 {\tiny $\pm 0.4$} & \textbf{28.5} {\tiny $\pm \textbf{0.4}$} & 27.0 {\tiny $\pm 0.4$} \\
Cars & 25.4 {\tiny $\pm 0.5$} & 30.4 {\tiny $\pm 0.5$} & \textbf{30.7} {\tiny $\pm \textbf{0.4}$} \\
Letters & 34.2 {\tiny $\pm 0.8$} & \textbf{45.6} {\tiny $\pm \textbf{0.8}$} & 45.2 {\tiny $\pm 1.4$} \\
\midrule
Average acc & 40.5 & \textbf{43.8} & 43.3 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\end{center}
\caption{Accuracy comparison between NCM, LDA, and Linear head without using any adaptation (\textbf{NA} method). The reported results are based on \textbf{10} shots and averaged over 5 runs (mean±std). A pre-trained EfficientNet-B0 is used as a backbone in all cases.}
\label{table:head_comparison_na_10shots}
%\endgroup
\end{table}

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{6.5pt} % Default value: 6pt %\renewcommand{\arraystretch}{.9} \begin{center}
%\renewcommand{\arraystretch}{.9}
\begin{center}
    
\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
 \textbf{Dataset} & \textbf{NCM} & \textbf{LDA} &  \textbf{Linear} \\
 \midrule
Caltech101 & 90.4 {\tiny $\pm 0.6$} & 91.9 {\tiny $\pm 0.5$} & \textbf{93.0} {\tiny $\pm \textbf{0.4}$} \\
CIFAR100 & 52.0 {\tiny $\pm 0.9$} & 57.4 {\tiny $\pm 1.0$} & \textbf{60.9} {\tiny $\pm \textbf{1.0}$} \\
Flowers102 & 77.2 {\tiny $\pm 0.2$} & \textbf{83.9} {\tiny $\pm \textbf{0.3}$} & 81.9 {\tiny $\pm 0.2$} \\
Pets & 88.2 {\tiny $\pm 0.3$} & 89.5 {\tiny $\pm 0.4$} & \textbf{89.9} {\tiny $\pm \textbf{0.6}$} \\
Sun397 & 52.6 {\tiny $\pm 1.1$} & 55.9 {\tiny $\pm 1.0$} & \textbf{58.4} {\tiny $\pm \textbf{0.8}$} \\
SVHN & 19.3 {\tiny $\pm 1.7$} & 28.3 {\tiny $\pm 1.1$} & \textbf{28.9} {\tiny $\pm \textbf{1.1}$} \\
DTD & 58.5 {\tiny $\pm 0.0$} & 61.1 {\tiny $\pm 0.0$} & \textbf{65.4} {\tiny $\pm \textbf{0.2}$} \\
\midrule
EuroSAT & 81.7 {\tiny $\pm 0.6$} & 87.7 {\tiny $\pm 0.9$} & \textbf{88.2} {\tiny $\pm \textbf{0.7}$} \\
Resics45 & 66.6 {\tiny $\pm 0.7$} & 73.5 {\tiny $\pm 0.9$} & \textbf{78.2} {\tiny $\pm \textbf{0.7}$} \\
\midrule
Patch Camelyon & 70.9 {\tiny $\pm 5.4$} & \textbf{76.2} {\tiny $\pm \textbf{1.1}$} & 76.2 {\tiny $\pm 1.5$} \\
Retinopathy & 29.2 {\tiny $\pm 2.2$} & \textbf{32.9} {\tiny $\pm \textbf{2.2}$} & 32.9 {\tiny $\pm 1.9$} \\
\midrule
CLEVR-count & 26.3 {\tiny $\pm 1.5$} & 30.1 {\tiny $\pm 1.0$} & \textbf{31.2} {\tiny $\pm \textbf{1.0}$} \\
CLEVR-dist & 27.8 {\tiny $\pm 0.8$} & \textbf{32.2} {\tiny $\pm \textbf{1.1}$} & 31.7 {\tiny $\pm 1.0$} \\
dSprites-loc & 9.3 {\tiny $\pm 0.8$} & \textbf{11.9} {\tiny $\pm \textbf{0.4}$} & 9.9 {\tiny $\pm 0.6$} \\
dSprites-ori & 14.9 {\tiny $\pm 0.5$} & \textbf{20.1} {\tiny $\pm \textbf{1.1}$} & 18.7 {\tiny $\pm 2.2$} \\
SmallNORB-azi & 9.5 {\tiny $\pm 0.6$} & \textbf{12.3} {\tiny $\pm \textbf{0.8}$} & 12.1 {\tiny $\pm 1.1$} \\
SmallNORB-elev & 15.2 {\tiny $\pm 1.3$} & 19.1 {\tiny $\pm 0.7$} & \textbf{20.0} {\tiny $\pm \textbf{0.5}$} \\
DMLab & 29.1 {\tiny $\pm 0.3$} & 30.6 {\tiny $\pm 0.3$} & \textbf{32.3} {\tiny $\pm \textbf{0.7}$} \\
KITTI-dist & 53.2 {\tiny $\pm 0.9$} & \textbf{61.4} {\tiny $\pm \textbf{2.3}$} & 60.7 {\tiny $\pm 3.2$} \\
\midrule
FGVC-Aircraft & 30.9 {\tiny $\pm 0.5$} & 41.0 {\tiny $\pm 0.7$} & \textbf{46.1} {\tiny $\pm \textbf{0.6}$} \\
Cars & 33.7 {\tiny $\pm 0.0$} & 43.3 {\tiny $\pm 0.0$} & \textbf{46.5} {\tiny $\pm \textbf{0.2}$} \\
Letters & 43.1 {\tiny $\pm 1.0$} & 57.6 {\tiny $\pm 0.8$} & \textbf{65.9} {\tiny $\pm \textbf{1.1}$} \\
\midrule
Average acc & 44.5 & 49.9 & \textbf{51.3} \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\end{center}
\caption{Accuracy comparison between NCM, LDA, and Linear head without using any adaptation (\textbf{NA} method). The reported results are based on \textbf{50} shots and averaged over 5 runs (mean±std). A pre-trained EfficientNet-B0 is used as a backbone in all cases.}
\label{table:head_comparison_na_50shots}
%\endgroup
\end{table}

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{6.5pt} % Default value: 6pt %\renewcommand{\arraystretch}{.9} 
\begin{center}
%\renewcommand{\arraystretch}{.9}
\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
 \textbf{Dataset} & \textbf{NCM} & \textbf{LDA} &  \textbf{Linear} \\
 \midrule
Caltech101 & 90.4 {\tiny $\pm 0.6$} & 91.9 {\tiny $\pm 0.5$} & \textbf{93.0} {\tiny $\pm \textbf{0.4}$} \\
CIFAR100 & 53.5 {\tiny $\pm 1.6$} & 68.2 {\tiny $\pm 1.7$} & \textbf{68.3} {\tiny $\pm \textbf{0.8}$} \\
Flowers102 & 77.2 {\tiny $\pm 0.2$} & \textbf{83.9} {\tiny $\pm \textbf{0.3}$} & 81.9 {\tiny $\pm 0.3$} \\
Pets & 88.7 {\tiny $\pm 0.2$} & 89.9 {\tiny $\pm 0.2$} & \textbf{90.7} {\tiny $\pm \textbf{0.3}$} \\
Sun397 & 53.9 {\tiny $\pm 1.1$} & 56.9 {\tiny $\pm 1.2$} & \textbf{58.4} {\tiny $\pm \textbf{0.6}$} \\
SVHN & 24.5 {\tiny $\pm 0.4$} & 36.8 {\tiny $\pm 0.6$} & \textbf{40.8} {\tiny $\pm \textbf{0.8}$} \\
DTD & 58.5 {\tiny $\pm 0.0$} & 61.1 {\tiny $\pm 0.0$} & \textbf{65.3} {\tiny $\pm \textbf{0.3}$} \\
\midrule
EuroSAT & 82.4 {\tiny $\pm 0.3$} & 88.1 {\tiny $\pm 0.1$} & \textbf{93.2} {\tiny $\pm \textbf{0.2}$} \\
Resics45 & 67.1 {\tiny $\pm 0.2$} & 74.6 {\tiny $\pm 0.2$} & \textbf{81.8} {\tiny $\pm \textbf{0.4}$} \\
\midrule
Patch Camelyon & 72.9 {\tiny $\pm 0.0$} & 79.1 {\tiny $\pm 0.0$} & \textbf{79.7} {\tiny $\pm \textbf{0.5}$} \\
Retinopathy & 33.0 {\tiny $\pm 0.3$} & 40.4 {\tiny $\pm 0.3$} & \textbf{46.9} {\tiny $\pm \textbf{0.4}$} \\
\midrule
CLEVR-count & 28.9 {\tiny $\pm 0.3$} & 40.1 {\tiny $\pm 0.4$} & \textbf{50.3} {\tiny $\pm \textbf{0.3}$} \\
CLEVR-dist & 29.2 {\tiny $\pm 0.5$} & 38.7 {\tiny $\pm 0.4$} & \textbf{45.5} {\tiny $\pm \textbf{1.3}$} \\
dSprites-loc & 14.6 {\tiny $\pm 0.6$} & 20.9 {\tiny $\pm 0.7$} & \textbf{30.8} {\tiny $\pm \textbf{1.4}$} \\
dSprites-ori & 15.5 {\tiny $\pm 0.4$} & 22.5 {\tiny $\pm 0.6$} & \textbf{33.3} {\tiny $\pm \textbf{0.9}$} \\
SmallNORB-azi & 11.5 {\tiny $\pm 0.5$} & 14.1 {\tiny $\pm 0.7$} & \textbf{14.2} {\tiny $\pm \textbf{0.7}$} \\
SmallNORB-elev & 19.3 {\tiny $\pm 0.4$} & 24.1 {\tiny $\pm 0.5$} & \textbf{26.3} {\tiny $\pm \textbf{0.8}$} \\
DMLab & 35.4 {\tiny $\pm 0.4$} & 39.7 {\tiny $\pm 0.3$} & \textbf{44.4} {\tiny $\pm \textbf{0.4}$} \\
KITTI-dist & 53.4 {\tiny $\pm 0.0$} & 66.7 {\tiny $\pm 0.0$} & \textbf{69.8} {\tiny $\pm \textbf{0.4}$} \\
\midrule
FGVC-Aircraft & 31.8 {\tiny $\pm 0.0$} & 41.3 {\tiny $\pm 0.0$} & \textbf{45.8} {\tiny $\pm \textbf{0.4}$} \\
Cars & 33.7 {\tiny $\pm 0.0$} & 43.3 {\tiny $\pm 0.0$} & \textbf{46.6} {\tiny $\pm \textbf{0.3}$} \\
Letters & 44.9 {\tiny $\pm 1.3$} & 59.7 {\tiny $\pm 0.5$} & \textbf{69.5} {\tiny $\pm \textbf{0.5}$} \\
\midrule
Average acc & 46.4 & 53.4 & \textbf{58.0} \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\end{center}
\caption{Accuracy comparison between NCM, LDA, and Linear head without using any adaptation (\textbf{NA} method). The reported results are based on the full training dataset and averaged over 5 runs (mean±std). A pre-trained EfficientNet-B0 is used as a backbone in all cases.}
\label{table:head_comparison_na_alldata}
%\endgroup
\end{table}


%%%%%%%%%%%%
% A-FiLM %%%
%%%%%%%%%%%%

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{6.5pt} % Default value: 6pt %\renewcommand{\arraystretch}{.9} 
\begin{center}
%\renewcommand{\arraystretch}{.9}
\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
 \textbf{Dataset} & \textbf{NCM} & \textbf{LDA} &  \textbf{Linear} \\
 \midrule
Caltech101 & 86.6 {\tiny $\pm 0.5$} & \textbf{89.0} {\tiny $\pm \textbf{0.6}$} & 88.5 {\tiny $\pm 0.4$} \\
CIFAR100 & 47.4 {\tiny $\pm 1.2$} & \textbf{51.8} {\tiny $\pm \textbf{1.3}$} & 50.3 {\tiny $\pm 1.4$} \\
Flowers102 & 80.2 {\tiny $\pm 0.4$} & \textbf{85.0} {\tiny $\pm \textbf{0.8}$} & 83.5 {\tiny $\pm 0.5$} \\
Pets & 81.8 {\tiny $\pm 1.5$} & 81.8 {\tiny $\pm 1.7$} & \textbf{82.6} {\tiny $\pm \textbf{1.6}$} \\
Sun397 & 40.9 {\tiny $\pm 0.7$} & \textbf{40.9} {\tiny $\pm \textbf{0.7}$} & 38.1 {\tiny $\pm 1.0$} \\
SVHN & 28.6 {\tiny $\pm 3.8$} & \textbf{31.7} {\tiny $\pm \textbf{3.7}$} & 30.1 {\tiny $\pm 4.5$} \\
DTD & 49.6 {\tiny $\pm 1.5$} & 50.2 {\tiny $\pm 0.9$} & \textbf{50.8} {\tiny $\pm \textbf{1.3}$} \\
\midrule
EuroSAT & 75.8 {\tiny $\pm 1.5$} & 78.1 {\tiny $\pm 1.2$} & \textbf{78.3} {\tiny $\pm \textbf{1.2}$} \\
Resics45 & 62.7 {\tiny $\pm 1.1$} & 64.7 {\tiny $\pm 1.2$} & \textbf{65.8} {\tiny $\pm \textbf{0.7}$} \\
\midrule
Patch Camelyon & 64.7 {\tiny $\pm 5.8$} & \textbf{64.9} {\tiny $\pm \textbf{6.6}$} & 62.9 {\tiny $\pm 5.4$} \\
Retinopathy & \textbf{27.4} {\tiny $\pm \textbf{3.1}$} & 26.0 {\tiny $\pm 2.0$} & 25.2 {\tiny $\pm 2.4$} \\
\midrule
CLEVR-count & \textbf{24.0} {\tiny $\pm \textbf{1.3}$} & 23.4 {\tiny $\pm 1.4$} & 23.2 {\tiny $\pm 0.7$} \\
CLEVR-dist & 23.1 {\tiny $\pm 1.4$} & 23.1 {\tiny $\pm 1.1$} & \textbf{24.0} {\tiny $\pm \textbf{1.3}$} \\
dSprites-loc & 19.5 {\tiny $\pm 1.8$} & \textbf{19.8} {\tiny $\pm \textbf{2.0}$} & 16.7 {\tiny $\pm 5.9$} \\
dSprites-ori & 20.6 {\tiny $\pm 1.6$} & \textbf{26.5} {\tiny $\pm \textbf{0.8}$} & 25.5 {\tiny $\pm 1.4$} \\
SmallNORB-azi & 9.0 {\tiny $\pm 1.0$} & 10.1 {\tiny $\pm 0.6$} & \textbf{10.3} {\tiny $\pm \textbf{0.6}$} \\
SmallNORB-elev & 14.6 {\tiny $\pm 0.9$} & 15.4 {\tiny $\pm 0.7$} & \textbf{15.5} {\tiny $\pm \textbf{0.8}$} \\
DMLab & 23.4 {\tiny $\pm 2.3$} & 23.3 {\tiny $\pm 1.9$} & \textbf{24.8} {\tiny $\pm \textbf{0.9}$} \\
KITTI-dist & \textbf{55.7} {\tiny $\pm \textbf{3.6}$} & 52.7 {\tiny $\pm 3.5$} & 53.2 {\tiny $\pm 1.8$} \\
\midrule
FGVC-Aircraft & 28.7 {\tiny $\pm 0.7$} & 32.6 {\tiny $\pm 0.9$} & \textbf{33.1} {\tiny $\pm \textbf{1.3}$} \\
Cars & 22.7 {\tiny $\pm 0.5$} & \textbf{28.1} {\tiny $\pm \textbf{0.4}$} & 27.2 {\tiny $\pm 0.7$} \\
Letters & 52.2 {\tiny $\pm 2.9$} & 55.9 {\tiny $\pm 2.5$} & \textbf{56.4} {\tiny $\pm \textbf{3.2}$} \\
\midrule
Average acc & 42.7 & \textbf{44.3} & 43.9 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\end{center}

\caption{Accuracy comparison between NCM, LDA, and Linear head using FiLM adaptation (\textbf{A-FiLM} method). The reported results are based on \textbf{5} shots and averaged over 5 runs (mean±std). A pre-trained EfficientNet-B0 is used as a backbone in all cases.}
\label{table:head_comparison_film_5shots}
%\endgroup
\end{table}

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup
\setlength{\tabcolsep}{8.6pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
 \textbf{Dataset} & \textbf{NCM} & \textbf{LDA} &  \textbf{Linear} \\
 \midrule
Caltech101 & 89.9 {\tiny $\pm 0.2$} & \textbf{91.5} {\tiny $\pm \textbf{0.4}$} & 91.1 {\tiny $\pm 0.6$} \\
CIFAR100 & 59.2 {\tiny $\pm 1.7$} & \textbf{62.8} {\tiny $\pm \textbf{1.1}$} & 60.6 {\tiny $\pm 0.5$} \\
Flowers102 & 86.2 {\tiny $\pm 0.5$} & 91.1 {\tiny $\pm 0.3$} & \textbf{91.2} {\tiny $\pm \textbf{0.3}$} \\
Pets & 85.8 {\tiny $\pm 1.0$} & 86.3 {\tiny $\pm 0.8$} & \textbf{86.6} {\tiny $\pm \textbf{0.8}$} \\
Sun397 & 48.5 {\tiny $\pm 0.8$} & \textbf{49.3} {\tiny $\pm \textbf{0.6}$} & 44.8 {\tiny $\pm 1.2$} \\
SVHN & 40.3 {\tiny $\pm 2.5$} & \textbf{45.3} {\tiny $\pm \textbf{3.0}$} & 43.9 {\tiny $\pm 3.3$} \\
DTD & 58.3 {\tiny $\pm 0.8$} & 59.1 {\tiny $\pm 0.8$} & \textbf{59.2} {\tiny $\pm \textbf{1.1}$} \\
\midrule
EuroSAT & 81.9 {\tiny $\pm 1.4$} & \textbf{84.4} {\tiny $\pm \textbf{1.6}$} & 83.5 {\tiny $\pm 0.7$} \\
Resics45 & 70.2 {\tiny $\pm 1.1$} & 73.0 {\tiny $\pm 1.3$} & \textbf{73.5} {\tiny $\pm \textbf{0.7}$} \\
\midrule
Patch Camelyon & \textbf{69.2} {\tiny $\pm \textbf{5.2}$} & 68.5 {\tiny $\pm 6.1$} & 67.1 {\tiny $\pm 4.8$} \\
Retinopathy & 26.7 {\tiny $\pm 1.3$} & \textbf{26.9} {\tiny $\pm \textbf{1.1}$} & 25.6 {\tiny $\pm 1.0$} \\
\midrule
CLEVR-count & \textbf{30.1} {\tiny $\pm \textbf{1.9}$} & 27.6 {\tiny $\pm 1.6$} & 29.2 {\tiny $\pm 1.2$} \\
CLEVR-dist & 25.3 {\tiny $\pm 1.7$} & 26.2 {\tiny $\pm 1.3$} & \textbf{26.5} {\tiny $\pm \textbf{0.7}$} \\
dSprites-loc & \textbf{26.2} {\tiny $\pm \textbf{11.4}$} & 26.1 {\tiny $\pm 10.6$} & 24.2 {\tiny $\pm 14.7$} \\
dSprites-ori & 26.7 {\tiny $\pm 2.4$} & \textbf{34.0} {\tiny $\pm \textbf{2.6}$} & 33.8 {\tiny $\pm 2.4$} \\
SmallNORB-azi & 11.0 {\tiny $\pm 0.8$} & \textbf{11.7} {\tiny $\pm \textbf{1.2}$} & 11.3 {\tiny $\pm 1.4$} \\
SmallNORB-elev & 15.6 {\tiny $\pm 0.7$} & 16.3 {\tiny $\pm 0.4$} & \textbf{16.6} {\tiny $\pm \textbf{0.3}$} \\
DMLab & 27.2 {\tiny $\pm 1.9$} & 26.6 {\tiny $\pm 1.5$} & \textbf{29.3} {\tiny $\pm \textbf{1.7}$} \\
KITTI-dist & \textbf{56.7} {\tiny $\pm \textbf{3.7}$} & 55.4 {\tiny $\pm 3.7$} & 56.2 {\tiny $\pm 4.5$} \\
\midrule
FGVC-Aircraft & 37.5 {\tiny $\pm 0.7$} & 43.3 {\tiny $\pm 1.1$} & \textbf{43.4} {\tiny $\pm \textbf{1.5}$} \\
Cars & 36.3 {\tiny $\pm 0.8$} & \textbf{43.1} {\tiny $\pm \textbf{1.0}$} & 42.1 {\tiny $\pm 1.0$} \\
Letters & 64.0 {\tiny $\pm 1.5$} & 67.5 {\tiny $\pm 1.3$} & \textbf{68.1} {\tiny $\pm \textbf{1.4}$} \\
\midrule
Average acc & 48.8 & \textbf{50.7} & 50.4 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\end{center}
\caption{Accuracy comparison between NCM, LDA, and Linear head using FiLM adaptation (\textbf{A-FiLM} method). The reported results are based on \textbf{10} shots and averaged over 5 runs (mean±std). A pre-trained EfficientNet-B0 is used as a backbone in all cases.}
\label{table:head_comparison_film_10shots}
%\endgroup
\end{table}

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{6.5pt} % Default value: 6pt %\renewcommand{\arraystretch}{.9} 
\begin{center}
%\renewcommand{\arraystretch}{.9}
\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
 \textbf{Dataset} & \textbf{NCM} & \textbf{LDA} &  \textbf{Linear} \\
 \midrule
Caltech101 & 93.4 {\tiny $\pm 0.7$} & \textbf{93.8} {\tiny $\pm \textbf{0.5}$} & 93.5 {\tiny $\pm 1.0$} \\
CIFAR100 & 72.6 {\tiny $\pm 0.7$} & \textbf{73.8} {\tiny $\pm \textbf{0.9}$} & 73.7 {\tiny $\pm 0.5$} \\
Flowers102 & 86.2 {\tiny $\pm 0.5$} & 91.1 {\tiny $\pm 0.3$} & \textbf{91.2} {\tiny $\pm \textbf{0.3}$} \\
Pets & 89.3 {\tiny $\pm 0.6$} & \textbf{89.9} {\tiny $\pm \textbf{0.7}$} & 89.9 {\tiny $\pm 0.7$} \\
Sun397 & 58.5 {\tiny $\pm 0.7$} & 59.7 {\tiny $\pm 0.6$} & \textbf{60.8} {\tiny $\pm \textbf{0.7}$} \\
SVHN & 73.9 {\tiny $\pm 1.1$} & \textbf{77.2} {\tiny $\pm \textbf{0.8}$} & 76.8 {\tiny $\pm 1.0$} \\
DTD & 66.8 {\tiny $\pm 0.3$} & 68.4 {\tiny $\pm 0.2$} & \textbf{68.7} {\tiny $\pm \textbf{0.7}$} \\
\midrule
EuroSAT & 91.0 {\tiny $\pm 0.6$} & 93.0 {\tiny $\pm 0.6$} & \textbf{93.2} {\tiny $\pm \textbf{0.6}$} \\
Resics45 & 81.7 {\tiny $\pm 0.2$} & 83.4 {\tiny $\pm 0.6$} & \textbf{85.3} {\tiny $\pm \textbf{0.6}$} \\
\midrule
Patch Camelyon & \textbf{78.5} {\tiny $\pm \textbf{2.0}$} & 77.9 {\tiny $\pm 2.4$} & 78.1 {\tiny $\pm 2.4$} \\
Retinopathy & 34.2 {\tiny $\pm 1.6$} & \textbf{35.2} {\tiny $\pm \textbf{1.2}$} & 33.5 {\tiny $\pm 1.9$} \\
\midrule
CLEVR-count & \textbf{56.8} {\tiny $\pm \textbf{0.9}$} & 46.6 {\tiny $\pm 1.1$} & 53.1 {\tiny $\pm 1.1$} \\
CLEVR-dist & 40.2 {\tiny $\pm 1.8$} & 38.8 {\tiny $\pm 1.0$} & \textbf{41.2} {\tiny $\pm \textbf{1.5}$} \\
dSprites-loc & 83.6 {\tiny $\pm 5.4$} & \textbf{83.7} {\tiny $\pm \textbf{5.6}$} & 81.6 {\tiny $\pm 5.9$} \\
dSprites-ori & 41.2 {\tiny $\pm 0.8$} & 52.1 {\tiny $\pm 1.3$} & \textbf{53.8} {\tiny $\pm \textbf{1.4}$} \\
SmallNORB-azi & 17.0 {\tiny $\pm 0.8$} & 16.8 {\tiny $\pm 0.8$} & \textbf{17.5} {\tiny $\pm \textbf{1.0}$} \\
SmallNORB-elev & 23.1 {\tiny $\pm 1.2$} & 22.9 {\tiny $\pm 0.5$} & \textbf{24.0} {\tiny $\pm \textbf{0.6}$} \\
DMLab & 35.0 {\tiny $\pm 0.6$} & 34.6 {\tiny $\pm 0.6$} & \textbf{35.8} {\tiny $\pm \textbf{0.4}$} \\
KITTI-dist & \textbf{67.3} {\tiny $\pm \textbf{2.1}$} & 66.8 {\tiny $\pm 3.0$} & 66.5 {\tiny $\pm 2.7$} \\
\midrule
FGVC-Aircraft & 60.6 {\tiny $\pm 0.9$} & 65.1 {\tiny $\pm 0.7$} & \textbf{68.0} {\tiny $\pm \textbf{0.6}$} \\
Cars & 60.9 {\tiny $\pm 0.2$} & 67.9 {\tiny $\pm 0.2$} & \textbf{74.5} {\tiny $\pm \textbf{0.4}$} \\
Letters & 76.7 {\tiny $\pm 0.5$} & 79.7 {\tiny $\pm 0.4$} & \textbf{81.9} {\tiny $\pm \textbf{0.8}$} \\
\midrule
Average acc & 63.1 & 64.5 & \textbf{65.6} \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\end{center}
\caption{Accuracy comparison between NCM, LDA, and Linear head using FiLM adaptation (\textbf{A-FiLM} method). The reported results are based on \textbf{50} shots and averaged over 5 runs (mean±std). A pre-trained EfficientNet-B0 is used as a backbone in all cases.}
\label{table:head_comparison_film_50shots}
%\endgroup
\end{table}

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{6.5pt} % Default value: 6pt %\renewcommand{\arraystretch}{.9} 
\begin{center}
%\renewcommand{\arraystretch}{.9}
\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
 \textbf{Dataset} & \textbf{NCM} & \textbf{LDA} &  \textbf{Linear} \\
 \midrule
Caltech101 & 93.6 {\tiny $\pm 0.4$} & \textbf{94.4} {\tiny $\pm \textbf{0.3}$} & 94.1 {\tiny $\pm 0.6$} \\
CIFAR100 & 77.4 {\tiny $\pm 1.1$} & 78.2 {\tiny $\pm 1.1$} & \textbf{82.1} {\tiny $\pm \textbf{1.1}$} \\
Flowers102 & 88.6 {\tiny $\pm 0.6$} & \textbf{91.2} {\tiny $\pm \textbf{0.4}$} & 90.6 {\tiny $\pm 0.5$} \\
Pets & 90.2 {\tiny $\pm 0.2$} & 90.8 {\tiny $\pm 0.3$} & \textbf{91.0} {\tiny $\pm \textbf{0.4}$} \\
Sun397 & 61.4 {\tiny $\pm 0.5$} & 62.1 {\tiny $\pm 0.3$} & \textbf{63.7} {\tiny $\pm \textbf{0.9}$} \\
SVHN & 92.9 {\tiny $\pm 0.4$} & 93.1 {\tiny $\pm 0.4$} & \textbf{95.1} {\tiny $\pm \textbf{0.4}$} \\
DTD & 64.8 {\tiny $\pm 0.2$} & 66.8 {\tiny $\pm 0.5$} & \textbf{67.6} {\tiny $\pm \textbf{0.6}$} \\
\midrule
EuroSAT & 96.5 {\tiny $\pm 0.3$} & 97.2 {\tiny $\pm 0.1$} & \textbf{98.1} {\tiny $\pm \textbf{0.3}$} \\
Resics45 & 88.0 {\tiny $\pm 0.3$} & 89.4 {\tiny $\pm 0.4$} & \textbf{94.2} {\tiny $\pm \textbf{0.4}$} \\
\midrule
Patch Camelyon & 84.3 {\tiny $\pm 1.5$} & \textbf{85.9} {\tiny $\pm \textbf{1.2}$} & 85.8 {\tiny $\pm 1.6$} \\
Retinopathy & 52.3 {\tiny $\pm 0.7$} & 52.6 {\tiny $\pm 0.8$} & \textbf{59.5} {\tiny $\pm \textbf{0.8}$} \\
\midrule
CLEVR-count & 94.5 {\tiny $\pm 0.2$} & 93.5 {\tiny $\pm 0.7$} & \textbf{95.3} {\tiny $\pm \textbf{0.6}$} \\
CLEVR-dist & 79.3 {\tiny $\pm 1.4$} & 80.1 {\tiny $\pm 2.3$} & \textbf{84.5} {\tiny $\pm \textbf{2.0}$} \\
dSprites-loc & 98.0 {\tiny $\pm 0.5$} & 98.5 {\tiny $\pm 0.6$} & \textbf{99.3} {\tiny $\pm \textbf{0.4}$} \\
dSprites-ori & 69.8 {\tiny $\pm 2.4$} & 80.0 {\tiny $\pm 0.8$} & \textbf{90.7} {\tiny $\pm \textbf{0.8}$} \\
SmallNORB-azi & \textbf{26.1} {\tiny $\pm \textbf{1.2}$} & 24.4 {\tiny $\pm 0.6$} & 23.5 {\tiny $\pm 0.5$} \\
SmallNORB-elev & 47.0 {\tiny $\pm 0.9$} & \textbf{47.9} {\tiny $\pm \textbf{1.2}$} & 47.9 {\tiny $\pm 1.4$} \\
DMLab & 60.2 {\tiny $\pm 0.6$} & 61.3 {\tiny $\pm 0.5$} & \textbf{65.8} {\tiny $\pm \textbf{1.0}$} \\
KITTI-dist & 78.5 {\tiny $\pm 0.9$} & \textbf{80.1} {\tiny $\pm \textbf{1.1}$} & 79.7 {\tiny $\pm 0.4$} \\
\midrule
FGVC-Aircraft & 63.3 {\tiny $\pm 0.2$} & 67.5 {\tiny $\pm 0.4$} & \textbf{71.5} {\tiny $\pm \textbf{0.5}$} \\
Cars & 60.1 {\tiny $\pm 0.1$} & 67.3 {\tiny $\pm 0.3$} & \textbf{73.6} {\tiny $\pm \textbf{0.3}$} \\
Letters & 77.1 {\tiny $\pm 0.3$} & 81.7 {\tiny $\pm 0.4$} & \textbf{85.2} {\tiny $\pm \textbf{0.3}$} \\
\midrule
Average acc & 74.7 & 76.6 & \textbf{79.0} \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\end{center}
\caption{Accuracy comparison between NCM, LDA, and Linear head using FiLM adaptation (\textbf{A-FiLM} method). The reported results are based on the full training dataset and averaged over 5 runs (mean±std). A pre-trained EfficientNet-B0 is used as a backbone in all cases.}
\label{table:head_comparison_film_alldata}
%\endgroup
\end{table}


%%%%%%%%%%%%
% A-Full Body %%%
%%%%%%%%%%%%

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{6.5pt} % Default value: 6pt %\renewcommand{\arraystretch}{.9} 
\begin{center}
%\renewcommand{\arraystretch}{.9}
\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
 \textbf{Dataset} & \textbf{NCM} & \textbf{LDA} &  \textbf{Linear} \\
 \midrule
Caltech101 & 87.1 {\tiny $\pm 0.6$} & \textbf{89.4} {\tiny $\pm \textbf{0.7}$} & 86.1 {\tiny $\pm 0.9$} \\
CIFAR100 & 48.1 {\tiny $\pm 0.7$} & \textbf{49.3} {\tiny $\pm \textbf{1.1}$} & 49.2 {\tiny $\pm 1.0$} \\
Flowers102 & 81.5 {\tiny $\pm 0.8$} & 81.7 {\tiny $\pm 0.6$} & \textbf{83.6} {\tiny $\pm \textbf{0.8}$} \\
Pets & \textbf{80.9} {\tiny $\pm \textbf{1.7}$} & 80.8 {\tiny $\pm 1.7$} & 71.1 {\tiny $\pm 1.2$} \\
Sun397 & 35.5 {\tiny $\pm 0.3$} & 35.2 {\tiny $\pm 0.5$} & \textbf{37.2} {\tiny $\pm \textbf{0.3}$} \\
SVHN & 19.1 {\tiny $\pm 1.5$} & \textbf{19.6} {\tiny $\pm \textbf{1.2}$} & 19.2 {\tiny $\pm 1.8$} \\
DTD & 48.4 {\tiny $\pm 1.3$} & \textbf{49.0} {\tiny $\pm \textbf{1.3}$} & 41.6 {\tiny $\pm 0.8$} \\
\midrule
EuroSAT & 75.4 {\tiny $\pm 4.1$} & 76.7 {\tiny $\pm 2.9$} & \textbf{78.5} {\tiny $\pm \textbf{1.2}$} \\
Resics45 & 61.7 {\tiny $\pm 2.3$} & 62.3 {\tiny $\pm 2.5$} & \textbf{63.5} {\tiny $\pm \textbf{2.5}$} \\
\midrule
Patch Camelyon & 59.2 {\tiny $\pm 4.9$} & 59.4 {\tiny $\pm 4.9$} & \textbf{60.5} {\tiny $\pm \textbf{7.0}$} \\
Retinopathy & 24.6 {\tiny $\pm 2.7$} & 24.5 {\tiny $\pm 2.5$} & \textbf{26.1} {\tiny $\pm \textbf{2.4}$} \\
\midrule
CLEVR-count & 23.9 {\tiny $\pm 2.9$} & 23.5 {\tiny $\pm 3.0$} & \textbf{24.2} {\tiny $\pm \textbf{3.1}$} \\
CLEVR-dist & 25.1 {\tiny $\pm 3.3$} & 25.6 {\tiny $\pm 3.5$} & \textbf{25.6} {\tiny $\pm \textbf{2.4}$} \\
dSprites-loc & 26.1 {\tiny $\pm 2.7$} & \textbf{27.1} {\tiny $\pm \textbf{1.6}$} & 25.5 {\tiny $\pm 3.6$} \\
dSprites-ori & 18.3 {\tiny $\pm 1.6$} & \textbf{19.9} {\tiny $\pm \textbf{1.5}$} & 15.6 {\tiny $\pm 1.9$} \\
SmallNORB-azi & 10.0 {\tiny $\pm 0.7$} & \textbf{10.4} {\tiny $\pm \textbf{0.8}$} & 10.3 {\tiny $\pm 0.9$} \\
SmallNORB-elev & 15.8 {\tiny $\pm 1.1$} & \textbf{16.2} {\tiny $\pm \textbf{1.1}$} & 15.6 {\tiny $\pm 0.8$} \\
DMLab & 21.3 {\tiny $\pm 1.6$} & 22.1 {\tiny $\pm 1.3$} & \textbf{22.6} {\tiny $\pm \textbf{0.9}$} \\
KITTI-dist & 51.1 {\tiny $\pm 2.5$} & \textbf{52.8} {\tiny $\pm \textbf{2.5}$} & 52.1 {\tiny $\pm 2.0$} \\
\midrule
FGVC-Aircraft & 23.8 {\tiny $\pm 0.7$} & 23.6 {\tiny $\pm 0.8$} & \textbf{25.1} {\tiny $\pm \textbf{1.0}$} \\
Cars & 23.1 {\tiny $\pm 0.3$} & 23.5 {\tiny $\pm 0.3$} & \textbf{25.3} {\tiny $\pm \textbf{0.5}$} \\
Letters & 35.5 {\tiny $\pm 3.3$} & 35.7 {\tiny $\pm 3.3$} & \textbf{37.0} {\tiny $\pm \textbf{3.2}$} \\
\midrule
Average acc & 40.7 & \textbf{41.3} & 40.7 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\end{center}
\caption{Accuracy comparison between NCM, LDA, and Linear head using full-body adaptation (\textbf{A-FB} method). The reported results are based on \textbf{5} shots and averaged over 5 runs (mean±std). A pre-trained EfficientNet-B0 is used as a backbone in all cases.}
\label{table:head_comparison_full_5shots}
%\endgroup
\end{table}

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{6.5pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
 \textbf{Dataset} & \textbf{NCM} & \textbf{LDA} &  \textbf{Linear} \\
 \midrule
Caltech101 & 90.4 {\tiny $\pm 0.8$} & \textbf{91.7} {\tiny $\pm \textbf{0.7}$} & 89.3 {\tiny $\pm 0.8$} \\
CIFAR100 & 58.8 {\tiny $\pm 0.4$} & \textbf{59.5} {\tiny $\pm \textbf{0.3}$} & 59.5 {\tiny $\pm 0.8$} \\
Flowers102 & 89.9 {\tiny $\pm 0.6$} & 90.0 {\tiny $\pm 0.5$} & \textbf{91.3} {\tiny $\pm \textbf{0.6}$} \\
Pets & 85.5 {\tiny $\pm 0.9$} & \textbf{85.7} {\tiny $\pm \textbf{0.5}$} & 78.4 {\tiny $\pm 1.7$} \\
Sun397 & 45.2 {\tiny $\pm 0.7$} & 45.0 {\tiny $\pm 0.4$} & \textbf{46.3} {\tiny $\pm \textbf{0.3}$} \\
SVHN & 26.4 {\tiny $\pm 3.4$} & \textbf{27.1} {\tiny $\pm \textbf{3.8}$} & 26.4 {\tiny $\pm 3.6$} \\
DTD & 55.2 {\tiny $\pm 0.8$} & \textbf{56.7} {\tiny $\pm \textbf{1.0}$} & 48.0 {\tiny $\pm 0.8$} \\
\midrule
EuroSAT & 83.9 {\tiny $\pm 1.5$} & 84.9 {\tiny $\pm 1.5$} & \textbf{86.3} {\tiny $\pm \textbf{1.5}$} \\
Resics45 & 72.6 {\tiny $\pm 1.2$} & 72.8 {\tiny $\pm 1.3$} & \textbf{74.3} {\tiny $\pm \textbf{1.1}$} \\
\midrule
Patch Camelyon & 61.3 {\tiny $\pm 4.5$} & 61.2 {\tiny $\pm 4.5$} & \textbf{63.0} {\tiny $\pm \textbf{5.1}$} \\
Retinopathy & 25.1 {\tiny $\pm 4.2$} & 24.6 {\tiny $\pm 3.3$} & \textbf{27.5} {\tiny $\pm \textbf{2.0}$} \\
\midrule
CLEVR-count & 28.0 {\tiny $\pm 1.9$} & 27.7 {\tiny $\pm 2.0$} & \textbf{28.7} {\tiny $\pm \textbf{2.1}$} \\
CLEVR-dist & \textbf{30.1} {\tiny $\pm \textbf{4.1}$} & 30.0 {\tiny $\pm 4.2$} & 29.9 {\tiny $\pm 3.6$} \\
dSprites-loc & 42.9 {\tiny $\pm 2.7$} & \textbf{44.8} {\tiny $\pm \textbf{1.3}$} & 42.2 {\tiny $\pm 3.1$} \\
dSprites-ori & 26.4 {\tiny $\pm 6.5$} & \textbf{29.6} {\tiny $\pm \textbf{6.8}$} & 22.9 {\tiny $\pm 10.4$} \\
SmallNORB-azi & \textbf{12.2} {\tiny $\pm \textbf{0.6}$} & 11.5 {\tiny $\pm 0.8$} & 11.7 {\tiny $\pm 0.6$} \\
SmallNORB-elev & 18.2 {\tiny $\pm 1.3$} & \textbf{18.3} {\tiny $\pm \textbf{1.5}$} & 17.3 {\tiny $\pm 1.1$} \\
DMLab & 25.3 {\tiny $\pm 1.2$} & 25.6 {\tiny $\pm 1.3$} & \textbf{26.1} {\tiny $\pm \textbf{1.1}$} \\
KITTI-dist & 53.5 {\tiny $\pm 2.3$} & \textbf{54.9} {\tiny $\pm \textbf{1.3}$} & 52.2 {\tiny $\pm 2.1$} \\
\midrule
FGVC-Aircraft & 37.4 {\tiny $\pm 0.5$} & 36.7 {\tiny $\pm 0.6$} & \textbf{38.6} {\tiny $\pm \textbf{0.4}$} \\
Cars & 43.8 {\tiny $\pm 0.8$} & 43.5 {\tiny $\pm 0.6$} & \textbf{46.9} {\tiny $\pm \textbf{0.8}$} \\
Letters & 55.8 {\tiny $\pm 1.5$} & 55.2 {\tiny $\pm 1.3$} & \textbf{56.6} {\tiny $\pm \textbf{1.4}$} \\
\midrule
Average acc & 48.5 & \textbf{49.0} & 48.3 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\end{center}
\caption{Accuracy comparison between NCM, LDA, and Linear head using full-body adaptation (\textbf{A-FB} method). The reported results are based on \textbf{10} shots and averaged over 5 runs (mean±std). A pre-trained EfficientNet-B0 is used as a backbone in all cases.}
\label{table:head_comparison_full_10shots}
%\endgroup
\end{table}

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{6.5pt} % Default value: 6pt %\renewcommand{\arraystretch}{.9} 
\begin{center}
%\renewcommand{\arraystretch}{.9}
\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
 \textbf{Dataset} & \textbf{NCM} & \textbf{LDA} &  \textbf{Linear} \\
 \midrule
Caltech101 & 92.8 {\tiny $\pm 0.3$} & \textbf{93.9} {\tiny $\pm \textbf{0.3}$} & 92.6 {\tiny $\pm 0.5$} \\
CIFAR100 & 72.9 {\tiny $\pm 0.9$} & \textbf{73.1} {\tiny $\pm \textbf{0.7}$} & 72.7 {\tiny $\pm 0.8$} \\
Flowers102 & 89.9 {\tiny $\pm 0.6$} & 90.0 {\tiny $\pm 0.5$} & \textbf{91.3} {\tiny $\pm \textbf{0.6}$} \\
Pets & 88.7 {\tiny $\pm 0.5$} & \textbf{89.6} {\tiny $\pm \textbf{0.6}$} & 84.9 {\tiny $\pm 1.1$} \\
Sun397 & 59.9 {\tiny $\pm 0.6$} & 60.4 {\tiny $\pm 0.6$} & \textbf{62.4} {\tiny $\pm \textbf{0.4}$} \\
SVHN & 63.9 {\tiny $\pm 1.5$} & 64.5 {\tiny $\pm 1.3$} & \textbf{64.6} {\tiny $\pm \textbf{1.6}$} \\
DTD & 60.9 {\tiny $\pm 0.3$} & \textbf{64.4} {\tiny $\pm \textbf{0.2}$} & 57.4 {\tiny $\pm 0.7$} \\
\midrule
EuroSAT & 93.8 {\tiny $\pm 0.5$} & \textbf{94.1} {\tiny $\pm \textbf{0.6}$} & 93.9 {\tiny $\pm 1.0$} \\
Resics45 & 87.4 {\tiny $\pm 0.8$} & 87.6 {\tiny $\pm 0.7$} & \textbf{88.0} {\tiny $\pm \textbf{0.8}$} \\
\midrule
Patch Camelyon & 71.6 {\tiny $\pm 1.7$} & 72.2 {\tiny $\pm 1.8$} & \textbf{74.4} {\tiny $\pm \textbf{1.8}$} \\
Retinopathy & 31.1 {\tiny $\pm 3.3$} & 31.3 {\tiny $\pm 2.9$} & \textbf{31.9} {\tiny $\pm \textbf{2.2}$} \\
\midrule
CLEVR-count & \textbf{46.5} {\tiny $\pm \textbf{1.0}$} & 45.2 {\tiny $\pm 1.1$} & 45.4 {\tiny $\pm 1.9$} \\
CLEVR-dist & 44.0 {\tiny $\pm 2.1$} & 44.7 {\tiny $\pm 2.2$} & \textbf{45.7} {\tiny $\pm \textbf{2.2}$} \\
dSprites-loc & 85.3 {\tiny $\pm 4.0$} & \textbf{87.1} {\tiny $\pm \textbf{2.4}$} & 85.2 {\tiny $\pm 3.2$} \\
dSprites-ori & 42.6 {\tiny $\pm 3.2$} & \textbf{44.8} {\tiny $\pm \textbf{2.3}$} & 39.3 {\tiny $\pm 4.7$} \\
SmallNORB-azi & \textbf{19.6} {\tiny $\pm \textbf{0.6}$} & 18.3 {\tiny $\pm 0.7$} & 19.1 {\tiny $\pm 1.1$} \\
SmallNORB-elev & \textbf{31.4} {\tiny $\pm \textbf{1.4}$} & 31.3 {\tiny $\pm 1.7$} & 31.3 {\tiny $\pm 2.1$} \\
DMLab & 32.6 {\tiny $\pm 1.4$} & 32.7 {\tiny $\pm 1.6$} & \textbf{34.0} {\tiny $\pm \textbf{0.9}$} \\
KITTI-dist & 65.8 {\tiny $\pm 2.1$} & \textbf{66.9} {\tiny $\pm \textbf{2.2}$} & 65.8 {\tiny $\pm 1.8$} \\
\midrule
FGVC-Aircraft & 74.2 {\tiny $\pm 0.8$} & 73.5 {\tiny $\pm 0.4$} & \textbf{74.6} {\tiny $\pm \textbf{0.3}$} \\
Cars & 79.3 {\tiny $\pm 0.1$} & 79.4 {\tiny $\pm 0.1$} & \textbf{81.5} {\tiny $\pm \textbf{0.2}$} \\
Letters & 82.1 {\tiny $\pm 0.7$} & 82.3 {\tiny $\pm 0.9$} & \textbf{83.1} {\tiny $\pm \textbf{0.6}$} \\
\midrule
Average acc & 64.4 & \textbf{64.9} & 64.5 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\end{center}
\caption{Accuracy comparison between NCM, LDA, and Linear head using full-body adaptation (\textbf{A-FB} method). The reported results are based on \textbf{50} shots and averaged over 5 runs (mean±std). A pre-trained EfficientNet-B0 is used as a backbone in all cases.}
\label{table:head_comparison_full_50shots}
%\endgroup
\end{table}

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup
\setlength{\tabcolsep}{6.5pt} % Default value: 6pt %\renewcommand{\arraystretch}{.9}
\begin{center}
%\renewcommand{\arraystretch}{.9}
\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
 \textbf{Dataset} & \textbf{NCM} & \textbf{LDA} &  \textbf{Linear} \\
 \midrule
Caltech101 & 94.2 {\tiny $\pm 0.5$} & 94.6 {\tiny $\pm 0.3$} & \textbf{94.8} {\tiny $\pm \textbf{0.3}$} \\
CIFAR100 & 84.2 {\tiny $\pm 1.2$} & 84.3 {\tiny $\pm 0.9$} & \textbf{85.0} {\tiny $\pm \textbf{1.1}$} \\
Flowers102 & 90.3 {\tiny $\pm 0.3$} & 90.3 {\tiny $\pm 0.4$} & \textbf{91.4} {\tiny $\pm \textbf{0.5}$} \\
Pets & 89.7 {\tiny $\pm 0.4$} & 89.5 {\tiny $\pm 0.3$} & \textbf{90.0} {\tiny $\pm \textbf{0.4}$} \\
Sun397 & 65.9 {\tiny $\pm 0.3$} & 66.1 {\tiny $\pm 1.0$} & \textbf{66.7} {\tiny $\pm \textbf{0.4}$} \\
SVHN & \textbf{95.6} {\tiny $\pm \textbf{0.2}$} & 95.3 {\tiny $\pm 0.5$} & 95.5 {\tiny $\pm 0.3$} \\
DTD & 67.6 {\tiny $\pm 0.8$} & 68.1 {\tiny $\pm 0.4$} & \textbf{68.5} {\tiny $\pm \textbf{0.5}$} \\
\midrule
EuroSAT & 98.1 {\tiny $\pm 0.2$} & 98.5 {\tiny $\pm 0.3$} & \textbf{98.6} {\tiny $\pm \textbf{0.2}$} \\
Resics45 & 95.3 {\tiny $\pm 0.1$} & 95.5 {\tiny $\pm 0.2$} & \textbf{95.9} {\tiny $\pm \textbf{0.1}$} \\
\midrule
Patch Camelyon & 81.1 {\tiny $\pm 2.2$} & 85.0 {\tiny $\pm 0.7$} & \textbf{86.5} {\tiny $\pm \textbf{0.9}$} \\
Retinopathy & 55.8 {\tiny $\pm 0.9$} & 56.1 {\tiny $\pm 1.4$} & \textbf{57.7} {\tiny $\pm \textbf{0.7}$} \\
\midrule
CLEVR-count & 98.5 {\tiny $\pm 0.3$} & \textbf{98.7} {\tiny $\pm \textbf{0.3}$} & 98.3 {\tiny $\pm 0.3$} \\
CLEVR-dist & 89.0 {\tiny $\pm 0.6$} & 89.0 {\tiny $\pm 0.6$} & \textbf{89.4} {\tiny $\pm \textbf{1.5}$} \\
dSprites-loc & 99.7 {\tiny $\pm 0.3$} & \textbf{99.8} {\tiny $\pm \textbf{0.1}$} & 99.6 {\tiny $\pm 0.4$} \\
dSprites-ori & 89.2 {\tiny $\pm 1.0$} & \textbf{94.0} {\tiny $\pm \textbf{0.7}$} & 93.0 {\tiny $\pm 1.1$} \\
SmallNORB-azi & \textbf{29.8} {\tiny $\pm \textbf{1.0}$} & 28.7 {\tiny $\pm 0.6$} & 28.9 {\tiny $\pm 0.8$} \\
SmallNORB-elev & 74.3 {\tiny $\pm 4.3$} & \textbf{81.8} {\tiny $\pm \textbf{3.1}$} & 77.2 {\tiny $\pm 4.6$} \\
DMLab & 64.8 {\tiny $\pm 0.6$} & \textbf{65.7} {\tiny $\pm \textbf{0.4}$} & 65.6 {\tiny $\pm 0.7$} \\
KITTI-dist & 78.2 {\tiny $\pm 0.7$} & 82.1 {\tiny $\pm 0.6$} & \textbf{82.3} {\tiny $\pm \textbf{1.1}$} \\
\midrule
FGVC-Aircraft & 76.0 {\tiny $\pm 0.5$} & 75.8 {\tiny $\pm 0.7$} & \textbf{76.7} {\tiny $\pm \textbf{0.8}$} \\
Cars & 79.1 {\tiny $\pm 0.1$} & 78.9 {\tiny $\pm 0.2$} & \textbf{81.3} {\tiny $\pm \textbf{0.2}$} \\
Letters & 86.0 {\tiny $\pm 0.5$} & 85.7 {\tiny $\pm 0.5$} & \textbf{87.2} {\tiny $\pm \textbf{0.3}$} \\
\midrule
Average acc & 81.0 & 82.0 & \textbf{82.3} \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\end{center}
\caption{Accuracy comparison between NCM, LDA, and Linear head using full-body adaptation (\textbf{A-FB} method). The reported results are based on the full training dataset and averaged over 5 runs (mean±std). A pre-trained EfficientNet-B0 is used as a backbone in all cases.}
\label{table:head_comparison_full_alldata}
%\endgroup
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%
% Tables for Resnet18 %%%
%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{.2pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{footnotesize}
%\begin{sc}
\begin{tabular}{l c c c c}
\toprule
 \textbf{Dataset} & \textbf{NA(RN)} & \textbf{FiLM(RN)} &  \textbf{NA(EN)} &  \textbf{FiLM(EN)} \\
 \midrule
Caltech101 & 80.9 {\tiny $\pm 0.7$} & 81.1 {\tiny $\pm 0.7$} & 88.2 {\tiny $\pm 0.8$} & 89.0 {\tiny $\pm 0.6$} \\
CIFAR100 & 40.4 {\tiny $\pm 0.5$} & 42.2 {\tiny $\pm 0.9$} & 42.7 {\tiny $\pm 1.6$} & 51.8 {\tiny $\pm 1.3$} \\
Flowers102 & 72.6 {\tiny $\pm 0.8$} & 79.4 {\tiny $\pm 1.4$} & 76.1 {\tiny $\pm 0.4$} & 85.0 {\tiny $\pm 0.8$} \\
Pets & 76.9 {\tiny $\pm 1.2$} & 74.5 {\tiny $\pm 1.4$} & 82.4 {\tiny $\pm 1.6$} & 81.8 {\tiny $\pm 1.7$} \\
Sun397 & 35.1 {\tiny $\pm 0.9$} & 29.1 {\tiny $\pm 0.7$} & 41.9 {\tiny $\pm 1.0$} & 40.9 {\tiny $\pm 0.7$} \\
SVHN & 20.9 {\tiny $\pm 1.3$} & 28.8 {\tiny $\pm 2.7$} & 16.5 {\tiny $\pm 1.1$} & 31.7 {\tiny $\pm 3.7$} \\
DTD & 43.2 {\tiny $\pm 1.7$} & 42.2 {\tiny $\pm 0.7$} & 48.9 {\tiny $\pm 1.7$} & 50.2 {\tiny $\pm 0.9$} \\
\midrule
EuroSAT & 75.1 {\tiny $\pm 1.9$} & 79.3 {\tiny $\pm 1.2$} & 76.3 {\tiny $\pm 1.8$} & 78.1 {\tiny $\pm 1.2$} \\
Resics45 & 56.8 {\tiny $\pm 1.3$} & 57.0 {\tiny $\pm 1.2$} & 58.8 {\tiny $\pm 1.4$} & 64.7 {\tiny $\pm 1.2$} \\
\midrule
Patch Camelyon & 62.4 {\tiny $\pm 5.5$} & 64.6 {\tiny $\pm 7.2$} & 59.8 {\tiny $\pm 7.2$} & 64.9 {\tiny $\pm 6.6$} \\
Retinopathy & 23.0 {\tiny $\pm 2.5$} & 23.6 {\tiny $\pm 1.7$} & 25.6 {\tiny $\pm 1.6$} & 26.0 {\tiny $\pm 2.0$} \\
\midrule
CLEVR-count & 21.6 {\tiny $\pm 1.7$} & 23.0 {\tiny $\pm 1.3$} & 23.1 {\tiny $\pm 1.1$} & 23.4 {\tiny $\pm 1.4$} \\
CLEVR-dist & 22.9 {\tiny $\pm 1.4$} & 24.4 {\tiny $\pm 1.3$} & 24.5 {\tiny $\pm 2.3$} & 23.1 {\tiny $\pm 1.1$} \\
dSprites-loc & 13.0 {\tiny $\pm 1.0$} & 15.9 {\tiny $\pm 1.0$} & 8.5 {\tiny $\pm 0.6$} & 19.8 {\tiny $\pm 2.0$} \\
dSprites-ori & 14.4 {\tiny $\pm 0.6$} & 22.9 {\tiny $\pm 0.8$} & 16.2 {\tiny $\pm 0.8$} & 26.5 {\tiny $\pm 0.8$} \\
SmallNORB-azi & 9.4 {\tiny $\pm 0.8$} & 9.8 {\tiny $\pm 1.1$} & 9.3 {\tiny $\pm 0.8$} & 10.1 {\tiny $\pm 0.6$} \\
SmallNORB-elev & 15.8 {\tiny $\pm 0.7$} & 15.9 {\tiny $\pm 0.7$} & 15.1 {\tiny $\pm 0.6$} & 15.4 {\tiny $\pm 0.7$} \\
DMLab & 21.6 {\tiny $\pm 1.5$} & 22.1 {\tiny $\pm 1.8$} & 22.1 {\tiny $\pm 1.3$} & 23.3 {\tiny $\pm 1.9$} \\
KITTI-dist & 54.3 {\tiny $\pm 2.8$} & 54.0 {\tiny $\pm 2.5$} & 51.4 {\tiny $\pm 2.7$} & 52.7 {\tiny $\pm 3.5$} \\
\midrule
FGVC-Aircraft & 19.1 {\tiny $\pm 0.9$} & 20.3 {\tiny $\pm 0.7$} & 22.1 {\tiny $\pm 1.0$} & 32.6 {\tiny $\pm 0.9$} \\
Cars & 14.8 {\tiny $\pm 0.5$} & 13.9 {\tiny $\pm 0.3$} & 22.6 {\tiny $\pm 0.6$} & 28.1 {\tiny $\pm 0.4$} \\
Letters & 32.4 {\tiny $\pm 1.9$} & 45.5 {\tiny $\pm 2.4$} & 36.1 {\tiny $\pm 2.1$} & 55.9 {\tiny $\pm 2.5$} \\
\midrule
Average acc & 37.6 & 39.5 & 39.5 & 44.3 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{footnotesize}
\end{center}
\caption{Accuracy comparison between NA and FiLM methods in offline mode using either a pre-trained ResNet-18 (RN) or a pre-trained EfficientNet-B0 (EN) backbone. We use an LDA head. The reported results are based on \textbf{5} shots. Results are averaged over 5 runs (mean±std).}
\label{table:resnet18_vs_effnet_film_5shots}
%\endgroup
\end{table}

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{.2pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{footnotesize}
%\begin{sc}
\begin{tabular}{l c c c c}
\toprule
 \textbf{Dataset} & \textbf{NA(RN)} & \textbf{FiLM(RN)} &  \textbf{NA(EN)} &  \textbf{FiLM(EN)} \\
 \midrule
Caltech101 & 85.0 {\tiny $\pm 0.6$} & 86.6 {\tiny $\pm 0.6$} & 90.0 {\tiny $\pm 0.8$} & 91.5 {\tiny $\pm 0.4$} \\
CIFAR100 & 48.5 {\tiny $\pm 0.4$} & 52.2 {\tiny $\pm 0.8$} & 50.1 {\tiny $\pm 1.5$} & 62.8 {\tiny $\pm 1.1$} \\
Flowers102 & 81.2 {\tiny $\pm 0.7$} & 87.1 {\tiny $\pm 0.2$} & 83.9 {\tiny $\pm 0.3$} & 91.1 {\tiny $\pm 0.3$} \\
Pets & 82.3 {\tiny $\pm 0.7$} & 80.5 {\tiny $\pm 1.1$} & 86.4 {\tiny $\pm 0.7$} & 86.3 {\tiny $\pm 0.8$} \\
Sun397 & 42.8 {\tiny $\pm 0.9$} & 36.3 {\tiny $\pm 1.0$} & 49.0 {\tiny $\pm 1.3$} & 49.3 {\tiny $\pm 0.6$} \\
SVHN & 24.6 {\tiny $\pm 1.7$} & 35.8 {\tiny $\pm 4.1$} & 19.4 {\tiny $\pm 2.9$} & 45.3 {\tiny $\pm 3.0$} \\
DTD & 51.9 {\tiny $\pm 0.9$} & 50.5 {\tiny $\pm 0.6$} & 55.6 {\tiny $\pm 0.6$} & 59.1 {\tiny $\pm 0.8$} \\
\midrule
EuroSAT & 82.0 {\tiny $\pm 0.7$} & 85.4 {\tiny $\pm 0.9$} & 82.1 {\tiny $\pm 0.9$} & 84.4 {\tiny $\pm 1.6$} \\
Resics45 & 64.8 {\tiny $\pm 1.5$} & 67.2 {\tiny $\pm 2.0$} & 65.5 {\tiny $\pm 1.1$} & 73.0 {\tiny $\pm 1.3$} \\
\midrule
Patch Camelyon & 66.9 {\tiny $\pm 3.7$} & 68.8 {\tiny $\pm 3.7$} & 66.5 {\tiny $\pm 3.7$} & 68.5 {\tiny $\pm 6.1$} \\
Retinopathy & 25.5 {\tiny $\pm 1.3$} & 25.8 {\tiny $\pm 3.7$} & 27.1 {\tiny $\pm 2.2$} & 26.9 {\tiny $\pm 1.1$} \\
\midrule
CLEVR-count & 23.8 {\tiny $\pm 0.7$} & 25.6 {\tiny $\pm 2.0$} & 25.7 {\tiny $\pm 0.6$} & 27.6 {\tiny $\pm 1.6$} \\
CLEVR-dist & 24.9 {\tiny $\pm 0.7$} & 27.2 {\tiny $\pm 1.2$} & 26.3 {\tiny $\pm 1.1$} & 26.2 {\tiny $\pm 1.3$} \\
dSprites-loc & 14.7 {\tiny $\pm 0.4$} & 25.4 {\tiny $\pm 1.5$} & 8.7 {\tiny $\pm 0.3$} & 26.1 {\tiny $\pm 10.6$} \\
dSprites-ori & 16.6 {\tiny $\pm 0.9$} & 29.7 {\tiny $\pm 1.3$} & 18.2 {\tiny $\pm 0.7$} & 34.0 {\tiny $\pm 2.6$} \\
SmallNORB-azi & 10.4 {\tiny $\pm 0.9$} & 12.2 {\tiny $\pm 1.1$} & 9.5 {\tiny $\pm 1.1$} & 11.7 {\tiny $\pm 1.2$} \\
SmallNORB-elev & 16.9 {\tiny $\pm 0.8$} & 17.2 {\tiny $\pm 1.1$} & 16.5 {\tiny $\pm 1.1$} & 16.3 {\tiny $\pm 0.4$} \\
DMLab & 24.6 {\tiny $\pm 1.8$} & 25.6 {\tiny $\pm 1.4$} & 25.7 {\tiny $\pm 1.2$} & 26.6 {\tiny $\pm 1.5$} \\
KITTI-dist & 53.0 {\tiny $\pm 2.0$} & 55.9 {\tiny $\pm 3.5$} & 52.9 {\tiny $\pm 1.5$} & 55.4 {\tiny $\pm 3.7$} \\
\midrule
FGVC-Aircraft & 25.9 {\tiny $\pm 0.8$} & 29.5 {\tiny $\pm 0.8$} & 28.5 {\tiny $\pm 0.4$} & 43.3 {\tiny $\pm 1.1$} \\
Cars & 21.5 {\tiny $\pm 0.5$} & 24.0 {\tiny $\pm 0.2$} & 30.4 {\tiny $\pm 0.5$} & 43.1 {\tiny $\pm 1.0$} \\
Letters & 41.5 {\tiny $\pm 1.2$} & 62.7 {\tiny $\pm 1.9$} & 45.6 {\tiny $\pm 0.8$} & 67.5 {\tiny $\pm 1.3$} \\
\midrule
Average acc & 42.2 & 46.0 & 43.8 & 50.7 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{footnotesize}
\end{center}
\caption{Accuracy comparison between NA and FiLM methods in offline mode using either a pre-trained ResNet-18 (RN) or a pre-trained EfficientNet-B0 (EN) backbone. We use an LDA head. The reported results are based on \textbf{10} shots. Results are averaged over 5 runs (mean±std).}
\label{table:resnet18_vs_effnet_film_10shots}
%\endgroup
\end{table}

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{.2pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}

\begin{footnotesize}
%\begin{sc}
\begin{tabular}{l c c c c}
\toprule
 \textbf{Dataset} & \textbf{NA(RN)} & \textbf{FiLM(RN)} &  \textbf{NA(EN)} &  \textbf{FiLM(EN)} \\
 \midrule
Caltech101 & 88.0 {\tiny $\pm 0.3$} & 87.7 {\tiny $\pm 0.7$} & 91.9 {\tiny $\pm 0.5$} & 93.8 {\tiny $\pm 0.5$} \\
CIFAR100 & 58.2 {\tiny $\pm 0.9$} & 61.8 {\tiny $\pm 0.7$} & 57.4 {\tiny $\pm 1.0$} & 73.8 {\tiny $\pm 0.9$} \\
Flowers102 & 81.2 {\tiny $\pm 0.7$} & 87.1 {\tiny $\pm 0.2$} & 83.9 {\tiny $\pm 0.3$} & 91.1 {\tiny $\pm 0.3$} \\
Pets & 86.9 {\tiny $\pm 0.4$} & 86.8 {\tiny $\pm 0.6$} & 89.5 {\tiny $\pm 0.4$} & 89.9 {\tiny $\pm 0.7$} \\
Sun397 & 51.4 {\tiny $\pm 1.3$} & 47.8 {\tiny $\pm 0.9$} & 55.9 {\tiny $\pm 1.0$} & 59.7 {\tiny $\pm 0.6$} \\
SVHN & 37.3 {\tiny $\pm 0.8$} & 74.5 {\tiny $\pm 0.9$} & 28.3 {\tiny $\pm 1.1$} & 77.2 {\tiny $\pm 0.8$} \\
DTD & 59.9 {\tiny $\pm 0.0$} & 59.3 {\tiny $\pm 0.6$} & 61.1 {\tiny $\pm 0.0$} & 68.4 {\tiny $\pm 0.2$} \\
\midrule
EuroSAT & 88.3 {\tiny $\pm 0.5$} & 92.6 {\tiny $\pm 0.5$} & 87.7 {\tiny $\pm 0.9$} & 93.0 {\tiny $\pm 0.6$} \\
Resics45 & 73.7 {\tiny $\pm 1.1$} & 77.5 {\tiny $\pm 1.1$} & 73.5 {\tiny $\pm 0.9$} & 83.4 {\tiny $\pm 0.6$} \\
\midrule
Patch Camelyon & 76.3 {\tiny $\pm 0.9$} & 77.4 {\tiny $\pm 1.1$} & 76.2 {\tiny $\pm 1.1$} & 77.9 {\tiny $\pm 2.4$} \\
Retinopathy & 29.2 {\tiny $\pm 2.1$} & 30.4 {\tiny $\pm 1.0$} & 32.9 {\tiny $\pm 2.2$} & 35.2 {\tiny $\pm 1.2$} \\
\midrule
CLEVR-count & 29.5 {\tiny $\pm 1.3$} & 39.9 {\tiny $\pm 1.4$} & 30.1 {\tiny $\pm 1.0$} & 46.6 {\tiny $\pm 1.1$} \\
CLEVR-dist & 31.7 {\tiny $\pm 0.8$} & 45.3 {\tiny $\pm 2.6$} & 32.2 {\tiny $\pm 1.1$} & 38.8 {\tiny $\pm 1.0$} \\
dSprites-loc & 21.8 {\tiny $\pm 0.6$} & 70.2 {\tiny $\pm 2.0$} & 11.9 {\tiny $\pm 0.4$} & 83.7 {\tiny $\pm 5.6$} \\
dSprites-ori & 20.8 {\tiny $\pm 0.4$} & 52.1 {\tiny $\pm 1.5$} & 20.1 {\tiny $\pm 1.1$} & 52.1 {\tiny $\pm 1.3$} \\
SmallNORB-azi & 13.9 {\tiny $\pm 0.5$} & 16.4 {\tiny $\pm 0.7$} & 12.3 {\tiny $\pm 0.8$} & 16.8 {\tiny $\pm 0.8$} \\
SmallNORB-elev & 21.4 {\tiny $\pm 1.0$} & 25.1 {\tiny $\pm 0.6$} & 19.1 {\tiny $\pm 0.7$} & 22.9 {\tiny $\pm 0.5$} \\
DMLab & 29.7 {\tiny $\pm 0.5$} & 31.6 {\tiny $\pm 0.9$} & 30.6 {\tiny $\pm 0.3$} & 34.6 {\tiny $\pm 0.6$} \\
KITTI-dist & 62.0 {\tiny $\pm 3.5$} & 66.0 {\tiny $\pm 2.7$} & 61.4 {\tiny $\pm 2.3$} & 66.8 {\tiny $\pm 3.0$} \\
\midrule
FGVC-Aircraft & 38.9 {\tiny $\pm 0.5$} & 53.1 {\tiny $\pm 0.3$} & 41.0 {\tiny $\pm 0.7$} & 65.1 {\tiny $\pm 0.7$} \\
Cars & 34.4 {\tiny $\pm 0.0$} & 49.5 {\tiny $\pm 0.2$} & 43.3 {\tiny $\pm 0.0$} & 67.9 {\tiny $\pm 0.2$} \\
Letters & 56.1 {\tiny $\pm 1.2$} & 77.7 {\tiny $\pm 1.3$} & 57.6 {\tiny $\pm 0.8$} & 79.7 {\tiny $\pm 0.4$} \\
\midrule
Average acc & 49.6 & 59.5 & 49.9 & 64.5 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{footnotesize}
\end{center}
\caption{Accuracy comparison between NA and FiLM methods in offline mode using either a pre-trained ResNet-18 (RN) or a pre-trained EfficientNet-B0 (EN) backbone. We use an LDA head. The reported results are based on \textbf{50} shots. Results are averaged over 5 runs (mean±std).}
\label{table:resnet18_vs_effnet_film_50shots}
%\endgroup
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tables for meta-learning %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{1.pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{footnotesize}
%\begin{sc}
\begin{tabular}{l c c c c}
\toprule
 \textbf{Dataset} & \textbf{NA} & \textbf{Meta-Learn} &  \textbf{FiLM} &  \textbf{Full-body} \\
 \midrule
Caltech101 & 88.2 {\tiny $\pm 0.8$} & 86.7 {\tiny $\pm 0.9$} & 89.0 {\tiny $\pm 0.6$} & \textbf{89.4} {\tiny $\pm \textbf{0.7}$} \\
CIFAR100 & 42.7 {\tiny $\pm 1.6$} & 42.1 {\tiny $\pm 1.3$} & \textbf{51.8} {\tiny $\pm \textbf{1.3}$} & 49.3 {\tiny $\pm 1.1$} \\
Flowers102 & 76.1 {\tiny $\pm 0.4$} & 78.2 {\tiny $\pm 0.4$} & \textbf{85.0} {\tiny $\pm \textbf{0.8}$} & 81.7 {\tiny $\pm 0.6$} \\
Pets & 82.4 {\tiny $\pm 1.6$} & \textbf{83.8} {\tiny $\pm \textbf{1.0}$} & 81.8 {\tiny $\pm 1.7$} & 80.8 {\tiny $\pm 1.7$} \\
Sun397 & \textbf{41.9} {\tiny $\pm \textbf{1.0}$} & 40.2 {\tiny $\pm 0.6$} & 40.9 {\tiny $\pm 0.7$} & 35.2 {\tiny $\pm 0.5$} \\
SVHN & 16.5 {\tiny $\pm 1.1$} & 27.4 {\tiny $\pm 3.6$} & \textbf{31.7} {\tiny $\pm \textbf{3.7}$} & 19.6 {\tiny $\pm 1.2$} \\
DTD & 48.9 {\tiny $\pm 1.7$} & \textbf{50.5} {\tiny $\pm \textbf{1.7}$} & 50.2 {\tiny $\pm 0.9$} & 49.0 {\tiny $\pm 1.3$} \\
\midrule
EuroSAT & 76.3 {\tiny $\pm 1.8$} & 75.2 {\tiny $\pm 1.5$} & \textbf{78.1} {\tiny $\pm \textbf{1.2}$} & 76.7 {\tiny $\pm 2.9$} \\
Resics45 & 58.8 {\tiny $\pm 1.4$} & 62.7 {\tiny $\pm 1.0$} & \textbf{64.7} {\tiny $\pm \textbf{1.2}$} & 62.3 {\tiny $\pm 2.5$} \\
\midrule
Patch Camelyon & 59.8 {\tiny $\pm 7.2$} & 64.2 {\tiny $\pm 7.3$} & \textbf{64.9} {\tiny $\pm \textbf{6.6}$} & 59.4 {\tiny $\pm 4.9$} \\
Retinopathy & 25.6 {\tiny $\pm 1.6$} & \textbf{26.8} {\tiny $\pm \textbf{3.5}$} & 26.0 {\tiny $\pm 2.0$} & 24.5 {\tiny $\pm 2.5$} \\
\midrule
CLEVR-count & 23.1 {\tiny $\pm 1.1$} & 22.6 {\tiny $\pm 0.8$} & 23.4 {\tiny $\pm 1.4$} & \textbf{23.5} {\tiny $\pm \textbf{3.0}$} \\
CLEVR-dist & 24.5 {\tiny $\pm 2.3$} & 23.8 {\tiny $\pm 1.1$} & 23.1 {\tiny $\pm 1.1$} & \textbf{25.6} {\tiny $\pm \textbf{3.5}$} \\
dSprites-loc & 8.5 {\tiny $\pm 0.6$} & 8.9 {\tiny $\pm 0.5$} & 19.8 {\tiny $\pm 2.0$} & \textbf{27.1} {\tiny $\pm \textbf{1.6}$} \\
dSprites-ori & 16.2 {\tiny $\pm 0.8$} & 19.2 {\tiny $\pm 0.7$} & \textbf{26.5} {\tiny $\pm \textbf{0.8}$} & 19.9 {\tiny $\pm 1.5$} \\
SmallNORB-azi & 9.3 {\tiny $\pm 0.8$} & 8.7 {\tiny $\pm 1.0$} & 10.1 {\tiny $\pm 0.6$} & \textbf{10.4} {\tiny $\pm \textbf{0.8}$} \\
SmallNORB-elev & 15.1 {\tiny $\pm 0.6$} & 15.4 {\tiny $\pm 0.5$} & 15.4 {\tiny $\pm 0.7$} & \textbf{16.2} {\tiny $\pm \textbf{1.1}$} \\
DMLab & 22.1 {\tiny $\pm 1.3$} & \textbf{24.9} {\tiny $\pm \textbf{1.5}$} & 23.3 {\tiny $\pm 1.9$} & 22.1 {\tiny $\pm 1.3$} \\
KITTI-dist & 51.4 {\tiny $\pm 2.7$} & \textbf{55.0} {\tiny $\pm \textbf{1.5}$} & 52.7 {\tiny $\pm 3.5$} & 52.8 {\tiny $\pm 2.5$} \\
\midrule
FGVC-Aircraft & 22.1 {\tiny $\pm 1.0$} & 31.9 {\tiny $\pm 0.6$} & \textbf{32.6} {\tiny $\pm \textbf{0.9}$} & 23.6 {\tiny $\pm 0.8$} \\
Cars & 22.6 {\tiny $\pm 0.6$} & 22.8 {\tiny $\pm 0.4$} & \textbf{28.1} {\tiny $\pm \textbf{0.4}$} & 23.5 {\tiny $\pm 0.3$} \\
Letters & 36.1 {\tiny $\pm 2.1$} & 46.5 {\tiny $\pm 3.2$} & \textbf{55.9} {\tiny $\pm \textbf{2.5}$} & 35.7 {\tiny $\pm 3.3$} \\
\midrule
Average acc & 39.5 & 41.7 & \textbf{44.3} & 41.3 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{footnotesize}
\end{center}
\caption{Accuracy comparison between different adaptation methods in offline mode using a pre-trained EfficientNet-B0 backbone. We use an LDA head. The reported results are based on \textbf{5} shots and averaged over 5 runs (mean±std).}
\label{table:meta_effenet_5shots}
%\endgroup
\end{table}

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{1.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{footnotesize}
%\begin{sc}
\begin{tabular}{l c c c c}
\toprule
 \textbf{Dataset} & \textbf{NA} & \textbf{Meta-Learn} &  \textbf{FiLM} &  \textbf{Full-body} \\
 \midrule
Caltech101 & 90.0 {\tiny $\pm 0.8$} & 89.1 {\tiny $\pm 0.3$} & 91.5 {\tiny $\pm 0.4$} & \textbf{91.7} {\tiny $\pm \textbf{0.7}$} \\
CIFAR100 & 50.1 {\tiny $\pm 1.5$} & 50.1 {\tiny $\pm 1.2$} & \textbf{62.8} {\tiny $\pm \textbf{1.1}$} & 59.5 {\tiny $\pm 0.3$} \\
Flowers102 & 83.9 {\tiny $\pm 0.3$} & 84.4 {\tiny $\pm 0.3$} & \textbf{91.1} {\tiny $\pm \textbf{0.3}$} & 90.0 {\tiny $\pm 0.5$} \\
Pets & 86.4 {\tiny $\pm 0.7$} & \textbf{86.8} {\tiny $\pm \textbf{0.2}$} & 86.3 {\tiny $\pm 0.8$} & 85.7 {\tiny $\pm 0.5$} \\
Sun397 & 49.0 {\tiny $\pm 1.3$} & 46.3 {\tiny $\pm 0.9$} & \textbf{49.3} {\tiny $\pm \textbf{0.6}$} & 45.0 {\tiny $\pm 0.4$} \\
SVHN & 19.4 {\tiny $\pm 2.9$} & 33.0 {\tiny $\pm 2.2$} & \textbf{45.3} {\tiny $\pm \textbf{3.0}$} & 27.1 {\tiny $\pm 3.8$} \\
DTD & 55.6 {\tiny $\pm 0.6$} & 57.7 {\tiny $\pm 1.4$} & \textbf{59.1} {\tiny $\pm \textbf{0.8}$} & 56.7 {\tiny $\pm 1.0$} \\
\midrule
EuroSAT & 82.1 {\tiny $\pm 0.9$} & 81.2 {\tiny $\pm 0.7$} & 84.4 {\tiny $\pm 1.6$} & \textbf{84.9} {\tiny $\pm \textbf{1.5}$} \\
Resics45 & 65.5 {\tiny $\pm 1.1$} & 68.4 {\tiny $\pm 1.2$} & \textbf{73.0} {\tiny $\pm \textbf{1.3}$} & 72.8 {\tiny $\pm 1.3$} \\
\midrule
Patch Camelyon & 66.5 {\tiny $\pm 3.7$} & 67.5 {\tiny $\pm 5.5$} & \textbf{68.5} {\tiny $\pm \textbf{6.1}$} & 61.2 {\tiny $\pm 4.5$} \\
Retinopathy & \textbf{27.1} {\tiny $\pm \textbf{2.2}$} & 26.9 {\tiny $\pm 0.4$} & 26.9 {\tiny $\pm 1.1$} & 24.6 {\tiny $\pm 3.3$} \\
\midrule
CLEVR-count & 25.7 {\tiny $\pm 0.6$} & 24.3 {\tiny $\pm 1.1$} & 27.6 {\tiny $\pm 1.6$} & \textbf{27.7} {\tiny $\pm \textbf{2.0}$} \\
CLEVR-dist & 26.3 {\tiny $\pm 1.1$} & 25.5 {\tiny $\pm 0.8$} & 26.2 {\tiny $\pm 1.3$} & \textbf{30.0} {\tiny $\pm \textbf{4.2}$} \\
dSprites-loc & 8.7 {\tiny $\pm 0.3$} & 8.9 {\tiny $\pm 0.4$} & 26.1 {\tiny $\pm 10.6$} & \textbf{44.8} {\tiny $\pm \textbf{1.3}$} \\
dSprites-ori & 18.2 {\tiny $\pm 0.7$} & 20.4 {\tiny $\pm 1.2$} & \textbf{34.0} {\tiny $\pm \textbf{2.6}$} & 29.6 {\tiny $\pm 6.8$} \\
SmallNORB-azi & 9.5 {\tiny $\pm 1.1$} & 10.5 {\tiny $\pm 0.2$} & \textbf{11.7} {\tiny $\pm \textbf{1.2}$} & 11.5 {\tiny $\pm 0.8$} \\
SmallNORB-elev & 16.5 {\tiny $\pm 1.1$} & 15.8 {\tiny $\pm 0.6$} & 16.3 {\tiny $\pm 0.4$} & \textbf{18.3} {\tiny $\pm \textbf{1.5}$} \\
DMLab & 25.7 {\tiny $\pm 1.2$} & \textbf{27.8} {\tiny $\pm \textbf{1.7}$} & 26.6 {\tiny $\pm 1.5$} & 25.6 {\tiny $\pm 1.3$} \\
KITTI-dist & 52.9 {\tiny $\pm 1.5$} & \textbf{56.4} {\tiny $\pm \textbf{1.8}$} & 55.4 {\tiny $\pm 3.7$} & 54.9 {\tiny $\pm 1.3$} \\
\midrule
FGVC-Aircraft & 28.5 {\tiny $\pm 0.4$} & 39.0 {\tiny $\pm 0.8$} & \textbf{43.3} {\tiny $\pm \textbf{1.1}$} & 36.7 {\tiny $\pm 0.6$} \\
Cars & 30.4 {\tiny $\pm 0.5$} & 29.8 {\tiny $\pm 0.1$} & 43.1 {\tiny $\pm 1.0$} & \textbf{43.5} {\tiny $\pm \textbf{0.6}$} \\
Letters & 45.6 {\tiny $\pm 0.8$} & 54.5 {\tiny $\pm 1.5$} & \textbf{67.5} {\tiny $\pm \textbf{1.3}$} & 55.2 {\tiny $\pm 1.3$} \\
\midrule
Average acc & 43.8 & 45.7 & \textbf{50.7} & 49.0 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{footnotesize}
\end{center}
\caption{Accuracy comparison between different adaptation methods in offline mode using a pre-trained EfficientNet-B0 backbone. We use an LDA head. The reported results are based on \textbf{10} shots and averaged over 5 runs (mean±std).}
\label{table:meta_effenet_10shots}
%\endgroup
\end{table}

\begin{table}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{1.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{footnotesize}
%\begin{sc}
\begin{tabular}{l c c c c}
\toprule
 \textbf{Dataset} & \textbf{NA} & \textbf{Meta-Learn} &  \textbf{FiLM} &  \textbf{Full-body} \\
 \midrule
Caltech101 & 91.9 {\tiny $\pm 0.5$} & 91.0 {\tiny $\pm 0.4$} & 93.8 {\tiny $\pm 0.5$} & \textbf{93.9} {\tiny $\pm \textbf{0.3}$} \\
CIFAR100 & 57.4 {\tiny $\pm 1.0$} & 58.0 {\tiny $\pm 0.9$} & \textbf{73.8} {\tiny $\pm \textbf{0.9}$} & 73.1 {\tiny $\pm 0.7$} \\
Flowers102 & 83.9 {\tiny $\pm 0.3$} & 84.4 {\tiny $\pm 0.3$} & \textbf{91.1} {\tiny $\pm \textbf{0.3}$} & 90.0 {\tiny $\pm 0.5$} \\
Pets & 89.5 {\tiny $\pm 0.4$} & 89.6 {\tiny $\pm 0.3$} & \textbf{89.9} {\tiny $\pm \textbf{0.7}$} & 89.6 {\tiny $\pm 0.6$} \\
Sun397 & 55.9 {\tiny $\pm 1.0$} & 53.7 {\tiny $\pm 0.8$} & 59.7 {\tiny $\pm 0.6$} & \textbf{60.4} {\tiny $\pm \textbf{0.6}$} \\
SVHN & 28.3 {\tiny $\pm 1.1$} & 47.3 {\tiny $\pm 1.4$} & \textbf{77.2} {\tiny $\pm \textbf{0.8}$} & 64.5 {\tiny $\pm 1.3$} \\
DTD & 61.1 {\tiny $\pm 0.0$} & 63.8 {\tiny $\pm 0.0$} & \textbf{68.4} {\tiny $\pm \textbf{0.2}$} & 64.4 {\tiny $\pm 0.2$} \\
\midrule
EuroSAT & 87.7 {\tiny $\pm 0.9$} & 85.7 {\tiny $\pm 0.6$} & 93.0 {\tiny $\pm 0.6$} & \textbf{94.1} {\tiny $\pm \textbf{0.6}$} \\
Resics45 & 73.5 {\tiny $\pm 0.9$} & 75.5 {\tiny $\pm 1.0$} & 83.4 {\tiny $\pm 0.6$} & \textbf{87.6} {\tiny $\pm \textbf{0.7}$} \\
\midrule
Patch Camelyon & 76.2 {\tiny $\pm 1.1$} & \textbf{78.0} {\tiny $\pm \textbf{1.4}$} & 77.9 {\tiny $\pm 2.4$} & 72.2 {\tiny $\pm 1.8$} \\
Retinopathy & 32.9 {\tiny $\pm 2.2$} & 31.6 {\tiny $\pm 1.2$} & \textbf{35.2} {\tiny $\pm \textbf{1.2}$} & 31.3 {\tiny $\pm 2.9$} \\
\midrule
CLEVR-count & 30.1 {\tiny $\pm 1.0$} & 28.7 {\tiny $\pm 1.1$} & \textbf{46.6} {\tiny $\pm \textbf{1.1}$} & 45.2 {\tiny $\pm 1.1$} \\
CLEVR-dist & 32.2 {\tiny $\pm 1.1$} & 30.5 {\tiny $\pm 1.7$} & 38.8 {\tiny $\pm 1.0$} & \textbf{44.7} {\tiny $\pm \textbf{2.2}$} \\
dSprites-loc & 11.9 {\tiny $\pm 0.4$} & 12.2 {\tiny $\pm 0.5$} & 83.7 {\tiny $\pm 5.6$} & \textbf{87.1} {\tiny $\pm \textbf{2.4}$} \\
dSprites-ori & 20.1 {\tiny $\pm 1.1$} & 24.7 {\tiny $\pm 1.9$} & \textbf{52.1} {\tiny $\pm \textbf{1.3}$} & 44.8 {\tiny $\pm 2.3$} \\
SmallNORB-azi & 12.3 {\tiny $\pm 0.8$} & 12.4 {\tiny $\pm 0.5$} & 16.8 {\tiny $\pm 0.8$} & \textbf{18.3} {\tiny $\pm \textbf{0.7}$} \\
SmallNORB-elev & 19.1 {\tiny $\pm 0.7$} & 18.9 {\tiny $\pm 1.0$} & 22.9 {\tiny $\pm 0.5$} & \textbf{31.3} {\tiny $\pm \textbf{1.7}$} \\
DMLab & 30.6 {\tiny $\pm 0.3$} & 32.6 {\tiny $\pm 0.8$} & \textbf{34.6} {\tiny $\pm \textbf{0.6}$} & 32.7 {\tiny $\pm 1.6$} \\
KITTI-dist & 61.4 {\tiny $\pm 2.3$} & 62.6 {\tiny $\pm 2.0$} & 66.8 {\tiny $\pm 3.0$} & \textbf{66.9} {\tiny $\pm \textbf{2.2}$} \\
\midrule
FGVC-Aircraft & 41.0 {\tiny $\pm 0.7$} & 50.9 {\tiny $\pm 0.7$} & 65.1 {\tiny $\pm 0.7$} & \textbf{73.5} {\tiny $\pm \textbf{0.4}$} \\
Cars & 43.3 {\tiny $\pm 0.0$} & 40.1 {\tiny $\pm 0.0$} & 67.9 {\tiny $\pm 0.2$} & \textbf{79.4} {\tiny $\pm \textbf{0.1}$} \\
Letters & 57.6 {\tiny $\pm 0.8$} & 64.2 {\tiny $\pm 0.6$} & 79.7 {\tiny $\pm 0.4$} & \textbf{82.3} {\tiny $\pm \textbf{0.9}$} \\
\midrule
Average acc & 49.9 & 51.7 & 64.5 & \textbf{64.9} \\
\bottomrule
\end{tabular}
%\end{sc}
\end{footnotesize}
\end{center}
\caption{Accuracy comparison between different adaptation methods in offline mode using a pre-trained EfficientNet-B0 backbone. We use an LDA head. The reported results are based on \textbf{50} shots and averaged over 5 runs (mean±std).}
\label{table:meta_effenet_50shots}
%\endgroup
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tables with detailed acc per session %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%
% High-shot %%%
%%%%%%%%%%%%%%%

% CIFAR100
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{9.8pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{normalsize}
%\begin{sc}
\begin{tabular}{l c c c c c c c c c c}
\toprule
\multirow{2}{*}{Method} &  \multicolumn{10}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){2-11} 
        &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} & \textbf{6} &  \textbf{7} & \textbf{8} & \textbf{9} & \textbf{10}\\
 \midrule
NA & 93.2 & 87.1 & 81.9 & 80.2 & 76.8 & 74.3 & 72.8 & 70.6 & 70.1 & 68.2\\
\hdashline
E-EWC+SDC & \textbf{97.2} & 70.5 & 63.6 & 46.4 & 40.2 & 40.7 & 38.8 & 35.5 & 33.9 & 32.4 \\
FACT & 96.6 & 48.2 & 32.8 & 24.2 & 19.3 & 16.4 & 13.9 & 12.5 & 11.3 & 10.2 \\
ALICE & 96.6  &  80.2  & 73.7 & 69.4  & 64.8  & 61.7 &  58.1 & 55.7 &  54.3 &  52.4 \\
FSA & 96.0 & 86.3 & 80.5 & 77.7 & 74.2 & 70.9 & 68.2 & 65.8 & 64.2 & 62.8 \\
FSA-LL & 96.4 &  84.9 &  79.1 &  75.4 &  71.6 &  68.5 &  66.4 &  64.1 &  62.7 &  60.5 \\
FSA-FiLM & 96.4 & \textbf{90.4} & \textbf{86.8} & \textbf{84.7} & \textbf{82.0} & \textbf{79.8} & \textbf{78.2} & \textbf{76.1} & \textbf{75.7} & \textbf{73.8} \\
\midrule
GDumb-1k & 94.17 & 86.2 & 81.0 & 76.1 & 70.8 & 64.3 & 62.0 & 59.7 & 57.1 & 54.5 \\
GDumb-5k & 97.0 & 91.6 & 88.1 & 85.1 & 81.8 & 77.9 & 75.6 & 73.2 & 71.8 & 69.3 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{normalsize}
\end{center}
\caption{Detailed accuracy for each incremental session on \textbf{CIFAR100} under the \textbf{high-shot CIL} setting. The best results across all methods per session are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k is used as a backbone for all methods.}
\label{table:high_shot_cifar100}
%\endgroup
\end{table*}

% CORE50
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{11.8pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{normalsize}
%\begin{sc}
\begin{tabular}{l c c c c c c c c c}
\toprule
\multirow{2}{*}{Method} &  \multicolumn{9}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){2-10} 
        &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} & \textbf{6} &  \textbf{7} & \textbf{8} & \textbf{9}\\
 \midrule
NA & 96.3 & 94.5 & 91.6 & 89.9 & 87.7 & 84.8 & 82.0 & 82.8 & 82.6\\
\hdashline
E-EWC+SDC & 98.7 & 89.7 & 72.6 & 65.4 & 43.0 & 40.8 & 35.1 & 26.6 & 21.7 \\
FACT & 98.5 & 66.9 & 50.5 & 40.4 & 33.8 & 28.9 & 25.3 & 23.9 & 22.0 \\
ALICE & 98.1 & 92.2 & 87.0 & 84.4 & 80.4 & 76.4 & 72.6 & 73.4 & 72.8 \\
FSA & 98.0 & 93.6 & 89.8 & 88.8 & 86.8 & 84.4 & 81.7 & 82.3 & 82.8 \\
FSA-LL & 97.8 & 92.1 & 87.3 & 85.6 & 83.6 & 81.4 & 78.5 & 78.6 & 79.0 \\
FSA-FiLM & \textbf{98.5} & \textbf{96.0} & \textbf{92.6} & \textbf{90.6} & \textbf{89.5} & \textbf{87.3} & \textbf{85.0} & \textbf{85.6} & \textbf{85.4} \\
\midrule
GDumb-1k & 96.9 &  94.3 &  91.9 &  90.6 &  88.2 & 85.4 & 80.7 & 82.3 & 82.4 \\
GDumb-5k & 97.5 & 96.7 & 94.6 & 92.7 & 91.8 & 90.3 & 89.0 & 90.0 & 90.0 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{normalsize}
\end{center}
\caption{Detailed accuracy for each incremental session on \textbf{CORE50} under the \textbf{high-shot CIL} setting. The best results across all methods per session are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k is used as a backbone for all methods.}
\label{table:high_shot_core50}
%\endgroup
\end{table*}

% SVHN
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{12.8pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{normalsize}
%\begin{sc}
\begin{tabular}{l c c c c c }
\toprule
\multirow{2}{*}{Method} &  \multicolumn{5}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){2-6} 
        &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} \\
 \midrule
NA & 81.5 & 61.5 & 48.5 & 42.5 & 39.9\\
\hdashline
E-EWC+SDC & 99.0 & 55.5 & 48.1 & 44.7 & 39.5 \\
FACT & \textbf{99.3} & 63.5 & 47.4 & 38.7 & 33.8 \\
ALICE & 99.3 & 73.5 &  56.4 &  49.9 &  46.1 \\
FSA & 97.2 & 86.4 & 78.2 & 73.0 & 71.3 \\
FSA-LL & 96.7 & 82.7 & 72.6 & 67.4 & 64.6 \\
FSA-FiLM & 99.1 & \textbf{89.0} & \textbf{81.7} & \textbf{77.6} & \textbf{75.9} \\
\midrule
GDumb-1k  & 97.4 &  91.7 &  87.3 &  83.8 & 78.3 \\
GDumb-5k & 98.6 & 97.3 & 95.8 & 93.7 & 93.2 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{normalsize}
\end{center}
%\endgroup
\caption{Detailed accuracy for each incremental session on \textbf{SVHN} under the \textbf{high-shot CIL} setting. The best results across all methods per session are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k is used as a backbone for all methods.}
\label{table:high_shot_svhn}
\end{table*}

% dSprites-loc
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{12.8pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{normalsize}
%\begin{sc}
\begin{tabular}{l c c c c c c c }
\toprule
\multirow{2}{*}{Method} &  \multicolumn{5}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){2-8} 
        &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} & \textbf{6} & \textbf{7} \\
 \midrule
NA & 44.9 & 37.4 & 31.6 & 27.1 & 23.8 & 21.5 & 20.6 \\
\hdashline
E-EWC+SDC & 99.5 & 58.1 & 29.9 & 33.0 & 19.4 & 21.7 & 18.6 \\
FACT & \textbf{100.0} &  16.6 &  12.7 &  10.1 &  8.4 &  7.2 &  6.4 \\
ALICE & \textbf{100.0} & 92.6 & 77.6 &  69.6 & 65.6 &  69.8 &  68.3 \\
FSA & \textbf{100.0} & \textbf{95.4} & \textbf{92.3} & \textbf{87.7} & \textbf{89.9} &  \textbf{90.7} & \textbf{91.5} \\
FSA-LL & 99.8 &  94.0 &  93.9 &  90.5 &  91.5 &  91.4 &  91.3 \\
FSA-FiLM & 99.6 &  89.6 &  84.6 &  78.7 &  77.5 &   77.0 &  76.9 \\
\midrule
GDumb-1k  & 91.2 &  85.5 &  85.6  & 83.8 &  76.3 &  78.1 &   79.5 \\
GDumb-5k & 99.4 &  99.5 &  99.6 &  98.5 &  99.4 &  98.4 &  99.4 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{normalsize}
\end{center}
%\endgroup
\caption{Detailed accuracy for each incremental session on \textbf{dSprites-loc} under the \textbf{high-shot CIL} setting. The best results across all methods per session are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k is used as a backbone for all methods.}
\label{table:high_shot_dspritesloc}
\end{table*}

% FGVC-Airicraft
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{9.8pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{normalsize}
%\begin{sc}
\begin{tabular}{l c c c c c c c c c c}
\toprule
\multirow{2}{*}{Method} &  \multicolumn{10}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){2-11} 
        &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} & \textbf{6} &  \textbf{7} & \textbf{8} & \textbf{9} & \textbf{10}\\
 \midrule
NA & 42.0 & 38.0 & 29.9 & 37.0 & 43.9 & 41.3 & 40.7 & 42.4 & 41.2 & 41.2\\
\hdashline
E-EWC-SDC & 58.0 & 35.3 & 27.3 & 27.7 & 27.4 & 28.2 & 23.5 & 25.4 & 25.7 & 25.6\\
FACT & 58.7 & 30.6 & 24.9 & 21.4 & 19.1 & 19.0 & 17.6 & 16.9 & 15.5 & 14.7 \\
ALICE & \textbf{61.3} & 43.5 & 36.7 &  39.5 & 41.5 & 41.8 & 41.0 & 41.6 & 40.0 & 39.8 \\
FSA & 54.2 & 44.4 & 39.7 & 45.9 & 52.2 & 49.6 & 48.9 & 51.4 & 51.1 & 50.8 \\
FSA-LL & 58.0 & 40.5 & 37.0 & 41.6 & 44.3 & 44.9 & 44.9 & 46.1 & 45.1 & 45.4 \\
FSA-FiLM & 52.9 & \textbf{46.2} & \textbf{44.7} & \textbf{50.3} & \textbf{53.3} & \textbf{55.0} & \textbf{54.5} & \textbf{56.3} & \textbf{55.5} & \textbf{55.9} \\
\midrule
GDumb-1k & 59.8 & 47.3 & 42.6 & 46.5 & 51.8 & 43.7 & 43.4 & 43.0 & 39.2 & 38.4 \\
GDumb-5k & 58.6 & 43.0 & 36.9 & 40.1 & 41.0 & 36.1 & 30.3 & 30.3 & 29.5 & 25.3 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{normalsize}   
\end{center}
\caption{Detailed accuracy for each incremental session on \textbf{FGVC-Aircraft} under the \textbf{high-shot CIL} setting. The best results across all methods per session are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k is used as a backbone for all methods.}
\label{table:high_shot_fgvcaircraft}
%\endgroup
\end{table*}

% Stanford Cars
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{9.8pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{normalsize}
%\begin{sc}
\begin{tabular}{l c c c c c c c c c c}
\toprule
\multirow{2}{*}{Method} &  \multicolumn{10}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){2-11} 
        &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} & \textbf{6} &  \textbf{7} & \textbf{8} & \textbf{9} & \textbf{10}\\
 \midrule
NA & 72.7 & 49.9 & 49.9 & 46.4 & 47.1 & 47.2 & 44.5 & 44.7 & 44.6 & 43.3 \\
\hdashline
E-EWC+SDC & 80.2 & 47.3 & 38.7 & 37.2 & 34.8 & 33.5 & 31.0 & 31.6 & 31.2 & 30.0 \\
FACT & 79.8 & 2.9 & 1.9 & 1.4 & 1.1 & 0.9 & 0.8 & 0.7 & 0.6 & 0.6 \\
ALICE & 82.7 & 52.9 & 49.6 & 45.1 & 42.8 & 41.1 & 39.0 & 38.8 & 38.1 & 36.4 \\
FSA & 79.3 & 55.0 & 55.9 & 54.0 & 53.3 & 52.7 & 51.5 & 51.5 & 51.4 & 50.3 \\
FSA-LL & \textbf{81.2} & 49.3 & 50.5 & 49.9 & 49.0 & 46.9 & 46.8 & 46.9 & 46.6 & 45.7 \\
FSA-FiLM & 80.1 & \textbf{59.5} & \textbf{60.0} & \textbf{59.4} & \textbf{58.9} & \textbf{58.2} & \textbf{56.8} & \textbf{57.3} & \textbf{56.7} & \textbf{55.9} \\
\midrule
GDumb-1k & 81.5 & 59.9 & 54.0 & 47.3 & 40.5 & 33.9 & 32.7 & 27.6 & 22.8 & 18.1 \\
GDumb-5k & 82.1 & 65.8 & 59.0 & 51.8 & 46.7 & 38.0 & 37.6 & 32.3 & 28.7 & 24.2 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{normalsize}    
\end{center}
\caption{Detailed accuracy for each incremental session on \textbf{Cars} under the \textbf{high-shot CIL} setting. The best results across all methods per session are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k is used as a backbone for all methods.}
\label{table:high_shot_cars}
%\endgroup
\end{table*}


% Letters
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{8.8pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{normalsize}
%\begin{sc}
\begin{tabular}{l c c c c c c c c c c c}
\toprule
\multirow{2}{*}{Method} &  \multicolumn{10}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){2-11} 
        &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} & \textbf{6} &  \textbf{7} & \textbf{8} & \textbf{9} & \textbf{10} & \textbf{11}\\
 \midrule
NA & 90.12 & 84.3 & 82.4 & 80.1 & 78.7 & 78.0 & 76.0 & 75.3 & 72.8 & 71.6 & 68.4 \\
\hdashline
E-EWC+SDC & 99.9 & 83.4 & 64.5 & 59.9 & 47.8 & 54.1 & 42.6 & 40.4 & 31.1 & 30.0 & 33.6 \\
FACT & 99.9 & 69.9 & 53.9 & 43.4 & 36.3 & 32.7 & 29.3 & 27.0 & 24.4 & 22.4 & 20.9 \\
ALICE & \textbf{99.9} & 96.1 & 93.4 & 89.5 & 88.7 & 87.9 & 85.8 & 83.7 & 81.1 & 79.3 & 75.7 \\
FSA & 99.8 &  96.4 & 94.6 &  91.3 & 90.3  & 89.6 & 87.9 & 86.3 & 83.4 & 82.0 & 78.4 \\
FSA-LL & 99.8 & 95.9 & 94.0 & 90.4 & 89.0 & 88.3 & 86.3 & 85.3 & 82.4 & 81.0 & 77.2  \\
FSA-FiLM & 99.6 & \textbf{96.0} & \textbf{94.4} &  \textbf{92.0}  & \textbf{91.1} & \textbf{90.6} & \textbf{88.5} & \textbf{87.7} &  \textbf{85.0} &  \textbf{83.4} & \textbf{79.7} \\
\midrule
GDumb-1k & 96.0 & 92.2 & 89.4 & 86.7 & 85.7 & 83.9 &  81.1 &  80.3 & 76.2 & 75.2 & 70.1 \\
GDumb-5k & 99.4 & 98.3 & 97.2 & 95.2 & 94.6 & 94.3 & 92.2 & 91.3 & 88.5 & 86.9 & 82.6\\
\bottomrule
\end{tabular}
%\end{sc}
\end{normalsize}    
\end{center}
\caption{Detailed accuracy for each incremental session on \textbf{Letters} under the \textbf{high-shot CIL} setting. The best results across all methods per session are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k is used as a backbone for all methods.}
\label{table:high_shot_letters}
%\endgroup
\end{table*}

%%%%%%%%%%%%%%%
% Few-shot+ %%%
%%%%%%%%%%%%%%%

% CIFAR100
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{8.5pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{normalsize}

%\begin{sc}
\begin{tabular}{l c c c c c c c c c c}
\toprule
\multirow{2}{*}{Method} & \multirow{2}{*}{Backbone} & \multicolumn{9}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){3-11} 
     &   &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} & \textbf{6} &  \textbf{7} & \textbf{8} & \textbf{9}\\
 \midrule
Decoupled-Cos* &  \multirow{4}{*}{RN-20} & 74.6 & 67.4 & 63.6 & 59.6 & 56.1 & 53.8 & 51.7 & 49.7 & 47.7 \\
CEC* &  & 73.1 & 68.9 & 65.3 & 61.2 & 58.1 & 55.6 & 53.2 & 51.3 & 49.1 \\
FACT* & & 74.6 & 72.1 & 67.6 & 63.5 & 61.4 & 58.4 & 56.3 & 54.2 & 52.1 \\
FSA & & 75.1 & 71.2 & 67.5 & 63.3 & 60.0 & 57.6 & 55.5 & 54.2 & 52.0 \\
\hdashline
NA &  \multirow{5}{*}{RN-18} & 68.9 & 65.4 & 62.4 & 58.7 & 57.2 & 54.7 & 53.3 & 51.9 & 50.4 \\
FACT &  & 75.8 & 71.0 & 66.3 & 62.5 & 59.1 & 56.3 & 54.1 & 51.8 & 49.5 \\
ALICE$^{\dagger}$ & & 79.0 & 70.5 & 67.1 & 63.4 & 61.2 & 59.2 & 58.1 & 56.3 & 54.1 \\
FSA-FiLM  &  & 73.0 & 69.7 & 66.3 & 63.2 & 61.9 & 59.3 & 58.3 & 57.2 & 55.2 \\
FSA &  & 82.0 & 78.2 & 74.8 & 70.22 & 68.7 & 66.2 & 65.3 & 63.8 & 61.4 \\
\hdashline
NA & \multirow{5}{*}{EN-B0} & 74.4 & 70.4 & 67.4 & 63.4 & 62.4 & 59.8 & 58.4 & 56.9 & 55.2 \\
FACT & & 86.4 & 80.6 & 75.6 & 71.1 & 67.6 & 64.4 & 61.8 & 59.2 & 56.5 \\
ALICE & & 87.7 & 83.3 & 78.7 & 74.4 & 72.1 & 69.6 & 67.4 & 65.4 & 62.7 \\
FSA-FiLM & & 79.6 & 75.6 & 72.9 & 68.8 & 68.2 & 65.4 & 64.9 & 63.9 & 61.8 \\
FSA & & \textbf{87.6} & \textbf{83.5} & \textbf{79.7} & \textbf{75.4} & \textbf{73.8} & \textbf{70.9} & \textbf{70.2} & \textbf{68.8} & \textbf{66.1}  \\
\bottomrule
\end{tabular}
%\end{sc}
\end{normalsize}   
\end{center}
\caption{Detailed accuracy for each incremental session on \textbf{CIFAR100} under the \textbf{few-shot+ CIL} setting. Asterisk (*) indicates that the reported results of a method are from \cite{zhou2022forward} and $\dagger$ that the reported results of a method are from \cite{peng2022few}. We use three different backbones, EfficientNet-B0 (EN-B0) and ResNet-18/20 (RN-18/20); EN-B0 and RN-18 are pre-trained on Imagenet-1k.}
\label{table:few_shot_plus_cifar100}
%\endgroup
\end{table*}

% CUB200
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{5.8pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{normalsize}
%\begin{sc}
\begin{tabular}{l c c c c c c c c c c c c}
\toprule
\multirow{2}{*}{Method} & \multirow{2}{*}{Backbone} & \multicolumn{11}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){3-13} 
     &   &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} & \textbf{6} &  \textbf{7} & \textbf{8} & \textbf{9} & \textbf{10} & \textbf{11} \\
 \midrule
NA &  \multirow{7}{*}{RN-18} & 70.7 &  66.7 & 63.4 & 59.0 & 58.2 & 56.4 & 54.0 & 52.3 & 50.5 & 50.5 & 50.0 \\
Decoupled-Cos* &  & 75.5 & 71.0 & 66.5 & 61.2 & 60.9 & 56.9 & 55.4 & 53.5 & 51.9 & 50.9 & 49.3 \\
CEC* &  & 75.9 & 71.9 & 68.5 & 63.5 & 62.4 & 58.3 & 57.7 & 55.8 & 54.8 & 53.5 & 52.3 \\
FACT* &  & 75.9 & 73.2 & 70.8 & 66.1 & 65.6 & 62.2 & 61.7 & 59.8 & 58.4 & 57.9 & 56.9 \\
ALICE$^{\dagger}$ &  & 77.4&  72.7&  70.6&  67.2&  65.9&  63.4&  62.9&  61.9&  60.5&  60.6&  60.1 \\
FSA-FiLM  &  & 72.7 & 68.2 & 64.9 & 60.8 & 60.2 & 58.1 & 55.4 & 54.8 & 53.5 & 53.4 & 52.7 \\
FSA &  & 76.1 & 72.6 & 69.6 & 65.0 & 64.6 & 62.3 & 61.6 & 59.6 & 58.2 & 58.2 & 57.6  \\
\hdashline
NA & \multirow{5}{*}{EN-B0} & 78.6 & 75.8 & 73.4 & 69.5 & 69.2 & 67.3 & 66.5 & 64.3 & 62.7 & 63.1 & 63.2 \\
FACT & & \textbf{82.0} & \textbf{77.5} & 74.4 & 70.0 & 69.3 & 66.6 & 66.2 & 64.7 & \textbf{64.0} & 63.3 & 62.9 \\
ALICE & & 81.6 & 77.1 & \textbf{75.1} & \textbf{71.9} & \textbf{70.5} & \textbf{67.8} & \textbf{66.8} & \textbf{65.7} & \textbf{64.1} & \textbf{64.0} & \textbf{63.5} \\
FSA-FiLM & & 79.0 & 75.3 & 72.7 & 69.5 & 68.3 & 66.5 & 65.3 & 64.1 & 62.8 & 62.9 & 62.9 \\
FSA & & 80.2 & 77.1 & 74.2 & 69.3 & 69.3 & 66.9 & 66.4 & 64.8 & 63.6 & 63.8 & 63.4 \\
\bottomrule
\end{tabular}
%\end{sc}
\end{normalsize}
    
\end{center}
\caption{Detailed accuracy for each incremental session on \textbf{CUB200} under the \textbf{few-shot+ CIL} setting. Asterisk (*) indicates that the reported results of a method are from \cite{zhou2022forward} and $\dagger$ that the reported results of a method are from \cite{peng2022few}. We use two different backbones, EfficientNet-B0 (EN-B0) and ResNet-18 (RN-18); EN-B0 and RN-18 are pre-trained on Imagenet-1k.}
\label{table:few_shot_plus_cub200}
%\endgroup
\end{table*}

%%%%%%%%%%%%%%
% Few-shot %%%
%%%%%%%%%%%%%%

% CIFAR100
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{3.2pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{footnotesize}
\begin{tabular}{l c c c c c c c c c}
\toprule
\multirow{2}{*}{Method} & \multicolumn{9}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){2-10} 
   &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} & \textbf{6} &  \textbf{7} & \textbf{8} & \textbf{9}\\
 \midrule
NA & 80.2 {\footnotesize $ \pm $ 0.9} & 76.2 {\footnotesize $ \pm $ 0.7} & 72.4 {\footnotesize $ \pm $ 1.5} & 68.7 {\footnotesize $ \pm $ 1.5} & 65.2 {\footnotesize $ \pm $ 1.4} & 63.5 {\footnotesize $ \pm $ 1.3} & 60.8 {\footnotesize $ \pm $ 1.3} & 59.5 {\footnotesize $ \pm $ 1.9} & 57.4 {\footnotesize $ \pm $ 1.0}\\
\hdashline
GDumb & 83.9 {\footnotesize $ \pm $ 1.4} & 80.1 {\footnotesize $ \pm $ 0.5} & 77.6 {\footnotesize $ \pm $ 1.6} & 71.7 {\footnotesize $ \pm $ 2.2} & 67.5 {\footnotesize $ \pm $ 1.8} & 64.0 {\footnotesize $ \pm $ 1.5} & 59.4 {\footnotesize $ \pm $ 1.2} & 58.6 {\footnotesize $ \pm $ 1.9} & 55.7 {\footnotesize $ \pm $ 1.0}\\
\hdashline
FACT & 83.0 {\footnotesize $ \pm $ 1.2} & 54.5 {\footnotesize $ \pm $ 1.4} & 40.7 {\footnotesize $ \pm $ 1.0} & 32.6 {\footnotesize $ \pm $ 1.0} & 27.6 {\footnotesize $ \pm $ 0.9} & 23.8 {\footnotesize $ \pm $ 0.7} & 20.8 {\footnotesize $ \pm $ 0.5} & 18.7 {\footnotesize $ \pm $ 0.4} & 16.8 {\footnotesize $ \pm $ 0.3} \\
FSA & 82.7 {\footnotesize $ \pm $ 2.1} & 75.4 {\footnotesize $ \pm $ 1.7} & 72.5 {\footnotesize $ \pm $ 1.8} & 69.5 {\footnotesize $ \pm $ 1.6} & 66.8 {\footnotesize $ \pm $ 1.8} & 64.5 {\footnotesize $ \pm $ 1.4} & 63.1 {\footnotesize $ \pm $ 1.5} & 62.7 {\footnotesize $ \pm $ 1.5} & 60.3 {\footnotesize $ \pm $ 1.3} \\
FSA-FiLM & \underline{\textbf{89.2} {\footnotesize $ \pm $ \textbf{0.9}}} & \underline{\textbf{85.8} {\footnotesize $ \pm $ \textbf{1.3}}} & \underline{\textbf{84.3} {\footnotesize $ \pm $ \textbf{1.3}}} & \underline{\textbf{81.0} {\footnotesize $ \pm $ \textbf{1.3}}} & \underline{\textbf{77.9} {\footnotesize $ \pm $ \textbf{1.7}}} & \underline{\textbf{75.9} {\footnotesize $ \pm $ \textbf{1.0}}} & \underline{\textbf{74.3} {\footnotesize $ \pm $ \textbf{1.4}}} & \underline{\textbf{74.2} {\footnotesize $ \pm $ \textbf{1.1}}} & \underline{\textbf{70.9} {\footnotesize $ \pm $ \textbf{1.0}}} \\
\bottomrule
\end{tabular}
\end{footnotesize}
\end{center}
%\endgroup

\caption{Detailed accuracy for each incremental session on \textbf{CIFAR100} under the \textbf{few-shot CIL}  setting. GDumb is the only
memory-based method used for comparisons; we use a buffer size equal to the first session’s number of images $N_1$. The best results across
all methods are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k
is used as a backbone for all methods.}
\label{table:few_shot_cifar100}
\end{table*}

% SVHN
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{9.5pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{normalsize}
%\begin{sc}
\begin{tabular}{l c c c c c}
\toprule
\multirow{2}{*}{Method} & \multicolumn{5}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){2-6} 
   &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} \\
 \midrule
NA & 73.5 {\tiny $ \pm $ 4.6} & 53.3 {\tiny $ \pm $ 3.7} & 37.3 {\tiny $ \pm $ 1.8} & 33.6 {\tiny $ \pm $ 1.5} & 28.3 {\tiny $ \pm $ 1.1} \\
\hdashline
GDumb & 78.2 {\tiny $ \pm $ 4.9} & 46.7 {\tiny $ \pm $ 5.1} & 35.2 {\tiny $ \pm $ 1.6} & 23.3 {\tiny $ \pm $ 3.8} & 21.0 {\tiny $ \pm $ 2.1}\\
\hdashline
FACT & 71.3 {\tiny $ \pm $ 1.0} & 46.6 {\tiny $ \pm $ 3.5} & 34.0 {\tiny $ \pm $ 1.9} & 27.7 {\tiny $ \pm $ 2.5} & 24.1 {\tiny $ \pm $ 2.0} \\
FSA & 70.7 {\tiny $ \pm $ 2.9} & 50.8 {\tiny $ \pm $ 3.9} & 38.4 {\tiny $ \pm $ 3.2} & 35.7 {\tiny $ \pm $ 1.6} & 32.9 {\tiny $ \pm $ 1.0} \\
FSA-FiLM & \underline{\textbf{90.7} {\tiny $ \pm $ \textbf{1.8}}} & \underline{\textbf{70.4} {\tiny $ \pm $ \textbf{1.4}}} & \underline{\textbf{60.5} {\tiny $ \pm $ \textbf{1.5}}} & \underline{\textbf{55.5} {\tiny $ \pm $ \textbf{2.3}}} & \underline{\textbf{51.3} {\tiny $ \pm $ \textbf{2.1}}} \\
\bottomrule
\end{tabular}
%\end{sc}
\end{normalsize}
\end{center}
\caption{Detailed accuracy for each incremental session on \textbf{SVHN} under the \textbf{few-shot CIL}  setting. GDumb is the only
memory-based method used for comparisons; we use a buffer size equal to the first session’s number of images $N_1$. The best results across
all methods are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k
is used as a backbone for all methods.}
\label{table:few_shot_svhn}
%\endgroup
\end{table*}

% dSprites-loc
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{7.8pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
%\begin{sc}
\begin{tabular}{l c c c c c c c c}
\toprule
\multirow{2}{*}{Method} & \multicolumn{7}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){2-8} 
   &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} &  \textbf{6} & \textbf{7} \\
 \midrule
NA & 35.7 {\footnotesize $ \pm $ 1.4} & 26.4 {\footnotesize $ \pm $ 1.7} & 22.1 {\footnotesize $ \pm $ 1.7} & 18.1 {\footnotesize $ \pm $ 1.2} & 15.4 {\footnotesize $ \pm $ 0.8} & 13.5 {\footnotesize $ \pm $ 0.7} & 11.9 {\footnotesize $ \pm $ 0.4}\\
\hdashline
GDumb & 36.4 {\footnotesize $ \pm $ 7.9} & 29.9 {\footnotesize $ \pm $ 6.3} & 20.3 {\footnotesize $ \pm $ 3.6} & 22.1 {\footnotesize $ \pm $ 5.5} & 13.1 {\footnotesize $ \pm $ 2.1} & 11.7 {\footnotesize $ \pm $ 3.2} & 16.4 {\footnotesize $ \pm $ 2.6}\\
\hdashline
FACT & 32.6 {\footnotesize $ \pm $ 1.4} & 22.7 {\footnotesize $ \pm $ 2.2} & 18.4 {\footnotesize $ \pm $ 2.1} & 14.4 {\footnotesize $ \pm $ 1.9} & 12.4 {\footnotesize $ \pm $ 1.5} & 11.9 {\footnotesize $ \pm $ 1.6} & 11.7 {\footnotesize $ \pm $ 1.7} \\
FSA & 57.4 {\footnotesize $ \pm $ 2.3} & 44.8 {\footnotesize $ \pm $ 2.8} & 39.3 {\footnotesize $ \pm $ 1.6} & 34.8 {\footnotesize $ \pm $ 2.1} & 32.9 {\footnotesize $ \pm $ 1.9} & 33.2 {\footnotesize $ \pm $ 2.6} & 33.7 {\footnotesize $ \pm $ 1.7} \\
FSA-FiLM & \underline{\textbf{62.7} {\footnotesize $ \pm $ \textbf{2.1}}} & \underline{\textbf{50.2} {\footnotesize $ \pm $ \textbf{2.4}}} & \underline{\textbf{46.9} {\footnotesize $ \pm $ \textbf{2.3}}} & \underline{\textbf{40.1} {\footnotesize $ \pm $ \textbf{2.2}}} & \underline{\textbf{37.3} {\footnotesize $ \pm $ \textbf{2.5}}} & \underline{\textbf{36.1} {\footnotesize $ \pm $ \textbf{2.2}}} & \underline{\textbf{35.7} {\footnotesize $ \pm $ \textbf{2.1}}} \\
\bottomrule
\end{tabular}
%\end{sc}
\end{center}
\caption{Detailed accuracy for each incremental session on \textbf{dSprites-position} under the \textbf{few-shot CIL}  setting. GDumb is the only
memory-based method used for comparisons; we use a buffer size equal to the first session’s number of images $N_1$. The best results across
all methods are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k
is used as a backbone for all methods.}
\label{table:few_shot_dsprites}
%\endgroup
\end{table*}

% FGVC-Aircraft
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{2.7pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{small}
\begin{tabular}{l c c c c c c c c c}
\toprule
\multirow{2}{*}{Method} & \multicolumn{9}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){2-10} 
   &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} & \textbf{6} &  \textbf{7} & \textbf{8} & \textbf{9}\\
 \midrule
NA & 35.5 {\footnotesize $ \pm $ 0.9} & 28.7 {\footnotesize $ \pm $ 0.7} & 36.4 {\footnotesize $ \pm $ 0.8} & 42.8 {\footnotesize $ \pm $ 0.4} & 40.0 {\footnotesize $ \pm $ 0.4} & 39.4 {\footnotesize $ \pm $ 0.6} & 41.4 {\footnotesize $ \pm $ 0.7} & 40.3 {\footnotesize $ \pm $ 0.9} & 41.0 {\footnotesize $ \pm $ 0.7}\\
\hdashline
GDumb & \textbf{51.1} {\footnotesize $ \pm $ \textbf{1.7}} & \textbf{45.4} {\footnotesize $ \pm $ \textbf{1.2}} & 46.9 {\footnotesize $ \pm $ 1.8} & 52.2 {\footnotesize $ \pm $ 1.0} & 45.4 {\footnotesize $ \pm $ 1.7} & 42.5 {\footnotesize $ \pm $ 1.6} & 41.8 {\footnotesize $ \pm $ 0.9} & 39.5 {\footnotesize $ \pm $ 1.9} & 38.6 {\footnotesize $ \pm $ 1.0}\\
\hdashline
FACT & 41.4 {\footnotesize $ \pm $ 0.6} & 25.9 {\footnotesize $ \pm $ 0.9} & 19.6 {\footnotesize $ \pm $ 0.4} & 16.3 {\footnotesize $ \pm $ 0.4} & 13.7 {\footnotesize $ \pm $ 0.4} & 11.3 {\footnotesize $ \pm $ 0.5} & 10.4 {\footnotesize $ \pm $ 0.5} & 9.4 {\footnotesize $ \pm $ 0.6} & 8.3 {\footnotesize $ \pm $ 0.6} \\
FSA & 42.9 {\footnotesize $ \pm $ 2.6} & 39.5 {\footnotesize $ \pm $ 2.0} & 45.5 {\footnotesize $ \pm $ 1.5} & 51.6 {\footnotesize $ \pm $ 1.7} & 48.2 {\footnotesize $ \pm $ 1.8} & 47.3 {\footnotesize $ \pm $ 1.4} & 49.8 {\footnotesize $ \pm $ 1.5} & 49.1 {\footnotesize $ \pm $ 1.7} & 50.1 {\footnotesize $ \pm $ 1.5} \\
FSA-FiLM & \underline{46.6 {\footnotesize $ \pm $ 1.9}} & \underline{44.8 {\footnotesize $ \pm $ 1.1}} & \underline{\textbf{49.4} {\footnotesize $ \pm $ \textbf{0.8}}} & \underline{\textbf{52.9} {\footnotesize $ \pm $ \textbf{1.6}}} & \underline{\textbf{54.0} {\footnotesize $ \pm $ \textbf{0.7}}} & \underline{\textbf{53.5} {\footnotesize $ \pm $ \textbf{1.0}}} & \underline{\textbf{55.8} {\footnotesize $ \pm $ \textbf{0.7}}} & \underline{\textbf{55.2} {\footnotesize $ \pm $ \textbf{0.5}}} & \underline{\textbf{55.8} {\footnotesize $ \pm $ \textbf{0.6}}} \\
\bottomrule
\end{tabular}
\end{small}
\end{center}
\caption{Detailed accuracy for each incremental session on \textbf{FGVC-Aircraft} under the \textbf{few-shot CIL}  setting. GDumb is the only
memory-based method used for comparisons; we use a buffer size equal to the first session’s number of images $N_1$. The best results across
all methods are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k
is used as a backbone for all methods.}
\label{table:few_shot_fgvcaircraft}
%\endgroup
\end{table*}

% Letters
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{2.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{scriptsize}
      
%\begin{sc}
\begin{tabular}{l c c c c c c c c c c c}
\toprule
\multirow{2}{*}{Method} & \multicolumn{11}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){2-12} 
   &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} & \textbf{6} &  \textbf{7} & \textbf{8} & \textbf{9} & \textbf{10} & \textbf{11} \\
 \midrule
NA & 82.1 {\tiny $ \pm $ 0.8} & 76.6 {\tiny $ \pm $ 0.9} & 73.0 {\tiny $ \pm $ 1.5} & 69.6 {\tiny $ \pm $ 1.0} & 69.0 {\tiny $ \pm $ 1.3} & 67.6 {\tiny $ \pm $ 1.3} & 65.8 {\tiny $ \pm $ 1.2} & 64.1 {\tiny $ \pm $ 1.0} & 60.4 {\tiny $ \pm $ 0.6} & 59.0 {\tiny $ \pm $ 0.8} & 57.6 {\tiny $ \pm $ 0.8}\\
\hdashline
GDumb & 91.3 {\tiny $ \pm $ 1.6} & \textbf{91.8} {\tiny $ \pm $ \textbf{1.2}} & 80.0 {\tiny $ \pm $ 1.4} & 72.0 {\tiny $ \pm $ 1.9} & 69.2 {\tiny $ \pm $ 3.0} & 63.5 {\tiny $ \pm $ 1.5} & 59.9 {\tiny $ \pm $ 1.1} & 54.5 {\tiny $ \pm $ 0.3} & 48.0 {\tiny $ \pm $ 0.4} & 44.3 {\tiny $ \pm $ 1.9} & 41.2 {\tiny $ \pm $ 1.7}\\
\hdashline
FACT & 84.3 {\tiny $ \pm $ 1.4} & 72.0 {\tiny $ \pm $ 1.2} & 68.0 {\tiny $ \pm $ 2.2} & 63.2 {\tiny $ \pm $ 1.0} & 62.3 {\tiny $ \pm $ 1.0} & 59.5 {\tiny $ \pm $ 1.2} & 58.0 {\tiny $ \pm $ 1.0} & 55.8 {\tiny $ \pm $ 1.0} & 52.8 {\tiny $ \pm $ 0.7} & 51.7 {\tiny $ \pm $ 0.8} & 49.8 {\tiny $ \pm $ 0.8} \\
FSA & 87.0 {\tiny $ \pm $ 1.4} & 79.6 {\tiny $ \pm $ 1.1} & 76.4 {\tiny $ \pm $ 0.9} & 72.7 {\tiny $ \pm $ 0.7} & 73.0 {\tiny $ \pm $ 0.9} & 71.3 {\tiny $ \pm $ 0.4} & 69.7 {\tiny $ \pm $ 0.4} & 68.4 {\tiny $ \pm $ 0.4} & 64.7 {\tiny $ \pm $ 0.5} & 62.9 {\tiny $ \pm $ 0.4} & 62.2 {\tiny $ \pm $ 0.4} \\
FSA-FiLM & \underline{\textbf{94.3} {\tiny $ \pm $ \textbf{0.9}}} & \underline{90.6 {\tiny $ \pm $ 0.3}} & \underline{\textbf{88.6} {\tiny $ \pm $ \textbf{1.0}}} & \underline{\textbf{85.1} {\tiny $ \pm $ \textbf{0.6}}} & \underline{\textbf{84.9} {\tiny $ \pm $ \textbf{0.4}}} & \underline{\textbf{84.0} {\tiny $ \pm $ \textbf{0.4}}} & \underline{\textbf{82.5} {\tiny $ \pm $ \textbf{0.7}}} & \underline{\textbf{81.1} {\tiny $ \pm $ \textbf{0.4}}} & \underline{\textbf{76.8} {\tiny $ \pm $ \textbf{0.4}}} & \underline{\textbf{75.0} {\tiny $ \pm $ \textbf{0.4}}} & \underline{\textbf{73.4} {\tiny $ \pm $ \textbf{0.4}}} \\
\bottomrule
\end{tabular}
%\end{sc}
\end{scriptsize}   
\end{center}

\caption{Detailed accuracy for each incremental session on \textbf{Letters} under the \textbf{few-shot CIL}  setting. GDumb is the only
memory-based method used for comparisons; we use a buffer size equal to the first session’s number of images $N_1$. The best results across
all methods are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k
is used as a backbone for all methods.}
\label{table:few_shot_letters}
%\endgroup
\end{table*}

% DomainNet
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{3.2pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{small}
\begin{tabular}{l c c c c c c c c c}
\toprule
\multirow{2}{*}{Method} & \multicolumn{9}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){2-10} 
   &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} & \textbf{6} &  \textbf{7} & \textbf{8} & \textbf{9}\\
 \midrule
NA & 83.3 {\scriptsize $ \pm $ 1.0} & 62.6 {\scriptsize $ \pm $ 0.5} & 60.9 {\scriptsize $ \pm $ 1.0} & 61.5 {\scriptsize $ \pm $ 0.3} & 68.3 {\scriptsize $ \pm $ 1.2} & 71.1 {\scriptsize $ \pm $ 0.6} & 72.0 {\scriptsize $ \pm $ 0.7} & 70.8 {\scriptsize $ \pm $ 1.0} & 69.0 {\scriptsize $ \pm $ 0.3}\\
\hdashline
GDumb & \textbf{88.3} {\scriptsize $ \pm $ \textbf{0.4}} & 63.6 {\scriptsize $ \pm $ 0.8} & 58.6 {\scriptsize $ \pm $ 0.6} & 56.4 {\scriptsize $ \pm $ 1.0} & 66.0 {\scriptsize $ \pm $ 1.1} & 68.7 {\scriptsize $ \pm $ 0.4} & 68.9 {\scriptsize $ \pm $ 0.6} & 65.8 {\scriptsize $ \pm $ 1.0} & 63.2 {\scriptsize $ \pm $ 1.1}\\
\hdashline
FACT & 84.3 {\scriptsize $ \pm $ 0.6} & 53.6 {\scriptsize $ \pm $ 0.6} & 43.0 {\scriptsize $ \pm $ 0.5} & 35.9 {\scriptsize $ \pm $ 0.6} & 28.3 {\scriptsize $ \pm $ 0.6} & 24.2 {\scriptsize $ \pm $ 0.3} & 22.6 {\scriptsize $ \pm $ 0.3} & 22.0 {\scriptsize $ \pm $ 0.5} & 20.6 {\scriptsize $ \pm $ 0.2} \\
FSA & 85.2 {\scriptsize $ \pm $ 0.3} & 63.3 {\scriptsize $ \pm $ 0.3} & 61.4 {\scriptsize $ \pm $ 0.7} & 61.6 {\scriptsize $ \pm $ 0.5} & 68.5 {\scriptsize $ \pm $ 0.9} & 71.2 {\scriptsize $ \pm $ 1.1} & 72.2 {\scriptsize $ \pm $ 0.5} & 71.2 {\scriptsize $ \pm $ 0.7} & 70.3 {\scriptsize $ \pm $ 0.4} \\
FSA-FiLM & \underline{87.7 {\scriptsize $ \pm $ 0.3}} & \underline{\textbf{68.5} {\scriptsize $ \pm $ \textbf{0.6}}} & \underline{\textbf{66.9} {\scriptsize $ \pm $ \textbf{0.4}}} & \underline{\textbf{66.7} {\scriptsize $ \pm $ \textbf{0.9}}} & \underline{\textbf{73.7} {\scriptsize $ \pm $ \textbf{0.6}}} & \underline{\textbf{76.0} {\scriptsize $ \pm $ \textbf{0.7}}} & \underline{\textbf{76.0} {\scriptsize $ \pm $ \textbf{0.5}}} & \underline{\textbf{75.0} {\scriptsize $ \pm $ \textbf{0.6}}} & \underline{\textbf{74.0} {\scriptsize $ \pm $ \textbf{0.3}}} \\
\bottomrule
\end{tabular}
\end{small}
\end{center}
%\endgroup
\caption{Detailed accuracy for each incremental session on \textbf{DomainNet} under the \textbf{few-shot CIL}  setting. GDumb is the only
memory-based method used for comparisons; we use a buffer size equal to the first session’s number of images $N_1$. The best results across
all methods are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k
is used as a backbone for all methods.}
\label{table:few_shot_domainnet}
\end{table*}

% iNaturalist
\begin{table*}[ht]
%\vspace*{1.5 cm}
%\begingroup

\setlength{\tabcolsep}{9.7pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
\begin{center}
\begin{normalsize}
%\begin{sc}
\begin{tabular}{l c c c c c c c c c}
\toprule
\multirow{2}{*}{Method} & \multicolumn{9}{c}{Accuracy (\%) in each session ($\uparrow$)}  \\
\cmidrule(lr){2-10} 
   &  \textbf{1} & \textbf{2} & \textbf{3} &  \textbf{4} & \textbf{5} & \textbf{6} &  \textbf{7} & \textbf{8} & \textbf{9}\\
 \midrule
NA & 51.9 & 52.8 & 44.9 & 46.8 & 49.3 & 51.7 & 54.4 & 53.8 & 49.7\\
\hdashline
GDumb & 56.4 & 50.1 & 36.3 & 47.5 & 44.2 & 44.7 & 46.4 & 40.9 & 40.4\\
\hdashline
FACT & 54.9 & 29.9 & 24.6 & 23.8 & 20.4 & 17.8 & 15.7 & 16.4 & 14.3 \\
FSA & 52.1 & 53.6 & 40.0 & 47.8 & 49.2 & 51.3 & 55.1 & 55.1 & 51.5 \\
FSA-FiLM & \underline{\textbf{61.8}} & \underline{\textbf{61.6}} & \underline{\textbf{52.0}} & \underline{\textbf{56.5}} & \underline{\textbf{57.0}} & \underline{\textbf{59.4}} & \underline{\textbf{61.8}} & \underline{\textbf{61.2}} & \underline{\textbf{58.8}} \\
\bottomrule
\end{tabular}
%\end{sc}
\end{normalsize}    
\end{center}
\caption{Detailed accuracy for each incremental session on \textbf{iNaturalist} under the \textbf{few-shot CIL}  setting. GDumb is the only
memory-based method used for comparisons; we use a buffer size equal to the first session’s number of images $N_1$. The best results across
all methods are in bold while the best results across the no-memory methods are underlined. A pre-trained EfficientNet-B0 on Imagenet-1k
is used as a backbone for all methods.}
\label{table:few_shot_inaturalist}
%\endgroup
\end{table*}


\end{document}
