\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
\usepackage[review]{cvpr}      % To produce the REVIEW version
%\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

\usepackage{chngpage}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
\usepackage{dirtytalk}
\usepackage{multirow}
\usepackage[margin=3cm,showframe=false]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{bbm}
\usepackage{xparse}
\usepackage[version=3]{mhchem}
\usepackage{array}
\usepackage{tabularx}
\usepackage{ragged2e}
\usepackage{multicol}
\usepackage{lineno}
\usepackage{arydshln}
\usepackage{layouts}
\usepackage[justification=centering]{caption}
%\usepackage[singlelinecheck=false]{caption}

% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

% Formatting packages
\usepackage{float}
\usepackage{xcolor}

% In paragraph enumerate
\usepackage{paralist}

%\title{Toyota project}
%\author{}
%\date{March 2022}
\newcommand{\argmin}{\mathop{\mathrm{argmin}}}  
\newcommand{\argmax}{\mathop{\mathrm{argmax}}} 

\newcommand{\dx}{\mathrm{d}x}
\newcommand{\dy}{\mathrm{d}y}
\newcommand{\dz}{\mathrm{d}z}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\zV}{\mathbf{0}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cU}{\mathcal{U}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\hp}{\hat{\phi}}
\newcommand{\ap}{\alpha}
\newcommand{\eps}{\epsilon}
\newcommand{\veps}{\varepsilon}
\newcommand{\Sp}{\Omega}
\newcommand{\D}{\delta}
\newcommand{\W}{\mathrm{W}}
\newcommand{\PD}{D_\phi}
\newcommand{\KL}{\mathrm{KL}}
\newcommand{\JF}{\mathrm{JF}}
\newcommand{\JS}{\mathrm{JS}}
\newcommand{\SH}{\mathrm{H}^2}
\newcommand{\TV}{\mathrm{TV}}
\newcommand{\CS}{\chi^2}
\newcommand{\HA}{\mathcal{H}_\alpha}
\newcommand{\PQ}[1]{(P_{#1},Q_{#1})}
\newcommand{\LHS}{\textrm{LHS}}
\newcommand{\RHS}{\textrm{RHS}}
\newcommand{\vspan}{\mathrm{span}}
\newcommand{\cl}{\mathrm{cl}}
\newcommand{\trace}{\mathrm{Tr}}
\newcommand{\var}{\mathrm{Var}}
\newcommand{\cov}{\mathrm{Cov}}
\newcommand{\dom}{\mathrm{dom}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\nn}{\textrm{nn}}
\newcommand{\phii}{e}
\newcommand{\xii}{\boldsymbol{\omega}}

\DeclareMathOperator{\tr}{tr}
\newcommand{\bB}{\mathcal{B}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bm}{\mathbf{m}}
\newcommand{\bn}{\mathbf{n}}
\newcommand{\bS}{\mathbf{S}}
\newcommand{\bk}{\mathbf{k}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bff}{\mathbf{f}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bh}{\mathbf{h}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\balpha}{\boldsymbol{\alpha}}
\newcommand{\bsigma}{\boldsymbol{\sigma}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bdelta}{\boldsymbol{\delta}}
\newcommand{\bzeta}{\boldsymbol{\zeta}}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\bxi}{\boldsymbol{\xi}}
\newcommand{\bnu}{\boldsymbol{\nu}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\Op}{\mathcal{O}}
\newcommand{\boldeta}{\boldsymbol{\eta}}
\newcommand{\kk}{t}
\newcommand{\la}{\mathbf{\ell}}





%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{*****} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Few  Shot CL}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}



\maketitle

\section{Prototype vs LDA vs Linear head}

\begin{figure*}[htb]
\centering
\includegraphics[width = \textwidth]{plots/barplot_compare_all_heads_shots} 
\caption{Average accuracy across all VTAB+ datasets using no-adaptation (\textbf{NA}), FiLM adaptation (\textbf{A-FiLM}), and full body adaptation (\textbf{A-FB}) for different classifier heads (\textbf{Prototype}, \textbf{LDA}, \textbf{Linear}) and number of shots (\textbf{5}, \textbf{10}, \textbf{50}, \textbf{All Data}).}
\label{fig:head_comparisons}
\end{figure*}

\textbf{Conclusions}
textwidth in inches: \printinunitsof{in}\prntlen{\textwidth}
(See Fig. \ref{fig:head_comparisons})
\begin{itemize}
    \item As we increase the number of shots, the linear head outperforms the other two heads.
    \item LDA has the best performance on the low-shot setting.
    \item Prototype head is consistently outperformed by the two other methods regardless adaptation and number of shots.
    \item The more parameters (and data) we use for adaptation the smaller the performance gap between the three heads.
    \item A-FiLM achieves higher performance than A-FB in the low-shot setting.
    \item Overall, LDA head achieves very close performance with Linear head for the high-shot setting and outperforms all the other heads for the low-shot setting. This is important as it’s very easy to do continual learning with an LDA head and we know it can be deployed directly to the continual learning setting whereas incremental updates of a linear head are difficult and will result in a loss in performance over the offline setting
    \item Comparisons between Efficientnet-B0 and Resnet18. FiLM adaptation provides significant boost if the dataset is far from ImageNet regardless backbone's architecture. See Table \ref{table:resnet18_vs_effnet_film}.
    \item We have also tried meta-learning based adaptation methods for the body which support continual learning out of the box, but we have found these to be poorly performing compared to the methods shown here. See Table \ref{table:meta_effenet}.
\end{itemize}

%-----------------------------------------------------------------------------------------------------------------------------
\vspace*{3cm}
\newpage
\section{Few-shot continual learning + small number of classes per session}
\begin{itemize}
    \item See Tables \ref{table:50shot_CL} (accuracy) and \ref{table:50shot_CL_pd} (forgetting). The forgetting metric we use here is the percent performance dropping rate (PPDR)~($\downarrow$), i.e. $ \text{PPDR} = 100 * \frac{\mathcal{A}_1 - \mathcal{A}_S}{\mathcal{A}_1} \%$, where $\mathcal{A}_1$ stands for the accuracy after the first session, and $\mathcal{A}_S$ is the accuracy after the last session.
    \item See Table \ref{table:convnext_vs_film} for comparisons with ConvNext.
    \item What happens when there’s not much data / classes in the first task. See Table \ref{table:shots_vs_ways}.
    \item Making the continual learning sessions less homogeneous does not affect performance greatly (See tables \ref{table:cifar100_superclass} for inhomogeneous CIFAR sessions drawn from a single session and table \ref{table:domainnet_superclass} which samples each session from a different superclass \emph{and} a different domain).
\end{itemize}


\begin{table*}[htb]
%\vspace*{1.5 cm}
%\begingroup
\setlength{\tabcolsep}{2.2pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c c c c c}
\toprule
 \textbf{Method/Dataset} & \textbf{CIFAR100} & \textbf{SVHN} &  \textbf{dSprites-loc} &  \textbf{FGVC-Aircraft} & \textbf{Letters}  & \textbf{DomainNet} & \textbf{iNaturalist} \\
 \midrule
NA & 57.4 (28.4) & 28.3 (61.5) & 11.9 (66.6) & 41.0 (-15.5) & 57.6 (29.9) & 69.0 (17.2) & 49.7 (4.3)\\
\hdashline
FACT & 16.8 (79.7) & 24.1 (66.2) & 11.7 (64.1) & 8.3 (79.9) & 49.8 (40.9) & 20.6 (75.6) & 14.3 (74.0) \\
GDumb & 55.7 (33.7) & 21.0 (73.1) & 16.4 (55.0) & 38.6 (24.5) & 41.2 (54.8) & 63.2 (28.4) & 40.4 (28.4) \\
FSA & 60.3 (27.0) & 32.9 (53.5) & 33.7 (\textbf{41.3}) & 50.1 (-16.8) & 62.2 (28.5) & 70.3 (17.5) & 51.5 (\textbf{1.1}) \\
FSA-FiLM & \textbf{70.9} (\textbf{20.5}) & \textbf{51.3} (\textbf{43.5}) & \textbf{35.7} (43.1) & \textbf{55.8} (\textbf{-19.8}) & \textbf{73.4} (\textbf{22.1}) & \textbf{74.0} (\textbf{15.6}) & \textbf{58.8} (4.8)\\
\midrule
Offline-FiLM & 73.8 & 77.2 & 83.7 & 65.1 & 79.7 & 75.1 & 62.1 \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
%\endgroup
\caption{Accuracy (\%) ($\uparrow$)  of the last session and PPDR (\%) ($\downarrow$) in parentheses for the 50-shot CL-experiment.}
\label{table:50shot_CL_acc_ppd}
\end{table*}



\begin{table*}[htb]
%\vspace*{1.5 cm}
%\begingroup
\setlength{\tabcolsep}{2.2pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c c c c c}
\toprule
 \textbf{Method/Dataset} & \textbf{CIFAR100} & \textbf{SVHN} &  \textbf{dSprites-loc} &  \textbf{FGVC-Aircraft} & \textbf{Letters}  & \textbf{DomainNet} & \textbf{iNaturalist} \\
 \midrule
NA & 57.4 {\footnotesize $ \pm $ 1.0} & 28.3 {\footnotesize $ \pm $ 1.1} & 11.9 {\footnotesize $ \pm $ 0.4} & 41.0 {\footnotesize $ \pm $ 0.7} & 57.6 {\footnotesize $ \pm $ 0.8} & 69.0 {\footnotesize $ \pm $ 0.6} & 49.7\\
\hdashline
FACT & 16.8 {\footnotesize $ \pm $ 0.3} & 24.1 {\footnotesize $ \pm $ 2.0} & 11.7 {\footnotesize $ \pm $ 1.7} & 8.3 {\footnotesize $ \pm $ 0.6} & 49.8 {\footnotesize $ \pm $ 0.8} & 20.6 {\footnotesize $ \pm $ 0.5} & 14.3 \\
GDumb & 55.7 {\footnotesize $ \pm $ 1.0} & 21.0 {\footnotesize $ \pm $ 2.1} & 16.4 {\footnotesize $ \pm $ 2.6} & 38.6 {\footnotesize $ \pm $ 1.0} & 41.2 {\footnotesize $ \pm $ 1.7} & 63.2 {\footnotesize $ \pm $ 0.7} & 40.4 \\
FSA & 60.3 {\footnotesize $ \pm $ 1.3} & 32.9 {\footnotesize $ \pm $ 1.0} & 33.7 {\footnotesize $ \pm $ 1.7} & 50.1 {\footnotesize $ \pm $ 1.5} & 62.2 {\footnotesize $ \pm $ 0.4} & 70.3 {\footnotesize $ \pm $ 0.6} & 51.5 \\
FSA-FiLM & \textbf{70.9} {\footnotesize $ \pm $ \textbf{1.0}} & \textbf{51.3} {\footnotesize $ \pm $ \textbf{2.1}} & \textbf{35.7} {\footnotesize $ \pm $ \textbf{2.1}} & \textbf{55.8} {\footnotesize $ \pm $ \textbf{0.6}} & \textbf{73.4} {\footnotesize $ \pm $ \textbf{0.4}} & \textbf{74.0} {\footnotesize $ \pm $ \textbf{0.5}} & \textbf{58.8}\\
\midrule
Offline-FiLM & 73.8 {\footnotesize $ \pm $ 0.9} & 77.2 {\footnotesize $ \pm $ 0.8} & 83.7 {\footnotesize $ \pm $ 5.6} & 65.1 {\footnotesize $ \pm $ 0.7} & 79.7 {\footnotesize $ \pm $ 0.4} & 75.1 {\footnotesize $ \pm $ 0.4} & 62.1 \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
%\endgroup
\caption{Mean Accuracy (\%) ($\uparrow$) and standard deviations of the last session for the 50-shot CL-experiment. We repeat the experiments five times.}
\label{table:50shot_CL_acc_std}
\end{table*}


\begin{table*}[htb]
%\vspace*{1.5 cm}
%\begingroup
\setlength{\tabcolsep}{2.2pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c c c c c}
\toprule
 \textbf{Method/Dataset} & \textbf{CIFAR100} & \textbf{SVHN} &  \textbf{dSprites-loc} &  \textbf{FGVC-Aircraft} & \textbf{Letters}  & \textbf{DomainNet} & \textbf{iNaturalist} \\
 \midrule
NA-ConvNext & \textbf{87.1 (0.6)} & 43.6 (1.6) & 13.6 (0.5) & 50.2 (0.5) & 63.1 (1.1) & \textbf{82.9 (0.7)} & \textbf{72.6} \\
FSA-FiLM & 70.9 (1.0) & \textbf{51.3 (2.1)} & \textbf{35.7 (2.1)} &\textbf{55.8 (0.6)} & \textbf{73.4 (0.4)} & 74.0 (0.2) & 58.8 \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
%\endgroup
\caption{Accuracy comparison between a pretrained ConvNext on ImageNet-22K and FSA-FiLM. We use the 50-shot CL setting as before and we report the accuracy after the last session.}
\label{table:convnext_vs_film}
\end{table*}



\begin{table}[htb]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c}
\toprule
&  \multicolumn{2}{c}{\textbf{FSA-FiLM}}  \\
\cmidrule(lr){2-3} 
        &   \textbf{10-shot/10-way} & \textbf{50-shot/2-way} \\
\midrule
Caltech101 & 88.7 (0.4) & \textbf{89.8 (0.2)} \\
CIFAR100 & 49.5 (1.4) & \textbf{49.7 (1.5)} \\
Flowers102 & \textbf{84.5 (0.3)} & 81.0 (0.4) \\
Pets & 86.6 (0.6) & \textbf{88.4 (0.5)} \\
Sun397 & 43.4 (0.7) & \textbf{49.7 (0.6)} \\
DTD & 58.0 (0.9) & \textbf{62.1 (0.1)} \\
Resics45 & 69.2 (0.9) & \textbf{71.0 (0.4)} \\
dSprites-loc & \textbf{34.8 (2.9)} & 34.6 (1.4) \\
dSprites-ori & \textbf{33.2 (1.8)} & 32.9 (1.7) \\
SmallNORB-azi & 11.1 (0.9) & \textbf{14.1 (1.1)} \\
FGVC-Aircraft & 37.6 (0.5) & \textbf{48.9 (0.4)} \\
Cars & 30.3 (0.4) & \textbf{40.3 (0.1)} \\
Letters & 56.8 (0.8) & \textbf{62.8 (0.4)} \\
\midrule
Average acc & 52.6 & \textbf{55.8} \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
\caption{Accuracy comparison between two different continual learning settings; in the first setting we use 10 classes with 10 images each (10-shot/10-way) and for the second setting 2 classes and 50 images each  (50-shot/2-way). For both settings, we use FSA-FiLM.}
\label{table:shots_vs_ways}
\end{table}

\begin{table}[htb]
\begingroup
\setlength{\tabcolsep}{2.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{1.1}
\begin{small}
%\begin{sc}
\begin{tabular}{l c c c c}
\toprule
\textbf{No adaptation} & \textbf{Aqua} & \textbf{DevFurn} &  \textbf{Vehicles} \\
 \midrule
57.4 (1.0) & 66.11 (1.61) & 66.21 (1.94) & 67.88 (1.24) \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\endgroup
\caption{Accuracies of FSA-FiLM for three different continual learning settings on CIFAR-100. We split the data into 19 sessions using 50 shots. The first session includes 10 classes from super-classes (i) aquatic mammals and fish (\textbf{Aqua}), (ii) electric devices and furniture (\textbf{DevFurn}), and (iii) Vehicles 1 and Vehicles 2 (\textbf{Vehicles}). Each of the other 18 sessions includes images from the remaining 18 super-classes. }
\label{table:cifar100_superclass}
\end{table}

\begin{table}[htb]
\begingroup
\setlength{\tabcolsep}{2.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{1.1}
\begin{small}
%\begin{sc}
\begin{tabular}{l c c c c}
\toprule
\textbf{No adaptation} & \textbf{El-Real} & \textbf{Furn-Clipart} &  \textbf{Tr-Sketch} \\
 \midrule
69.00 (0.43) & 70.62 (0.57) & 71.68 (0.63) & 72.77 (0.45) \\
\bottomrule
\end{tabular}
%\end{sc}
\end{small}
\endgroup
\caption{Accuracies of FSA-FiLM for three different continual learning settings on DomainNet. We split the data into 6 sessions using 50 shots with 10 classes in each session. The first session includes 10 classes of (i) the ``electricity'' superclass of the real domain (\textbf{El-Real}), (ii) the ``furniture'' superclass of the clipart domain (\textbf{Furn-Clipart}), and (iii) the ``transportation'' superclass of the sketch domain (\textbf{Tr-sketch}).}
\label{table:domainnet_superclass}
\end{table}

%-----------------------------------------------------------------------------------------------------------------------------


\section{First session with full shots and large number of classes. Few shots for the rest of the sessions.}

\begin{itemize}
    \item See Table \ref{table:fact_vs_our}.
\end{itemize}

\begin{table}[htb]
\begingroup
\setlength{\tabcolsep}{3.1pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c}
\toprule
& & \multicolumn{2}{c}{ \textbf{Datasets}} \\
\cmidrule(lr){3-4}  \textbf{Method} & \textbf{CNN} &  \textbf{CIFAR100} &  \textbf{CUB200} \\
\midrule
FACT & RN-20 & 52.1 (30.2)* & - \\ 
FSA & RN-20 & 52.0 (30.8) & - \\ 
\hdashline
NA & RN-18 & 50.4 (26.8) & 50.0 (29.3) \\ 
FACT & RN-18 & 49.5 (34.8) & 56.9 (25.0)* \\ 
FSA-FiLM & RN-18 & 55.2 (24.4) & 52.6 (27.6) \\ 
FSA & RN-18 & 61.4 (25.1) & 57.6 (24.3) \\ 
\hdashline
NA & EN-B0 & 55.2 (25.8) &  63.2 (\textbf{19.6}) \\ 
FACT & EN-B0 & 56.5 (34.6) & 62.9 (23.3) \\ 
FSA-FiLM & EN-B0 & 61.8 (\textbf{22.4}) & 62.9 (20.4) \\ 
FSA & EN-B0 &  \textbf{66.0} (24.6) & \textbf{63.4} (20.9) \\ 
\midrule
Offline & EN-B0 & 67.0 & 65.1 \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
\endgroup
\caption{Performance comparison between FACT and the rest of the methods. We use the setting described in \cite{zhou2022forward} where a large number of classes/shots are available in the first session and a low number of classes/shots in the rest of the sessions. We report the accuracy (\%) ($\uparrow$) of the last session and the PPDR (\%) ($\downarrow$) in parentheses. Asterisk (*) indicates that the reported results used come from \cite{zhou2022forward}.}
\label{table:fact_vs_our}
\end{table}


%-------------------------------------------------------------------------------------------------------------------------------
\section{First session with full shots and a small number of classes. Full shots with small number of class for the rest of the sessions.}

\begin{itemize}
    \item See Table \ref{table:cifar100_core50_fullshots}.
    \item See Figures \ref{fig:gdumb_cifar100_time_acc} and \ref{fig:gdumb_core50_time_acc} for accuracy and time comparisons between FSA-FiLM and GDumb with different memory sizes.
\end{itemize}

\begin{table}[htb]
%\vspace*{1.5 cm}
%\begingroup
\setlength{\tabcolsep}{3.9pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c}
\toprule
& \multicolumn{2}{c}{\textbf{Datasets}} \\
\cmidrule(lr){2-3} \textbf{Method} & \textbf{CIFAR100} & \textbf{CORE50} \\
 \midrule
NA & 68.2 (26.8) & 82.6 (14.2)\\
\hdashline
FACT & 10.2 (89.4) & 22.0 (77.7) \\
GDumb & 69.3 (28.6) & \textbf{90.0} (\textbf{7.6}) \\
FSA & 62.8 (34.5) & 82.8 (15.5) \\
FSA-FiLM & \textbf{73.8} (\textbf{23.4}) & 85.4 (13.3)\\
\midrule
Offline-FiLM & 76.5 & 88.4 \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
%\endgroup
\caption{Last session accuracies on CIFAR100 and CORE50 datasets. The first session contains all the images for each of the first 10 classes. The rest of the sessions include 10 (5 for CORE50) classes using all the available training images of these classes. We use an EfficientNet-B0 as a backbone for all methods.}
\label{table:cifar100_core50_fullshots}
\end{table}


\begin{figure*}[htb]
\centering
\includegraphics[width = \textwidth]{plots/cifar100_core50_full_shots_acc_time} 
\caption{Accuracy and running time comparison for CIFAR100 and CORE50 datasets. between FSA-FILM and GDumb-$m$ where $m \in \{ 200, 500, 1\text{K}, 2\text{K}, 5\text{K}, 10\text{K}^*  \}$ is the size of the memory buffer. We report the test accuracy of the last session and we use a memory buffer equals to 10K images only for CORE50.}
\label{fig:gdumb_cifar100_core50_time_acc}
\end{figure*}


%------------------------------------------------------------------------------------------

\section{Discussion}

\begin{itemize}
    \item Whether to adapt or not depends on how ``close'' is the dataset to Imagenet.
    \item In general, if we are in a high-shot with a large number of classes setting using FSA gives the best performance. For low-shot settings FSA-FiLM works much better.
\end{itemize}



%------------------------------------------------------------------------------------------

\begin{figure}[h]
\centering
\includegraphics[width =\linewidth]{plots/clustering_scores} 
\caption{Scatter plot of the last session's accuracy differences between FSA-FiLM and NA against the Calinski-Harabasz (CH) index. We use 5 classes for the first session and 50 shots in general.}
\label{fig:ch_index}
\end{figure}


\begin{figure*}[htb]
\centering
\includegraphics[width = \textwidth]{plots/barplot_na_film_diff_full_shots} 
\caption{Bar plot of the accuracy differences between FiLM and NA on offline mode. We use all the available training data.}
\label{fig:na_film_diff_full_shots_offline}
\end{figure*}

\begin{figure}[h]
\centering
\includegraphics[width = \linewidth]{plots/barplot_na_film_diff_shots=50} 
\caption{Bar plot of the accuracy differences between FiLM and NA on offline mode. We use 50 shots.}
\label{fig:na_film_diff_50_shots_offline}
\end{figure}


%------------------------------------------------------------------------------------------


\begin{table*}[htb]
%\vspace*{1.5 cm}
%\begingroup
\setlength{\tabcolsep}{2.9pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c c}
\toprule
 \textbf{Dataset} & \textbf{NA-Resnet18} & \textbf{FiLM-Resnet18} &  \textbf{NA-EffnetB0} &  \textbf{FiLM-EffnetB0} \\
 \midrule
Caltech101 & 87.96 (0.28) & 87.70 (0.71) & 91.86 (0.45) & 93.80 (0.51) \\
CIFAR100 & 58.22 (0.95) & 61.78 (0.74) & 57.44 (1.04) & 73.77 (0.86) \\
Flowers102 & 81.24 (0.73) & 87.11 (0.24) & 83.86 (0.27) & 91.13 (0.27) \\
Pets & 86.91 (0.38) & 86.78 (0.57) & 89.49 (0.38) & 89.92 (0.66) \\
Sun397 & 51.35 (1.26) & 47.84 (0.86) & 55.88 (0.99) & 59.75 (0.61) \\
SVHN & 37.34 (0.82) & 74.54 (0.86) & 28.31 (1.10) & 77.23 (0.80) \\
DTD & 59.95 (0.00) & 59.34 (0.56) & 61.12 (0.00) & 68.44 (0.17) \\
\midrule
EuroSAT & 88.35 (0.54) & 92.59 (0.51) & 87.73 (0.92) & 93.02 (0.61) \\
Resics45 & 73.75 (1.13) & 77.48 (1.07) & 73.51 (0.88) & 83.36 (0.61) \\
\midrule
Patch Camelyon & 76.28 (0.86) & 77.38 (1.13) & 76.20 (1.08) & 77.92 (2.38) \\
Retinopathy & 29.20 (2.08) & 30.37 (1.00) & 32.93 (2.15) & 35.21 (1.19) \\
\midrule
CLEVR-count & 29.51 (1.34) & 39.87 (1.42) & 30.15 (1.05) & 46.63 (1.11) \\
CLEVR-dist & 31.66 (0.77) & 45.31 (2.63) & 32.25 (1.08) & 38.83 (1.01) \\
dSprites-loc & 21.81 (0.63) & 70.20 (1.96) & 11.91 (0.43) & 83.73 (5.56) \\
dSprites-ori & 20.84 (0.41) & 52.13 (1.45) & 20.09 (1.13) & 52.14 (1.33) \\
SmallNORB-azi & 13.93 (0.47) & 16.41 (0.68) & 12.32 (0.80) & 16.80 (0.79) \\
SmallNORB-elev & 21.42 (0.98) & 25.06 (0.62) & 19.13 (0.70) & 22.92 (0.52) \\
DMLab & 29.74 (0.53) & 31.58 (0.94) & 30.57 (0.26) & 34.61 (0.57) \\
KITTI-dist & 61.97 (3.51) & 65.96 (2.72) & 61.41 (2.30) & 66.75 (2.97) \\
\midrule
FGVC-Aircraft & 38.90 (0.51) & 53.06 (0.33) & 40.99 (0.74) & 65.05 (0.68) \\
Cars & 34.39 (0.04) & 49.49 (0.23) & 43.34 (0.04) & 67.86 (0.23) \\
Letters & 56.05 (1.18) & 77.74 (1.29) & 57.60 (0.80) & 79.74 (0.43) \\
\midrule
Average acc & 49.6 & 59.5 & 49.9 & 64.5 \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
%\endgroup
\caption{Accuracy comparison between NA and FiLM methods on offline mode using either a Resnet18 or an EfficinetNet-B0 backbone. The reported results are based on 50 shots.}
\label{table:resnet18_vs_effnet_film}
\end{table*}

%------------------------------------------------------------------------------------------

\begin{table*}[htb]
%\vspace*{1.5 cm}
%\begingroup
\setlength{\tabcolsep}{2.9pt} % Default value: 6pt
%\renewcommand{\arraystretch}{.9}
%\begin{small}
%\begin{sc}
\begin{tabular}{l c c c c}
\toprule
 \textbf{Dataset} & \textbf{NA} & \textbf{Meta-Learn} &  \textbf{FiLM} &  \textbf{Full-body} \\
 \midrule
Caltech101 & 91.86 (0.45) & 91.03 (0.44) & 93.80 (0.51) & 93.87 (0.26) \\
CIFAR100 & 57.44 (1.04) & 58.00 (0.93) & 73.77 (0.86) & 73.08 (0.68) \\
Flowers102 & 83.86 (0.27) & 84.40 (0.34) & 91.13 (0.27) & 89.98 (0.47) \\
Pets & 89.49 (0.38) & 89.55 (0.31) & 89.92 (0.66) & 89.56 (0.58) \\
Sun397 & 55.88 (0.99) & 53.66 (0.77) & 59.75 (0.61) & 60.44 (0.59) \\
SVHN & 28.31 (1.10) & 47.28 (1.40) & 77.23 (0.80) & 64.49 (1.28) \\
DTD & 61.12 (0.00) & 63.78 (0.00) & 68.44 (0.17) & 64.39 (0.23) \\
\midrule
EuroSAT & 87.73 (0.92) & 85.72 (0.61) & 93.02 (0.61) & 94.07 (0.63) \\
Resics45 & 73.51 (0.88) & 75.53 (0.99) & 83.36 (0.61) & 87.64 (0.67) \\
\midrule
Patch Camelyon & 76.20 (1.08) & 77.97 (1.39) & 77.92 (2.38) & 72.15 (1.76) \\
Retinopathy & 32.93 (2.15) & 31.61 (1.22) & 35.21 (1.19) & 31.34 (2.90) \\
\midrule
CLEVR-count & 30.15 (1.05) & 28.71 (1.12) & 46.63 (1.11) & 45.24 (1.15) \\
CLEVR-dist & 32.25 (1.08) & 30.53 (1.74) & 38.83 (1.01) & 44.73 (2.17) \\
dSprites-loc & 11.91 (0.43) & 12.24 (0.54) & 83.73 (5.56) & 87.10 (2.37) \\
dSprites-ori & 20.09 (1.13) & 24.69 (1.90) & 52.14 (1.33) & 44.77 (2.27) \\
SmallNORB-azi & 12.32 (0.80) & 12.42 (0.46) & 16.80 (0.79) & 18.26 (0.70) \\
SmallNORB-elev & 19.13 (0.70) & 18.94 (0.96) & 22.92 (0.52) & 31.30 (1.68) \\
DMLab & 30.57 (0.26) & 32.62 (0.81) & 34.61 (0.57) & 32.69 (1.63) \\
KITTI-dist & 61.41 (2.30) & 62.59 (2.05) & 66.75 (2.97) & 66.95 (2.18) \\
\midrule
FGVC-Aircraft & 40.99 (0.74) & 50.92 (0.67) & 65.05 (0.68) & 73.47 (0.45) \\
Cars & 43.34 (0.04) & 40.12 (0.03) & 67.86 (0.23) & 79.44 (0.11) \\
Letters & 57.60 (0.80) & 64.23 (0.63) & 79.74 (0.43) & 82.28 (0.91) \\
\midrule
Average acc & 49.9 & 51.7 & 64.5 & 64.9 \\
\bottomrule
\end{tabular}
%\end{sc}
%\end{small}
%\endgroup
\caption{Accuracy comparison between different adaptation methods on offline mode using an EfficinetNet-B0 backbone. The reported results are based on 50 shots.}
\label{table:meta_effenet}
\end{table*}

%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{refs}
}




\end{document}
