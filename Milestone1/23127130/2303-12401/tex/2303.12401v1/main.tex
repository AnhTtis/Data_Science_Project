\documentclass[11pt]{elsarticle}

\makeatletter
\def\ps@pprintTitle{%
 \let\@oddhead\@empty
 \let\@evenhead\@empty
 \def\@oddfoot{}%
 \let\@evenfoot\@oddfoot}
\makeatother

% \usepackage{lineno}
% \modulolinenumbers[5]
\usepackage{caption} 
\captionsetup[table]{skip=10pt}
\usepackage[hyphens]{url}
% \usepackage{parskip}

\usepackage[margin=1in]{geometry}
\usepackage{setspace}
% \doublespacing
\pagestyle{plain}
\usepackage{amsmath,amssymb,amsthm,bm}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{flafter}
\usepackage{color,hyperref,xcolor}
\usepackage{float}
\usepackage{algorithm2e}
\usepackage{framed}
\hypersetup{colorlinks=true,urlcolor=blue,citecolor=purple}
\usepackage{cleveref}
\usepackage{longtable}
\usepackage{float}
\usepackage[export]{adjustbox}
\usepackage{placeins}
\usepackage{blkarray}
\usepackage{booktabs, bigstrut, multicol}
% \usepackage{parskip}

% \usepackage{lscape}
% \usepackage{float}
% % \usepackage{newtxmath}
% \usepackage[ruled,vlined]{algorithm2e}
% \usepackage{comment}
% \usepackage{booktabs}
% \usepackage{multirow}

%% Harvard
\bibliographystyle{model2-names}\biboptions{authoryear}
%\bibliographystyle{model1-num-names}
% \usepackage[
% backend=biber,
% style=authoryear,
% sorting=ynt
% ]{biblatex}
% \addbibresource{references.bib}

\numberwithin{equation}{section}

\def\X{\bm{X}}
\def\Z{\bm{Z}}
% \def\N{\mathcal{N}}
\def\boldeps{\bm{\varepsilon}}

\def\R{\mathbb{R}}
% \def\X{\mathbb{X}}
\def\Y{\mathbb{Y}}
% \def\Z{\mathbb{Z}}
\def\E{\mathbb{E}}
\def\I{\mathbf{I}}
%\def\Z{\mathbb{Z}}
\def\N{\mathbb{N}}
\def\No{\mathcal{N}}
\def\bmu{\bm{\mu}}
\def\L{\mathcal{L}}
\def\F{\mathcal{F}}
\def\M{\mathcal{M}}
\renewcommand{\vec}[1]{\mathbf{#1}}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\prob}{\mathbb{P}}

\newcommand{\tr}{\mathrm{T}_{\mathrm{R}}}
\newcommand{\e}{\mathbf{e}}
\newcommand{\w}{\mathbf{w}}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\norm}[1]{\left\| #1 \right\|}
\newcommand{\cov}{\mbox{Cov}}
\newcommand{\var}{\mathrm{Var}}
\newcommand{\eps}{\varepsilon}
\newcommand{\given}{\hspace{2pt}\vert\hspace{2pt}}
\newcommand{\dash}{^{\prime}}
\newcommand{\ddash}{^{\prime\prime}}
\newcommand{\poi}{\mathrm{Poisson}}
\newcommand{\ber}{\mathrm{Bernoulli}}
\renewcommand{\vec}[1]{\mathbf{#1}}

\newcommand{\sd}[1]{{\color{red} SD: #1}}
\newcommand{\rr}[1]{{\color{red} RR: #1}}

\newtheoremstyle{general}
{3mm} % Space above
{3mm} % Space below
{} % Body font
{} % Indent amount
{\bfseries} % Theorem head font
{.} % Punctuation after theorem head
{.5em} % Space after theorem head
{} % Theorem head spec (can be left empty, meaning `normal')

% theorem definitions
\theoremstyle{general}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{assumption}{Assumption}


\begin{document}

\begin{frontmatter}

\title{Real-time forecasting within soccer matches through a Bayesian lens}
\author{Chinmay Divekar, Soudeep Deb, Rishideep Roy }
\address{Indian Institute of Management Bangalore \\ Bannerghatta Main Road, Bangalore, KA 560076, India.}

\begin{abstract}
This paper employs a Bayesian methodology to predict the results of soccer matches in real-time. Using sequential data of various events throughout the match, we utilize a multinomial probit regression in a novel framework to estimate the time-varying impact of covariates and to forecast the outcome. English Premier League data from eight seasons are used to evaluate the efficacy of our method. Different evaluation metrics establish that the proposed model outperforms potential competitors, which are inspired from existing statistical or machine learning algorithms. Additionally, we apply robustness checks to demonstrate the model's accuracy across various scenarios. 
%capabilities by forecasting two matches in real-time.
%Our evaluation of the models' predictive performance is based on F1 and Brier score, and the results indicate that the proposed model outperforms it's competitors. and compare our forecasts to those generated by a generalized linear model and other machine learning algorithms. 
\end{abstract}

\begin{keyword}
In-game forecasting \sep Ordered multinomial probit model \sep Soccer prediction \sep Bayesian method
\end{keyword}

\end{frontmatter}

%\vspace{0.1in}
%
%\noindent {\bf Corresponding author:} Soudeep Deb
%
%\vspace{0.1in}
%
%\noindent {\bf Address:} \\
%Indian Institute of Management Bangalore \\ 
%Bannerghatta Main Road, Bangalore, KA 560076, India. \\
%Email: soudeep@iimb.ac.in, ORCiD: 0000-0003-0567-7339.
%
%\vspace{0.1in}
%
%\noindent {\bf Running head:} Within-game forecasting in soccer
%
\newpage

\section{Introduction}\label{sec:introduction}

Sports and games are recreations that have attracted mankind since time immemorial. Soccer is a significant one among them. Early forms of sports involving feet and ball have been noted in many parts of the world. The game Tsu'chu or Cuju (in China), which literally stood for `kicking the ball' is one of the earliest versions of the game from East Asia, and was in practice a few millennia ago. There was a similar sport in Japan called Kemari, which still survives. Similarly, there have been examples of sports using balls and feet from ancient Greek and Roman civilizations, among the Native Americans, the indigenous people of Oceania etc. There have been similar other sports recorded in Europe, particularly in the modern-day United Kingdom during the middle ages. With the progress of time, some of the old forms have modified themselves, some have lost out in the race, and others have taken their place. Their popularity, not only in terms of participation but also in attracting the audience, keeps the sheen of soccer. As \cite{walvin2014people} notes in his book on the history of soccer, it is literally the ``people's game''.  Spectators are especially engaged in rooting for their favourite heroes and teams and in predicting the outcome of the games. In fact, forecasting and decision-making have become intrinsic parts of sports. For avid fans, betting on their favourite teams provides just as good an experience as watching the game. The global sports betting market is estimated to increase at an approximate compound annual growth rate of 10.3\% till 2032, with soccer (or, association football) bringing the most attention, as stated in \cite{SportsCAGR2022}. Arguably the most viewed sport in the world, the sports market connected to soccer is also huge. %Soccer is one of the most popular sports in the world and generates interest across the globe. It is widely watched, played and also bet on. As such, the sports market connected with it is also huge.

With the increasing viewership and fandom, the concept of within-game result forecasting is turning out to be a very important aspect in soccer. The market associated with this prediction being ever so on the rise, there is greater requirement on the precision of these predictions, which include not just the result but also the final scoreline. There are numerous techniques to forecast the outcome of a soccer match based on aggregated data at the beginning of a match, but they lack the flexibility to update the predictions based on the sequence of particular events during the match. Over time within the games, new information come to light in the form of the events that occur on the soccer field with every passing minute. This naturally motivates a Bayesian model, which takes into account the minute-by-minute data of soccer matches, to predict the final outcome of the game. To the best of our knowledge, there is no published work in this direction. In the current work, we aim to bridge that gap in the extant literature by developing a predictive Bayesian model that can be used for within-match forecasting in soccer. Our methodology works with the final outcome as an ordinal response variable and models the latent variable by suitably incorporating different covariates and events relevant to the game. On one hand, the proposed approach allows us to identify the time-varying impacts of various events in soccer, while on the other, it is found to record superior predictive performance than a few other possible approaches, which are developed as extensions from existing statistical and machine learning methods. %with cut-offs as a dummy for it. For this model we chose priors for the coefficients and the cut-offs, and ultimately get a posterior predictive distribution for the latent variable, which we then evaluate in terms of its predictive performance. 

Before delving into the proposed methodology, we find it pivotal to present a succinct account of existing literature that focus on forecasting problems related to soccer using formal statistical methods, as well as the ones that develop in-game prediction methods for other types of sports. 


\subsection{Brief literature review}

% In this section, we shall begin with a brief review of forecasting in soccer. We will then move on to within-game forecasting and discuss some papers on forecasting in different sports, ultimately culminating to our specific interest of within game forecasting in soccer. 

Accurate forecasting of results in sports has been an interest of the world for a long time. Quite naturally, due to its popularity and financial impacts, prediction problems in soccer constitute an extensively researched area. Early papers like \cite{maher1982modelling} modelled the distribution of goals using bivariate Poisson random variables. \cite{rue2000prediction} extended the bivariate modelling approach to a Bayesian setup while considering the strength of a team as a time-dependent factor. \cite{crowder2002dynamic} proposed a more computationally efficient method to update the strength parameters. \cite{goddard2005regression} compared the forecasting performance of a goal-based model (bivariate Poisson regression model) against a result-based model (ordered probit model). \cite{mchale2007modelling} extended the idea of dependence in a bivariate framework and utilized copulas to model the results of soccer matches. Another advanced technique of sparse bivariate Poisson model, along with the concepts of boosting to select appropriate covariates, was used by \cite{mchale2007modelling}. On the other hand, \cite{hvattum2010using} worked with a rating-based system to predict the result of soccer matches, demonstrating that ELO rating-based measures can adequately incorporate past results. 

Another branch of literature studies the relationship between the match results and bookmaker odds. \cite{forrest2000forecasting} analyzed English soccer match odds provided by newspaper agencies to determine their efficiency. The authors concluded that these odds do not appropriately utilize team strength and such publicly available data to enhance their forecasting prowess. The articles by \cite{vstrumbelj2010online}, \cite{vstrumbelj2014determining} explored the quality of bookmaker odds by viewing them as probabilistic evaluations of the match results. Different aspects of the game that seemed to have an effect on the outcome were also studied. \cite{clarke1995home} explored the effect of home advantage on the game result, while \cite{ley2019ranking} compared the existing team strength-based modelling approaches. \cite{koopman2019forecasting} proposed a dynamic modelling framework for the scenario when the outcome variable is goals scored, win/draw/loss and difference in goals scored. The time-dependent covariates in this method are updated as an autoregressive process. Different machine learning techniques have also been used in this regard. \cite{liti2017predicting} provides an excellent comparative discussion on the accuracy of various such algorithms, while \cite{mendes2020comparing} assesses the efficacy of neural network ensemble methods in forecasting match outcomes in soccer. %(\sd{Next two papers are not related to sports at all, they should be removed from here.}) \cite{kwon2007identifying} used a Bayesian approach for modelling ordinal outcomes. The author used a Dirichlet prior for the cutoffs and jointly models the regression parameters with the cutoffs. \cite{zhou2006bayesian} used a mixture-model approach to model ordinal data. The estimation above differs from these methods due to the distributional independence of covariate parameters from the cutoffs.

Moving on to the literature of in-game forecasting, we note that since the 2000s, with the influx of data, this topic has picked pace in the domain of sports analytics. In cricket, \cite{easton2006examination} demonstrated the impact of in-game ball-by-ball events on the change in the odds of winning. In tennis, \cite{klaassen2003forecasting} modelled the probability of the player serving to win the match and designed a way to update this probability after every point. This model was further explored by \cite{easton2010forecasting} to demonstrate tennis betting markets' in-game efficiency. \cite{stern2005brownian} forecast the winning probability in a game of basketball by modelling the difference in points scored as a Brownian process. An extension of this by incorporating the betting odds and using a Gamma process was proposed by \cite{song2020making}. Intriguingly, even though soccer is arguably the most popular sport across the globe, we could not find any research article to tackle the problem of within-game forecasting in soccer. Our focus in this article is to address this issue through the help of a Bayesian framework.%This is where we are trying to bridge the gap, and our work aims to  


%\cite{harville1977use} developed a rating system for American college football (\sd{Why is American Football relevant in soccer paper?}) to predict the teams going through to the playoffs. They proposed a linear model for the difference in scores and obtained forecasts similar to those of bookmakers. Recently, deep learning frameworks have been used to predict soccer match outcomes as well.


\subsection{Our contribution}

In sports like basketball, baseball or cricket, the main events deciding the result (points, runs, wickets etc.) typically have a high rate of occurrence; hence a much gradual change is expected to be observed in the outcome probabilities over time. In contrast, the frequency of the corresponding variable (that is, a goal) in professional soccer is extremely low. Consequently, the fate of a soccer match is immensely volatile, which is likely to hinder the accuracy of an in-game forecaster. This article attempts to solve this problem and fill the gap in the extant literature, by proposing a Bayesian model for within-game forecasting in soccer. 

The proposed methodology treats the outcome of a match with respect to the home team as an ordinal multinomial random variable (win/draw/loss). Then, utilizing appropriate time-invariant and time-dependent covariates which record the events happening in real-time in a soccer match, our model forecasts the result as the match progresses. We use a complete Bayesian framework for predicting the final outcome of the match. A latent variable with two cutoffs is used as a proxy for modelling the final outcome. We assume that this latent variable depends on different covariates pertaining to the match, as well as random errors, and this dependence is linear. The latent variable is continuously updated using Bayesian techniques, which in turn predicts the final outcome as well. As we shall discuss in detail below, it is quite a broad framework without making strong assumptions about the model. We use real-life data from the top division of English club football to demonstrate the predictive accuracy of the proposed algorithm. The model is also able to quantify the effects of specific types of events as a function of time during the progression of the match. Furthermore, different robustness checks are done to establish that the method works well across various scenarios.

The outline of the rest of the article is as follows. The methodology used for analysis is described in \Cref{sec:methodology}. We begin with our model specification in detail, followed by the Bayesian techniques used in our work. We also describe a way of evaluating our method, which includes the estimations as well as the predictive distributions. For completeness of the study, we extend a few other existing methods for conventional forecasting in soccer to within-game predictive techniques and compare their performances against our proposed model. \Cref{sec:data} describes the dataset we use for our work, along with some exploratory analysis and descriptive statistics. Our results are demonstrated in \Cref{sec:results} where we first present a general analysis, followed by a robustness study. Next, we look at two specific case studies to understand the results better. The article ends with the summary and some important concluding remarks in \Cref{sec:conclusion}. 

% Ordinal variable as an outcome is usually dealt with by replacing it with a latent variable with cutoffs determining the categories. Analysis of ordinal outcomes using PH regression was proposed by McCullagh (1980)$^\ref{1}$. Albert and Chib (1993)$^\ref{4}$ extended the idea in a Bayesian framework using truncated Normal distribution as the prior for the cutoffs. Kwon et. al. (2007)$^\ref{9}$ and Mwalili, Lesaffre and Declerck (2005)$^\ref{8}$ adopted similar methods. Zhou (2006) proposed a mixture distribution approach for the latent variables to mitigate the convergence issues in Gibbs sampling. Dechi (2019)$^\ref{12}$ proposed a Dirichlet prior for the cutoffs, establishing a relation between the cutoffs and the parameters of a Dirichlet distribution. 



\section{Methodology}\label{sec:methodology}

\subsection{Model specification}\label{subsec:model}

Throughout this article, we shall use $\N$, $\mathbb{Z}$ and $\R$ to denote the sets of natural numbers, integers and real numbers, respectively. We use the shorthand notation $[K]$ for the set of all natural numbers from $1$ to $K$, i.e.\ $\{ k:1 \leqslant k \leqslant K; k \in \N \}$.  Any matrix is represented in bold capital letters, and any vector in lower-case bold letters; for example, $\bm{a}$ would indicate a vector and $\bm{A}$ would represent a matrix. We shall use $\bm I_d$ to denote an identity matrix of dimension $d\times d$. Also, we shall use $\bm{1}(\cdot)$ to denote an indicator function. 

Let us formally define the framework now. We model the outcome of a game from the perspective of the team playing at home. The dependent variable is therefore denoted by an ordered multinomial random variable with three categories -- loss, draw or win -- correspondingly denoted by $r\in R = \{-1, 0, 1\}$, respectively. The focus of the model is on forecasting the outcome in real-time, that is, after every minute of the match. Therefore, we define a time index set $\Gamma = \{t:1 \leqslant t \leqslant 90 ;~ t \in \N \}$. At the end of every minute $t \in \Gamma$, we record a set of covariates from minutes $1$ through $t$. Hereafter, we refer to these as time-varying covariates.


To define the main model, let $Y_i$ denote the outcome for the home team in the $i^{th}$ match, for $i\in [n]$. The vector of the outcomes $(Y_1,\hdots,Y_n)$ will be denoted as $\bm{y}$. It is treated along the lines of \cite{greene2003econometric}, for an ordered probit model. We define a latent variable $\Pi_i$ and cut-offs $\delta_1, \delta_2$ such that,
\begin{equation}\label{eq:yspec}
Y_i=
    \begin{cases}
    -1, &\mbox{if } \Pi_i < \delta_1 \\
    ~~0, &\mbox{if } \delta _1\leqslant \Pi_i \leqslant \delta_2 \\
    ~~1, &\mbox{if } \Pi_i > \delta_2. 
    \end{cases} 
\end{equation}

Here, $\Pi_i$ is the value of the latent variable in the $i^{th}$ match, which can be modelled as a function of the covariates. Note that \cite{goddard2005regression} modelled the ordinal outcome using probit regression with linear and additive functional forms of the covariates. \cite{angelini2017parx}, \cite{koopman2019forecasting} also follow a similar specification in their papers. Motivated by these studies, we use a linear function with additive error for modelling the outcome of a soccer match in a similar setup. Mathematically, for the $i^{th}$ match, $\Pi_i$ is modeled as
\begin{equation}\label{eq:pispec}
    \Pi_i = \textbf{z}_i^{\top} \bm{\gamma} + \sum_{k \in [K]} {\textbf{x}_{ik}^{(t)}}^\top \bm{\beta}_{k}^{(t)} + \boldeps_i, 
\end{equation}
where $\textbf{z}_i$ is a $p\times 1$ vector of time-invariant covariates such as the strengths of the starting elevens for both the teams and $\bm{\gamma}$ is the corresponding vector of coefficients. On the other hand, $\bm{\beta}_k^{(t)}$ is a $2t \times 1$ vector of coefficients capturing the time-varying effect of an event of type $k$ on the outcome of a match, whereas
\begin{equation*}
    \textbf{x}_{ik}^{(t)} = \begin{bmatrix} x_{ik,1}^H & x_{ik,2}^H & \cdots & x_{ik,t}^H & x_{ik,1}^A & x_{ik,2}^A & \cdots & x_{ik,t}^A  \end{bmatrix}^\top, \; \text{for } i \in [n],
\end{equation*}
is the associated vector indicating the number of occurrences for the $k^{th}$ type of event until time $t$ for both teams. Here, $x_{ik,t}^H$ and $x_{ik,t}^A$ denote the corresponding covariates for the home ($H$) and away ($A$) teams, respectively. We assume that there are a total of $K$ types of such events. For instance, one may consider goals, fouls, cards, shots-on-goal, corners etc. The variables used in this article are further elaborated in \Cref{sec:data}. It should be reiterated that the proposed model incorporates all time-varying events in a linear additive fashion.

Finally, we assume that all $\boldeps_i$ are independent and identically distributed (iid) zero-mean Gaussian random variables. Such an assumption for the error distribution is a popular choice in the current context, see \cite{koning2000balance} for example. \cite{koopman2019forecasting} also explored various methods to predict match results, and used Gaussian marginals since it leads to a parsimonious model with straightforward estimation procedures. Another motivation for such an assumption is that in a Bayesian setting which we use for implementation, a Normal prior for $\boldeps$ induces conjugacy in the posterior distributions and is hence simpler to implement in  Markov chain Monte Carlo (MCMC) methods. With this assumption, we can write 
\begin{equation}\label{eq:epsi}
    \boldeps \sim \No_n(0, \sigma_y^2 \bm{I}_n),
\end{equation}
where $\sigma_y^2$ is the error variance. Due to the structure of the latent variable in the model, we cannot estimate the cutoffs $\bm{\delta}$ and the error variance $\sigma^2_y$ simultaneously (see \cite{higgs2010clipped} for relevant discussions). Thus, we shall assume $\sigma_y^2$ to be known in the estimation algorithm below. 

%The author assumes that the error variance is a known quantity for the sake of identification. On the same lines of \cite{rue2000prediction} and \cite{koopman2019forecasting} we assume $\sigma_y^2$ is known. 

%(\sd{I think this paragraph can be removed to avoid unncessary comments from reviewers.}) 
%A consequence of the iid assumption is it implies that all match outcomes are independent. On the contrary, we have pairs of teams usually playing sixteen matches over eight seasons we have analyzed. It can be argued that some information can be gained by correlating the match results for all such pairs. 
%We acknowledge that having a covariance structure which incorporates the dependence between matches played by the same pair of teams is preferable. 
%We still prefer an iid construction for $\boldeps_i$ as it helps with faster convergence and gives good results. From now on, we drop the time index notation for all variables. 


\subsection{Bayesian Estimation}

We use a complete Bayesian framework to estimate the model parameters and provide a probabilistic forecast for the response variable. In that regard, suitable prior specifications are necessary and we elaborate on them below. For notational simplicity, we shall drop the time index for all variables in this section. Also, we shall be using $f(\cdot)$ to denote conditional and marginal densities in the likelihood and prior, and $\pi(\cdot)$ to denote the posterior likelihoods. 

A Gaussian prior for the covariates in a probit model is a well researched topic, cf.\ \cite{mcculloch2000bayesian}. Such a prior has been found to work well in predicting soccer match outcomes too (\cite{rue2000prediction}). Accordingly, we specify suitable Gaussian distributions as conjugate priors for $\bm\gamma$ and $\bm\beta_k$ which result in straightforward conditional posterior distributions. In particular, for the two parameter vectors in the mean structure of the model, we consider
\begin{equation}
    \bm{\gamma} \sim \No_p(\bm{0},\bm{I}_p),
\end{equation}
and %where, $\bm{I}_p$ is a $p \times p$ identity matrix. Similarly we have,
\begin{equation}
    \bm{\beta}_k= \begin{bmatrix} \beta_{k,1}^H & \beta_{k,2}^H & \cdots & \beta_{k,t}^H &  \beta_{k,1}^A & \beta_{k,2}^A & \cdots & \beta_{k,t}^A \end{bmatrix}^T \sim \No_{2t}(\bm{0}, \bm{\Sigma}_k^{(t)}),
\end{equation}
defined for each $k \in [K]$. Recall that $\bm\gamma$ is the vector of coefficients representing the effect of time-invariant covariates, whereas $\beta_{k,j}^H$ and $\beta_{k,j}^A$ (for $1 \leqslant j \leqslant t$) are the coefficients capturing the time-varying effects for the home ($H$) and away ($A$) teams respectively. In the above formulation, $\bm{\Sigma}_k^{(t)}$ is a $2t \times 2t$ covariance matrix entailing the dependence between the effects of the same type of event with respect to various time points. We now specify the structure of $\bm{\Sigma}_k^{(t)}$, assumed to be common for all events $k \in [K]$. First, we assume that there is no correlation between home ($H$) and away ($A$) team events, that is,
\begin{equation}
    \cov \left(\beta^H_{k,t_1},\beta^A_{k,t_2}\right) = 0 \; \text{for all} \; t_1,t_2 \in \Gamma.
\end{equation}
Next, to define the covariance structure common to both home and away coefficients, we assume that the dependence between occurrences of event $k$ at distinct time points $t_1$ and $t_2$ is governed by the structure
\begin{equation}
    \cov \left(\beta_{k,t_1}^H,\beta_{k, t_2}^H\right) = \cov \left(\beta_{k,t_1}^A,\beta_{k, t_2}^A\right) = g\left(\abs{t_1 - t_2}\right),
\end{equation}
where $g:\mathbb{R}\to \mathbb{R}$ is a decreasing function. Throughout this paper, we assume an exponential function for $g$, i.e.\ $g(x) \propto e^{-x}$.  We also assume that distinct events $k, k' \in [K]$ are not correlated amongst themselves.

Finally, we specify the prior distributions for the cutoffs $\delta_1,\delta_2$. Previous works such as \cite{albert1993bayesian} and \cite{liddell2018analyzing} demonstrate that Gaussian priors work well for the cut-offs in a probit model. Taking motivation from these studies, we assume
\begin{equation}\label{deltas}
    \delta_i \sim  \No(0,\tau^2), \; i \in \{ 1,2 \},
\end{equation}
where $\tau$ is a large number to ensure high variability of the prior. For the purpose of this paper, we shall always use $\tau=300$.

In order to explain the main steps of the Bayesian estimation procedure, one can note that the set of time-varying and time-invariant covariates can be combined into a single matrix denoted by $\bm{\M}$, and the proposed model in equations (\ref{eq:yspec}) and (\ref{eq:pispec}) can be rewritten as
\begin{equation}
    Y_i=
    \begin{cases}
    -1, &\mbox{if } \Pi_i < \delta_1, \\
    ~~0, &\mbox{if } \delta _1\leqslant \Pi_i \leqslant \delta_2, \\
    ~~1, &\mbox{if } \Pi_i > \delta_2. 
    \end{cases} 
    \quad \text{with} \; \; \Pi = \bm{\M}^{\top} \bm{\nu} + \bm{\epsilon}, 
\end{equation}
where $\Pi$ is the vector of outcomes of dimension $n \times 1$, and $\boldeps$ is defined the same as in \cref{eq:epsi}. Similarly, $\bm{\M}$ is a matrix of dimension $(p+2Kt) \times n$ comprising of all covariates, while $\bm{\nu}$ is a $(p+2Kt) \times 1$ vector of parameters to be estimated. Since both $\bm{\gamma}$ and $\bm{\beta}_k$ are assumed to have Gaussian priors, we can further write %combine them into a single Gaussian prior. Therefore, we have 
\begin{equation}
    \bm{\nu} \sim \No_{p+2Kt}\left(\bm{0}, \bm{\Sigma}_0\right), \; \text{where} \;
    \bm{\Sigma}_0 = \left[\begin{array}{c c c c}
    \bm{I}_p & \bm{0} & \hdots & \bm{0} \\
    \bm{0} & \bm{\Sigma}_1^{(t)} & \hdots & \bm{0} \\
    \vdots & \vdots & \ddots & \vdots  \\
    \bm{0} & \bm{0} & \hdots & \bm{\Sigma}_K^{(t)} \\
    \end{array}\right]_{(p+2Kt) \times (p+2Kt)}.
\end{equation}

% In the above, each $\bm{\Sigma}_k^{(t)}$ is the covariance matrix for the $k^{th}$ time-varying covariate for both the teams, with $k \in [K]$. 
%(\cite{dechi2019bayesian}). In this regard, we first estimate the conditional marginal distribution for the said parameters. 

For implementation purposes, we use the concepts of Gibbs sampling in this work. Recall that the Gibbs sampling scheme is a modification of the conventional Metropolis-Hastings algorithm to obtain a sample from multivariate distributions without a closed form. Interested readers are referred to the works of \cite{geman1984stochastic} and \cite{gelfand2000gibbs} for further reading on this algorithm, which relies on the principle that iterative samples from the conditional posterior distributions will lead to a sample representative of their joint distribution. We follow the Gibbs sampling procedure to obtain the joint posterior distribution of $\bm{\nu}$ and $\bm{\delta}$. 

To start with, the likelihood can be written as
\begin{equation}
    \mathcal{L}(\bm{\nu},\bm{\delta}\mid \bm{\M},\Pi, \textbf{y}) = \prod_{i=1}^n \prod_{j=1}^3 P(Y_i = j)^{\bm{1}(Y_i = j)}.
\end{equation}

Recall that $\Pi_i$ is the latent variable in the model. Moreover, for the proposed structure, we can equivalently denote $Y_i$ by an expression with $\Pi_i$ and $\bm{\delta}$. Since we employ a Gibbs sampling procedure with the latent variable, we restrict ourselves to the use of $\Pi$ and $\bm\delta$ for the estimation procedure instead of $Y_i$. For computational purposes, we treat ${\Pi}_i$ as the parameter vector, and we compute the conditional distribution of it for the Gibbs sampling steps. It is straightforward to note that the conditional posterior of ${\Pi}_i$ is given by: 
\begin{equation}
    \Pi_i \mid \bm{\M}, \bm{\nu}, \bm{\delta} \sim \mathcal{N} (  \bm{\M}'\bm{\nu}, \sigma_y^2). 
\end{equation}

Next, the choice of a Gaussian prior assumed for $\bm{\nu}$ is essential and leads to a simple closed form expression for its conditional posterior, which can be written as
\begin{equation}
    \pi(\bm{\nu}\mid \bm{\M},\Pi,\textbf{y}, \bm{\delta}) \propto \prod_{i=1}^n f(\Pi_i, \bm{\delta} \mid \bm{\nu},\bm{\M}) f(\bm{\nu}).
\end{equation}
% \begin{equation}
%     \pi(\bm{\nu},\bm{\delta}|\bm{\M},\Pi,\textbf{y}) \propto \mathcal{L}(\bm{\nu},\bm{\delta}|\bm{\M},\Pi,\textbf{y}) f(\bm{\nu}) f(\bm{\delta}).
% \end{equation}
% \begin{equation}
%     \pi(\bm{\nu}|\bm{\M},\Pi,\textbf{y}) \propto \prod_{i=1}^n f_{\Pi}(\Pi_i)  \bm{1}(\delta_{j-1} < \Pi_i < \delta_j) f(\bm{\nu}).
% \end{equation}
From our assumption of a Gaussian prior distribution, we get
\begin{equation}
    \pi(\bm{\nu}\mid\bm{\M},\Pi,\textbf{y}, \bm{\delta}) \propto \exp \left[ -\frac{1}{2\sigma^2_y} \sum_{i=1}^n (\Pi_i - \M_i^{\top}\bm{\nu})^2 \right] \exp \left[ -\frac{1}{2} \bm{\nu}' \bm{\Sigma}^{-1}_0 \bm{\nu} \right].
\end{equation}
% Simplifying each term we get,
% \begin{align*}
%     \pi(\nu|\bm{\M},\Pi,Y) &\propto \exp \left[ -\frac{1}{2} \left( -2\Pi'\bm{\M}\nu + \nu'\bm{\M}'\bm{\M}\nu + \nu'\Sigma^{-1}_0\nu - 2\beta_0'\Sigma^{-1}_0\nu \right) \right].
% \end{align*}
% Grouping the terms above with respect to $\nu$ we can write it as,
% \begin{align*}
%     \pi(\nu|\bm{\M},\Pi,Y) &\propto \exp \left[ - \frac{1}{2} \left( \nu'(\bm{\M}'\bm{\M} + \Sigma^{-1}_0)\nu - 2(\Pi'\bm{\M} + \beta_0'\Sigma^{-1}_0)\nu \right) \right].
% \end{align*}
After some algebraic simplification and comparing it to a Gaussian distribution, we observe that the conditional posterior distribution of $\bm{\nu}$ can be expressed as,
\begin{equation}
    \bm{\nu}\mid\bm{\M},\Pi,\textbf{y}, \bm{\delta} \sim \No_{p+2Kt} \left( \sigma^{-2}_y \bm{\Tilde{\Sigma}}(\bm{\M}'\Pi) , \bm{\Tilde{\Sigma}} \right), \label{postnu}
\end{equation}
where $\bm{\Tilde{\Sigma}} = (\sigma^{-2}_y \bm{\M}'\bm{\M} + \bm{\Sigma}^{-1}_0)^{-1}$. 

% We assume a Dirichlet ($\alpha_1,\alpha_2,\alpha_3$) distribution for the cutoffs $\bm{\delta} = [\delta_1 \hspace{0.2cm}\delta_2]$, where $\alpha_i > 0 ~\forall i=1,2,3$. (\rr{There is an issue with this sentence, and it needs to be written carefully and precisely. The cut-offs themselves have a Gaussian prior. The CDF corresponding to them are related to the dirichlet.}) In our model, we choose to use a Dir (2,2,2) prior due to the favorable convergence properties of its conditional marginals. 

Now, to estimate $\bm{\delta}$, we refer to the work of \cite{dechi2019bayesian}. The author establishes a correspondence between the multinomial categories through a transformation of the Dirichlet distribution. The Dirichlet distribution is a multivariate generalization of the Beta distribution with the support being a set of $l$-dimensional vectors with non-negative entries $\L$ such that $||\L||_1$ is one. These can be considered as probabilities of a multinomial outcome with $l$ categories. It is a natural conjugate for a multinomial outcome. For this paper, we assume a Dirichlet ($\alpha_1,\alpha_2,\alpha_3$) distribution with each $\alpha_i = 2$. We choose this specification due to the favourable convergence properties of its conditional marginals. The relationship between the Dirichlet parameters and the cutoffs $\delta_i$ is defined as, 
\begin{equation}
    P(\delta_i \leqslant \delta < \delta_{i+1}) = p_{i+1},
\end{equation}
where $p_{i}$ is the support of the distribution such that $\sum_{i=1}^3 p_i = 1$, and $p_i \in [0,1] \hspace{0.2cm} \forall$ $i \in \{ 1,2,3 \}$. We also define $\delta_0 = -\infty$, $\delta_3 = \infty$ for the sake of completeness. Then, the joint distribution of $\bm{\delta}$ can be written as,
\begin{equation}
    f(\bm{\delta}) = F(\delta_1)^{\alpha_1 - 1} \left[F(\delta_2) - F(\delta_1)\right]^{\alpha_2 - 1} [1 - F(\delta_2)]^{\alpha_3 - 1}\prod_{j=1}^{2}f(\delta_j),
\end{equation}
where $F(.)$ is any cumulative distribution function with $\R$ being the domain of the random variable. Simple algebraic manipulation leads to the joint conditional posterior likelihood for $\bm{\delta}$ being expressed as, 
\begin{equation}
    \pi(\bm{\delta}\mid\bm{\M},\Pi,\textbf{y},\bm{\nu}) \propto f(\boldsymbol{\delta}) \prod_{i=1}^{n} \prod_{j=1}^{3} \bm{1}(\delta_{j-1} < \Pi_i < \delta_j).
\end{equation}

We now convert the joint likelihood into marginal by conditioning on the other $\delta_j$'s. Because of the Gaussian prior for $\bm{\delta}$ in \cref{deltas}, the conditional posterior distribution for each $\delta_j$ is simply
\begin{equation}
    \pi\left(\delta_j \mid \bm{\M},\Pi,\textbf{y},\bm{\nu},\delta_{-j}\right) \propto \left[\Phi(\delta_j) - \Phi(\delta_{j-1})\right]^{\alpha_j - 1} \left[\Phi(\delta_{j+1} - \Phi(\delta_j))\right]^{\alpha_{j+1}-1} \phi(\delta_j) \bm{1}(c_{j,1} <\delta_j < c_{j,2}) \label{condpostdelta},
\end{equation}
where $c_{j,1} = \max\{\Pi_i:Y_i=j\}$, $c_{j,2} = \min\{\Pi_i:Y_i = j+1\}$ for $j = 1,2$, and $\Phi(.)$ is the cumulative distribution function (CDF) of a univariate Gaussian distribution. For our model with three categories, we define $\Phi(\delta_0) = 0$ and $\Phi(\delta_3) = 1$ for completeness. We now identify the conditional posterior CDF for $\delta_j|\delta_{-j}$. In that regard, we define $\omega = \left(\Phi(\delta_j) - \Phi(\delta_{j-1})\right)/\left(\Phi(\delta_{j+1}) - \Phi(\delta_{j-1})\right).$ Letting $\Phi(\delta_{j-1}) = a$ and $\Phi(\delta_{j+1}) = b$, we can write $\delta_j = \Phi^{-1}((b-a)\omega +a)$. Utilizing the distribution of $\delta_j$, with regard to the distribution of $\omega$, it can be defined as  $f(\omega) = \pi_{\delta}(\delta_j) \frac{\partial \delta_j}{\partial \omega}$,
where $\pi_\delta(.)$ is the unconditional posterior distribution of $\delta_j$.  By substituting the form of $\delta_j$ in \cref{condpostdelta}, we can obtain the expression %for $\pi_\delta(.)$ as: 
\begin{equation}
    \pi_{\delta}\left(\Phi^{-1}((b-a)\omega + a)\right) \propto \left(\Phi(\delta_j) - a\right)^{\alpha_j-1} \left(b - \Phi(\delta_j)\right)^{\alpha_{j+1}-1}\phi(\delta_j).
\end{equation}
A simple algebraic simplification of the above equation and ignoring terms without $\omega$ leads us to,
\begin{equation}
        \pi_\delta(\delta_j) \propto \omega^{\alpha_{j}-1}(1-\omega)^{\alpha_{j+1}-1}\phi(\delta_j). \label{postdelta}
\end{equation}
The derivative of $\omega$ with respect to $\delta_j$ is simply given by $\frac{\partial\omega}{\partial\delta_j}= \frac{b-a}{\phi(\delta_j)}$. 
Now that we have obtained simplified expressions for the terms required to identify $f(\omega)$, one can argue that
\begin{equation}
    f(\omega) \propto \omega^{\alpha_{j}-1}(1-\omega)^{\alpha_{j+1}-1}\phi(\delta_j) \times \frac{b-a}{\phi(\delta_j)}. 
\end{equation}
Simplifying the above expression and comparing it to a Beta distribution, we get
\begin{equation}
    \omega \sim \mathrm{Beta}(\alpha_j,\alpha_{j+1}). \label{omegaa}
\end{equation}
In this manner, we can now incorporate the parameters of the Dirichlet distribution, namely $\alpha_j$, in the distribution of $\delta_j$ through a closed-form expression for $\omega$. Hence, the conditional posterior distribution of $\delta_j$ can be expressed as
\begin{equation}
\Phi(\delta_j \mid \bm{\M},\Pi,\textbf{y},\bm{\nu}, \delta_{-j}) \sim [\Phi(\delta_{j+1}) - \Phi(\delta_{j-1})] \mathrm{Beta}(\alpha_j,\alpha_{j+1}) + \Phi(\delta_{j-1}).
\end{equation}

Note that $\Phi(\delta_j)$ will be truncated from below and above by $\Phi(c_{j,1})$ and $\Phi(c_{j,2})$ respectively. Let us use the shorthand notation $\Phi_{\delta_j}$ to denote the conditional distribution of $\delta_j$ given the other cutoffs. Therefore, in the modelling setup above, in the case of three ordered categories we obtain the following set of conditional posterior distributions:
\begin{equation}\label{postdeltafinal}
\begin{split}
    \Phi(\delta_1 \mid \delta_2,\bm{\M},\Pi,\textbf{y},\bm{\nu}) &\sim \Phi(\delta_2) \mathrm{Beta}(\alpha_1,\alpha_2) \hspace{3.5cm} \Phi(c_{1,1}) \leqslant \Phi_{\delta_1} \leqslant \Phi(c_{1,2}), \\
    \Phi(\delta_2 \mid \delta_1,\bm{\M},\Pi,\textbf{y},\bm{\nu}) &\sim [1 - \Phi(\delta_1)] \mathrm{Beta}(\alpha_2,\alpha_3) + \Phi(\delta_1) \hspace{1.25cm} \Phi(c_{2,1}) \leqslant \Phi_{\delta_2} \leqslant \Phi(c_{2,2}).
\end{split}
\end{equation}

Now that we have the closed-form expressions for all the conditional posterior distributions corresponding to the unknown parameters in the model, we can implement the Gibbs sampling algorithm to sample from the joint posterior distribution. Following the principles of this algorithm, we need to sequentially sample from the distributions of $(\Pi \mid \bm{\nu},\bm{\delta})$, $(\bm{\nu} \mid \Pi,\bm{\delta})$ and $(\delta_j \mid \delta_{-j},\Pi,\bm{\nu})$ until convergence. We use the Gelman-Rubin statistic to assess the convergence, and it is explained below. After the Markov chains in the Gibbs sampler converge, we can obtain a sample from their joint distribution. To ensure the independence of the observations we draw samples from sufficiently distant iterations. The steps followed in the implementation of the Gibbs sampling procedure are now summarized in Algorithm \ref{alg:one}. 

\RestyleAlgo{ruled}
\begin{algorithm}[h!]
\caption{Gibbs sampler for the posterior distribution in the proposed model}\label{alg:one}
\textbf{Input}: Dataset ($\textbf{y},\bm{\M}$) where, \textbf{y} is the multinomial outcome variable and $\bm{\M}$ is the set of covariates. \\
\textbf{Output}: A sample of size S from the posterior distribution of the tuple $(\Pi_i,\bm{\nu},\bm{\delta})$ \\
\textbf{Initialize}: $\Pi^{(0)}$, $\bm{\nu}^{(0)}$ and $\bm{\delta}^{(0)}$. Let $\mathcal{C}$ be the convergence criteria. \\
%To obtain sample for the $m^{th}$ iteration :  \vspace{0.3cm}\\
Let $m \gets 1$ \\
\While {$\mathcal{C}$ not met} 
%\For {S iterations} 
{\vspace{0.2cm}  Sample from $\Pi_i^{(m)} \mid \bm{\nu}^{(m-1)},\bm{\delta}^{(m-1)}  \sim \No(\bm{\M}'\bm{\nu}^{(m-1)}, \sigma^2_y)$ \\ \vspace{0.3cm} 
Sample from $\bm{\nu}^{(m)} \mid \Pi^{(m)},\bm{\delta}^{(m-1)} \sim \No(\Tilde{\bm{\nu}}^{(m)},\bm{\Tilde{\Sigma}})$, where $\Tilde{\bm{\nu}}^{(m)}$ is the updated mean of the conditional posterior distribution after observing $\Pi^{(m)}$ \\ \vspace{0.3cm} 
\ForEach {$j \in \{1,2\}$} {\vspace{0.2cm} Sample from  \vspace{0.2cm} \\
$\Phi(\delta_j^{(m)}) \mid \bm{\delta}_{(-j)}^{(m-1)},\Pi^{(m)},\bm{\nu}^{(m)} \sim [\Phi(\delta_{j+1}^{(m-1)}) - \Phi(\delta_{j-1}^{(m)})] \mathrm{Beta}(\alpha_j,\alpha_{j+1}) + \Phi(\delta_{j-1}^{(m)})$  \vspace{0.3cm}\\
with, $\Phi(\delta_j^{(m)}) \in [\Phi(c_{j,1}), \Phi(c_{j,2})]$ \\
\vspace{0.3cm}} Let $m \gets m + 1$}
% \EndWhile 
\normalfont{Discard these first M iterations (until $\mathcal{C}$ is met) as burn-in sample}. \\
Continue the iteration procedure given above until we reach iteration $M+S$. The requisite sample is obtained from iterations $M+1$ to $S$.
\end{algorithm}

In order to assess the convergence of the Gibbs sampler, we use the \cite{gelman1992inference} statistic, hereafter abbreviated as GR statistic. In this diagnostic approach, multiple chains are generated using the Gibbs sampler, each with a set of different initial values. Since all chains are theoretically guaranteed to converge, the GR statistic makes use of the within and between-chain variances to infer about the convergence of the Markov chains, under the same principles as ANOVA. To elaborate, let $\{\theta_{i1}, \theta_{i2}, \dots \theta_{ip}\}$, for $i = 1,2,\dots, m$, be a posterior sample of $p$ number of parameters, coming from a set of $m$ parallel chains. Then, the within-chain variance ($W$) and the between-chain variance ($B$) are defined as
\begin{equation}\label{eq:within-between-var-GR}
    W = \frac{\sum_{i=1}^m \sum_{j=1}^{n} (\theta_{ij} - \Bar{\theta}_{i\cdot})^2}{m (n-1)}, \; B = \frac{n \sum_{i=1}^m (\Bar{\theta}_{i\cdot} - \Bar{\theta}_{\cdot\cdot})^2}{m-1},
\end{equation}
where $\Bar{\theta}_{i\cdot}$ is the mean for the $i^{th}$ chain and $\Bar{\theta}_{\cdot\cdot}$ is the overall mean. Subsequently, the GR statistic is given by
\begin{equation}
    \hat{R} = \sqrt{\frac{(n-1)W/n + B(m+1)/(mn)}{W}}.
\end{equation}

A value of $\hat{R} <1.1$ for the GR statistic is assumed to be good enough to indicate convergence. We draw a sample for the posterior distribution after the chains converge. 



\subsection{Predictive analysis}%on, evaluation and comparison}
\label{subsec:comparison}

It is important to note that the methodology developed above is primarily used to forecast the match outcome after every time-point. We explain this within-game forecasting technique in this subsection. 

Consider that the model needs to be trained on the dataset $\mathcal{S}_{tr}$, and let the test dataset be $\mathcal{S}_{te}$, with $\abs{\mathcal{S}_{te}}=m$. We shall compare the evaluation metrics (to be elaborated below) for our model as well as for other potential models (discussed later) using the test data. Suppose, we wish to obtain the in-game predictions for the $i^{th}$ match in $\mathcal{S}_{te}$. We shall compute this as a function of $t\in \Gamma$. We know that data are recorded on various events such as goals, corners, cards etc., which take place every single minute. This renders a minute-by-minute record of events which have occurred till time $t$. Following the same notations as before, for the training data, let the set of covariates after time $t$ be denoted as $\bm{\M}$, and the entire training data as $\mathcal{D} = \{\bm{\M},\textbf{y},\Pi\}$. Our aim is to implement the proposed model on $\mathcal{D}$ to predict the outcome of the $i^{th}$ match in $\mathcal{S}_{te}$, after $t$ minutes have passed in the match. Let us use $\hat{\Pi}_i^{(t)}$ to denote the estimated latent variable in this regard, and define the vector $\hat{\Pi}^{(t)} = [\hat{\Pi}_1^{(t)},\dots,\hat{\Pi}_m^{(t)}]'$ which furnishes the forecasts for all matches in the test dataset at time $t \in \Gamma$. 

As a general notation, let the set of covariates corresponding to the test set be $\bm{\M_*}$. Then, $\hat{\Pi}^{(t)}$ can be obtained from the posterior predictive distribution that estimates the probabilistic structure of the outcome variable given a new set of covariates. It incorporates the variability in the parameters by weighting the likelihood of $\hat{\Pi}^{(t)}$ by the posterior distribution of the parameters. For our model, we can write
\begin{equation}\label{eq:posterior-predictive}   
\pi\left(\hat{\Pi}^{(t)} \mid \bm{\M_*},\mathcal{D}\right) = \int_{\bm{\nu}} f\left(\hat{\Pi}^{(t)} \mid \bm{\M_*},\mathcal{D},\bm{\nu}\right) \pi(\bm{\nu} \mid \mathcal{D}) \, d\bm{\nu}.
\end{equation}

% We will now elaborate on the comparisons made in the paper and the metrics used to evaluate the models. We also have the posterior distribution of $\Pi$. This can be used to obtain


Here, the distribution of the forecasts for the test data is conditional on the training data $\mathcal{D}$ and the posterior distribution of $\bm{\nu}$. The first term in the expression is simply a likelihood taking a Gaussian form, due to \cref{eq:epsi}. The second term is the posterior distribution of $\bm{\nu}$ given by \cref{postnu}. The above expression can be simplified since both are normally distributed. Thus, the posterior predictive distribution for $\hat{\Pi}^{(t)}$ can be simplified as
\begin{equation}
    \pi\left(\hat{\Pi}^{(t)} \mid \bm{\M_*},\mathcal{D}\right) \sim \No \left( \sigma^{-2}_y \bm{\M}_*^\top \bm{\Tilde{\Sigma}}(\bm{\M}'\hat\Pi) , (\sigma^{-2}_y\bm{I}_m + \bm{\M}_*^\top \bm{\Tilde{\Sigma}} \bm{\M}_*) \right), \label{postpred}
\end{equation}
where $\bm{\Tilde{\Sigma}}$ is the posterior covariance matrix of $\bm{\nu}$. As stated above, the estimate of the latent variable, denoted by $\hat{\Pi}$, for the training set can be obtained from the posterior sample through the Gibbs sampler outlined in Algorithm \ref{alg:one}. We also estimate $\bm{\Tilde{\Sigma}}$, and the cutoffs $\hat{\bm\delta}$ from the posterior samples. Now, in order to predict the outcome, one can obtain a sample from the above posterior predictive distribution, and use that along with the cutoffs to get $\hat{Y}_i^{(t)}$ as the predicted category based on the data up to time $t$. Moreover, the probabilities of the different categories for the outcome variable, corresponding to the home team, can be calculated as
\begin{equation}\label{eq:predicted-prob}
\begin{split}
    &P\left(\text{Win}\right) = 1- \Phi_{\hat{\Pi}_i}(\hat{\delta}_2), \\
    &P\left(\text{Draw}\right) = \Phi_{\hat{\Pi}_i}(\hat{\delta}_2) - \Phi_{\Pi_i}(\hat{\delta}_1), \\
    &P\left(\text{Loss}\right) = \Phi_{\hat{\Pi}_i}(\hat{\delta}_1),
\end{split}
\end{equation}
where $\Phi_{\hat{\Pi}_i}$ is the Gaussian cumulative distribution function of $\hat{\Pi}_i$. We are going to use $\hat{Y}_i^{(t)}$ and the derived probabilities in \cref{eq:predicted-prob} to evaluate the forecasting accuracy of the proposed methodology. It is important to reiterate that the evaluation metrics will be computed for the vector of $\hat{\Pi}_i^{(t)}$ for every time point $t \in \Gamma$. 

In the main application of this article, for the completeness of the study, we are going to compare our model with a few other potential approaches. We highlight that there is no existing work on the topic of within-game forecasting in soccer, but we rely on different algorithms that have been used for predictive modelling in different capacities and extend them to develop competing approaches in our context. The first one in this regard is a version of the generalized linear model (GLM). We train the GLM in a standard probit regression framework by considering the data on the available covariates up to time $t$ for all matches, and predict the outcome in the test set based on that. Thus, on the same lines as our proposed method, the GLM needs to be trained after every time point $t \in \Gamma$, and the forecasts are updated accordingly. %The obtained forecasts for the test data $\hat{\Pi}$ are used to compute the evaluation metrics for each of the models.

We next refer to the work of \cite{baboota2019predictive}, who identified a set of features which highly influence the result of a soccer match, through extensive feature engineering and selection. The authors used support vector machine (SVM) and random forest algorithms for predicting the outcome of the match. Although not used in a temporal within-game setting, we consider these models as competitors to our model due to their flexibility in implementation. The covariates selected for modelling by the authors are similar to ours, which serve as another motivation for choosing them as competitors. Note that SVMs are very flexible supervised-learning models, usually used for classification problems. In the comparison study below, when we employ the SVM as one of the contenders, we employ two types of SVMs with respect to the kernel used for modelling, which is one of the most important hyper-parameters in this algorithm. For the first model, we assume linearly separable classes and we shall denote it as Linear SVM below. In the second case, a Gaussian radial basis function is used to incorporate non-linearity in the model. This model will be abbreviated as RBF SVM hereafter. The R library \texttt{caret} is used for tuning both models. 

As the fourth model in the comparative discussions, we modify the standard random forest (RF) algorithm, typically used in various classification problems related to soccer. This tree-based algorithm is widely implemented due to its tendency to incorporate dependencies between the covariates in the model. The performance of the random forest algorithm usually depends on finding the precise hyper-parameter. The two most pivotal hyper-parameters are the number of trees and the number of variables to possibly split a node. In order to find the optimal choices of these hyper-parameters, we employed a grid search technique for tuning. As the set of possible features in this algorithm, akin to the other contending approaches, we use the same combination of covariates, the information being available up to time $t$ in every match. 

In order to compare the performances of different algorithms mentioned above, we first rely on the F1-score. It is a standard evaluation criterion of prediction accuracy for a categorical outcome variable, and is essentially the harmonic mean of sensitivity (recall) and specificity (precision). It ranges from zero to one, the latter depicting better accuracy. Below, we define this measure for our proposed model, and a similar computation will be done for the other competitors as well. To avoid notational jargon, we also remove the superscripts indicating the forecast made at time $t$, and it is understood throughout that the metrics are computed as a function of time during the progression of the match.

Let $\hat{\Pi}_{i}$ be the predicted value of the latent variable for the $i^{th}$ match. Following the definition of the categorization, we can determine $\hat{Y}_{i}$ as $j$ if $\hat{\delta}_{j-1} \leqslant \hat{\Pi}_{i} < \hat{\delta}_j$. Then, for the $j^{th}$ outcome category $\mathcal{C}_j$, the confusion matrix for the test set is reduced to a $2 \times 2$ matrix given by
\begin{equation}
\begin{blockarray}{cccc}
 & & \mathcal C_j & \mathcal C_{\neq j}  \\
\begin{block}{cc[cc]}
& \mathcal C_j & a_{j,11}  & a_{j,12} \bigstrut[t] \\
& \mathcal C_{\neq j} & a_{j,21} & a_{j,22} \bigstrut[b]\\
\end{block}
\end{blockarray},
\end{equation}
where $a_{j,11}$ indicates the total number of matches in the test set where correct classification is made in the $j^{th}$ category, and so on. From this confusion matrix, sensitivity and specificity are then defined as
\begin{equation}
    \mathrm{Sen}_j = \frac{a_{j,11}}{(a_{j,11}+a_{j,21})}, \; \mathrm{Spc}_j = \frac{a_{j,22}}{(a_{j,12}+a_{j,22})}.
\end{equation}
    
Subsequently, the F1-score is computed as
\begin{equation}
    \mathrm{F1}_{j} = \frac{2 (\mathrm{Sen}_j)(\mathrm{Spc}_j)}{\mathrm{Sen}_j + \mathrm{Spc}_j}.
\end{equation}

Note that the F1-score is computed for each outcome category separately. This enables us to identify biases in forecasts with regard to the classes, if any. A high F1-score implies that the model can consistently forecast the correct outcome. 

%We denote $F_{1i}^{(t)}$ as the F1-score for class $i$ at time $t$. 
%This measure can also be represented visually by a conventional confusion matrix for each class.

%However, as several researchers (e.g.\ 

One of the criticism with the F1-score is that it gives larger weight to smaller classes, and it favors models with similar sensitivity and specificity. It is imperative to use another criteria to evaluate the predictive accuracy of the models. Following the discussions by \cite{czado2009predictive} and \cite{kolassa2016evaluating} who pointed out the need to take into account the probability with which the forecast is made in similar problems, we are going to use the Brier score. It is a widely used scoring rule for multi-class prediction problems with mutually exclusive classes. The reader is referred to the works by \cite{brier1950verification} and \cite{murphy1973new} for the definition and related discussions on the Brier score. The scoring mechanism takes into account the probabilities of classification and compares them against the observed outcome. Recall the predicted probabilities in \cref{eq:predicted-prob} and let $\hat{p}_{ir}$ be the value corresponding to the $r^{th}$ category, for the $i^{th}$ match in $\mathcal{S}_{te}$. Then, the Brier score for the test set is given by
\begin{equation}
    \mathrm{Brier ~ score} = \frac{1}{m}\sum_{i=1}^{m} \sum_{r \in R} \left(\hat{p}_{ir} - \bm{1}(Y_i = r)\right)^2.
\end{equation}

Evidently, a lower Brier score implies a better predictive performance of the model. As mentioned before, these evaluation criterion will be reported for the competing models, for every minute $t \in \Gamma$ of the match.


% at time $t$, i.e.\ %Define $p_{ir}$ as,
% \begin{equation}
%     \hat{p}_{ir}^{(t)} = \begin{cases}
%      \Phi_{\hat{\Pi}_i}(\hat{\delta}_1) \hspace{2cm} \mbox{if } r = -1, \\
%      \Phi_{\hat{\Pi}_i}(\hat{\delta}_2) - \Phi_{\hat{\Pi}_i}(\hat{\delta}_1) \hspace{0.3cm} \mbox{if } r = 0, \\
%      1- \Phi_{\hat{\Pi}_i}(\hat{\delta}_2)\hspace{1.4cm} \mbox{if } r = 1.
%     \end{cases}
% \end{equation}

% It is important to note that we evaluate these probabilities at every time point $t \in \Gamma$, but for convenience, we are dropping the superscripts on $\hat{\Pi}_i^{(t)}$ and $\hat{\delta}_j^{(t)}$. \\
% We also define an indicator variable $o_{ir}$ for the $i^{th}$ match and $r^{th}$ category of outcome as
% \begin{equation}
%     o_{ir} = \begin{cases}
%     1 &  \mbox{if } Y_i = r, \\
%     0 &  \mbox{if } Y_i \neq r.
%     \end{cases}
% \end{equation}
% Note that this is independent of $t$ since it is the true outcome of the match.

%We sequentially estimate the model after every minute $t$ of the match with the appropriate set of covariates. Therefore we can obtain a model evaluation measure for each time-point in the match.



\section{Data}\label{sec:data}

\subsection{Description}

In this article, we use the data from English Premier League (EPL) matches from the 2008-09 season to the 2015-16 season. It is extracted from the European Soccer Database (ESD) which is available on Kaggle (link: \url{https://www.kaggle.com/datasets/hugomathien/soccer}). 

EPL is the top division in the English soccer system. Every season, 20 teams play in a double round-robin format, and in the end, the bottom three teams are relegated to the English Football League (EFL). To maintain the 20 team format, the top three teams from EFL are promoted to play in the EPL for the next season. Such a structure results in the total number of matches recorded over 8 seasons being $3040$. It is important to mention that it is not the same 20 teams playing in the EPL year on year and consequently the dataset has a total of 34 teams, each playing a varying number of seasons. One should note that the league matches finishing in tied scores by the end of regular time (90 minutes) do not go into extra-time or penalty shootouts. This enables an ordinal multinomial outcome with three categories. To analyze this dataset, we use a multinomial response variable to illustrate the match result for the team playing at home. As mentioned earlier, the covariates in the model are of two types: time-invariant covariates and time-varying ones. For the latter, remember that the dataset reports different types of events happening in every match, with their corresponding times of occurrence. We use eight such events in the model as time-varying covariates. These are goals, shots-on-goal, shots-off-goal, red cards, yellow cards, corners, crosses and fouls. Each event $k$ has an associated vector of covariates as defined in \cref{eq:pispec}. 

Regarding the time-invariant covariates, we consider the strength of the playing elevens for both teams. In order to define this, we rely on the ESD that records the overall rating for each player in the league, updated periodically based on their real-life performances on different parameters. These ratings consider 33 types of skills of the players, and the details can be found in the aforementioned link. Based on the information on the eleven players who start a game for each team, we compute the covariate depicting the overall strengths of the team. Specifically, the average of the ratings of the players in the starting eleven is computed based on the players' ratings at the beginning of the match. We point out that due to the absence of substitution data, the strength variable is assumed to be fixed over the course of the match and thus, we classify it as a time-invariant covariate. 

A brief discussion on the motivation behind the above choices is of the essence here. Previously, \cite{gonzalez2019effect} and \cite{gomez2018analysis} showed that the strength of a team based on its players and team rankings is useful in predicting the outcomes. Many other studies have used various events at an aggregate level as regressors for predicting match outcomes in soccer. \cite{liu2015match}, for example, used a generalized linear model to identify key winning indicators from 24 different event types from World Cup data. The authors identified shots, shots-on-target, tackles, red cards and crosses as important events which influence the result of a match. An interesting finding is the negative impact of crosses, which corroborates \cite{vecer2014crossing} who demonstrated through a multilevel Poisson regression model that crosses indeed have a negative impact on the goals scored by a team. Earlier, \cite{castellano2012use} used discriminant analysis to infer about various attack and defence attributes with regard to their effect on the result. Total shots and shots on target were found to have the greatest discriminatory power amongst the variables used. In more recent studies, \cite{ashimolowo2018econometric} investigated the association of crosses, corners, free kicks and the number of shots-on-goal with the outcome of a soccer match, whereas \cite{vcerveny2018effects} modelled the effect of a card on the goal-scoring rate of a team through a proportional hazard model. 




\subsection{Exploratory analysis}\label{subsec:exploratory}

Before moving on to the main analysis, we find it imperative to present the descriptive statistics of the covariates used in the model. \Cref{tab:decriptive} displays the summary statistics of these variables, for both home and away teams. We report the mean and standard deviation per game, along with the percentage of matches with no events of that type.

\begin{table}[!ht]
\centering
\caption{Summary of the covariates used in the analysis. Mean and standard deviation (SD) are computed per game, whereas the zeros column indicates the percentage of matches with zero cases.}
\label{tab:decriptive}
\begin{tabular}{ccccc}
     \hline
     & \multicolumn{2}{c}{\text{Home}} & \multicolumn{2}{c}{\text{Away}} \\
     \hline
    \text{Variable} & Mean (SD) & Zeros (\%) &   Mean (SD) & Zeros (\%) \\ 
    \hline
    Goal & 1.551 (1.312) & 22.829 & 1.160 (1.145) & 34.309 \\
    Shot-on & 6.684 (3.512) & 0.559 & 5.274 (2.936) & 2.072 \\
    Shot-off & 6.606 (3.091) & 0.428 & 5.212 (2.678) & 1.349 \\
    Red Card & 0.065 (0.254) & 93.717 & 0.097 (0.312) & 90.822 \\
    Yellow Card & 1.418 (1.170) & 24.243 & 1.802 (1.286) & 15.757 \\
    Corner & 10.196 (5.810) & 1.283 & 8.048 (5.080) & 2.368 \\
    Cross & 16.128 (7.609) & 0.066 & 12.448 (6.243) & 0.329 \\
    Foul & 10.691 (3.546) & 0 & 11.398 (3.687) & 0 \\
    Team Strength & 76.081 (3.784) & - & 75.843 (3.871) & - \\
    \hline
\end{tabular}
\end{table}    

We observe that the average number of goals scored by the home teams is slightly more than that by the away teams. This home advantage can be further illustrated by the fact that a home team is held scoreless in about $23\%$ of the matches as opposed to $34\%$ for the away team. This difference is a result of more shots-on-goal being taken by the home team. Identical observations can be made about shots-off-goal as well. When it comes to corners, the home team is awarded two more corners than the away team on average. Average crosses per the game trend in the same direction with the home team averaging four extra crosses. However, one may note that the strength variable, as expected, does not appear to be significantly different between the home and the away teams.

Coming to the disciplinary covariates, red cards are found to be infrequent events. In EPL, a red card is shown less than once in every ten matches on average. Comparing the raw per-game numbers, we observe that the away team is 1.5 times more likely to get a red card than the home team. Although the difference in yellow cards per game for the home and away teams is much smaller, the event of no yellow cards being shown in a match happens in nearly $10\%$ more matches for the home team as compared to the away side. In terms of the number of fouls, we observe a similar trend but to a lesser extent. One can possibly attribute these differences to refereeing bias towards the home team (\cite{boyko2007referee}).

We further illustrate the nature of the time-varying covariates in the proposed model. To that end, \Cref{fig:summary-covariates} provides valuable insights into the aggregate number of events over the course of a match for both teams. In these plots, the total number of events for each type, computed from the entire dataset of 3040 matches, are presented. 

\begin{figure}[!h]
    \centering
    \caption{Aggregate number of events (computed for 3040 matches in the dataset) of different types over the course of a match for home and away teams.}
    \label{fig:summary-covariates}
    \includegraphics[width = 0.8\textwidth,keepaspectratio]{Summary_8.pdf}
\end{figure}

A striking feature, for all the events, is the spike observed at the $45^{th}$ minute and the $90^{th}$ minute. This phenomenon is related to the fact that stoppage time is provided to compensate for any delays that may have occurred during the preceding half, and during this time, typically all teams tend to play with high intensity. We also want to point out that in this analysis, any event occurring in stoppage-time is reported corresponding to the last minute of the half, that is with the $45^{th}$ or the $90^{th}$ minute as appropriate, and therefore we are unable to assess any potential impact of the stoppage time on the outcome variable. 

Among the specific covariates, the pattern of the number of cards given as a function of time appears to be interesting. We observe that the frequency of yellow cards being handed out significantly increases as a match progresses. A similar increasing trend is observed in the case of red cards, albeit at a much slower rate. The difference in means between home and away teams for red cards can largely be attributed to the spike of the red cards given to the away team in stoppage time. However, no such trend has been found in cases of fouls, potentially hinting at the referees becoming stricter in their rulings, or a higher degree of aggressive play by both teams towards the end of the matches. We observe a systematic difference in the number of crosses and shots taken over time. This consequently results in an increased difference in the number of corners and the goals scored between the home and away teams. Interestingly, these differences are constant over time, but as we shall see in the main analysis, they are expected to have a differential impact on the final outcome of the game. 


%takes the temporality of an event which impacts the outcome and not just it's aggregate occurrences. 

% \begin{table}[h]
%     \centering
%     \begin{tabular}{|c|c|}\hline
%          \textbf{Outcome} &  \textbf{Frequency}\\ \hline
%          Loss & 867 \\ \hline
%          Draw & 783 \\ \hline
%          Win & 1390 \\ \hline
%     \end{tabular}
%     \caption{Outcome Frequencies for Home team}
%     \label{tab:my_label3}
% \end{table}


\section{Results and Discussion}\label{sec:results}

\subsection{Primary results}

For the main analysis, the focus is on understanding the predictive accuracy of the proposed methodology. In order to assess that, we split the dataset -- $90\%$ of the data are used for training the model, while the remaining $10\%$ are used as the test data. The results reported in this section correspond to this split, whereas in \Cref{subsec:robustness} we shall check the robustness of the algorithm by considering different training and test datasets. All calculations are carried out using RStudio Server 2022.02.3 (R version 4.2.0). The library \texttt{future.apply} is used for parallel computing while \texttt{e1071} and \texttt{ranger} are used for the competing models.

The prior specifications and the Gibbs sampling steps are detailed in \Cref{sec:methodology}. As stated there, the Gelman-Rubin statistic is used as a diagnostic test for convergence. It is observed that the chains converge after approximately 7000 iterations. Thus, for practical implementation of the same, in order to obtain the posterior sample for the model parameters, we iterate 10,000 times and use a burn-in period of 7000 iterations in all applications. We restate that the goal is to forecast the match result in-game, that is when minute-by-minute data for the covariates are recorded in real-time. In line with this idea, we estimate the model with the time-varying covariates taken up to the $t^{th}$ time point for each $t \in \{1,2,\hdots,90\}$. We further forecast the match results for the test data for every such model using the mean of the posterior predictive distribution. Following the aforementioned notations, we use $\hat{\Pi}_{it}$ to obtain the predicted outcome of $i^{th}$ game when $t$ minutes of the match has passed, that is, the covariate information is available upto time $t$. 

We first examine the posterior estimates of the covariate effects in the model. From the posterior samples obtained from the proposed algorithm, we find the posterior means and the credible intervals for each parameter. In the case of the time-invariant covariates, the impact of the team strength is found to be substantial for both home and away teams. The coefficient of the home team is obtained to be 16.2, with the 95\% credible interval being $(12.76, 19.71)$. The same for the away team are $-15.6$ and $(-19.03, -12.13)$, respectively. As expected, one can see that the effect of home strength and away strength are relatively equal and of opposite signs. Next, in \Cref{fig:betas}, we demonstrate the temporal variation in the impact of various events on the probability of winning for the home team. A positive value implies an increase in the win probability by more occurrences of the event at that time-point, whereas a negative coefficient implies otherwise.


\begin{figure}[!h]
       \centering
       \caption{Effect of each event on the outcome of the match captured at every time-point for both teams. The estimates displayed herein are from the model with complete match data.}
       \includegraphics[width = 0.8\textwidth,keepaspectratio]{Beta_est.pdf}
       \label{fig:betas}
\end{figure}

Goals are naturally the best indicator of the outcome of a match, as can be gleaned from the figure. We can observe an increasing effect of goals scored in the latter stages of the match as compared to the initial minutes. This phenomenon can be rationalized by the fact that a team has less time to respond when a goal is scored towards the end. The findings align with the results from \cite{castellano2012use}, \cite{vcerveny2018effects} and \cite{rocha2021influence}. Next, the variables shots-on-goal and shots-off-goal exhibit marginal influence on the outcome of a soccer match. Their impact is typically found to be negligible throughout the timeline. This can be attributed to the inclusion of goals scored as an event, which might capture most of the variability explained by shots-on-goal and shots-off-goal.

When it comes to cards, both red and yellow cards are usually negatively associated with the outcome. Specifically, a red card for any home is found to have a detrimental effect on their chances of winning, making it the second most crucial event in a soccer match. It is noteworthy that red cards, akin to goals, have a significant effect on the result over the course of the match; whereas yellow cards generally do not render deciding impact. With regard to temporal fluctuations, a red card awarded to the opponent in the latter stages of the match is more advantageous for the home team as compared to the away team. 

Corners, though deemed advantageous in a soccer match (\cite{ashimolowo2018econometric}), do not prove to be as effective in forecasting the outcome. Our findings are contrary to the common notion that corners are significant factors when awarded in the dying stages of a match. This is especially true in the $90^{th}$ minute and stoppage time where getting a corner does not impact the outcome in any significant manner. A contrasting behaviour is observed in the effect of a cross, which is conventionally a long-range pass made towards the opponent's goal from the two sides of the field. For the majority of the match, the influence of a cross on the outcome is discovered to be negligible, but after the $75^{th}$ minute, this changes. As time winds down, teams tend to be more aggressive and push for a goal. This usually leads to more long balls and crosses, and an inaccurate cross may result in a decisive counterattack on the other end, which is usually the case. Interestingly, this phenomenon is captured by the model which estimates a significant negative impact of crosses towards the end of the match for both teams. The negative influence of crosses keeps on increasing till the end. It is imperative to recall that this observation conforms with the results of \cite{vecer2014crossing} and \cite{liu2015match}, as discussed earlier.

We now move on to the results of the predictive accuracy, the main focus of this article. The F1-scores and the Brier score, as defined in \Cref{subsec:comparison}, are displayed in \Cref{fig:my_label}. These accuracy metrics are computed as averages, based on the predicted outcomes at each time point of the matches in the test set. We report the values for our method, along with the same for each of the four competing models.

\begin{figure}[h!]
    \centering
    \caption{F1-score and Brier score (averaged over the test set) for different models, with respect to their within-game forecasting accuracy as a soccer match progresses}
    \includegraphics[width = 0.9\textwidth,keepaspectratio]{Metric1.pdf}
    \label{fig:my_label}
\end{figure}

F1-score, as discussed before is determined for every outcome category independently. When the match result is a loss for the home team, we observe a distinctly higher F1-score for our model as the match unfolds. A similar trend is observed for the wins as well. Contrary to that, if the final outcome is a draw, the proposed method outshines its competitors throughout the time frame of the match. The linear SVM is the second-best-performing model in such cases.

To elaborate on the behaviour of the F1-scores thus obtained, one may argue that the competitor models weigh the effects of the goals in a much more severe manner as compared to the proposed model. Our model does not rely that heavily on goals and incorporates the effect of other events while forecasting. As a direct consequence of this, the proposed model performs much better than all the contender models while predicting drawn games. Also, in games where the scores are level, other covariates, such as team strength, home advantage, and player performance, are likely to have a greater impact on the forecast outcome which plays to our models' strengths. We emphasize that the aversion to relying heavily on the number of goals scored is unique to our model. This effect is further reflected upon in the case studies in \Cref{subsec:specific-examples}. Moreover, due to the availability of more covariate information, it is observed that in the latter stages of the match, our model provides uniformly better predictions than the rest. % When comparing scores across outcomes it is not surprising that the model would be able to predict decisive outcomes such as wins or losses better than draws due to the effect of goals as a covariate.

% , especially in the early minutes of the game when there are fewer goals to differentiate the teams. In these situations, other covariates, such as team strength, home advantage, and player performance, are likely to have a greater impact on the forecast outcome. As the game progresses and more goals are scored, the effect of these covariates may become less dynamic and the models ability to predict decisive outcomes becomes similar to its ability to predict draws. This behaviour is reflected in the F1-scores as well. The models emphasis on home team goals may explain the observed disparity in the F1-scores between wins and losses for the home team especially in the early stages of a match. 

A look at the plot for Brier score tells a similar story. We emphasize that this scoring rule incorporates the predicted probability of the outcome for model evaluation. Generally, lower values are recorded by our method, but the scores are still comparable until the end of the first hour, following which the Bayesian approach stands out from its competitors until the end of the match. Akin to the earlier argument, we believe that the proposed model's performance is considerably better during the second half as it utilizes more available data in a better way. A peculiar observation can be made about the behaviour of GLM. Even though its F1-score does not display major irregularities, a significant spike in the Brier score is observed during the latter stages, likely due to its over-dependence on the number of goals. Overall, we can conclude that our model registers greater accuracy with more certainty than the contenders.  %along with predicting them with higher probabilities.



\subsection{Robustness of the analysis}\label{subsec:robustness}

To further support our previous results, we conduct a few robustness checks. One way to evaluate the heterogeneity in model forecasts is to compare the forecast accuracy based on the strength of a team. In that aspect, we split the set of EPL teams into two groups -- `Big 6' (consisting of Arsenal, Chelsea, Liverpool, Manchester City, Manchester United, Tottenham) and the rest. These `Big 6' teams are known for their large payrolls and fan-bases across the world. Our objective is to identify if the predictive accuracy is different for these teams, as compared to the conventionally weaker teams. \Cref{fig:big6} below shows the Brier scores for the matches corresponding to these two groups, split further according to who they played against.

\begin{figure}[!h]
    \centering
    \caption{Brier scores as a function of time when the teams are classified into two categories, namely `Big 6' and others}
    \includegraphics[width = 0.9\textwidth,keepaspectratio]{Robust1.pdf}
    \label{fig:big6}
\end{figure}

Home advantage is a commonly observed phenomenon in soccer (\cite{staufenbiel2015home}). The `Big 6' clubs are the largest and most successful clubs in English soccer, and it is not surprising that they would have a stronger home advantage than other teams. This is reflected in the lower Brier scores in predicted outcomes for games involving these clubs at their home stadiums. Interestingly, when two of the `Big 6' clubs play against each other, the average Brier score is found to be on the higher end during the first half. As discussed previously, team strength plays a crucial role in forecasting match outcomes in the early stages. Due to the strength being comparable for both teams such a phenomenon can be observed. For other teams playing at home, our model is robust in its accuracy irrespective of the opponents. Additionally, games involving the `Big 6' clubs against other teams at their home stadiums also show better forecasting accuracy in general. This suggests that home advantage is an effective performance indicator for the bigger teams, but not as much for smaller market teams. After the 60th minute mark in these matches, we note that the metric is similar for all cases, thereby establishing the proposed model's robustness in this aspect.

Next, we look at a different perspective where we predict the outcomes of the matches for a certain team, by training the model on the dataset excluding all matches of that team. This exercise is performed for each of the 34 teams in the dataset, and we compute the average Brier scores, which are reported in \Cref{fig:specific}. 

\begin{figure}[!ht]
    \centering
    \caption{Brier scores computed after excluding a team's games from the training data. The test data comprises entirely of matches played by the excluded team.}
    \includegraphics[width = \textwidth,keepaspectratio]{Robust2.pdf}
    \label{fig:specific}
\end{figure}

It must be noted that the teams have different extents of variations in their year-end positions. For example, Manchester United is typically at the top table in all seasons, whereas Aston Villa is a team with an average year-end position of 13 with the highest and lowest positions being 7 and 17. Some teams fluctuate in and out of the league on a yearly basis due to relegation as well. The idea is to identify how well the model performs when forecasting for all these teams, even without using its data in the training set. We believe that a robust model should be able to forecast the results of across all scenarios. The plots in \Cref{fig:specific} indicate that the model registers comparable accuracy in predicting the outcomes of games for all teams. This suggests that the model effectively captures the key features of the teams and their performances, even in the presence of notable fluctuations from one year to the next. This is a significant result, as it implies that the model may be able to make reliable predictions for a wide range of teams and situations.


\subsection{Two specific examples}\label{subsec:specific-examples}

As a last piece of discussion in this section, we look at the performance of the proposed approach for two specific games of different flavours. For each game, the model is trained on the data of all other matches before it, and the in-game forecasting is done on a minute-by-minute basis. 

The first game we discuss was played between Manchester United and Everton, at the home ground of the former. It was a low-scoring match with a solitary goal being scored towards the end. This case study demonstrates the ability of our model to accurately forecast the outcome by considering a variety of factors, including team ratings and time-varying covariates to understand the flow of the game. The within-game forecasting of the win probabilities for the two teams is displayed in \Cref{fig:case1}. 

\begin{figure}[h!]
    \centering
    \caption{Minute-by-minute forecast of the win probability for both teams during the match between Manchester United and Everton}
    \includegraphics[scale = 0.4]{Case1.pdf}
    \label{fig:case1}
\end{figure}

One can note that the final scoreline read 0-1 with the lone goal in the match being scored in the $86^{th}$ minute. Interestingly, Manchester United was the favourable winner at the start of the match, both due to being a better team (with respect to team rating) and for playing at home. The predicted win probability at the start was around 62\% and it improved for a few minutes in the beginning. Then, the sudden drop in the win probability around the $10^{th}$ minute is due to a flurry of corners awarded to Everton resulting in shots on goal. It is evident that our model could identify the dominance of the away team in the game and the predicted win probability for Manchester United dropped below 25\% within the first half itself. Subsequently, our model was likely to forecast the correct result with high certainty by as early as the $50^{th}$ minute. We see that the win probability of Everton was more than 50\% for a major part of the second half, thereby establishing that the proposed methodology does not necessarily need a goal to change the forecast probabilities of winning. The other covariates used in our method are good indicators of the final outcome of the game as well.

In contrast to the previous case, the second example is a high-scoring affair of Norwich City, playing at home against Liverpool. The score at the end of $90$ minutes was 4-5, with Liverpool managing a victory. Predicted win probabilities for the two teams, updated after every minute, are presented in \Cref{fig:case2}.

\begin{figure}[h!]
    \centering
    \caption{Minute-by-minute forecast of the win probability for both teams during the match between Norwich City and Liverpool}
    \includegraphics[scale = 0.4]{Case3.pdf}
    \label{fig:case2}
\end{figure}

Several intriguing observations can be made about this game. First of all, due to Norwich being a comparatively weaker team, our model estimates only about $25\%$ probability for them to win the contest initially, whereas the same for Liverpool was around 40\%. The chance of a victory for Norwich drops sharply as soon as Liverpool scores the first goal of the match. It is indeed worth mentioning that the goals scored by the two teams are found to have differential impacts on the probabilities, potentially due to the other covariates used in the model. For instance, after the initial goal by Liverpool in the $22^{nd}$ minute, it takes Norwich 2 goals to increase their win probability back to the initial level. Next, we see that at the $56^{th}$ minute, when a goal by Liverpool makes the score 3-2 in favour of Norwich, the estimated win probability for Norwich drops from $83\%$ to $16\%$, even though they are leading the match. At this moment, the odds are equally in favour of both sides. Thereafter, at the $63^{rd}$ minute mark, after Liverpool equalizes the scoreline, we see that the probability of Norwich winning reduces to zero and remains that for the rest of the match. Liverpool is predicted to emerge victorious with more than 75\% chance for the remaining of the match and the result indeed goes in their favour at the end. Clearly, this case study serves as another captivating example of the importance of considering team strength in predictive modelling and the ability of our model to incorporate several factors accurately.



\section{Conclusion}\label{sec:conclusion}

In this article, we developed a Bayesian latent variable model for analyzing and forecasting soccer match outcomes in real-time. As per our review of the literature, this is one of the first works for within-game prediction in soccer using a Bayesian framework. We used the data from EPL matches across eight seasons, with minute-by-minute data of various events in the matches. The main variable of interest for each game was the outcome, modelled as an ordered multivariate random variable with three categories of response. We used a latent variable and two cut-offs on it as a proxy for the final outcome and modelled this latent variable using a linear functional form. The functional form involved time-variant and time-invariant covariates as well as their corresponding coefficient, along with a random error term. In our computations we use a Gaussian prior for the random errors, the coefficient as well as the cut-offs, and a Dirichlet prior for the joint probabilities based on the cut-offs, to compute the step-wise conditional distributions as well as the posterior predictive distribution. 
%We employ a Gibbs sampling procedure to obtain the joint posterior densities of the parameters.

We then evaluated the model's performance in terms of forecast accuracy. Our model provides insights into the effect of various events such as corners, crosses and cards in soccer on the outcome. The modelling approach is the first to incorporate real-time predictions to the best of our knowledge. Through various evaluation criteria, we find the model to be highly effective across different scenarios. We have seen that the results are robust for conventional big teams, as well as for teams with inconsistent performances. Furthermore, taking two specific examples, we demonstrate the effectiveness of the model in predicting the outcome well beforehand a decisive goal is actually scored. Keeping that in mind, we strongly believe that the proposed methodology can be an extremely useful tool to maintain audience engagement in broadcasting soccer matches, or for the betting markets in real-time. 

We would like to end the paper with a short account of possible future extensions of this study. We note that the data did not include detailed information on the passing sequence, ball possessions, or substitutions. These aspects are expected to have a strong impact on the outcome of the game, but unfortunately, our model fails to incorporate them in this current work. Naturally, future implementation of the model can include these events in the framework and assess their impact on the match outcomes. A closely related area of research would be to understand the improvement in the win probability by potential substitutions, which may facilitate the coaches to devise a statistically sound substitution strategy during a match. Another possible improvement in the prediction accuracy can be to incorporate dependencies among different pairs of teams with respect to their previous outcomes. Last but not the least, we recall that the assumption of Gaussian priors on the coefficients associated with the real-time events might be construed to be restrictive. We plan to address this issue in future works, by considering a more general structure, possibly along with a semi-parametric approach to model the outcome of the game. %, which in the present work is based on parametric models. 


\section*{Data availability statement}

The data used in this study are obtained from the publicly available European Soccer Database in Kaggle (link: \url{https://www.kaggle.com/datasets/hugomathien/soccer}).


\bibliography{references}

\end{document}

%begin split