\section{Related Work}



% With the vast amount of videos available online and new ones being generated and uploaded everyday, an efficient video search engine  is of great practical value. The core of a video search engine is the retrieval task, which deals with finding the best matching videos based on the user's text query~\cite{mithun2018learning,miech2018learning,liu2019use,dzabraev2021mdmmt,cheng2021improving}. With collective efforts over the years, current state-of-the-art methods~\cite{andres2021straightforward,luo2021clip4clip,fang2021clip2video} have achieved reasonable performance on several different video retrieval benchmarks~\cite{xu2016msr,chen2011collecting,anne2017localizing,krishna2017dense,rohrbach2015dataset}.

% The aim of video retrieval system is to find the best matching videos according to the queries provided by users~\cite{mithun2018learning,miech2018learning,liu2019use,dzabraev2021mdmmt,cheng2021improving}. Video retrieval has significant practical value as the vast amount of videos on the web has triggered the need for efficient and effective video search systems. Besides, video retrieval also has direct applications in video recommendation systems~\cite{bendersky2014up,covington2016deep}. However, current video retrieval research mainly focuses on the plain-text query such as video caption or description regardless the need for searching videos using queries with complex structure. 
% In this paper, we focus on a less-studied setting of video retrieval: dialogue-to-video retrieval where the search query is dialogue which contains structured information from each turn of the dialogue. The need for dialogue-to-video retrieval derives from the increasing amount of online dialogues/conversations on social media, which inspires the development of effective dialogue-to-video retrieval systems for many purposes especially recommendation systems~\cite{alamri2019audiovisual,he2021improving,zheng2022MMChat}. Different from general text-to-video retrieval, dialogue-to-video uses user-generated dialogues as the search query to retrieval videos. The dialogue contains the discussion towards a certain video object from users, which provide dramatically different information from a plain-text query. Because during the interaction between users in the dialogue, the following discussion could happen "A: \textit{The main character of that movie was involved in a horrible car accident when he was 13.} B: \textit{No, I think you mean another character.}". Such discussion contains subtle information about the interested video and thus cannot be treated as a plain-text query.

% Therefore, to incorporate the conversational information from dialogues, we proposed a novel dialogue-to-video retrieval approach. In our proposed model, we sequentially encode each turn of the dialogue to obtain the dialogue-aware query representation in purpose of keeping the dialogue information. Then we use it to compare with frames in the video to calculate similarities between frame and query to get the weighted video representation. Finally we use the video representation to compute an overall similarity score with the dialogue-aware query. To validate the effectiveness of our approach, we conduct dialogue-to-video experiments on a benchmark dataset AVSD~\cite{alamri2019audiovisual}. Experimental results show that our approach achieves significant improvements over previous state-of-the-art models including \textsc{FiT} and \textsc{ViReD}~\cite{maeoki2020interactive,bain2021frozen,madasu2022learning}.

