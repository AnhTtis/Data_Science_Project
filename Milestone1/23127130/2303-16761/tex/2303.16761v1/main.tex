% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
% \usepackage{times}
\usepackage{booktabs}
\usepackage{amsmath}

% \usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{Dialogue-to-Video Retrieval}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Chenyang Lyu\and
Manh-Duy Nguyen\and
Van-Tu Ninh\and$^{\thanks{The first three authors contributed equally.}}$\\
Liting Zhou\and
Cathal Gurrin \and
Jennifer Foster}
%
\authorrunning{C. Lyu et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{School of Computing, Dublin City University, Dublin, Ireland \\ \email{\{chenyang.lyu2,manh.nguyen5,van.ninh2\}@mail.dcu.ie \\ \{liting.zhou,cathal.gurrin,jennifer.foster\}@dcu.ie}\\}

% Van Tu Ninh <van.ninh2@mail.dcu.ie>
% \author{Anonymous}
% \institute{}
% \authorrunning{Anonymous}
%
\maketitle              % typeset the header of the contribution
%
%\def\thefootnote{$\dagger$}\footnotetext{These authors contributed equally to this work.}
\begin{abstract}
Recent years have witnessed an increasing amount of dialogue/conversation on the web especially on social media. That inspires the development of dialogue-based retrieval, in which retrieving videos based on dialogue is of increasing interest for recommendation systems. Different from other video retrieval tasks, dialogue-to-video retrieval uses structured queries in the form of user-generated dialogue as the search descriptor.
%which contains structured information from utterance. 
%Therefore, 
We present a novel dialogue-to-video retrieval system, incorporating structured conversational information. Experiments conducted on the AVSD dataset show that our proposed approach using plain-text queries improves over the previous counterpart model by 15.8\% on R@1. Furthermore, our approach using dialogue as a query, improves retrieval performance by 4.2\%, 6.2\%, 8.6\% on R@1, R@5 and R@10 and outperforms the state-of-the-art model by 0.7\%, 3.6\% and 6.0\% on R@1, R@5 and R@10 respectively.


% Contribution:
% \begin{itemize}
%     \item Incorporate audio feature in video retrieval
    
%     \item Use dialogue as search query to retrieve video
    
%     \item Making use of CLIP~\cite{radford2021learning_clip} for video retrieval
% \end{itemize}

\keywords{dialog-based retrieval \and dialogue search query \and conversational information}
\end{abstract}

\input{0-Introduction}
% Introduce the novel parts of the task

% Link the new task with the old relevant tasks in VBS (Textual Known Item Search)


% There're increasingly amount of dialogs/conversations on social media, which creates needs to recommend/retrieve videos to social media users

% Describe our system and experimental results.
% Contributions:


% \input{1-Related-Work}

\input{2-Methodology}

% 

\input{3-Experiments}

\input{4-Conclusion}


\section*{Acknowledgements}
This work was funded by Science Foundation Ireland through the SFI Centre for Research Training in Machine Learning (18/CRT/6183). We thank the reviewers for their helpful comments.

\bibliographystyle{splncs04}
\bibliography{mybibliography}

\end{document}
