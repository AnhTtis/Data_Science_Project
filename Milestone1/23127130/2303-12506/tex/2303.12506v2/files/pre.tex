\section{Preliminaries}\label{sec:preliminaries}
% \eden{to myself: to do}
% In this section, we provide the definitions we use within the paper, assuming that they are already familiar to the reader.
% For brevity, if not explicitly stated otherwise, optimization is considered in this paper in terms of maximization.

We denote the set $\{1,\dots, n\}$ by $[n]$ for $n \in \mathbb{N}$.

 \paragraph{Single-objective optimization}

A \emph{single-objective maximization (minimization) problem} is a tuple $(S,f)$ where $S$ is the set of all feasible solutions to the problem (usually $S \subseteq \mathbb{R}^m$ for some $m \in \mathbb{N}$) and $f \colon S \to \mathbb{R}$ is a function describing the objective value of a solution $x \in S$.
The goal in such problems is to find an \emph{optimal} solution, that is, a feasible solution $x^* \in S$ that has the maximum (minimum) objective value, that is $f(x^*) \geq f(x)$ ($f(x^*) \leq f(x)$) for any other solution $x \in S$.


A \emph{$(1-\multError,\additiveError)$-approximation algorithm} for a single-objective \emph{maximization} problem $(S,f)$ is one that returns a  solution $x\in S$ that \emph{approximates} the optimal solution $x^*$ from below. That is, $f(x) \geq(1-\multError) \cdot f(x^*) - \additiveError$ for $\multError  \in [0,1)$ and $\additiveError \geq 0$ (that describe the allowed multiplicative and additive error factors respectively).

Similarly,  a \emph{$(1+\multError,\additiveError)$-approximation algorithm} for a single-objective \emph{minimization} problem is one that returns a feasible solution $x$ that \emph{approximates} the optimal solution $x^*$ from above. That is, $f(x) \leq(1+\multError) \cdot f(x^*) + \additiveError$ for $\multError \geq 0$ and $\additiveError \geq 0$.
% \end{definition}
% \erel{For brevity, we can say that we focus on maximization problems, and not talk about minimization problems at all.}
% \eden{I though about it but we use approximation for a minimization problem in the app section. Would it better to explain it there?}

% \eden{In the beginning I called it "half-randomized" but I'm not sure about the "half"... I tried to emphasize the fact that the algorithm returns a feasible solution and that the "random" part is related only to the objective value..}
A \emph{$p$-randomized} approximation algorithm, for $p\in(0,1]$, is one that returns a solution $x\in S$ such that, with probability $p$, the objective value $f(x)$ is approximately-optimal.


\paragraph{Multi-objective optimization}
A \textit{multi-objective maximization} problem \cite{branke_multiobjective_2008} can be described as follows:
\begin{align*}
    \max \quad &\{f_1(x), f_2(x), \dots f_n(x)\} \\
    s.t. \quad  & x \in S
\end{align*}
Where $S\subseteq \mathbb{R}^m$ for some $m \in \mathbb{N}$ is the \textit{feasible region} and $f_1, f_2, \dots, f_n$ are $n$ \textit{objective-functions} $f_i\colon S \to \mathbb{R}$.
An example application is group decision making:
some $n$ people have to decide on an issue that affects all of them.
The set of possible decisions is $S$, and the utility each person $i$ derives from a decision $x\in S$ is $f_i(x)$.


% Our motivating application is fair resource allocation, which is a special case of group decision making in which $S$ is the set of all possible allocations.
% \eden{I'm not sure it is necessary since we said it in the introduction}
% \eden{we actually does not use the example application in this section... maybe to remove it?}
% \erel{I agree.}



%-------------------- leximin description -----
\iffalse
\paragraph{The leximin order} Ideally, we would like to find a solution that would maximize the utility of all players. 
In practice, there may be conflicts among their interests. 
Therefore, when considering different possible solutions, we aim to find the fairest one.
% There are many ways to define fairness, but Pareto optimality is one of the most commonly used.
% A solution is considered a Pareto optimal solution if no other solution can increase some objective without decreasing another one.
%----------------------
% \paragraph{Leximin}
A known concept for measuring fairness is the leximin order which prefers solutions that are less offensive to the poorest ones. 
% \eden{It extends the \textit{egalitarian rule} \cite{}....}
More precisely, an optimal solution according to this order maximizes the smallest objective, subject to this maximizes the second-smallest objective, and so on.
\erel{We already described leximin informally in the intro, so we do not need to repeat it here; it is sufficient to show the formal definition.}
Note that the smallest objective value is known as the \textit{egalitarian value}; and in many cases, the problem of maximizing this value is interesting by itself.
\fi
%--------------------
%--------------------


\paragraph{Ordered outcomes notation}
The multiset of objective values achieved from a solution $x\in S$ is denoted by $\allValues{x} = \{f_i(x)\}_{i=1}^n$, and the $j$'th smallest objective value by $\valBy{j}{x}$, i.e.,
\begin{align*}
    \valBy{1}{x} \leq \valBy{2}{x} \leq \dots \leq \valBy{n}{x}.
\end{align*}
% \eden{to do}
% \erel{Why do you switch from F to V and then to $\mathcal{V}$?}
% \eden{F is actually not needed. I tried $\textbf{V}$ to emphasize that it is a vector ("mathcal" does not become bold), would it be better to use $V_k^{\uparrow}$ for the $k$-th value?}
% \eden{We also need to think about how to handle the case where two (or more) functions get the same value (and then this is not well defined).}
% \yon{in which case, $\allValues{}$ is a multiset}
% \erel{We can say that we break ties arbitrarily. It does not matter very much, since we will only be interested in $\valBy{k}{x}$ and not in $\funcBy{k}{x}$ by its own, right?}
% \eden{how is this alternative notation? $\mathbf{F}(x,k)$}
% \erel{
% I am not sure; it might look as if $k$ is just another argument to $F$.
% }
% \eden{how about this one: $\mathcal{OBJ}_k(x)$ or this: $\mathcal{OBJ}_k^{\uparrow}(x)$}
% \eden{how about $\mathpzc{obj}_k^{\uparrow}(x)$}
% \eden{Or something with "V" (to represent objective \textbf{value}): $\mathpzc{V}_k^{\uparrow}(x)$}
% %
%\subsection{Fairness in Multi-Objective Optimization}\label{sec:fairness-in-multi-obj-opt}


\paragraph{The leximin order}
% A leximin-optimal solution is determined by the \emph{leximin order}, which depends on the following preferences relation:
% Accordingly, the leximin order is described as follows: a
A solution $y$ is considered \emph{leximin-preferred} over a solution $x$, denoted $y \leximinPreferred x$, if there exists an integer $1 \leq k\leq n $ such that the smallest $(k-1)$ objective values of both are equal, whereas the $k$'th smallest objective value of $y$ is higher:
\begin{align*}
    \forall j < k \colon \quad &\valBy{j}{y} = \valBy{j}{x}\\
    & \valBy{k}{y} > \valBy{k}{x}
\end{align*} 
Two solutions, $x,y,$ are \emph{leximin equivalent} if $\allValues{x} = \allValues{y}$. 
The leximin order
% , which we denote by $\succeq$, 
is a \emph{total} order, and strict between any two solutions that yield \emph{different} utility multisets ($\allValues{x} \neq \allValues{y}$).  
A \emph{maximum} element of the leximin order is a solution
% that is preferred over all the solutions that yield different utilities (i.e., a solution $x$ such that $x \leximinPreferred y$ for any solution $y$ for which $\allValues{x} \neq \allValues{y}$).
% Notice that since two such solutions are comparable, $x \leximinPreferred y$ implies that $y \nLeximinPreferred x$, and so, a maximum element is also one 
over which \emph{no} solution is preferred (including solutions that yield the same utilities).
% \eden{I'm not sure how to handle the comment we got here: \textit{the discussion before the definition of Leximin optimal confused me. How do you maintain the strict ordering property if you can have the same sets of utilities? Or are you assuming that the *sets* may be equal, but (with respect to the numbering of the criteria) the values are permuted between the two instances? Or that you've used lexicographic tie breaking?
% }}
% \eden{would it be better to put it as an Observation?}
% \erel{I don't think so. It is quite well-known.}

\paragraph{Leximin optimal}
% As the order determines only by the utilities  maximum element 
% accordingly, the order has a unique
%
% every solution ($x \in S$) with a sorted utility vector $(\valBy{1}{x},\ldots,\valBy{n}{x})$ that corresponds to this element is called a \emph{leximin-optimal solution}.
A \emph{leximin optimal} solution is a maximum element of the leximin order.
% \er{
% Given a feasible region $S$, we are interested in finding a solution $x\in S$,  
% such that $\allObjFunc(x)$ is maximum in the leximin order. 
% We denote this optimization problem as follows. 
% \begin{align*}
% 	\lexmaxmin \quad &\{f_1(x), f_2(x), \dots f_n(x)\} \\
% 	s.t. \quad  & x \in S
% \end{align*}
% }
% Given a feasible region $S$, we are interested in finding a solution $x\in S$,  which is a maximum element of the leximin order. 
Given a feasible region $S$, as the order is determined only by the utilities, we denote this optimization problem as follows. 
\begin{align*}
	\lexmaxmin \quad &\{f_1(x), f_2(x), \dots f_n(x)\} \\
	s.t. \quad  & x \in S
\end{align*}
% \eden{maybe "$\maxlexmin \quad \{f_1(x), f_2(x), \dots f_n(x)\}$" since it is a maximal element according to the leximin order?..}
% \erel{Both are equally good IMO.}

