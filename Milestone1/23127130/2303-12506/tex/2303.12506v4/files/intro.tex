

\section{Introduction}
% title: real life motivation
Many real life scenarios involve more than one objective. 
These situations are often modeled as \emph{multi-objective optimization problems}. These are defined by the set of possible decisions, along with functions that describe the different objectives.
As a concrete example, we use the context of social choice, in which the objective functions represent people's utilities.
Different criteria can be used to determine optimality when considering multi-objectives. 
For example, the \emph{utilitarian} criterium aims to maximize the sum of utilities, whereas the \emph{egalitarian} criterium aims to maximize the least utility.
This paper focuses on the \emph{leximin} criterium, according to which one aims to maximize the least utility, and, subject to this, maximize the second-smallest utility, and so on.
In the context of social choice, 
the leximin criterium is considered a criterium of fairness,
as strives to benefit, as much as possible, the least fortunate in society.

Common algorithms for finding a leximin optimal solution are iterative, optimizing one or more single-objective optimization problems at each iteration (for example~\cite{airiau_portioning_2019,arbiv_fair_2022,bei_truthful_2022, nace_max-min_2008,Ogryczak2004TelecommunicationsND,willson}).
Often, these single-objective problems cannot be solved exactly (e.g. when they are computationally hard, or when there are numeric inaccuracies in the solver), but can be solved approximately.
In this work, we define an approximate variant of leximin and show how such an approximation can be computed, given approximate single-objective solvers.

\paragraph{The Challenge}
When single-objective solvers only \emph{approximate} the optimal value, existing methods for extending the solvers to leximin optimally may fail, as we illustrate next.

A common algorithm,
independently proposed many times, e.g.~\cite{airiau_portioning_2019,nace_max-min_2008,Ogryczak2004TelecommunicationsND, willson}, is based on the notion of \textit{saturation}. It operates roughly  as follows.
In the first iteration, the algorithm looks for the maximum value that all objective functions can achieve simultaneously, denoted $z_1$. Then, it determines which of the objective functions are saturated --- that is, cannot achieve more than $z_1$ given that the others achieve at least $z_1$.
Afterwards, in each iteration $t$, given that for any $i<t$ the objective-functions that were determined saturated in the $i$'th iteration achieve at least $z_i$, it looks for the maximum value that all other objective-functions can achieve simultaneously, denoted $z_t$, and then determines which of those functions are saturated.
When all functions become saturated, the algorithm ends.

%As an example of how the algorithm works, consider the following problem:
%\begin{align*}
%    \lexmaxmin \quad &\{f_1(x) = x_1, f_2(x)=x_2, f_3(x) = x_3\}\\
%        s.t. \quad &(1) \quad x_1 \leq 1, \text{ }\Lquad \Hquad\Hquad\quad 
 %       (3) \quad x_2 + x_3 \leq 5 \\
  %      &(2) \quad x_1 + x_2 \leq 3, \Lquad      (4) \quad x \in \mathbb{R}^3_{+} 
%\end{align*}
  
%In the first iteration, the algorithm finds that the maximum value all objective functions can achieve simultaneously is $1$.
%The optimal value of $f_1$ given that the others ($f_2$ and $f_3$) achieve at least $1$ is $1$, where the optimal values of $f_2$ and $f_3$ are $2$ and $4$ respectively. 
%Therefore, only $f_1$ is determined saturated with a saturation value $z_1 =1$.
%In the second iteration, we find that when $f_1$ achieves at least $1$, the maximum value that $f_2$ and $f_3$ can achieve simultaneously is $2$.
%The optimal value of $f_2$ given that $f_1$ achieves at least $1$ and $f_3$ achieve at least $2$ is $2$, and the optimal value of $f_3$ given that $f_1$ achieves at least $1$ and $f_2$ achieve at least $2$ is $3$.
%And so, $f_2$ is determined saturated with saturation value $z_2 = 2$.
%At the third iteration, we find that when $f_1$ achieves at least $1$ and $f_2$ achieves at least $2$, the maximum value that $f_3$ can achieve is $3$, and as it is also its optimal value, $f_3$ is determined saturated with saturation value $z_3 = 3$.
%We get that the leximin optimal solution to this problem is $x = (1,2,3)$.

The following simple example  demonstrates the problem that may arise when the individual solver may return sub-optimal results. Consider the following problem:
\begin{align*}
    \lexmaxmin \quad &\{f_1(x) = x_1, f_2(x)=x_2\} \\
    s.t. \quad  &(1) \Hquad x_1 + x_2 \leq 1, \quad (2) \Hquad x \in \mathbb{R}^2_{+}
\end{align*}
As $f_1$ and $f_2$ are symmetric, the leximin optimal solution in this case is $(0.5,0.5)$.
Now suppose that rather than finding the exact value $0.5$, the solver returns the value $0.49$. 
The optimal value of $f_1$ given that $f_2$ achieves at least $0.49$ is $0.51$, and vice versa for $f_2$.
As a consequence, none of the objective functions would be determined saturated, and the algorithm may not terminate. 
One could perhaps define an objective as ''saturated'' if its maximum attainable value is close to the maximum $z_t$, but there is no guarantee that this would lead to a good approximation\footnote{An example will be given on request.}
% \eden{ (for more details see Appendix \ref{}\fullVer)}.
%
% EREL: In fact, we have examples showing that it will not lead to a good approximation. It may be good to mention them here.
% \eden{to add an example and reference to it}

% The algorithm suggested in this paper returns an appropriate approximation even in the presence of errors.
% EREL: It is not suggested in this paper.
% EDEN: maybe: suggested for porpuse?

\paragraph{Contributions}
This paper studies the problem of leximin optimization in multi-objective optimization problems, 
focusing on problems for which even the single-objective problems cannot be solved exactly in polynomial time.
\eden{Was: 'Our contribution is threefold.', should it be rewritten differently for two? maybe: 'We present two key contributions in this research.'}
Our contribution is twofold.


First, a new definition of leximin approximation is presented.
It captures both multiplicative and additive errors.
The definition has several desirable properties, including that a leximin optimal solution is always approximately-optimal,
% (for any approximation factor),
and that the definition is equivalent to the original one in the absence of errors.

Second, an algorithm is provided that, given an approximation algorithm for a single-objective problem, computes a leximin approximation to the multi-objective problem.
The algorithm was first presented by Ogryczak
and {\'{S}}liwi{\'{n}}ski~\cite{Ogryczak_2006} for exact leximin-optimization. In contrast to the saturation-based algorithm described in the Introduction, this algorithm always terminates, even when the single-objective solver is inaccurate. 
Moreover, the accuracy of the returned solution is closely correlated with the accuracy of the single-objective solver --- given an $(\multApprox,\additiveApprox)$-approximation algorithm for the single-objective problem (where $\multApprox$ and $\additiveApprox$ describe the multiplicative and additive factors respectively), the returned solution is an $\left(\frac{\multApprox^2}{1-\multApprox + \multApprox^2}, \frac{\additiveApprox}{1-\multApprox +\multApprox^2}\right)$-approximation of leximin.
Importantly, this holds for any number of objectives.
% It should also be noted that the algorithm is applicable in many cases, for example, when the single-objective solver is inaccurate due to numeric issues, e.g. floating-point rounding errors, or iterative methods that are stopped before complete convergence due to time constraints. 

Our algorithm is applicable whenever a single-objective solver is inaccurate due to numerical issues, such as floating-point rounding errors, or stopping an iterative solution procedure before complete convergence.
% Another application is when the feasible region is convex and all the objectives are concave (and polynomially computable) --- where under several assumptions it can be approximated to any wanted factor.
%
%
% \eden{I remove it for now....... but maybe it would be better to keep it and just change it a bit....\\
% It should also be noted that the algorithm is applicable in many cases, for example, when the feasible region is convex and all the objectives are concave (and polynomially computable).}


\paragraph{Organization} 
Section \ref{sec:preliminaries} gives preliminary knowledge and basic definitions. 
Section \ref{sec:approx-leximin-def} presents the definition of leximin approximation.
An algorithm for computing such an approximation is presented in Section \ref{sec:algo-short}.
Section \ref{sec:future} concludes with some future work directions.


\input{files/related-work.tex}