\section{Proof of Theorem \ref{th:app-main}}\label{sec:app-sec-proofs}
\eden{should probably change the title}
This section proves Theorem \ref{th:app-main}.


% \erel{Here, before presenting our solution, I would mention that \textcite{kawase_max-min_2020} solved the max min problem without the "lex". Then, explain that we need to adapt their solution to "lex". }

% title: the specific problem as P3
% \eden{if we use version 2, need to rewrite this}
As we saw in Section \ref{sec:algo-short}, an approximation to leximin can be obtained (Theorem \ref{th:main}) by providing a procedure \textsf{OP} to approximate \eqref{eq:vsums-OP}, which, under these particular settings, becomes:
% \erel{Why do you call it "configuration LP"? I think this term refers to something else: \url{https://en.wikipedia.org/wiki/Configuration_linear_program}}
\begin{align}
\max \quad &z_t\tag{C1}\label{eq:app-vsums-OP}\\
s.t. \quad  & (1.1) \quad \sum_{A \in \mathcal{A}} p_d(A) = 1 \nonumber\\
& (1.2) \quad p_d(A) \geq 0  && \forall A \in \mathcal{A} \nonumber\\
& (2) \quad \ell y_{\ell} - \sum_{j=1}^n m_{\ell,j}\geq \sum_{i=1}^{\ell}  z_i && \ell = 1, \ldots,t-1 \nonumber \\
& (3) \quad t y_t - \sum_{j=1}^{n} m_{t,j} \geq \sum_{i=1}^{t}  z_i \nonumber \\
& (4) \quad m_{\ell,j} \geq y_{\ell} - \sum_{A \in \mathcal{A}}p_d(A) \cdot u_j(A)  && \ell = 1, \ldots,t,\Hquad j = 1, \ldots,n \nonumber \\
& (5) \quad m_{\ell,j} \geq 0  && \ell = 1, \ldots,t,\Hquad j = 1, \ldots,n \nonumber
\end{align}
Here the variables are $p_d(A)$ for any deterministic allocation $A \in \mathcal{A}$, $\ztVar{}$, and $y_{\ell}$ and $m_{\ell,j}$ for all $\ell \in [t]$ and $ j\in [n]$; and the values $z_1, \ldots z_{t-1}$ are constants.
Notice that it is a \emph{linear program} that has a polynomial number of constraints thanks to \eqref{eq:vsums-OP} representation, but an exponential number of variables (since there is a variable $p_d(A)$ for each possible deterministic allocation).
So, it is unclear how to approach it directly in polynomial time.

% title: baseline
% \erel{I would move the following paragraph upwards}
With $t=1$, \eqref{eq:app-vsums-OP} can be viewed as the problem of egalitarian welfare maximization, indeed,  \textcite{kawase_max-min_2020} who studied this problem, considered a slightly simpler representation (a one corresponding to \eqref{eq:sums-OP}). 
% After proving that approximating the optimal value to a factor better than $(1-\frac{1}{e})$ is NP-hard, they present a dual-based algorithm that achieves this accuracy \er{w.h.p (?)}.
We now show how their dual-based technique can be applied to approximate \eqref{eq:app-vsums-OP} for any $t\geq 1$ while maintaining the same approximation factor.


To begin, consider the following program \eqref{eq:app-ver2-vsums-OP}, which is the result of modifying \eqref{eq:app-vsums-OP} in three ways. 
First, changing the objective-function to $\min 1/z_t$ instead of $\max z_t$. 
Second, replacing all the original variables and constants, except $z_t$, with new ones that are smaller by a factor $z_t$ (that is, $p'_A = p_d(A)/z_t$ for all $A \in \mathcal{A}$, $,y'_{\ell} = y_{\ell}/z_t,m'_{\ell,j} = m_{\ell,j}/z_t$ for $\ell \in [t]$ and $ j\in [n]$,  and $z'_i = z_i/z_t$ for $i \in [t-1]$).
And third, dividing all the constraints by $z_t$ ($z_t > 0$ since $z_t \geq z_1$ for any $t \geq 1$ and  $z_1 >0$).
\begin{align}
\min \quad & \sum_{A \in \mathcal{A}} p'_A \tag{C2}\label{eq:app-ver2-vsums-OP}\\
s.t. \quad  & (1) \quad p'_A \geq 0  && \forall A \in \mathcal{A} \nonumber\\
& (2) \quad \ell y'_{\ell} - \sum_{j=1}^n m'_{\ell,j}\geq \sum_{i=1}^{\ell}  z'_i && \ell = 1, \ldots,t-1 \nonumber \\
& (3) \quad t y'_t - \sum_{j=1}^{n} m'_{t,j} \geq \sum_{i=1}^{t-1}  z'_i + 1 \nonumber \\
& (4) \quad m'_{\ell,j} \geq y'_{\ell} - \sum_{A \in \mathcal{A}}p'_A \cdot u_j(A)  && \ell = 1, \ldots,t,\Hquad j = 1, \ldots,n \nonumber \\
& (5) \quad m'_{\ell,j} \geq 0  && \ell = 1, \ldots,t,\Hquad j = 1, \ldots,n \nonumber
\end{align}
The programs \eqref{eq:app-vsums-OP} and \eqref{eq:app-ver2-vsums-OP} are related in the following way:
% \erel{I would make this a lemma:}
\begin{lemma}\label{lemma:bijection}
There exists a bijection mapping each solution of 
\eqref{eq:app-vsums-OP} with objective value $V$ to a unique solution of 
\eqref{eq:app-ver2-vsums-OP} with objective value $1/V$.
\end{lemma}
\begin{proof}
Let $p_d(A)$ for $A \in \mathcal{A}$, $\ztVar{}$, and $y_{\ell}$ and $m_{\ell,j}$ for all $\ell \in [t]$ and $ j\in [n]$ be a feasible solution to the program \eqref{eq:app-vsums-OP} with objective value $V$.
It can be easily verified that $p'_A = p_d(A)/z_t$ for $A \in \mathcal{A}$, $\ztVar{}$, and $y'_{\ell} = y_{\ell}/z_t$ and $m_{\ell,j} = m_{\ell,j}/z_t$ for all $\ell \in [t]$ and $ j\in [n]$ is a feasible solution to the program \eqref{eq:app-ver2-vsums-OP} with objective value $1/V$.
\end{proof}

Denote this mapping by $\Psi$, this also implies the following:
\begin{lemma}\label{lemma:approx-acc-by-bijection}
    If a solution approximates the program \eqref{eq:app-ver2-vsums-OP} with a multiplicative error of $\frac{\multError}{1-\multError}$. Then the corresponding solution to \eqref{eq:app-vsums-OP} according to the mapping $\Psi$ approximates this program with a multiplicative error of $\multError$.
\end{lemma}

\begin{proof}
    Let $V^*$ be the optimal objective value of \eqref{eq:app-vsums-OP}. 
    By Lemma \ref{lemma:bijection}, there exists a solution to \eqref{eq:app-ver2-vsums-OP} with value $1/V^{*}$.
    This solution yields the optimal value for \eqref{eq:app-ver2-vsums-OP} --- if there was a solution that had a value \emph{lower} than $1/V^{*}$ (\eqref{eq:app-ver2-vsums-OP} is a minimization problem), then the corresponding solution to \eqref{eq:app-vsums-OP} (by the mapping $\Psi$) would have a value higher than the optimal value $V^*$.
    Now, let the value of the solution that approximates the program \eqref{eq:app-ver2-vsums-OP} with a multiplicative error of $\frac{\multError}{1-\multError}$ be $1/V$. 
    Since \eqref{eq:app-ver2-vsums-OP} is a minimization problem, assuming that $1/V$ approximates $1/V^*$ with a multiplicative error of $\frac{\multError}{1-\multError}$ means that:
    \begin{align*}
        \frac{1}{V} \leq \left(1+\frac{\multError}{1-\multError}\right)\frac{1}{V^*},
    \end{align*}
 which implies that $V \geq (1-\multError)V^*$.
    As \eqref{eq:app-vsums-OP} is a maximization problem, this means that $V$ approximates this problem with multiplicative error $\multError$.
    By Lemma \ref{lemma:bijection}, $V$ is the value of the corresponding solution to \eqref{eq:app-vsums-OP} by the mapping $\Psi$.
\end{proof}


% title: dual 
Now, let us consider the dual program of \eqref{eq:app-ver2-vsums-OP}, which can be described as follows:
% \erel{When you present an LP, it can help the reader if you mention what exactly the variables of the LP are.}
\begin{align}
    \max \quad & \sum_{\ell=1}^{t-1} q_{\ell} \sum_{i=1}^{\ell} z_i + q_t (\sum_{i=1}^{t-1} z_i +1) \tag{D2}\label{eq:app-dual}\\
        s.t. \quad  & (1) \quad \sum_{j=1}^n u_j(A) \sum_{\ell=1}^t v_{\ell,j} \leq 1  && \forall A \in \mathcal{A} \nonumber\\
                    & (2) \quad \ell q_{\ell} - \sum_{j=1}^n v_{\ell,j} = 0 && \ell = 1, \ldots,t \nonumber \\
                    & (3) \quad q_{\ell} - v_{\ell,j} \leq 0  && \ell = 1, \ldots,t,\Hquad j = 1, \ldots,n \nonumber \\
                    & (4) \quad v_{\ell,j} \geq 0  && \ell = 1, \ldots,t,\Hquad j = 1, \ldots,n \nonumber \\
                    & (5) \quad q_{\ell} \geq 0  && \ell = 1, \ldots,t \nonumber
\end{align}
Here, the variables are $q_{\ell}$ and $v_{\ell,j}$ for any $\ell \in [t]$ and $j \in [n]$; and the constants are (as before) $z_i$ for $i \in [t-1]$.
Recall that $u_j(A)$ is the utility that agent $j$ assigns to deterministic allocation $A$, as given by the value oracle.
% title: ellipsoid variant
This problem has an exponential number of constraints --- a constraint for each allocation (in line (1)) but only a polynomial number of variables.
Using the ellipsoid method \cite{grotschel_ellipsoid_1981}, it could be solved in polynomial time 
if we had a \emph{separation oracle} ---
an oracle that given a vector $\upsilon$ either determines that $\upsilon$ is infeasible and returns a violated constraint, or asserts that $\upsilon$ is feasible.
Unfortunately, as we shall now see, it is NP-hard to compute a separation oracle to this problem.
\begin{lemma}
    Computing a separation oracle to \eqref{eq:app-dual} is NP-hard.
\end{lemma}

% very similar to what they did in yonatan's paper..
\begin{proof}
We prove that a separation oracle for \eqref{eq:app-dual} would allow us to compute a leximin optimal stochastic allocation.
    As discussed previously, computing such an allocation is NP-hard, so the same applies for computing a separation oracle for \eqref{eq:app-dual}.

    First, we prove that such a separation oracle can be used to extract an optimal solution to \eqref{eq:app-ver2-vsums-OP}.
    Assume that the ellipsoid method was operated with the given oracle to solve \eqref{eq:app-dual}.
    Let $C$ be the set of constraints that the oracle determined as being violated.
    Since the ellipsoid method operates in polynomial time, the size of the set $C$ is also polynomial.
    Let $V_C$ be the set variables of \eqref{eq:app-ver2-vsums-OP} associated with the constraints in $C$.
    By complementary slackness, the variables in $V_C$ are the only ones that may get a \emph{positive} value in the corresponding optimal solution to \eqref{eq:app-ver2-vsums-OP}.
    Therefore, the program \eqref{eq:app-ver2-vsums-OP} with only the variables in $V_C$ (and the other variables equal to zero) has a polynomial size, and therefore can be solved exactly.


    But, By Lemma \ref{lemma:approx-acc-by-bijection}, this would allow us to use the mapping $\psi$ to find the corresponding optimal solution to \eqref{eq:app-vsums-OP}.
    This means the described process can be used as an approximation procedure to \eqref{eq:vsums-OP} (that became \eqref{eq:app-vsums-OP} under the settings of this problem) with $\multError = \additiveError = 0$.
    Therefore, by Theorem \ref{th:main}, this means we can use Algorithm \ref{alg:basic-ordered-Outcomes} to obtain a leximin optimal solution\footnote{Actually, Theorem \ref{th:main} says that Algorithm \ref{alg:basic-ordered-Outcomes} will output a $(1,0)$-approximately-optimal solution; But Lemma \ref{lemma:absence-of-errors} says that such a solution is, indeed, a leximin optimal solution.}.
\end{proof}


% --- it would allow us to compute a leximin optimal stochastic allocation, which is, as discussed previously, NP-hard.

In Appendix \ref{sec:mult-variant-ellipsoid}, we present another variant of the ellipsoid method, which allows us to approximate the program \eqref{eq:app-ver2-vsums-OP} given a \emph{half-randomized approximate separation oracle} to \eqref{eq:app-dual}.
That is, an oracle that, given a multiplicative error $\multError$, a success probability $p$, and a vector $\upsilon$, either determines that $\upsilon$ is infeasible and returns a violated constraint; or determines that $\upsilon$ is $\multError$-\textit{approximately-feasible}, which means that for any constraint $a \cdot x \leq b$, the vector $\upsilon$ satisfies $a \cdot \upsilon \leq (1+\multError)\cdot b$.
When the oracle says that $\upsilon$ is $\multError$-approximately-feasible, it is correct with probability at least $p$.
Given such an oracle for the dual program, the ellipsoid method variant can be used to output a solution to the primal, that approximates it to the same factor with probability at least $p^I$, where $I$ is an upper bound on the number of iterations in any execution of the ellipsoid method variant on the dual (if it is given a deterministic oracle).
We can therefore conclude the following result:
\begin{lemma}\label{lemma:approx-sep-oracle-to-goal}
    Given a half-randomized approximate separation oracle to the problem \eqref{eq:app-dual}, with a multiplicative error of $\frac{\beta}{1-\beta}$ and a success probability $p$, a stochastic allocation that approximates leximin to a multiplicative error $\frac{\multError}{1-\multError+\multError^2}$ can be obtained with probability $p^{nI}$.
\end{lemma}

\begin{proof}
    % To begin, assume that we are given a deterministic approximate separation oracle (i.e., with failure probability $p=0$).
    As described above, we can use the ellipsoid method variant of Appendix \ref{sec:mult-variant-ellipsoid} with the given oracle to \eqref{eq:app-dual} to obtain a solution to \eqref{eq:app-ver2-vsums-OP},  that approximates it with a multiplicative error of $\frac{\multError}{1-\multError}$ with probability $p^I$.
    Then, by Lemma \ref{lemma:approx-acc-by-bijection}, we can use the mapping $\psi$ to find the corresponding solution to \eqref{eq:app-vsums-OP}, that, with probability $p^I$, approximates it with a multiplicative error of $\multError$.
    That is, the described process can be used as a randomized approximation procedure to \eqref{eq:vsums-OP} (that became \eqref{eq:app-vsums-OP} under the settings of this problem).
    % with $\multError = \additiveError = 0$.
    Therefore, by Theorem \ref{th:main}, Algorithm \ref{alg:basic-ordered-Outcomes} can be used to obtain an approximately-optimal leximin solution to the original problem with only a multiplicative error of $\frac{\multError}{1-\multError+\multError^2}$ with probability $p^{nI}$ (Corollary \ref{corollary:main-with-probability}).
\end{proof}

Now, we show that such an oracle can be designed given a randomized approximation algorithm for computing a deterministic allocation that approximates the utilitarian welfare. Specifically, 

\begin{lemma}\label{lemma:alg-for-utilitarian-to-sep-oracle}
    Given a randomized approximation algorithm with  algorithm for computing a deterministic allocation that approximates the utilitarian welfare with multiplicative error $\multError$ and a success probability $p$, a half-randomized approximate separation oracle to \eqref{eq:app-dual} can be designed with a multiplicative error of $\frac{\beta}{1-\beta}$ and a success probability at least $\left(1-\frac{1}{nI}(1-p)\right)$.
\end{lemma}

\eden{should say somewhere that the oracle is polynomial time and therefore everything is...}
% FROM HERE: https://tex.stackexchange.com/a/675333/20929
\algdef{SE}[REPEATN]{REPEATN}{ENDREP}[1]{\algorithmicrepeat\ #1 \textbf{times}}{\algorithmicend\ \algorithmicrepeat}
\begin{algorithm}[!tbp]
\caption{A Half-Randomized Approximate Separation Oracle to \eqref{eq:app-dual}}
\label{alg:sep-oracle}
INPUT: variables $q_{\ell}$ and $v_{\ell,j}$ for any $\ell \in [t]$ and $j \in [n]$, an $\multApprox$-approximation algorithm for the utilitarian welfare problem (\eqref{eq:utilitarian}) with success probability $p$.
\begin{algorithmic}[1] %[1] enables line numbers
\STATE Iterate over constraints (2)-(5) of \eqref{eq:app-dual}. If one of them is  violated, stop and return it.
\STATE \textbf{If} $p=1$ then set $T:=1$; \textbf{else} set $T := 1 + \lceil-\log_{(1-p)}(nI)\rceil$.

\REPEATN{$T$}
    \STATE Operate the algorithm for the utilitarian welfare problem on $n,m,(u'_j)_{j=1}^n$ to obtain an allocation $\Tilde{A}$ with value $\nu$.
    \IF{$\nu > 1$}  
        \STATE Return the corresponding violated constraint $\sum_{j=1}^n u_j(\Tilde{A}) \sum_{\ell=1}^t v_{\ell,j} > 1$
    \ENDIF
\ENDREP
\STATE Return "the assignment is approximately-feasible".

\end{algorithmic}
\end{algorithm}


Algorithm \ref{alg:sep-oracle} describes the oracle.
It accepts as input an assignment to the variables of \eqref{eq:app-dual}, that is, $q_{\ell}$ and $v_{\ell,j}$ for any $\ell \in [t]$ and $j \in [n]$, and an algorithm for approximating the maximum utilitarian welfare.
It starts by verifying constraints (2)-(5) one by one (this is possible as their number is polynomial in $n$ and $m$). 
If a violated constraint was found, the oracle simply returns it. Otherwise, it proceeds to check constraints (1).
Although the number of constraints described by (1) is exponential in $n$, they can be treated collectively in polynomial time (as in \cite{kawase_max-min_2020}).
% \eden{here maybe to say something about the randomness}.\erel{Maybe mention that \textcite{kawase_max-min_2020} ignored this issue.}
First, notice that in order to determine whether the expression $\sum_{j=1}^n u_j(A) \sum_{\ell=1}^t v_{\ell,j}$ is at most $1$ for all deterministic allocations ($A \in \mathcal{A}$), it is sufficient to check the allocation that maximizes this expression and compare it to $1$.
Define new utility functions for all $j \in [n]$ and $A \in \mathcal{A}$, 
\begin{align*}
u'_j(A) := \sum_{\ell=1}^t v_{\ell,j} \cdot u_j(A) 
\end{align*}
The above expression can be simplified to $\sum_{j=1}^n u'_j(A)$. An allocation that maximizes this expression is an allocation that maximizes the utilitarian welfare (i.e., the sum of utilities) when the same sets of agents and items is considered but with different utilities%
\footnote{Notice that the utilities $u'_j$ are  normalized, monotone, submodular, and can be computed using $t\leq n$ calls to the value oracle of $u_j$}
($u'_j$ instead of $u_j$ for $j \in [n]$).
Such an allocation cannot be found in polynomial time since approximating the utilitarian welfare up to a factor better than $(1-\frac{1}{e})$ in the case of submodular utilities is known to be NP-hard \cite{khot_inapproximability_2008}.
However, the oracle is given an approximation algorithm to the utilitarian welfare problem as input.
\erel{What algorithm exactly? Is it Vondrak's algorithm?}
\eden{I meant the algorithm the oracle gets as a input. is it more clear now?}
Therefore, an allocation $\Tilde{A}$ with utilitarian value at least $(1-\multError)$ of the optimal can be obtained with probability $p$.
We shall now see that it is enough.


\begin{proof}[Proof of Lemma \ref{lemma:alg-for-utilitarian-to-sep-oracle}]
First, observe that when Algorithm \ref{alg:sep-oracle} returns a violated constraint, it is always correct.
This is obvious for constraints described by (2)-(5), since these constraint has been verified directly.
For constraints described by (1), it means that the algorithm found an allocation $\Tilde{A}$ that satisfies $\sum_{j=1}^n u'_j(\Tilde{A}) > 1$.
    By the definition of $u'$, the constraint corresponding to this allocation is, indeed, violated:
    \begin{align*}
         \sum_{j=1}^n u_j(\Tilde{A}) \sum_{\ell=1}^t v_{\ell,j} = \sum_{j=1}^n u'_j(\Tilde{A}) > 1.
    \end{align*}
Let us assume that the given algorithm for the utilitarian welfare problem is deterministic (i.e., $p=1$) and then revisit the case $p<1$.
    Assume that the oracle said that the assignment is approximately-feasible, and we prove that it is correct.
    This means that the algorithm for the utilitarian welfare problem found an allocation $\Tilde{A}$ with value at most $1$.
    Since $\Tilde{A}$ is approximately-optimal, the optimal utilitarian value is at most $1/(1-\multError)\cdot 1$.
    As this is an upper bound of the utilitarian value of any allocation, it follows that all the constraints are $\frac{\multError}{1-\multError}$-approximately maintained:
    \begin{align*}
        \forall A \in \mathcal{A} \colon \quad \sum_{j=1}^n u'_j(A) = \sum_{j=1}^n u_j(A) \sum_{\ell=1}^t v_{\ell,j} \leq \frac{1}{1-\multError}\cdot 1 = \left(1+\frac{\multError}{1-\multError}\right)\cdot1
    \end{align*}
    We get that, in this case, the oracle is also deterministic, and that the success probability is at least $\left(1-\frac{1}{nI}(1-p)\right) = 1$ for $p=1$.

    Assume now that $p<1$. Then, the oracle may be incorrect when it says the assignment is approximately feasible, but only if the algorithm for the utilitarian welfare problem did not return an appropriate approximation in all $T = \lceil-\log_{(1-p)}(nI)\rceil + 1$ operations, that is, with probability at most $(1-p)^T$.
    % as each operation of the oracle is independent
    Notice that $T>1$ since $\log_{(1-p)}(nI) < 0$\footnote{
    % The fact that  $\log_{(1-p)}(nI) < 0$ can be easily concluded 
    Since $(1-p)\in(0,1)$ and $nI>1$ by change of base: $\log_{(1-p)}(nI) = \log(nI)/\log(1-p)$, the numerator is positive and the denominator is negative.}.
    Now, as $T \geq -\log_{(1-p)}(nI) + 1$ and $(1-p)<1$ we get that:
    \begin{align*}
        &(1-p)^T \leq (1-p)\cdot(1-p)^{-\log_{(1-p)}(nI)} = (1-p)(nI)^{-1}
    \end{align*}
    So, the success probability is at least $\left(1-\frac{1}{nI}(1-p)\right)$.
\end{proof}

We can now prove Theorem \ref{th:app-main}.

\begin{proof}[Proof of Theorem \ref{th:app-main}]
    Assume we are given an algorithm that returns a deterministic allocation that approximates the utilitarian welfare with multiplicative error $\multError$ with success probability $p$.
    By Lemma \ref{lemma:alg-for-utilitarian-to-sep-oracle} this algorithm can be used to obtain an half-randomized approximate separation oracle to \eqref{eq:app-dual} with a multiplicative error $\frac{\multError}{1-\multError}$ with success probability $\left(1-\frac{1}{nI}(1-p)\right)$.
    By Lemma \ref{lemma:approx-sep-oracle-to-goal}, with such an oracle a stochastic allocation that approximates leximin to a multiplicative error of $\frac{\multError}{1-\multError+\multError^2}$ can be obtained with probability $\left(1-\frac{1}{nI}(1-p)\right)^{nI}$.
    If $p=1$ then the success probability is $1$ too (at least $\left(1-\frac{1}{nI}(1-p)\right)^{nI}= 1$).
    However, if $p<1$, then $\frac{1}{nI}(1-p) \in (0,1)$ and therefore the success probability is at least $p$\footnote{For any $\epsilon \in (0,1)$ and $k \in \mathbb{Z}_{+} \colon \Hquad (1 - \epsilon)^k \geq 1 - k \cdot \epsilon$}:
    \begin{align*}
        \left(1-\frac{1}{nI}(1-p)\right)^{nI} \geq \left(1-nI\cdot\frac{1}{nI}(1-p)\right) = p.   \end{align*}
\end{proof}
