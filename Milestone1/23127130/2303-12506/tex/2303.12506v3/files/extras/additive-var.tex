\section{Additive Variant}\label{sec:additive}

\begin{theorem}\label{thm:leximin-approx-alg-leximin-opt}
    Let $\epsilon \in [0,1]$ and \textsf{OP} be a procedure that outputs a $\epsilon$ \emph{additive} approximation to \eqref{eq:vsums-OP}. Then Algorithm \ref{alg:basic-ordered-Outcomes} outputs a $\epsilon$ additive-approximate Leximin solution.  
\end{theorem}

\begin{proof}
    Contrariwise, suppose that $\retSol$ is not an $\epsilon$-approximately Leximin-optimal solution.
    This means that there exists a solution $y$ that is $\epsilon$-preferred over $\retSol$.
    That is, there exists an integer $k \in [n]$ such that:
    \begin{align*}
        \forall j < k \colon &\valBy{j}{y} \geq \valBy{j}{\retSol};\\
        & \valBy{k}{y} > \valBy{k}{\retSol} + \epsilon.
    \end{align*}
    We get that for all $s \in [k-1]$:
    \begin{align*}
         &\sum_{i=1}^s \valBy{i}{y} \geq \sum_{i=1}^s \valBy{i}{\retSol}
        && \text{since } i\leq s<k \text{ and $y$'s def.}\\
        & \geq \sum_{i=1}^s z_i && \text{constraint (2) for $t=n$.}
    \end{align*}
    Therefore, $y$ is a solution to the OP that was solved when $t = k$.
    \erel{You proved that $y$ satisfies constraint (2), but what about constraint (3)?}
    \eden{I'm not sure how to explain that constraint (3) is not a \textbf{standard} constraint. It determines the objective value $z$, so although it is not always optimal, it is always valid.}
    
    In addition, either $k<n$ or $k=n$. 
    If $k<n$ then constraint (2) for $t=n$ says that:
    \begin{align}\label{equ:approx-sum-k-geq-z-1}
        \sum_{i=1}^k \valBy{i}{\retSol} \geq \sum_{i=1}^k z_i
    \end{align}
    If $k=n$ then since $z=z_n$ constraint (3) says it.
    In both cases, we know that equation \ref{equ:approx-sum-k-geq-z-1} holds.
    
    And so, we get that:
    \begin{align*}
         \sum_{i=1}^k \valBy{i}{y} &= \sum_{i=1}^{k-1} \valBy{i}{y} + \valBy{k}{y}\\
         &  \geq\sum_{i=1}^{k-1}\valBy{i}{\retSol} + \valBy{k}{y} &&  \text{since } i \leq k-1 < k \text{ and $y$'s def.}\\
        & > \sum_{i=1}^{k-1}\valBy{i}{\retSol} + \valBy{k}{\retSol} + \epsilon &&  \text{$y$'s def. for } k
        \\
        & = \sum_{i=1}^{k}\valBy{i}{\retSol} + \epsilon \\
        & \geq \sum_{i=1}^{k} z_i + \epsilon &&  \text{equation } \ref{equ:approx-sum-k-geq-z-1}
    \end{align*}
    Which simply means that:
    \begin{align}\label{equ:sum-y-geq-sum-z-plus-eps}
         \sum_{i=1}^k \valBy{i}{y} > \sum_{i=1}^{k} z_i +\epsilon
    \end{align}
    That means that the $z$ achieved by the solution $y$ in the OP that was solved when $t = k$ is strictly more than the value we achieved $z_k$ plus $\epsilon$:
    \begin{align*}
        &\sum_{i=1}^k \valBy{i}{y} - \sum_{i=1}^{k-1} z_i && \text{insulated } z\\
        &> \sum_{i=1}^{k} z_i + \epsilon - \sum_{i=1}^{k-1} z_i  && \text{equation } \ref{equ:sum-y-geq-sum-z-plus-eps} \\
        &= z_k + \epsilon
    \end{align*}
    But we know that the error in this OP is at most $\epsilon$ --- a contradiction.
\end{proof}