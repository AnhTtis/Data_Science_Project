\section{Proof of Theorem \ref{th:app-main}}\label{sec:app-sec-proofs}
% \eden{should probably change the title}

% Agents are assumed to care only about their own share (allowing us to use the following abuse of notation in which $u_j$ takes a bundle $b$ of items), their utilities are assumed to be normalized ($u_j(\emptyset) = 0$), monotone ($u_j(b_1) \leq u_j(b_2)$ if $b_1 \subseteq b_2$), and submodular ($u_j(b_1) + u_j(b_2) \geq u_j(b_1 \cup b_2) + u_j(b_1 \cap b_2)$ for any bundles $b_1,b_2$).
% It is assumed that each agent assigns a positive utility to the set of all items.
% The utilities $(u_i)_{i=1}^n$ are assumed to be given in the \emph{value oracle model}, meaning that we do not have a direct access to them, but only to an oracle that indicates the value of an agent from a given simple allocation.
% % \eden{z1 > 0}

This section proves Theorem \ref{th:app-main}:
suppose we are given a randomized algorithm that returns a simple allocation that approximates the utilitarian welfare with multiplicative error $\multError$ (with success probability $p$).
Then, Algorithm \ref{alg:basic-ordered-Outcomes} can be used to obtain a stochastic allocation that approximates leximin with a multiplicative error of at most $\frac{\multError}{1-\multError +\multError^2}$ (with the same probability).

% title: the specific problem as P3
As we saw in Section \ref{sec:algo-short}, an approximation to leximin can be obtained by providing a procedure \textsf{OP} to approximate \eqref{eq:vsums-OP}  (Theorem \ref{th:main}), which, under these particular settings, becomes:
% \erel{Why do you call it "configuration LP"? I think this term refers to something else: \url{https://en.wikipedia.org/wiki/Configuration_linear_program}}
\begin{align}
&\max \quad z_t \quad s.t. \tag{\progAppFirst}\label{eq:app-vsums-OP}\\
& (\text{\progAppFirst.1.1}) \Hquad \sum_{A \in \mathcal{A}} p_d(A) = 1 \nonumber\\
& (\text{\progAppFirst.1.2}) \Hquad p_d(A) \geq 0  && \forall A \in \mathcal{A} \nonumber\\
& (\text{\progAppFirst.2}) \Hquad \ell y_{\ell} - \sum_{j=1}^n m_{\ell,j}\geq \sum_{i=1}^{\ell}  z_i && \forXinY{\ell}{t-1} \nonumber \\
& (\text{\progAppFirst.3}) \Hquad t y_t - \sum_{j=1}^{n} m_{t,j} \geq \sum_{i=1}^{t}  z_i \nonumber \\
& (\text{\progAppFirst.4}) \Hquad m_{\ell,j} \geq y_{\ell} - \sum_{A \in \mathcal{A}}p_d(A) \cdot u_j(A)  && \forXinY{\ell}{t},\Hquad \forXinY{j}{n} \nonumber \\
& (\text{\progAppFirst.5}) \Hquad m_{\ell,j} \geq 0  && \forXinY{\ell}{t},\Hquad \forXinY{j}{n} \nonumber
\end{align}
Here the variables are $p_d(A)$ for any simple allocation $A \in \mathcal{A}$, $\ztVar{}$, and $y_{\ell}$ and $m_{\ell,j}$ for all $\ell \in [t]$ and $ j\in [n]$; and the values $z_1, \ldots z_{t-1}$ are constants.
Notice that it is a \emph{linear program} that has a polynomial number of constraints thanks to \eqref{eq:vsums-OP} representation, but an exponential number of variables (since there is a variable $p_d(A)$ for each simple allocation).
So, it is unclear how to approach it directly in polynomial time.
% \eden{here?}
In addition, it means that the output size is exponential in $n$.
To deal with this issue, the solutions are considered in \emph{sparse form} --- a list of the variables with positive values, along with their values.
Accordingly, if a solution has only a polynomial number of variables with positive values it can be represented by a polynomial size.
We will later see that the procedure described in this section returns such a solution in polynomial time.
% \eden{should write something about the output size, as \cite{kawase_max-min_2020}}

% title: baseline
% \erel{I would move the following paragraph upwards}
With $t=1$, \eqref{eq:app-vsums-OP} can be viewed as the problem of egalitarian welfare maximization, indeed, Kawase and Sumita \cite{kawase_max-min_2020} who studied this problem, considered a slightly simpler representation. 
% After proving that approximating the optimal value to a factor better than $(1-\frac{1}{e})$ is NP-hard, they present a dual-based algorithm that achieves this accuracy \er{w.h.p (?)}.
We now show how their dual-based technique can be applied to approximate \eqref{eq:app-vsums-OP} for any $t\geq 1$ while maintaining the same approximation factor.


To begin, consider the following program \eqref{eq:app-ver2-vsums-OP}, which is the result of modifying \eqref{eq:app-vsums-OP} in three ways. 
First, changing the objective-function to $\min 1/z_t$ instead of $\max z_t$. 
Second, replacing all the original variables and constants, except $z_t$, with new ones that are smaller by a factor $z_t$ (that is, $p'_A = p_d(A)/z_t$ for all $A \in \mathcal{A}$, $,y'_{\ell} = y_{\ell}/z_t,m'_{\ell,j} = m_{\ell,j}/z_t$ for $\ell \in [t]$ and $ j\in [n]$,  and $z'_i = z_i/z_t$ for $i \in [t-1]$).
And third, dividing all the constraints by $z_t$ ($z_t > 0$ since $z_t \geq z_1$ for any $t \geq 1$ and  $z_1 >0$).
\eden{to myself: maybe to explain why $z_1>0$}

\begin{align}
& \min \quad 1/z_t \quad s.t. \tag{\progAppSecond}\label{eq:app-ver2-vsums-OP}\\
& (\text{\progAppSecond.1.1}) \Hquad \sum_{A \in \mathcal{A}} p'_A = 1/z_t \nonumber\\
& (\text{\progAppSecond.1.2}) \Hquad p'_A \geq 0  && \forall A \in \mathcal{A} \nonumber\\
& (\text{\progAppSecond.2}) \Hquad \ell y'_{\ell} - \sum_{j=1}^n m'_{\ell,j}\geq \sum_{i=1}^{\ell}  z'_i && \forXinY{\ell}{t-1} \nonumber \\
& (\text{\progAppSecond.3}) \Hquad t y'_t - \sum_{j=1}^{n} m'_{t,j} \geq \sum_{i=1}^{t-1}  z'_i + 1 \nonumber \\
& (\text{\progAppSecond.4}) \Hquad m'_{\ell,j} \geq y'_{\ell} - \sum_{A \in \mathcal{A}}p'_A \cdot u_j(A)  && \forXinY{\ell}{t},\Hquad \forXinY{j}{n} \nonumber \\
& (\text{\progAppSecond.5}) \Hquad m'_{\ell,j} \geq 0  && \forXinY{\ell}{t},\Hquad \forXinY{j}{n} \nonumber
\end{align}
The programs \eqref{eq:app-vsums-OP} and \eqref{eq:app-ver2-vsums-OP} are related in the following way:
% \erel{I would make this a lemma:}
\begin{lemma}\label{lemma:bijection}
There exists a bijection mapping each solution of 
\eqref{eq:app-vsums-OP} with objective value $V$ to a unique solution of 
\eqref{eq:app-ver2-vsums-OP} with objective value $1/V$.
\end{lemma}
\begin{proof}
Let $p_d(A)$ for $A \in \mathcal{A}$, $\ztVar{}$, and $y_{\ell}$ and $m_{\ell,j}$ for all $\ell \in [t]$ and $ j\in [n]$ be a feasible solution to the program \eqref{eq:app-vsums-OP} with objective value $V$.
It can be easily verified that $p'_A = p_d(A)/z_t$ for $A \in \mathcal{A}$, $z_t$, and $y'_{\ell} = y_{\ell}/z_t$ and $m'_{\ell,j} = m_{\ell,j}/z_t$ for all $\ell \in [t]$ and $ j\in [n]$ is a feasible solution to the program \eqref{eq:app-ver2-vsums-OP} with objective value $1/V$.
\end{proof}
% \eden{maybe to write something about why it is a bijection (or to write that it is straightforward)}

Denote this bijection by $\Psi$, this also implies the following:
\begin{lemma}\label{lemma:approx-acc-by-bijection}
    If a solution approximates the program \eqref{eq:app-ver2-vsums-OP} with a multiplicative error of $\frac{\multError}{1-\multError}$. Then the corresponding solution to \eqref{eq:app-vsums-OP} according to the bijection $\Psi$ approximates this program with a multiplicative error of $\multError$.
\end{lemma}

\begin{proof}
    Let $V^*$ be the optimal objective value of \eqref{eq:app-vsums-OP}. 
    By Lemma \ref{lemma:bijection}, there exists a solution to \eqref{eq:app-ver2-vsums-OP} with value $1/V^{*}$.
    This solution yields the optimal value for \eqref{eq:app-ver2-vsums-OP} --- if there was a solution that had a value \emph{lower} than $1/V^{*}$ (\eqref{eq:app-ver2-vsums-OP} is a minimization problem), then the corresponding solution to \eqref{eq:app-vsums-OP} (by the bijection $\Psi$) would have a value higher than the optimal value $V^*$.
    Now, let the value of the solution that approximates the program \eqref{eq:app-ver2-vsums-OP} with a multiplicative error of $\frac{\multError}{1-\multError}$ be $1/V$. 
    Since \eqref{eq:app-ver2-vsums-OP} is a minimization problem, assuming that $1/V$ approximates $1/V^*$ with a multiplicative error of $\frac{\multError}{1-\multError}$ means that:
    \begin{align*}
        \frac{1}{V} \leq \left(1+\frac{\multError}{1-\multError}\right)\frac{1}{V^*},
    \end{align*}
 which implies that $V \geq (1-\multError)V^*$.
    As \eqref{eq:app-vsums-OP} is a maximization problem, this means that $V$ approximates this problem with multiplicative error $\multError$.
    By Lemma \ref{lemma:bijection}, $V$ is the value of the corresponding solution to \eqref{eq:app-vsums-OP} by the bijection $\Psi$.
\end{proof}

Notice that the only constraint of \eqref{eq:app-ver2-vsums-OP} that includes the variable $z_t$, (\progAppSecond.1.1), says that $\sum_{A \in \mathcal{A}}p'_A = 1/z_t$, and also that its objective function is $\min 1/z_t$.
As a result, we can reduce the need for the variable $z_t$ by removing constraint (\progAppSecond.1.1) and changing the objective function to $\min \sum_{A \in \mathcal{A}}p'_A$.
This change makes \eqref{eq:app-ver2-vsums-OP} a \emph{linear} program.
This will allow us to approximate it using its dual, as we will see.

The following observation will be useful later:
\begin{observation}\label{obs:c2-to-c1-in-poly-time}
    If a solution to \eqref{eq:app-ver2-vsums-OP} is given in a sparse form --- a list of the variables with nonzero value and their values, then the corresponding solution to \eqref{eq:app-vsums-OP} in a sparse form can be computed in time polynomial to the number of nonzero variables.
\end{observation}
\noindent For completeness, we briefly outline the process. 
When given a list of variables with nonzero values, we first iterate the list and sum all variables of the form $p'_A$, and then set $z_t$ to be $1$ divided by this sum. 
After, for each variable $\nu'$ in the list, we set the corresponding variable, $\nu$, to $z_t \cdot \nu'$.


% title: dual 
Now, let us consider the dual program of \eqref{eq:app-ver2-vsums-OP}, which can be described as follows:
% \erel{When you present an LP, it can help the reader if you mention what exactly the variables of the LP are.}
\begin{align}
    \max &&& \sum_{\ell=1}^{t-1} q_{\ell} \sum_{i=1}^{\ell} z_i + q_t (\sum_{i=1}^{t-1} z_i +1) \tag{\progAppDual}\label{eq:app-dual}\\
        s.t. &&& (\text{\progAppDual.1}) \Hquad \sum_{j=1}^n u_j(A) \sum_{\ell=1}^t v_{\ell,j} \leq 1  && \forall A \in \mathcal{A} \nonumber\\
                    &&& (\text{\progAppDual.2}) \Hquad \ell q_{\ell} - \sum_{j=1}^n v_{\ell,j} = 0 && \forXinY{\ell}{t} \nonumber \\
                    &&& (\text{\progAppDual.3}) \Hquad q_{\ell} - v_{\ell,j} \leq 0  && \forXinY{\ell}{t},\Hquad \forXinY{j}{n} \nonumber \\
                    &&& (\text{\progAppDual.4}) \Hquad v_{\ell,j} \geq 0  && \forXinY{\ell}{t},\Hquad \forXinY{j}{n} \nonumber \\
                    &&& (\text{\progAppDual.5}) \Hquad q_{\ell} \geq 0  && \forXinY{\ell}{t} \nonumber
\end{align}
Here, the variables are $q_{\ell}$ and $v_{\ell,j}$ for any $\ell \in [t]$ and $j \in [n]$; and the constants are (as before) $z_i$ for $i \in [t-1]$.
Recall that $u_j(A)$ is the utility that agent $j$ assigns to simple allocation $A$, as given by the value oracle.
% title: ellipsoid variant
This problem has an exponential number of constraints --- a constraint for each allocation (in line (\progAppDual.1)) but only a polynomial number of variables.
Using the ellipsoid method \cite{grotschel_ellipsoid_1981}, it could be solved in polynomial time 
if we had a \emph{separation oracle} ---
an oracle that given a vector $\upsilon$ either determines that $\upsilon$ is infeasible and returns a violated constraint, or asserts that $\upsilon$ is feasible.
Unfortunately, as we shall now see, it is NP-hard to compute a separation oracle to this problem.
\begin{lemma}
    Computing a separation oracle to \eqref{eq:app-dual} is NP-hard.
\end{lemma}

% very similar to what they did in yonatan's paper..
\begin{proof}
We prove that a separation oracle for \eqref{eq:app-dual} would allow us to compute a leximin optimal stochastic allocation.
    As discussed previously, computing such an allocation is NP-hard, so the same applies for computing a separation oracle for \eqref{eq:app-dual}.

    First, we prove that such a separation oracle can be used to extract an optimal solution to \eqref{eq:app-ver2-vsums-OP}.
    Assume that the ellipsoid method was operated with the given oracle to solve \eqref{eq:app-dual}.
    Let $C$ be the set of constraints that the oracle determined as being violated.
    Since the ellipsoid method operates in polynomial time, the size of the set $C$ is also polynomial.
    Let $V_C$ be the set of variables of \eqref{eq:app-ver2-vsums-OP} associated with the constraints in $C$.
    By complementary slackness, the variables in $V_C$ are the only ones that may get a \emph{positive} value in the corresponding optimal solution to \eqref{eq:app-ver2-vsums-OP}.
    Therefore, the program \eqref{eq:app-ver2-vsums-OP} with only the variables in $V_C$ (and the other variables equal to zero) has a polynomial size, and therefore can be solved exactly.


    But, by Observation \ref{obs:c2-to-c1-in-poly-time}, this would allow us to find the corresponding optimal solution to \eqref{eq:app-vsums-OP} in polynomial time.
    % \erel{Did we say that $\psi$ can be computed in polynomial time?}\eden{in the way it is written now is not, it iterate over each variable of \eqref{eq:app-vsums-OP} and there are exponential number of them. I need to think how to write it appropriately. maybe "that can be computed in time equals to the number of positive variables"?}
    % \erel{If it is not polynomial, then the reduction is not polynomial, so it does not imply NP-hardness}
    This means the described process can be used as an approximation procedure to \eqref{eq:vsums-OP} (that became \eqref{eq:app-vsums-OP} under the settings of this problem) with $\multError = \additiveError = 0$.
    Therefore, by Theorem \ref{th:main}, this means we can use Algorithm \ref{alg:basic-ordered-Outcomes} to obtain a leximin optimal solution\footnote{Actually, Theorem \ref{th:main} says that Algorithm \ref{alg:basic-ordered-Outcomes} will output a $(1,0)$-leximin-approximation; But Lemma \ref{lemma:absence-of-errors} says that such a solution is, indeed, a leximin optimal solution.}.
\end{proof}


% --- it would allow us to compute a leximin optimal stochastic allocation, which is, as discussed previously, NP-hard.

In Appendix \ref{sec:mult-variant-ellipsoid}, we present another variant of the ellipsoid method, which allows us to approximate the program \eqref{eq:app-ver2-vsums-OP} given a \emph{half-randomized approximate separation oracle} to \eqref{eq:app-dual}.
That is, an oracle that, given a multiplicative error $\multError$, a success probability $p$, and a vector $\upsilon$, either determines that $\upsilon$ is infeasible and returns a violated constraint; or determines that $\upsilon$ is $\multError$-\textit{approximately-feasible}, which means that for any constraint $a \cdot x \leq b$, the vector $\upsilon$ satisfies $a \cdot \upsilon \leq (1+\multError)\cdot b$.
When the oracle says that $\upsilon$ is $\multError$-approximately-feasible, it is correct with probability at least $p$.
Given such an oracle for the dual program, the ellipsoid method variant can be used to output a solution to the primal, that approximates it to the same factor with probability at least $p^I$, where $I$ is an upper bound on the number of iterations in any execution of the ellipsoid method variant on the dual (if it is given a deterministic oracle).
We can therefore conclude the following result:
\begin{lemma}\label{lemma:approx-sep-oracle-to-goal}
    Given a half-randomized approximate separation oracle to the problem \eqref{eq:app-dual}, with a multiplicative error of $\frac{\beta}{1-\beta}$ and a success probability $p$, a stochastic allocation that approximates leximin to a multiplicative error $\frac{\multError}{1-\multError+\multError^2}$ can be obtained with probability $p^{nI}$.
\end{lemma}

\begin{proof}
    % To begin, assume that we are given a deterministic approximate separation oracle (i.e., with failure probability $p=0$).
    As described above, we can use the ellipsoid method variant of Appendix \ref{sec:mult-variant-ellipsoid} with the given oracle to \eqref{eq:app-dual} to obtain a solution to \eqref{eq:app-ver2-vsums-OP},  that approximates it with a multiplicative error of $\frac{\multError}{1-\multError}$ with probability $p^I$.
    Then, by Observation \ref{obs:c2-to-c1-in-poly-time}, this would allow us to find the corresponding solution to \eqref{eq:app-vsums-OP}, that, with probability $p^I$, approximates it with a multiplicative error of $\multError$.
    That is, the described process can be used as a randomized approximation procedure to \eqref{eq:vsums-OP} (that became \eqref{eq:app-vsums-OP} under the settings of this problem).
    % with $\multError = \additiveError = 0$.
    Therefore, by Theorem \ref{th:main}, Algorithm \ref{alg:basic-ordered-Outcomes} can be used to obtain a leximin approximation to the original problem with only a multiplicative error of $\frac{\multError}{1-\multError+\multError^2}$ with probability $p^{nI}$ (Corollary \ref{corollary:main-with-probability}).
\end{proof}

Now, we show that such an oracle can be designed given a randomized approximation algorithm for computing a simple allocation that approximates the utilitarian welfare. Specifically, 

\begin{lemma}\label{lemma:alg-for-utilitarian-to-sep-oracle}
    Given a randomized approximation algorithm for computing a simple allocation that approximates the utilitarian welfare with multiplicative error $\multError$ and a success probability $p$, a half-randomized approximate separation oracle to \eqref{eq:app-dual} can be designed with a multiplicative error of $\frac{\beta}{1-\beta}$ and a success probability at least $\left(1-\frac{1}{nI}(1-p)\right)$.
\end{lemma}

% \eden{should say somewhere that the oracle is polynomial time and therefore everything is?...}
% FROM HERE: https://tex.stackexchange.com/a/675333/20929
\algdef{SE}[REPEATN]{REPEATN}{ENDREP}[1]{\algorithmicrepeat\ #1 \textbf{times}}{\algorithmicend\ \algorithmicrepeat}
\begin{algorithm}[!tbp]
\caption{A Half-Randomized Approximate Separation Oracle to \eqref{eq:app-dual}}
\label{alg:sep-oracle}
INPUT: variables $q_{\ell}$ and $v_{\ell,j}$ for any $\ell \in [t]$ and $j \in [n]$, an $\multApprox$-approximation algorithm for the utilitarian welfare problem (\eqref{eq:utilitarian}) with success probability $p$.
\begin{algorithmic}[1] %[1] enables line numbers
\STATE Iterate over constraints (\progAppDual.2)-(\progAppDual.5). If one of them is  violated, stop and return it.
\STATE \textbf{If} $p=1$ then set $T:=1$; \textbf{else} set $T := 1 + \lceil-\log_{(1-p)}(nI)\rceil$.

\REPEATN{$T$}
    \STATE Operate the algorithm for the utilitarian welfare problem on $n,m,(u'_j)_{j=1}^n$ to obtain an allocation $\Tilde{A}$ with value $\nu$.
    \IF{$\nu > 1$}  
        \STATE Return the corresponding violated constraint $\sum_{j=1}^n u_j(\Tilde{A}) \sum_{\ell=1}^t v_{\ell,j} > 1$
    \ENDIF
\ENDREP
\STATE Return "the assignment is approximately-feasible".

\end{algorithmic}
\end{algorithm}


Algorithm \ref{alg:sep-oracle} describes the oracle.
It accepts as input an assignment to the variables of \eqref{eq:app-dual}, that is, $q_{\ell}$ and $v_{\ell,j}$ for any $\ell \in [t]$ and $j \in [n]$, and an algorithm for approximating the maximum utilitarian welfare.
It starts by verifying constraints (\progAppDual.2)-(\progAppDual.5) one by one (this is possible as their number is polynomial in $n$ and $m$). 
If a violated constraint was found, the oracle simply returns it. Otherwise, it proceeds to check constraints (\progAppDual.1).
Although the number of constraints described by (\progAppDual.1) is exponential in $n$, they can be treated collectively in polynomial time (as in \cite{kawase_max-min_2020}).
% \eden{here maybe to say something about the randomness}.\erel{Maybe mention that \textcite{kawase_max-min_2020} ignored this issue.}
First, notice that in order to determine whether the expression $\sum_{j=1}^n u_j(A) \sum_{\ell=1}^t v_{\ell,j}$ is at most $1$ for all simple allocations ($A \in \mathcal{A}$), it is sufficient to check the allocation that maximizes this expression and compare it to $1$.
Define new utility functions for all $j \in [n]$ and $A \in \mathcal{A}$, 
\begin{align*}
u'_j(A) := \sum_{\ell=1}^t v_{\ell,j} \cdot u_j(A) 
\end{align*}
The above expression can be simplified to $\sum_{j=1}^n u'_j(A)$. An allocation that maximizes this expression is an allocation that maximizes the utilitarian welfare (i.e., the sum of utilities) when the same sets of agents and items is considered but with different utilities%
\footnote{Notice that the utilities $u'_j$ are  normalized, monotone, submodular, and can be computed using $t\leq n$ calls to the value oracle of $u_j$}
($u'_j$ instead of $u_j$ for $j \in [n]$).
Such an allocation cannot be found in polynomial time since approximating the utilitarian welfare up to a factor better than $(1-\frac{1}{e})$ in the case of submodular utilities is known to be NP-hard \cite{khot_inapproximability_2008}.
However, the oracle is given an approximation algorithm to the utilitarian welfare problem as input.
Therefore, an allocation $\Tilde{A}$ with utilitarian value at least $(1-\multError)$ of the optimal can be obtained with probability $p$.
We shall now see that it is enough.


\begin{proof}[Proof of Lemma \ref{lemma:alg-for-utilitarian-to-sep-oracle}]
First, observe that when Algorithm \ref{alg:sep-oracle} returns a violated constraint, it is always correct.
This is obvious for constraints described by (\progAppDual.2)-(\progAppDual.5), since these constraints have been verified directly.
For constraints described by (\progAppDual.1), it means that the algorithm found an allocation $\Tilde{A}$ that satisfies $\sum_{j=1}^n u'_j(\Tilde{A}) > 1$.
    By the definition of $u'$, the constraint corresponding to this allocation is, indeed, violated:
    \begin{align*}
         \sum_{j=1}^n u_j(\Tilde{A}) \sum_{\ell=1}^t v_{\ell,j} = \sum_{j=1}^n u'_j(\Tilde{A}) > 1.
    \end{align*}
Let us assume that the given algorithm for the utilitarian welfare problem is deterministic (i.e., $p=1$) and then revisit the case $p<1$.
    Assume that the oracle said that the assignment is approximately-feasible.
    This means that the algorithm for the utilitarian welfare problem found an allocation $\Tilde{A}$ with value at most $1$.
    Since $\Tilde{A}$ is approximately-optimal, the optimal utilitarian value is at most $1/(1-\multError)\cdot 1$.
    As this is an upper bound of the utilitarian value of any allocation, it follows that all the constraints described bu (\progAppDual.1) are $\frac{\multError}{1-\multError}$-approximately maintained --- that is, for any allocation $A \in \mathcal{A}$ the following holds:
    \begin{align*}
        \sum_{j=1}^n u'_j(A) = \sum_{j=1}^n u_j(A) \sum_{\ell=1}^t v_{\ell,j} \leq \frac{1}{1-\multError}\cdot 1 = \left(1+\frac{\multError}{1-\multError}\right)\cdot1
    \end{align*}
    We get that, in this case, the oracle is also deterministic, and that the success probability is at least $\left(1-\frac{1}{nI}(1-p)\right) = 1$ for $p=1$.

    Assume now that $p<1$. Then, the oracle may be incorrect when it says the assignment is approximately feasible, but only if the algorithm for the utilitarian welfare problem did not return an appropriate approximation in all $T = \lceil-\log_{(1-p)}(nI)\rceil + 1$ operations, that is, with probability at most $(1-p)^T$.
    % as each operation of the oracle is independent
    Notice that $T>1$ since $\log_{(1-p)}(nI) < 0$\footnote{
    % The fact that  $\log_{(1-p)}(nI) < 0$ can be easily concluded 
    Since $(1-p)\in(0,1)$ and $nI>1$ by change of base: $\log_{(1-p)}(nI) = \log(nI)/\log(1-p)$, the numerator is positive and the denominator is negative.}.
    Now, as $T \geq -\log_{(1-p)}(nI) + 1$ and $(1-p)<1$ we get that:
    \begin{align*}
        &(1-p)^T \leq (1-p)\cdot(1-p)^{-\log_{(1-p)}(nI)} = (1-p)(nI)^{-1}
    \end{align*}
    So, the success probability is at least $\left(1-\frac{1}{nI}(1-p)\right)$.
\end{proof}

We can now prove Theorem \ref{th:app-main}.

\begin{proof}[Proof of Theorem \ref{th:app-main}]
    Assume we are given an algorithm that returns a simple allocation that approximates the utilitarian welfare with multiplicative error $\multError$ with success probability $p$.
    By Lemma \ref{lemma:alg-for-utilitarian-to-sep-oracle} this algorithm can be used to obtain an half-randomized approximate separation oracle to \eqref{eq:app-dual} with a multiplicative error $\frac{\multError}{1-\multError}$ with success probability $\left(1-\frac{1}{nI}(1-p)\right)$.
    By Lemma \ref{lemma:approx-sep-oracle-to-goal}, with such an oracle a stochastic allocation that approximates leximin to a multiplicative error of $\frac{\multError}{1-\multError+\multError^2}$ can be obtained with probability $\left(1-\frac{1}{nI}(1-p)\right)^{nI}$.
    If $p=1$ then the success probability is $1$ too (at least $\left(1-\frac{1}{nI}(1-p)\right)^{nI}= 1$).
    However, if $p<1$, then $\frac{1}{nI}(1-p) \in (0,1)$ and therefore the success probability is at least $p$\footnote{For any $\epsilon \in (0,1)$ and $k \in \mathbb{Z}_{+} \colon \Hquad (1 - \epsilon)^k \geq 1 - k \cdot \epsilon$}:
    \begin{align*}
        \left(1-\frac{1}{nI}(1-p)\right)^{nI} \geq \left(1-nI\cdot\frac{1}{nI}(1-p)\right) = p.   \end{align*}
\end{proof}
