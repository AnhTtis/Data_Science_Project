\section{Approximate Leximin Optimality}\label{sec:approx-leximin-def}
In this section, we present our definition of leximin approximation in the presence of multiplicative and additive errors, in the context of multi-objective optimization problems.


% \yonatan{I think the following discussion is too detailed for the introduction - where the actual definition is not provided.}
\subsection{Motivation: Unsatisfactory  Definitions}

Which solutions should be considered approximately-optimal in terms of  leximin? 
Several definitions appear intuitive at first glance.
As an example, suppose we are interested in approximations with an allowable multiplicative error of $0.1$.
Denote the utilities in the leximin-optimal solution by $(u_1,\ldots,u_n)$.
A first potential definition is that any solution in which the sorted utility vector is at least $(0.9\cdot u_1,\ldots,0.9\cdot u_n)$ should be considered approximately-optimal.
For example, if the utilities in the optimal solution are $(1,2,3)$, then a solution with utilities $(0.9, 1.8, 2.7)$ is approximately-optimal.
However, allowing the smallest utility to take the value $0.9$ may substantially increase the maximum possible value of the second (and third) smallest utility --- e.g.~a solution that yields utilities $(0.9, 1000,1000)$ might exist. In that case, a solution with utilities  $(0.9, 1.8, 2.7)$ is very far from optimal.
We expect a good approximation notion to consider the fact that an error in one utility might change the optimal value of the others.

The following, second attempt at a definition, captures this requirement.
An approximately-optimal solution is one that yields utilities at least $(0.9\cdot m_1, 0.9 \cdot m_2, \dots, 0.9 \cdot m_n)$, where $m_1$ is the maximum value of the smallest utility, $m_2$ is the maximum value of the second-smallest utility \emph{among all solutions whose smallest utility is at least $0.9 \cdot m_1$};
$m_3$ is the maximum value of the third-smallest utility among all solutions whose smallest utility is at least $0.9 \cdot m_1$ and their second-smallest utility is at least $0.9\cdot m_2$; and so on. 
In the above example, to be considered approximately-optimal, the smallest utility should be at least $0.9$ and the second-smallest should be at least $900$.
Thus, a solution with utilities $(0.9, 1.8, 2.7)$ is not considered approximately-optimal. Unfortunately, according to this definition, even the leximin-optimal solution --- with utilities $(1,2,3)$  --- is not considered approximately-optimal.
We expect a good approximation notion to be a relaxation of leximin-optimality.
% \eden{is this paragraph relevant here? if so, to write about algorithms as well?\\
% \textit{Is there an algorithm that can be used when the single-objective solver can only approximate the optimal value?}}
% \erel{I like the examples. I am not sure where is the best place to mention the algorithms.}



\subsection{Our Definition}\label{sub:our-def}
 Let $\DEFmultApprox\in (0,1]$ and $\DEFadditiveApprox \geq 0$ be multiplicative and additive approximation factors, respectively.

% \eden{I took out the definition of a numerical value preferred over another, how is that?}
\paragraph{Comparison of values}
As we focus on maximization problems, 
%a value $v_1 \in \mathbb{R}$ is considered a $(\DEFmultApprox,\DEFadditiveApprox)$-approximation of a value $v_2 \in \mathbb{R}$ if $v_1 \geq \DEFmultApprox\cdot v_2 - \DEFadditiveApprox$.
%
%
% we say that a value %Therefore, we say that 
% $v_2$ is \emph{$(\DEFmultApprox,\DEFadditiveApprox)$-preferred} over another value $v_1$ if $v_2 > \frac{1}{\DEFmultApprox}(v_1 + \DEFadditiveApprox)$.
% That is, if $v_1$ is smaller than any approximation of $v_2$.
given two values $v_2 \geq v_1 \geq 0$, we say that $v_1$ approximates $v_2$ if $v_1 \geq \DEFmultApprox \cdot v_2 - \epsilon$.
In this case, $v_1$ is an approximate replacement for $v_2$.
However, when $v_1 < \DEFmultApprox \cdot v_2 - \epsilon$, we say that $v_2$ is \emph{$(\DEFmultApprox,\DEFadditiveApprox)$-substantially-higher} than $v_1$.
In this case, $v_1$ is smaller than any $(\alpha,\epsilon)$-approximation of $v_2$. 
\eden{is it clearer now?}


\paragraph{The approximate leximin order} 
The first step is defining the following \textit{partial} order\footnote{A proof that the approximate leximin order is a strict partial order can be found in Appendix \appendixName{\ref{sec:approx-order-is-strict-partial}}{A}\fullVer.}:
%(a partial order allows two solutions with different utilities such that no one is preferred over the other).:
a solution $y$ is \emph{$(\DEFmultApprox,\DEFadditiveApprox)$-leximin-preferred} over a solution $x$, denoted $y \alphaBetaPreferred x$, if there exists an integer $1 \leq k \leq n$ such that the smallest $(k-1)$ objective values of $y$ are \emph{at least} those of $x$, and the $k$'th smallest objective value of $y$ is $(\DEFmultApprox,\DEFadditiveApprox)$-substantially-higher than the $k$'th smallest objective value of $x$, that is:
\begin{align*}
    \forall j < k \colon \quad &\valBy{j}{y} \geq \valBy{j}{x}\\
    &\valBy{k}{y} > \frac{1}{\DEFmultApprox} \left( \valBy{k}{x} + \DEFadditiveApprox\right)
\end{align*}
A maximal element of this order is a solution over which no solution is $(\DEFmultApprox,\DEFadditiveApprox)$-leximin-preferred.
% Note that it is not equivalent to one that is preferred over all others (as in total order).
For clearity, we define the corresponding relation set as follows:
\begin{align*}
    \relationSetAlphaBeta = \{(y,x) \mid  x,y \in S, \Hquad y \alphaBetaPreferred x\}
\end{align*}
% The corresponding relation set is defined as follows:
% \begin{align*}
%     \relationSetAlphaBeta = \{(y,x) \mid \forall x,y \in S \colon y \alphaBetaPreferred x\}
% \end{align*}

Before describing the approximation definition, we present two observations about this relation that will be useful later, followed by an example to illustrate how it works.
The proofs are straightforward and are omitted. 

\iffalse
Consider the case were $\DEFmultApprox = 1$ and $\DEFadditiveApprox=0$. 
The relations $\leximinPreferred$ and $\alphaBetaPreferredParams{1}{0}$ may look similar at first glance (as the requirement for $k$ is the same), but they are different.
In the first relation, the requirement for $j<k$ says that the values of $y$ are \emph{equal} to those of $x$, while in the second relation it says that they are \emph{at least} as good. 
In spite of this, Lemma \ref{lemma:approx-relation-prop1} proves that these two relation are equivalent.
\fi
The first observation is that the leximin order is equivalent to the approximate leximin order for $\DEFmultApprox = 1$ and $\DEFadditiveApprox = 0$ (that is, in the absence of errors).

\begin{lemma}\label{lemma:approx-relation-prop1}
    Let $x,y \in S$. Then, $y \leximinPreferred x \iff y \alphaBetaPreferredParams{1}{0} x$
\end{lemma}

\iffalse
\begin{proof}
For the first direction,
    assume that $y \leximinPreferred x$. 
    By definition there exists an integer $1 \leq k \leq n$ such that $\valBy{j}{y} = \valBy{j}{x}$ for any $j < k$, and $\valBy{k}{y} > \valBy{k}{x}$.
    It is easy to verify that the same $k$ also implies that $y \alphaBetaPreferredParams{1}{0} x$. 
    
For the second direction,
    assume that $y \alphaBetaPreferredParams{1}{0} x$. 
    By definition there exists an integer $1 \leq k \leq n$ such that $\valBy{j}{y} \geq \valBy{j}{x}$ for any $j < k$, and $\valBy{k}{y} > \frac{1}{1} \left(\valBy{k}{x}+0\right) = \valBy{k}{x}$.
    Let $k'$ be the smallest integer for which $\valBy{k'}{y} > \valBy{k'}{x}$; 
    % (such a $k'$ must exist since it is true in particular for $k$) . 
    Note that $k'\leq k$.
    This means that $\valBy{j'}{y} = \valBy{j'}{x}$  for any $j' < k'$, and $\valBy{k'}{y} > \valBy{k'}{x}$, so $y \leximinPreferred x$.
\end{proof}
\fi


% The second observation is related to the sizes of the different errors determined by $\DEFmultApprox$ and $\DEFadditiveError$.
The second observation relates different approximate leximin orders according to their \emph{error} factors.
Notice that, for additive errors, $\DEFadditiveError$ also describes the error size; whereas for multiplicative errors, one minus $\DEFmultApprox$ describes it.
Throughout the remainder of this section, we denote the multiplicative \emph{error factor} by $\DEFmultError = 1-\DEFmultApprox$.
% EREL: Why is it called sometimes $\theta$ and sometimes $\beta$?
% EDEN: in the definition section we use different alphas 

\begin{observation}\label{obs:approx-relation-prop2}
     Let $0 \leq \DEFmultErrorOf{\DEFmultApprox_1} \leq  \DEFmultErrorOf{\DEFmultApprox_2} < 1$ and $0 \leq \DEFadditiveError_1 \leq \DEFadditiveError_2$. 
     Then, $y \alphaBetaPreferredParams{\DEFmultApprox_2}{\DEFadditiveApprox_2} x \Rightarrow y \alphaBetaPreferredParams{\DEFmultApprox_1}{\DEFadditiveApprox_1} x$.
\end{observation}
% \begin{proof}
%     Assume that $y \xPreferred{\gamma} x$.
%     By definition this means that there exists an integer $k\in [n]$ such that:
%     \begin{align*}
%         \forall j < k \colon \quad &\valBy{j}{y} \geq \valBy{j}{x}\\
%         &\valBy{k}{y} > \gamma \cdot \valBy{k}{x} 
%     \end{align*}
%     However, since $\gamma \geq \delta$, this $k$ also implies that $y \alphaBetaPreferred x$ as $\valBy{k}{y} > \gamma \cdot \valBy{k}{x} \geq \delta \cdot \valBy{k}{x}$, and for $j<k$ it is the same as for $\gamma$. 
% \end{proof}
One can easily verify that it follows directly from the definition as
% $\DEFmultApprox_1 \geq \DEFmultApprox_2$ and therefore,
$\frac{1}{\DEFmultApprox_2} \geq \frac{1}{\DEFmultApprox_1}$. 
% Lemma \ref{lemma:approx-relation-prop2} connects the different relations generated by different parameters, that is, the relations $\xPreferred{\gamma}$ and $\alphaBetaPreferred$, arising from $\gamma \geq \delta \geq 1$.
Accordingly, by considering the relation sets $\relationSetParams{\DEFmultApprox_1}{\DEFadditiveApprox_1}$ and $\relationSetParams{\DEFmultApprox_2}{\DEFadditiveApprox_2}$, we can conclude that $\relationSetParams{\DEFmultApprox_2}{\DEFadditiveApprox_2} \subseteq \relationSetParams{\DEFmultApprox_1}{\DEFadditiveApprox_1}$.
This means that as the \emph{error} parameters $\DEFmultError$ and $\DEFadditiveApprox$ increase,
the relation becomes \emph{more partial}:
when $\DEFmultError = 0$ and $\DEFadditiveApprox = 0$ it is a total order, any two elements that yield different utilities appear as a pair in $\relationSetParams{1}{0}$; but as they increase, the set $\relationSetAlphaBeta$ potentially becomes smaller, as fewer pairs are comparable.

% \eden{to use not non-ordered utilities if there is space}
\paragraph{Example } To illustrate, consider a group of $3$ agents, that has to select one out of three options $x,y,z$, with sorted utility vectors $\sortedValues{x}=(1,10,15), \sortedValues{y} =(1,40,60), \sortedValues{z}=(2,20,30)$.
% $u_x=(1,10,15), u_y =(1,40,60), u_z=(2,20,30)$.
% \eden{TODO: give two practical examples with calc}
Table \ref{table:relationSets} indicates what is $\relationSetParams{\DEFmultApprox}{\DEFadditiveApprox}$ for different choices of $\DEFmultApprox$ and $\DEFadditiveApprox$.
\displayEcai{

}
It is easy to verify that, indeed, $\relationSetParams{1}{0}$ is a total order --- $(z,x), (z,y) \in \relationSetParams{1}{0}$ since $2>1$ and $(y, x) \in \relationSetParams{1}{0}$ since $1=1$ and $40>10$.
\displayEcai{

}
In accordance with Observation \ref{obs:approx-relation-prop2}, the relation set remains the same or becomes smaller as either $\DEFmultApprox$ decreases (and the error factor $\DEFmultError$ increases) or $\DEFadditiveError$ increases.
As an example, we provide a partial calculation of $\relationSetParams{0.75}{1}$.
\displayEcai{

}
First, by Observation \ref{obs:approx-relation-prop2}, we know that $\relationSetParams{0.75}{1} \subseteq \relationSetParams{1}{0}$, and so, it is sufficient to consider only the pairs in $\relationSetParams{1}{0}$. 
\displayEcai{

}
Consider the pair $(z,x)$.
In order to be included in the relation set, there must be a $1 \leq k \leq 3$ that meets the requirements.
For $k=1$, as $2 \ngtr \frac{1}{0.75}(1+1)$, the requirement for $k$ does not hold.
However, for $k=2$, it does. As $2 \geq 1$, the requirement for $i<k$ holds; and as $20 > \frac{1}{0.75}(10+1)$, the requirement for $k$ holds.
Therefore, $(z,x) \in \relationSetParams{0.75}{1}$.
Similarly, one can check that
$(y,x) \in \relationSetParams{0.75}{1}$.
\displayEcai{

}
Next, consider the pair $(z,y)$.
For $k=1$, as before, since $2 \ngtr \frac{1}{0.75}(1+1)$, the requirement for $k$ does not hold.
For $k =2$ and $k=3$, it is sufficient to notice that $20 < 40$, therefore the requirements for both does not hold. And so, $(z,y) \notin \relationSetParams{0.75}{1}$.


\begin{table}
\centering
{\caption{Different relation sets result from different choices of $\DEFmultApprox$ and $\DEFadditiveApprox$ in the example above.
Each cell contains the corresponding relation set $\relationSetParams{\DEFmultApprox}{\DEFadditiveApprox}$.}
\label{table:relationSets}}
\begin{tabular}{|c |c c c c|}
 \hline
\backslashbox{$\DEFmultApprox$}{$\DEFadditiveApprox$}& 0 & 1 & 15 & 45 \\ 
 \hline
 1 & \{(z,x),(z,y),(y,x)\} & \{(z,x),(y,x)\} & \{(y,x)\} & \{\}\\ 
 0.75 & \{(z,x),(z,y),(y,x)\} & \{(z,x),(y,x)\} & \{(y,x)\} &\{\}\\
 0.5 & \{(y,x)\} & \{(y,x)\} & \{\}&\{\} \\
 0.25 & \{\} & \{\} & \{\}&\{\} \\ [1ex]
 \hline
\end{tabular}
\end{table}


% \begin{center}
% \begin{tabular}{|c c ||c c c c|} 
%  \hline
%  &&\multicolumn{4}{c}{ $\DEFadditiveError$} \\
% && 0 & 1 & 15 & 45 \\ 
%  \hline\hline
%  \multirow{4}[0]{*}{\begin{turn}{90} $\DEFmultError$ \end{turn}} &0 & \{(z,x),(z,y),(y,x)\} & \{(z,x),(z,y),(y,x)\} & \{(y,x)\} & \{\}\\ 
%  &0.25 & \{(z,x),(z,y),(y,x)\} & a & b &f\\
%  &0.5 & \{(y,x)\} & c & e&h \\
%  &0.75 & \{\} & d & ee&g \\ \\ [1ex]
%  \hline
% \end{tabular}
% \end{center}


% \eden{for us for checking my calculation:
% \begin{align*}
%     &\relationSetParams{0.25}{0} = \{(z,x),(z,y),(y,x)\} \Hquad \frac{1}{1-0.25} \approx 1.33\\
%     & \quad (z,x), (z,y) \text{ since } 2 > \frac{1}{1-0.25}1 \approx 1.33, \Hquad (y,x)  \text{ since } 40 > \frac{1}{1-0.25}10 \approx 13.33\\
%     &\relationSetParams{0.5}{0} = \{(y,x)\}  \Hquad \frac{1}{1-0.5} = 2\\
%     & \quad (y,x) \text{ since } 40 > \frac{1}{1-0.5}10\approx 1.33, \Hquad \text{NOT }(z,x), (z,y)  \text{ since the ratio is} <2\\
%      &\relationSetParams{0.75}{0} = \emptyset,  \Hquad \frac{1}{1-0.75} = 4, \Hquad \text{ the ratio is always} \leq 4\\ 
%      &\relationSetParams{0}{1} = \{(z,x),(z,y),(y,x)\}\\
%      &\relationSetParams{0}{15} = \{(y,x)\}\\
%      &\relationSetParams{0}{45} = \emptyset,\Hquad \text{ the difference is always} \leq 45\\ \\
%      &\relationSetParams{0.1}{0.5} = \{(z,x),(z,y),(y,x)\}\\
%      &\relationSetParams{0.25}{1} = \{(y,x)\}\\
%      &\relationSetParams{0.25}{20} = \emptyset
% \end{align*}
% }


The leximin approximation can now be defined.

\paragraph{Leximin approximation}
We say that a solution $x\in S$ is \emph{$(\DEFmultApprox,\DEFadditiveError)$-approximately leximin-optimal} if it is a maximum element of the order $\alphaBetaPreferred$\displayComsoc{.} \displayEcai{ in $S$ for $\DEFmultApprox\in (0,1]$ and $\DEFadditiveError \geq 0$.
That is, if there is \emph{no} solution in $S$ that is $(\DEFmultApprox,\DEFadditiveError)$-leximin-preferred over it.}
For brevity, we use the term \emph{leximin approximation} to describe an approximately leximin-optimal solution.
% --- $y \nAlphaBetaPreferred x$ for all $y\in S$.


This definition has some important properties.
Lemma \ref{lemma:absence-of-errors} proves that in the absence of errors ($\DEFmultError = \DEFadditiveError = 0$) it is equivalent to the exact leximin optimal definition. 
Then, Lemma \ref{lemma:beta1-beta2-approx} shows that an $(\DEFmultApprox_1,\DEFadditiveError_1)$-leximin-approximation is also an $(\DEFmultApprox_2,\DEFadditiveError_2)$-leximin-approximation when $0 \leq \DEFmultErrorOf{\DEFmultApprox_1} \leq  \DEFmultErrorOf{\DEFmultApprox_2} < 1$ and $0 \leq \DEFadditiveError_1 \leq \DEFadditiveError_2$.
Finally, Lemma \ref{lemma:exact-is-always-optimal} proves that a leximin optimal solution is also a leximin approximation for all factors.
% And third, the definition preserves the leximin nature according to which a solution that hurts the poorest is never preferred.

\begin{lemma}\label{lemma:absence-of-errors}
 % In the absence of errors, $\DEFmultError = \DEFadditiveError = 0$, a solution is a leximin approximation if and only if it is leximin optimal.
 A solution is a $(1,0)$-leximin-approximation if and only if it is leximin optimal.
\end{lemma}
% \eden{should it be a corollary?}
\begin{proof}
    % We will show that $x^*$ is a leximin optimal solution if and only if it is approximately-optimal for $\DEFmultError = 0$.
    % First, assume that $x^*$ is a leximin optimal solution. 
    % From Lemma \ref{lemma:exact-is-always-optimal} it is also approximately-optimal for any $\DEFmultError \in [0,1)$, in particular for  $\DEFmultError = 0$.
    % Now, assume that $x^*$ is approximately-optimal for $\DEFmultError = 0$.
    % By definition, $x \nxPreferred{1} x^*$ for any solution $x \in S$. 
    % By Observation \ref{obs:approx-relation-prop2} we can conclude that $x \nLeximinPreferred x^*$ and therefore it is 
    %
    % The claim follows almost directly from Lemma \ref{lemma:approx-relation-prop1}, which implies that $y \nLeximinPreferred x \iff y \nAlphaBetaPreferredParams{0}{0} x$.
    By definition, a solution $x^*$ is a $(1,0)$-leximin-approximation if and only if $x \nAlphaBetaPreferredParams{1}{0} x^*$ for any solution $x \in S$.
    This holds if and only if $x \nLeximinPreferred x^*$ for any solution $x \in S$ (by Lemma \ref{lemma:approx-relation-prop1}).
    Thus, by definition, $x^*$ is also leximin optimal.
\end{proof}




\begin{lemma}\label{lemma:beta1-beta2-approx}
    Let $0 \leq \DEFmultErrorOf{\DEFmultApprox_1} \leq  \DEFmultErrorOf{\DEFmultApprox_2} < 1$, $0 \leq \DEFadditiveError_1 \leq \DEFadditiveError_2$, and $x \in S$ be an $(\DEFmultApprox_1,\DEFadditiveError_1)$-leximin-approximation. Then $x$ is also an $(\DEFmultApprox_2,\DEFadditiveError_2)$-leximin-approximation.
\end{lemma}

\begin{proof}
    Since $x$ is an $(\DEFmultApprox_1,\DEFadditiveError_1)$-leximin-approximation, by definition, $y \nAlphaBetaPreferredParams{\DEFmultApprox_1}{\DEFadditiveError_1} x$ for any solution $y \in S$.
    Observation \ref{obs:approx-relation-prop2} implies
        % \footnote{Observation \ref{obs:approx-relation-prop2} says that $y \alphaBetaPreferredParams{\DEFmultError_2}{\DEFadditiveError_2} x \Rightarrow y \alphaBetaPreferredParams{\DEFmultError_1}{\DEFadditiveError_1} x$, which implies that $y \nAlphaBetaPreferredParams{\DEFmultError_1}{\DEFadditiveError_1} x \Rightarrow y \nAlphaBetaPreferredParams{\DEFmultError_2}{\DEFadditiveError_2} x$.} 
        that
        % $y \nAlphaBetaPreferredParams{\DEFmultError_1}{\DEFadditiveError_1} x \Rightarrow 
        $y \nAlphaBetaPreferredParams{\DEFmultApprox_2}{\DEFadditiveError_2} x$ 
    % Therefore, $y \nAlphaBetaPreferredParams{\DEFmultError_2}{\DEFadditiveError_2} x$ 
    for any solution $y \in S$. This means, by definition, that $x$ is an $(\DEFmultApprox_2,\DEFadditiveError_2)$-leximin-approximation.
\end{proof}


\begin{lemma}\label{lemma:exact-is-always-optimal}
    Let $x^* \in S$ be a leximin optimal solution. Then $x^*$ is also an $(\DEFmultApprox,\DEFadditiveError)$-leximin-approximation for any $\DEFmultError \in [0,1)$  and $\DEFadditiveError \geq 0$.
\end{lemma}

% \eden{maybe we should say somewhere that for brevity when we say "any other solution" we mean any solution that has different sorted utility vector; where is the right place to write it?}
\begin{proof}
    % Let $\DEFmultError \in [0,1)$.
    By Lemma \ref{lemma:absence-of-errors}, $x^*$ is an $(1,0)$-leximin-approximation.
    Thus, according to Lemma \ref{lemma:beta1-beta2-approx}, $x^*$ is also an $(\DEFmultApprox,\DEFadditiveError)$-leximin-approximation for any $0 \leq \DEFmultErrorOf{\DEFmultApprox} < 1$ and $\DEFadditiveError \geq 0$.
    %
    % definition of a leximin optimal solution,  $x \nLeximinPreferred x^*$ for any solution $x \in S$.
    % However, as $\frac{1}{1-\DEFmultError} \geq 1$, Observation \ref{obs:approx-relation-prop2} implies\footnote{Observation \ref{obs:approx-relation-prop2} says that $y \xPreferred{\gamma} x \Rightarrow y \alphaBetaPreferred x$ for $\gamma \geq \delta \geq 1$, which implies that $y \nDeltaPreferred x \Rightarrow y \nxPreferred{\gamma} x$} that $x \nLeximinPreferred x^* \Rightarrow x \nxPreferred{\frac{1}{1-\DEFmultError}} x^*$.
    % Therefore, there is no solution that is  $\frac{1}{1-\DEFmultError}$-preferred over $x^*$ and so, by definition, $x^*$ is also $(1-\DEFmultError)$ approximately-optimal.
\end{proof}



Using the example given previously, we shall now demonstrate that as the error parameters $\DEFmultError$ and $\DEFadditiveError$ increase, the quality of the approximation decreases.
Consider table \ref{table:relationSets} once again.
% \displayComsoc{Consider table \ref{table:relationSets} once again.}
% \displayEcai{Table \ref{table:approx-solutions} displays, for any choice of $\DEFmultApprox$ and $\DEFadditiveApprox$, the solutions that are $(\DEFmultApprox,\DEFadditiveApprox)$-approximately leximin-optimal.
% The values in the tables can be easily deduced from the relation sets in Table \ref{table:relationSets}.

% }
If the corresponding relation set for $\DEFmultApprox$ and $\DEFadditiveApprox$ is the total order $\{(z,x),(z,y),(y,x)\}$, the only solution over which no other solution is $(\DEFmultApprox,\DEFadditiveApprox)$-leximin-preferred is $z$. Therefore, $z$ is the only $(\DEFmultApprox,\DEFadditiveApprox)$-leximin-approximation for these factors.
Indeed, it is the only group decision that maximizes the welfare of the agent with the smallest utility.
If the corresponding relation set is either $\{(z,x),(y,x)\}$ or $\{(y,x)\}$, as no solution is $(\DEFmultApprox,\DEFadditiveApprox)$-leximin-preferred over $z$ and $y$, both are $(\DEFmultApprox,\DEFadditiveApprox)$-leximin-approximations.
For example, for $\alpha=0.5$ and $\epsilon=0$, $z$ still maximizes the utility of the poorest agent (2), and $y$ gives the poorest agent a utility of $1$, which is acceptable as it is half the maximum possible value $(2)$, and subject to giving the poorest agent at least $1$, maximizes the second-smallest utility ($40$). In contrast, while $x$, too, gives the poorest agent utility $1$, its second-smallest utility is $10$, which is less than half the maximum possible in this case ($40$), and therefore, $x$ is not a $(\alpha,\epsilon)$-leximin-approximation.
Lastly, if  the relation set is the empty set, then no solution is $(\alpha,\epsilon)$-leximin-preferred over the other, and all are $(\alpha,\epsilon)$-leximin-approximations.


% \displayEcai{
% Using the example given previously, we shall now demonstrate that as the error parameters $\DEFmultError$ and $\DEFadditiveError$ increase, the quality of the \emph{approximation} decreases.
% Table \ref{table:approx-solutions} displays, for any choice of $\DEFmultApprox$ and $\DEFadditiveApprox$, the solutions that are $(\DEFmultApprox,\DEFadditiveApprox)$-approximately leximin-optimal.
% The values in the tables can be easily deduced from the relation sets in Table \ref{table:relationSets}.
% If the relation set is the total order $\{(z,x),(z,y),(y,x)\}$, the only solution that no other solution is  leximin-preferred over is $z$. Therefore, in these cases, $z$ is the only approximately leximin-optimal solution.
% If the relation set is either $\{(z,x),(y,x)\}$ or $\{(y,x)\}$, as no solution is leximin-preferred over $z$ and $y$, both are approximately leximin-optimal solutions.
% Lastly, if  the relation set is the empty set, then no solution is leximin-preferred over the other, and all are approximately leximin-optimal solutions.

\eden{I removed the second table since there was no space for it. is it clear enough?}
% \displayEcai{
% \begin{table}
% \begin{center}
% {\caption{The approximately leximin-optimal solutions result from different choices of $\DEFmultApprox$ and $\DEFadditiveApprox$ in the previous example.
% Each cell contains all of the solutions that are  $(\DEFmultApprox,\DEFadditiveApprox)$-approximately leximin-optimal.}
% \label{table:approx-solutions}
% }
% \begin{tabular}{|c |c c c c|}
%  \hline
% \backslashbox{$\DEFmultApprox$}{$\DEFadditiveApprox$}& 0 & 1 & 15 & 45 \\ 
%  \hline
%  1 & $z$ & $z,y$ & $z,y$ & $z,y,x$\\ 
%  0.75 & $z$ & $z,y$ & $z,y$ &$z,y,x$\\
%  0.5 & $z,y$ & $z,y$ & $z,y,x$ & $z,y,x$ \\
%  0.25 & $z,y,x$ & $z,y,x$ & $z,y,x$ & $z,y,x$ \\ [1ex]
%  \hline
% \end{tabular}
% \end{center}
% \end{table}
% }
%%%

% We saw that $\relationSetParams{1}{0} = \{(z,x),(z,y),(y,x)\}$. 
% This makes the leximin optimal solution, $z$, the only solution over which no solution is preferred, and thus, as expected, the only approximately-optimal solution for these parameters.
% The same applies for $\relationSetParams{0.75}{0} = \relationSetParams{1}{1} = \relationSetParams{0.9}{0.5} = \{(z,x),(z,y),(y,x)\}$ --- the only approximately-optimal solution for these parameters is $z$.
% However, $\relationSetParams{0.5}{0} =\relationSetParams{1}{15} = \relationSetParams{0.75}{1} = \{(y,x)\}$. 
% According to the relation set $\{(y,x)\}$, both $z$ and $y$ are solutions over which no solution is preferred, and therefore, they are both approximately optimal for these parameters.
% Lastly, as $\relationSetParams{0.25}{0} =\relationSetParams{1}{45} = \relationSetParams{0.75}{20} = \emptyset$, \emph{all} three solutions are approximately-optimal for these parameters.


\paragraph{Egalitarian generalization} 
Another property of our definition is that a leximin-approximation also approximates the optimal egalitarian welfare to the same approximation factors. Formally: 

\begin{observation}\label{obs:rppeox-lex-generalizes-approx-egal}
    Let $x$ be an $(\DEFmultApprox, \DEFadditiveApprox)$-leximin-approximation. Then, the egalitarian value of $x$ (i.e., $\min_{i \in [n]} f_i(x) = \valBy{1}{x}$) is an $(\DEFmultApprox, \DEFadditiveApprox)$-approximation of the optimal egalitarian value (i.e., $\max_{y \in S}\min_{i \in [n]} f_i(y)$).
\end{observation}

