\section{Method}
\label{sec:method}
\newcommand{\argmax}{\mathop{\mathrm{argmax}}}
\newcommand{\x}{\boldsymbol{x}}
\newcommand{\f}{\boldsymbol{f}}
\newcommand{\p}{\boldsymbol{p}}
\newcommand{\A}{\boldsymbol{a}}
\newcommand{\B}{\boldsymbol{\varphi}}
\newcommand{\D}{\boldsymbol{\delta}}
\newcommand{\DD}{\boldsymbol{\Delta}}

\newcommand{\J}{\left[j\right]}
\newcommand{\lgt}{\boldsymbol{l}}
\newcommand{\old}{\boldsymbol{o}}
\newcommand{\new}{\boldsymbol{n}}
\newcommand{\para}{\boldsymbol{\theta}}
\newcommand{\pt}{t\!-\!1}
\newcommand{\pc}{\p_{\left\{\B^{\pt}_{y}\right\}}}
\newcommand{\xc}{\mathcal{X}^{t}_{\left\{\B^{\pt}_{y}\right\}}}

\subsection{Preliminaries and Notions}

\begin{figure*}[t] 
\centering
\includegraphics[width=0.9\linewidth]{figs/figure1.pdf} 
\caption{Schematic diagram of semantic compensation with analogous prompt.
}
\label{fig:figure1} 
\end{figure*}

\textbf{Incremental Learning}. 
Incremental learning (IL) is to train a single model on a non-stationary data stream without catastrophic forgetting. In this paper, we focus on the senior where a sequence of task is well defined, \emph{i.e.}, $t \in  \mathcal{T}=\left\{1,2,\cdots, T\right\}$, $T$ is the total task number, and we can only access the current task data. Let $\mathcal{Y}^{t}$ denote the label set of the task-$t$, and $\mathcal{S}^{t}$ denote all seen labels until the task-$t$,\emph{i.e.}, $\mathcal{S}^{t}$ = $\cup \left\{\mathcal{Y}^{1}, \mathcal{Y}^{2},...,\mathcal{Y}^{t} \right\}$. Let $\mathcal{X}^{t}$ represent the accessible samples of the task-$t$, and $(\x, y) \in \mathcal{D}^{t}$ represent the sample-label pairs of the task-$t$. $\mathcal{X}_y$ represents samples of the class-$y$. 

\textbf{Vision Transformer and Prompt Tuning}.
The vision transformer (ViT) backbone consists of two components, \emph{i.e.}, $f = f_a \circ f_e$, where $f_e$ is the embedding block which transforms the input image $\x \in \mathbb{R}^{H \times W \times C}$ into patch tokens $f_e(\x) \in \mathbb{R}^{L \times D}$, whose first token is the $[class]$ token inherited from the pretrained model; $f_a$ consists of a sequence of transformer encoders, each of which includes a multi-head attention (MHA) and a multi-layer perception (MLP). We take the first token $\f \in \mathbb{R}^{D}$ of the last layer, the corresponding output of the $[class]$ token, as the feature vector for classification tasks, \emph{i.e.}, $\f = f_a(f_e(\x))\left[1\right]$.

As $f_a$ allows arbitrary length of tokens as input, we can attach additional learnable tokens to the original image tokens, \emph{i.e.}, $f_e(\x) \oplus \p$. $\oplus$ denotes the concatenate operator along the token sequence; $\p \in \mathbb{R}^{J \times D}$ is the learnable prompt tokens, which has the same feature dimension as the image tokens. Finally, the prompt-conditioned feature vector can be calculated as $\tilde{\f}= f_a(f_e(\x) \oplus \p)\left[1\right]$, $\tilde{\f} \in \mathbb{R}^{D}$. 

In the following section, we abbreviate the above two equations as:
\begin{equation}
  \f = f_{\para}(\x), \tilde{\f} = f_{\para}(\x|\p),  
\end{equation}
where $\f$ represents the original feature vector, $\hat{\f}$ represents the prompt-conditioned feature vector, and $\para$ is the model parameters.  $f^{\pt}(\cdot)$ is the abbreviation for $f_{\para^{\pt}}(\cdot)$, which represents the model before the task-$t$ finetuning; $f^{t}(\cdot)$ is the abbreviation for $f_{\para^{t}}(\cdot)$, which represents the model after the task-$t$ finetuning. More details about ViT and prompt tuning can be found in~\cite{AlexeyDosovitskiy2020ViT,liu2021pre}, and our architecture is visualized in Fig.~\ref{}.


\subsection{Analogical Prompt Training}\label{sec:ptrain}
In this section, we describe how to train analogical prompts (A-prompts) to characterize the feature distribution of the previous seen classes with the current task's data. The training process is efficient as only the lightweight prompts need to be learnt, while the base model is frozen.

Since our method strictly follows the data-free setting, we can only save prototypes in the feature space for each old class, \emph{i.e.}, $\left\{\B_{ym}^{\pt}  | y \in \mathcal{S}^{t-1}; m \in \{1,2,\cdots,M\}  \right\}$, where $M$ is the total number saved prototypes for each class. The larger $M$ can better preserve the feature distribution, but also increases the additional memory consumption. We set $M$ to 6 in our experiments, which is comparable to the memory increase of DaulP~\cite{wang2022DualP}. We abbreviate $\B_{ym}$ in the following as $\B_{y}$ without ambiguity, because constructing and updating multiple prototypes is just a simple repetition of one prototype. We initialize prototypes with the K-Means clustering centers for each new class, and update them with the compensation method described in Sec.~\ref{sec: sdc}.

Our target is to use our A-prompts to ``convert" the new data into the old classes from the perspective of the old model, which can be measured from two aspects: first, whether the prompt-conditioned data are classified into the target class; second, whether their feature distribution is similar to the original distribution of the target class.

According to the above two criterion, we design our prompt training process. To accelerate the training of A-prompts, we first sample a subset from the current task's data $\mathcal{X}^{t}$ according their distance to the target prototype $\B^{\pt}_y, y \in \mathcal{S}^{\pt}$:
\begin{equation}\label{eq:sample}
    \xc = \left\{ \x | \x \in \mathcal{X}^{t}, f^{\pt} (\x) \in \text{K-NN}(\B^{\pt}_y) \right\}, 
\end{equation}
where $K$ is the total sample number for each historical prototype, and $\text{K-NN}(\cdot)$ is the K-Nearest-Neighbor of a given feature vector. We use these selected samples to train the prototype-specific prompts $\left\{\pc | y \in \mathcal{S}^{\pt}\right\}$, and propose an objective function includes three components:
\begin{equation}\label{eq:pt}
 \mathcal{L}_{PT} = \mathcal{L}_{CC} + \mathcal{L}_{PP} + \mathcal{L}_{DE}, \x \in \xc. 
\end{equation}

The first component is named class-convert (CC) loss, which designed to classify the prompt-conditioned data into the target old class $y \in \mathcal{S}^{\pt}$: 
\begin{equation}\label{eq:adv}
        \mathcal{L}_{CC} = -\frac{1}{N}\sum_{i=1}^{N} \log(A(h^{\pt}(\tilde{\f}^{\pt}_i))\left[ y \right]),
\end{equation}
where $N$ is the training batch size; $\tilde{\f}_{i}^{\pt} = f^{\pt}(\x_i| \p_{\left\{\B_{y}^{\pt}\right\}})$ is the prompt-conditioned feature; $h(\cdot)$ is the fully-connected classification layer; and $A(\cdot)$ is the softmax normalize function $A(\lgt)\left[j\right] = \exp(\lgt_{j})/\sum_{i}\exp(\lgt_{i})$.

The second component is named prototype-pull (PP) loss, which designed to pull the prompt-conditioned features close to the target prototype, $\cos(\cdot, \cdot)$ is the cosine similarity between two vectors: 
\begin{equation}\label{eq:pp}
    \mathcal{L}_{PP} = \frac{1}{N}\sum_{i=1}^{N}(1 - \cos(\B_{y}^{\pt}, \tilde{\f}_{i}^{\pt})).
\end{equation}

The third component is named diversity-encourage (DE) loss, which prevents prompt-conditioned features from collapsing into a single point:
\begin{equation}\label{eq:de}
    \mathcal{L}_{DE} = \frac{1}{N(N-1)}\sum_{i=1}^{N}\sum_{j=i+1}^{N}\lfloor \cos(\tilde{\f}_{i}^{\pt}, \tilde{\f}_{j}^{\pt}) - \Omega \rfloor_{+}, 
\end{equation}
where $\lfloor \cdot \rfloor_{+}$ truncates negative value to zero, $\Omega$ is a constant threshold, and we set it to $0.95$. 

Once the corresponding feature vectors of the old class for the instances of new classes are generated (prompt-conditioned feature), we can compute and then compensate for the shift of the historical prototypes, which is described in the next section.

\subsection{Analogical Feature Compensation}\label{sec: sdc}

We have ``analogized" the old classes with the A-prompts and the new data from the perspective of the old model, which to some extent equivalent to saving images of the old classes. Then, we can use these prompt-conditioned data to compensate the representation shift of the old prototypes:
\begin{equation}\label{eq:cps_p}
\begin{aligned}
  \D_i &= f^{t}(\x_i| \pc)- f^{\pt}(\x_i| \pc), \x \in \xc \\
  \DD_y &= \frac{\sum_{i} \exp( \beta \cos(f^{\pt}(\x_i| \pc), \B^{\pt}_{y})) \D_i}{\sum_{i} \exp( \beta \cos(f^{\pt}(\x_i| \pc), \B^{\pt}_{y}))}, \\
  \hat{\B}^{t}_{y} &= \B^{\pt}_{y} + \DD_{y}, 
\end{aligned}
\end{equation}
where $\D_i$ is the representation shift of the $i$-th sample, and $\DD_{y}$ is the estimated shift of $\B^{\pt}_{y}$ after the model finetuning on the task-$t$, $\beta$ is the scaling factor controls the smoothness of the above Soft-Nearest function. 

Eq.~\eqref{eq:cps_p} assumes that data points close together in the old feature space should have similar shifts after finetuning. Therefore, The reliability and the accuracy of the prototype compensation depends heavily on how close the reference data points are to this prototype. The more dense the sample points around the prototype, the more accurate the estimation of the shift will be. That's why we use Eq.~\eqref{eq:pp} to pull features towards prototypes, and use Eq.~\eqref{eq:de} to encourage the feature diversity.

\noindent \textbf{The rational of using analogical features:} SDC~\cite{LuYu2020SDC} also uses the shift compensation to update historical prototypes, Nevertheless, it directly takes the new data $\mathcal{X}^{t}$ as the reference data to calculate the shift of the old prototypes $\left\{\B^{\pt}_{y}|y \in \mathcal{S}^{\pt}\right\}$.
Theoretically, SDC performs well when there exists semantic overlaps between different tasks, performs worse when semantic gap between different tasks is enormous, since the shift direction is not consistent between distant points. This theory is also verified by our experimental results in Sec.~\ref{secï¼šbase}. Fig.~\ref{} compare our methods with SDC. As can be seen, the original semantic gap between different classes is large, which makes the shift estimation of SDC inaccurate. Meanwhile, our method successfully remedies the semantic gap and gives more accurate shift estimations of the old prototypes.

\subsection{Model Finetuning and Classification}\label{sec:finetune}

In this section, we describe how to finetune the model on the task-$t$. For training efficiency and alleviating catastrophic forgetting , we only update MLP of each transformer encoder and the final classification header. We adopt the local softmax cross-entropy loss~\cite{masana2020class} instead of the original softmax cross-entropy loss to avoid over-penalizing historical classes, and knowledge distilling loss to maintain previous knowledge. 

We only use the new data $\mathcal{X}^{t}$ to finetune our model, without using A-prompts to ``analogize" data of old classes, because we find that distinguishing prompt-conditioned data from original ones is easy to over-fitting, and destroys the prompt-free test accuracy. 

The final objective function to finetune the model on the task-$t$ also includes three components:
\begin{equation}\label{eq:ft}
 \mathcal{L}_{FT} = \mathcal{L}_{LS} +  \mathcal{L}_{KD} + \mathcal{L}_{SC}, \x \in \mathcal{X}^{t} 
\end{equation}

The first component is named local-softmax (LS) cross-entropy loss~\cite{masana2020class}, only normalized with the new classes, which avoids over-penalizing the classes when their data is not available. $\lgt_{i}^{t} = h^{t}(f^{t}(\x_i)), \lgt_{i}^{t} \in \mathbb{R}^{|\mathcal{S}^{t}|}$ is the logits output of the new model. We can separate $\lgt^{t}$ into $\old^{t} \in \mathbb{R}^{|\mathcal{S}^{\pt}|}$, $\new^{t} \in \mathbb{R}^{|\mathcal{Y}^{t}|}$, where $\lgt^{t} = \old^{t} \oplus \new^{t}$. Finally, the classification loss is defined as follows:
\begin{equation}
    \mathcal{L}_{LS} = -\frac{1}{N}\sum_{i=1}^{N}\log(A(\new_{i}^{t})\left[y_i-|\mathcal{S}^{\pt}|\right]).
\end{equation}

The second component is the knowledge distilling (KD) loss, which is widely used in incremental learning:
\begin{equation}
  \mathcal{L}_{KD} =  -\frac{1}{N}\sum_{i=1}^{N}\sum_{j=1}^{|\mathcal{S}^{\pt}|} A\left(\lgt_{i}^{\pt}/ \zeta \right)\left[j\right]\log\left(A\left(\old_{i}^{t}/\zeta \right)\left[j\right]\right), 
\end{equation}
where $\zeta$ is the smoothing temperature, which is set to $2$ as previous methods~\cite{}. 

Moreover, we propose a shift consistency (SC) loss, which maximum the cosine similarity between and the true feature vector and the compensated feature vector:
\begin{equation}\label{eq:sc}
\begin{aligned}
  \D_j &= \f^{t}_{j} - \f^{\pt}_{j} \\
  \DD_i &= \frac{\sum_{j} \exp( \beta \cos(\f^{\pt}_{j}, \f^{\pt}_{i})) \D_j}{\sum_{j} \exp( \beta \cos(\f^{\pt}_{j}, \f^{\pt}_{i}))}, \\
  \hat{\f}^{t}_{i} &= \f^{\pt}_{i} + \DD_{i}, 
\end{aligned}
\end{equation}


\begin{equation}
 \mathcal{L}_{SC} = \frac{1}{N}\sum_{i=1}^{N} (1 - \cos(\f_{i}^{t}, \hat{\f}_{i}^{t})),  
\end{equation}
where $\f_i^{t}=f^{t}(\x_i)$ is the true feature vector of the current model, and $\hat{\f}_{i}^{t}= f^{\pt}(\x_i) + \DD_{i}$ is the compensated feature vector which uses $\left\{\x_j | j \neq i; y_{j}=y_{i}; j \in \left\{ 1,2,\cdots, N \right\} \right\}$ as the reference data to estimate $\DD_{i}$.

After finishing the model finetuning, we can easily initialize prototypes of the current task by taking the K-Means clustering centers for each new class. Then, we train A-prompts for the old prototypes by Eq.~\eqref{eq:pt}, and compensate the old prototypes by Eq.~\eqref{eq:cps_p}, which makes it possible to track prototypes along with the model update and the representation shift, More details about our training process can be found in Alg.~\ref{alg:algo_train}.  

Finally, We adopt the Soft-Nearest-Multi-Prototype (SNMP) classifier, which is an extension of  Nearest-Mean-of-Exemplars (NME) Classifier~\cite{2013distance}. NME is widely used in incremental learning~\cite{2013distance,2017icarl,LuYu2020SDC} since it can easily add novel classes by calculating their mean centers in feature space and less bias to the new classes. SNMP maintains multiple prototypes for each class instead of a single mean center, better characterizing the feature distribution and the boundary between different classes, which is formulated as follows: 
\begin{equation}\label{eq:class}
    y^* = \argmax_{y \in \mathcal{S}^{t}} \frac{\sum_{m=1}^{M} \exp(\beta \cos(f_{\para}(\x), \B_{ym}))}{\sum_{y \in \mathcal{S}^{t}}\sum_{m=1}^{M} \exp(\beta \cos(f_{\para}(\x), \B_{ym}))}.
\end{equation}



\begin{algorithm}
\caption{Model Training}\label{alg:algo_train}
\begin{footnotesize}
\KwIn{the total task number $T$; the pretrained ViT model $f$; the training sequence $\left\{\mathcal{D}^{t}|t \in \mathcal{T}\right\}$}
\KwOut{$f^{T}$; $\left\{\B^{T}_{y}|y \in \mathcal{S}^{T}\right\}$}
Initialize $f^{0}=f$;\\
\For{$t=1,\ldots,T$}{
\eIf{$t=1$}{ Train $f^{\pt}$ by $\mathcal{L}_{c}$ on $\mathcal{D}^{t}$ to get $f^{t}$; \\
             Get $\left\{\B^{t}_{y}|y \in \mathcal{Y}^{t}\right\}$ by class-wise K-Means; 
}{
    \For{$y=1,\ldots,|\mathcal{S}^{\pt}|$}{
    Sample $\xc$ by Eq.~\eqref{eq:sample}; \\
    Train $\pc$ by Eq.~\eqref{eq:pt} on $\xc$;
    }
    Training $f^{\pt}$ by Eq.~\eqref{eq:ft}  on $\mathcal{D}^{t}$ to get $f^{t}$; \\
    Get $\left\{\B^{t}_{y}|y \in \mathcal{Y}^{t}\right\}$ by class-wise K-Means; \\
    Update $\left\{\B^{\pt}_{y}|y \in \mathcal{S}^{\pt}\right\}$ to $\left\{\B^{t}_{y}|y \in \mathcal{S}^{\pt}\right\}$ in-place by Eq.~\eqref{eq:cps_p} with $\left\{(\pc, \xc)|y \in \mathcal{S}^{\pt}\right\}$ ;
}
abandon $f^{\pt}$, $\mathcal{D}^{t}$, $\left\{(\pc, \xc)|y \in \mathcal{S}^{\pt}\right\}$;
}
\Return $f^{T}$, $\left\{\B^{T}_{y}|y \in \mathcal{S}^{T}\right\}$
\end{footnotesize}
\end{algorithm}














