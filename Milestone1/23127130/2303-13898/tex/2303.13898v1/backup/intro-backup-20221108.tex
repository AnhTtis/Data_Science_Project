\section{Introduction}
\label{sec:intro}

% 提纲:
% 第一部分首先给出增量学习的定义，明确本文不针对有task-id的情景
% 第二部分引出memory-based的设定，并对memory-based的方法不足总结
% 第三部分介绍image-sythesis的方法（额外的网络，不好训练，数据多样性得不到保证），以及特征rehearsal的方法
% 第四部分提出输入编码的概念（能不能通过当前的输入回忆起之前的知识）， 类比学习的概念并引出我们的方法
% 第五部分介绍方法，详细比较L2P Dual 以及 compensation

%  --- after training on the latest data, the performance of previously seen data degrades significantly

Incremental learning (IL), in which a single model is used to learn a non-stationary data sequence, is essential to achieve human-like AI. Many methods have been proposed to prevent \emph{catastrophic forgetting} (the significant performance degradation of previously seen data)\cite{mccloskey1989catastrophic,french1999catastrophic} during incremental learning. These methods can be roughly divided into three categories: regularization-based\cite{li2017LWF,kirkpatrick2017EWC,aljundi2018MAS,castro2018EEIL}, architecture-based\cite{yoon2017DEN,buzzega2020DER,mallya2018PackNet,mallya2018Piggyback}, and memory-based\cite{2017icarl,rolnick2019ER,Hou_2019lucir,SonglinDong2021RKD}. Most state-of-the-art methods combine at least two of them. 

Memory-based methods have superior performance in challenging scenarios where task-ID is non-accessible at inference time, such as class-incremental learning (CIL). These methods use external memory to save representative data of previous tasks and replay them during the latest training. Nonetheless, Nonetheless, concerns about memory-based methods have arisen in the community\cite{mai2022onlineSurvey,masana2020class} recently, recently, since they are susceptible to memory size and cannot be applied in scenarios with strict privacy protection and memory budget restrictions.

Data-free methods\cite{JamesSmith2021ABD,liu2022ERDR} have been proposed to avoid saving data. Several methods adopt a separate generative model to generate pseudo data of previous tasks. However, maintaining and updating an additional generative model is computationally and memory intensive and still has privacy concerns~\cite{na2018theore}. Moreover, data-free knowledge distillation~\cite{yin2020dreaming} has been introduced into incremental learning~\cite{JamesSmith2021ABD,liu2022ERDR} to avoid adding an additional generative model, which use the original classification model to optimize the random noise inputs into synthesis images. However, their performance still lags behind that of memory-based methods~\cite{JamesSmith2021ABD}. Another line of data-free methods store features rather than the original images~\cite{LuYu2020SDC,iscen2020memory} to keep previous knowledge. These methods suffers from the representation shift \XPC{that XXXX} and thus 
require estimating the drift of previously saved features with only data of the current task. It is difficult when the semantic gap between tasks is significant (details elaborated in Sec.~\ref{sec:method}). We are inspired by feature-based methods and find out the obstacle lies in how to bridge the semantic gap between different tasks. 

Our human beings depend on thinking about the relationships between things, not simply about individuals. This ability enables us to understand an infinite number of entities through associations and comparisons, and to continually learn from experience\cite{hofstadter2013Analogy}. Analogy ability has proven to be a core mechanism of human intelligence, and we can easily transform one entity to another with a simple ``prompt". For example, a motorcycle is like a cycle powered by a motor; an airport is like a port for airplanes. However, the correspondence between different entities is not always straightforward. 

In this paper, we adopt learnable, analogical prompts (a-prompts) to reparameterize data from the current classes into previously seen classes; then maintain and update previous class prototypes with these prompt-conditioned data. 

The prompt technique designs input text templates or attaches additional learnable tokens to adapt the pre-trained transformer to the downstream task rather than fine-tuning the original weights. L2P\cite{wang2022L2P} and DualPrompt\cite{wang2022DualPrompt} introduce prompt-tuning into incremental learning, maintaining a pool of prompts that convey different task information, which alleviates catastrophic forgetting caused by interference between tasks. Instead of using prompts to isolate different tasks, we use a-prompts to establish correspondence between different tasks. These prompts can be discarded after updating the model, which allows our method inference by original images without retrieving prompts from the prompt pool.

Specifically, our method consists of three stages: prompts generation, model finetuning, and prototype compensation. We use the pre-trained vision transformer (ViT)\cite{AlexeyDosovitskiy2020ViT} as our base model, the same as L2P and DualP, and adopt an additional multi-prototype nearest neighbor classifier which maintains multiple prototypes for each class to characterize the feature distribution. 

Before finetuning model on the current task's data, we first freeze the model and train a-prompts for each prototype of seen classes, the loss function includes three components: the first loss is classifying the prompt-condition data of the current task to the previous targeting class; the second loss is pulling features of prompt-condition data towards corresponding prototype; the third loss is encouraging feature diversity of the prompt-condition data to avoid trivial solution. After training, we can ``convert" the current data to any previous seen class by attaching the corresponding a-prompts.

The second stage is to finetune the model on the current task data. We only finetune each transformer encoder's multi-layer perception and the final classification header for training efficiency and alleviating catastrophic forgetting. We do not use a-prompts at this stage since distinguishing prompt-conditioned data from original ones is prone to overfitting. We adopt the local softmax cross-entropy~\cite{masana2020class} instead of the original softmax cross-entropy to avoid over-penalizing historical classes, and knowledge distilling loss to maintain previous knowledge. Moreover, we propose a drift consistency loss applied on feature space to improve our prototype compensation performance.

%  We also find that the widely used LwF method has a conflict between the knowledge distilling loss and cross-entropy loss, and we propose an improved version named LwF+, which solves the conflict by only applying cross-entropy loss on the current task.

Our prototype compensation method is inspired by Semantic drift compensation (SDC)\cite{LuYu2020SDC}. SDC first calculates the feature drifts of the current task data, i.e., the vectors pointing from the previous to the current feature space, and then estimates prototype drift using the weighted average of the data drifts, whose weights correlate negatively to distances from the data to the prototype. Finally, prototypes are updated by adding drifts to them. It assumes that data close together in the feature space should have similar drifts. This estimation is only reliable when the semantic gap between different tasks is small, i.e., some current task data are close to previous prototypes in feature space. However, in incremental learning, this condition usually is not satisfied.

To bridge the semantic gap between different tasks, instead of using the original data of the current task, we use the prompt-conditioned data already drawn close to the prototype to estimate its drift. We maintain multiple prototypes per class, initialized by k-means cluster centers and updated by prototype compensation. It is worth noting that we can drop a-prompts when the prototype update is complete. In the inference phase, we only feed original data into the model, which saves both memory and computational costs.

The contribution of this paper can be summarized as follows:
\begin{itemize}
    \item We propose analogical prompts to ``convert" the current task data into previous classes, which bridge the semantic gap between different tasks for prototype compensation.
    \item We propose a combined objective function to train diverse analogical prompts.
    \item We propose a drift consistency loss to boost performance for prototype compensation.
    \item The proposed method outperforms memory-based methods by only saving prototypes in feature space for each classes, significantly reduces additional memory and prevents privacy concerns.
	\item The proposed method achieves state-of-the-art performance on four difficult incremental learning benchmarks, including class incremental learning, domain incremental learning, and cross-domain class incremental learning. 
\end{itemize}


































