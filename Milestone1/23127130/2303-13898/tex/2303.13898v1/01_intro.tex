\section{Introduction}
\label{sec:intro}


\begin{figure}[t] 
\centering
\includegraphics[width=0.95\linewidth]{figs/teaser.pdf} 
\caption{Illustration of the basic idea. Given a sample of the new class \emph{zebra}, the old model produces a feature vector far away from any previous class. We use the carefully designed prompts to guide the feature vector towards the old class \emph{car}, so that the frozen old model finally considers it as a \emph{car}. With such an analogy mechanism, for each new sample, we can find its counterpart feature vector to any category seen before (such as the one corresponding to the imaged \emph{car with stripes}), which is called the \emph{analogical feature}. The pairs of features of the \emph{analogical sample} by the \textbf{old} and the \textbf{updated new} models are further used to estimate \XP{and counteract} the representation shift caused by finetuning.
%for shift counteraction.
% the features by the \textbf{updated} model of the new samples and the corresponding analogical features by the \textbf{old} model are used to estimate the representation shift caused by the model update.
%With the help of carefully designed prompts, the feature vector is moving towards the old class \emph{car}, which the frozen old model finally considers as a \emph{car}.
} 
%, inevitably leading to more forgetting or interference
\label{fig:basicidea} 
% \vspace{-0.5cm}
\end{figure}

Incremental learning (IL), in which a single model is used to learn a non-stationary data sequence, is essential to achieve human-like AI. Many methods have been proposed to prevent \emph{catastrophic forgetting}~\cite{mccloskey1989catastrophic,french1999catastrophic} (the significant performance degradation of previously seen data) during incremental learning. A number of methods have been proposed, including  regularization-based~\cite{li2017LWF,kirkpatrick2017EWC,aljundi2018MAS}, architecture-based~\cite{yoon2017DEN,buzzega2020DER,mallya2018PackNet}, and replay-based~\cite{2017icarl,shin2017DGR} methods. 
Data-replay methods~\cite{lopez2017,chaudhryefficient, 2017icarl,rolnick2019ER,Hou_2019lucir,belouadah2019il2m} have superior performance in challenging scenarios, such as class-incremental learning (CIL). These methods use an external buffer to save representative data of previous tasks and replay them during the new task learning. Nonetheless, concerns have recently been raised about these data-replay methods~\cite{mai2022onlineSurvey,masana2020class}, as they are susceptible to memory constraints and cannot be used in scenarios with strict privacy protection.


Data-free-replay methods have been proposed to avoid explicitly saving data. Several methods~\cite{ostapenko2019learning,shin2017DGR,he2018exemplar,hu2019overcoming,xiang2019incremental,chenshen2018MemoryReplayGANs,kamra2017DGDM,NEURIPS2020GANMemory} adopt a separate generative model to generate pseudo data of previous tasks. However, maintaining and updating an additional generative model is computationally and memory intensive and still with privacy concerns~\cite{na2018theore}. Data-free knowledge distillation~\cite{yin2020dreaming} has been introduced into incremental learning~\cite{JamesSmith2021ABD,liu2022ERDR} to get rid of the additional generative model, which adopts the original classification model to synthesis the old images from scratch.  their performance is still lower than that of data-replay methods~\cite{JamesSmith2021ABD}. Another type of Data-free-replay methods~\cite{liu2020generative,zhu2022self,toldo2022bring,hayes2020remind,wang2021acae,zhu2021prototype,Petit_2023_WACV} stores the prototypes of each class in the feature space rather than the original images (feature-replay methods). These methods suffer from the representation shift, \emph{i.e.}, the features of the same input data change continuously as the model parameters are updated, making previously saved prototypes no longer applicable to the new feature space. Therefore, estimating the shift of the historical prototypes becomes critical. Previous methods~\cite{LuYu2020SDC,iscen2020memory} estimate the shift of the \emph{historical prototypes} by the feature shift of the \emph{current task's data}, which is biased and unreliable when the semantic gap between different tasks is significant (details elaborated in Sec.~\ref{sec:ptrain}). \textit{Without the old data, how can we fill the semantic gap and make an unbiased estimation of the representation shift?}

In this paper, we seek a new answer to this question from the inspiration of human intelligence. As a core mechanism of human intelligence, analogy is key for humans to learn and transfer knowledge efficiently to new domains. This ability enables us to connect different individual concepts, understand an infinite number of entities through associations and comparisons, and to continuously learn from experience~\cite{hofstadter2013Analogy}. People can easily find out the partial correspondence between different objects such as an \emph{armchair} is a chair with \emph{arms}.

% \MZ{ People can easily transform one entity to another with a simple \emph{prompt}. For example, a motorcycle is a \XP{bicycle powered by a motor (prompt); and an airport is a port (prompt)} for airplanes. (NOT Exactly)}

Inspired by this, we propose a novel data-free incremental learning approach to counteract the representation shift problem by explicitly building correspondence between the new and the old data. The basic idea is to imagine by analogy how a sample of a new class looks like in the old classes, which allows reminiscing about the old tasks while learning the new task. Once the corresponding feature vectors of the old class are generated using only the new samples, the semantic gap is resolved and we can calculate and then counteract the representation shift of the updated model in an unbiased manner. 

Specifically, our approach consists of three components. Firstly and most importantly, we propose a prompt-based analogy-making mechanism on top of the pre-trained vision transformer (ViT)~\cite{AlexeyDosovitskiy2020ViT}, as shown in Fig.~\ref{fig:basicidea}. We design a learning method with three carefully designed loss functions to obtain the \emph{analogical prompts} (A-prompts) for the classes seen before. On this basis, we can remap the samples of the new classes to the features of any previously-seen classes from the perspective of the old model, conditioned with the learnt A-prompts. For clarity and simplicity, the new samples conditioned with the learnt A-prompts and the corresponding feature vectors are named by the \emph{analogical samples} (A-samples) and the \emph{analogical features} (A-features), respectively. This mechanism is efficient as only the lightweight prompts need to be learnt, with the base model frozen.

Next, for an \emph{A-sample}, its corresponding \emph{A-feature} generated by the old model as well as the one generated by the updated model forms a pair. They are used to compute the instance-wise feature shift, and further accumulated to estimate the shift of the old class prototypes. On this basis, we counteract the shift of the old class prototypes at the new task and provide unbiased old prototypes for classification. Finally, we propose a tailored new task learning scheme to finetune the backbone model. Along with the classification loss, we propose a shift consistency loss to encourage the close points in the old feature space to have consistent shifts after finetuning, making the feature shift more predictable.


Our method is fundamentally different from previous prompt-based incremental learning methods, such as L2P~\cite{wang2022L2P}, DualP~\cite{wang2022DualP}, and S-Prompts~\cite{wang2022SPrompts}. These methods train task-specific prompts to reduce inter-task interference. In the test, they \XP{have to} perform a prompt-free inference to obtain the task ID \XP{first}, and then perform the task-prompt-conditioned inference to obtain the final prediction. In contrast \XP{to this two-pass inference, we only need a single pass of prompt-free inference, which significantly reduces, more specifically halves the inference cost of previous prompt-based methods. The main reason is that} our A-prompts are only used to update historical prototypes \XP{during training}, which are discarded upon completion. Moreover, our method eliminates the errors that arise from task ID prediction and further improves performance.

%Our method is fundamentally different from previous prompt-based incremental learning methods, such as L2P~\cite{wang2022L2P}, DualP~\cite{wang2022DualP}, and S-Prompts~\cite{wang2022SPrompts}. These methods train task-specific prompts to reduce inter-task interference. In the test, they first perform a prompt-free inference to obtain the task ID, and then perform the task-prompt-conditioned inference to obtain the final prediction. In contrast, our A-prompts are only used to update historical prototypes, which are discarded upon completion. In the test, we only need a single pass of prompt-free inference to obtain the result.  This reduces the inference cost to less than half of previous prompt-based methods and avoids the errors introduced by task ID prediction.

We evaluate the proposed method on four challenging  benchmarks, under both class incremental learning and domain incremental learning settings. Our method achieves state-of-the-art performance and even outperforms data-replay methods by only saving prototypes in feature space for each class. Moreover, our method \textit{has nearly touched the empirical upper bound} by joint training on Core50.
    
In summary, we propose a radically new incremental learning approach, which is inspired by the human analogy ability. The contributions of this paper are manifold:
\begin{itemize}

    \item We design a prompt-based analogy-making mechanism and the shift consistency loss for representation shift estimation and counteraction, which provides unbiased prototypes for classification.

    \item We propose an  analogical prompt learning method to produce the class-specific A-prompts, which plays a central role in linking the new samples to the old classes for analogy making.
    
    \item Our method reduces inference costs by half compared to previous prompt-based methods, and achieves state-of-the-art performance on four benchmarks.
\end{itemize}


































