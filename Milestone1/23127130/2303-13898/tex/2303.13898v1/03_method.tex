\section{Method}
\label{sec:method}
\newcommand{\argmax}{\mathop{\mathrm{argmax}}}
\newcommand{\x}{\boldsymbol{x}}
\newcommand{\f}{\boldsymbol{f}}
\newcommand{\p}{\boldsymbol{p}}
\newcommand{\A}{\boldsymbol{a}}
\newcommand{\B}{\boldsymbol{\varphi}}
\newcommand{\D}{\boldsymbol{\delta}}
\newcommand{\DD}{\boldsymbol{\Delta}}

\newcommand{\J}{\left[j\right]}
\newcommand{\lgt}{\boldsymbol{l}}
\newcommand{\old}{\boldsymbol{o}}
\newcommand{\new}{\boldsymbol{n}}
\newcommand{\para}{\boldsymbol{\theta}}
\newcommand{\pt}{t\!-\!1}
\newcommand{\pc}{\p_{y}}
\newcommand{\xc}{\tilde{\mathcal{X}}^{t}_{y}}

\subsection{Preliminaries and Notions}


\begin{figure}[!t] 
\centering
\includegraphics[width=0.95\linewidth]{figs/Structure.pdf} 
\caption{The network structure and the trainable parameters. We use the standard ViT as the backbone, and the training process includes two different stages: (a) In the analogy-making stage, we adopt the prompt-conditioned inference, and the only trainable parameter is the A-prompts; (b) In the new task finetuning stage, we use a workflow without prompt, where the trainable parameters are the MLP in each transformer encoder and the classification header.}
\label{fig:figure2}
\end{figure}


\noindent \textbf{Incremental Learning}. 
Incremental learning (IL) is to train a single model on a non-stationary data stream without catastrophic forgetting. In this paper, we focus on the scenario where a sequence of tasks is well defined, \emph{i.e.}, $t \in  \mathcal{T}=\left\{1,2,\cdots, T\right\}$, $T$ is the total task number, and we can only access the current task data. Let $\mathcal{Y}^{t}$ denote the label set of the task-$t$, and $\mathcal{S}^{t}$ denote all seen labels until the task-$t$,\emph{i.e.}, $\mathcal{S}^{t}$ = $\cup \left\{\mathcal{Y}^{1}, \mathcal{Y}^{2},...,\mathcal{Y}^{t} \right\}$. Let $\mathcal{X}^{t}$ represent the accessible samples of the task-$t$, and $(\x, y) \in \mathcal{Z}^{t}$ represent the sample-label pairs of the task-$t$. $\mathcal{X}_y$ represents samples of the class-$y$. 

\noindent \textbf{Vision Transformer and Prompt Tuning}.
The vision transformer (ViT) backbone consists of two components, \emph{i.e.}, $f = f_a \circ f_e$, where $f_e$ is the embedding layer which transforms the input image $\x \in \mathbb{R}^{H \times W \times C}$ into patch tokens $f_e(\x) \in \mathbb{R}^{(L+1) \times D}$, whose first token is the $[class]$ token inherited from the pre-trained model; $f_a$ consists of a sequence of transformer encoders, each of which includes a multi-head attention (MHA) and a multi-layer perception (MLP). We take the first token $\f \in \mathbb{R}^{D}$ of the last layer, the corresponding output of the $[class]$ token, as the feature vector for classification tasks, \emph{i.e.}, $\f = f_a(f_e(\x))\left[0\right]$.

As $f_a$ allows the arbitrary length of tokens as input, we can attach additional learnable tokens to the original image tokens, \emph{i.e.}, $f_e(\x) \oplus \p$. $\oplus$ denotes the concatenate operator along the token sequence; $\p \in \mathbb{R}^{J \times D}$ is the learnable prompt token, which has the same feature dimension as the image tokens. Finally, the prompt-conditioned feature vector can be calculated as $\tilde{\f}= f_a(f_e(\x) \oplus \p)\left[0\right]$, $\tilde{\f} \in \mathbb{R}^{D}$. In the following section, we abbreviate the above two equations:
\begin{equation}
  \f = f_{\para}(\x), \tilde{\f} = f_{\para}(\x|\p),  
\end{equation}
where $\f$ and $\tilde{\f}$ are the original and the prompt-conditioned feature vector, respectively. $\para$ is the model's parameters. Furthermore, $f^{\pt}(\cdot)$ is the abbreviation for $f_{\para^{\pt}}(\cdot)$, which represents the model before the task-$t$ finetuning; $f^{t}(\cdot)$ is the abbreviation for $f_{\para^{t}}(\cdot)$, which represents the model after the task-$t$ finetuning. More details about ViT and prompt tuning can be found in~\cite{AlexeyDosovitskiy2020ViT,liu2023pre}.

\subsection{Overall Framework}

We propose a Soft-Nearest-Multi-Prototype (SNMP) classifier in our method, which is an extension of  the Nearest-Mean-of-Exemplars (NME) Classifier~\cite{2013distance}. NME is widely used in incremental learning~\cite{2013distance,2017icarl,LuYu2020SDC} since it can easily add novel classes by calculating their mean centers in feature space, and less bias to the latest task. Our SNMP maintains multiple prototypes for each class instead of a single mean center, better characterizing the feature distribution and the complex boundaries between different classes, which is formulated as follows: 
\begin{equation}\label{eq:class}
    y^* = \argmax_{y \in \mathcal{S}^{t}} \frac{\sum_{m=1}^{M} e^{-d(f_{\para}(\x), \B_{ym})}}{\sum_{y \in \mathcal{S}^{t}}\sum_{m=1}^{M} e^{-d(f_{\para}(\x), \B_{ym})}},
%y^* = \argmax_{y \in \mathcal{S}^{t}} \frac{\sum_{m=1}^{M} \exp(\beta \cos(f_{\para}(\x), \B_{ym}))}{\sum_{y \in \mathcal{S}^{t}}\sum_{m=1}^{M} \exp(\beta \cos(f_{\para}(\x), \B_{ym}))}   
\end{equation}
where $\B_{ym}$ represents the $m$-th prototype of the class $y$, and $M$ is the total prototype number per class. $d(\cdot,\cdot)$ can be any distance function between two vectors. 
% $\beta$ is the scaling factor that controls the smoothness of classification boundaries. 
We abbreviate $\B_{ym}$ in the following as $\B_{y}$ without ambiguity because constructing and maintaining multiple prototypes is just a simple repetition of one prototype.

We can easily construct prototypes of the current task by taking the K-Means clustering centers for each new class. The main difficulty is how to keep track of historical prototypes affected by the representation shift. data-replay methods~\cite{2013distance,2017icarl} can simply re-inference the saved old data on the new model to obtain unbiased prototypes, which is not possible in the data-free setting. Therefore, we propose the analogical prompts (A-prompts) which ``convert" the new data into old classes and use the analogical features (A-features) to obtain the shift-counteracted prototypes. We name the new sample conditioned with the A-prompts as analogical samples (A-samples).

In the following subsections, we will elaborate on how to obtain the shift-counteracted prototype $\B_{y}$ (Sec.~\ref{sec:ptrain}) and efficiently learn the ViT backbone $f_{\para}(\x)$ (Sec.~\ref{sec:finetune}).

\subsection{Analogical Shift Counteraction}\label{sec:ptrain}

\begin{figure}[!t] 
\centering
\includegraphics[width=0.95\linewidth]{figs/Method.pdf} 
\caption{Analogical shift counteraction. (a) We push the K-Nearest new samples towards the old prototype and make it be classified into the old class from the perspective of the old model with the learned class-specific A-prompts; (b) We obtain the instance-wise shift between the pair of analogical features on the new and the old model; (c) We counteract the old prototype's shift in the updated feature space by adding the weighted average shift of its reference analogical features.
}
\label{fig:figure3}
\end{figure}

\noindent \textbf{Analogy Making}. In order to retain old knowledge and resist forgetting, the prompt-based analogy mechanism makes the A-samples behave like the old samples from the perspective of the old model. We can consider it from following two aspects: first, the A-samples will be classified into the target old class on the old model; second, A-features should follow the corresponding distribution in the old feature space. By meeting the above two criteria, the A-samples can substitute the old samples to some extent, which is further used to counteract the prototype shift.

We describe the training process of our A-prompts in the following. To accelerate the training process, we first select the most similar subset from the current task data $\mathcal{X}^{t}$ according to their distance to the target prototype $\B^{\pt}_y, y \in \mathcal{S}^{\pt}$:
\begin{equation}\label{eq:sample}
    \xc = \left\{ \x | \x \in \mathcal{X}^{t}, f^{\pt} (\x) \in \text{K-NN}(\B^{\pt}_y) \right\}, 
\end{equation}
where $K$ is the total sample number for each historical prototype, and $\text{K-NN}(\cdot)$ is the K-Nearest-Neighbor of a given feature vector. We use this subset to train the class-specific prompts $\left\{\pc | y \in \mathcal{S}^{\pt}\right\}$. In the prompt training stage, the only trainable parameters are A-prompts while the old model is frozen (visualized in Fig.~\ref{fig:figure2} (a)). We propose an objective function that includes three components:
\begin{equation}\label{eq:pt}
 \mathcal{L}_{PT} = \mathcal{L}_{CC} + \mathcal{L}_{PP} + \mathcal{L}_{DE}, \x \in \xc. 
\end{equation}

\noindent The first component is \XP{the} class-convert (CC) loss to remap the A-samples into the target old class $y \in \mathcal{S}^{\pt}$: 
\begin{equation}\label{eq:adv}
        \mathcal{L}_{CC} = -\frac{1}{N}\sum_{i=1}^{N} \log(h^{\pt}(\tilde{\f}^{\pt}_{i|y})\left[ y \right]),
\end{equation}
where $N$ is the training batch size; $\tilde{\f}_{i|y}^{\pt} = f^{\pt}(\x_i| \pc)$ is the $i$-th A-feature of the class-$y$ from the perspective of the old model; $h(\cdot)$ is the fully-connected classification layer with the softmax normalize function.

The second component is named prototype-push (PP) loss, which is designed to push the A-features towards to the target prototype: 
\begin{equation}\label{eq:pp}
    \mathcal{L}_{PP} = \frac{1}{N}\sum_{i=1}^{N}d(\B_{y}^{\pt}, \tilde{\f}_{i|y}^{\pt}). 
\end{equation}

The third component is named diversity-encourage (DE) loss, which prevents A-features from collapsing into a single point:
\begin{equation}\label{eq:de}
    \mathcal{L}_{DE} = \frac{1}{N(N-1)}\sum_{i=1}^{N}\sum_{j=i+1}^{N}\lfloor \Omega - d(\tilde{\f}_{i|y}^{\pt}, \tilde{\f}_{j|y}^{\pt}) \rfloor_{+},
\end{equation}
where $\lfloor \cdot \rfloor_{+}$ truncates negative value to zero; $\Omega$ is a constant margin, which is set to 1 in our experiments. 

Once the A-prompts are obtained, we can counteract the shift of the historical prototypes, which is described below.

\begin{figure}[!t] 
\centering
\includegraphics[width=0.7\linewidth]{figs/bias_distance.pdf}
\caption{Comparison of prototype estimation bias. The prototype estimation bias is the distance between the shift-counteracted prototypes and the ground-truth prototypes after the new task finetuning; the average reference distance is the average distance between the reference features and the prototypes before finetuning, \emph{i.e.}, $d(\tilde{\f}^{\pt}_{i|y},\B_{y}^{\pt})$ for ours and $d(\f^{\pt}_i,\B_{y}^{\pt})$ for SDC, respectively.}\label{fig:bias}
\end{figure}

\noindent \textbf{Shift Estimation and Counteraction}.
The pairs of features of the A-samples by the old and the updated new models are used to estimate the representation shift caused by finetuning:
\begin{equation}\label{eq:shift}
    \D_{i|y} = \tilde{\f}^{t}_{i|y} - \tilde{\f}^{\pt}_{i|y},
\end{equation}
where $\tilde{\f}_{i|y}^{t} = f^{t}(\x_i| \pc)$ is the $i$-th A-feature of the class-$y$ in the new feature space, $\D_{i|y}$ is the instance-wise shift between the new and the old A-feature. Since features close together in the old feature space should have similar shifts after finetuning, we can estimate the prototype shift as follows:
\begin{equation}\label{eq:cps_p}
    \DD_y = \frac{\sum_{i} \exp( -d(\tilde{\f}^{\pt}_{i|y}, \B^{\pt}_{y})) \D_{i|y}}{\sum_{i} \exp( -d(\tilde{\f}^{\pt}_{i|y}, \B^{\pt}_{y}))},
\end{equation}
where $\DD_y$ represents the estimated shift of prototype $\B^{\pt}_{y}$. Finally, we can counteract the shift of old prototypes as follows:
\begin{equation}\label{eq:counteract}
    \B^{t}_{y} = \B^{\pt}_{y} + \DD_{y}.
\end{equation}

The diagram of the analogical shift counteraction process is shown in Fig.~\ref{fig:figure3}.

\noindent \textbf{The rationality of using A-features:} SDC~\cite{LuYu2020SDC} also uses the shift counteraction to update historical prototypes. Nevertheless, it directly takes the original features of new data as the reference rather than the A-features. That is, in Eq.~\eqref{eq:shift} and Eq.~\eqref{eq:cps_p}, SDC replaces $\tilde{\f}^{t}_{i|y}$ and $\tilde{\f}^{\pt}_{i|y}$ with $\f^{t}_{i}$ and $\f^{\pt}_{i}$, respectively, where $\f_{i}^{t} = f^{t}(\x_i), \x_i \in \mathcal{X}^{t}$. The intuitive assumption behind Eq.~\eqref{eq:cps_p} is that the closer the points are in the feature space, the more consistent the shifts will be after the finetuning.  Therefore, the reliability and accuracy of the prototype shift counteraction is highly dependent on how close the reference features are to the prototype. We verify this assumption with analytical experiments. Fig.~\ref{fig:bias} visualizes relationship between the average reference distance and shift estimation bias. As can be seen, larger average reference distances result in more significant prototype estimation bias for SDC. In contrast, Our method has less prototype estimation bias than SDC, since our A-features have already been pushed towards to their target prototypes by Eq.~\eqref{eq:pp}. The TSNE~\cite{van2008visualizing} visualization of the feature space can be found in the supplementary material. Finally, our method achieves consistent performance improvement over SDC (Sec.~\ref{sec:compare}).

\subsection{New Task Finetuning}\label{sec:finetune}

In this section, we describe how to finetune the old model $f^{\pt}$ on the task-$t$ to get the new model $f^{t}$. For training efficiency and alleviating catastrophic forgetting, we only update the transformer encoder's MLP layer and the classification header, as visualized in Fig.~\ref{fig:figure2} (b). The training objective of the task-$t$ is defined as follows:
\begin{equation}\label{eq:ft}
 \mathcal{L}_{FT} = \mathcal{L}_{C} +  \mathcal{L}_{SC}, \x \in \mathcal{X}^{t}, 
\end{equation}
where $\mathcal{L}_{C}$ is the cross-entropy loss on the current task~\cite{castro2018EEIL}; $\mathcal{L}_{SC}$ is the shift consistency loss, which encourages local feature shifts to become consistent:
\begin{equation}
    \begin{aligned}
            \mathcal{L}_{SC} &= \frac{1}{N}\sum_{i=1}^{N} d\left(\D_i, \DD_i\right), \D_{i} = \f_{i} - \f^{\pt}_{i},\\
            \DD_{i} &= \frac{\sum\limits_{j,j \neq i} \exp( -d(\f^{\pt}_{j}, \f^{\pt}_{i})) \D_{j}}{\sum\limits_{j,j \neq i} \exp( -d(\f^{\pt}_{j}, \f^{\pt}_{i}))},
    \end{aligned}    
\end{equation}
where $\D_{i}$ is the true feature shift of the $i$-th sample during finetuning, $\DD_{i}$ is the feature shift estimated by its nearby feature shifts.

It is worth noting that we only use the new samples $\mathcal{X}^{t}$ to finetune our model, without using A-prompts to ``analogize" samples of old classes, because we find that distinguishing A-samples from original samples is easy to over-fitting, and destroys the prompt-free test accuracy. After finishing the model finetuning on the new task, we can easily initialize new prototypes by taking the K-Means clustering centers for each new class and counteracting the shift of old prototypes by Eq.~\eqref{eq:counteract}. Finally, we can classify the test samples with Eq.~\eqref{eq:class}. More details about our training process can be found in Alg.~\ref{alg:algo_train}.  




\begin{algorithm}
\caption{Model Training}\label{alg:algo_train}
\begin{footnotesize}
\KwIn{the total task number $T$; the pre-trained ViT model $f$; the training data sequence $\left\{\mathcal{Z}^{t}|t \in \mathcal{T}\right\}$}
\KwOut{$f^{T}$; $\left\{\B^{T}_{y}|y \in \mathcal{S}^{T}\right\}$}
Initialize $f^{0}=f$;\\
\tcp{Start from the pre-trained model}
\For{$t=1,\ldots,T$}{
\eIf{$t=1$}{ Train $f^{\pt}$ by $\mathcal{L}_{C}$ on $\mathcal{Z}^{t}$ to get $f^{t}$; \\
             \tcp{Finetune on the first task}
             Get $\left\{\B^{t}_{y}|y \in \mathcal{Y}^{t}\right\}$ by class-wise K-Means; \\
             \tcp{Initialize prototypes}
}{
    \For{$y=1,\ldots,|\mathcal{S}^{\pt}|$}{
    \tcp{Repeat on all old classes}
    Sample $\xc$ by Eq.~\eqref{eq:sample}; \\
    \tcp{Samples for training A-prompt}
    Train $\pc$ by Eq.~\eqref{eq:pt} on $\xc$; \\
    \tcp{Train class-specific A-prompt}
    }
    Training $f^{\pt}$ by Eq.~\eqref{eq:ft}  on $\mathcal{Z}^{t}$ to get $f^{t}$; \\
    \tcp{Finetune model on the new task}
    Get $\left\{\B^{t}_{y}|y \in \mathcal{Y}^{t}\right\}$ by class-wise K-Means; \\
    \tcp{Construct new prototypes}
    Update $\left\{\B^{\pt}_{y}|y \in \mathcal{S}^{\pt}\right\}$ to $\left\{\B^{t}_{y}|y \in \mathcal{S}^{\pt}\right\}$ in-place by Eq.~\eqref{eq:counteract} with $\left\{(\pc, \xc)|y \in \mathcal{S}^{\pt}\right\}$;
    \tcp{Update old prototypes}
}
abandon $f^{\pt}$, $\mathcal{Z}^{t}$, $\left\{(\pc, \xc)|y \in \mathcal{S}^{\pt}\right\}$;
}
\Return $f^{T}$, $\left\{\B^{T}_{y}|y \in \mathcal{S}^{T}\right\}$
\end{footnotesize}
\end{algorithm}














