
@misc{Authors14,
 author = {Full Author Name},
 title = {The Frobnicatable Foo Filter},
 note = {Face and Gesture  submission ID 324. Supplied as additional material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {Full Author Name},
 title = {Frobnication Tutorial},
 note = {Supplied as additional material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {Alvin Alpher},
title = {Frobnication},
journal = {Journal of Foo},
volume = 12, 
number = 1, 
pages = {234--778}, 
year = 2002
}

@article{Alpher03,
author = {Alvin Alpher and Ferris P.~N. Fotheringham-Smythe},
title = {Frobnication Revisited},
journal = {Journal of Foo},
volume = 13, 
number = 1, 
pages = {234--778}, 
year = 2003
}

@article{Alpher04,
author = {Alvin Alpher and Ferris P.~N. Fotheringham-Smythe and Gavin Gamow},
title = {Can a Machine Frobnicate?},
journal = {Journal of Foo},
volume = 14, 
number = 1, 
pages = {234--778}, 
year = 2004
}

%%%%%%%%%%%%%%%%% direct prediction without correspondence (or Holistic methods)

@inproceedings{Li&Ling22eccv,
  author    = {Xinyi Li and
               Haibin Ling},
  title     = {{GTCaR}: Graph Transformer for Camera Re-localization},
  booktitle = {Proceedings of European Conference on Computer Vision (ECCV)},
  series    = {Lecture Notes in Computer Science},
  volume    = {13670},
  pages     = {229--246},
  publisher = {Springer},
  year      = {2022},
  url       = {https://doi.org/10.1007/978-3-031-20080-9\_14},
  doi       = {10.1007/978-3-031-20080-9\_14},
  biburl    = {https://dblp.org/rec/conf/eccv/LiL22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Li&Ling21iccv,
  author    = {Xinyi Li and Haibin Ling},
  title     = {{PoGO-Net}: Pose Graph Optimization with Graph Neural Networks},
booktitle	= {{IEEE/CVF} International Conference on Computer Vision (ICCV)},
  pages     = {5875--5885},
  year      = {2021},
  url       = {https://doi.org/10.1109/ICCV48922.2021.00584},
  doi       = {10.1109/ICCV48922.2021.00584},
}

% template matching methods (PVNet reference)
@article{huttenlocher1993comparing,
  title={Comparing images using the Hausdorff distance},
  author={Huttenlocher, Daniel P and Klanderman, Gregory A. and Rucklidge, William J},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={15},
  number={9},
  pages={850--863},
  year={1993},
  publisher={IEEE}
}

@inproceedings{gu2010discriminative,
  title={Discriminative mixture-of-templates for viewpoint classification},
  author={Gu, Chunhui and Ren, Xiaofeng},
  booktitle={European Conference on Computer Vision},
  pages={408--421},
  year={2010},
  organization={Springer}
}

@article{hinterstoisser2011gradient,
  title={Gradient response maps for real-time detection of textureless objects},
  author={Hinterstoisser, Stefan and Cagniart, Cedric and Ilic, Slobodan and Sturm, Peter and Navab, Nassir and Fua, Pascal and Lepetit, Vincent},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={34},
  number={5},
  pages={876--888},
  year={2011},
  publisher={IEEE}
}

% classification of viewpoint
@inproceedings{tulsiani2015viewpoints,
  title={Viewpoints and keypoints},
  author={Tulsiani, Shubham and Malik, Jitendra},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1510--1519},
  year={2015}
}

@inproceedings{su2015render,
  title={Render for cnn: Viewpoint estimation in images using cnns trained with rendered 3d model views},
  author={Su, Hao and Qi, Charles R and Li, Yangyan and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2686--2694},
  year={2015}
}

% decompose into viewpoint classfication and in-plane rotation classification and eliminate viewpoints causing ambiguity 
@inproceedings{kehl2017ssd,
  title={Ssd-6d: Making rgb-based 3d detection and 6d pose estimation great again},
  author={Kehl, Wadim and Manhardt, Fabian and Tombari, Federico and Ilic, Slobodan and Navab, Nassir},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1521--1529},
  year={2017}
}

% can be viewed as classification (they create a code book for orientation)
@inproceedings{sundermeyer2018implicit,
  title={Implicit 3d orientation learning for 6d object detection from rgb images},
  author={Sundermeyer, Martin and Marton, Zoltan-Csaba and Durner, Maximilian and Brucker, Manuel and Triebel, Rudolph},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={699--715},
  year={2018}
}

% object pose -- regression, no 3D-2D correspondences
%object dataset: YCB-Video
@inproceedings{xiang2017posecnn,
  title={Posecnn: A convolutional neural network for 6d object pose estimation in cluttered scenes},
  author={Xiang, Yu and Schmidt, Tanner and Narayanan, Venkatraman and Fox, Dieter},
  booktitle = {Robotics: Science and Systems},
  year      = {2018}
}

% regression + classification
@inproceedings{kundu20183d,
  title={3d-rcnn: Instance-level 3d object reconstruction via render-and-compare},
  author={Kundu, Abhijit and Li, Yin and Rehg, James M},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3559--3568},
  year={2018}
}

% regression + classification
@inproceedings{li2018unified,
  title={A unified framework for multi-view multi-class object pose estimation},
  author={Li, Chi and Bai, Jin and Hager, Gregory D},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={254--269},
  year={2018}
}

% without predefined symmetry
% direct estimation (regression), multiple outputs
@inproceedings{manhardt2019explaining,
  title={Explaining the ambiguity of object detection and 6d pose from visual data},
  author={Manhardt, Fabian and Arroyo, Diego Martin and Rupprecht, Christian and Busam, Benjamin and Birdal, Tolga and Navab, Nassir and Tombari, Federico},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6841--6850},
  year={2019}
}

%%%%%%%%%%%%%%%%% sparse correspondence

% heatmap representation cannot represent the points out of the ROI due to the detection error
% The output of this step is a set of heatmaps for each keypoint
@inproceedings{pavlakos20176,
  title={6-dof object pose from semantic keypoints},
  author={Pavlakos, Georgios and Zhou, Xiaowei and Chan, Aaron and Derpanis, Konstantinos G and Daniilidis, Kostas},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={2011--2018},
  year={2017},
  organization={IEEE}
}

% they predict the 2D coordinates of the eight 3D bounding box corners, similar to a previous paper "A Novel Representation of Parts for Accurate 3D Object Detection and Tracking in Monocular Images"
% The 2D coordinates are predicted by a CNN, inputs are image patches
% the difference between this sparse correspondences and our correspondences: the CNN can only accept regular inputs so the 3D keypoints can only be implicitly encoded by the network parameters; also, for consistency across different objects, they use bounding box corners 
@inproceedings{rad2017bb8,
  title={Bb8: A scalable, accurate, robust to partial occlusion method for predicting the 3d poses of challenging objects without using depth},
  author={Rad, Mahdi and Lepetit, Vincent},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={3828--3836},
  year={2017}
}

% network to predict the 2D projections of the corners of the 3D bounding box around our objects.  The main insight was that YOLO was originally designed to regress 2D bounding boxes and to predict the projections of the 3D bounding box corners in the image, a few more 2D points had to be predicted for each object instance in the image.
% BB8 [26] takes a similar approach. However, they first find a 2D segmentation mask around the object and present a cropped image to a second network that predicts the eight 2D corners in the image. 
% The 3D output tensor from our network, which represents for each **cell** a vector consisting of the 2D corner locations, the class probabilities and a confidence value associated with the prediction.
@inproceedings{tekin2018real,
  title={Real-time seamless single shot 6d object pose prediction},
  author={Tekin, Bugra and Sinha, Sudipta N and Fua, Pascal},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={292--301},
  year={2018}
}

% this work uses heatmaps to represent the 2D projections of the 3D keypoints
% so strictly speaking, it is not truely sparse
@inproceedings{oberweger2018making,
  title={Making deep heatmaps robust to partial occlusions for 3d object pose estimation},
  author={Oberweger, Markus and Rad, Mahdi and Lepetit, Vincent},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={119--134},
  year={2018}
}

% the output are pixel-wise offset to the 2D projection
@inproceedings{hu2019segmentation,
  title={Segmentation-driven 6d object pose estimation},
  author={Hu, Yinlin and Hugonot, Joachim and Fua, Pascal and Salzmann, Mathieu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3385--3394},
  year={2019}
}

% % the output are pixel-wise directional vectors to the 2D projection
@inproceedings{peng2019pvnet,
  title={Pvnet: Pixel-wise voting network for 6dof pose estimation},
  author={Peng, Sida and Liu, Yuan and Huang, Qixing and Zhou, Xiaowei and Bao, Hujun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4561--4570},
  year={2019}
}

% hybrid correspondence; it does not estimate GDR-Net style correspondences though
% keypoints: same as PVNet, pixelwise directional vector to the 2D coordinates of the keypoints
% other intermediate representation: edges between every pair of keypoints, pixel-wise symmetry correspondences
% todo: their results on LM-O in CVPR version does not follow the consistent dataset split ratio used in other baseline methods. They update the results in arXiv. GDR-Net refer the arXiv results but use the CVPR reference
@inproceedings{song2020hybridpose,
  title={Hybridpose: 6d object pose estimation under hybrid representations},
  author={Song, Chen and Song, Jiaru and Huang, Qixing},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={431--440},
  year={2020}
}

% PointNet based network to replace PnP+RANSAC
@inproceedings{hu2020single,
  title={Single-stage 6d object pose estimation},
  author={Hu, Yinlin and Fua, Pascal and Wang, Wei and Salzmann, Mathieu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2930--2939},
  year={2020}
}

% multi-scale version of segmentation-driven
% we need to compare the result on LM-O as well
% but it is not as good as GDR-Net
@inproceedings{hu2021wide,
  title={Wide-Depth-Range 6D Object Pose Estimation in Space},
  author={Hu, Yinlin and Speierer, Sebastien and Jakob, Wenzel and Fua, Pascal and Salzmann, Mathieu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15870--15879},
  year={2021}
}

% domain adaptation
@inproceedings{zhang2021keypoint,
  title={Keypoint-Graph-Driven Learning Framework for Object Pose Estimation},
  author={Zhang, Shaobo and Zhao, Wanqing and Guan, Ziyu and Peng, Xianlin and Peng, Jinye},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1065--1073},
  year={2021}
}

%%%%%%%%%%%%%%%%% dense correspondence 
% i.e. input: each 2d pixel; output: each 3d coord.

@inproceedings{zakharov2019dpod,
  title={Dpod: 6d pose object detector and refiner},
  author={Zakharov, Sergey and Shugurov, Ivan and Ilic, Slobodan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1941--1950},
  year={2019}
}

% dense correspondence: disentangle the pose to predict rotation and translation separately to achieve highly accurate and robust pose estimation
% dynamic zoom-in
@inproceedings{li2019cdpn,
  title={Cdpn: Coordinates-based disentangled pose network for real-time rgb-based 6-dof object pose estimation},
  author={Li, Zhigang and Wang, Gu and Ji, Xiangyang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7678--7687},
  year={2019}
}

% GAN based
@inproceedings{park2019pix2pose,
  title={Pix2pose: Pixel-wise coordinate regression of objects for 6d pose estimation},
  author={Park, Kiru and Patten, Timothy and Vincze, Markus},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7668--7677},
  year={2019}
}

% tackle symmetry of the correspondence by fragment-based object representation
% essentially it still estimates dense correspondences
@inproceedings{hodan2020epos,
  title={EPOS: estimating 6D pose of objects with symmetries},
  author={Hodan, Tomas and Barath, Daniel and Matas, Jiri},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11703--11712},
  year={2020}
}

% end-to-end: ConvNet based network to replace PnP+RANSAC
@inproceedings{wang2021gdr,
  title={GDR-Net: Geometry-Guided Direct Regression Network for Monocular 6D Object Pose Estimation},
  author={Wang, Gu and Manhardt, Fabian and Tombari, Federico and Ji, Xiangyang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16611--16621},
  year={2021}
}

% improved version of GDR-Net
% utilize self-occlusion
@inproceedings{di2021so,
  title={SO-Pose: Exploiting Self-Occlusion for Direct 6D Pose Estimation},
  author={Di, Yan and Manhardt, Fabian and Wang, Gu and Ji, Xiangyang and Navab, Nassir and Tombari, Federico},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={12396--12405},
  year={2021}
}

% 
@inproceedings{pitteri20203d,
  title={3d object detection and pose estimation of unseen objects in color images with local surface embeddings},
  author={Pitteri, Giorgia and Bugeau, Aur{\'e}lie and Ilic, Slobodan and Lepetit, Vincent},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  year={2020}
}

% not end-to-end trainable
@article{su2022zebrapose,
  title={ZebraPose: Coarse to Fine Surface Encoding for 6DoF Object Pose Estimation},
  author={Su, Yongzhi and Saleh, Mahdi and Fetzer, Torben and Rambach, Jason and Navab, Nassir and Busam, Benjamin and Stricker, Didier and Tombari, Federico},
  journal={arXiv preprint arXiv:2203.09418},
  year={2022}
}

% end-to-end, by predicting the distribution of the pose
@article{chen2022epro,
  title={EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation},
  author={Chen, Hansheng and Wang, Pichao and Wang, Fan and Tian, Wei and Xiong, Lu and Li, Hao},
  journal={arXiv preprint arXiv:2203.13254},
  year={2022}
}

@article{haugaard2021surfemb,
  title={SurfEmb: Dense and Continuous Correspondence Distributions for Object Pose Estimation with Learnt Surface Embeddings},
  author={Haugaard, Rasmus Laurvig and Buch, Anders Glent},
  journal={arXiv preprint arXiv:2111.13489},
  year={2021}
}

%%%%%%%%%%%%%%%%% other pose estimation methods
% GDR-Net refers this paper to demonstrate why we want differentiable pose estimator...
@inproceedings{wang2020self6d,
  title={Self6D: Self-supervised Monocular 6D Object Pose Estimation},
  author={Wang, Gu and Manhardt, Fabian and Shao, Jianzhun and Ji, Xiangyang and Navab, Nassir and Tombari, Federico},
  booktitle={European Conference on Computer Vision},
  pages={108--125},
  year={2020},
  organization={Springer}
}

@article{wang2021occlusion,
  title={Occlusion-Aware Self-Supervised Monocular 6D Object Pose Estimation},
  author={Wang, Gu and Manhardt, Fabian and Liu, Xingyu and Ji, Xiangyang and Tombari, Federico},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2021},
  publisher={IEEE}
}


% note: published in ECCV 2022
@inproceedings{park2021dprost,
  title={DProST: 6-DoF Object Pose Estimation Using Space Carving and Dynamic Projective Spatial Transformer},
  author={Park, Jaewoo and Cho, Nam Ik},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  year={2022}
}

@inproceedings{huang2022neural,
  title={Neural Correspondence Field for Object Pose Estimation},
  author={Huang, Lin and Hodan, Tomas and Ma, Lingni and Zhang, Linguang and Tran, Luan and Twigg, Christopher and Wu, Po-Chen and Yuan, Junsong and Keskin, Cem and Wang, Robert},
  booktitle={European Conference on Computer Vision},
  pages={585--603},
  year={2022},
  organization={Springer}
}

@article{hu2022perspective,
  title={Perspective Flow Aggregation for Data-Limited 6D Object Pose Estimation},
  author={Hu, Yinlin and Fua, Pascal and Salzmann, Mathieu},
  journal={arXiv preprint arXiv:2203.09836},
  year={2022}
}

@article{cai2022sc6d,
  title={Sc6d: Symmetry-agnostic and correspondence-free 6d object pose estimation},
  author={Cai, Dingding and Heikkil{\"a}, Janne and Rahtu, Esa},
  journal={arXiv preprint arXiv:2208.02129},
  year={2022}
}

@inproceedings{castro2023crt,
  title={CRT-6D: Fast 6D Object Pose Estimation with Cascaded Refinement Transformers},
  author={Castro, Pedro and Kim, Tae-Kyun},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={5746--5755},
  year={2023}
}

%%%%%%%%%%%%%%%%% pose refinement 

@inproceedings{li2018deepim,
  title={Deepim: Deep iterative matching for 6d pose estimation},
  author={Li, Yi and Wang, Gu and Ji, Xiangyang and Xiang, Yu and Fox, Dieter},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={683--698},
  year={2018}
}

@inproceedings{labbe2020cosypose,
  title={CosyPose: Consistent multi-view multi-object 6D pose estimation},
  author={Labb{\'e}, Yann and Carpentier, Justin and Aubry, Mathieu and Sivic, Josef},
  booktitle={European Conference on Computer Vision},
  pages={574--591},
  year={2020},
  organization={Springer}
}

@inproceedings{iwase2021repose,
  title={RePOSE: Fast 6D Object Pose Refinement via Deep Texture Rendering},
  author={Iwase, Shun and Liu, Xingyu and Khirodkar, Rawal and Yokota, Rio and Kitani, Kris M},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3303--3312},
  year={2021}
}

@inproceedings{xu2022rnnpose,
  title={RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust Correspondence Field Estimation and Pose Optimization},
  author={Xu, Yan and Lin, Kwan-Yee and Zhang, Guofeng and Wang, Xiaogang and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14880--14890},
  year={2022}
}

@inproceedings{lipson2022coupled,
  title={Coupled Iterative Refinement for 6D Multi-Object Pose Estimation},
  author={Lipson, Lahav and Teed, Zachary and Goyal, Ankit and Deng, Jia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6728--6737},
  year={2022}
}

%%%%%%%%%%%%%%%%% pose estimation dataset (if not mentioned above)

% Linemod
% evaluation metric: ADD(-S)
@inproceedings{hinterstoisser2012model,
  title={Model based training, detection and pose estimation of texture-less 3d objects in heavily cluttered scenes},
  author={Hinterstoisser, Stefan and Lepetit, Vincent and Ilic, Slobodan and Holzer, Stefan and Bradski, Gary and Konolige, Kurt and Navab, Nassir},
  booktitle={Asian conference on computer vision},
  pages={548--562},
  year={2012},
  organization={Springer}
}

% Linemod-Occluded
@inproceedings{brachmann2014learning,
  title={Learning 6d object pose estimation using 3d object coordinates},
  author={Brachmann, Eric and Krull, Alexander and Michel, Frank and Gumhold, Stefan and Shotton, Jamie and Rother, Carsten},
  booktitle={European conference on computer vision},
  pages={536--551},
  year={2014},
  organization={Springer}
}

% YCB-Video, AUC metric, (see PoseCNN)

% BOP benchmark, which provides physically-based rendered data for training LM-O and YCB-V.
@article{hodan2020bop,
  title={{BOP} Challenge 2020 on {6D} Object Localization},
  author={Hoda{\v{n}}, Tom{\'a}{\v{s}} and Sundermeyer, Martin and Drost, Bertram and Labb{\'e}, Yann and Brachmann, Eric and Michel, Frank and Rother, Carsten and Matas, Ji{\v{r}}{\'i}},
  journal={European Conference on Computer Vision Workshops (ECCVW)},
  year={2020}
}

% evaluation metric: ADD(-S)
@inproceedings{hodavn2016evaluation,
  title={On evaluation of 6D object pose estimation},
  author={Hoda{\v{n}}, Tom{\'a}{\v{s}} and Matas, Ji{\v{r}}{\'\i} and Obdr{\v{z}}{\'a}lek, {\v{S}}t{\v{e}}p{\'a}n},
  booktitle={European Conference on Computer Vision},
  pages={606--619},
  year={2016},
  organization={Springer}
}

% evaluation metric: n degree, n cm
@inproceedings{shotton2013scene,
  title={Scene coordinate regression forests for camera relocalization in RGB-D images},
  author={Shotton, Jamie and Glocker, Ben and Zach, Christopher and Izadi, Shahram and Criminisi, Antonio and Fitzgibbon, Andrew},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2930--2937},
  year={2013}
}

% (from GDR-Net) Notice that to account for symmetries, n-degree n cm is computed w.r.t. the smallest error for all possible ground truth poses --> refer to DeepIM

%%%%%%%%%%%%%%%%% off-the-shell object detector

% \cite{kehl2017ssd} extend it to pose estimation
@inproceedings{liu2016ssd,
  title={Ssd: Single shot multibox detector},
  author={Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C},
  booktitle={European conference on computer vision},
  pages={21--37},
  year={2016},
  organization={Springer}
}

@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  pages={91--99},
  year={2015}
}

@inproceedings{tian2019fcos,
  title={Fcos: Fully convolutional one-stage object detection},
  author={Tian, Zhi and Shen, Chunhua and Chen, Hao and He, Tong},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9627--9636},
  year={2019}
}

%%%%%%%%%%%%%%%%% features, pretrained, etc

% traditional ones, for traditional sparse correspondences
@inproceedings{lowe1999object,
  title={Object recognition from local scale-invariant features},
  author={Lowe, David G},
  booktitle={Proceedings of the seventh IEEE international conference on computer vision},
  volume={2},
  pages={1150--1157},
  year={1999},
  organization={Ieee}
}

@article{rothganger20063d,
  title={3d object modeling and recognition using local affine-invariant image descriptors and multi-view spatial constraints},
  author={Rothganger, Fred and Lazebnik, Svetlana and Schmid, Cordelia and Ponce, Jean},
  journal={International journal of computer vision},
  volume={66},
  number={3},
  pages={231--259},
  year={2006},
  publisher={Springer}
}

@inproceedings{bay2006surf,
  title={Surf: Speeded up robust features},
  author={Bay, Herbert and Tuytelaars, Tinne and Van Gool, Luc},
  booktitle={European conference on computer vision},
  pages={404--417},
  year={2006},
  organization={Springer}
}

@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@inproceedings{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={652--660},
  year={2017}
}

@article{qi2017pointnet++,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
  author={Qi, Charles R and Yi, Li and Su, Hao and Guibas, Leonidas J},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{chen2017rethinking,
  title={Rethinking atrous convolution for semantic image segmentation},
  author={Chen, Liang-Chieh and Papandreou, George and Schroff, Florian and Adam, Hartwig},
  journal={arXiv preprint arXiv:1706.05587},
  year={2017}
}

% DGCNN, graph network
@article{wang2019dynamic,
  title={Dynamic graph cnn for learning on point clouds},
  author={Wang, Yue and Sun, Yongbin and Liu, Ziwei and Sarma, Sanjay E and Bronstein, Michael M and Solomon, Justin M},
  journal={Acm Transactions On Graphics (tog)},
  volume={38},
  number={5},
  pages={1--12},
  year={2019},
  publisher={ACM New York, NY, USA}
}

% HRNet
@article{wang2020deep,
  title={Deep high-resolution representation learning for visual recognition},
  author={Wang, Jingdong and Sun, Ke and Cheng, Tianheng and Jiang, Borui and Deng, Chaorui and Zhao, Yang and Liu, Dong and Mu, Yadong and Tan, Mingkui and Wang, Xinggang and others},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={10},
  pages={3349--3364},
  year={2020},
  publisher={IEEE}
}

%%%%%%%%%%%%%%%%% P3P

@article{quan1999linear,
  title={Linear n-point camera pose determination},
  author={Quan, Long and Lan, Zhongdan},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={21},
  number={8},
  pages={774--780},
  year={1999},
  publisher={IEEE}
}

@article{gao2003complete,
  title={Complete solution classification for the perspective-three-point problem},
  author={Gao, Xiao-Shan and Hou, Xiao-Rong and Tang, Jianliang and Cheng, Hang-Fei},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={25},
  number={8},
  pages={930--943},
  year={2003},
  publisher={IEEE}
}

@inproceedings{persson2018lambda,
  title={Lambda twist: An accurate fast robust perspective three point (P3P) solver},
  author={Persson, Mikael and Nordberg, Klas},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={318--332},
  year={2018}
}



%%%%%%%%%%%%%%%%% PnP

@article{lepetit2009epnp,
  title={Epnp: An accurate o (n) solution to the pnp problem},
  author={Lepetit, Vincent and Moreno-Noguer, Francesc and Fua, Pascal},
  journal={International journal of computer vision},
  volume={81},
  number={2},
  pages={155},
  year={2009},
  publisher={Springer}
}

@inproceedings{kneip2014upnp,
  title={Upnp: An optimal o (n) solution to the absolute pose problem with universal applicability},
  author={Kneip, Laurent and Li, Hongdong and Seo, Yongduek},
  booktitle={European Conference on Computer Vision},
  pages={127--142},
  year={2014},
  organization={Springer}
}

@inproceedings{ferraz2014very,
  title={Very fast solution to the PnP problem with algebraic outlier rejection},
  author={Ferraz, Luis and Binefa, Xavier and Moreno-Noguer, Francesc},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={501--508},
  year={2014}
}

@article{urban2016mlpnp,
  title={MLPnP - A real-time maximum likelihood solution to the perspective-n-point problem},
  author={Urban, Steffen and Leitloff, Jens and Hinz, Stefan},
  journal={arXiv preprint arXiv:1607.08112},
  year={2016}
}

% differentiable PnP: based on implicit function theorem
@inproceedings{chen2020end,
  title={End-to-end learnable geometric vision by backpropagating PnP optimization},
  author={Chen, Bo and Parra, Alvaro and Cao, Jiewei and Li, Nan and Chin, Tat-Jun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8100--8109},
  year={2020}
}

%%%%%%%%%%%%%%%%% pose representation
% the rotation representation we use 
@inproceedings{zhou2019continuity,
  title={On the continuity of rotation representations in neural networks},
  author={Zhou, Yi and Barnes, Connelly and Lu, Jingwan and Yang, Jimei and Li, Hao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5745--5753},
  year={2019}
}

%%%%%%%%%%%%%%%%% pose estimation application

% robot
% template match (PVNet reference)
@inproceedings{zhu2014single,
  title={Single image 3D object detection and pose estimation for grasping},
  author={Zhu, Menglong and Derpanis, Konstantinos G and Yang, Yinfei and Brahmbhatt, Samarth and Zhang, Mabel and Phillips, Cody and Lecce, Matthieu and Daniilidis, Kostas},
  booktitle={2014 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={3936--3943},
  year={2014},
  organization={IEEE}
}

@inproceedings{tremblay2018deep,
  title={Deep Object Pose Estimation for Semantic Robotic Grasping of Household Objects},
  author={Tremblay, Jonathan and To, Thang and Sundaralingam, Balakumar and Xiang, Yu and Fox, Dieter and Birchfield, Stan},
  booktitle={Conference on Robot Learning},
  pages={306--316},
  year={2018},
  organization={PMLR}
}

@inproceedings{tremblay2020indirect,
  title={Indirect object-to-robot pose estimation from an external monocular rgb camera},
  author={Tremblay, Jonathan and Tyree, Stephen and Mosier, Terry and Birchfield, Stan},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4227--4234},
  year={2020},
  organization={IEEE}
}

% autonomous navigation
@inproceedings{manhardt2019roi,
  title={Roi-10d: Monocular lifting of 2d detection to 6d pose and metric shape},
  author={Manhardt, Fabian and Kehl, Wadim and Gaidon, Adrien},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2069--2078},
  year={2019}
}

@inproceedings{wu20196d,
  title={6d-vnet: End-to-end 6-dof vehicle pose estimation from monocular rgb images},
  author={Wu, Di and Zhuang, Zhaoyong and Xiang, Canqun and Zou, Wenbin and Li, Xia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={0--0},
  year={2019}
}

@inproceedings{li2021exploring,
  title={Exploring intermediate representation for monocular vehicle pose estimation},
  author={Li, Shichao and Yan, Zengqiang and Li, Hongyang and Cheng, Kwang-Ting},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1873--1883},
  year={2021}
}

% augmented reality
@article{marchand2015pose,
  title={Pose estimation for augmented reality: a hands-on survey},
  author={Marchand, Eric and Uchiyama, Hideaki and Spindler, Fabien},
  journal={IEEE transactions on visualization and computer graphics},
  volume={22},
  number={12},
  pages={2633--2651},
  year={2015},
  publisher={IEEE}
}

@article{tang20193d,
  title={3D Mapping and 6D Pose Computation for Real Time Augmented Reality on Cylindrical Objects},
  author={Tang, Fulin and Wu, Yihong and Hou, Xiaohui and Ling, Haibin},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={30},
  number={9},
  pages={2887--2899},
  year={2019},
  publisher={IEEE}
}

%%%%%%%%%%%%%%%%% implementation details

% please cite this paper for PyTorch
@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  pages={8026--8037},
  year={2019}
}

%% our optimizer
%% refer to ICLR version?
@inproceedings{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle = {{ICLR}},
  year      = {2015}
}

%% our CNN is pretrained ResNet-34, for fair comparison with GDR-Net.
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

% the split of LM (15% for training) is based on this paper
@inproceedings{brachmann2016uncertainty,
  title={Uncertainty-driven 6d pose estimation of objects and scenes from a single rgb image},
  author={Brachmann, Eric and Michel, Frank and Krull, Alexander and Yang, Michael Ying and Gumhold, Stefan and others},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3364--3372},
  year={2016}
}

% cosine schedule
% TODO: cite the ICLR version?
@inproceedings{loshchilov2016sgdr,
  title     = {{SGDR:} Stochastic Gradient Descent with Warm Restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle = {{ICLR}},
  year={2017}
}

% Chamfer distance (PyTorch3D)
@article{ravi2020pytorch3d,
    author = {Nikhila Ravi and Jeremy Reizenstein and David Novotny and Taylor Gordon
                  and Wan-Yen Lo and Justin Johnson and Georgia Gkioxari},
    title = {Accelerating 3D Deep Learning with PyTorch3D},
    journal = {arXiv:2007.08501},
    year = {2020},
}

% please cite the following three papers for Ranger optimizer
@article{liu2019variance,
  title={On the variance of the adaptive learning rate and beyond},
  author={Liu, Liyuan and Jiang, Haoming and He, Pengcheng and Chen, Weizhu and Liu, Xiaodong and Gao, Jianfeng and Han, Jiawei},
  journal={arXiv preprint arXiv:1908.03265},
  year={2019}
}

@article{zhang2019lookahead,
  title={Lookahead optimizer: k steps forward, 1 step back},
  author={Zhang, Michael and Lucas, James and Ba, Jimmy and Hinton, Geoffrey E},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{yong2020gradient,
  title={Gradient centralization: A new optimization technique for deep neural networks},
  author={Yong, Hongwei and Huang, Jianqiang and Hua, Xiansheng and Zhang, Lei},
  booktitle={European Conference on Computer Vision},
  pages={635--652},
  year={2020},
  organization={Springer}
}


%%%%%%%%%%%%%%%%% existing PnP solver
% progressive-x
@inproceedings{barath2019progressive,
  title={Progressive-X: Efficient, anytime, multi-model fitting algorithm},
  author={Barath, Daniel and Matas, Jiri},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={3780--3788},
  year={2019}
}

%%%%%%%%%%%%%%%%% review of 6D pose
@article{du2021vision,
  title={Vision-based robotic grasping from object localization, object pose estimation to grasp estimation for parallel grippers: a review},
  author={Du, Guoguang and Wang, Kai and Lian, Shiguo and Zhao, Kaiyong},
  journal={Artificial Intelligence Review},
  volume={54},
  number={3},
  pages={1677--1734},
  year={2021},
  publisher={Springer}
}

%%%%%%%%%%%%%%%%% Sequence prediction etc
@article{sun2001sequence,
  title={Sequence learning: From recognition and prediction to sequential decision making},
  author={Sun, Ron and Giles, C Lee},
  journal={IEEE Intelligent Systems},
  volume={16},
  number={4},
  pages={67--70},
  year={2001}
}

% teacher forcing technique
@article{williams1989learning,
  title={A learning algorithm for continually running fully recurrent neural networks},
  author={Williams, Ronald J and Zipser, David},
  journal={Neural computation},
  volume={1},
  number={2},
  pages={270--280},
  year={1989},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~â€¦}
}


%%%%%%%%%%%%%%%%%%% fusion in RGBD
@inproceedings{wang2019densefusion,
  title={Densefusion: 6d object pose estimation by iterative dense fusion},
  author={Wang, Chen and Xu, Danfei and Zhu, Yuke and Mart{\'\i}n-Mart{\'\i}n, Roberto and Lu, Cewu and Fei-Fei, Li and Savarese, Silvio},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3343--3352},
  year={2019}
}

@inproceedings{he2021ffb6d,
  title={Ffb6d: A full flow bidirectional fusion network for 6d pose estimation},
  author={He, Yisheng and Huang, Haibin and Fan, Haoqiang and Chen, Qifeng and Sun, Jian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3003--3013},
  year={2021}
}

%%%%%%%%%%%%%%%%% visibility, self-occlusion
@incollection{katz2007direct,
  title={Direct visibility of point sets},
  author={Katz, Sagi and Tal, Ayellet and Basri, Ronen},
  booktitle={ACM SIGGRAPH 2007 papers},
  pages={24--es},
  year={2007}
}

%%%%%%%%%%%%%%%%% literature review for GNN

@inproceedings{simonovsky2017dynamic,
  title={Dynamic edge-conditioned filters in convolutional neural networks on graphs},
  author={Simonovsky, Martin and Komodakis, Nikos},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3693--3702},
  year={2017}
}


@inproceedings{chen2021fs,
  title={Fs-net: Fast shape-based network for category-level 6d object pose estimation with decoupled rotation mechanism},
  author={Chen, Wei and Jia, Xi and Chang, Hyung Jin and Duan, Jinming and Shen, Linlin and Leonardis, Ales},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1581--1590},
  year={2021}
}

@inproceedings{zhou2021pr,
  title={Pr-gcn: A deep graph convolutional network with point refinement for 6d pose estimation},
  author={Zhou, Guangyuan and Wang, Huiqun and Chen, Jiaxin and Huang, Di},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2793--2802},
  year={2021}
}

% representation learning
@inproceedings{lin2020convolution,
  title={Convolution in the cloud: Learning deformable kernels in 3d graph convolution networks for point cloud analysis},
  author={Lin, Zhi-Hao and Huang, Sheng-Yu and Wang, Yu-Chiang Frank},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1800--1809},
  year={2020}
}

@inproceedings{verma2018feastnet,
  title={Feastnet: Feature-steered graph convolutions for 3d shape analysis},
  author={Verma, Nitika and Boyer, Edmond and Verbeek, Jakob},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2598--2606},
  year={2018}
}

% detection
@inproceedings{shi2020point,
  title={Point-gnn: Graph neural network for 3d object detection in a point cloud},
  author={Shi, Weijing and Rajkumar, Raj},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1711--1719},
  year={2020}
}

@inproceedings{chen2020hierarchical,
  title={A hierarchical graph network for 3d object detection on point clouds},
  author={Chen, Jintai and Lei, Biwen and Song, Qingyu and Ying, Haochao and Chen, Danny Z and Wu, Jian},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={392--401},
  year={2020}
}

% segmentation
@inproceedings{qi20173d,
  title={3d graph neural networks for rgbd semantic segmentation},
  author={Qi, Xiaojuan and Liao, Renjie and Jia, Jiaya and Fidler, Sanja and Urtasun, Raquel},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5199--5208},
  year={2017}
}

@inproceedings{li2019deepgcns,
  title={Deepgcns: Can gcns go as deep as cnns?},
  author={Li, Guohao and Muller, Matthias and Thabet, Ali and Ghanem, Bernard},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9267--9276},
  year={2019}
}

% data generation
@inproceedings{qian2020pugeo,
  title={PUGeo-Net: A geometry-centric network for 3D point cloud upsampling},
  author={Qian, Yue and Hou, Junhui and Kwong, Sam and He, Ying},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XIX},
  pages={752--769},
  year={2020},
  organization={Springer}
}

@inproceedings{lin2021mesh,
  title={Mesh graphormer},
  author={Lin, Kevin and Wang, Lijuan and Liu, Zicheng},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={12939--12948},
  year={2021}
}

% initial GNN
@article{sperduti1997supervised,
  title={Supervised neural networks for the classification of structures},
  author={Sperduti, Alessandro and Starita, Antonina},
  journal={IEEE Transactions on Neural Networks},
  volume={8},
  number={3},
  pages={714--735},
  year={1997},
  publisher={IEEE}
}
