{
    "arxiv_id": "2303.09412",
    "paper_title": "NeRFtrinsic Four: An End-To-End Trainable NeRF Jointly Optimizing Diverse Intrinsic and Extrinsic Camera Parameters",
    "authors": [
        "Hannah Schieber",
        "Fabian Deuser",
        "Bernhard Egger",
        "Norbert Oswald",
        "Daniel Roth"
    ],
    "submission_date": "2023-03-16",
    "revised_dates": [
        "2023-07-07"
    ],
    "latest_version": 3,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Novel view synthesis using neural radiance fields (NeRF) is the state-of-the-art technique for generating high-quality images from novel viewpoints. Existing methods require a priori knowledge about extrinsic and intrinsic camera parameters. This limits their applicability to synthetic scenes, or real-world scenarios with the necessity of a preprocessing step. Current research on the joint optimization of camera parameters and NeRF focuses on refining noisy extrinsic camera parameters and often relies on the preprocessing of intrinsic camera parameters. Further approaches are limited to cover only one single camera intrinsic. To address these limitations, we propose a novel end-to-end trainable approach called NeRFtrinsic Four. We utilize Gaussian Fourier features to estimate extrinsic camera parameters and dynamically predict varying intrinsic camera parameters through the supervision of the projection error. Our approach outperforms existing joint optimization methods on LLFF and BLEFF. In addition to these existing datasets, we introduce a new dataset called iFF with varying intrinsic camera parameters. NeRFtrinsic Four is a step forward in joint optimization NeRF-based view synthesis and enables more realistic and flexible rendering in real-world scenarios with varying camera parameters.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.09412v1",
        "http://arxiv.org/pdf/2303.09412v2",
        "http://arxiv.org/pdf/2303.09412v3"
    ],
    "publication_venue": null
}