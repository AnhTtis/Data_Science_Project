\section{Discussion}
\label{sec:discussion}

Our breaking point analysis shows that we outperform \ac{nerf}$\text{-}\text{-}$ on \ac{llff} and \datasetname. However, on some scenes our method needs a sufficient number of images for successful joint optimization, as indicated in Table~\ref{tab:breaking_ana} and the supplementary material. When dealing with multiple intrinsic camera parameters on \datasetname, the same conclusion emerges. Nevertheless, our approach can handle diverse intrinsic camera parameters while \ac{nerf}$\text{-}\text{-}$ learns only an average over the input. Fig.~\ref{fig:bulli_fig} shows that accurately estimated intrinsic camera parameters are crucial for a valid image representation. While an average over the images can lead to high distortions, our precise estimation of differing intrinsic camera parameters supports accurate image synthesis.

We also observe that a rotation error of $180^{\circ}$ leads to a mirror pose. This was already reported by Wang et al.~\cite{wang_nerf_2021}. We provide an example image in the supplementary material. While mirror poses still lead to a high \ac{psnr} value, the position of objects in the scene is shifted. To further stabilize the pose \ac{mlp}, we added the \ac{ssim} loss. Our supplementary material shows that our approach with the \ac{ssim} loss achieves better convergence for a fixed random seed. However, using the loss over the whole training process leads to a degradation in performance for the \ac{psnr} value.

Our experiments highlight the importance of accurate intrinsic and extrinsic camera parameter estimations for an end-to-end trainable \ac{nerf}. Incorrect extrinsic camera parameters can shift objects in the scene, while incorrect intrinsic camera parameters can distort the resulting image.