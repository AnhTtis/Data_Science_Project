\section{Related Work}
Our approach addresses the joint optimization of \ac{nerf} as well as intrinsic and extrinsic camera parameters. We first review approaches, that predict camera parameters, followed by the combination of \ac{nerf} and camera pose refinement. Most importantly, we consider approaches estimating camera parameters and optimizing \ac{nerf} without prior initialization.

\subsection{Camera Parameter Estimation}
Traditional approaches which estimate the camera parameters often use \ac{sfm}. \ac{sfm} algorithms extract features and match them to find a 2D-3D correspondence. They estimate candidate poses and apply classical or optimized RANSAC to find the best matching poses~\cite{brachmann_visual_2021,fischler_random_1981}. 

In addition to \ac{sfm}-based approaches, \ac{slam} algorithms often jointly optimize the camera parameters together with the 3D reconstruction. MonoSLAM~\cite{davison_monoslam_2007} and ORB-SLAM~\cite{campos_orb-slam3_2021} estimate the  extrinsic camera parameters using feature correspondences. Others apply the photometric loss to optimize the camera pose~\cite{engel_lsd-slam_2014,forster_svo_2014,newcombe_dtam_2011}. COLMAP~\cite{schonberger_structure--motion_2016} is typically used to preprocess the camera parameters for \ac{nerf}. It first creates a sparse reconstruction using \ac{sfm}, and afterwards applies dense modelling using multi-view stereo.

Besides \ac{sfm} or \ac{slam}, deep learning based approaches are applied. Lee et al.~\cite{lee_camera--robot_2020} estimate the extrinsic camera parameters, assuming the intrinsic parameters to be known. The pose is estimated via the prediction of keypoints by a deep neural network using purely synthetic data. Elmoogy et al.~\cite{elmoogy_pose-gnn_2021} use a \ac{cnn} to extract features from each image and feed a \ac{gnn} to find the extrinsic camera parameters.  In addition to only predicting the extrinsic camera parameters, Butt et al.~\cite{butt_camera_2022} simultaneously estimate intrinsic camera parameters using a  \ac{cnn}. They apply Inception-v3 and a camera projection loss to estimate all camera parameters.

\subsection{\acs{nerf} and Camera Pose Refinement}
Mildenhall et al.~\cite{mildenhall_nerf_2020} introduced \ac{nerf}, which encodes a scene representation in a \ac{mlp}. 
Subsequent approaches optimize towards a higher image quality, handle fewer input views~(e.g.~\cite{barron_mip-nerf_2021,kulkarni_360fusionnerf_2022,martin-brualla_nerf_2021}) or use search engine results as input and handle the camera parameters via COLMAP~\cite{martin-brualla_nerf_2021}. 
Others investigate the impact of jointly optimizing extrinsic camera parameters and \ac{nerf} to improve \ac{nvs} quality~\cite{jeong_self-calibrating_2021,lin_barf_2021,meng_gnerf_2021,truong_sparf_2022}. 

Jeong et al.~\cite{jeong_self-calibrating_2021} tackle the joint extrinsic camera parameter and \ac{nvs} optimization with the geometric loss. This loss jointly optimizes the \ac{nerf} and extrinsic camera parameters focusing on forward-facing scenes. Besides optimizing initialized camera parameters, their approach can estimate unknown parameters by finding correspondences.
Lin et al.~\cite{lin_barf_2021} enhance this idea by using a coarse-to-fine annealing schedule in BARF. BARF jointly optimizes the 3D scene representation and registers the camera poses, initialized by noisy camera poses. Chen et al.~\cite{chng_gaussian_2022} improve BARF using Gaussian activation functions. While Truong et al.~\cite{truong_sparf_2022} also optimize on noisy poses, they additionally consider only sparse input views.

Apart from BARF-like approaches, Meng et al.~\cite{meng_gnerf_2021} combine \ac{nerf} and a GAN in GNeRF. GNeRF first randomly samples poses from a predefined pose sampling space and then optimizes the \ac{nerf}. The discriminator differentiates between real and fake images. An inversion network then learns the camera pose. Finally, the pose embedding and \ac{nerf} are optimized using the photometric loss.

\subsection{\acs{nerf} Without Known Camera Parameters}

While previous methods initialize their pose regression from noisy poses~\cite{lin_barf_2021,truong_sparf_2022,chng_gaussian_2022} or sample from a predefined space~\cite{meng_gnerf_2021}, iNerf~\cite{yen-chen_inerf_2021} optimizes the camera pose by inverting a pretrained \ac{nerf}. It starts from an initial pose and applies gradient descent to minimize the residual between the pixels in the rendered image and the observed image. Wang et al.~\cite{wang_nerf_2021} introduce \ac{nerf}$\text{-}\text{-}$ which optimizes not only the extrinsic but also the intrinsic camera parameters. The camera parameters are jointly optimized with the \ac{nerf} using the photometric loss. However, the intrinsic camera parameter estimation is limited to only one camera. They also limit their \ac{nerf} to focus on forward-facing scenes with a perturbation $\leq20^{\circ}$ and do not provide specific ray sampling for $360^{\circ}$ scenes. SiNeRF~\cite{xia_sinerf_2022} extends this approach by utilizing sinusoidal activation functions for radiance mapping and a novel \ac{mrs}. The \ac{mrs} ensures efficient training and prevents poor supervision from the lack of ray diversity. Their approach also focuses on one single camera intrinsic. Although they use \ac{mrs} the applicability is limited to forward-facing scenes. % \ac{nerf} minimizing the correspondence between pre-extracted poses

The most relevant work to ours is \ac{nerf}$\text{-}\text{-}$~\cite{wang_nerf_2021} and SiNeRF~\cite{xia_sinerf_2022} as they jointly optimize the \ac{nerf}, intrinsic camera parameters and extrinsic camera parameters, without any priors. However, the intrinsic camera parameters are restricted to one type of camera. Thus, we further optimize the camera intrinsic estimation to generalize on differing cameras at the same time. Moreover, we not only learn the six extrinsic parameters but show that a \ac{mlp} using Gaussian Fourier features can minimize the translation and rotation error and improves \ac{nvs} quality.
