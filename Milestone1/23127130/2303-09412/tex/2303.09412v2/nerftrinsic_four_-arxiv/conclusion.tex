\section{Limitations}

A limitation of our work, inherited from previous research~\cite{wang_nerf_2021,xia_sinerf_2022}, is the focus on forward-facing scenes. This means that our approach is not suitable for $360^{\circ}$ scenes. While current approaches that can handle non-forward-facing scenes exist~\cite{lin_barf_2021,truong_sparf_2022,yen-chen_inerf_2021}, they typically rely on noisy poses or a pretrained \ac{nerf} for initialization, which are not transferable to real-world scenarios. Additionally, we found that predicting extrinsic camera parameters becomes more challenging in our joint optimization approach when dealing with varying camera intrinsic parameters.

Moreover, the initialization of the pose \ac{mlp} is challenging. Therefore, we see potential in a regularization method for  coordinate based \acp{mlp}~\cite{ramasinghe_regularizing_2022}.


\section{Conclusion}

We introduce \approach, an end-to-end trainable \ac{nerf} that jointly optimizes the extrinsic camera parameters, the intrinsic camera parameters, and the scene representation. Unlike other joint optimization frameworks, it is not limited to one type of camera. 
To validate our approach, we present our real-world \datasetname dataset, which demonstrates that \approach achieves better results compared to \ac{nerf}$\text{-}\text{-}$ when a diverse set of cameras is used. Additionally, our work outperforms the joint optimization frameworks \ac{nerf}$\text{-}\text{-}$ and SinNeRF on existing datasets. By using our Gaussian Fourier feature-based pose \ac{mlp}, we achieve a better camera pose estimation, which consequently enables an improved estimation of the intrinsic camera parameters and higher-quality \ac{nvs} results. In summary, \approach allows the estimation of both diverse intrinsic and extrinsic camera parameters in joint optimization with \ac{nerf}.