\section{Related works}
 
\noindent\textbf{Place recognition as image retrieval.} 
Visual place recognition is widely addressed as a metric learning problem, in which the descriptors of images of a place are learned to be close together in a latent space~\cite{milford15metric}. Existing methods optimize ranking loss functions, such as contrastive, triplet or average precision~\cite{radenovic2018fine,Gordo2017,revaud2019learning}. An extensive  benchmark of different approaches is in~\cite{Berton2022Bench}.
NetVLAD~\cite{Arandjelovic2017} is milestone of VPR and builds on a triplet network with an end-to-end trainable VLAD layer. It requires a computationally- and memory-expensive hard-pair mining to compose proper batches and guarantee convergence. 
SARE~\cite{liu2019stochastic} uses a NetVLAD backbone trained with a probabilistic attractive and repulsive mechanism, also making use of hard-pair mining. %While hard-pair mining addresses issues of the training stalling in local minima due to noisy binary labels~\cite{Arandjelovic2017}, we argue that batch composition can be effectively addressed before training. For instance, we use image metadata, such as GPS and compass angle, to estimate the graded similarity of image pairs, and subsequently use it to balance the distribution of hard- and easy-pairs in the training batches. 
Hard-pair mining addresses issues of the training stalling in local minima due to noisy binary labels, and is used to compose the training batches so that hard pairs are selected for the training~\cite{Arandjelovic2017}. We instead use image metadata (e.g. camera pose as GPS and compass) to a-priori estimate the graded similarity of image pairs, and subsequently use it to balance hard- and easy-pairs in the training batches. This allows to train VPR models using the graded similarity of images and avoiding hard-pair mining.

Training with noisy binary labels produces image descriptors with drawbacks in nearest neighbor search retrieval, and re-ranking algorithms are necessary to post-process the retrieved results and increase VPR performance~\cite{delg,sarlin20superglue}. Patch-NetVLAD~\cite{hausler2021patch} builds on a NetVLAD backbone and performs multi-scale aggregation of NetVLAD descriptors to re-rank retrieval results. A transformer architecture named TransVPR was trained using a triplet loss function and hard-pair mining in~\cite{wang2022transvpr}. The retrieval step is combined with a costly re-ranking strategy to improve the retrieval results. We instead focus on using  more informative and robust image pair labels to avoid noisy training and obtain more effective image descriptors for nearest neighbor search, with no necessity of performing re-ranking.

%re-ranking is used to overcome weaknesses of the learned representations in nearest neighbor search at the cost of extra processing~\cite{hausler2021patch,wang2022transvpr}.


 
\noindent\textbf{Image graded similarity. } 
Soft assignment to positive and negative classes of image pairs was investigated in~\cite{thoma2020soft}, where weighting of the assignment was based on the Euclidean distance between the GPS coordinates associated to the images. As the GPS distance induced label noise in the training process, hard-negative pair mining was still necessary to train VPR networks.
In~\cite{SFRS}, image region similarity was coupled with the GPS weak labels in a self-supervised framework to mine hard positive samples. In~\cite{berton22cosplace}, the authors formulated the VPR metric learning as a classification problem, splitting image training into classes based on similar GPS locations  to facilitate large-scale city-wide recognition.
Camera pose was used in~\cite{balntas2018relocnet} to estimate the camera frustum overlap and regress descriptors for camera (re-)localization in small-scale (indoor) environments. 
%Some attempts to include partial similarity information were done to train descriptors for relative pose estimation and camera localization in RelocNet and CamNet~\cite{ding2019camnet}, where the camera frustum overlap is used as a target to regress the relative pose of cameras. 
In~\cite{kim2021embedding}, a weighting scheme for the contrastive loss function is proposed as a function of the distance in the latent space, which requires an extra step of normalization of the distances to avoid a divergent training. In this work, we relabel VPR datasets using camera pose and field of view overlap, or ratio of shared 3D surface as proxies to estimate the graded similarity of training image pairs. We compute the new labels once, and use them to select the training batches and directly in the optimization of the networks to obtain effective descriptors for VPR in a data-efficient manner.


\noindent\textbf{Relation and difference with prior works. } We undertake a different direction than previous works, and propose a simplified way to learn image descriptors for retrieval-based VPR. We use contrastive architectures without hard-pair mining and exploit the graded similarity of image pairs to learn robust descriptors.
Instead of developing algorithmic solutions (e.g. hard-pair mining or re-ranking) to achieve better VPR results by increasing the complexity of the methods,  %, to , that is better retrieved results in a nearest-neighbor retrieval scheme. 
we focus on data-efficiency and improve similarity labels to better exploit the training data. This allows to purposely keep the complexity of the architecture simpler (a convolutional backbone and a straightforward pooling strategy) than other methods. We apply prior knowledge and use metadata about the position and orientation of the cameras to estimate a more robust ground truth image similarity that enables to drop expensive hard-mining procedures and train (bigger) networks efficiently. We show that this approach leads to reduced training time and very robust descriptors that perform well in nearest neighbour search with no need of re-ranking.


%In this light, we showed that for place recognition we can achieve very high results (in some cases better than sota), without the need of complicating the models, but with a wiser use of the data and labels.

