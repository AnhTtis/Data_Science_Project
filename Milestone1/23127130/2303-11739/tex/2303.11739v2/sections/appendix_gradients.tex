\section{Gradient computations}
Let us consider two input images $x_i$ and $x_j$, their latent representations $\hat{f}(x_i)$ and $\hat{f}(x_j)$, and define $ d(x_i, x_j)$ the Euclidean distance between the representations, such as:
\begin{equation}
\nonumber
 d(x_i, x_j) = \left \| \hat{f}(x_i)-\hat{f}(x_j) \right \|_2
\end{equation}
For simplicity of notation, hereinafter we refer to $d(x_i, x_j)$ as $d$.

\subsection{Contrastive loss}

\noindent The Contrastive Loss function is defined as:
\begin{equation}
\nonumber
\mathcal{L}_{CL}=\begin{cases}
\frac{1}{2} d ^2 ,& \text{if } y= 1\\
\frac{1}{2}\max(\tau- d ,0)^2,& \text{if } y=0
\end{cases}
\end{equation}
\noindent where $y$ corresponds to the binary ground truth label and $\tau$ corresponds to the margin.

\noindent In order to compute the gradient for this function, we consider three cases, depending on the ground truth label $y$ and the value of the distance $d$. 

\noindent \textbf{Case 1) $y=1$}

\noindent The loss function becomes:
\begin{equation}
    \nonumber
    \mathcal{L}_{CL}=\frac{1}{2} d ^2
\end{equation}

\noindent and its derivative with respect to $d$ is:
\begin{align}
\nonumber
\begin{split}
    \nabla  \mathcal{L}_{CL} = \frac{\partial}{\partial d} \left( \mathcal{L}_{CL} \right) =\frac{\partial}{\partial d} \left( \frac{1}{2} d^2 \right)=  d
\end{split}
\end{align}

\noindent \textbf{Case 2) $y=0, d < \tau$}
\noindent The loss function becomes:
\begin{equation}
    \nonumber
    \mathcal{L}_{CL}=\frac{1}{2}(\tau- d)^2
\end{equation}

\noindent and its derivative with respect to $d$ is:
\begin{align*}
\nonumber
\begin{split}
\nabla {} \mathcal{L}_{CL}=&
\frac{\partial}{\partial d} \left(  \mathcal{L}_{CL} \right) =\frac{\partial}{\partial d} \left[ \frac{1}{2}(\tau- d)^2 \right]=\\
&=(\tau-d)(-1)= d-\tau
\end{split}
\end{align*}

\noindent  \textbf{Case 3) $y=0, d \geq \tau$}
\begin{equation}
    \nonumber
    \mathcal{L}_{CL} = 0
\end{equation}
and the gradient $\mathcal{L}_{CL} = 0$ as well. Thus, case 2 and case 3, for $y=0$, can be grouped as: 
%\textbf{Case 2 and Case 3 simplification, $y=0$}

\begin{equation}
    \nonumber
     \nabla  \mathcal{L}_{CL}=\begin{cases}
     d-\tau ,& \text{if } d < \tau\\
    0 ,& \text{if } d \geq \tau
\end{cases}
\end{equation}

\noindent and simplified as:

\begin{equation}
    \nonumber
     \nabla  \mathcal{L}_{CL}=\min( d-\tau,0)
\end{equation}

\noindent Finally, the \textbf{gradient of the Contrastive Loss function} is:

\begin{equation}
\nonumber
     \nabla  \mathcal{L}_{CL}=\begin{cases}
     d ,& \text{if } y= 1\\
    \min( d-\tau,0) ,& \text{if } y=0
\end{cases}
\end{equation}

%
\subsection{Generalized Contrastive loss}
We defined the Generalized Contrastive Loss function as:
\begin{equation}
\nonumber
 \mathcal{L}_{GCL}= \psi_{i,j}\cdot \frac{1}{2}d^2 + (1-\psi_{i,j}) \cdot \frac{1}{2}\max(\tau-d,0)^2
\end{equation}
\noindent where $\psi_{i,j}$ is the ground truth degree of similarity between the input images $x_i$ and $x_j$, and its values are in the interval $[0,1]$.
To compute the gradient of the GCL function we consider two cases, namely when 1) the distance $d$ between the representations is lower than the margin $\tau$ and 2) the alternative case when $d$ is larger than $\tau$. 

\noindent \textbf{Case 1) $d < \tau$}
\noindent The Generalized Contrastive loss function becomes:

\begin{equation}
\nonumber
 \mathcal{L}_{GCL}= \psi_{i,j}\cdot \frac{1}{2}d^2 + (1-\psi_{i,j}) \cdot \frac{1}{2}(\tau-d)^2 
\end{equation}

\noindent and its derivative with respect to $d$ is:
\begin{align*} 
\nonumber
\nabla  \mathcal{L}_{GCL}= \\
& = \frac{\partial}{\partial d} \mathcal{L}_{GCL}=\\
& = \frac{\partial}{\partial d} \left[ \psi_{i,j} \cdot \frac{1}{2} d^2  + (1 - \psi_{i,j}) \cdot \frac{1}{2}(\tau - d)^2 \right]=
\\&=\psi_{i,j} \cdot d + (1-\psi_{i,j}) (\tau-d)(-1)=
% \\&=\psi_{i,j} \cdot d + (1 - \psi_{i,j}) \cdot (d - \tau)=
\\&=\psi_{i,j} \cdot d + d - \tau- \psi_{i,j} \cdot d + \psi_{i,j} \cdot \tau =
%\\&=d-\tau+\psi_{i,j}\cdot\tau=
%\\&=d+\tau(-1+\psi_{i,j})=
\\&=d+\tau(\psi_{i,j} -1)
\end{align*}

\noindent \textbf{Case 2) $d \geq \tau$}

\noindent The Generalized Contrastive loss function becomes:
\begin{equation}
\nonumber
 \mathcal{L}_{GCL}= \psi_{i,j}\cdot \frac{1}{2}d^2 + (1-\psi_{i,j}) \cdot \frac{1}{2}(0)^2 = \psi_{i,j}\cdot \frac{1}{2}d^2
\end{equation}

\noindent and its derivative with respect to $d$ is:
\begin{align*} 
\nonumber
\nabla \mathcal{L}_{GCL}=
\\&=\frac{\partial}{\partial d}\mathcal{L}_{GCL}=
\\&=\frac{\partial}{\partial d} \left[ \psi_{i,j}\cdot \frac{1}{2} d^2  \right]
\\&=d \cdot \psi_{i,j}
\end{align*}


\noindent Finally, the \textbf{gradient of the Generalized Contrastive Loss function} is:
\begin{equation}
     \nabla  \mathcal{L}_{GCL}=\begin{cases}d+\tau(\psi_{i,j}-1),& \text{if } d<\tau\\
     d \cdot \psi_{i,j},& \text{if } d \geq \tau\\
     \end{cases}
\end{equation} 
