{
    "arxiv_id": "2303.16067",
    "paper_title": "Lazy learning: a biologically-inspired plasticity rule for fast and energy efficient synaptic plasticity",
    "authors": [
        "Aaron Pache",
        "Mark CW van Rossum"
    ],
    "submission_date": "2023-03-26",
    "revised_dates": [
        "2023-03-29"
    ],
    "latest_version": 1,
    "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
    ],
    "abstract": "When training neural networks for classification tasks with backpropagation, parameters are updated on every trial, even if the sample is classified correctly. In contrast, humans concentrate their learning effort on errors. Inspired by human learning, we introduce lazy learning, which only learns on incorrect samples. Lazy learning can be implemented in a few lines of code and requires no hyperparameter tuning. Lazy learning achieves state-of-the-art performance and is particularly suited when datasets are large. For instance, it reaches 99.2% test accuracy on Extended MNIST using a single-layer MLP, and does so 7.6x faster than a matched backprop network",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16067v1"
    ],
    "publication_venue": "13 pages, 6 figures"
}