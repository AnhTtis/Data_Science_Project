{
    "arxiv_id": "2303.08133",
    "paper_title": "MeshDiffusion: Score-based Generative 3D Mesh Modeling",
    "authors": [
        "Zhen Liu",
        "Yao Feng",
        "Michael J. Black",
        "Derek Nowrouzezahrai",
        "Liam Paull",
        "Weiyang Liu"
    ],
    "submission_date": "2023-03-14",
    "revised_dates": [
        "2023-03-15"
    ],
    "latest_version": 1,
    "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
    ],
    "abstract": "We consider the task of generating realistic 3D shapes, which is useful for a variety of applications such as automatic scene generation and physical simulation. Compared to other 3D representations like voxels and point clouds, meshes are more desirable in practice, because (1) they enable easy and arbitrary manipulation of shapes for relighting and simulation, and (2) they can fully leverage the power of modern graphics pipelines which are mostly optimized for meshes. Previous scalable methods for generating meshes typically rely on sub-optimal post-processing, and they tend to produce overly-smooth or noisy surfaces without fine-grained geometric details. To overcome these shortcomings, we take advantage of the graph structure of meshes and use a simple yet very effective generative modeling method to generate 3D meshes. Specifically, we represent meshes with deformable tetrahedral grids, and then train a diffusion model on this direct parametrization. We demonstrate the effectiveness of our model on multiple generative tasks.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.08133v1"
    ],
    "publication_venue": "Published in ICLR 2023 (Spotlight, Notable-top-25%)"
}