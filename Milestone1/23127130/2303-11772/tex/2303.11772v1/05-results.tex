\section{Results of ROV-Enforcement}\label{sc:rov}
Previous work explored the fraction of ROV filtering without characterizing the networks that enforce ROV. In 2018 \cite{hlavacek2018practical} found that between 0.5\% and 2,3\% of the ASes enforce ROV, and in 2021 \cite{rodday2021revisiting} found only 0.6\%, with more extensive protection by routeservers. Our findings indicate that at least 27\% of the ASes enforce ROV either strictly or partially, with the highest deployment rates in Europe and North America. We analyze the size and type of ROV-enforcing ASes, finding that mostly large ASes and ISPs enforce ROV.

\subsection{How many ASes enforce ROV?}

{\bf According to control-plane measurements.} The control-plane measurement passively observes BGP announcements on the Internet. Thus, it cannot directly correlate differences in forwarding paths to the two prefixes from the same origin, which mitigates the utilization of divergence points in the control-plane classification. The control-plane classification scheme thus relies on identifying ROV-enforcing ASes over negative evidence; ASes with negative evidence are classified as not ROV-enforcing. ASes without negative evidence are classified according to their visibility in different measurements. If an ASes has been observed on paths to both prefixes and in both configurations and still only forwarded valid paths, the classification scheme concludes that the AS likely enforced ROV.

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.42\textwidth]{figures_pdf/class_continents.pdf}
    \caption[Classification Distribution Data-Plane]%
    {ROV enforcement worldwide. Significant differences in ROV enforcement across regions.}
    \vspace{-10pt}
    \label{fig:class-cont}
\end{figure}

The results of the control-plane illustrate an upper bound ROV enforcement of 45.4\%, summing up the observed percentages of categories 2, 3, and 4. The percentage of ASes with evidence for enforcement is 36.8\%, out of which 29.9\% show strong signs of enforcement. The distribution of ASes to control-plane categories is given by:

{\scriptsize
\begin{verbatim}
[C1] negative evidence:        190 [54.6%] 
[C2] no negative evidence:     30  [8.6%]
[C3] strong positive evidence: 104 [29.9%] 
[C4] some positive evidence:   24  [6.9%]
\end{verbatim}
}

{\bf According to data-plane measurements.} The data-plane results confirm the trend observed on the control-plane.Of the 2325 ASes observed in the data-plane measurement, approximately 24\% show signs of strict ROV enforcement. 43\% show no signs of any enforcement. This relatively low rate indicates that the majority of systems in the Internet are currently affected by ROV, either through the passive protection of ROV enforcement by others, through partial enforcement or implemented own strict enforcement. The distribution of ASes according to data-plane categories is given by:

{\scriptsize
\begin{verbatim}
[C1] no ROV:               995 [42.8%] 
[C2] weak depreference:    39  [1.7%]
[C3] strong depreference:  58  [2.5%]
[C4] no negative evidence: 393 [16.9%]
[C5] no positive evidence: 286 [12.3%]
[C6] ROV evidence:         196 [8.4%]
[C7] strong evidence:      358 [15.4%]
\end{verbatim}
}


\begin{figure}[t!]
    \centering
    \includegraphics[width=0.44\textwidth]{figures_pdf/effect_th.pdf}
    \caption{Size distribution among the categories. ASes with strict or partial ROV enforcement are on average larger than other categories. Allowing a threshold of invalid paths in strict enforcement increases the size in strictly enforcing ASes.}
      \vspace{-10pt}
    \label{fig:size-by-cat}
\end{figure}

{\bf Correlation control- vs. data-plane.}
Since the control-plane measurements use a different architecture than the data-plane, they see a partially different view of the Internet. Collectors of the control-plane are distributed differently than the vantage points in the data-plane and thus, our measurement results in the control-plane contain more ASes from North America. The intersection between data-plane and control-plane measurements contains 163 ASes, while 220 ASes were only observed in the control-plane, and 2162 ASes were only seen in the data-plane.

Even with its limited size, the intersection of the measurements provides insights into their classification differences.

Overall, we rate 99 ASes as high similarity, 47 ASes as medium, and 17 ASes as low similarity. These results indicate that classification results between control and data-plane are coherent; both approaches reach a consistent result for 90\% of the observed ASes. 10\% of the categorizations are conflicting, i.e., the ASes are classified as ROV-enforcing in one measurement while being classified as non-enforcing in the other. The factors that lead to a different classification include limited path visibility of the control-plane, selective enforcement depending on the route-origin, a lack of IXP visibility in the control-plane. 

\ignore{
\begin{itemize}
    \item \textbf{High Similarity} 99
    \item \textbf{Medium Similarity:} 47
    \item \textbf{Low Similarity:} 17
    \label{enum:cor-results}
\end{itemize}

\begin{enumerate}
    \item \textbf{Category 1 - No ROV:} 995 [42.8\%] 
    \item \textbf{Category 2 - Weak Depreference:} 39 [1.7\%]
    \item \textbf{Category 3 - Strong Depreference:} 58 [2.5\%]
    \item \textbf{Category 4 - No negative Evidence:} 393 [16.9\%]
    \item \textbf{Category 5 - No positive Evidence:} 286 [12.3\%]
    \item \textbf{Category 6 - ROV Evidence:} 196 [8.4\%]
    \item \textbf{Category 7 - Strong Evidence:} 358 [15.5\%]
    \label{enum:cats-dp}
\end{enumerate}
}

\ignore{
\begin{figure}[t!]
    \centering
    \includesvg[width=0.5\columnwidth]{figures_svg/categories_dp.svg}
    \caption[Classification Distribution Data-Plane]%
    {The classification results show that non-enforcing ASes are still the largest group on the Internet. However, most ASes in the measurement did not propagate ROA-invalid paths and are classified into higher categories that either indicate ROV enforcement or ROV protection by an upstream. 15.4\% of ASes have strong evidence for ROV enforcement.}
    \label{fig:categories-dp}
\end{figure}}




\subsection{Characterization of ASes with ROV}
Our measurements have good coverage of ASes and are representative. 

{\bf ROV distribution by continent.} The distribution of ROV-enforcing ASes differs significantly by continent. Figure \ref{fig:class-cont} shows that Europe and North America have significantly higher rates of enforcing ASes than the rest of the world. The higher rate of total ROV enforcement in the EU over NA (30.3\% vs. 23.5\%) might be explained by an effort of the European RIR RIPE to advance the deployment of ROV, while the North American RIR ARIN is less active in the promotion of ROV. The graph also shows that the other continents lag behind in the deployment of ROV (30.3\% vs. 11.3\%). 

{\bf ROV distribution by AS type.} ROV protection is not equally distributed among AS types. Figure \ref{fig:categories-types-dp} illustrates that IXPs and stub-ASes have a significantly higher rate of indirect protection or the lack of positive evidence than ISPs. The measurements further indicate that nine Tier-1 providers show direct evidence for ROV enforcement, while only four providers show no signs of depreferencing invalid routes. 

{\bf AS size and ROV enforcement.}  We expect to find ASes that are classified as non-enforcing but only have a tiny percentage of invalid paths, e.g., because one router in an AS does not enforce ROV strictly. To test the impact that such ASes have on our results, we threshold the classification by the number of invalid paths as well as by the routers that forward invalid paths in an AS. We find that 10 / 1065 ASes in categories 1-3 forward less than 10\% invalid paths and have less than 10\% invalid routers, indicating either partial ROV deployment or selective route filtering. The average size of the 10 ASes, measured by the number of IP addresses in their customer cones, is 66.9x larger than the average observed AS, indicating that larger providers are more likely to apply selective filtering or have a partial deployment of ROV. 
The size distribution of ASes by category in Figure \ref{fig:size-by-cat} illustrates the difference introduced by the threshold. The threshold mostly affects large ASes, changing their classification from non-strictly enforcing to strictly enforcing. It also shows that ASes that enforce ROV strictly tend to be larger than non-enforcing ASes, even without application of the threshold.


\begin{figure}[t!]
    \centering
    \includegraphics[width=0.42\textwidth]{figures_pdf/class_by_type_dp.pdf}
    \vspace{-10pt}
    \caption[Classification Distribution Data-Plane]%
    {Category distribution among different AS types.}
     \vspace{-10pt}
    \label{fig:categories-types-dp}
\end{figure}


\subsection{Accuracy of our Results}


{\bf Eliminating errors due to random events.} The room for error was minimized by routing traffic to two prefixes and using inverse configurations for the prefix hijacks. % but a small number of random routing changes might still have influenced the results.

{\bf Eliminating bias in the results.} The distribution of probes and collectors introduces a bias in the results. As the vantage points that run probes and the collectors are located in more modern parts of the Internet, the results primarily represent the technologically advanced Internet regions, e.g., Europe and North America. The smaller number of probes in Africa, Asia, and Oceania therefore limits the generalization of the results. The bias may imply that the deployment over all global ASes might be lower than the found results. To improve the visibility of the data-plane measurements, we placed two announcing servers in regions outside of Europe and North America, one in Brazil and one in Japan. 

{\bf Taking into account peering relationships.} The peering relationships between ASes influence the propagation of BGP routes. For example, a child usually does not forward routes received by its parent. Identifying these relationships is a challenging task as the relations are in constant flux and often more complex than simple child-parent or peer-to-peer peering. We consider the peering relationships between ASes implicitly. We do not construct possible paths based on assumed peering relationships between ASes. Instead, we only considers paths that we observe in our analyses. We thereby ensure that calculations and conclusions are conducted according to paths that are possible and consistent with the complex peering relationships in the real Internet.
 
{\bf Visibility of stub-ASes.} Most stub-ASes on the Internet do not run an Atlas probes and are thus not visible by the measurement. On the other hand, since most stub-ASes also do not operate a relying party validator, the ISP dataset is most relevant for measurements of ROV enforcement. 

\begin{figure}[t!]
    \centering
    \vspace{6pt}
    \includegraphics[width=0.42\textwidth]{figures_pdf/ixp_paths.pdf}
    \vspace{-10pt}
    \caption{ Distribution of paths over IXPs by IXP category. Most observed paths run over IXPs that do not enforce ROV.}
    \vspace{-10pt}
    \label{fig:ixp-paths}
\end{figure}
 
Despite presented limitations, our methodology provides the most accurate results up-to-date, as we combine announcements from multiple ASes in multiple configurations with active measurements and a new, fine grained classification scheme. We provide a comparison of the characteristics of our study to previous approaches in Table \ref{tab:comparison}, Related Work in Section \ref{sc:works}.


\subsection{Validation of our Results}
\label{subsec:vali}
Despite ongoing interest and past discussions on the implementation of a ground-truth for ROV enforcement, no such database exists, as evident in a discussion from 3rd March 2023 on the RIPE mailing list of active experts and operators of RPKI\footnote{\url{https://www.ripe.net/ripe/mail/archives/db-wg/2023-March/007772.html}}. Therefore, validation of ROV measurements is still an open question. As shown in the linked source, the community considers the Cloudflare project as the best available data on ROV enforcement, likely as it is easy to access and work with.

We use multiple approaches to validate our results. The control-plane measurement showed that the results are mostly coherent when looking at BGP updates and data traffic. We further conduct a manual search of online sources by large providers to show that their published enforcement  status is consistent with the classification in our measurement. Additionally, we compare to two other current projects on measuring ROV enforcement, the Cloudflare project, and a project by APNIC \footnote{\url{https://stats.labs.apnic.net/rpki}}.

\textbf{Comparison to public sources.} To validate our results, we look at online publications of AS operators regarding the status of ROV enforcement in their systems. Due to the high amount of observed ASes, we limit the online search to the most significant ASes, the 15 Tier-1 providers. The search is conducted over Google with the keywords \textit{[Operator Name]}, \textit{Route Origin Validation, ROV, and RPKI}. We only consider announcements published up to 3 months after our measurement, as newer publications might indicate a change in deployment after the measurement was finished. This limitation excludes the publication of one operator, which announced ROV implementation six months after our measurements were concluded. Our search finds that all providers that we classify as either strictly enforcing ROV, or as using ROV to strongly depreference invalid routes, have made public posts announcing that they enforce ROV. We did not find any publication by the 4 providers that show no signs of ROV enforcement regarding a running deployment. One operator has published that they are working on ROV validation, but no follow-up publication has been found that announces a running deployment. Further, this operator is also classified as non-enforcing by the Cloudflare project and regularly forwards ROV invalid routes.

\textbf{Comparison to other measurements.} A comparison to other ROV measurements allows us to validate that our results are coherent with observations by other entities and that conclusions on enforcement are sensible. However, comparing to other approaches also has limitations, and a direct comparison on an AS level is only partially possible. We first compare to the Cloudflare measurement, since it uses a similar amount of route injection points, to explain discrepancies in results caused by the differences in the methodologies and limitations of the Cloudflare approach. We then present a comparison to the APNIC measurement, showing general limitations inherent in comparing both approaches with different points of route announcement. Since the APNIC approach is more sophisticated than Cloudflare, we use their results to show how different methodologies can reach differing conclusions on ROV enforcement in some systems, with both conclusions rooted in a consistent behavior of the underlying AS. This observation includes conflicting classifications of two Tier-1 providers.

{\em Comparison to Cloudflare:} Cloudflare makes their current dataset of ROV-enforcing ASes public. We compare the Cloudflare dataset to the ROV-enforcing ASes in our measurements. Our measurements observed 200 of the ASes in the Cloudflare dataset. We see an overlap in classification of 75\%, with 57.5\% being classified identically and 17.5\% classified similarly, e.g., our measurements lack positive evidence to confirm ROV enforcement while Cloudflare indicates strict enforcement or we classify it as strongly depreferencing invalid routes while Cloudflare concludes a non-enforcement. 25\% of ASes are classified differently in our results. 10.5\% are classified as ROV-enforcing in our measurements but non-enforcing in the Cloudflare set, which might indicate that the AS implemented ROV recently and no user updated the status yet, or that the AS applies selective filtering for some announcements. A prominent example of this observation is AS6461, a Tier-1 provider. Further, we see 6\% of ASes classified as ROV-enforcing, which we classify as partially enforcing. The difference is likely caused by either partial deployment, where the user that tested it was by chance protected, or by selective filtering, which again had the user protected but other traffic not protected by ROV. 5\% of ASes are classified as ROV-enforcing by Cloudflare but as completely non-enforcing by our measurements, which may indicate that the AS was upstream protected during the measurement of the user but not fully protected by all upstream providers during our measurements. The remaining 3.5\% of different classifications are attributed to changes in routing architecture as well as to errors by contributors. Thus, while there are differences in the results due to the different methodologies of our approach and Cloudflare, the results are generally coherent.



 % NEW
 
 {\em Comparison to APNIC:} APNIC also makes its measurement results available over a public API.
We thus additionally compare our findings against the results by APNIC.

To avoid conflicting classifications due to changes in the deployment over time, the results are compared on the day of our measurement. Further, since APNIC only provides results averaged out over specific time periods, we use the smallest available period of 7 days to minimize differences due to time differences between the measurements. Lastly, we exclude all ASes in the APNIC measurements that did not complete any measurement in the investigated seven days. This leaves a total overlap of 1231 ASes.

In the overlap, 971 ASes (79\%) are classified coherently in the measurements, i.e., as enforcing, non-enforcing or depreferncing in both measurements. Since the APNIC measurement averages results over seven days and a small number of invalid routes even in ROV-enforcing systems is expected, we classify an AS as enforcing in the APNIC measurement if it has more than 90\% exclusively valid measurements.

260 classifications are conflicting, including observed non-enforcement in two Tier-1 providers. Tier-1 provider AS6461 is classified as ROV-enforcing in our measurement while being classified as not enforcing in APNIC (3.16\% valid paths). Further, the AS1239 is also classified as ROV-enforcing by us while being classified as not strictly enforcing by APNIC (73.47\% valid paths). Both networks have announced publicly that they do enforce ROV \footnote{\url{https://www.sprint.net/policies/rpki}}\footnote{\url{https://seclists.org/nanog/2022/Aug/205}}.

The observed invalid routes over these networks are unlikely to originate from errors in the measurement as they are directly evident in the data. It is thus surprising that the APNIC measurements observe invalid routes despite published ROV enforcement. This observation can be explained by operational practices for implementing ROV in networks. Operators often restrain from enforcing ROV in specific BGP sessions, e.g., with their customers. For example, the online publication of AS6461 includes a statement that routes announced by the operator's customers may be excluded from ROV. While we could not find a similar public statement by AS1239, online sources by other providers indicate that exemptions from ROV enforcement in some sessions are a common practice during the implementation of RPKI \footnote{\url{https://www.gin.ntt.net/support-center/policies-procedures/routing-registry/}}\footnote{\url{https://mailman.nanog.org/pipermail/nanog/2019-February/099501.html}}\footnote{\url{https://seclists.org/nanog/2022/Aug/205}}. The need for such exemptions is also evident in RPKI documentation \footnote{\url{https://rpki.readthedocs.io/en/latest/rpki/using-rpki-data.html}}, and in the standardization of Simplified Local Internet Number Resource Management with the RPKI (SLURM) in [RFC8416]. SLURM allows administrators to override validation results of specific resources for operational purposes, for example, to allow customer routes. Thus, while the observations of the APNIC measurement conflict with the online sources on enforcement by the providers and our measurement results, they are likely caused by an APNIC anycast route injection point announcing an invalid route as a customer of AS6461 and AS1239. 

Another aspect hindering the comparison is that routing policies are usually business secrets. Thus, directly identifying if any AS, including AS6461 and AS1239, only forwarded the routes because a customer announced them is impossible with ROV measurements. However, comparing the conflicting classifications between the APNIC measurement with many injection points and our measurement with three injection points still provides insights into the different views of the Internet that different measurements observe, depending on the methodology used and the injection points.

First, we look at the overall amount of different classifications. The APNIC measurement identified 200 ASes as not enforcing ROV, which we classified as ROV-enforcing. Further, we identify 60 ASes as not enforcing ROV that are classified as enforcing by APNIC. Thus, both measurements see a substantial amount of non-enforcing ASes that are observed to enforce ROV in the other measurement. The APNIC measurement classifies more ASes non-enforcing, which appear enforcing in our measurement than vice versa.
To explain why APNIC sees more non-enforcing ASes than our measurement, we investigate ASes with conflicting classifications apart from ASes with coherent classifications.

For this, we look at the position of ASes on the Internet tree. We expect to see differences in the tree position between ASes classified conflictingly and ASes classified consistently; ASes higher in the tree have more customers and are thus more likely to have one of the route-injecting ASes as a customer. 
The position of an AS in the Internet tree is identified by calculating the minimal amount of hops of every AS to a tree root in the CAIDA Internet graph \footnote{https://snap.stanford.edu/data/as-caida.html}. For example, an AS that is a direct customer of a Tier-1 provider would be considered on the second layer of the Internet tree (1 hop). Further, the grandchild of a Tier-1 provider would be considered on the third layer (2 hops).

On average, we find that ASes observed in both measurements are 1.42 hops away from a Tier-1 provider, i.e., a tree root. Interestingly, both measurements see a noticeable difference between ASes that are classified as ROV-enforcing and ASes that are identified as non-enforcing. On average, ASes classified as enforcing in both measurements are 1.14 hops distant from a Tier-1 provider. This distance increases by 34\% to 1.53 hops for ASes classified as non-enforcing, indicating that ROV-enforcing ASes tend to be higher in the Internet tree than non-enforcing ASes.
The difference in relative position is a sensible observation as networks with routing as a core business focus are incentivized to make direct contracts with Tier-1 providers for better reachability, and to implement ROV to secure their routing. A correlation between the implementation of ROV and a high position in the tree is thus expected.
We further look at the tree position of ASes with conflicting classifications in the two measurements.

ASes that are classified as ROV-enforcing in our measurement but as non-enforcing by APNIC have a 20.3\% higher tree position than ASes that are classified as non-enforcing by both (1.22 vs. 1.53). Similarly, ASes that are classified as non-enforcing by our measurement but as enforcing by APNIC are 11.8\% higher in the tree (1.35 vs. 1.53).
Thus, ASes which show signs of selective route filtering are higher in the tree than ASes with consistent behavior. This is not surprising considering that selective filtering is mostly used to allow invalid customer announcements. ASes higher in the tree generally have more customers in their cone and are thus more likely to have a measurement injection point as a customer. It is thus expected that more classification conflicts are observed in ASes higher in the tree, even though these ASes have higher visibility and are thus easier to classify. 

The impact of selective filtering on the results of a measurement increases with the number of injection points. With more ASes announcing the invalid prefix, the likelihood of an announcing AS in the customer cone of a selectively filtering AS increases. Measurements with different locations and amounts of injection points see a partially different view of ROV enforcement in the Internet. The influence of the different amount of injection points is also indicated in the comparison to APNIC. The APNIC measurement has more injection points and correspondingly has stronger indications for the effects of selectively enforcing ASes than our measurement (20.3\% vs. 11.8\%). This observation indicates that adding more route injection points while reducing false-positives also increases the rate of networks observed as non-enforcing because they apply selective filtering. We conclude that there is a great benefit in applying a path-aware methodology to reduce false-positives instead of simply adding more injection points.


\section{Invalid Paths over Internet Exchanges}\label{sc:routeservers}
Previous work reports that when ASes use ROV-filtering on routeservers at Internet Exchange Points (IXPs)\footnote{An Internet Exchange is a switching platform over which customers exchange peering traffic with each other.}, they are protected from hijacks since invalid routes do not reach them \cite{reuter2018towards,rodday2021revisiting}. This conclusion was derived based on the fact that during the measurements, no invalid paths were sent from the routeservers. IXPs use routeservers to manage peering arrangements for their customer ASes present at an IXP. An AS can connect its border router with a single BGP session to the routeserver, which connects it with separate BGP sessions to the peers. In addition to the administration of peering arrangements, ROV-enforcing routeservers also guarantee protection to the customer ASes against BGP prefix hijacks by dropping invalid routes via ROV filtering at the routeserver. Indeed, the majority of large IXPs are known to enforce ROV. Therefore the IXPs promise to block invalid paths to the ASes peering over them.

In our study, we find that the data-plane paths traversed the address space of 159 different IXPs\footnote{There are ca. 300 active IXPs, of which 70 IXPs with more than 10GB/s peak throughput {\scriptsize{\url{wikipedia.org/wiki/List_of_Internet_exchange_points_by_size}}}.}, including the most significant European IXPs DE-CIX Frankfurt (on 3000 paths) and Amsterdam Internet Exchange (on 1300 paths).
Due to the prevalence of IXPs on Internet paths, we explore their role in blocking the propagation of invalid routes with ROV filtering at the routeservers. We find that the ROV enforcement at the routeservers generally does not block the global propagation of invalid routes. In this section, we explain our study and the factors that limit the security effect of routeservers. A detailed analysis of the impact of routeservers is in Section \ref{sc:invalid:paths}.

{\bf Leakage of invalid routes at IXPs.} We analyze the data-plane paths to investigate which IXPs enforce ROV. Since the number of paths over IXPs is not equally distributed, we look at the number of paths over IXPs by category in Figure \ref{fig:ixp-paths}. The graph shows that most paths run over IXPs that are classified as either non-enforcing or weakly de-preferencing invalid routes, which is surprising as large IXPs are known to enforce ROV. It would thus be expected that they are classified as strongly de-preferencing invalid routes.

{\bf Direct peerings propagate more routes.} We explain this observation by taking the five largest IXPs in our measurements as an example: DE-CIX Frankfurt, AMS-IX, Milan IX, NIX.CZ, and EQUINIX Singapore. Manual investigation of the five IXPs shows that all their routeservers implement ROV \cite{eqRPKI, aixRPKI, mixRPKI, nixRPKI, decixRPKI}, and the looking-glasses confirm that the routeservers drop invalid BGP announcements that conflict with ROAs. 

The observation that the routeservers of these IXPs do not propagate invalid routes leads to the conclusion that all invalid routes over their address space must have been propagated over direct sessions and not the routeserver. We thus approximate that all connections over the IXP that only propagated valid paths run over the routeserver.
Applying the approximation to the results shows that most peerings we observe in measurement paths over IXP address space, only forward valid paths and are thus considered routeserver connections. The percentage of approximated routeserver peerings is plotted in Figure \ref{fig:path-over-val-peer-paths}. While our study shows that most peerings only forward valid updates, the amount of paths in our measurement over routeserver peerings is lower than expected.
{\em We find that the non-routeserver peerings, on average, propagate more paths than the routeserver peerings}. 
Therefore, in all the top five IXPs, the total number of paths learned over direct peerings is equal to or larger than over the routeserver. The average direct peering session we observed propagates 3.4x more paths than sessions over a routeserver in the top five IXPs and 2.9x more paths averaged over all observed IXPs.

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.85\columnwidth]{figures_pdf/peerings.pdf}
    \vspace{-10pt}
    \caption{Percentage of connections over IXPs that only forwarded valid paths \& percentage of IXP paths that only use these valid peerings.}
    \label{fig:path-over-val-peer-paths}
\end{figure}


The paths learned over direct peerings are not protected by ROV in the routeserver. As a result, a significant fraction of invalid paths traverse the top five IXPs despite their ROV enforcement. We confirm our analysis with a measurement of invalid path propagation over the IXPs and find that all the five IXPs allow a significant percentage of invalid traffic over their IP space: DE-CIX Frankfurt has 33.5\% invalid paths (1000 / 2982), Amsterdam IX has 27.4\% invalid paths (342 / 1246), Milan IX has  27.9\% invalid paths (63 / 226), NIX.CZ has 32.3\% invalid paths (62 / 192), and Equinix Singapore has 40.3\% invalid paths (77 / 191).

{\bf IXPs do not block hijacks.} Our analysis shows that although routeserver ROV protects most peering connections over the IXP, it does not protect the majority of paths that traverse IXP address space. Direct peering sessions circumvent the security impact of ROV in IXPs because they allow invalid updates to leak over the IXP address space and propagate to different parts of the Internet. IXPs cannot prevent leakage of invalid paths because they do not have control-plane influence over the direct session traffic routed through their IP space. The existence of many direct peering sessions causes the ASes not to be protected since they allow the propagation of invalid announcements despite the ROV filtering at the routeserver. 

{\bf Why direct peering sessions instead of routeserver?} Many large providers create direct peering sessions or have historical relationships with other connected ASes at the IXP. In addition, the routeservers are a relatively new service, while most ASes already have existing business agreements. Finally, a significant aspect is that with the routeservers, the ASes lose control over their routing configurations and cannot have comparable fine-grained control over their path policies. For instance, the ASes need to rely on the preferences of the routserver to choose the optimal route, potentially resulting in non-optimal routing for a connected AS.