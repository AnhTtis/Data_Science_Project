\section{Conclusion}
Our proposed \textit{\acronym} is capable of efficiently building a topological map by metric-free exploration to represent an environment. It entirely works in an image feature space to explore a new environment by jointly hallucinating the next step feature and predicting the appropriate action that best moves the agent to the feature. It is simple and lightweight as it just requires RGB images and the model size is small. It is trained via deeply-supervised imitation learning where the expert demonstration is easy to acquire and scale up. We show its strong zero-shot sim2sim and sim2real generalization capability by experiments in both large-scale and photo-realistic simulation environments and real-world environments. Future works include designing more elaborate historic memory modules and involving multi-modality sensors to further improve the performance of visual exploration and navigation.