\section{Introduction}
Mobile agents often create maps to represent their surrounding environments\,\cite{slam_summary}. Typically, such a map is either topological or metrical\,(including hybrid ones). We consider a topological map to be metric-free, which means it does not explicitly store global/relative position/orientation information with measurable geometrical accuracy~\cite{kuipers1991robot,topomap_sonarvision}. Instead, it is a graph that stores local sensor observations, such as RGB images, as graph nodes and the spatial neighborhood structure (and often navigation actions) as graph edges that connects observations taken from nearby locations. While metric maps are often reconstructed by optimizing geometric constraints between landmarks and sensor poses from classic simultaneous localization and mapping (SLAM), topological maps have recently attracted attention in visual navigation tasks due to the simplicity, flexibility, scalability, and interpretability~\cite{savinov2018semiparametric,neural_topomap,nav_maze,VisualGraphMem_ICCV21,learn2explore_iclr20,TSGM}.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.98\linewidth]{teasing_fig.pdf}
    \vspace{-2mm}
    \caption{\textit{\acronym{}} illustration: it is metric-free and plans in the feature space. It jointly hallucinates the next step feature to visit and predicts the appropriate action taking the agent to the hallucinated feature. We show that \textit{\acronym{}} is efficient in simulation environment and possesses strong zero-shot sim2real capability in exploring real-world environment.}
    \label{fig:teasingfig}
    \vspace{-4mm}
\end{figure}

There are two robot exploration methods to collect data to construct a topological map in a new environment. 
The first and also the simplest one is to let the agent explore the new environment through metric-free \emph{random walk}, after which the topological map could be built by projecting the recorded observations into a feature space and adding graph edges from temporal connections and loop closures~\cite{savinov2018semiparametric}. However random walking is very inefficient especially in large or complex rooms, leading to repetitive visits to the nearby local areas. The other way is to design a navigation policy that controls the agent to more effectively explore the area while creating the map. It is known as \emph{active SLAM} and often involves some metric information (e.g., distance and orientation) from either additional input modalities~\cite{leung2006active,learn2explore_iclr20} or intermediate estimations~\cite{neural_topomap}. 
Could we combine the merits of the two ways by finding \emph{an exploration policy that (1) is metric-free thus simple and lightweight in hardware and model complexity, and (2) exhibits strong generalization ability to explore unknown environment} for topological map construction?

To achieve this objective, we propose \textit{\acronym{}} (see Fig.~\ref{fig:teasingfig}), a new framework to achieve metric-free efficient exploration by imitating easy-to-access expert exploration demonstrations~\cite{imitation_learning}. The expert demonstration is a sequence of image and action pairs taken on a route that efficiently covers a new environment. This could come from either an \textit{oracle policy} having full access to virtual environments or simply a \textit{human expert} in the real world.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.80\linewidth]{overview.pdf}
    \vspace{-3mm}
    \caption{\textbf{Workflow of \textit{\acronym{}} and the following topological mapping.} The agent explores a novel environment by task and motion planning in feature space~(left); The following topological mapping completes the initial topological map by adding new edges via VPR and \textit{ActionAssigner}. }
    \label{fig:general_overview}
    \vspace{-5mm}
\end{figure*}

\textit{\acronym{}} follows the task and motion planning formalism~(TAMP) and entirely works in image feature space.
Its task planner, a two-layer LSTM~\cite{LSTM} network, conceives the next best goal feature to be explored by hallucination from the latest sequence of observed image features. Its motion planner, a simple multi-layer perceptron~(MLP), fuses the current and the hallucinated features to predict the best action moving the agent toward the hallucinated feature. Both the two planners are trained jointly by deep supervision~\cite{deeply_supervised_nets} of per-step feature hallucination and action prediction.
The trained \textit{\acronym{}} are deployed by iteratively calling the task and the motion planners to predict the next action. 



\textit{\acronym{}} is designed for active topological mapping of unknown environments. During each exploration step, the topological map is updated by adding the latest image observation as a new node and the action on the new edge. We further adopt VLAD-based~\cite{VLAD} visual place recognition (VPR)~\cite{VPR_survey} for loop closing, adding additional new edges between image pairs that are temporally disjoint but spatially close. In the meantime, we train an \emph{ActionAssigner} to assign each VPR-added new edge with corresponding actions that move the agent from one node to the other. We call the above process as \textit{Topological Mapping}~(see Fig.~\ref{fig:general_overview}). Finally, the completed topological map efficiently represents environment connectivity and traversability. We can apply it to various robot tasks like visual navigation~\cite{savinov2018semiparametric}.


We demonstrate the advantage of \textit{\acronym{}} on both visual \textbf{exploration} and \textbf{navigation} tasks. We train it on Gibson~\cite{gibson_env} simulation dataset and test its \textbf{exploration} efficiency on both Gibson validation and MP3D~\cite{Matterport3D} dataset~(for zero-shot sim2sim generalization test). We further show its strong zero-shot sim2real generalization capability by directly deploying the Gibson-trained \textit{\acronym{}} to explore a real-world environment. For the navigation task, we run experiments on both Gibson~\cite{gibson_env} and MP3D~\cite{Matterport3D} dataset with the topological map built by \textit{\acronym{}}. 

In summary, our contributions are listed as follows:

\begin{itemize}
\item We propose \textit{\acronym{}} for efficient metric-free visual exploration based on task and motion planning entirely in an image feature space.

\item We train \textit{\acronym{}} via deeply-supervised imitation through joint feature hallucination and action prediction, whose importance is shown in our ablation study.

\item Through experiments on both exploration and navigation tasks, we show the efficiency and strong sim2sim/sim2real generalization capability of \textit{\acronym{}}.
\end{itemize}
