\section{Characterization of Strong Duality}%: The Discounted Cost Criterion}
\label{sec:strongduality}
To solve \eqref{eq:macpomdp}, let us define the Lagrangian function $L : \uspace\times \mcl{Y} \mapsto \mbb{R} \cup \{ \infty \}$ as follows.
\begin{align*}
\lags{u}{\lambda} &= \lag{u}{\lambda} 
\defeq \fullccosts{u} + \dotp{\lambda}{\fulldcosts{u} -\constraintv}\\
&= \fullccosts{u} + \sum_{k=1}^{K} \lambda_k \l(D_{k}\l(u\r) - \constraintv_k \r)
,\numberthis\label{eq:lagrangian}
\end{align*}
Here, $\mcl{Y} \defeq \{ \lambda \in \mbb{R}^K : \lambda \ge 0\}$ is the set of tuples of $K$ non-negative real-numbers, each commonly known as a Lagrange-multiplier. Our main result shows that the the solution $\udl{C}$ satisfies
\begin{align*}
\optcosts &= \infsup{u\in \uspace }{\lambda\in \mcl{Y}} \lags{u}{\lambda}
,\numberthis\label{eq:optccost:infsup}
\end{align*}
and that the inf and sup can be interchanged, i.e.,
\begin{align*}
\optcosts &= \supinf{\lambda\in \mcl{Y}}{u\in \uspace } \lags{u}{\lambda}
.\numberthis\label{eq:optccost:supinf}
\end{align*}

\begin{thm}[Strong Duality]\label{thm:strongduality}
Under Assumption \ref{assmp:boundedcosts}, the following statements hold.
\begin{enumerate}
\item[(a)] The optimal value satisfies 
\begin{align*}
\optcosts = \infsup{u\in\uspace}{\lambda\in \mcl{Y}} \lags{u}{\lambda}
.\numberthis   
\end{align*}
\item[(b)] A policy-profile $u^\star \in \uspace$ is optimal if and only if $\optcosts = \sup_{\lambda\in \mcl{Y}} \lags{u^\star}{\lambda}$.
\item[(c)] Strong duality holds for \eqref{eq:macpomdp}, i.e.,
\begin{align*}
\optcosts &= \infsup{u\in\uspace}{\lambda\in \mcl{Y}} \lags{u}{\lambda}
= \supinf{\lambda\in \mcl{Y}}{u\in\uspace} \lags{u}{\lambda}
.\numberthis
\end{align*}
Moreover, there exists a $u^\star \in \uspace$ such that $\optcosts = \sup_{\lambda \in \mcl{Y}} \lags{u^\star}{\lambda} $ and $u^\star$ is optimal for \eqref{eq:macpomdp}. In particular, if Assumption \ref{assmp:slatercondition} holds, then there also exists $\lambda^\star \in \mcl{Y}$ such that the following saddle-point condition holds for all $(u,\lambda)\in \uspace \times \mcl{Y}$,
\begin{align*}
\lags{u^\star}{\lambda} \le \lags{u^\star}{\lambda^\star} = \optcosts \le \lags{u}{\lambda^\star}.
\numberthis\label{eq:saddlepointconditions} 
\end{align*}
i.e., $u^\star$ minimizes $\lags{\cdot}{\lambda^\star}$ and $\lambda^\star$ maximizes $\lags{u^\star}{\cdot}$. In addition to this, the primal dual pair $\l( u^\star, \lambda^\star \r)$ satisfies the complementary-slackness condition:
\begin{align*}\label{eq:compslack}
    \dotp{\lambda^\star}{\fulldcosts{u^\star}-\constraintv} = 0.\numberthis
\end{align*}
\end{enumerate}
\end{thm}

\begin{proof}
\begin{enumerate}
\item[(a)] If $u \in \uspace$ is feasible (i.e., it satisfies $\fulldcosts{u} \le \constraintv$), then the $\sup$ is obtained by choosing $\lambda = 0$, so
\begin{align*}
\sup_{\lambda\in\mcl{Y}} \lags{u}{\lambda} &= \fullccosts{u}.
\numberthis\label{eq:ufeasible}
\end{align*}
If $u \in \uspace$ is not feasible, then %it is easily seen that
\begin{align*}
\sup_{\lambda\in \mcl{Y}} \lags{u}{\lambda} = \infty.
\numberthis\label{eq:unotfeasible}
\end{align*}
Indeed, suppose WLOG that the $k^{th}$ constraint is violated, i.e., $\fulldkcosts{k}{u} > \constraintv_k$, then $\infty$ can be obtained by choosing $\lambda_k$ arbitrarily large and setting other $\lambda_k$'s to 0.

From \eqref{eq:ufeasible}, \eqref{eq:unotfeasible}, and our convention that $\optcosts = \infty$ whenever the feasible-set is empty, it follows that
\begin{align*}
\optcosts = \infsup{u\in\uspace}{\lambda\in\mcl{Y} } \lags{u}{\lambda}.
\numberthis\label{eq:fullccostisinfsup}
\end{align*}

\item[(b)] By our convention on the value of $\optcosts$ (when there is no feasible policy-profile), $u^\star$ is optimal if and only if $\fullccosts{u^\star} = \optcosts $, i.e., $\sup_{\lambda\in \mcl{Y} } \lags{u^\star}{\lambda} = \optcosts$.

\item[(c)] To establish strong duality, we use 
%Sion's Minimax Theorem (see Proposition \ref{prop:sionminimax}) 
Proposition \ref{prop:sionminimax} which requires $\uspace$ and $\mcl{Y}$ to be convex\footnote{Convexity is a set property rather than a topological property. In the rest of the paper, by a ``convex topological space'', we shall mean convexity of the set on which the topology is defined.} topological spaces (with $\uspace$ being compact also). It is clear that $\mcl{Y}$ is convex and we can endow it with the usual subspace topology of $\mbb{R}^K$. 
%For $\uspace$, however, we do not as yet have a topology. Therefore, our first order of business is to endow $\uspace$ with a suitable topology in which it is compact. 
For $\uspace$ however, we need to endow it with a suitable topology in which it is compact and then also show that it is convex. To achieve compactness, we can use the finiteness of action-space $\anspace{n} $ and the countability of observation-space $\ospace$ to associate $\uspace$ with a product of compact sets that are parameterized by (countable number of) all possible histories. Tychonoff's theorem (see Proposition \ref{prop:tychonoff}) then helps achieve compactness under the product topology. (Convexity comes trivially). Now, we make this idea precise. For $n\in[0,N]_{\mbb{Z}}$, let $\hstnspace{t}{n}$ denote the set of all possible realizations of $\Hstn{t}{n}$. Then, by countability of observation and action spaces, the sets
\begin{align}
\begin{split}\label{eq:hthnandh}
\hstspace{t} &\defeq \prod_{n=0}^{N} \hstnspace{t}{n},\\
\hsnspace{n} &\defeq \bigcup_{t= 1}^{\infty} \hstnspace{t}{0} \times \hstnspace{t}{n}, \text{ and }\\
\hsspace &\defeq \bigcup_{t=1}^{\infty} \hstspace{t},
\end{split}
\end{align}
are countable. Here, $\hstspace{t}$ is the set of all possible joint-histories at time $t$, $\hsnspace{n}$ is the set of all possible histories of agent $n$, and $\hsspace$ is the set of all possible joint-histories. With this in mind, one observes that $\uspace$ is in one-to-one correspondence with the set $\xuspace \defeq \prod_{n=1}^{N} \xuspacen{n}$, where
\begin{align*}
\xuspacen{n} \defeq \prod_{h \in \hsnspace{n}} \m{\anspace{n}; h},\numberthis\label{eq:xuspace}
\end{align*}
where $\m{\anspace{n}; h}$ is a copy of $\m{\anspace{n}}$ dedicated for agent-$n$'s history $h$. For example, a given policy $u$ would correspond to a point $x\in \xuspace$ such that $x_{n, \l( \hstn{h}{t}{0}, \hstn{h}{t}{n}\r) } = \utn{u}{t}{n} \l( \cdot | \hstn{h}{t}{0}, \hstn{h}{t}{n} \r) $, and similarly, vice versa. 

\hspace{5pt} Now, given $\anspace{n}$ is a complete separable (compact) metric space, by Prokhorov's Theorem (see Proposition \ref{prop:prokhorov}), each $\m{\anspace{n}; h}$ is a compact (and convex\footnote{Convexity of $\m{\anspace{n}}$ is trivial.}) metric space (with the topology of weak-convergence). Therefore, endowing $\xuspacen{n}$ and $\xuspace$ with the product topology makes each a compact (and convex) metric space via Tychonoff's theorem (see Proposition \ref{prop:tychonoff}), which is also metrizable (via Proposition \ref{prop:metrizability}). Given $\uspacen{n}$ and $\uspace$ are respectively identifiable with $\xuspacen{n}$ and $\xuspace$, \textbf{from now onwards, we assume that $\uspacen{n}$ and $\uspace$ have the same topology as that of $\xuspacen{n}$ and $\xuspace$ respectively}. Thus, henceforth, we will consider $C$, $D_k$, and $L$ as functions on topological spaces. Furthermore, since we have been able to show $\uspacen{n}$'s and $\uspace$ as compact metric spaces (hence complete and separable as well), we can also define $\borel{\uspacen{n}}$, $\borel{\uspace} = \otimes_{n=1}^{N} \borel{\uspacen{n}}$\footnote{For separable metric spaces $\mcl{W}_1, \mcl{W}_2, \ldots$, $\borel{\mcl{W}_1 \times \mcl{W}_2 \times \ldots } = \borel{\mcl{W}_1} \otimes \borel{\mcl{W}_2} \otimes \ldots$. See \cite{kallenberg2002foundations}[Lemma 1.2].}, $\m{\uspacen{n}}$, and $\m{\uspace}$, where the last two are compact (and convex) metrizable spaces by Prokhorov's theorem (see Proposition \ref{prop:prokhorov}). 

\hspace{5pt} To establish part (c), it will be helpful to work with (decentralized) mixtures of behavioral policy-profiles -- wherein each agent first uses a measure $\mun{n} \in \m{\uspacen{n}} $ to choose its policy-profile $\un{u}{n}$ and then proceeds with it from time 1 onward. We denote this enlarged space by $\uspacemix \defeq \prod_{n=1}^{N} \m{\uspacen{n}}$, whose typical element, denoted by $\mu \defeq \mymathop{\times}_{n=1}^{N} \mun{n} $, is a factorized measure on $\uspace$, i.e., $\mun{n}\in \m{\uspacen{n}}$. Now, we can extend the definition of the Lagrangian function to $\uspacemix$ by defining $\ov{L} : \uspacemix \times \mcl{Y} \ra \mbb{R} \cup \{ \infty\}$, where
\begin{align*}
\lagsmix{\mu}{\lambda} &= \lagmix{\mu}{\lambda} 
\defeq \mbb{E}^{(\mu)} \l[ \lags{u}{\lambda} \r]
,\numberthis\label{eq:lagrangianmix}    
\end{align*}
In Lemma \ref{lem:dominance}, it is shown that any $\mu \in \uspacemix$ can be replicated by a behavioral policy-policy $u \in \uspace$. Corollary \ref{cor:lbar_and_l} then shows that
\begin{align}
\begin{split}\label{eq:lag_and_lagmix}
    \infsup{u\in\uspace}{\lambda\in\mcl{Y}} \lags{u}{\lambda} &= \infsup{\mu \in\uspacemix}{\lambda\in\mcl{Y}} \lagsmix{\mu}{\lambda}, \text{ and } \\
    \supinf{\lambda\in\mcl{Y}}{u\in\uspace} \lags{u}{\lambda} &= \supinf{\lambda\in\mcl{Y}}{u\in\uspacemix} \lagsmix{\mu}{\lambda}.
    \end{split}
\end{align}
In light of \eqref{eq:lag_and_lagmix}, it suffices to prove part (c) for $\ov{L}$. By definition, $\ov{L}$ is affine and thus trivially concave in $\lambda$. Proposition \ref{prop:integral_linearity} implies that $\ov{L}$ is convex in $\mu$ and Lemma \ref{lem:lsc2} shows that $\ov{L}$ is lower semi-continuous\footnote{For definition of lower semi-continuity, see Definition \ref{dfn:lsc}.} in $\mu$. From 
%Sion's Minimax Theorem (Proposition \ref{prop:sionminimax}), 
Proposition \ref{prop:sionminimax}, it then follows that
\begin{align*}
\infsup{u\in\uspacemix}{\lambda\in \mcl{Y}} \lagsmix{u}{\lambda} = \supinf{\lambda\in \mcl{Y}}{\uspacemix} \lagsmix{u}{\lambda},
\end{align*}
and that there exists $\mu^\star \in \uspacemix$ such that
\begin{align*}
\sup_{\lambda\in \mcl{Y}} \lags{\mu^\star}{\lambda} = \infsup{u\in\uspacemix}{\lambda\in \mcl{Y}} \lagsmix{u}{\lambda}.
\end{align*}
The optimality of $\mu^\star$ is implied by parts (b) and (a) and the final claim (using Assumption \ref{assmp:slatercondition}) follows from Lagrange-multiplier theory.
\end{enumerate}
This concludes the proof.
\end{proof}


\begin{lem}[Lower Semi-Continuity of $\ov{L}$ on $\uspacemix$]\label{lem:lsc2}
    Under Assumption \ref{assmp:boundedcosts}, $\ov{L}$ is lower semi-continuous on $\uspacemix$.
\end{lem}
\begin{proof}
    Fix $\lambda\in\mcl{Y}$ and $\mu\in \uspacemix$. Let $\l\{ \mu_i \r\}_{i=1}^{\infty}$ be a sequence of (factorized) measures that converges (weakly) to $\mu$ in $\uspacemix \subseteq \m{\uspace}$. Since $\uspacemix$ is closed in $\m{\uspace}$, $\l\{ \mu_i \r\}_{i=1}^{\infty}$ also converges (weakly) to $\mu$ in $ \m{\uspace}$. We want to show
    \begin{align*}
        \liminf_{i\ra\infty} \E{\mu_i}{P_1} \l[  \lags{u}{\lambda} \r] \ge \E{\mu}{P_1} \l[  \lags{u}{\lambda} \r].
    \end{align*}
    By Lemma \ref{lem:lsc}, $L$ is (point-wise) lower semi-continuous on $\uspace$. Therefore, Proposition \ref{prop:lsc} applies on $\m{\uspace}$ and the above inequality follows.
\end{proof}

\begin{lem}[Lower Semi-Continuity of $L$ on $\uspace$]\label{lem:lsc}
Under Assumption \ref{assmp:boundedcosts}, the functions $C$ and $D_k$'s are lower semi-continuous on $\uspace$. Hence, $L$ is lower semi-continuous on $\uspace$. 
\end{lem}
\begin{proof}
We will prove the statement for $C$. The proof of lower semi-continuity of $D_k$'s is similar. For brevity, let 
\begin{align*}
\pruphsts{u}{t}{\hst{h}{t}, \at{t}} &= \pruphst{u}{t}{\hst{h}{t}, \at{t}} \defeq \prup{u}{P_1}\l(\Hst{t} = \hst{h}{t}, \At{t} = \at{t}\r),
\\
\zuphsts{u}{t}{\hst{h}{t}, \at{t}} &= \zuphst{u}{t}{\hst{h}{t}, \at{t}}\\
&\hspace{-25pt} \defeq \pruphsts{u}{t}{\hst{h}{t}, \at{t}} \mbb{E}_{P_1}\l[ \cCost | \Hst{t} = \hst{h}{t}, \At{t} = \at{t} \r].
\end{align*}
Then,
\begin{align*}
\fullccosts{u} &= \E{u}{P_1}\l[ \sum_{t=1}^{\infty} \alpha^{t-1} c(S_t, A_t) \r] \\
&= \E{u}{P_1}\l[ \sum_{t=1}^{\infty} \alpha^{t-1} \l( c(S_t, A_t) - \udl{c} \r) \r] + \sum_{t=1}^{\infty} \alpha^{t-1} \udl{c}\\
&\labelrel{=}{eqr:cp1u:a} \sum_{t=1}^{\infty} \alpha^{t-1} \E{u}{P_1} \l[ c(S_t, A_t) - \udl{c} \r] + \sum_{t=1}^{\infty} \alpha^{t-1} \udl{c}\\
&= \sum_{t=1}^{\infty} \alpha^{t-1} \E{u}{P_1} \l[ c(S_t, A_t) \r] \\
&\labelrel{=}{eqr:cp1u:b} \sum_{t=1}^{\infty} \alpha^{t-1} \E{u}{P_1} \l[ \mbb{E}_{P_1} \l[ c(S_t, A_t) \r] | \Hst{t}, \At{t} \r]\\
&= \sum_{t=1}^{\infty} \sum_{\hst{h}{t} \in \hstspace{t}} \sum_{\at{t}\in \aspace} \alpha^{t-1} \zuphsts{u}{t}{\hst{h}{t}, \at{t}}.
\end{align*}
Here, \eqref{eqr:cp1u:a} follows from applying the Monotone-Convergence Theorem to the (increasing non-negative) sequence $\{ \sum_{t=1}^{i} \alpha^{t-1} \l( c\l( \Stt{t}, \At{t} \r) - \udl{c} \r) \}_{i=1}^{\infty}$ (see Proposition \ref{prop:mct}); and \eqref{eqr:cp1u:b} uses the tower property of conditional expectation.

Let $\l\{ \useq{i}{u} \r\}_{i=1}^{\infty}$ be a sequence in $\uspace$ that converges to $u$. By Fatou's Lemma (see Proposition \ref{prop:fatou}),
\begin{align*}
\liminf_{i\ra \infty} \fullccosts{\useq{i}{u}} \ge \sum_{t=1}^{\infty} \sum_{\hst{h}{t} \in \hstspace{t}} \sum_{\at{t}\in \aspace} \alpha^{t-1} \liminf_{i\ra\infty} \zuphsts{\useq{i}{u}}{t}{\hst{h}{t}, \at{t}}.\numberthis\label{eq:step1}
\end{align*}
Following Lemma \ref{lem:puth}, $\pruphsts{\useq{i}{u}}{t}{\hst{h}{t}, \at{t}} $ converges to $\pruphsts{u}{t}{\hst{h}{t}, \at{t}}$. Therefore,
\begin{align*}
\lim_{i\ra\infty} \zuphsts{\useq{i}{u}}{t}{\hst{h}{t}, \at{t}} = \zuphsts{u}{t}{\hst{h}{t}, \at{t}}.\numberthis\label{eq:step2}
\end{align*}
From \eqref{eq:step1} and \eqref{eq:step2}, it follows that
\begin{align*}
\liminf_{i\ra \infty} \fullccosts{\useq{i}{u}} \ge \fullccosts{u},
\end{align*}
which establishes the lower semi-continuity of $\fullccosts{u}$. 
\end{proof}