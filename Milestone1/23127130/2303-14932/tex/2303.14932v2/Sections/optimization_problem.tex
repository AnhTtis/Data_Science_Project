\section{Optimization Problem}\label{sec:optimization_problem}
To formulate the MA-C-POMDP optimization problem, we first need to give a suitable topology to the space of behavioral policy-profiles, in particular, one in which it is compact and convex.\footnote{Convexity is a set property rather than a topological property. In the rest of the paper, by a ``convex topological space'', we mean convexity of the set on which the topology is defined.} To this end, 
we use the finiteness of the action space $\anspace{n} $ and the countability of the joint-observation space $\ospace$ to associate $\uspace$ with a product of compact sets that are parameterized by (countable number of) all possible histories. Tychonoff's theorem 
% (see~\cite{khan23}[Proposition 4])
(see Proposition \ref{prop:tychonoff} )
then helps achieve compactness under the product topology. (Convexity comes trivially). Now, we make this idea precise. For $t\in \mbb{N}$ and $n\in[0,N]_{\mbb{Z}}$, let $\hstnspace{t}{n}$ denote the set of all possible realizations of $\Hstn{t}{n}$. Then, by countability of observation and action spaces, the sets
\begin{align}
\begin{split}\label{eq:hthnandh}
\hstspace{t} &\defeq \prod_{n=0}^{N} \hstnspace{t}{n},\\
\hsnspace{n} &\defeq \bigcup_{t= 1}^{\infty} \hstnspace{t}{0} \times \hstnspace{t}{n}, \text{ and }\\
\hsspace &\defeq \bigcup_{t=1}^{\infty} \hstspace{t},
\end{split}
\end{align}
are countable. Here, $\hstspace{t}$ is the set of all possible joint-histories at time $t$, $\hsnspace{n}$ is the set of all possible histories of agent $n$, and $\hsspace$ is the set of all possible joint-histories. With this in mind, one observes that $\uspace$ is in one-to-one correspondence with the set $\xuspace \defeq \prod_{n=1}^{N} \xuspacen{n}$, where
\begin{align*}
\xuspacen{n} \defeq \prod_{h \in \hsnspace{n}} \m{\anspace{n}; h},\numberthis\label{eq:xuspace}
\end{align*}
and $\m{\anspace{n}; h}$\footnote{$M_1(\cdot)$ denotes the set of all probability measures on $\cdot$.} is a copy of $\m{\anspace{n}}$ dedicated for agent-$n$'s history $h$. For example, a given policy $u$ would correspond to a point $x\in \xuspace$ such that $x_{n, \l( \hstn{h}{t}{0}, \hstn{h}{t}{n}\r) } = \utn{u}{t}{n} \l( \cdot | \hstn{h}{t}{0}, \hstn{h}{t}{n} \r) $, and similarly, vice versa. 

\hspace{5pt} Since $\anspace{n}$ is a complete separable (compact) metric space, by Prokhorov's Theorem 
% (see~\cite{khan23}[Proposition 6]),
(see Proposition \ref{prop:prokhorov}),
each $\m{\anspace{n}; h}$ is a compact (and convex\footnote{Convexity of $\m{\anspace{n}}$ is trivial.}) metric space (with the topology of weak-convergence). Therefore, endowing $\xuspacen{n}$ and $\xuspace$ with the product topology makes each a compact (and convex) metric space via Tychonoff's theorem (see 
% \cite{khan23}[Proposition 4] 
Proposition \ref{prop:tychonoff}), 
which is also metrizable 
%(via~\cite{khan23}[Proposition 6])
via Proposition \ref{prop:metrizability}. Given the one-to-one correspondence, \textbf{from now onward, we assume that $\uspacen{n}$ and $\uspace$ have the same topology as that of $\xuspacen{n}$ and $\xuspace$ respectively}. Henceforth, we will consider $C$ and $D_k$'s as functions on topological spaces. Furthermore, since $\uspace$ has been shown to be a compact metric space (hence, also complete and separable), we can also define $\borel{\uspace} = \otimes_{n=1}^{N} \borel{\uspacen{n}}$\footnote{For separable metric spaces $\mcl{W}_1, \mcl{W}_2, \ldots$, $\borel{\mcl{W}_1 \times \mcl{W}_2 \times \ldots } = \borel{\mcl{W}_1} \otimes \borel{\mcl{W}_2} \otimes \ldots$. See \cite{kallenberg2002foundations}[Lemma 1.2].}, and $\m{\uspace}$, where $\m{\uspace}$ is compact (and convex) metrizable space by Prokhorov's theorem 
% (see~\cite{khan23}[Proposition 6]).
(see Proposition \ref{prop:prokhorov}).

It will be helpful to work with mixtures of behavioral policy-profiles -- wherein the team first uses a measure $\mu \in M_1(\uspace) $ to choose its policy-profile $\policy \in \uspace$ and then proceeds with it from time 1 onward. Under this setup, the policy-profile chosen collectively by the agents becomes a random object, and we extend the definitions of $C$ and $D$ to $\wh{C} : \m{\uspace} \ra \mbb{R} \cup \{\infty\}$ and $\wh{D}: \m{\uspace} \ra \mbb{R}^K$ as follows:
\begin{align}
\begin{split}\label{eq:lagrangianmix}
    \fullccostsmix{\mu} &= \fullccostmix{\mu} \defeq \E{U\sim \mu}{} \l[ C(U) \r], \text{and} \\
    \wh{D} (\mu) &= \fulldcostmix{\mu} \defeq \E{U\sim \mu}{} \l[ D(U) \r].
    \end{split}
\end{align}
The goal of the agents is to work cooperatively to solve the following constrained optimization problem.
\begin{align}
\begin{split}
 &\text{minimize } \fullccostsmix{\mu} \notag\\
 &\text{subject to } \mu \in \m{\uspace} \text{ and } \fulldcostsmix{\mu} \le \constraintv.
\end{split}
 \Bigg\}\tag{\textit{MA-C-POMDP}} \label{eq:macpomdp}
\end{align}
Here, $\constraintv$ is a fixed $K$-dimensional real-valued vector. We refer to the solution of \eqref{eq:macpomdp} as its \emph{optimal value} and denote it by $\optcosts = \optcost$. In particular, if the set of feasible mixtures is empty, we set $\optcosts$ to $\infty$, and, with slight abuse of terminology, we will consider any mixture in $\m{\uspace}$ to be optimal.

\hspace{5pt} The following assumption about feasibility of \eqref{eq:macpomdp} will be used in one of the parts of Theorem \ref{thm:strongduality}.
\begin{assumption}[Slater's Condition]\label{assmp:slatercondition}
There exists a mixture $\mu \in \m{\uspace}$ and $\zeta > 0$ for which
\begin{align*}
    \fulldcosts{\mu} \le \constraintv - \zeta1.\numberthis\label{eq:slatercondition} 
\end{align*}
\end{assumption}