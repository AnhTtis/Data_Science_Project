\section{Characterization of Strong Duality}\label{sec:strongduality}
To solve \eqref{eq:macpomdp}, we define the Lagrangian function $\wh{L} : \m{\uspace} \times \mcl{Y} \ra \mbb{R} \cup \{\infty\} $ as follows.
\begin{align*}
\lagsmix{\mu}{\lambda} &= \lagmix{\mu}{\lambda} 
\defeq \wh{C}(\mu) + \dotp{\lambda}{\wh{D}(\mu) -\constraintv}\\
&= \E{U\sim \mu}{} \underbrace{\l[ C(U) + \dotp{\lambda}{D(U) - \constraintv}  \r]}_{\defeq \lag{U}{\lambda}=\lags{U}{\lambda}}.
\numberthis\label{eq:lagrangian}
\end{align*}
Here, $\mcl{Y} \defeq \{ \lambda \in \mbb{R}^K : \lambda \ge 0\}$ is the set of tuples of $K$ non-negative real-numbers, each commonly known as a Lagrange-multiplier. %It is clear that $\mcl{Y}$ is convex and we can endow it with the usual subspace topology of $\mbb{R}^K$.
Our main result shows that the the solution $\udl{C}$ satisfies
\begin{align*}
\optcosts &= \infsup{\mu\in \m{\uspace}}{\lambda\in \mcl{Y}} \lagsmix{\mu}{\lambda}
,\numberthis\label{eq:optccost:infsup}
\end{align*}
and that the inf and sup can be interchanged, i.e.,
\begin{align*}
\optcosts &= \supinf{\lambda\in \mcl{Y}}{\mu\in \m{\uspace}} \lagsmix{\mu}{\lambda}
.\numberthis\label{eq:optccost:supinf}
\end{align*}

\begin{thm}[Strong Duality and Existence of Saddle Point]\label{thm:strongduality}
Under Assumption \ref{assmp:boundedcosts}, the following statements hold.
\begin{enumerate}[leftmargin=0pt, itemindent=20pt, labelwidth=15pt, labelsep=5pt, listparindent=0.7cm, align=left]
\item[(a)] The optimal value satisfies 
\begin{align*}
\optcosts = \infsup{\mu\in\m{\uspace}}{\lambda\in \mcl{Y}} \lagsmix{\mu}{\lambda}
.\numberthis   
\end{align*}
\item[(b)] A mixture $\mu^\star \in \m{\uspace}$ is optimal if and only if $\optcosts = \sup_{\lambda\in \mcl{Y}} \lagsmix{\mu^\star}{\lambda}$.
\item[(c)] Strong duality holds for \eqref{eq:macpomdp}, i.e.,
\begin{align*}
\optcosts &= \infsup{\mu\in\m{\uspace}}{\lambda\in \mcl{Y}} \lagsmix{\mu}{\lambda}
= \supinf{\lambda\in \mcl{Y}}{\mu\in\m{\uspace}} \lagsmix{\mu}{\lambda}
.\numberthis
\end{align*}
Moreover, there exists a $\mu^\star \in \m{\uspace}$ such that $\optcosts = \sup_{\lambda \in \mcl{Y}} \lagsmix{\mu^\star}{\lambda} $ and $\mu^\star$ is optimal for \eqref{eq:macpomdp}. 
\item[(d)] If Assumption \ref{assmp:slatercondition} holds, then there also exists $\lambda^\star \in \mcl{Y}$ such that the following saddle-point condition holds for all $(\mu,\lambda)\in \m{\uspace} \times \mcl{Y}$,
\begin{align*}
\lagsmix{\mu^\star}{\lambda} \le \lagsmix{\mu^\star}{\lambda^\star} = \optcosts \le \lagsmix{\mu}{\lambda^\star}.
\numberthis\label{eq:saddlepointconditions} 
\end{align*}
i.e., $\mu^\star$ minimizes $\lagsmix{\cdot}{\lambda^\star}$ and $\lambda^\star$ maximizes $\lagsmix{\mu^\star}{\cdot}$. In addition to this, the primal dual pair $\l( \mu^\star, \lambda^\star \r)$ satisfies the complementary-slackness condition:
\begin{align*}\label{eq:compslack}
    \dotp{\lambda^\star}{\fulldcostsmix{\mu^\star}-\constraintv} = 0.\numberthis
\end{align*}
\end{enumerate}
\end{thm}

\begin{proof}
\begin{enumerate}[leftmargin=0pt, itemindent=20pt,
labelwidth=15pt, labelsep=5pt, 
% listparindent=0.7cm,
align=left]
\item[(a)] If $\mu \in \m{\uspace}$ is feasible (i.e., it satisfies $\fulldcostsmix{\mu} \le \constraintv$), then the $\sup$ is obtained by choosing $\lambda = 0$, so
\begin{align*}
\sup_{\lambda\in\mcl{Y}} \lagsmix{\mu}{\lambda} &= \fullccostsmix{\mu}.
\numberthis\label{eq:ufeasible}
\end{align*}
If $\mu \in \m{\uspace}$ is not feasible, then %it is easily seen that
\begin{align*}
\sup_{\lambda\in \mcl{Y}} \lagsmix{\mu}{\lambda} = \infty.
\numberthis\label{eq:unotfeasible}
\end{align*}
Indeed, suppose WLOG that the $k^{th}$ constraint is violated, i.e., $\fulldkcostsmix{k}{\mu} > \constraintv_k$, then $\infty$ can be obtained by choosing $\lambda_k$ arbitrarily large and setting other $\lambda_k$'s to 0.

\hspace{5pt} From \eqref{eq:ufeasible}, \eqref{eq:unotfeasible}, and our convention that $\optcosts = \infty$ whenever the feasible-set is empty, it follows that
\begin{align*}
\optcosts = \infsup{\mu\in\m{\uspace}}{\lambda\in\mcl{Y} } \lagsmix{\mu}{\lambda}.
\numberthis\label{eq:fullccostisinfsup}
\end{align*}

\item[(b)] By our convention on the value of $\optcosts$ (when there is no feasible mixture), $\mu^\star$ is optimal if and only if $\fullccostsmix{\mu^\star} = \optcosts $, i.e., $\sup_{\lambda\in \mcl{Y} } \lagsmix{\mu^\star}{\lambda} = \optcosts$.

\item[(c)] To establish strong duality, we use 
% \cite{khan23}[Proposition 4]
Proposition \ref{prop:sionminimax} 
which requires $\m{\uspace}$ and $\mcl{Y}$ to be convex topological spaces, with $\m{\uspace}$ being compact as well. It is clear that $\mcl{Y}$ is convex and we can endow it with the usual subspace topology of $\mbb{R}^K$. Convexity of $\m{\uspace}$ is trivial and its compactness has been ensured in Section \ref{sec:optimization_problem}. By definition, $\wh{L}$ is affine and thus trivially concave in $\lambda$. Proposition \ref{prop:integral_linearity} 
implies that $\wh{L}$ is convex in $\mu$ and Lemma \ref{lem:lsc2} shows that $\wh{L}$ is lower semi-continuous\footnote{For definition of lower semi-continuity, see 
Definition \ref{dfn:lsc}.} 
% \cite{khan23}[Definition 1].} 
in $\mu$. 
% From~\cite{khan23}[Proposition 11],
From Proposition \ref{prop:sionminimax}, 
it then follows that
\begin{align*}
\infsup{\mu\in\m{\uspace} }{\lambda\in \mcl{Y}} \lagsmix{\mu}{\lambda} = \supinf{\lambda\in \mcl{Y}}{\mu\in \m{\uspace}} \lagsmix{\mu}{\lambda},
\end{align*}
and that there exists $\mu^\star \in \m{\uspace}$ such that
\begin{align*}
\sup_{\lambda\in \mcl{Y}} \lagsmix{\mu^\star}{\lambda} = \infsup{\mu\in\m{\uspace}}{\lambda\in \mcl{Y}} \lagsmix{\mu}{\lambda}.
\end{align*}
The optimality of $\mu^\star$ is implied by parts (b) and (a). 

\item[(d)] This follows from Lagrange-multiplier theory.
\end{enumerate}
This concludes the proof.
\end{proof}


\begin{lem}[Lower Semi-Continuity of $\wh{L}$ on $\m{\uspace}$]\label{lem:lsc2}
    Under Assumption \ref{assmp:boundedcosts}, $\wh{L}$ is lower semi-continuous on $\m{\uspace}$.
\end{lem}
\begin{proof}
    Fix $\lambda\in\mcl{Y}$ and $\mu\in \m{\uspace}$. Let $\l\{ \mu_i \r\}_{i=1}^{\infty}$ be a sequence of measures in $\m{\uspace}$ that converges to $\mu$. 
    We want to show
    \begin{align*}
        \liminf_{i\ra\infty} \E{U \sim \mu_i}{} \l[  \lags{U}{\lambda} \r] \ge \E{U \sim \mu}{} \l[  \lags{U}{\lambda} \r].
    \end{align*}
    By Lemma \ref{lem:lsc}, $L$ is point-wise lower semi-continuous on $\uspace$. Therefore, 
    % \cite{khan23}[Proposition 9] 
    Proposition \ref{prop:lsc} 
    applies on $\m{\uspace}$ and the above inequality follows.
\end{proof}

\begin{lem}[Lower Semi-Continuity of $L$ on $\uspace$]\label{lem:lsc}
Under Assumption \ref{assmp:boundedcosts}, the functions $C$ and $D_k$'s are lower semi-continuous on $\uspace$. Hence, $L$ is lower semi-continuous on $\uspace$. 
\end{lem}
\begin{proof}
We will prove the statement for $C$. The proof of lower semi-continuity of $D_k$'s is similar. For brevity, let 
\begin{align*}
\pruphsts{u}{t}{\hst{h}{t}, \at{t}} &= \pruphst{u}{t}{\hst{h}{t}, \at{t}} \defeq \prup{u}{P_1}\l(\Hst{t} = \hst{h}{t}, \At{t} = \at{t}\r),
\\
\zuphsts{u}{t}{\hst{h}{t}, \at{t}} &= \zuphst{u}{t}{\hst{h}{t}, \at{t}}\\
&\hspace{-25pt} \defeq \pruphsts{u}{t}{\hst{h}{t}, \at{t}} \mbb{E}_{P_1}\l[ \cCost | \Hst{t} = \hst{h}{t}, \At{t} = \at{t} \r],
\end{align*}
where we use the convention $0\cdot\infty=0$. Then,
\begin{align*}
\fullccosts{u} &= \E{u}{P_1}\l[ \sum_{t=1}^{\infty} \alpha^{t-1} c(S_t, A_t) \r] \\
&= \E{u}{P_1}\l[ \sum_{t=1}^{\infty} \alpha^{t-1} \l( c(S_t, A_t) - \udl{c} \r) \r] + \sum_{t=1}^{\infty} \alpha^{t-1} \udl{c}\\
&\labelrel{=}{eqr:cp1u:a} \sum_{t=1}^{\infty} \alpha^{t-1} \E{u}{P_1} \l[ c(S_t, A_t) - \udl{c} \r] + \sum_{t=1}^{\infty} \alpha^{t-1} \udl{c}\\
% &= \sum_{t=1}^{\infty} \alpha^{t-1} \E{u}{P_1} \l[ c(S_t, A_t) \r] \\
&\labelrel{=}{eqr:cp1u:b} \sum_{t=1}^{\infty} \alpha^{t-1} \E{u}{P_1} \l[ \mbb{E}_{P_1} \l[ c(S_t, A_t)  | \Hst{t}, \At{t} \r] \r]\\
&= \sum_{t=1}^{\infty} \sum_{\hst{h}{t} \in \hstspace{t}} \sum_{\at{t}\in \aspace} \alpha^{t-1} \zuphsts{u}{t}{\hst{h}{t}, \at{t}}.
\end{align*}
Here, \eqref{eqr:cp1u:a} follows from applying the Monotone-Convergence Theorem to the (increasing non-negative) sequence $\{ \sum_{t=1}^{i} \alpha^{t-1} \l( c\l( \Stt{t}, \At{t} \r) - \udl{c} \r) \}_{i=1}^{\infty}$ 
% (see~\cite{khan23}[Proposition 1]); 
(see Proposition \ref{prop:mct}); 
and \eqref{eqr:cp1u:b} uses the tower property of conditional expectation.\footnote{The conditional expectations $\mbb{E}_{P_1} \l[ c(S_t, A_t) | \Hst{t}, \At{t} \r]$ exist and are unique because $c(\cdot, \cdot)$ is bounded from below.}

Let $\l\{ \useq{i}{u} \r\}_{i=1}^{\infty}$ be a sequence in $\uspace$ that converges to $u$. By Fatou's Lemma 
% (see~\cite{khan23}[Proposition 3]), 
(see Proposition \ref{prop:fatou}), 
\begin{align*}
\liminf_{i\ra \infty} \fullccosts{\useq{i}{u}} \ge \sum_{t=1}^{\infty} \sum_{\hst{h}{t} \in \hstspace{t}} \sum_{\at{t}\in \aspace} \alpha^{t-1} \liminf_{i\ra\infty} \zuphsts{\useq{i}{u}}{t}{\hst{h}{t}, \at{t}}.\numberthis\label{eq:step1}
\end{align*}
% Following~\cite{khan23}[Lemma 5],
Following Lemma \ref{lem:puth}, 
$\pruphsts{\useq{i}{u}}{t}{\hst{h}{t}, \at{t}}\ge 0 $ converges to $\pruphsts{u}{t}{\hst{h}{t}, \at{t}}$. Therefore,
\begin{align*}
\liminf_{i\ra\infty} \zuphsts{\useq{i}{u}}{t}{\hst{h}{t}, \at{t}} \ge \zuphsts{u}{t}{\hst{h}{t}, \at{t}}.\numberthis\label{eq:step2}
\end{align*}
Then, \eqref{eq:step1} and \eqref{eq:step2} result in
% \begin{align*}
$\liminf_{i\ra \infty} \fullccosts{\useq{i}{u}} \ge \fullccosts{u},$ 
% \end{align*}
which establishes the lower semi-continuity of $\fullccosts{u}$. 
\end{proof}


\begin{lem}\label{lem:puth}[Limit Probabilities for a converging sequence of policy-profiles]
Let $\l\{ \useq{i}{u} \r\}_{i=1}^{\infty}$ be a sequence in $\uspace$ that converges to $u$. Then, for any $t \in \mbb{N}$, $ \hst{h}{t} \in \hstspace{t} $, and $\at{t} \in \mcl{A}$,
\begin{align*}
\lim_{i\ra \infty}  \pruphsts{\useq{i}{u}}{t}{\hst{h}{t}, \at{t}} = \pruphsts{u}{t}{\hst{h}{t}, \at{t}},
\end{align*}
where $\pruphsts{\cdot}{t}{\hst{h}{t}, \at{t}} = \prup{\cdot}{P_1} \l( \Hst{t} = \hst{h}{t}, \At{t} = \at{t} \r)$. In other words, for every $t \in \mbb{N}$, the sequence of measures $\l\{ \pruphsts{ \useq{i}{u}}{t}{\cdot, \cdot} \r\}_{i=1}^{\infty}$ converges weakly to $\pruphsts{u}{t}{\cdot, \cdot}$.
\end{lem}
\begin{proof}
Given that $\useq{i}{u}$ converges to $u$, by Proposition \ref{prop:conv_in_prod_topology}, for every $n \in [N]$, $\useq{i}{\utn{u}{t}{n}} (\hstn{h}{t}{0}, \hstn{h}{t}{n} )$ converges weakly to $ \utn{u}{t}{n} ( \hstn{h}{t}{0}, \hstn{h}{t}{n} ) $. Since $\mcl{A}^n$ is finite, this means that for each $\an{n}\in \anspace{n}$, $\useq{i}{\utn{u}{t}{n}} ( \an{n} | \hstn{h}{t}{0}, \hstn{h}{t}{n} )$ converges to $\utn{u}{t}{n} ( \an{n} | \hstn{h}{t}{0}, \hstn{h}{t}{n} )$, which further implies that for all $a \in \aspace$, $ \useq{i}{\ut{u}{t}} ( a | \hst{h}{t}) $ converges to $ \ut{u}{t} ( a | \hst{h}{t}) $. Now, we use forward induction to prove the statement. 
\begin{enumerate}
[leftmargin=0pt, 
itemindent=10pt,
labelwidth=0pt, 
labelsep=5pt, 
% listparindent=0.7cm,
% align=left
]
\item \textbf{Base Case}:  For time $t=1$, let $\ot{1} \in \hstspace{1} = \ospace$ and $\at{1} \in \mcl{A}$. We have
\begin{align*}
\pruphsts{\useq{i}{u}}{1}{\ot{1}, \at{1}}
=P_1\l( \sspace, o \r) \useq{i}{\ut{u}{1}} \l( \at{1} | \ot{1} \r) 
\ra \pruphsts{u}{1}{\ot{1}, \at{1}}.
\end{align*}

\item \textbf{Induction Step}: Assuming that the statement is true for time $t$, we show that it is true for time $t+1$. Let $\hst{h}{t+1} = \l( \ot{1:t+1}, \at{1:t} \r) = \l( \hst{h}{t}, \at{t}, \ot{t+1} \r) \in \hstspace{t+1}$ and $\at{t+1} \in \aspace$. We have
\begin{align*}
&\pruphsts{\useq{i}{u}}{t+1}{\hst{h}{t+1}, \at{t+1}} =  
\pruphsts{\useq{i}{u}}{t}{\hst{h}{t}, \at{t}} \\
&\hspace{25pt} \times \useq{i}{\ut{u}{t+1}} \l( \at{t+1} | \hst{h}{t+1} \r) \pr_{P_1} \l( \ot{t+1} | \hst{h}{t}, \at{t} \r).
\end{align*}
By inductive hypothesis, $\pruphsts{\useq{i}{u}}{t}{\hst{h}{t}, \at{t}} $ converges to $\pruphsts{u}{t}{\hst{h}{t}, \at{t}}$, and $ \useq{i}{\ut{u}{t}}\l( \at{t+1} | \hst{h}{t+1}\r) $ converges to $ \ut{u}{t} \l( \at{t+1} | \hst{h}{t+1}\r) $ by assumption. We conclude that $\pruphsts{\useq{i}{u}}{t+1}{\hst{h}{t+1}, \at{t+1}}$ converges to $\pruphsts{u}{t+1}{\hst{h}{t+1}, \at{t+1}}$.
\end{enumerate}
This completes the proof.
\end{proof}
