@article{10.1093/biomet/92.1.31,
    author = {Schennach, Susanne M.},
    title = "{Bayesian exponentially tilted empirical likelihood}",
    journal = {Biometrika},
    volume = {92},
    number = {1},
    pages = {31-46},
    year = {2005},
    month = {03},
    abstract = "{While empirical likelihood has been shown to exhibit many of the properties of conventional parametric likelihoods, a formal probabilistic interpretation has so far been lacking. We show that a likelihood function very closely related to empirical likelihood naturally arises from a nonparametric Bayesian procedure which places a type of noninformative prior on the space of distributions. This prior gives preference to distributions having a small support and, among those sharing the same support, it favours entropy-maximising distributions. The resulting nonparametric Bayesian procedure admits a computationally convenient representation as an empirical-likelihood-type likelihood where the probability weights are obtained via exponential tilting. The proposed methodology provides an attractive alternative to the Bayesian bootstrap as a nonparametric limit of a Bayesian procedure for moment condition models.}",
    issn = {0006-3444},
    doi = {10.1093/biomet/92.1.31},
    url = {https://doi.org/10.1093/biomet/92.1.31},
    eprint = {https://academic.oup.com/biomet/article-pdf/92/1/31/687866/921031.pdf},
}

@article{ishwaran2002exact,
  title={Exact and approximate sum representations for the Dirichlet process},
  author={Ishwaran, Hemant and Zarepour, Mahmoud},
  journal={Canadian Journal of Statistics},
  volume={30},
  number={2},
  pages={269--283},
  year={2002},
  publisher={Wiley Online Library}
}

@article{ishwaran2002dirichlet,
  title={Dirichlet prior sieves in finite normal mixtures},
  author={Ishwaran, Hemant and Zarepour, Mahmoud},
  journal={Statistica Sinica},
  pages={941--963},
  year={2002},
  publisher={JSTOR}
}

@article{kleijn2012bernstein,
  title={The Bernstein-von-Mises theorem under misspecification},
  author={Kleijn, Bas JK and van der Vaart, Aad W},
  journal={Electronic Journal of Statistics},
  volume={6},
  pages={354--381},
  year={2012},
  publisher={Institute of Mathematical Statistics and Bernoulli Society}
}


@article{2021,
   title={Sensitivity analysis using approximate moment condition models},
   volume={12},
   ISSN={1759-7323},
   url={http://dx.doi.org/10.3982/QE1609},
   DOI={10.3982/qe1609},
   number={1},
   journal={Quantitative Economics},
   publisher={The Econometric Society},
   author={Armstrong, Timothy B. and Kolesár, Michal},
   year={2021},
   pages={77–108}
}

@book{muller2015bayesian,
  title={Bayesian nonparametric data analysis},
  author={M{\"u}ller, Peter and Quintana, Fernando Andr{\'e}s and Jara, Alejandro and Hanson, Tim},
  volume={1},
  year={2015},
  publisher={Springer}
}

@book{anderson,
  title={An introduction to multivariate statistical analysis},
  author={T.W Anderson},
  year={1958},
  publisher={John Wiley \& Sons Inc}
}

@article{teh2010dirichlet,
  title={Dirichlet Process.},
  author={Teh, Yee Whye},
  journal={Encyclopedia of machine learning},
  volume={1063},
  pages={280--287},
  year={2010}
}

@book{owen2001empirical,
  title={Empirical likelihood},
  author={Owen, Art B},
  year={2001},
  publisher={Chapman and Hall/CRC}
}

@article{muller2004nonparametric,
  title={Nonparametric Bayesian data analysis},
  author={M{\"u}ller, Peter and Quintana, Fernando A},
  journal={Statistical science},
  volume={19},
  number={1},
  pages={95--110},
  year={2004},
  publisher={Institute of Mathematical Statistics}
}

@article{doi:10.1080/01621459.2018.1469995,
author = {Jeffrey W. Miller and David B. Dunson},
title = {Robust Bayesian Inference via Coarsening},
journal = {Journal of the American Statistical Association},
volume = {114},
number = {527},
pages = {1113-1125},
year  = {2019},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.2018.1469995},
    note ={PMID: 31942084},

URL = { 
        https://doi.org/10.1080/01621459.2018.1469995
    
},
eprint = { 
        https://doi.org/10.1080/01621459.2018.1469995
    
}

}

@article{safebayes,
      title={Inconsistency of {B}ayesian Inference for Misspecified Linear Models, and a Proposal for Repairing It}, 
      author={Peter Grünwald and Thijs van Ommen},
      journal = {Bayesian analysis},
      year={2017},
      url = {https://pure.uva.nl/ws/files/22184651/1510974325.pdf},
      eprint={1412.3730},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}

@article{2008,
   title={Gibbs posterior for variable selection in high-dimensional classification and data mining},
   volume={36},
   ISSN={0090-5364},
   url={http://dx.doi.org/10.1214/07-AOS547},
   DOI={10.1214/07-aos547},
   number={5},
   journal={The Annals of Statistics},
   publisher={Institute of Mathematical Statistics},
   author={Jiang, Wenxin and Tanner, Martin A.},
   year={2008},
   month={Oct}
}

@misc{pivotposterior,
      title={The pivot posterior}, 
      author={M Heller},
      year={2016},
      
}

@misc{hooker2012bayesian,
  doi = {10.48550/ARXIV.1112.4213},
  
  url = {https://arxiv.org/abs/1112.4213},
  
  author = {Hooker, Giles and Vidyashankar, Anand},
  
  keywords = {Methodology (stat.ME), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {{B}ayesian Model Robustness via Disparities},
  
  publisher = {arXiv},
  
  year = {2011},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{JMLR:v18:16-655,
  author  = {Stanislav Minsker and Sanvesh Srivastava and Lizhen Lin and David B. Dunson},
  title   = {Robust and Scalable {B}ayes via a Median of Subset Posterior Measures},
  journal = {Journal of Machine Learning Research},
  year    = {2017},
  volume  = {18},
  number  = {124},
  pages   = {1-40},
  url     = {http://jmlr.org/papers/v18/16-655.html}
}

@article{10.2307/30042042,
 ISSN = {00063444},
 URL = {http://www.jstor.org/stable/30042042},
 abstract = {Research has shown that empirical likelihood tests have many of the same asymptotic properties as those derived from parametric likelihoods. This leads naturally to the possibility of using empirical likelihood as the basis for Bayesian inference. Different ways in which this goal might be accomplished are considered. The validity of the resultant posterior inferences is examined, as are frequentist properties of the Bayesian empirical likelihood intervals.},
 author = {Nicole A. Lazar},
 journal = {Biometrika},
 number = {2},
 pages = {319--326},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {{B}ayesian Empirical Likelihood},
 volume = {90},
 year = {2003}
}

@misc{chib2021bayesian,
      title={{B}ayesian Estimation and Comparison of Conditional Moment Models}, 
      author={Siddhartha Chib and Minchul Shin and Anna Simoni},
      year={2021},
      url = {https://arxiv.org/abs/2110.13531},
      eprint={2110.13531},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}

@article{Villani2003TopicsIO,
  title={Topics in Optimal Transportation},
  author={C{\'e}dric Villani},
  journal = {American Mathematical Society},
  url = {https://www.math.ucla.edu/~wgangbo/Cedric-Villani.pdf},
  year={2003}
}

@article{2019,
   title={Statistical Aspects of {W}asserstein Distances},
   volume={6},
   ISSN={2326-831X},
   url={http://dx.doi.org/10.1146/annurev-statistics-030718-104938},
   DOI={10.1146/annurev-statistics-030718-104938},
   number={1},
   journal={Annual Review of Statistics and Its Application},
   publisher={Annual Reviews},
   author={Panaretos, Victor M. and Zemel, Yoav},
   year={2019},
   month={Mar},
   pages={405–431}
}


@misc{hallin2021multivariate,
      title={Multivariate goodness-of-Fit tests based on {W}asserstein distance}, 
      author={Marc Hallin and Gilles Mordant and Johan Segers},
      year={2021},
      eprint={2003.06684},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@misc{ramdas2015wasserstein,
      title={On {W}asserstein Two Sample Testing and Related Families of Nonparametric Tests}, 
      author={Aaditya Ramdas and Nicolas Garcia and Marco Cuturi},
      year={2015},
      eprint={1509.02237},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}

@misc{bernton2019parameter,
      title={On parameter estimation with the {W}asserstein distance}, 
      author={Espen Bernton and Pierre E. Jacob and Mathieu Gerber and Christian P. Robert},
      year={2019},
      eprint={1701.05146},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}


@incollection{huber2011robust,
  title={Robust statistics},
  author={Huber, Peter J},
  booktitle={International encyclopedia of statistical science},
  pages={1248--1251},
  year={2011},
  publisher={Springer}
}


@inproceedings{le2019treesliced,
 author = {Tam Le and Makoto Yamada and Kenji Fukumizu and Marco Cuturi},
 booktitle = {Advances in Neural Information Processing Systems},
 publisher = {Curran Associates, Inc.},
 title = {Tree-Sliced Variants of {W}asserstein Distances},
 url = {https://proceedings.neurips.cc/paper/2019/file/2d36b5821f8affc6868b59dfc9af6c9f-Paper.pdf},
 year = {2019}
}

@inproceedings{cuturi2013sinkhorn,
 author = {Cuturi, Marco},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C.J. Burges and L. Bottou and M. Welling and Z. Ghahramani and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Sinkhorn Distances: Lightspeed Computation of Optimal Transport},
 url = {https://proceedings.neurips.cc/paper/2013/file/af21d0c97db2e27e13572cbf59eb343d-Paper.pdf},
 volume = {26},
 year = {2013}
}

@article{delon:hal-02178204,
  TITLE = {{A {W}asserstein-type distance in the space of Gaussian Mixture Models}},
  AUTHOR = {Delon, Julie and Desolneux, Agn{\`e}s},
  URL = {https://hal.archives-ouvertes.fr/hal-02178204},
  JOURNAL = {{SIAM Journal on Imaging Sciences}},
  PUBLISHER = {{Society for Industrial and Applied Mathematics}},
  VOLUME = {13},
  NUMBER = {2},
  PAGES = {936--970},
  YEAR = {2020},
  KEYWORDS = {optimal transport ; Wasserstein distance ; Gaussian mixture model ; multi-marginal optimal trans- port ; barycenter ; image processing applications ; 65K05 ; 90C05 ; 62-07 ; 68Q25 ; 68U10 ; 68U05 ; 68R10 ; multi-marginal optimal trans- 10 port ; image processing applications 11 AMS subject classifications 65K10 ; 68R10 12 ; image processing applications AMS subject classifications 65K10},
  PDF = {https://hal.archives-ouvertes.fr/hal-02178204v4/file/WassersteinGMM-arxiv-final2.pdf},
  HAL_ID = {hal-02178204},
  HAL_VERSION = {v4},
}

@article{BionNadal2019OnAW,
  title={On a {W}asserstein-type distance between solutions to stochastic differential equations},
  author={Jocelyne Bion-Nadal and Denis Talay},
  journal={The Annals of Applied Probability},
  year={2019}
}

@article{Resnick,
  title={A Probability Path},
  author={Sydney Resnick},
  journal={Birkhäuser Boston},
  year={2013}
}

@article{JMLR:v17:14-540,
  author  = {Aki Vehtari and Tommi Mononen and Ville Tolvanen and Tuomas Sivula and Ole Winther},
  title   = {{B}ayesian Leave-One-Out Cross-Validation Approximations for Gaussian Latent Variable Models},
  journal = {Journal of Machine Learning Research},
  year    = {2016},
  volume  = {17},
  number  = {103},
  pages   = {1-38},
  url     = {http://jmlr.org/papers/v17/14-540.html}
}

@article{doi:10.1080/01621459.2016.1255636,
author = {Jeffrey W. Miller and Matthew T. Harrison},
title = {Mixture Models With a Prior on the Number of Components},
journal = {Journal of the American Statistical Association},
volume = {113},
number = {521},
pages = {340-356},
year  = {2018},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.2016.1255636},
    note ={PMID: 29983475},

URL = { 
        https://doi.org/10.1080/01621459.2016.1255636
    
},
eprint = { 
        https://doi.org/10.1080/01621459.2016.1255636}
}

@article{Cambanis1981OnTT,
  title={On the theory of elliptically contoured distributions},
  author={Stamatis Cambanis and Steel T. Huang and Gordon Simons},
  journal={Journal of Multivariate Analysis},
  year={1981},
  volume={11},
  pages={368-385}
}

@article{10.2307/4616956,
 ISSN = {03036898, 14679469},
 URL = {http://www.jstor.org/stable/4616956},
 abstract = {We present general results on the identifiability of finite mixtures of elliptical distributions under conditions on the characteristic generators or density generators. Examples include the multivariate t-distribution, symmetric stable laws, exponential power and Kotz distributions. In each case, the shape parameter is allowed to vary in the mixture, in addition to the location vector and the scatter matrix. Furthermore, we discuss the identifiability of finite mixtures of elliptical densities with generators that correspond to scale mixtures of normal distributions.},
 author = {Hajo Holzmann and Axel Munk and Tilmann Gneiting},
 journal = {Scandinavian Journal of Statistics},
 number = {4},
 pages = {753--763},
 publisher = {[Board of the Foundation of the Scandinavian Journal of Statistics, Wiley]},
 title = {Identifiability of Finite Mixtures of Elliptical Distributions},
 volume = {33},
 year = {2006}
}


@article{10.2307/24305538,
 ISSN = {10170405, 19968507},
 URL = {http://www.jstor.org/stable/24305538},
 abstract = {In this paper we give a simple and new constructive definition of Dirichlet measures removing the restriction that the basic space should be Rk. We also give complete, self contained proofs of the three basic results for Dirichlet measures: 1. The Dirichlet measure is a probability measure on the space of all probability measures. 2. It gives probability one to the subset of discrete probability measures. 3. The posterior distribution is also a Dirichlet measure.},
 author = {Jayaram Sethuraman},
 journal = {Statistica Sinica},
 number = {2},
 pages = {639--650},
 publisher = {Institute of Statistical Science, Academia Sinica},
 title = {A CONSTRUCTIVE DEFINITION OF DIRICHLET PRIORS},
 volume = {4},
 year = {1994}
}

@article{10.2307/2975974,
 ISSN = {00221082, 15406261},
 URL = {http://www.jstor.org/stable/2975974},
 author = {Harry Markowitz},
 journal = {The Journal of Finance},
 number = {1},
 pages = {77--91},
 publisher = {[American Finance Association, Wiley]},
 title = {Portfolio Selection},
 volume = {7},
 year = {1952}
}

@article{doi:10.1080/07474930801960394,
author = { Anil K.   Bera  and  Sung Y.   Park },
title = {Optimal Portfolio Diversification Using the Maximum Entropy Principle},
journal = {Econometric Reviews},
volume = {27},
number = {4-6},
pages = {484-512},
year  = {2008},
publisher = {Taylor & Francis},
doi = {10.1080/07474930801960394},

URL = { 
        https://doi.org/10.1080/07474930801960394
    
},
eprint = { 
        https://doi.org/10.1080/07474930801960394
    
}

}


@misc{gajane2018formalizing,
      title={On Formalizing Fairness in Prediction with Machine Learning}, 
      author={Pratik Gajane and Mykola Pechenizkiy},
      year={2018},
      url = {https://www.fatml.org/media/documents/formalizing_fairness_in_prediction_with_ml.pdf},
      eprint={1710.03184},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@Article{e21080741,
AUTHOR = {Fitzsimons, Jack and Al Ali, AbdulRahman and Osborne, Michael and Roberts, Stephen},
TITLE = {A General Framework for Fair Regression},
JOURNAL = {Entropy},
VOLUME = {21},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {741},
URL = {https://www.mdpi.com/1099-4300/21/8/741},
ISSN = {1099-4300},
ABSTRACT = {Fairness, through its many forms and definitions, has become an important issue facing the machine learning community. In this work, we consider how to incorporate group fairness constraints into kernel regression methods, applicable to Gaussian processes, support vector machines, neural network regression and decision tree regression. Further, we focus on examining the effect of incorporating these constraints in decision tree regression, with direct applications to random forests and boosted trees amongst other widespread popular inference techniques. We show that the order of complexity of memory and computation is preserved for such models and tightly binds the expected perturbations to the model in terms of the number of leaves of the trees. Importantly, the approach works on trained models and hence can be easily applied to models in current use and group labels are only required on training data.},
DOI = {10.3390/e21080741}
}


@misc{yang2019fair,
  doi = {10.48550/ARXIV.1907.08646},
  
  url = {https://arxiv.org/abs/1907.08646},
  
  author = {Yang, Dana and Lafferty, John and Pollard, David},
  
  keywords = {Statistics Theory (math.ST), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Fair quantile regression},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{doi:10.1198/016214501750332848,
author = {Siddhartha Chib and Ivan Jeliazkov},
title = {Marginal Likelihood From the Metropolis–Hastings Output},
journal = {Journal of the American Statistical Association},
volume = {96},
number = {453},
pages = {270-281},
year  = {2001},
publisher = {Taylor & Francis},
doi = {10.1198/016214501750332848},

URL = { 
        https://doi.org/10.1198/016214501750332848
    
},
eprint = { 
        https://doi.org/10.1198/016214501750332848
    
}

}


@article{10.1214/11-BJPS164,
author = {Anthony O’Hagan and Luis Pericchi},
title = {{{B}ayesian heavy-tailed models and conflict resolution: A review}},
volume = {26},
journal = {Brazilian Journal of Probability and Statistics},
number = {4},
publisher = {Brazilian Statistical Association},
pages = {372 -- 401},
keywords = {Built-in robustness, heavy-tailed modelling, Outliers, partial rejection of information, rejection of information, theory of conflict resolution},
year = {2012},
doi = {10.1214/11-BJPS164},
URL = {https://doi.org/10.1214/11-BJPS164}
}

@article{Gonccalves2015RobustBM,
  title={Robust {B}ayesian model selection for heavy-tailed linear regression using finite mixtures},
  author={Fl'avio B. Gonccalves and Marcos Oliveira Prates and Victor Hugo Lachos},
  journal={arXiv: Methodology},
  year={2015}
}

@Article{sym12060929,
AUTHOR = {Mahmoudi, Mohammad Reza and Maleki, Mohsen and Baleanu, Dumitru and Nguyen, Vu-Thanh and Pho, Kim-Hung},
TITLE = {A {B}ayesian Approach to Heavy-Tailed Finite Mixture Autoregressive Models},
JOURNAL = {Symmetry},
VOLUME = {12},
YEAR = {2020},
NUMBER = {6},
ARTICLE-NUMBER = {929},
URL = {https://www.mdpi.com/2073-8994/12/6/929},
ISSN = {2073-8994},
ABSTRACT = {In this paper, a Bayesian analysis of finite mixture autoregressive (MAR) models based on the assumption of scale mixtures of skew-normal (SMSN) innovations (called SMSN&ndash;MAR) is considered. This model is not simultaneously sensitive to outliers, as the celebrated SMSN distributions, because the proposed MAR model covers the lightly/heavily-tailed symmetric and asymmetric innovations. This model allows us to have robust inferences on some non-linear time series with skewness and heavy tails. Classical inferences about the mixture models have some problematic issues that can be solved using Bayesian approaches. The stochastic representation of the SMSN family allows us to develop a Bayesian analysis considering the informative prior distributions in the proposed model. Some simulations and real data are also presented to illustrate the usefulness of the proposed models.},
DOI = {10.3390/sym12060929}
}

@article{pati,
author = {Pati D., Dunson D.B},
title = {{{B}ayesian nonparametric regression with varying residual density}},
journal = {Annals of the Institute of Statistical Mathematics},
year = {2014},
}

@article{doi:10.1198/106186006X157441,
author = {David Chan and Robert Kohn and David Nott and Chris Kirby},
title = {Locally Adaptive Semiparametric Estimation of the Mean and Variance Functions in Regression Models},
journal = {Journal of Computational and Graphical Statistics},
volume = {15},
number = {4},
pages = {915-936},
year  = {2006},
publisher = {Taylor & Francis},
doi = {10.1198/106186006X157441},

URL = { 
        https://doi.org/10.1198/106186006X157441
    
},
eprint = { 
        https://doi.org/10.1198/106186006X157441
    
}

}

@InProceedings{pmlr-v115-jiang20a,
  title = 	 {{W}asserstein Fair Classification},
  author =       {Jiang, Ray and Pacchiano, Aldo and Stepleton, Tom and Jiang, Heinrich and Chiappa, Silvia},
  booktitle = 	 {Proceedings of The 35th Uncertainty in Artificial Intelligence Conference},
  pages = 	 {862--872},
  year = 	 {2020},
  editor = 	 {Adams, Ryan P. and Gogate, Vibhav},
  volume = 	 {115},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {22--25 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v115/jiang20a/jiang20a.pdf},
  url = 	 {https://proceedings.mlr.press/v115/jiang20a.html},
  abstract = 	 {We propose an approach to fair classification that enforces independence between the classifier outputs and sensitive information by minimizing Wasserstein-1 distances. The approach has desirable theoretical properties and is robust to specific choices of the threshold used to obtain class predictions from model outputs.We introduce different methods that enable hid-ing sensitive information at test time or have a simple and fast implementation.  We show empirical  performance  against  different  fair-ness baselines on several benchmark fairness datasets.}
}

@book{muirhead2005aspects,
  added-at = {2011-02-15T15:41:05.000+0100},
  author = {Muirhead, Robb J.},
  biburl = {https://www.bibsonomy.org/bibtex/2410d53b128be06949a71a5dbce51facc/ytyoun},
  interhash = {ba679b25bfbd69cb79c0af8475c454a1},
  intrahash = {410d53b128be06949a71a5dbce51facc},
  keywords = {multivariate statistics textbook},
  publisher = {Wiley-Interscience},
  timestamp = {2016-10-24T07:48:03.000+0200},
  title = {Aspects of Multivariate Statistical Theory},
  year = 2005
}

@misc{noauthororeditor,
  added-at = {2019-12-11T00:48:10.000+0100},
  author = {Santambrogio, Filippo},
  biburl = {https://www.bibsonomy.org/bibtex/281ed66090d576f173cc088fb4596d431/kirk86},
  description = {OTAM-cvgmt.pdf},
  interhash = {d50122af28034ea04f9891cf91bd5af4},
  intrahash = {81ed66090d576f173cc088fb4596d431},
  keywords = {book optimal-transport},
  timestamp = {2019-12-11T00:48:58.000+0100},
  title = {Optimal Transport for Applied Mathematicians. Calculus of Variations, PDEs and Modeling},
  url = {https://www.math.u-psud.fr/~filippo/OTAM-cvgmt.pdf},
  year = 2015
}


@article{10.2307/44162497,
 ISSN = {03067734, 17515823},
 URL = {http://www.jstor.org/stable/44162497},
 abstract = {The paper discusses the asymptotic validity of posterior inference of pseudo-{B}ayesian quantile regression methods with complete or censored data when an asymmetric Laplace likelihood is used. The asymmetric Laplace likelihood has a special place in the Bayesian quantile regression framework because the usual quantile regression estimator can be derived as the maximum likelihood estimator under such a model, and this working likelihood enables highly efficient Markov chain Monte Carlo algorithms for posterior sampling. However, it seems to be underrecognised that the stationary distribution for the resulting posterior does not provide valid posterior inference directly. We demonstrate that a simple adjustment to the covariance matrix of the posterior chain leads to asymptotically valid posterior inference. Our simulation results confirm that the posterior inference, when appropriately adjusted, is an attractive alternative to other asymptotic approximations in quantile regression, especially in the presence of censored data.},
 author = {Yunwen Yang and Huixia Judy Wang and Xuming He},
 journal = {International Statistical Review / Revue Internationale de Statistique},
 number = {3},
 pages = {327--344},
 publisher = {[Wiley, International Statistical Institute (ISI)]},
 title = {Posterior Inference in {B}ayesian Quantile Regression with Asymmetric Laplace Likelihood},
 urldate = {2022-05-09},
 volume = {84},
 year = {2016}
}

@Inbook{Haynes2013,
author="Haynes, Winston",
title="Maximum Likelihood Estimation",
bookTitle="Encyclopedia of Systems Biology",
year="2013",
publisher="Springer New York",
address="New York, NY",
pages="1190--1191",
isbn="978-1-4419-9863-7",
doi="10.1007/978-1-4419-9863-7_1235",
url="https://doi.org/10.1007/978-1-4419-9863-7_1235"
}

@article{10.1093/biomet/asx010,
    author = {Holmes, C. C. and Walker, S. G.},
    title = "{Assigning a value to a power likelihood in a general {B}ayesian model}",
    journal = {Biometrika},
    volume = {104},
    number = {2},
    pages = {497-503},
    year = {2017},
    month = {03},
    abstract = "{Bayesian robustness under model misspecification is a current area of active research. Among recent ideas is that of raising the likelihood function to a power. In this paper we discuss the choice of appropriate power and provide examples.}",
    issn = {0006-3444},
    doi = {10.1093/biomet/asx010},
    url = {https://doi.org/10.1093/biomet/asx010},
    eprint = {https://academic.oup.com/biomet/article-pdf/104/2/497/17239738/asx010.pdf},
}

@article{10.1214/aos/1024691240,
author = {Isabella Verdinelli and Larry Wasserman},
title = {{{B}ayesian goodness-of-fit testing using infinite-dimensional exponential families}},
volume = {26},
journal = {The Annals of Statistics},
number = {4},
publisher = {Institute of Mathematical Statistics},
pages = {1215 -- 1241},
keywords = {Bayes factor, consistency, Gaussian process prior, Markov chain Monte Carlo, nonparametric Bayesian inference, sieve},
year = {1998},
doi = {10.1214/aos/1024691240},
URL = {https://doi.org/10.1214/aos/1024691240}
}

@article{10.1214/aos/1176342871,
author = {Charles E. Antoniak},
title = {{Mixtures of Dirichlet Processes with Applications to {B}ayesian Nonparametric Problems}},
volume = {2},
journal = {The Annals of Statistics},
number = {6},
publisher = {Institute of Mathematical Statistics},
pages = {1152 -- 1174},
keywords = {Bayes, bio-assay, Dirichlet process, discrimination, Empirical Bayes, mixing distribution, nonparametric, Random measures},
year = {1974},
doi = {10.1214/aos/1176342871},
URL = {https://doi.org/10.1214/aos/1176342871}
}

@article{10.1214/aos/1176325623,
author = {Michael Lavine},
title = {{More Aspects of Polya Tree Distributions for Statistical Modelling}},
volume = {22},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1161 -- 1176},
keywords = {Dirichlet processes, Nonparametric regression, Robust Bayes, tail-free processes},
year = {1994},
doi = {10.1214/aos/1176325623},
URL = {https://doi.org/10.1214/aos/1176325623}
}

@misc{https://doi.org/10.48550/arxiv.2112.09206,
  doi = {10.48550/ARXIV.2112.09206},
  
  url = {https://arxiv.org/abs/2112.09206},
  
  author = {Kim, Eunseop and MacEachern, Steven and Peruggia, Mario},
  
  keywords = {Methodology (stat.ME), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Empirical Likelihood for the Analysis of Experimental Designs},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@Article{RePEc:eee:econom:v:115:y:2003:i:2:p:293-346,
  author={Chernozhukov, Victor and Hong, Han},
  title={{An MCMC approach to classical estimation}},
  journal={Journal of Econometrics},
  year=2003,
  volume={115},
  number={2},
  pages={293-346},
  month={August},
  keywords={},
  doi={},
  abstract={No abstract is available for this item.},
  url={https://ideas.repec.org/a/eee/econom/v115y2003i2p293-346.html}
}

@article{Dwork09differentialprivacy,
    author = {Cynthia Dwork and Jing Lei},
    title = {Differential privacy and robust statistics },
    journal={STOC '09: Proceedings of the forty-first annual ACM symposium on Theory of computing},
    pages={371-380},
    year = {2009},
    url = {https://dl.acm.org/doi/10.1145/1536414.1536466}
}

@misc{https://doi.org/10.48550/arxiv.2111.06578,
  doi = {10.48550/ARXIV.2111.06578},
  
  url = {https://arxiv.org/abs/2111.06578},
  
  author = {Liu, Xiyang and Kong, Weihao and Oh, Sewoong},
  
  keywords = {Statistics Theory (math.ST), Cryptography and Security (cs.CR), Information Theory (cs.IT), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Differential privacy and robust statistics in high dimensions},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{doi:10.1080/01621459.2019.1700130,
author = {Marco Avella-Medina},
title = {Privacy-Preserving Parametric Inference: A Case for Robust Statistics},
journal = {Journal of the American Statistical Association},
volume = {116},
number = {534},
pages = {969-983},
year  = {2021},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.2019.1700130},

URL = { 
        https://doi.org/10.1080/01621459.2019.1700130
    
},
eprint = { 
        https://doi.org/10.1080/01621459.2019.1700130
    
}

}

@misc{https://doi.org/10.48550/arxiv.2105.11570,
  doi = {10.48550/ARXIV.2105.11570},
  
  url = {https://arxiv.org/abs/2105.11570},
  
  author = {Du, Wei and Wu, Xintao},
  
  keywords = {Machine Learning (cs.LG), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Robust Fairness-aware Learning Under Sample Selection Bias},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{NEURIPS2020_37d097ca,
 author = {Wang, Serena and Guo, Wenshuo and Narasimhan, Harikrishna and Cotter, Andrew and Gupta, Maya and Jordan, Michael},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {5190--5203},
 publisher = {Curran Associates, Inc.},
 title = {Robust Optimization for Fairness with Noisy Protected Groups},
 url = {https://proceedings.neurips.cc/paper/2020/file/37d097caf1299d9aa79c2c2b843d2d78-Paper.pdf},
 volume = {33},
 year = {2020}
}

@INPROCEEDINGS{9156647,  author={Wang, Zhen and Hu, Guosheng and Hu, Qinghua},  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},   title={Training Noise-Robust Deep Neural Networks via Meta-Learning},   year={2020},  volume={},  number={},  pages={4523-4532},  doi={10.1109/CVPR42600.2020.00458}}

@inproceedings{han2018coteaching,
  title={Co-teaching: Robust training of deep neural networks with extremely noisy labels},
  author={Han, Bo and Yao, Quanming and Yu, Xingrui and Niu, Gang and Xu, Miao and Hu, Weihua and Tsang, Ivor and Sugiyama, Masashi},
  booktitle={NeurIPS},
  pages={8535--8545},
  year={2018}
}

@article{doi:10.1080/02331934.2019.1655738,
author = {Zhi Chen and Pengqian Yu and William B. Haskell},
title = {Distributionally robust optimization for sequential decision-making},
journal = {Optimization},
volume = {68},
number = {12},
pages = {2397-2426},
year  = {2019},
publisher = {Taylor & Francis},
doi = {10.1080/02331934.2019.1655738},

URL = { 
        https://doi.org/10.1080/02331934.2019.1655738
    
},
eprint = { 
        https://doi.org/10.1080/02331934.2019.1655738
    
}

}

@inproceedings{NIPS2010_19f3cd30,
 author = {Xu, Huan and Mannor, Shie},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Lafferty and C. Williams and J. Shawe-Taylor and R. Zemel and A. Culotta},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Distributionally Robust Markov Decision Processes},
 url = {https://proceedings.neurips.cc/paper/2010/file/19f3cd308f1455b3fa09a282e0d496f4-Paper.pdf},
 volume = {23},
 year = {2010}
}

@inproceedings{
Shafahi2020Adversarially,
title={Adversarially robust transfer learning},
author={Ali Shafahi and Parsa Saadatpanah and Chen Zhu and Amin Ghiasi and Christoph Studer and David Jacobs and Tom Goldstein},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=ryebG04YvB}
}

@article{doi:10.1080/01621459.2021.1909599,
author = {Jacob Fiksel and Abhirup Datta and Agbessi Amouzou and Scott Zeger},
title = {Generalized {B}ayes Quantification Learning under Dataset Shift},
journal = {Journal of the American Statistical Association},
volume = {0},
number = {0},
pages = {1-19},
year  = {2021},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.2021.1909599},

URL = { 
        https://doi.org/10.1080/01621459.2021.1909599
    
},
eprint = { 
        https://doi.org/10.1080/01621459.2021.1909599
    
}

}

@article{10.1214/009053606000000029,
author = {B. J. K. Kleijn and A. W. van der Vaart},
title = {{Misspecification in infinite-dimensional Bayesian statistics}},
volume = {34},
journal = {The Annals of Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {837 -- 877},
keywords = {infinite-dimensional model, misspecification, posterior distribution, rate of convergence},
year = {2006},
doi = {10.1214/009053606000000029},
URL = {https://doi.org/10.1214/009053606000000029}
}

@article{10.2307/24310519,
 ISSN = {10170405, 19968507},
 URL = {http://www.jstor.org/stable/24310519},
 abstract = {In this paper, we study the asymptotic properties of a sequence of posterior distributions based on an independent and identically distributed sample and when the Bayesian model is misspecified. We find a sufficient condition on the prior for the posterior to accumulate around the densities in the model closest in the Kullback–Leibler sense to the true density function. Examples are presented.},
 author = {Pierpaolo De Blasi and Stephen G. Walker},
 journal = {Statistica Sinica},
 number = {1},
 pages = {169--187},
 publisher = {Institute of Statistical Science, Academia Sinica},
 title = {BAYESIAN ASYMPTOTICS WITH MISSPECIFIED MODELS},
 urldate = {2022-05-16},
 volume = {23},
 year = {2013}
}

@Manual{r,
     title = {R: A Language and Environment for Statistical Computing},
     author = {{R Core Team}},
     organization = {R Foundation for Statistical Computing},
     address = {Vienna, Austria},
     year = {2017},
     url = {https://www.R-project.org/},
   }
   
   
@inproceedings{gratch-etal-2014-distress,
    title = "The Distress Analysis Interview Corpus of human and computer interviews",
    author = "Gratch, Jonathan  and
      Artstein, Ron  and
      Lucas, Gale  and
      Stratou, Giota  and
      Scherer, Stefan  and
      Nazarian, Angela  and
      Wood, Rachel  and
      Boberg, Jill  and
      DeVault, David  and
      Marsella, Stacy  and
      Traum, David  and
      Rizzo, Skip  and
      Morency, Louis-Philippe",
    booktitle = "Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)",
    month = may,
    year = "2014",
    address = "Reykjavik, Iceland",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2014/pdf/508_Paper.pdf",
    pages = "3123--3128",
    abstract = "The Distress Analysis Interview Corpus (DAIC) contains clinical interviews designed to support the diagnosis of psychological distress conditions such as anxiety, depression, and post traumatic stress disorder. The interviews are conducted by humans, human controlled agents and autonomous agents, and the participants include both distressed and non-distressed individuals. Data collected include audio and video recordings and extensive questionnaire responses; parts of the corpus have been transcribed and annotated for a variety of verbal and non-verbal features. The corpus has been used to support the creation of an automated interviewer agent, and for research on the automatic identification of psychological distress.",
}

@article{10.2307/2315957,
 ISSN = {00029890, 19300972},
 URL = {http://www.jstor.org/stable/2315957},
 author = {A. J. Maria},
 journal = {The American Mathematical Monthly},
 number = {10},
 pages = {1096--1098},
 publisher = {Mathematical Association of America},
 title = {A Remark on Stirling's Formula},
 urldate = {2022-10-03},
 volume = {72},
 year = {1965}
}

@misc{https://doi.org/10.48550/arxiv.1301.3781,
  doi = {10.48550/ARXIV.1301.3781},
  
  url = {https://arxiv.org/abs/1301.3781},
  
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Efficient Estimation of Word Representations in Vector Space},
  
  publisher = {arXiv},
  
  year = {2013},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{vilnis-etal-2018-probabilistic,
    title = "Probabilistic Embedding of Knowledge Graphs with Box Lattice Measures",
    author = "Vilnis, Luke  and
      Li, Xiang  and
      Murty, Shikhar  and
      McCallum, Andrew",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1025",
    doi = "10.18653/v1/P18-1025",
    pages = "263--272",
    abstract = "Embedding methods which enforce a partial order or lattice structure over the concept space, such as Order Embeddings (OE), are a natural way to model transitive relational data (e.g. entailment graphs). However, OE learns a deterministic knowledge base, limiting expressiveness of queries and the ability to use uncertainty for both prediction and learning (e.g. learning from expectations). Probabilistic extensions of OE have provided the ability to somewhat calibrate these denotational probabilities while retaining the consistency and inductive bias of ordered models, but lack the ability to model the negative correlations found in real-world knowledge. In this work we show that a broad class of models that assign probability measures to OE can never capture negative correlation, which motivates our construction of a novel box lattice and accompanying probability measure to capture anti-correlation and even disjoint concepts, while still providing the benefits of probabilistic modeling, such as the ability to perform rich joint and conditional queries over arbitrary sets of concepts, and both learning from and predicting calibrated uncertainty. We show improvements over previous approaches in modeling the Flickr and WordNet entailment graphs, and investigate the power of the model.",
}

@inproceedings{ijcai2021p278,
  title     = {Unsupervised Knowledge Graph Alignment by Probabilistic Reasoning and Semantic Embedding},
  author    = {Qi, Zhiyuan and Zhang, Ziheng and Chen, Jiaoyan and Chen, Xi and Xiang, Yuejia and Zhang, Ningyu and Zheng, Yefeng},
  booktitle = {Proceedings of the Thirtieth International Joint Conference on
               Artificial Intelligence, {IJCAI-21}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Zhi-Hua Zhou},
  pages     = {2019--2025},
  year      = {2021},
  month     = {8},
  note      = {Main Track},
  doi       = {10.24963/ijcai.2021/278},
  url       = {https://doi.org/10.24963/ijcai.2021/278},
}

@inproceedings{pennington2014glove,
  added-at = {2016-02-18T12:02:38.000+0100},
  author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  biburl = {https://www.bibsonomy.org/bibtex/2a6e77a38c13e374ab250e13ae22993ec/thoni},
  booktitle = {EMNLP},
  interhash = {29813227df1eea94efa14c7df2b5553a},
  intrahash = {a6e77a38c13e374ab250e13ae22993ec},
  keywords = {deeplearning deepwiki glove semantic},
  pages = {1532--1543},
  timestamp = {2016-09-06T08:23:07.000+0200},
  title = {Glove: Global Vectors for Word Representation.},
  volume = 14,
  year = 2014
}

@conference{2be2c4c3e8504383bf53ebeb79f9caf4,
title = "Zero-shot learning by convex combination of semantic embeddings",
abstract = "Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces. In some cases the embedding space is trained jointly with the image transformation. In other cases the semantic embedding space is established by an independent natural language processing task, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional n-way classification framing of image understanding, particularly in terms of the promise for zero-shot learning – the ability to correctly annotate images of previously unseen object categories. In this paper, we propose a simple method for constructing an image embedding system from any existing n-way image classifier and a semantic word embedding model, which contains the n class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no additional training. We show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes, and indeed outperforms state of the art methods on the ImageNet zero-shot learning task.",
author = "Mohammad Norouzi and Tomas Mikolov and Samy Bengio and Yoram Singer and Jonathon Shlens and Andrea Frome and Corrado, {Greg S.} and Jeffrey Dean",
year = "2014",
month = jan,
day = "1",
language = "English (US)",
note = "2nd International Conference on Learning Representations, ICLR 2014 ; Conference date: 14-04-2014 Through 16-04-2014",
}

@article{Jebara2004ProbabilityPK,
  title={Probability Product Kernels},
  author={Tony Jebara and Risi Kondor and Andrew G. Howard},
  journal={J. Mach. Learn. Res.},
  year={2004},
  volume={5},
  pages={819-844}
}

@misc{https://doi.org/10.48550/arxiv.1412.6623,
  doi = {10.48550/ARXIV.1412.6623},
  
  url = {https://arxiv.org/abs/1412.6623},
  
  author = {Vilnis, Luke and McCallum, Andrew},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Word Representations via Gaussian Embedding},
  
  publisher = {arXiv},
  
  year = {2014},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@InProceedings{pmlr-v108-singh20a,
  title = 	 {Context Mover’s Distance &amp; Barycenters: Optimal Transport of Contexts for Building Representations},
  author =       {Singh, Sidak Pal and Hug, Andreas and Dieuleveut, Aymeric and Jaggi, Martin},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {3437--3449},
  year = 	 {2020},
  editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v108/singh20a/singh20a.pdf},
  url = 	 {https://proceedings.mlr.press/v108/singh20a.html}
}


@InProceedings{muzellec2019generalizing,
 author = {Muzellec, Boris and Cuturi, Marco},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Generalizing Point Embeddings using the {W}asserstein Space of Elliptical Distributions},
 url = {https://proceedings.neurips.cc/paper/2018/file/b613e70fd9f59310cf0a8d33de3f2800-Paper.pdf},
 volume = {31},
 year = {2018}
}


@book{LevinPeresWilmer2006,
  added-at = {2010-01-19T17:51:27.000+0100},
  author = {Levin, David A. and Peres, Yuval and Wilmer, Elizabeth L.},
  biburl = {https://www.bibsonomy.org/bibtex/2097dc4d1d0e412b2444f540b04110797/tmalsburg},
  interhash = {61354795a6accb6407bfdbf04753a683},
  intrahash = {097dc4d1d0e412b2444f540b04110797},
  keywords = {markovchains probabilitytheory textbook},
  publisher = {American Mathematical Society},
  timestamp = {2010-01-19T17:51:27.000+0100},
  title = {{Markov chains and mixing times}},
  url = {http://scholar.google.com/scholar.bib?q=info:3wf9IU94tyMJ:scholar.google.com/&output=citation&hl=en&as_sdt=2000&ct=citation&cd=0},
  year = 2006
}




@book{alma991023405949705251,
author = {Pinsker, M. S.},
address = {San Francisco},
booktitle = {Information and information stability of random variables and processes},
keywords = {Information theory},
language = {eng;und},
lccn = {64014623},
publisher = {Holden-Day},
series = {Holden-Day series in time series analysis},
title = {Information and information stability of random variables and processes / by M.S. Pinsker. Translated and edited by Amiel Feinstein.},
year = {1964},
}

@misc{https://doi.org/10.48550/arxiv.1712.01504,
  doi = {10.48550/ARXIV.1712.01504},
  
  url = {https://arxiv.org/abs/1712.01504},
  
  author = {Bhatia, Rajendra and Jain, Tanvi and Lim, Yongdo},
  
  keywords = {Functional Analysis (math.FA), FOS: Mathematics, FOS: Mathematics},
  
  title = {On the Bures-{W}asserstein distance between positive definite matrices},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{https://doi.org/10.1111/rssa.12613,
author = {Aliverti, Emanuele and Lum, Kristian and Johndrow, James E. and Dunson, David B.},
title = {Removing the influence of group variables in high-dimensional predictive modelling},
journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
volume = {184},
number = {3},
pages = {791-811},
keywords = {batch effects, constrained optimization, criminal justice, neuroscience, orthogonal predictions, predictive modelling, singular value decomposition},
doi = {https://doi.org/10.1111/rssa.12613},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssa.12613},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssa.12613},
abstract = {Abstract In many application areas, predictive models are used to support or make important decisions. There is increasing awareness that these models may contain spurious or otherwise undesirable correlations. Such correlations may arise from a variety of sources, including batch effects, systematic measurement errors or sampling bias. Without explicit adjustment, machine learning algorithms trained using these data can produce out-of-sample predictions which propagate these undesirable correlations. We propose a method to pre-process the training data, producing an adjusted dataset that is statistically independent of the nuisance variables with minimum information loss. We develop a conceptually simple approach for creating an adjusted dataset in high-dimensional settings based on a constrained form of matrix decomposition. The resulting dataset can then be used in any predictive algorithm with the guarantee that predictions will be statistically independent of the nuisance variables. We develop a scalable algorithm for implementing the method, along with theory support in the form of independence guarantees and optimality. The method is illustrated on some simulation examples and applied to two case studies: removing machine-specific correlations from brain scan data, and removing ethnicity information from a dataset used to predict recidivism. That the motivation for removing undesirable correlations is quite different in the two applications illustrates the broad applicability of our approach.
%},
year = {2021}
}

@inproceedings{90450a4b5b49471b8111fc88355f2e7f,
title = "Fair regression: Quantitative definitions and reduction-based algorithms",
abstract = "In this paper, we study the prediction of a real-valued target, such as a risk score or recidivism rate, while guaranteeing a quantitative notion of fairness with respect to a protected attribute such as gender or race. We call this class of problems fair regression. We propose general schemes for fair regression under two notions of fairness: (1) statistical parity, which asks that the prediction be statistically independent of the protected attribute, and (2) bounded group loss, which asks that the prediction error restricted to any protected group remain below some pre-determined level. While we only study these two notions of fairness, our schemes are applicable to arbitrary Lipschitzcontinuous losses, and so they encompass least-squares regression, logistic regression, quantile regression, and many other tasks. Our schemes only require access to standard risk minimization algorithms (such as standard classification or least-squares regression) while providing theoretical guarantees on the optimality and fairness of the obtained solutions. In addition to analyzing theoretical properties of our schemes, we empirically demonstrate their ability to uncover fairness-accuracy frontiers on several standard datasets.",
author = "Alekh Agarwal and Miroslav Dud{\'i}k and Wu, {Zhiwei Steven}",
year = "2019",
month = jan,
day = "1",
language = "English (US)",
series = "36th International Conference on Machine Learning, ICML 2019",
publisher = "International Machine Learning Society (IMLS)",
pages = "166--183",
booktitle = "36th International Conference on Machine Learning, ICML 2019",
note = "36th International Conference on Machine Learning, ICML 2019 ; Conference date: 09-06-2019 Through 15-06-2019",
}

@article{Nabi2018, title={Fair Inference on Outcomes}, volume={32}, url={https://ojs.aaai.org/index.php/AAAI/article/view/11553}, DOI={10.1609/aaai.v32i1.11553}, abstractNote={ }, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Nabi, Razieh and Shpitser, Ilya}, year={2018}, month={Apr.} }

@article{Ferguson,
author = {Thomas S. Ferguson},
title = {{A {B}ayesian Analysis of Some Nonparametric Problems}},
volume = {1},
journal = {The Annals of Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {209 -- 230},
year = {1973},
doi = {10.1214/aos/1176342360},
URL = {https://doi.org/10.1214/aos/1176342360}
}


@article{McAuliffe,
author = {McAuliffe and Blei and Jordan},
title = {{Nonparametric empirical {B}ayes for the Dirichlet process mixture model}},
volume = {1},
journal = {Stat Comput},
number = {2},
publisher = {},
pages = {5-14},
year = {2006},
doi = {},
URL = {}
}

@article{IZ,
    author = {Ishwaran, H and Zarepour, M},
    title = "{Markov chain Monte Carlo in approximate Dirichlet and beta two-parameter process hierarchical models}",
    journal = {Biometrika},
    volume = {87},
    number = {2},
    pages = {371-390},
    year = {2000},
    month = {06},
    abstract = "{We present some easy-to-construct random probability measures which approximate the Dirichlet process and an extension which we will call the beta two-parameter process. The nature of these constructions makes it simple to implement Markov chain Monte Carlo algorithms for fitting nonparametric hierarchical models. For the Dirichlet process, we consider a truncation approximation as well as a weak limit approximation based on a mixture of Dirichlet processes. The same type of truncation approximation can also be applied to the beta two-parameter process. Both methods lead to posteriors which can be fitted using Markov chain Monte Carlo algorithms that take advantage of blocked coordinate updates. These algorithms promote rapid mixing of the Markov chain and can be readily applied to normal mean mixture models and to density estimation problems. We prefer the truncation approximations, since a simple device for monitoring the adequacy of the approximation can be easily computed from the output of the Gibbs sampler. Furthermore, for the Dirichlet process, the truncation approximation offers an exponentially higher degree of accuracy over the weak limit approximation for the same computational effort. We also find that a certain beta two-parameter process may be suitable for finite mixture modelling because the distinct number of sampled values from this process tends to match closely the number of components of the underlying mixture distribution.}",
    issn = {0006-3444},
    doi = {10.1093/biomet/87.2.371},
    url = {https://doi.org/10.1093/biomet/87.2.371},
    eprint = {https://academic.oup.com/biomet/article-pdf/87/2/371/591069/870371.pdf},
}

@article{EscobarWest,
author = { Michael D.   Escobar  and  Mike   West },
title = {{B}ayesian Density Estimation and Inference Using Mixtures},
journal = {Journal of the American Statistical Association},
volume = {90},
number = {430},
pages = {577-588},
year  = {1995},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.1995.10476550},

URL = { 
    
    
        https://www.tandfonline.com/doi/abs/10.1080/01621459.1995.10476550
    

},
eprint = { 
    
    
        https://www.tandfonline.com/doi/pdf/10.1080/01621459.1995.10476550
    

}

}

@article{Chib2018,
author = {Siddhartha Chib and Minchul Shin and Anna Simoni},
title = {{B}ayesian Estimation and Comparison of Moment Condition Models},
journal = {Journal of the American Statistical Association},
volume = {113},
number = {524},
pages = {1656-1668},
year  = {2018},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.2017.1358172},

URL = { 
    
        https://doi.org/10.1080/01621459.2017.1358172
    
    

},
eprint = { 
    
        https://doi.org/10.1080/01621459.2017.1358172
    
    

}

}

@article{SkewNormal,
    author = {Azzalini, A. and Valle, A. DALLA},
    title = "{The multivariate skew-normal distribution}",
    journal = {Biometrika},
    volume = {83},
    number = {4},
    pages = {715-726},
    year = {1996},
    month = {12},
    abstract = "{The paper extends earlier work on the so-called skew-normal distribution, a family of distributions including the normal, but with an extra parameter to regulate skewness. The present work introduces a multivariate parametric family such that the marginal densities are scalar skew-normal, and studies its properties, with special emphasis on the bivariate case.}",
    issn = {0006-3444},
    doi = {10.1093/biomet/83.4.715},
    url = {https://doi.org/10.1093/biomet/83.4.715},
    eprint = {https://academic.oup.com/biomet/article-pdf/83/4/715/702865/83-4-715.pdf},
}

@misc{sandwitch,
  doi = {10.48550/ARXIV.1211.0087},
  
  url = {https://arxiv.org/abs/1211.0087},
  
  author = {Hoff, Peter and Wakefield, Jon},
  
  keywords = {Methodology (stat.ME), FOS: Computer and information sciences, FOS: Computer and information sciences, 62G35},
  
  title = {{B}ayesian sandwich posteriors for pseudo-true parameters},
  
  publisher = {arXiv},
  
  year = {2012},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Bernton_2019,
	doi = {10.1111/rssb.12312},
  
	url = {https://doi.org/10.1111%2Frssb.12312},
  
	year = 2019,
	month = {feb},
  
	publisher = {Oxford University Press ({OUP})},
  
	volume = {81},
  
	number = {2},
  
	pages = {235--269},
  
	author = {Espen Bernton and Pierre E. Jacob and Mathieu Gerber and Christian P. Robert},
  
	title = {Approximate {B}ayesian computation with the {W}asserstein distance},
  
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)}
}

@article{auglag1,
author = {Conn, Andrew R. and Gould, Nicholas I. M. and Toint, Philippe},
title = {A Globally Convergent Augmented Lagrangian Algorithm for Optimization with General Constraints and Simple Bounds},
journal = {SIAM Journal on Numerical Analysis},
volume = {28},
number = {2},
pages = {545-572},
year = {1991},
doi = {10.1137/0728030},

URL = { 
    
        https://doi.org/10.1137/0728030
    
    

},
eprint = { 
    
        https://doi.org/10.1137/0728030
    
    

}
,
    abstract = { The global and local convergence properties of a class of augmented Lagrangian methods for solving nonlinear programming problems are considered. In such methods, simple bound constraints are treated separately from more general constraints and the stopping rules for the inner minimization algorithm have this in mind. Global convergence is proved, and it is established that a potentially troublesome penalty parameter is bounded away from zero. }
}

@article{auglag2,
author = { E.G.   Birgin  and  J.M.   Martínez },
title = {Improving ultimate convergence of an augmented Lagrangian method},
journal = {Optimization Methods and Software},
volume = {23},
number = {2},
pages = {177-195},
year  = {2008},
publisher = {Taylor & Francis},
doi = {10.1080/10556780701577730},

URL = { 
    
        https://doi.org/10.1080/10556780701577730
    
    

},
eprint = { 
    
        https://doi.org/10.1080/10556780701577730
    
    

}

}

@Article{cvxr2020,
    title = {{CVXR}: An {R} Package for Disciplined Convex Optimization},
    author = {Anqi Fu and Balasubramanian Narasimhan and Stephen Boyd},
    journal = {Journal of Statistical Software},
    year = {2020},
    volume = {94},
    number = {14},
    pages = {1--34},
    doi = {10.18637/jss.v094.i14},
  }

@Article{nlopt,
    title = {The NLopt nonlinear-optimization package},
    author = {Steven G. Johnson},
    journal = {The Comprehensive R Archive Network},
    year = {2022},
  }
@Article{TCFOCS,
    title = {Templates for convex cone problems with applications to sparse signal recovery},
    author = {Becker and Candès and Grant},
    journal = {Math. Prog. Comp},
    year = {2011},
  }

@Manual{RCore,
     title = {R: A Language and Environment for Statistical Computing},
     author = {{R Core Team}},
     organization = {R Foundation for Statistical Computing},
     address = {Vienna, Austria},
     year = {2022},
     url = {https://www.R-project.org/},
}

@incollection{gb08,
  author    = {Michael Grant and Stephen Boyd},
  title     = {Graph implementations for nonsmooth convex programs},
  booktitle = {Recent Advances in Learning and Control},
  series    = {Lecture Notes in Control and Information Sciences},
  editor    = {V. Blondel and S. Boyd and H. Kimura},
  publisher = {Springer-Verlag Limited},
  pages     = {95--110},
  year      = 2008,
  note      = {\url{http://stanford.edu/~boyd/graph_dcp.html}}
}

@article{martin2019,
    author = {Syring, Nicholas and Martin, Ryan},
    title = "{Calibrating general posterior credible regions}",
    journal = {Biometrika},
    volume = {106},
    number = {2},
    pages = {479-486},
    year = {2018},
    month = {12},
    abstract = "{Calibration of credible regions derived from under- or misspecified models is an important and challenging problem. In this paper, we introduce a scalar tuning parameter that controls the posterior distribution spread, and develop a Monte Carlo algorithm that sets this parameter so that the corresponding credible region achieves the nominal frequentist coverage probability.}",
    issn = {0006-3444},
    doi = {10.1093/biomet/asy054},
    url = {https://doi.org/10.1093/biomet/asy054},
    eprint = {https://academic.oup.com/biomet/article-pdf/106/2/479/28575455/asy054.pdf},
}

@misc{epsiloncontamination,
  doi = {10.48550/ARXIV.1511.04144},
  
  url = {https://arxiv.org/abs/1511.04144},
  
  author = {Chen, Mengjie and Gao, Chao and Ren, Zhao},
  
  keywords = {Statistics Theory (math.ST), FOS: Mathematics, FOS: Mathematics},
  
  title = {A General Decision Theory for Huber's $ε$-Contamination Model},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{MFM-SBM,
author = {Junxian Geng and Anirban Bhattacharya and Debdeep Pati},
title = {Probabilistic Community Detection With Unknown Number of Communities},
journal = {Journal of the American Statistical Association},
volume = {114},
number = {526},
pages = {893-905},
year  = {2019},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.2018.1458618},

URL = { 
    
        https://doi.org/10.1080/01621459.2018.1458618
    
    

},
eprint = { 
    
        https://doi.org/10.1080/01621459.2018.1458618
    
    

}

}

@article{Ex-SBM,
author = {Sirio Legramanti and Tommaso Rigon and Daniele Durante and David B. Dunson},
title = {{Extended stochastic block models with application to criminal networks}},
volume = {16},
journal = {The Annals of Applied Statistics},
number = {4},
publisher = {Institute of Mathematical Statistics},
pages = {2369 -- 2395},
keywords = {Bayesian nonparametrics, Gibbs-type prior, network, product partition model},
year = {2022},
doi = {10.1214/21-AOAS1595},
URL = {https://doi.org/10.1214/21-AOAS1595}
}

@misc{MRF-MFM,
  doi = {10.48550/ARXIV.2002.06678},
  
  url = {https://arxiv.org/abs/2002.06678},
  
  author = {Zhao, Peng and Yang, Hou-Cheng and Dey, Dipak K. and Hu, Guanyu},
  
  keywords = {Methodology (stat.ME), Applications (stat.AP), Computation (stat.CO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {{B}ayesian Spatial Homogeneity Pursuit Regression for Count Value Data},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Homogeneity,
author = {Guanyu Hu and Junxian Geng and Yishu Xue and Huiyan Sang},
title = {{{B}ayesian Spatial Homogeneity Pursuit of Functional Data: An Application to the U.S. Income Distribution}},
journal = {Bayesian Analysis},
publisher = {International Society for Bayesian Analysis},
pages = {1 -- 27},
keywords = {Lorenz curve, Markov random field, mixture of finite mixtures, spatial functional data clustering},
year = {2022},
doi = {10.1214/22-BA1320},
URL = {https://doi.org/10.1214/22-BA1320}
}

@misc{cai,
  doi = {10.48550/ARXIV.2007.04470},
  
  url = {https://arxiv.org/abs/2007.04470},
  
  author = {Cai, Diana and Campbell, Trevor and Broderick, Tamara},
  
  keywords = {Statistics Theory (math.ST), Methodology (stat.ME), Machine Learning (stat.ML), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Finite mixture models do not reliably learn the number of components},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{cai2,
  author = {Cai, Diana and Campbell, Trevor and Broderick, Tamara},
  title = {Power posteriors do not reliably learn the number of components in a finite mixture},
  publisher = {arXiv},
  url = {https://openreview.net/pdf?id=BRb4tLp6A3o},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
