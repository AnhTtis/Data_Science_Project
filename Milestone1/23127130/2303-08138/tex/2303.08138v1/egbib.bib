% @String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
% @String(IJCV = {Int. J. Comput. Vis.})
% @String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
% @String(ICCV= {Int. Conf. Comput. Vis.})
% @String(ECCV= {Eur. Conf. Comput. Vis.})
% @String(NIPS= {Adv. Neural Inform. Process. Syst.})
% @String(ICPR = {Int. Conf. Pattern Recog.})
% @String(BMVC= {Brit. Mach. Vis. Conf.})
% @String(TOG= {ACM Trans. Graph.})
% @String(TIP  = {IEEE Trans. Image Process.})
% @String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
% @String(TMM  = {IEEE Trans. Multimedia})
% @String(ACMMM= {ACM Int. Conf. Multimedia})
% @String(ICME = {Int. Conf. Multimedia and Expo})
% @String(ICASSP=	{ICASSP})
% @String(ICIP = {IEEE Int. Conf. Image Process.})
% @String(ACCV  = {ACCV})
% @String(ICLR = {Int. Conf. Learn. Represent.})
% @String(IJCAI = {IJCAI})
% @String(PR   = {Pattern Recognition})
% @String(AAAI = {AAAI})
% @String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
% @String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

% @String(SPL	= {IEEE Sign. Process. Letters})
% @String(VR   = {Vis. Res.})
% @String(JOV	 = {J. Vis.})
% @String(TVC  = {The Vis. Comput.})
% @String(JCST  = {J. Comput. Sci. Tech.})
% @String(CGF  = {Comput. Graph. Forum})
% @String(CVM = {Computational Visual Media})


% @String(PAMI  = {IEEE TPAMI})
% @String(IJCV  = {IJCV})
% @String(CVPR  = {CVPR})
% @String(ICCV  = {ICCV})
% @String(ECCV  = {ECCV})
% @String(NIPS  = {NeurIPS})
% @String(ICPR  = {ICPR})
% @String(BMVC  =	{BMVC})
% @String(TOG   = {ACM TOG})
% @String(TIP   = {IEEE TIP})
% @String(TVCG  = {IEEE TVCG})
% @String(TCSVT = {IEEE TCSVT})
% @String(TMM   =	{IEEE TMM})
% @String(ACMMM = {ACM MM})
% @String(ICME  =	{ICME})
% @String(ICASSP=	{ICASSP})
% @String(ICIP  = {ICIP})
% @String(ACCV  = {ACCV})
% @String(ICLR  = {ICLR})
% @String(IJCAI = {IJCAI})
% @String(PR = {PR})
% @String(AAAI = {AAAI})
% @String(CVPRW= {CVPRW})
% @String(CSVT = {IEEE TCSVT})



@article{cifar,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}

@techreport{cub200,
	Title = {The caltech-ucsd birds200-2011 dataset},
	Author = {Wah, C. and Branson, S. and Welinder, P. and Perona, P. and Belongie, S.},
	Year = {2011},
	Institution = {California Institute of Technology},
	Number = {CNS-TR-2011-001}
}

@inproceedings{nabirds,
  author    = {Grant Van Horn and
               Steve Branson and
               Ryan Farrell and
               Scott Haber and
               Jessie Barry and
               Panos Ipeirotis and
               Pietro Perona and
               Serge J. Belongie},
  title     = {Building a bird recognition app and large scale dataset with citizen scientists: The fine print in fine-grained dataset collection},
  booktitle = {CVPR},
  year      = {2015},
}

@inproceedings{oxford_flowers,
  author    = {Maria{-}Elena Nilsback and
               Andrew Zisserman},
  title     = {Automated Flower Classification over a Large Number of Classes},
  booktitle = {ICVGIP},
  year      = {2008},
}

@inproceedings{stanford_dogs,
author = {Aditya Khosla and Nityananda Jayadevaprakash and Bangpeng Yao and Li Fei-Fei},
title = {Novel Dataset for Fine-Grained Image Categorization},
booktitle = {CVPR Workshops},
year = {2011}
}

@inproceedings{food101,
  author    = {Lukas Bossard and
               Matthieu Guillaumin and
               Luc Van Gool},
  title     = {Food-101 - Mining Discriminative Components with Random Forests},
  booktitle = {ECCV},
  year      = {2014}
}

@inproceedings{dtd,
  author    = {Mircea Cimpoi and
               Subhransu Maji and
               Iasonas Kokkinos and
               Sammy Mohamed and
               Andrea Vedaldi},
  title     = {Describing Textures in the Wild},
  booktitle = {CVPR},
  year      = {2014}
}

@article{svhn,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  year={2011}
}

@article{gtsrb,
  title={Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition},
  author={Stallkamp, Johannes and Schlipsing, Marc and Salmen, Jan and Igel, Christian},
  journal={Neural networks},
  year={2012}
}

@inproceedings{adapter1,
  author    = {Neil Houlsby and
               Andrei Giurgiu and
               Stanislaw Jastrzebski and
               Bruna Morrone and
               Quentin de Laroussilhe and
               Andrea Gesmundo and
               Mona Attariyan and
               Sylvain Gelly},
  title     = {Parameter-Efficient Transfer Learning for {NLP}},
  booktitle = {ICML},
  year      = {2019}
}

@inproceedings{adapter2,
  author    = {Jonas Pfeiffer and
               Andreas R{\"{u}}ckl{\'{e}} and
               Clifton Poth and
               Aishwarya Kamath and
               Ivan Vulic and
               Sebastian Ruder and
               Kyunghyun Cho and
               Iryna Gurevych},
  title     = {AdapterHub: {A} Framework for Adapting Transformers},
  booktitle = {EMNLP},
  year      = {2020}
}

@inproceedings{guo2021parameter,
  title={Parameter-Efficient Transfer Learning with Diff Pruning},
  author={Guo, Demi and Rush, Alexander M and Kim, Yoon},
  booktitle={ACL},
  year={2021}
}

@inproceedings{he2021towards,
  title={Towards a Unified View of Parameter-Efficient Transfer Learning},
  author={He, Junxian and Zhou, Chunting and Ma, Xuezhe and Berg-Kirkpatrick, Taylor and Neubig, Graham},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{hu2021lora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{zaken2022bitfit,
  title={BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models},
  author={Zaken, Elad Ben and Goldberg, Yoav and Ravfogel, Shauli},
  booktitle={ACL},
  year={2022}
}

@inproceedings{chen2022adaptformer,
  title={AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition},
  author={Chen, Shoufa and Ge, Chongjian and Tong, Zhan and Wang, Jiangliu and Song, Yibing and Wang, Jue and Luo, Ping},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{lian2022scaling,
  title={Scaling \& Shifting Your Features: A New Baseline for Efficient Model Tuning},
  author={Lian, Dongze and Zhou, Daquan and Feng, Jiashi and Wang, Xinchao},
  booktitle={NeurIPS},
  year={2022}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{zhang2020side,
  title={Side-tuning: a baseline for network adaptation via additive side networks},
  author={Zhang, Jeffrey O and Sax, Alexander and Zamir, Amir and Guibas, Leonidas and Malik, Jitendra},
  booktitle={ECCV},
  year={2020}
}

@inproceedings{cai2020tinytl,
  title={Tinytl: Reduce memory, not parameters for efficient on-device learning},
  author={Cai, Han and Gan, Chuang and Zhu, Ligeng and Han, Song},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{rebuffi2017learning,
  title={Learning multiple visual domains with residual adapters},
  author={Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{jia2022vpt,
  title={Visual Prompt Tuning},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  booktitle={ECCV},
  year={2022}
}

@article{bahng2022vp,
         title={Exploring Visual Prompts for Adapting Large-Scale Models}, 
         author={Hyojin Bahng and Ali Jahanian and Swami Sankaranarayanan and Phillip Isola},
         journal={arXiv preprint arXiv:2203.17274},
         year={2022}
}

@inproceedings{DosovitskiyB0WZ21,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  booktitle = {ICLR},
  year      = {2021}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{TouvronCDMSJ21,
  author    = {Hugo Touvron and
               Matthieu Cord and
               Matthijs Douze and
               Francisco Massa and
               Alexandre Sablayrolles and
               Herv{\'{e}} J{\'{e}}gou},
  title     = {Training data-efficient image transformers {\&} distillation through attention},
  booktitle = {ICML},
  year      = {2021}
}

@inproceedings{dong2022cswin,
  title={Cswin transformer: A general vision transformer backbone with cross-shaped windows},
  author={Dong, Xiaoyi and Bao, Jianmin and Chen, Dongdong and Zhang, Weiming and Yu, Nenghai and Yuan, Lu and Chen, Dong and Guo, Baining},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{liu2022swin,
  title={Swin transformer v2: Scaling up capacity and resolution},
  author={Liu, Ze and Hu, Han and Lin, Yutong and Yao, Zhuliang and Xie, Zhenda and Wei, Yixuan and Ning, Jia and Cao, Yue and Zhang, Zheng and Dong, Li and others},
  booktitle={CVPR},
  year={2022}
}

@Inproceedings{Chen21mocov3,
  author={Xinlei Chen and Saining Xie and Kaiming He},
  title={An Empirical Study of Training Self-Supervised Vision Transformers},
  booktitle={ICCV},
  year={2021}
}

@Inproceedings{chen2020simclr,
  title={A Simple Framework for Contrastive Learning of Visual Representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={ICML},
  year={2020}
}

@inproceedings{bao2021beit,
  title={BEiT: BERT Pre-Training of Image Transformers},
  author={Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{zhai2022scaling,
  title={Scaling vision transformers},
  author={Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{chen2021empirical,
  title={An empirical study of training self-supervised vision transformers},
  author={Chen, Xinlei and Xie, Saining and He, Kaiming},
  booktitle={CVPR},
  year={2021}
}

@article{liu2021pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={arXiv preprint arXiv:2107.13586},
  year={2021}
}

@inproceedings{gao2021making,
  title={Making Pre-trained Language Models Better Few-shot Learners},
  author={Gao, Tianyu and Fisch, Adam and Chen, Danqi},
  booktitle={ACL},
  year={2021}
}

@article{jiang2020can,
  title={How can we know what language models know?},
  author={Jiang, Zhengbao and Xu, Frank F and Araki, Jun and Neubig, Graham},
  journal={Transactions of the Association for Computational Linguistics},
  year={2020}
}

@inproceedings{shin2020autoprompt,
  title={AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts},
  author={Shin, Taylor and Razeghi, Yasaman and Logan IV, Robert L and Wallace, Eric and Singh, Sameer},
  booktitle={EMNLP},
  year={2020}
}

@inproceedings{li2021prefix,
  title={Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author={Li, Xiang Lisa and Liang, Percy},
  booktitle={ACL},
  year={2021}
}

@inproceedings{lester2021power,
  title={The Power of Scale for Parameter-Efficient Prompt Tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  booktitle={EMNLP},
  year={2021}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  year={2021}
}

@article{zhou2022learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={IJCV},
  year={2022}
}

@inproceedings{lu2022prompt,
  title={Prompt Distribution Learning},
  author={Lu, Yuning and Liu, Jianzhuang and Zhang, Yonggang and Liu, Yajing and Tian, Xinmei},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{zhou2022conditional,
  title={Conditional prompt learning for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  booktitle={CVPR},
  year={2022}
}

@article{yao2021cpt,
  title={Cpt: Colorful prompt tuning for pre-trained vision-language models},
  author={Yao, Yuan and Zhang, Ao and Zhang, Zhengyan and Liu, Zhiyuan and Chua, Tat-Seng and Sun, Maosong},
  journal={arXiv preprint arXiv:2109.11797},
  year={2021}
}

@inproceedings{sung2022vl,
  title={Vl-adapter: Parameter-efficient transfer learning for vision-and-language tasks},
  author={Sung, Yi-Lin and Cho, Jaemin and Bansal, Mohit},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{ni2022expanding,
  title={Expanding language-image pretrained models for general video recognition},
  author={Ni, Bolin and Peng, Houwen and Chen, Minghao and Zhang, Songyang and Meng, Gaofeng and Fu, Jianlong and Xiang, Shiming and Ling, Haibin},
  booktitle={ECCV},
  year={2022}
}

@inproceedings{zhang2022tip,
  title={Tip-Adapter: Training-free Adaption of CLIP for Few-shot Classification},
  author={Zhang, Renrui and Wei, Zhang and Fang, Rongyao and Gao, Peng and Li, Kunchang and Dai, Jifeng and Qiao, Yu and Li, Hongsheng},
  booktitle={ECCV},
  year={2022}
}

@inproceedings{sun397,
  title={Sun database: Large-scale scene recognition from abbey to zoo},
  author={Xiao, Jianxiong and Hays, James and Ehinger, Krista A and Oliva, Aude and Torralba, Antonio},
  booktitle={CVPR},
  year={2010}
}

@article{mullner2011modern,
  title={Modern hierarchical, agglomerative clustering algorithms},
  author={M{\"u}llner, Daniel},
  journal={arXiv preprint arXiv:1109.2378},
  year={2011}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={ICML},
  year={2017}
}

@article{nichol2018reptile,
  title={Reptile: a scalable metalearning algorithm},
  author={Nichol, Alex and Schulman, John},
  journal={arXiv preprint arXiv:1803.02999},
  year={2018}
}

@inproceedings{stl10,
  title={An analysis of single-layer networks in unsupervised feature learning},
  author={Coates, Adam and Ng, Andrew and Lee, Honglak},
  booktitle={AISTATS},
  year={2011}
}

@inproceedings{hou2017vegfru,
  title={Vegfru: A domain-specific dataset for fine-grained visual categorization},
  author={Hou, Saihui and Feng, Yushan and Wang, Zilei},
  booktitle={ICCV},
  year={2017}
}

@inproceedings{parkhi2012cats,
  title={Cats and dogs},
  author={Parkhi, Omkar M and Vedaldi, Andrea and Zisserman, Andrew and Jawahar, CV},
  booktitle={CVPR},
  year={2012}
}

@article{helber2019eurosat,
  title={Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification},
  author={Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian},
  journal={IEEE J-STARS},
  year={2019}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={CVPR},
  year={2009}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{zhang2018unreasonable,
  title={The unreasonable effectiveness of deep features as a perceptual metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle={CVPR},
  year={2018}
}

@article{zhai2019large,
  title={A large-scale study of representation learning with the visual task adaptation benchmark},
  author={Zhai, Xiaohua and Puigcerver, Joan and Kolesnikov, Alexander and Ruyssen, Pierre and Riquelme, Carlos and Lucic, Mario and Djolonga, Josip and Pinto, Andre Susano and Neumann, Maxim and Dosovitskiy, Alexey and others},
  journal={arXiv preprint arXiv:1910.04867},
  year={2019}
}


