\vspace{-0.2cm}
\section{Conclusion}
\vspace{-0.2cm}
In this paper, we present a new approach towards NeRF reconstruction that can work with a modest number of in-the-wild views of an indoor scene. We address the under-constrained nature of this problem by regularizing the NeRF optimization with additional depth estimates for each view. Our key technical contribution is to model multimodality in the depth estimates, which can capture inherent ambiguities in monocular depth estimation as well as the possible presence of non-opaque surfaces. We resolve ambiguities using a novel space carving loss that fuses the multimodal depth estimates from different views and seeks the modes that are consistent across views so as to arrive at a globally consistent 3D reconstruction. The improved recovery of shape and appearance enables higher fidelity novel view synthesis from sparse views. 
\vspace{-0.4cm}
\paragraph{Limitations and Future Work.} The performance of our method is constrained by the quality of the monocular depth priors. While we found that our prior generalizes well across domains, if the domain gap is too great, the performance of our method will degrade. A future direction would to be detect when this happens and dynamically adjust the strength of depth supervision in response. 
\vspace{-0.4cm}
\paragraph{Acknowledgements.} We sincerely thank the Teleportation and CCI team in Google for all the insightful discussions during the summer. We also thank Mirko Visontai for internship logistics, Guandao Yang for experiment set-up assist, and Weicheng Kuo for looking over the paper. 