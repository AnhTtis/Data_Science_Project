% !TEX root = ./supplemental.tex
% !TEX spellcheck = en-US

\begin{table*}
    \centering
    % \rowcolors{3}{}{gray!10}
    % \scalebox{0.9}{
    \begin{tabular}{l@{\hspace{3em}}ccc@{\hspace{3em}}ccc@{\hspace{3em}}ccc}
        \toprule
        \multirow{2}{*}{Category}  & \multicolumn{3}{c@{\hspace{3em}}}{FCOSv2~\cite{fcosv2}}                &\multicolumn{3}{c@{\hspace{3em}}}{PAA~\cite{PAA}}             &\multicolumn{3}{c}{\bf Ours}         \\
        ~                           & AP        & AP$_{50}$     & AP$_{75}$     & AP            & AP$_{50}$     & AP$_{75}$ & AP            & AP$_{50}$     & AP$_{75}$ \\
        \midrule
        Toaster                     & {20.9} &{38.4}& {30.5}          & 16.1          & 34.0          & 25.7      & {\bf 31.8}    & {\bf 47.2}    & {\bf 42.3}         \\
        Bottle                      & {38.3}      & {59.4}  & {43.1}          & 37.0          & 58.5          & 41.9        & {\bf 40.5}  & {\bf 60.7}    & {\bf 45.7}     \\
        Skateboard                  & 50.1       & {69.7} & 59.4          & {50.2}  & 69.3  & {60.2}      & {\bf 52.6} & {\bf 71.5}  & {\bf 63.8}        \\
        % bicycle                     &           &               &               & 27.3          &               &           & 29.7          &               &           \\
        Suitcase                    & 34.7      & {52.5}          & 38.8          & {35.1} & 52.0   & {39.0}       & {\bf 36.5}   & {\bf 53.6}    & {\bf 40.7}        \\ 
        Cup                         & 41.3      & 62.3  & {50.6}  & {41.5}  & {62.7}  & {50.6}      & {\bf 42.8}    & {\bf 63.2}    & {\bf 52.2}        \\
        ... & & ... & & & ... & & & ... \\
        \midrule
        Cat                         & {65.7}  & {86.8} & {68.4}          & {\bf 67.2}   & {\bf 88.9} & {\bf 69.8}     & 63.0          & 84.5          & 66.2        \\
        Dog                         & {60.7} & {81.9}   & {62.4}          & {\bf 62.1}    & {\bf 83.2}    & {\bf 63.9}       & 59.3          & 80.8         & 60.7     \\  
        Cow                         & {56.4}      & {72.3}  & {60.5}          & {\bf 58.0}    & {\bf 74.0}    & {\bf 62.8}      & 56.0           & 71.0       & 60.2   \\
        Sheep                       & {51.4} & {71.2}  & {60.7}          & {\bf 51.7}   & {\bf 71.6} & {\bf 61.2}      & 50.0          & 70.3          & 58.6         \\
        Bird                        & {\bf 36.2}& {\bf 54.8}& {\bf 42.3}    & {35.6}  & {54.0}  & 41.4     & 35.1          & 53.5          & {41.6}      \\
        ... & & ... & & & ... & & & ... \\
        \midrule
        {Avg.}                  & 38.9      & \underline{57.5}  & 42.2          & {\bf 40.4}          & {\bf 58.4}          & {\bf 43.9}      & \underline{40.0}    & 57.1  & \underline{43.4}      \\
        \bottomrule
    \end{tabular}
    % }
    \caption{{\bf Evaluation of general detection on COCO.} Although the general detection dataset COCO does not fully match our assumption of rigid targets, our method outperforms the baselines significantly on categories such as toaster, bottle, etc., which are mainly rigid objects, and our method achieves similar performance to the baselines in average accuracy.
    }
    \label{tab:coco_eval}
\end{table*}

\section{Appendix}

\noindent \textbf{General scenario.} Our work is motivated by the rigidity of the targets in 6D object pose estimation. The general scenario, e.g., COCO, does not fully match our assumption. Nevertheless, we report results with the same experimental setting as FCOSv2 and PAA in Table~\ref{tab:coco_eval}. In addition to the average accuracy across the 80 COCO categories, we report the accuracy of the 5 categories on which our method outperforms the baselines the most, and the 5 categories on which our method performs the worst. Our method outperforms the baselines significantly on categories such as toaster, bottle, etc., which are mainly rigid objects. By contrast, the categories on which our method underperforms include cat, dog, etc., which are mainly non-rigid targets and break our assumption. Our method nevertheless achieves similar performance to the baselines in average accuracy.

% \noindent \textbf{Additional qualitative results.}
% In Fig.~\ref{fig:more_vis}, we visualize additional results on the LM-O, T-LESS, IC-BIN, and YCB datasets. These results demonstrate the robustness of our method.

\noindent \textbf{Additional quantitative results.}
We show the detailed object pose results using different metrics on LM-O, T-LESS, TUD-L, IC-BIN, ITODD, HB, and YCB in Table~\ref{tab:compare_lmo},~\ref{tab:compare_tless},~\ref{tab:compare_tudl},~\ref{tab:compare_icbin},~\ref{tab:compare_itodd},~\ref{tab:compare_hb}, and~\ref{tab:compare_ycbv}, respectively.
Our method combined with PFA-Pose~\cite{pfa} outperforms the state of the art in most experimental settings.

\begin{table}[h]
    \centering
    \scalebox{0.95}{
    % \rowcolors{2}{}{gray!10}
    \input{tabs/compare_lmo_pose}
    }
    \caption{{\bf Additional object pose results on LM-O.}
    % We compare our method with PFA~\cite{pfa}, SurfEmb~\cite{surfemb}, CIR~\cite{coupled_iterative}, Cosypose~\cite{cosypose}, and CDPNv2~\cite{cdpn}.
    }
    \label{tab:compare_lmo}
\end{table}

\begin{table}
    \centering
     \scalebox{0.95}{
    % \rowcolors{2}{}{gray!10}
    \input{tabs/compare_tless_pose}
    }
    \caption{{\bf Additional object pose results on T-LESS.}
    % We compare our method with PFA~\cite{pfa}, SurfEmb~\cite{surfemb}, CIR~\cite{coupled_iterative}, Cosypose~\cite{cosypose}, and CDPNv2~\cite{cdpn}.
    }
    \label{tab:compare_tless}
\end{table}

\begin{table}
    \centering
     \scalebox{0.95}{
    % \rowcolors{2}{}{gray!10}
    \input{tabs/compare_tudl_pose}
    }
    \caption{{\bf Additional object pose results on TUD-L.}
    % We compare our method with PFA~\cite{pfa}, SurfEmb~\cite{surfemb}, CIR~\cite{coupled_iterative}, Cosypose~\cite{cosypose}, and CDPNv2~\cite{cdpn}.
    }
    \label{tab:compare_tudl}
\end{table}

\begin{table}
    \centering
     \scalebox{0.95}{
    % \rowcolors{2}{}{gray!10}
    \input{tabs/compare_icbin_pose}
    }
    \caption{{\bf Additional object pose results on IC-BIN.}
    % We compare our method with PFA~\cite{pfa}, SurfEmb~\cite{surfemb}, CIR~\cite{coupled_iterative}, Cosypose~\cite{cosypose}, and CDPNv2~\cite{cdpn}.
    }
    \label{tab:compare_icbin}
\end{table}

\begin{table}
    \centering
     \scalebox{0.95}{
    % \rowcolors{2}{}{gray!10}
    \input{tabs/compare_itodd_pose}
    }
    \caption{{\bf Additional object pose results on ITODD.}
    % We compare our method with PFA~\cite{pfa}, SurfEmb~\cite{surfemb}, CIR~\cite{coupled_iterative}, Cosypose~\cite{cosypose}, and CDPNv2~\cite{cdpn}.
    }
    \label{tab:compare_itodd}
\end{table}

\begin{table}
    \centering
    \scalebox{0.95}{
    % \rowcolors{2}{}{gray!10}
    \input{tabs/compare_hb_pose}
    }
    \caption{{\bf Additional object pose results on HB.}
    % We compare our method with PFA~\cite{pfa}, SurfEmb~\cite{surfemb}, CIR~\cite{coupled_iterative}, Cosypose~\cite{cosypose}, and CDPNv2~\cite{cdpn}.
    }
    \label{tab:compare_hb}
\end{table}

\begin{table}
    \centering
    \scalebox{0.95}{
    % \rowcolors{2}{}{gray!10}
    \input{tabs/compare_ycbv_pose}
    }
    \caption{{\bf Additional object pose results on YCB.}
    % We compare our method with PFA~\cite{pfa}, SurfEmb~\cite{surfemb}, CIR~\cite{coupled_iterative}, Cosypose~\cite{cosypose}, and CDPNv2~\cite{cdpn}.
    }
    \label{tab:compare_ycbv}
\end{table}

% \section{Pose Initialization Performance}
% PFA-Pose~\cite{pfa} relies on WDR-Pose~\cite{wdr}, which works on the whole image, for pose initialization.
% We do some modifications to incorporate our detection method into WDR-Pose.
% The original WDR-Pose uses the multi-level fusion strategy with the help of FPN~\cite{fpn} to handle the large depth range.
% However, the scale change becomes small when operating on the zoomed-in patch. Thus, we remove FPN and the multi-level fusion strategy, and only supervise the predictions from the foreground cells of the last stage of the backbone by the proposed 3D loss, in fact, more similar to Segdriven~\cite{segdriven}. 
% As shown in Table~\ref{tab:compare_estimator}, although the modified WDR-Pose follows a much simpler design philosophy, it outperforms other methods by a large margin with the help of our detection method.

% \noindent \textbf{Detailed detection results.}
% We show the detection results in more detailed metrics, including AP$_{50}$ and AP$_{75}$~\cite{coco, ATSS, PAA}, in Table~\ref{tab:compare_ap50_75}. Consistent with the main paper, our method outperforms other methods significantly, especially in the more strict metric AP$_{75}$.

% \begin{table*}
%     \centering
%     \rowcolors{2}{}{gray!10}
%     \input{tabs/compare_allpose_mspd}
%     \caption{{\bf Comparison against the state of the art on MSPD metric.}}
%     \label{tab:compare_mspd}
% \end{table*}

% \begin{table*}
%     \centering
%     \rowcolors{2}{}{gray!10}
%     \input{tabs/compare_allpose_mssd}
%     \caption{{\bf Comparison against the state of the art on MSSD metric.}}
%     \label{tab:compare_mssd}
% \end{table*}

% \begin{table*}
%     \centering
%     \rowcolors{2}{}{gray!10}
%     \input{tabs/compare_allpose_vsd}
%     \caption{{\bf Comparison against the state of the art on VSD metric.}}
%     \label{tab:compare_vsd}
% \end{table*}



% \begin{table}
%     \centering
%     \rowcolors{2}{}{gray!10}
%     \input{tabs/compare_estimator}
%     \caption{{\bf Comparison against the 6D pose estimation methods without pose refinement.}
%     Cosypose$\dag$ denotes Cosypose without pose refinement.}
%     \label{tab:compare_estimator}
% \end{table}

% \begin{figure*}
%     \centering
%     \setlength\tabcolsep{1pt}
%     \input{figures/more_visualization}
%     \caption{{\bf Additional qualitative results on LM-O, T-LESS, IC-BIN, and YCB-V.} We present the results on different datasets from top to bottom, showing the detection and object pose results for each.}
%     \label{fig:more_vis}
% \end{figure*}

% \begin{figure}
%     \centering
%     \setlength\tabcolsep{1pt}
%     \input{figures/more_visulaization_part2}
%     \caption{{\bf More visualization results on YCB-V.}}
%     \label{fig:more_vis_part2}
% \end{figure}

% \begin{table}
%     \centering
%     \rowcolors{3}{gray!10}{}
%     \input{tabs/compare_detect_more}
%     \caption{{\bf Detailed detection results.}
%     We compare our method with FCOSv2~\cite{fcosv2} and Mask R-CNN~\cite{maskrcnn} in different detection metrics.
%     }
%     \label{tab:compare_ap50_75}
% \end{table}
% \begin{table*}
%     \centering
%     \rowcolors{2}{}{gray!10}
%     \input{tabs/compare_detector_ap50}
%     \caption{{\bf Detection comparison on AP$_{50}$ metric.}}
%     \label{tab:compare_ap50}
% \end{table*}

% \begin{table*}
%     \centering
%     \rowcolors{2}{}{gray!10}
%     \input{tabs/compare_detector_ap75}
%     \caption{{\bf Detection comparison on AP$_{75}$ metric.}}
%     \label{tab:compare_ap75}
% \end{table*}
