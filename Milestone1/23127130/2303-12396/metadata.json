{
    "arxiv_id": "2303.12396",
    "paper_title": "Rigidity-Aware Detection for 6D Object Pose Estimation",
    "authors": [
        "Yang Hai",
        "Rui Song",
        "Jiaojiao Li",
        "Mathieu Salzmann",
        "Yinlin Hu"
    ],
    "submission_date": "2023-03-22",
    "revised_dates": [
        "2023-03-23"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Most recent 6D object pose estimation methods first use object detection to obtain 2D bounding boxes before actually regressing the pose. However, the general object detection methods they use are ill-suited to handle cluttered scenes, thus producing poor initialization to the subsequent pose network. To address this, we propose a rigidity-aware detection method exploiting the fact that, in 6D pose estimation, the target objects are rigid. This lets us introduce an approach to sampling positive object regions from the entire visible object area during training, instead of naively drawing samples from the bounding box center where the object might be occluded. As such, every visible object part can contribute to the final bounding box prediction, yielding better detection robustness. Key to the success of our approach is a visibility map, which we propose to build using a minimum barrier distance between every pixel in the bounding box and the box boundary. Our results on seven challenging 6D pose estimation datasets evidence that our method outperforms general detection frameworks by a large margin. Furthermore, combined with a pose regression network, we obtain state-of-the-art pose estimation results on the challenging BOP benchmark.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.12396v1"
    ],
    "publication_venue": "CVPR 2023"
}