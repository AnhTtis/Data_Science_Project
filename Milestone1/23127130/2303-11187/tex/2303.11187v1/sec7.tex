\section{Application of CCB-PV with Extended Policy Class: One-step Linear Partially Observable Markov Decision Process}\label{sec:POMDP}
% \begin{figure}
% \centering
%   % Requires \usepackage{graphicx}
%   \subfloat[DAG of the observational process in DTR]{\includegraphics[height=2.5cm]{figure/POMDP_behavior.pdf}
%   % \label{fig:POMDP behavior}
%   }
%   \hspace{1.5cm}
%   \subfloat[DAG of the interventional process in DTR]{\includegraphics[height=2.5cm]{figure/POMDP_evaluation.pdf}
%   % \label{fig:POMDP evaluation}
%   }\\
% %   \vspace{0.5cm}
%    \caption{A DAG illustration of the one-step POMDP model}
%    % \label{fig:POMDP}
% \end{figure}
% \begin{figure}
%   \tikz{
% % nodes
%  \node[obs] (S_1) {$S_1$};
%  \node[latent, below=of S_1] (A_1) {$A_1$};
%  \node[latent, below=of S_1, xshift=1.25cm] (Y_1) {$Y_1$};
%  \node[latent, above=of S_1] (O_1) {$O_1$};
 
%  \node[obs, right=of S_1, xshift=0.75cm] (S_2) {$S_2$};
%  \node[latent, below=of S_2] (A_2) {$A_2$};
%  \node[latent, below=of S_2, xshift=1.5cm] (Y_2) {$Y_2$};
%  \node[latent, above=of S_2] (O_2) {$O_2$};
% %  \node[latent,above=of X1,xshift=-1cm,fill] (y) {$y$}; %
% %  \node[latent,above=of X1,xshift=1cm] (z) {$z$}; %
% %  \draw (0,1.69) circle(.36cm);
% % plate
% %  \plate [inner sep=.25cm,yshift=.2cm] {plate1} {(S_1)(A_1)(Y_1)(O_1)} {$N$}; %
% % edges
%  \edge {S_1}{A_1};
%  \edge {S_1, A_1, O_1}{Y_1};
%  \edge {S_1}{O_1};
%  \edge {S_1, A_1, O_1}{S_2}
%  \edge {S_2}{A_2};
%  \edge {S_2, A_2, O_2}{Y_2};
%  \edge {S_2}{O_2};
%  }
% \end{figure}


\paragraph{Background.}
We consider a one-step Partially Observable Markov Decision Process (POMDP) following the example in \citep{shi2021minimax, uehara2021finite}. Here, the term "one-step" means that we only care about the policy and reward at the first step, but the environment is allowed to transit into the following steps. 
The POMDP starts with a pre-observation $O^-$ and the environment transits into state $S$. An observation $O$ is generated according to $S$, and the agent in the observational process takes an action $A$ according to $\pib:\cS\rightarrow \Delta(\cA)$. After the action is conducted, a reward $Y_0$ is received and the environment transits into the following state $S^+$ with observation $O^+$. 
Note that $Y$ is allowed to depend on $O$.
In the interventional process, since the agent gains no access to the hidden state, its policy can only depend on the observations.
We consider the extended interventional policy class discussed in \S\ref{sec:extended CCB-PV}, i.e.,  $\pie:\cO^-\times\cO\rightarrow\Delta(\cA)$ by viewing $O^-$ as the context ($X$ in CCB-PV) and $O$ as the outcome proxy ($W$ in CCB-PV).
Note that such a policy also captures the case where the policy only depends on $O$.
% These two cases corresponds to the original policy class discussed in \S\ref{sec:CCB-PV} and the extended policy class discussed in \S\ref{sec:extended CCB-PV} respectively 

\begin{figure}[h]  
\centering 
  \begin{subfigure}[b]{0.4\linewidth}
  \centering
    \begin{tikzpicture}
        \node[hiddenstate] (S) [right=of O] {$S$};
        \node[missingstate] (O) [above=of S] {$O$};
        \node[missingstate] (O-) [left=of S] {$O^-$};
        \node[state] (A) [below=of S] {$A$};
        \node[hiddenstate] (S+) [right=of S] {$S^+$};
        \node[state] (Y) [below=of S+] {$Y$};
        \node[missingstate] (O+) [above=of S+] {$O^+$};
        \node[state] (A+) [right=of S+] {$A^+$};
        \path[normal] (O-) edge (S);
        \path[normal] (O) edge (Y);
        \path[normal] (S) edge (O);
        \path[normal, blue] (S) edge (A);
        \path[normal] (S) edge (S+);
        \path[normal] (S) edge (Y);
        \path[normal] (A) edge (S+);
        \path[normal] (A) edge (Y);
        \path[normal] (S+) edge (O+);
        \path[normal] (S+) edge (A+);
    \end{tikzpicture}
    \caption{DAG of the observational process in one-step POMDP.}
  \end{subfigure}\qquad
\begin{subfigure}[b]{0.4\linewidth}
\centering
  \begin{tikzpicture}  
        \node[hiddenstate] (S) [right=of O] {$S$};
        \node[state] (O) [above=of S] {$O$};
        \node[state] (O-) [left=of S] {$O^-$};
        \node[state] (A) [below=of S] {$A$};
        \node[hiddenstate] (S+) [right=of S] {$S^+$};
        \node[state] (Y) [below=of S+] {$Y$};
        \node[state] (O+) [above=of S+] {$O^+$};
        \path[normal] (O-) edge (S);
        \path[normal] (O) edge (Y);
        \path[normal] (S) edge (O);
        \path[normal] (S) edge (S+);
        \path[normal] (S) edge (Y);
        \path[normal] (A) edge (S+);
        \path[normal] (A) edge (Y);
        \path[normal] (S+) edge (O+);
        \path[normal, red] (O) edge[bend left=-30] (A);
        \path[normal, red] (O-) edge (A);
\end{tikzpicture}
\caption{DAG of the interventional process in one-step POMDP.}
\end{subfigure}
\caption{A DAG illustration of the one-step POMDP model.}% \label{fig:POMDP}
\end{figure}  


\paragraph{Missingness.} Very similar to the DTRs example, we assume that $R_{O}$ is caused by $O$ and $A$ and $R_{O^+}$ is caused by $O^+$ and $A^+$ in the observational dataset. Note that the pre-observation $O^-$ is exogenous to the model, it is thereby reasonable to assume that $R_{O^-}$ only depends on $O^-$. A tricky part is that following the observational policy, we have that $A^+\sim \pib(a^+\given s^+)$ and $S^+\sim \pr(s^+\given s, a)$. It thus turns out that $R_{O^+}$ is alternatively caused by $(O^+, S, A)$. 

\paragraph{Mapping to CCB-PV.} We provide a mapping from this one-step POMDP to the CCB-PV in Table \ref{tab:POMDP}. 
It is easy to verify that the assumption of PV independence and the assumption of unconfounded and outcome-independent missingness in Assumption \ref{asp:CCB-PV} both hold for this one-step POMDP. The PV complete assumption corresponds to assuming that $O^+$ is complete over $S$, i.e., for any $a\in\cA$, $o^-\in\cO^-$, $\EEob\sbr{\sigma(S)\given o^-, a, o^+, R_{O^+}=1}=0$ holds for any $o^+\in\cO^+$ if and only if $\sigma(S^+)\overset{\text{a.s.}}{=} 0$ holds. Such an assumption suggests this should be a non-degenerate MDP, i.e., $O^+$ still contains sufficient information of the hidden state of the previous step.
Then following Theorem \ref{thm:CCB-PV ID extension}, we have the $v^\pie(x)$ identified by
%\begin{gather}
\begin{align}
    &\EEob\sbr{h_1(Y, A, O^-, O^+) \given a, o^-, o^+, (R_{O^-}, R_{O^+})=\ind}=0, \label{eq:POMDP ID 1}\\
    &\EEob\sbr{h_2(A, O, O^-) - h_1(Y, A, O^-, O^+)-Y\pie(A\given O^-, O)\given a, o, o^-, o^+, (R_{O}, R_{O^-}, R_{O^+})=\ind}, 
    % \label{eq:POMDP ID 2}
    \nend
    &\EEob\sbr{h_3(Y, A, O^-)-\sum_{a'\in\cA} h_2(a', O, O^-)\given a, o, o^-, (R_{O}, R_{O^-})=\ind}, 
    % \label{eq:POMDP ID 3}
    \nend
    &\EEob\sbr{g^\pie(O^-)-h_3(Y, A, O^-)\given o^-, R_{O^-}=1}=0, \label{eq:POMDP ID 4}
\end{align}
%\end{gather}
if the bridge functions exist.
\begin{table}[]
    \centering
    \begin{tabular}{  c  c c c} 
  \hline
  Variable Type & One-step POMDP  & Observability in $\cD$ & Correspondence to CCB-PV\\ 
  \hline
  confounder        &   $S$ & unobservable        & $U$    \\
  context           &   $O^-$ & partially missing   & $X$    \\
  treatment         &   $A$ & observable          & $A$    \\
  outcome           &   $Y$ & observable          & $Y$    \\
  treatment proxy   &   $O^+$ & partially missing   & $Z$    \\
  outcome proxy     &   $O$ & partially missing   & $W$    \\
  \hline
\end{tabular}
    \caption{Mapping of variables from the one-step POMDP to the CCB-PV.}
    \label{tab:POMDP}
\end{table}

\paragraph{Linear function class.} Similar to the linear DTRs example, we characterize the existence of the bridge functions and the linearity of the one-step POMDP model. We assume that the interventional policy falls into some linear function class. Specifically, we let $\Pie$ be a subset of the following linear function class,
\begin{align}
\Pie = \cbr{\pie \bigg | \pie(a\given o, o^-)=\frac{\exp\rbr{w_0^\top\phi_0(a, o, o^-)}}{\sum_{a'\in\cA}\exp\rbr{w_0^\top\phi_0(a', o, o^-)}}, w_0\in\RR^{m_2}, \nbr{w_0}_2\le C_0,  \nbr{\phi_0(\cdot)}_2\le 1}.\label{def:linear policy}
\end{align}
\begin{assumption}[Existence of linear bridge function] \label{asp:POMDP linear 1}
We assume that for any $\pie\in\Pie$, there exists $\vh^{\pie, *}=(h_1^{\pie, *}, h_2^{\pie, *}, h_3^{\pie, *}, g^{\pie, *})$ as a solution to the IES \eqref{eq:POMDP ID 1}-\eqref{eq:POMDP ID 4}.
In addition, we assume that $h_1^{\pie, *}, h_2^{\pie, *}, h_3^{\pie, *}$ fall into the following linear function classes,
\begin{gather*}
    \cH_k=\{h_k\given h_k(\cdot)= w_k^\top\phi_k(\cdot), w_k\in\RR^{m_k}, \nbr{w_k}_2\le C_k, \nbr{\phi_k(\cdot)}\le 1\}, \quad k=1, 2, 3, 
\end{gather*}
with $h_k^{\pie, *}=(w_k^{\pie, *})^\top \phi_k$.
\end{assumption}

Assumption \ref{asp:POMDP linear 1} assumes the bridge functions to exist and fall into some linear function classes.
Now for the corresponding kernels $\phi_1$, $\phi_2$ and $\phi_3$, we assume their conditional moments are captured by kernel series $\psi_1, \psi_2, \psi_3, \psi_4$. 
\begin{assumption}[Linearity of the dual function class]\label{asp:POMDP linear 2}
We assume that the kernel $\phi_1$, $\phi_2$, $\phi_3$, $\psi_4$ satisfies
\begin{itemize}
    \item[(i)] $\EEob\sbr{\phi_1(Y, A, O^-, O^+)\given a, o^-, o^+, R_{o^+}=1} = W_1 \psi_1(a, o^-, o^+)$ where $\psi_1:\cA\times\cO^-\times\cO^+\rightarrow \RR^{d_1}$, $W_1\in \RR^{m_1\times d_1}$, and $\nbr{\psi_1(\cdot)}_2\le 1$.
    \item[(ii)] $\EEob\sbr{\phi_1(Y, A, O^-, O^+)\given a, o, o^-, o^+, R_{O^+}=1}=W_2\psi_2(a, o, o^-, o^+)$ and $\EEob[\phi_2(A, O, O^-) \given a, o, \allowbreak o^-, o^+, R_{O^+}]=W_3\psi_2(a, o, o^-, o^+)$ where $\psi_2:\cA\times\cO\times\cO^-\times\cO^+\rightarrow \RR^{d_2}$, $W_2\in\RR^{m_1\times d_2}$, $W_3\in\RR^{m_2\times d_2}$, and $\nbr{\psi_2(\cdot)}_2\le 1$.
    \item[(iii)] $\sum_{a'\in\cA}\phi_2(a', O, O^-)=W_4\psi_3(a, o, o^-)$ for any $a\in\cA$ and $\EEob\sbr{\phi_3(Y, A, O^-)\given a, o, o^-}=W_5\allowbreak \psi_3(a, o, o^-)$, where $\psi_3:\cA\times\cO\times\cO^-\rightarrow \RR^{d_3}$, $W_4\in\RR^{m_2\times d_3}$, $W_5\in \RR^{m_3\times d_3}$, and $\nbr{\psi_3(\cdot)}_2\le 1$.
    \item[(iv)] $\EEob\sbr{\phi_3(Y, A, O^-)\given o^-}=W_6 \psi_4(o^-)$ where $\psi_4:\cO^-\rightarrow \RR^{m_4}$, $W_5\in\RR^{m_3\times m_4}$, and $\nbr{\psi_4(\cdot)}_2\le 1$.
\end{itemize}
\end{assumption}
Consider a linear operator $T:\cF(\cA, \cO, \cO^+)\rightarrow \cF(\cA, \cO^-, \cO^+)$ defined as $Tf(a, o^-, o^+)=\EEob\sbr{f(A, O, O^-)\given a, o^-, o^+, R_{o^+}=1}$.
Condition (i) of Assumption \ref{asp:POMDP linear 2} indicates that the operator $T$ is captured by the kernel $\psi_1(a, o^-, o^+)$.
The arguments for conditions (ii)-(iv) are similar. 
Using condition (iv) of Assumption \ref{asp:POMDP linear 2} in conditional moment equation \eqref{eq:POMDP ID 4}, it holds for the CATE $g^{\pie, *}$  that,
\begin{align*}
    g^{\pie, *}(o^-)=\EEob\sbr{\h{3}{\pie, *}(Y, A, O^-)\given o^-} = (w_3^{\pie, *} )^\top W_6 \psi_4(o^-), 
\end{align*}
which implies that $g^{\pie, *}$ lies in the linear space $\cG=\{w_4\in\RR^{m_4}:\cO^-\rightarrow w_4^\top\psi_4(\cdot), \nbr{w_4}\le C_3\nbr{W_6}_F, \nbr{\psi_4(\cdot)}_2\le 1\}$.
Therefore, by letting $\vH=\cH_1\times \cH_2\times \cH_3\times \cG$ be the hypothesis space, we have the realizability error $\vareH$ equal to zero.
Combining Assumptions \ref{asp:POMDP linear 1} and \ref{asp:POMDP linear 2}, it further holds for the linear operator $\cT^\pie$ that,
%\begin{gather}
\begin{align}
    &\cT^\pie_1\vh(a,o^-, o^+)=(w_1-w_1^{\pie, *})^\top W_1 \psi_1(a, o^-, o^+), \nend
    &\cT^\pie_2\vh(a, o, o^-, o^+)=\rbr{(w_2-w_2^{\pie, *})^\top W_3 - (w_1-w_1^{\pie, *})^\top W_2}\psi_2(a, o, o^-, o^+), \nend
    &\cT^\pie_3\vh(a, o, o^-) = \rbr{(w_3-w_3^{\pie, *})^\top W_5- (w_2-w_2^{\pie, *})^\top W_4} \psi_3(a, o, o^-), \nend
    &\cT^\pie_4\vh(o^-) = \rbr{(w_4-w_4^{\pie, *})^\top - (w_3-w_3^{\pie, *})^\top W_6}\psi_4(o^-).\nonumber
\end{align}
%\end{gather}
Therefore, $\cT^\pie_k\vh$ falls into the following linear function class
\begin{align*}
 \Theta_k=\{\theta_k\given \theta_k(\cdot)=\beta_k^\top \psi_k(\cdot), \beta_k\in\RR^{d_k}, \nbr{\beta_k}\le D_k, \nbr{\psi_k(\cdot)}_2\le 1\}, \quad k=1, 2,3, 4, 
\end{align*}
where we require $D_1>2C_1 \nbr{W_1}_F$, $D_2> 2 (C_1\nbr{W_2}_F+C_2\nbr{W_3}_F)$, $D_3> 2 (C_3\nbr{W_5}_F+C_2\nbr{W_4}_F)$, and $D_4> 2 (C_4+C_3\nbr{W_6}_F)$.
Using $\vH=\cH_1\times \cH_2\times \cH_3\times \cG$ as the hypothesis space and $\Theta=\Theta_1\times \Theta_2\times \Theta_3\times \Theta_4$ as the dual function class,  we have the following corollary for the convergence of the sub-optimality for the one-step linear POMDP by Theorem \ref{thm:CCB-PV ID extension}.
\begin{corollary}
Suppose that Assumptions \ref{asp:POMDP linear 1} and \ref{asp:POMDP linear 2} hold. Let $e_{\cD}>(2 L_\alpha^2+5/ 4)\eta^2$ where $\eta=\sum_{k=1}^2\eta_k^2$ and $\eta_k$ bounds the critic radius for the function class $\cQ_k=\{\alpha_k^\pie(\vh, \cdot)\theta_k: \vh\in\vH, \theta_k\in\Theta_k, \pie\in\Pie\}$. Suppose that for any $o^-\in\cO^-$, $a\in\cA$ and $o^+\in\cO^+$ there exists $b_1:\cO^-\times\cA\times\cO^+\rightarrow\RR$ satisfying
\begin{align*}
    \EEob\sbr{b_1(O^-, A, O^+)\given o^-, s, a, R_{O^+}=1} = \frac{\pob(s\given o^-)\tpr(o^-)}{\pob(s, o^-, a\given  R_{o^+}=1)}.
\end{align*}
The sub-optimality corresponding to $\piepessi$ for the CCB-PV is bounded with probability at least $1-2K\xi$ by
    \begin{align*}
        \SubOpt(\piepessi) \lesssim \sum_{k=1}^4 \nbr{b_k}_{\mu_k, 2} \cdot \rbr{ O\rbr{\sqrt{e_\cD}} +  O\rbr{\eta}}, 
    \end{align*}
    where $b_2:\cA\times\cO\times\cO^-\rightarrow \RR$, $b_3:\cO\times\cO^-\times\cA\rightarrow\RR$ and $b_4:\cO^-\rightarrow\RR$ characterize the distribution shift and are defined by
    %\begin{gather*}
    \begin{align*}
        &b_2(a, o, o^-) = b_1(o^-, a, o^+)\frac{\pob(a, o, o^-\given (R_{O^-}, R_{O^+})=\ind)}{\pob(a, o, o^-\given (R_{O}, R_{O^-}, R_{O^+})=\ind)}, \\
        &b_3(o, o^-, a) = \frac{\tpr(o^-)\pob(a, o\given o^-, R_{O^-}=1)}{\pob(o^-, a, o\given (R_{O}, R_{O^-})=\ind)}, \\
        &b_4(o^-) = \frac{\tpr(o^-)}{\pob(o^-\given R_{O^-}=1)}.
    \end{align*}
    %\end{gather*}
\end{corollary}
The critical radius is calculated in \S\ref{app:POMDP critical radius}. The result can be summarized as $\eta=\cO(|\cA|\sqrt{\log T_2/T_2})$, where $T_2$ corresponds the total number of samples that are subject to no missingness in the observations $(O, O^-, O^+)$. Therefore, we establish the convergence of the sub-optimality for the one-step linear POMDP.


\paragraph{Discussion of RKHS Space.} 
We remark that a similar result can also be established for other function classes, e.g., the RKHS space.
Following Proposition 6.3 in \cite{duan2021risk}, the critical radius for a RKHS space $\cF$ with kernel $K$ and bounded norm $\nbr{f}_\cK\le C$ is given by,
\begin{align*}
    \eta=2\min_{j\in\NN} \cbr{\frac j T + C\sqrt{\frac{2}{T}\sum_{i=j+1}^\infty \lambda_i^\cF}}, 
\end{align*}
where $\lambda_i^\cF$ corresponds to the eigenvalues of the kernel $K$. If the eigenvalues decay exponentially with high probability, we can also obtain a fast convergence rate of order $\cO(\sqrt{1/T})$.