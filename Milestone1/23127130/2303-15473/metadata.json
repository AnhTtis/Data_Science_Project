{
    "arxiv_id": "2303.15473",
    "paper_title": "Can Large Language Models assist in Hazard Analysis?",
    "authors": [
        "Simon Diemert",
        "Jens H Weber"
    ],
    "submission_date": "2023-03-25",
    "revised_dates": [
        "2023-03-29"
    ],
    "latest_version": 1,
    "categories": [
        "cs.HC",
        "cs.AI",
        "eess.SY"
    ],
    "abstract": "Large Language Models (LLMs), such as GPT-3, have demonstrated remarkable natural language processing and generation capabilities and have been applied to a variety tasks, such as source code generation. This paper explores the potential of integrating LLMs in the hazard analysis for safety-critical systems, a process which we refer to as co-hazard analysis (CoHA). In CoHA, a human analyst interacts with an LLM via a context-aware chat session and uses the responses to support elicitation of possible hazard causes. In this experiment, we explore CoHA with three increasingly complex versions of a simple system, using Open AI's ChatGPT service. The quality of ChatGPT's responses were systematically assessed to determine the feasibility of CoHA given the current state of LLM technology. The results suggest that LLMs may be useful for supporting human analysts performing hazard analysis.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.15473v1"
    ],
    "publication_venue": null
}