%Template prepared by grzegorz ha\l aj for second AMaMeF conference, 17 Oct 2006


\documentclass[9pt]{article}
\usepackage{pdflscape}
\usepackage{eurosym}
\usepackage{soul}
\usepackage{calc}
\usepackage{color}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{placeins}%\ifx\pdftexversion\undefined
  \usepackage[dvips]{graphicx}
%\else
%  \usepackage[pdftex]{graphicx}
%\fi
\usepackage{amssymb}
\usepackage{bbold}
\usepackage{authblk}
\usepackage{amsmath}
%\usepackage[cp1250]{inputenc}
\usepackage[utf8]{inputenc}
\usepackage{eurosym}
\usepackage{multirow}

\usepackage{setspace}

%\usepackage{biblatex}

%\addbibresource{mybibliography.bib}

%\addtolength{\voffset}{-1.5cm} \addtolength{\textheight}{2cm}
\headsep         1cm
%\topmargin     -.3cm
\topmargin     -2cm
\textheight     23cm
\textwidth      15cm
%\textheight     22cm
%\textwidth      14cm
%\textheight     25cm
%\textwidth      15cm
\evensidemargin  0.6cm
\oddsidemargin   0.6cm

\newtheorem{assumption}{Assumption}
\newtheorem{proof}{Proof}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}

\renewcommand\Authfont{\scshape\small}
\renewcommand\Affilfont{\itshape\small}
\setlength{\affilsep}{1em}

\newcommand{\smalllineskip}{\baselineskip=15pt}
\newcommand{\keywords}[1]{{\footnotesize\hspace{0.68cm}{\textit{Keywords}: }#1\par
  \vskip.7\baselineskip}}
\renewenvironment{abstract}[0]{\small\rm
        \begin{center}ABSTRACT
        \\ \vspace{1pt}
        \begin{minipage}{5.2in}\smalllineskip
        \hspace{1pc}}{\end{minipage}\end{center}\vspace{-1pt}}
\newcommand{\emailaddress}[1]{\newline{\sf#1}}
\newcommand{\vbar}{\bar{v}}

\let\LaTeXtitle\title
\renewcommand{\title}[1]{\LaTeXtitle{\large\textsf{\textbf{#1}}}}

%%%TITLE
\title{Plant Performance in Precision Horticulture:\\Optimal climate control under stochastic uncertainty }
\date{}

%%AFFILIATIONS
\author[1]{Simon van Mourik, Bert van't Ooster  \& Michel Vellekoop }
%\affil[1]{
%Faculty of Economics \& Business,
%University of Amsterdam, The Netherlands
%\emailaddress{m.h.vellekoop@uva.nl}}

%%DOCUMENT
\begin{document}
%\pagestyle{empty}
\maketitle
\centerline{\today}

\newcommand{\mycomment}[1]{}
\newcommand{\be}{\begin{eqnarray*}}
\newcommand{\ee}{\end{eqnarray*}}
\newcommand{\mycomments}[1]{}
\newcommand{\quav}[2]{\left< #1,#2 \right>}
\newcommand{\sfrac}[2]{ {\textstyle\frac{#1}{#2}} }


\bibliographystyle{unsrt}

\begin{abstract}

 This paper presents an optimal control algorithm for crop production when state dynamics are uncertain due to stochastic noise. The case study concerns a 50 day production round of lettuce in a greenhouse where control input consists of daily and nightly temperature set points. The control problem was formulated in terms of a stochastic Markov decision process with the objective to maximize the expected net revenue at harvest time.
 \\
The performance was compared to that of a stochastic static controller, and a deterministic time-varying dynamic feedback controller for the case of heat limited weather conditions, and strict requirements on harvest weight precision. Compared to the stochastic dynamic controller, the static controller resulted in lower maximal expected net revenue (-19 \%), less precision at harvest time (state uncertainty increased with 86 \%), and a larger sensitivity towards a change in starting day (varying the starting time from 0 to 10 days caused a variation of 15 \% in expected net revenue, compared to 11\% for the original controller). The deterministic controller also resulted in lower maximal expected net revenue (-16 \%), and less precision at harvest time (state uncertainty increased with 40 \%). The sensitivity of expected net revenue towards a change in starting day increased dramatically (60 \% compared to 11\% for the original controller).
\\
The results of the deterministic controller provided insights in the trade-off between optimality in case of no noise, versus robustness to noise, whereas the results of the static controller provided insights in importance of dynamic feedback in achieving high precision in harvest weight. The results of this single case study should be interpreted with caution, however they illustrate a considerable potential benefit for stochastic greenhouse climate control.

\end{abstract}

\section{Keywords}
Markov decision process, greenhouse, lettuce
 
\section{Introduction}

One of the main goals of sustainable greenhouse horticulture is to achieve high quantity and high quality production under efficient use of resources such as water, biocides, energy, and labour. Precision Horticulture is a scientific domain that aims to achieve that goal through optimal crop, climate, and energy management by means of precise dosage and timing of input and actions aided by precision technology (in the form of crop handling robotics, and equipment for climate control and energy storage) \cite{Bac2014,stanghellini2019} and machine intelligence \cite{mourik2021}. The machine intelligence that is built up from models and algorithms enabling monitoring, prediction and control, forms the core of automated decision support for operational management. In climate management, a challenge that is central for several decades, is deciding on daily settings for temperature, humidity, carbon dioxide levels, and light intensity to reach an optimal balance between crop production rate and quality, and costs associated with resource input and control actions. The methodological development of decision support in the form of monitoring and control algorithms based on predictive models is a well established academic research line \cite{vanStraten2010}. A major obstacle for reliable and accurate model predictions is formed by prediction uncertainty. 

% Different causes for prediction uncertainty: unexplained variation in crop development (model errors), and indoor climate variability, second sensor noise, 
There are various causes for prediction uncertainty. First off, there exists quite some unexplained variation in crop development, which is corroborated by the observation that crop models display a broad range in yield prediction accuracy, from $1-15\%$ \cite{Poorter2013,Righini2020}. Also, spatiotemporal variability in climatic variables \cite{balendonck2010} that is unforeseen or not modelled, may increase prediction uncertainty. Second, due sensor noise it might be hard to make accurate estimates of the crop and climate status, that form the starting point of any predictions about future development. Filter algorithms were shown to be able to mitigate the effect of sensing errors using model based predictions \cite{Speetjens2009,Hameed2010}. However, a case study showed that even well tuned filters might not meet the accuracy required in modern greenhouses \cite{vanMourik2019}. Third, forecast errors of processes like the weather, energy prices and crop market can substantially increase prediction uncertainty and thereby hinder control performance \cite{Kuijpers2021,Su2021,Payne2021}. Uncertainty in crop response and indoor climate dynamics is often modelled with parametric uncertainty \cite{Vazquez2014,Lopez2018uncertainty, Guzman2009}, or stochastic noise \cite{Speetjens2009}. State estimation methods like Kalman filters are based on stochastic noise in state and output. Forecast errors are usually modelled by, and interpreted as, stochastic processes \cite{Kuijpers2021,Oldewurtel2013}.  

% literature on (stochastic) MPC in greenhouse that deals with uncertainty
In this paper we focus on the control problem of optimizing the expected costs of a dynamic system with stochastic uncertainty, which is known as a Markov decision process (MDP) \cite{boucherie2017} or a stochastic dynamic programming problem \cite{Ross2014}. Research towards MDP in precision farming spans a wide range of applications such as precision field irrigation \cite{Huong2018}, pig breeding \cite{kovacs2012}, crop disease control \cite{Onstad1985,sells1995}, and planting, fertilization and harvesting \cite{Boussios2019}. Greenhouse horticulture research to optimal control under stochastic disturbances includes optimal indoor climate management using a stochastic error forecast model \cite{Kuijpers2022, Della2019}, optimal energy management under random renewable energy availability \cite{Zhuang2018}, and tracking and predicting crop states such as dry weight and leaf area in lettuce using a dynamic Bayesian network \cite{Kocian2020}.

To deal with the high dimensional decision space and consequent computational demand that characterizes Markov decision process optimization, the employment of reinforcement learning for greenhouse climate control is an active topic of investigation \cite{Tchamitchian2005, zhang2021, Ajagekar2022}. Stochastic noise adds a layer of complexity to the control problem, which increases computational demand but also might hinder transparency of software and computational outcomes. The question that arises is: what is the added performance of a stochastic controller compared to more straightforward control methods? Not much is reported about the importance of stochastic control in a greenhouse setting. It was found that stochastic controller outperformed expert growers in a tomato greenhouse regarding net profit (93\%) and crop yield (by 10\%) \cite{cao2022igrow}, suggesting a high importance, however the question remains to what extent the complexity of the controller contributes to the performance. 

This paper introduces a stochastic dynamic controller, that is obtained by optimizing a MDP in terms of net revenue, through dynamic programming. The case study concerns a 50 day production round of lettuce in a greenhouse where control input consists of daily and nightly temperature set points. The control problem was formulated in terms of a stochastic Markov decision process with the objective to maximize the expected net revenue at harvest time. 

In part I the control policy, and corresponding dynamics and performance are visualized in order to gain insight into the rationale behind the control policy. The results are visualized in four maps that show for on a discrete grid of time and state the day and night setpoints, the associated crop growth rate, and the associated value in terms of expected net revenue.  

In part II, the obtained stochastic dynamic time-varying feedback controller was compared against a stochastic static controller and a deterministic dynamic time-varying feedback controller. Performance was assessed in terms of maximum expected net revenue at the start of a production round, state uncertainty at harvesting time, and robustness against deviation from the optimal starting time.

\section{Materials and methods}

\subsection{System dynamics}

For times $k\in {\mathbb K}:=\{0,1,2,3...,T-1\}$ we define the stochastic scalar dynamic system 
\begin{align}\label{eq:model}
x_{k+1}&= x_k+f_k(x_k,u_k^d,u_k^n)\,\Delta t  \ + \ x_k\sigma\sqrt{\Delta t} \ \epsilon_k\\
(u_k^d,u_k^n) &= g_k(x_k).
\end{align}

Here $x~[\textrm{kg}\textrm{m}^{-2}]$ is the crop state, with time index $k$ (time is discretized as $t_k=k\Delta t$). The function $f:{\mathbb R}^3\to{\mathbb R}$ describes the dynamic interactions between state and input. The scalars  $u_k^{d}~[^\textrm{o}\textrm{C}]$ and $u_k^{n}~[^\textrm{o}\textrm{C}]$ are daily ($d$) and nightly ($n$) control inputs respectively. The inputs are determined by a state feedback control policies $g$, which is a sequence of input functions $g_k:{\mathbb R}^2\to{\mathbb R}$ for all days $k$. The stochastic variables $(\epsilon_k)_{k\in \mathbb K}$ are iid with standard Gaussian distributions. We use the notation $x^g_k$ for crop states that are found if a policy $g$ is applied for crop with an initial state $x_0^g=x_0$, which may be stochastic.

Due to the stochastic state dynamics, it cannot be predicted a priori how the state will evolve exactly, and therefore it is also not possible to a priori determine an optimal sequence of inputs. Therefore, for each point in time, $k$, and for each possible state, $x_k$, an optimal input needs to be determined.

\subsection{Control problem}
The goal is to determine a policy that maximizes value, defined by the expected revenues  $J(x_T^g)$  for crops at harvest time $T$, minus the running costs $L_k$. The associated control problem is to find a policy that satisfies
\begin{equation}\label{eq:controlproblem_0}
\max_{g\in {\cal G}} \mathbb{E} \left[ J(x_T^g) - \sum_{k=0}^{T-1} L_k(g_k(x_k^g))) \Delta t\, \right]
\end{equation} 
for any given state $x_k$, at any time $k$, over all  control laws $(g_k)_{k\in \mathbb K}$ such that $g_k$ is in an admissible set  ${\cal G}_k$. We use $\cal G$ to denote the collection of admissible sets $({\cal G}_k)_{k\in \mathbb K}$

\subsection{Dynamic programming}
Starting from an optimal solution at time $k$, the optimal solutions at the previous time point are obtained through backwards dynamic programming.
 The expected net revenue after time $k$ when starting from state value $x_k$ under policy $g$ is represented by the value functions $V_k^g:{\mathbb R}\to{\mathbb R}$ for all $k\in \mathbb K$ and $g\in\cal G$ 
\begin{equation}
V_k^g(x) = \mathbb{E}\left.\left[ J(x_T^g)-\sum_{j=k}^{T-1} L_j(g_j(x_j^g)) \Delta t   \ \right| \ x_k^g=x\right].     
\end{equation}
The control problem can be formulated as finding the control policy resulting in the maximum value
\begin{equation}\label{eq:controlproblem}
V_k^*(x) = \max_{ g\in {\cal G}} V_k^g(x),\qquad 
g^*_k = \arg\max_{ g\in {\cal G}_k} V_k^g(x),
%\mathbb{E}\left[ J(x_T)-\sum_{j=k}^{T-1} L_j(g_j) \Delta t  \right]     
\end{equation} 
for all $k\in \mathbb K$ and for all $x_k$. 


The dynamic programming principle implies that the sequence of functions $V_k^*$ can be found using the backward recursion
\begin{eqnarray}\label{eq:DPg}
    g_k^*(x)&=&\arg\max_{ g_k\in {\cal G}} \mathbb{E}\left[V_{k+1}^*(x_{k+1}^{g_k}) - L_k(g_k(x_k)) \Delta t  \right.  \ | \ x_k=x ],\\
    V_k^*(x)&=& \max_{ g_k\in {\cal G}} \mathbb{E}\left[V_{k+1}^*(x_{k+1}^{g_k}) - L_k(g_k(x_k)) \Delta t  \right.  \ | \  x_k=x ],  \label{eq:DPV}  
\end{eqnarray}
with $V_T^*(x)=J(x)$, then the policy $g^*=\{ g_1^*(x), g_2^*(x),..,g^*_{T-1}(x) \}$ is optimal \cite{Bertsekas2012}.

The conditional expectations depend on the conditional probability of state transitions described by the system model (\ref{eq:model}) \cite{Giuliani2014}, whereas the running costs at time $k$ are known once the policy has been decided. This results in 

\begin{align}\label{eq:expectancyV}
\mathbb{E}[V_{k+1}^*(x_{k+1}^{g_k})\ \mid \ x_k=x] &=\int_{\mathbb R} V^*_{k+1}(y)p_{x_{k+1}^{g_k}|x_k,g_k} (y|x,g_k) dy\\
    \mathbb{E} [L(g(x_k))\ \mid \ x_k=x]&=L(g(x_k)) \label{eq:expectancyL},
\end{align}
with the conditional probability of state transition described by
\begin{equation}
    p_{x_{k+1}^{g_k}|x_k,g_k} (y|x,g_k )  %p(x_{k+1}|x_k,g_k)
    \ = \ \frac{1}{x\sigma   \sqrt{2\pi\Delta t}}\exp{\frac{(y-f_k(x,g_k))^2}{-2\sigma^2 x^2\Delta t}}.
\end{equation}

\subsection{Discretization}
The control problem (\ref{eq:controlproblem}) was solved by applying the backward induction \eqref{eq:DPg}-\eqref{eq:DPV} on a discretized system. We thus define  $$x(i)=x_{min}+\sum_{h=1}^{i-1}\Delta x(h),\qquad i=1..N.$$ The grid shape and corresponding $\Delta x$ values are flexible and  a quadratic grid transformation was chosen (see Computational settings). The probability density of a state jump from $x(i)$ to any $x(j)$, for all $i,j$, is described by a transition matrix $A$, whose elements are defined as
\begin{eqnarray}
      \tilde{A}_{i,j}^g &=& p_{x_{k+1}^{g}|x_k,g_k} (x(j)|x(i),g ) =
    \frac{1}{x(i)\sigma   \sqrt{2\pi\Delta t}}\exp{\frac{(x(j)-f_k(x(i),g))^2}{-2\sigma^2 x(i)^2\Delta t}},\\
   {A}_{i,j}^g &=&\tilde{A}_{i,j}^g /\sum_{j=1}^n\tilde{A}_{i,j}^g.
\end{eqnarray}

We define $V^*_{k,i}=V_k^*(x(i))$ for all $1\leq i\leq N$, which reduces the backward induction in \eqref{eq:DPg}-\eqref{eq:DPV} to
\begin{eqnarray}\label{eq:controlproblemdiscrete}
V^*_{k,i} &=& \max_{ g\in {\cal G}_k}  \sum_{j=1}^N {A}_{i,j}^g (\ V^*_{k+1,j}-L_k(g)\Delta t \ ) ,\\ 
g^*_k &=& \arg\max_{ g\in {\cal G}_k}  \sum_{j=1}^N {A}_{i,j}^g (\ V^*_{k+1,j}-L_k(g)\Delta t \ ).    
\end{eqnarray} 
The values of $V^*_{k,i}$ for different $i$ are collected in a vector $\mathbf{V}_k^*$ and build an analogous matrix $\mathbf{A}^g$ from the values of ${A}_{i,j}^g$ the problem can be characterized as
\begin{eqnarray}\label{eq:controlproblemdiscretemat}
V^*_{k} &=& \max_{ g\in {\cal G}_k} \, ( \, \mathbf{A}^g\mathbf{V}_{k+1}^*-L_k(g)\Delta t \, ) ,\\ 
g^*_k &=& \arg\max_{ g\in {\cal G}_k} \, ( \, \mathbf{A}^g\mathbf{V}_{k+1}^*-L_k(g)\Delta t \, )    
\end{eqnarray} 
with $\mathbf{V}_T^*$ the vector with elements $(\mathbf{V}_T^*)_i=V^*(x_T(i))=J(x_T(i))$ for all $1\leq i \leq N$.



\subsection{Crop and Greenhouse Model}
We consider the case of lettuce crop (\textit{Lactuca sativa} L.) production inside a greenhouse that is temperature controlled. The control input at time $k$ (in days)  $u_k=(u^d_k,u^n_k)$ consists of the indoor temperature during the day and during the night, in degrees Celsius. The unit for the scalar plant mass  $x\in \{x(1),x(2),...,x(N)\}$ is kg per square meter.

\subsubsection{Growth Dynamics}
The crop growth model is based on the single state crop model of \cite{vanHenten1994}, which describes the state dynamics of the dry weight of 16 crops per $\textrm{m}^{2}$ in terms of a function $f_k:\mathbb R^3\to \mathbb R$ that is given by: % for example: $f(x,\theta,u) = x(1-x/x_{\rm max})\theta_1 u/(u+\theta_2)$
\begin{equation}\label{eq:growthdynamics}
f_k(x_k,u_k^d,u_k^n) =   c_{\rm day} c_\beta(\  c_\alpha F_k^{\rm photo}(x_k,u_k^d,u_k^n,\gamma_k) \ - \  F_k^{\rm resp}(x_k,u_k^d,u_k^n)) \ \ \ [\textrm{kg} \textrm{m}^{-2} \textrm{day}^{-1}] 
\end{equation}
with $x_k$ the crop dry weight on day $k$, $c_{\rm day}=3600\cdot 24$ a scale factor for the number of seconds in a day, and with $c_\beta=0.80$ [-], $c_\alpha=0.68$ [-]. The  photosynthesis as described by the function $F^{\rm photo}:\mathbb R^4\to \mathbb R$ depends, among others, on the sequence $\gamma_k\in {\mathbb R}^{24}$ of average radiation levels $\gamma_{k,h}$ in the Netherlands for each hour $h$ of day $k\in\mathbb K$ which equals
$$
\gamma_{k,h}=c_{\tau,cover}I_{k,h}^{\rm out},\qquad c_{\tau,cover}=0.7,
$$
since it is assumed that the measured outdoor radiation $I_{k,h}^{out}$ is partly absorbed or reflected by the cover. Empirical observations of  values for $I_{k,h}^{\rm out}$ are available and used as external input. The function $F^{\rm resp}:\mathbb R^3\to \mathbb R$ characterizes respiration. Photosynthesis and respiration are described separately in the following two sub-paragraphs.

\subsubsection{Photosynthesis}
The photosynthesis rate on any given day $k$ is the weighted average over daily and nightly photosynthesis rates which are themselves the average photosynthesis over hours during the day and night respectively\footnote{The criterion to decide whether hour $h$ of day $k$ is day or night is defined as follows: it is night whenever radiation $\gamma_{k,h}$ during that hour
%(which is given in an external data file for every day of the year and every hour in that day) 
is lower than the critical value $c_{Ith}=20 \textrm{W}\textrm{m}^{-2}$}. This leads to the specification\footnote{Note that the unit is $s^{-1}$, and that the growth rate is converted to $\rm{day}^{-1}$ by $c_{\rm day}$ in \eqref{eq:growthdynamics}.}
\be
F^{\rm photo}_k(x_k,u_k^d,u_k^n,\gamma_k)&=&  \sfrac{1}{24}\sum_{h=0}^{23}(
 F^{\rm photo}(x_k,T_k^d(u_k^d),\gamma_k^d){\bf 1}_{(k,h){\rm\ is\ day}  }\\&&\qquad
\ + \
 F^{\rm photo}(x_k,T_k^n(u_k^n),\gamma_k^n){\bf 1}_{(k,h){\rm\ is\ night}}) \ [\textrm{kg} \textrm{m}^{-2} \textrm{s}^{-1}].\
\ee
The values are based on the average daytime temperature $T_k(u_k^d)$, the average nighttime temperature $T_k(u_k^n)$ and  average daytime and nighttime radiation levels $\gamma_k^d$ and $\gamma_k^n$ that are defined below; we use these instead of hourly values to speed up computations. Temperature averages depend on the control variables for indoor temperatures but also on the  outside temperature for hour $h$ of day $k$, $T_{k,h}^{\rm out}$. It is assumed that on average the indoor temperature is in steady state. Since there is no active cooling (e.g. by pad fan or humidifiers), and since indoor temperature is usually kept equal to, or higher than outside temperature to prevent problems with high relative humidity, it is required that the indoor temperature is equal to, or higher than the outside temperature. This gives the following averages:
\be
T_k^d(u_k^d) &=& \frac
{\sum_{h=0}^{23} (T_{k,h}^{\rm out}\vee u_k^d){\bf 1}_{(k,h){\rm\, is\ day} }}{\sum_{h=0}^{23} {\bf 1}_{(k,h){\rm\, is\ day}} },\qquad\
\gamma^d_k \ = \ \frac
{\sum_{h=0}^{23} \gamma_{k,h}{\bf 1}_{(k,h){\rm\, is\ day} }}{\sum_{h=0}^{23} {\bf 1}_{(k,h){\rm\, is\ day}} }
\\
T_k^n(u_k^n) &=&\frac
{\sum_{h=0}^{23} (T_{k,h}^{\rm out}\vee u_k^n){\bf 1}_{(k,h){\rm\, is\ night} }}{\sum_{h=0}^{23} {\bf 1}_{(k,h){\rm\, is\ night}} },\qquad
\gamma^n_k \ = \ \frac
{\sum_{h=0}^{23} \gamma_{k,h}{\bf 1}_{(k,h){\rm\, is\ night} }}{\sum_{h=0}^{23} {\bf 1}_{(k,h){\rm\, is\ night}} }.
\ee
Here $a \vee b$ denotes the maximum between $a$ and $b$. The photosynthesis function itself is
\be
F^{\rm photo}(x,T,\gamma) &=&
\phi_{\rm phot,max}(T,\gamma)\cdot(1-e^{-c_k c_{\rm lars}(1-c_{\tau,\rm resp})x}) \ \ [\textrm{kg} \textrm{m}^{-2} \textrm{s}^{-1}]
\ee
with extinction coefficient $c_k=0.90$ [-], shoot leaf area ratio $c_{\rm lars}=62.5$ [m$^2$ kg$^{-1}$], root to total crop dry weight ratio $c_{\tau,\rm resp}=0.07$ [-]. It depends on
\be
\phi_{\rm phot,max}(T,\gamma) &=& \frac{\epsilon(T)c_{\rm par}c_{\rm radrf}\gamma \sigma(T)(c_{CO2}-\Gamma(T))}{\epsilon(T)c_{\rm par}c_{\rm radrf}\gamma+\sigma(T)(c_{CO2}-\Gamma(T))} \ \ [\textrm{kg} \textrm{m}^{-2} \textrm{s}^{-1}].
\ee
The carbon dioxide compensation point $\Gamma$ in this expression equals 
\be
\Gamma(T) &=& c_{\gamma}\cdot{c_{\rm q10resp}}^{c_{\rm a resp}(T-c_{\rm reftemp})}.
\ee
We have $c_{\gamma}=7.32\cdot10^{-5}$ [kg m$^{-3}$], $c_{\rm q10resp}=2$ [-], $c_{\rm a resp}=0.10$ [$^\textrm{o}\textrm{C}^{-1}$] and $c_{\rm reftemp}=20$ [$^\textrm{o}\textrm{C}$],
with an average density of $\textrm{CO}_\textrm{2}$ in air of $c_{\rm CO2}=0.720$ [kg m$^{-3}$] (corresponding to 400 ppm),
photosynthetically active radiation ratio $c_{\rm par}=0.50$ [-], and transmission coefficient of the roof for solar radiation $c_{\rm radrf}=0.42$ [-].

The effect of photorespiration on light use efficiency is
\be
\epsilon(T) &=& c_{\epsilon}\frac{c_{CO2}-\Gamma(T)}{ c_{CO2} + 2\Gamma(T) },
\ee
with light use efficiency coefficient $c_{\epsilon} = 17 \cdot 10^{-9}$ [kg J$^{-1}$]. The leaf conductance to carbon dioxide transport function $\sigma$ is
\be
\sigma(T) &=& ( \frac{1}{c_{\rm bnd}}+\frac{1}{c_{\rm stm}}+\frac{1}{\sigma_{\rm car}(T)})^{-1}
\ee
with $c_{\rm bnd}=0.004$ [s$^{-1}$] and $c_{\rm stm}=0.007$ [s$^{-1}$]. Further,
\be
\sigma_{\rm car}(T) &=& \ c_{\rm car,2}T^2 + c_{\rm car,1} T + c_{\rm car,0}
\ee
with $c_{car,2}=-5.11\cdot10^{-6}$, $c_{car,1}=2.3\cdot10^{-4}$ and $c_{car,0}=-6.29\cdot10^{-4}$.


\subsubsection{Respiration Dynamics}
The respiration rate is averaged per day, as was the case for photosynthesis,
\be
 F_k^{\rm resp}(x_k,u_k^d,u_k^n) &=&
 \sfrac{1}{24}\sum_{h=0}^{23}(
 F^{\rm resp}(x_k,T_k^d(u_k^d))
{\bf 1}_{(k,h){\rm\ is\ day}  }\\&&\qquad
\ + \
 F^{\rm resp}(x_k,T_k^n(u_k^n)){\bf 1}_{(k,h){\rm\ is\ night}} \ ), \ [\textrm{kg} \textrm{m}^{-2} \textrm{s}^{-1}]
\ee
with
\begin{equation}\label{eq:respiration}
 F^{\rm resp}(x,T) =
x\cdot c_{\rm resp}\ {c_{\rm q10resp}}^{c_{\rm a resp}(T-c_{\rm Tempref})},
\end{equation}
with $c_{\rm Tempref}=25$, and
$c_{\rm resp}= c_{\rm s resp} (1-c_{\rm \tau resp} )  + c_{\rm r resp}c_{\rm \tau resp},
$ with $c_{\rm \tau resp}=0.07$ [-]. Maintenance respiration for shoot is $c_{\rm s resp}= 3.47\cdot10^{-7}$ [\rm s$^{-1}$], maintenance respiration for root is $ c_{\rm r resp}= 1.16\cdot10^{-7}$ [\rm s$^{-1}$] while as before $c_{\rm q10resp}=2$ [-] and  $c_{\rm a resp}=0.10$.


\subsection{Cost and revenue functions}

\subsubsection{Running costs}
The running costs $L_k$ on day $k$ depend on the amount of heating required. This depends on the incoming outside radiation $I_{k,h}^{out}$ for hour $h$ of day $k$ and the earlier established average daytime and nighttime temperatures based on the control setpoints $u_k^d$ and $u_k^n$.
Running costs also depend on the outside air temperature $T^{\rm out}_{k,h}$, sky temperature $T^{\rm sky}_{k,h}$ and wind speed $V^{\rm wind}_{k,h}$, in a way that is specified below.

Heating is needed during hour $h$ of day $k$ when $u_k>T^{\rm out}_{k,h}+I_{k,h}/Q_{k,h}, \qquad I_{k,h}=I_{k,h}^{out}\cdot c_{\tau,cover} \cdot c_{sens}.$ %\hl{ $I^{\rm out}$ was previously called $I^{\rm glob}$? (I cannot find instances of Iglob in the text, but in the code it was called Iglob.) And definition of radiation above implies that $I_{k,h}=c_{sens}\gamma_{k,h}$ which is perhaps nicer since more similar to specification of photosynthesis part? (I like it better as it is, since it distinguishes the incoming radiation and reduction factors)} 

Here $c_{\tau,cover}=0.7$ is the transmissivity of the cover [-], $c_{sens}=0.3$ is the fraction of radiation that is converted into sensible heat inside the greenhouse [-], and $Q_{k,h}$ is the specific heat loss through ventilation and transmission heat per Kelvin temperature difference [$\rm W \textrm{m}^{-2} K^{-1}$]. 

It is assumed that both $c_{\tau,cover}$ and $c_{sens}$ remain constant over time. 
%$I_{k,h}^{out}\cdot c_{\tau,cover} \cdot c_{sens}$ is expressed as $I_{k,h}$. 
Heating costs are calculated separately for the heating demand in daily and nightly hours since at night it is assumed that the thermal screens are closed, to reduce heat loss. 

The heating cost can then be expressed as:
\be
L_k(u_k^d,u_k^n) &=& c_L \sum_{h=0}^{23}\ [ \ ( \
Q_{k,h}(u_{k}^d)\cdot (u_k^d-T^{\rm out}_{k,h})-I_{k,h}\ )^+ \,
{\bf 1}_{(k,h){\ \rm is\ day}}\\
&&\qquad\ \ +  ( \
Q_{k,h}(u_k^n)\cdot (u_k^n-T^{\rm out}_{k,h})-I_{k,h}\ )^+ \,
{\bf 1}_{(k,h){\ \rm is\ night }}\ ] \ [\rm{GJ \,day}^{-1}],
\ee
with $c_L = 3.6\,10^{-6}\, c_{\rm pGJ} / c_{\rm eff}$. The number $3.6\,10^{-6}$ represents the conversion from seconds to hours, and from joule to gigajoule ($[{\rm sh}^{-1} \rm{J}\,{\rm GJ}^{-1}]$). Furthermore, $ c_{\rm pGJ} =11$ is the estimated price in \euro\ per GJ gross energy\footnote{ This is based on 
a gross natural gas price of 0.04 \euro/KWh = 11\euro/GJ. }, and $c_{\rm eff}=0.90$ is the water sided efficiency of the heater.

The energy flux $Q$ is calculated as follows:

\be
Q_{k,h}(u) &=&   \rho c_p \cdot\Phi_{k,h} +  c_{\rm As}  \frac{ c_{\rm Sc}{\bf 1}_{(k,h){\ \rm is\ night}} + {\bf 1}_{(k,h){\ \rm is\ day}}}  {1/c_{\alpha} + 1/ (\alpha_{k,h}(u)+{\rm \alpha}_{e,k,h})\ },\\
\alpha_{k,h}(u)&=& 100\wedge  4 c_{\epsilon} \, c_{\sigma}\,
 (\, \sfrac{1}{2}u + \sfrac{1}{2}T^{\rm out}_{k,h} + 273.15\, )^3 \ \left| \frac{u-T^{\rm sky}_{k,h}}{u-T^{\rm out}_{k,h}}\right|,\\
 \Phi_{k,h} &=& (0.2\cdot {\bf 1}_{(k,h){\ \rm is\ night}} + {\bf 1}_{(k,h){\ \rm is\ day}})
\, c_{\rm navg}\, c_{\rm H}.
\ee

Here $\rho c_p$ is specific heat of greenhouse air which is approximately 1206 [$\rm J \, m^{-3} \, K^{-1}$] at 20 $^o$C air temperature, $\Phi$ is the heat flux through ventilation, $c_{\rm As}=1.12$ the specific greenhouse cladding area $[-]$, $c_{Sc}=0.6$ the energy screen factor $[-]$, $c_{\rm navg}=0.25/3600$ the average ventilation rate [$s^{-1}$] when the greenhouse is heated, and $c_{\rm H}=6$ the average greenhouse height $[\textrm{m}]$.  The heat conductivity is a sum of effects due to  radiation and convection so 
$c_{\alpha} = c_{\rm \alpha si} + c_{\rm \alpha ci}$ with  $c_{\rm \alpha si}=4.9$ [$\rm W \, m^{-2} \, K^{-1}$] and $c_{\rm \alpha ci}=2.98$ [$\rm W \, m^{-2} \, K^{-1}$]. The constant
 $c_{\epsilon}=0.90$ is the emission constant for the greenhouse cover material for thermal infrared, and $c_{\sigma}=5.67\cdot 10^{-8}$ is the Stefan Boltzmann constant. Furthermore,
\be
{\rm \alpha}_{e,k,h} &=& 2.5(V^{\rm wind}_{k,h})^{0.8}{\bf 1}_{V^{\rm wind}_{k,h}>4} + (2.8+1.2V^{\rm wind}_{k,h}){\bf 1}_{V^{\rm wind}_{k,h}\leq 4}.
\ee

Here ${\rm \alpha}_{e,k,h}$ represents the convective heat transfer at the outside of a saw-tooth shaped roof  \cite{bot1983,dezwart1996}.

\subsubsection{Revenues}

The revenues associated with crop yield are expressed by the following goal function

\begin{equation}\label{eq:revenues}
J(x)= \ c_{\rm dryfrac}\, c_{\rm price} x  {\bf 1}_{x \in [x^*-\Delta_H,
x^*+\Delta_H]}.
\end{equation}  
    
Here $\Delta_H$ determines the allowed margin of harvested weight (e.g. due to delivery contracts based on consumer demand for product uniformity). The nominal value is $\Delta_H=15 \rm \,g\, m^{-2}$. Further, $c_{\rm dryfrac}=20$ at a dry matter content of 5\% and $c_{\rm price}=0.25/0.4$, that is \euro 0.25 per head of 400 g. The two constants represent the conversion from dry to fresh weight, and the revenues associated with fresh weight, respectively. Assuming an ideal fresh weights of 400 grams per crop head \cite{KWIN2019}, and 16 plants per $\rm m^{-2}$, this comes to a dry weight of $x^*=400/ c_{\rm dryfrac}\cdot 16= 320 \, \rm g \,m^{-2}$. The revenue function is displayed in Figure \ref{fig:goalfunction}. 

\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{Images/Goalfunction.jpg}
    \caption{Goal function $J(x)$. The harvested weight is required to fall within a bandwidth of 30 grams around the ideal weight of 320 grams.}
    \label{fig:goalfunction}
\end{figure}


\subsection{Visualization}

The outcomes of the dynamic programming algorithm to find the optimal policy form a 4-tuple $(u^{d*}_k(x_k),\, u^{n*}_k(x_k),\, f^*_k(x_k),\, g^*_k(x_k) )$ for every day $k\in\mathbb K$ and every possible value of the state $x_k$. Here $f^*_k(x_k)$ is defined as the growth acoording to the optimal policy given the current state, so $f^*_k(x_k)=f(x_k,g^*_k(x_k))$. 

In the following section we will show plots of these four characteristics of the  optimal day and night temperatures, optimal plant growth  and optimal revenues to create some intuition for the rationale behind the optimized policies.

\subsection{Computational settings}
\begin{itemize}
    \item All numerical computations were carried out within a Matlab environment.
computational grid: $N \times T =300 \times 50$. The state is discretized into $N=300$ parts for the nominal and static controller, and into $N=900$ parts for the deterministic controller. The time horizon is $T=50$ days, and $\Delta t =$ 1 day.
% MENTION CONVERGENCE RATES AND GRID CHOICE IN M&M
% log(n) - log(error); error = y - y(most accurate)
% dx^2 ~ x^2 sigma^2 dt 

% n=300   -4.9082   -4.9079
% n=600   -4.7066    -4.7058
% n=900  - 4.7921  eruit
% n=1200  -4.7734
% n=1500  -4.8030  eruit 

% nominal Vmax
% n=200: -5.6938
% n=300: -5.73 
% n=600: -5.72
% n=900: -5.7409
\item The state space ranges from $[5,400]~\textrm{g} \textrm{m}^{-2}$, and the initial state in the dynamic simulations was $x_0=5 \textrm{g}\textrm{m}^{-2}$ unless stated otherwise.
\item The optimization algorithm to solve equation (\ref{eq:controlproblemdiscretemat}) was carried out with the 'fmincon' routine.  
The set of admissible control values is ${\cal G}=[5,10]\times [5,20]$, in $^\textrm{o} \textrm{C}$. This means that the night temperature setpoint is within the range $[5,10]$ $^\textrm{o} \textrm{C}$, and the day setpoint is within the range $[5,20]$ $^\textrm{o} \textrm{C}$.
\item The weather data was retrieved from Bleiswijk, The Netherlands (52°02N 4°32E) 2014 The Netherlands, as was done in a previous study \cite{Katzin2020}. 
\item For each selected day, the following period of 50 days is assumed to have the same daily weather pattern as the selected day. This simplification was done to examine the control strategy based on solely crop state and time before harvest, and not changes in weather. The uncertainty associated with possible forecast errors is assumed to be accounted for by the stochastic state noise. 
\item Since the crop growth curves typically had quadratic shapes, with slow absolute growth in the beginning, and large growth near the end of the production cycle, the grid was locally refined using the transformation $x_i=y_i^2$, where $y_i=y_{min}+i\Delta y$, with $\Delta y=\frac{y_{max}-y_{min}}{N+1}$, and $y_{max/min}=\sqrt{x_{max/min}}$. This transformation helped improve upon computational efficiency. For example, without transformation $N=400$ was required to avoid numerical problems with the 'fmincon' routine, whereas with transformation $N=100$ was sufficient.  
\item The maximum start value was defined as the maximum expected net revenues at start of production cycle, with initial value $x=x_0$. This value was calculated as $V^{max}(x_0)= \mathop{\max}_{t_0\in {V^*(x_0,t_0)}} $. 
\end{itemize}

\subsubsection{Part I}
The following settings were used for part I.
\begin{itemize}
\item The nominal weather pattern has relatively much light, and low temperatures (day 80 in 2014, mean temperature was 4.6 $^\textrm{o} \textrm{C}$, and mean light intensity $190~\textrm{W}\textrm{m}^{-2}$), that creates a heat limitation in the greenhouse. That is, extra heating during the day will result in increased crop growth. 
For two other weather patterns the control laws and corresponding performance was computed, namely for day 6 of the year (mean temperature was -4 $^\textrm{o} \textrm{C}$, and mean light intensity $53~\textrm{W}\textrm{m}^{-2}$), and for day 188 (mean temperature was 18 $^\textrm{o} \textrm{C}$, and mean light intensity $330~\textrm{W}\textrm{m}^{-2}$).
\item The nominal stochastic noise level was $\sigma^2=10^{-4}~[\rm kg^{-1} m^2 day^{-1}]$. 
\item The stochastic noise level was changed to $5~10^{-5} \,[\rm kg^{-1} m^2 day^{-1}]$ and to \\ $\sigma^2=5 \,10^{-4}~[\rm kg^{-1}  m^2 day^{-1}]$.
\item The nominal harvest margin was $\Delta_H = 15 ~[\textrm{g} \textrm{m}^{-2}]$
\end{itemize}

\subsubsection{Part II}
The following settings and methods were used for part II.
\begin{itemize}
    \item The static controller input $(u^d,u^n)$, as a function of starting time $t=t_0$ was retrieved by directly solving equation (\ref{eq:controlproblem_0}), using the 'fmincon' algorithm for for varying starting times, and for fixed initial weight $x(t_0)=x_0$.  
    \item A deterministic optimal controller was mimicked by applying the original stochastic control algorithm at nominal settings, with a noise variance that was reduced with a factor 100 ($\sigma^2=10^{-6}$). Strictly speaking this is still a stochastic controller, however one that approaches a deterministic one in the sense that it is designed under the assumption that noise effects are almost absent (as can be seen in figure \ref{fig:dyn_det}) and therefore deemed negligible.  
    \item The controllers were compared to the original controller by evaluating the expected net revenues at the optimal starting time (the one that maximizes $V^*(x_0,t)$). 
\end{itemize}

\section{Results Part I}

\subsection{System dynamics}

Figure \ref{fig:nominaldynamics} show the controlled dynamics of the probability density of crop weight starting at time $t=0$, together with the goal function. 
\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{Images/Dynamics_day80.jpg}
    \caption{The probability density dynamics of crop weight at 20\% intervals of final time $T$. The dispersion is relatively small compared to the allowed harvest margin, so there is in this case not much risk that the harvest weight will end up outside the allowed weight margin (dotted line). In this case, the controller steers the maximum likelihood to 2 grams above the ideal weight of $=320 \textrm{g}\textrm{m}^{-2}$.}
    \label{fig:nominaldynamics}
\end{figure}

The maximum likelihood of the state at harvest time $x(T)$ is $322~\textrm{g}\,\textrm{m}^{-2}$, which is only slightly higher than the ideal weight of $=320 ~\textrm{g}\,\textrm{m}^{-2}$. It can be seen that the probability density of crop weight disperses over time. The dispersion is relatively small compared to the allowed harvest margin, so there is in this case not much risk that the harvest weight will end up outside the allowed weight margin (dotted line). A larger dispersion will result in lower  expected net revenues, which can intuitively be seen from the the figure, and can be explained using the formula $V(x_T)=\mathbb{E}J(x_T)=\int J(x_T)p(x_T)dx_T$. If $p$ has a high dispersion, the product inside the integral will have a low mean value. 

\subsection{Control policy and performance}
Figure \ref{fig:nominal} show 1) the control strategy (daily and nightly temperature set-points),  2) resulting growth rates, and 3) associated value $V$ (expected net revenue) for all $x_k$ and $k$ in four heat maps, where the color scales with the intensity. The optimal indoor night and day temperatures shows clearly that the decision to heat or not depends on time and state. From this it can be concluded that a time-varying feedback controller, or a dynamic but state-independent optimal controller would in principle be suboptimal. 

\begin{figure}
    \centering
    \includegraphics[width=1.0\textwidth]{Images/day80.jpg}
    \caption{Optimal control policy (top), and corresponding performance (bottom) for day 80 in 2014. Top left: indoor day temperature. Top right: indoor night temperature. Bottom left: crop growth rate. Bottom right: value function $V$ (expected net revenues).}
    \label{fig:nominal}
\end{figure}

% Observation 
The regions in state space where input is applied (for heating during the day, this is roughly from 0 $\textrm{kg} \textrm{m}^{-2}$ at day 10 to 0.3 $\textrm{kg} \textrm{m}^{-2}$ at day 50, and from 0 $\textrm{kg} \textrm{m}^{-2}$ at day 30 to 0.15 $\textrm{kg} \textrm{m}^{-2}$ at day 50), form convex bands around the optimal state trajectory. These controlled regions have sharply defined borders, within which growth rate and consequently expected net revenues are controlled substantially, and outside which
there is little to no control input. The controlled regions are quite small. This is at least partly due to the fact that there is only a small region within it is at all possible steer crop weight towards the desired range defined in (\ref{eq:revenues}), which not surprising since there is only a single constrained input (heating). In any case,  outside the controlled regions there is no control signal available to steer back in such a way that the value (i.e. expected net revenue) is larger than zero.  

The controlled regions translate into a single band in the growth rate plot, and also in a band in the value plot. Within this band, value is relatively high since it is expected that the crop weight at harvest time will be inside the desired range of harvest weight defined in (\ref{eq:revenues}) (so, close to the desired weight of 320 $\textrm{g} \textrm{m}^{-2}$). Outside the band the value is zero or close to zero, since the harvest weight is expected to fall outside the range. Close inspection reveals that the indoor day temperature controlled region coincides with the lower part of the value band. Hence, the lower part of the value band is high due to an elevated growth rate. Physiologically this can be explained by the fact that under high light intensities, and low temperatures, growth is limited due to inhibition of metabolic processes that convert carbohydrates produced by photosynthesis, to dry matter. The controlled region for the indoor night temperatures translates into a region with a lowered growth rate. Physiologically this can be explained by the fact that in absence of photosynthesis in the night, a higher temperature will increase the maintenance respiration rate (equation (\ref{eq:respiration})) and thereby decrease growth rate (equation (\ref{eq:growthdynamics})). Close inspection reveals that the elevated night temperatures coincide largely with the upper part of the value band. So these values remain high due to heating during nighttime. In summary, day temperatures are elevated to increase growth rate, and night temperatures are elevated to decrease growth rate, thereby keeping crop growth on track towards one of the two ideal weights. 

At harvest time, the bands in the value plot are most narrow, and have the highest values. In other words, the earlier the moment of starting the crop production cycle, the more the bands in the value plot are dispersed. This outcome can be explained by realizing that a long production cycle generally there is more risk along the way of getting off track, compared to a short production cycle. It can also be seen that on average, the value function increases with time (from left to right the colors in the value plot get lighter on average). The explanation for this observation is that the running costs $L$ monotonously increase over time. The values near day 0 are slightly negative for most $x_0$ values. This is explained by the requirement that the minimal indoor temperature equals the outdoor temperature. Especially at night, the radiative heat loss may require additional heating input of which the investment surpasses the harvest value, which will result in a negative net value. In other words, the combination of precise harvest weight requirements with poor timing of the start of a production cycle (or of the initial weight), can result in a very small harvest value, that is surpassed by the costs due to the heating requirements. 

The sensitivity of value towards starting day of the growth cycle is quite low. The value (the expected net revenue, $V^*(x_0,t_0)$) displays a large robustness towards timing of starting day. Varying $t_0$ from 1-10 days, results in variation in values in the range $[5.1-5.7]$ \euro \,$m^{-2}$. 

\subsection{Different weather patterns}
To illustrate that the control policy depends largely on weather pattern, two days were selected with weather patterns contrasting that of the nominal case. With the weather in day 6, growth is limited due to low temperature as well as low light intensity (mean temperature was -4 $^\textrm{o} \textrm{C}$, and mean light intensity $53~\textrm{W}\textrm{m}^{-2}$). At day 188 growth is light limited (mean temperature was 18 $^\textrm{o} \textrm{C}$, and mean light intensity $330~\textrm{W}\textrm{m}^{-2}$). The results are shown in figure \ref{fig:differentdays}. 

\begin{figure}
    \centering
    \includegraphics[width=0.49\textwidth]{Images/day6.jpg}
    \includegraphics[width=0.49\textwidth]{Images/day188.jpg}
    \caption{Results for different weather patterns. Left: For a weather pattern with low temperature and low light intensity (-4 $^\textrm{o} \textrm{C}$ and $53~\textrm{W}\textrm{m}^{-2}$) the input policy differs from the nominal case, as daytime heating is prescribed to decrease crop growth. Right: For a weather pattern with high temperature and mean light intensity (18 $^\textrm{o} \textrm{C}$ and $330~\textrm{W}\textrm{m}^{-2}$) heating input is not prescribed at any time and for any state. Nonetheless, a high overall growth rate is observed, resulting in a production round that lasts around 29 days, and a steep, lowly dispersed band in the value plot.}
    \label{fig:differentdays}
\end{figure}

For the weather pattern in day 6 there is barely any growth possible, as can be seen from the growth rate plot (maximum growth rate is around 2.5 $\rm g \, m^2 \, day^{-1}$, compared to 8 $\rm g \, m^2 \, day^{-1}$ for day 80). This can also be seen from the shapes of the controlled regions, which suggest a less steep growth curve compared to day 80. The value plot indicates that the optimal state trajectory starts around 0.25 $\textrm{kg}\, \textrm{m}^{-2}$, which means that in 50 days only 0.07 $\textrm{kg} \, \textrm{m}^{-2}$ is gained. It is tempting to conclude from this plot that with this weather pattern, and with only heating input, the ideal harvest weight can only be achieved when starting with almost full grown plants. However, the costs of acquiring almost full grown plants will be much higher than the costs of acquiring small plants, and this aspect is not incorporated in the cost function (only running costs are). Hence, this conclusion does not hold. A more correct way to draw conclusions is to assume that each production round starts with plants of the same weight, and to extend the duration of the production round time such that there exist a control scheme that steers the crop weight to within the desired range at harvest time. In that way, running costs are compared fairly between days with different weather patterns. Nonetheless, additional costs for running the greenhouse for a longer time, such as staff work hours and rent, would not be incorporated in such a scenario comparison. 

The temperature plots show that high heating is used to decrease crop weight during day and night, and that there is a controlled region in which day temperature is slightly elevated to increase growth rate. Compared to day 80 the input policy has changed in a fundamental way; daytime heating is prescribed to decrease growth rate, whereas before the role of growth decrease was assigned only to nighttime heating.

For the weather pattern of day 188, growth is limited by light, and hence there is no role at all for heating as a means to control growth. As a result, the daily and nightly setpoints assume the values of the outside temperatures during day and night, respectively. Despite the light limited growth, and absence of additional heating, the growth rate plot indicates a high maximum growth rate (around 12 $\textrm{g}\textrm{m}^{-2} \textrm{day}^{-1}$, compared to 8 $\textrm{g}\textrm{m}^{-2} \textrm{day}^{-1}$ for day 80). The value plot indicates an optimal state trajectory with a steep growth curve, and a production round that only lasts around 29 days. The short time of the production round explains the relatively low dispersion in the band in the value plot. 

\section{Results part II: comparison against static and deterministic control}

The stochastic control policy is state and time dependent. The performance is compared to a static control policy that does not depend on state or time, but is optimized for stochastic noise. The second comparison is against a deterministic controller, that is optimized with respect to state and time, however does not deal with stochastic noise.  

\subsection{Comparison with static control}

Figure \ref{fig:perf_static} shows the dynamics of state probabilities with a static controller, compared to the original controller for the nominal case, starting from day 1. It can be seen that the uncertainty with static control is considerably larger. More specifically, at harvest time standard deviation has increased with 86 \% ($13~ \textrm{g} \textrm{m}^{-2}$) compared to the original controller ($7~ \textrm{g} \textrm{m}^{-2}$). This means that at harvest time on average a deviation of 12 grams dry weight per square meter is to be expected. The difference between the static and original control performance is explained by the fact that the original controller actively steers the weight towards the optimal trajectory by adjusting the input whereas the static controller does not have such a compensation mechanism. Furthermore, static control results in a 19 \% decrease in maximal value at starting time ($V^{max}(x_0)=4.6$ \euro $\,\textrm{m}^{-2}$ compared to $5.7$  \euro $\,\textrm{m}^{-2}$ for the original controller). 

The robustness of value towards starting day of the growth cycle is comparable to that of the original controller. The value (the expected net revenue, $V^*(x_0,t_0)$) displays a large robustness towards timing of starting day. Varying $t_0$ from 1-10 days, results in variation in values in the range $[3.9-4.6]$ \euro $\,\textrm{m}^{-2}$, which is a 15\% variation. 

\begin{figure}
    \centering
    \includegraphics[width=0.48\textwidth]{Images/uconst.jpg}
        \includegraphics[width=0.48\textwidth]{Images/ustoch.jpg}
    \caption{Dynamics of probability through static control (left), and stochastic control (right). With stochastic control the standard deviation at harvest time is approximately 50\% smaller compared to static control.}
    \label{fig:perf_static}
\end{figure}

\subsection{Comparison with deterministic control}
Figure \ref{fig:dyn_det} shows the probability dynamics using a deterministic controller. When the controller is applied to the deterministic system where it is designed for, there is (practically) no uncertainty, and the controller steers the state precisely towards the value for which $J$ is maximal. However, when it is applied to the stochastic system, the standard deviation is much higher; at harvest time standard deviation has increased with roughly 40 \% ($10~ \textrm{g} \textrm{m}^{-2}$) compared to the original controller ($7~ \textrm{g} \textrm{m}^{-2}$). The state that maximizes $J$ is in this case theoretically optimal, however it is also not very robust in the sense that only a small positive deviation from this optimum results in $J=0$ (a zero payoff). In case of noise the controller should aim for a lower final state, such that the expected net revenue is more robust against possible deviations in final state. In this particular case there is a very strict payoff function, however for a less strict $J$ the principle that optimizing the expected net revenue requires balancing optimality with robustness. 

\begin{figure}
    \centering
    \includegraphics[width=0.48\textwidth]{Images/Dynamics_det_control.jpg}
        \includegraphics[width=0.48\textwidth]{Images/Dynamics_det_control_noise.jpg}
    \caption{Dynamics of probability using deterministic control. Left: deterministic controller applied to deterministic system. Right: deterministic controller applied to stochastic system.}
    \label{fig:dyn_det}
\end{figure}


Figure \ref{fig:perf_deterministic} shows the control policy and performance of the deterministic controller.

\begin{figure}
    \centering
    \includegraphics[width=0.99 \textwidth]{Images/Deterministic_control.jpg}   
    \caption{ Optimal policy, and corresponding performance for the deterministic controller. Compared to the original controller, the controlled region is more time and state specific. The value plot shows a relatively small band with high values, indicating a small robustness against deviations from the optimal state trajectory.}
    \label{fig:perf_deterministic}
\end{figure}

For indoor day temperature, the size of the controlled region is somewhat larger compared to that of the original controller (compare Figure \ref{fig:nominal}). Overall, the prescribed control input is smaller than for the original controller, and much more time and state specific, which can be seen from the fragmented coloration (The possible influence of erroneous local minima was checked by using different starting points in fmincon. Small differences were observed, but the general outcomes remain the same). This is likely because the dynamics are almost precisely known, allowing for very specific timing and dosage. For indoor night temperature, the controlled region is almost absent.  

Close inspection of the value plot reveals that applying the deterministic controller on the stochastic system, with nominal noise variance, results in a 16\% loss of value at start time compared to the nominal case ($V^{max}(x_0)=4.8$ \euro $\,\textrm{m}^{-2}$ compared to $5.7$ \euro $\,\textrm{m}^{-2}$)). The bandwidth containing high values is much smaller. Also, there is no sharp contrast anymore, but the values decline gradually, and there is a relatively small bandwidth in which the values are close to optimal. For example, at day 30 the vertical width of the bright yellow band is $22~ \textrm{g}\textrm{m}^{-2}$, so there is a 22 gram range within which the controller can achieve more or less the optimal harvest weight. For the original controller the margin is 48 gram. Hence the loss in robustness, quantified as the allowed deviation from the optimal state trajectory with small or no loss of value, is 54 \%.  

The sensitivity of value towards starting day of the growth cycle is relatively high. Between days 1-10 the value ranges within $[2.0-4.8]$ \euro $\,\textrm{m}^{-2}$, which is a 60 \% variation. Hence for this particular case and with this controller, the performance in terms of expected net revenue, displays a large sensitivity towards timing of starting day. 

% Deterministic
% n=300: -3.9007   -4.1265   -4.6913   -4.9082   -4.8922   -4.6768   -3.7668   -2.3117   -0.8419    0.1228
% n=600: -2.0657   -2.2791   -2.7939   -3.2687   -3.7990   -4.1330   -4.5768   -4.7066   -3.9917   -2.4949
% n=900: -1.9566   -2.1364   -2.4195   -2.6835   -3.1893   -3.5466   -3.9858   -4.5484   -4.8384   -4.3033


\section{Discussion}
\subsection{Part I}

\subsubsection{Visualization and link to crop physiology}
By visually linking together the optimal control policy and subsequent crop dynamics and performance in terms of value (expected net revenues) in maps of time and state space (figure \ref{fig:nominal}), transparency is created in the sense that some mechanisms that underlie the outcomes of a rather complex optimization algorithm become intuitively clear. In particular, the comparison between input, crop dynamics, and value function reveals that temperature increases are used to steer the weight in case it deviates from its optimal trajectory towards a desirable harvest weight. It is particularly interesting to see that an elevated indoor temperature is prescribed to accelerate the crop growth rate during daytime and to decelerate it during nighttime. Heating during the day to accelerate the growth makes sense physiologically since increasing assimilate production and conversion to cell matter requires heat and light. Heating during the night to decelerate the growth makes sense since without light there will be no dry matter production, so assimilate loss will increase due to increased maintenance respiration. However, the question is what this means for crop quality. It is well known that an imbalance between heat and light input can result in thick yellow leaves due to starch buildup in case of heat limitation, or in long thin leaves in case of light limitation. Any violations to the requirements regarding the heat-light balance can be spotted relatively easily by crop physiology experts, and can be prevented through refinements in the definition of control input domain $\cal G$. 
This way of representation might help elucidate the rationale behind the optimal control policy so that possible mistakes due to weakness of the model can be spotted and prevented by subsequent model refinements. Such refinements could be in the form of model extension, or refinement in the control input domain, as mentioned above. A model extension could mean extending the state space model by incorporating additional states or inputs.

\subsubsection{Model refinement and computational demand}
Model extensions come at a computational price; if the number of states is $d$, and each state consists of $N$ parts, the number of possible states used in matrix $A_{i,\cdot}$ and the number of optimizations to be solved for each $k$ in equation \ref{eq:controlproblemdiscretemat} is $N^d$, a number that grows exponentially fast with $d$. A possible way to mitigate the high computational costs is to employ a reinforcement learning strategy \cite{Tchamitchian2005, zhang2021, Ajagekar2022}, where an optimal policy is constructed by exploring only a fraction of all possible state combinations. As can be see in the control map (e.g. figure \ref{fig:nominal}), a large fraction of the possible states is unlikely to be realized (large weights near the start, and small weights near the end of the cultivation round), hence an optimal policy does not necessarily need to cover those instances. Incorporating multiple inputs ($N_u$ ) will increase computational demand: for each of the $N^d$ optimizations, a minimum needs to be found within an $N_u$ dimensional space. 
% perhaps a smart way is not exploring the full space/all possible state transitions since some of them are not likely to happen, or not relevant. This is also seen in the relatively small size of the controlled region. 

\subsubsection{Visualization challenges}
In case the model is extended to more than one state, a transparent visualization will probably become challenging. Currently, the horizontal axis is reserved for time, and the vertical axis for state, which culminates in a 2D map that is relatively easy to oversee. For a two state model a straightforward way for visualization is by employing a 3D map, however this will be already harder to graphically display and interpret. It is not possible to display more than two states in this way. Possible approaches for displaying systems and control behaviour with multiple states consist of approximation methods, e.g. to display only the most important state, or one or two principal component vectors obtained via principal component analysis, or to conduct a time scale approximation methods that leave only one dynamic state and for the rest auxiliary states. Alternatively, one could leave  the hyper-dimensional state space intact and visualize it by means of projection mapping \cite{Zamora2011}. 

\subsubsection{Refinement of uncertainty model}
As was mentioned above, all uncertainty sources are indirectly modelled by the stochastic noise component. In order to disentangle the roles of the various uncertainty sources, a promising approach would be to extend the model-control framework with a state estimator that is designed for a similar type of noise, such as the Kalman filter. That would however mean that the state vector would be extended with the covariance of the states, which might bring along computational and visualization challenges as mentioned above. Another possible extension of the framework would be to incorporate noise on the running costs that reflects the stochastic nature of energy prices. Mathematically this would be relatively straightforward since it would only require adding a state transition probability in equation (\ref{eq:expectancyL}).

In this paper, the control policy is designed based on the assumption that the crop state can be measured online and without error. Online crop weight measurement is however still not standard practice, even in sophisticated greenhouse systems, since it requires costly weight sensors, or the employment of state of the art computer vision via cameras to estimate weight in a smart way. Promising results have been achieved e.g. via point cloud estimation \cite{Mortensen2018segmentation}, or neural network approach \cite{zhang2020}. In these studies the measurement errors were quite small, resulting in high $R^2$ values (0.8-0.95), however these might still be relevant for control performance. Hence, it would be insightful to investigate the effect of measurement accuracy on control performance.

\subsection{Part II: comparison with deterministic and static control}

Compared to the stochastic dynamic controller, the static controller resulted in lower maximal expected net revenue (-19 \%). This is not surprising, given that the optimal control policy in figure \ref{fig:nominal} strongly depends on time and state. The deterministic controller also resulted in lower maximal expected net revenue (-16 \%). Hence it can be concluded that both time-varying feedback as well as optimizing over uncertainty may have a large effect on control performance in terms of net revenue. 

The static controller also results in less precision at harvest time (state uncertainty increased with 86 \%). This is likely due to the absence of a feedback mechanism that steers the state back towards the optimal trajectory (the one that maximizes value) whenever it deviates from that trajectory. The deterministic controller showed much less state dispersion (state uncertainty increased with 40 \%). From these observations we conclude that time-varying feedback may increase state precision dramatically, and that optimizing over uncertainty may increase state precision considerably. 

Compared to the original controller, the static controller displayed a slightly larger sensitivity towards a change in starting day (varying the starting time from 0 to 10 days caused a variation of 15 \% in expected net revenue, compared to 11 \% for the original controller). % oorzaak: .. 

The deterministic controller displayed a large sensitivity of expected net revenue towards a change in starting day (60 \% compared to 11 \% for the original controller). This loss in robustness can be explained by the very narrow control band (Figure \ref{fig:perf_deterministic} and consequently the narrow shape of the value function. 

Altogether, these results indicate considerable and even dramatic possible improvements when uncertainty is incorporated into a time-varying feedback control policy. The results of this single case study should naturally be interpreted with caution, however they illustrate a considerable potential benefit for stochastic greenhouse climate control.


%-bij deterministic: Nature of uncertainty: sigma is a shortcut. there is noise in input, sensors, energy prices, and weather. Parametric uncertainty in crop and greenhouse/cost model. So further disentanglement would shed light on ways to effectively improve control performance by reducing most contributing sources. This would also entail selection of controllers that can deal with non-stochastic uncertainty. 



\section{Conclusion}

This paper presents an optimal control algorithm for crop production with strict harvest weight requirements when state dynamics are uncertain due to stochastic noise. The case study concerns a 50 day production round of lettuce in a greenhouse where control input consists of daily and nightly temperature set points. The control objective was to maximize the expected net revenue at harvest time.

The regions in state space where input is applied, form convex bands around the optimal state trajectory. These controlled regions have sharply defined borders, within which growth rate an consequently expected net revenues are controlled substantially, and outside which there is little to no control input. The optimal stochastic control policy depends strongly on time and state, showing that state feedback or deterministic open loop control may be be significantly sub-optimal. The control policy pattern can change dramatically as the weather pattern changes. Consequently, the optimal input changes principally within a day depending on time and state, whereas the optimal control policy changes with the weather. An increased prediction uncertainty due to increased state noise was mitigated primarily by less heating investment in the beginning of the production round. The optimal control policy increases indoor temperature to accelerate and decelerate crop growth rate to steer towards a desirable harvest weight. Since it is questionable whether a deceleration towards negative growth will lead to acceptable crop quality, the visualization of a policy like this can serve as starting point for fine tuning the model including input and state constraints by incorporating additional expertise. 

The performance was compared to that of a stochastic static controller, and a deterministic dynamic feedback controller for the case of heat limited weather conditions, and strict requirements on harvest weight precision. Compared to the stochastic dynamic controller, the static controller resulted in lower maximal expected net revenue (-19 \%), less precision at harvest time (state uncertainty increased with 86 \%), and a larger sensitivity towards a change in starting day (varying the starting time from 0 to 10 days caused a variation of 15 \% in expected net revenue, compared to 11\% for the original controller). The deterministic controller also resulted in lower maximal expected net revenue (-16 \%), and less precision at harvest time (state uncertainty increased with 40 \%). The sensitivity of expected net revenue towards a change in starting day increased dramatically (60 \% compared to 11\% for the original controller). 

The results of the deterministic controller provided insights in the trade-off between optimality in case of no noise, versus robustness to noise, whereas the results of the static controller provided insights in importance of dynamic feedback in achieving high precision in harvest weight. The results of this single case study should be interpreted with caution, however they illustrate a considerable potential benefit for stochastic greenhouse climate control.


\newpage


% TO DO

% Grid aanpassen en grid analyse bij M&M zetten. Check performance/convergentie linear grid
% Sensivitity plot (en bespreek in Discussie part II, pas waar nodig abstract en conclusies aan)
% Graadurenmethode vs andere methode (check vooral gelineariseerde Boltzmann vergelijking) 

\bibliography{bibfileStoch} 



\end{document}
