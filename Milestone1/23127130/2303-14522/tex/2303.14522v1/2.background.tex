\section{Background}
\label{sec:background}

\glspl{ea} are optimization algorithms inspired by the biological processes of natural evolution. 
A population of individuals (candidate solutions) evolves over several generations, guided by a fitness function. 
Similar to nature, these individuals are subject to selection, reproduction, and genetic variation.
These algorithms face known issues such as parameter tuning, premature convergence, and lack of diversity. 
Researchers propose novel representations \cite{handbookge,Loureno2018,Megane2022}, selection methods, genetic operators, and parameter selection approaches to address these issues.
% completar referencias

\subsection{Grammar-based Genetic Programming}

\gls{gp} is an \gls{ea} that evolves solutions as programs.
Over the years, researchers have proposed many variants of \gls{gp}, and grammar-based approaches gained more popularity as grammars are helpful to set restrictions to the search space \cite{McKay2010}.

\gls{ge} \cite{handbookge} is the most popular grammar-based \gls{gp} methods.
The individuals' genotype is a string/vector of integers that is translated into a phenotype (an executable function) through a grammar. 
The individuals are subject to selection mechanisms, mutation, and crossover in each generation.
% TODO: talvez mencionar que a mutação e o crossover são das principais causas estudadas para a redundancia e localidade \cite{Byrne2009,hugosson2007}

This approach is relevant but suffers from high redundancy \cite{Thorhauer2016}, and poor locality \cite{Rothlauf2006}, damaging the efficiency of evolution. Redundancy is measured by analyzing the proportion of effective mutations, and locality studies how well genotypic neighbors correspond to phenotypic neighbors. Standard \gls{ge} showed performance similar to random search \cite{Whigham2015}, which motivated researchers to propose different initialization methods \cite{Nicolau2017}, representations \cite{Loureno2018,Megane2022}, genetic operators, but also to investigate grammar design \cite{Nicolau2018}.
% Grammar design can be used to to incorporate expert knowledge \cite{Nicolau2018}. 

% pi ge ?
\gls{pige} \cite{ONeill2004} uses a different representation and mapping mechanism that removes the positional dependency that exists in \gls{ge}. Each codon of the genotype contains two values, \textit{nont} that consists of the non-terminal and \textit{rule} that states the rule index to expand. 
This method improves performance compared with \gls{ge} \cite{Fagan2010}. However, another study found that this method also suffers from poor locality \cite{Medvet2017}.


\gls{sge} \cite{Loureno2016,Loureno2018} proposed a new representation for the genotype and variation operators, which resulted in better performance and fewer issues regarding locality and redundancy \cite{Loureno2017,Medvet2017}. 
The genotype comprises a list of integers (one per grammar non-terminal), with each integer corresponding to the index of a production rule. 
This structure allows mutation to occur inside the same non-terminal and crossover to exchange the list of derivation options. 
Another advantage of this proposal is that only valid solutions are allowed.
\gls{sge} imposes a depth limit on solutions.
Once the limit is surpassed, only non-recursive productions are chosen, forcing individuals to consolidate into a valid genotype.
% CONTINUAR


% ate era interessante passar isto para grammar design só para salientar que modificar a gramatica ajuda a guiar o processo
\gls{psge} \cite{Megane2022} is a recent proposal to \gls{sge} that uses a probabilistic grammar, namely a \gls{pcfg}, to bias the search, and where codons of the genotype are floats. 
Each grammar production rule has a probability of being selected. 
These probabilities change based on the frequency of expansion of that rule on the best individual. 
If the rule is not expanded, the probability decreases. 
This proposal performed better or similarly compared to \gls{sge} and outperformed \gls{ge} in all problems. The evolved grammar also provides information about the features more relevant to the problem \cite{Megane2021}.
Another probabilistic grammar approach is \gls{copsge} \cite{Megane2022gecco}. In this method, each individual has a \gls{pcfg}, which may suffer mutation to the probabilities values. This approach also showed similar or better performance than \gls{sge}.





\subsection{Adaptive mutation rate}
Although most works in the literature use a static parameter for mutation and crossover rates, research shows that dynamic parameters may improve the search and introduce more diversity to the population.
Adaptive mutations have been widely proposed in the literature to tackle some of the issues that \glspl{ea} present. % adaptive operator

Self-adaptive Gaussian mutation has been widely used by \gls{es} \cite{Beyer2004EvolutionS} and adapted into \glspl{ea} \cite{Hinterding}. During the evolutionary process, the mutation rate varies, suffering a Gaussian mutation.
This approach achieves better results than standard mutation and performs similarly to \gls{es}.
Teo \cite{Teo2006} studied a self-adaptive Gaussian mutation operator for the \gls{g3} algorithm, and it outperformed the standard algorithm in two of the four problems tested.

% driven by fitness

Other approaches consider individuals' fitness when adapting the mutation probability. 
Libelli et al. \cite{MarsiliLibelli2000} and Lis \cite{Lis1995} approaches showed better performance than classical \gls{ga}.
% nao sei se deva explicar realmente o que fazem, sao aplicados em GA, e baseado em fitness, é um bocado seca

\gls{apmga} \cite{Stark2012ANS} dynamically adjusts the mutation probability during the evolutionary process based on the variations of the population entropy between the current and previous generations. 
%This approach outperforms the same algorithm's fixed mutation rates. 

% GP ADAPTIVE OPERATORS FITNESS DRIVEN
% NOT STRICTLY MUTATION SO MAYBE NOT CITE THIS.
Salinas et al. \cite{Cruz_Salinas_2017} proposed an \gls{ea} where operators are \gls{gp} trees. 
In each generation, the probability of an operator increases or decreases based on the individual's performance after the operator.


Gomez proposed \gls{haea} \cite{Gmez2004SelfAO} to adapt the operator probabilities during evolution. Each individual encodes its genetic rates. The probabilities by a random value can change according to the fitness of the offspring. This algorithm inspired other proposals that showed that although for some problems there are no significant improvements in performance, the algorithm can obtain similar results without the need to pre-tuning, needing less computational time \cite{Gmez2021,Montero2007,Montero}.


Coelho et al. \cite{Coelho2016} presented a new hybrid self-adaptive algorithm based on \gls{es} guided by neighborhood structures and tested for combinatorial contains mutation probabilities, and the second contains integer values that control the strength of the disturbance. 
The results were similar to the other approaches tested and showed that the adaptive mutation could escape local optima and balance exploration and exploitation.



% GRAMMATICAL EVOLUTION ADAPTIVE MUTATION DRIVEN BY FITNESS

To our knowledge, there is only one adaptive mutation rate parameter proposal in \gls{ge}.
Fagan et al. \cite{Fagan2012} propose \gls{frm}, an adaptive mutation that increases the mutation rate in case a fitness plateau is reached to diversify the population and decreases when a new optimum is found, using increments/decrements of 0.01. The approach found similar results as the fixing mutation rate.
% TODO: escrever, tenho preguiça, vou só organizar




\subsection{Grammar-design}
% grammar design
It is possible to design grammar to produce syntactically constrained solutions or to incorporate domain knowledge by biasing the grammar. The grammar's design can significantly impact the search of \gls{ge} \cite{nicolau2004,dick2022,Hemberg2008PreIP}.

Miguel Nicolau \cite{nicolau2004} proposes a method to reduce the number of non-terminals of the grammar. 
The authors compare standard \gls{ge} with a standard and a reduced grammar and showed an empirical increase in performance.
This work motivated a study with different types of grammars.
This study shows that recursion-balanced grammar could also improve performance \cite{Nicolau2018}. 

A recent work by Dick et al. \cite{dick2022} showed that \gls{ge} is more sensitive to grammar design than \gls{cfggp}.
The results suggest that \gls{cfggp} is more sensitive to parameter tuning than grammar design.

Hemberg et al. \cite{Hemberg2008PreIP} compared \glspl{ge} with a depth-first mapping mechanism that uses three grammars: infix (standard \gls{ge}), prefix and postfix. The results showed that different grammars can improve performance, although the authors report no significant differences.

% GE^2
\gls{ge2} uses two grammars, the universal and the solution grammar. The universal grammar describes the rules to construct the solution grammar. The rules are used to map the individuals and can evolve towards biasing the search space. Results showed that the evolved grammars presented some bias towards some non-terminal symbols.


Manzoni et al. \cite{Manzoni_2020} showed theoretically that different grammars of equal quality impact the performance of (1+1)-\gls{ea}. The structure of the grammar is problem dependent but can favor the search. A mutation operator that modifies the probability of selecting the grammar rules was also proposed.

