\documentclass{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{verbatim}
%\usepackage{gensymb}
\usepackage{graphicx}
\usepackage{pgfplots}
\usepackage{esint}
\usepackage{color}
\usepackage{amsmath}
\usepackage{array}
\usepackage{amsbsy}
\usepackage{mathabx}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage{tikz-dimline}
\usepackage{amscd}
\usepackage[all]{xy}
\usepackage{bbm}
\usepackage{mathrsfs}
\usepackage{tikz-cd}
\usepackage{mathtools}
\usepackage{harpoon}
\usepackage{enumitem}
\usepackage{makeidx}
\usepackage{graphicx}
%\usepackage{natbib}
\usepackage{subfiles}
\usetikzlibrary{matrix,calc,arrows}
%\usepackage[margin=0.65in]{geometry}
\usepgfplotslibrary{fillbetween}

\usepackage[colorlinks=black, bookmarksdepth=2]{hyperref}
\usepackage{amsmath,amssymb,amsthm,amsfonts,amsbsy,latexsym,dsfont,color,graphicx,enumitem, upgreek, xcolor, xfrac}

\theoremstyle{plain}
\newtheorem{solution}{Solution}
\newtheorem*{solution*}{Solution}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\A}{\mathbb{A}}
\renewcommand{\P}{\mathbb{P}}
%\newcommand{\P}{\mathbb{P}}
\newcommand{\lin}{\mathscr{L}}
\newcommand{\ham}{\mathbb{H}}
\newcommand{\Var}{\text{Var}}
\newcommand{\dist}{\text{dist}}
\newcommand{\lcm}{\operatorname{lcm}}
\newcommand{\fix}{\operatorname{Fix}}
\newcommand{\inv}{^{-1}}
\newcommand{\n}{_{n\in\N}}
\newcommand{\dual}{^{\ast}}
\newcommand{\Dom}{\text{Dom}}
\newcommand{\Quad}{\text{Quad}}
\newcommand{\conv}{\text{conv}}
\newcommand{\aut}{\operatorname{Aut}}
\newcommand{\charac}{\operatorname{char}}
\newcommand{\syl}{\operatorname{Syl}}
\newcommand{\eps}{\delta}
\newcommand{\inter}{\operatorname{int}}
\newcommand{\normal}{\operatorname{\lhd}}
\newcommand{\osc}{\mathop{\rm osc}}
\newcommand{\tensor}{\otimes}
\newcommand{\vect}{\mathbf}
\newcommand{\Bin}{\text{Bin}}
\newcommand{\Inv}{\operatorname{Inv}}
\newcommand{\Hom}{\operatorname{Hom}}
\newcommand{\Acal}{\mathcal{A}}
\newcommand{\Bcal}{\mathcal{B}}
\newcommand{\Ccal}{\mathcal{C}}
\newcommand{\Dcal}{\mathcal{D}}
\newcommand{\Ecal}{\mathcal{E}}
\newcommand{\Fcal}{\mathcal{F}}
\newcommand{\Gcal}{\mathcal{G}}
\newcommand{\Hcal}{\mathcal{H}}
\newcommand{\Ical}{\mathcal{I}}
\newcommand{\Jcal}{\mathcal{J}}
\newcommand{\Kcal}{\mathcal{K}}
\newcommand{\Lcal}{\mathcal{L}}
\newcommand{\Mcal}{\mathcal{M}}
\newcommand{\Ncal}{\mathcal{N}}
\newcommand{\Ocal}{\mathcal{O}}
\newcommand{\Pcal}{\mathcal{P}}
\newcommand{\Qcal}{\mathcal{Q}}
\newcommand{\Rcal}{\mathcal{R}}
\newcommand{\Scal}{\mathcal{S}}
\newcommand{\Tcal}{\mathcal{T}}
\newcommand{\Ucal}{\mathcal{U}}
\newcommand{\Vcal}{\mathcal{V}}
\newcommand{\Wcal}{\mathcal{W}}
\newcommand{\Xcal}{\mathcal{X}}
\newcommand{\Ycal}{\mathcal{Y}}
\newcommand{\Zcal}{\mathcal{Z}}
\newcommand{\sech}{\text{sech}}
\newcommand{\bdot}{\boldsymbol{\cdot}}
\newcommand{\der}{\partial}
\newcommand{\del}{\nabla}
\newcommand{\pd}[2]{\dfrac{\strut \der #1}{\strut \der #2}}
\newcommand{\lap}{\mathscr{L}}
\newcommand{\ba}{\begin{align*}}
\newcommand{\ea}{\end{align*}}
\newcommand{\e}{\mathrm{e}}
\newcommand{\irv}{\mathbbm{1}}
\newcommand{\capnab}{\nabla^{\nu}_{a^*}}

\newcommand{\presub}[2]{\prescript{}{#1}{#2}}

\DeclareMathOperator*{\esssup}{ess\,sup}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\numberwithin{definition}{section}
\numberwithin{equation}{section}
%Use to have a definition/thm have an extra number attached to it corresponding to whichever section the statement resides in.

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{amsmath}

\newcommand{\textoperatorname}[1]{%
  \operatorname{\textnormal{#1}}%
}

    \newtheorem{remark}[definition]{Remark}
   \newtheorem{proposition}[definition]{Proposition}
   \newtheorem{observation}[definition]{Observation}
   \newtheorem{corollary}[definition]{Corollary}
   \newtheorem{lemma}[definition]{Lemma}
   \newtheorem{exercise}[definition]{Exercise}
   \newtheorem{claim}[definition]{Claim}
   \newtheorem{conjecture}[definition]{\textcolor{blue}{Conjecture}}
   \newtheorem{theorem}[definition]{Theorem}
   \newenvironment{soln}
        {\begin{proof}[Solution]}
        {\end{proof}}

 \newtheorem{example}[definition]{Example}
 %\numberwithin{example}{section}
 \newtheorem*{example*}{Example}

\title{On Steiner Symmetrizations for First Exit Time Distributions}
\author{Tim Rolling}
%\date{2023}

\begin{document}

\maketitle

\begin{abstract}
    Let $A_t$ be a rotationally symmetric stable process, $0<\alpha\leq 2$, on $\R^d$ and $D\subset \R^d$ be a bounded domain.  
 This paper presents a proof, based on the classical Brascamp-Lieb-Luttinger inequalities for multiple integrals, that  the distribution of the first exit time of $A_t$ from $D$ increases under Steiner symmetrization. Further, it is shown that when a sequence of domains $\{D_m\}$ satisfying the $\varepsilon$-cone condition converges to a domain $D'$ with respect to the Hausdorff metric, the distributions of exit times for Brownian motion from  $D_m$  converge to the distribution of the exit time of Brownian motion from  $D'$. These results are applied distributions of the first exit time from triangles and quadrilaterals in the plane to show that they are maximized by the respective first exit time distributions for the equilateral triangle and square by extending a classical result of P\'olya and Szeg\"o \cite{PolyaSzego}.
\end{abstract}

\section{Introduction and Preliminaries}

Symmetrization techniques have been useful in establishing many isoperimetric inequalities. For example, for $D\subset\R^d$ a bounded domain, let the symmetric decreasing rearrangement $D\dual$ be the ball centered at the origin $0\in\R^d$ with the same $d$-dimensional Lebesgue measure as $D$; then the classical isoperimetric inequality states that $D\dual$ has the minimum surface area of all domains of a fixed volume. We can also obtain generalized isoperimetric inequalities by considering quantities such as Dirichlet eigenvalues and integrals of transition densities. To give some examples related to what follows, let $p_D(t,x,y)$ be the heat kernel of the Dirichlet Laplacian in $D$. Then we have the well-known inequality below for $x\in D$, $t>0$ (see \cite{Luttinger1}, \cite{Luttinger2}, \cite{Luttinger3}):
\begin{equation}\label{integralIneq}
    \int_D p_D(t,x,y)dy\le\int_{D\dual} p_{D\dual}(t,0,y)dy,
\end{equation}
which is equivalent to the probabilistic inequality
\begin{equation}\label{SDR-Prob}
    \P_x(\tau_D>t)\le\P_0(\tau_{D\dual}>t),
\end{equation}
where $\tau_D$ is the first exit time of Brownian motion $B_t$ from $D$ and $\P_x$ is the corresponding probability measure when $B_t$ starts at $x\in D$. Also, in denoting $\lambda_D$ as the first eigenvalue of the Dirichlet Laplacian in $D$, the well-known result
\begin{equation}\label{eigenvalue}
\lambda_D=\lim_{t\rightarrow\infty}\frac{-2}{t}\log(\P_x(\tau_D>t))
\end{equation}
yields the classical Rayleigh-Faber-Krahn inequality
\begin{equation}\label{RFK}
\lambda_{D\dual}\le\lambda_D.
\end{equation}

Another example of an isoperimetric inequality that will be relevant in the sequel is the classical conjecture from P\'olya and Szeg\"o (\cite{PolyaSzego}). Given $n\ge3$, this states that, among all $n$-sided polygons $P_n$ of fixed area $\zeta>0$, the regular $n$-sided polygon $R_n$ of area $\zeta$ minimizes the first Dirichlet eigenvalue; that is:
\begin{equation}\label{PS-Ineq}
\lambda_{P_n}\ge\lambda_{R_n}.
\end{equation} 
While P\'olya proved this conjecture in 1947 for $n=3$ and $n=4$, the problem still remains open for $n\ge5$; however, recent work by Indrei (see \cite{Indrei}) has been done to prove this result for sufficiently large $n\ge5$ on local sets. That is, \cite{Indrei} constructs explicit $(2n-4)$-dimensional polygonal manifolds $\Mcal(n,\zeta)$ and shows that there exists a computable $N\ge5$ such that for every $n\ge N$, the admissible $n$-gons are given via $\Mcal(n,\zeta)$ and there exists an explicit set $\Acal_n(\zeta)\subset\Mcal(n,\zeta)$ such that $R_n$ has the smallest Dirichlet eigenvalue among all $n$-gons in $\Acal_n(\zeta)$. 

Motivated by \eqref{eigenvalue} and \eqref{PS-Ineq}, Ba\~nuelos in \cite{BanuelosTalk} conjectured that 
\begin{equation}\label{polygonDistribution}
    \sup_{x\in P_n}\P_x(\tau_{P_n}>t)\le\P_0(\tau_{R_n}>t).
\end{equation}
In this paper we show that \eqref{polygonDistribution} holds for $n=3, 4$ not only for Brownian motion (case $\alpha =2$) but for  all $0<\alpha\leq 2$. In particular, this also extends the P\'olya and Szeg\"o inequality (case $n=3, 4$) of \eqref{PS-Ineq}  to the fractional Laplacian of order $0<\alpha< 2$.

%Our approach to proving (\ref{PS-Ineq}) in the cases $n=3,4$ will be based off a conjecture given by Ba\~nuelos in \cite{BanuelosTalk}, which states that, in the case of Brownian motion, the regular $n$-gon maximizes the first exit time distribution among all $n$-sided polygons of fixed area. More precisely, for $n=3,4$ and $\alpha>0$, let $P_n$ and $R_n$ be as above. Then for $t>0$:
%\begin{equation}\label{polygonDistribution}
%    \sup_{x\in P_n}\P_x(\tau_{P_n}>t)\le\P_0(\tau_{R_n}>t).
%\end{equation}
%One can then use (\ref{eigenvalue}) to get (\ref{PS-Ineq}).

To prove (\ref{polygonDistribution}), we will use Steiner symmetrization, which is based off of the construction in \cite{Baernstein} as follows: decompose $x\in\R^d$ as $x=(y,z)$ where $y\in\R^k$, $z\in\R^{d-k}$, and $1\le k\le d-1$, then define the slice of $D$ through $z\in\R^{d-k}$ as:
$$D(z)\coloneqq\{y\in\R^k:(y,z)\in D\}.$$
Denoting $\Lcal^k$ as the $k$-dimensional Lebesgue measure, then by Fubini's Theorem, $D(z)$ is $\Lcal^k$-measurable for $\Lcal^{d-k}$-almost every $z\in\R^{d-k}$, and:
$$D=\bigcup_{z\in\R^{d-k}}(D(z)\times\{z\}).$$
From this, let $D\dual(z)$ be the $k$-dimensional ball centered at $0\in\R^k$ with the same $\Lcal^k$-measure as $D(z)$. As per \cite{Baernstein}, let $D\dual(z)=\emptyset$ if $D(z)$ is not $\Lcal^k$-measurable and $D\dual(z)=\{0\}$ when $\Lcal^k(D(z))=0$.

With the notation above, we can define Steiner symmetrization below.
\begin{definition}\label{SSDefn} For $D\subset\R^d$ a bounded domain, the Steiner symmetrization $D^\#$ of $D$ is:
$$D^\#\coloneqq\bigcup_{z\in\R^{d-k}}(D\dual(z)\times\{z\}).$$
\end{definition}

In general, we can take a Steiner symmetrization with respect to any $(d-k)$-dimensional hyperplane $V$. This is done as follows: given the $k$-dimensional slice of $D$ containing $x\in D$ orthogonal to $V$, let the orthogonal projection $x^\#$ be the point in the corresponding slice in $D^\#$ that is also on $V$. Hence every slice of $D$ orthogonal to $V$ has its symmetric decreasing rearrangement centered around $x^\#$.

Examples of inequalities to which Steiner symmetrization can be applied not only include (\ref{RFK}) above with $D\dual$ replaced by $D^\#$, but also others stated in \cite{BetsakosE}. Such examples relevant for our purposes here are the following: let $x,y\in D$, $t>0$, $\Sigma$ be a line orthogonal to $V$ intersecting $D$, and $\Phi:\R\rightarrow\R$ be a non-constant, convex, and increasing function with $\Phi(0)=0$. Then:
\begin{align}
    p_D(t,x,y)&\le p_{D^\#}(t,x^\#,y^\#)\label{SS-density}\\
    \int_\Sigma\Phi(p_D(t,x,y))\Lcal^1(dy)&\le\int_\Sigma\Phi(p_{D^\#}(t,x^\#,y))\Lcal^1(dy).\label{SS-int-density}
\end{align}
Letting $\Phi(x)=x$, we can obtain from (\ref{SS-int-density}) the following variant of (\ref{SDR-Prob}):
\begin{equation}\label{SS-Prob}
    \P_x(\tau_D>t)\le\P_{x^\#}(\tau_{D^\#}>t).
\end{equation}

As another example, in denoting the trace of $D$ as:
$$\text{Tr}(t,D)=\int_Dp_D(t,x,x)dx$$
for $t>0$, \cite{Baernstein} showed that
\begin{equation}\label{traceIneq}
\text{Tr}(t,D)\le\text{Tr}(t,D\dual)
\end{equation}
and
\begin{equation}\label{traceIneq2}
\text{Tr}(t,D)\le\text{Tr}(t,D^\#)
\end{equation}
using a Brascamp-Lieb-Luttinger inequality (see \cite{Luttinger1}) and the following approximation of the heat kernel:
$$p_D^m(t,x,y)=\int_D\cdots\int_D\prod_{j=1}^m p(t_m,x_j,x_{j-1})dx_1\cdots dx_{m-1},$$
where $x_0=x$, $x_m=y$, $t_m=t/m$, and $p(s,x,y)=(2\pi s)^{-d/2}e^{-|x-y|^2/2s}$.

These results are a generalization of the same inequalities when the symmetric decreasing rearrangement is applied; hence the extension to Steiner symmetrization follows from fixing certain variables. Further, since the hyperplanes of symmetrization can vary, we can apply this technique on a sequence of hyperplanes that cause the original domain to converge to a new domain $D'$ with respect to the Hausdorff metric $d_\Hcal$, which is defined below for bounded sets $A,B$:
$$d_\Hcal(A,B)\coloneqq\max\left\{\sup_{a\in A}d(a,B),\sup_{b\in B}d(A,b)\right\}.$$
There are several equivalent definitions of $d_\Hcal$; see Definition 2.3.13 in \cite{Henrot}. For what follows, we use the first of the definitions given there.

The goal of this paper is to apply Steiner symmetrization to probability distributions involving rotationally symmetric $\alpha$-stable process where $0<\alpha\le2$. Recall that the stochastic process $\{A_t\}_{t\ge0}$ is a rotationally symmetric $\alpha$-stable process if it has stationary and independent increments, paths that are a.s. right continuous with left limits, and is stochastically continuous. That is, for $\eta>0$, $x\in\R^d$:
$$\lim_{t\rightarrow s}\P_x(|A_t-A_s|>\eta)=0.$$
Denoting $\E_x$ as the expectation corresponding to the probability measure $\P_x$, we have that $\{A_t\}_{t\ge0}$ also has the following characteristic function for $x\in\R^d$:
$$\E_x[e^{i\xi\cdot(A_t-x)}]=\exp(-t|\xi|^\alpha).$$

Our first result generalizes (\ref{SS-Prob}) by considering the distribution of the first exit time $\tau_D=\inf\{t>0:A_t\notin D\}$ of the process $A_t$ from $D$.

\begin{theorem}\label{MainResult1} Let $D\subset\R^d$ be a bounded domain, $D^\#$ its Steiner symmetrization with respect to a $(d-k)$-dimensional hyperplane $V$, $1\le k\le d-1$, and $x_0^\#$ be the orthogonal projection of $x_0\in D$ on $V$. Then for $t>0$:
\begin{equation}\label{SS-Prob-SSP}
    \P_{x_0}(\tau_D>t)\le\P_{x_0^\#}(\tau_{D^\#}>t).
\end{equation}
\end{theorem}

In \cite{BetsakosE}, Betsakos proved this in the case of Brownian motion by appealing to (\ref{SS-int-density}) when $\Phi(x)=x$. In \cite{BetsakosS}, Betsakos proves (\ref{SS-int-density}) for the case of Steiner symmetrization replaced with the polarization technique. %; however, estimates for other symmetrization techniques can be obtained from this inequality. 
The approach here will make use the Brascamp-Lieb-Luttinger inequality in \cite{Luttinger1} along with Fubini's Theorem by treating $A_t$ as a subordination of Brownian motion $B_t$; that is, $A_t=B_{2\sigma_t}$ for $\sigma_t$ a subordinator (see \cite{SSPs}; also if $\alpha=2$, then $\sigma_t=t$ so that $A_t$ is Brownian motion running at twice the speed). With this reasoning, Theorem \ref{MainResult1} holds for any subordination of Brownian motion. As a result, this proof will be more akin to that of (\ref{traceIneq}) and (\ref{traceIneq2}) in that we will need to deal with finite dimensional distributions as a product of transition densities over multiple integrals. The precise representation of $x^\#$ will be established in the next section on a case-by-case basis, so we will refrain from giving one here.

%Also, by the reasoning in the proof of Theorem \ref{MainResult1}, this result holds for any process $X_t$ that is a subordination of Brownian motion; that is, $X_t=B_{2\sigma_t}$ where $\sigma_t$ is a stable subordinator.
%Maybe save this paragraph/quick remark for the next section?

Our next result concerns extending the inequality in (\ref{SS-Prob-SSP}) to a countable sequence of consecutive Steiner symmetrizations on $D$ and create a new sequence of domains that converge to some domain $D'$ with respect to the Hausdorff metric. Before doing this, we must introduce the following from \cite{HenrotPierre}.

\begin{definition} Let $y,\xi\in\R^d$ with $\xi$ a unit vector and $\varepsilon>0$. Let $C(y,\xi,\varepsilon)$ be the cone of vertex $y$ (without its vertex), of direction $\xi$ and dimension $\varepsilon$, defined by:
$$C(y,\xi,\varepsilon)=\{z\in\R^n,\langle z-y,\xi\rangle\ge\cos(\varepsilon)|z-y|\text{ and }0<|z-y|<\varepsilon\},$$
where $\langle x_1,x_2\rangle$ denotes the dot product of $x_1,x_2\in\R^d$.

An open set $D$ has the $\varepsilon$-cone property if for every $x\in\partial D$, there exists a unit vector $\xi=\xi_x$ such that for every $y\in\overline{D}\cap B(x,\varepsilon)$, $C(y,\xi_x,\varepsilon)\subset D$.
\end{definition}

By Theorem 2.4.7 in \cite{HenrotPierre}, this is equivalent to a bounded domain $D$ being Lipschitz. Recall that a domain $D\subset\R^d$ is a Lipschitz domain if for some constants $L,a,r>0$, then for any $x_0\in\partial D$, there exist an orthogonal coordinate system with origin at $x_0=0$, a cylinder $K=K'\times(-a,a)$ centered at the origin, with $K'$ an open ball in $\R^{d-1}$ of radius $r$, and a function $\varphi:K'\rightarrow(-a,a)$, $L$-Lipschitz continuous with $\varphi(0)=0$, and:
\begin{align*}
    \partial D\cap K&=\{(x',\varphi(x')):x'\in K'\}\\
    D\cap K&=\{(x',x_d):x'\in K',x_d>\varphi(x')\}.
\end{align*}
If $D$ satisfies the $\varepsilon$-cone condition, then $L=\cot\varepsilon$, $a=2\varepsilon$, and $r=\varepsilon$ as per \cite{HenrotPierre}.

%it is bounded and for each $Q\in\partial D$ there are a Lipschitz function $\Gamma_Q:\R^{d-1}\rightarrow\R$, an orthonormal coordinate system $CS_Q$, a number $R_Q>0$ such that if $y=(y^1,\dots,y^d)$ in $CS_Q$ coordinates, then:
%\begin{equation*}%\label{LocalizationCondition}
    %D\cap B(Q,R_Q)=\{y:y^d>\Gamma_Q(y^1,\dots,y^{d-1})\}\cap B(Q,R_Q).
%\end{equation*}

Here we prove a more general result to which we will apply to specific domains in $\R^2$. In what follows, we will consider the class of domains $\Ocal_{\varepsilon,B}$ as given in \cite{HenrotPierre} where:
$$\Ocal_{\varepsilon,B}\coloneqq\{D\subset \R^d: D\subset B\text{ ball}\text{ and }D\text{ satisfies the }\varepsilon\text{-cone condition}\}.$$

\begin{theorem}\label{MainResult2}
    Given $\varepsilon>0$ and a ball $B\subset\R^d$, let $\{D_m\}_{m=0}^\infty$ be a sequence of domains in $\Ocal_{\varepsilon,B}$ that converges to a domain $D'$ with respect to the Hausdorff metric. Further, suppose there exists a sequence $\{x_m\}_{m=0}^\infty$ such that $x_m\in D_m$ for every $m\ge0$ and $x_m\rightarrow x'$ for some $x'\in D'$. If $\tau_{D_m}$ and $\tau_{D'}$ denote the first exit times of Brownian motion from $D_m$ and $D'$, respectively, then for any $t>0$:
    \begin{equation}
        \lim_{m\rightarrow\infty}\P_{x_m}(\tau_{D_m}>t)=\P_{x'}(\tau_{D'}>t).
    \end{equation}
\end{theorem}

It should be noted, by Theorem 2.4.10 in \cite{HenrotPierre}, that $D'$ as in the above result is also in the class $\Ocal_{\varepsilon,B}$ of domains.

The assumption that each of $D_m$ and $D'$ must be in $\Ocal_{\varepsilon,B}$ is due to the fact that Theorem \ref{MainResult2} makes use of Lemma \ref{BMWGeneral}-which requires that the domains be Lipschitz-and being in $\Ocal_{\varepsilon,B}$ allows the constants in Lemma \ref{BMWGeneral} to be bounded above by a constant dependent only on $\varepsilon$ and $B$. In addition, the first exit times above can be extended to a rotationally symmetric $\alpha$-stable symmetric process provided each of $D_m$ and $D'$ are convex or $C^{1,1}$ domains. The reasoning for this will be made clear in Section 3.

The application of Theorems \ref{MainResult1} and \ref{MainResult2} is the following corollary which one can use along with (\ref{eigenvalue}) to prove the P\'olya-Szeg\"o conjecture in the cases $n=3,4$. By the reasoning above, we may extend our interest to first exit times of rotationally symmetric $\alpha$-stable process. Further reasoning on this is given in Section 4.

\begin{corollary}\label{applications} For $n=3,4$, let $P_n$ be an $n$-sided polygon in $\R^2$ of fixed area and $R_n$ be a regular $n$-sided polygon centered at the origin $0\in\R^2$ with the same area as $P_n$. If $\tau_{P_n}$ and $\tau_{R_n}$ are first exit times of a rotationally symmetric $\alpha$-stable symmetric process from their respective domains, then for $t>0$:
\begin{equation}\label{distributionIneq2}
    \sup_{x\in P_n}\P_x(\tau_{P_n}>t)\le\P_0(\tau_{R_n}>t).
\end{equation}
\end{corollary}

While the inequality (\ref{distributionIneq2}) is identical in structure to (\ref{polygonDistribution}), the above reasoning allows us to consider exit times of rotationally symmetric $\alpha$-stable process, not just Brownian motion; further details are provided in Section 4.

The rest of this paper will be organized as follows. In Sections 2 and 3 we prove Theorems \ref{MainResult1} and \ref{MainResult2}, respectively. In Section 4 we prove Corollary \ref{applications} as an application of Theorems \ref{MainResult1} and \ref{MainResult2}.% by proving the cases $n=3$ and $n=4$.

\section{Proof of Theorem \ref{MainResult1}}

First, as mentioned in the previous section, for $0<\alpha\le2$, the rotationally symmetric $\alpha$-stable symmetric process $A_t$ in $\R^d$ has the representation $A_t=B_{2\sigma_t}$ where $\sigma_t$ is a stable subordinator of index $\alpha/2$ independent of the Brownian process. Thus, if we denote $p^\alpha(t,x,y)=p^\alpha(t,x-y)$ and $g_\alpha(t,s)$ as the transition densities for $A_t$ and $\sigma_t$, respectively, then:
\begin{equation}\label{SSPasBM}
    p^\alpha(t,x,y)=\int_0^\infty p(s,x,y)g_{\alpha/2}(t,s)ds,
\end{equation}
where $p(s,x,y)$ is as in Section 1.

In the calculations that follow, we will require an extra approximation by an increasing sequence of open domains $\{D_i\}_{i=1}^\infty$ with $\overline{D_i}\subset D_{i+1}$ and $D_i\nearrow D$ as per \cite{AizenmanSimon}. In the case of Brownian motion, this is always required since $B_t$ is a.s. continuous and hence $\P_x(B_{\tau_D}\in\partial D)=1$ for any $x\in D$; however, for rotationally symmetric $\alpha$-stable process, this is not always required. For example, Bogdan in Lemma 6 of \cite{Bogdan} showed that for any Lipschitz domain $D$:
\begin{equation}\label{LipschitzSSP}
    \P_x(A_{\tau_D}\in\partial D)=0.
\end{equation}
Wu in \cite{Wu} imposed more general conditions on $D$ for which (\ref{LipschitzSSP}) holds, yet even this does not exhaust the list of all possible domains; in fact, Wu shows there are still open sets for which the probability in (\ref{LipschitzSSP}) is positive. Because of this, we will impose the extra approximation of $D$ on rotationally symmetric $\alpha$-stable process.

Thus, using the right continuity of the sample paths along with the Markov Property, we obtain:
\begin{align*}%\label{approximations}
    \P_{x_0}(\tau_D>t)&=\P_{x_0}(A_s\in D,0\le s\le t)\\
    &=\lim_{i\rightarrow\infty}\lim_{m\rightarrow\infty}\P_{x_0}(A_{jt/m}\in D_i, j=1,\dots,m)\\
    &=\lim_{i\rightarrow\infty}\lim_{m\rightarrow\infty}\int_{D_i}\cdots\int_{D_i}\prod_{j=1}^mp^\alpha(t_m,x_j,x_{j-1})dx,
\end{align*}
where $t_m=t/m$ as in Section 1 and $dx=dx_m\cdots dx_1$; similar notation will be used throughout this paper for $dy$, $dz$, etc. One can use this along with (\ref{SSPasBM}) and Fubini's Theorem to get that it suffices to prove Theorem \ref{MainResult1} for the case when $A_t$ is Brownian motion.

Proceeding from this, let $\tau_D$ be the first time Brownian motion exits $D$; then similar reasoning as above yields:
\begin{align}\label{BMapproximation}
    \P_{x_0}(\tau_D>t)&=\lim_{i\rightarrow\infty}\lim_{m\rightarrow\infty}\int_{D_i}\cdots\int_{D_i}\prod_{j=1}^mp(t_m,x_j,x_{j-1})dx
\end{align}

From here, we will use the inequality by Luttinger in \cite{Luttinger1} and Fubini's Theorem to establish (\ref{SS-Prob-SSP}). Since \cite{Luttinger1} involves the notion of the symmetric decreasing rearrangement of a function, we first recall it here.

\begin{definition} Let $f:\R^d\rightarrow\R$ be a measurable and nonnegative function; then the symmetric decreasing rearrangement $f\dual:\R^d\rightarrow\R$ is a function that satisfies:
\begin{align}
    f\dual(x)&=f\dual(y)\text{ if }|x|=|y|,\label{SDRProp1}\\
    f\dual(x)&\le f\dual(y)\text{ if }|x|\ge|y|,\label{SDRProp2}\\
    \lim_{|x|\rightarrow|y|^+}&f\dual(x)=f\dual(y),\label{SDRProp3}\\
    \Lcal^d\{x:f(x)>t\}&=\Lcal^d\{x:f\dual(x)>t\},\text{ }t>0.\label{SDRProp4}
\end{align}
\end{definition}

%This definition will be applied to the function $p(t,x,y)$ above; however, since $p$ is already a nonincreasing radially symmetric function about its maximum, we get that $p$ is its own symmetric decreasing rearrangement up to translation.

Let us now return to proving (\ref{SS-Prob-SSP}). The idea here is to take the iterated integral expression in (\ref{BMapproximation}) and establish the following:
\begin{align}\label{FDDIneq}
\begin{split}
    \int_{D_i}\cdots\int_{D_i}&\prod_{j=1}^m p(t_m,x_j,x_{j-1})dx\\
    &\le\int_{D_i^\#}\cdots\int_{D_i^\#}p(t_m,x_1,x_{0}^\#)\prod_{j=2}^m p(t_m,x_j,x_{j-1})dx,
\end{split}
\end{align}
where the Steiner symmetrization is performed with respect to a $(d-k)$-dimensional hyperplane $V$, $1\le k\le d-1$, $x_0^\#$ is the orthogonal projection of $x_0$ defined in Section 1. From this, one can obtain:
\begin{align*}\label{BMapproximation}
    \P_{x_0}(\tau_D>t)&=\lim_{i\rightarrow\infty}\lim_{m\rightarrow\infty}\int_{D_i}\cdots\int_{D_i}\prod_{j=1}^mp(t_m,x_j,x_{j-1})dx\\
    &\le\lim_{i\rightarrow\infty}\lim_{m\rightarrow\infty}\int_{D_i^\#}\cdots\int_{D_i^\#}p(t_m,x_0^\#,x_{1})\prod_{j=2}^mp(t_m,x_j,x_{j-1})dx\\
    &=\P_{x_0^\#}(\tau_{D^\#}>t)
\end{align*}

Note that the last inequality follows since $D_i\nearrow D$ and $\overline{D_i}\subset D_{i+1}$ implies $D_i^\#\nearrow D^\#$ and $\overline{D_i^\#}\subset D_{i+1}^\#$. To see why, note that since $D_i\nearrow D$, each $k$-dimensional slice of $D$ perpendicular to the hyperplane $V$ (denote by $D_k$) satisfies $(D_k)_i\nearrow D_k$ so that their symmetric decreasing rearrangements also satisfy this property so that $(D_k)_i\dual\nearrow D_k\dual$. Hence by Definition \ref{SSDefn}, $D_i^\#\nearrow D^\#$. Similar reasoning also gives that $\overline{D_i}\subset D_{i+1}$ implies $\overline{D_i^\#}\subset D_{i+1}^\#$.\\

From here, the proof will be broken up into four cases based on the choice of the hyperplane of symmetrization $V$.\\

In the first case, let $V=\{x=(x^1,\dots,x^d)\in\R^d:x^1=\cdots=x^k=0\}$ so that the origin $0\in V$ and the $x^1$-$,\cdots,x^k$-axes are orthogonal to $V$ (without loss of generality, assume the symmetrization is done with respect to the first $k$ coordinates in what follows; otherwise, permute the coordinates so that the symmetrization is with respect to $x^1,\dots,x^k$). Therefore if $x_0=(y_0,z_0)$ with $y_0\in\R^k$, $z_0\in\R^{d-k}$, then $x_0^\#=(0,z_0)$ since the last $d-k$ coordinates are unaffected in the symmetric decreasing rearrangement of each $k$-dimensional slice of $D$ orthogonal to $V$ as constructed above. In what follows, we will use the shorthand notation $D^k=D(z_k)$ and $(D^k)^\#=D^\#(z_k)$ for $1\le k\le d-1$ where $D^\#$ is as in Definition \ref{SSDefn}. We will also use the notation $$p^{(z_1,z_2)}(t,y_1,y_2)\coloneqq p(t,(y_1,z_1),(y_2,z_2))$$ to denote the slice of $p$ in fixing $z_1,z_2\in\R^{d-k}$ and letting $y_1,y_2\in\R^k$ vary.

With the established setup, since $p$ is already a nonincreasing radially symmetric function about its maximum, we obtain the following using \cite{Luttinger1} and Fubini's Theorem:
\begin{align*}
    &\int_{D_i}\cdots\int_{D_i}p\left(t_m,x_1,x_0\right)\prod_{j=2}^m p\left(t_m,x_j,x_{j-1}\right)dx\\
    &=\int_{\R^{m(d-k)}}\left(\int_{D_i^1}\cdots\int_{D_i^m} p^{(z_1,z_0)}\left(t_m,y_1,y_0\right)\prod_{j=2}^mp^{(z_j,z_{j-1})}\left(t_m,y_j,y_{j-1}\right)dy\right)dz\\
    &\le\int_{\R^{m(d-k)}}\left(\int_{(D_i^1)\dual}\cdots\int_{(D_i^m)\dual} p^{(z_1,z_0)}\left(t_m,y_1,0\right)\prod_{j=2}^mp^{(z_j,z_{j-1})}\left(t_m,y_j,y_{j-1}\right)dy\right)dz\\
    &=\int_{D_i^\#}\cdots\int_{D_i^\#}p(t_m,x_1,x_0^\#)\prod_{j=2}^m p(t_m,x_j,x_{j-1})dx,
\end{align*}
establishing (\ref{FDDIneq}) in this case.\\

In the next case, consider a hyperplane of the form $$V=\{(x^1,\dots,x^d)\in\R^d:x^j=\omega^j, j=1,\dots,k\}$$ with at least one $\omega^i\neq0$ so that $V$ is orthogonal to the $x^1$-$,\dots,x^k$-axes, but the origin $0\notin V$. From this, denote \begin{align*}
    \omega&\coloneqq(\omega^1,\dots,\omega^k),\\
    w=y-\omega&=(y^1-\omega^1,\dots,y^k-\omega^k),
\end{align*}
with $w^j=y^j-\omega^j$ for $j\le k$ and, for any measurable set $E\subset\R^k$:
$$E-\omega=\{y-\omega:y\in E\}.$$
Using this definition, we obtain:
$$V-\omega=\{(x^1,\dots,x^d)\in\R^d:x^1=\cdots=x^k=0\}.$$
In addition, if we decompose $D$ into slices, then we can define $D\subset\R^d$ as:
$$D-\omega\coloneqq D-(\omega,0)=\bigcup_{z\in\R^{m}}((D(z)-\omega)\times\{z\}),$$
and:
$$(D-\omega)^\#\coloneqq (D-(\omega,0))^\#=\bigcup_{z\in\R^{m}}((D(z)-\omega)\dual\times\{z\}).$$
The above notation along with Case 1 may now be applied to the iterated integral in (\ref{FDDIneq}) to get:

\begin{align*}
    &\int_{D_i}\cdots\int_{D_i}p\left(t_m,x_1,x_0\right)\prod_{j=2}^mp\left(t_m,x_j,x_{j-1}\right)dx\\
    &=\int_{\R^{m(d-k)}}\left(\int_{D_i^1}\cdots\int_{D_i^m}p^{(z_1,z_0)}\left(t_m,y_1,y_0\right)\prod_{j=2}^mp^{(z_j,z_{j-1})}\left(t_m,y_j,y_{j-1}\right)dy\right)dz\\
    &=\int_{\R^{m(d-k)}}\left(\int_{D_i^1-\omega}\cdots\int_{D_i^m-\omega}p^{(z_1,z_0)}\left(t_m,w_1,y_0-\omega\right)\prod_{j=2}^mp^{(z_j,z_{j-1})}\left(t_m,w_j,w_{j-1}\right)dw\right)dz\\
    &\le\int_{\R^{m(d-k)}}\left(\int_{(D_i^1-\omega)\dual}\cdots\int_{(D_i^m-\omega)\dual}p^{(z_1,z_0)}\left(t_m,w_1,0\right)\prod_{j=2}^mp^{(z_j,z_{j-1})}\left(t_m,w_j,w_{j-1}\right)dw\right)dz\\
    &=\int_{\R^{m(d-k)}}\left(\int_{(D_i^1-\omega)\dual+\omega}\cdots\int_{(D_i^m-\omega)\dual+\omega}p^{(z_1,z_0)}\left(t_m,y_1,\omega\right)\prod_{j=2}^mp^{(z_j,z_{j-1})}\left(t_m,y_j,y_{j-1}\right)dy\right)dz\\
    &=\int_{(D_i^1-\omega)^\#+\omega}\cdots\int_{(D_i^m-\omega)^\#+\omega}p\left(t_m,x_1,(\omega,z_0)\right)\prod_{j=2}^mp\left(t_m,x_j,x_{j-1}\right)dx
\end{align*}
so that $x_0^\#=(\omega,z_0)$ in this case.\\

For the third case, consider the rotation operator $\rho\neq I$ (where $I$ is the identity operator) such that $$\rho V=\{\rho x|x\in V\}=\{(x^1,\dots,x^d)\in\R^d:x^1=\cdots=x^k=0\}$$ and $\rho0=0$ so that $0\in V$, but $V$ is not orthogonal to the $x^1$-axis (such an operator exists by the invertibility of $\rho$). If we denote $\xi_m=\rho x_m$, then the fact that $\rho$ is a linear transformation gives that each $\rho(x_j-x_{j-1})=\xi_j-\xi_{j-1}$ for each $j$. Therefore, if we let $\rho D=\{\rho x|x\in D\}$ and $\rho x_0=(y_0',z_0')$ for $y_0'\in\R^k$, $z_0'\in\R^{d-k}$, we may apply Case 1 with respect to $\rho V$ to get:
\begin{align*}
    &\int_{D_i}\cdots\int_{D_i}p\left(t_m,x_1,x_0\right)\prod_{j=2}^mp\left(t_m,x_j,x_{j-1}\right)dx\\
    &=\int_{\rho D_i}\cdots\int_{\rho D_i}p\left(t_m,\xi_1,(y_0',z_0')\right)\prod_{j=2}^mp\left(t_m,\xi_j,\xi_{j-1}\right)d\xi\\
    &\le\int_{(\rho D_i)^\#}\cdots\int_{(\rho D_i)^\#}p\left(t_m,\xi_1,(0,z_0')\right)\prod_{j=2}^mp\left(t_m,\xi_j,\xi_{j-1}\right)d\xi\\
    &=\int_{\rho\inv((\rho D_i)^\#)}\cdots\int_{\rho\inv((\rho D_i)^\#)}p(t_m,x_1,\rho\inv(0,z_0'))\prod_{j=2}^mp(t_m,x_j,x_{j-1})dx,
\end{align*}
so that $x_0^\#=\rho\inv(0,z_0')$.\\

In this last case, let the hyperplane $V$ be neither orthogonal to the $x^1$-$\dots,x^k$-axes nor does it have the origin. Since there exists $\gamma\in V$ such that $\gamma^j=0$ for $j>k$, if we translate $V$ by $\gamma=(\gamma^1,\dots,\gamma^k)$ units in the first $k$ coordinates, then 
$$0\in V'\coloneqq V-(\gamma^1,\dots,\gamma^k,0,\dots,0)$$ 
so that we may apply the appropriate rotation operator $\rho$ to get that 
$$\rho V'=\{(\eta^1,\dots,\eta^d)\in\R^d:\eta^1=\cdots=\eta^k=0\}.$$ 
On the other hand, since $\rho$ is a linear transformation, we have that 
$$\rho V'=\rho V-(\omega^1,\dots,\omega^k,\omega^{k+1},\dots,\omega^d),$$
where $(\omega^1,\dots,\omega^k,\omega^{k+1},\dots,\omega^d)=\rho(\gamma^1,\dots,\gamma^k,0,\dots,0)$ so that $$\rho V=\{(x^1,\dots,x^d)\in\R^d:x^j=\omega^j, j\le k\}$$ since $\rho V=\rho V'+(\omega^1,\dots,\omega^d)$. Thus, if we let:
\begin{itemize}
    \item $\gamma=(\gamma^1,\dots,\gamma^k)\in\R^k$,
    \item $\xi_j=\rho x_j$ for $j\le k$ as in Case 3, with $\xi=(y,z)$ for $y\in\R^k$, $z\in\R^{d-k}$,
    \item $\rho x_0=(y_0',z_0')$ for $y_0'\in\R^k$, $z_0'\in\R^{d-k}$ as in Case 3,
    \item $w^j=y^j-\gamma^j$ for each $j\le k$,
    \item $\omega=(\omega^1,\dots,\omega^k)$, $w-\omega$, $E-\omega$, $D-\omega$ are as in Case 2 for $E\subset\R^k$, $D\subset\R^d$,
    \item the decomposition of $\rho D$ into slices be given as:
    $$\rho D=\bigcup_{z\in\R^{d-k}}(D_\rho(z)\times\{z\}),$$
    with each slice $D_\rho(z)$ parallel to the $\xi^1$-$,\dots,\xi^k$-axes of the coordinate system rotated by $\rho$,
\end{itemize}
we get by Cases 2 and 3 the following:
\begin{align*}
    &\int_{D_i}\cdots\int_{D_i}p(t_m,x_1,x_0)\prod_{j=2}^mp(t_m,x_j,x_{j-1})dx\\
    &=\int_{\rho D_i}\cdots\int_{\rho D_i}p(t_m,\xi_1,(y_0',z_0'))\prod_{j=2}^mp\left(t_m,\xi_j,\xi_{j-1}\right)d\xi\\
    &\le\int_{(\rho D_i-\omega)^\#+\omega}\cdots\int_{(\rho D_i-\omega)^\#+\omega}p(t_m,\xi_1, (\omega,z_0'))\prod_{j=2}^mp\left(t_m,\xi_j,\xi_{j-1}\right)d\xi\\
    &=\int_{\rho\inv((\rho D_i-\omega)^\#+\omega)}\cdots\int_{\rho\inv((\rho D_i-\omega)^\#+\omega)}p(t_m,x_1,\rho\inv(\omega,z_0'))\prod_{j=2}^mp\left(t_m,x_j,x_{j-1}\right)dx
\end{align*}
so that $x_0^\#=\rho\inv(\omega,z_0')$ in this most general case. This concludes the proof of Theorem \ref{MainResult1}.

\section{Proof of Theorem \ref{MainResult2}}
To establish Theorem \ref{MainResult2}, we will first prove the following lemma which is a generalization of Lemma 5.2 from \cite{BMW}.

\begin{lemma}\label{BMWGeneral} Let $D,G\subset\R^d$ be Lipschitz domains and let $C_{p,D}$ be a constant dependent on $p>0$ and $D$, and define $C_{p,G}$ similarly.
\begin{enumerate}
    \item If $p\ge1$, then:
    $$\sup_{x\in G\cup D}\E_x[|\tau_D-\tau_G|^p]\le\max\left\{C_{p,D}\sup_{x\in D\setminus\overline{G}}(d(x,\partial D))^\beta,C_{p,G}\sup_{x\in G\setminus\overline{D}}(d(x,\partial G))^\beta\right\}.$$
    \item If $p\in(0,1)$, then:
    $$\sup_{x\in G\cup D}\E_x[|\tau_D-\tau_G|^p]\le\max\left\{C_{p,D}\sup_{x\in D\setminus\overline{G}}(d(x,\partial D))^{p\beta},C_{p,G}\sup_{x\in G\setminus\overline{D}}(d(x,\partial G))^{p\beta}\right\}.$$
\end{enumerate}
Here, $\beta>0$ depends on the Lipschitz character of the domain.
\end{lemma}
\begin{proof} We will break this up into cases:\\
First, let $x\notin D\cup G$; then $\tau_D=\tau_G=0$ a.s., and so the inequality is trivial.\\
Next, let $x\in D\setminus\overline{G}$; then $\tau_G=0$ a.s., so by the proof of Lemma 6.4 in \cite{BMW} and the fact that $D\setminus\overline{G}=D\setminus\overline{D\cap G}$, we obtain the following for $p\ge1$:
$$\sup_{x\in D\setminus\overline{G}}\E_x[\tau_D^p]\le C_{p,D}\sup_{x\in D\setminus\overline{G}}\E_x[\tau_D]\le C_{p,D}\sup_{x\in D\setminus\overline{G}}(d(x,\partial D))^\beta.$$
If $p\in(0,1)$, then an application of the proof of Lemma 6.4 from \cite{BMW} along with Jensen's inequality yields:
$$\sup_{x\in D\setminus\overline{G}}\E_x[\tau_D^p]\le\sup_{x\in D\setminus\overline{G}}(\E_x[\tau_D])^p\le C_{D}^p\sup_{x\in D\setminus\overline{G}}(d(x,\partial D))^{p\beta},$$
The case when $x\in G\setminus\overline{D}$ uses the same argument as Case 2 above with $D,G$ interchanged.\\
Lastly, let $x\in\overline{D\cap G}$. First let $\tau_D\ge\tau_G$ a.s.; that is, the Brownian process starting at $x$ first exits $G$. Then $\tau_G=\tau_{D\cap G}$ a.s., and so we may apply the result of Lemma 6.4 in \cite{BMW} to get the following when $p\ge1$:
\begin{align*}
    \sup_{x\in \overline{D\cap G}}\E_x[|\tau_D-\tau_G|^p]=\sup_{x\in \overline{D\cap G}}\E_x[|\tau_D-\tau_{D\cap G}|^p]&\le\sup_{x\in \overline{D}}\E_x[|\tau_D-\tau_{D\cap G}|^p]\\
    &\le C_{p,D}\sup_{x\in \overline{D\setminus (D\cap G)}}(d(x,\partial D))^\beta\\
    &= C_{p,D}\sup_{x\in D\setminus \overline{G}}(d(x,\partial D))^\beta.
\end{align*}
The supremum is taken over $D\setminus \overline{G}$ in place of $\overline{D\setminus G}$ since $d(x,\partial D)=0$ on $x\in\partial D$. For $p\in(0,1)$:
$$\sup_{x\in\overline{D\cap G}}\E_x[|\tau_D-\tau_G|^p]\le\sup_{x\in \overline{D}}\E_x[(\tau_D-\tau_{D\cap G})^p]\le C_D^p\sup_{x\in D\setminus \overline{G}}(d(x,\partial D))^{p\beta}.$$
The case when $\tau_D\le\tau_G$ a.s. is identical to the one above in interchanging $D,G$.
\end{proof}

\begin{remark}\label{generalizationRemark} The above result easily extends to a rotationally symmetric $\alpha$-stable symmetric process $A_t$ when the domains $D,G$ are either a $C^{1,1}$ domain or convex, since \cite{Kulczycki} established intrinsic ultracontractivity for $A_t$ on general Lipschitz domains; this is required in the proof of Lemma 5.2 in \cite{BMW} when $p>1$. (Note that bounded convex domains are Lipschitz; see \cite{DekelLev}.) Further, the inequality below:
\begin{equation}\label{ExitTimeIneq}
    \E_x[\tau_D]\le C d(x,\partial D)^\beta
\end{equation}
for $C,\beta>0$ constants dependent on $D$ holds if $D$ is a $C^{1,1}$ domain or if $D$ is convex (see \cite{Kulczycki2} and \cite{Siudeja}, respectively). In each case, the proper bounds on the Green function of $D$ are used to get (\ref{ExitTimeIneq}). It is yet to be established if the same inequality holds if $D$ is a general Lipschitz domain; however, Lemma \ref{BMWGeneral} generally holds for any pair of Lipschitz domains $D,G$ that satisfies (\ref{ExitTimeIneq}).
\end{remark}

An immediate corollary to Lemma \ref{BMWGeneral} is the following which holds for any sequence of domains $\{D_m\}$ in $\Ocal_{\varepsilon,B}$ converging to some $D'$ with respect to the Hausdorff metric:
\begin{corollary}\label{LpConvergence} Given $\varepsilon>0$, if $\{D_m\}_{m=0}^\infty\subset\Ocal_{\varepsilon,B}$ converges to $D'$ with respect to the Hausdorff metric, then for any $p\in(0,1]$:
$$\sup_{x\in D'}\E_x[|\tau_{D_m}-\tau_{D'}|^p]\rightarrow0.$$
\end{corollary}
\begin{proof}
    Firstly, if $D\in\Ocal_{\varepsilon,B}$, then there exists a constant $C_{\varepsilon,B}$ such that the constant $C_D$ as in (\ref{ExitTimeIneq}) satisfies $C_D\le C_{\varepsilon,B}$; this holds in each of the cases discussed above. When $\tau_D$ is the first exit time of Brownian motion from a Lipschitz domain $D$, the only dependence of $C_D$ on $D$ is on the angle $\theta$ of the uniform cone condition (see \cite{DeBlassie}); since $D\in\Ocal_{\varepsilon,B}$, however, let $\theta=\varepsilon$.

    For the case when $\tau_D$ corresponds to the first exit time of a rotationally symmetric $\alpha$-stable symmetric process from $D$ a $C^{1,1}$ domain or a convex domain, the dependence of $C_D$ on $D$ follows from the radius of the uniform outer ball condition-which can be expressed in terms of $\varepsilon$-and the diameter of $D$ which is bounded above by that of $B$ (again, see \cite{Kulczycki2} and \cite{Siudeja}, respectively). Hence, $C_D$ here can be bounded above by another constant dependent only on $\varepsilon$ and $B$.

    Now, if $p=1$, then since each of $D_m,D'\in\Ocal_{\varepsilon,B}$, the constants $C_{D_m}$ and $C_{D'}$ as in Lemma \ref{BMWGeneral} can be bounded above by a constant $C_{\varepsilon,B}$ as per the above argument. Hence Lemma \ref{BMWGeneral} gives:
    \begin{align*}
        \sup_{x\in D'}\E_x[|\tau_{D_m}-\tau_{D'}|]\le C_{\varepsilon,B}\max\left\{\sup_{x\in D'\setminus\overline{D_m}}(d(x,\partial D'))^\beta,\sup_{x\in D_m\setminus\overline{D'}}(d(x,\partial D_m))^\beta\right\}
    \end{align*}
    Since $d_\Hcal(D_m,D')\rightarrow0$, each expression inside the brackets above goes to 0, yielding the desired result.

    If $p\in(0,1)$, an application of Jensen's inequality yields:
    $$\sup_{x\in D'}\E_x[|\tau_{D_m}-\tau_{D'}|^p]\le\sup_{x\in D'}\left(\E_x[|\tau_{D_m}-\tau_{D'}|]\right)^p.$$
    Since the expression on the right hand side of the inequality converges to 0 as $m\rightarrow\infty$ as per the above argument, the result follows for $p\in(0,1)$.
\end{proof}
It should be noted here that since each of $D_m$, $D'$ satisfy the $\varepsilon$-cone property and are uniformly bounded, the constants $C_{p,D_m}$ and $C_{p,D'}$ depend only on $p,\varepsilon$, and the ball $B$ such that $D_m,D'\subset B$. %In Lemma \ref{BMWGeneral}, since $D$ and $G$ are Lipschitz, they satisfy the desired cone property for some $\varepsilon_D$ and $\varepsilon_G$, respectively; hence they both satisfy the $\varepsilon$-cone property where $\varepsilon=\min(\varepsilon_1,\varepsilon_2)$.

We now turn to the proof of Theorem \ref{MainResult2}.

\begin{proof} To see that
\begin{equation}\label{DistributionConv}
|\P_{x_m}(\tau_{D_m}>t)-\P_{x'}(\tau_{D'}>t)|\rightarrow0
\end{equation}
holds, we will break up the difference above as follows:
\begin{align*}
    &|\P_{x_m}(\tau_{D_m}>t)-\P_{x'}(\tau_{D'}>t)|\\
    &\le|\P_{x_m}(\tau_{D_m}>t)-\P_{x'}(\tau_{D_m}>t)|+|\P_{x'}(\tau_{D_m}>t)-\P_{x'}(\tau_{D'}>t)|.
\end{align*}

The fact that $|\P_{x'}(\tau_{D_m}>t)-\P_{x'}(\tau_{D}>t)|\rightarrow0$ follows immediately from Corollary \ref{LpConvergence}, since $L^p$-convergence for some $p>0$ implies the desired convergence in distribution.
To see that $|\P_{x_m}(\tau_{D_m}>t)-\P_{x'}(\tau_{D_m}>t)|\rightarrow0$ as $m\rightarrow\infty$, consider the following:
\begin{align*}
    |\P_{x_m}(\tau_{D_m}>t)-\P_{x'}(\tau_{D_m}>t)|&=\left|\int_{D_m}p_{D_m}(t,y,x_m)dy-\int_{D_m}p_{D_m}(t,y,x')dy\right|\\
    &\le\int_{D_m}\left|p_{D_m}(t,y,x_m)-p_{D_m}(t,y,x')\right|dy.
\end{align*}
From here, we will use the integral representation of $p_{D_m}$ as in Lemma 4.3 in Section II.4 of \cite{Bass} and the continuity of $p$ as follows; given $\eta>0$, let $M\in\N$ hold so that $|p(t,z,x_m)-p(t,z,x')|<\eta$ for $m\ge M$:
\begin{align*}
    &\left|p_{D_m}(t,y,x_m)-p_{D_m}(t,y,x')\right|\\
    &=\left|\lim_{\gamma\rightarrow0^+}\int_{\R^d}p_{D_m}(t-\gamma,y,z)p(\gamma,z,x_m)dz-\lim_{\gamma\rightarrow0^+}\int_{\R^d}p_{D_m}(t-\gamma,y,z)p(\gamma,z,x_m)dz\right|\\
    &\le\lim_{\gamma\rightarrow0^+}\int_{\R^d}p_{D_m}(\gamma,y,z)\left|p(t-\gamma,z,x_m)-p(t-\gamma,z,x')\right|dz\\
    &<\eta \lim_{\gamma\rightarrow0^+}\int_{\R^d}p_{D_m}(\gamma,y,z)dz\\
    &\le\eta \lim_{\gamma\rightarrow0^+}\int_{\R^d}p(\gamma,y,z)dz\\
    &=\eta.
\end{align*}
Thus:
\begin{align*}
    |\P_{x_m}(\tau_{D_m}>t)-\P_{x}(\tau_{D_m}>t)|&<\eta\cdot\Lcal^d(D_m)\le\eta\Lcal^d(B),
\end{align*}
where $B$ is the bounded ball from the class of domains $\Ocal_{\varepsilon,B}$. With $\eta>0$ arbitrary, this yields that
$$\lim_{m\rightarrow\infty}|\P_{x_m}(\tau_{D_m}>t)-\P_{x'}(\tau_{D_m}>t)|=0,$$
and hence
$$\lim_{m\rightarrow\infty}|\P_{x_m}(\tau_{D_m}>t)-\P_{x'}(\tau_{D'}>t)|=0,$$
as desired.
\end{proof}

Denoting $p_D^\alpha(t,x,y)$ as the transition density of the fractional Laplacian $(-\Delta)^{\alpha/2}$ in $D$, then since $p_D^\alpha(t,x,y)$ shares many properties in common with $p_D(t,x,y)$ (see Theorem 2.1 in \cite{ChenSong}), one can use similar reasoning as Section II.4 of \cite{Bass} to get that the integral representation of $p_{D_m}$ used above-and hence (\ref{DistributionConv})-hold even for rotationally symmetric $\alpha$-stable process provided each of $D_m$ and $D'$ are $C^{1,1}$ or convex.

It should also be noted that Steiner symmetrization does not necessarily preserve the Lipschitz boundary. As a counterexample, let $f(x)$ be defined as follows:
\[   f(x)=\left\{
\begin{array}{ll}
      3-2\sqrt{1-(x-1)^2} & x\in(-2,0) \\
      3 & \text{else} \\
\end{array} 
\right. \]
and consider the open set:
$$D=\{(x,y)\in\R^2:-3<x<3,-f(-x)<y<f(x)\}.$$
Then $D$ satisfies the $\varepsilon$-cone property where $\varepsilon=1/2$; however, in performing a Steiner symmetrization with respect to the $x$-axis, then the resulting region:
$$D^\#=\{(x,y)\in\R^2:-3<x<3,-0.5[f(x)+f(-x)]<y<0.5[f(x)+f(-x)]\}$$
cannot satisfy the $\varepsilon$-cone property for any $\varepsilon>0$ due to the cusps at $(0,3)$ and $(0,-3)$. Because of this, $D^\#$ cannot be a Lipschitz domain.

Hence in applying Theorem \ref{MainResult2} to the case of Steiner symmetrizations, given $D_0=D$ and $x_0=x\in D$, let $D_m$ be the $m$-th consecutive symmetrization of $D$ with respect to the sequence of hyperplanes $\{V_1,\dots,V_m\}$ that converges to $D'$ with respect to the Hausdorff metric; then we must assume that each $D_m$ is in the class of domains $\Ocal_{\varepsilon,B}$ for some $\varepsilon>0$ and some ball $B$. As shown below, the corresponding sequence of orthogonal projections $x_m$ converges to some $x'\in D'$ as shown below.

\begin{lemma} Consider the sequences $\{x_m\}_{m=0}^\infty$, $\{D_m\}_{m=0}^\infty$, and $\{V_m\}_{m=1}^\infty$ described above. If $D_m$ converges to some $D'$ with respect to the Hausdorff metric, then there exists $x'$ such that $x_m\rightarrow x'$.
\end{lemma}

\begin{proof} Suppose by contradiction that $x_m$ does not converge; that is, for every $x'\in\R^d$, there exists $\varepsilon>0$ such that for every $m_0\in\N$, there exists $m\ge m_0$ such that $|x_m-x'|\ge\varepsilon$. Then for every $y\in B_{\varepsilon/2}(x_m)$ and $m\ge m_0$:
$$|x'-y|=|(x'-x_m)-(y-x_m)|\ge\left||x'-x_m|-|y-x_m|\right|>\varepsilon-\varepsilon/2=\varepsilon/2$$
so that the ball $B_{\varepsilon/2}(x_m)$ cannot converge to any ball $B_{\varepsilon/2}(x')$ with respect to the Hausdorff metric. Hence if $D\subseteq B_{\varepsilon/2}(x)$, then since Steiner symmetrization reduces diameter (see Theorem 6.14, \cite{Baernstein}), we have that each $D_m\subseteq B_{\varepsilon/2}(x_m)$ for $m\ge1$; however, the choice of hyperplanes $V_m$ does not permit the sequence of balls $B_{\varepsilon/2}(x_m)$ to converge with respect to the Hausdorff metric, so the sequence of symmetrized domains $D_m$ with $x_m\in D_m$ does not converge with respect to the Hausdorff metric either. Hence we obtain an contradiction in this case. Else, if $D\not\subseteq B_{\varepsilon/2}(x)$, let $t\in(0,1)$ be such that $t(D_m-x_m)+x_m\subset B_{\varepsilon/2}(x_m)$. By the above reasoning, the sequence of domains $t(D_m-x_m)+x_m$ cannot converge with respect to the Hausdorff metric, and so neither can $D_m$ by scaling of the domains, a contradiction.
\end{proof}

An immediate corollary of this is the following.

\begin{corollary}\label{xmInD} If $d_\Hcal(D_{m},D')\rightarrow0$, then there exists $M\in\N$ such that $x_{m}\in D'$ for all $m\ge M$ and hence $x'\in D'$.
\end{corollary}

Hence we can establish the following variant of Theorem \ref{MainResult2} in the context of Steiner symmetrizations.

\begin{corollary} Given $\varepsilon>0$ and $B\subset\R^d$ a ball, let the sequences $\{x_m\}_{m=0}^\infty$, $\{D_m\}_{m=0}^\infty$, and $\{V_m\}_{m=1}^\infty$ be as above with $\{D_m\}_{m=0}^\infty\subset\Ocal_{\varepsilon,B}$ converging to $D'$ in the Hausdorff metric and $x_m$ converging to some $x'$. Then for any $t>0$:
\begin{equation}\label{mainResultCountable}
\lim_{m\rightarrow\infty}\P_{x_m}(\tau_{D_m}>t)=\P_{x'}(\tau_{D'}>t)
\end{equation}
\end{corollary}

%Since Steiner symmetrization is measure-preserving (see \cite{Baernstein}), $\Mcal$ as in the proof of Theorem \ref{MainResult2} is bounded.

\section{Applications}
\subsection{Triangles Converging to an Equilateral Triangle}
This first part of the application section is devoted to proving Corollary \ref{applications} for the case $n=3$; more precisely, let $T\subset\R^2$ be a triangle of fixed area and $T'$ be an equilateral triangle centered at the origin $0\in\R^2$ with the same area as $T$. Then for any $x\in T$, $t>0$:
\begin{equation}\label{triangleIneq}
    \P_x(\tau_T>t)\le\P_0(\tau_{T'}>t),
\end{equation}
where $\tau_T$, $\tau_{T'}$ are first exit times of a rotationally symmetric $\alpha$-stable symmetric process from $T$ and $T'$, respectively. Recall that we may extend the result of Theorem \ref{MainResult2} to first exit times of a rotationally symmetric $\alpha$-stable symmetric process as per Remark \ref{generalizationRemark} since triangles are always convex.

To prove this, we appeal to an algorithm from \cite{PolyaSzego} and \cite{Henrot} that transforms any triangle $T\subset\R^2$ of fixed area to an equilateral triangle $T'$ with the same area using a countable sequence of Steiner symmetrizations. %with respect to the mediator of each side. 
More precisely, a Steiner symmetrization is performed on $T$ with respect to the mediator of one of its sides to obtain $T_1$; another symmetrization would then be done on $T_1$ with respect to the mediator of a different side yielding $T_2$; and another on $T_2$ with respect to the mediator of the last side to get $T_3$. This process would repeat indefinitely to get a sequence of triangles $T_m$ in $\R^2$. It was shown in \cite{Henrot} that the sine of each angle of $T_m$ converges to $\sqrt{3}/2$. This meant that the sequence $T_m$ converges to an equilateral triangle $T'$ of the same area; however, we need convergence of $T_m$ with respect to the Hausdorff metric to apply Theorem \ref{MainResult2}, which \cite{Henrot} does not explicitly prove. Hence we will prove the following below.

\begin{proposition}\label{triangleProp1} Let $T_m,T'$ be as above. Then $d_\Hcal(T_m,T')\rightarrow0$.
\end{proposition}
\begin{proof} Since the sine of each angle of $T_m$ converges to $\sqrt{3}/2$, this yields that each angle of $T_m$ must converge to $\pi/3$, a characteristic unique to equilateral triangles. Further, the mediator of each side of $T'$ intersects the opposing vertex so that the Steiner symmetrization of $T'$ with respect to these mediators is itself. Because of this and the fact that each mediator of $T'$ intersects at the center of $T'$, the distance between the mediators of each side of $T_m$ and the respective opposite vertex converges to 0. %In addition, we have that $d_\Hcal(T_m,T_{n+1})<D_m$ which follows from the fact that each slice of $T_m\cap T_{n+1}$ orthogonal to the mediators has length at most $D_m$. With this above data, we get that $d_\Hcal(T_m,T_{n+1})\rightarrow0$.

Further, because the Steiner symmetrizations act on mediators of $T_m$, given $\eta>0$, there exists $M\in\N$ such that the quantities $\sup_{x\in T_{m_1}}d(x,T_{m_2})$ and $\sup_{x\in T_{m_2}}d(T_{m_1},x)$ are both bounded by $\eta$ for ${m_1},{m_2}\ge M$. Hence, $\{T_m\}$ is a Cauchy sequence with respect to $d_\Hcal$, and so with $d_\Hcal$ complete in a compact metric space (see \cite{Henrikson}), the sequence must converge with respect to $d_\Hcal$. Since the angles of $T_m$ converge to $\pi/3$, $T_m$ must converge to an equilateral triangle $T'$ with respect to $d_\Hcal$.
\end{proof}

With this algorithm, note that the smallest angle $\alpha_m$ of $T_m$ is at most that of $T_{m+1}$; hence with $T_m$ converging to $T'$ in the Hausdorff metric, $\alpha_m$ is a nondecreasing sequence converging to $\pi/3$. Thus each $T_m,T'$ satisfies the $\varepsilon$-cone property where $\varepsilon=\alpha_1/2$, and since Steiner symmetrization decreases the diameter of a domain (see \cite{Baernstein}), they are uniformly bounded by a ball $B$ of radius $2\cdot\text{diam}(T_1)$.

Now, letting $x_0=x$ and $T_0=T$, Theorem \ref{MainResult1} establishes that:
$$\P_{x_0}(\tau_{T_0}>t)\le\P_{x_1}(\tau_{T_1}>t)\le\cdots\le\P_{x_m}(\tau_{T_m}>t),$$
where $x_m\in T_m$ in this case denotes the $m$-th consecutive orthogonal projection of $x_0=x$. Further, we have that:
$$\P_x(\tau_T>t)\le\lim_{m\rightarrow\infty}\P_{x_m}(\tau_{T_m}>t)$$
so since $\P_{x_m}(\tau_{T_m}>t)$ is a nondecreasing bounded sequence, it must converge to a finite probability. From here, to prove (\ref{triangleIneq}), we need to establish the following using Theorem \ref{MainResult2}:
\begin{equation}\label{triangleIneq2}
    \lim_{m\rightarrow\infty}\P_{x_m}(\tau_{T_m}>t)=\P_{0}(\tau_{T'}>t)
\end{equation}
so to do this, we will prove that $x_m\rightarrow0$ below.

\begin{comment}
\begin{lemma}\label{incBoundary} For any $x\in D$:
\begin{equation*}
    d(x,\partial D)\le d(x^\#,\partial D^\#).
\end{equation*}
\end{lemma}
\begin{proof}The symmetric decreasing rearrangement variant of this inequality holds quickly from the fact that:
$$\sup_{x\in D}d(x,\partial D)\le d(0,\partial D\dual).$$
Hence in the case of Steiner symmetrization, if we consider the slice $D_0^\#$ of $D^\#$ perpendicular to the hyperplane of symmetrization $V$ that contains $x^\#$, then the above reasoning gives that $x^\#$ has the maximal distance from any point in $D_0^\#$ to $\partial D_0^\#$; hence $d(x,\partial D)\le d(x^\#,\partial D_0^\#)$. Moreover, since this holds for any slice $D_0^\#$ of $D^\#$, we get that $x^\#$ has the maximal distance from any point in $D_0^\#$ to $\partial D^\#$. Hence $d(x,\partial D)\le d(x^\#,\partial D^\#)$, as desired.
\end{proof}
\end{comment}

\begin{lemma} Let $x_m\in T_m$ be the orthogonal projections described above. Then $x_m\rightarrow0$.    
\end{lemma}

\begin{proof} As in the algorithm in \cite{Henrot}, we will first perform a countable number of consecutive symmetrizations on $T'$ such that each line of symmetrization connects between 0 and a vertex of $T'$. More precisely, let $l_i$ be the line connecting 0 and the vertex $v_i$, $i=1,2,3$; then the first three symmetrizations will be performed with respect to $l_1$, $l_2$, and $l_3$, respectively, and from there, the process repeats indefinitely. We will still have $T'$ after each symmetrization, but denoting the orthogonal projection at the $m$-th step as $x_m'$, we now claim that $x_m'\rightarrow0$.

To see this, first note that the intersection of all three lines $l_1$, $l_2$, $l_3$ is precisely at 0. Hence, if $x'\in T'$ is such that the first symmetrization with respect to $l_1$ causes the orthogonal projection $x'_{1}$ to be 0, then we are done since $0^\#=0$ for symmetrization performed with respect to any $l_i$. Else, if $x_1'\neq0$, then $x'_{1}$ is not orthogonal to the slice of $T'$ that is perpendicular to $l_2$ and has 0, so $x'_{2}\neq0$ either, and by similar iterative reasoning, none of the other $x'_{m}$ points equal 0 either. On the other hand, though, each $x'_{m}$ is also distinct; this can be seen by drawing a right triangle with one vertex at $x'_{m}$, the other at its orthogonal projection $x'_{m+1}$ with respect to the mediator on which the Steiner symmetrization is performed, and the other at 0. From this right triangle, we can see that $|x'_{m+1}|=|x'_{m}|\cos(\pi/6)$ for every $m\in\N$ and hence $x_m'\rightarrow0$.

To see that $x_m\rightarrow0$ from this, since $d_\Hcal(T_m,T')\rightarrow0$, we have that each $x_m$ can be approximated by $x_m'$ above; that is, given $\eta>0$, there exists $M_1\in\N$ such that $x_m\in T_m$ and the respective $x_m'\in T_m'$ satisfy $|x_m-x_m'|<\eta$ for $m\ge M_1$. Also, since $x_m'\rightarrow0$, let $M_2\in\N$ satisfy $|x'_m|<\eta$ for $m\ge M_2$. Hence for $m\ge\max\{M_1,M_2\}$:
\begin{align*}
    \left|x_{m}\right|&\le\left|x_{m}-x_{m}'\right|+\left|x_{m}'\right|<2\eta
\end{align*}
and so $|x_m|<2\eta$. Hence with $\eta>0$ arbitrary, the sequence $x_{m}$ converges to $0\in T'$.
\end{proof}

\subsection{Quadrilaterals Converging to a Square}
We now consider proving Corollary \ref{applications} in the case $n=4$; more precisely, let $Q\subset\R^2$ be a quadrilateral of fixed area and $Q'$ be a square centered at $0\in\R^2$ with the same area as $Q$. Then for $x\in Q, t>0$:
\begin{equation}\label{quadIneq}
\P_x(\tau_Q>t)\le\P_0(\tau_{Q'}>t),
\end{equation}
where $\tau_Q,\tau_{Q'}$ are first exit times of a rotationally symmetric $\alpha$-stable symmetric process from $Q$ and $Q'$, respectively.

For this case, first note that \cite{Henrot} pictorially gives an algorithm used to transform any quadrilateral $Q$ into a rectangle $R$ with the same area via three Steiner symmetrizations; however, to get to the square, we require an algorithm from \cite{PolyaSzego} which transforms a rectangle into a square using a countable number of Steiner symmetrizations. For the convenience of the reader, we will describe the algorithm transforming $Q$ into $R$ from \cite{Henrot} and prove how the algorithm in \cite{PolyaSzego} creates a sequence of quadrilaterals $Q_m$ that converge to the square $Q'$ with respect to the Hausdorff metric provided each line of symmetrization has the origin $0\in\R^2$.
%The algorithm in [PolyaSzego] is on p.159.

\begin{proposition} Given any quadrilateral $Q\subset\R^2$, it takes at most 3 Steiner symmetrizations to transform $Q$ into a rectangle $R$ with the same area.
\end{proposition}
\begin{proof} Let us first consider the case when $Q$ is a parallelogram. Without loss of generality, let $Q$ here be such that a pair of parallel lines are also parallel to the $x$-axis. Here, the line at which the Steiner symmetrization occurs must be perpendicular to the parallel lines chosen; then a symmetrization with respect to the line $l=\{(x,y)\in\R^2:x=0\}$ will transform $Q$ into a rectangle centered at the origin in $\R^2$, as the midpoints of the parallel lines will be on $l$ and the other two lines will also become parallel to each other with the same sides; thus we get a rectangle.

Next, consider the case when $Q$ is a kite (with 2 pairs of adjacent congruent sides). Assume the line segment $l$ whose endpoints are the vertices of the kite where the congruent sides meet is parallel to the $y$-axis; then the line of symmetrization is perpendicular to $l$ and intersects $l$ at its midpoint. The quadrilateral then becomes a parallelogram, at which point we refer to the process above to get that at most 2 Steiner symmetrizations are required if $Q$ is a kite.

Finally, in the most general case, let $m$ denote the maximum of the length of the opposite sides of $Q$. Rotate the line segment $l$ whose endpoints are the opposite vertices of distance $m$ so that it is parallel to the $x$-axis. The line at which the Steiner symmetrization should occur must be parallel to $l$ and intersects this line at its midpoint. The quadrilateral $Q$ then becomes a kite, so referring to the second paragraph above to get that at most 3 Steiner symmetrizations are needed if we want to transform $Q$ into a rectangle of the same area.
\end{proof}

Because of the above proposition, we only need to apply Theorem \ref{MainResult1} at most three times to get that, for any $w\in Q$, $t>0$:
$$\P_w(\tau_Q>t)\le\sup_{z\in R}\P_z(\tau_R>t),$$
where $\tau_R$ is the first exit time from $R$ of a rotationally symmetric $\alpha$-stable symmetric process. Further, let $R$ be centered at the origin in $\R^2$ with two sides parallel to the $x$-axis and the other two parallel to the $y$-axis. Then two Steiner symmetrizations on the $x$- and $y$-axes respectively yield that:
\begin{equation}\label{ReflectionRectangle}
\P_{(x,y)}(\tau_R>t)\le\P_{(0,y)}(\tau_R>t)\le\P_{(0,0)}(\tau_R>t)
\end{equation}
and so for any $w\in Q$, $t>0$:
\begin{equation*}
    \P_w(\tau_Q>t)\le\P_0(\tau_R>t).
\end{equation*}


To prove (\ref{quadIneq}) from here, it suffices to show:
\begin{equation}\label{quadIneq2}
    \P_0(\tau_R>t)\le\P_0(\tau_{Q'}>t)
\end{equation}
To do this, recall from \cite{PolyaSzego} the algorithm that transforms $R$ into $Q'$; first symmetrize $R$ with respect to a line perpendicular to one of its diagonals to obtain a rhombus $Q_1$, then symmetrize $Q_1$ with respect to a line perpendicular to one of its sides to get a rectangle $Q_2$. Repeat these two steps indefinitely to get a sequence of quadrilaterals $Q_m$. Since rectangles and rhombi are convex, we may also generalize Theorem \ref{MainResult2} to the case of first exit times of rotationally symmetric $\alpha$-stable process to prove (\ref{quadIneq2}) and hence (\ref{quadIneq}). To establish convergence with respect to the Hausdorff metric, we prove the following.

\begin{proposition} Let $Q_m$ and $Q'$ be as above. If the rectangle $R$ above is centered at the origin $0\in\R^2$, then $d_\Hcal(Q_m,Q')\rightarrow0$.
\end{proposition}
\begin{proof}
    Without loss of generality, let $R$ have vertices:
    $$P_1=(a,b),\text{ }P_2=(-a,b),\text{ }P_3=(-a,-b),\text{ }P_4=(a,-b),$$
    and consider the line $l_1=\{(x,y)\in\R^2:y=-\frac{a}{b}x\}$ perpendicular to the diagonal through $P_1$ and $P_3$. Performing a symmetrization on $R$ with respect to $l_1$ yields a rhombus $Q_1$ with vertices at:
    \begin{equation}\label{rhombusPts}
    P'_1=P_1,\text{ }P'_2=\left(\frac{-2ab^2}{a^2+b^2},\frac{2a^2b}{a^2+b^2}\right),\text{ }P'_3=P_3,\text{ }P'_4=\left(\frac{2ab^2}{a^2+b^2},\frac{-2a^2b}{a^2+b^2}\right),
    \end{equation}
and each side of $Q_1$ has length:
$$\frac{\sqrt{a^6+7a^4b^2+7a^2b^4+b^6}}{a^2+b^2}.$$
Note that $Q_1$ is still centered at the origin since the diagonals of $Q_1$ intersect there. Also, since $0\in l_1$, we have that $0^\#=0$.

To get to the rectangle $Q_2$ from $Q_1$, the symmetrization will be performed about the line $l_2$ below:
$$l_2=\left\{(x,y)\in\R^2:y=-\frac{a^3+3ab^2}{b^3-a^2b}x\right\}$$
which is perpendicular to the line segments $\overline{Q_1Q_2}$ and $\overline{Q_3Q_4}$. This forms a rectangle $Q_2$ centered at the origin with side lengths:
\begin{equation}\label{newSides}
b'=4ab\sqrt{\frac{a^2+b^2}{a^4+6a^2b^2+b^4}}\hspace{.5cm}\text{and}\hspace{.5cm}a'=\sqrt{\frac{a^4+6a^2b^2+b^4}{a^2+b^2}}.
\end{equation}
To see that the difference between the side lengths has decreased, consider the recursive definitions below based off (\ref{newSides}):
\begin{equation*}%\label{recursiveSides}
b_{m+1}=4a_mb_m\sqrt{\frac{a_m^2+b_m^2}{a_m^4+6a_m^2b_m^2+b_m^4}}\hspace{.5cm}\text{and}\hspace{.5cm}a_{m+1}=\sqrt{\frac{a_m^4+6a_m^2b_m^2+b_m^4}{a_m^2+b_m^2}}.
\end{equation*}
We will next look at the quotient $b_m/a_m$ in the following way:
$$\frac{b_{m+1}}{a_{m+1}}=4a_mb_m\left(\frac{a_m^2+b_m^2}{a_m^4+6a_m^2b_m^2+b_m^4}\right)=\frac{b_m}{a_m}\left(\frac{4a_m^2(a_m^2+b_m^2)}{a_m^4+6a_m^2b_m^2+b_m^4}\right)$$
so that if we let $c_m=b_m/a_m$, then we can rewrite the above recursive relation as:
$$c_{m+1}=\frac{4c_m+4c_m^3}{1+6c_m^2+c_m^4}.$$
From this, consider the function:
$$f(c)=\frac{4c^3+4c}{c^4+6c^2+1}.$$
Using methods from Calculus, one can see that $f(c)$ increases on $(0,1)$ and decreases on $(1,\infty)$. Hence with $f(1)=1$, we have that the sequence $c_m$ satisfies $c_0\in(0,\infty)$ and $c_m<1$ for all $m\ge1$. This yields that $c_m$ is a bounded increasing sequence, so it will converge to a fixed point of $f(c)$; however, the only positive fixed point of $f(c)$ is 1, so it must hold that $b_m/a_m=c_m\rightarrow1$.

Now, with the sides of the rectangles in $Q_m$ converging to the same length, the distance between the line of symmetrization $y=-\frac{a_m}{b_m}x$ and the endpoints of the diagonal formed by $(a_m,-b_m)$ and $(-a_m,b_m)$ converge to 0 as $m\rightarrow\infty$. Further, by considering the points of a rhombus $Q_m$ with vertices of the form described in (\ref{rhombusPts}), the fact that $b_m/a_m\rightarrow1$ yields that the angle at any vertex on the rhombus converges to $\pi/2$; thus  the rhombi in $Q_m$ also converge to a square of the same area. With these in mind, in a similar fashion as in the triangle case, for given $\eta>0$, there exists $M\in\N$ such that the quantities $\sup_{x\in Q_{m_1}}d(x,Q_{m_2})$ and $\sup_{x\in Q_{m_2}}d(Q_{m_1},x)$ are both bounded by $\eta$ for ${m_1},{m_2}\ge M$. Hence, $\{Q_m\}$ is a Cauchy sequence with respect to $d_\Hcal$, and so the sequence must converge with respect to $d_\Hcal$. Since the ratio of the sides of $Q_m$ converge to 1, $Q_m$ must converge to a square $Q'$ with respect to $d_\Hcal$.
\end{proof}

The above proof helps to establish that:
$$\P_0(\tau_R>t)\le\P_0(\tau_{Q_1}>t)\le\P_0(\tau_{Q_2}>t)\le\cdots$$
since the orthogonal projection of the origin in each symmetrization is itself (since the origin is on each line of symmetrization). Hence the sequence $x_m=0$ is constant and so converges to $0\in\R^2$. In addition, each $Q_m$ satisfies the $\varepsilon$-cone property where $\varepsilon$ is half of the smallest angle in $Q_2$. Thus, using Theorem \ref{MainResult2}, we have (\ref{quadIneq2}), and hence (\ref{quadIneq}), as desired.

\section*{Acknowledgements}
The author would like to thank Professor Rodrigo Ba\~nuelos for suggesting the problem as well as his valuable insights and time while preparing this paper. Author was supported in part by NSF Grant \#DMS-1854709 under PI Rodrigo Ba\~nuelos and is part of the author's PhD Thesis.

\begin{comment}
\section{Concluding Remarks}

Some improvements that can be made on the established results include being able to generalize Theorem \ref{MainResult2} to the case of general rotationally symmetric $\alpha$-stable process, $\alpha\in(0,2)$. As was mentioned after Lemma \ref{BMWGeneral}, one of the results we need to establish this is proving $\E_x[\tau_D]\le Cd(x,\partial D)^\beta$ where $C,\beta>0$ depend only on $D$ a Lipschitz domain. This result is already established if Brownian motion is considered (see \cite{DeBlassie}) or if $D$ is a $C^{1,1}$ domain (\cite{Kulczycki2}) or a convex domain (\cite{Siudeja}); however, extending this inequality to rotationally symmetric $\alpha$-stable process on general Lipschitz domains has not yet been established.

Another topic that could be of interest from this is extending the results on general L\'evy processes found in \cite{BanMen} to the case of a sequence of Steiner symmetrizations from the symmetric decreasing rearrangement. Some extensions to the Steiner symmetrization case will follow quickly from applications of the Brascamp-Lieb-Luttinger inequalities in a similar manner as in Lemma \ref{MainResult1}.
\end{comment}

\bibliography{bibtex}{}
\bibliographystyle{plain}

\end{document}
