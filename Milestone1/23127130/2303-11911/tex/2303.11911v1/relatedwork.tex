
\section{Related Work}
% \vspace{-0.2cm}
\label{relatedwork}
\subsection{Contrastive Time Series Representation Learning}
% Contrastive learning aims to learn an encoder that pulls the positive pairs of instances, generated from data augmentations, close in the embedding space and pushes negative pairs of instances apart. 
Contrastive learning has been utilized widely in representation learning with superior performances in various domains~\citep{chen2020simple,xie2019unsupervised,you2020graph}. Recently, some efforts have been devoted to applying contrastive learning to the time series domain~\citep{oord2018representation,franceschi2019unsupervised,fan2020self,eldele2021time,tonekaboni2021unsupervised,yue2021learning}. Time Contrastive Learning trains a feature extractor with a multinomial logistic regression classifier to discriminate all segments in a time series~\citep{hyvarinen2016unsupervised}.  In \citep{franceschi2019unsupervised}, Franceschi et.al. generate positive and negative pairs based on subsequences.  TNC employs a debiased contrastive objective to  ensure that in the representation space, signals in the local neighborhood are distinguishable from non-neighboring signals~\citep{tonekaboni2021unsupervised}. SelfTime adopts multiple hand-crafted augmentations for unsupervised time series contrastive learning by exploring both inter-sample and intra-sample relations~\citep{fan2020self}. TS2Vec learns a representation for each time stamp and conducts contrastive learning in a hierarchical way~\citep{yue2021learning}. However, data augmentations in these methods are either universal or selected by error-and-trail, hindering them away from been widely applied in complex real-life datasets.



\subsection{Time Series Forecasting} Forecasting is a critical task in time series analysis. Deep learning architectures used in the literature include Recurrent Neural Networks (RNNs)~\citep{salinas2020deepar,oreshkin2019n}, Convolutional Neural Networks (CNNs)~\citep{bai2018empirical}, Transformers~\citep{li2019enhancing,zhou2021informer}, and Graph Neural Networks (GNNs)~\citep{cao2021spectral}. N-BEATS deeply stacks fully-connected layers with backward and forward residual links for univariate times series forecasting~\citep{oreshkin2019n}. TCN utilizes a deep CNN architecture with dilated causal convolutions~\citep{bai2018empirical}. Considering both long-term dependencies and short-term trends in multivariate time series, LSTnet combines both CNNs and RNNS in a unified model~\citep{lai2018modeling}. LogTrans brings the Transformer model to time series forecasting with causal convolution in its attention mechanism~\cite{li2019enhancing}. Informer further proposes a sparse self-attention mechanism to reduce the time complexity and memory usage~\citep{zhou2021informer}. StemGNN is a GNN based model that considers the intra-temporal and inter-series correlations simultaneously~\cite{cao2021spectral}. Unlike these works, we aim to learn general representations for time series data that can not only be used for forecasting but also other tasks, such as classification. Besides, the proposed framework is compatible with various architectures as encoders.


\subsection{Adaptive Data Augmentation}
Data augmentation is an important component in contrastive learning. Existing researches reveal that the choices of optimal augmentation are dependent on downstream tasks and datasets~\citep{chen2020simple,fan2020self}. Some researchers have explored adaptive selections of optimal augmentations for contrastive learning in the vision field. 
AutoAugment automatically searches the combination of translation policies via a reinforcement learning method~\citep{cubuk2019autoaugment}. Faster-AA improves the searching pipeline for data augmentation using a differentiable policy network~\citep{hataya2020faster}. DADA further introduces an unbiased gradient estimator for an efficient one-pass optimization strategy~\citep{li2020dada}. Within contrastive learning frameworks, Tian et.al. apply the Information Bottleneck theory that optimal views should share minimal and sufficient information, to guide the selection of good views for contrastive learning in the vision domain~\citep{tian2020makes}.
% It proposes a flow-based generative model to transfer images from natural color spaces into novel color spaces for data augmentation.
Considering the inexplicability of time series data, directly applying the InfoMin framework may keep insufficient information during augmentation. Different from \citep{tian2020makes}, we focus on the time series domain and propose an end-to-end differentiable method to automatically select the optimal augmentations for each dataset.


