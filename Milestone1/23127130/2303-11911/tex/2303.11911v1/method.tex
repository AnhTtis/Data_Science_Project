\section{Methodology}
\label{sec:method}
\subsection{Notations and Problem Definition}
A time series instance $x$ has dimension $T \times F$, where $T$ is the length of sequence and $F$ is the dimension of features.  Given a set of time series instances $\sX$, we aim to learn an encoder $f_{\vtheta}(x)$ that maps each instance $x$ to a fixed-length vector $\b{z}\in\mathbb{R}^D$, where $\vtheta$ is the learnable parameters of the encoder network and  $D$ is the dimension of representation vectors. In semi-supervised settings, each instance $x$ in the labelled set $\sX_{L} \subseteq  \sX$ is associated with a label $y$ for the downstream task. Specially, $\sX_{L} = \sX$ holds in the fully supervised setting. In the work, we use the Sans-serif style lowercase letters, such as $\rx$, to denote random time series variables and italic lowercase letters, such as $x$, for sampled instances.

 
\subsection{Information-Aware Criteria for Good Augmentations}
\label{sec:criteria}
The goal of data augmentation for contrastive learning is to create realistically rational instances that maintain semantics through different transformation approaches. Unlike instances in vision and language domains, the underlying semantics of time series data is not recognizable to human, making it hard, if not impossible, to include human knowledge to data augmentation for time series data.  For example, rotating an image will not change its content or the label. While permuting a time series instance may ruin its signal patterns and generates a meaningless time series instance. In addition, the tremendous heterogeneity of real-life time series datasets further makes selections based on trial-and-errors impractical.  Although multiple data augmentation methods have been proposed for time series data, there is less discussion on what is a good augmentation that
is meaningful for a given learning task and dataset without prefabricated human priors. From our perspective, ideal data augmentations for contrastive representation should keep high fidelity, high variety, and adaptive to different datasets.  The illustration and examples are shown in Figure~\ref{fig:criteria}.


\stitle{High Fidelity.} Augmentations with high fidelity maintain the semantic identity that is invariant to transformations. Considering the inexplicability in practical time series data, it is challenging to visually check the fidelity of augmentations. Thus, we assume that the semantic identity of a time series instance is presented by its label in the downstream task, which might be either available or unavailable during the training period. Here, we start our analysis from the supervised case and will extend it to the unsupervised case later. Inspired by on the information bottleneck~\citep{tishby2000information}, we define the objective that keeps high fidelity as the large mutual information (MI) between augmentation $\rv$ and the label $\ry$, i.e., $\text{MI}(\rv;\ry)$.

We consider augmentation $\rv$ as a \textit{probabilistic} function of $\rx$ and a random variable $\b{\epsilon}$, that $\rv=g(\rx;\epsilon)$. From the definition of mutual information, we have $\text{MI}(\rv;\ry)=H(\ry)-H(\ry|\rv)$, where $H(\ry)$ is the (Shannon) entropy of $\ry$ and $H(\ry|\rv)$ is the entropy of $\ry$ conditioned on augmentation $\rv$. Since $H(\ry)$ is irrelevant to data augmentations, the objective is equivalent to minimizing the conditional entropy $H(\ry|\rv)$.
% With $\rv=g(\rx;\epsilon)$, we have $H(\ry|\rv)=\mathbb{E}_\epsilon [H(y|g(x;\epsilon)]$.
Considering the efficient optimization, we follow~\citep{ying2019gnnexplainer} and ~\citep{luo2020parameterized} to approximate it with  cross-entropy  between $\ry$ and $\hat{\ry}$, where $\hat{\ry}$ is the prediction with augmentation $\rv$ as the input and calculated via
\begin{equation}
       \rv = g(\rx;\epsilon) \quad \quad  \rvz = f_{\vtheta}(\rv) \quad \quad \hat{\ry}=h_{\vw}(\rvz),
\end{equation}
 where $\mathbf{z}$ is the representation and $h_{\vw}(\cdot)$ is a prediction projector parameterized by $\vw$. The prediction projector is optimized by the classification objective. Then, the objective of high fidelity for supervised or semi-supervised cases is to minimize 
 \begin{equation}
 \vspace{-0.1cm}
 \label{eq:supervisedfidelity}
      \text{CE} (\ry;\hat{\ry}) =  -\sum_{c=1}^C P(\ry=c)\log P(\hat{\ry}=c),
    % \text{CE} (\ry;\hat{\ry}) =  -\mathbb{E}_y [\log p(\hat{\ry})],
 \end{equation}
 \vspace{-0.1cm}
where $C$ is the number of labels.

In the \textit{unsupervised} settings where $\ry$ is unavailable, \textit{one-hot} encoding $\ry_s \in \mathbb{R}^{|\mathbb{X}|} $ is utilized as the pseudo label to replace $\ry$ in Eq.~(\ref{eq:supervisedfidelity}).
The motivation is that augmented instances are still distinguishable from other instances with the classifier. We theoretically show that augmentations that preserving pseudo labels have the following properties.

\noindent{\textbf{Property 1}\emph { (Preserving Fidelity).}} \emph{If  augmentation $\rv$ preserves the one-hot encoding pseudo label, the mutual information between $\rv$ and the downstream task label $\ry$ (although not visible to training) is equivalent to that between raw input $\rx$ and $\ry$, i.e., $\text{MI}(\rv;\ry) = \text{MI} (\rx;\ry)$.}

\noindent{\textbf{Property 2}\emph { (Adding New Information).}} \emph{By preserving the one-hot encoding pseudo label, augmentation $\rv$ contains new information comparing to the raw input $\rx$, i.e., $H(\rv)\geq H(\rx)$.}

Detailed proofs are shown in the Appendix~\ref{sec:app:proof}. These properties show that in the unsupervised setting, preserving the one-hot encoding pseudo label guarantees that the generated augmentations will not decrease the fidelity, regardless of the downstream tasks and variances inherent in the augmentations. Concurrently, it may introduce new information for contrastive learning.

Since the number of labels is equal to the number of instances in dataset $\mathbb{X}$ in an unsupervised case, direct optimization of Eq.~(\ref{eq:supervisedfidelity}) is inefficient and unscalable. Thus, we further relax it by approximating $\ry$ with the batch-wise one-hot encoding $\ry_B$, which decreases the number of labels $C$ from the dataset size to the batch size.

\begin{figure}[!t]
% \vspace{-0.65cm}
    \centering
    \subfigure[Information-aware criteria]{\includegraphics[width=1.5in]{figures/xyv.pdf}\label{fig:indc:xyv}} \hspace{1.5cm}
    \subfigure[Examples]{\includegraphics[width=2.2in]{figures/augmentation.pdf}\label{fig:indc:augmentation}}
        \vspace{-0.32cm}
    \caption{Illustration of the criteria. (a) The proposed criteria have two components: high fidelity, and variety. Fidelity is represented by the area of A+B, the mutual information between augmented data $\rv$ and label $\ry$. Variety is denoted by A+D, the entropy of $\rv$ conditioned on the raw input $\rx$. (b) In the supervised setting, good data augmentations generate instances in the area constrained by the label to enlarge the input training space. In the unsupervised setting, with one-hot-based pseudo labels, the generated instances are constrained to the region around the raw input. Such that they are still distinguishable from other instances. }
    \label{fig:criteria}
        \vspace{-0.32cm}
\end{figure}
\stitle{High Variety.} Sufficient variances in augmentations improve the generalization capacity of contrastive learning models.  In the information theory, the uncertainty inherent in the random variable's possible outcomes is described by its entropy. Considering that augmented instances are generated based on the raw input $\rx$, we maximize the entropy of $\rv$ conditioned on $\rx$, $H(\rv|\rx)$, to maintain a high variety of augmentations. From the definition of conditional entropy, we have
\begin{equation}
    H(\rv|\rx) = H(\rv)-\text{MI}(\rv;\rx).
\end{equation}
We dismiss the first part since the unconstrained entropy of $\rv$ can be dominated by meaningless noise.  Considering the continuity of both $\rv$ and $\rx$, we minimize the mutual information between $\rv$ and $\rx$ by minimize the leave-one-out upper (L1Out) bound~\citep{poole2019variational}. 
Other MI upper bounds, such as contrastive log-ratio upper bound of mutual information~\citep{cheng2020club}, can also conveniently be the plug-and-play component in our framework. Then, the objective to encourage high variety is to minimize the L1Out between $\rv$ and $\rx$:
\begin{equation}
\label{eq:variety}
\text{I}_\text{L1Out}(\rv;\rx) = \mathbb{E}_x \left[ \log \frac{\exp(\text{sim}(\mathbf{z}_{x},\mathbf{z}_v))}{\sum_{x'\in \mathbb{X},x'\neq x} \exp(\text{sim}(\mathbf{z}_x,\mathbf{z}_{v'}))} \right],
\end{equation}
where $v'$ is an augmented instance of input instance $x'$.  $\b{z}_x$, $\b{z}_v$, and $\b{z}_{v'}$ are representations of instance $x$, $v$, and $v'$ respectively. $\text{sim}(\b{z}_1,\b{z}_2) = \b{z}_1^T\b{z}_2$ is the inner product of vectors $\b{z}_1$ and $\b{z}_2$.



\stitle{Criteria.} Combining the information-aware definition of both high fidelity and variety, we propose the criteria for selecting good augmentations without prior knowledge,
\begin{equation}
\label{eq:criteria}
    \min_{\rv} \text{I}_\text{L1Out}(\rv;\rx)+\beta \text{CE}(\ry;h_\vw(f_\vtheta(\rv))),
\end{equation}
where $\beta$ is a hyper-parameter to achieve the trade-off between fidelity and variety. Note that in the \textit{unsupervised} settings, $\ry$ is replaced by \textit{one-hot} encoding pseudo label.

\stitle{Relation to Information Bottleneck.}
Although the formation is similar to information bottleneck in data compression, $ \min _{p(\re|\rx)} \text{MI}(\rx;\re)-\beta \text{MI}(\re;\ry)$, our criteria are different in the following aspects. 
First, $\re$ in the information bottleneck is a representation of input $\rx$, while $\rv$ in Eq.(\ref{eq:criteria}) represents the augmented instances. Second, the information bottleneck aims to keep minimal and sufficient information for data compression, while our criteria are designed for data augmentations in contrastive learning.  Third, in the information bottleneck, the compressed representation $\re$ is a deterministic function of input $\rx$ with no variances. $\text{MI}(\re;\ry)$ and $\text{MI}(\re;\rx)$ are constraint by $\text{MI}(\rx;\ry)$ and $H(\rx)$ that $\text{MI}(\re;\ry) \leq \text{MI}(\rx;\ry)$ and  $\text{MI}(\re;\rx) = H(\re)$, where $H(\re)$ is the entropy of $\re$. In our criteria, 
$\rv$ is a probabilistic function of input $\rx$. As a result, the variances of $\rv$ make the augmentation space much larger than the compression representation space in the information bottleneck.


\stitle{Relation to InfoMin.}
InfoMin is designed based on the information bottleneck that good views should keep minimal and sufficient information from the original input~\citep{tian2020makes}. Similar to the information bottleneck, InfoMin assumes that augmented views are functions of the input, which heavily constrains the variance of data augmentations. Besides, high fidelity property is dismissed in the unsupervised setting. It works for image datasets due to the availability of human knowledge. However, it may fail to generate reasonable augmentations for time series data. In addition, they adopt adversarial learning, which minimizes a lower bound of MI, to increase the variety of augmentations. While to minimize statistical dependency, we prefer an upper bound, such as L1Out, instead of lower bounds.

\subsection{Time Series Meta-Contrastive Learning}
We aim to design a learnable augmentation selector that learns to select feasible augmentations in a data-driven manner. With such adaptive data augmentations, the contrastive loss is then used to train the encoder that learns representations from raw time series. % Figure 1 illustrates the architecture of our proposed method, InfoTS. 


\subsubsection{Architecture}
\label{sec:method:arch}
The adopted encoder $f_\vtheta(x): \mathbb{R}^{T\times F}\rightarrow \mathbb{R}^{D}$ consists of two components, a fully connected layer, and a 10-layer dilated CNN module~\citep{franceschi2019unsupervised,yue2021learning}.  To explore the inherent structure of time series, we include both global-wise (instance-level) and local-wise (subsequence-level) losses in the contrastive learning framework to train the encoder.

\stitle{Global-wise contrastive loss} is designed to capture the instance level relations in a time series dataset. Formally, given a batch of time series instances $\mathbb{X}_B \subseteq \mathbb{X}$, for each instance $x \in \mathbb{X}_B$, we generate an augmented instance $v$ with an adaptively selected transformation, which will be introduced later. $(x,v)$ is regarded as a positive pair and other $(B-1)$ combinations $\{(x,v')\}$, where $v'$ is an augmented instance of $x'$ and $x'\neq x$, are considered as negative pairs. 
Following~\citep{chen2020simple,you2020graph}, we design the global-wise contrastive loss based on InfoNCE~\citep{hjelm2018learning}. The batch-wise instance-level contrastive loss is
% \vspace{-0.4cm}
\begin{equation}
\label{eq:global}
    \mathcal{L}_g = -\frac{1}{|\sX_B|}\sum_{x\in \mathbb{X}_B} \log \frac{\exp(\text{sim}(\mathbf{z}_x,\mathbf{z}_v))}{\sum_{x'\in \mathbb{X}_B} \exp(\text{sim}(\mathbf{z}_x,\mathbf{z}_{v'}))}.
    % \mathcal{L}_g = -\sum_{x\in \mathbb{X}_B} \log \frac{\exp(sim(z_{v},z_x))}{\sum_{x'\in \mathbb{X}_B} \exp(sim(z_v,z_{x'}))} +\log \frac{\exp(sim(z_{v},z_x))}{\sum_{x'\in \mathbb{X}_B} \exp(sim(z_{v'},z_{x}))},
\end{equation}

\stitle{Local-wise contrastive loss } is proposed to explore the intra-temporal relations in time series. For an augmented instance $v$ of a time series instance $x$, we first split it into a set of subsequences $\sS$, each with length $L$.  For each subsequence $s\in \sS$, we follow \citep{tonekaboni2021unsupervised} to generate a positive pair $(s,p)$ by selecting another subsequence close to it. Non-neighboring samples, $\bar{\mathcal{N}}_s$, are adopted to generate negative pairs. Detailed descriptions can be found in Appendix~\ref{sec:app:algorithm}.
Then, the local-wise contrastive loss for an instance $x$ is:

\begin{small}
\begin{equation}
\label{eq:local}
    \mathcal{L}c_x = -\frac{1}{|\sS|}\sum_{s \in \sS} \log \frac{\exp(\text{sim}(\mathbf{z}_s,\mathbf{z}_p))}{\exp(\text{sim}(\mathbf{z}_s,\mathbf{z}_p))+\sum_{j\in \bar{\mathcal{N}}_s} \exp(\text{sim}(\mathbf{z}_s,\mathbf{z}_j))}.
\end{equation}
\end{small}
\normalfont
Across all instances in a batch, we have $\mathcal{L}_c = \frac{1}{|\sX_B|}\sum_{x\in \mathbb{X}_B} \mathcal{L}c_x$. The final contrastive objective is:
\begin{equation}
\label{eq:contrastive}
    \min_\vtheta \mathcal{L}_g +\alpha \mathcal{L}_c,
\end{equation}
where $\alpha$ is a hyper-parameter to achieve the trade-off between global and local contrastive losses.


\subsubsection{Meta-learner Network}
Previous time series contrastive learning methods~\citep{franceschi2019unsupervised,fan2020self,eldele2021time,tonekaboni2021unsupervised} generate augmentations with either rule of thumb guided by prefabricated human priors or tedious trial-and-errors, which are designed for specific datasets and learning tasks.
In this part, we discuss how to adaptively select the optimal augmentations with a meta-learner network based on the proposed information-aware criteria. We can regard its choice of optimal augmentation as a kind of prior selection. 
We first choose a set of candidate transformations $\sT$, such as jittering and time warping. Each candidate transformation $t_i\in \sT$ is associated with a weight $p_i \in (0,1)$, inferring the probability of selecting transformation $t_i$. For an instance $x$, the augmented instance $v_i$ through transformation $t_i$ can be computed by:
\begin{equation}
\label{eq:bernoulli}
    a_i \sim \text{Bernoulli}(p_i) \quad \quad v_i = (1-a_i)x+a_it_i(x).
\end{equation}
Considering multiple transformations, we pad all $v_i$ to be with the same length. Then, the adaptive augmented instance can be achieved by combining candidate ones, $v=\frac{1}{|\sT|}\sum_i v_i$.

To enable the efficient optimization with gradient-based methods, we approximate discrete Bernoulli processes with binary concrete distributions~\citep{maddison2016concrete}.  Specifically, we approximate $a_i$ in Eq.~(\ref{eq:bernoulli}) with 
\begin{equation}
\centering
\begin{aligned}
\label{eq:concrete}
    &\epsilon \sim \text{Uniform}(0,1) \\
    & a_i=\sigma((\log \epsilon - \log (1-\epsilon) + \log\frac{p_i}{1-p_i})/\tau),
\end{aligned}
\end{equation}
where $\sigma(\cdot)$ is the sigmoid function and $\tau$ is the temperature  controlling the approximation.  The rationality of such approximation is given in Appendix~\ref{sec:app:proof}. Moreover, with temperature $\tau >0 $, the gradient $\frac{\partial v }{\partial p_i}$ is well-defined. Therefore, our meta-network is end-to-end differentiable. Detailed algorithm is shown in Appendix~\ref{sec:app:algorithm}.

