

\section{Experiments}
We evaluated the effectiveness of GeoSpark by integrating it with three backbones: PointNet++ \cite{Qi2017PointNet++:Space}, KPConv \cite{Thomas2019KPConv:Clouds}, and PointTransformer \cite{Zhao_2021}. We selected two competitive indoor datasets for testing, including the Stanford 3D Indoor dataset (S3DIS) \cite{Armeni_2016} and ScanNetV2 \cite{Dai_2017}. We compared the results of GeoSpark with the corresponding baselines and other state-of-the-art methods, as shown in Table \ref{s3dis_pre_class} and Table \ref{scanv2}.

We also conducted comprehensive ablation studies to evaluate various design decisions, which involved analyzing individual modules (refer to Table \ref{MODULE}), local-global balance for GIA (refer to Table \ref{balance}), sampling strategies (refer to Table \ref{ab_samp}), and the geometric partition size (refer to Table \ref{partition_cap}).

\subsection{Experiments Setting}
\paragraph{Network architecture.} 

\input{section/table/s3dis}


The network architecture using PointTransformer as the backbone is presented below. For further information on the settings used for other backbones, please refer to the Supplementary Materials. The regularization strength \(\lambda\), was set to 3 for S3DIS and 2 for ScanNetV2 to obtain expressive partitions. Within the global branch, the Superpoints were down-sampled by a ratio of 1/2 after each stage. While the feature dimensions were chosen as [32, 64, 128, 256, 512] for stages 1-5.
Regarding Geometric Downsampling, a size cap of [0.10, 0.20, 0.40, 0.80] m was set for S3DIS, and [0.25, 0.50, 0.75, 1.00] m for ScanNetV2, during stages 1-5.
In the global branch, aggregation was only performed once at each stage. Meanwhile, in the local branch, the depths were set to [1, 2, 2, 6, 2] for stages 1-5, following the approach in \cite{Zhao_2021}. The depth settings were the same for both S3DIS and ScanNetV2 datasets.

\input{section/table/scannetv2}

\paragraph{Implementation details.}
All experiments were conducted using two A100 GPUs. The following presents details of model using Point Transformer as THE backbone. For S3DIS, the model was trained for 30,000 iterations with a batch size of 16. Following previous works \cite{Zhao_2021, Lai_2022}, the input sets were subsampled with a 4mm grid. Area 5 was used for testing while other areas were used for training. The loss weight \(\beta\) was set to 0.1, and the training was carried out using the \textit{AdamW}, optimizer, with a learning rate of 0.004 and a weight decay of 0.02.
As for ScanNetV2, the model was trained for 600 epochs with a batch size of 12. The input sets were subsampled with a 2mm grid, and the \textit{AdamW} optimizer was also used with a learning rate of 0.005 and a weight decay of 0.05. Further implementation details can be found in the Supplementary Materials.

\subsection{Comparisons against State-of-the-arts}

\input{section/table/ablation_table_group}

\paragraph{Quantitative comparisons.} 
We noticed a consistent enhancement in performance across three backbone structures by integrating the GeoSpark plug-in. For the S3DIS dataset, the PointNet backbone exhibited a notable 5.3\% improvement in mIoU matrix, while the KPconv backbone (Rigid Version) showed an increase of 0.4\% in mIoU and 1.3 \% in mACC performance as well. In addition, by adding GeoSpark to the Point Transformer, we achieved an mIoU of 71.5\%, which surpassed the baseline model by 1.1\% and ranked highly on the benchmarks.

On the ScanNetV2 validation set, integrating GeoSpark to PointNet++ backbone saw a remarkable improvement of 10.0\%, outperforming many other complex designs. This result further demonstrates that modeling long-range features are crucial for accurate large-scale scene understanding. The KPConv backbone demonstrated an increase of 2.5\% in mIoU performance as well. By incorporating Geospark into the Point Transformer, we achieved an mIoU score of 74.7\%, which was a 4.1\% improvement over the baseline model. This approach also surpassed other transformer-based networks, like Fast Point Transformer and Stratified Transformer, indicating the usefulness of geometry guidance in aggregation and sampling modules. 
Our method performed exceptionally well for smaller classes such as chairs, sofas, and boards, as shown in Table \ref{s3dis_pre_class}, highlighting the significance of geometry features in small class segmentation, as shown in Table Further information regarding training time and the number of parameters can be found in the supplementary materials.
\vspace{-3mm}
\paragraph{Visual results}
Figure \ref{fig:visual} presents the visual prediction outcomes of Point Transformer both with and without GeoSpark. Furthermore, Figure \ref{fig:visual_downsamppling} compared our GD approach to other sampling techniques, including FPS and voxel-based sampling.
\begin{figure*}[t!]
 \centering
 \includegraphics[width=1\textwidth]{section/images/Vis.JPG}
 
 \caption{\textbf{Visual comparison of the Point Transformer with and without GeoSpark.} GeoSpark captures finer details and produces better predictions for certain objects such as chairs, tables, sofas, and cabinets. The main difference between the prediction results of the Point Transformer and the Point Transformer with GeoSpark was highlighted in a red block}
 \label{fig:visual}
 \centering
 \vspace{0mm}
 \includegraphics[width=1\textwidth]{section/images/GD_vis.JPG}
 \vspace{-6mm}
 \caption{\textbf{Visualization of various sampling methods on the S3DIS dataset}. In comparison to FPS and Voxel-based sampling, Geometric Downsampling preserves key points better, particularly in geometry complex areas. This provides significant benefits, especially for small objects.The red block highlights the preservation of details for small objects.}
 \label{fig:visual_downsamppling}
 \vspace{-5mm}
\end{figure*}

\subsection{Ablation Study}
A number of controlled experiments were carried out to evaluate the decisions made during the model design process. The ablations were tested on the ScanNetV2 dataset and employed Point Transformer as the backbone. 
\vspace{-4mm}
\paragraph{Module ablation.} For a fair comparison, Point Transformer is retrained with the same experiment setting, including feature dimensions, module depths, and data argumentation. By upgrading the attention module to \textit{GIA}, a substantial improvement is observed. With the help of pseudo-label loss, a 1.4\% gain in mIoU is achieved. This significant improvement confirmed our hypothesis that local aggregation suffers from losing global context and that the \textit{GIA} module is capable of providing meaningful long-range contexts for better aggregation. Changing the sampling strategies also offered a boost in performance, improving the mIoU to 73.5\%. The joining of both modules with the pseudo label loss achieves a final result of 74.7\%. 
\vspace{-3mm}
\paragraph{Local-global balance.}
We then investigate the setting of the number of neighbour points \(k_{local}\), and \(k_{global}\), as shown in Table \ref{balance}. The best results are yielded when the attention module learns from 16 local points and 8 superpoints for feature aggregation. Increasing the number of global points does not provide significant benefits due to the possible introduction of noise. Also, we notice that it is possible to reduce the number of local points, such as (\(k_{local}\) = 10, \(k_{global}\) = 5) set, which achieves similar results as the baseline.
\vspace{-3mm}
\paragraph{Sampling methods.} The "Voxel" approach partitioned input with a voxel grid and uses pooling operations to fuse points. In Table \ref{ab_samp}, we notice that, with the help of geometric contexts, the GD approach indeed significantly improves the results compared to the FPS baseline. Interestingly, we also see an improvement in the voxel-based approaches. A potential reason is that Voxel-based sampling can better preserve geometry features, than that of FPS (as shown in the comparison in Figure \ref{fig:GD}), leading to a boost in performance. With the optimal sampling size setting, GD yields the best results and outperformed its voxel counterparts, demonstrating the benefits of sampling with the geometry-aware approach. 
\vspace{-4mm}

\paragraph{Geometric partition size.} We investigate the different sizes of caps for geometric partition (Table \ref{partition_cap}). For S3DIS, 1.0 m is the optimal size for geometric partitions, while for ScanNetV2, 3.0 m yields the best results, since the data are slightly large. We notice that it is essential to have the partition cap set to be larger than the maximum receptive field at the end of the encoder, to provide extra global contexts while reducing the risk of introducing noise.

