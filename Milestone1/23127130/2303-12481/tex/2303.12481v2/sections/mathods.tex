\vspace{-0.25in}
\section{SuperDeepFool: Efficient Algorithms to Find Minimal Perturbations}
\vspace{-0.11in}
\label{How-to-Improve-DF}
In this section, we propose a new class of methods that modifies DF to address the aforementioned challenges in the previous section. The goal is to maintain the desired characteristics of DF, i.e., computational efficiency and the fact that it is parameter-free while finding smaller adversarial perturbations. We achieve this by introducing an additional projection step which its goal is to steer the direction of perturbation towards the optimal solution of \eqref{global-formula}.
\begin{wrapfigure}[16]{r}{0.4\textwidth}
	\vspace{-0.50cm}
	\centering
	\includegraphics[width=0.3\textwidth]{photos/FMN.pdf}
	\caption{Histogram of the cosine angle between the normal to the decision boundary and the perturbation vector obtained by C$\&$W and FMN.}
	\label{fig:orthogonality_other}
\end{wrapfigure}
Let us first briefly recall how DF finds an adversarial perturbations for a classifier $f$. Given the current point $\x_i$, DF updates it according to the following equation:
\begin{align}
    \label{eq:DeepFool-step}
    {\x}_{i+1} = \x_{i} - \frac{f(\x_{i})}{\| \nabla f(\x_i)\|^{2}_{2}}\nabla f(\x_{i}).
\end{align}
Here the gradient is taken w.r.t. the input. The intuition is that, in each iteration, DF finds the minimum perturbation for a linear classifier that approximates the model around $\x_i$.
The below proposition shows that under certain conditions, repeating this update step eventually converges to a point on the decision boundary.
\begin{proposition}
    \label{prop:deepfool}
    Let the binary classifier $\mathcal{F}$\footnote{For the sake of clarity, we use $\mathcal{F}$ to denote binary classifiers for this proposition.}$:\mathbb{R}^{d} \rightarrow \mathbb{R}$ be~continuously differentiable and its gradient $\nabla \mathcal{F}$ is $\beta$-Lipschitz. For a given input sample $\x_0$, suppose $\mathcal{B}(\x_{0},\varepsilon)$ is a ball centered around $\x_0$ with radius $\varepsilon$, such that there exists $\x^{\star}\in \mathcal{B}(\x_{0},\varepsilon)$ that $f(\x^{\star})=0$. If $\|\nabla \mathcal{F}\|_{2}\geq \zeta$ for all $\x\in \mathcal{B}$ and $\varepsilon < \left( \dfrac{\zeta}{\beta} \right)^2$, then DF iterations converge to a point on the decision boundary.
    
    \textit{Proof:} \textit{We defer the proof to the Appendix.}
\end{proposition}
%\textit{Proof:} \textit{We defer the proof to the Appendix}.
Notice while the proposition guarantees the perturbed sample to lie on the decision boundary, it does not state anything about the orthogonality of the perturbation to the decision boundary.
%~(\orig{For a comprehensive analysis of global convergence guarantees, please see the Appendix~\ref{convergence}.})
%Moreover, in practice, DF typically terminates after less than four iterations when an adversarial example is found.
%As discussed in the previous section, such a solution may not necessarily lie on the decision boundary. 

To find perturbations that are more aligned with the normal to the decision boundary, we introduce an additional projection step that steers the perturbation direction towards the optimal solution of \eqref{global-formula}. Formally, the optimal perturbation, $\boldsymbol{r}^*$, and the normal to the decision boundary at $\x_0+\boldsymbol{r}^*$, $\nabla f(\x_0+\boldsymbol{r}^*)$, should be parallel. Equivalently, $\boldsymbol{r}^*$ should be a solution of the following maximization problem:
\begin{equation}
    \max_{\boldsymbol{r}} \frac{{\boldsymbol{r}}^\top\nabla f(\x_0+\boldsymbol{r})}{\|\nabla f(\x_0+\boldsymbol{r})\| \|\boldsymbol{r}\|},
    \label{eq:proj_max}
\end{equation}
which is the cosine of the angle between $\boldsymbol{r}$ and $\nabla f(\x_0+\boldsymbol{r})$. A necessary condition for $\boldsymbol{r}^*$ to be a solution of \eqref{eq:proj_max} is
that the projection of $\boldsymbol{r}^*$, i.e,~($\mathcal{P}_{\mathcal{S}}$) on the subspace orthogonal to $\nabla f(\x_0+\boldsymbol{r}^*)$ should be zero.
Then, $\boldsymbol{r}^*$ can be seen as a fixed point of the following iterative map:
\begin{equation}
    \boldsymbol{r}_{i+1} = T(\boldsymbol{r}_i)=\frac{{\boldsymbol{r}_i}^\top\nabla f(\x_0+\boldsymbol{r}_i)}{\|\nabla f(\x_0+\boldsymbol{r}_i)\|}\cdot\frac{\nabla f(\x_0+\boldsymbol{r}_i)}{\|\nabla f(\x_0+\boldsymbol{r}_i)\|}.
    \label{eq:iterative_proj}
\end{equation}

The scalar multiplier on the right-hand side of Eq.~(\ref{eq:iterative_proj}) represents the norm of the projection of the vector $\boldsymbol{r}_i$ along the gradient direction. The following proposition shows that this iterative process can converge to a solution of \eqref{eq:proj_max}.

\begin{proposition}
\label{prop:projection}
For a differentiable $f$ and a given $\boldsymbol{r}_0$, $\boldsymbol{r}_i$ in the iterations \eqref{eq:iterative_proj} either converge to a solution of \eqref{eq:proj_max} or a trivial solution (i.e., $\boldsymbol{r}_i\rightarrow 0$).

\textit{Proof:} \textit{We defer the proof to the Appendix.}
\end{proposition}
%\textit{Proof:} \textit{We defer the proof to the Appendix.}
Intuitively, by the geometrical properties of a decision boundary~($\mathscr{B}$), a small portion of the boundary can be enclosed between two
affine parallel hyperplane. The following proposition from~(\cite{brau2022minimal}) states that the angle between $\nabla f(\x)$ and the
optimal direction $\nabla f(\x + \boldsymbol{r^{*}})$ can be bounded in a neighborhood
of the boundary $\mathscr{B}$.
\begin{proposition}
	\label{proposition_3}
	(\cite{brau2022minimal})
	\textit{Given a radius $\boldsymbol{r} > 0$ and $\Psi _{\boldsymbol{r}}$ is the set of all samples whose distance from the decision boundary $\mathscr{B}$ is less than $\boldsymbol{r}$.
		For each angle $|\theta| \in \left( 0, \frac{\pi}{2} \right)$, there exists a distance $\boldsymbol{\widetilde{r}}_{(\theta)}$, such that, for all $\x \in \Psi_{\boldsymbol{\widetilde{r}}_{(\theta)}}$, the following inequality holds:
		\begin{equation}
			\frac{\nabla f(\x)^{\top} \nabla f(\mathcal{P}_{\mathcal{S}}(\x))}{\|\nabla f(\x)\| \|\nabla f(\mathcal{P}_{\mathcal{S}}(\x))\|} > \cos(\theta),
		\end{equation}
		\textit{where $\mathcal{P}_{\mathcal{S}}$ is the unique projection of $\x$ on the $\mathscr{B}$.}}
	
		\textit{Proof:} \textit{We defer the proof to the Appendix.}
\end{proposition}

%\textit{Proof:} \textit{We defer the proof to the Appendix.}

%\subsection*{Proof}

%From Assumption A, we deduce the continuity of $\nabla f$. From Assumption C and the compactness of $\mathcal{B}$, we deduce that there exists a distance $\boldsymbol{r}$ such that $\|\nabla f(x)\| \neq 0$ in $\bar{\Psi} _{\boldsymbol{r}}$ (the closure of $\Psi _{\boldsymbol{r}}$), and so we deduce that $\frac{\nabla f}{\|\nabla f\|}$ is uniformly continuous in $\bar{\Psi} _{\boldsymbol{r}}$. Hence, for each $\varepsilon$, there exists a distance $\boldsymbol{r}_\varepsilon \leq \boldsymbol{r}$ such that, for each $\x, \y \in \bar{\Psi}_{\boldsymbol{r}}$ and $\| \x - \y\| < \boldsymbol{r}_\varepsilon$, the following inequality holds
%\[
%\left\| \frac{\nabla f(\x)}{\|\nabla f(\x)\|} - \frac{\nabla f(\y)}{\|\nabla f(\y)\|} \right\| < \varepsilon.
%\]
%%By remembering that $\|v - w\|^2 = \|v\|^2 + \|w\|^2 - 2v^T w$ for each $v, w \in \mathbb{R}^n$, we can deduce the following inequality
%\[
%1 - \frac{1}{2} \varepsilon^2 < \frac{\nabla f(\x)^T \nabla f(\y)}{\|\nabla f(\x)\| \|\nabla f(\y)\|}.
%\]
%In conclusion, by taking $\y = \mathbb{P}_{\mathbf{s}}(\x)$ and by selecting $\varepsilon = \sqrt{2 - 2 \cos(\theta)}$, we derive Equation (11) where $\boldsymbol{\widetilde{r}}_{(\theta)} = \min(\boldsymbol{r}, \boldsymbol{r}_\varepsilon)$.



%\orig{\paragraph{Convergence guarantees.} A common challenge for all gradient-based optimization methods applied to non-convex problems is the lack of a guarantee in finding globally optimal perturbations for SotA neural networks. Obtaining even local guarantees is not trivial. Nevertheless, in Propositions~\ref{prop:deepfool} and \ref{prop:projection} we worked towards this goal. We have established local guarantees showing the convergence of each individual operation, namely the DeepFool step and projection step. However, further analysis is needed to establish local guarantees for the overall algorithm.}
% \newpage
\vspace{-0.19in}
\subsection{A Family of Adversarial Attacks}
\AlgoDontDisplayBlockMarkers
\RestyleAlgo{ruled}
\SetAlgoNoLine
\LinesNumbered
\begin{wrapfigure}{l}{0.45\textwidth}
\vspace{-0.5cm}
\begin{algorithm}[H]
    \SetKwFor{RepTimes}{repeat}{times}{end}
	\SetKwFunction{Union}{Union}\SetKwFunction{DeepFool}{\texttt{DeepFool}}\SetKwFunction{l}{\texttt{projection step}}
 
 	\KwIn{image $\x_0$, classifier $f$, $m$, and $n$.}
 	\KwOut{perturbation $\boldsymbol{r}$}

	Initialize: $\x\leftarrow\x_0$
	
    \While{$\sign(f(\x))= \sign(f(\x_{0}))$}
    	 {  
    	 \smallskip
         \RepTimes{$m$}{
         
         
    	    \smallskip               	    
  	    
    	    \smallskip
    	    $\x\gets \x-
         \frac{\left|f(\x)\right|}{\|\nabla f(\x)\|_2^2}\nabla f(\x)$
    	  
    	  \smallskip
    	  }
	  \smallskip
	  \RepTimes{$n$}{
	       $\x \gets \x_0 + \frac{(\x-\x_0)^\top\nabla f(\x)}{\|\nabla f(\x)\|^2} \nabla f(\x)$	  
	  }
    	  }	
        % \ali{$\x = \text{clip}(\x,0,1)$}
        
 	\KwRet $\boldsymbol{r}=\x-\x_{0}$
\caption{SDF~($m$,$n$) for binary classifiers}
\label{alg:SuperDeepFool}
\end{algorithm}
%\end{minipage}
%\hfill
\end{wrapfigure}
Finding minimum-norm adversarial perturbations can be seen as a multi-objective optimization problem, where we want $f(\x+\boldsymbol{r})=0$ and the perturbation $\boldsymbol{r}$ to be orthogonal to the decision boundary. So far we have seen that DF finds a solution satisfying the former objective and the iterative map \eqref{eq:iterative_proj} can be used to find a solution for the latter. A natural approach to satisfy both objectives is to \textbf{\textit{alternate}} between these two iterative steps, namely \eqref{eq:DeepFool-step} and \eqref{eq:iterative_proj}. We propose a family of adversarial attack algorithms, coined SuperDeepFool, by varying how frequently we alternate between these two steps.
We denote this family of algorithms with SDF$(m,n)$, where $m$ is the number of DF steps \eqref{eq:DeepFool-step} followed by $n$ repetition of the projection step \eqref{eq:iterative_proj}. This process is summarized in Algorithm~\ref{alg:SuperDeepFool}.
One interesting case is SDF$(\infty,1)$ which, in each iteration, continues DF steps till a point on the decision boundary is found and then applies the projection step.

This particular case has a resemblance with the strategy used in~\cite{rahmati2020geoda} to find black-box adversarial perturbations. This algorithm can be interpreted as iteratively approximating the decision boundary with a hyperplane and then analytically calculating the minimal adversarial perturbation for a linear classifier for which this hyperplane is the decision boundary.
It is justified by the observation that the decision boundary of state-of-the-art deep networks has a small mean curvature around data samples~\cite{fawzi2017robustness,fawzi2018empirical}.
A geometric illustration of this procedure is shown in Figure~\ref{fig:illus-SDF}.
% \begin{wrapfigure}[10]{R}{0.5\textwidth}
%   \centering
%   % \vspace{+0.9cm}
%   \includegraphics[width=0.80\linewidth]{photos/SuperDF_illus_S.pdf}
%   \caption{Illustration of two iterations of the SDF($\infty$,1) algorithm. Here $\mathbf{x}_0$ is the original data point and $\mathbf{x}_*$ is the minimum-norm adversarial example, which is the closest point on the decision boundary to $\mathbf{x}_0$. $\tilde{\mathbf{x}}_i$ and $\mathbf{x}_i$ indicate the DF and the orthogonal projection steps, respectively. The algorithm will eventually converge to $\mathbf{x}_*$.}
%   \label{fig:illus-SDF}
% \end{wrapfigure}

% \begin{figure}[t]
%   \centering
%   % \vspace{+0.9cm}
%   \includegraphics[width=0.50\linewidth]{photos/SuperDF_illus_S.pdf}
%   \caption{Illustration of two iterations of the SDF($\infty$,1) algorithm. Here $\mathbf{x}_0$ is the original data point and $\mathbf{x}_*$ is the minimum-norm adversarial example, which is the closest point on the decision boundary to $\mathbf{x}_0$. $\tilde{\mathbf{x}}_i$ and $\mathbf{x}_i$ indicate the DF and the orthogonal projection steps, respectively. The algorithm will eventually converge to $\mathbf{x}_*$. \orig{As previously stated in section 2 of the paper. The function $f(\mathbf{x})$ serves as a classifier by defining the decision boundary.}}
%   \label{fig:illus-SDF}
%   \vspace{-0.5cm}
% \end{figure}


% \myparagraph{SDF Attack}

% \begin{minipage}[t]{0.48\textwidth}
% \begin{algorithm}[H]
% 	\SetKwFunction{Union}{Union}\SetKwFunction{DeepFool}{\texttt{DeepFool}}\SetKwFunction{l}{\texttt{projection step}}
%  	\KwIn{image $\x_0$, classifier $f$.}
%  	\KwOut{perturbation $\boldsymbol{r}$}

% 	Initialize: $\x\leftarrow\x_0$
	
%     \While{$\hat{k}(\x)= \hat{k}(\x_{0})$}
%     	 {
%     	    \smallskip
%     		$\widetilde{\x}\leftarrow \DeepFool(\x)$    		
      
%     		\smallskip
       
%     		$\w\leftarrow\nabla f_{\hat{k}(\widetilde{\x})}(\widetilde{\x}) - \nabla f_{\hat{k}(\x_0)}(\widetilde{\x})$
    		
%     		\smallskip

%             $\x \gets \x_0 + \frac{(\widetilde{\x}-\x_0)^\top\w}{\|\w\|^2} \w$
%     	  }	
%         % \ali{$\x = \text{clip}(\x,0,1)$}
       
%  	\KwRet $\boldsymbol{r}=\x-\x_{0}$
% \caption{SDF for multi-class classifiers}
% \label{alg:SuperDeepFool-multi}
% \end{algorithm}
% \end{minipage}
% \end{figure}



% \begin{figure}
% \begin{minipage}[t]{0.48\textwidth}
% \begin{algorithm}[H]
%     \SetKwFor{RepTimes}{repeat}{times}{end}
% 	\SetKwFunction{Union}{Union}\SetKwFunction{DeepFool}{\texttt{DeepFool}}\SetKwFunction{l}{\texttt{projection step}}
 
%  	\KwIn{image $\x_0$, classifier $f$, $m$, and $n$.}
%  	\KwOut{perturbation $\boldsymbol{r}$}

% 	Initialize: $\x\leftarrow\x_0$
	
%     \While{$\sign(f(\x))= \sign(f(\x_{0}))$}
%     	 {  
%     	 \smallskip
%          \RepTimes{$m$}{
         
         
%     	    \smallskip               	    
  	    
%     	    \smallskip
%     	    $\x\gets \x-
%          \frac{\left|f(\x)\right|}{\|\nabla f(\x)\|_2^2}\nabla f(\x)$
    	  
%     	  \smallskip
%     	  }
% 	  \smallskip
% 	  \RepTimes{$n$}{
% 	       $\x \gets \x_0 + \frac{(\x-\x_0)^\top\nabla f(\x)}{\|\nabla f(\x)\|^2} \nabla f(\x)$	  
% 	  }
%     	  }	
%         % \ali{$\x = \text{clip}(\x,0,1)$}
        
%  	\KwRet $\boldsymbol{r}=\x-\x_{0}$
% \caption{SDF~($m$,$n$) for binary classifiers}
% \label{alg:SuperDeepFool}
% \end{algorithm}
% \end{minipage}
% \hfill
% \begin{minipage}[t]{0.48\textwidth}
% \begin{algorithm}[H]
% 	\SetKwFunction{Union}{Union}\SetKwFunction{DeepFool}{\texttt{DeepFool}}\SetKwFunction{l}{\texttt{projection step}}
%  	\KwIn{image $\x_0$, classifier $f$.}
%  	\KwOut{perturbation $\boldsymbol{r}$}

% 	Initialize: $\x\leftarrow\x_0$
	
%     \While{$\hat{k}(\x)= \hat{k}(\x_{0})$}
%     	 {
%     	    \smallskip
%     		$\widetilde{\x}\leftarrow \DeepFool(\x)$    		
      
%     		\smallskip
       
%     		$\w\leftarrow\nabla f_{\hat{k}(\widetilde{\x})}(\widetilde{\x}) - \nabla f_{\hat{k}(\x_0)}(\widetilde{\x})$
    		
%     		\smallskip

%             $\x \gets \x_0 + \frac{(\widetilde{\x}-\x_0)^\top\w}{\|\w\|^2} \w$
%     	  }	
%         % \ali{$\x = \text{clip}(\x,0,1)$}
       
%  	\KwRet $\boldsymbol{r}=\x-\x_{0}$
% \caption{SDF for multi-class classifiers}
% \label{alg:SuperDeepFool-multi}
% \end{algorithm}
% \end{minipage}
% \end{figure}


%\begin{wrapfigure}[20]{r}{0.40\textwidth}
%	\vspace{-1.20cm}
%	\centering
%	\includegraphics[width=0.40\textwidth]{photos/Query_norm_WRN_Rony.pdf}
%	\caption{
%		\orig{As demonstrated in~\cite{pintor2021fast}, query-distortion curves are utilised as a metric for evaluating computational complexity of white-box attacks. In this particular context, the term ``query'' refers to the quantity of forward passes available to find adversarial perturbations.}}
%	\label{fig:orthogonality_other}
%\end{wrapfigure}


\subsection{SDF Attack}
We empirically compare the performance of SDF$(m,n)$ for different values of $m$ and $n$ in Section~\ref{sec:exp-sdf}. Interestingly, we observe that we get better attack performance when we apply several DF steps followed by a single projection.
Since the standard DF typically finds an adversarial example in less than four iterations for state-of-the-art image classifiers, 
one possibility is to continue DF steps till an adversarial example is found and then apply a single projection step. We simply call this particular version~SDF$(\infty,1)$ of our algorithm SDF, which we will extensively evaluate in Section~\ref{sec:experiments}.

SDF can be understood as a generic algorithm that can also work for the multi-class case by simply substituting the first inner loop of Algorithm~\ref{alg:SuperDeepFool} with the standard multi-class DF algorithm. The label of the obtained adversarial example determines the boundary on which the projection step will be performed. A summary of multi-class SDF is presented in Algorithm~\ref{alg:SuperDeepFool-multi}. Compared to the standard DF, this algorithm has an additional projection step. We will see later that such a simple modification leads to significantly smaller perturbations.

\begin{wraptable}[13]{r}{0.45\textwidth}
	\vspace{-0.4cm}
	\centering
	\caption{Comparison of $\ell_{2}$-norm perturbations using DF and SDF algorithms on CIFAR10, employing consistent model architectures and hyperparameters as those used in~\cite{carlini2017towards,Rony_2019_CVPR} studies.}
	\vspace{-0.25cm}
	%		\begin{small}
	%			\begin{sc}
	% \vspace{-3mm}
	\resizebox{0.9\linewidth}{!}{
		\begin{tabular}{lrr}
			\toprule
			Attack & Median-$\ell_{2}$ & Grads \\
			\midrule
			DF  & $0.15$ & $\mathbf{14}$ \\
			SDF~(1,1)& $0.13$ & $22$ \\
			SDF~(1,3)& $0.14$ & $26$ \\
			SDF~(3,1)& $0.11$ & $30$ \\
			\rowcolor{Gray}SDF$(\infty,1)$& $\mathbf{0.10}$ & $32$ \\
			\bottomrule
		\end{tabular}
	}
	%			\end{sc}
	%		\end{small}
	\label{tab:CIFAR10_architecture_DF}
	
	%	\end{minipage}
\end{wraptable}

Table~\ref{tab:CIFAR10_architecture_DF} demonstrates that SDF family outperforms DF in finding more accurate perturbations, particularly SDF($\infty$,1) which significantly outperforms DF at a small cost.

Like any other gradient-based optimization method tackling a non-convex problem, providing a definitive explanation for why one algorithm outperforms others is not straightforward. We have the following speculation on why SDF$(\infty,1)$ consistently outperforms the other configurations: Note that each projection step reduces the perturbation, while each DF step moves the perturbation nearer to the boundary. So when projection is repeated multiple times~($n > 1$), it might undo the progress made by DF, potentially slowing down the algorithm's convergence. On the other hand, by first reaching a boundary point through multiple DF steps and then applying the projection operator just once, we at least ensure that the algorithm has reached intermediate adversarial examples. Each subsequent outer loop is hoped to incrementally move the adversarial example closer to the optimal point~(see~\ref{fig:illus-SDF}).



\begin{figure}[h!]
\begin{minipage}{0.48\textwidth}
\vspace{-0.5cm}
\begin{algorithm}[H]
	\SetKwFunction{Union}{Union}\SetKwFunction{DeepFool}{\texttt{DeepFool}}\SetKwFunction{l}{\texttt{projection step}}
 	\KwIn{image $\x_0$, classifier $f$.}
 	\KwOut{perturbation $\boldsymbol{r}$}

	Initialize: $\x\leftarrow\x_0$
	
    \While{$\hat{k}(\x)= \hat{k}(\x_{0})$}
    	 {
    	    \smallskip
    		$\widetilde{\x}\leftarrow \DeepFool(\x)$    		
      
    		\smallskip
       
    		$\w\leftarrow\nabla f_{\hat{k}(\widetilde{\x})}(\widetilde{\x}) - \nabla f_{\hat{k}(\x_0)}(\widetilde{\x})$
    		
    		\smallskip

            $\x \gets \x_0 + \frac{(\widetilde{\x}-\x_0)^\top\w}{\|\w\|^2} \w$
    	  }	
        % \ali{$\x = \text{clip}(\x,0,1)$}
       
 	\KwRet $\boldsymbol{r}=\x-\x_{0}$
\caption{SDF for multi-class classifiers}
\label{alg:SuperDeepFool-multi}
\end{algorithm}
\end{minipage}
% \vfill
	\hfill
	\begin{minipage}{0.45\textwidth}
	  \centering
	  \includegraphics[width=0.91\linewidth]{photos/SuperDF_illus_S.pdf}
	  \caption{Illustration of two iterations of the SDF($\infty$,1) algorithm. Here $\x_0$ is the original data point and $\x_*$ is the minimum-norm adversarial example.%, which is the closest point on the decision boundary to $\mathbf{x}_0$. $\tilde{\mathbf{x}}_i$ and $\mathbf{x}_i$ indicate the DF and the orthogonal projection steps, respectively. The algorithm will eventually converge to $\mathbf{x}_*$. \orig{As previously stated in section 2 of the paper. The function $f(\mathbf{x})$ serves as a classifier by defining the decision boundary.}
	  }
	  \label{fig:illus-SDF}
	  \vspace{-0.5cm}
	\end{minipage}
\end{figure}




% \begin{figure}
% \center
% \includegraphics[width=0.45\textwidth]{photos/SuperDF_illus_S.pdf}
% \caption{\label{fig:illus-SDF}Illustration of two iterations of the SDF($\infty$,1) algorithm. Here $\x_0$ is the original data point and $\x_*$ is the minimum-norm adversarial example, that is the closest point on the decision boundary to $\x_0$. $\tilde{\x}_i$ and $\x_i$ indicate the DF and the orthogonal projection steps respectively. The algorithm will eventually converges to $\x_*$.}
% \end{figure}




% \AlgoDontDisplayBlockMarkers
% \RestyleAlgo{ruled}
% \SetAlgoNoLine
% \LinesNumbered
% \begin{algorithm}[tb]
% 	\SetKwFunction{Union}{Union}\SetKwFunction{DeepFool}{\texttt{DeepFool}}\SetKwFunction{l}{\texttt{projection step}}
%  	\KwIn{image $\x_0$, classifier $f$.}
%  	\KwOut{perturbation $\boldsymbol{r}$}

% 	Initialize: $\x\leftarrow\x_0$
	
%     \While{$\hat{k}(\x)= \hat{k}(\x_{0})$}
%     	 {
%     	    \smallskip
%     		$\widetilde{\x}\leftarrow \DeepFool(\x)$    		
      
%     		\smallskip
       
%     		$\w\leftarrow\nabla f_{\hat{k}(\widetilde{\x})}(\widetilde{\x}) - \nabla f_{\hat{k}(\x_0)}(\widetilde{\x})$
    		
%     		\smallskip

%             $\x \gets \x_0 + \frac{(\widetilde{\x}-\x_0)^\top\w}{\|\w\|^2} \w$
%     	  }	
%         % \ali{$\x = \text{clip}(\x,0,1)$}
       
%  	\KwRet $\boldsymbol{r}=\x-\x_{0}$
% \caption{SDF for multi-class classifiers}
% \label{alg:SuperDeepFool-multi}
% \end{algorithm}

