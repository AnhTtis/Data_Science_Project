\section{DeepFool (DF) and Minimal Adversarial Perturbations}
\label{DeepFool}

In this section, we first discuss the geometric interpretation of the minimum-norm adversarial perturbations, i.e., solutions to the optimization problem in~\eqref{global-formula}.
We then examine DF to demonstrate why it may fail to find the minimum-norm perturbation. Then in the next section, we introduce our proposed method that exploits DF to find smaller perturbations.



Let $f$ : $\mathbb{R}^{d} \rightarrow \mathbb{R}^{C}$ denote a $C$-class classifier, where $f_k$ represents the classifier's output associated to the $k$th class. Specifically, for a given datapoint $\x$ $\in$ $\mathbb{R}^{d}$, the estimated label is obtained by $\hat{k}(\x)= \text{argmax}_{k} f_{k}(\x)$, where $f_{k}(\x)$ is the $k^{\text{th}}$ component of $f(\x)$ that corresponds to the $k^{\text{th}}$ class.

Note that the classifier $f$ can be seen as a mapping that partitions the input space $\mathbb{R}^{d}$ into classification regions, each of which has a constant estimated label (i.e., $\hat{k}(.)$ is constant for each such region). The decision boundary $\mathscr{B}$ is defined as the set of points in $\mathbb{R}^d$ such that $f_i(\x)=f_j(\x)=\max_{k}f_k(\x)$ for some distinct $i$ and $j$.

Additive $\ell_2$-norm adversarial perturbations are inherently related to the geometry of the decision boundary. More formally, Let $\x \in \mathbb{R}^{d}$, and $\boldsymbol{r}^{*}(\x)$ be the minimal adversarial perturbation defined as the minimizer of~\eqref{global-formula}. Then  $\boldsymbol{r}^{*}(\x)$, 1) is orthogonal to the decision boundary of the classifier $\mathscr{B}$, and 2) its norm $\|\boldsymbol{r}^{*}(\x)\|_2$ measures the Euclidean distance between $\x$ and $\mathscr{B}$, that is $\x+\boldsymbol{r}^{*}$ lies on $\mathscr{B}$. We aim to investigate whether the perturbations generated by DF satisfy the aforementioned two conditions. Let $\boldsymbol{r}_\text{DF}$ denote the perturbation found by DF for a datapoint $\x$.
We expect $\boldsymbol{x}+\boldsymbol{r}_\text{DF}$ to lie on the decision boundary. Hence, if $\boldsymbol{r}$ is the minimal perturbation, for all $0<\gamma <1$, we expect the perturbation $\gamma \boldsymbol{r}$  to remain in the same decision region as of $\x$ and thus fail to fool the model.

In Figure~\ref{fig:overly}, we consider the fooling rate of $\gamma\,\boldsymbol{r}_\text{DF}$ for $0.2<\gamma<1$. For a minimum-norm perturbation, we expect an immediate sharp decline for $\gamma$ close to one. However, in Figure~\ref{fig:overly} we cannot observe such a decline (a sharp decline happens close to $\gamma=0.9$, not 1).
This is a confirmation that DF typically finds an overly perturbed point. One potential reason for this is the fact that DF stops when a misclassified point is found, and this point might be an overly perturbed one within the adversarial region, and not necessarily on the decision boundary.

Now, let us consider the other characteristic of the minimal adversarial perturbation. That is, the perturbation should be orthogonal to the decision boundary. We measure the angle between the found perturbation $\boldsymbol{r}_\text{DF}$ and the normal vector orthogonal to the decision boundary~($\nabla f(\x+\boldsymbol{r}_\text{DF})$). To do so, we first scale $\boldsymbol{r}_\text{DF}$ such that $\x+\gamma\boldsymbol{r}_\text{DF}$ lies on the decision boundary. It can be simply done via performing a line search along $\boldsymbol{r}_\text{DF}$. We then compute the cosine of the angle between $\boldsymbol{r}_\text{DF}$ and the normal to the decision boundary at $\x+\gamma\boldsymbol{r}_\text{DF}$~(this angle is denoted by $\cos(\alpha)$). 
For an optimal perturbation, we expect these two vectors to be parallel.
In Figure~\ref{fig:orthogonality}, we show the distribution of cosine of this angle. Ideally, we wanted this distribution to be accumulated around one. However, Figure~\ref{fig:orthogonality} clearly shows that this is not the case, which is a confirmation that $\boldsymbol{r}_\text{DF}$ is not necessarily the minimal perturbation.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\columnwidth]{photos/Overly_perturbed_DF_S.pdf}
    \caption{We generated $1000$ images with one hundred $\gamma$ between zero and one, and the fooling rate of the DF is reported. This experiment is done on the CIFAR-$10$ dataset and ResNet-$18$~\cite{he2016deep} model. The accuracy of this Network is $94\%$.}
    \label{fig:overly}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\columnwidth]{photos/orthogonality-2_S.pdf}
    \caption{Histogram of the cosine angle distribution between the gradient in the last step of DF and the perturbation vector obtained by DF.
    This experiment has been performed on $1000$ images from the CIFAR-$10$~\cite{krizhevsky2009learning} dataset with the ResNet-$18$~\cite{he2016deep} model.}
    \label{fig:orthogonality}
\end{figure}

