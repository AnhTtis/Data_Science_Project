\section{Efficient Algorithms to Find Minimal Perturbations}
\label{How-to-Improve-DF}

In this section, we propose a new class of methods that modifies DF to address the aforementioned challenges in the previous section. The goal is to maintain the desired characteristics of DF, i.e., computational efficiency and the fact that it is parameter-free while finding smaller adversarial perturbations. We achieve this by introducing an additional projection step which its goal is to steer the direction of perturbation towards the optimal solution of \eqref{global-formula}.

Let us first briefly recall how DF finds an adversarial perturbations for a classifier $f$. Given the current point $\x_i$, DF updates it according to the following equation:
\begin{align}
    \label{eq:DeepFool-step}
    {\x}_{i+1} = \x_{i} - \frac{f(\x_{i})}{\| \nabla f(\x_i)\|^{2}_{2}}\nabla f(\x_{i}).
\end{align}
Here the gradient is taken w.r.t. the input. The intuition is that, in each iteration, DF finds the minimum perturbation for a linear classifier that approximates the model around $\x_i$.
The below proposition shows that under certain conditions, repeating this update step eventually converges to a point on the decision boundary.

\begin{proposition}
    Let the binary classifier $f:\mathbb{R}^{d} \rightarrow \mathbb{R}$ be continuously differentiable and its gradient $\nabla f$ be $L^{'}$-Lipschitz. For a given input sample $\x_0$, suppose $B(\x_{0},\epsilon)$ is a ball centered around $\x_0$ with radius $\epsilon$, such that there exists $\x\in B(\x_{0},\epsilon)$ that $f(\x)=0$. If $\|\nabla f\|_{2}\geq \zeta$ for all $\x\in B$ and $\epsilon < \frac{\zeta^2}{{L^{'}}^{2}}$, then DF iterations converge to a point on the decision boundary.
\end{proposition}
\textit{Proof:} \textit{We defer the proof to the Appendix}.

Note that while the proposition guarantees the perturbed sample to lie on the decision boundary, it does not state anything about the orthogonality of the perturbation to the decision boundary. Moreover, in practice, DF typically terminates after less than four iterations when an adversarial example is found. As discussed in the previous section, such a solution may not necessarily lie on the decision boundary. 

To find perturbations that are more aligned with the normal to the decision boundary, we introduce an additional projection step that steers the perturbation direction towards the optimal solution of \eqref{global-formula}. Formally, the optimal perturbation, $\boldsymbol{r}^*$, and the normal to the decision boundary at $\x_0+\boldsymbol{r}^*$, $\nabla f(\x_0+\boldsymbol{r}^*)$, should be parallel. Equivalently, $\boldsymbol{r}^*$ should be a solution of the following maximization problem:
\begin{equation}
    \max_{\boldsymbol{r}} \frac{{\boldsymbol{r}}^\top\nabla f(\x_0+\boldsymbol{r})}{\|\nabla f(\x_0+\boldsymbol{r})\| \|\boldsymbol{r}\|},
    \label{eq:proj_max}
\end{equation}
which is the cosine of the angle between $\boldsymbol{r}$ and $\nabla f(\x_0+\boldsymbol{r})$. A necessary condition for $\boldsymbol{r}^*$ to be a solution of \eqref{eq:proj_max} is
that the projection of $\boldsymbol{r}^*$ on the subspace orthogonal to $\nabla f(\x_0+\boldsymbol{r}^*)$ should be zero.
Then, $\boldsymbol{r}^*$ can be seen as a fixed point of the following iterative map:
\begin{equation}
    \boldsymbol{r}_{i+1} = T(\boldsymbol{r}_i)=\frac{{\boldsymbol{r}_i}^\top\nabla f(\x_0+\boldsymbol{r}_i)}{\|\nabla f(\x_0+\boldsymbol{r}_i)\|^2} \nabla f(\x_0+\boldsymbol{r}_i).
    \label{eq:iterative_proj}
\end{equation}

The following proposition shows that this iterative process can find a solution of \eqref{eq:proj_max}. 

\begin{proposition}
For a differentiable $f$ and a given $\boldsymbol{r}_0$, $\boldsymbol{r}_i$ in the iterations \eqref{eq:iterative_proj} either converge to a solution of \eqref{eq:proj_max} or a trivial solution (i.e., $\boldsymbol{r}_i\rightarrow 0$).
\end{proposition}
\textit{Proof:} \textit{We defer the proof to the Appendix.}

% \AlgoDontDisplayBlockMarkers
% \RestyleAlgo{ruled}
% \SetAlgoNoLine
% \LinesNumbered
\begin{algorithm}[t]
    \SetKwFor{RepTimes}{repeat}{times}{end}
	\SetKwFunction{Union}{Union}\SetKwFunction{DeepFool}{\texttt{DeepFool}}\SetKwFunction{l}{\texttt{projection step}}
 
 	\KwIn{image $\x_0$, classifier $f$, $m$, and $n$.}
 	\KwOut{perturbation $\boldsymbol{r}$}

	Initialize: $\x\leftarrow\x_0$
	
    \While{$\sign(f(\x))= \sign(f(\x_{0}))$}
    	 {  
    	 \smallskip
         \RepTimes{$m$}{
         
         
    	    \smallskip               	    
  	    
    	    \smallskip
    	    $\x\gets \x-
         \frac{\left|f(\x)\right|}{\|\nabla f(\x)\|_2^2}\nabla f(\x)$
    	  
    	  \smallskip
    	  }
	  \smallskip
	  \RepTimes{$n$}{
	       $\x \gets \x_0 + \frac{(\x-\x_0)^\top\nabla f(\x)}{\|\nabla f(\x)\|^2} \nabla f(\x)$	  
	  }
    	  }	
 	\KwRet $\boldsymbol{r}=\x-\x_{0}$
\caption{SDF~($m$,$n$) for binary classifiers}
\label{alg:SuperDeepFool}
\end{algorithm}
\subsection{A Family of Adversarial Attacks}
Finding minimum-norm adversarial perturbations can be seen as a multi-objective optimization problem, where we want $f(\x+\boldsymbol{r})=0$ and the perturbation $\boldsymbol{r}$ to be orthogonal to the decision boundary. So far we have seen that DF finds a solution satisfying the former objective and the iterative map \eqref{eq:iterative_proj} can be used to find a solution for the latter. A natural approach to satisfy both objectives is to alternate between these two iterative steps, namely \eqref{eq:DeepFool-step} and \eqref{eq:iterative_proj}. We propose a family of adversarial attack algorithms, coined \textit{SuperDeepFool}, by varying how frequently we alternate between these two steps.
We denote this family of algorithms with \textit{SDF}$(m,n)$, where $m$ is the number of DF steps \eqref{eq:DeepFool-step} followed by $n$ repetition of the projection step \eqref{eq:iterative_proj}. This process is summarized in Algorithm~\ref{alg:SuperDeepFool}.

One interesting case is SDF~$(\infty,1)$ which, in each iteration, continues DF steps till a point on the decision boundary is found and then applies the projection step. This particular case has a resemblance with the strategy used in~\cite{rahmati2020geoda} to find black-box adversarial perturbations. This algorithm can be interpreted as iteratively approximating the decision boundary with a hyperplane and then analytically calculating the minimal adversarial perturbation for a linear classifier for which this hyperplane is the decision boundary.
It is justified by the observation that the decision boundary of state-of-the-art deep networks has a small mean curvature around data samples~\cite{fawzi2017robustness,fawzi2018empirical}.
A geometric illustration of this procedure is shown in Figure~\ref{fig:illus-SDF}.



\subsection{SDF Attack}
We empirically compare the performance of SDF$(m,n)$ for different values of $m$ and $n$ in Section~\ref{sec:exp-sdf}. Interestingly, we observe that we get better attack performance when we apply several DF steps followed by a single projection. Since the standard DF typically finds an adversarial example in less than four iterations for state-of-the-art image classifiers, 
one possibility is to continue DF steps till an adversarial example is found and then apply a single projection step. We simply call this particular version of our algorithm SDF, which we will extensively evaluate in Section~\ref{sec:experiments}.

SDF can be understood as a generic algorithm that can also work for the multi-class case by simply substituting the first inner loop of Algorithm~\ref{alg:SuperDeepFool} with the standard multi-class DF algorithm. The label of the obtained adversarial example determines the boundary on which the projection step will be performed. A summary of multi-class SDF is presented in Algorithm~\ref{alg:SuperDeepFool-multi}. Compared to the standard DF, this algorithm has an additional projection step. We will see later that such a simple modification leads to significantly smaller perturbations.


\begin{figure}
\center
\includegraphics[width=0.45\textwidth]{photos/SuperDF_illus_S.pdf}
\caption{\label{fig:illus-SDF}Illustration of two iterations of the SDF($\infty$,1) algorithm. Here $\x_0$ is the original data point and $\x_*$ is the minimum-norm adversarial example, that is the closest point on the decision boundary to $\x_0$. $\tilde{\x}_i$ and $\x_i$ indicate the DF and the orthogonal projection steps respectively. The algorithm will eventually converges to $\x_*$.}
\end{figure}



% \AlgoDontDisplayBlockMarkers
% \RestyleAlgo{ruled}
% \SetAlgoNoLine
% \LinesNumbered
\begin{algorithm}[tb]
	\SetKwFunction{Union}{Union}\SetKwFunction{DeepFool}{\texttt{DeepFool}}\SetKwFunction{l}{\texttt{projection step}}
 	\KwIn{image $\x_0$, classifier $f$.}
 	\KwOut{perturbation $\boldsymbol{r}$}

	Initialize: $\x\leftarrow\x_0$
	
    \While{$\hat{k}(\x)= \hat{k}(\x_{0})$}
    	 {
    	    \smallskip
    		$\widetilde{\x}\leftarrow \DeepFool(\x)$    		
      
    		\smallskip
       
    		$\w\leftarrow\nabla f_{\hat{k}(\widetilde{\x})}(\widetilde{\x}) - \nabla f_{\hat{k}(\x_0)}(\widetilde{\x})$
    		
    		\smallskip

            $\x \gets \x_0 + \frac{(\widetilde{\x}-\x_0)^\top\w}{\|\w\|^2} \w$
    	  }	
 	\KwRet $\boldsymbol{r}=\x-\x_{0}$
\caption{SDF for multi-class classifiers}
\label{alg:SuperDeepFool-multi}
\end{algorithm}

