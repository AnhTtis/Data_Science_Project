
@inproceedings{yao2019spotting,
  title={Spotting visual keywords from temporal sliding windows},
  author={Yao, Yue and Wang, Tianyu and Du, Heming and Zheng, Liang and Gedeon, Tom},
  booktitle={2019 International Conference on Multimodal Interaction},
  pages={536--539},
  year={2019}
}

@inproceedings{jha2018word,
  title={Word spotting in silent lip videos},
  author={Jha, Abhishek and Namboodiri, Vinay P and Jawahar, CV},
  booktitle={2018 IEEE Winter conference on applications of computer vision (WACV)},
  pages={150--159},
  year={2018},
  organization={IEEE}
}

@inproceedings{stafylakis2018zero,
  title={Zero-shot keyword spotting for visual speech recognition in-the-wild},
  author={Stafylakis, Themos and Tzimiropoulos, Georgios},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={513--529},
  year={2018}
}

@article{prajwal2021transpotter,
  title={Visual keyword spotting with attention},
  author={Prajwal, KR and Momeni, Liliane and Afouras, Triantafyllos and Zisserman, Andrew},
  journal={arXiv preprint arXiv:2110.15957},
  year={2021}
}

@article{momeni2020KWS,
  title={Seeing wake words: Audio-visual keyword spotting},
  author={Momeni, Liliane and Afouras, Triantafyllos and Stafylakis, Themos and Albanie, Samuel and Zisserman, Andrew},
  journal={arXiv preprint arXiv:2009.01225},
  year={2020}
}

@article{muller2007DTW,
  title={Dynamic time warping},
  author={M{\"u}ller, Meinard},
  journal={Information retrieval for music and motion},
  pages={69--84},
  year={2007},
  publisher={Springer}
}

@inproceedings{graves2006CTC,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={369--376},
  year={2006}
}

@article{rabiner1989HMM,
  title={A tutorial on hidden Markov models and selected applications in speech recognition},
  author={Rabiner, Lawrence R},
  journal={Proceedings of the IEEE},
  volume={77},
  number={2},
  pages={257--286},
  year={1989},
  publisher={Ieee}
}

@inproceedings{mcauliffe2017MFA,
  title={Montreal Forced Aligner: Trainable Text-Speech Alignment Using Kaldi.},
  author={McAuliffe, Michael and Socolof, Michaela and Mihuc, Sarah and Wagner, Michael and Sonderegger, Morgan},
  booktitle={Interspeech},
  volume={2017},
  pages={498--502},
  year={2017}
}

@inproceedings{kurzinger2020ctc-align,
  title={CTC-segmentation of large corpora for german end-to-end speech recognition},
  author={K{\"u}rzinger, Ludwig and Winkelbauer, Dominik and Li, Lujun and Watzel, Tobias and Rigoll, Gerhard},
  booktitle={International Conference on Speech and Computer},
  pages={267--278},
  year={2020},
  organization={Springer}
}

@article{alberto2017aeneas,
  title={Aeneas (Version 1.7.3) [Computer Program]},
  author={Pettarin, Alberto},
  journal={Availabe at: \url{https://www.readbeyond.it/aeneas}},
  year={2017}
} 

@article{hong2022visual,
  title={Visual Context-driven Audio Feature Enhancement for Robust End-to-End Audio-Visual Speech Recognition},
  author={Hong, Joanna and Kim, Minsu and Yoo, Daehun and Ro, Yong Man},
  journal={arXiv e-prints},
  pages={arXiv--2207},
  year={2022}
}

@inproceedings{ma2021confavsr,
  title={End-to-end audio-visual speech recognition with conformers},
  author={Ma, Pingchuan and Petridis, Stavros and Pantic, Maja},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7613--7617},
  year={2021},
  organization={IEEE}
}

@article{sataloff1992humanvoice,
  title={The human voice},
  author={Sataloff, Robert T},
  journal={Scientific American},
  volume={267},
  number={6},
  pages={108--115},
  year={1992},
  publisher={JSTOR}
}

@article{kim2021cromm,
  title={Cromm-vsr: Cross-modal memory augmented visual speech recognition},
  author={Kim, Minsu and Hong, Joanna and Park, Se Jin and Ro, Yong Man},
  journal={IEEE Transactions on Multimedia},
  year={2021},
  publisher={IEEE}
}

@inproceedings{agarwal2020detecting,
  title={Detecting deep-fake videos from phoneme-viseme mismatches},
  author={Agarwal, Shruti and Farid, Hany and Fried, Ohad and Agrawala, Maneesh},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={660--661},
  year={2020}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{chen2020uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={European conference on computer vision},
  pages={104--120},
  year={2020},
  organization={Springer}
}

@article{lee2020multimodaltransformer,
  title={Parameter efficient multimodal transformers for video representation learning},
  author={Lee, Sangho and Yu, Youngjae and Kim, Gunhee and Breuel, Thomas and Kautz, Jan and Song, Yale},
  journal={arXiv preprint arXiv:2012.04124},
  year={2020}
}

@inproceedings{chung2017lrs2,
  title={Lip Reading Sentences in the Wild},
  author={Chung, Joon Son and Senior, Andrew and Vinyals, Oriol and Zisserman, Andrew},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={3444--3453},
  year={2017},
  organization={IEEE}
}

@article{afouras2018lrs3,
  title={LRS3-TED: a large-scale dataset for visual speech recognition},
  author={Afouras, Triantafyllos and Chung, Joon Son and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1809.00496},
  year={2018}
}

@article{kim2021lip2speech,
  title={Lip to Speech Synthesis with Visual Context Attentional GAN},
  author={Kim, Minsu and Hong, Joanna and Ro, Yong Man},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={2758--2770},
  year={2021}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{gulati2020conformer,
  title={Conformer: Convolution-augmented transformer for speech recognition},
  author={Gulati, Anmol and Qin, James and Chiu, Chung-Cheng and Parmar, Niki and Zhang, Yu and Yu, Jiahui and Han, Wei and Wang, Shibo and Zhang, Zhengdong and Wu, Yonghui and others},
  journal={arXiv preprint arXiv:2005.08100},
  year={2020}
}

@article{ren2019fastspeech,
  title={Fastspeech: Fast, robust and controllable text to speech},
  author={Ren, Yi and Ruan, Yangjun and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{kim2022distinguishing,
  title={Distinguishing Homophenes using Multi-head Visual-audio Memory for Lip Reading},
  author={Kim, Minsu and Yeo, Jeong Hun and Ro, Yong Man},
  booktitle={Proceedings of the 36th AAAI Conference on Artificial Intelligence, Vancouver, BC, Canada},
  volume={22},
  year={2022}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{petridis2018end,
  title={End-to-end audiovisual speech recognition},
  author={Petridis, Stavros and Stafylakis, Themos and Ma, Pingehuan and Cai, Feipeng and Tzimiropoulos, Georgios and Pantic, Maja},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={6548--6552},
  year={2018},
  organization={IEEE}
}

@article{stafylakis2017reslstm,
  title={Combining residual networks with LSTMs for lipreading},
  author={Stafylakis, Themos and Tzimiropoulos, Georgios},
  journal={arXiv preprint arXiv:1703.04105},
  year={2017}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{kudo2018sentencepiece,
  title={Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing},
  author={Kudo, Taku and Richardson, John},
  journal={arXiv preprint arXiv:1808.06226},
  year={2018}
}

@inproceedings{xiao2020deformation,
  title={Deformation flow based two-stream network for lip reading},
  author={Xiao, Jingyun and Yang, Shuang and Zhang, Yuanhang and Shan, Shiguang and Chen, Xilin},
  booktitle={2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)},
  pages={364--370},
  year={2020},
  organization={IEEE}
}

@article{weng2019twostream,
  title={Learning spatio-temporal features with two-stream deep 3d cnns for lipreading},
  author={Weng, Xinshuo and Kitani, Kris},
  journal={arXiv preprint arXiv:1905.02540},
  year={2019}
}

@article{assael2016lipnet,
  title={Lipnet: End-to-end sentence-level lipreading},
  author={Assael, Yannis M and Shillingford, Brendan and Whiteson, Shimon and De Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01599},
  year={2016}
}

@inproceedings{martinez2020mstcn,
  title={Lipreading using temporal convolutional networks},
  author={Martinez, Brais and Ma, Pingchuan and Petridis, Stavros and Pantic, Maja},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6319--6323},
  year={2020},
  organization={IEEE}
}

@article{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{afouras2018deep,
  title={Deep audio-visual speech recognition},
  author={Afouras, Triantafyllos and Chung, Joon Son and Senior, Andrew and Vinyals, Oriol and Zisserman, Andrew},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2018},
  publisher={IEEE}
}

@inproceedings{afouras2020asr,
  title={Asr is all you need: Cross-modal distillation for lip reading},
  author={Afouras, Triantafyllos and Chung, Joon Son and Zisserman, Andrew},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={2143--2147},
  year={2020},
  organization={IEEE}
}

@inproceedings{zhao2020hearing,
  title={Hearing lips: Improving lip reading by distilling speech recognizers},
  author={Zhao, Ya and Xu, Rui and Wang, Xinchao and Hou, Peng and Tang, Haihong and Song, Mingli},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={6917--6924},
  year={2020}
}

@inproceedings{ren2021learning,
  title={Learning from the master: Distilling cross-modal advanced knowledge for lip reading},
  author={Ren, Sucheng and Du, Yong and Lv, Jianming and Han, Guoqiang and He, Shengfeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13325--13333},
  year={2021}
}

@inproceedings{kim2021multi,
  title={Multi-modality associative bridging through memory: Speech sound recollected from face video},
  author={Kim, Minsu and Hong, Joanna and Park, Se Jin and Ro, Yong Man},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={296--306},
  year={2021}
}

@article{ma2021lira,
  title={LiRA: Learning visual speech representations from audio through self-supervision},
  author={Ma, Pingchuan and Mira, Rodrigo and Petridis, Stavros and Schuller, Bj{\"o}rn W and Pantic, Maja},
  journal={arXiv preprint arXiv:2106.09171},
  year={2021}
}

@inproceedings{chung2016syncnet,
  title={Out of time: automated lip sync in the wild},
  author={Chung, Joon Son and Zisserman, Andrew},
  booktitle={Asian conference on computer vision},
  pages={251--263},
  year={2016},
  organization={Springer}
}

@article{ren2020fastspeech2,
  title={Fastspeech 2: Fast and high-quality end-to-end text to speech},
  author={Ren, Yi and Hu, Chenxu and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:2006.04558},
  year={2020}
}

@inproceedings{elias2021parallel,
  title={Parallel tacotron: Non-autoregressive and controllable tts},
  author={Elias, Isaac and Zen, Heiga and Shen, Jonathan and Zhang, Yu and Jia, Ye and Weiss, Ron J and Wu, Yonghui},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5709--5713},
  year={2021},
  organization={IEEE}
}

@article{gorman2011prosodylab,
  title={Prosodylab-aligner: A tool for forced alignment of laboratory speech},
  author={Gorman, Kyle and Howell, Jonathan and Wagner, Michael},
  journal={Canadian Acoustics},
  volume={39},
  pages={192},
  year={2011}
}

@article{yuan2008speaker,
  title={Speaker identification on the SCOTUS corpus},
  author={Yuan, Jiahong and Liberman, Mark and others},
  journal={Journal of the Acoustical Society of America},
  volume={123},
  number={5},
  pages={3878},
  year={2008},
  publisher={[New York: Acoustical Society of America]}
}

@inproceedings{li2022neufa,
  title={Neufa: Neural Network Based End-to-End Forced Alignment with Bidirectional Attention Mechanism},
  author={Li, Jingbei and Meng, Yi and Wu, Zhiyong and Meng, Helen and Tian, Qiao and Wang, Yuping and Wang, Yuxuan},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={8007--8011},
  year={2022},
  organization={IEEE}
}

@inproceedings{yuan2019local,
  title={To find where you talk: Temporal sentence localization in video with attention based location regression},
  author={Yuan, Yitian and Mei, Tao and Zhu, Wenwu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={9159--9166},
  year={2019}
}

@inproceedings{gao2017local,
  title={Tall: Temporal activity localization via language query},
  author={Gao, Jiyang and Sun, Chen and Yang, Zhenheng and Nevatia, Ram},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5267--5275},
  year={2017}
}

@inproceedings{anne2017local,
  title={Localizing moments in video with natural language},
  author={Anne Hendricks, Lisa and Wang, Oliver and Shechtman, Eli and Sivic, Josef and Darrell, Trevor and Russell, Bryan},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5803--5812},
  year={2017}
}

@inproceedings{bojanowski2015local,
  title={Weakly-supervised alignment of video with text},
  author={Bojanowski, Piotr and Lajugie, R{\'e}mi and Grave, Edouard and Bach, Francis and Laptev, Ivan and Ponce, Jean and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4462--4470},
  year={2015}
}

@inproceedings{loshchilov2018decoupled,
  title={Decoupled Weight Decay Regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{kim2022speaker,
  title={Speaker-adaptive Lip Reading with User-dependent Padding},
  author={Kim, Minsu and Kim, Hyunjun and Ro, Yong Man},
  booktitle={European Conference on Computer Vision},
  pages={576--593},
  year={2022},
  organization={Springer}
}

@article{hong2022visual,
  title={Visual Context-driven Audio Feature Enhancement for Robust End-to-End Audio-Visual Speech Recognition},
  author={Hong, Joanna and Kim, Minsu and Yoo, Daehun and Ro, Yong Man},
  journal={arXiv preprint arXiv:2207.06020},
  year={2022}
}

@inproceedings{kurzinger2020ctcsegment,
  title={CTC-segmentation of large corpora for german end-to-end speech recognition},
  author={K{\"u}rzinger, Ludwig and Winkelbauer, Dominik and Li, Lujun and Watzel, Tobias and Rigoll, Gerhard},
  booktitle={International Conference on Speech and Computer},
  pages={267--278},
  year={2020},
  organization={Springer}
}

@article{shi2022avhubert,
  title={Learning audio-visual speech representation by masked multimodal cluster prediction},
  author={Shi, Bowen and Hsu, Wei-Ning and Lakhotia, Kushal and Mohamed, Abdelrahman},
  journal={arXiv preprint arXiv:2201.02184},
  year={2022}
}

@inproceedings{lee2022audio,
  title={Audio-Visual Mismatch-Aware Video Retrieval via Association and Adjustment},
  author={Lee, Sangmin and Park, Sungjune and Ro, Yong Man},
  booktitle={European Conference on Computer Vision},
  pages={497--514},
  year={2022},
  organization={Springer}
}