\begin{figure}[t]
    \vspace{-0.2cm}
    \centering
       \includegraphics[width=\linewidth]{figs/cdr_semseg_link.pdf}
       \caption{
           \textbf{Workflow of the pixel-to-vertex matching feature refinement.} \textit{Upper:} Matching matrix $\mathbf{M}$ for pixel-to-vertex correspondence is constructed with camera projection. The red-shaded boxes in the 3D volume denote an example of valid correspondence pairs of the 2D semantic prediction $\overrightarrow{m}_a$ and its surrounding 3D scene. The green and purple boxes in the 3D volume view denote the occluded vertex and out-of-view vertex that is not imaged in the 2D semantic prediction, which correspond to $\overrightarrow{m}_b$ and $\overrightarrow{m}_z$, respectively; \textit{Lower:} The 2D features are further masked by $\mathbf{M}(a)$ with the mapped coordinates from the sparse 3D features of the scene that are valid for the current view.
        %   \color{red}{Green, purple and red boxes description. Consistent with the body context.}
        }
       \label{fig:cdr_matching}
      \vspace{-0.3cm}
\end{figure}