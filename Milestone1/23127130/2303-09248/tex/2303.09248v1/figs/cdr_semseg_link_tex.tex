\begin{figure*}[ht]
    \vspace{-1.2cm}
    \centering
       \includegraphics[width=\linewidth]{figs/cdr_semseg_link.pdf}
       \caption{
           \textbf{Workflow of the pixel-to-vertex matching feature refinement.} In the upper part, matching matrix $M$ for pixel-to-vertex correspondence is constructed with camera projection. The 2D features are furthered masked by $M(i)$ with the mapped coordinates from the sparse 3D features of the scene that are valid for current view, as shown in the lower part. By doing so, the semantic labeling information that is latent in the 2D feature can be imposed on $s_i$ from GRU.
           The red-shaded boxes denote an example of valid correspondence pairs of the 2D semantic prediction $\mathbf{m_i}$ and its surrounding 3D scene. The green and purple boxes denote occluded vertex and out-of-view vertex that are not imaged in the 2D semantic prediction, which correspond to $\mathbf{m_k}$ and $\mathbf{m_j}$, respectively.
        %   \color{red}{Green, purple and red boxes description. Consistent with the body context.}
        }
       \label{fig:cdr_matching}
      \vspace{-0.3cm}
\end{figure*}