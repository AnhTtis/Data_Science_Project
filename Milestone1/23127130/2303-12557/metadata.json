{
    "arxiv_id": "2303.12557",
    "paper_title": "Q-HyViT: Post-Training Quantization for Hybrid Vision Transformer with Bridge Block Reconstruction",
    "authors": [
        "Jemin Lee",
        "Yongin Kwon",
        "Jeman Park",
        "Misun Yu",
        "Sihyeong Park",
        "Hwanjun Song"
    ],
    "submission_date": "2023-03-22",
    "revised_dates": [
        "2023-08-22"
    ],
    "latest_version": 2,
    "categories": [
        "cs.CV",
        "cs.AI"
    ],
    "abstract": "Recently, vision transformers (ViTs) have superseded convolutional neural networks in numerous applications, including classification, detection, and segmentation. However, the high computational requirements of ViTs hinder their widespread implementation. To address this issue, researchers have proposed efficient hybrid transformer architectures that combine convolutional and transformer layers with optimized attention computation of linear complexity. Additionally, post-training quantization has been proposed as a means of mitigating computational demands. For mobile devices, achieving optimal acceleration for ViTs necessitates the strategic integration of quantization techniques and efficient hybrid transformer structures. However, no prior investigation has applied quantization to efficient hybrid transformers. In this paper, we discover that applying existing PTQ methods for ViTs to efficient hybrid transformers leads to a drastic accuracy drop, attributed to the four following challenges: (i) highly dynamic ranges, (ii) zero-point overflow, (iii) diverse normalization, and (iv) limited model parameters ($<$5M). To overcome these challenges, we propose a new post-training quantization method, which is the first to quantize efficient hybrid ViTs (MobileViTv1, MobileViTv2, Mobile-Former, EfficientFormerV1, EfficientFormerV2) with a significant margin (an average improvement of 8.32\\% for 8-bit and 26.02\\% for 6-bit) compared to existing PTQ methods (EasyQuant, FQ-ViT, and PTQ4ViT). We plan to release our code at \\url{https://github.com/Q-HyViT}.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.12557v1",
        "http://arxiv.org/pdf/2303.12557v2"
    ],
    "publication_venue": "12 pages, 8 figures"
}