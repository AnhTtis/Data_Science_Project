{
    "arxiv_id": "2303.16321",
    "paper_title": "Worst-Case Control and Learning Using Partial Observations Over an Infinite Time-Horizon",
    "authors": [
        "Aditya Dave",
        "Ioannis Faros",
        "Nishanth Venkatesh",
        "Andreas A. Malikopoulos"
    ],
    "submission_date": "2023-03-28",
    "revised_dates": [
        "2023-03-30"
    ],
    "latest_version": 1,
    "categories": [
        "math.OC",
        "cs.AI",
        "eess.SY"
    ],
    "abstract": "Safety-critical cyber-physical systems require control strategies whose worst-case performance is robust against adversarial disturbances and modeling uncertainties. In this paper, we present a framework for approximate control and learning in partially observed systems to minimize the worst-case discounted cost over an infinite time-horizon. We model disturbances to the system as finite-valued uncertain variables with unknown probability distributions. For problems with known system dynamics, we construct a dynamic programming (DP) decomposition to compute the optimal control strategy. Our first contribution is to define information states that improve the computational tractability of this DP without loss of optimality. Then, we describe a simplification for a class of problems where the incurred cost is observable at each time-instance. Our second contribution is a definition of approximate information states that can be constructed or learned directly from observed data for problems with observable costs. We derive bounds on the performance loss of the resulting approximate control strategy.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16321v1"
    ],
    "publication_venue": null
}