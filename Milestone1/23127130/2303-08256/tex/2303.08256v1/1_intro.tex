\section{Introduction}


Reasoning high-level abstractions from bit-blasted Boolean networks (BNs) such as gate-level netlists has demonstrated its wide applications in improving functional verification efficiency~\cite{ciesielski2019understanding,mahzoon2019revsca} and identifying malicious logic such as detecting hardware trojan and intellectual property infringement usage~\cite{li2019attacking,botero2021hardware}.
In the era of globalization and democratization of integrated circuit (IC) development and fabrication, such reasoning is expected to bring broader impacts on hardware security, which is at the heart of modern computing systems: more than 40 percent of FPGA/ASIC projects are working under safety-critical development process standards or guidelines~\cite{wilson2022}. 
% \cy{should we say more about just reverse engineering? i think reasoning BNs is more general and RE is one type of application}

Due to the optimization conducted by RTL synthesis tools, reasoning high-level abstractions such as function blocks from unstructured or flattened netlists is extremely challenging, since hierarchy and module information is lost during multi-level logic minimization and technology mapping, which is also complicated by functional blocks overlapping and gate sharing. 
The problem goes further due to the explosion in runtime for large-scale BNs.
% \cy{this first sentence motivates the work but only from the difficulty part; we should also talk the runtime challenge up front.} 
Conventional reasoning approaches leverage topological structural analysis and functional propagation. 
Structural approaches either adopt shape hashing based on circuit topology to find structurally similar wires to form word-level abstractions~\cite{li2013wordrev}, or rely on reference libraries to map sub-circuits with reference circuits~\cite{cakir2018reverse}.
Functional approaches focus on identifying functionally equivalent gates and wires by cut enumeration~\cite{subramanyan2013reverse,gascon2014template}.
The combination of structural and functional analysis \cite{li2013wordrev,subramanyan2013reverse,yu2017fast} is more prevalent for efficient word-level abstraction and propagation.
Despite the achieved success, the performance of these conventional approaches is restricted by \textbf{limited scalability} and \textbf{inefficient utilization of modern computing power}:
(1) structural hashing is very time/memory-consuming for large BNs with billions of nodes;
(2) functional propagations by symbolic evaluation are solver-ready but extremely expensive, in particular for \textit{bit-blasted} non-linear arithmetic BNs;
(3) all these algorithms do not effectively utilize modern computing power due to the difficulty of parallelism.

Recently we have witnessed the emergence of machine learning (ML) applied for computer systems and electronic design automation (EDA) tasks~\cite{wu2022survey}, as an alternative to conventional design solutions.
Since circuit netlists or BNs can be easily represented as graphs, graph neural networks (GNNs) are naturally suitable to classify sub-circuit functionality from gate-level netlists~\cite{alrahis2021gnn}, analyze impacts of circuit rewriting on functional operator detection~\cite{zhao2022graph}, and predict boundaries of arithmetic blocks~\cite{he2021graph}.


\begin{figure}[t]
    \centering
    \vspace{2pt}
    \includegraphics[width=\linewidth]{figures/aggregation.pdf}
    %\vspace{-20pt}
    \caption{The inputs to \textsc{Gamora} are flattened gate-level netlists, with each node as an AND gate and dashed edges as inverters. By encoding Boolean functional information as node features, \textsc{Gamora} can simultaneously handle functional and structural aggregation, analogous to functional propagation and structural hashing in conventional reasoning but with strong scalability.}
    %\vspace{-20pt}
    \label{fig:high-level}
\end{figure}



Motivated by the limitations of conventional approaches and potentials of GNNs applied on circuit designs, we propose a graph learning-based symbolic reasoning framework to reverse engineer functional blocks from gate-level netlists, namely \textsc{Gamora}, which has \textbf{high reasoning accuracy}, \textbf{scalability} to BNs with billions of nodes, and \textbf{generalization capability} from simple to complex designs.
% As shown in Figure~\ref{fig:high-level}, the inputs are flattened gate-level netlists, and the outputs are BNs with higher level abstractions (i.e., target functional units).
\textsc{Gamora} employs a multi-task GNN to guarantee the high reasoning precision and to handle the structural and functional information from BNs simultaneously.
Once \textsc{Gamora} is well trained, it can generalize to large-scale and complex BNs, in which the inference can be accelerated and paralleled by modern computing systems.
We summarize our contributions as follows.
%\red{emphasis on multipliers}

% -> limitation of current GNN-based methods (GNN for different functional units identification) (handling hundreds of thousands gates, which can be larger; identify the inputs/outputs of functional units and matching these inputs with outputs by flow-based methods, instead of marking the functionality, limited by the capability of post-processing;
% the benchmark mixes a couple of circuit designs, node-level classification, limited application for real-world applications;
% very complex node features;
% lack analysis of design complexity and impacts from different technology mapping)


\begin{itemize}[leftmargin=*]
\item \textbf{Novel multi-task GNN for structure and function fusion.} 
The message passing mechanisms in GNNs enable simultaneous \textit{Boolean functional} and \textit{structural aggregation}, corresponding to symbolic propagation and structural hashing in conventional reasoning methods, as shown in Figure~\ref{fig:high-level}.
The multi-task setting allows knowledge sharing across different reasoning sub-tasks to guarantee high reasoning accuracy.

%\item It includes a set of domain-specific reduction techniques, including node attributes compression, and BN-specific graph coarsening, and refinement methods, enable truly-scalable embedding on \underline{billion-node} BNs embedding.

\item \textbf{Billion-node scalability and parallelism.} 
We develop domain-specific techniques to compress node features, significantly reducing compute costs.
The exploitation of graph learning draws better support from modern computing systems, such as GPU deployment, for scalability to large BNs and parallel execution.

% -- Unlike traditional symbolic reasoning approaches which are hard to be parallelized, GLOBAL will effectively utilize modern computing power supported by ML frameworks such as PyTorch and domain-specific compilers such as TVM

\item {\bf Generalization capability.} 
Unlike many ML-based approaches that are trained with complex designs and infer on simpler ones, \textsc{Gamora} can easily generalize from simple to complex BNs and handle the reasoning complexity introduced by more advanced designs (such as Booth multipliers) and technology mapping.


% \item {\bf End-to-end system integration.}
% \textsc{Gamora} is integrated with the logic synthesis tool ABC~\cite{brayton2010abc}, which can be applied to reduce complexity of Boolean SAT solving, logic minimization, and malicious logic detection.
% \item A local-to-global graph embedding based reasoning approach will be developed to identify word-level functions in bit-blasted BNs; and will be applied to accelerate Boolean \textit{Satisfiability} (SAT) solving and improve logic circuit minimization by algorithmic design space exploration, based on BN characterization.

% -- GLOBAL will be applied to the real-life applications in Boolean SAT solving and logic minimization by integrating with the state-of-the-art SAT solvers through PySAT and synthesis tool ABC \cite{brayton2010abc}, along with a novel \textit{local-to-global} BN characterization technique based on graph embedding.

%\item GLOBAL will also be integrated and released with PySAT \cite{imms-sat18}, an open-source python interface to a number of state-of-the-art SAT solvers, and will be integrated with ABC \cite{abc:cav10} for logic circuit characterization and minimization tasks.

\item \textbf{Evaluation.} 
Regarding reasoning performance, \textsc{Gamora} reaches almost 100\% and over 97\% reasoning accuracy for carry-save array (CSA) and Booth multipliers, respectively;
after technology mapping, the reasoning accuracy is still over 92\%.
Regarding runtime and scalability, \textsc{Gamora} can perform reasoning for large BNs with tens of millions of nodes/edges within one second, with a speedup of up to six orders of magnitude compared to ABC.

\end{itemize}





