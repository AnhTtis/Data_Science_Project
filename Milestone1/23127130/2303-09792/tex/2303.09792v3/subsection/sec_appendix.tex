
%%%%%%%%% ABSTRACT
\begin{figure*}[ht!]
\centering
\includegraphics[width=\linewidth]{./images/visual_V2.pdf}
\vspace{-0.39cm}
\caption{Qualitative comparison of SVDP with previous SOTA method: CoTTA~\cite{Wangetal2022}, VDP~\cite{gan2022decorate} on ACDC Fog, Night, Rain, and Snow four scenarios. SVDP could better segment different pixel-wise classes such as shown in the white box.}
\label{fig:qualitative} 
\vspace{-0.3cm}
\end{figure*}
\section*{Appendix Overview}
\label{sec: ap}

The following items are included in this supplementary material.

\begin{itemize}
    \item Additional Ablation Studies of
    \begin{itemize}
        \item Depth Estimation on TTA scenario
        \item Domain Prompt Updating
    \end{itemize}
    \item Qualitative Analysis of 
    \begin{itemize}
        \item Semantic Segmentation
        \item Depth Estimation
    \end{itemize}
    \item Additional Quantitative Results
    \item Additional Related Work
\end{itemize}

\section{Additional Ablation Studies}
\subsection{Depth Estimation on TTA scenario}
\label{Sec:ablation ctta}
The proposed method comprises a Sparse Visual Prompt (SVDP), a Domain Prompt Placement (DPP) strategy, and a Domain Prompt Updating (DPU) strategy to mitigate domain shifts in semantic segmentation tasks. In this study, we conduct ablation experiments on the TTA scenario (KITTI-to-DrivingStereo Foggy) to evaluate the effectiveness of each component.

To compare the performance of our method with and without using the teacher-student (TS) structure, a common technique in TTA used to generate pseudo labels in the target domain, we present the results in Tab.~\ref{aptab:ablation} $Ex_{2}$. The results show that without our method, TS only has 0.069 Abs Rel reduces, indicating that our method's improvement does not come from the usage of this prevalent scheme.
In $Ex_{3}$, we introduce SVDP to extract local target domain knowledge without damaging the original spatial information. The results demonstrate that SVDP achieves a 21.0\% $\delta>1.25$ improvement and 0.073 Abs Rel reduction, effectively addressing the domain shift problem. In $Ex_{4}$, DPP achieves a further 3.3\% $\delta>1.25$ improvement and 0.014 Abs Rel reduces by serving as a specially designed prompt placement strategy to assist SVDP in extracting more target domain-specific knowledge.
We evaluate the effectiveness of the DPU in $Ex_{5}$, which adaptively optimizes for different samples during testing. Compared with $Ex_{3}$, DPU reduces the Abs Rel 0.006 and improves 2.2\% $\delta>1.25$ respectively. Finally, in $Ex_{6}$, we show the complete combination of all components, which achieves a total of 69.4\% $\delta>1.25$ improvement and 0.161 Abs Rel reduction. These results demonstrate that all components of our method effectively address the depth estimation domain shift and compensate for each other to achieve superior performance.


\begin{table}[!tb]
\caption{\textbf{Ablation: Contribution of each component on KITTI-to-DrivingStereo Foggy. 
}}
\centering
\setlength\tabcolsep{5pt}%调列距
\renewcommand\arraystretch{1}%调行距
\begin{tabular}{c|cccc|cc}
\toprule
 & \makecell*[c]{TS} & \makecell*[c]{SVDP} & \makecell*[c]{DPP} & \makecell*[c]{DPU}  & Abs Rel$\downarrow$ & $\delta>1.25 \uparrow$\\\midrule
$Ex_{1} $ &  & & & &0.313& 0.040 \\ 
$Ex_{2} $& \checkmark &  & &  & 0.244& 0.482\\
$Ex_{3}$ &\checkmark  & \checkmark &  & & 0.171& 0.692\\
$Ex_{4}$  & \checkmark & \checkmark &\checkmark  &  &0.157& 0.725\\
$Ex_{5}$  & \checkmark & \checkmark & &\checkmark & 0.165& 0.714\\
$Ex_{6} $ & \checkmark &  \checkmark &\checkmark  &\checkmark & 0.152& 0.734\\
\bottomrule
\end{tabular}
\vspace{-0.2cm}
\label{aptab:ablation}
\end{table}

\begin{figure}[!h]
\includegraphics[width=0.43\textwidth]{./images/dpu_senstivity_V9.pdf}
\centering
\vspace{-0.05cm}
\caption{Sensitivity Analysis: The effect of prompt EMA's parameter $\beta$ on depth estimation performance in the CTTA scenario.}
\label{fig:senstivity}
\vspace{-0.25cm}
\end{figure}
\subsection{Domain Prompt Updating}
\label{Sec: sentivity}
For SVDP, we utilize Eq.5 to update the prompt parameters and conduct an analysis of the sensitivity of the parameter $\beta$ in the depth estimation CTTA scenario. As depicted in Fig.~\ref{fig:senstivity}, we investigate the impact of $\delta>1.25$ values on the performance. Specifically, we gradually increase the value of $\beta$ and record the corresponding $\delta>1.25$ values. We observe that the $\delta>1.25$ improves with increasing $\beta$; however, it starts to decrease once $\beta$ exceeds 0.999. Compare with the best fixed $\beta$ value, our proposed DPU (\textcolor{red}{red line}) strategy can further achieve 1.5\% $\delta>1.25$ improvement. Therefore, due to the different degrees of domain shift, we need to update prompt parameters for the each sample with different EMA weights.





\section{Qualitative analysis}
\subsection{Semantic Segmentation}
\label{Sec:qualitative}
To further demonstrate the effectiveness of our proposed method, SVDP, we conduct a qualitative comparison with two current leading methods, CoTTA \cite{Wangetal2022} and VDP \cite{gan2022decorate}, on the CTTA scenario (Cityscapes-to-ACDC). 


The results of the comparison are presented in Fig .\ref{fig:qualitative}. 
In the foggy target-domain, we highlight a white box that contains a tall truck object. This object is difficult to segment as it shares characteristics with the \emph{sign} class. Thanks to the contribution of the Domain Prompt Placement (DPP), our proposed method, SVDP, has a significant advantage in dealing with such confusing semantic segmentation categories with high uncertainty. Our method also outperforms CoTTA and VDP in the remaining three domains. In these domains, our proposed method correctly distinguishes the sidewalk from the road, avoiding misclassification.
Overall, our method can achieve better local segmentation results and neglect the influence of local domain shift.
And our method produces finer results than the previous state-of-the-art methods, with clear visual improvement.

\subsection{Depth estimation}
To demonstrate the generalizability of our proposed method SVDP, we compare it with the current SOTA method on the Depth Estimation task, and the results of the qualitative analysis are shown in Fig.~\ref{fig:qualitative_depth}

Compared with the VDP and CoTTA, We notice that our SVDP can obviously improves the semantic representation of the model, which concentrates more on the foreground object. 
The results verify that our methods can extract the target domain knowledge during the test time adaptation. 
Furthermore, our SVDP enhances the model's depth estimation ability in the regions of edges, sharpness, and long distances.

\begin{figure*}[ht!]
\centering
\includegraphics[width=\linewidth]{./images/visual_depth_v2.pdf}
\vspace{-0.39cm}
\caption{Qualitative comparison of SVDP with previous SOTA method: CoTTA\cite{Wangetal2022}, VDP\cite{gan2022decorate} on Driving Stero  Cloudy, Foggy, Rainy, and Sunny four scenarios. SVDP could make the depth estimation better such as shown in the white circle.}
\label{fig:qualitative_depth} 
\vspace{-0.3cm}
\end{figure*}
\begin{table*}
\caption{Performance Comparison for \textbf{Cityscapes-to-ACDC Fog domain in TTA scenario}. The IoU score of each class and the mIoU score are reported. The best results are highlighted in \textbf{bold}.
  } \label{table:fog acdc}
  \centering
  \resizebox{0.99\textwidth}{!}{
    \def\arraystretch{1.1}
    \begin{tabular}{ l | c c c c c c c c c c c c c c c c c c c | c }
        \Xhline{1.2pt}
        Method & \rotatebox{0}{road} & \rotatebox{0}{side.} & \rotatebox{0}{buil.} & \rotatebox{0}{wall} & \rotatebox{0}{fence} & \rotatebox{0}{pole} & \rotatebox{0}{light} & \rotatebox{0}{sign} & \rotatebox{0}{veg.} & \rotatebox{0}{terr.} & \rotatebox{0}{sky} & \rotatebox{0}{pers.} & \rotatebox{0}{rider} & \rotatebox{0}{car}& \rotatebox{0}{truck} & \rotatebox{0}{bus} & \rotatebox{0}{train} & \rotatebox{0}{mbike} & \rotatebox{0}{bike} & mIoU \\
        \hline
        \hline
        Source  & 94.0 & 63.9 & 79.8 & 55.7 & 24.9 & 45.0 & 41.5 & 69.8 & 86.6 & 71.0 & 97.6 & 64.1 & 66.2 & 87.4 & 73.0 & 92.6 & 87.7 & 50.2 & 61.7 & 69.1 \\
        TENT & 94.0 & 64.0 & 79.7 & 55.4 & 24.6 & 44.6 & 41.4 & 69.9 & 86.7 & 71.1 & 97.6 & 64.0 & 65.9 & 87.4 & 73.0 & 92.6 & 88.0 & 50.2 & 61.9 & 69.0 \\
        CoTTA & 93.9 & 63.6 & 80.0 & 55.5 & 25.1 & 49.0 & 43.4 & 73.0 & 87.0 & 70.7 & 97.8 & 68.6 & 71.3 & 87.1 & 74.8 & 93.6 & 89.1& 58.0 & 66.7 & 70.9 \\
        DePT & 94.0 & 64.0 & 79.9 & 56.1 & 25.3 & 48.8 & 43.5 & 73.0 & 87.1 & 70.6 & 97.5 & 67.9 & \textbf{71.5} & 87.3 & 75.1 & 93.5 & 89.1& 57.4 & 66.5 & 71.0 \\
        VDP & 93.9 & 63.6& 80.0 & 55.6 & 25.1& 49.0& 43.4 & 73.0& 86.9 & 70.7 & 97.7 & 68.5 & 71.1 & 87.2 & 74.7 & 93.5 & 89.2 & 57.9 & 66.6 & 70.9 \\
        \cellcolor{lightgray}\textbf{SVDP} &\cellcolor{lightgray}\textbf{94.4} &\cellcolor{lightgray}\textbf{65.9}&\cellcolor{lightgray}\textbf{80.5}&\cellcolor{lightgray}\textbf{57.8}&\cellcolor{lightgray}\textbf{26.5}&\cellcolor{lightgray}\textbf{50.5}&\cellcolor{lightgray}\textbf{43.9}&\cellcolor{lightgray}\textbf{73.6}&\cellcolor{lightgray}\textbf{87.6}&\cellcolor{lightgray}\textbf{72.0}&\cellcolor{lightgray}\textbf{98.0}&\cellcolor{lightgray}\textbf{68.8}&\cellcolor{lightgray}71.3 
 &\cellcolor{lightgray}\textbf{87.7}&\cellcolor{lightgray}\textbf{77.6}&\cellcolor{lightgray}\textbf{94.4}&\cellcolor{lightgray}\textbf{92.6}&\cellcolor{lightgray}\textbf{60.0}      &\cellcolor{lightgray}\textbf{67.4} 
 &\cellcolor{lightgray}\textbf{72.1}\\\bottomrule


       
        
        \Xhline{1.2pt}
    \end{tabular}
  }

\end{table*}

\begin{table*}
\caption{Performance Comparison for \textbf{Cityscapes-to-ACDC Night domain in TTA scenario}. The IoU score of each class and the mIoU score are reported. The best results are highlighted in \textbf{bold}.
  } 
  \centering
  \resizebox{0.99\textwidth}{!}{
    \def\arraystretch{1.1}
    \begin{tabular}{ l | c c c c c c c c c c c c c c c c c c c | c }
        \Xhline{1.2pt}
        Method & \rotatebox{0}{road} & \rotatebox{0}{side.} & \rotatebox{0}{buil.} & \rotatebox{0}{wall} & \rotatebox{0}{fence} & \rotatebox{0}{pole} & \rotatebox{0}{light} & \rotatebox{0}{sign} & \rotatebox{0}{veg.} & \rotatebox{0}{terr.} & \rotatebox{0}{sky} & \rotatebox{0}{pers.} & \rotatebox{0}{rider} & \rotatebox{0}{car}& \rotatebox{0}{truck} & \rotatebox{0}{bus} & \rotatebox{0}{train} & \rotatebox{0}{mbike} & \rotatebox{0}{bike} & mIoU \\
        \hline
        \hline
        Source  & 87.6 & 46.3 & 61.8 & 27.0 & 25.3 & 40.8 & 38.7 & 39.4 & 47.7& 26.8 & \textbf{11.4} & 48.6 & 39.9 & 76.1 & 15.9 & 24.2 & 52.0 & 26.5 & 29.6 & 40.3 \\
        TENT & \textbf{87.7} & 46.4 & 61.9 & 27.1 & 25.2 & 40.8 & 38.8 & 39.3  & 47.0 & 26.8 & 9.6 & 48.7 & 40.0 & 76.2 & 16.1 & 24.3 & 51.9 & 26.6& 29.7 & 40.2 \\
        CoTTA & 87.6 & 46.7 & \textbf{62.3}& 27.2 & 25.0 & 44.0 & 42.9 & 40.8 & 47.2 & 26.7 & 8.8 & 51.8 & 41.9 & 76.6 & 18.8 & 22.4 & 51.7& 27.8 & 32.1 & 41.2 \\
        DePT & 87.3 & 46.5 & 62.0 & 27.0 & 25.3 & 43.5 & 40.9 & 41.0 & 47.2 & 26.6 & 8.8 & 51.0 & 42.5 & 77.1 & 17.5 & 23.0 & 51.5 & 26.4 & 31.7 & 40.9 \\
        VDP & 87.6 & 46.8 & 62.2 & 27.1 & 25.0 & 44.0 & 42.9 & 41.0 & 47.3 & 26.6 & 9.0 & 51.7 & 41.9 & 76.6& 18.7 & 23.2 & 51.9 & 27.8& 32.0 & 41.2 \\
        \cellcolor{lightgray}\textbf{SVDP} &\cellcolor{lightgray}87.5 &\cellcolor{lightgray}\textbf{46.6}&\cellcolor{lightgray}52.7&\cellcolor{lightgray}\textbf{28.3}&\cellcolor{lightgray}\textbf{23.1}&\cellcolor{lightgray}\textbf{46.0}&\cellcolor{lightgray}\textbf{44.7}&\cellcolor{lightgray}\textbf{41.2}&\cellcolor{lightgray}\textbf{56.1}&\cellcolor{lightgray}\textbf{23.9}&\cellcolor{lightgray}10.5&\cellcolor{lightgray}\textbf{53.4}&\cellcolor{lightgray}\textbf{43.2} 
 &\cellcolor{lightgray}\textbf{78.0}&\cellcolor{lightgray}\textbf{25.7}&\cellcolor{lightgray}\textbf{26.0}&\cellcolor{lightgray}\textbf{46.9}&\cellcolor{lightgray}\textbf{29.7}     &\cellcolor{lightgray}\textbf{34.1} 
 &\cellcolor{lightgray}\textbf{42.0}\\\bottomrule
       

        
        \Xhline{1.2pt}
    \end{tabular}
  }
\label{table:night acdc}
\end{table*}

\begin{table*}[!htb]
\caption{Performance Comparison for \textbf{Cityscapes-to-ACDC Rain domain in TTA scenario}. The IoU score of each class and the mIoU score are reported. The best results are highlighted in \textbf{bold}.
  } 
  \centering
  \resizebox{0.99\textwidth}{!}{
    \def\arraystretch{1.1}
    \begin{tabular}{ l | c c c c c c c c c c c c c c c c c c c | c }
        \Xhline{1.2pt}
        Method & \rotatebox{0}{road} & \rotatebox{0}{side.} & \rotatebox{0}{buil.} & \rotatebox{0}{wall} & \rotatebox{0}{fence} & \rotatebox{0}{pole} & \rotatebox{0}{light} & \rotatebox{0}{sign} & \rotatebox{0}{veg.} & \rotatebox{0}{terr.} & \rotatebox{0}{sky} & \rotatebox{0}{pers.} & \rotatebox{0}{rider} & \rotatebox{0}{car}& \rotatebox{0}{truck} & \rotatebox{0}{bus} & \rotatebox{0}{train} & \rotatebox{0}{mbike} & \rotatebox{0}{bike} & mIoU \\
        \hline
        \hline
        Source  & 82.3 & 47.1 & 89.5 & 36.8 & 26.6 & 51.0 & 64.8 & 62.9 & 89.5 & 60.3 & 97.8 & 46.0 & 53.0 & 81.1 & 25.3 & 65.4 & 56.7 & 47.6 & 51.2 & 59.7 \\
        TENT & 82.4 & 46.7 & 89.6 & 37.3 & 27.0 & 50.6 & 64.6 & 62.9 & 89.5 & 60.4 & 97.7 & 46.7 &54.5 & 81.2 & 25.4 & 65.2 & 56.6 & 47.3 & 51.8 & 59.9 \\
        CoTTA & 83.0 & 48.4& 90.2 & 38.3 & 28.0 & 55.5 & 68.1 & 67.5& 90.3 &61.2 & 98.0 & 54.1 & 60.1 &82.0 & 27.4 & 67.0 & 59.1 & 50.9 & 55.4 & 62.6 \\
        DePT & 82.0 & 47.3 & 89.8& 37.5 & 26.9 & 53.0 & 66.2 & 65.8 & 89.6 & 60.8 & 97.7 & 52.8 & 59.5 & 81.6 & 26.5 & 66.5 & 57.9 & 49.5 & 53.2 & 61.3 \\
        VDP  & 83.0 & 48.3 & 90.2 & 38.2 & 28.0 & 55.5 & 68.2 &67.5 & 90.2 & 61.2 & 97.9 & 54.1 & 59.9 & 82.0 & 27.5 & 67.0 & 59.1 & 50.9 & 55.3 & 62.3 \\
        \cellcolor{lightgray}\textbf{SVDP} &\cellcolor{lightgray}\textbf{85.2} &\cellcolor{lightgray}\textbf{54.4}&\cellcolor{lightgray}\textbf{91.1}&\cellcolor{lightgray}\textbf{43.1}&\cellcolor{lightgray}\textbf{31.8}&\cellcolor{lightgray}\textbf{57.7}&\cellcolor{lightgray}\textbf{69.2}&\cellcolor{lightgray}\textbf{69.9}&\cellcolor{lightgray}\textbf{90.8}&\cellcolor{lightgray}\textbf{62.1}&\cellcolor{lightgray}\textbf{98.2}&\cellcolor{lightgray}\textbf{56.5}&\cellcolor{lightgray}\textbf{60.7} 
 &\cellcolor{lightgray}\textbf{83.0}&\cellcolor{lightgray}\textbf{28.7}&\cellcolor{lightgray}\textbf{67.6}&\cellcolor{lightgray}\textbf{63.6}&\cellcolor{lightgray}\textbf{55.0}      &\cellcolor{lightgray}\textbf{55.7} 
 &\cellcolor{lightgray}\textbf{64.4}\\\bottomrule
       
        
        \Xhline{1.2pt}
    \end{tabular}
  }
\label{table:rain acdc}
\end{table*}



\begin{table*}[!htb]
\caption{Performance Comparison for \textbf{Cityscapes-to-ACDC Snow domain in TTA scenario}. The IoU score of each class and the mIoU score are reported. The best results are highlighted in \textbf{bold}.
  } 
  \centering
  \resizebox{0.99\textwidth}{!}{
    \def\arraystretch{1.1}
    \begin{tabular}{ l | c c c c c c c c c c c c c c c c c c c | c }
        \Xhline{1.2pt}
        Method & \rotatebox{0}{road} & \rotatebox{0}{side.} & \rotatebox{0}{buil.} & \rotatebox{0}{wall} & \rotatebox{0}{fence} & \rotatebox{0}{pole} & \rotatebox{0}{light} & \rotatebox{0}{sign} & \rotatebox{0}{veg.} & \rotatebox{0}{terr.} & \rotatebox{0}{sky} & \rotatebox{0}{pers.} & \rotatebox{0}{rider} & \rotatebox{0}{car}& \rotatebox{0}{truck} & \rotatebox{0}{bus} & \rotatebox{0}{train} & \rotatebox{0}{mbike} & \rotatebox{0}{bike} & mIoU \\
        \hline
        \hline
        Source  & 79.8 & 40.8 & 86.9 & 43.6 & 46.5 & 56.4 & 72.3 & 65.5 & 82.9 &  \textbf{5.7} & 97.1 & 62.8 & 40.4 & 85.4 & 54.7 & 44.5 & 73.1 & 22.7 & 36.0 & 57.8 \\
        TENT & 79.6 & 40.0 & 86.8 & 43.4 & 46.5 & 56.1 & 72.2 & 65.6 & 82.9 &  \textbf{5.7} & 97.1 & 63.0 & 40.9 & 85.5 & 54.7 & 43.1 & 72.7& 23.0 & 36.5& 57.7\\
        CoTTA & 80.1 & 40.7 & 87.5 & 43.9 & 47.7 & 59.9 & 75.3 & 69.2 & 84.0 & 5.1 & 97.2 & 67.3 & 46.9 & 86.2 & 56.1& 43.4 & 74.1 &  25.7& 43.3 & 59.8 \\
        DePT & 79.1 & 40.6 & 86.8 & 43.4 & 47.5 & 59.8 & 75.1 & 69.4 & 83.5 & 5.2 & 97.1 & 67.2 & 46.5 & 86.3 & 56.0 & 44.0 & 73.9 & 25.6 & 43.1 & 59.5 \\
        VDP & 80.1 & 40.8 & 87.5 & 43.9 & 47.8 & 59.9 & 75.1 & 69.4 & 83.9 & 5.1 & 97.2 & 67.2 & 46.7 & 86.2 & 56.2 & 43.9 & 74.0 & 25.7 & 42.9 & 59.7 \\
        \cellcolor{lightgray}\textbf{SVDP} &\cellcolor{lightgray}\textbf{86.6} &\cellcolor{lightgray}\textbf{57.7}&\cellcolor{lightgray}\textbf{88.2}&\cellcolor{lightgray}\textbf{47.0}&\cellcolor{lightgray}\textbf{45.5}&\cellcolor{lightgray}\textbf{62.4}&\cellcolor{lightgray}\textbf{75.9}&\cellcolor{lightgray}\textbf{71.5}&\cellcolor{lightgray}\textbf{84.9}&\cellcolor{lightgray}3.9&\cellcolor{lightgray}\textbf{97.4}&\cellcolor{lightgray}\textbf{68.0}&\cellcolor{lightgray}\textbf{49.3} 
 &\cellcolor{lightgray}\textbf{87.1}&\cellcolor{lightgray}\textbf{57.1}&\cellcolor{lightgray}\textbf{49.2}&\cellcolor{lightgray}\textbf{77.5}&\cellcolor{lightgray}\textbf{26.8 }     &\cellcolor{lightgray}\textbf{45.4} 
 &\cellcolor{lightgray}\textbf{62.2}\\\bottomrule
        \Xhline{1.2pt}
    \end{tabular}
  }
\label{table:snow acdc}
\end{table*}






\section{Additional Quantitative Results}
\label{Sec: quantitative}
We present a comprehensive presentation of experimental results on the Test-time adaptation task for Cityscapes-to-ACDC, as shown in Tab .~\ref{table:fog acdc} - Tab .~\ref{table:snow acdc}. Our findings suggest that our proposed approach can better address the domain shift problem and achieve better IoU value in most categories.




\section{Additional related work}
\label{Sec:related}

\textbf{Semantic segmentation} is a crucial task in many computer vision applications aimed at assigning a categorical label to every pixel in an image. Several representative works in this field include DeepLab \cite{chen2017deeplab}, PSPNet \cite{zhao2017pyramid}, RefineNet \cite{lin2017refinenet}, and Segformer \cite{xie2021segformer}. Despite their high performance, these methods usually require extensive amounts of pixel-level annotated data, which can be laborious and time-consuming to collect. Additionally, they may suffer from poor generalization when applied to new domains.
Recent research has focused on addressing these challenges through domain adaptation strategies. For instance, \cite{yang2020fda} proposes a method that swaps the low-frequency spectrum to align the source and target domains. \cite{tranheden2021dacs} mixes the images from both domains, along with their corresponding labels and pseudo-labels. In contrast, \cite{wu2021dannet} uses adversarial learning to train a domain adaptation network for nighttime semantic segmentation. \cite{hoyer2022daformer} develops a novel model and training strategies to enhance training stability and avoid overfitting to the source domain.
However, these methods often require retraining the model on the source domain, which is inconvenient. Furthermore, they need to be retrained when adapting to a new target domain, incurring additional time and resource costs. Therefore, we propose SVDP to efficiently address the domain shift problem, which leverages a pre-trained model on the source domain and adds only a few parameters to achieve strong generalization capabilities on the target domain.

\textbf{Depth estimation} 
Depth estimation is a crucial task of machine scene comprehension. The ascendancy of deep learning has established it as the dominant approach for supervised depth estimation across both outdoor~\cite{eigen2014depth, geiger2012we, yang2019drivingstereo} and indoor settings~\cite{Silberman:ECCV12, scharstein2014high}. Typical methodologies involve the integration of a universal encoder, responsible for assimilating global context, alongside a decoder designed to retrieve depth details~\cite{Xu_2018_CVPR, Ramamonjisoa_2020_CVPR, lee2019monocular, Ramamonjisoa_2019_ICCV, fu2018deep}. In the context of cross-domain depth estimation, the emphasis is on aligning source and target domains either at the input or feature level~\cite{kundu2018adadepth,zheng2018t2net,zhao2019geometry}. As a case in point, the work presented in~\cite{zhao2019geometry} introduced a geometry-centric symmetric adaptation framework, conceived to optimize both the translation and the depth estimation processes simultaneously.~\cite{li2023test} combines the self-supervised model and the supervised model to tackle this problem. However, these methods always lead to catastrophic forgetting, and thus we introduce the Sparse Visual Domain Prompt to tackle this problem.
% \bibliography{supbib}
