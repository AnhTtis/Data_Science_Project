\begin{table*}[htb]
\caption{\textbf{Performance comparison of Cityscapes-to-ACDC TTA.} We use Cityscape as the source domain and ACDC as the four target domains in this setting. Mean-mIoU represents the average mIoU value in four TTA experiments.}
\vspace{-0.3cm}
\centering
\setlength\tabcolsep{11pt}%调列距
\begin{adjustbox}{width=1\linewidth,center=\linewidth}
\begin{tabular}{c|c|cc|cc|cc|cc|c }
\hline

\multicolumn{2}{c|}{Test-Time Adaptation}          & \multicolumn{2}{c|}{Source2Fog}    & \multicolumn{2}{c|}{Source2Night}     & \multicolumn{2}{c|}{Source2Rain}  & \multicolumn{2}{c|}{Source2Snow}    & \multirow{2}{*}{Mean-mIoU}  \\ \cline{1-10}
Method &REF &mIoU$\uparrow$ &mAcc$\uparrow$ 
&mIoU$\uparrow$ &mAcc$\uparrow$ &mIoU$\uparrow$ &mAcc$\uparrow$ &mIoU$\uparrow$ &mAcc$\uparrow$& \\ \hline
Source & NIPS2021 \cite{xie2021segformer}&69.1&79.4&40.3&55.6&59.7&74.4&57.8&69.9 &56.7\\ 
TENT  & ICLR2021 \cite{wang2020tent}  &69.0&79.5&  40.3&55.5&  59.9&74.1&  57.7&69.7 &56.7\\ 
CoTTA& CVPR2022\cite{Wangetal2022} &70.9&80.2 &41.2&55.5 &62.6&75.4 &59.8&70.7&58.6\\ 
DePT & ICLR2023\cite{gao2022visual}  &71.0&80.2&40.9&\textbf{55.8}&61.3&74.4&59.5&70.0&58.2\\ 
VDP & AAAI2023\cite{gan2022decorate}  &70.9&80.3&41.2&55.6&62.3&75.5&59.7&70.7&58.5\\ 

\cellcolor{lightgray}\textbf{SVDP} &\cellcolor{lightgray}\textbf{ours} &\cellcolor{lightgray}\textbf{72.1}
&\cellcolor{lightgray}\textbf{81.2} &\cellcolor{lightgray}\textbf{42.0}&\cellcolor{lightgray}54.9& \cellcolor{lightgray}\textbf{64.4}&\cellcolor{lightgray} \textbf{76.7} &\cellcolor{lightgray}\textbf{62.2}&\cellcolor{lightgray}\textbf{72.8}&\cellcolor{lightgray}\textbf{60.2}\\  \bottomrule

 \hline
\end{tabular}
\end{adjustbox}
\label{tab:TTA}
\vspace{-0.3cm}
\end{table*}
We provide the details of the task settings for test-time adaptation (TTA) and continual TTA (CTTA), as well as a description of the datasets. In the second and third subsections, we compare our method with other baselines \cite{xie2021segformer, wang2020tent, Wangetal2022, gao2022visual, gao2022visual} in four TTA and two CTTA scenarios. 
Comprehensive ablation studies are conducted in the last subsection, which investigates the impact of each component.
We also provide more quantitative analysis in the Appendix \ref{sec: ap}.

\subsection{Task settings and Datasets}
\label{sec:4.1}
\textbf{TTA and CTTA} are commonly used source-free technology in real-world scenarios in which a source pre-trained model adapts to the distribution of an unseen target domain \cite{liang2023comprehensive}. CTTA is of the same setting as TTA but further sets the target domain constantly changing, bringing more difficulties during the continual adaptation process.

\textbf{Cityscapes-to-ACDC} is designed for semantic segmentation cross-domain learning. And we conduct four TTA and one CTTA experiment on the scenario. The source model is an off-the-shelf pre-trained segmentation model that was trained on the Cityscapes dataset~\cite{cordts2016cityscapes}. 
The ACDC dataset~\cite{sakaridis2021acdc} contains images collected in four different unseen visual conditions: Fog, Night, Rain, and Snow. For the TTA, we adapt the source pre-trained model to each of the four ACDC target domains separately. For the CTTA, we repeat the same sequence of target domains (Fog→Night→Rain→Snow) multiple times to simulate environment changes in real-world scenarios \cite{Wangetal2022}.

\textbf{KITTI-to-Driving Stereo.}
To demonstrate the generalization of our method, we also conduct experiments in depth estimation CTTA scenario. The source model employed is an off-the-shelf, pre-trained model, initially trained on the KITTI dataset \cite{geiger2012we}. The Driving Stereo\cite{yang2019drivingstereo} comprises images collected under four disparate, unseen visual conditions: foggy, rainy, sunny, and cloudy. For the CTTA, we repeat the same sequence of target domains (Foggy→Rainy→Sunny→Cloudy) multiple times.


\textbf{Implementation Details.} We follow the implementation details \cite{Wangetal2022} to set up our semantic segmentation TTA experiments. Specifically, we use the Segformer-B5 ~\cite{xie2021segformer} pre-trained on Cityscapes as our off-the-shelf source model.  
We down-sample the original image size of 1920x1080 of the ACDC dataset to 960x540, which serves as network input. We evaluate our predictions under the original resolution. 
We use a range of image resolution scale factors [0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0] for the augmentation method in teacher model. 
For depth estimation CTTA, we follow the implementation details in previous work~\cite{liu2022unsupervised} and adopt the pre-trained DPT~\cite{Ranftl2021} on the KITTI as the source model. 
The optimizer is performed using Adam optimizer~\cite{kingma2014adam}  with $(\beta_1, \beta_2) = (0.9, 0.999)$. We set the learning rate specific values for each backbone, such as 3e-4 for Segformer and 1e-5 for DPT, and batch size 1 for both TTA and CTTA experiments.
All experiments are conducted on NVIDIA V100 GPUs.
\subsection{The effectiveness on Semantic Segmentation}
\label{sec:4.2}
\begin{table*}[htb]
\caption{\textbf{Performance comparison for Cityscape-to-ACDC CTTA.} We take the Cityscape as the source domain and ACDC as the continual target domains. During testing, we sequentially evaluate the four target domains three times. Mean is the average score of mIoU. Gain refers to the improvement achieved by the method compared to the Source model.}
\vspace{-0.3cm}
\centering
\setlength\tabcolsep{2pt}%调列距
\begin{adjustbox}{width=1\linewidth,center=\linewidth}
\begin{tabular}{c|c|ccccc|ccccc|ccccc|c|c }
\hline

\multicolumn{2}{c|}{Time}     & \multicolumn{15}{c}{$t$ \makebox[10cm]{\rightarrowfill} }                                                                              \\ \hline
\multicolumn{2}{c|}{Round}          & \multicolumn{5}{c|}{1}    & \multicolumn{5}{c|}{2}     & \multicolumn{5}{c|}{3}  & \multirow{2}{*}{Mean$\uparrow$}   & \multirow{2}{*}{Gain}  \\ \cline{1-17}
Method & REF & Fog & Night & Rain & Snow & Mean$\uparrow$ & Fog & Night & Rain & Snow  & Mean$\uparrow$ & Fog & Night & Rain & Snow & Mean$\uparrow$ & \\ \hline
Source & NIPS2021 \cite{xie2021segformer}  &69.1&40.3&59.7&57.8&56.7&69.1&40.3&59.7& 	57.8&56.7&69.1&40.3&59.7& 57.8&56.7&56.7&/\\ 
TENT & ICLR2021 \cite{wang2020tent}  &69.0&40.2&60.1&57.3&56.7&68.3&39.0&60.1& 	56.3&55.9&67.5&37.8&59.6&55.0&55.0&55.7&-1.0\\ 
CoTTA & CVPR2022\cite{Wangetal2022}  &70.9&41.2&62.4&59.7&58.6&70.9&41.1&62.6& 	59.7&58.6&70.9&41.0&62.7&59.7&58.6&58.6&+1.9\\ 
DePT & ICLR2023\cite{gao2022visual} 
&71.0&40.8&58.2&56.8&56.5&68.2&40.0&55.4&53.7& 54.3&66.4&38.0&47.3&47.2&49.7&53.4&-3.3\\
VDP & AAAI2023\cite{gan2022decorate}  &70.5&41.1&62.1&59.5&  58.3    &70.4&41.1&62.2&59.4& 58.2     & 70.4&41.0&62.2&59.4& 58.2   &  58.2 & +1.5\\
\cellcolor{lightgray}\textbf{SVDP} &\cellcolor{lightgray}\textbf{ours} &\cellcolor{lightgray}\textbf{72.1}&\cellcolor{lightgray}\textbf{44.0}&\cellcolor{lightgray}\textbf{65.2}&\cellcolor{lightgray}\textbf{63.0}&\cellcolor{lightgray}\textbf{61.1}& 
 \cellcolor{lightgray}\textbf{72.2}&\cellcolor{lightgray}\textbf{44.5}&\cellcolor{lightgray}\textbf{65.9}&\cellcolor{lightgray}\textbf{63.5}&\cellcolor{lightgray}\textbf{61.5} 
 &\cellcolor{lightgray}\textbf{72.1}&\cellcolor{lightgray}\textbf{44.2}&\cellcolor{lightgray}\textbf{65.6}&\cellcolor{lightgray}\textbf{63.6}&\cellcolor{lightgray}\textbf{61.4}      &\cellcolor{lightgray}\textbf{61.3} 
 &\cellcolor{lightgray}+\textbf{4.6}\\\bottomrule
 \hline
\end{tabular}
\end{adjustbox}
\vspace{-0.3cm}
\label{tab:CTTA}
\end{table*}


\textbf{Cityscapes-to-ACDC TTA.}
We evaluate the performance of the proposed SVDP on four scenarios with significant domain gap during TTA. 
Tab .\ref{tab:TTA} shows that the Mean-mIoU for the four domains using the source domain model alone is only 56.7\%. Recent advanced methods CoTTA increases it to 58.6\% while our method further increases it by 1.6\%. 
These results demonstrate that our method can better address the domain shit problem in test time compared to other methods.  Furthermore, in contrast to VDP, which employs dense prompts, our method successfully circumvents the occlusion issue, leading to improved extraction of both semantic and domain knowledge for TTA. In comparison to DePT, which introduces prompts at the token level, our SVDP approach operates at the image-level. This aspect enables the extraction of local domain knowledge, thereby resulting in substantial performance enhancements.


\textbf{Cityscapes-to-ACDC CTTA.}
To demonstrate that our method can also address continuously changing domain shifts, we deal with the four domain data during test time periodically.
As shown in Tab .\ref{tab:CTTA}, due to catastrophic forgetting, the performance of TENT and DePT gradually decreases over time. These methods only focus on acquiring new domain-specific knowledge from the target domain, resulting in a neglect of the original knowledge from the source domain.
And we find that our method gains 2.7\% increase of mIoU more than the previous SOTA CTTA method \cite{Wangetal2022}. 
The results prove that our method can continuously extract target domain knowledge via sparse prompt and preserve previous domain knowledge via model parameters, showing the ability to address dynamic domain shifts. 
In term of qualitative analysis, shown in Fig .\ref{fig:vis}, our method correctly distinguish the sidewalk from the road, avoiding mis-classification in target domains. 


Overall, our method outperforms several previous SOTA methods on all semantic segmentation TTA and CTTA tasks and shows promising potential for real-world applications.
% These results suggest that SVDP is a valuable approach for adapting pre-trained models to new and diverse target domains.
\begin{figure*}[htb]
\centering
\includegraphics[width=0.98\linewidth]{./images/vis_V3.pdf}
\vspace{-0.25cm}
\caption{Qualitative comparison of our method with previous SOTA methods on the ACDC dataset. Our method could better segment different pixel-wise classes such as shown in the white box. More qualitative analysis is shown in supplement.}
\label{fig:vis}
\vspace{-0.3cm}
\end{figure*}


\begin{table*}[htb]
\caption{\textbf{Performance comparison for KITTI-to-Driving Stereo CTTA.} We take the KITTI as the source domain and Driving Stereo as the continual target domains. Mean is the average score of $\delta>1.25$ for four domains.}
\vspace{-0.3cm}
\centering
\setlength\tabcolsep{2pt}%调列距
\begin{adjustbox}{width=1\linewidth,center}
\begin{tabular}{c|cccc|cccc|cccc|cccc|c }
\hline

\multicolumn{1}{c|}{Time}     & \multicolumn{14}{c}{$t$ \makebox[13.8cm]{\rightarrowfill} }                                                                              \\ \hline
\multicolumn{1}{c|}{Domain}          & \multicolumn{4}{c|}{Foggy}    & \multicolumn{4}{c|}{Rainy}     & \multicolumn{4}{c|}{Sunny} & \multicolumn{4}{c|}{Cloudy} & \multirow{2}{*}{Mean$\uparrow$}     \\ \cline{1-17}
Method  & $\delta>1.25$$\uparrow$ & $\delta>1.25^2$$\uparrow$ & AbsRel$\downarrow$ & RMSE$\downarrow$ &  $\delta>1.25$ $\uparrow$& $\delta>1.25^2$$\uparrow$ & AbsRel$\downarrow$ & RMSE$\downarrow$ &  $\delta>1.25$$\uparrow$ & $\delta>1.25^2$ $\uparrow$& AbsRel$\downarrow$ & RMSE$\downarrow$ &  $\delta>1.25$$\uparrow$ & $\delta>1.25^2$$\uparrow$ & AbsRel$\downarrow$ & RMSE$\downarrow$ &  \\ \hline
Source   &0.040&0.791&0.313&10.864&0.046&0.573&0.382&15.966& 0.153&0.896&0.270&7.404&0.134& 0.8697&0.282&7.758&0.093\\ 
CoTTA   &0.436&0.892&0.268&9.615&0.553&0.791&0.289& 12.231&0.597&0.964&0.191&5.445&0.476&0.959&0.203&5.536&0.516\\ 
VDP  &0.683&0.902&0.159&9.068& 0.575&0.692&0.253&15.403& 0.716&0.876&0.181&8.905&0.689&0.858&0.197& 9.200&0.666\\
\cellcolor{lightgray}\textbf{SVDP} &\cellcolor{lightgray}\textbf{0.734}&\cellcolor{lightgray}\textbf{0.943}&\cellcolor{lightgray}\textbf{0.152}&\cellcolor{lightgray}\textbf{7.092}&\cellcolor{lightgray}\textbf{0.689}&\cellcolor{lightgray}\textbf{0.894}&\cellcolor{lightgray}\textbf{0.159}&\cellcolor{lightgray}\textbf{9.700}&\cellcolor{lightgray}\textbf{0.800}&\cellcolor{lightgray}\textbf{0.937}&\cellcolor{lightgray}\textbf{0.168}&\cellcolor{lightgray}\textbf{5.719}&\cellcolor{lightgray}\textbf{0.784}&\cellcolor{lightgray}\textbf{0.930}&\cellcolor{lightgray}\textbf{0.169}&\cellcolor{lightgray}\textbf{5.784}&\cellcolor{lightgray}\textbf{0.752}\\\bottomrule
\hline
\end{tabular}
\end{adjustbox}
\vspace{-0.3cm}
\label{tab: Driving Stereo}
\end{table*}

\subsection{The effectiveness on Depth Estimation}
\textbf{KITTI-to-Driving Stereo CTTA.}
To demonstrate the effectiveness of our approach in addressing CTTA problem in depth estimation task, we conducted a series of evaluations on four distinct target domains from the Driving Stereo dataset at regular intervals during the testing phase.
As shown in Table \ref{tab: Driving Stereo}, our method consistently outperforms the state-of-the-art (SOTA) technique across all four evaluation metrics. Particularly noteworthy is the significant enhancement in the mean $\delta>1.25$, achieving a remarkable improvement of 65.9\% when compared to the Source model, and an impressive 8.6\% improvement over the previous SOTA method. This result underscores the robust continual adaptation ability of our method in the context of depth estimation.
Given that CTTA has access to the data only once, as opposed to CoTTA, our approach leverages sparse prompt to effectively adapt to the target domain, resulting in significant performance gains. 
% Unlike the VDP, our Sparse Visual Domain Prompts are positioned in areas with the large domain shift, optimizing the preservation of spatial information while effectively capturing domain-specific knowledge. 
Overall, these results show that our SVDP consistently attains superior outcomes in the depth estimation tasks.

\subsection{Ablation study}
\label{sec:4.3}
% In this subsection, we evaluate the contribution of each component in SVDP. Since the Night scenario is the most different from the cityscape scenario and has the largest domain gap, we conduct the ablation study on the Night domain. Due to the limitation of space, we demonstrate the ablation study of CTTA in appendix.
In this subsection, we evaluate the contribution of each component in our method. Since the CTTA is the most challenging and realistic scenario, we conduct the ablation study on the KITTI-to-Driving Stero CTTA. Due to the space limitations, more ablation study is shown in the supplement.
% Due to the limitation of space, we show the ablation study on other scenarios in Appendix A.

% Specifically, SVDP contains three main contribution: Sparse visual prompt~(SVP), Uncertainty-guided Prompt Placement~(UPP) and Uncertainty-guided Prompt Updating~(UPU)
\begin{table}[!tb]
\caption{\textbf{Ablation: Contribution of each component. % need to be modified lower is better
}}
\vspace{-0.3cm}
\label{ablationDAP}
\centering
\setlength\tabcolsep{4.0pt}%调列距
\renewcommand\arraystretch{1}%调行距
\begin{tabular}{c|cccc|cc}
\toprule
 & \makecell*[c]{TS} & \makecell*[c]{SVDP} & \makecell*[c]{DPP} & \makecell*[c]{DPU}  & Abs Rel$\downarrow$ & $\delta>1.25 
 \uparrow$\\\midrule
$Ex_{1}$ &  & & & &0.312& 0.093 \\ 
$Ex_{2}$& \checkmark &  & &  & 0.249& 0.503\\
$Ex_{3}$ &\checkmark  & \checkmark &  & & 0.187& 0.705\\
$Ex_{4}$  & \checkmark & \checkmark &\checkmark  &  &0.169& 0.737\\
$Ex_{5}$  & \checkmark & \checkmark & &\checkmark & 0.177& 0.723\\
$Ex_{6}$ & \checkmark &  \checkmark &\checkmark  &\checkmark & 0.162& 0.752\\
\bottomrule
\end{tabular}
\vspace{-0.42cm}
\label{tab:ablation}
\end{table}
\textbf{Effectiveness of each component.} 
As presented in Tab.~\ref{tab:ablation} $Ex_{2}$, 
Teacher-student~(TS) structure is a common technique in CTTA \cite{Wangetal2022, gan2022decorate}, which is used to generate pseudo label in the target domain and only has 0.063 Abs Rel reduces without our method. This verifies the improvement of our method does not come from the usage of this prevalent scheme.
In $Ex_{3}$, by introducing sparse prompts (SVDP), we observe that the Abs Rel reduces 0.062 and $\delta>1.25$ increases 20.2\%, respectively. The result demonstrates that SVDP facilitates addressing the domain shift problem, since it can extract local target domain knowledge without damaging the original semantic information.
% The result demonstrates that SVDP can extract local target domian knowledge to address the domain shift problem, without damaging the original semantic information. 
% This leads to the model better fitting the target domain in dense prediction tasks.
As shown in $Ex_{4}$, DPP achieves further 0.018 Abs Rel reduces and 3.2\% $\delta>1.25$ improvement since the specially designed prompt placement strategy can assist SVDP in extracting target domain-specific knowledge more efficiently. 
% , which demonstrate that the specially designed prompt placement strategy can assist SVDP in extracting more target domain knowledge. 
Compared with $Ex_{3}$, DPU ($Ex_{5}$) also reduces the Abs Rel 0.01 and improves 1.8\% $\delta>1.25$, respectively. The results prove the effectiveness of DPU and show the importance of adaptively optimizing for different samples during TTA process.
$Ex_{6}$ shows the complete combination of  all components which achieves 65.9\% $\delta>1.25$ improvement and 0.150 Abs Rel reduction in total. It proves that all components compensate each other and jointly address the depth estimation domain shift problem in test time.



\textbf{How does the prompt sparsity affect the performance?}
As shown in Fig .\ref{fig:exp_prompt_sparsity}, we investigate the performance impact caused by the sparsity of SVDP.  Specifically, we gradually increase the density of SVDP pixel-wise parameters and place it into more pixel. We find that $\delta>1.25$ initially improves along with increasing SVDP density and then starts to decrease when the density exceeds 1e-3.
This observation suggests that when SVDP is excessively sparse, it fails to capture the domain-specific knowledge effectively due to the limited number of parameters. In contrast, if the SVDP becomes too dense, the prompt will occlude many spatial details, leading to depth estimation performance degradation.
Therefore, it is crucial to strike a balance on the degree of prompt sparsity and we consider that SVDP can achieve optimal potential in 1e-3 sparsity.



\begin{figure}[t]
\includegraphics[width=0.48\textwidth]{./images/fig6_sparsity_V5.pdf}
\centering
\vspace{-0.6cm}
\caption{Effect of prompts' sparsity}
\label{fig:exp_prompt_sparsity}
\vspace{-0.3cm}
\end{figure}


\section{Conclusion and discussion of limitations}
In this paper, we are the first to introduce the Sparse Visual Domain Prompt (SVDP) in dense prediction TTA tasks, which address the problem of inaccurate contextual information extraction and insufficient domain-specific feature transferring caused by dense prompt occlusion. Moreover, the Domain Prompt Placement (DPP) and Domain Prompt Updating (DPU) strategies are specially designed for applying SVDP to ease the domain shift better. Extensive experiments on multiple TTA and CTTA scenarios demonstrate that our method achieves SOTA performance and efficiently tackles the domain shift. For limitations, the teacher-student framework brings more computational costs during SVDP tuning. However, the forward time and computational costs are the same as the baseline in testing.


