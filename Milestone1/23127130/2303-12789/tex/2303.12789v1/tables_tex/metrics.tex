\begin{table}
    \begin{center}
        \centering
        \scriptsize{
        \begin{tabular}{l|c|c}
            \toprule 
             & \scriptsize{CLIP Text-Image} & \scriptsize{CLIP Direction}\\ & \scriptsize{Direction Similarity} $\uparrow$ & \scriptsize{Consistency} $\uparrow$ \\ \midrule
             Per-frame IP2P~\cite{brooks2022instructpix2pix} & \textbf{0.1603} & 0.8185 \\
             One-time DU & 0.1157 & 0.8823 \\
             %IDU w/ SD~\cite{rombach2022high} & 0.0423 & 0.9371 \\
             SDS w/ IP2P~\cite{brooks2022instructpix2pix} & 0.0266 & \textit{0.9160} \\
             Ours & \textit{0.1600} & \textbf{0.9191}\\
             \bottomrule
        \end{tabular}
        }
    \end{center}
    \caption{\textbf{Quantiative Evaluation.}
Although edits are subjective, we provide quantitative metrics that evaluate the alignment of the edits to the text and consistency between subsequent frames in the CLIP space. Our approach results in similar CLIP similarity as per-frame edit, while achieving best consistency in CLIP space.
%per-frame\ak{is it? fix this} consistency in the CLIP space. Our approach is..\todo{fill} (we need to explain why we don't have the best clip score or the best consistency score, but why being great at both is what you want)
    }
    \label{tab:metrics}
\end{table}