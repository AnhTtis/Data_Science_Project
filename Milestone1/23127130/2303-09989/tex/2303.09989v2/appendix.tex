\section{Appendix}

In this Appendix, we describe optimization procedures in detail, give additional detailed results and describe the open world data sets in detail. Furthermore, we give proof for \autoref{prop:main}.




\subsection{Detailed Qualitative Results}
\begin{figure}
     \centering
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.7\textwidth]{figures_appendix/pacs_low_scores_0_knn.png}
         \caption{Lowest scores  Art.}
     \end{subfigure}
     \begin{subfigure}[b]{0.4
\textwidth}
         \centering
         \includegraphics[width=0.7\textwidth]{figures_appendix/pacs_high_scores_0_knn.png}
         \caption{Highest scores Art.}
     \end{subfigure}%

     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.7\textwidth]{figures_appendix/pacs_low_scores_1_knn.png}
         \caption{Lowest scores Cartoon.}
     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.7\textwidth]{figures_appendix/pacs_high_scores_1_knn.png}
         \caption{Highest scores Cartoon.}
     \end{subfigure}
     \caption{Images with highest and lowest scores for different domains on PACS. Scores are computed with Deep-KNN on ERM.}
        \label{fig:all_low_high_scores_1}
\end{figure}

\begin{figure}
     \centering
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.7\textwidth]{figures_appendix/pacs_low_scores_2_knn.png}
         \caption{Lowest scores Photography.}
     \end{subfigure}
     \begin{subfigure}[b]{0.4
\textwidth}
         \centering
         \includegraphics[width=0.7\textwidth]{figures_appendix/pacs_high_scores_2_knn.png}
         \caption{Highest scores Photography.}
     \end{subfigure}

     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.7\textwidth]{figures_appendix/pacs_low_scores_3_knn.png}
         \caption{Lowest scores Sketch.}
     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.7\textwidth]{figures_appendix/pacs_high_scores_3_knn.png}
         \caption{Highest scores Sketch.}
     \end{subfigure}
     \caption{Images with highest and lowest scores for different domains on PACS. Scores are computed with Deep-KNN on ERM.}
        \label{fig:all_low_high_scores_2}
\end{figure}


\autoref{fig:all_low_high_scores_1} and \autoref{fig:all_low_high_scores_2} show for the PACS data set the three images attaining the highest and the lowest incompetence scores per class respectively. Images with lower scores achieve higher accuracy compared to the highest-scored images. 

\subsection{Detailed Quantitative Results - Dependence on Competence Threshold}
\label{app:dependence_threshold}

We show the accuracy on OOD test data in dependence on the competence threshold $\alpha$ for the DG data sets PACS, OfficeHome, VLCS, TerraIncognita, DomainNet and SVIRO in \autoref{fig:competence_curve_pacs}, \autoref{fig:competence_curve_office_home}, \autoref{fig:competence_curve_vlcs}, \autoref{fig:competence_curve_terra}, \autoref{fig:competence_curve_domain_net} and \autoref{fig:competence_curve_sviro} respectively. We only show results for Deep-KNN, Logit, ViM and GMM
applied on the ERM classifier. For Deep-KNN, Logit, and Vim we see in almost all cases the monotonic behavior as predicted in \autoref{prop:main}. On the DG data sets VLCS, DomainNet and  TerraIncognita the GMM score fails to show this monotonic behavior for some test domains. Therefore, GMM has not the monotonic behavior we would expect from an admissible incompetence score. For some domains, all scores do not behave as we aimed for. For instance, in the LabelMe test domain in VLCS (see \autoref{fig:competence_curve_vlcs}) we cannot achieve the ID accuracy for all thresholds $\alpha$ and all incompetence scores. While this behavior is extremely rare in our experiments (for the feature- and logit-based scores), it shows that the current competence scores can fail for some domain shifts.
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures_appendix/accuracy_curves/safe_curves_ERM_PACS.pdf}
    \caption{The accuracy of the ERM classifier on OOD data $\mathrm A_{\operatorname{OOD}}(\alpha)$ as the competence region is enlarged by increasing the allowed incompetence $\alpha$. Here we show the results for all DG tasks of the PACS data set.}
    \label{fig:competence_curve_pacs}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures_appendix/accuracy_curves/safe_curves_ERM_OfficeHome.pdf}
    \caption{The accuracy of the ERM classifier on OOD data $\mathrm A_{\operatorname{OOD}}(\alpha)$ as the competence region is enlarged by increasing the allowed incompetence $\alpha$. Here we show the results for all DG tasks of the OfficeHome data set.}
    \label{fig:competence_curve_office_home}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures_appendix/accuracy_curves/safe_curves_ERM_VLCS.pdf}
    \caption{The accuracy of the ERM classifier on OOD data $\mathrm A_{\operatorname{OOD}}(\alpha)$ as the competence region is enlarged by increasing the allowed incompetence $\alpha$. Here we show the results for all DG tasks of the VLCS data set.}
    \label{fig:competence_curve_vlcs}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures_appendix/accuracy_curves/safe_curves_ERM_TerraIncognita.pdf}
    \caption{The accuracy of the ERM classifier on OOD data $\mathrm A_{\operatorname{OOD}}(\alpha)$ as the competence region is enlarged by increasing the allowed incompetence $\alpha$. Here we show the results for all DG tasks of the TerraIncognita data set.}
    \label{fig:competence_curve_terra}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures_appendix/accuracy_curves/safe_curves_ERM_DomainNet.pdf}
    \caption{The accuracy of the ERM classifier on OOD data $\mathrm A_{\operatorname{OOD}}(\alpha)$ as the competence region is enlarged by increasing the allowed incompetence $\alpha$. Here we show the results for all DG tasks of the DomainNet data set.}
    \label{fig:competence_curve_domain_net}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.58\textwidth]{figures_appendix/accuracy_curves/safe_curves_ERM_SVIRO.pdf}
    \caption{The accuracy of the ERM classifier on OOD data $\mathrm A_{\operatorname{OOD}}(\alpha)$ as the competence region is enlarged by increasing the allowed incompetence $\alpha$. Here we show the results for all DG tasks of the SVIRO data set.}
    \label{fig:competence_curve_sviro}
\end{figure}

\addJM{
In \autoref{fig:percentile_line_plot} we also show results for different thresholds according to their percentile in the ID distribution. We can see that the relative performance of the scores stays considerably stable. }

\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{figures_appendix/percentile_plot.pdf}
    \caption{\addJM{Median of accuracies in competence region for different thresholds (percentiles of ID distribution ) over all domain roles and classifiers.}}
    \label{fig:percentile_line_plot}
\end{figure}



\subsection{Detailed Quantitatively Results -- Extensive Study}

\label{app:detailed_results}
In \autoref{tab:four_domains_details}, \autoref{tab:domainnet_results} and \autoref{tab:sviro_details} we give detailed results for all DG data sets considered in this work: PACS, VLCS, OfficeHome, TerraIncognita, DomainNet, and SVIRO. We list the accuracies in the competence region where the incompetence threshold is chosen as the 95\% percentile of the ID validation set. Here we show the median, the 5\% and 95\% percentiles over all test domains and classifiers. We can see that the deviations between different test domains are quite severe indicating different strengths of domain shifts across the DG tasks. The main observations in \autoref{sec:extensive_results} (e.g. the OOD-gain is quite significant and feature-based methods [ViM; Deep-KNN] are very successfull) hold across the different DG tasks.


\begin{table*}[tbh]
    \begin{center}
    \resizebox{\textwidth}{!}{\input{appendix_results/four_datasets_domains_results.tex}}
    \end{center}
    \caption{Accuracy on competence region of OOD domain for different \textit{PACS}, \textit{OfficeHome}, \textit{VLCS} and \textit{TerraIncognita} domains and incompetence scores. As the threshold for the competence regions, we choose the 95\% percentile of the ID validation set.  
    For all metrics, a higher value means better performance ($\uparrow$). All displayed values are medians over different domain roles and classifiers, brackets indicate 90\% confidence interval.}
    \label{tab:four_domains_details}
\end{table*}


\begin{table*}[tbh]
    \begin{center}
    \resizebox{\textwidth}{!}{\input{appendix_results/domainbed_results.tex}}
    \end{center}
    \caption{Accuracy on competence region of OOD domain for different DomainNet domains and incompetence scores. As the threshold for the competence regions, we choose the 95\% percentile of the ID validation set.  
    For all metrics, a higher value means better performance ($\uparrow$). All displayed values are medians over different domain roles and classifiers, brackets indicate 90\% confidence interval.}
    \label{tab:domainnet_results}
\end{table*}


\begin{table*}[tbh]
    \begin{center}
    \resizebox{\textwidth}{!}{\input{appendix_results/sviro_results.tex}}
    \end{center}
    \caption{Accuracy on competence region of OOD domain for different SVIRO domains and incompetence scores. As the threshold for the competence regions, we choose the 95\% percentile of the ID validation set.  
    For all metrics, a higher value means better performance ($\uparrow$). All displayed values are medians over different domain roles and classifiers, brackets indicate 90\% confidence interval.}
    \label{tab:sviro_details}
\end{table*}






\subsection{Open World Setting}
\label{app:open_world}




\paragraph{Open World Creation}

We use additional data to extend the closed world data sets to the open world setting. We use similar domains of other data sets with disjunct classes to generalize the DG data sets. The ID data sets and the open world extensions are listed in \autoref{tab:appOWdata}. We show examples of test data (closed world) and open world samples for all DG data sets. For PACS (in \autoref{fig:open_world_pacs}) for VLCS (in \autoref{fig:open_world_vlcs}), for OfficeHome (in \autoref{fig:open_world_officehome}) and for TerraIncognita (in \autoref{fig:open_world_terraincognita})

\begin{table*}[tbh]%
    \centering
    \resizebox{0.95\textwidth}{!}{
    \begin{tabular}{|l|c|c|c|}
        \hline
        ID data set & Open world data set& Test domain $\to$ Open world domains& Open world classes\\
        \hline
        \hline
        PACS&DomainNet&\makecell{art $\to$ painting \\ cartoon $\to$ clipart \\ photo $\to$ photo \\ sketch $\to$ sketch}& \makecell{alarm clock, ambulance, apple,\\ backpack, baseball, basketball,\\ bat, bear,bed and bicyle} \\
        \hline
        VLCS&PACS&all environments $\to$  photo & elephant, giraffe and guitar\\
        \hline
        OfficeHome&DomainNet&  \makecell{art $\to$ paint \\ clipart $\to$ clipart \\ product $\to$ real \\ real world $\to$ real}& bread, butterfly, cake, carrot, cat\\
        \hline
        TerraIncognita&PACS&all enviroments $\to$ photo& elephant, giraffe and horse\\
        \hline
    \end{tabular}
    }
    \caption{Open world extensions of different DG data sets and their test domains.}
    \label{tab:appOWdata}
\end{table*}

\paragraph{Open World Results}
\autoref{fig:app_acc_boxplot} shows the ID-Gain and OOD-Gain for all incompetence scores considered in this work depending on the fraction of open world samples. We see that ViM and Deep-KNN are particularly able to delineate unknown class instances from known class instances resulting in an improved ID- and OOD-Gain across all open world fractions. 

In \autoref{fig:app_auroc} we investigate the behavior of different scores in detail. It shows the AUROC of delineating ID data vs. correctly classified samples of the test domain, ID data vs. wrongly classified samples of the test domain, and ID data vs. unknown class instances in general. Here we consider an unknown test domain where 25\% of all samples are open world outliers. We see an interesting behavior here: ViM and Deep-KNN are well-able to filter out wrongly classified samples, but also filter out many correctly classified samples. The logit-based scores (Logit, Softmax, Energy, Energy-React) are less successful in filtering out wrongly classified samples, but also keep more correctly classified samples. In the optimal case, we would expect that the AUROC of ID vs. correct test data is $\le 0.5$ and the AUROC of ID vs. false OOD data is 1. This would imply that we could successfully filter out wrongly predicted samples and keep a high coverage. \autoref{fig:app_auroc} shows that ViM and Deep-KNN are capable of filtering out new class instances across all DG data sets. For all other scores, we can find data sets where this behavior is not achieved. Consequently, ViM and Deep-KNN work best when unknown class instances occur.


\begin{figure}
     \centering
     \begin{subfigure}[b]{1.\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures_appendix/app_acc_boxplots_id.pdf}
     \end{subfigure}
     \begin{subfigure}[b]{1.\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures_appendix/app_acc_boxplots_ood.pdf}
     \end{subfigure}
    \caption{\textit{OOD-Gain} and \textit{ID-Gain} for different incompetence score for an increasing fraction of open world data (unknown classes) in the test domain (higher is better).}
    \label{fig:app_acc_boxplot}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures_appendix/app_auroc.pdf}
    \caption{\textit{Above:} AUROC of delineating ID data vs. correctly classified samples on the OOD data. \textit{Middle:} AUROC of delineating  ID data vs. wrongly classified samples on the OOD data. \textit{Below:} AUROC of delineating ID data vs. open world data in general. All test domains are enriched with 25\% open world outliers.}
    \label{fig:app_auroc}
\end{figure}

\subsection{Training Details and Classifiers}
\label{app:training}

%\paragraph{Training Details}
All classifiers are trained using the DomainBed repository \footnote{\url{https://github.com/facebookresearch/DomainBed}}. 
We train three different neural network architectures with Emprirical-Risk-Minimization, shortly ERM \citep{vapnik1999overview}. Namely, a ResNet based architecture \citep{he2016deep}, a Vision Transformer \citep{dosovitskiy2020image} and a  Swin Transformer \citep{liu2021swin}. If we just refer to ERM, we mean the ResNet-based architecture. 
Furthermore, we train classifiers with various recent DG algorithms, namely Fish \citep{shi2021gradient}, GroupDRO \citep{sagawa2019distributionally}, SD \citep{pezeshki2021gradient}, SagNet \citep{nam2021reducing}, Mixup \citep{yan2020improve} and VREx \citep{krueger2021out}. 

We use all the standard settings provided in the DomainBed repository and train all classifiers with hyperparameters proposed in the repository. The Vision Transformer and SwinTransformer are trained with hyperparameters found useful on these data sets and architectures as in \citep{wenzel2022assaying}. Each model is trained for 100 epochs on the smaller data sets (PACS, VLCS, TerraIncognita and OfficeHome) and for 10 epochs on DomainNet and SVIRO. When no improvement in terms of accuracy on the validation set is achieved, we stop the training. The best model is chosen due to the accuracy on the ID distribution measured via the accuracy on the validation set.


Some scores are computed on the logits and some on the features. 
If computed on the features, we use the output of the penultimate layer of the model as input to the score function. 

We distinguish between training, validation, and test set of the ID distribution. For the OOD distribution we only consider one data set provided by the DG task which is not seen during training. Score quantiles are always computed on the ID validation set. The ID accuracy is computed on the ID test data set. If score functions need optimization (as with GMM), we train them on the ID training set. If a score function needs optimization, we restrict the training set to 50 000 samples. This only affects the DomainNet data set. We do only little to no optimization of the parameters of the score functions. We mainly stay in line with the standard settings found in the literature. For Deep-KNN we choose $K=1$ because it shows slightly improved performance on the ID distribution (only inspected on PACS).

%\paragraph{Classifiers}
\subsection{Trained Classifiers}
\label{app:classifiers_trained}

\autoref{fig:app_accuracy} shows the accuracies of all different Classifiers on all DG data sets for the ID data and the OOD data. Here we show the means and standard deviations over the different domains.  All classifiers obtain a similar ID and OOD accuracy. One exception is VREx which did not converge for all domains on DomainNet. 
\addJM{In \autoref{fig:app_accuracy_box} we show the accuracies for the different DG methods on all data sets. }

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{figures_appendix/acc_box_plots.pdf}
    \caption{Accuracies for different classifiers on OOD test data. The boxes show the quartiles and medians.}
    \label{fig:app_accuracy_box}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{figures_appendix/app_acccuracy2.pdf}
    \caption{Accuracies for different classifiers on ID and OOD test data. We show the means and standard deviations over different DG tasks.}
    \label{fig:app_accuracy}
\end{figure}

\vspace*{-1em}

\subsection{Proof of Proposition 3.1}
\label{app:proof}

\vspace*{-0.8em}

\begin{proof}
\begin{enumerate}
\item[(b)] Take the limit $X_C(\alpha) \xrightarrow{\alpha \to \infty} \mathbb R^D$. Then there is no restriction of the support of $p_{\operatorname{OOD}}$, so the accuracy for large $\alpha$ approaches the accuracy on the entire OOD data set.

\item[(a)]
    By assumption $p_{\operatorname{ID}}$ and $p_{\operatorname{OOD}}$ share their support when restricted to the competence region $X_C(\alpha)$ when $\alpha \leq \alpha^*$. Thus we can always assume that $p_{\operatorname{OOD}}(X_C(\alpha)) > 0$ for all $\alpha \geq \min_{x \in \operatorname{supp}(P_{\operatorname{ID}})} s_c(x) =: \alpha_0$, which makes the accuracy well-defined for all relevant $\alpha \geq \alpha_0$:
    \begin{align}
        A_{\operatorname{OOD}}(\alpha) = \frac{P_{\operatorname{OOD}}(X_C(\alpha), c(X) = Y_{\text{true}})}{P_{\operatorname{OOD}}(X_C(\alpha))}.
    \end{align}
    Here, $Y_{\text{true}}$ is the correct label to the input $X$.

    For the remainder, we consider $\alpha \in [\alpha_0, \alpha^*]$, so $A_{\operatorname{OOD}}(\alpha) = A_{\operatorname{ID}}(\alpha)$.

    Then, we have that $A_{\operatorname{OOD}}(\alpha) = A_{\operatorname{ID}}(\alpha) \geq \lim_{\alpha \to \infty} A_{\operatorname{ID}}(\alpha) = A_{\operatorname{ID}}$. The limit can be taken analogously to the proof of (b) above.
\end{enumerate}
\end{proof}



\begin{figure}
     \centering
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/PACS_env_0.pdf}
         \caption{Test data for domain Art}
     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/PACS_env_0_open.pdf}
         \caption{Open world data for domain Art}
     \end{subfigure}

     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/PACS_env_1.pdf}
         \caption{Test data for domain Cartoon}
     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/PACS_env_1_open.pdf}
         \caption{Open world data for domain Cartoon.}
     \end{subfigure}

         \centering
  \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/PACS_env_2.pdf}
         \caption{Test data from domain Photo.}

     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/PACS_env_2_open.pdf}
         \caption{Open world data for domain Photo.}
     \end{subfigure}
     
  \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/PACS_env_3.pdf}
         \caption{Test data from domain Sketch.}

     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/PACS_env_3_open.pdf}
         \caption{Open world data for domain Sketch.}
     \end{subfigure}

     \caption{Test (left) and open world data (right) for the PACS data set.} %
     \label{fig:open_world_pacs}
\end{figure}

\begin{figure}[ht]
         \centering
  \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/VLCS_env_0.pdf}
         \caption{Test data from domain Cal101.}

     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/VLCS_env_0_open.pdf}
         \caption{Open world data for domain Cal101.}
     \end{subfigure}
     
  \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/VLCS_env_1.pdf}
         \caption{Test data from domain LabelMe.}

     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/VLCS_env_1_open.pdf}
         \caption{Open world data for domain LabelMe.}
     \end{subfigure}

     \label{fig:open_world_vlcs_1}

         \centering
  \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/VLCS_env_2.pdf}
         \caption{Test data from domain SUN09.}

     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/VLCS_env_2_open.pdf}
         \caption{Open world data for domain SUN09.}
     \end{subfigure}
     
  \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/VLCS_env_3.pdf}
         \caption{Test data from domain VOC2007.}

     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/VLCS_env_3_open.pdf}
         \caption{Open world data for domain VOC2007.}
     \end{subfigure}

     \caption{Test (left) and open world data (right) for the VLCS data set.} %
     \label{fig:open_world_vlcs}
\end{figure}

\begin{figure}[ht]
         \centering
  \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/OfficeHome_env_0.pdf}
         \caption{Test data from domain Art.}

     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/OfficeHome_env_0_open.pdf}
         \caption{Open world data for domain Art.}
     \end{subfigure}
     
  \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/OfficeHome_env_1.pdf}
         \caption{Test data from domain Clipart.}

     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/OfficeHome_env_1_open.pdf}
         \caption{Open world data for domain Clipart.}
     \end{subfigure}



         \centering
  \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/OfficeHome_env_2.pdf}
         \caption{Test data from domain Product.}

     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/OfficeHome_env_2_open.pdf}
         \caption{Open world data for domain Product.}
     \end{subfigure}
     
  \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/OfficeHome_env_3.pdf}
         \caption{Test data from domain Real World.}

     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/OfficeHome_env_3_open.pdf}
         \caption{Open world data for domain Real World.}
     \end{subfigure}

     \caption{Test (left) and open world data (right) for the OfficeHome data set.} %
     \label{fig:open_world_officehome}
\end{figure}

\begin{figure}[ht]
         \centering
  \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/TerraIncognita_env_0.pdf}
         \caption{Test data from domain L100.}

     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/TerraIncognita_env_0_open.pdf}
         \caption{Open world data for domain L100.}
     \end{subfigure}
     
  \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/TerraIncognita_env_1.pdf}
         \caption{Test data from domain L38.}

     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/TerraIncognita_env_1_open.pdf}
         \caption{Open world data for domain L38.}
     \end{subfigure}


         \centering
  \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/TerraIncognita_env_2.pdf}
         \caption{Test data from domain L43.}
     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/TerraIncognita_env_2_open.pdf}
         \caption{Open world data for domain L43.}
     \end{subfigure}
     
  \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/TerraIncognita_env_3.pdf}
         \caption{Test data from domain L46.}
     \end{subfigure}
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.74\textwidth]{figures_appendix/TerraIncognita_env_3_open.pdf}
         \caption{Open world data for domain L46.}
     \end{subfigure}
     \caption{Test (left) and open world data (right) for the TerraIncognita data set.} %
     \label{fig:open_world_terraincognita}
\end{figure}

