\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate]{lipics-v2021}

\pdfoutput=1 %
\hideLIPIcs  %

\usepackage{lucas}
\lstset{
  basicstyle=\ttfamily,
  mathescape
}
\usepackage{svg}
\usepackage{csvsimple} 
\usepackage[textsize=tiny]{todonotes}
\usepackage{csquotes}
\usepackage{nicematrix}
\usepackage[binary-units=true]{siunitx}
\usepackage{booktabs}

\newtheorem{myexample}[theorem]{Example}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{patterns}
\newcommand{\LO}{{\fontfamily{qcr}\selectfont LightsOut}}
\def\hexagonsize{0.4cm}
\def\hexconst{0.866025}
\pgfdeclarepatternformonly
  {hexagons}%
  {\pgfpointorigin}%
  {\pgfpoint{3*\hexagonsize}{\hexconst*2*\hexagonsize}}%
  {\pgfpoint{3*\hexagonsize}{\hexconst*2*\hexagonsize}}%
  {%
   \pgfsetlinewidth{0.4pt}
   \pgftransformshift{\pgfpoint{0mm}{\hexconst*\hexagonsize}}
   \pgfpathmoveto{\pgfpoint{0mm}{0mm}}
   \pgfpathlineto{\pgfpoint{0.5*\hexagonsize}{0mm}}
   \pgfpathlineto{\pgfpoint{\hexagonsize}{-\hexconst*\hexagonsize}}
   \pgfpathlineto{\pgfpoint{2*\hexagonsize}{-\hexconst*\hexagonsize}}
   \pgfpathlineto{\pgfpoint{2.5*\hexagonsize}{0mm}}
   \pgfpathlineto{\pgfpoint{3*\hexagonsize+0.2mm}{0mm}}
   \pgfpathmoveto{\pgfpoint{0.5*\hexagonsize}{0mm}}
   \pgfpathlineto{\pgfpoint{\hexagonsize}{\hexconst*\hexagonsize}}
   \pgfpathlineto{\pgfpoint{2*\hexagonsize}{\hexconst*\hexagonsize}}
   \pgfpathlineto{\pgfpoint{2.5*\hexagonsize}{0mm}}
   \pgfusepath{stroke}
  }
\bibliographystyle{plainurl}%
\tikzset{
    buffer/.style={
        draw,
        shape border rotate=0,
        regular polygon,
        regular polygon sides=3,
        node distance=2cm,
        minimum height=40em
    }
}

\title{Decoding quantum color codes with MaxSAT}

\author{Lucas Berent}{Technical University of Munich, Germany}{lucas.berent@tum.de}{https://orcid.org/0000-0002-2973-1689}{}

\author{Lukas Burgholzer}{Johannes Kepler University Linz, Austria}{lukas.burgholzer@jku.at}{https://orcid.org/0000-0003-4699-1316}{}

\author{Peter-Jan H.~S. Derks}{Freie Universit{\"a}t Berlin, Germany}{peter-janderks@hotmail.com}{https://orcid.org/0000-0002-9197-1309}{}

\author{Jens Eisert}{Freie Universit{\"a}t Berlin, Germany \and Helmholtz-Zentrum Berlin f{\"u}r Materialien und Energie, Germany}
{jense@zedat.fu-berlin.de}{https://orcid.org/0000-0003-3033-1292}{}
\author{Robert Wille}{Technical University of Munich, Germany \and Software Competence Center Hagenberg GmbH (SCCH), Austria}{robert.wille@tum.de}{https://orcid.org/0000-0002-4993-7860}{}

\authorrunning{L. Berent, L. Burgholzer, P.J. Derks, J. Eisert and R. Wille} %

\Copyright{Lucas Berent, Lukas Burgholzer, Peter-Jan H.S. Derks, and Robert Wille} %

\begin{CCSXML}
<ccs2012>
    <concept_id>10010583.10010786.10010813.10011726.10011728</concept_id>
        <concept_desc>Hardware~Quantum error correction and fault tolerance</concept_desc>
        <concept_significance>500</concept_significance>
    </concept>
   <concept>
       <concept_id>10010583.10010682</concept_id>
       <concept_desc>Hardware~Electronic design automation</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010583.10010786.10010813.10011726</concept_id>
       <concept_desc>Hardware~Quantum computation</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
<concept>


 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Hardware~Electronic design automation}
\ccsdesc[500]{Hardware~Quantum computation}

\keywords{MaxSAT, Quantum Computing, Quantum Error Correction} 
\category{} %

\relatedversion{} %
\supplement{\emph{Source Code:} \href{https://github.com/cda-tum/qecc}{\url{https://github.com/cda-tum/qecc}}\\
\emph{Numerical data:} \href{https://doi.org/10.5281/zenodo.7760135}{\url{https://doi.org/10.5281/zenodo.7760135}}}
 \funding{L.~B., L.~B., and R.~W. acknowledge funding from the European Research Council (ERC) under the European Unionâ€™s Horizon 2020 research and innovation program (grant agreement No. $101001318$) as well as support by the BMWK on the basis of a decision by the German Bundestag through project QuaST. P.~J.~D. and J.~E. acknowledge funding from BMBF (RealistiQ, QSolid) and the DFG (CRC 183).
This work has been conducted within the framework of the Munich Quantum Valley, which is supported by the Bavarian state government with funds from the Hightech Agenda Bayern Plus, for which this is a joint-node project.}

\acknowledgements{The authors thank Craig Gidney for fruitful discussions on the MaxSAT decoder and for pointing out the possible \LO{} analogy.}

\nolinenumbers %

\EventEditors{John Q. Open and Joan R. Access}
\EventNoEds{2}
\EventLongTitle{42nd Conference on Very Important Topics (CVIT 2016)}
\EventShortTitle{CVIT 2016}
\EventAcronym{CVIT}
\EventYear{2016}
\EventDate{December 24--27, 2016}
\EventLocation{Little Whinging, United Kingdom}
\EventLogo{}
\SeriesVolume{42}
\ArticleNo{23}

\begin{document}

\maketitle

\begin{abstract}
In classical computing, error-correcting codes are well established and are ubiquitous both in theory and practical applications. For quantum computing, error-correction is essential as well, but harder to realize, coming along with substantial resource overheads and being concomitant with needs for substantial classical computing. Quantum error-correcting codes play a central role on the avenue towards fault-tolerant quantum computation beyond presumed near-term applications. Among those, color codes constitute a particularly important class of quantum codes that have gained interest in recent years due to favourable properties over other codes. As in classical computing, \emph{decoding} is the problem of inferring an operation to restore an uncorrupted state from a corrupted one and is central in the development of fault-tolerant quantum devices. In this work, we show how the decoding problem for color codes can be reduced to a slight variation of the well-known \LO{} puzzle. We propose a novel decoder for quantum color codes using a formulation as a MaxSAT problem based on this analogy. Furthermore, we optimize the MaxSAT construction and show numerically that the decoding performance of the proposed decoder achieves state-of-the-art decoding performance on color codes. The implementation of the decoder as well as tools to automatically conduct numerical experiments are publicly available as part of the \emph{Munich Quantum Toolkit} (MQT) on GitHub. 
\end{abstract}

\section{Introduction}
In classical computing, error-correcting codes are ubiquitous
both in theory and practical applications. The main idea is to add redundancy to data that needs to be protected from errors in order to tolerate noise and enable the correction of errors. A famous class of codes are so-called linear codes, which are defined as a vector space that allows to encode $k$ \emph{logical} bits (that hold the information) into $n$ \emph{physical} bits, where $n>k$. The simplest form of an error-correcting code is the $n$-repetition code, which encodes $0\mapsto 000$ and $1 \mapsto 111$ (for $n=3$). In quantum computing~\cite{nielsen2002quantum}, a similar need for error-correction exists: 
qubits are fragile in nature and experience decoherence over time. Moreover, operations on qubits are imperfect and thus introduce additional errors. As a consequence, running a quantum algorithm consisting of thousands of operations on such a noisy machine produces results that are almost completely random. Thus, to realize large-scale quantum computers, it is necessary to protect quantum systems from inevitable noise occurring during computation. 


To overcome this issue of noise, \emph{quantum error-correction} (QEC) and -- building upon this, allowing each step to be imperfect -- \emph{fault-tolerance} (FT) will ultimately be needed. The general idea---similar to classical coding theory---is to use \emph{quantum error-correcting codes} (QECCs) to encode quantum information by using additional, redundant information. However, due to the laws of quantum physics, for instance, the famous \emph{no-cloning theorem}, naive mechanisms such as copying quantum data are not possible. In order to conduct computations on encoded data, referred to as the \emph{logical information}, universal sets of noise-resilient quantum operations need to be designed, which is the goal of research in quantum fault-tolerance~\cite{preskill1998reliable, shor1996fault}. 

The general idea behind QEC is to conduct specific measurements on the (possibly corrupted) encoded information without destroying the encoded logical information, which allows to infer whether an error occurred and approximately ``where'' this error occurred, while acquiring no information whatsoever about
the logical information encoded, which would corrupt the
precious quantum information. Given this classical information, the aim is to derive a \emph{recovery operation} that, when applied to the corrupted state, restores the encoded information to an uncorrupted state. The process of inferring such a recovery operation is called \emph{decoding} and is highly non-trivial---as in classical coding theory. In fact,
notions of decoding are moving much to the centre of the discussion of
quantum error correction. This for good reason, as the classical
software needs to keep up with the time scales of the
quantum noise and has to offer correction steps in real-time while the noise is acting onto the system. For this reason, decoders must not only have high decoding performance, but also be fast.

An important class of quantum codes is constituted by \emph{Calderbank-Shor-Steane} (CSS) codes~\cite{calderbank1996good, steane1996error}, which can be defined as a suitable combination of two classical linear codes. Out of CSS codes, \emph{planar color codes}~\cite{bombin2006topological,kesselring2022anyon, kubica2018abcs,thomsen2022low} form an essential class. They are defined on a two-dimensional lattice that is required to be three-valent and three-colourable with respect to its faces. There are various properties such as lower resource requirements, or the realization of logical operations that render color codes favourable over the currently widely researched \emph{surface code}~\cite{kitaev2003fault, krinner2022realizing, google2023suppressing}. Moreover, there have been first advances of physical implementations of FT-quantum computation with small instances of color codes~\cite{postler2022demonstration, ryan2021realization}. 
One of the central open problems towards FT is scalable, accurate and fast decoding. After all, in any real implementation, decoding has to be faster than the quantum noise can 
compromise the coherence of the
quantum information stored.

\pagebreak
In this work, we show that the decoding problem can be formulated as a slight variation of the well-known \LO{}-puzzle. \LO{} is a famous combinatorial puzzle and has various connections to linear algebra and graph theory. Based on this analogy, we propose a MaxSAT encoding that allows to determine minimal solutions to the underlying problem. By this, we aim to bridge the gap between powerful classical constraint satisfaction solving approaches and quantum computing and thereby inspire new research in this direction.

Numerical evaluations of the resulting MaxSAT decoder for color codes show that it achieves near-optimal decoding performance for the considered noise model (bit-flip errors with noiseless syndrome measurements). It outperforms all color code decoders in terms of accuracy, except the tensor network decoder \cite{chubb2021general}, which it outperforms in run-time. \autoref{fig:decoder_comparison} shows a classification of color code decoders. To achieve these results, we improved the performance as well as the re-usability of the proposed encoding by carefully optimizing all constraints. Moreover, we compared the run-time of different MaxSAT solvers for the proposed satisfiability encoding. The results show that the implementation with Z3 outperforms other solvers.
\begin{figure}
    \centering    
    \includegraphics[width=\textwidth]{decoder_comparison.pdf}
    \caption{Abstract comparison of the decoding accuracy and run-time of several color code decoders. This figure is inspired by a figure comparing surface code decoders in Ref.~\cite{NewmanTalk}.}
    \label{fig:decoder_comparison}
\end{figure}
Finally, both the implementation of the proposed decoder and means to conduct numerical simulations are provided as an open-source Python package as part of the \emph{Munich Quantum Toolkit} (MQT) at
\url{www.github.com/cda-tum/qecc}. 

The remainder of this work is structured as follows. In ~\autoref{sec:background}, a high-level overview on quantum color codes is given to provide some background on quantum CSS codes. Then, in~\autoref{sec:overview} we give an overview of the main problem and discuss prior work. In~\autoref{sec:proposed-method}, the \LO{} puzzle and the analogy to color code decoding are discussed. The corresponding MaxSAT formulation is presented in~\autoref{sec:maxsat}. Then, numerical experiments and results are given in~\autoref{sec:experiments}. Finally, a summary and brief outlook on future work is presented in~\autoref{sec:conclusion}.






\section{Background}\label{sec:background} %
In this section, a brief introduction to quantum error correction and color codes is given.  For the sake of simplicity, the fundamental notions are explained in a high-level manner and we refer the reader to introductions on quantum error-correction and color codes~\cite{nielsen2002quantum, roffe2019quantum, kesselring2022anyon,kesselring2018boundaries,thomsen2022low} for more details.
A classical linear code $\calC$ that encodes $k$ logical bits into $n$ physical bits with distance $d$, written as an $[n,k,d]$-code, is defined as a $k$-dimensional vector space
\[
    \calC = \{c \in \Ftn: Hc=0\},
\]
i.e., the kernel of a matrix $H\in \Ft^{(n-k)\times n}$, called the \emph{parity-check matrix} of $\calC$. Intuitively, the rows of $H$ correspond to parity checks and a vector $c\in \Ftn$ is a \emph{codeword} iff all checks are satisfied, i.e., all checks are equal to $0$. The \emph{distance} $d$ of the code is the minimum Hamming weight of a non-zero codeword. In principle, a code with distance $d$ can correct up to $(d-1)/2$ errors.

\begin{example}\label{ex:hammingc}
Consider the parity-check matrix $$H = \left(\begin{matrix}
				1 &0 &0 &1 &0 &1 &1 \\
				0 &1 &0 &1 &1 &0 &1 \\
				0 &0 &1 &0 &1 &1 &1\\
			    \end{matrix}\right),$$ 
       which defines a $[7,4,3]$-code. The vector $x = (1,0,0,0,0,0)$ is not a codeword, since the first check $x_0 + x_3 + x_5 + x_6 \overset{?}{=} 0$ is violated, i.e., $H\cdot x = (1,0,0) \neq (0,0,0)$. 
\end{example}

A quantum CSS code is defined as a combination of two classical linear codes with parity-check matrices $H_1\in \Ft^{k\times n}$ and $H_2\in \Ft^{\ell \times n}$ that fulfill the orthogonality condition 
\[H_2^TH_1 = 0 \, (\text{or equivalently } H_1^TH_2=0).\] 
Color codes form a subclass of CSS codes that have the same $H_1$ and $H_2$-checks (i.e., they are \emph{self-dual} CSS codes). Thus, both sets of checks can be treated analogously and, for the rest of this work, only a single set of checks is considered, which is referred to as $H$.
A planar quantum color code is defined on a two-dimensional lattice that is three-valent and three-colorable with respect to its faces. Let $V$ and $F$ denote the set of vertices and faces of the lattice, respectively. The qubits are placed on the vertices $v \in V$ and checks are associated with each face of the lattice $f\in F$. Each check acts on the qubits around it, essentially computing the parity of the qubits. Besides the checks, a crucial set of operations on the code are \emph{logical operators} (which are analogous to codewords in classical coding theory). It is important to note that logical operators change the encoded information, which is vital when the decoding problem is considered. For triangular color codes, logical operators that act on the encoded information pictorially look like strings that (i) run along a side of the triangle, (ii) connect a boundary to the opposite vertex of the same color, or (iii) strings that connect all three boundaries of the triangle.
\begin{example}
    An important family of color codes is the so-called 6.6.6 triangular color code, which is defined on a hexagonal lattice with a triangular shape (with boundaries), as depicted in~\autoref{fig:tccs} (for $d=11$).
    Checks involving four or six qubits are associated with the faces of the lattice and the qubits are put on the vertices of the lattice. The checks associated with the hexagonal faces act on the qubits around the faces. A logical operator acting on 11 qubits is shown. 
\end{example}
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{cc.pdf}
    \caption{Triangular color code on a hexagonal lattice with boundaries. a) The two kinds of checks of the code, b) a logical operator of the code.\label{fig:tccs}}
\end{figure}
In general, the distance $d$ of a quantum CSS code is the minimum Hamming weight of a non-trivial logical operator. In the case of triangular color codes, for example, the distance is given as the number of qubits in a string along a side of the triangle. The overall parameters of the triangular color code are $[[(3d^2+1)/4, 1, d]]$. Hence, the distance can be increased by simply considering triangles featuring larger side lengths.
In case of an error occurring on a qubit, the checks of the adjacent faces are used to ``detect'' the error and the collection of faces that are ``triggered'' by an error is called the \emph{syndrome} of an error. Pictorically this can be depicted as highlighting the triggered faces accordingly. Thus, an error on a single qubit triggers the adjacent faces around it. 

\section{Decoding color codes}\label{sec:overview}
In this section, an overview of the considered problem and a brief review of prior work on decoding color codes is given.

\subsection{Considered problem}\label{sec:considered_problem}
In the remainder of this work, we consider the decoding problem for quantum color codes and for that, we use the  triangular color codes as a suitable representative. We focus on the bit-flip noise model, where each qubit is independently affected by an error with probability~$p$---the \emph{physical error rate}. Since each face of the lattice corresponds to a check, an error on a qubit (a vertex in the lattice) leads to a violation of adjacent checks. Note that this is a rather simple noise model. However, it is well-established for determining the principle capabilities of codes and decoders.


An error on $n$ qubits can be represented as a binary vector $e \in \Ftn$, which is simply the indicator vector for the support of the error, i.e., $e_i = 1$ iff qubit $i$ is affected by the error. The \emph{syndrome} $s = H \cdot e$ corresponds to a vector indicating the violated checks (faces on the lattice) and is used as input to the decoder. The goal of the decoding procedure is to infer an estimate $\varepsilon$ for $e$ that is consistent with the syndrome, i.e., $s = H\cdot \varepsilon$. In fact, for quantum codes it is only required to find an estimate \emph{up to stabilizer}, which means that the residual error $r = e+\varepsilon$ is in the rowspace of the parity-check matrix. Moreover, to reduce the probability of a logical error, it is required that the estimate $\varepsilon$ involves a minimal number of qubits, i.e., has minimal support.
 \begin{figure}
     \centering
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.6\linewidth]{steane-ex.pdf}
        \label{fig:cc-dec-example-a}
     \end{subfigure}
    \hfill
     \begin{subfigure}[b]{0.4\textwidth}
         \begin{align*}
            & H = \left(\begin{matrix}
				1 &0 &0 &1 &0 &1 &1 \\
				0 &1 &0 &1 &1 &0 &1 \\
				0 &0 &1 &0 &1 &1 &1\\
			    \end{matrix}\right),\\
             &e = (1,0,0,0,0,0),\\
             &s = H\cdot e = (1,0,0),\\
             &\text{Goal: find } \varepsilon \text{ such that } H \varepsilon = s.
         \end{align*}
        \label{fig:cc-dec-example-b}
     \end{subfigure}\vspace*{-2mm}
    \caption{Example of a single-qubit error on a distance-$3$ triangular color code.\label{fig:steane-ex}}
\end{figure}
\begin{example}\label{ex:steane}
    Consider again the parity-check matrix from~\autoref{ex:hammingc}. This corresponds to a parity-check matrix of a $7$-qubit triangular color code, as depicted in~\autoref{fig:steane-ex}. Assume that the qubit ordering induces index $0$ for the qubit on top of the triangle and the indices of the faces are $\mathit{blue}=0$, $\mathit{green}=1$, and $\mathit{red}=2$. A single-qubit error happens on the top-most qubit of the triangle (with index $0$), which leads to a violation of the check on the adjacent face, i.e., the corresponding face gets ``triggered'' (indicated by the blue circle). The error $e$ on the first qubit corresponds to the binary vector shown on the right-hand side of the figure. The syndrome vector $s$ then indicates that the blue face is ``triggered'' by the error. The result of all other checks is equal to $0$.
\end{example}

\subsection{Related work}\label{sec:rel-work}

Several decoders for (triangular) color codes exist to date. Apart from generic decoders for CSS codes such as the \emph{clustering algorithm union-find} (UF)~\cite{delfosse2021almost,delfosse2022toward,berent2023software}, one of the most studied algorithms (including several extensions and variations) is the projection decoder~\cite{delfosse2014decoding, kubica2018abcs, maskara2019advantages,bombin2012strong,beverland2021cost,li2018fault, stephens2014efficient}. The main idea of the projection decoder is to map the color code onto copies of surface codes 
\cite{Unfolding}
and to decode these separately using a matching-based decoder, which pairs up syndromes using the lowest-weight correction possible. Similarly, in Ref.~\cite{sahay2022decoder}, a 
\emph{minimum-weight perfect matching} approach has been applied to lattices embedded on a M\"obius strip. Other types of decoders, whose performance for the color code has been benchmarked, are \emph{neural network decoders}~\cite{maskara2019advantages} and \emph{renormalization group decoders}~\cite{sarvepalli2012efficient}.
A slightly different approach, which has been introduced in Ref.~\cite{miguel2022cellular}, makes use of a cellular automaton decoder \cite{CADecoders} for a 
variant of the color code for biased noise.

\section{LightsOut analogy}\label{sec:proposed-method}

In the following, we demonstrate how the problem of decoding color codes (under the considered noise model) can be reduced to a variation of the well-known \LO{} puzzle~\cite{gervacio2011note,anderson1998turning,amin1998parity,araujo2000turn,caro2003odd,goldwasser1997maximization,goldwasser2005parity} on the respective color code lattice.
An instance of \LO{} consists of a lattice whose faces are associated with \emph{switches} and \emph{lights} that can either be \emph{on} or \emph{off}. 
Toggling a switch on the lattice (considered a single \emph{move}) toggles all neighbouring lights, i.e., any adjacent light that was on before toggling the switch is off afterwards, and vice versa.
The goal of the puzzle is, given an initial configuration of lights, to find a sequence of moves---called a \emph{solution set}---that turns off all the lights.

\pagebreak

\begin{figure}[th]
    \centering
    \includegraphics[width=0.99\textwidth]{lo.pdf}
    \caption{\LO{} puzzle and a solution on a $3\times3$ square lattice.}
    \label{fig:lo}
\end{figure}

\begin{example}
Consider the \LO{} puzzle on a $3\times3$ square lattice as illustrated in~\autoref{fig:lo}. 
In the initial configuration (the left-most lattice), a single light, indicated as a yellow box, is turned on. 
Toggling the switch of the middle light, indicated by a green circle, turns on the middle light and all adjacent lights, while the light that was previously on is turned off.
Moving on as illustrated in the figure eventually turns off all the lights and, thus, yields a solution to the \LO{} puzzle with four moves.
\end{example}
This type of puzzle has two interesting properties~\cite{anderson1998turning}:

\begin{enumerate}
    \item Toggling a switch twice is the same as not touching it at all. As a result, each switch has to be toggled at most once for any solution to a given \LO{} puzzle.
    \item The state of a light only depends on how often the corresponding switch and its neighbors have been toggled, i.e., the order in which the switches are toggled does not matter.
\end{enumerate}

Based on these observations, it can be concluded that any solution to a \LO{} puzzle must toggle the lights that are \emph{on} in the initial configuration an \emph{odd} number of times and the lights that are initially \emph{off} an \emph{even} number of times.
The \LO{} puzzle on an $n\times m$
grid can be solved with Gaussian elimination in
polynomial time, in fact, 
in $\mathcal{O}(n^2)$ time and $\mathcal{O}(nm)$ space, where $n\leq m$ \cite{anderson1998turning}. Using this insight, one can also bound the run-time of the decoder in a polynomial fashion. For general graphs finding a minimum-weight solution to the \LO{} puzzle is NP-hard \cite{berman2021lights}.

\begin{figure}
    \centering
    \includegraphics[width=0.75\linewidth]{lights-out.pdf}
    \caption{Color code decoding as an instance of the \LO{} puzzle. The lattice for the $d=11$ triangular color code is shown. An initial configuration is indicated by marked faces. A possible (not necessarily minimal) solution set is marked in green.}
    \label{fig:problem-form}
\end{figure}

Now consider an instance of the decoding problem for a color code $\calC$ given the syndrome $s = He$ of an (unknown) error $e$. Then, the question of computing an estimate $\varepsilon$ of $e$ such that $H \varepsilon = s$ can be turned into a variation of the \LO{} puzzle described above as follows:
Instead of identifying lights and switches with the same entities (i.e., the faces of the underlying lattice) consider the following variation: 

\begin{itemize}
    \item Let each face of the color code lattice correspond to a light and
    \item each vertex (qubit) of the lattice correspond to a switch that toggles all adjacent lights.
\end{itemize}

\noindent Moreover, choose and fix an ordering of the lights and switches such that the set of lights that are turned on can be described as a binary vector whose length is equal to the number of lights (and analogously for switches).
The syndrome $s$ describes the initial configuration of the lights in the puzzle.
\begin{example}
    Consider the \LO{} illustration for the $d=11$ color code lattice depicted in~\autoref{fig:problem-form}. 
    Vertices correspond to switches, while faces correspond to lights.
    The figure shows an initial configuration with five lights being on (highlighted in yellow).
\end{example}

\pagebreak
Although the problem formulation is slightly different from the classical \LO{} puzzle, the observation made above still holds.
As such, the goal for the decoding problem in this analogy is to find a set of switches $\varepsilon$ such that toggling them turns off all the lights.
Such a set corresponds to an estimate $\varepsilon$ that is consistent with the syndrome, i.e., $H \varepsilon = s$.
Here, the size of the set corresponds to the \emph{weight} of the estimate (i.e., the number of qubits involved).
As described in \autoref{sec:considered_problem}, the goal of the decoding process is to determine an estimate with minimal (Hamming) weight. The following table provides a summary of the \LO{} analogy described throughout this section:

\begin{center}
\vspace{3mm}
     \begin{tabular}{l  l}%
        \toprule
             QEC & \LO{}\\
         \midrule
                         Qubits/vertices             & Switches   \\
                         Checks/faces             & Lights \\
                         Syndrome           & Initial configuration \\
                         Valid decoding estimate     & Solution set  \\
                         Minimum-weight decoding estimate  & Minimal solution set \\
                             
        \bottomrule
    \end{tabular}\\\vspace{3mm}
\end{center}


                             


\section{MaxSAT decoding}\label{sec:maxsat} %

In the following, we propose a MaxSAT formulation of the \LO{} analogy for the color code decoding problem that allows to determine \emph{minimum-weight} solutions.

\subsection{General idea}\label{sec:general_idea}

In order to formulate the \LO{} analogy of the decoding problem as a MaxSAT problem, a description of the underlying lattice $(F, V)$ is needed.
To this end, we first introduce Boolean variables $\mathit{switch}_1, \dots, \mathit{switch}_{|V|}$, where $|V|$ denotes the number of vertices in the lattice, associated with the number of qubits in the code.
In addition, a discrete function $\mathcal{F}_{\mathit{switches}}\colon\;F\to V^*$ is introduced (and realized as a dictionary), that takes a face $f\in F$ as input and returns the set of vertices $\mathcal{F}_{\mathit{switches}}(f)=\{v_1,\dots,v_{n_f}\}$ surrounding the face.
Finally, a Boolean function $\mathcal{F}_{\mathit{init}}\colon\;F\to \{\mathit{true},\,\mathit{false}\}$ describes the syndrome that has been measured and shall be decoded.
In the \LO{} analogy, $\mathcal{F}_{\mathit{switches}}$ returns the switches that toggle a given light, while $\mathcal{F}_{\mathit{init}}$ describes the initial configuration of the lights.

As observed above, any valid solution to the \LO{} puzzle toggles an \emph{odd} number of switches around a light that is \emph{on} in the initial configuration, while an \emph{even} number of switches surrounding a light that is initially \emph{off} is toggled.
This can be formulated as \emph{parity constraints}
\[
\forall{f\in F}\colon\; \bigoplus_{v\in \mathcal{F}_{\mathit{switches}}(f)} \mathit{switch}_v = \mathcal{F}_\mathit{init}(f),
\]
where $\bigoplus$ denotes the \emph{exclusive-or}  (XOR).
Satisfying these constraints, i.e., solving the satisfiability problem under these constraints, guarantees a valid solution to the \LO{} puzzle and, hence, the decoding problem.
Moreover, the formulation can be easily adapted to a \emph{maximum satisfiability problem} (MaxSAT) by adding the following soft constraints
\[
\forall f\in F\colon\;\mathit{not}(\mathit{switch}_f).
\]
The general MaxSAT problem is {\tt NP}-hard, as its solution leads to the solution of the Boolean satisfiability problem, which in turn is 
{\tt NP}-complete. 
Maximizing over these soft constraints \emph{minimizes} the switch variables that are set to \emph{true} in the solution and, hence, yields a \emph{minimum-weight} estimate for the decoding problem.

\subsection{Implementation details}\label{sec:details}

The encoding in the previous section has a rather simple form. For a given lattice $(V, F)$ representing some code, it introduces $|V|$ Boolean variables and $|F|$ parity constraints that involve at most
\[
\max_{f\in F} |\mathcal{F}_{\mathit{switches}}(f)|
\]
variables.
For the example of the triangular color code discussed before in \autoref{sec:background}, each parity constraint involves either four or six variables (due to the hexagonal tiling of the triangle).
However, it is well known that the way in which multi-variable parity constraints are realized heavily influences the performance of SAT solvers~\cite{soos2009extending, haanpaa2006hard, laitinen2012extending}.
Thus, for the resulting decoder to be efficient, a suitable encoding must be found.
Furthermore, the decoding problem is not a one-and-done task, but rather has to be solved over and over with different syndromes as input during the operation of an error-corrected quantum computer.
Hence, it is also important to allow for efficiently re-using an existing SAT instance instead of always constructing a new instance from scratch.
The straight-forward linear encoding
\[
\left[\bigoplus_{v\in \mathcal{F}_{\mathit{switches}}(f)} \mathit{switch}_v = \mathcal{F}_\mathit{init}(f)\right] \equiv \left[\left(\left(\left(\mathit{switch}_1 \oplus \mathit{switch}_2\right) \oplus \mathit{switch}_3\right)\cdots\right) = \mathcal{F}_\mathit{init}(f)\right]
\]
satisfies none of the above criteria. Such an encoding is known to cause problems for SAT solvers and there is no direct way of adjusting these constraints to new values of $\mathcal{F}_\mathit{init}(f)$ despite recreating them as a whole.

To overcome this issue, the proposed formulation introduces $k=|\mathcal{F}_{\mathit{switches}}(f)|-1$ helper variables $h_1,\dots,h_{k}$ and splits the overall constraint into $k+1$ separate constraints
\begin{align*}
    \mathit{switch}_1 \oplus h_1 &= \mathcal{F}_\mathit{init}(f), \\
    h_{i} &= \mathit{switch}_{i+1} \oplus h_{i+1} \qquad\mbox{ for } i=1,\dots, k-1, \\
    h_{k} &= \mathit{switch}_{k}.
\end{align*}
It is easy to verify that this still realizes the parity constraint on the switch variables.
Observe how only the first of those constraints depends on the value of $\mathcal{F}_\mathit{init}(f)$.
All other constraints can be pre-computed independently.
As confirmed by numerical evaluations, which are summarized next, this yields an efficient and re-usable MaxSAT decoder for quantum color codes that achieves state-of-the-art decoding performance (for the considered noise model and code).










\section{Numerical evaluation}\label{sec:experiments}
To evaluate the proposed approach, the decoder performance as well as the run-time (scaling) of the proposed approach have been comprehensively investigated using numerical simulations. 
The results will be presented in two parts. First, the decoder performance and the \emph{threshold}---a well-established figure of merit---are discussed. 
In a second series of experiments, we focus on the run-time scaling of the proposed approach.
In addition to all numerical data, the implementation of the decoder as well as means to conduct numerical simulations are made available as open-source software at %
\url{www.github.com/cda-tum/qecc}
as part of %
of the \emph{Munich Quantum Toolkit} (MQT). 

\subsection{Decoding performance}\label{sec:dp}
In this section, findings related to the decoding performance are presented. 
To this end, the proposed decoder has been implemented using the MaxSAT engine of Microsoft's Z3~\cite{de2008z3} solver. All simulations have been conducted on a machine equipped with an \mbox{AMD Ryzen 9 5950X} CPU and \SI{64}{\gibi\byte} RAM running Ubuntu~22.04. 
As previously stated in the paper, the error model under consideration is \emph{bit-flip noise}.
In a first round of experiments, the \emph{logical error rate} of triangular color codes is investigated. Recall that a logical error is an error that changes the logical information. Thus, if a decoding estimate (the resulting residual error) induces a logical error, the decoding process is considered to have failed, since the proposed estimate (together with the actual error) has altered the logical information. 
A widely used figure of merit of a code $+$ decoder $+$ error model combination is the \emph{threshold} $p_{th}$. Intuitively, this is an estimate of a physical error rate up to which the code is beneficial. For $p<p_{th}$, the logical error rate can be exponentially suppressed by scaling the code (inducing a potentially large overhead). The optimal threshold of color codes on a hexagonal lattice under bit-flip noise is $\approx 10.9\%$~\cite{katzgraber2009error}, which is achieved by the tensor network decoder~\cite{chubb2021general} as mentioned in~\autoref{sec:rel-work}.

In order to investigate the logical error rates and estimate the threshold, we run \mbox{Monte-Carlo} simulations for increasing physical error rates $p$ and code distances up to $d=21$. A single sample is obtained in the following steps: 

\pagebreak

\begin{itemize}
    \item Sample an error $e \in \Ftn$,
    \item compute the syndrome $s = H\cdot e$,
    \item use the proposed decoder to get an estimate $\varepsilon$,
    \item compute the residual error $r = e + \varepsilon$, and
    \item check if $r$ is a logical operator.
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{ler-th-ms.pdf}
    \caption{Logical error rates of triangular color codes with distances ranging from 3 to 21 under bit-flip noise. The right plot shows the subsection of the left plot close to the threshold of $p_{th}\approx 10.1$. The error bars in the right plot correspond to one standard deviation.}
    \label{fig:lers-th}
\end{figure}

If $r$ is a logical operator, the correction together with the original error has altered the encoded information, which is recorded as a \emph{logical error}. The \emph{logical error rate} (LER) is then computed as the number of logical errors over the number of samples. The results are shown on the left-hand side in~\autoref{fig:lers-th}. 
Our results show that the proposed decoder achieves a threshold of $p_{th}\approx 10.1\%$, outperforming many other state-of-the-art decoders. The threshold is computed using the critical exponent method described in Ref.~\cite{WANG200331}. The logical error rate close to the threshold is shown on the right-hand side in \autoref{fig:lers-th}. 

In order to put this in context, the following table shows a comparison with other state-of-the-art decoders and their threshold for color codes on a hexagonal lattice under the same noise model as considered in this work.
\begin{center}
     \begin{tabular}{l r r}%
        \toprule
             Decoder & Threshold & Source\\
         \midrule
                         Optimal           & $10.9\%$  & \cite{katzgraber2009error}  \\
                         Tensor network    & $10.9\%$  & \cite{chubb2021general}\\
                         MaxSAT*            & $10.1\%$ & this work \\
                         Neural network    & $10.0\%$  & \cite{maskara2019advantages} \\
                         M\"obius MWPM     & $9.0\%$  & \cite{sahay2022decoder}  \\
                         Restriction MWPM  & $8.7\%$   & \cite{delfosse2014decoding}  \\
                         Union-find        & $8.4\%$   & \cite{delfosse2021almost}  \\
                         RG                & $7.8\%$   & \cite{sarvepalli2012efficient} \\    
        \bottomrule
    \end{tabular}\\\vspace{1mm}
    \label{table:sota}
\end{center}

A fundamental theorem of FT, the \emph{threshold theorem} states that if errors can be exponentially suppressed below the threshold $p_{th}$, arbitrarily long quantum computations can be conducted fault-tolerantly \cite{preskill1998reliable}. To demonstrate this sub-threshold scaling, we plot the logical error rates as a function of the distance for different physical error rates in~\autoref{fig:lers-perd}. For error rates below the threshold $p<p_{th}$ it can be verified that for increased distances the logical error rate decreases exponentially,  while, naturally, above the threshold this is not the case.

Recall that the distance of an $[[n,k,d]]$-code is the minimum weight of a (non-trivial) logical operator. In general, the distance is an indicator of how many errors a code can in principle correct ($(d-1)/2$). In the best case, the decoder performance matches this bound. In our experiments, we observe that the minimum weight logical operators induced by the decoder always have weight equal to the distance $d$ for the investigated distances. Note that it is common for decoders to be only able to correct up to a polynomial fraction of $d$. 
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{ler-d.pdf}
    \caption{Logical error rate per distance for various physical error rates $p$. Note that $p=0.11$ and $p=0.13$ are above threshold.}
    \label{fig:lers-perd}
\end{figure}

\subsection{Run-time scaling}\label{sec:rt}
To estimate the time needed to decode and to determine how the run-time performance scales as the codes under consideration get larger, numerical simulations to measure the time needed to solve the MaxSAT instance were conducted. 
Since the MaxSAT instance and most of the needed information concerning the code can be precomputed, the dominant bottleneck of a single correction cycle is the MaxSAT solver. Thus, we only record the time needed to solve a given instance, which we indicate as \emph{run-time} of the solver.
The results are summarized in~\autoref{fig:rts}. Overall the run-time for a single decoding takes up to a hundred milliseconds for distances smaller than $21$ and a few hundred milliseconds for larger distances. What is especially interesting is that the run-time scales proportionally with the physical error rate, hence for lower physical error rates the run-time is better. This is similar to the run-time behaviour of matching-based decoders and beneficial since in practice the lower physical error rates are the more relevant ones. 

\begin{figure}
    \centering
    \includegraphics[width=0.96\textwidth]{rt-ms.pdf}
    \caption{Average run-time in micro seconds for a single decoding run of the MaxSAT decoder on triangular color codes and run-time per distance for several physical error rates $p$. Every data point has been obtained from $10^4$ samples.}
    \label{fig:rts}
\end{figure}

To put the obtained estimates in context (without arguing that the proposed approach is directly applicable to be employed for physical devices), consider that for realizations of quantum error-correction, a quantum device built on a superconducting architecture has cycles times in the micro-second regime~\cite{google2021exponential,google2023suppressing}. This means that the decoder would need to be able to decode single instances in such time regimes as well in order not to slow down the whole computation. For ion-trap based devices, it is known that operations are slower and cycle times are in the millisecond regime~\cite{ryan2021realization}. Note that for such practical settings the decoder needs to be able to take a more involved noise model into account. Additionally, since the run-time is highly dependent on the MaxSAT formulation, how the constraints are exactly formulated, and the solver itself, we expect that the obtained run-times can be optimized further. However, we leave more fine-grained run-time optimizations for future work. 

\begin{figure}
    \centering
    \includegraphics[width=.9\textwidth]{cmp.pdf}
    \caption{Comparison of the run-time performance of a state-of-the-art MaxSAT solver for different physical error rates on triangular color codes.}
    \label{fig:rt-cmp-solvers}
\end{figure}
Since MaxSAT solvers and their optimization is a vibrant area of research, we conducted simulations to compare the original implementation that uses Z3 and other state-of-the-art MaxSAT solvers. 
More specifically, we conducted simulations to compare the run-time performance of all MaxSAT solvers that participated in the \emph{MaxSAT Evaluation 2022}  (MSE22)~\cite{bacchus2022maxsat}.
Preliminary evaluations indicated that all solvers from the MSE22 have comparative run-time performance---running within $\approx4\%$ of each other.
Consequently, we chose the winner of the MSE22 (\emph{CASHWMaxSAT-CorePlus}) and compared its run-time against the original implementation that uses Z3.
The results, which are depicted in \autoref{fig:rt-cmp-solvers}, show that the Z3-based solution outperforms the other MaxSAT solver in all but one case.
The most vital insight, however, is that only the performance of the original implementation that uses Z3 as solver has run-time performance that scales proportionally with the physical error rate. 
This is not true for all other investigated solvers. 
Since the sub-threshold regime (low physical error rate) is the one relevant in practice, this behaviour is desirable and, overall, the Z3-based implementation outperforms all other solvers in this regime.
One reason for this phenomenon could be that Z3 (as an SMT solver) performs a diverse set of optimizations on the constructed MaxSAT formulations, while, in order to use the other MaxSAT solvers, the formulation had to be converted to \emph{weighted CNF} (WCNF)---for which we used the automatic conversion methods built into Z3).
This conversion might limit the potential for optimization that are performed by the solvers.

\subsection{Comparison with the tensor network decoder}
To draw a comparison to implementations of existing decoders, we compare the run-time and the decoding performance of the proposed MaxSAT decoder to the \emph{tensor network decoder}~\cite{chubb2021general}, as this is the only known state-of-the art decoder that has a higher threshold than the proposed MaxSAT decoder. We use the tensor network decoder implementation provided in the QECSIM tool~\cite{qecsim} (which---to the best of our knowledge---is the only open-source implementation). 

We run the decoder on the same machine used for the MaxSAT decoder simulations. The decoder takes as an input parameter the maximum bond-dimension, which we set to 10. The run-time includes the time QECSIM takes to sample an error and check if a logical error occurred, but the obtained estimates are enough to draw reasonable comparisons, as the overall time is dominated by the decoding time.
The results are shown in~\autoref{fig:rts-tn}. 
Our results indicate that the run-time of the tensor network decoder does not scale with the physical error rate. This agrees with the known run-time of the tensor network decoder, which is $\mathcal{O}(n \chi^3)$, where $n$ is the number of qubits and $\chi$ is the bond dimension.  
The MaxSAT decoder run-time does scale with physical error rate and it therefore performs better for sub-threshold error rates. 
To be specific, for a distance 21 code at a physical error rate of $10^{-3}$ the MaxSAT decoder is approximately 9 times faster than the tensor network decoder ($25$ vs $225$ milliseconds).

\begin{figure}
    \centering
    \includegraphics[width=.9\textwidth]{rt-tn.pdf}
    \caption{Run-time performance of the tensor network decoder. The results are obtained using $10^4$ samples and the maximum bond dimension of the tensor network is set to 10. }
    \label{fig:rts-tn}
\end{figure}


\section{Conclusions and outlook}\label{sec:conclusion}

In this work, we have proposed a novel decoding approach for quantum codes. Based on an analogy of the decoding problem for color codes and the well-known mathematical puzzle, \LO{}, we have introduced a MaxSAT solution to the corresponding problem. Moreover, an efficient construction of the corresponding satisfiability instance through various constraint optimizations has been proposed. In several numerical simulations, it has been shown that the proposed decoder achieves near-optimal decoding performance. Moreover, the experimental evaluation signifies that the run-time performance of the decoder scales proportionally with the error rate and thus outperforms state-of-the-art decoders, such as the tensor network decoder for low error rates. In addition to the high performance and good run-time scaling, an advantage of the proposed decoder is that it is very general and not limited to color codes. The decoder implementation, as well as all the obtained data are integrated into the open-source software package QECC~\cite{berent2023software} as part of the \emph{Munich Quantum Toolkit (MQT)}.

Concerning future work building on the findings laid out here, one of the most exciting directions is to extend the considered noise model to more realistic scenarios, such as noisy syndrome measurements and circuit-level noise. It would be interesting to see what the limitations of the decoder performance for such noise models is. Moreover, since for low-weight syndromes the run-time performance is good, a combination with other decoders such as \emph{union-find} or \emph{belief-propagation} (belief-MaxSAT, union-MaxSAT) might result in a better overall performance for larger codes. Furthermore, it is reasonable to assume that the run-time performance can be further improved through optimizations regarding the MaxSAT solver. There are SAT solvers such as \emph{crypto-minisat}~\cite{soos2009extending} that are optimized for XOR-constraints. Unfortunately, we are not aware of a MaxSAT version of such solvers at the moment. Overall, a general goal of this work is to highlight that fundamental problems in quantum computing are still open and to foster interest in solving these problems with known and well-established tools from the field of SAT and constraint satisfaction research. In turn, these tools may help tackling the decoding problem that to date is one of the roadblocks against fault tolerant quantum computing.

\bibliography{refs}


\end{document}
