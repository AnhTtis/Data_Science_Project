{
    "arxiv_id": "2303.10536",
    "paper_title": "TempT: Temporal consistency for Test-time adaptation",
    "authors": [
        "Onur Cezmi Mutlu",
        "Mohammadmahdi Honarmand",
        "Saimourya Surabhi",
        "Dennis P. Wall"
    ],
    "submission_date": "2023-03-19",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.AI"
    ],
    "abstract": "In this technical report, we introduce TempT, a novel method for test time adaptation on videos by ensuring temporal coherence of predictions across sequential frames. TempT is a powerful tool with broad applications in computer vision tasks, including facial expression recognition (FER) in videos. We evaluate TempT's performance on the AffWild2 dataset as part of the Expression Classification Challenge at the 5th Workshop and Competition on Affective Behavior Analysis in the wild (ABAW). Our approach focuses solely on the unimodal visual aspect of the data and utilizes a popular 2D CNN backbone, in contrast to larger sequential or attention based models. Our experimental results demonstrate that TempT has competitive performance in comparison to previous years reported performances, and its efficacy provides a compelling proof of concept for its use in various real world applications.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10536v1"
    ],
    "publication_venue": "4 Pages, 3 figures"
}