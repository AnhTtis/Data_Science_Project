@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@article{ekman,
  title={Basic emotions},
  author={Ekman, Paul and others},
  journal={Handbook of cognition and emotion},
  volume={98},
  number={45-60},
  pages={16},
  year={1999}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{resnext,
  title={Aggregated residual transformations for deep neural networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1492--1500},
  year={2017}
}

@inproceedings{squeezeexcite,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}

@article{adamw,
  title={Fixing weight decay regularization in adam},
  author={Loshchilov, Ilya and Hutter, Frank},
  year={2017}
}

@inproceedings{bn_freeze_adapt,
  title={Partial transfusion: on the expressive influence of trainable batch norm parameters for transfer learning},
  author={Kanavati, Fahdi and Tsuneki, Masayuki},
  booktitle={Medical Imaging with Deep Learning},
  pages={338--353},
  year={2021},
  organization={PMLR}
}

@article{salimans2016weight,
  title={Weight normalization: A simple reparameterization to accelerate training of deep neural networks},
  author={Salimans, Tim and Kingma, Durk P},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{conv3d,
  title={3D convolutional neural networks for human action recognition},
  author={Ji, Shuiwang and Xu, Wei and Yang, Ming and Yu, Kai},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={1},
  pages={221--231},
  year={2012},
  publisher={IEEE}
}

@inproceedings{transformer,
  title={Vivit: A video vision transformer},
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{\'c}, Mario and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6836--6846},
  year={2021}
}

@inproceedings{cnnlstm,
  title={Modeling spatial-temporal clues in a hybrid deep learning framework for video classification},
  author={Wu, Zuxuan and Wang, Xi and Jiang, Yu-Gang and Ye, Hao and Xue, Xiangyang},
  booktitle={Proceedings of the 23rd ACM international conference on Multimedia},
  pages={461--470},
  year={2015}
}



@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{bn_adapt,
  title={Improving robustness against common corruptions by covariate shift adaptation},
  author={Schneider, Steffen and Rusak, Evgenia and Eck, Luisa and Bringmann, Oliver and Brendel, Wieland and Bethge, Matthias},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11539--11551},
  year={2020}
}

@article{ldam,
  title={Learning imbalanced datasets with label-distribution-aware margin loss},
  author={Cao, Kaidi and Wei, Colin and Gaidon, Adrien and Arechiga, Nikos and Ma, Tengyu},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

% Datasets
@article{mollahosseini2017affectnet,
  title={Affectnet: A database for facial expression, valence, and arousal computing in the wild},
  author={Mollahosseini, Ali and Hasani, Behzad and Mahoor, Mohammad H},
  journal={IEEE Transactions on Affective Computing},
  volume={10},
  number={1},
  pages={18--31},
  year={2017},
  publisher={IEEE}
}

@inproceedings{rafdb1,
  title={Reliable Crowdsourcing and Deep Locality-Preserving Learning for Expression Recognition in the Wild},
  author={Li, Shan and Deng, Weihong and Du, JunPing},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={2584--2593},
  year={2017},
  organization={IEEE}
}

@article{rafdb2,
  title={Reliable Crowdsourcing and Deep Locality-Preserving Learning for Unconstrained Facial Expression Recognition},
  author={Li, Shan and Deng, Weihong},
  journal={IEEE Transactions on Image Processing},
  volume={28},
  number={1},
  pages={356--370},
  year={2019},
  publisher={IEEE}
}

@article{kalantarian2019labeling,
  title={Labeling images with facial emotion and the potential for pediatric healthcare},
  author={Kalantarian, Haik and Jedoui, Khaled and Washington, Peter and Tariq, Qandeel and Dunlap, Kaiti and Schwartz, Jessey and Wall, Dennis P},
  journal={Artificial intelligence in medicine},
  volume={98},
  pages={77--86},
  year={2019},
  publisher={Elsevier}
}

@article{jacobian,
  title={Robust learning with jacobian regularization},
  author={Hoffman, Judy and Roberts, Daniel A and Yaida, Sho},
  journal={arXiv preprint arXiv:1908.02729},
  year={2019}
}

% TTA

@article{bn1,
  title={Revisiting batch normalization for practical domain adaptation},
  author={Li, Yanghao and Wang, Naiyan and Shi, Jianping and Liu, Jiaying and Hou, Xiaodi},
  journal={arXiv preprint arXiv:1603.04779},
  year={2016}
}

@inproceedings{ttt,
  title={Test-time training with self-supervision for generalization under distribution shifts},
  author={Sun, Yu and Wang, Xiaolong and Liu, Zhuang and Miller, John and Efros, Alexei and Hardt, Moritz},
  booktitle={International conference on machine learning},
  pages={9229--9248},
  year={2020},
  organization={PMLR}
}

@article{tent,
  title={Tent: Fully test-time adaptation by entropy minimization},
  author={Wang, Dequan and Shelhamer, Evan and Liu, Shaoteng and Olshausen, Bruno and Darrell, Trevor},
  journal={arXiv preprint arXiv:2006.10726},
  year={2020}
}

@article{bn_expressive,
  title={Training batchnorm and only batchnorm: On the expressive power of random features in cnns},
  author={Frankle, Jonathan and Schwab, David J and Morcos, Ari S},
  journal={arXiv preprint arXiv:2003.00152},
  year={2020}
}

@article{arm,
  title={Adaptive risk minimization: Learning to adapt to domain shift},
  author={Zhang, Marvin and Marklund, Henrik and Dhawan, Nikita and Gupta, Abhishek and Levine, Sergey and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={23664--23678},
  year={2021}
}

@inproceedings{shot,
  title={Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation},
  author={Liang, Jian and Hu, Dapeng and Feng, Jiashi},
  booktitle={International Conference on Machine Learning},
  pages={6028--6039},
  year={2020},
  organization={PMLR}
}

@article{memo,
  title={Memo: Test time robustness via adaptation and augmentation},
  author={Zhang, Marvin and Levine, Sergey and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={38629--38642},
  year={2022}
}

@article{note,
  title={Note: robust continual test-time adaptation against temporal correlation},
  author={Gong, Taesik and Jeong, Jongheon and Kim, Taewon and Kim, Yewon and Shin, Jinwoo and Lee, Sung-Ju},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27253--27266},
  year={2022}
}

@inproceedings{cotta,
  title={Continual test-time domain adaptation},
  author={Wang, Qin and Fink, Olga and Van Gool, Luc and Dai, Dengxin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7201--7211},
  year={2022}
}

% MUST CITE

@article{kollias2023abaw,
  title={ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit Detection \& Emotional Reaction Intensity Estimation Challenges},
  author={Kollias, Dimitrios and Tzirakis, Panagiotis and Baird, Alice and Cowen, Alan and Zafeiriou, Stefanos},
  journal={arXiv preprint arXiv:2303.01498},
  year={2023}
}

@article{kollias2022abaw, title={ABAW: Learning from Synthetic Data \& Multi-Task Learning Challenges}, author={Kollias, Dimitrios}, journal={arXiv preprint arXiv:2207.01138}, year={2022} }


@article{kollias2021distribution, title={Distribution Matching for Heterogeneous Multi-Task Learning: a Large-scale Face Study}, author={Kollias, Dimitrios and Sharmanska, Viktoriia and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:2105.03790}, year={2021} }

@inproceedings{kollias2021analysing, title={Analysing affective behavior in the second abaw2 competition}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages={3652--3660}, year={2021}}

@article{kollias2021affect, title={Affect Analysis in-the-wild: Valence-Arousal, Expressions, Action Units and a Unified Framework}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:2103.15792}, year={2021}}


@inproceedings{kollias2020analysing, title={Analysing Affective Behavior in the First ABAW 2020 Competition}, author={Kollias, D and Schulc, A and Hajiyev, E and Zafeiriou, S}, booktitle={2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)(FG)}, pages={794--800}, year={2021}}


@article{kollias2019expression, title={Expression, Affect, Action Unit Recognition: Aff-Wild2, Multi-Task Learning and ArcFace}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:1910.04855}, year={2019}}


@article{kollias2019face,title={Face Behavior a la carte: Expressions, Affect and Action Units in a Single Network}, author={Kollias, Dimitrios and Sharmanska, Viktoriia and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:1910.11111}, year={2019}}


@article{kollias2019deep, title={Deep affect prediction in-the-wild: Aff-wild database and challenge, deep architectures, and beyond}, author={Kollias, Dimitrios and Tzirakis, Panagiotis and Nicolaou, Mihalis A and Papaioannou, Athanasios and Zhao, Guoying and Schuller, Bj{\"o}rn and Kotsia, Irene and Zafeiriou, Stefanos}, journal={International Journal of Computer Vision}, pages={1--23}, year={2019}, publisher={Springer} }


@inproceedings{zafeiriou2017aff, title={Aff-wild: Valence and arousal ‘in-the-wild’challenge}, author={Zafeiriou, Stefanos and Kollias, Dimitrios and Nicolaou, Mihalis A and Papaioannou, Athanasios and Zhao, Guoying and Kotsia, Irene}, booktitle={Computer Vision and Pattern Recognition Workshops (CVPRW), 2017 IEEE Conference on}, pages={1980--1987}, year={2017}, organization={IEEE} } 

@ARTICLE{8453893,
  author={Li, Shan and Deng, Weihong},
  journal={IEEE Transactions on Image Processing}, 
  title={Reliable Crowdsourcing and Deep Locality-Preserving Learning for Unconstrained Facial Expression Recognition}, 
  year={2019},
  volume={28},
  number={1},
  pages={356-370},
  doi={10.1109/TIP.2018.2868382}}

@ARTICLE{8576656,
  author={Li, Yong and Zeng, Jiabei and Shan, Shiguang and Chen, Xilin},
  journal={IEEE Transactions on Image Processing}, 
  title={Occlusion Aware Facial Expression Recognition Using CNN With Attention Mechanism}, 
  year={2019},
  volume={28},
  number={5},
  pages={2439-2450},
  doi={10.1109/TIP.2018.2886767}}

@ARTICLE{9075283,
  author={Fan, Yingruo and Li, Victor O.K. and Lam, Jacqueline C.K.},
  journal={IEEE Transactions on Affective Computing}, 
  title={Facial Expression Recognition With Deeply-Supervised Attention Network}, 
  year={2022},
  volume={13},
  number={2},
  pages={1057-1071},
  doi={10.1109/TAFFC.2020.2988264}}

@inproceedings{xue2021transfer,
  title={Transfer: Learning relation-aware facial expression representations with transformers},
  author={Xue, Fanglei and Wang, Qiangchang and Guo, Guodong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3601--3610},
  year={2021}
}

